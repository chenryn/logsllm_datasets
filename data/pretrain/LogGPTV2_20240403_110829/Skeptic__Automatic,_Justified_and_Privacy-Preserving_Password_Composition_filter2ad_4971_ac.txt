### Flow Between Tools

The utility is parametric on a password probability distribution derived from a real-world leaked password dataset. Password probabilities are then redistributed according to a password composition policy (interpreted by Authority), producing output distributions under each supported macrobehavior. The architecture is modular, allowing user-specified macrobehaviors to be integrated without modifying the core of the tool. The Pyrrho plugin corresponding to the proportional password reselection macrobehavior from Section 3.3 is shown in Figure 10. Here, `total` is the sum of all probabilities in the distribution before filtration (which should be approximately 1), `surplus` is the sum of the probabilities of all filtered passwords, and `df` is the data frame representing the password probability distribution to be processed.

Pyrrho additionally performs power-law curve fitting to the altered password probability distributions to quantify their uniformity (see Section 3.4). The resulting equations are stored as JSON files alongside the distributions. These JSON files can be used to compare and rank policies from the Pacpal DSL (see Section 4.3).

While Pyrrho is primarily designed to be used alongside password composition policies encoded in Coq using Authority, the inter-process communication between the two utilities can make processing large datasets time-consuming. For applications where the ability to reason about password composition policies within Coq is less critical, Pyrrho supports Pure Python Mode. In this mode, all dataset filtration with respect to a password composition policy is handled within Pyrrho itself. This results in a utility that runs approximately 2.75 times faster (see Section 5.1), but at the expense of the flexibility and reasoning capabilities provided by Authority, as Pure Python Mode supports only a limited set of password composition policy rules.

### Skeptic: Automatic, Justified, and Privacy-Preserving Password Composition Policy Selection

#### Example Pacpal Code
```python
# Load three equations produced by Pyrrho.
load linkedin-basic16-proportional.json as li_b16
load linkedin-2word16-proportional.json as li_2w16
load linkedin-3class12-proportional.json as li_3c12

# Assert that one policy is better than another.
assert li_2w16 better li_b16

# Build group to rank.
group linkedin_ranking
add li_b16 to linkedin_ranking as basic16
add li_2w16 to linkedin_ranking as 2word16
add li_3c12 to linkedin_ranking as 3class12

# Print group in ranked order (worst to best):
rank linkedin_ranking
```
Figure 11: A piece of example Pacpal code, demonstrating ranking of policies based on fitted power-law equations.

The `assert` statement will display an error if the relationship does not hold. We use Pacpal to produce the rankings of all 28 password policies used in this study (see Section 5.4).

### Evaluation

In this section, we demonstrate the validity of our approach by replicating results from previous literature across different evaluation methodologies. Specifically, we use the Skeptic toolkit to replicate results from the study by Shay et al. [31] that uses real participants recruited via Amazon Mechanical Turk (see Section 5.2) and the study by Weir et al. [36] that draws on large leaked password datasets (see Section 5.3). In Section 5.5, we demonstrate the advantages of the Authority Coq metaprogramming utility (see Section 4.1) by proving that certain policies confer immunity to password guessing attacks from within the proof assistant itself.

#### 5.1 Experimental Setup

The password probability distribution processing (via Pyrrho) for this experiment was conducted on a cluster of 14 cloud-based virtual machines, each with 6 Intel® Xeon® CPUs at 1.80GHz, 16GB of RAM, and 320GB of hard disk space running 64-bit Ubuntu 18.04.3 (LTS). The times taken by Pyrrho to process each dataset studied in this work under each policy and macrobehavior are shown in Table 2.

#### 5.2 Replication of Results: Shay et al.

Shay et al. [31] ranked the effectiveness of 8 different password composition policies under a password guessing attack at two different magnitudes—10^6 guesses and 10^14 guesses. These thresholds are suggested by Florêncio et al. [15] as being representative of the cutoff points for contemporary online (i.e., against a live service) and offline (i.e., against a compromised password hash) guessing attacks, respectively. Passwords were chosen by humans under each policy using Amazon Mechanical Turk, and the attack was multimodal, using both a trained, targeted probabilistic context-free grammar (PCFG) [22, 37] and the Password Guessability Service (PGS) [33]. Table 3 contains an overview of these results.

Table 3: The results obtained by Shay et al. [31] for passwords collected under 8 different password composition policies at both attack magnitudes.

| 10^6 guesses | 10^14 guesses |
|-------------|--------------|
| **Policy**  | **Cracked (%)** | **Rank** | **Cracked (%)** | **Rank** |
| comp8       | 2.2          | 3        | 50.1            | 7        |
| basic12     | 9.1          | 8        | 52              | 8        |
| basic16     | 7.9          | 7        | 29.7            | 4        |
| basic20     | 5.6          | 6        | 16.4            | 2        |
| 2word12     | 3.4          | 5        | 46.6            | 6        |
| 2word16     | 1.1          | 1        | 22.9            | 3        |
| 3class12    | 3.2          | 4        | 36.8            | 5        |
| 3class16    | 1.2          | 2        | 13.8            | 1        |

We attempted to replicate these results using the Skeptic toolkit. For each of our 3 datasets and each of the 4 studied macrobehaviors, we redistributed probability according to each policy in Table 3. We then obtained the α values yielded by fitting power-law curves to the resulting distributions using the methodology described in Section 3.4. To quantify how closely our results reflect the rankings from Shay et al. [31], we plotted the percentage of passwords cracked under each policy in Shay et al. [31] against the α-values we obtained and calculated the Pearson correlation coefficient ρ. A value closer to -1 indicates that more uniform distributions (i.e., a less negative α-value) are more strongly correlated with a lower percentage of cracked passwords, while a value closer to 1 indicates the opposite. A value of 0 indicates no correlation. The complete set of correlation coefficients and their mean values across datasets (¯ρ) can be found in Table 4, while an example visualization using the LinkedIn dataset only is shown in Figure 12. Complete results are shown in the Appendix (Table 11).

Table 4: Pearson correlation coefficients of the percentage of passwords cracked under different policies by Shay et al. [31] at 10^14 guesses against α-values yielded by Skeptic.

| Dataset | Yahoo | RockYou | LinkedIn* |
|---------|-------|----------|------------|
| Proportional | -0.661 | -0.591 | -0.929 |
| Convergent | 0.882 | -0.069 | 0.615 |
| Extraneous | -0.722 | -0.689 | -0.952 |
| Null | -0.550 | -0.565 | -0.884 |
| Mean (¯ρ) | -0.727 | 0.476 | -0.788 | -0.666 |

* Visualized in Figure 12.

From Table 4, it is apparent that α-values for proportional, extraneous, and null macrobehaviors tend to correlate well with the empirical results from Shay et al. [31]. Using thresholds proposed by Evans [12], correlation strengths range from moderate (0.40 ≤ |ρ| ≤ 0.59) to very strong (0.80 ≤ |ρ| ≤ 1.0) for each of these macrobehaviors across all 3 datasets, with an average correlation strength of strong (0.60 ≤ |ρ| ≤ 0.79). By contrast, the convergent macrobehavior tends to show a correlation in the opposite direction, with less uniform distributions being associated with lower percentages of cracked passwords. This suggests that the convergent macrobehavior is a poor model of how users actually reselect passwords in response to password composition policies.

We found α-values yielded by Skeptic to correlate slightly less closely with the percentage of passwords cracked by the smaller online-range guessing attack from Shay et al. [31] (see Table 5 and Figure 13). We hypothesize that this is due to the success of smaller guessing attacks being more dependent on the dataset they are performed against. It is also possible that the multimodal attack employed by Shay et al. [31] is causing guessing attacks at lower magnitudes to be more effective against passwords created under different password composition policies than at higher magnitudes.

Table 5: Pearson correlation coefficients of the percentage of passwords cracked under different policies by Shay et al. [31] at 10^6 guesses against α-values yielded by Skeptic.

| Mode | Yahoo | RockYou | LinkedIn* | Mean (¯ρ) |
|------|-------|----------|------------|-----------|
| Proportional | -0.866 | -0.676 | -0.149 | -0.564 |
| Convergent | 0.217 | -0.181 | 0.615 | 0.217 |
| Extraneous | -0.830 | -0.808 | -0.462 | -0.700 |
| Null | -0.684 | -0.797 | -0.558 | -0.680 |

* Visualized in Figure 13.

The observation that the proportional, null, and extraneous macrobehaviors offer a more accurate picture of user password reselection than convergent reselection is encouraging because each of these models provides a more realistic representation of password composition policy effectiveness, rather than collecting passwords from humans themselves under those policies.

Table 6: An approximation of the results obtained by Weir et al. [36] for passwords obtained under 12 different password composition policies by filtering their target dataset.

| Policy | 5 × 10^4 guesses | Cracked (%) | Rank |
|--------|------------------|--------------|------|
| basic7 | 26.06            | 12           |
| basic8 | 23.16            | 11           |
| basic9 | 18.98            | 10           |
| basic10 | 13.85            | 8            |
| upper7 | 13.89            | 9            |
| upper8 | 10.71            | 7            |
| upper9 | 7.71             | 6            |
| upper10 | 5.72             | 4            |
| symbol7 | 6.92             | 5            |
| symbol8 | 5.57             | 3            |
| symbol9 | 4.76             | 2            |
| symbol10 | 3.28             | 1            |

This work, among other results, presents the percentage of passwords cracked at 50,000 guesses under 4 different password length thresholds (7, 8, 9, and 10) and 3 different character requirements (none, at least one uppercase, and at least one symbol). Both the target passwords and the attack were drawn from separate subsets of the same RockYou dataset [11] used in this work. We present an approximation of results from [36] in Table 6, obtained using a plot digitizer from the visualizations in the work.

Table 7: Pearson correlation coefficients of password policy ranks from [36] at 5 × 10^4 guesses against α-values yielded by Skeptic.

| Mode | Yahoo | RockYou | LinkedIn Mean |
|------|-------|----------|---------------|
| Proportional | -0.884 | -0.916 | -0.895 |
| Convergent | 0.686 | -0.657 | -0.885 |
| Extraneous | -0.955 | -0.951 | 0.089 |
| Null | -0.953 | -0.945 | 0.234 |
| Mean (¯ρ) | -0.969 | -0.969 | -0.969 |