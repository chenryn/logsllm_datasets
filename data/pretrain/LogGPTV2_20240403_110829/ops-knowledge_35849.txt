User: Say I have 3 input files A, B, C. I want that 

the mapper only gets records from A
the partitioner gets input from both the mapper and files B and C
the reducer gets input from the mapper (which has been directed by the partitioner) and file C.

Is this possible to do in Hadoop?
P.S. - I am using Python and Hadoop Streaming
Assistant: The only way you can do it is if files B and C are very small so that you can put them into the distcache and fetch them in all your Job.   There is no partitioner Job in Hadoop.  Partitioners run as part of map jobs, so it's the every mapper that has to read all 3 files A,B and C.
The same applies to the reducer part.  If B and C files are very large then you have to examine you data-flow and combine A,B,C in separate jobs. Can't explain how do it unless you share more details about your processing