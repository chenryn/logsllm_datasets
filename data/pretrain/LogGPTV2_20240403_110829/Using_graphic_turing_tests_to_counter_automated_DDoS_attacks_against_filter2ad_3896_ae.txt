0.56
6. RELATED WORK
As a result of its increased popularity and usefulness, the In-
ternet contains both interesting targets and enough malicious and
ignorant users that DoS attacks are simply not going to disappear
on their own; indeed, although the press has stopped reporting such
incidents, recent studies have shown a surprisingly high number
of DoS attacks occurring around the clock throughout the Internet
[23]. Worse, the Internet is increasingly being used for time-critical
applications (e.g., electricity production monitoring and coordina-
tion between different generators). A further compounding factor is
the susceptibility of the basic protocols (i.e., IP and TCP) to denial
of service attacks [32, 14].
The need to protect against or mitigate the effects of DoS attacks
has been recognized by both the commercial and research world.
Some work has been done toward achieving these goals, e.g., [15,
9, 31, 30, 13, 33, 35]. However, these mechanisms focus on de-
tecting the source of DoS attacks in progress and then countering
them, typically by “pushing” some ﬁltering rules on routers as far
away from the target of the attack (and close to the sources) as
possible. Thus, they fall into this class of approaches that are re-
active. The motivation behind such approaches has been twofold:
ﬁrst, it is conceptually simple to introduce a protocol that will be
used by a relatively small subset of the nodes on the Internet (i.e.,
ISP routers), as opposed to requiring the introduction of new pro-
tocols that must be deployed and used by end-systems. Second,
these mechanisms are fairly transparent to protocols, applications,
and legitimate users. Unfortunately, these reactive approaches by
themselves are not always adequate solutions.
• Methods that ﬁlter trafﬁc by looking for known attack pat-
terns or statistical anomalies in trafﬁc patterns (e.g., [29])
can be defeated by changing the attack pattern and masking
the anomalies that are sought by the ﬁlter. Furthermore, sta-
tistical approaches will likely ﬁlter out valid trafﬁc as well.
Since the Internet spans multiple administrative domains and
(legal) jurisdictions, it is often very difﬁcult, if not outright
impossible, to shut down an attack by contacting the admin-
istrator or the authorities closest to the source. In any case,
such action cannot be realistically delivered in a timely fash-
ion (often taking several hours). Even if this were possible,
it is often the case that the source of the attack is not the real
culprit but simply a node that has been remotely subverted
by a cracker. The attacker can just start using another com-
promised node.
• Using a “pushback”-like mechanism, such as the one de-
scribed in [15], to counter a DoS attack makes close coopera-
tion among different service providers necessary: since most
attacks use random source IP addresses (and since ingress
ﬁltering is not widely used), the only reliable packet ﬁeld
that can be used for ﬁltering is the destination IP address (of
the target). If ﬁlters can only be pushed “halfway” through
the network between the target and the sources of the at-
tack, the target runs the risk of voluntarily cutting off or
adversely impacting (e.g., by rate-limiting) its communica-
tions with the rest of the Internet. The accuracy of such ﬁl-
tering mechanisms improves dramatically as the ﬁlters are
“pushed” closer to the actual source(s) of the attack. Thus,
it will be necessary for providers to allow other providers,
or even end-network administrators, to install ﬁlters on their
routers. Apart from the very realistic possibility of abuse, it
is questionable whether such collaboration can be achieved
to the degree necessary.
The same concerns hold for the case of collaborative action by
the ISPs: even easy to implement mechanisms such as ingress ﬁl-
tering, that could reduce or even eliminate spoofed-address DoS
attacks, are still not in wide use. We believe it is rather unrealis-
tic to expect that cooperative providers would even establish static
ﬁlters to allow legitimate (paying) clients to tunnel through their in-
frastructure with any assurance of quality of service, and much less
so for the case of mobile or remote clients (as may be the case for
emergency teams). The D-WARD system [29] monitors outgoing
trafﬁc from a given source network and attempts to identify attack
trafﬁc by comparing against models of reasonable congestion con-
trol behavior. The amount of throttling on suspicious trafﬁc is pro-
portional to its deviation from the expected behavior, as speciﬁed
by the model. An extension of D-WARD, COSSACK [25], allows
participating agents to exchange information about observed trafﬁc.
An approach that uses BGP to propagate source addresses that
can be used for ﬁltering out source-spoofed packets inside the Inter-
net cote [26] places undue burden on the core and is useful only in
weeding out spoofed packets; unfortunately, the majority of DDoS
attacks do not use spoofed packets.
[18] proposes using Class-Based Queuing on a web load-balancer
to identify misbehaving IP addresses and place them in lower pri-
ority queues. However, most DDoS attacks use spoofed IP ad-
dresses that vary over time, thus defeating classiﬁcation. Even if
the same address is used, the amount of state that the load-balancer
needs to keep may be prohibitive. Furthermore, many of the DDoS
attacks simply cause congestion to the web server’s access link.
To combat that, the load-balancer would have to be placed closer
to the network core. Not only would this further compound the
state-explosion problem, but such detailed ﬁltering and especially
state-management on a per-source-IP address basis can have per-
formance implications at such high speeds.
Another approach to mitigating DoS attacks against information
carriers is to massively replicate the content being secured around
the entire network. To prevent access to the replicated information,
an attacker must attack all replication points throughout the entire
network — a task that is considerably more difﬁcult than attack-
ing a small number of, often co-located, servers. Replication is
a promising means to preserve information that is relatively static,
such as news articles. However, there are several reasons why repli-
cation is not always an ideal solution. For instance, the information
may require frequent updates complicating large-scale coherency
(especially during DoS attacks), or may be dynamic by its very na-
ture (e.g., a live web-cast). Another concern is the security of the
stored information: engineering a highly-replicated solution with-
out leaks of information is a challenging endeavor.
An extension of the ideas in SOS appears in [1]. There, the two
main facets of the SOS architecture: ﬁltering and overlay rout-
ing, are explored separately, and several alternative mechanisms
are considered. It is observed that in some cases, the various secu-
rity properties offered by SOS can still be maintained using mecha-
nisms that are simpler and more predictable. However, some second-
order properties, such as the ability to rapidly reconﬁgure the archi-
tecture in anticipation of or in reaction to a breach of the ﬁltering
identity (e.g., identifying the secret servlet) are compromised.
The NetBouncer project [36] considers the use of client-legitimacy
tests for ﬁltering attack trafﬁc. Such tests include packet-validity
tests (e.g., source address validation), ﬂow-behavior analysis, and
application-speciﬁc tests, including Graphic Turing Tests. How-
ever, since their solution is end-point based, it is susceptible to large
link-congestion attacks.
[4] examines several different DDoS mitigation technologies and
their interactions. Among their conclusions, they mention that re-
quiring the clients to do some work, can be an effective counter-
measure, provided the attacker does not have too many resources
compared to the defender.
7. CONCLUSIONS
We presented WebSOS, an architecture that allows legitimate
users to access a web server in the presence of a denial of ser-
vice attack. The architecture uses a combination of Graphic Turing
tests, cryptographic protocols for data origin authentication, packet
ﬁltering, overlay networks, and consistent hashing to provide ser-
vice to casual web-browsing users. We discussed our prototype
implementation, which uses standard web proxying and authenti-
cation mechanisms built in all browsers. Our architecture requires
no changes to web servers, browsers, or existing protocols.
We conducted a performance evaluation of WebSOS over both a
local area network and over the Internet using PlanetLab, a testbed
for experimentation with network overlays and similar technolo-
gies. Our experiments show that, in a realistic but worst-case de-
ployment scenario, the end-to-end communication latency between
browser and server increases on the average by a factor of 7, with
a worst case of 10. We also implemented and evaluated a shortcut
optimization, which reduced the latency to a factor of 2. These re-
sults are consistent with our simulations. We also discussed other
optimizations. However, we believe that even at its current level,
the overhead imposed is acceptable for many critical environments
and applications.
Future work plans include completion and long-term deployment
of the WebSOS prototype on PlanetLab, development of the IPsec-
enabled prototype that allows for transparent proxying and asym-
metric trafﬁc routing for improved performance, and more compre-
hensive performance measurements, over a longer period of time
and for a wider set of users and web sites.
8. ACKNOWLEDGEMENTS
Alexander Konstantinou’s NetCallback was used as a basis for
the forwarding code in the communications module. Abhinav Kamra
wrote the Chord implementation used for overlay routing.
9. REFERENCES
[1] D. G. Andersen. Mayday: Distributed Filtering for Internet
Services. In 4th USENIX Symposium on Internet
Technologies and Systems USITS, March 2003.
[2] L. Amini, H. Schulzrinne, and A. Lazar. Observations from
Router-level Internet Traces. In DIMACS Workshop on
Internet and WWW Measurement, Mapping and Modeling,
February 2002.
[3] S. M. Bellovin. Distributed Firewalls. ;login: magazine,
special issue on security, pages 37–39, November 1999.
[4] W. J. Blackert, D. M. Gregg, A. K. Castner, E. M. Kyle, R. L.
Hom, and R. M. Jokerst. Analyzing Interaction Between
Distributed Denial of Service Attacks and Mitigation
Technologies. In Proceedings of DISCEX III, pages 26–36,
April 2003.
[5] CCITT. X.509: The Directory Authentication Framework.
International Telecommunications Union, Geneva, 1989.
[6] A. Cohen, S. Rangarajan, and J. H. Slye. On the Performance
of TCP Splicing for URL-Aware Redirection. In USENIX
Symposium on Internet Technologies and Systems, 1999.
[7] D. Cook. Analysis of Routing Algorithms for Secure
Overlay Service. Computer Science Department Technical
Report CUCS-010-02, Columbia University, April 2002.
[8] S. A. Crosby and D. S. Wallach. Denial of Service via
Algorithmic Complexity Attacks. In Proceedings of the 12th
USENIX Security Symposium, pages 29–44, August 2003.
[9] D. Dean, M. Franklin, and A. Stubbleﬁeld. An Algebraic
Approach to IP Traceback. In Proceedings of the Network
and Dsitributed System Security Symposium (NDSS), pages
3–12, February 2001.
[10] S. Dietrich, N. Long, and D. Dittrich. Analyzing Distributed
Denial of Service Tools: The Shaft Case. In Proceedings of
USENIX LISA XIV, December 2000.
[11] G. Dommety. Key and Sequence Number Extensions to
GRE. RFC 2890, September 2000.
[12] D. Farinacci, T. Li, S. Hanks, D. Meyer, and P. Traina.
Generic Routing Encapsulation (GRE). RFC 2784, March
2000.
[13] M. T. Goodrich. Efﬁcient Packet Marking forLArg-Scale IP
Traceback. In Proceedings of the 9th ACM Conference on
Computer and Communications Security (CCS), pages
117–126, November 2002.
[14] L. Heberlein and M. Bishop. Attack Class: Address
Spooﬁng. In Proceedings of the 19th National Information
Systems Security Conference, pages 371–377, October 1996.
[15] J. Ioannidis and S. M. Bellovin. Implementing Pushback:
Router-Based Defense Against DDoS Attacks. In
Proceedings of the Network and Distributed System Security
Symposium (NDSS), February 2002.
[16] S. Ioannidis, A. Keromytis, S. Bellovin, and J. Smith.
Implementing a Distributed Firewall. In Proceedings of
Computer and Communications Security (CCS), pages
190–199, November 2000.
[17] D. Karger, E. Lehman, F. Leighton, R. Panigrahy, M. Levine,
and D. Lewin. Consistent Hashing and Random Trees:
Distributed Caching Protocols for Relievig Hot Spots on the
World Wide Web. In Proceedings of ACM Symposium on
Theory of Computing (STOC), pages 654–663, May 1997.
[18] F. Kargl, J. Maier, and M. Weber. Protecting web servers
from distributed denial of service attacks. In World Wide
Web, pages 514–524, 2001.
[19] S. Kent and R. Atkinson. Security Architecture for the
Internet Protocol. RFC 2401, Nov. 1998.
[20] A. D. Keromytis, V. Misra, and D. Rubenstein. SOS: Secure
Overlay Services. In Proceedings of ACM SIGCOMM, pages
61–72, August 2002.
[21] A. D. Keromytis, J. Parekh, P. N. Gross, G. Kaiser, V. Misra,
J. Nieh, D. Rubenstein, and S. Stolfo. A Holistic Approach to
Service Survivability. In Proceedings of the ACM Survivable
and Self-Regenerative Systems Workshop, October 2003.
[22] S. Miltchev, S. Ioannidis, and A. D. Keromytis. A Study of
the Relative Costs of Network Security Protocols. In
Proceedings of USENIX Annual Technical Conference,
Freenix Track), pages 41–48, June 2002.
[23] D. Moore, G. Voelker, and S. Savage. Inferring Internet
Denial-of-Service Activity. In Proceedings of the 10th
USENIX Security Symposium, pages 9–22, August 2001.
[24] G. Mori and J. Malik. Recognizing Objects in Adversarial
Clutter: Breaking a Visual CAPTCHA. In Computer Vision
and Pattern Recognition CVPR’03, June 2003.
[25] C. Papadopoulos, R. Lindell, J. Mehringer, A. Hussain, and
R. Govindan. COSSACK: Coordinated Suppression of
Simultaneous Attacks. In Proceedings of DISCEX III, pages
2–13, April 2003.
[26] K. Park and H. Lee. On the Effectiveness of Route-based
PAcket Filtering for Distributed DoS Attack Prevention in
Power-law Internets. In Proceedings of ACM SIGCOMM,
pages 15–26, August 2001.
[27] L. Peterson, D. Culler, T. Anderson, and T. Roscoe. A
Blueprint for Introducing Disruptive Technology into the
Internet. In Proceedings of the 1st Workshop on Hot Topics
in Networks (HotNets-I), October 2002.
[28] S. Ratnasamy, P. Francis, M. Handley, R. Karp, and
S. Shenker. A Scalable Content-Addressable Network. In
Proceedings of ACM SIGCOMM, August 2001.
[29] P. Reiher, J. Mirkovic, and G. Prier. Attacking DDoS at the
source. In Proceedings of the 10th IEEE International
Conference on Network Protocols, November 2002.
[30] S. Savage, D. Wetherall, A. Karlin, and T. Anderson.
Practical Network Support for IP Traceback. In Proceedings
of the 2000 ACM SIGCOMM Conference, pages 295–306,
August 2000.
[31] S. Savage, D. Wetherall, A. Karlin, and T. Anderson.
Network Support for IP Traceback. ACM/IEEE Transactions
on Networking, 9(3):226–237, June 2001.
[32] C. Schuba, I. Krsul, M. Kuhn, E. Spafford, A. Sundaram, and
D. Zamboni. Analysis of a Denial of Service Attack on TCP.
In IEEE Security and Privacy Conference, pages 208–223,
May 1997.
[33] A. Snoeren, C. Partridge, L. Sanchez, C. Jones,
F. Tchakountio, S. Kent, and W. Strayer. Hash-Based IP
Traceback. In Proceedings of ACM SIGCOMM, August
2001.
[34] I. Stoica, R. Morris, D. Karger, F. Kaashoek, and
H. Balakrishnan. Chord: A Scalable Peer-To-Peer Lookup
Service for Internet Application. In Proceedings of ACM
SIGCOMM, August 2001.
[35] R. Stone. CenterTrack: An IP Overlay Network for Tracking
DoS Floods. In Proceedings of the USENIX Security
Symposium, August 2000.
[36] R. Thomas, B. Mark, T. Johnson, and J. Croall. NetBouncer:
Client-legitimacy-based High-performance DDoS Filtering.
In Proceedings of DISCEX III, pages 14–25, April 2003.
[37] L. von Ahn, M. Blum, N. J. Hopper, and J. Langford.
CAPTCHA: Using Hard AI Problems For Security. In
Proceedings of EUROCRYPT’03, 2003.