Prometheus 探针，其中包装了
[Finagle](https://twitter.github.io/finagle/)。因为我们的大多数微服务都以繁重的网络分散收集方式工作，而内部逻辑有限。通过公开有关传入和传出网络调用的指标，此框架的用户无需通常样板代码即可深入了解其服务的运行状况。这反过来又使得首先使用框架更具吸引力。
ProdEng
使团队能够轻松地改进自己的监控，并另外提供了一些通用的高级警报。以这些为起点，开发团队现在更容易进行像样的监控，而不是完全不进行监控，这一深刻转变消除了将监控视为负担的观念。
有了这些工具，我们准备解决小型、嘈杂、仅限专家的轮值问题。为了限制参与轮值的时间，我们需要更多的工程师进行轮换，而不仅仅是专家。
一些较小的团队开始将其轮值角色合并为一个。这意味着，即使没有专门的 SRE
或 Ops
团队，工程师也能再次维护他们没有参与开发且不属于自己的服务。这是通过遵循
SRE 实践实现的。
这组团队记录并宣传了他们的经验，以及他们为加入此轮换的任何其他团队制定的基本规则：
-   任何想要加入统一轮值服务的团队都必须至少有一名工程师加入轮值。这样，团队就必须承诺做出回馈，才能交出所有运维责任。
-   事件处理的所有运维任务都必须记录在运行手册中。必须有一个 Runbook
    条目，至少给出上下文和每个警报的含义。
-   必须消除嘈杂报警，加入统一的轮值意味着报警都应该有明确意义。除非有强有力的论据认为将来的警报是可操作的，否则不可操作的警报通常会导致真正的问题被掩盖。这往往会导致真正有理由被关注的警报被弱化，造成"狼来了"的效果。
-   只要可以，机械化的补救操作就应自动执行。
-   如果文档不足或问题复杂，可以将事件上报给拥有该服务的团队。这种情况很少发生，以至于这些团队通常没有单独的守门人，只能将通知群发给团队中的每个人。
-   在工作日，轮值工程师可以将任何警报的处理委托给拥有该服务的团队。这避免了此工程师纠结于如何发现对此服务刚刚做出的更改。
-   拥有服务的团队有责任首先防止问题发生。
所有这些在一起不仅使共享轮值变得可行，还有助于改善拥有该服务的开发人员的工作效率和健康状况。与专用
SRE 支持相比，让开发人员轮值，对遵循最佳实践的要求更加严格。拥有 SRE
头衔的至少是全职 SRE，而具有 SRE 职责的开发人员只需很短时间即可胜任 SRE
职能。
因为结构化和减少轮值压力的激励，团队对其文档和监控进行改善开始变得有动力。很快，就形成了更统一的轮值共享，通常是由具有相关功能和类似工程文化（如语言和框架选择）的团队组成的。
拥有一项功能的团队最终负责与该功能相关的所有服务的运维，这样的设置成为一个重要的安全阀。尽管团队可以自由地权衡短期功能交付与长期维护和技术债务，但他们不能永远忽视后者。当服务达到其设计的极限，或者创建设计糟糕的服务时，团队的运维负载也会增加。这会减慢未来功能交付的速度，因此，如果情况变得如此糟糕，以至于服务从合并轮值中被开除，于是运维再次成为单个团队的责任。     
## 使用事后分析解决跨团队可靠性问题
   即使有最好的意图、隐式探针和通用警报，不同团队拥有的系统也会出现问题。维护具有意外的副作用、错过警报或新功能严重依赖于某系统（但此系统所有者却无从得知）。
全公司范围内，严谨的、轻量级的故障处理*网站可靠性工程：谷歌如何运行生产系统，*[第15章](https://landing.google.com/sre/book/chapters/postmortem-culture.html)是解决这些问题的基础。所有团队都记录严重事件，这有助于他们确定改进自身系统（及其与其它系统交互）的优先级和合理性。负责维护自身系统的集成工程团队有强烈的动机解决事故的反复发生原因，尤其是在估计和报告可能用于事件响应的（本可用于开发功能）工作时间。以我们的规模，ProdEng
可以审查整个公司范围内的所有事件，并确定跨团队发生的（或可能通过跨团队努力解决的）问题。
故障检查文档遵循由内部 wiki
中的模板指导的特定格式。我们优先考虑人类的易读性，而不是机器的可读性，但也提取一些自动报告。
每周一次的会议用于讨论最近事件、决议和未来改进。会议由至少一名代表出席，他们分别代表议程中涉及的每次事件、ProdEng
和任何希望加入的人。大多数与会者是直接参与受影响服务开发的工程师。与会者的更广泛视角通常会对手头的事件带来新的见解，或将过去和当前事件联系起来。
故障报告会议是传播有关导致或避免事件的模式和做法的知识、帮助解决事件并减轻其影响的有效方法。在这方面，小型组织比大公司具有很大的优势：如果整个组织有一次会议，这种知识可以在很短的时间内深入到所有团队，而无需通过管理层。
如果在合理的时间内讨论的事件太多，ProdEng
会根据注意性或影响进行策划。通常讨论影响比较高的事件，但这不是绝对的。通常，了解接近崩溃以及为什么没有发展成灾难，这样的知识（比有清晰解决方案的易于理解和接受的故障方案）更为重要。最后，所有事件报告都要接受这种或那种审查，即使并非所有事件报告都要对应一次会议。专门处理单一事件的会议只在特殊情况下举行，并纳入常规故障报告会议。
 通常，尤其是对于跨团队问题，很容易陷入推卸责任上。故障报告的准则应该考虑到这一点，侧重于导致事件的系统性问题，找到完全避免此类问题的方法，并试图了解原始背景以及如何加以改进。参加会议的工程师将这些学习带回了他们的团队。会议通常会激发其他知识共享方式，例如内部技术讲座、文档或配对协助。
## 统一的基础设施和工具与自主和创新
 从历史上看，SoundCloud
的技术堆栈非常多样化，尤其是在语言和运行时方面。这有其优点。选择的自由使开发人员感到满意，并使招聘更容易。可以非常具体地为手头的项目挑选工具。
然而，从长期来看，这也要付出代价。转换系统所有者通常意味着新的所有者需要学习另一套新的技术，并且许多车轮需要多次重新发明。较不常见的语言的系统通常缺乏我们维护微服务队列所需的更复杂的探针和客户端负载平衡功能。
在 SoundCloud，技术方向通常自下而上的出现，而不是自上而下决定。在从"Ruby
商店"转型阶段，我们向许多不同的语言和平台社区开放和招聘。在这种文化中，仅仅宣布一组允许的技术是不能接受的。然而，类似寒武纪的爆炸式技术发展导致围绕工具和框架的努力难以为继。为了控制这种情况，管理层开始通过分配资源来维护此生态系统，从而倾向于
Java 虚拟机 （JVM）、Scala 和 Finagle 堆栈。但是，我们选择 HTTP 传输的
JSON
作为主要通信协议，而不是更高效的竞争者，如[ThriftMux](https://twitter.github.io/finagle/guide/Protocols.html#mux)。这种服务到服务通信的*通用语言*允许我们不必立即重写所有不符的服务，并为其他语言和技术的实验留出了空间。作为直接的结果，Go
在某些案例中获得了立足点，其简单性和性能带来的好处超越了（无法从 Scala
框架中投入的所有工作中获益的）不足。
这种方法还超越了语言选择的范围。通过为遵循常见实践的任何人提供一条简单的路径，开发团队有强烈的动机不引入新技术，但如果收益大于开拓新路线的成本，他们就*能*使用新技术。
这也扩展到数据存储的域。某些数据库和缓存技术（[Percona Server for
MySQL](https://www.percona.com/software/mysql-database/percona-server)、[Cassandra](http://cassandra.apache.org)
和
[Memcached](http://memcached.org)）被维护为易于重用的共享组件。它们允许任何团队非常快速地建立群集，并从广泛使用且广为人知的技术堆栈的所有自动化、文档文档和支持中获益。
如前所述，尽管为它们提供了设置，但团队完全负责日常轮值和维护其专用基础结构依赖项。他们不需要请求许可或与任何人协调，以更改架构或创建新功能。就架构和容量规划进行协商是自愿的，通常没有必要。部分地，这是由于物理分离而可能。每个系统的专用数据库群集都会限制不明智的更改或容量不足带来的颠簸。开发速度的提高和来自这种自治的更可预测的规划，都或多或少地减少了罕见技术堆栈的利用率。
然而，有时候一项新技术确实可以更好地解决问题，值得我们去考虑。这是每个团队自己做出的决定。例如，数据平台团队采用
Apache
[Kafka](https://kafka.apache.org)为中心事件总线提供计算引擎，取代了成熟的[RabaMQ](https://www.rabbitmq.com)。很快，Kafka
也获得了其他团队的青睐，于是他们可以在原始探险家以前的工作基础上更进一步。
但是，维护适用于许多团队的通用解决方案，这可能会对应专注于实际产品的团队的资源造成压力。此时，将技术交给一个旨在维护通用技术基础的团队是有意义的。成立了一个专门的团队来支持基于