with index j (where 1 ≤ j ≤ N) with expected frequency tj,
and we consider n-grams at the i-th position of the passwords
only (thus 1 ≤ i ≤ l). Deﬁne the random variables Si,j
h :=
h) is the indicator function for the j-
χj(P i
th n-gram on the i-th position in the h-th password. The
random variables Si,j
h = 1) = tj and
i,j = 0) = 1 − tj.
P r(Sh
For 1 ≤ i ≤ l and 1 ≤ j ≤ N, we deﬁne the empirical
(cid:80)
frequency obtained from a password database with k pass-
words as T i,j
follows a binomial
distribution Bin(k, tj) with k trials with success probabil-
ity tj each.
Let Ri,j ∼ Bin(k, γ) be random variables describing the
noise added to the i-th n-gram in our construction, where
1 ≤ i ≤ l ranges over the n-grams per password, and 1 ≤
j ≤ N ranges over all n-grams, and let Oi,j
k + Ri,j
be the observed noisy value. The information that can leak by
publishing a single noisy n-grams is the mutual information
between T i,j
k
k , i.e., the quantity I(T i,j
h=1,...,k Si,j
k ; Oi,j
h . T i,j
k = 1
k
and Oi,j
def
= T i,j
k ):
k
k
I(T i,j
k ; Oi,j
k )
k ) − H(Oi,j
= H(Oi,j
k ) − H(Ri,j),
= H(Oi,j
k |T i,j
k )
(10)
where the ﬁrst equality is the deﬁnition of mutual informa-
tion (Eq. (6)), and the second equality follows from Equa-
tion (5).
Using ﬁrst Equation (9) and then Equations (7) and (8)
we can evaluate this further as follows:
H(Oi,j) − H(Ri,j)
(11)
= H(Bin(k, γ) + Bin(k, tj)) − H(Bin(k, γ))
≤ γ +
C (γ+tj )/2
+
− C γ
k2 − C γ
3
k3
− C γ
1
k
tj
2γ
2k
4
2
The full n-gram database which is leaked is the concate-
nation of the sums of the individual n-gram counts, i.e., the
actual information leakage is3:
l(cid:88)
(cid:18)
l(cid:88)
(cid:19)
i=1
L = I((
T i,j
k )1≤j≤N ; (
i=1
≤ 4kγ +
1
γ
6.1 +
1
5kγ
Oi,j
k )1≤j≤N ))
(12)
1
for l = 4. For a reasonable choice of parameters γ =
1.000.000 and k = 5.000.000 this means that overall, the
n-gram database can leak at most 6.2 million bits, or on
“average” about 1.3 bits per password. Values for different
parameters are given in Table 2.
3Appendix A presents in details how the results presented in this section
were derived.
γ = 5 · 10−7
γ = 1 · 10−6
γ = 5 · 10−6
k = 1 · 106
13.1 · 106 (13.1)
6.4 · 106 (6.4)
1.3 · 106 (1.3)
k = 5 · 106
12.4 · 106 (2.5)
6.2 · 106 (1.24)
1.3 · 106 (0.3)
k = 1 · 107
12.4 · 106 (1.24)
6.2 · 106 (0.62)
1.3 · 106 (0.13)
Table 2. Total leakage (and average leakage per password) in bits for different parameters of k and γ,
bold numbers indicate parameters that strike a good balance between accuracy and security.
6 Accuracy of our Construction
We now evaluate the accuracy of our scheme and compare
it with other password strength meters.
Datasets: In order to evaluate the accuracy of our scheme,
we use the RockYou password list. This list consists of
over 32.6 million passwords that were released to the public
after a breach occurred in December 2009 to the website
www.rockyou.com.4 The dataset is valuable for different
reasons. First, it was the result of an SQL injection attack
against the password database that was successful because
passwords were stored in clear and not hashed. This means
that all the passwords were collected, not only weak ones.
A number of other, smaller password lists exist, e.g., the
MySpace list which was obtained by a phishing attack and
thus might include weaker passwords as well as fake input
by users that realized the phishing attempt. Also, RockYou
did not enforce any password rules, yielding a “plain” pass-
word set that provides a clear insight of how users choose
passwords.
We also used the MySpace list of 37, 000 passwords
leaked from MySpace by a phishing attack in 2006, 184, 389
leaked by PhpBB in 2009, and a list of 8347 passwords from
the religious forum Faithwriters. Note that these passwords
were not used to train our model for the experiments, but
only to assess the need of adaptive password strength meters
as shown in Figure 1(a).
6.1 Measuring Accuracy Using Rank Correlation
First, we analyse the accuracy of our Markov-based pass-
word meter (with and without adding noise) as well as the
NIST, Google, and Microsoft password meters, by compar-
ing their score to the ideal password strength meter (see
Section 2.1). The ideal password meter is built upon the
knowledge of the most common passwords in the Rock-
You dataset. This comparison only makes sense if there are
enough data-points to keep the approximation error for the
probability low. The estimation is reasonable for the 10000
most frequent passwords; see Appendix B for a derivation
of this bound.
4One can remark the irony in the fact that a failure in password storing
best-practices led to a deeper understanding of user chosen passwords.
For comparing the different password meters we use
Spearman’s rank correlation. It describes how well the rela-
tionship between two vectors can be described using a mono-
tonic function. The coefﬁcient lies between [−1, 1], with
0 indicating no correlation, +1 indicating perfect positive
correlation and −1 indicating perfect negative correlation
(i.e., given two sets of values X and Y , the Spearman cor-
relation coefﬁcient becomes 1 when X and Y are perfectly
monotonically related, i.e., ∀i, j xi > xj implies yi > yj).
All the password meters under examination where measured
by computing the rank correlation of their scores against the
scores of the ideal meters. (The intuition is that if the ideal
score of password p1 is higher than the ideal score of pass-
word p2, then an approximation of the ideal meter should
rate these two passwords in the same order.) To obtain a
more ﬁne-grained comparison, we plotted the correlation at
different intervals, using the ﬁrst 10, 20, ..., 10000 passwords
in the set. The results are shown in Figure 2(a).
First, we can see that our Markov-based password meter
outperforms the other checkers, even when noise is added.
Second, the noise added to establish the security of the
scheme only slightly decreases the accuracy of the meter.
Third, the NIST, Microsoft and Google checker perform
equally badly and are not much better than random guessing
the password strength, as their correlation with the ideal
meter is close to zero.
Training and Testing using Different Datasets: In order
to quantify the importance of using the correct password
database, in an additional experiment we included data from
the PhpBB password list. We computed the optimal score
for the 1000 most frequent passwords of the PhpBB list from
their empirical frequency, let us call the resulting vector X.
Then we scored the same 1000 passwords using the Markov
5-gram Model trained on the RockYou password dataset,
we call the resulting vector Y . The correlation between the
two vectors X and Y is 0.27 only, much lower than 0.55,
the result we obtained by training and testing on the same
password list.
This test shows that training a Markov Model on a web
service (in this case RockYou) and using it to score pass-
words on a second service (in our case PhpBB) potentially
signiﬁcantly lowers accuracy, which further strengthens the
previous ﬁndings in Section 3.1. This serves as justiﬁcation
for our APSM to be trained on the same web service where
(a) Spearman correlation coefﬁcient against the ideal password meter.
(b) ROC Curve comparing the performance of our password meter (with
and without noise) to the NIST password checker. γ = 5 · 10−6 was
chosen for the noise.
Figure 2. Accuracy Analysis
it is used to score passwords.
6.2 Measuring Accuracy based on Binary Classi-
ﬁcation
Next, we compare the accuracy of the password meters
in terms of binary classiﬁcation accuracy, i.e., we establish
the accuracy of distinguishing between “strong” and “weak”
passwords. The security of a password is the inverse of its
probability. In this experiment we set a probability threshold
of 2−20 to distinguish between strong and weak passwords.
For guessing attacks, this threshold guarantees that in order
to correctly guess one single password the attacker has to
guess 218 different passwords. This number should be sufﬁ-
ciently high to prevent online guessing attack if the server
uses simple rate limiting on the password guesses. We refer
the interested reader to [8] for an analysis of rate limiting
policies on passwords.
This threshold was chosen because, given our dataset of
32 million password, we can divide the password in “strong”
and “weak” using their frequency and build a ground truth
set. Roughly, all the passwords that appear with frequency
higher than 2−20 are marked as weak, the others are marked
as strong. However, special caution must be taken when
dealing with this probability estimation. In fact, a small
estimation error near the threshold can mean that a password
is incorrectly labelled. Thus we excluded the passwords with
frequency too close to the threshold using Wilson interval
estimation for the binomial probability estimation [3], with
z-value z1−α/2 = 2.58.
Using this estimation we can ﬁnd the passwords above
and below the threshold probability with 99% conﬁdence.
We divided our testing dataset of 600000 passwords in 4163
surely weak password, called W , and 142205 strong pass-
words, called S. In this experiment too, we built an ideal
ground-truth using the RockYou dataset and sound probabil-
ity estimations.
We test the accuracy of our Markov-based password me-
ter (with and without noise) in distinguishing between these
two sets. We also test the NIST meter alongside as a com-
parison. The Microsoft and Google meter were not tested
in this experiment, as we cannot map the threshold t to the
scoring given by those meters. We computed the score of all
the passwords in the sets W and S using both the Markov
method and NIST. For different thresholds, we measured
true positives ratio (passwords correctly marked as weak)
and false positive ratio (strong password incorrectly marked
as weak). The results can be seen in the ROC curve showed
in Figure 2(b). The diagonal line gives the performance of
a random password meter, which scores the passwords as
weak or strong at random (this is a inherent property of ROC
curves). The closer a curve is to the top-left corner (false
positive rate of zero and true positive rate of one) the better
the classiﬁcation is. An ideal meter would be a perfect clas-
siﬁer of strong and weak passwords. Again, we can see that
our password strength meter (with and without noise) clearly
outperforms the NIST meter. Also, the introduction of noise
affects performance only slightly. The Markov based meter
performs close to optimal with a success rate of 93.4%.
7
Implementation Considerations
7.1 Bootstrapping
One remaining question is how to bootstrap our system.
In fact, when only few passwords are stored in the system,
those might be particularly vulnerable to leakage as the ad-
versary can easily learn what passwords are not present, by
 0 0.2 0.4 0.6 0.8 1 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000Spearman correlation to ideal meterFirst k common passwordsMarkov 5-gramMarkov 5-gram with noiseNISTMicrosoftGoogle 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1True Positive RateFalse Positive RateMarkov 5-gramMarkov 5-gram with noiseMarkov 5-gram trained on PhpBBNISTRandomchecking what n-grams are not present in the database. We
notice, however, that both these problems can be easily ad-
dressed. The solution lies in inserting the noise in batches
of size k rather than every time a password is inserted. In
practice we execute step 3 of the DCU algorithm, (described
in Section 4.2.1) k times in advance. The value k should
be high enough to provide a balance between usability and
security and a reasonable value of k could be 1.000.000
(Section 5.3 details how k should be selected in order to
provide security). Then, for the ﬁrst k passwords entered in
the system, only step 2 and step 4 of the DCU algorithm are
executed (i.e., no noise is added as it was added in advance).
After the ﬁrst k passwords, the full DCU algorithm (step 2,
step 3 and step 4) is then executed.
Note that our system cannot be used to estimate the
strength of the ﬁrst k passwords (the noise would introduce
too much error in the estimations). For these passwords, we
suggest to use our scheme with a n-gram database conﬁg-
ured with n-grams extracted from a public source such as
the RockYou database, and then switch back to our database
when the number of passwords exceeds k.
One additional remark is that our password meter is better
suited for large web services, that can leverage on password
databases of several thousand passwords and larger. In our
tests we observed that the accuracy of the Markov model
increases rapidly with small training sets and then achieves
only marginal better performance with larger training sets.
For example, the Markov model trained with only 100.000
passwords achieved an accuracy of 90.3%, when trained
with 50.000 passwords an accuracy of 92.9%, and when
trained with 32 million passwords an accuracy of 93.4%.
This is most likely due to the fact that the most common
n-grams are quickly learned, while there is a very long tail
of uncommon n-grams. Services that do not have access to
tens of thousands of passwords (e.g., smaller web services
or local services) must either rely on training the markov
model on dictionaries [19] or leaked password databases like
RockYou.
7.2 Usability
Our password meter returns real numbers between 0 and 1.
However, these values might not be easy for users to interpret.
We envision three ways in which the output of our password
strength meter can be presented to the users. First, the user
can be given the score computed by the Markov model, but
converted to a discrete value, e.g., too weak, weak, medium,
strong, instead of a real number. The probability could be
translated into a sliding “strength bar” that reﬂects the score
computed. This approach would look exactly like current
password strength meters, albeit with the higher accuracy
given by our construction.
However, we notice that the ﬁne-grained score given by
our meter enables us to do more. We could translate the
score of the password strength meter into a more concrete
metric such as the effort required by an adversary to break
the password in terms of time. This could be done, for
example, by using the guessing entropy bound derived from
the Shannon entropy. In this context, the user could be given
a message of the type, “your password can be guessed – on
average – in x attempts, that can be tried automatically in
about y hours”.
Third, the score could be used to compute an estimation
of the strength of the password relative to their peers, which
might provide an incentive for users to choose better pass-
words. Users could be prompted with a message that says,
for example, “your password is amongst the 5% weakest
passwords on our web site”, which might encourage them to
choose a better password. Conversely, having a password in
the top 5% might be an incentive for users to choose stronger
passwords.
8 Conclusion
In this work, we proposed a novel way to measure the
strength of user-selected passwords. The construction is
based on Markov-models and achieves much higher accuracy
than commonly used password meters. The ﬁne-grained mea-
surement of the password strength provided by our strength
meter allows for a very precise feedback to users.
We have formally proven that this construction is secure
even when the local data storage is compromised by an at-
tacker, thus, meeting best practices in securing password
storage. We evaluated the accuracy of our scheme by per-
forming extensive experiments and showed that it outper-
forms existing schemes.
References
[1] J. Adell, A. Lekuona, and Y. Yu. Sharp bounds on the entropy
of the poisson law and related quantities. Information Theory,
IEEE Transactions on, 56(5):2299–2306, 2010.
[2] M. Bishop and D. V. Klein.
Improving system security
via proactive password checking. Computers & Security,
14(3):233–249, 1995.
[3] L. D. Brown, T. T. Cai, and A. DasGupta. Interval estimation
for a binomial proportion. Statistical Science, 16(2):101–133,
2001.
[4] W. E. Burr, D. F. Dodson, and W. T. Polk. Electronic authen-
tication guideline: NIST special publication 800-63, 2006.
[5] J. A. Cazier and D. B. Medlin. Password security: An empir-
ical investigation into e-commerce passwords and their crack
times. Information Security Journal: A Global Perspective,
15(6):45–55, 2006.
[6] M. Dell’Amico, M. Pietro, and Y. Roudier. Password strength:
An empirical analysis. In INFOCOM ’10: Proceedings of
29th Conference on Computer Communications. IEEE, 2010.
[7] D. Florencio and C. Herley. A large-scale study of web
In WWW ’07: Proceedings of the 16th
password habits.
international conference on World Wide Web, pages 657–666.
ACM, 2007.
[8] D. Florˆencio, C. Herley, and B. Coskun. Do strong web
passwords accomplish anything? In Proceedings of the 2nd
USENIX workshop on Hot topics in security, Berkeley, CA,
USA, 2007. USENIX Association.
[9] C. Herley. So long and no thanks for the externalities: The
rational rejection of security advice by users. In Proceedings
of the 2009 Workshop on New security paradigms, pages
133–144. ACM, 2009.
[10] A. Kerckhoffs. La cryptographie militaire. Journal des
sciences militaires, IX:5–38, January 1883.
[11] D. V. Klein. Foiling the cracker: A survey of, and improve-
ments to, password security. In Proc. USENIX UNIX Security