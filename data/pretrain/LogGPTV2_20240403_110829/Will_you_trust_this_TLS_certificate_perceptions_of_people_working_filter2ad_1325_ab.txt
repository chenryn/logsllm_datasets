### Network Security Tools Usage and Participant Security Behavior

Participants reported using a variety of network security tools, including Network Security Services (25%, 19 participants), Java Keytool (25%, 19 participants), GnuTLS (19%, 14 participants), and Windows Certutil (12%, 9 participants). Additionally, about one-third of the participants (36%, 27 participants) had previously used Let’s Encrypt Certbot.

To assess the security behavior intentions of our participants, we utilized the Security Behaviors Intentions Scale (SeBIS) [16]. Our sample generally exhibited stronger intentions towards secure behavior compared to the general population [16], particularly in the device securement subscale, where individual scores were on average 0.1–1.3 points higher.

### Participant Consent and Study Conditions

The majority of participants (89%, 46 in English and 21 in Czech) consented to audio recording for qualitative analysis. Participants were randomly assigned to either the original condition (59%, 44 participants) or the redesigned condition (41%, 31 participants). No significant differences were observed between the two conditions in terms of self-reported previous experience, IT education, IT employment, or tools used, indicating that the samples are comparable.

### Potential Bias and Sample Characteristics

To check for potential bias, we inquired whether participants had taken part in a similar experiment at the same conference the previous year [39]. Only a minority (13%, 10 participants) had done so. Excluding these participants did not alter the conclusions drawn from the results. Therefore, we present the results for the full sample.

### Data Collection and Analysis

Data from all sources were matched based on timestamps, and each participant was assigned a pseudonym. Timestamps were used to compute the time spent on individual tasks, and browser history was used to identify the resources accessed.

We conducted a qualitative descriptive analysis of the post-task interviews [35]. After transcribing the interviews, two researchers independently familiarized themselves with the data. The data were then processed using open coding [34], where the researchers independently identified recurring themes and assigned codes to text passages. The analysis was framed by participants' comprehension of validation messages, their opinions, and actions. After the open coding, the researchers discussed the created codes and consolidated a common codebook. The transcripts were then re-coded using the shared codebook. The results reported in Sections 3 and 4 are based on this coding round.

To ensure the reliability of the analysis, a third independent coder coded half of the English and half of the Czech transcripts using the shared codebook. Interrater agreement was substantial (according to Landis and Koch [27]) for both English (Cohen’s κ = 0.69, p < 0.001) and Czech (Cohen’s κ = 0.63, p < 0.001). All coders used all codes, indicating that the defined codes were present in the interviews and that the codebook was well-defined. Some deviations in coding stemmed from the fact that the independent coder was slightly more conservative in assigning codes compared to the original coders.

Supplementary materials, including the experimental setup (the complete virtual machine) and the anonymized dataset, are available at https://crocs.fi.muni.cz/papers/acsac2019.

### Study Limitations

As with any study, various limitations may affect the applicability of the results. First, to ensure natural behavior, we designed a realistic and appealing task (developing a patch for the registration system at a conference on open-source technologies). We did not limit time or resources, allowing participants to behave as they would in reality. Realistic and well-known entities and hostnames were chosen for the certificates. Although different hostnames might have slightly different reception, we preferred this to the less ecologically valid option of solving five separate cases with the same hostname.

The second concern is sample bias. We recruited attendees from a single industrial conference, which may not fully represent the wider IT population. However, a 2018 Developer Survey by Stack Overflow [37] estimates that almost half of developers contribute to open-source projects, and Linux is the most developed-for platform. Compared to this survey, our sample follows the general trends for professional experience and education but has a slightly higher mean (peaking at 3–5 years working in IT instead of 0–2 and at the master’s degree instead of the bachelor’s). This suggests that the reported comprehension may be slightly higher in our sample compared to the general population.

Thirdly, participants' behavior may have been influenced by the context or parts of the questionnaire. However, we were cautious not to mention security when advertising the study and tried to recruit all passing participants regardless of their skill level.

Lastly, we attempted to mitigate multiple response biases. To combat question order bias, we randomized the order of questions in the initial questionnaire and the order of evaluated certificate cases in both the task and the trust scale. To address response order bias, we inverted all Likert scales for half of the participants. To reduce the observer effect, interviewers left participants alone during the tasks but were available for consultation. Some participants might have been more cautious due to social desirability bias, so we consider the obtained trust evaluations as a lower bound.

### Perception of Certificate Flaws

In this section, we present the comprehension and perceived trustworthiness of tested certificate flaws, along with the reasoning provided by participants in the exit interview. Comprehension is based on the qualitative analysis of the post-task interview (67 participants). Trust assessment and answers to structured interview questions are available for all 75 participants. The section concludes with a cross-case comparison and an investigation into the influence of previous knowledge.

#### Hostname Mismatch Case

The hostname mismatch flaw was well understood. A majority of participants (50) mentioned that the core issue was the server hostname not matching the name in the certificate (code: BadName, see Table 1 for frequency, simplified definition, and representative quotes). Many participants (27) explicitly noted the extra letter 's' in the certificate name (code: NameCheck), indicating they had inspected the certificate. The prevalent opinion was that the error was due to an attack (code: Attack, 22 participants), though a few participants (8) suggested it could be a mistake or typo (code: Mistake).

On average, the connection was assessed as "outright untrustworthy" (mean 0.68 ± 1.08, median 0, see Fig. 1 for detailed information and Appendix A for the whole scale). This low trust is unsurprising, as a server with a mismatched second-level domain name provides almost no identity guarantees.

#### Self-signed Case

The self-signed case was also well understood. Participants frequently mentioned that the certificate was self-signed (code: ByItself, 50 participants), that no CA was involved in its issuance (code: NoCA, 28 participants), and that anyone, including the participants themselves, could issue such a certificate (code: AnyoneCan, 21 participants).

Table 1 provides an overview of the comprehension and reasoning codes occurring in at least 10% (7 participants) of the interviews (67 in total, 39 in the original condition and 28 in the redesigned condition). Codes labeled with an asterisk (*) indicate case comprehension.

| **Case / Code** | **Frequency** | **Simplified Definition** | **Representative Quote** |
|-----------------|---------------|---------------------------|--------------------------|
| **Hostname Mismatch** | | | |
| BadName* | 50 | The certificate subject and server name do not match. | "The last one server, Facebook, [the certificate] was issued for a different hostname." [P39, original] |
| NameCheck | 27 | Mentioning the exact difference in the names. | "[...] because it is not Facebook, it is Facesbook or something like that." [P57, original] |
| Attack | 22 | Connection may be attacked. | "It can be some phishing site or something like this." [P76, original] |
| Mistake | 8 | It can be only a mistake or server misconfiguration. | "And in this case – it’s a different domain, but I’d say it’s some kind of typo or something like that." [P63, redesigned] |
| **Self-signed** | | | |
| ByItself* | 50 | The certificate is signed by itself/self-signed. | - |
| NoCA* | 28 | No CA was involved in its issuance. | - |
| AnyoneCan* | 21 | Anyone can create such a certificate. | - |

This table summarizes the key findings and provides representative quotes to illustrate the participants' understanding and reasoning.