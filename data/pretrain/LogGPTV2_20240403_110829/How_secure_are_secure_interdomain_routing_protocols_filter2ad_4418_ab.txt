One strategic manipulator. We assume that all ASes in
the AS graph behave normally, i.e., according to the policies
in Section 2.1 - 2.2, except for a single manipulator (e.g., AS
m in Figure 1). We leave models dealing with colluding ASes
for future work.
Normal ASes and normal paths.
We assume that
every normal AS uses the routing policies in Section 2.2;
thus, the normal path is the path an AS (even the manipu-
lator) would choose if he used the normal rankings of Sec-
tion 2.2, and normal export is deﬁned analogously.
(e.g.,
In Figure 1, the manipulator m’s normal path is through
his customer AS a3.) We shall assume that every normal
AS knows its business relationship with his neighbors, and
also knows the next hop it chooses for forwarding traﬃc to
a given destination. In order to evaluate the eﬀectiveness of
each secure routing protocol, we assume that ASes believe
everything they hear, except when the secure routing pro-
tocol tells them otherwise. As such, we do not assume that
ASes use auxiliary information to detect attacks, including
knowledge of the network topology or business relationships
between distant ASes, etc., unless the secure routing proto-
col speciﬁcally provides this information.
Attraction v.s. Interception attacks.
In an attrac-
tion attack, the manipulator’s goal is to attract traﬃc, i.e.,
to convince the maximum number of ASes in the graph to
forward traﬃc that is destined to the victim IP preﬁx via
the manipulator’s own network. To model the idea that a
manipulator may want to eavesdrop or tamper with traﬃc
before forwarding it on to the legitimate destination, we also
consider interception attacks. In an interception attack, the
manipulator has the additional goal of ensuring that he has
an available path to the victim. This is in contrast to an
attraction attack, where the manipulator is allowed, but not
required, to create a blackhole where he has no working path
to the victim IP preﬁx (e.g., Figure 6).
The fraction of ASes attracted.
In this paper, we
measure the success of an attack strategy by counting the
fraction of ASes in the internetwork from which that manip-
ulator attracts traﬃc; this amounts to assuming that every
AS in the internetwork is of equal importance to the ma-
nipulator.2 However, it is well known that the distribution
2We acknowledge that a manipulator may want to attract
traﬃc from a speciﬁc subset of ASes. We avoid analyzing
this, because we lack empirical data to quantify that subset
of ASes that a given manipulator may want to attract.
89of traﬃc in the Internet is not uniform across the ASes; to
address this, we also report the fraction of ASes of various
sizes from which the manipulator attracts traﬃc, where we
measure size by the number of direct customers the AS has.
Attack strategies. To capture the idea that the manip-
ulator is strategic, we allow him to be more clever than the
normal ASes; speciﬁcally, we allow him to use knowledge of
the global AS graph and its business relationships in order
to launch his attacks. (However, most of the strategies we
considered require only knowledge that is locally available
at each AS.) An attack strategy is a set of routing announce-
ments and forwarding choices that deviates from the normal
routing policies speciﬁed in Section 2.2. An attack strategy
may include, but is not limited to:
(cid:129) Announcing an unavailable or non-existent path.
(cid:129) Announcing a legitimate available path that is diﬀerent
(cid:129) Exporting a path (even the legitimate normal path) to
a neighbor to which no path should be announced to
according to the normal export policies.
from the normal path.
Indeed, one might argue that some of these strategies do not
constitute ‘dishonest behavior’. However, it is important to
consider these strategies in our study, since we shall ﬁnd that
they can sometimes be used to attract as much traﬃc as
the traditional ‘dishonest’ strategies (e.g., announcing non-
existent paths).
Scope of this paper.
This paper focuses on traﬃc
attraction attacks; we do not consider other routing secu-
rity issues, for instance, mismatches between the control-
and data-plane [4, 10], or traﬃc deﬂection attacks, where
a manipulator wants to divert traﬃc from himself or some
distant, innocent AS [5]. Moreover, we do not cover issues
related to the adoption of secure routing protocols, nor their
eﬀectiveness under partial deployment [19]. See the full ver-
sion [1] for more discussion of related work.
2.4  Experiments  o n  empirical  AS  graphs 
All the results and examples we present are based on
empirically-obtained snapshots of the Internet’s AS graph
annotated with business relationships between ASes. Our
experimental results were obtained via algorithmic simula-
tions; details are in the full version [1].
Average case analysis. Since the inﬂuence of an attack
strategy depends heavily on the locations of the manipu-
lator and the victim in the AS graph, we run simulations
across many (manipulator, victim) pairs. Rather than re-
porting average results, we plot the distribution of the frac-
tion of ASes that direct traﬃc to the manipulator. We by
no means believe that a manipulator would select its vic-
tim at random; however, reporting distributions allows us
to measure the extent to which a secure protocol can blunt
the power of the manipulator, determine the fraction of vic-
tims that a manipulator could eﬀectively target, and identify
positions in the network that are eﬀective launching points
for attacks.
Ideally, to determine how damaging a given
attack strategy can be, we would have liked to run simula-
tions over every (manipulator,victim) pair in the AS graph.
However, this would require (30K)2 simulations per dataset,
which would be prohibitive.
Instead, we run experiments
on randomly-chosen (manipulator, victim) pairs. We found
that 60K experiments of each type were suﬃcient for our
results to stabilize.
Multiple datasets. Because the actual AS-level topol-
ogy of the Internet remains unknown, and inferring AS re-
lationships is still an active area of research, we run sim-
ulations on a number of diﬀerent datasets: multiple years
of CAIDA data [11], and Cyclops data [12] augmented with
21,000 peer-to-peer edges from [13]’s IXP dataset. Even
though these datasets use diﬀerent relationship-inference al-
gorithms, the trends we observed across datasets were re-
markably consistent. Thus, all the results we present are
from CAIDA’s November 20, 2009 dataset (with slight mod-
iﬁcations to the sibling relationships, see the full version);
counterparts of these graphs, computed from Cyclops and
IXP data [12, 13] are in the full version [1].
Realistic examples.
Rather than providing contrived
counterexamples, we give evidence that the attack strate-
gies we discuss could succeed in wild by ensuring that every
example we present comes from real data. All the exam-
ples we present here were found in CAIDA’s November 20,
2009 dataset [11], and then “anonymized” by replacing AS
numbers with symbols (e.g., in Figure 1, m for manipula-
tor, v for victim, T 1 for a Tier 1 AS, etc.). We do this in
order to avoid ‘implicating’ innocent ASes with our example
attacks, as well as to avoid reporting potentially erroneous
AS-relationship inferences made in the CAIDA dataset (see
Section 6.4 for further discussion).
3. FOOLING BGP SECURITY PROTOCOLS
This section overviews the security protocols we consider,
and presents the set of (possibly) bogus paths that a manipu-
lator can announce to each neighbor without getting caught.
We use the anonymized subgraph of CADIA’s AS graph in
Figure 1 to demonstrate the fraction of traﬃc a manipulator
m could attract by announcing one of these (possibly) bogus
paths to all its neighbors.
Our focus is on protocols with well-deﬁned security guar-
antees. Thus, we consider the ﬁve major BGP security vari-
ants, ordered from weakest to strongest security, as follows:
(unmodiﬁed) BGP, Origin Authentication, soBGP, S-BGP,
and data-plane veriﬁcation. Because we focus on security
guarantees and not protocol implementation, we use these
as an umbrella for many other proposals (see [5] for a sur-
vey) that provide similar guarantees using alternate, often
lower-cost, implementations. Furthermore, our ordering of
protocols is strict: an attack that succeeds against a strong
security protocol, will also succeed against the weaker se-
curity protocol. We also consider defensive ﬁltering as an
orthogonal security mechanism.
BGP. BGP does not include mechanisms for validating
information in routing announcements. Thus, the manip-
ulator can get away with announcing any path he wants,
including (falsely) claiming that he is the owner of the vic-
tim’s IP preﬁx. Indeed, when the manipulator m in Figure 1
(an anonymized Canadian Tier 2 ISP) launches this attack
on the v’s IP preﬁx (an anonymized Austrian AS), our sim-
ulations show that he attracts traﬃc from 75% of the ASes
in the internetwork.3
3In fact, another strategy, called a subpreﬁx hijack, is avail-
able to manipulator; by announcing a longer, more speciﬁc
subpreﬁx of the victim’s IP preﬁx, he can attract traﬃc from
100% of the ASes in the internetwork. This work does not
90Origin Authentication. Origin authentication [6] uses
a trusted database to guarantee that an AS cannot falsely
claim to be the rightful owner for an IP preﬁx. However,
the manipulator can still get away with announcing any
path that ends at the AS that rightfully owns the victim
IP preﬁx. For instance, in Figure 1, the manipulator m can
attract traﬃc from 25% of the ASes in the internetwork by
announcing the path (m, v, Preﬁx), even though no such
path physically exists.
soBGP. Secure Origin BGP (soBGP) [8] provides origin
authentication as well as a trusted database that guarantees
that any announced path physically exists in the AS-level
topology of the internetwork. However, a manipulator can
still get away with announcing a path that exists but is
not actually available. In Figure 1, the manipulator m can
attract traﬃc from 10% of the ASes in the internetwork by
announcing the path (m, p, v, Preﬁx). Notice that this
path is unavailable; GR2 forbids the Swiss Tier 2 ISP p to
announce a peer path to another peer.
S-BGP. In addition to origin authentication, Secure BGP
[9] also uses cryptographically-signed routing announcements
to provides a property called path veriﬁcation. Path veriﬁ-
cation guarantees that every AS a can only announce a path
abP to its neighbors if it has a neighbor b that announced the
path bP to a. Thus, it eﬀectively limits a single manipula-
tor to announcing available paths. For instance, in Figure 1,
the manipulator’s normal path (see Section 2.3) is the ﬁve-
hop customer path (m, a3, a2, a1, v, Preﬁx); announcing
that path allows him to attract traﬃc from 0.9% of the ASes
in the internetwork. However, with S-BGP the manipula-
tor could instead announce the shorter four-hop provider
path (m, T 1, a1, v, Preﬁx), thus doubling attracted traﬃc
to 1.7%.
Indeed, S-BGP does not prevent the manipula-
tor from announcing the shorter, more expensive, provider
path, while actually forwarding traﬃc on the cheaper, longer
customer path.
Data-plane veriﬁcation. Data-plane veriﬁcation [5, 10]
prevents an AS from announcing one path, while forwarding
on another. Thus, if the manipulator in Figure 1 wants to
maximize his attracted traﬃc, he must also forward traﬃc
on the provider path.
Defensive Filtering. Defensive ﬁltering polices the BGP
announcements made by stubs. A stub is an AS with no cus-
tomers, and in our model, GR2 implies that a stub should
never announce a path to a preﬁx it does not own. Thus,
our model of defensive ﬁltering has each provider keep a
“preﬁx list” of the IP preﬁxes owned by its direct customers
that are stubs. If a stub announces a path to any IP preﬁx
that it does not own, the provider drops/ignores the an-
nouncement, thus enforcing GR2.
In most of our analy-
sis, we assume that every provider in the internetwork cor-
rectly implements defensive ﬁltering (see also the discussion
in Section 8). As such, we assume that defensive ﬁltering
completely eliminates all attacks by stubs.
4. SMART ATTRACTION ATTACKS
We simulate attraction attacks on measured graphs of the
Internet’s AS-level topology [11–13] to determine how much
consider subpreﬁx hijacks, mostly because these attacks are
well understood, but also because they can be prevented by
the ﬁltering practices discussed in [5].
1
0.8
0.6
0.4
0.2
0
No Defensive Filtering
Defensive Filtering
   BGP
   OrAuth
   soBGP
   SBGP
Figure 2: Lower bounds on the probability of at-
tracting at least 10% of ASes in the internetwork.
traﬃc a manipulator can attract in the average case. This
section ﬁrst presents the attack strategies we simulated, and
then reports our results.
4.1  A  smart-but-suboptimal  attack  strategy
We assumed that ASes make routing decisions based on
business relationships and path length, and that a manipu-
lator m cannot lie to his neighbor a about their business re-
lationship (i.e., between m and a). Thus, intuition suggests
that the manipulator’s best strategy is to widely announce
the shortest possible path:
“Shortest-Path Export-All” attack strategy.
An-
nounce to every neighbor, the shortest possible path that is
not ﬂagged as bogus by the secure routing protocol.
Every “Shortest-Path Export-All” attack strategy
on S-BGP is also an attack on data-plane veriﬁ-
cation. The “Shortest-Path Export-All” attack strategy
on S-BGP has the manipulator announce his shortest legiti-
mate available path to the victim, instead of his normal path
(see Sections 2.3 and 3). Notice that if the manipulator
actually decides to forward his traﬃc over the announced
path, he has a successful attack on data-plane veriﬁcation
as well! Thus, the “Shortest-Path Export-All” attack strat-
egy on data-plane veriﬁcation is identical to the attack on
S-BGP. (To reduce clutter, the following mostly refers to the
attack on S-BGP.)
We underestimate damage.
Section 6 shows that the
“Shortest-Path Export-All” attack strategy is not actually
optimal for the manipulator, and Section 7 shows that ﬁnd-
ing the optimal attack strategy is NP-hard. Thus, we give
up on ﬁnding the optimal attack strategy, and run simu-
lations assuming that the manipulator uses this smart-but-
suboptimal attack. This means that the results reported in
this section underestimate the amount of damage a manip-
ulator could cause, and we usually cannot use these results
to directly compare diﬀerent secure routing protocols.
In
spite of this, our simulations do provide both (a) useful lower
bounds on the amount of damage a manipulator could cause,
and (b) a number of surprising insights on the strategies a
manipulator can use to attract traﬃc to his network.
4.2  D efensive  ﬁl teri ng  i s  cruci al 
Our ﬁrst observation is that defensive ﬁltering is a crucial
part of any Internet security solution:
Figure 2: We show the probability that, for a randomly
chosen (manipulator,victim) pair, the manipulator can at-
tract traﬃc destined for the victim from at least 10% of
the ASes in the internetwork. The manipulator uses the
911
0.8
0.6
0.4
0.2
0
0
0.2
0.8
Fraction of ASes routing thru Manipulator
0.4
0.6
1