# 五、使用自定义指标扩展`HorizontalPodAutoscaler`
Computers make excellent and efficient servants, but I have no wish to serve under them.
- *史巴克*
采用**水平自动标尺** ( **HPA** )通常经历三个阶段。
第一阶段是*发现*。当我们第一次发现它的作用时，我们通常会大吃一惊。“看看这个。它可以自动扩展我们的应用。我再也不需要担心复制品的数量了。”
第二阶段是*用法*。一旦我们开始使用 HPA，我们很快就会意识到基于内存和 CPU 扩展应用是不够的。一些应用确实会随着负载的增加而增加内存和 CPU 的使用，而其他许多应用则不会。或者更准确地说，不是成比例的。对于某些应用，HPA 运行良好。对许多其他人来说，它根本不起作用，或者是不够的。迟早，我们需要将 HPA 阈值扩展到基于内存和 CPU 的阈值之外。这个阶段的特点是*失望*。“这似乎是一个好主意，但我们无法在大多数应用中使用它。我们需要回到基于指标和手动更改副本数量的警报。”
第三阶段是*重新发现*。一旦我们浏览了 HPA v2 文档(在撰写本文时仍处于测试阶段)，我们可以看到它允许我们将其扩展到几乎任何类型的度量和表达式。通过适配器，我们可以将 HPA 与普罗米修斯或几乎任何其他工具挂钩。一旦我们掌握了这一点，我们可以设置的触发应用自动扩展的条件就几乎没有限制了。唯一的限制是我们能够将数据转换成 Kubernetes 的自定义指标。
我们的下一个目标是扩展 HorizontalPodAutoscaler 定义，以包括基于普罗米修斯中存储的数据的条件。
# 创建集群
`vfarcic/k8s-specs`([https://github.com/vfarcic/k8s-specs](https://github.com/vfarcic/k8s-specs))存储库将继续作为 Kubernetes 定义的来源。我们将通过获取最新版本来确保它是最新的。
All the commands from this chapter are available in the `05-hpa-custom-metrics.sh` ([https://gist.github.com/vfarcic/cc546f81e060e4f5fc5661e4fa003af7](https://gist.github.com/vfarcic/cc546f81e060e4f5fc5661e4fa003af7)) Gist.
```
 1  cd k8s-specs
 2
 3  git pull
```
这些要求与我们在上一章中的要求相同。唯一的例外是 **EKS** 。我们将继续对所有其他 Kuberentes 口味使用与之前相同的 Gists。
A note to EKS users
Even though three t2.small nodes we used so far have more than enough memory and CPU, they might not be able to host all the Pods we'll create. EKS (by default) uses AWS networking. A t2.small instance can have a maximum of three network interfaces, with four IPv4 address per each. That means that we can have up to twelve IPv4 addresses on each t2.small node. Given that each Pod needs to have its own address, that means that we can have a maximum of twelve Pods per node. In this chapter, we might need more than thirty-six Pods across the cluster. Instead of creating a cluster with more than three nodes, we'll add Cluster Autoscaler (CA) to the mix, and let the cluster expand if needed. We already explored CA in one of the previous chapters and the setup instructions are now added to the Gist `eks-hpa-custom.sh` ([https://gist.github.com/vfarcic/868bf70ac2946458f5485edea1f6fc4c)](https://gist.github.com/vfarcic/868bf70ac2946458f5485edea1f6fc4c)).
请使用以下 Gists 之一来创建新集群。如果您已经有了一个想要用于练习的集群，请使用 Gists 来验证它是否满足所有要求。
*   `gke-instrument.sh` : **具有 3 个 n1-standard-1 工作节点的 GKE** 、 **nginx Ingress** 、 **tiller** 、 **Prometheus** Chart 和环境变量 **LB_IP** 、 **PROM_ADDR** 和 **AM_ADDR** ( [)](https://gist.github.com/vfarcic/675f4b3ee2c55ee718cf132e71e04c6e)
*   `eks-hpa-custom.sh` : **具有 3 个 T2 .小型工作节点的 EKS** 、 **nginx Ingress** 、 **tiller** 、 **Metrics Server** 、 **Prometheus** 图表、环境变量 **LB_IP** 、 **PROM_ADDR** 和 **AM_ADDR** ，以及**集群自动缩放器**([https://gist . github . com](https://gist.github.com/vfarcic/868bf70ac2946458f5485edea1f6fc4c)
*   `aks-instrument.sh` : **带有 3 个 Standard_B2s 工作节点的 AKS** 、 **nginx Ingress** 和 **tiller** 、 **Prometheus** 图表，以及环境变量 **LB_IP** 、 **PROM_ADDR** 和**AM _ ADDR**([https://gist . github . com/vfarcic/65a 0d 5834 c 9 e 20 ebf1 b 924](https://gist.github.com/vfarcic/65a0d5834c9e20ebf1b99225fba0d339)
*   `docker-instrument.sh` : **带有 **2 个 CPU**、 **3 GB RAM** 、 **nginx Ingress** 、 **tiller** 、**度量服务器**、**普罗米修斯**图表，以及环境变量 **LB_IP** 、 **PROM_ADDR** 和**AM _ ADDR**([https://](https://gist.github.com/vfarcic/1dddcae847e97219ab75f936d93451c2)**
*   `minikube-instrument.sh` : **Minikube** 带 **2 个 CPU**、 **3 GB RAM** 、**入口**、**存储提供程序**、**默认存储类**和**指标-服务器**插件已启用、**分蘖**、**普罗米修斯**图表和环境变量 **LB_IP** 、【T21
现在我们已经准备好扩展我们对 HPA 的使用。但是，在我们这样做之前，让我们(再次)简单探讨一下 HPA 是如何开箱即用的。
# 在没有度量适配器的情况下使用 HorizontalPodAutoscaler
如果我们不创建度量适配器，度量聚合器只知道与容器和节点相关的 CPU 和内存使用情况。让事情变得更复杂的是，这些信息只限于最后几分钟。由于 HPA 只关心 Pods 和其中的容器，我们只限于两个指标。当我们创建 HPA 时，如果构成 Pods 的容器的内存或 CPU 消耗高于或低于预定义的阈值，它将扩展或缩减 Pods。
度量服务器定期从工作节点内部运行的库元素中获取信息(中央处理器和内存)。
这些指标被传递给指标聚合器，在这种情况下，它不会增加任何额外的价值。从那时起，高性能计算部门定期(通过其应用编程接口端点)查阅指标聚合器中的数据。当 HPA 中定义的目标值与实际值之间存在差异时，HPA 将操纵部署或状态集的副本数量。正如我们已经知道的那样，对这些控制器的任何更改都会导致通过创建和操作复制集来执行滚动更新，复制集会创建和删除 Pod，这些 Pod 由运行在调度 Pod 的节点上的 Kubelet 转换为容器。
![](img/d9f95b8d-7de9-4e19-86e5-702c61885999.png)
Figure 5-1: HPA with out of the box setup (arrows show the flow of data)
在功能上，我们刚才描述的流程运行良好。唯一的问题是指标聚合器中的可用数据。仅限于内存和 CPU。很多时候，这还不够。因此，我们没有必要改变流程，而是将可用数据扩展到 HPA。我们可以通过度量适配器来做到这一点。
# 探索普罗米修斯适配器
考虑到我们希望通过 Metrics API 扩展可用的指标，并且 Kubernetes 允许我们通过它的*Custom Metrics API*([https://github . com/Kubernetes/Metrics/tree/master/pkg/API/Custom _ Metrics](https://github.com/kubernetes/metrics/tree/master/pkg/apis/custom_metrics))来实现我们的目标，一个选项可能是创建我们自己的适配器。
根据我们存储指标的应用(数据库)，这可能是一个不错的选择。但是，鉴于重新发明轮子毫无意义，我们的第一步应该是寻找解决方案。如果有人已经创建了一个适合我们需求的适配器，那么采用它将是有意义的，而不是我们自己创建一个新的。即使我们确实选择了只提供我们正在寻找的部分特性的东西，在此基础上构建(并为项目做出贡献)也比从头开始更容易。
鉴于我们的指标存储在普罗米修斯中，我们需要一个能够从中获取数据的指标适配器。既然普罗米修斯很受欢迎，被社区采纳，那就已经有一个项目等着我们去使用了。名为*Kubernetes 普罗米修斯定制度量适配器*。它是 Kubernetes 自定义度量 API 的一个实现，使用 Prometheus 作为数据源。
由于我们所有的安装都采用了 Helm，我们将使用它来安装适配器。
```
 1  helm install \
 2      stable/prometheus-adapter \
 3      --name prometheus-adapter \
 4      --version v0.5.0 \
 5      --namespace metrics \
 6      --set image.tag=v0.5.0 \
 7      --set metricsRelistInterval=90s \
 8      --set prometheus.url=http://prometheus-server.metrics.svc \
 9      --set prometheus.port=80
10
11  kubectl -n metrics \
12      rollout status \
13      deployment prometheus-adapter
```
我们从`stable`存储库中安装了`prometheus-adapter`舵图。资源是在`metrics`命名空间中创建的，`image.tag`设置为`v0.3.0`。
我们将`metricsRelistInterval`从`30s`的默认值更改为`90s`。这是适配器将用于从普罗米修斯获取指标的时间间隔。由于我们的 Prometheus 设置是每 60 秒从其目标获取一次指标，我们不得不将适配器的时间间隔设置为一个更高的值。否则，适配器的频率会高于普罗米修斯的拉取频率，我们会有没有新数据的迭代。
最后两个参数指定了适配器访问普罗米修斯应用编程接口的网址和端口。在我们的例子中，网址被设置为通过普罗米修斯的服务。
Please visit *Prometheus Adapter Chart README* ([https://github.com/helm/charts/tree/master/stable/prometheus-adapter](https://github.com/helm/charts/tree/master/stable/prometheus-adapter)) for more information about all the values you can set to customize the installation.
最后，我们等到`prometheus-adapter`推出。
如果一切都按预期运行，我们应该能够查询 Kubernetes 的定制度量 API，并检索通过适配器提供的一些 Prometheus 数据。
```
 1  kubectl get --raw \
 2      "/apis/custom.metrics.k8s.io/v1beta1" \
 3      | jq "."
```
Given the promise that each chapter will feature a different Kubernetes' flavor, and that AWS did not have its turn yet, all the outputs are taken from EKS. Depending on the platform you're using, your outputs might be slightly different.
查询自定义指标输出的第一个条目如下。
```
{
  "kind": "APIResourceList",
  "apiVersion": "v1",
  "groupVersion": "custom.metrics.k8s.io/v1beta1",
  "resources": [
    {
      "name": "namespaces/memory_max_usage_bytes",
      "singularName": "",
      "namespaced": false,
      "kind": "MetricValueList",
      "verbs": [
        "get"
      ]
    },
    {
      "name": "jobs.batch/kube_deployment_spec_strategy_rollingupdate_max_unavailable",
      "singularName": "",
      "namespaced": true,
      "kind": "MetricValueList",
      "verbs": [
        "get"
      ]
    },
    ...
```
通过适配器可用的自定义指标列表很大，我们可能不得不认为它包含了所有存储在普罗米修斯中的指标。我们以后会知道这是否是真的。目前，我们将重点关注我们可能需要的与`go-demo-5`部署相关的 HPA 指标。毕竟，为自动缩放提供指标是适配器的主要功能，如果不是唯一的功能的话。
从现在开始，度量聚合器不仅包含来自度量服务器的数据，还包含来自普罗米修斯适配器的数据，该适配器反过来从普罗米修斯服务器获取度量。我们尚未确认我们通过适配器获得的数据是否足够，以及 HPA 是否适用于自定义指标。
![](img/2caa17d4-543c-4aef-bc51-67282a29270b.png)
Figure 5-2: Custom metrics with Prometheus Adapter (arrows show the flow of data)
在深入探讨适配器之前，我们将定义`go-demo-5`应用的目标。
我们应该不仅能够根据内存和 CPU 使用情况来扩展 Pods，还能够根据通过入口进入的请求数量或通过仪表化指标观察到的请求数量来扩展 Pods。我们可以添加许多其他标准，但作为一种学习体验，这些应该就足够了。我们已经知道如何配置 HPA 来基于 CPU 和内存进行扩展，所以我们的任务是用请求计数器来扩展它。这样，当应用接收到太多请求时，我们将能够设置增加副本数量的规则，并在流量减少时对其进行清理。
既然我们想扩展连接到`go-demo-5`的 HPA，我们下一步就是安装应用。
```
 1  GD5_ADDR=go-demo-5.$LB_IP.nip.io
 2
 3  helm install \
 4    https://github.com/vfarcic/go-demo-5/releases/download/
    0.0.1/go-demo-5-0.0.1.tgz \
 5      --name go-demo-5 \
 6      --namespace go-demo-5 \
 7      --set ingress.host=$GD5_ADDR
 8
 9  kubectl -n go-demo-5 \
10      rollout status \
11      deployment go-demo-5
```
我们定义了应用的地址，安装了图表，并一直等到部署推出。
A note to EKS users
If you received `error: deployment "go-demo-5" exceeded its progress deadline` message, the cluster is likely auto-scaling to accommodate all the Pods and zones of the PersistentVolumes. That might take more time than the `progress deadline`. In that case, wait for a few moments and repeat the `rollout` command.
接下来，我们将通过入口资源向应用发送 100 个请求来生成一点流量。
```
 1  for i in {1..100}; do
 2      curl "http://$GD5_ADDR/demo/hello"
 3  done
```
现在我们生成了一些流量，我们可以尝试找到一个指标来帮助我们计算有多少请求通过了入口。由于我们已经知道`nginx_ingress_controller_requests`提供了通过入口进入的请求数量，我们应该检查它现在是否作为自定义指标可用。
```
 1  kubectl get --raw \
 2      "/apis/custom.metrics.k8s.io/v1beta1" \
 3      | jq '.resources[]
 4      | select(.name
 5      | contains("nginx_ingress_controller_requests"))'
```
我们向`/apis/custom.metrics.k8s.io/v1beta1`发出了请求。但是，正如您已经看到的，仅这一项就可以返回所有指标，我们只对一项感兴趣。这就是为什么我们将输出传输到`jq`并使用它的过滤器只检索包含`nginx_ingress_controller_requests`作为`name`的条目。
如果您收到一个空的输出，请等待一会儿，直到适配器从普罗米修斯提取指标(它每 90 秒提取一次)并重新执行命令。
输出如下。
```
{
  "name": "ingresses.extensions/nginx_ingress_controller_requests",
  "singularName": "",
  "namespaced": true,
  "kind": "MetricValueList",
  "verbs": [
    "get"
  ]
}