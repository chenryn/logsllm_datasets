within the browser.
Time Synchronization: As the two devices (phone and terminal
running browser application) may have two different local time
clocks, our implementation, like Sound-Proof, requires the record-
ings from these devices to be synchronized. For this reason, both
the phone and the browser applications run a simple time synchro-
nization protocol with the web-server. Similar to Sound-Proof,
the protocol is implemented over HTTP that allows each device
to compute the time difference between the local time and the
server time. Each device runs the time synchronization protocol
while it is recording the ambient audio. Both devices compute
their round-trip time delay (θ = t2 − t0) and then clock differ-
ence (δ = t2 − t1 − θ/2) with the web-server. Here, t0, t1, and t2
are the timestamps of the device’s request transmission, the server’s
request reception/response transmission, and the device’s response
reception, respectively. During our ofﬂine analysis of audio sam-
ples, the recordings from each of the devices are adjusted taking
into account the clock difference (δ) with the web-server.
2.3 Implementing and Testing Sound-Proof’s
Correlation Engine
Correlation Analysis: Correlation analysis between an audio pair
is implemented in a similar fashion as Sound-Proof. That is, we
used one-third octave band ﬁltering and cross-correlation to get a
similarity score of an audio pair, as described below:
• One-third Octave Bands: We divide the audio samples into dif-
ferent bands based on frequency. Each band covers a speciﬁc
range of frequencies. A frequency is said to be an octave in
width when the upper band frequency is twice the lower band
frequency. A one-third octave band is deﬁned as a frequency
band whose upper band-edge frequency is equal to the lower
band frequency multiplied by the cube root of two [20]. The
audio spectrum from 20Hz to 20kHz can be divided into 32 one-
third octave bands with the center frequency of 19th one-third
octave band set to 1000Hz. The center frequency of the lowest
band is 16Hz covering from 14.1Hz to 17.8Hz, while the center
frequency of the highest band is 20kHz covering from 17.78kHz
to 22.39kHz [25].
Since we are targeting Sound-Proof, we divide the audio into the
bands ranging from 50Hz to 4kHz. Sound-Proof utilizes only
these set of bands, as these bands provided the best Equal Er-
ror Rate (EER) in the analysis reported in [17]. Hence, we only
use the sixth band with the center frequency 50Hz to the twenty
sixth band with the center frequency 4kHz, i.e. we consider only
910twenty bands out of the thirty two available bands. We use twen-
tieth order Butterworth bandpass ﬁlter [19] in MATLAB to split
the audio samples into these bands.
• Cross Correlation: We use the same system that was imple-
mented in [16] to correlate ambient noise. Sound-Proof also
closely follows this system for calculating cross-correlation. We
use standard cross-correlation function to measure the similar-
ity between the time-based signals Xi and Xj. To calculate the
similarity, we ﬁrst normalize the signals according to their en-
ergy. Then, we calculate the correlation between each signal at
different lags and use maximum correlation value. The corre-
lation between two time-based signals Xi and Xj is measured
as:
Corr(i, j) = max(CrossCorr(Xi, Xj))
(1)
Sound-Proof also considers the lag to get the cross-correlation.
This plays a major role to prevent attacks on the system when an
attacker submits a similar audio sample as that in victim’s envi-
ronment, which may be separated by a certain lag. Sound-Proof
has bound the lag l between 0 and lmax, where it sets lmax to
150ms. Hence, in our attack analysis, we also check the max-
imum cross-correlation of audio pairs with the time lag bound
to 150ms. This lag value yielded a low EER in Sound-Proof’s
analysis reported in [17].
Data Collection and Experiments: We collected audio samples
using the framework described in Section 2.2 at different loca-
tions such as lab/ofﬁce, home, cafe, and library. We used Google
Chrome on MacBook Air and Samsung Galaxy S V to record the
audio samples using our implementation of Sound-Proof. We col-
lected total of 525 audio pair samples and mix-matched them to get
the correlation between each audio pair. The data collection exper-
iment was approved by our University’s IRB. The audio recordings
were around 8 seconds long which were trimmed to 3 seconds after
time synchronization for the correlation analysis (similar to [17]).
Similar to Sound-Proof, our implementation uses one-third oc-
tave band ﬁltering and cross-correlation to calculate the similarity
score between an audio pair, as described above. We use octave
band ﬁltering to split 3 second long audio recordings from both
devices into 20 one-third octave bands. Maximum correlation is
computed with the time-lag bound to 150ms between these audio
pairs in their respective bands. The average correlation value ob-
tained from these bands is the correlation between the audio pair.
The audio pairs which are co-recorded (recorded at the same lo-
cation and at almost the same time) are labeled as True Positive
(TP) and the rest are labeled as True Negatives (TN). Once the cor-
relation values for each of the co-recorded audio pairs as well as
non co-recorded audio pairs are calculated, we compute the FPR
(False Positive Rate) and FNR (False Negative Rate) as a function
of the correlation threshold. FPR for a given threshold deﬁnes the
fraction of audio pairs (out of all audio pairs) which are not co-
recorded but are classiﬁed as valid (TP) at that threshold, while
FNR for a given threshold deﬁnes the fraction of co-recorded audio
pairs (out of all audio pairs) that are classiﬁed as invalid (TN) at that
threshold. Using FPR and FNR at different threshold values, we
calculate EER (Equal Error Rate) and determine the optimal value
of correlation threshold (Tc) at which FNR and FPR are equal.
From the data collected in our experiments, we obtained the op-
timal threshold Tc of 0.1524 yielding an EER of 0.1607. The cor-
relation threshold set in our experiment is in line with the corre-
lation threshold of Sound-Proof (0.13) [17]. Moreover, our other
parameter settings are exactly the same as in Sound-Proof’s im-
plementation [17], i.e., using the audio samples each of length 3
seconds, ﬁltering the audio samples into 20 different one-third oc-
tave bands, and cross-correlating the audio samples with time lag
bound to 150ms. Since our correlation threshold is higher than that
used in Sound-Proof’s implementation, it means that attacking our
implementation will be harder than attacking Sound-Proof’s im-
plementation reported in [17]. In other words, the Sound-Danger
attack against our implementation (threshold 0.1524) would imply
an attack against Sound-Proof’s implementation (threshold 0.13)
[17]. Nevertheless, we analyze the performance of Sound-Danger
for different (higher) correlation threshold values in the attack anal-
ysis in Section 4, and show that the attacks still work well even at
such higher thresholds.
3. ATTACKS
As the threat model of our Sound-Danger attack system sug-
gests, we assume that the attacker is already in possession of the
victim’s username and password but is not co-located with the vic-
tim (i.e. victim’s phone). The attacker’s goal is to satisfy the second
factor requirement, which is to fool the system into accepting the
co-location of the attacker’s terminal and the victim’s phone.
We consider two types of attacks against Sound-Proof, both of
which exploit the sounds generated by the phone itself. The ﬁrst
type of Sound-Danger attack is the active attack, where the attacker
performs an activity by which a sound (a phone ringing tone or an
app-based notiﬁcation) would dominate the ambient audio around
the victim’s device. Since the attacker is aware of the audio pro-
duced at the phone’s end, it can generate the same sound at its
own surroundings (or feed the same sound programmatically to the
browser) and succeed in proving the co-location with the phone.
The second type of Sound-Danger attack is the passive attack, in
which the attacker waits for the phone to create a previously known
sound, speciﬁcally a morning alarm, at an opportune moment and
then tries to generate the same noise at its local terminal. The steps
taken by the attacker to target Sound-Proof are shown in Figure 1.
3.1 Active Attacks
In the Sound-Danger active attack scenarios, we assume that the
attacker has already compromised the web service that uses Sound-
Proof. Since account databases on such servers typically store other
forms of user’s data (e.g., phone number for the password recovery
purposes), hacking into the server reveals other information that
can be a used in the active attacks. Such data if not stored on the
main server is assumed to be obtained with data aggregation attack
through other services that user has an account with (which proba-
bly does not use 2FA).
Based on the type of information that the attacker possesses, we
deﬁne (and later implement and evaluate) the following attacks:
Ringtone Attack: In this attack, the attacker predicts the ringtone
(or vibration sound) that the victim has set for the received phone
calls. The attacker calls the victim using the knowledge it has ob-
tained from compromised account database. At the same time, the
attacker attempts to login by entering the previously leaked vic-
tim’s credentials to the login page via its own login terminal. To
mimic the victim’s ambient noise (now the sound of the ringtone),
attacker plays the same ringtone audio at its location next to the
login terminal.
Information known to the attacker: Victim’s username and pass-
word, victim’s phone number and victim’s ringtone.
Task of the attacker: Ring the victim’s phone and create same sound
around the local login terminal.
App Notiﬁcation Attack: In this attack, the attacker predicts the
voice/messaging application running on the victim’s phone and
911Figure 1: Sound-Danger Attack Flowchart: The attacker (human or bot) enforces the ambient audio to be highly similar at both (attacker’s and victim’s)
ends by making calls or sending notiﬁcations to the victim’s phone, or waiting for an alarm to go off at the victim’s phone, and by simultaneously feeding the
same sounds at its own end. The attacker would succeed in logging into the webservice, while the user may remain unaware of the attack or even when the
attack is detected, the account may already have been compromised.
tries to activate the notiﬁcation tone or ring tone of the application
by communicating to the victim through the application. Since the
user typically registers to many of the web services using phone
number or user id, the attacker can contact the user on these ap-
plications either by their phone number (obtained by hacking the
primary account database) or user id (possibly similar to the one
registered with the primary service.
Examples of such applications are Google Voice, FaceTime,
Skype, Facebook, WhatsApp and Viber. Calling or texting the user
on these applications generates a default ringtone or notiﬁcation
tone that is known to the attacker and is usually not changed by the
users. Hence, the attacker starts a login attempt to the primary ser-
vice using the known credentials, and then contacts the user on any
of the mentioned applications. At the same time, it plays the same
ringtone or notiﬁcation tone locally near the login terminal. The
attacker would succeed since it regenerates the same ambient noise
as the victim’s phone locally (around the attacker’s login terminal).
Information known to the attacker: Victim’s username and pass-
word, victim’s phone number, victim’s installed application on the
phone, victim’s id with the application (same as phone number or
primary username) and application ringtone.
Task of the attacker: Ring the victim’s messaging application and
create the same sound around the local login terminal.
Feasibility of Attacks: In all of our attacks above, the attacker
would have to predict some information necessary to execute the
attacks (e.g., the type of ringtone used by the victim). However,
given predictable patterns and phone usage habits across users, this
is not much of a problem for the attacker. In Section 5, we sup-
port these assumptions and claims made here, based on the data
gathered from the participants in an online survey.
3.2 Passive Attacks
In the passive attack, the attacker predicts, or knows users’ ac-
tivity and launches the attack based on the knowledge it has from
the users’ proﬁle gathered from the leaked database. Unlike the
active attack, the attacker does not attempt to generate a sound at
the user’s side but only regenerates the same ambient sound that is
supposed to be available at the user’s side. Unlike the active attack,
the passive attack does not alert the user by creating a sound, and
hence can be repeatedly attempted without triggering suspicion.
Although there are different scenarios where an attacker can cre-
ate a similar ambient noise to that at victim’s side such as simi-
lar media attack (both attacker and victim are watching same me-
dia/TV channel, as also brieﬂy considered in [17]), same event
(both attacker and victim are attending a popular event), or similar
vehicles sound (attacker knows when victim commutes and uses
similar in-vehicle sound), we chose to exploit the ambient noise
that is created by victim’s phone itself such as alarms or morning re-
ports. We believe that this attack has a higher chance of succeeding
compared to other ambience-based passive attacks since the sound
of the alarm of the phone will dominate the ambient sounds.
Alarm Attack: In this attack, the attacker knows the speciﬁc app
which generates an audio at particular time of day such as the morn-
ing alarm. Attacker attempts to log in at a speciﬁc moment when
such alarm is supposed to go off using the victim’s credential. At
the same moment, the attacker plays the alarm tone at its local lo-
gin terminal to mimic the ambient noise around the victim’s phone.
In this attack apart from the victim’s username and password, the
victim’s alarm time, alarm tone is also known to the attacker.
Information known to the attacker: Victim’s username and pass-
word, victim’s alarm ringtone and victim’s timezone.
Task of the attacker: Create the same alarm sound around its local
login terminal.
Feasibility of the Attack: Similar to the active attacks, the attacker
would have to predict some information necessary to execute the
attacks (e.g., the type of ringtone used by the victim and victim’s
timezone). However, given predictable patterns and phone usage
habits across users, this is not challenging, as we demonstrate in
Section 5 based on the results of an online survey.
3.3 Active vs. Passive Attacks
We introduced passive and active attacks, each of which has their
912(a) Phone Call
(b) WhatsApp Call
(c) SMS Notiﬁcation
(d) Facebook Notiﬁcation
Figure 2: Change in correlations when an attacker makes call or sends notiﬁcation via different apps at different point of time. In Figures a and b, the ringtone
at the victim’s side starts playing at the 5th second while in Figures c and d the notiﬁcation audio goes off at 4th second as depicted by highest correlation.
There is no audio at the victim’s side from the ringtone when the attacker plays the respective audio at 0th second. The correlation values are higher when the
ringer is ringing compared to that when there is no ringer i.e. before 2 sec in call.
own merits. With the passive alarm attack, it is very likely that the
victim user would not notice the ongoing malicious login attempt.
Therefore, the attacker might be able to repeat the attack repeatedly
until it is successful. In case of active attacks, the sounds generated
by the attacker on the user’s phone (e.g., a phone ringing tone)
could notify the user and seek her attention. However, only a few
seconds of audio is enough for the Sound-Proof system to verify
the co-presence of the phone and the terminal. Therefore, by the
time the user attends to the phone (e.g., to pick up the call) and
even when the user notices the malicious login attempt, the attack
would have already succeeded and the user’s account might have
already been compromised.
Although Sound-Proof logs the login attempts on the device (as
suggested in [17]), the users may leave their phones unattended, in
purses or bags, might not be concerned about security or be dili-
gent enough to the extent that they review the logs carefully and
frequently. Extensive research literature in user-centered security
shows that users may not pay attention to security notiﬁcations or
heed security warnings and messages (e.g., [13, 24]). Moreover,
relying upon the users to detect such attacks will break the “zero-
effort” property of Sound-Proof. Furthermore, even if the logs were
read and understood by the users, the attack may have already suc-
ceeded by the time suspicious activity is noticed.
4. ATTACK CORRELATION ANALYSIS
In this section, we show the correlation analysis of different at-
tacks using Sound-Danger introduced in Section 3. In other words,
we test the rate at which the attack samples (corresponding to at-
tacker’s browser and victim’s phone) will be accepted as valid lo-
gin attempts by our implementation of the Sound-Proof app. In our
analysis, we used Samsung Galaxy S5 from Verizon as the victim’s
smartphone along with Google Chrome browser in MacBook Air
(mid 2012) as attacker’s terminal to perform the attack. The at-
tacker makes calls or sends notiﬁcation from LG G3 from Verizon
or a computer to create an audio it desires at the victim’s side.
To perform the attacks described in Section 3, the attacker fol-
lows the steps as illustrated in Figure 1. The attacker who per-
forms such attacks tries to generate or predict a similar audio at
the victim’s side while it logs into the victim’s account with the
victim’s credentials. The attacker has full control over the com-
puter/browser that it is using. However, the attacker does not have
any direct control over the victim’s smartphone/app.
4.1 Ringtone and App Notiﬁcation Attacks
To test our ringtone and app notiﬁcation based active attacks, as
described in Section 3, we use phone ringtone (call/SMS) as well as
various other ringtones from some of the popular apps in Google
Play Store, such as Facebook, WhatsApp Messenger, Viber, and
Skype. We use default ringer of the app/phone call. Although some
of the victims may have customized the ringtone for phone call or
any other app, some of these apps do not allow users to customize
the ringtone for calls or notiﬁcations. The primary difference be-
tween call and notiﬁcation attack is that the ringtone audio is played
longer for the call than it is for the notiﬁcation.
Since the attacker does not have any direct control over the vic-
tim’s phone, the attacker faces challenges due to two types of de-
lays: (1) Sound-Proof recording delay, and (2) call/notiﬁcation de-
lay. Due to Sound-Proof recording delay, the attacker cannot per-
fectly guess at what time instance Sound-Proof starts recording au-
dio from the victim’s phone for the purpose of login. And, due to
the call/notiﬁcation delay, when the attacker makes call or sends
notiﬁcation to the victim’s phone, the attacker also cannot make a
perfect estimate to when the ringer sound will be played at the vic-
tim’s side. To estimate these two delays, the attacker can run an
experiment by making calls or sending notiﬁcations to itself and
monitor the delays. Based on this, the attacker tries to synchro-
nize the ringer being played at both sides as much as possible. We
run and analyze the attacks assuming that the attacker knows when
Sound-Proof starts recording at its end. This is a valid assumption
since the attacker fully controls its terminal. Because of the delays
mentioned above, during the actual attack, Sound-Proof may start