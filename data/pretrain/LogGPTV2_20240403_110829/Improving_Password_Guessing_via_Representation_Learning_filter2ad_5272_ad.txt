concept of password weak locality. Section IV-B introduces
DPG from theoretical (Section IV-B1) as well as practical
(Section IV-B2) viewpoints.
A. Password weak locality
The embedding properties of the latent representation map
passwords with similar characteristics close to each other
in the latent space. We called this property strong locality,
and we exploited it to generate variants of a chosen pivot
password or template (discussed in Section III-A). In that case,
the adjective “strong” highlights the strict semantic relation
among the generated set of passwords. However, the same
dynamics enable a broader form of semantic bounding among
passwords. This latter property partially captures the general
features of the entire password distribution. Such features
could be very abstract properties of the distribution, such as the
average passwords length and character distribution ascribable
to password policies. We refer to this observed property as
password weak locality to contrast it with the strong locality.
As a representative example, Fig. 3 depicts the 2D repre-
sentation of passwords from myspace [10], hotmail [4], and
phpbb [11] on the latent space learned by a generator.8 We
8It is important to emphasize that these graphical depictions are obtained
by a dimension reduction algorithm. Hence, they do not depict latent space
accurately. So, they merely serve as a representative illustration. We will verify
our assumption empirically later in the paper.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:44 UTC from IEEE Xplore.  Restrictions apply. 
1389
can observe that the passwords coming from the same dataset
tend to be concentrated in the latent space and do not spread
abruptly all over the spectrum. The dimensionality of the
fraction of latent space covered by an entire password set
(the red parts in Fig. 3 (a), (b), and (c) clearly depends on
the heterogeneity of its passwords. Passwords from smaller
sets (e.g., myspace) are concentrated in restricted and dense
zone of the latent space, whereas passwords from larger sets
(e.g., as phpbb) tend to cover a more signiﬁcant section while
they are still tightly knitted.
In the following sections, we will present evidence of this
to
locality property, and we will show how to exploit
improve password guessing.
B. DPG for covariate shift reduction
it
First, we present the theoretical motivation behind DPG in
Section IV-B1 followed by its instantiation in Section IV-B2.
1) Theoretical motivation: Probabilistic password guessing
tools implicitly or explicitly attempt to capture the data dis-
tribution behind a set of observed passwords, i.e., the train-
set. This modeled distribution is then used to generate new
and coherent guesses during a password guessing attack. A
train-set is usually composed of passwords that were pre-
viously leaked. By assumption, every password-set leak is
characterized by a speciﬁc password distribution p∗(x). When
we train the probabilistic model, we implicitly assume p∗(x)
to be general enough to well-represent the entire class of
password distributions. This generality is essentially due to the
fact that the real-word password guessing attacks are indeed
performed over sets of passwords that potentially come from
completely different password distributions. As a matter of
fact, we typically do not have any information about the attack-
set distribution. This can indeed be completely different from
the one used for model training. As a representative example,
different password policies or users’ predominant languages
can cause the test-set’s distribution to differ from the train-set’s
distribution drastically. This discrepancy in the distribution of
the train-set and test-set is a well-known issue in the domain of
machine learning, and it is referred to as covariate shift [49].
As stated above, typically, we do not know anything about
the distribution of the attacked-set. However, once we crack
the ﬁrst password, we can start to observe and model the
attacked distribution. Every new successful guess provides
valuable information that we can leverage to improve the
quality of the attack, i.e., to reduce the covariate shift. This
iterative procedure recalls a Bayesian-like approach since
there is continuous feedback between observations and the
probability distribution.
For fully data-driven approaches, a naive solution to in-
corporate the acquired information from successful guesses
is to ﬁne-tune the model to change the learned password
distribution. However, prescribed probabilistic models such
as FLA directly estimate the password distribution using a
parametric function:
p(x) = p(x; θ),
(2)
where θ is the set of weights of a neural network. In this
case, the only possibility of modifying the distribution p(x)
in a meaningful way is to act on θ by harnessing the learning
process. However, this is not an easy/attractive solution mainly
because the new guessed passwords are potentially inadequate
representatives9 and will not force the model to generalize over
the new information. Additionally, the computational cost of
ﬁne-tuning the network is considerable, and the ﬁnal results
cannot be guaranteed due to the sensitivity of the learning
process.
Similar to FLA, our generative model also exploits a neural
network as an estimator. However, its modeled distribution is
a joint probability distribution, shown in Eq. 3:
p(x) = p(x, z) = p(x | z; θ)p(z),
(3)
where p(z) is referred to as the latent distribution.
As introduced in Section II-A, when p(z) = ˙p(z) (i.e., prior
latent distribution), p(x | z; θ)p(z) acts as a good approx-
imation of the target data distribution (i.e., the distribution
followed by the train-set). Nevertheless, p(z) can be arbi-
trarily chosen and used to indirectly change the probability
distribution modeled by the generator. The RHS of the Eq. 3
clearly shows that θ is not the only free parameter affecting the
9A very few guessed passwords against a dataset of millions of unknown
passwords.
(a) myspace
(b) hotmail
(c) phpbb
Fig. 3. Password Weak Locality: 2D visualization of the latent points for three different passwords sets for a generator trained on the RockYou train-set. The
red points represent the latent points corresponding to the passwords in the respective password set whereas the blue points loosely represent the dense part
of the latent space. Please refer to the color version for better illustration.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:44 UTC from IEEE Xplore.  Restrictions apply. 
1390
distribution of the ﬁnal passwords. Indeed, p(z) is completely
independent of the generator, and so it can be modiﬁed
arbitrarily without acting on the parameters of the neural
network.
This possibility, along with the passwords locality of the
latent space, allows us to correctly and efﬁciently generalize
over the new guessed passwords,
leading the pre-trained
network to model a password distribution closer to the guessed
ones. It is noteworthy that this capability of generalizing over
the new points is achieved via the weak locality and not
from the neural network itself. The intuition here is that
when we change p(z) to assign more density to a speciﬁc
guessed password x, we are also increasing the probability
of its neighboring passwords that, due to the weak locality
property, share similar characteristics. This, in turn, makes
it possible to highlight the general features of the guessed
passwords (e.g., structure, length, character set, etc.).
Thus, by controlling the latent distribution, we can in-
crease the probabilities of the zones potentially covered by
the passwords coming from the target distribution. We call
this technique Dynamic Password Guessing (DPG). In the
case of homogeneous distribution (e.g., myspace), we can
narrow down the solution space around the dense zones, and
avoid exploring the entire latent-space. On the other hand, for
passwords sets sampled from distributions far from the one
modeled by the generator, we can focus on zones of the latent
space, which, otherwise, would have been poorly explored. In
both cases, we can reduce the covariate shift and improve the
performance of the password guessing attack.
In a broad sense, DPG can potentially adapt to very pe-
culiar password distributions; distributions induced from
the contexts where no suitable train-sets can be collected.
E.g., passwords created under an unmatched composition
policy or rare/unobserved users’ habits. As long as the gen-
erator has a non-zero probability of generating such rare
passwords, the feedback given from the correct guesses
can consistently be used to reweigh the latent distribution
and mimic the unknown target password distribution. We
will validate this claim in the next section.
2) Practical implementation: In this section, we cover DPG
from a practical viewpoint. Algorithm 2 brieﬂy describes DPG.
In Algorithm 2, O represents the target set of passwords,
the passwords guessed by the
Z is the collection of all
Algorithm 2 Dynamic Password Guessing (DPG)
Input: Set: O, Int: α
1: i = 0
2: platent = ˙p(x)
3: Z = {}
4: foreach z ∼ platent do
5:
6:
7:
8:
9:
10:
11:
12:
13: end for
i + +
Zi = Z = Z ∪ {z}
if i ≥ α then
platent = makeLatentDistribution(Zi)
x = G(z)
if x ∈ O then
end if
end if
generator, and α is deﬁned as the hot-start parameter of
the attack, an element that we describe later in this section.
The variable platent in the pseudo-code, represents the latent
distribution from which we sample latent points. The pro-
cedure makeLatentDistribution returns the latent distribution
induced from the group of guessed passwords Zi at step i.
Leveraging the maximum-likelihood framework, we choose
such a distribution to maximize the probability of the set
of observed passwords Xi = {G(z) | z ∈ Zi}. This is
accomplished by considering a latent distribution p(z | Zi)
conditioned to the set of passwords guessed at each step i.
The ﬁnal password distribution represented by the generator
during DPG is reported in Eq. 4.
p(x) = p(x | z; θ)p(z | Zi).
(4)
As a natural extension of the proximity password generation
harnessed in Section III-B, we choose to represent p(z | Zi)
as a ﬁnite mixture of isotropic Gaussians. In particular, the
mixture is composed of n Gaussians, where: (1) n is the
number of the latent points in Zi; and (2) for each zj ∈ Zi,
a Gaussian is deﬁned as N (zj, σI) with center as zj and a
ﬁxed standard deviation σ.
When the probability of a password, i.e., xj = G(zj), is
known, we weight the importance of the jth distribution as
P (xj); otherwise a uniform distribution among the Gaussians
is assumed. In the reported experiments, we always used
uniform weighting. Equation 5 deﬁnes the probability density
function of the latent space.
n(cid:88)
p(z | Zi) =
P (G(zj)) · N (z | zj, σI).
(5)
j=0
Every new guessed password x introduces a new Gaussian
centered at z to the mixture. Consequently, every new guessed
password contributes to changes in the latent distribution
p(z | Zi) by moving the density of the distribution in the
zone of the latent space where it lies. Fig. 4 visualizes this
phenomenon.
In the context of DPG, the GAN generator performs slightly
better than CWEA. For this reason, all the experiments re-
ported in this section are obtained with our GAN generator
trained on the RockYou train-set. Fig. 5 depicts the perfor-
mance comparison between a static attack (e.g., PassGAN)
and DPG over the three passwords sets. Adaptively changing
the latent distribution allows us to boost the number of guessed
passwords per unit of time. Importantly, this improvement
comes without any additional information or assumption over
the attacked passwords set. In addition, the computational
overhead due to the new sampling technique is negligible.
The steep improvement
in the performance obtained with
DPG supports our view that reducing the covariate shift is
a sound strategy.
The sudden growth in the guessed passwords in DPG
(shown in Fig. 5) is due to the hot-start or α parameter; in
DPG, we use the prior latent distribution until a predetermined
number (α) of passwords has been guessed. After that, we start
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:44 UTC from IEEE Xplore.  Restrictions apply. 
1391
(a) Actual attacked set
(b) 104 generation
(c) 105 generation
(d) 106 generation
(e) 107 generation
Fig. 4. 2D visualization of: (a) the entire hotmail dataset (red-part) mapped on the latent space learned from the RockYou train-set and (b-e) the latent space
in four progressive attack steps for DPG on the hotmail test-set. The red markers portray the guessed passwords at each step (i.e., the Zi), whereas the color
intensity of the blue regions depicts the probability assigned from the used latent distribution (i.e., mixture of Gaussians) to the latent space.
(a) myspace
(b) hotmail
(c) phpbb
Fig. 5. The performance gain obtained by DPG (with α = 0.15) with respect to static attack for three different test-sets
to use the conditional latent distribution p(z | Zi). The reason
is that if DPG starts with the very ﬁrst guessed password,
then the latent distribution can be stuck in a small area of
the latent space. However, launching DPG after guessing a
sufﬁcient number of passwords (i.e., after ﬁnding a set of
uncorrelated latent points in the latent space) gives us the
possibility to match a heterogeneous set of passwords, which
correctly localize the dense zones of the latent space where
the attacked passwords are likely to lie.
The ﬁnal hyper-parameter of our attack is the standard
deviation (σ) assigned to every Gaussian in the mixture.
Under the Kernel Density Estimation (KDE) perspective, σ
represents the bandwidth of our Gaussian kernels. In the
guessing scenario, instead, this value deﬁnes how far we want
to sample from the clusters of observed passwords. A larger
value of σ allows us to be less biased and explore a wider
zone around the guessed passwords; whereas a smaller value
enables a more focused inspection of the latter. Appendix D
better explicates the effect of σ and α on DPG.
In Fig. 6, we report a direct comparison of the proposed
DPG against the state-of-the-art password models for three
password leaks. For the comparison, we used the same tools
and conﬁgurations described in Section III-D1.10 In the ﬁgure,
DPG refers to the dynamic guessing attack, whereas SPG to
the static one. min-auto is obtained by combining the guesses
of FLA, Hashcat, OMEN, and PCFG. min-auto+DPG is then
obtained by adding DPG to the min-auto ensemble. Fig. 6 (a)
reports the results for the LinkedIn leak. Here, the dynamic
adaptation allows us to guess up to 10% more passwords
then the static approach. However, it cannot directly match
the performance of FLA and PCFG in this general case.
Nevertheless, our models behave better than mangling rules
and the Markov model. Given the different nature of the
dynamic guessing strategy, combining DPG with min-auto
10For the min-auto, we do not use CMU-PGS [13] directly given their limits
on the number of queries allowed and the cardinality of the tested sets.
(a) LinkedIn
(b) Youku
(c) Zomato
Fig. 6. Performance of various password models on three password leaks. For DPG, we used σ = 0.35 and α = 10%.
1392
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:44 UTC from IEEE Xplore.  Restrictions apply. 
0.00.20.40.60.81.0Generated passwords1e90.00.20.40.60.81.0Macthed passwords (%)0.00.20.40.60.81.0Generated passwords1e9010203040506070Macthed passwords (%)min-automin-auto+DPGDPGSPGFLAPCFGhashcatOMEN0.00.20.40.60.81.0Generated passwords1e100204060Macthed passwords (%)0.00.20.40.60.81.0Generated passwords1e100204060Macthed passwords (%)0.00.20.40.60.81.0Generated passwords1e90204060Macthed passwords (%)permits us to guess more passwords. We will better motivate
this phenomenon in the next section.
Consistently better results are observed as soon as we con-
sider leaks that exhibit peculiar biases in their password dis-
tributions. Fig. 6 (b) reports the results for the leak Youku [8],
[1] - a Chinese video hosting service. In this case, the inherent
distribution shifts induced by a different class of users causes
a substantial covariate shift phenomenon. Here, the dynamic
adaptation allows us to guess more passwords than the other
tools; DPG improves guess after guess, each time evolving
and eventually surpassing the min-auto conﬁguration obtained
by combining all other models.
Even more interesting results can be observed when we
consider leaks that introduce heavier biases. Fig. 6 (c) reports
the results for the Zomato [15], [14] leak. This leak is an
extreme case since ∼ 40% of its content includes random
tokens of six alphanumeric characters. That creates a sharply
segmented bimodal distribution that can be detected and
efﬁciently captured by DPG. In this instance, the dynamic
adaptation of the latent space allows us to guess up to
∼ 5 times more passwords than the static attack (i.e., SPG),
allowing our model to match more than 50% of the set in
less than 109 iterations. On the other hand, static approaches,
including min-auto, cannot match the performance of DPG in
this extreme case. Of note, adding DPG to the ensemble of
min-auto (i.e., min-auto+DPG) allows us to guess ∼ 70% of
the set.
The last two examples highlight the ability of DPG to adapt
to the target password distribution. However, the result of the
LinkedIn leak tells us that the dynamic attack cannot directly
match the performance of the state-of-the-art solutions in case
there is no evident covariate shift. In the next section, we will
show that the DPG algorithm is indeed useful also in such
cases, as it soundly permits to guess peculiar passwords of
the attacked distribution that would be otherwise ignored.
3) The impact of the dynamic adaptation: In this section,
we clarify the effect of the dynamic latent adaptation over
the password distribution originally modeled from the deep
generative model. To this end, we compare the probability of
the guessed passwords according to different password distri-
butions, namely, (1) the distribution of the train-set and (2) the
distribution of the attacked-set of passwords. To soundly
represent and generalize such probability distributions, we rely
on FLA [42] as an explicit password mass estimator. We train
two instances of FLA on the two passwords sets and use the
trained models to infer probabilities over the password guessed
during the dynamic and static attacks.
Fig. 7 summarizes our measurements for the phpbb pass-
word leak (i.e., the attacked distribution). Here, the cumulative
probability of the guessed password is reported for both
dynamic and static attacks. In particular, Fig. 7 (a) describes
the probabilities assigned from the probability distribution
of the train-set (i.e., the FLA instance trained on RockYou),
whereas Fig. 7 (b) reports the same data points, but computed
according to the probability distribution of the attacked-set
(i.e., the FLA instance trained on phpbb).
When we perform DPG, we expect the password distribu-
tion represented from the deep generative model to gradually
diverge from the one learned at
training time. Fig. 7 (a)
graphically describes this phenomenon; here, we note how the
latent adaptation is causing the model to guess passwords that
have a lower probability according to the train-set distribution.
More interestingly, whereas the discrepancy between the mod-
eled and the train distribution grows, the discrepancy sharply
reduces for the attacked distribution. Fig. 7 (b) explicates
the convergence process towards the latter. Furthermore, this
ﬁgure gives us a piece of more valuable information. It shows
that the DPG guesses passwords that have high-probability ac-
cording to the attacked distribution, i.e., passwords associated
with a higher number of users in the attacked service. Sudden
jumps in the latter cumulative probability curve, indeed, can
be attributed to the event of guessing such high-probability
passwords. To note, once we guess a ﬁrst high-probability
password, we start sampling new guesses around it, guessing
more high-probability passwords consequently and making
those jumps even steeper.
Relying on the same example, more practical results can be
appreciated when we consider the adversarial interpretation.
Fig. 7 (c) reports the cumulative guess-number graph for
the static and dynamic attacks measured using the FLA
instance trained on RockYou (i.e., the train-set of our model).
The estimated cumulative guess-number of
the dynamic
attack is two magnitudes larger than that of the static attack.
Considering FLA’s accuracy [28], this result conﬁrms that
DPG can induce the generation of passwords that have low
belief according to the train-set distribution. Moreover, this
example shows how DPG can induce the earlier generation
of passwords that would require multiple magnitude more
guesses
state-of-the-art
password guessers, such as FLA. In the reported example,