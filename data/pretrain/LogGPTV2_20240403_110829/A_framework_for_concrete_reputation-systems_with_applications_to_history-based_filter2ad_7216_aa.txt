title:A framework for concrete reputation-systems with applications to history-based
access control
author:Karl Krukow and
Mogens Nielsen and
Vladimiro Sassone
A Framework for Concrete Reputation›Systems
with Applications to History›Based Access Control(cid:3)
Karl Krukowy z
BRICS
Mogens Nielsen
BRICS
University of Aarhus, Denmark
University of Aarhus, Denmark
PI:EMAIL
PI:EMAIL
Vladimiro Sassonex
Department of Informatics
University of Sussex, UK
PI:EMAIL
ABSTRACT
In a reputation-based trust-management system, agents main-
tain information about the past behaviour of other agents.
This information is used to guide future trust-based de-
cisions about interaction. However, while trust manage-
ment is a component in security decision-making, many ex-
isting reputation-based trust-management systems provide
no formal security-guarantees.
In this extended abstract,
we describe a mathematical framework for a class of sim-
ple reputation-based systems.
In these systems, decisions
about interaction are taken based on policies that are exact
requirements on agents’ past histories. We present a ba-
sic declarative language, based on pure-past linear temporal
logic, intended for writing simple policies. While the ba-
sic language is reasonably expressive (encoding e.g. Chinese
Wall policies) we show how one can extend it with quanti(cid:12)-
cation and parameterized events. This allows us to encode
other policies known from the literature, e.g., ‘one-out-of-
k’. The problem of checking a history with respect to a
policy is e(cid:14)cient for the basic language, and tractable for
the quanti(cid:12)ed language when policies do not have too many
variables.
(cid:3)Extended Abstract. The full paper is available as a
BRICS technical report, RS-05-23 [17], online at http:
//www.brics.dk/RS/05/23.
yNielsen and Krukow are supported by SECURE:
Secure Environments for Collaboration among Ubiquitous
Roaming Entities, EU FET-GC IST-2001-32486.
Krukow is supported by DISCO: Semantic Foundations of
Distributed Computing, EU IHP, Marie Curie,
HPMT-CT-2001-00290.
zBRICS: Basic Research in Computer Science (www.brics.dk),
funded by the Danish National Research Foundation.
xSupported by MyThS: Models and Types for Security in
Mobile Distributed Systems, EU FET-GC IST-2001-32617.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for pro(cid:2)t or commercial advantage and that copies
bear this notice and the full citation on the (cid:2)rst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speci(cid:2)c
permission and/or a fee.
CCS’05, November 7(cid:150)11, 2005, Alexandria, Virginia, USA.
Copyright 2005 ACM 1›59593›226›7/05/0011 ...$5.00.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information]:
Security and Protection; D.4.6 [Operating Systems]: Se-
curity and Protection { Access controls
General Terms
Algorithms, Security, Languages
Keywords
Reputation, trust management, history-based access con-
trol, temporal logic, model checking
1.
INTRODUCTION
In global-scale distributed systems, traditional authoriza-
tion mechanisms easily become either overly restrictive, or
very complex [2].
In part, this is due to the vast num-
bers of principals they must encompass, and the open na-
ture of the systems. In dynamic and reputation-based trust-
management systems, the problems of scale and openness
are countered by taking a less static approach to autho-
rization and, more generally, decision making. In these sys-
tems, principals keep track of the history of interactions with
other principals. The recorded behavioural information is
used to guide future decisions about interaction (see refer-
ences [15, 24, 27] on reputation). This dynamic approach is
being investigated as a means of overcoming the above men-
tioned security problems of global-scale systems. Yet, in
contrast with traditional (cryptographic) security research,
within the area of dynamic trust and reputation, no widely
accepted security-models exist, and to our knowledge, few
systems provide provable security guarantees (see, however,
references [6, 18, 20] on general formal modelling of trust in
global computing systems).
Many reputation systems have been proposed in the litera-
ture, but in most of these the recorded behavioural informa-
tion is heavily abstracted. For example, in the EigenTrust
system [16], behavioural information is obtained by counting
the number of ‘satisfactory’ and ‘unsatisfactory’ interactions
with a principal. Besides lacking a precise semantics, this
information has abstracted away any notion of time, and
is further reduced (by normalization) to a number in the
interval [0; 1].
In the Beta reputation system [14], similar
abstractions are performed, obtaining a numerical value in
[(cid:0)1; 1] (with a statistical interpretation). There are many
other examples of such information abstraction or aggrega-
tion in the reputation-system literature [15], and the only
non-example we are aware of is the framework of Shmatikov
and Talcott [27] which we discuss further in the concluding
section.
Abstract representations of behavioural information have
their advantages (e.g., numerical values are often easily com-
parable, and require little space to store), but clearly, infor-
mation is lost in the abstraction process. For example, in
EigenTrust, value 0 may represent both \no previous inter-
action" and \many unsatisfactory previous interactions" [16].
Consequently, one cannot verify exact properties of past be-
haviour given only the reputation information.
In this paper, the concept of ‘reputation system’ is to
be understood very broadly, simply meaning any system in
which principals record and use information about past be-
haviour of principals, when assessing the risk of future in-
teraction. We present a formal framework for a class of sim-
ple reputation systems in which, as opposed to most \tra-
ditional" systems, behavioural information is represented in
a very concrete form. The advantage of our concrete rep-
resentation is that su(cid:14)cient information is present to check
precise properties of past behaviour. In our framework, such
requirements on past behaviour are speci(cid:12)ed in a declara-
tive policy-language, and the basis for making decisions re-
garding future interaction becomes the veri(cid:12)cation of a be-
havioural history with respect to a policy. This enables us
to de(cid:12)ne reputation systems that provide a form of provable
\security" guarantees, intuitively, of the form: \If principal p
gains access to resource r at time t, then the past behaviour
of p up until time t satis(cid:12)es requirement  r."
To get the (cid:13)avour of such requirements, we preview an
example policy from a declarative language formalized in
the following sections. Edjlali et al. [9] consider a notion
of history-based access control in which unknown programs,
in the form of mobile code, are dynamically classi(cid:12)ed into
equivalence classes of programs according to their behaviour
(e.g. \browser-like" or \shell-like"). This dynamic classi(cid:12)ca-
tion falls within the scope of our very broad understanding of
reputation systems. The following is an example of a policy
written in our language, which speci(cid:12)es a property similar
to that of Edjlali et al., used to classify \browser-like" appli-
cations:
 browser (cid:17) :F(cid:0)1(modify) ^
:F(cid:0)1(create-subprocess) ^
G(cid:0)1 (cid:0)8x:(cid:2)open(x) ! F(cid:0)1(create(x))(cid:3)(cid:1)
Informally, the atoms modify, create-subprocess, open(x)
and create(x) are events which are observable by moni-
toring an entity’s behaviour. The latter two are parame-
terized events, and the quanti(cid:12)cation \8x" ranges over the
possible parameters of these. Operator F(cid:0)1 means ‘at some
point in the past,’ G(cid:0)1 means ‘always in the past,’ and con-
structs ^ and : are conjunction and negation, respectively.
Thus, clauses :F(cid:0)1(modify) and :F(cid:0)1(create-subprocess)
require that the application has never modi(cid:12)ed a (cid:12)le, and
has never created a sub-process. The (cid:12)nal, quanti(cid:12)ed clause
G(cid:0)1 (cid:0)8x:(cid:2)open(x) ! F(cid:0)1(create(x))(cid:3)(cid:1) requires that when-
ever the application opens a (cid:12)le, it must previously have
created that (cid:12)le. For example, if the application has opened
the local system-(cid:12)le "/etc/passwd" (i.e. a (cid:12)le which it has
not created) then it cannot access the network (a right as-
signed to the \browser-like" class). If, instead, the applica-
tion has previously only read (cid:12)les it has created, then it will
be allowed network access.
1.1 Contributions and Outline
We present a formal model of the behavioural information
that principals obtain in our class of reputation systems.
This model is based on previous work using event struc-
tures for modelling observations [21], but our treatment of
behavioural information departs from the previous work in
that we perform (almost) no information abstraction. The
event-structure model is presented in Section 2.
We describe our formal declarative language for interac-
tion policies.
In the framework of event structures, be-
havioural information is modelled as sequences of sets of
events. Such linear structures can be thought of as ((cid:12)nite)
models of linear temporal logic (LTL) [22]. Indeed, our ba-
sic policy language is based on a (pure-past) variant of LTL.
We give the formal syntax and semantics of our language,
and provide several examples illustrating its naturality and
expressiveness. We are able to encode several existing ap-
proaches to history-based access control, e.g. the Chinese
Wall security policy [3] and a restricted version of so-called
‘one-out-of-k’ access control [9]. The formal description of
our language, as well as examples and encodings, is pre-
sented in Section 3.
An interesting new problem is how to re-evaluate policies
e(cid:14)ciently when interaction histories change as new infor-
mation becomes available. It turns out that this problem,
which can be described as dynamic model-checking, can be
solved very e(cid:14)ciently using an algorithm adapted from that
of Havelund and Ro(cid:24)su, based on the technique of dynamic
programming, used for runtime veri(cid:12)cation [13].
Interest-
ingly, although one is verifying properties of an entire in-
teraction history, one needs not store this complete history
in order to verify a policy: old interaction can be e(cid:14)ciently
summarized relative to the policy. Descriptions of two algo-
rithms, and analysis of their time- and space-requirements
is given in the full paper [17]. The results are outlined in
Section 3.
Our simple policy language can be extended to encom-
pass policies that are more realistic and practical (e.g., for
history-based access control [1, 9, 11, 29], and within the tra-
ditional domain of reputation systems: peer-to-peer- and
online feedback systems [16, 24]). In the full paper we de-
scribe a form of quantitative policies, a notion of policy ref-
erencing to include other principals’ data, and quanti(cid:12)ed
policies. In Section 5 we illustrate the extension to quanti-
(cid:12)ed policies, and describe results regarding policy-checking
algorithms and complexity.
Related work is discussed in the concluding section. Due
to space restrictions no proofs are included in this paper.
The interested reader is referred to the associated technical
report [17] for proofs and additional examples.
2. OBSERVATIONS AS EVENTS
Agents in a distributed system obtain information by ob-
serving events which are typically generated by the reception
or sending of messages. The structure of these message ex-
changes are given in the form of protocols known to both
parties before interaction begins. By behavioural observa-
tions, we mean observations that the parties can make about
speci(cid:12)c runs of such protocols. These include information
about the contents of messages, diversion from protocols,
failure to receive a message within a certain time-frame, etc.
Our goal in this section, is to give precise meaning to the
notion of behavioural observations. Note that, in the setting
of large-scale distributed environments, often, a particular
agent will (concurrently) be involved in several instances of
protocols; each instance generating events that are logically
connected. One way to model the observation of events is
using a process algebra with \state", recording input/output
reactions, as is done in the calculus for trust management,
ctm [7]. Here we are not interested in modelling interaction
protocols in such detail, but merely assume some system
responsible for generating events.
We will use the event-structure framework of Nielsen and
Krukow [21] as our model of behavioural information. The
framework is suitable for our purpose as it provides a generic
model for observations that is independent of any speci(cid:12)c
programming language. In the framework, the information
that an agent has about the behaviour of another agent p,
is information about a number of (possibly active) protocol-
runs with p, represented as a sequence of sets of events,
x1x2 (cid:1) (cid:1) (cid:1) xn, where event-set xi represents information about
the ith initiated protocol-instance. Note, in frameworks for
history-based access control (e.g., [1, 9, 11]), histories are al-
ways sequences of single events. Our approach generalizes
this to allow sequences of ((cid:12)nite) sets of events; a general-
ization useful for modelling information about protocol runs