1
32, we see the maximum
possible leakage value of ùêº(ùêµ, ùê∂) = 1, which means that we learn
one bit of each base64 character by observing the accessed cache
line. If the table is not evenly distributed, the entropy for the sparser
cache line decreases, making it easier to infer the respective base64
character; however, at the same time, the entropy for the denser
cache line increases, making up for an overall smaller leakage. If the
alignment is not at a cache line boundary, but within a cache line,
the table may spread over more than two cache lines, leading to a
potentially higher leakage. In our experiments, we mostly observed
64 byte and 32 byte alignments, except for libraries compiled with
the SGX framework: Due to the memory constraints, the standard
Makefiles enable optimization for space (-Os in GCC), which reduces
the table alignment down to 1 byte. While the leaked information
per base64 character is rather small and capped at one bit, the
redundancy imposed by storing multiple secret key parameters
makes up for this, as we show in Section 5.
Non-LUT-based base64 decoding: Another approach for base64
decoding is treating each case separately: Most characters (letters
and numbers) are ASCII-encoded in contiguous chunks, with only
few exceptions. Thus, one can test whether the current character
is in a specific interval, and then simply add/subtract a certain
constant which then yields the associated 6-bit value. This approach
has, e. g., been used by BoringSSL [14] and the Rust base64 package,
although the latter has since moved to a LUT-based implementation.
Depending on the binary layout of the code handling each case,
an attacker may be able to acquire much more fine-grained infor-
mation about each character than in a LUT-based attack: If they can
distinguish each case, which may be possible by counting the num-
ber of executed instructions per loop iteration, they learn whether
the current character is an upper- or lower-case letter, a number, or
a special symbol. This corresponds to more than 1 bit of information,
even higher than the leakage induced by LUT-based decoding.
3.3.3 Exploiting the DER Format. Even though the majority of the
detected leakages are found in the base64 decoder, we also iden-
tified subtle secret-dependent computations in the DER decoder
and the big number initialization. In DER, the parameters are not
stored directly next to each other, but have a prefix denoting their
type (integer, 02) and byte length (see Listing 9 in the appendix).
Since base64 encoding divides the payload into 6-bit chunks, some
chunks may contain bits from both a secret parameter and a byte
belonging to DER formatting. If this DER byte is known to an at-
tacker, they can reduce the remaining uncertainty from detecting
the corresponding LUT cache line, and infer up to 4 bits of the
first or last secret parameter byte. While the parameter type byte
Session 10A: Crypto, Symbols and Obfuscation CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2460Table 1: LUT properties and expected leakage of base64 decoding implementations of several standard and SGX crypto libraries.
The observed LUT alignment is taken from our test system and may vary between systems and package sources. The estimated
leakage ùë∞ (ùë©, ùë™) depends on the LUT size, its observed alignment and the distribution of relevant entries over cache lines.
Decode iterations
LUT alignment (observed)
# Cache Lines
Version
2.17.0
3.6
2.24.0
ùêº(ùêµ, ùê∂)
Library
0.974 bit
Botan [15]
0.974 bit
GNU Nettle [30]
0.974 bit
mbedTLS [54]
0.811 bit
MS CryptoAPI [56]
0.696 bit
NSS [62]
0.974 bit
OpenSSL [63]
0.564 bit
RustSGX [69]
wolfSSL [79]
0.811 bit
1 The source code is not publicly available, so we could not determine whether Microsoft uses a fixed or a variable alignment.
2 The base64 decoder itself is included in a separate package (version 0.13.0), which gets pulled into the SGX enclave.
variable (32 byte)
variable (32 byte)
variable (32 byte)
unknown1(64 byte)
variable (64 byte)
variable (32 byte)
variable (20 byte)
variable (64 byte)
LUT size
256 byte
256 byte
128 byte
80 byte
256 byte
128 byte
256 byte
80 byte
3.58
1.1.1h
1.1.32
4.5.0
10.0.18362.476
1
1
2
1
1
2
1
1
5
5
3
2
4
3
5
2
is constant, the length byte is not; however, an attacker can learn
the length of the parameter through other leakages, like in cases
where a parameter is copied when initializing a big number object:
In order to speed up arithmetic operations, many big number imple-
mentations divide their state into 64-bit integer chunks, which are
initialized by copying the number bytes using bitwise operations
like shifts and OR. The attacker can then simply count the number
of loop iterations and thus learn the parameter length, if the loop
is not constant-time.
4 CACHE ATTACK ON INTEL SGX ENCLAVE
Attacking a simple lookup procedure, which mainly involves mem-
ory loads executed in a very short time frame, requires a high
temporal attack resolution or a slowed down victim process. Thus,
we attack the base64 decoding process of RSA keys in an Intel SGX
enclave, which allows us to analyze the decoding process on a per-
instruction basis. The attack we implemented is specific to the way
OpenSSL implements the decoding of base64 keys into its internal
data format, especially the offline analysis part which leverages
OpenSSL‚Äôs access pattern to the LUT. However, the translation
from base64 to binary by means of a LUT is a recurring pattern
in all of the libraries shown in Table 1. Thus, the general attack
scheme is applicable to other libraries as well.
In short, our attack on the base64 LUT-based decoding process
of RSA keys consists of several steps. First, we run OpenSSL‚Äôs key
decoding in an SGX enclave and execute it in a controlled, single-
stepped fashion, where the corresponding memory page accesses to
the LUT and decoding function are tracked. We combine the page
access monitoring with a classic Prime+Probe attack on the LLC to
track which cache line of the decoding table is accessed when the
investigated code is executed. The resulting trace is then processed
during an offline analysis step, which outputs a cache line access
pattern with the same length as the original base64 string in the
PEM file holding the private key.
We first run the attack without mitigation against recent tran-
sient execution attacks like LVI [19] and obtain mostly negative
results. However, as we show in this section, running the same
experiments with enabled mitigation drastically reduces noise in
the measurements, which allows to reliably extract all information
introduced by non-constant-time behavior in the base64 decoding.
4.1 Attack description
4.1.1 Attacker model. Intel SGX aims to protect programs by run-
ning them in enclaves isolated by special hardware mechanisms.
Ultimately, it allows enclaves to be guarded from a malicious OS
and otherwise rogue software environments and system adminis-
trators as long as the authenticity and integrity of the enclave and
SGX instance are verified by attestation [6, 24, 55]. Consequently,
attacking a process running in a protected enclave assumes an
attacker with system level privileges having full control over the
OS kernel and the system BIOS: They are capable of translating
virtual to physical addresses, manipulating page access bits and
setting timed interrupts using the APIC timer. Additionally, they
have access to the program‚Äôs binary and control the unprotected
application part. By using the SGX-Step framework [20], the enclave
can be single-stepped.
4.1.2 Cache Attack. For our cache attack, we use Prime+Probe
with eviction sets. After the discovery of Foreshadow [18], Intel
published a microcode fix which conducts an L1 cache flush on
every enclave exit, so we are restricted to attacking the L3 cache.
4.1.3 Attack process. Figure 2 shows an overview of the attack
process on base64 decoding in Intel SGX. We start with initializing
the victim‚Äôs enclave (#1) and constructing eviction sets (#2) for
every cache set possibly containing the cache lines holding the
lookup table. Since the last level cache is divided into slices, the
number of required eviction sets is determined by the number of
cache lines occupied by the LUT times the number of slices. To
construct the eviction sets, we implement an algorithm similar to
the procedure presented by Liu et al. [51] using virtual to physical
address translation. After constructing the eviction sets, we use
SGX-Step to configure APIC timer interrupts which allow us to
single step code running in the enclave (#3) and subsequently trigger
the base64 decoding (#4).
Session 10A: Crypto, Symbols and Obfuscation CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2461#1
Initialize enclave
#2
Eviction set
construction
#4
Start decoding
Activate
#3
single stepping
#5
Enclave
Decoding
#6
IRQ handler
#8
Offline analysis
#7
AEP
Check page access bit
Probe cache lines
Prime cache lines
Reset page access bit
Log
Figure 2: Attack process. Red: Attacker activity, Blue: Vic-
tim activity; The attacker is in control of the environment
as well as the enclave host application and calls the victim
code to start the attack process.
Next, we enter the enclave with the EENTER instruction and
execute one instruction (#5) during which the APIC timer interrupt
arrives. The interrupt causes an EEXIT, which is followed by the
IRQ handler (#6) which redirects to our customized AEP function
(#7). The latter is used to implement the attack code and finally
resume the enclave, returning to state #5. The cycle is terminated
when the end of the base64 procedure is detected.
Single stepping the victim code allows us to analyze the cache
behavior on a per instruction resolution, and, since the enclave is
in an interrupted state, our attack code in step #7 is not time con-
strained. However, entering the enclave takes substantially longer
than executing the next victim instruction, which adds potential
for noise accumulation in the LLC cache from other processes on
the system. To reduce unwanted side-effects and noise in the LLC,
the AEP routine starts with checking the page access bits of the
memory pages holding the LUT and the decoding routine, and then
immediately continues with probing the cache. After probing the
cache, the results of the cache eviction measurements and the page
access states are stored to disk for offline analysis (#8). Before re-
suming the enclave, the cache sets of interest are primed, the page
access bits belonging to the memory pages holding the LUT and
decoding routine are reset and the APIC timer is reprogrammed.
4.1.4 Offline Analysis. The data collected in step #7 is processed
in an offline analysis after the measurement finished. It contains
cache eviction time measurements and page access information, as
explained in 4.1.3, for every single-stepped instruction. In the fol-
lowing, a measurement refers to all the data collected for one single
stepped instruction. The goal of the offline analysis is identifying
those instructions that read data from the LUT and determining
the respectively accessed cache lines. Finally, a trace of cache line
accesses corresponding to the base64 characters in the private key‚Äôs
PEM file is constructed.
We first determine the median eviction times and corresponding
standard deviations for each eviction set over all measurements, ex-
cluding those with observed memory page access to the pages hold-
ing the LUT and decoding function. Those measurements which
show an access to both pages are, with a few exceptions at the
beginning of the trace, the ones corresponding to an actual lookup
operation. The median eviction times and standard deviation serve