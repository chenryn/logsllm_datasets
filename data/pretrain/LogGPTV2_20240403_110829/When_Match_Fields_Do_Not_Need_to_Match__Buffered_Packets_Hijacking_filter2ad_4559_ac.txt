example, it limits an application to install ﬂow rules for ﬂows
whose IP addresses are within 10.13.0.0/16. However, our
attack still succeeds under the presence of SDNShield. Though
the malicious application must install or update ﬂow rules
under the constraints of SDNShield, it can still set buffer IDs
at will and thus hijacks targeted packets to bypass ﬁrewalls.
C. TCP Three-Way Handshake Disruption
Attack Mechanism. This attack targets at the data plane layer
of SDN by disrupting TCP three-way handshake. As shown in
Figure 5, the host h1 aims to build a TCP connection with the
host h2 for reliable communications. According to the TCP
protocol, three packets must be exchanged before a reliable
TCP connection is established. The ﬁrst packet is the TCP
SYN packet. As there are no ﬂow rules matching the TCP
SYN packet that belongs to a new ﬂow, the switch S1 buffers
the packet and reports a PACKET_IN to the controller. An
application named APP Y installs ﬂow rules with a FLOW_MOD
message for the new ﬂow and forwards the buffered TCP SYN
packet to h2. After that, h2 returns a TCP packet with the
SYN and ACK signal bits set to h1. Finally, h1 sends a TCP
packet with the ACK signal bits set to ﬁnish building the TCP
connection.
Similar to the attack in Figure 4, a malicious application
named APP X can hijack the buffered TCP SYN packet if
it receives the PACKET_IN message before APP Y. APP X
issues a FLOW_MOD message to the switch S1. The match
ﬁeld of the message is speciﬁed as another ﬂow to avoid rule
conﬂicts. The buffer ID is speciﬁed as the ID of the buffered
TCP SYN packet, and the action is speciﬁed as drop. As
a result, the buffered TCP SYN packet is dropped, which
disrupts the TCP three-way handshake. After some time, h1
will send a TCP SYN packet to h2 again to make another try.
At this time, TCP SYN packet can be successfully forwarded
to h2 since APP Y has installed related ﬂow rules matching
the packet.
Though the attack cannot completely block the TCP con-
nections, it signiﬁcantly delays the ﬁnish time of building TCP
connections. According to the implementation of the network
protocol stack, a second TCP SYN packet is sent after 1000 ms
in the Linux operating system if a host does not get a response
of the ﬁrst TCP SYN packet. In windows, the time is much
longer, i.e., 3000 ms. It signiﬁcantly increases ﬂow completion
time (FCT) for small ﬂows whose FCT is usually smaller
than 50 ms [24]. Consequently, user experience and operator
revenue are highly impacted. According to a report [25], every
100 ms latency will cost 1% in business revenue for Amazon.
Defense Evasion. As far as we know, there are no related
defense considering this kind of attacks that disrupt TCP three-
way handshakes by hijacking buffered packets in SDN.
D. Control Trafﬁc Ampliﬁcation
Attack Mechanism. This attack targets at the SDN control
layer. It consumes bandwidth and computing resources by
copying massive buffered packets to controllers. As shown
in Figure 6, there are many buffered packets of new ﬂows
in switches. Switches generate PACKET_IN messages to the
controller for rule installation. The malicious APP X receives
PACKET_IN messages before a benign application that is
responsible for installing ﬂow rules for new ﬂows. It allows
the malicious application to hijack buffered packets. Besides
hijacking buffered packets to modify packet headers or for-
warding behaviors, the malicious application can copy lots of
buffered packets to generate a huge amount of PACKET_IN
messages with the group_all action in FLOW_MOD mes-
sages. The group_all action contains a list of action buck-
ets. A packet is cloned for each bucket and its forwarding
behavior follows the actions in a bucket. Thus, if the malicious
application installs a FLOW_MOD message where the buffer ID
is set as the ID of a buffered packet and the group_all
action contains many buckets of the output:controller
action, massive copies of the buffered packet will be sent
to controllers with PACKET_IN messages. Moreover,
the
application can force a PACKET_IN message to contain the
entire data packet
instead of a packet header by adding
the no_buffer action. Therefore, the attack generates an
ampliﬁcation effect on the control trafﬁc since a new ﬂow
triggers more than one PACKET_IN message.
6
APP Y  FLOW_MODAPP X  FLOW_MODmatch: bluebuf_id: 2action: dropAPP X: FLOW_MOD...buf_id:2h1S1h2match: redbuf_id: 2action: output:h2APP Y: FLOW_MODDropTCP SYN Packet...  FLOW_MODAPP XSDN Controller...buf_id:2h1S1h2  PACKET_IN...match: bluebuf_id: 2action: no_buffer, group_all,            output:controllerFLOW_MODWe deﬁne the ampliﬁcation factor η as the ratio of the size
of PACKET_IN messages with the attack over that without the
attack. If we use n to denote the number of action buckets in
a group_all action, d to denote the size of a data packet,
h to denote the size of the header of the data packet, and
p to denote the size of a PACKET_IN message excluding
the part that stores data packets. According to the OpenFlow
speciﬁcation [22], a PACKET_IN message contains the ﬁrst
128 bytes of a buffered data packet by default. For packets
less than 128 bytes, paddings are automatically added to the
message. Thus, the ampliﬁcation factor η is represented as
follows:
η = 1 +
p + max(d, 128)
p + 128
· n
(1)
We consider a real example with a new TCP ﬂow. The ﬁrst
packet of a TCP ﬂow is always a TCP SYN packet containing
no payloads, which is 74 bytes. As the packet is less than 128
bytes, the ampliﬁcation factor entirely depends on the number
of action buckets in a group_all action. According to our
investigation, Brocade FastIron SDN switch [26] supports at
most 64 action buckets in a group_all action. Thus, the
ampliﬁcation factor is 65. Previous studies [21], [27] have
shown that the bandwidth of the control channel between a
switch and a controller is tens of Mbps. Such an ampliﬁcation
effect on control trafﬁc can easily make the control channel
congested. Moreover, the ampliﬁcation factor can further en-
large for a UDP ﬂow since the ﬁrst packet of a UDP ﬂow
is possible to reach 1518 bytes, i.e., the maximal size of
a packet for Ethernet. According to our measurements, p is
108 bytes. Thus, the ampliﬁcation factor can be calculated as:
1 + 108+1518
108+128 · 64 ≈ 442, which is extremely large.
Defense Evasion. Previous studies [21], [27], [28], [29] have
provided various defense mechanisms to mitigate potential
PACKET_IN ﬂooding attacks. They are effective to defend
the ﬂooding attack where a malicious host randomly generates
anomalous packets with a high probability of matching no ﬂow
rules to trigger massive PACKET_IN messages. However, they
cannot defeat the ﬂooding attack exploiting buffered packet
hijacking. Different from previous ﬂooding attack, our attack
exploits the ﬁrst packet of benign data ﬂows to trigger massive
PACKET_IN messages. Thus, FloodDefender [21] fails to ﬁl-
ter out malicious data ﬂows and block them. FloodGuard [27]
defends PACKET_IN ﬂooding attacks by installing a wildcard
ﬂow rule of the lowest priority to forward packets matching
no ﬂow rules to data plane cache. The data plane cache
schedules packets and forwards them to the controller in a
rate-limited manner. However, as the ﬂow rules installed by
the malicious application has speciﬁed the actions of buffered
packets, buffered packets will not match the wildcard ﬂow
rules that send packets to the data plane cache. Instead, they
are copied and directly reported to controllers. Thus, our
attack can ﬂood the controller to consume bandwidth and
computing resources even if FloodGuard is deployed. AVANT-
GUARD [29] and LineSwitch [28] adopt the TCP SYN proxy
technique to defeat the PACKET_IN ﬂooding attack based on
TCP ﬂows. However, as mentioned by previous studies [21],
[27], they are invalid for ﬂows of other protocols. Therefore,
our attack can evade them by hijacking buffered packets of
other protocols, e.g., UDP packets, to ﬂood controllers.
7
Fig. 7: The model of m processing chains. ai,j denotes the j-th
application in the i-th processing chain with ni applications.
V. THEORETICAL ANALYSIS
In this section, we build a model of processing chains and
analyze the probability of successfully launching an attack by
hijacking buffered packets.
A. Processing Chain Model
The model of PACKET_IN processing chains can be
illustrated in Figure 7, regardless of the implementations of
different controllers. We assume there are m processing chains
in a controller and ni applications in the i-th processing chain,
i.e., the length of the chain is ni. Moreover, ai,j denotes the
j-th SDN application in the i-th processing chain. Once a
PACKET_IN message arrives at the controller, m copies of
it are sent to m processing chains simultaneously. Applica-
tions get a PACKET_IN message in sequence according to
their orders in a processing chain. There are many different
PACKET_IN messages encapsulating different data packets.
Each PACKET_IN message is processed by one or more
applications that are interested in the message. An application
typically continues transferring the message into the following
application after ﬁnishing processing it. The last application
in each processing chain stops transferring the PACKET_IN
message and eliminates it.
To conduct
theoretical analysis, we need to know the
delay for an application to process a PACKET_IN message
before it is transferred into the next application. Obviously, the
processing delay is not ﬁxed. We model the processing delay
as a random variable. According to previous studies [30], the
log-logistic (ﬁsk) distribution has been widely used to model
the processing delay when data is processed by an application
and then travels to another application. Moreover, we collect
a large number of real processing delays from different SDN
applications. We ﬁnd the log-logistic (ﬁsk) distribution suits
well for modeling the processing delays of PACKET_IN mes-
sages. For detailed distributions of processing delays, please
see Appendix A.
Thus, we deﬁne the processing delay of the application ai,j
as a random variable denoted by Di,j. It meets the log-logistic
distribution with two parameters, i.e., the scale parameter αi,j
and the shape parameter βi,j. Formally, we represent it as
follows:
(2)
Here, 1 ≤ i ≤ m and 1 ≤ j ≤ ni. If we deﬁne fi,j(d) as the
Di,j ∼ LL(αi,j, βi,j)
................................................                                                                             probability density function (PDF) of Di,j, we have:
(βi,j/αi,j)(x/αi,j)βi,j−1
; d > 0
fi,j(d) =
(1 + (x/αi,j)βi,j )2
(3)
When d ≤ 0, we have: fi,j(d) = 0. We ignore the propagation
delay between two successive applications for a PACKET_IN
message since the delay is far below the processing delay
in an application. For example,
the propagation delay is
only several microseconds according to our measurement on
Floodlight, while the processing delay of an application
is in the order of milliseconds.
B. Hijacking Probability Analysis
Based on the above model, we conduct a comprehensive
analysis on the probability of successfully hijacking a buffered
packet for a malicious application in processing chains. We
consider that an attacker has compromised the application ar,c
in Figure 7. The attacker aims to hijack a buffered packet
that should be processed by a benign application,
i.e., a
target application. There are two scenarios for the malicious
application to conduct the attack, i.e., attacking with an intra
processing chain and attacking with inter processing chains.
Attacking with an Intra Processing Chain. To successfully
launch the attack with an intra processing chain, the malicious
application ar,c must modify buffered packets in switches be-
fore a target application modiﬁes the buffered packets. In other
words, the malicious application ar,c must ﬁnish processing
a PACKET_IN message ahead of the target application. As
shown in Figure 7, we can see that the attack can succeed only
if the target application in the r-th processing chain is behind
the malicious application ar,c. If we use ar,j to denote the
target application, the hijacking probability with the malicious
application ar,c and the target application ar,j is:
(cid:26)100%, if j ∈ {1, 2, ..., c − 1}
0, if j ∈ {c + 1, c + 2, ..., nr}
(4)
pintra(ar,c, ar,j) =
As shown in Equation 4, the hijacking probability depends on
the relative positions of the malicious application and the target
application, regardless of processing delays.
Attacking with Inter Processing Chains. In the scenario of
inter processing chains, multiple copies of a PACKET_IN mes-
sage are fed into different processing chains. We consider that
the attacker aims to hijack the buffered packet that should be
processed by the target application ai,j in the i-th processing
chain. If the malicious application ar,c can successfully modify
the buffered packet in switches, the total processing delay for
a PACKET_IN copy delivered from the ﬁrst application to the
malicious application in the r-th processing chain must be
smaller than the total processing delay for a copy delivered
from the ﬁrst application to the j-th application in the i-
th processing chain. Formally,
the successful condition of
hijacking the buffered packet with the malicious application
ar,c and the target application ai,j can be represented as
follows:
Dr,k <
Di,k
(5)
c(cid:88)
k=1
j(cid:88)
k=1
Here, 1 ≤ i ≤ m and 1 ≤ j < ni. Dr,k and Di,k are
random variables meeting the log-logistic distribution. Thus,
the hijacking probability with the malicious application ar,c
and the target application ai,j is:
pinter(ar,c, ai,j) = P (
Di,k < 0)
(6)
We now deﬁne a new random variable Zi,j as follows:
c(cid:88)
k=1
Dr,k − j(cid:88)
c(cid:88)
k=1
(−Dr,k)
j(cid:88)
Zi,j =
Di,k +
k=1
k=1
(7)
c−1(cid:89)
k=1
We deﬁne the PDF of Zi,j as ˆfi,j(z). We can calculate ˆfi,j(z)
based on the PDF of each Di,j (i ∈ [1, m] and j ∈ [1, ni]).
Since the probability distribution of the sum of independent
random variables is the convolution of their individual distri-
butions [31], ˆfi,j can be derived as the following expression:
(cid:90) +∞
(cid:124)
−∞
(cid:90) +∞
(cid:125)
−∞