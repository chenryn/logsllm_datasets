### Performance Evaluation and Benchmarking

#### Authenticated Triples Generation
We conducted our initial benchmark by generating SPDZ-style authenticated triples [13] in two locations: Ohio and Northern Virginia. When generating approximately one-third of a million authenticated triples, the Low Gear protocol produced 3,100 authenticated triples per second, with 2.80 kilobytes of data transmitted per triple.

**Optimization for Authenticated Triples:**
To optimize the generation of multiple authenticated triples in parallel, we implemented a wide and low-depth circuit. Our protocol further enhances this process by directly utilizing the additive shares obtained from the outer protocol just before the output reconstruction step, thereby avoiding an additional sharing phase required by the functionality.

**Benchmark Results:**
We ran our benchmark to generate 1 million and 10 million authenticated triples using various block widths listed in Table 2. The computation time and communication per triple are reported in Table 3, with Low Gear as a reference. Our performance is comparable to Low Gear in terms of both computation and communication, and it improves with larger block widths.

| Block Width | Mult/ms | Bytes/Mult |
|-------------|---------|------------|
| 1,317       | 17.32   | 715        |
| 3,065       | 20.07   | 650        |
| 6,749       | 21.93   | 614        |
| 14,332      | 23.11   | 592        |

#### Random "Wide" Circuits
While the above benchmark demonstrates that our protocol can match previous implementations for generating authenticated triples, its strength lies in utilizing our combined IPS protocol instead of relying on the SPDZ online phase. To showcase this, we executed our protocol on synthetic circuits. These random circuits consist of 2 input layers (one per user) with \( \delta \) multiplication gates each, \( r \) multiplication layers, and 1 output layer. Each gate's left and right wires originate from the outputs of two randomly chosen gates from the previous layers.

**Results:**
For \( r = 4096 \) and various block widths, the results are shown in Figures 10 and 11. Our protocol's efficiency improves with block width. For \( w = 61,386 \), the protocol processed 15,700 multiplications per second at 662 bytes per multiplication. Compared to Low Gear, which ignores the costs of the online phase, our protocol is at least 5 times faster and uses 4 times less communication.

#### Comparison with Passively Secure Protocol
We also compared our protocol's execution with a passively secure protocol. Figures 10 and 11 plot the communication and running times for generating passive OLEs required for a GMW-style passive protocol to evaluate the same circuit. We only plot the offline time, noting that the online time is not significant. Our results show that our communication and running times are within 4 times slower than the naive passive protocol.

#### Active OLE Benchmark
Our optimized active OLE protocol, detailed in Section 5.3, was benchmarked, and the results are shown in Table 4. When generating 10 million active OLEs, we achieved the fastest time performance of 23,000 OLEs per second with 592 bytes per OLE, using a block width \( w = 14,332 \). The savings compared to other benchmarks are due to the fact that we consume \( n/w \) passive OLEs per active one, compared to \( 2n/w \) passive OLEs per multiplication in generic circuits.

| Block Width | Mult/ms | Bytes/Mult |
|-------------|---------|------------|
| 1,317       | 17.32   | 715        |
| 3,065       | 20.07   | 650        |
| 6,749       | 21.93   | 614        |
| 14,332      | 23.11   | 592        |

#### Actively Secure Neural-Network Inference
Finally, we benchmarked our system on a simple neural network inference problem using a network trained on the TIMIT speech recognition dataset [22]. The neural network consists of four layers with 3 hidden, fully connected layers, each with \( N \) neurons and quadratic activations. The input is encoded as an \( X \)-component vector, and the output layer is fully connected with \( O \) output neurons, using the softmax activation function. We do not perform the softmax activation via secure computation but delegate it back to the client.

**Experiment Setup:**
We ran an experiment with \( X = 1845 \), \( N = 2000 \), \( O = 183 \), and a block width \( w = 6749 \), resulting in a circuit with about 16.1 million multiplications. The entire computation took approximately 34.6 minutes, with a total communication of 20.7 GB. In comparison, evaluating the same functionality using Low Gear would require 86 minutes and 45.14 GB of communication (this estimate only accounts for offline authenticated triple generation and ignores the efficient Low Gear online phase).

**Overhead Over Passive Protocol:**
The offline part of the passive protocol to compute the neural network would have required 6.2 minutes and 2.88 GB.

### Acknowledgements
We thank Leo de Castro, Chiraag Juvekar, and Vinod Vaikuntanathan for their helpful discussions and for sharing their code of their OLE implementation. We also thank the anonymous CCS reviewers for their valuable comments.

### Funding
- The first author was supported by the European Research Council under the ERC consolidators grant agreement n. 615172 (HIPS), the BIU Center for Research in Applied Cryptography and Cyber Security in conjunction with the Israel National Cyber Bureau in the Prime Ministerâ€™s Office, and ISF grant 1316/18.
- The second author was supported by ERC grant 742754 (project NTSC), ISF grant 1709/14, NSF-BSF grant 2015782, and a grant from the Ministry of Science and Technology, Israel, and the Department of Science and Technology, Government of India.
- The third author was supported by NSF Award CNS-1561209 and AFOSR Award FA9550-18-1-0267.
- The fourth author was supported by a Google Faculty Research Grant and NSF Award CNS-1618884.

### References
[References listed here, formatted as in the original text]

---

This version of the text is more structured, coherent, and professional, making it easier to understand and follow.