hit ratio and average transmission delay.
7138
VOLUME 8, 2020
B. Guo et al.: Dueling DQN-Based Delay-Aware Cache Update Policy for Mobile Users in F-RANs
FIGURE 6. Average hit ratios of different caching policies for varying
storage sizes (M = 5, K = 10, τu = 10).
FIGURE 8. Average hit ratios of different caching policies for varying MU
numbers (M = 5, N = 15, τu = 10).
FIGURE 7. Average transmission delays of different caching policies for
varying storage sizes (M = 5, K = 10, τu = 10).
FIGURE 9. Average transmission delays of different caching policies for
varying MU numbers(M = 5, N = 15, τu = 10).
To evaluated the inﬂuences of storage size in average
hit ratio and average transmission delay, simulations are
performed for varying storage sizes. In the simulations,
the number of F-APs M are set to 5, the number of MUs K
is set to 10, the dwell time of each MU τu is 10 slots, and
the storage size N varies in a range of [5, 25]. The average
hit ratios of different caching policies for varying storage
sizes are shown in Fig. 6. From the ﬁgure, all the average
hit ratios of different caching policies rise, as the increase of
storage size. For each storage size, the average hit ratio of the
proposed caching policy is higher than those of other policies.
Fig. 7 illustrates the average transmission delays of different
caching policies for varying storage sizes. In the ﬁgure, all
the average transmission delays of different caching policies
descend, as the storage size expands. Besides, the average
transmission delay of the proposed caching policy is much
better than those of other policies. This is because the larger
storage can store more requested contents, so that the MUs
can download more cache-hit contents from local cache
directly instead of fetching the cache-miss contents from
remote server.
The inﬂuences of MU number in average hit ratio and
average transmission delay is also conﬁrmed, and the
simulation results are depicted in Fig. 8 and Fig. 9. In the
ﬁgures, the number of F-APs M is 5, the size of storage
in each F-AP N is 15, the dwell time of each MU τu is
10 slots, and the number of MUs K varies from 5 to 25.
From Fig. 8, it can be seen that all the average hit ratios of
different caching policies decrease gradually, as the increase
of MU number. For each K , the average hit ratio of the
proposed caching policy is higher than those of other policies.
From Fig. 9, the average transmission delays of different
caching policies go up, as K increases. Moreover, the average
transmission delay of the proposed caching policy is lower
than those of other policies for different MU numbers. Since
the preferences of different MU are different, the kinds of the
requested contents increases, as the increase of MU number.
Consequently, the number of cache-hit contents decreases,
if the number of MUs increases and the storage size remains
unchanged.
Note that
the same value in Fig. 6∼9. Actually,
the dwell
of different MUs may be different because of
times of different MUs are set
times
their
the dwell
VOLUME 8, 2020
7139
B. Guo et al.: Dueling DQN-Based Delay-Aware Cache Update Policy for Mobile Users in F-RANs
• The proposed caching policy can work well in various
scenarios with different storage sizes, user densities and
mobility patterns. Furthermore, the proposed caching
policy outperforms other traditional caching policies in
different scenarios.
VI. CONCLUSION
In this work, a cache update problem in F-RAN is
investigated, by taking into account diverse user preferences,
random user mobility, time-varying channel fading and coop-
eration between adjacent F-APs. Resorting to the dueling
DQN technique, this paper develops a delay-aware cache
update policy for MUs in F-RAN. In the proposed dueling
DQN based caching policy, the average transmission delay of
MUs is designed as the reward at each iteration step to achieve
the minimum average transmission delay. In order to analyze
performance of the proposed caching policy, simulations are
performed in various scenarios with different storage sizes,
user densities and mobility patterns, compared with three
traditional caching policies, i.e., FIFO, LRU and LFU. The
simulation results show that the proposed caching policy can
not only improve the average hit ratio, but also reduce the
average transmission delay. Although the number of MUs
becomes denser and the movements of MUs are arbitrary
and ruleless, the proposed cache update policy can still show
much more superiority than other caching algorithms.
Although the caching problem studied in this paper is
under F-RANs, the proposed caching policy can still work
in other network scenarios, e.g. mobile edge computing sys-
tems. It is noticed that the transmission bandwidth is allocated
to each user equally in this paper. Obviously, it is not an
efﬁcient way to make use of radio resource because of the
time-varying and diverse user demands. However, a radio
resource efﬁcient cache update policy will be investigated in
future works.
REFERENCES
[1] Cisco, San Jose, CA, USA. (Feb. 2019). Cisco Visual Networking Index:
Forecast and Trends, 2017–2022.
[Online]. Available: https://www.
cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking
-index-vni/white-paper-c11-741490.html
[2] P. Zhang, X. Kang, D. Wu, and R. Wang, ‘‘High-accuracy entity state
prediction method based on deep belief network toward IoT search,’’ IEEE
Wireless Commun. Lett., vol. 8, no. 2, pp. 492–495, Apr. 2019.
[3] D. Wu, Z. Zhang, S. Wu, J. Yang, and R. Wang, ‘‘Biologically inspired
resource allocation for network slices in 5G-enabled Internet of Things,’’
IEEE Internet Things J., vol. 6, no. 6, pp. 9266–9279, Dec. 2019.
[4] Z. Li, Y. Jiang, Y. Gao, L. Sang, and D. Yang, ‘‘On buffer-constrained
throughput of a wireless-powered communication system,’’ IEEE J. Sel.
Areas Commun., vol. 37, no. 2, pp. 283–297, Feb. 2019.
[5] P. Zhang, X. Kang, X. Li, Y. Liu, D. Wu, and R. Wang, ‘‘Overlapping
community deep exploring-based relay selection method toward multi-
hop D2D communication,’’ IEEE Wireless Commun. Lett., vol. 8, no. 5,
pp. 1357–1360, Oct. 2019.
[6] M. Peng, S. Yan, K. Zhang, and C. Wang, ‘‘Fog-computing-based radio
access networks: Issues and challenges,’’ IEEE Netw., vol. 30, no. 4,
pp. 46–53, Jul. 2016.
[7] X. Zhang and Q. Zhu, ‘‘Hierarchical caching for statistical QoS guaran-
teed multimedia transmissions over 5G edge computing mobile wireless
networks,’’ IEEE Wireless Commun., vol. 25, no. 3, pp. 12–20, Jun. 2018.
[8] T. Zhang, X. Xu, L. Zhou, X. Jiang, and J. Loo, ‘‘Cache space efﬁcient
caching scheme for content-centric mobile ad hoc networks,’’ IEEE Syst. J.,
vol. 13, no. 1, pp. 530–541, Mar. 2019.
FIGURE 10. Average hit ratios of different caching policies for varying
storage sizes, and the dwell times of different MUs are
different(M = 5, K = 10).
FIGURE 11. Average transmission delays of different caching policies for
varying storage sizes, and the dwell times of different MUs are different
(M = 5, K = 10).
random behaviors. Accordingly, the dwell times of 10 MUs
are set to {10, 20, 30, 40, 50, 60, 70, 80, 90, 100} slots in
Fig. 10 and Fig. 11 to simulate the unpredictable user mobil-
ity. Besides, the number of F-APs M are set to 5, the number
of MUs K is set to 10. As the storage size increases, the aver-
age hit ratios raise, while the average transmission delays
drop. Since each MU moves randomly, the stored contents
may not be requested at next slot. Although the movements
of MUs are arbitrary and ruleless, the dueling DQN can
still work well. Furthermore, the proposed caching policy
provides superior average hit ratio and average transmission
delay, compared to other traditional policies.
From the simulation results, the following conclusions can
be summarized.
• As the increase of the storage size, the average hit
ratios of caching policies ascent, while the average
transmission delays of caching policies descent.
• As the number of MU raises, the average hit ratios of
caching policies fall, whilst the average transmission
delays of caching policies go up.
7140
VOLUME 8, 2020
B. Guo et al.: Dueling DQN-Based Delay-Aware Cache Update Policy for Mobile Users in F-RANs
[9] C. Li, L. Toni, J. Zou, H. Xiong, and P. Frossard, ‘‘QoE-driven mobile edge
caching placement for adaptive video streaming,’’ IEEE Trans. Multime-
dia, vol. 20, no. 4, pp. 965–984, Apr. 2018.
[10] P. Yang, N. Zhang, S. Zhang, L. Yu, J. Zhang, and X. Shen, ‘‘Content
popularity prediction towards location-aware mobile edge caching,’’ IEEE
Trans. Multimedia, vol. 21, no. 4, pp. 915–929, Apr. 2019.
[11] Y. M. Saputra, D. T. Hoang, D. N. Nguyen, E. Dutkiewicz, D. Niyato, and
D. I. Kim, ‘‘Distributed deep learning at the edge: A novel proactive and
cooperative caching framework for mobile edge networks,’’ IEEE Wireless
Commun. Lett., vol. 8, no. 4, pp. 1220–1223, Aug. 2019.
[12] Y. Jiang, M. Ma, M. Bennis, F.-C. Zheng, and X. You, ‘‘User preference
learning-based edge caching for fog radio access network,’’ IEEE Trans.
Commun., vol. 67, no. 2, pp. 1268–1283, Feb. 2019.
[13] B. Chen and C. Yang, ‘‘Caching policy for cache-enabled D2D commu-
nications by learning user preference,’’ IEEE Trans. Commun., vol. 66,
no. 12, pp. 6586–6601, Dec. 2018.
[14] P. Cheng, C. Ma, M. Ding, Y. Hu, Z. Lin, Y. Li, and B. Vucetic, ‘‘Localized
small cell caching: A machine learning approach based on rating data,’’
IEEE Trans. Commun., vol. 67, no. 2, pp. 1663–1676, Feb. 2019.
[15] C. Zhong, M. C. Gursoy, and S. Velipasalar, ‘‘A deep reinforcement
learning-based framework for content caching,’’ in Proc. 52nd Annu. Conf.
Inf. Sci. Syst. (CISS), Mar. 2018, pp. 1–6.
[16] W. Jiang, G. Feng, S. Qin, T. S. P. Yum, and G. Cao, ‘‘Multi-agent rein-
forcement learning for efﬁcient content caching in mobile D2D networks,’’
IEEE Trans. Wireless Commun., vol. 18, no. 3, pp. 1610–1622, Mar. 2019.
[17] A. Sadeghi, F. Sheikholeslami, and G. B. Giannakis, ‘‘Optimal and scalable
caching for 5G using reinforcement learning of space-time popularities,’’
IEEE J. Sel. Top. Signal Process., vol. 12, no. 1, pp. 180–190, Feb. 2018.
[18] K. Zhang, S. Leng, Y. He, S. Maharjan, and Y. Zhang, ‘‘Cooperative
content caching in 5G networks with mobile edge computing,’’ IEEE
Wireless Commun., vol. 25, no. 3, pp. 80–87, Jun. 2018.
[19] P. Lin, K. S. Khan, Q. Song, and A. Jamalipour, ‘‘Caching in heterogeneous
ultradense 5G networks: A comprehensive cooperation approach,’’ IEEE
Veh. Technol. Mag., vol. 14, no. 2, pp. 22–32, Jun. 2019.
[20] Y. Zhou, Z. Zhao, R. Li, H. Zhang, and Y. Louet, ‘‘Cooperation-based prob-
abilistic caching strategy in clustered cellular networks,’’ IEEE Commun.
Lett., vol. 21, no. 9, pp. 2029–2032, Sep. 2017.
[21] D. Wu, L. Zhou, Y. Cai, and Y. Qian, ‘‘Collaborative caching and match-
ing for D2D content sharing,’’ IEEE Wireless Commun., vol. 25, no. 3,
pp. 43–49, Jun. 2018.
[22] D. Wu, Q. Liu, H. Wang, Q. Yang, and R. Wang, ‘‘Cache less for more:
Exploiting cooperative video caching and delivery in D2D communica-
tions,’’ IEEE Trans. Multimedia, vol. 21, no. 7, pp. 1788–1798, Jul. 2019.
[23] B. Guo, X. Zhang, Y. Wang, and H. Yang, ‘‘Deep-Q-network-based mul-
timedia multi-service QoS optimization for mobile edge computing sys-
tems,’’ IEEE Access, vol. 7, pp. 160961–160972, 2019.
[24] D. Wu, H. Shi, H. Wang, R. Wang, and H. Fang, ‘‘A feature-based learning
system for Internet of Things applications,’’ IEEE Internet Things J., vol. 6,
no. 2, pp. 1928–1937, Apr. 2019.
[25] Z. Wang, T. Schaul, M. Hessel, H. Van Hasselt, M. Lanctot, and
N. De Freitas, ‘‘Dueling network architectures for deep reinforcement
learning,’’ 2015, arXiv:1511.06581. [Online]. Available: https://arxiv.
org/abs/1511.06581
[26] Y. Li, C. Zhong, M. C. Gursoy, and S. Velipasalar, ‘‘Learning-based delay-
aware caching in wireless D2D caching networks,’’ IEEE Access, vol. 6,
pp. 77250–77264, 2018.
[27] Z. Zhang and L. Wang, ‘‘Social tie-driven content priority scheme for D2D
communications,’’ Inf. Sci., vol. 480, pp. 160–173, Apr. 2019.
[28] T. Dang and M. Peng, ‘‘Joint radio communication, caching, and comput-
ing design for mobile virtual reality delivery in fog radio access networks,’’
IEEE J. Sel. Areas Commun., vol. 37, no. 7, pp. 1594–1607, Jul. 2019.
[29] Z. Li, J. Chen, and Z. Zhang, ‘‘Socially aware caching in D2D enabled fog
radio access networks,’’ IEEE Access, vol. 7, pp. 84293–84303, 2019.
[30] Z. Zheng, L. Song, Z. Han, G. Y. Li, and H. V. Poor, ‘‘A Stackelberg game
approach to proactive caching in large-scale mobile edge networks,’’ IEEE
Trans. Wireless Commun., vol. 17, no. 8, pp. 5198–5211, Aug. 2018.
[31] J. Jiao, X. Hong, and J. Shi, ‘‘Proactive content delivery for vehicles over
cellular networks: The fundamental beneﬁts of computing and caching,’’
China Commun., vol. 15, no. 7, pp. 88–97, Jul. 2018.
[32] X. Zhang, T. Lv, Y. Ren, W. Ni, N. C. Beaulieu, and Y. J. Guo, ‘‘Economical
caching for scalable videos in cache-enabled heterogeneous networks,’’
IEEE J. Sel. Areas Commun., vol. 37, no. 7, pp. 1608–1621, Jul. 2019.
[33] O. Ayoub, F. Musumeci, M. Tornatore, and A. Pattavina, ‘‘Energy-efﬁcient
video-on-demand content caching and distribution in metro area net-
works,’’ IEEE J. Sel. Areas Commun., vol. 3, no. 1, pp. 159–169, Mar. 2019.
[34] S. O. Somuyiwa, A. Gyorgy, and D. Gunduz, ‘‘A reinforcement-learning
approach to proactive caching in wireless networks,’’ IEEE J. Sel. Areas
Commun., vol. 36, no. 6, pp. 1331–1344, Jun. 2018.
[35] L. Hou, L. Lei, K. Zheng, and X. Wang, ‘‘A Q-learning-based proactive
caching strategy for non-safety related services in vehicular networks,’’
IEEE Internet Things J., vol. 6, no. 3, pp. 4512–4520, Jun. 2019.
[36] Z. Zhang, Y. Yang, M. Hua, C. Li, Y. Huang, and L. Yang, ‘‘Proac-
tive caching for vehicular multi-view 3D video streaming via deep rein-
forcement learning,’’ IEEE Trans. Wireless Commun., vol. 18, no. 5,
pp. 2693–2706, May 2019.
[37] L. Breslau, P. Cao, L. Fan, G. Phillips, and S. Shenker, ‘‘Web caching
and Zipf-like distributions: Evidence and implications,’’ in Proc. IEEE
INFOCOM, vol. 1, Mar. 1999, pp. 126–134.
[38] R. Bellman, ‘‘A Markovian decision process,’’ Indiana Univ. Math. J.,
vol. 6, no. 4, pp. 679–684, 1957.
[39] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu,
J. Veness,
M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski,
S. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran,
D. Wierstra, S. Legg, and D. Hassabis, ‘‘Human-level control through
deep reinforcement learning,’’ Nature, vol. 518, no. 7540, pp. 529–533,
Feb. 2015.
BOREN GUO received the B.Eng. degree in
electronic information engineering from the Bei-
jing University of Posts and Telecommunications
(BUPT), in 2015, where he is currently pursuing
the Ph.D. degree with the Wireless Theories and
Technologies Laboratory. His research interests
include C-RAN, F-RAN, MEC, deep reinforce-
ment learning, and other 5G NR techniques.
XIN ZHANG received the B.Eng. degree in com-
munications engineering, the M.Eng. degree in
signal and information processing, and the Ph.D.
degree in communications and information sys-
tems from the Beijing University of Posts and
Telecommunications (BUPT), in 1997, 2000, and
2003, respectively. He joined BUPT, in 2003, cur-
rently working with the Wireless Theories and
Technologies Laboratory as an Associate Profes-
sor, and focuses the research mainly on key tech-
nologies and performance analysis of air interface of wireless networks.
QIWEI SHENG received the B.Eng. degree in
communication engineering from the Beijing Uni-
versity of Posts and Telecommunications, in 2018,
where he is currently pursuing the M.Eng. degree.
His research interests include deep reinforce-
ment
learning, C-RAN, MEC, and other 5G
technologies.
HONGWEN YANG received the B.S. and M.S.
degrees from the Beijing University of Posts and
Telecommunications (BUPT), in 1984 and 1987,
respectively. After graduating, he joined the Fac-
ulty of BUPT, where he is currently a Professor.
His research mainly focuses on wireless physical
layer, including modulation and coding, MIMO,
and OFDM.
VOLUME 8, 2020
7141