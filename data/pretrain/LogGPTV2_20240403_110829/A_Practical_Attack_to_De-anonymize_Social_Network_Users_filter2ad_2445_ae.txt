results are a valid, yet rough estimation of how the de-
anonymization attack would perform against random users
on the Internet.
thus,
Of the 9,969 participants, we found at least one group
hit for 3,717 users and of these, we were able to correctly
de-anonymize 1,207 individuals. This corresponds to 12.1%
of the overall participants, and to 37.3% of the users who
had at least one Xing-speciﬁc link in their browsing history,
and therefore are likely to be members of Xing. While this is
lower than the percentage that we achieved in our controlled
experiment, we think that this still shows the real-world
feasibility of the attack.
C. Run-Time and Throughput Rate
The runtime of the attack signiﬁcantly inﬂuences its suc-
cess rate in practice. Recall that we perform an active attack,
and probe the victim’s browsing history. Thus, the victim
needs to interact with the attacker for a certain amount of
time. There are many techniques to convince a victim to stay
longer at the attacker’s website. These techniques range from
benign attempts such as showing a video or music clip, to
offensive techniques such as “hijacking” the user’s browser
with the help of JavaScript to prevent her from leaving the
site. In any case, from the point of view of the attacker, it
is desirable that the attack takes as little time as possible.
We measured the typical time it takes to perform a history
stealing attack in practice. We performed experiments with
010203040506070Time in seconds020000400006000080000100000Number of tested pagesSafari 4 MacSafari 4ChromeFF 3.5FF 3.5 MacFF 3.5 LinuxIE 8A. Server-side Mitigation
As a server-side mitigation, web applications could use
dynamic hyperlinks that an attacker cannot easily predict.
For example, existing systems could be hardened against the
history stealing attack by automatically adding HTTP GET
parameters that contain random tokens to all hyperlinks.
Depending on the utilized web server, it might be possible
to retroﬁt existing web applications by using URL rewriting
to automatically add such tokens to each URL. Even adding
a simple, alphanumerical string of length 2 would increase
the attacker’s search space by a factor of 3844 (622). Hence,
the attack would effectively be prevented.
Also, web applications should preferably use HTTP POST
instead of HTTP GET in order to send parameters. This is
because only GET parameters are stored in the browsing
history. In fact, a server-side mitigation solution that random-
izes web-application links is presented in existing work [22].
Note that one difﬁculty with server-side mitigation is that
the usability of the web applications may be affected. For
example, it may become more difﬁcult to bookmark parts of
the application, or links to certain groups may become more
difﬁcult to remember. Furthermore, server-side mitigation is
also only effective if all (or at least many) social networks
implement it: if a user is a member of several social networks
and only some of them implement the mitigation strategy,
the user is still subject to the attack based on the information
collected on the social network that did not
implement
countermeasures. Thus, a social network might not have an
incentive to deploy a countermeasure unless all other social
networks also participate.
B. Client-side Mitigation
On the client-side, history stealing is more difﬁcult to
the goal
ﬁx without sacriﬁcing functionality. Obviously,
is to prevent browsers from leaking sensitive and private
information via style information. As a solution, browsers
could generally restrict client-side scripts from accessing the
CSS properties of hyperlinks. Unfortunately, this could also
break existing websites that legitimately do so.
Jackson et al. offer a clever solution by extending the
same-origin concept of web browsers to visited links [8].
Unfortunately, so far, none of the published countermeasures
to history snifﬁng have experienced wide-spread adoption,
whether on the server, nor on the client-side.
Current web browsers only provide limited options for
protection against attacks that are based on history stealing.
Because the attack can be implemented without the need
for client-side scripting,
turning off JavaScript, or using
browser add-ons that protect against script-based attacks (for
example, NoScript [23]) may only provide limited help. A
mitigation option could be to throttle the rate at which style
properties can be accessed (and limit the total number of
checks that can be performed on a single page), but we did
not explore this option in depth.
Figure 8: Degradation of group data in Xing.
an attacker has to invest for a de-anonymization attack. An
attacker can also develop iterative approaches for keeping
the collected information up-to-date, e.g. social networking
features that explicitly allow the listing of only new members
in groups and newly created groups can be used.
For measuring the ﬂuctuation in groups, we conducted
experiments for Xing. Instead of repeatedly crawling the
entire network, we only downloaded the group directory and
the member size for each group. This permitted us to repeat
this operation every four hours over a period of 18 days.
Figure 8 shows the CDF for the changes in group size for
four different periods. Interestingly, while the results from
our measurements conﬁrm that the quality of the collected
group and member data degrades over time, they also show
that the data stays relatively stable, signiﬁcantly reducing
the necessary crawling effort for an attacker.
While we are aware of the possibility that the amount
of users that either join or leave a group might lead to the
same overall group size, we believe that the result of our
experiment is still accurate enough to give an indication
of the amount of change that affects the Xing’s group
conﬁgurations.
VI. POSSIBLE MITIGATION TECHNIQUES
The approach presented in this work allow a malicious
user to launch de-anonymization attacks against a large num-
ber of victims with relatively little effort. Whereas history
stealing by itself is often not enough to identify individual
users, combined with the misuse of group membership
information stored in social networks, it becomes a critical
weakness. In this section, we list mitigation techniques that
aim to thwart our attack.
0%10%20%30%40%50%Change in group size0%20%40%60%80%100%1 day6 days12 days18 daysUsers can also permanently, or at least temporarily, disable
the browsing history. Furthermore, they can, for example,
use the “private browsing modes” that are supported by sev-
eral current browsers (e.g., Firefox, Safari). Unfortunately,
all of these methods also require some effort on behalf of
the user, and reduce the usability of web browsers and web
applications.
C. Responsible Disclosure
We notiﬁed the affected social networks about our attack
and discussed possible mitigation strategies with them. Since
client-side mitigation was out of scope for them, we focused
on server-side mitigation as discussed above.
Within four days after our notiﬁcation, Xing had added
a random number to all the relevant links on the platform
(i.e., links containing group information) [24]. The random
number takes the current date and a user-speciﬁc number
into account, thus it also changes every 24 hours. As a result,
the de-anonymization attack presented in this paper is not
effective against Xing anymore. At the time of this writing,
Facebook and LinkedIn are still investigating how this attack
can be mitigated best.
VII. RELATED WORK
Clearly, de-anonymization of privacy-sensitive data is not
a new concept. Research initially focused on anonymization
and de-anonymization of network level data. For example,
work by Pang et al. [25] presents techniques for anonymizing
network packet traces with the intent of sharing data be-
tween researchers. As a reaction to anonymization research,
Coulls et al. [26] introduced approaches that allow an at-
tacker to de-anonymize network traces, and recover sensitive
data on network topologies.
Information Leakage and Social Networks: Due to the
popularity of social networks and the large amounts of sensi-
tive data they store, the focus of de-anonymization research
has recently extended to this area. Several publications have
shown that seemingly non-sensitive data from publicly avail-
able sources can be used to recover private information about
individuals. For example, Grifﬁth and Jakobsson [10] use
public records to infer individuals’ mothers’ maiden names,
and Heatherly et al. [27], as well as Zheleva and Getoor [6],
show how public data provided by social networks can be
used to infer private information.
In addition, several publications have analyzed and mea-
sured features of social networks that are privacy-related.
For example, Mislove et al. present a measurement study on
social networks [28] while Bonneau and Preibusch evaluate
the privacy settings and policies of a large number of social
networks [29]. Closely related to this context, several recent
papers focus on scenarios for malicious activity directed
against social networks. For example, Jagatic et al. evaluate
the success rates of phishing attacks [15], and Brown et al.
discuss context-aware spam [30]. Another study [31] by
Bilge et al. shows the feasibility of automated identity theft
attacks in social networks.
Our attack is passive, i.e., a user needs to visit a website
which then perform the attack. Ur and Ganapathy [32]
explored active attacks (e.g., injecting images into popular
MySpace proﬁles) and showed that such attacks can signif-
icantly increase the success rate. In the future, we might
study such attacks, but ethical and legal considerations need
to be taken into account.
Attacks on Browsing Privacy: The de-anonymization
scenario presented in this work leverages a browsing history
stealing technique that is based on CSS and has been known
since the year 2000. This technique has been discussed in
several browser bug reports [12]–[14], and has been shown
to be practical for targeted phishing attacks by Jakobsson and
Stamm [9]. Despite its malicious potential, browser history
stealing has not lead to any changes in browser software.
There are also other techniques that aim at exposing
private browsing information. Several systems use timing
properties to recover private information. For example, Fel-
ten and Schneider show an attack on web browsing history
by analyzing caching operations [33], while Bortz and
Boneh [34] use timing attacks to recover private information
from web applications.
De-Anonymization of Social Networks: Narayanan and
Shmatikov have shown that statistical methods can be
applied to de-anonymize micro-data by cross-correlating
multiple datasets [11]. They extend their approach to so-
cial networks in [5], and prove that it is possible to de-
anonymize members by mapping known, auxiliary informa-
tion on the (social) network topology. Diaz et al. present
a de-anonymization approach that uses information gained
from observing communication patterns between social net-
work members [35]. Backstrom et al. showed how to de-
anonymize a single social network [3].
In contrast to existing work, our attack uses only infor-
mation from a single social networking site, and combines it
with the browsing history of a user to identify individuals.
This enables us to learn the actual identity of the visitor
of a website. Furthermore, our attack is highly practical,
and works effectively in the real-world. In fact, as we
demonstrate in the paper, the attack has the potential to affect
the privacy of millions of registered social network users.
VIII. CONCLUSION
In this paper, we introduce a novel, practical de-
anonymization attack that makes use of the group infor-
mation in social networking sites. Using empirical, real-
world experiments, we show that the group membership of
a user in a social network (i.e., the groups within a social
network in which a user is a member), may reveal enough
information about an individual user to identify her when
visiting web pages from third parties.
The implications of the attack we present are manifold.
The attack requires a low effort, and has the potential to
affect millions of registered social networking users who
have group memberships. The theoretical analysis and em-
pirical measurements we present demonstrate the feasibility
of the attack on the Xing, Facebook, and LinkedIn social
networks. Furthermore, our investigations suggest that many
more social networks that support group memberships can
potentially be misused for similar attacks.
Acknowledgments: This work has been supported by
the Austrian Research Promotion Agency under grant
820854,
the Austrian Science Foundation under grant
P18764-N04, and by the European Commission through
project FP7-ICT-216026-WOMBAT. We also thank our
shepherd Vitaly Shmatikov and the anonymous reviewers
for their valuable insights and comments.
REFERENCES
[1] Alexa, “Top 500 Global Sites,” http://www.alexa.com/
topsites, 2009.
[2] “Facebook,” http://www.facebook.com, 2009.
[3] L. Backstrom, C. Dwork, and J. Kleinberg, “Wherefore
Art Thou R3579X?: Anonymized Social Networks, Hidden
Patterns, and Structural Steganography,” in 16th Conference
on World Wide Web (WWW’07), 2007.
[4] M. Chew, D. Balfanz, and B. Laurie, “(Under)mining Privacy
in Social Networks,” in Proceedings of Web 2.0 Security and
Privacy Workshop (W2SP), 2008.
[5] A. Narayanan and V. Shmatikov, “De-anonymizing social
networks,” in IEEE Symposium on Security and Privacy,
2009.
[6] E. Zheleva and L. Getoor, “To Join or Not To Join: The
Illusion of Privacy in Social Networks with Mixed Public
and Private User Proﬁles,” in 18th International Conference
on World Wide Web (WWW), 2009.
[7] EFF, “Panopticlick: How Unique – and Trackable – is Your
Browser?” http://panopticlick.eff.org/, 2010.
[8] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell, “Pro-
tecting Browser State From Web Privacy Attacks,” in 15th
International Conference on World Wide Web (WWW), 2006.
[9] M. Jakobsson and S. Stamm, “Invasive Browser Snifﬁng and
Countermeasures,” in 15th International World Wide Web
Conference, 2006.
[10] V. Grifﬁth and M. Jakobsson, “Messin’ with Texas, Deriving
Mother’s Maiden Names using Public Records,” in Third
Conference on Applied Cryptography and Network Security
(ACNS), June 2005.
[11] A. Narayanan and V. Shmatikov, “Robust De-anonymization
of Large Sparse Datasets,” in IEEE Symposium on Security
and Privacy, 2008.
[12] J. Ruderman, “CSS on a:visited can load an image and/or
reveal if visitor been to a site,” https://bugzilla.mozilla.org/
show bug.cgi?id=57351, 2000.
[13] D. Baron, “:visited support allows queries into global history,”
https://bugzilla.mozilla.org/show bug.cgi?id=147777, 2002.
[14] Z. Braniecki, “CSS allows to check history via :visited,” https:
//bugzilla.mozilla.org/show bug.cgi?id=224954, 2003.
[15] T. N. Jagatic, N. A. Johnson, M. Jakobsson, and F. Menczer,
“Social phishing,” Commun. ACM, vol. 50, no. 10, pp. 94–
100, 2007.
[16] R. Dingledine, N. Mathewson, and P. F. Syverson, “Tor:
The Second-Generation Onion Router,” in USENIX Security
Symposium, 2004.
[17] U.S. Census Bureau, “Frequently Occurring Names and Sur-
names,” http://www.census.gov/genealogy/www, 2009.
[18] M. Jakobsson, P. Finn, and N. Johnson, “Why and How
to Perform Fraud Experiments,” Security & Privacy, IEEE,
vol. 6, no. 2, pp. 66–68, March-April 2008.
[19] M. Jakobsson and J. Ratkiewicz, “Designing ethical phishing
experiments: a study of (ROT13) rOnl query features,” in 15th
International Conference on World Wide Web (WWW), 2006.
[20] “LinkedIn,” http://www.linkedin.com, 2009.
[21] Computational Crawling LP, “80legs,” http://www.80legs.
com, 2009.
[22] M. Jakobsson and S. Stamm, “Web Camouﬂage: Protecting
Your Clients from Browser-Snifﬁng Attacks,” IEEE Security
and Privacy, vol. 5, no. 6, 2007.
[23] G. Maone, “NoScript,” https://addons.mozilla.org/de/ﬁrefox/
addon/722, 2009.
[24] J. Mainusch, “De-De-Anonymizing in Four Days,” http:
//blog.xing.com/2010/02/de-de-anonymizing-in-four-days/,
2010.
[25] R. Pang, M. Allman, V. Paxson, and J. Lee, “The Devil and
Packet Trace Anonymization,” SIGCOMM Comput. Commun.
Rev., vol. 36, no. 1, 2006.
[26] S. Coulls, C. Wright, F. Monrose, M. Collins, and M. Reiter,
“Playing Devil’s Advocate: Inferring Sensitive Information
from Anonymized Traces,” in Symposium on Network and
Distributed Systems Security (NDSS), 2007.
[27] R. Heatherly, M. Kantarcioglu, and B. Thuraisingham, “Pre-
venting Private Information Inference Attacks on Social Net-
works,” University of Texas at Dallas, Tech. Rep. UTDCS-
03-09, 2009.
[28] A. Mislove, M. Marcon, K. P. Gummadi, P. Druschel, and
B. Bhattacharjee, “Measurement and Analysis of Online So-
cial Networks,” in 7th ACM SIGCOMM Internet Measurement
Conference (IMC), 2007.
[29] J. Bonneau and S. Preibusch, “The Privacy Jungle: On the
Market for Privacy in Social Networks,” in Eighth Workshop
on the Economics of Information Security (WEIS), 2009.
[30] G. Brown, T. Howe, M. Ihbe, A. Prakash, and K. Bor-
ders, “Social networks and context-aware spam,” in ACM
2008 Conference on Computer Supported Cooperative Work
(CSCW), 2008.
[31] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda, “All Your
Contacts Are Belong to Us: Automated Identity Theft Attacks
on Social Networks,” in 18th International Conference on
World Wide Web (WWW), 2009.
[32] B. E. Ur and V. Ganapathy, “Evaluating Attack Ampliﬁcation
in Online Social Networks,” in Web 2.0 Securit and Privacy,
2009.
[33] E. W. Felten and M. A. Schneider, “Timing Attacks on
Web Privacy,” in 7th ACM Conference on Computer and
Communications Security (CCS), 2000.
[34] A. Bortz and D. Boneh, “Exposing Private Information by
Timing Web Applications,” in 16th International Conference
on World Wide Web (WWW), 2007.
[35] C. Diaz, C. Troncoso, and A. Serjantov, “On the Impact
of Social Network Proﬁling on Anonymity,” in 8th In-
ternational Symposium on Privacy Enhancing Technologies
(PETS), 2008.