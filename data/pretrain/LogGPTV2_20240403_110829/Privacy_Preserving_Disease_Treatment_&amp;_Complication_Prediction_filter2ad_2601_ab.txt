ized treatments, and predict disease complications for
their patients. However, since each hospital may only
have limited number of patients associated with a par-
ticular disease, the prediction models may not always
be comprehensive and accurate. Thus, in order to ob-
tain more accurate prediction, the hospital servers may
send relevant information extracted from their trained
model securely to the public cloud so that the pub-
lic cloud can perform data mining operations on the
aggregated data received to generate a more accurate
prediction model for all participating hospitals to use.
• Semi-trusted public cloud: The public cloud stores the
relevant encrypted information sent from each partici-
pating hospital, and performs data mining operations
to generate predictive models. It also constructs a key-
word based encrypted index tree which allows autho-
rized clients to conduct searches based on their indi-
vidual proﬁles, lab tests for potential disease diagnosis,
treatment options, and risk analysis of potential com-
plications related to their current illnesses.
• Fully-trusted authority (TA): TA is responsible for gen-
erating and distributing the symmetric encryption keys
to authorized clients and all participating hospitals. It
is also responsible for sending relevant disease cate-
gorization information, e.g., which disease belongs to
which top-level category nodes, to the hospitals and
the public cloud.
• Clients: Clients refer to those who wish to conduct
searches for disease diagnosis, personalized treatments,
and assessing their risks of disease complications caused
by their current illnesses.
At the initial phase, TA generates the encryption keys and
sends them to all participating hospitals and their autho-
rized clients. Upon receiving the keys, each hospital server
ﬁrst encrypts its data and performs data mining operations
to generate locally trained models. Each hospital server then
sends the relevant information from the locally trained mod-
els securely to the public cloud. The public cloud will then
generate aggregated trained models for disease diagnosis,
possible treatment models for diﬀerent groups of patients
based on their proﬁles and medical histories, and prediction
models of any potential disease complications. In addition,
the public cloud will generate an encrypted index tree which
allows clients to search for information more eﬃciently. De-
tails of what the encrypted index tree contains will be de-
scribed in Section 4.
When a client wishes to query the public cloud for health
related predictions, the client ﬁrst uses the received keys
from the TA to generate a search request and then sends
it to the public cloud. After receiving the encrypted query,
the public cloud server will perform the search over the en-
crypted index tree and send back all the relevant answers to
the authorized client.
3.2 Adversarial Model
We assume that the trusted authority can be trusted fully
and it will not be compromised. As for all participating
hospitals, we assume that they are semi-trusted, i.e., they
will honestly follow the designated protocols but always cu-
rious to gain additional insights from the information sent
by other hospitals. They may also collude with the cloud
server to ﬁnd such information.
Similarly, we also adopt a “honest-but-curious” model for
the public cloud server as in [30, 29]. Like the hospitals, it
will execute the designated protocols honestly but will be
843• Extensibility: Our system should be designed such
that the encrypted index tree as well as trained data
models can be updated easily without complete re-
design.
3.4 Important Building Blocks
Before we present the detailed description of our newly
designed scheme, we ﬁrst discuss some of the security tools
we use in this work, and deﬁne a few terminologies.
1. Organization of Information Regarding Various Dis-
eases: Patients may suﬀer from diﬀerent types of diseases.
To make it easier for P DT CP S we design to answer users’
questions regarding diagnosis, treatment options, or poten-
tial disease complications, we decide to categorize patients’
illnesses similar to how a popular healthcare forum website
called patientslikeme organizes diﬀerent types of diseases.
Diseases are categorized based on how they aﬀect human
body parts (refer to Fig 2), e.g., Endocrine includes all dis-
eases which aﬀect the endocrine system such as diabetes,
hypothyroidism, hyperthyroidism, etc.
For each disease, our system keeps several pieces of im-
portant information, namely (i) a trained model for disease
diagnosis based on results of laboratory tests, symptoms,
(ii)various treatment options based on patients’ proﬁles, and
(iii) a trained model for complication prediction based on pa-
tients’ proﬁles, laboratory tests, and medical histories, e.g.,
other diseases a patient may have.
Figure 2: Healthcare Searchable Tree
2. Order-preserving Encryption: Order-preserving sym-
metric encryption (OP E) is a deterministic encryption scheme
which preserves numerical ordering of the plaintexts. It al-
lows order relations between data items to be established
based on their encrypted values, without revealing the data
itself. For example if x ≤ y, then OP EK (x) ≤ OP EK (y),
for any secret key K. Thus, with the help of OP E encryp-
tion, the server can perform data mining operations over the
encrypted data.
3. Parallel SV M method: Support Vector Machines (SVMs)
are powerful classiﬁcation and regression tools, but their
computational costs increase rapidly with the size of train-
ing instances. Eﬃcient parallel algorithms for constructing
SV M models are critical to ensure that SV M can be used
for large scale data mining analysis.
The parallel SV M method [31] we use is based on the
cascade SV M model where a partial SV M model is con-
structed for each partition of a large dataset. Then, the
partial SV M s are aggregated iteratively as shown in Fig
3. The sets of support vectors from two SV M s are merged
into one set and used to create a new SV M . Such a pro-
cess is repeated until only one set of support vectors remain.
This parallel SV M approach allows large scale optimization
Figure 1: System Model for PDTCPS
curious to infer any extra information it can derive from the
information sent by all participating hospitals and from the
queries/responses issued/received by the authorized clients.
Depending on the available information to the cloud server,
the following two threat models are considered in this work:
• Known Ciphertext Model: The encrypted data, the
secure index, encrypted queries and responses are all
available to the cloud server.
• Known Background Model: In addition to the avail-
able information assumed in the former model, the
cloud server can also use statistical information to de-
duce speciﬁc contents in a query. It can even collude
with other attackers to derive additional information
from the encrypted data.
In addition, we assume users are trusted entities. They
obtain authorized keys from the TA.
3.3 Design Goals
To address the security and threat models we have pre-
sented earlier, we design a P DT CP S scheme, which allows
authorized users to conduct privacy-aware searches for dis-
ease diagnosis, personalized treatment and prediction of po-
tential complications based on their individual proﬁles, lab-
oratory test results, and potential medical histories. Our
system is designed with the following goals in mind:
• Fuzzy keyword search: During query generation, an
authorized client may make typos while inputting query
contents. For example, a client may type “dibetes”
instead of “diabetes” in the following query: “(dis-
ease=“dibetes”)”. Our scheme should support such
fuzzy query and still return relevant information.
• Search Eﬃciency and Accuracy: The scheme should
achieve high search accuracy, i.e., it should return mostly
correct answers to search queries. It should also achieve
high search eﬃciency, i.e., the average search time per
query is small.
• Privacy Guarantee: Our system should provide pri-
vacy guarantees by not leaking sensitive information
about stored data or encrypted indices. Our system
should provide query privacy and unlinkability. The
cloud server should not be able to deduce sensitive
contents that have been used for search. Submitted
queries should look diﬀerent each time even if the same
keyword and lab results are submitted. Furthermore,
the search and access patterns should be hidden from
the public cloud server. In other words, the encrypted
index structure should be designed such that the server
traverses diﬀerent nodes on the index tree even for the
same search request.
844problems to be divided into smaller independent optimiza-
tions.
Figure 3: Training process of parallel SVM
4. Parallel Decision Tree method: Decision trees are sim-
ple yet eﬀective classiﬁcation algorithms, but one needs to
sort all numerical attributes in order to decide where to split
a node within a decision tree, which costs much computation
time when a large data set is involved. Thus, it is important
to develop parallel version of decision tree algorithms which
can be eﬃcient and scalable.
The decision tree method we use is a parallel histogram-
based decision tree algorithm for classiﬁcation [8] where the
master node builds the regression trees layer by layer as
shown in Fig 4. At each iteration, a new layer is constructed
as follows: each node compresses its share of the data using
histograms and sends them to the master node. The master
node merges the histograms and uses them to approximate
the best splits for each leaf node, thereby constructing a new
layer. Then, the master node sends this new layer to each
participating node, and those nodes construct histograms
for this new layer. Therefore, every iteration consists of an
updating phase performed simultaneously by all the partici-
pating nodes and a merging phase performed by the master
node. The communication cost for this method consists of
all the histograms sent by the participating nodes to the
master and the master sending information of a new layer
of the tree to those nodes.
4. PDTCPS SCHEME
As discussed earlier, PDTCPS provides a secure way for
clients to diagnose their diseases, predict complications and
search for possible treatment options for their illnesses. One
important component of our PDTCPS system is the en-
crypted index tree that the public cloud constructs based
on instructions given by the TA. Before we describe our
scheme, we ﬁrst give the deﬁnitions of various notations we
use.
Notations:
• KO - the symmetric key for OP E encryption.
Figure 4: Training process of parallel Decision Tree
• KB - the Bloom ﬁlter generation key.
• KA - the key used to generate key hash values for key-
• CW - the category keywords set, denoted as CW ={cw1,
• W - the disease keywords set, denoted as W ={w1, w2,
words, i.e. Enc(w) = KeyHash(KA, w).
cw2, ··· , cw|CW|}.
··· , w|W|}.
• (cid:102)Wi - a subset of W , indicating the disease keywords
in the ith category, denoted as (cid:102)Wi={ai1, ai2, ··· , ai|(cid:103)Wi|},
• (cid:101)S - a set, indicating the number of children that under
each category node, denoted as (cid:101)S = {|C1|,|C2|,··· |C|(cid:101)S||}.
• (cid:101)sv - a set, indicating the training features of a disease.
• k - the number of diseases stored in every 2nd level node.
• bf (wi) - a Bloom ﬁlter, containing the keyword wi and
• cwq - the category keyword for the query.
• F - the lab test results set, denoted as F = {F1, F2,···}.
• h - the number of hash functions used in generating the
where aij ∈ W .
its associated fuzzy keywords.
Bloom ﬁlter.
4.1 Overview
Fig 5 is an overview of PDTCPS which shows the informa-
tion provided by the TA, hospitals, and queries submitted
by authorized clients.
Figure 5: Overview of PDTCPS
During the encrypted index tree construction phase, the
TA sends the public cloud some information to help the
public cloud build the encrypted index tree. Speciﬁcally, TA
sends the public cloud a set of encrypted category keywords,
which will form the 1st level nodes.
In addition, the TA
sends a Bloom ﬁlter for each 1st level node which contains
keywords of all the illnesses listed under this 1st level node
as well as their associated fuzzy keywords. Fuzzy keywords
are generated to deal with typos. For example, for a disease
or category keyword, wi = “hypoglycemia”, the following
wild-card keywords having an edit distance of 1 from the
keyword “hypoglycemia”: {∗hypoglycemia, h∗ypoglycemia,
hy ∗ poglycemia, hyp ∗ oglycemia, hypo ∗ glycemia, hypog ∗
lycemia, hypogl∗ ycemia, hypogly∗ cemia, hypoglyc∗ emia,
hypoglyce ∗ mia, hypoglycem ∗ ia, hypoglycemi ∗ a, ···}
are inserted into the Bloom ﬁlter. Note that, it is easy to
extend our system to support multiple edit distances. (e.g.,
generate one Bloom ﬁlter per edit distance).
The TA also sends information regarding the number of
845children each 1st level node will have, e.g., top-level node i
will have |Ci| 2nd level nodes. Each 2nd level node has a
Bloom ﬁlter containing k encrypted disease keywords and
their associated fuzzy keyword sets (to address typos). All
Bloom ﬁlters associated with 2nd level nodes are also sent to
the public cloud. The public cloud then stores those Bloom
ﬁlters in the appropriate child nodes of ﬁrst level nodes.
Each 2nd level node represents k diseases and has three
child nodes, namely (i) diagnosis, (ii) complication predic-
tion, and (iii) treatment options. These child nodes are leaf
nodes. The diagnosis node will contain the training models
for disease diagnosis of the k diseases that this 2nd level node
represents. Each training model has an associated disease
token (which is a secure Bloom ﬁlter that contains hash val-
ues of a disease keyword with its typos) for the public cloud
to determine which training model to use when it processes a
query. Similarly, the complication prediction node contains
k training models, each for predicting potential complica-
tions which may arise of a particular disease. Finally, the
treatment node contains training models for k diseases, one
for each illness. Each training model represents an aggre-
gated model constructed by the public cloud using encrypted
information sent by each hospital. The training model is
built using patients’ proﬁles, disease treatments, laboratory
tests, etc, and is used to assess the best treatment option
for a particular patient based on his personal proﬁle, and/or
laboratory test results.
As for the clients, they may use their personal proﬁles
and lab tests results to generate search requests. After re-
ceiving an encrypted search request, the public cloud server
ﬁrst ﬁnds a matched category in the 1st level category nodes.
Then, the server will only search for matching results among
the child nodes of that best matched 1st level category node.
This can signiﬁcantly reduce the search time because the
server merely searches information within this relevant sub-
tree structure, only a subset of the whole information collec-
tion. The server goes through the child nodes of this selected
category node to ﬁnd k = 2 best matched 2nd level nodes.
Next, based on the query identiﬁer, the server randomly se-
lects one of the k matched level 2 nodes, and traverses into
its sub-tree structure based on the query type, e.g., diagno-
sis, complication or treatment. After ﬁnding the matched
leaf node, the cloud server will return the answers using the
appropriate training model for that query. For example,
based on the disease token and query type, the cloud server
selects the appropriate training model to see if a client has
suﬀered this disease or predict potential complications that
may arise or the treatment options for this particular dis-
ease based on that client’s unique proﬁles and laboratory
test results.
4.2 Detail Design of PDTCPS
We present more detailed descriptions of the proposed
scheme in this section.
Index Tree Construction
4.2.1
The public cloud constructs a keyword based encrypted in-
dex tree which allows authorized clients to conduct searches
for health related questions based on their individual proﬁles
and lab tests results.
Here, we describe how the encrypted index tree is con-
In our design, we use SHA − 256 as our keyed