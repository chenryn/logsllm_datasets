title:Adapting Software Fault Isolation to Contemporary CPU Architectures
author:David Sehr and
Robert Muth and
Cliff Biffle and
Victor Khimenko and
Egor Pasko and
Karl Schimpf and
Bennet Yee and
Brad Chen
Adapting Software Fault Isolation to Contemporary CPU Architectures
David Sehr
Robert Muth
Karl Schimpf
Cliff Bifﬂe
Bennet Yee
Victor Khimenko
Brad Chen
Egor Pasko
{sehr,robertm,cbifﬂe,khim,pasko,kschimpf,bsy,bradchen}@google.com
Abstract
Software Fault Isolation (SFI) is an effective approach
to sandboxing binary code of questionable provenance,
an interesting use case for native plugins in a Web
browser. We present software fault isolation schemes for
ARM and x86-64 that provide control-ﬂow and memory
integrity with average performance overhead of under
5% on ARM and 7% on x86-64. We believe these are the
best known SFI implementations for these architectures,
with signiﬁcantly lower overhead than previous systems
for similar architectures. Our experience suggests that
these SFI implementations beneﬁt from instruction-level
parallelism, and have particularly small impact for work-
loads that are data memory-bound, both properties that
tend to reduce the impact of our SFI systems for future
CPU implementations.
1
As an application platform, the modern web browser has
some noteworthy strengths in such areas as portability
and access to Internet resources.
It also has a number
of signiﬁcant handicaps. One such handicap is compu-
tational performance. Previous work [30] demonstrated
how software fault isolation (SFI) can be used in a sys-
tem to address this gap for Intel 80386-compatible sys-
tems, with a modest performance penalty and without
compromising the safety users expect from Web-based
applications. A major limitation of that work was its
speciﬁcity to the x86, and in particular its reliance on x86
segmented memory for constraining memory references.
This paper describes and evaluates analogous designs for
two more recent instruction set implementations, ARM
and 64-bit x86, with pure software-fault isolation (SFI)
assuming the role of segmented memory.
Introduction
The main contributions of this paper are as follows:
• A design for ARM SFI that provides control ﬂow
and store sandboxing with less than 5% average
overhead,
• A design for x86-64 SFI that provides control ﬂow
and store sandboxing with less than 7% average
overhead, and
• A quantitative analysis of these two approaches on
modern CPU implementations.
We will demonstrate that the overhead of fault isolation
using these techniques is very low, helping to make SFI
a viable approach for isolating performance critical, un-
trusted code in a web application.
1.1 Background
This work extends Google Native Client [30].1 Our
original system provides efﬁcient sandboxing of x86-32
browser plugins through a combination of SFI and mem-
ory segmentation. We assume an execution model where
untrusted (hence sandboxed) code is multi-threaded, and
where a trusted runtime supporting OS portability and se-
curity features shares a process with the untrusted plugin
module.
The original NaCl x86-32 system relies on a set of
rules for code generation that we brieﬂy summarize here:
• The code section is read-only and statically linked.
• The code section is conceptually divided into ﬁxed
sized bundles of 32 bytes.
• All valid instructions are reachable by a disassem-
bly starting at a bundle beginning.
• All
indirect control ﬂow instructions are re-
placed by a multiple-instruction sequence (pseudo-
instruction) that ensures target address alignment to
a bundle boundary.
• No instructions or pseudo-instructions in the binary
crosses a bundle boundary.
All rules are checked by a veriﬁer before a program is
executed. This veriﬁer together with the runtime system
comprise NaCls trusted code base (TCB).
For complete details on the x86-32 system please refer
to our earlier paper [30]. That work reported an average
overhead of about 5% for control ﬂow sandboxing, with
the bulk of the overhead being due to alignment consid-
erations. The system beneﬁts from segmented memory
to avoid additional sandboxing overhead.
Initially we were skeptical about SFI as a replace-
ment for hardware memory segments. This was based
in part on running code from previous research [19], in-
dicating about 25% overhead for x86-32 control+store
SFI, which we considered excessive. As we continued
1We abbreviate Native Client as “NaCl” when used as an adjective.
our exploration of ARM SFI and sought to understand
ARM behavior relative to x86 behavior, we could not ad-
equately explain the observed performance gap between
ARM SFI at under 10% overhead with the overhead on
x86-32 in terms of instruction set differences. With fur-
ther study we understood that the prior implementations
for x86-32 may have suffered from suboptimal instruc-
tion selection and overly pessimistic alignment.
Reliable disassembly of x86 machine code ﬁgured
largely into the motivation of our previous sandbox de-
sign [30]. While the challenges for x86-64 are substan-
tially similar, it may be less clear why analogous rules
and validation are required for ARM, given the relative
simplicity of the ARM instruction encoding scheme, so
we review a few relevant considerations here. Modern
ARM implementations commonly support 16-bit Thumb
instruction encodings in addition to 32-bit ARM instruc-
tions, introducing the possibility of overlapping instruc-
tions. Also, ARM binaries commonly include a number
of features that must be considered or eliminated by our
sandbox implementation. For example, ARM binaries
commonly include read-only data embedded in the text
segment. Such data in executable memory regions must
be isolated to ensure it cannot be used to invoke system
call instructions or other instructions incompatible with
our sandboxing scheme.
Our architecture further requires the coexistence of
trusted and untrusted code and data in the same pro-
cess, for efﬁcient interaction with the trusted runtime that
provides communications and portable interaction with
the native operating system and the web browser. As
such, indirect control ﬂow and memory references must
be constrained to within the untrusted memory region,
achieved through sandboxing instructions.
We brieﬂy considered using page protection as an al-
ternative to memory segments [26].
In such an ap-
proach, page-table protection would be used to prevent
the untrusted code from manipulating trusted data; SFI is
still required to enforce control-ﬂow restrictions. Hence,
page-table protection can only avoid the overhead of data
SFI; the control-ﬂow SFI overhead persists. Also, further
use of page protection adds an additional OS-based pro-
tection mechanism into the system, in conﬂict with our
requirement of portability across operating systems. This
OS interaction is complicated by the requirement for
multiple threads that transition independently between
untrusted (sandboxed) and trusted (not sandboxed) ex-
ecution. Due to the anticipated complexity and over-
head of this OS interaction and the small potential per-
formance beneﬁt we opted against page-based protection
without attempting an implementation.
2 System Architecture
The high-level strategy for our ARM and x86-64 sand-
boxes builds on the original Native Client sandbox for
x86-32 [30], which we will call NaCl-ARM, NaCl-x86-
64, and NaCl-x86-32 respectively. The three approaches
are compared in Table 1. Both NaCl-ARM and NaCl-
x86-64 sandboxes use alignment masks on control ﬂow
target addresses, similar to the prior NaCl-x86-32 sys-
tem. Unlike the prior system, our new designs mask
high-order address bits to limit control ﬂow targets to a
logical zero-based virtual address range. For data ref-
erences, stores are sandboxed on both systems. Note
that reads of secret data are generally not an issue as the
address space barrier between the NaCl module and the
browser protects browser resources such as cookies.
In the absence of segment protection, our ARM and
x86-64 systems must sandbox store instructions to pre-
vent modiﬁcation of trusted data, such as code addresses
on the trusted stack. Although the layout of the address
space differs between the two systems, both use a combi-
nation of masking and guard pages to keep stores within
the valid address range for untrusted data. To enable
faster memory accesses through the stack pointer, both
systems maintain the invariant that the stack pointer al-
ways holds a valid address, using guard pages at each
end to catch escapes due to both overﬂow/underﬂow and
displacement addressing.
Finally, to encourage source-code portability between
the systems, both the ARM and the x86-64 systems use
ILP32 (32-bit Int, Long, Pointer) primitive data types, as
does the previous x86-32 system. While this limits the
64-bit system to a 4GB address space, it can also improve
performance on x86-64 systems, as discussed in section
3.2.
At the level of instruction sequences and address space
layout, the ARM and x86-64 data sandboxing solutions
are very different. The ARM sandbox leverages instruc-
tion predication and some peculiar instructions that allow
for compact sandboxing sequences. In our x86-64 sys-
tem we leverage the very large address space to ensure
that most x86 addressing modes are allowed.
3
3.1 ARM
The ARM takes many characteristics from RISC micro-
processor design.
It is built around a load/store archi-
tecture, 32-bit instructions, 16 general purpose registers,
and a tendency to avoid multi-cycle instructions. It devi-
ates from the simplest RISC designs in several ways:
• condition codes that can be used to predicate most
Implementation
instructions
• “Thumb-mode” 16-bit instruction extensions can
improve code density
Feature
Addressable memory
Virtual base address
Data model
Reserved registers
Data address mask method
Control address mask method
Bundle size (bytes)
Data embedded in text segment
“Safe” addressing registers
Effect of out-of-sandbox store
Effect of out-of-sandbox jump
NaCl-x86-32
1GB
Any
ILP32
0 of 8
None
Explicit instruction
32
Forbidden
All
Trap
Trap
NaCl-ARM
1GB
0
ILP32
0 of 15
Explicit instruction
Explicit instruction
16
Permitted
sp
No effect (typically) Wraps mod 4GB
Wraps mod 1GB
Wraps mod 4GB
NaCl-x86-64
4GB
44GB
ILP32
1 of 16
Implicit in result width
Explicit instruction
32
Forbidden
rsp, rbp
Table 1: Feature Comparison of Native Client SFI schemes. NB: the current release of the Native Client system have changed since
the ﬁrst report [30] was written, where the addressable memory size was 256MB. Other parameters are unchanged.
• relatively complex barrel shifter and addressing
modes
While the predication and shift capabilities directly ben-
eﬁt our SFI implementation, we restrict programs to the
32-bit ARM instruction set, with no support for variable-
length Thumb and Thumb-2 encodings. While Thumb
encodings can incrementally reduce text size, most im-
portant on embedded and handheld devices, our work tar-
gets more powerful devices like notebooks, where mem-
ory footprint is less of an issue, and where the negative
performance impact of Thumb encodings is a concern.
We conﬁrmed our choice to omit Thumb encodings with
a number of major ARM processor vendors.
Our sandbox restricts untrusted stores and control ﬂow
to the lowest 1GB of the process virtual address space,
reserving the upper 3GB for our trusted runtime and the
operating system. As on x86-64, we do not prevent un-
trusted code from reading outside its sandbox. Isolating
faults in ARM code thus requires:
• Ensuring that untrusted code cannot execute any
forbidden instructions (e.g. undeﬁned encodings,
raw system calls).
• Ensuring that untrusted code cannot store to mem-
ory locations above 1GB.
• Ensuring that untrusted code cannot jump to mem-
ory locations above 1GB (e.g. into the service run-
time implementation).
We achieve these goals by adapting to ARM the ap-
proach described by Wahbe et al. [28]. We make three
signiﬁcant changes, which we summarize here before re-
viewing the full design in the rest of this section. First,
we reserve no registers for holding sandboxed addresses,
instead requiring that they be computed or checked in
a single instruction. Second, we ensure the integrity of
multi-instruction sandboxing pseudo-instructions with a
variation of the approach used by our earlier x86-32 sys-
tem [30], adapted to further prevent execution of embed-
ded data. Finally, we leverage the ARM’s fully predi-
cated instruction set to introduce an alternative data ad-
dress sandboxing sequence. This alternative sequence
replaces a data dependency with a control dependency,
preventing pipeline stalls and providing better overhead
on multiple-issue and out-of-order microarchitectures.
3.1.1 Code Layout and Validation
On ARM, as on x86-32, untrusted program text is sepa-
rated into ﬁxed-length bundles, currently 16 bytes each,
or four machine instructions. All indirect control ﬂow
must target the beginning of a bundle, enforced at run-
time with address masks detailed below. Unlike on the
x86-32, we do not need bundles to prevent overlapping
instructions, which are impossible in ARM’s 32-bit in-
struction encoding. They are necessary to prevent indi-
rect control ﬂow from targeting the interior of pseudo-
instruction and bundle-aligned “trampoline” sequences.
The bundle structure also allows us to support data em-
bedded in the text segment, with data bundles starting
with an invalid instruction (currently bkpt 0x7777)
to prevent execution as code.
The validator uses a fall-through disassembly of the
text to identify valid instructions, noting the interior of
pseudo-instructions and data bundles are not valid con-
trol ﬂow targets. When it encounters a direct branch,
it further conﬁrms that the branch target is a valid in-
struction. For indirect control ﬂow, many ARM opcodes
can cause a branch by writing r15, the program counter.
We forbid most of these instructions2 and consider only
explicit branch-to-address-in-register forms such as bx
r0 and their conditional equivalents. This restriction is
consistent with recent guidance from ARM for compiler
2We do permit the instruction bic r15, rN, MASK Although it
allows a single-instruction sandboxed control transfer, it can have poor
branch prediction performance.
writers. Any such branch must be immediately preceded
by an instruction that masks the destination register. The
mask must clear the most signiﬁcant two bits, restricting
branches to the low 1GB, and the four least signiﬁcant
bits, restricting targets to bundle boundaries. In 32-bit
ARM, the Bit Clear (bic) instruction can clear up to
eight bits rotated to any even bit position. For example,
this pseudo-instruction implements a sandboxed branch
through r0 in eight bytes total, versus the four bytes re-
quired for an unsandboxed branch:
bic r0, r0, #0xc000000f
bx r0
As we do not trust the contents of memory, the com-
mon ARM return idiom pop {pc} cannot be used. In-
stead, the return address must be popped into a register
and masked:
pop { lr }
bic lr, lr, #0xc000000f
bx lr
Branching through LR (the link register) is still recog-
nized by the hardware as a return, so we beneﬁt from
hardware return stack prediction. Note that these se-
quences introduce a data dependency between the bx
branch instruction and its adjacent masking instruction.
This pattern (generating an address via the ALU and im-
mediately jumping to it) is sufﬁciently common in ARM
code that the modern ARM implementations [3] can dis-
patch the sequence without stalling.
For stores, we check that the address is conﬁned to the
low 1GB, with no alignment requirement. Rather than
destructively masking the address, as we do for control
ﬂow, we use a tst instruction to verify that the most
signiﬁcant bit is clear together with a predicated store:3
tst r0, #0xc0000000
streq r1, [r0, #12]
Like bic, tst uses an eight-bit immediate rotated
to any even position, so the encoding of the mask is
efﬁcient. Using tst rather than bic here avoids a
data dependency between the guard instruction and the
store, eliminating a two-cycle address-generation stall
on Cortex-A8 that would otherwise triple the cost of
the added instruction. This illustrates the usefulness of
the ARM architecture’s fully predicated instruction set.
Some predicated SFI stores can also be synthesized in
this manner, using sequences such as tsteq/streq.
For cases where the compiler has selected a predicated
store that cannot be synthesized with tst, we revert
to a bic-based sandbox, with the consequent address-
generation stall.
3The eq condition checks the Z ﬂag, which tst will set if the se-
lected bit is clear.
We allow only base-plus-displacement addressing
with immediate displacement. Addressing modes that
combine multiple registers to compute an effective ad-
dress are forbidden for now. Within this limitation, we
allow all types of stores, including the Store-Multiple
instruction and DMA-style stores through coprocessors,
provided the address is checked or masked. We allow the
ARM architecture’s full range of pre- and post-increment
and decrement modes. Note that since we mask only the
base address and ARM immediate displacements can be
up to ±4095 bytes, stores can access a small band of
memory outside the 1GB data region. We use guard
pages at each end of the data region to trap such ac-
cesses.4
3.1.2 Stores to the Stack
To allow optimized stores through the stack pointer, we
require that the stack pointer register (SP) always con-
tain a valid data address. To enforce this requirement,
we initialize SP with a valid address before activating
the untrusted program, with further requirements for the
two kinds of instructions that modify SP. Instructions that
update SP as a side-effect of a memory reference (for ex-
ample pop) are guaranteed to generate a fault if the mod-
iﬁed SP is invalid, because of our guard regions at either
end of data space. Instructions that update SP directly
are sandboxed with a subsequent masking instruction, as
in:
mov SP, r1
bic SP, SP, #c0000000
This approach could someday be extended to other reg-
isters. For example, C-like languages might beneﬁt from
a frame pointer handled in much the same way as the SP,
as we do for x86-64, while Java and C++ might addition-
ally beneﬁt from efﬁcient stores through this. In these
cases, we would also permit moves between any two