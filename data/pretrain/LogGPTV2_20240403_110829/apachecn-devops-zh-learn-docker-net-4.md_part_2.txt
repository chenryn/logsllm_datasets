    To see how to connect Docker to this machine, run: docker-machine env swarm-master
    ```
    前面命令中使用的参数使用如下:
    *   `--swarm`:用于用 Swarm 配置机器。
    *   `--engine-opt`:该选项用于定义需要提供的任意守护程序选项。在我们的例子中，我们将在创建时为引擎守护程序提供`--cluster-store`选项，该选项告诉引擎键值存储的位置，以便覆盖网络的可用性。`--cluster-advertise`选项会将机器放在特定端口的网络上。
    *   `--swarm-discovery`:是用来发现和 Swarm 一起使用的服务，在我们这里`consul`就是那个服务。
    *   `--swarm-master`:用于将机器配置为 Swarm 主机。
6.  也可以创建另一个主机并添加到 Swarm 集群中，如下所示:
    ```
    $ docker-machine create -d virtualbox --swarm --swarm-image="swarm:1.0.0-rc2" --swarm-discovery="consul://$(docker-machine ip sample-keystore):8500" --engine-opt="cluster-store=consul://$(docker-machine ip sample-keystore):8500" --engine-opt="cluster-advertise=eth1:2376" swarm-node-1
    Running pre-create checks...
    Creating machine...
    Waiting for machine to be running, this may take a few minutes...
    Machine is running, waiting for SSH to be available...
    Detecting operating system of created instance...
    Provisioning created instance...
    Copying certs to the local machine directory...
    Copying certs to the remote machine...
    Setting Docker configuration on the remote daemon...
    Configuring swarm...
    To see how to connect Docker to this machine, run: docker-machine env swarm-node-1
    ```
7.  机器可列举如下:
    ```
    $ docker-machine ls
    NAME            ACTIVE   DRIVER       STATE     URL               SWARM
    sample-keystore   -     virtualbox   Running   tcp://192.168.99.100:2376
    swarm-master      -     virtualbox   Running   tcp://192.168.99.101:2376  swarm-master (master)
    swarm-node-1      -     virtualbox   Running   tcp://192.168.99.102:2376   swarm-master
    ```
8.  现在，我们将 Docker 环境设置为`swarm-master` :
    ```
    $ eval $(docker-machine env --swarm swarm-master)
    ```
9.  可以在主机上执行以下命令，以创建覆盖网络并进行多主机联网:
    ```
    $ docker network create –driver overlay sample-net
    ```
10.  可以使用以下命令在主机上检查网桥:
    ```
    $ docker network ls
    NETWORK ID         NAME           DRIVER
    9f904ee27bf5      sample-net      overlay
    7fca4eb8c647       bridge         bridge
    b4234109be9b       none            null
    cf03ee007fb4       host            host
    ```
11.  当切换到 Swarm 节点时，我们可以轻松地列出新创建的覆盖网络，如下所示:
    ```
    $ eval $(docker-machine env swarm-node-1)
    $ docker network ls
    NETWORK ID        NAME            DRIVER
    7fca4eb8c647      bridge          bridge
    b4234109be9b      none             null
    cf03ee007fb4      host            host
    9f904ee27bf5     sample-net       overlay
    ```
12.  一旦网络被创建，我们可以在任何主机上启动容器，它将是网络的一部分:
    ```
    $ eval $(docker-machine env swarm-master)
    ```
13.  启动样本`ubuntu`容器，约束环境设置为第一个节点:
    ```
    $ docker run -itd --name=os --net=sample-net --env="constraint:node==swarm-master" ubuntu
    ```
14.  我们可以使用`ifconfig`命令检查容器是否有两个网络接口，并且可以从任何其他主机上使用 Swarm 管理器部署的容器访问。
# 立方结构
Kubernetes 是一个容器集群管理工具。目前，它支持 Docker 和 Rocket。这是一个由谷歌支持的开源项目，该项目于 2014 年 6 月在谷歌 I/O 启动，支持在 GCE、Azure、AWS、vSphere 等各种云提供商上部署，也支持在裸机上部署。Kubernetes 管理器是精简的、可移植的、可扩展的和自我修复的。
Kubernetes 有各种重要成分，如下表所示:
*   **节点**:这是 Kubernetes 集群的物理或虚拟机部分，运行 Kubernetes 和 Docker 服务，可以在其上调度 pods。
*   **主**:这维护了 Kubernetes 服务器运行时的运行时状态。它是配置和管理 Kubernetes 组件的所有客户端调用的入口点。
*   **Kubectl** :这是命令行工具，用于与 Kubernetes 集群交互，以提供对 Kubernetes APIs 的主访问。通过它，用户可以部署、删除和列出 pods。
*   **Pod** :这是 Kubernetes 最小的调度单元。它是共享卷且没有端口冲突的 Docker 容器的集合。它可以通过定义一个简单的 JSON 文件来创建。
*   **复制控制器**:它管理一个 Pod 的生命周期，并通过根据需要创建或杀死 Pod 来确保指定数量的 Pod 在给定时间运行。
*   **标签**:标签用于根据键值对识别和组织 pods 和服务。
下图显示了 Kubernetes 主/迷你流:
![Kubernetes](img/00026.jpeg)
## 在 AWS 上部署 Kubernetes
让我们在 AWS 上开始 Kubernetes 集群部署，这可以通过使用 Kubernetes 代码库中已经存在的配置文件来完成:
1.  在[http://aws.amazon.com/console/](http://aws.amazon.com/console/)登录自动气象站控制台。
2.  在[https://console.aws.amazon.com/iam/home?#home](https://console.aws.amazon.com/iam/home?#home)打开 IAM 控制台。
3.  选择 IAM 用户名，选择**安全凭证**选项卡，并点击**创建访问密钥**选项。
4.  创建密钥后，下载并保存在安全的地方。下载的`.csv`文件将包含一个`Access Key ID`和`Secret Access Key`，用于配置 AWS 命令行界面。
5.  安装并配置 AWS 命令行界面。在本例中，我们使用以下命令在 Linux 上安装了 AWS CLI:
    ```
    $ sudo pip install awscli
    ```
6.  要配置 AWS 命令行界面，请使用以下命令:
    ```
    $ aws configure
    AWS Access Key ID [None]: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
    AWS Secret Access Key [None]: YYYYYYYYYYYYYYYYYYYYYYYYYYYY
    Default region name [None]: us-east-1
    Default output format [None]: text
    ```
7.  配置 AWS CLI 后，我们将创建一个配置文件，并为其附加一个角色，该角色可以完全访问 S3 和 EC2:
    ```
    $ aws iam create-instance-profile --instance-profile-name Kube
    ```
8.  The role can be created separately using the console or AWS CLI with a JSON file that defines the permissions the role can have:
    ```
    $ aws iam create-role --role-name Test-Role --assume-role-policy-document /root/kubernetes/Test-Role-Trust-Policy.json
    ```
    可以将一个角色附加到前面的配置文件中，该配置文件可以完全访问 EC2 和 S3，如下图所示:
    ![Deploying Kubernetes on AWS](img/00027.jpeg)
9.  创建角色后，可以使用以下命令将其附加到策略:
    ```
    $ aws iam add-role-to-instance-profile --role-name Test-Role --instance-profile-name Kube
    ```
10.  默认情况下，脚本使用默认配置文件。我们可以修改如下:
    ```
    $ export AWS_DEFAULT_PROFILE=Kube
    ```
11.  Kubernetes 集群可以使用一个命令轻松部署，如下所示:
    ```
    $ export KUBERNETES_PROVIDER=aws; wget -q -O - https://get.k8s.io | bash
    Downloading kubernetes release v1.1.1 to /home/vkohli/kubernetes.tar.gz
    --2015-11-22 10:39:18--  https://storage.googleapis.com/kubernetes-release/release/v1.1.1/kubernetes.tar.gz
    Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.220.48, 2404:6800:4007:805::2010
    Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.220.48|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 191385739 (183M) [application/x-tar]
    Saving to: 'kubernetes.tar.gz'
    100%[======================================>] 191,385,739 1002KB/s   in 3m 7s
    2015-11-22 10:42:25 (1002 KB/s) - 'kubernetes.tar.gz' saved [191385739/191385739]
    Unpacking kubernetes release v1.1.1
    Creating a kubernetes on aws...
    ... Starting cluster using provider: aws
    ... calling verify-prereqs
    ... calling kube-up
    Starting cluster using os distro: vivid
    Uploading to Amazon S3
    Creating kubernetes-staging-e458a611546dc9dc0f2a2ff2322e724a
    make_bucket: s3://kubernetes-staging-e458a611546dc9dc0f2a2ff2322e724a/
    +++ Staging server tars to S3 Storage: kubernetes-staging-e458a611546dc9dc0f2a2ff2322e724a/devel
    upload: ../../../tmp/kubernetes.6B8Fmm/s3/kubernetes-salt.tar.gz to s3://kubernetes-staging-e458a611546dc9dc0f2a2ff2322e724a/devel/kubernetes-salt.tar.gz
    Completed 1 of 19 part(s) with 1 file(s) remaining
    ```
12.  前面的命令将调用`kube-up.sh`，然后使用`config-default.sh`脚本调用`utils.sh`，该脚本包含具有四个节点的 K8S 集群的基本配置，如下所示:
    ```
    ZONE=${KUBE_AWS_ZONE:-us-west-2a}
    MASTER_SIZE=${MASTER_SIZE:-t2.micro}
    MINION_SIZE=${MINION_SIZE:-t2.micro}
    NUM_MINIONS=${NUM_MINIONS:-4}
    AWS_S3_REGION=${AWS_S3_REGION:-us-east-1}
    ```
13.  实例是运行 Ubuntu 操作系统的`t2.micro`。该过程需要 5 到 10 分钟，之后会列出主服务器和从属服务器的 IP 地址，并可用于访问 Kubernetes 集群。
## Kubernetes 网络及其与 Docker 网络的区别
Kubernetes 偏离了默认 Docker 系统的网络模型。目标是每个 pod 都有一个由系统的管理命名空间赋予的 IP 级别，它与系统上的其他物理机器和容器完全一致。从端口分配、系统管理、命名、管理公开、负担调整、应用设计以及 pods 从一台主机移动到另一台主机的角度来看，为每个 pods 单元分配 IP 有助于一个干净、倒退且良好的模型，其中单元可以像虚拟机或物理主机一样处理。所有 Pod 中的所有容器都可以使用它们的地址与所有其他 Pod 中的所有其他容器进行对话。这也有助于将传统应用转移到面向容器的方法。
由于每个 pod 都获得了一个真实的 IP 地址，它们可以相互通信，而不需要任何翻译。通过在 pod 内部和外部进行相同的 IP 地址和端口配置，我们可以创建一个无 NAT 的平面地址空间。这不同于标准的 Docker 模型，因为在那里，所有容器都有一个私有的 IP 地址，这将允许它们能够访问同一主机上的容器。但是在 Kubernetes 的例子中，一个 pod 中的所有容器的行为就好像它们在同一个主机上，并且可以到达本地主机上彼此的端口。这减少了容器之间的隔离，并提供了简单性、安全性和性能。端口冲突可能是其中的一个缺点；因此，一个容器内的两个不同容器不能使用同一个端口。
在 GCE 中，使用 IP 转发和高级路由规则，Kubernetes 集群中的每个虚拟机都会获得额外的 256 个 IP 地址，以便轻松地跨 pods 路由流量。
GCE 中的路由允许您在虚拟机中实现更高级的网络功能，例如设置多对一网络地址转换。Kubernetes 利用了这一点。
这是对虚拟机拥有的主以太网桥的补充；该桥被称为容器桥`cbr0`，以区别于 Docker 桥`docker0`。为了将数据包从 Pod 传送出 GCE 环境的，它应该经过 SNAT 到虚拟机的 IP 地址，GCE 识别并允许该地址。
其他主要目的是提供每荚 IP 模型的实现有开放虚拟交换机、Flannel 和 Weave。
在类似 GCE 的 Kubernetes 开放虚拟交换机桥的设置中，接下来是 Docker 桥被`kbr0`取代以提供额外的 256 个子网地址的模型。此外，还添加了一个 OVS 桥(`ovs0`)，该桥为 Kubernetes 桥添加了一个端口，以便提供 GRE 隧道来跨不同的从属端传输数据包，并连接驻留在这些主机上的 Pod 。在接下来的图表中，还将更详细地阐述每个 pod 的 IP 模型，其中还将解释 Kubernetes 的服务抽象概念。
服务是另一种广泛使用的抽象类型，建议在 Kubernetes 集群中使用，因为它允许通过虚拟 IP 地址访问一组 pods(应用)，并代理到服务中的所有内部 pods。部署在 Kubernetes 中的一个应用可能使用同一个 pod 的三个副本，它们有不同的 IP 地址。但是，客户端仍然可以在暴露在外的一个 IP 地址上访问应用，而不管哪个后端 pod 接受请求。服务充当不同副本 Pod 之间的负载平衡器，并为使用该应用的客户端提供单点通信。Kubernetes 的服务之一 Kubeproxy 提供负载平衡，并使用规则来访问服务 IPs，并将它们重定向到正确的后端 pod。
## 部署 KubernetesPod 
现在，在下面的示例中，我们将部署两个 nginx 复制单元(`rc-pod`)并通过服务公开它们，以便理解 Kubernetes 网络。由**服务代理**决定应用可以通过虚拟 IP 地址暴露在哪里，以及请求将被代理到 pod(负载均衡器)的哪个副本。详情请参考下图:
![Deploying the Kubernetes pod](img/00028.jpeg)
以下是部署 Kubernetes pod 的步骤: