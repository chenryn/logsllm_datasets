2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
ReachingEdgesSet ← {}
for each e = (cid:2)n, m(cid:3) of outgoing edges of n do
if m ∈ V isitedN odes then
ReachingEdgesSet.push((cid:2)n, m(cid:3))
if ReachingEdgesSet.size() > 1 then
if m /∈ V isitedN odes then
Queue.push(m)
for n ∈ V isitedN odes do
InstrumentationSet.push(ReachingEdgesSet)
return InstrumentationSet
Algorithm 1 shows the algorithm for incremental optimiza-
tion. Line 3 illustrates the idea of processing each target
function incrementally. For each target function, Lines 4–17
are to ﬁnd true branching nodes relative to it. Speciﬁcally,
Lines 4–10 are a backward breadth-ﬁrst search; as it omits
nodes already visited (Line 9), it can correctly handle back
edges. Then Lines 11–17 are to ﬁnd true branching nodes.
V. OFFLINE ATTACK ANALYSIS AND PATCH GENERATION
The Ofﬂine Patch Generator component runs the vulnerable
program using the attack input and generates the patch as part
of the dynamic analysis report. It is built on dynamic binary in-
strumentation and shadow memory of Valgrind [54]. As shown
in Figure 3, for every bit of the program memory, a Validity bit
(V-bit) is maintained to indicate whether the accompanying bit
has a valid value (i.e., initialized); instructions are inserted for
534
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:53:42 UTC from IEEE Xplore.  Restrictions apply. 
(cid:2)(cid:20)(cid:20)(cid:16)(cid:15)(cid:10)(cid:8)(cid:23)(cid:15)(cid:19)(cid:18)(cid:1)
(cid:5)(cid:12)(cid:17)(cid:19)(cid:21)(cid:25)
(cid:3)(cid:25)(cid:23)(cid:12)(cid:28)(cid:1)
(cid:3)(cid:25)(cid:23)(cid:12)(cid:29)
(cid:3)(cid:25)(cid:23)(cid:12)(cid:29)
…………(cid:26)(cid:26)
(cid:3)(cid:25)(cid:23)(cid:12)(cid:18)
(cid:6)(cid:14)(cid:8)(cid:11)(cid:19)(cid:24)(cid:1)
(cid:5)(cid:12)(cid:17)(cid:19)(cid:21)(cid:25)
(cid:6)(cid:14)(cid:8)(cid:11)(cid:19)(cid:24)(cid:1)
(cid:4)(cid:18)(cid:13)(cid:19)(cid:21)(cid:17)(cid:8)(cid:23)(cid:15)(cid:19)(cid:18)
(cid:6)(cid:14)(cid:8)(cid:11)(cid:19)(cid:24)(cid:1)
(cid:4)(cid:18)(cid:13)(cid:19)(cid:21)(cid:17)(cid:8)(cid:23)(cid:15)(cid:19)(cid:18)
(cid:6)(cid:14)(cid:8)(cid:11)(cid:19)(cid:24)(cid:1)
(cid:4)(cid:18)(cid:13)(cid:19)(cid:21)(cid:17)(cid:8)(cid:23)(cid:15)(cid:19)(cid:18)
…………(cid:26)(cid:26)
(cid:6)(cid:14)(cid:8)(cid:11)(cid:19)(cid:24)(cid:1)
(cid:4)(cid:18)(cid:13)(cid:19)(cid:21)(cid:17)(cid:8)(cid:23)(cid:15)(cid:19)(cid:18)
(cid:2)(cid:1)(cid:9)(cid:15)(cid:23)
(cid:1)(cid:7)(cid:1)(cid:9)(cid:15)(cid:23)(cid:22)
(cid:28)
(cid:28)
(cid:28) (cid:28) (cid:28) (cid:28) (cid:28) (cid:28) (cid:28) (cid:28)
(cid:28)(cid:28) (cid:28)(cid:28) (cid:28)(cid:28) (cid:28)(cid:28) (cid:28)(cid:28) (cid:28)(cid:28) (cid:28)(cid:28) (cid:28)
(cid:2)(cid:1)(cid:9)(cid:15)(cid:23)
(cid:1)(cid:7)(cid:1)(cid:9)(cid:15)(cid:23)(cid:22)
(cid:27)
(cid:27)
(cid:27) (cid:27) (cid:27) (cid:27) (cid:27) (cid:27) (cid:27) (cid:27)
(cid:27)(cid:27) (cid:27)(cid:27) (cid:27)(cid:27) (cid:27)(cid:27) (cid:27)(cid:27) (cid:27)(cid:27) (cid:27)(cid:27) (cid:27)
Fig. 3. Shadow memory.
1 typedef struct {
uint32_t i;
uint8_t c;
} A;
5 A y, *p = (A *) malloc( sizeof(A) );
p->i = 0; p->c = ’f’;
y = *p;
Fig. 4. Legal uninitialized read due to padding.
the propagation of V-bits when data copy occurs (e.g., when a
word is read from memory to a register); for every byte of the
memory location, an Accessibility bit (A-bit) is maintained to
indicate whether the memory location can be accessed.
When a heap buffer is allocated, the returned memory is
marked as accessible but invalid. Each buffer is surrounded
by a pair of red zones (16 bytes each), which are marked
as inaccessible. When a heap buffer is free-ed, its memory
is set as inaccessible. In addition, whenever a heap buffer is
allocated, the current calling context ID (CCID) is recorded
and associated with the buffer.
(1) Detecting overﬂows: A buffer overﬂow will access the
inaccessible red zone appended to the buffer and get detected.
(2) Detecting use after free: A free-ed buffer is set as
inaccessible and then added to a FIFO queue of freed blocks.
Thus, the memory is not immediately made available for reuse.
Any attempts to access any of the blocks in the queue can be
detected. The maximum total size of the buffers in the queue is
set as 2GB by default, which is large enough for the exploits
we investigated, and can be customized. In Section IX, we
discuss how to handle it if the quota is insufﬁcient.
(3) Detecting uninitialized read: To detect uninitialized read,
an attempt is to report any access to uninitialized data, but this
will lead to many false positives. For instance, given the code
snippet in Figure 4, most of the compilers will round the size
of A to 8 bytes; so only 5 bytes of the heap buffer is initialized
(and the V-bits for the remaining 3 bytes are zero), while the
compiler typically generates code to copy all 8 bytes for y =
*p, which would cause false positives due to accessing the 3
bytes whose V-bits are zero. To avoid false positives due to
padding, we check the V-bit of a value only when it is used to
decide the control ﬂow (e.g., jnz), used as a memory address,
or used in a system call (as the kernel behavior is not tracked).
As every bit of the program has a V-bit, bit-precision detection
of uninitialized read is achieved. Moreover, origin tracking is
(cid:19)(cid:49)(cid:48)(cid:42)(cid:45)(cid:43)(cid:53)(cid:50)(cid:37)(cid:52)(cid:45)(cid:49)(cid:48)(cid:1)(cid:42)(cid:45)(cid:46)(cid:41)
(cid:1)(cid:3)(cid:5)(cid:12)(cid:9)(cid:2)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:6)(cid:6)(cid:9)(cid:7)(cid:2)
(cid:1)(cid:13)(cid:25)(cid:19)(cid:20)(cid:16)(cid:22)(cid:14)(cid:15)(cid:18)(cid:19)(cid:18)(cid:24)(cid:26)(cid:4)
(cid:1)(cid:16)(cid:47)(cid:41)(cid:47)(cid:37)(cid:46)(cid:45)(cid:43)(cid:48)(cid:4)(cid:1)(cid:8)(cid:14)(cid:12)(cid:11)(cid:15)(cid:12)(cid:12)(cid:9)(cid:15)(cid:9)(cid:4) (cid:1)(cid:29)(cid:34)(cid:21)(cid:30)(cid:22)(cid:26)(cid:29)(cid:35)(cid:17)
(cid:1)(cid:16)(cid:39)(cid:37)(cid:46)(cid:46)(cid:49)(cid:39)(cid:4)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:14)(cid:13)(cid:11)(cid:10)(cid:12)(cid:13)(cid:12)(cid:11)(cid:11)(cid:10)(cid:4)(cid:1)(cid:1)(cid:33)(cid:31)(cid:21)(cid:5)(cid:18)(cid:22)(cid:32)(cid:21)(cid:30)(cid:5)(cid:22)(cid:30)(cid:21)(cid:21)(cid:17)
(cid:1)(cid:16)(cid:47)(cid:37)(cid:46)(cid:46)(cid:49)(cid:39)(cid:4)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:9)(cid:12)(cid:8)(cid:11)(cid:14)(cid:10)(cid:4)(cid:1)(cid:1)(cid:33)(cid:28)(cid:25)(cid:28)(cid:25)(cid:32)(cid:25)(cid:18)(cid:26)(cid:25)(cid:36)(cid:21)(cid:20)(cid:5)(cid:30)(cid:21)(cid:18)(cid:20)(cid:17)
 … (cid:6)(cid:6)(cid:6)
(cid:24)(cid:37)(cid:51)(cid:44)(cid:1)(cid:52)(cid:37)(cid:38)(cid:46)(cid:41)
(cid:10)(cid:16)(cid:26)
(cid:1)(cid:16)(cid:27)(cid:21)(cid:27)(cid:18)(cid:26)(cid:25)(cid:23)(cid:28)(cid:4)(cid:1)(cid:8)(cid:14)(cid:12)(cid:11)(cid:15)(cid:12)(cid:12)(cid:9)(cid:15)(cid:9)(cid:17)
(cid:1)(cid:16)(cid:19)(cid:18)(cid:26)(cid:26)(cid:29)(cid:19)(cid:4)(cid:1)(cid:14)(cid:13)(cid:11)(cid:10)(cid:12)(cid:13)(cid:12)(cid:11)(cid:11)(cid:10)(cid:17)
(cid:1)(cid:16)(cid:27)(cid:18)(cid:26)(cid:26)(cid:29)(cid:19)(cid:4)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:9)(cid:12)(cid:8)(cid:11)(cid:14)(cid:10)(cid:17)
…(cid:6)(cid:6)
(cid:30)(cid:41)(cid:37)(cid:40)(cid:1)(cid:38)(cid:54)(cid:1)(cid:11)(cid:20)(cid:19)(cid:18)(cid:20)(cid:16)(cid:1)
(cid:7)(cid:16)(cid:17)(cid:16)(cid:20)(cid:23)(cid:16)(cid:1)(cid:8)(cid:16)(cid:20)(cid:16)(cid:22)(cid:14)(cid:24)(cid:21)(cid:22)
(cid:13)(cid:14)(cid:19)(cid:25)(cid:16)
(cid:2)(cid:7)(cid:7)(cid:8)(cid:3)(cid:9)
(cid:2)(cid:7)(cid:8)(cid:7)(cid:3)(cid:9)
(cid:2)(cid:8)(cid:7)(cid:7)(cid:3)(cid:9)
… … 
Fig. 5. Patches read into a hash table.
When an attack is detected,
used to track the use of invalid data back to the uninitialized
data (such as a heap buffer) when a warning is raised, which
allows us to retrieve the allocation-time CCID associated with
the vulnerable buffer.
the patch is generated in
the form of (cid:2) FUN, CCID, T(cid:3), where FUN is the func-
tion used to request
the heap buffer (such as malloc,
memalign), CCID is an integer representing the allocation-
time calling context ID of the vulnerable buffer, and T is a
three-bit integer representing the vulnerability type (the three
bits are used to indicate OVERFLOW, USE-AFTER-FREE,
UNINITIALIZED-READ, respectively). Example patches are
shown in the upper graph in Figure 5.
How to handle realloc: If the new size is smaller than the
original size, the cut-off region is marked as inaccessible. If
the new size is larger, the added region is set as accessible but
invalid. The allocation-time CCID associated with the buffer
is also updated with the value upon the realloc invocation.
How to handle multiple vulnerabilities: An attack input may
exploit multiple vulnerabilities. For example, the Heartbleed
attack exploits both uninitialized read and overread. In order to
handle the case that an attack exploits multiple vulnerabilities,
we resume the program execution upon warnings. Plus, once
the V bits for a value have been checked, they are then set to
valid; this avoids a large number of chained warnings. Finally,
a script is used to process the many warnings according to
the origin (i.e., the vulnerable buffer) of those warnings and
generate patches.
VI. CODE-LESS PATCHING AND ONLINE DEFENSES
When the patched program is started, as shown in Figure 5,
the Online Defense Generator library has an initialization
function4 that reads patches from the conﬁguration ﬁle and
stores them into a hash table, where the key of each entry
is (cid:2) ALLOCATION_FUNCTION, CCID(cid:3) and the value is the
vulnerability type(s) and parameters, if any, for generating
online defenses. Note once the hash table is initialized, its
memory pages are set as read only.
The Online Defense Generator library intercepts all heap
memory allocation operations. Whenever a heap buffer is
allocated, the name of the allocation function along with the
4__attribute__((constructor)) is used to declare the function.
535
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:53:42 UTC from IEEE Xplore.  Restrictions apply. 
Metadata
Structure 1 
Unused
Buffer size
Buffer 
type
User buffer 
12 bits
48 bits
4 bits
Metadata
 4 KB guard page
Structure 2
(w/t guard page)
Unused
Location of
guard page
Buffer 
type
User buffer  Buffer
size Unused
24 bits
36 bits
4 bits
48 bits
Metadata
Structure 3 
(aligned)
Structure 4
(aligned and w/t 
guard page)
Padding 
for 
alignment
Padding 
for 
alignment
Alignment
information
Buffer size
Buffer 
type
User buffer 
6 bits
48 bits
4 bits
Metadata
 4 KB guard page
Alignment
information
Location of 
guard page
Buffer 
type
User buffer 
Buffer
size Unused
6 bits
36 bits
4 bits
48 bits
Fig. 6. Buffer structures. Note how we pack the metadata into only one word
(64 bits) preceding the user buffer.
current CCID is used to search in the patch hash table, which
takes only O(1) time. If there is no match, the buffer does not
need to be enhanced; otherwise, the buffer is enhanced based
on the associated vulnerability type(s) and parameters.
Several considerations make the design of online defenses
challenging. (1) In some cases,
the same buffer may be
vulnerable to multiple attacks, such as uninitialized read and
overﬂow. (2) In addition to handling malloc and free, the
system needs to support a family of other allocation functions,
such as realloc and memalign (aligned allocation). These
challenges are well resolved by our system. Another com-
plexity is that we maintain heap metadata ourselves, such as
the buffer size (to support realloc correctly), vulnerability
type(s), the buffer alignment information, and the location of
the guard page, so that our system can work without having
to change the underlying allocator or rely on its internals.
(1) Handling overﬂows: If the buffer is vulnerable to over-
ﬂows, a guard page is appended to it to prevent such attacks.
While the guard page can effectively prevent overﬂows, they
are known to be prohibitively expensive when being applied
to every buffer. In our system, however,
the guard page
is precisely applied to vulnerable buffers, and the resulting
overhead is dramatically reduced.
As shown in Figure 6, Structure 2 is used for non-aligned
buffers, while Structure 4 is used for aligned buffers (allocated
using memalign, etc.). When a heap allocation request is
intercepted, the requested size is increased to accommodate the
word for metadata and the guard page (as well as necessary
padding following the user buffer to ensure the guard page is
page aligned). The address of the user buffer is returned to
service the user program.
A SUMMARY OF THE USE OF BUFFER STRUCTURES.
TABLE I
Vulnerability type