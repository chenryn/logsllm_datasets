No
No
No
Yes
Yes
Yes
Yes
Yes
B
Θ(1)
Θ(1)
Θ(1)
Θ(1)
Θ(nϵ )
ω (log n)
O (1)
Ω(log n)
Θ(1)
Θ(1)
M
Θ(1)
Θ(1)
Θ(nϵ )
Θ(1)
Θ(nϵ )
ω (B log n)
Θ(polylog n)
Ω(log n)
Θ(1)
Θ(logϵ n)
I/O Overhead
O (log3 n)
O (log3 n)
O (log n)
O (log2 n/ log log n)
O (1)
O (log2 n/ log B)
O (log2 n log log n)
O (log2 n/ log2 B)
O (log2 n log log n)
O (log2 n)
Table 1: Our isogrammic-fusion ORAM bounds (in boldface), compared to some of the asymptotically best previous ORAM
methods. The parameter 0 < ϵ ≤ 1/2 is a fixed constant.
A WARM UP: STACKS AND QUEUES
Wang et al. [21] show how to implement simple data structures, like
stacks and queues in an oblivious way. We show in this section how
to implement such data structures in our isogrammic framework.
Stacks. Recall that a stack maintains a set of objects organized
according to a last-in, first-out protocol, where a push(x ) operation
adds the element x to the set and a pop() operation returns and
removes the most recently pushed element. Suppose we are given
a sequence of push and pop operations. We can convert this into
an isogrammic access sequence as follows.
We assume that in her private storage, Alice keeps track of the
size, n, and a random nonce, r, associated with the top element
of the stack. Thus, we can assume that Alice will never issue a
pop() operation on an empty stack. Let us also assume that our
random nonce generator provides sufficiently random nonces so
that it never repeats any nonces (e.g., we can enforce this by adding
a counter to nonces). We initialize such a stack, Z, by issuing a
put((Z , r ), null) operation, where r is an initial random nonce, and
Z is the name of our stack, and we have Alice store r in her private
memory as well. This put() serves to create out empty stack, Z.
To process a push(x ) operation, we generate a new random
nonce, r′, and issue a put(k, (x, r )) operation, where k = (Z , r′)
and r is the current top-level random nonce that Alice is storing
in her private memory. That is, we use the old top-level random
nonce, r, along with x, as the “value” for our put() operation and
we use the new random nonce as a part of the key, k. Alice then
stores r′ as the new top-level nonce in her private memory.
To process a pop operation, we issue a get(k ) operation, where
k = (Z , r ) and r is the top-level nonce that Alice stores in her private
memory. This get(k ) returns as its value a pair, (x, r′), where x was
the most recently added element and r′ was the top-level nonce
when x was pushed. Thus, we return x to Alice as the actual result
of her pop() operation and we have Alice store the nonce, r′, as the
updated top-level nonce for the stack, Z.
The access sequence of put(k, v) and get(k ) operations this
transformation creates is isogrammic, because (1) each get(k ) has
a previous put(k, v) operation, (2) we never have two put(k, v)
operations with the same key, k, and (3) each key, k, includes a
unique random nonce. Moreover, it adds O (1) put(k, v) and/or
get(k ) operations for each push(x ) or pop operation.
Queues. Recall that a queue is a data structure that maintains a
set accounding a first-in, first-out protocol, where enqueue(x ) adds
an element x to the set and dequeue() removes the oldest element
in the set.
We assume that in her private storage, Alice keeps track of
the size, n, of the queue, and two random nonces, h and t, that
are associated respectively with the head and tail of her queue, Q.
Initially, we choose t at random and set h = null. Also, because Alice
stores n, we can assume that Alice will never issue a dequeue()
operation on an empty queue.
To process an enqueue(x ) operation, we generate a new random
tail nonce, t′, and issue a put(k, (x, t′)) operation, where k = (Q, t )
and t is the current random tail nonce that Alice is storing in her
private memory. Alice then stores t′ as the new tail nonce in her
private memory. If the queue, Q, was previously empty, Alice stores
the old tail nonce, t, as the new head nonce, h.
To process a dequeue operation, we issue a get(k ) operation,
where k = (Q, h) and h is the current head nonce that Alice stores
in her private memory. This get(k ) returns as its value a pair, (x, t′),
where x is the oldest element and t′ is the nonce used in the key for
the next element in the queue (unless there is none). We return x to
Alice as the actual result of her dequeue() operation. If the queue,
Q, becomes empty, then we generate a new tail nonce, t, and set
h = null. Otherwise, if the queue Q is not empty, we have Alice
store the nonce, t′, as the updated head nonce, h, for the queue, Q.
The access sequence of put(k, v) and get(k ) operations this
transformation creates is isogrammic, because (1) each get(k ) has
a previous put(k, v) operation, (2) we never have two put(k, v)
operations with the same key, k, and (3) each key, k, includes a
unique random nonce. Moreover, it adds O (1) put(k, v) and/or
get(k ) operations for each enqueue(x ) or dequeue operation.
Session 16: Applied Crypto 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea7051/2
1/2
B A BRIEF REVIEW OF FUSION TREES
A fusion tree data structure [2, 8] is a B-tree (e.g., see [5]) that has a
branching factor of O (w
) and utilizes compressed internal nodes
that can each be represented using O (w ) bits. That is, each internal
node in a fusion tree can be represented with a single memory word
of size w while nevertheless achieving a branching factor that is
); hence, the depth of a fusion tree is O (log n/ log w ). Fur-
O (w
thermore, we can use fusion trees in our client-server model, for thin
clients, because a message block stores O (1) words in this model
when B = O (1), which is a part of our definition of a thin client.
Moreover, all the standard search and insert/delete operations can
be performed on a fusion trees in O (logw n) = O (log n/ log w ) I/Os
using bit-level parallel instructions on the word-size nodes that
make up the internal and external nodes in the tree. Since such
bit-level parallel operations would be performed by the client, Alice,
in her private memory during any ORAM simulation or oblivious
storage scenario, let us not concern ourselves here with their details
other than to observe that from the perspective of the server, Bob,
the I/Os for searching a fusion tree would look like Alice requesting
O (log n/ log w ) memory cells (and we can define the tree so that
each leaf node has the same depth, so the number of nodes accessed
is always the same for each access or update operation).
C OMITTED PROOFS
Proof. (Theorem 1.) We already established the claims for
performance and the result being isogrammic. For the security
claim, consider a simulation of the security game mentioned in the
introduction, assuming the statistical security for isogrammic OS.
That is, assume Bob creates two access sequences, σ1 and σ2, and
gives them to Alice, who then chooses one at random and simulates
it. For each access to a memory index, i, in the RAM simulation
for her chosen σj, the memory cell for i is read and written to by
doing a search in R. The important observation is that this access
consists of O (log n) accesses a root-to-leaf sequence of nodes of R,
indexed by newly-generated independent random numbers each
time. Thus, nothing is revealed to Bob about the index, i. That is,
the number of accesses in Alice’s simulation is the same for σ1 and
σ2, and the sequence of keys used is completely independent of
the choice of σ1 or σ2. Thus, Bob is not able to determine which of
these sequences she chose with probability better than 1/2.
□
Proof. (Theorem 2.) For the I/O overhead bounds, note that
each search or update in F requires O (log2
n/ log w ) I/Os plus
the amortized I/O overhead for rebuilding steps. Moreover, each
access causes us to add D = O (log n/ log w ) nodes to the top-
level cache, Cℓ, for the nodes in the search set, π. To account for
rebuilding steps, note that the rebuilding of Ci occurs each n/2i
steps. Thus, in the case of constant-size client-side private memory,
the total I/O overhead for n searches or updates (which then cause
a reinitialization), is proportional to O (n log2
n/ log w ) plus at most
ℓ(cid:88)
i =0
2i (D + 1) log n ≤ n(D + 1) log2
2i n
n
= O (n log3
n/ log w ).
In the case of client-side private memory that is of size O (nϵ ),
the total I/O overhead for n accesses (which then cause a reinitial-
ization), is proportional to O (n log2
n/ log w ) plus at most
ℓ(cid:88)
i =0
2i (D + 1) ≤ n(D + 1) log n
2i n
= O (n log2
n/ log w ).
The security claim follows from the fact that we always access the
same number of nodes with each access, for a given capacity, n,
for the fusion tree, and that we never access any node a second
time without caching it. Thus, in the security game, Bob is not
able to distinguish between two access sequences chosen by Alice.
The probability claim follows from the fact that oblivious shuffling
is based on obliviously sorting items with random keys of O (w )
bits.
□
Proof. (Lemma 3.) The expected value of f , which can be
expressed as a sum of independent indicator random variables,
is at most L/W = d logc−1/2
n, for constants c, d ≥ 3. Thus, by a
Chernoff bound (e.g., see [15]),
Pr( f ≥ 4L/W ) ≤ e
−L/W ≤ e
−d logc−1/2 n ≤ n
−3 log3/2 n .
The probability bound argument for a leaf in H is similar. The
lemma follows, then, by a union bound across all nodes of H and
the polynomial length of access sequences.
□
Proof. (Theorem 4.) The height of the tree, H, is O (log n/ log w ).
Thus, by Theorem 2, the I/O overhead in the case when M = O (1)
and B = O (1) is proportional to
log n
log w
· log3
L
log w
,
which, since L = O (logc n) and w = Θ(log n), is O (log n log log n).
In the case when M = O (1) and B = O (logϵ n), by Theorem 2, the
I/O overhead is proportional to (log n/log w )· (log2
L/log w ), which
is O (log n).
For the security claim, consider an instance of the simulation
game, where Bob chooses two isogrammic access sequences, σ1 and
σ2, of length N for a key set of size n, and gives them to Alice, who
then chooses one uniformly at random and simulates it according
to the isogrammic OS scheme. Each access that she does involves
accessing a sequence of nodes of H determined by random keys
and for each node doing a lookup in an OS scheme that is itself
statistically secure, by Theorem 2. In addition, put operations add
items at the top bucket and are obfuscated with data-oblivious flush
operations. Therefore, Bob is not able to distinguish between σ1
and σ2 any better than at random.
□
Proof. (Theorem 5.) By Theorem 1, each access in A gets
expanded into O (log n) operations in an isogrammic access se-
quence, and, with high probability, each such operation has over-
head O (log n log log n), if M = O (1) and B = O (1), or O (log n), if
M = O (logϵ n) and B = O (1), by Theorem 4. The security claim
follows from the security claims of Theorems 1 and 4.
□
Session 16: Applied Crypto 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea706