# The Good, the Bad, and the Ugly: Stepping on the Security Scale

**Author:** Mary Ann Davidson  
**Oracle Corporation**  
**Redwood Shores, California**  
**Email:** [PI:EMAIL]  

## Abstract
Metrics are both fashionable and timely. Many regulations that impact cybersecurity rely on metrics—often in the form of checklists—to ensure compliance. However, the most effective use of security metrics extends beyond mere regulatory compliance. These metrics can be used to:

- Focus scarce resources on the most pressing problems with the highest potential for resolution.
- Make a compelling business case for necessary changes.
- Identify issues early or recognize successes promptly.
- Address external concerns or criticisms fairly and objectively.

A successful security metric should:
- Encourage good behavior (not just actions to make the numbers look good).
- Prompt additional questions (e.g., "Why? How?") to understand the underlying factors.
- Answer basic questions about performance (e.g., "Are we doing better or worse?").
- Be objective and measurable, even if correlation does not imply causation.

With the increasing regulation of information through acts like the Federal Information Security Management Act (FISMA) and Sarbanes-Oxley, organizations often need to provide measurable proof points to independent auditors. The US Federal Government is also emphasizing security metrics through initiatives such as the Federal Desktop Core Configuration (FDCC) and the development of security measurement schemes like Common Weakness Enumeration (CWE) and Common Vulnerabilities and Exposures (CVE).

Information security naturally lends itself to measurement, especially given the challenges in determining "How much security is enough?" and "Am I doing the right things?" Security professionals must have a clear understanding of critical systems and their security readiness, including patch levels and secure configuration status.

While fads are not a good reason to adopt a business practice, there are strong reasons to implement security metrics. A well-designed metrics program can help manage more effectively. For example, former New York City Mayor Rudy Giuliani improved the city's governance and livability through a robust metrics program.

This paper explores the qualities of effective security metrics and their application in security vulnerability handling and software assurance programs.

**Keywords:** Security metrics, vulnerability handling, software assurance

## 1. Why Security Metrics?

Many management fads come and go, but the current trend in IT security is the use of metrics. This is not unusual, as businesses generally rely on measurements as key management indicators. Financial statements and ratios like earnings per share (EPS), net present value (NPV), and internal rate of return (IRR) are all forms of external metrics. IT, being a business enabler, should be subject to similar management oversight, including appropriate measurement.

Metrics can be either external or internal. External metrics are often focused on presenting a positive image, while internal metrics aim to improve management. If metrics do not help an organization be honest with itself, they are of little value.

## 2. Implementing a Metrics Program

Implementing a metrics program requires resources, including time, money, and people. Given that most organizations have limited resources, it is crucial to consider the value of the information captured by the metrics. Not all data is worth collecting; the cost of obtaining a metric should be weighed against its value. If capturing and analyzing data will not lead to better decision-making or management, it is better to focus on other, more valuable metrics.

A good starting point for a metrics program is to mine existing data. Many organizations already track various aspects of their IT systems, such as help desk tickets and configuration management actions. This data can be incorporated into a metrics program. Creating a metrics plan that prioritizes what else you want to know, how to obtain that information, and how to use the data is essential.

For example, at Oracle, the security metrics program for software assurance focuses on security vulnerability handling. The foundation of this program is the Oracle bug database, which already tracks and resolves bugs. Security bugs are flagged separately and not published to customers to avoid putting them at risk. The security metrics wiki, which analyzes security vulnerability trends, is based on this bug database. The goal is to reduce the rate of serious security defects and prevent vulnerabilities, which directly impacts Oracle's security brand and represents a significant cost to the company and its customers.

In the short term, it is important to ensure that:
- Security vulnerabilities are handled promptly.
- The backlog of unfixed security vulnerabilities is not growing.
- Most security vulnerabilities are found internally rather than by customers or third-party researchers.

Focusing metrics on vulnerabilities is practical because development already has many metrics around development processes. The primary goal of the security metrics wiki is to give developers the tools they need to manage their own workload. A self-policing model, where developers have the tools to manage their own work, is preferable to a "security police" model.

## 3. Encouraging Positive Behavior

A challenge in a metrics program is creating measurements that not only provide useful information but also incentivize the correct behavior. Correct behavior can be demonstrated by positive trends (e.g., fewer security defects) or by hygiene metrics (e.g., the number of people who have completed mandatory security training). While these metrics may not always prove a direct cause and effect, they are still considered positive achievements.

It is important to ensure that metrics are fair and not easily manipulated. Poorly designed metrics can lead to unintended and often perverse side effects. For example, one Oracle development organization used to run bug reports every Friday at noon. Product managers would temporarily close bugs to make the numbers look good, then reopen them later. This "gaming" behavior made the metric unusable.

Using a "point in time" metric instead of analyzing overall trends or triangulating multiple data points can lead to such gaming. Effective metrics should be designed to encourage the right behavior and provide a true picture of the situation.

---

This revised version aims to enhance clarity, coherence, and professionalism while maintaining the original content and intent.