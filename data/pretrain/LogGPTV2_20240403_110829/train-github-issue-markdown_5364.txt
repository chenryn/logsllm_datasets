Hello,
I've stumbled onto a behavior that causes performance problems on large
datasets: When creating a multiindex with second level being a DateTime64 col,
and then doing a `.loc[('val1', TimeStamp('val2'),)]` to get at particular
value, pandas coerces (via _box_func, called from **iter** ) all values in
that particular column to TimeStamp dtype. This is done only on first access,
but affect performance quite heavily since the op is O(n).
However, when chaining the same op (or calling it via multi-level `.xs`, this
behavior is not exhibited. It is not a viable workaround however because doing
so introduces an extra call to getitem per each level of multiindex.
Is there a workaround for this or what am i doing wrong?  
In essence, given a df with unique multiindex, i want to get to a particular
row given values for each level of the index.
Repro:
    df = 
    gr = df.groupby(('colA', 'colB',))
    ag = gr.aggregate({'colC':'sum'})
    path = ('one', pd.TimeStamp('2015-01-01 01:02:03'),)
    ag.loc[path] # << first call iterates over entire dataset doing the conversion, and is slow
    ag.loc[path] # << second call is very quick
    ag.xs(path, levels=('colA','colB',)) # << this takes a different code path but does an extra call to getitem, making it slower.
Other things:
  * padding numpy.datetime64 into the path tuple instead of timestamp doesnt help
  * specifiying axis for loc doesn't help