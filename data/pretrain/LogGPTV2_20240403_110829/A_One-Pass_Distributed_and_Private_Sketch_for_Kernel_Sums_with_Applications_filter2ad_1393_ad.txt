200). We preprocess the nursery and occupancy datasets by us-
ing integer coding for the categorical attributes. We also scale the
features of our linear regression datasets so that the training data
lies in the unit sphere, as this is required for some of our baseline
algorithms to have good performance. Here, our main objective
is to show that these machine learning tasks can be performed
using only the private RACE summary. To show that the private
RACE sketch can be used to obtain reasonable machine learning
models, we compare the performance on a test set with well-known
methods to privately train linear and logistic models.
Hyperparameters: Our goal is to provide a fair comparison that
shows the performance of each algorithm under high-performing
hyperparameter settings. For kernel density estimation and max-
likelihood classification, we use the p-stable Euclidean LSH kernel,
which closely resembles the exponential kernel. We chose the ker-
nel bandwidth based on the scale of the features in the dataset. For
example, we selected σ = $5k as a reasonable level at which to
distinguish annual salaries and σ = 5 as a significant difference in
the distance between RGB color tones. We provide detailed infor-
mation about hyperparameter tuning for each algorithm below. It
should be noted that in practice, the privacy loss incurred by the
hyperparameter tuning process affects the end-to-end differential
privacy budget. However, an end-to-end evaluation is outside the
scope of our experiments. Although we do limit the number of hy-
perparameter settings for each algorithm (i.e. we avoid exhaustive
grid search, which is utterly infeasible in practice), our goal is to
compare algorithm performance and computation costs under opti-
mal parameter configurations. Therefore, the values of ϵ reported
in our experiments are the privacy loss of the best-performing con-
figuration rather than the total privacy loss for all configurations
that were considered.
5.1 Baseline Algorithms
We consider the following algorithms in our evaluation. To give a
fair comparison, we profiled and optimized each of our baselines.
Unless otherwise specified, we implemented each algorithm in
Python.
Spectral Approximation: We approximate the kernel density
function with a Fourier series, truncate the series expansion, and
add Laplace noise to each coefficient. We release the noisy co-
efficients as the function summary. This algorithm is otherwise
known as the orthogonal series estimator [22, 46]. Due to the high-
dimensional Bravais lattice used for the Fourier Transform, the
memory footprint of spectral approximation scales poorly. As a re-
sult, we were only able to apply this method to our one-dimensional
salary datasets. Spectral approximation requires that the dataset
lie within the interval [0, 1] - we scale the salaries by 250k to sat-
isfy this condition. The method takes one hyperparameter M, the
number of basis functions, which we select from [2, 4, 8, 10, 20].
Bernstein Mechanism: This method is also based on func-
tion approximation, but uses Bernstein polynomials rather than
the Fourier basis [3]. The coefficients of the Bernstein interpo-
lation are released on a high-dimensional grid via the Laplace
mechanism, where the number of grid points M is user-specified.
While M scales exponentially with dimensions, the coefficients
can be computed in parallel using linear memory. We consider
M ∈ {2, 4, 8, 10, 20, 40, 100}, but were unable to evaluate M > 20
for the skin and codrna datasets due to computational limitations.
The Bernstein mechanism requires that the dataset lie within the
unit hypercube, so we scale the datasets accordingly.
Private Functional Data Analysis (PFDA): We use the PFDA
algorithm from [31], to release an estimator for the KDE. PFDA
guarantees (ϵ, δ) differential privacy, as it uses the Gaussian mecha-
nism. For all experiments, we use δ = 0.01. PFDA uses a smoothing
hyperparameter ϕ, which we set to 0.01 as suggested by the paper.
We used the R implementation from [31] but were unable to run
the algorithm on high-dimensional datasets.
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3259Kernel Mean Embedding (KME): This baseline method uses
the kernel mean embedding to generate a synthetic database. Data
release via KME involves weighting the synthetic database so that
the kernel mean embedding of the synthetic public database is close
to the embedding of the private database. We use the Python code
released by [5] in our experiments. The method has two hyperpa-
rameters: the distribution of the synthetic points and the number M
of synthetic points. Where possible, we use information about the
dataset to inform the distribution of synthetic points because this
can substantially improve the performance of KME. For example,
all skin tone value are between 0 and 255, so we adjust the mean
and standard deviation of the public synthetic dataset to cover this
range. We choose M from [5k, 10k, 20k, 40k, 100k].
PrivBayes: PrivBayes [50] is a recent synthetic database release
algorithm that draws samples from a private Bayesian network
that models the correlations between features in the data. We use
PrivBayes to release synthetic datasets for our KDE and regression
experiments. However, we were unable to evaluate PrivBayes on the
128-dimensional gas dataset, as it took > 6 hours to construct the
high-dimensional conditional distributions and release the dataset
for each value of ϵ. We use the code provided by [50] and optimize
two hyperparameters: the degree D of the Bayesian network and
the number M of synthetic points. We consider D = [2, 3, 4, 5] as
suggested by the paper and M = [5k, 10k, 20k, 40k, 100k].
Synthetic Data from Histograms: For our salary datasets, we
constructed a simple baseline method that draws samples from a
Laplace-perturbed histogram. We begin by releasing a differentially
private histogram using standard techniques [32], and construct
a weighted synthetic dataset from the histogram bin centers and
values. This algorithm is not effective for high dimensional data
due to limitations that are inherent to histogram-based methods.
Objective Perturbation: Objective perturbation is a general
technique for differentially private empirical risk minimization [8].
The algorithm first perturbs the loss function to preserve privacy,
then trains a model using the modified version of the loss. The
model can then be released with ϵ-differential privacy. We use the
technique to train a regularized logistic classifier for our classifi-
cation experiments and to release linear regression models for our
regression experiments. For our logistic classifier, we select the
regularization hyperparameter from λ = [0.01, 0.1, 1.0, 2.0] based
on test set performance.
SSP and AdaSSP: Sufficient statistics perturbation and the new
adaptive version of the algorithm are specialized algorithms for
linear regression which privately release a set of sufficient statistics
to compute the linear model. The algorithms essentially release
private projections of X⊤X and Xy. We use the MATLAB imple-
mentations provided by [43].
OPS and AdaOPS: Posterior sampling (OPS) [44] and the adap-
tive version proposed by [43] are algorithms which privately sample
from a Bayesian posterior and use the sample to obtain the model.
We use the MATLAB implementations provided by [43]. Note that
the AdaSSP and AdaOPS methods do not require hyperparameter
tuning.
RACE: We implemented RACE using Python and NumPy to
batch-process the hash calculations. For our KDE experiments, we
used W = 1000 and selected R using the procedure described in Sec-
tion 3.3. In practice, the hyperparameter search process amounted
to building RACE sketches with R = [100, 200, 500, 1000, 2000] and
selecting the best sketch. For our classification experiments, we
construct max-likelihood classifiers using RACE to estimate the
likelihood functions. We used W = 100 for all sketches and selected
R from R = [10, 20, 50, 100, 200] because these datasets have smaller
N . These experiments were mostly done with binary-coded cat-
egorical data on the unit hypercube. Therefore, we selected the
bandwidth parameter via binary search of the interval [0, 1]. For
our regression experiments, we use the surrogate loss described in
Section 4 with R = 1000 and W = 16 (for this loss function, W is
determined by the hash function - see [11] for details).
5.2 Results
Figure 3 shows the results of our KDE experiments. On our salary
datasets, we evaluate performance using the L2 function norm
between the approximate KDE and the ground-truth KDE. We query
the SF and NYC datasets on a grid of 200 points ranging from $10k to
$250k. We integrate the squared error over this grid to approximate
the L2 function error. Figure 3 shows the relationship between the
error and the privacy budget. To visualize the functions released
by various methods, we also include a qualitative comparison at
the ϵ = 1.0 privacy budget. For high-dimensional datasets like
skin, covtype and codrna, it is too computationally expensive to
integrate the density over the entire domain. Instead, we query
these datasets using a test set of 2000 query points and report the
average relative (percent) error. Figure 7 shows the results of KDE
on the covtype dataset. While RACE ran in under 2 minutes, we
needed to apply sampling to get the baselines to run in less than 6
hours. Figure 4 shows the results of our classification experiments,
and Figure 5 shows our linear regression experiments. In both
sets of experiments, we privately train the model and evaluate
performance on a held-out test set.
Computation: Table 3 displays the computation time needed
to construct a useful function release. Note that Bernstein release
can run faster if we use fewer interpolation points (see Table 1), but
we still required at least 12 hours of computation for competitive re-
sults. The Bernstein mechanism requires many binomial coefficient
evaluations, which were expensive even when we used optimized
C code. KME required a large-scale kernel matrix computation, and
PFDA required several days for an expensive eigenvalue compu-
tation. Although PrivBayes ran well for skin (d = 3 dimensions),
the runtime of the algorithm rapidly degrades in high dimensions.
In particular, it took several hours to release synthetic databses for
the naval and gas regression datasets.
6 LARGE SCALE EXPERIMENTS
To test the scaling capacity of our algorithm, we consider kernel
density problems on the graphs from the Stanford Network Analysis
Project [26]. In the context of social networks, the Jaccard kernel is
a measure of the local edge density near the query node [37]. Since
well-connected nodes have high density, a differentially private
Jaccard sum reveals whether a query node is part of a community
without disclosing the presence of any particular data node.
Parallel Construction: We use OpenMP in C++ to distribute
the sketching algorithm over 90 threads and merge the sketches.
We implement the algorithm as a data-parallel operation, where
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3260Figure 3: Privacy-utility tradeoff for private function release methods. We report the L2 function error and the mean relative
error for 2000 held-out queries.
Figure 4: Binary classification experiments. We show the privacy-utility tradeoff for a private logistic regression classifier and
the RACE max-likelihood classifier. Average over 10 repetitions.
we divide the dataset evenly among the 90 threads. We merge the
sub-sketches by adding the corresponding integer counters. We add
the Laplace noise Lap(Rϵ−1) to the sketch of the complete dataset
after merging is finished.
Results: Figure 6 shows the mean error between our sketch
and fD. It should be noted that computing the ground truth sums
took several weeks for the Friendster graph, while our sketching
algorithm runs in a mere 18 minutes with microsecond queries
(Table 4). Unfortunately, we were unable to compare against base-
line methods due to the dimensionality and size of the graphs. For
example, each row of the Friendster graph (N = 65M) is a sparse
binary vector with 65 million dimensions. Even if we were able to
project this vector to a subspace embedding of 100 dimensions, the
Bernstein mechanism and KME release would be infeasible because
they require many kernel sum calculations.
7 EXTENSIONS
The RACE framework can be extended to accommodate private
distributed sketching, exotic LSH kernel compositions, and the use
of public data to improve the private algorithm.
7.1 Learned Hash Constructions
Until now, we have only considered collision probabilities k(x, q)
that have an analytic closed-form expression. We focused on simple
LSH functions because they allow us to derive concise theoretical
expressions for the estimation error of fD. However, the space of
LSH kernels contains a wide variety of exotic kernels.
There are two ways to extend the RACE framework to work for
more values of k(x, q). The first method is to construct a new ker-
nel by combining existing LSH functions, using the concatenation
50100150200250Salary ($k)0.0000.0250.0500.0750.1000.1250.1500.1750.200Density EstimateSF Density Approximation (ε=1.0)Ground TruthSpectralKMEPFDABernsteinPrivBayesSyntheticRACE50100150200250Salary ($k)0.000.050.100.150.20Density EstimateNYC Density Approximation (ε=1.0)Ground TruthSpectralKMEPFDABernsteinPrivBayesSyntheticRACE10−510−410−310−210−1100101Privacy (ε)1011031051071091011L2 Function ErrorSF (d = 1, N = 29k)SpectralKMEPFDABernsteinPrivBayesSyntheticRACE10−510−410−310−210−1100101Privacy (ε)1021041061081010L2 Function ErrorNYC (d = 1, N = 25k)SpectralKMEPFDABernsteinPrivBayesSyntheticRACE10−610−410−2100102Privacy (ε)10−1101103105Relative Errorcodrna (d = 8, N = 57k)KMEBernsteinRACEPrivBayes10−410−310−210−1100Privacy (ε)10−1100101102103Relative Errorskin (d = 3, N = 241k)KMEBernsteinRACEPrivBayes10−310−210−1100101Privacy (ε)0.50.60.70.8AccuracyNomao (d = 26, N = 34k)LogisticRACEMajority10−610−410−2100Privacy (ε)0.30.40.50.60.70.80.91.0AccuracyPulsar (d = 8, N = 17k)LogisticRACEMajority10−610−410−2100Privacy (ε)0.20.30.40.50.60.70.80.91.0AccuracyOccupancy (d = 5, N = 17k)LogisticRACEMajoritySession 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3261Figure 5: Linear regression experiments. We show the privacy-utility tradeoff for RACE and several other linear regression
methods. Average over 10 repetitions.
Graph
Friendster
Google Plus
Slashdot
N
65M
72.3K
82.2K
Edges
1.8B
13M
948K
Sketch
18.1 min
31 sec
25 sec
Query Baselines
> 1 week
164 µs
238 µs
> 1 week
> 1 week
157 µs
Table 4: Large-scale datasets used for graph experiments.
The sketch time is reported for our parallel sketch imple-
mentation. Query times are an average over ≈2k queries.
We were unable to run baseline methods on problems of
this size, but based on rough calculations we estimate that
it would take weeks to perform function release on these
datasets with baseline algorithms.
in the deep learning community that hash functions can be learned
to improve performance in recommender systems and information
retrieval. For example, many algorithms learn embeddings of docu-
ments, images, users or words. If these embeddings are later hashed
using an LSH function, the RACE sketch estimates a transformed
version of the collision probability:
Pr[l(д(x)) = l(д(y))] = k(д(x), д(y))
Here, д(x) is a transformation that alters the shape of the LSH
kernel. We could design д(x) explicitly, but we can also learn д(x)
from arbitrary inputs by considering a regression problem that fits
k(д(x), д(y)) to the desired function.
7.2 Access to Public Data
A recent trend in differential privacy is to consider the situation
where we have free access to a (small) public dataset and wish
to answer queries about a (large) private dataset. In practice, this
situation may arise if some users voluntarily disclose information
publicly. Several recent works address the question of whether it is
possible to improve our private queries using the publicly-available
information. For example, the Public-Assisted Private framework
of [6] provides a way to characterize the number of public samples
that are required to improve private learning algorithms whose
hypothesis classes obey specific constraints.
The KME paper considers a similar problem, where we are asked
to release a synthetic database but are allowed to freely use a public
subset of the data. For the RACE sketch, public data can be exploited
Figure 6: Approximating the Jaccard KDE over large social
network graphs. We use R = 2k and W = 100k except for
Friendster, where we use W = 500k.
techniques discussed in [11]. One can obtain a private RACE sketch
for any k(x, q) that is a linear combination or product of LSH ker-
nels. To identify the specific components of the new hash function,
one could perform an exhaustive search, use mixed-integer linear
programming over the space of kernel functions, or apply standard
techniques for basis function decomposition.
However, another way to construct the hash function is to adopt
methods from the learning to hash literature [42]. It is widely known
Figure 7: RACE can approximate high-dimensional, large
kernel sums. To run Bernstein or KME, we must sub-sample
the data to N = 100k and apply dimensionality reduction to
d < 10.
10−1100101Privacy (ε)10−410−310−210−1100101102103104MSEAirfoil (d = 5, N = 1.4k)Non-privateTrivialSSPObjPertOPSAdaSSPAdaOPSPrivBayesRACE10−1100101Privacy (ε)10−610−410−2100102104MSENaval (d = 16, N = 11k)Non-privateTrivialSSPObjPertOPSAdaSSPAdaOPSPrivBayesRACE10−1100101Privacy (ε)10−610−410−2100102104MSEGas (d = 128, N = 3.6k)Non-privateTrivialSSPObjPertOPSAdaSSPAdaOPSRACESession 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3262by learning the hash function on the public data points. For example,
we can improve our max-likelihood classifier by learning a hash
function that causes samples from the same class to collide more
frequently with each other than with other classes. There are many
standard techniques to learn this type of hash function; see [42] for
a comprehensive review.
7.3 Private Distributed Sketching
From a computational perspective, our sketch already possesses
the three critical properties that make sketches ideal for distributed