0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
rel. error
rel. error
rel. error
Figure 11: CDF of the relative of several LDS parametrizations under varying uniform loss rates. Solid lines
represent ﬂows with at least 103 packets, while dashed lines, ﬂows with more than 100 packets.
too quickly invalidated under increasing loss, causing mea-
surements to be lost.
In contrast, the multi-bank LDS performs consistently
well under all loss rates. This desirable behavior is a con-
sequence that, in all three scenarios, most ﬂows experience
losses that are well tolerated by at least one of the banks.
Therefore, very seldom a ﬂow invalidates all of its buckets,
and accurate measurements are always produced.
The accuracy of LDS in Fig. 11 is still above that of RLI
and MPE without loss (as presented in Sec. 5.1). However,
MPE and RLI are more robust to loss. Hence, in scenarios
with high loss and temporal correlation, we expect MPE and
RLI to be a better choice.
5.3 Flow Weighting
We now test a more realistic use case of our technique.
We envision a data center that hosts network services for a
series of customers. Not all customers, though, are equally
sensitive to network delay. We group the hosted services in
three classes. First, bronze customers are not overly con-
cerned about packet delays in the data center. For example,
those could include bulk data transfer applications, such as
backup, static web content serving, e-mail relaying, or com-
puting intensive tasks.
Second, silver customers are somewhat dependent on net-
work delay, but they do not require strict compliance of low-
delay QoS requirements. A class that would ﬁt these well
are interactive services, such as remote shells, highly inter-
active web applications (e.g., Google is known to seek low
delay to enhance the user’s browsing experiences of AJAX-
powered web applications), or web services for third party
applications.
Finally, gold customers host applications that are extremely
sensitive to delay, and wish to closely track the QoS of the
services they are oﬀering. Perfect examples for this class
of applications involve multi-media streaming, audio/video
conferencing, or remote gaming. Financial services such as
automated trading could also ﬁt this category, although,
given that, in their case, low-delay data transmission is crit-
ical, they are unlikely to be hosted in shared infrastructure.
Since we do not have access to network traﬃc from a data
center that hosts such applications, we adapt our scenario
as follows. We randomly assign each ﬂow to one of the cat-
egories. Bronze customers take 90% of the ﬂows; silver cus-
tomers, 9%, and gold customers, 1%. This approach ensures
that the results are not an artifact of ﬂow sizes, since large
ﬂows tend to be more accurately measured. In a real setting,
these weights can be adjusted to the speciﬁc characteristics
of the traﬃc under measurement.
We experiment with diﬀerent sizings of the data structure,
and various weights for each of the customer classes. Fig-
ure 12 shows the result of a series of experiments. We have
tested two reference conﬁgurations. One that uses 40,000
counters (ﬁrst row), an another that uses 100,000 counters
and provides greater accuracy (second row). The ﬁrst con-
ﬁguration ﬁts in 625KB, and the second, in around 1.5MB.
As for ﬂow weights, we have tested three diﬀerent conﬁg-
urations, which can be observed in each column: assigning
weights of 1, 25 and 100 (ﬁrst); 1, 10 and 100 (second), and,
1, 50 and 2500 (third).
The ﬁgure shows the relative error for the full set of ﬂows
(solid lines) and only for ﬂows with more than 100 pack-
ets (dashed lines). Besides the error of each customer class,
the ﬁgure also shows, as a reference, the result of apply-
ing no weighting. An important observation to be made
is that ﬂows from classes that have higher weights obtain
signiﬁcantly greater accuracy. The accuracy boost greatly
depends on the actual weights; for example, when gold cus-
tomers carry weight 2500, they obtain extreme accuracy.
However, this penalizes the accuracy of bronze customers.
In this case, we have ensured that the accuracy of bronze
customers is not highly penalized, because few ﬂows belong
to higher priority classes. If, otherwise, the number of ﬂows
in each class was more balanced, the only option to increase
accuracy for the ﬂows of a given class without signiﬁcantly
diminishing that of a lower priority class would be to in-
crease the sketch size. In other words, this method is only
applicable to increase the accuracy of a small subset of ﬂows.
6. RELATED WORK
One-way packet delay has been measured both using pas-
sive and active schemes. Active monitoring methods (e.g.,
[5, 24, 6, 28]) are based on injecting probe traﬃc in the
network under study, and inferring one-way delay from the
delays incurred by such probes. In contrast, passively mon-
itoring network delays has been traditionally accomplished
by recording packet timestamps in two measurement points,
and exchanging such timestamps for comparison. Because
these techniques generate huge data volumes, they require
aggressive sampling to reduce the overhead. Further, packet
sampling has to be coordinated across nodes, since the times-
tamps recorded at both measurement points must corre-
49410000x4 sketch
10000x4 sketch
10000x4 sketch
)
z
(
x
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
gold (weight 100)
silver (weight 25)
bronze (weight 1)
no weighting
)
z
(
x
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
gold (weight 100)
silver (weight 10)
bronze (weight 1)
no weighting
gold (weight 2500)
silver (weight 50)
bronze (weight 1)
no weighting
0.00
0.05
0.10
0.15
0.20
0.25
0.00
0.05
0.10
0.15
0.20
0.25
0.00
0.05
0.10
0.15
0.20
0.25
25000x4 sketch
25000x4 sketch
25000x4 sketch
)
z
(
x
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
gold (weight 100)
silver (weight 25)
bronze (weight 1)
no weighting
)
z
(
x
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
gold (weight 100)
silver (weight 10)
bronze (weight 1)
no weighting
gold (weight 2500)
silver (weight 50)
bronze (weight 1)
no weighting
)
z
(
x
)
z
(
x
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
0.00
0.05
0.10
0.15
0.20
0.25
0.00
0.05
0.10
0.15
0.20
0.25
0.00
0.05
0.10
0.15
0.20
0.25
Figure 12: CDFs of the relative error with various ﬂow weights and sketch sizes. Solid lines correspond to
ﬂows with more than 100 packets, while dashed lines include the full set of ﬂows.
spond to an equal subset of all packets. This eﬀect can
be achieved using consistent hashing, i.e., using same pre-
arranged hash function—an idea used before in trajectory
sampling [11]).
More recently, LDA [17] has been proposed as a mecha-
nism to overcome the linear relationship between sample size
and overhead. LDA has been further analyzed in [27, 14] as
well. Since our paper borrows some of the ideas of LDA,
we have discussed this idea in great length. The problem
of obtaining per-ﬂow latency estimates in a scalable fashion,
which is exactly the problem we attempted to solve in this
paper, has received recent attention [18, 19].
[19] proposes
modifying NetFlow [7] to allow measurement of one-way de-
lay.
If NetFlow samples packets using consistent hashing,
the ﬁrst and last timestamp ﬁelds of NetFlow records can be
used to obtain two delay samples of a given ﬂow that can be
reﬁned from using samples from other ﬂows in between these
two timestamps. The core idea of temporal delay correla-
tion forms the basis for Reference Latency Interpolation [18],
that we also discussed in detail in the paper. The biggest
diﬀerence between RLI and our work is that we do not as-