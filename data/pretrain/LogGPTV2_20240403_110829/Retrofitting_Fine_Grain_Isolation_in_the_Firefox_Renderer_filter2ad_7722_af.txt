an overhead of 13%. As a comparison point, the overhead of
naively using process sandboxes (using only conditional vari-
ables without any CPU pinning) incurs an overhead of 167%.
We ﬁnd the average peak renderer memory overhead
to be 25% and 18% for the SFI and Process sandboxes,
respectively. This overhead is modest and, more importantly,
transient: we can destroy a sandbox after the media has been
decoded during page load.
USENIX Association
29th USENIX Security Symposium    711
yelp.comeurosport.comlegacy.comreddit.comseatguru.comtwitch.tvamazon.comeconomist.comespn.comwowprogress.com0246810Page load (sec)StockSFIProcessyelp.comeurosport.comlegacy.comreddit.comseatguru.comtwitch.tvamazon.comeconomist.comespn.comwowprogress.com020040060080010001200Peak memory (MB)7.4.2 Sandboxing video and audio decoding
To understand the performance overhead of RLBox on video
and audio decoding, we measure the performance of Firefox
when decoding media from two video formats (Theora and
VPX) and one audio format (OGG-Vorbis).
Benchmark. Our benchmark measures decoding perfor-
mance on the Sintel sequence in Xiph.org’s media test suite8.
As this sequence is saved as lossless video, we setup the bench-
mark by ﬁrst converting this to ultra HD videos of 4K resolu-
tion in the Theora and VP9 formats; we similarly convert the
lossless audio to a high resolution OGG-vorbis audio ﬁle with
a sample rate of 96 kHz and a bit rate of 500 Kb/s using the
suggested settings for these formats [57, 59]. Our benchmark
then measures the frame-rate and bit-rate of the video and
audio playback—by instrumenting the decoders with timers—
when using the sandboxed libraries. We run the test 5 times
and report the median values of frame-rate and bit-rate.
Results. We ﬁnd that neither the SFI nor the Process
sandboxing mechanism visibly degrades performance. In
particular, our sandboxed Firefox are able to maintain the
same frame-rate (24 fps for the VPX video and 60 fps for
the Theora video) and bit-rate (478 bits per second) as stock
Firefox for these media ﬁles.
7.5 Microbenchmarks of RLBox in Firefox
To understand the performance impact of RLBox on the
different libraries, we perform several microbenchmarks that
speciﬁcally measure the impact of sandboxing webpage de-
compression, image decoding and sandbox scaling in Firefox.
7.5.1 Sandboxing webpage decompression
Firefox uses zlib to decompress webpages. Since webpage
decompression is done entirely before the page is rendered,
we report the overhead of sandboxing zlib by measuring the
slowdown in page load time.
Benchmark. We create a webpage whose HTML content
(excluding media and scripts) is 1.8 MB, the size of an av-
erage web page9, and measure the page load time with Talos.
We use the median page load time from 1000 runs of this test.
Results. For both SFI and Process sandboxing mechanisms,
the overhead of sandboxing zlib is under 1%. In other words,
the overhead of sandboxing zlib is largely offset by other
computations needed to render a page.
7.5.2 Sandboxing image decoding
To understand performance impact of sandboxing on image
rendering, we measure per-image execution time for the .jpeg
and .png decoders, with different forms of sandboxing, and
compare our results to stock Firefox. Decoder execution time
is a better metric for image rendering performance than page
8Online: https://media.xiph.org/. Last visited November 15, 2019.
9See the HTTP Archive page weight report, https://httparchive.
org/reports/page-weight. Last visited May 15, 2019.
load time because Firefox decodes and renders images asyn-
chronously; the usual test harness would notify us that a page
has been loaded before images have actually been decoded
and displayed in full—and this might be visible to the user.
Benchmarks. We use the open Image Compression
benchmark suite10 to measure sandboxed image decoding
overheads. To capture the full range of possibilities for
performance overhead, we measure overheads of images at
3 sizes (135p, 320p, and 1280p) and three compression levels
(best, default, and none) for each image in the benchmark
suite. We run this test 4000 times for each image and compare
the median decoder code execution times.
Results. Since all images in the suite produce similar results,
we give the results of one 8-bit image in Figure 5. We start
with three high-level observations. First, both SFI and Process
based sandboxes have reasonable overheads—23-32% and
< 41% respectively for most JPEGs, 2-49% and < 15%
respectively for PNGs. Second, Process sandbox sometimes
has negative overheads. This is because the Process sandbox
dedicates one of the two available cores exclusively for
execution of sandboxed code (§6.3) including the sandboxed
image rendering code, while the stock and SFI Firefox builds
use all cores evenly. Third, for JPEGs at the best compression,
the overhead relative to stock Firefox is high—roughly 80%
for SFI and 140% for Process sandboxes. This is because
decoding high compression images have low absolute decode
times (~650µs), and thus have larger overheads as control
transfer overheads between Firefox and the sandbox image
libraries cost are not effectively amortized. However, in
absolute terms, the differences are less than 1.5ms and have
no impact on end-user experience.
7.5.3 Sandbox scaling characteristics
Web pages often contain tens of images of different types
from multiple origins. Thus, the scaling properties of different
isolation mechanisms are an important consideration.
Benchmark. We evaluate sandbox scaling by rendering
pages with an increasing number of JPEG images from unique
origins. Each image thus creates a new sandbox which incurs
both CPU and memory costs. CPU costs are measured by
measuring the total amount of time executing image decoding
functions. We measure memory overhead as before, but don’t
destroy any sandbox; this allows us to estimate the worst
case scenario where memory usage is not transient. As before
(§7.5.2), we measure the decoder execution time for 4000
image loads at each scale, and report the median overhead.
Results. Figure 6 shows the CPU overhead of image
rendering as we increase the number of sandboxes for both
large (1280p) and small (135p) JPEG images using default
compression. This experiment allows us to make several
observations. We can run up to 250 concurrent SFI sandboxes
10Online: https://imagecompression.info/test_images/. Last
visited May 15, 2019.
712    29th USENIX Security Symposium
USENIX Association
(a) JPEG rendering overhead
(b) PNG rendering overhead
Figure 5: Per-image decoding overhead for images at 3 compression levels and 3 resolutions, normalized against stock Firefox.
beyond Firefox, we applied it in two different contexts: the
Apache web server and Node.js runtime.
Apache allows developers to write C modules that extend
its base functionality. These modules often depend on
third-party libraries. For example, the mod_markdown [31]
module uses the libmarkdown library to transform Markdown
to HTML on the ﬂy to support serving Markdown ﬁles.
To protect Apache from bugs in libmarkdown we modify
mod_markdown to run libmarkdown in an RLBox SFI
sandbox. The change required a single person-day, and
added or modiﬁed roughly 300 lines of code. We measured
the average and tail latency as well as throughput of the
webserver using the autocannon 4.4.0 benchmarking tool [2]
with default conﬁgurations (1 minute runtime, 10 parallel
connections) serving a 16K markdown ﬁle. The unmodiﬁed
webserver’s average latency, tail latency and throughput
were 10.5ms, 36ms and 940 requests/second, respectively;
the sandboxed server’s average latency, tail latency and
throughput were 14ms, 40ms and 684 requests/second.
Though the average latency and throughput overhead is
modest, we observe that the tail latency—arguably the most
important metric—is within 10% of baseline.
Node.js is a JavaScript runtime system written in C++,
largely used for web applications. Like Apache, Node.js
allows developers to expose new functionality implemented
in native plugins to the JavaScript code. For example,
the bcrypt [38] password hashing library relies on native
code—indeed the JavaScript code largely wraps Provos’ C
bcrypt library. To protect the runtime from memory-safety
bugs in the C library, we modify the C++ code in bcrypt to
run the bcrypt C library in an RLBox SFI sandbox—a change
that required roughly 2 person hours, adding or modifying
75 lines of code. We measured—using the benchmark.js
library—the overhead in average hashing throughput (hashing
a random 32-byte password) to be modest: 27%.
8 Related work
Isolation in the browser. Modern browsers since Chrome [3]
rely on coarse grain privilege separation [39] to prevent
browser compromises from impacting the local OS [40].
However, a compromised renderer process can still use any
credentials the browser has for other sites, enabling extremely
Figure 6: Performance overhead of image decoding with increasing
the number of sandboxes (each image is rendered in a fresh sandbox).
before we run into limitations like exhausting pre-allocated
thread local storage or ﬁnding aligned free virtual memory.
These limitations can be overcome with more engineering
effort. We never came close to these limits browsing real
websites, including those of Section 7.4.1. Both the SFI and
the Process sandbox similarly scale well on both small and
large images, with CPU overheads between 20% and 40%
for most sandbox counts. The process sandbox, however,
scales only because we use multiple synchronization modes
described (§6).
Extra sandboxes add memory overhead for two reasons.
First, each sandbox uses a private copy of code (e.g., libjpeg
and libc for each libjpeg sandbox). Second, each sandbox
has its own stack and heap. In this experiment, we observed
that memory consumption increases linearly with the
number of images (which corresponds to the number of
sandboxes created). On average, an SFI sandbox consumes
1.6 MB, while Process sandboxing consumes 2.4 MB for
each sandbox. Several optimizations to reduce memory
consumption exist that we have not yet implemented. For
example, the SFI sandbox currently loads a fresh copy of the
code for each sandbox instance. We could optimize this by
sharing code pages between sandboxes—and, indeed, we do
this in production for our Wasm sandbox.
7.6 RLBox outside Firefox
RLBox is a general-purpose sandboxing framework that can
be used in any C++ application. To demonstrate its utility
USENIX Association
29th USENIX Security Symposium    713
-50 0 50 100 1501280pbest320p135p1280pdefault320p135p1280pnone320p135pOverhead (%)SFIProcess-50-25 0 25 501280pbest320p135p1280pdefault320p135p1280pnone320p135pOverhead (%)SFIProcess-20 0 20 40 60 80 1 10 100Overhead (%)Sandbox count (log scale)SFI—large imageProcess—large imageSFI—small imageProcess—small imagepowerful universal cross-site scripting (UXSS) attacks [14].
In response to UXSS attacks and recent Spectre attacks,
Chrome introduced Site Isolation [41]. Site Isolation puts
pages and iframes of different sites into separate processes.
Unfortunately, as discussed in Section 1, this does not prevent
UXSS attacks across related sites (e.g., mail.google.com
and pay.google.com). Firefox’s Project Fission [34]
proposes to go further and isolate at the origin boundary,
similar to previous research browsers [18, 44, 61], but this
still does not protect the renderer when loading cross-origin
resources such as images.
An unpublished prototype using SFI called MinSFI [48]
was developed at Google in 2013 to protect the Chrome ren-
derer from compromise of zlib library; however, it was missing
several features necessary for compatibility and efﬁciency,
including threading and callback support. Additionally, the
project was primarily focused on improving the efﬁciency of
SFI rather than the integration challenges tackled by RLBox
including handling tainted data, migration of code bases, etc.
In some parts of the renderer, there is no substitute for
strong memory safety to prevent attacks. Servo [1] is an
ongoing project to rewrite much of the Firefox rendering
stack in Rust. However, for the foreseeable future, Firefox
and other browsers will continue to rely on libraries written
in C/++. This makes sandboxing the most viable approach
to containing vulnerabilities.
Sandboxing. There has been some related work on providing
APIs to simplify using sandboxed libraries (e.g., Codejail [63]
and Google Sandboxing APIs [5]). However, these efforts
do not provide the type-driven automation of RLBox (e.g.,
pointer swizzling and migration assistance) nor the safety
of tainted types—leaving developers to manually deal
with attacks of Section 3. Sammler et al. [43] formal model
addresses some of these attacks using a type-direct approach,
but require applications to be formally veriﬁed correct (in
contrast to our local validators) to give meaningful guarantees.
There is a long line of work on sandboxing mechanisms
with different performance trade-offs [20, 48, 49, 58, 60].
Recent, excellent surveys [52, 56] present a comprehensive
overview of these mechanisms. RLBox makes it easy for
developers to use such mechanisms without modifying
the application or library (§6.2). In production we use
WebAssembly; WebAssembly stands out as a principled
approach with wide adoption [20].
Data sanitization and leaks. There is a large body of work
on static and dynamic approaches to preventing or mitigating
missed sanitization errors; see the survey by Song et al. [53].
These tools are orthogonal to RLBox. Developers could use
them to check their data validation functions for bugs.
DUI Detector [22] uses runtime trace analysis to identify
missing pointer sanitizations in user code. Other work has
looked at sanitizing user pointers in the kernel [9]. For
example, type annotations [25] have been used to distinguish
between untrusted user pointers and trusted pointers in OS
kernel code. In contrast, RLBox automatically applies such
pointer sanitizations by leveraging the C++ type system.
One approach to avoid double-fetch bugs is to marshal
all shared data before using it. But, this comes at a cost.
Marshaling tools and APIs typically require array bounds an-
notations, which is tedious and demands in-depth knowledge
of the sandboxed library’s internal data structures. Automatic
marshaling tools like C-strider [45] and PtrSplit [29]
address this limitation; however, these tools either impose
a signiﬁcant overhead or lack support for multi-threading.
RLBox uses shared memory and statically enforces that
shared data is placed in shared memory, avoiding the need for
custom marshaling tools or annotations. The use of shared
memory, however, introduces possible double-fetch bugs.
While RLBox provides APIs to assist with double-fetches,
the possibility of unhandled double-fetch bugs still remain.
Several recent techniques detect double-fetches from shared
memory [47, 62, 64] and can be used alongside RLBox.
Previous efforts have also sought to prevent leaking point-
ers that could compromise ASLR [6, 13, 30]. RLBox prevents
pointer leaks by disallowing pointers to renderer memory to
pass into the sandboxed library via the type system.
Porting assistance. Several privilege separation tools pro-
vide assistance when migrating to a sandboxed architecture.
Wedge (Crowbar) [4] uses dynamic analysis to guide the
migration, and also supports an incremental porting mode that
disables isolation so that developers can test the partial port
and identify the next step. SOAAP [19] uses code annotations
and a custom compiler to guide the developer. PrivTrans [8]
uses code annotations and automatic source code rewriting to
separate code and data into separate components. In contrast,
RLBox assists with porting without any custom tooling,
purely through the use of compile-time errors, by identifying
code that must be modiﬁed for security and shared data that
must be migrated to sandbox memory (§5).
9 Using RLBox in production
Over the last 6 months we’ve been integrating RLBox into
production Firefox. In this section, we describe the difference
between our research prototype and the production RLBox,
and our migration of the libGraphite font shaping library to
use RLBox. We are in the process of migrating several other
libraries and adding support for Firefox on Windows [15, 51].
9.1 Making RLBox production-ready
To make RLBox production-ready we adapt a new isolation
mechanism based on WebAssembly and rewrite the RLBox
API, using our prototype implementation as a reference.
SFI using WebAssembly. In production, we use Wasm
instead of NaCl to isolate library code from the rest of Firefox
within a single process. Though Wasm’s performance and
feature-set is not yet on par with NaCl’s [23], NaCl has been
deprecated in favor of Wasm [17] and maintaining a separate
toolchain for library sandboxing is prohibitive. Moreover,
714    29th USENIX Security Symposium
USENIX Association
these limitations are likely to disappear soon: as part of the