worm attack. It has realistic end-hosts and network entities, all realized as virtual
machines (VMs) and conﬁned in a virtual network (VN). The salient features
of vGround include: (1) high ﬁdelity supporting real worm codes exploiting
real vulnerable services, (2) strict conﬁnement making the real Internet totally
invisible and unreachable from inside a vGround, (3) high resource efﬁciency
achieving sufﬁciently large scale of worm experiments, and (4) ﬂexible and
efﬁcient worm experiment control enabling fast (tens of seconds) and automatic
generation, re-installation, and ﬁnal tear-down of vGrounds. Our experiments
with real-world worms (including multi-vector worms and polymorphic worms)
have successfully exhibited their probing and propagation patterns, exploitation
steps, and malicious payloads, demonstrating the value of vGrounds for worm
detection and defense research.
Keywords: Internet Worms, Intrusion Observation and Analysis, Destructive
Experiments.
1 Introduction
In recent worm detection and defense research, we have witnessed increasingly novel
features of emerging worms [41] in their infection and propagation strategies. Examples
are polymorphic appearance [34], multi-vector infection [15], self-destruction [23],
and intelligent payloads such as self-organized attack networks [18] or mass-mailing
capability [21]. In order to understand key aspects of worm behavior such as probing,
exploitation, propagation, and malicious payloads, researchers have long hoped to
have a safe and convenient environment to run and observe real-world worms. Such
a “worm playground” environment is useful not only in accessing the impact of worm
intrusion and propagation, but also in testing worm detection and defense mechanisms
[46, 42, 35, 37].
A. Valdes and D. Zamboni (Eds.): RAID 2005, LNCS 3858, pp. 1–21, 2006.
c(cid:2) Springer-Verlag Berlin Heidelberg 2006
2
X. Jiang et al.
Despite its usefulness,
there are difﬁculties in realizing a worm playground.
Major challenges include the playground’s ﬁdelity, conﬁnement, scalability, resource
efﬁciency, as well as the convenience in worm experiment setup and control. Currently,
a common practice is to deploy a dedicated testbed with a large number of physical
machines, and to use these machines as nodes in the worm playground. However, this
approach may not effectively address the above challenges, for the following reasons:
(1) Due to the coarse granularity (one physical host) of playground entities, the scale
of a worm playground is constrained by the number of physical hosts, affecting the
full exhibition of worm propagation behavior; (2) By nature, worm experiments are
destructive. With physical hosts as playground nodes, it is a time-consuming and
error-prone manual task for worm researchers to re-install, re-conﬁgure, and reboot
worm-infected hosts between experiment runs; and (3) Using physical hosts for worm
tests may lead to security risk and impact leakage, because the hosts may connect
to machines outside the playground. However, if we make the testbed a physically-
disconnected “island”, the testbed will no longer be share-able to remote researchers.
The contribution of our work is the design, implementation, and evaluation of a
virtualization-based platform to quickly create safe virtual worm playgrounds called
vGrounds, on top of general-purpose infrastructures. Our vGround platform can be
readily used to analyze Linux worms, which represent a non-negligible source of
insecurity especially with the rise of popularity of Linux in servers’ market. Though
the current prototype does not support Windows-based worms, our design principles
and concepts can also be applied to build Windows-based vGrounds.
The vGround platform can conveniently turn a physical infrastructure into a base
to host vGrounds. An infrastructure can be a single physical machine, a local cluster,
or a multi-domain overlay infrastructure such as PlanetLab [7]. A vGround is an all-
software virtual environment with realistic end-hosts and network entities, all realized
as virtual machines (VMs). Furthermore, a virtual network (VN) connects these VMs
and conﬁnes worm trafﬁc within the vGround. The salient features of vGround include:
– High ﬁdelity. By running real-world OS, application, and networking software, a
vGround allows real worm code to propagate as in the real Internet. Our full-system
virtualization approach achieves the ﬁdelity that leads to more opportunities to
capture nuances, tricks, and variations of worms, compared with simulation-based
approaches [39]. For example, one of our vGround-based experiments identiﬁed a
misstatement in a well-known worm bulletin1.
– Strict conﬁnement. Under our VM and VN (virtual network) technologies, the real
Internet is totally invisible (unaddressable) from inside a vGround, preventing the
leakage of negative impact caused by worm infection, propagation, and malicious
payloads [16, 23] into the underlying infrastructure and cascadingly, the rest of
the Internet. Furthermore, the damages caused by a worm only affect the virtual
entities and components in one vGround and therefore do not affect other vGrounds
running on the same infrastructure.
– Flexible and efﬁcient worm experiment control. Due to the all-software nature
of vGrounds, the instantiation, re-installation, and ﬁnal tear-down of a vGround are
1 The misstatement is now ﬁxed and the authors have agreed not to disclose the details.
Virtual Playgrounds for Worm Behavior Investigation
3
both fast and automatic, saving worm researchers both time and labor. For example,
in our Lion worm experiment, it only takes 60, 90, and 10 seconds, respectively,
to generate, bootstrap, and tear-down the vGround with 2000 virtual nodes. Such
efﬁciency is essential when performing multiple runs of a destructive experiment.
These operations can take hours or even days if the same experiment is performed
directly on physical hosts. More importantly, the operations can be started by the
researchers without the administrator privilege of the underlying infrastructure.
– High resource efﬁciency. Because of the scalability of our virtualization tech-
niques, the scale of a vGround can be magnitudes larger than the number of physical
machines in the infrastructure. In our current implementation, one physical host can
support several hundred VMs. For example, we have tested the propagation of Lion
worms [16] in a vGround with 2000 virtual end hosts, based on 10 physical nodes
in a Linux cluster.
However, we would like to point out that although such scalability is effective
in exposing worm propagation strategies based on our limited physical resources
(Section 4), it is not comparable to the scale achieved by worm simulations. Having
different focuses and experiment purposes, vGround is more suitable for analyzing
detailed worm actions and damages, while the simulation-based approach is
better for modeling worm propagation under Internet scale and topology. Also,
lacking realistic background computation and trafﬁc load, current vGrounds are
not appropriate for accurate quantitative modeling of worms.
We are not aware of similar worm playground platforms with all the above features
that are widely deployable on general-purpose infrastructures. We have successfully
run real worms, including multi-vector worms and polymorphic worms, in vGrounds
on our desktops, local clusters, and PlanetLab. Our experiments are able to fully
exhibit the worms’ probing and propagation patterns, exploitation attempts, and ma-
licious payloads, demonstrating the value of vGrounds in worm detection and defense
research.
The rest of this paper is organized as follows: Section 2 provides an overview
of the vGround approach. The detailed design is presented in Section 3. Section 4
demonstrates the effectiveness of vGround using our experiments with several real-
world worms. A discussion on its limitations and extensions is presented in Section 5.
Related works are discussed in Section 6. Finally, Section 7 concludes this paper.
2 The vGround Approach
A vGround is a virtualization-based self-conﬁned worm playground where not only
each entity, including an end host, a ﬁrewall, a router, and even a network cable, is fully
virtualized, but also every communication trafﬁc is strictly conﬁned within. Due to its
virtualization-based nature and associated self-conﬁnement property, a vGround can
be safely created on a wide range of general-purpose infrastructures, including regular
desktops, local clusters, and even wide-area shared infrastructures such as PlanetLab.
For example, Figure 1 shows a simple vGround (the vGrounds in our worm experiments
are much larger in scale) which is created on top of three PlanetLab hosts A, B, and C.
4
X. Jiang et al.
Enterprise Network A
(128.10.0.0/16)
Enterprise Network B
(128.11.0.0/16)
AS1_H2: 128.10.1.2
AS2_H1: 128.11.1.3
AS2_H2: 128.11.1.4
Enterprise Network C
(128.12.0.0/16)
AS3_H1: 128.12.1.5
Worm
To: 128.12.1.5
R1
R2
R3
A vGround
128.10.1.250
128.8.1.1
128.8.1.2
128.9.1.2
128.9.1.1
128.12.1.250
AS1_H1: 128.10.1.1
AS3_H2: 128.12.1.6
Physical Host A
(planetlab6.millennium.berkeley.edu)
Physical Host B
(planetlab1.cs.purdue.edu)
Physical Host C
(planetlab8.lcs.mit.edu)
Fig. 1. A PlanetLab-based vGround for worm experiment
The vGround includes three virtual enterprise networks connected by three virtual
routers (R1, R2, and R3). Within the vGround, the “seed” worm node (AS1 H1 in
network A 128.10.0.0/16) is starting to infect other nodes running vulnerable services.
Note that a vGround essentially appears as a virtual Internet whose network address
assignment can be totally orthogonal to that of the real Internet. Furthermore, multiple
simultaneously running vGrounds can safely overlap their address space without
affecting each other as one vGround is completely invisible to another vGround.
Using a vGround speciﬁcation language, a worm researcher will be able to specify
the worm experiment setup in a vGround, including software systems and services, IP
addresses, and routing information of virtual nodes (i.e. virtual end hosts and routers).
Given the speciﬁcation, the vGround platform will perform automatic vGround instan-
tiation, bootstrapping, and clean-up. In a typical worm experiment, multiple runs are
often needed as each different run is conﬁgured with a different parameter setting (e.g.,
different worm signatures [8, 1] and different trafﬁc throttling thresholds[46]). However,
because of the worm’s destructive behavior, the vGround will be completely unusable
after each run and need to be re-installed. The vGround platform is especially efﬁcient
in supporting such an iterative worm experiment workﬂow.
2.1 Key vGround Techniques
Existing full-system virtualization is adopted to achieve high ﬁdelity of vGrounds.
Worms infect machines by remotely exploiting certain vulnerabilities in OS or applica-
tion services (e.g., BIND, Sendmail, DNS). Therefore, the vulnerabilities provided by
vGrounds should be the same as those in real software systems. As such, vGround can
not only be leveraged for experimenting worms propagating via known vulnerabilities,
but also be useful for discovering worms exploiting unknown vulnerabilities, of which
worm simulations are not capable.
There exist various VM technologies that enable full-system virtualization. Exam-
ples include Virtual PC [12], VMware [13], Denali [49], Xen [26], and User-Mode
Linux (UML) [30]. The differences in their implementations lead to different levels
of cost, deployability and conﬁgurability: VMware and similarly Virtual PC require
Virtual Playgrounds for Worm Behavior Investigation
5
several loadable kernel modules for virtualizing underlying physical resources; Xen and
Denali “paravirtualize” physical resources by running in place of host OS; and UML
is mainly a user-level implementation through system call virtualization. We choose
UML in the current vGround implementation so that the deployment of vGround does
not require the root privilege of the shared infrastructure. As a result, current vGround
prototype can be widely deployed in most Linux-based systems (including PlanetLab).
However, we would like to point out that the original UML itself is not able to satisfy
the vGround needs. As described next, we have developed new extensions to UML.
New network virtualization techniques are developed to achieve vGround conﬁne-
ment. Simply running a worm experiment in a number of VMs will not conﬁne the worm
trafﬁc just within these VMs and thus prevent potential worm “leakage”. Although
existing UML implementation does have some support for virtual networking, it is
still not capable of organizing different VMs into an isolated virtual topology. In
particular, when the underlying shared infrastructure spans multiple physical domains,
additional VPN softwares are needed to create the illusion of the virtual Internet.
However, there are two notable weaknesses: (1) a VPN does not hide the existence
of the underlying physical hosts and their network connections, which fails to meet
the strict conﬁnement requirement; (2) a VPN usually needs to be statically/manually
conﬁgured as it requires the root privilege to manipulate the routing table, which fails to
meet the ﬂexible experiment control requirement. As our solution, we have developed a
link-layer network virtualization technique to create a VN for VMs in a vGround. The
VN reliably intercepts the trafﬁc at the link-layer and is thus able to constrain both the
topology and volume of trafﬁc generated by the VMs. Such a VN essentially enables
the illusion as a “virtual Internet” (though with a smaller scale) with its own IP address
space and router infrastructure. More importantly, the VN and the real Internet are, by
nature of our VN implementation, mutually un-addressable.
New optimization techniques are developed to improve vGround scalability, efﬁ-
ciency, and ﬂexibility. To increase the number of VMs that can be supported in one phys-
ical host, the resource consumption of each individual VM should be conserved. For
example, a full-system image of Red-Hat 9.0/7.2 requires approximately 1G/700M
disk space. For a vGround of 100 VMs, a naive approach would require at least
100G/70G disk space. Our optimization techniques exploit the fact that a large portion
of the VM images is the same and can be shared among the VMs. Furthermore, some
services, libraries, and software packages in the VM image are not relevant to the worm
being tested, and could therefore be safely removed. We also develop a new method to
safely and efﬁciently generate VM images in each physical host (Section 3.4). Finally, a
new technique is being developed to enable worm-driven vGround growth: new virtual
nodes/subnets can be added to the vGround at runtime in reaction to a worm’s infection
intent.
2.2 Advanced vGround User Conﬁgurability
The vGround platform provides a vGround speciﬁcation language to worm researchers.
There are two major types of entities - network and virtual node, in the vGround
6
X. Jiang et al.
speciﬁcation language. A network is the medium of communication among virtual
nodes. A virtual node can be an end-host, a router, a ﬁrewall, or an IDS system and it
has one or more network interface cards (NICs) - each with an IP addresses. In addition,
the virtual nodes are properly connected using proper routing mechanisms. Currently,
the vGround platform supports RIP, OSPF, and BGP protocols.
In order to conveniently specify and efﬁciently generate various system images,
the language deﬁnes the following notions: (1) A system template contains the basic
VM system image which is common among multiple virtual nodes. If a virtual node is
derived from a system template, the node will inherit all the capabilities speciﬁed in the
system template. The deﬁnition of system template is motivated by the observation that
most end-hosts to be victimized by a certain worm look quite similar from the worm’s
perspective. (2) A cluster of nodes is the group of nodes located in the same subnet.
The user may specify that they inherit from the same system template, with their IP
addresses sharing the same subnet preﬁx.
project  Planetlab−Worm
template slapper {
           image slapper.ext2
           cow enabled
           startup {
                /etc/rc.d/init.d/httpd start
           }
}
template router {
           image router.ext2
           routing ospf
           startup {
                /etc/rc.d/init.d/ospfd start
           }
}
router R1 {
      superclass router
      network eth0 {
            switch AS1_lan1
            address 128.10.1.250/24
      }
      network eth1 {
            switch AS1_AS2
            address 128.8.1.1/24
      }
}
switch AS1_lan1 {
        unix_sock sock/as1_lan1
        host  planetlab6.millennium.berkeley.edu
}
switch AS1_AS2 {
        udp_sock 1500
        host  planetlab6.millennium.berkeley.edu
}
node   AS1_H1 {
           superclass slapper
           network eth0 {
                   switch AS1_lan1
                   address 128.10.1.1/24
                   gateway 128.10.1.250
           }
}
node   AS1_H2 {
           superclass slapper
           network eth0 {
                   switch AS1_lan1
                   address 128.10.1.2/24
                   gateway 128.10.1.250
           }
}
switch AS2_lan1 {
        unix_sock sock/as2_lan1
        host  planetlab1.cs.purdue.edu
}
switch AS2_AS3 {
        udp_sock 1500
        host  planetlab1.cs.purdue.edu
}
node   AS2_H1 {
           superclass slapper
           network eth0 {
                   switch AS2_lan1
                   address 128.11.1.3/24
                   gateway 128.11.1.250
           }
}
node   AS2_H2 {
           superclass slapper
           network eth0 {