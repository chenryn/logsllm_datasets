pseudolocations averaged over all locations for optimal and
obfuscation LPPMs, respectively. Given arbitrary LPPM
location obfuscation function f (.) and user proﬁle ψ(.), the
probability distribution of pseudolocations is
Pr(r′) =Xr
ψ(r)f (r′|r).
(35)
As it is shown, the distribution corresponding to the opti-
mal LPPM is more uniform, making it more diﬃcult for the
adversary to invert it eﬀectively.
In Figures 2(4) and 2(5), we show the distribution of pseu-
dolocations for speciﬁc location r = loc(13, 7). By observing
how uniform their outputs are, we can easily make the com-
parison between the two LPPMs. The obfuscation LPPM
is obviously more concentrated around the actual location,
whereas the optimal LPPM (with the same service-quality
loss as the obfuscation method) broadens the set of pseudolo-
cations to most of possible regions including highly probable
regions (i.e. regions r with a large ψ(r)). This higher diver-
sity brings higher privacy as we will see later in this section.
Tradeoﬀ between Privacy and Service Quality.
We now study the tradeoﬀ between the level of privacy
that the optimal LPPM provides, against the optimal at-
tack, and the service-quality loss that it causes. We plot
in Figure 3(a) the evolution of the service quality loss, as
the optimal LPPM is conﬁgured to guarantee diﬀerent lev-
els of service quality (for users with diverse proﬁles and for
various service quality thresholds). Each line in the ﬁgure
represents one user and each ◦ represents one Qmax
loss . We plot
P rivacy(ψ, f, h, dp) versus Qloss(ψ, f, dq).
Unsurprisingly, increasing the level of location-privacy pro-
tection signiﬁcantly degrades the service quality. Also, as
expected, we can observe that the maximum achievable loca-
tion privacy is strongly dependent on the user proﬁle. This is
reﬂected by the separation between the diﬀerent lines. Each
user can have up to a certain level of privacy regardless of
the quality threshold (represented by ◦ in the ﬁgure). Hence,
the service-quality loss remains constant once this level has
been reached. This is due to the presence of the optimal
attack that squeezes the location-privacy gain.
This eﬀect is further illustrated in Figure 3(b), where the
service-quality loss of optimal LPPM is plotted against the
service-quality threshold. Once the optimal LPPM oﬀers the
maximal location privacy for a given user proﬁle, loosening
the service-quality constraint does not signiﬁcantly change
the LPPM’s underlying function f , and thus there is no
reduction in service quality.
In other words, there is no
need to sacriﬁce the service quality, because doing so does
not increase the user’s location privacy.
Eﬀectiveness of the Optimal Strategies.
Given Euclidean distance functions dp(.) and dq(.), we
compute the optimal LPPM and attack methods for a set of
service quality thresholds Qmax
loss . For each user, we run the
Bayesian inference attack on her optimal LPPM. We also
evaluate the location privacy oﬀered by the basic obfuscation
LPPM with respect to the optimal attack. We vary the
obfuscation level from 1 (minimum) to 30 (maximum), and
for each case we compute the corresponding quality loss.
Then, this value is set as the threshold Qmax
loss for ﬁnding the
optimal attack mechanism.
Figure 4(a) shows the superiority of the optimal attack
to the Bayesian attack, when location privacy of users is
protected using the optimal LPPM: For any given user and
service-quality threshold, the location privacy that the user
obtains is smaller when the adversary implements the opti-
mal strategy rather than the Bayesian inference attack.
Figure 4(b) shows the superiority of the optimal LPPM
to the obfuscation LPPM, against the optimal attack: For
any given user and service-quality threshold, a user has a
higher privacy level when the LPPM implements the opti-
mal strategy. As expected, obtained privacy by both mech-
anisms become equal when no service quality is guaranteed
for the user (i.e., Qmax
loss is set to its maximum value).
Consider a single user. To further investigate the eﬀec-
tiveness of optimal strategies, we evaluate her privacy under
four diﬀerent combinations of optimal and non-optimal pro-
tection/attack methods, that have been explained before.
Similar to Figure 2, we consider the basic obfuscation
LPPM as the basis for generating the service-quality thresh-
6235
4.5
4
3.5
3
5
4.5
4
3.5
3
q
)
d
,
f
,
ψ
(
s
s
o
q
)
d
,
f
,
ψ
(
s
s
o
l
Q
2.5
2
1.5
1
1
l
Q
2.5
2
1.5
1
0
1.5
2
2.5
3
3.5
4
Privacy(ψ, f, h, d
)
p
2
4
6
max
loss
Q
8
10
12
(a) Location privacy P rivacy(ψ, f, h, dp) vs. Service-quality
loss Qloss(ψ, f, dq) for a given service-quality threshold Qmax
loss .
The circles ◦ represent diﬀerent values of Qmax
loss .
(b) Service-quality threshold Qmax
Service-quality
loss Qloss(ψ, f, dq),
location privacy
P rivacy(ψ, f, h, dp). The circles ◦ represent diﬀerent values
of P rivacy(ψ, f, h, dp).
loss vs.
for a given level of
Figure 3: Tradeoﬀ between Privacy and Service Quality: Optimal LPPM against the optimal attack. The
diﬀerent lines represent users with diverse proﬁles ψ(.). (Euclidean dq(.) and Euclidean dp(.).)
h
k
c
a
t
t
i
A
n
a
s
e
y
a
B
,
)
d
,
h
,
f
,
ψ
(
y
c
a
v
i
r
P
p
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
0
f
M
P
P
L
n
o
i
t
a
c
s
u
f
b
O
,
)
d
p
,
h
,
f
,
ψ
(
y
c
a
v
i
r
P
1
2
3
4
5
Privacy(ψ, f, h, d
), Optimal Attack h
p
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
0
1
2
3
4
5
Privacy(ψ, f, h, d
), Optimal LPPM f
p
(a) Location privacy P rivacy(ψ, f, h, dp) oﬀered by the opti-
mal LPPM against the optimal attack derived using the game
theoretic approach vs. against the Bayesian-inference attack.
(b) Location privacy P rivacy(ψ, f, h, dp) oﬀered by the opti-
mal LPPM vs. location privacy oﬀered by the basic obfusca-
tion LPPM, both evaluated against the optimal attack.
Figure 4: Eﬀectiveness of the optimal attack and optimal LPPM strategies. Diﬀerent lines represent users
with diverse proﬁles ψ(.), and the circles ◦ represent diﬀerent values of Qmax
loss . (Euclidean dq(.) and dp(.).)
old Qmax
loss . In all graphs of Figure 5 each dot represents one
obfuscation level used in the basic obfuscation LPPM. The
corresponding service-quality loss for each obfuscation level
is shown on the x-axis of all four plots. As it can be eas-
ily observed from the ﬁgures, the optimal attack, compared
with the Bayesian attack, always results in a higher degra-
dation of the user’s location privacy. Moreover, the optimal
LPPM always provides a higher level of privacy for the user
(regardless of the service-quality threshold) compared with
the basic obfuscation LPPM.
The ﬁgures well illustrate how both user and adversary
converge to use optimal strategies against each other. The
user’s favorite setting, i.e. the one that brings her a high
level of privacy, is (Optimal, Bayesian). Inversely, the (Ob-
fuscation, Optimal) combination is the favorite setting for
the adversary, in which he pays the minimum cost of estimation-
error. However, neither of these two settings is a stable
state. In the (Optimal, Bayesian) combination, the adver-
sary would gain more by choosing the Optimal attack. In the
(Obfuscation, Optimal) combination, the user would gain
624 
Obfuscation,Bayesian
Optimal,Bayesian
Obfuscation,Optimal
Optimal,Optimal
0.221774
0.418235
0.638889
0.721595
0.773723
0.811246
Q
max
loss
(b) Hamming dq(.) and Euclidean dp(.)
Obfuscation,Bayesian
Optimal,Bayesian
Obfuscation,Optimal
Optimal,Optimal
0.666667
0.75
0.8
0.5
max
loss
Q
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
p
)
d
,
h
,
f
,
ψ
(
y
c
a
v
i
r
P
p
)
d
,
h
,
f
,
ψ
(
y
c
a
v
i