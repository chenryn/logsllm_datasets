normal situations, whenever a (ransomware) process tries to write such ﬁles,
this module can immediately identify the process as malicious. Furthermore, the
presence of a signiﬁcant number of decoy ﬁles (though of smaller sizes) increases
the probability that a ransomware would encrypt one of these ﬁles even before
trying to encrypt an original ﬁle. Hence, the advantage of using decoy ﬁles is
twofold: (1) it allows the detection system to readily identify a malicious process,
and (2) it delays the time when ransomware starts encrypting the original ﬁles
and thus gives enough time for anomaly detection to complete its analysis and
stop the malicious processes even before they start encrypting the original ﬁles
(see Sect. 5.2 for the experimental data about the time required by RWGuard to
complete the analysis). RWGuard decoy ﬁles are generated with an automated
decoy generator tool that we discuss in details in Sect. 4.2. Note that, our decoy
generator periodically modiﬁes the decoy ﬁles so that even if a ransomware looks
at the time when a ﬁle is last modiﬁed (to ensure that the ﬁle it encrypts is valu-
able to the user), it would not be able to recognize the decoy ﬁles.
A Real-time Detection System Against Cryptographic Ransomware
119
Table 1. Fast I/O read/write types
Table 2. Metrics for the PMon module
READ types
FASTIO READ
FASTIO MDL READ
FASTIO READ COMPRESSED
FASTIO READ COMPLETE COMPRESSED
WRITE types
FASTIO WRITE
FASTIO MDL WRITE
FASTIO MDL WRITE COMPLETE
FASTIO WRITE COMPRESSED
FASTIO MDL WRITE COMPLETE COMPRESSED
Metric #
1
2
3
4
5
6
7
8
9
10
11
Metric name
Number of IRP WRITE requests
Number of FastIO WRITE requests
Number of IRP READ requests
Number of FastIO READ requests
Number of IRP OPEN requests
Number of FastIO OPEN requests
Number of IRP CREATE requests
Number of FastIO CREATE requests
Number of IRP CLOSE requests
Number of FastIO CLOSE requests
Number of temporary ﬁle created
3.4 Process Monitoring (PMon) Module
Unlike some existing approaches [13,14] that look for speciﬁc patterns (e.g.,
read→ encrypt→ delete) in the processes’ I/O requests, we exploit the fact that
ransomware typically attempts to encrypt data rapidly [10] (to maximize damage
and minimize the chance of being detected) which leads to anomalous numbers
of IRPs. Exploiting this property results in faster detection since IRPs can be
logged well ahead of actual ﬁle operations. Our PMon module monitors the
I/O requests made by the processes running on the system. Though IRP is the
default mechanism for requesting I/O operations, many ransomware perform
ﬁle operations using fast I/O requests. Fast I/O is speciﬁcally designed for rapid
synchronous I/O operations on cached ﬁles, bypassing the ﬁle system and the
storage driver stack. Therefore, in our design, we monitor both the IRPs and the
fast I/O requests. A fast I/O read/write operation can be any of the types listed
in Table 1. Given that ransomware processes encrypt ﬁles rapidly, the behavior
of such processes has certain characteristics. Hence, in this module, we train a
machine learning model that given a process’s I/O requests, identiﬁes the process
as benign or ransomware. Ransomware that encrypt ﬁles slowly may evade this
module but are identiﬁed by the FCMon module as discussed in Sect. 3.5.
Process Proﬁling. In order to train the machine learning model, as a ﬁrst
step, we collect the IRPs (from this point, the term ‘IRP’ represents both I/O
and fast I/O) of both benign and ransomware processes. Table 2 shows the IRP
metrics used in this training phase which also includes the number of temporary
ﬁles created by a process. The temporary ﬁles (.TMP) are usually created by
ransomware to hold the data while copying or removing the original ﬁles. Once
the proﬁles for benign and ransomware processes are built in the training phase,
the Process Proﬁling component of the PMon module (Fig. 1) stores the model
parameters to check against the running processes’ parameters in real-time (i.e.,
the test phase). The PMon module re-computes the metrics listed in Table 2 for
each running process over a 3 s sliding window.
120
S. Mehnaz et al.
Table 3. Performance evaluation for diﬀerent machine learning techniques
Classiﬁer
Accuracy (%) ROC
area
Naive Bayes
80.07
Logistic regression 81.22
Decision tree
Random forest
89.27
96.55
0.69
0.72
0.87
0.94
True
positive
rate
False
positive
rate
0.80
0.81
0.89
0.96
0.70
0.66
0.18
0.08
Precision Recall
0.75
0.77
0.89
0.96
0.80
0.81
0.89
0.96
• Training phase: The data collection and classiﬁer training steps are follow-
ing:
1. Data collection: For the training set, we collect IRP data of processes
from both ransomware samples and benign applications. We use nine of the
most popular ransomware families, namely: Wannacry, Cerber, CryptoLocker,
Petya, Mamba, TeslaCrypt, CryptoWall, Locky, and Jigsaw for the training
phase. We also include benign processes, e.g., Explorer.exe, WmiPrvSE.exe,
svchost.exe, FileSpy.exe, vmtoolsd.exe, csrss.exe, System, SearchFilter-
Host.exe, SearchProtocolHost.exe, SearchIndexer.exe, chrome.exe, GoogleUp-
date.exe, services.exe, audiodg.exe, WinRAR.exe, taskhost.exe, drpbx.exe,
lsass.exe, etc. It is important to note that most of the ransomware sam-
ples spawn multiple malicious processes during execution. Our ﬁnal training
dataset contains IRPs from 261 processes including both benign and malicious
ones.
2. Classiﬁer training: Using the training data, we train a machine learning
classiﬁer that, given a set of processes, is able to distinguish between ran-
somware and benign processes. In order to identify the best machine learn-
ing technique for this classiﬁcation, we analyzed diﬀerent classiﬁers, namely:
Naive Bayes (using estimator classes), Logistic Regression (multinomial logis-
tic regression model with a ridge estimator), Decision Tree [24], and Random
Forest [3] classiﬁers. We used 10 fold cross validation on the obtained data set
and measured accuracy, precision, recall, true positive rate and false positive
rate for each of the above-mentioned classiﬁers. Table 3 presents a compar-
ison of the classiﬁers used in our analysis. Figure 2 shows the results for all
the classiﬁers in terms of ROC curves (which plot true positive rate against
false positive rate). The low accuracy (∼80%) of the naive Bayes classiﬁer
can be attributed to its class independence property. From our observation,
ransomware usually employs a combination of read, write, open, and close
requests which are correlated. Therefore, assuming that these parameters are
independent of each other leads to a lower accuracy. The regression classi-
ﬁer works slightly better than the naive Bayes classiﬁer with an accuracy of
∼81%. A logistic regression model searches for a single linear decision bound-
ary in the feature space. Hence, the low accuracy can be attributed to the
A Real-time Detection System Against Cryptographic Ransomware
121
1
0.8
0.6
0.4
0.2
0
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
Naive Bayes
Logistic Regression
Decision Tree
Random Forest
0.8
1
0
0.2
0.6
0.4
False positive rate
Fig. 2. ROC curves for diﬀerent classiﬁers.
fact that our data does not have a linear boundary for decisions. The rea-
son is that many ransomware make a large number of write/read requests as
compared to the open/close requests. Therefore, the ideal decision boundary
for our dataset would be non-linear.
The tree-based classiﬁers (random forest and decision tree) perform the best
with accuracies of ∼97% and ∼89%, respectively. The reason is that the
decision boundary for our data is non-linear and these classiﬁers build non-
linear decision boundaries. However, the decision tree classiﬁer is susceptible
to over-ﬁtting while random forest classiﬁers do not have this issue. Also, in
terms of deployment, the random forest classiﬁer is faster and more scalable
compared to other classiﬁers. Therefore, ﬁnally, we use the random forest
classiﬁer in our RWGuard PMon module.
• Test phase: In the test phase, along with the nine families used for train-
ing, we add ﬁve more ransomware families in the experiment set: Vipasana,
Satana, Radamant, Rex, and Matsnu. These samples are executed one at a
time and depending on the spawned processes and their activities, the mali-
cious processes are ﬂagged. Details of the test phase results are given in
Sect. 5.
File Encryption. In our experiments, we observe that few benign processes,
e.g., Chrome, VMware tools are sometimes classiﬁed as malicious by the machine
learning model due to these processes’ I/O request behaviors. Therefore, besides
monitoring the process proﬁling metrics, it is important to monitor whether a
particular process is responsible for any signiﬁcant ﬁle changes. Hence, our PMon
module considers ﬁle encryption as a signiﬁcant parameter (communicated by
the FCMon module as described in Sect. 3.5) and identiﬁes a process as malicious
only if it encrypts ﬁles along with indications of anomalous I/O behaviors.
122
S. Mehnaz et al.
3.5 File Change Monitoring (FCMon) Module
This monitoring module can be conﬁgured to target a range of ﬁles from a single
directory to the whole ﬁle system. It computes and stores the initial properties
of the ﬁles (or, dynamically computes the properties when a ﬁle is created) and
these properties are updated accordingly in the event of a ﬁle change. In real-
time, the FCMon module looks for signiﬁcant changes in those ﬁles after each
write operation using the following metrics: (1) similarity, (2) entropy, (3) ﬁle
type change, and (4) ﬁle size change. While some of these metrics have been
used for ransomware detection in existing work [13,26], our goal is to verify the
fast detections by the PMon module and thereby minimize the false positive
rates. In what follows, we describe the File Manager component of the FCMon
module and present the details of the above metrics.
File Manager. This component stores the current properties of each ﬁle (e.g.,
ﬁle type, current entropy of a ﬁle, ﬁle size, last modiﬁed time etc.) so that any
signiﬁcant change in the ﬁles’ properties can be detected upon a write operation.
If a new ﬁle is created, this component computes the properties of the new ﬁle
instantly and stores them in the map (map key: ﬁle name and path, key value:
computed properties).
Metrics. The metrics of FCMon module are following:
1. Similarity metric: In comparison with a benign ﬁle change, e.g., modifying
some of the existing text or adding some text, an encryption would result
in data that is very dissimilar to the original data. Therefore, the similarity
between a ﬁle’s previous (before the write operation) and later (after the write
operation) versions is an important factor to understand the characteristics
of the ﬁle change. In order to compute the similarity between two versions,
we use sdhash, a similarity-preserving hash function proposed by Roussev et
al. [25] for generating the ﬁle hashes. The sdhash function outputs a score in
the range [0,100]. A score of 0 is obtained when we compute the similarity
between two completely random arrays of data. Conversely, a score of 100 is