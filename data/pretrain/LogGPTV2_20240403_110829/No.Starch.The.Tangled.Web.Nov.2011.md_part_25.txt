Around 2006, Microsoft agreed that the current approach was not sustain-
able and developed a more secure descendant policy for frame navigation in
Internet Explorer 7. Under this policy, navigation of non-same-origin frames
is permitted only if the party requesting the navigation shares the origin with
one of the ancestors of the targeted view. Figure 11-2 shows the navigation
scenario permitted by this new policy.
Bunny Browser 2000
http://bunnyoutlet.com
frame: bunnyoutlet.com
Nested frame
frame: fuzzybunnies.com navigation
possible
frame “private”: fuzzybunnies.com
Figure 11-2: A complex but permissible navigation between non-same-origin frames.
This attempt succeeds only because the originating frame has the same origin as one
of the ancestors of the targeted document—here, it’s the top-level page itself.
As with many other security improvements, Microsoft never backported
this policy to the still popular Internet Explorer 6, and it never convincingly
pressured users to abandon the older and increasingly insecure (but still
superficially supported) version of its browser. On a more positive note, by
2009, three security researchers (Adam Barth, Collin Jackson, and John C.
Mitchell) convinced Mozilla, Opera, and WebKit to roll out a similar policy
in their browsers,3 finally closing the mashup loophole for a good majority
ofthe users of the Internet.
Well, almost closing it. Even the new, robust policy has a subtle flaw.
Notice in Figure 11-2 that a rogue site, http://bunnyoutlet.com/, can interfere
with a private frame that http://fuzzybunnies.com/ has created for its own use.
At first glance, there is no harm here: The attacker’s domain is shown in the
address bar, so the victim, in theory, should not be fooled into interacting
with the subverted UI of http://fuzzybunnies.com/ in any meaningful way. Sadly,
there is a catch: Some web applications have learned to use frames not to
Life Outside Same-Origin Rules 177
create user interfaces but to relay programmatic messages between origins.
For applications that need to support Internet Explorer 6 and 7, where
postMessage(...) is not available, the tricks similar to the approach shown
inFigure 11-3 are commonplace.
Bunny Browser 2000
http://www.fuzzybunnies.com
// Step 1: send message to login.fuzzybunnies.com
// This is permitted because the send_to_child frame is a descendant of this document.
frames["send_to_child"].src = "http://login.fuzzybunnies.com/login_handler#" + message_to_send;
frame “send_to_child”: login.fuzzybunnies.com/login_handler#
// Step 2: read message sent in step 1.
// It is always possible to examine your own fragment ID.
response_text = process_message_from_parent(location.hash);
// Step 3: send response to www.fuzzybunnies.com.
// This is permitted because send_to_parent is a descendant of this document.
frames["send_to_parent"].location = "http://www.fuzzywunnies.com/blank#" + response_text
frame “send_to_parent”: www.fuzzybunnies.com/blank#
// Step 4: read back data from login.fuzzybunnies.com.
// This is permitted because the send_to_parent frame is same-origin with this document.
process_message_from_child(frames["send_to_parent"].location.hash);
Figure 11-3: A potential cross-domain communication scheme, where the top-level
page encodes messages addressed to the embedded gadget in the fragment identi-
fier of the gadget frame and the gadget responds by navigating a subframe that is
same-origin with the top-level document. If this application is framed on a rogue site,
the top-level document controlled by the attacker will be able to inject messages
between the two parties by freely navigating send_to_parent and send_to_child.
If an application that relies on a similar hack is embedded by a rogue
site, the integrity of the communication frames may be compromised, and
the attacker will be able to inject messages into the stream. Even the uses of
postMessage(...) may be at risk: If the party sending the message does not spec-
ify a destination origin or if the recipient does not examine the originating
location, hijacking a frame will benefit the attacker in exactly the sameway.
Unsolicited Framing
The previous discussion of cross-frame navigation highlights one of the more
interesting weaknesses in the browser security model, as well as the discon-
nect between the design goals of HTML and the aim of the same-origin pol-
icy. But that’s not all: The concept of cross-domain framing is, by itself, fairly
risky. Why? Well, any malicious page may embed a third-party application with-
out a user’s knowledge, let alone consent. Further, it may obfuscate this fact by
overlaying other visual elements on top of the frame, leaving visible just a small
chunk of the original site, such as a button that performs a state-changing
178 Chapter 11
action. In such a setting, any user logged into the targeted application with
ambient credentials may be easily tricked into interacting with the disguised
UI control and performing an undesirable and unintended action, such as
changing sharing settings for a social network profile or deleting data.
This attack can be improved by the rogue site leveraging a CSS2 property
called opacity to make the targeted frame completely invisible without affecting
its actual behavior. Any click in the area occupied by such a see-through frame
will be delivered to the UI controls contained therein (see Figure 11-4). Too,
by combining CSS opacity with JavaScript code to make the frame follow the
mouse pointer, it is possible to carry out the attack fairly reliably in almost
any setting: Convincing the user to click anywhere in the document window
is not particularly hard.
Figure 11-4: A simplified example of a UI-splicing attack that
uses CSS opacity to hide the document the user will actually
interact with
Researchers have recognized the possibility of such trickery to some
extent since the early 2000s, but a sufficiently convincing attack wasn’t dem-
onstrated until 2008, when Robert Hansen and Jeremiah Grossman publi-
cized the issue broadly.4 Thus, the term clickjacking was born.
The high profile of Hansen and Grossman’s report, and their interesting
proof-of-concept example, piqued vendors’ interest. This interest proved to
be short-lived, however, and there appears to be no easy way to solve this
problem without taking some serious risks. The only even remotely plausible
way to mitigate the impact would be to add renderer-level heuristics to dis-
allow event delivery to cross-domain frames that are partly obstructed or that
have not been displayed long enough. But this solution is complicated and
hairy enough to be unpopular.5 Instead, the problem has been slapped with
a Band-Aid. A new HTTP header, X-Frame-Options, permits concerned sites to
opt out of being framed altogether (X-Frame-Options: deny) or consent only to
framing within a single origin (X-Frame-Options: same-origin).6 This header
Life Outside Same-Origin Rules 179
issupported in all modern browsers (in Internet Explorer, beginning with
version 8),* but it actually does little to address the vulnerability.
Firstly, the opt-in nature of the defense means that most websites will
notadopt it or will not adopt it soon enough; in fact, a 2011 survey of the top
10,000 destinations on the Internet found that barely 0.5 percent used this
feature.7
To add insult to injury, the proposed mechanism is useless for applica-
tions that want to be embedded on third-party sites but that wish to preserve
the integrity of their UIs. Various mashups and gadgets, those syndicated
“like” buttons provided by social networking sites, and managed online dis-
cussion interfaces are all at risk.
Beyond the Threat of a Single Click
As the name implies, the clickjacking attack outlined by Grossman and
Hansen targets simple, single-click UI actions. In reality, however, the prob-
lem with deceptive framing is more complicated than the early reporting
would imply. One example of a more complex interaction is the act of select-
ing, dragging, and dropping a snippet of text. In 2010, Paul Stone proposed
a number of ways in which such an action could be disguised as a plausible
interaction with an attacker’s site,8 the most notable of which is the similarity
between drag-and-drop and the use of a humble document-level scrollbar.
The same click-drag-release action may be used to interact with a legitimate
UI control or to unwittingly drag a portion of preselected text out of a sensi-
tive document and drop it into an attacker-controlled frame. (Cross-domain
drag-and-drop is no longer permitted in WebKit, but as of this writing other
browser vendors are still debating the right way to address this risk.)
An even more challenging problem is keystroke redirection. Sometime
in 2010, I noticed that it was possible to selectively redirect keystrokes across
domains by examining the code of a pressed key using the onkeydown event in
JavaScript. If the pressed key matched what a rogue site wanted to enter into
a targeted application, HTML element focus could be changed momentarily
to a hidden , thereby ensuring the delivery of the actual keystrokes to
the targeted web application rather than the harmless text field the user seems
to be interacting with.9 Using this method, an attacker can synthesize arbi-
trarily complex text in another domain on the user’s behalf—for example,
inviting the attacker as an administrator of the victim’s blog.
Browser vendors addressed the selective keystroke redirection issue by
disallowing element focus changes in the middle of a keypress, but doing so
did not close the loophole completely. After all, in some cases, an attacker
can predict what key will be pressed next and roughly at what time, thereby
permitting a preemptive, blindly executed focus switch. The two most obvi-
ous cases are a web-based action game or a typing-speed test, since both typi-
cally involve rapid pressing of attacker-influenced keys.
* In older versions of Internet Explorer, web application developers sometimes resort to Java-
Script in an attempt to determine whether the window object is the same as parent, a condition
that should be satisfied if no higher-level frame is present. Unfortunately, due to the flexibility of
JavaScript DOM, such checks, as well as many types of possible corrective actions, are notoriously
unreliable.
180 Chapter 11
In fact, it gets better: Even if a malicious application only relies on free-
form text entry—for example, by offering the user a comment-submission
form—it’s often possible to guess which character will be pressed next based
on the previous few keystrokes alone. English text (and text in most other
human languages) is highly redundant, and in many cases, a considerable
amount of input can be predicted ahead of time: You can bet that a-a-r-d-v
will be followed by a-r-k, and almost always you will be right.
Cross-Domain Content Inclusion
Framing and navigation are a distinct source of trouble, but these mecha-
nisms aside, HTML supports a number of other ways to interact with non-
same-origin data. The usual design pattern for these features is simple and
seemingly safe: A constrained data format that will affect the appearance of
the document is retrieved and parsed without being directly shown to the ori-
gin that referenced it. Examples of mechanisms that follow this rule include
markup such as , , , and
several related cases discussed throughout Part I of this book.
Regrettably, the devil is in the details. When these mechanisms were first
proposed, nobody asked several extremely pressing questions:
 Should these subresources be requested with ambient credentials associ-
ated with their origin? If so, there is a danger that the response may con-
tain sensitive data not intended for the requesting party. It would probably
be better to require some explicit form of authentication or to notify the
server about the origin of the requesting page.
 Should the relevant parsers be designed to minimize the risk of mis-
taking one document type for another? And should the servers have
control over how their responses are interpreted (for example through
the Content-Type header)? If not, what are the consequences of, say, inter-
preting a user’s private JPEG image as a script?
 Should the requesting page have no way to infer anything about the
contents of the retrieved payloads? If yes, then this goal needs to be
taken into account with utmost care when designing all the associated
APIs. (If such separation is not a goal, the importance of the previous
questions is even more pronounced.)
The developers acted with conflicting assumptions about these topics, or
perhaps had not given them any thought at all, leading to a number of pro-
found security risks. For example, in most browsers, it used to be possible to
read arbitrary, cookie-authenticated text by registering an onerror handler on
cross-domain  loads: The verbose “syntax error” message generated by
the browser would include a snippet of the retrieved file. Still, no problem in
this category is more interesting than a glitch discovered by Chris Evans in
2009.10 He noticed that the hallmark fault tolerance of CSS parsers (which,
as you may recall, recover from syntax errors by attempting to resynchronize
at the nearest curly bracket) is also a fatal security flaw.
In order to understand the issue, consider the following simple HTML
document. This document contains two occurrences of an attacker-controlled
Life Outside Same-Origin Rules 181
string, and—sandwiched in between—a sensitive, user-specific value (in this
case, a user’s name):
Page not found: ');} gotcha { background-image: url('/
...
You are logged in as: John Doe
...
Page not found: ');} gotcha { background-image: url('/
...
Let’s assume that the attacker lured the victim to his own page and, on
this page, used  to load the aforementioned cross-domain
HTML document in place of a stylesheet. The victim’s browser will happily
comply: It will request the document using the victim’s cookies, will ignore
Content-Type on the subsequent response, and will hand the retrieved content
over to the CSS parser. The parser will cheerfully ignore all syntax errors
leading up to what appears to be a CSS rule named gotcha. It will then process
the url('... pseudo-function, consuming all subsequent HTML (including the
secret user name!), until it reaches a matching quote and a closing parenthe-
sis. When this faux stylesheet is later applied to a class=gotcha element on the
attacker’s website, the browser will attempt to load the resulting URL and will
leak the secret value to the attacker’s server in the process.
Astute readers may note that the CSS standard does not support multi-
line string literals, and as such, this trick would not work as specified. That’s
partly true: In most browsers, the attempt will succeed only if the critical seg-
ment of the page contains no stray newlines. Some web applications are opti-
mized to avoid unnecessary whitespaces and therefore will be vulnerable, but
most web developers use newlines liberally, thwarting the attack. Alas, as noted
in Chapter 5, one browser behaves differently: Internet Explorer accepts
multiline strings in stylesheets and many other egregious syntax violations,
accidentally amplifying the impact of this flaw.
NOTE Since identifying this problem, Chris Evans has pushed for fixes in all mainstream brows-
ers, and as of this writing, most implementations reject cross-domain stylesheets that don’t
begin right away with a valid CSS rule or that are served with an incompatible Content-
Type header (same-origin stylesheets are treated less restrictively). The only vendor to
resist was Microsoft, which changed its mind only after a demonstration of a successful
proof-of-concept attack against Twitter.11 Following this revelation, Microsoft agreed not
only to address the problem in Internet Explorer 8 but also—uncharacteristically—to
backport this particular fix to Internet Explorer 6 and 7 as well.
Thanks to Chris’s efforts, stylesheets are a solved problem, but similar
problems are bound to recur for other types of cross-domain subresources.
In such cases, not all transgressions can be blamed on the sins of the old. For
182 Chapter 11
example, when browser vendors rolled out , a simple HTML5 mech-
anism that enables JavaScript to create vector and bitmap graphics,12 many
implementations put no restrictions on loading cross-domain images onto
the canvas and then reading them back pixel by pixel. As of this writing, this
issue, too, has been resolved: A canvas once touched by a cross-domain image
becomes “tainted” and can only be written to, not read. But when we need
tofix each such case individually, something is very wrong.
A Note on Cross-Origin Subresources
So far, we have focused on the risks of malicious websites navigating or
including content that belongs to trusted parties. That said, the ability to
load certain types of subresources from other origins has significant conse-
quences, even if not actively subverted by a third-party site.
In Part I of the book, we hinted that loading a script or a stylesheet
fromanother origin effectively equates the security of the document that
performs the load to the security of the origin of the loaded subresource; in
particular, loading an HTTP script on an HTTPS page undoes most of the
benefits of encryption. Similarly, loading a script from a provider whose
infrastructure is vulnerable to attack can be nearly as problematic as not
properly maintaining your own servers.
In addition to scripts and stylesheets, other content types that may lead
to serious trouble include remote fonts (a recent addition to CSS) and plug-
ins with access to the embedding page (such as allowScriptAccess=always for
Flash). It is also somewhat dangerous to load images, icons, cursors, or HTML
frames from untrusted sources, although the impact of doing so is contained
to some extent and will be use specific.
Contemporary browsers attempt to detect cases where HTTPS documents
load HTTP resources—a condition known as mixed content. They do so fairly
inconsistently, however: Internet Explorer is the only browser that blocks most
types of mixed content by default (and Chrome is expected to follow suit), but
neither Internet Explorer nor Firefox nor Opera consistently detects mixed
content on , , or  tags. In browsers other than Internet
Explorer, the default action is a subtle warning (for example, an exclamation
mark next to the lock icon) or a cryptic dialog, which does very little to pro-
tect the user but which may alert a sufficiently attentive web developer.
As to the other flavor of mixed content—loading subresources across
domains that offer different levels of trust—browsers have no way to detect
this. The decision to include content from dubious sources is often made too
lightly and such mistakes can be difficult to spot until too late.
NOTE Another interesting problem with cross-domain subresources is that they may request
certain additional permissions or credentials from the browser. The associated browser
security prompts are usually not designed with such scenarios with mind, and they do
not always make sufficiently clear which origin is requesting the permission and based
on what sort of relationship with the top-level site. We discussed one such problem in
Chapter 3: the authentication prompt shown in response to HTTP code 401. Several
other, related cases will appear in Chapter 15.
Life Outside Same-Origin Rules 183
Privacy-Related Side Channels
Another unfortunate and noteworthy consequence of the gaps in the same-
origin policy is the ability to collect information about a user’s interaction