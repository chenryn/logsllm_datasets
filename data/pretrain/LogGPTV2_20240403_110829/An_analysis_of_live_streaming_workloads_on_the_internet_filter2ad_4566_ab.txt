100-350 kbps.
Going back to the daily summary statistics presented in Fig-
ure 1, 600-800 of the daily streams are audio, and only 50 of the
daily streams are video. Most of the requests are for audio streams,
and roughly 50,000 of the daily requests, less than 1%, are for video
streams.
2.6 Data Sets
For the analysis in the following sections, we split the data into
the three sets listed in Table 1. The set All is the data for the entire
3-month period. The set DailyTop40 is composed of the top 20
most popular audio and top 20 video streams for each of the three
encoding formats for every day in the 3-month period, a total of
9,068 streams. The set Large has all the large-scale streams with
peak stream sizes of more than 1,000 concurrent clients. There are
a total of 660 large streams. As it happens, these streams are a
subset of the DailyTop40 set. The remaining 8,408 streams in the
DailyTop40 have smaller peak sizes.
To our knowledge, our data set is the most extensive live stream-
ing data in terms of number of streams and requests studied to date.
The streams served by Akamai are samples of the type of content
currently streamed on the Internet. We acknowledge that our data
set may not be a representative sample, as the data is likely biased
towards large and popular content publishers who are customers of
Akamai. For example, the folklore from ISP operators is that adult
content is a popular type of streaming content. However, Akamai
serves little to none adult content.
2.7 Macroscopic Analysis
Given the amount of data we have, it is infeasible to analyze
and present each stream in detail. Rather, our methodology is to
select representative statistics from each stream, and present the
distribution of those statistics across all streams. When we wish
to illustrate a (cid:2)ner point, we look at smaller data sets or individual
streams.
3. POPULARITY OF EVENTS
To understand how requests are distributed amongst the events,
we look at the popularity of events, as depicted in Figure 3. Popu-
larity, here, is de(cid:2)ned as the total number of requests for each event
across the entire 3-month period as shown on the y-axis. The x-axis
is the rank of the stream. Both axes are in log-scale. We (cid:2)nd that
the popularity distribution is Zipf-like with 2 distinct modes.
 Flatter: For 1,000 of the most popular streams with 10,000-
7.3 million requests, the popularity distribution (cid:2)ts a straight
line, exhibiting Zipf behavior, with an  of 1.01.
 Steeper: For the remaining streams, which are less popular,
with fewer than 10,000 requests the popularity is Zipf-like,
but with an  much larger than 1. We hypothesize that this
re(cid:3)ects the nature of using a CDN, in that publishers are un-
s
t
s
e
u
q
e
R
f
o
r
e
b
m
u
N
1e+07
1e+06
100000
10000
1000
100
10
1
1
Three months
One day
10
100
Event Rank
1000
10000
Figure 3: Popularity of events.
likely to pay a CDN to host unpopular content, as a single
server hosted by the content publisher may suf(cid:2)ce to get the
job done.
To see what the popularity distribution looks like at smaller
timescales, we randomly pick one day from our logs, and plot the
popularity distribution of requests that arrived on that one day on
the same scale as the 3-month distribution. As depicted in Figure 3,
the one-day distribution looks similar to the 3-month one.
Our (cid:2)ndings are in contrast to previously studied popularity dis-
tributions for Web objects that report that the popularity is Zipf-like
with only one mode [11, 9, 15, 2, 5]. However, a 2-mode Zipf distri-
bution is consistent with studies of on-demand streaming objects [1,
6] and multimedia (cid:2)le-sharing workloads [12].
4. CLASSIFICATION OF STREAMS
In this section, we present a scheme for classifying streams
(24-hour chunks of events) into types. We use this classi(cid:2)cation
throughout the paper when we wish to show that certain properties
are related to the type of stream.
4.1 Large vs. Small
There are several de(cid:2)nitions of large streams: total number of
requests (discussed in Section 3), total unique clients, and peak con-
current clients. While all three de(cid:2)nitions are related, for this paper,
we choose the third de(cid:2)nition: peak concurrent clients as it is an
indicator of how much server capacity needs to be provisioned to
accommodate the stream. Using the de(cid:2)nition from Section 2, large
streams have a peak of at least 1,000 concurrent clients. Out of our
3-month data set, 660 streams are large. All other streams are small.
4.2 Nonâ€ºStop vs. Short Durations
Non-stop streams are streams that are broadcast live every day,
all hours of the day. This is similar to always being (cid:147)on-the-air(cid:148) in
radio terminology. On the other hand, short duration streams have
well-de(cid:2)ned durations typically on the order of a few hours. An
example of a short-duration stream is a talk show that runs from
9am-10am that is broadcast only during that period, and has no traf-
(cid:2)c at any other time during the day. To distinguish between these
two stream types we look at the stream duration. However, the logs
do not provide us with any explicit stream duration (cid:2)eld. Therefore,
we estimate the stream duration using two different methods. We
then compare the resulting classi(cid:2)cation to con(cid:2)rm the accuracy of
the methods.
The (cid:2)rst method follows directly from our de(cid:2)nition that a non-
stop stream is always on 24-hours a day. To capture that prop-
erty, we estimate the (cid:147)stream duration(cid:148) from the logs. We de(cid:2)ne
the stream duration as the period of time for which the stream has

	
 or more concurrent receivers, where 
	

is set at 10.
A threshold of 10 is relatively robust at estimating stream duration
for large streams. If a stream duration is roughly 24 hours, then it is
a non-stop stream.
Note that this methodology does not work for small streams.
For example, consider an unpopular non-stop radio station that has
a sparse audience of 1-2 concurrent clients during the day and no
clients at night even though the content is available 24 hours a day.

	
 of 1, we would estimate the stream duration
Even with an 
to be only during the day, which is incorrect. For correctness, we
only classify large streams.
The cumulative distribution of stream durations for large streams
is depicted in Figure 4(a). The x-axis is the stream duration, and the
y-axis is the CDF. We (cid:2)nd that 76% of streams are non-stop, and the
remaining 24% have short durations. We also experimented with

	
 values and did not (cid:2)nd signi(cid:2)cant differences except
other 
for when the threshold was very low (1 or 2). In such cases, this
method was susceptible to including (cid:147)idle time(cid:148) in the stream du-
ration when one or two clients access the URL for a short duration
stream before the stream of(cid:2)cially started.
The second method examines the slope of the tail of the ses-
sion duration distribution, where a session duration is de(cid:2)ned as the
amount of time a request lasts (how long the client associated with
the request receives data). If a streamâ€™s tail has a steep slope, it is a
short duration stream. See Section 5.2 for a more detailed descrip-
tion of this property. Figure 4(b) depicts the cumulative percentage
of streams and the slope of the tail. Roughly 20% of streams had
a tail slope of -4 or steeper (where steeper means a more negative
number).
We then compared the streams classi(cid:2)ed using the two meth-
ods against one another and found a good agreement: roughly 92%
matched. When the two methods did not agree, it was for streams
that were short, but had relatively long stream durations (close to 24
hours).
We wish to note that in our data set, all video streams were
short. It is possible that the higher cost of delivering non-stop video
compared to audio is a deterrent for content publishers.
4.3 Recurring vs. Oneâ€ºTime
A recurring stream is de(cid:2)ned as one in which the event URL
(say Radio Station X) shows up on multiple days. Recurrence may
be periodic, for example, a daily event. Or, it may follow a pre-
determined schedule, for example, a cricket series will often use
the same URL for many of its matches throughout the series. We
(cid:2)nd that 97% of large streams are recurring. Note that all non-
stop streams are recurring by de(cid:2)nition. However, there are also
recurring short duration streams, such as daily 2-hour talk shows.
About 21% of large streams are these short recurring streams.
4.4 Flash Crowd vs. Smooth Arrivals
During a (cid:3)ash crowd, there is a large increase in the number of
people wanting to tune in to the stream. In turn, the arrival rate and
total number of concurrent clients increase at a rate that is higher
than average. A stream with smooth arrivals, on the other hand, sees
either no change or gradual changes (due to time of day effects).
All short duration streams have (cid:3)ash crowd behavior.
Intu-
itively, this is because short duration streams take place during a
speci(cid:2)c period, for example 2 hours. It is natural for people to want
to start joining and watching the stream from the beginning. In ad-
dition, a number of non-stop streams also have (cid:3)ash crowds. We
s
m
a
e
r
t
S
f
o
e
g
a
t
n
e
c
r
e
P
e
v
i
t
a
u
m
u
C
l
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
s
m
a
e
r
t
S
f
o
e
g
a
t
n
e
c
r
e
P
e
v
i
t
a
u
m
u
C
l
5
10
15
20
25
Stream Duration (hours)
(a) Stream duration.
0
-35
-30
-25
-20
-15
-10
-5
0
Tail Slope
(b) Tail slope.
Figure 4: Classify streams as non-stop or short.
believe that there are sometimes speci(cid:2)c content-related events that
happen for a brief period during the non-stop stream. For example,
an invited guest appearance can cause a (cid:3)ash crowd.
To detect whether or not a stream has (cid:3)ash crowd behavior, we
look at the streamâ€™s arrival rate over time. We (cid:2)rst ran a low-pass
(cid:2)lter on the data by looking at (cid:147)smoothed(cid:148) arrival rates, averaged
over 10-minute windows. Any sudden increase (large slope) in the
arrival rate is (cid:3)agged as (cid:3)ash crowd behavior. We (cid:2)nd that setting a
minimum threshold at a slope of 3 (a 3-times increase in the arrival
rate compared to the previous window) is reasonable based on visual
inspection. About 50% of the large streams are detected as having
(cid:3)ash crowd behavior.
The prominence of (cid:3)ash crowd events in the streams has several
implications on systems design. While there are a few systems de-
signs that consider (cid:3)ash crowds [19], the problem has been largely
ignored. Our (cid:2)ndings indicate that (cid:3)ash crowds are the norm in
live streaming workloads and systems must be able to cope with
sizable changes in the request volume. The system should be able
to support new hosts wanting to connect (in the Akamai network,
this requires a DNS-based name resolution to the IP address of a
server) and new hosts connecting to the system (a request packet to
a streaming server). Over-engineering, redundancy [4], and mecha-
nisms for rejecting requests to prevent the system from melt-down
in both the DNS and the streaming infrastructure can help. To our
knowledge, throughout the 3-month data collection period, the Aka-
mai network was able to serve the entire request volume presented
to it.
5. SESSION CHARACTERISTICS
In this section, we conduct our analysis on sessions. Recall that
a session is de(cid:2)ned at the granularity of a client request, i.e., one
request is one session. We (cid:2)rst look at the session arrival process,
and then at the session duration distribution.
5.1 Arrival Process
5.1.1 Highâ€ºLevel Characteristics
Figure 5 depicts the mean and median request interarrival times
for the DailyTop40 streams from all days, separated into large streams
vs. the small streams in the DailyTop40. The (cid:2)rst curve on the left
depicts the CDF of the observed median interarrival time for all
large streams. For example, 70% of large streams had a median
interarrival time of 1 second or less. The next curve is the mean
interarrival time for large streams, and the next two curves are for
the median and mean interarrival times for the remaining smaller
streams in the DailyTop40. Note that in interpreting this (cid:2)gure, the
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
s
m
a
e
r
t
S
f
o
e
g
a
t
n
e
c
r
e
P
e
v
i
t
l
a
u
m
u
C
0
0.1
Large Median
Large Mean
Small Top40 Median
Small Top40 Mean
1
10
100
1000
10000
100000
Interarrival (seconds)
Figure 5: Mean and median interarrival times for DailyTop40
streams.
order of streams sorted by the median is not necessarily the same as
the order sorted by the mean.
We make the following observations. First, the interarrival time
is generally shorter for large streams than for smaller streams. The
mean time between arrivals is at most 10 seconds for large streams,
whereas the mean time can be as high as 10,000 seconds for smaller
streams. This makes sense as large streams have more requests.
Second, the median interarrival time is generally smaller than the
mean indicating that there are some periods where the interarrival
time is much longer than the other periods.
In general, the arrival rate varies over time, and the arrival pro-
cess is not stationary over large timescales. We analyze the arrival
process at shorter (stationary) timescales and (cid:2)nd that exponen-
tial distributions can be used to model request interarrivals. Our
(cid:2)ndings are consistent with previously studied arrival processes of
on-demand streaming servers [1], live streaming servers [23], and
MBone multicast groups [3]. We do not present the modeling re-
sults due to space limitations.
Next, we discuss two types of behavior that contribute to changes
in the arrival rate: time-of-day effects and (cid:3)ash crowds.
5.1.2 Timeâ€ºofâ€ºDay Behavior
To illustrate that the arrival rate does indeed vary over time,
we show the number of active clients tuning in to a non-stop radio
station over a one-week period in Figure 6(a). The x-axis is the
date, and the y-axis is the number of clients. There are 7 peaks,
corresponding to the peaks on each day of the week. The smaller
 All 
 UK 
 US 
 PL 
 1200
 1000
 800
 600
 400
 200
s
t
s
o
H
f
o
r
e
b
m
u
N
 0
10/14
10/15
10/16
10/17