experiment to 2000 second, all the metric distributions have large
overlapped areas between good nodes and shifting attackers. For
outlier detection mechanisms, these results reveal that, the metric
distribution shifting is only one problem. Another more important
problem is that the Mahalanobis distance metric cannot differen-
tiate good nodes and shifting attackers. The reason why the out-
lier detection metrics fail on the shifting attack is that, both spatial
outlier detection and temporal outlier detection mechanisms rely
on coordinates movements to detect malicious nodes. If the mali-
cious nodes’ coordinates move wildly, they are more likely to be
detected. However, in the shifting attack, the malicious nodes can
mimic normal coordinates movements. This makes it hard for out-
lier detection mechanisms to identify these attackers.
2.5
2
1.5
1
0.5
r
o
r
r
e
e
v
i
t
a
l
e
R
0
0
200
Measured relative error
Kalman filter prediction
400
600
800
1000
Iterations
Figure 10: The prediction error of Kalman ﬁlter model on a
surveyor
For the Kalman ﬁlter detection mechanism, we can see from Fig-
ure 9 (c) and (f) that, the metric distributions are always very sim-
ilar on good nodes and shifting attackers. After removing a small
fraction of malicious nodes that are beyond detection threshold, the
Kalman ﬁlter prediction error metric loses its power to differentiate
good nodes and malicious nodes. Therefore, the detection proce-
dure ends up with very high false negative rate and a large fraction
of malicious nodes remaining in neighbor set. The reason why the
Kalman ﬁlter detection mechanism does not work well is that the
Kalman ﬁlter model itself yields large error in predicting the rel-
ative error of neighbor edges. The error mainly comes from two
sources. First, we observe that, the relative error of neighbor edges
has a large variance. The Kalman ﬁlter is an adaptive weighted
averaging ﬁlter. When the relative error has a large variance, even
when a node learns the Kalman ﬁlter model from its own experi-
enced error, it is still hard to predict its future error. To demonstrate
this observation, Figure 10 shows prediction error of the Kalman
ﬁlter model on a surveyor. The surveyor trains the Kalman ﬁl-
ter parameter from its recent neighbors’ error, and uses this ﬁlter
to predict its current neighbor’s error. From this graph, we can
see that, because the measured relative error has a large variance,
the Kalman ﬁlter model can only predict the general trend of error
curve, but it cannot predict particular neighbor error values accu-
rately. Second, the median delay among ordinary nodes and their
surveyors is 21 ms. When a node uses the Kalman ﬁlter model
learned by a remote surveyor node to predict its own neighbors’
error, the prediction error is even higher.
Figure 8 shows the results for the delay attack. We can make the
same observation that, all the statistical detection mechanisms fail
to mitigate the delay attack. In the delay attack, malicious nodes
are honest in computing their coordinates. Therefore the delay at-
tackers exhibit normal behavior in terms of coordinates movement
and thus the outlier detection mechanisms fail. The Kalman ﬁlter
detection mechanism works especially poorly on the delay attack.
It actually increases the fraction of malicious nodes in neighbor
sets. The reason is that Kalman ﬁlter detection is based on the
relative error of neighbor edges. However, in the delay attack, ma-
licious nodes attack the system by inﬂating their delays to other
nodes, which, because of how relative error is deﬁned, in most
cases, makes the malicious nodes exhibit smaller relative error than
good nodes.
4.4 Securing Network Coordinates in Two
Phases
The existing statistical detection mechanisms try to detect all
types of attacks by a single metric. However, our evaluation re-
sults reveal that they cannot provide satisfactory protection against
even simple attacks. This indicates the difﬁculty of detecting arbi-
trarily behaving malicious nodes by a small number of statistical
features. In this section, we address the coordinates security prob-
lem by a different approach. Instead of defending all types of at-
tacks as a whole, we decouple the coordinates security problem in
two parts. In each round of the coordinates embedding procedure, a
node takes two steps to update its coordinates. The ﬁrst step is delay
measurement, in which the node probes its neighbors to measure
the propagation delay. The second step is coordinates computation,
in which the node uses an optimization algorithm to compute its
own coordinates based on the neighbors’ delays and coordinates.
To secure network coordinates, both steps must be secured. There-
fore, the coordinates security problem has two parts: securing co-
ordinates computation and securing delay measurement.
4.4.1 Securing Coordinates Computation by
Byzantine Fault Detection
Let us at this moment assume that malicious nodes are honest in
delay measurements. They attack the network coordinates by only
reporting faked coordinates to other nodes.
Coordinates computation can be formalized as follows: for a
node A, at each embedding step i, its coordinates can be com-
puted by ci = f (ci−1,{ck
i }, si), where ci is A’s coordinates
i , dk
at the ith embedding step, {ck
i } are node A’s neighbors’ coor-
i , dk
dinates and delays, and si is the random seed used in the optimiza-
tion algorithm f (·). At the beginning of the embedding procedure,
c0 is initialized to the origin of the metric space. Note that, the
spring algorithm in Vivaldi requires the neighbors to reply an es-
timated error for the purpose of computation convergence. This
error value can be treated as an extra dimension of the neighbors’
coordinates. The optimization algorithm f (·) used in coordinates
computation is deterministic. Therefore, fundamentally, the coordi-
nates computation can be protected by well-known Byzantine Fault
Tolerance (BFT) [3] or Byzantine Fault Detection (BFD) [9] tech-
niques. BFT and BFD techniques represent different design points
in defending against Byzantine faulty nodes in distributed systems.
BFT techniques can tolerate f Byzantine faulty nodes out of 3f +1
nodes and prevent them from attacking the system. But BFT tech-
niques have large communication overhead and scale poorly. BFD
techniques detect Byzantine faulty nodes after they have attacked
the system, which is insufﬁcient to deal with faults that have ir-
reversible effects. But BFD techniques offer better efﬁciency and
scalability. In the case of coordinates computation, BFD techniques
are suitable since network coordinates can be recomputed after a
faulty node is detected. In the rest of this subsection, we show that
one BFD technique, PeerReview [9], can be applied to protect co-
ordinates computation.
PeerReview - To apply PeerReview to a certain distributed sys-
tem, the following general requirements must be satisﬁed:
(1) Any node n can be modeled as a deterministic state machine
Sn. Each node has access to a reference implementation of all Sn.
The implementation can create a snapshot of its state, and its state
can be initialized according to a given snapshot.
(2) Each node is associated with a set of witnesses. For a node
n, the witness set is denoted w(n). The set n ∪ w(n) must contain
at least one correct node.
(3) A message sent from one correct node to another is eventu-
ally received, if retransmitted sufﬁciently often. Each node has a
public/private key-pair bound to a unique node ID. Nodes can sign
messages, and faulty nodes cannot forge the signature of a correct
node.
PeerReview uses the following mechanisms to verify the behav-
ior of a node:
(1) Tamper-evident log: Each node keeps a secured log of its own
behavior. The log is secured by a hash chain. A log commitment
protocol is used to ensure that a node cannot add or hide messages it
sent and received in its log. Every time when a node communicates
with another node, it has to send the node the corresponding log
entry signed by its private key, which is called an authenticator.
(2) Auditing and consistency veriﬁcation: Suppose a node n is
associated with a set of witnesses w(n). Each witness w of n will
periodically challenge n to return all the log entries since the last
audit. Then w can create a local copy of n’s log. w can audit
n’s behavior by replaying the reference implementation of n’s state
machine with the same input in n’s log. If n does not follow the
state machine correctly, it will be detected as faulty. The witnesses
uses n’s signed log entries as veriﬁable evidence for faulty behav-
ior. Witnesses use a consistency protocol to verify the information
in n’s log entries. Suppose node n has communicated with a set
of nodes p(n). The witnesses collect all the authenticators n has
sent to p(n), and thus know whether n has lied about other nodes’
information or sent faked information to other nodes. To prevent
node n from colluding with nodes in p(n), each witness w will
also contact the witnesses of every node in p(n).
A node is called detectably faulty if it breaks the state machine
in a way that affects a correct node; a node is called detectably
ignorant if it never acknowledges that it received a message sent
by a correct node. It has been proven in [9] that PeerReview can
achieve the following security guarantees:
(1) Completeness: Eventually, every detectably ignorant node is
suspected forever by every correct node and every detectably faulty
node is detected or forever suspected by every correct node.
(2) Accuracy: No correct node is ever mistaken as a faulty node
by a correct node.
Suitability of PeerReview - Let us now show that a network
coordinates system satisﬁes all the PeerReview requirements.
(1) The coordinates computation is performed by a determinis-
tic state machine f (·). This state machine is available to all nodes
since all nodes use the same algorithm to compute their coordi-
nates. The coordinates are computed in a step by step fashion,
therefore it is easy to create a snapshot and initialize the state ma-
chine according to a given snapshot.
(2) PeerReview requires that for any node n, the set n ∪ w(n)
contains at least one correct node. By using a membership server to
randomly assign witnesses, this requirement can be achieved with
very high probability. For example, suppose 30% of the nodes are
malicious, even with just 5 randomly assigned witnesses for n, the
probability that n∪w(n) contains at least one correct node is 0.999.
(3) The third requirement of PeerReview is a general assumption
for distributed systems. A network coordinates system can meet
this requirement.
Customizing PeerReview - To use PeerReview to secure coor-
dinates computation, we only need to customize what should be
recorded in the secured log and what should be veriﬁed in the au-
diting procedure:
(1) Log entries: The secured log on each node contains all the
inputs and outputs it uses to compute coordinates. Every time
when a node sends or receives a message or computes its coor-
dinates, the node adds one entry to its log. Each log entry is a
3-tuple {seq, type, data}, where seq is a sequence number; type
is the entry type, and data contains the data associated with the
speciﬁc type of entry. There are three types of entry: PROBE,
PROBE_REPLY and COMPUTE. The PROBE type records the send-
ing or receipt of a probe message, the corresponding data contains
either the source (for receipt) or the destination (for sending) ad-
dress of the message. The PROBE_REPLY type records the send-
ing or receipt of a reply message, the corresponding data con-
tains the source (for receipt) or the destination (for sending) ad-
dress of the message and the replied coordinates ck
i (for receipt).
The COMPUTE type records coordinates computation, the cor-
responding data contains information about the computation, i.e.
{ci, ci−1, {dk
PROBE_REPLY).
i } is already recorded in
i }, si} (note that {ck
(2) Coordinates auditing: When a witness w audits a node n,
it simply recompute n’s coordinates with the information in n’s
log. If n’s coordinates are inconsistent with w’s computation, n is
detected as faulty, and w uses n’s log as a public proof.
Overhead evaluation - Suppose in a network coordinates sys-
tem, each node has N neighbors, and M witnesses. Every time
when a witness w audits a node n, it will contact node n, n’s
neighbors and the neighbors’ witnesses. This step has O(M N )
message complexity. Therefore, O(M 2N ) messages are required
to fully audit a node. Since M and N are constant numbers, the
communication overhead to audit a node does not increase when
the system scales up. Thus PeerReview has good scalability. How-
ever, O(M 2N ) messages per auditing is not ignorable overhead in
the system. Fortunately, because our stabilization algorithm makes
computing stable coordinates possible, the audit needs only to be
performed once after a node’s coordinates have stabilized. More-
over, PeerReview guarantees to detect faked coordinates; once a
node is deemed malicious, it can be forever banned from the sys-
tem. Thus, there is no more incentives for malicious nodes to fake
coordinates.
To quantify the communication incurred in auditing a node, con-
sider a network coordinates system using 5D Euclidean coordi-
nates. Assume each coordinate, delay, or random seed is 2 bytes,
sequence number or address is 4 bytes and the type ﬁeld is 1 byte.
Therefore, each PROBE entry takes 9 bytes; each PROBE_REPLY
entry takes 19 bytes, and each COMPUTE entry takes 2N + 27
bytes.
In one embedding step, a node probes all its neighbors
and computes its coordinates. This will add N PROBE entries,
N PROBE_REPLY entries, and one COMPUTE entry in its log,
i.e. 30N + 27 bytes. When a witness w audits one computa-
tion of a node n, w will retrieve the log entries from n, which is
30N + 27 bytes. For the consistency veriﬁcation protocol, w also
needs to collect the PROBE and PROBE_REPLY entries from all of
n’s neighbors and send them to n’s neighbors’ witnesses to verify
the information. This step transmits 28 × (M + 1) × N bytes.
Thus, altogether, when a witness w audits one computation of n,
28 × (M + 1) × N + 30N + 27 bytes of data is transmitted. Of
course, a witness in reality audits all the computations of a node
before it stabilizes in one batch, thus the data is transmitted in bulk.
By applying a compression tool such as gzip, the data can be com-
pressed to 30% of its original size.
Suppose N = 32, M = 5, and we make a pessimistic assump-
tion that a node stabilizes after 200 computation steps (this is pes-
simistic because it represents a scenario where a large number of
nodes join simultaneously), the audit of a node transmits a total of
1.9MB of data. In the common case, the number of computation
steps should be much smaller and the overhead will be proportion-
ally reduced. The power of this mechanism is that each node only
needs to be audited once after its coordinates stabilize to decide
whether its coordinates are faulty or correct. The audit result can
be recorded by the membership server for all nodes to see. If a node
refuses to stabilize, it must be detectably faulty and can be caught
easily.
4.4.2 Securing Delay Measurement by TIV
Detection
The difﬁculty of securing delay measurement is that delay mea-
surement relies on the honesty of end hosts. For two nodes A and
B, the only way for A to know the propagation delay between them
is to measure against B by sending probing packets. If node B is
honest and replies to a probing packet immediately after it is re-
ceived, after collecting enough samples, A can obtain the true prop-
agation delay between A and B. However, if node B is malicious,
it can manipulate the delay by not replying to a probing packet im-
mediately. There is no foolproof way for node A to differentiate
the real network propagation delay from the artiﬁcial delay added
by B.
Note that a malicious node cannot shorten the propagation delay.
Node A can simply add a random number in each probing packet
and require B to include the random number in the reply packet.
Thus, B cannot shorten network delay because it cannot generate
a reply before receiving the probe. With this observation, we can
design a strategy to protect delay measurement.
Statistical detection of faked delays - Since PeerReview can
guarantee the security of coordinates computation, the only remain-
ing way a malicious node can impact good nodes’ coordinates is to
inﬂate the delays to them and mislead their coordinates. This is ex-
actly the behavior of the delay attack. In the previous section, we
have already seen that all existing statistical detection mechanisms
fail to mitigate the delay attack. However, now that we have nar-
rowed down the coordinates security problem to a speciﬁc kind of
attacks, delay attacks we can design a statistical detection mecha-
nism to protect good nodes’ coordinates against faked delays.
The way delay attackers impact good nodes’ coordinates is that
the artiﬁcially inﬂated delays can cause more triangle inequality
violations (TIVs) in the delays among neighbors. If good nodes
use these faked delays to compute their coordinates, the coordinates
will have very poor accuracy. However, a point we want to clarify
is that, the inﬂated delays do not always cause more TIVs in the
n
o
i
t
c
n
u
F
y
t
i
s
n
e
D
y
t
i
l
i
b
a
b
o
r
P
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
0
Good nodes
Malicious nodes
1
2
Prediction ratio metric in TIV detection
3
4
5
0.5
t
e
s
r
o
b
h
g
e
n
n
i
i
s
e
d
o
n
s
u
o
c
i
i
l
a
M
f
o
n
o
i
t
c
a
r
F
0.4
0.3
0.2
0.1
0
0
500
10% delay attackers
20% delay attackers
30% delay attackers
50% delay attackers
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
Vivaldi(no malicious nodes)
Vivaldi(10% delay attackers)
Vivaldi(20% delay attackers)
Vivaldi(30% delay attackers)
Vivaldi(50% delay attackers)
Vivaldi+TIV detection(10% delay attackers)
Vivaldi+TIV detection(20% delay attackers)
Vivaldi+TIV detection(30% delay attackers)
Vivaldi+TIV detection(50% delay attackers)
i
n
o
i
t
u
b
i
r
t
s
d
e
v
i
t
a
u
m
u
C
l
1000
1500
Simulation time(s)
2000
2500
0
0
1
2
3
Relative error
4
5
(a)
(b)
(c)
Figure 11: The performance of TIV detection on delay attack (a) Metric distribution (b) Detection performance (c) Coordinates
accuracy
network. If a powerful delay attacker knows all the delays among
other nodes, it can manipulate its delays to other nodes to reduce
the TIVs in the network. But in this case, these faked delays do not
signiﬁcantly hurt good nodes’ coordinates. Previous study [15] has
shown that, when there are fewer TIVs in the network, the nodes’
coordinates have better accuracy. Therefore, when we consider the
delay attacks, what we care most are those faked delays that cause
severe TIVs in the network and hurt good nodes’ coordinates. This
inspires our idea to protect good nodes’ coordinates against faked
delays using the TIV alert technique proposed in [33]. The TIV
alert technique uses the prediction ratio ( predicted
measured ) of coordinates
as a heuristic indicator to detect the edges causing severe TIVs in
the network. As discussed in [33], the edges that cause severe