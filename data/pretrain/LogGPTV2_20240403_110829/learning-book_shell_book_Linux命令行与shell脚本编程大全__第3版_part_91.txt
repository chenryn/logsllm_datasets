26.2获取格言
575
Resolving wn.quotationapage,con... 57.228.101.64
ConnectLng to twr_quotationspage.com|67,228.101. 641:80 connected
HTTP requeat sent, awalting response... 2oo OK
Length: unspeci fied [text /html]
Saving to: *qotd.html.3*
[
113 , 80 6
- , K/α
1n 0.1a
[9081 p8e .=*tu*paob, - (8/88 9*86) 1z=2:60 22-60-5102
每日格言脚本最终会通过cron（参见第16章）或其他的脚本自动化工具设置成每天执行一次。
所以让wget命令的会话输出出现在STDOUT是不合适的。可以使用-o选项将会话输出保存在日志
文件中，随后再浏览。
S url=www.quotationspage.con/qotd.html
S vget =o quote.1og $ux1
S cat quote.1og
=20150923 09 :41 :46--  http: / /vww, quotat.1on.spage com/qotd. htn1
Resolving wwv.quotationspage con... 67,228 .101.64
Connect1ng to wwv.quotationspage, com |67, 228 101 ,64 I :80 connected.
Length: unspecified [text/htm1]
HTTP request sent, awalting response... 2oo OK
Saving to: *qotd.html .1*
81.7K=0 .2a
20150923 09:41:46 (81.7 KB/a) - *qotd.htn1,1* saved [13806]
$
现在，当wget检索到Web页面信息时，它会将会话输出保存在日志文件中。如果需要，你可
以像上面代码中那样使用cat命令浏览会话日志。
说明出于各种原因，你可能不考望wget生成目志文件或显示会语输出。如果是这样的话，可
以使用-q选项，wget命令会安安静静地完成你下达给它的任务。
要控制Web页面信息保存的位置，可以使用wget命令的-O选项。这样你就可以自己指定文
件名，而不是非得使用Web页面的名字作为文件名。
26
S url=w,quotationspage,con/qotd .html
S vget -o quote.log -0 Daily_Quote.htnl $ur1
S cat Daily_Quote.html
---
## Page 591
576
第26章一些小有意思的脚本
[ - .. ]
-O选项允许将Web页面数据保存在指定的文件Daily_Quote.html中。现在我们已经能够控制
wget工具的输出了，下一个需要的功能是核查Web地址的有效性。
2.测试Web地址
Web地址会发生变化。这些地址有时候似乎每天都在变。所以在脚本中测试地址的有效性就
非常重要。可以使用wget工具的--spider选项完成这项任务。
S ur1=ww.quotationspage.con/qotd.htnl
tang xaprds-- aobn S
Spider node enabled. Check if renote file exiata.
Reso1ving www quotatlonapage,com... 57-228.101. 64
--20150923 12 :45:41-- http= / /wwv , quotat1onspage . com/qotd.htm1
Connect1ng to wwv. quotat.ionspage com167 .228 -101 , 64l :80 connect.ed,
HTPP reguest. sent, avaiting response... 20o OK
Length: unspeciEled [text/htm1]
but recurslon La diaabled -- not retrleving.
Renote file exlsts and could contaln fuxther linkcs,
命令输出表明指定的URL是有效的，但就是输出的内容太多了。可以加上-nv（代表
non-verbose）选项来精简输出信息。
[ang xeptds-- Au- qoBn
6=2 22-60-5102
URL: http: //wuv. quotat ionspage ,com/qotd.hta1 20o oK
-nv选项只显示出Web地址的状态，这种输出要容易理解得多。不过和你认为的恰恰相反，
行尾的ok并不是说Web地址是有效的，而是表明返回的Web地址和发送的地址是一样的。这个概
念有点让人迷惑，等你看到无效的Web地址是什么样的时候就能明白了。
将URL变量的内容修改成一个错误的Web地址，看看wget是如何显示的。使用错误地址重新
发出wget命令。
S ur1=ww.quotationspage.con/SAD_uRL.htn1
S uget -nv --spider $ur1
2015-09-23 12:54:33
URL: http://wuv,quotationspage ,com/errox404 html 200 OK
注意，输出的最后仍然是ok。但是Web地址的结尾是error404.html。这才表示Web地址是
无效的。
使用必要的wget命令抓取励志格言的Web贝面，并能够测试贞面地址的有效性，现在可以来
---
## Page 592
26.2获取格言
577
动手编写脚本了。你的每日励志格言正在等着你呢。
26.2.2创建脚本
要在脚本编写过程中进行测试，需要将一个包含网站URL的参数传递给脚本。在脚本中，变
量qutoe_url包含了传入参数的值。
quote_url=$1
1.检查所传递的URL
在脚本中多做检查总是没错的。要检查的第一件事就是确保每日励志格言脚本所使用的网站
URL是有效的。
和你想的一样，脚本仍l旧使用wget和--spider选项来检查Web地址的有效性。但是结果必
须保存到变量中，以便随后使用ir语句进行检查。使用wget命令实现这一点稍微有些麻烦。
要保存输出结果，需要在命令上使用标准的S{1语法。除此之外，还得重定向STDERR和
STDOUT。这可以通过在wget命令后使用2>&1来实现。
check_ur1=$ (vget -nv --spider Squote_ur1 2>&1)
现在网站URL的状态消息被保存在了变量check_ur1中。要从变量中找出错误指示
error404，需要使用参数扩展和echo命令。
bad_url=$ (echo ${check_ur1/*error404*/error404))
在这个例子中，宇符串参数扩展（string parameterexpansion）允许对保存在check_ur1中的
字符串进行搜索。可以把字符串参数扩展视为sed的另一种简单快速的替代形式。在搜索关键词
周围加上通配符（*error404*），这样可以搜索整个字符串。如果找到了，echo命令会使得字
符串error404被保存在bad_ur1变量中。要是没有找到,bad_ur1变量中包含的就是check_ur1
变量中的内容。
现在可以使用if语句（参见第12章）检查bad_ur1变量中的字符串了。如果从中找到了
error404，则显示一条消息，然后退出脚本。
if [*Sbad_url* = *error404* ]
26
then
echo *Bad veb address*
echo *$quote_url invalid*
echo
*Exiting script...*
exit
fi
---
## Page 593
578第26章一些小有意思的脚本
还有一种更简洁易行的方法。这种方法完全不需要使用字符串参数扩展和bad_ur1变量。if
语句的双方括号可以对变量check_ur1进行搜索。
if [{ $check_ur] == *error4o4* ]]
then
echo *$quote_url invalid*
echo *Bad veb address*
echo *Exiting script...*
fi
ex1t
iE结构中的test语句搜索变量check_ur1中的字符串。如果从中找到了子串error404，则
显示提示信息并退出脚本。要是没有发现错误，脚本继续执行。这条语句可谓省时省力，不需要
使用任何的字符串参数扩展，甚至连bad_ur1变量都用不着。
现在检查工作已经就绪了，可以用一个无效的Web地址来测试一下脚本。将ur1变量设置成
一个错误的URL，作为参数传给get_quote.sh脚本。
$ ur1=ww.quotationspage com/BAD_URL.htn]
$-/get_quote.sh $url
ww, quotat ionspage -com/BAD_URL .html invalid
ssaippe qan peg
Exiting script...
者起来没间题。为了确保方无一失，再试试有效的Web地址。
 ur1=ww,quotationspage,con/gotd.htnl
$ -/get_quote.sh $ur1
没有出现错误。到目前为止一切顺利！目前只是做了必要的检查，下一个需要加入脚本的功
能是获取Web页面的数据。
2.获取Web页面信息
抓取每日励志格言的页面数据很简单。可以在脚本中使用本章先前讲过的wget命令。唯一
需要的改变就是将日志文件和包含页面信息的HTML文件保存在/tmp目录中。
[n≥onbs uauonb/@u/ 0- Eo*=qonb/d/ o- a
在编写脚本的其余部分之前，需要使用一个有效的Web地址测试这部分代码。
 ur1=ww,quotationspage,con/gotd.htnl
$ -/get_quote-sh $ur1
S 18 /tnp/quote.*
/tmp/quote 1og  /tnp/quote htn1
$ cat /tap/quote.htm]
---
## Page 594
26.2获取格言
579
[. . .]
窍门如果在获取网站信息时不需要cookie，可以加入wget命令的--no-cookies选项。默认情
况下是不会存储cookie的
下一个任务是从下载好的Web页面文件的HTML代码中找出每日励志格言。这需要借助sed
工具和gawk工具。
3.解析出需要的信息
为了找出实际的励志格言，需要做一些处理。这部分脚本将使用sed和gawk来解析出需要的
信息。
说明当根据自己的需要修改这个脚本时，这部分需妥作出的变动最大。sed和gawk工其用来搜
索针对特定格言网站数据的关键字。可能需妥使用不同的关键字以及不同的sed/gawk命令
来提取需要的数据。
脚本首先从保存着Web页面信息的/tmp/quote.html文件中删除所有的HTML标签。sed工具能
够完成这项任务。
sed α/] *//g* /tap/quote.htn]
上面的代码看起来非常眼熟，我们在21.7.6节中讲过。
删除掉HTML标签后，输出信息变成了下面的样子。
S url=www.quotationspage.com/qotd.htm1
S ./get_quote.sh Sux1
26
[ - + - ]
>Quotes of the Day - The Quotations Page>
>>Selected fron KMlchael Moncur*a Collection of Quotatlona
[. . ]
- Septenber 23, 2015>>
[..- ]
---
## Page 595
580
第26章
一些小有意思的脚本
从这段经过删节后的输出信息可以看出，文件中还有太多无用的数据，因此还需要进一步解
析。幸运的是，我们需要的格言正好位于当前日期的右边。因此脚本可以使用当前日期作为搜索
关键字！
这里需要用到grep命令、${1以及date命令。sed命令的输出通过管道传人grep命令。grep
命令经过格式化的当前日期来匹配格言页面中的日期。找到日期文本之后，使用-A2选项提取出
另外两行文本。
sed *α/]*//g* /tnp/gquote,htn] |
grep *$(date +3**↓-d,+*$Y) *-A2
现在，脚本的输出如下。
S -/get_quote.ah Sur1
>>Selected fron Michael Moncur'a Collection of Quotatlon.8
>>>Horse sense ia che thing a hoxae haa which keepa It fron
- Septenber 23, 2015>>
bett1ng on peop1e.> >>>>>>>>>>>>>>>>>N, C. F1e1ds>(1880 -
1946]> 4nbap; >>>
>>ieuspapermen learn to cal1 a murderer *an alleged murderex
and the King of England the alleged King of England' to
avoid 11be1 sultα,> >>>>>>>>>>>>>>>>>>Stephen Leacock> (1869
-1944]> snbsp; >>> - Hoxe quotatlons on: [>Jouxmalian>] >
S
窍门如果Linux系统的目期设置和格言页面上的日期不一样，你只能得到一个空行。上面的
grep命令假定你的系统日期和Web页面上的目期是相同的。
尽管输出的信息量已经大为降低，但是文本仍然太杂乱。多余的>符号可以很轻松的使用sed
工具删除掉。在脚本中，grep命令的输出被管接到sed工具中，后者用来移除>符号。
1Tuqaonb/du/ ,6//[/α。 paα
,6//]*//g* /tnp/quote,htm1 1
#
1zY- - [As,.*ps, ,gs+ eep1s。 dex6
sed *α/>/ /g* 1
sed /&nbap;/(n ; d) *
可以测试一下脚本看看新加人的sed命令是否能够解决多条格言的问题。
S ./get_quote.sh $ur1
Selected fron Michael
- Septerber 23, 2015
Moncur'a Collectlon of QuotatLong
Horse sense ia the thing a horse has which keepa it fron
betting on people. N. C. Flelds (1880 - 1946) &nbap;
多余的格言被删掉啦！留下来的那条还需要继续清理。在格言的末尾仍然有一个字符串
&nbsp：。脚本可以使用另一条sed命令来解决这个麻频，不过出于多样性的考虑，我们这次使用
gawk命令。
1twau*eonb/du/ ,6//+[/8, pes
F
grep *$1date +LB+ +$-d,* *sY) * -A2 1
sed */snbsp;/[n ; d) * |
sed 'α/>/ /g′ |
[T$ auTxd) (=dequ=s&1αIosg. yne6
在上面的代码中，gawk命令使用了输人字段分隔符FS（参见第22章）。这个字段分隔符被设
置成字符串snbsp：，这样会使得gawk从输出中把它丢弃掉。
S ./get_quote.sh $url
Selected fxon Michael
1 Moncura Collection of Quotatlona
- Septerber 23, 2015
Horse sense la the thing a horse has which keepa It Cron
26
betting e people. N. C. Flelda (188o - 1946)
脚本要做的最后一步是将格言保存到文件中。这里该tee命令（参见第15章）登场了。目前，
整个格言提取过程如下。
tuau*esonb/du/ ,6/ /[/8, pes
---
## Page 597
582
第26章
一些小有意思的脚本
grep *$(date +13+*4-d, **$Y)*-A21
sed */&nbsp;/ (n : d)* 1
sed *s/>//g* 1
1 (t$ auTxd) (rdequs=ga)xiogg, xnef
tee /tmp/daily_quote txt
> /dev/nu11