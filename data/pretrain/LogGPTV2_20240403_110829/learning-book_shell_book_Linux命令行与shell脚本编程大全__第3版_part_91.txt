### 26.2 获取格言

#### 26.2.1 使用 `wget` 抓取网页数据

每日格言脚本最终会通过 `cron`（参见第16章）或其他自动化工具设置为每天执行一次。因此，让 `wget` 命令的会话输出出现在标准输出 (`STDOUT`) 是不合适的。可以使用 `-o` 选项将会话输出保存到日志文件中，随后再浏览。

```bash
url="www.quotationspage.com/qotd.html"
wget -o quote.log $url
cat quote.log
```

当 `wget` 检索到 Web 页面信息时，它会将会话输出保存在日志文件中。如果需要，你可以像上面代码中那样使用 `cat` 命令浏览会话日志。

**注意**：出于各种原因，你可能不希望 `wget` 生成日志文件或显示会话输出。如果是这样的话，可以使用 `-q` 选项，`wget` 命令会安静地完成任务。

要控制 Web 页面信息保存的位置，可以使用 `wget` 命令的 `-O` 选项。这样你就可以自己指定文件名，而不是使用 Web 页面的名字作为文件名。

```bash
url="www.quotationspage.com/qotd.html"
wget -o quote.log -O Daily_Quote.html $url
cat Daily_Quote.html
```

#### 26.2.2 创建脚本

要在脚本编写过程中进行测试，需要将一个包含网站 URL 的参数传递给脚本。在脚本中，变量 `quote_url` 包含了传入参数的值。

```bash
quote_url=$1
```

##### 1. 检查所传递的 URL

在脚本中多做检查总是没错的。要检查的第一件事就是确保每日励志格言脚本所使用的网站 URL 是有效的。

```bash
check_url=$(wget -nv --spider $quote_url 2>&1)
bad_url=$(echo ${check_url/*error404*/error404})

if [[ $bad_url == *error404* ]]; then
    echo "Bad web address"
    echo "$quote_url is invalid"
    echo "Exiting script..."
    exit
fi
```

还有一种更简洁的方法，不需要使用字符串参数扩展和 `bad_url` 变量：

```bash
if [[ $check_url == *error404* ]]; then
    echo "$quote_url is invalid"
    echo "Bad web address"
    echo "Exiting script..."
    exit
fi
```

现在检查工作已经就绪，可以用一个无效的 Web 地址来测试一下脚本：

```bash
url="www.quotationspage.com/BAD_URL.html"
./get_quote.sh $url
```

##### 2. 获取 Web 页面信息

抓取每日励志格言的页面数据很简单。可以在脚本中使用 `wget` 命令，并将日志文件和包含页面信息的 HTML 文件保存在 `/tmp` 目录中。

```bash
wget -o /tmp/quote.log -O /tmp/quote.html $quote_url
```

在编写脚本的其余部分之前，需要使用一个有效的 Web 地址测试这部分代码：

```bash
url="www.quotationspage.com/qotd.html"
./get_quote.sh $url
```

##### 3. 解析出需要的信息

为了找出实际的励志格言，需要做一些处理。这部分脚本将使用 `sed` 和 `gawk` 来解析出需要的信息。

首先从保存着 Web 页面信息的 `/tmp/quote.html` 文件中删除所有的 HTML 标签：

```bash
sed 's/<[^>]*>//g' /tmp/quote.html
```

删除掉 HTML 标签后，输出信息变成了下面的样子：

```bash
Quotes of the Day - The Quotations Page
Selected from Michael Moncur's Collection of Quotations
...
- September 23, 2015
...
```

从这段经过删节后的输出信息可以看出，文件中还有太多无用的数据，因此还需要进一步解析。幸运的是，我们需要的格言正好位于当前日期的右边。因此脚本可以使用当前日期作为搜索关键字！

这里需要用到 `grep` 命令、`${}` 以及 `date` 命令。`sed` 命令的输出通过管道传入 `grep` 命令。`grep` 命令经过格式化的当前日期来匹配格言页面中的日期。找到日期文本之后，使用 `-A2` 选项提取出另外两行文本。

```bash
sed 's/<[^>]*>//g' /tmp/quote.html | grep "$(date +'%B %d, %Y')" -A2
```

尽管输出的信息量已经大为降低，但是文本仍然太杂乱。多余的 `>` 符号可以很轻松地使用 `sed` 工具删除掉。在脚本中，`grep` 命令的输出被管接到 `sed` 工具中，后者用来移除 `>` 符号。

```bash
sed 's/<[^>]*>//g' /tmp/quote.html | grep "$(date +'%B %d, %Y')" -A2 | sed 's/>//g'
```

多余的格言被删掉啦！留下来的那条还需要继续清理。在格言的末尾仍然有一个字符串 `&nbsp;`。脚本可以使用另一条 `sed` 命令来解决这个问题，不过出于多样性的考虑，我们这次使用 `gawk` 命令。

```bash
sed 's/<[^>]*>//g' /tmp/quote.html | grep "$(date +'%B %d, %Y')" -A2 | sed 's/>//g' | gawk -F'&nbsp;' '{print $1}'
```

脚本要做的最后一步是将格言保存到文件中。这里该 `tee` 命令登场了。目前，整个格言提取过程如下：

```bash
sed 's/<[^>]*>//g' /tmp/quote.html | grep "$(date +'%B %d, %Y')" -A2 | sed 's/>//g' | gawk -F'&nbsp;' '{print $1}' | tee /tmp/daily_quote.txt > /dev/null
```

这样，我们就完成了每日格言的获取和解析。