BitTorrent.
P2P. In the P2P design, each peer keeps constant rate
streams with a ﬁxed number of other peers, and inserts
payload into these streams; that is, at every time unit, the
sum of chaﬀ bytes and real traﬃc bytes is constant. When
forming the P2P overlay paths, ﬂows may be unevenly dis-
tributed over streams (i.e., several ﬂows may share the same
links), meaning some number of streams generate only chaﬀ
traﬃc (pure overhead) while others generate only payload
traﬃc. As the number of P2P connections n increases the
number of chaﬀed overlay links increases, while the number
of payload ﬂows remains constant. Thus, the overhead ratio
increases for P2P as k increases.
Aqua. For Aqua, the overhead comes from chaﬀ traﬃc gener-
ated by kset members with less payload than the kset trans-
fer rate. This chaﬀ traﬃc is generated only while a kset is
active. Because ksets have relatively short lifetimes, peers
spend less time generating chaﬀ traﬃc than in the other
designs, thus contributing to a signiﬁcantly lower overhead.
Furthermore, we observe that the overhead ratio decreases
with larger k because the amount of traﬃc (chaﬀ or pay-
load bytes) sent over each link is constrained by the slowest
connection. Larger ksets are likely to include relatively low-
bandwidth peers, which reduces the rate at which each host
sends traﬃc. These lower rates lead to relatively lower over-
head for ﬂows containing only chaﬀ traﬃc.
Throttling. We show the throttling results for the
constant-rate, broadcast, P2P, and Aqua designs in Fig. 4.
At a high level, the volumes of chaﬀ traﬃc required by
Broadcast and P2P are quite large; Aqua reduces this throt-
tling by grouping peers with similar bandwidth demands
into the same ksets, then tearing down ksets as soon as all
members’ ﬂows have completed. The constant-rate design
has no throttling, as expected, at the expense of high over-
head.
Constant rate. The constant-rate design has no throttling
because all endpoints always send or receive traﬃc at their
capacity rate.
Broadcast. Throttling in the Broadcast design depends on
the groups’ capacities and sizes k, and the payload band-
width demand of peers. The impact of groups’ capacities on
y
t
i
c
a
p
a
c
/
d
a
e
h
r
e
v
O
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Overhead of Traffic Obfuscation at the Edges
Throttling of Traffic Obfuscation at the Edges
n
o
i
t
a
z
i
l
i
t
u
t
n
e
r
r
o
T
t
i
B
/
s
e
t
y
b
d
e
l
t
t
o
r
h
T
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Aqua
Download
Upload
Constant Broadcast
P2P
Designs
Aqua
Download
Upload
Constant Broadcast
P2P
Designs
Figure 3: Overhead of traﬃc obfuscation at the
edges for the diﬀerent designs. Shown on the y axis
are the median, 10th and 90th percentile of the over-
head. The bars from left to right for Broadcast, P2P,
and Aqua correspond to k equals 10, 100, and 1,000.
Note that Constant-rate is not parameterized by k,
so we show its overhead for the number of peer in
our traces.
throttling is minimal in our simulations because we assign
peers to broadcast groups based on their bandwidth capac-
ities. The main factor aﬀecting the degree of throttling is
k because the capacity available for payload in a broadcast
group is 1/k. We see in Fig. 4 that there is little throttling
for k = 10 because there is enough available bandwidth to
satisfy peers’ demand rate (5% in the median case). How-
ever, throttling increases considerably for larger k because
the bandwidth available for payload is insuﬃcient to meet
peers’ demands.
P2P. In the P2P model, the number of overlay links in-
creases with n and so the capacity of individual P2P links
decreases. As a result, the throttling increases with the size
of the anonymity set.
Aqua. With Aqua, the median download throttling remains
between 0.02 and 0.21 for all values of k. When all peers in
a kset have suﬃcient capacity, ﬂow rates ramp up without
throttling. When a fraction of peers ﬁnish their ﬂows before
others, there is throttling for idle peers until all peers can
ramp down simultaneously. The impact of this throttling is
limited because ﬂows in BitTorrent are short-lived.
Throttling increases with k = 1, 000 because it is more
likely that a high-capacity peer joins a kset with a lower-
capacity peer, forcing the high-capacity peer to throttle its
throughput to that of the lowest-capacity peer. A potential
optimization is to prevent such ksets from forming unless
there is no alternative option, or even delaying a transfer to
wait for a suﬃcient number of peers with similar capacity
to appear.
4.4.2 Mix performance
Next, we present the results for network overheads in-
curred by routing traﬃc over multiple hops, where traﬃc
Figure 4: Throttling of the diﬀerent designs due to
traﬃc obfuscation at the edges. Shown on the y
axis are the median, 10th and 90th percentile of the
throttling. The bars from left to right for Broadcast,
P2P, and Aqua correspond to k equals 10, 100, and
1,000.
is mixed and chaﬀed. Note that these results apply only
to designs that use mixes, namely, Constant-rate and Aqua.
We ﬁnd that, in general, Aqua has low overhead in the core,
because multipath routing evenly balances payload traﬃc
across mixes, reducing the need for chaﬀ.
Methodology. For this evaluation, we use a twenty-mix
full mesh topology, and simulate single-path routing, multi-
path routing, and perfect routing. Here, perfect routing
assumes that ﬂows can be split and routed perfectly among
all the mixes and links, i.e., distributed evenly so as to mini-
mize the necessary chaﬀ traﬃc. For multi-path routing, the
number of paths for each ﬂow is the number of mixes mi-
nus two, as described in Section 3. We provision the mix
network with aggregated bandwidth required by the worst
case, Constant-rate with single path routing.
In Constant-rate simulations, each pair of mixes exchange
traﬃc at the same constant rate, which is the maximum
payload rate on all links over all the simulation time.
In
Aqua simulations, we allow link rates to vary uniformly every
hour, so at any time, the rates on all links are identical, and
equal to the maximum link payload rate in this hour.
Overhead. We show the overhead of Constant-rate and
Aqua in Fig. 5, each with three routing schemes, single-
path routing, multi-path routing, and perfect routing, re-
spectively. Although Constant-rate with single-path routing
has a median overhead above 0.49, the overhead is reduced
to 0.1 when multi-path routing is used.
Compared to Constant-rate, Aqua mixes can dynamically
change rates. As a result, overheads are signiﬁcantly lower—
less than 0.01 in all cases. Taking Aqua receive rates as
an example, we ﬁnd that overhead is 0.0093 for single-path
routing, and less than an order of magnitude smaller when
using multi-path (0.00088). While the absolute diﬀerence is
small in this case, it is relative to a large capacity required
for Constant-rate traﬃc. Thus, in practice multipath can
y
t
i
c
a
p
a
c
/
d
a
e
h
r
e
v
O
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Overhead of Traffic Obfuscation in the Core
Download
Upload
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
Latency of Multiple Hops
Direct
Onion routing
Aqua (10ms)
P2P
s
h
t
a
p
f
o
F
D
C
Constant
   Aqua
Designs
0
0
1000
2000
Median latency (ms)
3000
4000
5000
Figure 5: Overhead for traﬃc obfuscation in the
core for diﬀerent designs. Shown on the y axis are
the median, 10th and 90th percentile of the over-
head. The bars from left to right for Constant-rate
and Aqua correspond to single-path, multi-path, and
perfect routing.
Figure 6: Median latency for paths using the diﬀer-
ent designs, based on latency data gathered from
end users. The cumulative distribution function
shows that Aqua with 10 ms delay has only 12%
higher latency than onion routing and 20% lower la-
tency than an approach that routes exclusively over
end users (labeled P2P).
lead to substantial overhead savings relative to single-path
routing.
4.4.3 Multi-hop Latency
Next, we consider the question of how much additional
latency is imposed by each anonymity system and determine
its impact on transfer rates. Our key ﬁnding is that latency
for Aqua is comparable to that of onion routing, and the
added latency will not signiﬁcantly impact the rates for the
vast majority of BitTorrent ﬂows in our dataset.
Methodology. Our deployment model for Aqua includes
mixes that are located in hosting providers in the core of the
network, e.g., in well-connected points of presence (PoPs).
To model the latency overhead in Aqua, we would like to
use empirical delays from peers in edge networks to hosts in
popular PoPs, and delays between hosts in popular PoPs.
Furthermore, we want to include a set of delays exclusively
between peers in edge networks to compare with an approach
such as Tarzan.
To address these needs, we use latencies gathered from