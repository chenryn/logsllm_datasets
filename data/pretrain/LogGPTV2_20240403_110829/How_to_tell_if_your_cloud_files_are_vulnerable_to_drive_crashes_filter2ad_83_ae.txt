protocol. In Figure 6, we show the 100% separation between the
honest and adversarial servers deﬁned as the difference between
the minimum adversarial response time and the maximum honest
response time in a challenge. Where the time in the graph is neg-
ative, an adversary using two drives could potentially convince the
client that he is using three drives as promised.
One way for the adversary to cheat is to ignore the protocol en-
tirely and instead read the whole ﬁle sequentially into memory and
then respond to challenges. In the 10 MB ﬁle case this becomes
the optimal strategy almost immediately, and thus both the average
and complete separation graphs are entirely negative. For the 100
MB ﬁle this strategy becomes dominant around 100 steps. At this
point, reading the ﬁle sequentially becomes faster than performing
100 random seeks. The turning point for the larger ﬁles is much
higher and thus not visible in these graphs. Since an adversary can
choose how to respond to the challenges, and may in fact read the
ﬁle into memory to answer queries, a RAFT will only be effective
for relatively large ﬁles.
We plot in Figures 7-10 the actual read-time histograms for both
honest and adversarial servers for the shown number of steps in
the lock-step protocol. Using 10 steps for the 10 MB ﬁle achieves
no separation between honest and adversarial servers, due to the
fact that the ﬁle ﬁts completely in the disk buffer (running for more
steps would only beneﬁt the adversary). For a 100MB ﬁle, there
is a small separation (of 14ms) between the adversarial and hon-
est servers at 100 steps.8 On the other hand, an honest server can
respond to a 175 step challenge on a 1 GB ﬁle in roughly one sec-
ond, a task which takes an adversary almost 400 ms more, and with
250 steps over a 10 GB ﬁle we can achieve nearly a second of sep-
aration between honest and adversarial servers. As discussed in
Section 5.1, this degree of separation is sufﬁcient to counteract the
variability in network latency encountered in wide area networks.
As such, a RAFT protocol is likely to work for ﬁles larger than
100MB when the latency between the client and cloud provider ex-
periences little variability, and for ﬁles larger than 1GB when there
is highly variable latency between the client and cloud provider.
Simulated experiments for c > 3 drives.
We have been comparing in all our experiments so far an honest
server using c = 3 drives to an adversary using d = 2 drives. We
now perform some simulations to test the effect of the number of
drives the ﬁle is distributed across on the protocol’s effectivness.
Figure 11 shows, for different separation thresholds (given in mil-
liseconds), the number of steps required in order to achieve 95%
separation between the honest server’s read times and an adver-
sary’s read times for a number of drives c ranging from 3 to 11.
The honest server stores a 1 GB ﬁle, encoded for resilience to one
drive failure, evenly across the available number of drives, while
the adversarial server stores the same ﬁle on only c − 1 drives,
using a balanced allocation across its drives optimized given the
adversary’s knowledge of Map.
The graph shows that the number of steps that need to be per-
formed for a particular separation threshold increases linearly with
the number of drives c used by the honest server. In addition, the
number of steps for a ﬁxed number of drives also increases with
larger separation intervals. To distinguish between an honest server
using 5 drives and an adversarial one with 4 drives at a 95% sepa-
8Running more than 100 steps for a 100 MB ﬁle would not beneﬁt
us here as the adversary would simply switch to a strategy of read-
ing the entire ﬁle into memory and then answering the challenge
from memory.
510y
t
i
l
i
b
a
b
o
r
P
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
0
10 Step Response Time Histogram for 10 MB File
100 Step Response Time Histogram for 100 MB File
Honest (3 Drives)
Adversary (2 Drives)
Honest (3 Drives)
Adversary (2 Drives)
y
t
i
l
i
b
a
b
o
r
P
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0
50
100
150
200
250
300
400
450
500
550
600
650
700
750
Time (ms)
Time (ms)
Figure 7: Read-time histogram at 10 steps for a 10 MB ﬁle
Figure 8: Read-time histogram at 100 steps for a 100 MB ﬁle
175 Step Response Time Histogram for 1 GB File
250 Step Response Time Histogram for 10 GB File
y
t
i
l
i
b
a
b
o
r
P
 0.5
 0.4
 0.3
 0.2
 0.1
 0
Honest (3 Drives)
Adversary (2 Drives)
y
t
i
l
i
b
a
b
o
r
P
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
Honest (3 Drives)
Adversary (2 Drives)
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
2000
2200
2400
2600
2800
3000
3200
3400
3600
Time (ms)
Time (ms)
Figure 9: Read-time histogram at 175 steps for a 1 GB ﬁle
Figure 10: Read-time histogram at 250 steps for a 10 GB ﬁle
s
p
e
S
t
 300
 250
 200
 150
 100
 50
 0
 3
Steps to Achieve 95% Separation
300 ms.
200 ms.
100 ms.
10 ms.
 5
 7
 9
 11
Number of Honest Server Drives
Figure 11: Effect of drives and steps on separation
ration threshold of 100ms, the lock-step protocol needs to use less
than 150 steps. On the other hand, for a 300ms separation thresh-
old, the number of steps increases to nearly 250.
More powerful adversaries.
In the experiments presented thus far we have considered an “ex-
pected” adversary, one that uses d = c − 1 drives, but allocates ﬁle
blocks on disks evenly. Such an adversary still needs to perform a
double read on at least one drive in each step of the protocol. For
this adversary, we have naturally assumed that the block that is a
double read in each step is stored equally likely on each of the c − 1
drives. As such, our expected adversary has limited ability to select
the drive performing a double read.
One could imagine a more powerful adversary that has some
control over which drive performs a double read. As block read
times are variable, the adversary would ideally like to perform the
double read on the drive that completes the ﬁrst block read fastest
(in order to minimize its total response time). We implement such
a powerful adversary by storing a full copy of the encoded ﬁle on
each of the d = c − 1 drives available. In each step of the proto-
col, the adversary issues one challenge to each drive, and then the
fourth challenged block to the drive that completes ﬁrst.
We performed some experiments with a 2GB ﬁle. We imple-
mented the honest server using all four of our test drives and issu-
ing a random read to each in each step of the protocol. We then
removed the OS drive (Hitachi) from the set, and implemented
both the expected and the powerful adversaries with the remain-
ing (fastest) three drives. We show in Figure 12 the average time
to respond to a challenge for an honest server using c = 4 drives,
as well as for the expected and powerful adversaries using d = 3
drives (the time shown includes the threading overhead needed to
issue blocking read requests to multiple drives simultaneously, as
well as the time to read challenged blocks from disk).
The results demonstrate that even if a powerful adversarial server
is willing to store triple the necessary amount of data, it is still dis-
tinguishable from an honest server with a better than 95% probabil-
ity using only a 100-step protocol. Moreover, the number of false
511Response Times of Different Adversaries
Honest (4 Drives)
Powerful (3 Drives)
Expected (3 Drives)
)
s
m
(
e
m
T
i
 3500
 3000
 2500
 2000
 1500
 1000
 500
 0
50
100
150
Steps
200
250
Figure 12: Time to complete lock-step protocol
negatives can be further reduced by increasing the number of steps
in the protocol to achieve any desired threshold.
6.2.2 Contention model
We now turn to look at implementing RAFT in the face of con-
tention from other users. For that, we performed tests on Mozy,
a live cloud backup service. As conﬁrmed by a system architect
[19], Mozy does not use multi-tiered storage: Everything is stored
in a single tier of rotational drives. Drives are not spun down
and ﬁles are striped across multiple drives. An internal server ad-
dresses these drives independently and performs erasure encod-
ing/decoding across the blocks composing ﬁle stripes. Given Mozy’s
use of a single tier of storage, independently addressable devices,
and internal points of ﬁle-block aggregation and processing, we be-
lieve that integration of RAFT into Mozy and other similar cloud
storage systems is practical and architecturally straightforward.
To demonstrate the feasibility of such integration, we performed
a simple experiment. This experiment shows that even with no
modiﬁcation or optimization for RAFT, and in the face of con-
tention from other users, it is possible to achieve a very basic RAFT-
style demonstration that ﬁles span multiple drives.
Timing: Mozy Cloud Storage vs. Local HP Drive
HP Average
HP Min
Mozy Average
Mozy Min
)
s
m
(
e
m
T
i
 7000
 6000
 5000
 4000
 3000
 2000
 1000