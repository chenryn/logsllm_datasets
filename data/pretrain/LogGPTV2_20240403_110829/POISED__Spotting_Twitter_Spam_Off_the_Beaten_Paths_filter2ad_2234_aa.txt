title:POISED: Spotting Twitter Spam Off the Beaten Paths
author:Shirin Nilizadeh and
Francois Labreche and
Alireza Sedighian and
Ali Zand and
Jos&apos;e M. Fernandez and
Christopher Kruegel and
Gianluca Stringhini and
Giovanni Vigna
POISED: Spotting Twitter Spam Off the Beaten Paths
Shirin Nilizadeh
Alireza Sedighian
UC Santa Barbara
California, USA
Ecole Polytechnique de Montréal
François Labrèche
Québec, Canada
Québec, Canada
Ecole Polytechnique de Montréal
PI:EMAIL
PI:EMAIL
PI:EMAIL
7
1
0
2
g
u
A
9
2
]
R
C
.
s
c
[
1
v
8
5
0
9
0
.
8
0
7
1
:
v
i
X
r
a
Ali Zand
UC Santa Barbara
California, USA
PI:EMAIL
José Fernandez
Ecole Polytechnique de Montréal
Québec, Canada
PI:EMAIL
Christopher Kruegel
UC Santa Barbara
California, USA
PI:EMAIL
Gianluca Stringhini
University College London
London, United Kingdom
PI:EMAIL
ABSTRACT
Cybercriminals have found in online social networks a propitious
medium to spread spam and malicious content. Existing techniques
for detecting spam include predicting the trustworthiness of ac-
counts and analyzing the content of these messages. However,
advanced attackers can still successfully evade these defenses.
Online social networks bring people who have personal con-
nections or share common interests to form communities. In this
paper, we first show that users within a networked community
share some topics of interest. Moreover, content shared on these
social network tend to propagate according to the interests of peo-
ple. Dissemination paths may emerge where some communities
post similar messages, based on the interests of those communi-
ties. Spam and other malicious content, on the other hand, follow
different spreading patterns.
In this paper, we follow this insight and present POISED, a sys-
tem that leverages the differences in propagation between benign
and malicious messages on social networks to identify spam and
other unwanted content. We test our system on a dataset of 1.3M
tweets collected from 64K users, and we show that our approach
is effective in detecting malicious messages, reaching 91% preci-
sion and 93% recall. We also show that POISED’s detection is more
comprehensive than previous systems, by comparing it to three
state-of-the-art spam detection systems that have been proposed
by the research community in the past. POISED significantly out-
performs each of these systems. Moreover, through simulations,
we show how POISED is effective in the early detection of spam
messages and how it is resilient against two well-known adversarial
machine learning attacks.
CCS CONCEPTS
• Security and privacy → Social network security and pri-
vacy; Intrusion/anomaly detection and malware mitigation;
KEYWORDS
Spam Detection; Online Social Networks; Information Diffusion;
Communities of Interest; Parties of Interest
Giovanni Vigna
UC Santa Barbara
California, USA
PI:EMAIL
1 INTRODUCTION
Cybercriminals have found in social networks a propitious medium
to spread malicious content and perform scams against users [36].
Social networks are leveraged by cybercriminals for a number of
reasons. First, social networks are very popular, with the largest
ones having hundreds of millions of users: this constitutes a large
victim base for criminals. Second, attackers who compromise social
network accounts with an already established reputation can exploit
the inherent trust between connected users to spread malicious
content very effectively [27, 38].
Previous work addressed the detection of spam on social net-
works by predicting the trustworthiness of the accounts that post
messages, notably by detecting Sybil communities [22, 87], bots [29,
75, 86], compromised accounts [27], or a combination of these [13,
85]. Recent research, however, showed how attackers can suc-
cessfully evade both Sybil-based defenses [50] and account-based
ones [93]. This happens because existing spam detection systems
detect the way in which malicious accounts infiltrate the network and
build connections, rather than the way in which malicious messages
spread across the network in comparison to legitimate ones.
In this paper, we propose a novel way to detect malicious mes-
sages on social networks. Instead of looking at the characteristics
of accounts or messages, we inspect the way in which messages
spread on the social network.
In social networks, users tend to form networked communities,
where most users are connected to many other users within the
same community. These communities can be recognized by their
structure in the underlying connection graph, as they form strongly
connected subgraphs. For this reason, they are also dubbed struc-
tural communities. The reasons why such communities form are as
varied as the reasons why people connect to each other, such as fam-
ily, geographical location, past common history, etc. Nonetheless,
it has been recognized that one important reason why members
of social networks tend to connect to others is the so-called ho-
mophily principle, i.e., people connect to other people who hold
similar thoughts and values [54]. In that sense, these people also
form communities of interest, where connected users communicate
and interact on topics of common interest. In principle, members of
a networked community may not necessarily share the same inter-
ests, and thus, structural communities and communities of interest
may not coincide. However, we postulate that the homophily prin-
ciple constitutes indeed the principal reason why people connect.
Therefore, we formalize our first hypothesis as follows:
H1: In social networks, the topics of interest of users within a
networked community are strongly shared among its members. In
other words, networked communities are structured subsets of the
larger set of users interested in the same topics.
It is recognized that the topology of social networks has an ex-
tremely important role in the dissemination of information [59, 90].
The dissemination of information is shaped by the structure of the
network, and in particular faster dissemination is favored within
networked communities [48]. Nonetheless, such dissemination can
traverse networked communities as long as there are members
in both communities who share the same interests. As time pro-
gresses, dissemination paths may emerge where some communities
trigger and post specific messages based on the interests of those
communities and of the surrounding ones. These dissemination
paths can help us predict patterns of postings within and outside of
communities. For example, if two communities C1 and C2 always
post messages on similar topics, then when a message is observed
in C1, the same or similar message has a high probability to also be
posted or shared in C2. In this paper, we refer to these communities
interested in the same set of topics as parties of interest.
On the other hand, spam typically spread differently throughout
the network. For example, messages that are posted by compro-
mised accounts may spread in unexpected communities, because
each compromised user posts that message regardless of whether
the topic is of interest to the account owner or of the communities
of interest of which the compromised user is a member [28]. This
leads to formulate our second hypothesis as follows:
H2: Normal messages disseminate through predictable parties
of interest that include intra-community communication and inter-
community exchanges between structural communities that share
common interests. Conversely, the propagation probability of mali-
cious messages through these parties of interest do not match with
those of normal messages.
In this paper, we investigate these two hypotheses through ex-
perimentation on the Twitter social network. First, our analysis
shows that, on Twitter, community members have a similar and
restricted set of topics of interest, thus validating our first hypothe-
sis. We then build a system, called POISED, that is able to detect
whether a message shared on a social network spreads through
expected parties of interest, or if it rather spreads anomalously.
Our experimental performance evaluation shows that POISED can
detect malicious spam messages with high accuracy, thus validating
our second hypothesis.
In a nutshell, POISED works as follows. First, it detects net-
worked communities in Twitter by partitioning its social graph.
Second, it identifies topics of interest in these communities. Then,
it tracks the dissemination of similar messages through communi-
ties and constructs a probabilistic model of the parties of interest
through which these messages are normally disseminated. Finally,
leveraging this model, a classifier detects malicious content by iden-
tifying the messages that do not follow these expected parties of
interest. POISED can successfully detect spam messages with 91%
precision and 93% recall. We also compare POISED to three state-of-
the-art spam detection systems that have been proposed by previous
work: SpamDetector [75], Compa [27], and BotOrNot [25]. With
respect to the F1-score, POISED outperformed them by more than
70%, 35%, and 83%, accordingly.
Through simulations, we show that POISED performs very well
in detecting spam messages early on. For example, it can detect
spam messages that have spread through only 20% of the commu-
nities with 88% precision and 75% recall.
Finally, we investigate the resilience of POISED against two
common adversarial machine learning attacks [46], poisoning [70]
and evasion attacks [5]. Our simulation results suggest that the
adversary needs to have a great knowledge about the network and
parties of interest to highly impact the performance of POISED. For
example, even if 30% of the network is compromised, the precision
and recall remain at 82% and 87%, in the case of a poisoning attack,
and at 75% and 52%, in the case of an evasion attack.
In summary, this paper makes the following contributions:
(1) Through our experiments on 300 Twitter neighborhoods
with more than 15M tweets and 82K users, we show that
networked communities are built around shared topics.
(2) We developed POISED, which relies on a combination of
techniques from network science, natural language pro-
cessing, and machine learning to detect spam messages by
predicting the dissemination of messages through parties
of interest. We tested POISED on a ground-truth dataset
including data for 202 neighborhoods in Twitter with about
1.3M tweets and 64K users. Our results suggest that our ap-
proach is successful in detecting spam messages. Moreover,
it outperforms other state-of-the-art detection systems.
(3) Our results demonstrate that this approach is scalable and
can detect spam with only a partial knowledge of the social
network. Our simulation results show that spam messages
can be detected early on, when only attaining 20% of their
potential reach in their neighborhood network. We also
show that POISED is difficult to evade for an active ad-
versary. We simulate two attacks in which the adversary
attempts to mimic the propagation of benign messages, and
show that POISED is still highly effective even when the
adversary has compromised a large portion of the network.
2 BACKGROUND AND THREAT MODEL
2.1 Threat Model
In our threat model, spam messages are posted on a large scale [81,
83] and are similar in content and format since, in most cases, they
are generated by similar templates [31, 32]. This can be accom-
plished either by creating fake (Sybil) accounts [22], compromising
and abusing legitimate accounts [27], or by purchasing bots [30].
Unlike other related work that focuses on analyzing message
content (i.e., URLs) [47, 80], or finding compromised accounts [22,
28], we do not place any additional constraints on the type of spam
messages sent nor on the type of accounts used by the adversary.
Spam detection is an adversarial problem. In a real setting, an
adversary could reverse engineer how POISED works and actively
attempt to evade it. Therefore, we assume that the adversary is able
to post spam messages through parties of interest similar to those
of benign messages. Particularly, we assume that the community
detection and topic detection algorithms can be played. Malicious
accounts can compromise some parts of the network, establish con-
nections with honest users and pretend to share the same interests
as the target communities. We also assume they can replicate the
propagation model of benign messages through the parties of in-
terest. For example, an attacker may observe the number of times
a specific benign (viral) message has been posted in compromised
communities as well as the number of users who have posted those
messages, and then generate or compromise accounts to imitate
legitimate parties of interest.
2.2 Communities and Parties of Interest
In social networks, users establish connections with others, and
through them are able to interact with each other. The structure of
the underlying connection graph is not homogeneous: rather than
being connected with any user in the network, users tend to connect
to each other, creating networked communities, where “everybody
knows everybody.” On the other hand, users tend to come together
and form groups to interact around specific topics of interest [20,
39, 49], i.e., that they tend to form communities of interest. Thus,
the question becomes whether networked communities, defined in
terms of the actual connections in the network, coincide with this
topic-oriented notion of communities of interest.
The homophily principle [54] has been observed on online social
networks, where users tend to connect to people who hold similar
thoughts and values [42, 89]. In summary, this research would seem
to suggest that the concepts of community and topics of interest
are related.