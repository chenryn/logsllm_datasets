# Feature Extraction and Classification for Anti-Adblocking Scripts

## 1. Introduction
This document outlines the process of extracting features from JavaScript code to identify anti-adblocking scripts. We use three types of feature sets: `all`, `literal`, and `keyword`. The `all` feature set includes all text, while `literal` and `keyword` focus on specific syntactic properties and keywords, respectively.

## 2. Feature Types
- **All**: Includes all text, such as variable and function names (e.g., `_checkBait` and `_creatBait`).
- **Literal**: Captures literal strings in the JavaScript code.
- **Keyword**: Focuses on syntactic properties like `clientHeight` and `clientWidth`.

## 3. Feature Selection
### 3.1 Initial Feature Extraction
We extracted a total of 1,714,827, 1,211,029, and 16,620 distinct features from the `all`, `literal`, and `keyword` feature sets, respectively. Each feature is binary, with a value of 1 if the feature is present in the script and 0 otherwise.

### 3.2 Vector Space Construction
We construct a vector space to map scripts, where scripts with similar features are placed close to each other. The mapping function \(\phi\) is defined as:
\[
\phi : x \rightarrow (\phi_s(x))_{s \in S}
\]
where
\[
\phi_s(x) = 
\begin{cases} 
1 & \text{if } x \text{ contains the feature } s \\
0 & \text{otherwise}
\end{cases}
\]
and \(S\) is the set of all possible features.

### 3.3 Irrelevant Feature Removal
#### 3.3.1 Variance Filter
We remove features with low variance (less than 0.01). After applying this filter, we are left with 68,510, 32,226, and 6,171 features for the `all`, `literal`, and `keyword` feature sets, respectively.

#### 3.3.2 Duplicate Feature Removal
We also remove duplicate features, resulting in 33,832, 12,974, and 5,785 features for the `all`, `literal`, and `keyword` feature sets, respectively.

#### 3.3.3 Chi-Square Correlation
To further reduce the number of features, we use chi-square correlation:
\[
\chi^2 = \frac{N \times (AD - CB)^2}{(A + C) \times (B + D) \times (A + B) \times (C + D)}
\]
where:
- \(N\) is the total number of scripts.
- \(A\) is the number of positive samples where the binary feature is present.
- \(B\) is the number of negative samples where the binary feature is present.
- \(C\) is the number of positive samples where the binary feature is absent.
- \(D\) is the number of negative samples where the binary feature is absent.

We rank features based on their chi-square values and select the top 10K, 5K, 1K, and 100 features for further analysis.

## 4. Classifier Training
We use AdaBoost, a boosting algorithm, to handle the imbalance of anti-adblockers. AdaBoost combines multiple weak classifiers into a strong meta-classifier. The model is expressed as:
\[
f(x) = \text{sign}\left(\sum_{t=1}^{T} \alpha_t h_t(x)\right)
\]
where:
- \(x\) is the input vector.
- \(h_t(x)\) is the component classifier.
- \(\alpha_t\) is the weight of each classifier.

Training samples that are misclassified get higher weights. We use SVM with an RBF kernel as the component classifier for AdaBoost.

## 5. Results and Evaluation
### 5.1 Cross-Validation
We evaluate the classifier using 10-fold cross-validation. The results are reported in terms of True Positive (TP) rate and False Positive (FP) rate.

### 5.2 Performance Metrics
- **TP Rate**: Fraction of correctly classified anti-adblock scripts.
- **FP Rate**: Fraction of incorrectly classified non-anti-adblock scripts.

| Feature Set | Classifier | # Features | TP Rate (%) | FP Rate (%) |
|-------------|------------|------------|-------------|-------------|
| All         | AdaBoost + SVM 10K | 10K | 99.6 | 3.9 |
| All         | AdaBoost + SVM 1K | 1K | 99.2 | 8.9 |
| All         | AdaBoost + SVM 100 | 100 | 99.2 | 8.9 |
| Literal     | AdaBoost + SVM 10K | 10K | 99.6 | 3.9 |
| Literal     | AdaBoost + SVM 1K | 1K | 99.2 | 8.9 |
| Literal     | AdaBoost + SVM 100 | 100 | 99.2 | 8.9 |
| Keyword     | AdaBoost + SVM 5K | 5K | 99.6 | 3.7 |
| Keyword     | AdaBoost + SVM 1K | 1K | 99.7 | 3.2 |
| Keyword     | AdaBoost + SVM 100 | 100 | 99.2 | 8.9 |

### 5.3 Additional Testing
We tested our model on 2,701 unique anti-adblocking scripts from Alexa's top 100K live websites, achieving a TP rate of 92.5%.

## 6. Conclusion
Our machine learning approach can be used offline by filter list authors or online by adblockers to detect and remove anti-adblock scripts. This reduces manual labor and enhances the effectiveness of adblocking solutions.

## 7. Acknowledgments
We thank our shepherd, Matteo Varvello, and the anonymous reviewers for their feedback. This work is supported by the National Science Foundation and the Data Transparency Lab.

## 8. References
[References listed here]

---

This revised version provides a clear and structured overview of the feature extraction, selection, and classification process, along with the results and conclusions.