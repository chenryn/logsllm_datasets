remaining undetected? (Subsection 5.1)
(6) How will the botmaster holistically combine these adapted
techniques into a functional malware, including the hiding
of notifications and transaction histories? (Subsection 5.2)
(7) How efficient can the botmaster make the C2 infrastructure
while maintaining robustness and effectiveness? What ROI
can he expect and how many bots does he need? (Section 6)
(8) How profitable is botnet-based stock market manipulation
compared to other scams? (Subsection 7.2)
(9) What are the possible paths towards defending against a
market manipulating botnet? (Subsection 7.3)
We identify these challenges as being unique to automating
market manipulation and find that their solutions have a signifi-
cant effect on the design of Bot2Stock’s malware and C2 protocol.
General challenges to operating botnets, like acquiring C2 infras-
tructure and infecting victim machines with malware, are already
studied in prior and ongoing research [4, 39].
3.4 Threat Model
In this work, we assume a botmaster has assembled a botnet by in-
fecting devices with malware and has discovered that some portion
of these devices are regularly used to access brokerage accounts —
presenting an opportunity to commit market fraud. We focus on U.S.
exchanges and brokerages, but believe our findings are applicable
to other countries as well. Users conduct trading either via their
browser, using a brokerage website, or with a native program (i.e.,
trading platform). Accounts are protected using current industry
practices, meaning 2FA is available, but not required, and notifica-
tions are delivered via email. We confirm this to be the case for the
top U.S. online brokerages in Subsection 5.1.
279ACSAC 2020, December 7–11, 2020, Austin, USA
Carter Yagemann, et al.
We assume each compromised account has at least $5,000 in cash
(measured in Subsection 4.3) and does not have a line of credit with
the brokerage, meaning shorting and margin buying is unavailable
(Subsection 3.1). The brokerages are expected to be running anom-
aly detection systems designed to monitor individual accounts for
irregular or questionable trading patterns. For example, one com-
plaint filed by the SEC describes Q6, a proprietary program capable
of detecting indicators of layering [43]. Exchanges are also assumed
to be using anomaly detection software, however due to how or-
ders are routed from trader to brokerage to broker to exchange, the
relationship between orders and traders is opaque — as evident by
ongoing efforts to design and implement a consolidated audit trail
for U.S. markets [13, 15]. In short, for the botnet to be successful,
it must shape and distribute its trading patterns to evade several
layers of anomaly detection while still maintaining profitability.
4 GENERALIZING MARKET FRAUD
The SEC publicly releases all the case files for formally investigated
complaints. As a starting point for our study, we manually examine
all the summaries for cases filed between 2015 and 2018 (about 700
cases in total). We decide to focus on two types of cases, PnD and
layering, because these offenses are purely based on trading behavior,
making them feasible to automate. We do not consider crimes like
insider trading and Ponzi schemes, which have a significant social
engineering component that a botnet alone cannot conduct.
With our categories chosen, we further expand our dataset by
searching the SEC site for documents containing relevant keywords
and by consulting the “Recent Trade Surveillance Enforcement
Actions” list maintained by Trillium [49].
In order to identify the exemplar SEC cases for detailed analysis,
we apply the following search criteria:
(1) We only consider pure trading manipulation and eliminate
cases with non-trading behavior. For example, even if a case
involved PnD, if it also relied on sending spam to promote
the stock, we exclude it.
(2) We only consider cases where at least one detailed exam-
ple of the alleged manipulation is provided. It must include
sufficient information to derive the exact orders made and
the criminal’s net gain. In most cases, the culprit repeats the
manipulation several times, so their total gain is significantly
higher than the net gain of the lone recorded example.
(3) We only consider cases where market manipulation directly
benefits the culprit. In several instances, fraud was performed
to keep the stock eligible for trading on the NASDAQ, which
is a motive outside the scope of this work.
4.1 Automating Layering
Layering can be utilized to raise or lower the price of a target stock.
For simplicity, we will explain how it is used to lower the price. The
perpetrator begins by placing asks at prices slightly worse than the
current best offer to create pressure. As orders from other traders
execute in response to the pressure, the perpetrator cancels and
replaces his own, always staying slightly worse than the best offer.
Once the price is sufficiently lowered, the perpetrator bids at the
manipulated price, allowing him to obtain shares at an artificially
low price. He then cancels all his remaining open orders, waits for
the price to revert back to its original value, and then sells his shares
for a profit. Readers can refer to the Appendix for more detailed
examples with real-world data.
Automation. The main challenge we notice with automating
layering is a bootstrapping hurdle where in order to make any sell
orders (even non-bona fide ones), the seller must first own the shares
to be sold. It is possible to use short selling to sidestep this issue, but
as previously mentioned, we do not assume the hijacked accounts
have the credit necessary for margin trading. Having the bots buy
shares in advance is difficult because buying too quickly will impact
the price negatively for the criminal and buying too slowly will
prolong the attack duration, reducing profits and raising the risk of
premature detection.
Instead, the easiest solution is to start with layering bids, whereas
the real-world cases in Table 1 all started with asks. The criminal’s
profit remains unchanged, but now he only needs to prepare his
own account to sell as opposed to having to prepare all the bots.
Evasiveness. There are two patterns that are typically used by
anomaly detectors to spot layering. The first is a trader opening
orders on both sides of the order book (asks and bids), with one
side being disproportionately larger than the other. In one case the
SEC investigated, this kind of trading behavior tripped the anom-
aly detector used by Lek Securities Corporation — a proprietary
system called Q6 [43]. Bot2Stock avoids creating this pattern by
having each bot only place a single order, on one side of the market,
to setup the layering. The other signal is placing orders on one
side of a stock’s order book at progressively increasing prices and
then canceling them in bulk (e.g., Taub et al. [44]). Bot2Stock also
avoids creating this pattern because again, each bot only places a
single order. Cumulatively, an imbalance is created in the book, but
individually the bots are only placing one order per account at a
time.
This highlights the advantage of performing market manipula-
tion with a botnet. Namely, the large number of bot participants
obscures the manipulative intent of the botmaster by making the
orders appear as the independent acts of unrelated parties.
A summary of all the cases we pick for further analysis is con-
tained in Table 1. The format “x v.s. y” indicates that x is the plaintiff
and y is the defendant in the case. Interestingly, among the SEC
cases we consider, the majority were instances of PnD that involved
non-trade behavior (mainly to promote the target). The two cases
listed in Table 1 utilized hijacked accounts to manually carry out il-
legitimate trades, suggesting that this direction is ripe for malicious
automation.
4.2 Automating Pump-and-Dump
A PnD perpetrator starts by buying or selling shares in a stock to
drive the price in the corresponding direction. Other traders see this
momentum and start placing orders based on the wrong assumption
that there is a legitimate reason behind the price movement. The
perpetrator then stops pumping and reverses the direction of his
orders to profit from the momentum. For example, if he was buying
to pump up the price, he would follow up with asks at an even
280On the Feasibility of Automating Stock Market Manipulation
ACSAC 2020, December 7–11, 2020, Austin, USA
Table 2: Stolen Charles Schwab Accounts (9/16/16–12/12/16)
Table 3: Automating Taub et al. Layering Instances
Selling Price Min Account Cash Max Account Cash
$20,000
$100,000
-
$50
$75
$100
Accounts Sold
$5,000
$20,000
≥ $100,000
(1,005)
Layering Orders Cash Lost Cash Needed
Table 9 & 8
$401, 102
$303, 460
Table 10 & 11
Table 12 & 13
$219, 449
$728
$1, 345
$3, 065
Time (s)
141
120
218
Profit
$3, 285
$4, 927
$24, 501
higher price, yielding a profit when the momentum perpetuated by
the fooled traders reaches that price.
More aggressive perpetrators can also double their profit using
margin orders. Continuing the current example, when the perpetra-
tor places his asks to dump the shares he acquired while pumping,
he can also short the stock. In other words, the perpetrator borrows
shares, sells them at the pumped up price and then after the price
crashes back to its starting value, the perpetrator can buy at the
original value to pay back the owed shares.
The primary shortcomings with PnD, from the criminal’s per-
spective, is that acquiring enough shares or cash to bootstrap the
scam is difficult and executing many trades accumulates commis-
sion fees that eat into the criminal’s leverage. This leads us to
conclude that layering is better suited to automation.
Automation. Table 1 contains additional details about the PnD
cases, including the number of times the fraud was successfully
performed and the illicit revenue according to the SEC. Applying
PnD to a malware requires the botmaster to coordinate the use of
the hijacked accounts. Specifically, performing the setup too slowly
prolongs the attack and raises the risk of premature detection, but
moving too quickly will result in a “smash and grab” with a higher
risk of tripping anomaly detectors. Due to how orders are matched
best-offer-first, the bots will need to keep pumping the price until
it is sufficiently inflated (via buying) or deflated (via selling) for the
botmaster to make a profit.
Evasiveness. In the Willner case, it took 4 days for the brokerage
to start an investigation into his trading patterns. The FS-ISAC also
started questioning his trades in roughly the same amount of time.
The key anomaly implicating him was the placement of sell orders
at prices significantly higher than the market price. The hijacked
accounts were not discovered until a later investigation. Therefore,
the botmaster should be careful not to place his orders prior to the
bots pumping the stock’s price.
Conversely, in the Unknown Traders case, the account compro-
mises were detected first and then correlated with trades made by
the culprits across 15 stock symbols. In short, reusing the exact
same accounts across sessions led to their detection. They only
evaded prosecution because they were able to act anonymously
through the domestic brokerage accounts of Latvian-based relief
defendant JSC Parex Bank. The bank was fined for negligence.
Both cases demonstrate a limitation in automating PnD. Namely,
because the profiting account has to make trades that so blatantly
contradict the background market movements, the botmaster is
likely to be detected, regardless of the botnet’s activity. This makes
layering the more likely technique to be used in a successful crimi-
nal botnet campaign.
4.3 Approximating Leverage & Availability of
Hijacked Accounts
Once the criminal has gained control of the victim’s brokerage
account, any owned assets can be used to manipulate the market.
Our modeled criminal does not touch any of the securities already
held in the account, because rapidly liquidating an account’s assets
is a red flag for brokerage anomaly detectors [42]. However, he can
use the cash in the account that is readily available for trading. We
refer to the combined cash across all the accounts controlled by the
adversary as the trading leverage.
Methodology. To estimate how much leverage an adversary
can expect to gain per compromised account, we turn to dark web
marketplaces for data. Our data was collected over several months
in 2016 from the now dismantled AlphaBay marketplace, which
was accessible via the Tor network. We focus on accounts belonging
to Charles Schwab, which is a major U.S. brokerage.
We collected and parsed listings using a website scraper to per-
form periodic keyword searches [26]. Listings on AlphaBay dis-
played the price and number of units (i.e., accounts) sold. Criminals
priced accounts based on the amount of cash they contained. How-
ever, only the approximate cash values were displayed. We use this
data as a proxy for how much effort the hacker exerted to hijack
accounts. Specifically, we divide the price of the stolen account by
the amount of cash it contained to approximate how much cash
leverage is gained per dollar spent.
Results. Our data is summarized in Table 2. Between September
and December of 2016, we found 1,005 sold accounts, priced from
$50 to $100 per account. They were advertised as having at least
$5,000 in cash and some claimed to contain over $100,000, although
the upper bound was not provided.
Based on the data, the average leverage is $660 per every $1 spent
with a minimum of $100 per $1 spent. To keep our calculations
throughout this work conservative, we use the minimum observed
leverage for an account that was actually sold. This stolen account
went for $50 and contained $5,000 in cash.
4.4 Profitability of Automated Layering
Table 1 shows the alleged illicit gains for our layering case studies.
For the rest of our analysis, we focus on the the complaint “SEC v.s.
Taub et. al.” because it has the most detailed transaction logs. To
approximate the profitability of automated layering, we consider
the revenue and costs associated with a botnet performing the same
actions as reported in this case.
The full transaction tables for Taub et al. are in Appendix A. The
case does not state which stocks were manipulated, but mentions
that each instance was for a different company traded on the NYSE.
281ACSAC 2020, December 7–11, 2020, Austin, USA
Carter Yagemann, et al.
Table 4: Automating Pump-and-Dump Instances
Stock
Instance
Willner #1
FCCO
Willner #2 HIHO
EARS
Willner #3
Unknown
REDI
Traders #1
Unknown
Traders #2 DEPO
Unknown
Traders #3 ORCH
Cash Lost Cash Needed
Time (s)
$2,942
$3,600
$6,660
$49,000
$7,991
$25,722
$35,460
$251,964
$133,107
$1,435,400
$77,285
$765,310
N/A
600
60
9000
3600
4560
Profit
$2,942
$3,000
$6,201
$75,720
$51,078
$55,783
To be conservative, we assume a $5 commission fee per executed
order3 and that each hijacked account starts with at least $5,000 in
cash (Subsection 4.3). To approximate the total commission fees, we
take the cash value of the executed order and divide by the per-bot
cash to determine the number of distinct orders bots would have
to place collectively to achieve the desired result. For example, if
$8,000 worth of shares were bought in the original manipulation
and each bot has $5,000 in cash, 2 bots would collectively need to
make 2 orders ($4,000 each), resulting in $10 of commission.
Results. Our results are summarized in Table 3. If we consider
a scenario where each account costs $50 to hijack and has $5,000 in
cash (Subsection 4.3), repeating the reported instances will require
up to 80 bots and yield $24,501 in profit. Subtracting fees and com-
missions, each bot will yield $41 to $557 in profit. If we assume each
bot is only used once, our lower bound profit estimate for 1,000
bots is $41,000.
Compared to PnD (calculated in Subsection 4.5), this seems like
a low profit margin, especially considering that both techniques
require roughly the same amount of cash to bootstrap. However,
layering takes significantly less time to perform (under 4 minutes
compared to hours for PnD) and inflicts almost no cash loss on
the bots. Specifically, only $3 in cash is lost per bot, on average,
because most non-bona fide orders cancel successfully. This makes
it highly feasible to perform layering multiple times in the same
span of time as a single PnD manipulation.
For example, given the cash needed to launch an instance of
layering, 1,000 bots ($5 million starting cash) can conduct 12 to 22
layering manipulations in parallel. This allows 44 to 80 instances to
complete in 10 minutes, generating $158,000 to $1,078,000 in profit.