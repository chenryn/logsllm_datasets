### Fault Injection on Master and Slave Threads

Injecting faults into the memory management (MM) without considering thread deviation results in an approximately 5% silent data corruption (SDC) rate. This is significantly lower compared to fault injection on the master thread, which yields an SDC rate of 28%.

### SDC Rates for Different Threads

The following table illustrates the SDC rates for various threads across different benchmarks:

| Benchmark | Master Thread SDC Rate | Slave Thread SDC Rate |
|-----------|------------------------|-----------------------|
| bfs       | 28%                    | 5%                    |
| lud       | 28%                    | 5%                    |
| nn        | 28%                    | 5%                    |
| hotspot   | 28%                    | 5%                    |
| nw        | 28%                    | 5%                    |
| srad      | 28%                    | 5%                    |
| kmeans    | 28%                    | 5%                    |

### Segment-Level Differences in Error Resilience

To more accurately evaluate the resilience of OpenMP programs, we propose a method that considers the error resilience of the master and slave threads separately. For slave threads, we focus only on the parallel segment where these threads are spawned. The master thread, however, consists of multiple segments, each requiring individual consideration.

#### Execution Time Profiling

We manually split each benchmark into segments and measure the time spent in each segment. Future work will aim to automate this process. Figure 5 shows the execution time profile of the OpenMP benchmarks. In six of the programs, the parallel segment dominates the execution time, while I/O operations (output processing) take longer in two programs (bfs and srad).

**Figure 5: Execution Time Profile of OpenMP Benchmarks**

| Segment                | bfs | lud | nn  | pathfinder | hotspot | nw  | srad | kmeans |
|------------------------|-----|-----|-----|------------|---------|-----|------|--------|
| Input Processing       | 10% | 5%  | 15% | 10%        | 5%      | 5%  | 10%  | 5%     |
| Pre-Algorithm          | 5%  | 5%  | 5%  | 5%         | 5%      | 5%  | 5%   | 5%     |
| Parallel Region        | 70% | 70% | 70% | 70%        | 70%     | 70% | 70%  | 70%    |
| Post-Algorithm         | 5%  | 5%  | 5%  | 5%         | 5%      | 5%  | 5%   | 5%     |
| Output Processing      | 10% | 15% | 5%  | 10%        | 10%     | 10% | 10%  | 10%    |

### Fault Injection Based on Execution Time

Ideally, fault injection should be based on the execution time of each segment, measured consistently, such as in cycles. However, due to limitations in the LLFI infrastructure, our fault injection is based on the number of dynamic instructions executed in each segment. We manually map each segment in the source code to IR code, identifying the boundaries in the IR code. This allows us to determine the IR instruction range for each segment and track when and where faults are injected.

**Figure 6: SDC Rates in Different Segments of the Benchmarks**

| Segment                | bfs | lud | hotspot | nw  | pathfinder | srad | kmeans |
|------------------------|-----|-----|---------|-----|------------|------|--------|
| Input Processing       | 20% | 10% | 30%     | 20% | 10%        | 20%  | 10%    |
| Pre-Algorithm          | 10% | 20% | 10%     | 10% | 10%        | 10%  | 10%    |
| Parallel Region        | 20% | 20% | 20%     | 20% | 20%        | 20%  | 20%    |
| Post-Algorithm         | 10% | 10% | 10%     | 10% | 10%        | 10%  | 10%    |
| Output Processing      | 30% | 30% | 30%     | 30% | 30%        | 30%  | 30%    |

### Estimating Overall Resilience

To estimate the overall resilience, we propose two approaches:
1. **End-to-End SDC Rate**: Combine the SDC rate of each segment with its time profile.
2. **Algorithm-Related SDC Rate**: Consider only the pre-algorithm, post-algorithm, and parallel segments.

**Figure 7: SDC Rates Estimated in Two Approaches**

- **End-to-End SDC Rate**: Average SDC rate is 20%.
- **Algorithm-Related SDC Rate**: Average SDC rate is 14%.

**Figure 7: SDC Rates in Two Approaches**

| Benchmark | End-to-End SDC Rate | Algorithm-Related SDC Rate |
|-----------|---------------------|----------------------------|
| bfs       | 20%                 | 14%                        |
| lud       | 20%                 | 14%                        |
| nn        | 20%                 | 14%                        |
| pathfinder| 20%                 | 14%                        |
| hotspot   | 20%                 | 14%                        |
| nw        | 20%                 | 14%                        |
| srad      | 20%                 | 14%                        |
| kmeans    | 20%                 | 14%                        |

### Discussion

Our previous study on GPGPU applications suggests that algorithmic characteristics influence error resilience. Table III lists the operations that may affect resilience, and Table IV classifies the operations in OpenMP benchmarks.

**Table III: Operations Affecting Resilience in GPGPU Applications**

| Operation             | Description                                                                 |
|-----------------------|-----------------------------------------------------------------------------|
| Comparison-Based      | Comparing two values; high resilience due to high likelihood of correct value. |
| Average-Out           | Final state is a product of multiple temporary states, often iterative and merging. |
| Graph Processing      | Algorithms like breadth-first search.                                        |
| Linear Algebra        | Basic linear algebra computations.                                           |
| Bit-Wise Operation    | Data chunked based on bit length.                                            |

**Table IV: Operations in OpenMP Benchmarks and Resilience Estimation**

| Operation             | Benchmarks               | Observed SDC Rate |
|-----------------------|--------------------------|-------------------|
| Comparison-Based      | nn, nw                   | 0.07% ∼ 1%        |
| Grid Computation      | hotspot, srad            | 23%               |
| Graph Processing      | bfs, pathfinder          | 9% ∼ 10%          |
| Average-Out           | kmeans                   | 4.2%              |
| Linear Algebra        | lud                      | 44%               |

### Summary

This paper presents a methodology to investigate the end-to-end error resilience of OpenMP applications through fault injection. Our experiments show that, on average, 14% of the injected faults result in SDC when only the algorithm-related parts of the code are considered, while 20% of the injected faults result in SDC when the entire program is considered. We also find significant variations in SDC rates depending on the thread and program segment into which the fault is injected. Preliminary evidence suggests that the algorithmic characteristics of an application are correlated with its observed SDC rates, corroborating our earlier results for GPGPU applications.

### Acknowledgment

This work was supported in part by an NSERC Discovery grant, an NSERC Engage Grant, and a research gift from AMD Corporation. We thank the anonymous reviewers of FTXS2014 for their feedback.

### References

[1] S. Michalak, et al., "Assessment of the impact of cosmic-ray-induced neutrons on hardware in the roadrunner supercomputer," IEEE Transactions on Device and Materials Reliability, vol. 12, no. 2, pp. 445–454, June 2012.

[2] B. Schroeder, et al., "DRAM errors in the wild: A large-scale field study," SIGMETRICS '09, 2009.

[3] V. Sridharan and D. Liberty, "A study of DRAM failures in the field," SC '12, 2012.

[4] B. Fang, et al., "GPU-QIN: A methodology for evaluating the error resilience of GPGPU applications," ISPASS, March 2014.

[5] G. J. Barbara Chapman and R. van der Pas, Using OpenMP. MIT Press, 2007.

[6] C. Lattner and V. Adve, "LLVM: A compilation framework for lifelong program analysis and transformation," San Jose, CA, USA, Mar 2004.

[7] J. Wei, et al., "Quantifying the accuracy of high-level fault injection techniques for hardware faults," DSN, June 2014.

[8] S. Che, et al., "Rodinia: A benchmark suite for heterogeneous computing," IISWC '09, 2009, pp. 44–54.

[9] J. Aidemark, et al., "GOOFI: Generic object-oriented fault injection tool," DSN, 2001, pp. 83–88.

[10] D. Stott, et al., "NFTAPE: A framework for assessing dependability in distributed systems with lightweight fault injectors," IPDPS 2000, 2000, pp. 91–100.

[11] D. Li, et al., "Classifying soft error vulnerabilities in extreme-scale scientific applications using a binary instrumentation tool," SC, 2012, pp. 1–11.

[12] C. da Lu and D. Reed, "Assessing fault sensitivity in MPI applications," SC2004, Nov 2004, pp. 37–37.

[13] J. Wei and K. Pattabiraman, "BLOCKWATCH: Leveraging similarity in parallel programs for error detection," DSN, 2012.

[14] J. Sloan, et al., "An algorithmic approach to error localization and partial recomputation for low-overhead fault tolerance," DSN, June 2013, pp. 1–12.

[15] K. S. Yim, et al., "HAUBERK: Lightweight silent data corruption error detector for GPGPU," IPDPS, 2011.

[16] W. Gu, et al., "Error sensitivity of the Linux kernel executing on PowerPC G4 and Pentium 4 processors," DSN, 2004, pp. 887–896.

[17] Clang-OMP. [Online]. Available: http://clang-omp.github.io/

---

This optimized version aims to improve clarity, coherence, and professionalism, making the content more accessible and easier to understand.