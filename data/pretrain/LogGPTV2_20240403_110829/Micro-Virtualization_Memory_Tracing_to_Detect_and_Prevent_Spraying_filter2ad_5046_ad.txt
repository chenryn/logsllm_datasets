Shellcode per page
Average Guess Offset
amazon.com
ask.com
baidu.com
blogspot.com
craiglist.org
delta-search.com
facebook.com
google.co.jp
google.com.br
google.com
instagram.com
microsoft.com
msn.com
yahoo.com
10/500
2/500
48/500
64/500
10/500
8/500
25/500
162/500
69/500
74/500
224/500
0/500
5/500
13/500
1/20
1/20
4/20
4/20
2/20
3/20
4/20
3/20
3/20
3/20
5/20
—
1/20
1/20
Table 2: Shellcode Frequency Analysis Results.
false alarms (Table 1 reports the results for the first 14
domains analyzed).
In the second set of experiments we tested the effec-
tiveness of the Malicious Code detection component. In
this case we used the exploit for CVE-2009-2477 af-
fecting the Javascript interpreter of Mozilla Firefox 3.5.
This attack exploits a memory corruption vulnerability
in the Firefox browser, in which the Javascript inter-
preter fails to preserve the return value of the escape()
function and results in the use of an uninitialized mem-
ory area. During the exploit, Graﬃti reported that the av-
erage number of analyzed pages containing a potential
shellcode was 100% – thus raising an alarm and stop-
ping the attack. To test the false positive of the same
detection technique, we used the same browser to visit
the top 1000 Alexa domains. In this case, the average
number of potential shellcodes per page was always be-
low 50% and therefore no false alert were raised in the
test.
In table 2 we reported results about the first 14
domains analyzed, the number of pages that present po-
tential shellcode and the average on shellcode found in
the first 500 allocated memory pages. As we can see
from the table, our malicious code detector component
does not present any false positive.
2010-0248 Adobe Flash player ROP + packed sc
JIT + packed sc
2011-0609 Adobe Reader
ROP + packed sc
2011-2462 Adobe Reader
Ret2Lib + packed sc
2010-2883 Adobe Reader
ROP
2011-1996 IExplorer
2009-2477 Firefox
Plain Shellcode
Yes
Yes
Yes
Yes
Yes
Yes
Table 3: Exploitation Detection Results.
In our third experiment, we analyzed the Self-
unpacking Shellcode Detector component. In this case
we selected different CVEs and we used the metas-
ploit [35] tool to exploit them with packed payloads. In
particular, we used two packing methods: the shikata-
ga-nai packer and a simple xor algorithm. Our detection
system was always able to intercept the first execution
of the packed code and consequently detect the attacks
without any false negative. Also for this component, we
tested the false positive rate by browsing the top 1000
domains from the Alexa dataset. We did not observe any
false positive, even though several website included ob-
fuscated Javascript code. A further investigation on ob-
fuscated java-script shows that the de-obfuscation rou-
tine is implemented at the compiler level so it does not
present any problem or generate any false positive in our
system.
To conclude, Table 3 reports all the vulnerabilities we
used for our tests, along with the type of payload deliv-
ery and the detection results of Graﬃti. Even though our
detectors had a very high precision in all our tests, an
attacker equipped with knowledge about the internals of
our detectors could try to mimic the behavior of a be-
nign application to evade detection. A further analysis
of such attacks is presented in Section 8.
Aggregated Experiments
So far, we tested each piece of our infrastructure in isola-
tion. In our final experiments, we put all pieces together.
In the first test, we used Graﬃti to analyze three datasets:
a set of 1000 malicious PDF documents, a set contain-
ing 1000 benign web pages, and one containing 1000
benign PDFs. The first dataset was collected by a com-
pany working on malware analysis, while the other in-
cluded the top Alexa web pages and random documents
collected from various sources. All experiments were
conducted with a very conservative activation threshold
of 150MB and a sampling rate of 10%. Graﬃti suc-
cessfully detected all malicious documents, with zero
false alarms. Moreover, the overhead on loading the
web pages was in average of 23% (a value in line with
previous OS-specific approaches that were only able to
protect the web browser).
USENIX Association  
25th USENIX Security Symposium  441
11
In the second experiment, we asked real users to use a
Graﬃti-protected system during their everyday activities
for a total of 8-to-10 hours per day in a 7-days period.
Graﬃti was installed on two Windows 7 machines, con-
figured to monitor Internet Explorer 8 with an activation
threshold of 150 MB. All three spraying attacks detec-
tors were enabled during the experiments (even though
the first was not necessary on this setup). Overall, the
real users visited a total of 492 distinct web pages and
the detectors were activated 55 times, with an average
of ≈8 times per day. On the same period, Graﬃti raised
12 alerts on pages that seemed to be benign. A closer
inspection of the FPs showed the data spraying detector
(Section 6) to be the only responsible. This component
is in charge of detecting data spraying attacks and bases
its detection on the number of potential code pointers
present in memory.
It is important to stress the fact that the three detec-
tion plugins are not the main contribution of our work,
and our micro-virtualization framework allows other re-
searchers to easily improve, extend, and replaced them
with other techniques. For instance, a possibility to de-
crease the false positive rate of this component could
be to check not only if the code pointer points to a cor-
rect executable page, but also whether it points to a dan-
gerous machine instruction sequences (e.g., a gadget).
We manually inspected the websites that raised the false
alarms and we found that applying such simple method
would be able to prevent all the alerts. This check could
be activated only when the data spraying detector iden-
tifies a possible attack, to prevent a significant increase
of the overhead.
8 Security Evaluation
It is possible that an attacker, knowing the internals of
our three detectors, could mount a mimicry attack that
can successfully evade detection. For instance, an at-
tacker can elude the code pointers frequency analysis by
mimicking the variance of benign memory pages. Al-
though this technique can be successful, it has two re-
strictions. The first is related to the minimum number
of gadgets that the attacker needs to connect to perform
a useful attack. To be useful, an attack should execute
either an API call or a system call. Based on the number
of API call parameters, we estimate that a useful num-
ber of gadgets for a standard shellcode is around 20 (i.e.,
to call the VirtualProtect function, commonly used
in Windows shellcodes to remap a page as executable)
even though some previous works show that the length
of the gadgets for useful shellcode may vary from 8 to
12 [32]. The second restriction is related to the maxi-
mum number of gadgets that an attacker can include to
build a shellcode. Theoretically this number could be in-
finite. In case of spraying attacks, to increase the chance
of success, the size of the shellcode should be smaller
than the size of the NOP-sled, otherwise the probability
to divert the control-flow of the application to the ap-
propriate entry points decreases. In our experiments, for
benign applications the range of code pointers in mem-
ory varies between 0 and 1024, with the vast majority
of pages on the left end of the scale. These values are
hard to mimic in a real attack.
It may be possible in
certain particular cases, but still our component would
have considerably raised the bar making the exploitation
much more difficult.
Another way an attacker can avoid detection is by
evading the shellcode frequency analysis. To this end,
the attacker can act on two parameters. She can decrease
the number of successful entry points for each page – but
this would drastically decrease the success rate of the at-
tack. A second, more subtle, technique would consist in
spraying the memory only with NOP instructions, and
inject only one copy of the shellcode in a second time,
when Graﬃti already concluded its analysis. In this case
we could extend our component to postpone the analysis
when long nop sequences are identified. It is important
to note that the attacker cannot wait for a long time in
order to inject the shellcode, since any additional mem-
ory allocation done by the application would break the
continuity of the nop sled.
A current limitations of Graffiti is that it cannot han-
dle the case when an application allocates a big chunk
of memory at the beginning of the process and then uses
its own allocation functions to perform memory opera-
tions. However, since none of the applications that we
tested in our experiments exhibited such behavior, we
left this case for a future improvement.
To summarize, we believe that evading our three
heuristics is not easy but it is certainly possible. How-
ever, the contribution of this paper is not in the heuris-
tics per se, but in the underlying monitoring framework.
Graﬃti offers the first comprehensive, multi-OS solu-
tion, and this is an important step forward compared
with existing defense solutions and compared with other
techniques presented in previous papers.
9 Related Work
Several solutions have been proposed so far to cope with
single instances of the spraying problem. In the follow-
ing we summarize the existing works that address heap,
JIT, and data spraying techniques.
12
442  25th USENIX Security Symposium 
USENIX Association
Heap Spraying
Researchers have proposed several approaches for de-
tecting heap-spraying attacks [36, 16, 21]. For exam-
ple, Egele et al. [16] used x86 emulation techniques to
defend web browsers against drive-by download attacks
that use heap-spraying code injection. More in details,
the authors proposed to check for the presence of a shell-
code by monitoring all the strings that are allocated by
the JavaScript interpreter. Their goal is similar to that
of NOZZLE [36], which uses static analysis of the ob-
jects on the heap to detect heap-spraying attacks. In par-
ticular, NOZZLE scans memory objects looking for a
sequence of instructions that includes a NOP sled and
ends with a malicious shellcode. However, as the au-
thors point out, the tool presents several drawbacks. For
example, attackers can evade detection by avoid using
large NOP sleds. Moreover, NOZZLE is also specific
for the Java Script Engine Memory Allocator and it can-
not be applied to a generic application. Another work
to defend against heap spraying attack is BuBBLE [21].
In this case, the authors start from the assumption that
an attack needs to spray a large part of the Heap mem-
ory with homogeneous data (i.e. NOP sled). BuBBLE
breaks such an assumption by inserting special values
in a random position inside strings before storing them
in memory, and removing them when a string is used
by the application. Again this solution is specific for the
Javascript language and it cannot be easily ported for the
protection of other applications.
Our approach is different since it does not require to
know how the memory allocator of a particular inter-
preter engine works, and consequently it does not re-
quire access to source code and it is operating system
independent. Moreover, it can protect any system ap-
plication as well as kernel subsystems without any as-
sumption about internals of the protected component.
JIT Spraying
Bania [5] proposed a detection technique based on the
fact that in order to force the JIT compiler to generate
code, an attacker should use ActionScript arithmetic op-
erators. However, it is not mandatory for JIT spraying
attacks to use arithmetic operations.
Another JIT spraying defense has been proposed by
Hu et al. [22]. This solution consists of a kernel patch,
JITsec, that tests for several conditions when a system
call is invoked. In particular, the authors argue that an
application can maintain its security properties and exe-
cute code from the stack and heap by decoupling sen-
sitive from non-sensitive code and allowing the latter
to run from writable memory pages. As a result, such
detector only detects attacks that directly issue system
calls. Mimicry attack and ROP attacks are therefore not
covered by this model.
JITDefender [11] is another work based on hardware-
assisted technologies which aims at defeating JIT Spray-
ing attacks. The system protects the Virtual Machine dy-
namic memory pages created by the JIT-Compiler and
allows to execute only the pages requested by the VM.
This approach is strictly VM dependent, and it can only
detect JIT-spraying attack.
Our solution is orthogonal to the type of attack, and
therefore it can successfully detect JIT-spraying attacks
without any assumption about the instructions that are
used by the attacker.
Finally, Lobotomy [27] proposes to mitigate JIT
spraying attacks by applying the principle of least-
privilege to the Firefox JIT engine: by splitting the
compiler and executor modules of the engine, indeed, it
greatly reduces the amount of code that needs to access
writable and executable pages. The main drawbacks
of Lobotomy, with respect to Graﬃti, are: 1) its over-
head, that is sensibly high if compared with ours, and
2) the need to re-design the JIT engine of the protected
process. The latter is particularly hindering because it
greatly limits the portability of Lobotomy to other JIT
engines. On the contrary, Graﬃti can seamlessly protect
any program, without modifying any of its inner com-
ponents.
Data Spraying