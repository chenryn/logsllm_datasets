title:Mining anomalies using traffic feature distributions
author:Anukool Lakhina and
Mark Crovella and
Christophe Diot
Mining Anomalies Using Trafﬁc Feature Distributions
Dept. of Computer Science,
Dept. of Computer Science,
Anukool Lakhina
Boston University
Mark Crovella
Boston University
Christophe Diot
Intel Research
Cambridge, UK
PI:EMAIL
PI:EMAIL
PI:EMAIL
ABSTRACT
The increasing practicality of large-scale ﬂow capture makes it pos-
sible to conceive of trafﬁc analysis methods that detect and identify
a large and diverse set of anomalies. However the challenge of ef-
fectively analyzing this massive data source for anomaly diagnosis
is as yet unmet. We argue that the distributions of packet features
(IP addresses and ports) observed in ﬂow traces reveals both the
presence and the structure of a wide range of anomalies. Using en-
tropy as a summarization tool, we show that the analysis of feature
distributions leads to signiﬁcant advances on two fronts: (1) it en-
ables highly sensitive detection of a wide range of anomalies, aug-
menting detections by volume-based methods, and (2) it enables
automatic classiﬁcation of anomalies via unsupervised learning.
We show that using feature distributions, anomalies naturally fall
into distinct and meaningful clusters. These clusters can be used
to automatically classify anomalies and to uncover new anomaly
types. We validate our claims on data from two backbone networks
(Abilene and G´eant) and conclude that feature distributions show
promise as a key element of a fairly general network anomaly di-
agnosis framework.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network Opera-
tions
General Terms
Measurement, Performance, Security
Keywords
Anomaly Detection, Anomaly Classiﬁcation, Network-Wide Traf-
ﬁc Analysis
This work was supported in part by NSF grants ANI-9986397 and
CCR-0325701, and by Intel.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’05, August  22–26,  2005,  Philadelphia,  Pennsylvania,  USA.
Copyright 2005 ACM 1-59593-009-4/05/0008 ...$5.00.
1.
INTRODUCTION
Network operators are routinely confronted with a wide range of
unusual events — some of which, but not all, may be malicious.
Operators need to detect these anomalies as they occur and then
classify them in order to choose the appropriate response. The prin-
cipal challenge in automatically detecting and classifying anoma-
lies is that anomalies can span a vast range of events: from network
abuse (e.g., DOS attacks, scans, worms) to equipment failures (e.g.,
outages) to unusual customer behavior (e.g., sudden changes in de-
mand, ﬂash crowds, high volume ﬂows), and even to new, previ-
ously unknown events. A general anomaly diagnosis system should
therefore be able to detect a range of anomalies with diverse struc-
ture, distinguish between different types of anomalies and group
similar anomalies. This is obviously a very ambitious goal.
However, at the same time that this goal is coming into focus,
operators are increasingly ﬁnding it practical to harvest network-
wide views of trafﬁc in the form of sampled ﬂow data. In principle,
this data source contains a wealth of information about normal and
abnormal trafﬁc behavior. However the anomalies present in this
data are buried like needles in a haystack. An important challenge
therefore is to determine how best to extract understanding about
the presence and nature of trafﬁc anomalies from the potentially
overwhelming mass of network-wide trafﬁc data.
A considerable complication is that network anomalies are a
moving target. It is difﬁcult to precisely and permanently deﬁne
the set of network anomalies, especially in the case of malicious
anomalies. New network anomalies will continue to arise over
time; so an anomaly detection system should avoid being restricted
to any predeﬁned set of anomalies.
Our goal in this paper is to take signiﬁcant steps toward a system
that fulﬁlls these criteria. We seek methods that are able to detect
a diverse and general set of network anomalies, and to do so with
high detection rate and low false alarm rate. Furthermore, rather
than classifying anomalies into a set of classes deﬁned a priori,
we seek to mine the anomalies from the data, by discovering and
interpreting the patterns present in network-wide trafﬁc.
Our work begins with the observation that despite their diver-
sity, most trafﬁc anomalies share a common characteristic:
they
induce a change in distributional aspects of packet header ﬁelds
(i.e., source and destination addresses and ports; for brevity in what
follows, these are called trafﬁc features). For example, a DOS at-
tack, regardless of its volume, will cause the distribution of trafﬁc
by destination addresses to be concentrated on the victim address.
Similarly, a scan for a vulnerable port (network scan) will have a
dispersed distribution for destination addresses, and a skewed dis-
tribution for destination ports that is concentrated on the vulnerable
port being scanned. Even anomalies such as worms might be de-
tectable as a change in the distributional aspect of trafﬁc features if
217observed at a high aggregation level, i.e. network wide. Our thesis
is that examining distributions of trafﬁc features yields consider-
able diagnostic power in both detection and classiﬁcation of a large
set of anomalies.
Treating anomalies as events that disturb the distribution of traf-
ﬁc features differs from previous methods, which have largely fo-
cused on trafﬁc volume as a principal metric.
In comparison,
feature-based analysis has two key beneﬁts. First, it enables de-
tection of anomalies that are difﬁcult to isolate in trafﬁc volume.
Some anomalies such as scans or small DOS attacks may have
a minor effect on the trafﬁc volume of a backbone link, and are
perhaps better detected by systematically mining for distributional
changes instead of volume changes. Second, unusual distributions
reveal valuable information about the structure of anomalies—
information which is not present in trafﬁc volume measures. The
distributional structure of an anomaly can aid in automatic classiﬁ-
cation of anomalies into meaningful categories. This is a signiﬁcant
advance over heuristic rule-based categorizations, as it can accom-
modate new, unknown anomalies and at the same time expose their
unusual features.
The key question then is how to effectively extract the properties
of feature distributions in a manner that is appropriate for anomaly
detection and provides necessary information for anomaly classiﬁ-
cation. In this paper, we ﬁnd that entropy is a particularly effective
metric for this purpose. Entropy captures in a single value the dis-
tributional changes in trafﬁc features, and observing the time series
of entropy on multiple features exposes unusual trafﬁc behavior.
We analyze network-wide ﬂow trafﬁc measurements (as the set
of Origin Destination ﬂows) from two IP backbone networks: Abi-
lene and G´eant. We ﬁnd that examining trafﬁc feature distributions
as captured by entropy is an effective way to detect a wide range of
important anomalies. We show that entropy captures anomalies dis-
tinct from those captured in trafﬁc volume (such as bytes or packets
per unit time). Almost all the anomalies detected are important to
network operators — that is, our methods exhibit low false alarm
probability. Further we show that our methods are very sensitive,
capable of detecting anomalies that only comprise on the order of
1% of an average trafﬁc ﬂow. In the technical report version of this
paper [24], we also demonstrate that our methods are particularly
effective at detecting network-wide anomalies that span multiple
ﬂows, detecting multi-ﬂow anomalies that are severely dwarfed in
individual ﬂows (e.g., constituting much less than 1% of a ﬂow’s
trafﬁc).
We ﬁnd that anomalies detected in Abilene and G´eant naturally
fall into distinct clusters, even when using simple clustering meth-
ods. Moreover, the clusters delineate anomalies according to their
internal structure, and are semantically meaningful. The power of
this approach is shown by (1) the discovery of new anomalies in
Abilene that we had not anticipated and (2) the successful detec-
tion and classiﬁcation of external anomalies (previously identiﬁed
attacks and worms) injected into the Abilene and G´eant trafﬁc.
We believe our methods are practical; they rely only on sampled
ﬂow data (as is currently collected by many ISPs using router em-
bedded software such as netﬂow [5, 15]). However, our objective
in this paper is not to deliver a fully automatic anomaly diagnosis
system. Instead, we seek to demonstrate the utility of new primi-
tives and techniques that a future system could exploit to diagnose
anomalies.
This paper is organized as follows. We survey related work in
Section 2. Then, in Section 3, we elaborate on the utility of trafﬁc
feature distributions for diagnosing anomalies, and introduce the
sample entropy metric to summarize distributions. In Section 4,
we describe our anomaly diagnosis framework, comprising both
an extension of the subspace method [23] to accommodate multi-
ple data types, and an unsupervised classiﬁcation technique using
simple clustering algorithms. In Section 5 we introduce our exper-
imental data. In Section 6, we show that entropy detects a new set
of anomalies, not previously detected by the volume metrics; and
we manually inject previously identiﬁed anomalies in our trafﬁc to
demonstrate the sensitivity of our methods. In Section 7, we show
how to use entropy to identify anomalies, by automatically cluster-
ing them into distinct types. Finally, we conclude in Section 8.
2. RELATED WORK
Anomaly detection has been studied widely (dating back at least
as far as Denning’s statistical model for anomaly detection [6]),
and has received considerable attention recently. Most of the
work in the recent research and commercial literature (for e.g.,
[2–4,22,23,29,30]) has treated anomalies as deviations in the over-
all trafﬁc volume (number of bytes or packets). Volume based
detection schemes have been successful in isolating large trafﬁc
changes (such as bandwidth ﬂooding attacks), but a large class of
anomalies do not cause detectable disruptions in trafﬁc volume. In
contrast, we demonstrate the utility of a more sophisticated treat-
ment of anomalies, as events that alter the distribution of trafﬁc
features.
Furthermore, anomaly classiﬁcation remains an important, un-
met challenge. Much of the work in anomaly detection and identi-
ﬁcation has been restricted to point-solutions for speciﬁc types of
anomalies, e.g., portscans [14], worms [17, 32], DOS attacks [11],
and ﬂash crowds [12]. A general anomaly diagnosis method re-
mains elusive, although two notable instances of anomaly clas-
siﬁcation are [34] and [18]. The authors of [34] seek to clas-
sify anomalies by exploiting correlation patterns between differ-
ent SNMP MIB variables. The authors of [18] propose rule-based
heuristics to distinguish speciﬁc types of anomalies in sampled ﬂow
trafﬁc volume instead, but no evaluation on real data is provided.
Our work suggests that one reason for the limited success of both
these attempts at anomaly classiﬁcation is that they rely on volume
based metrics, which do not provide sufﬁcient information to dis-
tinguish the structure of anomalies. In contrast, we show that by
examining feature distributions, one can often classify anomalies
into distinct categories in a systematic manner.
A third distinguishing feature of our method is that they can
detect anomalies in network-wide trafﬁc. Much of the work in
anomaly detection has focussed on single-link trafﬁc data. A
network-wide view of trafﬁc enables detection of anomalies that
may be dwarfed in individual link trafﬁc. Two studies that detect
anomalies in network-wide data are [23], which analyzes link traf-
ﬁc byte-counts, and [22], which examines trafﬁc volume in Origin-
Destination ﬂows. Both studies use the subspace method to detect
changes in trafﬁc volume. We also employ the subspace method
to compare volume-based detections to anomalies detected via en-
tropy of feature distributions. We note however that our work goes
beyond [22, 23] by mining for anomalies using trafﬁc feature dis-
tributions instead of trafﬁc volume.
In doing so, we extend the
subspace method to detect both multi-ﬂow anomalies as well as
anomalies that span multiple trafﬁc features. Finally, we tackle the
anomaly classiﬁcation problem, which was not studied by the au-
thors of [23] and [22].
We are not aware of any work that provides a systematic method-
ology to leverage trafﬁc feature distributions for anomaly diagno-
sis. The authors of [20] and [19] use address correlation properties
in packet headers to detect anomalies. The authors of [21] also
found that IP address distributions change during worm outbreaks.
Entropy has been proposed for anomaly detection in other contexts,
Anomaly Label
Alpha Flows
DOS
Flash Crowd
Port Scan
Network Scan
Outage Events
Point to Multipoint
Worms
Deﬁnition
Unusually large volume point to point ﬂow
Denial of Service Attack (distributed or single-source)
Unusual burst of trafﬁc to single destination, from a “typ-
ical” distribution of sources
Probes to many destination ports on a small set of desti-
nation addresses
Probes to many destination addresses on a small set of
destination ports
Trafﬁc shifts due to equipment failures or maintenance
Trafﬁc from single source to many destinations, e.g.,
content distribution
Scanning by worms for vulnerable hosts (special case of
Network Scan)
Trafﬁc Feature Distributions Affected
Source address, destination address (possibly ports)
Destination address, source address
Destination address, destination port
Destination address, destination port
Destination address, destination port
Mainly source and destination address
Source address, destination address
Destination address and port
Table 1: Qualitative effects on feature distributions by various anomalies.
for example for problems in intrusion detection by [26], and to de-
tect DOS attacks [9]. We use entropy as a summarization tool for
feature distributions, with a much broader objective: that of detect-
ing and classifying general anomalies, not just individual types of
anomalies. Other work proposes sketch-based methods to detect
trafﬁc volume changes and hierarchical heavy-hitters [36]. These
methods also move beyond treating anomalies as simple volume-
based deviations, but operate on single-link trafﬁc only. There has
also been considerable work on using trafﬁc features to automat-
ically ﬁnd clusters in single-link trafﬁc (not network-wide trafﬁc,
which is our focus); a notable example is [8]. Finally, concurrent
with our work, the authors of [35] also use entropy to summarize
trafﬁc feature distributions, with the goal to classify and proﬁle traf-
ﬁc on a single backbone link.
Finally, similar problems (pertaining to anomaly detection and
classiﬁcation) arise in the intrusion detection literature, where they
remain open research problems [28]. Intrusion detection methods
are well-suited for the network-edge, where it is feasible to collect
and analyze detailed packet payload data. As such, many data min-
ing methods proposed to detect intrusions rely on detailed data to
mine for anomalies. Such methods do not appear likely to scale
to network-wide backbone trafﬁc, where payload data is rare, and
only sampled packet header measurements are currently practical
to collect. In contrast to the work in edge-based anomaly detec-
tion with packet payload data, our objective is to diagnose network-
wide anomalies using sampled packet header data.
3. FEATURE DISTRIBUTIONS
Our thesis is that the analysis of trafﬁc feature distributions is
a powerful tool for the detection and classiﬁcation of network
anomalies. The intuition behind this thesis is that many impor-
tant kinds of trafﬁc anomalies cause changes in the distribution of
addresses or ports observed in trafﬁc.
For example, Table 1 lists a set of anomalies commonly encoun-
tered in backbone network trafﬁc. Each of these anomalies affects
the distribution of certain trafﬁc features. In some cases, feature
distributions become more dispersed, as when source addresses are
spoofed in DOS attacks, or when ports are scanned for vulnerabil-
ities. In other cases, feature distributions become concentrated on
a small set of values, as when a single source sends a large number
of packets to a single destination in an unusually high volume ﬂow.
A trafﬁc feature is a ﬁeld in the header of a packet. In this paper,
we focus on four ﬁelds: source address (sometimes called source IP
and denoted srcIP), destination address (or destination IP, denoted
dstIP), source port (srcPort) and destination port (dstPort). Clearly,
these are not the only ﬁelds that may be examined to detect or clas-
sify an anomaly; our methods are general enough to encompass
other ﬁelds as well. However all our results in this paper are based
on analysis of these four ﬁelds.
Figure 1 illustrates an example of how feature distributions
change as the result of a trafﬁc anomaly—in this case, a port scan
occurring in trafﬁc from the Abilene backbone network (described
in Section 5). Two trafﬁc features are illustrated: destination ports
in the upper half of the ﬁgure, and destination addresses in the
lower half of the ﬁgure. Each plot shows a distribution of features
found in a 5-minute period. Distributions are plotted as histograms
over the set of features present, in decreasing rank order. On the
left in each case is the distribution during a typical 5-minute pe-
riod, and on the right is the distribution during a period including
the port scan event.
In the upper half of the ﬁgure, both plots have the same range
in the y-axis. Thus, although the most common destination port
occurs about the same number of times (roughly 30) in both cases,
the total number of ports seen is much larger during the anomaly.
This results in a distribution that is much more dispersed during the
anomaly than during normal conditions. The reverse effect occurs
with respect to destination addresses. In the lower half of the ﬁgure,
both plots have the same range in the x-axis. Here there is roughly
the same number of distinct addresses in both cases, but during the