title:VUDDY: A Scalable Approach for Vulnerable Code Clone Discovery
author:Seulbae Kim and
Seunghoon Woo and
Heejo Lee and
Hakjoo Oh
2017 IEEE Symposium on Security and Privacy
VUDDY: A Scalable Approach for Vulnerable Code
Clone Discovery
Seulbae Kim, Seunghoon Woo, Heejo Lee∗, Hakjoo Oh
Department of Computer Science and Engineering
Korea University
Seoul, Korea
{seulbae, seunghoonwoo, heejo, hakjoo oh}@korea.ac.kr
Abstract—The ecosystem of open source software (OSS) has
been growing considerably in size. In addition, code clones - code
fragments that are copied and pasted within or between software
systems - are also proliferating. Although code cloning may
expedite the process of software development, it often critically
affects the security of software because vulnerabilities and bugs
can easily be propagated through code clones. These vulnerable
code clones are increasing in conjunction with the growth of OSS,
potentially contaminating many systems. Although researchers
have attempted to detect code clones for decades, most of these
attempts fail to scale to the size of the ever-growing OSS code
base. The lack of scalability prevents software developers from
readily managing code clones and associated vulnerabilities.
Moreover, most existing clone detection techniques focus overly
on merely detecting clones and this impairs their ability to
accurately ﬁnd “vulnerable” clones.
In this paper, we propose VUDDY, an approach for the scalable
detection of vulnerable code clones, which is capable of detecting
security vulnerabilities in large software programs efﬁciently
and accurately. Its extreme scalability is achieved by leveraging
function-level granularity and a length-ﬁltering technique that
reduces the number of signature comparisons. This efﬁcient
design enables VUDDY to preprocess a billion lines of code in
14 hour and 17 minutes, after which it requires a few seconds to
identify code clones. In addition, we designed a security-aware
abstraction technique that renders VUDDY resilient to common
modiﬁcations in cloned code, while preserving the vulnerable
conditions even after the abstraction is applied. This extends the
scope of VUDDY to identifying variants of known vulnerabilities,
with high accuracy. In this study, we describe its principles
and evaluate its efﬁcacy and effectiveness by comparing it
with existing mechanisms and presenting the vulnerabilities it
detected. VUDDY outperformed four state-of-the-art code clone
detection techniques in terms of both scalability and accuracy,
and proved its effectiveness by detecting zero-day vulnerabilities
in widely used software systems, such as Apache HTTPD and
Ubuntu OS Distribution.
I. INTRODUCTION
During the last few years,
the number of open source
software (OSS) programs has increased at a rapid pace. Re-
search published in literature showed that open source software
projects have linear to quadratic growth patterns [1], [2], [3].
In practice, the number of registered open source projects in
SourceForge [4] increased from 136 K to 430 K between
October 2009 and March 2014. GitHub [5] announced that
its 10 millionth repository had been created in December
2013, with most of the repositories being software projects.
∗Heejo Lee is the corresponding author.
Meanwhile, they currently have over 85 million projects, in
March 2017.
The considerable increase in the number of OSS programs
has naturally led to an increase in software vulnerabilities
caused by code cloning, thereby posing dire threats to the
security of software systems. Code cloning, the act of copying
and pasting portions of other software, can be useful if it is
properly exploited [6], [7]. However, in practice, code cloning
is often regarded as a bad programming practice because
it can raise maintenance costs [8], reduce quality [9], [10],
produce potential legal conﬂicts, and even propagate software
vulnerabilities [11], [12], [13]. In particular, as OSS programs
are widely used as codebase in software development, (e.g.,
libraries), code cloning is becoming one of the major causes
of software vulnerabilities. For example, the OpenSSL Heart-
bleed vulnerability (CVE-2014-0160) has affected several
types of systems (including websites, web servers, operating
system distributions, and software applications), because the
affected system either used the whole OpenSSL library or
cloned some part of the library for use in their systems.
Moreover, the lifecycle of vulnerabilities exacerbates such
problems. Even if a vendor were to release a patch imme-
diately after the discovery of vulnerability in the original
program, it would take time for the patch to be fully deployed
through every program that cloned the vulnerable code of
the original program [14]. For example, in April 2016, the
“Dogspectus” ransomware was disclosed. This ransomware
exploits a bug in the Linux kernel named “futex local privilege
escalation vulnerability” (CVE-2014-3153) to deliver drive-
by-download malware to the mobile devices that run an
unpatched Android operating system (versions 4.0.3 to 4.4.4).
Another example, the Dirty COW vulnerability (CVE-2016-
5195), which exploits a race condition for privilege escalation,
was found in the memory subsystem of the Linux kernel in
October 2016. What makes this vulnerability outrageous is that
this bug was already ﬁxed in 2005, but the ﬁx was undone
due to another problem raised by the ﬁx. As shown in the
examples, old, vulnerable code fragments that are supposed to
be eliminated, are ceaselessly re-emerging in various locations
for a variety of reasons.
Many researchers have proposed code clone detection tech-
niques to address clone-related problems. However, to our
surprise, few techniques are suitable for accurately ﬁnding
vulnerability in a scalable manner. For example, lexical tech-
© 2017, Seulbae Kim. Under license to IEEE.
DOI 10.1109/SP.2017.62
595
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:26:17 UTC from IEEE Xplore.  Restrictions apply. 
niques such as CCFinder [15] have the disadvantage of high
complexity as it uses a sufﬁx tree algorithm to measure the
similarity between token sequences of programs. In addition,
its parameter replacement strategy is so aggressive that it
introduces a signiﬁcant number of false positives. Similarly,
approaches that transform code into abstract data structures
(e.g., abstract syntax trees) have to apply expensive tree-
matching operations or graph mining techniques for similarity
estimation [16], [17]. Although such an approach would be
capable of discovering code fragments with similar syntactic
patterns, this does not guarantee accurate vulnerability de-
tection because two code fragments with identical abstract
syntax trees do not necessarily contain the same vulnerability.
Notable exceptions are ReDeBug [18] and SourcererCC [19].
ReDeBug aims to achieve both accuracy and scalability by
applying hash functions to lines of code and later detecting
clones by comparing hash values. However, as we show in
this paper, ReDeBug is still not satisfactory both in terms of
accuracy and scalability when it comes to ﬁnding vulnerable
code clones in massive code bases. For example, when testing
an Android smartphone (15 MLoC), ReDeBug requires half
an hour, and has 17.6 % false positives. SourcererCC uses a
bag-of-tokens strategy to manage minor to speciﬁc changes in
clones, which impairs the accuracy from a security perspec-
tive. For example, SourcererCC detects clones in which the
sequence of code is changed, or statements are inserted. As
a result, it misleadingly detects a patched code fragment as a
clone of an unpatched code fragment.
In this paper, we present VUDDY (VUlnerable coDe clone
DiscoverY), a scalable approach for code clone detection. This
approach is speciﬁcally designed to accurately ﬁnd vulnerabil-
ities in a massive code base. To achieve the goal of highly
scalable yet accurate code clone detection from a security
perspective, we use the functions in a program as a unit for
code clone detection. Since a function delivers both syntactic
and symbolic information of the code, we are able to guarantee
high accuracy in detecting clones with respect to security
issues. Moreover, by applying carefully designed abstraction
and normalization schemes to functions, clones with common
modiﬁcations (e.g., variable names) can be detected, which in
turn enables VUDDY to identify unknown vulnerabilities, as
well. In addition, a clever classiﬁcation of functions based on
the length of a function body considerably reduces the search
space, and thus enables VUDDY to work scalably even on a
massive code base. With this design, VUDDY accomplishes an
unprecedented balance between high scalability and accuracy.
In addition, we present a detailed explanation of the princi-
ples and implementation of VUDDY, as well as the application
of the proposed approach for the detection of vulnerabilities.
We further propose a method to collect CVE vulnerabilities in
an automated way. From 9,770 vulnerability patches obtained
from eight well-known Git repositories (e.g., Google Android),
we retrieved 5,664 vulnerable functions that address 1,764
CVEs. Our evaluation involves empirically measuring the per-
formance of VUDDY and then evaluating the practical merits
of VUDDY by demonstrating the vulnerabilities detected from
a pool consisting of real-world open source software. This pool
includes 25,253 active C/C++ projects collected from GitHub,
Linux kernels, and the Android OS of a smartphone that
was released in March 2016. The results show that VUDDY
preprocesses the 172 M functions (in 13.2 M ﬁles, 8.7 BLoC)
of the 25,253 projects in 4 days and 7 hours, then identiﬁes
133,812 vulnerable functions in approximately 1 second for
each project. VUDDY is twice faster than ReDeBug, while
having no false positive with Android ﬁrmware. Meanwhile,
ReDeBug had 17.6 % false positives.
The contributions of this study include:
• Scalable clone detection: We propose “VUDDY,” an
approach to scalable yet accurate code clone detection,
which adopts a robust parsing and a novel ﬁngerprinting
mechanism for functions. VUDDY processes a billion
lines of code in 14 hours and 17 minutes, which is an
unprecedented speed.
• Vulnerability-preserving abstraction: We present an ef-
fective abstraction scheme optimized for detecting un-
known vulnerable code clones. This allows VUDDY to
detect unknown vulnerable code clones, as well as known
vulnerabilities in a target program. Owing to this design,
VUDDY detects 24 % more vulnerable clones which are
unknown variants of known vulnerabilities.
• Automated vulnerability acquisition: We introduce a fully
automated method for acquiring known vulnerable func-
tions from Git repositories, by taking advantage of secu-
rity patch information.
• Open service: We have been servicing VUDDY as a form
of open web service at no charge, since April 2016. In
practice, VUDDY is being used by many in the open
source community and by IoT device manufacturers, for
the purpose of examining their software. In the past 11
months, 14 billion lines of code have been queried to our
open service, and 144,496 vulnerable functions have been
detected. Please see https://iotcube.net/
The remainder of this paper is organized as follows. Sec-
tion II clariﬁes the taxonomy and summarizes existing ap-
proaches concerning code clone detection. Section III presents
the problem and goal. Section IV describes the principles
of our proposed approach, VUDDY. In Section V, we ex-
plain how VUDDY is applied to vulnerability discovery. In
Section VI, we discuss issues regarding the implementation
of VUDDY. Then in Section VII, we describe various ex-
periments conducted for evaluating the scalability, time, and
accuracy of VUDDY against the most competitive techniques
on real-world programs. Section VIII compares VUDDY with
ReDeBug, the most competitive technique, in detail. A quali-
tative evaluation is given through case studies in Section IX.
Section X presents a discussion, and Section XI offers the
conclusion and future work.
II. TAXONOMY AND RELATED WORK
A. Taxonomy
To avoid confusion concerning the various taxonomies
adopted in other research, we use the following well accepted
([20], [21], [22], [23]) deﬁnitions of the types of code clones.
• Type-1: Exact clones. These code fragments are dupli-
cated without any change, i.e., are unmodiﬁed.
596
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:26:17 UTC from IEEE Xplore.  Restrictions apply. 
• Type-2: Renamed clones. These are syntactically identi-
cal clones except for the modiﬁcation of types, identiﬁers,
comments, and whitespace. VUDDY covers Type-1 and
Type-2 clones.
• Type-3: Restructured clones. Further structural mod-
iﬁcation (e.g., deletion, insertion, or rearrangement of
statements) is applied to renamed clones to produce
restructured clones.
• Type-4: Semantic clones. These are clones that could be
syntactically different, but convey the same functionality.
For the purpose of making VUDDY optimized for detecting
security-related clones, we devotedly designed VUDDY to be
able to detect Type-1 and Type-2 clones, which is the right
scope that retains the context while allowing minor changes
that frequently occur after code cloning. In the following
sections, we explain why two former types of clones properly
handle the security-aware context, and how approaches for
detecting Type-3 and Type-4 clones sacriﬁce accuracy, and
lead to increased false positive rate.
We also specify a granularity unit which refers to the scale
of a code fragment, which is referenced throughout this study.
the compiler can
understand. For example, in the statement int i = 0;
ﬁve tokens exist: int, i, =, 0, and ;.
• Token: This is the minimum unit
• Line: This represents a sequence of tokens delimited by
a new-line character.
• Function: This is a collection of consecutive lines that
perform a speciﬁc task. A standard C or C++ function
consists of a header and body. A header includes a return
type, function name, and parameters, and a body includes
a sequence of lines that determine the behavior of the
function.
• File: This contains a set of functions. A ﬁle may in fact
contain no functions. However, most source ﬁles usually
contain multiple functions.
• Program: This is a collection of ﬁles.
In summary, a program is a collection of ﬁles that contain
functions, and a function is a collection of lines that are
composed of tokens. Code cloning can occur with any of
the listed granularity units. VUDDY take a function as its
processing granularity.
B. Related work
Rataan et al. reviewed an extensive amount of research on
code clone detection, and reported more than 70 techniques
published in 11 journals and 37 conferences and workshops
[23]. In this section we review some of the representative
techniques which can be grouped into ﬁve categories based
on the clone granularity level: set of tokens, set of lines, set
of functions, ﬁles, or a hybrid of others. The selection of the
granularity level greatly affects the ensuing clone detection
process, and contributes greatly to scalability and accuracy.
1) Token-level granularity: Techniques that adopt token-
level granularity lexically analyze a program in order to
transform it into a sequence, or bag, of tokens. The token
sequences are then compared for similarity comparison. The
best-known of these are CCFinder [15] and CP-Miner [24].
597
In CCFinder, the similarity of the sequence of lexical com-
ponents, i.e., tokens, is measured by a sufﬁx-tree algorithm,
which is computationally expensive and consumes a large
amount of memory.
CP-Miner parses a program and compares the resulting
token sequences using the “frequent subsequence mining”
algorithm known as CloSpan [25]. Due to CloSpan’s heuristics
for improved efﬁciency, CP-Miner can scale to the size of
moderately large code bases such as the Linux kernel, by con-
suming less memory space. However, the mining complexity
of CP-Miner is still O(n2) in the worst case where n is the
number of LoC, and their experiment showed that CP-Miner
requires a similar amount of execution time as CCFinder.
Aside from scalability issues, the two aforementioned tech-
niques generate a high false positive rate caused by their
aggressive abstraction, and ﬁltering heuristics. Although the
developers of CP-Miner claim that CP-Miner detects 17 to 52
percent more clones than CCFinder, Jang et al. [18] revealed
that the false positive rate for reported code clones was 90 %
for CP-Miner. This implies that this design does not guarantee
sufﬁcient reliability to be useful for vulnerability detection.
2) Line-level granularity: ReDeBug [18] takes a set of
lines as its processing unit. It slides a window of n (4,
by default) lines through the source code and applies three
different hash functions to each window. The code clones
between ﬁles are detected by means of membership checking
in a bloom ﬁlter, which stores the hash values of each window.
Although the line-based window sliding technique enables
ReDeBug to detect some of the Type-3 clones, ReDeBug
cannot detect Type-2 clones in which variables are renamed or
data types are changed. Consequently, ReDeBug misses many
vulnerable clones with slight modiﬁcations. Moreover, the use
of a line-level granularity leads to a limited information of the
context, and it eventually introduces many false positive cases.
In terms of performance, this approach adequately scales to
30 K SourceForge projects (922 MLoC), but it required 23.3
hours to process ﬁles and build a hash database.
3) Function-level granularity: SourcererCC [19] attempts
to detect Type-3 clones by using the bag-of-tokens tech-
nique. It parses all of the functions, and creates an index
consisting of the bag-of-tokens of each function. Then, it
infers the similarity of functions by applying an Overlap
function which is computed as the number of tokens shared
by two functions. If the similarity between the two functions
exceeds a predetermined threshold, they are deemed as a clone
pair. They reduced the number of similarity computations, by
using ﬁltering heuristics that assign more weight to frequent
tokens in the bag to achieve large-scale clone detection. In
their experiment, SourcererCC detected code clones from 100
MLoC in approximately 37 hours, whereas it required 78
hours for CCFinder to execute for the same code base, despite
CCFinder detecting fewer clones than SourcererCC. However,
as a tradeoff for detecting Type-3 clones, their applicability
for vulnerability detection is badly damaged. In many cases,
vulnerabilities are suppressed by inserting a single if statement.
However, SourcererCC cannot distinguish between patched
(i.e., an if statement inserted) and unpatched (i.e., without an
if statement, and thus vulnerable) code fragments.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:26:17 UTC from IEEE Xplore.  Restrictions apply. 
Yamaguchi, et al. proposed a method named vulnerability
extrapolation [26], and its generalized extension that exploits
patterns extracted from the abstract syntax trees (ASTs) of
functions to detect semantic clones [27]. When extracted
ASTs are embedded in a vector space, their semantics can
be identiﬁed by the latent semantic analysis technique. In
particular, they perform a singular value decomposition on
the embedded vectors, and obtain the structural patterns of
functions. Although their method is capable of detecting Type-
4 clones, they rely heavily on expensive operations, and the
accuracy of detection is not precisely given in their analysis.
We must note that techniques that adopt a considerably high
level of abstraction (e.g., a function into a bag-of-tokens, or
into syntax trees) might be effective for detecting clones, but
they are not suitable for accurately detecting vulnerable code
clones, because security issues are very context sensitive.
4) File-level granularity: DECKARD [17] builds ASTs for
each ﬁle, then extracts characteristic vectors from the ASTs.
After clustering vectors based on their Euclidean distance,
vectors that lie in proximity to one another within the Eu-
clidean space are identiﬁed as code clones. Such tree-based
approaches require extensive execution time, as the subgraph
isomorphism problem is a well-known and time-consuming
NP-Complete problem [28]. Furthermore, DECKARD does
not guarantee sufﬁcient scalability to handle the Debian Linux
OS Distribution, according to Jang, et al. [18]. In addition, it
was pointed out [29] that DECKARD has a 90 % false positive
rate, which again suggests that code fragments with similar
abstract trees are not necessarily clones.
FCFinder [30] removes comments, redundant whitespace,