N i,j i,j N i,ci i,ci
i=1j=1 i=1
XN
1
=− logyˆ (1.16)
N i,ci
i=1
L 范式
p
向量x的p-范式用来测量其数值幅度大小：如果一个向量的值更大，它的p-范式也会有一
个更大的值。p是一个大于或等于1的值，p-范式定义为
0 1
1/p
XN
∥x∥ =@ |x |pA
p i
i=1
XN
i.e.,∥x∥p = |x |p (1.17)
p i
i=1
p-范式在深度学习中往往用来测量两个向量的差别大小，写作L ，如在公式(1.18)一样，其
p
中y为目标值向量，yˆ为预测值向量。
12
1.6 优化
XN
L =∥y−yˆ∥p = |y −yˆ|p (1.18)
p p i i
i=1
均方误差
均方误差 (Mean Squared Error，MSE) 是由公式 (1.19) 所定义的 L 范式的平均值。均方误
2
差可以在网络输出是连续值的回归问题中使用。比如说，两个不同图像在像素上的区别就可以用
MSE来测量：
XN
1 1
L= ∥y−yˆ∥2 = (y −yˆ)2 (1.19)
N 2 N i i
i=1
其中N 是样本数据的大小，y和yˆ分别为目标值向量和预测值向量。
平均绝对误差
与均方误差类似，平均绝对误差(MeanAbsoluteError，MAE)也可以被用来做回归任务，它
被定义为L 范式的平均。
1
XN
1
L= |y −yˆ| (1.20)
N i i
i=1
均方误差和平均绝对误差都可衡量y 和yˆ的误差，用以优化网络模型。其中，均方误差提
供了更好的数学性质，从而让我们能更简便地计算梯度下降所需要的偏导数。而在平均绝对误差
中，当y = yˆ 时，我们注意到上面公式中的绝对值项无法求导，这对平均绝对误差来说是一个
i i
无法解决且需要规避的问题。另外，当y 和yˆ 的绝对差大于1时，均方误差相对平均绝对误差
i i
来说误差值更大。显然地，当(y −yˆ)>1时，(y −yˆ)2 >|y −yˆ|。
i i i i i i
1.6 优化
在这一小节里，我们将描述深度神经网络的优化，即深度神经网络参数训练。本节包含了反
向传播算法、梯度下降、随机梯度下降和超参数的选择等内容。
1.6.1 梯度下降和误差的反向传播
如果我们有一个神经网络和一个损失函数，那么对于这个网络的训练的意义是通过学习它的
θ使得损失值L最小化。最暴力的方法是通过寻找一组参数θ，使它满足▽ L=0，以找到损失
θ
值的最小值。但这种方法在实际中很难实现，因为通常深度神经网络参数很多、非常复杂。所以
13
第1章 深度学习入门
我们需要考虑一种叫作梯度下降（GradientDescent）的方法，它是通过逐步优化来一步一步地寻
找更好的参数来降低损失值的。
图1.9展示了两个梯度下降的例子。梯度下降的学习过程从一个随机指定的参数开始，其损
失值L随参数的更新而逐步下降，其过程如箭头所示。具体来说，在神经网络中，参数通过偏导
数 ∂L 被逐步优化，优化过程为θ :=θ−α∂L，其中α为学习率，用以控制步长幅度。可见，梯
∂θ ∂θ
度下降法的关键是计算出偏导数 ∂L。
∂θ
O O
图1.9 梯度下降的示例：在左图中，我们有一个可以训练的参数θ =w；在右图中，我们有两个
可以训练的参数θ =[w ,w ]。在梯度下降里，整个学习过程的初始化参数是随机的。在
1 2
每一步对参数调整之后，损失L会慢慢地减少，但无法保证最后能找到全局最小的损失
值，在大多数情况下，我们能找到的都是局部最小值
反向传播（Back-Propagation）(LeCunetal.,2015;Rumelhartetal.,1986)是一种计算神经网络
中偏导数 ∂L 的方法。为了使得表示对 ∂L 的计算更加清晰，这种方法引入一个中间量δ = ∂L，
∂θ ∂θ ∂z
用来表示损失函数L对于神经网络输出z 的偏导数。因此，这种方法可以通过中间量δ 来计算
损失函数L对于每个参数的偏导数，并最终共同组成 ∂L。
∂θ
网络层的序号为l =1,2,··· ,L，其中输出层的序号为L。对于每个网络层，我们有输出zl，
中间值 δl = ∂L 和一个激活值输出 al = f(zl) （其中 f 为激活函数）。下面是一个使用均方误
∂zl
差和 sigmoid 激活函数的多层感知器的例子：已知 zl = Wlal−1 +bl, al = f(zl) = 1 和
1+e−zl
L= 1∥y−aL∥2，可以得出激活值输出对于原先输出的偏导数 ∂al =f′(zl)=f(zl)(1−f(zl))=
2 2 ∂zl
al(1−al)，以及损失函数对于激活值输出的偏导数 ∂L = (aL−y)。然后，为了计算损失函数
∂aL
对于输出层的偏导数，可以使用链式法则，具体如下：
从输出层开始向后传播误差，先计算输出层的中间量：
• δL = ∂L = ∂L ∂aL =(aL−y)⊙(aL(1−aL))
∂zL ∂aL ∂zL
然后计算损失函数对于后一层输出的偏导数，如（l=1,2,··· ,L−1）：
• 已知zl+1 =Wl+1al+bl+1，则 ∂zl+1 =Wl+1；且 ∂al =al(1−al)
∂al ∂zl
14
1.6 优化
• 那么δl = ∂L = ∂L ∂zl+1∂al =(Wl+1)Tδl+1⊙(al(1−al))
∂zl ∂zl+1 ∂al ∂zl
从输出层开始向后传播，计算出所有层的中间值δl 后，反向传播算法的第二步是在中间值
δl 的基础上计算损失函数对于每层参数 ∂L 和 ∂L 的偏导数。
∂Wl ∂bl
• 若有zl =Wlal−1+bl，我们有 ∂zl =al−1和 ∂zl =1
∂Wl ∂bl
• 那么 ∂L = ∂L ∂zl =δl(al−1)T，∂L = ∂L ∂zl =δl
∂Wl ∂zl∂Wl ∂bl ∂zl ∂bl
最后，我们用 ∂L 和 ∂L 及梯度下降更新Wl 和bl：
∂Wl ∂bl
• Wl :=Wl−α ∂L
∂Wl
• bl :=bl−α∂L
∂bl
可见，有了偏导数 ∂L =[ ∂L , ∂L]，我们可以使用梯度下降来对参数进行迭代，直到其收敛
∂θ ∂Wl ∂bl
到了损失函数中的一个最小值，如图1.9所示。在实践中，我们最终得到的最小值往往是一个局
部最小值，而不是全局最小值。但是，因为深度神经网络往往可以提供一个很强的表示能力，这
些局部最小值通常会很接近全局最小值(Goodfellowetal.,2016)，使得损失值足够小。
这里额外介绍sigmoid的问题，当使用sigmoid时，∂al = al(1−al)，当a接近于0或者1
∂zl
时，∂al 会非常小，从而导致δl非常小。在网络很深的情况下，反向传播时δ会越来越小，出现
∂zl
梯度消失（VanishingGradient）问题，导致模型靠近输入部分的参数很难被更新，模型无法训练
起来。而ReLU的 ∂al 在a大于0时衡为1，就不会有这个问题，这也是现在的深度模型往往在
∂zl
隐藏层中使用ReLU而不再使用sigmoid的原因。
在梯度下降中，如果数据集的大小（即数据样本的数量）N 较大，则在每个迭代中计算损失
函数L的计算开销可能会较高。拿之前的均方误差举例，我们可以把上式展开成
XN
1 1
L= ∥y−aL∥2 = (y −aL)2 (1.21)
2 2 2 i i
i=1
在实践中，数据集很有可能会很大，梯度下降因需要计算L而变得十分低效。随机梯度下降
应运而生，其他对于L的计算只包含少量的数据样本。
1.6.2 随机梯度下降和自适应学习率
与其是在每个迭代中对全部训练数据计算损失函数 L，随机梯度下降（Stochastic Gradi-
ent Descent, SGD）(Bottou et al., 2007) 计算损失值时随机选取一小部分的训练样本。这些小
样本被称为小批量 (Mini-batch)，而在这些小批量的具体大小被称为批大小 (Batch Size) B。然
后，我们就可以用批大小 B 和 B ≪ N 重写公式 (1.21)，得到公式 (1.22)，以改进计算 L 的
效率：
XB
1 1
L= ∥y−aL∥2 = (y −aL)2 (1.22)
2 2 2 i i
i=1
15
第1章 深度学习入门
随机梯度下降的训练过程请见算法 1.1。如果参数在算法 1.1 中更新了足够多的次数，那么
小批量可以覆盖整个训练集。
算法1.1随机梯度下降的训练过程
Input: 参数θ，学习率α，训练步数/迭代次数S
1: fori=0toS do
计算一个小批量的L
2:
3: 通过反向传播计算 ∂L
∂θ
▽θ ←−α· ∂L;
4:
∂θ
5: θ ←θ+▽θ更新参数
6: endfor
7: return θ；返回训练好的参数
学习率(LearningRate)控制了随机梯度下降中每次更新的步长。如果学习率过大，随机梯度
下降可能无法找到最小值，如图1.10所示。另一方面，如果学习率过小，随机梯度下降的收敛速
率将会变得十分缓慢。如何决定学习率是一个很困难的过程。为了解决这个问题，需要使用自适
应学习率算法，如Adam(Kingmaetal.,2014)、RMSProp(Tielemanetal.,2017)和Adagrad(Duchi
etal.,2011)等。其作用为通过自动、自适应的方法来调整学习率，从而加速训练算法的收敛速度。
这些算法的原理在于，当参数收到了一个较小的梯度时，算法会转到一个更大的步长；反之，如
果梯度过大，算法就会给出一个较小的步长。其中，Adam是最常见的自适应学习率算法。与其
直接用梯度更新参数，Adam首先会计算梯度的滑动平均和二阶动量。然后，如算法1.2所示，这
些新计算的数值会被用来更新我们想要训练的参数。算法 1.2 中的 β 和 β 为梯度的遗忘因子，
1 2
或者分别是其动量和二阶动量。在默认设置下，β 和β 的值分别是0.9和0.999(Kingmaetal.,
1 2
2014)。