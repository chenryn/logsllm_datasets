is expressed as X (i)
S =(cid:83)
pre is given by:
(cid:40)⊥k
x
f (i)
pre(x) =
(if x ∈ X (i)
S,k)
(otherwise).
(19)
pre. The i-th user stores f (i)
After mapping personal data x ∈ X to intermediate data z ∈
Z, the (ZS,YP,ε)-utility-optimized mechanism Qcmn maps
z to obfuscated data y ∈ Y . Examples of Qcmn include the
(ZS,ε)-uRR (in Deﬁnition 3) and (ZS,ε)-uRAP (in Deﬁni-
tion 4). As a whole, the PUM Q(i) can be expressed as:
Q(i) = Qcmn ◦ f (i)
pre and Qcmn in a
device that obfuscates her personal data (e.g., mobile phone,
pre is leaked, x ∈ XN corre-
personal computer). Note that if f (i)
sponding to each bot (e.g., home, workplace) is leaked. Thus,
the user keeps f (i)
pre secret. To strongly prevent the leakage
of f (i)
pre using a tamper-resistant
hardware/software. On the other hand, the utility-optimized
mechanism Qcmn, which is common to all users, is available
to the data collector.
pre, the user may deal with f (i)
The feature of the proposed PUM Q(i) is two-fold: (i) the
secrecy of the pre-processor f (i)
pre and (ii) the κ semantic tags.
By the ﬁrst feature, the i-th user can keep X (i)
(i.e., what is
S
sensitive for her) secret, as shown in Section 5.2. The second
feature enables the data collector to estimate a distribution p
with high accuracy. Speciﬁcally, she estimates p from obfus-
cated data Y using Qcmn and some background knowledge
about p conditioned on each tag, as shown in Section 5.3.
In practice, it may happen that a user has her speciﬁc sen-
sitive data x ∈ X (i)
that is not associated with any semantic
tags. For example, if we prepare only tags named “home”
and “workplace”, then sightseeing places, restaurants, and
any other places are not associated with these tags. One way
to deal with such data is to create another bot associated with
a tag named “others” (e.g., if ⊥1 and ⊥2 are associated with
S
USENIX Association
28th USENIX Security Symposium    1885
ࣲௌࣲࣲேࣳ௉ࣳࣳூࣲௌࣲேࣴௌ݂௣௥௘ሺ௜ሻࡽ௖௠௡ࣲௌሺ௜ሻࣴ1N5.3 Distribution Estimation
We now explain how to estimate a distribution p from data
Y obfuscated using the PUM. Let r(i) be a distribution of
intermediate data for the i-th user:
r(i)(z) =
S,k
∑x∈X (i)
0
p(z)
p(x) (if z = ⊥k for some k = 1, . . . ,κ)
(if z ∈ X (i)
S )
(otherwise).
and r be the average of r(i) over n users;
i.e., r(z) =
i=1 r(i)(z) for any z ∈ Z. Note that ∑x∈X p(x) = 1 and
n ∑n
1
∑z∈Z r(z) = 1. Furthermore, let πk be a distribution of per-
sonal data x ∈ X conditioned on ⊥k deﬁned by:
πk(x) =
p(i)
k (x) =
i=1 p(i)
∑n
(cid:40)
∑x(cid:48)∈X ∑n
p(x)
0
,
k (x)
i=1 p(i)
(if f (i)
(otherwise).
k (x(cid:48))
pre(x) = ⊥k)
(20)
πk(x) in (20) is a normalized sum of the probability p(x) of
personal data x whose corresponding intermediate data is ⊥k.
Note that although x ∈ X is deterministically mapped to z ∈ Z
for each user, we can consider the probability distribution πk
for n users. For example, if ⊥k is tagged as “home”, then πk
is a distribution of users at home.
We propose a method to estimate a distribution p from
obfuscated data Y using some background knowledge about
πk as an estimate ˆπk of πk (we explain the case where we have
no background knowledge later). Our estimation method ﬁrst
estimates a distribution r of intermediate data from obfuscated
data Y using Qcmn. This can be performed in the same way as
the common-mechanism scenario. Let ˆr be the estimate of r.
After computing ˆr, our method estimates p using the esti-
mate ˆπk (i.e., background knowledge about πk) as follows:
ˆp(x) = ˆr(x) +
κ
∑
k=1
ˆr(⊥k)ˆπk(x), ∀x ∈ X .
(21)
Note that ˆp in (21) can be regarded as an empirical estimate
of p. Moreover, if both ˆr and ˆπk are in the probability simplex
C , then ˆp in (21) is always in C .
If we do not have estimates ˆπk for some bots (like the
one tagged as “others” in Section 5.1), then we set ˆπk(x) in
proportion to ˆr(x) over x ∈ XN (i.e., ˆπk(x) =
ˆr(x(cid:48))) for
such bots. When we do not have any background knowledge
ˆπ1,··· , ˆπκ for all bots, it amounts to simply discarding the
estimates ˆr(⊥1),··· , ˆr(⊥κ) for κ bots and normalizing ˆr(x)
over x ∈ XN so that the sum is one.
ˆr(x)
∑x(cid:48)∈XN
5.4 Utility Analysis
We now theoretically analyze the data utility of our PUM.
Recall that ˆp, ˆr, and ˆπk are the estimate of the distribution
of personal data, intermediate data, and personal data condi-
tioned on ⊥k, respectively. In the following, we show that the
l1 loss of ˆp can be upper-bounded as follows:
Theorem 1 (l1 loss of the PUM).
κ
∑
l1(ˆp,p) ≤ l1(ˆr,r) +
ˆr(⊥k)l1(ˆπk,πk).
(22)
k=1
This means the upper-bound on the l1 loss of ˆp can be
decomposed into the l1 loss of ˆr and of ˆπk weighted by ˆr(⊥k).
The ﬁrst term in (22) is the l1 loss of ˆr, which depends
on Qcmn. For example, if we use the uRR or uRAP as Qcmn,
the expectation of l1(ˆr,r) is given by Propositions 4 and 7,
respectively. In Section 6, we show they are very small.
The second term in (22) is the summation of the l1 loss
of ˆπk weighted by ˆr(⊥k). If we accurately estimate πk, the
second term is very small. In other words, if we have enough
background knowledge about πk, we can accurately estimate
p in the personalized-mechanism scenario.
It should be noted that when the probability ˆr(⊥k) is small,
the second term in (22) is small even if we have no background
knowledge about πk. For example, when only a small number
of users map x ∈ X (i)
to a tag named “others”, they hardly
affect the accuracy of ˆp. Moreover, the second term in (22) is
k=1 ˆr(⊥k), since the l1 loss is at most 2.
upper-bounded by 2∑κ
Thus, after computing ˆr, the data collector can easily compute
the worst-case value of the second term in (22) to know the
effect of the estimation error of ˆπk on the accuracy of ˆp.
Last but not least, the second term in (22) does not depend
on ε (while the ﬁrst term depends on ε). Thus, the effect of
the second term is relatively small when ε is small (i.e., high
privacy regime), as shown in Section 6.
Remark. Note that different privacy preferences might skew
the distribution πk. For example, doctors might not consider
hospitals as sensitive as compared to patients. Consequently,
the distribution πk conditioned on “hospital” might be a dis-
tribution of patients (not doctors) in hospitals. This kind of
systematic bias can increase the estimation error of ˆπk. Theo-
rem 1 and the above discussions are also valid in this case.
S
6 Experimental Evaluation
6.1 Experimental Set-up
We conducted experiments using two large-scale datasets:
Foursquare dataset. The Foursquare dataset (global-scale
check-in dataset) [54] is one of the largest location datasets
among publicly available datasets (e.g., see [10], [44], [55],
[57]); it contains 33278683 check-ins all over the world, each
of which is associated with a POI ID and venue category (e.g.,
restaurant, shop, hotel, hospital, home, workplace).
We used 359054 check-ins in Manhattan, assuming that
each check-in is from a different user. Then we divided Man-
hattan into 25× 25 regions at regular intervals and used them
1886    28th USENIX Security Symposium
USENIX Association
as input alphabets; i.e., |X| = 625. The size of each region is
about 400m (horizontal) × 450m (vertical). We assumed a
region that includes a hospital visited by at least ten users as a
sensitive region common to all users. The number of such re-
gions was |XS| = 15. In addition, we assumed a region in XN
that includes a user’s home or workplace as her user-speciﬁc
sensitive region. The number of users at home and workplace
was 5040 and 19532, respectively.
US Census dataset. The US Census (1990) dataset [35] was
collected as part of the 1990 U.S. census. It contains responses
from 2458285 people (each person provides one response),
each of which contains 68 attributes.
We used the responses from all people, and used age, in-
come, marital status, and sex as attributes. Each attribute has
8, 5, 5, and 2 categories, respectively. (See [35] for details
about the value of each category ID.) We regarded a tuple
of the category IDs as a total category ID, and used it as an
input alphabet; i.e., |X| = 400 (= 8× 5× 5× 2). We consid-
ered the fact that “divorce” and “unemployment” might be
sensitive for many users [34], and regarded such categories
as sensitive for all users (to be on the safe side, as described
in Section 2.1). Note that people might be students until their
twenties and might retire in their ﬁfties or sixties. Children
of age twelve and under cannot get married. We excluded
such categories from sensitive ones. The number of sensitive
categories was |XS| = 76.
We used a frequency distribution of all people as a true
distribution p, and randomly chose a half of all people as
users who provide their obfuscated data; i.e., n = 179527 and
1229143 in the Foursquare and US Census datasets, respec-
tively. Here we did not use all people, because we would like
to evaluate the non-private mechanism that does not obfuscate
the personal data; i.e., the non-private mechanism has an esti-
mation error in our experiments due to the random sampling
from the population.
As utility, we evaluated the TV (Total Variation) by com-
puting the sample mean over a hundred realizations of Y.
6.2 Experimental Results
Common-mechanism scenario. We ﬁrst focused on the
common-mechanism scenario, and evaluated the RR, RAP-
POR, uRR, and uRAP. As distribution estimation methods,
we used empirical estimation, empirical estimation with the
signiﬁcance threshold, and EM reconstruction (denoted by
“emp”, “emp+thr”, and “EM”, respectively). In “emp+thr”,
we set the signiﬁcance level α to be α = 0.05, and uniformly
assigned the remaining probability to each of the estimates
below the signiﬁcance threshold in the same way as [51].
Figure 5 shows the results in the case where ε is changed
from 0.1 to 10. “no privacy” represents the non-private mech-
anism. It can be seen that our mechanisms outperform the
existing mechanisms by one or two orders of magnitude.
Our mechanisms are effective especially in the Foursquare
Figure 5: ε vs. TV (common-mechanism). A bold line parallel
to the y-axis represents ε = ln|X|.
dataset, since the proportion of sensitive regions is very
small (15/625 = 0.024). Moreover, the uRR provides almost
the same performance as the non-private mechanism when
ε = ln|X|, as described in Section 4.3. It can also be seen that
“emp+thr” and “EM” signiﬁcantly outperform “emp”, since
the estimates in “emp+thr” and “EM” are always non-negative.
Although “EM” outperforms “emp+thr” for the RAPPOR and
uRAP when ε was large, the two estimation methods provide
very close performance as a whole.
We then evaluated the relationship between the number