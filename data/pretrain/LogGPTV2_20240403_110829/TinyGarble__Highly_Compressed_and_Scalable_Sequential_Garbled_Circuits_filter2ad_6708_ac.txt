circuit generation/evaluation routines which is increased by one for
each gate.
416416
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:52 UTC from IEEE Xplore.  Restrictions apply. 
the function in a high level language like C/C++ and
convert it to HDL using a HLS tool. TinyGarble uses
existing HDL synthesis tools to map an HDL to a list
of basic binary gates. In digital circuit theory, this list is
called a netlist. The netlist is generated based on various
constraints and objectives such that it is functionally
equivalent to the HDL/HLS input function. Exploiting
synthesis tools helps to reduce both number of non-
XOR gates in the circuit and the garbling time while
also making the framework easily accessible.
A. Synthesis Flow
In the ﬁrst step, a synthesis converts functional de-
scription of a circuit
into a structural representation
consisting of standard logical elements. Then, it converts
this structural representation into a netlist speciﬁc to the
target platform. In both steps, the synthesis tool works
under a set of user deﬁned constraints/objectives like
minimizing the total delay or limiting the area. In the
following, we describe the details of these two steps and
how we manipulate the synthesis tools in each of the
steps to generate optimized netlists for SFE.
a) Synthesis library: The ﬁrst step in the synthesis
ﬂow is to convert arithmetic and conditional operations
like add, multiply, and if-else to their logical representa-
tions that ﬁts best to the user’s constraints. For example,
the sum of two N-bit numbers can be replaced with an
N-bit ripple carry adder in case of area optimization
or an N-bit carry look ahead adder in case of timing
optimization. A library that consists of these various
implementations is called a synthesis library. We develop
our own synthesis library that includes implementations
customized for SFE. In this library, we build the arith-
metic operations based on a full adder with one non-XOR
gate [5] and conditional operations based on a 2-to-1
multiplexer (MUX) with one non-XOR gate [44].
b) Technology library: The next step is to map
the structural representation onto a technology library to
generate the netlist. A technology library contains basic
units available in the target platform. For example, tools
targeting Field Programmable Gate Arrays (FPGAs) like
Xilinx ISE or Quartus contain Look-Up Tables and Flip
Flops in their technology libraries, which form the archi-
tecture of an FPGA. On the other hand, tools targeting
Application Speciﬁc Integrated Circuits (ASICs) like
Synopsys DC, Cadence, and ABC, may contain a more
diverse collection of elements starting from basic gates
like AND, OR, etc., to more complex units like FFs.
The technology library contains logical descriptions of
these units along with performance parameters like their
delay and area. The goal of the synthesis tool in this
step is to generate a netlist of library components that
best ﬁt the given constraints. For HDL synthesis, we
use tools targeting ASICs as they allow more ﬂexibility
in their input technology library. We design a custom
technology library that contains 2-input gates as required
by the front-end GC tools. We set the area of XOR
gates to 0 and the area of non-XOR gates to a non-
0 value. By choosing area minimization as the only
optimization goal, the synthesis tool produces netlists
with the minimum possible number of non-XOR gates.
An additional feature of our custom technology li-
brary is that it contains non-standard gates (other than
basic gates like NOT, AND, NAND, OR, NOR, XOR,
and XNOR) to increase ﬂexibility of mapping process.
For example, the logical functions F = A ∧ B and
F = (¬A) ∧ B requires equal effort in garbling/evalua-
tion. However by using only standard gates, the second
function will require two gates (a NOT gate and an AND
gate) and store one extra token for ¬A in the memory.
We include four such non-standard gates with an inverted
input in our custom library.
For synthesis of sequential circuits, the technology
library includes memory elements. These elements can
be implemented as FFs which are connected to a clock
signal. Although in conventional ASIC design FFs are
typically as costly as four AND gates, in our GC appli-
cation, FFs do not have any impact on the garbling/evalu-
ation process as they require no cryptographic operations.
Therefore, we set the area of FFs to 0 to show its lack
of impact on computation and communication time of
garbling/evaluation. Moreover, we modify our FFs such
that they can accept an initial value. This helps us remove
extra MUXs in standard FF design for initialization.
B. Ofﬂine Circuit Synthesis
In TinyGarble, we use HDL synthesis tools in an
ofﬂine manner to generate a circuit for a given functional-
ity. This ofﬂine synthesis followed by a topological sort
provides a ready-to-use circuit description for any GC
framework. This approach, unlike online circuit genera-
tion, does not require misspending time for circuit gener-
ation during garbling/evaluation. It also enables the use
of beneﬁcial synthesis optimization techniques that were
previously infeasible for online generation. Moreover, the
synthesis tools have a global view of the circuit, unlike
previous work that manually optimized small modules of
the circuit. This allows more effective optimization for
any arbitrary function and set of constraints.
However, the ofﬂine approach has certain limitations
when it comes to generating circuits for extremely large
functions. Fortunately, the sequential description helps to
overcome most limitations as it generates more compact
circuits. Sequential circuits are radically smaller than
combinational ones with the same functionality. This
property allows synthesis tools to perform more effec-
tive circuit optimization. Moreover, the compatibility of
our sequential descriptions with standard synthesis tools
417417
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:52 UTC from IEEE Xplore.  Restrictions apply. 
simpliﬁes the workﬂow of circuit generation for SFE
applications.
VI. PRIVATE FUNCTION EVALUATION
Two-party Private Function SFE (PF-SFE) allows se-
cure computation of a function fAlice(·) held by one
party (Alice) operating on another party’s data xBob
(Bob) while both the data and the function are kept
private. This is in contrast to the usual setting of SFE
where the function is known by both parties. PF-SFE
is especially useful when the function is proprietary or
classiﬁed.
It is well known that PF-SFE can be reduced to regular
SFE by securely evaluating a Universal Circuit (UC)
[65]. UC is a circuit capable of simulating any circuit
(function) f (·) given the description of f (·) as input [45],
[68]. More formally:
U C(fAlice(·), xBob) = fAlice(xBob).
Secure evaluation of UC completely hides the function-
ality of f (·), including its topology. Subsequent works
have shown how to allow PF-SFE while avoiding the
overhead of UCs [41], [57].
A UC is similar to a Universal Turing Machine (UTM)
[34], [67] that receives a Turing machine description
fAlice(·) and applies it to the input data (xBob) on its
tape [15]. One party provides the machine description
and the other one provides the initial data. The output
fAlice(xBob) resides on the tape after the operation is
completed. A general purpose processor is a special
realization of a UTM. It receives a list of instructions
fAlice(·) and applies them to the input data xBob in
memory.
A. Arithmetic Logic Unit
The core of conventional processors is the Arithmetic
Logic Unit (ALU) which receives two operands and an
opcode indicating the desired operation. ALU supports
an operation set consisting of operations like addition,
multiplication, XOR, etc. The ALU circuit consists of
multiple sub-circuits for these operations and a MUX
which selects one of their outputs. Secure evaluation of
an ALU, where the opcode comes from one party and
operands come from the other party, keeps the operations
private. Thus, ALU can be thought of as an emulator of a
simple UC in which the input function fAlice(·) is limited
to a single operation.
One can combine a number of ALUs to make a more
comprehensive UC that can support functions consisting
of multiple operations. Unfortunately, this approach is
not practical as the complexity of the circuit grows
linearly with the number of operations. On the other
hand, in conventional processors, ALUs are combined
with arrays of FFs, a.k.a., registers, in order to store
the intermediate values for supporting functions with
arbitrarily large number of operations. Since none of
the earlier implementations of GC explicitly supported
memory elements such as FFs,
the ways to connect
the feedback loop around the ALU were rather limited.
However, an explicit sequential description supported by
TinyGarble allows us to leverage conventional processor
architectures. Therefore,
the TinyGarble methodology
not only provides a powerful method for generating
compact circuits with a low overhead for SFE, but
also paves the way for systematically building scalable
sequential circuits that can be used for PF-SFE.
The idea of using an ALU or a universal next-
instruction circuit in the GC protocol can also be found
in [51]. The objective of that paper was improving
efﬁciency of SFE where the function is known by both
parties, unlike PF-SFE where the function is private.
Nonetheless, instead of ALU they eventually decided to
use an instruction-speciﬁc circuit which leaks informa-
tion about the function but results in less effort for non-
private function evaluation.
B. Memory
The processor accesses the memory while executing an
instruction to read the instruction and data and write the
data back. If the memory is securely evaluated along with
the processor, the access patterns must be also oblivious
to both parties. On the other hand, if the memory is not
evaluated securely, the access patterns could be revealed
that in turn could reveal information about the function
to Bob and about the data to Alice. For example, the
instruction read pattern discloses the branching decisions
in the function which may leak information about the
data. Because of TinyGarble sequential methodology, the
memory can be easily implemented using MUX and
arrays of FFs. Thus, it can be included in the processor
circuit to be evaluated securely using the GC protocol.
However,
inclusion of MUXs and FFs increases the
operation time and communication linearly with respect
to the memory size.
One alternative approach for hiding memory access
patterns is the use of Oblivious Random-Access Machine
(ORAM) protocols [27] which allows oblivious load/s-
tore operations with amortized polylogarithmic overhead
[25], [28], [51], [52]. For the sake of simplicity, we do
not use ORAM in this work. However, one can simply
connect our implementation of PF-SFE to an ORAM to
beneﬁt from its lower amortized complexity. As another
alternate, [71] showed that algorithms can sometimes be
rewritten to use data structures such as stacks, queues,
or associative maps for which they give compact circuit
constructions of poly-logarithmic size.
418418
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:52 UTC from IEEE Xplore.  Restrictions apply. 
We assume Alice provides
C. Secure Processor
the private function
fAlice(·) and Bob provides private data xBob. At the end
of the operation, only Bob learns the output fAlice(xBob).
Note that we are not considering the case where both
parties learn the output as that would allow Alice to learn
Bob’s private data with an identity function (f ≡ I). The
protocol is as follows:
1) Alice and Bob agree on an instruction set architec-
ture (ISA), its implementation (i.e., the processor
circuit), the maximum number of sequential cycles,
and the conﬁguration of data xBob in the memory.
2) Alice compiles the function fAlice(·) according to
the ISA. Her input is the compiled binary of the
function.
3) Bob prepares his input based on the agreed conﬁg-
uration to initialize the processor memory.
4) Using any secure GC framework, Alice garbles
the processor circuit for the maximum number of
sequential cycles and Bob, after receiving his inputs
with OT, evaluates the garbled processor circuit for
the same number of cycles.
5) Alice reveals the output types such that Bob learns
the value of the output fAlice(xBob) stored in mem-
ory. This needs to be done only for agreed memory
locations containing the outputs such that Bob does
not learn intermediate values in the memory.
Because of secure evaluation using the GC protocol
in Step 4, no information about values in the circuit will
be leaked except the output. Without knowing internal
values in the processor circuit, none of the parties can
distinguish instructions or memory access patterns. In
the following, we demonstrate an implementation of a
processor supporting the MIPS (Microprocessor without
Interlocked Pipeline Stages) ISA, as an example of a gar-
bled processor for securely evaluating private functions.
D. MIPS
MIPS is a text-book Reduced Instruction Set Com-
puting (RISC) ISA [40]. The RISC ISA consists of a
small set of simpliﬁed assembly instructions in contrast
to Complex Instruction Set Computing (CISC) (e.g., x86
ISA) which includes more complex multi-step instruc-
tions [33]. We choose a RISC ISA processor instead of
CISC for the following main reasons: (i) lower num-
ber of non-XOR gates, (ii) simple and straightforward
implementation, and (iii) availability and diversity of
open-source implementations. Moreover, we choose a
single-cycle MIPS architecture (i.e., one instruction per
sequential cycle). Other architectures (i.e, multi-cycle
and pipelined) increase the performance of the processor
by parallelization. However, the GC protocol does not
beneﬁt from such low level parallelization. The only
important factor for GC is the total number of non-XORs
419419
which is smaller in the single-cycle MIPS. We follow
the Harvard Architecture which has distinct instruction
memory (IM) and data memory (DM) in order to separate
the parties’ inputs. IM is a Read-Only Memory (ROM)
that stores Alice’s instructions. DM is a Random Access
Memory (RAM) that is initialized with Bob’s input. The
parties’ inputs are connected to the initial signal inputs
of FFs in the memories. Bob’s outputs are connected
to the outputs of FFs in the speciﬁed address of DM.
The output address in DM is part of the agreed memory
conﬁguration.
Fig. 6 shows the overall architecture of our 32-bit
MIPS processor. It is based on the Plasma project in
opencores [64]. We modiﬁed the circuit such that the
instruction ROM (IM) and the data RAM (DM) are
separated. The original Plasma processor supports all
the MIPS I ISA except unaligned memory access. In
our implementation, we also omit division instructions
because of their large overhead. Any arbitrary C/C++
function can be easily compiled to MIPS I assembly code
using a cross-platform compiler e.g., GNU gcc.
In 32-bit MIPS, the program counter (PC) is a 32-bit
register (array of FFs) that points to the instruction being
executed at the current cycle. The instruction is fetched
from IM based on the current PC value. The controller
unit is responsible for setting signals to perform the
instruction. In 32-bit MIPS, the register ﬁle consists of
32 registers of 32-bit each. In each cycle, at most two
registers can be read and at most one register can be
written back. ALU receives the read register(s) or a sign
extended immediate as operands. ALU also receives an
opcode from the controller unit. The output of ALU will
be either written back to the register ﬁle or fed to DM
as an address for load/store. The loaded data from DM
is written back to the register ﬁle. In each cycle, PC is
incremented by 4 to point to the next instruction in IM
or is changed according to a branch or jump instruction.
VII. EVALUATION
We use a variety of benchmark functions to evaluate
the performance and practicability of TinyGarble. In this
section, we ﬁrst describe our experimental setup (Sec-
tion VII-A) and metrics for quantifying the performance
of TinyGarble (Section VII-B). We outline the perfor-
mance comparison of TinyGarble (with HDL synthesizer
and our custom libraries) on combinational benchmark
functions with PCF [46], one of the best known ear-
lier automated methodologies to generate circuits for
garbling in Section VII-D. TinyGarble’s performance in
generating sequential circuits for benchmark functions
using a standard HDL synthesis tool is demonstrated in
Section VII-E. Section VII-F shows the CPU time for
various numbers of sequential cycles which demonstrates
the effect of memory footprint reduction in garbling time.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:52 UTC from IEEE Xplore.  Restrictions apply. 




	












	


















	

	







Fig. 6: Lite MIPS architecture. Alice’s and Bob’s inputs and the output are shown.