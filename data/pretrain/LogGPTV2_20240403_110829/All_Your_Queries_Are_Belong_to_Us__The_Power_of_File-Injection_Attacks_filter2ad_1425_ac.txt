Let Rt(cid:27) be the search result of token t(cid:27) on files F2.
kt(cid:27) ← Recover(Rt(cid:27),K(cid:27)(cid:27))
Let Rt(cid:27) be the search result of token t(cid:27) on files F2.
kt(cid:27) ← Recover hierarchical(Rt(cid:27),K(cid:27)(cid:27))
F2 ← Inject Files hierarchical(K(cid:27)(cid:27)).
for each token t(cid:27) ∈ t2 do
Figure 5: Recovering multiple keywords using partial file knowledge. T is the threshold determining the maximum
number of keywords in a file; δ is a parameter. Inject Files and Recover are from Figure 2.
et al. [4] (CGPR15). We do not compare with the attacks
of Islam et al. [10] (IKK12), since their results are strictly
dominated by those of CGPR15.
5.1 Setup
For our experiments we use the Enron email dataset [1],
consisting of 30,109 emails from the “sent mail” folder
of 150 employees of the Enron corporation that were sent
between 2000–2002. We extracted keywords from this
dataset as in CGPR15: words were first stemmed us-
ing the standard Porter stemming algorithm [18], and we
then removed 200 stop words such as “to,” “a,” etc. Do-
ing so results in approximately 77,000 keywords in total.
In our experiments, we chose the top 5,000 most frequent
keywords as our keyword universe (as in CGPR15).
We assumed the threshold countermeasure with T =
200. As discussed earlier, only 3% of the files contained
more than this many keywords.
We could not find real-world query datasets for email.
Therefore, in our experiments we choose the client’s
queries uniformly from the keyword universe, as in
CGPR15. (However, our attacks do not use any informa-
tion about the distribution of the queries.) Leaked files
are chosen uniformly from the base set of 30,109 emails,
and the percentage of leaked files was varied from 1%
to 100%. For each value of the file-leakage percentage,
we repeat the attack on 100 uniform sets of queries (con-
taining either one token or 100 tokens) and 10 uniformly
sampled sets of leaked files of the appropriate size; we
USENIX Association  
25th USENIX Security Symposium  713
7
)
%
(
e
t
a
r
y
r
e
v
o
c
e
R
Our attack
CGPR15
100
90
80
70
60
50
40
30
20
10
Our attack
CGPR15
100
90
80
70
60
50
40
30
20
10
)
%
(
e
t
a
r
y
r
e
v
o
c
e
R
1
10
20
40
30
70
Leakage percentage (%)
50
60
80
90 100
1
10
20
40
30
70
Leakage percentage (%)
50
60
s
e
l
ﬁ
d
e
t
c
e
j
n
i
f
o
r
e
b
m
u
N
50
45
40
35
30
25
20
15
10
5
1
10
20
(a)
40
30
70
Leakage percentage (%)
50
60
80
90 100
80
90 100
Figure 6: Recovering the keyword corresponding to a
single token. Probability of recovering the correct key-
word as a function of the percentage of files leaked.
report the average. We do not include error bars in our
figures, but have observed that the standard deviation in
our experiments is very small (less than 3% of the aver-
age).
5.2 Recovery of a Single Token
The performance of our attack for recovering the key-
word associated with a single token (described in Sec-
tion 4.2.1) is displayed in Figure 6. The server only needs
to inject (cid:31)log2T(cid:30) = 9 files in order to carry out the at-
tack. It can be observed that our attack performs quite
well even with only a small fraction of leaked files, e.g.,
recovering the keyword about 70% of the time once only
20% of the files are leaked, and achieving 30% recovery
rate even when given only 1% of the files.
Neither the IKK12 attack nor the CGPR15 attack ap-
plies when the server is given the search results of only a
single token. To provide a comparison with our results,
we run the CGPR15 attack by giving it the search results
of 100 tokens (corresponding to uniformly chosen key-
words) and then measure the fraction of keywords recov-
ered. As shown in Figure 6, the CGPR15 attack recov-
ers a keyword with probability less than 20% even when
95% of the client’s files are leaked. Of course, our attack
model is stronger than the one considered in CGPR15.
5.3 Recovery of Multiple Tokens
We have also implemented our attack from Section 4.2.2
which can be used to recover the keywords correspond-
ing to multiple tokens. In our experiments, we target the
recovery of the keywords associated with m = 100 to-
kens; we choose n = 10, and set δ as described in Sec-
tion 4.2.2.
Figure 7a tabulates the fraction of keywords recovered
by our attack, and compares it to the fraction recovered
(b)
Figure 7: Recovering the keywords corresponding to 100
tokens. (a) Fraction of keywords recovered and (b) num-
ber of files injected as a function of the percentage of
files leaked.
by the CGPR15 attack. (As noted in the previous sec-
tion, the CGPR15 attack inherently requires search re-
sults for multiple tokens; this explains why the results
for the CGPR15 attack in Figure 7a are almost identi-
cal to the results for their attack in Figure 6.) Both at-
tacks do well when the fraction of leaked files is large,
however the recovery rate of the CFPR15 attack drops
dramatically as the fraction of leaked files decreases. In
contrast, our attack continues to perform well, recovering
65% of the keywords given access to 50% of the client’s
files, and still recovering 20% of the keywords when only
10% of the client’s files have been leaked. We stress that
in our attack the server knows which keywords have been
recovered correctly and which have not, something that
is not the case for prior attacks.
Figure 7b shows the number of files that need to be
injected in order to carry out our attack. The number of
files injected never exceeds 40, and in many cases it is
even less than that. We also highlight that the number of
files injected to recover the keywords associated with 100
714  25th USENIX Security Symposium 
USENIX Association
8
tokens is more than an order-of-magnitude smaller than
100× the number of files injected to recover the keyword
associated with a single token in the previous section.
The number of files injected by our attack first in-
creases with the fraction of leaked files, and then de-
creases; we briefly explain why. The number of files
injected in step 1 of our attack is independent of the
fraction of leaked files. The number of files injected
in step 2 of the attack depends on both the number of
unrecovered tokens (i.e., the size of t2) and the average
size of the candidate universe for each unrecovered to-
ken t(cid:30) (i.e., the size of Kt(cid:30)). When the fraction of leaked
files is very small, the estimated joint frequencies are far
from the true frequencies and, in particular, most esti-
mated joint frequencies are 0; thus, many keywords are
removed from Kt(cid:30) and hence the size of Kt(cid:30) is low. The
net result is that the recovery rate is small, but so is the
number of injected files. As the fraction of leaked files
increases, more keywords are included in Kt(cid:30), leading to
higher recovery rate but also more injected files. When
the fraction of leaked files becomes very high, however,
the estimated frequencies are very close to the true fre-
quencies and so more keywords are recovered in step 1
of the attack. This leaves fewer unrecovered tokens in
step 2, leading to fewer injected files overall even as the
recovery rate remains high.
6
Ineffectiveness of Keyword Padding
Prior work [10, 4] suggests keyword padding as another
potential countermeasure for attacks that exploit the file-
access pattern. The basic idea is to distort the real fre-
quency of each keyword k by randomly associating files
that do not contain that keyword with k; this is done at
setup time, when the client uploads its encrypted files to
the server. One version of the countermeasure [4] en-
sures that the number of files returned in response to any
search result is a multiple of an integer λ . A stronger ver-
sion of the countermeasure [10] involves performing the
padding in such a way that for any keyword k there are
at least α −1 other keywords having the same frequency.
These countermeasures defeat the attacks in prior work,
but we show that they have little effect on our attacks.
We remark that keyword padding seems difficult to ap-
ply in the dynamic setting, where new files are uploaded
after the initial setup done by the client. The dynamic
case is not discussed in [10, 4].
6.1 Binary-/Hierarchical-Search Attacks
Even when keyword padding is used, our binary-search
and hierarchical-search attacks will recover the key-
word k corresponding to some token t unless one of the
injected files that does not contain k is returned in re-
sponse to the search using t. We show that the proba-
bility of this bad event is small, focusing on the binary-
search attack for concreteness. Say (cid:31) of the files con-
tain k and that, after keyword padding, an additional
β · (cid:31) random and independently chosen files (in expec-
tation) that do not contain k are returned in response to
the search using t. (By setting parameters appropriately,
this roughly encompasses both the countermeasures de-
scribed above.) Now consider some file injected as part
of the binary-search attack that does not contain k. The
probability that this file is chosen as one of the spuri-
ous files returned in response to the search using t is
β (cid:31)/(F − (cid:31)), where F is the total number of files (includ-
ing the injected files). Since (cid:27)log|K|(cid:25) files are injected,
the overall probability that the bad event occurs is at most
1−(cid:31)1−
β (cid:31)
(F − (cid:31))(cid:30)(cid:27)log|K|(cid:25)
.
In fact, this is an over-estimate since if k is uniform then
on average only half the injected files contain k.
For the Enron dataset with |K| = 5,000, F = 30,109,
(cid:31) = 560, and β = 0.6, and assuming half the injected files
contain the keyword in question, the probability that the
binary-search attack succeeds is 0.93. (In fact, β = 0.6
is quite high, as this means that more than 1/3 of the files
returned in response to a query do not actually contain
the searched keyword.) With β = 0.6 the IKK12 and
CGPR15 attacks recover no keywords at all.
6.2 Attacks with Partial File Leakage
Although our attacks with partial file leakage use in-
formation about keyword frequencies and joint frequen-
cies,
they are still not significantly affected by the
padding countermeasures. The reason is that although
the padding ensures that a given frequency no longer suf-
fices to uniquely identity a keyword, the frequency of any
particular keyword doesn’t change very much. Thus, the
exact frequency and the estimated frequency of any key-
word remain close even after the padding is done, and
the underlying keyword is still likely to be included in
the candidate universe of a target token. As long as this
occurs, the search step recovers the token with high prob-
ability as discussed in the previous section. This is even
more so the case with regard to joint frequencies, since
these do not change unless two keywords are both asso-
ciated with the same random file that contains neither of
those keywords, something that happens with low prob-
ability.
To validate our argument, we implement the padding
countermeasure proposed in [4] and repeat the experi-
ments using our attacks. As shown in Figures 8 and 9,
USENIX Association  
25th USENIX Security Symposium  715
9
Our attack, no padding
Our attack, β = 0.2
Our attack, β = 0.4
Our attack, β = 0.6
)
%