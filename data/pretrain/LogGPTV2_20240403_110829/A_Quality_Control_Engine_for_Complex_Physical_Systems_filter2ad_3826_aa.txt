# A Quality Control Engine for Complex Physical Systems

**Authors:** Haifeng Chen, Takehiko Mizoguchi, Yan Tan, Kai Zhang, Geoff Jiang  
**Conference:** 2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks  
**Affiliation:** NEC Laboratories America, Princeton, NJ, USA  
**Emails:** {haifeng, tmizoguchi, yan, kai, gfj}@nec-labs.com

## Abstract
This paper introduces a novel framework to automatically identify suspicious sensors that contribute to quality changes in complex physical systems, such as manufacturing plants. The framework treats sensor readings as time series and consists of three main stages: time series transformation to feature series, feature ranking, and ranking score fusion. In the first stage, we transform time series into multiple feature series to describe the underlying dynamics of each sensor's data. Next, we compute the importance scores of all feature series using various feature selection and ranking techniques, each capturing specific aspects of feature importance and their dependencies in the feature space. Finally, we combine the importance scores from all rankers and features to obtain the final ranking of each sensor with respect to the system quality change. Our experiments, based on both synthetic and real-world sensor data, demonstrate the effectiveness of the proposed method. Additionally, we have implemented our framework as a production engine and successfully applied it to several real physical systems.

**Keywords:** Time series, quality control, feature extraction, sliding window, feature selection, regularization

## I. Introduction
With the decreasing cost of hardware and the increasing demand for autonomous management, many modern physical systems are equipped with extensive networks of sensors distributed across different parts of the system. These sensors continuously collect time series data, which monitor the operational status of the system. It is crucial to effectively model and discover patterns from these sensor data to better understand the underlying dynamics of system operation and facilitate practical management tasks, such as anomaly detection, quality control, and capacity planning.

In this paper, we leverage sensor data to control the quality of physical systems, particularly in manufacturing. The output quality of manufacturing systems is typically controlled by human operations, but under certain conditions, the quality may drop, directly affecting manufacturing profits. Therefore, it is essential to identify the hidden conditions leading to quality degradation to quickly adjust the system and avoid future losses.

The quality control is achieved by analyzing the data from deployed sensors. The goal is to locate suspicious sensors that contribute to quality changes, thereby assisting system operators in pinpointing the root cause of quality degradation.

There are several challenges in identifying suspicious sensors for quality control:
1. **Data Volume and Correlation:** There are a large number of sensors, and the data collected can be highly correlated, making manual inspection impractical.
2. **Diverse Sensor Behaviors:** Different sensors exhibit different behaviors due to the diversity in system components and their functionalities. For example, some sensors show direct changes in raw values, while others exhibit significant frequency changes.
3. **Nonlinear Dependencies:** The relationships between sensor data and system operational status are often highly nonlinear. A hidden fault in one component may undergo a sequence of nonlinear physical processes before affecting the final product quality.

To address these challenges, this paper proposes a general framework for quality control in physical systems. The framework utilizes several learning techniques, including feature selection and ranking, and information fusion, to achieve automatic and accurate localization of suspicious sensors. Given the time series data from a sensor, we first transform it into multiple feature series. These features are derived from a pre-defined library that describes different aspects of the signal dynamics. We then rank the importance of these feature series with respect to system quality using several feature selection techniques, including regularization-based, tree-based, and localized nonlinear rankers. Finally, we perform ranking score fusion to combine the outputs from all rankers and obtain the final ranking of sensors that can explain the quality change.

We have implemented the proposed method as a quality control engine and successfully applied it to several real physical systems, such as a food manufacturing system. Our experimental results, presented in Section VI, demonstrate the effectiveness of our approach in real-world applications.

## II. Engine Overview
Given \( n \) sensors in a system, we obtain \( n \) time series \( x_1(t), \ldots, x_n(t) \), where \( t = 1, \ldots, T \) is the system operation period. During this period, the system quality is represented by \( y(t) \), \( t = 1, \ldots, T \). Typically, \( y(t) \) is obtained from a special sensor called the 'key performance indicator' (KPI). Figure 1 shows an example of KPI values in a real system. Based on the KPI values, we divide the system operations into good-quality and bad-quality regions, as indicated by the dashed line in Figure 1. Our goal is to rank the time series \( x_i(t) \) based on their contributions to the system quality change.

![Figure 1: An example of KPI time series](fig1.png)

System quality changes are often triggered by variations in the underlying physical operations, which are reflected in the dynamics of related sensor readings. However, the dynamics of different time series are usually represented in different ways. For example, in Figure 2(a), we can infer quality changes directly from the raw values of the time series. In contrast, for the sensor in Figure 2(b), the frequency distribution in the readings is relevant. For the series in Figure 2(c), the change in temporal dependencies explains the KPI changes. Specifically, in the good-quality region, the time series has a dependency relation \( x(t) = f(x(t-1), x(t-2), \ldots) \), whereas in the bad-quality region, the relation changes to \( x(t) = g(x(t-1), x(t-2), \ldots) \), where \( f(\cdot) \neq g(\cdot) \).

![Figure 2: KPI and related raw time series](fig2.png)

To address the diverse dynamics of time series, we construct a library of features that can potentially interpret various time series evolution patterns. These feature definitions are based on feedback from domain experts. While we cannot guarantee completeness, they cover the majority of time series dynamics in physical systems.

Given the feature definitions in the library \( F_1, \ldots, F_m \), we transform the raw time series into candidate feature series \( x(t) \rightarrow \{x_{F_1}(t), \ldots, x_{F_m}(t)\} \) and use feature selection techniques to rank these features according to their relationship to the quality change. In practice, when the number of time series \( n \) is large, we encounter a huge feature space with \( (m + 1)^n \) feature candidates, including raw time series and their feature series. Ranking these features in a stable way is non-trivial, especially given the potential for highly nonlinear dependencies. To address these issues, we provide an ensemble of feature rankers, including a regularization-based ranker, a tree-based ranker, and a localized nonlinear ranker. These rankers generate different subsets of important features, and by combining their power, we aim to obtain a complete and stable ranking from the large feature space.

![Figure 3: High-level workflow of the quality control engine](fig3.png)

After feature transformation and ranking, we combine all ranking results to obtain the final ranked list of suspicious sensors, as shown in the 'Ranking score fusion' step in Figure 3. This process involves two dimensions of ranking score fusion:
1. **Aggregation of Feature Rankings:** Since the final output is the ranking of sensors (i.e., the raw time series), we need to aggregate all feature ranking scores for each raw time series.
2. **Combination of Ranker Outputs:** We need to combine the outputs of different rankers to obtain an overall ranking score. By combining both dimensions, we obtain the final ranked list of sensors based on their contribution to the system quality change.

In the remaining sections, we will describe each step of the workflow in detail. Section III describes the types of features used to transform the sensor data. Section IV describes the feature ranking algorithms. Section V presents the fusion of ranking scores to get the final sensor ranking. Some experimental results are described in Section VI.

## III. Discover Features from Sensor Data
Data from different sensors exhibit different dynamics with respect to system operation. These dynamics can vary in shape, frequency, scale, and other characteristics. To handle these heterogeneous behaviors, we transform the time series collected from each sensor into a set of feature series. These features cover various aspects of the dynamics of the raw time series and can be used to localize sensors that contribute to quality changes.

### A. Sliding Windows
The typical strategy for feature extraction from time series is the sliding window technique. This technique allows us to extract features from time series while preserving continuity along the time axis. Figure 4 illustrates the concept of this technique.

![Figure 4: Sliding window technique](fig4.png)

Consider a time series \( x_i(t) \), where \( i = 1, \ldots, n \) is the index of the time series and \( t = 1, \ldots, T \) is the time stamp. The width of the window is denoted as \( w \). If the series starts from \( t = t' \), where \( t' = 1, \ldots, T - w + 1 \), we obtain a subsequence of width \( w \), i.e., \( x_i(t'), x_i(t' + 1), \ldots, x_i(t' + w - 1) \). From this subsequence, we can extract a possible feature value \( x_{F_j}^i(t') \):

\[ \{x_i(t'), x_i(t' + 1), \ldots, x_i(t' + w - 1)\} \rightarrow x_{F_j}^i(t') \]

where \( F_j \) represents the \( j \)-th feature in the pre-defined feature library \( F \). We extract feature \( x_{F_j}^i(t') \) from \( x_i(t) \) for all possible \( t' \) and obtain the corresponding feature time series with length \( T - w + 1 \), i.e., \( x_{F_j}^i(1), x_{F_j}^i(2), \ldots, x_{F_j}^i(T - w + 1) \).

If we extract \( m \) feature sequences as defined in the feature library \( F_1, \ldots, F_m \) for each time series \( x_i(t) \) (where \( i = 1, \ldots, n \)), we will have a total of \( (m + 1) \times n \) series, including the raw time series.

### B. Feature Library
Table I presents a list of features implemented in our engine. These features cover the following aspects of time series properties:

- **Temporal Domain Characteristics:** We extract basic statistics from time series to reflect the shape of its evolution, including mean, standard deviation, and higher-order moments of the subsequence within each sliding window. We also compute the 5% and 95% quantiles of the value distribution in the sliding window.
- **Frequency Domain Characteristics:** We apply the Fast Fourier Transform (FFT) to these subsequences and use information from the power spectral density as features. For example, we use the power and location of the most dominant frequency as features. We also divide the frequency region into different bands and compute the sum of the power spectrum in each band as a feature.
- **Temporal Dependencies of Individual Time Series:** We use the auto-regressive (AR) model to describe this property, and the coefficients of the AR model are used as features. Not all time series have strong temporal dependencies. We compute the Akaike’s Information Criterion (AIC) score as a measure of the goodness of the AR model. If the score is consistently low over time, we ignore the AR-related features for that time series.
- **Dependencies Across Different Time Series:** We can also extract features from two or more time series. For example, we compute their correlation coefficient and use it as a feature if we have subsequences of two time series from the same sliding window.

After extracting a feature time series, we give it a name, called a 'token', as shown in the right column of Table I, to retrieve the original time series and related feature series. For example, the mean feature time series from a time series 'Series1' will be named 'mean::Series1'. Figure 5 shows examples of different features from the same time series, illustrating that different features capture different dynamics of time series behavior.

![Figure 5: Examples of feature time series](fig5.png)

## IV. Feature Ranking
After feature extraction, the original sensor data are transformed into an expanded set of time series:

\[ x(t) = [x_1(t), x_{F_1}^1(t), \ldots, x_{F_m}^1(t), \ldots, x_n(t), x_{F_1}^n(t), \ldots, x_{F_m}^n(t)]^\top \]

The set includes both the original time series and the transformed feature series \( x(t) \in \mathbb{R}^N \) (where \( t = 1, \ldots, T \) and \( N = (m+1)n \)). While feature transformation provides an opportunity to generate different time series properties, it poses challenges in accurately selecting and ranking important features because the problem space becomes much larger. Additionally, different feature series are often correlated, and the relationships between feature series and system quality are no longer linear. To achieve a reliable and stable ranking of feature series, we need to consider all aspects of feature interactions and their dependencies with respect to the KPI quality. Therefore, rather than relying on a single feature ranking method, we utilize an ensemble of feature rankers, including a regularization-based ranker, a tree-based ranker, and a local structure-based ranker.

### A. Regularization-Based Ranker
The regularization-based ranker focuses on the regression-based relationship between features and the system quality. It uses techniques like LASSO (Least Absolute Shrinkage and Selection Operator) to select and rank features based on their importance in predicting the KPI.

### B. Tree-Based Ranker
The tree-based ranker uses information theory-based criteria to detect important features. For a node \( \tau \) in the tree, we search for the best feature \( x_f \) that leads to the best split of \( \tau \). By comparing the values of \( x_f \) with an optimal cut point, the original node is split into two sub-nodes \( \tau_l \) and \( \tau_r \) containing \( n_l \) and \( n_r \) samples, respectively. The goodness of the split is measured by the reduction in impurity, such as Gini impurity or entropy.

### C. Local Structure-Based Ranker
The local structure-based ranker, such as RELEAFF, looks at local regions to detect nonlinear relationships. It evaluates the importance of features by considering their impact on the local structure of the data, providing a complementary view to the global rankings from the other rankers.

By combining the outputs from these rankers, we aim to obtain a comprehensive and stable ranking of the feature series. The next section describes how we fuse these ranking scores to obtain the final sensor ranking.

## V. Fusion of Ranking Scores
The final step in our framework is to combine the ranking scores from all rankers and features to obtain the final ranked list of sensors. This process involves two dimensions of ranking score fusion:
1. **Aggregation of Feature Rankings:** For each raw time series, we aggregate the ranking scores of all its feature series to obtain a single ranking score.
2. **Combination of Ranker Outputs:** We combine the outputs of different rankers to obtain an overall ranking score for each feature series.

By combining both dimensions, we obtain the final ranked list of sensors based on their contribution to the system quality change. This fused ranking provides a robust and reliable indication of which sensors are most likely to be responsible for quality changes in the system.

## VI. Experimental Results
We evaluate the effectiveness of our proposed method through experiments on both synthetic and real-world sensor data. The synthetic data allow us to test the framework under controlled conditions, while the real-world data provide insights into its practical applicability.

### A. Synthetic Data
We generated synthetic time series data to simulate various scenarios, including different levels of noise, varying degrees of nonlinearity, and different types of quality changes. Our experiments show that the proposed framework can accurately identify the suspicious sensors that contribute to quality changes, even in the presence of high noise and complex dynamics.

### B. Real-World Data
We applied our framework to several real physical systems, including a food manufacturing system. The results demonstrate that our method can effectively pinpoint the root causes of quality degradation, enabling system operators to take timely corrective actions. The detailed evaluation metrics, such as precision, recall, and F1-score, are provided in the full paper.

## Conclusion
In this paper, we introduced a novel framework for quality control in complex physical systems. The framework leverages time series data from sensors, transforms them into feature series, ranks the importance of these features, and fuses the ranking scores to identify suspicious sensors. Our experiments on both synthetic and real-world data demonstrate the effectiveness of the proposed method. We have also implemented the framework as a production engine and successfully applied it to several real physical systems, showcasing its practical utility.

**Acknowledgments:** We would like to thank the anonymous reviewers for their valuable feedback and suggestions. This work was supported in part by the National Science Foundation (NSF) under Grant No. XXXX.

**References:**
1. [Reference 1]
2. [Reference 2]
3. [Reference 3]
4. [Reference 4]
5. [Reference 5]
6. [Reference 6]

---

**Note:** Figures and references should be added as per the actual content and sources.