We use a dumb-bell topology in which ten source ASes connect
to a destination AS via a transit AS. Each source AS has 100 source
hosts connected to a single access router. The transit AS has two
routers Rbl and Rbr, and the destination AS has one victim desti-
nation host. The link between Rbl and Rbr is the bottleneck link,
and all other links have sufﬁcient capacity to avoid congestion. We
vary the bottleneck link capacity from 400Mbps to 50Mbps to sim-
ulate the scenario where 25K ∼ 200K senders (both legitimate and
malicious) share a 10Gbps link. Each sender’s fair share bandwidth
varies from 400Kbps ∼ 50Kbps, which is NetFence’s targeted op-
erating region. The propagation delay of each link is 10ms.
In the simulations, each sender is either a legitimate user or an
attacker. To stress-test our design, we let each source AS have
only one legitimate user that repeatedly sends a 20KB ﬁle to the
victim using TCP. We let each attacker send 1Mbps constant-rate
UDP trafﬁc to the victim. We measure the effectiveness of a DoS
defense system using two metrics: 1) the average time it takes to
complete a successful ﬁle transfer; and 2) the fraction of successful
ﬁle transfers among the total number of ﬁle transfers initiated. We
set the initial TCP SYN retransmission timeout to 1 second, and
abort a ﬁle transfer if the TCP three-way handshake cannot ﬁnish
after nine retransmissions, or if the entire ﬁle transfer cannot ﬁnish
in 200 seconds. We terminate a simulation run when the simulated
time reaches 4000 seconds.
For each DoS defense system we study, we simulate the most
effective DoS ﬂooding attacks malicious nodes can launch. In case
of an unwanted trafﬁc ﬂooding attack, the most effective ﬂooding
strategy in NetFence and TVA+ is the request packet ﬂooding at-
tack. Under this attack, each NetFence sender needs to choose a
proper priority level for its request packets. We make an attacker
always select the highest priority level at which the aggregate attack
trafﬁc can saturate the request channel. A legitimate sender starts
with the lowest priority level and gradually increases the priority
level if it cannot obtain valid congestion policing feedback.
Figure 8 shows the simulation results. The average ﬁle transfer
completion ratio is omitted because all ﬁle transfers complete in
these simulations. As can be seen, StopIt has the best performance,
because the attack trafﬁc is blocked near the attack sources by net-
work ﬁlters. TVA+ and NetFence also have a short average ﬁle
transfer time that only increases slightly as the number of simulated
senders increases. This is because in a request packet ﬂooding at-
tack, as long as a legitimate sender has one request packet delivered
to the victim, it can send the rest of the ﬁle using regular packets
that are not affected by the attack trafﬁc. The average ﬁle transfer
time in NetFence is about one second longer than that in TVA+, be-
cause a legitimate sender will initially send a level-0 request packet
that cannot pass the bottleneck link due to attackers’ request packet
ﬂoods. After one second retransmission backoff, a sender is able
to retransmit a request packet with sufﬁciently high priority (level-
10) to pass the bottleneck link. Attackers cannot further delay le-
gitimate request packets, because they are not numerous enough to
congest the request channel at this priority level.
Figure 8 also shows that FQ alone is an ineffective DoS defense
mechanism. With FQ, the average ﬁle transfer time increases lin-
early with the number of simulated senders, as each packet must
compete with the attack trafﬁc for the bottleneck bandwidth.
These results show that NetFence performs similarly to capability-
based and ﬁlter-based systems when targeted victims can stop the
attack trafﬁc. A legitimate sender may wait longer in NetFence
to successfully transmit a request packet than in TVA+ or StopIt.
This is because NetFence uses coarse-grained exponential back-
off to schedule a request packet’s transmission and set its prior-
ity, while TVA+ uses ﬁne-grained but less scalable per-sender fair
queuing to schedule a request packet’s transmission, and StopIt en-
ables a victim to completely block unwanted trafﬁc.
6.3.2 Colluding Attacks
Next we present our simulation results for regular trafﬁc ﬂooding
attacks where malicious sender-receiver pairs collude to ﬂood the
263o
i
t
a
R
t
u
p
h
g
u
o
r
h
T
 1
 0.8
 0.6
 0.4
 0.2
 0
o
i
t
a
R
t
u
p
h
g
u
o
r
h
T
 1
 0.8
 0.6
 0.4
 0.2
 0
NetFence
FQ
StopIt
TVA+
25K
50K
100K
Number of Simulated Senders
(a) Long-running TCP
NetFence
FQ
StopIt
TVA+
25K
50K
100K
Number of Simulated Senders
(b) Web-like trafﬁc
200K
200K
Figure 9: Throughput Ratio between legitimate users and attackers
when receivers fail to suppress the attack trafﬁc. Fairness Index among
legitimate users is close to 1 in all the simulations.
network. Such attacks may also occur if DoS victims fail to identify
the attack trafﬁc.
Single Bottleneck: We use a similar topology as in the previous
experiments (§ 6.3.1) to simulate colluding attacks. In this simu-
lation topology, the router at the right-hand side of the bottleneck
link Rbr connects to one destination AS with a victim host and
nine additional ASes, each having a colluding host (colluder). Each
source AS has 25% legitimate users and 75% attackers, simulating
the case where the attackers are numerous but there are still a rea-
sonable number of legitimate users in each source AS.
Each legitimate user sends TCP trafﬁc to the victim host. We
simulate two types of user trafﬁc: 1) long-running TCP, where a le-
gitimate sender sends a single large ﬁle; 2) web-like trafﬁc, where a
sender sends small ﬁles whose size distribution mimics that of web
trafﬁc. We draw the ﬁle size distribution from a mixture of Pareto
and exponential distributions as in [29], and make the interval be-
tween two ﬁle transfers uniformly distributed between 0.1 and 0.2
seconds. The maximum ﬁle size is limited to 150KB to make the
experiments ﬁnish within a reasonable amount of time.
To simulate colluding attacks, we let each attacker send 1Mbps
UDP trafﬁc to a colluder. The attackers in TVA+ and NetFence
send regular packets. Colluders in StopIt do not install ﬁlters to stop
the attack trafﬁc. We simulate each experiment for 4000 seconds.
When compromised nodes organize into pairs to send attack traf-
ﬁc, NetFence aims to guarantee each legitimate sender its fair share
of the bottleneck bandwidth without keeping per-sender queues in
the core network. We use two metrics to measure a DoS defense
system’s performance under this type of attack: 1) Throughput Ra-
tio, the ratio between the average throughput of a legitimate user
and that of an attacker; and 2) Fairness Index among legitimate
users [11]. Let xi denote a legitimate sender i’s throughput, and the
fairness index is deﬁned as (P xi)2/(n P x2
i ). The ideal through-
put ratio is 1, indicating that a legitimate user obtains on average
the same bottleneck bandwidth as an attacker. The ideal fairness
index is also 1, indicating that each legitimate sender has the same
average throughput. We only measure the fairness index among
legitimate users because Throughput Ratio has already quantiﬁed
how well a legitimate user performs relatively to an attacker.
Figure 9 shows the simulation results. The fairness index for all
systems is close to 1 in all the simulations and is thus not shown
in the ﬁgure. For long-running TCP, NetFence’s throughput ratio is
also close to 1. This result shows that NetFence provides a legiti-
mate sender its fair share of bandwidth despite the presence of DoS
ﬂooding trafﬁc, consistent with the theoretic analysis in § 3.4. For
the web-like trafﬁc, NetFence’s throughput ratio increases gradu-
ally from 0.3 to close to 1 as the number of simulated senders in-
creases. The throughput ratio is low when the number of senders is
small, because a legitimate sender cannot fully utilize its fair share
bandwidth: each sender has a large fair share of bandwidth, but
a legitimate sender’s web-like trafﬁc has insufﬁcient demand and
there are gaps between consecutive ﬁle transfers.
FQ and StopIt perform exactly the same, because in these collud-
ing attacks, they both resort to per-sender fair queuing to protect a
legitimate user’s trafﬁc. However, unexpectedly, we note that they
provide legitimate users less throughput than attackers even when
the user trafﬁc is long-running TCP. By analyzing packet traces,
we discover that this unfairness is due to the interaction between
TCP and the DRR algorithm. A TCP sender’s queue does not al-
ways have packets due to TCP’s burstiness, but a constant-rate UDP
sender’s queue is always full. When a TCP sender’s queue is not
empty, it shares the bottleneck bandwidth fairly with other attack-
ers, but when its queue is empty, the attack trafﬁc will use up its
bandwidth share, leading to a lower throughput for a TCP sender.
1
1
TVA+ has the lowest throughput ratio among all systems in this
simulation setting, indicating that a small number of colluders can
signiﬁcantly impact TVA+’s performance. This is because TVA+
uses per-destination fair queuing on the regular packet channel.
With NC colluders, a DoS victim obtains only
NC +1 fraction of
the bottleneck capacity C at attack times, and each of the victim’s
G legitimate senders obtains
G(1+NC ) fraction of the capacity C.
The attackers, however, obtain an aggregate NC
(1+Nc) fraction of C.
If this bandwidth is shared by B attackers fairly, each will get a
B(1+Nc ) fraction of the bottleneck capacity. A sender’s bottleneck
bandwidth share in other systems (NetFence, StopIt, and FQ) is
G+B , and does not depend on the number of colluders NC . In our
simulations, Nc = 9, G = 25% × 1000, and B = 75% × 1000. A
1
2500 of the bottleneck bandwidth,
legitimate TVA+ sender obtains
while an attacker obtains
7500 of the bottleneck bandwidth, three
times higher than a legitimate sender, as shown in Figure 9.
NC
1
9
In these simulations, we also measure the bottleneck link uti-
lization. The result shows that the utilization is above 90% for
NetFence, and almost 100% for other systems. NetFence does not
achieve full link utilization mainly because a router stamps the L↓
feedback for two extra control intervals after congestion has abated,
as explained in § 4.3.4.
Multiple Bottlenecks: To evaluate NetFence’s performance with
multiple bottlenecks, we have also simulated colluding attacks on
a parking-lot topology with two bottleneck links. The results show
that in a multi-bottleneck topology, NetFence provides a reason-
able share of bandwidth to a legitimate TCP sender, but this share
may be less than a TCP sender’s max-min fair share, because a
TCP ﬂow may switch back and forth between two rate limiters and
cannot adapt quickly enough to fully use its rate limit. This per-
formance can be improved with a more complicated design, as dis-
cussed in § 4.3.5. More discussions and simulation results for the
multi-bottleneck topology can be found in [28].
Strategic Attacks: Attackers may launch sophisticated attacks
(§ 5.2) than brute-force ﬂooding attacks. We simulate microscopic
264Ton=4s
Ton=0.5s
)
s
p
b
K
(
t
u
p
h
g
u
o
r
h
T
r
s
U
 400