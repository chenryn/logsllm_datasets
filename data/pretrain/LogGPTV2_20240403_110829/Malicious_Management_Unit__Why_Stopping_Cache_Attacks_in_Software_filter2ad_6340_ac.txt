0x9619320c8000 to its corresponding memory page on
the x86_64 architecture.
table walk
eviction sets should target page colors outside the
security domain enforced by existing defenses.
3. Similar to existing cache attacks, XLATE attacks are
subject to noise. Worse, due to their indirect nature,
addressing the sources of noise is more challenging.
We need to overcome this noise for an effective im-
plementation of XLATE.
Next we discuss how we overcome these challenges in
our implementation of XLATE attacks.
6
Implementing XLATE Attacks
Before we can use the MMU to mount XLATE attacks,
we need to fully understand how the MMU performs a
page table walk when translating virtual addresses into
their physical counterparts. Even though it is already
known that the MMU uses the TLB and the CPU caches
as part of its translation process [12], there are also other
caches (e.g., translation caches [1]) with mostly an un-
known architecture. We need to reverse engineer their
architecture before we can ensure that our virtual address
translations end up using the CPU caches where our vic-
tim data is stored. We reverse engineer these properties
in Section 6.1. In Section 6.2, we show how we retroﬁt
an existing algorithm for building PRIME + PROBE evic-
tion sets to instead build suitable eviction sets for XLATE
attacks. We further show how XLATE can blindly build
eviction sets for security domains to which it does not
have access. Finally, in Section 6.3, we identify different
sources of noise and explain how to mount a noise-free
XLATE attack.
6.1 Reverse Engineering the MMU
The MMU is a hardware component available in many
modern processor architectures, that is responsible for
942    27th USENIX Security Symposium
USENIX Association
081624324048566472808896104112120128CacheSets0481216CacheWaysNon-SecureSecureLast-LevelCache0816243240485664CacheSets0481216CacheWaysPageColors0816243240485664CacheSets0481216CacheWaysPageTableColorsPML4PTE #300PML3PTE #100PML2PTE #400PML1PTE #2000x9619320c8000100101100001100100110010000011001000CR3partially resolved virtual addresses instead. With trans-
lation caches, the MMU can look up the virtual address
and select the entry with the longest matching preﬁx to
skip the upper levels of the page table hierarchy. Figure 3
visualizes how different caches interact when the MMU
translates a virtual address.
We rely on the fact that the MMU’s page table walk
ends up in the target processor’s data caches to learn
about translation caches. More speciﬁcally, the TLB can
only host a limited number of virtual address transla-
tions. Therefore, if we access at least that many pages,
we can evict the TLB, and consequently enforce the
MMU to perform a page table walk. We now ﬁx our tar-
get address in such a way that we know the cache sets that
host the PTEs for that virtual address. We then mount an
EVICT + TIME attack for each of the page table levels,
where we evict the TLB and the cache set that we ex-
pect to host the PTE for that level. Then we measure
the time it takes for the MMU to resolve the address to
determine if the page table walk loads the PTE in the ex-
pected cache set. If the translation caches are not ﬂushed,
then the page table walk skips part of the page table hi-
erarchy and simply starts from a lower level page table.
As a result the page table walk does not load the PTEs
for the higher level page tables to their respective cache
sets. Therefore, we now have a basic mechanism to de-
tect whether we properly ﬂushed the translations caches.
While the sizes of the TLB and the CPU caches are al-
ready known, the sizes of the translation caches are not.
We can use the aforementioned mechanism to reverse
engineer the size of translation caches. For instance,
a second-level page table maps 2 MiB worth of virtual
memory. Thus, if we access any page within that 2 MiB
region, the page table walk loads the corresponding PTE
pointing to the second-level page table to the translation
cache. Similar to TLBs, the number of entries in such
a translation cache is limited. Therefore, if we access at
least that many 2 MiB regions, we can ﬂush the corre-
sponding translation cache. We use the aforementioned
algorithm to tell us whether we the amount of 2 MiB re-
gions is sufﬁcient to ﬂush the translation cache, and thus
we know the size of the corresponding translation cache.
Finally, we proceed using this algorithm to ﬁnd the sizes
of the translation caches for all the page table levels.
6.2 Building Eviction Sets with the MMU
To build eviction sets for XLATE attacks, we draw from
traditional eviction set building algorithms described in
the literature for PRIME + PROBE (and derivatives) as
shown in Algorithm 1. We ﬁrst identify the page col-
ors available to our security domain by building eviction
sets using PRIME + PROBE. More speciﬁcally, we ﬁrst
ﬁnd eviction sets for the available subset of page colors:
Figure 3: A generic implementation of an MMU and all the
components involved to translate a virtual address into a phys-
ical address.
the translation of virtual addresses to their correspond-
ing physical address. These translations are stored in
page tables–a directed tree of multiple levels, each of
which is indexed by part of the virtual address to select
the next level page tables, or at the leaves, the physi-
cal page. Hence, every virtual address uniquely selects
a path from the root of this tree to the leaf to ﬁnd the
corresponding physical address. Figure 2 shows a more
concrete example of how the MMU performs virtual ad-
dress translation on x86_64. First, the MMU reads the
CR3 register to ﬁnd the physical address of the top-level
page table. Then, the top nine bits of the virtual address
index into this page table to select the page table entry
(PTE). This PTE contains a reference to the next-level
page table, which the next nine bits of the virtual address
index to select the PTE. By repeating this operation, the
MMU eventually ﬁnds the corresponding physical page
for 0x644b321f4000 at the lowest-level page table.
The performance of memory accesses improves
greatly if the MMU can avoid having to resolve a vir-
tual address that it already resolved recently. Hence, the
MMU stores resolved address mappings in a fast Trans-
lation Lookaside Buffer (TLB). To further improve the
performance of a TLB miss, the PTEs for the differ-
ent page table levels are not only stored in the CPU
caches, but modern processors also store these in page
table caches or translation caches [1]. While page table
caches simply store PTEs together with their correspond-
ing physical address and offset, translation caches store
USENIX Association
27th USENIX Security Symposium    943
Algorithm 1: Algorithm to build eviction sets dynami-
cally for either a given or a randomly chosen target.
Input: a set of potentially conﬂicting cache lines pool, all
set-aligned, and an optional target to ﬁnd an
eviction set for.
Output: the target and the eviction set for that target
working set ← {};
if target is not set then
target ← choose(pool);
remove(pool, target);
end
while pool is not empty do
repeat
member ← choose(pool);
remove(pool, member);
append(working set, member);
until evicts(working set, target);
foreach member in working set do
remove(working set, member);
if evicts(working set, target) then
append(pool, member);
append(working set, member);
else
end
end
foreach member in pool do
if evicts(working set, member) then
remove(pool, member);
end
end
end
return target, working set
1(cid:13) We allocate a sufﬁciently large pool of pages to build
2(cid:13) We pick random pages from this
these eviction sets.
pool of pages and add them to the eviction set until it is
able to evict one of the remaining pages in the pool, the
3(cid:13) We optimize the eviction
target of our eviction set.
set by removing pages that do not speed up the access to
the target after accessing the eviction set. Upon ﬁnding
the eviction set, the other pages in the pool are colored
using this eviction set and we repeat the process until all
the pages have been colored, yielding eviction sets for all
the available colors in our security domain. If the amount
of page colors is restricted, this results in fewer eviction
sets, whereas if the amount of cache ways is restricted,
these eviction sets consist of fewer entries.
Using page tables Now we retroﬁt this algorithm to
use the MMU to evict a given page, the target of our
choice. More speciﬁcally, we build eviction sets of page
tables that evict the target page.
Instead of allocating
pages, we will map the same shared page to multiple lo-
cations to allocate unique page tables. Then we apply
1(cid:13) We allocate a sufﬁ-
the same algorithm as before:
ciently large pool of page tables to build these eviction
2(cid:13) We pick random page tables (by selecting their
sets.
corresponding virtual addresses) from this pool of page
tables and add them to the eviction set until it is able to
evict the target page. 3(cid:13) We optimize the eviction set by
removing page tables that do not speed up the access to
the target after accessing the eviction set. Upon ﬁnding
the eviction set, the other page tables in the pool are col-
ored using this eviction set. We can then repeat this for
other pages until all the page tables have been colored,
yielding eviction sets for all the available colors in our
security domain.
Defeating way partitioning To defeat software-based
cache defenses using way partitioning, we now try to ﬁnd
eviction sets that cover the whole cache set. First, we
build eviction set of normal pages to ﬁnd all the available
page colors. Then for each of the eviction sets, we build
an eviction set of page tables that evicts any page in the
eviction set. Since these eviction sets of page tables map
to the full cache sets, they bypass way partitioning.
Defeating set partitioning
In case of StealthMem and
cache defenses using set partitioning, or more speciﬁ-
cally, page coloring, we end up with a pool of the re-
maining page tables that could not be colored. To ﬁnd the
remaining eviction sets, we apply the same algorithm as
before to the remaining page tables. This time, however,
we choose a random page table from the pool of page ta-
bles to use as the target for our algorithm. Ultimately, we
end up with the eviction sets for all the remaining page
colors. Therefore we are able to bypass cache defenses
that use page coloring.
6.3 Minimizing Noise in XLATE Attacks
To mount XLATE attacks, we are interested in ﬁnding an
eviction set for our target, of which the PTEs for each
of the pages in the eviction set map to the same cache
set as our target. However, as we are trying to perform
an indirect cache attack from the MMU, there are vari-
ous source of noise that potentially inﬂuence our attack.
To minimize the noise for XLATE attacks, we rely on
the following: (1) translation caches, (2) pointer chasing,
(3) re-using physical pages, (4) and transactions.
Translation caches Now that we have reverse engi-
neered the properties of the MMU, we can control which
PTEs hit the LLC when performing a page table walk.
To improve the performance and to reduce the amount
of noise, we are only interested in loading the page ta-
bles closer to the leaves into the LLC. Thus, we want
to only ﬂush the TLB, while we preserve the translation
caches. Algorithm 2 extends PRIME + PROBE to ﬂush
944    27th USENIX Security Symposium
USENIX Association
Algorithm 2: XLATE + PROBE method for determining
whether an eviction sets evicts a given cache line.
Input: the eviction set eviction set and the target target.
Output: true if the eviction set evicted the target, false
timings ← {};
repeat
otherwise.
access(target);
map(access, TLB set);
map(access, eviction set);
map(access, reverse(eviction set));
map(access, eviction set);
map(access, reverse(eviction set));
append(timings, time(access(target)));
until length(timings) = 16;
return true if median(timings) ≥ threshold else false
the TLB using the technique described in Section 6.1.
To preserve the translation caches, we reduce the num-
ber of 2 MiB region accesses by keeping the pages in the
TLB eviction set (i.e., TLBSet) sequential. This guaran-
tees that an eviction set of PTEs can evict the target from
the LLC.
Pointer chasing Hardware prefetchers in modern pro-
cessors often try to predict the access pattern of programs
to preload data into the cache ahead of time. To pre-
vent prefetching from introducing noise, the eviction set
is either shufﬂed before each call to XLATE + PROBE
or a technique called pointer chasing is used to tra-
verse the eviction set, where we build an intrusive linked
list within the cache line of each page. Because the
prefetcher repeatedly mispredicts the next cache line to
load, it is disabled completely not to hamper the perfor-
mance. To defeat adaptive cache replacement policies
that learn from cache line re-use, we access the eviction
set back and forth twice as shown in Algorithm 2.
Re-using physical pages To perform a page table
walk, we have to perform a memory access. Unfortu-
nately, the page and its corresponding page table pages
could have different colors. Therefore, we want to craft
our XLATE attack in a way that only page table can evict
the target page. For this reason we propose three dif-
ferent techniques to make sure that only the cache lines
storing the PTEs are able to evict our target’s cache line.
First, we can exploit page coloring to ensure that the
pages pointed to by page tables in the eviction set do not
share the same page color as the target page. This way,
only the page table pages can evict the target page. Sec-
ond, by carefully selecting the virtual addresses of the
pages in our eviction set, we can ensure that the cache
lines of these pages do not align with the cache line of
the target page. Therefore, by only aligning the cache
line of the corresponding page tables, we can ensure that
only the page tables can inﬂuence the target page. Third,
we allocate a single page of shared memory and map it
to different locations in order to allocate many different
page tables that point to the exact same physical page.
Since we only have one physical page mapped to mul-
tiple locations, only the page tables are able to evict the
cache line of the target page. In our implementation, we
use the third technique, as it shows the best results.
Transactions
In XLATE + ABORT, we leverage Intel
TSX in a similar fashion to PRIME + ABORT. We ob-
serve that page table walks performed by the MMU dur-
ing a hardware transaction lead to an increase in conﬂict
events when the victim is also using the same cache set.
Therefore, we can simply measure the amount of conﬂict
events and check whether this exceeds a certain thresh-
old.
7 Evaluation
We evaluate XLATE on a workstation featuring an In-
tel Core i7-6700K @ 4.00GHz (Skylake) and 16 GB of
RAM. We also consider other evaluation platforms for
reverse engineering purposes. To compare our XLATE
attack variants against all the state-of-the-art cache at-
tacks, we also implemented FLUSH + RELOAD, FLUSH
+ FLUSH, EVICT + TIME, PRIME + PROBE, and PRIME
+ ABORT and evaluated them on the same evaluation
platform. We provide representative results from these
attacks in this section and refer the interested reader to
more extended results in Appendix A.
Our evaluation answers four key questions: (i) Reverse
engineering: Can we effectively reverse engineer trans-
lation caches on commodity microarchitectures to mount
practical XLATE attacks? (ii) Reliability: How reliable
are XLATE channels compared to state-of-the-art cache
attacks? (iii) Effectiveness: How effective are XLATE at-
tacks in leaking secrets, cryptographic keys in particular,
in real-world application scenarios? (iv) Cache defenses:
Can XLATE attacks successfully bypass state-of-the-art
software-based cache defenses?
7.1 Reverse Engineering
Table 3 presents our reverse engineering results for the
translation caches of 26 different contemporary microar-