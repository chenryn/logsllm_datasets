(pk, sk) ← Setup(1λ)
U, CU ← []
state ← AOreg,Ocorr
L ← []
b ← AOc2 (state, pk)
if b (cid:60) L ∧
∃(id, credid) ∈ U\CU.
opencred(b, sk, U ) = credid then
return 1
Figure 7: Credential non-malleability
adversary A,
P(cid:104)
ExpNMA (λ) = 1(cid:105) is negligible
where ExpNMA (λ) is defined on Figure 7. For example, Belenios and
Civitas have non-malleable credentials.
Theorem 4.4 (Privacy implies individual verifiability). Let
V be an id-based, strongly correct, voting scheme that has the piecewise
tally property. If V is private, then V is individually verifiable.
Similarly, let V be a cred-based voting scheme that has the piecewise
tally property and non-malleable credentials. If V is private, then V
is individually verifiable.
The proof of this theorem is inspired by the same intuition as in
the symbolic case: if an attacker manages to break verifiability, that
is, to obtain that not all votes from the honest voters are counted
correctly, then there also exists an attack against privacy. Indeed,
consider a scenario with additional, new voters, whose votes should
compensate those cast by the initial voters. By performing the attack
on verifiability for the initial voters, the attacker reaches a state
where, in the result of the election, they are no longer compensated
by the new votes. This allows the attacker to break privacy.
More precisely, the general idea of the proof is as follows. Con-
sider an attacker A that breaks individual verifiability, i.e. wins
the game Expverif with non negligible probability. We construct
an attacker B that breaks privacy, i.e. wins Exppriv, β . B starts by
registering, and corrupting, the same voters as A, using oracles
Oreg and Ocorr. Let id1, . . . , idn be this first set of voters. B then
1, . . . , id′
registers another set of n voters id′
are fresh
identities, that A does not use.
B then simulates A, using the oracle Op
to simulate A’s calls
to Ov
vote(id, v), B calls the oracle
vote
vote(id, v, vblank), where vblank is a neutral vote. Once B is done
Op
simulating A, it triggers the new voters id′
to vote, by calling
i
i , vblank, vi), where vi is the (last) vote cast by
the oracle Op
idi. The vote of each id′
compensates the vote of idi, so that the
condition ρ(V0) = ρ(V1) from Exppriv holds. B then obtains the
result r of the election, which is equal to r1 ∗r2, where r1 is the tally
of the ballots cast by A, and r2 the tally of the additional ballots
cast by B. Then:
. Specifically, when A calls Ov
n, where the id′
vote(id′
vote
i
i
1
(pk)
Expdis, βA (λ)
(pk, sk) ← Setup(1λ)
U, CU ← []
state1 ← AOreg,Ocorr
V0, V1 ← []
state2, BB ← AOd
if ρ(V0) = ρ(V1) then
r ← Tally(BB, sk, U)
β′ ← A3(state2, pk, r)
return β′
vote
(state1, pk)
2
vote(id, v0, v1)
Od
if (id, ∗) ∈ U\CU then
b ← Vote(id, credid, pk, vβ)
V0 ← V′
V1 ← V′
return b
0∥(id, v0)
1∥(id, v1)
0 (resp. V′
1)
where (id, credid) ∈ U
and V′
is obtained from V0 (resp. V1)
by removing all instances
of (id, ∗)
Figure 8: Privacy against a dishonest board (PrivDis-Naive)
• if β = 0: then all the votes cast by the id′
were vblank, and the
i
result is thus r = r1. Since A breaks individual verifiability,
r1 does not contain the honest votes, i.e., for all multiset Vc
of votes, r (cid:44) ρ(v1, . . . , vn) ∗ ρ(Vc).
• if β = 1 however, the votes cast by the id′
were the vi, and
i
the partial tally r2 is therefore r2 = ρ(v1, . . . , vn). Hence, the
result r does contain the honest votes.
Therefore, by observing whether the final result of the election
contains the honest votes, B is able to guess β, and wins Exppriv.
5 PRIVACY WITH A DISHONEST BOARD
Our main theorem states that privacy implies individual verifiability.
However, the privacy definition introduced by Benaloh assumes
an honest ballot box, as most existing privacy definitions of the
literature [7]. Therefore, our main theorem shows that whenever a
voting scheme is private w.r.t. an honest ballot box, then it is also
individually verifiable w.r.t. an honest ballot box, which is of course
a rather weak property. However, intuitively, our proof technique
does not rely on the trust assumptions.
As pointed out in introduction, extending cryptographic pri-
vacy definitions to a dishonest ballot box is difficult. Consider the
natural extension of privacy as displayed in Figure 8: the game
is the same than Exppriv, βA (λ) except that the adversary arbitrarily
controls the ballot box. Unfortunately, an adversary can always
win this new game. Indeed, he may simply query Od
vote(id1, 0, 1)
and Od
vote(id2, 1, 0), yielding respectively ballots bid1 and bid2. Then
the adversary choses BB = bid1. The tally will return β, hence the
adversary wins. This corresponds to the fact that an adversary may
always isolate a voter and break her privacy.
5.1 Privacy with careful voters
To solve this issue, we choose another approach, which consists in
explicitly modelling the verification steps made by voters: the tally
will be performed only if honest voters have successfully run their
checks (e.g. checking that their ballot belongs to the bulletin board).
Therefore, we extend the privacy game as follows. The adversary
arbitrarily controls the ballot box and may request honest voters to
vote through Op,c
vote(id, v0, v1) as before. Note that there is no need
for the Ocast oracle since the adversary may add directly his own
10
1
A
(pk)
Exppriv−careful, β
(λ)
(pk, sk) ← Setup(1λ)
U, CU ← []
state1 ← AOreg,Ocorr
V0, V1, Lid (for all id in U) ← []
state2, BB ← AOp,c
(state1, pk)
H ← []
state3 ← AOhappyBB
if ∀id . (id, ∗) ∈ V0, V1 ⇒ id ∈ H
and ρ(V0) = ρ(V1) then
r ← Tally(BB, sk, U)
(state2)
vote
2
3
vote(id, v0, v1)
Op,c
if (id, ∗) ∈ U\CU then
b ← Vote(id, credid, pk, vβ)
V0 ← V′
0∥(id, v0)
V1 ← V′
1∥(id, v1)
Lid ← Lid ∥(b, vβ)
return b
1) is obtained
0 (resp. V′
where (id, credid) ∈ U
and V′
from V0 (resp. V1) by
removing all instances
of (id, ∗)
else
r ← ⊥
β′ ← A4(state3, pk, r)
return β′
(id)
OhappyBB
if (id, credid) ∈ U\CU then
if VerifVoter(id, credid, Lid, BB)
then H ← H∥id
Figure 9: Privacy game against a dishonest board with care-
ful voters (Priv-careful)
ballots in the ballot box. He triggers voters to run their verification
tests through the oracle OhappyBB
(id). To run her verification test
(using algorithm VerifVoter), the voter has access to the ballot box
BB forged by the adversary as well as her local state Lid that contains
in particular her previously generated ballots. The tally is performed
only if all honest voters have successfully performed their test and
if, as previously, the set V0 of left votes v0 yields the same result than
the set V1 of right votes v1. Formally, privacy with careful voters is
defined through the game Exppriv−careful displayed on Figure 9.
Definition 5.1 (Privacy with careful voters). A voting system is
private against a dishonest board with careful voters if for any adver-
sary A,
(cid:12)(cid:12)(cid:12)P(cid:104)
Exppriv−careful,0
A
is negligible.
(λ) = 1(cid:105) − P(cid:104)
(λ) = 1(cid:105)(cid:12)(cid:12)(cid:12)
Exppriv−careful,1
A
While this definition models a dishonest ballot box, it implicitly
assumes that all voters see the same (possibly dishonest) ballot
box. This is a very common assumption in voting, that needs to be
achieved by external means.
Similarly, we extend individual verifiability to individual verifia-
bility against a dishonest board as expected, assuming that the tally
is performed only if all honest voters have successfully performed
their test. The formal definition of individual verifiability against a
dishonest board can be found in appendix.
5.2 Privacy implies individual verifiability
against a dishonest box too
We need to assume that the verification test run by honest voters
(VerifVoter) is consistent with how the voter voted. Namely, if the
vote(id, v0, v1)
Obs
if (id, ∗) ∈ U\CU then
b ← Vote(id, credid, pk, vβ)
L ← L∥(b, v0, v1)
return b
where (id, credid) ∈ U
1
(pk)
ExpBS, βA (λ)
(pk, sk) ← Setup(1λ)
U, CU ← []
state1 ← AOreg,Ocorr
L ← []
state2, BB ← AObs
2
if ∀v .
|{b |b ∈ BB ∧ ∃v′
|{b |b ∈ BB ∧ ∃v′
then
r ← Tally(BB, sk, U)
β′ ← A3(state2, pk, r)
return β′
vote
(state1, pk)
. (b, v, v′) ∈ L}| =
. (b, v′
, v) ∈ L}|
Figure 10: PrivacyBS [9]
voter’s intended ballot is the one that is selected from the board
by the revote policy (e.g. appears last w.r.t. this voter), then this
voter must be satisfied with the board (that is, VerifVoter passes).
Conversely, if the test VerifVoter fails for voter id then adding
ballots unrelated to id (or her credential) will not change this fact
(VerifVoter will still fail). These assumptions are formally stated in
appendix.
Theorem 5.2 (Privacy implies individual verifiability against
a dishonest board). Let V be an id-based, strongly correct voting
scheme that has the piecewise tally property. If V is private against a
dishonest board with careful voters, then V is individually verifiable
against a dishonest board with careful voters.