We answer the open question of [2] for outsourcing low-
degree multivariate polynomials, which may have many in-
teresting applications (see Section I-B). We propose a new
multi-server verifiable computation (MSVC) model. In our
model, a k-server verifiable computation is a protocol between
a client and k servers. In such a protocol, the client distributes
both a share of the function F and a share of the input x
to each server; each server locally computes a partial result;
t-private (secure) k-server VC schemes for degree-d polynomials
TABLE I
k
d(t + 1) + 1
(d + 1)t + 1
dt + 1
d(t + 1) + 1
(d + 1)t + 1
t-security
i.t.
i.t.
i.t.
DHI
DLog
Π1
Π2
Π3
Π4
Π5
t-privacy
i.t.
i.t.
i.t.
i.t.
i.t.
verification
private
private
private
public
public
delegation
public
public
public
public
public
and finally the client performs verification and reconstructs
F (x) from all servers’ partial results. An MSVC scheme is
t-secure if no t servers can persuade the client to output
a wrong result. Both information-theoretic (i.t.) security and
computational security will be considered. An MSVC scheme
is t-private if no t servers can distinguish between two inputs.
We shall consider information-theoretic privacy. We construct
five schemes (see Table I) for securely outsourcing P(q, m, d),
the set of polynomials that have coefficients in a finite field
Fq, m variables, and total degree ≤ d.
Input privacy & security. The client’s input x is information-
theoretically t-private in all schemes. The schemes Π1, Π2, and
Π3 also have information-theoretic t-security; Π4 and Π5 are
computationally t-secure under the DHI assumption [30] and
the DLog assumption, respectively.
Delegatability. In all schemes, any client can prepare its input
x, verify the servers’ partial results and reconstruct F (x), i.e.,
all schemes are publicly delegatable [80].
Verifiability. The schemes Π1, Π2 and Π3 are privately verifi-
able such that only the client that prepared x is able to verify
the servers’ partial results. Π4 and Π5 are publicly verifiable
such that any third party can verify.
Outsourceability. The client in Π1 and Π4 has to perform an
offline preprocessing of F . We follow the amortized model of
[51], [79], [80] and call an MSVC outsourceable if the client’s
online computation is substantially faster than the native
computation of F (x). Our schemes are all outsourceable.
Server’s computation. In all schemes, the computation of
each server is very efficient and roughly equivalent to evalu-
ating the outsourced function F once.
Number of servers. To outsource degree-d polynomials with
t-privacy, Π3 requires dt + 1 servers. This number of servers
is optimal/least provided that information-theoretic t-privacy
is needed and the servers do not communicate. In fact, such
MSVC implies a t-private k-player d-multiplicative secret
sharing [12], which exists if and only if k > dt.
Limitations. The number of servers required by our schemes
is linear in the degree d of the outsourced polynomial. A large
d may result in a large number of servers. Therefore, although
our schemes can handle polynomials of any degree, for sake of
practicality they are more suitable for outsourcing low-degree
polynomials, which have interesting applications.
B. Applications
Curve fitting on private data points. Curve fitting [5] is
the process of constructing a curve or function y = f (x)
that has the best fit to a set of data points {(xi, yi)}m
i=1.
Depending on whether the data points exhibit a significant
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:14:01 UTC from IEEE Xplore.  Restrictions apply. 
2597
degree of error, curve fitting may be realized with least
squares regression [34] or interpolation [34]. In least squares
regression, to fit a degree-d polynomial, one has to evaluate
polynomials in {(xi, yi)}m
i=1, whose degrees are determined
by d. Small values of d are usually preferred and approached
first [58]. Thus, low-degree polynomial evaluations will be
frequently used. The same situation occurs in multiple linear
regression and interpolation. When the data points contain
highly sensitive personal information [65], [77], our schemes
provide solutions that are both private and secure.
Private information retrieval. In a t-private k-server PIR,
each server stores a database F = (F1, F2, . . . , Fn); by
sending a query to each server and learn the servers’ answers,
the client can reconstruct a block Fi of its choice but any
t servers cannot learn i. The t-private t-Byzantine robust k-
server PIR schemes of [15], [73] allow the client to reconstruct
correctly, even if t servers respond incorrectly. They also
enable the identification of cheating servers. For general t, the
best such schemes to date have communication complexity
O(n1/(⌊(2k−1)/t⌋−4)). Identification of cheating servers may
be overly strong in many scenarios such as private media
browsing [62], where it suffices for the client to detect the
existence of cheating. Our MSVC gives t-private k-server
PIR with private (resp. public) detection of cheating and
better communication complexity of O(n1/⌊(2k−1)/t⌋) (resp.
⌋ − 1}).
O(n1/ν(k,t)), where ν(k, t) = max{⌊ 2k−1
Comparing with PIR for honest servers, our schemes incur
limited extra cost.
Privacy preserving statics and GAS. Computations of many
meaningful statistics such as average, variance, covariance,
RMS, correlation coefficient and many more, and the Genetic
Risk Scores in GAS (Genetic Association Studies) [10] heavily
depend on the low-degree multivariate polynomial evaluations.
Our schemes provide secure outsourcing solutions that pre-
serve the privacy of sensitive data.
C. Efficiency
t+1 ⌋,⌊ 2k−1
t
is the total
in MSVC. The time cost
Our schemes are all outsourceable in the amortized model
of [51], [79], [80]. Nevertheless, we focus on the more realistic
metrics of performance such as the client’s time cost and
monetary cost
time
spent by the client in preparing input, waiting for the latest
answer from a server, and verifying the results. The monetary
cost is measured with the equivalent local computing cost of
the input preparation, the result verification, and all servers’
computations. We test the proposed schemes by evaluating
polynomials of degree 2, 4, 8, 16, 32 and 64. The experimental
results show that the ratio of the client’s time cost to the time
of locally computing F (x) tends to the ratio of the computing
speed of the client to that of each server; and the ratio of the
client’s monetary cost to the cost of locally computing F (x)
tends to a multiple of the previous ratio, where the multiple
is roughly equal to the number of servers. In the schemes
with preprocessing (i.e., Π1 and Π4), the client will benefit
only if the same function is evaluated multiple times. In our
experiments for d = 2, this number is ≤ 20.
D. Our Techniques
t-Privacy. In our constructions, t-privacy is achieved by secret-
sharing the input x ∈ Fm
q among all servers using Shamir’s
threshold scheme [87] for vectors. The client chooses a random
degree-t curve c(u) that passes through (0, x) and distributes
k > dt curve points to k servers; the k servers provide k eval-
uations of F ; finally the client interpolates ϕ(u) = F (c(u))
and learns F (x) = ϕ(0).
t-Security. The verification techniques in five schemes are
different. In Π1, the client picks a random line ℓ(u) and
makes both the line and the restriction of F on the line (i.e.,
f (u) = F (ℓ(u))) public. It also increases the degree of c(u)
by 1 such that c(u) intersects ℓ(u) at a random point. With this
choice, k = d(t + 1) + 1 evaluations of F suffice to recover
ϕ(u). For verifications, it evaluates F at the random point in
two different ways: one is with ϕ(u) and the other is with
f (u). It accepts only if two results agree. The main idea is
leaving the heavy computation of f (u) to the offline phase
such that the client is able to quickly retrieve the value for
verification in the online phase.
In Π2, the client additionally secret-shares a random field
element α among the servers, by using a degree-t univariate
polynomial b(u). Each server is giving a point on c(u) and a
share of α, which is an evaluation of b(u). The client offloads
the computation of F (x) and αF (x) to k = (d + 1)t + 1
servers. This is done by every server providing both a share
of F (x) and a share of αF (x) such that the client is able to
recover ϕ(u) = F (c(u)) and ψ(u) = F (c(u))b(u). If the free
terms of both polynomials differ by a factor α, then the client
believes that ϕ(u) is correct. Without knowing α, any t servers
can cheat successfully only with a very small probability.
In Π3, the client will choose c(u) such that it passes through
through (α, x) for a random field element α. It makes a
critical change by choosing both the coefficients of c(u) and
α from an extension field of Fq such as Fq2, instead of Fq.
Then any k = dt + 1 evaluations of F suffice to recover
ϕ(u) = F (c(u)) and give F (x) = ϕ(α). Without knowing
α, the wrong partial results provided by any t servers will
result in the client reconstructing a value in Fq2 \ Fq with
overwhelming probability and be rejected by the client.
Π4 is obtained from Π1 by converting the private ver-
ification to public. In Π1, the client has to memorize the
locations where c(u) and ℓ(u) intersect. This leads to a private
verification that compares the evaluations of two polynomials,
i.e., ϕ(u) and f (u). Given a cyclic group G = ⟨g⟩ of order q,
we publish the exponentiation of two locations and thus move
the comparison to the exponent of g. We prove the scheme is
secure under the DHI assumption in G.
The scheme Π5 is obtained from Π2 with a public key gα.
The verification is moved to the exponent of g as checking
whether (gα)F (x) = gαF (x). We prove the scheme is secure
under the DLog assumption in G.
E. Related Work
In the security community, correctness of outsourced com-
putations may be verified with replication, audit, or secure
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:14:01 UTC from IEEE Xplore.  Restrictions apply. 
3598
co-processors. The replication based solutions [3], [29], [63],
[68] may be not viable and provide no input privacy. The
audit-based solutions [16], [78], [82] require recalculation of
the server’s work or knowledge of the server’s hardware. The
secure co-processors [90], [95] are either poor in physical tam-
per resistance or expensive. In the cryptographic community,
expensive cryptographic operations had been outsourced to
semi-trusted devices [35].
Interactive proofs. Interactive proofs [6], [56] allow a power-
ful prover to convince a weak verifier of the truth of statements
that could be too complex to be computed by the verifier. The
statement may take the form F (x) = y. Early research in this
field focused on how to use limited resources to verify complex
statements. The IP=PSPACE theorem of [75], [88] shows that
polynomial space computations is verifiable in polynomial
time. It was scaled down in [50] for a superpolynomial time
prover. For NC circuits, Goldwasser et al. [57] proposed
interactive proofs where the prover runs in polynomial time
and the verifier runs in nearly linear time. The protocol of
[57] has been refined and implemented in [39], [91], [93].
For NC circuits, these systems do not require preprocessing,
have a highly efficient verifier, achieve low overhead for the
prover, and have information-theoretic security. However, they
are interactive and leave the client’s input unprotected.
Interactive arguments. The MIP=NEXP theorem of [8]
constructed multi-prover interactive proofs with a polynomial
time prover and a polylogarithmic time verifier, and led to
the notion of probabilistically checkable proofs (PCP) [7].
Although a few locations of PCP suffice for verification,
PCP is too long and infeasible for the verifier to process.
Kilian [69], [70] suggested the prover send a Merkle tree
based commitment of PCP and then interactively open the
verifier-requested locations. Kilian’s idea results in interactive
arguments [24] where the soundness holds for computationally
bound provers. Ishai et al. [67] simplified the PCP by using a
homomorphic encryption based technique. The simplified PCP
was refined and implemented in [25], [84]–[86]. These systems
can outsource generic functions, require a preprocessing for
the verifier and have high prover overhead. These interactive
systems provide no input privacy.
Succinct non-interactive arguments of knowledge. The
non-interactive argument system of Micali [76] removed the
interactions in [69], [70] by applying a random oracle to
the commitment and then using the output
to choose the
locations that will be opened. More efficient non-interactive
argument systems [19], [52], [60], [61], [79] were based on
the CRS model and called succinct non-interactive arguments
(SNARGs). SNARGs were then strengthened to succinct non-
interactive arguments of knowledge (SNARKs) [19], [45],
[52], [61], [79] such that the prover producing a convinc-
ing proof must “know” a witness. Recently many efficient