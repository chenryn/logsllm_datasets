in detection systems can provide Malicious examples at low cost, and random
sampling can provide Benign examples. In both cases, the initial labelled dataset
does not contain all the malicious families we want to detect, and it is not
representative of the data in the deployment environment. ILAB enriches the
initial labelled dataset across the iterations to make it representative of the
environment where the detection system is deployed.
The iterations are performed until the annotation budget B has been spent.
At each iteration, buncertain annotation queries are generated with uncertainty
126
A. Beaugnon et al.
sampling to improve the detection model and bfamilies = b − buncertain instances
are queried for annotation with rare category detection to avoid sampling bias
(see Fig. 3).
4.1 Uncertainty Sampling
A binary probabilistic detection model M is learned from the annotated
instances in DL. We use a discriminant linear model, i.e. logistic regression [10].
Linear models are highly valued by computer security experts who do not trust
black box detection models [27]. These detection models can be interpreted
because the coeﬃcients associated with each feature represent their contribution
to the detection model. Besides, discriminant models are known to be better
than generative ones in active learning settings [47]. Finally, learning a logistic
regression model and applying it to predict the label of new instances is fast
so the expert does not wait a long time between iterations. Our approach is
generic, the expert can choose to use another model class particularly suited for
her application.
The rare malicious families are often the most interesting in intrusion detec-
tion, hence the impact of the training instances from rare families is increased.
The logistic regression model is learned with sample weights inverse to the pro-
portion of the family in the training dataset:
β(x, y, z) =
|DL|
|{(x(cid:4), y(cid:4), z(cid:4)) ∈ DL | y(cid:4) = y ∧ z(cid:4) = z}| .
The weights are capped, ˆβ = min(β, 100), to avoid giving too much weight to
very rare families. Learning the logistic regression detection model with these
weights is crucial to ensure a good detection of the rare malicious families.
The model M is used to compute the probability p(x) that an unlabelled
instance x ∈ DU is Malicious according to M:
∀x ∈ DU , p(x) = PM(y = Malicious | x).
Annotation Queries. The buncertain unlabelled instances which are the closest to
the decision boundary of M are annotated by the expert:
|p(x) − 1/2|.
arg min
x∈DU
(1)
The detection model is uncertain about the label of these instances, that is why
their annotations allow to improve the detection model. This step corresponds
to uncertainty sampling [20], a classical active learning method applied in [1].
Uncertainty sampling suﬀers, however, from sampling bias [29]. We also perform
rare category detection to foster the discovery of yet unknown families.
ILAB: An Interactive Labelling Strategy for Intrusion Detection
127
4.2 Rare Category Detection
Rare category detection is applied on the instances that are more likely to be
Malicious and Benign (according to the detection model M) separately. Not all
families are present in the initial labelled dataset and rare category detection [26]
fosters the discovery of yet unknown families to avoid sampling bias. One might
think that we could run rare category detection only on the malicious instances
since it is the class of interest in intrusion detection. However, a whole malicious
family may be on the wrong side of the decision boundary (see the family M1
in Fig. 2), and thus, running rare category detection on the predicted benign
instances is necessary. Hereafter, we only detail the rare category detection run
on the Malicious predictions since the analysis of the Benign ones is performed
similarly.
instances whose predicted label by M is
Malicious and DMalicious
be the set of malicious instances already annotated
by the expert. First, a multi-class logistic regression model is learned from the
to predict the family of the instances in DMalicious
families speciﬁed in DMalicious
.
Let Cf be the set of instances from DMalicious
whose family (anno-
tated or predicted) is f. Each family f is modelled with a Gaussian distribution
N (μf , Σf ) depicted by an ellipsoid in Fig. 3. The mean μf and the diagonal
covariance matrix Σf are learned with Gaussian Naive Bayes [10]. We denote by
pN (μf ,Σf )(x) the probability that x follows the Gaussian distribution N (μf , Σf ).
be the set of
L
Let DMalicious
∪ DMalicious
L
L
U
U
U
Annotation Queries. The family annotation budget bfamilies is evenly distributed
among the diﬀerent families. We now explain which unlabelled instances are
queried for annotation from each family.
First, ILAB asks the expert to annotate instances that are likely to belong
to a yet unknown family to avoid sampling bias. These instances are located at
the edge of the ellipsoid, they have a low likelihood of belonging to the family
f [26,40]:
arg min
x∈Cf\DMalicious
L
pN (μf ,Σf )(x).
(2)
Then, ILAB queries representative examples of each family for annotation.
These instances are close to the centre of the ellipsoid, they have a high likelihood
of belonging to the family f:
arg max
x∈Cf\DMalicious
L
pN (μf ,Σf )(x).
(3)
Half the budget is allocated to low likelihood instances, and the other half
to high likelihood instances. Low likelihood instances are likely to belong to yet
unknown families that is why these annotation queries foster the discovery of
new families. They are, however, more likely to be outliers that may impair
the detection model performance. ILAB also asks the expert to annotate high
likelihood instances to get more representative examples of the families in the
labelled dataset for a better generalization of the detection model.
128
A. Beaugnon et al.
5 Comparison with State of the Art Labelling Strategies
5.1 Datasets
Labelling strategies are generic methods that can be applied to any detection
problem once the features have been extracted. We consider a system and a
network detection problem: (1) detection of malicious PDF ﬁles with the dataset
Contagio1, and (2) network intrusion detection with the dataset NSL-KDD2.
These datasets cannot be used to train a model intended for production as they
are non-representative of real-world data. However, our comparisons are relevant
as we are not comparing attack detection models but labelling strategies in order
to train attack detection models on new problems.
Contagio is a public dataset composed of 11,101 malicious and 9,000 benign
PDF ﬁles. We transform each PDF ﬁle into 113 numerical features similar to the
ones proposed by Smutz and Stavrou [35,36].
NSL-KDD contains 58,630 malicious and 67,343 benign instances. Each
instance represents a connection on a network and is described by 7 cate-
gorical features and 34 numerical features. The 7 categorical features (e.g.
protocol type with the possible values tcp, udp or icmp) are encoded into
several binary features corresponding to each value (e.g. tcp → [1, 0, 0], udp →
[0, 1, 0], icmp → [0, 0, 1]). We end up with 122 features.
Table 1. Description of the public datasets
#instances #features #malicious families #benign families
Dataset
Contagio 10% 10, 000
NSL-KDD 10% 74, 826
113
122
16
19
30
15
The malicious instances in NSL-KDD are annotated with a family but the
benign ones are not, and Contagio does not provide any family information. The
families are, however, required to run simulations with Aladin and ILAB, and to
assess the sampling bias of the diﬀerent labelling strategies. We have assigned
families to the remaining instances with a k-means clustering and the number
of families k has been selected visually with the silhouette coeﬃcient [28].
Neither dataset has a proportion of malicious instances representative of
a typical network (55% for Contagio and 47% for NSL-KDD). We have uni-
formly sub-sampled the malicious class to get 10% of malicious instances. Table 1
describes the resulting datasets: Contagio 10% and NSL-KDD 10%.
1 http://contagiodump.blogspot.fr/.
2 http://www.unb.ca/cic/research/datasets/nsl.html.
ILAB: An Interactive Labelling Strategy for Intrusion Detection
129
5.2 Labelling Strategies
We compare ILAB with uncertainty sampling [20], Aladin [40], and G¨ornitz et al.
labelling method [14]. Since there is no open source implementation of these
labelling strategies, we have implemented them in Python with the machine
learning library scikit-learn [25]. All the implementations are released to ease
comparison in future research works. We brieﬂy present each labelling strat-
egy, we provide some details about our implementations and how we set the
additional parameters if relevant.
Uncertainty Sampling [20]. At each iteration, a binary logistic regression model
is trained on the labelled instances, and the expert is asked to annotate the b
most uncertain predictions, i.e. the closest to the decision boundary. Uncertainty
sampling has no additional parameter.
G¨ornitz et al. labelling strategy [14]. At each iteration, a semi-supervised anom-
aly detection model is trained on both the labelled and the unlabelled instances.
The model relies on an adaptation of an unsupervised anomaly detection model,
Support Vector Data Description (SVDD) [42], that takes into account labelled
m and a radius r ∈ R:
instances. It consists in a sphere deﬁned by a centre c ∈ R
the instances inside are considered benign, and the ones outside malicious. The
labelling strategy queries instances that are both close to the decision boundary
and have few malicious neighbours to foster the discovery of new malicious fam-
ilies. The nearest neighbours are computed with the Euclidean distance with the
scikit-learn ball tree implementation [23] that is eﬀective with a large number of
instances in high dimension.
Semi-supervised SVDD has no open source implementation, so we have imple-
mented it for our experiments with the information provided in [12–14]. The
parameters c, r, and the margin γ ∈ R are determined with the quasi-Newton
optimization method BFGS [46] available in scipy [17]. The optimization algo-
rithm requires initial values for c, r, and γ that are not speciﬁed in the papers.
We initialize c with the mean of the unlabelled and benign instances, r with the
average distance of the unlabelled and benign instances to the centre c, and γ
with the default value 1. Moreover, the detection model has three parameters:
ηU ∈ R and ηL ∈ R, the weights of the unlabelled and labelled instances, and
κ the weight of the margin γ. The authors provide no information about how
to set these parameters. When we set them to the default value 1, numerical
instabilities prevent the optimization algorithm from converging properly, and
lead to an extremely high execution time and very poor performance (more than
2 hours for training the model on Contagio 10% to get an AUC below 93%). We
have thus worked on the setting of these parameters. We have set ηU and ηL
to the inverse of the number of unlabelled and labelled instances, to give as
much weight to unlabelled and labelled instances, and to ensure numerical sta-
bility. The detection model is trained without any kernel as in the experiments
presented in [12–14].
Finally, the labelling strategy requires to set two additional parameters:
k ∈ N the number of neighbours considered, and δ ∈ [0, 1] the trade-oﬀ between
130
A. Beaugnon et al.
querying instances close to the decision boundary and instances with few mali-
cious neighbours. We use k = 10 as in [14] and the default value δ = 0.5.
Aladin [40]. Aladin runs rare category detection on all the data. It asks the expert
to annotate uncertain instances lying between two families to reﬁne the decision
boundaries, and low likelihood instances to discover yet unknown families. Aladin
does not have additional parameters.
This labelling strategy relies on a multi-class logistic regression model and a
multi-class Gaussian Naive Bayes model. The logistic regression parameters are
selected automatically with a grid search 4-fold cross validation optimizing the
AUC [16]. The penalty norm is either (cid:8)1 or (cid:8)2 and the regularization strength
is selected among the values {0.01, 0.1, 1, 10, 100}. The Gaussian Naive Bayes
model is trained without any prior.
ILAB. ILAB labelling strategy has only an additional parameter: buncertain. It
is set to 10% of the number of annotations performed at each iteration, i.e.
buncertain = 10 in our case. Some instances near the decision boundary are
annotated to help the detection model make a decision about these instances,
but not too many since these instances are often harder to annotate for the
expert [3,15,33] and they may lead to a sampling bias [29].
The logistic regression and Gaussian Naive Bayes models are trained the
same way as for Aladin.
5.3 Results
The datasets Contagio 10% and NSL-KDD 10% are split uniformly into two
datasets: (1) an active learning dataset (90%) used as a pool to build the labelled
dataset DL, and (2) a validation dataset (10%) to assess the performance of the
detection model trained on DL. The diﬀerent labelling strategies are compared
with simulations where the annotation queries are answered by an oracle pro-
viding the ground truth labels and families.
All the strategies are run with b = 100 annotations at each iteration. The
annotation budget is set to B = 1000 for Contagio 10%, and to B = 2000
for NSL-KDD 10% as this dataset contains more instances. The initial labelled
datasets are composed of instances belonging to the most represented families:
7 malicious instances and 13 benign instances.
All the experiments are run on Linux 3.16 on a dual-socket computer with
64Go RAM. Processors are Intel Xeon E5-5620 CPUs clocked at 2.40 GHz with
4 cores each and 2 threads per core. Each labelling strategy is run 15 times and
we report the average performance with the 95% conﬁdence interval.
First, we compare the number of known families across the iterations to assess
sampling bias (see Fig. 4a). Then, we compare the performance of the detection
models on the validation dataset (see Fig. 4b). Finally, we monitor the execution
time of the query generation algorithms to evaluate the expert waiting time
between iterations (see Fig. 4c).
ILAB: An Interactive Labelling Strategy for Intrusion Detection
131
Contagio 10%
NSL-KDD 10%
30
20
10
s
e
i
l
i
m
a
F
.
m
u
N
n
a
e
M
0
0