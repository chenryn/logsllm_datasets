# Checklist
  * I have verified that the issue exists against the `master` branch of Celery.
  * This has already been asked to the discussion group first.
  * I have read the relevant section in the  
contribution guide  
on reporting bugs.
  * I have checked the issues list  
for similar or identical bug reports.
  * I have checked the pull requests list  
for existing proposed fixes.
  * I have checked the commit log  
to find out if the bug was already fixed in the master branch.
  * I have included all related issues and possible duplicate issues  
in this issue (If there are none, check this box anyway).
## Mandatory Debugging Information
  * I have included the output of `celery -A proj report` in the issue.  
(if you are not able to do this, then at least specify the Celery  
version affected).
  * I have verified that the issue exists against the `master` branch of Celery.
  * I have included the contents of `pip freeze` in the issue.
  * I have included all the versions of all the external dependencies required  
to reproduce this bug.
## Optional Debugging Information
  * I have tried reproducing the issue on more than one Python version  
and/or implementation.
  * I have tried reproducing the issue on more than one message broker and/or  
result backend.
  * I have tried reproducing the issue on more than one version of the message  
broker and/or result backend.
  * I have tried reproducing the issue on more than one operating system.
  * I have tried reproducing the issue on more than one workers pool.
  * I have tried reproducing the issue with autoscaling, retries,  
ETA/Countdown & rate limits disabled.
  * I have tried reproducing the issue after downgrading  
and/or upgrading Celery and its dependencies.
## Related Issues and Possible Duplicates
#### Related Issues
  * #5935
#### Possible Duplicates
  * None
## Environment & Settings
**Celery version** : 4.4.3
**`celery report` Output:**
    software -> celery:4.4.3 (cliffs) kombu:4.6.10 py:3.8.0
                billiard:3.6.4.0 redis:3.5.3
    platform -> system:Linux arch:64bit, ELF
                kernel version:5.3.0-40-generic imp:CPython
    loader   -> celery.loaders.app.AppLoader
    settings -> transport:redis results:redis://worker-wm-01.local:6379/
    broker_url: 'redis://worker-wm-01.local:6379//'
    result_backend: 'redis://worker-wm-01.local:6379/'
    include: ['tasks']
    broker: 'redis://worker-wm-01.local:6379'
    broker_transport_options: {
     'interval_max': 5, 'interval_start': 0, 'interval_step': 0.4, 'max_retries': 5}
    broker_pool_limit: None
    backend: 'redis://worker-wm-01.local:6379/'
    redis_backend_health_check_interval: 120
    task_acks_late: True
    worker_prefetch_multiplier: 1
# Steps to Reproduce
## Required Dependencies
  * **Minimal Python Version** : 3.8.0
  * **Minimal Celery Version** : 4.4.3
  * **Minimal Kombu Version** : 4.6.10
  * **Minimal Broker Version** : N/A or Unknown
  * **Minimal Result Backend Version** : N/A or Unknown
  * **Minimal OS and/or Kernel Version** : N/A or Unknown
  * **Minimal Broker Client Version** : N/A or Unknown
  * **Minimal Result Backend Client Version** : N/A or Unknown
### Python Packages
**`pip freeze` Output:**
    absl-py==0.12.0         
    alembic==1.4.1   
    amqp==2.6.1 
    ase==3.21.1       
    astroid==2.5.4   
    attrs==20.3.0    
    billiard==3.6.4.0
    cachetools==4.2.1 
    celery==4.4.3                
    certifi==2020.12.5  
    chardet==3.0.4
    click==7.1.2 
    cloudpickle==1.6.0  
    coverage==5.5         
    cycler==0.10.0      
    databricks-cli==0.14.3
    dataclasses==0.6        
    decorator==4.4.2
    docker==5.0.0             
    entrypoints==0.3                 
    flake8==3.9.1   
    Flask==1.1.2
    Flask-PyMongo==2.3.0    
    future==0.18.2 
    gitdb==4.0.7   
    GitPython==3.1.14
    google-auth==1.29.0
    google-auth-oauthlib==0.4.4
    googledrivedownloader==0.4
    greenlet==1.0.0       
    grpcio==1.37.0       
    gunicorn==20.1.0    
    h11==0.8.1          
    h2==3.2.0               
    h5py==3.2.1 
    hpack==3.0.0 
    http3==0.6.7             
    hyperframe==5.2.0
    idna==2.10  
    iniconfig==1.1.1
    isodate==0.6.0       
    isort==5.8.0            
    itsdangerous==1.1.0
    Jinja2==2.11.3
    joblib==1.0.1       
    kiwisolver==1.3.1
    kombu==4.6.10  
    lazy-object-proxy==1.6.0
    llvmlite==0.36.0 
    Mako==1.1.4 
    Markdown==3.3.4   
    MarkupSafe==1.1.1
    matplotlib==3.4.1
    mccabe==0.6.1  
    minio==7.0.3      
    mlflow==1.15.0               
    networkx==2.5.1     
    numba==0.53.1
    numpy==1.20.2
    oauthlib==3.1.0     
    packaging==20.9       
    pandas==1.2.4       
    pefile==2019.4.18  
    Pillow==8.2.0           
    pluggy==0.13.1
    prometheus-client==0.10.1 
    prometheus-flask-exporter==0.18.1
    protobuf==3.15.8
    py==1.10.0 
    pyasn1==0.4.8           
    pyasn1-modules==0.2.8
    pycodestyle==2.7.0
    pyflakes==2.3.1
    pylint==2.7.4
    pymongo==3.11.3
    pyparsing==2.4.7
    pytest==6.2.3
    python-dateutil==2.8.1
    python-dotenv==0.17.0
    python-editor==1.0.4
    python-louvain==0.15
    pytorch-lightning==0.9.0
    pytz==2021.1
    PyYAML==5.4.1
    querystring-parser==1.2.4
    rdflib==5.0.0
    redis==3.5.3
    requests==2.25.1
    requests-async==0.6.2
    requests-oauthlib==1.3.0
    rfc3986==1.4.0
    rsa==4.7.2
    scikit-learn==0.24.1
    scipy==1.6.2
    seaborn==0.11.1
    six==1.15.0
    smart-open==5.0.0
    smmap==4.0.0
    SQLAlchemy==1.4.11
    sqlparse==0.4.1
    structlog==21.1.0
    tabulate==0.8.9
    tensorboard==2.2.0
    tensorboard-plugin-wit==1.8.0
    threadpoolctl==2.1.0
    toml==0.10.2
    torch==1.7.0
    torch-cluster==1.5.8
    torch-geometric==1.6.3
    torch-scatter==2.0.5
    torch-sparse==0.6.8
    torch-spline-conv==1.2.0
    tqdm==4.60.0
    typing-extensions==3.7.4.3
    urllib3==1.26.4
    uWSGI==2.0.19.1
    vine==1.3.0
    websocket-client==0.58.0
    Werkzeug==1.0.1
    wrapt==1.12.1
### Other Dependencies
N/A
## Minimally Reproducible Test Case
    @shared_task(bind=True)
    def process(self, filename):
        run_long_process()  # more than 2 hours
        return filename
    celery_app.send_task("tasks.process", args=(filename,), queue=queue)
# Expected Behavior
Task is executed only once.
# Actual Behavior
the task is keep executing after having got state SUCCESS once:
    >>> from app import celery_app
    >>> ar = celery_app.AsyncResult('46906783-4351-4397-8893-dfc69c8421cf')
    >>> ar.state
    'SUCCESS'
    [2021-07-22 21:03:05,141: INFO/MainProcess] Received task: tasks.process[46906783-4351-4397-8893-dfc69c8421cf]  
    [2021-07-22 23:22:02,694: INFO/MainProcess] Received task: tasks.process[46906783-4351-4397-8893-dfc69c8421cf]  
    [2021-07-23 01:41:35,151: INFO/MainProcess] Received task: tasks.process[46906783-4351-4397-8893-dfc69c8421cf]  
    [2021-07-23 04:02:10,839: INFO/MainProcess] Received task: tasks.process[46906783-4351-4397-8893-dfc69c8421cf]  
I've noticed that unlike the similar issue, the default value of 1 hour
visibility timeout doesn't affect me. Tasks between 1 and 2 hours long are
performed only once, but this one takes about 140 minutes and keeps
reappearing. I also read that actually visibility timeout doesn't affect
anything and this kind of bugs happens mostly with Redis backend. Like in
other cases, change to Rabbit is not an option.
I would like to discover more about this issue, but i'm not sure where to head
at. and whether it is similar to other cases or a new one. and what exactly is
the nature of getting tasks to a worker (is it only that this method must be
called for a task to never be picked again or it doesn't matter in some
cases)?