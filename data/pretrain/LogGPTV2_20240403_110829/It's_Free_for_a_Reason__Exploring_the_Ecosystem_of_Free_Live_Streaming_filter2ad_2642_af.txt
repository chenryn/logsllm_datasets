on a page and incorporate this ratio as a numeric feature.
B. Evaluation
Implementation. To build the FLIS classiﬁer, we opt for
a supervised learning approach. In this approach, we ﬁrst
collected a set of labeled webpages, and we have used this set
to train the classiﬁer by extracting the feature vectors. Once
the classiﬁer is trained, a new page is crawled, translated into
the feature vector, and passed to the FLIS classiﬁer. The FLIS
classiﬁer then labels the page as a FLIS or non-FLIS page.
Speciﬁcally, for each new page, the classiﬁer outputs a score.
If this score is greater than a selected threshold, the classiﬁer
labels the page as a FLIS aggregator page.
The components of the FLIS classiﬁer used to crawl a
website and extract the features are written in Python. To build
the FLIS classiﬁer, we used the Random Forest algorithm [19]
implementation in Weka [27]. The rational of using the random
forest algorithm is that it is fast, robust with regards to outliers,
yields extremely accurate predictions, and can process a large
number of input features without overﬁtting. To foster future
research in FLIS services, we will be making the prototype
implementation of the FLIS classiﬁer publicly available.
Evaluation datasets. To evaluate the performance of the
FLIS classiﬁer, we assembled three different datasets that we
carefully examined and labeled. We now provide the details
on each of the datasets.
(cid:5) Balanced dataset (BD): The balanced dataset consists of an
equal number of positive (FLIS aggregator pages) and negative
training samples (non-FLIS pages). We collected non-FLIS
pages by randomly crawling the links of Alexa top 1,000
domains and label each instance through manual inspection.
For aggregator pages, we extract the subset of webpages from
the gathered dataset and label each page through manual
inspection. Overall, this dataset consists of 3,500 aggregator
pages and 3,500 non-FLIS pages.
(cid:5) Imbalanced dataset (ID): Besides the balanced dataset, we
also evaluate the performance of the FLIS classiﬁer on an
imbalanced dataset. In reality, there are more non-FLIS web-
pages than FLIS aggregator pages. This unequal distribution
of webpages can bias the performance of classiﬁer towards the
majority class (i.e., non-FLIS pages). To exhaustively evaluate
the discriminative nature of features and the classiﬁcation
algorithm, we built a dataset with a class imbalance ratio of
10 to 1. Speciﬁcally, the imbalanced dataset contains 15,000
non-FLIS and 1,500 FLIS aggregator pages.
(cid:5) Special testing dataset (STD): In both the balanced and
imbalanced datasets, the nature of the negative training samples
is substantially different from the positive samples. As such, an
evaluation on only these datasets will represent our classiﬁer’s
ability to distinguish between FLIS webpages from entirely
different non-FLIS webpages (e.g., fb.com and bbc.com). To
this end, we assemble an additional special testing dataset
13
Run-time performance. In addition to classiﬁcation results,
we also measured the run-time performance of the FLIS
classiﬁer. Running as a single threaded application on a 64-
bit 2.8 GHz Intel Core i5 CPU, our classiﬁer takes 18.4
seconds on average to classify a given webpage, the slowest
being 75 seconds. The most expensive processes are extracting
the features from the HTML sources and network trace.
These processes are IO bound and account for the majority
of the runtime. Overall, in our data gathering process (as
demonstrated in Section III-A), we observed that the FLIS
classiﬁer scales well in an online process.
Classiﬁer evasion. The presented FLIS classiﬁer is built on
attributes targeting the look and modus operandi of aggrega-
tor pages. Therefore, an aggregator’s attempt to purposefully
evade detection is not an easy task. While an adversary can
evade a few speciﬁc features used in the learning process, this
is likely going to result in either increased operating costs,
or a loss of a percentage of their viewers. For instance, if
aggregators stop using text and images related with sports and
legitimate broadcast channels, they are likely to attract less
users to click on their links and interact with their malicious
ads. Overall, we argue that our FLIS classiﬁer provides robust
detection of aggregator pages, which could be used both by
law enforcement as part of a take-down process, as well as
by users who may confuse an aggregator page for a legitimate
service provided by a reputable channel.
VI. RELATED WORK
There is a signiﬁcant amount of prior work on the piracy
of live broadcasts from a legal perspective. Speciﬁcally, the
focus of this research is on highlighting copyright law [28],
[33], [36], [50], analyzing the consequences of piracy on
related organizations [16], [24], [47], and issuing proposals to
improve judicial conducts [28]. In contrast to these studies, we
map the FLIS ecosystem through real-world experiments and
empirically quantify the threats for both users landing on FLIS
domains, as well as for related companies whose copyrights
and trademarks are potentially abused by FLIS services.
Other research has focused on analyzing malicious adver-
tisement in the context of online fraud [26], [32], [46], and
how certain Internet services have been abused for monetary
gain [20], [34], [51], [52]. Studies that speciﬁcally target
deceptive advertisement techniques mainly focus on examining
the security implications of deceptive ad banners [23], [37].
Our work differs from these studies in that it focuses on the
interactions of users with the, practically unexplored, video
overlay ads and the numerous threats associated with it.
VII. CONCLUSION
In this paper, we presented the results of the ﬁrst empirical
study of free live streaming services. We developed an infras-
tructure that enabled us to map the ecosystem of FLIS services,
identify the parties that facilitate anonymous broadcast of live
streams, and analyze the deceptive advertising content that
users are exposed to when they watch live broadcasts on FLIS
websites. In this process, we discovered various types of abuse
including malware distribution, malicious browser extensions,
substandard overlay advertising, and scams that could cost
users their personal information as well as ﬁnancial loss.
Given the extent of the observed abuse and the large
number of copyright complaints, we engineered a classiﬁer
Figure 11: Zoomed ROC curves of the FLIS classiﬁer on
balanced & imbalanced datasets.
to evaluate our classiﬁer’s ability of distinguishing between
common sports webpages and FLIS webpages. This dataset
contains 1,000 randomly crawled non-FLIS pages listed under
the “Sports” category of the open directory project [3].
Cross validation. To evaluate the detection accuracy of the
FLIS classiﬁer, we perform a 10 fold cross-validation test on
both the balanced and imbalanced datasets. In the 10 fold
cross-validation test, the dataset is randomly divided into 10
smaller subsets, out of which 9 subsets are used for training
the classiﬁer and 1 subset is used for testing (unseen pages
during training). This process is then repeated 10 times, with
each of the 10 subsets used exactly once as the testing data.
To avoid any artifacts, we repeat the process of 10 fold cross-
validation 10 times, each time the data is randomly divided
into 10 smaller subsets with a different seed value.
Figure 11 shows the ROC curves that we obtained on
averaged results of the tests for the balanced and imbalanced
dataset. In order to emphasize the FLIS classiﬁer performance
at low false positives, we plot the zoomed-in ROC where the
false positive rates range from 0% to 3%. The tables shown in
Figure 11 provide details of the area under the ROC (AUC)
and the trade-off between the true positive (TP) rate and false
positive (FP) rate for a few preferred operating points on the
balanced and imbalanced ROC curves. The 99.9% area under
the curve (AUC) for both datasets, shows that our classiﬁer
can properly handle both balanced and imbalanced datasets.
Moreover, we can see that for both datasets, when we select
a threshold value to achieve a false positive rate of 0%, the
classiﬁer still yields a true positive rate of approximately
99.2%. These results indicate the accuracy of our classiﬁer
when distinguishing the FLIS webpages from entirely different
non-FLIS webpages.
STD experiment. For this experiment, we ﬁrst train a model
on 15,000 non-FLIS pages (from ID) and 3,500 FLIS pages
(from BD). The trained model is then used to classify the
special testing dataset (STD). Out of the 1,000 non-FLIS sports
pages in STD, the FLIS classiﬁer misclassiﬁed only 3 pages
as FLIS aggregator webpages (false positive rate = 0.3%)
demonstrating the accuracy of the FLIS classiﬁer when dealing
with the non-FLIS sports webpages.
14
00.0050.010.0150.020.0250.030.990.9910.9920.9930.9940.9950.9960.9970.9980.9991False Positive RateTrue Positive Rate Balanced DatasetImbalanced DatasetBalanced DatasetAUC = 0.999TP | FP----------------------0.9923 - 0.0000 0.9926 - 2.8e-041.0000 - 0.0209Imbalanced DatasetAUC = 0.999TP | FP----------------------0.9927 - 0.0000 0.9960 - 0.0292 0.9993 - 0.3165that can be used to, among others, alert users that they are
currently interacting with potentially dangerous FLIS page,
or help analysts ﬁnd unknown FLIS pages in an effort to
curb copyright
infringements. We employed the proposed
classiﬁer in an online process to ﬁnd new aggregator pages,
and showed that our classiﬁer achieves high accuracy with low
false positives.
ACKNOWLEDGMENTS
We thank Jesse Davis for providing his insightful input
on the evaluation of FLIS classiﬁer, Alexandros Kapravelos
for helping us with analyzing the Chrome extensions, Nicolas
Christin for his help with the preparation of the ﬁnal version
of this paper, and the anonymous reviewers for their valuable
comments. We also thank Amazon for providing us with the
virtual machines that enabled our large-scale, advertisement-
characterizing experiments. For KU Leuven, this research is
partially funded by the Research Fund KU Leuven, with the
ﬁnancial support from the Prevention of and Fight against
Crime Programme of the European Union (B-CCENTRE), and
by the EU FP7 project NESSoS. For Stony Brook University,
this work was supported by the National Science Foundation
(NSF) under grant CNS-1527086.
REFERENCES
[1] HTTP Live Streaming. https://goo.gl/crRhm9.
[2]
InfoSoc Directive 2001/29. http://goo.gl/SOVjac.
[3] Open Directory Project. https://www.dmoz.org/.
[4] Python-Goose. https://github.com/grangier/python-goose.
[5] Real Time Messaging Protocol. http://goo.gl/d1NO9l.
[6] Real Time Streaming Protocol. https://www.ietf.org/rfc/rfc2326.txt.
[7] Realnetworks Incorporation History. http://goo.gl/IxHQRB.
[8] Siezed Domain. http://atdhe.net/.
[9] Siezed Domain. http://frombar.com/.
[10] VirusTotal. https://www.virustotal.com/.
[11] W3C: Same Origin Policy - Web Security. http://goo.gl/Xps3Ph.
[12] Wizwig taken-down. http://www.wiziwig.tv/ofﬂine.html.
[13] Digital video in-stream ad format guidelines and best practices. 2008.
http://www.iab.net/media/ﬁle/IAB-Video-Ad-Format-Standards.pdf.
[14] Sumayah Alrwais, Kan Yuan, et al. Understanding the dark side of
domain parking. In USENIX Security, 2014.
[15] Marco Balduzzi, Manuel Egele, Engin Kirda, Davide Balzarotti, and
Christopher Kruegel. A solution for the automated detection of
clickjacking attacks. In ASIA CCS, 2010.
[16] Barclay Ballard.
Premier League knocks out Wiziwig in illegal
streaming crackdown. http://goo.gl/ETCjH2.
[17] Paul Barford, Igor Canadi, et al. Adscape: Harvesting and analyzing
online display ads. In WWW, 2014.
[18] Eda Baykan, Monika Henzinger, Ludmila Marian, and Ingmar Weber.
Purely URL-based topic classiﬁcation. In WWW, 2009.
[19] Leo Breiman. Random forests. Machine learning, 45(1), 2001.
[20] Nicolas Christin, Sally S Yanagihara, and Keisuke Kamataki. Dissecting
one click frauds. In CCS, 2010.
[21] Vacha Dave, Saikat Guha, and Yin Zhang. Viceroi: Catching click-spam
in search ad networks. In CCS, 2013.
[22] Holger Dreger, Anja Feldmann, Michael Mai, Vern Paxson, and Robin
Sommer. Dynamic application-layer protocol analysis for network
intrusion detection. In USENIX Security, 2006.
[23] Sevtap Duman, Kaan Onarlioglu, Ali Osman Ulusoy, William Robert-
son, and Engin Kirda. Trueclick: automatically distinguishing trick
banners from genuine download links. In ACSAC, 2014.
[24] Aaron Elstein. Web pirates are stealing from sports broadcasters. http:
//goo.gl/TVOxRi.
[25] Rgis Gras, Einoshin Suzuki, Fabrice Guillet, and Filippo Spagnolo.
Statistical Implicative Analysis. Springer, 2008.
15
[26] Hamed Haddadi. Fighting online click-fraud using bluff ads. SIG-
COMM Computer Communication Review, 40(2), 2010.
[27] Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter
Reutemann, and Ian H Witten. The WEKA data mining software: an
update. ACM SIGKDD explorations newsletter, 11(1), 2009.
[28] Stephanie N Horner. DMCA: Professional sports leagues’ answer to
protecting their broadcasting rights against illegal streaming. Marq.
Sports L. Rev., 24, 2014.
[29] Luca Invernizzi, Paolo Milani, Stefano Benvenuti, Christopher Kruegel,
Marco Cova, and Giovanni Vigna. EvilSeed: A guided approach to
ﬁnding malicious web pages. In Oakland, 2012.
[30] Nav Jagpal, Eric Dingle, Moheeb Abu Rajab, Panayiotis Mavrommatis,
Niels Provos, and Kurt Thomas. Trends and lessons from three years
ﬁghting malicious extensions. In USENIX Security, 2015.
[31] Dave Lee. Premier league wins piracy block of ﬁrst row sports. http:
//www.bbc.com/news/technology-23342349.
[32] Zhou Li, Kehuan Zhang, Yinglian Xie, Fang Yu, and XiaoFeng Wang.
Knowing your enemy: Understanding and detecting malicious web
advertising. In CCS, 2012.
[33] Michael J Mellis. Internet piracy of live sports telecasts. Marq. Sports
L. Rev., 18, 2007.
[34] Nick Nikiforakis, Federico Maggi, Gianluca Stringhini, M Zubair
Raﬁque, Wouter Joosen, et al. Stranger danger: exploring the ecosystem
of ad-based url shortening services. In WWW, 2014.
[35] Allison Nixon and Christopher Camejo. DDoS protection bypass
techniques. In Black Hat Brieﬁngs, 2013. https://goo.gl/58Ah2j.
[36] Association of Internet Security Professional.
cyber security risks: A dangerous status quo?, 2014.
WE43IM.
Illegal streaming and
http://goo.gl/
[37] Kaan Onarlioglu, Utku Ozan Yilmaz, Engin Kirda, and Davide
Balzarotti. Insights into user behavior in dealing with internet attacks.
In NDSS, 2012.
[38] Cisco Press Release. Global Internet trafﬁc projected to quadruple by
2015. http://goo.gl/MXi3pN.
[39] Niels Provos, Mavrommatis Panayiotis, Moheeb Abu Rajab, and Fabian
Monrose. All your iframes point to us. In USENIX Security, 2008.
[40] M Zubair Raﬁque and Juan Caballero. FIRMA: Malware clustering and
network signature generation with mixed network behaviors. In RAID.
2013.
[41] M Zubair Raﬁque, Ping Chen, et al. Evolutionary algorithms for
classiﬁcation of malware families through different network behaviors.
In GECCO, 2014.
[42] Gerard Salton and MJ McGill.
Introduction to Modern Information
Retrieval. McGraw-Hill Book Co, 1983.
[43] Homeland Security Investigations. Curbing illegal streaming: The
investigation and the case. Anti-Piracy and Content Protection Summit.
http://www.antipiracycontentsummit.com/media/1000508/44011.pdf.
[44] Chris Smith. Pirating copyrighted content is legal in Europe, if done
correctly. http://goo.gl/G6OoCh.
[45] Pete South. Illegal football streams war shows no sign of ending for
premier league. http://goo.gl/ajnxcQ.
[46] Kevin Springborn and Paul Barford.
Impression fraud in on-line
advertising via pay-per-view networks. In USENIX Security, 2013.
[47] Christina Sterbenz. How sketchy streaming sites really work and why
some are legal. http://goo.gl/e6FYXo.
[48] Kurt Thomas, Elie Bursztein, Chris Grier, et al. Ad injection at scale:
Assessing deceptive advertisement modiﬁcations. In Oakland, 2015.
[49] Alexander Tuzhilin. The Lanes Gifts v. Google Report. http://bit.ly/
13ABxSZ.
[50] Carson S Walker. A la carte television: A solution to online piracy.
CommLaw Conspectus, 20, 2011.
[51] Xinyu Xing, Wei Meng, Byoungyoung Lee, et al. Understanding
malvertising through ad-injecting browser extensions. In WWW, 2015.
[52] Apostolis Zarras, Alexandros Kapravelos, Gianluca Stringhini, et al.
The dark alleys of madison avenue: Understanding malicious adver-
tisements. In IMC, 2014.
[53] Christoph Zauner.
Implementation and benchmarking of perceptual
image hash functions. Master’s thesis, Upper Austria University of
Applied Sciences, 2010.