 最初在 Spotify
构建和使用的工具用于管理我们新生的队列，假定服务器在安装并投入使用后将继续在后端的某处工作，直到退役。还假定，从大概率来说，预配服务器本身将是一个不寻常的事件，每月只执行几次。因此，安装服务器的工具需要几分钟才能运行，而且频繁的手动干预是可以接受的。从开始到结束，一批服务器的安装可能需要一个小时到一个完整的工作日。
到 2011
年，我们安装新服务器的频率远远超过预期。重新利用服务器是一个已知的过程，但经常有一些问题迫使运维介入并手动修复问题。
对于一家拥有少量服务器的小型公司来说，这并不奇怪或没有错，但在我们目前的阶段，Spotify
已经有了两个数据中心，有实时流量，还有第三个数据中心正在启用中。由于服务器数量数不胜数，因此越来越难以做到这一点。
## 打破那些坏习惯
 业内的运维模式正在转变，尽管我们中的一些人看到了它的到来，但谁也不知道这对我们意味着什么，也不知道我们的服务的可用性将会如何。当这种转变在我们之中发生时，其实是简单和明显的：我们需要调整我们的硬件，以适应我们的意图，而不是调整我们的意图，以适应硬件。
这种转变对于我们中的许多人来说很难进入，因为我们在日常工作中太舒服了。事实上，这种心态花了几年时间才完全改变，可能是因为我们花了这么长时间才创造出工具，使这种心态的转变成为可能。
2011
年底，又开始了另一个基本上被忽视的转变：功能开发人员开始以不同的方式组织。午餐时，我们听到开发人员谈论自主自组织团队，以及他们属于哪个"章节"。我们仍然可以与他们讨论服务和用户，但现在的对话包括关注产品和利益相关者。整个开发部门正在缓慢地过渡到一个可扩展的敏捷组织，我们运维部门从一旁观察到这一点。
从我们这些在运维团队中的人的角度来看，这种组织变革最令人不快的是它对我们的角色产生了辅助作用。命名从"开发团队"到"团队"的转变，加上对自主性和自我组织性的重视，挑战了我们习惯的中心性。小队又被分组成所谓的"部落"，这些"部落"也有自主和自我组织的明确意图。
现在，运维团队面对的是多个部落，每个部落的结构略有不同，令人担忧的是，很少有保持同质化的迹象。 
## 关键收获
这一时期的一些主要知识是：
-   将思维模式从以服务器为中心切换到以服务为中心，并使工具反映这一点。
-   敏捷矩阵组织模型的引入迫使我们重新思考运维的定位。
# 无法扩展的系统：2012
-    近 25 名运维工程师
-   近 70 名后端工程师
-   三个数据中心，几千台服务器
-   近 50 个后端服务
## 前奏
在本节中，我们将讨论运维团队与组织一同扩展的挑战：
迭代胜过失败
:   有效的扩展仍然很困难，而放弃我们的责任是不够的。我们需要重新审视
    Spotify 的运维含义。
默认需要运维经验
:   执行大部分运维工作的中央运维团队无法扩展规模。我们需要通过将运维责任完全转移到开发人员更近的位置，使运维真正成为普遍技能。
现在是 2012 年，Spotify
用户群继续增长，为我们带来了新的可扩展性和稳定性问题。
运维小组由不到十名 SRE 组成（事实上，在这两年才开始 SRE
这个称呼），在斯德哥尔摩和纽约两地按需招聘。作为运维所有者，每个 SRE
负责数十项后端服务的维护：处理新版本的部署、容量规划、系统设计评审、配置管理或代码评审，以及维护操作手册，当然还有其他几个日常运维职责。
我们的后端现在在三个数据中心运行，第四个数据中心即将投入运行，我们必须维护更多资源。这意味着我们负责配置机架交换机、订购硬件、远程手动布线、服务器引入、主机配置、打包服务、配置管理和部署，从物理空间到应用程序环境。由于责任范围扩大，我们组建了另一个团队来开发工具自动化，并与运维部门密切合作。该团队开发的早期产品之一是（用于硬件清单和容量调配的）配置管理数据库（CMDB）。
由于配置定制且不均匀性，可预测性很难。运维所有者与服务的开发人员需要密切合作，努力提高质量，遵循生产就绪实践，并运行一个现已正式的部署清单，以确保即使在初始阶段的服务设计也符合运维标准。我们经常提出的关切包括：
-   服务是否在我们的构建系统上打包和构建？
-   该服务是否生成日志？
-   是否有图形、监视和警报？
-   已定义备份和还原测试？
-   是否有安全审查？
-   谁拥有这项服务？它的依赖项是什么？
-   是否有任何潜在的可扩展性问题？是否有任何单点故障？
## 手工运维碰壁
 尽管我们不断手动或通过配置管理进行部署，但持续交付机制并未形成。我们仍然以良好的速度，不断的发布更新，但是以手工完成的工作为代价。
服务发现包括静态 DNS 记录以及手动编辑和维护的区域文件。DNS
更改通常由运维审核和部署。我们在 DNS 部署期间往往通过脚本自动在 IRC
上喊话"DNS 部署开始了！"。
运维所有者和开发所有者定期浏览容量规划电子表格，以确保服务有足够的容量来维持当前使用量的增加。收集访问模式和资源利用率，并根据当前增长预测容量需求。对于几十个服务的所有者来说，这意味着要进行大量的容量规划。
在 2012 年下半年，我们达到 100
万并发用户。这意味着有一百万人直接收听连接到我们三个数据中心之一的音乐。一个相当伟大的壮举。
回顾一下，这应该归因于一些早期的决策，如 Spotify
后端架构被设计为可扩展，早期的客户端/协议/后端优化，以及良好的实现，这些都得到了回报。此外，由于没有复杂的逻辑，大多数故障都可以轻松定位和隔离。每个后端服务都做了一件事，并且做了正确的事。我们保持简单。
随着流媒体音乐用户数量呈指数级增长，运维团队无法做到这一点。我们发现集中式
SRE 运维团队是一个无法扩展的系统。
## 关键收获
我们从这一时期的主要学习是：
-   使运维从开始真正成为默认的；如果你构建它，你就要运行和维护它。
-   将运维责任转移到更接近于目标的人：开发人员。
-   随着服务生态系统的扩展，需要不断审视运维工作是如何扩展的。昨天效果好的东西今天可能效果不好。 
# 介绍小组内嵌运维：2013\~2015
-     近 50 名运维工程师
-   近 150 名后端工程师
-   3 个数据中心
-   60 个后端服务
-   1 个用于登台环境的云服务商
## 前奏
在本节中，我们将讨论新的运维方法如何减少瓶颈并允许技术组织更快地增长：
迭代胜过失败
:   采用"小组内嵌运维"的新模式，使我们得以集中精力尽量减少手工作业。
核心工程价值
:   小组拥有自己的运维人员，这在不知不觉中帮助我们维护了自主和信任的价值观。工程师有可能造成广泛的损害，但同时他们手上也有避免这种破坏的工具和流程。
此时，工程组织已经变得太大，无法作为单个团队运行。于是基础架构和运维（IO）部落成立，专注于为我们的后端开发人员提供基础架构，并解决大规模运维带来的问题。这个部落的一部分叫做服务可用性（SA），主要由我们以前在生产运维中工作的工程师组成。到
2013 年，SA
由四个小队组成，分别是：安全、监控和另外两个工作小组（他们负责提供管理服务器所需的任何其他基础设施工具）。我们聘用新开发人员和启动新开发团队的速度太高，以至于这四个
SA 团队无法跟上。由于我们可以购买和安装新服务器、查看和合并 Puppet
更改、添加 DNS