we found that it quickly decreased as we increased the
number of websites in the training set.
In general, the classiﬁers performed better in identify-
ing clients’ connections better than the hidden services
servers; the TPR was comparable, but the FPR was sig-
niﬁcantly lower for classifying clients. We believe that
this is, at least partially, due to the fact that we are us-
ing one real hidden service to emulate multiple hidden
services; our data does not capture the differences in the
differences in hardware, software, locations, and other
characteristics real hidden service servers would have.
8 Future Possible Defenses
Our attacks rely on the special properties of the circuits
used for hidden service activities. For the ﬁrst attack
(Section 5.1), we used three very identiﬁable features
of the circuits: (1) DoA, (2) number of outgoing cells,
and (3) number of incoming cells. To defend against this
attack, Tor should address the three features. First, all
circuits should have similar lifetime. Client IP and hid-
den service IP lasts either a very short or very long time,
and this is very identifying. We recommend that circuits
with less than 400 seconds of activity should be padded
to have a lifetime of 400-800 seconds. Furthermore, we
suggest that hidden services re-establish their connection
to their IPs every 400-800 seconds to avoid any circuits
from lasting too long. Second, hidden service and client
IP should have a larger and varying number of outgo-
ing and incoming cells.
IPs are only used to establish
the connection which limits the possible number of ex-
changed cells. We believe they should send and receive
a random number of PADDING cells, such that their me-
dian value of incoming and outgoing cells is similar to
that of a general circuit. We evaluated the effectiveness
of this defense on the same dataset used in Section 6.1,
and found that the true positive rate for the IPs and RPs
fell below 15%. Once the features look the same, the
classiﬁers cannot do much better than simply guessing.
To prevent the second attack (Section 5.2), we recom-
mend that every circuit be established in a pair with the
same sequence for the ﬁrst few cells. If an extend fails
for either circuit (which should be a rare occurrence),
then we should restart the whole process to ensure no in-
formation is leaked. To do this efﬁciently, Tor could use
its preemptive circuits. Tor already has the practice of
building circuits preemptively for performance reasons.
We can leverage this, and build the preemptive circuit
5The results are not directly comparable to previous WF attacks due
to the differences in the settings, such as the size of the open world.
Figure 14: TPR and FPR of the client side classiﬁcation for
different classiﬁers.
Figure 15: TPR and FPR of the server side classiﬁcation for
different classiﬁers.
one instance of the websites in the training set), and mea-
sured the TPR and FPR. The results of the open world
experiment on the clients and the servers are shown in
Figure 14 and Figure 15 respectively.
In all settings, we found that k-NN classiﬁer works
the best for classifying hidden services. We believe this
is because k-NN considers multiple features simultane-
ously while the tree-based classiﬁers consider each fea-
ture one after another.
In the closed world, the accu-
racy of k-NN was 97% for classifying the clients and
94.7% for the servers.
In the open world, the k-NN
classiﬁer again performed the best. The TPR of k-NN
reduced slightly as we increased the number of trained
non-monitored websites. The TPR ranged from 90% to
88% and 96% to 88% for classifying clients and servers
respectively. The FPR steadily decreased as we trained
on more non-monitored websites: for classifying clients,
it varied from 40% to 2.9% depending on the number of
trained pages. Similarly, FPR of classifying servers var-
300  24th USENIX Security Symposium 
USENIX Association
14
with another general circuit with the same sequence as
the IP-RP pairs. This would eliminate the second attack.
For WF attacks (Section 7), defenses proposed by pre-
vious works [35, 9] will be effective here as well. Fur-
thermore, for the clients, the results of Juarez et al. [24]
suggest that WF attacks on hidden service would have
signiﬁcantly lower accuracy if an RP circuit is shared
across multiple hidden service accesses.
9 Related Work
Several attacks challenging the security of Tor have been
proposed. Most of the proposed attacks are based on
side-channel leaks such as congestion [31, 17], through-
put [30], and latency [21]. Other attacks exploit Tor’s
bandwidth-weighted router selection algorithm [5] or its
router reliability and availability [7]. Most of these at-
tacks are active in that they require the adversary to per-
form periodic measurements, induce congestion, inﬂu-
ence routing, or kill circuits.
Our attacks on the other hand, like the various WF at-
tacks, are passive. Other passive attacks against Tor in-
clude Autonomous Systems (AS) observers [15], where
the attacker is an AS that appears anywhere between the
client and his entry guard, and between the exit and the
destination.
In addition, several attacks have been proposed to
deanonymize hidden services. Øverlier and Syver-
son [32] presented attacks aiming to deanonymize hid-
den services as follows: the adversary starts by deploying
a router in the network, and uses a client which repeat-
edly attempts to connect to the target hidden service. The
goal is that, over time, the hidden service will choose the
malicious router as part of its circuit and even as its entry
guard to the client allowing the attacker to deanonymize
him using trafﬁc conﬁrmation.
A similar trafﬁc conﬁrmation attack was described by
Biryukov et al. [6]. The malicious RP sends a message
towards the hidden service consisting of 50 padding cells
when it receives the rendezvous1 sent by the hidden
service. This signal allows another malicious OR along
the circuit from the hidden service to the RP, to iden-
tify the hidden service or its entry guard on the circuit.
Biryukov et al. also show how it is possible for the at-
tacker to enumerate all hidden services and to deny ser-
vice to a particular target hidden service.
10 Conclusion
Tor’s hidden services allow users to provide content and
run servers, while maintaining their anonymity. In this
paper, we present the ﬁrst passive attacks on hidden ser-
vices, which allow an entry guard to detect the presence
of hidden service activity from the client- or the server-
side. The weaker attacker, who does not have perfect cir-
cuit visibility, can exploit the distinctive features of the
IP and RP circuit communication and lifetime patterns
to classify the monitored circuits to ﬁve different classes.
For the stronger attacker, who has perfect circuit vis-
ibility (in the case where the client uses only one entry
guard), the attacker runs a novel pairwise circuit correla-
tion attack to identify distinctive cell sequences that can
accurately indicate IP and RP circuits.
We evaluated our attacks using network traces ob-
tained by running our own clients and hidden service on
the live Tor network. We showed that our attacks can
be carried out easily and yield very high TPR and very
low FPR. As an application of our attack, we studied the
applicability of WF attacks on hidden services, and we
made several observations as to why WF is more real-
istic and serious in the domain of hidden services. We
applied state-of-the-art WF attacks, and showed their ef-
fectiveness in compromising the anonymity of users ac-
cessing hidden services, and in deanonymizing hidden
services. Finally, we propose defenses that would miti-
gate our trafﬁc analysis attacks.
11 Code and Data Availability
Our data and scripts are available at http://people.
csail.mit.edu/kwonal/hswf.tar.gz.
12 Acknowledgements
The authors thank Tao Wang and the reviewers for their
useful feedback and comments. This reserach was sup-
ported in part by the QCRI-CSAIL partnership.
References
[1] Alexa The Web Information Company. https://www.alexa.
com.
[2] Tor Hidden Service Search. https://ahmia.fi.
[3] Tor. Tor Metrics Portal.
https://metrics.torproject.
org/.
[4] ALSABAH, M., BAUER, K., AND GOLDBERG, I. Enhancing
tor’s performance using real-time trafﬁc classiﬁcation.
In Pro-
ceedings of the 2012 ACM Conference on Computer and Commu-
nications Security (New York, NY, USA, 2012), CCS ’12, ACM,
pp. 73–84.
[5] BAUER, K., MCCOY, D., GRUNWALD, D., KOHNO, T., AND
SICKER, D. Low-Resource Routing Attacks Against Tor.
In
Proceedings of the Workshop on Privacy in the Electronic Society
(WPES 2007) (October 2007), pp. 11–20.
[6] BIRYUKOV, A., PUSTOGAROV, I., AND WEINMANN, R.-P.
Trawling for Tor Hidden Services: Detection, Measurement,
Deanonymization. In Proceedings of the 2013 IEEE Symposium
on Security and Privacy (Washington, DC, USA, 2013), SP ’13,
IEEE Computer Society, pp. 80–94.
USENIX Association  
24th USENIX Security Symposium  301
15
[7] BORISOV, N., DANEZIS, G., MITTAL, P., AND TABRIZ, P. De-
nial of Service or Denial of Security? How Attacks on Reliability
can Compromise Anonymity. In Proceedings of the 14th ACM
Conference on Computer and Communications Security, CCS ’07
(October 2007), pp. 92–102.
[8] BREIMAN, L., FRIEDMAN, J. H., OLSHEN, R. A., AND
STONE, C. J. Classiﬁcation and Regression Trees. CRC Press,
New York, 1999.
[9] CAI, X., NITHYANAND, R., WANG, T., JOHNSON, R., AND
GOLDBERG, I. A Systematic Approach to Developing and Eval-
uating Website Fingerprinting Defenses.
In Proceedings of the
2014 ACM SIGSAC Conference on Computer and Communica-
tions Security (New York, NY, USA, 2014), CCS ’14, ACM,
pp. 227–238.
[10] CAI, X., ZHANG, X., JOSHI, B., AND JOHNSON, R. Touching
from a Distance: Website Fingerprinting Attacks and Defenses.
In Proceedings of the 19th ACM conference on Computer and
Communications Security (CCS 2012) (October 2012).
[11] DINGLEDINE, R.
Using Tor Hidden Services for Good.
https://blog.torproject.org/blog/using-tor-good,
2012. Accessed February 2015.
[12] DINGLEDINE, R. Tor security advisory: “relay early” trafﬁc
conﬁrmation attack. https://blog.torproject.org/blog/tor-security-
advisory-relay-early-trafﬁc-conﬁrmation-attack, 2014. Accessed
February 2015.
[13] DINGLEDINE, R., HOPPER, N., KADIANAKIS, G., AND
MATHEWSON, N.
One Fast Guard for Life (or 9
months). https://www.petsymposium.org/2014/papers/
Dingledine.pdf, 2015. Accessed February 2015.
[14] DINGLEDINE, R., MATHEWSON, N., AND SYVERSON, P. Tor:
The Second-Generation Onion Router. In Proceedings of the 13th
USENIX Security Symposium (August 2004), pp. 303–320.
[15] EDMAN, M., AND SYVERSON, P. As-awareness in Tor Path
Selection. In Proceedings of the 16th ACM Conference on Com-
puter and Communications Security (2009), CCS ’09, pp. 380–
389.
[16] ELAHI, T., BAUER, K., ALSABAH, M., DINGLEDINE, R., AND
GOLDBERG, I. Changing of the Guards: A Framework for Un-
derstanding and Improving Entry Guard Selection in Tor. In Pro-
ceedings of the 2012 ACM Workshop on Privacy in the Electronic
Society (2012), WPES ’12, pp. 43–54.
[17] EVANS, N., DINGLEDINE, R., AND GROTHOFF, C. A Practical
Congestion Attack on Tor Using Long Paths.
In Proceedings
of the 18th USENIX Security Symposium (Berkeley, CA, USA,
2009), USENIX Association, pp. 33–50.
[18] HALL, M., FRANK, E., HOLMES, G., PFAHRINGER, B.,
REUTEMANN, P., AND WITTEN, I. H. The WEKA Data Mining
Software: An Update. SIGKDD Explor. Newsl. 11, 1 (November
2009), 10–18.
[19] HERN ´ANDEZ-CAMPOS, F., JEFFAY, K., AND SMITH, F. D.
Tracking the Evolution of Web Trafﬁc: 1995-2003.
In 11th
International Workshop on Modeling, Analysis, and Simulation
of Computer and Telecommunication Systems (MASCOTS 2003),
12-15 October 2003, Orlando, FL, USA (2003), pp. 16–25.
[20] HERRMANN, D., WENDOLSKY, R., AND FEDERRATH, H.
Website Fingerprinting: Attacking Popular Privacy Enhancing
Technologies with the Multinomial Naive Bayes Classiﬁer.
In
Proceedings of the 2009 ACM Workshop on Cloud Computing
Security (2009), CCSW ’09, pp. 31–42.
[21] HOPPER, N., VASSERMAN, E. Y., AND CHAN-TIN, E. How
Much Anonymity does Network Latency Leak? In Proceedings
of the 14th ACM conference on Computer and Communications
Security (October 2007), CCS ’07.
[22] JANSEN, R., TSCHORSCH, F., JOHNSON, A., AND SCHEUER-
MANN, B. The Sniper Attack: Anonymously Deanonymizing
and Disabling the Tor Network.
In 21st Annual Network and
Distributed System Security Symposium, NDSS 2014, San Diego,
California, USA, February 23-26, 2013 (2014).
[23] JOHNSON, A., FEIGENBAUM, J., AND SYVERSON, P. Prevent-
ing Active Timing Attacks in Low-Latency Anonymous Com-
munication. In Proceedings of the 10th Privacy Enhancing Tech-
nologies Symposium (PETS 2010) (July 2010).
[24] JUAREZ, M., AFROZ, S., ACAR, G., DIAZ, C., AND GREEN-
STADT, R. A Critical Evaluation of Website Fingerprinting At-
tacks. In Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security (New York, NY, USA,
2014), CCS ’14, ACM, pp. 263–274.
[25] LEVINE, B. N., REITER, M. K., WANG, C., AND WRIGHT,
M. K. Timing Attacks in Low-Latency Mix-Based Systems.
In Proceedings of Financial Cryptography (February 2004),
pp. 251–265.
[26] LI, W., AND MOORE, A. W. A Machine Learning Approach
for Efﬁcient Trafﬁc Classiﬁcation.
In 15th International Sym-
posium on Modeling, Analysis, and Simulation of Computer and
Telecommunication Systems (MASCOTS 2007), October 24-26,
2007, Istanbul, Turkey (2007), pp. 310–317.
[27] LUO, Y., XIANG, K., AND LI, S. Acceleration of Decision
Tree Searching for IP Trafﬁc Classiﬁcation. In Proceedings of the
4th ACM/IEEE Symposium on Architectures for Networking and
Communications Systems (New York, NY, USA, 2008), ANCS
’08, ACM, pp. 40–49.
[28] MATHEWSON, N.
Some Thoughts on Hidden Services.
https://blog.torproject.org/category/tags/
hidden-services, 2014. Accessed February 2015.
[29] MCCOY, D., BAUER, K., GRUNWALD, D., KOHNO, T., AND
SICKER, D. Shining Light in Dark Places: Understanding the
Tor Network. In Proceedings of the 8th Privacy Enhancing Tech-
nologies Symposium (July 2008), pp. 63–76.
[30] MITTAL, P., KHURSHID, A., JUEN, J., CAESAR, M., AND
BORISOV, N. Stealthy Trafﬁc Analysis of Low-Latency Anony-
mous Communication Using Throughput Fingerprinting. In Pro-
ceedings of the 18th ACM conference on Computer and Commu-
nications Security (2011), CCS ’11, pp. 215–226.
[31] MURDOCH, S. J., AND DANEZIS, G. Low-cost trafﬁc analysis
of tor. In Proceedings of the 2005 IEEE Symposium on Security
and Privacy (Washington, DC, USA, 2005), SP ’05, IEEE Com-
puter Society, pp. 183–195.
[32] ØVERLIER, L., AND SYVERSON, P. Locating Hidden Servers.
In Proceedings of the 2006 IEEE Symposium on Security and Pri-
vacy (May 2006), pp. 100–114.
[33] PANCHENKO, A., NIESSEN, L., ZINNEN, A., AND ENGEL, T.
Website Fingerprinting in Onion Routing Based Anonymization
Networks. In Proceedings of the ACM Workshop on Privacy in
the Electronic Society (WPES) (October 2011), pp. 103–114.
[34] QUINLAN, J. R. C4.5: Programs for Machine Learning. Morgan
Kaufmann Publishers Inc., San Francisco, CA, USA, 1993.
[35] WANG, T., CAI, X., NITHYANAND, R., JOHNSON, R., AND
GOLDBERG, I. Effective Attacks and Provable Defenses for
Website Fingerprinting.
In 23rd USENIX Security Symposium
(USENIX Security 14) (San Diego, CA, Aug. 2014), USENIX
Association, pp. 143–157.
[36] WANG, T., AND GOLDBERG, I. Improved Website Fingerprint-
In Proceedings of the Workshop on Privacy in the
ing on Tor.
Electronic Society (WPES 2013) (November 2013), ACM.
302  24th USENIX Security Symposium 
USENIX Association
16