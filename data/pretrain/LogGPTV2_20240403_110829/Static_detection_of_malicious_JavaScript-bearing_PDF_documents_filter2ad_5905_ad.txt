# Feature and Variable Naming
The following code snippet appears to be defining a feature or variable named `NAME` and performing some operations with it. However, the syntax is unclear and needs to be corrected for better readability and functionality.

```python
# Define a feature or variable
feature_name = "NAME"

# Assign the value of feature_name to var_name
var_name = feature_name

# Assign the value of feature_name to this_name
this_name = feature_name

# Call a method on this_name
result = this_name.method_name()
```

# False Negative Top 5
The following table lists the top 5 false negatives by rank and weight.

| Rank | Weight |
|------|--------|
| 0.01593 | 1     |
| 0.00490 | 98    |
| 0.00394 | 141   |
| 0.00372 | 154   |
| 0.00177 | 355   |

# Features of True Negatives (TNs) and False Negatives (FNs)
The features of TNs and FNs are as follows:

- **Feature 1:** `NAME.NAME`
- **Feature 2:** `NAME.NAME()`
- **Feature 3:** `THIS.NAME`
- **Feature 4:** `THIS.NAME()`
- **Feature 5:** `NAME(THIS.)`

## Table 6: Features of TNs and FNs
| Feature 1 | Feature 2 | Feature 3 | Feature 4 | Feature 5 |
|-----------|-----------|-----------|-----------|-----------|
| NAME.NAME | NAME.NAME() | THIS.NAME | THIS.NAME() | NAME(THIS.) |

# Performance Analysis of PJScan
JavaScript extraction is the most time-consuming part of PJScan. The operation takes approximately 2,041 seconds using a single process, with an average processing time of 31 milliseconds per file. The overall CPU usage was very low (up to 40%, with I/O waiting of up to 30%), while disk utilization remained above 95% during the extraction phase. This indicates that disk throughput is the main performance bottleneck for the application. Using a faster storage device or reading files through a fast network can improve the performance of PJScan.

## Table 7: Processing Time for Different Stages of PJScan in Batch Execution Mode
| Stage       | Total Time (s) | Average Time (s) | Standard Deviation (s) | Percentage (%) |
|-------------|----------------|------------------|------------------------|----------------|
| Extractor   | 180            | 0.0032           | 0.0392                 | 11.63          |
| Tokenizer   | 1,356          | 0.0205           | 0.0015                 | 87.65          |
| Learner     | N/A            | 0.000015         | N/A                    | 0.0009         |
| Classifier  | N/A            | 0.000009         | N/A                    | 0.0006         |

## Table 8: Throughput Characteristics of PJScan
| Category      | Total Time (s) | Average File Size (MB) | Files per Second | Data Throughput (Mbps) | Seconds per File (s) |
|---------------|----------------|------------------------|------------------|------------------------|----------------------|
| Detected      | 1208           | 1.39                   | 33.3             | 370.5                  | 0.030                |
| Undetected    | 339            | 0.106                  | 75.8             | 64.3                   | 0.013                |
| All Files     | 1547           | 0.89                   | 42.6             | 303.5                  | 0.023                |

# Related Work
Detection of malware in PDF documents has not been extensively studied in the research literature. Early approaches, such as those by Li et al. [13] and Shaﬁq et al. [21], used n-gram analysis of raw document content. However, these methods were limited in scope and did not account for modern evasion techniques like object compression and code-level obfuscation. PJScan addresses these limitations by focusing on lexical features of PDF documents.

Recent work, such as MalOffice [10] and MDscan [24], combines static and dynamic analysis. MalOffice uses pdftk20 for static analysis and CWSandbox [26] for dynamic analysis. MDscan, similar to PJScan, uses static analysis to extract JavaScript content but performs detection dynamically using Nemu [16]. PJScan, however, only uses SpiderMonkey for token extraction and performs detection statically, resulting in a significant performance improvement.

# Discussion and Limitations
PJScan's experimental results confirm the practical feasibility of a static, learning-based approach for detecting malicious JavaScript-bearing PDF documents. The preprocessing component can help security administrators manually extract and analyze JavaScript code. The learning component enables the extraction of knowledge from large-scale malware corpora, allowing for lightweight models with negligible performance overhead (<50ms per file). The operational false-positive rate is less than 0.4%, which is acceptable in practice.

However, PJScan has limitations. It may have difficulty accurately discriminating between malicious and benign JavaScript content, as indicated by the high false-positive rate for benign files containing JavaScript. Additionally, PJScan is susceptible to certain obfuscation techniques, such as short JavaScript entry-point code that fetches further code from unexpected document locations. Future work will address these limitations by integrating more extensive static and dynamic analysis techniques.

# Conclusions
PJScan offers a new static approach to detecting malicious JavaScript-bearing PDF documents. It achieves about 85% of the detection accuracy of all antivirus engines at VirusTotal with a performance overhead of less than 50ms per file. It is minimally affected by text-level obfuscation and can be used as a standalone application or integrated into email gateways and HTTP proxies. Future work will explore the integration of static and dynamic analysis techniques to handle code-level obfuscation and improve detection accuracy.

# Acknowledgements
The authors acknowledge financial support from the Heisenberg Fellowship of the Deutsche Forschungsgemeinschaft (DFG) and the German Federal Office for Information Security.

# References
[1] Internet Security Threat Report. Symantec, 2010.
[2] APSB11-03. http://www.adobe.com/support/security/bulletins/apsb11-03.html.
[3] APSB11-08. http://www.adobe.com/support/security/bulletins/apsb11-08.html.
[4] M. Barreno, B. Nelson, A. Joseph, and J. Tygar. The security of machine learning. Machine Learning, 81(2):121–148, 2010.
[5] D. Canali, M. Cova, G. Vigna, and C. Kruegel. Prophiler: a fast filter for the large-scale detection of malicious web pages. In International Conference on World Wide Web (WWW), pages 197–206, 2011.
[6] C.-C. Chang and C.-J. Lin. LIBSVM: a library for support vector machines, 2001. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm.
[7] M. Cova, C. Kruegel, and G. Vigna. Detection and analysis of drive-by-download attacks and malicious JavaScript code. In International Conference on World Wide Web (WWW), pages 281–290, 2010.
[8] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert. ZOZZLE: Fast and precise in-browser JavaScript malware detection. In USENIX Security Symposium, 2011. to appear.
[9] A. Dewald, T. Holz, and F. Freiling. ADSandbox: sandboxing JavaScript to fight malicious websites. In Symposium on Applied Computing (SAC), pages 1859–1864, 2010.
[10] M. Engelberth, C. Willems, and H. T. MalOﬃce – analysis of various application data files. In Virus Bulletin International Conference, 2009.
[11] B. Feinstein and D. Peck. Caffeine Monkey: Automated collection, detection and analysis of malicious JavaScript. In Black Hat USA, 2007.
[12] K. Itabashi. Portable document format malware. Symantec white paper, 2011.
[13] W.-J. Li, S. Stolfo, A. Stavrou, E. Androulaki, and A. Keromytis. A study of malcode-bearing documents. In Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA), pages 231–250, 2007.
[14] J. Nazario. PhoneyC: a virtual client honeypot. In USENIX Workshop on Large-scale Exploits and Emergent Threats (LEET), 2009.
[15] PDF Reference. http://www.adobe.com/devnet/pdf/pdf_reference.html, 2008.
[16] M. Polychronakis, K. Anagnostakis, and E. Markatos. Comprehensive shellcode detection using runtime heuristics. In Annual Computer Security Applications Conference (ACSAC), pages 287–296, 2010.
[17] N. Provos, P. Mavrommatis, M. Abu Rajab, and F. Monrose. All your iFRAMEs point to us. In USENIX Security Symposium, pages 1–16, 2008.
[18] P. Ratanaworabhan, B. Livshits, and B. Zorn. NOZZLE: A defense against heap-spraying code injection attacks. In USENIX Security Symposium, pages 169–186, 2009.
[19] K. Rieck, T. Krüger, and A. Dewald. Cujo: Efficient detection and prevention of drive-by-download attacks. In Annual Computer Security Applications Conference (ACSAC), pages 31–39, 2010.
[20] K. Rieck and P. Laskov. Linear-time computation of similarity measures for sequential data. Journal of Machine Learning Research, 9:23–48, 2008.
[21] Z. Shaﬁq, S. Khayam, and M. Farooq. Embedded malware detection using Markov n-grams. In Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA), pages 88–107, 2008.
[22] R. Sommer and V. Paxson. Outside the closed world: On using machine learning for network intrusion detection. In IEEE Symposium on Security and Privacy, pages 305–316, 2010.
[23] D. Tax and R. Duin. Support vector data description. Machine Learning, 54:45–66, 2004.
[24] Z. Tzermias, G. Sykiotakis, M. Polychronakis, and E. Markatos. Combining static and dynamic analysis for the detection of malicious documents. In European Workshop on System Security (EuroSec), 2011.
[25] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski, S. Chen, and S. King. Automated web patrol with Strider HoneyMonkeys: Finding web sites that exploit browser vulnerabilities. In Network and Distributed System Security Symposium (NDSS), 2006.
[26] C. Willems, T. Holz, and F. Freiling. CWSandbox: Towards automated dynamic binary analysis. IEEE Security and Privacy, 5(2):32–39, 2007.
[27] J. Wolf. OMG WTF PDF. Chaos Communication Congress (CCC), Dec. 2010.