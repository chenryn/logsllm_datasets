no ﬂows are currently hashed to the cell; we refer to this as
0 henceforth. Null with a count of 2 or more represents that
two or more ﬂows have collided at that cell and corresponds
to a DK. Each ﬂow is hashed to k cells (like a standard
Bloom ﬁlter).
The main innovation of the SBF ACSM is that whenever
we have a collision at a location in our ﬁlter among two
or more ﬂows with diﬀerent state values, we encode “don’t
know” in the cell. When doing a lookup on a ﬂow-id in the
ﬁlter, as long as at least 1 value is not DK, a state value
can be returned. (This threshold of 1 could conceivably be
changed to trade oﬀ various errors; we have not found this
Flow: X  State: 3 to 5
Before
2
1
3
0
3
2
0
?
1
0
0
0
X
After
2
1
5
0
5
2
0
?
1
0
0
0
Figure 3: A state change with a SBF ACSM (no
state needs to be given). The hash locations give
the state or possibly a Don’t Know (represented as
a ’ ?’). A cell obtains a ’ ?’ if on an insertion a state
already is stored in the cell.
especially eﬀective, and we do not consider it further here.)
We can deﬁne rules for the various operations. Below,
where we say hash the ﬂow, we mean the operation takes
eﬀect at each cell the ﬂow hashes to.
• Insertion. Hash the ﬂow. If the cell counter is 0, write
the new value and set the count to 1. If the cell value
is DK, increment the count.
If the cell value equals
the ﬂow value, increment the count. If the cell value
does not equal the ﬂow value, increment the count but
change the cell to DK.
• Modify. Hash the ﬂow. If the cell value is DK, leave
it. If the current count is 1, change the cell value. If
current count is exceeds 1, change the cell value to DK.
• Deletion. Hash the ﬂow. If the count is 1, reset cell to
0. If the count it at least 1, decrement count, leaving
the value or DK as is.
• Lookup. Check all cells associated with a ﬂow. If all
cell values are DK, return DK. If all cell values have
value i or DK (and at least one cell has value i), return
i. If there is more than one value in the cells, the item
is not in the set.
If the system is well-behaved, these rules guarantee that
we never return an incorrect value for a ﬂow, although we
may return a “don’t know”. This structure could therefore
be used as an alternative to Bloomier ﬁlter structures in
a dynamic setting. Notice that once there is a collision in
a cell, so that a DK value arises, one must wait for the
cell count to go to 0 before the cell is reset from DK to
0. This requires that the system is well-behaved; otherwise,
deletions must be handled via a timing-based mechanisms.
As with the DBF ACSM, we can provide an analysis for
the SBF ACSM under the assumption the system is well-
behaved. For convenience here we consider the case of in-
sertions only; to handle deletions, one must have a model
of deletions so as to account for the DK values as described
above. Suppose we have m cells, n ﬂows, and k hash func-
tions. Further let ni be the number of ﬂows with state value
i. The probability x ∈ S with value i yields a don’t know is
equivalent to the probability that each of its cells are hashed
to by some element with a value that is not i. This is then
easily computed using the standard Bloom ﬁlter analysis as
“
1 − (1 − 1/m)
k(n−ni)
1 − e−k(n−ni)
“
”k ≈
”k
.
The probability that x /∈ S yields a false positive with value
”!k
“
DK is
1−(1−1/m)
“
1−(1−1/m)
 X
”k−
(1−1/m)
k(n−ni)
kn
kni
,
i
as this is just the probability each cell for x is hashed to by
some ﬂow, subtracting oﬀ the probability each cell is hashed
to only by ﬂows with only one value. The probability that
x /∈ S yields a false positive with value i can be approxi-
mated by assuming that x hashes to k distinct cells, ﬁnding
the probability that each of the k cells gives either an i or
a DK, and subtracting oﬀ the probability x /∈ S yields a
false positive with value DK. (The expression is long but
not complex.)
As before, when using timing, we do not need to keep
counters, as every DK state is equivalent regardless of the
count; we can simply wait for a timer event to reset a cell.
In this case, we detect when two ﬂows share a cell only on
an insertion; on an insertion, any non-zero cell becomes a
DK. Again, in this setting, an invalid state transition can
incorrectly change cell values, leading to future errors. An
example of a state change under a SBF ACSM (without
counters) is given in Figure 3.
When the system is not well-behaved, there are further
issues to deal with. As mentioned, if a ﬂow is not properly
terminated, then the ﬁlter will become polluted, causing in-
creased DK return values. This is handled using timing-
based mechanisms. Also, it is possible for spurious packets
to disrupt the ﬁlter, by causing a state transition when one
should not occur, although this can only happen if there is
a false positive for a speciﬁc state value. The eﬀects of this
problem are less severe than for the direct Bloom ﬁlter ap-
proach; the most likely outcome is a false negative (rather
than a false return state) as the cells for a ﬂow may then not
have matching states. Spurious packets can also introduce
DK values similarly.
3.4 An Approach Using d-left Hashing
Although the SBF ACSM has reasonable performance, we
have found that for most settings an approach using d-left
hashing in combination with ﬁngerprints gives better perfor-
mance. We call this a ﬁngerprint-compressed ﬁlter (FCF)
ACSM. A great advantage of the FCF ACSM is that there
are a few key parameters that can be ﬁne-tuned for various
performance tradeoﬀs. The application of d-left hashing in
combination with ﬁngerprints is interesting in its own right;
for example, in Section 4 we also show how this technique
can be used to obtain a data structure with the same func-
tionality as a counting Bloom ﬁlter, using much less space.
The basic idea is very simple: store a ﬁngerprint of the
ﬂow-id along with the ﬂow’s current state in a hash table.
If the set were static, and there was suitably eﬃcient per-
fect hash function for the set of ﬂows, this would suﬃce [3,
17]. (Recall a perfect hash function maps a ﬁxed set to a
range without collisions.) As we are in a dynamic setting,
perfect hash functions are generally not eﬃcient for the pur-
poses we consider. We demonstrate that instead using d-left
hashing (in combination with timing mechanisms) provides
an eﬃcient alternative. While the similarities between per-
fect hash functions and d-left hashing were noted previously
in [3], this application appears entirely novel.
For good usage of space and quick, ﬁxed lookup times, no
pointers should be used. Instead, we adopt a hash table with
a ﬁxed size, and a ﬁxed number of ﬂows that can be stored
in each hash bucket. We call this ﬁxed number of ﬂows the
height of the bucket. Each bucket will therefore be assigned
a ﬁxed amount of space, corresponding to the number of
ﬂows that can be held. If fewer ﬂows than the maximum
are stored in a bucket, we assume that the remaining space
is ﬁlled by empty ﬂows, which are signaled in a speciﬁc way,
say with an entry of all zeroes.
In order to eﬃciently use the space available in the hash
table under these conditions, as well as make the probabil-
ity of a bucket overﬂow appropriately small, we can apply
d-left hashing, as explained in [3]. We provide a summary
here. In the d-left scheme, the hash table is broken up into
d subtables, ordered for convenience from left to right; gen-
erally these subtables are of equal size (although technically
this is not necessary). When a ﬂow is placed in the hash
table, it has d possible locations, one in each subtable, with
the location in each subtable given by independent uniform
hashes of the item. (Many practical hash functions approx-
imate this behavior reasonably in practice.) The d possible
buckets are examined, and the item is placed in the bucket
holding the fewest items; in case of ties, ties are broken to
the left. The number of items in a bucket is also called its
load. This is a particularly eﬃcient variation of using multi-
ple choices in hashing, giving extremely balanced loads, and
in particular very small maximum loads.
Notice the number of diﬀerent parameters and can choose
in setting up an ACSM in this way: the number of hash
functions d; the number of buckets b of each subblock of the
hash table; the height h of each bucket; the size f of the
ﬁngerprint in bits. Assuming x additional bits for each ﬂow
(to represent the state and the timer bit) gives a total space
of dbh(f + x) bits for the hash table.
The settings of d, b and h must be such so that the prob-
ability of an overﬂow is very small. (We note that also a
small TCAM could be added to handle hash table over-
ﬂows if their probability is suﬃciently small. While a small
TCAM would be recommended in practice, appropriate de-
sign should make overﬂows extremely rare, as we describe,
and we ignore this in the subsequent analysis.) The uti-
lization u of the table is the fraction of occupied cells; if
we have n ﬂows and dbh cells then u = n/(dbh). A typical
conﬁguration, given as an example in [3], considers the case
where d = 3, h = 6, and b = n/12. This gives a utilization
of u = 2/3. In this case, the asymptotic fraction of buck-
ets that overﬂow (in the case of insertions only) is approx-
imately 5.6 · 10
−31 [3]; even with insertions and deletions
of items, overﬂow events are remarkably rare. This sug-
gests that overﬂow, while it needs to be considered, can be
handled straightforwardly with this structure. Also, higher
utilizations and hence less overall space is possible by using
larger values of d, f , and h (and correspondingly smaller
values of b).
Even in the case where ﬂows are well-behaved, ﬂows can
yield false positives or DK values. A false positive occurs
if a lookup is performed on a non-extant ﬂow and a ﬁnger-
print matches. As each ﬁngerprint matches with probability
−f , a simple union bound gives an upper bound of dh2
−f .
2
Similarly, a DK value could arise if the ﬁngerprint for a ﬂow
appeared in two buckets that the ﬂow hashed to. Such an
occurrence would also, of course, make it impossible to per-
form a deletion in a valid manner (as we would not know
which entry to delete – this is why the problem is easier to
Flow: X    Fingerprint: 11110101001000111    State: 3 to 5
Fingerprint
State
X
10001110011111100   3
01110100100010111   1
01110010010101111   6
11110101001000111   3
11110111001001011   2
00011110011101101   1
11111111110000000   4
10101110010101011   2
01110010001011111   3
11100010010111110   1
Figure 4: A state change with an FCF ACSM. First,
the three buckets associated with ﬂow X are found.
When the appropriate ﬁngerprint is found, the state
can be changed. Alternatively, if the ﬂow is deleted
and re-inserted, it could be re-placed into the left-
most of the least loaded buckets.
handle with a static set and a perfect hash function). If a
DK is found on a lookup, and a state change is required,
it may be appropriate to change the state of both items to
a special DK value; this depends on the application. DK
values can also be handled using a TCAM, to store ﬂow-ids
that yield a DK in the data structure explicitly.
Finally, it is worth noting that on a state change, there are
two possible ways of accomplishing the change. First, one
could simply change the state of the appropriate ﬁngerprint
as found in the table. Second, one could delete the current
state and re-insert the new state; this may cause a change
in the location of the ﬁngerprint, if there is an alternative
bucket with a smaller load. The ﬁrst approach requires less
work, and the second approach will do a slightly better job
keeping the load evenly distributed. See Figure 4 for an
example.
As with our other schemes, issues become more compli-
cated if the system is ill-behaved, as non-extant ﬂows can
change the state for extant ﬂows. To cope with this, the ﬁn-
gerprint should be chosen to keep false positives suﬃciently
rare. Also, timing-based deletions must be used to remove
the ﬁngerprint of non-terminating ﬂows.
4. AN ALTERNATIVE COUNTING BLOOM
FILTER
Using the same approach as for our FCF ACSM, we can
construct a variation of a counting Bloom ﬁlter that we dub
the d-left counting Bloom ﬁlter, or d-left CBF. The d-left
CBF uses less space than a standard counting Bloom ﬁl-
ter, with the same functionality of tracking a dynamically
changing set of items under insertions and deletions. We of-
fer a brief sketch here; the d-left CBF is more fully described
in an additional paper [6]. The analysis of the d-left CBF
informs why this approach is also eﬀective in the design of
ACSMs.
Again, the idea is to store a ﬁngerprint of each item in a
d-left hash table, with the intuition that d-left hashing pro-
vides a suﬃciently good approximation to perfect hashing.
For an insertion, we insert the ﬁngerprint in the least loaded
subtable (breaking ties to the left); for a lookup, we look for
the ﬁngerprint; and for a deletion, we remove the ﬁnger-
print. We still have the potentially problematic issue, how-
ever, that if a ﬁngerprint associated with an items appears in
multiple places, we cannot perform a deletion eﬀectively, as
we are not sure which copy of the ﬁngerprint to delete. We
avoid this problem by introducing a trick that ensures that
we have never have multiple ﬁngerprints associated with an
item in the hash table.
For convenience we assume each subtable has size a power
of 2, say b = 2z, and we are using f bit ﬁngerprints. First,
each item is hashed using a (pseudo-)random hash function
into f + z bits; for an item x, call this bit string S(x). We
then use d (pseudo-)random permutations h1, h2, . . . , hd on
the string S(x) of f + z bits; the ﬁrst f bits of hi(S(x)) give
the ﬁngerprint that will be used for x in the ith subtable,
and the last z bits of hi(S(x)) give the index of hi(S(x)) in
the ith subtable. Note that the ﬁngerprint associated with
an item x can vary according to the subtable. Each cell
in the table will consist of both a ﬁngerprint and a small
counter (generally 2 bits will suﬃce). We use the counter as
follows: if, when inserting an item, we see its ﬁngerprint al-
ready exists in a subtable, we simply increment the counter
for that ﬁngerprint, rather than insert another ﬁngerprint
in a diﬀerent subtable. On deletion a counter can be decre-
mented.
By using these permutations, we avoid the problem of
ever having two ﬁngerprints associated with an item appear