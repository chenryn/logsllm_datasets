trigger
words) to have large probability values. Therefore, we propose
a delayed normalization strategy in which the dimension
values are normalized (to sum of 1) in every 30 epochs. The
relaxation empirically enlarges the chance of success.
Example. Consider a trojaned model #47 from TrojAI round
6 with a trigger “supposing knowingly screaming immune
ﬁxer stances”. The bar charts in Figure 11 show how a few
dimension values (including that for the trigger word ‘im-
mune’) change with per-epoch normalization (a) and delayed
normalization (b). For each word on the x axis, the bars from
left to the right denote the results after increasing optimization
epochs. Observe ‘immune’ stands out in the later case. (cid:2)
Loss Function. We use four terms in the loss function. The
ﬁrst term is the cross-entropy loss that aims to induce mis-
classiﬁcation to the target label (cid:5). Note that it does not mean
we know the target label beforehand. PICCOLO scans each
output label, that is, considering each as the possible target
label. The second term is the dot product of the representation
embedding and the CLS dimension importance vector I(cid:6). The
intuition is that the inverted trigger word should yield large
values at the CLS dimensions that the classiﬁer Mcls2y deems
important. The third term is to reduce the dimension values
in the trigger word vector x until there is only one dimension
whose value exceeds 0.5. This is to help selecting good trigger
word candidates, avoiding too many dimensions having close
to 1 values. The fourth term is to ensure the inverted trigger
does not induce the same misclassiﬁcation on a random benign
model (on the same dataset). It is optional as benign models
may not be available. Let xz be the word vector with the tanh
function, deﬁned in Equation (8), and yz the classiﬁcation
result deﬁned in Equation (4), (cid:5)0 the victim label and y(cid:2)
z
the classiﬁcation of the benign model. The loss function is
formally deﬁned as follows.
w1 · Lce (yz, (cid:5)) + w2 · r (cid:4) I(cid:6)+
arg min
z
w3 · sum(xz) + w4 · Lce (y(cid:2)
z, (cid:5)0),
with w3 = wlarge if count(xz > 0.5) > 2 else 0,
(9)
w1, w2, wlarge , w4 > 0,
xz = (tanh(z) + 1)/2,
r = T (xz × Mw2t × Mt2e) the rep. embedding
Design justiﬁcation. Our choices of the optimization method,
loss function and hyper-parameters are empirical, which is
typical in the literature. We perform an ablation study of using
tanh and delayed normalization on the TrojAI round 6 test
set. The overall accuracy of PICCOLO decreases from 0.907
to 0.776 when changing tanh and delayed normalization to
softmax. The details are in Appendix IX-G.
E. Trigger Validation
The validation step checks the ASR of the likely trigger
words. Speciﬁcally, we select the words corresponding to the
10 most likely trigger words in DistilBERT, and 20 in GPT.
With the 2 inverted word vectors in our implementation, in
total there are 20 in DistilBERT and 40 in GPT. We ﬁrst test
the ASRs of individual words or word pairs. If any of the ASRs
exceed 0.9, we consider the subject model trojaned. Otherwise,
we further test if the model is particularly discriminative for
any of these words. Speciﬁcally, we train a linear model for
each of these words w as mentioned before and acquire the
linear weight vector θ for the word. Note that such training is
very fast. We further acquire the dimension importance vector
I(cid:6) for the target label. If the dot product of the two exceeds
170, we consider the model trojaned.
VI. EVALUATION
We evaluate PICCOLO with various model architectures,
application tasks, and a range of backdoor types. We com-
pare with two state-of-the-art techniques GBDA [36] and T-
miner [38]. In addition, we study PICCOLO’s efﬁciency and its
performance against advanced attacks and adaptive attacks. We
also carry out an ablation study to investigate each component
of PICCOLO. PICCOLO is implemented in PyTorch [53] and
will be released upon publication.
A. Experiment Setup
Datasets and Models. We leverage 3,256 models (half benign
and half backdoored) from the training and test sets of TrojAI
rounds 5-7 [39]. As PICCOLO does not require training, we use
all these models for evaluation. We also train 103 GRU models
from T-miner [38], and 120 BERT classiﬁcation models and
120 LSTM models from hidden killer [8] on SST-2 [40],
OLID [54] and AG news [55]. For the combination lock
attack [9], we train 240 BERT classiﬁcation models on SST-
2, OLID and AG news. For adaptive attacks, we use TrojAI
ofﬁcial repository [39] to generate 730 backdoored DistilBERT
classiﬁcation models. The details of experiment setup are in
Appendix IX-E.
B. Effectiveness of PICCOLO
Table II and Table III present
the detection results. In
Table II, the ﬁrst column shows the evaluation sets. The second
column shows the model architectures. Columns 3-7 show the
results of PICCOLO. Columns 8-12 and columns 13-17 show
the results of GBDA and T-miner, respectively. Columns TP,
FP, FN, and TN denote the number of true positives, false
positives, false negatives, and true negatives, respectively. Col-
umn Acc presents the overall detection accuracy. As GBDA
and T-miner were designed for NLP classiﬁcation tasks and
cannot be easily adapted to NER tasks, we hence evaluate
them only on TrojAI rounds 5-6 models and T-miner models.
Besides, due to the low efﬁciency of T-miner, we only evaluate
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:09 UTC from IEEE Xplore.  Restrictions apply. 
102034
Evaluation Set
Arch.
TrojAI R5 train
TrojAI R5 test
TrojAI R6 train
TrojAI R6 test
TABLE II: Effectiveness of PICCOLO on classiﬁcation tasks
PICCOLO
FN
35
23
33
14
16
19
1
2
14
13
6
TN
199
202
195
69
68
67
11
12
114
108
39
Acc
0.894
0.898
0.877
0.885
0.873
0.858
0.917
0.917
0.917
0.896
0.942
TP
325
188
224
70
69
66
11
10
106
107
58
FP
27
21
26
4
4
3
1
0
6
12
0
DistilBERT
BERT
GPT
DistilBERT
BERT
GPT
DistilBERT
GPT
DistilBERT
GPT
GRU
TP
254
118
140
47
67
59
10
6
75
90
57
FP
88
28
27
11
19
11
3
1
40
30
0
GBDA
FN
106
93
117
37
18
26
2
5
45
30
7
TN
138
195
194
62
53
59
9
12
80
90
39
Acc
0.677
0.721
0.700
0.694
0.764
0.761
0.792
0.750
0.646
0.750
0.932
T-miner*
FP
4
6
16
2
3
1
3
2
1
4
4
FN
330
170
223
41
39
43
10
9
46
45
8
TN
222
217
205
48
47
49
9
10
49
46
35
Acc
0.430
0.594
0.500
0.57
0.58
0.56
0.458
0.542
0.53
0.51
0.883
TP
30
41
34
9
11
7
2
3
4
5
56
T-miner models
*Due to T-miner running too slow, we test T-miner on randomly sampled 100 models on R5-test and R6-test dataset
TABLE III: Effectiveness of PICCOLO on NER tasks
Acc
Evaluation Set
0.979
0.938
0.938
0.917
0.917
0.896