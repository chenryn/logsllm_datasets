in-depth” approach to address this challenge, as extreme
outliers can be captured quite effectively by manual rules.
It still remains an open question to address such outliers
within the DEC framework.
• DEC, like other supervised or semi-supervised machine
learning systems, is heavily dependent on the quality of its
training data labels. Adversaries that manage to induce in-
accurate human labeling at scale may be able to manipulate
or interfere with DEC’s classiﬁcations. We are constantly
working to improve our labeling process to address any
observed or potential limitations.
Even with these limitations, our evaluation on production data
at Facebook indicates that DEC offers better performance than
traditional detection approaches.
9 Conclusion
We have presented Deep Entity Classiﬁcation (DEC), a ma-
chine learning framework developed to detect abusive ac-
counts in OSNs. Our framework addresses two problems in
the existing abuse detection systems: First, its “deep feature”
extraction method creates features that are powerful for classi-
ﬁcation and (thus far) show no signs of the adversarial adapta-
tion typical for account or behavioral features. Second, it uses
a novel machine learning training framework to leverage both
high-quantity, low-precision and low-quantity, high-precision
training data to improve model performance.
Our evaluation on production data at Facebook indicates
that DEC offers better performance than traditional detection
USENIX Association
30th USENIX Security Symposium    4111
approaches. Moreover, DEC’s performance is stable over time,
suggesting that it is robust to adversarial adaptation. During
DEC’s deployment for more than two years at Facebook, it
has detected hundreds of millions of abusive accounts. We
estimate that DEC is responsible for a 27% reduction in the
volume of active abusive accounts on the platform.
10 Acknowledgements
Many individuals at Facebook contributed to the development
of DEC and to this publication. Among them we would like
to thank Daniel Bernhardt, Scott Renfro, Vishwanath Sarang,
and Gregg Stefancik.
We would also like to thank the anonymous reviewers
for their valuable feedback that substantially improved this
work’s quality.
References
[1] Leman Akoglu, Hanghang Tong, and Danai Koutra.
Graph based anomaly detection and description: A sur-
In Data mining and knowledge discovery, vol-
vey.
ume 29, pages 626–688, 2015.
[2] Raman Arora, Ofer Dekel, and Ambuj Tewari. Online
bandit learning against an adaptive adversary: From
regret to policy regret. arXiv preprint arXiv:1206.6400,
2012.
[3] Fabricio Benevenuto, Gabriel Magno, Tiago Rodrigues,
and Virgilio Almeida. Detecting spammers on Twitter.
In Collaboration, electronic messaging, anti-abuse and
spam conference (CEAS), volume 6, page 12, 2010.
[4] Elie Bursztein.
How to successfully har-
https:
to combat fraud and abuse.
ness AI
//elie.net/talk/how-to-successfully-
harness-ai-to-combat-fraud-and-abuse/,
2018. RSA.
[5] Qiang Cao, Michael Sirivianos, Xiaowei Yang, and
Tiago Pregueiro. Aiding the detection of fake accounts
in large scale social online services. In USENIX NSDI,
pages 15–15, 2012.
[6] Rich Caruana. Multitask learning. In Machine learning,
volume 28, pages 41–75. Springer, 1997.
[7] David A Cohn, Zoubin Ghahramani, and Michael I Jor-
dan. Active learning with statistical models. Journal of
artiﬁcial intelligence research, 4:129–145, 1996.
[8] Nilesh Dalvi, Pedro Domingos, Sumit Sanghai, Deepak
Verma, et al. Adversarial classiﬁcation. In SIGKDD
conference on knowledge discovery and data mining
(KDD), pages 99–108. ACM, 2004.
[9] George Danezis and Prateek Mittal. Sybilinfer: Detect-
ing sybil nodes using social networks. In NDSS, pages
1–15, 2009.
[10] Louis DeKoven, Trevor Pottinger, Stefan Savage, Geof-
frey Voelker, and Nektarios Leontiadis. Following their
footsteps: Characterizing account automation abuse and
defenses. In Internet Measurement Conference (IMC),
pages 43–55. ACM, 2018.
[11] John Duchi, Elad Hazan, and Yoram Singer. Adaptive
subgradient methods for online learning and stochastic
optimization. Journal of machine learning research,
12(Jul):2121–2159, 2011.
[12] Facebook.com.
https://www.facebook.com/
communitystandards/, 2019.
[13] Facebook.com. https://www.facebook.com/help/
287137088110949, 2019.
[14] Facebook.com. https://www.facebook.com/help/
166863010078512?helpref=faq_content, 2019.
[15] Facebook.com.
https://www.facebook.com/
communitystandards/objectionable_content,
2019.
[16] Facebook.com.
https://www.facebook.com/
communitystandards/safety, 2019.
[17] Alhussein Fawzi, Omar Fawzi, and Pascal Frossard.
Analysis of classiﬁers’ robustness to adversarial per-
In Machine learning, volume 107, pages
turbations.
481–508. Springer, 2018.
[18] Michael Fire, Gilad Katz, and Yuval Elovici. Strangers
intrusion detection: Detecting spammers and fake pro-
ﬁles in social networks based on topology anomalies. In
Human journal, volume 1, pages 26–39, 2012.
[19] David Mandell Freeman. Can you spot the fakes?: On
the limitations of user feedback in online social net-
works. In Proceedings of the 26th International Confer-
ence on World Wide Web, pages 1093–1102, 2017.
[20] Jerome H Friedman. Greedy function approximation: A
gradient boosting machine. Annals of statistics, pages
1189–1232, 2001.
[21] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth
Garg. Badnets: Identifying vulnerabilities in the ma-
chine learning model supply chain. arXiv preprint
arXiv:1708.06733, 2017.
[22] Geoffrey E Hinton and Ruslan R Salakhutdinov. Reduc-
ing the dimensionality of data with neural networks. In
Science, volume 313, pages 504–507, 2006.
4112    30th USENIX Security Symposium
USENIX Association
[23] Piotr Indyk and Rajeev Motwani. Approximate nearest
neighbors: Towards removing the curse of dimensional-
ity. In ACM symposium on theory of computing, pages
604–613. ACM, 1998.
[24] Ashesh Jain, Amir R Zamir, Silvio Savarese, and
Ashutosh Saxena. Structural-RNN: Deep learning on
In Proceedings of the IEEE
spatio-temporal graphs.
conference on computer vision and pattern recognition,
pages 5308–5317, 2016.
[25] Meng Jiang, Peng Cui, and Christos Faloutsos. Suspi-
cious behavior detection: Current trends and future di-
rections. In IEEE intelligent systems, volume 31, pages
31–39. IEEE, 2016.
[26] Xin Jin, C Lin, Jiebo Luo, and Jiawei Han. A data
mining-based spam detection system for social media
In Proceedings of the VLDB endowment,
networks.
volume 4, pages 1458–1461, 2011.
[27] Thomas N Kipf and Max Welling. Semi-supervised
classiﬁcation with graph convolutional networks. arXiv
preprint arXiv:1609.02907, 2016.
[28] W. Koehrsen.
Embeddings in neural network.
https://towardsdatascience.com/neural-
network-embeddings-explained-4d028e6f0526,
2018.
[29] Xiangnan Kong, Jiawei Zhang, and Philip S Yu. Infer-
ring anchor links across multiple heterogeneous social
networks. In International conference on information &
knowledge management, pages 179–188. ACM, 2013.
[30] Fedor Kozlov, Isabella Yuen, Jakub Kowalczy, Daniel
Bernhardt, David Freeman, Paul Pearce, and Ivan Ivanov.
A method for evaluating changes to fake account veriﬁ-
cation systems. In RAID, 2020.
[31] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
Deep learning. In Nature, volume 521, page 436, 2015.
[32] Kyumin Lee, James Caverlee, and Steve Webb. Un-
covering social spammers: Social honeypots + machine
learning. In Conference on Research and Development
in Information Retrieval (SIGIR), 2010.
[33] Qimai Li, Zhichao Han, and Xiao-Ming Wu. Deeper
insights into graph convolutional networks for semi-
supervised learning. In Thirty-Second AAAI Conference
on Artiﬁcial Intelligence, 2018.
[34] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and
Richard Zemel. Gated graph sequence neural networks.
arXiv preprint arXiv:1511.05493, 2015.
[35] Guanjun Lin, Nan Sun, Surya Nepal, Jun Zhang, Yang
Xiang, and Houcine Hassan. Statistical Twitter spam
detection demystiﬁed: Performance, stability and scala-
bility. In IEEE access, volume 5, pages 11142–11154.
IEEE, 2017.
[36] Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee,
Juan Zhai, Weihang Wang, and Xiangyu Zhang. Trojan-
ing attack on neural networks. In NDSS, 2017.
[37] Anshu Malhotra, Luam Totti, Wagner Meira Jr, Pon-
nurangam Kumaraguru, and Virgilio Almeida. Study-
ing user footprints in different online social networks.
In International conference on advances in social net-
works analysis and mining (ASONAM), pages 1065–
1070. IEEE Computer Society, 2012.
[38] Shirin Nilizadeh, Francois Labrèche, Alireza Sedighian,
Ali Zand, José Fernandez, Christopher Kruegel, Gian-
luca Stringhini, and Giovanni Vigna. Poised: Spotting
Twitter spam off the beaten paths. In CCS, 2017.
[39] Sinno Jialin Pan and Qiang Yang. A survey on transfer
learning. IEEE Transactions on knowledge and data
engineering, 22(10):1345–1359, 2009.
[40] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deep-
walk: Online learning of social representations. In Pro-
ceedings of the 20th ACM SIGKDD international con-
ference on Knowledge discovery and data mining, pages
701–710, 2014.
[41] Lorien Y Pratt. Discriminability-based transfer between
In Advances in neural information
neural networks.
processing systems, pages 204–211, 1993.
[42] PyTorch. https://pytorch.org/.
[43] David Saad. Online algorithms and stochastic approxi-
mations. Online Learning, 5:6–3, 1998.
[44] United States Securities
Facebook archive form 10-q.
mission.
//www.sec.gov/Archives/edgar/data/1326801/
000132680117000007/fb-12312016x10k.htm, 2016.
and Exchange Com-
https:
[45] United States Securities
Facebook archive form 10-q.
mission.
//www.sec.gov/Archives/edgar/data/1326801/
000132680118000067/fb-09302018x10q.htm, 2018.
and Exchange Com-
https:
[46] Burr Settles. Active learning literature survey. Technical
report, University of Wisconsin-Madison Department
of Computer Sciences, 2009.
[47] Ali Shafahi, W Ronny Huang, Mahyar Najibi, Octavian
Suciu, Christoph Studer, Tudor Dumitras, and Tom Gold-
stein. Poison frogs! targeted clean-label poisoning at-
tacks on neural networks. In Advances in Neural Infor-
mation Processing Systems, pages 6103–6113, 2018.
USENIX Association
30th USENIX Security Symposium    4113
[48] Tao Stein, Erdong Chen, and Karan Mangla. Facebook
immune system. In Workshop on social network systems,
page 8. ACM, 2011.
[49] Gianluca Stringhini, Christopher Kruegel, and Giovanni
Vigna. Detecting spammers on social networks. In An-
nual Computer Security Applications Conference (AC-
SAC), 2010.
[50] Gianluca Stringhini, Pierre Mourlanne, Gregoire Jacob,
Manuel Egele, Christopher Kruegel, and Giovanni Vi-
gna. EVILCOHORT: Detecting communities of mali-
cious accounts on online services. In USENIX Security,
2015.
[51] Enhua Tan, Lei Guo, Songqing Chen, Xiaodong Zhang,
and Yihong Zhao. UNIK: Unsupervised social network
spam detection. In International conference on informa-
tion & knowledge management, pages 479–488. ACM,
2013.
[52] Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin,
Abhinav Gupta, and Serge J Belongie. Learning from
noisy large-scale datasets with minimal supervision. In
CVPR, pages 6575–6583, 2017.
[53] A. H. Wang. Don’t follow me: Spam detection in Twit-
ter. In Conference on Security and Cryptography (SE-
CRYPT), 2010.
[54] Gang Wang, Tristan Konolige, Christo Wilson, Xiao
Wang, Haitao Zheng, and Ben Y. Zhao. You are how
you click: Clickstream analysis for sybil detection. In
USENIX Security, 2013.
[55] Felix Wu, Tianyi Zhang, Amauri Holanda de Souza Jr,
Christopher Fifty, Tao Yu, and Kilian Q Weinberger.
arXiv
Simplifying graph convolutional networks.
preprint arXiv:1902.07153, 2019.
[56] XGBoost. https://xgboost.ai/.
[57] Cao Xiao, David Mandell Freeman, and Theodore Hwa.
Detecting clusters of fake accounts in online social net-
works. In Workshop on artiﬁcial intelligence and secu-
rity, pages 91–101. ACM, 2015.
[58] Chao Yang, Robert Chandler Harkreader, and Guofei
Gu. Die free or live hard? empirical evaluation and
new design for ﬁghting evolving Twitter spammers. In
Conference on Recent Advances in Intrusion Detection
(RAID), 2011.
[59] Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao,
Ben Y. Zhao, and Yafei Dai. Uncovering social network
sybils in the wild. In Internet Measurement Conference
(IMC), 2011.
[60] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod
Lipson. How transferable are features in deep neural
networks? In Proceedings of the Conference on Neural
Information Processing Systems, 2014.
[61] Haifeng Yu. Sybil defenses via social networks: A tu-
torial and survey. In ACM SIGACT news, volume 42,
pages 80–101. ACM, 2011.
[62] Haifeng Yu, Phillip B Gibbons, Michael Kaminsky, and
Feng Xiao. Sybillimit: A near-optimal social network
defense against sybil attacks. In Symposium on security
and privacy, pages 3–17. IEEE, 2008.
[63] Haifeng Yu, Michael Kaminsky, Phillip B Gibbons, and
Abraham Flaxman. Sybilguard: Defending against sybil
attacks via social networks. In ACM SIGCOMM com-
puter communication review, volume 36, pages 267–278.
ACM, 2006.
[64] Yao Zhao, Yinglian Xie, Fang Yu, Qifa Ke, Yuan Yu,
Yan Chen, and Eliot Gillum. Botgraph: Large scale
spamming botnet detection. In USENIX NSDI, 2009.
4114    30th USENIX Security Symposium
USENIX Association