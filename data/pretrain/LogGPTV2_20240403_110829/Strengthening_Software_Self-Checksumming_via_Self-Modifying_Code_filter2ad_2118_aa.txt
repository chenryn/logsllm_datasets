title:Strengthening Software Self-Checksumming via Self-Modifying Code
author:Jonathon T. Giffin and
Mihai Christodorescu and
Louis Kruger
Strengthening Software Self-Checksumming
via Self-Modifying Code∗
Jonathon T. Gifﬁn
Mihai Christodorescu
Louis Kruger
Computer Sciences Department
University of Wisconsin
{gifﬁn,mihai,lpkruger}@cs.wisc.edu
Abstract
Recent research has proposed self-checksumming as a
method by which a program can detect any possibly mali-
cious modiﬁcation to its code. Wurster et al. developed an
attack against such programs that renders code modiﬁca-
tions undetectable to any self-checksumming routine. The
attack replicated pages of program text and altered values
in hardware data structures so that data reads and instruc-
tion fetches retrieved values from different memory pages. A
cornerstone of their attack was its applicability to a variety
of commodity hardware: they could alter memory accesses
using only a malicious operating system.
In this paper,
we show that their page-replication attack can be detected
by self-checksumming programs with self-modifying code.
Our detection is efﬁcient, adding less than 1 microsecond
to each checksum computation in our experiments on three
processor families, and is robust up to attacks using either
costly interpretive emulation or specialized hardware.
1. Introduction
Tamper resistant software attempts to protect itself from
unwanted modiﬁcation by a malicious user of the software
[5, 22]. The software provides some functionality desired
by the user but contains additional code that the user ﬁnds
undesirable. For example, commercial software frequently
includes a license veriﬁcation that an illegal user of the soft-
ware may wish to circumvent. The user may attempt to alter
the program’s code to remove or bypass the license check.
To protect their code and limit its illicit use, software pro-
ducers can introduce protections against manipulation, such
as obfuscated code [9, 15, 25], and manipulation detectors,
such as self-checksumming [7, 13]. Enforcement of digital
∗This work was supported in part by the Ofﬁce of Naval Research under
contract N00014-01-1-0708. Jonathon T. Gifﬁn was partially supported by
a Cisco Systems Distinguished Graduate Fellowship.
rights [11] and protection of processes executing remotely
on untrusted hosts [18, 19] similarly require detection of
code manipulation.
Self-checksumming is one technique by which a pro-
cess can detect unexpected modiﬁcations to its code. As
it executes, the process computes checksums of the instruc-
tions in its code segment. Any value that disagrees with a
checksum precomputed by the software producer indicates
that code modiﬁcation has occurred. Self-checksumming
processes implicitly assume that main memory is von Neu-
mann: code and data share the same memory address space
[24]. On a von Neumann machine, code read by the check-
sum veriﬁcation routines is the same code fetched by the
processor for execution.
Wurster et al. [23, 27, 28] successfully defeated self-
checksumming by violating this implicit assumption. Using
a modiﬁed operating system, they replicated memory pages
containing program code so that data reads and instruction
fetches at the same virtual address accessed different physi-
cal addresses. The attack created a virtual Harvard memory
architecture [2, 3] with distinct instruction and data memo-
ries. A malicious user can alter execution by changing code
in the instruction memory yet remain undetected by check-
sum routines that read from the data memory.
In their discussion of
the page-replication attack,
Wurster et al. stated:
The attack strategy outlined is devastating to the
general approach of self-integrity protection by
checksumming. [28]
While it is true that their attack defeated existing techniques
that implicitly relied upon the von Neumann assumption,
the attack is not an end to self-checksumming. We show in
this paper that processes can use self-modifying code to de-
tect the page-replication attack. Memory write operations
in a Harvard architecture change the data memory but not
the code memory. Our detection algorithm modiﬁes a code
sequence using memory writes and then checks whether the
modiﬁed code is visible to both instruction fetches and data
reads. More speciﬁcally, we generate code I2 for which the
checksum is previously known at a virtual memory address
A containing a different code sequence I1. We then both ex-
ecute the code at A and compute its checksum. If the code
executed was the original, unchanged I1 but the computed
checksum matches that of I2, then the memory is Harvard
and the modiﬁed code was written only to the data mem-
ory. Only when both the executed code and the computed
checksum match I2 can we conclude that that memory is
von Neumann. This detection works even when the Harvard
architecture is simulated in software on a von Neumann ma-
chine, as done by Wurster et al. The algorithm is efﬁcient,
using only 68 to 1,773 clock cycles (90 to 969 nanoseconds)
in our tests on x86, SPARC, and PowerPC processors.
We show in Section 4.1 that an attacker can defeat our
detection only with custom hardware or by incurring the se-
vere performance cost of interpretive emulation. To evade
detection, the attacker must emulate memory reads or writes
or instruction fetches, which requires trapping and interpret-
ing of instructions. By interleaving program code and data
on the same memory pages, we can limit the possibility that
attack optimizations can reduce the number of instructions
requiring interpretation. Others have measured interpreted
instructions to be about 1800 times slower than code exe-
cuting at native speed [10].
Existing self-checksumming schemes defeated by the
page-replication attack can be augmented with our mem-
ory architecture detection to restore their previous viability.
Yet, self-checksumming remains an incomplete solution to
software tamper resistance. Self-checksumming programs
execute atop an untrusted operating system and untrusted
hardware. Regardless of the speciﬁc self-checksumming al-
gorithm used, the presence of obfuscation, or the use of our
page-replication attack detection, one-time, costly emula-
tion attacks that produce modiﬁed programs with no self-
checksumming code remain valid attacks.
Our use of self-modifying code does impose some lim-
It prevents the use of
itations on widespread adoption.
systems such as PaX [21] that create non-writable code
pages and non-executable data pages in memory. System-
wide memory demands will increase as memory pages can-
not be shared among multiple processes. As with self-
checksumming algorithms, memory architecture detection
will increase the complexity of compilers generating pro-
tected programs.
In summary, this paper contributes the following:
• We analyze a previously unrealized assumption in
self-checksumming literature.
Self-checksumming
critically assumes a von Neumann main memory ar-
chitecture so that checksum code actually veriﬁes code
to be executed. This assumption was previously over-
looked, leading to the successful page-replication attack
R1
R2
(a)
R1
R2
Check 1
Check 2
(b)
Figure 1. (a) Layout of a program to protect.
The code producer wants to protect the in-
tegrity of the code in [R1, R2). (b) Code pro-
tected using self-checksumming.
of Wurster et al. that created a Harvard memory architec-
ture. Section 2 further examines this assumption.
• We present a mechanism to detect violations of the
von Neumann assumption. We show how a process
can detect a Harvard memory architecture with self-
modifying code in Section 3. This mechanism enables
us to verify the overlooked assumption required for self-
checksumming to work.
• We strengthen self-checksumming to detect memory
page-replication attacks. As described in Section 4, this
detection is efﬁcient and robust up to attacks that use ex-
pensive interpretive emulation or custom hardware.
2. Background
Self-checksumming veriﬁes the authenticity of a pro-
gram’s code during execution. The code producer inserts
checksum computations and veriﬁcations throughout the
program code. A checksum algorithm computes a hash over
a range of critical code that should not be altered. Veriﬁca-
tion compares the result of a checksum computation against
a known value hard-coded in the program body. A failed
veriﬁcation indicates unexpected modiﬁcation of the pro-
gram, and the program’s integrity is no longer assured.
Consider a program that can run only in the presence of
a valid license. The program should protect against modi-
ﬁcation of any code performing the license check. In Fig-
ure 1(a), the shaded code region contains the license check.
An attacker may wish to remove the license check by over-
writing the corresponding code, or simply by inserting code
to jump around the license check.
Protecting this program fragment using checksumming
might lead to the code in Figure 1(b). Several check-
sum computation and veriﬁcation sequences are added to
the program. This paper is not proposing a new check-
CPU
Fetch
RAM
Read
Write
I−RAM
D−RAM
CPU
Fetch
Read
Write
Figure 2. Von Neumann memory architecture.
Instructions and data share a common main
memory even though intermediate caches
may be divided. Data write operations alter
both instructions and data.
Figure 3. Harvard memory architecture.
In-
structions and data are maintained in sepa-
rate main memories. Data write operations
alter the data RAM but leave the instruction
RAM unchanged.
sum algorithm; any of the previously published algorithms
[5, 7, 13, 19] would be suitable for use. Each checksum se-
quence will verify the integrity of a critical code region,
such as the license check, and zero or more checksum se-
quences. An attack that modiﬁes the protected license ver-
iﬁcation code will be detected because the checksums over
the critical code region [R1, R2) will not match the stored
value. The program will then terminate, preventing the at-
tacker from running the program without a valid license.
2.1. Self-Checksumming Assumptions
The ability of self-checksumming to detect software
tampering relies upon three assumptions. If the malicious
host violates any of these assumptions, an attacker can de-
feat self-checksumming. Assumption 3 has not been ad-
dressed in previous work and is the focus of this paper.
Assumption 1 [OPAQUE CODE ASSUMPTION]
The attacker cannot identify all relevant checksum computa-
tion code or veriﬁcation code within the protected program.
The intuition behind this assumption is that static analy-
sis of the program is in general undecidable and can be
made arbitrarily hard using code obfuscation techniques.
This assumption prevents an attacker from ﬁrst altering or
removing the checksum code from the program, and then
undetectably altering the program. Although we question
the legitimacy of this assumption—if an attacker has the
ability to ﬁnd and remove undesired code like a license
check, they are likely able to ﬁnd and remove checksum
code—we note that literature on obfuscation [9, 15, 25] at-
tempts to make the assumption hold.
Assumption 2 [PERFORMANCE ASSUMPTION]
The attacker desires to run the protected program at full
speed or with only a reasonable slowdown.
Software self-checksumming can never guarantee secu-
rity, as a self-checksumming program executes atop an un-
trusted operating system and an untrusted machine. For ex-
ample, program emulation allows undetectable code manip-
ulation by intercepting all data reads from memory so that
only the original code is read. However, these attacks come
at high performance cost. An attacker willing to violate As-
sumption 2 and forgo reasonable performance can success-
fully defeat self-checksumming.
Our memory architecture detection technique is as re-
silient
to program emulation attacks as standard self-
checksumming. We neither introduce new emulation at-
tacks nor prevent emulation attacks from working success-
fully. The threat of a one-time, costly emulation attack that
produces a modiﬁed program with no self-checksumming
code remains. Non-deterministic, multithreaded checksum-
ming routines, originally envisioned by Aucsmith [5], may
provide a successful defense against these attacks. Our
memory architecture detection restores the viability of Auc-
smith’s routines by detecting page-replication attacks.
Assumption 3 [VON NEUMANN ASSUMPTION]
Programs protected by self-checksumming operate on a
commodity von Neumann architecture.
On a von Neumann machine, instruction fetches and data
reads access the same physical memory. This architectural
property is critically important as self-checksumming relies
on the ability to read a program region both as data bytes to
checksum and as instruction bytes to execute. As most mod-
ern, commodity systems use a von Neumann main memory,
this assumption was implicitly considered reasonable and of
no further concern.
Unfortunately, the complexity of modern architectures
allows the memory values read when computing a check-
sum over a code region to have no correlation to instruc-
tions actually executed. Failure to explicitly address the
CPU
Fetch
Read
Write
I−RAM
Altered
code
D−RAM
Genuine
code
I−RAM
CPU
Fetch
I1
D−RAM
I
2
Read
Write
Figure 4. The Wurster et al. page-replication
attack creates a virtual Harvard architecture.
The data memory contains the original, gen-
uine copy of the program text read and veri-
ﬁed by the self-checksumming program. The
instruction memory contains the actual ex-
ecuted code, undetectably altered by an at-
tacker.
Figure 5. Our memory architecture detection.
We overwrite an existing instruction I1 with a
new instruction I2 that would alter execution
behavior. In a Harvard architecture, I2 is visi-
ble only to subsequent data reads and not to
instruction fetches. Program execution still
reﬂects I1. This read/fetch mismatch identi-
ﬁes the page-replication attack.
von Neumann assumption in previous work led to a suc-
cessful page-replication attack against self-checksumming.
We show in Section 3 how to efﬁciently verify the assump-
tion using self-modifying code.
2.2. Memory Architectures
To better understand the page-replication attack and its
implications to self-checksumming schemes, we ﬁrst con-
sider the architecture of main memory on commodity sys-
tems. A processor uses three operations to retrieve instruc-
tions and data and to write values back to memory:
• fetch: retrieve an instruction from memory for execution,
• read: load a value from memory, and
• write: store a value to memory.
Based on how these three operations interact with memory,
a machine’s physical memory architecture can be classiﬁed
into one of two fundamental designs: the von Neumann ar-
chitecture and the Harvard architecture.
A von Neumann memory architecture [24] uses a com-
mon store for both instructions and data (Figure 2). An in-
struction fetch will read from the same physical memory lo-
cation as a data read of the same address. Critically, a data
write modiﬁes the memory so that subsequent instruction
fetches and data reads will both retrieve the new value.
Conversely, a Harvard architecture [2, 3] maintains sep-
arate instruction and data stores (Figure 3). An instruction
fetch and a data read of the same address access physically
distinct memory locations. A value written to memory al-
ters only the data memory and leaves the instruction mem-
ory unchanged. We deﬁne a virtual Harvard architecture as
a system with separate instruction and data memories main-
tained by software on a machine that is physically von Neu-
mann. Even if the software layer duplicates virtual mem-
ory addresses in both the instruction and data memories,
a process can write to only one memory at a time. Com-
modity processors provide no instruction allowing a process
to write to multiple physical memory addresses simultane-
ously.
2.3. Violating the von Neumann Assumption
As modern, commodity processors present processes
with a von Neumann main memory, previous self-
checksumming approaches implicitly assumed that the von
Neumann assumption must hold. Wurster et al. violated the
assumption to undetectably alter self-checksumming pro-
grams. Their attack modiﬁed an operating system’s mem-
ory manager to create a virtual Harvard architecture from
the physical von Neumann memory. The attack implemen-
tation varied based upon speciﬁc properties of particular
commodity processors, but, in all cases, the attack created
distinct instruction and data stores from the main memory
of the system.
Successful evasion of checksum computations then be-
comes clear. The attacker replicates in both the instruction
and data memories those memory pages containing code
that they wish to alter. The copy in data memory remains
unchanged so that checksum calculations are correct. How-
ever, execution fetches instructions from the copy in the in-
struction memory (Figure 4). The attacker is free to unde-
tectably manipulate the copy in instruction memory and al-
ter program execution as they desire.
Reconsider
the example program in Figure 1(b).
Wurster et al. place the original code in the data memory
at address R1. The attack then places the modiﬁed code
in the instruction memory, also at address R1. The pro-
gram executes this altered code from the instruction mem-
1
2
3
4
5
6
7
movb $1, A+1
movb A+1, %al
A: andb $0, %al