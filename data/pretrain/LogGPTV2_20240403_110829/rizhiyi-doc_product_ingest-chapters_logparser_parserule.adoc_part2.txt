==== KeyValue分解
KV分解算子主要用来解析明显的KV字符串，例如上面的例子中正则表达式解析后，request_query字段为：
 field=tag&filters=&order=desc&page=1&query=*&size=50&sourcegroup=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
这是一个按照"&"和"＝"来分割的KV字段。添加解析规则：KeyValue分解，source字段选择request_query，定义字段分隔符为&，定义k-v分隔符为=，点击解析，如图可看到解析结果：
image::images/parserule-kv.png[]
[TIP]
====
如果可能有很多个key，推荐 您通过填写key名称做保留或者取舍，也可以填写丢弃前缀名简化日志内容。
====
==== KeyValue正则匹配
某些日志中KV字段可能比较复杂，用户往往希望查看解析后简单明了的字段格式，并丢弃某些无关紧要的字段，您可以使用KeyValue正则匹配算子，来提取字段，例如一条日志为：
 May 18 11:20:10 2016 HLJ_S12508_1_FW %%10FILTER/6/ZONE_DP_FLT_EXECUTION_TCP_LOG(l): -DEV_TYPE=SECPATH-PN=210231A0H6010C000002; srcZoneName(1034)=serveruntrust;destZoneName(1035)=servertrust;rule_ID(1070)=90;policyActType(1071)=denied;protType(1001)=TCP(6);srcIPAddr(1017)=10.167.77.99;destIPAddr(1019)=10.166.5.70;srcPortNum(1018)=49362;destPortNum(1020)=1521;beginTime_e(1013)=05182016112009;endTime_e(1014)=05182016112009;
先对日志正则匹配：
 (?%{NOTSPACE}\s+%{NOTSPACE}\s+%{NOTSPACE}\s+%{NOTSPACE}\s+)%{NOTSPACE:host} \%\%(?[^/]*)/(?[^/]*)/(?[^:]*): -DEV_TYPE=SECPATH-PN=210231A0H6010C000002; (?.*)
image::images/parserule-kvregex-before.png[]
然后针对“message”字段，进行KeyValue正则匹配的解析配置：
image::images/parserule-kvregex-config.png[]
点击解析，可以看到解析结果：
image::images/parserule-kvregex.png[]
==== 数值型字段转换
默认提取出来的字段都是字符串类型的。如果您希望将这个值转换成数值类型，以方便再后面做统计，则需要通过这个算子来做转换。转换时需要您设置数值进制以及配置数值的类型：int/float
例如： 您的日志经过解析得出如下字段：
 k1: "123",
 k2: "123.0"
经过转换可以转变为：
 k1: 123,
 k2: 123.0
如针对正则表达式的解析结果，选择resp_len字段，点选“int”，点击解析. 数值型字段可以同时选择多个：
image::images/parserule-mutate.png[]
==== URL解码
将编码过的URL进行解码，这个算子只能针对已经解析出来的字段。如针对之前正则表达式小节样例日志的解析结果，选择字段request_query，点击解析：
image::images/parserule-url.png[]
==== User Agent解析
UA解析算子用来分析HTTP日志中User Agent的用户操作系统和浏览器信息。如针对之前正则表达式小节样例日志解析后的结果，选择ua字段，点击解析：
image::images/parserule-ua.png[]
==== 时间戳识别
使用者通常关心日志发生的时间，比如检索最近几天的日志，需要转换日志中的timestamp字段的内容，日志易系统就可以识别这条日志的时间戳。这就需要您在之前抽取字段时就提取出timestamp字段。例如：
 timestamp: "150120 16:00:30"
需要配置时间格式为：
 yyMMdd HH:mm:ss
具体的配置格式参考：
[options="header"]
|=================
|符号|含义|格式|举例
|e
|星期
|数字
|星期二 -> e:2, ee:02
|E
|星期
|文本
|星期二 -> E:Tue, EEEE:Tuesday
|M
|月份
|月
|七月 -> M:7, MM:07, MMM:Jul, MMMM:July
|d
|一月的第几天
|数字
|第9天 -> d:9, dd:09
|H
|0-23小时
|数字
|8点 -> H:8, HH:08
|m
|0-59分钟
|数字
|8分 -> m:8, mm:08
|s
|0-59毫秒
|数字
|8秒 -> s:8, ss:08
|S
|0-999毫秒
|数字
|888毫秒 -> SSS:888
|z
|时区
|文本
|zzz:PST, zzzz:Pacific Standard Time
|Z
|时区
|时区
|Z:+0800, ZZ:+08:00, ZZZZ:America/Los_Angeles
|=================
如果符合ISO8601标准可以直接配置成"ISO8601"，例如：Fri Jul 05 21:28:24 2013 ISO8601。
如果是UNIX格式可以直接配置成"UNIX"，例如：1412899200.000。
如果解析失败或者没有配置，默认使用进入系统的时间作为这条日志发生的时间。
对上面例子中的日志时间戳进行配置，source字段选择timestamp，填入“dd/MMM/yyyy:HH:mm:ss Z”，选择时区和时间戳语言，点击解析，弹出配置成功窗口如下图：
image::images/parserule-date.png[]
针对特殊格式的时间戳格式，您可以选择设定时间戳前缀和最大匹配长度，更好的解析日志。
日志解析时间戳识别功能支持自动补全不完整时间戳。格式可以不写yyyyMMdd，根据Heka发出的file-last-modified-timestamp，会自动用文件的最后更新时间的年月日补全。
==== CSV解析
针对CSV格式的日志解析算子，可以将字符串按照固定分隔符进行切分，例如：
 192.168.1.21,mobileapi,raocl,13800000000 
可以根据“,”来对其进行切分；然后定义切分后字段名称列表为：
 ip,application,admin,telephone 
点击解析，即得到解析结果如图所示：
image::images/parserule-csv.png[]
注：如果 CSV 文件有双引号、管道符分割等情况，请优先选择分割类型为 CSV。
==== XML解析
针对XML格式的日志解析算子，而且支持jsonpath语法获取部分字段。
由于XML数据在层级过多，且不需要全部解析的情况下，会浪费较多的CPU与空间。日志易的XML解析通过支持jsonpath语法，可以实现只获取XML格式下的部分字段，由此缩短运行时间，提高效率。
image::images/parserule-xml.png[]
* xml解析长度限制:在这个长度范围之内的字段正常抽取, 超过这个长度的内容不解析，0 代表不限制。配置留空时, 使用logriver的默认配置：log_parser.xml_parse_extract_limit xml解析长度限制, 默认5000。
需要注意: xml解析使用jsonpath不受长度限制影响
==== JSON解析 [[json-parser]]
同上节一样，JSON解析算子对多层嵌套数组也支持jsonpath的语法，在层级较多且复杂的情况下，通过该语法轻松获取其中特定的字段值。
JSON解析主要用于解析JSON格式的日志, 例如原始日志为：
[source,javascript]
{"Name": "John Smith ", "Age": 23, "Employed": true, "Address": {"Street": "324 Chrome St", "City": "Portland, New York,Los Angeles ", "Country": "United States"}}
JSON解析后如下图所示：
image::images/parserule-json.png[]
同xml解析规则一样，json解析长度同样受限制，配置留空时则使用logriver的默认配置：log_parser.json_parse_extract_limit json解析长度限制, 默认5000, 0代表不限制。
需要注意: json解析使用jsonpath不受长度限制影响。
==== Syslog_pri解析
针对syslog格式日志中 PRI(priority)消息的解析算子。可以解析出Severity和Facility字段。例如：
image::images/parserule-syslog-pri.png[]
==== 字典扩展
原始日志中往往包含了大量具有特殊意义的代码字符，即使是专业人员也无法迅速理解日志内容，造成日志分析工作难以进行，利用字典扩展解析算子可以对日志内容进行自定义的对应转换，使日志更易读，分析更容易。
例如以下这条日志
[source,javascript]
{"Category":"","ComputerName":"WIN-999OGBVAHMI","EventCode":7036,"EventIdentifier":1073748860,"EventType":3,"Logfile":"System","Message":"Application Experience 服务处于 正在运行 状态。","RecordNumber":108343,"SourceName":"Service Control Manager","User":"","TimeGenerated":"2015-01-04T20:45:09+08:00"}`
在日志易日志展示时，字典扩展解析算子将原始日志中的某些字段替换成自定义的字段名称及内容。下面我们介绍一下利用字典扩展解析算子，如何将SourceName字段映射为具体的等级和来源信息。
日志易目前支持string字段映射，int字段暂时无法使用字典扩展解析算子。具体操作如下：
1. 需要根据日志编写相应的csv文件。针对上面举例的日志，编写csv文件如下：
+
image::images/parserule-csv-example.png[]
+
表头第一列填写需要替换的字段名称sourcename，该列依次填入原始日志中SourceName的字段内容，第二列之后为替换字段。需要注意的是每个字段可对应多个替换字段，替换字段名称由英文字符组成，如上面例子中替换字段名称为第二列的level、第三列的source。映射内容允许出现空缺。 完成csv文件后保存
2. 进入"元数据-字典管理"页面，可以在该页面实现上传、下载、新建、编辑、删除字典，给字典授权，编辑字典标签等多种操作。
点击“上传”，选择csv文件上传即完成操作。
+
image::images/dic_list.png[]
+
3. 字典上传后并没有立刻使用，进入设置-资源-字段提取的配置页面中
+
image::images/parserule-csv-config.png[]
+
添加解析规则选择“字典扩展”，再分别在下拉菜单选择来源字段，选择扩展源类型为"CSV字典"，选择扩展源为上一步上传的字典名称，选择基准字段为 sourcename，扩展字段为 level 和 source，点击确定关闭弹窗后，再解析成功后即可提交配置。随后正式上传的日志即可出现字典内容置换。日志中出现的字段内容会依据该csv表格进行替换。
除"CSV字典"以外，扩展源类型还可以选择"资产模型"。然后在扩展源上选择可用的资产模型名称，并选择某个模型属性为基准字段，若干模型属性为扩展字段。系统将使用该资产模型对应的资产实体属性进行内容扩展解析。有关资产模型和资产实体的更多介绍，请阅读《日志易使用手册》相关章节。
image::images/parserule-asset-config.png[]
在字典列表中点击字典名称会跳转到字典详情页，默认显示50条，可分页显示。
image::images/dic_detail.png[]
如果您想变更或补充字典内容，可以点击下载原文件, 修改完成后,点击编辑重新上传，也可以在线编辑csv文件（在线编辑最大支持5w行，10M的文件大小，如果文件大小超过限制，则提示不能上传）。在线编辑支持右键菜单的多个操作如下图所示，支持单元格的拖拽填充，支持撤销和重置。
image::images/dic_edit.png[]
[NOTE]
=======
CSV字典同样可以被SPL的inputlookup、lookup指令读取，可以被SPL的outputlookup指令覆盖写入。当字典内容需要动态维护时，可以采用SPL语句和定时任务功能配合完成。
=======