plication under consideration, in line with Kerckhoffs’ second
design principle.3
Reasoning about any abstraction of real systems runs the
risk of eliding implementation-level details that may impact
security in practice. Systems captured by such an abstraction
must take care to minimize the side effects of their operations
(e.g., processing time), as these may foster attacks that are
outside the formalized attack model.
That being said, we believe that
this work can en-
able future censorship circumvention developers to ground
their security arguments in formalized assumptions, ultimately
helping users to choose the right system for their unique
circumstances.
II. BACKGROUND
A. Secure steganography
Hopper, von Ahn, and Langford [11] gave the first
complexity-theoretic security notion for steganography, a
close analogue to the covert channel notion we consider in
this work. The authors use the concept of a channel oracle
to serve as the source of truth for acceptability of messages.
While this highly general approach has led to a substantial
body of theoretical results [12, 13, 14], as well as insights into
other areas of cryptography [15], to our knowledge it has not
informed the design of any censorship circumvention system
used in practice. One recent work, Meteor [16], does acknowl-
edge steganographic security as a goal for their scheme but
the actual construction they present does not treat the channel
3Also known as Shannon’s maxim: “the enemy knows the system”.
oracle as a black box so it is not clear that this is the right
choice of security notion.
We believe that this dearth of practical application may
be due to the unrealistic requirements on the channel oracle,
which must perfectly model all observable aspects of the
communication channel, including timing, duration, and other
details which could properly be considered meta-information.
With the benefit of hindsight, our syntax is motivated directly
by systems that target real-world deployment, and our syntac-
tic choices support security notions that more readily expose
what is needed from the core components of these systems.
B. Covert application tunnels
In the next few paragraphs we discuss several of the
(tunneling-based) censorship circumvention systems used to
motivate our formalisms. As we refer to several of these
systems throughout the paper, we aim here to provide a self-
contained description sufficient for understanding the high-
level approach taken by each of them.
Streaming media. One popular choice for tunneling appli-
cations is streaming media, as it generally supports high
throughput and often utilizes a secure channel such as TLS
by default. One method of creating a covert channel is to
embed covert data into a serialized stream of audio or video
immediately before it is provided to the cover application (i.e.,
on the user side), as is done by FreeWave [3], SkypeLine [17],
Facet [18], CovertCast [19], and DeltaShaper [2]. The primary
challenge in these systems is embedding covert data in such a
way that the underlying application does not exhibit changes
in behavior from its multimedia codec and quality-of-service
protocol, although undetectability is also dependent upon
selection of a plausible multimedia cover stream (whether live
or pre-recorded).
Real-time games. Another choice of tunneling application is
video games. Castle [1] utilizes real-time strategy games as
the tunneling application, embedding covert messages through
encoded user-side inputs such as game commands. These
encoded inputs are issued via desktop automation software,
allowing the system to mimic the speed and response time of
an actual human player. However, the communicating parties
must utilize a specially designed map which has game objects
(units and/or buildings) arranged in a predetermined way to
support this encoding, and both the map and the encoded
commands may be distinctive compared to normal gameplay.
Thus, Castle assumes the tunneling application uses a secure
channel to hide this.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:36:38 UTC from IEEE Xplore.  Restrictions apply. 
1973
transmit
Rook [4] is designed for games that
large
amounts of high-entropy data, such as position and velocity
information in first-person shooters. It creates a covert channel
by manipulating outgoing game traffic (i.e., on the wire side)
to encode covert messages based on a shared symbol table
mapped to specific data fields. Rook does not assume a
secure channel, and thus the encoded values must be carefully
selected from the set of values that have been observed during
normal gameplay.
Traffic replacement. To sidestep the technical challenges and
constrained throughput associated with the above systems,
Protozoa [5] and Balboa [6] embed covert messages after
the application has processed its input, relying on a secure
channel to hide the fact that such embedding has occurred.
Balboa accomplishes this with almost no coupling to the
underlying application by extracting TLS key material and
decrypting outgoing packets as they are written to the network.
Protozoa utilizes a software hook inserted into a WebRTC
implementation that invokes the covert embedding just after
the media frame data has been finalized but before it has been
encrypted. On the receiver side, each of these systems inverts
the operation performed on the sender side by extracting the
covert bits and restoring valid data—in the case of Balboa,
the exact message is restored using a pre-shared lookup table
called a traffic model, while in Protozoa a local “dummy”
video stream is used.
This traffic replacement technique can also be observed in
Slitheen [20] and Waterfall [21], two censorship circumvention
systems which utilize an architecture known as refraction
networking to tunnel a connection to a blocked web address
under the cover of a connection to an allowed web address.
Specifically, a friendly network router on the return path from
an allowed destination is permitted to man-in-the-middle the
secure connection and then replace certain types of content
with covert data. This replacement must be done carefully
because web browsing, even when encrypted, can produce
distinctive patterns of network traffic that are easily finger-
printed [22].
Finally, we note that embedding covert messages into
network application traffic has obvious connections to other
areas of covert communication, including settings where roles
are reversed and the adversary is the party attempting to
embed a covert message while the “honest” user is trying to
detect this undesired usage. As an example of this setting,
a number of recent works address adversarial commands
embedded into natural voice commands directed at consumer
devices [23, 24, 25]. Our work is focused on settings where the
adversary is monitoring the network to detect a covert channel,
so our syntax and security notion are explicitly designed
around a very strong eavesdropper.
III. PRELIMINARIES
When x is a string, we write |x| for its length. When y
is also a string, we write x∥y for their concatenation, and we
write x ⪯ y (resp. x ≺ y) to denote that x is a prefix (resp.
strict prefix) of y. We denote by ε the empty string.
We use bold lowercase letters to denote finite sequences
(or “vectors”) of values. For a sequence w we denote its length
by #(w), and use bracketed integers (starting from 1) to refer
to individual elements, e.g. w = w[1], . . . , w[n]. We also use
basic Python-like range indexing to refer to subsequences, e.g.
w[2 : 4] yields the sequence w[2], w[3], w[4]. When w is a
sequence of n strings we write ∥w to denote the component-
wise concatenation w[1]∥w[2]∥ . . .∥w[n], and (overloading
notation) |w| to denote the length of ∥w. The function $(·)
randomizes its input; i.e. on input an ℓ-bit string it returns a
bitstring sampled uniformly from {0, 1}ℓ. We also overload
this function for vectors of strings, such that it implicitly
distributes over the components of the input vector.
We name and describe algorithms using pseudocode.
When Alg is a randomized algorithm, we write x ←←
AlgO1,...(i1, . . .) to denote the execution of Alg on inputs
(i1, . . .) when provided access to oracles O1, . . ., and assigning
the returned value to variable x. We use the underscore
symbol in procedure headers and assignment statements—e.g.,
(x, ) ←← AlgO(y)—to denote values that are not referenced
in subsequent statements and can be ignored.
When considering syntactic objects as tuples of named
algorithms, we use an infix ‘.’ operator to disambiguate algo-
rithms from different objects with similar names: for object
Obj = (Alg1, Alg2, . . . ), we use Obj.Algi(. . . ) to denote the
execution of Algi from Obj’s tuple of algorithms.
A. Experiments and games
Our security notions are formalized as pseudocode exper-
iments, with the standard naming convention Expxxx
p1,... where
xxx is a shortened version of the notion name and p1, . . .
are objects that parameterize the experiment. Our experiments
take one input which we call an adversary—a randomized
algorithm which returns a value in {0, 1}. All variables named
in the body of the experiment are global (i.e. may be refer-
enced in oracle procedures), but variables named within oracle
procedures are local.
After fixing the parameters of an experiment, we call it
a game and usually give it a succinct name such as G0 or
CC. For a fixed y, we write Pr[ G(A) ⇒ y ] to denote the
probability, over the coins of the game G and adversary A,
that the game returns y. For games G, H and adversary A,
let ∆(G, H) = Pr[ G(A) ⇒ 1 ] − Pr[ H(A) ⇒ 1 ] . We refer
to this quantity as the distinguishing advantage. Finally, for
a fixed adversary A and games G, H, I we have the “triangle
equality” [26]
∆(G, I) = ∆(G, H) + ∆(H, I).
B. Stream-based channels
Several of our constructions rely on secure channels. To