




 


!












"

#



$
%

$
%

$
%
&
$
%

$
%
'
$
%

$
%
(
$
%

$
%
)
*
+


Figure 10: Energy dissipation of different systems.
 ,-
.
/+
0





















 

!












"

#



$
%

$
%

$
%
&
$
%

$
%
'
$
%

$
%
(
$
%

$
%
)
*
+


Figure 11: Normalized performance of three-level, proposed and Scrubbing in terms of CPI.
Table VII: System overhead.
Res.a
(1,1)
(1,2)
(2,1)
(2,5)
(5,2)
(5,5)
Size(MB)b Read(nj)b Latency(ns)
Refresh(mw)
28
14
14
3
3
2
3.682
3.373
3.373
1.924
1.924
0.982
7.96637
7.37958
7.37958
6.00324
6.00324
4.51
0.352
0.115
0.115
0.0231
0.0231
0.0011
a Resolution of quantization, (time, temperature).
b Energy and access time per access, reported by CACTI.
memory accesses without any additional mechanisms in-
volved for controlling resistance drift. Hence, programming
to narrower levels (‚Äú01‚Äù, ‚Äú10‚Äù) needs more iterations to
achieve the desirable target resistance bands. When our
system is incapable to handle resistance drift using the
resistance margins, it relies on dynamic sensing approach
which in turn needs to have one access to SBT and therefore,
energy dissipation of SBT is also added to the access energy.
As SBT is a dynamic memory, the refresh overhead must be
considered, too. We also have one refresh per day, due to the
limited size of SBT. In this paper, we compare our results
with two state-of-the-art designs, three-level PCM [27] and
Scrubbing mechanism [2]. Thus, we consider the following
assumptions for these two designs. For three-level PCM, it
is assumed that each 3 bits are stored in 2 cells [31] and
4
3 fraction encoding for assigning each 3-bit data to three-
level states is employed [12]. Therefore, accessing a block
3 √ó 2 (cid:3) 682
of 128 bytes in three-level PCM needs 128√ó8
cells to be read or written. For Scrubbing scheme, on the
other hand, we assume a refresh period of 32 seconds that
exhibits 0.13% BER. Fig. 10 shows energy dissipation of
described systems across different workloads. As can be seen
in Fig. 10, on average our proposal consume less energy
compared to Scrubbing (43%). But some exceptions can
be seen in the energy Ô¨Ågure (Mix1, Mix2 and Mix3), too.
These three applications are very memory-intensive, and
have much SBT accesses, hence dissipating more energy.
Moreover, for three-level, better energy efÔ¨Åciency than time-
and temperature-aware sensing and Scrubbing is observable.
The energy efÔ¨Åciency reason of three-level relates to semi-
SLC nature of this technique.
System performance. The memory access latency in our
system depends on time and temperature of the requested
block at the time a read request is received at the mem-
ory controller. First of all, the drift controller unit must
decide about the mechanism for handling resistance drift.
To make such a decision the drift controller unit needs the
block‚Äôs resident time and corresponding temperature. The
213213213
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:25:07 UTC from IEEE Xplore.  Restrictions apply. 
temperature of the block is available when the address of
the request is received. In other words, sensor selection unit,
based on the address, can determine location of the block and
consequently, return the digitized value sensed by the sensor
to drift controller unit. On the other hand, to avoid the impact
of resistance drift on meta-data, we should keep resident
time data in the SLC mode. As the resident time values
are stored in the SLC mode, reading these value consume
less time (about %50 of MLC, on average). Hence, while
the memory block is being read, the value of resident time
is read concurrently, too. Immediately after SLC cell was
read, we send these values to the drift controller unit. With
this scheme, reading the value of resident time tag could
be removed from critical path and the drift controller unit
has enough time to decide about the sensing mechanism.
We take a conservative approach and assume that reading
from SBT is on critical path. Based on this discussion,
we evaluate our performance in terms of cycle per instruc-
tion (CPI). If time and temperature are in a range that
resistance margin can tolerate resistance drift, read latency
is as same as that of baseline; otherwise, one read from
SBT is added to our latency. In three-level PCM, because
a semi-SLC approach is used, the performance is always
better than a 2-bit MLC PCM. For Scrubbing mechanism,
we assume 32 seconds refresh period which means for a
4 GB memory system with 8 banks, assuming that bank
concurrent refresh is available, the memory system might be
unavailable for 6.3 seconds. Fig. 11 demonstrates the CPI
values for the evaluated systems. As can be seen in Fig.
11 , our time- and temperature-aware sensing approach has
18% better performance compared to Scrubbing. However,
about 3% performance loss is seen in comparison with three-
level. Using narrow inter-level margins is very helpful in
our proposal, because large portions of error-free memory
accesses are guaranteed. Moreover, SBT access latency is
negligible compared to MLC PCM latency. Therefore, our
system performance is very close to the three-level approach.
VII. OVERALL OVERHEAD ANALYSIS
In this section, we review the overheads of the proposed
system. In our system, we have a time-tag for each block
of main memory. If we consider a 32-bit length for each
4B
128B = 3.125%
time-tag, the storage overhead will be
which is negligible in a 4 GB memory system. Another
required storage is SBT;
in the best case of BER, we
need 28MB DRAM cache, while for a moderate level of
reliability, we can use a 3 MB one. Temperature sensors are
also needed for thermal proÔ¨Åling. Nowadays, temperature
sensors are common components in chips, hence there is no
concern about thermal analysis and the availability of such
a system. The drift controller unit is actually composed of
two comparators that compare time and temperature to 15
seconds and 66 ‚ó¶C, respectively, and generate an address for
SBT. Therefore, it has no signiÔ¨Åcant overhead. As PCM is
scalable and capable of being MLC, it is valuable to put lots
of efforts to make reliable PCM MLC memory systems in
the presence of such moderate overheads. We remark that
all drift tolerance methods have overheads. The proposed
method has 3.1% overhead, much lower than 13.5% in
ECC-based schemes [34]. To further reduce it, OS can be
setup virtualize time-tags on disk (like virtual memory).
We guarantee data integrity of time-tags by storing them
in SLC that is inherently drift-immune. Storage overheads
of other state-of-the-art designs are summarized as follow:
Time-aware sensing [30] has 3.1% storage overhead, Three-
level [27] as stores 3 bits per 2 cells has 33% capacity
reduction and ECC/BCH [34] has 13.5% storage overhead
because of storing redundant information. BrieÔ¨Çy, although
our proposal has non-negligible overhead, compared to other
recent solutions our overhead seems to be acceptable.
VIII. CONCLUSION
The emerging technology of PCM has been shown to
be an interesting candidate for 3D-stacked memories. The
next step will be to use MLC PCMs, but its advantage
in increasing the storage density comes with the serious
shortcoming of resistance drift that is further accelerated in
3D designs. BrieÔ¨Çy, in this paper:
‚Ä¢ We investigated the effect of temperature in high stress
thermal environments.
‚Ä¢ We showed that most of the workloads do not require
large resistance margins for drift-resilience, and the
same reliability can be achieved with small margin sizes
for most of the memory accesses. Using narrow inter-
level resistance margins with low impact on program-
ming energy leads to a resistance drift resilient solution
for a signiÔ¨Åcant portion of memory accesses.
‚Ä¢ To address resistance drift for the remaining mem-
ory accesses, we also introduced an adaptive sensing
scheme to determine threshold voltages on-demand. To
do so, we estimate the amount of drift from a simple
analytical model and store it in memory in design-time
in order to eliminate run-time calculation overhead.
‚Ä¢ And ultimately, we showed that MLC PCM can be
efÔ¨Åciently accommodated in 3D-stacked memories with
the same reliability as conventional DRAM. However,
it requires some new integration techniques to be suc-
cessful.
REFERENCES
[1] ‚ÄúUltraSPARC T1‚Ñ¢ supplement to the UltraSPARC architec-
ture 2005,‚Äù Sun Microsystems, Tech. Rep. Draft D2.0, May
2006.
[2] M. Awasthi et al., ‚ÄúEfÔ¨Åcient scrub mechanisms for error-
prone emerging memories,‚Äù in HPCA, Feb 2012, pp. 1‚Äì12.
[3] F. Bedeschi et al., ‚ÄúA bipolar-selected phase change memory
featuring multi-level cell storage,‚Äù IEEE JCCS, vol. 44, no. 1,
pp. 217‚Äì227, Jan 2009.
214214214
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:25:07 UTC from IEEE Xplore.  Restrictions apply. 
[4] C. Bienia and K. Li, ‚ÄúPARSEC 2.0: A new benchmark suite
for chip-multiprocessors,‚Äù in MoBS, Jun 2009.
[21] T. Nirschl et al., ‚ÄúWrite strategies for 2 and 4-bit multi-level
phase-change memory,‚Äù in IEDM, Dec 2007, pp. 461‚Äì464.
[5] B. Black et al., ‚ÄúDie stacking (3D) microarchitecture,‚Äù in
MICRO, Dec 2006, pp. 469‚Äì479.
[6] S.-W. Chen, M.-H. Chang, W.-C. Hsieh, and W. Hwang,
‚ÄúFully on-chip temperature, process, and voltage sensors,‚Äù in
ISCAS, May 2010, pp. 897‚Äì900.
[7] Y.-H. Chiu et al., ‚ÄúImpact of resistance drift on multilevel
pcm design,‚Äù in ICICDT, 2010, pp. 20‚Äì23.
[8] A. S. T. M. M. B. C. L. H. Pozidis., N. Papandreou. and
E. Eleftheriou, ‚ÄúReliable mlc data storage and retention in
phase-change memory after endurance cycling,‚Äù 2009.
[22] N. Papandreou, H. Pozidis, T. Mittelholzer, G. F. Close,
M. Breitwisch, C. Lam, and E. Eleftheriou, ‚ÄúDrift-tolerant
multilevel phase-change memory,‚Äù in IMW, 2011, pp. 1‚Äì4.
[23] N. Papandreou, A. Sebastian, A. Pantazi, M. Breitwisch,
C. Lam, H. Pozidis, and E. Eleftheriou, ‚ÄúDrift-resilient cell-
state metric for multilevel phase-change memory,‚Äù in IEDM,
2011, pp. 3.5.1‚Äì3.5.4.
[24] M. Qureshi, M. Franceschini, and L. Lastras-Montano, ‚ÄúIm-
proving read performance of phase change memories via write
cancellation and write pausing,‚Äù in HPCA, Jan 2010, pp. 1‚Äì
11.
[9] Ielmini et al., ‚ÄúPhysical interpretation, modeling and impact
on phase change memory (PCM) reliability of resistance drift
due to chalcogenide structural relaxation,‚Äù in IEDM, Dec
2007, pp. 939‚Äì942.
[25] A. Redaelli, A. Pirovano, A. Locatelli, and F. Pellizzer, ‚ÄúNu-
merical implementation of low Ô¨Åeld resistance drift for phase
change memory simulations,‚Äù in NVSMW/ICMTD, 2008, pp.
39‚Äì42.
[10] D. Ielmini, A. Lacaita, and D. Mantegazza, ‚ÄúRecovery and
drift dynamics of resistance and threshold voltages in phase-
change memories,‚Äù IEEE Transactions on Electron Devices,
vol. 54, pp. 308‚Äì315, Feb 2007.
[26] E. C. Samson et al., ‚ÄúInterface material selection and ther-
mal management technique in second generation platforms
built on Intel Centrino mobile technology,‚Äù Intel Technology
Journal, vol. 9, no. 1, Feb 2005.
[27] N. H. Seong, S. Yeo, and H.-H. S. Lee, ‚ÄúTri-level-cell phase
change memory: toward an efÔ¨Åcient and reliable memory
system,‚Äù SIGARCH Comput. Archit. News, vol. 41, no. 3, pp.
440‚Äì451, jun 2013.
[28] K. Skadron et al., ‚ÄúTemperature-aware microarchitecture:
Modeling and implementation,‚Äù ACM TACO, vol. 1, no. 1,
pp. 94‚Äì125, Mar 2004.
[29] C. D. Spradling, ‚ÄúSPEC CPU2006 benchmark tools,‚Äù CAN,
vol. 35, no. 1, pp. 130‚Äì134, Mar 2007.
[30] W. Xu and T. Zhang, ‚ÄúA time-aware fault tolerance scheme to
improve reliability of multilevel phase-change memory in the
presence of signiÔ¨Åcant resistance drift,‚Äù IEEE TVLSI, vol. 19,
no. 8, pp. 1357‚Äì1367, Aug 2011.
[31] D. H. Yoon, J. Chang, R. S. Schreiber, and N. P. Jouppi,
‚ÄúPractical nonvolatile multilevel-cell phase change memory,‚Äù
in SC, 2013, pp. 21:1‚Äì21:12.
[32] W. Zhang and T. Li, ‚ÄúCharacterizing and mitigating the
impact of process variations on phase change based memory
systems,‚Äù in MICRO, Dec 2009, pp. 2‚Äì13.
[33] ‚Äî‚Äî, ‚ÄúHelmet: A resistance drift resilient architecture for
multi-level cell phase change memory system,‚Äù in DSN, Jun
2011, pp. 197‚Äì208.
[34] ‚Äî‚Äî, ‚ÄúExploring phase change memory and 3D die-stacking
for power/thermal friendly, fast and durable memory archi-
tectures,‚Äù in PACT, 2009, pp. 101‚Äì112.
[11] D. Jevdjic, S. Volos, and B. FalsaÔ¨Å, ‚ÄúDie-stacked DRAM
caches for servers: Hit ratio, latency, or bandwidth? have it
all with footprint cache,‚Äù in ISCA, Jun 2013, pp. 405‚Äì415.
[12] L. Jiang, Y. Zhang, and J. Yang, ‚ÄúEr: Elastic reset for low
power and long endurance mlc based phase change memory,‚Äù
in ISLPED, 2012, pp. 39‚Äì44.
[13] X. Jiang et al., ‚ÄúCHOP: Adaptive Ô¨Ålter-based DRAM caching
for CMP server platforms,‚Äù in HPCA, Jan 2010, pp. 1‚Äì12.
[14] D. H. Kang et al., ‚ÄúTwo-bit cell operation in diode-switch
phase change memory cells with 90nm technology,‚Äù in VLSIT,
Jun 2008, pp. 98‚Äì99.
[15] I. Karpov and S. Kostylev, ‚ÄúSET to RESET programming
in phase change memories,‚Äù IEEE EDL, vol. 27, no. 10, pp.
808‚Äì810, 2006.
[16] B. C. Lee, E. Ipek, O. Mutlu, and D. Burger, ‚ÄúArchitecting
phase change memory as a scalable dram alternative,‚Äù in
ISCA, 2009, pp. 2‚Äì13.
[17] G. Loh, ‚Äú3D-Stacked memory architectures for multi-core
processors,‚Äù in ISCA, Jun 2008, pp. 453‚Äì464.
[18] P. S. Magnusson et al., ‚ÄúSimics: A full system simulation
platform,‚Äù Computer, vol. 35, no. 2, pp. 50‚Äì58, Feb 2002.
[19] M. M. K. Martin et al., ‚ÄúMultifacet‚Äôs general execution-driven
multiprocessor simulator (GEMS) toolset,‚Äù CAN, vol. 33,
no. 4, pp. 92‚Äì99, Nov 2005.
[20] N. Muralimanohar, R. Balasubramonian, and N. Jouppi, ‚ÄúOp-
timizing NUCA organizations and wiring alternatives for
large caches with CACTI 6.0,‚Äù in MICRO, Dec 2007, pp.
3‚Äì14.
215215215
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:25:07 UTC from IEEE Xplore.  Restrictions apply.