information leakage when training a DNN model on a shared
GPU. We found that the GPU context-switching penalty can
be exploited to allow a spy to obtain ﬁner-grained information
of another CUDA application, including DNN ops and hyper-
parameters. By leveraging active slow-down attack and passive
inference based on LSTM models, we are able to achieve good
accuracy for those attack tasks. For future work, we will test
the potential defenses as mentioned and we also call on the
community and stakeholders to come up with new protection
mechanisms schemes to mitigate this risk.
ACKNOWLEDGMENT
The authors would like to thank the insightful reviews and
suggestions from our shepherd Dr. Chengmo Yang and anony-
mous reviewers. The authors also thank Hao Chen and Suprith
Ramanan from UC Irvine for their help. The researchers
from Fudan University are supported by NSFC 61802068
and Shanghai Sailing Program 18YF1402200. This material
is based upon work partially supported by the United States
Ofﬁce of Naval Research (ONR) under contract N00014-17-1-
2499. Any opinions, ﬁndings, and conclusions or recommen-
dations expressed in this material are those of the authors and
do not necessarily reﬂect the views of the Ofﬁce of Naval
Research or its Contracting Agents.
11
REFERENCES
[1] Mart´ın Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis,
Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving,
Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry
Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan,
Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Ten-
In Proceedings
sorﬂow: A system for large-scale machine learning.
of the 12th USENIX Conference on Operating Systems Design and
Implementation, OSDI’16, pages 265–283, Berkeley, CA, USA, 2016.
USENIX Association.
[2] Alejandro Cabrera Aldaya, Billy Bob Brumley, Sohaib ul Hassan,
Cesar Pereida Garc´ıa, and Nicola Tuveri. Port contention for fun and
proﬁt. In 2019 IEEE Symposium on Security and Privacy (SP), pages
870–887. IEEE, 2019.
[3] Giuseppe Ateniese, Giovanni Felici, Luigi V Mancini, Angelo Spog-
nardi, Antonio Villani, and Domenico Vitali. Hacking smart machines
with smarter ones: How to extract meaningful data from machine
learning classiﬁers. arXiv preprint arXiv:1306.4447, 2013.
[4] Ahmed Osama Fathy Atya, Zhiyun Qian, Srikanth V. Krishnamurthy,
Thomas F. La Porta, Patrick D. McDaniel, and Lisa M. Marvel. Mali-
cious co-residency on the cloud: Attacks and defense. In INFOCOM,
pages 1–9. IEEE, 2017.
[5] Lejla Batina, Shivam Bhasin, Dirmanto Jap, and Stjepan Picek. CSI NN:
Reverse engineering of neural network architectures through electro-
magnetic side channel. In 28th USENIX Security Symposium (USENIX
Security 19), pages 515–532, Santa Clara, CA, August 2019. USENIX
Association.
[6] Atri Bhattacharyya, Alexandra Sandulescu, Matthias Neugschwandtner,
Alessandro Sorniotti, Babak Falsaﬁ, Mathias Payer, and Anil Kur-
mus. Smotherspectre: Exploiting speculative execution through port
In Proceedings of the 2019 ACM SIGSAC Conference on
contention.
Computer and Communications Security, CCS ’19, pages 785–800, New
York, NY, USA, 2019. ACM.
[7] BigML. Bigml.com. https://bigml.com/, 2019.
[8] Caffe. Brewing imagenet.
https://caffe.berkeleyvision.org/gathered/
examples/imagenet.html, 2019.
[9] Nicola Capodieci, Roberto Cavicchioli, Marko Bertogna, and Aingara
Paramakuru. Deadline-based scheduling for gpu with preemption
In 2018 IEEE Real-Time Systems Symposium (RTSS), pages
support.
119–130. IEEE, 2018.
[10] Jie Chen and Guru Venkataramani. Cc-hunter: Uncovering covert
timing channels on shared processor hardware. In Proceedings of the
47th Annual IEEE/ACM International Symposium on Microarchitecture,
MICRO-47, pages 216–228, Washington, DC, USA, 2014. IEEE Com-
puter Society.
[11] Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen,
cudnn: Efﬁcient
John Tran, Bryan Catanzaro, and Evan Shelhamer.
primitives for deep learning. CoRR, abs/1410.0759, 2014.
[12] Christopher De Sa, Matthew Feldman, Christopher R´e, and Kunle
Olukotun. Understanding and optimizing asynchronous low-precision
stochastic gradient descent. In ACM SIGARCH Computer Architecture
News, volume 45, pages 561–574. ACM, 2017.
[13] Vasisht Duddu, Debasis Samanta, D. Vijay Rao, and Valentina E.
Balas. Stealing neural networks via timing side channels. CoRR,
abs/1812.11720, 2018.
[14] Matthew Fredrikson, Somesh Jha, and Thomas Ristenpart. Model
inversion attacks that exploit conﬁdence information and basic coun-
termeasures. In Proceedings of the 22nd ACM SIGSAC Conference on
Computer and Communications Security, pages 1322–1333. ACM, 2015.
[15] Matthew Fredrikson, Eric Lantz, Somesh Jha, Simon Lin, David Page,
and Thomas Ristenpart. Privacy in pharmacogenetics: An end-to-end
case study of personalized warfarin dosing. In 23rd USENIX Security
Symposium (USENIX Security 14), pages 17–32, 2014.
[16] Pietro Frigo, Cristiano Giuffrida, Herbert Bos, and Kaveh Razavi. Grand
pwning unit: Accelerating microarchitectural attacks with the GPU. In
2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings,
21-23 May 2018, San Francisco, California, USA, pages 195–210, 2018.
[17] Karan Ganju, Qi Wang, Wei Yang, Carl A Gunter, and Nikita Borisov.
Property inference attacks on fully connected neural networks using
permutation invariant representations. In Proceedings of the 2018 ACM
SIGSAC Conference on Computer and Communications Security, pages
619–633. ACM, 2018.
12
[18] Google. Cloud machine learning engine.
https://cloud.google.com/
ml-engine/, 2019.
[19] Google. Tensorﬂow timeline. https://github.com/tensorﬂow/tensorﬂow/
blob/master/tensorﬂow/python/client/timeline.py, 2019.
[20] Jamie Hayes, Luca Melis, George Danezis, and Emiliano De Cristofaro.
Logan: evaluating privacy leakage of generative models using generative
adversarial networks. arXiv preprint arXiv:1705.07663, 2017.
[21] Kim Hazelwood, Sarah Bird, David Brooks, Soumith Chintala, Utku
Diril, Dmytro Dzhulgakov, Mohamed Fawzy, Bill Jia, Yangqing Jia,
Aditya Kalro, et al. Applied machine learning at facebook: A datacenter
In 2018 IEEE International Symposium
infrastructure perspective.
on High Performance Computer Architecture (HPCA), pages 620–629.
IEEE, 2018.
[22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
In The IEEE Conference on
residual learning for image recognition.
Computer Vision and Pattern Recognition (CVPR), June 2016.
[23] Sanghyun Hong, Michael Davinroy, Yigitcan Kaya, Stuart Nevans
Locke, Ian Rackow, Kevin Kulda, Dana Dachman-Soled, and Tudor
Dumitras. Security analysis of deep neural networks operating in the
presence of cache side-channel attacks. CoRR, abs/1810.03487, 2018.
[24] Xing Hu, Ling Liang, Lei Deng, Shuangchen Li, Xinfeng Xie, Yu Ji,
Yufei Ding, Chang Liu, Timothy Sherwood, and Yuan Xie. Neural net-
work model extraction attacks in edge devices by hearing architectural
hints. CoRR, abs/1903.03916, 2019.
[25] Weizhe Hua, Zhiru Zhang, and G. Edward Suh. Reverse engineering
convolutional neural networks through side-channel information leaks.
In Proceedings of the 55th Annual Design Automation Conference, DAC
’18, pages 4:1–4:6, New York, NY, USA, 2018. ACM.
[26] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan
Long, Ross B. Girshick, Sergio Guadarrama, and Trevor Darrell.
Caffe: Convolutional architecture for fast feature embedding. CoRR,
abs/1408.5093, 2014.
[27] Zhen Hang Jiang, Yunsi Fei, and David R. Kaeli. A complete key
In HPCA, pages 394–405. IEEE
recovery timing attack on a GPU.
Computer Society, 2016.
[28] Zhen Hang Jiang, Yunsi Fei, and David R. Kaeli. A novel side-channel
timing attack on gpus. In ACM Great Lakes Symposium on VLSI, pages
167–172. ACM, 2017.
[29] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
classiﬁcation with deep convolutional neural networks.
in neural information processing systems, pages 1097–1105, 2012.
Imagenet
In Advances
[30] Evangelos Ladakis, Lazaros Koromilas, Giorgos Vasiliadis, Michalis
Polychronakis, and Sotiris Ioannidis. You can type, but you can’t hide:
In Proceedings of the 6th European
A stealthy gpu-based keylogger.
Workshop on System Security (EuroSec), 2013.
[31] Nikolay Laptev, Jason Yosinski, Li Erran Li, and Slawek Smyl. Time-
series extreme event forecasting with neural networks at uber.
In
International Conference on Machine Learning, volume 34, pages 1–
5, 2017.
[32] Sangho Lee, Youngsok Kim, Jangwoo Kim, and Jong Kim. Stealing
webpages rendered on your browser by exploiting gpu vulnerabilities.
In Proceedings of the 2014 IEEE Symposium on Security and Privacy,
SP ’14, pages 19–33, Washington, DC, USA, 2014. IEEE Computer
Society.
[33] Xiangyu Liu, Zhe Zhou, Wenrui Diao, Zhou Li, and Kehuan Zhang.
When good becomes evil: Keystroke inference with smartwatch.
In
Proceedings of the 22Nd ACM SIGSAC Conference on Computer and
Communications Security, CCS ’15, pages 1273–1285, New York, NY,
USA, 2015. ACM.
[34] Yunhui Long, Vincent Bindschaedler, Lei Wang, Diyue Bu, Xiaofeng
Wang, Haixu Tang, Carl A. Gunter, and Kai Chen. Understanding
membership inferences on well-generalized learning models. CoRR,
abs/1802.04889, 2018.
[35] Chao Luo, Yunsi Fei, Pei Luo, Saoni Mukherjee, and David R. Kaeli.
Side-channel power analysis of a GPU AES implementation. In 33rd
IEEE International Conference on Computer Design, ICCD 2015, New
York City, NY, USA, October 18-21, 2015, pages 281–288, 2015.
[36] Pankaj Malhotra, Lovekesh Vig, Gautam Shroff, and Puneet Agarwal.
Long short term memory networks for anomaly detection in time series.
In Proceedings, page 89. Presses universitaires de Louvain, 2015.
[37] Microsoft. Lightgbm. https://github.com/microsoft/LightGBM, 2019.
[38] Thorben Moos, Amir Moradi, and Bastian Richter. Static power side-
IACR Cryptology
channel analysis-a survey on measurement factors.
ePrint Archive, 2018:676, 2018.
[39] MXNet. A scalable deep learning framework. https://mxnet.apache.org/,
2019.
[40] Hoda Naghibijouybari, Khaled N. Khasawneh, and Nael B. Abu-
Ghazaleh. Constructing and characterizing covert channels on gpgpus.
In Proceedings of the 50th Annual IEEE/ACM International Symposium
on Microarchitecture, MICRO 2017, Cambridge, MA, USA, October 14-
18, 2017, pages 354–366, 2017.
[41] Hoda Naghibijouybari, Ajaya Neupane, Zhiyun Qian, and Nael Abu-
Ghazaleh. Rendered insecure: Gpu side channel attacks are practical.
In Proceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security, CCS ’18, pages 2139–2153, New York, NY,
USA, 2018. ACM.
[42] Nvidia. Cuda c++ programming guide. https://docs.nvidia.com/cuda/
cuda-c-programming-guide/index.html.
[43] Nvidia. Multi-process service - nvidia developer documentation.
https://docs.nvidia.com/deploy/pdf/CUDA Multi Process Service
Overview.pdf, 2018.
[44] Nvidia. Cuda zone. https://developer.nvidia.com/cuda-zone, 2019.
[45] Nvidia. Cupti cuda toolkit documentation. https://docs.nvidia.com/cuda/
cupti/index.html, 2019.
[46] Nvidia.
Pascal gpu architecture.
https://www.nvidia.com/en-us/
data-center/pascal-gpu-architecture/, 2019.
[47] Nvidia. Security bulletin: Nvidia gpu display driver - february 2019.
https://nvidia.custhelp.com/app/answers/detail/a id/4772, 2019.
[48] Seong Joon Oh, Max Augustin, Bernt Schiele, and Mario Fritz. Towards
International Confer-
reverse-engineering black-box neural networks.
ence on Learning Representations, 2018.
[49] Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, and Michael P
In 2018
Wellman. Sok: Security and privacy in machine learning.
IEEE European Symposium on Security and Privacy (EuroS&P), pages
399–414. IEEE, 2018.
[50] Roberto Di Pietro, Flavio Lombardi, and Antonio Villani. CUDA leaks:
a detailed hack for CUDA and a (partial) ﬁx. ACM Transactions on
Embedded Computing Systems (TECS), 15(1):15, 2016.
org/docs/0.3.1/notes/cuda.html\#cuda-streams, 2017.
[51] PyTorch. Cuda semantics pytorch master documentation. https://pytorch.
[52] PyTorch. Pytorch. https://pytorch.org/, 2019.
[53] Thomas Ristenpart, Eran Tromer, Hovav Shacham, and Stefan Savage.
Hey, you, get off of my cloud: Exploring information leakage in third-
party compute clouds. In Proceedings of the 16th ACM Conference on
Computer and Communications Security, CCS ’09, pages 199–212, New
York, NY, USA, 2009. ACM.
[54] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev
Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla,
Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. Imagenet large
scale visual recognition challenge. Int. J. Comput. Vision, 115(3):211–
252, December 2015.
[55] Pulkit Sharma. 5 amazing deep learning frameworks every data scientist
must know (with illustrated infographic). https://www.analyticsvidhya.
com/blog/2019/03/deep-learning-frameworks-comparison/, 2019.
[56] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.
Membership inference attacks against machine learning models.
In
IEEE Symposium on Security and Privacy, pages 3–18. IEEE Computer
Society, 2017.
[57] Karen. Simonyan and Andrew Zisserman. Very deep convolutional
networks for large-scale image recognition. In International Conference
on Learning Representations (ICLR), 2015.
[58] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,
Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew
In Proceedings of the
Rabinovich. Going deeper with convolutions.
IEEE conference on computer vision and pattern recognition, pages 1–
9, 2015.
[59] Florian Tram`er, Fan Zhang, Ari Juels, Michael K Reiter, and Thomas
In
Ristenpart. Stealing machine learning models via prediction apis.
USENIX Security Symposium, pages 601–618, 2016.
[60] VMware.
networking.
Performance and use cases of vmware directpath i/o
https://blogs.vmware.com/performance/2010/12/
for
performance-and-use-cases-of-vmware-directpath-io-for-networking.
html, 2010.
[61] Binghui Wang and Neil Zhenqiang Gong. Stealing hyperparameters in
machine learning. In 2018 IEEE Symposium on Security and Privacy, SP
2018, Proceedings, 21-23 May 2018, San Francisco, California, USA,
pages 36–52, 2018.
[62] Chen Wang, Xiaonan Guo, Yan Wang, Yingying Chen, and Bo Liu.
Friend or foe?: Your wearable devices reveal your personal pin.
In
Proceedings of the 11th ACM on Asia Conference on Computer and
Communications Security, ASIA CCS ’16, pages 189–200, New York,
NY, USA, 2016. ACM.
[63] Lingxiao Wei, Bo Luo, Yu Li, Yannan Liu, and Qiang Xu. I know what
you see: Power side-channel attack on convolutional neural network
In Proceedings of the 34th Annual Computer Security
accelerators.
Applications Conference, ACSAC ’18, pages 393–406, New York, NY,
USA, 2018. ACM.
[64] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad
Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao,
Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing
Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto
Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff
Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg
Corrado, Macduff Hughes, and Jeffrey Dean. Google’s neural machine
translation system: Bridging the gap between human and machine
translation. CoRR, abs/1609.08144, 2016.
[65] Mengjia Yan, Christopher W. Fletcher, and Josep Torrellas. Cache
telepathy: Leveraging shared resource attacks to learn DNN architec-
In 29th USENIX Security Symposium (USENIX Security 20),
tures.
Boston, MA, August 2020. USENIX Association.
[66] Matthew D Zeiler and Rob Fergus. Visualizing and understanding
In European conference on computer vision,
convolutional networks.
pages 818–833. Springer, 2014.
[67] Yinqian Zhang, Ari Juels, Alina Oprea, and Michael K. Reiter. Home-
Alone: Co-residency detection in the cloud via side-channel analysis. In
32nd IEEE Symposium on Security and Privacy, pages 313–328. IEEE
Computer Society, 2011.
[68] Zhe Zhou, Wenrui Diao, Xiangyu Liu, Zhou Li, Kehuan Zhang, and
Rui Liu. Vulnerable GPU memory management: Towards recovering
raw data from GPU. PoPETs, 2017(2):57–73, 2017.
13