### Code Execution and System Security

#### Malicious Code
Email attachments and web links are common sources of viruses and other malware. To protect systems from such threats, we utilized a Secure Execution Environment (SEE). Specifically, we modified the MIME type handler configuration file used by Mozilla to ensure that executables and document viewers (e.g., Ghostscript and Xpdf) fetched over the Internet were run within the SEE. We tested this approach with sample malicious PostScript and Perl code. The code was executed inside the SEE, and using our graphical user interface (GUI), we observed that these programs were performing unexpected actions, such as creating large files in the user's home directory. These actions were then aborted. Additionally, at the time of writing, several image flaw exploits (JPEG virus) have attracted the attention of many researchers. Running image viewers inside an SEE can help mitigate the potential danger, as any malicious activity will be isolated from the main system.

Some types of malicious code are designed to recognize typical sandbox environments and may not display their malicious behavior when detected. This can lead users to trust the code and execute it outside the sandbox, where it can deliver its payload. Our approach ensures that running the code inside the SEE does not significantly inconvenience the user, making it more likely for them to use it consistently. In this case, the code will always exhibit benign behavior.

#### Software Installation
In another experiment, we performed a trial installation of the Mozilla browser. During the installation, an incorrect directory name (`/usr/bin`) was chosen instead of the default directory (`/usr/local/mozilla`). Under normal circumstances, this would cause Mozilla to copy numerous files into `/usr/bin`, thereby "polluting" the directory. By running the program in an SEE, the GUI indicated that a large number of files (some non-executable) were added to `/usr/bin`, which was undesirable. We aborted the installation and ran it again, this time specifying `/usr/local/mozilla` as the installation location. After completing the installation, we restarted the browser and visited several websites to verify that the program worked as expected. For this experiment, the system call restriction layer was modified to allow all web accesses. Finally, we committed the installation, and from that point on, we were able to use the new browser installation successfully outside the SEE.

#### Upgrading and Testing a Server
We also used the SEE to upgrade our web server to support SSL. We started a command shell under the SEE and used it to upgrade the Apache software installation. We then ran the new server, using static redirection for network operations so that a bind operation to port 80 was redirected to port 3080. We verified the new server's operation by accessing it via a browser connected to port 3080. Meanwhile, the original server remained accessible to everyone, allowing us to test the upgrade without shutting down the original server. After verifying the new server, we attempted to commit the results. However, this produced conflicts on some files, such as the access and error log files. We chose to ignore updates to these output files made within the SEE and committed only the rest, which was successful.

### Performance Evaluation

All performance results reported in this paper were obtained from a laptop running Red Hat Linux 7.3 with a 1.0GHz AMD Athlon4 processor, 512MB memory, and a 20GB, 4200rpm IDE hard disk. The primary metric was elapsed time.

#### Overhead for Applications Running in SEE
- **Utility Programs**: We studied `ghostview` and `tar` utilities. For `ghostview`, we processed a 31MB file with no file modification operations. For `tar`, we generated a tarball from a 26MB directory, with the only modification being the creation of this archive. From Figure 2, we observed a 3-12% overhead during the isolation phase and negligible commit time overhead.
- **Servers**: We measured the performance overhead on the Apache web server using WebStone [35], a standard web server benchmark. We used version 2.5 of this benchmark, running it on a separate computer connected to the server via a 100Mbps network. We ran the benchmark with two, sixteen, and thirty clients, simulating concurrent access to the web server. The clients randomly fetched HTML files ranging from 500 bytes to 5MB. The benchmark ran for 30 minutes, and the results were averaged across ten runs. The results are shown in Figure 2.
- **File System Benchmarks**: We used Postmark [9] and Am-Utils [18] benchmarks to evaluate the IFS. Postmark is a file system benchmark for measuring the performance of file systems used by internet applications, such as email. We configured Postmark to create 500 files in a file pool, with file sizes ranging from 500 bytes to 500KB. A total of 2000 file system operations were performed, including 1515 file creations, 1010 reads, 990 writes, and 1515 deletions. The tests were repeated ten times, and the results are depicted in Figure 2, showing an overall 18% performance degradation and near-zero commit overhead. Am-Utils is a CPU-intensive benchmark involving building the Am-Utils package, which contains 7.6M lines of C code and scripts. The building process creates 152 files and 19 directories, with 6 rename and 8 setattr operations. We ran this experiment in both the original file system and IFS. The results, shown in Figure 2, indicate a low isolation overhead of under 2% and negligible commit overhead.

#### Comparison of Log-based and State-based Commit
Figure 3 compares the efficiency of our state-based commit approach with a log-based commit implementation. The results show the advantage of using a state-based commit approach, particularly for applications like `tar`, Postmark, and Am-Utils. For instance, the large number of temporary files created and deleted in Am-Utils compilation and all the files created and deleted in Postmark execution are not considered in the committing stage as candidates, while log-based commit still needs to perform the whole set of operations (e.g., write) to all these files, resulting in a significant difference in commit time.

### Related Work

#### Sandboxing
Sandboxing approaches [7, 6, 1, 21, 27, 22] involve observing a program's behavior and blocking actions that may compromise the system's security. Janus [7] uses a proc file system-based system call interposition technique for Solaris, with a more recent version implemented on Linux using a kernel module. Chakravyuha [6] employs a kernel interception mechanism. MAPbox [1] is a sandboxing mechanism that aims to make the sandbox more configurable and usable by providing a template for sandbox policies based on a classification of application behaviors. Another approach [21] creates a policy sandbox for programs by first tracking the file requests made by the programs. This requires a training phase where users run the programs with "normal" inputs to capture a complete set of accessed files. Safe Virtual Execution (SVE) [27] uses Software Dynamic Translation to implement sandboxing, while Systrace [22] notifies the user about all system calls and uses the response to generate a policy.

The main drawback of sandboxing approaches is the difficulty in policy selection, i.e., determining what actions are permissible for a given piece of software. Malicious behavior may involve accessing authorized resources in unauthorized ways, and it is challenging to develop a practical system that allows users to conveniently state policies. In contrast, an SEE permits manual inspection, aided by helper applications, to determine if a program behaved as expected, offering more flexibility.

#### Isolation Approaches
Two-way isolation between a host and guest operating system forms the basis of security in virtual machine-based approaches for realizing SEEs. "Playground" approaches for Java programs [15, 4] also fall into this category, where untrusted programs are run on a physically isolated system while their display is redirected to the user's desktop. Covirt [3] proposes running most applications inside virtual machines instead of host machines. Denali [36] is another virtual machine-based approach that runs untrusted distributed applications.