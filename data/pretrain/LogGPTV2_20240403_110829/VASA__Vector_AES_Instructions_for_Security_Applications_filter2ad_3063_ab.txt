of MPC and the hardware acceleration of AES in x86 processors
(§ 2). Next, we provide context to our work with related work (§ 3).
Following that, we describe our computational framework for ef-
ficient batch identification and computation and how we applied
it (§ 4). Next, we evaluate and discuss the performance of the ap-
plications (§ 5). Finally, we conclude and provide possible future
research directions (§ 6).
2 BACKGROUND
In this section, we provide a brief background on secure multi-party
computation and how AES is computed using AES-NI and VAES
on x86-based processors.
2.1 AES Computation
There are two instruction set extensions on x86 for providing func-
tionality relating to the computation of AES: the AES new instruc-
tions (AES-NI) and the vector AES instructions (VAES) [5, 33, 56].
For the encryption direction, the key instructions from these ex-
tensions are AESENC and AESENCLAST which compute a single AES
round and the last AES round, respectively. The difference between
AES-NI and VAES is the instructions’ width and how many blocks
and round keys they work with: AES-NI is restricted to one and
VAES also allows two or four. Thus, one can compute AES-128 by
chaining an XOR operation with nine AESENC and one AESENCLAST
using a pre-expanded key. The key expansion itself can also take
advantage of the AESENCLAST instruction and is most efficiently
ACSAC’21,December6–10,2021,VirtualEvent,USAJean-PierreMünch,ThomasSchneider,andHosseinYalameTable1:Summaryofourperformanceimprovements.NewBatchedAES-NIindicateswhethertheimplementationreceivedanadditionalbatchingAES-NIimplementation.VAESindicateswhethertheperformanceimprovementincludesVAES.FrameworkNewBatchedAES-NIVAESMax.TotalImprov.ABY(Ref)[13,25,97]✓✓244%ABY(Custom)[25,40,41,97]✗✓171%EMP-OT[90]✗✓30%EMP-AGMPC[90,92]✓✓24%CrypTFlow2[82]✗✓52%ourfocus).Itcanbegeneralizedtoallnon-trivialimplementationsofcryptographicprimitiveswhichincludespipelinedAESimple-mentationsonARM[7],bitslicedAESimplementations[17,63]aswellasmoreunusualtechniqueslikeinstance-vectorizedhashfunctions.Anaturalareawheresuchcomplexdependenciesoc-curisSecureMulti-partyComputation(MPC),especiallygarbledcircuits[10,40,67,85,95,97],whichiswhyweusethemforas-sessingtheperformanceimpactforVAES.Moreconcretely,withgarbledcircuits,typicallybinarycircuitsusingprimarilyANDandXORgatesareevaluatedwithXORgatesonlyrequiringXORoper-ations[67],whereasANDgatesdorequireAESoperationstobeandsendingciphertexts.Thesegarbledcircuitscanthenbeusedforhighperformancesecuretwo-partycomputation,interactivezero-knowledgeproofsofarbitrarystatements[44,60,97],andotherapplications.MPCallowstosecurelycomputeapublicfunctiononprivateinputdataprovidedbymultiplepartiesandhenceisaninteractivewayforcomputingunderencryption.Sinceseveralyears,amulti-tudeofcompanies,includingAlibaba,Bosch,NTT,andUnboundamongmanyothersintheMPCAlliance[4],areworkingonMPCtechnology.WestudytheABYframework[25]forpassivelysecuretwo-partycomputationandtheEMP-AGMPC[90,92]frameworkforactivelysecuremulti-partycomputation.Aswearemanuallychangingtheimplementationoftheseschemeswithoutchangingtheprotocols,wesubstantiallyincreasethedeployabilityoftheseframeworksanddependentworksaswellasprovidingguidancetohowsimilareffectscanbeachievedforsimilarframeworks.Privacy-preservingmachine-learning(PPML)isapopularap-plicationofMPC.Here,generalmachine-learningtechniquesarerunonprivatedatawhilealsoprotectingthemodelparameters.Theprivateoutputistheinferenceortrainingresult[39].PPMLhasbecomeahottopicinrecentyearsandgainedtheattentionofmajorsoftware,serviceandhardwarevendors,e.g.,Facebook[66],Google[16],Intel[15],andMicrosoft[82],allofwhomareworkingonincreasingitspracticality.ApplicationsofPPMLincludeprivatehealthcare-basedinference,e.g.,topredictillnesses[22,69,84],pri-vatehealthcaremodeltrainingtoacquiremodelswithouthavingtorevealpatientdata[1],andprivateclusteringtopartitiondataaccordingwithcommonfeatures[73].Inparticular,inthiswork,wediscussprivateMLinferenceinthestate-of-the-artframeworkMicrosoftCrypTFlow2[82]whereonepartyholdsapre-trainedmodelandtheotheradataitemtobeclassifiedandthentheproto-colallowsclassificationusingthemodelwithoutthetwopartiesrevealingtheirprivateinputs.WeimproveCrypTFlow2[82]usingVAES.Asourfocusliesonmanualimplementationimprovements,wesubstantiallyincreasesuchPPMLapplications’deployabilitywithoutsacrificingcompatibilityorsecurity.OurContributions.Ourmaincontributionsareasfollows:•WeexpandthefocusofVAESfrommicroarchitecturalissueswheretheorderofAESoperationsisfixedapriori,toproto-colandimplementationdesignwherethesequenceofAESoperationsisnotknowninadvance.Forthis,weintroduceautomaticbatchidentificationandcomputationtechniquesforefficientuseofAESincomplexsecurityapplications.•WereportthefirstperformancemeasurementsforVAESintheareaofMulti-PartyComputation(MPC)andshowperformanceimprovementsfortheMPCframeworksABY,EMP-OTandEMP-AGMPC,aswellasthePPMLframeworkCrypTFlow2.OurimprovementsaresummarizedinTable1.•Weprovideourimplementationsforre-usebyothersandasguidanceforfutureimplementationeffortsathttps://encrypto.de/code/VASA.Outline.Therestofthispaperisorganizedasfollows:WestartwithprovidingthenecessarybackgroundontheinvestigatedtypesofMPCandthehardwareaccelerationofAESinx86processors(§2).Next,weprovidecontexttoourworkwithrelatedwork(§3).Followingthat,wedescribeourcomputationalframeworkforef-ficientbatchidentificationandcomputationandhowweappliedit(§4).Next,weevaluateanddiscusstheperformanceoftheap-plications(§5).Finally,weconcludeandprovidepossiblefutureresearchdirections(§6).2BACKGROUNDInthissection,weprovideabriefbackgroundonsecuremulti-partycomputationandhowAESiscomputedusingAES-NIandVAESonx86-basedprocessors.2.1AESComputationTherearetwoinstructionsetextensionsonx86forprovidingfunc-tionalityrelatingtothecomputationofAES:theAESnewinstruc-tions(AES-NI)andthevectorAESinstructions(VAES)[5,33,56].Fortheencryptiondirection,thekeyinstructionsfromtheseex-tensionsareAESENCandAESENCLASTwhichcomputeasingleAESroundandthelastAESround,respectively.ThedifferencebetweenAES-NIandVAESistheinstructions’widthandhowmanyblocksandroundkeystheyworkwith:AES-NIisrestrictedtooneandVAESalsoallowstwoorfour.Thus,onecancomputeAES-128bychaininganXORoperationwithnineAESENCandoneAESENCLASTusingapre-expandedkey.Thekeyexpansionitselfcanalsotake132VASA: Vector AES Instructions for Security Applications
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
done using the technique of Gueron et al. [40]. As most modern
x86 processors providing the AES extensions are pipelined, the data
dependency between the AES instructions can lead to pipeline stalls
if not filled otherwise. This is the reason why multiple independent
AES calls are batched together, allowing interleaved execution of
the instructions, i.e., starting execution of the second round of all
batched AES calls before starting execution of the third round of
any one of them.
This leads to optimal, minimal sizes for batches of AES calls
which depend on the microarchitecture involved as they need to
hide the latency of the instructions using the throughput and the
width of the instructions. A summary of these performance char-
acteristics using the data of [38] for modern x86 processor archi-
tectures is provided in Table 2. The performance characteristics of
128-bit AES instructions have remained the same for all successors
of AMD’s Zen architecture so far. Also the performance character-
istics of the AESENC and AESENCLAST instructions are identical.
Table 2: AES-NI and VAES instruction latencies, through-
put [38], and resulting minimal batch size for optimal effi-
ciency. Width 128 bits corresponds to AES-NI and other val-
ues are VAES. Cycles per instruction is abbreviated as “cy-
c/instr”.
2.2 Secure Multi-Party Computation
The goal of secure multi-party computation (MPC) is to compute
arbitrary functions among multiple parties on private inputs only
known to one party each [12, 14, 78, 94, 95]. Most relevant for this
work are protocols for oblivious transfer (OT), garbled circuits (GC),
and privacy-preserving machine-learning (PPML).
Oblivious Transfer (OT). In oblivious transfer, one party (the
receiver) inputs a choice bit and the other (the sender) supplies
two messages. The receiver then learns only the message cor-
responding to the choice bit. The computation of OT protocols
typically uses a small number of invocations of a public-key-based
OT protocol [23, 74] to extend to a larger number of OTs using
symmetric cryptography [8, 9, 57]. The primary bottleneck of
these OT extension protocols are the communication time, the
computation of a bit matrix transposition, and the computation
of encryption operations using AES [8]. Common variants of the
above OT functionality which allow to decrease communication
are random OT (R-OT) where the sender gets two random strings
and the receiver gets one of them depending on the choice bit, and
correlated OT (C-OT) where the sender can input a correlation
that the returned strings have to satisfy. Additionally, there has
been a line of research looking to further minimize the com-
munication needed for C-OT using a learning parity with noise
(LPN) assumption [18, 19, 93]. These pseudo-random correlation
generators (PCGs), like FERRET [93], reduce communication at
the expense of computation, and increased complexity where
a large matrix-vector product with randomized entries is computed.
Garbled Circuits (GC). Secure computation of general functions
is typically performed using a circuit-oriented representation of
that function. Garbled circuits (GCs) are one approach for this,
originally proposed for two parties [95] and later generalized
multiple parties [12]. In GC, the key invariant is that each wire’s
value is represented by two random keys which represent the
zero and one bits. The garbling party knows both wire keys and
the evaluating party only ever learns one key for each wire. For
each gate a garbled table is generated forming the garbled circuit,
to allow translation of a given pair of gate-input-wire keys to
the output wire key corresponding to the correct output bit. The
evaluator obtains the keys corresponding to the circuit input wires
via OT. Early constructions [12, 75, 95] used garbled tables that
could effectively be generated in parallel due to a lack of data
dependencies. However, more modern schemes like free-XOR [67],
HalfGates [97], or PRF-based garbling [40] require a topologically
ordered processing of gates in exchange for requiring only two
ciphertexts instead of three per AND gate, and XOR gates require
no communication in free-XOR [67] or one ciphertext in PRF-
garbling [40]. As these schemes require at least four applications of
a cryptographic function on some counter or gate identifier as well
as the gate input keys to generate the tables, most implementations
use AES with a fixed key [13, 42] though instantiations with
variable keys were also proposed in [40, 41]. Yao’s garbled circuits
protocol described above initially provides security against passive
adversaries [70] and there have been extensions in research to
security against active adversaries [51, 76, 77, 91, 92] that can
arbitrarily deviate from the protocol specification. The latest of
these schemes [91, 92] uses the free-XOR optimization [67] and
parties jointly compute authenticated versions of the garbled
tables so that a malicious garbler does not know the actual tables
nor can tamper with them while a malicious evaluator only sees
random-looking ciphertexts.
AES vs. LowMC. With free-XOR [67] and the S-box of [17], a
Boolean circuit for AES consists of 5 210 AND gates [47]. Starting
with LowMC [3], several dedicated MPC-friendly block ciphers
have been designed that minimize the number of AND gates (or
also multiplicative depth) over AES [3, 27, 28, 61]. Due to their
smaller and/or shallower circuits, such MPC-friendly block ciphers
improve the function that is evaluated via MPC, e.g., to privately
evaluate a block cipher, called Oblivious Pseudo-Random Function
(OPRF) [81], which has several applications like private set intersec-
tion for unbalanced set sizes in private contact discovery [62, 65].
However, the MPC protocols themselves are still implemented with
AES (e.g., garbling schemes, OT extension, or PRFs). The reason for
that is the superb performance of hardware acceleration of AES in
today’s CPUs which are highly optimized ASICs that require only
∼ 1.3 cycles/byte on one core using AES-NI [2]. In our paper, we
VASA:VectorAESInstructionsforSecurityApplicationsACSAC’21,December6–10,2021,VirtualEvent,USAadvantageoftheAESENCLASTinstructionandismostefficientlydoneusingthetechniqueofGueronetal.[40].Asmostmodernx86processorsprovidingtheAESextensionsarepipelined,thedatadependencybetweentheAESinstructionscanleadtopipelinestallsifnotfilledotherwise.ThisisthereasonwhymultipleindependentAEScallsarebatchedtogether,allowinginterleavedexecutionoftheinstructions,i.e.,startingexecutionofthesecondroundofallbatchedAEScallsbeforestartingexecutionofthethirdroundofanyoneofthem.Thisleadstooptimal,minimalsizesforbatchesofAEScallswhichdependonthemicroarchitectureinvolvedastheyneedtohidethelatencyoftheinstructionsusingthethroughputandthewidthoftheinstructions.Asummaryoftheseperformancechar-acteristicsusingthedataof[38]formodernx86processorarchi-tecturesisprovidedinTable2.Theperformancecharacteristicsof128-bitAESinstructionshaveremainedthesameforallsuccessorsofAMD’sZenarchitecturesofar.Alsotheperformancecharacter-isticsoftheAESENCandAESENCLASTinstructionsareidentical.Table2:AES-NIandVAESinstructionlatencies,through-put[38],andresultingminimalbatchsizeforoptimaleffi-ciency.Width128bitscorrespondstoAES-NIandotherval-uesareVAES.Cyclesperinstructionisabbreviatedas“cy-c/instr”.ArchitectureWidthLatencyThroughputMinimal[bits][cycles][cyc/instr]BatchSizeIntelHaswell128717IntelSkylake128414IntelIceLake12830.5625630.5125123112AMDZen12840.58AMDZen325640.5162.2SecureMulti-PartyComputationThegoalofsecuremulti-partycomputation(MPC)istocomputearbitraryfunctionsamongmultiplepartiesonprivateinputsonlyknowntoonepartyeach[12,14,78,94,95].Mostrelevantforthisworkareprotocolsforoblivioustransfer(OT),garbledcircuits(GC),andprivacy-preservingmachine-learning(PPML).ObliviousTransfer(OT).Inoblivioustransfer,oneparty(thereceiver)inputsachoicebitandtheother(thesender)suppliestwomessages.Thereceiverthenlearnsonlythemessagecor-respondingtothechoicebit.ThecomputationofOTprotocolstypicallyusesasmallnumberofinvocationsofapublic-key-basedOTprotocol[23,74]toextendtoalargernumberofOTsusingsymmetriccryptography[8,9,57].TheprimarybottleneckoftheseOTextensionprotocolsarethecommunicationtime,thecomputationofabitmatrixtransposition,andthecomputationofencryptionoperationsusingAES[8].CommonvariantsoftheaboveOTfunctionalitywhichallowtodecreasecommunicationarerandomOT(R-OT)wherethesendergetstworandomstringsandthereceivergetsoneofthemdependingonthechoicebit,andcorrelatedOT(C-OT)wherethesendercaninputacorrelationthatthereturnedstringshavetosatisfy.Additionally,therehasbeenalineofresearchlookingtofurtherminimizethecom-municationneededforC-OTusingalearningparitywithnoise(LPN)assumption[18,19,93].Thesepseudo-randomcorrelationgenerators(PCGs),likeFERRET[93],reducecommunicationattheexpenseofcomputation,andincreasedcomplexitywherealargematrix-vectorproductwithrandomizedentriesiscomputed.GarbledCircuits(GC).Securecomputationofgeneralfunctionsistypicallyperformedusingacircuit-orientedrepresentationofthatfunction.Garbledcircuits(GCs)areoneapproachforthis,originallyproposedfortwoparties[95]andlatergeneralizedmultipleparties[12].InGC,thekeyinvariantisthateachwire’svalueisrepresentedbytworandomkeyswhichrepresentthezeroandonebits.Thegarblingpartyknowsbothwirekeysandtheevaluatingpartyonlyeverlearnsonekeyforeachwire.Foreachgateagarbledtableisgeneratedformingthegarbledcircuit,toallowtranslationofagivenpairofgate-input-wirekeystotheoutputwirekeycorrespondingtothecorrectoutputbit.TheevaluatorobtainsthekeyscorrespondingtothecircuitinputwiresviaOT.Earlyconstructions[12,75,95]usedgarbledtablesthatcouldeffectivelybegeneratedinparallelduetoalackofdatadependencies.However,moremodernschemeslikefree-XOR[67],HalfGates[97],orPRF-basedgarbling[40]requireatopologicallyorderedprocessingofgatesinexchangeforrequiringonlytwociphertextsinsteadofthreeperANDgate,andXORgatesrequirenocommunicationinfree-XOR[67]oroneciphertextinPRF-garbling[40].Astheseschemesrequireatleastfourapplicationsofacryptographicfunctiononsomecounterorgateidentifieraswellasthegateinputkeystogeneratethetables,mostimplementationsuseAESwithafixedkey[13,42]thoughinstantiationswithvariablekeyswerealsoproposedin[40,41].Yao’sgarbledcircuitsprotocoldescribedaboveinitiallyprovidessecurityagainstpassiveadversaries[70]andtherehavebeenextensionsinresearchtosecurityagainstactiveadversaries[51,76,77,91,92]thatcanarbitrarilydeviatefromtheprotocolspecification.Thelatestoftheseschemes[91,92]usesthefree-XORoptimization[67]andpartiesjointlycomputeauthenticatedversionsofthegarbledtablessothatamaliciousgarblerdoesnotknowtheactualtablesnorcantamperwiththemwhileamaliciousevaluatoronlyseesrandom-lookingciphertexts.AESvs.LowMC.Withfree-XOR[67]andtheS-boxof[17],aBooleancircuitforAESconsistsof5210ANDgates[47].StartingwithLowMC[3],severaldedicatedMPC-friendlyblockciphershavebeendesignedthatminimizethenumberofANDgates(oralsomultiplicativedepth)overAES[3,27,28,61].Duetotheirsmallerand/orshallowercircuits,suchMPC-friendlyblockciphersimprovethefunctionthatisevaluatedviaMPC,e.g.,toprivatelyevaluateablockcipher,calledObliviousPseudo-RandomFunction(OPRF)[81],whichhasseveralapplicationslikeprivatesetintersec-tionforunbalancedsetsizesinprivatecontactdiscovery[62,65].However,theMPCprotocolsthemselvesarestillimplementedwithAES(e.g.,garblingschemes,OTextension,orPRFs).ThereasonforthatisthesuperbperformanceofhardwareaccelerationofAESintoday’sCPUswhicharehighlyoptimizedASICsthatrequireonly133ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Jean-Pierre Münch, Thomas Schneider, and Hossein Yalame
show how the efficiency of such implementations of MPC protocols
can be further improved by using VAES.
Privacy-Preserving Machine-Learning (PPML). The goal of
PPML is to apply machine-learning techniques while preserving
the privacy of the data and models [37, 39, 45, 64]. While this
application can include training and inference [39], we focus
on inference, in particular on inference for neural networks as
done in Microsoft CrypTFlow2 [82]. This involves computing the
linear and non-linear stages using optimized protocols for the
client’s private data input and the server’s private model input,
only yielding the result to the client. We note that the practicality
of PPML has improved drastically over time to the point where
now accurate, full-sized neural network inference is possible
in a privacy-preserving setting even on moderately powerful
hardware [82].
3 RELATED WORK
In this section, we discuss how our work relates to previous work.
In particular, we discuss the relation to previous protocol-level and
implementation-level improvements.
3.1 Protocol-Level Improvements
One primary direction for research in the past has been to improve
the protocols themselves, e.g., by reducing the amount of communi-
cation or the number of invocations to computationally expensive
primitives [10, 43, 67, 75, 85, 91, 97]. In addition, some works handle
the circuit generation for MPC protocols from specifications in a
high-level language by using industry-grade hardware synthesis
tools and tweaking them for logic synthesis [24, 46, 79, 87]. Our
work is largely orthogonal to these approaches as we focus on im-
proving the implementations and the frameworks used for them.
However, there are advances in protocol design which significantly
complicate efficient implementation, e.g., the requirement for gates
in circuits to be processed in topological order [40, 67, 97]. There
have been prior works that modified the protocol and increased
communication to allow for more efficient computation [55], but
we do not follow their approach and maintain protocol compati-
bility. This focus on implementation improvements for relatively
low-level building blocks allows protocol compatible performance
improvements for the discussed protocols and those building on
top of it. Such works include Cerebro [98], TinyGarble2 [52], and
CrypTFlow2 [82] all of which build on EMP [90] and can thus profit
from our improvements of EMP.
3.2 Implementation-Level Improvements
Another major direction has been improving the implementation
of the protocols. This has seen four sub-directions: Improving the
performance of individual operations, improving the parallelization
of the implementation, improving the memory behavior, and using
dedicated hardware to accelerate computationally expensive steps.
Operations. In OT extension, bit matrix transposition is one of the
most computationally expensive operations [8]. Previous optimiza-
tions of this operation have been using an asymptotically optimal
transposition algorithm [36], or 128-bit vector registers [90]. We
improve on the latter through the use of wider AVX512 vector
registers instead. Beyond this, OT extension has been a major
application of fixed-key AES [13] on which we improve through
the use of VAES instead of AES-NI for the implementation. Fur-
thermore, there have been efforts to increase the performance of
individual operations in GC, e.g., improving the implementation