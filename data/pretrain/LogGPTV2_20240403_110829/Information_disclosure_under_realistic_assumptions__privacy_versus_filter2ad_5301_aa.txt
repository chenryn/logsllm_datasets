title:Information disclosure under realistic assumptions: privacy versus
optimality
author:Lei Zhang and
Sushil Jajodia and
Alexander Brodsky
Information Disclosure under Realistic Assumptions:
Privacy versus Optimality
Lei Zhang1
Sushil Jajodia1,2
Alexander Brodsky1,3
1Center for Secure Information Systems, George Mason University, Fairfax, VA 22030
2The MITRE Corporation, 7515 Coleshire Drive, Mclean, VA 22102
3Department of Computer Science, George Mason University, Fairfax, VA 22030
{lzhang8, jajodia, brodsky}@gmu.edu
ABSTRACT
The problem of information disclosure has attracted much
interest from the research community in recent years. When
disclosing information, the challenge is to provide as much
information as possible (optimality) while guaranteeing a
desired safety property for privacy (such as l-diversity). A
typical disclosure algorithm uses a sequence of disclosure
schemas to output generalizations in the nonincreasing or-
der of data utility; the algorithm releases the ﬁrst gener-
alization that satisﬁes the safety property.
In this paper,
we assert that the desired safety property cannot always be
guaranteed if an adversary has the knowledge of the un-
derlying disclosure algorithm. We propose a model for the
additional information disclosed by an algorithm based on
the deﬁnition of deterministic disclosure function (DDF),
and provide deﬁnitions of p-safe and p-optimal DDFs. We
give an analysis for the complexity to compute a p-optimal
DDF. We show that deciding whether a DDF is p-optimal
is an NP-hard problem, and only under speciﬁc conditions,
we can solve the problem in polynomial time with respect to
the size of the set of all possible database instances and the
length of the disclosure generalization sequence. We then
consider the problem of microdata disclosure and the safety
condition of l-diversity. We relax the notion of p-optimality
to weak p-optimality, and develop a weak p-optimal algo-
rithm which is polynomial in the size of the original table
and the length of the generalization sequence.
Categories and Subject Descriptors
K.4.1 [COMPUTERS AND SOCIETY]: Public Policy
Issues—Privacy; F.2.m [ANALYSIS OF ALGORITHMS
AND PROBLEM COMPLEXITY ]: Miscellaneous
General Terms
Security
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07, October 29–November 2, 2007, Alexandria, Virginia, USA.
Copyright 2007 ACM 978-1-59593-703-2/07/0010 ...$5.00.
Name Age
Alan
Old
Bob
Old
Clark Middle M
F
Diana Middle
Ellen
Young
F
F
Young
Fen
Condition
Sex
M Heart Disease
M Viral Infection
Cancer
Cancer
Flu
Ulcer
Table 1: A Patient Table
Keywords
Privacy Preservation, Information Disclosure, Disclosure Al-
gorithm
1.
INTRODUCTION
The problem of information disclosure has drawn much
attention in recent years. To support sharing information
on a large scale, we need to ensure privacy while providing
as much data utility to users as possible. Typically, privacy
requirements are expressed by a formal safety condition. For
example, the property l-diversity (e.g., [2]) is used to ensure
privacy in the microdata disclosure.
There has been much work on maximizing data utility
subject to the satisfaction of a safety property. A typical
approach is to enumerate a sequence of data generalizations
T = (T1, T2, . . . , Tn) in a nonincreasing order of data utility.
The ﬁrst data generalization Ti in the sequence that satisﬁes
the desired safety property is disclosed. Because the ﬁrst
such generalization is disclosed, intuitively, maximal data
utility is achieved, while the safety property is satisﬁed at
the same time. This enumeration approach is used in many
algorithms for microdata disclosure, including [2, 8, 15, 25].
Unfortunately, this approach does not take into account
the fact that users may know not only the disclosed data
and the safety property it satisﬁes, but also the disclosure
algorithm used to produce the disclosed data. In conjunction
with this knowledge, we claim that the adversary can “break”
the safety property.
To illustrate the problem, consider an example of micro-
data disclosure in Table 1 which contains medical records
of six patients. The ﬁrst three columns of the table are as-
sumed to be public knowledge. To protect patient privacy,
suppose that we do not wish that a condition of any patient
can be determined from the disclosed data and the public
knowledge. Certainly, removing all the information of the
Name attribute is not enough.
If the attributes Age, Sex
573and Condition are released, the patient who has a particu-
lar condition can be still determined from the attributes Sex
and Condition, which are so-called quasi-identiﬁers [23]. For
example, from the fact that there is only one patient who is
Middle age and also Male, Clark’s medical condition can be
determined.
Assume that we would like to release the patient table
over (possibly generalized) quasi-identiﬁer and the sensitive
attribute Condition, and guarantee the safety property of
entropy 2-diversity [2], which in this case means, intuitively,
that each patient has at least two equally likely choices of
sensitive attribute values. Assume also that we traverse the
generalization lattice1 for the quasi-identiﬁers in this order:
(Age, Sex), (Age, ∗), (∗, Sex) and (∗, ∗), in which case we
generate corresponding disclosure tables shown in Figure 1.
The ﬁrst table in the sequence that satisﬁes Entropy 2-
diversity is table (c). (In fact, table (c) even satisﬁes entropy
3-diversity, more than the required 2-diversity.) Therefore, a
standard algorithm will disclose table (c). However, with the
knowledge of the selection algorithm and the generalization
sequence, an adversary can infer that both Clark and Diana
have Cancer from the disclosed table, which is a violation
of their privacy.
Indeed, an adversary can reason as follows: From the
public knowledge, the adversary knows that Alan and Bob
are of old age, Clark and Diana are of middle age, and
Ellen and Fen are of young age. Furthermore, the adver-
sary knows that the generalization (Age, *), (corresponding
to table (b)) was not selected because it does not satisfy
entropy 2-diversity. Therefore, at least one pair (Alan and
Bob), (Clark and Diana), or (Ellen and Fen) must have the
same condition. Finally, from the disclosed table (c), the ad-
versary knows that the ﬁrst 3 rows correspond to Alan, Bob
and Clark (who are males), and the last 3 rows correspond
to Diana, Ellen and Fen (who are females). Therefore, Alan
and Bob cannot have the same condition, nor can Ellen and
Fen. The only remaining possibility is that Clark and Diana
have the same condition. Since Clark and Diana belong to
two separate groups in table (c), the only common condition
they may have is Cancer. This violates their privacy (i.e.,
entropy 2-diversity).
The above example illustrates that the traditional method
of selecting the ﬁrst generalization in the sequence that sat-
isﬁes the safety property cannot guarantee this safety prop-
erty when an adversary knows the disclosure algorithm and
the generalization sequence. We believe that it is unrealistic
to assume otherwise in most cases. This situation is similar
in the cryptography area where encryption algorithms are
typically assumed to be known by the adversary.
This paper is concerned with the problem of maximizing
data utility subject to satisfaction of a safety property. To
the best of our knowledge, this is the ﬁrst paper to propose
a model and algorithms that guarantee safety under a more
realistic assumption that the adversary knows the disclosure
algorithm and the generalization sequence.
More speciﬁcally, the contributions of this paper are as
follows. First, we model disclosed information under the
assumption that the adversary has the knowledge of what
we call a deterministic disclosure function (DDF), which is a
formal notion of a function deﬁned by a disclosure algorithm.
1A generalization lattice consists of all the possible gener-
alizations of quasi-identiﬁers and a partial order deﬁned by
the generalization function.
This is done by introducing a formal deﬁnition of a disclosure
set. Intuitively, all the adversary can infer from the disclosed
data and the knowledge of the DDF is that a true database
state is one of the database state in the disclosure set.
Second, given a safety predicate p, we deﬁne the notion
of p-safety for a DDF. Intuitively, it means that for any
true database state, the DDF returns an answer, such that
the disclosure set inferred by the adversary (not just the
disclosed answer!) satisﬁes the safety predicate p. We also
deﬁne the notion of p-optimality for a DDF. Intuitively, it
means that, in addition to p-safety, there does not exist a
locally better DDF, in terms of data utility, that is also p-
safe.
Third we prove that p-optimal DDF is computable, al-
though the problem of deciding whether a DDF is p-optimal
is NP-hard. We then introduce two speciﬁc conditions un-
der each of which we prove that the problem of whether
a DDF is p-optimal is P-time in the size of the set of all
possible database states and the size of the generalization
sequence. We do this by developing polynomial algorithms
to compute a p-optimal DDF. Note, however, that the size
of all possible database states may be exponential, in the
worst case, in the size of a single database state. Clearly,
computing p-optimal DDFs in such a general setting would
not be practical beyond a restricted number of considered
database states.
Fourth, we turn to developing a disclosure algorithm for
a speciﬁc setting of microdata disclosure. For this case, the
locally better relation on DDFs in terms of data utility is
provided by a sequence of quasi-identiﬁer generalizations.
We develop a p-safe algorithm which is weakly p-optimal,
deﬁned formally in the paper, which is polynomial in the
size of the original table and the generalization lattice.
This paper is organized as follows. In Section 2 we develop
a general model for the the information disclosure that han-
dles the problem discussed, and deﬁne the notions of DDF,
disclosure set, p-safety and p-optimality.
In Section 3 we
prove the computability of p-optimal DDF, give its complex-
ity result and propose polynomial algorithms to compute p-
optimal DDF under additional conditions. In Section 4 we
consider the problem of p safety and optimality in microdata
disclosure, and provide a polynomial algorithm for ﬁnding
weekly p-optimal DDF. We discuss related work in Section 5
and conclude in Section 6.
2. MODELLING THE PROBLEM
We denote by x the true database state. As an example,
x could hold a single value, a vector of values, or a relational
database instance. Given a database type, we denote by D
the domain of database, i.e., the set of all possible database
states. Furthermore, we denote by D a sub-domain of D
which is the set of states in D that satisfy given database
constraints.
Consider the following Example 1: Let the true database
state be x = 22040, i.e., it consists of a single ZIP code. The
domain D of database is the set of all 5-digit nonnegative
integers. Assume D ={22030, 22031, 22040, 23000, 24000}
is a sub-domain which satisﬁes the database constraint that
each ZIP code must be of a hospital owned by the Acme
Corporation.
When we do not want to disclose the true database state
x, the system can instead provide the user with a set s of
database states that contains x. To formalize this, we next
Age Sex Cond
Age Sex Cond
Age Sex Cond
Age Sex Cond
O
O
M
M
Y
Y
HD
VI
Ca
Ca
Fl
Ul
M
M
M
F
F
F
(a)
O
O
M
M
Y
Y
VI
HD
Ca
Ca
Fl
Ul
∗
∗
∗
∗
∗
∗
(b)
∗
∗
∗
∗
∗
∗
Ca
VI
HD
Fl
Ul
Ca
M
M
M
F
F
F
(c)
∗
∗
∗
∗
∗
∗
VI
Ca
HD
Fl
Ul
Ca
∗
∗
∗
∗
∗
∗
(d)
Figure 1: Sequence of Disclosure Tables
22040
(a)
22030
22031
22040
(b)
22030
22031
22040
23000
24000
(c)
Figure 2: Instance Sets for Example 1
introduce the notion of a disclosure schema, which deﬁnes,
for a given true database state x, the set s to be returned
to the user.
Deﬁnition 1. A disclosure schema T over D is a partition
i=1 si = D and
of D; i.e., T = {s1, s2, . . . , snT }, where SnT
si ∩ sj = φ ∀1 ≤ i < j ≤ n.
Intuitively, given a true database state x and a disclosure
schema T , the “returned” partial information will be a set
s ∈ T such that x ∈ s.
In Example 1, consider a possible disclosure schema Ti,
1 ≤ i ≤ 6, that partitions the set of all 5-digit zip codes
into subsets, each of which having all the zip codes with the
same ﬁrst 6−i digits. If Ti is used, the disclosed information
would be the ﬁrst 6 − i digits of the true database state x.
Many possible disclosure schemas can be used to disclose
partial information on a true database state to preserve pri-
vacy. However, it is important to provide maximal data util-
ity, i.e., disclose as precise information on the true database
state as possible.
1, si
2, . . . , si
For simplicity, we assume that we are provided with a can-
didate disclosure schema sequence T = (T1, T2, . . . , Tn), Ti =
{si
ni }, 1 ≤ i ≤ n where T1, . . . , Tn are disclosure
schemas, which appear in nonincreasing order of data util-
ity. We always assume that the last disclosure schema Tn
is {D}, which corresponds to disclosing no information, be-
yond what the user knows from the database constraints.
This gives the system the choice to disclose nothing, and
thus always be able to satisfy the required safety property.
To represent the nonincreasing order of data utility in the
candidate disclosure schema sequence T , we write Ti < Tj
to denote that Ti appears earlier than Tj in T (i.e., i < j).
Also, by a slight abuse of notation, we will sometimes
refer to T as a set of all elements in the sequence T . Given
a speciﬁc problem, we call the correlated triple (D, D, T ) the
problem setting.
In Example 1, one possible candidate schema sequence is
T = (T1, T2, . . . , T6) where the disclosure schema Ti, 1 ≤
i ≤ 6, discloses the ﬁrst 6 − i digits of the true database
state x.
Given a speciﬁc disclosure schema Ti and the assumption
that the user already has the knowledge that x ∈ D, the
Input: D, D, T , x;
Var: