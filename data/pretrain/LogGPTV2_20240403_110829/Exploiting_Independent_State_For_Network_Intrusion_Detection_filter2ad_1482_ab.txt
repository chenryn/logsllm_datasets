ternate analyses.
Alternatively, we can simply print the data, either in a
“pretty-printed” human-readable form, or encoded as XML
(although this latter is not fully implemented at this point).
This provides us with a more abstract view of network activ-
ity than raw packets, and we expect this to be highly useful
for trafﬁc analysis.
3.2.2 Spatially Independent State
For spatially-independent state, we need to transfer state
from one NIDS instance to another running concurrently.
We do so by establishing network connections between
the instances. One of the instances calls the new function
listen, which opens a port on the local host waiting for
connections from other instances. Once a connection is es-
tablished, there are several ways to exchange state. Figure 1
shows how we integrated them into Bro’s architecture. Us-
ing the script-function request remote events one
side can subscribe to a set of events, meaning that whenever
the other side generates one of the events, it automatically
forwards the event to the other side:
# Request all HTTP events from peer.
request_remote_events(10.0.0.1,
47756/tcp, /http_.*/);
At the receiving end the event looks the same as one gener-
ated locally (though it’s possible to test whether a particular
event did indeed originate locally, or remotely).
In addition to sharing events, multiple Bro instances may
share data, too. When a global script-level identiﬁer is de-
clared as &synchronized, modiﬁcations to its value will
be propagated to all peers for which the identiﬁer is also de-
clared &synchronized. For example:
global saw_Blaster: set[addr] &synchronized;
Figure 1: Integrating independent state into Bro.
Configuration
Policy scripts
Real−time notification
Policy Layer
User State
Event Subscriptions
Event control
Event stream
Events
Event Engine
Connections
Packet Filter
Packet filter
Packets
Packet stream
Network
Exchanged with peers
will cause the script variable saw Blaster to be synchro-
nized across each active Bro process. Any change made by
one of them to the set will be transparently reﬂected in the
value of the set as seen by the others.
We implemented synchronized tables by propagating
changes to the data in terms of descriptions of the opera-
tions to perform on the data rather than the full (and prob-
ably mostly unmodiﬁed) data itself. For example, when we
insert an element into a large set, we propagate “insert ele-
ment ‘foo’ into set ‘bar’ ”. This can in some circumstances
however lead to race conditions. Avoiding them would re-
quire mutually-exclusive data operations, for example by
using a token-based reservation system [24], but this would
violate Bro’s realtime processing constraints due to having
to wait for access before performing an operation. For fur-
ther details, see [19].
3.3 Robust and Secure Communication
Clearly, inter-NIDS communication requires robust and
secure operation. Regarding robustness, a key point is that,
from the perspective of the NIDS process’s main function-
ality, inter-NIDS communication should be unobtrusive. In
particular, inevitable networking difﬁculties such as time-
outs or unexpected termination should not perturb the main
operation. Therefore, rather than adding a network commu-
nication component directly into the current event engine /
script interpreter structure, we instead spawn a second pro-
cess exclusively dedicated to handling the communication
with peers. The two processes communicate by means of
a Unix pipe. (We did not use threads in order to keep their
address spaces separate.) On multi-processor systems, us-
ing two processes has the additional advantage of making
use of more than one CPU. Subsequently, we refer to the
two processes as main process and communication process,
respectively.
One key element of our design was to base it on se-
mantically unidirectional communication. This means that
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:11:05 UTC from IEEE Xplore.  Restrictions apply. 
Bro’s processing never expects one side to reply to some-
thing the other side sent. While doing so restricts er-
ror detection and handling somewhat, it also signiﬁcantly
eases implementation by avoiding having to deal with unre-
ceived replies (which would require timeouts and a failure-
recovery scheme). We believe that the decrease in complex-
ity wins more in terms of robustness than we lose in terms of
error processing. Yet, we note that the unidirectionality only
affects the core-level communication. It is still quite possi-
ble to build a script-level handshake mechanism by passing
a sequence of events between two peers.
In §3.2.2 we discussed how the NIDS’s realtime con-
straints leads us to abide impure synchronization seman-
tics, i.e., the possibility of race conditions. Similarly, our
communication design does not make any timing guaran-
tees for the communication. For example, transferring large
amounts of data may delay the reception of an event. Also,
while all state from one endpoint will always arrive in the
order in which it was sent, state from multiple endpoints
may be received intermixed.
Along with designing for robust communication, we also
need to secure the communication, i.e., provide for conﬁ-
dentiality and authentication. We do so via SSL (imple-
mented using OpenSSL [15]). See [19] for a discussion of
such security aspects.
3.4 Integrating External State
While we performed our initial implementation of inde-
pendent state in the context of the Bro NIDS, the concept
applies more generally to other applications as well.
In
principle, any system, not just other NIDS instances, may
choose to make its ﬁne-grained internal state accessible to
peers.
As a major step in this direction, the lightweight, highly
portable Broccoli2 library [4] enables arbitrary applications
to partake in the exchange of Bro’s state. Broccoli is
an independent implementation of (parts of) the serializa-
tion/communication protocol that we have developed for the
Bro system. Broccoli nodes can request, send, and receive
events just like Bro instances can. In [8], we demonstrate
some of the power of such NIDS-external independent state
by supplying the Bro system with host-based application
context.
4 Applications
We now describe several powerful applications of inde-
pendent state in network intrusion detection. We ﬁrst show
how we can use independent state to greatly enhance Bro’s
2Broccoli is the healthy acronym for “Bro Client Communications Li-
brary.”
traditional model of regular checkpointing, including sup-
port for robust crash recovery. Then we discuss distributed
intrusion detection, concentrating on the utility of spatially
independent state. Finally, we show how independent state
can be used for dynamic reconﬁguration, proﬁling, and de-
bugging.
We implemented each of these applications. Given in-
dependent state, combined with the NIDS’s ﬂexibility, we
found all rather easy to achieve. Although at ﬁrst blush each
might seem to be yet-another-extension of Bro’s generally-
extensible functionality, the ease of implementation proves
the power of the approach.
Our experiences with these applications come from mon-
itoring the access links in several large environments: the
M¨unchner Wissenschaftsnetz (MWN; research network in-
cluding two universities and other institutions; Gbps, heav-
ily loaded), the University of California, Berkeley (UCB;
Gbps, heavily loaded), and the Lawrence Berkeley National
Laboratory (LBNL; Gbps, medium load).
4.1 Checkpointing
IDS’s face fundamental state management problems. Ei-
ther the system uses a static allocation of state for its anal-
ysis, in which case it becomes vulnerable to easy forms of
attacker evasion; or it allocates different types of state dy-
namically, in which case managing and reclaiming that state
becomes a major burden. While Bro provides a variety of
timers for use in state management, from operational ex-
perience we have found that state still inexorably accrues,
in part due to our reluctance to assign timers to every data
item because it’s hard to determine good a priori settings
for these, or even identify all of them (there are hundreds of
script-level variables).
To date, Bro’s only support for large-scale state recla-
mation has been the brute force approach of simply start-
ing over from scratch. That is, to run Bro 24x7 we (and
other Bro users) resort to checkpointing, which in this con-
text means periodically starting up a new instance of Bro
and killing off the old one.
The frequency with which
this is done ranges from daily (LBNL) to every few hours
(MWN, UCB).
For Bro, the two main types of state lost when check-
pointing are internal connection state (including analyzer-
speciﬁc state and attached timers) and script-level data.
However, the concept of persistence described in §3.2.1
now enables us to individually choose connections (by
calling make connection persistence) and script-
level data (via &persistent declarations) to transform
into independent state, thus enabling a new Bro instance
to use them as part of its initial state. Doing so allows us
to continue longer-running forms of analysis uninterrupted,
such as tracking slow scans, long-lived interactive connec-
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:11:05 UTC from IEEE Xplore.  Restrictions apply. 
tions, usernames, inferred software versions, alerts already
generated, and addresses that Bro has blocked in the past
using its dynamic blocking facility.
While temporally-independent state thus enables us to
keep key state across restarts, implementing it soundly also
requires a dynamic handover mechanism. The problem
here is that the currently executing instance of Bro has to
save its persistent state at some speciﬁc point in time, after
which the new instance can begin executing. If we have to
wait for the new instance to start up, we will incur a mon-
itoring outage. We solve this problem by using not tem-
porally independent state, but spatially independent. We
implement dynamic handover by starting up the new in-
stance and having it connect via a (local) network connec-
tion to the old instance, requesting its current set of persis-
tent state. After this has been successfully transmitted, the
old instance terminates itself, and the new one starts pro-
cessing.
As already discussed, we do not simply make all state
persistent. Doing so would defeat the purpose of check-
pointing. But having the tools now to selectively make state
persistent, the next step is to identify the state for which
this makes sense. For our operational environments, we
keep internal connection state for interactive services that
tend to have long-lived connections: FTP, SSH, telnet, and
rlogin connections. For script-level data, we took Bro’s de-
fault policy scripts (as of version 0.8a57) as representative
for the usage of state in Bro scripts. Our ﬁrst observation is
that nearly all of the scripts store their relevant data in tables
or sets. We found ﬁve basic usages: (1) remembering mes-
sages already logged to avoid duplication, (2) remember-
ing hosts which have done “something” (e.g., propagating
a worm), (3) associating additional state with connections
(e.g., which FTP data connections have been negotiated by
a control channel), (4) holding conﬁguration data, such as
particular hosts allowed to do “something”, (e.g., connect to
a certain host; this data is more or less ﬁxed), (5) remember-
ing additional data derived from the script’s analysis (e.g.,
software installed on a host).
Taking the MWN environment as a test case, we made all
tables belonging to the ﬁrst group persistent. Most of these
tables are low in volume,3 and suppressing unnecessary log
messages is a vital NIDS capability [2, 10]. For the second
group, we differentiate between short-term (minutes or less)
and longer-term data. The former is often quite large in vol-
ume and often not worth keeping. For example, the script
recognizing the Blaster worm [3] by its scanning activity
keeps two tables: one tracking hosts that have communi-
cated over TCP port 135 within the last ﬁve minutes, and the
second remembering all already-identiﬁed worm sources.
We decided to make only the latter persistent.
3With the notable exception of the table weird ignore recording all
the “crud” [16]. In large networks, we see tons of crud.
The third group (associating additional state) is more
problematic. Ideally, we would like to keep information for
all persistent connections, but discard all the rest. But to do
so the scripts would need signiﬁcant restructuring, as their
semantics vary too much to automatically deduce which in-
formation is associated with persistent connections. There
are some tables, though, which we know always correspond
to state for persistent connections (e.g., the FTP analyzer
script remembers FTP connections). We made these persis-
tent, but left all other tables unmodiﬁed (i.e., ephemeral).
We also left the fourth group untouched, as conﬁgura-
tions are mostly static and better changed manually if the
need arises. Finally, for the last group we found we needed
to make case-by-case decisions. For example, to keep vul-
nerability proﬁles [20] one of the scripts detects the soft-
ware used by different hosts, an excellent example of infor-
mation we declare &persistent so we do not lose it.
4.2 Crash Recovery
A related application of independent state is better re-
covery from crashes. Three main reasons for the crash of
a NIDS are resource exhaustion, attacks, and programming
errors [16]. In most systems, including Bro, in each case we
lose all the state so far collected by the system. By using the
checkpoint function (see §3.2.1) regularly, however, we
can signiﬁcantly mitigate the effects of crashes, so that we
only lose data accumulated since the last checkpoint.
Our experience is that crash recovery is invaluable. This
is not only the case when actively developing the IDS, but
also in a production environment, where crashes are still a
fact of life, particularly due to resource exhaustion. Not
only does crash recovery allow us to continue operating
with only a minor loss of state (in terms of the importance
of the state), but the checkpoint also allows us to analyze
the particularly signiﬁcant state post mortem (cf. §4.4).
4.3 Distributed Analysis
Once we’ve provided a means for a NIDS to communi-
cate its state, we can then use that mechanism to distribute
its analysis. To date, distributed NIDS have generally im-
posed a speciﬁc model on the form of distribution. For ex-
ample, DIDS [18] pioneered the sensor model, gathering
low-level data remotely while performing higher level se-
mantic analysis centrally. On the other hand, Emerald [17]
constructs a hierarchical structure to propagate information
up to the root level.
Independent, ﬁne-grained state opens up new degrees of
ﬂexibility for distributed analysis. In this section we look
at three different models, all of which we have been able to
implement and experiment with by having added indepen-
dent state to Bro. The ﬁrst model supports load-balancing
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:11:05 UTC from IEEE Xplore.  Restrictions apply. 
for monitoring high-volume links. The second supports the
well-known “distributed sensor” model. The third looks at
propagating information between decoupled systems.
4.3.1 Load-balancing
On today’s high-volume links,4 it is exceedingly difﬁcult
to analyze the full packet stream with a single NIDS (unless
one utilizes custom hardware [14]). One strategy for coping
with such a load is to distribute the analysis across several
machines, each doing only a part of the work. A key ques-
tion then is how to coordinate their operation. Currently,
using Bro operationally we do this by running several inde-
pendent instances on different slices of the network trafﬁc.
But without any state sharing, this loses important informa-
tion. Thus, our goal is to retain the depth of analysis a single
Bro could in principle achieve if it could cope with the load.
To this end, we ﬁrst need to decide how to divide the
trafﬁc between the multiple systems. We can either do so
statically (each system gets all packets matching some ﬁxed
criteria) or dynamically (e.g., for each connection we de-
cide individually which system will analyze it). Our initial
efforts have focused on static approaches due to their sim-
plicity, distributing based on: (i) the local IP space, or (ii)
application protocol.