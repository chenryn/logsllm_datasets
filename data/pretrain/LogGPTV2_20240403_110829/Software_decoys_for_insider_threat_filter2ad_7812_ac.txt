tools, MOSS [17]. This experiment shows that the generated
bogus software is completely different from the original one.
• Software Complexity: Based on software metrics proposed
in [7], we evaluate the software complexity of the resulting
1http://www.apache.org/, http://sourceforge.net/
2For beacons, we tested all types of beacons with the collected OSS
projects.
 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80Similarity(%)Open Source Projects 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80Similarity(%)Open Source ProjectsFirst code transformationSecond code transformationThird code transformation 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80Similarity(%)Open Source Projects(a) Experiment A
(b) Experiment B
Figure 3: Containment (The x-axis is each of 80 open source
projects.)
(a) WMC(Number of methods
deﬁned in class)
(b) CBO(Coupling
object classes)
between
(c) NOC(Number of immedi-
ate sub-classes of a class)
(d) DIT(Maximum inheritance
path from the class to the root
class
Figure 4: Software Complexity for diverse bogus projects and
an ordinal project (from Experiment A)
bogus projects. As original projects are transformed to cre-
ate bogus programs, design weaknesses in the structure of
the newly created bogus programs can make them vulnera-
ble to detection by professional adversaries. Hence, we use
software metrics [7] to evaluate the soundness of the design
and structure of a bogus project so that the generated bogus
software looks like normal source code. We utilize various
metrics: Weighted Method per Class(WMC), Coupling Be-
tween Objects(CBO), Number of Children(NOC), and Depth
of Inheritance Tree(DIT). These software metrics are widely
accepted to evaluate software complexity.
We experimented with various combinations of bogus projects
and original projects as follows (Note that Tj = {t1, t2, ...., tn }
and j, k, l = {1, ..., n}). These various experiments demonstrate
that the proposed system creates a large number of dissimilar bogus
projects for a given project. We executed code transformation for
Experiment A and B as follows.
1. Experiment A: With the same input, we produced diverse
bogus projects. We transform an original project three times
to generate different bogus projects. The input is always the
same target original project. Thus, the output will be three
different bogus projects from the same original project, P 1
Bn,
Bn, P 3
P 2
Bn. (i.e. PO
Tj→ P k
Bn )
2. Experiment B: With different inputs, we generate different
bogus projects. We transform an original project and its re-
sulting bogus projects consecutively. In other words, the ﬁrst
input is an original project, the second input is the ﬁrst result-
ing bogus project, the third input is the second resulting bo-
gus project, and so on. The output is three different kinds of
bogus projects from different inputs. We estimate the num-
ber of code transformation iterations to satisfy a desirable
threshold. (i.e. PO
Tj→ P k
Tj→ P l
Bn)
Bn
3. Comparison C: We evaluate the similarity among all the re-
sulting bogus projects from Experiment A and Experiment
B. (i.e. The comparison is a combination of P k
Bn)
Similarity: Figure 2 (a) shows that the proposed system drops
from 45% to 60% of the similarities between bogus and original
projects in the ﬁrst iteration. This means that the proposed sys-
tem dramatically changes given original software to bogus soft-
ware. The bogus software seems totally different from the original
software.
Bn and P l
Figure 2 (b) shows the similarity after transforming one target
project three consecutive times. The similarities between the ﬁrst
resulting bogus projects and the target original project are less than
50%. However, as we proceeded to perform code transformation
several times, the similarities were decreased approximately 10%
to 20% for each iteration. The similarity between the bogus project
in the last iteration and the original project was in the range of
0%-30% for MOSS. This means that the proposed system can dra-
matically obfuscate original source code with only 2 or 3 iterations
to obtain desirable similarity satisfying a predeﬁned threshold.
Figure 2 (c) displays the diversity of bogus programs. Even
though we used the same original project, the similarities among
the resulting bogus projects are very different. In addition, through
the course of several iterations, the similarities among the different
bogus projects become low.
Based on our ﬁndings, we expect that the resulting bogus project
will have low similarity so as to thwart adversaries and render them
incapable of distinguishing bogus programs from real programs.
Containment: Figure 3 describes the containment between bo-
gus projects and original projects. To measure it, we extracted the
number of lines matched between two projects by using MOSS. We
calculated the total number of lines in Java source code for each
project. The results is very similar to the result of similarity, so we
discuss these results in brief., Figure 3(a) showed that the ﬁrst re-
sulting bogus program had less than half of the original code. As in
Figure 3(b), the containment between different bogus projects from
one target project gradually decreases, according to the number of
transformation iterations. The last bogus project from one target
project includes a small portion of original source code. However,
the containment is high between different versions of one bogus
project for the version control system.
Software Complexity: Figure 43 shows the results concerning
software complexity with respect to each of the four metrics: WMC,
CBO, NOC, DIT. The experiment validates one of the system prop-
erties in Section 2 as being believable.
To achieve another property, that is, to be believable, the trans-
formed bogus projects should have similar software complexity
simulating real projects. Figures 4 shows that the complexity in
the resulting bogus projects in our proposed system is in fact sim-
ilar to the original projects. In the case of WMC, the bogus and
original projects have small classes in the codes. The DIT is 2 in
3Due to the space limitation, we show only the result of Experiment
A. However, the result of Experiment B is similar to Figure 4.
 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80Containment(%)Open Source Projects 0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80Containment(%)Open Source ProjectsFirst code transformationSecond code transformationThird code transformation 0 10 20 30 40 50 0 10 20 30 40 50 60 70 80WMCOpen Source Projects 0 10 20 30 40 50 0 10 20 30 40 50 60 70 80CBOOpen Source Projects 0 1 2 3 4 5 0 10 20 30 40 50 60 70 80NOCOpen Source Projects 0 1 2 3 4 5 0 10 20 30 40 50 60 70 80DITOpen Source Projectseach case, since DIT should in general be less than 5. Since the
CBO should generally be less than 14, the accumulated total for
both projects is less than 20. Almost identical results are obtained
in both projects when measuring NOC.
Therefore, even though the proposed system transforms source
code, the resulting software complexity remains similar to the orig-
inal project. We expect that adversaries can not help but interpret
bogus projects as normal source code, failing to notice the forg-
eries despite their best efforts using these standard software mea-
surement tools.
5. RELATED WORK
Decoy Technologies have been a critical defense method to se-
cure our computing system. Cliff Stoll was the ﬁrst to use decoy
ﬁles and honeytokens to detect insider attacks exﬁltrating informa-
tion [18, 20]. Bell and Whaley proposed the structure of deception
used to hide real information while exposing false information [4].
Bowen et al. designed an automated system for generating decoy
documents [5, 6]. They also deﬁned the desirable properties for de-
coy documents [5], and the proper deployment of decoy documents
was suggested through various user studies [16]. These methods
aimed to detect insider attacks based on fake information to con-
fuse and deceive adversaries.
To create software decoys, we utilized various code obfusca-
tion techniques that are used in order to protect software copyright.
Fred Cohen [9] ﬁrst proposed call obfuscation to generate syntacti-
cally different but semantically identical versions of the same pro-
gram. There has been much work on program diversity through
semantics-preserving transformations [3, 12, 11]. Such code ob-
fuscation is also used in generating malicious programs, such as
metamorphic or polymorphic codes to avoid virus scanners [8, 10].
In this paper, we utilized code obfuscation to automatically gener-
ate software decoys.
6. CONCLUSION
We proposed a software-based decoy system that is designed to
identify software exﬁltration by insiders through complete isolation
of proprietary software from planted bogus software. The proposed
system is a trap-based defensive system that is intended to deceive
malicious adversaries, forcing them to expend considerable effort
to differentiate real source code from bogus programs. To create
software decoys, we utilized various code obfuscation techniques
that are designed to protect a program from analysis and unwanted
modiﬁcation. Code obfuscation transforms a program either by in-
serting new code or modifying existing code. This makes the pro-
posed system generate a large number of diverse believable bogus
software programs from any given input program. To our knowl-
edge, the proposed system is the ﬁrst to study how to automatically
generate large volumes of bait software, represented as ordinary
normal source code project archives in a ﬁle system, that is believ-
able and difﬁcult it for an adversary to judge as fake.
7. REFERENCES
[1] http://sneakers.cs.columbia.edu:8080/fog/.
[2] DARPA-funded fake docs track unauthorized users.
http://www.theverge.com/2011/11/4/2537647/darpa-fake-
documents-security-wikileaks.
[3] B. Anckaert, M. Jakubowski, R. Venkatesan, and
K. De Bosschere. Run-time randomization to mitigate
tampering. In Proceedings of the Security 2nd international
conference on Advances in information and computer
security, pages 153–168, 2007.
[4] J. B. Bell and B. Whaley. Cheating and deception.
Transaction Publishers, 1991.
[5] B. M. Bowen, S. Hershkop, A. D. Keromytis, and S. J.
Stolfo. Baiting inside attackers using decoy documents. In
5th International ICST conference for Security and Privacy
in Communication Networks (SecureComm), pages 51–70,
2009.
[6] B. M. Bowen, M. B. Salem, S. Hershkop, A. D. Keromytis,
and S. J. Stolfo. Designing host and network sensors to
mitigate the insider threat. IEEE Security & Privacy,
7(6):22–29, 2009.
[7] S. R. Chidamber and C. F. Kemerer. A metrics suite for
object oriented design. IEEE Transaction on Software
Engingeering, 20:476–493, June 1994.
[8] F. B. Cohen. Defense-in-depth against computer viruses.
Computers & Security, 11(6):563–579, 1992.
[9] F. B. Cohen. Operating system protection through program
evolution. Computers & Security, 12(6):565–584, 1993.
[10] F. B. Cohen. A Short Course on Computer Viruses. John
Wiley & Sons, 1994.
[11] C. Collberg, C. Thomborson, and D. Low. A taxonomy of
obfuscating transformations. Technical report, Department of
Computer Science, The University of Aukland, 1997.
[12] K. Heffner and C. S. Collberg. The obfuscation executive. In
Proceedings of 7th International Information Security
Conference(ISC), volume 3225 of Lecture Notes in
Computer Science, pages 428–440, September 2004.
[13] M. A. McQueen and W. F. Boyer. Deception used for cyber
defense of control systems. In Proceedings of the 2nd
conference on Human System Interactions, HSI’09, 2009.
[14] T. Parr and K. Fisher. Ll(*): the foundation of the antlr parser
generator. In Proceedings of the 32nd ACM SIGPLAN
conference on Programming language design and
implementation(PLDI ’11), 2011.
[15] T. J. Parr and R. W. Quong. Adding semantic and syntactic
predicates to ll(k): pred-ll(k). In International Conference on
Compiler Constrution (CC), pages 263–277.
Springer-Verlag, 1994.
[16] M. B. Salem and S. J. Stolfo. Decoy document deployment
for effective masquerade attack detection. In Proceedings of
the Eighth Conference on Detection of Intrusions and
Malware & Vulnerability Assessment(DIMVA), July 2011.
[17] S. Schleimer, D. S. Wilkerson, and A. Aiken. Winnowing:
Local algorithms for document ﬁngerprinting. In
Proceedings of the 2003 ACM SIGMOD International
Conference on Management of Data, San Diego, California,
USA, June 9-12, 2003, pages 76–85, 2003.
[18] L. Spitzner. Honeytokens: The other honeypot. 2003.
[19] J. Yuill, D. Denning, and F. Feer. Using deception to hide
things from hackers: Processes, principles, and techniques.
5:26–40, 2006.
[20] J. Yuill, M. Zappe, D. Denning, and F. Feer. Honeyﬁles:
deceptive ﬁles for intrusion detection. Proceedings from the
Fifth Annual IEEE SMC Information Assurance Workshop
2004, (June):116–122, 2004.