2023
TABLE VII: Attack Performance (Precision and Recall) of
LINKTELLER on three datasets in the transductive setting, compared
with two baseline methods LSA2-{post, attr} [11]. We follow He et
al. [11] to compose a balanced dataset containing an equal number
of connected and unconnected node pairs. Groups of rows represent
different density belief ˆk of the attacker.
Cora
Citeseer
Pubmed
ˆk
Method
k/4
k/2
k
1.5k
Ours
LSA2-post
LSA2-feat
Ours
LSA2-post
LSA2-feat
Ours
LSA2-post
LSA2-feat
Ours
LSA2-post
LSA2-feat
precision
99.9 ± 0.1
96.7 ± 0.2
96.9 ± 0.2
99.9 ± 0.0
94.1 ± 0.3
90.4 ± 0.5
99.5 ± 0.1
86.7 ± 0.2
73.6 ± 0.1
66.7 ± 0.0
66.0 ± 0.0
59.9 ± 0.2
recall
25.0 ± 0.0
24.2 ± 0.0
24.2 ± 0.0
50.0 ± 0.0
47.0 ± 0.1
45.2 ± 0.2
99.5 ± 0.1
86.7 ± 0.2
73.6 ± 0.1
100.0 ± 0.0
99.1 ± 0.0
89.8 ± 0.2
precision
100.0 ± 0.0
98.8 ± 0.1
99.8 ± 0.1
100.0 ± 0.0
96.7 ± 0.0
97.4 ± 0.1
99.7 ± 0.0
90.1 ± 0.2
80.9 ± 0.1
66.7 ± 0.0
66.4 ± 0.0
63.2 ± 0.1
recall
25.0 ± 0.0
24.7 ± 0.0
24.9 ± 0.0
50.0 ± 0.0
48.4 ± 0.0
48.7 ± 0.1
99.7 ± 0.0
90.1 ± 0.2
80.9 ± 0.1
100.0 ± 0.0
99.6 ± 0.0
94.7 ± 0.2
precision
100.0 ± 0.0
89.9 ± 0.2
97.8 ± 0.2
100.0 ± 0.0
86.8 ± 0.1
95.2 ± 0.1
99.7 ± 0.0
78.8 ± 0.1
82.4 ± 0.1
66.6 ± 0.0
65.3 ± 0.0
64.0 ± 0.0
recall
25.0 ± 0.0
22.5 ± 0.1
24.4 ± 0.0
50.0 ± 0.0
43.4 ± 0.0
47.6 ± 0.0
99.7 ± 0.0
78.8 ± 0.1
82.4 ± 0.1
99.9 ± 0.0
98.0 ± 0.0
96.0 ± 0.0
TABLE VIII: AUC of LINKTELLER comparing with two baselines
LSA2-{post, attr} [11] in the transductive setting. Each column cor-
responds to one dataset. Different rows represent different methods.
Method
Ours
LSA2-post
LSA2-attr
Dataset
Citeseer
Cora
Pubmed
1.00 ± 0.00 1.00 ± 0.00 1.00 ± 0.00
0.93 ± 0.00 0.96 ± 0.00 0.87 ± 0.00
0.81 ± 0.00 0.89 ± 0.00 0.90 ± 0.00
in the inductive setting. As analyzed in Appendix E5, in the
transductive setting, LINKTELLER is expected to achieve bet-
ter performance and retain its advantage over LSA2-X. Here,
we aim to provide evaluations on the performance of LINK-
TELLER in the transductive setting to support the analysis.
We compare LINKTELLER to LSA2-{post, attr} [11] in the
transductive setting using three datasets (Cora, Citeseer, and
Pubmed) from their paper. We also follow the same setup (as
in their Paragraph “Datasets Conﬁguration” in Section 5.1) to
compose the balanced set of node pairs to be attacked which
contains an equal number of connected and unconnected pairs.
We follow the hyper-parameters in Kipf et al. [13] to train the
GCN models on these datasets and then perform LINKTELLER
attack and LSA2-{post, attr} attacks on the trained models.
We report the attack performance (Precision and Recall)
in Table VII and the AUC scores in Table VIII. First, as a
sanity check, our results in Table VIII matches the Figure 4
in He et al. [11] on these three datasets. Second, we evaluate
the density belief ˆk only up to 1.5k in Table VII, since 2k
corresponds to the case where all node pairs are predicted
positive by the attacker, leading to 50% precision and 100%
recall for all methods. Overall, as shown in the two tables,
LINKTELLER invariably outperforms LSA2-{post, attr} in the
transductive setting.
6) Choosing ε on a Validation Dataset: In Section VI, we
present the model utility and attack effectiveness under a range
of ε (1-10) in Figure 3, and provide corresponding discussions
regarding the tradeoff between model utility and privacy as
well as its dependencies in Section VI-C and Section VI-D.
TABLE IX: (a) Model utility and (b) attack effectiveness on differ-
ent models. Each column corresponds to a dataset. We consider four
types of models: vanilla GCN, MLP, EDGERAND, and LAPGRAPH.
(a) Model utility (F1 score)
Dataset
RU
0.319
0.290
DE
0.551
0.545
FR
0.404
0.373
ENGB
0.601
0.598
PTBR
0.411
0.358
Flickr
0.515
0.463
0.299 ± 0.006 0.545 ± 0.003 0.321 ± 0.027 0.607 ± 0.000 0.423 ± 0.018 0.459 ± 0.002
0.292 ± 0.011 0.546 ± 0.001 0.299 ± 0.017 0.601 ± 0.001 0.401 ± 0.010 0.467 ± 0.002
ε = 7
ε = 8
ε = 6
ε = 9
Model
vanilla GCN
MLP
EDGERAND
LAPGRAPH
(b) Attack effectiveness (F1 score) on different node degree distri-
butions
Degree
Model
Dataset
RU
DE
FR
ENGB
PTBR
Flickr
low
uncon-
strained
high
vanilla GCN 84.9 ± 1.2
EDGERAND 18.9 ± 10.8
LAPGRAPH
22.9 ± 3.3
vanilla GCN 74.7 ± 1.5
EDGERAND 58.1 ± 2.2
LAPGRAPH
59.6 ± 1.2
vanilla GCN 75.8 ± 2.3
EDGERAND 72.6 ± 1.5
LAPGRAPH
69.6 ± 1.0
86.8 ± 5.1
4.4 ± 6.3
5.3 ± 7.5
78.5 ± 4.5
60.1 ± 5.0
59.6 ± 2.0
78.9 ± 0.8
76.5 ± 1.8
68.5 ± 1.1
92.5 ± 5.4
0.0 ± 0.0
13.3 ± 12.5
80.9 ± 2.0
67.1 ± 4.6
67.1 ± 2.9
83.0 ± 3.7
78.1 ± 2.7
73.4 ± 2.8
82.9 ± 4.9
19.0 ± 12.0
22.0 ± 1.0
69.5 ± 2.5
41.6 ± 8.1
46.9 ± 3.7
82.2 ± 3.4
82.3 ± 1.5
68.0 ± 1.7
86.6 ± 1.3
32.9 ± 2.5
23.8 ± 2.2
77.9 ± 3.5
73.2 ± 5.1
68.4 ± 5.8
84.8 ± 1.6
83.7 ± 1.0
78.4 ± 1.4
52.1 ± 5.8
0.0 ± 0.0
26.8 ± 10.1
32.9 ± 13.3
0.0 ± 0.0
2.4 ± 3.4
18.3 ± 5.2
16.9 ± 2.9
15.7 ± 2.6
In this part, we take on a new perspective and focus on
a practical approach for selecting the appropriate parameters
(mainly the privacy budget ε) to train DP GCN models with
reasonable model utility—we select the parameter ε on the
validation dataset, and then report the ﬁnal performance on the
test set. Concretely, when selecting ε on the validation set, we
set a lower threshold (e.g., F1 score of the MLP model) for the
model utility, and select the smallest ε satisfying that the utility
of the trained DP GCN on the validation set is higher than the
given threshold. Then, we evaluate both the model utility and
attack effectiveness under the selected ε on the test set.
Due to the space limit, we refer the readers to our full ver-
sion [49] for the detailed evaluation setup. We report the evalu-
ation results in Table IX and brieﬂy summarize the conclusions
below. First, regarding the model utility in Table IX(a), with
the same constraint on model utility on the same dataset, we
end up with different ε for different DP mechanisms, which
implies that the level of noise that can be tolerated by different
DP mechanisms is different. Second, in terms of the attack
effectiveness in Table IX(b), the main conclusion is that the
theoretical guarantee provided by DP cannot translate into
sufﬁcient protection against LINKTELLER while maintaining
a reasonable level of model utility. However, the attack effec-
tiveness presented in Table IX(b) suggests that, in low degree
settings, differential privacy can empirically protect against
LINKTELLER although the level of protection is heavily data-
dependent, varying a lot across different datasets and different
node degree distributions. Relevant discussions on the impact
of node degree distributions speciﬁcally are provided in Sec-
tion VI-D.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:20:38 UTC from IEEE Xplore.  Restrictions apply. 
2024