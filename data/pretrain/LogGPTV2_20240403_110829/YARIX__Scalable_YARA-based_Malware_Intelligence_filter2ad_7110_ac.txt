most settings. Malware analysts regularly deﬁne new search
criteria ad hoc to explore malware ﬁles as part of their threat
analysis. Any new n-gram not covered by the index yet re-
quires a costly rebuild of the index. Consequently, in this
work, we do not assume such a priori knowledge of search
criteria, which allows to apply arbitrary searches.
Another optimization strategy would be to ignore n-grams
that do not serve as discriminative part of any search criteria.
In the setting of text ﬁles, one could ignore words that fre-
quently occur (like articles), and likewise ignore them during
search. In our setting, lacking knowledge of the search crite-
ria, we could stop maintaining posting lists of those n-grams
that are shared by “too many” ﬁles in the index. This follows
the intuition that such n-grams would not help to distinguish
between malware families, each of which makes up only a
smaller portion of the overall index. However, a general risk
of this strategy is that the index can no longer used as ﬁlter
for large classes of ﬁles in the index. For example, in princi-
ple, the n-gram of the Windows PE header allows to search
for all Windows executables. Yet, given that it is shared by
“too many” ﬁles, it will not be part of the index. Furthermore,
particular malware families may be overrepresented in mal-
ware collections [34], e.g., due to polymorphism. Neglecting
popular n-grams would thus render it infeasible to search for
those families. Given that we want YARIX to be generic, com-
plete, and compatible to large search results, we do not further
follow this strategy.
3.3.2 Optimizing the Posting Lists
A completely orthogonal approach to shrinking the set of
n-grams is to reduce the size of the posting lists. For the rea-
sons mentioned before, for YARIX, we follow only optimiza-
tion strategies of this kind. In particular, YARIX (i) operates
without storing offset, (ii) deploys optimal delta encoding to
represent posting lists, and (iii) groups ﬁles to shorten the
identiﬁer space that has to be stored. All of these methods do
not break our completeness guarantees, i.e., they retain that
all ﬁles matching a certain criteria will be returned.
3.4 Offset-Free Index
As a ﬁrst measure to shrink the posting lists, we remove any
positional information from them so that they only contain the
ﬁle IDs. Typically, posting lists contain the ﬁle ID where an
3546    30th USENIX Security Symposium
USENIX Association
n-gram was found, plus its offset within the ﬁle. Neglecting
offsets saves a large amount of data. Apart from not storing
the offsets themselves, we also save space as we do not count
n-grams occurring multiple times. For instance, if a malware
sample f contains the 4-gram 00 00 00 00 1000 times, a
traditional inverted n-gram index would store 1000 ( f ,oi)
pairs in the posting list of 00 00 00 00 where the oi values
are the offsets at which the 4-gram occurs in f . In contrast,
YARIX will only store f once in the posting list. The negative
aspect of ignoring offsets is that it complicates the search
process. After intersecting the posting lists, a position-aware
index ensures that the offsets contained in the posting lists are
in sequential order to eliminate any wrong candidates among
the set of all possible candidates. Given that this is not possi-
ble anymore if we remove offsets from the posting lists, we
solve this is by performing a normal sequential search on the
candidates. However, this is not a problem in our context as
the YARA expression optimizations that we described in Sec-
tion 2 require us to do a sequential YARA scan anyway. We
will show in Section 4 that acceptable real-world performance
is maintained with this solution.
3.5 Variable Delta Encoding
We aim to create an index for up to 232 malware ﬁles. Such
a bound nicely sets an upper limit for the size of one ID. In
particular, we have the guarantee that a ﬁle ID always ﬁt into
32 bits. Note this restriction is not a limitation. In fact, if the
index is saturated, we can create further indexes and search
through all indexes combined.
Despite the upper bound for ﬁle IDs, storing 32 bits per
entry is wasteful. In particular, when using sorted posting lists,
we can store ID differences instead of their absolute values. In
well-populated lists, such deltas would be signiﬁcantly smaller
than 32 bits. That is, in a sorted posting list, we compute
δi = fi+1 − fi and we store the list f0,δ0,δ1, . . . ,δ(cid:96)−2, f(cid:96). We
store the smallest ﬁle ID in the beginning to ensure that we can
reconstruct the original posting list. Similarly, we store the
last ﬁle ID f(cid:96) in an absolute representation to ease incremental
index updates (see Section 3.7 for details).
To leverage the space gain of delta encoding, we store
the deltas using a variable-length s-bit encoding instead of
ﬁxed-size deltas. s-bit encoding uses chunks of s + 1 bits,
where the most signiﬁcant bit of a chunk indicates that an-
other chunk follows. For example, consider the number 6743,
which is 11010 01010111 in binary. In an uncompressed
form, we would naively require 32 bits to store this num-
ber. With 7-bit encoding, the number would be encoded as
11101001 00010111, i.e., 16 bits only. Similarly, with 5-bit
encoding it would be 111010 101010 000111, i.e., 18 bits.
For s = 3, the encoding would be 1110 1100 1101 1011
0001, i.e., 20 bits.
Given that the optimal value for s depends on the size of the
posting list, YARIX uses a hybrid s-bit encoding that chooses
the optimal s. During the initial index build, the optimal value
of s is determined per posting list by comparing different
choices. Header bits encode this optimal choice.
3.6 Grouping
We previously removed offsets from our index to save space.
Doing so made pure index searches unsound as the returned
ﬁle IDs were an overapproximation and soundness could only
be gained back by using the index as an optimizer for sequen-
tial search. In a situation where even more compression is
required, we can apply a more aggressive overapproximation
to the posting lists, which we call grouping.
General idea. The basic idea is as follows: we randomly
assign each ﬁle ID in a posting list to a group and store a group
ID instead of the ﬁle ID. Storing group IDs instead of ﬁle
IDs brings two optimization beneﬁts. First, by choosing the
possible number of groups small enough it further decreases
the footprint given that storing a group ID requires fewer bits
than a ﬁle ID even in an uncompressed form. Second, the
random mapping from ﬁle IDs to group IDs creates collisions,
as multiple ﬁle IDs in a posting list may belong to the same
group and thus also saves space.
Formally, given a posting list mapping an n-gram x to a list
of ﬁle IDs f1, . . . , f(cid:96), we compute a group ID gi for each fi as
follows:
gi = fi mod gn,
(1)
where gn is the number of groups. We could have gi = g j for
i (cid:54)= j, i.e., collisions can occur as previously discussed. This
means that the index search for a single n-gram x will now
yield a of set of group IDs Gx = {g1, . . . ,g(cid:96)} instead of a set
of ﬁle IDs. It will be necessary to revert Gx to a set of ﬁle IDs
Fx, which can be done by inverting Equation (1). Formally, let
fmax be the largest ﬁle ID currently indexed by YARIX, then
Fx is the union of a ﬁnite subset of the congruence class of gi
modulo gn for each gi ∈ Gx, i.e.,:
Fx =
{gi + kgn | k ≥ 0,gi + kgn ≤ fmax}.
(2)
(cid:91)
gi∈Gx
When searching for a string there will be one such set for each
distinct n-gram of the string, i.e., sets Fx1, . . . ,Fx(cid:96). To get the
ﬁnal set of ﬁle IDs F, that will then be searched sequentially,
we perform a set intersection, i.e.:
F =
Fxi.
(3)
(cid:92)
xi∈{x1,...,x(cid:96)}
Varying moduli reduce over-approximation. Note that
the immense overapproximation created by Equation (2) (be-
cause of the set union) is compensated by the set intersection
in Equation (3). As previously mentioned, the choice of gn
inﬂuences the disk footprint as smaller group IDs require less
space and trigger more collisions. For example, by ensuring
USENIX Association
30th USENIX Security Symposium    3547
that gn ≤ 216 we can guarantee that a group ID will never
occupy more than 2 bytes. However, to minimize the overlap
between different posting lists in Equation (3) we want gn to
be prime and most importantly to differ per n-gram xi (cid:54)= x j.
That is, instead of a ﬁxed gn, we want a variable gnx. This
is obviously not possible in most situations, e.g., consider
the case n = 4 where 232 prime numbers would be required,
which does not work if gnx ≤ 216. However, by inspecting
Equation (3) it becomes evident that a problem only occurs
if all gnxi are the same, because then the intersection will be
all the true ﬁle IDs plus all their congruence classes modulo
gnxi. As soon as one gnxi is different this is not the case as
the congruence classes do not all overlap anymore. Therefore,
we simply deﬁne gnx as a uniform hash function that maps
n-grams to the list of the largest m prime numbers smaller
than gn. By choosing the m largest prime numbers we ensure
that the groups stay close to our desired number of groups
gn in order to not overapproximate too much. For a search
string consisting of (cid:96) different n-grams, the probability of
all n-grams sharing the same modulus is therefore given by
m−(cid:96). In our evaluation in Section 4, we will use m = 256,
which will make that probability sufﬁciently small even for
short search strings. For example, for a search string consist-
ing of 2 distinct n-grams, we have m−(cid:96) = 0.0015%. From
a computational point of view it is also worth noting that
Equation (2) and Equation (3) can be computed and at the
same time most of the costly set operations can be avoided.
For instance, let Gi be the smallest set of group IDs. We then
iterate over each f ∈ Fi and check for each n-gram x j (cid:54)= xi if
G j (cid:51) g = f mod gnx j. Only if this is the case for all n-grams
x j we know that f ∈ F. This avoids the set union in Equa-
tion (2) by generating Fi element by element and also avoids
the set intersection in Equation (3) by performing a cheap set
element check g ∈ G j of an already constructed set.
Selective Grouping: It is advisable to not apply grouping
to every posting list. For example, consider 16-bit group IDs
and a posting list consisting of 300000 ﬁle IDs. In this case
almost all group IDs would be occupied after grouping and
using these posting lists during search would reduce the com-
pensatory effects of the intersection. To account for this, we
can determine a threshold τ for the size of posting lists up
until which they will be considered for grouping. We will
evaluate different choices for the grouping threshold τ as well
as the general overall effectiveness of grouping in Section 4.
Example. In the following, we will give a brief example for
our grouping methodology. Consider a case where N = 100
malware samples need to be indexed, i.e., we can assume 7
bits per ﬁle ID for simplicity. Assume we use gn = 8 groups,
i.e., we can use 4 btis per group ID and we use the primes
11,13,17,19, . . .. Furthermore, for the sake of simplicity as-
sume we use 1-grams instead of 4-grams. We want to search
for all ﬁles containing the bytes A, B and C, which we assume
are matched by the ﬁle IDs 303030 and 989898.
Let the corresponding posting lists look as follows:
A (cid:55)→ {18,30,33,39,40,49,98,99}
B (cid:55)→ {10,30,31,53,98}
C (cid:55)→ {25,30,33,52,83,98}
If no grouping is used, the intersection of those posting lists
yields the optimal result, i.e., {303030,989898}.
If we use the simple grouping mechanism with the ﬁxed
modulus gn as described in Section 3.6, the posting lists look
as follows:
A (cid:55)→ {18 mod 8,303030 mod 8, . . .} = {0,1,222,3,666,7}
B (cid:55)→ {10 mod 8,303030 mod 8, . . .} = {222,5,666,7}
C (cid:55)→ {25 mod 8,303030 mod 8, . . .} = {1,222,3,4,666}
A set intersection of those posting lists yields the group IDs 2
and 6 which can be restored to the following 25 ﬁle IDs, i.e.,
all ﬁle IDs that are congruent to 2 or 6 ( mod 8):
{2,6,10,14,18,22,26,303030,34,38,42,46,50,
54,58,62,66,70,74,78,82,86,90,94,989898}
If we instead use different moduli per posting list, we get
the following groups:
A (cid:55)→ {18 mod 11,303030 mod 11, . . .} = {0,5,6,7,8,10}
B (cid:55)→ {10 mod 13,303030 mod 13, . . .} = {1,4,5,7,10}
C (cid:55)→ {25 mod 17,303030 mod 17, . . .} = {1,8,13,15,16}
To intersect the lists, we ﬁrst need to revert the grouping
process as previously described and intersect the resulting
lists of ﬁle IDs. This yields the following set of 7 candidate
ﬁles:
{18,303030,33,49,66,83,989898}
As we can see, the optimized version with different moduli
allowed us to eliminate 18 candidate ﬁles.
Incremental Index Updates
3.7
Our ﬁle index is sufﬁciently generic and does therefore not
require updates for new YARA rules. However, if new ﬁles
have to be indexed, our design allows adding further samples
to the index in a non-costly manner. Ignoring grouping for
the moment, adding a sample to the index can be trivially
done by computing its n-grams and updating the necessary
posting lists. Even with delta-encoding, updating the posting
list is cheap, because we store the last ﬁle ID of the posting
list in an absolute representation (additionally to the relative
representation). This means we do not need to reconstruct the
whole posting list before adding the new ﬁle ID.
When considering grouping, special care has to be taken
during incremental index updates. Adding new ﬁles to the
3548    30th USENIX Security Symposium
USENIX Association
index involves extending posting lists. If the size of a grouped
posting list surpasses the threshold τ after adding new ﬁles,
we would need to revert the grouping which would potentially
involve scanning billions of ﬁles in the worst case. This is
not a viable option. Instead, we can group every posting list,
and if a list surpasses the threshold, we can store ﬁle IDs
instead of group IDs. Such a posting list will then consist of
ﬁle IDs and group IDs. As we will show in Section 4.7, the
distribution of posting list sizes of a set of indexed samples
can be extrapolated to learn the distribution of posting list
sizes for the desired number of samples. This means that
a reasonable value for τ can be chosen a priori to ensure
predictable grouping behavior and to minimize the number of
posting lists surpassing the threshold τ.
4 Evaluation
We evaluate YARIX and benchmark the performance of
YARIX regarding index build time, disk footprint and search
performance.
4.1 Dataset
We build an inverted 4-gram index over N = 32M malware
samples with a total uncompressed size of 13.79 TiB. We
will discuss the choice of n = 4 in Section 4.5. The samples
stem from VirusShare.com, non-public repositories and AV
vendor feeds, and include well-known malware families for
all popular operating systems. We retrieved anti-virus labels
for 900k samples and found more than 19k Microsoft labels
and more than 21k Kaspersky labels, indicating high diversity.
The feeds are updated on a daily basis and thus represent
a real-world excerpt of the malware ecosystem. In order to
evaluate the YARA search, we use all 1404 YARA rules from
the Malpedia project [33] repository4. About 286k of the 32M
samples matched at least one of the 1404 YARA rules.
Index Build Time
4.2