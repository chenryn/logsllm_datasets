signature sets, one to determine the FPR and two for the
TPR. The test dataset used to compute FPR corresponds to a
515151
through all
1-week network trace at a university institution. We captured
all HTTP trafÔ¨Åc to the main web servers at the university,
including the institutional web servers, the registration and
payment servers, and the web interface for the mailing
servers. The network trace amounts to 4.53 GB and included
over 1.4 million HTTP GET requests. Although no ground
truth existed for this trace, we ran it
three
signature sets and manually reviewed the alerts generated.
All alerts were false positives; therefore we concluded no
malicious attack was included in the trace. Also, no incidents
were reported during this time by the network‚Äôs managers.
A second testing dataset was used to compute the TPR
of all signature sets. We generated this testing dataset by
running SQLmap [7], a popular SQL injection scanning tool,
against a vulnerable web application [43] running Apache
Tomcat and MySQL database. SQLmap was launched
against the application which contained 136 vulnerabilities,
triggering the scanning tool to generate over 7200 attack
samples. To collect this testing dataset, we set up an isolated
network which only had the test trafÔ¨Åc and thus the traces
were not contaminated with other trafÔ¨Åc.
A third testing dataset was created to further determine
the TPR of all the signature sets. Using two tools, Arachni
[1] and Vega [39], we generated another SQLi dataset of
8578 samples and used it to test the detection rate (TP)
of all the signatures sets. We will refer to the Arachni and
Vega together as the Arachni set since we do not present the
results separately for them due to space reasons and because
they provide similar insights. The use of three different
tools to generate the TPR testing sets, with their different
methods for generation of attack samples, was important to
our evaluation strategy to assess the generality of pSigene
in detecting a variety of SQLi attacks.
C. Implementation in Bro
To run our experiments, we implemented the signatures
generated by pSigene into the Bro IDS and then instructed
Bro to use only our signatures and not its own. To achieve
this, we coded a function count_all() that accepted as
input two parameters, a regular expression and a string, and
returned the number of times the regular expression was
found in the string. pSigene is invoked by Bro from its
upper policy layer, which is analogous to where Bro‚Äôs own
signatures reside.
D. Experiment 1: Accuracy and Precision
We performed the evaluation separately with seven sig-
natures (corresponding to seven biclusters, labeled 1 to 7
in Figure 2) and with nine signatures (adding biclusters 8
and 11 to previous set of seven biclusters). The set of seven
signatures obtained a higher TPR than Bro and Snort, while
also producing a very low FPR. The results from the set of
nine signatures allowed determining how much the TPR can
be improved while also measuring the increase in the FPR.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:01 UTC from IEEE Xplore.  Restrictions apply. 
ACCURACY COMPARISON BETWEEN DIFFERENT SQLI RULESETS.
Table V
RULES
ModSecurity
pSigene
(9 signatures)
pSigene
(7 signatures)
Snort - Emerging
Threats
Bro
TPR (%)
(SQLmap)
TPR (%)
(Arachni)
FPR (%)
96.07
86.53
82.72
79.55
73.23
98.72
90.52
89.48
76.59
76.33
0.0515
0.037
0.016
0.1742
0.0000
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
ROC Curves for Generalized Signatures
Signature 6
Signature 8
Signature 1
Signatures 2 and 3
Signature 7
Signature 11
Signature 5
Signature 4
e
t
a
R
e
v
i
t
i
s
o
P
e
u
r
T
We visually identiÔ¨Åed eleven biclusters from the heatmap
using a rule of 5%. That is, for any bicluster we selected
from the heatmap, it would have to include at least 5% of
all samples in the training dataset. This permitted to include
a large percentage of all the samples in the original training
set, while giving reasonably homogeneous colored areas.
From the list of eleven biclusters selected, pSigene dis-
carded those considered as black holes which are deÔ¨Åned
as biclusters composed of vectors of mostly zeroes. These
biclusters will show on the heat map in black color and
more than 99% of all the features values in corresponding
samples, are zeroes. In our experiments, biclusters 9 and 10
were black holes (shown in Figure 2) so no signatures were
generated from them.
The results are shown in Table V for all testing sets. From
the SQLmap set, our signatures had higher detection rate
(86.53% for 9 signatures and 82.72% for 7 signatures) than
Snort and Bro, but lower than ModSecurity (96.07%) and
a similar result was obtained from the Arachni set. Both
our signature sets had the lowest FPRs, only behind Bro‚Äôs
signature set (which did not raise a single false positive).
Although the other FPRs were very low, one should not be
deceived by these numbers. A FPR of 0.174%, as recorded
for Snort, represents over 2, 463 false alarms generated over
the one week trafÔ¨Åc, while ModSec‚Äôs represents over 730
false alarms. In comparison, our sets produced 523 false
alarms in the case of nine signatures and 226 in the case of
seven signatures.
ModSecurity achieved the highest TPR of all signatures
sets. We had suspected this to be a difÔ¨Åcult result to improve
upon. The ModSec set is part of a popular open source WAF
tool and has been manually developed by expert security
administrators (we had personal communication with the
lead developer of the project, conÔ¨Årming this belief that we
had already obtained through reading of public discussion
groups). The resulting set is a group of complex regular
expressions, making it difÔ¨Åcult for regular system adminis-
trators to update it when new vulnerabilities are discovered
and to adjust it to the trafÔ¨Åc of a particular network.
0
0
0.005
0.01
0.015
0.025
0.02
0.03
False Positive Rate
0.035
0.04
0.045
0.05
Figure 3.
ROC curves for each of the signatures generated for the
generalized set. The plot shows different performance for each signature,
suggesting that each one can be tuned separately which can improve the
overall detection rate of the set.
Accuracy and Precision of Individual Signatures
We wanted to drill deeper into the overall accuracy and
precision result of pSigene to see what the contribution from
each of the signatures is. For this, we plotted the ROC curves
for each of the 9 signatures for the entire test data. The
result is shown in Figure 3. To generate the ROC curve for
a given signature, we ran pSigene with only that signature
enabled and we varied the probability threshold for the
output of logistic regression. In the ROC curve, the point
(0, 1) corresponds to the ideal case and the greater is the
area under the curve, the better the performance is. Note that
in this plot, the FPR only goes till 0.05, not till 1. This is
because the maximum value of FPR for the systems under
test does not grow beyond 0.05.
The Ô¨Årst observation is that there is wide variability in
the quality of the signatures. Signature 6 performs well
while signature 4 lags. Second, signatures 1, 2, 3, and 8 are
quite insensitive to the threshold settings. Third, signature 6
will produce false positives faster than signatures 1 and 8.
From a ROC curve like this and with an idea of a desired
TPR and FPR, a security administrator can visually, and
approximately, decide which signatures to enable or disable.
Coverage of Individual Signatures
Another aspect of the clusters and the corresponding
signatures is how many samples does each cover and how
many features are used in each cluster‚Äôs signature. The
results are shown in Table VI. There is quite a large range
of cluster sizes and number of features. The largest cluster
has 44% of the samples while the smallest has 5.5%. Three
clusters use 57% of the total number of features (90 out of
159). However, an interesting, and not a priori obvious, ob-
servation is that logistic regression does signiÔ¨Åcant amount
of pruning of features for these three clusters. Thus, logistic
525252
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:01 UTC from IEEE Xplore.  Restrictions apply. 



























#

"

!



		
	
	
	
	
	
	
	
	

 !"$%&!'

("!!$%)*+









Figure 4. Cumulative TPR for set of 9 signatures produced by pSigene.
Seven signatures contributed between 7 and 19 percent of the total TPR.
Signatures 7 and 8 contributed 1.64 percent each.
regression downplays the role of some features in classifying
a sample as being malicious or benign. For example, for
cluster 3, logistic regression throws out 88% of the features,
for cluster 2 86% of the features, and for cluster 1 63%
of the features. We hypothesize that this large amount of
Ô¨Åltering by logistic regression is due to two causes. First,
the reduction of the feature set from 477 to 159 is a manual
process and there still remain overlaps between some of
them. Second,
logistic regression is focused on picking
features that help to classify while biclustering has that only
as an indirect goal. Nevertheless, biclustering is a crucial
step and needs to precede logistic regression. Biclustering
creates some order out of the chaos of the large amount of
samples and large set of features, by identifying the samples
which are similar and by identifying a superset of features
according to which they are similar.
Figure 4 shows the contributions of the individual signa-
tures (for the 9 cluster case) toward the TPR. The signatures
are arranged in descending order of their quality. The plot
shows that signatures are of differing qualities, but all
of the signatures make non-trivial contribution toward the
overall TPR‚Äîsignature 1 contributes the most at 19%, while
signature 8 contributes the least with 1.63%.
E. Experiment 2: Incremental Learning
In this experiment, we Ô¨Årst incremented the number of
attack samples while learning the Œò parameters in logistic
regression to create the signatures. We progressively added
some attack samples from the test dataset into the training
dataset - we experimented with 20% and 40% of the test
dataset being included in the training. This reÔ¨Çects the real
world scenario where fresh attack samples will be fed to
pSigene to do incremental training with these new samples.
Thus, over time, pSigene will be able to detect more and
535353
DETAILS OF SIGNATURES FOR EACH CLUSTER CREATED BY pSigene.
Table VI
BICLUSTER
NUMBER
OF
SAMPLES
NUMBER OF NUMBER OF
FEATURES
FEATURES
(BICLUSTERING)
(SIGNATURE)
1
2
3
4
5
6
7
8
11
13272
5477
2629
6947
4245
2741
3928
1676
1671
90
90
90
12
8
6
10
8
15
33
13
11
8
5
6
5
6
14
more of the attacks as it operates for longer periods and gets