1.  下载 NVIDIA vGPU 驱动程序并在您的系统中安装它们。具体步骤请查看
    [NVIDIA
    文档](https://docs.nvidia.com/grid/latest/grid-software-quick-start-guide/index.html#getting-your-nvidia-grid-software){.link}。
2.  如果 NVIDIA 软件安装程序没有创建
    [**/etc/modprobe.d/nvidia-installer-disable-nouveau.conf**]{.strong}
    文件，请在 [**/etc/modprobe.d/**]{.strong} 中创建任意名称的
    `conf`{.literal} 文件，并在文件中添加以下行：
    ``` literallayout
    blacklist nouveau
    options nouveau modeset=0
    ```
3.  为当前内核重新生成初始 ramdisk，然后重新启动。
    ``` literallayout
    # dracut --force
    # reboot
    ```
4.  检查内核是否已加载 `nvidia_vgpu_vfio`{.literal} 模块，并且
    `nvidia-vgpu-mgr.service`{.literal} 服务正在运行。
    ``` literallayout
    # lsmod | grep nvidia_vgpu_vfio
    nvidia_vgpu_vfio 45011 0
    nvidia 14333621 10 nvidia_vgpu_vfio
    mdev 20414 2 vfio_mdev,nvidia_vgpu_vfio
    vfio 32695 3 vfio_mdev,nvidia_vgpu_vfio,vfio_iommu_type1
    # systemctl status nvidia-vgpu-mgr.service
    nvidia-vgpu-mgr.service - NVIDIA vGPU Manager Daemon
       Loaded: loaded (/usr/lib/systemd/system/nvidia-vgpu-mgr.service; enabled; vendor preset: disabled)
       Active: active (running) since Fri 2018-03-16 10:17:36 CET; 5h 8min ago
     Main PID: 1553 (nvidia-vgpu-mgr)
     [...]
    ```
    另外，如果基于 NVIDIA Ampere GPU 设备创建 vGPU，请确保为物理 GPU
    启用虚拟功能。具体步骤请查看 [NVIDIA
    文档](https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#creating-sriov-vgpu-device-red-hat-el-kvm){.link}。
5.  生成设备 UUID。
    ``` literallayout
    # uuidgen
    30820a6f-b1a5-4503-91ca-0c10ba58692a
    ```
6.  根据检测到的 GPU 硬件，使用 mediated 设备配置准备 XML
    文件。例如，以下命令会在 0000:01:00.0 PCI 总线上运行的 NVIDIA Tesla
    P4 卡中配置 `nvidia-63`{.literal} vGPU
    类型的介质设备，并使用上一步中生成的 UUID。
    ``` programlisting
        pci_0000_01_00_0
            30820a6f-b1a5-4503-91ca-0c10ba58692a
    ```
7.  根据您准备的 XML 文件定义 vGPU 介质设备。例如：
    ``` literallayout
    # virsh nodedev-define vgpu-test.xml
    Node device mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0 created from vgpu-test.xml
    ```
8.  [**可选：**]{.strong}验证介质设备是否被列为 inactive。
    ``` literallayout
    # virsh nodedev-list --cap mdev --inactive
    mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    ```
9.  启动您创建的 vGPU 介质设备。
    []{#assembly_managing-gpu-devices-in-virtual-machines_configuring-and-managing-virtualization.html#starting-nvidia-vgpu-devices_assembly_managing-nvidia-vgpu-devices}
    ``` literallayout
    # virsh nodedev-start mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    Device mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0 started
    ```
10. [**可选：**]{.strong}确保介质设备被列为 active。
    ``` literallayout
    # virsh nodedev-list --cap mdev
    mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    ```
11. 将 vGPU 设备设置为在主机重启后自动启动
    ``` literallayout
    # virsh nodedev-autostart mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    Device mdev_d196754e_d8ed_4f43_bf22_684ed698b08b_0000_9b_00_0 marked as autostarted
    ```
12. 将 mediated 设备附加到要共享 vGPU
    资源的虚拟机。要做到这一点，请将以下行以及之前生成的 UUID
    添加到虚拟机 XML 配置的 [**\**]{.strong} 部分。
    []{#assembly_managing-gpu-devices-in-virtual-machines_configuring-and-managing-virtualization.html#attaching-nvidia-vgpu-devices_assembly_managing-nvidia-vgpu-devices}
    ``` programlisting
    ```
    请注意，每个 UUID 每次只能分配给一个虚拟机。另外，如果虚拟机没有
    QEMU 视频设备，如 `virtio-vga`{.literal}，在 ``{.literal}
    行中添加 `ramfb='on'`{.literal} 参数。
13. 有关在分配的虚拟机上可用的 vGPU 介质设备的完整功能，请在虚拟机上设置
    NVIDIA vGPU 客户端软件许可。有关详情和说明，请参阅 [NVIDIA Virtual
    GPU Software License Server User
    Guide](https://docs.nvidia.com/grid/ls/latest/grid-license-server-user-guide/index.html#installing-nvidia-grid-license-server){.link}。
:::
::: orderedlist
**验证**
1.  查询您创建的 vGPU 的功能，并确保它列为 active 和 persistent。
    ``` literallayout
    # virsh nodedev-info mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    Name:           virsh nodedev-autostart mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    Parent:         pci_0000_01_00_0
    Active:         yes
    Persistent:     yes
    Autostart:      yes
    ```
2.  启动虚拟机并验证客户端操作系统是否检测到 mediated device 作为 NVIDIA
    GPU。例如，如果虚拟机使用 Linux：
    ``` literallayout
    # lspci -d 10de: -k
    07:00.0 VGA compatible controller: NVIDIA Corporation GV100GL [Tesla V100 SXM2 32GB] (rev a1)
            Subsystem: NVIDIA Corporation Device 12ce
            Kernel driver in use: nvidia
            Kernel modules: nouveau, nvidia_drm, nvidia
    ```
:::
::: itemizedlist
**已知问题**
-   将 NVIDIA vGPU 介质设备分配给使用 RHEL 9
    客户机操作系统的虚拟机当前禁用该虚拟机上的 Wayland 会话，并改为载入
    Xorg 会话。这是因为 NVIDIA 驱动程序和 Wayland 之间的不兼容。
:::
::: itemizedlist
**其它资源**
-   [NVIDIA vGPU
    软件文档](https://docs.nvidia.com/grid/latest/grid-vgpu-release-notes-red-hat-el-kvm/index.html#validated-platforms){.link}
-   `man virsh`{.literal} 命令
:::
:::
::: section
::: titlepage
## []{#assembly_managing-gpu-devices-in-virtual-machines_configuring-and-managing-virtualization.html#proc_removing-nvidia-vgpu-devices_assembly_managing-nvidia-vgpu-devices}删除 NVIDIA vGPU 设备 {.title}
:::
要更改[分配的 vGPU
介质设备](#assembly_managing-gpu-devices-in-virtual-machines_configuring-and-managing-virtualization.html#proc_setting-up-nvidia-vgpu-devices_assembly_managing-nvidia-vgpu-devices "设置 NVIDIA vGPU 设备"){.link}
的配置，您需要从分配的虚拟机中删除现有设备。具体步骤请查看以下操作：
::: itemizedlist
**先决条件**
-   要从中删除该设备的虚拟机关闭。
:::
::: orderedlist
**流程**
1.  获取您要删除的介质设备的 ID。
    ``` literallayout
    # virsh nodedev-list --cap mdev
    mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    ```
2.  停止 vGPU mediated 设备的运行实例。
    ``` literallayout
    # virsh nodedev-destroy mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    Destroyed node device 'mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0'
    ```
3.  [**可选：**]{.strong}确定已取消激活介质设备。
    ``` literallayout
    # virsh nodedev-info mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    Name:           virsh nodedev-autostart mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    Parent:         pci_0000_01_00_0
    Active:         no
    Persistent:     yes
    Autostart:      yes
    ```
4.  从虚拟机 XML 配置中删除该设备。要做到这一点，使用
    `virsh edit`{.literal} 实用程序编辑虚拟机的 XML 配置，并删除 mdev
    的配置片段。这个片段类似如下：
    ``` programlisting
    ```
    请注意，停止和分离 mediated 设备不会删除它，而是将其保留为
    [**defined**]{.strong}。因此，您可以[重启](#assembly_managing-gpu-devices-in-virtual-machines_configuring-and-managing-virtualization.html#starting-nvidia-vgpu-devices_assembly_managing-nvidia-vgpu-devices){.link}并把设备[附加](#assembly_managing-gpu-devices-in-virtual-machines_configuring-and-managing-virtualization.html#attaching-nvidia-vgpu-devices_assembly_managing-nvidia-vgpu-devices){.link}到不同的虚拟机。
5.  [**可选：**]{.strong}要删除已停止的介质设备，请删除其定义。
    ``` literallayout
    # virsh nodedev-undefine mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    Undefined node device 'mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0'
    ```
:::
::: itemizedlist
**验证**
-   如果您只停止和分离该设备，请确保介质设备被列为 inactive。
    ``` literallayout
    # virsh nodedev-list --cap mdev --inactive
    mdev_30820a6f_b1a5_4503_91ca_0c10ba58692a_0000_01_00_0
    ```
-   如果您也删除了该设备，请确保以下命令不会显示它。
    ``` literallayout
    # virsh nodedev-list --cap mdev
    ```
:::
::: itemizedlist
**其它资源**
-   `man virsh`{.literal} 命令
:::
:::
::: section
::: titlepage
## []{#assembly_managing-gpu-devices-in-virtual-machines_configuring-and-managing-virtualization.html#proc_obtaining-nvidia-vgpu-information-about-your-system_assembly_managing-nvidia-vgpu-devices}获取有关您系统的 NVIDIA vGPU 信息 {.title}
:::
要评估可用的 vGPU
功能的功能，您可以获取有关系统中介质设备的附加信息，例如：
::: itemizedlist
-   可创建给定类型的 mediated 设备
-   您的系统中已经配置了哪些介质设备。
:::
::: itemizedlist
**流程**
-   要查看您主机上可以支持 vGPU 介质设备的可用 GPU 设备，请使用
    `virsh nodedev-list --cap mdev_types`{.literal}
    命令。例如，下面显示了有两个 NVIDIA Quadro RTX6000 设备的系统。
    ``` literallayout
    # virsh nodedev-list --cap mdev_types
    pci_0000_5b_00_0
    pci_0000_9b_00_0
    ```
-   要显示特定 GPU 设备支持的 vGPU 类型以及其他元数据，请使用
    `virsh nodedev-dumpxml`{.literal} 命令。
    ``` literallayout
    # virsh nodedev-dumpxml pci_0000_9b_00_0
      pci_0000_9b_00_0
      /sys/devices/pci0000:9a/0000:9a:00.0/0000:9b:00.0
      pci_0000_9a_00_0
        nvidia
        0x030000
        0
        155
        0
        0
        TU102GL [Quadro RTX 6000/8000]
        NVIDIA Corporation
            GRID RTX6000-12C
            vfio-pci
            2
            GRID RTX6000-3A
            vfio-pci
            8
          [...]
            GRID RTX6000-4A
            vfio-pci
            6
            GRID RTX6000-8Q
            vfio-pci
            3