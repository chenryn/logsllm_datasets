title:Characterizing Unstructured Overlay Topologies in Modern P2P File-Sharing
Systems
author:Daniel Stutzbach and
Reza Rejaie and
Subhabrata Sen
Characterizing Unstructured Overlay Topologies
in Modern P2P File-Sharing Systems
Daniel Stutzbach, Reza Rejaie
University of Oregon
{agthorr,reza}@cs.uoregon.edu
Subhabrata Sen
AT&T Labs—Research
PI:EMAIL
Abstract
During recent years, peer-to-peer (P2P) ﬁle-sharing sys-
tems have evolved in many ways to accommodate growing
numbers of participating peers. In particular, new features
have changed the properties of the unstructured overlay
topology formed by these peers. Despite their importance,
little is known about the characteristics of these topologies
and their dynamics in modern ﬁle-sharing applications.
This paper presents a detailed characterization of P2P
overlay topologies and their dynamics, focusing on the
modern Gnutella network. Using our fast and accurate P2P
crawler, we capture a complete snapshot of the Gnutella
network with more than one million peers in just a few
minutes. Leveraging more than 18,000 recent overlay snap-
shots, we characterize the graph-related properties of indi-
vidual overlay snapshots and overlay dynamics across hun-
dreds of back-to-back snapshots. We show how inaccuracy
in snapshots can lead to erroneous conclusions—such as a
power-law degree distribution. Our results reveal that while
the Gnutella network has dramatically grown and changed
in many ways, it still exhibits the clustering and short path
lengths of a small world network. Furthermore, its overlay
topology is highly resilient to random peer departure and
even systematic attacks. More interestingly, overlay dy-
namics lead to an “onion-like” biased connectivity among
peers where each peer is more likely connected to peers
with higher uptime. Therefore, long-lived peers form a sta-
ble core that ensures reachability among peers despite over-
lay dynamics.
1 Introduction
The Internet has witnessed a rapid growth in the popular-
ity of various Peer-to-Peer (P2P) applications during recent
years. In particular, today’s P2P ﬁle-sharing applications
(e.g., FastTrack, eDonkey, Gnutella) are extremely popu-
lar with millions of simultaneous clients and contribute a
signiﬁcant portion of the total Internet trafﬁc [1, 13, 14].
These applications have changed in many ways to accom-
modate growing numbers of participating peers. In these
applications, participating peers form an overlay which
provides connectivity among the peers to search for de-
sired ﬁles. Typically, these overlays are unstructured where
peers select neighbors through a predominantly random
process, contrasting with structured overlays,
i.e., dis-
tributed hash tables such as Chord [29] and CAN [22].
Most modern ﬁle-sharing networks use a two-tier topol-
ogy where a subset of peers, called ultrapeers, form an
unstructured mesh while other participating peers, called
leaf peers, are connected to the top-level overlay through
one or multiple ultrapeers. More importantly, the overlay
topology is continuously reshaped by both user-driven dy-
namics of peer participation as well as protocol-driven dy-
namics of neighbor selection. In a nutshell, as participating
peers join and leave, they collectively, in a decentralized
fashion, form an unstructured and dynamically changing
overlay topology.
The design and simulation-based evaluation of new
search and replication techniques has received much at-
tention in recent years. These studies often make certain
assumptions about topological characteristics of P2P net-
works (e.g., power-law degree distribution) and usually ig-
nore the dynamic aspects of overlay topologies. However,
little is known about the topological characteristics of pop-
ular P2P ﬁle sharing applications, particularly about over-
lay dynamics. An important factor to note is that properties
of unstructured overlay topologies cannot be easily derived
from the neighbor selection mechanisms due to implemen-
tation heterogeneity and dynamic peer participation. With-
out a solid understanding of topological characteristics in
ﬁle-sharing applications, the actual performance of the pro-
posed search and replication techniques in practice is un-
known, and cannot be meaningfully simulated.
Accurately characterizing the overlay topology of a large
scale P2P network is challenging [33]. A common ap-
proach is to examine properties of snapshots of the overlay
captured by a topology crawler. However, capturing ac-
USENIX Association
Internet Measurement Conference 2005  
49
curate snapshots is inherently difﬁcult for two reasons: (i)
the dynamic nature of overlay topologies, and (ii) a non-
negligible fraction of discovered peers in each snapshot are
not directly reachable by the crawler. Furthermore, the ac-
curacy of captured snapshots is difﬁcult to verify due to the
lack of any accurate reference snapshot.
Previous studies that captured P2P overlay topologies
with a crawler either deployed slow crawlers, which in-
evitably lead to signiﬁcantly distorted snapshots of the
overlay [23], or partially crawled the overlay [24, 18] which
is likely to capture biased (and non-representative) snap-
shots. These studies have not examined the accuracy of
their captured snapshots and only conducted limited anal-
ysis of the overlay topology. More importantly, these few
studies (except [18]) are outdated (more than three years
old) since P2P ﬁlesharing applications have signiﬁcantly
increased in size and incorporated several new topologi-
cal features over the past few years. An interesting recent
study [18] presented a high level characterization of the
two-tier Kazaa overlay topology. However, the study does
not contain detailed graph-related properties of the overlay.
Finally, to our knowledge, the dynamics of unstructured
P2P overlay topologies have not been studied in detail in
any prior work.
We have recently developed a set of measurement tech-
niques and incorporated them into a parallel P2P crawler,
called Cruiser [30]. Cruiser can accurately capture a com-
plete snapshot of the Gnutella network with more than one
million peers in just a few minutes. Its speed is several or-
ders of magnitude faster than any previously reported P2P
crawler and thus its captured snapshots are signiﬁcantly
more accurate. Capturing snapshots rapidly also allows us
to examine the dynamics of the overlay over a much shorter
time scale, which was not feasible in previous studies. This
paper presents detailed characterizations of both graph-
related properties as well as the dynamics of unstructured
overlay topologies based on recent large-scale and accu-
rate measurements of the Gnutella network.
1.1 Contributions
Using Cruiser, we have captured more than 18,000 snap-
shots of the Gnutella network during the past year. We
use these snapshots to characterize the Gnutella topology
at two levels:
• Graph-related Properties of Individual Snapshots: We
treat individual snapshots of the overlay as graphs and
apply different forms of graph analysis to examine
their properties1.
• Dynamics of the Overlay: We present new method-
ologies to examine the dynamics of the overlay and its
evolution over different timescales.
s
r
e
s
U
e
v
i
t
c
A
s
u
o
e
n
a
t
l
u
m
S
i
1.4e + 06
1.2e + 06
1e + 06
800000
600000
400000
200000
0
AprMayJun Jul AugSep OctNovDec Jan FebMar
Time
Figure 1: Change in network size over months. Vertical
bars show variation within a single day.
We investigate the underlying causes of the observed
properties and dynamics of the overlay topology. To the
extent possible, we conduct our analysis in a generic (i.e.,
Gnutella-independent) fashion to ensure applicability to
other P2P systems. Our main ﬁndings can be summarized
as follows:
• In contrast to earlier studies [7, 23, 20], we ﬁnd that
node degree does not exhibit a power-law distribution.
We show how power-law degree distributions can re-
sult from measurement artifacts.
• While the Gnutella network has dramatically grown
and changed in many ways, it still exhibits the clus-
tering and the short path lengths of a small world net-
work. Furthermore, its overlay topology is highly re-
silient to random peer departure and even systematic
removal of high-degree peers.
• Long-lived ultrapeers form a stable and densely con-
nected core overlay, providing stable and efﬁcient
connectivity among participating peers despite the
high degree of dynamics in peer participation.
• The longer a peer remains in the overlay, the more
it becomes clustered with other long-lived peers with
similar uptime2. In other words, connectivity within
the core overlay exhibits an “onion-like” bias where
most long-lived peers form a well-connected core, and
a group of peers with shorter uptime form a layer with
a relatively biased connectivity to each other and to
peers with higher uptime (i.e., internal layers).
1.2 Why Examine Gnutella?
eDonkey, FastTrack, and Gnutella are the three most
popular P2P ﬁle-sharing applications today, according to
Slyck.com [1], a website which tracks the number of users
for different P2P applications. We elected to ﬁrst focus on
the Gnutella network due to a number of considerations.
First, a variety of evidence indicates that the Gnutella
network has a large and growing population of active users
50
Internet Measurement Conference 2005
USENIX Association
and generates considerable trafﬁc volume. Figure 1 depicts
the average size of the Gnutella network over an eleven
month period ending February 2005, indicating that net-
work size has more than tripled (from 350K to 1.3 million
peers) during our measurement period. We also observed
time-of-day effects in the size of captured snapshots, which
is a good indication of active user participations in the Gnu-
tella network. Also, examination of Internet2 measurement
logs3 reveal that the estimated Gnutella trafﬁc measured on
that network is considerable and growing. For example,
for the 6 week period 10/11/04 − 11/21/04, the Gnutella
trafﬁc on Internet2 was estimated to be 79.69 terabytes,
up from 21.52 terabytes for a 6 week period (02/02/04 −
03/14/04) earlier that year.
Second, Gnutella, which was the ﬁrst decentralized P2P
system, has evolved signiﬁcantly since its inception in
2000. While it is among the most studied P2P networks
in the literature, prior studies are at least 2–3 years old, and
mostly considered the earlier ﬂat-network incarnation. A
detailed measurement study of the modern two-tier Gnu-
tella network is therefore timely and allows us to compare
and contrast the behavior today from the earlier measure-
ment studies, and to gain insights into the behavior and im-
pact of the two-tier, unstructured overlay topologies which
have been adopted by most modern P2P systems.
Third, our choice was also inﬂuenced by the fact that
Gnutella is the most popular P2P ﬁle-sharing network with
an open and well-documented protocol speciﬁcation. This
eliminates (or at least signiﬁcantly reduces) any incompati-
bility error in our measurement that could potentially oc-
cur in other proprietary P2P applications that have been
reverse-engineered, such as FastTrack/Kazaa and eDonkey.
The rest of this paper is organized as follows: Section 2
provides a description of the modern Gnutella P2P over-
lay network and describes the fundamental challenges in
capturing accurate snapshots. We present a brief overview
of our crawler in Section 3. Section 4 presents a detailed
characterization of graph-related properties of individual
snapshots as well as the implications of our ﬁndings. In
Section 5, we examine overlay dynamics, their underlying
causes, and their implications on design and evaluation of
P2P applications. Section 6 presents an overview of related
work and Section 7 concludes the paper.
2 Background
To accurately characterize P2P overlay topologies, we need
to capture complete and accurate snapshots. By “snap-
shot”, we refer to a graph that presents all participating
peers (as nodes) and the connections between them (as
edges) at a single instance in time. The most reliable,
and thus common, approach to capture a snapshot is to
crawl the overlay. Given information about a handful of
initial peers, the crawler progressively contacts participat-
ing peers and collects information about their neighbors.
In practice, capturing accurate snapshots is challenging for
two reasons:
(i) The Dynamic Nature of Overlays: Crawlers are not
instantaneous and require time to capture a complete snap-
shot. Because of the dynamic nature of peer participa-
tion and neighbor selection, the longer a crawl takes, the
more changes occur in participating peers and their con-
nections, and the more distorted the captured snapshot be-
comes. More speciﬁcally, any connection that is estab-
lished or closed during a crawl (i.e., changing connections)
is likely to be reported only by one end of the connection.
We note that there is no reliable way to accurately resolve
the status of changing peers or changing connections. In
a nutshell, any captured snapshot by a crawler will be dis-
torted, where the degree of distortion is a function of the
crawl duration relative to the rate of change in the overlay.
(ii) Unreachable Peers: A signiﬁcant portion of discov-
ered peers in each snapshot are not directly reachable since
they have departed, reside behind a ﬁrewall, or are over-
loaded [30]. Therefore, information about the edges of the
overlay that are connected between these unreachable peers
will be missing from the captured snapshots.
We argue that sampling a snapshot of unstructured net-
works through partial crawls [24] or passive monitor-
ing [25] is not a reliable technique for an initial character-
ization of the overlay topology for the following reasons:
(i) in the absence of adequate knowledge about the prop-
erties and dynamics of the overlay topology, it is difﬁcult
to collect unbiased samples. For example, partial crawl-
ing of the network can easily result in a snapshot that is
biased towards peers with higher degree; (ii) some graph-
level characteristics of the overlay topology, such as the
mean shortest path between peers (which we discuss in
Subsection 4.2) cannot be accurately derived from partial
snapshots. Because of these reasons, we attempt to cap-
ture snapshots as complete as possible and use them for
our characterizations.
To describe our measurement methodology for address-
ing the above challenges, we provide a brief description
of modern Gnutella as an example of a two-tier P2P ﬁle-
sharing application.
2.1 Modern Gnutella
In the original Gnutella protocol, participating peers form
a ﬂat unstructured overlay and use TTL-scoped ﬂooding of
search queries to other peers. This approach has limited
scalability. To improve the scalability of the Gnutella pro-
tocol, most modern Gnutella clients adopt a new overlay
structure along with a new query distribution mechanism
as follows:
(i) Two-tier Overlay: A new generation of popular ﬁle-
sharing applications have adopted a two-tier overlay archi-
USENIX Association
Internet Measurement Conference 2005  
51
of
T o p olo g y
T o p-le v el o v e rla y
n u tella
G
t h e
Legacy Peer
Ultra Peer
Leaf Peer
Figure 2: Two-tier Topology of Modern Gnutella
tecture to improve their scalability: a subset of peers, called
ultrapeers, form a top-level overlay while other participat-
ing peers, called leaf peers, are connected to the top-level
overlay through one or multiple ultrapeers (Figure 2). Fast-
Track (or Kazaa), Gnutella, and eDonkey all use some vari-
ation of this model. Those peers that do not implement the
ultrapeer feature, called legacy peers, can only reside in the
top-level overlay and do not accept any leaves. When a
leaf connects to an ultrapeer, it uploads a set of hashes of
its ﬁlename keywords to that ultrapeer. This allows the ul-
trapeer to only forward messages to the leaves who might
have matching ﬁles. This approach reduces the number of
forwarded messages towards leaf peers which in turn in-
creases the scalability of the network by a constant factor.
Leaf peers never forward messages.
(ii) Dynamic Query: The Gnutella developer community
has adopted a new scheme for query distribution called Dy-
namic Querying [9]. The goal in this scheme is to only
gather enough results to satisfy the user (typically 50 to 200
results). Rather than forwarding a query to all neighbors,
ultrapeers manage the queries for their leaves. Toward this
end, an ultrapeer begins by forwarding a query to a subset
of top-level connections using a low TTL. From that point
on, the query is ﬂooded outward until the TTL expires. The
ultrapeer then waits for the results, and uses the ratio be-
tween the number of results and the estimated number of
visited peers to determine how rare matches are. If matches
are rare (i.e., there are few or no responses), the query is
sent through more connections with a relatively high TTL.
If matches are more common but not sufﬁcient, the query
is sent down a few more connections with a low TTL. This
process is repeated until the desired number of results are
collected or the ultrapeer gives up. Each ultrapeer estimates
the number of visited ultrapeers through each neighbor
(d − 1)i. This
based on the following formula: P
formula assumes that all peers have the same node degree,
d. When Dynamic Querying was introduced, the number
of neighbors each ultrapeer attempts to maintain was in-
creased to allow more ﬁne-grained control with Dynamic
Querying by giving ultrapeers more neighbors to choose
from.
TTL−1
i=0
3 Capturing Accurate Snapshots
In this section, we present an overview of our data collec-
tion and post-processing steps.
Cruiser: We have developed a set of measurement tech-
niques into a parallel Gnutella crawler, called Cruiser [30].
While the basic crawling strategy by Cruiser is similar to
other crawlers, it improves the accuracy of captured snap-
shots by signiﬁcantly increasing the crawling speed (i.e.,
reducing crawl duration) primarily by using the following
techniques: First, Cruiser employs a master-slave architec-
ture in order to achieve a high degree of concurrency and
to effectively utilize available resources on multiple PCs.
Using a master-slave architecture also allows us to deploy
Cruiser in a distributed fashion if Cruiser’s access link be-
comes a bottleneck. The master process coordinates mul-
tiple slave processes that crawl disjoint portions of the net-
work in parallel. Each slave crawler opens hundreds of par-
allel connections, contributing a speed-up of nearly three
orders of magnitude.
Second, Cruiser leverages the two-tier structure of the
modern Gnutella network by only crawling the top-level
peers (i.e., ultrapeers and legacy peers). Since each leaf
must be connected to an ultrapeer, this approach enables
us to capture all the nodes and links of the overlay by con-
tacting a relatively small fraction of all peers. Overall, this
strategy leads to around an 85% reduction in the duration
of a crawl without any loss of information.
These techniques collectively result in a signiﬁcant in-
crease in crawling speed. Cruiser can capture the Gnu-
tella network with one million peers in around 7 minutes
using six off-the-shelf 1 GHz GNU/Linux boxes in our lab.
Cruiser’s crawling speed is about 140K peers/minute (by
directly contacting 22K peers/minute), This is orders of
magnitude faster than previously reported crawlers (i.e., 2
hours for 30K peers (250/minute) in [23], and 2 minutes for
5K peer (2.5K/minute) in [24]). It is worth clarifying that
while our crawling strategy is aggressive and our crawler
requires considerable local resources, its behavior is not in-
trusive since each top-level peer is contacted only once per
crawl.
Post-Processing: Once information is collected from all
reachable peers, we perform some post-processing to re-
move any obvious inconsistencies that might have been in-
troduced due to changes in the topology during the crawl-
ing period. Speciﬁcally, we include edges even if they are
only reported by one peer, and treat a peer as an ultrapeer if
it neighbors with another ultrapeer or has any leaves. Due
to the inconsistencies, we might over-count edges by about
1% and ultrapeers by about 0.5%.
Unreachable Peers: We have carefully examined the ef-
fect of unreachable peers on the accuracy of captured snap-
shots [33]. Previous studies assumed that these unreachable
peers departed the network or are legacy peers that reside
behind a ﬁrewall (or NAT), and simply excluded this large
group of unreachable peers from their snapshot. It is impor-
tant to determine what portion of unreachable peers are de-
parted or NATed because each group introduces a different
52
Internet Measurement Conference 2005
USENIX Association
Crawl Date Total Nodes
09/27/04
10/11/04
10/18/04
02/02/05
725,120
779,535
806,948
1,031,471
Leaves
614,912
662,568
686,719
873,130
Top-level Unreachable Top-Level Edges
110,208
116,967
120,229
158,345
1,212,772
1,244,219
1,331,745
1,964,121
35,796
41,192
36,035
39,283
Table 1: Sample Crawl Statistics
error on the snapshot. However, there is no reliable test to
distinguish between departed and ﬁrewalled peers because
ﬁrewalls can time out or refuse connections depending on
their conﬁguration.
In summary, our investigation revealed that in each