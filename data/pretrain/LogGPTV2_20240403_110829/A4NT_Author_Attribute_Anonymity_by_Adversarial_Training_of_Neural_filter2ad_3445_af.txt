score of the A4NT output against the difﬁculty of the in-
put text. We see that the meteor is high for sentences
already across the decision boundary. These are easy
cases, where the A4NT networks need not intervene. As
the input gets more difﬁcult, the meteor score of the
A4NT output drops, as the network needs to do more
changes to be able to fool the attribute classiﬁer. The
CycML+Lang model fares better than the other two mod-
els, with consistently higher meteor across the difﬁculty
spectrum.
Figure 10 shows the histogram of privacy gain across
the test set. Privacy gain is the difference between the at-
tribute classiﬁer score on the input and the A4NT network
output. We see that majority of transformations by the
A4NT networks leads to positive privacy gains, with only
a small fraction leading to negative privacy gains. This is
promising given that this histogram is over all the 500k
sentences in the test set. Meteor score plotted against
privacy gain shown in Figure 10, again conﬁrms that large
privacy gains comes with a trade-off of loss in semantics.
7 Conclusions
We presented a novel fully automatic method for pro-
tecting privacy sensitive attributes of an author against
NLP based attackers. Our solution consists of the
A4NT network which learns to protect private attributes
with novel adversarial training of a machine translation
USENIX Association
27th USENIX Security Symposium    1647
0.00.20.40.60.81.0Author classifier score on Input sentences0.00.20.40.60.81.0Author classifier score on Style              Transfer outputAuthor classifier score on Input vs style transfer sentenceFBsemCycMLCycML+Langinputideal score0.00.20.40.60.81.0Author classifier score of input sentence0.00.20.40.60.81.0Meteor score of style transfer outputMeteor score of style transfer output vs Difficulty of input textFBsemCycMLCycML+Langdecision boundary1.00.50.00.51.0Privacy gain upon style translation100101102103104105106HistogramHistogram of privacy gain in logscale1.00.50.00.51.0Privacy gain upon style translation0.10.20.30.40.50.60.70.80.91.0Meteor score of translationMeteor score Vs Privacy GainFBsemCycMLCycML+Lang[7] P. Juola.
(2013) How a computer program helped show
J.K. rowling write a cuckoos calling. [Online]. Available:
https://goo.gl/mkZai1
[8] A. A. Morgan-Lopez, A. E. Kim, R. F. Chew, and P. Ruddle,
“Predicting age groups of twitter users based on language and
metadata features,” PloS one, 2017.
[9] K. Ikeda, G. Hattori, C. Ono, H. Asoh, and T. Higashino, “Twitter
user proﬁling based on text and community mining for market
analysis,” Know.-Based Syst., 2013.
[10] A. Makazhanov, D. Raﬁei, and M. Waqar, “Predicting political
preference of twitter users,” Social Network Analysis and Mining,
2014.
[11] H. Grassegger and M. Krogerus. (2017) The data that turned the
world upside down. [Online]. Available: https://motherboard.vice.
com/en us/article/mg9vvn/how-our-likes-helped-trump-win
[12] M. Brennan, S. Afroz, and R. Greenstadt, “Adversarial stylom-
etry: Circumventing authorship recognition to preserve privacy
and anonymity,” ACM Transactions on Information and System
Security (TISSEC), 2012.
[13] S. Afroz, M. Brennan, and R. Greenstadt, “Detecting hoaxes,
frauds, and deception in writing style online,” in Security and
Privacy (SP), 2012 IEEE Symposium on.
IEEE, 2012.
[14] A. W. McDonald, S. Afroz, A. Caliskan, A. Stolerman, and
R. Greenstadt, “Use fewer instances of the letter” i”: Toward
writing style anonymization.” in Privacy Enhancing Technologies.
Springer, 2012.
[15] D. Castro, R. Ortega, and R. Mu˜noz, “Author Masking by Sentence
Transformation—Notebook for PAN at CLEF 2017,” in CLEF
2017 Evaluation Labs and Workshop – Working Notes Papers, Sep.
2017.
[16] Y. Keswani, H. Trivedi, P. Mehta, and P. Majumder, “Author
masking through translation.” in CLEF (Working Notes), 2016.
[17] A. Caliskan and R. Greenstadt, “Translate once, translate twice,
translate thrice and attribute: Identifying authors and machine
translation tools in translated text,” in 2012 IEEE Sixth Interna-
tional Conference on Semantic Computing, Sept 2012.
[18] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-
Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative ad-
versarial nets,” in Advances in Neural Information Processing
Systems (NIPS), 2014.
[19] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence
learning with neural networks,” in Advances in neural information
processing systems, 2014.
[20] W. Xu, A. Ritter, B. Dolan, R. Grishman, and C. Cherry, “Para-
phrasing for style,” Proceedings of COLING 2012, 2012.
[21] S. Afroz, A. C. Islam, A. Stolerman, R. Greenstadt, and D. McCoy,
“Doppelg¨anger ﬁnder: Taking stylometry to the underground,” in
Security and Privacy (SP), 2014 IEEE Symposium on.
IEEE,
2014.
[22] A. Caliskan-Islam, R. Harang, A. Liu, A. Narayanan, C. Voss,
F. Yamaguchi, and R. Greenstadt, “De-anonymizing programmers
via code stylometry,” in USENIX Security Symposium, 2015.
[23] A. Abbasi and H. Chen, “Writeprints: A stylometric approach to
identity-level identiﬁcation and similarity detection in cyberspace,”
ACM Transactions on Information Systems (TOIS), 2008.
[24] D. Bagnall, “Author identiﬁcation using multi-headed recurrent
neural networks,” arXiv preprint arXiv:1506.04891, 2015.
[25] G. Kacmarcik and M. Gamon, “Obfuscating document stylom-
etry to preserve author anonymity,” in Proceedings of the COL-
ING/ACL on Main conference poster sessions. Association for
Computational Linguistics, 2006.
[26] G. Karadzhov, T. Mihaylova, Y. Kiprov, G. Georgiev, I. Koychev,
and P. Nakov, “The case for being average: A mediocrity approach
to style masking and author obfuscation,” in International Con-
ference of the Cross-Language Evaluation Forum for European
Languages. Springer, 2017.
[27] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation
by jointly learning to align and translate,” Proceedings of the
International Conference on Learning Representations (ICLR),
2014.
[28] Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey,
M. Krikun, Y. Cao, Q. Gao, K. Macherey et al., “Google’s neural
machine translation system: Bridging the gap between human and
machine translation,” arXiv preprint arXiv:1609.08144, 2016.
[29] T. Shen, T. Lei, R. Barzilay, and T. Jaakkola, “Style transfer from
non-parallel text by cross-alignment,” To appear in NIPS, 2017.
[30] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Good-
fellow, and R. Fergus, “Intriguing properties of neural networks,”
in Proceedings of the International Conference on Learning Rep-
resentations (ICLR), 2014.
[31] I. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and har-
nessing adversarial examples,” in Proceedings of the International
Conference on Learning Representations (ICLR), 2015.
[32] N. Carlini and D. Wagner, “Towards evaluating the robustness
of neural networks,” in Security and Privacy (SP), 2017 IEEE
Symposium on.
IEEE, 2017.
[33] S. J. Oh, M. Fritz, and B. Schiele, “Adversarial image perturbation
for privacy protection–a game theory perspective,” in International
Conference on Computer Vision (ICCV), 2017.
[34] S. Samanta and S. Mehta, “Towards crafting text adversarial sam-
ples,” arXiv preprint arXiv:1707.02812, 2017.
[35] B. Liang, H. Li, M. Su, P. Bian, X. Li, and W. Shi, “Deep text
classiﬁcation can be fooled,” arXiv preprint arXiv:1704.08006,
2017.
[36] R. Jia and P. Liang, “Adversarial examples for evaluating reading
comprehension systems,” in Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Processing, 2017.
[37] J. Schler, M. Koppel, S. Argamon, and J. W. Pennebaker, “Ef-
fects of age and gender on blogging.” in AAAI spring symposium:
Computational approaches to analyzing weblogs, 2006.
[38] A. A. Morgan-Lopez, A. E. Kim, R. F. Chew, and P. Ruddle,
“Predicting age groups of twitter users based on language and
metadata features,” PLOS ONE, 08 2017.
[39] S. Hochreiter and J. Schmidhuber, “Long short-term memory,”
Neural computation, 1997.
[40] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their compo-
sitionality,” in Advances in Neural Information Processing Systems
(NIPS), 2013.
[41] J. Pennington, R. Socher, and C. Manning, “Glove: Global vectors
for word representation,” in Proceedings of the 2014 conference
on empirical methods in natural language processing (EMNLP),
2014.
[42] R. J. Weiss, J. Chorowski, N. Jaitly, Y. Wu, and Z. Chen,
“Sequence-to-sequence models can directly transcribe foreign
speech,” arXiv preprint arXiv:1703.08581, 2017.
[43] X. Ma and E. Hovy, “End-to-end sequence labeling via bi-
directional LSTM-CNNs-CRF,” in Proceedings of the Annual
Meeting of the Association for Computational Linguistics (ACL),
2016.
[44] R. Shetty, M. Rohrbach, L. A. Hendricks, M. Fritz, and B. Schiele,
“Speaking the same language: Matching machine to human cap-
tions by adversarial training,” in Proceedings of the IEEE Interna-
tional Conference on Computer Vision (ICCV), 2017.
1648    27th USENIX Security Symposium
USENIX Association
[45] E. Jang, S. Gu, and B. Poole, “Categorical reparameterization with
gumbel-softmax,” Proceedings of the International Conference on
Learning Representations (ICLR), 2016.
[46] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, “Unpaired image-
to-image translation using cycle-consistent adversarial networks,”
Proceedings of the IEEE International Conference on Computer
Vision (ICCV), 2017.
[47] A. Conneau, D. Kiela, H. Schwenk, L. Barrault, and A. Bordes,
“Supervised learning of universal sentence representations from
natural language inference data,” in Proceedings of the Conference
on Empirical Methods in Natural Language Processing (EMNLP),
2017.
[48] R. Kiros, Y. Zhu, R. R. Salakhutdinov, R. Zemel, R. Urtasun,
A. Torralba, and S. Fidler, “Skip-thought vectors,” in Advances in
neural information processing systems, 2015.
[49] S. R. Bowman, G. Angeli, C. Potts, and C. D. Manning, “A large
annotated corpus for learning natural language inference,” Pro-
ceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), 2015.
[50] Pytorch framework. [Online]. Available: http://pytorch.org/
[51] T. Tieleman and G. Hinton, “Lecture 6.5-rmsprop: Divide the gra-
dient by a running average of its recent magnitude,” COURSERA:
Neural networks for machine learning, 2012.
[52] J. T. Woolley and G. Peters. (1999) The american presidency
project. [Online]. Available: http://www.presidency.ucsb.edu
[53] J. R. Finkel, T. Grenager, and C. Manning, “Incorporating non-
local information into information extraction systems by gibbs
sampling,” in Proceedings of the Annual Meeting of the Associa-
tion for Computational Linguistics (ACL), 2005.
[54] M. Denkowski and A. Lavie, “Meteor universal: Language spe-
ciﬁc translation evaluation for any target language,” in Proceedings
of the Ninth Workshop on Statistical Machine Translation. ACL,
2014.
[55] Z. Li, X. Jiang, L. Shang, and H. Li, “Paraphrase generation with
deep reinforcement learning,” arXiv preprint arXiv:1711.00279,
2017.
[56] D. Elliott, S. Frank, L. Barrault, F. Bougares, and L. Specia, “Find-
ings of the second shared task on multimodal machine translation
and multilingual image description,” in Proceedings of the Second
Conference on Machine Translation, 2017.
[57] E. Agirre, C. Banea, D. Cer, M. Diab, A. Gonzalez-Agirre, R. Mi-
halcea, G. Rigau, and J. Wiebe, “Semeval-2016 task 1: Semantic
textual similarity, monolingual and cross-lingual evaluation,” in
Proceedings of the 10th International Workshop on Semantic Eval-
uation (SemEval-2016), 2016.
[58] C. J. Maddison, A. Mnih, and Y. W. Teh, “The concrete distri-
bution: A continuous relaxation of discrete random variables,”
Proceedings of the International Conference on Learning Repre-
sentations (ICLR), 2016.
A Differentiability of discrete samples
We obtain an output sentence sample ˜sy from the
A4NT network Zxy by sampling from the distribution
p( ˜wt sx), shown in (5), repeatedly until a special ‘END’
token is sampled. This naive sampling though is not suit-
able for training Zxy within a GAN framework as sampling
from multinomial distribution is not differentiable.
To make sampling differentiable we follow the ap-
proach used in [44] and use the Gumbel-Softmax approx-
imation [45] to obtain differentiable soft samples from
p( ˜wt sx). The gumbel-softmax approximation includes
with respect to the probabilities p( ˜wt sx). Next, softmax
two parts. First, the re-parametrization trick using the
gumbel random variable is applied to make the process of
sampling from a multinomial distribution differentiable
is used to approximate the arg-max operator to obtain
“soft” samples instead of one-hot vectors. This makes
the samples themselves differentiable. Thus, the gumbel-
softmax approximation allows differentiating through sen-
tence samples from the A4NT network enabling end-to-
end GAN training. Further details on gumbel-softmax
approximation can be found in [45, 58].
B Human evaluation
Rating Instruction
5
4
3
2
1
0
The two sentences are completely equivalent, as they mean the
same thing.
The two sentences are mostly equivalent, but some
unimportant details differ.
The two sentences are roughly equivalent, but some important
information differs/missing.
The two sentences are not equivalent, but share some details.
The two sentences are not equivalent, but are on the same topic
The two sentences are completely dissimilar
Table X: The zero to ﬁve scale and corresponding instruc-
tions used to conduct the user study of absolute semantic
similarity between the input and the output sentence.
Figure 11: Comparing distribution of ratings obtained by
our model and the GoogleMT baseline in the absolute
semantic similarity user study. Left ﬁgures shows the
distribution of the ratings, whereas the ﬁgure on the right
shows the distribution of maximum difference between
user ratings for each sentence.
Both the user studies presented in Section 6.1.2 were
conducted on Amazon Mechanical Turk platform (AMT).
The workers were based in the united states and were
required to have Mechanical Turk masters qualiﬁcation,
which is given by the AMT platform to workers producing
high quality work. The workers were also required to
have a minimum approval rating of 95% in their prior
assignments on AMT. All the workers who participated
USENIX Association
27th USENIX Security Symposium    1649
012345Ratings0200400600800100012001400Number of votesDistribution of user ratingsA4NTGoogleMT012345Maximum disagreement between ratings0100200300400Number of votesDistribution of user disagreementA4NTGoogleMTsentences identical compared to the GoogleMT baseline.
in the two user studies were compensated through the
AMT platform. The workers were paid an average of
0.02$ for each sentence evaluation task, which took a
median of twelve seconds complete. Both the studies
were conducted on the human-eval test set containing 745
test sentences and each sentence was evaluated by three
unique users. We did not collect any personal information
from the users. A total of 18 unique users participated
in the user study measuring absolute semantic similarity,
with each user rating on an average 176.25 sentences. In
the relative semantic similarity evaluations, a total of 70
unique users participated with each user evaluating on
average 55.6 pairs of sentences.
Relative evaluation: In the ﬁrst evaluation we show each
user the input sentence and the modiﬁed sentences from
different models and ask the users to pick the sentence
which best preserves the meaning of the input text. This
task was titled “Pick semantically similar sentence from
a list” on AMT and was description provided was “Pick
from the given list, the sentence closest in meaning to the
provided reference sentence”. Each time a model’s output
sentence is picked by a user, we consider it as ranked ﬁrst.
For sentences were one or more of the models produce
output sentence identical to the input, we directly award
those models rank one for these sentences. Finally, we
compare the models based on the percentage of instances
they were ranked ﬁrst as presented in Section 6.1.2. We
found good agreement between the users on this task. All
the three users rating each sentence agreed 62% of the
time in this task, compared 25% chance of agreement if
the three users were randomly voting.
Absolute evaluation: We also evaluated the semantic
similarity of the edited text to the input on an absolute
scale of zero to ﬁve. Each user is shown the input sentence
and the edited sentence and is asked to rate the semantic
similarity on zero (no similarity) to ﬁve (identical) scale.
This task was titled “Rate the similarity of two sentences
on a scale” on AMT and was description provided was
“You are presented with two sentences. Rate how similar
they are in meaning on a scale of 0 to 5” along with the
rating guide in Table X. Again, if a model produces iden-
tical output sentence to the input, we award a rating of
ﬁve automatically. The models are compared using the
average rating they obtain as presented in Section 6.1.2.
To evaluate the agreement between the three user ratings
for each sentence, we plot the distribution of ratings and
distribution of maximum difference between the three rat-
ings in Figure 11. We can see that the most of the ratings
are distributed between four and ﬁve. Also the users tend
to rate the sentences similarly, with the maximum dif-
ference between user ratings mostly distributed between
zero and one. We see that users tend to agree more on our
A4NT model compared to the GoogleMT baseline. This
is due to the fact that our model preserves many more
1650    27th USENIX Security Symposium
USENIX Association