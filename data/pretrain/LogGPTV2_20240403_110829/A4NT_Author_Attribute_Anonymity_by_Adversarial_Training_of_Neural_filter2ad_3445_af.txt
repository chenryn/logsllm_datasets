### Analysis of A4NT Output Against Input Text Difficulty

The METEOR score of the A4NT output is evaluated against the difficulty of the input text. For sentences that are already beyond the decision boundary, the METEOR score is high, indicating these are straightforward cases where the A4NT networks do not need to intervene significantly. As the input text becomes more challenging, the METEOR score of the A4NT output decreases. This is because the network must make more substantial changes to fool the attribute classifier. Among the models, CycML+Lang consistently outperforms the other two, maintaining a higher METEOR score across the spectrum of input difficulties.

### Privacy Gain Across the Test Set

Figure 10 presents the histogram of privacy gain across the test set. Privacy gain is defined as the difference between the attribute classifier score on the input and the A4NT network output. The results show that the majority of transformations by the A4NT networks lead to positive privacy gains, with only a small fraction resulting in negative privacy gains. This is encouraging, given that the histogram covers all 500,000 sentences in the test set. The plot of METEOR score against privacy gain in Figure 10 further confirms that significant privacy gains come at the cost of some loss in semantic fidelity.

### Conclusions

We introduced a novel, fully automatic method for protecting privacy-sensitive attributes of an author from NLP-based attackers. Our solution, the A4NT network, learns to protect private attributes through adversarial training of a machine translation model. The results demonstrate that our approach effectively enhances privacy while maintaining a reasonable level of semantic similarity.

### References

[7] P. Juola. (2013) How a computer program helped show J.K. Rowling wrote "A Cuckoo's Calling." [Online]. Available: https://goo.gl/mkZai1

[8] A. A. Morgan-Lopez, A. E. Kim, R. F. Chew, and P. Ruddle, “Predicting age groups of Twitter users based on language and metadata features,” PloS one, 2017.

[9] K. Ikeda, G. Hattori, C. Ono, H. Asoh, and T. Higashino, “Twitter user profiling based on text and community mining for market analysis,” Know.-Based Syst., 2013.

[10] A. Makazhanov, D. Rafiei, and M. Waqar, “Predicting political preference of Twitter users,” Social Network Analysis and Mining, 2014.

[11] H. Grassegger and M. Krogerus. (2017) The data that turned the world upside down. [Online]. Available: https://motherboard.vice.com/en_us/article/mg9vvn/how-our-likes-helped-trump-win

[12] M. Brennan, S. Afroz, and R. Greenstadt, “Adversarial stylometry: Circumventing authorship recognition to preserve privacy and anonymity,” ACM Transactions on Information and System Security (TISSEC), 2012.

[13] S. Afroz, M. Brennan, and R. Greenstadt, “Detecting hoaxes, frauds, and deception in writing style online,” in Security and Privacy (SP), 2012 IEEE Symposium on. IEEE, 2012.

[14] A. W. McDonald, S. Afroz, A. Caliskan, A. Stolerman, and R. Greenstadt, “Use fewer instances of the letter 'i': Toward writing style anonymization.” in Privacy Enhancing Technologies. Springer, 2012.

[15] D. Castro, R. Ortega, and R. Muñoz, “Author Masking by Sentence Transformation—Notebook for PAN at CLEF 2017,” in CLEF 2017 Evaluation Labs and Workshop – Working Notes Papers, Sep. 2017.

[16] Y. Keswani, H. Trivedi, P. Mehta, and P. Majumder, “Author masking through translation.” in CLEF (Working Notes), 2016.

[17] A. Caliskan and R. Greenstadt, “Translate once, translate twice, translate thrice and attribute: Identifying authors and machine translation tools in translated text,” in 2012 IEEE Sixth International Conference on Semantic Computing, Sept 2012.

[18] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in Advances in Neural Information Processing Systems (NIPS), 2014.

[19] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning with neural networks,” in Advances in neural information processing systems, 2014.

[20] W. Xu, A. Ritter, B. Dolan, R. Grishman, and C. Cherry, “Paraphrasing for style,” Proceedings of COLING 2012, 2012.

[21] S. Afroz, A. C. Islam, A. Stolerman, R. Greenstadt, and D. McCoy, “Doppelgänger Finder: Taking stylometry to the underground,” in Security and Privacy (SP), 2014 IEEE Symposium on. IEEE, 2014.

[22] A. Caliskan-Islam, R. Harang, A. Liu, A. Narayanan, C. Voss, F. Yamaguchi, and R. Greenstadt, “De-anonymizing programmers via code stylometry,” in USENIX Security Symposium, 2015.

[23] A. Abbasi and H. Chen, “Writeprints: A stylometric approach to identity-level identification and similarity detection in cyberspace,” ACM Transactions on Information Systems (TOIS), 2008.

[24] D. Bagnall, “Author identification using multi-headed recurrent neural networks,” arXiv preprint arXiv:1506.04891, 2015.

[25] G. Kacmarcik and M. Gamon, “Obfuscating document stylometry to preserve author anonymity,” in Proceedings of the COLING/ACL on Main conference poster sessions. Association for Computational Linguistics, 2006.

[26] G. Karadzhov, T. Mihaylova, Y. Kiprov, G. Georgiev, I. Koychev, and P. Nakov, “The case for being average: A mediocrity approach to style masking and author obfuscation,” in International Conference of the Cross-Language Evaluation Forum for European Languages. Springer, 2017.

[27] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation by jointly learning to align and translate,” Proceedings of the International Conference on Learning Representations (ICLR), 2014.

[28] Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey, M. Krikun, Y. Cao, Q. Gao, K. Macherey et al., “Google’s neural machine translation system: Bridging the gap between human and machine translation,” arXiv preprint arXiv:1609.08144, 2016.

[29] T. Shen, T. Lei, R. Barzilay, and T. Jaakkola, “Style transfer from non-parallel text by cross-alignment,” To appear in NIPS, 2017.

[30] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus, “Intriguing properties of neural networks,” in Proceedings of the International Conference on Learning Representations (ICLR), 2014.

[31] I. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” in Proceedings of the International Conference on Learning Representations (ICLR), 2015.

[32] N. Carlini and D. Wagner, “Towards evaluating the robustness of neural networks,” in Security and Privacy (SP), 2017 IEEE Symposium on. IEEE, 2017.

[33] S. J. Oh, M. Fritz, and B. Schiele, “Adversarial image perturbation for privacy protection–a game theory perspective,” in International Conference on Computer Vision (ICCV), 2017.

[34] S. Samanta and S. Mehta, “Towards crafting text adversarial samples,” arXiv preprint arXiv:1707.02812, 2017.

[35] B. Liang, H. Li, M. Su, P. Bian, X. Li, and W. Shi, “Deep text classification can be fooled,” arXiv preprint arXiv:1704.08006, 2017.

[36] R. Jia and P. Liang, “Adversarial examples for evaluating reading comprehension systems,” in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 2017.

[37] J. Schler, M. Koppel, S. Argamon, and J. W. Pennebaker, “Effects of age and gender on blogging.” in AAAI spring symposium: Computational approaches to analyzing weblogs, 2006.

[38] A. A. Morgan-Lopez, A. E. Kim, R. F. Chew, and P. Ruddle, “Predicting age groups of Twitter users based on language and metadata features,” PLOS ONE, 08 2017.

[39] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural computation, 1997.

[40] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, “Distributed representations of words and phrases and their compositionality,” in Advances in Neural Information Processing Systems (NIPS), 2013.

[41] J. Pennington, R. Socher, and C. Manning, “Glove: Global vectors for word representation,” in Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), 2014.

[42] R. J. Weiss, J. Chorowski, N. Jaitly, Y. Wu, and Z. Chen, “Sequence-to-sequence models can directly transcribe foreign speech,” arXiv preprint arXiv:1703.08581, 2017.

[43] X. Ma and E. Hovy, “End-to-end sequence labeling via bidirectional LSTM-CNNs-CRF,” in Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), 2016.

[44] R. Shetty, M. Rohrbach, L. A. Hendricks, M. Fritz, and B. Schiele, “Speaking the same language: Matching machine to human captions by adversarial training,” in Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2017.

[45] E. Jang, S. Gu, and B. Poole, “Categorical reparameterization with gumbel-softmax,” Proceedings of the International Conference on Learning Representations (ICLR), 2016.

[46] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, “Unpaired image-to-image translation using cycle-consistent adversarial networks,” Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2017.

[47] A. Conneau, D. Kiela, H. Schwenk, L. Barrault, and A. Bordes, “Supervised learning of universal sentence representations from natural language inference data,” in Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2017.

[48] R. Kiros, Y. Zhu, R. R. Salakhutdinov, R. Zemel, R. Urtasun, A. Torralba, and S. Fidler, “Skip-thought vectors,” in Advances in neural information processing systems, 2015.

[49] S. R. Bowman, G. Angeli, C. Potts, and C. D. Manning, “A large annotated corpus for learning natural language inference,” Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2015.

[50] Pytorch framework. [Online]. Available: http://pytorch.org/

[51] T. Tieleman and G. Hinton, “Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude,” COURSERA: Neural networks for machine learning, 2012.

[52] J. T. Woolley and G. Peters. (1999) The American Presidency Project. [Online]. Available: http://www.presidency.ucsb.edu

[53] J. R. Finkel, T. Grenager, and C. Manning, “Incorporating non-local information into information extraction systems by Gibbs sampling,” in Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), 2005.

[54] M. Denkowski and A. Lavie, “Meteor Universal: Language-specific translation evaluation for any target language,” in Proceedings of the Ninth Workshop on Statistical Machine Translation. ACL, 2014.

[55] Z. Li, X. Jiang, L. Shang, and H. Li, “Paraphrase generation with deep reinforcement learning,” arXiv preprint arXiv:1711.00279, 2017.

[56] D. Elliott, S. Frank, L. Barrault, F. Bougares, and L. Specia, “Findings of the second shared task on multimodal machine translation and multilingual image description,” in Proceedings of the Second Conference on Machine Translation, 2017.

[57] E. Agirre, C. Banea, D. Cer, M. Diab, A. Gonzalez-Agirre, R. Mihalcea, G. Rigau, and J. Wiebe, “SemEval-2016 Task 1: Semantic textual similarity, monolingual and cross-lingual evaluation,” in Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), 2016.

[58] C. J. Maddison, A. Mnih, and Y. W. Teh, “The concrete distribution: A continuous relaxation of discrete random variables,” Proceedings of the International Conference on Learning Representations (ICLR), 2016.

### Differentiability of Discrete Samples

To obtain an output sentence sample \(\tilde{s}_y\) from the A4NT network \(Z_{xy}\), we sample from the distribution \(p(\tilde{w}_{t} | s_x)\) repeatedly until a special ‘END’ token is sampled. However, this naive sampling is not suitable for training \(Z_{xy}\) within a GAN framework, as sampling from a multinomial distribution is not differentiable.

To make the sampling process differentiable, we follow the approach used in [44] and use the Gumbel-Softmax approximation [45] to obtain differentiable soft samples from \(p(\tilde{w}_{t} | s_x)\). The Gumbel-softmax approximation involves two parts:
1. **Re-parametrization Trick**: Using the Gumbel random variable to make the process of sampling from a multinomial distribution differentiable.
2. **Softmax Approximation**: Using the softmax function to approximate the arg-max operator, thereby obtaining "soft" samples instead of one-hot vectors.

This makes the samples themselves differentiable, allowing for end-to-end GAN training. Further details on the Gumbel-softmax approximation can be found in [45, 58].

### Human Evaluation

#### Rating Instruction

| Rating | Description |
|--------|-------------|
| 5      | The two sentences are completely equivalent, as they mean the same thing. |
| 4      | The two sentences are mostly equivalent, but some unimportant details differ. |
| 3      | The two sentences are roughly equivalent, but some important information differs or is missing. |
| 2      | The two sentences are not equivalent, but share some details. |
| 1      | The two sentences are not equivalent, but are on the same topic. |
| 0      | The two sentences are completely dissimilar. |

**Table X: The zero to five scale and corresponding instructions used to conduct the user study of absolute semantic similarity between the input and the output sentence.**

#### User Study Results

Figure 11 compares the distribution of ratings obtained by our model and the GoogleMT baseline in the absolute semantic similarity user study. The left figure shows the distribution of the ratings, while the right figure shows the distribution of the maximum difference between user ratings for each sentence.

Both user studies were conducted on the Amazon Mechanical Turk (AMT) platform. Workers were based in the United States and required to have the Mechanical Turk Masters qualification, which is given by AMT to workers producing high-quality work. They also needed a minimum approval rating of 95% in their prior assignments on AMT. All workers who participated in the two user studies were compensated through the AMT platform. Each sentence evaluation task paid an average of $0.02 and took a median of twelve seconds to complete. Both studies were conducted on the human-eval test set containing 745 test sentences, with each sentence evaluated by three unique users. No personal information was collected from the users.

- **Absolute Evaluation**: In the first evaluation, each user was shown the input sentence and the edited sentence and asked to rate the semantic similarity on a scale of 0 (no similarity) to 5 (identical). If a model produced an identical output sentence to the input, it automatically received a rating of 5. The models were compared using the average rating they obtained.
- **Relative Evaluation**: In the second evaluation, each user was shown the input sentence and modified sentences from different models and asked to pick the sentence that best preserves the meaning of the input text. If a model’s output sentence was picked by a user, it was considered ranked first. For sentences where one or more models produced output identical to the input, those models were directly awarded rank one. The models were compared based on the percentage of instances they were ranked first.

The results showed good agreement between the users. For the relative evaluation, all three users rating each sentence agreed 62% of the time, compared to a 25% chance of agreement if the three users were randomly voting. For the absolute evaluation, the distribution of ratings and the distribution of the maximum difference between the three ratings are shown in Figure 11. Most ratings were distributed between four and five, and the maximum difference between user ratings was mostly between zero and one. Users tended to agree more on our A4NT model compared to the GoogleMT baseline, likely due to the fact that our model preserves more semantic information.