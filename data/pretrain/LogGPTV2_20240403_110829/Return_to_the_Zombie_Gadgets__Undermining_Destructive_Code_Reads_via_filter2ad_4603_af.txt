work of Crane et al. [16] provides an execute-only primitive
and fully separates code and data at the compiler-level, which
eliminates the need for destructive reads. Unfortunately, these
techniques require one to either recompile open source soft-
ware (instead of using the binary distribution) or leave end-
users at the mercy of application developers for closed-source
software. Binary-compatible mitigations instead transparently
mitigate attacks on the (closed or open source) applications
that are already in use. We believe the development and
wide-spread adoption of mitigation tools such as Microsoft’s
Enhanced Mitigation Experience Toolkit (EMET) [33] aptly
demonstrate the demand for binary-compatible mitigations.
Clearly, moving forward, any security analysis of binary-
level execute-only memory protections that rely on destruc-
tive code reads must take into consideration the underlying
guarantees of the code diversiﬁcation technique being relied
upon. Given that achieving complete randomization coverage
(e.g., using basic block reordering [47]) is challenging for
complex closed-source applications (which systems such as
Heisenbyte [45] and NEAR [48] are meant to protect), best-
effort
techniques such as in-place code randomization are
the only available options. Sadly, as our results have shown,
such schemes are not sufﬁcient when destructive reads are the
principal protection limiting the partial inference of code bytes.
Other protections are needed. Thus, we hope that this work
motivates the need for additional research into more advanced
binary-level code diversiﬁcation techniques that can withstand
code association attacks of the types presented in this paper.
Fortunately, more straightforward solutions are in reach
for mitigating the attacks that exploit code non-persistence
via library reloads. The simplest solution is to disallow the
unloading of libraries, even if doing so comes at a price
of higher memory utilization and less ﬂexibility for complex
applications. An alternative, but more difﬁcult, solution would
965965
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:39 UTC from IEEE Xplore.  Restrictions apply. 
be to re-randomize each time a library is loaded. Of course,
such re-randomization would need to be performed in a way
that does not hinder one’s ability to support shared libraries.
More challenging still is the design and implementation of
practical techniques for re-randomizing all libraries each time
a process loads (for example, in a new browser tab). The use
of position independent code [30] will likely be required to
achieve that goal, though the challenges of supporting shared
libraries seem rather demanding. An alternative might be to
use the frameworks suggested by Crane et al. [17] and Bigelow
et al. [8] as a base for frequent re-randomizations. While these
approaches appear to offer at least one path forward, they
currently offer no support for closed-source applications.
VII. CONCLUSION
The emergence of JIT-ROP attacks that leverage memory
leak vulnerabilities to bypass code diversiﬁcation protections
has prompted active research on defenses that enforce execute-
only memory, which prevents the runtime disclosure of code
by prohibiting read accesses on executable memory. From a
practical perspective, only a few of those approaches [45, 4]
can be applied for the protection of the complex COTS pro-
grams that are being targeted by current in-the-wild exploits,
such as closed-source browsers and document viewers.
In this paper, we show that the recently proposed notion
of destructive code reads [45, 48], which enforces a relaxed
property of allowing data reads from executable memory, but
prevents the subsequent execution of previously read data,
is at best fragile. Although this approach seemingly strikes
a balance between compatibility with complex binaries and
protection against runtime code disclosure attacks, giving an
attacker the ability to perform reads even in a destructive way
is enough to undermine any offered protection.
To demonstrate this, we presented four ways in which an
attacker can pinpoint the location and state of gadgets. In
particular, code cloning via JIT code generation and code
non-persistence via shared library or process reloading rely
on destructively reading copies of generated or existing code,
allowing the reuse of gadgets that have not been previously
read, while code inference relies on reading preceding bytes
related to the randomized state of gadgets. These techniques
highlight the need for further research in binary-compatible
code randomization schemes tailored for use in conjunction
with execute-only memory protection, that will prevent gadget
inference through code cloning or implicit reads.
VIII. ACKNOWLEDGMENTS
We express our gratitude to Nathan Otterness, Micah Mor-
ton and Teryl Taylor for insightful discussions. We also thank
the anonymous reviewers for their suggestions on how to im-
prove the paper. This work is supported in part by the National
Science Foundation under awards 1421703 and 1127361 (with
a supplement from the Department of Homeland Security
under its Transition to Practice program), and the Ofﬁce of
Naval Research under award N00014-15-1-2378. Any opin-
ions, ﬁndings, and conclusions or recommendations expressed
herein are those of the authors and do not necessarily reﬂect
the views of the National Science Foundation, the Department
of Homeland Security, or the Ofﬁce of Naval Research.
REFERENCES
[1] “Intercom: Cross-window message broadcast interface.”
[Online]. Available: https://github.com/diy/intercom.js
[2] M. Athanasakis, E. Athanasopoulos, M. Polychronakis,
G. Portokalidis, and S. Ioannidis, “The devil is in the
constants: Bypassing defenses in browser JIT engines,” in
Symposium on Network and Distributed System Security,
2015.
[3] M. Backes and S. N¨urnberger, “Oxymoron: Making ﬁne-
grained memory randomization practical by allowing
code sharing,” in USENIX Security Symposium, 2014, pp.
433–447.
[4] M. Backes, T. Holz, B. Kollenda, P. Koppe,
S. N¨urnberger, and J. Pewny, “You can run but
you can’t
in
executable code,” in ACM Conference on Computer and
Communications Security, 2014, pp. 1342–1353.
read: Preventing disclosure exploits
[5] A. Barresi, K. Razavi, M. Payer, and T. R. Gross,
“Cain: Silently breaking ASLR in the cloud,” in USENIX
Workshop on Offensive Technologies, 2015.
[6] E. Bhatkar, D. C. Duvarney, and R. Sekar, “Address
obfuscation: an efﬁcient approach to combat a broad
range of memory error exploits,” in USENIX Security
Symposium, 2003, pp. 105–120.
[7] S. Bhatkar, R. Sekar, and D. C. DuVarney, “Efﬁcient
techniques for comprehensive protection from memory
error exploits,” in USENIX Security Symposium, 2005,
pp. 17–17.
[8] D. Bigelow, T. Hobson, R. Rudd, W. Streilein, and
H. Okhravi, “Timely rerandomization for mitigating
memory disclosures,” in ACM Conference on Computer
and Communications Security, 2015, pp. 268–279.
[9] D. Blazakis, “Interpreter exploitation,” in USENIX Work-
shop on Offensive Technologies, 2010, pp. 1–9.
[10] T. K. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang,
“Jump-oriented programming: a new class of code-reuse
attack.” in ACM Asia Conference on Computer and
Communications Security, 2011, pp. 30–40.
[11] K. Braden, S. Crane, L. Davi, M. Franz, P. Larsen,
C. Liebchen, and A.-R. Sadeghi, “Leakage-resilient lay-
out randomization for mobile devices,” in Symposium on
Network and Distributed System Security, 2016.
[12] S. Brookes, R. Denz, M. Osterloh, and S. Taylor, “Ex-
oshim: Preventing memory disclosure using execute-
only kernel code,” in International Conference on Cyber
Warfare and Security, 2016, p. To appear.
[13] N. Carlini and D. Wagner, “ROP is still dangerous:
Breaking modern defenses,” in USENIX Security Sym-
posium, 2014, pp. 385–399.
[14] N. Carlini, A. Barresi, M. Payer, D. Wagner, and T. R.
Gross, “Control-ﬂow bending: On the effectiveness of
966966
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:39 UTC from IEEE Xplore.  Restrictions apply. 
control-ﬂow integrity,” in USENIX Security Symposium,
2015, pp. 161–176.
[15] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi,
H. Shacham, and M. Winandy, “Return-oriented pro-
gramming without returns,” in ACM Conference on Com-
puter and Communications Security, 2010, pp. 559–572.
[16] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen,
A.-R. Sadeghi, S. Brunthaler, and M. Franz, “Readactor:
Practical code randomization resilient to memory disclo-
sure,” in IEEE Symposium on Security and Privacy, 2015,
pp. 763 – 780.
[17] S. J. Crane, S. Volckaert, F. Schuster, C. Liebchen,
P. Larsen, L. Davi, A.-R. Sadeghi, T. Holz, B. De Sut-
ter, and M. Franz, “It’s a trap: Table randomization
and protection against function-reuse attacks,” in ACM
Conference on Computer and Communications Security,
2015, pp. 243–255.
[18] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and
F. Monrose, “Isomeron: Code randomization resilient to
(just-in-time) return-oriented programming,” in Sympo-
sium on Network and Distributed System Security, 2015.
[19] L. V. Davi, A. Dmitrienko, S. N¨urnberger, and A.-R.
Sadeghi, “Gadge me if you can: Secure and efﬁcient ad-
hoc instruction-level randomization for x86 and ARM,”
in ACM Asia Conference on Computer and Communica-
tions Security, 2013, pp. 299–310.
[20] I. Evans, F. Long, U. Otgonbaatar, H. Shrobe, M. Rinard,
H. Okhravi, and S. Sidiroglou-Douskos, “Control jujutsu:
On the weaknesses of ﬁne-grained control ﬂow integrity,”
in ACM Conference on Computer and Communications
Security, 2015, pp. 901–913.
[21] J. Gionta, W. Enck, and P. Ning, “Hidem: Protecting the
contents of userspace memory in the face of disclosure
vulnerabilities,” in ACM Conference on Data and Appli-
cation Security and Privacy, 2015, pp. 325–336.
[22] H. Gisbert and I. Ripoll, “On the effectiveness of nx,
ssp, renewssp, and aslr against stack buffer overﬂows,”
in IEEE International Symposium on Network Computing
and Applications, 2014, pp. 145–152.
[23] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “En-
hanced operating system security through efﬁcient and
ﬁne-grained address space randomization,” in USENIX
Security Symposium, 2012, pp. 475–490.
[24] J. D. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and
J. W. Davidson, “ILR: Where’d my gadgets go?” in IEEE
Symposium on Security and Privacy, 2012, pp. 571–585.
[25] A. Homescu, S. Brunthaler, P. Larsen, and M. Franz,
“Librando: transparent code randomization for just-in-
time compilers,” in ACM Conference on Computer and
Communications Security, 2013, pp. 993–1004.
[26] R. Hund, C. Willems, and T. Holz, “Practical timing side
channel attacks against kernel space ASLR,” in IEEE
Symposium on Security and Privacy, May 2013, pp. 191–
205.
[27] A. Jangda, M. Mishra, and B. De Sutter, “Adaptive just-
in-time code diversiﬁcation,” in Proceedings of the Sec-
ond ACM Workshop on Moving Target Defense (MTD),
2015, pp. 49–53.
[28] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning, “Address
space layout permutation (ASLP): Towards ﬁne-grained
randomization of commodity software,” in Annual Com-
puter Security Applications Conference, 2006, pp. 339
–348.
[29] H. Koo and M. Polychronakis, “Juggling the gadgets:
Binary-level code randomization using instruction dis-
placement,” in ACM Asia Conference on Computer and
Communications Security, May 2016.
[30] J. R. Levine, Chapter 8: Loading and overlays. Linkers
and Loaders. San Francisco: Morgan-Kauffman, 1999.
[31] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh,
J. Mitchell, and M. Horowitz, “Architectural support for
copy and tamper resistant software,” in International
Conference on Architectural Support for Programming
Languages and Operating Systems, 2000, pp. 168–177.
[32] L. Liu, J. Han, D. Gao, J. Jing, and D. Zha, “Launching
return-oriented programming attacks against randomized
relocatable executables,” in IEEE International Confer-
ence on Trust, Security and Privacy in Computing and
Communications, 2011, pp. 37 – 44.
[33] Microsoft, “The enhanced mitigation experience toolkit.”
2016. [Online]. Available: https://support.microsoft.com/
en-us/kb/2458544/
[34] B. Niu and G. Tan, “Rockjit: Securing just-in-time com-
pilation using modular control-ﬂow integrity,” in ACM
Conference on Computer and Communications Security,
2014, pp. 1317–1328.
[35] V. Pappas, M. Polychronakis, and A. D. Keromytis,
“Smashing the gadgets: Hindering return-oriented pro-
gramming using in-place code randomization,” in IEEE
Symposium on Security and Privacy, 2012, pp. 601–615.
[36] C. Rohlf and Y. Ivnitskiy, “The security challenges of
client-side just-in-time engines,” IEEE Security & Pri-
vacy, vol. 10, no. 2, pp. 84–86, March/April 2012.
[37] C. Rohlf and Y. Ivnitskiy, “Attacking clientside JIT
compilers,” in Black Hat USA, 2011.
[38] F. J. Serna, “The info leak era on software exploitation,”
[40] H. Shacham, “The geometry of innocent ﬂesh on the
bone: Return-into-libc without function calls (on the
x86),” in ACM Conference on Computer and Commu-
nications Security, 2007, pp. 552–561.
[41] H. Shacham, E. jin Goh, N. Modadugu, B. Pfaff, and
D. Boneh, “On the effectiveness of address-space ran-
domization,” in ACM Conference on Computer and Com-
munications Security, 2004, pp. 298–307.
[42] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko,
C. Liebchen, and A.-R. Sadeghi, “Just-in-time code
reuse: On the effectiveness of ﬁne-grained address space
layout randomization,” in IEEE Symposium on Security
and Privacy, 2013, pp. 574–588.
in Black Hat USA, 2012.
[39] F. J. Serna, “Flash JIT - spraying for info leak gadgets,”
2013.
967967
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:39 UTC from IEEE Xplore.  Restrictions apply. 
[43] C. Song, C. Zhang, T. Wang, W. Lee, and D. Melski,
“Exploiting and protecting dynamic code generation,” in
Symposium on Network and Distributed System Security,
2015.
[44] A. Sotirov and M. Dowd, “Bypassing browser memory
protections in Windows Vista,” 2008.
[45] A. Tang, S. Sethumadhavan, and S. Stolfo, “Heisenbyte:
Thwarting memory disclosure attacks using destructive
code reads,” in ACM Conference on Computer and
Communications Security, 2015, pp. 256–267.
[46] R. Wartell, Y. Zhou, K. W. Hamlen, M. Kantarcioglu,
and B. Thuraisingham, “Differentiating code from data
in x86 binaries,” in Proceedings of the European Con-
ference on Machine Learning and Knowledge Discovery
in Databases, 2011, pp. 522–536.
[47] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin, “Binary
stirring: Self-randomizing instruction addresses of legacy
x86 binary code,” in ACM Conference on Computer and
Communications Security, 2012, pp. 157–168.
[48] J. Werner, G. Baltas, R. Dallara, N. Otterness, K. Z.
Snow, F. Monrose, and M. Polychronakis, “No-execute-
after-read: Preventing code disclosure in commodity
software.” in ACM Asia Conference on Computer and
Communications Security, 2016.
968968
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:39 UTC from IEEE Xplore.  Restrictions apply.