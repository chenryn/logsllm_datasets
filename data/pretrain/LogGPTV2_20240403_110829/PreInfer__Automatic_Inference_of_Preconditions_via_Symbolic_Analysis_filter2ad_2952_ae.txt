the comparison of preconditions generated by the three
approaches for cases where target preconditions must con-
tain existential or universal quantiﬁers (i.e., the collection-
element cases). As shown in Table VI, FixIt cannot handle
any single case, since FixIt uses only the last-branch predi-
cate to form a precondition. FixIt does not infer a precondi-
tion from multiple branch conditions and has no notion of a
quantiﬁer. Our PREINFER approach can handle 17 out of the
33 cases. Figure 2 shows a code example (from DSA), which
686
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:29:38 UTC from IEEE Xplore.  Restrictions apply. 
1 public static string ReverseWords(this
string value)
2 {
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27 }
int last = value.Length - 1;
int start = last;
StringBuilder sb = new StringBuilder();
while (last >= 0) {
while (start >= 0 &&
char.IsWhiteSpace(value[start])) {
start--;
}
last = start;
while (start >= 0 &&
!char.IsWhiteSpace(value[start])) {
start--;
}
for (int i = start + 1; i  0) {
sb.Append(’ ’);
}
last = start - 1;
start = last;
}
if (char.IsWhiteSpace(sb[sb.Length - 1]))
{
sb.Length = sb.Length - 1;
}
return sb.ToString();
Figure 2. An example of a method under study from DSA
PREINFER can handle. The method ReverseWords takes
an input string representing a sequence of words separated
by some whitespaces. The method returns a new string
representing the reverse of the sequence and removes some
whitespaces. If we pass an empty string as part of the input
to the method, the method throws an exception IndexOut-
OfRangeException on Line 23 as sb.Length - 1 being
negative. A ground-truth precondition to prevent this excep-
tion is value == null || ∃i,(i < value.Length ∧
char.IsWhiteSpace(value[i]) == false). Each fail-
ing path condition for this exception contains some predi-
cates indicating that all the characters in value must be
whitespaces. Our technique of collection-element general-
ization is able to generalize all the failing paths by us-
ing the quantiﬁed predicate, ∀i,(i < value.Length =⇒
char.IsWhiteSpace(value[i]) == true). Thus,
the
resulting precondition matches the ground-truth precondi-
tion.
One limitation of PREINFER is that if a path condition
does not contain all
the predicates that are needed to
infer an existential or universal template, PREINFER cannot
generalize anything, so the collection-element generalization
technique cannot work for such cases. For example, to infer a
template, ∀i,(i + 1 < 3) =⇒ s[i + 1] == ‘a’, each
failing path condition must contain predicate s[j + 1] ==
687
y
t
i
x
e
l
p
m
o
C
PREINFER (left bar)
DySy (right bar)
238.84
250
200
150
100
94.03
50
10.02
all
60.22
72.06
51.83
0.82
all-correct
3.67
some-correct
all-wrong
Figure 3.
PREINFER and DySy in four categories across all the subjects.
Average relative complexity of preconditions inferred by
‘a’ if it contains predicate j + 1 < 3. However, the failing
path condition may contain predicate s[1 + j] == ‘a’
instead, which is semantically the same, but syntactically
different. One way to improve our technique is to use a
constraint solver to help determine predicate equivalence in-
stead of using the raw string representations of the predicates
appearing in path conditions. In almost all cases, PREINFER
can outperform both DySy and FixIt; however, for some
cases that contain complex loops that PREINFER cannot
handle but the correct precondition is just the negation of
the last-branch predicate, PREINFER fails to resolve and
simplify the long path conditions for the loops, since our
technique of collection-element generalization works for
only some speciﬁc kinds of loops matching the two tem-
plates. When the technique fails to generalize some failing
paths related to loops, the failing paths are too speciﬁc. Thus,
the precondition generated from those failing paths is not
sufﬁcient (i.e., does not block all failing paths). FixIt, which
directly infers a precondition from the last-branch predicate,
can address such cases. Moreover, for some cases where
Pex cannot generate any passing path, PREINFER cannot
infer anything, whereas DySy can infer correct preconditions
for such cases. To address such cases, we can improve
PREINFER by slightly modifying our technique to skip all
the steps that require passing paths.
D. RQ2: How complex are the preconditions inferred by
PREINFER compared to those inferred by DySy and FixIt?
One may be interested to see how complex the precondi-
tions inferred by each approach under study are. For FixIt,
the average relative complexity of correct preconditions
inferred by FixIt is 0.19, and the average relative complexity
of incorrect preconditions inferred by FixIt is 0.76. Thus, the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:29:38 UTC from IEEE Xplore.  Restrictions apply. 
relative complexity of preconditions inferred by FixIt is very
low, regardless of their correctness. By design, preconditions
inferred by FixIt are not complex because they do not
capture potential control or data dependencies with the
assertion-containing location. Preconditions inferred by FixIt
are generated directly from last-branch predicates. Thus,
the average relative complexity of preconditions inferred
by FixIt is close to zero. However, the consequences of
FixIt’s design signiﬁcantly compromise the accuracy of the
preconditions as shown in Table V.
Figure 3 shows that the average relative complexity of
preconditions inferred by PREINFER and DySy in four
categories. The category “all” consists of all the ACLs. The
category “all-correct” consists of all the ACLs that both
approaches can infer correct preconditions (sufﬁcient and
necessary). The category “some-correct” consists of all the
ACLs that at least one approach infers correct preconditions,
and the category “all-wrong” consists of all the ACLs that
none of the approaches can infer correct preconditions.
In all four categories, the average relative complexity of
preconditions inferred by PREINFER is a lot lower than that
of preconditions inferred by DySy. On average across the
four categories, the average relative complexity of precon-
ditions inferred by PREINFER is about 9.70% of that of
preconditions inferred by DySy. Thus, preconditions inferred
by PREINFER are less complex than the ones inferred by
DySy. One possible reason is that failing path conditions
tend to have a fewer number of predicates than passing
path conditions, since the execution stops early when it
throws an exception. Thus, using failing path conditions
instead of passing path conditions (used by DySy) to infer
preconditions can reduce the complexity of the precon-
ditions. Moreover, PREINFER also has some heuristic to
prune unnecessary predicates from each failing path, helping
reduce the complexity of the inferred preconditions. As
shown in Figure 3, the average relative complexity of the
preconditions inferred by both approaches is getting higher
for a harder case. In the category “all-wrong”, the average
relative complexity of the preconditions inferred by both
approaches is much higher than that in the category “all-
correct”, since the category “all-wrong” usually contains
loop cases, which have long path conditions.
VI. RELATED WORK
Dynamic Invariant Detection. Ernst et al. [19] propose the
Daikon approach for dynamically detecting likely program
invariants through the execution of tests. Daikon infers
invariants based on patterns of variable values matching
predeﬁned templates. DySy [8] and Vigilante [20] infer
preconditions using the disjunction of the path conditions
from a set of passing and failing tests, respectively. In
the presence of loops, these approaches produce very long
and complex preconditions. Unlike their approaches that
leverage only passing or only failing tests, our approach
leverages both passing and failing tests, along with white-
box information (e.g., path conditions), allowing for more
pruning opportunities. Additionally, our approach summa-
rizes overly speciﬁc predicates introduced by loops.
Static Inference of Preconditions or Input Filters. The
approach of precondition inference in cccheck [18], [21] is
based on abstract interpretation. Its underlying static analysis
is undesirably more conservative and less precise than dy-
namic analysis (being used in our approach). Bouncer [22]
generates input ﬁlters to block exploit inputs. It combines
both static and dynamic analyses to perform precondition
slicing for pruning irrelevant predicates in path conditions.
SIFT [23] is a sound approach for input-ﬁlter generation
to block integer overﬂow vulnerabilities. SIFT uses static
analysis to derive symbolic constraints on how the sizes of
memory blocks are allocated to generate input ﬁlters that
block integer-overﬂow-causing inputs. Seghir et al. [24] pro-
pose an approach to infer preconditions by iteratively reﬁn-
ing an over-approximation of the set of safe and unsafe states
until they become disjoint. The reﬁnement process is to add
predicates such that a safe state and an unsafe state cannot
share their initial state. Unlike these approaches based on
static analysis, our approach leverages only the dynamically
collected path conditions to infer preconditions and requires
no static analysis (which often faces signiﬁcant challenges
in analyzing real-world code bases). Moreover, our approach
includes a technique to infer quantiﬁed preconditions for
summarizing overly speciﬁc predicates introduced by loops,
while these approaches do not handle loops specially.
Black-box Learning of Speciﬁcations. Among black-box
learning approaches for inferring speciﬁcations, Gehr et
al. [25] use random sampling to generate a ﬁxed set of tests
and use heuristics to extract diverse samples from their initial
set to learn commutativity speciﬁcations. Similarly, Padhi
et al. [26] learn preconditions, but also include techniques
to expand the initial features needed for learning. Sankara-
narayanan et al. [27] use an initial set of predicates to obtain
a partial truth table and then use a decision-tree-learning
algorithm to learn preconditions. Our approach differs from
these black-box approaches in that our approach is a white-
box one and can infer rich properties related to collection
elements.
VII. CONCLUSION
In this paper, we have presented PREINFER, a novel
approach of path-condition analysis for automatic precon-
dition inference. PREINFER infers preconditions that guard
against failures exposed by the generated failing tests with-
out blocking passing tests. In particular, PREINFER prunes
predicates that are irrelevant for helping achieve location
reachability and expression preservation, and generalizes
overly speciﬁc predicates involving collection elements as
quantiﬁed formulas over the indices of collection structures.
688
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:29:38 UTC from IEEE Xplore.  Restrictions apply. 
Our evaluation on a set of benchmarks from CodeCon-
tracts and SVComp along with two real-world open-source
projects (DSA and Algorithmia) shows PREINFER’s high
effectiveness on precondition inference and its superiority
over two related state-of-the-art approaches.
ACKNOWLEDGMENT
This work was supported in part by National Science
Foundation under grants no. CCF-1409423, CNS-1513939,
CNS1564274, and the GEM fellowship.
REFERENCES
[1] P. Godefroid, N. Klarlund, and K. Sen, “DART: Directed
automated random testing,” in Proc. PLDI, 2015, pp. 213–
223.
[2] N. Tillmann and J. De Halleux, “Pex: White box test gener-
ation for .NET,” in Proc. TAP, 2018, pp. 134–153.
[3] N. Tillmann, J. de Halleux, and T. Xie, “Transferring an
automated test generation tool to practice: from Pex to Fakes
and Code Digger,” in Proc. ASE, 2014, pp. 385–396.
[4] Microsoft.
tests
(2015) Generate smart unit
for your
code. [Online]. Available: https://msdn.microsoft.com/library/
dn823749
(2009) Exploring implicit branches.
[5] Microsoft.
Available:
US/c92907eb-3b2d-4c30-abcd-93ec1c120b00/exploring-
implicit-branches?forum=pex
[Online].
https://social.msdn.microsoft.com/Forums/en-
[6] P. Godefroid, “Higher-order test generation,” in Proc. PLDI,
2011, pp. 258–269.
[7] P. Godefroid and D. Luchaup, “Automatic partial loop sum-
marization in dynamic test generation,” in Proc. ISSTA, 2011,
pp. 23–33.
[8] C. Csallner, N. Tillmann, and Y. Smaragdakis, “DySy: Dy-
namic symbolic execution for invariant inference,” in Proc.
ICSE, 2018, pp. 281–290.
[9] N. Tillmann and J. D. Halleux, “Parameterized unit testing
with Microsoft Pex (Long Tutorial),” 2010.
[Online].
Available: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=
10.1.1.159.4711
[10] GitHub, “GitHub,” https://github.com.
[11] lukadt, “Data Structures and Algorithms (DSA).” [On-
line]. Available: https://github.com/lukadt/Data-Structures-
and-Algorithms-DSA
[12] SolutionsDesign, “Algorithmia.” [Online]. Available: https:
//github.com/SolutionsDesign/Algorithmia/tree/master
[13] N. Polikarpova, C. A. Furia, Y. Pei, Y. Wei, and B. Meyer,
“What good are strong speciﬁcations?” in Proc. ICSE, 2013,
pp. 262–271.
[14] X. Xiao, S. Li, T. Xie, and N. Tillmann, “Characteristic
studies of loop problems for structural test generation via
symbolic execution,” in Proc. ASE, 2013, pp. 246–256.
[15] Software and Computational Systems Lab, “Collection of
veriﬁcation tasks.” [Online]. Available: https://github.com/
sosy-lab/sv-benchmarks
[16] J. Jaffar, V. Murali, J. A. Navas, and A. E. Santosa,
“TRACER: A symbolic execution tool for veriﬁcation,” in
Proc. CAV, 2012, pp. 758–766.
[17] X. Xie, B. Chen, Y. Liu, W. Le, and X. Li, “Proteus:
Computing disjunctive loop summary via path dependency
analysis,” in Proc. FSE, 2016, pp. 61–72.
[18] P. Cousot, R. Cousot, M. F¨ahndrich, and F. Logozzo, “Auto-
matic inference of necessary preconditions,” in Proc. VMCAI,
2013, pp. 128–148.
[19] M. D. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin,
“Dynamically discovering likely program invariants to sup-
port program evolution,” in Proc. ICSE, 2001, pp. 99–123.
[20] M. Costa, J. Crowcroft, M. Castro, A. Rowstron, L. Zhou,
L. Zhang, and P. Barham, “Vigilante: End-to-end containment
of Internet Worms,” in Proc. SOSP, 2015, pp. 133–147.
[21] P. Cousot, R. Cousot, and F. Logozzo, “Precondition inference
from intermittent assertions and application to contracts on
collections,” in Proc. VMCAI, 2011, pp. 150–168.
[22] M. Costa, M. Castro, L. Zhou, L. Zhang, and M. Peinado,
“Bouncer: Securing software by blocking bad input,” in Proc.
SOSP, 2007, pp. 117–130.
[23] F. Long, S. Sidiroglou-Douskos, D. Kim, and M. Rinard,
“Sound input ﬁlter generation for integer overﬂow errors,”
in Proc. POPL, 2014, pp. 439–452.
[24] M. N. Seghir and D. Kroening, “Counterexample-guided
precondition inference,” in Proc. ESOP, 2013, pp. 451–471.
[25] T. Gehr, D. Dimitrov, and M. T. Vechev, “Learning commu-
tativity speciﬁcations,” in Proc. CAV, 2015, pp. 307–323.
[26] S. Padhi, R. Sharma, and T. Millstein, “Data-driven precon-
dition inference with learned features,” in Proc. PLDI, 2016,
pp. 42–56.
[27] S. Sankaranarayanan, S. Chaudhuri, F. Ivanˇci´c, and A. Gupta,
“Dynamic inference of likely data preconditions over predi-
cates by tree learning,” in Proc. ISSTA, 2008, pp. 295–306.
689
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:29:38 UTC from IEEE Xplore.  Restrictions apply.