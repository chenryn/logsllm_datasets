Springer, 1999, pp. 223–
238.
[51] B. Pinkas and T. Reinman, “Oblivious ram revisited,” in Advances in
Cryptology–CRYPTO 2010. Springer, 2010, pp. 502–519.
J. Plenz, “nocache - minimize ﬁlesystem caching effects,” Available at
https://github.com/Feh/nocache.
[52]
[53] L. Ren, C. W. Fletcher, A. Kwon, E. Stefanov, E. Shi, M. van Dijk, and
S. Devadas, “Ring oram: Closing the gap between small and large client
storage oblivious ram.” IACR Cryptology ePrint Archive, vol. 2014, p.
997, 2014.
[54] D. S. Roche, A. Aviv, and S. G. Choi, “A practical oblivious map data
structure with secure deletion and history independence,” in 2016 IEEE
Symposium on Security and Privacy (SP).
IEEE, 2016, pp. 178–197.
[55] D. S. Roche, A. Aviv, S. G. Choi, and T. Mayberry, “Deterministic,
stash-free write-only oram,” in Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security. ACM, 2017,
pp. 507–521.
[56] C. Sahin, V. Zakhary, A. El Abbadi, H. Lin, and S. Tessaro, “Taostore:
Overcoming asynchronicity in oblivious data storage,” in 2016 IEEE
Symposium on Security and Privacy (SP).
IEEE, 2016, pp. 198–217.
[57] A. Shamir, “How to share a secret,” Communications of the ACM,
vol. 22, no. 11, pp. 612–613, 1979.
[58] S. Shepler, B. Callaghan, D. Robinson, R. Thurlow, C. Beame,
M. Eisler, and D. Noveck, “Network ﬁle system (nfs) version 4
protocol,” Tech. Rep., 2003.
[59] E. Shi, T.-H. H. Chan, E. Stefanov, and M. Li, “Oblivious ram with
o ((logn) 3) worst-case cost,” in Advances in Cryptology–ASIACRYPT
2011. Springer, 2011, pp. 197–214.
[60] V. Shoup, “Ntl: A library for doing number theory,” Available at https:
//www.shoup.net/ntl/.
[61] E. Stefanov and E. Shi, “Multi-cloud oblivious storage,” in Proceedings
of the 2013 ACM SIGSAC conference on Computer & communications
security. ACM, 2013, pp. 247–258.
[62] ——, “Oblivistore: High performance oblivious cloud storage,” in 2013
IEEE, 2013, pp. 253–267.
[63] E. Stefanov, E. Shi, and D. Song, “Towards practical oblivious ram,”
IEEE Symposium on Security and Privacy.
arXiv preprint arXiv:1106.3652, 2011.
[64] E. Stefanov, M. Van Dijk, E. Shi, C. Fletcher, L. Ren, X. Yu, and
S. Devadas, “Path oram: an extremely simple oblivious ram protocol,”
in Proceedings of the 2013 ACM SIGSAC conference on Computer and
Communications security. ACM, 2013, pp. 299–310.
[65] S. Tople, Y. Jia, and P. Saxena, “Pro-oram: Practical read-only oblivious
{RAM},” in 22nd International Symposium on Research in Attacks,
Intrusions and Defenses ({RAID} 2019), 2020.
[66] X. Wang, H. Chan, and E. Shi, “Circuit oram: On tightness of
the goldreich-ostrovsky lower bound,” in Proceedings of
the 22nd
ACM SIGSAC Conference on Computer and Communications Security.
ACM, 2015, pp. 850–861.
[67] X. S. Wang, Y. Huang, T. H. Chan, A. Shelat, and E. Shi, “Scoram:
oblivious ram for secure computation,” in Proceedings of the 2014
ACM SIGSAC Conference on Computer and Communications Security.
ACM, 2014, pp. 191–202.
[68] X. S. Wang, K. Nayak, C. Liu, T. Chan, E. Shi, E. Stefanov, and
Y. Huang, “Oblivious data structures,” in Proceedings of the 2014
ACM SIGSAC Conference on Computer and Communications Security.
ACM, 2014, pp. 215–226.
[69] P. Williams, R. Sion, and B. Carbunar, “Building castles out of mud:
practical access pattern privacy and correctness on untrusted storage,”
in Proceedings of the 15th ACM conference on Computer and commu-
nications security. ACM, 2008, pp. 139–148.
[70] P. Williams, R. Sion, and A. Tomescu, “Privatefs: A parallel oblivious
ﬁle system,” in Proceedings of the 2012 ACM conference on Computer
and communications security. ACM, 2012, pp. 977–988.
15
APPENDIX
We ﬁrst prove the security of matrix multiplication proto-
cols in §IV-B1. We deﬁne the security model for the matrix
multiplication with veriﬁability as follows.
Deﬁnition 3 (Matrix multiplication with veriﬁability). We ﬁrst
deﬁne the ideal world and real world as follows.
Ideal world. Let Fmult be an ideal functionality, which
performs the matrix multiplication for each client request as
follows. In each time step, the environment Z speciﬁes two
matrices X and Y as the client’s input. The client sends X
and Y to Fmult. Fmult notiﬁes the simulator Smult (without
revealing X and Y to Smult). If Smult returns ok to Fmult,
Fmult computes and sends Z = X × Y to the client. The
client then returns Z to the environment Z. If Smult returns
abort to Fmult, Fmult returns ⊥ to the client.
In the real world, Z speciﬁes an input (X, Y)
Real world.
to the client. The client executes the matrix multiplication
protocol Π with servers (S0, . . . , S(cid:96)−1). The environment Z
gets the view of the adversary A after every operation. The
client outputs to the environment Z the output of the protocol
Π or abort.
We say that a protocol ΠF securely realizes the ideal
functionality Fmult in the presence of a malicious adversary
corrupting t servers iff for any PPT real-world adversary that
corrupts up to t servers, there exists a simulator Smult, such that
for all non-uniform, polynomial-time environment Z, there
exists a negligible function negl such that
| Pr[REALΠF ,A,Z (λ) = 1]−Pr[IDEALFmult,Smult,Z (λ) = 1]| ≤ negl(λ).
p
p
and Y ∈ Fm×p
Proof of Lemma 1: We prove by constructing a simulator
such that the environment Z cannot distinguish between the
real protocol and the ideal functionality. We deﬁne the simu-
lator Smult in the ideal world and a sequence of hybrid games
as follows.
The simulator Smult. The simulator follows the honest pro-
cedure on behalf of the client to multiply two dummy matrices
X ∈ Fn×m
. During the multiplication, if the
client (executed by the simulator) aborts then the simulator
sends abort to Fmult and stops. Otherwise,
the simulator
returns ok to Fmult (causing it to output the result to the client).
Sequence of Hybrid Games. We deﬁne a sequence of hybrid
games to show that the following real world and the simulation
in the ideal world are statistically indistinguishable:
| Pr[REALΠF ,A,Z (λ) = 1]−Pr[IDEALFmult,Smult,Z (λ) = 1]| ≤ negl(λ).
Game 0. This is the real game REALΠF ,A,Z (λ) with an
environment Z and three servers in the presence of an adver-
sary A presented in Deﬁnition 3. In this case, the real matrix
multiplication protocol ΠF is the one presented in Figure 2.
Without loss of generality, we assume server S0 is corrupted.
In this game, the client locally computes Z = X ×
Game 1.
Y. Whenever the client executes the protocol ΠF with three
servers, if abort does not occur, the client uses their locally
computed Z for further processing. The difference between
Game 0 and Game 1 happens if at some point, where the
client obtains an incorrect computation from the servers, but
unable to detect because the adversary generates a valid MAC
of the computation (thus the abort does not occur). We claim
that Game 0 and Game 1 are statistically indistinguishable. The
S0
S1
S2
(1)
+
+
can be expressed as
intuition is to show that if the adversarial server ever cheats by
modifying the protocol input during the computation, it will
be caught with high probability (thereby forcing the adversary
to follow the protocol faithfully).
Let (cid:104)X(cid:105)i = ((cid:74)X(cid:75)i,(cid:74)αX(cid:75)i) and (cid:104)X(cid:105)i = ((cid:74)Y(cid:75)i,(cid:74)αY(cid:75)i)
that X = (cid:80)
i(cid:74)Y(cid:75)i, αX = (cid:80)
i(cid:74)X(cid:75)i, Y = (cid:80)
be the authenticated shares of X and Y for every server
αY =(cid:80)
i(cid:74)αX(cid:75)i and
Si, 0 ≤ i ≤ 2. Due to additive secret sharing, we have
i(cid:74)αY(cid:75)i. By replicated secret sharing, Z = X × Y
=(cid:0)(cid:74)X(cid:75)0 ×(cid:74)Y(cid:75)0 +(cid:74)X(cid:75)0 ×(cid:74)Y(cid:75)1 +(cid:74)X(cid:75)1 ×(cid:74)Y(cid:75)0
(cid:1)
Z =((cid:74)X(cid:75)0 +(cid:74)X(cid:75)1 +(cid:74)X(cid:75)2) × ((cid:74)Y(cid:75)0 +(cid:74)Y(cid:75)1 +(cid:74)Y(cid:75)2)
(cid:1)
(cid:0)(cid:74)X(cid:75)1 ×(cid:74)Y(cid:75)1 +(cid:74)X(cid:75)1 ×(cid:74)Y(cid:75)2 +(cid:74)X(cid:75)2 ×(cid:74)Y(cid:75)1
(cid:0)(cid:74)X(cid:75)2 ×(cid:74)Y(cid:75)2 +(cid:74)X(cid:75)0 ×(cid:74)Y(cid:75)2 +(cid:74)X(cid:75)2 ×(cid:74)Y(cid:75)0
(cid:1)
(cid:0)R(0)
(cid:0)R(0)
(cid:0)R(0)
(cid:0)R(0)
+(cid:0)R(0)
+(cid:0)R(0)
2 )S0 + (R(1)
2 )S2
0 + R(2)
2 + R(2)
0 + R(1)
2 + R(1)
1 + R(1)
0 + R(1)
1 + R(2)
0 + R(2)
0 + R(1)
=(R(0)
(R(2)
0 + R(0)
0 + R(2)
1 + R(0)
1 + R(2)
1 + R(1)
1 + R(2)
2 + R(1)
2 + R(2)
1 + R(1)
2 )S1 +
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(3)
S0 can cheat at three stages: (i) before the re-sharing phase
where S0 modiﬁes their own shares ((cid:74)X(cid:75)0,(cid:74)Y(cid:75)0,(cid:74)X(cid:75)1,(cid:74)Y(cid:75)1)
(Equation 1); (ii) during the re-sharing phase where S0 sends
inconsistent shares to other servers (Equation 2); (iii) after
the re-sharing phase where S0 deviates the linear combination
(Equation 3). It can be seen that (ii) and (iii) may result
in the servers storing inconsistent copies with each other,
which can be detected at the output phase of the protocol.
Speciﬁcally, every server Si performs the random linear com-
(cid:74)x(cid:75)i ←(cid:80)
bination of all components(cid:74)zj(cid:75)i in the resulting matrix(cid:74)Z(cid:75)i as
j rj(cid:74)zj(cid:75)i. Due to RSS,(cid:74)x(cid:75)i will be computed by two
servers on their own shares. This means if(cid:74)Z(cid:75)i is inconsistent
from two servers, the client will receive two different xi and,
therefore, can tell whether one of the servers has cheated.
S0
S2
S0
S2
0
2
1
0
+
S1
+
S1
=
(2)
1
2
Finally, we show that if the adversary adds any error to his
local computation before the re-sharing phase (i.e., stage (i)),
they will also get caught. Let T be an error introduced by S0
during its local computation. By Equation 1, the computation
will now become (X× Y + T). Hence, to make the client not
abort, S0 should modify its shares of the MACs in such a way
that all servers will compute the valid share of the MAC of the
form α(X × Y + T) at the end. Remark that the MAC of the
multiplication X × Y is α(X × Y), which can be computed
αX × Y =((cid:74)αX(cid:75)0 +(cid:74)αX(cid:75)1 +(cid:74)αX(cid:75)2) × ((cid:74)Y(cid:75)0 +(cid:74)Y(cid:75)1 +(cid:74)Y(cid:75)2)
=(cid:0)(cid:74)αX(cid:75)0 ×(cid:74)Y(cid:75)0 +(cid:74)αX(cid:75)0 ×(cid:74)Y(cid:75)1 +(cid:74)αX(cid:75)1 ×(cid:74)Y(cid:75)0
(cid:1)
by multiplying αX with Y via replicated secret sharing as
(cid:0)(cid:74)αX(cid:75)1 ×(cid:74)Y(cid:75)1 +(cid:74)αX(cid:75)1 ×(cid:74)Y(cid:75)2 +(cid:74)αX(cid:75)2 ×(cid:74)Y(cid:75)1
(cid:1)
(cid:0)(cid:74)αX(cid:75)2 ×(cid:74)Y(cid:75)2 +(cid:74)αX(cid:75)2 ×(cid:74)Y(cid:75)0 +(cid:74)αX(cid:75)0 ×(cid:74)Y(cid:75)2
(cid:1)
Let T(cid:48) be an error introduced by S0 during the local
computation in Equation 4. As shown above, the resulting
MAC computation will be of the form (αX × Y + T(cid:48)). Thus,
α(X × Y) + T(cid:48) = α(X × Y + T) ⇐⇒ T(cid:48) = αT.
(5)
Since α is the global MAC key known only be the client, the
probability that S0 can generate a valid (T, T(cid:48)) pair is
1|Fp|.
That means the adversary cannot deviate from the protocol,
otherwise, they will cause the client to abort the protocol with
+
+
(4)
.
S0
S1
S2
high probability.
Game 1’.
In this game, the client executes ΠF with three
servers using dummy matrices,
instead of the one chosen
by the environment Z. We introduce the ideal functionality
Fmult, which the client queries to answer the environment
requests. During executing ΠF , if the client does not abort,
the output of F is forwarded to Z. We claim that Game 1
and Game 2 are statistically indistinguishable, in which the
view of the adversary can be simulated given the view of
the honest servers. At the beginning of the ΠF protocol, the
client distributes the authenticated share of the multiplication
matrices to each server. Due to the perfect secrecy of additive
secret sharing, all these shares are uniformly distributed. After
the local computation, each server re-shares the computed
result with additive secret sharing and distributes the shares
to other servers (i.e., step 1 in Figure 2). Such shares are
also uniformly distributed due to the security of additive secret
sharing. All these properties permit to simulate the view of the
adversary given the view of the honest servers.
Game 0’. We deﬁne Game 0’ similar to Game 0 except that
the client uses dummy matrices to interact with the servers,
instead of the ones provided by the environment Z. The client
queries the ideal functionality Fpir on the actual input provided
by Z and forwards the output to Z. We claim that Game 1’
and Game 0’ are indistinguishable using the same argument
as between Game 1 and Game 0. We can see that Game 0’ is
the ideal game IDEALFmult,Smult,Z with simulator Smult and the
environment Z.
Putting all the games together, we have that Game 0 ≡
Game 1 ≡ Game 1’ = Game 0’ and this completes the proof.
Proof of Corollary 1: This proof can be derived from
the proof of Lemma 1 and the one in [20] so that we will
not present it in detail due to repetition. Intuitively, the proof