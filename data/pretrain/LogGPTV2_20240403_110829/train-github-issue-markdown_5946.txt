(k8s 1.1.4)
After restarting my master server components, 2 out of 5 of my DaemonSet pods
were terminated (why?) and never recreated. It seems like all `ds` pods were
requeued during this event, however the IDs of the currently running pods do
not even match what is reported by the DaemonSet.
  * Restarting the `kubelet` on faulty nodes does nothing but re-adding a SyncLoop
  * Restarting the `kube-controller-manager` again shows `Waiting for pods controller to sync, requeuing ds ingress-apis`
  * `kube-scheduler` shows no relevant information
The first message in the kubelet log ("... The image pull may not succeed.")
makes me think it _might_ be related to #18947, however:
  * a pull should not have been triggered since the imagePullPolicy is `IfNotPresent`, and the image was present before the restart
  * `SyncLoop (ADD)` shouldn't have happened in the first place since 5 pods were already running before the restart
##
Current state of the ds:
    Name:       ingress-apis
    Image(s):   nginx:1.9.7
    Selector:   app=ingress,tier=backend
    Node-Selector:  
    Labels:     app=ingress,tier=backend
    Desired Number of Nodes Scheduled: 5
    Current Number of Nodes Scheduled: 5
    Number of Nodes Misscheduled: 0
    Pods Status:    3 Running / 0 Waiting / 0 Succeeded / 2 Failed
    Events:
      FirstSeen LastSeen    Count   From        SubobjectPath   Reason          Message
      ─────────   ────────    ───── ────        ───────────── ──────          ───────
      40m       40m     1   {daemon-set }           SuccessfulCreate    Created pod: ingress-apis-0svoi
      40m       40m     1   {daemon-set }           SuccessfulCreate    Created pod: ingress-apis-qn8tk
      39m       39m     1   {daemon-set }           SuccessfulCreate    Created pod: ingress-apis-4p04e
      39m       39m     1   {daemon-set }           SuccessfulCreate    Created pod: ingress-apis-2ncfy
      39m       39m     1   {daemon-set }           SuccessfulCreate    Created pod: ingress-apis-v6iuf
##
Current pods:
    NAME                 READY     STATUS    RESTARTS   AGE
    ingress-apis-jwlqo   1/1       Running   0          19h
    ingress-apis-mabp8   1/1       Running   0          17h
    ingress-apis-rte9q   1/1       Running   0          19h
##
`kubelet` logs on a faulty node:
    --Jan 20 09:44:11--
    kubelet.go:1477] Unable to retrieve pull secret default/docker-registry for default/ingress-apis-mensq due to Get https://k8s.freeletics.com/api/v1/namespaces/default/secrets/docker-registry: dial tcp 10.0.31.59:443: connection refused.  The image pull may not succeed.
    kubelet.go:2012] SyncLoop (ADD): "ingress-apis-0svoi_default"
    kubelet.go:1862] Pod "ingress-apis-0svoi_default": HostPort is already allocated, ignoring: [[0].port: duplicate value '9080/TCP']
    kubelet.go:2015] SyncLoop (UPDATE): "ingress-apis-mensq_default"
    manager.go:1404] Killing container "bac67ab2623eb60b6d23e714feee4d74be6b5c3e7417f07b08bd874d2183245f nginx default/ingress-apis-mensq" with 30 second grace period
    manager.go:1438] Container "bac67ab2623eb60b6d23e714feee4d74be6b5c3e7417f07b08bd874d2183245f nginx default/ingress-apis-mensq" exited after 68.511739ms
    manager.go:1444] No ref for pod '"bac67ab2623eb60b6d23e714feee4d74be6b5c3e7417f07b08bd874d2183245f nginx default/ingress-apis-mensq"'
    manager.go:1404] Killing container "eb0b4d358a9afe7aa2ac18d7f6eec57a6d2cd54506e4ae18096c7996c011de77 default/ingress-apis-mensq" with 30 second grace period
    manager.go:1438] Container "eb0b4d358a9afe7aa2ac18d7f6eec57a6d2cd54506e4ae18096c7996c011de77 default/ingress-apis-mensq" exited after 213.225172ms
    manager.go:1444] No ref for pod '"eb0b4d358a9afe7aa2ac18d7f6eec57a6d2cd54506e4ae18096c7996c011de77 default/ingress-apis-mensq"'
    kubelet.go:2015] SyncLoop (UPDATE): "ingress-apis-mensq_default"
    kubelet.go:2018] SyncLoop (REMOVE): "ingress-apis-mensq_default"
    kubelet.go:2108] Failed to delete pod "ingress-apis-mensq_default", err: pod not found
    --Jan 20 09:44:22--
##
`kube-controller-manager` logs:
    --Jan 20 09:44:14--
    controller.go:493] Waiting for pods controller to sync, requeuing ds ingress-apis
    controller.go:493] Waiting for pods controller to sync, requeuing ds ingress-apis
    controller.go:493] Waiting for pods controller to sync, requeuing ds ingress-apis
    controller.go:493] Waiting for pods controller to sync, requeuing ds ingress-apis
    controller.go:493] Waiting for pods controller to sync, requeuing ds ingress-apis
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"4b05bf3e-9c18-11e5-b4d2-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"63618203", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-0svoi
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"4b05bf3e-9c18-11e5-b4d2-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"63618203", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-qn8tk
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"4b05bf3e-9c18-11e5-b4d2-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"63618203", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-4p04e
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"4b05bf3e-9c18-11e5-b4d2-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"63618203", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-2ncfy
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"4b05bf3e-9c18-11e5-b4d2-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"63618203", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-v6iuf
    --Jan 20 09:44:20--
* * *
Before someone asks, although this is obvious, I solved it by deleting and
recreating the `ds` (identically):
##
`kubelet` logs on a previously faulty node:
    --Jan 20 10:52:33--
    kubelet.go:2015] SyncLoop (UPDATE): "ingress-apis-0svoi_default"
    kubelet.go:2018] SyncLoop (REMOVE): "ingress-apis-0svoi_default"
    kubelet.go:2108] Failed to delete pod "ingress-apis-0svoi_default", err: pod not found
    kubelet.go:2012] SyncLoop (ADD): "ingress-apis-9us1a_default"
    manager.go:1707] Need to restart pod infra container for "ingress-apis-9us1a_default" because it is not found
    --Jan 20 10:52:34--
##
`kube-controller-manager` logs:
    --Jan 20 10:52:40--
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"ed06f7f4-bf63-11e5-91dc-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"64118991", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-hgcn1
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"ed06f7f4-bf63-11e5-91dc-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"64118991", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-9us1a
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"ed06f7f4-bf63-11e5-91dc-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"64118991", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-lsobz
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"ed06f7f4-bf63-11e5-91dc-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"64118991", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-ogjrw
    event.go:206] Event(api.ObjectReference{Kind:"DaemonSet", Namespace:"default", Name:"ingress-apis", UID:"ed06f7f4-bf63-11e5-91dc-0a59d1e77755", APIVersion:"extensions", ResourceVersion:"64118991", FieldPath:""}): reason: 'SuccessfulCreate' Created pod: ingress-apis-9tae0
    --Jan 20 10:52:41--