title:Control-Flow Bending: On the Effectiveness of Control-Flow Integrity
author:Nicholas Carlini and
Antonio Barresi and
Mathias Payer and
David A. Wagner and
Thomas R. Gross
Control-Flow Bending: On the Effectiveness of 
Control-Flow Integrity
Nicolas Carlini, University of California, Berkeley; Antonio Barresi, ETH Zürich;  
Mathias Payer, Purdue University; David Wagner, University of California, Berkeley;  
Thomas R. Gross, ETH Zürich
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/carlini
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXControl-Flow Bending:
On the Effectiveness of Control-Flow Integrity
Nicolas Carlini
UC Berkeley
Antonio Barresi
ETH Zurich
Mathias Payer
Purdue University
David Wagner
UC Berkeley
Thomas R. Gross
ETH Zurich
Abstract
Control-Flow Integrity (CFI) is a defense which pre-
vents control-ﬂow hijacking attacks. While recent re-
search has shown that coarse-grained CFI does not stop
attacks, ﬁne-grained CFI is believed to be secure.
We argue that assessing the effectiveness of practi-
cal CFI implementations is non-trivial and that common
evaluation metrics fail to do so. We then evaluate fully-
precise static CFI — the most restrictive CFI policy that
does not break functionality — and reveal limitations in
its security. Using a generalization of non-control-data
attacks which we call Control-Flow Bending (CFB), we
show how an attacker can leverage a memory corruption
vulnerability to achieve Turing-complete computation on
memory using just calls to the standard library. We use
this attack technique to evaluate fully-precise static CFI
on six real binaries and show that in ﬁve out of six cases,
powerful attacks are still possible. Our results suggest
that CFI may not be a reliable defense against memory
corruption vulnerabilities.
We further evaluate shadow stacks in combination
with CFI and ﬁnd that their presence for security is nec-
essary: deploying shadow stacks removes arbitrary code
execution capabilities of attackers in three of six cases.
1
Introduction
Attacking software systems by exploiting memory-
corruption vulnerabilities is one of the most common
attack methods today according to the list of Common
Vulnerabilities and Exposures. To counter these threats,
several hardening techniques have been widely adopted,
including ASLR [29], DEP [38], and stack canaries [10].
Each has limitations: stack canaries protect only against
contiguous overwrites of the stack, DEP protects against
code injection but not against code reuse, and ASLR does
not protect against information leakage.
We classify defense mechanisms into two broad cat-
egories: prevent-the-corruption and prevent-the-exploit.
Defenses that prevent the corruption stop the actual
memory corruption before it can do any harm to the pro-
gram (i.e., no attacker-controlled values are ever used
out-of-context). Examples for prevent-the-corruption
defenses are SoftBound [22], Data-Flow Integrity [6],
or Code-Pointer Integrity [18].
In contrast, prevent-
the-exploit defenses allow memory corruption to occur
but protect the application from subsequent exploitation;
they try to survive or tolerate adversarial corruption of
memory. Examples for prevent-the-exploit defenses are
DEP [38] or stack canaries [10].
Control-Flow Integrity (CFI) [1, 3, 12, 15, 27, 30, 31,
39, 41–44] is a promising stateless prevent-the-exploit
defense mechanism that aims for complete protection
against control-ﬂow hijacking attacks under a threat
model with a powerful attacker that can read and write
into the process’s address space. CFI ensures that pro-
gram execution follows a valid path through the static
Control-Flow Graph (CFG). Any deviation from the
CFG is a CFI violation, terminating the application. CFI
is not speciﬁc to any particular exploitation vector for
control-ﬂow hijacking. Rather, it enforces its policy on
all indirect branch instructions. Therefore any attempt by
an attacker to alter the control-ﬂow in an invalid manner
will be detected, regardless of how the attacker changes
the target of the control-ﬂow transfer instruction.
CFI is often coupled with a protected shadow stack,
which ensures that each return statement matches the
corresponding call and thereby prevents an attacker from
tampering with return addresses. While the foundational
work [1, 15] included a shadow stack as part of CFI,
some more recent research has explored variants of CFI
that omit the shadow stack for better performance [9].
Whereas conformance to the CFG is a stateless policy,
shadow stacks are inherently dynamic and are more pre-
cise than any static policy can be with respect to returns.
Many prior attacks on CFI have focused on attacking a
weak or suboptimal implementation of CFI. Our focus is
on evaluating the effectiveness of CFI in its best achiev-
USENIX Association  
24th USENIX Security Symposium  161
able form, instead of artifacts of some (possibly weak)
CFI implementation. We deﬁne fully-precise static CFI
as the best achievable CFI policy as follows: a branch
from one instruction to another is allowed if and only
if some benign execution makes that same control-ﬂow
transfer. Such a policy could be imagined as taking any
CFG over-approximation and removing edges until re-
moving additional edges would break functionality.
Thus, fully-precise static CFI is the most restrictive
stateless CFI policy that still allows the program to run as
intended. Both coarse-grained and ﬁne-grained CFI are
less precise than fully-precise static CFI, because they
both over-approximate the set of valid targets for each
indirect transfer (though to a different degree). In con-
trast, fully-precise static CFI involves no approximation
by deﬁnition. We acknowledge that fully-precise static
CFI might be stricter than anything that can be prac-
tically implemented, but this makes any attacks all the
more meaningful: our results help us understand funda-
mental limits on the effectiveness of the strongest possi-
ble CFI policy.
Through several methods of evaluation, we argue that
fully-precise static CFI is neither completely broken (as
most coarse-grained defenses are) nor totally secure. We
explore what CFI can and cannot prevent, and hope that
this will stimulate a broader discussion about ways to fur-
ther strengthen CFI.
We evaluate the security of fully-precise static CFI
both with and without shadow stacks. Recent research
achieves better performance by omitting the shadow
stack in favor of a static policy on return statements. We
still call it fully-precise static CFI when we have added
a shadow stack, because the shadow stack is orthogonal.
This does not change the fact that the CFI policy is static.
CFI works by preventing an attacker from deviating
from the control-ﬂow graph. Our attacks do not involve
breaking the CFI mechanism itself: we even assume the
mechanism is implemented perfectly to its fullest extent.
Rather, our analysis demonstrates that an attacker can
still create exploits for most real applications, without
causing execution to deviate from the control-ﬂow graph.
This paper provides the following contributions:
1. formalization and evaluation of a space of different
kinds of CFI schemes;
2. new attacks on fully-precise static CFI, which reveal
fundamental limits on the effectiveness of CFI;
3. evidence that existing metrics for CFI security are
ineffective;
4. evidence that CFI without a shadow stack is broken;
5. widely applicable Turing-complete attacks on CFI
with shadow stacks; and,
6. practical case studies of the security of fully-precise
static CFI for several existing applications.
2 Background and software attacks
Over the past few decades, one of the most common at-
tack vectors has been exploitation of memory corruption
within programs written in memory-unsafe languages.In
response, operating systems and compilers have started
to support countermeasures against speciﬁc exploitation
vectors and vulnerability types, but current hardening
techniques are still unable to stop all attacks. We brieﬂy
provide an overview of these attacks; more information
may be found elsewhere [37].
2.1 Control-Flow Hijacking
One way to exploit a memory corruption bug involves
hijacking control ﬂow to execute attacker-supplied or
already-existing code in an application’s address space.
These methods leverage the memory corruption bug to
change the target of an indirect branch instruction (ret,
jmp *, or call *). By doing so, an attacker can completely
control the next instructions to execute.
2.2 Code-Reuse Attacks
Data Execution Prevention (DEP) prevents executing
attacker-injected code. However, redirecting control-
ﬂow to already-existing executable code in memory re-
mains feasible. One technique, return-to-libc [25, 36],
reuses existing functions in the address space of the vul-
nerable process. Runtime libraries (such as libc) often
provide powerful functions, e.g., wrapper functions for
most system calls. One example is libc’s system()
function, which allows the attacker to execute shell com-
mands. Code-reuse attacks are possible when attacker-
needed code is already available in the address space of
a vulnerable process.
2.3 Return Oriented Programming
Return Oriented Programming (ROP) [25, 36] is a more
advanced form of code-reuse attack that lets the attacker
perform arbitrary computation solely by reusing existing
code. It relies upon short instruction sequences (called
“gadgets”) that end with an indirect branch instruction.
This allows them to be chained, so the attacker can
perform arbitrary computation by executing a carefully-
chosen sequence of gadgets. ROP can be generalized
to use indirect jump or call instructions instead of re-
turns [4, 7].
2.4 Non-Control-Data Attacks
A non-control-data attack [8] is an attack where a mem-
ory corruption vulnerability is used to corrupt only data,
162  24th USENIX Security Symposium 
USENIX Association
2
but not any code pointer. (A code pointer is a pointer
which refers to the code segment, for example, a re-
turn address or function pointer.) Depending on the
circumstances, these attacks can be as effective as ar-
bitrary code-execution attacks. For instance, corrupt-
ing the parameter to a sensitive function (e.g., libc’s
execve()) may allow an attacker to execute arbitrary
programs. An attacker may also be able to overwrite se-
curity conﬁguration values and disable security checks.
Non-control-data attacks are realistic threats and hard to
defend against, due to the fact that most defense mecha-
nisms focus on the protection of code pointers.
2.5 Control-Flow Bending
We introduce a generalization of non-control-data at-
tacks which we call Control-Flow Bending (CFB). While
non-control-data attacks do not directly modify any
control-ﬂow data (e.g., return addresses, indirect branch
targets), in control-ﬂow bending we allow these modi-
ﬁcations so long as the modiﬁed indirect branch target
is still in the valid set of addresses as deﬁned by the
CFI policy (or any other enforced control-ﬂow or code
pointer integrity protection). CFB allows an attacker to
bend the control-ﬂow of the application (compared to hi-
jacking it) but adheres to an imposed security policy.
We deﬁne a “data-only” attack as a non-control-data
attack where the entire execution trace is identical to
some feasible non-exploit execution trace. (An execution
trace is the ordered sequence of instructions which exe-
cute, and does not include the effects those instructions
have except with respect to control ﬂow.) While data-
only attacks may change the control ﬂow of an applica-
tion, the traces will still look legitimate, as the observed
trace can also occur during valid execution. In contrast,
CFB is more general: it refers to any attack where each
control-ﬂow transfer is within the valid CFG, but the ex-
ecution trace is not necessarily required to match some
valid non-exploit trace.
In general, defense mechanisms implement an abstract
machine and can only observe security violations accord-
ing to the restrictions of that machine, e.g., CFI enforces
that control ﬂow follows a ﬁnite state machine.
For example, an attacker who directly overwrites the
arguments to exec() is performing a data-only attack:
no control ﬂow has been changed. An attacker who over-
writes an is admin ﬂag half-way through processing a
request is performing a non-control-data attack: the data
that was overwritten is non-control-data, but it affects the
control-ﬂow of the program. An attacker who modiﬁes a
function pointer to point to a different (valid) call target
is mounting a CFB attack.
3 Threat model and attacker goals
Threat model. For this paper we assume a powerful
yet realistic threat model. We assume the attacker can
write arbitrarily to memory at one point in time during
the execution of the program. We assume the process
is running with non-executable data and non-writeable
code which is hardware enforced.
This threat model is a realistic generalization of mem-
ory corruption vulnerabilities: the vulnerability typically