1.  # 智能运维背景
    1.  ## 背景
伴随新基建到来，IT数据业务呈指数型增长。业务复杂性的提高，使得不同业务之间衍生出大量的运维需求。
随着软件的规模、调用关系、变更频率的逐渐增大，同时由于持续集成、敏捷开发、DevOps等模块都可能发生变化，随时都可能给运维带来故障。容器、持续交付、软件架构、工程方法不断的演进，也不断给运维工作带来挑战。
现有的运维工作复杂度和强度日渐增大，常规的运维手段已经无法满足日渐庞杂的运维需求，我们需要能够灵活应对现状的新技术。使用AI算法来提升工作效率和质量，实现智能运维（AIOps），已成为运维发展到一定阶段的必然产物。
现在多个行业领域都表现出对智能运维的强烈需求。但是他们主要在各自行业内寻找解决方案。同时受限于所处行业运维团队的开发能力，他们往往对所处行业内的运维团队提出相对较低的需求------这些需求一般停留在自动化运维的阶段。如果各行业领域能够在深入了解智能运维框架中关键技术的基础上，制定合适的智能运维目标，并投入适当的资源，一定能够有效地推动智能运维在各自行业的发展。同时，在智能运维通用技术的基础上，各行业领域的科研工作者也可以在解决所处行业智能运维的一些特殊问题的同时，拓宽自身的科研领域。
在基于机器学习的智能运维框架下，机器将成为运维人员的高效可靠助手。但是，人的作用仍处于主导地位。在智能运维的框架下，运维工程师逐渐转型为大数据工程师，负责搭建大数据基础架构，开发和集成数据采集程序和自动化执行脚本，并高效实现机器学习算法。同时，在面对所处行业的智能运维需求时，智能运维工程师可以在整个智能运维框架下跨行业地寻找关键技术，从而能够更好地满足本行业的智能运维需求，达到事半功倍的效果。这种从普通工程师到大数据工程师（智能运维工程师）的职业技能转型对运维工程师是非常具有吸引力的。
智能运维的基石是机器学习和人工智能。
相比人工智能在其他领域的应用，智能运维几乎完美地拥有一个有前景的人工智能垂直应用领域必备的要素：
实际应用场景、大量数据、大量标注。智能运维几乎所有的关键技术都离不开机器学习算法；工业界不断产生海量运维日志；由于运维人员自身就是领域专家，其日常的工作就会产生大量的标注数据。海量的数据和标注降低了研究机器学习算法的门槛，有益于算法研究快速取得进展。因此，智能运维可以说是机器学习领域一个尚未开采的"金矿"，
非常值得机器学习领域科研人员的关注和投入。
作为人工智能的一个垂直方向，智能运维的理论也将取得长足的进步。除了互联网以外，智能运维在高性能计算、电信、金融、电力网络、物联网、
医疗网络和设备、航空航天、军用设备及网络都有很好的应用。
## 什么是智能运维
根据智能运维的运用水平，目前业界对智能运维划分了五个等级：
![屏幕快照 2019-06-05
下午4.07.10.png](media/image1.png){width="5.582125984251968in"
height="4.117011154855643in"}
对 AIOps 有想法，想要去尝试的人作为一级。
二级和三级是目前想要达到的目的，二级需要达到单点应用，例如公司的监控系统原先固定了阈值，加入算法之后，监控如果能达到AIOps要求的准确，且避免手工劳动这一级别，即可为单点应用。
三级需要达到串联应用，例如目前整个监控系统都能达到比较好的层次，监控作为很大的模块概念，包括判断是否为告警的地方，告警发送给哪些人，发送的信息应该包含哪些关联的东西等，当将
AI 加入到这些场景后，可认为这一串执行都被 AI
化，接着可以将目标转为容量调度，这样的监控可认为达到三级水平。
五级实现自动化有待发展。
智能运维为解决大量杂乱的运维问题而生，越是拥有大量运维机器或设备的企业，对智能运维的需求就越急切。智能运维基于大批量机器数据进行分析，数据是实施AI的主要对象。
为对数据进行有效分析，智能运维要进行大量的数据清洗工作，数据清洗占据了智能运维80%的工作量。真正处理好了以后的分析过程反而占据较少的工作量。日志易智能运维应用Lynxee可直接对日志易平台解析后的日志数据进行分析，借助于日志易上百种不同类型数据的内置采集分析方案，智能运维Lynxee使用成本大幅缩减。
## 日志易AIOps应用场景
具体说到AIOps的场景，可以从成本、质量、效率三大方面做出规划。当然，就目前的阶段，质量还是最关键、性价比最高的、可以首先实现智能化的部分。日志易Lynxee主要关注的也是这个方向。
![智能运维场景@2x.png](media/image2.png){width="5.763888888888889in"
height="3.3444444444444446in"}
在质量保障上，运维人员希望做到的，就是尽早告警，尽快定位，尽快修复。
对应快速发现故障，尽早告警，Lynxee提供了基于多种算法的异常预测。对应问题归因，尽快定位，Lynxee通过日志模式可快速洞察罕见报错信息。对应快速修复，Lynxee可通过多方位展现系统状态辅助修复决策。
此外，日志易还提供了告警归并功能，帮助运维人员应对因告警风暴造成的困然，对告警进行归并或其他处理。
# 产品架构
Lynxee应用是运用人工智能算法，基于日志易自身强大的数据检索平台功能，结合丰富的IT运维知识，打造的帮助用户主动发现和排查平常难以发现的问题的智能运维系统。
## 原理介绍
与尽早告警、尽快定位、尽快修复相对应，日志易智能运维Lynxee的主要使用场景分为KPI指标异常检测、日志模式异常检测和基于多KPI指标的服务健康度异常检测三类。
![](media/image3.png){width="5.768055555555556in"
height="2.5737707786526682in"}
### 指标异常检测
以尽快告警为例。告警的本质，是告诉运维人员两件事情：第一，有问题了；第二，问题有多严重。
一般而言，监控系统会有两种告警，一种是匹配关键字，一种是采样指标的阈值对比。匹配关键字的严重性呢，就是warning、critical；阈值的严重性呢，就是定义多个阈值区间，比如CPU大于80%发中危，大于120%发高危。
在日志中心里，显然这两种方式都存在。从日志直接产生告警，或者经过统计分析变成时序指标（KPI指标异常检测），再监控告警。
指标告警的原理从很多个地方可以得以体现。如《SRE：谷歌运维解密》中提出的黄金指标：
-   延迟lantency：IO await、response_time
-   流量traffic：CPU util%、MEM used、QPS
-   错误error：packet loss、4xx、5xx
-   饱和度saturation：OOM、queue_size、API rate_limit
不管是主机设备层面、还是应用服务层面，或者集群，端到端等等，都可以从这四个最关键的角度，来衡量它的健康状态。
### 服务健康度异常检测
通过告警的优先级和重要程度，拟合出来一个服务的健康度，让用户对系统状态一目了然，即服务健康度异常检测。
Lynxee
会为每个服务都会生成一个健康度分值，并持续的监控和更新这个分值，帮助你快速了解服务的运行状态。
服务健康度由归属服务的监控项(监控项详细介绍见稍后章节)、以及所依赖的服务的健康度分值共同计算得出。计算公式为:
![](media/image4.png){width="2.473652668416448in"
height="0.5668788276465442in"}
公式中的变量解释如下:
-   N = 监控项数量
-   G = 单个监控项的权重值
-   K = 单个监控项当前的危急程度(设定:正常=100, 低危=70, 中危=30,
    高危=0)
默认的，所依赖服务的健康度分值拥有最高级别的权重，而普通监控项拥有中间级别的权重。为了辅助理解，Lynxee
界面提供了健康度分值模拟器。你可以在服务编辑页面上，通过模拟监控项的危急程度和权重设置，来预览最终计算所得的服务健康度分值。比如，你如果模拟一个服务的监控项危急程度和权重如下所示:
![page7image17805504](media/image5.png){width="5.768055555555556in"
height="1.7986111111111112in"}
分值的计算过程如下:
服务健康度 = 100∗10/(10+7+5) + 70∗7/(10+7+5) + 30∗5/(10+7+5) = 74.55
至于单个健康项的权重确定需要结合实际情况，判断指标项对于服务的影响程度来决定。我们可以根据该项指标是会直接影响服务的正常运行，间接影响或者可能会影响等不同程度来设定指标的权重。
### 日志模式异常检测
除了指标的异常，还有就是日志的异常。
我们知道，最常见的日志告警就是关键字匹配。不过我们还知道，大多数系统的研发，不会把日志写的那么完美。
2016年，中科院《软件学报》发过一篇国防科大的《大规模软件系统日志研究综述》，里面引用了不少国内外的调查分析。其中有几条数据蛮有趣的：
-   日志代码的更新频率比其他代码要快约 1 倍；
-   约四分之一的日志修改是把新的程序变量写入日志；
-   约一半的日志修改是对日志消息静态文本的修改；
-   这些研究一般都是基于大型分布式离开源项目，比如Hadoop啊，openstack啊。企业内部的系统开发，应该情况会比这些著名的项目要严重的多。
大家输出日志的时候，很难做到完美规范。日志格式经常在变动。
数据量多而复杂，依赖关键字或者固定的某种正则表达式提取，在长期运行的场景下，是不足以做到日志异常检测。也需要AI算法来帮忙。
日志模式异常检测的思路是采用层次聚类。
先进行最基础的分词和类型判断，然后聚类合并。聚类可以用最长子串，也可以用文本频率等等。聚类里，不同的部分就用通配符替换掉。
![](media/image6.png){width="5.721311242344707in"
height="2.5694444444444446in"}
上图把8条日志，先合并成4个日志格式，再合并成2个，最后合并成1个，这就是一个树。在研究领域，我们一般把这种日志格式的树状结构，叫模式树。
当然我们实践的时候，不用真的收敛到最顶端，一般来说，模式数量收敛速度差不多了，或者模式里的通配符数量差不多了，就可以停下来了。日志易通过用户体验方面的调研发现，一般通配符数量占据模式分词数量的15%以上，就能满足很多用户的需求。
得到日志模式后，一般有两种用法。
一种是故障定位的时候。比如查错误日志，单纯用关键词可能出来几百上千条。查找起来耗时长，如果内容字很多，还可能看漏了。使用日志模式异常检测，直接查看匹配关键字的日志的模式情况，可能就只有那么三五条信息，一眼就可以看，很快就可以知道问题在哪。
另一个用途是把学习得到的模式，加载到日志采集的实时处理流程里，进行异常检测，提前发现问题。这时候除了模式，还可以检测参数、占比等。
![](media/image7.png){width="5.768055555555556in" height="2.21875in"}
上图左侧是一个最简单的示例，3条日志，得到的模式是\* are
\，然后我们同时可以检测符合这个模式的日志，第一位只能是we或you，第三位只能是平均值93.3，标准差9.4的正态分布区间内。
然后日志采集进来，先检测一下这个模式是不是合法的。如果合法，再检测一下各个参数位置的取值是不是合法的。如果依然合法，再检测一下这段时间这个模式的日志数量，和之前相比，是不是正常的。
这么三层检测下来，相当于把模式异常、数值异常、时序指标异常融合到了一起。
![](media/image8.png){width="5.768055555555556in"
height="2.509027777777778in"}
这张截图就是日志异常检测的一个历史列表。可以看到，哪怕在INFO级别，也是可能出现你从来没见过的古怪日志的。这就需要密切关注了。
当然，因为日志量特别大，所以训练样本很容易错过一些正常情况，所以上线初期，我们需要一些迭代、标注的优化过程。把初始样本不断丰富起来。
### 告警归并
随着网络的发展，大数据时代的到来，运维工程师经常被告警风暴困扰，告警风暴的形成主要有这几个原因：
-   告警重复度高，告警策略执行周期计算，会持续产生重复报警。
-   告警关注度不足，尤其是夜间告警的关注率低至25%。
-   告警接收人冗余，报警策略的接收人往往会填写了运维团队中的所有人，但实际值班人只有一个人，大家按周期轮转。因此，对于一个特定的报警，大部分同学是不需要即时关注的。
-   告警时效性不足，40%以上告警只需要简单的处理即可恢复，比如磁盘打满或者内存泄露等。
日志易告警归并功能支持不同策略过滤使用，支持多种归并分组条件，并可根据不同条件，触发自愈操作，升级二线责任人，或进行高危通知等。
由于告警归并的内容在高级教材监控告警章节已有详细介绍，此处不再进行额外说明。
## Lynxee架构
Lynxee依托日志易智能日志分析平台强大的数据处理能力，组合多种深度学习及监督异常检测算法，对周期性、离散性、周期突变性各类型指标进行分析。无需人工干预，Lynxee即能根据指标周期性规律自动选择最佳算法和参数进行自动异常检测，极大减少运维配置工作量，解决了大量故障阀值漏报和动态基线误报问题。
根据现有日志平台提供的数据，Lynxee可以主动学习识别发现异常情况。结合现有仪表盘、告警等功能模块，实现深度数据加工分析。通过不断增多的日志数据进行分析，结合历史数据纠正，可以不断提高异常发现、异常定位、根因分析等能力，最终提高异常预测准确性。
Lynxee获取到的异常信息目前存放在Influxdb中，通过采集Influxdb中相关数据作为机器学习的结果数据，可实现异常信息的展示告警、报告等。
作为以日志易为主的数据引擎系统的一部分，
Lynexx机器学习引擎在企业系统中的相关架构如图所示：
![](media/image9.png){width="5.768055555555556in"
height="3.3152777777777778in"}
日志易日志分析系统中，与Lynxee相关的产品模块有：
-   Kpi_analyze：算法服务模块。目前支持的算法有MovingAverage（移动平均）、CVAE（变粉自编码器）、KDE（核密度）以及isolationForest（孤立森林）；
-   Kpi_monitor:
    监控和管理的模块，从Kafka读取数据写入influxdb，从influxdb读数据提供给算法模块；