490(cid:179)
1, (cid:126)Y (cid:48)
u, (cid:126)Y (cid:48)
π(i))}u(cid:48)
1 , . . . , (cid:126)Y (cid:48)
we show security against a malicious P2 in a hybrid model
where the parties have access to ideal functionalities com-
puting Fks and the parallel OT functionality. We prove
security by brieﬂy describing a simulator that is given ac-
cess to an ideal functionality computing Fg,h. (By standard
composition theorems, this implies security of πtxt.)
Let (S1,S2) be the simulators guaranteed for the Yao gar-
bled circuit construction. Our simulator begins by running
u independent copies of S1(1k, H) to obtain ( (cid:126)X(cid:48)
1 , s1),
u, su) (note that here each (cid:126)X(cid:48), (cid:126)Y (cid:48) is a k-tuple of
. . ., ( (cid:126)X(cid:48)
strings, cf. Section 2.1). The simulator then extracts from
P2 its input y to the parallel OT functionality, and provides
to P2 in return the vectors (cid:126)Y (cid:48)
u. Next, the simulator
extracts from P2 its input p to the Fks functionality. The
simulator sends (p, y) to the ideal functionality computing
Fg,h and receives in return a set {zi}u(cid:48)
i=1 (where 0 ≤ u(cid:48) ≤ u).
The simulator then chooses a random permutation π of
(cid:180)
{1, . . . , u} and gives to P2 the values {(π(i), (cid:126)X(cid:48)
i=1 as the
output from the invocation of Fks. To complete the simula-
tion, the simulator computes gHπ(i) ← S2
(p, y), zi, sπ(i)
for i = 1 to u(cid:48), and gHπ(i) ← S2(p, y,⊥, sπ(i)) for i = u(cid:48) + 1
to u. It then sends gH1, . . . , gHu as the ﬁnal message to P2.
We omit the proof that this generates a view for P2 that is
computationally indistinguishable from the view of P2 when
running πtxt in the speciﬁed hybrid model.
4.3 Efﬁciency
The most notable feature of our protocol is that it uses
only u garbled circuits, rather than O(|T|) garbled circuits
as in a naive application of Yao’s methodology. To see the
resulting improvement, let us focus on the communication
complexity (though a similar calculation applies to the com-
putational complexity also) and concentrate on terms that
depend on |T| — a reasonable choice if we assume |T| domi-
nates all other parameters. Any “naive” application of Yao’s
approach to computing the functionality in Equation (2) will
involve garbling a circuit containing (among other things)
|T| copies of H. The communication required for transmit-
ting the resulting garbled circuit is thus lower bounded by
(roughly) 4k|T||H| bits. In our protocol, on the other hand,
the only dependence on |T| is in the sub-protocol for key-
word search. Looking at the keyword-search protocol from
Section 3 (and ignoring the OPRF sub-protocol there, whose
complexity is independent of |T|), we see that the commu-
nication complexity used by that protocol will be (roughly)
|T|· (k |gout| + k) bits, where |gout| denotes the output length
of the function g.
5. APPLICATIONS AND EXTENSIONS
In Section 4 we have described a protocol πtxt for secure
text processing. In this section we describe some extensions
and potential applications of that protocol.
Let us return to the functionality considered in the Intro-
duction (cf. Equation (1)). That function can “almost” be
viewed as an instance of the class of functions Fg,h described
in the previous section if we set g(T, i) def= (cid:96)max(T, Ti) and
(cid:48)
h((cid:96)
, (, (cid:96))) =
1 |(cid:96)(cid:48) − (cid:96)| ≤ 
0 otherwise
.
(3)
(cid:189)
the resulting protocol is ineﬃcient since P2 (possibly) gets
the same answer u times rather than just once; second, it
is insecure since it reveals how many times p occurs as a
substring in T (whereas the functionality as described in
Equation (1) does not reveal this information).
Nevertheless, we can address both these issues with a pro-
tocol constructed using the same general paradigm employed
in the previous section. Speciﬁcally, we now have P1 con-
struct only a single garbled circuit gH for H (reﬂecting the
fact that a single evaluation of h is suﬃcient for comput-
ing the desired functionality). We need P2 to evaluate this
circuit on P2’s inputs , (cid:96) as well as the value (cid:96)(cid:48) = g(T, p).
Once again, the problem reduces to ﬁnding a way for P2 to
learn all the appropriate input-wire labels.
As before, it is easy for P2 to learn the labels of the wires
corresponding to its own inputs , (cid:96) using oblivious transfer.
To enable P2 to learn the appropriate input-wire labels, we
use keyword search: P1 prepares a “database” of entries of
the form (p∗, g(T, p∗)), and P1 learns only g(T, p). An ad-
ditional subtlety here is that we need to prevent P2 from
learning how many times the pattern p appears in T ; this
can be handled by “padding” the database using entries with
random keys. See Figure 4.
In Figure 4, P1 “pads” the database D so that it always
contains exactly t = n − m + 1 entries; this prevents P2
from learning how many distinct patterns occur as sub-
strings of T . An alternative approach, which may be more
eﬃcient depending on the relative sizes of |T| and |Σ|m, is
described next. First, both parties re-deﬁne h as:
h(b|(cid:96)
(cid:48)
, (, (cid:96))) =
.
Then for each pattern p ∈ Σm, party P1 does:
|(cid:96)(cid:48) − (cid:96)| ≤ 
b
0 otherwise
(cid:189)
(cid:180)
(cid:180)
(cid:179)
(cid:179)
• If p occurs as a substring in T , then add the tuple
p, (cid:126)X(1|(cid:96)max(T, p))
to D.
• If p does not occur as a substring in T , then add the
tuple
p, (cid:126)X(0|0|(cid:96)max|)
to D.
Now the database always has exactly |Σ|m entries.
On another note, we remark that the protocol in Figure 4
returns ⊥ to P2 in case its pattern p does not occur as a
substring of T . This is avoided when using the technique
described in the previous paragraph (and can be avoided in
the protocol from Figure 4 via similar techniques).
6. REFERENCES
[1] W. Aiello, Y. Ishai, and O. Reingold. Priced oblivious
transfer: How to sell digital goods. In Advances in
Cryptology — Eurocrypt 2001, volume 2045 of LNCS,
pages 119–135. Springer, 2001.
[2] M. Atallah, F. Kerschbaum, and W. Du. Secure and
private sequence comparisons. In Proc. ACM
Workshop on Privacy in the Electronic Society
(WPES), pages 39–44. ACM, 2003.
[3] E. De Cristofaro and G. Tsudik. Practical private set
intersection protocols with linear complexity. In
Financial Cryptography and Data Security 2010.
Available at http://eprint.iacr.org/2009/491.
Two problems arise in formulating the problem this way
and applying the protocol from the previous section: ﬁrst,
[4] M. J. Freedman, Y. Ishai, B. Pinkas, and O. Reingold.
Keyword search and oblivious pseudorandom
491Input to P1: A text T ∈ Σn.
Input to P2: A pattern p ∈ Σm (m < n) and parameters , (cid:96).
Common input: The input lengths n, m.
Output: P2 learns M (T, p, , (cid:96)) (see Equation (1)).
Let h be as in Equation (3), and let H be a circuit computing h. Let t = n− m + 1.
The parties do:
1. P1 runs Garble(1k, H) to obtain (gH, (cid:126)X, (cid:126)Y ).
2. P1 and P2 execute (parallel) instances of OT to enable P2 to learn the
input-wire labels (cid:126)Y (cid:48) corresponding to its inputs , (cid:96).
3. P1 deﬁnes a database D as follows.
(a) For each p ∈ Σm that is a substring of T , add
(cid:179)
(cid:180)
p|0k, (cid:126)X((cid:96)max(T, p))
to D. (We assume (cid:96)max is always a ﬁxed number of bits.)
(b) Let d denote the number of elements in D. Then add an additional
t − d elements to D of the form (p∗r, (cid:126)X(0|(cid:96)max|)), where r ← {0, 1}k
and p∗ ∈ Σm is arbitrary.
4. P1 and P2 compute Fks on D and p|0k, respectively. As a result, P2 obtains
(cid:126)X(cid:48) or nothing. (In the latter case, P2 outputs ⊥. See text for discussion.)
(cid:179)
(cid:180)
5. P1 sends gH to P2.
6. P2 outputs Eval
gH, (cid:126)X(cid:48), (cid:126)Y (cid:48)
.
Figure 4: Computing the functionality of Equation (1).
functions. In 2nd Theory of Cryptography Conference,
volume 3378 of LNCS, pages 303–324. Springer, 2005.
transfer. In Cryptographers’ Track — RSA 2008,
volume 4964 of LNCS, pages 52–70. Springer, 2008.
[5] K. Frikken. Practical private DNA string searching
and matching through eﬃcient oblivious automata
evaluation. In Data and Applications Security, volume
5645 of LNCS, pages 81–94. Springer, 2009.
[6] R. Gennaro, C. Hazay, and J. S. Sorensen. Text search
protocols with simulation based security. In 13th Intl.
Conference on Theory and Practice of Public Key
Cryptography (PKC 2010), volume 6056 of LNCS,
pages 332–350. Springer, 2010.
[7] O. Goldreich. Foundations of Cryptography, vol. 2:
Basic Applications. Cambridge University Press,
Cambridge, UK, 2004.
[8] O. Goldreich, S. Micali, and A. Wigderson. How to
play any mental game, or a completeness theorem for
protocols with honest majority. In 19th Annual ACM
Symposium on Theory of Computing (STOC), pages
218–229. ACM Press, 1987.
[9] C. Hazay and Y. Lindell. Eﬃcient protocols for set
intersection and pattern matching with security
against malicious and covert adversaries. In 5th
Theory of Cryptography Conference — TCC 2008,
volume 4948 of LNCS, pages 155–175. Springer, 2008.
[10] S. Jarecki and V. Shmatikov. Eﬃcient two-party
secure computation on committed inputs. In Advances
in Cryptology — Eurocrypt 2007, volume 4515 of
LNCS, pages 97–114. Springer, 2007.
[11] S. Jha, L. Kruger, and V. Shmatikov. Towards
practical privacy for genomic computation. In IEEE
Symp. Security & Privacy, pages 216–230. IEEE, 2008.
[12] L. Kissner and D. X. Song. Privacy-preserving set
operations. In Advances in Cryptology — Crypto 2005,
volume 3621 of LNCS, pages 241–257. Springer, 2005.
[13] A. Lindell. Eﬃcient fully-simulatable oblivious
[14] Y. Lindell and B. Pinkas. An eﬃcient protocol for
secure two-party computation in the presence of
malicious adversaries. In Advances in Cryptology —
Eurocrypt 2007, volume 4515 of LNCS, pages 52–78.
Springer, 2007.
[15] Y. Lindell, B. Pinkas, and N. Smart. Implementing
two-party computation eﬃciently with security against
malicious adversaries. In 6th Intl. Conf. on Security
and Cryptography for Networks (SCN ’08), volume
5229 of LNCS, pages 2–20. Springer, 2008.
[16] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay
— a secure two-party computation system. In Proc.
13th USENIX Security Symposium, pages 287–302.
USENIX Association, 2004.
[17] M. Naor and B. Pinkas. Computationally secure
oblivious transfer. J. Cryptology, 18(1):1–35, 2005.
[18] A. Paus, A.-R. Sadeghi, and T. Schneider. Practical
secure evaluation of semi-private functions. In Conf.
on Applied Cryptography and Network Security,
volume 5536 of LNCS, pages 89–106. Springer, 2009.
[19] B. Pinkas, T. Schneider, N. Smart, and S. Williams.
Secure two-party computation is practical. In
Advances in Cryptology — Asiacrypt 2009, volume
5912 of LNCS, pages 250–267. Springer, 2009.
[20] J. R. Troncoso-Pastoriza, S. Katzenbeisser, and
M. Celik. Privacy preserving error resilient DNA
searching through oblivious automata. In 14th ACM
Conf. on Computer and Communications
Security (CCCS), pages 519–528. ACM Press, 2007.
[21] A. C.-C. Yao. How to generate and exchange secrets.
In 27th Annual Symp. on Foundations of Computer
Science (FOCS), pages 162–167. IEEE, 1986.
492