Gbps, but as the number of queues increases, the overall throughput
increases, achieving the line-rate starting from eight queues.
This required number of queues to achieve 10 Gbps can be proved
arithmetically. We have implemented Reinhardt to process a packet
in chunks of 256-bit (32 characters), resulting in the delay of 32
clocks per chunk, and this delay is always constant regardless of
the Reinhardt core size. Since the clock rate of NetFPGA-SUME is
160 MHz, 1 clock takes 6.25 ns, i.e., the delay of 32 clocks takes 200
ns. For processing 256-bit chunks at 10 Gbps speed, each chunk
must be processed within 25.6 ns. As a result, the required number
of queues can be calculated through 200/25.6 = 7.81, i.e., 8.
Theoretically, the processing time of Reinhardt takes 32 clocks of
delay, so there should be more latency in Reinhardt compared to NIC
connections. However, Figure 8b shows that latencies of Reinhardt
are in very close proximity to the latency of the NIC connections
regardless of the number of queues because the latency increase is
a negligible amount in the unit of nanoseconds, whereas the unit
of latency in the figure is microseconds. By using Reinhardt, packet
transmission can be guaranteed with a latency of 60 µs, regardless
of the number of queues.
Performance degradations by resubmitting: We measure
the throughput and latency variations of Reinhardt to see the de-
gree of performance degradations under the different number of
resubmissions. For this, we configure Reinhardt with eight queues.
As shown in Figure 9a, the throughputs with up to 4 times submis-
sions are steady. However, as the number of submissions increases,
20% of throughput degradations occur every resubmission. Latency
is slightly different, but most of them fall within the error range
of measurement and are still under 60 µs because there is a delay
of only about 200 ns per round, so even if 4 resubmits occur, the
delay is less than 1 µs. As the number of submissions increases, the
delay gradually accumulates; 32 resubmissions increase the overall
latency by about 6-8 µs.
These results are because the dynamic configurability can utilize
potential resources in FPGA; NetFPGA-SUME processes a packet
with 256-bit chunks per clock, but it takes 25.6 ns to get a 256-bit
chunk at the 10 Gbps speed, which is about 4 clocks at 160 MHz.
Thus, the chunks of incoming packets are processed every 4 clocks
and make the gap of 3 clocks during queue entry. This gap is utilized
for the chunks of resubmitted packets, so the submissions up to 4
times will not suffer throughput degradation.
5.2 Regex Pattern Deployment
Pattern capacity: Pattern capacity means how many regex pat-
terns Reinhardt can accommodate at once without performance
loss. However, it is difficult to make universal claims since Rein-
hardt aims at the dynamic configuration for various regex patterns
rather than fixed regex patterns, and the complexity of the patterns
varies the number of patterns. Thus, we randomly select regex pat-
terns among the regex set used to determine the core constraints
in §4 until the core becomes full, including the four resubmitting.
The experiment was repeated 100 times; Figure 10 describes the
number of deployed regex patterns for the different core sizes into
a candlestick graph of the body as the range of standard deviations
Metacharacter (ea)081624324048CDF0.20.40.60.80.91 Snort2.9.7Snort-COMM2.9Snort-COMM3Suricata4.1.2Metacharacter (ea)081624324048CDF0.20.40.60.80.91 Snort2.9.7Snort-COMM2.9Snort-COMM3Suricata4.1.2Metacharacter (ea)081624324048CDF0.20.40.60.80.91 Snort2.9.7Snort-COMM2.9Snort-COMM3Suricata4.1.2Metacharacter (ea)081624324048CDF0.20.40.60.80.91 Snort2.9.7Snort-COMM2.9Snort-COMM3Suricata4.1.2String Length48912162024CDF0.20.40.60.80.91 Snort2.9.7Snort-COMM2.9Snort-COMM3Suricata4.1.2String Length48912162024CDF0.20.40.60.80.91 Snort2.9.7Snort-COMM2.9Snort-COMM3Suricata4.1.2Metacharacter (ea)081624324048CDF0.20.40.60.80.91 Snort2.9.7Snort-COMM2.9Snort-COMM3Suricata4.1.2Metacharacter (ea)081624324048CDF0.20.40.60.80.91 Snort2.9.7Snort-COMM2.9Snort-COMM3Suricata4.1.2Packet size (bytes)64 25651210241514Throughput (Gbps)246810Packet size (bytes)6412825651210241514Throughput (Gbps)24681011NICQ1Q2Q4Q7Q8Q12128Latency (usec)4550556065CDF0.20.40.60.81 NICQ1Q2Q4Q7Q8Q12Packet size (bytes)6425651210241514Throughput (Gbps)246810NICS1S2S4S5S6S8128Latency (usec)4550556065CDF0.20.40.60.81 NICS1S2S4S5S6S8S32626ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Taejune Park, Jaehyun Nam, Seung Ho Na, Jaewoong Chung, and Seungwon Shin
(1) Snort 2.9.7 default (648 ea)
(3) Snort 3.0 community (524 ea)
(2) Snort 2.9 community (645 ea)
(4) Suricata 4.1 default (918 ea)
(5) Aggregated patterns to check maximum capacity
⋆ Core size: Width × Height × Queues, Submission 4 times
Figure 10: Pattern capacities with the different core sizes
# of the cells
# of patterns
Time (sec)
15,360
28,800
63,840
151,680
≤ 160
≤ 295
≤ 590
≤ 1313
0.116
0.186
0.403
0.965
Core size w×h×n
24×160×8
24× 300×4
24×665×2
24×1580×1
⋆ The number of the cells to configure considers four submissions
∗ The number of patterns is referenced in Figure 10
Table 3: Reinhardt cell configuration time
around the average and its shadow as a min-max. The number of
deployed patterns increases 160-1313 as the core size increases.
Pattern configuration time: One of the key contributions in
Reinhardt is the dynamic reconfigurability without service inter-
ruption. To show its agility, we measure the pattern configuration
times with the different core sizes. The configuration assumes that a
host software configures all cells in the core, including resubmitting
4 times (i.e., worst-case); Table 3 shows the number of cells being
configured and their configuration times. While these times are
measured under the worst cases, all configurations are completed
within a second. With the consideration of the number of deploy-
able regex patterns shown in Table 10, the configuration time takes
116 ms for 160 patterns and 965 ms for 798 patterns, which is much
faster than the configuration times in existing FPGA-based REM
described in Table 1. The configuration in Reinhardt is mostly spent
in communication between the datapath and software. The update
is instantly performed at the device.
Update response time in NIDS/IPS: To validate how effec-
tively Reinhardt addressed the challenge of FPGA-based DPI, we
back to our motivating example of Figure 2 in §2.3 and perform the
same evaluation with Reinhardt. Figure 11 shows its result. As in-
stalling the new pattern to inspect and filter Flow B, the new pattern
works instantly while the device is up and running as ever. Hence,
unlike the motivating example, Flow A is delivered continuously,
but only Flow B is dropped immediately after updating.
5.3 Comparison with DPDK-Hyperscan
Intel DPDK-Hyperscan [35, 78] is one of the best-of-breed baselines
for fast regex processing running with a multi-core CPU. Here, we
analyze the advantages and disadvantages of Reinhardt through
comparison with DPDK-Hyperscan. We implement a simple DPDK-
Hyperscan application using the Hyperscan open-source [34] and
DpdkBridge [58] that receives packets from network interfaces and
Figure 11: Update response time of the Simple IPS with Rein-
hardt (See with Figure 2 in §2.3)
(a) Simple patterns
(b) Complex patterns
⋆ The core size of Reinhardt is 24×160×8 // H.S.n means Hyperscan with n cores
∗ Simple and complex patterns contain 1.6 and 7.6 metacharacters on average.
Figure 12: Throughput for 100 patterns (vs Hyperscan)
Figure 13: Throughput
for 843 patterns
(vs Hyperscan)
⋆ The core size of Reinhardt is 24×160×8
Figure 14: Latency (RTT)
for 100 and 843 patterns
(vs Hyperscan)
matches them to target patterns. It also runs on Intel Xeon E5-2630
(10 cores, Hyper-Threading disabled), 64 GB of RAM and Intel X520
10GbE NICs. The target patterns used 843 compatible to Reinhardt
of 847 pcres from Intel’s sample data [36].
Throughput in capacity: To compare performance within the
Reinhardt capacity, we randomly select 100 regex patterns among
the 843 patterns into simple and complex cases respectively and
measure processing throughputs with Reinhardt 24×160×8 and
DPDK-Hyperscan, respectively. We repeat 20 times, and Figure 12
shows its average values; Reinhardt constantly achieves 10 Gbps
regardless of complexity, while DPDK-Hyperscan not only shows
performance degradation according to packet size and pattern com-
plexity. Four cores for simple patterns and eight for complex pat-
terns are required to extract the maximum performance with DPDK-
Hyperscan, but performance degradation is still observed in the
cases of 64-256 bytes packets, and overall throughput is up to 9.3
Gbps, slightly below the line rate (i.e., 10 Gbps).
300450600750900(A)(B)(C)(D)(A)(B)(C)(D)58459046550146931735859158846979810001100120013001400(E)(1)    (2)    (3)   (4)(1)   (2)    (3)    (4)    (5)24 x 665 x 2(2.7 Gbps)24 x 1580 x 1(1.4 Gbps)131311961400  1300  1200  1100  1000300   450   600   750   9000100200300400(A)(B)(C)(D)(A)(B)(C)(D)(1)    (2)    (3)   (4)(1)    (2)    (3)   (4)24x160x8(10 Gbps)24 x 300 x 4(5.6 Gbps)160126102137114143691002452952022432202601381720   100     200   300   400Number of Rules (ea)Pattern capacity by Reinhardt core size012345678910012345678910Delivered rate10Try pattern update012345678910012345678910Traﬃc ATraﬃc BDrop by the patternTime (sec)Packet size (bytes)64 25651210241514Throughput (Gbps)246810Rein.H.S.1H.S.2H.S.4H.S.8128Packet size (bytes)64 25651210241514Throughput (Gbps)246810Rein.H.S.1H.S.2H.S.4H.S.8128Packet size (bytes)64 25651210241514Throughput (Gbps)24681011Rein.H.S.1H.S.2H.S.4H.S.864 25651210241514245H.S.1H.S.2H.S.4H.S.864 2565121024151424524x160x824x300x424x665x224x1580x164 25651210241514Throughput (Gbps)24681011(a) Reinhardt(b) DPDK-Hyperscan128Latency (usec)5060708090100CDF0.20.40.60.81 Rein.100SRein.100CRein.843H.S.100SH.S.100CH.S.843627Reinhardt: Real-time Reconfigurable Hardware Architecture for Regular Expression Matching in DPI
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Throughput in excess of capacity: To measure performance
on a larger pattern set, we deploy all 843 patterns into each different
size of Reinhardt, taking into account the excess of the number of
resubmissions ensuring maximum speed (i.e., 4 times); Each core
24×160×8, 24×300×4, 24×665×2 and 24×1580×1 can accommodate
all patterns by taking total 19, 10, 5 and 2 submission rounds re-
spectively. Figure 13 presents their throughput averages for 20
iterations; Reinhardt with the core sizes 24×160×8 and 24×300×4
suffers significant performance degradation from 10 / 5.6 Gbps to
0.37 / 1.5 Gbps respectively due to processing delay from too many
resubmissions. On the other hand, since the core 24×665×2 and
24×1580×1 can handle all patterns within the capacity or with only
one more submission, they almost preserve the original through-
put. While Reinhardt shows the similar performance of Hyperscan
with 1-4 cores, Hyperscan can perform well with more cores (e.g.,
Hyperscan approaches 4.5 Gbps with 8 cores).
Latency: We compare the latencies of Reinhardt and the DPDK
version of Hyperscan while handling 100 simple/complex patterns
and 843 patterns. As seen in Figure 14, the latency of Reinhardt is
almost similar regardless of the complexity and number of patterns
because the overhead by 19 resubmissions is arithmetically only
about 4 us in Reinhardt, it is reasonable to arrive at similar results
within an error bound of measurement. In DPDK-Hyperscan, its
latency is slower to 50% as the complexity and number of patterns
increase, and the variation (i.e., jitter) becomes wide.
Discussion: This evaluation shows that Reinhardt guarantees
line-rate throughput within the capacity, and if overloaded, there is
a decrease but still provides stable throughput and latency regard-
less of the packet size or patterns. DPDK-Hyperscan also achieves
outstanding throughput, moreover, obtains better than Reinhardt
when processing a large number of regex as utilizing many CPU
cores. However, its throughput and latency are fairly affected by
regex complexity and the packet size.
Furthermore, while DPDK-Hyperscan should consume lots of
host resources, the matching process of Reinhardt runs standalone
on hardware. Hence, we expect that the rest of the resources can
be leveraged to facilitate extra services to reduce operating costs as
Microsoft’s AccelNet suggested [23].
6 CASE STUDY: NIDS AND SNORT
ACCELERATION
To understand how real-world networks benefit from Reinhardt,
we implement two security systems applying Reinhardt; NIDS/IPS
and PCRE replacement in Snort IDS.
6.1 NIDS/IPS using Reinhardt
Experiment setup: Figure 15 shows the extensions for Reinhardt
as NIDS/IPS. Signatures are parsed into headers in the 5-tuple
lookup table and corresponding patterns (i.e., the “content” and
the “pcre”) are converted to Reinhardt logics in the memory. Here,
header and pattern pairs are placed in the same memory ID to
consider resubmitting, and the IDs of the corresponding area are
assigned to each header. When packets arrive, Reinhardt fetches the
matching logic from the memory to the Reinhardt core, and the core