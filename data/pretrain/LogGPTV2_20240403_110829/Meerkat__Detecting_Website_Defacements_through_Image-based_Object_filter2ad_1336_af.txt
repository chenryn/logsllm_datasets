similar if the root mean squared deviation between the
images’ histograms is below some manually-determined
threshold. Clearly, a defacement system based on this
technique is not suitable in an adversarial context: an
attacker can (and eventually will) simply change the colors
slightly or add dynamic content, so that the root mean
squared deviation is above the threshold, but remains
visually the same to the human eye. Furthermore, exactly
as for Nappa et al. [66], one needs to pair-wise compare
the histogram of the screenshot one wants to classify to
some or all of the already-seen defacements.11
MEERKAT does not suffer from these shortcomings: ﬁrst,
it learns high-level features on the defacements’ general
look and feel to detect also previously unseen defacements,
and, second, its classiﬁcation time is constant in the number
of already-seen defacements.
7 Conclusions
In this paper, we introduced MEERKAT, a monitoring
system to detect website defacements, which utilizes a novel
approach based on the look and feel of a website to identify
if the website has been defaced. To accurately identify
website defacements, MEERKAT leverages recent advances
in machine learning, like stacked autoencoders and deep
neural networks, and combines them with computer vision
techniques. Different from prior work, MEERKAT does not
rely on additional information supplied by the website’s op-
erator, or on manually-engineered features based on domain
knowledge acquired a priori, such as how defacements look.
Instead, MEERKAT automatically learns high-level features
from data directly. By deciding if a website has been defaced
based on a region of the screenshot of the website instead
of the whole screenshot, the system is robust to the normal
evolution of websites and defacements and can be used at
scale. Additionally, to prevent the evasion of the system
through changes to the look and feel of defacements and to
be robust against defacement variants, MEERKAT employs
various techniques, such as dropout and ﬁne-tuning.
We showed the practicality of MEERKAT on the largest
website defacement dataset to date, spanning 10,053,772
defacements observed between January 1998 and May
2014, and 2,554,905 legitimate websites. On this dataset,
the system accurately detects
in different scenarios,
11Detection time increases with each observed defacement; it is at best
in O(logn) and at worst in O(n), with n being all observed defacements.
defacements with a true positive rate between 97.422%
and 98.816%, a false positive rate between 0.547% and
1.528%, and a Bayesian detection rate between 98.583%
and 99.845%, thus signiﬁcantly outperforming existing
state-of-the-art approaches.
8 Acknowledgments
We want to express our gratitude toward the reviewers for
their helpful feedback, valuable comments and suggestions
to improve the quality of the paper.
This work was supported by the Ofﬁce of Naval Research
(ONR) under grant N00014-12-1-0165, the Army Research
Ofﬁce (ARO) under grant W911NF-09-1-0553, the Depart-
ment of Homeland Security (DHS) under grant 2009-ST-
061-CI0001, the National Science Foundation (NSF) under
grant CNS-1408632, Lastline Inc., and SBA Research.
References
[1] G. Davanzo, E. Medvet, and A. Bartoli, “A Comparative Study of
Anomaly Detection Techniques in Web Site Defacement Detec-
tion”, in Proceedings of the IFIP 20th World Computer Congress,
Springer, 2008.
[2] Anonymous, Reference blinded for double-blind review process,
Nov. 2014. [Online]. Available: http://anonymized.
[3] Wall Street Journal (WSJ), Malaysia Airlines Website Hacked by
Group Calling Itself ‘Cyber Caliphate’, Jan. 26, 2015. [Online].
Available: http://goo.gl/RhO2tO.
[4] British Broadcasting Company (BBC), Keighley Cougars website
hacked to read ’I love you Isis’, Nov. 2014. [Online]. Available:
http://goo.gl/bzxJ8M.
[6]
[5] R. Preatoni, M. Almeida, K. Fernandez, and other unknown au-
thors, Zone-H.org - Unrestricted Information, since January 1998.
[Online]. Available: http://zone-h.org/.
E. Kovacs, Softpedia Interview: Alberto Redi, Head of Zone-H,
Jun. 8, 2013. [Online]. Available: http://goo.gl/cwPBrW.
[7] Malaysian Computer Emergency Response Team, MyCERT In-
cident Statistics, Jan. 2014. [Online]. Available: http://goo.
gl/0LTRPj.
[8] CyberSecurity Malaysia, “MyCERT 2nd Quarter 2013 Summary
Report”, eSecurity Bulletin, vol. 34, Aug. 2013.
S. Mansﬁeld-Devine, “Hacktivism: assessing the damage”, Net-
work Security, vol. 2011, no. 8, 2011.
[9]
[10] M. Gorge, “Cyberterrorism: hype or reality?”, Computer Fraud &
Security, vol. 2007, no. 2, 2007.
[11] H. Kircher, “The Practice of War: Production, Reproduction and
Communication of Armed Violence”, in. Berghahn Books, Mar.
2011, ch. 12. Martyrs, Victims, Friends and Foes: Internet Repre-
sentations by Palestinian Islamists.
[12] G. Weimann, “Terror on the Internet: The New Arena, the New
Challenges”, in. US Institute of Peace Press, 2006, ch. 6. Fighting
Back: Responses to Terrorism on the Internet, and Their Cost.
[13] Wall Street Journal (WSJ), Google Access Is Disrupted in Vietnam,
Feb. 23, 2015. [Online]. Available: http://goo.gl/JlVtfW.
L. Makani, 100+ Zambian websites hacked & defaced: Spar, Post-
dotnet, SEC, Home Affairs, Ministry of Finance, Apr. 2014. [On-
line]. Available: http://goo.gl/NvQsJM.
[14]
[15] British Broadcasting Company (BBC), Angry Birds website hacked
after NSA-GCHQ leaks, Jan. 2014. [Online]. Available: http:
//goo.gl/kHDIAj.
608  24th USENIX Security Symposium 
USENIX Association
14
[16] A. Mittal, NIC of Suriname, Antigua & Barbuda and Saint Lucia
Hacked by Pakistani Hackers, Oct. 2013. [Online]. Available:
http://goo.gl/ynGG0y.
J. Leyden, Islamist hackers attack Danish sites, Feb. 2006. [Online].
Available: http://goo.gl/jcE7iv.
[17]
[18] ——, Hacktivists attack UN.org, Aug. 2007. [Online]. Available:
http://goo.gl/SfvkUc.
[19] G. Maone, United Nations vs. SQL Injections, Aug. 2007. [Online].
Available: http://goo.gl/v8oXih.
S. Reid, Hip-Hop Sites Hacked By Apparent Hate Group; SOHH,
AllHipHop Temporarily Suspend Access, Jun. 2008. [Online]. Avail-
able: http://goo.gl/VtW4i6.
[20]
[22]
[21] B. Acohido, State Department webpages defaced, Oct. 23, 2013.
[Online]. Available: http://goo.gl/698XRW.
J. Leyden, Foxconn website defaced after iPhone assembly plant
suicides, May 2010. [Online]. Available: http://goo.gl/
6BtZbX.
[23] ——, Anti-Israel hackers deface central bank site, Apr. 2008.
[Online]. Available: http://goo.gl/7Ve2xT.
[24] British Broadcasting Company (BBC), Nottinghamshire Police
website hacked by AnonGhost, Nov. 2014. [Online]. Available:
http://goo.gl/Gbldxt.
[25] ——, Shropshire Fire Service website hacked by AnonGhost, Nov.
2014. [Online]. Available: http://goo.gl/3dq4Cq.
[26] D. Dagon, M. Antonakakis, P. Vixie, T. Jinmei, and W. Lee, “In-
creased DNS Forgery Resistance Through 0x20-Bit Encoding:
SecURItY viA LeET QueRieS”, in Proceedings of the 15th ACM
Conference on Computer and Communications Security (CCS),
ACM, 2008.
[27] G. Vigna and C. Kruegel, “Host-based Intrusion Detection”, Hand-
book of Information Security. John Wiley and Sons, 2005.
[28] A. Bartoli, G. Davanzo, and E. Medvet, “The Reaction Time to
Web Site Defacements”, Internet Computing, IEEE, vol. 13, no. 4,
2009.
[29] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker, “Spam-
scatter: Characterizing Internet Scam Hosting Infrastructure”, in
Proceedings of 16th USENIX Security Symposium on USENIX
Security Symposium, ser. SS’07, USENIX Association, 2007.
[30] K. Borgolte, C. Kruegel, and G. Vigna, “Delta: Automatic Iden-
tiﬁcation of Unknown Web-based Infection Campaigns”, in Pro-
ceedings of the 20th ACM SIGSAC Conference on Computer and
Communications Security (CCS), ACM, 2013.
P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and
Y. LeCun, “OverFeat: Integrated Recognition, Localization and
Detection using Convolutional Networks”, in Proceedings of the
2nd International Conference on Learning Representations (ICLR),
CBLS, Apr. 2014.
[31]
[32] Q. Le, M. Ranzato, R. Monga, M. Devin, K. Chen, G. Corrado, J.
Dean, and A. Ng, “Building High-level Features Using Large Scale
Unsupervised Learning”, in Proceedings of the 29th International
Conference on Machine Learning (ICML), IMLS, Jun. 2012.
[33] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet Classiﬁ-
cation with Deep Convolutional Neural Networks.”, in Advances
in Neural Information Processing Systems 25 (NIPS), vol. 1, 2012.
[34] R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hi-
erarchies for accurate object detection and semantic segmentation”,
arXiv preprint arXiv:1311.2524, 2013.
[35] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based
learning applied to document recognition”, Proceedings of the
IEEE, vol. 86, no. 11, 1998.
[36] R. Raina, A. Madhavan, and A. Y. Ng, “Large-scale deep unsu-
pervised learning using graphics processors”, in Proceedings of
the 26th International Conference on Machine Learning (ICML),
2009.
[37] Q. V. Le, J. Ngiam, Z. Chen, D. J. hao Chia, P. W. Koh, A. Y. Ng,
and D. Chia, “Tiled convolutional neural networks.”, in Advances
in Neural Information Processing Systems 23 (NIPS), 2010.
[38] H. Lee, R. Grosse, R. Ranganath, and A. Y. Ng, “Convolutional deep
belief networks for scalable unsupervised learning of hierarchical
representations”, in Proceedings of the 26th Annual International
Conference on Machine Learning (ICML), ACM, 2009.
P. Sermanet, S. Chintala, and Y. LeCun, “Convolutional neural
networks applied to house numbers digit classiﬁcation”, in Proceed-
ings of the 21st International Conference on Pattern Recognition
(ICPR), IEEE, 2012.
[39]
[40] A. Hyvärinen, J. Hurri, and P. O. Hoyer, Natural Image Statistics:
A Probabilistic Approach to Early Computational Vision. Springer,
2009, vol. 39.
[41] K. Gregor and Y. LeCun, “Emergence of complex-like cells in
a temporal product network with local receptive ﬁelds”, arXiv
preprint arXiv:1006.0448, 2010.
[42] K. Jarrett, K. Kavukcuoglu, M. Ranzato, and Y. LeCun, “What is
the best multi-stage architecture for object recognition?”, in Pro-
ceedings of the 12th IEEE International Conference on Computer
Vision, IEEE, 2009.
[43] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R.
Salakhutdinov, “Improving neural networks by preventing co-
adaptation of feature detectors”, arXiv preprint arXiv:1207.0580,
2012.
[44] Y. Jia, Caffe: An Open Source Convolutional Architecture for Fast
Feature Embedding, 2013. [Online]. Available: http://goo.
gl/Fo9YO8.
S. Axelsson, “The Base-Rate Fallacy and the Difﬁculty of Intrusion
Detection”, ACM Transactions on Information and System Security
(TISSEC), vol. 3, no. 3, 2000.
[45]
[46] G. Davanzo, E. Medvet, and A. Bartoli, “Anomaly Detection
Techniques for a Web Defacement Monitoring Service”, Expert
Systems with Applications, vol. 38, no. 10, 2011.
[48]
[47] A. Bartoli and E. Medvet, “Automatic Integrity Checks for Remote
Web Resources”, Internet Computing, IEEE, vol. 10, no. 6, 2006.
L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. Tygar,
“Adversarial Machine Learning”, in Proceedings of the 4th ACM
Workshop on Security and Artiﬁcial Intelligence (AISEC), ACM,
Oct. 2011.
[49] M. Barreno, B. Nelson, A. D. Joseph, and J. Tygar, “The Security
of Machine Learning”, Machine Learning, vol. 81, no. 2, 2010.
[50] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar,
“Can machine learning be secure?”, in Proceedings of the 13th
ACM Symposium on Information, Computer and Communications
Security (CCS), ACM, Oct. 2006.
[51] N. Šrndic and P. Laskov, “Practical Evasion of a Learning-Based
Classiﬁer: A Case Study”, in Proceedings of the 35th IEEE Sympo-
sium on Security and Privacy (Oakland), IEEE, May 2014.
[52] D. Lowd and C. Meek, “Adversarial Learning”, in Proceedings of
the 11th ACM SIGKDD International Conference on Knowledge
Discovery in Data Mining (KDD), ACM, Aug. 2005.
[53] N. Dalvi, P. Domingos, Mausam, S. Sanghai, and D. Verma, “Ad-
versarial Classiﬁcation”, in Proceedings of the 10th ACM SIGKDD
International Conference on Knowledge Discovery and Data Min-
ing (KDD), ACM, 2004.
USENIX Association  
24th USENIX Security Symposium  609
15
[54] A. Globerson and S. Roweis, “Nightmare at Test Time: Robust
Learning by Feature Deletion”, in Proceedings of the 23rd Interna-
tional Conference on Machine Learning (ICML), ACM, 2006.
[55] H. Xiao, H. Xiao, and C. Eckert, “Adversarial label ﬂips attack on
support vector machines”, in Proceedings of the 20th European
Conference on Artiﬁcial Intelligence (ECAI), Aug. 2012.
[56] D. Wagner and P. Soto, “Mimicry Attacks on Host-based Intrusion
Detection Systems”, in Proceedings of the 9th ACM Conference on
Computer and Communications Security (CCS), ACM, 2002.
[57] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna, “Au-
tomating Mimicry Attacks Using Static Binary Analysis”, in Pro-
ceedings of the 14th Conference on USENIX Security Symposium,
USENIX Association, 2005.
[58] A. Kapravelos, Y. Shoshitaishvili, M. Cova, C. Kruegel, and G.
Vigna, “Revolver: An Automated Approach to the Detection of
Evasive Web-based Malware”, in Proceedings of the 22nd USENIX
Security Symposium, 2013.
[59] C. Kolbitsch, E. Kirda, and C. Kruegel, “The Power of Procrasti-
nation: Detection and Mitigation of Execution-stalling Malicious
Code”, in Proceedings of the 18th ACM Conference on Computer
and Communications Security (CCS), ACM, 2011.
[60] K. Borgolte, C. Kruegel, and G. Vigna, “Relevant Change De-
tection: Framework for the Precise Extraction of Modiﬁed and
Novel Web-based Content as a Filtering Technique for Analysis
Engines”, in Proceedings of the Companion Publication of the 23rd
International World Wide Web Conference (WWW), IW3C2, 2014.
E. Medvet, C. Fillon, and A. Bartoli, “Detection of Web Deface-
ments by Means of Genetic Programming”, in Proceedings of
the 3rd International Symposium on Information Assurance and
Security, IEEE Computer Society, 2007.
[61]
[62] G. H. Kim and E. H. Spafford, “The Design and Implementation of
Tripwire: A File System Integrity Checker”, in Proceedings of the
2nd ACM Conference on Computer and Communications Security
(CCS), ACM, 1994.
[63] A. G. Pennington, J. D. Strunk, J. L. Grifﬁn, C. A. N. Soules, G. R.
Goodson, and G. R. Ganger, “Storage-based Intrusion Detection:
Watching Storage Activity for Suspicious Behavior”, in Proceed-
ings of the 12th Conference on USENIX Security Symposium,
USENIX Association, 2003.
E. Medvet, E. Kirda, and C. Kruegel, “Visual-similarity-based
Phishing Detection”, in Proceedings of the 4th International Con-
ference on Security and Privacy in Communication Networks
(SecureComm), ACM, 2008.
[64]
[65] W. Liu, X. Deng, G. Huang, and A. Y. Fu, “An Antiphishing Strat-
egy Based on Visual Similarity Assessment”, Internet Computing,
IEEE, vol. 10, no. 2, 2006.
[66] A. Nappa, M. Raﬁque, and J. Caballero, “Driving in the Cloud: An
Analysis of Drive-by Download Operations and Abuse Reporting”,
English, in Detection of Intrusions and Malware, and Vulnerability
Assessment, ser. Lecture Notes in Computer Science, K. Rieck,
P. Stewin, and J.-P. Seifert, Eds., vol. 7967, Springer Berlin Heidel-
berg, 2013. [Online]. Available: http://goo.gl/Z2IJ4D.
[67] C. Grier, L. Ballard, J. Caballero, N. Chachra, C. J. Dietrich, K.
Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pitsillidis,
N. Provos, M. Z. Raﬁque, M. A. Rajab, C. Rossow, K. Thomas,
V. Paxson, S. Savage, and G. M. Voelker, “Manufacturing Com-
promise: The Emergence of Exploit-as-a-Service”, in Proceedings
of the 2012 ACM Conference on Computer and Communications
Security, ser. CCS ’12, ACM, 2012. [Online]. Available: http:
//goo.gl/M1DOdZ.
Appendix
A Reporter Cross-validation Split
In our reporter split experiment (Section 4.4), we split the
dataset by reporter to simulate that a new defacer group
emerges. Each cross-validation bin contains the same
amount of reporters, but because they reported different
numbers of defacements, bins do not contain the same
amount of samples. We account for the size difference in
our experiments by weighting each bin. Table 3 lists the
number of samples per bin.
Bin
1
2
3
4
5
6
7
8
9
10
Total
Defacements
1,116,808
992,232
712,270
907,306
696,069
734,208
1,276,764
789,895
979,309
1,053,147
9,258,008
Legitimate Websites
308,202
273,823
196,563
250,387
192,092
202,617
352,345
217,985
270,257
290,634
2,554,905
Table 3: Number of samples per cross-validation bins used for the
reporter split. Note that the total number of defacements in the reporter
split contains 168 defacements less than available in the whole dataset
because otherwise reporters would be distributed unevenly per bin.
However, due to the considerable size of the dataset, omitting these
defacements has negligible impact.
B Image-based Object Recognition
Much prior work has been carried out in computer vision
to classify images and recognize objects in images. Most
recently, object recognition underwent a “new spring” with
the rise of deep learning. Deep learning gained traction
because training them on large datasets became computa-
tionally feasible, and they consistently outperformed other
algorithms. We discuss our two main inspirations.
Le et al. [32] introduce a feature learning approach that
leverages unsupervised learning with a deep networks
comprised of stacked sparse autoencoders utilizing pooling
and local contrast normalization. The main idea is to learn
high-level features from only unlabeled data (10 million
pictures from random Youtube videos); high-level features
such as if the image contains a cat, or a human face or body
part. After training, the network improves relatively to prior
state-of-the-art by 70% on the ImageNet dataset.
Krizhevsky et al. [33] employed supervised learning to
train a deep convolutional neural network to classify 1.2
million images spanning 1,000 classes from a subset of the
ImageNet dataset and they improve considerably on the
state-of-the-art with a top-1 error rate of 37.5% (the classiﬁer
is correct for 62.5%) and a top-5 error of 17.0% (for 83% im-
ages, the correct class is among top 5 classes). To not overﬁt
the dataset and to reduce the network’s training time, they
use rectiﬁed linear units as the neurons’ output functions.
610  24th USENIX Security Symposium 
USENIX Association
16