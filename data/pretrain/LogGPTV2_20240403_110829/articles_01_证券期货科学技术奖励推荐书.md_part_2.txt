以减少对系统的影响。所采集的日志都会包含应用名称、主机名称、标签，以保证对日
志类型、来源等信息的区分，也可以使用这三个维度对日志重新分类，以增加对数据可
管理性。
日志采集协调模块用于大型分布式系统的高可靠协调，提供的功能包括：配置维护、
名字服务、分布式同步、组服务等。封装好复杂易出错的关键服务，将简单易用的接口
和性能高效、功能稳定的系统提供给用户。
日志消息处理模块用于消息的持久化和缓存。该模块使用磁盘文件做持久化，顺序
进行读写，以 append 方式写入文件。为减少内存 copy，集群使用 sendfile 发送数据，
通过合 并 message 提升性 能。 集群 本 身不储 存每 个消 息 的状态 ，而 使用
（consumer/topic/partition）保存每个客户端状态以减少维护每个消息状态的麻烦。
在消息推拉的选择上，集群使用拉的方式，避免推的方式下存在的各个客户端的处理能
力、流量等不同产生不确定性。
2.2.2 运维指标数据的实时分析与计算
数据收集层直接接收采集客户端上送的数据，实时写入到 Kafka Topic，流处理引擎
Logriver 从 Kafka 直接消费数据进行格式化处理存入到搜索引擎 YottaSearch 中，同时
提供SparkStreaming 流处理和Spark离线处理等多种处理方式，按照不同数据需求者的
要求提供数据。
8
目前数据的实时计算支持：
 运行结点100+，并达到秒级延迟。
 使用基于内存的计算作为执行引擎，具有高效和容错的特性。
 能集成批处理和交互查询。
 为实现复杂的算法提供和批处理类似的简单接口。通过丰富的 API和基于内存的高速
计算引擎可以结合流式处理，批处理和交互查询等应用。
 计算流程：将流式计算分解成一系列短小的批处理作业。把输入数据（如 1秒）分成
一段一段的数据。
 容错性与实时性：将流式计算分解成多个 Job，对于每一段数据的处理都会经过分解，
以及任务集的调度过程。
 扩展性与吞吐量：能够线性扩展到 100个节点（每个节点 4Core），可以以数秒的延
迟处理万级以上 EPS。
2.2.3 可编程式检索与分析
索引集群采用分布式搜索引擎，具备高可靠性和高性能。支持时间文本索引和全文
检索，提供丰富的 API 用于索引、检索、修改大多数配置。能够快速搜索数百亿的集群
由 2 台及 2 台以上节点组成，其中一个为主节点，节点通过选举产生，主从节点是对于
整个集群内部来说的，从外部来看整个集群，逻辑上是一个整体，与任何一个节点的通
信和与整个集群通信是完全一致的。集群自动创建索引，通过配置我们可以非常方便的
调整索引分片和索引副本。通过索引分片技术，一个大的索引被拆分成多个，然后分布
在不同的节点上，以构成分布式搜索。索引副本的作用一是提供系统的容错性，当某个
节点某个分片损毁或丢失时，可以从副本中恢复；二是提供查询效率，集群内部会自动
实现搜索请求的负载均衡。
 支持智能检索功能，可通过输入的关键字条件快速检索到相关的日志数据，并可以进
一步查看日志数据的详细信息。
 支持通过关键字、条件表达式、时间范围等对事件及数据进行快速检索，快速定位到
运维分析人员关注的威胁事件和上下文数据，并支持查看数量趋势统计和检索结果详
细数据。
 支持TB级别的数据量检索。
9
模块架构如下：
2.2.4 数据安全设计
1） 数据传输安全
传输加密主要通过 SSL/TLS 加密协议完成。如果要进行 TLS/SSL 的配置，首先必须
要具有来自受信 CA 的证书，使用该 CA 生成每个节点的证书，节点的所有服务都会通过
上述生成的证书进行 SSL/TLS 加密。每个节点还需要建立本地的 Java Keystore 以支持
SSL/TLS公钥、秘钥的存放。
智能运维管理平台的数据从客户端-处理端-数据存储都支持 SSL 加密，确保数据在
传输过程中的安全，不会被恶意篡改。此外，流数据在成功处理后，才会提交对应数据
偏移量，确保当异常发生时，数据处理可以从最近一次成功处理的重新开始，从而确保
数据零丢失。
2） 数据存储安全
平台底层数据存储采用分布式引擎，每条数据都存储为多个数据备份，当单个数据
节点出现故障时，数据可以及时从其他节点恢复，保证数据在存储阶段的安全可靠。
对于数据加密，HDFS和HBase都提供了对应的功能。加密数据会有额外的计算开销，
这里只建议对部分关键目录进行加密，这两种加密方式对用户来说都是透明的，只要用
户有秘钥的访问权限就能查看对应数据。结构化数据加密：目前结构化数据都由
Hive/Impala进行存储，因此直接/user/hive/warehouse/${database}.db/${tablename}
的对应目录进行加密，Hive端不需要进行额外配置。非结构化数据加密：非结构化数据
分为小文件和大文件进行讨论。小文件：存放于 HBase中，HBase提供了数据单元（cell）
级别的加密，直接可以对部分文件的二进制加密存放。大文件：存放于 HDFS中，这部分
关键文件可以使用 HDFS加密的方式，建立对应的文件加密区，进行存放。
ElasticSearch 层面则可以针对索引 Index针对不同的人员进行访问控制管理。
3） 数据访问安全
用户基于 CMDB 中应用系统的管理员来进行访问权限隔离控制，即只有应用的 A，B
角才可以访问相应系统的数据。通过基于 RBCA的权限控制体系，可以进行更加详细的权
限划分。
10
3、 创新点
3.1 通过 AIOps 实现了故障发现、根源分析和故障定位
3.1.1 基于无监督学习实现了单指标异常的智能检测
对于异常检测技术，我们采用的是无监督自学习异常检测方案。因为随着各种监控
以及 web 应用程序的拓展，这些具有各种模式和数据质量的季节性 KPI 异常检测一直是
一个巨大的挑战，尤其是在没有标签的情况下。所以我们提出了一种基于 VAE 的无监督
异常检测算法——Donut。
变分自编码器是一种深度贝叶斯网络，我们通过 SGVB最大化证据下界（ELBO）近似后验
和生成模型联合训练。具体公式如下图所示：
我们基于此的 DONUT算法的结构如下：
由于我们的一些关键技术，Donut 的性能大大超过了现有的监督集成方法和基线 VAE
方法，采用的新的 Donut 重构 KDE 解释方法，使其成为第一个具有较强的理论解释力的
基于VAE的异常检测算法。
3.1.2 基于算法组合实现海量指标智能异常定位
我们的智能异常定位技术主要由三个关键技术组成：异常相关波动检测，相似机器
聚类，以及智能严重度评估排序。我们采用核密度估计和极值理论结合的方式来估算了
相关波动严重度。基本流程如下图所示：
11
聚类方面我们采用了皮尔森相关系数来对两台机器的异常度进行度量，并使用
DBSCAN算法来进行聚类。其中利用皮尔森系数来估算相似度的公式如下：
最后在排序阶段，我们使用了 Learning-to-Rank算法中的 PointWise排序法，利用
监督学习和逻辑回归配合，辅助历史事件的人工结果，自动训练合适的排序模型。最终
排序时采用的关键特性包括有：
 集群的最大异常值
 集群的异常值总和
 异常的KPI数目
 集群异常机器数量占据总数量的比例等
3.1.3 基于自然语言处理等技术日志异常检测技术实现的故障定位
故障定位的最终原因往往存在于应用日志中，我们从三个方面对设备或应用日志异常
检测问题展开设计：日志解析，单条异常日志检测，异常日志序列检测。
首先，从历史日志消息中构建频繁项前缀树以学习消息模板，从而构建模板库。基于
模板库，可以将历史日志消息映射到对应的模板上。然后，基于模板库将实时日志消息
映射到对应的模板上。如果发现实时日志消息无法映射到任一模板上，则自动地、增量
式地从该日志消息中学习模板，并扩充到模板库中。
借鉴频繁模式树（frequent pattern tree, FP-tree)）的思想，构建一种可动态添
加分枝的频繁项前缀树结构来表示设备或应用日志消息模板。其基本思想是，系统日志
消息中详细信息字段的子类型通常是频繁出现的单词的最长组合。因此，提取模板等价
于从系统日志消息中识别出频繁出现单词的最长组合。本系统为每一个消息类型的日志
消息构建一棵基于日志消息中单词频率的前缀树，从而实现自动地获取消息模板。该前
缀树的根节点为日志消息的消息类型。通过剪枝的方式，消息模板中需要被遮挡的部分
被删除掉，而日志消息子类型被保留了下来。所以，获取消息模板的过程是完全自动的，
并不依赖于专家知识。
12
通过一种日志异常检测机制，能够准确、高效地解析日志，且自动、准确地检测数据中
心各种型号设备或应用的多语法语义的单条异常日志和异常日志序列，主动发现设备或
应用的异常以及时采取应对措施，从而提高数据中心的稳定性，针对基于监控指标时序
数据的异常检测无法获知异常根因的问题，本系统基于日志自动、准确地对数据中心设
备或应用进行异常检测，以便于后续的异常定位和根因分析。
1） 构建时许序列
2） 突增现象的检测
针对窗口序列的突增现象检测是一个一维序列的异常检测问题，我们使用经典的
基于正态分布的一元离群点检测方法来检测这种异常。设当前处理的模版是 𝑇 𝑦𝑝𝑒，
其窗口序列为 𝑦，长度为 𝑁𝑤，我们根据 𝑦1 ∼ 𝑦𝑖 的情况来判断 𝑦𝑖+1 是否出现突
增。在基于正态分布的检测方法中，我们假设 𝑦1 ∼ 𝑦𝑖 符合正态分布，求出它们的
均值和方差:
若出现 𝑦𝑖+1 > 𝑀𝑒𝑎𝑛 + 𝐴 × 𝑆𝑡𝑑（𝐴 为参数，通常是 3），则说明 𝑦𝑖+1 已经
远高于 𝑦1 ∼ 𝑦𝑖 的平均水平，我们认为发生了突增现象。由于平均值受异常值影响
较大，为了增强算法的鲁棒性，我们使用 𝑦1 ∼ 𝑦𝑖 的中位数 𝑀𝑖𝑑𝑑𝑙𝑒 代替 𝑀𝑒𝑎𝑛。
对每一个模版 𝑇 𝑦𝑝𝑒 的窗口序列 𝑥𝑇 𝑦𝑝𝑒 进行一遍扫描，标记所有被检测出来出现
突增的窗口，我们称他们为异常窗口。
3） 计算模板在日志数量层面上的异常程度
通过异常窗口的检测，我们标记在异常时间周围的窗口序列 𝑥𝑇 𝑦𝑝𝑒 中存在异常
窗口的模版 𝑇 𝑦𝑝𝑒 为异常模版（以日志数量为标准的异常），对于每一个异常模版，
我们会计算出一个严重度 𝑆𝑇 𝑦𝑝𝑒，表示该模版在日志数量上的异常程度，严重度可
以用来将异常模版排序，也可以让运维人员对于每一个异常模版的异常表现产生一个
定量的参考。
我们基于两个标准来计算一个模版 𝑇 𝑦𝑝𝑒 严重度 𝑆𝑇 𝑦𝑝𝑒：
 该模版的日志在正常时段出现的越少，该模版的严重度越大。
 该模版在异常时段处异常窗口中日志越多，该模版严重度越大。
13
3.2 利用智能运维知识图谱实现了算法的编排
知识图谱应用在运维和排障领域，将我们独有的知识图谱技术融合了算法、日志、
指标、告警、事件、历史故障知识信息，整合成一张故障运维知识图谱体系，有效地实