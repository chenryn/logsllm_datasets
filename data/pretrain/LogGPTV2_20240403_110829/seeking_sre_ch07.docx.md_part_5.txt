记录或为服务设置警报的速度，交付新功能或改进功能的能力越来越慢。数十个功能团队迫不及待地等待将更新分发给我们的用户，但不得不等待我们进行代码审查或为其服务提供硬件。
我们还在要求提供核心服务，在我们努力跟上不断积累的任务时，这些服务的业务质量和稳定性受到了影响。全球"运维任务清单"一直在不断增长。
### 减轻手动负载
 在查看了后端工程师如何工作以及最常陷入等待的位置数据后，我们决定尽可能专注于消除这些障碍。是时候考虑恢复小型初创公司的协作氛围，在开发与运维之间的相互信任，使我们的功能团队能够快速迭代，同时保持生产的可靠性。
首先需要改进的领域之一是服务器的预配。当我们的数据中心中有服务器时，我们仍必须引导操作系统并配置基本环境。我们有一些基本的自动化，但为了启动这个过程，后端工程师必须为运维团队创建一个工单，指定他们需要哪个数据中心、多少台服务器以及什么服务。然后，守门员会照顾这个工单，并使用我们的一组管道式数据库和命令行工具来启动预配过程。通常在大约
40 分钟的自动化任务之后，服务器才为后端开发人员做好准备。
我们改善这个过程的第一次尝试是一个叫做 provgun
的工具，简称为"预配枪"。团队现在可以打开 JIRA
工单，自行启动预配，而不需要向运维团队发送工单或指望运维人员的垂青。一段时间后，cronjob
将扫描这些打开的工单，并自动启动我们以前手动执行的所有步骤，然后在成功预配服务器时向工单发出答复。
这释放了时间，让运维团队专注于其他事项，例如处理此系统的下一个版本：具有硬件可配置性和可用库存的自定义
Web 界面。此 Web
界面将显示未完成请求的队列、服务器的物理位置、机架多样性以及每个数据中心的可用服务器的当前库存，使开发人员有更多的选择，并更好地了解我们是如何构建我们的硬件生态系统。
 接下来要解决的是 DNS 基础结构。当时，运维团队手动添加和部署服务器的 DNS
记录。运维团队做的第一件事是使用 CMDB
作为事实来源，以确定哪些服务器记录应自动添加到区域文件中。这有助于减少错误的数量，例如忘记添加尾随的点号。经过反复检验，我们确信这些区域文件是准确的，于是它们能自动部署到权威
DNS 服务器。这再次释放了我们大部分的时间，开发人员的满意度也提高了。
我们的后端中的服务使用 DNS SRV 记录发现彼此。另外还有一些用户友好的
CNAME，任须手动添加到区域文件中，这是一个繁琐且容易出错的任务，仍然需要运维工程师来查看和部署更改。
为了消除这一瓶颈，我们考虑了如何自动执行审核和部署过程。引入了[一个基本测试框架](https://github.com/spotify/rspec-dns)，其中可以表达在审核中需要寻找的东西，例如"播放列表服务在我们的数据中心中是否可以发现？"我们还创建了一个自动程序，允许任何人合并更改（只要测试通过且经过互审）。
这是一个重大的更新：一个文件的简单更改可能会影响整个数据中心。在最初的一些事件中，一个团队的意外修改往往导致比预期的要严重的后果。但是，我们的后端开发人员很快了解了这些改变带来的力量和责任；很快，错误的数量几乎降到了零。同样，这减少了他们不得不等待运维团队的时间（从几天到几分钟）。
DNS 和服务器预配成功后，下一个难题是
Puppet，配置管理系统，它在我们的服务器上安装了所有软件并部署了我们的应用程序。运维团队早就接受了对
Puppet
的补丁，但在合并任何内容之前需要每个提交进行审查。对于较大的提交或复杂的系统，这意味着他们可能会等待审查数天之久，直到有人找到足够的时间来审查它。
我们尝试了使用 DNS
的方法：合并你自己的更改，只要你的修补程序得到了其他人的积极评价。在最初的几周里，我们都非常焦虑，几乎对合并的每一个承诺都进行了监控。我们很快发现这些焦虑其实没有什么理由。给后端开发人员一个反馈周期，让他们放手进行更改、合并、部署、发现问题，然后再做一遍，这样他们会更深入地了解我们遇到的许多常见问题，总体而言，这些反馈周期提高了代码质量。
使团队在运维上负责的最初几个步骤是成功的。他们现在可以获取服务器，为这些服务器添加
DNS
记录，并自行将配置和应用程序部署到新预配的服务器。我们不仅消除了开发人员的主要摩擦点和等待时间，而且由于从"构建它"到"运行它"的第一次责任转变，服务的稳定性也提高了。
## 以信任为基础
 但是，当我们跳过了运维团队以前完成的这些"运行状况检查"时，我们面临着一个新问题。没有运维团队的指导，后端现在更无序了。测试不足的服务和简单的实验使其问题进入生产环境，有时会导致停机，并要求轮值工程师的帮助，但他们现在缺乏对生产中运行内容的必要了解。我们需要找到一个办法，将知识和运维责任带回正确的位置，安排适当的人员来排除故障。
当 Spotify
是一个小型组织时，传统的运维所有者方法效果很好，但它在技术和组织方面都有复杂性和可扩展性问题。依靠一个或两个系统所有者来找出所有的问题是不可能的。我们还意识到，作为运维的看门人，这意味着我们保持了对运维学习机会的垄断。
将责任移交给后端团队似乎是合乎逻辑的下一步。下一个问题是如何继续。我们需要与团队积极接触，并找出与技术组织的其他部门合作的方法。
 我们开始推出一种新的工作方式，即"小组中的荣誉运维"，这实质上包括将服务轮值和运营责任移交给开发服务的团队所需的一切。我们需要编写工具来完成许多以前手工完成的事情；我们需要更好的文档和培训，以便开发人员能够解决生产问题；我们需要开发者的同意来推动这一变化。
为开发人员和运维人员创建的[指导文件](https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/)，在每个人之间共享知识并打开双向沟通渠道，定义了我们需要的一些关键内容：
-   定义服务级别协议的标准化方法（SLA；我们当时没有使用服务级别指标【SLI】和服务级别目标【SLO】概念）
-   关于轮值、处理事件、执行根本原因分析和进行故障报告的速成课程
-   关于容量规划的指导
-   设置监控和警报的最佳做法，以及解释监控数据的指导
-   故障排除、系统交互和基础结构工具的培训
当然，将所有这些责任交给团队，在很长一段时间内都是一项艰巨的任务，而基础设施团队仍要支持和构建核心平台。我们努力定义到底是什么算是核心平台；有些事情是显而易见的，例如网络、监视和预配，但其他系统更难分类。需要评估我们基础设施的关键部分，如用户登录服务、播放列表系统或歌曲加密密钥系统：它们是核心基础结构，还是应该像任何其他后端系统一样处理它们？
我们想达成交易：我们负责消除拥塞和摩擦，以换取将运维责任转移到功能团队中。如果团队需要在周五部署更改，则不应阻止它这样做。我们努力使运维服务的知识对开发人员来说唾手可得。
这没有得到组织内每个人的欢呼和鼓励；有人担心会对功能团队的迭代速度产生负面影响。如果团队还处理其系统的维护和操作职责，他们将如何有足够的时间来交付功能和增长？这些团队由开发人员组成，而不是
SRE；他们有多少时间要用于学习和练习操作？准备、过程和工具对于说服人们承担这一责任至关重要。
我们继续投入大量资源来改进我们的工具，编写和推广框架，并编写文档，以帮助大多数团队尽可能顺利地过渡。 
## 推动模式转变
> * 我们的目标是比任何人都更快地犯错误。*
>
> Daniel Ek，Spotify 创始人兼首席执行官
 为了向所有团队提供所需的信息和工具，我们采取了几种不同的方法。我们为开发人员举办了演示，讨论了后端系统如何组合在一起以及如何使用共享基础结构。我们的首席架构师为数十名核心开发人员演示了故障报告的编写，引导他们经历由级联故障导致的一个大型事件。通过具有中心入口点，我们使团队更容易找到基础结构系统的文档和所有权。我们开发了一本"小组运维手册"，该手册成为引入新开发人员的标准文档。它包含了团队入门所需的大部分信息；要做的事情；在哪里阅读更多；实施的流程、技术功能或流程的检查表。我们在短时间内嵌入后端团队，将主机团队过渡到轮值服务；帮助教授运维；并直接与改进系统、部署程序、运维手册编写等，为请求或需要的团队提供服务。再次，我们达成了一个协议：我们将与团队度过一些开发周期并"清洁房屋"，然后再将轮值的责任移交给他们。
2014
年，这种方法（将工程师嵌入团队）被扩展为"小组的运维"之旅，我们运维团队的某些部分每周前往不同的团队，参与日常工作，并努力帮助他们解决他们头疼的任何事情。
在这些嵌入过程中，我们深入了解了那些团队的体系结构，并研究了警报和监视，有助于在需要时改进这些体系结构。我们还讨论了如何围绕计划轮值、如何上报问题以及如何进行事后故障分析的最佳实践。特别是故障分析，有一个"遗体告别"的美誉。发生大量事件的团队经常跳过故障分析，因为建立时间表、查找根本原因和定义每周
10 或 20
个事件的补救工作似乎开销太大。在这些案例中，寻找故障报告的不同方法证明是有用的，例如将事件归结与多个主题，或同时对多个事件进行简短的事后分析。通常，许多事件都有类似的根本原因；确切的时间表不如确定顶级补救措施重要，这些补救措施将在未来将此类事件的可能性降低
90%。在整个转变过程中，我们保留了*无可指责*的事后报告原则，强调从错误中吸取教训的重要性，并确保没有人被边缘化或开除。
## 关键收获
这一时期的一些主要知识是：
-   努力自动化*一切*。去除手动步骤、摩擦和等待，这可提高迭代产品的能力。
-   确保自助操作工具具有足够的保护和安全考量。
-   通过协作来进行运维教学，着对于使运维在组织中成为"默认技能"至关重要。  
# 自主性与一致性的权衡：2015\~2017
-     近 100 名运维工程师
-   近 200 名后端工程师
-   4 个数据中心
-   120 个服务
-   多个云服务商
## 前奏
在本节中，我们将讨论如何尝试在小队的自主性与技术一致性之间取得平衡：
迭代失败
:   我们引入技术堆栈中一致性的第一种方法导致了无意的碎片化。尽管我们不断迭代并解决这些新暴露的问题，但我们发现自己其实再次阻止了团队的前进。
核心工程价值
:   帮助功能团队快速前进，这使我们能够保持团队的独立性和自由，同时引入急需的基础架构一致性。
在推进"小组的运维"模型时，我们将重点转移到标准化技术堆栈上。对于这种分散的运维模型，我们需要通过提供整个基础架构的一致性来降低团队的运维成本。高度无序意味着昂贵的上下文切换和不必要的开销。然而，在一致性和我们对自主的爱好之间取得平衡，需要深思熟虑和远见。
为 Spotify
的技术堆栈带来一致性有几个渠道。尽管团队现在负责维护他们的服务，但我们需要通过在正确的位置构建抽象层来避免构成阻塞。第一个抽象层级别是我们自己的工具，迭代了我们早期的
provgun 和
DNS，用来成功的消除摩擦点。从这些努力中诞生了一些新的工具：[moob](https://github.com/spotify/moob)，用于网络带外管理；一个作业调度程序名为
neep，用于安装、回收和重新启动硬件和一个批处理作业
zonextgen，用于为所有正在使用的服务器创建 DNS 记录，等等。
在 2015 年至 2016 年，我们专注于围绕容量管理、Docker 部署的实施、监视和
SLA