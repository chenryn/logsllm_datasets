tolerate faults in its own logic, e.g., the pointer remap-
ping  logic  or  the  fault  map.  These  structures  are  far 
smaller  than  the  structures  they  are  protecting,  which 
TABLE 1. Target System Parameters
pipeline depth
pipeline width
reorder buffer
functional
units
branch
predictor
registers
L1 D-cache
L1 I-cache
L2 cache
22
3
126
4 integer adders and multiplier, 
1 FP adder, 1 FP multiplier
gshare: BHT is 4096 entries, 
BHT entry is 2-bit counter, 
BHR is 8 bits
192
8K total size, 4-way, 2-cycle
8K total size, 4-way, 2-cycle
256K size, 8-way, 7-cycle
makes them less prone to hard faults, but they could still 
fail.  Second,  SRAS  does  not  tolerate  a  fault  in  a  table 
sub-array  if  no  more  spare  rows  are  available  in  that 
sub-array.  This  limitation  does  not  apply  to  buffers 
except  in  the  extreme  case  in  which  every  row  of  the 
buffer, including spares, is faulty. Third, SRAS does not 
tolerate a fault in a sub-array (for a buffer or table) if all 
of the check rows for that sub-array are faulty. 
All of these untolerated faults present the designer 
with a classic engineering trade-off: fault tolerance ver-
sus hardware cost. Future SRAS implementations could 
develop hardened logic if the ﬁrst fault model is consid-
ered important. The probabilities of the latter two cate-
gories  can  be  decreased  by  designing  the  SRAS 
protection to use more spare rows and more check rows. 
5  Evaluation
In  this  section,  we  quantitatively  evaluate  SRAS. 
We  compare  our  approach  to  unmodiﬁed  DIVA  (i.e., 
DIVA  without  SRAS  extensions  for  hard  faults),  in 
order to determine the relative performances in the fault-
free  and  faulty  scenarios.  We  begin  by  describing  our 
methodology,  and  then  we  present  our  experimental 
results and the broader applicability of these results. 
5.1  System Model and Methodology
We use the SimpleScalar toolset [2] to evaluate our 
design and compare it to unmodiﬁed DIVA. We model a 
dynamically scheduled microprocessor that is similar to 
currently  available  microprocessors,  such  as  the  Intel 
Pentium4  [9]  and  Alpha  21364  [8].  The  details  of  the 
target system are shown in Table 1. We simulate DIVA 
fault tolerance by comparing each instruction’s result to 
the fault-free result and, if they do not match, triggering 
a pipeline squash in the aggressive processor core. We 
simulate the SPEC2000 CPU benchmarks, and we use 
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:51:42 UTC from IEEE Xplore.  Restrictions apply. 
the  SimPoint  toolset  [20]  to  choose  statistically  repre-
sentative samples of these long benchmarks for detailed 
simulation.  We  inject  single-bit  stuck-at-1  and  all-bits 
(in a single row) stuck-at-1 faults into the simulated sys-
tems.  We  vary  the  number  of  injected  faults  of  these 
types and examine their impact on system performance. 
5.2  Results
In this section, we present our results. 
ROB. In Figure 4, we display the results of our experi-
ments with injecting faults into a ROB with 126 entries. 
This  large  ROB  size  corresponds  to  that  of  the 
Pentium4. The two ﬁgures—which represent results for 
the SPEC integer and ﬂoating point benchmarks, respec-
tively—plot  the  speedup  of  SRAS  as  compared  to 
unmodiﬁed DIVA, as a function of the number of faults 
injected. The results show that, for most of the bench-
marks,  SRAS  achieves  a  signiﬁcant  speedup  over 
unmodiﬁed  SRAS.  Even  for  just  a  single  all-bit  fault, 
speedup results range up to 1.4. 
The  trends  in  the  graphs  reveal  a  few  interesting 
phenomena. First, the SRAS speedup in the presence of 
a  given  number  of  single-bit  faults  is  always  less  than 
the speedup in the presence of the corresponding num-
ber of all-bit faults. The insight for this result is that a 
single-bit fault is far more likely to be logically masked. 
Second,  the  results  vary  across  the  benchmarks  more 
than one might expect. For unmodiﬁed DIVA, the num-
ber  of  recoveries  per  instruction  should  be  fairly  con-
stant across benchmarks. However, as the graphs show, 
certain benchmarks (e.g., mcf) achieve smaller speedups 
than  others.  Also,  in  general,  the  integer  benchmarks 
achieve smaller speedups than the ﬂoating point bench-
marks.  We  examined  the  raw  performances  of  every 
benchmark, in units of instructions per cycle (IPC), and 
we discovered a direct correlation between IPC and the 
magnitude of the SRAS speedup. As IPC decreases, the 
number of recoveries per cycle decreases, and thus the 
impact  of  SRAS  (compared  to  unmodiﬁed  DIVA) 
decreases.
BHT. In Figure 5,  we  compare  the  performance  of 
SRAS  and  unmodiﬁed  DIVA  in  the  presence  of  hard 
faults in the BHT. We only show the results for the case 
of  all-bit  faults,  since  the  results  for  1-bit  faults  are 
almost  identical.  We  observe  in  this  ﬁgure  that  SRAS 
actually results in a slowdown with respect to unmodi-
ﬁed DIVA. There are two reasons for this result. First, 
the  penalty  for  faulty  BHT  rows  is  small,  since  each 
individual row is exercised more rarely and is more eas-
ily  masked.  Second,  we  force  a  very  conservative  per-
formance penalty on SRAS by adding an extra pipeline 
stage for remapping this table. The delay for remapping 
is  only  2-4%  of  a  pipeline  stage,  and  this  delay  might 
not even be on the critical path (e.g., if the BHT access 
latency  is  not  the  critical  path  determinant  of  pipeline 
latency). However, even in the likely case that this added 
pipeline stage is overly conservative, we would still con-
clude that SRAS is probably not worth the effort for the 
BHT. 
With faults injected, SRAS speedups are still small 
and often less than one. Moreover, speedup results are 
largely  independent  of  the  number  of  faults  and  the 
benchmarks.  The  performance  penalty  incurred  by 
SRAS,  with  respect  to  unmodiﬁed  DIVA,  depends  on 
the impact of adding the pipeline stage in the front-end 
of the pipeline (i.e., towards fetch). For workloads that 
have a bottleneck at the back-end (i.e., towards commit), 
the  extra  latency  in  the  front-end  gets  hidden.  Thus, 
even when a branch is mis-predicted and ﬂushes subse-
quent  instructions,  the  re-fetched  instructions  can  still 
propagate  back  into  the  pipeline  before  it  runs  out  of 
instructions to execute. 
5.3  Broader Applicability of Results
Experimental  results  show  that  the  addition  of 
SRAS protection for the ROB is beneﬁcial and that it is 
probably not a good idea for the BHT. These results also 
suggest  which  types  of  microarchitectural  array  struc-
tures are most likely to beneﬁt from SRAS. The ROB is 
a heavily-used buffer with a high AVF, which is similar 
to the register ﬁle, reservation stations, and store buffer. 
We would expect SRAS to beneﬁt these structures, and 
future  work  will  explore  adding  SRAS  protection  to 
them. Conversely, the BHT is a sparsely-used table with 
an AVF of zero, which is similar to other tables that are 
used  for  prediction,  such  as  for  value  prediction  [12]. 
We  would  expect  SRAS  to  have  minimal  impact  on 
these structures, even if the remapping can be performed 
without  degrading  performance  in  the  fault-free  case. 
However, if a prediction table was small, and thus each 
entry was accessed more frequently, SRAS might help. 
6  Conclusions
In  this  paper,  we  have  developed  Self-Repairing 
Array  Structures  (SRAS),  a  hardware  technique  for 
masking hard faults in microprocessor array structures. 
We  combine  SRAS  with  DIVA,  a  cost-effective  error 
correction mechanism that incurs a performance penalty 
per error. SRAS masks faults by (a) detecting and diag-
nosing them with dedicated check rows, and (b) using a 
level of indirection to map out faulty rows. Experimen-
tal  results  show  that  the  addition  of  SRAS  to  heavily-
used buffers with a high AVF, such as the reorder buffer, 
improves performance (compared to unmodiﬁed DIVA) 
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:51:42 UTC from IEEE Xplore.  Restrictions apply. 
S
A
R
S
t
u
o
h
t
i
w
t
u
b
A
V
D
h
t
i
I
w
m
e
t
s
y
s
o
t
d
e
r
a
p
m
o
c
p
u
d
e
e
p
S
S
A
R
S
t
u
o
h
t
i
w
t
u
b
A
V
D
h
t
i
I
w
m
e
t
s
y
s
o
t
d
e
r
a
p
m
o
c
p
u
d
e
e
p
S
5
4
3
2
1
0
5
4
3
2
1
0
bzip2
crafty
eon
gap
gcc
gzip
mcf
parser
perl
twolf
vortex
vpr
SPEC 2000 Integer Benchmarks
no faults
1 fault, single bit stuck-at 1
4 faults, single bit stuck-at 1
8 faults, single bit stuck-at 1
1 fault, all bits stuck-at 1
4 faults, all bits stuck-at 1
8 faults, all bits stuck-at 1
no faults
1 fault, single bit stuck-at 1
4 faults, single bit stuck-at 1
8 faults, single bit stuck-at 1
1 fault, all bits stuck-at 1
4 faults, all bits stuck-at 1
8 faults, all bits stuck-at 1
ammp
applu
apsi
art
equake facerec fma3d galgel