so the attacker cannot predict these locations in advance. A second
strategy available to the attacker is that of brute-force memory
search. CSI renders brute-force scans impractical by distributing
code over a very large address space. As a result, the probability of
discovering a code page using a random probe is negligible.
These measures leave an attacker with only one option for ex-
amining code: reading data memory to discover code pointers, and
following these pointers to inspect code. To thwart this class of
attacks, we introduce a new technique called code pointer remapping
(CPR). CPR replaces code pointers with randomized (“encrypted”)
values scattered across a large address space. It is important to note
that these code pointer values are unrelated to the actual code locations
targeted by them. This is made possible by the “magic” of address
translation: at runtime, when an indirect control transfer instruc-
tion is executed, an “encrypted” code pointer value is translated
into the correct location for the corresponding code.
Both CSI and CPR protections are applied on all modules and
all low-level code and code pointers to prevent code reuse attacks.
Fig. 1: Architecture of SECRET. Discovered code pointers are remapped to randomized memory regions, which is not related to either original code or shadow
code. The actual instrumented code is hidden in a randomly allocated memory region with no data references to it. All code pointers are translated at runtime.
During address translation, any accesses to the address translation table are performed through a private TLS to avoid memory leaks.
Compared to existing compiler-level techniques with the same
goals [20], SECRET gains the following additional benefits due to
its ability to operate on COTS binaries:
• No changes to existing platforms: Our technique does not require
hardware support, OS support, modifications to compilation
tool chains, or recompilation of existing programs. Besides the
fact that source code is not always available, applying protec-
tions at the binary level is advantageous even for open-source
applications, since it is compatible with the current deployment
model of distributing identical binaries to every user.
• Completeness of protection: Defenses applied at the source code
level may leave hand-written assembly code unprotected. More
importantly, low-level code automatically inserted by tools such
as linkers or compilers would also be unprotected. As discussed
in previous research [19], many low-level code constructs such
as context switches could be exploited by attackers to bypass
existing defenses.
• Transparent remapping and exception-based attacks: By design,
SECRET ensures that no original code pointer points to shadow
code. Neither signals nor C++ exceptions leak code pointers.
(Signal delivery is intercepted to modify the code address on
the stack.) Both signals and C++ exceptions pose compatibility
problems or leak pointers in the case of previous techniques
such as Readactor [20].
3.1 Code Space Isolation (CSI)
Figure 1 illustrates our overall approach for protecting the original
and the instrumented code. This figure illustrates both code space
isolation, the topic of this section, and code-pointer remapping, a
topic discussed in the next section.
CSI relies on static analysis to identify data embedded within
the original code, and eliminates the rest of the code. CSI also
incorporates techniques to decouple the locations of instrumented
code from that of the original code. Decoupling is also applied to
address translation tables (specifically, LTTs) that contain pointers
to instrumented code. Finally, code that uses LTTs is implemented
in such a manner that avoids storing instrumented code addresses
in memory (other than the LTT itself). These measures turn the
instrumented code into shadow code that is designed to be outside
the attacker’s reach.
3.1.1 Identifying embedded data
To properly identify the original code, we need to identify any data
in the middle of code. To solve that problem, we have developed
a static analysis pass to identify embedded data. The goal of this
analysis is to be conservative: when in doubt, bytes should be
marked as data and preserved, rather than being erased.
There are two types of embedded data: (a) data in the middle of
functions, and (b) data between functions. The first type usually
corresponds to jump table data, so we reuse existing techniques
for jump table discovery to identify such data. For the second type
of data, we leverage the information in two sections of COTS ELF
binaries: .eh_frame and .eh_frame_header. These two sections
are generated in the DWARF format used for C++ exception handling
at runtime. Their purpose is to tell the C++ runtime how to unwind
function frames. They include information such as function bound-
aries, the position of the saved frame pointer in a stack frame (or
Original Code and Embedded Data(read only)Original DataInstrumented Code(read and executable)g:/* code wiped out */ retf’:...call lookup_callR’:g’:...jmp lookup_retELF metadatalookup_call(orig):...reg = LTT[orig]...jmp *regg’genclookup_ret(orig):...reg = LTT[orig]...jmp *regrandom distanceLocal addressTranslation Table LTTBinary Disassembly and Instrumentationframe_fRencframe_gobj:    vtable_ptr    ...Stack:Heap:Original Code Wiped Outstruct:    func *fenc    func *gencExecutable Shadow CodeR’Rencembedded dataRA LTTFP LTTf:/* %eax = &g  *//* call *%eax  */R: …User Memory●Identified code pointers remapped to different values●vtable ptr points into new dataRelocationfrom static analysisremoved after loading finishedobj_A:    vtable_ptr    ...Patch code/data ptrs at runtimeNew Data(read only)the stack height, in case the frame pointer is not available), and the
positions of callee-saved registers saved in the frame.
We have made an important observation about binaries gener-
ated from C programs, as well as several low-level binaries con-
taining assembly code: all such binaries contain .eh_frame and
.eh_frame_header sections. This is because C++ code may call non-
C++ code and vice-versa. In order to properly handle exceptions, all
function frames between the exception thrower and catcher must
be available. In our experiments these two sections were available
in all the COTS Linux binaries we have tested, including libraries
with hand-written assembly code, e.g., glibc. Over 90% of the func-
tion boundaries were identifiable using this information. For the
remaining cases, our current implementation falls back to the con-
servative binary analysis already incorporated into PSI. A better
approach would be to use some of the recent techniques [54] for
function boundary identification that achieve high accuracy.
3.1.2 Protecting shadow code
Our implementation platform places instrumented code at a mem-
ory location that follows the original code. Such an approach would
make it easy for attackers to identify the location of shadow code. To
prevent this, we redesigned the format of instrumented binaries in
SECRET to decouple the locations of the original and instrumented
code, turning instrumented code into shadow code.
To protect the shadow code in the 32-bit x86 architecture, we
use segmentation to prevent its access from non-shadow code. This
is achieved by isolating the shadow code as well as its LTT from
any other readable user memory using a sandbox implemented
by segmentation. The details of this technique are omitted since
similar approaches have also been implemented in several previous
works [4, 31, 39].
On architectures such as x86-64 where hardware segmentation
enforcement is missing, software fault isolation (SFI) [71] can be
used to protect the instrumented code, but the associated overheads
can be significant. Moreover, instrumenting all memory accesses
can be an engineering challenge due to the complexity of the x86
instruction set. We therefore opted for the alternative of base ad-
dress randomization to protect the instrumented code. The large
address space on x86-64 allows for sufficient entropy that makes
guessing attacks very difficult if not impractical.
In our implementation, the shadow code of each module is lo-
cated at a random distance from its original code. The random
distance is determined at runtime by our modified loader, and can
range over the entire address space available. The loading locations
of different modules are determined independently.
3.2 Code Pointer Remapping (CPR)
Although shadow code has been isolated and hidden from the at-
tacker, it still needs to be reachable. In particular, there will neces-
sarily be pointers within data memory (stack, heap, or static areas)
that can be used as control-flow targets. In the JIT-ROP threat
model, it is impossible to prevent attackers from simply reusing
such code pointers that they harvested by reading data memory.
In other words, one cannot block attacks consisting solely of gad-
gets beginning at harvested code pointers. However, we want to
prevent attackers from discovering additional usable gadgets from
these harvested pointers. Specifically, CPR is aimed at blocking the
following attack avenues:
(1) follow harvested code pointers to examine the shadow code
and discover additional gadgets, or
(2) use prior knowledge of the victim program’s code to compute
the locations of additional usable gadgets, e.g., by adding an
offset to a harvested code pointer value, or by repeatedly
probing several nearby locations.
CPR achieves its goal by storing only transformed code pointers
in memory. This transformation could be thought of as a crypto-
graphic hash. Since a hash function cannot be inverted, it becomes
infeasible to compute shadow code locations from the transformed
code pointers stored in memory. This blocks the first attack avenue.
For the second attack avenue, note that cryptographic hashes de-
stroy correlations between their inputs, e.g., it is not possible to
predict the hash of x + 1 given the hash of x. Thus, there is no way
for an attacker to probe “nearby” gadgets.
For performance and other reasons, our implementation does not
use a cryptographic hash. One limitation, dictated for compatibility
with C++ exception handling, is that transformed code addresses of
one function cannot be interspersed with that of another. However,
we do transform the code locations within a function into an address
space that is many orders of magnitude larger. Other than this need
to avoid interspersing different functions, the transformed address
space bears no relation to the actual locations where the target code
is stored.
The CPR implementation consists of components that operate at
instrumentation time and load time. At instrumentation time, CPR
requires the identification of all code pointer constants in a binary,
and their replacement with transformed values. Unfortunately, it is
not always feasible on binaries to determine whether a constant
represents a code pointer. As a result, a small fraction of code
pointers are not transformed. However, these pointers will point
to original code locations that have been cleared out by CSI, thus
preventing them from being used to discover the location of shadow
code.
At load-time, CPR requires changes to the system loader ld.so.
At the time of loading a module, this modified loader reserves a
range for transformed code addresses corresponding to this module.
Code pointer values in the module are updated to use values over
this address range. In order to speed up the loading process, we
generate relocation information at code instrumentation time. This
relocation information can be used by the loader to quickly fix
up the code pointers within the module so that they use these
transformed addresses.
In addition to replacing code references within the module, it
is also necessary to set up the address translation tables so that
they can map transformed code addresses into the corresponding
locations where the shadow code is loaded. Specifically, the LTT
needs to be updated so that it maps transformed code addresses
into the corresponding locations within the shadow code.
Of the two components of the CPR implementation, the instru-
mentation time component is by far the most complex, and hence
we describe it in more detail below.
3.2.1 Identifying code pointers
As discussed above, CPR requires the identification of code pointer
constants in a binary, and replacing them with a transformed ad-
dress. Clearly, such a transformation is safe only if we have very
high confidence that we are dealing with a code pointer. However,
it can be challenging to identify code pointer constants in COTS
binaries with the requisite degree of confidence. We address this
problem using a three-step approach:
• Develop static analysis techniques that are specialized for fre-
quently used code pointer categories, e.g., return addresses and
virtual functions.
• Develop a static analysis technique that can identify a subset of
remaining function pointers with a high degree of confidence.
• Develop an approach for handling possible code pointers that
are not detected in the previous two steps.
Sections 3.2.2 through 3.2.5 are devoted to the first step, while we
detail our approach for the other two steps here. In particular, for
the second step, our analysis identifies a constant as a code pointer
if (1) it is an operand of an instruction or a constant inside data
section and (2) it matches a function boundary address identified
by DWARF section. Our experiments show that all code pointers
inside SPEC benchmarks and binaries in coreutils could be correctly
identified using this simple method. It is less successful on shared
libraries.
For possible code pointers not recognized by the second step, we
leave them as is, i.e., we do not remap them. So they will continue
to point within the original code section. During address transla-
tion, these will be mapped into the corresponding locations within
shadow code. As a result, compatibility will be preserved without
leaking the location of shadow code. However, possible gadgets
beginning at un-remapped pointers remain accessible using their
original code addresses, and thus lose out the principal benefit of
CPR. Fortunately, as we show in the evaluation, the vast majority
of the pointers are remapped, so the number of gadgets accessible
are rather small.
3.2.2 Remapping return addresses
Changing return addresses has two potential implications, since
they may be used for purposes other than a return. Our experiments
have shown that all such uses fall into one of the following cases
on GNU/Linux:
• C++ exception handling: the return address is used to identify
whether the caller of the current function has a handler for the
current exception.
• Caller checking: the return address is used to determine the
• PIC data access: there are two cases: (a) jump tables, where the
return address is popped off the stack and used to compute the
base address of a jump table, and (b) static data accesses, where
the return address is popped off the stack and an offset is added
to find the base address for static data access.
source of the call. Such checks occur in the dynamic loader.
For cases where return addresses are used for C++ exception han-
dling, we update the corresponding DWARF metadata information.
This is to ensure that the stack unwinding mechanism can work cor-
rectly with randomized return addresses. In particular, we update
the DWARF information for each function by changing the func-
tion boundaries. The randomized function boundaries are currently
equally distributed in the large random region for the whole mod-
ule, but an alternative distribution that is proportional to the sizes
of the functions could also be used. Since the C++ exception han-
dling mechanism checks return addresses against their originators’
function boundaries, to make such that checking works as intended,
we must ensure that remapped return addresses still fall within
their corresponding randomized function range.
The second case we have observed occurs in the dynamic loader,
in which some internal functions check the location of callers. In
particular, they require that callers only come from libc.so or
libpthread.so. The check uses the loader’s internal data structure
link_map, which contains information about all modules. In order
to cope with this, we change the link_map data structures so that
base addresses correspond to the randomized address space. By
doing so, the remapped return addresses can be correctly identified.
In addition, to make sure all metadata can be accessed, we also
adjust other related fields in link_map, such as offsets to metadata
segments of the module. This is to ensure that our modifications
are transparent to accesses of ELF metadata sections.
For the remaining cases, we rely on a static analysis pass to detect
that the RA is being used as a data pointer, and avoid remapping it.
The analysis determines that those addresses will not be used as
part of actual return instructions (as they are popped off the stack),
and avoids including them in the list of valid targets for return
instructions.
3.2.3 Remapping C++ virtual functions
Since C++ programs on Linux follow the Itanium ABI, virtual func-
tion call sites and VTable assignments follow certain code signatures
that can be captured statically [52]. We leverage metadata of COTS
binaries, such as DWARF and runtime type identification (RTTI)1,
in combination with our static analysis, to identify VTables and
virtual function pointers. Our current implementation supports all
types of VTable recovery using RTTI, including those owned by
multi-inherited classes.
As in previous work [63], we begin by scanning read-only data
sections for the locations of the symbols __class_typeinfo,
__si_class_typeinfo, and __vmi_class_typeinfo to recover all
locations of typeinfo objects. In position-independent code (PIC),
these symbol references are available as part of the dynamic re-
location information, while in non-PIC, we identify the locations
by searching the entire section. Using these typeinfo locations,
we further scan the entire section for their references. Any loca-
tion with a valid typeinfo address preceded by a zero is the base
location of a VTable.
In case RTTI information is not available, we use static binary
analysis to reliably recover VTable locations. In particular, we detect
VTable assignment instructions using the following steps: 1) iden-
tifying constructor functions: In C++ programs, creating an object
usually requires calling a runtime function new, followed by its
constructor function where VTables are assigned (we discuss ex-
ceptional cases in Section 6). We can easily identify all call sites
1DWARF sections are mandatory for C++ programs in Linux because of exception
handling, while RTTI is optional but is by default turned on
of new (mangled names are _Znwj/_Znwm) and look into the next
call instruction that takes the return value of new as the first ar-
gument. 2) identifying all VTable assignments: We scan the code
of callee functions using a simple data flow analysis. VTable as-
signments are identified by checking the following properties: a)
a constant with a value pointing to read-only data is the source,
and b) the target location is the head of the object (first argument
of the constructor function). Due to multi-inheritance, multiple
VTable assignments may exist in one constructor. To identify all
other VTable assignments, we identify the co-appearance of their
corresponding constructor functions. A constant assignment in-
struction is a VTable assignment only if it is preceded by a call
instruction whose first argument matches the target address.
Once VTable base addresses and assignments are discovered, we
proceed to detect VTable boundaries. Note that compilers such as
gcc and llvm generate a VTable as a contiguous chunk of code
pointers. However, in practice, a VTable may be contiguous with an
adjacent VTable, rendering the boundary analysis incorrect. To deal
with this challenge, we follow the approach of previous work [52]
and conservatively scan each VTable linearly until we reach a non-
code pointer such as zero. Note that, in the code of many libraries,
several VTables may contain only zeros in the entire region. This