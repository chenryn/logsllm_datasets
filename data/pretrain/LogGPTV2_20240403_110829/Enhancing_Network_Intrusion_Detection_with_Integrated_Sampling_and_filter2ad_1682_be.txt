 174000
 176000
Time (s)
 178000
 180000
 182000
 0
 170000
 172000
 174000
 176000
Time (s)
 178000
 180000
 182000
(c) Assessed risk for a host with out-
bound alerts (3.5 hours)
(d) Assessed risk for a web server
(3.5 hours)
Fig. 7. Real-time risk assessment for a real Class C subnet (3.5 hours)
the results of the risk assessment. In this experiment, we have reused the HMM
parameters from the Lincoln Laboratory example. This allows us to compare
the performance of the model under similar circumstances. However, this is not
an optimal approach for this data set, as the parameters should be estimated
speciﬁcally for the monitored network.
5 Discussion
The network risk assessment approach presented in this paper provides a quan-
tiﬁcation of the risk level of hosts in a network. An alternative, naive approach
to this problem could involve counting alerts and assigning a value according to
the assumed impact of the alerts. A decay function could be used to facilitate
a gradual decrease in risk to avoid a non-decreasing risk situation. The method
proposed in this paper provides several advantages over the naive approach. The
primary advantage is that HMMs provide an established framework for state
estimation, modeling both the probabilities of entering certain states, as well as
the probabilities of receiving diﬀerent observations in each state, eﬀectively pro-
viding a framework for representing the false-positive and false-negative eﬀects
of IDSs. The state modeling and transition probabilities can also be related to
traditional risk assessment methodologies. Finally, the use of learning algorithms
and parameter re-estimation can be employed to tune the system automatically.
Using Hidden Markov Models to Evaluate the Risks of Intrusions
161
G
P
A
C
Fig. 8. A left-right HMM
Note that we model the security state of a system; we do not attempt to
model individual attacks or attackers. One limitation of the approach is that
an attacker with knowledge of the HMMs used could attempt to camouﬂage a
successful compromise by subsequently causing a number of less serious alerts.
Depending on the HMMs used, this could lead to a misrepresentation of the risk
level of the system.
The HMMs used in this paper are fully connected, in that every state of the
model can be reached in a single step from every other state of the model [13].
It is possible to use other types of HMMs, such as the left-right models. These
models can, for example, be used if one wants to model the compromised state
as consuming; i.e., that the probability of being in state C never decreases. Fig. 8
shows an example of a left-right HMM, which only allows transitions from left to
right; i.e., to more security critical states. If there is a steady input of alerts, the
risk of a system modeled with this HMM will tend to approach the maximum
risk for the system.
Although the experiments in this paper were run in an oﬀ-line mode, we
believe that the method is capable of handling alerts in real-time. The 3.5 hour
Lincoln Laboratory data set was processed in 2 minutes 44 seconds, while the
3 day TU Vienna data set was processed in 20 minutes 54 seconds. Even with
signiﬁcantly smaller time intervals, the model would still be able to process alerts
on a single host in real-time for multiple class C networks.
6 Related Work
Research in risk assessment and risk management has traditionally focused on
the development of methods, tools, and standards for risk assessment. Two com-
monly recommended references for risk management are [14] and [15]. Method-
ologies, such as Coras [2] and Morda [5], have been developed to support the
risk assessment process. This paper complements these approaches by performing
risk assessment in real-time based on an initial estimation of model parameters
representing the probabilities of diﬀerent security states. A real-time risk assess-
ment method has previously been proposed by [6]. However, that approach is
limited to risk assessment for individual hosts.
A number of diﬀerent approaches that perform alert prioritization have been
proposed. In [12] Porras et al. present a model that takes into account the im-
pact of alerts on the overall mission that a network infrastructure supports. This
approach relies on a knowledge base that describes the security-relevant char-
acteristics of the protected network in order to prioritize the alerts. Other alert
162
A. ˚Arnes et al.
prioritization systems [4,7,9] perform alert veriﬁcation. These systems assign a
higher priority to alerts that are veriﬁed as true attacks, while alerts that are de-
termined to be false positives are given a low priority. Alert veriﬁcation systems
operate either oﬄine or online. Oﬄine systems perform periodic vulnerability
scans of the protected network and store the result in a database. Alerts are
veriﬁed by checking if the vulnerabilities that the alerts refer to are present on
the attacked hosts. Online alert veriﬁcation systems operate in a similar way,
but no database is kept. Instead, vulnerability scanning is performed on-demand
when alerts are received by the system [10].
7 Conclusions and Future Work
We have presented an approach to real-time network risk assessment that de-
termines the risk level of a network as the composition of the risks of individual
hosts, providing a precise and ﬁne-grained model for risk assessment. The model
is probabilistic and uses Hidden Markov Models to represent the likelihood of
transitions between security states. We have tightly integrated the risk assess-
ment approach with the STAT framework and have used results of the risk
assessment to prioritize the IDS alerts. Finally, we have evaluated the approach
using both simulated and real-world data.
An important limitation of this approach is the need for model parameter
estimation. The parameters for our experiments were estimated manually. This
is a time-consuming task with inherent uncertainties. We plan to investigate the
use of training algorithms to estimate the model parameters
For the experiments in this paper we did not take into consideration dependen-
cies between hosts. Doing this would give a more accurate overview of network
risk and better model the consequences of security incidents relating to assets
inside a network. For example, if a host on the inside of a network is compro-
mised, this should increase the risk level of other hosts within the network as
well. We plan to include inter-host dependencies in our future experiments.
A general framework for handling multiple sensors can be implemented by
representing each of the sensors monitoring a host with an HMM. In this way,
each sensor can be assigned a separate observation probability matrix Q. The
state estimation can be performed on behalf of each of the sensors, while the
risk for a host is computed as a function of the state estimates of all the relevant
sensors. This will be implemented in the next version of the system.
We have performed experiments using real-traﬃc data in an oﬀ-line mode,
but we have not yet tested the system on-line with live traﬃc. This will be done
as part of the future work.
Acknowledgments
This research was supported by the U.S.– Norway Fulbright Foundation for
Educational Exchange, by the U.S. Army Research Oﬃce, under agreement
DAAD19-01-1-0484, and by the National Science Foundation, under grants CCR-
0238492 and CCR-0524853. The “Centre for Quantiﬁable Quality of Service in
Using Hidden Markov Models to Evaluate the Risks of Intrusions
163
Communication Systems, Centre of Excellence” is appointed by The Research
Council of Norway, and funded by the Research Council, NTNU and UNINETT.
References
1. Andr´e ˚Arnes, Karin Sallhammar, Kjetil Haslum, Tønnes Brekne, Marie Elisa-
beth Gaup Moe, and Svein Johan Knapskog. Real-time risk assessment with
network sensors and intrusion detection systems. In International Conference on
Computational Intelligence and Security (CIS 2005), 2005.
2. CORAS IST-2000-25031 Web Site, 2003. http://www.nr.no/coras.
3. Herv´e Debar, David A. Curry, and Benjamin S. Feinstein.
Intrusion detection
message exchange format (IDMEF) – internet-draft, 2005.
4. Neil Desai.
IDS correlation of VA data and IDS alerts.
securityfocus.com/infocus/1708, June 2003.
http://www.
5. Shelby Evans, David Heinbuch, Elizabeth Kyule, John Piorkowski, and James Wall-
ner. Risk-based systems security engineering: Stopping attacks with intention.
IEEE Security and Privacy, 02(6):59 – 62, 2004.
6. Ashish Gehani and Gershon Kedem. Rheostat: Real-time risk management. In
Recent Advances in Intrusion Detection: 7th International Symposium, (RAID
2004), Sophia Antipolis, France, September 15-17, 2004. Proceedings, pages 296–
314. Springer, 2004.
7. Ron Gula. Correlating ids alerts with vulnerability information. Technical report,
Tenable Network Security, December 2002.
8. Cristopher Kruegel, Engin Kirda, Darren Mutz, William Robertson, and Giovanni
Vigna. Polymorphic worm detection using structural information of executables. In
Proceedings of the International Symposium on Recent Advances in Intrusion De-
tection (RAID 2005), volume 3858 of LNCS, pages 207–226, Seattle, WA, Septem-
ber 2005. Springer-Verlag.
9. Cristopher Kruegel and William Robertson. Alert veriﬁcation: Determining the
In Proceedings of the 1st Workshop on the De-
success of intrusion attempts.
tection of Intrusions and Malware and Vulnerability Assessment (DIMVA 2004),
Dortmund, Germany, July 2004.
10. Cristopher Kruegel, William Robertson, and Giovanni Vigna. Using alert veriﬁca-
tion to identify successful intrusion attempts. Practice in Information Processing
and Communication (PIK 2004), 27(4):219 – 227, October – December 2004.
11. Lincoln Laboratory.
Lincoln laboratory
scenario
(DDoS)
1.0,
2000.
http://www.ll.mit.edu/SST/ideval/data/2000/LLS DDOS 1.0.html.
12. Phillip A. Porras, Martin W. Fong, and Alfonso Valdes. A mission-impact-based
approach to infosec alarm correlation. In Proceedings of the International Sympo-
sium on the Recent Advances in Intrusion Detection (RAID 2002), pages 95–114,
Zurich, Switzerland, October 2002.
13. Lawrence R. Rabiner. A tutorial on hidden markov models and selected applica-
tions in speech recognition. Readings in speech recognition, pages 267–296, 1990.
14. Standards Australia and Standards New Zealand. AS/NZS 4360: 2004 risk man-
agement, 2004.
15. Gary Stonebumer, Alice Goguen, and Alexis Feringa.
Risk management
guide for information technology systems, special publication 800-30, 2002.
http://csrc.nist.gov/publications/nistpubs/800-30/sp800-30.pdf.
164
A. ˚Arnes et al.
16. Sun Microsystems, Inc. Installing, Administering, and Using the Basic Security
Module. 2550 Garcia Ave., Mountain View, CA 94043, December 1991.
17. Giovanni Vigna, Richard A. Kemmerer, and Per Blix. Designing a web of highly-
conﬁgurable intrusion detection sensors. In W. Lee, L. M`e, and A. Wespi, editors,
Proceedings of the 4th International Symposium on Recent Advances in Intrusion
Detection (RAID 2001), volume 2212 of LNCS, pages 69–84, Davis, CA, October
2001. Springer-Verlag.
18. Giovanni Vigna, Fredrik Valeur, and Richard Kemmerer. Designing and implement-
ing a family of intrusion detection systems. In Proceedings of European Software
Engineering Conference and ACM SIGSOFT Symposium on the Foundations of
Software Engineering (ESEC/FSE 2003), Helsinki, Finland, September 2003.
The Nepenthes Platform: An Eﬃcient Approach
to Collect Malware
Paul Baecher1, Markus Koetter1, Thorsten Holz2, Maximillian Dornseif2,
and Felix Freiling2
1 Nepenthes Development Team
PI:EMAIL
2 University of Mannheim
Laboratory for Dependable Distributed Systems
{holz, dornseif, freiling}@informatik.uni-mannheim.de
Abstract. Up to now, there is little empirically backed quantitative and
qualitative knowledge about self-replicating malware publicly available.
This hampers research in these topics because many counter-strategies
against malware, e.g., network- and host-based intrusion detection sys-
tems, need hard empirical data to take full eﬀect.
We present the nepenthes platform, a framework for large-scale col-
lection of information on self-replicating malware in the wild. The basic
principle of nepenthes is to emulate only the vulnerable parts of a ser-
vice. This leads to an eﬃcient and eﬀective solution that oﬀers many
advantages compared to other honeypot-based solutions. Furthermore,
nepenthes oﬀers a ﬂexible deployment solution, leading to even better
scalability. Using the nepenthes platform we and several other organiza-
tions were able to greatly broaden the empirical basis of data available
about self-replicating malware and provide thousands of samples of pre-
viously unknown malware to vendors of host-based IDS/anti-virus sys-
tems. This greatly improves the detection rate of this kind of threat.
Keywords: Honeypots, Intrusion Detection Systems, Malware.
1 Introduction
Automated Malware Collection. Software artifacts that serve malicious purposes
are usually termed as malware. Particularly menacing is malware that spreads
automatically over the network from machine to machine by exploiting known
or unknown vulnerabilities. Such malware is not only a constant threat to the
integrity of individual computers on the Internet. In the form of botnets for
example that can bring down almost any server through distributed denial of
service, the combined power of many compromised machines is a constant danger
even to uninfected sites.
We describe here an approach to collect malware. Why should this be done?
There are two main reasons, both following the motto “know your enemy”:
First of all, investigating individual pieces of malware allows better defences
against these and similar artifacts. For example, intrusion detection and anti-
virus systems can reﬁne their list of signatures against which ﬁles and network
D. Zamboni and C. Kruegel (Eds.): RAID 2006, LNCS 4219, pp. 165–184, 2006.
c(cid:1) Springer-Verlag Berlin Heidelberg 2006
166
P. Baecher et al.
traﬃc are matched. In general, the better and more we know about what malware
is currently spreading in the wild, the better can our defenses be. The second
reason why we should collect malware is that, if we do it in a large scale, we
can generate statistics to learn more about attack patterns, attack trends, and
attack rates of malicious network traﬃc today, based on live and authentic data.
Collecting malware in the wild and analyzing it is not an easy task. In prac-
tice, much malware is collected and analyzed by detailed forensic examinations
of infected machines. The actual malware needs to be dissected from the compro-
mised machine by hand. With the increasing birth rate of new malware this can
only be done for a small proportion of system compromises. Also, sophisticated
worms and viruses spread so fast today that hand-controlled human intervention
is almost always too late. In both cases we need a very high degree of automation
to handle these issues.
Honeypot technology. The main tool to collect malware in an automated fashion
today are so-called honeypots. A honeypot is an information system resource
whose value lies in unauthorized or illicit use of that resource. The idea behind
this methodology is to lure in attackers such as automated malware and then
study them in detail. Honeypots have proven to be a very eﬀective tool in learning
more about Internet crime like credit card fraud [10] or botnets [6]. The literature
distinguishes two general types of honeypots:
– Low-interaction honeypots oﬀer limited services to the attacker. They em-
ulate services or operating systems and the level of interaction varies with
the implementation. The risk tends to be very low. In addition, deploying
and maintaining these honeypots tends to be easy. A popular example of this
kind of honeypots is honeyd [14]. With the help of low-interaction honeypots,
it is possible to learn more about attack patterns and attacker behavior.
– High-interaction honeypots oﬀer the attacker a real system to interact with.
More risk is involved when deploying a high-interaction honeypot, e.g., spe-
cial provisions are done to prevent attacks against system that are not in-
volved in the setup. They are normally more complex to setup and maintain.
The most common setup for this kind of honeypots is a GenIII honeynet [3].
Low-interaction honeypots entail less risks than high-interaction ones. In ad-
dition, deploying and maintaining low-interaction honeypots tends to be easy,
at least much easier than running high-interaction honeypots, since less special
provisions have to be done to prevent attacks against the system that runs the
honeypot software. However, high-interaction honeypots still allow us to study
attackers in more detail and learn more about the actual proceeding of attack-
ers than low-interaction honeypots. The diﬀerences between low-interaction and
high-interaction honeypots manifest a tradeoﬀ: high-interaction honeypots are
expressive, i.e., they oﬀer full system functionality which is in general not sup-
ported by low-interaction honeypots. However, low-interaction honeypots are
much more scalable, i.e., it is much easier and less resource-intensive to deploy
them in a large-scale.
The Nepenthes Platform: An Eﬃcient Approach to Collect Malware
167
Contribution. In this paper we introduce nepenthes, a new type of honeypot that
inherits the scalability of low-interaction honeypots but at the same time oﬀers
a high degree of expressiveness. Nepenthes is not a honeypot per se but rather
a platform to deploy honeypot modules (called vulnerability modules). This is
the key to increased expressiveness: Vulnerability modules oﬀer a highly ﬂexible
way to conﬁgure nepenthes into a honeypot for many diﬀerent types of vulner-
abilities. In classical terms, nepenthes still realizes a low-interaction honeypot
since it emulates the vulnerable services. However, as we argue in this paper,
emulation and the knowledge about the expected attacker behavior is the key
to automation. Furthermore, the ﬂexibility of nepenthes allows to deploy unique
features not available in high-interaction honeypots. For example, it is possible