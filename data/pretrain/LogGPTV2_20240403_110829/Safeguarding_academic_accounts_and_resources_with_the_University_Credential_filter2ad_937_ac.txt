matches our intuition that a signiﬁcant proportion of il-
legitimate activity was linked to library access that has
a coefﬁcient of 3.53, while legitimate users accessed the
web mail, course portal, and other academic websites more
frequently.
Finally, Fig. 3 shows the performance evaluation of
proﬁle-based features. The complementary cumulative dis-
tributions of proﬁle ﬁtness for the different features indicate
Institution
UofM
Website
Library
Web Mail
Course Portal
Remote Desktop
File Storage
% of benign
5.83%
34.63%
5.93%
1.39%
1.22%
% of compromised
44.66%
28.72%
0.78%
0
0
Table V
DISTRIBUTION OF TLDS
DISTRIBUTION OF WEBSITES VISITED AT UOFM
Table VIII
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:52 UTC from IEEE Xplore.  Restrictions apply. 
(a) Country code.
(b) ASN.
(c) Domain.
(d) Day of the week.
(f) Resource Usage.
Figure 3. Complementary cumulative distribution function of proﬁle ﬁtness for benign and compromised accounts.
(e) Time of the day.
that IP-related proﬁle features (country code, ASN, and
domain name) are effective in differentiating legitimate from
illegitimate activity. However, timing and resource-related
features provided poor performance, since the proﬁles col-
lected for the benign and compromised groups of accounts
are indistinguishable.
C. Model Evaluation
To evaluate the model, we conducted a cross-validation,
which is the traditional technique for evaluating machine-
learning algorithms. Given the limited number of positives,
we use a ﬁvefold cross-validation to ensure an adequate
number of positive samples in each set. Since each user may
have multiple feature vectors corresponding to multiple days,
we grouped the feature vectors by user before partitioning
the dataset. By doing so, we prevented artiﬁcially good
results by removing situations in which different feature
vectors were recorded in the training set and the evaluation
set for the same user.
An important parameter to choose is the length of the
training window. In Fig. 4, we show the detection results
collected from ﬁve training window sizes. As mentioned
before, our goal is to limit the average daily number of
false alarms to two. Since UCAAS analyzes about 1,000
unique users per day, we need to achieve a false positive rate
(FPR) less than or equal to 0.2%. Under that requirement,
the best true positive rates (TPRs) that the system achieved
was 95.4% at UofM with a training window of 11 days, and
100% at UIUC with a training window of 9 or 11 days.
D. Empirical Evaluation
We conducted the empirical evaluation by building a
model from the training set that was then used to classify
the validation set. At UofM, during two weeks starting from
September 14, 2011, 126 unique users who never appeared
in the training set were ﬂagged. 124 of them were validated
by the security team as compromised. The remaining 2
accounts had been shared with family members or friends
living in foreign countries. Those results exceeded our
expectations, since none of the ﬂagged accounts were false
positives. Also, there were no compromised accounts that
were detected in other ways but not detected by UCAAS.
Therefore, we can conclude that UCAAS achieves better
detection recall
than any other existing methods in the
university.
At UIUC, we conducted the empirical experiment by
running UCAAS on the validation dataset collected from
July 9 to July 23, 2011. A total of 11 alerts were produced,
reﬂecting 10 accounts already labeled for illegitimate activ-
ity in the training set. They appeared here again because
those accounts were still compromised when the validation
set was collected. The ﬂagged account that was not part of
the training set was validated as a true positive. These results
are encouraging, because no false positive was generated
and a new compromised account was discovered. We also
checked with the security team to conﬁrm that the system did
not miss a compromised account reported during this period.
However, because we collected the validation set at UIUC
very close to the time we collected the training set , the
lack of newly compromised accounts limits our conclusions
regarding the overall accuracy of UCAAS at UIUC. The
fact that UIUC has 10 times fewer active accounts than
UofM likely plays an important role in explaining the large
difference between the numbers of compromised accounts
at the two universities. As mentioned in Section II, the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:52 UTC from IEEE Xplore.  Restrictions apply. 
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1CCDFFitnessUofM Benign AccountsUofM Compromised AccountsUIUC Benign AccountsUIUC Compromised Accounts 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0 0.2 0.4 0.6 0.8 1CCDFFitnessUofM Benign AccountsUofM Compromised AccountsUIUC Benign AccountsUIUC Compromised Accounts 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0 0.2 0.4 0.6 0.8 1CCDFFitnessUofM Benign AccountsUofM Compromised AccountsUIUC Benign AccountsUIUC Compromised Accounts 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0 0.2 0.4 0.6 0.8 1CCDFFitnessUofM Benign AccountsUofM Compromised AccountsUIUC Benign AccountsUIUC Compromised Accounts 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1CCDFFitnessUofM Benign AccountsUofM Compromised AccountsUIUC Benign AccountsUIUC Compromised Accounts 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1CCDFFitnessUofM Benign AccountsUofM Compromised AccountsUIUC Benign AccountsUIUC Compromised Accounts(a) UofM.
(b) UIUC.
Figure 4. ROC curves.
difference in the number of active accounts is due to the
difference in account expiration rules. Indeed, we found that
half of the 124 compromised accounts detected at UofM
were alumni or former employee accounts. In conclusion,
results at both universities revealed excellent performance.
We were surprised to see that at UofM, the model built in
June offered perfect accuracy on September-October data,
indicating that it remained effective even after a few months.
E. Lessons Learned
We learned that the temporal-spatial violation feature was
the main reason for false positives generated during initial
testing phases. The incorrect violations were due to three
types of events: 1) users connected through more than one
VPN client, 2) users accessing campus services via remote
desktops, and 3) imprecise geolocation information.
The ﬁrst
two issues were mitigated by the fact
that
our approach combines complementary sets of features. A
temporal-spatial violation has to be associated with addi-
tional suspicious behavior captured by other features to raise
an alert. To address the last issue, of unreliable geolocation,
we revised location-related features to work at the country
level rather than the city level, and use a GeoIP database [8]
that is accurate enough at the country level. However, we
observed that attackers who own credentials from multiple
institutions can login to one university account via the
VPN of another university. By doing so,
they can hide
geographic location information and evade our detection
method. Therefore, the city-level geolocation information
is essential to covering those cases. As future work, we
plan to integrate better geolocation lookup approaches [9]
to increase the robustness of UCAAS.
V. RELATED WORK
Research efforts that have tried to understand the targets of
account theft through botnet takeover [3] or phishing target
analysis [2] pointed out that attackers are mostly attracted
by ﬁnancial and payment systems, since their credentials can
be directly linked to monetary gains. The main difference
with compromised university accounts is that users can
easily spot illegitimate transactions, since they have access
to the history of account activity. However, compromised
university accounts can be used stealthily for months or
even years without being noticed by users. Therefore, a
centralized compromised accounts assessment system is crit-
ical for academic institutions. In [10], the authors analyzed
credential-stealing attacks at UIUC based on forensic data
collected over ﬁve years. The results showed that attackers
not only accessed university resources with the compromised
credentials, but also harvested additional accounts and re-
sources by exploiting vulnerabilities. They concluded that
boundary protections (e.g., ﬁrewalls) are insufﬁcient for this
threat, and that institutions need sophisticated user action
monitoring systems.
Various statistical methods have been successfully ap-
plied to detection of fraudulent activities in other secu-
rity domains. For different applications, the detection tools
vary because of the nature of the problems as well as
the diversiﬁed data types [5]. Applications include credit
card fraud detection [11], [12], [13], telecommunications
fraud detection [14], [15], [16], and intrusion detection
systems [17], [18], [19]. Another interesting security area
in which machine-learning methods are heavily used is that
of malicious domain and URL detection [20], [21], [22],
where features such as lexical or network features are used
to distinguish malicious domains and URLs.
Our approach follows the general methods of anomaly
and fraud detection, by which we extract a set of features
and apply a statistical model to detect suspicious activities.
We note that our work addresses the additional challenge
of open university environments with very diversiﬁed user
behavior. The work we found most related to ours is a case
study on anomaly detection for VPN [23]. The purpose of
the study was to identify suspicious authentication activities
through clustering, and geographic distance was used as the
main feature. Our work signiﬁcantly extends that approach
by extracting a larger set of features and analyzing them au-
tomatically so that only a minimal manual effort is required.
VI. CONCLUSION
Large academic institutions are exposed to the difﬁcult
challenge of protecting user accounts while supporting a
wide set of services with limited security resources. This
paper presents the University Credential Abuse Auditing
System (UCAAS), a machine-learning approach for au-
tomatic detection of account compromises that abuse the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:52 UTC from IEEE Xplore.  Restrictions apply. 
 0.915 0.92 0.925 0.93 0.935 0.94 0.945 0.95 0.955 0.96 0.965 0.97 0.001 0.0015 0.002 0.0025 0.003 0.0035 0.004 0.0045 0.005True Positive RateFalse Positive Rate3 days window5 days window7 days window9 days window11 days window13 days window 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 0 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008True Positive RateFalse Positive Rate3 days window5 days window7 days window9 days window11 days window13 days windowVPN service. It considers a large set of automatically
generated features. These features are evaluated on their
ability to identify illegitimate behavior. A logistic regression
classiﬁer is then used to ﬂag accounts that are likely to
be compromised. The system was trained and evaluated
across two large universities and has been used by the
operations team to identify a total of 125 compromised
accounts in our two-week trial. Empirical validation shows
that UCAAS offers high detection accuracy with no false
positives across the two universities. This work is the result
of an extensive collaboration, not only between researchers
at two different institutions, but also between researchers
and security analysts who deal with the issue of account
compromise on a daily basis.
ACKNOWLEDGMENT
We wish to thank Paul Howell, who is the chief infor-
mation technology security ofﬁcer at UofM, for support in
data collection and access, discussion, and result validation.
We are also grateful
to the security team at UIUC for
their help; we particularly wish to thank Michael Corn,
Vlad Grigorescu, Warren Raquel, and Bill Gambardella. We
would also like to thank Carol Livingstone from the Division
of Management Information at UIUC for her support in
collecting and analyzing the demographic dataset.
This project has been sponsored at UIUC by the Air Force
Research Laboratory (AFRL), and we are thankful for the
support of Patrick Hurley. This work was supported at UofM
in part by the Department of Homeland Security (DHS)
under contract number NBCHC080037, by the National
Science Foundation (NSF) under contract numbers CNS
1111699, CNS 091639, CNS 08311174, and CNS 0751116,
and by the Department of the Navy under contract N000.14-
09-1-1042. Any opinions, ﬁndings, and conclusions or rec-
ommendations expressed in this material are those of the
authors and do not necessarily reﬂect
the views of the
National Science Foundation.
REFERENCES
[1] Trend Micro, “Data-stealing malware on the rise: Solutions
to keep businesses and consumers safe,” http://us. trendmicro.
com/imperia/md/content/us/pdf/threats/securitylibrary/, 2009.
[2] Anti-Phishing Working Group, “Phishing activity trends re-
port,” http://www.antiphishing.org/phishReportsArchive.html,
2010.
[3] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert, M. Szyd-
lowski, R. Kemmerer, C. Kruegel, and G. Vigna, “Your botnet
is my botnet: Analysis of a botnet takeover,” in Proc. of
the 16th ACM Conference on Computer and Communications
Security, 2009, pp. 635–647.
[4] J.
Young,
stop
R.
efforts
http://chronicle.com/article/Academic-Publisher-Steps-
Up/128031, 2011.
“Academic
piracy
of
publisher
its
online
to
steps
up
products,”
[5] R. J. Bolton and D. J. H, “Statistical fraud detection: A
review,” Statistical Science, vol. 17, pp. 235–249, 2002.
[6] “Weka 3 - Data Mining with Open Source Machine Learning
Software,” http://www.cs.waikato.ac.nz/ml/weka/.
[7] J. G. Orme and T. Combs-Orme, Multiple Regression with
Oxford University Press,
Discrete Dependent Variables.
2009.
[8] MaxMind.
http://www.maxmind.com/app/ip-location, 2011.
[9] Y. Wang, D. Burgener, M. Flores, A. Kuzmanovic, and
C. Huang, “Towards street-level client-independent IP geolo-
cation,” in Proc. of the 8th USENIX Symposium on Networked
Systems Design and Implementation, Mar. 2011.
[10] A. Sharma, Z. Kalbarczyk, R. Iyer, and J. Barlow, “Analysis
of credential stealing attacks in an open networked environ-
ment,” in Proc. of the Fourth International Conference on
Network and System Security. Washington, DC, USA: IEEE
Computer Society, 2010, pp. 144–151.
[11] E. Aleskerov, B. Freisleben, and B. Rao, “Cardwatch: A
neural network based database mining system for credit card
fraud detection,” Proc. of the IEEE IAFE 1997 conference
on Computational Intelligence for Financial Engineering, pp.
220–226, 1997.
[12] S. Panigrahi, A. Kundu, S. Sural, and A. K. Majum-
dar, “Credit card fraud detection: A fusion approach using
Dempster-Shafer theory and Bayesian learning,” Inf. Fusion,
vol. 10, pp. 354–363, Oct. 2009.
[13] R. Chen, T. Chen, Y. Chien, and Y. Yang, “Novel
questionnaire-responded transaction approach with SVM for
credit card fraud detection,” in Proc. of the 2nd International
Conference on Advances in Neural Networks, vol. 2, 2005,
pp. 916–921.
[14] D. Agarwal, “An empirical Bayes approach to detect anoma-
lies in dynamic multidimensional arrays,” in Proc. of the
Fifth IEEE International Conference on Data Mining.
IEEE
Computer Society, 2005, pp. 26–33.
[15] K. C. Cox, S. G. Eick, G. J. Wills, and R. J. Brachman,
“Visual data mining: Recognizing telephone calling fraud,”
Data Mining and Knowledge Discovery, vol. 1, pp. 225–231,
1997.
[16] C. Phua, D. Alahakoon, and V. Lee, “Minority report in fraud
detection: Classiﬁcation of skewed data,” SIGKDD Explor.
Newsl., vol. 6, no. 1, pp. 50–59, 2004.
[17] F. Esponda, S. Forrest, and P. Helman, “A formal framework
for positive and negative detection schemes,” IEEE Transac-
tions on Systems, Man, and Cybernetics, Part B: Cybernetics,
vol. 34, no. 1, pp. 357–373, 2004.
[18] K. A. Heller, K. M. Svore, A. D. Keromytis, and S. J. Stolfo,
“One class support vector machines for detecting anomalous
windows registry accesses,” in Proc. of the Workshop on Data
Mining for Computer Security, 2003.
[19] J. D. Brutlag, “Aberrant behavior detection in time series for
network monitoring,” Proc. of the 14th Systems Administra-
tion Conference (LISA 2000), Dec. 2000.
[20] C. Whittaker, B. Ryner, and M. Nazif, “Large-scale automatic
classiﬁcation of phishing pages,” in Proc. of 17th Annual
Network and Distributed System Security Symposium, 2010.
[21] M. Antonakakis, R. Perdisci, W. Lee, V. Nikolaos, and
D. Dagon, “Detecting malware domains at the upper DNS
hierarchy,” pp. 1–16, 2011.
[22] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker, “Beyond
blacklists: Learning to detect malicious web sites from sus-
picious URLs,” in Proc. of the SIGKDD Conference., 2009.
[23] M. Chapple, N. Chawla, and A. Striegel, “Authentication
anomaly detection: A case study on a virtual private network,”
in Proc. of the 3rd Annual ACM Workshop on Mining Network
Data. New York, NY, USA: ACM, 2007, pp. 17–22.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:52 UTC from IEEE Xplore.  Restrictions apply.