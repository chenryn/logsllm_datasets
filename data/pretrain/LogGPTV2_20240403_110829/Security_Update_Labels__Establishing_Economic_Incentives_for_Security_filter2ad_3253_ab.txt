current state of the vulnerability handling to the affected
consumers and policy-enforcing entities. The design of such
a reporting platform could follow the proposal of the Centre
for European Policy Studies [12, p.56] and is out of scope
of this paper. Procedures could be implemented based on the
established standards for responsible vulnerability disclosure,
e.g., ISO/IEC 29147 [48], and vulnerability handling, e.g.,
ISO/IEC 30111 [49]. When a suspected security vulnerability
is found, the reporting entity ﬁles a vulnerability report via this
platform, which in turn informs the affected manufacturers.
After receiving the vulnerability report, the time-to-patch clock
starts and the manufacturer investigates whether the vulnera-
bility can be reproduced. If the manufacturer concludes that
the reported vulnerability is an actual security ﬂaw, a security
patch shall be developed and provided within the guaranteed
provisioning time. We propose that consumers have a right to
compensation in the following cases:
• The manufacturer does not provide a required security patch
within the guaranteed provisioning time.
• The manufacturer provides a security patch, but the patch
does not ﬁx the bug, introduces other security problems, or
has serious effects on the performance of the product.
For the cases of disputes about the effectiveness of provided
updates or whether a bug requires a security patch, policy-
makers should establish an entity that enforces accountability,
judges the claims of the consumers, protects vulnerability
reporters, and has the power to sanction manufacturers, simi-
larly to the sanctions imposed by the General Data Protection
Regulations (GDPR) in the EU [50, Art.58].
D. Concerns towards Security Update Labels
The proposal of security update labels might raise the
following concerns.
1) Ineffectiveness: Some security vulnerabilities cannot be
patched with updates. For example, a security ﬂaw in the spec-
iﬁcation of an interconnected system might demand changes in
other components that are not maintained by the manufacturer,
or the hardware platform of the affected product cannot
support the patched software due to memory or computational
power constraints. In this case, the proposed label strengthens
consumer rights as the consumer is entitled to compensation.
2) Misuse: Manufacturers might be motivated to spend
even less resources on security of their products before re-
leasing them. They might decide that they always can patch
the product within a certain timeframe, which means that they
simply could outsource the debugging of their products to
the consumers. We believe that such behavior would damage
the user acceptance and the brand image. Furthermore, this
practice would lead to a high pressure on the manufacturers
to deliver numerous security patches within limited time.
In another scenario, manufacturers might try to transfer the
liability regarding their products to offshore companies. These
scenarios should be considered when deﬁning the legislation.
3) Low User Acceptance: The security update labels could
fail as they might not have the expected effect on consumers’
buying decisions. Prior user studies [51]–[54] outline that
consumers tend to be reluctant towards the installation of
updates. This behavior results from a lack of clarity about
the usefulness of updates as well as from negative update
experiences in the past, such as unwanted changes in user
interfaces or in functionality. In consequence,
the attitude
towards security updates is affected as users typically do not
differentiate between different types of updates. Therefore,
security update labels could have a low user acceptance.
Potential moral hazard [55] could also lead to a low user
acceptance. In our context, this means that users might not
be willing to pay a price premium to protect against security
vulnerabilities that will not affect them. An illustration are
the attacks by the Mirai botnet [7], in which thousands of
IoT consumer products deployed in Latin America attacked
US-based Internet services. In this case, why would a Latin-
American consumer pay a price premium for a security update
guarantee that protects US businesses?
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:38 UTC from IEEE Xplore.  Restrictions apply. 
432
The concerns of ineffectiveness and potential misuse de-
pend on the legislation and business decisions of particular
manufacturers. We leave the investigation of these concerns
to future work. In the following, we investigate the concern
of low user acceptance by means of a user study.
IV. CONCEPT OF USER STUDY
If security update labels turn out
to be important for
consumers’ buying decisions,
this would create economic
incentives for manufacturers to guarantee the timely patching
of security vulnerabilities in their IoT products. Therefore, we
consider the following research questions:
RQ1 What is the relative importance of the availability pe-
riod and provisioning time for security updates for buying
decisions compared to other product attributes?
RQ2 Are there differences in the relative importance of the
availability period and provisioning time for security up-
dates between products with a high perceived security risk
compared to products with a low perceived security risk?
RQ3 Are there differences in the relative importance of the
availability and provisioning time for security updates ac-
cording to demographic characteristics of the consumers?
RQ4 Are there differences in the relative importance of the
availability and provisioning time for security updates de-
pending on security behavior intentions, privacy concerns,
and security risk perception of the consumers?
In the following, we investigate these research questions for
German consumers by means of a user study. Germany has the
largest consumer market within the EU, and the fourth largest
consumer market worldwide after USA, China, and Japan [56].
Structure of the User Study: We utilize conjoint analysis, as
this method is well suited for our objectives (cf. Section II-C):
We aim to determine the inﬂuence of the availability period
and provisioning time attributes on consumers’ choices. This
includes whether these attributes are desired at all (i.e., do con-
sumers care about the availability of security updates?), and
which attribute levels are more attractive (i.e., do consumers
favor short provisioning time or long availability periods?).
To answer the research questions, we needed to choose
product categories that differ in the perceived security risk. We
decided on two product categories as this number is sufﬁcient
to answer the research questions: one with a high perceived
security risk as well as one with a low perceived security risk.
The user study followed a three-stage approach as shown in
Figure 1: In the ﬁrst stage (Prestudy 1), two suitable product
categories were selected. In the second stage (Prestudy 2),
we determined the most important product attributes and their
levels for each of the two product categories. In the third stage
(Conjoint Analysis), we assessed the consumers’ preferences
(RQ1), comparing the attributes of the security update label
with other important product attributes. Finally, we validated
the preference model, compared the product categories (RQ2),
and performed a segmentation analysis (RQ3, RQ4).
Ethics and Recruitment: The study design was approved
by the data protection ofﬁce of our university. All data was
Fig. 1: Structure of user study.
processed in accordance with the German data protection
laws and all survey answers were pseudonymized. The online
surveys were hosted on a web server that is provided by our
university, and secured such that only authorized entities have
access to the collected data. The respondents for the online
surveys were recruited at an online crowdworker platform, as
prior work showed that such samples are appropriate for secu-
rity research [57]. We used the Clickworker.de platform [58],
which claims to have the largest crowd of German-speaking
workers. For all online surveys, we selected the respondents
with following characteristics: all genders, age between 18 and
65, and Germany as country of residence. The crowdworkers
were paid according to the German minimum wage of e8.84
per hour.
Translation of Psychometric Scales: As we run our surveys
with German-speaking respondents, we translated all items of
utilized English psychometric scales. These scales measure,
e.g., privacy concerns [59] or security behavior intentions [60].
To ensure a reliable translation, we utilized a methodology
proposed by Venkatesh et al. [61]. Three bilingual domain
experts translated the English scales into German individually.
Then, the experts discussed differences in their translations and
agreed on a single ﬁnal version. Finally, three other persons
(an English native speaker, a professional translator, and a
German who lived for several years in the UK) retranslated
the German scales back into the original language. Through
verifying that
the original scales matched the retranslated
scales semantically, the translation was considered successful.
Statistical Data Analysis: We denote by µ the mean value,
and by σ the standard deviation. To assess the practical mean-
ing of the statistical results, we report effect sizes [62]: For
unpaired t-tests, the absolute value of d  0.8 large effect.
For paired t-tests, effect size dz is interpreted identically to
d. Cramer’s V measures effect sizes for χ2 tests, and r for
ANOVA1. Values around 0.10 indicate a small, 0.30 a medium,
and 0.50 a large effect [63].
Field [63, p. 472] and is calculated as(cid:112)η2.
1r denotes effect size for one-way independent ANOVA according to
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:38 UTC from IEEE Xplore.  Restrictions apply. 
433
V. PRELIMINARY STUDIES
A. Prestudy 1: Selection of Product Categories
The objective of this prestudy is to identify two categories
of IoT products according to the following criteria:
C1 Both categories should differ signiﬁcantly in their per-
ceived security risk.
C2 Both categories should be similar concerning other central
product attitudes and their purchase intentions: Attitude
towards product category (in terms of favor,
likability,
pleasure) [64], involvement with product category (in terms
of, e.g., fascination, excitement) [65], consumption motive
(hedonistic or utilitarian) [66], desirability to possess prod-
ucts of this product category [67], and purchase intention
for products of this product category [68]. The items of
these scales are reported in Appendix A.
Perceived Security Risk Scale: To distinguish between prod-
uct categories with a high and low perceived security risk
(criterion C1), we needed a scale that measures the perceived
security risk associated with IoT consumer products. After an
extensive literature review, we concluded that there is no scale
that sufﬁciently ﬁts our purpose. Declined candidates [59],
[69], [70] comprised scales that measure security and privacy
risks in e-commerce settings. However, because IoT products
may have adverse effects on the physical world, their security
risks are fundamentally different.
Thus, we developed a perceived security risk scale for IoT
consumer products using a similar methodology as proposed
by Davis [71]. In the ﬁrst step, we deﬁned the concept of
the perceived security risk in IoT products. Perceived risk is
deﬁned as the customers’ perceptions of uncertainty and unfa-
vorable consequences concerning a product or a service [72].
In the context of security, uncertainty means the probability of
a security incident, while consequences are the loss caused by
such an incident. We decided to measure only consequences
with our scale. We think that it is very difﬁcult for non-experts
to determine the probability of a security incident associated
with a particular IoT product category, because they would
need to assess the quality of the product’s security measures
as well as the attractiveness of the product for attackers. On
the other hand, the assessment of consequences of a security
incident requires knowledge about the deployment and utiliza-
tion of the product. Usage scenarios are known to consumers,
and therefore, they can imagine potential consequences. As
a result, we deﬁned that perceived security risk for an IoT
product exists if security vulnerabilities in this product are
perceived to lead to negative consequences for the user.
We further considered classical risk categories for product
purchase by Jacoby and Kaplan [73], which have often been
used to measure perceived risk in marketing research [72],
[74]. Additionally, we adapt risk categories by Featherman
and Pavlou [69], who already adapted Jacoby and Kaplan’s
categories for e-commerce settings.
We split the perceived security risk in four risk categories:
‘general’2, ‘privacy’, ‘physical’, and ‘ﬁnancial’. Jacoby and
Kaplan [73] and Featherman and Pavlou [69] present further
risk categories that we did not consider because they have
low relevance for the security risk of IoT products: ‘perfor-
mance’, ‘time’, ‘psychological’, and ‘social’. Although the
performance of IoT products can be affected in a security
incident, performance deﬁciencies that affect functionality in
a dangerous way are already covered by physical risk. The
risk of wasting time in case of a security incident exists
for all product categories alike. We excluded psychological
risk as its original deﬁnition relates to the consumer’s self-
image or self-concept regarding a product [73]3. Effects of IoT
products on consumers’ psychological state (e.g., perception
of surveillance, or privacy violations) are considered in our
scale by items in the risk categories ‘privacy’ and ‘general’.
Finally, we did not take social risk into account since privacy
risk already covers effects on the status in one’s social groups.
Item candidates were generated and iteratively improved
through expert reviews by 14 experts from the domains of
cybersecurity, psychology and marketing research. The ﬁnal
scale is presented in Appendix, Table XI and consists of 13
items relating to risk categories ‘general’, ‘privacy’, ‘physical’,
and ‘ﬁnancial’. For the statistical comparison of the product
categories, we averaged the scale to form a composite index.
Survey Structure and Data Collection: We selected eight
candidate product categories through an overview of popular
IoT consumer products on online shopping websites and expert
judgment: smart alarm systems, smart door locks, smart light
bulbs, smart home cameras, smart smoke detectors, smart
thermostats, smart vacuum robots, and smart weather stations.
In the surveys, the products were introduced in a random-
ized order. Each product category was introduced with an
exemplary product picture and a short text that explained the
products’ features and usage scenarios. We emphasized that
all these products connect to the Internet.
To determine the sample size for this prestudy, we per-
formed a power analysis [75] for paired t-tests. Assuming that
large effects indicate practical relevance (Cohen’s dz = 0.8),
and the desired power of 0.99, the power analysis determined
30 participants as sufﬁcient.
We collected data with an online questionnaire using
LimeSurvey [76]. The questionnaire was pretested by six
experienced colleagues at our institutes. During the tests we
realized that the amount of data that we wanted to collect
would lead to a long and exhausting survey. Therefore, we
decided to split the survey into two smaller questionnaires that
should be answered by two independent groups of respondents.
One group answered the perceived security risk (C1) for all
eight product categories, while the other group evaluated the
scales of C2 for all eight product categories. Each group
consisted of 30 crowdworkers. Through test runs, we estimated
2Jacoby and Kaplan [73] denote this risk category as ‘overall’. We renamed
it to ‘general’ since ‘overall’ could be misunderstood as average score over
all risk categories.
3Deﬁnition of psychologocal risk [73]: “the chances that an unfamiliar
brand of [product] will not ﬁt in well with your self-image or self-concept.”
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:38 UTC from IEEE Xplore.  Restrictions apply. 
434
the average time to answer the surveys to be 10 to 12 minutes.
We paid each crowdworker e1.80 for 12 minutes.
Results: Sixty respondents (23 female, 37 male) aged
between 19 and 62 years (µ = 38.5, σ = 10.7) answered the
surveys. We did not exclude any responses. The collected data
was analyzed using IBM SPSS [63]. The perceived security
risk scale (C1) showed good statistical properties, which are
not presented here for brevity. However, in Appendix B, we
present the statistical properties of the scale using the results of
the main study (Section VI). For all scales of C2, Cronbach’s
alpha, a measure that deﬁnes the inner consistency of a scale,
was above the recommended threshold of .700 (>.858) [63].
According to our criteria, we found three candidate pairs of
product categories that do not statistically signiﬁcantly differ
from each other in the factors of C2, but differ statistically
signiﬁcantly in the perceived security risk:
1) Smart home camera and smart weather station
(t(29) = 7.57, p < 0.001, dz = 1.383)
2) Smart smoke detector and smart thermostat
(t(29) = 2.09, p < 0.05, dz = 0.381)
3) Smart smoke detector and smart vacuum robot
(t(29) = 3.29, p < 0.01, dz = 0.600)
We decided on the ﬁrst pair as these product categories
have the highest difference between their perceived security
risk scores. More analysis details can be found in Appendix,
Tables XII and IX.
B. Prestudy 2: Deﬁnition of Product Attributes and Levels
After two product categories were chosen, the next step was
to determine product attributes that will be used in the conjoint
analysis. The number of attributes should be reasonable such
that a respondent can process them cognitively [77]. Otherwise
respondents might tend to use shortcut heuristics that ignore
less important features [78]. We decided for 7 attributes
per product category. Two attributes were reserved for the
attributes of the security update label (availability period and
provisioning time). The remaining ﬁve attributes comprised
existing product attributes that depend on the product category.
We paid attention to avoid correlation between attributes,
which would lead to illogical proﬁles. In the literature on
conjoint analysis, the speciﬁcation of attributes lacks a golden
standard [79] and is approached in various ways, such as focus
groups, surveys, or expert judgements.
Method: We conducted an online survey to identify the
most important attributes for each product category to use
in conjoint analysis. For this, attribute candidates were col-
lected from online shopping websites. We prepared an online
questionnaire on LimeSurvey that listed these 18 individual
attributes, which are given in Appendix, Table VIII. Respon-
dents rated the importance of these attributes for their buying
decision using the dual-questioning methodology by Alpert
[80], [81]. The respondents rated following two items on 7-
point Likert scales: “How important is each of these attributes
in your buying decision?” and “How much difference do you
feel, there is among products of the product category ‘[prod-
uct]’ in each of these attributes?”. Both scores were multiplied
TABLE I: Product categories with their respective attributes
and attribute levels.
Category Attribute
1 Price
2 Resolution
3 Field of vision
4 Frame rate
5 Zoom function
6 Availability of
Smart
home
camera
security updates
7 Provisioning time
for sec. updates
Smart
weather
station
1 Price
2 Battery lifetime
3 Precision
4 Rain/wind sensor
5 Expandability to
multiple rooms
6 Availability of
security updates
7 Provisioning time