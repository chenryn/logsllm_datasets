=== 高级配置功能
除上一节介绍的解析算子和常用设置项以外，日志易还提供了高级配置功能，让用户直接在页面上输入JSON格式的算子配置。页面提供了对JSON格式的校验，但如果是参数错误，可能会导致规则解析失败等状态发生。因此，建议用户在一定要使用这些高级配置时，一定要解析验证通过后才提交。
image::images/parserule-advance-conf.png[]
如上图所示，在算子名称后面点击切换按钮，即可转为高级配置输入框。再次点击切换，即放弃修改，返回原始状态。
[IMPORTANT]
====
对于已保存规则中的高级配置，再点击强制切换成普通配置界面，配置项需要重新填写。
====
==== 算子的高级配置介绍
一般而言，算子的高级配置主要内容和普通配置界面上的输入项一一对应。但是有少量隐藏参数可用。本节将列出所有算子的高级配置示例，多数情况下，通过普通配置界面足以完成解析目的。您仅需在必要时查阅这部分内容。
===== 正则解析
正则解析算子有单行和多行两种模式，但实际在高级配置里是通用的格式。pattern数组里，仅存在一个列表就是单行正则；存在多个列表，就是多行正则。示例如下：
[source,javascript]
{
                #解析的字段名
                "source" : "raw_message",
                "pattern" : [
                    #第一行正则，支持列表
                    ["(?.*)" ],
                    #其他行正则，支持列表
                    ["(?.*)" ]
                ],
                # 内部字段，固定值true
                "multiline": true 
                #"condition" : {"rule" : {"field":"a", "condition":"equal", "value":"1"}}
}
示例里，可以看到一个condition设置，这就是所有算子都有的条件控制部分，本节后续示例将采用…省略。高级配置支持更多的条件控制逻辑，本章稍后有单独内容讲解。
===== 正则片段解析
该算子用于从日志中抽取一小部分字段。标准的正则表达式解析算子，要求从日志起始位置开始匹配，尽量单次抽取全部可用信息。
对于很多IT日志，常用的信息其实格式比较固定，但在不同来源的日志中出现的位置却不固定。比如IP地址、端口号、用户和进程名称等。这时候，可以使用extract算子，单独提取小片段的内容。
正则片段解析算子和正则解析算子共用同一个入口，只是pattern和extract两个设置参数不同。用户只需要在正则解析算子的高级配置输入框中，填入如下语法即可：
[source,javascript]
{
                #配置默认的字段
                "source" : "raw_message",
                #是否多行，固定值false
                "multiline": false,
                #规则名称, 目前仅为方便调试
                "rule_name": "",
                #解析的字段名
                "extract" : [
                    #正则，多个正则使用
                    [{
                        #可选字段, 可选的字段名, 默认是空，用配置上层的字段
                        "source" : null,
                        #字段正则, 可以使用分组
                        "regex" : "(.*)"
                        #字段列表, 可以用$1, $2表示正则分组
                        "fields" : {
                            "a" : "$1",
                        },
                        #可选描述，目前仅为方便调试
                        "description" : "test regex"
                        }]
                ]
                #"condition" : …
}
使用该算子时，为了提高匹配效率，建议正则中最好含有一些比较固定的文本内容，方便快速定位。比如，下面是一段提取思科fwsm日志中用户名信息的正则片段解析算子配置：
[source,javascript]
{
                "source" : "raw_message",
                "rule_name": "report-user_for_cisco_fwsm",
                "multiline": false,
                "extract": [
                    [{
                        "regex": "[Uu]ser\\s[\"|']([^'\"]*)[\"|']",
                         "fields": {"user": "$1"},
                        "name": "user_for_cisco",
                    }, {
                        "regex": "\\sUname:\\s(.*)",
                        "fields": {"user": "$1"},
                        "name": "uname_for_cisco"
                        }
                ]]
}
我们可以看到，两个正则片段结果都是提取user字段，而对应的正则表达式本身却不一样。这两个表达式中，都有固定的文本内容，第一条是User，第二条是Uname:，这种表达式执行效率就比较好。
使用上例这个算子，我们对如下两条看似完全不同的日志，都可以得到user字段，值为enable_15：
 2014-11-07 11:18:33 192.168.1.1 FW-LZQ-MGJZZS-ASA5505-01 %ASA-5-111010: User 'enable_15', running 'CLI' from IP 192.168.1.11, executed 'debug http'
 2014-11-07 11:18:33 192.168.1.1 FW-LZQ-MGJZZS-ASA5505-01 %ASA-5-502103: User priv level changed: Uname: enable_15 From: 1 To: 15
===== JSON解析
JSON解析算子中，有一个隐藏参数：flatten_short_array。控制是否对只有一个元素的数组转换成普通键值对形式。
[source,javascript]
{
                #解析的字段名
                "source" : "raw_message",
                #选取字段路径(可选字段, 默认为空)
                # - 单个path的结果如果是多个，结果合并成数组
                # - 多个path结果的同名字段, 对象类型的合并，数组类型的覆盖
                "paths" : [
                    "a.b.c"
                ],
                #是否把单个元素的数组展开(可选字段，默认为false, 保留数组结构)
                "flatten_short_array" : false,
                #json的最大解析长度，超过这个长度的字段就不再解析;0表示不限制
                "extract_limit":0
                #"condition" : …
                #"add_fields": …
}
===== XML解析
和JSON一样，XML解析算子中，有一个隐藏参数：flatten_short_array。
[source,javascript]
{
                #解析的字段名
                "source" : "raw_message"
                #选取字段路径(可选字段, 默认为空)
                # - 单个path的结果如果是多个，结果合并成数组
                # - 多个path结果的同名字段, 对象类型的合并，数组类型的覆盖
                "paths" : [
                    "a.b.c"
                ],
                #是否把单个元素的数组展开(可选字段，默认为false, 保留数组结构)
                "flatten_short_array" : false,
                #xml的最大解析长度，超过这个长度的字段就不再解析;0表示不限制
                "extract_limit":0
                #"condition" : …
}
===== URL解析
[source,javascript]
{
                #解析的字段名
                "source" : "request_url"
                #"condition" : …
}
===== UserAgent解析
[source,javascript]
{
                #解析的字段名
                "source" : "request_user_agent"
                #"condition" : …
}
===== 删除字段
[source,javascript]
{
                #删除的字段名列表
                "source" : [
                    "a"
                ]
                #"condition" : …
}
===== GEO解析
GEO解析的普通配置界面只提供了解析到顶层字段、或替换来源字段的选择。在高级配置项中，则可以给target参数任意指定到其他字段名。
此外，还可以通过field参数，控制只保留部分解析结果。在有明确预期的时候，去除部分不用的结果可以节省硬件资源。
[source,javascript]
{
                #解析的ip地址字段名
                "source" : "request_ip",
                #结果的顶级字段名(可选, 默认为"geo")
                "target" : "geo",
                #geo结果字段名称(可选, 默认为"all"), 可选值为: "all", "city", "province", "country", "isp", "latitude", "longitude", "org"
                "field" : [
                    "all"
                ]
                #"condition" : …
}
===== 手机号码解析
手机号解析和GEO解析类似，也可以单独控制target参数。
[source,javascript]
{
                #解析的手机号码字段名
                "source" : "phone",
                #结果的顶级字段名(可选，默认为"phone")
                "target" : "phone",
                #"condition" : …
}
===== 固定电话解析
固定电话解析和GEO解析类似，也可以单独控制target参数。
[source,javascript]
{
                #解析的固定电话字段名
                "source" : "telephone",
                #结果的顶级字段名(可选，默认为"telephone)
                "target" : "telephone",
                #"condition" : …
}
===== KeyValue分解
[source,javascript]
{
                #解析的字段名
                "source" : "kv",
                #key value对儿的分隔符
                "field_split" :  [","] ,
                #key value之间的分隔符
                "value_split" : ["="],
                #丢弃的字段名前缀(可选, 默认为空), 以这些前缀开头的字段都会丢弃
                "drop_key_prefix" : [],
                #丢弃的字段值(可选, 默认为空), 这些字段都会丢弃
                "drop_key" : [],
                #保留字段的名(可选, 默认为空字)
                "reserved_key" : [],
                #碰到重复字段时的处理方式, 可用值: use_first(用第一个值), use_last(用最后一个值), merge_as_array (合并为数组)
                "duplicate_key_strategy" : "use_last"
                #"condition" : …
}
===== KeyValue正则匹配
KeyValue正则匹配和普通KV切割的区别是：该算子最终是组装成一条比较复杂的正则表达式进行匹配解析。
[source,javascript]
{
                #解析的字段名
                "source" : "kv",
                "kv_match_group": [{
                    #key的格式, 支持正则，
                    "key_regex" : "\\w*",
                    #value的格式, 支持正则
                    "value_regex" : "\\d*",
                    #kv的分隔符，支持正则
                    "value_split" : [
                        "="
                    ],
                    #group的正则, 需要自己提供分组名, 可选项
                    "group_regex" : ""
                }],
                #保留第一个匹配key(可选, 默认false)
                "find_first_only": false,
                #(废弃, 兼容性保留, 用duplicate_key_strategy)保留所有匹配value(可选, 默认true)
                "reserve_all_values_for_one_key": true,
                #丢弃的字段名前缀(可选, 默认为空), 以这些前缀开头的字段都会丢弃
                "drop_key_prefix" : [],
                #丢弃的字段值(可选, 默认为空), 这些字段都会丢弃
                "drop_key" : [],
                #保留字段的名(可选, 默认为空字)
                "reserved_key" : [],
                #碰到重复字段时的处理方式, 可用值: use_first(用第一个值), use_last(用最后一个值), merge_as_array (合并为数组)
                #注意: 不加reserve_all_values_for_one_key选项时才生效
                "duplicate_key_strategy" : "use_last"
                #"condition" : …
}
KV正则匹配算子中，有一个隐藏的高级参数：group_regex。该参数用来解析分组的KV键值对。group_regex参数需要提供有且只有一个分组, 而且需要匹配从group值到第一个KV键值对之间的分隔符。最终，KeyValue正则匹配算子，实际上会编译成下面这样的正则表达式：
 (?:group_regex)?(key_regex)value_split(value_regex)
比如如下一段日志文本：
[source,]
 [AB Server:type=Cell]
     ChildCount = 4
     MessageLimit = 12288
     Oid = CA_ABS
     CellName = CA_ABS
     ClientIp = 9.1.6.247
     ParentOid = CA_ABS
     OutOfService = false
     ChildCountLimit = 5000
     OverLoad = false
     MinuteCountLimit = 2000
 [AB Server:type=InvokeProcessor]
     AverageTaskTime = 7
     AverageTasksPerSecond = 0
     CompletedTasks = 22321
     ComputeAverageInterval = 10000
     RunningTasks = 0
KV正则解析的参数需要配置成如下值，才能得到较好的解析结果：
* key正则: \w+
* value正则: \w+
* kv分隔符正则: \s*=\s*
* group正则: \[[^\]]*=(\w+)[^\]]*\]\s*
这个group正则，可以改用多行模式解释：
[source]
(?#comment)
\[
    [^\]*
    =
    (\w+) #等号后边等字符是group名, 需要自定义正则分组
\]
\s*   #需要匹配分组到第一个kv之间的位置
===== CSV解析(字段值拆分)
CSV解析算子，又叫字段值拆分算子。
names列表为空时，拆分结果会自动变成一个数组字段。
split_option有两个可选项，各自对应了不同的split_string要求和后台行为：
* null: 会使用正则分割日志, split_string是个正则。
* "csv": 会使用csv的定义切分，支持csv的引号，split_string只支持一个字符。
[source,javascript]
{
                #解析的字段名
                "source" : "array",
                #分隔符, 支持正则
                "split_string" : ",",
                #分割出来的字段名, 和字段一一对应, 不需要的字段可以用字段名null
                "names" : [
                  "field_1"
                ],
                #可选分割的类型，默认是空，用正则分割字段。可选类型: csv
                "split_option": null
                #"condition" : …
}
===== 数值型字段转换
数值型字段转换算子的高级配置和其他算子不太一样。由于有多个字段可以分别选择转换成不同的整形或浮点型。该算子采用数组配置，数组内每个元素转换一个数值型字段。
[source,javascript]
[
            {
                #解析的字段名
                "source" : "request_status",
                #数值的类型，可选值为: "int", "float"
                "numeric_type" : "int",
                #数值的进制(可选, 默认10进制)
                "radix" : 10,
                #"condition" : …
            }
]
===== 自定义字典
自定义字段的高级配置中，实际使用的是已存字典的内部id。请谨慎修改。
[source,javascript]
{
        "source" : "error",
        #上传字典的id
        "id": "1",
        #对应字典的字段名
        "field" : "error_code",
        #字段匹配类型，可选值exact, cidr，默认是exact(v3.7.0.4之后版本支持）
        "match_type" : "exact",
        #字段中需要添加的字段名
        "ext_fields" : [
            "code",
            "name"
        ],
        #条件, 参考条件
        #"condition" : {"rule" : {"field":"a", "condition":"equal", "value":"1"}}
        #"add_fields" : [{"name":"matched", "value": "1"}]
}
当match_type的值是cidr时，支持cidr匹配。同时支持ipv4和ipv6。logriver会自动识别ip类型，注意字典文件只能全部是ipv4或者全部是ipv6，不能混合使用。
如果配置ip出现重叠，结果只会命中一个，以行数最小的优先级最高。
===== 时间戳识别
[source,javascript]
{
        "source": "timestamp",
        "prefix": "",
        "max_lookahead": 80,
        #时间格式列表
        "rule" : [
            "yyyy-MM-dd HH:mm:ss",
            "UNIX"
        ],
        #时区
        "zone" : "Asia/Shanghai",
        #本地化
        "locale": "en"
        #"condition" : …
}
===== IP格式转换
[source,javascript]
{
                "source" : "ip",
                #转换的类型, 可选值为："long2ip"
                "op_type" : "long2ip"
                #"condition" : …
}