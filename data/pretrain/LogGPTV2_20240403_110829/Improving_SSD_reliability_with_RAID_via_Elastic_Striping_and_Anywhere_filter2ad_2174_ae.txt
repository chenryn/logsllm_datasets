given workload. Table III represents the accuracy ratio between
the numbers obtained through the experiments and the numbers
estimated from the model for the various workloads. From
the table, we see that the model accurately estimates the P/E
cycles and the total number of pages writes of the various
RAID schemes. For the majority of the cases, the difference
between the model and the experimental results are within
10% of each other. These results show that our model is an
accurate indicator of the performance and wear out level of
ﬂash memory storage that employ the various RAID schemes.
With our model, we now project the long-term reliability
of various systems by extending the number of write requests
for the given workloads. A crucial reliability metric of ﬂash
memory storage is the bit error rate when a particular error
recovery technique is applied.
Let us assume that ECC can correct k bits errors, while
being able to detect 2k bit errors. This assumption is generally
valid as coding theory suggests that the number of errors that
can be detected by ECC is roughly twice the number of errors
that can be corrected. Considering only ECC, if ECC can
correct k errors, then the rate that less than k + 1 bits fail, that
is, the Correctable Page Error Rate (CPER) can calculated as
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:49:49 UTC from IEEE Xplore.  Restrictions apply. 
0.E+005.E+051.E+062.E+062.E+063.E+06SequentialRandomFinancialExchangeMSNP/E cycles ECCRAID-5(8)RAID-5(16)RAID-5(32)eSAP(8)eSAP(16)eSAP(32)0.E+005.E+041.E+052.E+05Sequential0.E+002.E+074.E+076.E+078.E+071.E+081.E+081.E+082.E+08SequentialRandomFinancialExchangeMSNTotal page writes ECCRAID-5(8)RAID-5(16)RAID-5(32)eSAP(8)eSAP(16)eSAP(32)0.E+005.E+061.E+07SequentialFig. 12: Comparison of (a) Uncorrectable Page Error Rate and (b) P/E cycles for ECC, RAID-5, and eSAP-RAID. eSAP shows lowest UPER and the number
of P/E cycles lies inbetween those of RAID-5 and ECC throughout its usage.
(a) UPER
(b) P/E cycles
follows [17], [19], [26]:
CP ER(n, k) =
(cid:18)n
(cid:19)
i
· RBERi · (1 − RBER)n−i
k(cid:88)
i=0
the rate that k + 1 or more bits fail,
Then,
Uncorrectable Page Error Rate (UPER) is
that
is,
the
U P ER(n, k) = 1 − CP ER(n, k)
(7)
Before discussing the bit error rate of RAID schemes,
a fundamental assumption of the RAID system must be
explained. The RAID system works only when it knows
whether disks in a stripe have errors or not. Without knowledge
regarding the existence of errors, it cannot correct errors even
though it may have redundant information. Unfortunately, ECC
does not guarantee error detection if more than 2k bit errors
occur in a page. Flash memory chips may report page read
errors or supplementary techniques such as CRC check may
be employed to detect such errors. In this study, however, we
derive the Uncorrectable Page Error Rate (UPER) based on
the conservative assumption that ﬂash memory storage using
RAID architecture can correct errors with parity only when a
page has bit errors less than or equal to 2k.
In a previous study, Lee et al. show that the UPER of
an SSD after the RAID scheme is applied, which we denote
U P ERST R, is
U P ERST R(N ) =
where F (x; N, p) =(cid:80)x
1 − F (1; N, U P ER(n, k))
(cid:1)·pi·(1−p)N−i, which is the
(8)
N
(cid:0)N
i
i=0
cumulative binomial distribution, and N is the number of pages
in a stripe [17]. However, this derivation does not consider the
fact that bit errors of more than 2k may not be detected. To
derive the error rate of the RAID scheme considering these
cases, we derive the Correctable Stripe Error Rate (CSER),
CSERST R(N ), deﬁned as F (1; N, U P ER(n, k)) in Eq. 8.
Speciﬁcally, there are two cases where bit errors in a stripe
can be corrected. The ﬁrst is when all pages comprising a stripe
have less than or equal to k bit errors such that these errors
are corrected by the ECC. The probability for this case to
(cid:1)CP ER(n, k)N . The other case is when N − 1
occur is (cid:0)N
pages in a stripe have less than or equal to k bit errors that
0
1
can be corrected by the ECC and one page has more than
k bit errors and less than or equal to 2k bit errors that are
detectable by the ECC. The probability of this case to occur is
(cid:1)RBERi·(1−RBER)n−i.
(cid:1)CP ER(n, k)N−1·(cid:80)2k
(cid:0)N
(cid:0)n
In this equation, we are excluding situations where there are
more than 2k bit errors in a page as those errors may not be
detected by the ECC and as a result, the RAID scheme can
not correct those errors. By summing up the equations of the
two cases, we get CSERST R(N ) as follows:
i=k+1
i
CSERST R(N ) =
CP ER(n, k)N +
CP ER(n, k)N−1 ·
RBERi(1 − RBER)n−i
(cid:19)
(cid:18)N
1
(cid:18)N
(cid:19)
0
2k(cid:88)
(cid:18)n
(cid:19)
i
i=k+1
we
Then,
get
F (1; N, U P ER(n, k))
resulting in the following equation:
U P ERST R(N )
in Eq.
replacing
8 with CSERST R(N )
by
U P ERST R(N ) =
1 − CSERST R(N )
N
(9)
Using Eqs. 7 and 9, we depict, in Fig. 12(a), the UPER
values for the SSD that employ only ECC and those that em-
ploy RAID-5 and eSAP. (For brevity, we denote U P ERST R
as UPER, hereafter.) Note that a subset of this ﬁgure was
presented as Fig. 1(a). In generating the graphs with Eqs. 7
and 9, the capacity of the SSD is assumed to be 64GB and the
parameters of the models of RAID-5 and eSAP are obtained
from Financial in Table II that shows that the average write
size for eSAP is roughly 8 times larger than that of RAID-5.
In the ﬁgure, we see that ECC has the highest UPER be-
cause it is not protected by any parity. However, the reliability
gap between ECC and RAID-5/eSAP gradually diminishes
as more data are written because both RAID-5 and eSAP
increases the number of P/E cycles to write parities resulting
in faster wear. Among the three schemes, the eSAP scheme
has the lowest UPER, with its value being far below that of
HDDs. Furthermore, the rate at which its reliability diminishes
is lower than RAID-5 as elastic striping reduces parity write
overhead. In fact, as more data is written and the SSD reaches
the latter stages of its life-cycle, we see that the difference in
UPER between RAID-5 and eSAP widens.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:49:49 UTC from IEEE Xplore.  Restrictions apply. 
1.E-391.E-361.E-331.E-301.E-271.E-241.E-211.E-181.E-151.E-121.E-091.E-061.E-031.E+00UPER (Log scale) ECCRAID-5(8)RAID-5(16)RAID-5(32)eSAP(8)eSAP(16)eSAP(32)Written bytes Error rate of HDD  0.E+002.E+034.E+036.E+038.E+031.E+041.E+041.E+042.E+04Expected Avg. P/E cycles ECCRAID-5(8)RAID-5(16)RAID-5(32)eSAP(8)eSAP(16)eSAP(32)Written bytes P/E cycle limit(MLC) Making use of eSAP provides the lowest UPER and yet,
the number of P/E cycles required is also far lower than that
of RAID-5 as depicted in Fig. 12(b). This ﬁgure is obtained
for the same 64GB SSD with the parameters of Financial in
Table II and making use of Eqs. 3 and 6. Fig. 1(b) is also
a subset of this ﬁgure. This ﬁgure shows that using eSAP
increases the number of P/E cycles somewhat compared to
ECC. However, compared to RAID-5, it requires far less P/E
cycles. Furthermore, except for eSAP(8), that is, eSAP with a
small stripe size, the number of P/E cycles remains below the
limit for up to 200TB of data writes.
The conclusion we make from these results is that eSAP
improves reliability considerably, while limiting its wear.
Speciﬁcally, while SSDs employing eSAP-RAID can be used
as long as current ECC based SSDs, its reliability level can
be maintained to that of the early stages of current ECC SSDs
throughout its entire lifetime.
VII. CONCLUSION
Though employing RAID-5 architecture inside SSDs in-
creases the reliability of SSDs, the parity update mechanism
in conventional RAID-5 introduces more writes resulting in in-
creased P/E cycles and hence, higher bit error rates. To remedy
this problem, we proposed a novel ﬂash-aware RAID scheme,
which we call Elastic Striping and Anywhere Parity RAID or
eSAP-RAID, that dynamically constructs stripes based on the
arrival order of write requests and places the parity anywhere
in the stripe so as to reduce parity update overhead and
to increase reliability. In particular, in this study, we derive
the performance and lifetime models of SSDs employing the
RAID-5 and eSAP-RAID schemes. The models estimate write
performance and P/E cycles for given workloads such that
long-term reliability can be projected. Through experiments
with various workloads, we evaluated the RAID schemes for
SSDs in terms of performance and reliability.
We validate the models that we derive with values obtained
from the experiments, and our results show that the experi-
mental results and the model results closely match each other.
Then, using the models we estimate the long-term reliability
of SSDs employing RAID schemes.
Our conclusion is that by making use of eSAP-RAID, SSD
performance and wear out can be maintained at current ECC
based SSD level, while maintaining the reliability level to that
of the early stages of ECC based SSD usage throughout the
lifetime of the SSD.
ACKNOWLEDGMENT
We would like to thank the anonymous reviewers for their
constructive comments. We also wish to thank Eunjae Lee
for helping us automate the calculations of the equations.
This research was supported in part by Seoul Creative Human
Development Program funded by Seoul Metropolitan Govern-
ment(No. HM120006), by the National Research Foundation
of Korea(NRF) grant funded by the Korea government(MEST)
(No. 2012R1A2A2A01045733), and by Basic Science Re-
search Program through the National Research Foundation of
Korea(NRF) funded by the Ministry of Education, Science and
Technology(2010-0025282).
REFERENCES
[1] UMASS TRACE REPOSITORY. http://traces.cs.umass.edu.
[2] Flash-memory Translation Layer for NAND Flash(NFTL). M-Systems.
1998.
[3] OCZ
TECHNOLOGY
EVEREST
LAUNCHES
SSD
INDILINX
http://www.ocztechnology.com/aboutocz/press/2012/491.
CONTROLLER
NEXT
GENERATION
PLATFORM.
[4] Samsung
Releases
TLC
NAND
Based
840
SSD.
http://www.anandtech.com/show/6329/samsung-releases-tlc-nand-
based-840-ssd.
[5] Understanding the Flash Translation Layer (FTL) Speciﬁcation. Intel
Corporation. 1998.
[6] M. Blaum, J. L. Hafner, and S. Hetzler. Partial-MDS Codes and Their
IBM Research Report,
Application to RAID Type of Architectures.
RJ100498, February 2012.
[7] P. M. Chen and E. K. Lee. Striping in a RAID Level 5 Disk Array.
In Proc. SIGMETRICS ’95, pages 136–145, Ottawa, Ontario, Canada,
1995.
[8] S. Chen. What
types of ecc should be used on ﬂash memory?
http://www.spansion.com/Support/AppNotes/, 2007.
[10]
Trends
[9] E. Deal.
Error
in NAND Flash Memory
Correction.
http://www.cyclicdesign.com/whitepapers/
Cyclic Design NAND ECC.pdf, Cyclic Design, White
Paper,
Jun. 2009.
J. Gary and C. van Ingen. Empirical Measurements of Disk Failure
Rates and Error Rates. Technical Report MSR-TR-2005-166, December
2005.
[11] L. M. Grupp, A. M. Caulﬁeld, J. Coburn, S. Swanson, E. Yaakobi,
P. H. Siegel, and J. K. Wolf. Characterizing Flash Memory: Anomalies,
Observations, and Applications. In Proc. MICRO 42, pages 24–33, New
York, NY, 2009.
[12] L. M. Grupp, J. D. Davis, and S. Swanson. The Bleak Future of NAND
Flash Memory. In Proc. FAST ’12, pages 17–24, San Jose, CA, 2012.
[13] X.-Y. Hu, E. Eleftheriou, R. Haas, I. Iliadis, and R. Pletka. Write
In Proc.
Ampliﬁcation Analysis in Flash-based Solid State Drives.
SYSTOR ’09, pages 10:1–10:9, Haifa, Israel, 2009.
[14] S. Im and D. Shin. Flash-Aware RAID Techniques for Dependable
IEEE Transactions on
and High-Performance Flash Memory SSD.
Computers, 60(1):80–92, Jan. 2011.
J. Kim, J. Lee, J. Choi, D. Lee, and S. H. Noh. Enhancing SSD
In Workshop on APSYS
Reliability through Efﬁcient RAID Support.
’12, pages 4:1–4:6, Seoul, Republic of Korea, 2012.
[15]
[16] H. Kwon, E. Kim, J. Choi, D. Lee, and S. H. Noh. Janus-FTL: Finding
the Optimal Point on the Spectrum between Page and Block Mapping
Schemes. In Proc. EMSOFT ’10, pages 169–178, Scottsdale, AZ, 2010.
[17] S. Lee, B. Lee, K. Koh, and H. Bahn. A Lifespan-Aware Reliability
Scheme for RAID-based Flash Storage. In Proc. SAC ’11, pages 374–
379, TaiChung, Taiwan, 2011.
[18] Y. Lee, S. Jung, and Y. H. Song. FRA: a ﬂash-aware redundancy array
of ﬂash storage devices. In Proc. CODES+ISSS ’09, pages 163–172,
Grenoble, France, 2009.
[19] N. Mielke, T. Marquar, N. Wu, J. Kessenich, H. Belgal, E. Schares,
F. Trivedi, E. Goodness, and L. Nevill. Bit Error Rate in NAND Flash
Memories. In Proc. IEEE Int’l Reliability Physics Symp., pages 9–19,
2008.
[20] D. Narayanan, E. Thereska, A. Donnelly, S. Elnikety, and A. Rowstron.
In Proc.
Migrating Server Storage to SSDs: Analysis of Tradeoffs.
EuroSys ’09, pages 145–158, Nuremberg, Germany, 2009.
[21] Y. Oh, J. Choi, D. Lee, and S. H. Noh. Caching Less for Better
Performance: Balancing Cache Size and Update Cost of Flash Memory
Cache in Hybrid Storage Systems. In Proc. FAST ’12, pages 313–326,
San Jose, CA, 2012.
[22] V. Prabhakaran and T. Wobber.
Simulation
us/downloads/b41019e2-1d2b-44d8-b512-ba35ab814cd4.
Environment.
SSD Extension for DiskSim
http://research.microsoft.com/en-
[23] M. Rosenblum and J. K. Ousterhout. The Design and Implementation of
a Log-structured File System. ACM Transactions of Computer Systems,
10(1):26–52, Feb. 1992.
[24] H. Sun, P. Grayson, and B. Wood. Quantifying Reliability of Solid-State
Storage from Multiple Aspects. In Workshop on SNAPI ’11, Denver,
CO, May 2011.
[25] W. Wang, Y. Zhao, and R. Bunt. HyLog: A High Performance Approach
In Proc. FAST ’04, pages 145–158, San
to Managing Disk Layout.
Francisco, CA, 2004.
[26] Y. Wang, L. A. D. Bathen, N. D. Dutt, and Z. Shao. Meta-Cure: a
Reliability Enhancement Strategy for Metadata in NAND Flash Memory
Storage Systems. In Proc. DAC ’12, pages 214–219, San Francisco, CA,
2012.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:49:49 UTC from IEEE Xplore.  Restrictions apply.