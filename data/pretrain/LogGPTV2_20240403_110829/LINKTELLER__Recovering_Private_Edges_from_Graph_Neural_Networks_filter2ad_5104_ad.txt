Compared with EDGERAND, LAPGRAPH has the advantage
of better preserving the density of the original graph, espe-
cially for large graphs and small ε. Since the number of edges
in a large graph is often orders of magnitude higher than the
sensitivity of adding/removing a single edge, it is possible to
estimate T even under a very limited privacy budget. Thus, the
density of the perturbed graph is much closer to the original
one than EDGERAND. This improvement makes it possible to
train DP GCN on large graphs under small privacy budgets
without causing memory errors.
Theorem 5. LAPGRAPH guarantees ε-edge DP.
Due to the lack of DP GCN approaches, here we focus on
the existing technique EDGERAND and the proposed LAP-
GRAPH to provide DP guarantees for GCN as countermeasures
to further evaluate the proposed attack LINKTELLER. We have
provided the formal analysis for the privacy guarantees for
EDGERAND and LAPGRAPH above, and next, we will discuss
a general upper bound of edge privacy on DP GCN models.
C. Discussion: Upper Bound of Edge Re-Identiﬁcation Attack
Performance on DP GCN
As implied by ε-edge DP in Deﬁnition 3, it is generally
difﬁcult to tell, among the two neighboring adjacency matri-
ces A and A(cid:48), which one leads to the observed prediction.
The direct consequence of the indistinguishability is that the
existence of the differing edge e = A⊕ A(cid:48) cannot be inferred.
In this section, we aim to analyze the upper bound of edge
re-identiﬁcation attacks against DP GCN.
Same as the attack model introduced in Section III-B, we
assume the attacker has access to a set of node features and
their labels without any knowledge about the GCN structure
and parameters.
To start with, we formalize the link re-identiﬁcation attack
proposed in Section III-B as the following game between the
graph owner Alice and the attacker Bob:
1) Let V be a set of nodes and AV be the set of all possible
adjacency matrices for graphs with nodes V . First, Alice
selects an adjacency matrix A ∈ AV uniformly at random
and uses it to generate a graph.
2) Bob selects a set of training nodes V (T ) ⊆ V . He sends
3) Alice then trains an ε-edge differentially private GCN
V (T ) with the features and labels of V (T ) to Alice.
model and exposes the inference API GBB to Bob.
4) Bob selects a set of inference nodes V (I) ⊆ V and nodes of
interests V (C) ⊆ V (I). Let k(C) denote the graph density
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:20:38 UTC from IEEE Xplore.  Restrictions apply. 
2011
over V (C). For each pair of nodes ∈ V (C)×V (C),
Bob launches a link re-identiﬁcation attack RGBB (u, v) to
infer whether an edge exists between nodes u and v, and
RGBB (u, v) ∈ {0, 1}.
To obtain an upper bound for the above attack, we assume
the attacker knows the inference node density k(C). Formally,
we bound the expected precision of the link re-identiﬁcation
attack R by the following theorem.
Theorem 6. The precision of RGBB over nodes of interests
V (C) with density k(C) is upper-bounded by:
[Auv = 1 | RGBB (u, v) = 1] ≤ exp(ε) · k(C),
∈V (C)×V (C)
where the probability is calculated over the randomness in the
graph selection, the noise introduced by the DP GCN training,
and the selection of node pair .
Pr
Proof Sketch. Based on Deﬁnition 3 and Bayes’ theorem,
the ratio between the posterior probability Pr[Auv = 1 |
GBB ∈ S] and the prior belief on Pr[Auv = 1] is bounded by
exp(ε). Since the precision of a random guess based on the
prior probability (i.e., the graph density) is at most k(C), the
upper bound for the precision of a link re-identiﬁcation attack
on an ε-edge differentially private GCN is exp(ε) · k(C). The
complete proof is provided in Appendix C.
Although Theorem 6 provides a theoretical upper bound for
the precision of an edge re-identiﬁcation attack, it may not
be sufﬁciently tight to provide the best privacy-utility trade-
off. For example, given a graph with 1% density, the attack
precision is bounded below 2% (i.e., no more than two times
higher than random guessing using the prior probability) if
and only if ε ≤ ln 2. However, in practice, the same empirical
protection might be achieved by a model with weaker privacy
protection (i.e., higher privacy budget) and therefore better
utility. Thus, in Section VI-B, we empirically evaluate the
privacy-utility trade-off of DP GCN across multiple datasets.
In addition to DP GCN approaches, it may also be possible
to leverage some heuristics to detect such attacks. For instance,
one may distinguish the abnormal behavior of querying the
same set of inference nodes V (I) multiple times (with the
node features of one node slightly altered in each query). The
defender could also optimize a query limit Q which decreases
the attack performance while maintaining reasonable benign
query accuracy, although there is no guarantee for such detec-
tion. More discussions on the detection strategies are deferred
to Appendix E1, and in this paper, we will focus on the DP
GCN mechanisms with privacy guarantees.
V. EVALUATION OF LINKTELLER
We evaluate the effectiveness of the LINKTELLER attack
on multiple graph datasets under various scenarios compared
with three baselines. In particular, we investigate how different
factors such as node degree affect the attack performance.
A. Datasets
We evaluate LINKTELLER on eight datasets in the induc-
tive setting and three datasets in the transductive setting (Ap-
pendix F1) and provide a brief description of the data below.
the ﬁrst dataset
is the twitch
Under the inductive setting,
dataset [29] which is composed of 6 graphs as disjoint sets
of nodes. Each of the graphs represents a set of people in
one country; the nodes within a graph represent users in one
country, and the links represent mutual friendships between
users. The dimension of the features is the same across differ-
ent graphs and each dimension has the same semantic mean-
ing. Some sampled features include games they like, location,
and streaming habits. The task is a binary classiﬁcation task
which classiﬁes whether a streamer uses explicit language.
This dataset is proposed for transfer learning, i.e., applying the
model learned on one graph to make inferences on the other
graphs corresponding to different countries. In our evaluation,
we train the GNN model on the graph twitch-ES, and trans-
fer it to other ﬁve countries (RU, DE, FR, ENGB, PTBR).
PPI [14] and Flickr [16] are another two standard datasets
used in graph inductive learning setting. PPI is a dataset for
multi-label classiﬁcation task, which aims to categorize the
function of proteins across various biological protein-protein
interaction graphs. Flickr is an evolving graph for the classiﬁ-
cation task, which contains descriptions and common proper-
ties of images as node features. For both PPI and Flickr, we
use the standard splits for training and testing following the
previous works. Under the transductive setting, we adopt three
standard datasets (Cora, Citeseer, and Pubmed). More details
of the data can be found in Appendix F1.
B. Models
We mainly experiment with GCN models. The conﬁgu-
rations/hyperparameters include the normalization techniques
applied to the adjacency matrix, the number of hidden layers,
the number of input units, hidden units, and output units, as
well as the dropout rate. For each combination of hyperparam-
eters, we train the network to minimize the cross-entropy loss
for the intended tasks. We performed grid search to get the best
set of hyperparameters on the validation set. The search space
for the hyperparameters and the formulae for different normal-
ization techniques are provided in Appendix F. To measure
the performance of a GCN model, we follow previous work
and use F1 score for their corresponding binary classiﬁcation
tasks. We leave the description of the best hyper-parameters
we achieve in Appendix F5. In addition to the 2-layer GCNs
evaluated in the main paper, in Appendix G2, we also ex-
perimented with the 3-layer GCNs and include a discussion
about GCNs of 1 layer and more than 3 layers. We conclude
that LINKTELLER is a successful attack against most practical
GCN models. In addition, we evaluate LINKTELLER on Graph
Attention Networks (GATs). The details are in Section V-F.
C. Setup of the Evaluation
In this section, we ﬁrst describe the metrics we use to
evaluate the attack effectiveness of LINKTELLER. We then
present the baseline attack methods.
1) Evaluation Metrics of the attack: We use the standard
metrics: precision (the fraction of existing edges among the
pairs recognized as true by Bob) and recall (the fraction of
edges discovered by Bob over all existing edges among the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:20:38 UTC from IEEE Xplore.  Restrictions apply. 
2012
subset of nodes). We also compute the F1 score (the harmonic
mean of precision and recall). The reason we adopt the met-
ric is that our problem here (distinguishing connected pairs
from unconnected ones) is an imbalanced binary classiﬁcation
problem where the minority (the connected pair) is at the core
of concern. See Appendix F2 for more details. Additionally,
for fair comparison with baselines, we follow the evaluation
in He et al. [11] and compute the AUC score.
2) Baseline Attacks: We compare LINKTELLER with two
baselines: random attack and LSA2 attacks in He et al. [11].
For the random attack, we follow the standard notion and
construct a random classiﬁer as a Bernoulli random variable
with parameter p which predicts true if and only if the random
variable takes the value 1 [30]. Given a set of instances where
a of them are true and b are false, the precision of this classiﬁer
is a/(a + b) and the recall is p. In our case, a is the number
of connected pairs of nodes, while a + b is the number of
all pairs. Therefore, precision is exactly the density k of the
subset, which we formally deﬁne as k = 2m/(n(n − 1)),
where n = |V (C)| is the size of the set of interest and m is
the number of connections among the set V (C). The recall of
such a random classiﬁer will be the density belief ˆk.
We also compare LINKTELLER with the state of the art
LSA2 attacks [11]. In the paper, the authors discussed several
types of background knowledge including node attributes, par-
tial graph, and a shadow dataset for attackers. Among the com-
binations, their Attack-2 is closest to our scenario where the
attacker has only access to the target graph’s node features. We
follow their best practices, computing the correlation distance
between 1) posteriors given by the target model and 2) node
attributes, referred to as LSA2-post and LSA2-attr attacks.
D. Evaluation Protocol
Think about the paparazzi who are fanatical about exploit-
ing the connections among celebrities, or the indiscriminate
criminals that are maliciously targeted at the mass mediocre
majority, their targets are substantially different. Consequently,
the subsets they gather for attack have diverse node degree dis-
tributions. Catering to the need of evaluating our attack against
nodes of different degree distributions, we design the scenario
as follows. We consider three types of subsets that are of
potential interest to the attacker: nodes of low degree, uncon-
strained degree, and high degree. For each type, we randomly
sample a ﬁxed number n(C) of nodes to form a subset V (C) for
evaluation. When sampling nodes of low (or high) degree, we
place a threshold value dlow (or dhigh) and sample from nodes
whose degrees are no larger than dlow (or no smaller than
dhigh). The value dlow and dhigh are chosen empirically based
on the graph. When sampling nodes of unconstrained degree,
we sample nodes from the entire test set uniformly at random.
More speciﬁcally, for all datasets, we choose n(C) =
|V (C)| = 500. For twitch datasets, to form the unconstrained
subset, we sample from each entire testing graph. For the low
degree subset and high degree subset, the threshold dlow and
dhigh are set to 5 and 10, respectively. We set the dlow value
to 10 for twitch-PTBR, since the graph is much denser with
abundant connections among a small number of nodes. For
PPI and Flickr graphs, the subsets for testing are sampled from
the testing graphs/nodes that are not involved in training. We
set dlow as 15 and dhigh as 30 for these two large graphs.
We also evaluate different density belief ˆk ∈ {k/4, k/2, k,
2k, 4k}, where k is the true density. In the experiments, we
round the density k to the closest value in its most signiﬁ-
cant bit (e.g., 5.61e-5 rounded to 6e-5). As we will see, the
effectiveness of LINKTELLER does not heavily depend on the
exact knowledge of the density k.
E. Evaluation for LINKTELLER
We ﬁrst evaluate the precision, recall, and AUC of LINK-
TELLER on eight datasets in the inductive setting, under 3 sam-
pling strategies (low, unconstrained, and high degree), using 5
density beliefs (k/4, k/2, k, 2k, 4k), compared with different
baselines. For each scenario, the reported results are averaged
over 3 runs using different random seeds for node sampling.
We report the precision, recall, and AUC results on some
datasets in Table I and Table II and the remaining datasets
in Appendix G4 due to the space limit. We leave the results of
the weak random attack baseline in Appendix G1. As a brief
summary, LINKTELLER signiﬁcantly outperforms the random
attack baseline. We mainly focus on the comparison with
LSA2 attacks [11]. We show that LINKTELLER signiﬁcantly
outperforms these two baselines. In Table I, LSA2-{post, attr}
fail to attack in most of the scenarios, while LINKTELLER
attains fairly high precision and recall. The AUC scores in Ta-
ble II also demonstrate the advantage of LINKTELLER. Since
the baselines LSA2-{post, attr} are only performed under
transductive setting in He et al. [11], to demonstrate the gener-
ality of LINKTELLER, we also compare with them following
the same evaluation protocol as in He et al. [11] on three
datasets in the transductive setting. The results are reported
in Appendix G5. We can see that the inductive setting is indeed
more challenging: the baselines always fail to attack in the
inductive setting while LINKTELLER is effective; the baselines
are able to re-identify some private edges in the transductive
setting, while LINKTELLER is consistently more effective.
Intuitively, the high attack effectiveness of LINKTELLER
compared to baselines is because that LSA2-{post, attr} only
leverage node-level information (posteriors or node attributes)
to perform the edge re-identiﬁcation attack. Although these
node-level features can be correlated with the graph structure
in some graphs, this correlation is not guaranteed, especially in
the inductive setting. In comparison, LINKTELLER leverages
the graph-structure information inferred from the inter-node
inﬂuence in a GCN model according to Theorem 1. We defer
more detailed comparison and analysis in Appendix E5.
In addition, it is clear that given an accurate estimation
of the density (ˆk = k), LINKTELLER achieves very high
precision and recall across different node degree distributions
and datasets. It is interesting to see that even when the density
estimation is inaccurate (e.g., ˆk ∈ {k/4, k/2, 2k, 4k}), the
attack is still effective. Concretely, when the belief is smaller
(ˆk = k/2), the precision values increase in all cases; when the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:20:38 UTC from IEEE Xplore.  Restrictions apply. 
2013
TABLE I: Attack Performance (Precision and Recall) of LINK-
TELLER on different datasets, compared with two baseline methods
LSA2-{post, attr} [11]. Each table corresponds to a dataset. We
sample nodes of low, unconstrained, and high degrees as our targets.
Groups of rows represent different density belief ˆk of the attacker.
twitch-RU
ˆk
Method
k/4
k/2
k
2k
4k
Ours
LSA2-post
LSA2-attr
Ours
LSA2-post