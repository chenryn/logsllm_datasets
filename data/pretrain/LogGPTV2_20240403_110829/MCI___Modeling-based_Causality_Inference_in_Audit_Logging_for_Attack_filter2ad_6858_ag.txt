### Constructing Causal Models for Zipsplit and PINE

A related causal model for Zipsplit is presented in Figure 18, which corresponds to the "read n files and compress to an output file" behavior. This model is context-free because it contains two groups of nodes (from the 4th to the 6th and from the 12th to the 16th) that have the same number of repetitions. The first group is responsible for reading the metadata of the n input files, while the second group reads the contents of these files and writes them to an output file.

MCI matches these models over the audit log collected from the attacker's machine, accurately revealing the causality between the secret document and the outgoing message. Figure 19(b) presents a causal graph generated by MCI, showing that c1.zip and c2.zip are derived from secret.pdf and are sent out via PINE. In contrast, Figure 19(a) shows a causal graph generated by BEEP, which contains many false-positives. BEEP was unable to identify removed attachments or the causal relations between inputs and outputs of Zipsplit. Upon manual inspection, we found that Zipsplit first compresses input files into a temporary file, then splits this file into multiple output files. Consequently, BEEP considers the temporary file dependent on all input files and the output files dependent on the temporary file, leading to the incorrect assumption that all output files are dependent on all input files. MCI, however, infers precise causality between each input and output file through implicit dependencies annotated in the model.

### Long-Running Real-World Applications

In our final experiment, we evaluate MCI on large-scale real-world workloads. Specifically, we use two months of NASA HTTP server access logs obtained from [41] and three months of our institution's HTTP server access logs (from November 2015 to January 2016). To obtain audit logs from the HTTP access logs, we first emulate the web server environment by crawling all the contents of the original servers. We then create a script that connects and accesses the web server according to the access log, allowing the audit logging system on our server to regenerate logs for analysis.

#### Table V: Evaluation on Long-Running Executions

| Access Log        | # of req. (unique) | Elapsed Time     | FP / FN   |
|-------------------|--------------------|------------------|-----------|
| NASA-HTTP [41]    | 3.4M (36K)         | 19 hrs 41 mins   | 3.9% / 0.2% |
| Our Institution   | 5.6M (4.2M)        | 40 hrs 13 mins   | 1.1% / 0.1% |

Our parser takes 19 hours and 40 hours to parse the logs from [41] and our institution, respectively. Given the size of the logs, we argue that our parser is reasonably scalable. For accuracy, we observe 3.9% and 1.2% false-positives for the respective logs. Analysis reveals that the NASA-HTTP log includes more CGI requests than our institution's log, with most false-positives originating from these CGI requests. Additionally, we have 0.2% and 0.1% false-negative rates, primarily caused by CGI requests and suspicious requests embedding binary payloads, which crash the web server during the experiment. Overall, the results show that MCI is scalable and effective in identifying causality over large-scale logs.

### Related Work

#### Causality Tracking

Several works have focused on tracking causal dependencies for system-level attack analysis [25], [16], [24], [26], [29], [23]. BackTracker [25] and Taser [16] propose backward and forward analysis techniques to identify the entry point of an attack and understand the damage to the target system. Recent works [32], [37], [36] aim to provide accurate and fine-grained attack analysis. Dynamic taint analysis techniques [42], [21], [20] track information flow between taint sources and sinks. SME [12] detects information flows between different security levels by running a program multiple times. LDX [31] proposes a dual execution-based causality inference technique, starting a slave execution by mutating input sources and comparing outputs to identify causal dependencies.

#### Program Behavior Modeling

Constructing program models representing internal structures or behaviors has been extensively studied, particularly in anomaly detection [46], [28], [14], [48], [50], [47]. These models are typically trained on benign executions and abstracted using methods such as DFA [28], FSA [46], [14], push-down automaton (PDA) [48], hidden Markov models [50], and machine learning [47], [34]. However, these models often lack dependency information. Incorporating dependencies (acquired from LDX) in our models allows us to use them for attack provenance investigation but also introduces new technical challenges. Static binary dependency analysis is difficult, making the generation of precise models using static analysis highly challenging.

### Discussion

#### Kernel-Level Attack

We trust audit logs collected at the victim system. Most audit logging systems, including Linux Audit and Windows ETW, collect and store logs at the kernel level. A kernel-level attack could disable the logging system or tamper with the logs. One possible solution is to integrate with LPM-HiFi [6], which provides stronger security guarantees.

#### Limitations by LDX [31]

In our offline analysis, we leverage LDX to construct causal models, inheriting its limitations. LDX doubles resource consumption, such as memory, processor, and disk storage, to run a slave execution alongside the original execution. However, these limitations apply only to offline analysis and do not affect end-users.

#### Model Coverage

MCI relies on causal models generated by training with typical workloads. If an audit log includes behaviors not covered by the provided models, MCI may not infer causality precisely, leading to false-positives/negatives. The cascading effect of missing models is mostly limited within a unit (e.g., each request in a server program) because MCI starts a new model instance when it encounters an input syscall that matches the model. We can detect matching failures due to incomplete models during parsing. Missing models often lead to causal graphs lacking important I/O-related system objects, which can be used to enhance the model by training with more workloads. Additionally, we can fall back to a conservative strategy, assuming unmatched events have inter-dependencies.

#### Signal and Exception Handler

Signals and exceptions can interrupt normal execution flow. System calls in handlers may affect our parser, but in practice, our models are robust enough to handle additional system calls. System calls in signal or exception handlers are generally distinct from those in our causal models, allowing our parser to filter them out. In many programs, such as Lighttpd, handler functions do not invoke any system calls. We plan to extend MCI to construct proper models for signal and exception handlers, enabling the identification and extraction of handler models from the audit log before applying MCI's model parsing process.

### Conclusion

We present MCI, a novel causality inference algorithm that works directly on audit logs from commodity systems without requiring special efforts or frameworks. Our offline analysis precisely infers causality from system call logs by constructing and identifying causal models. We implemented a prototype of MCI, and our evaluation results show that MCI is scalable and effective in handling large-scale logs from long-running applications. MCI can also accurately identify causal relations in realistic attack scenarios.

### Acknowledgment

We thank the anonymous reviewers for their constructive comments. This research was supported, in part, by DARPA, NSF, ONR, Sandia National Lab, and Cisco Systems. Any opinions, findings, and conclusions in this paper are those of the authors and do not necessarily reflect the views of our sponsors.

### References

[References listed here as in the original text.]

---

This version of the text is more structured, coherent, and professional, with improved clarity and flow.