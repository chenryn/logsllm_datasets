time) because we have controlled for correlated factors such as
chip density and CPU count. Not all systems exhibit this trend,
however: the h1; 12i system shows a small decrease in failure
rate going from 3 ! 4 years of age, which could be due to
second-order effects on failure rate from other factors that may
be correlated with age, such as transfer width.
V. MODELING DRAM FAILURES
We next develop a model for DRAM failures using the data
collected from our study. We use a statistical regression analysis
422422
●
1 Gb
2 Gb
4 Gb
●
e
t
a
r
e
r
u
l
i
a
f
r
e
v
r
e
s
e
v
i
t
a
e
R
l
0
0
.
1
0
5
.
0
0
0
.
0
●
3
●
4
1
2
1 Gb, 12 cores
2 Gb, 4 cores
2 Gb, 8 cores
2 Gb, 12 cores
2 Gb, 16 cores
4 Gb, 16 cores
e
t
a
r
e
r
u
l
i
a
f
r
e
v
r
e
s
e
v
i
t
a
e
R
l
0
0
.
1
0
5
.
0
0
0
.
0
●
3
●
4
1
2
Server age (years)
Server age (years)
●
1 Gb
2 Gb
4 Gb
e
t
a
r
e
r
u
l
i
a
f
r
e
v
r
e
s
e
v
i
t
a
e
R
l
0
0
.
1
0
5
.
0
0
0
.
0
●
4
8
12
16
CPU cores
Fig. 14: The relative failure rate of
servers of different ages. There is no
clear trend when controlling only for
chip density.
Fig. 15: The relative failure rate of servers of different
hchip density; CPU counti conﬁgurations. When controlling for
density and CPUs together, older devices usually have higher
failure rates.
Fig. 16: The relative failure rate of
servers with different numbers of CPU
cores. Servers with more CPUs have
higher failure rates.
TABLE II: The factors in our regression analysis and the resulting error model. p-value is the likelihood that a characteristic is inaccurately modeled: lower
p-values indicate more accurate modeling. Signiﬁcant? is whether the p-value is < 0:01, corresponding a < 1% chance that the characteristic is inaccurately
modeled. ˇ-coefﬁcient is the characteristic’s contribution to error rate and standard error is how much the model differs from the measured values for a given
characteristic. The model is publicly available at [1].
Characteristic
Intercept
Capacity
Density2Gb
Density4Gb
Chips
Width8
CPU%
Memory%
Age
CPUs
Failure model
Yes
p-value
Signiﬁcant?
Description
Standard error
A baseline server with 1 Gb chips with a (cid:3)4 interface and 0 <2:000 (cid:3) 10(cid:2)16
3:011 (cid:3) 10(cid:2)1
for all other factors.
<2:000 (cid:3) 10(cid:2)16
2:168 (cid:3) 10(cid:2)2
DIMM capacity (GB).
<2:000 (cid:3) 10(cid:2)16
1:039 (cid:3) 10(cid:2)1
1 if the server has 2 Gb density chips; 0 otherwise.
<2:000 (cid:3) 10(cid:2)16
1:907 (cid:3) 10(cid:2)1
1 if the server has 4 Gb density chips; 0 otherwise.
<2:000 (cid:3) 10(cid:2)16
1:294 (cid:3) 10(cid:2)2
Number of chips per DIMM.
1 if the server has (cid:3)8 DRAM chips; 0 otherwise.
1:277 (cid:3) 10(cid:2)1
0:071
<2:000 (cid:3) 10(cid:2)16
1:633 (cid:3) 10(cid:2)3
Average CPU utilization (%).
1:224 (cid:3) 10(cid:2)3
Average fraction of allocated physical pages (%).
0:962
<2:000 (cid:3) 10(cid:2)16
3:956 (cid:3) 10(cid:2)2
Server age (years).
<2:000 (cid:3) 10(cid:2)16
1:449 (cid:3) 10(cid:2)2
Number of physical CPU cores in the server.
ln ŒF =.1 (cid:4) F / D ˇIntercept C .Capacity (cid:5) ˇCapacity/ C .Density2Gb (cid:5) ˇDensity2Gb/ C .Density4Gb (cid:5) ˇDensity4Gb/ C .Chips (cid:5) ˇChips/
Yes
Yes
Yes
Yes
No
Yes
No
Yes
Yes
C.CPU% (cid:5) ˇCPU%/ C .Age (cid:5) ˇAge/ C .CPUs (cid:5) ˇCPUs/
ˇ-coefﬁcient
(cid:4)5:511
9:012 (cid:3) 10(cid:2)2
1:018
2:585
(cid:4)4:035 (cid:3) 10(cid:2)2
2:310 (cid:3) 10(cid:2)1
1:731 (cid:3) 10(cid:2)2
5:905 (cid:3) 10(cid:2)5
2:296 (cid:3) 10(cid:2)1
2:126 (cid:3) 10(cid:2)1
to determine which server characteristics have a statistically
signiﬁcant effect on failure rate and how much they contribute
to failure rate. The resulting model can then be used to examine
how relative server failure rate changes for servers with different
characteristics, which can be used to reason about the relative
reliability of different server conﬁgurations.
We used R [3] for our statistical analysis. We performed
a logistic regression [15, 32] on a binary characteristic that
represented whether a server was part of the error group or
control group of servers (see Section II-E for our error and
control group classiﬁcation/formation). We include most of the
characteristics we analyzed in Section IV in our regression with
the exception of DIMM vendor because it is anonymized and
workload type because it is difﬁcult to apply outside the context
of our ﬂeet.7 One limitation of the logistic regression model
is that it is able to identify only linear relationships between
characteristics and failure rates. On the other hand, using a
logistic regression made analyzing our large data set of errors
across many variables tractable.
Table II shows the parameters and output of the regression
and the resulting model (in the last row). The ﬁrst two columns
describe the factors included in the regression. The third column
lists the resulting p-value for each factor after performing
the logistic regression. The p-value is the likelihood that a
characteristic is inaccurately modeled: lower p-values indicate
more accurate modeling. The fourth column describes whether
the p-value is < 0:01, corresponding to a < 1% chance that
the characteristic is inaccurately modeled. The ﬁfth column, ˇ-
7This results in these contributions to the model being expressed indirectly
though other factors, whose values will be computed, in part, based on how
they are correlated with different vendors.
423423
coefﬁcient, is the characteristic’s contribution to error rate and
the last column, standard error, is how much the model differs
from the measured values for a given characteristic.
The Intercept is a byproduct of the regression and helps the
model ﬁt the measured data better. It represents a server with
a certain set of baseline characteristics (listed in Table II) and
0 for all other factors (0 CPUs, 0 years old, and so on). The
factors Density2Gb and Density4Gb take on the value 0 or 1
depending on whether the server has the characteristic (in which
case the value is 1) or does not (0). Note that the regression
analysis computes the ˇ-coefﬁcients for these variables in such
a way that when they are added to the model, they effectively
replace the default values represented in ˇIntercept (e.g., though
ˇIntercept represents a server with 1 Gb chips, when Density2Gb
is set to 1, the model computes the failure rate of servers with
2 Gb chips).
Note that a characteristic that is included in the model
does not necessarily mean that it affects failure rate in the
real world. It may mean that it is only correlated with other
characteristics that do affect failure rate. The opposite is true
as well: A characteristic that is not included in the model may
in fact contribute to failure rate but its effects are captured
by other characteristics present in the model. For example,
Figure 17 shows a heatmap representing the correlation between
the different measured factors: darker colors correspond to a
stronger correlation while lighter colors correspond to a weaker
correlation. While some factors that are independent of one
another have weak or no correlation (i.e., close to 0, such
as CPUs and Chips), others show strong correlations (i.e.,
more/less than ˙0:8, such as Capacity and Chips). We have
discussed and attempted to control for these correlations in
Section IV.
i
h
t
d
w
p
h
C
i
%
y
r
o
m
e
M
%
U
P
C
e
g
A
Age
CPU%
Memory%
Chip width
CPUs
Density
Capacity
Chips
y
t
i
s
n
e
D
s
U
P
C
y
t
i
c
a
p
a
C
i
s
p
h
C
1
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
−1
4 GB
16 GB
Fig. 17: The correlation between different measured factors.
1
0
16
25%
0
1
32
25%
1
0
16
50%
0
1
32
50%
Using the equation in Table II, we can solve for F, the rate
of memory failure for a server with a given set of characteristics.
For example, Table III compares the failure rates predicted by
the model for four different server types: (1) a low-end server
with low density DIMMs and few CPUs, (2) a high-end (HE)
server with high density DIMMs and twice as many CPUs
as the low-end server, (3) a high-end server that uses lower-
density DIMMs (HE/#density), and (4) a high-end server that
uses half as many CPUs (HE/#CPUs). So that the workload is
kept roughly similar across the conﬁgurations, we double the
CPU utilization for servers with half as many CPUs.
TABLE III: Predicted relative failure rates among different server types.
Low-end High-end (HE) HE/#density HE/#CPUs
Factor
Capacity
16 GB
4 GB
Density2Gb
Density4Gb
Chips
CPU%
Age
CPUs
Predicted
relative
failure rate
We can see that the model-predicted failure rate of the high-
end server is 6:5(cid:2) that of the low-end server. This agrees with