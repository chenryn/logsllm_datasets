probability of their coincidence given their joint distribution and
marginal distributions under the assumption of independence, and
is defined as PMI(x, y) = log p(x,y)
p(x)p(y). Higher PMI values indicate
greater association between x and y. Figure 3 shows the PMI values
for every pair of surveillance capabilities, as captured by our dataset
of 4,839 labeled apps. The top-3 strongest associations involve Email,
and they are between Email and the surveillance capabilities of
Keylogging, Screen, and Browsing-History, respectively.
5
Browsing-HistoryCall-LogsCall-RecordingsCameraContactsEmailGPS-TrackingInstalled-AppsKeyloggingMedia-ExtractionMicrophoneScreenSMSCall-LogsCall-RecordingsCameraContactsEmailGPS-TrackingInstalled-AppsKeyloggingMedia-ExtractionMicrophoneScreenSMSSocial-Media2.852.732.372.531.962.342.862.672.461.933.702.883.103.073.031.931.721.291.441.681.993.512.742.772.772.743.641.953.502.702.772.682.764.001.743.313.362.612.592.412.803.551.723.213.342.632.072.573.212.093.041.312.722.642.483.292.532.742.902.573.701.663.093.593.142.852.762.642.081.812.622.811.622.662.572.601.902.431.711.271.010.761.341.920.371.531.671.550.861.491.220.00.51.01.52.02.53.03.54.0961ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Han, Roundy, Tamersoy
vectors for each training text instance as follows:
tf-idf(w, d) = T F(w, d) log(N/(d f + 1))
(1)
where w denotes each word considered in the feature extraction, d
represents a document that corresponds to an app’s self-description
in our case, and N denotes the number of apps in the dataset. The
component d f denotes the document frequency, which is defined as
the frequency of occurrence of word w in the training text instances,
while T F(w, d) represents the term frequency, which is defined as
the instance count of word w in the training document d divided by
the number of words contained in document d. In the computation
of term frequency, all words are considered equally important,
though clearly, certain words may appear many times and yet have
little importance. Therefore, the second part of the equation, which
represents inverse document frequency (IDF), assigns low weights
to frequent terms while scaling up the importance of rare terms.
5.2 Detection with Learning-by-prediction
There are three important advantages of using active learning in
our work. Most fundamentally, no labeled dataset of stalkerware
surveillance capabilities is in existence, and constructing a big one
is time consuming. Second, stalkerware apps are sufficiently rare
that randomly sampling Android apps would be unlikely to turn
up any meaningful number of stalkerware apps to label. Indeed,
the Coalition Against Stalkerware’s [18] Stalkerware Threat List
contains fewer than ten thousand Android app ids, and security
vendors report observing 10 million or more app ids installed on
their customers’ devices in a year [42]. Finally, active learning not
only allows us to iteratively update our classifier’s parameters as
we process, but it also helps to adjust our threat detection pipeline
by incorporating additional data cleaning and/or improving feature
engineering. Our own experience provides examples of why this
helps. After the first few iterations of active learning with Dosmelt,
we made two realizations. First, among the highest ranking apps
were many apps in foreign languages that were not being suitably
categorized by Dosmelt because of overfitting due to insufficient
training data for languages other than English. This led us to adjust
our pipeline to improve its foreign-language filtering, limiting our
classifier to English. Second, as a result, we came to the determi-
nation that we should exclude keywords as features if they appear
only once. These two changes dramatically improved the classifier
in subsequent iterations of active learning.
In Algorithm 1, we provide Dosmelt’s active learning methodol-
ogy. In each iteration, we maintain a trained classifier f consisting
of an ensemble of base decision models fk (k = 1, 2, 3, ..., L). Each
base model fk is trained to increase the diversity between each
other, e.g., by randomly sampling feature subsets in training in a
random forest model. Classifier f then parses the set of the unla-
belled textual app descriptions. For each unlabelled instance, each
fk produces a confidence score normalized between 0 and 1 via the
sigmoid function. For detection, a higher confidence score denotes
that it is more likely that the app is stalkerware. For classification,
the magnitude of the score measures the decision confidence of
tagging an app with a specific surveillance capability. The resultant
confidence scores are ranked in descending order. The unlabelled
instances with the top-K ranked confidence scores are then investi-
gated by human analysts. After confirming/correcting the labels of
be represented as S(xi) =M
these instances, they are added to the training dataset. Finally the
classifier f is retrained with the updated training set. The number
K of selected instances for manual verification decides the sampling
coverage of the active learning method.
Let us denote the textual feature of an unlabelled app as xi,
(i = 1, 2, 3, ..., |U|). Assume yi = +1 if the app is stalkerware (for de-
tection) or has a specific stalkerware capability, and vice versa. The
ensemble vote score produced on the unlabelled textual instance can
k =1 fk(xi). The learning-by-prediction
method [1] augments the training dataset by hand-labeling the
unlabelled data instances for which the current detection/classifier
outputs the highest S(xi). If the true class label of xi is yi, the classi-
fication margin of xi with respect to the current detection/classifier
model f is given as mf (xi , yi) = yi(2∗ S(xi)− 1). The data instance
selection criterion applied in [1] has a two-fold goal. For the cor-
rectly detected/classified instances, the human annotator confirms
the prediction output from the ensemble model. The corresponding
instances usually contain very indicative keywords/terms denoting
the suspicious surveillance capabilities, which clearly differentiate
stalkerware and non-stalkerwre apps. For the misclassified instances,
where mf (xi , yi) is negative yet with a large magnitude, the hu-
man annotator identifies the misclassification error and provides
their true labels. In this sense, the learning-by-prediction step in
[1] converges to the well known principle of misclassification loss
reduction in active learning [47]:
x∗ = arg max
xi
Pθ ( ˆyi = 1|xi)ℓf (xi, yi)
(2)
where ˆyi is the predicted label by f , Pθ( ˆyi = 1|x) denotes the prob-
abilistic decision confidence of the classifier f , and ℓf (xi , yi) is the
misclassification loss of the current f over the data instance (xi , yi),
which is a monotonically decreasing function of the classification
margin. For the nuanced classification, since f produces multiple
outputs simultaneously, one per surveillance capability, Equation 2
can be instantiated to the multi-label learning scenario:
m
j =1
x∗ = arg max
xi
Pθ ( ˆyi, j = +1|xi)ℓf (xi, yi, j)
(3)
where m denotes the number of the surveillance capabilities in-
volved in the nuanced classification, and ˆyi, j and yi, j are the pre-
dicted label of xi with respect to the surveillance capability j (j =
1, 2, 3, ..., m). The inconsistency between the predicted class labels
and the ground truth labels denotes the incapability of the current
model in capturing the underlying decision boundaries. Adding
these instances for retraining can thus help correct the bias in
f causing large misclassification loss. Note that the dataset we
collected is heavily skewed towards benign apps due to the rare
existence of stalkerware apps. Therefore, the learn-by-prediction
process for building the stalkerware detector examines the apps
that are confidently classified to be malicious. In the first iterations
of the training process, we can find many false alarms in these
top-ranked apps. Correcting the mislassification errors then helps
the detector in terms of refining the boundary in the textual feature
space between the stalkerware and benign apps.
6
962Towards Stalkerware Detection with Precise Warnings
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Output: Learned stalkerware detector/classifier f
D0←D;
M0←M;
for t = 1 to m do
2 , ..., ft
L } ← A(Dt−1);
{ft
1 , ft
Generate voted confidence scores
y = {yi }(i = 1, 2, 3, ..., |Mt−1|) ←L
i =1 ft
i (Mt−1);
Algorithm 1: Learning-by-prediction Active Learning Framework
Input: Initial training dataset D, untagged textual training
instances M, a training paradigm A for the ensemble
classifier, the training rounds m
Select top-K text instances (denoted as S t ) with the largest yi
from M;
Let human analysts verify the true labels of the text samples in S;
Update the training text sample set D: Dt ← Dt−1 + S t , with
the manually verified labels for S;
Mt ← Mt−1 − S t ;
end
return the ensemble classifier {fm
1 , fm
L };
2 , ..., fm
6 EXPERIMENTAL EVALUATION
We evaluate the performance of our method with a dataset com-
posed of textual features for Android apps (see Section 3). Next, we
describe our experimental setup, cover the stalkerware detection
results, review the nuanced stalkerware capability detection results,
and provide insights into the classifier.
6.1 Experimental Setup
Our experimental setup consists of two components.
• Stalkerware detection: Detecting whether an app is an in-
stance of stalkerware is a classic binary classification task that
we approach with active learning because of the high cost of
labeling data for this purpose. When our detection module pro-
duces a positive label, it indicates that an input app contains
stalkerware functionality.
• Stalkerware capability detection: We further identify the
surveillance capabilities possessed by each stalkerware app
based on its textual features. In this classification task, the pres-
ence of a specific surveillance capability is indicated by a posi-
tive label. Note that some stalkerware apps might implement
multiple surveillance capabilities. This nuanced classification
task is thus an instance of multi-label classification, i.e., each
data instance can carry multiple labels.
To detect stalkerware, we experiment both with Random Forests
(RF) of 500 trees and Gradient Boosted Trees (GBDT) with 150
cascade layers as our ensemble detection model. Empirically, this
setting provides a stable detection accuracy. For the stalkerware
capability detection task, we use RF and Extremely Randomized
Trees (Extra-Tree) to build the ensemble classifier. Similar to RF,
Extra-Tree picks a random subset of candidate features for each tree.
Instead of looking for the most discriminative thresholds for a tree
split, the thresholds are drawn at random for each candidate feature
and the best of them is used as the splitting rule. This reduces the
variance of the model, at the expense of a slight increase in bias.
7
Accuracy
RF
0.763
0.900
0.960
0.975
GBDT
0.735
0.880
0.940
0.960
Round
0
1
2
Baseline
AUC
RF
0.760
0.897
0.960
0.970
GBDT Number of labeled instances
0.740
0.865
0.932
0.942
200/400 (stalkerware/benign apps)
400/470 (stalkerware/benign apps)
600/520 (stalkerware/benign apps)
All labeled instances
Table 2: Stalkerware detection results of different training
rounds in Dosmelt using Random Forest (RF) and Gradient
Boosted Trees (GBDT).
Both of these the tree-ensemble based methods are easy to tune
and generalize well across many data mining scenarios [10]. Fur-
thermore, RF and GBDT model training and feature importance
ranking (via measuring out-of-bag error) are easily parallelized. Fea-
ture importance evaluations measure the informativeness of each
keyword in the textual feature space. Though deep neural network
architectures might be able to improve classification performance,
we leave such experiments for future work.
6.2 Stalkerware Detection with Active Learning
We conduct studies to evaluate the overall performance of the Dos-
melt pipeline at the stalkerware prediction task and its ability to
learn quickly through active learning. First, we present a careful
measurement of Dosmelt’s performance in a cross-validation ex-
periment. Second, we present a more practical application of our
active learning methodology in which we use active learning to
improve Dosmelt’s ability to generalize to stalkerware detection
beyond our carefully curated dataset of labeled stalkerware apps.
A cross-validation study of Dosmelt’s stalkerware detection
using active learning. To measure Dosmelt’s stalkerware detec-
tion accuracy, we set aside 30% of the labeled dataset of Android
apps as an independent testing set and use the remaining 70% of
the labeled data for training. We repeat this training-testing split 5
times. The derived detection and classification performance metrics
are averaged and reported in Table 2. In particular, Table 2 shows
the result of a series of experiments we conducted to evaluate Dos-
melt’s active learning methodology. Each of the three rounds of
active learning use increasing amounts of labeled data during train-
ing. In the first iteration we allow the classifier access to only a
small amount of labeled stalkerware and non-stalkerware apps,
with the remaining training samples are hidden from the classifier
and are considered as unlabelled instances. At the end of each round,
Dosmelt selects the unlabelled instances with confidence score
larger than 0.9 as the next apps to be labeled by human analysts,
which are added to the training set in the subsequent round. Thus,
we expect to see improved classification accuracy in subsequent