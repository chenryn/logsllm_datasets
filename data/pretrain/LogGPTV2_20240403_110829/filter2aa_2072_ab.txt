(often for cryptocurrency mining) are also drawn to Kubernetes to harness the 
underlying infrastructure. In addition to resource theft, cyber actors may also target 
Kubernetes to cause a denial of service. The following threats represent some of the 
most likely sources of compromise for a Kubernetes cluster: 
 Supply Chain Risk - Attack vectors to the supply chain are diverse and 
challenging to mitigate. Supply chain risk is the risk that an adversary may 
subvert any element that makes up a system, including product components, 
services, or personnel that help supply the end product. This can include third-
party software and vendors used to create and manage the Kubernetes cluster. 
Supply chain compromises can affect Kubernetes at multiple levels including: 
 Container/Application level - The security of applications running in 
Kubernetes and their third-party dependencies relies on the 
trustworthiness of the developers and the defense of the development 
infrastructure. A malicious container or application from a third party could 
provide cyber actors with a foothold in the cluster.  
 Infrastructure - The underlying systems hosting Kubernetes have their 
own software and hardware dependencies. Any compromise of systems 
used as worker nodes or as part of the control plane could provide cyber 
actors with a foothold in the cluster.  
 Malicious Threat Actor - Malicious actors often exploit vulnerabilities to gain 
access from a remote location. Kubernetes architecture exposes several APIs 
that cyber actors could potentially leverage for remote exploitation. 
 Control plane - The Kubernetes control plane has a variety of components 
that communicate to track and manage the cluster. Cyber actors 
frequently take advantage of exposed control plane components lacking 
appropriate access controls. 
 Worker nodes - In addition to running a container engine, worker nodes 
host the kubelet and kube-proxy service, which are potentially exploitable 
by cyber actors. Additionally, worker nodes exist outside of the locked-
down control plane and may be more accessible to cyber actors.  
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
6 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
 Containerized applications - Applications running inside the cluster are 
common targets. Applications are frequently accessible outside of the 
cluster, making them reachable by remote cyber actors. An actor can then 
pivot from an already compromised Pod or escalate privileges within the 
cluster using an exposed application’s internally accessible resources.  
 Insider Threat - Threat actors can exploit vulnerabilities or use privileges given 
to the individual while working within the organization. Individuals from within the 
organization are given special knowledge and privileges that can be used against 
Kubernetes clusters. 
 Administrator - Kubernetes administrators have control over running 
containers, including the ability to execute arbitrary commands inside 
containerized environments. Kubernetes-enforced RBAC authorization 
can help reduce the risk by restricting access to sensitive capabilities. 
However, because Kubernetes lacks two-person integrity controls, there 
must be at least one administrative account capable of gaining control of 
the cluster. Administrators often have physical access to the systems or 
hypervisors, which could also be used to compromise the Kubernetes 
environment.  
 User - Containerized application users may have knowledge and 
credentials to access containerized services in the Kubernetes cluster. 
This level of access could provide sufficient means to exploit either the 
application itself or other cluster components. 
 Cloud Service or Infrastructure Provider - Access to physical systems or 
hypervisors managing Kubernetes nodes could be used to compromise a 
Kubernetes environment. Cloud Service Providers often have layers of 
technical and administrative controls to protect systems from privileged 
administrators. 
▲Return to Contents 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
7 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Kubernetes Pod security 
Pods are the smallest deployable Kubernetes unit and consist of one or more 
containers. Pods are often a cyber actor’s initial execution environment upon exploiting 
a container. For this reason, Pods should be hardened to make exploitation more 
difficult and to limit the impact of a successful compromise. 
Figure 3: Pod components with sidecar proxy as logging container 
“Non-root” containers and “rootless” container engines 
By default, many container services run as the privileged root user, and applications 
execute inside the container as root despite not requiring privileged execution. 
Preventing root execution by using non-root containers or a rootless container engine 
limits the impact of a container compromise. Both of these methods affect the runtime 
environment significantly, so applications should be thoroughly tested to ensure 
compatibility. 
Non-root containers: container engines allow containers to run applications as a 
non-root user with non-root group membership. Typically, this non-default setting is 
configured when the container image is built. Appendix A: Example Dockerfile for 
non-root application shows an example Dockerfile that runs an application as a 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
8 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
non-root user. Alternatively, Kubernetes can load containers into a Pod with 
SecurityContext:runAsUser specifying a non-zero user. While the runAsUser 
directive effectively forces non-root execution at deployment, NSA and CISA 
encourage developers to build container applications to execute as a non-root user. 
Having non-root execution integrated at build time provides better assurance that 
applications will function correctly without root privileges.  
Rootless container engines: some container engines can run in an unprivileged 
context rather than using a daemon running as root. In this scenario, execution 
would appear to use the root user from the containerized application’s perspective, 
but execution is remapped to the engine’s user context on the host. While rootless 
container engines add an effective layer of security, many are currently released as 
experimental and should not be used in a production environment. Administrators 
should be aware of this emerging technology and seek adoption of rootless 
container engines when vendors release a stable version compatible with 
Kubernetes.  
Immutable container file systems 
By default, containers are permitted mostly unrestricted execution within their own 
context. A cyber actor who has gained execution in a container can create files, 
download scripts, and modify the application within the container. Kubernetes can lock 
down a container’s file system, thereby preventing many post-exploitation activities. 
However, these limitations also affect legitimate container applications and can 
potentially result in crashes or anomalous behavior. To prevent damaging legitimate 
applications, Kubernetes administrators can mount secondary read/write file systems for 
specific directories where applications require write access. Appendix B: Example 
deployment template for read-only filesystem shows an example immutable 
container with a writable directory.  
Building secure container images 
Container images are usually created by either building a container from scratch or by 
building on top of an existing image pulled from a repository. In addition to using trusted 
repositories to build containers, image scanning is key to ensuring deployed containers 
are secure. Throughout the container build workflow, images should be scanned to 
identify outdated libraries, known vulnerabilities, or misconfigurations, such as insecure 
ports or permissions.  
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
9 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Figure 4: A container build workflow, optimized with webhook and admission controller 
One approach to implementing image scanning is by using an admission controller. An 
admission controller is a Kubernetes-native feature that can intercept and process 
requests to the Kubernetes API prior to persistence of the object, but after the request is 
authenticated and authorized. A custom or proprietary webhook can be implemented to 
scan any image before it is deployed in the cluster. This admission controller could 
block deployments if the image doesn’t comply with the organization’s security policies 
defined in the webhook configuration [4]. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
10 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Pod Security Policies 
A Pod Security Policy (PSP) is a cluster-wide policy that specifies security 
requirements/defaults for Pods to execute within the cluster. While security mechanisms 
are often specified within Pod/deployment configurations, PSPs establish a minimum 
security threshold to which all Pods must adhere. 
Some PSP fields provide default values used when a 
Pod’s configuration omits a field. Other PSP fields are 
used to deny the creation of non-conformant Pods. 
PSPs are enforced through a Kubernetes admission 
controller, so PSPs can only enforce requirements 
during Pod creation. PSPs do not affect Pods already running in the cluster. 
PSPs are useful technical controls to enforce security measures in the cluster. PSPs 
are particularly effective for clusters managed by admins with tiered roles. In these 
cases, top-level admins can impose defaults to enforce requirements on lower-level 
admins. NSA and CISA encourage organizations to adapt the Kubernetes hardened 
PSP template in Appendix C: Example Pod Security Policy to their needs. The 
following table describes some widely applicable PSP components. 
Table I: Pod Security Policy components2 
Field Name(s) 
Usage 
Recommendations 
privileged 
Controls whether Pods can run 
privileged containers. 
Set to false. 
hostPID, hostIPC 
Controls whether containers can 
share host process namespaces. 
Set to false. 
hostNetwork 
Controls whether containers can 
use the host network. 
Set to false. 
allowedHostPaths 
Limits containers to specific paths 
of the host file system. 
Use a “dummy” path name (such 
as “/foo” marked as read-only). 
Omitting this field results in no 
admission restrictions being placed 
on containers. 
readOnlyRootFilesystem 
Requires the use of a read only 
root file system. 
Set to true when possible. 
runAsUser, runAsGroup, 
supplementalGroups, 
fsGroup 
Controls whether container 
applications can run with root 
privileges or with root group 
membership.  
- Set runAsUser to 
MustRunAsNonRoot. 
- Set runAsGroup to non-zero (See 
the example in Appendix C: 
Example Pod Security Policy).  
2 https://kubernetes.io/docs/concepts/policy/pod-security-policy 
Pod creation adheres 
to the least restrictive 
authorized policy. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
11 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Field Name(s) 
Usage 
Recommendations 
- Set supplementalGroups to non-
zero (see example in appendix C). 
- Set fsGroup to non-zero (See the 
example in Appendix C: Example 
Pod Security Policy). 
allowPrivilegeEscalation 
Restricts escalation to root 
privileges.  
Set to false. This measure is 
required to effectively enforce 
“runAsUser: MustRunAsNonRoot” 
settings. 
seLinux 
Sets the SELinux context of the 
container.  
If the environment supports 
SELinux, consider adding SELinux 
labeling to further harden the 
container. 
AppArmor annotations  
Sets the AppArmor profile used by 
containers.  
Where possible, harden 
containerized applications by 
employing AppArmor to constrain 
exploitation. 
seccomp annotations  
Sets the seccomp profile used to 
sandbox containers.  
Where possible, use a seccomp 
auditing profile to identify required 
syscalls for running applications; 
then enable a seccomp profile to 
block all other syscalls. 
Note: PSPs do not automatically apply to the entire cluster for the following reasons: 
 First, before PSPs can be applied, the PodSecurityPolicy plugin must be enabled 
for the Kubernetes admission controller, part of kube-apiserver.  
 Second, the policy must be authorized through RBAC. Administrators should 
verify the correct functionality of implemented PSPs from each role within their 
cluster’s organization.  
Administrators should be cautious in environments with multiple PSPs as Pod creation 
adheres to the least restrictive authorized policy. The following command describes all 
Pod Security Policies for the given namespace, which can help to identify problematic 
overlapping policies: 
kubectl get psp -n  
Protecting Pod service account tokens 
By default, Kubernetes automatically provisions a service account when creating a Pod 
and mounts the account’s secret token within the Pod at runtime. Many containerized 
applications do not require direct access to the service account as Kubernetes 
orchestration occurs transparently in the background. If an application is compromised, 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
12 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
account tokens in Pods can be gleaned by cyber actors and used to further compromise 
the cluster. When an application does not need to access the service account directly, 
Kubernetes administrators should ensure that Pod specifications disable the secret 
token being mounted. This can be accomplished using the 
“automountServiceAccountToken: false” directive in the Pod’s YAML 
specification.  
Hardening container engines 
Some platforms and container engines provide additional options to harden the 
containerized environments. A powerful example is the use of hypervisors to provide 
container isolation. Hypervisors rely on hardware to enforce the virtualization boundary 
rather than the operating system. Hypervisor isolation is more secure than traditional 
container isolation. Container engines running on the Windows® operating system can 
be configured to use the built-in Windows hypervisor, Hyper-V®, to enhance security. 
Additionally, some security focused container engines natively deploy each container 
within a lightweight hypervisor for defense-in-depth. Hypervisor-backed containers 
mitigate container breakouts. 
▲Return to Contents 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
13 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Network separation and hardening 
Cluster networking is a central concept of Kubernetes. Communication between 
containers, Pods, services, and external services must be taken into consideration. By 
default, there are few network policies in place to separate resources and prevent 
lateral movement or escalation if a cluster is compromised. Resource separation and 
encryption can be an effective way to limit a cyber actor’s movement and escalation 
within a cluster.  
Namespaces 
Kubernetes namespaces are one way to partition cluster resources among multiple 
individuals, teams, or applications within the same cluster. By default, namespaces are 
not automatically isolated. However, namespaces do assign a label to a scope, which 
can be used to specify authorization rules via RBAC and networking policies. In addition 
to network isolation, policies can limit storage and compute resources to provide better 
control over Pods at the namespace level. 
There are three namespaces by default, and they cannot be deleted:  
 kube-system (for Kubernetes components) 
 kube-public (for public resources) 
 default (for user resources) 
User Pods should not be placed in kube-system or kube-public, as these are reserved 
for cluster services. A YAML file, shown in Appendix D: Example namespace, can be 
used to create new namespaces. Pods and services in different namespaces can still 
communicate with each other unless additional separation is enforced, such as network 
policies.  
Key points 
 Use network policies and firewalls to separate and isolate resources. 
 Secure the control plane. 
 Encrypt traffic and sensitive data (such as Secrets) at rest. 
U/OO/168286-21 | PP-21-1104 | August 2021 Ver. 1.0 
14 
National 
Security 
Agency 
Cybersecurity 
and Infrastructure 
Security Agency 
Kubernetes Hardening Guidance 
National 
Security 
Agency 
Network policies 
Network policies control traffic flow between Pods, namespaces, and external IP 
addresses. By default, no network policies are applied to Pods or namespaces, 
resulting in unrestricted ingress and egress traffic 
within the Pod network. Pods become isolated 
through a network policy that applies to the Pod or 
the Pod’s namespace. Once a Pod is selected in a 
network policy, it rejects any connections that are 
not specifically allowed by any applicable policy 
object. 
To create network policies, a network plugin that 
supports the NetworkPolicy API is required. Pods 