[4] 2019. Alexa and Google Home devices leveraged to phish and eavesdrop on
users, again. https://www.zdnet.com/article/alexa-and-google-home-devices-
leveraged-to-phish-and-eavesdrop-on-users-again/. (2019).
[5] 2019. Alexa Skills Policy Testing. https://developer.amazon.com/fr/docs/custom-
skills/policy-testing-for-an-alexa-skill.html. (2019).
Alexa
Skills
Privacy
Requirements.
https://developer.amazon.com/fr/docs/custom-skills/security-testing-for-
an-alexa-skill.html#25-privacy-requirements. (2019).
[6] 2019.
[7] 2019.
Alexa
Skills
Security
Requirements.
https://developer.amazon.com/fr/docs/alexa-voice-service/security-best-
practices.html. (2019).
[8] 2019. Amazon’s kid-friendly Echo Dot is under scrutiny for alleged child privacy
violations. https://www.theverge.com/2019/5/9/18550425/amazon-echo-dot-kids-
privacy-markey-blumenthal-ftc. (2019).
Smart
Global
2019.
https://www.emarketer.com/content/global-smart-speaker-users-2019. (2019).
Google and YouTube Will Pay Record 170 Million for Alleged
Violations of Children’s Privacy Law. https://www.ftc.gov/news-events/press-
releases/2019/09/google-youtube-will-pay-record-170-million-alleged-
violations. (2019).
Speaker
Users
[9] 2019.
[10] 2019.
[11] 2019. How to Improve Alexa Skill Discovery with Name-Free Interaction and
More. https://developer.amazon.com/blogs/alexa/post/0fecdb38-97c9-48ac-953b-
23814a469cfc/skill-discovery. (2019).
[12] 2019. Over a quarter of US adults now own a smart speaker, typically an Ama-
zon Echo. https://techcrunch.com/2019/03/08/over-a-quarter-of-u-s-adults-now-
own-a-smart-speaker-typically-an-amazon-echo/. (2019).
https://developers.google.com/actions/policies/general-policies. (2019).
[14] 2019. Smart Spies: Alexa and Google Home expose users to vishing and eaves-
dropping. https://srlabs.de/bites/smart-spies/. (2019).
[15] 2019.
The Rise of Virtual Digital Assistants Usage.
https://www.go-
gulf.com/blog/virtual-digital-assistants/. (2019).
[13] 2019.
Policies
for
Actions
on
Google.
[16] Tawfiq Ammari, Jofish Kaye, Janice Y. Tsai, and Frank Bentley. 2019. Music,
Search, and IoT: How People (Really) Use Voice Assistants. ACM Transactions on
Computer-Human Interaction (TOCHI) 26, 3 (2019), 1–28.
[17] Noah Apthorpe, Sarah Varghese, and Nick Feamster. 2019. Evaluating the Con-
textual Integrity of Privacy Regulation: Parents’ IoT Toy Privacy Norms Versus
COPPA. In USENIX Security.
[18] Layla El Asri, Jing He, and Kaheer Suleman. 2016. A Sequence-to-Sequence
Model for User Simulation in Spoken Dialogue Systems. CoRR abs/1607.00070
(2016).
[19] Alexander Benlian, Johannes Klumpe, and Oliver Hinz. 2019. Mitigating the
intrusive effects of smart home assistants by using anthropomorphic design
features: A multimethod investigation. Information Systems Journal (2019), 1–33.
https://doi.org/10.1111/isj.12243
[20] Antoine Bordes and Jason Weston. 2016. Learning End-to-End Goal-Oriented
Dialog. CoRR abs/1605.07683 (2016).
[21] Nicholas Carlini, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang, Micah Sherr,
Clay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden Voice Commands.
In USENIX Security Symposium (USENIX Security). 513–530.
[22] Guangke Chen, Sen Chen, Lingling Fan, Xiaoning Du, Zhe Zhao, Fu Song, and
Yang Liu. 2021. Who is Real Bob? Adversarial Attacks on Speaker Recognition
Systems. In IEEE Symposium on Security and Privacy (SP).
[23] S. Chen, K. Ren, S. Piao, C. Wang, Q. Wang, J. Weng, L. Su, and A. Mohaisen. 2017.
You Can Hear But You Cannot Steal: Defending Against Voice Impersonation
Attacks on Smartphones. In 2017 IEEE 37th International Conference on Distributed
Computing Systems (ICDCS). 183–195.
[24] H. Chung, M. Iorga, J. Voas, and S. Lee. 2017. “Alexa, Can I Trust You?”. IEEE
Computer 50, 9 (2017), 100–104.
[25]
Jide S. Edu, Jose M. Such, and Guillermo Suarez-Tangil. 2019. Smart Home
Personal Assistants: A Security and Privacy Review. CoRR abs/1903.05593 (2019).
[26] Huan Feng, Kassem Fawaz, and Kang G. Shin. 2017. Continuous Authentication
for Voice Assistants. In Annual International Conference on Mobile Computing
and Networking (MobiCom). 343–355.
[27] Christine Geeng and Franziska Roesner. 2019. Who’s In Control?: Interactions In
Multi-User Smart Homes. In Conference on Human Factors in Computing Systems
(CHI).
[28] Hang Hu, Limin Yang, Shihan Lin, and Gang Wang. 2020. A Case Study of the
Security Vetting Process of Smart-home Assistant Applications. In Proceedings
of IEEE Workshop on the Internet of Safe Things (SafeThings).
[29] Anjishnu Kumar, Arpit Gupta, Julian Chan, Sam Tucker, Björn Hoffmeister, and
Markus Dreyer. 2017. Just ASK: Building an Architecture for Extensible Self-
Service Spoken Language Understanding. In Workshop on Conversational AI at
NIPS’17.
[30] Deepak Kumar, Riccardo Paccagnella, Paul Murley, Eric Hennenfent, Joshua
Mason, Adam Bates, and Michael Bailey. 2018. Skill Squatting Attacks on Amazon
Alexa. In 27th USENIX Security Symposium (USENIX Security). 33–47.
Josephine Lau, Benjamin Zimmerman, and Florian Schaub. 2018. Alexa, Are You
Listening?: Privacy Perceptions, Concerns and Privacy-seeking Behaviors with
Smart Speakers. Proc. ACM Hum.-Comput. Interact. 2, CSCW (2018), 1–31.
[32] X. Lei, G. Tu, A. X. Liu, C. Li, and T. Xie. 2018. The Insecurity of Home Digital
Voice Assistants - Vulnerabilities, Attacks and Countermeasures. In 2018 IEEE
Conference on Communications and Network Security (CNS). 1–9.
[33] Bing Liu and Ian Lane. 2017. Iterative Policy Learning in End-to-End Trainable
Task-Oriented Neural Dialog Models. CoRR abs/1709.06136 (2017).
[34] Nathan Malkin, Joe Deatrick, Allen Tong, Primal Wijesekera, Serge Egelman, and
David Wagner. 2019. Privacy Attitudes of Smart Speaker Users. In 19th Privacy
Enhancing Technologies Symposium (PETS).
[35] Graeme McLean and Kofi Osei-Frimpong. 2019. Hey Alexa: examine the variables
influencing the use of artificial intelligent in-home voice assistants. Computers
in Human Behavior 99 (2019), 28 – 37.
[36] Richard Mitev, Markus Miettinen, and Ahmad-Reza Sadeghi. 2019. Alexa Lied to
Me: Skill-based Man-in-the-Middle Attacks on Virtual Assistants. In ACM Asia
Conference on Computer and Communications Security (AsiaCCS). 465–478.
[37] Nirupam Roy, Sheng Shen, Haitham Hassanieh, and Romit Roy Choudhury.
2018. Inaudible Voice Commands: The Long-Range Attack and Defense. In 15th
USENIX Symposium on Networked Systems Design and Implementation (NSDI 18).
547–560.
[38] Lea Schönherr, Katharina Kohls, Steffen Zeiler, Thorsten Holz, and Dorothea
Kolossa. 2019. Adversarial Attacks Against Automatic Speech Recognition
Systems via Psychoacoustic Hiding. In Network and Distributed System Security
Symposium.
[31]
[39] Faysal Shezan, Hang Hu, Jiamin Wang, Gang Wang, and Yuan Tian. 2020. Read
Between the Lines: An Empirical Measurement of Sensitive Applications of Voice
Personal Assistant Systems. In Proceedings of The Web Conference (WWW).
[40] Maurice E. Stucke and Ariel Ezrachi. 2017. How Digital Assistants Can Harm
our Economy, Privacy, and Democracy. Berkeley Technology Law Journal 32, 3
(2017), 1240–1299.
[41] Tavish Vaidya, Yuankai Zhang, Micah Sherr, and Clay Shields. 2015. Cocaine
Noodles: Exploiting the Gap between Human and Machine Speech Recognition.
In 9th USENIX Workshop on Offensive Technologies (WOOT 15).
[42] Qiben Yan, Kehai Liu, Qin Zhou, Hanqing Guo, and Ning Zhang. 2020. Surfin-
gAttack: Interactive Hidden Attack on Voice Assistants Using Ultrasonic Guided
Wave. In Network and Distributed Systems Security (NDSS) Symposium.
[43] Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai Chen,
Shengzhi Zhang, Heqing Huang, XiaoFeng Wang, and Carl A. Gunter. 2018. Com-
mandersong: A Systematic Approach for Practical Adversarial Voice Recognition.
In USENIX Conference on Security Symposium (USENIX Security). 49–64.
[44] Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and
Wenyuan Xu. 2017. DolphinAttack: Inaudible Voice Commands. In ACM SIGSAC
Conference on Computer and Communications Security (CCS). 103–117.
[45] Nan Zhang, Xianghang Mi, Xuan Feng, XiaoFeng Wang, Yuan Tian, and Feng
Qian. 2019. Understanding and Mitigating the Security Risks of Voice-Controlled
Third-Party Skills on Amazon Alexa and Google Home. In IEEE Symposium on
Security and Privacy (SP).
[46] Yangyong Zhang, Lei Xu, Abner Mendoza, Guangliang Yang, Phakpoom Chin-
prutthiwong, and Guofei Gu. 2019. Life after Speech Recognition: Fuzzing
Semantic Misinterpretation for Voice Assistant Applications. In Network and
Distributed System Security Symposium (NDSS).
10
APPENDIX A CONTENT POLICIES OF VA PLATFORMS
No.
Content Policies
Trademarks, Intellectual Property and Brands
Child-directed skills
Skill Submissions
Kids
General
Action Submissions
Kids
General
(Total/Certi-
fied/Failed)
(Total/Certi-
fied/Failed)
(Total/Certi-
fied/Failed)
(Total/Certi-
fied/Failed)
2/2/0
3/3/0
8/1/7
Platform
A/G
7/4/3
6/0/6
6/0/6
25/5/20
24/0/24
15/6/9
2/2/0
3/3/0
3/3/0
1/1/0
2/2/0
2/2/0
2/2/0
2/2/0
2/2/0
4/4/0
6/6/0
3/3/0
4/4/0
2/2/0
2/2/0
3/3/0
2/2/0
5/5/0
3/3/0
2/2/0
10/0/10
7/4/3
11/10/1
6/0/6
2/1/1
3/3/0
4/3/1
5/4/1
3/1/2
5/4/1
9/7/2
5/5/0
5/3/2
3/2/1
3/3/0
3/2/1
3/2/1
5/2/3
3/2/1
3/3/0
3/2/1
1
2
2.a
2.b
2.c
2.d
2.e
2.f
3
3.a
3.b
3.c
3.d
3.e
4
4.a
4.b
4.c
4.d
5
6
7
7.a
7.b
7.c
7.d
8
8.a
8.b
8.c
8.d
8.e
8.f
It promotes any products, content, or services, or directs end users to
engage with content outside of Alexa.
It sells any physical products or services.
It sells any digital products or services without using Amazon In-Skill
Purchasing.
It collects any personal information from end users.
It includes content not suitable for all ages.
Actions must not contain ads, including in streaming media.
Collects information relating to any person’s physical or mental health
or condition, the provision of health care to a person, or payment for
the same.
Claims to provide life-saving assistance through the skill or in the skill
name, invocation name or skill description.
Contains false or misleading claims in the responses, description,
invocation name, or home card regarding medicine, prescription drugs
or other forms of treatment. This includes claims that a treatment can
cure all diseases or specific incurable diseases. A claim can be
misleading if relevant information is left out or if it suggests something
that’s not true.
Provides information about black market sale of prescription drugs.
Is a skill that provides health-related information, news, facts or tips
and does not include a disclaimer in the skill description stating that
the skill is not a substitute for professional medical advice.
Recommends other skills which are not owned by the same developer.
Recommends skills in Alexa’s voice.
Offering compensation for using Actions/skills
Solicits donations from end users.
Advertising: Includes or otherwise surfaces advertising or promotional
messaging in skill responses, notifications, or reminders.
Sexually Explicit content: Pornography and sex
Contains graphic depictions or descriptions of extreme gore,
decapitations, unsettling content, and/or excessive violence.
Promotes organized crime, terrorism, or other illegal activities meant
to undermine local and/or national governments or police.
Self-harm, including instructions to carry out self-harm.
Bullying and harassment
Includes references to or information regarding forced marriages or
purchasable husbands and/or wives.
Purports to be able to predict gender.
Contains derogatory comments or hate speech specifically targeting
any group or individuals.
Contains content that references or promotes out-of-context
quotations that mislead about the intentions of the figure being quoted.
Contains or references Nazi symbols or other symbols of hate,
promotes hate speech, incites racial or gender hatred, or promotes
groups or organizations which support such beliefs such as the Ku
Actions that make inflammatory or excessively negative statements
about: Intelligence. Appearance or hygiene. Socio-economic status.
Ethics or morality. Disability or medical condition. Criminal history.
Klux Klan.
Sexual activity.
A
A
A
A/G
A/G
G
Health
A/G
A
4/4/0
4/4/0
3/3/0
7/7/0
5/5/0
3/3/0
2/2/0
2/2/0