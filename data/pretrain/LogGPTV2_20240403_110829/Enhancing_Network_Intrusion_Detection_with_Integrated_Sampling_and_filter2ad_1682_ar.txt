each of α spurious features, is F[s] = 1− pαps.
Derivation. The expected number of spurious features that will be included in a signa-
ture after collecting s samples is σ= αps. The chance of all σof those spurious features
being present in any given target-class samples is pσ. Hence, the expected false negative
rate of the signature is y = 1− pσ, which we rewrite as y = 1− pαps.
The attacker has two parameters to choose: the number of spurious features α, and
the probability of a spurious feature occurring in a target-class sample p. The attacker
2 In Section 5, we show that the hierarchical clustering algorithm used by Polygraph to tolerate
noise does not protect against these attacks.
88
J. Newsome, B. Karp, and D. Song
will use as high an α as is practical, often limited only by the number of additional
bytes that the attacker is willing to append.
The ideal value of p is not clear by inspection. A higher p results in more spu-
rious features incorporated into the signature, but it also means that the spurious
features that do get included in the classiﬁer are more likely to occur in other target-
class samples. We ﬁnd the best value of p by ﬁnding the roots of the derivative:
dy
d p = −αpαps+s−1(sln(p) + 1). There are two roots. p = 0 minimizes false negatives
(it is equivalent to not performing the attack at all), and p = e
negatives.
− 1
s maximizes false
Theorem 2. The value of p that maximizes the false negative rate in the Randomized
Red Herring attack is: p = e
− 1
s .
The p that generates the highest false negative rate depends on the number of target-
class samples seen by the learner, s. Hence, the optimal value of p depends on the exact
goals of the attacker. For a worm author, one way to choose a value of p would be to set
a goal for the number of machines to compromise before there is an effective classiﬁer,
and calculate the number of positive samples that the learner is likely to have gathered
by that time, based on the propagation model of his worm and the deployment of the
learner, and then set p to a value that ensures there are still a large number of false
negatives at that time.
y
e
t
a
r
e
v
i
t
a
g
e
n
l
e
s
a
F
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Theory p=.900
Theory p=.995
Theory p=.999
Eval p=.900
Eval p=.995
 200
 400
 600
 800
 1000
Number of training samples s
Fig. 2. Randomized Red Herring attack. α= 400
We implemented a version of the Randomized Red Herring attack based on this
model. We took a real buffer-overﬂow exploit against the ATPhttpd web server [19],
ﬁlled the attack-code with random bytes to simulate polymorphic encryption and ob-
fuscation, and replaced the 800 bytes of padding with 400 unique two-byte spurious
features. Speciﬁcally, we set each two-byte token to the binary representation of its
offset with probability p, and to a random value with probability 1 − p. Note that
Paragraph: Thwarting Signature Learning by Training Maliciously
89
the number of spurious features used here is conservative. In this attack, the 800 padding
bytes were already used, because they were necessary to overﬂow the buffer. The at-
tacker could easily include more bytes to use as spurious features. For example, he
could include additional HTTP headers for the sole purpose of ﬁlling them with spuri-
ous features.
Figure 2 shows the predicted and actual false negative rates as the number of train-
ing samples increases, for several values of p. We used values that maximized the false
negative rate when s = 10 (p = .900), when s = 200 (p = .995), and when s = 500
(p = .999). For each data point, we generate s worm samples, and use the Polygraph
conjunction learner to generate a classiﬁer. We then generate another 1000 worm sam-
ples to measure the false negative rate. There are two things to see in this graph. First,
our experimental results conﬁrm our probability calculations. Second, the attack is quite
devastating. Low values of p result in very high initial false negatives, while high val-
ues of p prevent a low-false-negative signature from being generated until many worm
samples have been collected.
3.2 Attack II: Dropped Red Herring Attack
Attack description. In the Dropped Red Herring attack, the attacker again chooses a
set of αspurious features. Initially, he includes all αfeatures in every target-class sam-
ple. As a result, the target-class samples in the learner’s malicious training pool will
all have all α spurious features, and all α spurious features will be included in the
signature.
Once the signature is in place, all the attacker needs to do to evade the signature is
to stop including one of the spurious features in subsequent target-class samples. The
signature will have a 100% false negative rate until the learner sees a target-class sample
missing the spurious feature, and deploys an updated signature that no longer requires
that feature to be present. At that point, the attacker stops including another spurious
feature. The cycle continues until the attacker has stopped including all of the spurious
features.
Attack analysis. For sake of comparison to the Randomized Red Herring attack, as-
sume that the attacker stops including a single spurious feature the instant that an up-
dated signature is deployed. Also assume that the learner deploys a new signature each
time it collects a new worm sample, since each successive sample will have one fewer
spurious feature than the last. In that case, the classiﬁer will have 100% false negatives
until α positive samples have been collected.
Theorem 3. The false negative rate F[s] for the signature generated after s target-class
samples have been collected is
(cid:29)
F[s] =
100% i f s < α
0% i f s ≥ α
With these assumptions, the Dropped Red Herring attack is compared to the Random-
ized Red Herring attack in Figure 3. When the attack is executed in this way, and there
90
J. Newsome, B. Karp, and D. Song
y
e
t
a
r
e
v
i
t
a
g
e
n
l
e
s
a
F
d
e
t
c
e
p
x
E
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Randomized p=.900
Randomized p=.995
Randomized p=.999
Dropped
 200
 400
 600
 800
 1000
Number of training samples
Fig. 3. Dropped Red Herring compared to Randomized Red Herring, α= 400
are a moderate number of spurious features, the attack can be quite devastating. The
generated signatures are useless until all α features have been eliminated from the sig-
nature.
While the Dropped Red Herring attack is far more effective than the Randomized
Red Herring attack (until the learner has dropped all α spurious features from the sig-
nature), the Randomized Red Herring attack has one important advantage: it is simpler
to implement. The Dropped Red Herring attack must interact with the signature learning
system, in that it must discover when a signature that matches the current target-class
samples has been published, so that it can drop another feature, and remain unﬁltered.
There is no such requirement of the Randomized Red Herring attack. This is not to say
that the Dropped Red Herring attack is impractical; the attacker has signiﬁcant room
for error. While dropping a feature prematurely will ‘waste’ a spurious feature, there is
little or no penalty for dropping a feature some time after an updated signature has been
deployed.
3.3 Attack Effectiveness
We show that even with an optimistic model of a distributed signature generation sys-
tem, and a pessimistic model of a worm, employing the Randomized Red Herring or
Dropped Red Herring attack delays the learner enough to infect a large fraction of vul-
nerable hosts before an accurate signature can be generated.
We assume that the learner is monitoring L addresses. Each time the worm scans
one of these addresses, the learner correctly identiﬁes it as a worm, and instantaneously
updates and distributes the signature. At that point, any scan of any vulnerable host
has probability F[s] of succeeding (the false negative rate of the current signature).
There are several optimistic assumptions for the learner here, most notably that up-
dated signatures are distributed instantaneously. In reality, distributing even a single
Paragraph: Thwarting Signature Learning by Training Maliciously
91
 1e+06
 900000
 800000
 700000
 600000
 500000
 400000
 300000
 200000
 100000
 0
No defense
Dropped RH
Randomized RH (p=.999)
Randomized RH (p=.995)
Randomized RH (p=.900)
Maximally Varying Polymorphic
 0
 1000  2000  3000  4000  5000  6000  7000  8000
Worm samples seen by learner (s)
d
e
t
c
e
f
n
I
s
t
s
o
H
e
b
a
r
e
n
u
V
l
l
Fig. 4. Worm propagation. L=1000, V=1000000, α= 400
signature to all hosts in less than the time it takes to infect all vulnerable hosts is a
challenge [22].3
We assume that the worm scans addresses uniformly at random. In reality, there are
several potential strategies a worm author might use to minimize the number of sam-
ples seen by the learner. An ideally coordinated worm may scan every address exactly
once, thus minimizing the number of samples sent to any one of the learner’s addresses,
and eliminating ‘wasted’ scans to already-infected hosts. The worm could further im-
prove this approach by attempting to order the addresses by their likelihood of being
monitored by the learner, scanning the least likely ﬁrst.
We model the worm by estimating the number of additional vulnerable hosts infected
in-between the learner receiving new worm samples. Note that because we assume sig-
nature updates are instantaneous, the scan rate of the worm is irrelevant. Intuitively, both
the rate of infection and the rate of the learner receiving new samples are proportional
to the scan rate, thus canceling each other out.
Theorem 4. For a worm scanning uniformly at random, where there are V vulnerable
hosts, L addresses monitored by the learner, and N total hosts, the expected number of
infected hosts I after s worm samples have been seen by the learner is:
I[s] = I[s− 1] + (V − I[s− 1])
(cid:16)
1−
(cid:14)
1− F[s− 1]
(cid:17)
(cid:15)(N/L)
N
Derivation. The expected number of worm scans in-between the learner receiving a
new worm sample is
P(scan is seen by learner) = N
L .
1
3 The Dropped Red Herring attack in particular is much more devastating when taking the sig-
nature generation and distribution time into account, since the next spurious feature is not
revealed before an updated signature is distributed. Hence, a worm using α spurious features
is allowed to propagate freely for at least α times the time needed to generate and distribute a
signature.
92
J. Newsome, B. Karp, and D. Song
Innocuous Pool
False Positive Rate
100%
Suspicious Pool
False Negative Rate
Innocuous Pool
False Positive Rate
100%
Suspicious Pool
False Negative Rate
e
t
a
R
F%
e
t
a
R
F%
Threshold