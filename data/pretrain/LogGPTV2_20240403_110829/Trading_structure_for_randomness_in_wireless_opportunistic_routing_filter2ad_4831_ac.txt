batch already stored at the node. Checking independence of all data
bytes is very expensive. Fortunately, this is unnecessary. The for-
warder node simply checks if the code vectors are linearly indepen-
dent. (Checking for vector independence can be done using Gaus-
sian elimination [13]. To amortize the cost over all packets each
node keeps code vectors of the packets in its buffer in row echelon
form.) The data in the packet itself is not touched; it is just stored
in a pool to be used later when the node needs to forward a lin-
ear combination from the batch. Thus, operations on individual data
bytes happen only occasionally at the time of coding or decoding,
while checking for innovativeness, which occurs for every overheard
packet, is fairly cheap.
(c) Pre-Code Packets: When the wireless driver is ready to send a
packet, the node has to generate a linear combination of the buffered
packets and hand that coded packet to the wireless card. Linearly
combining packets involves multiplying individual bytes in those
packets, which could take hundreds of microseconds. This inserts
signiﬁcant delay before every transmission, decreasing the overall
throughput.
To address this issue, MORE exploits the time when the wire-
less medium is unavailable to pre-compute one linear combination,
so that a coded packet is ready when the medium becomes avail-
able. If the node receives an innovative packet before the prepared
packet is handed over to the driver, the pre-coded packet is updated
by multiplying the newly arrived packet with a random coefﬁcient
and adding it to the pre-coded packet. This approach achieves two
important goals. On the one hand, it ensures the transmitted coded
packet contains information from all packets known to the node, in-
cluding the most recent arrival. On the other hand, it avoids inserting
a delay before each transmission.
6.
IMPLEMENTATION DETAILS
Finally, we put the various pieces together and explain the system
details.
6.1 Packet Format
MORE inserts a variable length header in each packet, as shown
in Fig. 3. The header starts with a few required ﬁelds that appear
in every MORE packet. The type ﬁeld distinguishes data packets,
which carry coded information, from ACKs, which signal batch de-
livery. The header also contains the source and destination IP ad-
dresses and the ﬂow ID. The last required ﬁeld is the batch ID, which
(a) Sender side
(b) Receiver side
Figure 4: MORE’s Architecture. The ﬁgure shows a ﬂow chart of our
MORE implementation.
identiﬁes the batch to which the packet belongs. The above is fol-
lowed by a few optional ﬁelds. The code vector exists only in data
packets and identiﬁes the coefﬁcients that generate the coded packet
from the native packets in the batch. The list of forwarders has vari-
able length and identiﬁes all potential forwarders ordered accord-
ing to their proximity to the source. For each forwarder, the packet
also contains its TX credit (see §5.1). Except for the code vector, all
ﬁelds are initialized by the source and copied to the packets created
by the forwarders. In contrast, the code vector is computed locally
by each forwarder based on the random coefﬁcients they picked for
the packet.
6.2 Node State
Each MORE node maintains state for the ﬂows it forwards. The
per-ﬂow state is initialized by the reception of the ﬁrst packet from
a ﬂow that contains the node ID in the list of forwarders. The state is
timed-out if no packets from the ﬂow arrive for a few minutes (the
default is 5 minutes). The source keeps transmitting packets until
the destination acks the last batch of the ﬂow. These packets will re-
initialize the state at the forwarder even if it is timed out prematurely.
The per-ﬂow state includes the following.
• The batch buffer stores the received innovative packets.
Note that the number of innovative packets in a batch is bounded
by the batch size K.
• The current batch variable identiﬁes the most recent batch
from the ﬂow.
• The forwarder list contains the list of forwarders and their
corresponding TX credits, ordered according to their distance
from the destination. The list is copied from one of the received
packets, where it was initialized by the source.
• The credit counter tracks the transmission credit. For each
packet arrival from a node with a higher ETX, the forwarder
increments the counter by its corresponding TX CREDIT, and
decrements it 1 for each transmission. A forwarder transmits only
when the counter is positive.
6.3 Control Flow
Figure 4 shows the architecture of MORE. The control ﬂow re-
sponds to packet reception and transmission opportunity signaled
by the 802.11 driver.
On the sending side, the forwarder prepares a pre-coded packet
for every backlogged ﬂow to avoid delay when the MAC is ready
for transmission. A ﬂow is backlogged if it has a positive credit
counter. Whenever the MAC signals an opportunity to transmit,
the node selects a backlogged ﬂow by round-robin and pushes its
pre-coded packet to the network interface. As soon as the transmis-
sion starts, a new packet is pre-coded for this ﬂow and stored for fu-
ture use. If the node is a forwarder, it decrements the ﬂow’s credit
counter.
On the receiving side, whenever a packet arrives the node checks
whether it is a forwarder by looking for its ID in the forwarder list in
the header. If the node is a forwarder, it checks if the batch ID on the
packet is the same as its current batch. If the batch ID in the
packet is higher than the node’s current batch, the node sets
current batch to the more recent batch ID and ﬂushes pack-
ets from older batches from its batch buffer. If the packet was
transmitted from upstream, the node also increments its credit
counter by its TX credit. Next, the node performs a linear in-
dependence check to determine whether the packet is innovative.
Innovative packets are added to the batch buffer while non-
innovative packets are discarded.
Further processing depends on whether the node is the packet’s ﬁ-
nal destination or just a forwarder. If the node is a forwarder, the pre-
coded packet from this ﬂow is updated by adding the recent packet
multiplied by a random coefﬁcient. In contrast, if the node is the
destination of the ﬂow, it checks whether it has received a full batch
(i.e., K innovative packets). If so, it queues an ACK for the batch,
decodes the native packets and pushes them to the upper layer.
6.4 ACK Processing
ACK packets are routed to the source along the shortest ETX path.
ACKs are also prioritized over data packets and transferred reliably.
In our implementation, when a transmission opportunity arises, a
queued ACK is given priority, and the ACK packet is passed to the
device. Unless the transmission succeeds (i.e., is acknowledged by
the MAC of the nexthop) the ACK is queued again. In addition, all
nodes that overhear a batch ACK update their current batch
variable and ﬂush packets from the acked batch from their batch
buffer.
7. MULTICAST
Multicast in MORE is a natural extension of unicast. All of our
prior description carries on to the multicast case except for three
simple modiﬁcations.
First, the source does not proceed to the next batch until all desti-
nations have received the current batch.
Second, the list of forwarders and their TX credits are different.
The source computes the TX credits and the forwarder list for hy-
pothetical unicast ﬂows from itself to each of the destinations in the
multicast group. The forwarder list of the multicast ﬂow is the union
of the forwarders of the unicast ﬂows. The TX credit of each for-
warder is computed using Eq. (3) where each zi is the maximum of
what forwarder i gets in each of the hypothetical unicast ﬂows.
Third, for multicast the TX credit of a forwarder takes a dynamic
nature. In particular, as the current batch progresses towards the
end, more and more destinations are able to decode. Those for-
warders that were included in the forwarder list in order to reach
destinations that have already decoded the batch are temporarily not
needed. Thus, whenever a destination acks the current batch, the
source recomputes the TX credits of the forwarders as the maxi-
mum TX credit taken over only the hypothetical unicast ﬂows to
the destinations that have not yet decoded the batch. The forwarders
that hear the new TX credit in the packet update their information
accordingly.
8. EXPERIMENTAL RESULTS
We use measurements from a 20-node wireless testbed to evaluate
MORE, compare it with both ExOR and traditional best path rout-
ing, and estimate its overhead. Our experiments reveal the following
ﬁndings.
• In the median case, MORE achieves 22% better throughput than
ExOR. In comparison with traditional routing, MORE improves
the median throughput by 95%, and the maximum throughput
gain exceeds 10x.
• MORE’s throughput exceeds ExOR’s mainly because of its abil-
ity to exploit spatial reuse. Focusing on ﬂows that
traverse
paths with 25% chance of concurrent transmissions, we ﬁnd that
MORE’s throughput is 45% higher than that of ExOR.
• For multicast trafﬁc, MORE’s throughput gain increases with the
number of destinations. For 2-4 destinations, MORE’s through-
put is 35-200% larger than ExOR’s. In comparison to traditional
routing, the multicast gain can be as high as 3x.
• MORE signiﬁcantly eases the problem of dead spots. In particu-
lar, 90% of the ﬂows achieve a throughput higher than 51 pack-
ets/second. The corresponding number in traditional routing is
only 12 packets/second.
• MORE keeps its throughput gain over traditional routing even
• MORE is insensitive to the batch size and maintains large
• Finally, we estimate MORE’s overhead. Our MORE implemen-
tation supports up to 44 Mb/s on low-end machines with Celeron
800MHz CPU and 128KiB of cache. Thus, MORE’s overhead is
reasonable for the environment it is designed for, namely station-
ary wireless meshes, such as Roofnet [1] and community wireless
networks [34, 3].
throughput gains with batch size as low as 8 packets.
when the latter is allowed automatic rate selection.
8.1 Testbed
(a) Characteristics: We have a 20-node wireless testbed that spans
three ﬂoors in our building connected via open lounges. The nodes
of the testbed are distributed in several ofﬁces, passages, and
lounges. Fig. 5 shows the locations of the nodes on one of the ﬂoors.
Paths between nodes are 1–5 hops in length, and the loss rates of
links on these paths vary between 0 and 60%, and averages to 27%.
(b) Hardware: Each node in the testbed is a PC equipped with a
NETGEAR WAG311 wireless card attached to an omni-directional
antenna. They transmit at a power level of 18 dBm, and operate in
the 802.11 ad hoc mode, with RTS/CTS disabled.
(c) Software: Nodes in the testbed run Linux, the Click toolkit [25]
and the Roofnet software package [1]. Our implementation runs as
s
w
o
F
l
f
o
n
o
i
t
c
a
r
F
e
v
i
t
l
a
u
m
u
C
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0
 50
 100
 150
 200
Throughput [pkt/s]
Srcr
ExOR
MORE
Figure 5: One Floor of our Testbed. Nodes’ location on one ﬂoor of our
3-ﬂoor testbed.
a user space daemon on Linux. It sends and receives raw 802.11
frames from the wireless device using a libpcap-like interface.
8.2 Compared Protocols
We compare the following three protocols.
• MORE as explained in §6.
• ExOR [7], the current opportunistic routing protocol. Our ExOR
• Srcr [6] which is a state-of-the-art best path routing protocol for
wireless mesh networks. It uses Dijkstra’s shortest path algorithm
where link weights are assigned based on the ETX metric [11].
code is provided by its authors.
8.3 Setup
In each experiment, we run Srcr, MORE, and ExOR in sequence
between the same source destination pairs. Each run transfers a 5
MByte ﬁle. We leverage the ETX implementation provided with the
Roofnet software to measure link delivery probabilities. Before run-
ning an experiment, we run the ETX measurement module for 10
minutes to compute pair-wise delivery probabilities and the corre-
sponding ETX metric. These measurements are then fed to all three
protocols, Srcr, MORE, and ExOR, and used for route selection.
Unless stated differently, the batch size for both MORE and
ExOR is set to K = 32 packets. The packet size for all three pro-
tocols is 1500B. The queue size at Srcr routers is 50 packets. In
contrast, MORE and ExOR do not use queues; they buffer active
batches.
Most experiments are performed over 802.11b with a bit-rate of
5.5Mb/s. In §8.7, we allow traditional routing (i.e., Srcr) to exploit
the autorate feature in the MadWiﬁ driver, which uses the Onoe
bit-rate selection algorithm [5]. Current autorate control optimizes
the bit-rate for the nexthop, making it unsuitable for opportunistic
routing, which broadcasts every transmission to many potential nex-
thops. The problem of autorate control for opportunistic routing is
still open. Thus in our experiments, we compare Srcr with autorate
to opportunistic routing (MORE and ExOR) with a ﬁxed bit-rate of
11 Mb/s.
8.4 Throughput
We would like to examine whether MORE can effectively exploit
opportunistic receptions to improve the throughput and compare it
with Srcr and ExOR.
(a) How Do the Three Protocols Compare? Does MORE improve
over ExOR? How do these two opportunistic routing protocols com-
pare with traditional best path routing? To answer these questions,
we use these protocols to transfer a 5 MByte ﬁle between various
Figure 6: Unicast Throughput. Figure shows the CDF of the uni-
cast throughput achieved with MORE, ExOR, and Srcr. MORE’s me-
dian throughput is 22% higher than ExOR. In comparison to Srcr, MORE
achieves a median throughput gain of 95%, while some source-destination
pairs show as much as 10-12x.
nodes in our testbed. We repeat the same experiment for MORE,
ExOR, and Srcr as explained in §8.3.
Our results show that MORE signiﬁcantly improves the unicast
throughput. In particular, Fig. 6 plots the CDF of the through-
put taken over 200 randomly selected source-destination pairs in
our testbed. The ﬁgure shows that both MORE and ExOR signif-
icantly outperform Srcr. Interestingly, however, MORE’s through-
put is higher than ExOR’s. In the median case, MORE has a 22%
throughput gain over ExOR. Its throughput gain over Srcr is 95%,
but some challenged ﬂows achieve 10-12x higher throughput with
MORE than traditional routing.
Further, MORE and opportunistic routing ease the problem of
dead spots. Fig. 6 shows that over 90% of MORE ﬂows have a
throughput larger than 51 packets a second. ExOR’s 10th percentile
is at 35 packets a second. Srcr on the other hand suffers from dead
spots with many ﬂows experiencing very low throughput. Speciﬁ-
cally, the 10th percentile of Srcr’s throughput is at 12 packets a sec-
ond.
(b) When Does Opportunistic Routing Win? We try to identify
the scenarios in which protocols like MORE and ExOR are partic-
ularly useful, i.e., when should one expect opportunistic routing to
bring a large throughput gain? Fig. 7a shows the scatter plot for the
throughputs achieved under Srcr and MORE for the same source-
destination pair. Fig. 7b gives an analogous plot for ExOR. Points
on the 45-degree line have the same throughput in the two compared
schemes.
These ﬁgures reveal
that opportunistic routing (MORE and
ExOR) greatly improves performance for challenged ﬂows, i.e.,
ﬂows that usually have low throughput. Flows that achieve good
throughput under Srcr do not improve further. This is because when
links on the best path have very good quality, there is little ben-
eﬁt from exploiting opportunistic receptions. In contrast, a source-
destination pair that obtains low throughput under Srcr does not have
any good quality path. Usually, however, many low-quality paths ex-
ist between the source and the destination. By using the combined
capacity of all these low-quality paths, MORE and ExOR manage
to boost the throughput of such ﬂows.
(c) Why Does MORE Have Higher Throughput than ExOR?
Our experiments show that spatial reuse is a main contributor to
MORE’s gain over ExOR. ExOR prevents multiple forwarders from
accessing the medium simultaneously [7], and thus does not exploit
spatial reuse. To examine this issue closely, we focus on a few ﬂows
that we know can beneﬁt from spatial reuse. Each ﬂow has a best
path of 4 hops, where the last hop can send concurrently with the
ﬁrst hop without collision. Fig. 8 plots the CDF of throughput of
]
s
/
t
k
p
[
t
u
p
h
g
u
o
r
h
T
E
R
O
M