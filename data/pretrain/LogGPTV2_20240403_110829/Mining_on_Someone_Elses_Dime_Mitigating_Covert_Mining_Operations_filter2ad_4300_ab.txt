a sampling rate of 2 s (empirically chosen for ease and accuracy). This gave us
noise-free process-level HPC-based signatures for numerous coins. For GPUs we
used nvprof [3]. The signature that we obtain during this phase is cleaned so that
the bootstrapping code of the miner is not considered and only the signature
Mitigating Covert Mining Operations in Clouds and Enterprises
293
for the core PoW algorithm is captured. We call this signature the OS-level
signature. In the second phase, we run miners inside VMs to cater to noise that
is induced by executing in a virtualized environment. No additional processes
are run on the VMs other than the default OS ones and our cryptominers, giving
us pure VM-level signatures. This phase corresponds to a scenario in which an
attacker uses dedicated VM instances for mining coins. Finally, in the last phase,
we perform mining inside VMs that are already running other jobs and processes.
This allows us to capture signatures in the presence of maximum noise. We repeat
our experiments for various popular and common cloud workloads running in
parallel with a cryptocurrency miner. Signatures generated during this phase
are called VM-Interference signatures. The aforementioned scheme, explicitly
captures the eﬀects of virtualization-induced noise and workload-induced noise
both of which are a must for eﬃcient detection of mining activity.
Signature Database: MineGuard’s signature database, which we use to train
the classiﬁer, is very small in size for numerous reasons. First, unlike generic
malware, miners have to stick to a core PoW algorithm. Whether the miner is
polymorphic, metamorphic or heavily obfuscated, the core algorithm, which we
proﬁle in our system, remains the same. Since there are a ﬁnite number of coins,
and consequently a limited number of proof-of-work algorithms, added to the
fact that there is no such thing as a zero-day coin, our resulting signatures are
few in number (<100). This makes our signature database small. And, since each
signature in the database is distinct and prominent compared to other common
cloud workloads, as shown in Sect. 6, the classiﬁer is able to build its inner models
successfully.
5 Methodology
Before we jump into the results, we explain our prototype implementation and
test environment, and present details of the cryptocurrencies, miners and bench-
marks we used for testing and evaluation.
MineGuard Implementation: We implemented MineGuard in userspace
using a combination of C++, Python and Bash. We used C++ for the signa-
ture creation and detection modules, and Bash and Python scripts for proﬁling
VMs and collecting and organizing data. We used an open source random forest
library [25] for the bagged decision tree implementation, and perf/perf-KVM [19]
and nvprof
[3] for CPU and GPU proﬁling, respectively. Upon deployment, a
driver script samples any given process (application/miner/VM) for 2 s (equiv-
alent to one test vector), formats the test vector and passes it to the predict
module to classify the process. Excluding the random forest library, the entire
MineGuard infrastructure only requires 282 lines of code. We have also made
the source code and training/test data publicly available at the following URL:
https://bitbucket.org/mhuzai/mineguard/overview.
Testbed: All experiments were performed on a machine with an Intel Core-i7
2600 K processor (Sandy Bridge), an NVIDIA GTX 960 GPU (Maxwell) and
294
R. Tahir et al.
Table 1. Cryptocoins we used along with their PoW algorithms and CPU/GPU miners.
Cryptocurrency Proof-of-work
CPU miner
GPU miner
Bitcoin
algorithm
SHA256
Bytecoin
CryptoNight
Dash
X11
Litecoin
Scrypt
Quarkcoin
BLAKE, Blue
Midnight Wish,
Gr∅stl, JH, SHA-3
and Skein
Vertcoin
Lyra2RE
Ethereum
Ethash (Modiﬁed
Dagger-Hashimoto)
cpuminer-multi-
windows,
bfgminer-5.1.0,
cgminer-2.11.4
cpuminer-multi-
windows
cpuminer-multi-
windows
cpuminer-multi-
windows
cpuminer-multi-
windows
–
ccMiner-cryptonight-0.17
ccMiner-1.6.6-tpruvot
cudaminer-2014-02-28
ccMiner-1.6.6-tpruvot
cpuminer-multi-
windows
ccMiner-1.6.6-tpruvot
ethminer-1.3.0
ethminer-1.3.0
Zcash
Equihash
nheqminer-0.5c
nheqminer-0.5c
8 GB of DDR3 RAM. We ran Linux 3.16.0-44 for both desktop (native) and
server (virtualized) environments. For collecting CPU-based training data, each
application was proﬁled for 20 s, with one sample being collected every 2 s, for
a total of 10 samples per application and miner. This provided ample data for
high accuracy classiﬁcation with negligible overhead (discussed in Sect. 6). For
GPU-based training data, samples were only collected once at the end of a 120 s
execution window - unlike perf, nvprof does not allow live periodic sampling of
running applications.
Cryptocurrencies and Miners: Other than Bitcoin, the seven additional
cryptocurrencies listed in Table 1 are still actively mined using CPUs and GPUs,
and hence together comprise a realistic group for mining in the cloud. Further-
more, the currencies were chosen to evaluate a variety of mining algorithms and
provide maximum coverage across the entire algorithm-space for mining-related
PoW algorithms. The coins were also chosen to represent a large fraction of the
market cap for mine-able coins (excluding Ripple, which cannot be mined, or
coins with similar PoW algorithms, like Monero which is based on the same
algorithm as Bytecoin). To mine these coins, we used cryptominers that were
open-source and readily available online. Table 1 lists the cryptominers and min-
ing algorithms for each of the cryptocurrencies used. Each miner was run using as
Mitigating Covert Mining Operations in Clouds and Enterprises
295
Local Memory Load Throughput (GB/s)
Core Occupancy
120
100
80
60
40
20
0
1
8
6
0
Fig. 2. Diﬀerence in behavior of GPU miners and GPU applications. Miners are shown
in red; applications are shown in blue. (Color ﬁgure online)
many cores as available on the test system (8 cores for both the non-virtualized
and virtualized environment) and public mining pools were used to mine coins.
Using public pools ensured that our signature also incorporated the I/O aspects
of miners, in addition to the dominant compute aspects. Finally, each miner was
proﬁled in three diﬀerent operating environments; OS (running standalone in
a host OS), VM (running standalone in a guest OS) and VM+Int (running
simultaneously with interfering applications in a guest OS).
Benchmarks and Cloud Workloads: To obtain signatures for non-mining
applications, we chose various workloads from representative benchmark suites
like CloudSuite (v3.0) [37], SPEC 2006 [20], Rodinia [33] and Parboil [49]. The
benchmarks were chosen to cover a wide variety of domains, such as Hadoop
workloads, scientiﬁc computing, AI simulations, data mining, graph analytics,
web searching etc.; and a wide variety of workload characteristics such as com-
pute and memory intensity, branch and cache behavior, and latency vs. through-
put sensitivity. Furthermore, our mix of benchmarks consisted of both single-
threaded and multi-threaded applications. We tested a total of 39 applications
which we feel are representative of a real-world cloud setting.
Classiﬁcation Algorithm and Evaluation Metrics: For evaluating our
multi-class classiﬁcation problem, we resorted to standard metrics like—
precision, recall, and F-score [47] which is the harmonic mean between precision
and recall. Since we do not know the underlying distribution of the diﬀerent fea-
tures for miners, we tried out diﬀerent non-parametric classiﬁers like k-Nearest
Neighbor (k-NN), Multiclass Decision Tree and Random Forest. We found that in
general, ensemble-based approaches like Random Forest outperformed the other
classiﬁers. During training, features from all applications (i.e., both miners and
non-miners) were used to train the classiﬁer. We used a random forest with 50
decision trees. In the test phase, the classiﬁer predicted the most probable class
for an unseen feature vector.1
1 Unless otherwise stated, all experiments perform binary classiﬁcation.
296
R. Tahir et al.
6 Evaluation
In this section we show empirical results from MineGuard, and present a dis-
cussion on various aspects and limitations of our system. Before moving onto
the ﬁrst set of results, we discuss the empirical overhead of our HPC-based app-
roach. Prior work has shown in detail that the overhead of sampling counters,
even in microsecond intervals (much more ﬁne-grained compared to our app-
roach), is negligible [35,46]. We observed very similar results with small values
(<0.01%) for various polling intervals, hence, we do not present results for the
overhead incurred due to space limitations and instead focus on other details
surrounding MineGuard. Additionally, we found that the average time required
to match a new sample against the classiﬁer was 8 ms, bulk of which was spent
in ﬁle I/O such as formatting the proﬁling data and reading the signature from
disk. However, unnecessary I/O can be eliminated by keeping the signature in
main memory. Finally, actual classiﬁcation only took 32 µs, showcasing the low
overhead nature of our design.
Uniqueness of GPU Mining Signatures: As explained above, MineGuard
uses HPC-based signatures to detect miners in real time. We justify our choice
of HPCs by demonstrating the uniqueness of mining behavior on GPU instances
compared to other common and popular GPU-based workloads. Figure 2 presents
this comparison between mining software and some popular and common GPU
workloads taken from the Rodinia [33] and Parboil [49] GPU-benchmark suites.
The ﬁgure shows the behavior of two diﬀerent proﬁling metrics, out of a total
of 28 GPU metrics, across four miners and six applications. We ran these
experiments for several other benchmarks from the aforementioned benchmark
suites and found consistent results. However, those results have been omitted for
brevity. Some observations from our GPU results are discussed below.
Miners have signiﬁcantly less core occupancy (number of actual threads out
of maximum possible threads) than non-mining applications. This is due to the
fact that, in general, it is a good practice to run as many threads as optimally
possible on a GPU core, and therefore non-mining applications tend to have
high core occupancy. Miners, on the other hand, also optimize for memory per
warp (the basic unit of execution in NVIDIA GPUs), and aim to avoid creating
bottlenecks in the memory system. Consequently, they usually exhibit low core
occupancies.
Another noticeable diﬀerence between miners and non-mining applications is
their usage of local memory. Local memory in NVIDIA GPUs is used for register
spilling and per-thread local data. However, despite its name, local memory
physically resides in the main memory of the GPU and as such it is not as fast
as scratchpads or texture caches. As a result, GPU application programmers
tune their code to minimize local memory usage as much as possible. As can
be seen in Fig. 2, the six diﬀerent non-mining applications have in fact no local
memory usage (an exception is MRI, which does use local memory but does
so minimally). Miners, in stark contrast, exhibit high usage of local memory.
This is a consequence of the fact that mining algorithms require a signiﬁcant
Mitigating Covert Mining Operations in Clouds and Enterprises
297
number of registers and this in turn results in a signiﬁcant number of register
spills (note: the high register usage of these algorithms also contributes to the
low core occupancy).
As evident, there is a marked diﬀerence between the performance counter
proﬁles of GPU miners and typical GPU applications. It is precisely these dif-
ferences that our classiﬁcation algorithm relies upon to detect miners with high
accuracy.
Uniqueness of CPU Mining Signatures: As with GPU-based miners, we
collected HPC-based signatures for CPU-based miners as well. These signatures
were then compared to common CPU-based workloads from CloudSuite and the
SPEC2006 benchmark suite to distinguish CPU miners from non-mining appli-
cations. The unique and distinct characteristics of CPU-based miners, similar to
their GPU counterparts, can be seen in Fig. 3. The ﬁgure shows subgraphs for
two diﬀerent HPCs, out of a total of 26 CPU HPCs shown later in Table 2. Both
subgraphs show a live-trace of a HPC’s value during the execution of a CPU-
based miner mining Litecoin and four non-mining applications; namely data
caching (memcached server), AI (game of Go), H264 (hardware video encoding)
and NAMD (molecular dynamics). The results from other benchmarks have been
omitted for clarity.
In both graphs, the mining signature stands out. Since miners repeatedly
run a small set of computations over and over again for millions of times, their
resource usage is consistent throughout their execution. In other words, min-
ers generally do not exhibit irregular phases as most common applications do.
Rather, miners possess regular and structured phases. This consistency in signa-
ture is represented by a step function like recurring pattern in both graphs (red
line).
On the other hand, non-mining applications and workloads have phases that
are noticeably diﬀerent. While the phases are, like miners, repeated in regular
intervals, the behavior of each phase is much more irregular and possesses a high
degree of variance (a ﬁnding consistent with prior research [35]). These patterns
are particularly visible for H264 (black line). For example, the L1 Store curve of
H264 is rhythmic but irregular, and, in fact, we found that troughs in load count
Frontend Stalls
L1 Stores
1.6E+09
1.4E+09
1.2E+09
1E+09
800000000
600000000
400000000
200000000
0
350000000
300000000
250000000
200000000
150000000
100000000
50000000
0
1
8
2
5
5
2
8
9
0
1
6
3
1
3
6
1
0
9
1
7
1
2
4