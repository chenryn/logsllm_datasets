the trajectories are chosen randomly in the control plane and
cannot be known by an attacker to inﬂuence this process.
Thereafter, the actual trajectories for the selected packets
are retrieved using mechanisms discussed in §5.1. At this
point, whenever the set of forwarding devices in the actual
853used in attacks such Denial of Service (DoS) against network
provider. WedgeTail detects packet dropping as follows:
If A (cid:54)⊆ E and card(A)  Td then there
is a packet delay attack.
Note that the estimated time may be set to be the average
time for all packets traversing that route or computed by
sending simple ping packets. The maximum valid congestion
may be computed using [36] or [40], where it is possible to
achieve real-time congestion detection and measurement.
6.1 Malicious Localization
As mentioned a trajectory is regarded as a total ordered
set. Once one of the malicious actions is detected, it is possi-
ble to locate the associated forwarding device by comparing
A and E (see previous section). Consider Figure 1 and as-
sume when inspecting F D(a) we retrieve E(¯τ ) and A(¯τ ) as
expected and actual trajectories between F D(a) and F D(e),
respectively.
A(¯τ ): F D(a) → F D(b) → F D(f ) → F D(e) equivalent to
total ordered set E = {F D(b), F D(f )}.
E(¯τ ): F D(a) → F D(b) → F D(c) → F D(d) → F D(e)
equivalent to total ordered set A ={F D(b), F D(c), F D(d)}
In this case, by intersecting E and A we retrieve that
{F D(b)} is the malicious node, where packet misrouting
was initiated. The analysis is continued with F D(c) and
F D(d) (or, A − E,) so that at the end of this process any
forwarding device that my be malicious is identiﬁed. The
same approach can be used for malicious actions 1, 3 and 4.
To locate a forwarding device that is delaying packets how-
ever, we retrace time hop by hop in A and compare with the
relevant expected time.
6.2 Practical Considerations
Network congestion will result in packet drops and delays.
Therefore, to minimize the number of false positives, Wed-
geTail has to estimate with a high accuracy the number of
packets drops and delays associated with network conges-
tion. Several solutions have already been proposed in the
literature to achieve this. [32] can detect packet dropping or
gray hole attacks in networks by exploiting the correlation
between packet delays and packet losses due to congestion.
Their proposed methodology is based on passive observa-
tions of the one-way network delay experienced. For the
scope of this work, the main advantage of this solution com-
pared with the better-known proposals such as [32] is that
we could implement it without any additional overhead or
Feature Attributes
Subject Forwarding Device(id) | Controller
Object Packet(id) | Flow(id) | Switch(id)
Action
Isolate(FD(id)) |
Update forwarding table(FD(id)) |
Alarm | Block Messages(FD(id)) |
Test Again(FD(id))
Exception Policy Pi
Validity
t (millisecond)
Table 1: Overview of the response engine policy syntax
support from the network – [32] assumes the routers in the
network cooperate and provide real-time data related to the
queue lengths at their interfaces.
7. THE RESPONSE ENGINE
WedgeTail can be programmed to automatically reply to
identiﬁed threats using its response engine. The response
engine takes as input a set of XML-formatted policies and
translates them into actions for the controller. Developing a
fully ﬂedged policy engine and ensuring the logical correct-
ness of them is out of scope for this work. We developed
a simpliﬁed policy engine for our initial evaluation of Wed-
geTail.
Policy Syntax: Each policy requires six main features
and attributes describing them. The features include Sub-
ject, Object, Actions, Condition, Exception and Validity
time. Table 1 lists the attributes currently supported for
these features. The naming used for attributes are assumed
to be self-descriptive. Note that the values in parenthesis are
expected to be provided as input for each of these attributes.
While each policy may have only one subject, the other fea-
tures may have more than just one associated attribute. The
Exception attribute is mainly used to build hierarchy for the
policies and validity is used to specify timing.
We now look at two examples. Let us revisit Figure 1 and
assume only FD(f) is detected as malicious. An administrator-
deﬁned policy may specify two diﬀerent policies matching
this forwarding device (i.e. one using the Forwarding Device
attribute and another using Controller attribute). First, it
may specify FD(g) as subject and instruct it to use an alter-
native route to forward traﬃc. Second, it may specify for the
Controller to block all incoming OpenFlow messages. Now,
consider the same scenario as before but this time with only
FD(b) identiﬁed as malicious. In this case, there may be an
Exception feature stating if a policy for FD(f) is still active
then no action is executed from this policy.
8.
IMPLEMENTATION
We envision WedgeTail to be integrated as an applica-
tion for SDN controllers for both detection and response.
However, at this stage, to demonstrate WedgeTail’s com-
patibility with diﬀerent platforms, evaluate it over diﬀer-
ent controllers and to ease the implementation we imple-
mented the detection engine as a proxy sitting in between
the control and data plane – a similar architecture is also
used in [11]. In fact, the detection engine requires advanced
functions that, currently, is not consistently available across
controllers. Currently, the response engine is programmed
as an application for Floodlight controller. WedgeTail’s cur-
rent architecture is shown in Figure 4.
854Figure 4: WedgeTail Architecture
We implemented our system, mainly, in Java using ap-
proximately 1500 lines of code. WedgeTail work starts by
creating scanning regions. To do this, it creates a unique
hash from a large number of packets. The packets are then
continuously tracked as they traverse the network by inter-
cepting the PACKET IN messages sent from the data plane
to control plane. This information is then used to create
database records that list all the forwarding devices visited
by packets along with some packet information and a times-
tamp attached to it. WedgeTail composes these records to-
gether and generates the actual packet trajectories using its
Actual Trajectory Extractor module.
Once the scanning zones are generated, and the target
forwarding devices identiﬁed, WedgeTailed requires having
the expected trajectories of packets to initiate its inspection.
Hence, WedgeTail queries the controller for current topology
and launches a Mininet matching the same setup. It then in-
tercepts all the OpenFlow messages exchanged between the
control plane and data plane including FLOW MOD and
PACKET IN messages. The OpenFlow messages sent from
the controller to forwarding devices (e.g. FLOW MOD) is
ﬁrst translated into a database INSERT command. This
command stores the rule, forwarding device receiving the
rule along with a time value in a MySQL database. There-
after, using the DB to Mininet Translator component, these
are retrieved from the database and translated into appro-
priate Mininet commands. The result is a virtual network
replica, which is continuously updated. The virtual network
replica is used by the Hassel Expected Trajectory module
to compute the expected trajectories of packets1.
9. EVALUATION
We evaluated WedgeTail over simulated networks, which
were diﬀerent in terms of the number of forwarding devices,
forwarding rules, network subnets, and trajectories – with
our latest simulation closely resembling real-world network
1We acknowledge that the authors of [35] provided the
source code of their program, which we used in our Target
Identiﬁcation module.
Number of
AARNet
FD
Subnet
Rules
Trajectory
Setup
12
40
391
403
Zib54
Setup
54
800
21,387
38,654
Sprint
Setup
316
48,966
15,649,486
638,271
Table 2: Overview of simulated networks
conditions. We replicated a number of attacks against SDN
networks that were previously reported in the literature and
analyzed the accuracy of WedgeTail in detecting these at-
tacks.
In order to further evaluate WedgeTail’s detection
engine, we then wrote scripts that synthetically implanted a
total 500 attacks covering all of the malicious actions speci-
ﬁed in §3 in our simulated networks.
Here, we report on WedgeTail’s accuracy and performance
including its detection and prevention success, average de-
tection time, user perceived latencies, overheads related to
policy veriﬁcation, etc. To further challenge WedgeTail’s
detection engine, we also introduced congestion to the sim-
ulated networks causing packet losses and measured the re-
sulting false alarms. Moreover, we also compared our pro-
posal with related works and argued how WedgeTail, in most
cases, outperforms them both in detection and response. Fi-
nally, given that target identiﬁcation and virtual network
replica reconstruction are new features introduced as part
of WedgeTail and may be of use in other domains, we report
on their performance separately.
9.1 Experimental Setup
We simulated three diﬀerent networks namely AARNet
Setup, Zib54 Setup and Sprint Setup. AARNet Setup was
used in our initial feasibility study and resembled a minimal-
istic backbone ISP network topology with only 12 forwarding
devices. The forwarding rules in this network reached 390,
and we generated benign traﬃc such that about 400 trajec-
tories existed in the snapshots taken for inspection by Wed-
geTail. In Zib54 Setup, we extended our simulated network
to more than 50 forwarding devices. Snapshots are taken for
855analysis contained up to 21000 forwarding rules and 38000
trajectories over 800 subnets. A large network is presumed
to have more forwarding devices as well as many more trajec-
tories at any given instance. These motivated us to evaluate
WedgeTail under Sprint Setup. The Sprint Setup contained
316 forwarding devices with more than 600000 trajectories
over a network with more than 15 million rules and 48000
subnets.
Network Topologies: The network topologies for AAR-
Net Setup, Zib54 and Sprint were extracted from The In-
ternet Topology Zoo [23], SNDlib [34] and Rocketfuel [39],
respectively. Figure 11.a and 11.b (in Appendix) represent
AARNet Setup and Zib54.
In these setups, each node is
assumed to contain only one forwarding device, and there
is only one link in-between these devices as also depicted in
the ﬁgures. Figure 11.c (in Appendix) depicts the intercon-
nection of diﬀerent domains at Sprint backbone network,
which we used as the network topology for Sprint Setup.
Note that in Figure 11.c, for clarity, the forwarding devices
at each node are not depicted, and only one link connects
the nodes to each other.
Flow Entries: We were unaware of any publicly avail-
able ﬂow entry data set for our simulated networks. Hence,
to add ﬂow-entries, we created an interface for a subset of
preﬁx found in a full BGP table from Route Views [37] and
spread them randomly and uniformly to each router as ‘lo-
cal preﬁxes’. We then computed forwarding tables using
shortest path routing. The resulting forwarding rules and
subnets for each setup are shown in Table I. We report that
a similar methodology is also adopted by relevant work such
as [8], [41].
Traﬃc Generation: We used Mausezahn [1] and a cus-
tom script to add benign traﬃc to the networks. Similar
to [11], our custom written script imported three real-world
network traces from [9, 10, 26] to drive traﬃc into Mininet.
We hosted the simulated networks on a machine equipped
with Intel Core i5, 2.66 GHz quad-core CPU and 16 GB
of RAM. The SDN controller equipped with WedgeTail was
hosted on a machine with Intel Core i7, 2.66 GHz quad-core
CPU and 8 GB of RAM.
9.2 Attack Scenarios
We replicated all the attacks presented by the authors
of [11] against networks using ODL, Floodlight, POX and
Maestro as controllers. We also implemented further attacks
including Network-to-Host DoS attack. All of these attacks
use one or more of the capabilities deﬁned in §3 and were
successfully detected by WedgeTail. As examples, we brieﬂy
revise the main characteristics of six diﬀerent attacks and
discuss how WedgeTail successfully detects all of them. We
also compare the advantages of WedgeTail with SPHINX
when detecting these threats – note that the authors did
not provide the source of their solution and therefore, we
cannot provide a numerical performance comparison at this
stage. We report on the performance metrics separately in
§9.4 and §9.5.
I. Network DoS: In this case, compromised forwarding
devices direct traﬃc into a loop and magnify a ﬂow until it
completely ﬁlls out the available link bandwidth. We report
that all four controllers were vulnerable to this attack and