locate the anonymous channel’s communication bandwidth, how-
ever, and are difﬁcult to protect against anonymous DoS attacks
by malicious group members. Strategies exist to strengthen DC-
nets against DoS attacks [22, 40], or to form new groups when an
attack is detected [32]. Dissent’s use of a shufﬂe protocol to set
up a deterministic DC-nets instance, however, cleanly avoids these
DoS vulnerabilities while providing the additional guarantee that
each member sends exactly one message per protocol run, a useful
property for holding votes or assigning 1-to-1 pseudonyms.
Mix-networks [9] offer scalable, practical anonymous unicast
communication, and can be adapted to group broadcast [27]. Un-
fortunately, mix-networks are difﬁcult to protect against trafﬁc anal-
ysis [31] and DoS attacks [16, 24], and in fact, lose security under
DoS attack [5]. Crowds [29] are more computationally efﬁcient
than mix-networks, but are vulnerable to statistical trafﬁc analy-
sis when an attacker can monitor many points across the network.
k-anonymous transmission protocols [39] provide anonymity only
when most members of a group are honest. Dissent, in contrast, is
provably secure against trafﬁc analysis, preserving anonymity even
when up to N − 2 members maliciously collude.
Anonymous voting protocols solve a problem closely related to
group broadcast. Each user casts a ballot whose contents should
be publicly known but whose author should be unknown to both
the election ofﬁcials and other voters. Many voting protocols allow
transmission of only ﬁxed-length messages, e.g., “Yes” or “No” [1].
Cryptographically veriﬁable shufﬂes [20, 26] might replace our
shufﬂe protocol, making the shufﬂe veriﬁable ofﬂine. These al-
gorithms require more exotic and complex cryptography, however,
and generally verify only a shufﬂe’s correctness (i.e., that it is a per-
mutation), and not its randomness (i.e., that it ensures anonymity).
All existing techniques of which we are aware to assure a shuf-
ﬂe’s randomness and anonymity, in the presence of compromised
members, require passing a batch of messages through a series of
independent shufﬂes, as in Dissent or mix-networks [15].
Group signatures [4, 11] and ring signatures [30] provide anony-
mous authentication rather than anonymous transmission. Com-
bining group/ring signatures with classic DC-nets transmission can
meet the ﬁrst two of Dissent’s three key security goals, integrity and
anonymity (see Section 2.3). Such a combination fails to provide
accountability, however: malicious group members can still anony-
mously disrupt the DC-nets transmission channel, preventing com-
munication from occurring at all. Layering group/ring signatures
atop DC-nets also does not provide the 1-to-1 mapping needed for
anonymous voting or assigning Sybil attack-resistant pseudonyms.
Tor [14] and Herbivore [32] are two well-known practical sys-
tems for providing anonymous communication over the Internet.
These systems scale to far larger groups than Dissent does, and also
permit interactive communication. These systems do not provide
Dissent’s strong guarantees of anonymity or accountability, how-
ever. As a system based on mix-networks, Tor is vulnerable to traf-
ﬁc analysis attacks. Herbivore provides unconditional anonymity,
but only within a small subgroup of the total group of participants.
Dissent may be more suitable for non-interactive communication
between participants willing to sacriﬁce protocol execution speed
for strong assurances of anonymity and accountability.
8. CONCLUSION
Dissent is a novel protocol for anonymous and accountable group
communication. Dissent allows a well-deﬁned group of partici-
pants to exchange variable-length messages anonymously without
the risks of trafﬁc analysis or anonymous DoS attacks associated
with mix-networks and DC-nets. Dissent improves upon previous
shufﬂed-send primitives by adding accountability—the ability to
trace misbehaving nodes—and by eliminating the message padding
requirements of earlier schemes. We have reviewed practical con-
cerns associated with a real-world deployment of Dissent, and have
proposed potential solutions for each. Our implementation demon-
strates Dissent to be practical, at least for non-interactive anony-
mous communication within moderate-size groups.
Acknowledgments
We would like to thank Vitaly Shmatikov, Michael Fischer, Bimal
Viswanath, Animesh Nandi, Justin Brickell, Jacob Strauss, Chris
Lesniewski-Laas, Pedro Fonseca, Philip Levis, and the anonymous
CCS reviewers for valuable feedback and discussion. This work
was supported in part by the National Science Foundation under
grant CNS-0916413.
9. REFERENCES
[1] Ben Adida. Advances in cryptographic voting systems. PhD
thesis, Cambridge, MA, USA, 2006.
[2] Mihir Bellare, Anand Desai, David Pointcheval, and Phillip
Rogaway. Relations among notions of security for public-key
encryption schemes. Advances in Cryptology —CRYPTO
’98, pages 549–570, 1998.
[3] Oliver Berthold, Andreas Pﬁtzmann, and Ronny Standtke.
The disadvantages of free MIX routes and how to overcome
them. In Workshop on Design Issues in Anonymity and
Unobservability, July 2000.
[4] Dan Boneh, Xavier Boyen, and Hovav Shacham. Short group
signatures. In CRYPTO, August 2004.
[5] Nikita Borisov, George Danezis, Prateek Mittal, and Parisa
Tabriz. Denial of service or denial of security? How attacks
on reliability can compromise anonymity. In 14th ACM CCS,
October 2007.
[6] Nikita Borisov, Ian Goldberg, and Eric Brewer.
Off-the-record communication, or, why not to use PGP. In
WPES, pages 77–84, October 2004.
[7] Justin Brickell and Vitaly Shmatikov. Efﬁcient
anonymity-preserving data collection. In Tina Eliassi-Rad,
Lyle H. Ungar, Mark Craven, and Dimitrios Gunopulos,
editors, KDD, pages 76–85. ACM, 2006.
[8] Miguel Castro and Barbara Liskov. Practical byzantine fault
tolerance. In 3rd OSDI, pages 173–186, February 1999.
[9] David Chaum. Untraceable electronic mail, return addresses,
and digital pseudonyms. Communications of the ACM, 24(2),
February 1981.
[10] David Chaum. The dining cryptographers problem:
Unconditional sender and recipient untraceability. Journal of
Cryptology, 1(1):65–75, January 1988.
[11] David Chaum and Eugène Van Heyst. Group signatures. In
Eurocrypt, April 1991.
[12] Ian Clarke, Oskar Sandberg, Brandon Wiley, and
Theodore W. Hong. Freenet: A distributed anonymous
information storage and retrieval system. In Workshop on
Design Issues in Anonymity and Unobservability, July 2000.
[13] David Davenport. Anonymity on the Internet: why the price
may be too high. Communications of the ACM, 45(4):33–35,
April 2002.
[14] Roger Dingledine, Nick Mathewson, and Paul Syverson. Tor:
the second-generation onion router. In SSYM’04:
Proceedings of the 13th conference on USENIX Security
349Symposium, pages 21–21, Berkeley, CA, USA, 2004.
USENIX Association.
[15] Roger Dingledine, Vitaly Shmatikov, and Paul Syverson.
Synchronous batching: From cascades to free routes. In
WPET, May 2004.
[16] Roger Dingledine and Paul Syverson. Reliable MIX cascade
networks through reputation. In Financial Cryptography,
March 2002.
[17] John R. Douceur. The Sybil attack. In 1st International
Workshop on Peer-to-Peer Systems, March 2002.
[18] Emulab network emulation testbed.
http://emulab.net/.
[19] Eiichiro Fujisaki, Tatsuaki Okamoto, David Pointcheval, and
Jacques Stern. RSA-OAEP is secure under the RSA
assumption. Journal of Cryptology, 17(2):81–104, 03 2004.
[20] Jun Furukawa and Kazue Sako. An efﬁcient scheme for
proving a shufﬂe. In CRYPTO, August 2001.
[21] David Goldschlag, Michael Reed, and Paul Syverson. Onion
routing for anonymous and private internet connections.
Communications of the ACM, 42(2):39–41, February 1999.
[22] Philippe Golle and Ari Juels. Dining cryptographers
revisited. Eurocrypt, May 2004.
[23] Andreas Haeberlen, Petr Kouznetsov, and Peter Druschel.
PeerReview: Practical accountability for distributed systems.
In 21st SOSP, October 2007.
[24] Jan Iwanik, Marek Klonowski, and Miroslaw Kutylowski.
DUO-Onions and Hydra-Onions — failure and adversary
resistant onion protocols. In IFIP CMS, September 2004.
[25] Leslie Lamport. The part-time parliament. TOCS,
16(2):133–169, 1998.
[26] C. Andrew Neff. A veriﬁable secret shufﬂe and its
application to e-voting. In 8th CCS, pages 116–125,
November 2001.
[27] G. Perng, M.K. Reiter, and Chenxi Wang. M2: Multicasting
mixes for efﬁcient and anonymous communication. In 26th
ICDCS, pages 59–59, 2006.
[28] Mario Di Raimondo, Rosario Gennaro, and Hugo Krawczyk.
Secure off-the-record messaging. In WPES, November 2005.
[29] Michael K. Reiter and Aviel D. Rubin. Anonymous web
transactions with crowds. Communications of the ACM,
42(2):32–48, 1999.
[30] Ronald Rivest, Adi Shamir, and Yael Tauman. How to leak a
secret. In ASIACRYPT, December 2001.
[31] Andrei Serjantov, Roger Dingledine, and Paul Syverson.
From a trickle to a ﬂood: Active attacks on several mix
types. Information Hiding, pages 36–52, 2003.
[32] Emin Gün Sirer et al. Eluding carnivores: File sharing with
strong anonymity. In 11th SIGOPS European Workshop,
September 2004.
[33] Frank Stajano and Ross Anderson. The cocaine auction
protocol: On the power of anonymous broadcast. In 3rd
Information Hiding Workshop, September 1999.
[34] Edward Stein. Queers anonymous: Lesbians, gay men, free
speech, and cyberspace. Harvard Civil Rights-Civil Liberties
Law Review, 38(1), 2003.
[35] Douglas R. Stinson. Cryptography: Theory and Practice,
Third Edition (Discrete Mathematics and Its Applications).
Chapman & Hall/CRC, November 2005.
[36] Brad Stone and Matt Richtel. The hand that controls the sock
puppet could get slapped. New York Times, July 2007.
[37] Al Teich, Mark S. Frankel, Rob Kling, and Ya-ching Lee.
Anonymous communication policies for the Internet: Results
and recommendations of the AAAS conference. Information
Society, May 1999.
[38] Eugene Vasserman, Rob Jansen, James Tyra, Nicholas
Hopper, and Yongdae Kim. Membership-concealing overlay
networks. In 16th ACM CCS, November 2009.
[39] Luis von Ahn, Andrew Bortz, and Nicholas J. Hopper.
k-anonymous message transmission. In 10th CCS, pages
122–130, New York, NY, USA, 2003. ACM.
[40] Michael Waidner and Birgit Pﬁtzmann. The dining
cryptographers in the disco: Unconditional sender and
recipient untraceability with computationally secure
serviceability. In Eurocrypt, page 690, April 1989.
[41] Jonathan D. Wallace. Nameless in cyberspace: Anonymity
on the internet, December 1999. Cato Brieﬁng Paper No. 54.
[42] Wikileaks. http://wikileaks.org/.
[43] The constitutional right to anonymity: Free speech,
disclosure and the devil. Yale Law Journal,
70(7):1084–1128, June 1961.
APPENDIX: KEY PAIR VERIFICATION
In the decryption phase of Dissent’s shufﬂe protocol, honest group
members receive secondary private keys from other, potentially
malicious group members, and must verify both that this private
key wi is valid for the cryptosystem in use, and that it corresponds
to the public key zi distributed during phase 1. Such a check is not a
standard function of public-key cryptosystems, but any public-key
cryptosystem can be augmented to support such a check. The key
point is that disclosure of the private key in phase 5a eliminates all
secrecy requirements associated with that key pair, so the member
who generated a key pair can “prove” the key’s validity simply by
including enough information with the private key for the receiving
member to replay the key generation process exactly.
Given a public-key cryptosystem [19] with a probabilistic key
generation algorithm K(ρ) taking security parameter ρ as input and
producing key pair (x, y) as output, we deﬁne a deterministic con-
struction K(ρ, r) of the same algorithm, where r contains the ran-
dom bits supplied to the key generation algorithm. We deﬁne the
augmented key pair of the original private/public key pair (x, y) to
be the pair ((x, r), (y, ρ)). Using this augmented algorithm, mem-
bers participating in the shufﬂe protocol broadcast (y, ρ) during
phase 1, and reveal (x, r) during phase 5a.
An honest member who receives an augmented key pair need not
rely on the correctness of the received private key x and its claimed
correspondence to the public key y.
Instead, the receiver runs
the deterministic key generation algorithm to compute (x′, y′) =
K(ρ, r), and verify x = x′ and y = y′.
Since ρ has a well-
deﬁned validity range and r is an unstructured bit string for which
any sufﬁciently long value is by deﬁnition valid, a correct key gen-
eration algorithm must produce a working key pair for any valid
input combination. Replay thus enables the receiver to verify that
the purported key pair is a correct output of the key generation al-
gorithm, before using the released private key for decryption.
A faulty member might choose the “random” bits r non-randomly
during initial key generation. A non-random r might compromise
the secrecy of ciphertexts encrypted using the public key gener-
ated from r, but such behavior harms the security only of the faulty
member itself, as if the faulty member incorrectly revealed its pri-
vate key before phase 5a.
Independently of how the random input
r was chosen or who knows it, a correct public-key cryptosystem
must encrypt and decrypt reliably using the resulting key pair.
350