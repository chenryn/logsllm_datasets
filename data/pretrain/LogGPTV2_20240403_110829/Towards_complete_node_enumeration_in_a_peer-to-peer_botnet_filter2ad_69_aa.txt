title:Towards complete node enumeration in a peer-to-peer botnet
author:Brent ByungHoon Kang and
Eric Chan-Tin and
Christopher P. Lee and
James Tyra and
Hun Jeong Kang and
Chris Nunnery and
Zachariah Wadler and
Greg Sinclair and
Nicholas Hopper and
David Dagon and
Yongdae Kim
RatBot: Anti-enumeration Peer-to-Peer Botnets
Guanhua Yan1, Songqing Chen2,(cid:2), and Stephan Eidenbenz1
1 Information Sciences (CCS-3)(cid:2)(cid:2)
Los Alamos National Laboratory
2 Department of Computer Science
George Mason University
Abstract. As evidenced by the recent botnet turf war between SpyEye
and Zeus, the cyber space has been witnessing an increasing number of
battles or wars involving botnets among diﬀerent groups, organizations,
or even countries. One important aspect of a cyber war is accurately
estimating the attack capacity of the enemy. Particularly, each party in
a botnet war would be interested in knowing how many compromised
machines his adversaries possess. Towards this end, a technique often
adopted is to inﬁltrate into an adversary’s botnet and enumerate ob-
served bots through active crawling or passive monitoring methods.
In this work, we study potential tactics that a botnet can deploy to
protect itself from being enumerated. More speciﬁcally, we are interested
in how a botnet owner can bluﬀ the botnet size in order to intimidate
the adversary, gain media attention, or win a contract. We introduce
RatBot, a P2P botnet that is able to defeat existing botnet enumeration
methods. The key idea of RatBot is the existence of a fraction of bots
that are indistinguishable from their fake identities. RatBot prevents
adversaries from inferring its size even after its executables are fully
exposed. To study the practical feasibility of RatBot, we implement it
based on KAD, and use large-scale high-ﬁdelity simulation to quantify
the estimation errors under diverse settings. The results show that a naive
enumeration technique can signiﬁcantly overestimate the sizes of P2P
botnets. We further present a few countermeasures that can potentially
defeat RatBot’s anti-enumeration scheme.
1 Introduction
Due to its open nature, the cyber space has been witnessing a growing number
of battles or wars among diﬀerent groups, organizations, or even countries. The
recent botnet turf war between SpyEye and Zeus ﬁghting for bots [7] suggests
that botnets can play an important role in cyber warfare. In a real battle or war,
it is crucial for each party to know the attack capacities of his adversaries. Simi-
larly, in a cyber war involving botnets, a party would be interested in estimating
accurately how many compromised machines his opponents possess.
(cid:2) Songqing Chen is partially supported by AFOSR grant FA9550-09-1-0071 and NSF
grant CNS-0746649.
(cid:2)(cid:2) Los Alamos National Laboratory Publication No. LA-UR 10-03929.
X. Lai, J. Zhou, and H. Li (Eds.): ISC 2011, LNCS 7001, pp. 135–151, 2011.
c(cid:2) Springer-Verlag Berlin Heidelberg 2011
136
G. Yan, S. Chen, and S. Eidenbenz
Currently, a commonly adopted approach to estimating botnet sizes is to
inﬁltrate into an adversary’s botnet and enumerate observed bots through ei-
ther active crawling or passive monitoring methods [13,12]. Diﬀerent techniques
have been used to enumerate existing botnets, such as the Storm botnet, and
they sometimes led to inconsistent results, spanning from 500,000 [13] to 50 mil-
lion [25]. Despite technical challenges such as NAT and DHCP that render it
diﬃcult to estimate botnet sizes accurately, advanced techniques can be applied
to sift out these eﬀects. For instance, the passive enumeration approach proposed
by Kang et al. can enumerate bots sitting behind a ﬁrewall or a NAT [13], and
the UDmap algorithm developed by Xie et al. [29] helps mitigate the eﬀects of
dynamic IP addresses when enumerating bots based on their IP addresses.
In this work, however, we aim to address a more fundamental question: can
a botnet be intelligently designed so that accurately estimating its size is inher-
ently diﬃcult? Particularly, we are interested in exploring potential tactics that
a botmaster can use to bluﬀ his botnet size. In a cyber battle, overestimating
the size of the adversary’s botnet can lead to the eﬀect of intimidation: a party
at a disadvantageous position can deploy this tactic to scare oﬀ a stronger oppo-
nent. In another example, a party can use this tactic to trick his adversary into
using an overly high amount of resources to defend against an attack launched
from one botnet so that he would hold advantage over his adversary in a diﬀer-
ent cyber battle that takes place simultaneously. Furthermore, when two botnet
owners compete for the same customer who wants to use the larger botnet for,
say, spamming or DDoS attacks, one botnet owner may apply the bluﬃng tac-
tics to get the bid. Sometimes, a botnet owner may want his botnet size to be
overestimated so that he can draw some media attention.
To study the power of such bluﬃng tactics, we design a hypothetical botnet
called RatBot, which protects itself from being enumerated. RatBot employs the
peer-to-peer (P2P) structure to improve its resilience against a single point of
failure. The key idea of RatBot is the existence of a fraction of bots that are
indistinguishable from their fake identities, which are spooﬁng IP addresses they
use to hide themselves. RatBot prevents adversaries from inferring its size even
after its executables are fully exposed. This is done with heavy-tailed distribu-
tions to generate the number of fake identities for each bot so that the sum of
observed fake identities converges only slowly and thus has high variation.
Due to its anti-enumeration mechanism by design, RatBot distinguishes itself
from those technical challenges (e.g., NAT and DHCP) making it diﬃcult to
enumerate bots accurately and is thus immune to existing solutions that aim to
address these challeges. The wide deployment of NAT actually leads to underes-
timation of botnet sizes, which is contrary to the design goal of RatBot. Another
distinguishing feature is that the degree to which RatBot can bluﬀ about its size
is controllable by the attacker. This is ideal in some situations (e.g., cyber war)
where the attacker wants to adjust his bluﬃng tactics dynamically.
To study the practical feasibility of RatBot, we implement it using the ac-
tual development code of aMule, a P2P client software that uses KAD for its
P2P communications [2]. We further develop a distributed simulation testbed
RatBot: Anti-enumeration Peer-to-Peer Botnets
137
to evaluate the eﬀectiveness of RatBot in misleading botnet size estimation. We
perform a variety of tests with diﬀerent settings and the results show that a
naive botnet enumeration approach by counting the IP addresses observed from
the P2P botnets could signiﬁcantly overestimate their sizes.
The remainder of this paper is organized as follows. Section 2 presents related
work and Section 3 gives the threat model. In Section 4, we discuss the design
of RatBot, and provide the rationale of such design in Section 5. We introduce
the implementation of RatBot in Section 6 and use large-scale simulation to
evaluate its performance in Section 7. In Section 8, we further discuss potential
countermeasures against RatBot and draw concluding remarks in Section 9.
2 Related Work
Behaviors of real-world botnets have been analyzed to provide insights into how
botnets operate in reality [4,12,13]. Complementary to these eﬀorts, our work
sheds light on the potential challenges regarding enumerating zombie machines
in P2P botnets accurately. In spirit, our work is similar to that of Rajab et
al. [18] as both explore the challenges of estimating botnet sizes, but ours focuses
on P2P botnets rather than IRC botnets. Some previous work has shown that
multiple factors contribute to inaccurate botnet size estimation, including DHCP
and NAT eﬀects [24]. Our results show that even if advanced techniques are
deployed to sift out these eﬀects [13,29], the botnet can still adopt sophisticated
obfuscation techniques to make it a diﬃcult task to estimate its size accurately.
A plethora of botnet detection techniques have been developed recently. Gu et
al. have proposed a series of bot detection methods exploiting spatial-temporal
correlation inherent in bot activities [11,10]. Other botnet detection techniques
include DNS-based methods [19], ISP-level analysis [14], signature-based ap-
proaches [9], and ﬂow-level aggregation and mining [31]. Our work is orthogonal
to these eﬀorts and focuses on anti-enumeration tactics.
Hypothetical botnets proposed previously include Super-Botnet [27], Over-
bot [20], AntBot [30], and hybrid P2P botnets [28]. Our work diﬀers from these
work on two aspects. First, our work focuses speciﬁcally on hypothetic P2P bot-
nets that aim to inﬂate the adversary’s estimation of botnet sizes. Second, we
have used large-scale high-ﬁdelity simulation to quantify the estimation errors
under diverse settings rather than presenting the design from a conceptual level.
The design and implementation of RatBot presented in this work is based on
the Storm botnet, which used the KAD protocol. Besides the Storm botnet, a
few other botnets also applied the P2P protocol to organize their bots, such as
Nugache [26], Waledac [23], and Conﬁcker [17]. Although none of these botnets
have applied anti-enumeration techniques to inﬂate the number of bots they
have, some methods developed for RatBot can be borrowed to enhance their
resilience against enumeration by the adversaries. However, as we shall discuss
later, there is a tradeoﬀ among operational ﬂexibility, local detectability, and
resilience against enumeration in the design space of P2P botnets.
138
G. Yan, S. Chen, and S. Eidenbenz
3 Threat Model
In this work, we consider two families of P2P botnets: immersive P2P botnets
and exclusive P2P botnets. For an immersive P2P botnet, the botmaster delivers
C&C information through a P2P network that has normal P2P nodes in ad-
dition to bots. The original Storm botnet, for instance, was an immersive P2P
botnet because the C&C information was delivered to the Storm bots through
the Overnet network. An exclusive P2P botnet, by contrast, has bots exclusively
as its peers and thus does not have any normal P2P user traﬃc in it. Since the
Overnet network was shut down, the Storm botnet became an exclusive P2P
botnet dubbed Stormnet because only bots can participate in the botnet.
The two primitive operations in a P2P network are publish and search. The
publish primitive is used to publish a data item either on the machine used
by the caller itself (e.g., in an unstructured P2P network) or on a machine
with an identiﬁer that is close to that of the data object (e.g., in a structured
P2P network). The search primitive is used by a peer node to search for data
items that satisfy some speciﬁc conditions, such as containing certain keywords
or producing a certain hash digest. In this work, we assume that in the P2P
network search operations are spoofable, that is to say, a peer node can request a
peer to ﬁnd a data item using a spoofed source IP address. This holds for many
P2P networks, which use UDP to implement the request/response mechanism in
a search operation. For instance, the widely deployed KAD protocol uses UDP
for signaling and TCP for data transfers [16].
It will be seen later that spoofable search operations play a key role in the
design of RatBot for hiding authentic search operations. It is, however, noted
that these constraints limit the design of RatBot only when it is implemented as
an immersive P2P botnet. For an exclusive P2P botnet, as bots do not require an
existing P2P network for their C&C communications, the botmaster has more
freedom on the implementation of spoofable search operations.
In this work, we assume a reasonable adversarial model from the attacker’s
standpoint. First, we do not assume that the P2P botnet deploys a strong au-
thentication scheme. As evidenced by previous eﬀorts of successfully reverse-
engineering the Storm bot executable, it is possible for white-hat security ana-
lysts to reveal secret keys used for bot communications through static or dynamic
malware analysis, and create fake bots to inﬁltrate into the P2P botnet [12,13].
Second, we also assume that the white-hat security analyst, through thorough
static code analysis, possesses full knowledge about the functionalities of an
authentic bot, including its communication protocol and anti-enumeration tech-
niques. Third, we assume that the behaviors of a fake bot and an authentic bot
are indistinguishable to the bots. A fake bot can intercept any message that
passes through it, thus obtaining the source IP address it has used. Fourth, a
fake bot may stay in the P2P botnet for a long time so that for some P2P pro-
tocols (e.g., KAD) a large number of peer nodes would add it to their contact
lists, or actively crawl the P2P network to obtain a list of observed P2P nodes.
In the paper, we use the adversary and the white-hat security analyst inter-
changeably. Next, we shall present the design of RatBot.
RatBot: Anti-enumeration Peer-to-Peer Botnets
139
4 RatBot Design
The key idea of RatBot is the existence of an army of obscure bots, each of which
creates a list of fake identities to hide itself. In this work, we assume that the
identity of a bot is manifested as the IP address that it uses to communicate
with other peers in the network. Although the P2P identiﬁer (e.g., KAD ID)
of a bot can also be used for enumeration purpose, these identiﬁers sometimes
can be changed by bots, thus leading to inaccurate estimate of the botnet size.
Moreover, a compromised machine can run multiple instances of bot executable
and counting each instance as a bot overestimates the size of a botnet.
As opposed to obscure bots, we say
the remaining bots are explicit bots. By
their nature, explicit bots can be enu-
merated. In Figure 1, we present the
architecture of RatBot in the form of
an immersive P2P botnet. If RatBot
is an exclusive P2P botnet, no normal
peers would exist.
Legend
Normal peer
Explicit bot
Obscure bot
A
B
B is A’s neighbor
Fig. 1. RatBot Architecture
4.1 Obscure Bot Selection
When a machine is infected and becomes a bot, it decides whether it should
be an obscure bot. As an obscure bot uses spoofed IP packets to hide its true
identity, an obscure bot must be able to spoof IP packets. Not every end host in
the Internet, however, possesses such a capability due to reasons such as NAT
deployment and blocking of spoofed packets by ﬁrewalls or the host operating
systems [5]. We thus let each bot contact a dedicated server during its bootstrap-
ping phase. The server is hardcoded in the bot executable code1. When a bot
contacts a server, it generates a UDP query packet with an arbitrary spoofed
source; the payload of the packet carries the authentic IP address of the bot. If
the packet arrives at the server, it means that the bot is capable of spooﬁng. The
server decides whether the bot should become an obscure bot and if so, sends
back a response packet to the bot using its authentic IP address carried in the
query packet. If the bot receives the response packet within a certain period of
time, it becomes an obscure bot; otherwise, it is an explicit bot.
How does the server decide whether a bot should be an obscure bot? Suppose
that it knows the size of the current botnet; this can be done by simply letting
each newly infected bot report to it using their authentic IP addresses. The
server then makes its decision by aiming to have a fraction ξ of the entire botnet
as obscure bots. ξ is not hardcoded in the bot executable and it is thus not
known to the adversary. Hence, the adversary cannot estimate the botnet size
as m/(1 − ξ), where m is the number of explicit bots that he has observed.
1 To improve the resilience of the botnet, multiple servers can be speciﬁed in the
executable code. Also, fast ﬂux techniques can be used to prevent easy disruption.
140
G. Yan, S. Chen, and S. Eidenbenz
4.2 Identity Obfuscation
Once a bot decides that it is an obscure bot, it randomly generates a list of
spooﬁng IP addresses that it will use to obfuscate its own IP address later in
P2P communications. The spooﬁng IP addresses should be chosen to be diﬃcult
for the adversary to verify their validity, even if the adversary is able to reverse-
engineer the bot code. For example, these spooﬁng IP addresses should avoid
using those from the dark IP address subspace, and being too concentrated in
a small IP address subspace. The detail of such algorithm is beyond the scope
of this work. For a given obscure bot, how many spooﬁng IP addresses does it
create? The answer provides a key role in the level of diﬃculty for the adversary
to infer the correct botnet size. Consider a simple scheme in which each obscure
bot generates a constant number k of spooﬁng IP addresses. As explained later,
a distinguishing feature of an obscure bot is that it does not respond to any
request by another peer. Suppose that the adversary can enumerate the entire
list of IP addresses S that do not respond to any normal P2P requests. Then,
the number of obscure bots can be estimated at |S|/(k + 1) if it is assumed that
spooﬁng IP addresses do not overlap.
Two observations are worth noting here. First, as obscure bots generate spoof-
ing IP addresses independently, these spooﬁng IP addresses may overlap in prac-
tice. But given that the large IP address space to spoof, the probability of such
overlapping should be low. Second, due to the P2P structure of the botnet and
independent generation of spooﬁng IP addresses by individual bots, compromis-
ing a small number of bots, although helping the adversary rule out the spooﬁng
addresses used by these bots, does not prevent the overall size of the botnet from
still being overestimated.
We now discuss how RatBot chooses the number of spooﬁng IP addresses per
bot. Consider a botnet with n obscure bots. Let Xi denote the number of spooﬁng
IP addresses obscure bot i generates. RatBot uses two levels of obfuscation. For
the ﬁrst level (distribution-level obfuscation), RatBot uses a distribution
with high variation to generate Xi, such as the Pareto distribution with PDF:
(cid:2)
f(x) =