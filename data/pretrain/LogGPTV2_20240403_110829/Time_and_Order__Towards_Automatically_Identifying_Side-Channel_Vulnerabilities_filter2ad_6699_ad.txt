0
×
×
×
×
0
204
×
0
0
0
39
23
34
35
11
15
0
1
0
13
|G i ↔ Ii|
t2
-
-
-
43
5
0
0
0
0
-
0
-
0
t3
-
-
-
0
0
0
0
0
0
-
0
-
0
t1
-
-
-
56
31
0
0
1
0
-
0
-
0
Table 1: The benchmark programs, their concrete input size, the corresponding PT trace size, and the result of branch level side
channel detection
Benchmark
Programs
Functionality
Under Test
Deep Learning
gsl
Hunspell
PNG
Freetype
Bio-rainbow
QRcodegen
Genometools
dA
SdA
DBN
RBM
Sort
LogisticRegression
Permutation
Spell Checking
Image Render
Character Render
Bioinfo Clustering
Generate QR Code
bed to gff3 convertion
p ↔ Ii|
127
112
128
28
6
17
100
156
103
206
39
204
5
Detecting Page Side Channel
|G i
|G i
|G i
p → Iis|
12
5
9
15
9
12
2
11
25
0
9
0
8
p ↔ Ii|
t2
52
28
11
43
24
0
0
2
1
-
0
-
5
t1
65
33
15
56
82
0
0
5
1
-
1
-
5
Detecting Cache Side Channel
|G i
t3
9
0
0
0
0
0
0
2
1
-
0
-
3
|G i
c ↔ Ii|
214
176
152
55
18
33
100
157
111
206
118
204
5
|G i
c → Iis|
0
0
0
16
23
16
2
11
22
0
1
0
8
t1
-
-
-
56
82
0
0
7
10
-
0
-
5
c ↔ Ii|
t2
-
-
-
43
24
0
0
7
6
-
0
-
5
t3
-
-
-
0
0
0
0
7
0
-
0
-
3
Table 2: The page level and cache level vulnerability detection results for the tested benchmark programs
Benchmark
Programs
Functionality
Under Test
Deep Learning
gsl
Hunspell
PNG
Freetype
Bio-rainbow
QRcodegen
Genometools
dA
SdA
DBN
RBM
Sort
LogisticRegression
Permutation
Spell Checking
PNG Image Render
Character Render
Clustering bioinformatics
Generate QR Code
bed to gff3 convertion
IG
(h)
48
48
48
48
48
48
48
48
48
48
48
48
48
TC
(h)
26.1
187.2
63.3
110.1
7.2
0.62
0.57
68.2
19.8
87.4
14.2
8.89
192.6
VI
(m)
7.9
61.7
43.8
13.2
1.8
0.2
0.2
4.4
1.6
19.8
20.9
22.4
15.2
CS
(h)
31.3
132.1
82.3
45.9
8.4
2.5
-
-
-
-
58
126
-
Table 3: Performance overhead for running each component
of ANABLEPS the tested programs. IG stands for Input Gen-
eration, TC stands for Trace Construction, VI stands for Vul-
nerability Identiﬁcation, and CS stands for Constraint Solver
we conﬁgured ANABLEPS to run 48 hours for all of the
benchmarks. Then, our Trace Construction (TC) component
decodes the trace, builds each G i, G i
c. For the
Vulnerability Identiﬁcation (VI), ANABLEPS just performs
the cross-comparison with the graphs we have built. Only
when detecting the branch-level side channel, we invoke
Constraint Solver (CS) to determine whether there is a unique
input for a speciﬁc trace. This execution time is reported in
p, and G i
the last column of Table 3. For certain programs that concolic
execution cannot ﬁnish (marked with ‘-’ in the Table), we
cannot evaluate their performance overhead. We can notice
that the bottleneck of the ANABLEPS is Trace Construction
and Constraint Solver, which are affected by the size of
execution trace ﬁles and computation power.
6 Exploitability of the Vulnerability
So far, we have discussed the design, implementation and
evaluation of ANABLEPS in automatically detecting order and
time based side-channel vulnerabilities. However, automated
tools can only provide syntactic-level analysis. Oftentimes,
such analysis cannot be directly translated into exploitability
of the program, especially when the input space of interest
(to the attackers) cannot be automatically determined. In this
section, we discuss how ANABLEPS can be used by enclave
program developers to analyze the exploitability of the vulner-
abilities by providing the proper input, locating and exploiting
the vulnerabilities.