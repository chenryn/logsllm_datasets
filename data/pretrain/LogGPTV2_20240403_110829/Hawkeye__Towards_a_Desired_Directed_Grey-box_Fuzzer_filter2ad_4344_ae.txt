### 5.3.1 Crash Reproduction against Binutils

Initially, we planned to compare GNU Binutils directly with AFLGo in our experiments, as it is a significant benchmark in [6] for demonstrating AFLGo’s directed fuzzing capabilities. However, we discovered that the actual implementation of AFLGo has several issues [2], particularly in generating static distances. Most notably, the distance calculation process is excessively time-consuming. As a result, when we attempted to use AFLGo’s static analysis on GNU Binutils 2.26, it failed to generate the "distance.cfg.txt" file, which contains the necessary distance information for instrumentation, even after 12 hours. Although AFLGo can still perform fuzzing without this distance information, the fuzzing process becomes undirected, reducing its effectiveness.

Therefore, we decided to use the results from [6] for comparison with our findings for the GNU Binutils benchmark. We followed the exact evaluation setup in [6], where each experiment was conducted 20 times with a time budget of 8 hours. The initial input seed file contained only a line break (generated by `echo "" > in/file`). The target sites were specified based on their CVE descriptions and the backtraces of the crashes. We compared Hawkeye with AFLGo and AFL, and the results are presented in Table 2.

In AFLGo’s paper, the A12 metric [42] is used to show the probability that one fuzzer is better than another across all runs. This metric is not included in Table 2 because we could not obtain the results of each individual run from their experiments.

Key observations:
1. For CVE-2016-4491 and CVE-2016-6131, Hawkeye achieved the best results, with the highest number of hitting rounds (both 9) and the shortest mean Time to Exploit (µTTE) (18773s and 17314s, respectively). On average, Hawkeye showed significant improvements over other tools in terms of hitting rounds (> 20%) and µTTE (> 20%).
2. For CVE-2016-4487/4488 and CVE-2016-4492/4493, all tools reproduced the crashes in all 20 runs, but Hawkeye had the best µTTE. Specifically, Hawkeye reduced the µTTE by at least 20% compared to other tools.
3. For CVE-2016-4489 and CVE-2016-4490, all tools reproduced the crashes within 7 minutes, indicating that these bugs are relatively easy to find. In such cases, directed fuzzers like Hawkeye do not show a significant advantage, and fuzzing randomness plays a more critical role in µTTE.

In summary, Hawkeye demonstrates strong potential for directed fuzzing tasks, especially when the target crashes are not easily detectable.

### 5.3.2 Crash Reproduction on MJS

To directly compare the performance of Hawkeye and AFLGo, we selected the MJS project, which consists of a single source file. The results are shown in Table 3. We chose this project for direct comparison because AFLGo took too long or failed to generate the distance information for other projects like Oniguruma and libpng. On MJS, AFLGo took an average of 13 minutes to generate the basic block distance for different targets. The initial input seed files were taken from the project’s tests directory, and the targets were selected from the crashes reported on the project’s GitHub pages, covering four categories of vulnerabilities: integer overflow (#1), invalid read (#2), heap buffer overflow (#3), and use after free (#4).

Key observations:
1. For #1 and #2, Hawkeye achieved the best results, with the most hitting rounds and the shortest µTTE. Specifically, Hawkeye found the bug in 5 runs for #1 and 7 runs for #2, while the other tools only detected the crashes in 2 runs. Notably, Hawkeye reduced the µTTE from about 3.5 hours to 0.5 hours.
2. For #3, all tools reproduced the crash in 8 rounds, but Hawkeye significantly improved the µTTE, using less than one-fourth of the µTTE of the other tools.
3. For #4, all tools reproduced the crash in all rounds, and the differences in µTTE were not significant.

The A12 values in Table 3 indicate that Hawkeye performed well, with a 95% confidence level of outperforming both other tools, as seen in the values for #2.

### 5.3.3 Crash Reproduction on Oniguruma

To highlight the advantages of dynamic analysis strategies in Hawkeye, we compared it with HE-Go on the Oniguruma regex library. The main difference between Hawkeye and HE-Go lies in the dynamic analysis part. Due to the performance issues of AFLGo in static analysis on Oniguruma and other large projects, we used HE-Go as an alternative in subsequent experiments.

Table 4 compares Hawkeye with HE-Go and AFL against Oniguruma. The first three bugs come from reported CVEs in version 6.2.0, and Bug #4 is a newly fixed vulnerability issue on the GitHub pages.

Key observations:
1. For #3 and #4, Hawkeye achieved the best results among the three tools. For #4, the improvements in both hitting rounds and µTTE were highly significant. For #3, Hawkeye found the bug in one more round, but the µTTE was similar for all tools.
2. For #1 and #2, all tools reproduced the crash in 8 rounds, and there were no significant differences in µTTE between Hawkeye and HE-Go.

These results demonstrate the effectiveness of the dynamic analysis strategies used in Hawkeye.

### 5.4 Target Site Covering

Certain locations in the Program Under Test (PUT) are difficult to reach, even if they do not trigger crashes. In practice, the generated seeds that cover these locations can be used as initial seeds for Coverage-Guided Fuzzers (CGFs) to enhance the overall fuzzing efficiency.