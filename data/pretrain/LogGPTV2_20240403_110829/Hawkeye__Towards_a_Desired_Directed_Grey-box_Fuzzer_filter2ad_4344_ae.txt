1.27
1.11
–
1.21
2.01
–
1.22
1.52
5.3.1 Crash Reproduction against Binutils. In the beginning, we
intended to compare GNU Binutils directly with AFLGo in our ex-
periments since it is an important benchmark in [6] to demonstrate
AFLGo’s directedness. However, we found that the actual implemen-
tation of AFLGo has a few issues [2] in generating static distances.
Most importantly, it takes too long to calculate the distances. As a
result, when we tried AFLGo’s static analysis on GNU Binutils 2.26,
it failed to generate “distance.cfg.txt” which contains the distance
information for instrumentation within 12 hours5. Although AFLGo
can still perform fuzzing without distance information instrumenta-
tion, the fuzzing process is no longer directed without any distance
input. Therefore, we reclaimed the results in [6] to compare with
ours for the GNU Binutils benchmark 6. We follow exactly the
evaluation setup in [6] where each experiment is conducted for 20
times, with the time budget set as 8 hours; the initial input seed file
only contains a line break (generated by echo "" > in/file). The
target sites we specified are based on their CVE descriptions and the
backtraces of the crashes. We compare Hawkeye with AFLGo and
AFL; the results are shown in Table 2. In AFLGo’s paper, the A12
metric [42] is used to show the possibility that one fuzzer is better
than the other according to all the runs. It is ignored in Table 2
since we cannot get the result of each run in their experiments.
We can observe the following facts: 1) For CVE-2016-4491 and
CVE-2016-6131, Hawkeye achieves the best results, with the most
hitting rounds (both are 9 rounds) and the shortest µTTE (18773s
and 17314s). Compared with other tools, on average for both cases,
Hawkeye’s improvements are significant in term of hitting rounds
(> 20%) and µTTE (> 20%). 2) For CVE-2016-4487/4488 and CVE-
2016-4492/4493, all tools reproduce the crashes in 20 runs, and
Hawkeye achieves the best µTTE. Specifically, on these two cases,
5Besides the performance issue of AFLGo, another reason to reclaim AFLGo’s results
in Table 2 is that the hardware environments are similar. The reason is supported by
the similar results produced by AFL in [6] and our experiments.
6Since CVE-2016-4487/CVE-2016-4488 and CVE-2016-4492/CVE-2016-4493 share the
same target sites, we treat them as the same; the reclaimed value for CVE-2016-
4487/CVE-2016-4488 are also average values.
Bug ID
#1
#2
#3
#4
Tool
Hawkeye
AFLGo
AFL
Hawkeye
AFLGo
AFL
Hawkeye
AFLGo
AFL
Hawkeye
AFLGo
AFL
Runs
5
2
2
7
2
2
8
8
8
8
8
8
µTTE(s)
5469
12581
13084
1880
12753
12294
178
819
1269
5519
5878
5036
Factor A12
–
0.77
0.77
–
0.95
0.95
–
0.91
0.95
–
0.57
0.48
–
2.30
2.39
–
6.78
6.54
–
4.60
7.13
–
1.07
0.91
Hawkeye’s improvement in terms of µTTE is significant — reduc-
ing at least 20% than other tools. 3) For CVE-2016-4489 and CVE-
2016-4490, all tools reproduce the crashes in all runs within 7 min-
utes since these bugs are relatively easy to find. Apparently, in such
cases, directed fuzzers have no significant advantage — in other
words, when the crashes are shallow or easy to trigger, Hawkeye’s
merits cannot show and fuzzing randomness matters for µTTE.
To summarize, Hawkeye has the real potential to fulfill directed
fuzzing tasks where the target crashes are not easy to be detected.
5.3.2 Crash Reproduction on MJS. In order to directly compare the
performance between Hawkeye and AFLGo, we chose a project
called MJS, which contains a single source file and the results are
in Table 3. We used this project for direct comparison with AFLGo
since AFLGo took too much time or failed to generate the distance
information for other projects such as Oniguruma, libpng, etc. On
MJS, AFLGo took an average of 13 minutes to generate the basic
block distance for different targets. During experiments, the initial
input seed files are all from the project’s tests directory. The targets
are selected from the crashes reported in the project’s GitHub pages,
which correspond to four categories of vulnerabilities, namely inte-
ger overflow (#1), invalid read (#2), heap buffer overflow (#3), and use
after free (#4). We can observe the following facts : 1) On #1 and #2,
Hawkeye achieves the best results, with the most hitting rounds
and the shortest µTTE for both cases. In terms of hitting rounds,
Hawkeye found #1’s bug in 5 runs and #2’s bug in 7 runs, while
for the other two tools they only detected both crashes in 2 runs.
Notably, this case is nontrivial and Hawkeye reduces the µTTE
from about 3.5 hours to 0.5 hours. 2) On #3, for which all the tools
reproduce the crash in 8 rounds. Still, Hawkeye has the highly sig-
nificant improvement on µTTE, using less than one fourth µTTE
of other tools. 3) On #4, all the tools reproduce the crash in all
rounds, and the µTTE differences among them are not significant.
As to A12, we can see that Hawkeye exhibits really good results,
for example, the values in #2 are both 0.95, which means Hawkeye
has 95% confidence to perform better than both other tools.
5.3.3 Crash Reproduction on Oniguruma. Here we compare Hawkeye
with HE-Go on Oniguruma to show the advantage of dynamic anal-
ysis strategies in Hawkeye. Therefore, the major differences be-
tween Hawkeye and HE-Go is mainly the dynamic part. Due to the
aforementioned performance issues of AFLGo in static analysis on
Table 4: Crash reproduction on Hawkeye, HE-Go and AFL
against Oniguruma.
Table 5: Target site covering results in Hawkeye, HE-Go
and AFL against Fuzzer Test Suite (libjpeg-turbo, libpng,
freetype2).
Bug ID
#1
#2
#3
#4
Tool
Hawkeye
HE-Go
AFL
Hawkeye
HE-Go
AFL
Hawkeye
HE-Go
AFL
Hawkeye
HE-Go
AFL
Runs
8
8
8
8
8
8
2
1
1
7
3
1
µTTE(s)
139
149
135
186
228
372
13768
14163
14341
6969
12547
14375
Factor A12
–
0.58
0.54
–
0.88
1.0
–
0.56
0.57
–
0.82
0.88
–
1.07
0.97
–
1.23
2.00
–
1.03
1.04
–
1.80
2.06
ID
#1
Project
jdmarker.c:659
#2
pngread.c:738
#3
pngrutil.c:3182
#4
ttgload.c:1710
Tool
Hawkeye
HE-Go
AFL
Hawkeye
HE-Go
AFL
Hawkeye
HE-Go
AFL
Hawkeye
HE-Go
AFL
Runs
8
8
8
8
8
8
8
8
8
7
7
6
µTTE(s)
1955
2012
4839
23
16
130
1
66
3
4283
4443
5980
–
1.03
2.48
–
0.70
5.65
–
Factor A12
–
0.53
0.95
–
0.43
1.00
–
0.56
0.51
–
0.55
0.60
66.00
3.00
–
1.04
1.40
Oniguruma and other big projects, hereinafter, we will used HE-Go
as an alternative to AFLGo in the subsequent experiments. We
therefore compare Hawkeye with HE-Go to show the effectiveness
of our dynamic strategies.
In Table 4, we compare Hawkeye with HE-Go and AFL against
the Oniguruma regex library. The first three bugs come from the
reported CVEs which occur on version 6.2.0, and Bug #4 is an newly
fixed vulnerability issue on its GitHub pages. Some observations are:
1) For #3 and #4, Hawkeye achieves the best results among the three
tools. Especially, for #4, the improvements in both hitting rounds
and µTTE are highly significant. For #3, Hawkeye can find the bug
in one more round, but the µTTE is similar for the three tools. 2)
For #1 and #2, all the tools reproduce the crash in 8 rounds. On the
other hand, Hawkeye and HE-Go have no significant differences in
µTTE. From the results, we can conclude that the dynamic analysis
strategies used in Hawkeye are effective.
5.4 Target Site Covering
Certain locations in the PUTs are hard to reach, though they may
not trigger crashes. In practice, the generated seeds that can cover
the such locations can also be used as initial seeds for CGFs to boost