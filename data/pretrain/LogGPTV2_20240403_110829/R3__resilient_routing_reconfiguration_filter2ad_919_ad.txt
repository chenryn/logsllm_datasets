to be 100 Mbps, and conﬁgure link delays to be measured values.
Table 1 summarizes the used topologies. The data for US-ISP are
not shown due to privacy concerns.
Trafﬁc: We obtained real hourly trafﬁc demand matrices of US-
ISP for a one-week period. For Rocketfuel topologies, we use the
gravity model [45] described in [30] to generate synthetic trafﬁc de-
mands. To generate realistic trafﬁc during our experiments on Em-
ulab, we extract Abilene trafﬁc matrix from measurement data and
scale down the values. Then we generate trafﬁc for each OD pair at
the rate encoded in the trafﬁc matrix. We use CAIDA Anonymized
2008 Internet traces [7] for real-time IP packet generation.
Failure scenarios: To evaluate the performance under failures, we
enumerate all possible single- and two-link failures, and randomly
sample around 1100 scenarios of three- and four-link failures. We
use random sampling for three- and four-link failures due to the
large number of all possible such failures. This sampling is only
needed for quantifying the performance under failures and not re-
quired for computing protection routing, since R3 does not require
enumeration of failure scenarios. In addition, for US-ISP, we ob-
tain real maintenance link groups (i.e., the sets of links that were
under maintenance together) for a 6-month period, and treat each
maintenance link group as a single failure event.
Performance metrics: For simulation results, we use two perfor-
mance metrics in our simulations: (1) bottleneck trafﬁc intensity,
and (2) performance ratio. Bottleneck trafﬁc intensity measures
network congestion. The performance ratio of an algorithm is de-
ﬁned as the ratio between the bottleneck trafﬁc intensity of the al-
gorithm and that of optimal ﬂow-based routing, under the same
network topology and trafﬁc demand, and measures how far the al-
gorithm is from being optimal under the given network topology
and trafﬁc demand. It is always no less than 1, and a higher value
indicates that the performance of the algorithm is farther away from
the optimal. We further evaluate the router storage overhead and the
efﬁciency of resilient routing reconﬁguration using measurement
data using Emulab experiments.
Algorithms: We consider the following base routing schemes:
• OSPF: This is widely used in IP/MPLS networks for trafﬁc engi-
neering. For US-ISP, we use the IGP weight optimization tech-
nique in [13] and compute a set of optimized weights for each
day during the evaluation period based on the 24 trafﬁc demand
matrices of that day.
• MPLS-ff: The base routing is computed using the algorithms in
Section 3.
We consider the following protection algorithms.
• CSPF-detour: This algorithm is widely used in fast rerouting.
The bypass routing for a set of failed links is computed using
OSPF algorithm with the failed links removed. The implementa-
tion of the bypass routing is generally based on standard MPLS.
• OSPF reconvergence (recon): In this algorithm, the OSPF rout-
ing protocol is allowed to re-compute routing for every changed
topology.
• Failure-Carrying Packet (FCP): This is the algorithm as described
in [26]. In this algorithm, individual data packet keeps track of
topology changes that have been encountered by the packet, and
the packet is routed along the OSPF path in the current snapshot
of topology.
• Path Splicing (PathSplice): This algorithm is proposed in [29].
 12
 10
 8
 6
 4
 2
U
L
M
d
e
z
i
l
a
m
r
o
N
OSPF+CSPF-detour
OSPF+recon
FCP
PathSplice
OSPF+R3
OSPF+opt
MPLS-ff+R3
optimal
 40
 45
 50
 55
 60
Interval
Figure 3: Time series of worst-case normalized trafﬁc intensity
with one failure during a given day for US-ISP.
OSPF+CSPF-detour
OSPF+recon
FCP
PathSplice
OSPF+R3
OSPF+opt
MPLS-ff+R3
o
i
t
a
r
e
c
n
a
m
r
o
f
r
e
P
 7
 6
 5
 4
 3
 2
 1
 0
 20
 40
 60
 80
 100
 120
 140
 160
 180
Scenarios sorted by performance ratio
Figure 4: Summary of one failure: US-ISP.
In our evaluation, we compute k = 10 slices with a = 0, b = 3
and W eight(a, b, i, j) = (degree(i)+degree(j))/degreemax,
where degreemax is the maximal node degree of the network.
When forwarding trafﬁc, if a router detects that the outgoing link
for a destination is unavailable, it detours trafﬁc to this destina-
tion through other connected slices using uniform splitting.
• R3: The protection routing is computed using the algorithms in
Section 3.
• Flow-based optimal link detour routing (opt): This is the op-
timal link detour routing for each given trafﬁc and failure sce-
nario. Speciﬁcally, for each failure scenario f , this scheme com-
putes an optimal protection plan (i.e., a rerouting for each link
in f ). Since the detour routing varies according to each failure
scenario, it is challenging to implement in a practical way. Its
performance is used to bound the best performance that can be
possibly achieved by any practical protection algorithms.
5.2 Simulation Results
US-ISP: To preserve conﬁdentiality of US-ISP, we do not report
the absolute trafﬁc intensity on the bottleneck link. Instead, we re-
port normalized bottleneck trafﬁc intensity. Speciﬁcally, for each
interval in the trace, we compute the bottleneck trafﬁc intensity us-
ing optimal ﬂow-based routing when there is no failure. We then
normalize the trafﬁc intensity during different intervals by the high-
est bottleneck trafﬁc intensity observed in the trace.
Single failure: We ﬁrst introduce one failure event (SRLG or MLG).
At each interval, we assume that the network topology deviates
from the base topology by only one failure event. We identify the
worst case performance upon all possible single failure events, and
report normalized trafﬁc intensity on the bottleneck link. Figure 3
shows the results. For clarity, we zoom in to a one-day time frame
during the evaluation period; thus, there are 24 intervals. We make
the following observations. First, R3 based protection (MPLS-
ff+R3 and OSPF+R3) performs close to the optimal, and achieves
performance similar to ﬂow-based optimal link detour routing on
top of OSPF (OSPF+opt). However, ﬂow-based optimal link de-
tour (opt) requires the computation of optimal protection routing
for each individual topology-change scenario, whereas R3 achieves
similar performance with only a single protection routing and a
simple, light-weight routing reconﬁguration. Second, comparing
the two R3 schemes, we observe that MPLS-ff+R3 performs bet-
ter than OSPF+R3 (see intervals 40 to 48). This is expected since
OSPF is less ﬂexible than MPLS. Third, without a good protection
298 
o
i
t
a
r
e
c
n
a
m
r
o
f
r
e
P
o
i
t
a
r
e
c
n
a
m
r
o
f
r
e
P
 4
 3.5
 3
 2.5
 2
 1.5
 1
 0
 4
 3.5
 3
 2.5
 2
 1.5
 1
 0
OSPF+CSPF-detour
OSPF+recon
FCP
PathSplice
OSPF+R3
OSPF+opt
MPLS-ff+R3
 200
 400
 600
 800
 1000
 1200
Scenarios sorted by performance ratio
(a) two failures
OSPF+CSPF-detour
OSPF+recon
FCP
PathSplice
OSPF+R3
OSPF+opt
MPLS-ff+R3
 200
 400
 600
 800
 1000
 1200
Scenarios sorted by performance ratio
(b) sampled three failures
Figure 5: Sorted performance ratio under multiple failures
during peak hour: US-ISP.
scheme, OSPF+recon, OSPF+CSPF-detour, and FCP all lead to
higher levels of normalized trafﬁc intensity. In the early part of the
day, their trafﬁc intensity can be as high as 3 times that of the other
routing protection schemes (∼5 vs. ∼1.5). Fourth, starting from
interval number 49, FCP starts to have better performance than
OSPF+recon, OSPF+CSPF-detour. But its trafﬁc intensity in the
later part of the day can still be as high as 2 times (e.g., during in-
terval number 60) that of MPLS-ff+R3, OSPF+R3 and OSPF+opt.
Finally, by rerouting trafﬁc to multiple slices in a “best effort” fash-
ion, PathSplice leads to less congestion and achieves much better
performance than other existing protection algorithms, though it is
still less efﬁcient than R3 based algorithms.
The previous evaluation shows the effectiveness of R3 during
one day. Next, we summarize the overall performance during the
entire evaluation period (which lasts seven days). Figure 4 shows
the performance ratio versus the time interval sorted based on the
performance ratio. We make the following observations. First,
MPLS-ff+R3, OSPF+R3, and OSPF+opt consistently perform within
30% of the optimal throughout the entire evaluation period. Sec-
ond, OSPF+recon, OSPF+CSPF-detour, PathSplice, and FCP all
cause signiﬁcant performance penalty. The performance of OSPF+recon,
OSPF+CSPF-detour, and FCP can be 260% higher than optimal.
PathSplice performs better, but it still can be 100% higher than the
optimal while R3 based schemes are within 30%. Thus, the trafﬁc
intensity of PathSplicing can be 54% higher than R3.
Multiple failure events: Next we evaluate using multiple failure
events in US-ISP. For clarity of presentation, we ﬁx the interval (a
peak hour) and evaluate the failure events. We report results for
two failures and sampled three failures. We report only sampled
three failures because there are too many failure scenarios to enu-
merate; thus, we use random sampling. Figure 5 shows the perfor-
mance ratio versus the scenario sorted based on the performance
ratio. To make it easier to read, we have truncated the y-axis of
Figure 5 at the value of 4. We observe that under two and three
failures, MPLS-ff+R3 and OSPF+R3 continue to signiﬁcantly out-
perform OSPF+recon, OSPF+CSPF-detour, FCP, and PathSplice.
From Figure 5(a), we observe that OSPF+recon, OSPF+CSPF-detour,
FCP and PathSplice can cause bottleneck trafﬁc intensity to be
more than 3.7 times of the optimal for two failures. This is 94%
higher than the highest of MPLS-ff+R3 and OSPF+R3 (they reach
around 1.9). For three failures, OSPF+recon, OSPF+CSPF-detour,
OSPF+CSPF-detour
OSPF+recon
FCP
PathSplice
OSPF+R3
OSPF+opt
MPLS-ff+R3
 0
 100
 200
 300
 400
 500
 600
Scenarios sorted by performance ratio
(a) two failures
OSPF+CSPF-detour
OSPF+recon
FCP
PathSplice
OSPF+R3
OSPF+opt
MPLS-ff+R3
o
i
t
a
r
e
c
n
a
m
r
o