the general memory consumption varies across different
programs in terms of their own memory usage.
1716    27th USENIX Security Symposium
USENIX Association
Programs
#Symbols
git-core
ssh
cli-hook
Curl
Firefox
Apache
247
16,983
1,983
56,010
4,091,773
2,128,700
Peak TagMap Cost (MB)
DataTracker Dytan RTAG
4.8
2.6
8.0
2.3
67.5
41.7
19
630
140
1,050
NA
NA
12
5.9
17
4.8
155
133
Reduc%
60 / 74
55 / 99
53 / 94
52 / 99
56 / NA
68 / NA
Table 3: DIFT Tag Map Overhead in Practice. #Symbols de-
notes the number of symbols used in performing the DIFT task;
NA means the DIFT is not complete so the peak memory cost
is not available.
In our experiments, DIFT reduced total memory usage
10% to 50% when compared with DataTracker [61], and
by 30% to 90% compared with Dytan [24]. Since these
DIFT systems are designed with the scope of one host, in
order for proper comparison against previous DIFT sys-
tems, we only measured the cases where all the tags are
within one host. Note that this approach only compares
DIFT runtime performance side by side, but does not in-
dicate or suggest that RTAG can only handle single-host
cases. For evaluating the time efficiency in performing
DIFT tasks, we assign the same DIFT tasks to RTAG as
well as to the DIFT engine used by RAIN [35]. Since
RAIN [35] does not support cross-host investigation, we
use RAIN [35] to run the DIFT tasks, sequentially simulat-
ing the time consumption it needs to serialize the network
interaction and orchestrating the replays. We observe that
the parallel DIFT of RTAG takes 60%–90% less time than
RAIN [35] (Table 2).
Figure 4: Comparison of normalized runtime performance be-
tween RAIN [35] and RTAG with CPU bound benchmark SPEC
CPU2006. “GEOMEAN” gives the geometric mean of the per-
formance numbers.
Figure 5: Comparison of normalized runtime performance be-
tween RAIN [35] and RTAG with IO bound benchmarks.
8.2.2 Runtime Overhead
Discussion. For the memory consumption, we find the
taint propagation is mainly composed of copy operations
such that the tag map is just updated with another value.
Combination operation for merging the tags of two loca-
tions is not frequent. Hence, though bit-vector (used in
[24]) ensures a constant length of tag for each location
even after combination, the benefit is not obvious. On the
contrary, its fixed size is linear to the number of symbols,
which causes out-of-memory crash when there are many
symbols to tag or (and) the many memory locations are
propagated during the execution. Using set eases the im-
plementation complexity as it natively supports the com-
bination operation with a good performance. However, it
incurs higher metadata cost (on x86 Linux, storing every
4-byte data in the set incurs over 14 bytes). For the time
consumption savings in RTAG, the total time consumption
depends on the longest DIFT task (e.g., Firefox ses-
sion). We are looking into integrating in-process parallel
DIFT techniques to RTAG that could further bring down
the time consumption.
We measure the runtime overhead of RTAG using two sets
of benchmarks: the SPEC CPU2006 benchmark for CPU-
bound use cases and the IO-intensive benchmarks for IO
bound cases. The measurements are performed on two
systems, one without RTAG and one with RTAG enabled.
The result of SPEC benchmark is given in Figure 4 with
RAIN [35] as reference. The geometric mean of the run-
time overhead is 4.84%, which shows RTAG has similar
low runtime overhead to previous refinable systems. We
also measure the runtime overhead using IO-intensive ap-
plications to test the performance in IO bound cases. The
benchmark is composed of four scenarios: using scp to
upload a 500MB archive file, using wget downloading
a 2GB mov movie file, compiling LLVM 3.8, and using
Apache to serve an http service for file downloading.
The result of IO-intensive applications is shown in Fig-
ure 5. The overhead of all the items is at most 50%. We
reason that the cause of the higher overhead during file
downloading and compiling is because network and file
inputs are cached during the recording time.
USENIX Association
27th USENIX Security Symposium    1717
Protocol
TCP
UDP
Setting
Window: 128KB
256KB
512KB
RTT%
Bandwidth%
+0.03%
0%
0%
+0.01%
0% +0.012%
Buffer: 512B
8KB
128KB
-0.8%
+0.02%
-0.05%
+0.01%
-0.01% +0.012%
Table 4: Bandwidth impact of RTAG. The bandwidth and round-
trip-time (RTT) are measured with iperf3 benchmark using
different settings for TCP and UDP protocols.
8.2.3 Network Performance Impact
We use iperf3 [13] to test the bandwidth impact of ap-
plying RTAG to typical network protocol settings. For
TCP, we measure the bandwidth both with and without
having RTAG running at different window sizes. For UDP,
we set the buffer size to be similar with real applications
such as DNS (512B), RTP (128KB). We also measure the
performance impact in the term of the end-to-end round-
trip-time (RTT) for one datagram to be delivered to the
server and echoed back to the client. Both impacts are
negligible. The results are summarized in Table 4.
8.2.4 Storage Footprint
As a refinable system, RTAG has the storage overhead for
the non-deterministic logs that are used for faithful replay
of the recorded system-wide process executions. This en-
sures the completeness of retroactive analysis particularly
for the advanced low and slow attacks. The storage foot-
print varies according to the workload on each host and is
comparable with the upstream system RAIN [35]. Note
that only the input data are stored as non-determinism,
thus in the multi-host case, the traffic from a sender to
a receiver are only stored at the receiver side, avoiding
duplicated storage usage. In the use of RTAG, we ob-
serve around 2.5GB–4GB storage overhead per day for
a desktop used by a lab student (e.g., programming, web
browsing); and around 1.5GB storage overhead per day
for a server hosting gitolite used internally by five lab
students for version controlling on course projects.
9 Related Work
Dynamic Information Flow Tracking. Dynamic taint
analysis [24, 29, 37, 49, 62] is a well-known technique
for tracking information flow instruction by instruction at
the runtime of a program without relying on the semantic
of a program source or binary. DIFT is useful for policy
enforcement [49], malware analysis [66], and detecting
privacy leaks [29, 62]. To support intra-process tainting,
Cross
DIFT
Host
Systems
×
Dytan [24]
×
DataTracker [61]
×
Panorama [66]
ShadowReplica [34] ×
×
Taintpipe [47]
×
Panda [27, 28]
×
Arnold [25]
×
RAIN [35]
×
Jetstream [55]
TaintExchange [67] ✓
✓
Cloudfence [50]
✓
RTAG
Inst
Time
Runtime
Runtime
Runtime
Runtime
Runtime
Replay
Replay
Replay
Replay
Runtime
Runtime
Replay
DIFT
Tag
Dep
Inlined
Inlined
Inlined
Inlined
Inlined
Inlined
Inlined
Inlined
Inlined
Inlined
Inlined
Decoupled Low
Run
Over
Over(T/M)
High High/High
High High/High
High High/High
Low/High
High
High
Low/High
High High/High
High/High
Low
High/High
Low
Low
Low/High
High High/High
High High/High
Low/Low
Table 5: Comparison of DIFT-based provenance systems.
“Cross Host” tells whether the system covers cross-host anal-
ysis; “Inst Time” represents when the instrumentation is per-
formed (i.e., runtime or replay); “Tag Dep” shows how the tag
dependency is handled; “Run Over” shows the runtime over-
head; “DIFT Over(T/M)” presents the overhead of performing
DIFT in terms of Time and Memory cost in which RTAG both
achieves reductions significantly.
Dytan [24] provides a customizable framework for multi-
color tags. DataTracker adapts standard taint tracking
to provide adequate taint marks for provenance tracking.
However, taint-tracking suffers from excessive perfor-
mance overhead (e.g., the overhead of one state-of-the-art
implementation, libdft [37] is six times as high as native
execution), which makes it difficult to use in a runtime
environment. To solve this problem, several approaches
have been proposed to decouple DIFT from the program
runtime [34, 46, 47, 55, 57]. For example, Taintpipe [47],
Straight-taint [46] and ShadowReplica [34] pre-compute
propagation models from the program source and use
them to speed up the DIFT at runtime. However, their
dependency on program source disables these systems to
analyze undefined behavior. In contrast to these DIFT sys-
tems, RTAG provides both efficient runtime (recording)
and the ability to reliably replay and perform DIFT on the
undefined behavior (e.g., memory corruptions) commonly
seen in recent attacks. Jetstream [55] records the nor-
mal runtime execution and defers tainting until replay by
splitting an application into several epochs. DTAM [30]
uses dynamic taint analysis to find the relevant program
inputs to its control flow and has a potential to reduce
the workload of a record-replay system. Similar to RTAG,
TaintExchange [67] and Cloudfence [50] provide multi-
host information-flow analysis at runtime, but incur sig-
nificant overhead (20× in some cases). We summarize
the comparisons between RTAG and previous DIFT-based
provenance systems in Table 5.
Provenance Capturing. Using data provenance [60] to
investigate advanced attacks, such at APTs, has become a
popular area of research [8, 31, 36, 39, 40, 42, 45, 48, 52].
For example, the Linux Audit System [8], Hi-Fi [52], and
PASS [48] capture system-level provenance with less than
1718    27th USENIX Security Symposium
USENIX Association
10% overhead. Linux provenance modules (LPM) [19] al-
lows developers to develop customized provenance rules
to create Linux Security Modules and LSM-like modules.
SPADE [31] decouples the generation and collection of
provenance data to provide a distributed provenance plat-
form, and ProvThings [63] generates provenance data for
IoT devices. Unfortunately, these systems are restricted
to coarse-grained provenance, which generate many false
dependencies. To reduce false positives and logging sizes,
Protracer [45] improves BEEP [42] to switch between
unit-level tainting and provenance propagation. In con-
trast, MCI [40] determines fine-grained dependencies
ahead-of-time by inferring implicit dependencies using
LDX [39] and creating causal models. DataTracker [61]
leverages DIFT to provide fine-grained data, but incurs
significant overhead. Finally, RAIN [35] uses record and
replay to defer DIFT until replay, then uses reachability
analysis to refine the dependency graph before tainting.
However, none of these systems can provide fine-grained
cross-host provenance like RTAG because they have no
tag association mechanism to support cross-host DIFT.
Network Provenance. In addition to system-wide track-
ing, provenance at network level is a well-researched
area [64, 68, 69]. For example, ExSPAN [69] provides
a distributed data model for storing network provenance.
One challenge network provenance faces is that it obvi-
ously cannot detect most system-level causality on end
nodes. Technically, network provenance and RTAG are or-
thogonal to each other, so that we can use both approaches
together to further enhance attack detection.
Record Replay System.
Deterministic record-and-
replay has been a well-researched area [17, 20, 26, 41,
56].
In addition to providing faithful replay, the cur-
rent state-of-the-art techniques allow instrumentation of
programs during the replay of execution [23, 25, 27].