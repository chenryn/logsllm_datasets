    ![Flocker](img/image_09_007.jpg)
8.  一旦从 outputs 选项卡完成栈部署，获取客户端节点和控制节点的 IP 地址。使用在 Flocker 栈部署开始时生成的键值对将 SSH 引入客户端节点。
设置以下参数:
```
$ export FLOCKER_CERTS_PATH=/etc/flocker 
$ export FLOCKER_USER=user1 
$ export FLOCKER_CONTROL_SERVICE= # not ClientNodeIP! 
$ export DOCKER_TLS_VERIFY=1 
$ export DOCKER_HOST=tcp://:2376 
$ flockerctl status # should list two servers (nodes) running 
$ flockerctl ls # should display no datasets yet 
$ docker info |grep Nodes # should output "Nodes: 2"
```
如果 Flocker `status`和`ls`命令成功运行，这意味着 Docker Swarm 和 Flocker 已经在 AWS 上成功设置。
Flocker 卷可以轻松设置，并允许您创建一个容器，该容器将在容器或容器主机的生命周期之外持续存在:
```
$ docker run --volume-driver flocker -v flocker-volume:/cont-dir --name=testing-container 
```
将创建一个外部存储块并将其装载到我们的主机上，容器目录将绑定到它。如果容器被删除或主机崩溃，数据仍然是安全的。可以使用相同的命令在第二个主机中启动备用容器，我们将能够访问共享存储。前面的教程是在 AWS 上为一个生产用例设置 Flocker，但是我们也可以在 Docker Swarm 设置的帮助下在本地测试 Flocker。让我们考虑一个用例，其中您有两个 Docker Swarm 节点和一个 Flocker 客户端节点。
## 在弗洛克客户端节点中
创建一个`docker-compose.yml`文件并定义容器`redis`和`clusterhq/flask`。提供相应的配置 Docker 映像、名称、端口和数据卷:
```
$ nano docker-compose.yml
web: 
  image: clusterhq/flask 
  links: 
   - "redis:redis" 
  ports: 
   - "80:80" 
redis: 
  image: redis:latest 
  ports: 
   - "6379:6379" 
  volumes: ["/data"]
```
创建一个名为`flocker-deploy.yml`的文件，在这里我们将定义两个将部署在相同节点上的容器-`node-1`；将`node-2`留为空白，从蜂群群集开始:
```
$ nano flocker-deploy.yml
"version": 1 
"nodes": 
  "node-1": ["web", "redis"] 
  "node-2": []
```
使用前面的`.yml`文件部署容器；我们只需要运行以下命令就可以做到这一点:
```
$ flocker-deploy control-service flocker-deploy.yml docker-compose.yml 
```
群集配置已更新。更改可能需要一段时间才能生效，尤其是在需要提取 Docker 映像的情况下。
可以观察到两个容器都在`node-1`中运行。设置完成后，我们可以在`http://node-1`上访问应用。它将显示此网页的访问次数:
```
"Hello... I have been seen 8 times" 
```
重新创建部署文件，以便将容器移动到`node-2`:
```
$ nano flocker-deply-alt.yml 
"version": 1\. 
"nodes": 
  "node-1": ["web"] 
  "node-2": ["redis"] 
```
现在，我们将把容器从`node-1`迁移到`node-2`，我们将看到 Flocker 将自动处理卷管理。当它出现在`node-2`时，它会将现有的卷插入 Redis 容器:
```
$ flocker-deploy control-service flocker-deploy-alt.yml docker-compose.yml
```
群集配置已更新。更改可能需要一段时间才能生效，尤其是在需要提取 Docker 映像的情况下。
我们可以 SSH 到`node-2`中，列出正在运行的 Redis 容器。尝试访问`http://node2`上的应用；我们将能够看到计数仍然保持在`node-1`中，并且随着从`node-2`访问应用而增加`1`:
```
"Hello... I have been seen 9 times" 
```
这个例子展示了我们如何轻松地将 Flocker 集群中的容器及其数据卷从一个节点迁移到另一个节点。
## 车队 Docker 卷插件
护航是另一个 Docker 卷插件，广泛用于提供存储后端。它是用 Go 编写的，主要优点是可以在独立模式下部署。护航将作为 Docker 卷扩展运行，并将表现得像一个中间容器。“护卫队”的初始实施利用了 Linux 设备，并为卷提供了以下四种 Docker 存储功能:
*   精简配置的卷
*   跨主机恢复卷
*   拍摄卷的快照
*   Back up the volumes to external object stores such as **Amazon EBS**, **Virtual File System** (**VFS**), and **Network File System** (**NFS**):
    ![Convoy Docker volume plugin](img/image_09_008.jpg)
    使用护航卷插件
在下面的示例中，我们将运行一个本地护航设备映射器驱动程序，并展示在两个容器之间使用护航卷插件来共享数据:
1.  验证 Docker 版本是否高于 1.8。
2.  通过本地下载插件 tar 文件并提取它来安装护航插件:
    ```
     $ wget https://github.com/rancher/convoy/releases/download
            /v0.5.0/convoy.tar.gz 
            $ tar xvf convoy.tar.gz 
            convoy/ 
            convoy/convoy-pdata_tools 
            convoy/convoy 
            convoy/SHA1SUMS 
            $ sudo cp convoy/convoy convoy/convoy-pdata_tools /usr/local/bin/ 
            $ sudo mkdir -p /etc/docker/plugins/ 
            $ sudo bash -c 'echo "unix:///var/run/convoy/convoy.sock" > 
            /etc/docker/plugins/convoy.spec'
    ```
3.  我们可以继续使用文件备份循环设备，该设备充当伪设备，并使文件可作为块设备访问，以便演示护航设备映射器驱动程序:
    ```
     $ truncate -s 100G data.vol 
            $ truncate -s 1G metadata.vol 
            $ sudo losetup /dev/loop5 data.vol 
            $ sudo losetup /dev/loop6 metadata.vol
    ```
4.  一旦数据和元数据设备被设置，启动护卫插件守护程序:
    ```
     sudo convoy daemon --drivers devicemapper --driver-opts 
            dm.datadev=/dev/loop5 --driver-opts dm.metadatadev=/dev/loop6
    ```
5.  在前面的终端中，护卫守护进程将开始运行；打开下一个终端实例并创建一个`busybox` Docker 容器，该容器使用安装在容器内`/sample`目录下的护航卷【T1:
    ```
     $ sudo docker run -it -v test_volume:/sample --volume-driver=convoy 