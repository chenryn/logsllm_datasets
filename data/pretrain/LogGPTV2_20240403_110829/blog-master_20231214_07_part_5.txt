local_pool | 
vip_pool   | {2659002,2420573,2986719}
-[ RECORD 4 ]-------------------------------------------------------------------------
top_pool   | {1404547,1932477,1471356,1193697,1346353}
local_pool | 
vip_pool   | {2891738,2092056,2197346}
-[ RECORD 5 ]-------------------------------------------------------------------------
top_pool   | {1571516,1956445,1464618,1187014}
local_pool | 
vip_pool   | {2603160,2547271}
```
users_hll `uid=10000000` . 对比jsonb , hll存储 2000 的已读视频失真就小很多.   
```
-[ RECORD 1 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------
top_pool   | {1790916,1160239,1318177,1028987,1619263,1178555,1413056,1116453,1023390,1463697,1753935,1401721,1784943,1302459,1696989,1593359,1441450,1693555,1300704,1912178}
local_pool | {420726}
vip_pool   | {2794676,2065227,2631995,2395876,2237920,2001372,2657814,2051098}
-[ RECORD 2 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------
top_pool   | {1899128,1714725,1868715,1153425,1852447,1206311,1272872,1195573,1413299,1483565}
local_pool | {217365,795102}
vip_pool   | {2406797,2459297,2522999,2467079}
-[ RECORD 3 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------
top_pool   | {1341596,1913171,1972329,1920133,1062190,1317098,1526785,1836627}
local_pool | {858336}
vip_pool   | {2043662,2553297,2180356}
-[ RECORD 4 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------
top_pool   | {1900979,1975859,1776285,1207471,1037560,1033851,1630524,1848453}
local_pool | {517531,419669,205882,556845}
vip_pool   | {2871970,2693050,2956581}
-[ RECORD 5 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------
top_pool   | {1711028,1411025,1769915,1306077,1473973}
local_pool | {242174,581692,581780}
vip_pool   | {2254656,2434176}
```
关于失真问题的解决方法:  
- 方法1, 调整精度, 具体参考: https://github.com/citusdata/postgresql-hll
- 方法2, 和jsonb一样, 使用数组, 每个mod内的vids存1个hll. readlist字段改成hll类型.
6\.1、hll也可以用来估算唯一值, 我们前面测试数据的唯一值(已读视频ID)分布分别为36.5万, 1万, 2000.  下面看看HLL统计的偏差有多少?  
```
postgres=# select # readlist from users_hll where uid=1;
     ?column?      
-------------------
 342784.9695243465
(1 row)
Time: 1.521 ms
postgres=# select # readlist from users_hll where uid=10001;
      ?column?      
--------------------
 10233.462757098567
(1 row)
Time: 1.183 ms
postgres=# select # readlist from users_hll where uid=10000000;
      ?column?      
--------------------
 1969.1239222652832
(1 row)
Time: 0.908 ms
```
7、压测脚本  
```  
vi ~/test1.sql        
```  
```   
\set uid random(1,10000000)        
\set mod random(0,63)    
select         
  (        
    select array_agg(vid) from         
    (        
      -- 全国视频池       
      select vid from t_videos_top_pool t1     
      -- 取出与用户喜爱的标签匹配的视频       
      where t1.tag=t.tag         
      -- 过滤已读VID , 使用partian index 0号分区        
      and hll_add(t.readlist, hll_hash_bigint(t1.vid)) <> t.readlist   
      -- 使用partian index 0号分区        
      and abs(mod(hashint8(vid),64)) = :mod        
      -- 按视频推荐权重逆序取出视频        
      order by t1.score desc         
      -- limit 条数来自tag_scores1.limits, 其中全国池占比 50%        
      limit ceil(t.limits*0.5)          
    ) x   -- 全国池limit占比 50%        
  ) as top_pool,           
  (        
    select array_agg(vid) from         
    (        
      -- 本地视频池      
      select vid from t_videos_local_pool t1         
      where t1.tag=t.tag         
      -- 本地池, 增加一个查询条件: 查询与本地用户地域匹配的视频        
      and t1.lid = (select lid from users_hll where uid=:uid)      
      and hll_add(t.readlist, hll_hash_bigint(t1.vid)) <> t.readlist    
      and abs(mod(hashint8(vid),64)) = :mod           
      order by t1.score desc         
      limit ceil(t.limits*0.3)        
    ) x   -- 本地池limit占比 30%         
  ) as local_pool,          
  (        
    select array_agg(vid) from         
    (        
      -- VIP视频池       
      select vid from t_videos_vip_pool t1         
      where t1.tag=t.tag         
      and hll_add(t.readlist, hll_hash_bigint(t1.vid)) <> t.readlist        
      and abs(mod(hashint8(vid),64)) = :mod            
      order by t1.score desc         
      limit ceil(t.limits*0.2)        
    ) x    -- vip池limit占比 20%          
  ) as vip_pool              
from       
(        
  -- 从用户表取出用户的喜好标签, 以及每个标签的返回条数        
  select readlist, (unnest(tag_scores1)).tag as tag, (unnest(tag_scores1)).limits as limits from         
    users_hll where uid=:uid    
) t;    
```  
8、开启压测:  
```  
pgbench -M prepared -n -r -P 1 -f ~/test1.sql -c 6 -j 6 -T 120         
```  
9、压测结果:  
```
transaction type: /root/test1.sql
scaling factor: 1
query mode: prepared
number of clients: 6
number of threads: 6
duration: 120 s
number of transactions actually processed: 177222
latency average = 4.062 ms
latency stddev = 5.174 ms
initial connection time = 11.740 ms
tps = 1476.846025 (without initial connection time)
statement latencies in milliseconds:
         0.000  \set uid random(1,10000000)        
         0.000  \set mod random(0,63)    
         4.062  select ......
```  
 users表使用jsonb类型过滤已读视频ID, 每秒推荐267622条视频;     
 使用users_hll表使用hll类型过滤已读视频ID, 每秒推荐147684条视频;     
使用hll存储已读视频ID, 已读视频个数再多也不怕. 你丝滑, 我比你更丝滑.    
## 还不够先进? 要结合AI?
如果你觉得基于喜好标签还比较传统(但是性能好), 想结合AI, 结合视频特征向量来进行喜好推荐?   
PG和PolarDB依旧可以满足你的愿望, 创建vector插件即可, 支持hnsw, ivfflat索引方法, 上千维度向量, 连ChatGPT都在使用PGVector.   
## 参考    
更多细节可以参考这些文章:       
- [《重新发现PostgreSQL之美 - 23 彭祖的长寿秘诀》](../202106/20210613_02.md)      
- [《重新发现PostgreSQL之美 - 26 这个推荐算法价值1亿》](../202106/20210615_09.md)      
- [《重新发现PostgreSQL之美 - 24 滑动窗口分析 2000x》](../202106/20210614_01.md)      
- [《PostgreSQL 应用开发解决方案最佳实践系列课程 - 2. 短视频业务实时推荐》](../202105/20210503_01.md)      
- [《[视频直播]亿级用户量的实时推荐数据库到底要几毛钱?》](../202009/20200910_02.md)      
- [《PostgreSQL 推荐系统优化总结 - 空间、时间、标量等混合多模查询场景, 大量已读过滤导致CPU IO剧增(类挖矿概率下降优化)》](../202006/20200612_01.md)      
- [《推荐系统, 已阅读过滤, 大量CPU和IO浪费的优化思路2 - partial index - hash 分片， 降低过滤量》](../202006/20200610_02.md)      
- [《PostgreSQL hll 在留存、UV统计中的通用用法》](../202006/20200610_01.md)      
- [《PostgreSQL 大量IO扫描、计算浪费的优化 - 推荐模块, 过滤已推荐. (热点用户、已推荐列表超大)》](../202006/20200601_01.md)      
- [《PostgreSQL 随机采样应用 - table sample, tsm_system_rows, tsm_system_time》](../202005/20200509_01.md)      
- [《PostgreSQL 生成随机数据方法大汇总》](../202006/20200609_01.md)      
- [《PostgreSQL x分组, y排序, 每组各取(N动态)条 - 子查询+子查询聚合使用》](../202007/20200710_02.md)        
- [《PostgreSQL 随机查询采样 - 既要真随机、又要高性能 - table sample方法》](../202105/20210527_01.md)      
- [《沉浸式学习PostgreSQL|PolarDB 1: 短视频推荐去重、UV统计分析场景》](../202308/20230819_02.md)      
- [《PostgreSQL 15 preview - Use a hash table to speed up NOT IN(values)》](../202107/20210707_02.md)
- [《实时营销, 人群圈选推荐业务 性能优化 - memory copy+rb contains计算瓶颈 - rb hash分片》](../202107/20210709_01.md)
- [《PostgreSQL 近似算法库 - DataSketches》](../202003/20200324_37.md)
- [《UID编码优化 - 用户画像前置规则 (bloom, 固定算法等)》](../201911/20191130_01.md)  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")