or techniques for detecting and mitigating such intrusions, must account for the
behavior of not only the hardware and software of the computing infrastructure
itself, but also the behavior of the human users of this infrastructure. Humans
remain notoriously diﬃcult to control, and experiments using human subjects
are often expensive, time consuming, and may require extensive interaction with
internal review boards.
Repeatability of experiments on the Internet is diﬃcult due to the global
network’s scale and its constant state of change and evolution. Even on an iso-
lated testbed, repeatability is hampered by the sheer complexity of modern com-
puter systems. Even relatively simple components like hard disks and Ethernet
switches maintain state internally (in cache buﬀers and ARP tables, respec-
tively), and many components perform diﬀerently under varying environmental
conditions e.g. temperature. Many recent CPUs dynamically adjust their clock
frequency in reaction to changes in temperature, and studies by Google suggest
that temperature plays an important role in the failure rates of hard disk drives
[14]. Reproducibility is even harder. It is unclear what level of detail is suﬃcient
for describing the hardware and software used in a test, but current practices in
the community likely fall short of the standards for publication in the physical
sciences.
The contributions of this paper address two of the above requirements
for performing scientiﬁc experiments in security. Speciﬁcally, we describe tech-
niques that enable controllable, repeatable experiments with client-side attacks
and defenses on isolated testbed networks. First, we present techniques for using
statistical models of human behavior to drive real, binary, GUI-enabled appli-
cation programs running on client machines on the testbed, so that tests can be
220
C.V. Wright et al.
performed without the randomness or privacy concerns inherent to using human
subjects. Second, we present adaptive replay techniques for producing convincing
facsimiles of remotely-hosted applications (e.g. those on the World Wide Web)
that cannot themselves be installed in an isolated testbed network, so that the
client-side applications have something to talk to. In doing so, we generate work-
loads on the hosts and traﬃc on the network that are both highly controllable
and repeatable in a laboratory testbed setting.
On the client side, our approach is to construct a Markov chain model for
the way real users interact with each application. Then, during the experiment,
we use the Markov chains to generate new event streams similar in distribution
to those generated by the real users, and use these to drive the applications on
the testbed. This provides a realistic model of measured human behavior, oﬀers
variability from trial to trial, and provides an experimenter with the ability to
change model parameters to explore new user classes. It also generates a reason-
ably realistic set of workloads on the host, in terms of running processes, ﬁles
and directories accessed, open network ports, system call sequences, and system
resource consumption (e.g. CPU, memory, disk). Many of these properties of
the system are important for experiments involving defensive tools like ﬁrewalls,
virus scanners, or other intrusion detection systems because they are used by
such systems to detect or prevent malicious behavior. Furthermore, because we
run unmodiﬁed application program binaries on the testbed hosts, we can closely
replicate the attack surface of a real network and use the testbed to judge the
eﬀectiveness of various real attacks and defenses against one another.
Using real applications also allows us to generate valid traﬃc on the testbed
network, even for complicated protocols that are proprietary, undocumented,
or otherwise poorly understood. We discuss related work in more detail in the
following section, but for now it suﬃces to say that almost all existing work on
synthetically generating network traﬃc focuses on achieving realism at only one
or two layers of the protocol stack. In contrast, our approach provides realistic
traﬃc all the way from the link layer up to and including the contents of the
application layer sessions.
For example, by emulating a user replying to an email, with just a few mouse
click events, we can generate valid application-layer traﬃc in open protocols like
DNS, IMAP, and LDAP, proprietary protocols including SMB/CIFS, DCOM,
and MAPI/RPC (Exchange mail). This is, of course, in addition to the SMTP
connection used to send the actual message. Each of these connections will ex-
hibit the correct TCP dynamics for the given operating system and will generate
the proper set of interactions at lower layers of the stack, including DNS look-
ups, ARP requests, and possibly Ethernet collisions and exponential backoﬀ.
Moreover, if a message in the user’s inbox contains an exploit for his mail client
(like the mass-mailing viruses of the late 1990s and early 2000s), simply inject-
ing a mouse click event to open the mail client may launch a wave of infections
across the testbed network.
For the case where the actual applications cannot be installed on the isolated
test network, we present techniques based on adaptive replay of application
Generating Client Workloads and High-Fidelity Network Traﬃc
221
dialog that allow us to quickly and eﬃciently reproduce reasonable mock-ups
that make it appear across the network as if the real applications were actually
running on the testbed. These techniques are particularly useful for creating a
superﬁcially realistic version of the modern World Wide Web, giving the illusion
of connectedness on an isolated network.
To illustrate the utility of these techniques, we perform a simple experiment
that would be labor intensive and time consuming to conduct without such
tools. Speciﬁcally, we investigate the performance impact of open source anti-
virus (AV) software on client machines. Conventional folk wisdom in the security
community has been that AV products incur a signiﬁcant performance penalty,
and this has been used to explain the diﬃculty of convincing end users to employ
such protection. Surprisingly, relatively little eﬀort has been put in to quantifying
the drop in performance incurred, perhaps due to the diﬃculty of performing
such a test in a controllable and repeatable manner.
The remainder of the paper is organized as follows. In Section 2, we review re-
lated work in network testbeds, automation of GUI applications, modeling user
behavior, and network traﬃc generation. In Section 3, we present our techniques
for driving real binary applications and for crafting reasonable facsimiles of net-
worked applications that we cannot actually install on the testbed. In Section 4,
we walk through a simple experiment to demonstrate the utility of these tech-
niques and to highlight some challenges in obtaining repeatable results. Finally,
we conclude in Section 5 with some thoughts on future directions for research in
this area.
2 Related Work
Several approaches for conﬁguring, automating, and managing network labora-
tory testbeds have recently been proposed, including Emulab [4], FlexLab [5],
ModelNet [6], and VINI [7]. Our group’s LARIAT testbed platform [8] grew out
of earlier work in the DARPA intrusion detection evaluations [15,16] and was
designed speciﬁcally for tests of network security applications. More recently,
along with others in our group, two of the current authors developed a graphical
user interface for testbed management and situational awareness [17] for use with
LARIAT. The DETER testbed [18] is built on Emulab [4] and, like LARIAT,
is also geared toward network security experiments. The primary contribution
of this paper, which is complementary to the above approaches, is to generate
client-side workloads and network traﬃc for experiments on such testbeds. The
techniques in Section 3.1 were ﬁrst described in the fourth author’s (unpublished)
MIT Master’s thesis [19]. USim, by Garg et al. [20], uses similar techniques for
building proﬁles of user behavior, and uses scripted templates to generate data
sets for testing intrusion detection systems.
Our server-side approach for emulating the Web is similar to the dynamic ap-
plication layer replay techniques of Cui et al. [21,22] and Small et al. [23]. Like
our client-side approach, the MITRE HoneyClient [24] and Strider HoneyMon-
keys from Microsoft Research [25] drive real GUI applications, but that work
222
C.V. Wright et al.
focuses narrowly on automating web browsers to discover new vulnerabilities
and does not attempt to model the behavior of a real human at the controls.
Software frameworks exist for the general-purpose automation of GUI applica-
tions, including autopy [26] and SIKULI [27], but these also require higher-level
logic for deciding which commands to inject. PLUM [28] is a system for learning
models of user behavior from an instrumented desktop environment. Simpson et
al. [29] and Kurz et al. [30] present techniques for deriving empirical models of
user behavior from network logs.
There is a large body of existing work on generating network traﬃc for use
on testbeds or in simulations, but unfortunately most of these techniques were
not designed for security experiments. Simply replaying real traﬃc [31,32] does
not allow for controllable experiments. Other techniques for generating synthetic
traﬃc based on models learned from real traﬃc [33,34,35,36,37] can match sev-
eral important statistical properties of the input trace at the Network and Trans-
port layers. However, because these approaches do not generate application layer
traﬃc, they are not compatible with many security tools like content-based ﬁlters
and intrusion detection or prevention systems, and they cannot interact with real
applications on a testbed. Sommers et al. [38] present a hybrid replay-synthesis
approach that may be more appropriate for some experiments in security. Mutz
et al. [39], Kayacik and Zincir-Heywood [40], and other work by Sommers et al.
[41] generate traﬃc speciﬁcally for the evaluation of defensive tools.
Commercial products from companies including Ixia, BreakingPoint, and
Spirent can generate application-layer traﬃc, but their focus is on achieving
high data rates rather than realistic models of individual user behavior, and
their implementations do not necessarily exhibit the same attack surface as the
real applications.
3 Traﬃc and Workload Generation Techniques
Although our techniques could potentially be applied using any of the exist-
ing network testbeds [4,5,6,7,8,18], our current implementation is built as an
extension of own testbed platform, LARIAT [8], which provides a centralized
database for experiment conﬁguration and logging and a graphical user interface
for launching automated tasks to conﬁgure the testbed and for controlling and
monitoring experiments. Since the publication of [8], the scope of the project
has expanded signiﬁcantly. LARIAT has been used to run distributed experi-
ments on testbeds of more than a thousand hosts. In addition to the user model-
driven actuation capabilities and internet reproduction described in this paper,
components have been added for automatically conﬁguring client and server
software, controlling hosts across a testbed, visualizing the conﬁguration and
logged data [17], and for distributing control across remote physical locations.
The current version can drive user-model behavior on a number of diﬀerent op-
erating system and physical device platforms including smart phones and router
consoles.
Generating Client Workloads and High-Fidelity Network Traﬃc
223
3.1 Client-Side Workload Generation
Our approach is to emulate a human user by injecting input events to applica-
tions via the operating system. In principle, we could use any number of possible
techniques to determine what events to inject and when. One simple approach
would be to simply record the sequence of events generated by a real user,
and replay them verbatim to the applications on the testbed. While this “cap-
ture/replay” approach oﬀers a level of realism that is diﬃcult to match with
synthetic workloads, it fails the requirement that experiments be controllable.
Our techniques strike a careful balance between realism of the workloads and
controllability of the experiment. We record the inputs generated by real human
users and then train a hierarchical Markov chain model for the events sent to
each application. Then, during the experiment, we simulate from the Markov
chains to generate new event streams similar in distribution to those generated
by the real users, and use these to drive the applications on the testbed.
Application User State Machines. We call these models Application User
State Machines, or AUSMs, because the Markov chain models describe a ﬁnite
state machine model of a human user of the application. Formally, an AUSM is
deﬁned as a 4-tuple (n, A, M, X), where n is the number of states in the ﬁnite
state machine model, A = {aij : i, j < n} is the Markov chain state transition
matrix, M = {mi
: i < n} is a set of second-level models for the outputs
produced by each state, and X = {Xij : i, j < n} is a set of models describing
the interarrival time distribution when an event of type i is immediately followed
by an event of type j. We describe the training and event generation processes
for these models in greater detail in the following paragraphs.
Setting AUSM Parameters. To collect training data for the AUSM’s, we use
the DETOURS framework [42] from Microsoft Research to instrument a set of
Windows desktop machines as they are driven by real human users. During the
training interval, we record the event ID, process ID, and arrival time of each
COM (Component Object Model) event on these instrumented systems for some
length of time. We then use the sub-sequence of events corresponding to each
application to set the parameters for a hierarchical Markov chain model that we
then use to drive the given application on the testbed.
To create an AUSM, we begin by creating one state for each event ID. We
count the number of times in the training data where event i was immediately
followed by event j, and store this count as cij. We then compute the probability
of a transition from state i to state j, and store this in the Markov model’s state
transition matrix as:
aij =
cij(cid:3)
k cik
Modeling State Output Distributions. To allow for ﬂexibility in the level of detail
provided by the AUSMs, the outputs of each state are represented using a second
level of models. Some states may always produce the same output, e.g. a state
that generates a mouse click on the “Start” button. Others, like the state that
224
C.V. Wright et al.
generates input for a text box in Internet Explorer, or the word processor input
model, use an n-gram word model of English to produce blocks of text at a time.
If we have no other source of data, these output models can be trained using
the values observed during the training data collection. In other cases, where we
have some expert knowledge of the application, the output models can be trained
using other, larger external data sources. For example, the model that generates
text for the body of an email could be trained using the contents of real emails
in the Enron corpus [43]. In our experiments, we use a locally-collected corpus
of real emails from the authors’ inboxes to train a bigram word model of English
text.
Modeling Event Interarrival Times. Each state transition edge (i, j) in the
AUSM also has an associated interarrival time distribution Xij, which charac-
terizes the delay between events when event i is immediately followed by event
j. Typically, waiting time distributions are well described by the exponential
distribution (e.g. time between buses arriving at a bus stop, time between ma-
jor hurricanes, etc.). However, the data collected from our users’ workstations
exhibits a heavier tail than the exponential distribution, with more wait times
that are much longer than the mean. Some so-called “heavy-tailed” distributions
that occur as a result of user interaction have been shown to be well described
by a power-law or Pareto distribution in the past [44], although the Pareto
distribution also does not appear to be a good ﬁt for our event interarrivals.
Figure 1 shows the observed empirical distribution of COM event interarrival
times for one state transition, together with the best-ﬁt exponential and Pareto
distributions.
Our hypothesis for the poor ﬁt of these two distributions is that there are
actually two sub-populations of event interarrival times. In the ﬁrst case, the
user is actively engaged with the application, generating events at shorter and
more regular intervals. In the second case, the user may switch to another appli-
cation or disengage from the system entirely to perform some other task, such
Fig. 1. Empirical distribution of event interarrival times, with best-ﬁt Exponential and
Pareto distributions
Generating Client Workloads and High-Fidelity Network Traﬃc
225
as answering the telephone, reading a paper, going to a meeting, going home for
the night, or even going on vacation while leaving the system up and running.
To capture this bimodal distribution, we use a mixture model with one Expo-
nential component to represent the periods of active engagement and one Pareto
component to represent the longer periods of inactivity.
Generating Client Workloads. In this section we explain how the state ma-
chine models developed above can be used to feed input to application programs
on a client machine to generate workloads on the host and traﬃc on the testbed
network. Figure 2 shows at a high level how our modules interface with the Win-
dows OS and applications on the client-side system under test (SUT) to achieve
the illusion of a human user at the controls.
Regarding Repeatability. We note that, in order to achieve repeatable experi-
mental results, the entire testbed needs to be started from a ﬁxed state at the
beginning of each run. While we believe the approach we describe here is a nec-
essary condition for obtaining repeatable experimental results, this alone is not
suﬃcient. We elaborate on other techniques for improving the repeatability of
an example experiment in Section 4.
To enable repeatable outputs from our state machines, we store a master ran-
dom seed in the LARIAT database for each experiment. As part of setting up
the testbed for the experiment, each host generates its own unique random seed
as a hash of the master random seed and a unique host identiﬁer assigned to
it by the LARIAT testbed management system. At the beginning of an exper-
iment, each host instantiates a Mersenne Twister [45] pseudo-random number
generator, seeded with its host seed. This PRNG is then used to drive the state
machines as explained above. Thus, by keeping the master seed unchanged for
several runs of the experiment, we can repeat a test many times and get the
same sequence of actions from the state machines in each run. Conversely, by
varying the master seed, we can explore the space of possible user actions and
the corresponding experimental outcomes.
Fig. 2. Client-side traﬃc generation overview
226
C.V. Wright et al.
To simulate the user arriving at the machine and logging in, the master LAR-
IAT server sends a message to the client host’s login module over the control
interface, instructing it to log in the given user. On Windows NT, 2000, and
XP systems, the login module is implemented as a GINA, a dynamic-link li-
brary used by the Windows Winlogon process for Graphical Identiﬁcation and
Authentication [46]. On Windows Vista and newer versions, it runs as a service.
In either case, the module provides login credentials to the OS to start up a
desktop session for the given user. It also launches the user agent module, which
generates user input to drive the Windows desktop and applications from that
point forward.
Upon login, the user agent module starts with a pseudorandomly-selected
AUSM and, if necessary, launches the corresponding application. Then, until
the user agent process receives a signal instructing it to log the user out, it
generates input for the applications by driving the state machines as follows.
In state i, the user agent ﬁrst samples from state i’s output model mi to
generate an input to the application. It injects the input events using the Mi-
crosoft COM APIs or as keyboard events so that, from the applications’ point of
view, these events are delivered by the operating system just as if they had been
generated by a real human user. Then, the user agent selects the next state j
by pseudorandomly sampling from row i of the Markov model’s state transition
matrix A. The user agent samples a pseudorandom delay x from the AUSM’s
event interarrival time distribution Xij. It then sleeps for x seconds, resets the
current state to j, and repeats the process. In some cases, the output of state j
may be to launch a new application or switch to another running application.
In such cases, the user agent also switches to using the new application’s AUSM
in the next iteration.
3.2 Server Side Techniques
For our client-side workload generation techniques to truly be useful on an iso-
lated testbed network, there must be something for the client side applications
to talk to. Sometimes this is relatively straightforward. For example, simply in-
stalling and conﬁguring a Microsoft Exchange email and calendaring server on
the client’s local area network is mostly suﬃcient to enable the MS Outlook
AUSM to function normally. Our previous work [8] presents techniques for gen-
erating emails for the virtual users to receive, and of course the Domain Name
Service and IP layer routing must be properly conﬁgured on the testbed so that
clients can discover one another’s SMTP servers and transmit the actual mail.
Some testbed management systems [47,8,18] handle part or all of this setup
process.
For some other network applications, most notably the world-wide web, set-
ting up a realistic environment on an isolated network is much more challenging.
Although installing a server for the underlying HTTP protocol is not especially
diﬃcult, getting realistic content is. In the early days of the web, most pages
consisted solely of static content, which could easily be downloaded and “mir-
rored” on another server to easily replicate the page. While some web pages
Generating Client Workloads and High-Fidelity Network Traﬃc
227
still use this model, for example many researchers’ proﬁle pages, the majority
of the most popular web sites are currently powered by special-purpose, propri-
etary programs that dynamically generate page content and are only accessible
as a service. Some web applications for dynamically generating page content are
available for installation on the testbed, either as software packages, or as a hard-
ware appliance such as the Google Search Appliance [48], and we do make use of
several such products, including the open source osCommerce [49] e-commerce
engine, the GreyMatter weblog software, and Microsoft Exchange’s webmail
interface.
However, to make it appear on the surface as if the isolated testbed network is
actually connected to the Internet, more sophisticated techniques are required.
Our approach is to use dynamic application-layer replay techniques like those
developed by Cui et al. [22,21] and Small et al. [23] for creating lightweight
server-side honeypots. We elaborate on our approach in the following sections.
Collecting Data. We begin by downloading a large number of web pages using