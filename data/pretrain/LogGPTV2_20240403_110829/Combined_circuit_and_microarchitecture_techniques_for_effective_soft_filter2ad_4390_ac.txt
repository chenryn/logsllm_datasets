represents the FIT with nominal vDD , while
FITenhanced represents the FIT with high vDD • Correspondingly,
Tnormnal_FIT and Tenhanced _FIT depict the period of FIT,lOminal and
FITenhanced respectively. As can be seen from Eq. 6, when the
small
number
the SER reduction gained via reducing
during Tenhanced _ FIT'
of ACE bits
structure
the
in
is
FIT (Le. increasing VDD ) is substantially discounted. Take an
extreme case for example, when there is no ACE bit, we can
not gain any benefit from increasing vDD since all the errors
are masked at microarchitecture level. On the other hand,
when all the bits in the structure are ACE (e.g. no error can be
masked), the benefit can be totally exploited.
high
ROB
when
shows
vulnerability
the supply voltage, unfortunately,
In order to effectively improve ROB reliability and control
the extra power consumption, we propose to trigger high
vDD
at
microarchitecture level and switch vDD back to nominal
VDD when the vulnerability drops below a threshold. Due to
the circuit-level complexity concerns, we limit our scheme to
two supply voltages, and that supply voltage transition is
called dual- vDD
technique [15]. A DC-DC converter can
continuously adjust
the
converter requires a long time for voltage ramping [18] and it
is not suitable for high performance SMT processors. We
choose to use two different power supply lines for the quick
vDD switching, and a pair of PMOS transistors is inserted to
handle the voltage transition. Li et a!. [18] and Usami et a!.
[19] proved that the energy and area overhead from the two(cid:173)
supply-power-network is negligible. The clock frequency
maintains the same while dual- vDD
is applied since the
transistor can operate with nominal frequency when the vDD
switches to high voltage. In [20], Burd et al. showed that
CMOS can continuously operate when the voltage switch is
limited in a certain amount per nano-second. In other words,
the voltage transition can not be completed immediately.
Therefore, when triggering high vDD , the structure's high
vulnerability period should be long enough to cover the
transition cycles. Figure 6 shows the relation between L2
miss and ROB AVF over a period of 5000 cycles on
benchmark vpr execution. Note that the right Y-axis just
the occurrence of L2 miss, and "1"
simply describes
represents that L2 miss exists at that cycle. As can be seen,
the ROB AVF jumps high when L2 miss occurs, and drops
down after it is solved. Because upon an L2 cache miss, the
pipeline usually ends up stalling and waiting for data,
instructions can fill up the ROB quickly and the congestion
will not be solved until L2 cache miss is handled. Note that
the ROB is not fully utilized in normal case because in SMT
to ensure the performance will not be hurt in
processors,
single-thread mode, each thread's private ROB has the same
size as in the single-thread core. Since high utilization in
ROB results in high quantity of vulnerable bits, the ROB
AVF usually exhibits a strong correlation to L2 cache miss.
In SMT processors, L2 cache miss latency often lasts for
hundreds of cycles which can cover the vDD transition cycles.
Therefore, L2 cache miss is a good trigger for vDD switching.
--8-- L2 cache rriss
Eo
CD
•
~rn
0>
~~
N
....J
OIl--~---.eI!J---lI__-1!P--~~
-'-II--
-'--tII----'------It-----'----i!l---"""...-s-__
272000
272,,00
27:3000
271,,00
274000
274500
275000
27",,00
276000
276500
277000
Time (cycle)
Figure 6. The correlation between ROB AVF and L2 cache miss.
4. Experimental Setup
[23]
To evaluate the reliability and performance impact of the
proposed techniques, we use
a reliability-aware SMT
simulation framework developed in [21]. It is built on a
heavily modified and extended M-Sim simulator [22]. In
addition, we ported Wattch power model
into our
simulation framework for power evaluation. Table 1 shows
the baseline machine configuration we used in this study. We
use ICOUNT [24] which assigns the highest priority to the
thread that has the fewest in-flight instructions as the baseline
fetch policy. In [5],
the relation between added capacitor
value, write time and SER for standard rSRAM was studied.
In our experiments, we assume the write time in rSRAM is as
three times as the standard SRAM. We apply 65nm process
technology, the nominal vDD is 1.0 V and high vDD is set as
1.5 V as [25] demonstrates that the vDD can be applied up to
1.5V. The enhanced SERsRAM is computed using Eq.l and 2.
We assume the voltage can transit 0.05v/ns and the transition
time lasts for 20 cycles. The SMT workloads in our
experiments are comprised of SPEC CPU 2000 integer and
floating point benchmarks. We create a set of SMT workloads
with
from
computation intensive to memory access intensive (see Table
2). The CPU and MEM workloads consist of programs only
characteristics
individual
ranging
thread
1-4244-2398-9/08/$20.00 ©2008 IEEE
142
DSN 2008: Fu et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:18:09 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-272008
from the CPU intensive and memory intensive workloads
respectively. Half of the programs in a SMT workload with
mixed behavior (MIX) are selected from the CPU intensive
group and the rest are selected from the MEM intensive group.
We use the Simpoint tool [26] to pick the most representative
simulation point for each benchmark and each benchmark is
fast-forwarded to its representative point before detailed
multithreaded simulation takes place. The simulations are
terminated once the number of committed instructions from
any thread reaches 400 million. The overall SER capturing
vulnerability on both circuit and microarchitecture levels is
used as a baseline metric to estimate how susceptible a
microarchitecture structure is to soft-error strikes. We use
throughput IPC, which qualifies the throughput improvement,
and harmonic mean of weighted IPC [27], which qualifies
both performance improvement and fairness, to evaluate the
performance impact of various techniques.
Table 1. Simulated machine configuration
Parameter
Processor width
Baseline Fetch Policv
Issue Queue
ITLB
Branch Predictor
BTB
Return Address Stack
Ll I-Cache
ROB Size
Load/Store Queue
Inte2er ALU
FPALU
DTLB
Ll D-Cache
L2 Cache
Memorv Access
Configuration
8-wide fetch/issue/commit
ICOUNT
96
128 entries 4-wav. 200 cvcle miss
2K entries Gshare
2K entries 4-wav
32 entries RAS Der thread
32K. 2-wav. 2 DOrts 1 cycle access
96 entries oer thread
48 entries oer thread
8 I-ALU 4 I-MULIDIV 4 Load/Store
8 FP-ALU 4FP-MUL/DIV/SQRT
256 entries 4-wav. 200 cvcle miss
64KB 4-wav. 2 DOrtS 1 cvcle access
unified 2MB 4-waY. 12 cycle access
64 bit wide 200 cycles access latency
CPU
MIX
5. Evaluation
In this section, we first evaluate the efficiency of the
proposed hybrid IQ design in terms of reliability and
performance. We then evaluate the reliability and power
impact of applying dual- vDD on ROB. Finally, the aggregate
results of the two proposed techniques are examined from the
view of the entire processor core.
5.1. Effectiveness of rSRAM Based IQ Design
We compare our hybrid scheme with severnl existing
techniques (e.g. 20P_BLOCK [11] and ORBIT [16]) which
exhibit
IQ reliability
capability
achieving
good
in
enhancement. A comparison is also performed with the
design that uses rSRAM to implement
the entire IQ.
Additionally, [21] showed that among the several advanced
fetch policies in SMT processors, FLUSH can effectively
reduce IQ vulnerability. We also compare our technique with
the baseline SMT processors that use FLUSH fetch policy. In
the hybrid scheme, we set critical threshold as 2 with RIQ
size of 24, and the threshold increases as high as the ROB
size during L2 miss. A detail sensitivity analysis is presented
in Section 5.2.
Figure 7 (a) - (c) presents the overall IQ soft error rate,
throughput
IPC and harmonic IPC yielded by various
techniques across three SMT workload categories. The results
are normalized to the baseline case without any optimization
technique. Note that rSRAM-based IQ has zero soft error rate
when normalized, its SER is not presented in Figure 7 (a). As
can be seen in Figure 7 (a), on average, our hybrid scheme
exhibits strong SER robustness which reduces IQ SER 80%
with only 0.3% throughput IPC and 1% harmonic IPC
reduction through all the workloads. The IQ SER reduction is
more noticeable on MEM workloads, because low IPC
workloads have less ready-to-execute instructions and RIQ is
fully utilized to protect the ACE bits in those instructions.
ORBIT obtains similar IQ SER reduction as our design since
they have common property that only ready-to-execute
instructions can be dispatched into unprotected IQ. The
20P_BLOCK scheme, which blocks instructions with 2 non(cid:173)
ready operands and the corresponding thread at dispatch stage
but still allows the dispatching of unready instructions to
unprotected IQ, gains 20% less SER reduction compared with
the hybrid scheme. Moreover, our design outperforms
FLUSH policy by 58% in reliability improvement. On the
performance perspective, as Figure 7 (b) and (c) show, the
hybrid scheme surpasses other techniques on both throughput
and fairness performance, and the performance difference is
more noticeable in MIX and MEM workloads. As we
expected,
significantly
performance penalty (20% degradation on both throughput
and harmonic IPC), and the performance degradation can be
as worse as 35%.
5.2. Sensitivity Analysis on Criticality Threshold
and RIQ Size
rSRAM based IQ suffers
the
pre-set
criticality
In SMT environment, a L2 miss can cause congestion in
the corresponding thread's ROB. As a result, the computed
instruction criticality using the critical table can easily surpass
the
threshold. Nevertheless, most
instructions are data dependent on the load miss instruction
and can not become ready-to-execute until the L2 cache miss
is solved. Their entrance to the RIQ, however, results in RIQ
resource congestion and prevents the dispatching of critical
instructions from other high performance threads. In our
study, in order to avoid the RIQ congestion and improve the
overall throughput, each thread is assigned with a pre-set
critical threshold and the threshold is adjusted to a high value
(e.g. equal to the RIQ size) when the thread is handling L2
cache miss.
1-4244-2398-9/08/$20.00 ©20081EEE
143
DSN 2008: Fu et a!.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:18:09 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
j D ORBIT
:.~. ~. FlUSH_e.nabled... .
B20P_BLOCK
I
..• H..•.Y.brid._....K).... .
....
0.6
0.4
0.2
o
.
"
~V ~.;:) ~.;:)
(\,
~ ""'-"-L'l-
0
-$" ~- ~-~~~ ~~Y~~~"~./J''bCSj
lI,
..b "
o!'J
(a) Normalized IQ SER
(b) Normalized throughput IPC
(c) Normalized harmonic IPC
Figure 7. A comparison of normalized IQ SER, throughput and harmonic IPCs
1.02
1
~ 0.98
1 0.96
ii 0.94
i 0.92
---. Noramlized Throughput IPC
-+- NonTlalized HarmonIc IPC
-tr- Normalized 10 SER
0.9
0.88 +-,-.,.....-.,.....-,....---,,-.,.,-.,.---,.,,---+
0.5
0.4 ffi
In
0.3 g
0.21
~
0.1 !
0.14
0.12 ffi
0.1 g
0.08 1
0.06 J
0.04
1.1
IX-~"~"~
0.1
]
~ 0.9~ 0.08 ;
0.06 i
..
i 0.7
0.04 i
---...
0.8
a
i
0.6
___ Noramllzed Throughput IPC
__ NonTlalized HanTlonlc IPC
- ( r - NonTlalized IQ SER
0.02
8
16
24
32
40
RlQllze
48
56
64
(a) CPU
8
16
24
56
64
48
32
40
RlQllze
(b) MIX
Figure 8. Criticality threshold analysis
8
16
24
40
32
RlQllze
48
56
64
(c)MEM
therefore,
instructions
into RIQ and affect
Both criticality threshold and RIQ size can control the
dispatching of
the
effectiveness of our hybrid scheme. In this paper, we perform
a sensitivity analysis to understand the impact and interaction
of these two factors. As can be seen, the two factors interact
each other, when criticality threshold is high, a large RIQ is
not necessary; on the other hand, a small RIQ requires a high
criticality threshold. In our study, we start the analysis from
the fixed criticality threshold of two, because instructions
with less than two consumers are likely to be dynamically
dead instructions whose computation result will not affect the
program final output,
they are not performance
critical. The fixed criticality threshold is combined with
various RIQ size ranging from 8 to 64. By doing this, we can
quickly figure out the optimal RIQ size required to satisfy the
lowest criticality threshold. Note that RIQ size cannot be
extended to extraordinary large or small, because with the
fixed total IQ size, an extra large RIQ size corresponds to an
extremely small NIQ size which has difficulty in holding all