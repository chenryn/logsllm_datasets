for handling the event have a large effect on the overall cost. On
the contrary, in [131] security breaches are found to negatively
impacting stock quotation of the victims, especially in the case of
e-commerce firms and DoS attacks.
E. From risk assessment to risk prediction
So far, a considerable amount of studies, frameworks, and
methodologies have focused on assessing the risk of cyber attacks
by explicitly defining their underlying causes and triggers. In fact, as
we show in Table I, the first column of each row specifies either the
particular action, the vulnerability or the exploit that makes the risk
materialize. While this assessment technique is well established in
other domains (e.g., industrial and financial), its effectiveness is still
unclear in a cyber scenario. Indeed, if the whole evaluation is based
on the current knowledge of vulnerabilities present in the system
and tools, and on the exploits available to the attackers, it quickly
becomes clear that the final measurement has limited lifespan, as
new ones are respectively discovered and released on a daily basis.
Moreover, when major cyber incidents occur, its root causes and
enabling factors are almost always unknown to the community,
greatly complicating the assessment of the associated risk.
The goal of prediction is to overcome this assumption and
carry out the risk estimation by leveraging a combination of risk
indicators, measurable factors that have been empirically proven to
reflect the risk across a number of experiments. For instance, back
to Table I, lower age, frequent use of untrusted internet connections,
and longer browsing sessions at night have been found to be
good signs for predicting which users are more at risk of malware
infections [26]. And this is done by mentioning none of their actions
or incautious behaviors — e.g., the user clicked on a malicious
banner or installed malicious software. In a similar way, companies
with misconfigured DNS services and expired certificates more
frequently show signs of botnet activities, otherwise less likely to
be observed in other entities where those are correctly set up [20].
These measurable indicators are merely correlated and not the
cause itself of the risk, the same way as the driver age is not the
cause of car accidents. But by measuring these signs, experts can
make predictions of the likelihood of future events.
Over the past two decades, few scattered studies have focused
explicitly on the problem of predicting security-related events.
In 2001, Browne et al. proposed a simple formula to predict the
Another traditional way to predict future events is to adapt soft-
ware reliability growth models (SRG) commonly used by the relia-
bility community to describe (typically through a non-homogeneous
Poisson process) and predict the evolution of defects in a software
artifact. For instance, Condon et al. [139] show that specific classes
of computer incidents (such as those that depend on particular vul-
nerabilities) can be modeled with an SRG, while the total aggregated
incident rate can be better approximated by using time series [140].
In 2016, Edwards [141] found that the daily frequency of
data breaches can be described by using a negative binomial
distribution and used this model to estimate the likelihood of similar
incidents in the future. Maillart [142] found instead that the theft of
personal information follows a power-tail distribution that is robust
independently of the sector and size of the targeted organization.
On a different but related topic, a large corpus of works aimed
at predicting the occurrence of new vulnerabilities in software
products [143]–[148]. However, as we will discuss in Section V,
it is still unclear how this information can translate to a prediction
or the likelihood of being attacked or compromised in the future.
amount of security incidents, as a function of time, related to
a known vulnerability [23]. Bozorgi [24] used instead publicly
available vulnerability databases to predict which, and how soon,
a vulnerability is likely to be exploited in the future. In 2005,
Schechter [137] looked at the challenges of predicting cyber attacks.
He discovers that experts had a much better understanding and
success in modeling traditional crimes, such as home burglary [138]
while “attempts to bring the quantitative approaches of insurance
and risk management to the measurement of [computer] security
risk have failed”. The author concluded that this is due to the fact
that we still lack techniques to measure the security strength of a
piece of software (we will get back to this idea of predicting risk
through measuring security in Section V).
In recent years, prediction techniques have been at the center
of few works for the purpose of assessing the risk in different
circumstances. In 2009, Bossler et at. [29] investigated the influence
of different factors in predicting data losses from malware infections
by conducting a survey over 788 college students. More recently,
Liu et al. [20], by using a set of external observable features,
attempted to predict the likelihood of an organization to suffer
a cyber incident in the future. The authors achieved, overall, a
90% accuracy with 10% of false predictions. Cyber incidents are
considered also by Thonnard et al. [22], who discussed organization-
and individual-level features that are correlated with the risk of
experiencing spearphishing attacks. In a similar way, Sarabi et
al. [21] build a predictor for cyber incidents using a set of industry,
business, and web visibility/population information. RiskTeller [25]
is a prediction tool that leverages internal telemetry data to predict
which machines are at risk of being infected by a broad spectrum
of different malware. Its prediction accuracy reaches 95%, showing
that such tool could be used to prioritize security spending towards
machines at higher risk of infection. The same conclusion is reached
by Yen et al. [26], who use logs from an antivirus software to infer
the risk for hosts in a large enterprise to encounter malware. On the
consumer side, Canali et al. [27], assess to what extent the risk class
of a given user can be predicted based only on his web browsing
behavior. The authors show how certain types of user actions
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:40:36 UTC from IEEE Xplore.  Restrictions apply. 
1374
Year & Paper
Predicted event
Ground truth
Features
Feature datasets
TABLE II: Works on prediction
2015 [20]
Cyber incidents
Incident reports
2015 [21]
Cyber incidents
Incident reports
2001 [23]
2010 [24]
Vulnerability incidents
Vulnerability exploitation
Incident reports
Vulnerability reports
2015 [22]
Targeted attacks
Mail scanning service
2017 [25]
Malware encounters
2014 [26]
Malware encounters
AV Telemetry
AV Telemetry
2007 [27]
2018 [28]
Malicious website encounters
AV Telemetry
Malicious website encounters
Website Blacklist
2009 [29]
Losses from malware infection
User questionnaires
Ext Mismanagement signs
Malicious activities
Website statistics
Industry sector
Size
Region
Popularity
Exploit release timing
Vulnerability features
Industry sector
Size
Employees features
Binary file appearance
Demographic
VPN logs
Network logs
Browsing behaviors
Browsing behaviors
Self-reported data
Routine Activities
Deviant Behavior
Guardianship
Ext
Ext
Ext
Int
Int
Int
Int
Ext
Int
Scanning tools
Public scan data
Information services
Vulnerability database
Vulnerability reports
Industry classification
Linkedin
Int telemetry
Int telemetry
Int telemetry
Int anti-virus service
Mobile ISP tracking data
User questionnaires
User questionnaires
Ext
Ext
Ext
Ext
Int + Ext
Int
Int
Int
Int
Int
considerably affect their risk exposure. In a similar way, Sharif et
al. [28] use mobile users’ browsing patterns complemented with self-
reported data to predict whether the users will encounter malicious
pages on a long and short period of time. In the latter case, on-the-fly
predictions within a browsing session could be useful to proactively
prevent malicious-content exposures. All these prediction efforts
are summarized in Table II, alongside the type of predicted events,
the source of ground truth information, the adopted features, and
the data from which they are extracted. The table also shows if the
ground truth and the predictive features are extracted from internal
sensors (Int) or are measured from public external information
(Ext). We will return on the importance of this aspect in Section VI.
Finally, few studies have focused on predicting the cost of
cyber incidents and data breaches. In this area, Jacobs [149]
proposed a regression model based solely on the number of user
records compromised. Romanosky [150] introduced more variables
(including the revenue and company type) and found that a 10%
increase in firm revenues is correlated with a 1.3% increase in the
cost of an incident. The author also noted that the price is ultimately
related to the size of the company and the size of the breach, and
not to the malicious nature of the incident or its outcome.
F. Discussion
Nowadays, cyber risk management methodologies, results of
game theoretical studies, and scenario-based simulations are key
components for the development of the cyber-insurance market. In
the first case, companies and individuals that want to adopt cyber
insurance can take advantage from the existence of these frameworks
and guidelines, despite the fact that they were not designed with the
insurance market as ultimate goal: indeed, risk management plays a
very important role to estimate attack probabilities and possible dam-
ages, allowing, in turn, individuals and companies to reason on their
needs for a cyber policy. Insurance carriers as well use these tools
during contract underwriting for assigning a value to a certain en-
tity’s risk and compute premiums for cyber-insurance policies [37].
Unfortunately, all available solutions discussed above have a
qualitative foundation and base their analysis, assessments, and
consequently their results on metrics based on experts knowledge
and previous experience, missing a feedback from real-world
experiments and measurable quantities. Existing methodologies
rely on checklists, worksheets, knowledge basis, catalogues, tables,
and what-if reasoning for identifying threats and hazards. The value
of this type of analysis largely depends upon the quality of the used
documents and the experience of the experts who brainstorm about
undesired events and their effects. In the same way, the use of tools
to capture dependencies among threats such as fault trees or the out-
come of HAZOP and FMEA studies also assumes that who carries
the analysis has detailed knowledge about the areas, operations, and
processes that may be exposed to hazardous events and conditions.
The absence of objective measures and the qualitative nature of
these methodologies make it also harder to obtain an actual value for
the likelihood of a given threat in a cyber scenario: threat probability
is, in fact, a key component for assessing risks and, although
simulations can approximate the frequency of popular attacks found
in the wild, the limitations discussed in the actuarial paragraph of
Section II exacerbate the quantification of such quantity.
Finally, since a sheer number of risk assessment methodologies
exists, it is still unclear which one fits best the cyber domain
and provides the most precise way to compute the likelihood
of cyber incidents. This aspect is further exacerbated by the
ever-growing adoption of IoT devices, for which new risk metrics
and specific risk evaluation methods are still missing [151]. Very
similar considerations apply to simulations based on scenarios, as
their creation, refinement, and precision to capture the intricate
relationships among different entities depends completely on
qualitative opinions of expert users and C-suite members.
As risk management methodologies and scenario-based tests,
game theory applied to cyber insurance can provide important
practical insights. Nevertheless, all conclusions obtained from these
studies are purely based on mathematical modeling, with all the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:40:36 UTC from IEEE Xplore.  Restrictions apply. 
1375
limitations that this implies. First of all, the finiteness of modeling
can lead to a huge difference between the actors considered and
their actual number. Moreover, when using game theory to simulate
the behaviors of clients and carriers, players can undertake a limited
set of actions and interact with each other only in pre-defined
ways, defined by assumptions respectively on the market type
and network topology. Unfortunately, there is no measurement
or comparison with real-world data that confirms the validity of
models and veracity of game theory results.
IV. FROM THEORY TO PRACTICE
As we described in the previous section, research in the cyber-
insurance domain has mostly focused on theoretical studies (from
a mathematical viewpoint) and on the analysis of the costs/benefits
tradeoff (from an economics viewpoint). At the same time, the
system security community has instead been largely ignoring this
emerging area. This could be simply the consequence of the lack
of interesting problems that require novel and practical solutions,
or it could be due to the lack of awareness from our community
towards these problems. As we believe the latter to be true, we
now focus on some of the areas where researchers’ experience with
system and network security can play a fundamental role to help
the development of the cyber-insurance domain. The contribution of
system security researchers can help the development of quantitative,