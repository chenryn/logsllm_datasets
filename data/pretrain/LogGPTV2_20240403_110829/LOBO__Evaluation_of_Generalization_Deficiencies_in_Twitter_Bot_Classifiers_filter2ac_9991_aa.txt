title:LOBO: Evaluation of Generalization Deficiencies in Twitter Bot Classifiers
author:Juan Echeverr&apos;ıa and
Emiliano De Cristofaro and
Nicolas Kourtellis and
Ilias Leontiadis and
Gianluca Stringhini and
Shi Zhou
LOBO – Evaluation of Generalization Deficiencies
in Twier Bot Classifiers
Juan Echeverrï£¡a1c, Emiliano De Cristofaro1, Nicolas Kourtellis2,
Ilias Leontiadis2, Gianluca Stringhini3, and Shi Zhou1
1University College London, 2Telefonica Research, 3Boston University
PI:EMAIL
ABSTRACT
Botnets in online social networks are increasingly often aecting
the regular ow of discussion, attacking regular users and their
posts, spamming them with irrelevant or oensive content, and
even manipulating the popularity of messages and accounts. Re-
searchers and cybercriminals are involved in an arms race, and
new and updated botnets designed to defeat current detection sys-
tems are constantly developed, rendering such detection systems
obsolete.
In this paper, we motivate the need for a generalized evaluation
in Twitter bot detection and propose a methodology to evaluate
bot classiers by testing them on unseen bot classes. We show that
this methodology is empirically robust, using bot classes of varying
sizes and characteristics and reaching similar results, and argue
that methods trained and tested on single bot classes or datasets
might not able to generalize to new bot classes. We train one such
classier on over 200,000 data points and show that it achieves
over 97% accuracy. The data used to train and test this classier
includes some of the largest and most varied collections of bots
used in literature. We then test this theoretically sound classier
using our methodology, highlighting that it does not generalize
well to unseen bot classes. Finally, we discuss the implications of
our results, and reasons why some bot classes are easier and faster
to detect than others.
KEYWORDS
Twitter Bots, Botnets, Generalization, Classication, Social Net-
works, Big Data.
ACM Reference Format:
Juan Echeverrï£¡a, Emiliano De Cristofaro, Nicolas Kourtellis,
Ilias
Leontiadis, Gianluca Stringhini, Shi Zhou. 2018. LOBO – Evalua-
tion of Generalization Deciencies in Twitter Bot Classiers. In Pro-
ceedings of ACSAC ’18, December 3–7, 2018, San Juan, PR, USA.
https://doi.org/10.1145/3274694.3274738
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for prot or commercial advantage and that copies bear this notice and the full citation
on the rst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specic permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6569-7/18/12...$15.00
https://doi.org/10.1145/3274694.3274738
137
1 INTRODUCTION
Automated malicious activity on social networks such as Twitter
has been a signicant problem for many years now. Fake accounts
controlled by bots are used to perform various types of abuse, e.g.,
sending spam [20, 22], participating in reputation-manipulation
schemes [6, 16, 24, 30], spreading malware [19], and phishing [17].
Large quantities of malicious accounts are often created and con-
trolled by single miscreants, forming so-called botnets [1]. To
counter this problem, the research community has developed a
number of systems to detect and block bot accounts on social net-
works. Such approaches look at either prole characteristics of fake
accounts that distinguish them from legitimate ones [2, 31], at dier-
ences in the social graph of fake and legitimate accounts [7, 13, 27],
at the way in which they are controlled by their operators [8, 32, 39],
or at the content that they post, looking for signs of malicious-
ness [26, 29, 35].
Despite the large body of research on detecting bots on Twit-
ter, this is still an open problem. One reason for this is that bot
detection is an inherently adversarial problem, and once a defense
mechanism is known, adversaries can modify their modus operandi
and avoid detection [41]. Another reason, more fundamental, and
often overlooked by the research community is that detection sys-
tems based on machine learning require example datasets of bots
to be trained on, and these often contain biases. For example, if
a system was trained on a dataset containing only bot accounts
belonging to one botnet, it would learn the idiosyncrasies (e.g., the
times at which messages are typically sent or the spam templates
used) of that specic botnet and become very accurate in detecting
it. However, when trying to identify bots belonging to other botnets
it would perform very poorly, because rather than learning the gen-
eral characteristics of bots on Twitter, it would overt on a single
family of bots. Even having multiple families of bots represented in
the training set, there is no guarantee that the system will be able
to identify new bot types or new botnets as they appear.
In this paper, we set to study this problem in a systematic way.
Firstly we collect a dataset that contains more than 20 dierent
bot classes , most of them used in previous bot detection eorts as
ground truth [11, 12, 17, 18, 21]. Secondly, we propose a methodol-
ogy to overcome this issue and produce a generalized bot detection
method. This methodology takes into account multiple types of
bots, and leverages state-of-art machine learning algorithms for
detection of dierent types of bots. The training and testing we in-
troduce is done using an eective “Leave-One-Botnet-Out” (LOBO)
method, which allows the machine learning algorithms to train on
data produced by many and diverse bots, and test its accuracy on
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Juan Echeverrï£¡a et al.
datasets which include bots with behaviors never seen before by
the classiers.
In particular, we use this novel methodology on these classes
of Twitter bots testing on over 1.5 million bots. We show that the
typical approach of training a model to detect bots using single bot
dataset is extremely eective, eortlessly reaching >97% accuracy.
However, the way these datasets are collected prevents them from
being representative of all bots in Twitter. We demonstrate that
when we mix bot classes equitably in a single dataset, the prediction
power of the same classier drops signicantly. More importantly,
we demonstrate that even this bot-detection system that has been
trained with a variety of bots is incapable of detecting new bot
families that were never observed before. In fact, some “target”
botnets completely mislead the classier resulting to less than 1%
detection accuracy, meaning 99% of the bots in that class were
classied as users.
This methodology provides a proxy for the real world general-
ization performance of the bot classier being evaluated. It further
aids in identifying how much each target class is related to the
rest of the bot classes without the need of extensive and costly
inspection.
Our results provide important insights to the research commu-
nity including a way to compare bot detection algorithms, beyond
their stated accuracy. We further suggest high generalization perfor-
mance does not necessarily follow high accuracy. We nally show
the positive insight that even a small portion of certain botnets
can be enough to fully identify them when adding it to a common
learning algorithm, allowing a classier to quickly scale, and incre-
mentally consider dierent and newly revealed bots. In summary,
this paper makes the following contributions:
• Shows the need to go beyond common machine learning
metrics like accuracy, precision, recall, etc. for Twitter bot
detection. As even getting near perfect values for all of them
for single bot classes is not necessarily followed by the ability
to detect other botnets.
• Addresses that need by providing a framework with which to
evaluate expected generalization of a bot detection algorithm
by selectively leaving bot classes and behaviours out of the
training data.
• Collects and combines the biggest and broadest botnet library
to date, which it uses to train a Twitter bot classier.
• Provides a Twitter bot classication strategy that reaches
accuracy values over 97% with a small number of commonly
used features, and evaluates its performance using the gen-
eralization test mentioned earlier.
• Introduces a framework to explore the trade-os between
adding more data from a single bot class and diversifying
the training data with data from a dierent bot class. Then
analyzes the amount of new samples needed to reach rea-
sonable performance on an target bot class, and discuss on
why dierences in this metric happen.
2 RELATED WORK
Bot Detection. Early approaches to detect bots on Twitter rely on
account characteristics that are typical of fake accounts [2, 31]. Yang
et al. [41] show that these approaches have a hard time keeping up
with the evolution of bots, and that they require constant retraining.
Another line of work looks at the way in which bots connect with
other accounts, forming social networks that are very dierent
from the ones built by legitimate accounts [5, 7, 13]. However, Liu
et al [27] show that these techniques can be gamed by adversaries
by exploiting the temporal dynamics used for detection.
Other approaches leverage bots’ similarity in their operation,
such as synchronization in posting messages [8], accesses by a com-
mon set of IP addresses [23, 32], or similar uses of the accounts [39].
Additional work focuses on the content posted by bots. Thomas
et al. [35] analyze the content of the Web pages linked by tweets,
learning to identify signs of spam. Lee et al. [26] look for signs of
evasion commonly used by cybercriminals, e.g., multiple HTTP
redirections. More recently, Nilizadeh et al. [29] presented ,
a system that detects malicious messages (e.g., spam) by identifying
ones with anomalous spreading patterns across the Twitter graph.
Fake Accounts. Thomas et al. [36] analyze over a million accounts
suspended by Twitter and, in follow-up work [37] tracking of
fake Twitter accounts. Yang et al. [40] look at social relationships
between spam accounts on Twitter, while Dave et al. [14] measure
click-spam in ad networks, and Gao et al. [20] analyze spam cam-
paigns on Facebook. Stringhini et al. [30, 33] study the market of
Twitter followers and proposes strategies to detect them in the wild.
Finally, there have been a few eorts both in and out of academia to
identify single botnets in their entirety. Some of them have obtained
large botnets based on geographic anomalies [18] and temporal
anomalies [17]. There have been also analysis on botnets promot-
ing topics or products, including diet pills [28] and even political
candidates [4].
Our work takes features from these eorts, but changes one
important aspect of them. We explicitly test against unseen classes
to evaluate the performance of a classier. We create a test for this,
which is inspired by cross validation and is thought of as a proxy
for generalization of bot classication. It will be clear that for a bot
detection strategy to be deemed as “generalizable”, the minimum
standard that should be passed is the test designed in this paper.
3 DATASETS
Two datasets were compiled for this paper. First, a botnet dataset
that contains the aggregated content generated from a variety of
bot datasets (some previously used in research as ground truth
[11, 12, 21]) and, second, a real-user dataset.
Each dataset includes the information available from the user’s
prole, and all the retrievable tweets at collection time in accordance
to Twitter’s API limitations. This means that each account in our
dataset contains a maximum of 3,200 tweets authored or retweeted
by that account. The way these datasets were nally constructed is
illustrated in Fig. 1.
3.1 Bot Datasets
In this work, we study to which extent various bot types have
dierent signatures that can potentially lead to detection failure
when they are rst discovered (before enough of their samples are
identied and included to the training set). To do this, we build a
dataset of 20 dierent botnet types, each with dierent purpose
138
LOBO – Evaluation of Generalization Deficiencies
in Twier Bot Classifiers
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Previous research
datasets
DeBot (from API)
Public Research
Datasets
Journalist attack
Datasets
Real User Dataset 
(Through BFS) 
Twitter  
User IDs
User  
Proﬁles
Proﬁle  
Features
Full
Dataset
Sub-Sampling
User  
Tweets 
Tweet  
Features
Twitter API
Figure 1: Data collection strategy.
General user
features 
(30) 
Dataset 
C30K
Dataset 
C500
and characteristics. To our knowledge, this is the most extensive
and diverse collection of Twitter bots used so far in the literature.
While most of the datasets have high percentage of bot accounts
associated with them, a few might have small amounts of false
positives in them. This is a trade-o that needs to be made to avoid
inducing bias by ltering these datasets before classication. Do
note that we are only reporting the number of accounts that, at
collection time, had not been suspended by Twitter or marked
as private. This is because suspension or marking an account as
private prevents us from collecting any of its information.
Many of these datasets were obtained from past papers either
from authors or directly querying each of the user IDs in them
against the Twitter API. Some of them come from an API themselves,
and a couple of extra ones are not related to research, but the result
of botnet attacks on two journalists and their own listing of the IDs
that were involved in those attacks. A summary of these datasets is
presented in Table 1. Overall, what follows is how we aggregated
one of the largest and most varied bot datasets in research.
The Star Wars Bots. Dataset A consists of bot accounts that tweet
exclusively quotes from Star Wars novels. It was reported by [18].
The Star Wars bots all share characteristics like a creation period,
id range and small numbers of friends and followers. This dataset
consists of over 355,000 accounts.
The Bursty Bots. The Bursty Bots is a botnet created on Twitter
with the objective of enticing users into blacklisted sites [3, 17].
It’s strategy was simple by using a mention and a shortened or
obfuscated URL. They share some characteristics like having zero
friends and followers, and only a few tweets created immediately
after account creation, only to remain completely silent afterwards.
This dataset B consists of over 500,000 accounts.
DeBot. Debot is a bot detection service that generates daily reports
of bot activity, and stems from the work of [10][9]. It comes with an
API which we were able to query to obtain over 700,000 accounts
that the service detected as bots. This dataset C is unique in our
list, as it is actually the result of a detection strategy, and not either
ground truth or a single botnet. The main feature that DeBot detec-
tion exploits is warped correlation in the tweet timing of dierent
accounts.
Fake Followers. We explore dierent fake follower datasets that
have been used in various research studies. Dataset D is used in [12]
and is just described as being fake followers. In contrast, datasets
Q-T are described in [11] as being purchased fake followers from
dierent fake follower services (Q) fastfollowerz, (S) intertwitter,
and (T) twittertechnology. All these datasets are used as ground
truth.
Traditional spambots. Datasets H and I are traditional spam
campaigns, pushing links to scam sites. Unfortunately the former
dataset was unavailable for collection, due to all but one of its
accounts being suspended. Datasets K and J are both groups of
accounts spamming job oers. All these datasets were used in [12],
while H was also used in [40].
Social spambots. Social spambots are a relatively new breed of
bots which are better described in [12]. In summary, Social spambots
have evolved to accurately mimic the characteristics of real users,
making them very dicult to identify. Dataset F are retweeters of
an Italian political candidate. Dataset E consists of spammers of
paid apps for mobile devices. Finally, dataset G is made of spammers
of products on sale at Amazon.com.
Honeypot bots. Dataset V consists of bots collected using honey-
pot accounts. A honeypot account is a fake account controlled by a
researcher. The interactions with the account are logged, assuming
they can only come from malicious accounts since the honeypot
account is fake and generally inactive. This dataset was made avail-
able through the DARPA twitter bot challenge [34]. It is used as
ground truth in that competition.
Journalist attack bots. In August 2017, journalists Brian Krebs
and Ben Nimmo were subject to an attack by twitter bots. They
logged some of the bots and published a dataset 1. We collected
the accounts from these two datasets and added them to our bot
datasets as datasets W (the attack on Brian Krebs) and X (the attack
on Ben Nimmo). These datasets are not used as ground truth and, to
the best of our knowledge, have not been used in research before.
Human Annotated Bots. Datasets L,M,N and O have been iden-
tied by humans as bots, and were used as ground truth in [21].
They were divided by the amount of followers that the bots have.
The bands in which they are divided are 900-1100 followers(L),
90k to 110k followers(M), 900k to 1m followers(N), and over 9m
followers(O). Noticeably, the intermediate groups with dierent
numbers of followers were not available for collection.
1https://krebsonsecurity.com/tag/twitter-bots/
139
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Juan Echeverrï£¡a et al.
BTS(%) BTS(Avg)
ID Name
Star Wars Bots
A
Bursty Bots
B
DeBot
C
Fake followers
D
Social spambots #1
E
Social spambots #2
F
Social spambots #3
G
Traditional spambots #1
H
Traditional spambots #2
I
Traditional spambots #3
J
Traditional spambots #4
K
⇠ 1k followers
L
M ⇠ 100K followers
⇠ 1M followers
N
⇠ 10M followers
O
Q