compatible with KLEE. For example, David avoided C code
that would generate certain LLVM “or” statements, since
these statements triggered excessive KLEE forking. David’s
and our own experiences with KLEE convinced us that we
needed a high-level way of expressing constraints that didn’t
force users to emulate a C compiler.
At the same time, checking LLVM IR by hacking directly
on SMT constraints—as we did in early versions of Sys—had
its own challenges. LLVM IR and SMT solvers have different
basic types (e.g., rich structs vs. simple bitvectors) and dif-
ferent correctness requirements. As an example of the latter,
the Boolector SMT solver’s [107] logical left shift operator
required the width of the second operand to be log2 of the
width of the ﬁrst operand; at the IR level, there is no such
restriction. Thus, in the middle of trying to write a checker,
we would forget the SMT requirement, use the shift, hard
crash the solver, add some width castings, get them wrong,
etc. In addition to accounting for SMT requirements like left
shift, our old approach required users to manually account
for LLVM’s requirements (e.g., by correctly padding their
own structs). We ran into similar problems using angr [131]
(e.g., solver crashes due to adding variables of incompatible
bitwidth), but with the addition of Python dynamic type er-
rors. After that, we wanted to express constraints in a way
that protected users from hand-translating IR into SMT.
3.3 Our solution: SysDSL
Sys clients use the SysDSL to write symbolic checkers like
the malloc checker in Section 2 (Figure 5). The DSL exposes
simple, safe LLVM-style operations that it automatically trans-
lates into Boolector SMT bitvector representations [43, 107].
In particular, with SysDSL, users can create symbolic vari-
ables and constants from LLVM ones; perform binary op-
1 translateAtomicrmw result rmwOp addr val = do
2
-- Get symbolic variable for LLVM operand addr
addrSym <- getOperand addr
valSym <- getOperand val
-- Get the LLVM operand val’s type
let operandType = typeOf val
-- Load value stored at symbolic addr in symbolic memory
oldValSym <- load addrSym operandType
-- Do the symbolic rmw operation with two symbolic vars
newValSym <- rmwOp oldValSym valSym
-- Store the symbolic result to symbolic memory at addr
store addrSym newValSym operandType
-- Assign the symbolic old value to be the result
assign result oldValSym
3
4
5
6
7
8
9
10
11
12
13
14
Figure 6: Implementation of the translateAtomicrmw LLVM instruction
in SysDSL.
erations, assignments, comparisons, and casts on these vari-
ables and constants; set and get ﬁelds in symbolic aggregate
structures; and, load and store to symbolic memory. We also
provide a library with symbolic operations like memcpy that
builds on top of the core primitives.
Though SysDSL is designed for writing checkers, we also
used it to implement every LLVM instruction that the sym-
bolic engine supports, guaranteeing that it’s powerful enough
to express whatever users want. As an example, we walk
through our implementation of an LLVM IR instruction to
show how the DSL works. The atomicrmw instruction in Fig-
ure 6 atomically updates memory using a given instruction
(e.g., addition). Given address addr and value val, the LLVM
atomicrmw instruction: (1) reads the value, oldValSym, at ad-
dress addr; (2) performs the given operation (e.g., addition)
with oldValSym and val; (3) writes the result back to addr;
(4) returns oldValSym.
First, and most importantly, SysDSL eliminates a whole
class of type and logic bugs that arise from operating on raw
SMT bitvectors. For example, if oldValSym and valSym (line
10) have different bitwidths, the SysDSL will exit with an
informative error. It also prevents more subtle type errors:
it lets us ignore the fact that addr would be a 32- or 64-bit
pointer, and that memory could be an array with blocks of
any size. If, say, addr is 32-bits in an LLVM ﬁle that speciﬁes
64-bit pointers, the SysDSL will exit with an error.
Second, SysDSL exposes functions that are polymorphic
over LLVM types to reﬂect LLVM’s polymorphism—e.g.,
that rmwOp (line 10) operates on all widths of integer and
vectors—and to simplify both the symex engine and checker
implementations. For example, val could be a vector or a
scalar of any width. Internally, the SysDSL handles the op-
eration accordingly—e.g., for vector vals it will automat-
ically decompose the vectors, un-pad the elements if they
are padded, add each pair of elements, re-pad the result, and
re-assemble the result vector. Doing this manually is both
cumbersome and error-prone.
SysDSL also automatically manages variable bindings,
mapping an LLVM variable to its corresponding SMT vari-
204    29th USENIX Security Symposium
USENIX Association
able. For example, the getOperand DSL function on line
three takes an LLVM operand as input and returns the sym-
bolic SMT bitvector representing that operand. Internally, this
function creates a new bitvector for the LLVM operand if one
has not already been created, and returns the existing bitvector
otherwise. Similarly, load and store always load from and
store to the most recent version of symbolic memory. Even
this seemingly simple task is error-prone when using SMT
libraries directly (since users must manually model scope,
loops, etc.).
Finally, SysDSL does not bind users’ hands: they can com-
pose existing operations to create their own custom opera-
tions; the atomicrmw LLVM instruction is one example of
how to compose new instructions out of SysDSL functions.
If, for some reason, users want direct access to our Boolector
SMT bindings, they can import them; since DSL and bindings
functions operate on the same constraint representation, they
can interoperate, too.
4 Memory design
Because memory modeling is one of the hardest parts of
symbolic checking, this section discusses how Sys models
memory. We use KLEE as a comparison point, since it: (1)
also focuses on bit-precise symbolic execution and (2) is
relatively well known [47] (e.g., it has its own workshop [23]).
Memory In order to perform queries on a memory location
in the checked program, a symbolic tool must map program
memory to a corresponding memory representation in its
constraint solver. The most natural approach (and what Sys
does) is to represent memory in the same way as most modern
hardware: as a single, ﬂat array.
In contrast, KLEE (and UC-KLEE) represents each object
as its own distinct, disjoint symbolic array (you can view this
as segmentation). This is because manually segregating arrays
lets the solver avoid reasoning about all reads and writes at
once; when KLEE was created, solvers had less sophisticated
optimization heuristics for arrays, so separate arrays were es-
sential for performance. If a pointer dereference *p == 0 can
point to N distinct symbolic objects, KLEE uses the constraint
solver to resolve each option, and fork the current path N
times to explore each one separately. This is because KLEE’s
solver requires that constraints refer to arrays by name, i.e.,
constraints cannot use “pointers” to arrays.
Sys can use a single ﬂat array for two reasons. First, modern
constraint solvers have much better support for arrays, and
second, Sys’s much smaller window size means that there are
simply many fewer memory accesses to handle. With a single
ﬂat array, every object’s address becomes an integer offset
from the base of the symbolic array. These offsets can be
concrete values or—crucially—fully symbolic expressions.
If we use array mem to represent memory and p to be a fully
symbolic expression, the query *p == 0 directly translates to
mem[p] = 0. By using ﬂat memory, Sys sidesteps enumerating
all of a pointer’s pointees—the SMT solver takes care of that.
A single ﬂat memory array makes translating code to con-
straints simple. Double-, triple-, quadruple- (or more) indirect
pointers take no special effort; ***p == 0 simply becomes
mem[mem[mem[p]]] = 0. Dereferences work naturally even
if naughty code casts pointers to integers and vice versa, or
mutilates them through combinations of bit-level hacks. In
contrast, just for double indirection, KLEE requires multiple
levels of forking resolution.
Shadow memory Flat memory also makes checking eas-
ier. Checking tools often need to associate metadata with
memory locations. Does a location contain a pointer? Is it
uninitialized? Is it deallocated? The wrong way to track this
information, for both dynamic and symbolic tools, is by using
a special “canary” value [82]. If checked code ever stores
the canary bit-pattern itself, the tool will ﬂag false positives,
and tracking small units like single bits is clearly infeasible.
The problem gets worse for underconstrained symbolic tools.
Consider an uninitialized memory checker that stores a canary
bit-pattern to all uninitialized pointers. This checker cannot
do queries asking if pointers may be uninitialized, since if
pointer p is initialized to point to fully-symbolic v, v can
equal the canary. Instead, the checker asks if pointers must
be uninitialized. This restriction goes a long way to defeating
the point of symbolic checking, since (among other issues),
the checker will miss all errors where a pointer could point to
both initialized and uninitialized locations.
The standard approach that dynamic tools like Val-
grind [106], Purify [82], and Eraser [123] take is to associate
each memory location m with a corresponding shadow mem-
ory location m(cid:48) that stores metadata about m. They can track
even the state of a single bit by setting its shadow location to
an integer value corresponding to “allocated,” “freed,” or “ini-
tialized.” To the best of our knowledge, UC-KLEE is the only
symbolic tool with shadow memory, and it was a 5–10KLOC
effort that no tool (that we know of) has since replicated.
Sys implements shadow memory as well—easily, in twenty
lines and an afternoon, because it represents memory as a
single ﬂat array. Shadow memory is separate, conﬁgurable
array. As a result, queries on shadow memory are almost
direct copies of queries on memory, perhaps with a scaling
adjustment. For example, if the user tracks a shadow bit for
each location, the expression *p maps to mem[p], and the
expression shadow[p/32] checks p’s shadow bit (assuming
32-bit pointers).
Drawbacks The ﬂat memory model has a number of draw-
backs, though: ﬁrst, it may be too slow for large window
sizes and full-program symbolic execution. Second, in a ﬂat
memory model, out-of-bounds memory accesses turn into
out-of-bounds accesses in symbolic memory. This means that
any memory corruption in the analyzed program becomes a
memory corruption in the analysis. This could be ﬁxed by
tracking a base and bound of each object in shadow memory,
and then preventing—but reporting—out-of-bounds accesses.
USENIX Association
29th USENIX Security Symposium    205
5 Using Sys to ﬁnd bugs
In this section, we evaluate Sys’s:
1. Expressiveness: can we use the SysDSL to express real,
diverse checkers and suppression heuristics?
2. Effectiveness: can we use Sys to ﬁnd new security bugs in
aggressively tested, huge codebases without sieving through
thousands of false positives?
We answer these questions by implementing three checkers
that look for two kinds of classic memory safety bugs—use
of uninitialized memory and out-of-bounds reads and writes—
in browser code, and one system-speciﬁc checker that ﬁnds
unvalidated use of untrusted user data in the FreeBSD kernel.
Workﬂow We built and debugged checkers on parts of
browser code (e.g., the Prio or Skia library) on our lap-
tops. For entire codebases, we ran Sys on a large ma-
chine: Intel Xeon Platinum 8160 (96 threads) with 1TB
of RAM, running Arch Linux (2/22/19). We check Fire-
fox changeset:commithash 503352:8a6afcb74cd9, Chrome
commit 0163ca1bd8da, and FreeBSD version 12.0-release.
We conﬁgured the checkers to run quickly enough that we
could debug problems easily: the uninitialized checker uses a
bound of 5 blocks, the out-of-bounds 15, and user input 20;
we set the solver timeout to 5 minutes. Chrome took longest
(under an hour for the out-of-bounds checkers and six hours
for the uninitialized memory checker) while FreeBSD was
quick (six minutes for user input). All symbolic checkers re-
ject ≥98% of statically proposed paths. We discuss block
bounds and timeouts further in Section 7.
Bug counting We only count unique bugs: if multiple re-
ports share the same root cause (e.g., an inlined function),
we only count a single bug. If the same bug occurs in both
browsers (e.g., [5]), we only count it once in the total tally. We
mark bugs as unknown if we were unable to map their LLVM
IR error message back to source (e.g., because of complicated
C++ inlining).
How good is the code we check? The main systems we
check—Chrome and Firefox—are some of the most aggres-
sively checked open-source codebases in the world. Both
browsers run bug bounty programs that reward security bug
reports [51, 103]. Mozilla’s program has paid over a million
dollars since 2004 [103], and Chrome’s most common bugs
yield $500− $15,000 [51].
Google runs a massive distributed fuzzer on Chrome 24/7
using over 25,000 machines [21] using three different dy-
namic sanitizers: AddressSanitizer (ASan) [55] (e.g., for
buffer overﬂows); MemorySanitizer (MSan) [56] (e.g., for
uninitialized memory); and UndeﬁnedBehaviorSanitizer (UB-
San) [57]. Chrome also encourages developers to write fuzz
targets for the their own components [102], and combined,
Google fuzzers and test cases reach 73% line coverage of
the entire browser [54]. Firefox has a whole team devoted
to fuzzing [125], and their JavaScript engine alone ran six
different fuzzers as of 2017 [88]. They direct developers to
use sanitizers [24] and Valgrind [106], and recently rolled
out the ASan Nightly project, where regular users browse the
web with ASan enabled—any error triggers an automatic bug
report, and any cash bounties are awarded to the user [67].
The browsers also use static tools. Chrome recommends
that developers run Clang’s core, C++, “Unix”, and dead code
checkers [52]. Firefox automatically runs static checkers on
every submitted patch [104]. These include: (1) Mozilla-
speciﬁc checkers; (2) Clang-tidy lints; and (3) traditional
Clang static checkers. Firefox also runs the Infer static an-
alyzer [15] alongside their Coverity scans (integrated in
2006) [20], which resulted in many thousands of bug ﬁxes.
How good are the bugs we ﬁnd? Our checkers focus on
low-level errors like uninitialized memory and buffer over-
ﬂows because these are the same bugs that almost every tool
we mention in this section detects—so ﬁnding these bugs is
a better test for Sys than ﬁnding errors that other tools have
never tried to ﬁnd. The bugs are also not just new introduc-
tions to the codebase. We looked at how long each bountied
bug existed, because those seem like the ones other people are
most incentivized to ﬁnd. The Prio bugs have existed since
Prio’s introduction last year (§5.1), the SQLite pattern has
existed for at least nine years (§5.2), and the Opus codec bug
has existed for three and a half years (§5.3).
5.1 Uninitialized memory
This section describes our uninitialized memory checker. We
start with this error type because it is arguably the most heavily
picked-over of any bug type (more even than buffer overﬂows).
The results in Figure 7 show that Sys is effective—it ﬁnds
21 errors—and we describe how the checker works and its
results below.
5.1.1 How the checker works
Static extension: a simple, somewhat conservative pass that
marks potential uses of uninitialized stack variables. For each
stack allocation s, the extension performs a ﬂow-sensitive
pass over all subsequent paths. If there is no obvious store
to s, the extension marks the ﬁrst load of s as potentially
uninitialized. The extension does not track pointer offsets,
instead considering every new offset as a new tracked location.
Symbolic checker: uses Sys’s shadow memory (§ 4) to detect
uses of uninitialized memory, similar to concrete tools like
Valgrind [106] and Purify [82]—with the advantage that it
can reason about many possible locations at once (e.g., all