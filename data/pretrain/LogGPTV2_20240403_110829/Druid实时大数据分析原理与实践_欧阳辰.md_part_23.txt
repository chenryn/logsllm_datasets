"timestampSpec":{
"column": "timestamp",
"format":
"dimensions": []
"value"
"timestamp"
"auto"
是
否
是否必需
是
是
183
---
## Page 208
184
consumerProperties
topic
属性
tionTimeout
handoffCondi-
Exceptions
reportParse-
Persists
maxPending-
PersistPeriod
intermediate-
Segment
maxRowsPer-
Memory
maxRowsIn-
task
属性
KafkaSupervisorIOConfig配置详解如下：
KafkaTuningConfig详解如下：
Integer
Boolean
Integer
Integer
String
Period
ISO
类型
Integer
Map
String
类型
8601
为毫秒
继续执行
在解析过程中发生异常后，
中间持久化的发生频率
Segment单个分片中的条数，注意是
果
为
当持
聚
InMemory x(2 + maxPendingPersists))
确保有足够大的堆内存：（maxRows-
入的原始数据集大小。调整该值，要
条数。这是聚合以后的条数，不是摄
持
索引任务的类型，必须是“kafka”
等
人
解释
待
true,
会阻
合以后的
久化之前内存增量索引中的最大
PORT_2.,..
表，格式为BROKER_1:PORT_1,BROKER_2:
bootstrap.servers属性，它是Kafka Broker的列
传给KafkaConsumer的属性Map。它至少包含
从Kafka中读取数据的Topic
解释
Segment
false,
久
2
塞
化的
0
意味表
会抛出异
直
数
条数。
移交的超时时间，单位
会
着永远
丢弃解析异常的数据
当前执行的持久化完
常并挂起摄人；如
超出了创建新的分
该值
等待
后
如果该值
数据摄
Druid实时大数据分析原理与实践
否（默认值：0）
否（默认值：false）
有的持久化都可以并发执
否（默认值为0，意味着所
否
否（默认值：5000000）
行，
否（默认值：75000）
是
是否必需
（默认值：PT10M）
而不需要排队等待）
是
否
是否必需
---
## Page 209
第7章
RejectionPeriod
lateMessage-
completionTimeout
useEarliestOffset
period
startDelay
taskDuration
taskCount
replicas
属性
高级功能和特性
Period
ISO8601
Period
ISO
Boolean
Period
ISO8601
Period
ISO8601
Period
ISO
Integer
Integer
类型
8601
8601
lateMessageRejectionPeriod),
如果消息的时间戳早于（任务的开始时间
可能永远不会发布
的超时时间，如果该值设为较小值，Segment有
任务进入发布状态到发布成功，然后任务退出
反之，使用largest，从最新开始读取
还没有保存Ofset，则从Kafka中获取Offset，如
在 Supervisor初始执行时，假设元数据存储中
则可能小于该值
所以这只是最大时间间隔，如果处理上述事件
务的成功、失败以及检查是否达到持续时间，
要注意的是，它同时负责处理其他事件，如任
Supervisor定时执行管理逻辑的时间间隔，
Supervisor管理任务之前的延迟
以及被历史节点加载以后任务才算完成
状态的时间长度，Segment 推送到深度存储中
任务从开始执行到终止读取进入 Segment发布
果
小于taskCount
任务处理多个Partition；反之，任务的数量会
果taskCount
返回当前活跃的Supervisor列表。
GET/druid/indexer/vl/supervisor
调用该接口，Supervisor会立即停止，同时使其管理的所有任务终止读取，进人Segment
获取其管理的所有任务的状态报告。
POST/druid/indexer/v1/supervisor//shutdown
使用该接口可以无缝衔接地处理Schema变更。
·使用Request 请求体内的规范创建一个新的 Supervisor，它会接管处于发布状态的任
·退出正在执行的Supervisor。
·正在运行的 Supervisor会通知其管理的所有任务终止读取并执行Segment发布。
POST/druid/indexer/v1/supervisor
务，以及创建新的任务从处于发布状态的任务的结束Offset处开始读取数据。
创建Supervisor
Supervisor API
获取Supervisor的状态报告
获取当前执行的Supervisor
Druid实时大数据分析原理与实践
---
## Page 211
储数据库中。
7.7.2
会有多个发布状态的任务，这种情况在发布执行的时间（生成Segment、推送到深度存储
态的任务并发运行，所以需要的最小容量为：workerCapacity=2×replicas×taskCount。
的任务总数为replicas×taskCount，但也有例外的情况，例如taskCount大于Partition的数量
超出容量限制以后，Kafka索引任务在队列中等待，直到有可用的Worker。这样有可能导致
7.7.1
7.7
7.6.7
7.6.6
taskDuration调整为足够长，给发布执行充足的时间。
中，以及等待被历史节点加载）大于taskDuration时出现。为了减少容量的使用，最好将
态以后，又会有replicas×taskCount数量的新任务创建，因此要保障处于读取状态和发布状
{numKafkaPartitions}，在这种情况下只需要{numKafkaPartitions}个任务。当任务处于发布状
始Offset的数据）。
查询时部分结果延迟，但不会导致数据丢失（假设在任务执行之前，Kafka不会清理任务起
享使用，例如实时任务、合并任务等。所以在规划容量时，需要考虑所有的索引任务。如果
限制。在生产实践中，需要保障有充足的Worker容量。Worker容量会被所有类型的任务共
第7章
处于读取状态的任务数量由taskCount 和replicas来控制。一般情况下，处于读取状态
Kafka索引任务运行在中间管理者上，因此其容量的使用上限受中间管理者集群规模的
当Supervisor规范通过POST/druid/indexer/v1/supervisor提交以后，会存储到元数据存
获取指定Supervisor的历史规范列表。
获取所有Supervisor的历史规范列表，包括当前使用的。
GET/druid/indexer/v1/supervisor/history
一个读取状态的任务对应一个发布状态的任务，这是非常理想的状态。在有些情况下
容量规划
最佳实践
获取Supervisor的历史
获取所有Supervisor的历史
高级功能和特性
Supervisor的持久化
---
## Page 212
据摄人。
索引服务也是对当前时间窗口模式和Kafka限制的一些突破，帮助实现更加可靠、灵活的数
的，特别是用于独立访问用户的计算，可以采用HyperLogLog或DataSketch的方法。Kafka
7.8
需要等待，实现无缝变更。
人发布状态，然后创建新的任务继续从处于发布状态的结束Ofset处读取数据，这样可以不
设存在正在运行的 Supervisor，则会将其停止，同时使其管理的所有任务结束读取状态，进
7.7.3
同都会导致不兼容，Supervisor会杀掉这样的任务，同时创建新的任务集合。
的任务，如果任务和 Supervisor规范兼容，它就接管这个任务。摄人规范和Partion分配不
据存储数据库中的每个Supervisor规范派生创建一个Supervisor。Supervisor会探索正在运行
188
当 Schema或者配置变更以后，只需要重新提交新的 Supervisor规范创建Supervisor，
本章介绍了Druid的几个高级功能，其中直方图和DataSketch在应用中还是比较常见
当Overlord成为Leader以后，无论是初始执行还是其他Overlord失败，它都会为元数
小结
Schema的配置与变更
Druid实时大数据分析原理与实践
---
## Page 213
mvn clean package
cd druid
git clone PI:EMAIL:druid-io/druid.git
议使用JDK8版本，因为社区开始讨论关于逐渐取消Java7的支持。Maven需要版本3以上。
8.1
0.9.1版本，已经特别注明。
解Druid的优势和局限性。
据结构还保持相对稳定，查询过程的变化也较少。了解这些数据结构和原理，可以更好地理
查询语句的底层实现，最后简单介绍Coordinator的实现原理。
包括Column、Index和Segment等，还包括数据装载和持久化的基本流程，而后讨论Druid
本章以 Druid 0.9版本为基础，介绍Druid的一些底层设计理念，也有部分代码来自于
Druid的社区非常活跃，项目也处于高速发展阶段，代码不断持续优化，但是基本的数
、本章介绍Druid的代码结构，以及如何编译项目。重点分析Druid的最基础数据结构，
编译之后，发布文件将位于distribution/target/druid-VERSION-bin.tar.gz。
配置好JDK和Maven之后，通过以下命令就可以下载和编译Druid项目了。
Druid项目需要有两个依赖软件：一个是JDK；另一个是Maven。JDK需要版本7以上，建
如何编译Druid代码
核心源代码探析
---
## Page 214
8.2
190
api
services
indexing-service
server
processing
核心项目
项目目录
这些项目简单介绍如下：
通过Intellij引人Druid的项目列表如图8-1所示。
Druid项目介绍
对外访问接口，解析各种访问
构建物理服务，包括命令行解析
索引服务，需要接收各种请求
组合各种功能类，形成服务
内部数据结构和处理
功能
druid
 DruidindividoalCLA.pdf
DruidCorporateCLApdf
CONTRIBUTING.md
Csenvices [druid-services]
server [druid-server]
pubications
processing [druid-processing]