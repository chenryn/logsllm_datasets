### 5. The SecureFL Framework

In this section, we present the SecureFL framework, which adapts the proposed crypto-friendly Federated Learning (FL) protocol (Algorithm 1) to a privacy-preserving context. At a high level, each participant locally trains their model and normalizes the gradient before sending it to the Service Provider (SP). Simultaneously, the SP trains the current global model on a seed dataset to obtain the server gradient and preprocesses the heavy matrix multiplication. After receiving the local gradients from all selected participants, the SP and the Cryptographic Server (CS) engage in two-party computation (2PC) to securely evaluate the robust aggregation protocol using several customized cryptographic protocols. The complete SecureFL protocol is detailed in Table 2.

#### 5.1 Detailed SecureFL Framework

Before formally presenting our framework, we introduce some notations. We denote the SP's and CS's shares of the normalized local gradient as \(\langle \nabla_i \rangle_0\) and \(\langle \nabla_i \rangle_1\), respectively. The servers' rearranged share matrices are denoted as \(\langle R \rangle_0 = (\langle \nabla_1 \rangle_0, \langle \nabla_2 \rangle_0, \ldots, \langle \nabla_n \rangle_0)^T\) and \(\langle R \rangle_1 = (\langle \nabla_1 \rangle_1, \langle \nabla_2 \rangle_1, \ldots, \langle \nabla_n \rangle_1)^T\), respectively. Note that \(R = (\nabla_1, \nabla_2, \ldots, \nabla_n)^T\). We then focus on the robust aggregation process.

**Algorithm 1: Crypto-friendly Byzantine-robust FL Protocol**

**Input:**
- Each participant \(P_i\), \(i \in [n]\), with a local dataset \(D_i\)
- SP with a seed dataset \(D_s\)
- Learning rate \(\eta\)
- Batch size \(b\)
- Number of training iterations \(Iter\)

**Training at the Participant Side (Parallel):**
```python
for i in [n]:
    \(\nabla_i = \text{SGD}(\omega, D_i, b)\)  # \(P_i\) computes the local gradient.
    Submit \(\nabla_i \leftarrow \frac{\nabla_i}{\|\nabla_i\|}\) to SP  # Local normalization.
```

**Training at the Server Side:**
```python
\nabla_s = \text{SGD}(\omega, D_s)  # SP computes the server gradient.
\nabla_s \leftarrow \frac{\nabla_s}{\|\nabla_s\|}  # Normalization.
```

**Robust Aggregation:**
```python
for i in [n]:
    flagnabla_i = 1_{\{|\langle \nabla_i, \nabla_i \rangle - 1| < \epsilon\}}
```
- **SP and CS run the DReLU procedure (Algorithm 2) to evaluate \(flagnabla_i = 1_{\{|\langle \nabla_i, \nabla_i \rangle - 1| < \epsilon\}}\).** After this, SP holds \(\langle flagnabla_i \rangle_B^0\) and CS holds \(\langle flagnabla_i \rangle_B^1\).

**Algorithm 2: The DReLU Protocol**

**Input:**
- SP and CS hold \(\langle x \rangle_0\) and \(\langle x \rangle_1\), respectively.
- FMill and FAND are adopted from [40] (more details in Appendix C).

**Output:**
- SP and CS get \(\langle \text{DReLU}(x) \rangle_0\) and \(\langle \text{DReLU}(x) \rangle_1\).

**Steps:**
1. SP and CS invoke an instance of FMill, where SP's input is \((p - 1 - \langle x \rangle_0)\) and CS's input is \(\langle x \rangle_1\). After this, SP and CS learn \(\langle \text{DReLU}(x) \rangle_0\) and \(\langle \text{DReLU}(x) \rangle_1\).

This structured and detailed approach ensures that the SecureFL framework is both secure and efficient, leveraging advanced cryptographic techniques to protect the privacy of the participants while maintaining the robustness of the federated learning process.