### 2. Detection Results of Different Machine Learning Algorithms

The following table summarizes the detection results of various machine learning algorithms on a labeled dataset. The analysis indicates that one-class SVM achieves the highest true positive rate (TPR) with a very low false positive rate (FPR).

| Algorithm | TPR | FPR |
|-----------|-----|-----|
| k-NN      | 94.2% | 0.71% |
| LOF       | 91.2% | 5.3%  |
| CBLOF     | 92.7% | 3.2%  |
| LDCOF     | 92.3% | 1.9%  |
| One-Class SVM | 94.2% | 0.71% |

**Table 2: Detection results of different machine learning algorithms on the labeled dataset.**

Based on this empirical analysis, we selected one-class SVM as our default machine learning algorithm for the rest of the paper.

### 5.2.1 Determining the Novelty Score

In the model testing process, USBESAFE applies the trained decision function to determine whether an input observation falls within the trained class or outside it. An observation is considered novel if the decision function assigns it to the -1 class, indicating that the input is outside the trained region. The novelty score is calculated as the ratio of inputs classified as novel observations over the total number of input observations.

We conducted an experiment using four different kernel functions to train the one-class SVM (see Appendix A) to determine the appropriate threshold for the novelty score. Our analysis showed that the system produced less than 1% false positives when the threshold value was set to 13.2% for all four kernel functions. In Section 5.3, we describe how we enhanced the detection model by empirically identifying specific parameters for the kernel functions.

### 5.3 Optimizing the Model

To improve the detection model, we explored the impact of changing the configuration parameters on the same labeled dataset. After constructing possible n-grams (see Section 3.1.2), we performed a grid search over the parameter space, which included:
1. One-class SVM model parameters (e.g., polynomial degree).
2. N-gram window size.
3. Combinations of detection features.

We generated 6,510 unique one-class SVM model instances based on 105 model parameter settings, 5 features, and n-grams with a window size of 2 (see Table 6 in Appendix A). To test the accuracy of these models against BadUSB attacks, we created a set of attacks using a Rubber Ducky USB drive [2]. These attacks were designed to perform covert HID attacks, such as opening a command prompt and executing malicious code or connecting to a remote server.

For each one-class SVM test, we logged the parameter setting used to generate the model, calculated the average accuracy across all 4-fold cross-validations, and removed any model instance with a false positive rate greater than 4.0%. Our analysis shows that USBESAFE achieves the highest TP and FP rates (TP rate 95.7% at 0.21% FPs) when one-class SVM uses the polynomial kernel with degree 3, γ = 0.1, and ν = 0.75, incorporating all the features defined in Section 3.1.

**Table 3: Detection results of USBESAFE on different machines.**

| Machine   | No. of Traces | TPs | FPs |
|-----------|---------------|-----|-----|
| Machine1  | 124           | 97.4% | 0.16% |
| Machine2  | 90            | 95.6% | 0.23% |
| Machine3  | 101           | 96.7% | 0.15% |
| Machine4  | 50            | 94.0% | 0.31% |
| Machine5  | 58            | 94.3% | 0.28% |
| Per User Model (avg) | 423 | 95.7% | 0.21% |
| General Model | 423 | 94.9% | 0.93% |

Our analysis shows that per-user models are more effective in terms of producing lower false positive cases.

### 5.3.1 Feature Set Analysis

We also conducted an experiment to measure the contribution of the proposed features by testing the model with labeled datasets from all five machines and calculating the average TP and FP rates. We used a recursive feature elimination (RFE) approach on the labeled dataset, dividing the feature set into three categories:
1. Type-based features (transfer and event type of packets, F1).
2. Time-based features (interarrival and post-enumeration time of packets, F2).
3. Content-based feature (payload of packets, F3).

The procedure started by incorporating all feature categories and measuring the FP and TP rates. In each step, the feature set with the minimum weight was removed, and the FP and TP rates were recalculated using 4-fold cross-validation to quantify the contribution of each feature.

**Table 4: True positive and false positive rates for different combinations of features.**

| Feature Sets | FPs | TPs |
|--------------|-----|-----|
| F1           | 43.4% | 54.7% |
| F2           | 14%   | 78%   |
| F3           | 16%   | 69%   |
| F12          | 2.2%  | 86.3% |
| F13          | 5.6%  | 65%   |
| F23          | 1.8%  | 94%   |
| All Features | 0.21% | 95.7% |

The results show that USBESAFE achieves the highest accuracy by incorporating all the features. When all features are combined, USBESAFE achieves a 0.21% FP rate with 95.7% TPs on the labeled dataset. Using a larger window size (n = 3) can achieve 100% TPs but results in higher false positives. Therefore, we decided to use a window size of n = 2.

### 5.3.2 Modeling the USB Traffic Pattern

To understand how URB arrivals can be modeled, we tested whether they follow a Poisson distribution. Prior work has shown that user-generated traffic arrivals, such as Telnet, can be well-modeled as Poisson distributions [18]. We randomly selected 100 traces from the labeled dataset and tested whether the URB arrivals follow exponentially distributed and independent interarrivals, the two requirements for a Poisson distribution.

**Figure 2: Statistical analysis on 100 randomly selected traces.**

The x-axis represents the percentage of intervals in the traces that follow exponentially distributed interarrivals, and the y-axis represents the percentage of intervals that follow independent interarrivals. We used the Anderson-Darling test [1] to verify the exponential distribution and Durbin-Watson statistics [29] to test for autocorrelation among URBs. The results show that more than 95% of the intervals pass the test, indicating that URB arrivals can be well-modeled by Poisson arrivals. This finding is used to generate mimicry attacks and test the system's ability to detect attacks that follow Poisson arrivals (see Appendix B).

### 5.3.3 Determining the Effect of Pause Time

To address the issue of unbounded interarrival time values between consecutive USB packets, we defined two configuration parameters: pause time and session. A session is a series of USB packets where the interarrival time within the series does not exceed a specified pause length. We performed experiments to determine the impact of the pause time value.

**Figure 3: The effect of pause time value on payload histogram.**

The figures show localized modality occurring approximately every 4,000 ms with large spikes. The results revealed minimal information payload differences among the pause time values, indicating that the chosen value is not consequential to overall model performance. For this reason, we set the pause to our lowest value of 20,000 ms.

(a) Payload histogram on a 20,000 ms pause with bin intervals of 200 ms.
(b) Payload histogram on a 40,000 ms pause with bin intervals of 200 ms.
(c) Payload histogram on a 60,000 ms pause with bin intervals of 200 ms.

These experiments help us understand the impact of different pause times on the payload histograms and ensure that the chosen pause time is optimal for the model.