k-NN
TPR
FPR
94.2%
0.71%
90.6%
11.3%
LOF
91.2
5.3%
CBLOF
LDCOF
92.7%
3.2%
92.3%
1.9%
Table 2: The detection results of different machine learning
algorithms on the labeled dataset. The analyses show that
one-class SVM achieves the highest TPs with a very low FP
rate on the same dataset.
observations. Based on this empirical analysis, we used the
one-class SVM as our default machine learning algorithm for
the rest of the paper.
5.2.1 Determining the Novelty Score
In the model testing process, USBESAFE applies the trained
decision function to determine whether an input observation
falls within the trained class or outside the trained class. We
consider a URB as a novel observation, if the decision function
assigns the input to the -1 class. In fact, the assigned value -1
implies that the input observation is outside the trained region.
The novelty score is calculated as the ratio of inputs classiﬁed
as novel observations over the total number of input observa-
tions. We ran an experiment by incorporating four different
kernel functions to train the one-class SVM (see Appendix
A), and understand what novelty score should be selected as
the threshold at which we decide whether the observation is
novel or not. Our analysis shows that the system produced
less than 1% false positives when the threshold value = 13.2%
was selected for all the four different kernel functions in the
one-class SVM algorithm. In Section 5.3, we describe how
we enhanced the detection model by empirically identifying
a speciﬁc set of parameters for the kernel functions.
5.3 Optimizing the Model
Another question that we wanted to answer was whether
we can improve the detection model by changing the re-
quired conﬁguration parameters of the model on the same
labeled dataset. After constructing possible n-grams (see Sec-
tion 3.1.2), we performed a grid search [31] over the parameter
space which consists of: (1) the one-class SVM model param-
eters (e.g., the polynomial degree), (2) the n-gram window
size, and (3) the combinations of detection features.
Based on the resulting parameter space with 105 model
parameter settings, 5 features and n-grams with window size
2 (see Table 6 in Appendix A), we generated 6,510 unique
one-class SVM model instances. To test the accuracy of the
models against BadUSB attacks, we created a set of attacks
using a Rubber Ducky USB drive [2]. The attacks were de-
signed to perform covert HID attacks which open a command
prompt and execute a malicious code, or connect to a remote
server. We elaborate on the malicious dataset later in Sec-
tion 5. For each individual one-class SVM test, we logged the
parameter setting used to generate the model, calculated the
average accuracy across all the 4-fold cross validations, and
Machine
Machine1
Machine2
Machine3
Machine4
Machine5
Per User Model (avg)
General Model
No. of Traces
TPs
FPs
124
90
101
50
58
423
423
97.4%
95.6%
96.7%
94.0%
94.3%
0.16%
0.23%
0.15%
0.31%
0.28%
95.7%
0.21%
94.9%
0.93%
Table 3: The detection results of USBESAFE on different machines.
In this experiment, we used one-class SVM with the polynomial
kernel with degree 3, γ = 0.1 and ν = 0.75 using all the features.
Our analysis shows that per user model is more effective in terms of
producing lower false positive cases.
their corresponding standard deviations. We removed a model
instance from our search space if the false positive rate of
the model was more han 4.0%. Our assumption was that it is
very unlikely that an end-point solution with a false positive
rate more than 4.0% would be useful to be deployed on user
machines. Our analysis shows that USBESAFE achieves the
highest TP and FP rates (TP rate 95.7% at 0.21% FPs) when
one-class SVM uses the polynomial kernel with degree 3,
γ = 0.1 and ν = 0.75 using all the features deﬁned in Sec-
tion 3.1. Table 3 shows the True Positives (TPs) and False
Positives (FPs) for each user machine based on the derived
model. The results show that it is possible to achieve even
a higher detection rate at a lower false positive rate on the
same dataset by tuning the detection model and incorporating
appropriate conﬁguration parameters.
A question that arises is whether a general multi-user model
can achieve the same level of detection accuracy when being
used on several machines. To test this, we incorporated all
the 423 traces in the learning process and tested the detection
results of USBESAFE. We observed that the general model,
unsurprisingly, produced a higher false positive rate on the
labeled dataset. Table 3 summaries the detection accuracy of
USBESAFE in the per user and multi-user scenarios. While
the general model achieved a lower detection rate with a
higher false positive rate, we observed that it can be deployed
temporarily on new machines while the per user model is in
the training phase. We provide more details on the real-world
deployment of USBESAFE in Section 6.
5.3.1 Feature Set Analysis
We also performed an experiment to measure the contribu-
tion of the proposed features by testing the model with the
labeled datasets collected from all the ﬁve machines, and cal-
culating the average of TPs and FPs. To this end, we used a
recursive feature elimination (RFE) approach on the labeled
dataset. We divided the feature set into three different cate-
gories: Type-based features which are transfer and event type
of packets (F1), Time-based features which are interarrival
and post-enumeration time of the packets (F2), and Content-
based feature which is the payload of the packets (F3). The
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 95procedure started by incorporating all the feature categories
while measuring the FP and TP rates. Then, in each step, a
feature set with the minimum weight was removed, and the
FP and TP rates were calculated by performing 4-fold cross-
validation to quantify the contribution of each feature in the
proposed feature set. Table 4 provides the details of feature
set evaluation using One-class SVM with the conﬁguration
parameters we tested in Section 5.3.
Our experiments show that the highest false positive rate is
43.4% and is produced when USBESAFE only incorporates
type-based features. When time-based and content-based fea-
tures were used together, USBESAFE achieved (1.8% FP with
94% TP). F23 resulted in higher detection rate as USBESAFE
was able to detect evasive scenarios where we intentionally
imposed an artiﬁcial delay, similar to stalling code in mal-
ware attacks, before launching a command injection attack.
When all the features were combined, USBESAFE achieved
(0.21% FP with 95.7% TPs) on labeled dataset. Note that if
USBESAFE uses a larger window size (n = 3), it is possible to
achieve 100% TPs. However, it results in higher false positive
cases as the number of suspicious sequence of USB packets
also increases. Therefore, as a design decision, we decided
to use the window size (n = 2). We provide more details in
Section 5. The results clearly imply that USBESAFE achieves
the highest accuracy by incorporating all the features.
Feature Sets
FPs
TPs
F1
F2
F3
F12
F13
F23
All Features
43.4%
14%
16%
2.2%
5.6%
1.8%
54.7%
78%
69%
86.3%
65%
94%
0.21%
95.7%
Table 4: The true positive and false positive rate for different com-
binations of features. The analysis shows that USBESAFE achieves
the best results by incorporating all the features.
We performed another experiment to rank the relative con-
tribution of each feature. We ﬁrst incorporated all the features,
and measured the FP and TP rates. Then, in each step, we
removed the feature with the minimum weight, and calculated
the FP and TP rates to quantify the contribution of each fea-
ture. Table 5 shows the results by ranking all the features with
the most signiﬁcant one at the top. For easier interpretation,
we calculated the score ratio by dividing the score value of
each feature with the most signiﬁcant score value. The ratio of
each feature simply tells how much the corresponding feature
can contribute to identify novel observations.
5.3.2 Modeling the USB Trafﬁc Pattern
A question that arises here is how URB arrivals can be mod-
eled. This is an important question as we want to test the
possibility of developing mimicry attacks where an adversary
can bypass the proposed detection mechanism. For example,
an attacker can create BadUSB attacks that generate URBs
Rank
Category
Feature
Type
Score Ratio
1
2
3
4
5
Time
Content
Time
Type
Type
Packet Interarrival Times
Packet Payload
Post-enumeration Time
Event Type
Transfer Type
Continuous
Ordinal
Continuous
Categorical
Categorical
100%
83.2%
35.6%
14.4%
12.1%
Table 5: The rank of each feature in USBESAFE to detect
novel observations.
which are similar to a normal user typing pattern. Prior work
revealed that user-generated trafﬁc arrivals such as Telnet can
be well modeled as Poisson distribution [18]. To test whether
the URB arrivals follow Poisson distribution, we ran a simple
statistical methodology where we tested whether the URB
arrivals follow exponentially distributed and independent in-
terarrivals – the two requirements for Poisson distribution.
To this end, we randomly selected 100 traces from the la-
beled dataset. Figure 2 represents the results of the analysis.
The x-axis represents the percentage of the intervals in the
traces that follow exponentially distributed interarrivals and
the y-axis represents the percentage of the intervals that fol-
low independent interarrivals. We used Anderson – Darling
test [1] to verify whether the interarrivals follow an exponen-
tial distribution. To test the interarrivals for independence, one
simple way is to check whether there is signiﬁcant autocorre-
lation among URB arrivals in a given time lag. To this end, we
used Durbin – Watson statistics [29] to test the autocorrelation
among URBs. As shown in the ﬁgure, more than 95% of the
intervals pass the test showing that the URB arrivals are truly
Poisson. We use this ﬁnding to generate mimicry attacks and
test whether the system can detect attacks that follow Poisson
arrivals (see Appendix B).
Figure 2: The result of statistical analysis on 100 randomly selected
traces. Our analysis shows that the URB arrivals can be well modeled
by Poisson arrivals.
5.3.3 Determining the Effect of Pause Time
As mentioned in Section 3.1, to tackle the issue of the un-
bounded interarrival time value between two consequent USB
707580859095100Exponential Distribution (%)707580859095100Uncorrolated Arrivals (%)Randomly Selected Traces96          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationMore speciﬁcally, when a raw interarrival time value i was
greater than the pause time, we reset i to 0, thereby starting a
new session.
We observed some common patterns by generating payload
histograms while varying pause values and interval lengths.
An interesting observation for the HID trafﬁc was that, re-
gardless of the pause time value, a localized modality occurs
approximately every 4000 ms, or 4 seconds, with large spikes
in the number of packets transmitted during these times. Ulti-
mately, the results of this experiment revealed that there was
minimal information payload differences among the pause
time values used, indicating that the value we chose is not
consequential to overall model performance. For this reason,
we set the pause to our lowest value of 20,000 ms. Figure 3
shows the details of this experiment.
(a) Payload histogram on a 20,000 ms pause
with bin intervals of 200 ms.
(b) Payload histogram on a 40,000 ms pause
with bin intervals of 200 ms.
(c) Payload histogram on a 60,000 ms pause
with bin intervals of 200 ms.
Figure 3: The effect of pause time value on payload histogram. The
ﬁgures show localized modality occurs approximately every 4,000
ms with large spikes.
packets, we deﬁned two conﬁguration parameters: pause time
and session. A session is a series of USB packets where the
interarrival time value within the series does not exceed a
speciﬁed pause length. To determine the impact of pause time
value, we performed a set of experiments. The experiments
had multiple goals: (1) to empirically characterize the dis-