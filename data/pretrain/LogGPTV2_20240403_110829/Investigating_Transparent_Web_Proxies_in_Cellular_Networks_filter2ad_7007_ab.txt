(cid:2)
AT&T T-Mobile Verizon Sprint
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
Investigating Transparent Web Proxies in Cellular Networks
267
the server port number. We use port 80 to elicit proxy behavior and port 7777
to bypass the proxy.
To characterize proxy behavior, we parameterize our experiments along mul-
tiple dimensions. We vary the server port, to control proxy interference. We
analyze traﬃc observed when accessing diﬀerent destinations, using both static
IPs and DNS names resolvable by our controlled DNS server. We also experi-
ment with multiple content types, ﬂow sizes, packet delay and loss through traﬃc
shaping, and investigate the eﬀect of diﬀerent HTTP header conﬁgurations.
4.1 Caching
Behavior. If a client receives an HTTP response without the request reaching
the server, we conclude that the carrier caches content. We use unique resources
hosted only on our server to ensure that content can only be delivered by our
server or a cache. We observe content caching for T-Mobile and Sprint. They
cache most Web objects (e.g., CSS, JavaScript, JPEG, PNG, GIF, and TXT)
but they do not cache HTML ﬁles. Both carriers cache at per-device and per-
session granularity. That is, the cache is not shared between users and gets
purged whenever the device releases its IP address. We conjecture the reason
of doing this is to not cache private or dynamic contents. We observe objects
remaining cached for a consistent period of time (≈5 min for Sprint, ≈30 min for
T-Mobile) across diﬀerent times of day.
Impact. Object fetch time can decrease since the content is closer to the client.
Figure 1 shows the measured fetch time for cached and non-cached objects, and
the impact of network latency. From top to bottom, the boxes describe 90th,
75th, 50th, 25th and 10th percentiles (same for subsequent ﬁgures). If the cellular
link dominates end-to-end latency we observe no noticeable performance gain
when accessing cached resources. However, in environments with larger wired
latencies (we demonstrate this by introducing delays for outgoing packets on
the server side), we see fetch time improvements for small ﬁles (10 KB). For
larger ﬁles (500 KB), TCP throughput is bottlenecked by the carrier capacity,
preventing caching beneﬁts. In addition to faster serving time, caching can reduce
a carrier’s inbound traﬃc, especially if the carrier segments are lossy.
4.2 Redirection
Behavior. Some proxies redirect traﬃc based on an independent DNS resolution
of the Host header ﬁeld of an HTTP request, ignoring the destination IP in the
packet sent by the client. To test for this, we send an HTTP request to our
Web server IP (i.e., no client-side DNS resolution required) but provide a third-
party domain name in the Host ﬁeld, which triggers an error if handled by our
server. If the proxy uses redirection, the request does not reach our server, yet the
referenced website renders at the client side. Only T-Mobile elicits this behavior.
We conﬁrm it for all of the Alexa top 100 websites.
268
X. Xu et al.
Impact. We cannot be certain, but this feature could be for traﬃc engineering
considerations, e.g., the carrier can control the destination for HTTP traﬃc at
the proxy instead of relying on devices. In doing so, any server IP mapping based
on client-selected DNS servers is silently and transparently overridden by this
feature.
4.3 Object Rewriting
Behavior. In this case a proxy modiﬁes ﬁle contents, for example to improve
performance through mechanisms like whitespace trimming, or image transcod-
ing to reduce the load on the cellular segment. For a variety of Web ﬁle types and
content patterns, we compared the payloads transmitted by the server with the
contents received by the mobile devices to detect this feature. We only observe
compression of image ﬁles, and only with Sprint up to an original ﬁle size of
500 KB (see Fig. 2). We conjecture that the reason of not transcoding large
images is to avoid this receiving latency as well as transcoding latency. For
text ﬁles, we did not observe any trimming of whitespace or comments.
Impact. Compressed ﬁles can be fetched faster, as shown in Fig. 3. But, aggres-
sive compression can distort images in ways that are unacceptable to the content
provider or user [6]. Further, the proxy must fetch the whole image and transcode
it before beginning to forward to the client.
4.4 Connection Persistence
Behavior. Proxies can persist connections to both endpoints. For the server-
side segment, some proxies remove a client’s connection: close directive in
the HTTP header (used to inform the server to close the connection upon query
response), or add a connection: keep-alive entry. To persist the client-proxy
connection, some proxies drop the server’s TCP FIN packet. We ﬁnd that AT&T
and Sprint proxies keep the connection to the HTTP server alive after each
request completes. The keepalive time is ∼10 s for AT&T, and ∼30 s for Sprint.
AT&T, Sprint and T-Mobile drop the TCP FIN from the server to persist the
client-proxy connection.
Impact. The advantages of this strategy are that persistent connections avoid
the delays that new per-object connections would incur from TCP handshakes
and slow start. Reusing a connection can also minimize overhead on NAT table
mappings at the edge of the carrier network.
4.5 Delayed Handshaking
Observation. Finally, we conﬁrm that proxies in each carrier delay the initial
handshake between themselves and a server until receiving the HTTP request.
Proxies wait for HTTP request because information from HTTP request helps
caching feature determine whether there is cached version of the request; it also
Investigating Transparent Web Proxies in Cellular Networks
269
helps redirecting feature to ﬁgure out the IP destination. Figure 4 illustrates
this behavior. We artiﬁcially delay the query which proportionally increases the
server-side reception delay for the handshake packet.
Impact. Deferred handshakes can delay end-to-end communication, especially
for modern browsers that open a connection early in anticipation of a later query,
to avoid incurring the handshake overhead when the query occurs.
5 Split Connection Performance
Intuitively, split TCP connections should oﬀer better client-perceived perfor-
mance (i.e., faster downloads) than direct connections if the proxy is on the
same path. First, splitting the connection reduces the RTTs between connected
endpoints, which allows TCP to grow its congestion window faster. Second, it
isolates the throughput impact of loss events to an individual segment, and it
speeds loss detection and recovery [13,21,25].
In practice, splitting TCP connections oﬀers beneﬁts that depend on the size
of the ﬂow and the relative performance of the split path segments. For short
ﬂows, it is unclear if split connections always result in better client-perceived
performance. Likewise, for cases where the cellular segment is substantially worse
than the wired segment, reducing RTT and loss have little impact on the fetch
time for Web objects.
This section uses controlled experiments to understand the performance
impact of split connections for a Web server we host, for alternative network con-
ditions between the server and proxy, and for realistic Web browser workloads.
We ﬁnd that the performance impact varies across carriers, network conditions,
or Web sites.
While our experiments cannot be used to compare performance across carri-
ers (since we cannot create identical conditions across them), we can get valuable
insights into the conditions under which split-connections do and do not work
well, and understand how these insights generalize across carriers. Results from
T-Mobile are qualitatively similar to AT&T, and Sprint results are similar to
Verizon, so we omit AT&T and Verizon. For full results, see our tech report [28].
(a) T-Mobile
(b) Sprint
Fig. 5. Fetching times for diﬀerent ﬁle sizes.
270
X. Xu et al.
Baseline Performance. For each carrier, we fetch objects with diﬀerent sizes
using split and non-split connections. Figure 5(b) shows there is no signiﬁcant
performance diﬀerence for Sprint for any ﬁle size. In contrast, Fig. 5(a) shows
that for T-Mobile, proxied downloads of larger objects ﬁnish much earlier (in the
1 MB case, 30 % faster in the median). T-Mobile has much better performance
than Sprint, because Sprint has much worse link quality where we conducted
our experiments. When we make performance statements about a carrier, say
Sprint, that is shorthand for “the performance seen by the mobile device in our
testbed connected to the Sprint network”, not a blanket statement about the
carrier’s overall performance.
To understand the reasons for diﬀerent performance beneﬁts, we analyze
the network properties of the cellular and wired path segments. First, we use
traces from the server to ﬁnd that the wired segments (server to proxy) for
all four carriers have similar characteristics in terms of latency and bandwidth.
For Sprint and Verizon, the limited bandwidth of their cellular segments is the
main performance bottleneck, thus limiting the eﬃcacy of split connections.
In contrast, AT&T and T-Mobile oﬀer more bandwidth, so transfers beneﬁt
from split connections, since shorter latencies enable faster ramp-up of TCP’s
congestion window.
Interestingly, the TCP congestion window on the server side ramps up slowly
in AT&T and T-Mobile due to TCP’s Hybrid Start feature used by default in
the Linux CUBIC congestion control mechanism [17,18]. The RTT and ACK
patterns inﬂuenced by the cellular segment result in an early transition to the
congestion avoidance phase to prevent heavy losses. Since the connection is
sender-limited and never reaches the channel capacity, splitting connections can
help to tune features like this for the two path segments independently.
(a) T-Mobile
(b) Sprint
Fig. 6. Fetching times for diﬀerent ﬁle sizes, with varying amounts of delay added.
Impact of Varying Network Conditions. We repeat the experiments above,
but emulate high latency wired path segments by having our server introduce
50–200 ms delay on each packet it sends. Figure 6 plots the impact on fetch
times for various ﬁle sizes, comparing proxied and unproxied traﬃc. Split con-
nections improve performance in AT&T’s and T-Mobile’s case for larger ﬁles
Investigating Transparent Web Proxies in Cellular Networks
271
and delays (e.g., 1 MB and 200 ms delay); we do not observe statistically signiﬁ-
cant changes with Sprint and Verizon. Performance improvements are similar for
AT&T, Sprint, and Verizon when introducing correlated loss on the wired seg-
ment. Interestingly, T-Mobile’s performance for proxied traﬃc is independent of
loss rate in our experiments, because the proxy maintains a large-enough buﬀer
to compensate for the reduced throughput during loss.
Overall, these experiments show that split connections are most impactful in
environments where the cellular segment is not the dominant factor with respect
to end-to-end performance. Thus, carriers with better cellular links beneﬁt most.
Web Browsing. We now move from characterizing performance for isolated
object fetches to realistic workloads generated by a browser accessing popu-
lar Web sites. Since we cannot bypass the proxy when accessing Web servers,
we resort to hosting Web site replicas on our server. For this, we fetch the
original URLs including all embedded resources, even if they are delivered by
third parties. We use a diﬀerent IP alias for each Web host. We then mea-
sure the round-trip time to each real Web host and induce per-alias delay at
our server to approximate the communication patterns between the phone and
the real hosts. We host three qualitatively diﬀerent types of sites: a news site
(18 objects), a search engine (14 objects), and an image-bound site (8 objects
with 2 large images). We introduce 3 % packet loss on the server side to investi-
gate the impact of congestion. Also, we simulate follow-up visits, by fetching the
news site, waiting 10 s, then fetching a link on the page. Thus, proxies that per-
sist connections and cache static content can potentially improve performance
compared to bypassed traﬃc.
(a) T-Mobile
(b) Sprint
Fig. 7. Fetching times for three Web site types (in loss-free and lossy environments).
Figure 7 shows the Web browsing results. With introduced loss, split con-
nections generally outperform their unproxied counterparts, with up to 30 %
lower completion times in the median. The proxy absorbs losses, thus keep-
ing performance comparable to a loss-free environment. The proxy buﬀer ben-
eﬁts for T-Mobile mentioned earlier are evident in this experiment as well.
Caching does not provide signiﬁcant gains on T-Mobile or Sprint in our tests.
In contrast, Sprint’s image compression drastically reduces fetch times on the
272
X. Xu et al.
image-bound site. Finally, we ﬁnd that T-Mobile and AT&T’s persistent con-
nections can improve performance by ∼10 % for follow-up visits (not shown).
6 On the Prevalence of Proxying
The experiments above tell us how a cellular proxy interacts with ﬂows to our
Web site, but do not necessarily inform how the proxies interact with other,
popular sites. For example, a carrier and content provider may have a special
agreement to bypass proxies for certain content, or the content provider’s servers
may be oﬀ-path from the proxy. The methodology in the previous sections does
not help here because it requires access to the mobile device and server; for
popular sites we have access to the former only.
To understand proxying prevalence for commonly accessed servers, we study
how many of the 100 most popular websites [1] are proxied. We have no visibility
at the server end, so we use a ﬁngerprint analysis technique to identify split TCP
connections and determine if the carriers proxy all, some, or none of the sites.