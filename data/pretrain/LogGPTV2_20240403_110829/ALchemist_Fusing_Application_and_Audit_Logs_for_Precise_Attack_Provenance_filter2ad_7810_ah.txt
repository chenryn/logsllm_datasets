cal system information and prevents adversaries from utilizing
host resources.
Application logs have been studied in recent years. Ghoshal
et al. [27] utilize a rule speciﬁcation to generate structured
provenance events by processing application log. The pro-
posed approach, however, only focuses on application logs
without considering system logs or log fusion. The exper-
iments were only conducted on 5 simple applications. The
provenance system designed by Chen et al. [20] uses a graph
recorder, which extracts provenance for applications written
in a speciﬁc declarative language or instrumented in source
code. ALchemist does not require any speciﬁc language or
instrumentation.
VIII. CONCLUSION
We propose a novel forensics technique ALchemist. It
leverages that built-in application logs and audit
log are
complementary and in the mean time share a lot of common
elements, which can be utilized for log fusion. A set of parsers
are developed to parse various kinds of logs to their canonical
representations. Datalog based fusion rules are applied to bind
these logs and more importantly, to derive new information that
is invisible from either kind of the logs. Our evaluation shows
that ALchemist is highly effective in partitioning execution to
units and producing precise attack provenance graphs, without
requiring any instrumentation. It also outperforms state-of-the-
art techniques with and without instrumentation.
ACKNOWLEDGMENT
We thank our shepherd, Daphne Yao, and those anonymous
reviewers for their comments and suggestions. This research
was supported, in part by NSF 1901242 and 1910300, ONR
N000141712045, N000141410468 and N000141712947, and
Sandia Lab MOD1-18046142. Any opinions, ﬁndings, and
conclusions in this paper are those of the authors only and
do not necessarily reﬂect the views of our sponsors.
REFERENCES
[1]
[2]
[3]
[4]
[5]
[6]
“50 essential linux applications,” https://tinyurl.com/wcj5og2.
“Alchemist2020/workload,” https://github.com/ALchemist2020/Workload.
“Apache http server benchmarking tool,” https://tinyurl.com/onkcat3.
“Apt groups,” https://tinyurl.com/y2tqt74o.
“Clickjacking,” https://tinyurl.com/62thhvp.
“darpa-i2o/transparent-computing: Darpa transparent computing pro-
gram,” https://github.com/darpa-i2o/Transparent-Computing.
16
[7]
[8]
[9]
“Datalog,” https://tinyurl.com/cam64up.
“Elasticsearch,” https://tinyurl.com/y3uv7342.
“jordansissel/xdotool: fake keyboard/mouse input, window manage-
ment, and more,” https://github.com/jordansissel/xdotool.
“Kernel path protection,” https://tinyurl.com/7ttl5h2.
“Nspr log modules,” https://tinyurl.com/gmlmtnz.
“Same-origin policy,” https://tinyurl.com/pp86n9a.
“Splunk,” https://www.splunk.com.
“Sysdig,” https://tinyurl.com/nzrexz5.
[10]
[11]
[12]
[13]
[14]
[15] S. T. Ali, V. Sivaraman, D. Ostry, G. Tsudik, and S. Jha, “Securing
ﬁrst-hop data provenance for bodyworn devices using wireless link
ﬁngerprints,” IEEE Transactions on Information Forensics and Security,
vol. 9, no. 12, pp. 2193–2204, 2014.
[16] S. Avizheh, T. T. Doan, X. Liu, and R. Safavi-Naini, “A secure event
logging system for smart homes,” in Proceedings of the 2017 Workshop
on Internet of Things Security and Privacy, 2017, pp. 37–42.
[17] M. Backes, S. Bugiel, and S. Gerling, “Scippa: system-centric ipc
provenance on android,” in Proceedings of the 30th Annual Computer
Security Applications Conference. ACM, 2014, pp. 36–45.
[18] A. Bates, D. J. Tian, K. R. Butler, and T. Moyer, “Trustworthy whole-
system provenance for the linux kernel,” in 24th USENIX Security
Symposium (USENIX Security 15), 2015, pp. 319–334.
[19] A. M. Bates, D. Tian, K. R. Butler, and T. Moyer, “Trustworthy
whole-system provenance for the linux kernel,” in USENIX Security
Symposium, 2015, pp. 319–334.
[20] A. Chen, Y. Wu, A. Haeberlen, B. T. Loo, and W. Zhou, “Data
provenance at internet scale: Architecture, experiences, and the road
ahead,” in Proceedings of 8th Biennial Conference on Innovative Data
Systems Research (CIDR), 2017.
[21] C. Collberg, A. Gibson, S. Martin, N. Shinde, A. Herzberg, and
H. Shulman, “Provenance of exposure: Identifying sources of leaked
documents,” in 2013 IEEE Conference on Communications and Net-
work Security (CNS), 2013, pp. 367–368.
[22] M. Du, F. Li, G. Zheng, and V. Srikumar, “Deeplog: Anomaly detection
and diagnosis from system logs through deep learning,” in Proceedings
of the 2017 ACM SIGSAC Conference on Computer and Communica-
tions Security, 2017, pp. 1285–1298.
[23] T. Dumitras and I. Neamtiu, “Experimental challenges in cyber security:
A story of provenance and lineage for malware.” in Proceedings of 4th
Workshop on Cyber Security Experimentation and Test (CSET), 2011.
[24] P. Gao, X. Xiao, D. Li, Z. Li, K. Jee, Z. Wu, C. H. Kim, S. R.
Kulkarni, and P. Mittal, “{SAQL}: A stream-based query system
for real-time abnormal system behavior detection,” in 27th USENIX
Security Symposium (USENIX Security 18), 2018, pp. 639–656.
[25] P. Gao, X. Xiao, Z. Li, F. Xu, S. R. Kulkarni, and P. Mittal, “{AIQL}:
Enabling efﬁcient attack investigation from system monitoring data,” in
2018 {USENIX} Annual Technical Conference ({USENIX}{ATC} 18),
2018, pp. 113–126.
[26] Y. Gao, S. Huang, and A. Parameswaran, “Navigating the data lake
with datamaran: Automatically extracting structure from log datasets,”
in Proceedings of the 2018 International Conference on Management
of Data, 2018, pp. 943–958.
[27] D. Ghoshal and B. Plale, “Provenance from log ﬁles: a bigdata prob-
lem,” in Proceedings of the Joint EDBT/ICDT 2013 Workshops, 2013,
pp. 290–297.
[28] A. Goel, K. Po, K. Farhadi, Z. Li, and E. De Lara, “The taser intrusion
recovery system,” in ACM SIGOPS Operating Systems Review, vol. 39,
no. 5, 2005, pp. 163–176.
[29] Z. Guo, H. Lin, M. Yang, D. Zhou, F. Long, C. Deng, C. Liu, and
L. Zhou, “G2: A graph processing system for diagnosing distributed
systems,” 2011.
[30] R. Hasan, R. Sion, and M. Winslett, “The case of the fake picasso:
Preventing history forgery with secure provenance.” in FAST, vol. 9,
2009, pp. 1–14.
[31] W. U. Hassan, S. Guo, D. Li, Z. Chen, K. Jee, Z. Li, and A. Bates,
“Nodoze: Combatting threat alert fatigue with automated provenance
triage.” in NDSS, 2019.
[32] W. U. Hassan, M. Lemay, N. Aguse, A. Bates, and T. Moyer, “Towards
scalable cluster auditing through grammatical inference over provenance
graphs,” in Network and Distributed Systems Security Symposium, 2018.
[33] W. U. Hassan, M. A. Noureddine, P. Datta, and A. Bates, “Omegalog:
High-ﬁdelity attack investigation via transparent multi-layer log analy-
sis,” in NDSS, 2020.
[34] P. He, J. Zhu, S. He, J. Li, and M. R. Lyu, “Towards automated
log parsing for large-scale log data analysis,” IEEE Transactions on
Dependable and Secure Computing, vol. 15, no. 6, pp. 931–944, 2017.
[35] M. N. Hossain, S. M. Milajerdi, J. Wang, B. Eshete, R. Gjomemo,
R. Sekar, S. D. Stoller, and V. Venkatakrishnan, “Sleuth: Real-time
attack scenario reconstruction from cots audit data,” in Proc. USENIX
Secur., 2017, pp. 487–504.
[36] Y. Ji, S. Lee, M. Fazzini, J. Allen, E. Downing, T. Kim, A. Orso, and
W. Lee, “Enabling reﬁnable cross-host attack investigation with efﬁcient
data ﬂow tagging and tracking,” in 27th USENIX Security Symposium
(USENIX Security 18), 2018, pp. 1705–1722.
[37] Y. Ji, S. Lee, and W. Lee, “Recprov: Towards provenance-aware user
space record and replay,” in International Provenance and Annotation
Workshop, 2016, pp. 3–15.
[38] H. Jordan, B. Scholz, and P. Suboti´c, “Soufﬂ´e: On synthesis of program
analyzers,” in International Conference on Computer Aided Veriﬁcation,
2016, pp. 422–430.
[39] V. P. Kemerlis, G. Portokalidis, K. Jee, and A. D. Keromytis, “libdft:
Practical dynamic data ﬂow tracking for commodity systems,” in Acm
Sigplan Notices, vol. 47, no. 7, 2012, pp. 121–132.
[40] T. Kim, X. Wang, N. Zeldovich, and M. F. Kaashoek, “Intrusion
recovery using selective re-execution,” 2010.
[41] S. T. King and P. M. Chen, “Backtracking intrusions,” ACM SIGOPS
Operating Systems Review, vol. 37, no. 5, pp. 223–236, 2003.
[42] S. T. King, Z. M. Mao, D. G. Lucchetti, and P. M. Chen, “Enriching
intrusion alerts through multi-host causality.” in NDSS, 2005.
[43] Y. Kwon, F. Wang, W. Wang, K. H. Lee, W.-C. Lee, S. Ma, X. Zhang,
D. Xu, S. Jha, G. Ciocarlie et al., “Mci: Modeling-based causality
inference in audit logging for attack investigation,” in Proceedings of
the 25th Network and Distributed System Security Symposium (NDSS).
The Internet Society, San Diego, California, USA, 2018.
[44] K. H. Lee, X. Zhang, and D. Xu, “Loggc: garbage collecting audit log,”
in Proceedings of the 2013 ACM SIGSAC conference on Computer &
communications security, 2013, pp. 1005–1016.
[45] ——, “High accuracy attack provenance via binary-based execution
partition.” in NDSS, 2013.
[46] B. Li, “Enabling ﬁne-grained reconstruction and analysis of web attacks
with in-browser recording systems,” Ph.D. dissertation, uga, 2017.
[47] Q. Lin, H. Zhang, J.-G. Lou, Y. Zhang, and X. Chen, “Log clustering
based problem identiﬁcation for online service systems,” in Proceedings
of the 38th International Conference on Software Engineering Compan-
ion, 2016, pp. 102–111.
[48] F. Liu, Y. Wen, D. Zhang, X. Jiang, X. Xing, and D. Meng, “Log2vec:
A heterogeneous graph embedding based approach for detecting cyber
threats within enterprise,” in Proceedings of the 2019 ACM SIGSAC
Conference on Computer and Communications Security, 2019, pp.
1777–1794.
[49] Y. Liu, M. Zhang, D. Li, K. Jee, Z. Li, Z. Wu, J. Rhee, and P. Mittal,
“Towards a timely causality analysis for enterprise security,” in Proceed-
ings of the 25th Network and Distributed System Security Symposium
(NDSS). The Internet Society, San Diego, California, USA, 2018.
[50] D. Ma, “Practical forward secure sequential aggregate signatures,” in
Proceedings of the 2008 ACM symposium on Information, computer
and communications security. ACM, 2008, pp. 341–352.
[51] D. Ma and G. Tsudik, “Forward-secure sequential aggregate authen-
tication,” in 2007 IEEE Symposium on Security and Privacy (SP’07),
2007, pp. 86–91.
[52] S. Ma, K. H. Lee, C. H. Kim, J. Rhee, X. Zhang, and D. Xu, “Accurate,
low cost and instrumentation-free security audit logging for windows,”
in Proceedings of the 31st Annual Computer Security Applications
Conference, 2015, pp. 401–410.
[53] S. Ma, J. Zhai, F. Wang, K. H. Lee, X. Zhang, and D. Xu, “Mpi: Mul-
tiple perspective attack investigation with semantics aware execution
partitioning,” in USENIX Security, 2017.
[54] S. Ma, X. Zhang, and D. Xu, “Protracer: Towards practical provenance
tracing by alternating between logging and tainting.” in NDSS, 2016.
[55] P. McDaniel, “Data provenance and security,” IEEE Security & Privacy,
vol. 9, no. 2, pp. 83–85, 2011.
[56] S. M. Milajerdi, R. Gjomemo, B. Eshete, R. Sekar, and V. Venkatakrish-
nan, “Holmes: real-time apt detection through correlation of suspicious
information ﬂows,” arXiv preprint arXiv:1810.01594, 2018.
[57] K.-K. Muniswamy-Reddy, D. A. Holland, U. Braun, and M. I. Seltzer,
“Provenance-aware storage systems.” in USENIX Annual Technical
Conference, General Track, 2006, pp. 43–56.
[58] M. Nagappan, K. Wu, and M. A. Vouk, “Efﬁciently extracting opera-
tional proﬁles from execution logs using sufﬁx arrays,” in 2009 20th
International Symposium on Software Reliability Engineering, 2009, pp.
41–50.
[59] K. Nagaraj, C. Killian, and J. Neville, “Structured comparative analysis
of systems logs to diagnose performance problems,” in Proceedings
of
the 9th USENIX conference on Networked Systems Design and
Implementation, 2012, pp. 26–26.
[60] A. Oprea, Z. Li, T.-F. Yen, S. H. Chin, and S. Alrwais, “Detection
of early-stage enterprise infection by mining large-scale log data,” in
2015 45th Annual IEEE/IFIP International Conference on Dependable
Systems and Networks, 2015, pp. 45–56.
[61] T. Pasquier, X. Han, T. Moyer, A. Bates, O. Hermant, D. Eyers, J. Ba-
con, and M. Seltzer, “Runtime analysis of whole-system provenance,”
in Proceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security, 2018, pp. 1601–1616.
[62] D. J. Pohly, S. McLaughlin, P. McDaniel, and K. Butler, “Hi-ﬁ:
collecting high-ﬁdelity whole-system provenance,” in Proceedings of
the 28th Annual Computer Security Applications Conference, 2012, pp.
259–268.
[63] A. Ramachandran, K. Bhandankar, M. B. Tariq, and N. Feamster,
“Packets with provenance,” Georgia Institute of Technology, Tech. Rep.,
2008.
[64] A. Ramachandran and M. Kantarcioglu, “Smartprovenance: a dis-
tributed, blockchain based dataprovenance system,” in Proceedings of
the Eighth ACM Conference on Data and Application Security and
Privacy, 2018, pp. 35–42.
[65] M. Stamatogiannakis, E. Athanasopoulos, H. Bos, and P. Groth, “Prov
2r: practical provenance analysis of unstructured processes,” ACM
Transactions on Internet Technology (TOIT), vol. 17, no. 4, p. 37, 2017.
[66] S. Thaler, V. Menkonvski, and M. Petkovic, “Towards a neural language
model for signature extraction from forensic logs,” in 2017 5th Inter-
national Symposium on Digital Forensic and Security (ISDFS), 2017,
pp. 1–6.
[67] Y. Xie, D. Feng, Z. Tan, L. Chen, K.-K. Muniswamy-Reddy, Y. Li, and
D. D. Long, “A hybrid approach for efﬁcient provenance storage,” in
Proceedings of the 21st ACM international conference on Information
and knowledge management, 2012, pp. 1752–1756.
[68] Y. Xie, K.-K. Muniswamy-Reddy, D. D. Long, A. Amer, D. Feng, and
Z. Tan, “Compressing provenance graphs.” in TaPP, 2011.
[69] K. Xu, H. Xiong, C. Wu, D. Stefan, and D. Yao, “Data-provenance
veriﬁcation for secure hosts,” IEEE Transactions on Dependable and
Secure Computing, vol. 9, no. 2, pp. 173–183, 2011.
[70] W. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, “Detecting
large-scale system problems by mining console logs,” in Proceedings
of the ACM SIGOPS 22nd symposium on Operating systems principles,
2009, pp. 117–132.
[71] Z. Xu, Z. Wu, Z. Li, K. Jee, J. Rhee, X. Xiao, F. Xu, H. Wang, and
G. Jiang, “High ﬁdelity data reduction for big data security dependency
analyses,” in Proceedings of the 2016 ACM SIGSAC Conference on
Computer and Communications Security, 2016, pp. 504–516.
[72] C. Yang, G. Yang, A. Gehani, V. Yegneswaran, D. Tariq, and G. Gu,
“Using provenance patterns to vet sensitive behaviors in android apps,”
in International Conference on Security and Privacy in Communication
Systems, 2015, pp. 58–77.
[73] R. Yang, S. Ma, H. Xu, X. Zhang, and Y. Chen, “Uiscope: Accurate,
instrumentation-free, deterministic and visible attack investigation,” in
NDSS, 2020.
17
[74] A. A. Yavuz, P. Ning, and M. K. Reiter, “Efﬁcient, compromise resilient
and append-only cryptographic schemes for secure audit logging,” in
International Conference on Financial Cryptography and Data Security,
2012, pp. 148–163.
[75] A. A. Yavuz and P. Ning, “Baf: An efﬁcient publicly veriﬁable secure
audit logging scheme for distributed systems,” in 2009 Annual Com-
puter Security Applications Conference, 2009, pp. 219–228.
[76] T.-F. Yen, A. Oprea, K. Onarlioglu, T. Leetham, W. Robertson, A. Juels,
and E. Kirda, “Beehive: Large-scale log analysis for detecting suspi-
cious activity in enterprise networks,” in Proceedings of the 29th Annual
Computer Security Applications Conference, 2013, pp. 199–208.
[77] H. Zhang, D. D. Yao, and N. Ramakrishnan, “Detection of stealthy
malware activities with trafﬁc causality and scalable triggering relation
discovery,” in Proceedings of the 9th ACM symposium on Information,
computer and communications security, 2014, pp. 39–50.
[78] H. Zhang, D. D. Yao, N. Ramakrishnan, and Z. Zhang, “Causality rea-
soning about network events for detecting stealthy malware activities,”
computers & security, vol. 58, pp. 180–198, 2016.
J. Zhu, S. He, J. Liu, P. He, Q. Xie, Z. Zheng, and M. R. Lyu, “Tools
and benchmarks for automated log parsing,” in 2019 IEEE/ACM 41st
International Conference on Software Engineering: Software Engineer-
ing in Practice (ICSE-SEIP), 2019, pp. 121–130.
[79]
[80] N. Zhu and T.-c. Chiueh, “Design, implementation, and evaluation of
repairable ﬁle service,” in 2003 International Conference on Depend-
able Systems and Networks (DSN), 2003, p. 217.
APPENDIX
A. Stability Study of Application Built-in Logging Modules
We study the stability of application built-in logging mod-
ules. The results are shown in Table IX. Column 1 presents
the name for the logging facilities. Note that the same logging
facility may be used by multiple applications. The second
column shows the applications. Column 3 shows the number
of regular expressions we implemented to parse the log.
Columns 4-5 present the two versions whose built-in logs are
compared. Column 6 indicates the new log types added (in
the new version) and column 7 presents the number of regular
expressions we have to change, that is, the log types are the
same but the formats are changed. Observe that most of them
are fairly stable. Even for ﬁrefox that has gone through major
code change, the logging module has only small changes.
B. Study of Top 30 Linux Application Built-in Logging
We study 32 Linux applications, including 30 most popular
applications listed in [1] and 15 complex applications widely
used in the APT attack literature. We want to analyze their
execution models and check if these applications have built-
in logging module and if their logs contain information to
disclose the underlying execution model, especially implicit/-
explicit unit boundaries, which are the most critical informa-
tion for execution partitioning. Here, implicit boundaries mean
that they can be inferred by log fusion. Column 1 shows the
applications. Column 2 presents if the application has built-in
logging facility. Column 3 presents the execution unit structure
for the application. Column 4 shows if the application log
contains information to separate different units. Column 5
shows the execution model(discussed in Section III) used by
the application. From the table, 28 out of 32 applications are