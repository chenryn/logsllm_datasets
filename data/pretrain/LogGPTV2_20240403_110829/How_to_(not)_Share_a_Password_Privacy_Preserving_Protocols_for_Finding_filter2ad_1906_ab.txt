One work that combines a privacy-preserving statistics collection scheme robust against ma-
licious manipulation is that of Mani and Sherr [MS17]. They also proposed a histogram-based
privacy-preserving statistics collection scheme robust against malicious manipulation in the con-
text of a Tor network. However, their communication complexity is linear in the number of bins,
compared to logarithmic in our protocol (for our example of 216 bins they require 122 MB per client
instead of 2 MB in our case). They also required non-colluding mix servers for privacy, while in our
protocol the user does not need to trust anyone.
Schechter et al. [SHM10] proposed a method (data structure) to securely publish a list of popular
passwords, with similar motivation to ours. However, they require users to reveal their passwords
to the server and do not oﬀer DP for the user upon password publication.
1.6 Paper Structure
Section 2 describes the security deﬁnitions and requirements. Section 3 explains the basic scheme,
the usage of DP to protect the device, and the possible attacks on the system and required secure
functionality in the malicious setting. Section 4 discusses how the server generates the list of popular
hash values and proves the correctness of our scheme.
The next two (sections 5 and 6) describe two diﬀerent methods for securely computing the
required functionality in the malicious setting, based on garbled circuits, and the assumption on
the intractability of quadratic residuosity (QR), respectively. The garbled circuit solution is more
eﬃcient both in run time and in bandwidth. On the other hand, it requires an interactive protocol.
The QR based protocol demands more resources but has a non-interactive version.
Section 7 describes a PoC implementation of the QR-based protocol and simulation results of
learning popular passwords. Section 9 discusses the results and raises open questions. Appendix A
has a summary of frequently asked questions about the scheme.
6
2 Overview of Security Deﬁnitions
We start with describing a password security game (Section 2.1) that is used to properly deﬁne the
privacy requirement regarding password protection (Section 2.2) and then go on with correctness
requirements (Section 2.3).
2.1 The Password Security Game
There are two main parameters for a password guessing attack: one is L, the number of trials
that the attacker is allowed to make. This number might be restricted either by computational
power (e.g. brute-forcing a hashed password list) or by the number of allowed trials (e.g. an online
account might be locked after 3 login attempts with a wrong password). The other parameter is γ,
the probability of success.
The password security game: To analyze the eﬀect that the proposed heavy hitters gathering
system has on password security we consider the password security game PGame(L): we think
of an attacker A that has some info about the system. Its move against a user (device) D is to
publish a list of L words which are the attacker’s guesses of the password of D. If the password is
one of the L words then the attacker wins. The attacker wishes L to be as small as possible and
the probability of winning to be as large as possible.
Our deﬁnition of privacy will say that the attacker does not gain much in terms of the parameters
of the attack as a result of witnessing the execution of the system.
Length/success probability trade-oﬀ: In general, there is a trade-oﬀ between the length L
and the probability of success γ: if an attacker A can win PGame(L) with probability γ, then for
any 0 ≤ ρ ≤ 1 there is an attacker A(cid:48) with the same information who can win PGame(ρL) with
probability ρ · γ. This is true, since A(cid:48) can imitate A and then simply sample ρL of the words in
the list. If the list contains the password (which happens with probability γ), then the probability
of successfully sampling it is ρ.
The eﬀect of releasing one bit: Given any a priori information about the password, releasing
a single bit function (even one chosen adversarially) about the password can increase the success
probability by a factor of at most 2 (which is equivalent to making the list twice as long). More
formally, for any Boolean function f , and for any attacker A that has some information about the
system and also obtains f (password ), and then plays PGame(L), there exists attacker A(cid:48) that
receives the same information about the system but not the value of f (password ) and has at least
the same probability of success in PGame(2L) (where the attacker generates a list that is twice as
long). The argument is simple: run A twice, with the two possibilities for the value of f (password ),
and then concatenate the resulting lists.
Note that this sort of protection on its own might not be suﬃcient wrt system-wide consid-
erations. In particular, the problem is that the adversary may decide on whom to prey after the
fact, namely after the information is gathered and some leakage occurred. Consider the case where
for each user there 10 possible passwords and the adversary guesses at random for each user a
candidate password c and a single bit function fc that isolates c from the rest of the bunch (this
could even be a linear function). Now for each user, after receiving fc(password) the adversary
learns whether the candidate c is correct or not. For roughly 1/10th of the users, the adversary
learns the password and can win the game PGame(1) with probability 1, without leaving a trace
of this wrt the rest of the users. As we shall see, this is addressed by diﬀerential privacy (DP).
7
Diﬀerential privacy: An important issue is the relationship between the password security game
and DP. Consider an adversary A that obtained -diﬀerentially private information regarding a
password, and compare its probability of success to that of A(cid:48) that did not receive this information
at all. Then for any list length L, the success probability of A in PGame(L) is at most e times the
probability of A(cid:48) in PGame(L). This follows from the immunity to post-processing of diﬀerential
privacy. This holds similarly to (, δ)−DP, where δ should be added to the probability of success.
Looking at the above example of picking which devices to attack after the protocol, we see that
the posteriori property of diﬀerential privacy prevents this case: the adversary cannot choose a
bunch of users where he will win the password game PGame(L) with much higher probability. I.e.
if the adversary received -DP information about many passwords, whenever the adversary chooses
a device to attack the probability of success is at most e times the probability of success of A(cid:48).
2.2 Privacy and Password Security
The privacy requirements are that the chances of an adversary in winning the above Password
Game with regards to a device (i.e. its password) do not increase by much if the individual de-
vice participates in the protocol (or participates with a fake-password). This should remain true
against an adversary controlling a coalition of devices. Furthermore, this should remain true even
a posteriori, that is when the adversary decides which devices to attack following the execution of
the protocol3.
We consider an adversary A that has a lot of power: it chooses a collection of distributions
of passwords for the devices, witnesses the protocol (in the sense that it sees the communication
with the devices and perhaps controls a subset of them) and then chooses one of the devices (not
under its control) as the challenge device, receives the passwords of the remaining devices and
participates in a Password Guessing game against the challenge device with parameter L. We want
to say that this A does not succeed in the game much better than a player that did not participate
in the protocol. We deﬁne the requirement by two parameters a and b related to whether the server
cooperates with the adversary or not (these parameters should ideally be very close to 1).
Coalition without the server: For any adversary A as above, controlling a coalition of devices
that does not include the server and after the execution of the protocol choosing another device as
a challenge in the password game PGame(L) (and receiving the passwords of all other devices)
there exists an A(cid:48) that simply gets the passwords of all the devices except for that of the challenge
device, but does not witness the execution of the protocol, so that A’s probability of winning the
game is at most a multiplicative factor a larger compared to that of A(cid:48).
Coalition with the server: When the server joins the coalition (and may even behave maliciously
in the protocol) then the probability of winning the game PGame(L) against the chosen device
increases by at most a multiplicative factor of b compared to that of A(cid:48) that simply gets the
passwords of all the devices except the challenge device but does not witness the execution of the
protocol.
3 So, for instance, a scheme where some devices are sampled and full information about their passwords is given
would be very bad in this respect.
8
2.3 Correctness Requirement
The correctness requirement is deﬁned via the functionality of a trusted third party (TTP). The
functionality is probabilistic and receives passwords one by one and at the end of the process releases
the list of heavy hitters. Functionality 1 describes the desired functionality in terms of correctness.
The parameters of the system are τ , the threshold, and δ, an allowed tolerance. The TTP should
return the correct label of the heavy hitter even in the presence of a malicious coalition of devices.
Namely, for parameters τ and δ, the protocol must ensure that passwords with a frequency of at
least τ (1 + δ) are added to the heavy hitters list, whereas passwords with a frequency of less than
τ (1− δ) are not added to this list (where τ, δ, τ (1 + δ) ∈ (0, 1)). There are also tolerable parameters
for the probabilities of false negatives pF N and false positives pF P .
We think of the false negative probability threshold pF N as being negligible, and therefore any
frequent password in the above sense is labeled as such with probability at least 1 − pF N , where
the probability is over the random coins of the server and the participants. On the other hand,
the false positive probability threshold pF P is not necessarily negligible: in particular, if we hash
the passwords to a relatively small range with 16, 24 or 32 bits, then an ‘innocent’ password may
simply hit a heavy hitter. If we have that for any password the probability of being disallowed is
pF P , this might not be so bad, since all it means that the human user will need to choose a new one.
But what we do not want to happen is the case where the user has in his or her mind a sequence
of potential passwords and all of them are falsely labeled as heavy hitters (so the user cannot
successfully choose a password). Instead, we add the requirement that any large enough collection
of passwords (of size at least M ), where none of them is a heavy hitter, are not simultaneously
labeled as such, except with negligible probability ptotal (which is another parameter).
Functionality 1 (Protocol’s Correctness requirement)
· Input:
· Blacklist generation:
to the blacklist with probability at least (1 − pF N ).
• All users send their passwords to the trusted party (TTP).
• For each password pass ∈ {0, 1}∗ with frequency of at least τ · (1 + δ) we have that pass is added
• For each password pass ∈ {0, 1}∗ with frequency of at most τ · (1 − δ) we have that pass is added
to the blacklist with probability at most pF P .
• For any subset P of passwords of size at least M where all of passwords in P have frequency at
most τ · (1 − δ) we have that the probability that all passwords in P are added to the blacklist is
at most ptotal.
• A password with frequency between τ · (1 + δ) and τ · (1 − δ) may be added to the list arbitrarily.
• The TTP sends to server the passwords in the blacklist.
· Output:
The threshold τ is dynamically chosen as the smallest possible value satisfying the required
error probability pF N , with the current number of users NC.
2.4 Correctness and Privacy Achieved
The protocols described in this work achieve correctness with parameters pF N , pF P and ptotal as de-
scribed above in the sense that the parameters can be set as a function of the number of participants
and the privacy requirement. See Section 4.5.
As to privacy, any coalition that does not include the server can only increase its success proba-
bility in the Password Guessing Game PGame(L) by at most an a = eDP factor. In Section 4.3 we
9
derive the value DP from the scheme parameters. We achieve this by making sure that the pass-
word is protected in a diﬀerentially private manner; therefore the adversary cannot pick a device
whose password was compromised. When the coalition includes the server this increase in success
should be bounded by b. If the server learns a single bit regarding the password, as is the case
in our protocols, then to make sure that b is indeed the bound we may use a simple randomized
response technique by ﬂipping this bit at random with probability ln 2/(b−1). The password is then
protected in a diﬀerentially private manner and the corresponding consequences in the Password
Guessing game.
“Everlasting” security and privacy: The proposed system should handle prolonged mainte-
nance of these properties, that is the system lives for a long time and tries to learn the current list
of heavy hitters. We will modify the requirements with some minor relaxations. The server needs to
add ephemeral noise to each publication of the blacklist to protect the user’s privacy and prevent
leakage of data that is required for the protocol’s secure functionality. Therefore, with regards to
the published blacklist, we will allow a password that should appear in this list to be omitted in a
single publication with probability pEphF N , and for a password that should not appear in the list
to appear in it with probability pEphF P .
3 Overview of the Scheme
We start by explaining our domain reduction to hash values. We then describe the basic con-
struction and provide details on how to fulﬁll properties such as diﬀerential privacy and security
against malicious behavior. A rough outline of the basic scheme is that blacklisting the popular
passwords can be reduced to learning a single bit via the Fourier coeﬃcients of the distribution
on the passwords’ hash values. This is done by the server sending a random vector to the device,
who responds with the inner product of the vector and the password’s hash value. To overcome
malicious behavior we need to perform this operation securely, without letting the user learn the
server’s random vector.
3.1 Password Domain Reduction
As we assume the password domain to be unbounded, we use a system-wide hash function H
to map arbitrary length passwords to an (cid:96)-bit output (a typical output length will be (cid:96) = 16, 24 or
32). Our scheme will ﬁnd and publish a blacklist of heavy hitters hash values. A user’s device can
check if the hash value of a newly chosen password is in the blacklist. In that case, the user will be
asked to choose a diﬀerent password.
A collision in the hash value of a user’s password and some “popular” password will cause a
“false positive”, where the user will be asked to change its password even though it is not popular.
This happens with a low probability, O(2−(cid:96)/τ ) where τ is the threshold frequency for a heavy hitter
(see Section 4.3). We can tolerate these events since the only consequence of a collision is that a
user will be asked to choose another password. We will therefore analyze the general problem of
ﬁnding heavy hitters in (cid:96)-bit hash values.
3.2 The Basic Semi-honest Scheme
The scheme works in the following way each time a new device is added or change password:
1. Device j maps its password to a secret (cid:96)-bit value vj = H(passj).
10
2. The device receives from the server a uniformly distributed random (cid:96)-bit value rj. The device
sends back the one bit value of the inner product of vj and rj over GF [2], denoted as (cid:104)vj, rj(cid:105).
3. The server keeps a table T [x] of 2(cid:96) counters, corresponding to all possible (cid:96)-bit values x (initialized
4. For every value of x if (cid:104)x, rj(cid:105) = (cid:104)vj, rj(cid:105) the corresponding counter is incremented by one, oth-
erwise it is decreased by one. Equality holds for exactly half of the values, that we call the
“correlated” values.
to zero on system setup).
We denote the total number of unique users that ran the protocol as NC, and p is the frequency
of the hash value x. The expected numbers of increments and decrements are NC(p + (1 − p)/2)
and NC(1 − p)/2 respectively. The expected value of the counter is E(T [x]) = pNC.
For a threshold frequency τ , the server simply publishes all x values such as T [x] > τ NC. Each
device j can now check if H(passj) is in the published hash values list. If it is, the device asks the
user to change the password.
Note that to allow password changes, the server needs to save rj and (cid:104)vj, rj(cid:105). If a device wants to
change its password, the server will ﬁrst reverse the change to the counters due to the old password
before applying the new changes.
Running Time: This procedure requires 2(cid:96) operations per update. This can be optimized using
Goldreich-Levin’s list decoding (see [Sud00]). However, the actual run time is insigniﬁcant for
suitable values of (cid:96) such as 16, 24 or 32.
3.3 User Diﬀerential Privacy
The scheme leaks only one bit of information about the user’s password. Although it seems that
leaking one bit of entropy about a password would not aﬀect its security by much (since passwords
should have good min-entropy to begin with), in some cases even one bit might be too much. There
are two diﬀerent privacy concerns from the user’s point of view:
1. Privacy from the server – Although some information must be leaked to the server for the scheme
to work, users may want to have some diﬀerential privacy guarantees on the single bit they send
to the server.
2. Privacy from third parties – Although a user may be willing to leak some information about his
password to the server, we want to assure that this information does not leak to any coalition of
users viewing the popular hash values list that is published by the server. This issue is ampliﬁed if
the user participates in schemes for discovering popular passwords with several diﬀerent services,
and each of these services publishes a list of popular passwords.
Protection from the Server: Pure Diﬀerential Privacy by Applying Randomized Re-
sponse The device can use a randomized response to reduce the amount of information that is