resolves the tension between different types of ﬂows accord-
ing to their respective goals. Since the primary goal of type
1 ﬂows is to meet their deadlines, Karuna uses the minimum
bandwidth required for these ﬂows to complete just before
their deadline, thus leaving maximal bandwidth to type 2&3
ﬂows to optimize their FCT.
Deadline ﬂows: A naive rate-control scheme to achieve near-
deadline completion is to always set the rate of a deadline
ﬂow to its expected rate, M/δ, where M is the remaining
size, and δ the remaining time to deadline. However, this
scheme fails [39] when many deadline ﬂows collide due to
lack of congestion control. Moreover, a similar but more
sophisticated rate-control scheme, D3 [39], has a "priority-
inversion" problem [22] due to its greedy algorithm (details
in §4). Thus, to achieve the desired behavior, we design a
new minimal-impact congestion control protocol for dead-
line ﬂows, MCP, which reacts to network congestion and
controls the rate conservatively to just meet the deadline
(§4). We place deadline ﬂows in the highest priority queue,
so they are protected from the aggressive non-deadline ﬂows.
Non-deadline ﬂows: Type 2&3 ﬂows reside in multiple lower
priority queues (Queue 2–K)4 and are regulated by aggres-
sive protocols (e.g., DCTCP [3]) at end hosts to use all band-
width left over by type 1. We further schedule, i.e. split
or sieve, them among these multiple lower priority queues
based on their sizes to minimize FCT:
• If their sizes are known a priori (type 2 ﬂows), they are
directly split into different priority queues based on their
sizes in the spirit of SJF .
• If their sizes are unknown (type 3 ﬂows), they are grad-
ually sieved from higher priority queues to lower priority
queues according to the number of bytes sent, which ef-
fectively emulates SJF without knowing ﬂow sizes.
How to sieve type 3 ﬂows has been explored in [6]. How-
ever, in Karuna, we need to handle both type 2 and 3 ﬂows,
which is a different problem. We thus extend the technique
4K is the number of priority queues supported by commodity
switches, usually 4–8 [5, 6].
Deadline Miss RateFraction00.20.4% type 2 trafﬁc with size smaller than type 1 ﬂow size12468101520Type-2 OverallType-2 Size0,∀s; yl(t)=
(cid:88)
(cid:80)t
0(γs(t)−xs(t))
s∈S (l)
≤0,∀s
lim
t→∞
t
xs(t),∀l;
(4)
4.1.1 Application of Lyapunov optimization
Next, we apply the Lyapunov optimization framework [32]
to transform this minimization problem to a convex problem,
and then derive an optimal congestion window update func-
tion (§4.1.2) based on the optimal solution to the transformed
convex problem. The drift-plus-penalty method [32] is the
key technique in Lyapunov optimization, which stabilizes a
queueing network while also optimizing the time-average of
an objective (e.g. per-packet latency).
Here we explain the application of drift-plus penalty method
(cid:80)
lQl(t)2. The Lyapunov drift is deﬁned as ∆(tk)=L(tk+1)−
to Problem 4 to transform it into a convex programming
problem. To use this framework, a solution to our problem
must address the following aspects:
Queue stability at all links: We ﬁrst deﬁne a scalar mea-
sure L(t) of the stability of the queueing system at time t,
which is called Lyapunov function in control theory. For
our model, we use the quadratic Lyapunov function: L(t)=
1
2
L(tk), the difference between 2 consecutive time instants.
The stability of a queueing network is achieved by taking
control actions that make the Lyapunov function drift in the
negative direction towards zero. With drift-plus-penalty method,
MCP controls the transmission rates of the sources to mini-
mize an upperbound to the network Lyapunov drift, so as to
ensure network stability.
Deadline constraint: To handle the deadline constraints in
(4), we transform them into virtual queues [32]. Consider a
virtual queue Zs(t) for ﬂow s at time t, where the expected
rate is the input and the actual rate is the output.
Zs(t+τs(t))=[Zs(t)+γs(t)−xs(t)]+,∀s
(5)
For the virtual queues to be stable, we have:
0γs(t)/t≤limt→∞(cid:80)t
0xs(t)/t
(6)
sZs(t)2).
Similar to the packet queues at the switches, the virtual queues
can also be stabilized by minimizing the Lyapunov drift. To
include the virtual queues, the Lyapunov function becomes
If the virtual queues are
L(t)= 1
stabilized, the deadline constraint (3) is also achieved, be-
cause the input γs(t) of the virtual queue is on average smaller
than the output xs(t).
Minimization of impact (per-packet latency): The above
two points concern the “drift”. We also use a “penalty” term
to achieve MCP’s goal of minimizing impact to other trafﬁc.
We formulate the drift-plus-penalty as ∆(tk)+V ˜P0(y(tk)).
where V is a non-negative weight chosen to ensure the time
average of ˜P0(t) is arbitrarily close (within O(1/V )) to op-
timal, with a corresponding O(V ) tradeoff in average queue
limt→∞(cid:80)t
2 ((cid:80)
lQl(t)2+(cid:80)
size [31]. By minimizing an upperbound of the drift-plus-
penalty expression, the time average of per-packet latency
can be minimized while stabilizing the network of packet
queues and virtual queues.
Convex Problem: Finally, we arrive at the following covex
problem:
(cid:80)
s{V (cid:80)
l∈L(s)
min
x(t)
xs(t) + (cid:80)
l∈L(s)
dl(yl(t))+ Zs(t)γs(t)
subject to yl(t)=(cid:80)