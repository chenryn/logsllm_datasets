Nevertheless, site authors also move code to new URLs
to avoid ﬁlter list rules. It is relatively easy for ﬁlter list
maintainers to identify tracking code served from a single, well
known URL, and fetched from popular sites. It is much more
difﬁcult for ﬁlter list maintainers to block the same tracking
code served from multitudes of different URLs.
1) Classiﬁcation Methodology: We detect cases of “moving
code” evasion by looking for cases where code with the
identical AST appears at both blocked and not-blocked URLs.
For each script that generated a signature that was not blocked
by EasyList or EasyPrivacy (i.e, an evading script), we ﬁrst
generated the AST of the script, and then generated a hash
from the ordered node types in the AST. We then compared
this AST hash with the AST hash of each blocked script
that also produced the same signature. For any not-blocked
14https://esprima.org/
15https://tracker.com/track.js → https://example.org/track.js
16https://tracker.com/track.js → https://tracker.com/abdcjd.js
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:35 UTC from IEEE Xplore.  Restrictions apply. 
1724
script whose AST hash matched one of the blocked scripts,
we labeled that as a case of evasion by “moving code”. We
observed 720 unique script units (7,924 instances) that evade
ﬁlter lists using this technique in in the Alexa 100K.
is a popular
2) Case Study: Google Analytics: Google Analytics
(GA)
tracking (or analytics) script, main-
tained by Google and referenced by an enormous num-
ber of websites. Generally websites get
the GA code
by fetching one of a small number of well known
(e.g., https://www.google-analytics.com/analytics.js).
URLs
As this code has clear implications for user privacy,
the
EasyPrivacy ﬁlter list blocks this resource, with the rule
||google-analytics.com/analytics.js.
However, many sites would like to take advantage of
GA’s tracking capabilities, despite users’ efforts to protect
themselves. From our results, we see 125 unique cases (i.e.,
unique URLs serving the evaded GA code) where site authors
copy the GA code from the Google hosted location and move
it to a new, unique URL. We encountered these 125 new,
unique Google-Analytics-serving URLs on 5,283 sites in the
Alexa 100k. Google Analytics alone comprised 17.36% and
66.67% of the unique scripts and instances, respectively, of
all cases in our “moving code” category. Most memorably,
we found the GA library, slightly out of date, being served
from https://messari.io/js/wutangtrack.js, and referenced from
messari.io.
B. Inlining Code
Trackers and site authors also bypass ﬁlter lists by “in-
lining” their code. While usually sites reference JavaScript
at a URL (e.g., ), HTML also al-
lows
in the page
(e.g. , which causes to the
browser to execute script without a network request.
to include JavaScript as
sites
text
A side effect of this “inlining” is that URL-based privacy
tools lack an opportunity to prevent the script’s execution. We
note that there are also additional harms from this practice,
most notably performance (e.g., code delivered inline is gen-
erally not cached, even if its reused on subsequent page views).
Depending on implementation, inlining scripts can also delay
rendering the page, in a way remote async scripts do not.
Inlining is
1) Classiﬁcation Methodology:
the most
straightforward evasion type in our taxonomy scheme. Since
PageGraph records the source location of each JavaScript unit
that executes during the loading of a page, we can easily
determine which scripts were delivered as inline code. We
then compare the AST hashes (whose calculation method we
described in Section V-A1) of all inline scripts to all blocked
scripts that generated identical signatures. We labeled all cases
where the hashed-AST of an inline script matched the hashed-
AST of a script blocked by EasyList or EasyPrivacy, and both
scripts generated identical signatures, as cases of evasion by
“inlining”. We observed 498 cases of sites moving blocked,
privacy harming behaviors inline.
2) Case Study: Dynatrace: Dynatrace
a popular
JavaScript analytics library that allows site owners to monitor
is
how their web application performs, and to learn about their
users behavior and browsing history. It is typically loaded as a
third-party library by websites, and is blocked in EasyPrivacy
by the ﬁlter rule ||dynatrace.comˆ$third-party.
Similar, client-speciﬁc versions of the library are also made
available for customers to deploy on their domains, which
EasyPrivacy blocks with the rule /ruxitagentjs_.
However, when Dynatrace wants to deploy its monitoring
code on its own site www.dynatrace.com (and presumably
make sure that it is not blocked by ﬁlter lists) it inlines the
entire 203k lines JavaScript library into the header of the page,
preventing existing ﬁlter lists from blocking its loading.
C. Combining Code
Site authors also evade ﬁlter lists by combining benign and
malicious code into a single code unit. This can be done by
trivially concatenating JavaScript ﬁles together, or by using
popular build tools that combine, optimize and/or obfuscate
many JavaScript ﬁles into a single ﬁle.
Combining tracking and user-serving code into a single
JavaScript unit is difﬁcult for existing tools to defend against.
Unlike the previous two cases, these scripts may be easy
for ﬁlter list maintainers to discover. However, they present
existing privacy tools with a no-win decision: blocking the
script may prevent the privacy-or-security harm, but break the
page for the user; not blocking the script allows the user to
achieve their goals on the site, though at possible harm to the
Web user.
1) Classiﬁcation Methodology: We identiﬁed cases of eva-
sion by “combing code” by looking for cases where the AST of
a blocked script is a subgraph of an evaded script, where both
scripts generated the same signature. To detect such cases,
we again use Esprima to generate AST for all scripts that
match the same signatures. We then look for cases where the
AST of a blocked script is fully contained in the AST of an
evaded script. More speciﬁcally, if an evaded script’s AST
has a subtree that is both (i) structurally identical to the AST
of a blocked script (i.e., subtree isomorphism) (ii) the corre-
sponding AST nodes in both trees have the same node type,
and (iii) both scripts generated the same signature, we then
labeled it as a case of evasion by “code combining”. In total we
observed 85 unique scripts (117 instances) that were privacy-
and-security harming scripts combined with other scripts.
2) Case Study: Insights JavaScript SDK:
Insights is a
JavaScript
tracking, analytics and telemetry package from
Microsoft,17 that allows application developers to track and
record visitors. It includes functionality identiﬁed by EasyPri-
vacy as privacy-harming, and is blocked by the ﬁlter rule
||msecnd.net/scripts/a/ai.0.js.
In order to evade EasyPrivacy, some sites copy the Microsoft
Insights code from the Microsoft provided URL, and included
it, among many other libraries, in a single JavaScript ﬁle.
This process is sometimes called “bundling” or “packing”.
As one example, the website https://lindex.com includes the
17https://docs.microsoft.com/en-us/azure/azure-monitor/overview
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:35 UTC from IEEE Xplore.  Restrictions apply. 
1725
Insights library, along with the popular Vue.js and Mustache
in a single URL,18 packaged together using the
libraries,
popular WebPack19 library.
There many other similar examples of downstream, privacy-
and-security harming libraries included by diverse JavaScript
applications, following this same pattern.
D. Included Library
Finally, ﬁlter lists are unable to protect against JavaScript
code including common privacy-harming libraries. Such li-
braries are rarely, if ever, included by the site directly, but are
instead downstream dependencies by the libraries directly in-
cluded on the website. These cases are common, as JavaScript
build systems emphasize small, reusable libraries. Downstream
libraries are difﬁcult for ﬁlter lists to target because there is
no URL ﬁlter list maintainers can block; instead, ﬁlter list
maintainers can only target the diverse and many bespoke
JavaScript applications that include the libraries.
1) Classiﬁcation Methodology: We identiﬁed 2,286 unique
scripts (3,505 instances) in the Alexa 100K that
include
such privacy-and-security threatening code as a dependency.
These were found by looking for common signiﬁcant subtrees
between ASTs. More speciﬁcally, when two scripts generated
the same signature, and the AST of the blocked script and the
AST of a not-blocked script, contained signiﬁcant identical
subtrees. We point out the possibility for false-positive here,
since two scripts generating the signature might have common
AST subtrees that are unrelated to the privacy-or-security-
affecting behavior being signatured. (e.g., both scripts could
include the jQuery library, but not have that library be the part
of either code unit involved in the signature).
It is difﬁcult to programmatically quantify the frequency of
such false positives due to the complexity of the JavaScript
code involved, which is often obfuscated to deter manual
analysis. Nevertheless, we point out that for scripts in this
category, (i) our signatures offer considerable improvements
over the current state-of-the-art, by allowing automatic ﬂag-
ging of scripts that exhibit the same privacy-harming semantics
as existing blocked scripts, and (ii) we believe these false
positives to be rare, based on a best-effort, expert human
evaluation (we encountered only one such case in a human
evaluation of over 100 randomly sampled examples, performed
during the signature size sampling described in Section III).
2) Case Study: Adobe Visitor API: The “Visitor API”
is a library built by Adobe, that enables the ﬁngerprinting
and re-identiﬁcation of site visitors. It
is never included
is instead included by many other
directly by sites, but
tools, many of which also generated and sold by Adobe
(e.g. Adobe Target). Some of these Adobe-generated, Visitor
API-including libraries, are blocked by the EasyPrivacy rule
||adobetm.comˆ$third-party.
Other libraries that include the Adobe Visitor API code
though are missed by ﬁlter lists, and thus are undefended
against. For example, the site ferguson.com indirectly loads the
Visitor API code on its site, through the site’s “setup” code.20
18https://lindex.com/web-assets/js/vendors.8035c13832ab6bb90a46.js
19https://webpack.js.org/
20https://nexus.ensighten.com/ferguson/fergprod/Bootstrap.js
VI. DISCUSSION
A. Comparison to Hash-Based Detection
Given the complexity of the signature-based approach pre-
sented by this work, we compared the usefulness of signature-
based matching with a much simpler approach of detecting
evasion by comparing code text. More speciﬁcally, we mea-
sured how many cases of evasion that we detected by using
signatures would have been missed by only comparing the
text (here, hash) of code units. We ﬁnd that the majority of
the evasion cases we identify using per-event-loop signatures
would be missed by simple text-comparison approaches.
First, we note the majority of evasions discussed in Sec-
tion V cannot be detected by trivial
text-comparison ap-
proaches. For example, a simple technique based on comparing
hashes of the script text against known-bad scripts can only
ﬁnd cases where the exact same script has been moved
verbatim from one URL to another, or copied verbatim into
a larger code unit; it would fail to ﬁnd evasion resulting
from even trivial modiﬁcations, miniﬁcation, or processing by
bundling (e.g., WebPack-like) tools.
Second, we ﬁnd that our signature-based approach is able to
identify a signiﬁcant number of cases that text-only approaches
would miss. Only 411 of the 720 unique scripts we observed
in the “moving code” category of our taxonomy (Section V-A)
had identical script text (i.e., SHA-256 hash); in the remaining
309 cases the scripts behavior was identical but the script
text was modiﬁed (a false negative rate of 42.8% in the
“moving code” category alone). However, the simpler, hash-
based approach identiﬁed 7,515 of the 7,924 incidents (i.e., not
unique) of moved scripts. Put differently, a text-comparison
approach would correctly handle most cases of scripts being
moved, but would miss 42.8% unique moved scripts (note that
by its nature, a script that has been moved verbatim to another
URL is a special case of “moving code” in our taxonomy).
Furthermore, evaded scripts in the bundling and common
code categories cannot be straightforwardly detected by com-
paring hashes of the script text, since by deﬁnition these scripts
contain new code and thus the hash of the script will be
different. Indeed, it is challenging, if not impossible, to use
text-based detection methods against these evasion techniques.
By comparison, since our approach targets the behavior rather
than the delivery mechanism of the harmful scripts (and
regardless of whether they are obfuscated and/or bundled with
other scripts),
it can detect evaded scripts whenever their
privacy-harming functionalities are executed.
B. Countermeasures
This work primarily focuses on the problem of measuring
how often privacy-and-security affecting code evades ﬁlter
lists, by building behavioral signatures of known-undesirable
code, and looking for instances where unblocked code per-
forms the same privacy-and-security harming behaviors. In this
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:35 UTC from IEEE Xplore.  Restrictions apply. 
1726
section we discuss how this same methodology can be used to
protect web users from these privacy-and-security threatening
code units.
We consider three exhaustive cases, and possible defenses
against each: blocked code being moved to a new URL,
privacy-and-security affecting event-loop turns that affect stor-
age but not network, and privacy-and-security affecting event-
loop turns that touch network.
1) Moved Code: In cases where attackers evade ﬁlter lists
by moving code to a new URL, our approach can be used
to programmatically re-identify those moved code units, and
generate new ﬁlter lists rules for the new URLs. Using
this approach, we have generated 586 new ﬁlter list URLs,
compatible with existing popular content blocked tools like
AdBlock Plus and uBlock Origin. Further, we have submitted
many of these new ﬁlter list rules to the maintainers EasyList
and EasyPrivacy; many have been upstreamed, and many more
are being reviewed by the maintainers.
2) Event-Loop Turns Without Network: Instances of code
being inlined, or privacy-or-security affecting code being com-
bined with other code, are more difﬁcult to defend against,
and require runtime modiﬁcations. These have not been im-
plemented as part of this work, but we discuss possible
approaches for doing so here.21 We note that
the single-
threaded model of the browser means that signature-matching
state only needs to be maintained per JavaScript content, to
track the behavior of the currently executing script; state does
not need to be maintained per code unit.
In cases where the privacy-harming, event-loop signature
only consists of storage events (i.e. no network behavior),
we propose staging storage for the length of each event-
loop turn, discarding the storage modiﬁcations if the event-
loop turn matches a signature, and otherwise committing it.
This would in practice be similar to how Safari’s “intelligent
tracking protection” system stages storage until the browser
can determine if the user is being bounce-tracked.
3) Event-Loop Turns With Network: The most difﬁcult
situation for our signature-based system to defend against is
when the event-loop turn being “signatured” involves network
activity, as this may force a decision before the entire signature
can be matched (i.e. if the network event occurs in the middle
of signature). In such cases, runtime matching would need to
operate, on average, with half as much information, and thus
would not provide protection in 50% of cases. While this is
not ideal, we note that this is a large improvement over current
privacy tools, which provide no protections in these scenarios.
We leave ways of more comprehensively providing runtime
protects against network-involving, security-and-privacy harm-
ing event-loop turns as future work.
C. Accuracy Improvements
This work generates signatures from known privacy-and-
security harming scripts, using as input the behaviors discussed