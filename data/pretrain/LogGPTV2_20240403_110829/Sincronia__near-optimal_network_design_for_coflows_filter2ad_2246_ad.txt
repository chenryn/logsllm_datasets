Sincronia uses a simple optimization for work conser-
vation that alleviates this problem. Each orphan coflow is
assigned an ordering among all the orphan coflows based
on its “oracle completion time (OCT)”, which is defined as
the time the coflow would take to finish if it were the only
coflow in the network. Note that the OCT of a coflow c is
simply maxp(d
c /bp), where bp is the bandwidth at port p.
Specifically, the orphan coflows are chosen to be scheduled
for work conservation in increasing order (smaller first) of
the following metric:
p
current_time + max_epoch_size - arrival_time
OCT
The reason this metric is interesting for work conservation is
that it finds the right balance between coflows that are “small”
(that is, have small OCTs) and coflows that are large but have
been waiting for a long while (that is, coflows that are being
starved) while selecting coflows to use for work conservation.
For instance, consider a time instant when there are three
coflows in the system; two of these coflows arrived at time 20
and have OCTs equal to 1 and 10, respectively, and the third
coflow arrived at time 0 and has OCT equal to 25. Suppose
the max_epoch_length is 4. Then, when choosing a coflow
for work conservation at time 21, the Sincronia daemon will
choose the coflow with OCT equal to 1 first (the metric value
being 1/5), then choose the coflow with OCT equal to 25
that has been waiting for too long (the metric value being
1) and then finally send the coflow with OCT equal to 10.
Thus, Sincronia is able to find the right balance between
small coflows and starving coflows to choose from for work
conservation purposes.
4.5 Other Practical Considerations
Finally, we discuss a few other techniques incorporated
within Sincronia implementation to handle practical issues
that may arise in real-world scenarios.
Co-existence of flows and coflows. In most datacenter
networks, multiple applications co-exist, some of which may
require the network fabric to optimize for coflow-based met-
rics while others may care about the performance of each
individual flow. Prior results on network design for coflows
enable coexistence of such applications by treating each in-
dividual flow as a coflow. This may be restrictive since flow
based applications may have different performance goals
compared to coflow based applications. Sincronia partially
handles such scenarios using coflow weights.
Specifically, while our discussion so far has focused on
Sincronia design and implementation for achieving near-
optimal performance in terms of average CCT, Sincronia
achieves something much more general — it optimizes for
“weighted” average CCT, as defined in §2. That is, it allows
network operators to set a weight for each individual coflow.
Network operators can use different weights for different
applications (e.g., those that require optimizing for flows
and those that require optimizing for coflows), and the BSSI
algorithm computes ordering of coflows that optimize for
the weighted average CCT. Finding the right mechanism to
set weights depends on the applications and is beyond the
scope of this paper.
Achieving other performance objectives. Sincronia also
allows achieving several other performance objectives using
the coflow weights. For instance, there has been quite a bit
of work in the community on deadline-aware scheduling
Sincronia: Near-Optimal Network Design for Coflows
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
for the traditional abstraction of network flows [4, 16, 25].
One way to handle deadlines in Sincronia is to assign coflow
weights inversely proportional to their deadlines. Sincronia
also supports admission control by assigning zero weights to
coflows which would definitely miss their deadlines, hence
scheduling them after other coflows. Designing coflow sched-
uling algorithms that provide provable guarantees for the
case of deadlines is an interesting open problem (§6).
Starvation Freedom. Minimizing average completion time
necessitates starvation [4, 10]. However, as discussed in §4.4,
the prioritized work conservation mechanism used in Sin-
cronia alleviates starvation to some extent. Intuitively, since
the choice of an unordered coflow for work conservation
depends inversely on the “waiting time” of the coflow (dif-
ference between current time and the arrival time), as the
waiting time of the coflow increases, its chances of being
selected for work conservation purposes also improve.
5 EVALUATION
We now present evaluation results for Sincronia3. We start
by describing the workloads and performance metrics used
in our evaluation (§5.1). We then evaluate Sincronia using
simulations (§5.2); the main goal here is to understand the
performance of Sincronia against the state-of-the-art [10],
to understand the envelope of workloads for which Sincro-
nia performs well, and to perform sensitivity analysis of
Sincronia performance over a variety of parameters includ-
ing workloads, number of coflows, network load and epoch
sizes. We then evaluate the Sincronia implementation with
TCP/DiffServ on a 16-server testbed interconnected with a
FatTree topology comprising 20 commodity switches (§5.3).
5.1 Workloads and Performance Metrics
We use two workloads in our evaluation. The first workload
is the one used in all prior network designs [10]: a 526-coflow
trace obtained from one-hour long run of MapReduce jobs
on a 3000-machine cluster at Facebook. Unfortunately, the
Facebook trace makes several simplifying assumptions, is
limited in number of coflows and imposes low network load.
The second workload is a collection of traces generated using
a coflow workload generator [1] that allows upsampling the
Facebook trace to desired number of coflows, network load,
etc., while keeping workload characteristics similar to the
original Facebook trace. Unless mentioned otherwise, all
results for these “custom” traces use the baseline of 2000
coflows, 0.9 network load and time horizon reset after 8
epochs. Varys does not support weighted coflow scheduling;
thus, to make a fair comparison, we use unit weights for
all coflows. We provide other setup details (e.g., topology,
3Sincronia implementation and simulator are publicly available at:
https://github.com/sincronia-coflow.
link bandwidth, etc.) for simulations and implementation in
respective subsections.
Metrics. For the offline algorithm, we evaluate the perfor-
mance in terms of CCT, on an average and at high percentiles.
For the online algorithm, we evaluate the performance of
Sincronia using the slowdown metric; for a given coflow,
the slowdown is defined as the ratio of its CCT and its OCT
(recall from §4.4, the OCT of a coflow is its completion time
when its the only coflow in the network). In presence of
other coflows, CCT of a coflow may be much larger than its
OCT; thus, our evaluation results for the online version of
Sincronia are against the best possible baseline.
5.2 Simulation Results
We now evaluate Sincronia against the state-of-the-art [10]
using simulations, and perform sensitivity analysis of Sin-
cronia performance over a variety of parameters.
Setup. Varys uses a flow-level simulator in its evaluation.
For a fair comparison, we incorporate Sincronia within Varys
simulator, with BSSI for coflow ordering (Algorithm 1, §3.1)
and greedy algorithm for flow scheduling (Algorithm 2, §4.3).
We use the same setup used in Varys, modeling the network
using a non-blocking 150-port switch, where each port corre-
sponds to a top-of-the-rack switch in 3000-machine cluster.
Offline Algorithm. We first evaluate Sincronia against ex-
isting network designs for the offline case, that is, when all
coflows arrive at time 0. While not a practical scenario, this
allows us to tease out the performance benefits of Sincronia’s
BSSI algorithm against those used in prior network designs.
Figure 5(a)-5(c) show that Sincronia significantly improves
upon state-of-the-art (Varys [10] and other heuristics) across
all evaluated workloads. Specifically, Figure 5(a) shows that,
when compared to TCF and Varys, Sincronia improves CCT
by 1.7× on an average and by 7.9× at 99-th percentile. In ad-
dition, Figure 5(b) shows that Sincronia improvements over
Varys increase with larger number of coflows in the trace,
both on an average and at high percentiles. Since both Varys
and Sincronia are work-conserving, CCT for some coflows
has to degrade for improvement in CCT for other coflows.
Figure 5(c) shows the CDF for distribution of improvement
across all coflows; interestingly, Sincronia degrades the CCT
for less than 20% of the coflows while improving the CCT
for more than 65% of the coflows.
Figure 5(d)-5(e) provide more insights on how Sincronia
achieves the observed improvements. Figure 5(d) shows that
most of the improvements come from Sincronia’s ordering al-
gorithm, Bottleneck-Select-Scale-Iterate (BSSI) — even when
BSSI is used with MADD, the rate allocation mechanism
from Varys, we observe significant CCT improvements on
an average and at tail. Figure 5(e) provides more insights
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
S. Agarwal et al.
Figure 5: Sincronia evaluation results for the offline case. Sincronia achieves consistently better performance compared to existing
heuristics for the original Facebook trace (top left) and maintains these improvements across a variety of workloads (top center, top right).
Most of Sincronia’s improvements are due to its BSSI scheduling algorithm from §3 (bottom left, bottom right). More discussion in §5.2.
about BSSI’s performance. The figure plots the average fac-
tor of improvement measured across coflows binned by their
OCTs normalized by the smallest OCT; that is, an OCT bin i
contains the set of coflows whose OCT is within [2i , 2i +1) of
the OCT of the smallest coflow. The figure shows that, when
compared to Varys, Sincronia results in CCT improvements
by making better scheduling decisions for coflows that are
neither too small (low OCTs) nor too large (high OCTs). In-
deed, scheduling decisions for small and large coflows are
rather straightforward, and both Sincronia and Varys end
up making similar decisions; it is precisely the medium size
coflows where the weight scaling step in BSSI helps Sincronia
in making the “right” decisions.
Online Algorithm. We now evaluate Sincronia for the case
when coflows arrive over time. We focus on custom traces
only since the Facebook trace has very low load and does
not provide meaningful insights. As discussed in §5.1, we
use the absolute best possible baseline here — ratio of coflow
CCT and its OCT. Figure 6 shows that Sincronia handles
online arrival of coflows very well; when compared to an
unloaded network (slowdown = 1), Sincronia at load 0.9
performs within 1.7× on an average and within 5.7× at high
percentiles for the Custom 4000 trace.
Figure 6(b)-6(c) provide more insights into Sincronia’s per-
formance. The former shows that around 60% of the coflows
achieving slowdown 1, that is, are optimally scheduled by
Sincronia. As the size of the trace increases, contention for
network resources increases resulting in higher slowdowns.
Figure 6(c) shows that larger slowdowns are caused mainly
by larger coflows; this is not only because smaller coflows
should indeed be prioritized but also that the work conserva-
tion heuristic in Sincronia (§4.2) prioritizes smaller coflows
until long coflows have been waiting for a long time.
Sensitivity Analysis. Figure 5 and Figure 6 already show
impact of trace sizes on Sincronia performance. We per-
form additional sensitivity analysis of Sincronia performance
against network load, number of epochs before resetting the
time horizon, and various epoch mechanisms in Figure 7.
Figure 7(a) shows that, as expected, Sincronia performance
improves as the network load decreases from 0.9 to 0.7. We
see in Figure 7(b) that Sincronia performance varies with
number of epochs before resetting the time horizon — as
the number of epochs increase, larger fraction of coflows
observe completion times close to their OCTs but the tail
slowdown also worsens. Intuitively, as the number of epochs
increase, the largest epoch size also increases; this, in turn,
increases the chance of a small coflow arriving between
epoch boundaries and being blocked by a large “ordered”
coflow, one that was ordered at the start of the epoch and
hence has higher priority than the small coflow. Finally, we
compare the performance of Sincronia with varying epoch
mechanisms. We use exponentially-increasing epoch sizes,
fixed-epoch sizes (with size equal to the longest epoch in
exponentially-increasing epoch size mechanism) and the “im-
mediate recomputation” mechanism that executes the BSSI
algorithm upon each coflow arrival and departure. Figure 7(c)
 1 2 4 8 16 32 64 128Average90th 99th Factor of Improvement  using Sincronia  over existing heuristicsPercentileNCFSCFTCFVarys 1 2 4 8 16Average90th 99th Factor of Improvement  using Sincronia  over VarysPercentileFBCustom 1000Custom 2000Custom 4000 0 0.2 0.4 0.6 0.8 12-52-42-32-22-120212223242526CDFFactor of Improvement using Sincronia over VarysFBCustom 1000Custom 2000Custom 4000 1 2 4 8 16Average90th 99th Factor of Improvement  using Sincronia  (using BSSI + Greedy)Percentile SEBF+MADD BSSI+MADD 1 2 3 4 5 6 0 2 4 6 8 10 12 14 16 18Factor of Improvement  using Sincronia  over Varys  for individual coflowsOCT binsCustom 1000Custom 2000Custom 4000Sincronia: Near-Optimal Network Design for Coflows
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
Figure 6: Sincronia evaluation results for the online case. (left, center) For the evaluated workloads, Sincronia achieves performance
within 1.7× on an average and 5.7× at high percentiles when compared to an unloaded network; (right) Coflows with larger sizes observe
larger slowdown in online version of Sincronia. More discussion in §5.2.
Figure 7: Sensitivity analysis of Sincronia performance over varying network load (left), varying number of epochs before resetting
the time horizon (center) and varying epoch mechanisms (right). More discussion in §5.2.
shows that, over the evaluated workloads, the first two mech-
anisms perform comparably and are only marginally worse
when compared to the (impractical) immediate recomputa-
tion mechanism.
5.3 Implementation Results
We now present evaluation results for Sincronia implementa-
tion on top of TCP (using Diffserv [6] for priority scheduling).
Our implementation runs on a topology shown in Figure 9.
We compare Sincronia performance against coflow-agnostic
TCP implementation4.
The main challenge in running these experiments is that
TCP does not handle incast traffic very well, precisely the
scenario for coflows (multiple sources sending data to the
same destination). Thus, we compute the expected load on
a destination (by using network load along with expected
number of sources sending data to a destination in the Face-
book trace), and refer to it as Maximum Sustainable Load
(MSL) for the cluster. We then generate the workloads for the
cluster using the workload generator for 16 ingress/egress
ports, with 1Gbps access link bandwidth and varying loads
(0.7×MSL, 1.4×MSL and 2.1×MSL).
4Despite trying for several weeks, we were not able to run Varys [10] over
our topology; the code for Varys is not maintained and the software stack
for which this code was written has evolved. Nevertheless, we would like
to thank the authors of Varys [10] to share their implementation with us
and helping us to try and run their code.
Figure 8 shows that for a workload comprising 526 coflows
at load 0.7×MSL, Sincronia implementation on top of TCP
improves the CCT by 18.61× on an average, by 46.95× at 90-
th percentile, and 149.05× at 99-th percentile when compared
to coflow-agnostic TCP.
As expected, the improvements are even more significant
for larger loads. Figure 8(b) shows that Sincronia achieves
these improvements by slowing down less than 10% of
the coflows by more than 2× (and even smaller fraction
for higher loads). Finally, Figure 8(c) shows that Sincronia
achieves similar benefits for larger traces. This evaluation
is a bit unfair — TCP is neither designed for coflows nor