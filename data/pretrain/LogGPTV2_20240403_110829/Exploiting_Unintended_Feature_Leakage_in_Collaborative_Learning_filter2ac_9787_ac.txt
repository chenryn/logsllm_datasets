thus reducing the computational cost of the attack.
Inference algorithm. As collaborative training progresses, the
adversary observes gradient updates gobs = Δθt − Δθadv
.
For single-batch inference, the adversary simply feeds the
observed gradient updates to the batch property classiﬁer fprop.
This attack can be extended from single-batch properties to
the target’s entire training dataset. The batch property classiﬁer
fprop outputs a score in [0,1], indicating the probability that
a batch has the property. The adversary can use the average
score across all iterations to decide whether the target’s entire
dataset has the property in question.
E. Active property inference
t
An active adversary can perform a more powerful attack
by using multi-task learning. The adversary extends his local
copy of the collaboratively trained model with an augmented
property classiﬁer connected to the last layer. He trains this
model to simultaneously perform well on the main task and
recognize batch properties. On the training data where each
record has a main label y and a property label p, the model’s
joint loss is calculated as:
Lmt = α · L(x, y; θ) + (1 − α) · L(x, p; θ)
During collaborative training, the adversary uploads the up-
dates ∇θLmt based on this joint loss, causing the joint model
to learn separable representations for the data with and without
the property. As a result, the gradients will be separable too
(e.g., see Figure 7 in Section VI-E), enabling the adversary to
tell if the training data has the property.
This adversary is still “honest-but-curious” in the cryp-
tographic parlance. He faithfully follows the collaborative
learning protocol and does not submit any malformed mes-
sages. The only difference with the passive attack is that this
adversary performs additional local computations and submits
the resulting values into the collaborative learning protocol.
Note that the “honest-but-curious” model does not constrain
the parties’ input values, only their messages.
V. DATASETS AND MODEL ARCHITECTURES
The datasets, collaborative learning tasks, and adversarial
inference tasks used in our experiments are reported in Table I.
Dataset
LFW
FaceScrub
PIPA
CSI
#Records Main tasks
Inference tasks
13.2k Gender/Smile/Age Race/Eyewear
Eyewear/Race/Hair
18.8k Gender
18.0k Age
1.4k Sentiment
Identity
Gender
Membership,
Region/Gender/Veracity
Membership
Membership,
Doctor specialty
Author
FourSquare
Yelp-health
15.5k Gender
17.9k Review score
Yelp-author
16.2K Review score
TABLE I: Datasets and tasks used in our experiments.
Our choices of hyperparameters are based on the standard
models from the ML literature.
Labeled Faces In the Wild (LFW). LFW [28] contains 13,233
62x47 RGB face images for 5,749 individuals with labels such
as gender, race, age, hair color, and eyewear.
FaceScrub. FaceScrub [40] contains 76,541 50x50 RGB
images for 530 individuals with the gender label: 52.5% are
labeled as male, the rest as female. For our experiments, we
selected a subset of 100 individuals with the most images, for
a total of 18,809 images.
On both LFW and FaceScrub, the collaborative models are
convolutional neural networks (CNN) with three spatial con-
volution layers with 32, 64, and 128 ﬁlters, kernel size set
to (3, 3), and max pooling layers with pooling size set to 2,
followed by two fully connected layers of size 256 and 2. We
use rectiﬁed linear unit (ReLU) as the activation function for
all layers. Batch size is 32 (except in the experiments where
we vary it), SGD learning rate is 0.01.
People in Photo Album (PIPA). PIPA [67] contains over
60,000 photos of 2,000 individuals collected from public
Flickr photo albums. Each image includes one or more people
and is labeled with the number of people and their gender,
age, and race. For our experiments, we selected a subset of
18,000 images with three or fewer people and scaled the raw
images to 128x128.
The collaborative model for PIPA is a VGG-style [54]
10-layer CNN with two convolution blocks consisting of
one convolutional layer and max pooling, followed by three
convolution blocks consisting of two convolutional layers and
max pooling, followed by two fully connected layers. Batch
size is 32, SGD learning rate is 0.01.
Yelp-health. We extracted health care-related reviews from the
Yelp dataset1 of 5 million reviews of businesses tagged with
numeric ratings (1-5) and attributes such as business type and
location. Our subset contains 17,938 reviews for 10 types of
medical specialists (see the leftmost column of Table IV).
Yelp-author. We also extracted a Yelp subset with the reviews
of the top 10 most proliﬁc reviewers, 16,207 in total.
On both Yelp datasets, the model is a recurrent neural net-
work with a word-embedding layer of dimension 100. Words
in a review are mapped to a sequence of word-embedding
vectors, which is fed to a gated recurrent unit (GRU [10])
1https://www.yelp.com/dataset
(cid:23)(cid:26)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:37 UTC from IEEE Xplore.  Restrictions apply. 
layer that maps it to a sequence of hidden vectors. We add a
fully connected classiﬁcation layer to the last hidden vector of
the sequence. SGD learning rate is 0.05.
FourSquare.
In [63, 64], Yang et al. collected a global
dataset of FourSquare location “check-ins” (userID,
time,
location, activity) from April 2012 to September 2013. For
our experiments, we selected a subset of 15,548 users who
checked in at least 10 different locations in New York City
and for whom we know their gender [65]. This yields 528,878
check-ins. The model is a gender classiﬁer, a task previously
studied by Pang et al. [44] on similar datasets.
CLiPS Stylometry Investigation (CSI) Corpus. This annually
expanded dataset [60] contains student-written essays and
reviews. We obtained 1,412 reviews, equally split between
Truthful/Deceptive or Positive/Negative and labeled with at-
tributes of the author (gender, age, sexual orientation, region
of origin, personality proﬁle) and the document (timestamp,
genre,
topic, veracity, sentiment). 80% of the reviews are
written by females, 66% by authors from Antwerpen, the rest
from other parts of Belgium and the Netherlands.
On both the FourSquare and CSI datasets, the model, which
is based on [31], ﬁrst uses an embedding layer to turn non-
negative integers (locations indices and word tokens) into
dense vectors of dimension 320, then applies three spatial con-
volutional layers with 100 ﬁlters and variable kernel windows
of size (3, 320), (4, 320) and (5, 320) and max pooling layers
with pooling size set to (l−3, 1), (l−4, 1), and (l−5, 1) where
l is the ﬁxed length to which input sequences are padded. The
hyperparameter l is 300 on CSI and 100 on FourSquare. After
this, the model has two fully connected layers of size 128 and
2 for FourSquare and one fully connected layer of size 2 for
CSI. We use RELU as the activation function. Batch size is
100 for FourSquare, 12 for CSI. SGD learning rate is 0.01.
VI. TWO-PARTY EXPERIMENTS
All experiments were performed on a workstation running
Ubuntu Server 16.04 LTS equipped with a 3.4GHz CPU i7-
6800K, 32GB RAM, and an NVIDIA TitanX GPU card.
We use MxNet [8] and Lasagne [12] to implement deep
neural networks and Scikit-learn [48] for conventional ML
models. The source code is available upon request. Training
our inference models takes less than 60 seconds on average
and does not require a GPU.
We use AUC scores to evaluate the performance of both
the collaborative model and our property inference attacks.
For membership inference, we report only precision because
our decision rule from Section IV-C is binary and does not
produce a probability score.
A. Membership inference
The adversary ﬁrst builds a Bag of Words (BoW) represen-
tation for the input whose membership in the target’s training
data he aims to infer. We denote this as the test BoW. During
training, as explained in Section IV-C, the non-zero gradients
of the embedding layer reveal which “words” are present in
Yelp-health
FourSquare
Precision
0.92
0.84
0.75
0.66
0.62
Batch Size
100
200
500
1,000
2,000
Batch Size
32
64
128
256
512
Precision
0.99
0.98
0.91
0.76
0.62
TABLE II: Precision of membership inference (recall is 1).
Infer T. Corr. AUC Main T.
Main T.
Gender
Black
1.0 Gender
0.93 Gender
Gender Asian
Black
Smile
1.0 Smile
0.93 Smile
Asian
Smile
Age
Black
1.0 Race
0.97 Race
Asian
Age
Eyewear Black
1.0 Hair
0.91 Hair
Eyewear Asian
-0.005
-0.018
0.062
0.047
-0.084
-0.078
0.034
-0.119
Infer T.
Sunglasses
Eyeglasses
Sunglasses
Eyeglasses
Sunglasses
Eyeglasses
Sunglasses
Eyeglasses
Corr. AUC
1.0
-0.025
0.94
0.157
1.0
-0.016
0.97
-0.083
0.026
1.0
0.96
-0.116
1.0
-0.013
0.139
0.96
TABLE III: AUC score of single-batch property inference on LFW.
We also report the Pearson correlation between the main task label
and the property label.
each batch of the target’s data, enabling the adversary to build
a batch BoW. If the test BoW is a subset of the batch BoW, the
adversary infers that the input of interest occurs in the batch.
We evaluate membership inference on the Yelp-health and
FourSquare datasets with the vocabulary of 5,000 most fre-
quent words and 30,000 most popular locations, respectively.
We split the data evenly between the target and the adversary
and train a collaborative model for 3,000 iterations.
Table II shows the precision of membership inference for
different batch sizes. As batch size increases, the adversary
observes more words in each batch BoW and the attack
produces more false positives. Recall is always perfect (i.e., no
false negatives) because any true test BoW must be contained
in at least one of the batch BoWs observed by the adversary.
B. Single-batch property inference
We call a training batch bnonprop if none of the inputs in
it have the property, bprop otherwise. The adversary aims to
identify which of the batches are bprop. We split the training
data evenly between the target and the adversary and assume
that the same fraction of inputs in both subsets have the
property. During training, 1
m of the target’s batches include
only inputs with the property (m = 2 in the following).
LFW. Table III reports the results of single-batch property
inference on the LFW dataset. We chose properties that
are uncorrelated with the main classiﬁcation label that the
collaborative model is trying to learn. The attack has perfect
AUC when the main task is gender classiﬁcation and the
inference task is “race:black” (the Pearson correlation between
these labels is -0.005). The attack also achieves almost perfect
AUC when the main task is “race: black” and the inference
task is “eyewear: sunglasses.” It also performs well on several
other properties, including “eyewear: glasses” when the main
task is “race: Asian.”
These results demonstrate that gradients observed during
training leak more than the characteristic features of each
class. In fact, collaborative learning leaks properties of the
(cid:23)(cid:26)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:37 UTC from IEEE Xplore.  Restrictions apply. 
(a) pool1
(b) pool2
(c) pool3
(d) fc
Fig. 3: t-SNE projection of the features from different layers of the joint model on LFW gender classiﬁcation; hollow circle point is female,