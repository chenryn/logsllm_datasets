Finding 8: For the same decision factor, negative messages
are more likely to impact users’ decisions compared with
positive messages.
The change rates for messages in each scenario are in Table
12. For the negative messages, the change rate is the percent-
age of participants who changed their decisions from grant
to deny among all participants who initially chose to grant.
Similarly, for positive messages, the change rate refers to the
percentage of respondents who changed from deny to grant.
We performed Wilcoxon signed rank test to evaluate
whether there is a signiﬁcant difference in user’s permission
decisions before and after the messages were provided. Ta-
ble 12 shows the signiﬁcant change rate of both negative and
Examples
“For microphone, I always concern that some people may
listen in my conversations, you know, they have access to that.”
“They can get my data, their database may leak my information.
The other way is that they can get your data through some network.
As long as your data go through the network, there are some risks.”
“I usually trust the big-companies apps more, [because] I know better
about them. They should be more secure.”
“They can provide something to help users differentiate good apps or
bad apps, [that] is helpful, like ratings.”
“I would like to see some reviews from authorities.”
positive messages in blue background. All negative mes-
sages have a signiﬁcant change rate (p<0.05), but less than
half of positive messages have a signiﬁcant change rate. In
addition, most negative messages have a higher change rate
than the corresponding positive messages for the same factor,
with ﬁve exceptions (marked in bold in Table 12).
We used the two-tailed Mann-Whitney U test to measure
the differences between the change rates of positive and nega-
tive messages. Table 12’s p-value columns show the results.
Three quarters (27 out of 36) of the change rates are signiﬁ-
cantly different. These results suggest that negative messages
are more likely to impact users’ decisions than positive mes-
sages. Negative messages may remind users of the potential
risks and reconsider their permission decisions.
Interestingly, eight participants changed their decision from
grant to deny after being presented with positive messages
(background access and data transmission with LCGE). The
reason may be that these participants are very cautious with
their location data. Even though the messages are positive,
they may be reminded of the potential risks of leaking their
locations and thus denied the permission. One participant puts
“Location will be noticed, because that may [have] risks.”
Finding 9: Users found background access the most helpful
while grant rate the least helpful in permission decisions.
For the same decision factor, users tended to ﬁnd the infor-
mation more helpful if negative messages were shown.
At the end of survey 2, we asked the respondents to rate
the helpfulness of the provided messages. Table 13 shows the
results. We computed the average helpfulness score of each
factor with positive and negative messages. Grant rate has the
lowest score: 33 respondents rated this factor as “not helpful
at all” (-2). Users would make permission decisions based on
their own needs, which may differ from other users’.
USENIX Association
30th USENIX Security Symposium    763
Table 12: The change rate for the negative (Neg.) and positive (Pos.) messages for each decision factor. For negative messages, the change rate
is the percentage of users who change their decision from ‘Allow’ to ‘Deny’, while for positive from ‘Deny’ to ‘Allow’. We mark the change
rate in blue if the rate’s p-value is signiﬁcant at α = 0.05 in Wilcoxon Signed Rank Test. The column of p-value represents the two-tailed
Mann–Whitney U test results of the change rate differences between positive and negative messages.
Scenario
Change rate %
Background access
Data transmission
Rating
Review
Grant rate
Brand reputation
Felp
Android
Neg.
46.4
24.0
61.5
48.0
37.0
52.0
Pos. p-value Neg.
30.3
7.7
35.0
21.4
3.1
31.0
47.6
6.7
58.3
0.0
17.9
22.6
0.000*
0.001*
0.000*
0.000*
0.000*
0.000*
iOS
Pos. p-value Neg.
33.3
7.7
22.6
12.5
20.0
50.0
39.4
5.3
36.1
11.1
12.9
34.5
0.000*
0.000*
0.007*
0.000*
0.000*
0.000*
RShare
Android
Pos. p-value Neg.
16.7
15.0
33.3
20.0
10.0
34.4
17.2
0.0
42.9
5.9
33.3
16.2
0.004*
0.030*
0.001*
0.000*
0.002*
0.079
iOS
Pos. p-value Neg.
28.6
6.7
10.5
12.0
15.8
61.0
32.4
12.5
28.9
0.0
16.7
47.2
0.002*
0.000*
0.005*
0.000*
0.000*
0.005*
LCGE
Android
Pos. p-value Neg.
41.7
46.2
12.8
10.0
41.7
25.6
42.1
23.1
28.6
18.2
28.6
42.5
0.344
0.019*
0.349
0.075
0.069
0.117
iOS
Pos. p-value
0.114
20.0
46.7
0.412
36.4
0.261
0.008*
0.0
0.013*
0.0
15.4
0.040*
Table 13: Helpfulness scores of the decision factors in the negative
and positive message framing groups. p-value represents testing
result of the helpfulness rating is different between positive and
negative group in two-tailed Mann–Whitney U test.
Positive
Negative
Background. 55 28
25 32
Data trans.
42 40
Rating
38 31
Review
Grant rate
25 30
46 34
Brand repu.
+2 +1 ±0 -1 -2 avg. +2 +1 ±0 -1 -2 avg. p-value
0.085
0.097
0.008*
0.034*
0.094
0.098
4 1.26 41 34
9
4
8 0.54 31 35
23 12
3 1.14 32 37
11
4
13 10
8 0.81 23 35
14 17 14 0.35 19 26
1 1.19 39 35
14
2 1.06
6
17
6 0.76
9
19
16
5 10 0.76
20 11 11 0.48
19 17 19 0.09
2 1.01
16
5
8
We observe that for the same decision factor respondents
found negative messages more helpful than positive messages.
For most factors, the average scores of negative messages
are much higher than positive messages. This conforms with
our previous ﬁnding: negative messages are more likely to
affect users’ permission decisions. For data transmission, the
negative messages’ score is lower than positive messages’. A
potential reason is that regarding data transmission, the posi-
tive messages surprise users more than the negative message.
Users may already anticipate their data will be transmitted
after collection, in accordance with the negative messages. In
contrast, the positive messages break their negative expecta-
tions and make them feel comfortable to grant a permission.
We also observe that the helpfulness scores from users
who changed their decisions in any of the scenarios (n=345,
µ=1.36) are signiﬁcantly higher than those from users who
changed no decision (n=855, µ=0.56) (χ2 = 368.5, p<0.001).
As for demographics, the respondents with experience in com-
puter science or related ﬁelds are signiﬁcantly less likely
to change their decisions in the simulated scenarios. (U =
135693.0, p<0.001; two-tailed) No signiﬁcant difference was
observed between the scores from Android and iOS users.
Answer to RQ3: We studied six factors that can affect
user’s permission decisions: background access, data trans-
mission, brand reputation, rating, review and grant rate,
among which, background access and brand reputation
were rated the most helpful by the users. We also found that
negative messages related to the factors can have a stronger
impact on users’ permission decisions.
7 Related work
Install-time permission comprehension. Several works
have studied user comprehension of permissions in the install-
time permission model [36,39, 43]. Felt et al. found that most
users do not pay attention to the permission notices shown be-
fore app installation or do not understand the risks behind the
permissions [39]. Kelley et al. found the users can not make
informed decisions that based on the technical descriptions for
permissions [43]. While these studies shared similar method-
ologies as our work, they focused on user comprehension in
the install-time model. Compared with the install-time model,
runtime permission dialogs use brief descriptions to describe
permission in groups to avoid interrupting users for a long
time. This calls for the need to study how users comprehend
the permission groups with brief descriptions. We studied
this problem with a mixed-methods approach, and found that
many users still miscomprehend certain permission groups
based on current descriptions (§5).
Felt et al. [36] were among the ﬁrst to study Android app
overprivilege problem where apps request permissions that
they do not use. Such problems can be mitigated in the run-
time permission model if users can deny the unnecessary
permission requests. However, we found that users have mis-
perceptions in certain permission groups based on the infor-
mation provided by the systems. Therefore, users may not
notice such overprivileged apps. This urges the need to im-
prove the design of permission systems and reduce users’
misperceptions.
Permission model change. Andriotis et al. [27] studied users’
adaptation to the new Android runtime permission model by
analyzing the permission settings of 50 users. Their study
focused on users’ general permission settings as well as
users’ viewpoint when just adapting to the runtime permission
model. Our study focuses on the problem of low-version apps
and their prevalence three years after the runtime permission
model has been introduced. Surprisingly, we found that low-
version apps are still widely installed and one-third users have
confusion on their behavior of requesting permissions (§4).
Rationale messages in requesting permissions. Previous
works studied the rationale messages provided by app devel-
764    30th USENIX Security Symposium
USENIX Association
opers [30, 50, 57]. Bonné et al. [30] found that users grant
or deny a permission based on their expectation on whether
an app needs the permission. Both Android and iOS adopt
the practice to let app developers provide rationale messages
to explain how permissions are used [16, 19]. However, only
relying on app developers providing rationale messages suffer
from several problems [50, 57]. First, app developers may not
provide correct and helpful rationale messages. Liu et al. [50]
found that a signiﬁcant portion of incomplete explanations
only describe basic permissions but hide their usage of other
permissions in the same permission group. Second, Tan et
al. [57] found that most messages only focus on the user ben-
eﬁts but not the potential risks. In comparison, we moved one
step further to investigate what systems can provide to help
users understand permissions (§6).
User concerns in granting permissions. Many previous
works aim to understand what concerns users have when
granting permissions [35, 38, 44, 61]. Inspired by these work,
our study aims to explore what additional information (fac-
tors) that systems can provide to resolve users’ concerns and
assist them in making permission decisions.
Felt et al. [38] surveyed and ranked users’ concerns on risks
related to private data that can be accessed by apps. Their
research goal lies in the selection of private data that should
be protected by permissions and warned to users. Our study
complements their work by focusing on what information can
be provided by the systems to improve users’ understanding
of the permission requests and address their concerns.
Other related works cover certain aspects of the ﬁve iden-
tiﬁed decision factors. (1) Previous works [28, 35] proposed
program analysis techniques that can detect sensitive data
transmission in Android apps. These techniques can be help-
ful in understanding application sensitive data usage behav-
iors and derive the information related to decision factors. (2)
Previous research on the impact of background access shows
that users are more likely to be uncomfortable with resources
requested in the background and block the requests [51,61,62].
Votipka et al. [61] found that users’ comfort level of the back-
ground resource access depends on the when and why the
resource was used. As a complement, our quantitative study
shows that background access is rated as the most helpful one
among the six decision factors. (3) Previous works found that
app store information of user rating and reviews have signiﬁ-
cant impact on both apps’ improvement [53] and users’ deci-
sion on updating apps [59], but none of them have explored
whether ratings and reviews can help users’ permission deci-
sions. (4) We found no previous work studied the relationship
between brand reputation and users’ permission decisions.
(5) We also included grant rate as one decision factor based
on previous studies [25, 47]. Lin et al. used the percentage
of users that ﬁnd a permission surprising to remind users at
the install-time warnings [47]. Agarwal et al. [25] used the
collected grant rate to make permission recommendations for
new users However, we found that grant rate is rated as the
least helpful among the six decision factors, even though this
factor will impact many users’ permission decisions (§6.2).
Other previous works in HCI communities explored the
feasibility to incorporate additional information to raise users’
attention to privacy and permissions [44] or help users better
understand permissions through examples [41]. These works
focused more on how to present the information to users;Our
paper studied what should be presented to the users by com-
paring different decision factors (§6) .
Context integrity for mobile privacy. Context integrity [54]
ties privacy protection to speciﬁc contexts. Wijesekera et