23:
24:
25:
26: end for
27: Sort values ⟨𝑉 ⟩ by their counts ⟨𝐶⟩ descendingly //Appendix F
28: return Rec(⟨𝑉 ⟩)
for party 𝑝 ∈ P do
⟨𝐶[ 𝑗]⟩ ← ADD(⟨𝐶[ 𝑗]⟩, ⟨𝜌 𝑗
𝑝 ⟩)
end for
⟨𝑏discard⟩ ← LE(⟨𝐶[ 𝑗]⟩, ⟨𝜏HH⟩)
⟨𝑉 [ 𝑗]⟩ ← CondSwap(⟨⊥⟩, ⟨𝑉 [ 𝑗]⟩, ⟨𝑏discard⟩)
an empty spot. HH sorts 𝑡 candidates via secure merge sort (Ap-
pendix F). Note that HH sorts a small map, i.e., 𝑡 ≪ 𝑛, and the main
effort is updating the map for 𝑛 elements. We also implemented a
version more suited for parallelization, denoted as HHthreads in our
evaluation (Section 5): The loop steps in HH can be run in parallel,
if we do not set 𝑖empty in the first loop (as this requires locking).
Thus, the main difference between HH and HHthreads is that we
use an additional (non-parallelized) loop to set 𝑖empty.
4.2 PEM: MPC of FPEM
PEM implements FPEM by using array 𝐶 to count candidate prefixes,
where, e.g., 𝐶[1] represents 0000 in the first step with 𝛾 +𝜂 = 4. The
users themselves can track which indices correspond to candidate
prefixes, simplifying the secure computation complexity. In the
last round of PEM, less than 2⌈log 𝑘⌉+𝜂 iterations are required if
(𝑏 − ⌈log 𝑘⌉)/𝜂 is not an integer. We use this optimization in our
implementation but omit it here for readability. Note that we sort
the candidates and do not release noisy counts. Recall, unrestricted
sensitivity (Δ > 𝑘) is realized with Gumbel noise (see Section 3.2.3).
Gumbel noise, unlike Laplace noise, is not DP by itself [32]; hence,
we cannot release noisy counts which the parties could sort locally.
Also, each party can remove its partial noise from the noisy count,
requiring additional noise or secure noise sampling (see Section 4.5).
If we are not interested in the order, i.e., which value is the 𝑖-th most
frequent, the sorting step can be replaced by linear scan (to find the
Algorithm 2 Algorithm PEM.
𝑑
𝜂
𝑖=1 𝐷𝑖
(cid:109) disjoint groups where 𝐷 =𝑔
Input: Noisy user reports (cid:99)𝜁 𝑐
indicating if 𝑑 ∈ 𝐷 has prefix 𝑐 (with
distributed noise as in Section 3.4), output size 𝑘, domain bit-length 𝑏,
prefix extension bit-length 𝜂, DP threshold 𝜏PEM, and distributed noises
(cid:108) 𝑏−⌈log 𝑘⌉
𝜌𝑝 per party 𝑝 ∈ P (for threshold).
Output: DP top-𝑘.
1: Split users in 𝑔 =
2: for group 𝑖 ← 1 to 𝑔 do
3:
4:
5:
6:
7:
8:
9:
10:
11:
Initialize arrays ⟨𝑆⟩, ⟨𝐶⟩ of sizes 𝑘, 2⌈log 𝑘⌉+𝜂 with zeros
Initialize array ⟨𝐼⟩ ← {⟨1⟩, . . . , ⟨2⌈log 𝑘⌉+𝜂⟩}
Initialize ⟨𝜌𝜏 ⟩ ← ⟨0⟩ and ⟨𝜏⟩ ← ⟨0⟩
for candidate 𝑐 ← 1 to 2⌈log 𝑘⌉+𝜂 do
for user datum 𝑑 ∈ 𝐷𝑖 do //Gather prefix candidate counts
𝑑 ⟩) //Prefix bit-length: 𝑖 · 𝜂 + 𝛾
end for
end for
Sort candidate indices ⟨𝐼⟩ by their corresponding counts ⟨𝐶⟩ de-
scendingly //Appendix F
for party 𝑝 ∈ P do
⟨𝜌𝜏 ⟩ ← ADD(⟨𝜌𝜏 ⟩, ⟨𝜌𝑝 ⟩)
end for
⟨𝜏⟩ ← ADD(ADD(⟨𝜏PEM⟩, ⟨𝜌𝜏 ⟩), ⟨𝐶[2⌈log 𝑘⌉+𝜂]⟩)
for candidate 𝑐 ← 1 to 𝑘 do //DP thresholding on noisy 𝐶
⟨𝑏discard⟩ ← LE(⟨𝐶[𝑐]⟩, ⟨𝜏⟩)
⟨𝑆[𝑐]⟩ ← CondSwap(⟨⊥⟩, ⟨𝐼 [𝑐]⟩, ⟨𝑏discard⟩)
end for
return Rec(⟨𝑆⟩)
⟨𝐶[𝑐]⟩ ← ADD(⟨𝐶[𝑐]⟩, ⟨(cid:99)𝜁 𝑐
12:
13:
14:
15:
16:
17:
18:
19:
20:
21: end for
minimum count for the threshold), improving the complexity of
this step from 𝑂(𝑐 log 𝑐) to 𝑐 for 𝑐 = 2⌈log 𝑘⌉+𝜂 (leading to 𝑐 instead
of 𝑘 iterations for thresholding in line 16 of Algorithm 2).
4.3 Running Time Complexity
We analyse the running time of our protocols HH, PEM w.r.t. the
number of basic MPC protocols from Table 1. Addition is omitted,
as the parties can compute it locally on secret shares (i.e., “for
free”) and we measure the running time of our implementation in
Section 5. The complexity per protocol is listed in Appendix E, and
is at most 𝑂(𝑙) for 𝑙-bit integers.
Theorem 4. HH has complexity 𝑂(𝑛𝑡).
Proof. For each 𝑛 values in 𝐷 HH requires: First, 𝑡 equality
checks (EQ), comparisons (LE), and conditional swaps (CondSwap),
to find matching values and look for an empty index. Then, one
EQ, AND, and NOT operation to set bit 𝑏decrement. For the DP
threshold, 𝑡 LE and CondSwap operations are used. Finally, HH
sorts the small map, i.e., 𝑂(𝑡 log 𝑡), and reconstruct 𝑡 counts. Note
that 𝑛 is the dominating factor as 𝑡 ≪ 𝑛, i.e., 𝑛𝑡 > 𝑡 log 𝑡. Overall,
HH performs 𝑂(𝑛𝑡) operations.
(cid:109)
Theorem 5. PEM with sorting has complexity 𝑂(𝑔𝑐 log 𝑐), and
PEM without sorting has complexity 𝑂(𝑔𝑐), where 𝑔 =
and 𝑐 = 2⌈log 𝑘⌉+𝜂.
(cid:108) 𝑏−⌈log 𝑘⌉
□
𝜂
Proof. First, we consider PEM with sorting. For each group
PEM sorts all 𝑐 candidates which requires 𝑂(𝑐 log 𝑐) operations, and
Session 7D: Privacy for Distributed Data and Federated Learning CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea 2367performs 𝑘 comparisons (LE) and conditional swaps (CondSwap).
Finally, 𝑘 (sorted) indices are returned. Overall, PEM with sorting
requires 𝑂(𝑐 log 𝑐) operations per group.
PEM, without sorting, requires 𝑐 comparisons per group to find
the lowest candidate count (used in the threshold). Then, PEM
iterates over 𝑐 elements per group (instead of 𝑘 elements as with
sorting). Finally, 𝑐 indices and counts are returned and the parties
can sort them themselves. Altogether, PEM without sorting requires
𝑂(𝑐) operations per group.
□
Note that the summation of user reports per prefix candidates
(line 8 in Algorithm 2) does not require any interaction between
the computation parties, as addition can be computed locally.
4.4 Privacy
Beimel et al. [14, Lemma 2.12] stated the following composition the-
orem for secure computation of differentially private mechanisms:
Theorem 6. Let Π be a protocol with one invocation of a black-box
access to some function 𝑓 . Let Π𝑓 be a protocol that securely computes
𝑓 with security parameter 𝜅 and coalitions of size up to 𝑡. Let Π′ be
as in Π, except that the call to 𝑓 is replaced with the execution of Π𝑓 .
If Π is (𝜖, 𝛿)-DP with coalitions of size up to 𝑡, and 𝛿𝜅 = negl(𝜅) then
Π′ is (𝜖, (exp(𝜖) + 1)𝛿𝜅 + 𝛿)-DP with coalitions of size up to 𝑡.
Thus, together with Theorems 1, 2, our secure implementations
HH and PEM are (Δ𝜖, (𝑒𝜖 + 1)𝛿𝜅 + 𝛿)- and (Δ𝜖,(𝑒𝜖 + 1)𝛿𝜅 + 𝛿
4 (𝑒Δ𝜖 +
1)(3 + log(Δ/𝛿)))-DP, resp. PEM requires multiple invocations but
over disjoint subsets of the data.
4.5 Security
We consider the semi-honest model introduced by Goldreich [45]
where corrupted protocol participants do not deviate from the pro-
tocol but gather everything created during the run of the protocol.
Our protocols HH and PEM consists of multiple subroutines real-
ized with MPC protocols listed in Table 1. To analyze a protocol’s
security, we apply the well-known composition theorem [45, Section
7.3.1]: MPC protocols using an ideal functionality remain secure
if the ideal functionality is replaced with an MPC protocol im-
plementing the functionality. We implement ideal functionalities
FHH, FPEM as HH, PEM with MPC frameworks MP-SPDZ [53] and
SCALE-MAMBA [4] (see Section 5).
More formally, to prove semi-honest security we show the exis-
tence of a simulator Sim such that the distributions of the protocol
transcript of secure implementation Π is computationally indistin-
guishable from simulated transcript using ideal functionality F
produced in an “ideal world” with a trusted third party [45], [41,
Def. 2.2]. Next, we formalize the ideal and real-world executions,
ideal and real:
, {𝑦𝑖}𝑖∈P) ← realΠ(𝜅, C, {𝑥𝑖}𝑖∈P), receives as
• ({VIEW𝑖
input security parameter 𝜅, the set C ⊂ P of corrupted par-
ties, and each parties input 𝑥𝑖. Then, the real-world execution
runs protocol Π, with each party 𝑖 ∈ P behaving honestly
using its own input 𝑥𝑖, and outputs the view of all corrupted
parties (i.e., all exchanged messages and internal state), as
well as the final output 𝑦𝑖 of each party.
• (S, {𝑦𝑖}𝑖∈P) ← idealF,Sim(𝜅, C, {𝑥𝑖}𝑖∈P), with the same
inputs, uses the ideal functionality F to compute {𝑦𝑖}𝑖∈P ←
Π}𝑖∈C
F ({𝑥𝑖}𝑖∈P). Then, the ideal-world execution runs simulator
S ← Sim(C, {(𝑥𝑖, 𝑦𝑖)}𝑖∈C) (i.e., simulator receives the set of
corrupted parties and their in/outputs) to create simulation
S, and output it along with the output of the parties.
An adversary in the ideal world learns nothing except the proto-
col inputs and outputs, hence, if he cannot distinguish simulated
transcripts (ideal world) from actual transcripts (real world), he
learns nothing in real-world implementations. Now we show the
existence of simulators for our protocols.
Theorem 7. Protocol HH realizes FHH in the presence of semi-
honest adversaries.
)
Proof. Simulator Sim, given final outputs 𝑉 , 𝐶 (i.e., {𝑦𝑖}𝑖∈P
can produce a transcript for realHH by replacing all secret shared
values with randomness. Note that all values in our protocols are
secret shared (marked with ⟨·⟩) and computationally indistinguish-
able from randomness (except with negligible probability in the
security parameter for some operations, e.g., integer comparisons
[4]). The only values that are not secret shared are publicly known
iteration counts (i.e., data size and map size 𝑡 for HH, and number
of groups and number of candidates in PEM). Finally, the simula-
tor ensures the expected reconstruction, i.e, 𝑉 , 𝐶, is produced by
Rec(𝑉), Rec(𝐶). Here, the corrupted parties, cannot distinguish ac-
tual from simulated reconstruction as they cannot see the actual
randomness (secret shares) from the other parties.
□
Theorem 8. Protocol PEM realizes FPEM in the presence of semi-
honest adversaries.
Proof. We focus on a transcript for one group of PEM, which
can be extended to all groups. Simulator Sim, given 𝑆, produces
a transcript of realPEM as follows: As before, Sim replaces all se-
cret shared values with randomness. Then, in the thresholding
step, the index for each candidate 𝑐, i.e., 𝑆[𝑐] is set such that the
reconstruction of 𝑆 provides the expected result.
From Semi-honest to Malicious: We consider semi-honest
computation parties and design our protocol accordingly. How-
ever, SCALE-MAMBA provides malicious security, i.e., consistency
within the computation is ensured and malicious tampering can
be detected. We employ (𝑡, 𝑚)-secret sharing, which prevents up
to 𝑡 − 1 malicious parties to reconstruct the secret. Still, malicious
parties (input parties or computation servers) can provide incorrect
initial inputs to skew the results, also known as a data poisoning
attack. Next, we discuss the affect of poisoning attacks on our pro-
tocol as well as potential (but not implemented) mitigations. In
general, LDP protocols are vulnerable to data poisoning attacks
[22, 24]. Cryptographic tools, however, can prevent data poisoning
attacks and such attacks have limited impact on our protocols HH
and PEM: For HH, each input party provides a single value, which
can change a count by at most 1; thus, a coalition of 𝑐 malicious
parties, can alter the count by at most 𝑐. For PEM, each input party
provides a single bit indicating if a prefix matches their value’s pre-
fix (1) or not (0). Thus, 𝑐 malicious parties, can skew the result by at
most 𝑐. (However, this requires additional zero-knowledge proofs,
ensuring that the provided value is from {0, 1} without revealing
it, e.g., [28, 65].) Distributed noise generation in the presence of
□
Session 7D: Privacy for Distributed Data and Federated Learning CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea 2368malicious parties is not possible without additional checks or as-
sumptions. E.g., assuming 𝑐 malicious parties, all parties have to
provide more noise4 as the malicious parties might not provide any
noise (or hide additional counts in the noise). To achieve optimal
noise magnitudes in the presence of malicious parties the Laplace
5
noise can be sampled securely: Given a uniform random 𝑟 ∈ (0, 1]
one can sample Laplace(𝑏) as ±𝑏 log(𝑟). However, this incurs addi-
tional computation costs [5], which we do not consider, since we
assume semi-honest parties like most LDP protocols [11, 12, 40, 42].
Outsourcing: To outsource the computation the 𝑛 input parties
send shares of their input to 𝑚 computation parties which run the
secure computation on their behalf. The latter can be a subset of
the input parties or non-colluding untrusted servers (e.g., multiple
cloud service providers). After sending their secret shared value for
HH or candidate counts for PEM the input parties can go offline.
5 EVALUATION
We implement our protocols with SCALE-MAMBA [4] (malicious
security) as well as MP-SPDZ [53] (semi-honest security) using
Shamir secret sharing with honest majority, and default settings,
i.e., 128-bit modulus and statistical security parameter 𝜅 = 40. Code
can be largely re-used between these frameworks as MP-SPDZ [53]
is a fork of SCALE-MAMBA’s predecessor SPDZ2.