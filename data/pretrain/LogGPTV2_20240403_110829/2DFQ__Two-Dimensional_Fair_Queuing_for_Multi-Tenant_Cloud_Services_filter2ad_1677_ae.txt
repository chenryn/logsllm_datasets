We compare zDFQ to WFQ and WFzQ as baseline algorithms. In addition to these, we implemented several other algorithms, including SFQ [zh], MSFzQ [˙], and DRR [(cid:254)§]. However, we have excluded these from our evaluation because their results were visually indistinguishable from either WFQ or WFzQ. The key differences between these algorithms are incidental to their fairness bounds.

For example, since we do not use a variable rate server, the primary feature of SFQ is not necessary, and SFQ and WFQ produce nearly identical schedules. Similarly, WFzQ and MSFzQ yield nearly identical results. MSFzQ's distinguishing feature handles cases where one tenant has a high weight or when few tenants share many links. In our evaluation, we consider many tenants (up to several hundred) with equal weights, making this feature less relevant.

Furthermore, algorithms such as DRR [(cid:254)§] and WFzQ+ [(cid:254)] improve algorithmic complexity but do not enhance fairness bounds or add additional features. In practice, they exhibit similar or worse behavior compared to WFQ or WFzQ.

### Evaluation Metrics
To evaluate the schedulers, we use the following metrics:

- **Service Lag**: The difference between the service a tenant should have received under GPS and the actual work done. For N threads with a processing rate r, we use a reference GPS system with a rate of Nr.
- **Service Lag Variation**: The standard deviation (σ) of service lag. Bursty schedules have high service lag variation due to oscillations in service.
- **Service Rate**: Work done measured in ¸§§ms intervals.
- **Latency**: Time between the request being enqueued and finishing processing. We focus on the 99th percentile of latency unless otherwise noted.
- **Gini Index**: An instantaneous measure of scheduler fairness across all tenants [(cid:13)(cid:146)].

### Evaluation Summary
Our evaluation of zDFQ shows that:

- When request costs are known, for both synthetic (§@.¸.¸) and real-world (§@.¸.z) workloads, zDFQ provides service with one to two orders of magnitude reduction in service lag variation for small and medium tenants.
- When many tenants have expensive requests, zDFQ maintains low service lag variation for small tenants (§@.¸.¸).
- When request costs are unknown, zDFQE reduces the service lag variation by one to two orders of magnitude for small and medium tenants (§@.z.z).
- With increasingly unpredictable workloads, zDFQE improves the tail latency of predictable tenants by up to 100× (§@.z.¸) and up to 50× (§@.z.z).

### 6.1 Known Request Costs

#### 6.1.1 Expensive Requests
In this experiment, we simulate the service received by 100 backlogged tenants sharing a server with 10 worker threads, each with a capacity of 1000 units per second. For varying values of n, we designate n of the tenants as small and 100 - n of the tenants as expensive. Small tenants sample request sizes from a normal distribution with a mean of 1 and a standard deviation of 0.5; large tenants sample request sizes from a normal distribution with a mean of 1000 and a standard deviation of 100.

Figure ˙a examines the service received over a 10-second interval for one of the small tenants, T, when 50% of the tenants are expensive (n=50). Since the thread pool has 10 threads, the ideal schedule would split cheap and expensive requests into separate threads, producing steady service of 100 units per second per tenant. Figure ˙a (top) shows that the service provided by WFQ has large-scale oscillations. This occurs because WFQ alternates between phases of servicing all 50 small tenants, followed by all 50 large tenants, in bursts of up to 1000 units per tenant. Figure ˙a (bottom) plots the service lag over time, showing that small tenants oscillate between 1 and 2 seconds ahead of their fair share, with a period of approximately 0.5 seconds.

Small tenants are consistently ahead of their fair share because small requests have the earliest finish time, so WFQ services them first. WFzQ has less long-term oscillation but suffers from more extreme oscillations over shorter time scales; the small tenant receives no service for almost a second. By design, WFzQ prevents T from getting too far ahead of its fair share, but due to the presence of expensive tenants, T continually falls behind by up to 1 second. This occurs because WFzQ determines that all small tenants are ineligible and schedules expensive requests to run on every worker thread, as illustrated in Figure ˙b.

Finally, the service provided by zDFQ is more stable, with occasional oscillations characterized as a period of slightly reduced service followed by a burst of increased service. As illustrated in Figure ˙b (bottom), zDFQ mostly partitions requests by size across the threads, and the remaining oscillations are a side effect of randomness in request sizes that enables expensive requests to temporarily run on 1 of the worker threads instead of 10.

We varied the proportion of expensive tenants n between 0 and 100 and show the resulting standard deviation of service lag in Figure ˙c. WFQ and WFzQ experience a linear increase in standard deviation as the proportion of expensive tenants grows. WFQ grows unboundedly, whereas WFzQ eventually plateaus. With only 5% of the workload comprising expensive tenants, WFzQ converges to its worst-case behavior. On the other hand, while zDFQ also sees gradually increased standard deviation, it is an order of magnitude lower compared to other schedulers.

#### 6.1.2 Production Workloads
In this experiment, we evaluate the fair share provided by zDFQ with a workload derived from production traces of Azure Storage. We simulate the service received by tenants sharing a server with 16 worker threads, each with a capacity of 1 million units. We replay 160 randomly chosen tenants drawn from workload traces of 16 servers. In aggregate across all tenants, request costs for this experiment vary from 100 to 1 million.

We first illustrate the improved service for tenants with small requests. Figure (cid:146)a (top) shows a 10-second time series for T1, comprising primarily small requests between 100 and 1000 in size. Figure (cid:146)a (middle) plots T1’s service lag. Under WFQ, the service received oscillates between 3s and 3.6s ahead of GPS. WFzQ more closely matches GPS but occasionally falls behind by up to 50ms due to the thread pool becoming occupied by expensive requests. zDFQ (the horizontal red line) closely matches GPS at all times. Figure (cid:146)a (bottom) plots the Gini index [(cid:13)(cid:146)] over time, an aggregate measure of fairness across all tenants. WFQ is significantly less fair in aggregate, while zDFQ and WFzQ are comparable.

Figure (cid:146)b illustrates the sizes of requests running on threads during the experiment. Service spikes under WFzQ correlate with several large requests occupying threads simultaneously. zDFQ partitions requests across threads according to request size, avoiding such spikes. Figure ¸§ plots a CDF of the service lag standard deviations across all tenants included in the experiment. A low standard deviation is desirable, as it corresponds to fewer oscillations in service. The figure shows that the first quartile of tenants have approximately 50x lower standard deviation under zDFQ than WFzQ and 100x lower standard deviation under zDFQ than WFQ. These tenants are the ones with primarily small requests.

To more precisely understand how zDFQ impacts tenants based on request sizes, we repeat the experiment and include an additional seven tenants, t1 . . . t7. These tenants submit requests with fixed costs of 10, 100, 1000, ..., 100000 respectively (from 100 to 1 million), spanning the range of costs in our workload. Figure ¸§ (right) plots the distribution of service lag experienced by t1 . . . t7 under WFQ, WFzQ, and zDFQ. Each distribution shows how much the tenant deviates from its fair share. Under all schedulers, large requests (t7) experience a wide range of service lag because service is received in large, coarse-grained bursts. For progressively smaller requests (t1 . . . t6), WFQ reduces service lag to a range of 0.2 seconds; WFzQ reduces it to 0.5 seconds, while zDFQ reduces it to 0.05 seconds. These results illustrate how zDFQ particularly improves the service received by tenants with small requests.

### 6.2 Unknown Request Costs

Our second set of experiments evaluates schedulers when request costs are not known a priori. We compare zDFQE (α = 0.99) to variants of WFQ and WFzQ that estimate request costs using per-tenant per-API exponential moving averages (α = 0.99). We refer to them, respectively, as WFQE and WFzQE. We also implemented both retroactive charging and refresh charging for WFQE and WFzQE. Without these techniques, we found that the quality of schedules deteriorated by a surprising amount. It turned out to be relatively common for workloads to have back-to-back requests that differ by several orders of magnitude; without retroactive charging, it takes too long to incorporate measurements back into the moving average to rectify estimation error. For the same reason, without refresh charging, it would quickly lead to multiple large requests taking over the thread pool. Since the bookkeeping techniques are straightforward to implement, we applied them to all algorithms, and our experiment results only reflect the differences between scheduling logic and estimation strategy.

#### 6.2.1 Unpredictable Workloads
In this experiment, we evaluate zDFQE’s pessimistic cost estimation strategy, demonstrating how it co-locates unpredictable tenants.