,
E
≈
j
σ′
. . .
≈
A2
O
≈
I
,
E
≈
σ′
k
e
e
. . .
. . .
Figure 2: Integrity property
Figure 2 shows the two traces from the integrity property. The
adversary’s steps are labelled A1 and A2 while the enclave’s steps
are labelled e. Assumptions are annotated in blue, and proof obli-
gations are shown in red. The enclave’s inputs are assumed to be
the same in both traces; this is shown by the ≈I symbol. The ini-
tial state of the two enclaves is assumed to be the same and this
is shown by the ≈E symbol. The adversary’s actions are defined
by the tamper function (see § 2.2.1), and these actions may differ
between the two traces. The integrity proof must show that the
enclave’s state and outputs do not differ despite this:∀i. Ee (π1[i]) =
Ee (π2[i]) ∧ Oe (π1[i]) = Oe (π2[i]). These proof obligations are de-
noted by the red ≈E and ≈O symbols. We assume that the adversary
executes for the same number of steps in both traces. This does
not restrict the adversary’s power as any attack that requires the
adversary to execute for a different number of steps in the two
traces can be simulated in our model by padding the adversary’s
shorter trace with the appropriate number of “no-ops.”
The theorem states that, given the above assumptions, enclave
state and outputs are identical in the two traces at every step:
∀i. Ee (π1[i]) = Ee (π2[i]) ∧ Oe (π1[i]) = Oe (π2[i]).
3.1.3 Confidentiality. The enclave platform must ensure that
the attacker does not observe the enclave’s execution beyond what
is allowed by the observation function obs, which must include
the init and config components of the enclave’s description, out-
puts to non-enclave memory, exit events from enclave mode to
untrusted code, and other side channels leakage as permitted by
the observation function obs. The privileged software attacker may
use any combination of machine instructions to perform an attack,
and the attacker should observe the same results from executing
these instructions for any pair of enclaves that produce the same
observation via the function obs. In other words, all enclave traces
with the same observations, but possibly different enclave states,
must be indistinguishable to the attacker. If a platform allows the
attacker to observe different values in two such traces, we say that
such a platform does not provide confidentiality.
Formally, to prove that an attacker learns no other information
beyond obs, we must prove that for any two traces that have equiva-
lent attacker operations and equivalent observations of the enclave
execution, but possibly different enclave private states and execu-
tions, the attacker’s execution (its sequence of states) is identical.
(cid:16)
∀π1, π2.
Ae1 (π1[0]) = Ae2 (π2[0])
∀i. curr (π1[i]) = curr (π2[i]) ∧ I P (π1[i]) = I P (π2[i])
(cid:16)∀i. Ae1 (π1[i]) = Ae2 (π2[i])
∀i. curr (π1[i]) = e =⇒ obse1 (π1[i + 1]) = obse2 (π2[i + 1])
(cid:17)
(cid:17)
(5)
∧
∧
=⇒
property ensures that the attacker does not learn more informa-
tion than what the enclave wishes to reveal. Together, these three
properties imply SRE.
SRE is useful for building practical trusted applications. Consider
the problem of executing a batch job securely in the cloud. The
user sends an enclave program, which implements a function on
sensitive data, to an enclave platform in the cloud. The protocol
includes the following steps:
A
A
σ0
A
≈
σ′
0
. . .
σi
A
≈
. . .
σ′
i
e1
e2
σi +1
≈
s
b
o
A
≈
σ′
i +1
A
A
σi +2
. . .
σj
A
≈
σ′
i +2
A
≈
σ′
j
. . .
e1
e2
σk
≈
s
b
o
A
≈
σ′
k
A
A
. . .
. . .
Figure 3: Confidentiality property
Figure 3 depicts the confidentiality property. As in Figure 2, the
attacker’s steps are labelled A while the enclave’s steps are labelled
e1 and e2. The two traces start off in equivalent states (shown by
the blue ≈A) but diverge (at state σi) because the two enclaves may
perform different computation. The enclave’s adversary-visible
observations are assumed to be the same in both traces when the
enclave is executing (shown by the blue obs≈). Adversary non-
determinism, I P (σ ), is assumed to be the same in both traces and
this ensures that adversary actions (defined by the tamper function
from § 2.2.1) are the same in both traces. The theorem states that
adversary state is identical at every step:∀i. Ae1 (π1[i]) = Ae2 (π2[i])
and is illustrated by the red ≈A. The theorem implies that adversary
state is a deterministic function of only adversary actions and initial
state. In particular, adversary state does not depend on enclave
state. This shows that the attacker has not learned any additional
information beyond the observation function.
3.2 Soundness of SRE Decomposition
Theorem 3.2. An enclave platform that satisfies secure measure-
ment, integrity, and confidentiality property for any enclave program
also satisfies secure remote execution.
Proof Sketch: Suppose that the user sends an arbitrary enclave e to
a remote server for execution, and the platform launches enclave er
some time later — because e is sent over an untrusted channel, e may
or may not equal er . If the user finds µ (er ) (cid:44) µ (e), then the platform
has no obligations to execute a trace from(cid:74)e(cid:75). Otherwise, if µ (er ) =
µ (e), we have that(cid:74)er(cid:75) = (cid:74)e(cid:75) thanks to the measurement and
integrity properties. So, the two programs have identical runtime
behaviors, which is a prerequisite for SRE. Finally, confidentiality
implies that the attacker’s observation is restricted to obs.
3.3 Application of Secure Remote Execution
The measurement and integrity properties guarantee that the re-
mote platform executes a trace from(cid:74)e(cid:75), while the confidentiality
6
(1) The user sends an enclave program e to the cloud provider,
which launches the program on an enclave platform.
(2) The user and enclave establish an authenticated TLS channel
via an ephemeral Diffie-Hellman (D-H) exchange.
(a) User sends her public parameter дx to the enclave, where
x is a randomly generated fresh value.
(b) Enclave sends its public parameter attest(дy ) to the user,
in the form of an attested statement, thus guaranteeing
that a genuine enclave platform launched the expected
enclave e.
(c) User and enclave compute a shared master secret дxy, and
derive symmetric session keys sue and seu, a key for each
direction.
(3) The user now sends encrypted input to enclave using this
shared secret: {in}sue
and returns the encrypted result to the user: {out}seu
(4) The enclave decrypts its input, performs the computation
.
.
Consider the following security property: the attacker neither
learns secret input {in} nor the secret output {out}. To that end, the
user 1) develops an enclave program that only accepts encrypted
inputs and sends encrypted outputs, and 2) specifies an observation
function (obs) where a privileged software adversary is only allowed
to view the enclave’s outputs to non-enclave memory — this is
acceptable because e encrypts its outputs.
The measurement guarantees that the user will only establish a
channel with the expected enclave on a genuine enclave platform.
Integrity ensures that the platform will execute a trace from(cid:74)e(cid:75),
thus respecting e’s semantics. The platform may choose to not
launch e or prematurely terminate e, but such executions will not
generate {out}seu
and hence can be trivially detected by the user. In-
tegrity also ensures that the platform does not rollback the contents
of enclave’s memory while it is alive (i.e., not destroyed) as such
from(cid:74)e(cid:75), and SRE guarantees(cid:74)e(cid:75). SRE does not require the plat-
attacks will cause the enclave’s execution to proceed differently
form to defend against rollback attacks on persistent storage. This
protection is not needed for the batch service because the enclave
does not update {in}sue
will fail the
cryptographic integrity checks. Finally, confidentiality ensures that
the enclave platform only reveals the obs function of enclave’s exe-
cution to the software attacker, which only includes the encrypted
outputs. We now have our end-to-end security property.
, and any tampering to {in}sue
Should the enclave require state beyond enclave’s memory to
perform the job, it would require integrity, freshness, and confi-
dentiality for non-enclave state, which is not covered by SRE. The
enclave can implement cryptographic protections (e.g., Merkle tree)
and techniques for state continuity [57] to address this concern.
Type
State Var.
VA
pc
N → W
regs
PA → W
mem
VA → (ACL × PA)
addr_map
(Set × Way) → (B × Tag) Cache: map from a tuple of cache sets and ways to valid bits and cache tags.
cache
Eid
current_eid
PA → Eid
owner
enc_metadata Eid → EM
EM
os_metadata
Description
The program counter.
Architectural registers: map from natural numbers to words.
The memory: a map from physical addresses to words.
Map from virtual addresses to permissions and physical addresses for current process.
Current enclave. current_eid = OS means that no enclave is being executed.
Map from physical address to the enclave address is allocated to.
Map from enclave ids to metadata record type (EM).
Record that stores a checkpoint of privileged software state.
Table 1: Description of TAP State Variables
4 THE TRUSTED ABSTRACT PLATFORM
The trusted abstract platform (TAP) consists of a processor with a
program counter, general purpose registers, virtual address trans-
lation and a set of primitives to support enclave execution. In this
section, we first introduce a formal model of the TAP. We present
a range of adversary models with varying capabilities. We then
present a set of machine-checked proofs showing that the TAP
satisfies the properties required for secure remote execution: (i)
secure measurement, (ii) integrity and (iii) confidentiality.
4.1 TAP Model
Recall that the TAP is modeled as a finite state transition system:
TAP = (Σ, ;, init). Σ is the set of states, ; is the transition relation
and init ∈ Σ is the initial state.
4.1.1 TAP State Variables. The states Σ of the TAP are a de-
fined as a valuation of the state variables Vars. These variables
are described in Table 1. pc, regs, mem have their usual meanings.
addr_map maps individual virtual addresses to physical addresses
and permissions. This is unlike a typical processor which uses a
page table to map virtual page numbers to physical page numbers.
The TAP is an abstraction and must abstract a diverse set of architec-
tures with different page table structures and page sizes. Therefore,
it maps each virtual address to a physical address.
The TAP models a cache to show that confidentiality is preserved
in the presence of a software adversary attempting cache attacks.
The cache model assumes a physically-indexed and physically-
tagged cache with symbolic parameters: an unbounded number
of sets, unbounded associativity, and an arbitrary deterministic
replacement policy. The TAP cache model leaves the mapping of
physical addresses to cache sets and mapping of physical addresses
to cache tags uninterpreted. In other words, the TAP formalism
applies to a broad space of set associative caches, and only requires
that the cache set and cache tag for each memory access be deter-
ministic functions of the physical address. The exact functions and
parameters are specified by implementations (refinements) of TAP,
which are models of SGX and Sanctum in this paper.
The variable current_eid tracks the enclave currently being
executed. owner maps each physical address to the enclave which
exclusively “owns” it. If owner[p] = e, only enclave e can access
(fetch/read/write) this word of memory. We abuse notation and
use e to refer to both the “enclave id,” a unique integer assigned
by the platform to an enclave, as well the enclave itself. Attempts