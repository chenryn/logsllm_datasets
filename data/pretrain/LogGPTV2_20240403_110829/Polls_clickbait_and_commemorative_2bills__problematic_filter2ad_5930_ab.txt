and two uncompetitive (Seattle, WA; Salt Lake City, UT).
‚Ä¢ Nov. 13, 2020 ‚Äì Dec. 8, 2020: Due to contested election results,
we switched two crawlers to Phoenix, AZ and Atlanta, GA.
The other two crawlers alternated between the 4 previous
locations (Seattle, Salt Lake City, Miami, Raleigh).
‚Ä¢ Dec. 9, 2020 ‚Äì Jan. 19, 2021: After the presidential election
was resolved, we crawled from Atlanta, GA and Seattle, WA
to observe the Georgia special election. Due to the Capitol
insurrection, we continued crawling for 2 weeks.
To simulate crawling from these locations, we tunneled our
traffic through the Mullvad VPN service. Mullvad‚Äôs VPN servers
ran on rented servers in local data centers (100TB, Tzulo, and M247).
We verified that the VPN servers were located in the advertised
locations using commercial IP geolocation services.
In sum, we ran 312 daily crawls, on 4 machines, using Chromium
88.0.4298.0, on a Debian 9 Docker image. The hardware was: Intel
Core i7-4790 3.6GHz 32GB RAM, Intel Core i7-7740X 4.3 GHz 64GB
RAM, and Intel Core i5-6600 3.30GHz, 16GB RAM (2x).
3.1.4 Data Collection Errors. No data was collected globally from
10/23‚Äì10/27 (VPN subscription lapsed), nor 12/16‚Äì12/29 and 1/15‚Äì
1/19 in Seattle (VPN server outage). Some individual crawls also
sporadically failed. In total, 33 of 312 daily crawl jobs failed.
3.2 Preprocessing Ad Content
3.2.1 Extracting Text from Ads. To enable large-scale analysis of
the content of our dataset, we extracted the text of each ad. For
IMC ‚Äô21, November 2‚Äì4, 2021, Virtual Event, USA
Eric Zeng, Miranda Wei, Theo Gregersen, Tadayoshi Kohno, Franziska Roesner
ads where 100% of the visual content is contained in an image,
we used the Google Cloud Vision API to perform optical character
recognition (OCR). We extracted text from 877,727 image ads (62.6%)
using this method. For native ads (i.e., sponsored content headlines),
the text is contained in the HTML markup, so we automatically
extracted the text from these ads using JavaScript. We extracted
text from 524,518 native ads (37.4%) using this method.
3.2.2 Ad Deduplication. Many ads in our dataset appeared multi-
ple times, some appearing tens of thousands of times. To reduce
redundancy during qualitative coding and the runtime of machine
learning tasks, we de-duplicated ads using the extracted text. We
grouped our dataset by the domain of the landing page of the ad,
and for each group, we used MinHash-Locality Sensitive Hashing1
(LSH) to identify ads with a Jaccard similarity > 0.5. We maintained
a mapping of unique ads to their duplicates, which we used later
to propagate qualitative labels for unique ads to their duplicates,
enabling analysis of the whole dataset. After deduplication, we
obtained a subset of 169,751 unique ads.
3.3 Analyzing Ad Content with Topic Modeling
To help us broadly understand the content of the ads in our dataset,
we used topic modeling to automatically create groups of semanti-
cally similar ads, allowing us to qualitatively analyze those groups.
We experimented with several topic modeling and text clustering
algorithms, and selected Gibbs-Sampling Dirichlet Mixture Model
(GSDMM) [94], which performed best on our dataset (see our ex-
perimental methodology in Appendix B). Second, we automatically
generated qualitative descriptions of each ad cluster, by using c-tf-
idf to extract the most significant words from the text cluster [33].
We applied GSDMM & c-tf-idf to describe the topics in our overall
ads dataset (Sec. 4.3) and political product ads (Sec. 4.7).
3.4 Analyzing Political Ads In-Depth
Our main focus is the content of political ads in our dataset. We de-
fined a political ad broadly: any ad with political content, whether or
not the advertiser was a political campaign. This includes ads with
incidental political content, such as ads for products incorporating
election imagery or ads promoting political news articles.
Our analysis of political ads consisted of three phases. First, we
used machine learning to automatically identify political ads in our
overall ads dataset. Second, we manually labeled the attributes of
each political ad, such as the purpose of the ad, and the advertiser‚Äôs
political affiliation. Lastly, we performed quantitative analyses of
the labeled political ad data.
3.4.1 Political Ads Classifier. To analyze political ads, we first
needed to isolate political ads from the overall ads dataset. We
implemented a binary text classifier based on the BERT language
model, to classify our ads as political or non-political.
We started by generated a training set of political and non-
political ads by labeling a random sample of ads in our dataset,
obtaining 646 political ads and 1,937 non-political ads. We supple-
mented this data by crawling 1,000 political ads from the Google
political ad archive [30] to balance the classes. We implemented
1We used the MinHash LSH implementation from the datasketch Python library:
http://ekzhu.com/datasketch/lsh.html.
the classifier by fine-tuning the DistilBERT model [76] for a binary
classification task. We trained our model with a 52.5% / 22.5% / 25%
Train / Validation / Test split. Our model achieved an accuracy of
95.5%, and an ùêπ1 score of 0.9. We ran the classifier on our dedupli-
cated dataset (169,751 unique ads) and it classified 8,836 unique ads
as political (5.2%).
3.4.2 Qualitative Analysis of Political Ads. Next, we we qualita-
tively coded the 8,836 unique political ads in our dataset to build
a systematic categorization of the ads‚Äô content and characteris-
tics [74]. Prior work in computer science and political science has
also analyzed ad content using qualitative coding [85, 96]. We de-
scribe the development of our qualitative codebook and coding
methods in detail in Appendix C.
Codebook Summary. We describe the high level categories of
our codebook; a full list of subcodes is presented in Table 2, and a
full set of definitions in Appendix C. We identified three mutually
exclusive categories at the top level. (1) Campaigns and Advo-
cacy ads explicitly addressed a political candidate, election, policy,
or call to action. We further coded the Election Level, Ad Purpose,
Political Affiliation, and Organization Type. We coded Election Level
based on the level of government, and Purpose based on the desired
action in the ad. We coded Organization Type by first identifying
the advertiser, using ‚ÄúPaid for By...‚Äù labels and the landing page
content, and then looking up the legal registration of the adver-
tiser. We coded Affiliation if the advertiser was officially associated
with a political party, or indicated alignment with words such as
‚Äúconservative‚Äù. We were able to attribute an organization type and
advertiser affiliation for 96.5% of the campaigns and advocacy ads.
(2) Political News and Media ads promoted political news articles,
videos, news sources, or events. We further demarcated two sub-
categories. Sponsored Articles / Direct Links to Articles included ads
which promoted a specific article or piece of content. News Outlets,
Programs, Events, and Related Media contained all other types of
political news and media. (3) Political Products ads centered on
selling a product or service by using political imagery or content.
We labeled political product ads as either Political Memorabilia,
Nonpolitical Products Using Political Topics, or Political Services. Ads
were labeled as (4) Malformed/Not Political if the classifier iden-
tified the ad as political, but the content was occluded, incorrectly
cropped, or contained multiple ads, in a way that made it impossible
to analyze the ad. False positives (ads incorrectly labeled as political
by the classifier) were also given this label.
3.5 Ethics
Our data collection method had two types of impacts on the web.
First, our crawler visited web pages and scraped their content. We
believe this had a minimal impact: all sites we visited were public-
facing content websites, contained no user data, and were visited
by our crawlers no more than 4 times per day.
Second, our crawler clicked on ads to scrape the landing page
of the ads. By clicking on the ads, we may cause the advertiser
to be charged for the clickthrough (unless our click is detected as
illegitimate), which is paid to the website and various middlemen.
We determined that clicking on ads was necessary because it
was the only way for us to obtain the content and URL of the
Polls, Clickbait, and Commemorative $2 Bills:
Problematic Political Advertising on News and Media Websites Around the 2020 U.S. Elections
IMC ‚Äô21, November 2‚Äì4, 2021, Virtual Event, USA
landing page for each ad. Many ads obscure their landing page
through nested iframes and redirect chains. This data was needed
for automatically determining the identity of the advertiser and for
manually investigating the landing pages during qualitative coding
(when the ad itself did not have sufficient context).
It is difficult to estimate the costs incurred to advertisers as a
result of our crawls, but we believe the amount was low enough to
be inconsequential. We cannot precisely determine the cost because
the bid for each ad is not visible, and we do not know if advertisers
pay using a cost-per-impression model or cost-per click model. For
advertisers who pay based on impressions, we estimate the amount
charged to be $3.00 per thousand impressions [87]. If all advertisers
paid by impression, we estimate the total cost to all advertisers to be
approximately $4,200. For the average advertiser, the mean number
of ads we crawled was 63, and the median was 3, resulting in a mean
cost of $0.19, and median cost of $0.009. If advertisers instead paid
per click, we estimate a cost of approximately $0.60 per click [39]: in
this case, the the mean advertiser would have been charged $37.80,
and the median would have paid $1.80. The outlier advertisers
in our dataset who received the most clicks were predominantly
intermediary entities, such as Zergnet (36k ads), mysearches.net
(26k ads), and comparisons.org (9k ads). These intermediaries place
ads on other websites on behalf of advertisers on their platform,
meaning that costs incurred for these intermediaries were spread
among many individual sub-advertisers.
Stepping back, as we discuss further in Section 5, because of the
distributed nature of the web ad ecosystem and the complex incen-
tives of different stakeholders, we believe it is critical that external
audits investigate the content and practices in this ecosystem, as
we do in this study. Towards that end, we believe that the (small)
costs of our study were justified. It is only through the process of
clicking on ads, and evaluating the resulting landing pages, that can
one fully understand the impact to users if they were to click on
the ads. This is akin to the observation that malware websites may
be linked from ads, potentially requiring search engine companies
aiming to develop lists of known malware sites to engineer their
crawlers to click on ads [63]. Moreover, similar methodologies have
been used in prior works studying ads [67, 93].
3.6 Limitations
Our crawling methodology provided an incomplete sample of polit-
ical advertising on the web. Our crawlers only visited a finite set of
news and media websites, excluding other places that political ads
appear, e.g., Facebook. Because we only visited each site once, we
only saw a fraction of all ad campaigns running at that time. Our
crawlers also only see political ad campaigns that were served to
them ‚Äî ongoing political ad campaigns may not have been shown
to the crawler e.g. because of targeting parameters. We may have
failed to load landing pages for ads because of detection and ex-
clusion of our crawler by ad platforms. Due to VPN outages and
crawler bugs, some days are missing from the data (Sec. 3.1.4).
We relied on categorizations from the fact checkers AllSides [3]
and Media Bias/Fact Check [54] to identify the political bias of our
input websites. 42% of our input sites had a rating: some uncatego-
rized sites were non-political news websites (e.g., espn.com), while
others may not have been popular enough to be rated.
Our automated content analyses were based on text extracted
with OCR and did not use visual context from images. Some ads
contained text artifacts, which negatively impacted downstream
analyses. Based on the sample we labeled, we estimate that 18%
ads in our dataset were malformed, i.e., impossible to read the
ad‚Äôs content. This was typically caused by modal dialogs (such as
newsletter signup prompts) occluding the ad, which are difficult to
automatically and consistently dismiss.
For the majority of ads, our data did not allow us to identify
the ad networks involved in serving the ads. Though our crawler
collected the HTML content of each ad (including iframes), this
alone was rarely sufficient to identify ad networks.
Despite the above limitations, our dataset presents a unique and
large-scale snapshot of political (and other) web ads surrounding
the 2020 U.S. election. These include ads that do not appear in
Google‚Äôs (or others‚Äô) political ad transparency reports. To support
future research and auditing of this ecosystem, we will release our
full dataset along with the publication of this paper, including ad
and landing page screenshots, OCR data, and our qualitative labels.
4 RESULTS
In this section, we present an analysis of the ads in our dataset. We
begin by providing an overview of the dataset as a whole, including:
How many ads appear overall, and how many of these are political
ads of different types (Sec. 4.1)? How did the number of ads (political
and non-political) change over time and location (Sec. 4.2)? Overall,
what ad topics were common (Sec. 4.3)?
Then, we dive more deeply into our analysis of political ads. We
investigate and characterize the sites political advertising appeared
on (Sec. 4.4), advertisers running official campaign and advocacy
ads (Sec. 4.5), misleading/manipulative campaign ads (Sec. 4.6), and
political product ads (Sec. 4.7) and news and media ads (Sec. 4.8).
4.1 Dataset Overview
Between September 26, 2020 and January 19, 2021, we collected
1,402,245 ads (169,751 unique ads) from 6 locations: Atlanta, Miami,
Phoenix, Raleigh, Salt Lake City, and Seattle. Our political ad classi-
fier and qualitative coding, detected 67,501 ads (8,836 unique) with
political content, or 3.9% of the overall dataset. During our qualita-
tive analysis of political ads, we removed 11,558 false positives and
malformed ads (3,201 unique), resulting in 55,943 political ads. In
Tab. 2, we show the number of political ads, across our qualitative
categories. About a third of ads were from political campaigns and
advocacy groups; over half advertised political news and media,
and the remainder political products.
4.2 Longitudinal and Location Analysis
4.2.1 Ads Overall. We show the quantity of ads collected by loca-
tion in Fig. 2a. The number of ads per day stayed relatively stable in
each location: consistently around 5,000 ads per day. The stability
in ad counts indicates that changes in demand for ad space before
and after the election had little impact on websites‚Äô ad inventory.
We collected about 1,000 fewer ads per crawler day in Atlanta
than other locations. We do not know if this was due to differ-
ences in location-based targeting or an artifact of our crawling (e.g.,
limitations of the Atlanta VPN provider).
IMC ‚Äô21, November 2‚Äì4, 2021, Virtual Event, USA
Eric Zeng, Miranda Wei, Theo Gregersen, Tadayoshi Kohno, Franziska Roesner
(a) The number of ads collected in each crawler location. We collected a relatively constant number of ads for each location.
(b) The number of political ads, classified as political by our text classifier, collected in each crawler location. The number of political ads was
higher prior to the elections in November and January, were lower in the period after the elections.
Figure 2: Longitudinal graphs showing the number of total ads and political ads, collected in six locations from Sept. 2020 to Jan.
2021. Salient U.S. political events, as well as ad bans implemented by Google, are superimposed for context. Gaps from mid-Nov.
to mid-Dec. are because we scheduled crawls on nonconsecutive days. Other gaps are due to VPN outages (see Sec. 3.1.4).
4.2.2 Political Ads. The amount of political ads over time and
locations is visualized in Fig. 2b. Leading up to the presidential
election on Nov. 3, 2020, the number of ads per day in each location
increases from less than 250 to peaks of 450. After election day,
the number of political ads seen by crawlers sharply decreases, to
below 200 ads/day. This decrease could be a natural consequence
of less political attention following election day; it likely was also
due to Google‚Äôs first ad ban, from Nov. 4 to Dec. 10. We believe
Google‚Äôs ad bans help contextualize our results, given Google‚Äôs
large presence in web ads ‚Äî but because we did not determine the
ad networks used by each ad, we cannot prove a causal connection.
During Google‚Äôs first ban, we collected 18,079 political ads. 76%
of these ads were political news ads and political product ads. In the
4,274 campaign and advocacy ads during this period, 82% were from
nonprofits and unregistered groups, such as Daily Kos, UnitedVoice,
Judicial Watch, and ACLU. The remaining 18% (783 ads) were from
registered committees, some from candidates in special elections
(e.g., Luke Letlow, Raphael Warnock), but others from PAC groups
specifically referencing the contested Presidential election. For ex-
ample, an ad from the Democratic-affiliated Progressive Turnout
Project PAC reads: ‚ÄúDEMAND TRUMP PEACEFULLY TRANSFER
POWER ‚Äì SIGN NOW‚Äù.
Google lifted their political ad ban on Dec. 11. At this time, we
only collected data from Seattle and Atlanta, and observed a rise
in the number of political ads per day in Atlanta until the Georgia
run-off election on Jan. 5, 2021, but no corresponding rise in Seattle.
The increase in Atlanta came almost entirely from Republican-
affiliated committees ‚Äî Democratic-affiliated advertisers seem to
have bought very little online advertising for this election (Fig. 3).
Following the Georgia election, we again observed a sharp drop
in ads per day from the Atlanta crawler, matching the Seattle
crawler at less than 200 political ads per day.
Figure 3: Campaign ads observed in Atlanta in Dec 2020‚ÄìJan
2021, prior to the Georgia special elections. Almost all ads
during this time period were run by Republican groups.
Though we observe that the volume of political advertising gen-
erally fell after elections, Google‚Äôs ban on political advertising did
not stop all political ads ‚Äî other platforms in the display ad ecosys-
tem still served political advertising.
4.3 Topics of Ads in Overall Dataset
To provide context before diving into political ads (Sec. 4.4-4.8), we
present results from a topic model of the entire dataset.