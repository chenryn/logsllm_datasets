access pattern leakage? The leakage model includes memory
addresses accessed during program execution.
Variable-time operation leakage (S). Does the tool consider
variable-time operation leakage? The leakage model includes
inputs to variable-time operations (e.g., ﬂoating point opera-
tions [153]–[155], division and modulus operations on some
architectures) classiﬁed according to timing-equivalent ranges.
C. Discussion
Achievements: Automatic veriﬁcation of constant-time
real-world code. There are several tools that can perform
veriﬁcation of constant-time code automatically, both for high-
level code and low-level code. These tools have been applied
to real-world libraries. For example, portions of the assembly
code in OpenSSL have been veriﬁed using Vale [103], high-
speed implementations of SHA-3 and TLS 1.3 ciphersuites
have been veriﬁed using Jasmin [102], and various off-the-
shelf libraries have been analyzed with FlowTracker [137].
Takeaway: Lowering the target provides better guarantees.
Of the surveyed tools, several operate at the level of C code;
others operate at the level of LLVM assembly; still others
operate at the level of assembly or binary. The choice of target
is important. To obtain a faithful correspondence with the ex-
ecutable program under an attacker’s scrutiny, analysis should
be performed as close as possible to the executed machine
code. Given that mainstream compilers (e.g., GCC and Clang)
are known to optimize away defensive code and even introduce
new side-channels [156], compiler optimizations can interfere
with countermeasures deployed and veriﬁed at source-level.
Challenge: Secure, constant-time preserving compilation.
Given that mainstream compilers can interfere with side-
channel countermeasures, many cryptography engineers avoid
using compilers at all, instead choosing to implement crypto-
graphic routines directly in assembly, which means giving up
the beneﬁts of high-level languages.
An alternative solution is to use secure compilers that carry
source-level countermeasures along the compilation chain
down to machine code. This way, side-channel resistant code
can be written using portable C, and the secure compiler takes
care of preserving side-channel resistance to speciﬁc architec-
tures. Barthe et al. [150] laid the theoretical foundations of
constant-time preserving compilation. These ideas were sub-
sequently realized in the veriﬁed CompCert C compiler [157].
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:10:25 UTC from IEEE Xplore.  Restrictions apply. 
787
Unfortunately, CompCert-generated assembly code is not as
efﬁcient as that generated by GCC and Clang, which in turn
lags the performance of hand-optimized assembly.
Challenge: Protecting against micro-architectural attacks.
The constant-time policy is designed to capture logical timing
side channels in a simple model of hardware. Unfortunately,
this simple model is inappropriate for modern hardware, as
microarchitectural features, e.g., speculative or out-of-order
execution, can be used for launching devastating side-channel
attacks. Over the last year,
the security world has been
shaken by a series of attacks, including Spectre [148] and
Meltdown [149]. A pressing challenge is to develop notions
of constant-time security and associated veriﬁcation methods
that account for microarchitectural features.
Challenge: Rethinking the hardware-software contract
from secure, formal foundations. An ISA describes (usually
informally) what one needs to know to write a functionally
correct program [158], [159]. However, current ISAs are an
insufﬁcient speciﬁcation of the hardware-software contract
when it comes to writing secure programs [160]. They do not
capture hardware features that affect the temporal behavior
of programs, which makes carrying side-channel countermea-
sures at the software-level to the hardware-level difﬁcult.
To rectify this, researchers have called on new ISA designs
that expose, for example, the temporal behaviors of hardware,
which can lend to reasoning about them in software [160].
This, of course, poses challenging and competing requirements
for hardware architects, but we believe developing formal
foundations for veriﬁcation and reasoning about security at
the hardware-software interface can help. This line of work
seems also to be the only path that can lead to a sound, formal
treatment of micro-architectural attacks.
D. Further Reading
For lack of space, we had to omit several
threads of
relevant work, e.g., on verifying side-channel resistance in
hardware [161]–[165], and on verifying masked implemen-
tations aimed at protecting against differential power analysis
attacks [166]–[171].
V. CASE STUDY I: CONSOLIDATING GUARANTEES
Previous sections focus on speciﬁc guarantees: design-level
security, functional correctness, efﬁciency, and side-channel
resistance. This case study focuses on unifying approaches that
can combine these guarantees. This is a natural and important
step towards the Holy Grail of computer-aided cryptography:
to deliver guarantees on executable code that match the
strength and elegance of guarantees on cryptographic designs.
Table VI collects implementations that veriﬁably meet more
than one guarantee. Implementations are grouped by year
(demarcated by dashed lines), starting from 2014 and ending
in 2019; within each year, implementations are listed alpha-
betically by author. We report on the primitives included, the
languages targeted, the tools used, and the guarantees met.
Computational security. We categorize computational se-
curity guarantees as follows: veriﬁed ( ), partially veri-
ﬁed ( ), not veriﬁed ( ), and not applicable (−). The
HACL∗-related implementations are partially veriﬁed, as only
AEAD primitives have computational proofs, which are semi-
mechanized [1]. Security guarantees do not apply to, e.g.,
elliptic curve implementations or bignum code.
Functional correctness. We categorize functional correct-
ness guarantees as follows: target-level ( ), source-level ( ),
and not veriﬁed ( ). Target-level guarantees can be achieved
in two ways: Either guarantees are established directly on
assembly code, or guarantees are established at source level
and a veriﬁed compiler is used.
Efﬁciency. We categorize efﬁciency as follows: comparable
to assembly reference implementations ( ), comparable to
portable C reference implementations ( ), and slower than
portable C reference implementations ( ).
Side-channel resistance. We categorize side-channel resis-
tance guarantees as follows: target-level ( ), source-level ( ),
and not veriﬁed ( ).
Takeaway: Existing tools can be used to achieve the
“grand slam” of guarantees for complex cryptographic
primitives. Ideally, we would like computational security
guarantees, (target-level) functional correctness, efﬁciency, and
(target-level) side-channel guarantees to be connected in a
formal, machine-checkable way (the “grand slam” of guar-
antees). Many implementations come close, but so far, only
one meets all four. Almeida et al. [69] formally verify an
efﬁcient implementation of the sponge construction from the
SHA-3 standard. It connects proofs of random oracle (RO)
indifferentiability for a pseudo-code description of the sponge
construction, and proofs of functional correctness and side-
channel resistance for an efﬁcient, vectorized, implementation.
The proofs are constructed using EasyCrypt and Jasmin.
Other works focus on either provable security or efﬁciency,
plus functional correctness and side-channel resistance. This
disconnect is somewhat expected. Provable security guarantees
are established for pseudo-code descriptions of constructions,
whereas efﬁciency considerations demand non-trivial opti-
mizations at the level of C or assembly.
Takeaway: Integration can deliver strong and intuitive
guarantees. Interpreting veriﬁcation results that cover multiple
requirements can be very challenging, especially because they
may involve (all at once) designs, reference implementations,
and optimized assembly implementations. To simplify their in-
terpretation, Almeida et al. [174] provide a modular methodol-
ogy to connect the different veriﬁcation efforts, in the form of
an informal meta-theorem, which concludes that an optimized
assembly implementation is secure against implementation-
level adversaries with side-channel capabilities. The meta-
theorem states four conditions: (i) the design must be prov-
ably black-box secure in the (standard) computational model;
(ii) the design is correctly implemented by a reference imple-
mentation; (iii) the reference implementation is functionally
equivalent to the optimized implementation; (iv) the optimized
implementation is protected against side-channels. These con-
ditions yield a clear separation of concerns, which reﬂects the
division of the previous sections.
Takeaway: Achieving broad scope and efﬁciency. Many
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:10:25 UTC from IEEE Xplore.  Restrictions apply. 
788
Implementation(s)
Target(s)
Tool(s) used
Computational
security
Functional
correctness
Efﬁciency
Side-channel
resistance
[172] C
[114] asm
[131] asm
[173] C
[174] C
RSA-OEAP
Curve25519 scalar mult. loop
SHA-1, SHA-2, HMAC, RSA
HMAC-SHA-2
MEE-CBC
Salsa20, AES, ZUC, FFS, ECDSA, SHA-3 [175] Java, C
[176] OCaml
Curve25519
Salsa20, Curve25519, Ed25519
[102] asm
SHA-2, Poly1305, AES-CBC
[103] asm
HMAC-DRBG
[177] C
HACL∗1
[5] C
HACL∗1
[5] C
[178] C
HMAC-DRBG
SHA-3
[69] asm
[117] asm
ChaCha20, Poly1305
BGW multi-party computation protocol
[179] OCaml
Curve25519, P-256
Poly1305, AES-GCM
Bignum code4
WHACL∗1, LibSignal∗
EverCrypt2
EverCrypt3
[104] asm
[98] C
[180] Wasm
[6] C
[7] C
[7] asm
EasyCrypt, Frama-C, CompCert
Coq, SMT
Dafny, BoogieX86
FCF, VST, CompCert
EasyCrypt, Frama-C, CompCert
Cryptol, SAW
F∗, Sage
Jasmin
Vale
FCF, VST, CompCert
F∗
F∗, CompCert
Cryptol, SAW
EasyCrypt, Jasmin
EasyCrypt, Jasmin
EasyCrypt, Why3
Fiat Crypto
F∗, Vale
CryptoLine
F∗
F∗
F∗, Vale
−
−
−
−
−
Computational security
– veriﬁed
– partially veriﬁed
– not veriﬁed
− – not applicable
Functional correctness
– target-level
– source-level
– not veriﬁed
Efﬁciency
– comparable to asm ref
– comparable to C ref
– slower than C ref
Side-channel resistance
– target-level
– source-level
– not veriﬁed
1(ChaCha20, Salsa20, Poly1305, SHA-2, HMAC, Curve25519, Ed25519)
3(AES-GCM, ChaCha20, Poly1305, SHA-2, HMAC, HKDF, Curve25519, Ed25519, P-256) 4(In NaCl, wolfSSL, OpenSSL, BoringSSL, Bitcoin)
2(MD5, SHA-1, SHA-2, HMAC, Poly1305, HKDF, Curve25519, ChaCha20)
VERIFIED CRYPTOGRAPHIC IMPLEMENTATIONS AND THEIR FORMAL GUARANTEES.
TABLE VI
implementations target either C or assembly. This involves
trade-offs between the portability and lighter veriﬁcation-effort
of C code, and the efﬁciency that can be gained via hand-
tuned assembly. EverCrypt [7] is one of the ﬁrst systems
to target both. This garners the advantages of both, and it
helps explain, in part, the broad scope of algorithms EverCrypt
covers. Generic functionality and outer loops can be efﬁciently
written and veriﬁed in C, whereas performance-critical cores
can be veriﬁed in assembly. Soundly mixing C and assembly
requires careful modeling of interoperation between the two,
including platform and compiler-speciﬁc calling conventions,
and differences in the “natural” memory and leakage models
used to verify C versus assembly [7], [104].
VI. CASE STUDY II: LESSONS LEARNED FROM TLS
The Transport Layer Security (TLS) protocol is widely used
to establish secure channels on the Internet, and is arguably
the most important real-world deployment of cryptography to
date. Before TLS version 1.3, the protocol’s design phases did
not involve substantial academic analysis, and the process was
highly reactive: When an attack was found, interim patches
would be released for the mainstream TLS libraries or a
longer-term ﬁx would be incorporated in the next version
of the standard. This resulted in an endless cycle of attacks
and patches. Given the complexity of the protocol, early
academic analyses considered only highly simpliﬁed crypto-
graphic cores. However, once the academic community started
considering more detailed aspects of the protocol, many new
attacks were discovered, e.g., [181], [182].
The situation changed substantially during the proactive
design process of TLS version 1.3: The academic community
was actively consulted and encouraged to provide analysis
during the process of developing multiple drafts. (See [183]
for a more detailed account of TLS’s standardization history.)
On the computer-aided cryptography side of things, there
were substantial efforts in verifying implementations of TLS
1.3 [1], [3] and using tools to analyze symbolic [2]–[4] and
computational [3] models of TLS. Below we collect the most
important lessons learned from TLS throughout the years.
Lesson: The process of formally specifying and verifying
a protocol can reveal ﬂaws. The work surrounding TLS has
shown that the process of formally verifying TLS, and perhaps