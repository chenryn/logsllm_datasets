list. In this scenario, the signaling thread instead waits on the event itself. 
Without this fallback, a signaling thread could signal the keyed event during the time that the user-
mode code saw the keyed event as unsignaled and attempt a wait. The wait might have come after 
the signaling thread signaled the keyed event, resulting in a missed pulse, so the waiting thread would 
deadlock. By forcing the signaling thread to wait in this scenario, it actually signals the keyed event only 
when someone is looking (waiting). This behavior made them similar, but not identical, to the Linux 
futex
Slim Read Writer (SRW) Locks.
Note When the keyed-event wait code needs to perform a wait, it uses a built-in sema-
phore located in the kernel-mode thread object (ETHREAD) called KeyedWaitSemaphore. 
(This semaphore shares its location with the ALPC wait semaphore.) See Chapter 4 of Part 1 
for more information on thread objects.
-
tion. The initial reason, during the Windows XP timeframe, was that keyed events did not offer scalable 
performance in heavy-usage scenarios. Recall that all the algorithms described were meant to be used 
196 
CHAPTER 8 System mechanisms
-
ed to handle. The primary performance bottleneck was that keyed events maintained the list of waiters 
described in a doubly linked list. This kind of list has poor traversal speed, meaning the time required 
to loop through the list. In this case, this time depended on the number of waiter threads. Because the 
object is global, dozens of threads could be on the list, requiring long traversal times every single time 
a key was set or waited on.
Note The head of the list is kept in the keyed event object, whereas the threads are linked 
through the KeyedWaitChain
LARGE_INTEGER, the same size as a doubly linked list) in the kernel-mode thread object 
(ETHREAD). See Chapter 4 of Part 1 for more information on this object.
Windows Vista improved keyed-event performance by using a hash table instead of a linked list 
to hold the waiter threads. This optimization is what ultimately allowed Windows to include the three 
new lightweight user-mode synchronization primitives (to be discussed shortly) that all depended on 
the keyed event. Critical sections, however, continued to use event objects, primarily for application 
compatibility and debugging, because the event object and internals are well known and documented, 
whereas keyed events are opaque and not exposed to the Win32 API.
With the introduction of the new alerting by Thread ID capabilities in Windows 8, however, this all 
changed again, removing the usage of keyed events across the system (save for one situation in init 
once
structure eventually dropped its usage of a regular event object and moved toward using this new ca-
pability as well (with an application compatibility shim that can revert to using the original event object 
if needed).
Fast mutexes and guarded mutexes
objects because, although they are still built on a dispatcher object—an event—they perform a wait 
only if the fast mutex is contended. Unlike a standard mutex, which always attempts the acquisition 
through the dispatcher, this gives the fast mutex especially good performance in contended environ-
all kernel-mode 
APC (described earlier in this chapter) delivery can be disabled, unlike regular mutex objects that block 
only normal
ExAcquireFastMutex and ExAcquireFastMutexUnsafe. The former function blocks all APC delivery by 
raising the IRQL of the processor to APC level. The latter, “unsafe” function, expects to be called with 
all kernel-mode APC delivery already disabled, which can be done by raising the IRQL to APC level. 
ExTryToAcquireFastMutex 
recursively, unlike mutex objects.
CHAPTER 8 System mechanisms
197
In Windows 8 and later, guarded mutexes are identical to fast mutexes but are acquired 
with KeAcquireGuardedMutex and KeAcquireGuardedMutexUnsafe. Like fast mutexes, a 
KeTryToAcquireGuardedMutex method also exists. 
Prior to Windows 8, these functions did not disable APCs by raising the IRQL to APC level, but by 
-
able APC delivery until the region was exited, as we saw earlier. On older systems with a PIC (which we 
also talked about earlier in this chapter), this was faster than touching the IRQL. Additionally, guarded 
mutexes used a gate dispatcher object, which was slightly faster than an event—another difference that 
is no longer true. 
Another problem related to the guarded mutex was the kernel function KeAreApcsDisabled. Prior to 
Windows Server 2003, this function indicated whether normal APCs were disabled by checking whether 
the code was running inside a critical section. In Windows Server 2003, this function was changed to 
indicate whether the code was in a critical or guarded region, changing the functionality to also return 
TRUE if special kernel APCs are also disabled.
Because there are certain operations that drivers should not perform when special kernel APCs 
are disabled, it made sense to call KeGetCurrentIrql to check whether the IRQL is APC level or not, 
which was the only way special kernel APCs could have been disabled. However, with the intro-
duction of guarded regions and guarded mutexes, which were heavily used even by the memory 
manager, this check failed because guarded mutexes did not raise IRQL. Drivers then had to call 
KeAreAllApcsDisabled for this purpose, which also checked whether special kernel APCs were disabled 
false positives, ultimately all led to the decision to simply make guarded mutexes revert to just being 
fast mutexes. 
Executive resources
Executive resources are a synchronization mechanism that supports shared and exclusive access; like 
fast mutexes, they require that all kernel-mode APC delivery be disabled before they are acquired. 
They are also built on dispatcher objects that are used only when there is contention. Executive re-
have long-lasting wait periods in which I/O should still be allowed to some extent (such as reads). 
Threads waiting to acquire an executive resource for shared access wait for a semaphore associated 
with the resource, and threads waiting to acquire an executive resource for exclusive access wait for an 
event. A semaphore with unlimited count is used for shared waiters because they can all be woken and 
granted access to the resource when an exclusive holder releases the resource simply by signaling the 
semaphore. When a thread waits for exclusive access of a resource that is currently owned, it waits on 
a synchronization event object because only one of the waiters will wake when the event is signaled. In 
the earlier section on synchronization events, it was mentioned that some event unwait operations can 
actually cause a priority boost. This scenario occurs when executive resources are used, which is one 
reason why they also track ownership like mutexes do. (See Chapter 4 of Part 1 for more information on 
the executive resource priority boost.)
198 
CHAPTER 8 System mechanisms
acquiring resources: ExAcquireResourceSharedLite, ExAcquireResourceExclusiveLite, ExAcquireShared 
StarveExclusive, and ExAcquireShareWaitForExclusive
Recent versions of Windows also added fast executive resources that use identical API names but 
add the word “fast,” such as ExAcquireFastResourceExclusive, ExReleaseFastResource, and so on. These 
are meant to be faster replacements due to different handling of lock ownership, but no component 
EXPERIMENT: Listing acquired executive resources
The kernel debugger !locks
dumps their state. By default, the command lists only executive resources that are currently 
owned, but the –d option is documented as listing all executive resources—unfortunately, this 
is no longer the case. However, you can still use the -v
resources instead. Here is partial output of the command:
lkd> !locks -v 
**** DUMP OF ALL RESOURCE OBJECTS **** 
Resource @ nt!ExpFirmwareTableResource (0xfffff8047ee34440)    Available 
Resource @ nt!PsLoadedModuleResource (0xfffff8047ee48120)    Available 
    Contention Count = 2 
Resource @ nt!SepRmDbLock (0xfffff8047ef06350)    Available 
    Contention Count = 93 
Resource @ nt!SepRmDbLock (0xfffff8047ef063b8)    Available 
Resource @ nt!SepRmDbLock (0xfffff8047ef06420)    Available 
Resource @ nt!SepRmDbLock (0xfffff8047ef06488)    Available 
Resource @ nt!SepRmGlobalSaclLock (0xfffff8047ef062b0)    Available 
Resource @ nt!SepLsaAuditQueueInfo (0xfffff8047ee6e010)    Available 
Resource @ nt!SepLsaDeletedLogonQueueInfo (0xfffff8047ee6ded0)    Available 
Resource @ 0xffff898f032a8550    Available 
Resource @ nt!PnpRegistryDeviceResource (0xfffff8047ee62b00)    Available 
    Contention Count = 27385 
Resource @ nt!PopPolicyLock (0xfffff8047ee458c0)    Available 
    Contention Count = 14 
Resource @ 0xffff898f032a8950    Available 
Resource @ 0xffff898f032a82d0    Available
Note that the contention count, which is extracted from the resource structure, records 
the number of times threads have tried to acquire the resource and had to wait because it was 
already owned. On a live system where you break in with the debugger, you might be lucky 
enough to catch a few held resources, as shown in the following output:
2: kd> !locks 
**** DUMP OF ALL RESOURCE OBJECTS **** 
KD: Scanning for held locks..... 
Resource @ 0xffffde07a33d6a28    Shared 1 owning threads 
    Contention Count = 28 
     Threads: ffffde07a9374080-01  
EXPERIMENT: Listing acquired executive resources
The kernel debugger !locks
dumps their state. By default, the command lists only executive resources that are currently 
owned, but the –d option is documented as listing all executive resources—unfortunately, this 
is no longer the case. However, you can still use the -v
resources instead. Here is partial output of the command:
lkd> !locks -v
**** DUMP OF ALL RESOURCE OBJECTS ****
Resource @ nt!ExpFirmwareTableResource (0xfffff8047ee34440)    Available
Resource @ nt!PsLoadedModuleResource (0xfffff8047ee48120)    Available
    Contention Count = 2
Resource @ nt!SepRmDbLock (0xfffff8047ef06350)    Available
    Contention Count = 93
Resource @ nt!SepRmDbLock (0xfffff8047ef063b8)    Available
Resource @ nt!SepRmDbLock (0xfffff8047ef06420)    Available
Resource @ nt!SepRmDbLock (0xfffff8047ef06488)    Available
Resource @ nt!SepRmGlobalSaclLock (0xfffff8047ef062b0)    Available
Resource @ nt!SepLsaAuditQueueInfo (0xfffff8047ee6e010)    Available
Resource @ nt!SepLsaDeletedLogonQueueInfo (0xfffff8047ee6ded0)    Available
Resource @ 0xffff898f032a8550    Available
Resource @ nt!PnpRegistryDeviceResource (0xfffff8047ee62b00)    Available
    Contention Count = 27385
Resource @ nt!PopPolicyLock (0xfffff8047ee458c0)    Available
    Contention Count = 14
Resource @ 0xffff898f032a8950    Available
Resource @ 0xffff898f032a82d0    Available
Note that the contention count, which is extracted from the resource structure, records 
the number of times threads have tried to acquire the resource and had to wait because it was 
already owned. On a live system where you break in with the debugger, you might be lucky 
enough to catch a few held resources, as shown in the following output:
2: kd> !locks
**** DUMP OF ALL RESOURCE OBJECTS ****
KD: Scanning for held locks.....
Resource @ 0xffffde07a33d6a28    Shared 1 owning threads
    Contention Count = 28
     Threads: ffffde07a9374080-01 
CHAPTER 8 System mechanisms
199
KD: Scanning for held locks.... 
Resource @ 0xffffde07a2bfb350    Shared 1 owning threads 
    Contention Count = 2 
     Threads: ffffde07a9374080-01  
KD: Scanning for held locks........................................................... 
Resource @ 0xffffde07a8070c00    Shared 1 owning threads 
     Threads: ffffde07aa3f1083-01 *** Actual Thread ffffde07aa3f1080 
KD: Scanning for held locks........................................................... 
Resource @ 0xffffde07a8995900    Exclusively owned 
     Threads: ffffde07a9374080-01  
KD: Scanning for held locks........................................................... 
    9706 total locks, 4 locks currently held
resource and any threads that are waiting for the resource, by specifying the –v switch and the 
2: kd> !locks -v 0xffffde07a33d6a28 
Resource @ 0xffffde07a33d6a28    Shared 1 owning threads 
    Contention Count = 28 
     Threads: ffffde07a9374080-01  
     THREAD ffffde07a9374080  Cid 0544.1494  Teb: 000000ed8de12000 
     Win32Thread: 0000000000000000 WAIT: (Executive) KernelMode Non-Alertable 
ffff8287943a87b8  NotificationEvent 
     IRP List: 
ffffde07a936da20: (0006,0478) Flags: 00020043  Mdl: ffffde07a8a75950 
ffffde07a894fa20: (0006,0478) Flags: 00000884  Mdl: 00000000 
     Not impersonating 
     DeviceMap
ffff8786fce35840 
     Owning Process
ffffde07a7f990c0
Image:
svchost.exe 
     Attached Process
N/A
Image:
N/A 
     Wait Start TickCount
3649
Ticks: 0 
     Context Switch Count
31
IdealProcessor: 1
     UserTime                  00:00:00.015 
     KernelTime                00:00:00.000 
     Win32 Start Address 0x00007ff926812390 
     Stack Init ffff8287943aa650 Current ffff8287943a8030 
     Base ffff8287943ab000 Limit ffff8287943a4000 Call 0000000000000000 
     Priority 7 BasePriority 6 PriorityDecrement 0 IoPriority 0 PagePriority 1 
     Child-SP
RetAddr
Call Site 
     ffff8287`943a8070 fffff801`104a423a nt!KiSwapContext+0x76 
     ffff8287`943a81b0 fffff801`104a5d53 nt!KiSwapThread+0x5ba 
     ffff8287`943a8270 fffff801`104a6579 nt!KiCommitThreadWait+0x153 
     ffff8287`943a8310 fffff801`1263e962 nt!KeWaitForSingleObject+0x239 
     ffff8287`943a8400 fffff801`1263d682 Ntfs!NtfsNonCachedIo+0xa52 
     ffff8287`943a86b0 fffff801`1263b756 Ntfs!NtfsCommonRead+0x1d52 
     ffff8287`943a8850 fffff801`1049a725 Ntfs!NtfsFsdRead+0x396 
     ffff8287`943a8920 fffff801`11826591 nt!IofCallDriver+0x55
KD: Scanning for held locks....
Resource @ 0xffffde07a2bfb350    Shared 1 owning threads
    Contention Count = 2
     Threads: ffffde07a9374080-01 
KD: Scanning for held locks...........................................................
Resource @ 0xffffde07a8070c00    Shared 1 owning threads
     Threads: ffffde07aa3f1083-01 *** Actual Thread ffffde07aa3f1080
KD: Scanning for held locks...........................................................
Resource @ 0xffffde07a8995900    Exclusively owned
     Threads: ffffde07a9374080-01 
KD: Scanning for held locks...........................................................
    9706 total locks, 4 locks currently held
resource and any threads that are waiting for the resource, by specifying the –v switch and the 
2: kd> !locks -v 0xffffde07a33d6a28
Resource @ 0xffffde07a33d6a28    Shared 1 owning threads
    Contention Count = 28
     Threads: ffffde07a9374080-01 
     THREAD ffffde07a9374080  Cid 0544.1494  Teb: 000000ed8de12000 
     Win32Thread: 0000000000000000 WAIT: (Executive) KernelMode Non-Alertable
ffff8287943a87b8  NotificationEvent
     IRP List:
ffffde07a936da20: (0006,0478) Flags: 00020043  Mdl: ffffde07a8a75950
ffffde07a894fa20: (0006,0478) Flags: 00000884  Mdl: 00000000
     Not impersonating
     DeviceMap
ffff8786fce35840
     Owning Process
ffffde07a7f990c0
Image:
svchost.exe
     Attached Process
N/A
Image:
N/A
     Wait Start TickCount
3649
Ticks: 0
     Context Switch Count
31
IdealProcessor: 1
     UserTime                  00:00:00.015
     KernelTime                00:00:00.000
     Win32 Start Address 0x00007ff926812390
     Stack Init ffff8287943aa650 Current ffff8287943a8030
     Base ffff8287943ab000 Limit ffff8287943a4000 Call 0000000000000000
     Priority 7 BasePriority 6 PriorityDecrement 0 IoPriority 0 PagePriority 1
     Child-SP
RetAddr
Call Site
     ffff8287`943a8070 fffff801`104a423a nt!KiSwapContext+0x76
     ffff8287`943a81b0 fffff801`104a5d53 nt!KiSwapThread+0x5ba
     ffff8287`943a8270 fffff801`104a6579 nt!KiCommitThreadWait+0x153
     ffff8287`943a8310 fffff801`1263e962 nt!KeWaitForSingleObject+0x239
     ffff8287`943a8400 fffff801`1263d682 Ntfs!NtfsNonCachedIo+0xa52
     ffff8287`943a86b0 fffff801`1263b756 Ntfs!NtfsCommonRead+0x1d52
     ffff8287`943a8850 fffff801`1049a725 Ntfs!NtfsFsdRead+0x396
     ffff8287`943a8920 fffff801`11826591 nt!IofCallDriver+0x55
200 
CHAPTER 8 System mechanisms
Pushlocks
Pushlocks are another optimized synchronization mechanism built on event objects; like fast and 
-
tages over them, however, in that they can also be acquired in shared or exclusive mode, just like an 
executive resource. Unlike the latter, however, they provide an additional advantage due to their size: 
a resource object is 104 bytes, but a pushlock is pointer sized. Because of this, pushlocks do not require 
allocation nor initialization and are guaranteed to work in low-memory conditions. Many components 
inside of the kernel moved away from executive resources to pushlocks, and modern third-party driv-
ers all use pushlocks as well.
There are four types of pushlocks: normal, cache-aware, auto-expand, and address-based. Normal 