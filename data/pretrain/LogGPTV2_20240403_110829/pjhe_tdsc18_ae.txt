| POP |0.99 |10,998 |10,720 (63%) |278 (2.5%) |splitRel to 0.1, splitAbs to 10, maxDistance to 0. We observe |splitRel to 0.1, splitAbs to 10, maxDistance to 0. We observe || Ground truth |1.00 |11,473 |11,195 (66%) |278 (2.4%) |splitRel to 0.1, splitAbs to 10, maxDistance to 0. We observe |splitRel to 0.1, splitAbs to 10, maxDistance to 0. We observe |
| Ground truth |1.00 |11,473 |11,195 (66%) |278 (2.4%) |that the accuracy of POP peaks for all datasets if we set GS |that the accuracy of POP peaks for all datasets if we set GS |Detected anomaly means the number of true anomalies detected by PCA. False alarm is the number of wrongly detected anomalies. Ground truth is an anomaly detection task with exactly correct parsed results. Notice that even the ground truth could not detect all anomalies because of the boundary of the PCA anomaly detection model.From Table 6, we observe that LogSig and IPLoM lead to nearly optimal results on the anomaly detection task. How-ever, SLCT does not perform well in anomaly detection with its acceptable parsing accuracy (0.83). It reports 7,515 false alarms in anomaly detection, which introduces extensive human effort on inspection. Furthermore, the parsing accu-racy of SLCT (0.83) and LogSig (0.87) is comparable, but the performance of anomaly detection using LogSig as parser is one order of magnitude better than that using SLCT. Anomaly detection task using LogSig only reports 413 false alarms. These reveal that anomaly detection results are sensitive to some critical events, which are generated by log parsers. It is also possible that F-measure, despite pervasively used in clus-tering algorithm evaluation, may not be suitable to evaluatein range [0.5, 0.6]. When GS is smaller, a log group is easier to get sent to step 4 without further partitioning, which may lower the accuracy because we may put log messages with different log events into the same log group. Thus we can observe the relatively lower accuracy in range [0, 0.3] on HPC and range [0, 0.2] on HDFS. When GS is larger, a log group has higher probability to go through partitioning pro-cess in step 3, which may lower the accuracy because we may put log messages with the same log event into different log groups. Thus we can observe the relatively lower accu-racy for range [0.8, 1.0] on HPC and range [0.8, 1.0] on HDFS. For dataset BGL, Zookeeper, and Proxifier, POP’s accuracy is consistently high (larger than 0.9) under all GS values. POP is also not sensitive to splitRel and splitAbs in our experiments. For maxDistance, setting a too large value will cause accuracy drop.To pick a suitable value, we could first set the parameter to a reasonable value according to its physical meaning. Then we tune it on a small sample dataset by evaluating the resulting accuracy. After finding the best parameter, we can apply it to the original dataset.
the effectiveness of log parsing methods on log mining. 4.6 ObservationsFindings. Log parsing is important because log mining is effective only when the parsing result is accurate enough. Log mining is sensitive to some critical events. 4 percent errors in parsing could even cause one order of magnitude performance degradation in anomaly detection.The parameters of POP in this experiment are the same as those tuned for 2k HDFS datasets. We observe that the accurate parsed results of POP are effective from the per-spective of this anomaly detection task. Although there are still 37 percent non-detected anomalies, we think this is the limitation of the anomaly detection model PCA. Because the anomaly detection task with ground truth as input provides comparable performance, where 34 percent anomalies are not detected. Note that although the performance of the anomaly detection task with POP as input is the same as that of IPLoM in Table 6, their parsing results are different.4.5 	Parameter Sensitivity
To study the impact of parameters, we evaluate the accu-racy of POP while varying the value of the studied parame-ter. All the sensitivity experiments are run on the 2kAmong the existing log parsers, LKE has quadratic time complexity, while the running time of others scales linearly with the number of log messages. LogSig is accurate on most datasets. IPLoM is accurate and efficient on small data-sets. SLCT requires the least running time. Although these widely used log parsing methods have their own merits, none of them can perform accurately and efficiently on vari-ous modern datasets. First, SLCT is not accurate enough. Because of its relatively low parsing accuracy, in our case study in Section 4.4, the false alarm rate of the subsequent anomaly detection task increases to 40 percent, which causes 7,515 false positives. Second, LKE and LogSig cannot handle large-scale log data efficiently. Specifically, LKE has quadratic time complexity, while LogSig needs computa-tion-intensive iterations. Moreover, LKE and LogSig both require non-trivial parameter tuning effort. Finally, IPLoM cannot efficiently handle large-scale log data (e.g., 200 mil-lion log messages) due to the limited computing power and memory of a single computer. Our proposed POP is the only log parser that performs accurately and efficiently on all the datasets.| datasets, which are the datasets used to evaluate the accu- | 5 | DISCUSSIONS |
|---|---|---|
| racy of the parsers in Section 4.2. Due to the space limit, we |5 |DISCUSSIONS |
only demonstrate the results of parameter GS on HPC and HDFS here in Fig. 9, while the remaining results are pro-vided in our supplementary report [24]. Similar to the parameter setting in our accuracy experiments, we setIn this section, we discuss the limitations of this work and provide some potential directions for future exploration.
Diversity of dataset. Not all datasets (two out of five) used in our evaluation are production data, and the results may
942 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 15, NO. 6, NOVEMBER/DECEMBER 2018be limited by the representativeness of our datasets. This is mainly because public log data is lacking. As a result, we
messages marked as “other events” after the latest training. If it is larger than a threshold, an alarm is reported to call
cannot claim that our results are broadly representative. 	for retraining.
However, 	Zookeeper 	and 	HDFS 	are 	systems 	widely 	POP for Big Data. We propose the parallel log parser POPadopted by companies for their distributed computing jobs. We believe these logs could reflect the logs from industrial companies to some extent. We also mitigate this issue by generating many sample datasets from the original ones, where each sample dataset has different properties, such as log size and the number of log events. The proposed parser POP at least has consistent accuracy and efficiency on all these datasets, which demonstrates its robustness. Besides, we thank those who release log data [3], [33], [34], which greatly facilitates our research.Diversity of log mining tasks. Results of effectiveness of log parsing methods are evaluated on anomaly detection, which may not generalize to other log mining tasks. This isin the manuscript because the existing nonparallel log pars-ers and SinglePOP cannot handle the large volume of logs generated by modern systems in the big data era. We can observe from the Fig. 7 that the increasing speed of Single-POP’s running time (i.e., slope) is faster than POP as the log size becomes larger. The running time of SinglePOP will be longer than that of POP on production level log data (e.g., over 200m log messages). For example, the running time of SinglePOP is already larger than that of POP on the 10m HDFS dataset as illustrated. Thus, although SinglePOP is efficient, we need POP, a parallel designed on top of Spark, to handle production level log data efficiently.| mainly because public real-world log mining data with | 6 | RELATED WORK |
|---|---|---|
| labels is scarce. However, the anomaly detection task evalu- |6 |RELATED WORK |
ated is an important log mining task widely studied [37], [38], which is presented in a paper [3] enjoying more than 300 citations. Besides, even conducting evaluation on one log event mining task, the result reveals that an accurate log parser is of great importance for obtaining optimal log min-ing performance. We will consider to extend our methodol-ogy on more log parsing data and different log mining tasksLog Management. With the prevalence of distributed systems and cloud computing, log management becomes a challeng-ing problem because of security assurance requirements and the huge volume of log data. Hong et al. [40] design a framework to sanitize search logs with strong privacy guar-antee and sufficiently retained utility. Zawoad et al. [41] propose a scheme to reveal cloud users’ logs for forensicsin our future work. 	investigation while preserving their confidentiality. Mean-
Logging of Event ID. Log parsing process can also be improved by recording event ID in logs in the first place. This approach is feasible because developers who design the logging statement know exactly the corresponding log event. Thus, adding event ID to logging statement is a good logging practice [39] from the perspective of log mining. Event ID adding tools that can automatically enrich logging statements may greatly facilitate the log parsing process.Training Log Data. Usually we hope to train our log parser on as many logs as possible. This can increase the generalizability of the results obtained by POP. This is also why we propose a parallel log parsing method that aims for parsing large-scale logs. However, we agree that in case we have too many historical logs for processing, sampling is an effective way. We suggest two methods to sample training data. (1) Using the latest logs. This sampling method is more likely to get the newest log events produced by new-version systems. (2) Collecting the logs periodically (e.g., collecting the logs every single day). This sampling method can allow the variability of logs. The quantity of sample logs depends on the training time we can afford. For exam-ple, in case of POP, if we want to finish the training process in 7 minutes for HDFS logs, then we can use the latest 200 million log messages.Log Event Changes. Logs change over time, a log message may not be matched by the current list of log events. To solve this problem, developers can use POP to periodically retrain on new training data to update the list. In runtime, if a log message is not matched by any log events, we mark it as “other events” and record it. When retraining, the devel-oper can retrain on the log messages marked as “other even-ts”, and add the new log events to the log event list. To avoid the burst of not-matched logs (e.g., a billion times), we can maintain a counter to remember the number of logwhile, to assist log analysts in searching, filtering, analyz-ing, and visualizing a mountain of logs, some promising solutions, such as commercial Splunk [42], and open-source Logstash[43], Kibana [44], have been provided. These solu-tions provide many plugins/tools for monitoring and ana-lyzing popular system logs (e.g., TCP/UDP, Apache Kafka) and present stunning visualization effects. However, their log parsing procedures are mainly based on prior knowl-edge and require user-defined matching patterns (e.g., regu-lar expressions). In this paper, we propose a automated log parsing method that can accurately and efficiently parse production-level log data. Besides, the evaluation of log parsing methods gives developers deeper insights on the log parsing procedure.Log Analysis. Logs, as an important data source, are in widespread use to ensure system dependability. For anomaly detection, Xu et al. [3] propose a PCA-based model, which is trained by system logs, to detect runtime anomalies. Kc et al. [45] detect anomalies by using both coarse-grained and fine-grained log features. As for pro-gram verification, Beschastnikh et al. [6] propose Synoptic to construct a finite state machine from logs as system model. Shang et al. [7] analyze logs from both pseudo and cloud environment to detect deployment bugs for big data analytics applications. Log analysis also facilitates system security assurance. Gu et al. [11] leverage system logs to build an attack detection system for cyber infrastructures. Oprea et al. [10] employ log analysis to detect early-stage enterprise infection. Besides, Pattabiraman et al. [46] design an assertion generator based on execution logs to detect application runtime errors. Log analysis is also employed in structured comparative analysis for perfor-mance problem diagnosis [9] and time coalescence assess-ment for failure reconstruction [47]. As shown in ourHE ET AL.: TOWARDS AUTOMATED LOG PARSING FOR LARGE-SCALE LOG DATA ANALYSIS 	943
experiemnts, the accuracy and efficiency of log parsing 	REFERENCES
could have great impact on the whole log analysis tasks. 	[1] 	The cost of downtime at the world’s biggest online retailer. (2016).
Thus, we believe our parallel log parsing approach could 	[Online]. Available: 
benefit future studies on dependability assurance withlog analysis. 	[2] 	Facebook loses $24,420 a minute during outages. (2014). [Online].
Available: 
Log Parsing. Log parsing has been widely studied in 	
recent years. Xu et al. [3] propose a log parser based on 	[3] 	W. Xu, L. Huang, A. Fox, D. Patterson, and M. Jordon, “Detecting
source code analysis to extract log events from logging 	large-scale system problems by mining console logs,” in Proc.statements. However, source code is often unavailable or 	ACM Symp. Operating Syst. Principles, 2009, pp. 117–132.
[4] 	Q. Fu, J. Lou, Y. Wang, and J. Li, “Execution anomaly detection in
incomplete to access, especially when third-party compo-	distributed systems through unstructured log analysis,” in Proc.
nents are employed. Recent work proposes data-driven log 	Int. Conf. Data Mining, 2009, pp. 149–158.parsers (e.g., SLCT [16], IPLoM [23], LKE [4], LogSig [18]), 	[5] 	S. He, J. Zhu, P. He, and M. Lyu, “Experience report: System log
analysis for anomaly detection,” in Proc. 27th Int. Symp. Softw. Reli-
in which data mining techniques are employed. But an 	ability Eng., 2016, pp. 207–218.
open-source implementations of log parsers is still lacking. 	[6] 	I. Beschastnikh, Y. Brun, S. Schneider, M. Sloan, and M. Ernst,Many researchers (e.g., [6], [9], [48], [49]) and practitioners	“Leveraging 	existing 	instrumentation 	to 	automatically 	infer
(as revealed in StackOverflow questions [50], [51]) in this 	invariant-constrained models,” in Proc. 19th ACM SIGSOFT Symp.
13th Eur. Conf. Found. Softw. Eng., 2011, pp. 267–277.
field have to implement their own log parsers to deal with 	[7] 	W. Shang, Z. Jiang, H. Hemmati, B. Adams, A. Hassan, andtheir log data. Our work not only provides valuable insights 	P. Martin, “Assisting developers of big data analytics applications
on log parsing, but also releases open-source tool imple-	when deploying on hadoop clouds,” in Proc. 35th Int. Conf. Softw.
Eng., 2013, pp. 402–411.
mentations on the proposed log parser POP and four repre-	[8] 	D. Yuan, et al., “Be conservative: Enhancing failure diagnosis withsentative log parsers 	proactive logging,” in Proc. 10th USENIX Conf. Operating Syst. Des.
Empirical Study. Empirical studies have attracted consid-	Implementation, 2012, pp. 293–306.
erable attraction in recent years, because the empirical 	[9] 	K. Nagaraj, C. Killian, and J. Neville, “Structured comparative
analysis of systems logs to diagnose performance problems,” inresults could usually provide useful insights and direct sug-	Proc. 9th USENIX Conf. Netw. Syst. Des. Implementation, 2012,
gestions to both academic researchers and industrial practi-	pp. 26–26.tioners. In particular, Yuan et al. [8], [52] conduct an empirical study on the logging practices in open-source sys-tems. Based on their findings, they provide actionable sug-gestions for improvement and a tool to identify potential unlogged exceptions. Besides, the logging practices in industry has been studied in some recent work [53], [54]. Our work extends the previous conference paper [22], which is an empirical study on log parsing and its subse-quent use in log mining.7 	CONCLUSIONThis paper targets automated log parsing for the large-scale log analysis of modern systems. Accordingly, we conduct a comprehensive study of four representative log parsing methods characterizing their accuracy, efficiency and effec-tiveness on subsequent log mining tasks. Based on the result of the comprehensive study, we propose a parallel log pars-ing method. POP employs specially designed heuristic rules and hierarchical clustering algorithm. It is optimized on top of Spark by using tailored functions for selected Spark oper-ations. Extensive experiments are conducted on both syn-thetic and real-world datasets, and the results reveal that POP can perform accurately and efficiently on large-scale log data. POP and the four studied log parsers have been publicly released to make them reusable and thus facilitate future research.ACKNOWLEDGMENTS
The work described in this paper was fully supported by the National Natural Science Foundation of China (Project No. 61332010), the Research Grants Council of the Hong Kong Special Administrative Region, China (No. CUHK 14205214 of the General Research Fund), and 2015 Microsoft Research Asia Collaborative Research Program (Project No. FY16-RES-THEME-005).[10] A. Oprea, Z. Li, T. Yen, S. Chin, and S. Alrwais, “Dectection of early-stage enterprise infection by mining large-scale log data,” in Proc. 45th Annu. IEEE/IFIP Int. Conf. Dependable Syst. Netw., 2015, pp. 45–56.
[11] Z. Gu, K. Pei, Q. Wang, L. Si, X. Zhang, and D. Xu, ‘‘LEAPS: Detecting camouflaged attacks with statistical learning guided by program analysis,” in Proc. 45th Annu. IEEE/IFIP Int. Conf. Depend-able Syst. Netw., 2015, pp. 57–68.[12] D. Lang, “Using SEC,” USENIX ;login: Mag., vol. 38, pp. 38–43, 	2013.
[13] H. Mi, H. Wang, Y. Zhou, M. R. Lyu, and H. Cai, “Toward fine-grained, unsupervised, scalable performance diagnosis for pro-duction cloud computing systems,” IEEE Trans. Parallel Distrib. Syst., vol. 24, no. 6, pp. 1245–1255, Jun. 2013.[14] J. Zhu, P. He, Q. Fu, H. Zhang, M. R. Lyu, and D. Zhang, “Learning to log: Helping developers make informed logging decisions,” in Proc. 37th Int. Conf. Softw. Eng., 2015, pp. 415–425.
[15] W. Xu, “System problem detection by mining console logs,” Ph.D. 	dissertation, University of California, Berkeley, CA, USA, 2010.
[16] R. Vaarandi, “A data clustering algorithm for mining patterns from event logs,” in Proc. 3rd Workshop IP Operations Manage., 2003, pp. 119–126.[17] A. Makanju, A. Zincir-Heywood, and E. Milios, “Clustering event logs using iterative partitioning,” in Proc. Int. Conf. Knowl. Discov-ery Data Mining, 2009, pp. 1255–1264.
[18] L. Tang, T. Li, and C. Perng, “LogSig: Generating system events from raw textual logs,” in Proc. ACM Int. Conf. Inf. Knowl. Manage., 2011, pp. 785–794.[19] C. Manning, P. Raghavan, and H. Schutze, Introduction to Informa-tion Retrieval. Cambridge, MA, USA: Cambridge University Press, 2008.
[20] Evaluation of clustering. (2009). [Online]. Available: 
[21] (2017). [Online]. Available: [22] P. He, J. Zhu, S. He, J. Li, and M. R. Lyu, “An evaluation study on 	log parsing and its use in log mining,” in Proc. 46th Annu. IEEE/ 	IFIP Int. Conf. Dependable Syst. Netw., 2016, pp. 654–661.[23] A. Makanju, A. Zincir-Heywood, and E. Milios, “A lightweight algorithm for message type extraction in system application logs,”IEEE Tran. Knowl. Data Eng., vol. 24, no. 11, pp. 1921–1936, Nov. 2012.
[24] Towards automated log parsing for large-scale log data analysis (supplementary report). (2017). [Online]. Available: 
944 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 15, NO. 6, NOVEMBER/DECEMBER 2018[25] Apache spark. (2012). [Online]. Available: [26] M. Zaharia, et al., “Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing,” in Proc. 9th USE-
[54] A. Pecchia, M. Cinque, G. Carrozza, and D. Cotroneo, “Industry practices and event logging: Assessment of a critical software development process,” in Proc. 37th Int. Conf. Softw. Eng., 2015,NIX Conf. Netw. Syst. Des. Implementation, 2012, pp. 2–2. 	pp. 169–178. [27] J. C. Gower and G. J. S. Ross, “Minimum spanning trees and single
| linkage cluster analysis,” J. Royal Statistical Soc. Series C Appl. Stat- |  | Pinjia He received the BEng degree in computer |
|---|---|---|