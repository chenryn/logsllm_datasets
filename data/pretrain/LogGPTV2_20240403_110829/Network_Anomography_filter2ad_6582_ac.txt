Daubechies wavelet [6] of order 6.
2. Then remove low- and mid-frequency components in
W by setting all coefﬁcients at frequency levels higher
than wc to 0. Here wc is a cut-off frequency level. For
the results presented in Section 6, we use 10-minute ag-
gregated link trafﬁc data of one week duration, and wc
is set at 3. That is, we only keep coefﬁcients at fre-
quency levels 1, 2, and 3, which is consistent with [1].
3. Reconstruct the signal: ˜B = WAVEREC(B). The re-
sult is the high-frequency components in the trafﬁc data.
It is easy to verify that the process of WAVEDEC and
WAVEREC only involves linear combinations of columns
of B. As a result, the ˜B derived through the wavelet based
anomography can also be modeled as right multiplying ma-
trix transformation.
3.3.4 Temporal PCA
In Section 3.2.1, we presented a method of applying PCA
to ﬁnd dominant patterns among different link-load time
series. A similar method can be used in identifying domi-
nant patterns across time.
Consider the link load matrix B = [b1 b2...bt]. We can
think of each row as a t-dimensional vector. What we are
looking for is a new coordinate system, v1, v2, ...
,vt,
such that the projection of the m links (on v1, v2, ..., vt)
has energy concentrated on the ﬁrst several axes. This is
exactly what PCA provides. The only difference is that
we now apply PCA on BT as opposed to B (as used in
spatial PCA). Then we follow the same procedure to de-
ﬁne an anomalous subspace and to extract anomalies that
have projections in the anomalous subspace. In this way,
we obtain a left multiplying transformation matrix T , i.e.,
˜BT = T BT . Taking transpose on both side of the equa-
tion, we have ˜B = ( ˜BT )T = (T BT )T = BT T where T T
is a right multiplying transformation matrix that extracts
anomalies from B.
3.4 Inference Algorithms
Once we obtain the matrix of link anomalies ˜B, the next
step is to reconstruct OD ﬂow anomalies ˜X by solving a se-
ries of ill-posed linear inverse problems ˜bj = A˜xj. For ex-
ample, Lakhina et al [19] proposed to ﬁnd the single largest
anomaly in each time interval j by applying a greedy al-
gorithm. We present below three common inference al-
gorithms for solving these problems. All three algorithms
deal with the underconstrained linear system by searching
for a solution that minimizes some notions of vector norm,
three examples of which are
• The `2 norm of a vector v is deﬁned as kvk2 =
(cid:0)Pi v2
i(cid:1) 1
• The `1 norm of a vector v is deﬁned as kvk1 =Pi |vi|,
• The `0 norm of a vector v is deﬁned as kvk0 = Pi v0
i.e., the sum of the absolute value of each element of v.
i ,
2 , where vi is the i-th element of vector v.
i.e., the number of non-zero elements of v.
3.4.1 Pseudoinverse Solution
A standard solution to ˜b = A˜x is the pseudoinverse solu-
tion ˜x = A+ ˜b, where A+ is the pseudoinverse (or Moore-
Penrose inverse) of matrix A. It is known that ˜x = A+ ˜b is
322
Internet Measurement Conference 2005 
USENIX Association
the solution to the problem ˜b = A˜x that minimizes the `2
norm of the anomaly vector, i.e. it solves:
minimize k˜xk2
subject to k˜b − A˜xk2 is minimal.
(8)
3.4.2 Sparsity Maximization
In practice, we expect only a few anomalies at any one
time, so ˜x typically has only a small number of large val-
ues. Hence it is natural to proceed by maximizing the spar-
sity of ˜x, i.e., solving the following `0 norm minimization
problem:
minimize k˜xk0
subject to ˜b = A˜x.
(9)
The `0 norm is not convex and is notoriously difﬁcult to
minimize, so in practice one needs to either approximate
the `0 norm with a convex function or use heuristics, for
example the greedy algorithm of Lakhina et al [19].
`1 norm minimization One common approach to ap-
proximate `0 norm minimization is to convexify (9) by re-
placing the `0 norm with an `1 norm, so that we seek a
solution to
minimize k˜xk1
subject to ˜b = A˜x
(10)
As shown in [8, 9], `1 norm minimization results in the
sparsest solution for many large under-determined linear
systems.
In the presence of measurement noise, the constraints
˜b = A˜x may not always be satisﬁable. In this case, we
can add a penalty term k˜b − A˜xk1 to the objective and re-
formulate (10) as:
minimize λk˜xk1 + k˜b − A˜xk1
(11)
where λ ∈ [0, 1] controls the degree to which the con-
straints ˜b = A˜x are satisﬁed. As shown in Section 6, the
algorithm is not very sensitive to the choice of λ. In the rest
of this paper, unless noted otherwise, we use λ = 0.001,
which gives satisfactory results.
We can cast (11) into the following equivalent Linear
Programming (LP) problem, for which solutions are avail-
able even when A is very large, owing to modern interior-
point linear programming methods.
minimize λPi ui +Pj vj
subject to
˜b = A˜x + z
u ≥ ˜x, u ≥ −˜x
v ≥ z,
v ≥ −z
(12)
Greedy algorithm Another common heuristic solution
for `0 norm minimization is to apply the greedy algorithm.
For example, the greedy heuristic has been successfully ap-
plied to wavelet decomposition, where it goes by the name
of Orthogonal Matching Pursuit (OMP) [24]. In the same
spirit here, we develop a greedy solution to maximize the
sparsity of ˜x. The algorithm starts with an empty set I
of non-zero positions for ˜x and then iteratively adds new
non-zero positions to I. During each iteration, for each po-
sition p 6∈ I, the algorithm tests how much it can reduce
the residual ˜b − A˜x by including p as a non-zero position.
More speciﬁcally, let J = I ∪{p}. The algorithm estimates
the values for the non-zero elements of ˜x (denoted as ˜xJ)
by solving the following least squares problem
minimize k˜b − AJ ˜xJ k2
(13)
max.
where AJ = A[., J] is a submatrix of A formed by the
column vectors of A corresponding to positions in J. The
residual is then computed as eJ = k˜b − AJ ˜xJ k2. The al-
gorithm then greedily chooses the position p that gives the
smallest eJ and adds it to I. The algorithm stops whenever
either the residual energy falls below some tolerance to in-
accuracy emax or the number of non-zero positions exceeds
some threshold `0
4 Dynamic Network Anomography
Up to this point, we have assumed that the routing matrices
are constant. However, we wish to allow for dynamic rout-
ing changes, and so we must allow Aj to vary over time.
In IP networks, routing changes occur as part of the nor-
mal “self-healing” behavior of the network, and so it is
advantageous to isolate these from trafﬁc anomalies and
only signal trafﬁc anomalies.
In addition, if some mea-
surements are missing (say at time j), we may still form a
consistent problem by setting the appropriate rows of Aj to
zero. Thus, for realistic SNMP measurements where miss-
ing data are often an issue, we still wish to vary Aj even
for static routing. Routing measurements may be obtained
using a route monitor, to provide accurate, up-to-date mea-
surements of routing (at least at the time scale of SNMP
measurements, e.g. minutes).
Where the tomography step can be done separately at
each time interval (for instance see [34, 35]), it is sim-
ple to adapt early-inverse methods to dynamic network
anomography by inverting (2) at each time step. Given the
straight forward approach for early-inverse methods, We
seek here to generalize late-inverse methods to dynamic
network anomography.
4.1 Dynamic Temporal Anomography
When the routing matrix is non-constant, there is no reason
to believe that the measurements B should follow a simple
model such as an ARIMA model. Even where the trafﬁc
itself follows such a model, a simple routing change may
change a link load measurement by 100%, for instance by
routing trafﬁc completely away from a particular link. If
we were to apply the ARIMA model to the measurements
B, we would see such a change in routing as a level-shift
anomaly. However, its cause is not an unknown change in
X (to be discovered), but rather a known change in the rout-
ing matrices Aj. Likewise, it no longer makes sense to try
to exploit spatial correlations which arose from a particular
routing, to the case of another routing.
USENIX Association
Internet Measurement Conference 2005  
323
However, it is no less reasonable to approximate the traf-
ﬁc matrix X by an ARIMA model (than B when the rout-
ing is constant), even when routing may change. Under
such a modeling assumption, we can write ˜X = XT . We
know also that the measurements are given by (2). A rea-
sonable approach to the solution is therefore to seek a so-
lution ˜X which is consistent with these equations, but also
minimizes one of the norms (described above) at each time
step. We choose to minimize the `1 norm k˜xjk1 here be-
cause (i) it allows us to naturally incorporate link load con-
straints at multiple time intervals, and (ii) it is more accu-
rate than both the pseudoinverse and the greedy algorithms
for static anomography (as we will show in Section 6).
Unfortunately, for transform based methods (the Fourier,
wavelet and PCA methods) the number of constraints be-
comes very large (as t grows). On the other hand, the set of
constraints for the ARIMA model can be written in a form
such that it does not grow with t. Hence, in the follow-
ing we concentrate on generalizing the ARIMA approach.
We present the algorithm for ARIMA(p, d, q) models with
d ≥ 1 (Section 4.2). We have also extended the algorithm
to handle ARIMA models with d = 0, though we omit this
treatment here for brevity (as it is a straightforward exten-
sion). Due to space limits, we will leave out the discussion
on model selection and parameter estimation, two impor-
tant issues for applying ARIMA-based anomography. In-
terested readers can ﬁnd this in our technical report [33].
4.2 Algorithm for ARIMA Models (d ≥ 1)
We are going to seek solutions that are consistent with
the measurements bj = Aj xj , for j = 1, . . . , t, and an
ARIMA model that gives ˜X = XT where T is the same
transformation matrix implicitly deﬁned by (6) and (7). Im-
portantly, we do not wish to have to estimate X (or we may
as well use an early-inverse method). The advantage of the
ARIMA model, is we do not need to know X, but only
linear combinations of X.
Let L be the backshift operator, whose effect on a pro-
cess z can be summarized as (Lz)k = zk−1. Let the AR
polynomial Φ(L) be
Φ(L) =
d+pX
i=0
γiLi def
=
1 −
φiLi!
pX
i=1
(1 − L)d.
By deﬁnition the sum Pd+p
Let yk−i = γixk−i. We now identify e = ˜x in the ARIMA
model described in (5) (or rather its multivariate extension).
i=1 φizk−i,
and so, for d ≥ 1, the ARIMA model (5) can be rewritten
i=0 yk−i = zk −Pp
d+pX
i=0
yk−i = ˜xk −
qX
j=1
θj ˜xk−j .
(14)
Deﬁne ck−i = γibk−i, then as yk−i = γixk−i, the mea-
surement equation (2) implies
Ak−iyk−i = ck−i,
i = 0, 1, · · · , d + p.
(15)
iteratively by solving
We can compute ˜x1, ˜x2, · · · , ˜xt
a series of `1 norm minimization problems Pk (k =
1, 2, · · · , t):
Pk : minimize k˜xkk1 subject to (14) and (15).
(16)
As an example, consider the simplest ARIMA model,
ARIMA(0, 1, 0). In this case, p = q = 0, so we have
Φ(L) =
1X
i=0
γiLi = (1 − L),
P1
so γ0 = 1 and γ1 = −1, and (14) becomes ˜xk =
i=0 yk−i, thus problem Pk is simply
minimize
subject to
k˜xkk1
˜xk =
Akyk =
yk + yk−1
bk
Ak−1yk−1 = −bk−1
(17)
As in Section 3.4.2, we can accommodate measurement
noise by incorporating penalty terms into the objective to
penalize against violation of constraints (14) and (15). We
can then solve the resulting `1 norm minimization problem
by reformulating it as an equivalent LP problem. We omit
such details in the interest of brevity.
We have also developed two techniques to signiﬁcantly
reduce the size of the above minimization problems Pk by
exploiting the fact that changes in routing matrices tend to
be infrequent (i.e., not in every time interval) and local (i.e.,
only in a small subset of rows). Interested readers please
refer to our technical report [33] for details.
5 Evaluation Methodology
5.1 Data Sets
We apply our techniques to real network measurement data
gathered from two large backbone networks – Internet2’s
Abilene network and a Tier-1 ISP network. Both networks
span the continental USA. The Abilene backbone is rela-
tively small, with 12 core routers, 15 backbone links and
144 OD ﬂow elements in its trafﬁc matrix. The Tier-1 ISP
network is much larger, consisting of hundreds of routers,
thousands of links and tens of thousands of different OD
ﬂows. To reduce computation complexity without loss of
utility, we use the technique in [34] to lump edge routers
with topologically equivalent connectivity. This reduces
the total number of OD ﬂows to about 6000.
The primary data inputs for our anomaly diagnosis are
the time series of link loads (bytes across interfaces) for
every network, gathered through SNMP. We use ﬂow level
data, where available, for validation. As is often the case,
the ﬂow data is incomplete. The ﬂow data are collected
at the edge of the network where data packets are sampled
and aggregated by the IP source and destination address,
and the TCP port number. Adjusted for sampling rate and
combined with BGP and ISIS/OSPF routing information,
324
Internet Measurement Conference 2005 
USENIX Association
these sampled IP ﬂow statistics are then aggregated into a
real trafﬁc matrix [11], where each element is an OD ﬂow
with the origin and destination being the ingress and egress
point of the ﬂow to/from the network. Consistent with [19],
we aggregate these measurements into bins of 10 minutes
to avoid any synchronization issues that could have arisen
in the data collection.
Ideally, to evaluate the methods, one would like com-
plete ﬂow level data, SNMP link load measurements, and
continuous tracking of routing information, providing a
consistent, comprehensive view of the network in opera-
tion. Unfortunately, we do not have the complete set of
ﬂow level data across the edge of the network (due to prob-
lems in vendor implementations or in data collection), and
our routing information is only “quasi-” real time (we rely
on snapshots available from table dumps carried out every
8 hours). As a result, inconsistencies sometimes arise be-
tween these measurements. To overcome these problems
and provide a consistent means for evaluating the algo-
rithms, we adopt the method in [34] and reconstruct the
link trafﬁc data by simulating the network routing on the
OD ﬂow trafﬁc matrix generated from the available set of
ﬂow level data. Note that we use derived link load measure-
ments for validation purposes only. In practice, our meth-
ods are applicable to direct measurement of trafﬁc data as
obtained from SNMP.
5.2 Performance Metrics
We conduct our evaluation in two steps. First, we com-
pare the different solution techniques for the inverse prob-
lem ˜bj = A˜xj (as described in Section 3.4). The in-
verse problem is common to all the late-inverse anomog-
raphy methods discussed in Section 3, so for simplicity
we choose to use the simplest temporal forecasting model,
ARIMA(0, 1, 0), for evaluation. This model predicts the
next observation to have the same value as the current one.