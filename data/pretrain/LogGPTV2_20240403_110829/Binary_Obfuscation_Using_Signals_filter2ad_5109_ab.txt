After obfuscating a control transfer instruction, we next
insert bogus code—a conditional branch and some junk
bytes—to further confuse disassemblers. This is shown
in Figure 2. Since the trap instruction has the effect of
278
16th USENIX Security Symposium
USENIX Association
Code−before
jmp
Addr
Code−after
Code−before
Setup code
trap instruction
conditional branch
junk bytes
Code−after
Addr
unreachable
}
(a) Original code
(b) Obfuscated code
Figure 2: Bogus code insertion
an unconditional control transfer, the conditional branch
immediately following the trap is “bogus code” that will
not be reachable in the obfuscated program, and hence
it will not be executed. The purpose of adding this in-
struction is to confuse the control ﬂow analysis of the
program by misleading the disassembler into identify-
ing a spurious edge in the control ﬂow graph; the con-
trol ﬂow edge so introduced can also lead to further dis-
assembly errors at the target of this control transfer. A
secondary beneﬁt of such bogus conditional branches is
that they help improve the stealthiness of the obfuscation,
since otherwise the disassembly would produce what ap-
peared to be long sequences of straight-line code without
any branches, which would not resemble code commonly
encountered in practice. We randomly select an uncon-
ditional branch—based on how frequently the different
kinds occur in normal programs—and use a random PC-
relative displacement.
The junk bytes are a proper preﬁx of a legal instruc-
tion. The goal is to cause a disassembler to consume the
ﬁrst few bytes of Code-after when it completes the in-
struction that starts with the junk bytes. This will ideally
cause it to continue to misidentify the true instruction
boundaries for at least a while.1 We determine the preﬁx
length n that maximizes the disassembly error for subse-
quent instructions (n depends only on the instructions in
Code-after), and insert the ﬁrst n bytes of an instruction
chosen randomly from a number of different alternatives.
Building the Mapping Table
After obfuscating control ﬂow and inserting bogus code,
our obfuscator computes a memory layout for the obfus-
cated program and determines ﬁnal memory addresses.
1This technique only works on variable-instruction-length architec-
tures such as the IA-32. Moreover, disassemblers tend to resynchronize
relatively quickly, so that on average they are confused for only three or
four instructions before again ﬁnding the true instruction boundaries.
Among these are the addresses of all the trap instruc-
tions that have been inserted. The obfuscator then goes
through the control ﬂow graph and gathers the informa-
tion it needs to build a table that maps trap locations to
original targets.
Suppose that N control transfer instructions have been
obfuscated. Then there are N rows in the mapping table,
one for each trap point. Each row contains a ﬂag that in-
dicates the type of transfer that was replaced, and zero,
one, or two target addresses, depending on the value of
the ﬂag. To make it hard to reverse engineer the contents
and use of this table, we use two techniques. First, we
generate a perfect hash function that maps the N trap ad-
dresses to distinct integers from 0 to N − 1 [12], and we
use this function to get indices into the mapping table;
this machine code is quite inscrutable and hence hard to
reverse engineer. Second, to make it hard to discover the
target addresses in the mapping table, in place of each
target address T we store a value XT that is the XOR of
T and the corresponding trap address S.
3.3 Signal Handling
When an instruction raises a signal, the processor stores
its address S on the stack, then traps into the kernel. Fig-
ure 3(a) shows the components and control transfers that
normally occur when a program raises a signal at address
S and has installed a signal handler that returns back
to the program at the same address. (If no handler has
been installed, the kernel takes the default action for the
signal.) Figure 3(b) shows the components and control
transfers that occur in our implementation. The essential
differences are that we return control to a different target
address T, and we do so by causing the kernel to transfer
control to our restore code rather than back to the trap
address. We allow obfuscated programs to install their
own signal handlers, as described below.
USENIX Association
16th USENIX Security Symposium
279
Kernel trap handler
S: Trap instruction
S: Trap instruction
User’s signal handler
Kernel restore function
T: Target instruction
Kernel trap handler
Our signal handler
Kernel restore function
Our restore function
(a) Normal signal handling
(b) Our signal handling path
Figure 3: Signal Handling: Normal and Obfuscated Cases
Handler and Restore Code Actions
We trigger the path shown in Figure 3(b) when a signal
is raised from a trap location that we inserted in the bi-
nary. However, other instructions in the original program
might raise the illegal instruction, ﬂoating point excep-
tion, or segmentation fault signals. To tell the difference,
we use a global array that is initialized to zero. In the
Setup code before each of the traps we insert in the pro-
gram, we set a random element of this array to a non-zero
value. In our signal handler, we loop through this array to
see if any value is nonzero (and we then reset it to zero).
In the normal case where our signal handler is pro-
cessing one of the traps we inserted in the program, it
overwrites the kernel restore function’s return address
with the address of our restoration code. That code (1)
invokes the perfect hash function on the trap address S
(which was put in the stack space allocated by our signal
handler), (2) looks up the original target address, (3) re-
sets the stack frame as appropriate for the type of control
transfer and (4) transfers control (via a return instruction)
to the original target address.
To make it harder for an attacker to ﬁnd and reverse
engineer the signal handler, we disperse our handler and
restore code over the program, i.e., we split the code into
multiple basic blocks and interleave these in with the
original program code. We also make multiple slightly
different copies of each code block so that we are not
always using the same locations each time we handle a
signal. As will be shown in Section 5, we are able to
obfuscate many hot instructions as a side effect of ob-
fuscating cold code. These include some of the code we
introduce to handle signals.
Interaction With Other Signals
We allow the original program to install signal handlers
and dynamically to change signal handling semantics.
By analyzing the binary, we determine whether it in-
stalls signal handlers:
this is done by checking to see
whether there are any calls to system library routines
(e.g., signal()) that install signal handlers. We trans-
form the code to intercept these calls at runtime and
record, in a table, the signals that are being handled and
the address of the corresponding signal handler. When
our signal handler determines that a signal did not get
raised by one of our obfuscations (by examining the ar-
ray of ﬂags), it consults this table. If the user installed
a handler, we call that handler then return to the original
program. Otherwise, we take the default action for that
kind of signal.
Although in general we are able to handle interactions
between signal handling in our code and the original pro-
gram, we discovered one instance of a race condition. In
particular, one of the SPECint-95 benchmark programs,
m88ksim, installs a handler for SIGINT, the interrupt sig-
nal. If we obfuscate that program, run the code, and in-
terrupt the program while it happens to be in our han-
dler, the program will cause a segmentation fault and
crash. To solve this type of problem, our signal han-
dler needs to delay the processing of other signals that
might be raised. (On Unix this can be done by having
the signal handler call the sigprocmask function, or
by using sigaction when we (re)install the handler.)
Once our trap processing code gets back to the restore
code block of the obfuscated program, it can safely be
interrupted because it is through manipulating kernel ad-
dresses. However, our current implementation does not
yet block other signals.
An even worse problem would occur in a multi-
threaded program, because multiple traps could occur
and have to be handled at the same time. Signal han-
dling is not thread safe in general in Unix systems, so
our obfuscation method cannot be used in an arbitrary
multithreaded program. However, this is a limitation of
Unix, not our method.
280
16th USENIX Security Symposium
USENIX Association
3.4 Attack Scenarios
4.1 Evaluating Disassembly Errors
Recall that our goal is to make static disassembly difﬁ-
cult enough to force any adversary to resort to dynamic
techniques. Here we discuss why we believe our scheme
is able to attain this goal.
We assume that our approach is known to the adver-
sary. As discussed in Section 3.2, the speciﬁcs of the ob-
fuscation as applied to a particular program—the setup
code, the kind of trap used for any particular control
transfer, the code sequence used to generate traps, as
well as the bogus control transfers inserted after the trap
instruction—are chosen randomly. This makes it difﬁcult
for an adversary to identify the location of trap instruc-
tions and bogus control transfers simply by inspecting
the obfuscated code.
Since locating the obfuscation code by simple inspec-
tion is not feasible, the only other possibility to consider,
for statically identifying the obfuscation instructions, is
static analysis. This is difﬁcult for two reasons. The ﬁrst
is the sheer number of candidates: for example, in prin-
ciple any memory operation can raise an exception and is
therefore potentially a candidate for analysis. Secondly,
the problem of statically determining the values of the
operands of such candidate instructions is difﬁcult, both
theoretically [22] and in practice, especially because, as
discussed in Section 3.1, such operands need not be ﬁxed
constant values. Furthermore, if a byte sequence is en-
countered in the disassembly that does not encode a legal
instruction (and therefore cannot be subjected to static
analysis), it can be either a part of the obfuscation (i.e.,
is “executed” and causes a trap), or it can be data embed-
ded in the instruction stream: determining which of these
is the case is in general an undecidable problem.
4 Evaluation
We measure the efﬁcacy of obfuscation in two ways: by
the extent of incorrect disassembly of the input, and by
the extent of errors in control ﬂow analysis of the dis-
assembled input. These quantities are related, in the
sense that an incorrect disassembly of a control trans-
fer instruction will result in a corresponding error in the
control ﬂow graph obtained for the program. However,
it is possible, in principle, to have a perfect disassem-
bly and yet have errors in control ﬂow analysis because
control transfer instructions have been disguised as in-
nocuous arithmetic instructions or bogus control trans-
fers have been inserted.
We measure the extent of disassembly errors using a
measure we call the confusion factor for the instructions,
basic blocks, and functions.
Intuitively, the confusion
factor measures the fraction of program units (instruc-
tions, basic blocks, or functions) in the obfuscated code
that were incorrectly identiﬁed by a disassembler. More
formally, let A be the set of all actual instruction ad-
dresses, i.e., those that would be encountered when the
program is executed, and let P be the set of all perceived
instruction addresses, i.e., those addresses produced by
a static disassembly. Then A − P is the set of addresses
that are not correctly identiﬁed as instruction addresses
by the disassembler. We deﬁne the confusion factor CF
to be the fraction of instruction addresses that the disas-
sembler fails to identify correctly:2
CF = |A − P|/|A|.
Confusion factors for functions and basic blocks are cal-
culated analogously: a basic block or function is counted
as being “incorrectly disassembled” if any of the instruc-
tions in it is incorrectly disassembled. The reason for
computing confusion factors for basic blocks and func-
tions as well as for instructions is to determine whether
the errors in disassembling instructions are clustered in a
small region of the code, or whether they are distributed
over signiﬁcant portions of the program.
4.2 Evaluating Control Flow Errors
Two kinds of errors can occur when comparing the con-
trol ﬂow structure of the disassembled program Pdisasm
with that of the original program Porig. First, Pdisasm may
contain some edge that does not appear in Porig, i.e., the
disassembler may mistakenly ﬁnd a control ﬂow edge
where the original program did not have one. Second,
Pdisasm may not contain some edge that appears in Porig,
i.e., the disassembler may fail to ﬁnd an edge that was
present in the original program. We term the ﬁrst kind of
error overestimation errors (written ∆over) and the second
kind underestimation errors (written ∆under), and express
them relative to the number of edges in the original pro-
gram. Let Eorig be the set of control ﬂow edges in the
original program and Edisasm the set of control ﬂow edges
identiﬁed by the disassembler, then:
= |Edisasm − Eorig|/|Eorig|
∆over
∆under = |Eorig − Edisasm|/|Eorig|
2We also considered taking into account the set P − A of addresses
that are erroneously identiﬁed as instruction addresses by the disas-
sembler, but we rejected this approach because it “double counts” the
effects of disassembly errors.
USENIX Association
16th USENIX Security Symposium
281
Even if we assume a perfect “attack disassembler” that
does not incur any disassembly errors, its output will
nevertheless contain control ﬂow errors arising from two
sources. First, it will fail to identify control transfers that
have been transformed to trap-raising instructions. Sec-
ond, it will erroneously identify bogus control transfers
introduced by the obfuscator. We can use this to bound
the control ﬂow errors even for a perfect disassembly.
Suppose that ntrap control ﬂow edges are lost from a pro-
gram due to control transfer instructions being converted
to traps, and nbogus bogus control ﬂow edges are added
by the obfuscator. Then, a lower bound on underestima-
tion errors, min ∆under, is obtained when the only con-
trol transfers that the attack disassembler fails to ﬁnd are
those that were lost due to conversion to trap instructions:
min ∆under = ntrap/Eorig. An upper bound on overesti-
mation errors, max ∆over, is obtained when every bogus
conditional branch inserted by the obfuscator is reported
by the disassembler: max ∆over = nbogus/Eorig.
5 Experimental Results
We evaluated the efﬁcacy of our techniques using eleven
programs from the SPECint-2000 benchmark suite.3 Our
experiments were run on an otherwise unloaded 2.4 GHz
Pentium IV system with 1 GB of main memory running
RedHat Linux (Fedora Core 3). The programs were com-
piled with gcc version 3.4.4 at optimization level -O3.
The programs were proﬁled using the SPEC training in-
puts and these proﬁles were used to identify any hot spots
during our transformations. The ﬁnal performance of
the transformed programs was then evaluated using the
SPEC reference inputs. Each execution time reported
was derived by running seven trials, removing the high-
est and lowest times from the sampling, and averaging
the remaining ﬁve.
We experimented with three different “attack disas-
semblers” to evaluate our techniques: GNU objdump
[24]; IDA Pro [11], a commercially available disassem-
bly tool that is generally regarded to be among the best
disassemblers available;4 and an exhaustive disassem-
bler by Kruegel et al.
that was engineered to handle
obfuscated binaries [15]. Objdump uses a straightfor-
ward linear sweep algorithm, while IDA Pro uses recur-
sive traversal. The exhaustive disassembler of Kruegel
et al. takes into account the possibility that the input bi-
nary may be obfuscated by not making any assumptions
about instruction boundaries. Instead, it considers alter-
native disassemblies starting at every byte in the code
region of the program, then examines these alternatives
3We did not use the eon programs from this benchmark suite be-
4We used IDA Pro version 4.3 for the results reported here.
cause we were not able to build it.
using a variety of statistical and heuristic analyses to dis-
card those that are unlikely or impossible. Kruegel et al.
report that this approach yields signiﬁcantly better dis-
assemblies on obfuscated inputs than other existing dis-
assemblers [15]; to our knowledge, the exhaustive disas-
sembler is the most sophisticated disassembler currently
available.
In order to maintain a reasonable balance between
the extent of obfuscation and the concomitant runtime
overhead, we obfuscated only the “cold code” in the
program—where a basic block is considered “cold” if,
according to the execution proﬁles used, it is not exe-
cuted. We evaluated a number of different combinations
of obfuscations. The data presented below correspond to
the combination that gave the highest confusion factors
without excessive performance overhead: ﬂip branches
to increase the number of unconditional jumps in the
code (see Section 3.2); convert all unconditional control
transfers (jumps, calls, and function returns) in cold code
to traps; insert bogus code after traps; and insert junk
bytes after jmp, ret, and halt instructions.
Disassembly Error
The extent of disassembly error, as measured by confu-
sion factors (Section 4.1) is shown in Figure 4(a). The
results differ depending on the attack disassembler, but
the results for each disassembler are remarkably consis-
tent across the benchmark programs. Because we have
focused primarily on disguising control transfer instruc-
tions by transforming them into signal-raising instruc-
tions, it does not come as a surprise that the straightfor-
ward linear sweep algorithm used by the objdump dis-
assembler has the least confusion at 43% of the instruc-
tions on average. However, these are spread across 68%
of the basic blocks and 90% of the functions. The other
disassemblers are confused to a much greater extent—
55% for the exhaustive disassembler and 57% for IDA
Pro, on average—but these are more somewhat more
clustered as they cover only about 60% of the basic
blocks and slightly fewer functions (89% and 85%, re-
spectively).
Overall, the instruction confusion factors show that
a signiﬁcant portion of each binary is disassembled in-
correctly; the basic block and function confusion factors
show that the errors in disassembly are distributed over
most of the program. Taken together, these data show
that our techniques are effective even against state-of-
the-art disassembly tools.
We have also measured the relative confusion factors
for hot and cold instructions, i.e., those in hot versus cold
basic blocks. For objdump, the confusion factors are
nearly identical at 42% of the hot instructions and 44% of
282
16th USENIX Security Symposium
USENIX Association
the cold instructions (again on average). The exhaustive
disassembler was confused by fewer of the hot instruc-
tions (35%) but more of the cold instructions (59%). IDA
Pro did the best on hot instructions at 28% confusion, on
average, but worst on cold instructions at 62% confusion.
It is not surprising that Kruegel and IDA Pro did better
with hot code, because we did not obfuscate it except to
insert junk after hot unconditional jumps, and junk by
itself should not confuse an exhaustive or recursive de-
scent disassembler. Then again, these disassemblers still
failed to disassemble about a third of the hot code.
As an aside, we had thought that interleaving hot and
cold basic blocks would cause more of the obfuscations
in cold code to cause disassembly errors to “spill over”
into succeeding hot code and increase the confusion
there. This turns out to be the case for objdump, which
is especially confused by junk byte insertion. However,
IDA Pro and the exhaustive disassembler are still able to
ﬁnd most hot code blocks. In fact, such interleaving in-
troduces additional unconditional jumps in the code, e.g.,
from one hot block to the next one, jumping around the
intervening cold code. The exhaustive disassembler and
IDA Pro are able to ﬁnd these jumps and use them to im-
prove disassembly, resulting in less confusion when hot
and cold code are interleaved. Morever, programs run
more slowly when hot and cold blocks are interleaved