pared to Figure 5a. This result implies that many posts for which
users do not care to limit sharing appear near the top, which are
more tolerable false positives than posts where the user actually
does not want to limit the audience. Note that this figure is only for
explanation purposes, as a priori knowledge of the doesn’t matter
class would not be possible in the real world. Thus, for performance
purposes, Figure 5a presents the realistic evaluation. We further
analyze false positives in Section 8.5.
To understand the tradeoff between false positives and false neg-
atives in prediction, we perform precision-recall analysis. Figure 6
shows the precision-recall curve for friend-post pair predictions.
For example, if we show the first 3 examples to users, we achieve
1.0 precision, which means all 3 examples are correctly labeled
limit sharing. However, very low recall shows that we missed many
posts for which users wish to limit sharing. If we set the cutoff to
match the distribution of limit sharing (i.e., k = 30), then both the
precision and recall are 0.49. If one were to compare this approach
to a heuristic of suggesting posts to reevaluate based on a low level
of interaction, the precision-recall area under the curve (PR AUC) is
0.118. Contrasted with XGBoost’s 0.493 AUC value, this represents
a 317% improvement over using the level of interaction with friends
to predict sharing reevaluation.
While these accuracy and precision numbers would be unreason-
able to deploy in a fully automated system, our intended deployment
for this task is part of a human-in-the-loop system (see Section 2).
Thus, we seek to achieve a balance of precision and accuracy, and
Figure 6: Precision-Recall curve for the friend-post dataset.
incorrect suggestions incur only a light time cost on users. Further-
more, deployment of such a system with satisfactory accuracy and
precision would enable the collection of further user decisions to
refine the performance of the classifier and suggestion mechanism.
Beyond simply achieving good performance, we also investigate
which features are most predictive of the limit sharing decision.
Table 4 lists the top 10 most important features according to XG-
Boost. From this list, we see that there is a mix of audience features
(days since first and last communication, number of wall words
exchanged, reaction counts), post statistics (age of the post, num-
ber of likes and comments of the post, whether the audience has
previously been changed), and survey or user features (age of the
account, user’s number of friends, if the user had a personal life
change). One notable result is that 9 out of 10 of these features can
be collected without user interaction, while the other feature (if the
user had a personal life change since the post) may require asking
the user explicitly. Although not displayed here, some Word2Vec
components and content classification categories were important,
specifically in the top-20 features, while LIWC features and senti-
ment analysis did not appear to be highly important.
Next, we explored the effect of audience (or friend) context in
the prediction. Figure 7 compares the precision@k curves when
using all features, excluding friendship features, and relying only
on friendship features using XGBoost. This suggests that while
friendship context alone is insufficient, friendship features do play
an important role in predicting friend-post pair privacy preferences.
1102030prediction cutoff k0.00.20.40.60.81.01.2precisionRFXGBXGB autoRandomInteraction1102030prediction cutoff k0.00.20.40.60.81.01.2precisionRFXGBXGB autoRandomInteraction0.00.20.40.60.81.0recall0.00.20.40.60.81.01.2precisionRFXGBXGB autoRandomInteractionMoving Beyond Set-It-And-Forget-It Privacy Settings on Social Media
CCS ’19, November 11–15, 2019, London, United Kingdom
Friend: Days since first communication with friend
Post: Age of the post
User: Number of friends
User: Age of the account
Friend: Days since last communication with friend
Post: Number of likes and comments on the post
Friend: Number of wall words exchanged from friend to user
User: If the user had a personal life change since the post
Post: If the audience of the post had changed previously
Friend: Reaction counts from the friend to the user
Table 4: Top 10 important features identified by XGBoost,
sorted in descending of importance.
Figure 8: Comparing different methods for handling doesn’t
matter responses during training with XGBoost.
Figure 7: Comparing precision@k curves using friend fea-
tures, no friend features, and only friend features for XG-
Boost. Post features are better than friend features individ-
ually, but combining them gives the best result.
We perform additional analysis on the neutral label doesn’t matter
because it was a large proportion of the friend-post pair dataset
(36.4%). We do so by considering different variations for training our
model, without changing anything in the testing data, with XGBoost
as the classifier. Since the response doesn’t matter is ambiguous, we
consider treating it as different labels to see how the precision@k
curves vary. We vary the training setup in four ways: (1) original:
keep doesn’t matter as the do not limit sharing category, which
is our original setup; (2) dm → limit: treat doesn’t matter as the
decision to limit sharing, training with the original limit audience
labels; (3) dm → class: treat doesn’t matter as a separate class,
transforming our problem into a three-class classification problem;
(4) dm→removed: remove doesn’t matter labels from the training
process. In order to allow fair comparison across training setups, we
use the exact same test data for all training setups and treat doesn’t
matter as do not limit sharing in the test data. For evaluation, we
order test examples based on the probability of being limit sharing.
Figure 8 shows that our original setup overall performs the best,
especially for the top examples, while treating doesn’t matter as its
own class in training is a close second. This result is intuitive since
we wish to identify posts to limit sharing, and separating them
clearly from other examples during training will result in better
classification. When we remove the label for doesn’t matter, we get
some decrease in precision. When treating doesn’t matter as limit
sharing, the precision@k drops significantly. The reason is that the
classifier learns over two different types of labels for limit audience,
which interferes with predicting the positive class during testing.
8.4.2 Post Dataset Prediction. Next, we study whether it is possible
to predict if a user would want to limit sharing of a post entirely,
rather than for specific friends. Figure 9 shows the precision@k
curves for individual post prediction, using all classifiers. In this
dataset, Logistic Regression performs the best. In Figure 9, the
Figure 9: Average precision@k for post dataset.
precision is relatively low even for top results (low k). Since the
underlying distribution of limit sharing for this dataset is 13.9%, a
cutoff at that percentage would be reasonable in a deployed system.
This corresponds to predicting the top 11 results per test fold where
the precision is 0.288. The best classifier for this task is logistic
regression, especially at lower cutoffs, where deep neural networks
perform especially poorly.
In order to understand what contributes to the false positives
(e.g., 0.6 for precision@1 for post prediction) and false negatives,
we further explored the reason behind misclassification of posts.
More specifically, we filtered out the posts and friend-post pairs
that were misclassified (false positives and false negatives) by our
predictor by a significant margin. We then performed qualitative
analysis on the participant-provided justification for their decisions
about these posts’ privacy settings to unpack possible rationales.
8.5 Analyzing Post Prediction Inaccuracy
Here, we qualitatively investigate the predictions missed by our
classifier and provide a comprehensive analysis of these misclassi-
fied posts. We envision this analysis to be beneficial for future study
designs by allowing researchers to gain insight into useful features
to account for while building such automated learning tools. In
addition, we also highlight the need for understanding personalized
user contexts when designing such human-in-the-loop interfaces.
We perform this analysis on both the post dataset and the
friend-post dataset predictions. We use the percentage of limit
sharing choices in the training data as the cutoff k and aggregate
all false positives and negatives across the 5 testing folds. For false
negatives, we focus on suggestions ranked in the bottom 50% of the
aggregated set as these are misclassified by a significant margin.
1102030prediction cutoff k0.00.20.40.60.81.01.2precisionWith Friend FeaturesWithout Friend FeaturesOnly Friend Features1102030prediction cutoff k0.00.20.40.60.81.01.2precisionoriginaldm->limitdm->classdm->removedRandomInteraction14812prediction cutoff k0.00.20.40.60.81.0precisionLRRandomCCS ’19, November 11–15, 2019, London, United Kingdom
Mondal et al.
Post-based features
Details of content associated with a post (e.g., labeling images / video)
Classes of sensitive information within the post text or content
Similarity analysis of post content with the participant’s present interests
Friend-based features
The interests, likes, and dislikes of the participant’s friends
If particular friends are close family or otherwise related
Frequency of offline interaction between the participant and their friends
Table 5: Potential features to collect in future studies.
A fair number (42%) of misclassified posts were caused by the
absence of accurate predictive features in our dataset. A signif-
icant number of these misclassified posts are linked to external
content such as associated images, videos, or news articles. To en-
sure participants’ privacy, and due to a lack of discussion in current
related work about significant predictive features, we chose not to
collect features specific to posts’ external content. In other cases,
participants’ responses also suggest the presence of whole classes
of sensitive content, e.g. “I would like posts of my children to be
as private as possible.” While we collect individual examples and
reasons, sufficiently described classes of sensitive content would
likely be a helpful supplement to our approach.
One additional source of inaccuracy was a lack of features spe-
cific to participants’ friends. For 16% of misclassified friend-post
pairs, participants mentioned the content of a given post being
closely aligned with their particular friend’s interests. For instance,
one participant explained, “I think she likes articles about animals.”
There were also cases where participants mentioned that their
friend would not like the content or it would be controversial. As
our friend-based features do not account for the preferences of par-
ticipants’ friends and we did not attempt to collect this information
for privacy and consent reasons, such instances are hard to predict.
Some misclassified posts were shared with close friends or family
members with whom users wanted to continue sharing the posts.
While Facebook allows participants to list family members on their
profile, we did not collect this information. In other friend-post
pairs, the level of interaction was not always representative of the
closeness of their relationship and led to an inaccurate prediction.
For instance, one participant said about a specific friend-post pair,
“He’s a long distance boyfriend that I grew up with so I don’t really
care too much if he sees it or doesn’t.” As the dynamics of Facebook
and its users change, online interaction levels will not always be
sufficient to determine complex social connections. Having access
to additional complementary features (e.g., family relationships)
can enable the development of more accurate classifiers.
In summary, elaborating on our findings from this investigative
analysis on mispredictions, Table 5 presents a list of useful features
that, if collected, could enable more accurate models for predicting
privacy-setting misalignment in the future.
Our analysis also revealed the strong presence of personalized
context, which limits the extent to which fully automated classifiers
can predict an individual’s preferences. For example, when explain-
ing a change to the privacy setting of a post, a participant wrote, “I
no longer participate in these activities and don’t find them appropri-
ate any longer.” Inferring a connection between participation in an
activity, its appropriateness, and a desired sharing setting may in
fact be possible, but such nuanced and subjective connections are
unlikely to be currently achievable. In other misclassified instances,
participants’ explanations emphasized the audience of a post. For
example, one participant wrote, “It was set to friends and that’s the
only people who I’d want to have my phone number.” Without access
to preferences regarding explicitly curated sharing lists, developing
an accurate understanding of friends’ closeness in light of their
limited social media interaction is non-trivial.
While the goal of any automated inference system is to minimize
or eliminate inaccuracies, a domain as subjective and contextual
as personal information sharing is bound to have occasional mis-
takes. When initially designing such a system, a human-centered
investigation of the mental models and preferences regarding these
decisions can provide valuable insights regarding what additional
features to collect, as well as which inference rules may not accu-
rately generalize across different individuals.
9 DISCUSSION AND CONCLUSIONS
For users, access control is typically a set-it-and-forget-it endeavor.
Even if the privacy setting a user has chosen for a social media post
was accurate at the time it was set, it may be inappropriate moving
forward. This mismatch can result from changes in the user’s life
and relationships, in addition to changes in the affordances and
usage of the sharing platform itself. In our user study, we asked 78
Facebook users to evaluate five of their previous Facebook posts. For
one-quarter of these posts, participants reported that they preferred
to move forward with a privacy setting different from the one
currently set. Participants wanted to reduce posts’ audience sizes
roughly as often as they want to increase them.
While we had initially hypothesized that one could predict which
privacy settings ought to change based on how frequently partic-
ipants interacted with particular friends or when they became
Facebook friends, these characteristics had no predictive power
for the task at hand. Participants desired to maintain sharing with
low-interaction (but high-importance) classes of friends like family
members. This insight is in line with previous work on invisible
audiences [9, 48] and further highlights the importance of low-
interaction friend connections on social networks.
In contrast, we showed promising results when building predic-
tive models for users who wish to limit the privacy of past posts.
Our results show that predicting the desired privacy settings of
friend-post pairs is a particularly viable approach. We find that it
is possible to automatically generate a ranked list of friend-post
pairs for which the highest ranked pairs are likely to be cases for
which the user wishes to retrospectively limit sharing for the post.
Compared to baseline methods that consider the level of publicly
visible interaction on Facebook, our predictive models perform
more than three times better when identifying the friend-post pairs
where the user would want to limit the audience. Additionally,
when considering the most useful features in our predictive models,
we found that focusing only on features that can be collected auto-
matically (rather than requiring explicit user interaction) minimally
impacts predictive performance. Thus, the initial identification of
such friend-post pairs can proceed without burdening users.
Potential deployment: Privacy decisions are often nuanced
and highly contextual. As our results on low-interaction, yet high-
importance, Facebook friends illustrate, the data necessary to fully
Moving Beyond Set-It-And-Forget-It Privacy Settings on Social Media
CCS ’19, November 11–15, 2019, London, United Kingdom
contextualize a privacy decision may not even be available in the
system in the first place. Furthermore, while our predictive models
are successful at ranking friend-post pairs such that the highest
ranked pairs are likely to require privacy reevaluation, the current
versions of these models have insufficient accuracy for automati-
cally determining privacy settings for all posts.
As a result, we imagine that our predictive models would be most
successfully deployed as part of a human-in-the-loop interface. For
example, similar to Facebook’s “friends you may know” suggestion
box, we imagine our classifier’s highest-ranked suggestions being
presented to the user as “posts whose privacy settings you may
wish to revisit.” Users could actively engage with these suggestions,
evaluating them in terms of their unique knowledge outside the
system (e.g., about their intended self-presentation and real-world
relationships with the recipients). Because of this human-in-the-
loop process, near-perfect prediction accuracy is not necessary.
False positives generated by the classifier will be evaluated by the
user, who will likely choose to keep the current privacy setting.
While a high rate of false positives might discourage attention and
engagement, our classifier results suggest that most of the highly
ranked friend-post pairs are likely to be true positives. As a result
of this human-in-the-loop aspect, the posts that are hidden based
on the user’s affirmative decisions are those they intend to hide.
When dealing with modern volumes of friend-post pairs for
which to maintain proper privacy settings, our work demonstrates
a promising approach to partially automating this process. This
approach promises to focus the user’s attention toward privacy
settings that need to be revisited far better than requiring users to
manually sift through past posts. Future work, however, is essential
for further specifying and designing potential human-in-the-loop
interfaces, as well as evaluating them in practice.
Low-interaction friends can be important: Our results high-
light participants’ desire to keep sharing with low-interaction, but
high-importance, friends, such as family members. Any interaction-
based cutoff for removing or reevaluating sharing decisions would
incorrectly remove these connections. This insight is in line with
previous work on invisible audiences [9, 48].
Additional external data can better contextualize posts: In
the case of inaccuracies, the data needed to correctly classify posts
was often not available through Facebook. Future research in this
area can mine external (e.g., the content to which URLs point) and
non-textual data (e.g., images, videos). At a high level, participant
responses suggested that individuals intend to broadly share con-
tent of general interest (e.g., news and humor) while restricting the