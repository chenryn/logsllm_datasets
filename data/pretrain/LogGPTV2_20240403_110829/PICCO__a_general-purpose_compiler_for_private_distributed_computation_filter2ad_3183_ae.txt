67.8
1,062
703.7
1,970
13,458
86,765
21.2
42.3
105.8
212.7
319.1
48,431
201,077
3,256
13,053
315
3,149
9,444
3,936
16,126
251,913
98,678
276,277
1,894,420
–
5,038
10,092
25,205
50,816
75,874
9,479,330
–
541,656
2,140,630
0.18
0.60
1.60
0.27
0.45
2.41
256.7
649.6
3,689
20,579
0.17
0.22
0.35
0.57
35.1
4,258
16,038
830
2,761
31.6
32.3
34.5
31.6
32.1
35.7
6,288
12,080
47,654
170,872
31.1
31.3
31.5
31.8
3,179
116,632
432,456
74,704
172,455
71
82
127
132
168
1,715
7,115
15,145
66,023
317,692
72
102
117
132
652 [34]
69,980
196,198
24,273
55,088
203
249
325
264
376
2,961
22,208
47,636
203,044
869,582
188
203
254
284
N/A
214,286
498,831
75,820
172,266
1,198
3,429
10,774
3,419
18,853
N/A
4,450
N/A
N/A
N/A
793
850
933
1,037
N/A
N/A
N/A
N/A
N/A
1,831
5,823
11,979
5,244
21,843
N/A
5,906
N/A
N/A
N/A
816
1,238
989
1,265
N/A
N/A
N/A
N/A
N/A
Table 2: Performance of representative programs using PICCO.
public int main() {
public int i, j, k, S;
smcinput(S, 1, 1);
int A[S][S], B[S][S], C[S][S];
smcinput(A, 1, S*S);
smcinput(B, 1, S*S);
for (i = 0; i  l) {
m = (r + l)/2;
mergesort(l, m);
mergesort(m + 1, r);
for (i = size >> 1; i > 0; i = i >> 1)
for (j = 0; j  A[k+i+l]) {
tmp = A[k+l];
A[k+l] = A[k+i+l];
A[k+i+l] = tmp;
}
}
}
public int main() {
public int i, median = K/2;
smcinput(A, 1, K);
mergesort(0, K-1);
smcoutput(A[median], 1);
return 0;
}
Figure 4: Basic mergesort median program.
plexity to the minimal single round and thus the performance is
bounded by a one-way communication delay from below. In our
experiments, the performance was improved by 2–3 orders of mag-
nitude depending on the problem size and the savings will continue
to increase for larger computational problems. The use of threads
additionally improves the running time for problems of large size
by a small factor that depends on the number of cores.
Mergesort computation is dominated by O(m log2 m) compar-
isons for a set of size m and this growth is reﬂected in the run-
times of the unoptimized (sequential) functionality. The use of
concurrent loop iterations greatly decreases the time that the merge
step takes, but for this functionality the use of threads to concur-
rently sort the ﬁrst half and the second half of the set also im-
proves the performance. The round complexity of mergesort is
O(log2 m) comparisons, but we do not achieve it because the num-
ber of threads is limited to the number of cores. (Likewise, our
Sharemind program written in a similar way does not achieve opti-
mal round complexity.)
For the AES implementation, the best performance can be achieved
when the computation is in GF(28) and thus the user needs to spec-
ify this ﬁeld as a conﬁguration parameter. Then the user secret-
shares each byte of the key and message with the computational
nodes. Recall that each round of AES consists of AddRoundKey,
SubBytes, ShiftRows, and MixColumns algorithms and the most
complex part of round key computation is the same as SubBytes.
When using arithmetic in GF(28), all operations other than S-box
computation in SubBytes and round key computation are linear and
thus are performed non-interactively. Instead of following the tra-
ditional implementations of the S-box as a table lookup, we write
the user program to compute the transformation directly, where the
computation of the inverse and bit decomposition is implemented
as suggested in [20]. One round of key expansion and one round of
void mergesort(public int l, public int r) {
public int i, j, k, m, size;
size = r - l + 1;
int tmp[size];
if (r > l) {
m = (r + l)/2;