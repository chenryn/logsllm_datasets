代码清单14-2 Local模式下用Java编写的Pig脚本
package cn.edu.ruc.cloudcomputing.book.chapter14；
import java.io.IOException；
import org.apache.pig.PigServer；
public class tst_local{
public static void main（String[]args）{
try{
PigServer pigServer=new PigServer（"local"）；
runIdQuery（pigServer，"/path/Student"）；//调用函数
}
catch（Exception e）{}
}
public static void runIdQuery（PigServer pigServer, String inputFile）throws
IOException{
pigServer.registerQuery（"A=load'"+inputFile+"'using PigStorage（'：'）as
（Sno：chararray, Sname：chararray, Ssex：chararray, Sage：int, Sdept：chararray）；"）；
pigServer.registerQuery（"B=foreach A generate Sname, Sage；"）；
pigServer.store（"B"，"/path/tstJavaLocal.out"）；
}
}
下面我们将通过14.2.3节中所介绍的在嵌入式方式下运行pig脚本的命令来对此文件进行编译、运行。
首先，使用下面命令对此Java源文件进行编译：
$javac-cp pig-*.*.*-core.jar local.java
当编译完成后，通过下面命令运行“.class”类文件：
$java-cp pig-*.*.*-core.jar：.local
然后打开生成的结果文件“tstJavaLocal.out”，我们会发现它和前面两种方式生成的结果是完全相同的。
14.6.2 MapReduce模式
这一节我们将结合上面给出的实例具体讲解如何在Pig的MapReduce模式下对数据进行操作。同时，我们同样对Pig在MapReduce模式下的三种运行方式进行详细介绍。
1.Grunt Shell
MapReduce模式下，Pig的使用其实是Pig Local模式和Hadoop操作的结合。因为要运行MapReduce程序我们需要在Hadoop的HDFS文件系统下对文件进行操作，但是在Linux系统下我们是看不到HDFS文件系统下的文件的，所以就不能使用常规的操作来“搬运”文件。这里，我们就需要使用与HDFS相关的命令在HDFS文件系统下执行Pig的命令。
首先，从终端进入Pig的MapReduce模式，然后使用copyFromLocal命令将文件从本地复制到HDFS文件系统中，如下所示：
grunt＞＞copyFromLocal srcpath/Student dstpath；
通过ls命令，我们可以查看是否成功将文件复制到相应的HDFS文件系统中了。操作完成后，我们就可以像在Local模式下一样对文件进行操作了。这里，Pig会自动地将我们的命令分散到分布式系统中去执行，然后返回给用户。
2.脚本文件
参考Local模式下脚本文件的执行。
3.嵌入式程序
参考Local模式下脚本文件的执行，这里我们给出MapReduce模式下程序的代码，可以看到，除了指定相应的模式之外，MapReduce模式下程序代码和Local模式没有什么不同。这是因为，所有的分布式操作将由Pig系统自动执行，而不需要用户在MapReduce的编程框架下设计程序，这就大大地减轻了用户的负担，也使得用户能更容易掌握Pig嵌入式程序，见代码清单14-3。
代码清单14-3 MapReduce模式下的Pig脚本
package cn.edu.ruc.cloudcomputing.book.chapter14；
import java.io.IOException；
import org.apache.pig.PigServer；
public class tst_mapreduce{
public static void main（String[]args）{
try{
PigServer pigServer=new PigServer（"mapreduce"）；//MapReduce模式
runIdQuery（pigServer，"/path/Student"）；//调用函数
}
catch（Exception e）{}
}
public static void runIdQuery（PigServer pigServer, String inputFile）throws
IOException{
pigServer.registerQuery（"A=load'"+inputFile+"'using PigStorage（'：'）as
（Sno：chararray, Sname：chararray, Ssex：chararray, Sage：int, Sdept：chararray）；"）；
pigServer.registerQuery（"B=foreach A generate Sname, Sage；"）；
pigServer.store（"B"，"/path/tstJavaMapReduce.out"）；
}
}
14.7 Pig进阶
本节将继续介绍Pig在实际中的应用，为了体现Pig系统的特点，本节中的所有操作都将在Hadoop MapReduce模式下进行。另外，我们选取了一组很有特点的例子进行数据分析，相信这对大家的理解一定很有帮助。
为了让大家能够更好地理解下面的操作，我们使用Grunt Shell方式进行数据分析，这样能够让大家更加清楚地理解Pig的执行过程。
 14.7.1 数据实例
结合14.6节中的数据，我们再给出另外两个数据。
第一组数据是14.6节中的学生表所对应的课程表（课程号、课程名、先修课程号、学分），它包含如下几条记录：
01，English，4
02，Data Structure，05，2
03，DataBase，02，2
04，DB Design，03，3
05，C Language，3
06，Principles Of Network，07，3
07，OS，05，3
它们所对应的数据类型如下所示：
Course（Cno：chararray, Cname：chararray, Cpno：chararray, Ccredit：int）
另外一组数据为学生表和课程表所对应的选课表（学号、课程号、成绩），它包含如下几条记录：
201000101，01，92
201000101，03，84
201000102，01，90
201000102，02，94
201000102，03，82
201000103，01，72
201000103，02，90
201000104，03，75
它们所对应的数据类型如下所示：
SC（Sno：chararray, Cno：chararray, Grade：int）
14.7.2 Pig数据分析
下面我们将对学生表、课程表和选课表进行数据分析操作。这一小节将分三个部分，分别计算学生的平均成绩、找出有不及格成绩的学生和找出修了先修课为“C Language”的学生。在语法上，Pig Latin虽然没有关系数据库中的关系操作语言强大，但是因为Pig系统架设在Hadoop的云平台之上，所以在处理大规模数据集的时候，Pig的效率却非常高。
1.计算每个学生的平均成绩
这里要求计算出每个学生的平均成绩，并且输出每个学生的姓名及其平均成绩。
我们先对数据进行分析。很容易看出，我们需要对学生表和选课表进行操作。首先，需要对学生表和选课表基于学号字段进行连接；然后，基于学号对学生数据进行操作，这时需要对每个学生所有的课程成绩分别求和，并除以课程总数；最后，按格式输出结果。
对于传统的关系型数据库的关系操作语言来说，为了实现这个目标，我们需要AVG运算和GROUP运算同时使用，十分方便。下面，我们就Pig Latin语言给出相应的操作。
1 从源数据文件学生表和选课表中读取数据
2 对学生表和选课表基于学号字段进行连接操作
3 基于学号对连接生成的表进行分组操作
4 计算每个学生的平均成绩
上面是对操作的描述，接下来需要对上述描述用Pig Latin语言来实现。
（1）读取数据
MapReduce在Hadoop的HDFS文件系统中对数据进行操作，所以需要复制要操作的数据到HDFS中：
copyFromLocal Student Student；
copyFromLocal SC SC
可以使用Hadoop的ls命令查看数据是否复制成功，确认后再读取数据：
A=load'Tmp/Student'using PigStorage（'：'）as（Sno：chararray, Sname：chararray, Ss
ex：chararray, Sage：int, Sdept：chararray）；B=load'Tmp/SC'using PigStorage（'，'）
as（Sno：chararray, Cno：chararray, Grade：int）；
（2）连接操作
使用JOIN关键字对A、B两组数据基于Sno字段进行连接操作。JOIN关键字的语法如下：
alias=JOIN alias BY{expression|'（'expression[，expression……]'）'}（，alias BY
{expression|'（'expression[，expression……]'）'}……）[USING'replicated'|'skewed'
|'merge'][PARALLEL n]；
下面是连接操作的命令：
D=Join A By Sno, B By Sno；
这里我们可以使用DUMP关键字来查看D中存储的数据，如图14-4所示。
图 14-4 对学生表和选课表进行连接操作后的结果
（3）分组操作
在进行分组操作之前，我们先提取必要的数据，这样不但减少了需要处理的数据量，而且让我们的操作更加简单。接着，我们基于学号字段对连接操作后的数据进行分组，如下所示：
E=Foreach D generate A：Sno, Sname, Grade；
F=Cogroup E By（Sno, Sname）；
我们再使用DUMP关键字查看一下F中的数据，如图14-5所示。接着用DESCRIBE分析F的模式，如图14-6所示。
图 14-5 F中的数据
图 14-6 F的模式
（4）计算学生的平均成绩
我们使用SUM关键字对学生成绩进行求和，使用COUNT关键字来计算课程的总数：
G=Foreach F Generate group.Sname，（SUM（E.Grade）/COUNT（E））；
下面，我们查看一下最终的结果，如图14-7所示：
图 14-7 学生平均成绩
因为Grade字段的数据类型为int，所以这里计算出的结果均为向下取整后的值。如果想要得到更为准确的数据，大家可以将Grade字段的数据类型设为Long或Float。
2.找出有不及格成绩的学生
这部分要求找出有不及格成绩的学生，并且输出学生的姓名和不及格的课程和成绩。
现在对问题进行分析。我们需要使用学生表来获取学生的姓名，使用课程表来获取学生的成绩和对应成绩的课程。
首先，我们还是需要读取源数据，然后使用连接字段将数据连接在一起，接着使用FILTER关键字过滤出我们需要的数据，最后提取需要的字段将数据输出。
这里我们不再像上面那样一步步地对数据进行分析了，下面给出Pig Latin操作语句：
A=load'/pigTmp/Student'using PigStorage（'：'）as（Sno：chararray, Sname：chararra
y, Ssex：chararray, Sage：int, Sdept：chararray）；--读取学生表
B=load'/pigTmp/SC'using PigStorage（'，'）as（Sno：chararray, Cno：chararray, Grade
：int）；--读取选课表
C=load'/pigTmp/Course'using PigStorage（'，'）as（Cno：chararray, Cname：chararray，
Cpno：chararray, Ccredit：int）；--读取课程表
D=Filter B By Grade＜60；--提前对B进行分析，过滤出需要的结果，减少操作的数据量
E=Join D By Sno, A By Sno；--连接操作
F=Join E By Cno, C By Cno；--连接操作
G=Foreach F Generate Sname, Cname, Grade；--输出结果
最后我们使用DUMP命令查看操作的结果，如图14-8所示：
图 14-8 不及格成绩的学生
3.找出修了先修课为“C Language”的学生
这里要求找出修了先修课为“C Language”的学生，并且输出学生的姓名。
现在，我们先对问题进行分析，从课程表的数据结构可以看出：我们需要找出“C Language”这门课的课程号，然后找对应“Cpno”（此课程号的课程），最后找出修了此门课程的学生，并输出学生的姓名。