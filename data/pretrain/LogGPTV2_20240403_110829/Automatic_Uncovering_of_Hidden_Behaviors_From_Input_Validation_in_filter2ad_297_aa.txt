title:Automatic Uncovering of Hidden Behaviors From Input Validation in
Mobile Apps
author:Qingchuan Zhao and
Chaoshun Zuo and
Brendan Dolan-Gavitt and
Giancarlo Pellegrino and
Zhiqiang Lin
Automatic Uncovering of Hidden Behaviors From
Input Validation in Mobile Apps
Qingchuan Zhao∗, Chaoshun Zuo∗, Brendan Dolan-Gavitt†, Giancarlo Pellegrino‡, Zhiqiang Lin∗
∗The Ohio State University, †New York University, ‡CISPA Helmholtz Center for Information Security
Abstract—Mobile applications (apps) have exploded in popu-
larity, with billions of smartphone users using millions of apps
available through markets such as the Google Play Store or the
Apple App Store. While these apps have rich and useful function-
ality that is publicly exposed to end users, they also contain hidden
behaviors that are not disclosed, such as backdoors and blacklists
designed to block unwanted content. In this paper, we show that
the input validation behavior—the way the mobile apps process
and respond to data entered by users—can serve as a powerful
tool for uncovering such hidden functionality. We therefore have
developed a tool, INPUTSCOPE, that automatically detects both the
execution context of user input validation and also the content
involved in the validation, to automatically expose the secrets of
interest. We have tested INPUTSCOPE with over 150,000 mobile
apps, including popular apps from major app stores and pre-
installed apps shipped with the phone, and found 12,706 mobile
apps with backdoor secrets and 4,028 mobile apps containing
blacklist secrets.
I.
INTRODUCTION
Mobile applications (apps) now number in the millions
and provide useful functionality to billions of users. However,
alongside this useful functionality, many apps also include
hidden behaviors that are not publicly disclosed to users. These
behaviors may range from innocuous Easter eggs, such as
custom animations used in Google Hangouts when certain
keywords are mentioned, to more pernicious behaviors like
backdoors and censorship blacklists.
The harm caused by such behaviors affects both users
and developers. Users’ security may be compromised if an
ostensibly secure app, such as a lock screen app, contains a
backdoor that allows anyone who knows the master password
to bypass the lock screen. Backdoors may also harm devel-
opers when backdoor secrets are exposed, since the hidden
functionality can allow users to bypass restrictions built into
the app (e.g., a hidden menu protected by a password may
enable paid features for free). Finally, censorship blacklists
may prevent users from exercising their freedom of expression
by banning the discussion of sensitive political topics (although
such blacklists may also have benign uses, such as preventing
users from choosing offensive usernames).
Nor are such cases hypothetical: by manually examining
several mobile apps, we found that a popular remote control
app1 (10 million installs) contains a master password that can
unlock access even when locked remotely by the phone owner
when device is lost. Meanwhile, we also discovered a popular
1Note that we do not reveal the concrete names of apps whose vulnerabilities
remain unpatched at the time of publication.
screen locker app (5 million installs) uses an access key to
reset arbitrary users’ passwords to unlock the screen and enter
the system. In addition, we also found that a live streaming
app (5 million installs) contains an access key to enter its
administrator interface, through which an attacker can recon-
ﬁgure the app and unlock additional functionality. Finally, we
found a popular translation app (1 million installs) contains a
secret key to bypass the payment for advanced services such
as removing the advertisements displayed in the app.
Motivated by the above examples, in this paper we tackle
the problem of uncovering hidden behaviors in mobile apps.
The key insight of our work is the observation that hidden
functionality can be uncovered by examining ways user inputs
are validated. Over the past decades, we have seen several
program analysis techniques that can analyze user input val-
idation (e.g., [4], [9], [10], [28], [29], [35], [37]). However,
existing approaches are too often speciﬁc to the class of input
validation vulnerabilities, such as SQL injection (e.g., [17],
[25]). Also,
these approaches can only determine when a
program fails to neutralize dangerous characters and fall short
at determining when input validation results in the execution
of hidden functions.
INPUTSCOPE,
In this paper, therefore, we present a new static analysis
technique,
to automatically uncover hidden
functionality in mobile apps. INPUTSCOPE takes as input an
Android mobile app, and then combines static taint analysis
with backward slicing to determine when the input app
compares data entered by the user against some value stored
in the app or retrieved over the network. Then, INPUTSCOPE
exposes input-triggered secrets by introducing the novel
concept of the execution context of user input validation,
which combines two orthogonal aspects of the input validation
procedure: (i) the types of the data being validated, and (ii) the
code dispatch behavior associated with the result of the com-
parison, such as the number of times the validation is iterated
and the number of potential branches following a successful
validation. Finally, INPUTSCOPE inspects both the content and
execution context with the aid of a set of security policies to
expose the hidden secrets, e.g., backdoors or blacklist secrets.
We have implemented a prototype of INPUTSCOPE and
studied the incidence of user input-triggered hidden secrets in
top-installed mobile apps. To that end, we created a dataset
of 150,000 apps, including the top 100,000 apps from the
Google Play by the number of installations, the top 20,000
apps from an alternative store by the number of installations,
and 30,000 pre-installed apps extracted from Samsung smart-
phones’ ﬁrmware.
Our evaluation uncovered a concerning situation. We iden-
tiﬁed 12,706 apps containing a variety of backdoors such as
secret access keys, master passwords, and secret commands
that can allow users to access admin-only functions or attackers
to gain unauthorized access to users’ accounts. Also, our
analysis discovered 4,028 apps validating user input against
blacklisted words of different categories such as insults, racial
discrimination, political leader names, and mass incidents.
Contribution. In short, we make the following contributions:
• Novel Discovery. We ﬁnd that input validation in mobile
apps can be used to expose input triggered secrets such as
backdoors and blacklist secrets, and that input-dependent
hidden functionality is widespread in Android apps.
• Systematic Tool. We develop a systematic, open source
tool2, INPUTSCOPE, to automatically identify both execu-
tion context and validated target content from input val-
idation, which we use to uncover input-triggered secrets
in mobile apps.
• Comprehensive Evaluation. We have tested our tool
with more than 150,000 popular mobile apps and dis-
covered that 8.47% of them contain backdoor secrets
such as secret access keys, master passwords, and secret
commands, and 2.69% of them contain blacklist secrets
such as offensive forbidden words.
II. BACKGROUND AND MOTIVATION
In this section, we present the necessary background to
better understand INPUTSCOPE. We begin by describing the
types of input received by mobile apps in §II-A. Then, we
brieﬂy present how user input is typically validated in a mobile
app in §II-B. Finally, we examine three real world apps to
motivate the problem we aim to solve in §II-C.
A. Types of Input to Mobile Apps
Similar to the software in non-mobile platforms, the input
to a mobile app can be generated from a variety of sources,
which can be classiﬁed into the following two categories:
Internal Input. An app can directly read the inputs from
itself (e.g., for conﬁguration), and we call these inputs internal
inputs. There are two types of internal inputs, based on where
the input comes from: input coming from the program code
(e.g., a hardcoded string) of the app, or input coming from the
resource ﬁles (e.g., a database) carried within the app.
External Input. In addition to internal input, apps consume
input from the external world. Based on where an external
input comes from, we can also classify them into two sub-
categories:
• External Local Input. Typically, an app will consume
local input such as keystrokes typed by a user, input
that originates from system libraries (e.g., a GPS library),
or input
is generated by other apps locally and
transmitted via an intent.
• External Remote Input. In addition to local input, an app
can also consume input from remote servers or external
peripherals (e.g., a bluetooth device). We call these inputs
that
2The source code is available at github.com/OSUSecLab/InputScope.
2
external remote inputs because they are generated by
remote parties.
B. How to Validate an Input
Input must be validated prior to being acted upon. Depend-
ing on whether the allowed inputs are known by the user, input
validation can be performed via either a blacklist or a whitelist:
• Blacklist. If an input is compared with a list that contains
the blocked content, this list is called a blacklist. In this
case, the user typically is not aware of the complete
list and the list is often not bounded (it can increase
over time); such lists are often kept secret. Anti-virus
signatures are an example of a blacklist and viruses should
not be aware of the signatures to prevent evasion.
• Whitelist. If an input is compared with a list that contains
the allowed content, this list is called whitelist. Unlike
blacklists, in which the item in the list is a secret, users
must know the items in the whitelist (and this list is often
bounded with a ﬁxed size), otherwise they will not be able
to use the system.
Input validation can be performed at either syntactic level
or semantic level (or both), and consequently we can have
syntactic validation and semantic validation:
• Syntactic validation. Syntactic validation operates on
structural properties of data, such as the format or size of
the input, with the goal to accept well-formed inputs and
disregard malformed ones (e.g., an invalid email address,
phone number, or zip code) [1].
• Semantic validation. Semantic validation focuses on the
meaning of the user input, e.g., a social app could check
whether an entered date is illegal, such as February
31st [1], and a shopping app could check whether the
number of the items in the shopping cart is greater than
0 when checking out.
C. Motivating Examples
Next, we present three real world examples to illustrate
how input validation can be used to reveal backdoors and
blacklist secrets.
Backdoor Secrets. If an input is used to bypass the access
control (e.g., authentication) in an app, this input is a backdoor
secret. We have witnessed numerous such backdoor secrets.
In the following, we use a popular ﬁle encryption app with
500,000+ installs, which is used to hide or lock private ﬁles
from being accessed by others, to illustrate how its validation
process exposes its master password (Figure 1).
In particular, we notice this app assigns a string converted
from a user input to variable v2 (at line 8 in Figure 1), where
the user input is identiﬁed by searching for its resource ID from
line 5 to 7. Then, variable v2 is used in a validation check at
line 11. In this validation, it has two conditions concatenated
with logic relation OR. In one of the conditions, the app checks
whether variable v2 is equal to a string value, b***1,3 which
is hardcoded in plaintext in the app. Because of the OR logic, if
3We redact the exact content of secret values for apps that have not ﬁxed at
the time of this writing and for which disclosure could cause negative impacts
for app developers.
Fig. 1: A backdoor triggered by a master password in a ﬁle
encryption app.
this sub-condition is satisﬁed, then the app will allow any user
to view all hidden or locked ﬁles by the original user who
has the correct password (stored in this.b). Otherwise, it
displays an error message, “Incorrect password”. This
hardcoded string is a backdoor secret that can be used to bypass
the entire access control mechanism implemented in the app.
Next, we use a dictionary app with 1 million installs as
an example to illustrate another type of backdoor, the secret
access key. As shown in Figure 2, this app uses variable
this.d to store user inputs at line 2. Then, the app converts
user input to a string and compares it with a hardcoded string,
q***d, to check equivalence. If their values are identical to
each other, then the app will remove advertisements displayed
in the app. Otherwise, it will continue with the normal actions
to translate user input text from English to Arabic. In fact,
removing advertisements is an in-app service with fees, which
means that this hardcoded string is a backdoor secret to bypass
app restrictions.
Fig. 3: Nickname validation revealing a blacklist in a news
app.
Speciﬁcally,
in line 4 for
further validation.
the user input validation for a nickname
goes through two methods. First,
the variable v0 is as-
signed with a user input String converted from a UI
widget this.a (at line 3). Then, validate_nickname
invokes isInterceptedNickName and passes variable
v0 as an argument
In
the invoked method, variable v0 is denoted as parameter
arg6. The app validates parameter arg6 in a while loop
against each element stored in an array v2 in line 19.
Array v2 contains values loaded from a local ﬁle (lines
13–15); the ﬁle name is “intercepted_word.txt” lo-
cated under the “/assets” directory. Within the while
loop that starts at
the app detects a match
between parameter arg6 and any element
in array v2,
then it will inform method validate_nickname of the
failure of the validation and validate_nickname will
show the error message “Nickname contains illegal
characters”. In this example, it is clear that the app ﬁlters
illegal characters in the nickname based on a blacklist, which
is stored locally, allowing its content to be extracted.
line 18,
if
Fig. 2: A backdoor triggered by a secret access key in a
dictionary app.
III. OVERVIEW
Blacklist Secrets. If a list is used to inspect the user input
to ﬁlter out unwanted items, we call
this list a blacklist
secret. Many apps use blacklists to validate user input. In the
following, we use a popular news app, which has 50,000 total
installs in Google Play, and 1.1 billion total installs in all al-
ternative markets together4, as an example to demonstrate how
its validation leaks its blacklist secrets. Because this app has
been obfuscated, for better illustration, we use human readable
method names (e.g., validate_nickname) instead of the
obfuscated names, as shown in Figure 3.
4https://www.qimai.cn/
The goal of INPUTSCOPE is analyzing the ways mobile
apps process user inputs to uncover hidden behaviors. Reach-
ing this goal is by no means trivial. In this section, we present
an overview of INPUTSCOPE. We ﬁrst describe the challenges
we must solve and insights we have in §III-A. Then, we
describe how INPUTSCOPE works in §III-B, and ﬁnally we
discuss the scope and assumptions in §III-C.
A. Challenges and Insights
We identify three key challenges to build INPUTSCOPE:
• C1: How to pinpoint secret-exposing validations. While