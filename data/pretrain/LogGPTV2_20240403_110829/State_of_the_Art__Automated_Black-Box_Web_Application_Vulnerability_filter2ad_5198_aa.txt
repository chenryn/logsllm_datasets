# State of the Art: Automated Black-Box Web Application Vulnerability Testing

**Authors:** Jason Bau, Elie Bursztein, Divij Gupta, John C. Mitchell  
**Affiliation:** Stanford University  
**Emails:** {jbau, divijg}@stanford.edu, {elie, mitchell}@cs.stanford.edu  
**Location:** Stanford, CA  
**Conference:** 2010 IEEE Symposium on Security and Privacy  
**DOI:** 10.1109/SP.2010.27

## Abstract
Automated black-box web application vulnerability scanners are tools designed to identify security vulnerabilities in web applications without access to their source code. To evaluate the current state of the art, we tested eight leading scanners to assess: (i) the types of vulnerabilities they test, (ii) their effectiveness against known and projected vulnerabilities, and (iii) the relevance of these vulnerabilities to those found in the wild. Our study utilized a custom web application with known and projected vulnerabilities, as well as previous versions of widely used web applications containing known vulnerabilities. The results highlight both the promise and limitations of automated tools, particularly noting that "stored" forms of Cross-Site Scripting (XSS) and SQL Injection (SQLI) are not effectively detected by many tools. This study aims to inform future research rather than evaluate specific vendors, so we do not provide comparative data or tool recommendations.

**Keywords:** Web Application Security, Black Box Testing, Vulnerability Detection, Security Standards Compliance

## I. Introduction
Black-box web application vulnerability scanners are automated tools that probe web applications for security vulnerabilities without access to the source code. While these tools have inherent limitations compared to code walkthroughs, automated source code analysis, and red team exercises, they also offer significant advantages. They simulate external attacks, provide cost-effective methods for detecting important vulnerabilities, and can configure and test defenses like web application firewalls. Given the importance of these tools in detecting vulnerabilities, we conducted a study to determine the effectiveness of leading scanners. Our goal is to report test results, identify the strengths and limitations of current tools, and suggest strategic directions for future research.

Web application security vulnerabilities, such as cross-site scripting, SQL injection, and cross-site request forgeries, are recognized issues with thousands of reported vulnerabilities each year. These vulnerabilities enable attackers to perform actions ranging from unauthorized account access to obtaining sensitive data like credit card numbers. In extreme cases, they can even reveal the identities of intelligence personnel. Due to these risks, web application vulnerability remediation has been integrated into major commercial and governmental standards, including PCI DSS, HIPAA, and the Sarbanes-Oxley Act. Web application scanners that detect vulnerabilities, offer remediation advice, and generate compliance reports are essential for meeting these mandates. The market for web vulnerability scanners has become highly active, with over 50 products approved for PCI compliance.

This paper presents a comprehensive study of current automated black-box web application vulnerability scanners, aiming to provide the necessary background for evaluating and identifying the potential value of future research. We tested eight well-known commercial scanners against a common set of sample applications. Our study addresses three key questions:
1. What vulnerabilities do the scanners test?
2. How representative are the scanner tests of real-world vulnerabilities?
3. How effective are the scanners?

Our goal is to assess the potential impact of future research, so we report aggregate data about all scanners and some data indicating the performance of the best-performing scanner on various measures. We do not provide comparative detection data or recommend specific tools, as this is not a commercial study. No single scanner consistently outperforms others across all vulnerability categories.

We outline our study methodology and summarize our most significant findings. We evaluated the set of vulnerabilities tested by the scanners and compared them with the distribution of real-world web application vulnerabilities. We used incidence rate data from VUPEN Security, an aggregator and validator of vulnerabilities reported by databases like NVD. We also compared the incidence rates of web application vulnerabilities against system vulnerabilities.

In the first phase of our experiments, we evaluated scanner performance on established web applications, using previous versions of Drupal, phpBB, and WordPress, all of which include known vulnerabilities. In the second phase, we constructed a custom testbed application with a wide range of contemporary vulnerabilities. Our testbed checks all vulnerabilities in the NIST Web Application Scanner Functional Specification and tests 37 of the 41 scanner vulnerability detection capabilities in the Web Application Security Consortium evaluation guide.

Our most significant findings include:
1. The most extensively tested vulnerabilities are Information Disclosure, Cross-Site Scripting (XSS), SQL Injection, and other forms of Cross-Channel Scripting (XCS). This testing distribution is roughly consistent with the real-world vulnerability population.
2. Many scanners are effective at following textually present links but struggle with links through active content technologies like Java applets, SilverLight, and Flash.
3. Scanners are generally effective at detecting well-known vulnerabilities, with an average detection rate of over 60% for basic "reflected" XSS.
4. Scanners performed poorly at detecting "stored" vulnerabilities. None detected our constructed second-order SQLI vulnerabilities, and the stored XSS detection rate was only 15%.

Our analysis suggests room for improvement in detecting certain vulnerabilities, and we propose potential areas of research. However, we did not measure the financial value of these tools or quantify the relative importance of detecting specific vulnerabilities. Scanners may still have significant value when used systematically as part of an overall security program.

The paper is organized as follows: Section II discusses the black-box scanners and their vulnerability test vectors. Section III establishes the population of reported web vulnerabilities. Section IV presents scanner results on previous versions of WordPress, phpBB, and Drupal. Section V discusses testbed results by vulnerability category and false positives. Section VI provides remarks on individual scanner performance and user experience. Section VII discusses related work, and Section VIII concludes by highlighting research opportunities.

## II. Black-Box Scanners
### A. Usage Scenario
To start a scanning session, the user typically enters the entry URL of the web application and provides login credentials. The user then specifies options for the scanner's page crawler to maximize coverage. Most scanners allow a "crawl-only" mode to verify the provided login and crawler settings. After setting the crawler, the user selects the scanning profile, or test vector set, and launches the scan. All scanners can proceed automatically, and most include interactive modes where the user can direct the scanner to scan each page. In our experiments, we set the scanner to run in automated mode with the most comprehensive set of tests available to maximize vulnerability detection.

### B. Software Architecture Descriptions
We tested two scanners, McAfee and Qualys, as remote services, configured via a web interface and launched from a vendor-run server farm. The other six scanners were tested as software packages running on a local computer, although NeXpose runs as a network service accessed via a browser. All scanners generate HTTP requests as test vectors and analyze the HTTP response for vulnerabilities. Local scanner engines generally run in a single process, except for Cenzic, which runs a separate browser process to render the HTTP response and find potential vulnerabilities.

### C. Vulnerability Categories Targeted by Scanners
All scanners in our study are qualified for PCI compliance and must test for each of the OWASP Top Ten 2007 vulnerability categories. We examined the scanning profile customization features for further insight into their target vulnerability categories. Six scanners allow views of the scanning profile by target vulnerability category, often based on OWASP, WASC, or CWE top 25. These scanners offer fine-grained test customization, resulting in over 100 targeted vulnerability categories. When combined, we identified a set of consensus classifications for which all tools test. Table II lists these classifications and example vulnerabilities. Cross-Site Scripting and SQL Injection are kept as separate classifications due to their high occurrence and targeting by all scanners. The Cross-Channel Scripting classification includes vulnerabilities allowing code injection across a channel onto the web server or client browser, excluding XSS and SQLI.

### D. Test Vector Statistics
We obtained detailed test profile information for four scanners (McAfee, IBM, HP, and Acunetix) to evaluate the number of test vectors targeting each vulnerability classification. Figure 1 shows the percentage of vectors targeting each classification aggregated over the four scanners. The results indicate that scanners devote most testing to information leakage vulnerabilities, followed by XSS and SQLI vulnerabilities.

## III. Vulnerability Population from VUPEN-Verified NVD
To evaluate how well the vulnerability categories tested by the scanners represent real-world web application vulnerabilities, we queried the VUPEN Security Vulnerability NotiÔ¨Åcation Service database for the years 2005 through 2009. We chose this database because it aggregates, verifies, and reports vulnerabilities to sources like the NVD.

Figure 2 shows the relative incidence rate trends of the web application vulnerability classes. Figure 3 compares the incidences of web application vulnerabilities with system vulnerabilities like Buffer Overflows, Integer Overflows, Format Strings, Memory Corruption, and Race Conditions.

Figure 2 demonstrates that Cross-Site Scripting, SQL Injection, and other forms of Cross-Channel Scripting are consistently among the top four reported web application vulnerability classes, along with Information Leakage. These are also the top four vulnerability classes by scanner test vector count. However, test vectors for Information Leakage are more numerous, while their incidence rates in the wild are generally lower than those of XSS, SQLI, and XCS. Overall, the testing emphasis for black-box scanners appears reasonably proportional to the real-world vulnerability distribution.