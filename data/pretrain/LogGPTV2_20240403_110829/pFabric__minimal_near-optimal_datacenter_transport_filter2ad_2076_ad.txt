of all ﬂows are one packet, it is not surprising that pFabric’s average
normalized FCT s 50% lower than PDQ.
FCT breakdown based on size: We now breakdown the FCT stats
across small (0, 100KB] and large (10MB, ∞) ﬂows. We omit the
441TCP-DropTail
DCTCP
PDQ
pFabric
Ideal
TCP-DropTail
DCTCP
PDQ
pFabric
Ideal
T
C
F
d
e
z
i
l
a
m
r
o
N
10
8
6
4
2
0
T
C
F
d
e
z
i
l
a
m
r
o
N
10
8
6
4
2
0
10
T
C
F
d
e
z
i
l
a
m
r
o
N
8
6
4
2
0
0.2
0.4
Load
0.6
0.8
T
C
F
d
e
z
i
l
a
m
r
o
N
25
20
15
10
5
0
0.2
0.4
Load
0.6
0.8
10
T
C
F
d
e
z
i
l
a
m
r
o
N
8
6
4
2
0
0.2
0.4
Load
0.6
0.8
T
C
F
d
e
z
i
l
a
m
r
o
N
10
8
6
4
2
0
0.2
0.4
Load
0.6
0.8
0.2
0.4
Load
0.6
0.8
(a) (0, 100KB]: Avg
(b) (0, 100KB]: 99th prctile
(c) (10MB, ∞): Avg
Figure 8: Web search workload: Normalized FCT statistics across different ﬂow sizes. Note that TCP-DropTail does not appear in
part (b) because its performance is outside the plotted range and the y-axis for part (c) has a different range than the other plots.
0.2
0.4
Load
0.6
0.8
(a) (0, 100KB]: Avg
(b) (0, 100KB]: 99th prctile
(c) (10MB, ∞): Avg
Figure 9: Data mining workload: Normalized FCT statistics across different ﬂow sizes. Note that TCP-DropTail does not appear in
part (b) because its performance is outside the plotted range.
results for the medium (100KB, 10MB] ﬂows whose performance
is qualitatively similar to the small ﬂows (the complete results are
provided in [6]) The results are shown in Figures 8 and 9 for the
two workloads. We plot the average (normalized) FCT in each bin
and also the 99th percentile for the small ﬂows The results show
that for both workloads, pFabric achieves near-optimal average and
99th percentile FCT for the small ﬂows: it is within ∼1.3–13.4%
of the ideal average FCT and within ∼3.3–29% of the ideal 99th
percentile FCT (depending on load). Compared to PDQ, the av-
erage FCT for the small ﬂows with pFabric is ∼30-50% lower for
the web search workload and ∼45-55% lower for the data mining
workload with even larger improvements at the 99th percentile.
pFabric also achieves very good performance for the average
FCT of the large ﬂows, across all but the highest loads in the web
search workload. pFabric is roughly the same as TCP and ∼30%
worse than Ideal at 80% load for the large ﬂows in the web search
workload (for the data mining workload, it is within ∼3.3% of
Ideal across all ﬂows). This gap is mainly due to the relatively
high loss rate at high load for this workload which wastes band-
width on the upstream links (§4.2). Despite the rate control, at
80% load, the high initial ﬂow rates and aggressive retransmissions
cause a ∼4.3% packet drop rate in the fabric (excluding drops at the
source NICs which do not waste bandwidth), almost all of which
occur at the last hop (the destination’s access link). However, at
such high load, a small amount of wasted bandwidth can cause a
disproportionate slowdown for the large ﬂows [4]. Note that this
performance loss occurs only in extreme conditions — with a chal-
lenging workload with lots of elephant ﬂows and at very high load.
As Figure 8(c) shows, under these conditions, PDQ’s performance
is more than 75% worse than pFabric.
5.4.2 Mix of deadline-constrained and
deadline-unconstrained trafﬁc
We now show that pFabric maximizes the number of ﬂows that
meet their deadlines while still minimizing the ﬂow completion
time for ﬂows without deadlines. To perform this experiment, we
assign deadlines for the ﬂows that are smaller than 200KB in the
web search and data mining workloads. The deadlines are assumed
to be exponentially distributed similar to prior work [21, 14, 18].
We vary the mean of the exponential distribution (in different sim-
ulations) from 100µs to 100ms to explore the behavior under tight
and loose deadlines and measure the Application Throughput (the
fraction of ﬂows that meet their deadline) and the average normal-
ized FCT for the ﬂows that do not have deadlines. We lower bound
the deadlines to be at least 25% larger than the minimum FCT pos-
sible for each ﬂow to avoid deadlines that are impossible to meet.
In addition to the schemes used for the baseline simulations with
deadline-unconstrained trafﬁc, we present the results for pFabric
with Earliest-Deadline-First (EDF) scheduling. pFabric-EDF as-
signs the packet priorities for the deadline-constrained ﬂows to be
the ﬂow’s deadline quantized to microseconds; the packets of ﬂows
without deadlines are assigned priority based on remaining ﬂow
size. Separate queues are used at each fabric port for the deadline-
constrained and deadline-unconstrained trafﬁc with strict priority
given to the deadline-constrained queue. Within each queue, the
pFabric scheduling and dropping mechanisms determine which pack-
ets to schedule or drop. Each queue has 36KB of buffer.
Figure 10 shows the application throughout for the two work-
loads at 60% load. We picked this moderately high load to test
pFabric’s deadline performance under relatively stressful condi-
tions. We ﬁnd that for both workloads, both pFabric-EDF and
pFabric achieve almost 100% application throughput even at the
tightest deadlines and perform signiﬁcantly better than the other
schemes. For the web search workload, pFabric-EDF achieves an
Application Throughput of 98.9% for average deadline of 100µs;
pFabric (which is deadline-agnostic and just uses the remaining
ﬂow size as the priority) is only slightly worse at 98.4% (the num-
bers are even higher in the data mining workload). This is not
surprising; since pFabric achieves a near-ideal FCT for the small
ﬂows, it can meet even the tightest deadlines for them. As expected,
PDQ achieves a higher application throughput than the other schemes.
But it misses a lot more deadlines than pFabric, especially at the
442100
80
60
40
20
)
%
(
t
u
p
h
g
u
o
r
h
T
n
o
i
t
a
c
i
l
p
p
A
0
102
100
)
%
(
t
u
p
h
g
u
o
r
h
T
n
o
i
t
a
c
i
l
p
p
A
80
60
40
20
0
102
TCP-DropTail
DCTCP
pFabric-EDF
pFabric
PDQ
103
Average Deadline (us)
104
TCP-DropTail
DCTCP
pFabric-EDF
pFabric
PDQ
103
Average Deadline (us)
104
(a) Web search workload
(b) Data mining workload
Figure 10: Application Throughput for deadline trafﬁc with
various deadline settings at 60% load.
72,
6,
5,
4,
3,
+
+
.
-
,
*
)
(
'
&
%
$
#
"
!
!"#$
%&'(!)*+,
%"!"#,
(-).&*/$
0%-,
(-).&*/, #%1,
!"#$
%&'(!)*+,