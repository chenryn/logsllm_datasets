### Flow Completion Time (FCT) Analysis

When all flows consist of a single packet, it is expected that pFabric’s average normalized FCT is 50% lower than PDQ.

#### FCT Breakdown by Flow Size

We now analyze the FCT statistics for small (0, 100KB] and large (10MB, ∞) flows. The results for medium (100KB, 10MB] flows are qualitatively similar to those for small flows (complete results are provided in [6]). Figures 8 and 9 illustrate the normalized FCT statistics for the web search and data mining workloads, respectively. 

- **Small Flows (0, 100KB]**:
  - **Average FCT**: For both workloads, pFabric achieves near-optimal performance, with an average FCT within 1.3–13.4% of the ideal.
  - **99th Percentile FCT**: pFabric's 99th percentile FCT is within 3.3–29% of the ideal, depending on the load.
  - **Comparison with PDQ**: For the web search workload, pFabric's average FCT is 30-50% lower than PDQ. For the data mining workload, this difference increases to 45-55%, with even larger improvements at the 99th percentile.

- **Large Flows (10MB, ∞)**:
  - **Web Search Workload**: pFabric performs well for the average FCT of large flows across most loads, except at the highest loads. At 80% load, pFabric's performance is roughly the same as TCP and about 30% worse than Ideal.
  - **Data Mining Workload**: pFabric's performance is within 3.3% of Ideal across all flow sizes.
  - **High Load Performance**: At 80% load, high initial flow rates and aggressive retransmissions cause a 4.3% packet drop rate in the fabric, primarily at the last hop. This leads to a disproportionate slowdown for large flows, but only under extreme conditions with many elephant flows and very high load. Under these conditions, PDQ's performance is more than 75% worse than pFabric.

### Deadline-Constrained and Unconstrained Traffic

We demonstrate that pFabric maximizes the number of flows meeting their deadlines while minimizing FCT for flows without deadlines. To conduct this experiment, we assign exponentially distributed deadlines to flows smaller than 200KB in the web search and data mining workloads. The mean of the exponential distribution varies from 100µs to 100ms to explore behavior under tight and loose deadlines. We measure Application Throughput (the fraction of flows meeting their deadline) and the average normalized FCT for flows without deadlines. Deadlines are set to be at least 25% larger than the minimum possible FCT to ensure they are achievable.

- **pFabric-EDF**:
  - **Scheduling**: pFabric-EDF assigns packet priorities based on the flow’s deadline quantized to microseconds for deadline-constrained flows. For flows without deadlines, priority is based on remaining flow size.
  - **Queue Management**: Separate queues are used for deadline-constrained and unconstrained traffic, with strict priority given to the deadline-constrained queue. Each queue has 36KB of buffer.

Figure 10 shows the application throughput for the two workloads at 60% load. Both pFabric-EDF and pFabric achieve nearly 100% application throughput even at the tightest deadlines, outperforming other schemes. For the web search workload, pFabric-EDF achieves 98.9% throughput with an average deadline of 100µs, while pFabric achieves 98.4%. PDQ, while achieving higher throughput, misses more deadlines compared to pFabric, especially at tighter deadlines.

### Conclusion

pFabric demonstrates superior performance in both FCT and deadline-constrained traffic scenarios, achieving near-ideal FCT for small flows and maximizing the number of flows meeting their deadlines. The performance gap with other schemes is particularly pronounced under high load and tight deadline conditions.