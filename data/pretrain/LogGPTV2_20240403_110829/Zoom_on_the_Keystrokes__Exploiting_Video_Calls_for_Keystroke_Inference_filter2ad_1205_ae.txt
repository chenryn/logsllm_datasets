of movement/posture changes. This limitation can also be
attributed to the fact that while using a laptop, a user’s position
is a bit constrained (given the webcam’s restricted ﬁeld-of-
view) and small movements/posture changes can result in the
user’s shoulders/upper arms becoming invisible/unavailable to
the adversary.
B. Typing Accuracy
Before presenting our word prediction results, we brieﬂy
analyze the rate of typographical errors made by our partici-
pants. As our inference framework does not have provisions for
handling rectiﬁcations made after typographical errors, partici-
pants’ typing accuracies have a direct correlation to our frame-
work’s prediction error. Appendix H lists the typing accuracies
of all our participants. As a case in point, participants I and C
had the worst typing accuracy (73.1% and 49%, respectively),
and our word prediction performance for participants I and
C was also the lowest. The following prediction performance
results are inclusive of all the typographical errors made by
our participants in the At-Home setting.
C. Keystroke or Text Prediction Performance
Next, we present results for word prediction in the At-
Home setting, separated based on the category of typed words.
It should be noted that, in contrast to the In-Lab setting, partic-
ipants in the At-Home setting typed their own words (for each
of the ﬁve categories), and that four out of the ﬁve categories
(of typed words) would most likely include words that would
not be present in a typical English language dictionary. Thus,
rather than using a standard English dictionary for prediction,
we ﬁrst create a ranked reference database of likely words in
each category (which could be contextually created based on
the target participant) and then employ it for the prediction
task. As our framework predicts the possible combinations of
typed characters based on the movements, and not individual
characters themselves, such a reference database is required to
complete the prediction task.
Websites. For the prediction of websites typed by target users,
we created a reference database of 1 million most-visited
websites [11]. In our dataset, all participants typed at least two
websites ranked in the top-20 of the reference database, with an
overall median rank of 140 and a mean rank of 36, 745.3 (mean
is signiﬁcantly higher than the median due to a few websites
that are not popular and thus have very high ranks in the
reference database). Our inference framework was successfully
able to infer 66.7% of the websites typed by participants,
within the top-25 predictions. An adversary may further reduce
the search space based on contextual information about the
target user.
Passwords. For prediction of passwords typed by target users,
we created a reference database of 1 million most commonly
used passwords [1]. Only 18.9% of the passwords were
successfully recovered within top-50 predictions, which can be
attributed to the fact that 74.4% of the passwords typed by our
participants were not found in the reference database used for
prediction. Considering only the passwords that were present
in the reference database, 74% of them were successfully
recovered within top-50 predictions.
English Words. For prediction of English words, we use the
65K-words dictionary used earlier for the In-Lab evaluation.
Similar to passwords, not all (25.6%) of the words typed by
11
Fig. 12: Performance of the typing activity detection technique.
(a)
(b)
(c)
(d)
(e)
(f)
(g)
Fig. 14: A left hand frame segment from a frame (a) unaltered,
(b) after blurring with zb = 5%, (c) after blurring with zb =
10%, (d) after blurring with zb = 20%, (e) after pixelation
with zp = 3%, (f) after pixelation with zp = 5%, and (g) after
pixelation with zp = 7%.
Fig. 13: Successful inference of different text predictions.
our participants existed in the dictionary used for prediction,
and 21.1% of the English words were successfully recovered
within top-50 predictions. One of the reasons our accuracy
is worse than the In-Lab setting is because the reference
dictionary’s rank sorting is based on word-usage frequency
in English language sentences, not based on random words
produced by people. In other words, the ranking of words
within the reference dictionary is not appropriate for prediction
of randomly typed words. If an adversary could produce a more
accurate contextual reference dictionary based on the target
user, we expect better performance from our framework.
Usernames and Email Addresses. Usernames and email ad-
dresses are commonly used as an identiﬁer for authentication,
but
they are also often publicly known and not sensitive
information by themselves. However, knowing when a target
user typed their username or email address can be valuable to
an adversary, as a password is likely to be typed immediately
afterwards during an authentication. Therefore,
instead of
predicting the usernames and email addresses typed by our
participants, we try to predict when their known username and
email address was typed by them. On average, we were able to
correctly predicted when 91.1% of the usernames and 95.6%
of the email addresses were typed.
XI. THREAT MITIGATION
In this section, we outline and evaluate potential mitigation
techniques to the video-based keystroke inference threat. We
evaluate these mitigation measures by applying them to the
In-Lab video dataset prior to using them in our keystroke
inference framework, and then measuring the performance of
our framework on these modiﬁed video data. We evaluate the
mitigation techniques using the In-Lab dataset instead of the
At-Home dataset, because with its higher inference success,
the In-Lab dataset can better illustrate the effectiveness of the
proposed mitigation techniques. We measure the performance
of our framework under the inﬂuence of these mitigation
techniques using the metrics of (i) effectiveness, (ii) efﬁciency,
and (iii) video quality, which we describe next followed by a
description and evaluation of the mitigation techniques.
(1) Effectiveness measures the average reduction in word
recovery due to the mitigation technique.
(2) Efﬁciency measures the average time to process each
frame.
(3) Video Quality measures the image quality in the modiﬁed
(edited) frames using SSIM index [52] as a measure of the
structural quality of the frames within the video.
A. Mitigation Techniques
We now outline three frame manipulation strategies as mit-
igation techniques against the video-based keystroke inference
threat presented earlier, and present performance results for
them using the metrics deﬁned above. It must be mentioned
that, although these techniques can be applied to all the frames
in the entire video call, it makes much more sense to apply
them to frames in the vicinity of the target user’s actual
keystrokes. As keystroke detection for mitigation can be easily
accomplished using OS-interrupts on the user side, it should be
relatively straightforward to identify frames just before, during
and after the keystroke on which the proposed manipulation
strategies should be applied. However, to effectively manip-
ulate the frames immediately before a keystroke, we must
maintain a buffer of those frames before they are transmitted
out. Obviously, a large buffer can introduce signiﬁcant latency
in the video call, which is detrimental to the overall quality.
We employ a buffer size of 2 frames (in a 30 f ps video) for the
ﬁrst two mitigation techniques, and we use a variable buffer
size in the third mitigation technique.
Blurring. The ﬁrst approach is to manipulate (sensitive)
frames using a Box blur approach [45]. This approach pro-
duces a blurring effect on the original frame by employing an
adjustable kernel. The size of the Box blur kernel is chosen as
some proportion (zb) of the original frame size and populated
with ‘1’s. Once the kernel is ﬁxed, blurring is done as follows:
For each pixel, pi,j, of the original image frame, the kernel is
centered on that pixel and a new pixel value is computed.
This new pixel value is the average of the neighboring pixel
values weighted using the kernel. This new pixel value then
replaces the original pixel pi,j. This process is repeated for all
the pixels of the frame. Some visual examples of the impact
of blurring on a sample image frame for different values of
the kernel parameter zb are depicted in Figures 14b to 14d. At
the press of a keystroke we blur all the buffered frames and
four following frames (total 6 frames) for a total duration of
about 200 ms, which is the mean duration of keystrokes [26].
Our experimentation with using blurring within our infer-
ence framework shows that we are able to reduce the average
word recovery from 65% to as low as 13% for zb = 20%
12
RecallPrecisionTP  FP   FN02040608010010203040PercentageCountTop 10Top 25Top 50Top 100Top 200020406080100PasswordsWebsitesWordsRecovery (%)(Figure 15). In other words, we see a mitigation effectiveness
of about -52% in top-50 prediction. We also observed that
using higher zb resulted in less words being recovered, as the
frames were more blurry. For 1920 × 1080 sized frames, we
observed that blurring takes around 17 ms per frame with a
kernel factor (zb) of 5%, on a laptop with an Intel i7-7700HQ
(2.8 GHz) processor and 32 GB RAM. In terms of image
quality, we saw an average SSIM index of 78.2% for zb =
20%. A high SSIM index implies that the manipulated frame
is similar to the original frame, and vice versa. These results
show that blurring is an effective mitigation technique, which
imposes little efﬁciency and quality overheads.
Pixelation. The second approach we analyze is pixelation,
where the frame is ﬁrst pixelated (partitioned) into areas
deﬁned by a proportion parameter zp. In other words, the frame
(of size m× n) is partitioned into 1/zp
× n
.
zp
Then, for each such area, the average of all pixel values within
that area is computed, and each pixel pi,j within that area
is reassigned this new average value. Some visual examples
of the impact of pixelation on an image frame for different
values of the pixelation proportion parameter zp is shown in
Figures 14e to 14g. Similar to blurring, at the hit of a keystroke
we pixelate all the buffered frames and four following frames
(total 6 frames) for a total duration of about 200 ms.
2 areas of size m
zp
Our experimentation with using pixelation within our infer-
ence framework shows that we are able to reduce the average
word recovery from 65% to as low as 4.3% for zp = 7%
(Figure 15). In other words, we see a mitigation effectiveness
of about -60% in top-50 prediction. We also observed that
using higher zp resulted in less words being recovered, as the
frames were more pixelated. For 1920 × 1080 sized frames,
we observed that pixelation takes around 1.41 ms per frame
with a zp of 3%, which is signiﬁcantly faster than blurring.
In terms of image quality, we saw an average SSIM index of
74% for zp = 7%. These results show that pixelation is even
more effective than blurring, and it imposes signiﬁcantly lesser
efﬁciency overhead, with a slight trade-off in quality.
Frame Skipping. The ﬁnal mitigation approach we analyze
is frame skipping, where as the name suggests, not all frames
(captured during the video call on the target user side) are
sent to the receiver (adversary). More speciﬁcally, the approach
continuously buffers f frames during the call on the target user
side. If typing is detected, all the buffered frames, as well as,
an additional f frames after the detected key press, are dropped
(i.e., not sent). Our experimentation shows that frame skipping
is the most effective method in reducing word recovery rate,
with only around 3% of the words recovered on an average (for
f = 5). In other words, we see a mitigation effectiveness of
about -62% in top-50 prediction. Frame skipping successfully
eliminates all movement relationship between consecutive key
strokes, resulting in such a high mitigation effectiveness.
Frame skipping does not impact image quality of individual
frames as the original frames are never modiﬁed. However, the
downside of frame skipping is that user’s video will appear to
be stuck at a frame just prior to the keystroke, to the other
participants in the video call. This can be confusing to the
uninformed, but can be remedied with a notice such as “John
Smith is typing” to other participants in the video call.
Fig. 15: Different mitigations techniques and resultant word
recovery (top-50, 4K dictionary).
XII. DISCUSSION & LIMITATIONS
Generalizability. Let us comment on the generalizability and
limitations of our study. First, we believe that our results are
very generalizable to real-life scenarios based on the number
of participants from which we collected data (more than
prior related studies [29], [21]) and the different choices of
webcams, keyboards, devices, participant clothings, and video
calling software used in our experiments, which we believe are
well representative samples. While all our participants were
students recruited from a university campus, we observed a
huge variety of different typing styles and quirks, which makes
us reasonably conﬁdent about it being representative of the
general population. Moreover, our data collection experiments
were designed to reduce all types participant biases, including
response bias, and were approved by the university’s IRB.
Limitations. In our framework we only employed video feed
to detect keystrokes, but video data can be combined with
audio data from the call to further improve keystroke detection.
The accuracy of our framework also relies signiﬁcantly on the
ﬁeld of view containing the target user. Obstacles blocking
(either completely or partially) the shoulder and arm areas
of the target user, such as, microphones, headphone wires, or
hair, could adversely affect both keystroke event detection and
prediction. Similarly, if a camera’s ﬁeld of view does not fully
or partially capture the shoulder and arm areas of the target
user, as often observed in laptop webcams as they are generally
set at an angle, it could also adversely impact the prediction
performance of our framework. Lastly, we have also observed
that signiﬁcant ambient lighting changes (during typing) also
disrupts the efﬁcacy of our prediction. Many target user-
speciﬁc factors can also disrupt the prediction performance
of our framework, for instance if there are signiﬁcant user
movements while typing. This is possible especially if the
target user is seated on a movable object, such as a rolling
chair. As seen in our mitigation techniques, video quality is
very impactful. If video frames are dropped, or the frames
had some quality issues such as blurring or pixelation, then
our framework will have poor inference accuracy.
XIII. CONCLUSION
We proposed and evaluated a keystroke inference frame-
work which can predict text typed by a user during a video
call. Speciﬁcally, we modeled and analyzed hand movements
observable in the webcam’s ﬁeld of view, in order to detect
keystroke events and then carry out a dictionary-based predic-
tions. We evaluated our framework in a variety of controlled
and uncontrolled scenarios, and were able to recover up to
75% words in some scenarios. We also proposed and evaluated
three mitigation techniques which can effectively deter such
keystroke inference attack in video calls.
13
OrginalFrame SkipPixelationBlurring020406080100Visual (4k dic)f = 3f = 5z p  = 3%z p  = 5%z p  = 7%z b  = 5%z b  = 10%z b  = 20%Word Recovery (%)REFERENCES
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[Online;
password
list
top
1000000,”
tiled
view,