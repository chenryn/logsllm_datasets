operations used to
calculate the best conﬁgurations.
dα∗/D). Hence, for each of these feature types, (cid:80)D
2
Implementation. If exhaustive search for optimal con-
ﬁgurations were allowed, the detection rates with the conﬁg-
urations in the matrix in Figure 7 would be (weakly) mono-
tonically improving from left top to right bottom. Due to a
limited number of tries when searching for an optimal con-
ﬁguration with the genetic algorithm, it is however possible
that no feasible conﬁguration can be found or the conﬁg-
uration found has a false positive rate not falling into the
current threshold range. In such circumstances, extra eﬀorts
are needed to ensure that classiﬁcation performances of the
entries in the matrix are indeed monotonically improving.
Let matrix M contain the conﬁgurations found; that is to
say, M (d, t) gives the conﬁguration (α, β) found when the
threshold on the false positive rate is dα∗/D for the t-th
feature type; if no conﬁguration is found, M (d, t) is null.
To optimize the process of ﬁnding the best conﬁgurations,
we update the t-th column in two passes when the search
for the t-th feature type is ﬁnished:
First pass: Consider the following example. The three
thresholds on false positive rates are 0.01, 0.02, and 0.03.
Suppose that the corresponding conﬁgurations found are
(0.005, 0.8), (0.001, 0.99), and (0.025, 0.9). Hence, both
the ﬁrst two conﬁgurations have a false positive rate falling
in the range [0, 0.01]. In this case, we use the second one to
overrule the ﬁrst one because it leads to a higher detection
rate. Hence, in the ﬁrst pass, for the conﬁguration found for
the d-th threshold, we proceed as follows:
(a.1) Its false positive rate is higher than dα∗/D. As this
violates the Neyman-Pearson criterion, we let M (d, t)
be null.
(a.2) Its false positive rate is no greater than dα∗/D but
In this case, we keep the
higher than (d − 1)α∗/D.
current solution found for this threshold.
(a.3) Its false positive rate is no greater than (d − 1)α∗/D.
Let the false positive rate of the solution found be r.
We calculate d(cid:48) = (cid:100)rD/α∗(cid:101) and compare the conﬁg-
uration previously found under the false positive rate
threshold d(cid:48)α∗/D. If the current solution outperforms
the previous conﬁguration, we replace the previous
conﬁguration under the false positive rate threshold
d(cid:48)α∗/D with the current solution, and set the current
solution under the false positive rate threshold dα∗/D
to be null.
127Second pass: Using the same example, after the ﬁrst pass,
the three conﬁgurations become (0.001, 0.99), null, and
(0.025, 0.9). Note that albeit having a higher false posi-
tive rate, the third conﬁguration has a lower detection rate,
suggesting that it is dominated by the ﬁrst conﬁguration.
Hence, in the second pass, we ensure that all conﬁgura-
tions in the matrix M are ordered by the performances. Let
maxβ Mi,j be the maximum detection rate among the ﬁrst i
rows and j columns of matrix M . Without loss of generality,
if Mi,j is null, its detection rate is assumed to be 0.
For the d-th conﬁguration where 1 ≤ d ≤ D, let its detec-
tion rate be βd,t. We have the following cases.
(b.1) maxβ Md,t−1 ≥ maxβ Md−1,t ≥ βd,t. This means that
classiﬁcation from the current feature type does not
help improve the detection accuracy. Hence, we in-
herit the classiﬁcation results from the previous fea-
ture type with the same false positive rate threshold
without using the current feature type.
(b.2) maxβ Md,t−1 ≥ maxβ Md−1,t ≥ βd,t. This implies that
the current feature type helps but increasing the false
positive rate threshold does not help. We thus deacti-
vate the conﬁgurations found from the current thresh-
old for this feature type and will not consider any fur-
ther results based on M (d, t). We say that M (d, t) is
now inactive.
(b.3) βd,t > max{maxβ Md,t−1, maxβ Md−1,t}. This means
that both the current threshold and the feature type
help improving the detection accuracy, and we thus
keep its classiﬁcation results.
After the two passes, we ensure that performances of the
conﬁgurations in matrix M , if they are active, must increase
(weakly) monotonically as we increase the false positive rate
threshold or add more feature types. These two passes are
performed immediately for each feature type once the con-
ﬁgurations are learned based on the chain Neyman-Pearson
criterion under all the false positive rate thresholds. Due to
the optimization applied in our implementation, the count
stated in Proposition 3 provides only an upper bound on the
real number of operations that have been executed.
It is noted that the overhead in feature extraction varies
with the type of the features. When we train the ensemble
classiﬁer under the chain Neyman-Pearson criterion, feature
groups are ordered based on their relative extraction over-
head in an non-decreasing manner. Hence, costly features
are used only if the cheap ones do not have suﬃcient dis-
criminative power in classifying the malware family being
considered.
6. EXPERIMENTS
We use those unpacked samples in the malware dataset
described in Section 2 for performance evaluation, although
in practice packed samples can be unpacked ﬁrst before ex-
tracting features from them. Due to limited resources avail-
able, we extract features only for those samples that have
been labeled. In total we have 15,494 labeled unpacked sam-
ples for experiments, and their family breakdown is as fol-
lows: Bagle (152), Bifrose (1677), Hupigon (4748), Koob-
face (371), Ldpinch (190), Lmir (181), Rbot (923), Sdbot
(253), Swizzor (1276), Vundo (2852), Zbot (1231), and Zlob
(2140). A classiﬁer is built for each of these families, based
on the one-against-all rule, which treats samples from the
family under study as positive and all others as negative.
Among all the samples, we randomly choose 80% of them
for training, and the remaining 20% for testing. In the train-
ing dataset, 75% of them are marked as unlabeled. When
using the chain Neyman-Pearson criterion to train classi-
ﬁers, we further divide the training dataset into ﬁve folds
(i.e., m = 5 in Section 5.1), four of them used to search the
best conﬁgurations and the remaining one used to evaluate
the performance of a conﬁguration.
It is noted that dur-
ing the training phase based on cross validation, the 20% of
the test data are not available. Our task is to train a cost-
sensitive classiﬁer from the training dataset, and then label
every instance in the test dataset. We set the false positive
rate allowed for the ensemble classiﬁer to be at most 5%
(i.e., α∗ = 0.05). For the purpose of dynamic programming,
we partition the overall false positive rate into 6 intervals,
i.e., D = 6 in Equation (13).
Moreover, when using the genetic algorithm to search the
optimal conﬁguration, we generate candidate solutions for
three generations, among which solutions in the ﬁrst gen-
eration are randomly generated based on the full mutation
scheme (see Figure 4). From the population of each gen-
eration, we choose the top three conﬁgurations for further
reproduction. Hence, three new conﬁgurations are generated
from crossover, and three others from partial mutation. In
addition, three more are produced from full mutation. The
size of the total population per generation is thus 9.
The six types of features mentioned in Section 2 are con-
sidered, PE-num, PE-bool, Hexdump 2-gram, Objdump 1-gram,
PIN 2-gram, and PIN SysCall. We use the logistic regres-
sion method discussed in [40] to choose 100 features from
each of the six feature types. When we search optimal con-
ﬁgurations for each feature type, we order the six feature
types based on the relative diﬃculty of obtaining their val-
ues. As both PE header features and Hexdump 2-gram fea-
tures can be obtained in a deterministic manner, we consider
them during the early phase of the classiﬁer ensemble. Ob-
jdump 1-gram features require disassembly code of the ex-
ecutable programs, which can be obtained through static
analysis. PIN features require dynamic execution of the pro-
grams, and are thus more diﬃcult to obtain. Hence, we train
individual classiﬁers sequentially according to the following
order of the six feature types: PE-num, PE-bool, Hexdump
2-gram, Objdump 1-gram, PIN 2-gram, and PIN SysCall.
6.1 Classiﬁcation Performance
Table 1 presents the average performances of the conﬁgu-
rations found by our method over the ﬁve test folds in terms
of false positive rates and detection rates. Clearly, for any of
these malware families, it is not necessary to include all six
feature types. For instance, for the Swizzor, Zbot, and Zlob
families, only the features extracted from the PE headers are
needed to classify their instances. This is desirable because
for some feature types such as those from dynamic execu-
tion, it takes signiﬁcant eﬀorts to collect their feature values.
Hence, our method based on the chain Neyman-Pearson cri-
terion has the eﬀect of selecting only those feature types that
are useful for automated malware classiﬁcation. Moreover,
it is observed that classiﬁcation of diﬀerent malware fami-
lies requires diﬀerent types of features. For instance, Hex-
dump 2-gram features are only useful for the Ldpinch and
the Lmir families but not the other ones. This is plausible
128Table 1: Performances trained under the chain Neyman-Pearson criterion. The numbers are the averages of
5-fold cross validation. ’-’ means that the feature type is not used. False positive rate threshold is 5%.
PE-bool
Hexdump 2-gram Objdump 1-gram
PIN 2-gram
PIN SysCall
-
(2.5%, 95.8%)
(3.7%, 99.4%)
-
-
-
(3.67%, 92.6%)
(1.6%, 76.5%)
-
-
-
-
-
-
-
-
-
-
(3.6%, 93.4%)
(4.0%, 96.0%)
-
-
Family
Bagle
Bifrose
Hupigon
Koobface
Ldpinch
Lmir
Rbot
Sdbot
Swizzor
Vundo
Zbot
Zlob
PE-num
(0.34%, 91.3%)
(0.7%, 81.7%)
(1.1%, 91.5%)
(0.06%, 90.9%)
(0.4%, 46.7%)
(0.35%, 70.7%)
(2.8%, 85.1%)
(1.2%, 58.3%)
(0.33%, 97.9%)
(0.33%, 95.6%)
(0.76%, 87.9%)
(1.5%, 98.6%)
(1.1%, 98.0%)
-
(1.9%, 98.4%)
(0.09%, 94.6%)
(1.9%, 83.1%)
(0.4%, 92.8%)
(3.2%, 91.5%)
(1.5%, 73.7%)
(0.5%, 99.7%)
(1.0%, 99.3%)
(1.6%, 92.2%)
(2.1%, 100.0%)
-
-
-
-
(3.04%, 90.5%)
(1.96%, 95%)
-
-
-
-
-
-
-
(0.96%, 100%)
-
-
-
-
-
-
-
-
(1.6%, 100.0%)
(2.0%, 91.2%)
-
(2.2%, 94.2%)
as the uniqueness of a malware family may manifest itself
over only a speciﬁc subset of feature types. Our algorithm
is able to ﬁnd these distinguishing feature types.
Figure 10 shows the classiﬁcation performance for each
malware family. From Figure 10(1), we observe that the
false positive rate for classifying the test samples in each
malware family is no greater than the predeﬁned threshold
of 5% for each malware family, suggesting that the classi-
ﬁer ensemble trained is indeed able to enforce the Neyman-
Pearson criterion. The detection rate per family is shown
in Figure 10(2). For most of the families, we observe that
the detection rate is above 90%, implying that the major-
ity of the samples of these families can be identiﬁed by our
method. For the Sdbot family, however, the detection rate
is only around 70%. We note that for this family, during
the training phase, our algorithm cannot ﬁnd good conﬁgu-
rations to achieve high classiﬁcation accuracy anyway: the
combination of PE header features and the PIN-SysCall fea-
tures can only lead to an average detection rate of 76.5%
based on 5-fold cross validation. Hence, the poor detection
rate of Sdbot samples attributes to the six feature types used
here which are unable to distinguish samples in the Sdbot
family as eﬀectively as those in the other ones. Comparing
the detection rates in Figure 10(2) against those in Table 1,
we ﬁnd that the former are typically lower than the corre-
sponding values by the classiﬁer ensembles seen in Table 1.
This is feasible as the detection rates in Figure 10(2) are
obtained on the test data, which are invisible to the train-
ing phase; by contrast, during the training phase, we search
conﬁgurations that lead to the highest detection rates under
the false positive rate constraint using 5-fold cross valida-
tion, which are shown in Table 1.
For a classiﬁer, let the number of true positives, false pos-
itives, true negatives, and false negatives be ntp, nf p, ntn
and nf n, respectively. Its precision is ntp/(ntp + nf p), and
its recall ntp/(ntp +nf n). The F-1 score, the harmonic mean
of precision and recall, is 2ntp/(2ntp +nf p +nf n). The preci-
sion, recall, and F-1 score of the classiﬁer trained for each of
the 12 malware families are shown in Figure 10(3). We note
that the recall measures are high for most of the malware
families (except the Sdbot family), because the recall mea-
sure is essentially the same as the detection rate. However,
the precision measure can be low for some of the families,
such as Bagle, Ldpinch, Lmir, and Sdbot. Common to these
families is the fact that they are severely underrepresented,
having a much smaller number of instances than the other
families. Consider any malware family, whose samples com-
prise a fraction p of the entire dataset. Let the false positive
rate and the detection rate of the classiﬁer trained for this
family be α and β, respectively. Then, we have:
pβ
(1 − p)α + pβ
≤
1
precision =
(14)
The inequality holds as β ≤ 1, so if p is small, meaning
that the malware family is signiﬁcantly underrepresented,
then 1/p − 1 is large, and precision becomes small even
though all positive samples can be detected successfully.
1 + α(1/p − 1)
.
In some cases, however, it is important to have a classiﬁer
with high precision. For instance, if we need to study com-
mon characteristics shared by samples by a malware family,
such as its unique string signatures, it is desirable to have
a classiﬁer that produces only a small fraction of false posi-
tives among the samples labeled as positive. For such cases,
there are two solutions. First, we can use a smaller false
positive rate in Equation (14), which can cancel the eﬀect
of 1/p − 1. For instance, we use a smaller false positive rate
threshold 0.5%, and the classiﬁcation performances for the
Ldpinch and the Lmir families are shown as follows: