out this, probes are wasted on paths where nothing is happening.
Within paths: a path ‘sample’ is a single probe rather than a full
traceroute, whose target interface is carefully chosen to combine
the beneﬁts of Paris Traceroute over time with efﬁciencies arising
from exploiting links shared between paths. This allows changes to
be spotted more quickly.
DTRACK monitors operate independently and use only locally
available information. Each monitor takes three inputs: a predictor
of virtual path changes, a set D of virtual paths to monitor, and a
probing budget; and consists of three main routines: sampling rate
allocation, change tracking, and change remapping. When a change
is detected in a path through sampling, that path is remapped, and
sampling rates for all paths are recomputed. A probing budget is
commonly used to control the average resource use [14, 25].
5.2 Path sampling rate allocation
For each path p in D, DTRACK uses NN4 to determine the rate λp
at which to sample it. Sampling rates are updated whenever there is
a change in the predictions, i.e., whenever any virtual path’s feature
vector changes its NN4 partition. This can happen as a result of a
change detection or simply route aging.
We constrain sampling rates to the range λmin ≤ λp ≤ λmax.
Setting λmin > 0 guarantees that all paths are sampled regularly,
which safeguards against poor predictions on very long lived paths.
An upper rate limit is needed to avoid probes appearing as an attack
(λmax implements the “politeness” of the tracking method [18]).
Based on the monitor’s probe budget of B probes per second,
a sampling budget of Bs samples per second for change detection
alone can be derived (Sec. 5.4). To be feasible, the rate limits must
obey λmin ≤ Bs/|D| ≤ λmax, where |D| is the number of paths.
We now describe three allocation methods for the sampling rates
λp. The ﬁrst two are based on residual life and the third minimizes
the number of missed changes.
Residual lifetime allocation. Since 1/L is precisely the rate that
would place a sample right at the next change, allocating sampling
rates proportional to 1/ ˆL is a natural choice. We will see that de-
spite the poor accuracy of ˆL found before, this is far better than the
traditional uniform allocation. To approximate this we deﬁne rates
to take values in
λp ∈ {λmax, a/ ˆL(p), λmin}
(4)
and require that λp ≥ λq if L(p)  A(r)}] − A(r),
where R is the set of all route instances in the dataset.
Finally, for comparison we add an oracular method which knows
(cid:5)
q 1/L(q).
the true L(p) and is not subject to rate limits:
RL-ORACLE: λp = a(cid:3)/L(p) where a(cid:3) = Bs
Minimizing missed changes (MINMISS, used in DTRACK). We
use a Poisson process as a simple model for when changes occur.
With this assumption we are able to select rates that minimize the
expected number of missed changes over the prediction horizon δ.
This combines prediction of Nδ with a notion of sampling more
where the pay off is higher. The rate μc(p) of the Poisson change
process is estimated as μc(p) = ˆNδ(p)/δ.
We idealize samples as occurring periodically with separation
1/λp. By the properties of a Poisson process, the changes falling
within successive gaps between samples are i.i.d. Poisson random
variables with parameter μ = μc(p)/λp = ˆNδ/(δλp). Let C
be the number of changes in a gap and M the number of these
missed by the sample at the gap’s end. It is easy to see that M =
max(0, C−1), since a sample can see at most one change (here we
assume that there is at most one instance of any route in the gap).
The expected number of missed changes in a gap is then
E[M (μ)] =
∞(cid:3)
m=0
= e−μ
∞(cid:3)
m=1
mPr(C = m + 1)
= μ − 1 + e−μ .
(5)
mPr(M = m) =
∞(cid:3)
m=1
mμm+1
(m + 1)!
Summing over the δλp gaps, we compute the sampling rates as the
solution of the following optimization problem:
(cid:3)
:
min
{λp}
δλp(μ − 1 + e−μ) =
ˆNδ + δλp(e− ˆNδ/(δλp)−1)
(cid:3)
p
such that
(cid:3)
p
p
λp = Bs, λmin ≤ λp ≤ λmax, ∀p.
We also evaluated Iδ as the basis of rate allocation, but as it is
inferior to MINMISS, we omit it for space reasons.
Implementation. Path sampling in DTRACK is controlled to be
‘noisily periodic’. As pointed out in [4], strictly periodic sampling
carries the danger of phase locking with periodic network events.
Aided by the natural randomness of round-trip-times, our im-
plementation ensures that sampling has the noise in inter-sample
times recommended to avoid such problems [3].
DTRACK maintains a FIFO event queue which emits a sam-
ple every 1/Bs seconds on average. Path p maintains a timer
T (p). When T (p) = 0 the next sample request is appended
to the queue and the timer reset to T (p) = 1/λp. When-
ever DTRACK updates sampling rates, the timers are rescaled as
Tnew(p) = Told(p)λold,p/λnew,p. Path timers are staggered at ini-
tialization by setting T (pi) = i/Bs, where i indexes virtual paths.
5.3 In-path sampling strategies
By a sample of a path we mean a measurement, using one or
more probes, of its current route. At one extreme a sample could
correspond to a detailed route mapping using MDA; however, when
checking for route changes rather than mapping from scratch, this
is too expensive. We now investigate a number of alternatives that
129are less rigorous (a change may be missed) but cheaper, for exam-
ple sending just a single probe. In each case however the sample is
load-balancing aware, that is we make use of the ﬂow-id to inter-
face mapping, established by the last full MDA, to target interfaces
to test in an informed and strategic way. Thus, although a single
sample takes only a partial look at a path and may miss a change,
it will not ﬂag a change where none exists, and can still cover the
entire route through multiple samples over time.
In what follows we describe a single sample of each technique
applied to a single path.
Per-sequence A single interface sequence from the route is se-
lected, and its interfaces are probed in order from the monitor to the
destination using a single probe each. Subsequent samples select
other sequences in some order until all are sampled and the route is
covered, before repeating. This strategy gives detailed information
but uses many probes in a short space of time. FastMapping has a
similar strategy only it probes a single sequence repeatedly rather
than looping over all sequences.
Per-probe The interface testing schedule is exactly as for per-
sequence, however only a single probe is sent, so the probing of
each sequence (and ultimately each interface in the route) is spread
out over multiple samples.
The above methods treat each path in isolation, but paths origi-
nated at a single monitor often have shared links. Doubletree [11]
and Tracetree [17] assume that the topology from a monitor to a set
of destinations is a tree. They reduce redundant probes close to the
monitor by doing backwards probing (from the destinations back
to the monitor). Inspired by this approach, we describe methods
that exploit spatial information, namely knowledge of shared links,
to reduce wasteful probing while remaining load-balancing-aware.
We deﬁne a link as a pair of consecutive interfaces found on some
path, which can be thought of as a set of links. Many paths may
share a given link.
Per-link A single probe is sent, targeting the far interface of the
least recently sampled link. The per-link sample sharing scheme
means that the timestamp recording the last sampling of a given
link is updated by any path that contains it. The result is that a
given path does not have to sample shared links as often, instead fo-
cussing more on links near the destination. Globally over all links,
the allocation of probes to links becomes closer to uniform.
Per-safelink As for per-link, except that a shared link only triggers
sample sharing when in addition an entire subsequence, from the
monitor down to the interface just past the link, is shared.
Any method that tries to increase probe efﬁciency through
knowledge of how paths share interfaces can fail. This happens
when a change occurs at a link (say (cid:6)) in some path p, but the mon-
itor probes (cid:6) using a path other than p, for which (cid:6) has not changed.
To help reduce the frequency of such events, per-link strengthens
the deﬁnition of sharing from an interface to a link, and per-safelink
expands it further to a subsequence.
Finally, for comparison we add an oracular method:
Per-oracle A single probe is sent, whose perfect interface targeting
will always ﬁnd a change if one exists.
5.4 Evaluation methodology
We describe how we evaluate DTRACK and compare it to other
tracking techniques.
Trace-driven simulation. We build a simulator that takes a dataset
with raw traceroutes as input, and for each change in each path
extracts a timestamp and the associated route description. It then
simulates how each change tracking technique would probe these
paths, complete with their missed changes and estimated (hence
inaccurate) feature vectors.
We use the traces described in Sec. 2.2 as input for our evalua-
tion. Different monitors in this dataset probe paths at different fre-
quencies. Let rmin be the minimum interval between two consecu-
tive path measurements from a monitor. We set λmax = 1/rmin per-
sequence samples per second (the average value over all monitors is
1/190), and this is scaled appropriately for other sampling strate-
gies. This setting is natural in our trace-driven approach: prob-
ing faster than 1/rmin is meaningless because the dataset contains
no path data more frequent than every rmin, and lower λmax would
guarantee that some changes would be missed. We set λmin = 0 for
all monitors.
Setting probe budgets. The total probe budget B is the sum
of a detection budget Bd used in sampling for change detection,
and a remapping budget or cost Br for route remapping. Let
the number of probes per sample be denoted by n(sam), where
sam ∈ {s, p, l, sl, o} is one of sampling methods above. The total
budget (in probes per second) can be written as
B = Bd + Br = n(sam)Bs + Nr · MDA,
(6)
where MDA is the average number of probes in a remapping, and
Nr is the average number of remappings per second.
When running live in an operational environment, typical es-
timates of Nr and MDA can be used to determine Bs based on
the monitor parameter B. Our needs here are quite different. For
the purposes of a fair comparison we control Bd to be the same
for all methods, so that the sampling rates will be determined by
Bs = Bd/n(sam) where sam is the sampling method in use. This
makes it much easier to give each method the same resources, since
we cannot predict how many changes different methods may ﬁnd.
More importantly, it does not make sense in this context to give
each method the same total budget B, since the principal mea-
sure of success is the detection of as many changes as possible.
More detections inevitably means increased remapping cost, but it
would be contradictory to focus on Br and to view this as a failing.
The remapping cost is essentially just proportional to the number
of changes found and, although important for the end system, is not
of central interest for assessing detection performance. We provide
some system examples below based on equal B.
The default MDA parameters are very conservative, leading to
high probe use. However, it is stated [31] that much less conserva-
tive parameters can be used with little ill effect. In this paper we
use default parameters for simplicity, since the change detection
performance is our main focus.
Performance metrics. We evaluate two performance metrics for
tracking techniques:
the fraction of missed virtual path changes,
and the change detection delay.
A change can be missed through a sample failing to detect a
change, or because of undersampling. We give two examples of
the latter. If a path changes from r1 to r2 and back to r1 before
a sample, then the tracking technique will miss two changes and
think that the path is stable between the two probes. If instead the
path changes from r1 to r2 to r3, then tracking will detect a change
from r1 to r3. For each detected change (and only for detected
changes), we compute the detection delay as the time of the detec-
tion minus the time of the last true change.
Alternative tracking techniques. We compare DTRACK against
two other techniques: FastMapping [8] (Sec. 2.2) and Trace-
tree [17] (Sec. 5.3).
Comparing Tracetree against FastMapping and DTRACK is difﬁ-
cult because Tracetree assumes a tree topology, and is also obliv-
130i
d
e
s
s
M
s
e
g
n
a
h
C
f
o
n
o
i
t
c
a
r
F
RL−age
Residual lifetime
Min. misses
RL−oracle
(a)
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0
 10
 0
Detection Budget  (probes/sec/path x10−3)
 30
 50
 60
 20
 40
i
d
e
s
s
M
s
e
g
n
a
h
C
f
o
n
o
i
t
c
a
r
F
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
per−sequence
per−probe
per−link
per−safelink
per−oracle
(b)
 0
 10
 0
Detection Budget  (probes/sec/path x10−3)
 20
 30
 40
 50
 60
i
d
e
s
s
M
s
e
g
n
a
h
C
f
o
n
o
i
t
c
a
r
F
 1
 0.1
FastMapping
Assisted Tracetree
DTrack (per−probe)
DTrack (per−safelink)
(c)
 0.01
 10
 0
Detection Budget  (probes/sec/path x10−3)
 20
 30
 40
 50
 60
Figure 8: Fraction of missed changes versus detection budget per path (Bd/|D|): (a) comparing path sampling rate allocation (using
per-sequence) (b) comparing sampling methods (using MINMISS), (c) comparing DTRACK to alternatives.
ious to load balancing. As such, Tracetree detects many changes
that do not correspond to any real change in any path. To help
quantify these false positives and to make comparison more mean-
ingful, in addition to the total number of Tracetree ‘changes’ de-
tected we compute a cleaned version by assisting Tracetree in three
ways. We ﬁlter out all changes induced by load balancing; ignore
all changes due to violation of the tree hypothesis; and whenever
a probe detects a change, we consider that it detects changes in all
virtual paths that traverse the changed link (even though they were
not directly probed). The result is “Assisted Tracetree”.
5.5 Evaluation of path rate allocation
This section evaluates RL, RL-AGE, and MINMISS, using per-
sequence, the simplest sampling scheme. Fig. 8(a) shows the frac-
tion of changes missed as a function of Bd/|D|, the detection bud-
get per path. Normalizing per-path facilitates comparison for other
datasets. For example, CAIDA’s Ark project [14] and DIMES [25]
use approximately 0.17×10−3 and 8.88×10−3 probes per second
per virtual path, respectively.
When the budget is too small, not even the oracle can track all
changes; whereas in the high budget limit all techniques converge
to zero misses. We see that Ark’s probing budget is the range where
even the oracle misses 72% of changes. To track changes more
efﬁciently Ark would need more monitors, each tracking a smaller
number of paths.
Comparing RL-AGE and RL shows that NN4 reduces the num-