title:Automatic Discovery and Quantification of Information Leaks
author:Michael Backes and
Boris K&quot;opf and
Andrey Rybalchenko
2009 30th IEEE Symposium on Security and Privacy
Automatic Discovery and Quantiﬁcation of Information Leaks
Michael Backes
Saarland University and MPI-SWS
Boris K¨opf
MPI-SWS
PI:EMAIL
PI:EMAIL
Andrey Rybalchenko
MPI-SWS
PI:EMAIL
Abstract
Information-ﬂow analysis is a powerful technique for rea-
soning about the sensitive information exposed by a program
during its execution. We present the ﬁrst automatic method
for information-ﬂow analysis that discovers what informa-
tion is leaked and computes its comprehensive quantitative
interpretation. The leaked information is characterized by an
equivalence relation on secret artifacts, and is represented
by a logical assertion over the corresponding program vari-
ables. Our measurement procedure computes the number of
discovered equivalence classes and their sizes. This provides
a basis for computing a set of quantitative properties, which
includes all established information-theoretic measures in
quantitative information-ﬂow. Our method exploits an in-
herent connection between formal models of qualitative
information-ﬂow and program veriﬁcation techniques. We
provide an implementation of our method that builds upon
existing tools for program veriﬁcation and information-
theoretic analysis. Our experimental evaluation indicates the
practical applicability of the presented method.
1. Introduction
Information-ﬂow analysis keeps track of sensitive infor-
mation that is processed by a program during its execution.
One of the main goals of the analysis is to check whether any
sensitive information is exposed to the environment. When
information is leaked, the analysis needs to qualitatively and
quantitatively assess the extent of the leak.
The existing approaches to information-ﬂow analysis pro-
vide a variety of techniques for dealing with the disclosure
of information, see [35]. Several approaches deal with the
qualitative aspect of information-ﬂow analysis [1], [5], [13],
[18], [34], which is usually formalized by an equivalence
relation over secret artifacts manipulated by the program.
Security guarantees correspond to the (im)possibility of
distinguishing between secret artifacts by observing program
behaviors. Existing quantitative approaches characterize the
magnitude of information leaks, e.g. in terms of the number
of secret bits that are revealed [9], [17], or in terms of the
rate at which information can be transmitted through the
leak [26].
of
the
the
applicability
Unfortunately,
existing
information-ﬂow analyses suﬀers from several limitations.
The qualitative approaches assume that
the equivalence
relation is supplied manually; however, such relations
are notoriously diﬃcult to ﬁnd due to the complexity of
reasoning about how the program treats its secrets. On the
quantitative side, the estimates computed by the existing
approaches mostly deal with the number of leaked bits,
e.g. [10], [29], which is not suﬃcient for establishing
comprehensive security guarantees. For example, a security
analysis might require a measure for the number of attempts
that are needed to identify a secret value, bounds on the
throughput of the program if it is used as an unwanted
communication channel, or a combination of several such
measures.
In this paper, we present the ﬁrst automatic method for
information-ﬂow analysis that addresses these challenges.
Our method delivers a complete analysis that automatically
discovers the leaked information, determines its information-
theoretic characteristics, and computes a comprehensive set
of quantitative properties.
The leaked information is computed in the form of an
equivalence relation and is represented by a logical assertion
over program variables. The equivalence relation computed
by our method is precise, i.e., describes only the infor-
mation that is leaked, and can be used on its own, e.g.,
for declassiﬁcation policies [4]. Our method goes beyond
this qualitative characterization, and uses the assertion as
an input to a measurement procedure that computes the
number of discovered equivalence classes and their sizes. We
demonstrate how these data provide a basis for computing a
set of quantitative properties, which is comprehensive in the
sense that it includes all information-theoretic measures that
are commonly considered in the literature on quantitative
information ﬂow, i.e., Shannon entropy, guessing entropy,
min-entropy, and channel capacity.
Our method exploits an inherent connection between
qualitative information-ﬂow and program veriﬁcation tech-
niques. The desired equivalence relation can be viewed as
a precondition for safe execution of the program under
consideration augmented with a ‘shadow’ copy and an
assertion checking the information leakage. The assertion
fails whenever the shadow copy of the program exhibits a
behavior that witnesses the ability to distinguish equivalent
1081-6011/09 $25.00 © 2009 IEEE
DOI 10.1109/SP.2009.18
141
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:15:53 UTC from IEEE Xplore.  Restrictions apply. 
artifacts. Our method iteratively constructs the equivalence
relation. It starts with a coarse initial candidate that claims no
leakage of sensitive information, and incrementally weakens
the claim by reﬁning the candidate relation, until
there
is no witness of further leaks. The key to the automatic
construction is the successive exclusion of counterexamples
witnessing inadequacy of the current equivalence.
We identify the characteristics of the equivalence rela-
tion that provide the common basis for computing various
entropy measures, as required by the quantitative analysis.
These characteristics consist of the number of equivalence
classes and their sizes, and can be further reﬁned by
probability distributions inside the equivalence classes. We
show how, given these characteristics, one can compute
the average uncertainty about the secret in bits (Shannon
entropy), the average number of guesses that are needed to
identify secrets (conditional and minimal guessing entropy,
respectively), and the maximal rate at which information
can be transmitted using the program as a communication
channel (channel capacity). Finally, we present a procedure
for computing these characteristics for a given equivalence
relation.
The presentation of our method is aligned with the exist-
ing body of research on program veriﬁcation and symbolic
reasoning. It suggests a basis for an automatic tool that
can be built by utilizing existing software model checkers,
quantiﬁer elimination algorithms and solution counting tech-
niques. We use these components in a black-box fashion,
hence our tool will immediately beneﬁt from the develop-
ment of the state-of-the-art in the respective areas.
We have implemented the presented method and have
successfully applied it to analyze a series of example pro-
grams: a password checker, an electronic purse, a sum query,
and an electronic auction. For each program, we determined
the equivalence relations representing the leaked information
and computed the sizes of the equivalence classes together
with diﬀerent information-theoretic interpretations.
In summary, our main contribution is the ﬁrst automatic
method for information-ﬂow analysis that discovers what
information is leaked and computes its comprehensive quan-
titative interpretation.
Outline. The paper is structured as follows. We present
related work in the remainder of this section. In Section 2,
we illustrate how our method applies to an example program.
We give the basic deﬁnitions in Section 3. In Section 4,
we present our method in abstract terms, before we outline
its implementation in Section 5. We present experimental
results in Section 6.
Related work. For an overview of language-based ap-
proaches to information-ﬂow security, refer to [33]; for an
overview on declassiﬁcation, see [35].
The use of equivalence relations to characterize partial in-
formation ﬂow was proposed in [13] and further explored in
[5], [18], [41]. Several approaches use equivalence relations
to specify downgrading assertions within information ﬂow
type systems [4], [34]. Our method can be used to synthesize
such assertions. The idea that secure information ﬂow can
be veriﬁed by analyzing pairs of program runs can be found
in [5], [16], [23], [38], [39].
Early approaches for quantifying information ﬂow focus
on the capacity of covert channels between processes in
multi-user systems [20], [30], [40] rather than on infor-
mation ﬂow in programs. The ﬁrst approach to connect
information theory to program analysis is [17].
A type system for statically deriving quantitative bounds
on the information that a program leaks is presented in [9],
[10]. The analysis is based on Shannon entropy and an
observer that can see, but not inﬂuence, the public inputs
to the program. Our method accommodates a variety of
information measures and captures attackers that can interact
with the program by providing inputs.
The information leakage of loops can be characterized
in terms of the loop’s output and the number of iterations
[27]. In our model, the information that is revealed by the
number of loop iterations can be captured by augmenting
loops with observable counters. For given upper bounds
on the number of iterations, our method can be used to
automatically determine this information.
Information-theoretic bounds in terms of the number of
program executions are presented in [24]. The algorithms
for computing these bounds for a concrete system rely on
an enumeration of the entire input space, and it is not yet
clear how the analysis scales to larger systems.
The model in [12] captures an attacker’s belief about a
secret, which may also be wrong. Reasoning about beliefs is
out of the scope of entropy-based measures, such as the ones
used in this paper. One advantage of entropy-based measures
is the direct connection to equivalence relations, which
makes them amenable to automated reasoning techniques.
To the best of our knowledge, our method is the ﬁrst static,
quantitative analysis that has been implemented.
An automatic dynamic quantitative information ﬂow anal-
ysis method is presented in [29]. The method enables one
to derive tight bounds on the information ﬂow in individual
program runs, but does not yield bounds on the maximal
information that a program can leak, which is important for
security analysis.
2. Illustrative example
To illustrate our method and the kind of results that it
provides, we show how it applies to an example program.
We consider an electronic sealed-bid auction in which
bidders want their bids to remain conﬁdential and the winner
is publicly announced. The announcement of the winner
142
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:15:53 UTC from IEEE Xplore.  Restrictions apply. 
reveals partial information about the individual bids, e.g.,
about their ordering.
This kind of electronic auction can be implemented as a
program P that takes as input n secret bids h1, . . . , hn and
outputs the winner of the auction in a variable l, i.e., upon
termination, l = i such that hi = max{h1, . . . , hn}.
int l=0;
for (int i=0; ih[l])
l=i;
}
In the ﬁrst step, we deduce an equivalence relation R on
the set of possible secret inputs to express what an attacker
can learn about the input by observing the program’s output:
two inputs are in the same equivalence class whenever
the program produces the same result on both inputs. By
observing the output of the program, the attacker can then
only deduce the secret input up to its R-equivalence class.
We cast such equivalence relations R as formulas over pairs
of secret inputs.
Checking that a program leaks no more secret information
than what is speciﬁed by R can be cast as a reachability
problem on two independent instances of the program, and
it can be solved using oﬀ-the-shelf model-checkers, such as
B [21], S [3], SA [11], and A [31]. If the
check fails (i.e., if the program leaks more information), the
model checker produces a counterexample: it returns two
program paths π and η along which two R-related inputs
produce diﬀerent outputs.
Guided by this counterexample, we reﬁne the relation R to
R(cid:48), such that R(cid:48) distinguishes between all secret inputs that
lead to diﬀerent observable outputs along the paths π and
η. We iterate this reﬁnement process until we have found
a relation R for which the check fails; this R is a logical
characterization of the maximal information that the program
can leak.
For our auction program and n = 3, this iterative reﬁne-
ment process yields the relation
R ≡ (h1 < h3 ∧ h2 < h3 ∧ h1 < h3 ∧ h2 < h3)
∨ (h1 < h3 ∧ h3 ≤ h2 ∧ h1 < h2 ∧ h3 ≤ h2)
∨ (h3 ≤ h1 ∧ h1 < h2 ∧ h1 < h2 ∧ h3 ≤ h2)
∨ (h2 < h3 ∧ h3 ≤ h1 ∧ h2 ≤ h1 ∧ h3 ≤ h1)
∨ (h3 ≤ h2 ∧ h2 ≤ h1 ∧ h2 ≤ h1 ∧ h3 ≤ h1) ,
which represents a set of pairs ((h1, h2, h3), (h1, h2, h3)) of
triples of input variables, i.e., a binary relation. Here h1, h2
and h3 denote the secret bids that are input to the second
instance of the program. Our speciﬁc implementation uses
the model-checker A, which does not cover arrays. To
analyze the auction program, we unfold the loop and replace
each array element h[i] by a variable h_i. Note that this
is a limitation of our implementation rather than one of our
method.
In the second step, we determine the R-equivalence
classes. To this end, we pick an arbitrary vector of bids
(say, (0, 0, 0)) and use it to instantiate the variables h1, h2, h3
of R. In this way, we obtain a formula B1 over the variables
h1, h2, h3 that represents all the bids that are R-equivalent
to (0, 0, 0), i.e., the R-equivalence class of (0, 0, 0). Then
we pick a representative of another equivalence class, i.e.
a model of ¬B1 and repeat the procedure. We proceed in
this way until we have enumerated all equivalence classes,
i.e., until B1 ∨ ··· ∨ Br ≡ (cid:62). The Omega-calculator [32] is a
tool for manipulating formulas in Presburger Arithmetic (i.e.,
linear arithmetic with quantiﬁers) using various operations,