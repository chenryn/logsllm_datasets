title:ARROW: restoration-aware traffic engineering
author:Zhizhen Zhong and
Manya Ghobadi and
Alaa Khaddaj and
Jonathan Leach and
Yiting Xia and
Ying Zhang
ARROW: Restoration-Aware Traffic Engineering
Alaa Khaddaj
Manya Ghobadi
Zhizhen Zhong
Massachusetts Institute of Technology
Massachusetts Institute of Technology
Massachusetts Institute of Technology
Jonathan Leach
Facebook
Yiting Xia
Max Planck Institute for Informatics
Ying Zhang
Facebook
ABSTRACT
Fiber cut events reduce the capacity of wide-area networks (WANs)
by several Tbps. In this paper, we revive the lost capacity by recon-
figuring the wavelengths from cut fibers into healthy fibers. We
highlight two challenges that made prior solutions impractical and
propose a system called Arrow to address them. First, our mea-
surements show that contrary to common belief, in most cases, the
lost capacity is only partially restorable. This poses a cross-layer
challenge from the Traffic Engineering (TE) perspective that has
not been considered before: ‚ÄúWhich IP links should be restored and
by how much to best match the TE objective?‚Äù To address this chal-
lenge, Arrow‚Äôs restoration-aware TE system takes a set of partial
restoration candidates (that we call LotteryTickets) as input and
proactively finds the best restoration plan. Second, prior work has
not considered the reconfiguration latency of amplifiers. However, in
practical settings, amplifiers add tens of minutes of reconfiguration
delay. To enable fast and practical restoration, Arrow leverages
optical noise loading and bypasses amplifier reconfiguration alto-
gether. We evaluate Arrow using large-scale simulations and a
testbed. Our testbed demonstrates Arrow‚Äôs end-to-end restoration
latency is eight seconds. Our large-scale simulations compare Ar-
row to the state-of-the-art TE schemes and show it can support
2.0√ó‚Äì2.4√ó more demand without compromising 99.99% availability.
CCS CONCEPTS
‚Ä¢ Networks ‚Üí Wide area networks; Traffic engineering algo-
rithms; Network reliability; Layering; Network simulations; Net-
work experimentation; Network measurement; ‚Ä¢ Computer sys-
tems organization ‚Üí Availability; ‚Ä¢ Mathematics of comput-
ing ‚Üí Probabilistic algorithms;
KEYWORDS
Wide-area networks, Traffic engineering, Optical restoration, Ran-
domized rounding, Network optimization
ACM Reference Format:
Zhizhen Zhong, Manya Ghobadi, Alaa Khaddaj, Jonathan Leach, Yiting Xia,
and Ying Zhang. 2021. ARROW: Restoration-Aware Traffic Engineering.
In ACM SIGCOMM 2021 Conference (SIGCOMM ‚Äô21), August 23‚Äì27, 2021,
Virtual Event, USA. ACM, New York, NY, USA, 20 pages. https://doi.org/10.
1145/3452296.3472921
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
¬© 2021 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-8383-7/21/08.
https://doi.org/10.1145/3452296.3472921
1 INTRODUCTION
Fiber cuts are undesirable events in Wide-Area Networks (WANs)
because (ùëñ) each fiber carries several Tbps of traffic, and (ùëñùëñ) fiber
cuts tend to take a long time to repair. Our analysis of failure tickets
at Facebook shows fiber cuts account for 67% of total downtime
and 50% of the fiber cut events take over nine hours to repair (¬ß2).
Today‚Äôs service providers cope with the loss of capacity caused
by fiber cut events by over-provisioning the network. In partic-
ular, to protect from massive packet loss, WAN operators pre-
allocate extra capacity for failover paths using (ùëñ) failure-aware
Traffic Engineering (TE) [17, 40, 48, 63, 79] and (ùëñùëñ) optical path
protection [14, 19, 59, 68, 80, 81, 84]. In such techniques, when fiber
cuts occur, traffic is automatically shifted from failed IP links to
pre-allocated backup paths. We argue that pre-allocating paths is
unnecessarily expensive because when a fiber is cut, the router
ports and transponders associated with that fiber are still usable.
A more attractive solution is to reconfigure the cut fiber‚Äôs wave-
lengths to healthy fibers enabling the transponders and router ports
associated with the cut fiber to carry traffic while the fiber itself
is out of commission. This idea is called optical restoration and
was proposed two decades ago [30]. Despite several follow up pa-
pers [32, 45, 49, 52, 56, 72, 74, 82] and the presence of commercially
available devices capable of wavelength reconfiguration, such as
Reconfigurable Optical Add Drop Multiplexers (ROADMs) [2, 4],
the deployment of prior proposals of optical restoration at scale
has several challenges, as we describe next.
Our measurements of a global WAN with over 200,000 IP links
and 1,000 optical fiber links show that in practice, 62% of fiber cuts
have to be partially restored because the remaining fibers do not
have enough available spectrum to host all the wavelengths of the
cut fiber. Hence, a practical restoration system must be able to
choose which IP links to restore partially and by how much.
We demonstrate that when full restoration is not possible, sim-
ply maximizing the restored bandwidth from the optical layer‚Äôs
perspective, without considering IP links‚Äô traffic demand, leads
to sub-optimal throughput. Hence, an IP/optical cross-layer TE is
needed to ensure the partially restored capacity is carefully allo-
cated across IP links and is efficiently utilized to match the current
traffic demand.
However, today‚Äôs TE schemes [17, 40, 42, 47, 48, 58, 60, 63, 77, 79]
do not consider optical restoration for fiber cuts. Instead, they con-
sider fiber cuts as fatal events: an IP link is down until the fiber is
repaired. To incorporate partial restoration into the TE, we propose
a restoration-aware TE system, called Agile RestoRation of Optical
Wavelengths (Arrow). Arrow grapples with the algorithmic chal-
lenges of formulating a restoration-aware TE, such as how to find
the best partial restoration plan while optimizing network through-
put, and also with system-level challenges, such as how to reduce
the end-to-end restoration latency.
In particular, Arrow‚Äôs TE formulation accounts for partial restora-
tion candidates for IP links during hypothetical fiber cut scenarios
and plans according to the best restoration plan proactively. We
show when full restoration is not possible, many partial restoration
candidates can maximize the total restored bandwidth from the
optical layer‚Äôs perspective, but not all of them maximize network
throughput from the TE perspective. Taking all of them into ac-
count in a joint IP/optical optimization is computationally infeasible,
while taking only one of them is sub-optimal.
Arrow solves this problem in a two-stage approach. The first
stage involves an offline analysis of the available fiber spectrum
to find a set of potential restoration candidates, which we call
LotteryTickets (¬ß3.2). Each LotteryTicket represents one possible
restoration candidate without taking instantaneous traffic demand
into account. The LotteryTickets serve as an abstraction between
the optical and IP layers. The second stage solves an online TE
formulation for the current traffic demand to find the winning
LotteryTicket for each hypothetical fiber cut scenario (¬ß3.3). The TE
formulation finds the appropriate tunnel allocations and restoration
plans proactively, before fiber cuts happen, enabling the network
to react quickly when a particular fiber cut happens.
An important practical consideration is the end-to-end recon-
figuration latency. Although ROADMs [4] have been ubiquitously
deployed in our WAN, reconfiguring a set of wavelengths from a cut
fiber to healthy ones results in optical power instability on the am-
plifiers of the new optical path(s). Such power excursions will cause
packet loss until all the amplifiers adjust their optical gain, a process
that takes several minutes in practice [16, 67, 90, 92]. To address
this challenge, Arrow leverages a recently commoditized device
called the Amplified Spontaneous Emission (ASE) noise source [83]
to bypass the amplifier reconfiguration time altogether, reducing
the end-to-end restoration latency from tens of minutes to eight sec-
onds. Prior work showed this device is currently being deployed in
large-scale WANs to facilitate wavelength installation [33, 35, 54].
To evaluate Arrow, we build a production-level testbed with 4
ROADM sites, 34 amplifiers, and over 2000 km fiber that faithfully
emulate part of our production backbone. Using this testbed, we
demonstrate the feasibility of reconfiguring 2.8 Tbps IP capacity
(14 wavelengths) within eight seconds. To evaluate the impact of
Arrow on throughput and availability, we conduct extensive sim-
ulations, comparing state-of-the-art TE algorithms (TeaVaR [17],
FFC [63], and ECMP [21]) with Arrow. Our simulations show Ar-
row supports between 2.0√ó‚Äì2.4√ó more demand without compro-
mising 99.99% availability. Moreover, we demonstrate that Arrow
sustains the same throughput at the same availability level while
requiring 2.8√ó fewer router ports and optical transponders.
2 BACKGROUND AND MEASUREMENTS
To motivate our work, we investigate the impact of fiber cuts in
a subset of Facebook‚Äôs WAN with more than 200,000 IP links and
10,000 optical wavelengths traversing 1,000 optical fiber cables
across the world.
Figure 1: Mapping between IP links and wavelengths.
2.1 Overview
Figure 1 illustrates how IP links and optical wavelengths are mapped
onto each other in Facebook. As shown, several router ports are
grouped into one port-channel. Each port-channel represents an
IP link and carries several Tbps of traffic via multiple wavelengths.
Flows destined for an IP address are load-balanced across all the
interfaces of a port-channel [9, 25, 46]. The aggregation device ag-
gregates multiple grey router ports into tunable Dense Wavelength-
Division Multiplexing (DWDM) transponders.1 For simplicity of
representation, the figure shows a 1-to-1 mapping between router
ports and transponders, but a real deployment is more complex.
The mapping between wavelengths and fibers is configured in the
ROADM. ROADMs can dynamically reconfigure wavelengths to
map to any fiber [1, 3, 37], but as we show in this paper, using this
feature is not without challenges.
Today, once a fiber is cut, router ports and transponders asso-
ciated with the failed fiber become unusable and sit idle until the
fiber is repaired. However, several healthy fibers are often available
to reconfigure the wavelengths traversing the cut fiber by recon-
figuring the ROADMs on the fiber path. For example, in Fig. 1, if
fiber 2 is cut, IP link 2 goes down, causing wavelengths ùúÜ3 to ùúÜ6,
their corresponding transponders, and their router ports (Eth1/1/3
to Eth1/1/6) to become idle. Our goal is to reconfigure these four
idle wavelengths (or some of them) on fiber 1 and/or fiber 3. We
refer to fiber 1 and fiber 3 as surrogate fibers. The decision of which
surrogate fiber to choose for each port-channel (i.e., IP link) and
how much capacity to restore depends on several factors discussed
later in the paper.
Figure 2 presents a high-level example of Arrow in action. The
top row shows the network in a healthy state. The first and last
columns show the optical and IP-layer views of the network, re-
spectively. The middle column represents the mapping between the
two layers. Note the purple IP link between A and C in Figs. 2(b)
and (c): even though there are no direct fibers between A and C, the
provider configured site D to pass through the light between A and
1The term grey router ports is a common term in the optics community [5]. It means
the transceivers on routers use optical wavelengths outside the DWDM‚Äôs color range.
The device that aggregates multiple grey ports and converts them to DWDM light is
often called an Optical Transport Network (OTN) switch.
ERouterROADMPort-Channel1IP Link 1IPv4: 1.1.1.1Eth1/1/1Eth1/1/2Port-Channel2IP Link 2IPv4: 2.2.2.2Eth1/1/3Eth1/1/4Eth1/1/5Eth1/1/6‚Ä¶MUX‚Ä¶TransponderùúÜ2ùúÜ3ùúÜ4ùúÜ5ùúÜ6ùúÜ1, ùúÜ2ùúÜ3,‚Ä¶, ùúÜ6ùúÜ1Fiber2Fiber1IP1IP2Fiber1Fiber2Fiber3IP3Eth1/1/7Eth1/1/8ùúÜ8ùúÜ7Port-Channel3IP Link 3IPv4: 3.3.3.3ùúÜ7, ùúÜ8Fiber3CDFSite BSite AAggregation device/OTN switchFigure 3: Analysis of 600 failure tickets.
Figure 2: Arrow restores the IP-layer view by reconfigur-
ing wavelengths traversing the cut fiber (i.e., ùúÜ1 and ùúÜ2) into
healthy ones.
Figure 4: Impact of fiber cuts on IP layer capacity.
C entirely in the optical domain. As a result, the light is not termi-
nated on intermediate hop D, and from the IP layer‚Äôs perspective,
IP1 is a direct IP link between nodes A and C.
The second row in Fig. 2 shows the status of the network after a
fiber cut without Arrow. As shown in Figs. 2(e) and (f), IP1 and
IP2 become unavailable because they were traversing the cut fiber.
Consequently, the IP layer has to operate with reduced capacity
while the router ports corresponding to IP1 and IP2 sit idle. In
contrast, Arrow (third row) restores the IP-layer view back to the
healthy state by reconfiguring the wavelengths corresponding to
IP1 and IP2 to traverse healthy fibers (through node B), as shown
in Figs. 2(h) and (i).
2.2 Impact of Fiber Cuts on IP Capacity
We begin by studying 600 WAN-related failure tickets in Facebook
over a period of three years (March 2016‚ÄìJune 2019). For each ticket,
we record the duration of the failure and its root cause.
Fig. 3(a) plots the CDF of the mean time to repair for all tickets
categorized by their root cause. It shows that 50% of the fiber cut
events last longer than nine hours, and 10% last over a day. Fig. 3(b)
shows the percentage of downtime for each category. As shown, the
duration of fiber cut events accounts for 67% of the total downtime.
Note that a fiber cut can occur for a variety of reasons including
accidental damage by construction workers, aerial poles falling,
extreme weather conditions, and fiber being chewed by animals.
To quantify how much IP-layer capacity is lost because of fiber
cuts, we dig deeper into the fiber-related failure tickets. We find
that, on average, 16 fiber cut events happen every month. Given
that Facebook‚Äôs datacenter sites have multiple fibers between them
(see Fig. 1) a fiber cut will take away some capacity between site-
pairs. We study the impact of fiber cuts on all site-pairs in Facebook.
Fig. 4(a) shows the time series of lost capacity between four site-
pairs that suffered the most capacity loss between 2017 and 2018.
Each peak in the figure represents a fiber cut, resulting in several
Tbps of capacity loss between site pairs.
Fig. 4(b) shows the CDF of lost capacity on all IP links caused
by fiber cuts during the entire three years of our measurement.
We observe that each fiber cut event resulted in the loss of up
to 8 Tbps of IP capacity. This massive loss of capacity motivates
us to investigate the potential of wavelength reconfiguration for