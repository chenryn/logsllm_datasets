# 【技术分享】机器学习在恶意软件检测中的应用
|
##### 译文声明
本文是翻译文章，文章来源：infosecinstitute.com
原文地址：
译文仅供参考，具体内容表达以及含义原文为准。
****
翻译：[兴趣使然的小胃](http://bobao.360.cn/member/contribute?uid=2819002922)
预估稿费：200RMB
投稿方式：发送邮件至linwei#360.cn，或登陆网页版在线投稿
**  
**
**一、前言**
机器学习是计算机科学的一个分支学科，目的在于赋予计算机从数据中学习的能力，使计算机能够有效利用当今互联网中存在的PB量级的数据，为人们在决策制定、任务执行方面提供帮助支持，这些工作对人们而言复杂度很高且耗时巨大。
恶意软件是企业和用户每天面临的紧迫威胁。无论是钓鱼邮件还是通过浏览器直接投放的漏洞利用工具，这些恶意软件可以与多种规避技术和其他安全漏洞相结合，将现有的防御系统远远抛在脑后。诸如Veil、Shelter等恶意软件框架已经被专业人士用于渗透测试中，取得了非常不错的效果。
今天我将向读者介绍机器学习如何在不使用特征值检测和行为分析方法前提下来检测恶意应用。
顺便提一句，像CylanceProtect、SentinelOne、Carbon
Black之类的安全产品在特征值检测和行为分析方面做了很多工作，本文介绍的恶意软件检测框架不会涉及这些产品所使用的这两类技术。
**二、机器学习简介**
机器学习这个分支学科融合了数学中的多个领域，主要包括统计学、概率论、线性代数以及数学计算（如算法、数据处理、数值计算）。机器学习能够深入挖掘大数据价值，被广泛用于欺诈检测、垃圾邮件检测、电影推荐、饮食及产品购买推荐等各方面。亚马逊、Facebook以及Google等数百家公司也使用机器学习来改进他们的产品及服务。
机器学习主要方法有两种：有监督学习（supervised learning）和无监督学习（unsupervised
learning）。有监督学习中，我们要处理的数据已事先打上标签，无监督学习则与之相反。两种方法都可以用于恶意软件检测，但我们主要关注第一种方法，因为我们的目标是对文件进行归类。
分类（classification）是有监督学习的一个子域，分类对象可以是二进制文件（恶意或非恶意软件）或其他类型对象（阿猫、阿狗、阿猪等等），因此恶意软件检测属于二进制文件分类范畴。
机器学习的详细介绍不在本文范围内，你可以通过多种渠道了解详细信息，也可以查看附录中的资源来深入学习。
**三、问题集**
机器学习的工作流程包括定义问题、收集数据、整理数据（使数据符合训练要求）、使用算法处理数据。这一系列步骤需要消耗大量资源，因此对普通人而言，机器学习在具体实现上较为困难。这些步骤称之为机器学习的工作流程，也是机器学习所需的最少步骤。
对于本文设定的场景，我们首先需要定义工作流程：
1、首先，我们需要收集恶意软件样本，剔除大小小于10k的那些样本。样本数量越多越好。
2、其次，我们需要从样本中提取有意义的特征，这些特征也是我们研究的基础。所谓的特征指的就是能够描述对象的那些属性，比如，一栋房子的特征包括：房间数、房屋面积、房屋价格等。
3、提取特征后，我们需要对样本进行处理，构建样本数据集。数据集可以是一个数据库文件或一个CSV文件，以便于转化为数据向量，因为机器学习算法的计算对象是向量。
4、最后，我们需要一个衡量指标来评价二进制文件的分类结果。有多种指标可以用来衡量算法的性能，如ROC（Receiver Operating
Characteristic，试者工作特征）、AUC（Area Under roc Curve，ROC曲线下面积）、混淆矩阵（Confusion
Matrix）等。这里我们使用的是混淆矩阵指标，因为它能够反应结果的正确比率以及假阳性比率、假阴性比例。
**四、收集样本以及特征提取**
本文假设读者已经了解PE文件格式的相关知识，或者读者也可以先从这里学习基础知识。收集样本非常简单，你可以使用付费服务（如VirusTotal）或者使用这个链接中的样本源。
现在我们开始讨论建模问题。
为了让我们的算法能够从输入的数据中学习，我们需要清理数据，使之整洁且易于理解。本文中，我们使用12个特征来训练算法，这12个特征提取自样本文件，保存在CSV文件中。
**（一）特征提取**
我们使用pefile提取样本特征。首先是使用python下载pefile，命令如下：
    pip install pefile
工具准备完毕，在开始写代码前，我们先讨论一下我们到底需要提取哪些特征。对于一个PE文件来说，我们关心的主要是以下几个特征字段：
1、主映像版本（Major Image Version）：表示应用程序的主版本号。对于4.0版本的Excel而言，该值为4
2、IMAGE_DATA_DIRECTORY的虚拟地址以及大小
3、操作系统版本
4、导入地址表（Import Address Table）地址
5、资源区大小
6、区段个数
7、链接器版本
8、保留栈大小
9、DLL属性值
10、导出表大小和地址
为了使代码结构更为清晰，我们使用类对象来表示PE文件信息，类结构如下所示：
    import os
    import pefile
    class PEFile:
    def __init__(self, filename):
    self.pe = pefile.PE(filename, fast_load=True)
    self.filename = filename
    self.DebugSize = self.pe.OPTIONAL_HEADER.DATA_DIRECTORY[6].Size
    self.DebugRVA =self.pe.OPTIONAL_HEADER.DATA_DIRECTORY[6].VirtualAddress
    self.ImageVersion = self.pe.OPTIONAL_HEADER.MajorImageVersion
    self.OSVersion = self.pe.OPTIONAL_HEADER.MajorOperatingSystemVersion
    self.ExportRVA = self.pe.OPTIONAL_HEADER.DATA_DIRECTORY[0].VirtualAddress
    self.ExportSize = self.pe.OPTIONAL_HEADER.DATA_DIRECTORY[0].Size
    self.IATRVA = self.pe.OPTIONAL_HEADER.DATA_DIRECTORY[12].VirtualAddress
    self.ResSize = self.pe.OPTIONAL_HEADER.DATA_DIRECTORY[2].Size
    self.LinkerVersion = self.pe.OPTIONAL_HEADER.MajorLinkerVersion
    self.NumberOfSections = self.pe.FILE_HEADER.NumberOfSections
    self.StackReserveSize =self.pe.OPTIONAL_HEADER.SizeOfStackReserve
    self.Dll =self.pe.OPTIONAL_HEADER.DllCharacteristics
    现在我们写个简单的函数，为每个PE文件构造一个字典，字典的键为特征字段，其值为特征值，这样每个样本都可以表示为一个python字典对象。如下所示：
    def Construct(self):
    sample = {}
    for attr, k in self.__dict__.iteritems():
    if(attr != "pe"):
    sample[attr] = k
    return sample
现在我们写个脚本，遍历文件夹中的所有样本，将生成的特征字典保存为csv文件，如下所示：
    def pe2vec():
        dataset = {}
    for subdir, dirs, files in os.walk(direct):
    for f in files:
    file_path = os.path.join(subdir, f)
    try:
                    pe = pedump.PEFile(file_path)
                    dataset[str(f)] = pe.Construct()
    except Exception as e:
    print e
    return dataset
    # now that we have a dictionary let's put it in a clean csv file
    def vec2csv(dataset):
        df = pd.DataFrame(dataset)
        infected = df.transpose()  # transpose to have the features as columns and samples as rows
    # utf-8 is prefered 
        infected.to_csv('dataset.csv', sep=',', encoding='utf-8')
接下来我们准备处理这些数据。
**（二）探索数据**
这不是必要步骤，但可以让你对这些数据有直观上的理解。
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    malicious = pd.read_csv("bucket-set.csv")
    clean = pd.read_csv("clean-set.csv")
    print "Clean Files Statistics"
    clean.describe()
    print "Malicious Files Statistics"
    malicious.describe()
以下两个表格分别对应了正常程序和恶意文件的统计情况：
我们可以看到这两组数据集之间的差异，特别是前两个特征字段，差异更为明显。我们可以绘制一个图表，从直观上感受这些差异。
    malicious['clean'] = 0
    clean['clean'] = 1
    import seaborn
    %matplotlib inline
    fig,ax = plt.subplots()
    x = malicious['IATRVA']
    y = malicious['clean']
    ax.scatter(x,y,color='r',label='Malicious')
    x1 = clean['IATRVA']
    y1 = clean['clean']
    ax.scatter(x1,y1,color='b',label='Cleanfiles')
    ax.legend(loc="right")
图表如下：
从上图可知，恶意软件样本“聚类”程度较高，而正常文件样本稀疏分布在x轴上。接下来我们可以试着绘制其他特征的图表，以便全面了解这些样本数据。