case with self modifying code within the current basic block, which
as we said can be detected in Pin with an optional switch at the
price of an increased overhead.
To conclude our discussion, we would like to mention the possi-
bility of having user-supplied analysis code pollute the transparency
of the execution, for instance in its context reconstruction process.
Frameworks like Pin that support registering analysis callbacks
might be slightly easier to use for analysis writers compared to oth-
ers like DynamoRIO that let users manipulate statements directly,
but DBI systems may hardly avoid leaving part of the responsibility
for transparency in the hands of their users.
5.2 Mitigations at Analysis Code Level
While revisiting architectural and implementation choices behind a
DBI system can bring better transparency by design, some research
has explored how user-provided analysis code can mitigate artifacts
of mainstream DBI systems and defeat evasive attempts observed
in some applications domains. This approach has been proposed by
PinShield [46] and adopted in the context of executable unpacking
in the presence of anti-instrumentation measures.
We have designed a high-level DBI library that could run in prin-
ciple in existing analysis systems to detect and possibly counter
DBI evasion and escape attempts. We revisited the design of Pin-
Shield to achieve better performance when shepherding memory
accesses, and introduced protective measures to cope with mem-
ory permission consistency (e.g., to enforce NX policies and page
guards), pointer leaks using FPU instructions, inconsistencies in
exception handling, and a number of detection queries to the OS
(e.g., for when the DBI engine is revealed a debugger).
For a prototype implementation we chose the most challenging
setting for user-provided stopgap measures: we target the popular
combination of Pin running on Windows. Unlike DynamoRIO, Pin
does not rewrite the results of basic fingerprinting operations that
can give away its presence like OS queries about memory. As it is
AsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand
D’Elia et al.
Figure 1: Performance impact of user-provided mitigations.
closed source, it cannot be inspected or modified to ease the imple-
mentation of mitigations, and using Windows makes immediate
cooperation on the OS side (e.g., via a kernel driver) more difficult.
Approach. We pursued a design for the library that could be
portable to other frameworks and Linux, avoiding uses of specific
primitives or choices that could tie it to Pin’s underpinnings.
To shepherd memory accesses, we maintain a shadow page table
as an array indexed by the page number for the address. We monitor
basic RWX permissions and page guard options using 4 bits in a
1-byte element per page4. For 32-bit Windows, this yields a table of
512 kbytes for the 2-GB user address space, with recently accessed
fragments likely to be found in the CPU cache for fast retrieval.
We update the table in presence of code loading events and every
time the program (or Windows components on its behalf) allocates,
releases, or changes permissions for memory, hooking system calls
and events that may cause such changes to the address space. When
a violation is detected, we create an exception for the application5.
Possible code pointer leaks from FPU instructions are intercepted
as revealing instructions get executed: we replace the address from
the code cache with the one in the original code. For this operation
one can either resort to APIs possibly offered by an engine to
convert addresses, or monitor the x87 instructions that cause the
FPU instruction pointer to change with a shadow register. Although
more expensive, we opted for the second approach for generality.
Exception handling inconsistencies may be unrelated to memory:
this is the case with the single-step exception and int 2d attacks
found in malware and executable protectors. We intercept such
sequences and forge exceptions where needed.
Due to lack of space, we refer the reader to our source code
for mitigations made of punctual countermeasures, such as pointer
leaks with int 2e attacks and detections based on debugger objects.
Overhead. The mitigations presented above can have a signifi-
cant impact on the baseline performance level offered by an engine
running an empty analysis code. Shepherding memory accesses is
a daunting prospect for DBI architects [4], let alone when imple-
mented on top of the engine. However, it may be affordable for a
user-defined analysis that already has to track such operations such
as taint analysis. Similarly, conformance checking on NX policy
slows down the execution as it requires that target of branches
be checked, but may be acceptable for code that already validates
transfers, for instance to support CFI or other ROP defenses.
We conducted a preliminary investigation on the SPEC CPU2006
benchmarks commonly used to analyze DBI systems [4, 34]. We
consider different protection levels: pointer leaks, NX and page
guard checks on indirect transfers, denying RW access to DBI re-
gions, the three strategies together, and a paranoid variant6. We
also consider a popular taint analysis library for byte-level tracking
granularity in its default configuration with 1-byte tags. Due to lack
of space (a more complete discussion is provided in Appendix A)
we report figures for a subset of benchmarks in Figure 1.
Tracking x87 instructions for leaks has a rather limited impact
on execution time. Enforcing NX and page guard protection on indi-
rect transfers seems cheap as well. Shepherding memory read/write
accesses incurs a high slowdown, but smaller than the one intro-
duced by the heavy-duty analysis of libdft. High overheads were
expected, but we do not find these figures demoralizing: while some
performance can be squeezed by optimizing the integration with
the backend and with analyses meant to run on top of it, we be-
lieve a fraction of this gap can be reduced if countermeasures get
implemented inside the engine. We used evasive packer programs
to stress the implementation, and we were able to run code packed
with PELock that [46] based on PinShield could not handle properly.
Discussion. Mitigating artifacts using user-level code is a slippery
road. As we mentioned in Section 5.1, there are aspects in system
call interposition that if overlooked can lead security tools to easily
be circumvented: one of them is incorrectly replicating OS seman-
tics. We follow the recommendations from [18] by querying the OS
to capture the effects of system calls that manipulate regions of the
address space: this helped us in dealing with occasional inconsisten-
cies between the arguments or output parameters for such calls and
the effects observed on the address space. Our library pursues at
analysis code level the DBI system design guideline G2 on making
discrepancies imperceivable to the monitored program (Section 4.1),
and its performance impact could be attenuated if cooperation oc-
curs on the DBI runtime side, for instance by supporting automatic
(optimized) guard insertion during trace compilation.
6 WRAP-UP AND CLOSING REMARKS
In the previous sections we have illustrated structural weaknesses
of the DBI abstraction and its implementations when analyzing code
in a software security setting, and discussed mitigations to make
DBI frameworks more transparent—at the price of performance
penalties—in the form of adjustments to their design or stopgap
measures inside analysis tools. We conclude by discussing implica-
tions for researchers that want to use DBI for security with respect
to instrumentation capabilities and to the relevance of the eva-
sion and escape problems, putting into the equation the attacker’s
capabilities and what is needed to counter adversarial sequences.
Choosing DBI in the first place. As we have seen in Section 3, the
flexibility of DBI primitives has supported researchers in developing
a great deal of analysis techniques over the years. Especially when
the source code of a program is not available, there are essentially
two options that could be explored other than DBI: SBI and VMI
techniques. Although tempting to make a general statement on
when one approach should be preferred, we believe the picture
is not so simple, and thorough methodological and experimental
comparisons would be required for different application domains.
4We leave 4 bits to encode more policies or host data from upper analysis layers.
5PinShield in such cases allows the access but rewires it to another region. We can
still use their approach for instance to protect ntdll trampolines.
6For when ESP holds data or EIP flows into a page with inconsistent permissions via
hard-wired jump offsets or branchless sequences that cross page boundaries [24].
0.1110100400.perlbench401.bzip2403.gcc429.mcf473.astarSlowdown w.r.t. Pinleaknxrwfullparanoidlibdft1.011.01.031.091.021.111.031.151.061.053.822.953.662.312.613.912.983.732.252.597.025.926.624.434.9521.7323.846.7117.0417.40SoK: Using Dynamic Binary Instrumentation for Security
AsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand
We can however elaborate on three aspects that could affect a
researcher’s choice. The first aspect is related to the instrumentation
capabilities of each technology. SBI can instrument a good deal
of program behaviors as long as static inference of the necessary
information is possible. On the other hand, VMI can capture generic
events at whole-system level regardless of the structure of the code,
using libraries that bridge the semantic gap to determine which
events belong to the code under analysis. However, current VMI
systems cannot make queries or execute operations using the APIs
provided by the OS, unlike DBI systems that naturally let their users
to. A 2015 work proposed with PEMU [65] a new design to move
DBI instrumentation out of VM, providing a mechanism called
forwarded guest syscall execution to mimic the normal functioning
of a DBI engine; however, the public codebase the authors made
available seems no longer under active development.
The second aspect is related to the deployability of the analysis
system runtime. In the case of SBI, the requirements are typically
limited as the original binary gets rewritten. For the DBI abstrac-
tion, the use of process virtualization paves the way for building
tools that operate on a single application in a possibly lightweight
manner, enabling their use also in production systems, e.g., when
legacy binary are involved [4]. For VMI technology, bringing up an
emulated or virtualized environment may very well be a daunting
prospect or a natural choice depending on the application scenario.
The third aspect is related to whether the analysis should not
only monitor, but also alter the execution when needed. To this end,
DBI and VMI are both capable of detecting and altering specific
instructions also when generated at run time. VMI technology is
currently lackluster in aspects that involve replacing entire calls or
sequences in the text of a program; on the other hand, system call
authorization can be dealt with as context switches occur.
Dealing with adversarial code. A fourth aspect, possibly the most
appealing for our readers, can be added to the technological discus-
sion: adversarial sequences. We should distinguish between general
detection techniques, which may affect more technologies at once,
and ad-hoc detection patterns, sometimes for a specific runtime.
For example, code very sensitive to time variations is likely
to deviate from the normal behavior when executing under DBI
or other in-guest dynamic analysis systems: consider for instance
time-based anti-analysis strategies in evasive malware. On the other
hand, code checksumming sequences give away several analysis
systems, but DBI ones are normally not bothered by them.
A crucial issue is related to the characteristics of the code that un-
dergoes analysis, that is, if there is the possibility for an attacker to
embed adversarial patterns specific to DBI. This is particularly (but
not only) the case of research focused on malicious code analysis
and reverse engineering activities. Such code can clearly challenge
massaged results and other mitigations for transparency issues put
in place by the engine or the analysis tool.
When the adversary does not have arbitrary memory read ca-
pabilities, mitigating leaked code pointers is already sufficient in
most cases to hide the presence of extra code regions, and different
attack surfaces should be tried, such as exhaustion or prediction
attacks for memory allocations. When the adversary cannot write
to arbitrary memory locations and leaked pointers have already
been dealt with, escaping attempts are essentially contained, while
the execution of unfeasible flows from inconsistencies in enforcing
NX policies can be avoided by shepherding control transfers.
What really raises the bar for DBI engines is coping with an
attacker that can register exception handlers and force memory
operations also on regions marked as unallocated in massaged OS
queries. The runtime overhead of shepherding every memory access
is intrinsically high for current DBI designs, but technologies like
executable-only memory may come to the rescue in the future.
One may also wonder whether the popularity of an analysis
technique can eventually lead to the diffusion of ad-hoc adversarial
sequences in the code it is meant to analyze. In the history of DBI
we are aware of ad-hoc evasions against Pin in some executable
packers [10], as simple DBI-based unpacking schemes from a few
years ago were effective against older generations of packers. On
the contrary, there is a possibility that even when an attack surface
is well known and not particularly hard to exploit, as in the case of
implicit flows against taint analysis [7], adversaries may focus their
attention elsewhere for anti-analysis sequences: for the proposed
example, malware authors in late years seem rather to have con-
centrated their efforts on escaping sandboxing technologies and
hindering code analysis with obfuscation strategies such as opaque
predicates and virtualization. We thus find it hard to speculate on
an arms race that could involve DBI evasion in the near future.
Finally, as we mentioned in Section 4.1 also approaches like
VMI that are more transparent by design can become fragile in the
presence of a dedicated adversary. Every technology has its own
trade-offs between transparency and aspects like performance or
instrumentation capabilities. In the case of SBI, the approach can
offer better performance than DBI, but its transparency is more frag-
ile than DBI and VMI: for instance, even recent SBI embodiments
cannot offer protection against introspective sequences when these
are not identified in the preliminary static code analysis phase.
Closing remarks. In this work we attempted to systematize exist-
ing knowledge and speculate on a problem that recently received a
good deal of attention in the security community, with opinions
sometimes at odds with one another. We think that using DBI for
security is not a black and white world, but is more about how the
DBI abstraction is used once the user is aware of its characteristics
in terms of execution transparency, understood not only as a se-
curity problem, but sometimes also as a correctness one. Hoping
that other researchers may benefit from it, we make available our
library of detection patterns and mitigations for Pin at:
https://github.com/season-lab/sok-dbi-security/
Acknowledgements. We are grateful to Ke Sun, Xiaoning Li, and
Ya Ou for sharing their code [56] with us. This work is supported in
part by a grant of the Italian Presidency of the Council of Ministers.
[2] Otto Brechelmacher, Willibald Krenn, and Thorsten Tarrach. 2018. A Vision for
REFERENCES
[1] Michael Backes, Thorsten Holz, Benjamin Kollenda, Philipp Koppe, Stefan Nürn-
berger, and Jannik Pewny. 2014. You Can Run but You Can’t Read: Preventing
Disclosure Exploits in Executable Code (CCS ’14). ACM.
Enhancing Security of Cryptography in Executables (ESSoS ’18). Springer.
Hardware-Assisted Virtualization (DIMVA ’16). Springer.
Instrumentation (VEE ’12). ACM.
Patching. Int. J. High Perform. Comput. Appl. 14, 4 (Nov. 2000).
[4] Derek Bruening, Qin Zhao, and Saman Amarasinghe. 2012. Transparent Dynamic
[5] Bryan Buck and Jeffrey K. Hollingsworth. 2000. An API for Runtime Code
[3] Michael Brengel, Michael Backes, and Christian Rossow. 2016. Detecting
AsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand
D’Elia et al.
[6] Juan Caballero, Pongsin Poosankam, Christian Kreibich, and Dawn Song. 2009.
Dispatcher: Enabling Active Botnet Infiltration Using Automatic Protocol Reverse-