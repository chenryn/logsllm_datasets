f
o
#
0.04
0.03
0.02
0.01
0
20
40
60
80
100
120
140
160
180
200
 Testing Period (# of Command Blocks)
Figure 4. False Positive Rate on Testing Data
probabilistic policy, the long-term expected average reward
would be calculated based on the probabilities of two out-
come occurring: N(cid:113) and N(cid:100). Hence (cid:117)(cid:119) is simpliﬁed as
(cid:14) (cid:3) (cid:15), in addition, as the ADC gets reward signal at ev-
ery decision step, (cid:117)(cid:119) can be further simpliﬁed as (cid:122)1 (cid:3) (cid:122)2.
Speciﬁcally, at each time step, for the observation trace, if
ADC takes action “Observe”, reward signal is assigned 0, if
the action is “Alarm”, reward signal is assigned (cid:3)1. A total
reward signal is then calculated after one pass through the
sequence data concatenated by observation traces (the ideal
value should be 0). To simplify the consensus strategy, any
false alarm reported by any elemental AD would led to the
“Alarm” action of ADC, with penalty to all ADs.
Figure 3 depicts the ADC’s behavior during the train-
ing phase (with 500 training epochs, parameters (cid:29)=0.90 and
(cid:31)1 = (cid:31)2 · · · = 10(cid:3)3
). The upper part of the ﬁgure shows
the changing of the number of false alarms in the training
phase, and the lower part of the ﬁgure shows the average
reward signal (to manifest the trend, ADC only considered
the past 10 passes, i.e., (cid:87) =10 in equation (2)). The ﬁg-
ure shows clearly that the ADC had incrementally improved
performance during the training phase, as the reward signal
improves, on average, over time to an optimum. We found
that after the 462th pass, there was no false alarm triggered.
After being trained, the parameter vector of ADC (cid:21) is:
µ
¶
(cid:21) =
0(cid:61)42 0(cid:61)84 0(cid:61)69 0(cid:61)79
0
30
10
6
4.2.2 Testing of False Alarms
To evaluate the capability of the ADC to suppress false
alarms, we tested the trained ADC using the normal test-
ing set in table 2. The testing data was also divided into 188
commands traces (each trace contains 30 command tokens),
together with their underlying audit events and processes.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:53:20 UTC from IEEE Xplore.  Restrictions apply. 
Table 5. Comparison of masquerade detec-
tion results between MCE and ADC
Table 6. Detection Performance Comparison
(‘B’ denotes Buffer overﬂow instance, ‘D’ denotes DoS instance)
Hits(%)
F.P.(%) Detected Attacks
Threshold
Methods
MCE ADC
Markov Chain
84.62
# of normal command traces
188
188
# of anomalous Command traces
Traces size
Hits(%)
Misses(%)
F.P.(%)
Total Detected
28
30
28
30
71.43
82.14
28.57
17.86
11.17
9.57
21
23
Figure 4 shows the relationship between the average false
alarm rate (the number of false alerts over the number of
command traces) and the number of command traces used
for testing data. Since the ADC gives the report with the
pace of each command trace, we compared its performance
with that of MCE (with initial parameter), which also re-
ports once on every command trace.
The ﬁgure shows that the ADC triggered less false alerts
compared with MCE. ADC generated its ﬁrst false alarm
at the 101th command trace (i.e., F.P.=0.99%, ﬁrst 94 com-
mand traces has been used to train ADC, thereby no false
alarms were triggered until the 101th command trace). At
the 183th command trace, MCE has generated 11 alerts,
i.e., F.P.=6.01%, while the ADC only generated 4 alerts,
F.P.=2.19%. We found that at the 128th and 171th com-
mand traces, MCE did not report false alarm, while ADC
reported, which means that one of the other 3 ADs has made
wrong actions. Although the analysis of other three ADs are
helpful to insight into the story, we did not carry it out here,
because of the intractable data partition and the lack of a
compelling need to do. In addition, the parameter used by
the MCE was directly derived from the ADC rather than by
individual training, therefore, we can not rule out the pos-
sibility that the MCE might achieve better performance af-
ter being trained and parameterized carefully with another
training dataset.
4.2.3 Detection of Common Exploits
First, we evaluated the ADC’s masquerade detection perfor-
mance. 850 command tokens (with underlying 2127 audit
events and 272 processes) of another user were truncated
into 28 command traces (each login session also contains
30 command tokens or so), and injected at randomly se-
lected positions, without replacement, into the stream of
original 188 command traces (a more complicated case
is to inject the command traces into the command tokens
STIDE
KNN
ADC
92.30
76.92
100.00
4.35
3.48
5.36
1.01
8B+3D
8B+4D
8B+2D
8B+5D
0.88
0.75
0.95
(cid:51)
instead of command traces;
in such a case, the bound-
aries between the traces might generate uncontrollable false
alarms). Meanwhile, the underlying audit events and pro-
cesses that have been executed by the ‘masquerader’ were
also injected into the respective normal observation traces.
The result is shown in Table 5, among total 216 command
traces (188 normal + 28 anomalous), MCE detected 20 out
of 28 anomalous command traces with a F.P. 11.17% by
regulating the threshold to 0.38. After this detection spot,
the F.P. raised sharply to 100% with a total 21 anomalous
command traces being detected. While the trained ADC
detected 23 anomalous command traces with a F.P. 9.57%.
Second, the trained ADC was used to detect the injected
attacks that shown in Table 3, and its performance was com-
pared with that of the individual ADs. In our work, detec-
tion accuracy is deﬁned as the ratio of the detected attacks
to all the injected attacks (hidden in 35 intrusive processes).
false alert rate is the ratio of the misreports to all the nor-
mal processes (total 690). To simplify the experiment while
keeping the validity, we assumed that the false alerts would
not be generated by those normal traces that have been used
in the last experiment for testing false alerts, and the consen-
sus strategy hence was adjusted as: any ‘Alarm’ report from
any individual ADs would cause the ADC to take ‘Alarm’
action. The initial parameters used by the individual ADs
were directly derived from the ADC, while to investigate
the relationship between detection accuracy and F.P., we
had to adjust them individually. Table 6 shows the detec-
tion result of the ADC, and the best trad-off between the
detection accuracy and F.P. of the elemental ADs by adjust-
ing respective thresholds (a higher detection performance
would cause a dramatic increase of false alerts). Speciﬁ-
cally, we have following observations:
• since the intrusive processes were injected into the normal
processes without corresponding command traces, MCE al-
ways took action ‘Observe’;
• the ADC detected all the injected attacks by combing the
reports from elemental ADs, while its false alert rate was
very low (i.e., 7 among 690 processes were misreported);
• all the ADs detected all the buffer overﬂow attacks, while
some DoS attacks were not discovered.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:53:20 UTC from IEEE Xplore.  Restrictions apply. 
5 Conclusion and Future Work
Based on the assumption that optimal combination of
several observation-speciﬁc ADs may broaden detection
coverage, suppress the false positive rate, and probably cap-
ture “root-cause” attacks, a POMDP model was formulated
and a policy-gradient reinforcement learning algorithm was
applied to tackle the delayed reward, partially observable,
multi-agent learning problem. In next stage, we intend to
collect more real trace data (and some artiﬁcial anomalies)
to enrich the experiments. Some additional problems, such
as computational cost, real-time response ability, and con-
sensus efﬁciency, also need careful consideration. Further-
more, we will extend our work to the computer networks,
to verify whether our ADC can detect distributed attacks
with ADs locating in several dominated hosts. Anomalies
in wireless networks or sensor networks are also expected
to be detected through the optimal cooperation of location-
centric ADs.
6 Acknowledgement
This research is conducted as a program for the ”Foster-
ing Talent in Emergent Research Fields” in Special Coor-
dination Funds for Promoting Science and Technology by
Ministry of Education, Culture, Sports, Science and Tech-
nology.
References
[1] Douglas Aberdeen, “A Survey of Approximate Methods for
Solving Partially Observable Markov Decision Processes”,
National ICT Australia Report, Canberra, Australia, 2003.
[2] Peter L. Barlett and Jonathan Baxter,
“Hebbian synaptic
modiﬁcations in spiking neurons that learn”, Technical re-
port, Computer Sciences Laboratory, RSISE, ANU, 1999.
[3] Jonathan Baxter and Peter L. Barlett,
“Stochastic Opti-
mization of Controlled Partially Observable Markov Deci-
sion Processes”, Proceedings of the 39th IEEE Conference
on Decision and Control(CDC00).
[4] Jonathan Baxter and Peter L. Barlett,
“Direct Gradient-
Based Reinforcement Learning: I.Gradiment Estimation Al-
gorithms”, Technical report, ANU,1999.
[5] J. Baxter, L. Weaver, and P.L. Bartlett, “Direct Gradient-
Based Reinforcement Learning: II.Gradiment Descent Algo-
rithms and Experiments”, Technical report, Research School
of Information Sciences and Engineering, Australian Na-
tional University, September 1999.
[6] Sung-Bae Cho and Hyuk-Jang Park. “Efﬁcient anomaly de-
tection by modeling privilege ﬂows using hidden Markov
model”, Computer and Security, Vol No.1, pp 45-55,2003.
[7] S. Forrest, S.A. Hofmeyr,,& T.A. Longstaff, “A sense of self
In proceedings of 1996 IEEE Sym-
for UNIX processes”,
posium on Security and Privacy, Los Alamitos, CA: IEEE
Computer Society Press.
[8] Giorgio Giacinto, Fabio Roli, Luca Didaci, “Fusion of multi-
ple classiﬁers for intrusion detection in computer networks”,
Pattern Recognition Letters 24(2003) 1795-1803.
[9] Sang-Jun Han, and Sung-Bae Cho, “Combining Multiple
Host-Based Detectors Using Decision Tree,” Artiﬁcial Intel-
ligence, LNAI 2903, pp.208-220, 2003.
[10] Joshua H., Dorene K.R., Larra T., Stephen T., “Validation
of Sensor Alert Coorelators,” IEEE Security and Privacy,
pp46-56, 2003.
[11] Yihua Liao, V. Rao Vemuri, “Use of K-Nearest Neighbor
classiﬁer for intrusion detection”, Computers and Security,
Vol 21, No 5, pp439-448, 2002.
[12] Roy A. Maxion,
“Masquerade Detection Using Enriched
Command Lines”, International Conference on Dependable
Systems & Networks: San Francisco, CA, 22-25 June 2003.
[13] Roy A. Maxion, “Masquerade Detection Using Truncated
Command Lines”, International Conference on Dependable
Systems & Networks: Washington, DC, 23-26 June 2002.
[14] Ning, P., Cui, Y., Reeves, D.S., and Ding X., “Techniques
and Tools for Analyzing Intrusion Alerts,” ACM Transac-
tions on Information and Systems Security, Vol.7, No.2, May
2004, Pages 274-318.
[15] Porras, P.A., Neumann, P.G., “EMERALD: Event Monitor-
ing Enabling Responses to Anomalous Live Disturbances,”
Proceedings of the 20th Natonal Information Systems Secu-
rity Conference,1997.
[16] Snapp, S.R., Smaha, S.E., Teal, D.M., Grance, T.,
“The
DIDS (Distributed Intrusion Detection System) prototype”,
the summer USENIX Conference, San Antonio, Texas,
USENIX Association (1992)227-233.
[17] Nigel Tao, Jonathan Baxter, Lex Weaver, “A Multi-Agent,
Policy-Gradient approach to Network Routing”, 18th Inter-
national Conference on Machine Learning, ICML 2001.
[18] Kymie M.C. Tan and Roy A. Maxion, ““Why 6” Deﬁning
the Operational Limites of stide, an Anomaly-Based Intru-
sion Detector,” Proceedings of the 2002 IEEE Symposium
on Security and Privacy, 2002.
[19] Kymie M.C. Tan, Kevin S. Killourhy, and Roy A. Maxion,
“Undermining an Anomaly-Based Intrusion Detection Sys-
tem Using Common Exploits,” RAID 2002, LNCS 2516, pp.
54-73, 2002.
[20] C. Warrender, S. Forrest and B. Pearlmutter.
“Detecting
Intrusion Detection Using System Calls: Alternative Data
Models”, In Proceedings of 1999 IEEE Symposium on Secu-
rity and Privacy, pp133-145, Oakland, 1999.
[21] Nong Ye, Xiangyang Li, Qiang Chen, Syed Masum Emran,
and Mingming Xu. “Probabilistic Techniques for Intrusion
Detection Based on Computer Audit Data”, IEEE Transac-
tion on Systems, Man, and Cybernetics-Part A:Systems and
Humans, Vol.31, No.4, July 2001.
[22] Nong Ye, Timothy Ehiabor and Yebin Zhang, “First-Order
Versus High-Order Stochastic Models For Computer Intru-
sion Detection”, Quality and Reliability Engineering inter-
national, 2002;18: 243-250.
[23] Dit-Yan Yeung, Yuxin Ding, “Host-based intrusion detec-
tion using dynamic and static behavioral models”, Pattern
Recognition 36 (2003) 229-243.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:53:20 UTC from IEEE Xplore.  Restrictions apply.