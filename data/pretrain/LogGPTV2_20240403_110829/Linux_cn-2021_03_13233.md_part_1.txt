---
author: Jr Oakes
category: 软件开发
comments_data: []
count:
  commentnum: 0
  favtimes: 0
  likes: 0
  sharetimes: 0
  viewnum: 3899
date: '2021-03-24 23:21:00'
editorchoice: false
excerpt: Google API 可以凸显出有关 Google 如何对网站进行分类的线索，以及如何调整内容以改进搜索结果的方法。
fromurl: https://opensource.com/article/19/7/python-google-natural-language-api
id: 13233
islctt: true
largepic: /data/attachment/album/202103/24/232018q66pz2uc5uuq1p03.jpg
permalink: /article-13233-1.html
pic: /data/attachment/album/202103/24/232018q66pz2uc5uuq1p03.jpg.thumb.jpg
related: []
reviewer: wxy
selector: lujun9972
summary: Google API 可以凸显出有关 Google 如何对网站进行分类的线索，以及如何调整内容以改进搜索结果的方法。
tags:
- 谷歌
- 搜索
- 自然语言
thumb: false
title: 利用 Python 探究 Google 的自然语言 API
titlepic: true
translator: stevenzdg988
updated: '2021-03-24 23:21:00'
---
> 
> Google API 可以凸显出有关 Google 如何对网站进行分类的线索，以及如何调整内容以改进搜索结果的方法。
> 
> 
> 
![](/data/attachment/album/202103/24/232018q66pz2uc5uuq1p03.jpg "magnifying glass on computer screen")
作为一名技术性的搜索引擎优化人员，我一直在寻找以新颖的方式使用数据的方法，以更好地了解 Google 如何对网站进行排名。我最近研究了 Google 的 [自然语言 API](https://cloud.google.com/natural-language/#natural-language-api-demo) 能否更好地揭示 Google 是如何分类网站内容的。
尽管有 [开源 NLP 工具](https://opensource.com/article/19/3/natural-language-processing-tools)，但我想探索谷歌的工具，前提是它可能在其他产品中使用同样的技术，比如搜索。本文介绍了 Google 的自然语言 API，并探究了常见的自然语言处理（NLP）任务，以及如何使用它们来为网站内容创建提供信息。
### 了解数据类型
首先，了解 Google 自然语言 API 返回的数据类型非常重要。
#### 实体
 实体   Entities 是可以与物理世界中的某些事物联系在一起的文本短语。 命名实体识别   Named Entity Recognition （NER）是 NLP 的难点，因为工具通常需要查看关键字的完整上下文才能理解其用法。例如， 同形异义字   homographs 拼写相同，但是具有多种含义。句子中的 “lead” 是指一种金属：“铅”（名词），使某人移动：“牵领”（动词），还可能是剧本中的主要角色（也是名词）？Google 有 12 种不同类型的实体，还有第 13 个名为 “UNKNOWN”（未知）的统称类别。一些实体与维基百科的文章相关，这表明 [知识图谱](https://en.wikipedia.org/wiki/Knowledge_Graph) 对数据的影响。每个实体都会返回一个显著性分数，即其与所提供文本的整体相关性。
![实体](/data/attachment/album/202103/24/232133yn9fxn48z9nq9wd4.png "Entities")
#### 情感
 情感   Sentiment ，即对某事的看法或态度，是在文件和句子层面以及文件中发现的单个实体上进行衡量。情感的 得分   score 范围从 -1.0（消极）到 1.0（积极）。 幅度   magnitude 代表情感的 非归一化   non-normalized 强度；它的范围是 0.0 到无穷大。
![情感](/data/attachment/album/202103/24/232134u49cg3zk9yp2q023.png "Sentiment")
#### 语法
 语法   Syntax 解析包含了大多数在较好的库中常见的 NLP 活动，例如    词形演变    lemmatization 、   词性标记    part-of-speech tagging  和    依赖树解析    dependency-tree parsing 。NLP 主要处理帮助机器理解文本和关键字之间的关系。语法解析是大多数语言处理或理解任务的基础部分。
![语法](/data/attachment/album/202103/24/232134l5q5rjdwdszzdszj.png "Syntax")
#### 分类
 分类   Categories 是将整个给定内容分配给特定行业或主题类别，其 置信度   confidence 得分从 0.0 到 1.0。这些分类似乎与其他 Google 工具使用的受众群体和网站类别相同，如 AdWords。
![分类](/data/attachment/album/202103/24/232134loa7cb69a8bnbapl.png "Categories")
### 提取数据
现在，我将提取一些示例数据进行处理。我使用 Google 的 [搜索控制台 API](https://developers.google.com/webmaster-tools/) 收集了一些搜索查询及其相应的网址。Google 搜索控制台是一个报告人们使用 Google Search 查找网站页面的术语的工具。这个 [开源的 Jupyter 笔记本](https://github.com/MLTSEO/MLTS/blob/master/Demos.ipynb) 可以让你提取有关网站的类似数据。在此示例中，我在 2019 年 1 月 1 日至 6 月 1 日期间生成的一个网站（我没有提及名字）上提取了 Google 搜索控制台数据，并将其限制为至少获得一次点击（而不只是 曝光   impressions ）的查询。
该数据集包含 2969 个页面和在 Google Search 的结果中显示了该网站网页的 7144 条查询的信息。下表显示，绝大多数页面获得的点击很少，因为该网站侧重于所谓的长尾（越特殊通常就更长尾）而不是短尾（非常笼统，搜索量更大）搜索查询。
![所有页面的点击次数柱状图](/data/attachment/album/202103/24/232134obtqt33t7qwbqd7d.png "Histogram of clicks for all pages")
为了减少数据集的大小并仅获得效果最好的页面，我将数据集限制为在此期间至少获得 20 次曝光的页面。这是精炼数据集的按页点击的柱状图，其中包括 723 个页面：
![部分网页的点击次数柱状图](/data/attachment/album/202103/24/232135xtqtlen7s7ydstoo.png "Histogram of clicks for subset of pages")
### 在 Python 中使用 Google 自然语言 API 库
要测试 API，在 Python 中创建一个利用 [google-cloud-language](https://pypi.org/project/google-cloud-language/) 库的小脚本。以下代码基于 Python 3.5+。
首先，激活一个新的虚拟环境并安装库。用环境的唯一名称替换 `` 。
```
virtualenv 
source /bin/activate
pip install --upgrade google-cloud-language
pip install --upgrade requests
```
该脚本从 URL 提取 HTML，并将 HTML 提供给自然语言 API。返回一个包含 `sentiment`、 `entities` 和 `categories` 的字典，其中这些键的值都是列表。我使用 Jupyter 笔记本运行此代码，因为使用同一内核注释和重试代码更加容易。
```
# Import needed libraries
import requests
import json
from google.cloud import language
from google.oauth2 import service_account
from google.cloud.language import enums
from google.cloud.language import types
# Build language API client (requires service account key)
client = language.LanguageServiceClient.from_service_account_json('services.json')
# Define functions
def pull_googlenlp(client, url, invalid_types = ['OTHER'], **data):
        html = load_text_from_url(url, **data)
        if not html:
        return None
        document = types.Document(
        content=html,
        type=language.enums.Document.Type.HTML )
        features = {'extract_syntax': True,
                'extract_entities': True,
                'extract_document_sentiment': True,
                'extract_entity_sentiment': True,
                'classify_text': False
                }
        response = client.annotate_text(document=document, features=features)
        sentiment = response.document_sentiment
        entities = response.entities
        response = client.classify_text(document)
        categories = response.categories
        def get_type(type):
        return client.enums.Entity.Type(entity.type).name
        result = {}
        result['sentiment'] = []    
        result['entities'] = []
        result['categories'] = []
        if sentiment: