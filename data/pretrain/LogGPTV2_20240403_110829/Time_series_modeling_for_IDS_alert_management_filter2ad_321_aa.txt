title:Time series modeling for IDS alert management
author:Jouni Viinikka and
Herv&apos;e Debar and
Ludovic M&apos;e and
Renaud S&apos;eguier
Time Series Modeling for IDS Alert Management
Jouni Viinikka, Herv´e Debar
Ludovic M´e, Renaud S´eguier
Sup´elec
BP 81127
35511 Cesson S´evign´e Cedex, France
ﬁPI:EMAIL
France Telecom
BP 6243
14066 Caen Cedex, France
ﬁPI:EMAIL
ABSTRACT
Intrusion detection systems create large amounts of alerts.
Signiﬁcant part of these alerts can be seen as background
noise of an operational information system, and its quantity
typically overwhelms the user. In this paper we have three
points to make. First, we present our ﬁndings regarding the
causes of this noise. Second, we provide some reasoning why
one would like to keep an eye on the noise despite the large
number of alerts. Finally, one approach for monitoring the
noise with reasonable user load is proposed. The approach
is based on modeling regularities in alert ﬂows with classi-
cal time series methods. We present experimentations and
results obtained using real world data.
Categories and Subject Descriptors
C.2.3 [Computer - Communication Networks]: Net-
work Operations—Network monitoring; C.2.0 [Computer -
Communication Networks]: General—Security and pro-
tection
General Terms
Security, Experimentation
1.
INTRODUCTION
Intrusion detection systems (IDS) create often excessive
amounts of alerts, a fact acknowledged widely in both sci-
ence and industry [1, 7, 12]. In this section we have a look
at some of the causes of this alert overﬂow and position our
work in the alert correlation domain.
In this paper by a sensor we mean a misuse- and network-
based sensor. The diagnostic capabilities of current sensors
are modest [5], and a large majority of generated alerts can
be of little or no use for the operator of the system [7]. This
chaﬀ is generated for diverse reasons, but can be roughly
divided into four classes. The last class is the most relevant
with respect to our work, and we will describe it in more
detail. 1) The behavior model of an anomaly-based sensor
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
AsiaCCS’06 March 21–24, 2006, Taipei, Taiwan
Copyright 2006 ACM 1-59593-272-0/06/0003 ...$5.00.
0
or the attack descriptions of a misuse-based sensor can be
inaccurate, creating false positives. 2) The sensor may be
unable to determine whether the seen attack is a real threat
in the working environment of the sensor. 3) The sensor is
often mono eventual i.e. unable to associate related attack
steps, checking e.g. just one network packet at the time.
4) The sensor is alerting on packets that a) are often caused
by normal system functioning, but b) can also be premises
or consequences of attacks or problems. The diﬃculty is
that it is impossible to make the diﬀerence using the infor-
mation carried by the packet. This implies that the ﬂow
of these alerts contains both signs of of wanted, or at least
acceptable, traﬃc, and possibly signs of of unwanted traﬃc.
Typically, these alerts are not associated with any vulnera-
bilities, and consequently alert veriﬁcation [9] using for ex-
ample the knowledge of the conﬁguration of the information
system is not possible.
Some of these issues could be, at least in theory and to
some extent, addressed by improving the sensors themselves.
However, in practice the data capture and analysis capabil-
ities of low level sensors are rather limited because of large
amount of data that needs to be monitored in (near) real-
time.
In addition, the visibility of one sensor can be too
limited for diagnosing large scale attacks or using knowl-
edge about the operating environment at sensor level.
Alert correlation has been proposed as one solution to
the problem [6, 8, 14, 16]. Harshly simplifying, correlation
is a higher level function taking multiple alerts and addi-
tional information into account to 1) reduce the alert vol-
ume, 2) improve the alert content, 3) and to track attacks
spreading across multiple packets or consisting of multiple
steps. The alerts can be issued by from multiple, hetero-
geneous sensors, and the additional information is, for in-
stance, the conﬁguration and vulnerability scan results of
the monitored system.
Our work focuses on processing high alert volumes pro-
duced by misuse- and network-based sensor Snort. The
alerts in question can mostly be associated with the cause
number four, the monitoring of common packets related to
system functioning. In the rest of this paper, when speaking
of alerts, we mean this particular type of alerts unless men-
tioned otherwise. In our operating environment we cannot
eliminate this type of alerts by deactivating the signatures,
so we need a methodology to process them.
The proposed methodology builds on three basic ideas:
1) instead of individual alerts we process alert ﬂows, 2) the
component of a ﬂow that can be attributed to the normal
system behavior is modeled using autoregressive time series
model, and 3) only deviations from the normal ﬂow behavior
are reported to the operator as meta-alerts.
The remaining of the paper is organized as follows. We
deﬁne the problem in section 2.
In section 3 we present
related work and position our work with respect to it. As
our approach is driven by problems detected in the wild, we
spend some space presenting the used alert corpus and our
observations made from the data in section 4. These ob-
servations have given the inspiration for this work, and we
consider them important. Section 5 explains the methodol-
ogy we propose to process alerts generated by proliﬁc signa-
tures. This section describes also the used time series analy-
sis methods. Practical results are discussed in section 6 and
ﬁnally we oﬀer our conclusions in section 7.
2. PROBLEM STATEMENT
In this section we deﬁne the problem we aim to solve, and
justify its signiﬁcance for the users of intrusion detection
systems.
The main objective of our work is to allow the user to
focus on more relevant tasks by relieving him from the man-
ual inspection of numerous benign alerts, and still provide
him with the contextual information available only in the
aggregates. It has been reported [7] that as much as 99% of
the alerts produced by intrusion detection systems can be
false positives, alerts mistakenly triggered by benign pack-
ets. First of all, we see that the deﬁnition of a false positive
is a bit problematic. We do think that as such, a large ma-
jority of alerts is quite useless for the operator. However,
we do not consider them all as false. Consider Snort signa-
tures without associated vulnerability. For example, Snort
has signatures for ICMP Destination Unreachable messages,
and when the sensor triggers the alert, it is not issued mis-
takenly, even though likely to be rather useless as such for
the operator. We prefer to call these kinds of alerts as the
background noise from an operational information system,
not false alerts.
It is impossible to make the diﬀerence between normal ac-
tivity and attacks/problems in the way they manifest them-
selves in this type of alerts by looking at the individual
alerts. However, we believe that the distinction can be made
by analyzing the aggregated alert ﬂow, and especially its in-
tensity, the number of alerts in a time unit with respect to re-
cent history. Returning to ICMP Destination Unreachable
messages, unusual changes in the alert intensity can indi-
cate a problem, that is possibly security related. Thus we
prefer to monitor alert aggregates instead of deactivating
the proliﬁc signatures or ﬁltering on alert-by-alert basis. As
mentioned before, alert veriﬁcation techniques are not a fea-
sible solution for this type of alerts.
In addition, we have observed in our operating environ-
ment rather signiﬁcant regularities in alert ﬂows, having
most likely non-malicious origins. Hence not any changes
is alert intensity, but only changes in and deviations from
the regular behavior are interesting for the operator, and
would require further investigation. As these regularities
account for a large majority of alerts, we aim to model the
regularity in order to ﬁlter it out.
Ordinary network sensors, for example information pro-
vided by netﬂow, 1 could be used to monitor some of these
packets at the network level as has been done in e.g.
[2].
1http://www.cisco.com/go/netflow/
However, we use Snort for the following reasons:
• Even though an ordinary network sensor could be used
to monitor for example ICMP messages, and diﬀerent
types of messages could be separated with header in-
formation, this is not enough for our purposes. We
need more ﬁne grained alert aggregation using pat-
tern matching on packet payload. For example, ICMP
Echo messages can contain information on the pur-
ported origin of the ping packet in the payload, which
is of interest to us.
• By its packet aggregation, Netﬂow creates an abstrac-
tion layer that is not present when we use individual
alerts from Snort. It could be seen that we are per-
forming ourselves a ﬂow level abstraction that suits
our needs better than the one provided by Netﬂow.
• Last, but not least, Snort is the interface to the mon-
It is a fact we need
itored network at our disposal.
to accept in our operating environment, and we try to
make the best use of available tools.
3. RELATED WORK
In this section we present related work, in intrusion de-
tection and alert correlation domains, and point out the dif-
ferences between these approaches and our work.
3.1
Intrusion detection
In [18,19] exponentially weighted moving average (EWMA)
control charts are used to monitor Solaris BSM event in-
tensity to detect denial-of-service attacks. The monitoring
method is similar to our previous work [17], but it is applied
at sensor level, and to host based data source.
Mahadik et al. [11] use EWMA based monitoring for Qual-
ity of Service (QoS) parameters, like jitter and packet drop
rate, in a DiﬀServ network to detect attacks on QoS. Thus
it can be seen to use network based data source. Our ap-
proach uses diﬀerent data source, namely alerts instead of
QoS parameters, and the processing method is diﬀerent. We
do apply a similar detection method for anomalies, but we
pre-process the alert series and model the normal behavior
of the alert ﬂow diﬀerently.
3.2 Alert correlation
Among the several proposed correlation methods and tech-
niques, we consider the following being related to our work.
Qin and Lee [15] use Granger Causality Test to ﬁnd un-
known relationships in alert data. The time series data is
formed as the number of occurrences of meta-alerts in a time
unit, and they search causal relationships between the se-
ries. The meta-alerts are formed by aggregating alerts shar-
ing other attributes, as deﬁned in IDMEF, than the time
stamp, therefore they use more ﬁne grained aggregation cri-
teria than we. We ﬁlter out the normal component in one
speciﬁc type of alert ﬂow instead of trying to track attacks
spreading across multiple steps (i.e./ alert series). In other
words, the objectives and the used techniques are diﬀerent.
Julisch [7, 8] uses data mining to ﬁnd root causes for false
alerts, and proposes to ﬁlter those alerts when it is not pos-
sible to ﬁx the root causes. The ﬁlters are based on alert
attributes and work on alert-by-alert basis. Firstly, changes
in the alert intensity created by the root cause can be in-
teresting, and this information is lost, if such ﬁlters are in
0
Table 1: Five most proliﬁc signatures in the ﬁrst data
set
signature
SNMP Request
Whatsup
ICMP Dest Unr
LOCAL-POLICY
Speedera
sum
SID # of alerts
1417
482
485
-
480
176 009
72 427
57 420
51 674
32 961
390 491
place. Secondly, for some alert ﬂows, there is no ﬁnite set of
root causes that could be easily ﬁltered. Episode rules [13]
could provide visibility over several alerts, but in [8] they
were reported as error prone and laborious approach.
4. ALERT CORPUS
In this section we describe the used alert corpus used in
the tests. We will also provide justiﬁcation for the narrow
scope of the approach, deﬁne diﬀerent ﬂow proﬁles, and an-
alyze ﬁve high-volume alert ﬂows in detail.
The data set consists of alerts generated by three Snort
sensors deployed in an operational information system, one
closer to the Internet, and two in more protected areas. The
sensors store the alerts in a database on a remote server, and
our processing component is situated on the server. As the
monitored traﬃc was real, the absolute truth concerning the
nature of observed traﬃc remains unknown. On the other
hand, alerts from a real system contain a wealthy amount
of background noise, which is challenging for the correlation
methods and might be diﬃcult to simulate. The data is the
same that was used in [17], and the main motivation for this
work was the shortcomings of the model used in that paper
with certain types of alert ﬂows. These shortcomings are
discussed in more detail in section 6.
The data was accumulated over 42 days, and contained
over 500k alerts. The sensors had the default set of signa-
tures activated, at that time approximately 2000 signatures
plus some additional custom signatures. 315 signatures had
triggered alerts, and only ﬁve had generated 68% of the to-
tal number of alerts. Table 1 shows these ﬁve signatures
with their Snort IDs (SID) and the number of alerts gen-
erated by them. All these ﬁve react on packets, that can
be generated by normal system functioning. Therefore we
consider it worthwhile to focus on processing this type of
alerts. This reasoning may be speciﬁc to the information
system in question. However, the reported examples, such
as in [8] would suggest that this could apply also to a wider
range of information systems.
4.1 Proﬁling alert ﬂows
While investigating collected alerts, this corpus and gen-
erally, we have identiﬁed four ﬂow proﬁles for alerts gener-
ated by proliﬁc signatures. Proﬁles are deﬁned according to
their regularity and our capability to explain seen behavior,
normal or anomalous.
A Known, constant: The alert generation is almost con-
stant. The ﬂow has relatively few anomalies that we
can explain and attribute to 1) change in the interac-
tion conﬁguration 2) a problem.
B Known, periodic: The alert ﬂow contains clearly vis-
ible periodicity and possibly a constant component
with a benign origin. The ﬂow contains some anoma-
lies, of which we can explain a majority.
C Unknown, periodic: The alert ﬂow is less stable than
in class B, it has more anomalies visible and we do not
know how to explain them.
D Unknown, random-like: The ﬂow seems to be more or
less random, only very little or no structure is visible
with plain eye. We have only limited explanations for
the origins of these alerts.
The regularity and explicability span two axes, and the
placement of classes with respect to them is depicted in
Fig. 1. None of these four classes falls into the second quad-
rant, as those alerts are usually associated with a vulnera-
bility, and are either true manifestations of attacks or false
positives. Most correlation work focuses on processing this
type of alerts via techniques like alert fusion, veriﬁcation,
and ﬁnding the prerequisites and the consequences among
them. In the ﬁrst quadrant we have two diﬀerent classes,
A and B. The reason in having two separate classes is the
the diﬀerent type of regularity, constant and periodic, of
the classes A and B, respectively. Packets causing constant
alert ﬂows have typically machine related origins given their
clock-like behavior, whereas humane activity can create pe-
riodic behavior. For example, if the network traﬃc trig-
gering the alerts is created by actions of a large number of
persons, natural rhythms with period of one day or week are
likely to exist in the alert ﬂows.
4.2 Alert ﬂow analysis
Now let’s have a closer look at the ﬁve signatures and the
alert ﬂows they generated. For each, we give a short de-
scription, enumerate the identiﬁed interesting phenomena,
and provide explanations for the phenomena when we have
them. Actual signature documentation can be found on the
Snort web site2 with the Snort ID. Figure 2 shows the alert
intensities as the function of time for the measurement pe-
riod. Dotted lines show the division to estimation and vali-
dation data, as will be explained in section 6.
2
explicable
1
A
B
high
regularity
C
non
explicable
4
low
regularity
D
3
Figure 1: The alert classes with respect to the two
axes, regularity and explicability
2http://www.snort.org
0
SNMP Request UDP reacts to Simple Network Man-
agement Protocol (SNMP) request from external sources to-
wards internal hosts.
As the source address is external, the request messages are
likely caused by a misconﬁguration outside the operator’s
control. The alert ﬂow is extremely regular, as can be seen
in Fig 2(a), with few peaks and valleys plus some smaller
In this case, there were few particular source
anomalies.
addresses responsible for the large bulk of alerts i.e.
the
root causes were identiﬁed, and alerts generated by those
nodes could have been ﬁltered out. However, in that case
the operator would have also missed the sharp change in the
alert intensity marked with p1.
We identiﬁed ﬁve interesting phenomena in the ﬂow. The