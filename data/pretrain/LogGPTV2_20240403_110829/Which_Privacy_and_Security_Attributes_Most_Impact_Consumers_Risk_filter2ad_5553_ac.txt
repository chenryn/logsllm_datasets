TABLE I: The 16 security and privacy attributes along with the values of
each attribute tested. The attributes are grouped here according to the layers
proposed in [13]. Note that the attribute “control over” is on both layers.
Attribute “average time to patch” was not included in the proposed label. Due
to the importance of security patches, we hypothesized that this attribute might
be appropriate for the secondary layer.
To evaluate participants’ attention and understanding of
the presented label information, we tested participants on the
speciﬁc privacy and security information they were asked about
with a multiple-choice question. For example, if the presented
attribute-value was security audit: none, we asked “Which
statement is correct about the device described in the previous
question?” and provided three incorrect answers alongside the
correct answer “The manufacturer does not conduct security
audits on its devices and services.” We designed these questions
to be answerable with only the information we provided in the
consumer explanation, e.g., in this example, without knowing
anything about the implications of security audits.
8) Perceived Device Functionality: To understand how
participants perceived the device data collection, we asked them
whether they believed the device is always sensing, sensing
only when it is triggered (e.g., by mentioning the wake word
or by someone turning on the light), sensing only when a user
pushes a physical button on the device, or they do not know
(see Appendix B-C).
9) Demographic Questions: We asked general demographic
questions to capture participants’ age, gender, highest degree
earned, and background in technology (see Appendix B-D).
B. Data Analysis
Our study used a repeated-measures design in which partici-
pants were presented with multiple scenarios with the same type
of questions. This design results in multiple observations for
each participant that are not completely independent. Therefore,
we used a statistical method that allows us to use random
effects to account for these dependencies. To quantitatively
measure the signiﬁcance of our independent variables, we used
Cumulative Link Mixed Models (CLMMs) with logit as the
link function. This allowed us to model all ﬁve levels of our
ordinal Likert scale responses for our dependent variables (risk
perception and willingness to purchase) rather than having to
bin them into two levels as required by logistic regression [68].
We used a signiﬁcance threshold of 0.05.
We used content analysis [69] to ﬁnd the reasons participants’
risk perception and willingness to purchase were impacted
or not impacted by privacy and security information. The
ﬁrst author constructed a codebook used to analyze free-text
responses. The ﬁrst author and another researcher independently
applied the codebook to the responses and through several
meetings, iteratively revised the codebook. After discussing
the coding discrepancies and resolving major disagreements,
we reached a Cohen’s Kappa inter-coder agreement of 81%,
which is considered excellent [70]. In case of unresolved
disagreements, we report on the ﬁndings of the ﬁrst author.
C. Limitations
We tested the impact of privacy and security attributes on
participants’ self-reported risk perception and willingness to
purchase. While these measures have been shown to strongly
correlate with actual behavior [27]–[30], [71], they are not
a complete substitute for a study that observes real purchase
scenarios. We expect that our approach likely exaggerates the
effect that each attribute-value has on risk perception and
willingness to purchase, as these attribute-values will compete
with each other for a consumer’s attention in a real purchase
scenario. Thus, in a more realistic study we would expect
attribute-value pairs that exhibited a minor effect in our study
to exhibit little or no effect.
We designed our study so that we could measure the
effectiveness of each privacy and security attribute-value pair in
isolation. This allowed us to study the impact of each attribute
in order to prioritize the information that is included on an
IoT label as well as to identify misconceptions associated
with individual attributes. However, a full privacy and security
label would include more than one attribute. Further testing is
needed to explore the nuances in consumers’ risk perception
and willingness to purchase when presented with a complete
IoT privacy and security label. Again, we expect that the effect
of each individual attribute will be muted when presented in
the context of a complete label. However, interaction effects
may also emerge.
We evaluated the importance of a limited number of factors
in describing risk perception and willingness to purchase. For
instance, we tested only two types of IoT devices, three types
of recipients, and two extreme values for the tested security and
privacy attributes. It would be useful to also test other levels
of these factors, for example, gifting a device to a child who
is being protected by Children’s Online Privacy Protection Act
(COPPA). It would also be useful to test the common values of
privacy and security attributes that fall in between the extremes,
e.g., default passwords and user-changeable passwords rather
than just no passwords and multi-factor authentication.
Our survey questions might have primed participants to
think about privacy, security, and risks more than they would
in realistic purchase scenarios. However, as participants were
equally primed in all conditions, we expect little impact on
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:26:35 UTC from IEEE Xplore.  Restrictions apply. 
522
the relative risk and desire to purchase for each attribute-value
and the relative ordering between them.
Our methodology and regression analysis capture the impact
of each attribute-value pair in isolation. However, as multiple
attribute-value pairs were presented to each participant, inter-
action effects among these factors may exist that we did not
investigate.
We provided a plain-language consumer explanation for each
privacy and security attribute-value pair to help participants
understand what they mean. To assess participants’ attention
to the provided explanations, we asked an attention-check
question and asked participants about their level of conﬁdence
in understanding the attribute-values. However, we did not
test participants on their knowledge related to the privacy
and security implication of each attribute-value pair and thus
have no quantitative assessment of whether participants’ level
of conﬁdence in their knowledge correlates with their actual
understanding. However, our qualitative analysis of open-ended
responses indicated that participants did not seem to ﬁnd the
attribute-value pairs confusing. Even so, as we will discuss
in Section IV-E, we found some misconceptions about the
implications of a few privacy and security attribute-value pairs.
More detailed knowledge questions are needed to fully assess
participants’ understanding of each attribute-value pair.
Finally, we recruited participants from MTurk who reside
in the US. Residents of other countries likely have different
perspectives on privacy and security risk and willingness to
purchase IoT devices. Furthermore, our participants are not
completely representative of the US population. For instance, as
shown in Table IV in Appendix D, our participants were slightly
more educated and younger than the general US population.
Past studies have found that, even when controlling for these
demographic factors, MTurk workers may have heightened
privacy concerns compared with the US population [72].
IV. RESULTS
We ﬁrst describe our participants and present summary
statistics. Next we present our statistical models of risk
perception and willingness to purchase. Finally, we provide
insights from our qualitative analysis of participants’ responses.
A. Participants and Study Conditions
We initially recruited 1,710 MTurk participants and excluded
those whose answers for all our open-ended questions were
irrelevant. This resulted in 1,371 participants who are included
in our analysis. All of these participants answered at least two
out of their three attention-check questions correctly. Overall,
at least 90% of participants correctly answered the attention-
check questions for all but two of the 33 attribute-value pairs,
indicating that participants were paying attention to the label
information we presented to them. The two attribute-value pairs
with the most wrong answers were: security audit: internal
& external (22% incorrect), and control over: device storage
(21% incorrect).
We randomly assigned each participant to one out of six
study conditions (based on two device types and three device
recipients). Each participant was asked to answer questions
related to three random attribute-value pairs for the condition
they were assigned to. There were between 224 and 233
participants per condition and between 119 and 132 participants
per attribute-value pair.
Our participants were 54% male and 45.5% female. Com-
pared to the 2018 US Census data [73], participants were
younger and better educated. Participant demographic informa-
tion is provided in Appendix D.
B. Summary Statistics
1) Concern Level: We found a strong correlation between
the device type (smart speaker, smart light bulb) and the
level of concern with the type of device (binary variable1),
χ2(1,N = 1371) = 189.14, p < 0.001,φ = 0.37 [74]. 62%
of the participants who were assigned to the smart light
bulb conditions reported being concerned, mainly due to the
unforeseeable consequences of their data being accessed by
unauthorized parties. In the smart speaker conditions, 93%
reported being concerned about these devices. Most participants
mentioned that they are concerned about smart speakers always
listening to them. The difference in participants’ level of
concern for the smart speaker and smart light bulb is consistent
with our hypothesis, as well as past ﬁndings [5], [26], [61].
2) Purchase History: 54% of participants reported having
a smart speaker in their home, and among those, 53% had
purchased the device themselves. Only 12% of participants
reported having a smart light bulb, and 61% of those reported
that they had purchased it themselves.
Among those who did not have the smart device in question,
23% reported that they had been in the market to purchase it
earlier. The main reasons stated for not going through with the
purchase were their price (30% for the smart speaker and 48%
for the smart light bulb) and lack of necessity (44% and 34%,
respectively). Privacy and security concerns were also reported
by 26% and 9% of participants as reasons not to purchase the
smart speaker and the smart light bulb, respectively.
3) Conﬁdence Level in Understanding Label Information:
More than 70% of participants reported being somewhat,
moderately, or very conﬁdent about knowing what the label
information meant for all but two attributes. Participants’ level
of conﬁdence was signiﬁcantly lower (p-value < 0.05) for
security audit and data linkage.2
C. Device Functionality Perception
We found that most participants have a correct understanding
about how the smart device in their study condition works. In
the smart light bulb condition, 72% of participants believed
that the light bulb always senses whether someone is present in
the room, 12% reported not being sure how the device works,
10% believed that the device starts sensing when a button on
the device is pushed, and 6% thought that the smart light bulb
1We coded “not at all concerned” as 0 and “only slightly concerned,”
“somewhat concerned,” “moderately concerned,” and “very concerned” as 1.
2We constructed a CLMM to model the impact of attribute-value on the
level of conﬁdence.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:26:35 UTC from IEEE Xplore.  Restrictions apply. 
523
starts sensing when triggered by someone’s presence in the
room. In the smart speaker condition, we found that 53% of
participants had a belief that the device waits for the user to
mention the wake word (e.g., “Alexa”, “OK Google”), 39%
thought that the device is always sensing, 4% reported not
knowing how the smart speaker works, and 4% believed that
the device starts listening when the user presses a button to
turn on the device microphone.
D. Risk Perception and Willingness-to-Purchase Models
We were interested in understanding the impact of various
factors on two dependent variables (DVs): participants’ risk
perception and willingness to purchase the smart device. We
built two Cumulative Link Mixed Models (CLMMs) to describe
our DVs. The factors we included in each model are as follows:3
• sp_attribute_value: 33 security/privacy attribute-
value pairs (see Table I). Among these 33 attribute-
value pairs, only three of them were randomly selected
and presented to each participant, while the rest of the
attributes were absent, i.e., not shown to the participant.
• prior_scenarios: Number of prior scenarios seen by
that participant, with three levels: 0, 1, and 2 scenarios.
• device_exposure: How much exposure participants
have to the smart device, with three levels: “Not having
the device,” “purchased the device” (owned the device and
purchased it themselves), and “didn’t purchase the device”
(owned the device, but did not purchase it themselves).
• device_type: Type of the device, with two levels:
Smart speaker and smart light bulb.
• device_recipient: Who the device is being pur-
chased for, with three levels: Yourself, friend, and family.
Our dataset included three scenarios from each of the 1,371
participants for a total of N = 4,113 observations. We asked
participants to specify, on a Likert scale, the impact of each
presented attribute-value pair on risk perception and willingness
to purchase (see Appendices B-B1 and B-B2), leading to J = 5
ordinal response categories. We modeled risk perception and
willingness to purchase by ﬁtting two CLMMs to the data. In
these CLMMs, we included a random intercept per participant
to take the natural and inherent variations among different
participants into account. In each model, the probability that
the ith observation, i ∈ {1, . . . ,N}, falls in the jth response
category or below, j ∈ {1, . . . ,J − 1}, is modeled as
logit(Pr(Yi ≤ j)) = α j| j+1 − uparticipanti
− βsp_attribute_valuei
− βprior_scenariosi − βdevice_exposurei
− βdevice_typei − βdevice_recipienti, (1)
3We also initially included the demographic information (see Appendix D)
and the type of prior privacy and security attribute-value, but we found
their impact to be insigniﬁcant in both models. Therefore, we decided to
remove them from our ﬁnal models to better ﬁt the data (according to Akaike
Information Criterion (AIC), which we used to assess the model goodness
of ﬁt [75]). Except for demographic factors as well as the prior privacy and
security attribute-value, removing other factors from the models resulted in
a decline in model ﬁt. Therefore, we did not remove any of the remaining