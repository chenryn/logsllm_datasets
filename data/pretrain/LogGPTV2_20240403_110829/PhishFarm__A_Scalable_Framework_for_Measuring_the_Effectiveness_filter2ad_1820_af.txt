[43] “SmartScreen:
Report
a Website.”
[Online].
Available:
https://feedback.smartscreen.microsoft.com/feedback.aspx?t=0url=
[44] “ESET:
Report
a
Phishing
Page.”
[Online].
Available:
http://phishing.eset.com/report/
[45] “NetCraft: Report
a
Phishing URL.”
[Online]. Available:
http://toolbar.netcraft.com/report url
(cid:18)(cid:20)(cid:22)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:45 UTC from IEEE Xplore.  Restrictions apply. 
[46] “McAfee: Custom URL ticketing System.”
[Online]. Available:
”https://www.trustedsource.org/en/feedback/url?action=checksingle
[47] “Digitalocean: Cloud computing,
simplicity at
scale.”
[Online].
Available: https://www.digitalocean.com/
[48] T. Moore and R. Clayton, “Examining the impact of website take-down
on phishing,” in Proceedings of the anti-phishing working groups 2nd
annual eCrime researchers summit. ACM, 2007, pp. 1–13.
[49] S. Garera, N. Provos, M. Chew, and A. D. Rubin, “A framework for
detection and measurement of phishing attacks,” in Proceedings of the
2007 ACM Workshop on Recurring Malcode, ser. WORM ’07, pp. 1–8.
[50] J. Cohen, “Statistical power analysis for the behavioral sciences.” 1988.
[51] E. Lewis, “The role of wildcards in the domain name system,” United
States, 2006.
[52] K. Ravishankar, B. Prasad, S. Gupta, and K. K. Biswas, “Dominant color
region based indexing for cbir,” in Image Analysis and Processing, 1999.
IEEE, 1999, pp. 887–892.
Proceedings. International Conference on.
[53] “Overview — safe browsing apis (v4) — google developers.” [Online].
Available: https://developers.google.com/safe-browsing/v4/
[54] D. G. Dobolyi and A. Abbasi, “Phishmonger: A free and open source
public archive of real-world phishing websites,” in Intelligence and
Security Informatics, 2016 IEEE Conference on, pp. 31–36.
[55] T. Moore, R. Clayton, and H. Stern, “Temporal correlations between
spam and phishing websites.” in LEET, 2009.
[56] T. Moore and R. Clayton, “How hard can it be to measure phishing?”
Mapping and Measuring Cybercrime, 2010.
Phish-
browser
2016.
methodology
https://research.nsslabs.com/reports/free-
[57] NSS
ing
[Online].
90/ﬁles/TestMethodology WebB/Page4
“Web
test
Available:
Labs,
protection
security:
v3.0,”
[58] C. Ludl, S. McAllister, E. Kirda, e. H. B. Kruegel, Christopher, and
R. Sommer, “On the effectiveness of techniques to detect phishing sites,”
in Detection of Intrusions and Malware, and Vulnerability Assessment.
Berlin, Heidelberg: Springer Berlin Heidelberg, 2007, pp. 20–39.
Jul
APPENDIX I: FULL TEST PER-ENTITY BLACKLISTING
Each entity we tested exhibited a characteristic blacklisting
behavior with respect to the different cloaking techniques; the
aggregate view of ﬁlter performance in Figure 3 masks some of
these characteristics. Figure 4 includes similar charts for each
individual entity as a supplement to Figure 3 and the entity
scores in Table VI. Each chart shows detailed blacklisting
performance over time, aggregated for all browsers, for each
ﬁlter type.
(a) GSB
(b) SmartScreen
(c) APWG
(d) PhishTank
(e) PayPal
Fig. 4: Blacklisting over time by ﬁlter (full tests).
(cid:18)(cid:20)(cid:22)(cid:26)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:45 UTC from IEEE Xplore.  Restrictions apply. 
(a) By ﬁlter (re-tested entities only)
(b) By URL type (all entities)
(c) By browser (all entities)
Fig. 5: Blacklisting over time (preliminary tests).
APPENDIX II: PRELIMINARY TEST DATA
Table VIII includes detailed performance scores for all
entities in the preliminary tests. These scores are based on the
formulas in Section V-B and are the basis of our comparative
discussion in Section V-C. We visualize the preliminary test
performance of only the subsequently re-tested entities (GSB,
SmartScreen, AWPG, PhishTank, and PayPal) in Figure 5a.
Figure 5b illustrates the increased likelihood of URLs with
a deceptive domain (Type IV [8], [49]) to be blacklisted during
the preliminary tests. As previously discussed, this increase is
linked to heuristics used by SmartScreen browsers; the positive
effect that this had on IE and Edge blacklisting can be seen in
the browser performance breakdown in Figure 5c. The latter
two charts are based on data from all 10 preliminary tests.
TABLE VIII: Aggregate entity blacklisting performance scores
in the preliminary tests.
GSB
Sbf
GSB
IE
Edge
Opera
P Bf
T Bf
SmartScreen
GSB
IE
Edge
Opera
Sbf
P Bf
T Bf
APWG
Sbf
GSB
IE
Edge
Opera
P Bf
T Bf
PhishTank
GSB
IE
Edge
Opera
Sbf
P Bf
T Bf
PayPal
Sbf
GSB
IE
Edge
Opera
P Bf
T Bf
ESET
Sbf
GSB
IE
Edge
Opera
P Bf
T Bf
WebSense
Sbf
GSB
IE
Edge
Opera
P Bf
T Bf
Netcraft
Sbf
GSB
IE
Edge
Opera
P Bf
T Bf
US CERT
GSB
IE
Edge
Opera
Sbf
P Bf
T Bf
McAfee
Sbf
GSB
IE
Edge
Opera
P Bf
T Bf
Filter A
0.988
0
0.950
0.138
1.000
38
Filter A
0
0
0.956
0
1.000
10
Filter A
0.648
0.255
0.958
0.345
1.000
73
Filter A
0.971
0.314
0.771
0.112
1.000
95
Filter A
0.637
0.345
0.213
0.102
1.000
121
Filter A
0.297
0
0.256
0.137
0.333
444
Filter A
0
0
0
0
0
444
Filter A
0
0.166
0.389
0.302
0.667
531
Filter A
0
0
0
0
0
N/A
Filter A
0
0.167
0.939
0
1
134
Filter B
0
0.142
0.130
0
1.000
10
Filter B
0
0.142
0
0
0.143
10
Filter B
0
0.432
0.142
0
1.000
286
Filter B
0.141
0
0
0.123
0.286
309
Filter B
0
0.517
0
0
1.000
181
Filter B
0
0
0
0
0
N/A
Filter B
0
0
0
0
0
N/A
Filter B
0.135
0
0
0.260
0.429
334
Filter B
0
0.127
0.127
0
0.143
28
Filter B
0
0.127
0
0
0.143
466
Filter C
0
0
0
0
0
N/A
Filter C
0
0.284
0
0
0.286
14
Filter C
0
0.306
0.137
0
1.000
199
Filter C
0.261
0
0
0
0.286
344
Filter C
0.276
0.448
0
0.253
1.000
128
Filter C
0
0
0
0
0
N/A
Filter C
0
0.142
0.128
0
0.143
4
Filter C
0
0.142
0.129
0.130
0.182
206
Filter C
0.139
0.142
0.127
0
0.286
70
Filter C
0
0.143
0
0
0.143
3702
Filter D
0.846
0
0.709
0.236
0.857
43
Filter D
0
0.142
0
0
0.143
18
Filter D
0.141
0.306
0
0
0.857
154
Filter D
0
0
0.124
0
0.125
3784
Filter D
0
0.306
0.173
0
1.000
179
Filter D
0
0
0
0