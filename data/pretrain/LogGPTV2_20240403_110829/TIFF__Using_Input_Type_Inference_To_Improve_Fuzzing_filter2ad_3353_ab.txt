In Listing 1, the ifd_offset field of struct header indi-
cates the start in the file of the image file descriptor (IFD) structures.
Each I F D structure contains a value that indicates the number of tags
present, a list of tags and, optionally, the offset of the next I F D. On
line 20, the function uses the number of tags to determine the amount
of memory to allocate for the 12-byte tag structures. Unfortunately,
the alloc_sz value can easily overflow if the corresponding byte
value is more than 5460. The result is that the buffer overflows when
the program tries to copy data in the buffer on line 24 (e.g., causing
a segmentation fault).
1 typedef
2
3
4
u i n t 1 6 _ t n o _ e n t r i e s ;
t a g * t a g l i s t ;
/ * p o i n t e r
i n t 3 2 _ t n e x t _ i f d _ o f f s e t ;
t o 12− b y t e t a g s t r u c t u r e * /
s t r u c t
i f d {
byte orderVersion numberFirst IFD OffsetIFHImage File HeaderIFDImage File DirectoryTag entry countTag 0Tag nTag 1next IFD offsetImage Data 0Tag entry countTag 0Tag nTag 1next IFD offsetImage Data n----507ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Vivek Jain, Sanjay Rawat, Cristiano Giuffrida, and Herbert Bos
presence of magic-bytes, markers are widely prevalent in binary
input formats. TIFF also computes the types of such offsets by
performing a separate analysis for type inference (Section 4) and
accordingly associates type tags (such as INT8, INT16, UINT32
and char*) with these offsets.
Besides control offsets, TIFF performs the type inference techni-
que (Section 4) to associate a type tag with other offsets of the
input. We refer to them as data offset types. Currently, TIFF associa-
tes INT8, INT16, INT32 and array/struct types to data
offsets.
3.3 Type Based Mutation
This is the main step that is responsible for mutating inputs towards
high code-coverage and bug detection. For a given input, TIFF first
considers the control offset types. It mutates the corresponding off-
sets either with the invariants learned for these offsets, or according
to the type tag associated with this offset, in case there is no invari-
ant associated with these offsets. Both options improve the fuzzer’s
code coverage. Next, TIFF considers the data-offset types for non
control offsets of the input. Here, it performs type-based mutation
selectively—on selected inputs that cover a new path only. The intui-
tion is that by focusing on data-offsets, we explore bugs that may lie
in this execution path. TIFF’ s mutation strategy differs depending
on the type of the input bytes. Specifically, for offsets of type INTx,
TIFF finds unusual (e.g., extreme values for a given integer type)
values based on the size x and places those values at those offsets.
This type of mutation mainly targets integer-overflows bugs and (to
a lesser extent) heap-overflow bugs. For offsets of type array, TIFF
inserts data (based on the array element type) of arbitrary length.
This type of mutation mainly targets buffer-overflow
INPUT TYPE INFERENCE
4
In the literature, there exist several type inference techniques, each
with their own strengths and weaknesses [11, 16, 32, 33, 38, 45].
Given the nature of our application, fuzzing, we want an algorithm
that is fast enough to work on multiple inputs, while providing type
information that is sufficiently precise for our task. Unlike other
application domains (such as binary rewriting [46]), fuzzing can
suffer some imprecision in type identification as misclassifications
merely lead to a reduction in fuzzing efficiency. For this purpose, we
developed a custom technique that, as we shall see, builds on Tupni’s
input format inference [16], Howard’s data structure extraction based
on memory accesses [45], and REWARD’s data structure identifica-
tion based on known API calls [32], but addresses key challenges
when complementing such techniques in a unified, practical type
identification system to boost fuzzing.
4.1
In-memory Data Structure Identification for
Input Offsets
As mentioned earlier, to mutate more effectively, we need to learn
the type system on the input. As TIFF mainly needs to cater to binary
input formats (TIFF focuses on applications that consume binary
files), techniques for learning grammars may not work well [19].
Binary files are often organized as arrays of data types such as
long and short integers, chars and strings. Our goal, therefore, is
to learn this type system automatically. More precisely we want to
Figure 2: High-level overview of TIFF. Each solid block repre-
sents a different component, while each dashed box represents
a different high-level functionality of the fuzzer.
we mutate the data at those offsets according to their types. In the
next sections, we provide details on our proposed technique.
3 OVERVIEW
TIFF is based on the concept of evolutionary fuzzing and a full
fuzzing cycle therefore consists of a sequence of steps. The cycle
begins with executing the application on a set of inputs. From the
execution traces, evolutionary fuzzers may extract interesting in-
formation about the program. In our case, for instance, we extract
information about the flow and types of data. Fuzzers then determine
the fitness of the inputs using a fuzzer-specific criteria, and select
the fittest inputs as promising starting points for the next generation.
Subsequently, they will mutate the promising inputs, for instance
by flipping bits or inserting bytes. A key advantage of TIFF is that
it will do the mutation on the most promising bytes as sensibly as
possible—taking into consideration collected properties such as type
information. Fig. 2 presents the main components of TIFF as well as
the interaction among them. The dashed boxes indicate the division
of tasks which we now explain in turn.
Input Execution and Fitness Function
3.1
As a mutation-based fuzzer, TIFF needs a set of seed inputs to
start fuzzing. The application executes these inputs and produces
an execution trace. In the current implementation, TIFF monitors
basic-blocks and their execution frequency and calculates the fitness
of an input on the basis of the executed basic-blocks. Any input that
executes a new basic block is considered for further mutation.
3.2 DTA and Input Type Inference
Dynamic taint analysis (DTA) plays a central role in determining
several interesting properties of the input. To maximize the code-
coverage and bug detection, TIFF derives two classes of features:
control offset types and data offset types
Control offsets indicate the bytes in the input that influence the
operands in cmp instructions and determine the outcome of branch
instructions. Note that like VUzzer, TIFF also performs DTA while
executing an input to find cmp instructions whose operands are
tainted by some offsets of the input. Such offsets are interesting
targets for mutation to change the execution path of the application.
TIFF further analyzes this information to infer invariants that the
application expects from the input. These invariants, such as the
LoopInputsExecutionTracecrashreportfitnessfunctioninput selectionDTAType Inferencecontrol offsettype detectiondata offsettype detectionType basedmutationEvolutionaryInput Execution & Fitness FunctionInput Type InferenceType based Mutation508TIFF: Using Input Type Inference To Improve Fuzzing
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
1
2
3
4
5
6
7
understand how the application processes each offset of the input.
We identify the following two categories of data types associated
with input offsets: (i)- individual nbytes values (e.g., 1byte, 2byte,
4byte, etc.), (ii) composite bytes (i.e., a set of offsets which are
processed as an array or struct).
Our in-memory DSI step consists of three components: basic
data type identification, composite data type (e.g., array) detection
and, precise detection of certain data types such as char*, int, etc.
For a given input i, the outcome of this step is a mapping ψ :
i[] → T , where i[] is a set of all offsets of the input i and T =
[I NT 8, I NT 16, I NT 32, array/struct]. T denotes the types that are
recognized by TIFF. To explain with an example, if we get ψ(i(2)) =
I NT 8, it means that the 3rd offset of the input i is of type I NT 8. To
support such type detection, TIFF employs a DTA engine to monitor
the flow of tainted inputs within the application.
DTA determines, during program execution, which memory loca-
tions and registers are dependent on tainted input bytes. Based on
the granularity, DTA then traces back the tainted values to individual
offsets in the input. Our DTA framework is based on LibDFT [28].
4.2 Basic Data Type Identification
Using Tupni’s technique of input format inference [16], we identify
types associated with (a set of) offsets in the input, based on the
observation that an application processes offsets almost exclusively
based on their type information. In other words, it processes a 4-byte
data item in the input (which could be of type INT32) as a chunk of
4 bytes in the application logic.
In short, Tupni’s algorithms works as follows: we partition the
input into short sequences of consecutive bytes and monitor the
application to know how instructions are accessing the tainted by-
tes. For example, consider an add instruction such as add reg32,
[addr] where [addr+0, addr+1, addr+2, addr+3] are
tainted by file offsets 0, 1, 2, and 3 respectively. In this case, we
classify the 0th byte as a chunk of size 4. We also assign a weight to
each chunk where the weight indicates how many times that chunk
has been accessed. We notice that the chunks may not always be
disjoint. For all pairs of intersecting chunks, we retain the chunk
with the higher weight.
4.3 Array Detection
For composite data types such as arrays and structs, we use Howard’s
in-memory array detection [45]. We choose Howard’s array detection
technique, as it is more precise and overcomes most of the limitations
of other techniques (such as those of Tupni which draw inspiration
from Polyglot [11]). Howard is a dynamic analysis technique to
recover data structures present in a binary.
Howard first identifies root pointers that are not derived from
any other pointers. It then identifies base pointers dynamically by
tracking the way in which the program derives new pointers from
existing ones, and how it dereferences them.
On top of Howard’s techniques, we associate another tag with
each memory address and general purpose register to record whether
the addresses/registers are tainted by any offset of the input. Thus,
whenever Howard detects an array, we check whether the memory
in the array is tainted by offsets of the input, thereby recovering
all the offsets of the input which the application processes as an
array. We observed that in some cases, because of the limitations
of Howard, some memory locations which are part of an array, are
not recovered as tainted. We apply heuristics to solve these cases. A
typical example is given below:
l e n ;
/ * t o t a l
i d e n t i f i e r [ ] ;
s t r u c t h e a d e r {
i n t
char
} * e l e m e n t ;
/ *
f o r ( i n t
i = 0 ;
p r i n t f ( "%02x " ,
. . .
a s s i g n some v a l u e t o e l e m e n t
* /
l e n g t h o f
s t r u c t * /
i  l e n ;
( ( unsigned char * ) e l e m e n t ) [ i ] ) ;
. . .
i ++)
Listing 2: A problematic case for array element detection in
Howard [45]
While not common, a program may access array elements with
respect to the start of a struct rather than the start of the array.
Listing 2 shows an example. In this case, Howard also classifies
len as an element of the array identifier. To filter such cases,
we verify if the difference in the addresses of successive memory
locations of the array remains constant. For example, let’s say integer
len in line 2 has address a1. In that case, the array elements in line 3
will have addresses a1 + 4, a1 + 5, a1 + 6 etc. We now eliminate len
from being an element of the array since the difference in the address
of len and that of the first array elements is not consistent with the
difference between the addresses of the other array elements. Clearly,
this is not a very strong heuristic and it would would fail in cases
where the types are the same, but this is good enough in practice;
fuzzing can easily tolerate some imprecision in type inference. We
provide few more finer details of our engineering efforts on top of
Howard’s original implementation in Appendix 9.2.
4.4 Precise Data Type Identification
Finally, we also use a limited version of REWARD [32] to identify
more precise data types, such as size_t (unsigned int),
char*, etc. We achieve this by hooking libc library calls for which
we have detailed type information for the arguments. For exam-
ple, for library calls strcpy or strcmp, we know that the argu-
ments are of type char*. Thus, using our dynamic taint analy-
sis we check if the arguments of such library calls are tainted by
any offset in the input. Additionally, for some of the string com-
parison APIs such as strcmp, strncmp, memcmp, we also re-
cord the input offsets, as well as the bytes to which they are com-
pared. We use these offsets and bytes later in our mutation stra-
tegy to increase coverage. For the current implementation of TIFF,
we hook 17 library calls from libc (for example, inferring char
* from strlen, strnlen, strdup, memchr, ... and
size_t from malloc, strndup, memcpy, memchr,...).
5 TYPE INFERENCE-ASSISTED MUTATION
After obtaining the type information for the input in the form of the
mapping ψ defined in Section 4.1, TIFF uses it to mutate inputs to
achieve the goal of high code coverage and early bug detection1.
Specifically, since we know the data type of the input offsets, we can
mutate these offsets more meaningfully. In the following, we discuss
1Thanks to the input type inference assisted value selection for mutation, keeping a
particular type of memory corruption bug in mind
509ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Vivek Jain, Sanjay Rawat, Cristiano Giuffrida, and Herbert Bos
how our mutation strategy helps achieving the goals of coverage-
oriented and bug-oriented mutation. An algorithmic description is
provided in Appendix 9.1.
5.1 Coverage-oriented Mutation
TIFF achieves our goal of high code-coverage by taking advantage of
the type of offsets that correspond to the operands of cmp instructi-
ons. Although a solution such as VUzzer also detects the offsets of
cmp instructions, it is unaware of the data type of these cmp offsets.
As a result, it wastes a considerable amount of its mutation effort
on mutating at such offsets with arbitrary values. For example, if
the offset used in a cmp instruction is of type INT8 (i.e., a byte),
we have 28 different values to choose from for mutation. However,
VUzzer commonly tries to mutate it (and surrounding offsets) by in-
terpreting it as part of a INT32 type, using values from the set of 232
possible integers. In case of TIFF, if the offset 0 is of type INT32,
TIFF would mutate these 4 bytes together, instead of mutating only
a single byte.
We also improve code coverage by replacing the input bytes at an
offset with the bytes which we have recorded by hooking the string-
compare family of library functions. For example, for a function
call with memcmp("II*", a) (as in our motivating example
in Section 2), where a is tainted by offset 0 during execution on
all the mutated inputs, we replace the bytes at offset 0 with the
string "II*". These features of TIFF in generating valid inputs
are more effective than those in existing fuzzers such as VUzzer
because in some cases VUzzer will miss these strings. For example,
in Listing 3 VUzzer was unable to get the byte % for offset 0 of the
file in cmp.out. When we further analyzed the issue, we observed
that internally, in the assembly of memcmp, if the string that is
compared has a size of 5 bytes, the first byte value is first taken into
a register and then that value is subtracted from the tainted value. If
the subtracted value is 0 (i.e., they are equal), it takes a jump to the
true branch (i.e., to a basic block that does another cmp with the rest
of the 4 bytes). Otherwise, it jumps to the false branch. Thus, since
there is no cmp for the first byte, VUzzer misses the magic byte
altogether. In contrast, because of TIFF’s hooking and recording of
such tainted library functions, it is able to detect these bytes precisely
and generate valid inputs accordingly.
(memcmp( buf , "%PDF−" , 5 ) ==0)
1 i f
2 do_something ( ) ;
/ / buf
t a i n t e d by o f f s e t s 0−5
Listing 3: Comparing bytes with memcmp. Missed when monitoring
cmp only
5.2 Bug-oriented Mutation
This type of mutation mainly targets the offsets of type data offsets.
In other words, while selecting the offsets for mutating the input to
generate next input, we consider offsets of a particular data type, al-
ong with the offsets that are used in any control-flow decision. In the
current implementation, we specifically increase the probability of
detecting two classes of memory corruption bugs: integer overflows
and buffer overflows. Integer overflow bugs occur when an integer
exceeds its maximum value or in the case of bad casting between
the types of the variables involved in some assignment, such as the
interpretation of a signed variable as an unsigned one. Buffer
overflow bugs occur when the amount of data copied into a memory
buffer exceeds its size.
To increase the probability of integer overflow bugs, TIFF perio-
dically chooses an input that contains the highest number of offsets
with type INTx. The period is a (configurable) parameter n whose
value can be configured on the basis of the size of the seed inputs.
In our experiments, we found n = 10 to be a good value for binary
inputs. For the chosen input, when the fuzzer encounters offsets with
types such as INT16 or INT32, it will modify them using interes-
ting integer values—for example, the values used by AFL [52].
Similarly, to increase the probability of triggering buffer overflow
bugs, we choose the input which has the highest number of offsets
associated with type array and then try to increase the size of these
arrays by inserting byte strings of some arbitrarily chosen length.
The place where we add the additional sequence of bytes is chosen
randomly between the array starting offset and ending offset.
For efficiency, we run these bug-oriented inputs without any mo-
nitoring or instrumentation. In other words, we do not calculate the
fitness value for these inputs. If any of such input results in a crash,
we consider the input for mutation in the following generations to
produce more inputs. This strategy is an optimization to increase the
input execution rate in a given period of time. This optimization is
based on the observation that, as the number of data offsets is much
higher than that of control offsets, we end up mutating mainly data
offsets, thereby reducing the likelihood of executing a new path. Ho-
wever, it should be noted that for jump table-based implementations
that depend on some non-control tainted input bytes, we may neglect
inputs that trigger newer paths on such jumps. But, as noted in [15],
common jump table implementations do rely on cmp instructions
and, if so, our mutation strategy is unaffected.
IMPLEMENTATION
6
This section begins with a discussion of the implementation aspects
of TIFF. This also highlights some auxiliary contributions—mainly
optimizations in the systems that we used for implementing TIFF.
We build TIFF on top of the open-source fuzzer VUzzer [39]. We