### Data Collection and Analysis

On April 16, 2010, we conducted a study to identify comment words (e.g., "wonderful," "worst") associated with different product brand names. We randomly selected some users and marked their tweets as sensitive data, simulating a privacy setting where the data is shared only with friends. The two examples for intrusion detection systems (IDS) were based on the DARPA Intrusion Detection Evaluation dataset [5]. This dataset includes sniffing data from external networks, which was marked as public in our study, and data from the internal network, which was considered sensitive. Our analysis involved identifying all ports connected by each IP address and determining the amount of traffic generated by individual hosts.

For email spam detection, we prepared a Naive Bayesian classifier. One job counted the occurrences of a set of words on a spam keyword list, while the other counted the total number of words in a large dataset. We used the published Enron email dataset [6] as private data and a SPAM archive [12] as public data. These jobs and their related datasets are detailed in Tables 2 and 3. Additionally, we performed an experiment to understand the performance of Sedic on datasets with various proportions of sensitive records, using a job that computed the average lengths of packet payloads over the IDS dataset. The code for this job was derived from Hadoop sample code [28].

**Table 2: Descriptions of Hadoop Jobs**

| Job | Dataset | Description |
| --- | --- | --- |
| Port Scan Detection | IDS dataset | Find the TCP ports connected by each host. |
| Traffic Statistics | IDS dataset | Count the total amount of traffic generated by each host (for detecting denial of service attacks). |
| Email Word Count | Spam dataset | Count the total number of words in the spam dataset (for calculating Bayes probability). |
| Spam Keyword Count | Spam dataset | Count the occurrences of each keyword on a given spam keyword list file (for calculating Bayes probability). |
| Grep Twitter | Twitter dataset | Search for word patterns according to predefined regular expressions within the dataset, e.g., brand names and comment words such as "awesome," "wonderful," "worst," etc. |

### Evaluation

In this section, we report the evaluation of our privacy-aware MapReduce framework. Our objective is to determine whether these techniques can significantly reduce the workload on the private cloud, scale to large amounts of data, and maintain acceptable overheads, particularly in terms of inter-cloud communication costs.

#### Experimental Setting

We built our hybrid cloud on FutureGrid [7], an NSF-supported, nationwide cloud test-bed [40]. The public cloud included three nodes at the University of Chicago, each equipped with an 8-core 2.93 GHz Intel Xeon, 24 GB memory, 862 GB local disk, and Linux 2.6.18. The private cloud consisted of three nodes at Indiana University, each with 8 to 24 cores of Intel Xeon CPUs, 32G or 48GB memory, 1.6TB disk, and Linux 2.6.18. These two clouds were connected by a 40 MBps link.

#### Experimental Results

We evaluated both the effectiveness of our code transformation tool and the performance of our execution framework, including computational and communication overheads.

**Code Transformation:**
All reducers in our experimental study were simple, typically summing values produced by mappers according to keys. Our analysis tool easily identified fold loops and determined that they were commutative and associative. These reducers were also set as combiners to combine data in the public and private clouds, respectively, and then reduce the outputs on the private node. Exceptions include tasks for collecting all ports associated with individual IP addresses and determining the average lengths of packet payloads. The former did not have loop dependencies and was directly used as a combiner. The latter calculated the mean of all inputs, as described in Section 4.2.

**Performance:**
We ran a job to compute average payload lengths on the IDS dataset to analyze the performance of our execution platform with different public/sensitive data mixtures. We considered the worst-case scenario where sensitive data was uniformly distributed across data blocks. We gradually increased the proportion of sensitive information from 10% to 50% to evaluate the amount of computation outsourced to the public cloud. The workload was measured by the total task execution time, summed over the execution time of individual tasks (map and reduce) processed by private nodes. This workload was compared to the baseline of running the entire job within the private cloud to estimate the outsourcing ratio. The results are shown in Figure 6.

**Figure 6: Performance vs. Sensitive Data Ratio**

The workload on the private cloud increased from about 69.68 seconds (an outsourcing ratio of about 76%) when 10% of the dataset was sensitive, to about 168.88 seconds (about 40% outsourcing ratio) when 40% of the data was private. The workload slightly decreased when the sensitive data ratio reached 50%, likely due to randomness in execution. The map task in the private cloud only processes sensitive records within each block, but there were noticeable overheads associated with initializing the task and seeking these records, which affected performance.

**Table 4: Performance**

| ID | Job | Task Execution Time (in seconds) | Total Task Execution Time of the Whole Job (Baseline, in seconds) | Outsource Ratio | Public Data Ratio | Communication w/o Transformation (MB) | Communication w/ Transformation (MB) |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | Port scan detection | 1723.87 | 1909.79 | 17.85 | 928.86 | 148.48 | 155.70 |
| 2 | Traffic statistics | 890.25 | 928.86 | 5.24 | 866.11 | 66.12 | 99.03 |
| 3 | Word count | 148.48 | 155.70 | 17.85 | 928.86 | 148.48 | 155.70 |
| 4 | Spam Keyword Count | 66.12 | 99.03 | 5.24 | 866.11 | 66.12 | 99.03 |
| 5 | Grep | 155.70 | 1723.87 | 17.85 | 928.86 | 148.48 | 155.70 |

**Communication Overheads:**
Our experiments showed that the new reduction structure automatically generated by Sedic effectively controlled inter-cloud data transfers, a major challenge in cloud computing. Specifically, we compared the bandwidth consumption of the original Hadoop jobs with that after reducer transformation. For example, in port scan detection, over 1.5 GB of data was reduced to just 8.2 MB using the automatically generated combiner on the public cloud. This significant reduction in bandwidth consumption improves the performance of hybrid-cloud computation, especially given the typically low inter-cloud bandwidth (e.g., Amazon EC2 to S3 is around 50 MBps, and external connections to EC2 are often less than 10 MBps).

### Related Work

Most security research in cloud computing focuses on data storage security [47] and virtualization security [33]. Little effort has been made to facilitate security and privacy protections during computation specific to this new platform, despite the rich literature on generic secure-computing techniques. One exception is Airavat [41], which ensures mandatory access control and differential privacy [26] for MapReduce operations on sensitive data. Unlike Airavat, which trusts the cloud platform, our work aims to protect sensitive data from the public cloud through a security mechanism designed for the hybrid-cloud platform.