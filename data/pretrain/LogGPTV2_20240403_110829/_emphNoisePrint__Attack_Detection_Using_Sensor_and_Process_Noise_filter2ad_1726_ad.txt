to the CPS by immediately saturating and maintaining |rk,i| at the
constant αi −ϵi. Therefore, for this attack, the sensor measurements
received by the controller take the form,
¯yk,i = Ci ˆxk + αi − ϵi .
(23)
Zero-Alarm Attack for CUSUM Detector: This attack is designed
to stay undetected by the CUSUM detectors. Consider the CUSUM
procedure and write (19) in terms of the estimated state ˆxk,
Sk,i = max(0, Sk−1,i + |yk,i − Ci ˆxk + δk,i| − bi),
(24)
if Sk−1,i ≤ τi and Sk,i = 0 if Sk−1,i > τi. As with the Bad-Data
procedure, we look for attack sequences that immediately saturate
and then maintain the CUSUM statistic at Sk,i = τi − ϵi where ϵi
(min(τi , bi) > ϵi > 0) is a small positive constant introduced to
account for numerical precision. Assume that the attack starts at
some k = k∗ ≥ 1 and Sk∗−1,i ≤ τi, i.e., the attack does not start
immediately after a false alarm. Consider the attack,
δk,i =
τi − ϵi + bi − yk,i + Ci ˆxk − Sk−1,i , k = k∗,
k > k∗.
bi − yk,i + Ci ˆxk ,
(25)
This attack accomplishes Sk,i = τi − ϵi for all k ≥ k∗ (thus zero
alarms). Note that the attacker can only induce this sequence by
exactly knowing Sk∗−1,i, i.e., the value of the CUSUM sequence
one step before the attack. This is a strong assumption since it
represents a real-time quantity that is not communicated over the
communication network. Even if the opponent has access to the
parameters of the CUSUM, (bi , τi), given the stochastic nature of
the residuals, the attacker would need to know the complete history
of observations (from when the CUSUM was started) to be able to
reconstruct Sk∗−1,i from data. This is an inherent security advan-
tage in favor of the CUSUM over static detectors like the Bad-Data.
Nevertheless, for evaluating the worst case scenario, we assume
that the attacker has access to Sk∗−1,i. Therefore, for this attack,
the sensor measurements received by the controller take the form,
(cid:40)
¯yk,i =
Ci ˆxk + τi − ϵi + bi − Sk−1,i − ϵi , k = k∗,
k > k∗.
Ci ˆxk + bi ,
(26)
(cid:40)
5.3 Performance Metrics
In our experiments, each sensor is assigned a unique ID and a two-
class classification is applied to identify each sensor. To evaluate
the performance, we use identification accuracy as a performance
metric. Let c be the total number of classes. We define T Pi as true
positive for class ci when it is rightly classified based on the ground
truth. False negative F Ni is defined as the wrongly rejected, and
False positive F Pi as wrongly accepted. True negative T Ni is the
rightly rejected class. The overall accuracy (acc) for total of c classes
is defined as,
Figure 6: Residual vector for the Tank-1 during the normal
operation of the SWaT plant.
c
i =1 T Pi +c
c
i =1 T Pi +c
i =1 T Ni +c
i =1 F Pi +c
i =1 T Ni
acc =
(27)
.
i =1 F Ni
5.4 Attack Detection Performance
Attack detection performance of the proposed scheme is presented
and compared with the statistical detectors from the literature.
Residual Vector for Normal Operation: Figure 6 shows plot for
residual vector for the case of normal operation in SWaT testbed.
Residue vector is shown for three different states of the system,
i.e. region A is the case for water emptying process in Tank-1,
region B is the case for static process and region C for water filling
process. The randomness in the residue vector is a function of sensor
and process noise as given by proposition 1. The intuition for the
proposed scheme is based on this noise pattern in the residue vector.
Sensor noise part is due to physical structure of the sensor [19]
and process noise is property of the process e.g. water sloshing in
the tank [4]. The horizontal line is the threshold for the Bad-Data
detector.
Threshold Validation for the Statistical Detectors: As explained
in previous section that the threshold has to be selected such that
it could satisfy the alarm rate, and it should not have too much
margin so that the false alarm rate is too high or is too low. Here
we tested our combined detector of both Bad-Data and CUSUM on
both tanks dynamically and the result is shown in Figure 9. The plot
shows that the alarm rate for tanks is between 0.02 to 0.04. Both
detectors running at Tank-1 converged to a 0.025 false alarm rate
when running for more than 1500 time stamps. Similarly detectors
running at Tank-2 converged to 0.045 false alarm rate. To achieve
this false alarm rate we used the threshold settings as shown in
Table 3.
Residual Vector for Zero-Alarm Attack: Figure 7 shows a plot
for the residual vector when system is under zero-alarm attack.
8
Session 12: Physical Attacks and DefenseASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea490Table 3: Threshold Validation for Statistical Detectors.
Parameter
α
τ
bias b
Tank-1
0.00046072
0.00015972
0.0003269
Tank-2
0.00045890
0.00014750
0.0003256
The left most plot shows real-time data for level sensor in Tank-1,
while two plots on the right show residual vectors for Bad-Data and
CUSUM detectors. From the design of zero-alarm attacks in previous
section, it was expected that the attacker would spoof the sensor
data to stay stealthy for the statistical detectors. In an attempt to be
stealthy but still be able to damage the plant [5, 17, 37], an attacker
would inevitably modify the noise pattern of the residual vector.
A visual comparison of normal operation in Figure 6 and system
under attack in Figure 7, reveals the deviation from the normal
noise pattern when system is under attack.
Attack Detection: Table 4 shows the results for the performance
of the attack detectors. A comparison between statistical detectors
and NoisePrint reveals that the proposed scheme is able to detect
sensor spoofing attacks using the same residual vector as used by
Bad-Data and CUSUM. Hence, NoisePrint removes the limitations
of these detectors and could detect the zero-alarm attacks.
• Constant Bias Attack: Figure 10 in appendix F shows the
water level at the Tank-1 when the system is under a constant
bias attack of δ1 = 0.01m. The PLC received this attacked
measurement value. The true value (plotted in gray) of the
level at Tank-1 is about 0.5m. This true level remains con-
stant throughout the attack and the inlet pump and valve
are switched OFF. The attack is launched at k = 11s (time
instant in plot) and the Bad-Data detector monitoring Tank-
1 detects it immediately. Furthermore this attack was also
detected by the CUSUM detector running at Tank-1.
NoisePrint also detects this attack using the SVM model
trained using residual from the normal operation of the plant.
The deviation in the residual vector from the normal opera-
tion is pictorially seen in Figure 10.
• Zero-Alarm Attack for Bad-Data and CUSUM Detec-
tor: We launched zero-alarm attack for Bad-Data and CUSUM
detectors for level sensor installed in two tanks at SWaT
testbed. Since this attack is designed to raise no alarms for
the Bad-Data or the CUSUM detectors, neither detector on
tanks detect the attack. The attacker has the complete knowl-
edge of the detectors, so he can deviate the level of the tank
in such a way that Bad-Data and CUSUM detectors would
not be able to detect it. Figure 7 shows the Tank-1 level sen-
sor under such an attack. It can be seen that attacker spoofs
sensor data in a way that residual vectors stay under the
detection threshold.
NoisePrint is able to detect zero-alarm attacks as noise pattern
is changed from the fingerprint created under the normal
operation.
Table 4: Attack detection performance and comparison be-
tween detectors.
Attack Type / Detector
Zero-Alarm Attack
Constant Bias Attack
Bad-Data
Detector
NoisePrint
CUSUM
Detector
Detected
Not Detected Not Detected Detected (100% Accuracy)
Detected (100% Accuracy)
Detected
5.5 Sensor Identification Accuracy
In Table 5, sensor identification accuracies are given for nine differ-
ent sensors in the water distribution testbed. We can see that the
lowest identification accuracy is 90% and the highest is 96.41%. The
sensors can be identified with a very high accuracy even though
few processes are of similar type e.g. flow of water, level of wa-
ter or pressure at the junctions. Two-class SVM is used for sensor
identification. One class is labeled as legitimate for the case of right
sensor and data from all other sensors, while attackers are labeled
as illegitimate. Since the residual vector (source of fingerprint) is a
function of sensor and process noise, if an adversary physically ma-
nipulates the sensor or execute analog sensor spoofing [47], it will
modify the sensor noise pattern. In case an adversary swaps level
sensors on two different tanks (processes) [4], the process noise
would deviate from the reference fingerprint. The proposed method
is able to detect such physical/analog domain manipulations. These
results highlight the significance of NoisePrint.
6 DISCUSSION
Security Argument: Attacks on sensor measurements can be de-
tected using NoisePrint for the case of an attacker with the knowl-
edge of either the system model including estimator gain or the
noise profile. However, for the case of a strong adversary (pos-
sessing knowledge of system model and noise distribution for a
sensor) the proposed scheme would fail only when an attacker
strictly follows the system model and imitates the noise profile. To
stay stealthy against NoisePrint an attacker should stay within the
bounds of noise distribution of a residual vector and can not deviate
from the system model, which means it can not inject arbitrary
values. An attacker injecting values from the noise distribution
of residual vector would not be able to achieve its objectives as
stated in the attacker model. NoisePrint raises the bar for such an
advanced attacker. For a more advanced attacker, we can comple-
ment NoisePrint with a challenge-response protocol, to detect replay
attacks. A challenge is generated from the physical quantity to be
measured and the challenger-sensor pair is fingerprinted, which
would help us detect replay attacks.
Scalability: In this article we considered a multitude of sensors
from two CPS testbeds. For evaluation of the proposed scheme
we have used two-class classification (LibSVM) by considering the
legitimate sensor (class 1) and rest of the sensors as illegitimate or
compromised (class 2). We also considered a variety of processes.
Multitude of devices, processes and the classification algorithm
indicates that NoisePrint is scalable. We studied the feasibility of
the proposed scheme on two different testbeds which also points
out the generality and scalability of the NoisePrint.
Attack Detection Speed: In this article we executed zero-alarm
9
Session 12: Physical Attacks and DefenseASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea491Figure 7: Zero-Alarm Attack for Bad-Data and CUSUM detectors on Tank-1 in SWaT. Horizontal line in right hand plots is the
threshold for the particular detector.
Table 5: WADI Sensor Identification Accuracy Result
Sensor
RADAR Level Sensor (Primary Grid)
RADAR Level Sensor (Secondary Grid)
RADAR Level Sensor (Secondary Grid)
Type and Model
iSOLV RD700
iSOLV EFS803/CFT183
iSOLV EFS803/CFT183
Differential Pressure Transmitter (Secondary Grid)
Differential Pressure Transmitter (Secondary Grid)
iSOLV SPT 200
iSOLV SPT 200
Electromagnetic Flowmeter (Primary Grid)
Electromagnetic Flowmeter (Secondary Grid)
Electromagnetic Flowmeter (Secondary Grid)
Electromagnetic Flowmeter (Secondary Grid)
iSOLV EFS803/CFT183
iSOLV EFS803/CFT183
iSOLV EFS803/CFT183
iSOLV EFS803/CFT183
Identification Accuracy
90.87%
96.41%
91.52%
92.02%
92.95%
92.76%
90.76%
90.0%
92.04%
attacks on two stages of the SWaT testbed and compared the per-
formance of NoisePrint and legacy statistical methods based on
certain thresholds. The proposed scheme can detect these attacks
while legacy methods fail. However, there is a trade-off for such a
good performance, in terms of detection time. For threshold based
schemes an attack detection decision is made at each time instant,
by comparing the residual value to a threshold, while for NoisePrint
we need 120 samples to extract features and then make a detection
decision. There is a delay of 120 samples to raise an alarm if any
attack is being executed. However, we propose an idea where we
only wait for initial 120 readings and then at each time instant use
previous readings in a moving window manner plus a set of fresh
readings to extract a feature vector. This way, we do not have to
wait for 120 readings and an attack can be detected in less time. We
have not tested this proposal yet, which is part of our future work.
Application in Real-World CPS: We have tested the proposed
method for a data set collected over a period of two weeks from a
water distribution testbed. The results are promising for such a time
period. However, it is recommended to train the classifiers after
every plant maintenance cycle. Moreover, being used in a testbed for
few weeks is different from being used in a real-world production
system of physical plants with possibly more harsh environment
especially for the case of level measurements including rivers, dams
etc. Although the testbeds used in the reported experiments imitate