        300000
        ipc.server.listen.queue.size
        3300
        hadoop.tmp.dir
        file:/data01/gpadmin/hadoop/tmp
        Abase for other temporary directories.
```
配置目录  
```
# mkdir -p /data01/gpadmin/hadoop/tmp
# chown -R gpadmin:gpadmin /data01
```
2\. /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/hdfs-site.xml  
namenode  
```
dfs.namenode.name.dir	        Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently.	
                                If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.
dfs.hosts / dfs.hosts.exclude	List of permitted/excluded DataNodes.	
                                If necessary, use these files to control the list of allowable datanodes.
dfs.blocksize	                268435456	
                                HDFS blocksize of 256MB for large file-systems.
dfs.namenode.handler.count	100	
                                More NameNode server threads to handle RPCs from large number of DataNodes.
```
datanode  
```
dfs.datanode.data.dir	Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks.	
                        If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices.
```
配置  
```
$ vi /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/hdfs-site.xml
        dfs.hosts
        /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/slaves
        dfs.replication
        2
        dfs.allow.truncate
        true
        dfs.blocksize
        268435456
        dfs.block.access.token.enable
        false
        dfs.block.local-path-access.user
        gpadmin
        dfs.client.socket-timeout
        300000000
        dfs.client.use.legacy.blockreader.local
        false
        dfs.datanode.data.dir.perm
        750
        dfs.datanode.handler.count
        60
        dfs.datanode.max.transfer.threads
        40960
        dfs.datanode.socket.write.timeout
        7200000
        dfs.namenode.accesstime.precision
        0
        dfs.namenode.handler.count
        600
        dfs.support.append
        true
         dfs.namenode.name.dir
         file:/data01/gpadmin/hadoop/dfs/name,file:/data02/gpadmin/hadoop/dfs/name
         dfs.datanode.data.dir
         file:/data01/gpadmin/hadoop/dfs/data,file:/data02/gpadmin/hadoop/dfs/data
        dfs.client.read.shortcircuit
        true
        dfs.domain.socket.path
        /data01/gpadmin/hadoop/sock/dn._PORT
```
配置目录  
```
mkdir -p /data01/gpadmin/hadoop/dfs/name
mkdir -p /data01/gpadmin/hadoop/dfs/data
mkdir -p /data02/gpadmin/hadoop/dfs/name
mkdir -p /data02/gpadmin/hadoop/dfs/data
mkdir -p /data01/gpadmin/hadoop/sock
chown -R gpadmin:root /data01/gpadmin
chown -R gpadmin:root /data02/gpadmin
```
## 配置Slaves File(host file)
datanode记为slave，所以所有的datanode主机名或IP都要写在这里  
```
Typically you choose one machine in the cluster to act as the NameNode and one machine as to act as the JobTracker, exclusively. 
The rest of the machines act as both a DataNode and TaskTracker and are referred to as slaves.
```
配置   
```
vi /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/slaves
host_digoal_01
host_digoal_02
host_digoal_03
chown gpadmin:gpadmin /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/slaves
```
## 配置rack感知 
dcn 表示主机处于哪个IDCn    
rackn 表示主机处于哪个交换机下（或哪个主机柜中）    
IP与主机名都需要配置入slaves文件    
```
echo "xxx.xxx.xxx.97  /dc1/rack1" > /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/topology.data 
echo "xxx.xxx.xxx.108 /dc1/rack2" >> /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/topology.data 
echo "xxx.xxx.xxx.104 /dc1/rack3" >> /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/topology.data 
echo "host_digoal_01 /dc1/rack1" >> /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/topology.data 
echo "host_digoal_02 /dc1/rack2" >> /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/topology.data 
echo "host_digoal_03 /dc1/rack3" >> /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/topology.data 
chown gpadmin:gpadmin /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/topology.data 
```
创建rack回馈脚本  
```
vi /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/hostrack.sh
HADOOP_CONF=/home/gpadmin/app/hadoop-2.7.3/etc/hadoop
while [ $# -gt 0 ] ; do  # //$#代表执行命令时输入的参数个数
  nodeArg=$1
  exec
        net.topology.script.file.name
        /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/hostrack.sh
        net.topology.script.number.args
        8000
```
## 配置secondary namenodes
需要用于secondary namenode的主机名都添加进来，本例使用1主1备  
可以使用IP或主机名  
```
vi /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/masters
xxx.xxx.xxx.108
chown gpadmin:gpadmin /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/masters
```
修改hdfs-site.xml, core-site.xml配置  
```
追加
vi /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/hdfs-site.xml
        dfs.http.address
        xxx.xxx.xxx.97:50070
        dfs.namenode.secondary.http-address
        xxx.xxx.xxx.108:50090
vi /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/core-site.xml
        fs.checkpoint.period
        3600
        The number of seconds between two periodic checkpoints.
        fs.checkpoint.size
        67108864
```
## 配置日志
/home/gpadmin/app/hadoop-2.7.3/etc/hadoop/log4j.properties  
## 确保配置文件所在目录，所有节点保持一致  
```
HADOOP_CONF_DIR 
cat /home/gpadmin/app/hadoop-2.7.3/etc/hadoop/hadoop-env.sh|grep HADOOP_CONF_DIR
```
## 初始化hdfs namenode
```
$HADOOP_HOME/bin/hdfs namenode -format 
```
例如  
```
$HADOOP_HOME/bin/hdfs namenode -format digoal
```
## 配置防火墙
内网相互信任，根据实际情况开放  
```
vi /etc/sysconfig/iptables
# 私有网段 INSERT
-A RH-Firewall-1-INPUT -s 192.168.0.0/16 -j ACCEPT
-A RH-Firewall-1-INPUT -s 10.0.0.0/8 -j ACCEPT
-A RH-Firewall-1-INPUT -s 172.16.0.0/16 -j ACCEPT
```
## 启动dfs  
如果配置了ssh无秘钥认证，并且配置了slave file(host file)，则可以直接启动  
```
$ start-dfs.sh
Starting namenodes on [host_digoal_01]
host_digoal_01: starting namenode, logging to /home/gpadmin/app/hadoop-2.7.3/logs/hadoop-gpadmin-namenode-host_digoal_01.out
host_digoal_01: starting datanode, logging to /home/gpadmin/app/hadoop-2.7.3/logs/hadoop-gpadmin-datanode-host_digoal_01.out
host_digoal_02: starting datanode, logging to /home/gpadmin/app/hadoop-2.7.3/logs/hadoop-gpadmin-datanode-host_digoal_02.out
host_digoal_03: starting datanode, logging to /home/gpadmin/app/hadoop-2.7.3/logs/hadoop-gpadmin-datanode-host_digoal_03.out
Starting secondary namenodes [host_digoal_02]
host_digoal_02: starting secondarynamenode, logging to /home/gpadmin/app/hadoop-2.7.3/logs/hadoop-gpadmin-secondarynamenode-host_digoal_02.out
```
## 检查dfs状态
```
[gpadmin@host_digoal_01 ~]$ hdfs dfsadmin -report
Configured Capacity: 603937480704 (562.46 GB)
Present Capacity: 603429277696 (561.99 GB)
DFS Remaining: 603429081088 (561.99 GB)
DFS Used: 196608 (192 KB)
DFS Used%: 0.00%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0
Missing blocks (with replication factor 1): 0
-------------------------------------------------
Live datanodes (3):
Name: xxx.xxx.xxx.108:50010 (host_digoal_02)
Hostname: host_digoal_02
Rack: /dc1/rack2
Decommission Status : Normal
Configured Capacity: 201312493568 (187.49 GB)
DFS Used: 65536 (64 KB)
Non DFS Used: 168005632 (160.22 MB)
DFS Remaining: 201144422400 (187.33 GB)
DFS Used%: 0.00%
DFS Remaining%: 99.92%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 2
Last contact: Fri Sep 16 08:39:18 CST 2016
Name: xxx.xxx.xxx.97:50010 (host_digoal_01)
Hostname: host_digoal_01