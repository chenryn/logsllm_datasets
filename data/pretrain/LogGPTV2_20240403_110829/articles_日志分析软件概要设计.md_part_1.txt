**日志分析软件概要设计**
#  {#section .}
#### 1.架构概述 {#架构概述 .list-paragraph}
日志分析软件采用高性能、低延时的准实时流式处理，采用分布式、松耦合、可扩展的集群架构，各模块可水平扩展，如果哪个模块成为性能瓶颈，只需要增加运行那个模块的服务器数量。提供开放的RESTful
API接口，可供第三方做二次开发。采用冗余容错的架构，所有模块都冗余部署，某台服务器出问题不会导致系统服务中断。提供完善的系统监控，无论是硬件还是软件故障，都能够及时告警。提供灵活的高可用、高性能分部署大数据接入、存储、处理、检索、展现的平台
##### 1.1架构图 {#架构图 .list-paragraph}
![](media/image1.png){width="5.778472222222222in"
height="2.966666666666667in"}
##### 1.2组件概述 {#组件概述 .list-paragraph}
图中蓝色部分为日志分析软件的模块，红色部分为可通过RESTful
API接入的第三方模块
###### 1.2.1采集系统 {#采集系统 .list-paragraph}
1.  如果数据在服务器端是文件形式，数据采集可以采用Linux标配的rsyslog或日志分析软件提供的agent，rsyslog或日志分析软件agent监控服务器的数据文件，读取数据文件及其增量并发送给日志分析软件系统。
2.  如果数据已经存入Hadoop系统或数据库，日志分析软件可提供定制化agent，将数据从Hadoop系统或数据库里读出来并发送给日志分析软件系统。
3.  网络设备可通过syslog协议把数据传送过来。
###### 1.2.2消息系统 {#消息系统 .list-paragraph}
日志分析软件采用分布式消息系统连接各个模块，消息系统也起到缓存的作用。
###### 1.2.3数据处理系统 {#数据处理系统 .list-paragraph}
数据处理系统基于高性能内存流式计算架构Spark
Streaming，根据配置的规则抽取数据关键字段，将非结构化的数据转换成结构化数据。抽取关键字段的好处是可以对关键字段进行统计分析。日志分析软件将对关键字段及原始数据进行索引，用户可对关键字段及原始数据进行搜索。
日志分析软件已经配置了常见数据的解析规则，对于日志分析软件没有预先配置解析规则的数据，用户可通过后台或Web页面配置解析规则，抽取关键字段。即使没有抽取关键字段，用户仍然可以通过全文检索搜索数据。
日志分析软件在数据做索引之前抽取关键字段，提高了检索的速度。业界有的竞品在检索阶段抽取字段，导致检索速度慢。日志分析软件克服了这个弊端。
###### 1.2.3数据检索系统 {#数据检索系统 .list-paragraph}
对数据的关键字段及全文做索引，每天的数据存为一个索引文件，方便用户决定保留多少天的数据。索引文件采用分布式存储，并且有副本，保障高可用。
另外，数据检索系统也支持对不同来源的数据做关联分析。
###### 1.2.4WEB服务 {#web服务 .list-paragraph}
进行数据展现、数据可视化，支持各种统计功能及图表展现，实现流畅的图形用户交互。
#### 2.WEB服务 {#web服务-1 .list-paragraph}
WEB服务提供了日志分析软件的访问页面，进行数据展现、数据可视化，支持各种统计功能及图表展现，实现流畅的图形用户交互。
##### 2.1服务架构 {#服务架构 .list-paragraph}
![](media/image2.png){width="5.779166666666667in"
height="4.378472222222222in"}
##### 2.2使用界面 {#使用界面 .list-paragraph}
![](media/image3.jpeg){width="6.345833333333333in"
height="2.9583333333333335in"}
##### 2.3ldap接入设计 {#ldap接入设计 .list-paragraph}
日志分析软件登陆支持OpenLDAP服务，同时保留原始的直接登陆方式用于管理员登陆，用户可在登陆界面进行选择。默认为通过LDAP登录。
首次通过LDAP登陆的用户只具有默认的基本权限，查看指定的默认分组的日志。
为首次通过LDAP登陆的用户在日志分析软件中创建平台用户，用于后续管理员对账户权限的管理。用户LDAP用户无法通过此用户直接登录。
支持日志分析软件管理员可配置接入LDAP的地址，加密方式，用户分组等。
配置项在Web服务的配置文件中指定，更改后只需重启Web服务即可生效，使用ini格式，含义依次说明：
server_domain:
OpenLDAP服务器域名。如果OpenLDAP服务端配置了传输加密,并且TLSVerifyClient配置项为demand,则需其为与证书CommanName一致的domain。
port: OpenLDAP服务端口。
domain_base: 搜索用户的根结点。
admin_dn: 通过此OpenLDAP账户进行用户查询。
admin_password: admin_dn密码。
encryption:
Web服务与OpenLDAP之间的传输支持plain,start_tls,ldaps三种加密方式。采用ldaps方式加密传输需要配置证书。
uid_attribute_name: LDAP中用户唯一ID字段名。
name_attribute_name: LDAP中用户名字段名。
email_attribute_name: LDAP中用户邮箱字段名。
rizhiyi_name_postfix:
用来为通过LDAP首次登陆的用户添加进大数据用户系统时作为后缀名，目的是避免命名冲突。
default_group: 默认可查询的日志分组。
operator\_\*:
因LDAP登陆用户第一次登陆时候即需要进行分组操作，需提供日志分析软件管理员账户密码。
private\_\*: 当对证书的要求是demand时候，客户端需要提供证书。
#### 3.数据采集 {#数据采集 .list-paragraph}
一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，支持在日志系统中定制各类数据发送方，用于收集数据；同时提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。
\(1\) 可靠性
当节点出现故障时，日志能够被传送到其他节点上而不会丢失。集群提供了end-to-end模式来保障可靠性：收到数据agent首先将event发送到后端消息队列集群，如果数据发送失败，将event写到磁盘上，可以重新发送。
\(2\) 可扩展性
模块完全是多主平行结构，不存在单点故障问题。
\(3\) 可管理性
每个节点均提供metric
api接口，以json格式数据展现服务状态，方便提供服务指标和运维监控。
##### 3.1模块架构 {#模块架构 .list-paragraph}
![](media/image4.png){width="5.772916666666666in"
height="4.145138888888889in"}
日志采集的模块主要分以下几部分：
##### 3.2Heka {#heka .list-paragraph}
> Server Heka主要功能：
>
> 1.接收来自syslogd或rsyslogd的普通syslog请求（原始请求不带token，appname，tag)
>
> 2.为每个syslog事件打上本集群的token
>
> 3.根据源IP设置对应的appname，tag
>
> 4.负责将Yottaweb收到的本地上传日志上传给Collector，这里还需要提供相关Api供前台预览分行结果
>
> Server
> Heka会有一个统一的配置管理页面负责管理源ip与appname，tag的映射关系，且YottaWeb
> 所在机器的Heka有个配置页面，来配置对本地上传日志文件的后续处理。
>
> ![](media/image5.png){width="6.684722222222222in"
> height="4.459722222222222in"}
-   **Agent**
用户在自己的服务器上（linux/windows)部署Heka，我们称之为 Agent
Heka，如下图：
![](media/image6.png){width="6.688194444444444in"
height="6.207638888888889in"}
Agent Heka 主要功能：
> 1.可以接入文件,Tcp/Udp,脚本，Windows Evenglog，性能数据等输入
>
> 2.可以限制上报速度
3.  可以在本地做简单的负载均衡，配置多个Collector地址，作为输出
后台接口设计
frontend
1.frontend提供接口给hekad-daemon上报心跳
请求：（新增os参数）
act=report_heartbeat&ip=x.x.x.x&port=8014&os=linux&status=Running
应答：
｛\"result\":true,
\"reason\":\"Success\",
\"collector_addresses\":\[\"192.168.1.70:5180\",\"192.168.1.71:5180\"\]
\"token\":\"xxx\",
\"other_conf\":\[
{\"type\":\"TcpInput\",
\"address\":\":514\",
\"mappings\":\"192.168.1.1:appname_1:tag_1:utf-8;192.168.1.2:appname_2:tag_2:gbk\"
},
{\"type\":\"UdpInput\",
\"address\":\":514\",
\"mappings\":\"192.168.1.1:appname_1:tag1:utf-8\"
}\]
}
注：other_conf目前只返回给Server
Heka（frontend通过hosts或者配置文件可以知道collector和yottaweb
ip以此区分Server Heka和Agent Heka），用以提供ServerHeka配置之用。
2.frontend提供接口供yottaweb查询Agent状态
请求：
act=get_agent_status&start=0&size=20&orderby=ip&ip=&isfuzzy=false
应答：(新增os)
{
\"result\" : true,
\"total\" : 3,
\"agent_status\" : \[ {
\"ip\" : \"10.211.55.7\",
\"port\" : 8080,
\"last_update_timestamp\" : \"2015-09-16 14:41:53.0\",
\"status\" : \"Running\"
\"os\": \"linux\"
}, {
\"ip\" : \"192.168.1.1\",
\"port\" : 80,
\"last_update_timestamp\" : \"2015-05-22 15:31:09.0\",
\"status\" : \"Running\"
\"os\": \"linux\"
}, {
\"ip\" : \"192.168.1.26\",
\"port\" : 18080,
\"last_update_timestamp\" : \"2015-10-14 10:58:27.0\",
\"status\" : \"Running\"
\"os\" : \"win\"
} \]
}
3.frontend提供接口供yottaweb管理ServerHeka配置：
a.查询Server Heka配置
请求：
act=get_server_heka_config
应答：
{\"result\":true,
\"reason\":\"Success\",
\"config\":\[
{\"type\":\"UdpInput\",
\"address\":\":514\",
\"mappings\":\"192.168.1.1:app:tag:charset;192.168.1.2:app:tag:charset\"}
\]
}
b.新增Server Heka配置
请求：
act=add_server_heka_config&type=UdpInput&address=:514&mappings=192.168.1.1:app:tag
应答：
{\"result\":true,
\"reason\":\"Success\"}
c.修改Server Heka配置
请求：
act=modify_server_heka_config&type=UdpInput&address=:514&mappings=192.168.1.1:app:tag
应答：
{\"result\":true,
\"reason\":\"Success\"}
d.删除Server Heka配置
act=del_server_heka_config&type=UdpInput&address=:514
应答：
{\"result\":true,
\"reason\":\"Success\"}
DB中会有新的表ServerHekaConfig用来持久化ServerHeka配置，表结构如下：
type varchar(16) 类型
address varchar(32) 监听地址
mappings text 源IP对应appname，tag，charset
hekad-daemon
1.查询配置