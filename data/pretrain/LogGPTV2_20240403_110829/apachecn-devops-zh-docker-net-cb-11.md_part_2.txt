让我们首先了解接口的主机端。例如，假设我们正在寻找这个接口的容器端:
```
user@docker1:~$ ip -d link show
…… 
4: docker0:  mtu 1500 qdisc noqueue state UP mode DEFAULT group default
    link/ether 02:42:ab:27:0e:3e brd ff:ff:ff:ff:ff:ff promiscuity 0
    bridge
6: vetha431055@if5:  mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default
    link/ether 82:69:cb:b6:9a:db brd ff:ff:ff:ff:ff:ff promiscuity 1
    veth
user@docker1:~$
```
这里有几件事需要指出。首先，将`-d`参数传递给`ip link`子命令，显示关于界面的额外细节。在这种情况下，它确认接口是 VETH 对。第二，VETH 配对命名一般遵循`@`命名惯例。在这种情况下，我们可以看到终端`vetha431055`是本地接口，`if5`是另一端。`if5`代表接口 5 或主机上第 5 个接口的索引 ID。因为 VETH 接口总是成对创建的，所以可以假设索引为 6 的 VETH 对的末尾很可能是索引 5 或 7。在这种情况下，命名表示它是 5，但是我们可以使用`ethtool`命令来确认:
```
user@docker1:~$ sudo ethtool -S vetha431055
NIC statistics:
 peer_ifindex: 5
user@docker1:~$
```
正如您所看到的，这个 VETH 对的另一端的接口索引为 5，如名称所示。现在找到哪个容器有 5 个是困难的部分。为此，我们需要检查每个容器的特定接口号。如果你运行很多容器，这可能是一个挑战。不用手动检查每个容器，你可以使用 Linux `xargs`循环检查它们。例如，看看这个命令:
```
docker ps -q | xargs --verb -I {} docker exec {} ip link | grep ^5:
```
我们在这里做的是返回所有运行容器的容器标识列表，然后将该列表传递给`xargs`。反过来，`xargs`使用这些容器标识来运行带有`docker exec`的容器内的命令。该命令恰好是`ip link`命令，它将返回所有接口及其相关索引号的列表。如果返回的任何信息以`5:`开头，表示界面索引为 5，我们将把它打印到屏幕上。为了查看哪个容器有问题的接口，我们必须以详细模式(`--verb`)运行`xargs`命令，这将在每个命令运行时显示给我们。输出如下所示:
```
user@docker1:~$ docker ps -q | xargs --verb -I {} docker exec {} ip link | grep ^5:
docker exec 4b521df22184 ip link
docker exec 772e12b15c92 ip link
docker exec d8f3e7936690 ip link
docker exec a2e3201278e2 ip link
docker exec f9216233ba56 ip link
docker exec ea32565ece0c ip link
5: eth0@if6:  mtu 1500 qdisc noqueue state UP
user@docker1:~$
```
正如你看到的，这台主机上运行着六个容器。直到最后一个容器，我们才找到我们要找的接口 ID。给定容器 ID，我们可以知道哪个容器有 VETH 接口的另一端。
### 注
您可以通过运行`docker exec -it` `ea32565ece0c ip link`命令来确认这一点。
现在，让我们尝试另一个从 VETH 对的容器端开始的例子。这稍微容易一些，因为接口的命名告诉我们主机端匹配接口的索引:
```
user@docker1:~$ docker exec web1 ip -d link show dev eth0
5: eth0@if6:  mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    veth
user@docker1:~$
```
然后，我们可以再次使用`ethtool`来验证主机上索引为 6 的接口与容器中索引为 5 的接口是否匹配:
```
user@docker1:~$ ip -d link show | grep ^6:
6: vetha431055@if5:  mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default
user@docker1:~$ sudo ethtool -S vetha431055
[sudo] password for user:
NIC statistics:
 peer_ifindex: 5
user@docker1:~$
```
# 验证发布的端口和出站伪装
在 Docker 网络中，更困难的部分之一是`iptables`。`iptables` /netfilter 集成在提供功能(如端口发布和出站伪装)方面发挥了关键作用。然而，`iptables`如果你还不熟悉，可能很难理解和排除故障。在本食谱中，我们将回顾如何详细检查`iptables`配置，并验证连接是否按预期工作。
## 做好准备
在本食谱中，我们将使用单个 Docker 主机。假设 Docker 已安装并处于默认配置。为了检查`iptables`规则集，您还需要根级访问。
## 怎么做…
正如我们在前面几章中看到的，Docker 代表您出色地管理了主机防火墙规则。您可能很少需要查看或修改与 Docker 相关的`iptables`规则。然而，在排除容器网络故障时，能够验证配置以排除`iptables`是一个可能的问题总是一个好主意。
为了演示遍历`iptables`规则集，我们将检查一个发布端口的示例容器。我们执行的步骤可以很容易地转移到检查任何其他 Docker 集成的`iptables`用例的规则。为此，我们将运行一个简单的容器，公开用于发布的端口`80`:
```
user@docker1:~$ docker run -dP --name web1 jonlangemak/web_server_1
```
既然我们告诉 Docker 发布任何暴露的端口，我们知道这个容器应该将其暴露的端口`80`发布给主机。为了验证端口实际上是被发布的，我们可以检查`iptables`规则集。我们要做的第一件事是确保端口发布所需的目标 NAT 已经到位。要检查`iptables`表，我们可以使用`iptables`命令并传递以下参数:
*   `n`:告诉`iptables`在输出中使用数字信息，例如地址和端口
*   `L`:告诉`iptables`您想要输出一个规则列表
*   `v`:告诉`iptables`提供详细的输出，这样我们就可以看到所有的规则信息以及规则计数器
*   `t`:告诉`iptables`只显示特定表格的信息
将放在一起，我们可以使用命令`sudo iptables –nL –t nat`查看主机 NAT 表中的规则:
![How to do it…](img/B05453_11_01.jpg)
### 注
请注意，我们将在本食谱中检查的所有默认表和链策略都是`ACCEPT`。如果默认的链策略是`ACCEPT`，这意味着即使我们没有得到规则匹配，流量仍然会被允许。不管默认策略设置为什么，Docker 都会创建规则。
如果你对`iptables`感到不舒服，解释这个输出可能会有点令人生畏。即使我们正在查看 NAT 表，我们也需要知道主机的入站通信正在处理哪个链。在我们的例子中，由于流量进入主机，我们感兴趣的链是`PREROUTING`链。让我们浏览一下表是如何处理的:
*   `PREROUTING`链中的第一行查找去往`LOCAL`或主机本身的流量。由于流量的目的地是主机接口上的一个 IP 地址，因此我们匹配此规则，并执行引用跳转到名为`DOCKER`的新链的操作。
*   在`DOCKER`链中，我们碰到的第一个规则是寻找进入`docker0`桥的流量。由于这些交通没有进入`docker0`大桥，规则被忽略，我们进入下一个规则。
*   `DOCKER`链中的第二个规则是寻找没有进入`docker0`桥并且有一个目的地端口为 TCP `32768`的流量。我们匹配此规则，并执行操作来执行到`172.17.0.2`端口`80`的目的 NAT。
表中的处理如下所示:
![How to do it…](img/B05453_11_02.jpg)
上图中的箭头表示流量通过 NAT 表时的流量。在这个例子中，我们只有一个容器在主机上运行，所以很容易看到哪些规则正在被处理。
### 注
您可以将这种输出与`watch`命令相结合，以获得计数器的实时输出，例如:
```
sudo watch --interval 0 iptables -vnL -t nat
```
现在我们已经遍历了 NAT 表，接下来我们需要担心的是过滤表。我们可以像查看 NAT 表一样查看过滤器表:
![How to do it…](img/B05453_11_03.jpg)
乍一看，我们可以看到这张表的布局与 NAT 表略有不同。例如，我们在这个表中有不同于 NAT 表的链。在我们的例子中，我们对入站发布端口通信感兴趣的链是前向链。这是因为主机正在将流量转发或路由到容器。流量将按如下方式遍历该表:
*   前向链中的第一条线将流量直接发送到`DOCKER-ISOLATION`链。
*   在这种情况下，`DOCKER-ISOLATION`链中唯一的规则是将流量发回的规则，因此我们继续查看`FORWARD`表中的规则。
*   前向表中的第二条规则是，如果流量流出`docker0`桥，将流量发送到`DOCKER`链。由于我们的目的地(`172.17.0.20`)住在`docker0`桥外，我们按照这条规则匹配并跳到`DOCKER`链。
*   在`DOCKER`链中，我们检查第一个规则，并确定它正在寻找目的地为 TCP 端口`80`上的容器 IP 地址的流量，该流量正在流出而不是流入`docker0`桥。我们匹配这个规则，流程被接受。
表中的处理如下所示:
![How to do it…](img/B05453_11_04.jpg)
通过过滤表是发布的端口流量到达容器必须采取的最后一步。然而，我们现在只到达了容器。我们仍然需要考虑从容器返回到与发布端口对话的主机的返回流量。所以现在，我们需要谈谈起源于容器的流量是如何被`iptables`处理的。
我们将遇到的出站流量的第一个表是过滤器表。来自容器的流量将再次使用过滤表的前向链。流程如下所示:
*   前向链中的第一条线将流量直接发送到`DOCKER-ISOLATION`链。
*   在这种情况下，`DOCKER-ISOLATION`链中唯一的规则是将流量发回的规则，因此我们继续检查 FORWARD 表中的规则。
*   前向表中的第二条规则是，如果流量来自`docker0`桥，则将流量发送到`DOCKER`链。由于我们的交通是进入`docker0`桥而不是出去，这条规则被忽略了，我们进入下一条规则。
*   前向表中的第三条规则是，如果流量从`docker0`桥流出，并且其连接状态为`RELATED`或`ESTABLISHED`，则流量应该被接受。这个交通要进入`docker0`桥，所以我们也不符合这个规则。但是，值得指出的是，该规则用于允许从容器发起的流的返回流量。它只是没有作为初始出站连接的一部分被命中，因为这代表了一个新的流。
*   前向表中的第四条规则是，如果交通是从`docker0`桥进去的，而不是从`docker0`桥出来的，要接受。因为我们的交通将进入`docker0`大桥，我们遵守这条规则，交通被接受。
表中的处理如下所示:
![How to do it…](img/B05453_11_05.jpg)
出站流量的下一个表是 NAT 表。这一次，我们要看`POSTROUTING`链。在这种情况下，我们匹配链的第一个规则，该规则寻找的流量不是从`docker0`桥发出的，而是来自`docker0`桥子网(`172.17.0.0/16`)的:
![How to do it…](img/B05453_11_06.jpg)