P[∑
y∈Y
Iy ≥ 1] ≤ E(|Y|)E(Iy) ∈ α(1/ f − 1)(αβ)O(logα)
⊆ o(1)
n
when (αβ)O(logα) ⊆ o(n). This proves the ﬁrst claim in the non-
constant case.
In the case that both α and β are constant, getting to know at least
one corrupted node with high probability might take a little longer,
say log(logn) rounds. Asymptotically this dominates the remain-
ing O(logα) rounds to make |Bk| > α. With the same reasoning as
above, the success probability is now at most (αβ)O(log logn)/n, but
for α,β ∈ O(1), this is also o(1).
Finally, when α,β ∈ O(log n), the success probability is
(αβ)O(logα)
(logn)O(log(logn))
= eO(log2(logn))
⊆ o(1).
n
=
n
n
The theorem suggests that for all realistic choices of search pa-
rameters, a rather simple eclipse attack defeats aggregated greedy
search (and thus, Kademlia) in the limit. Notice, however, that this
attack is based on the malicious nodes knowing x even in the ﬁrst
round. In order to overcome the problem, we propose to hide the
search value. This protection strategy will be discussed in the next
section.
5.2 Hiding the Search Value
We modify our search as follows. As before, in each round v
chooses the α known nodes closest to x. From each of these nodes,
instead of asking for x, v requests their whole ﬁnger table (FT).
Let α = log2(n) from now on. This value maximizes redun-
dancy, yet might still be tuned in real applications to avoid exces-
sive network load. In the ﬁrst step, v queries all peers in his ﬁnger
table. Each of the retrieved ﬁnger tables contains log2(n) entries.
These are all aggregated, and the best (closest to the searched ID)
log2(n) are selected for the next iteration. Only hitherto unqueried
nodes are requested to provide their ﬁnger tables. The search con-
tinues until the top list of log2(n) closest peers is not modiﬁed at the
end of an iteration. The closest peer is then returned as the result of
the search.
We choose to retrieve the whole FT because of the following
reasons: First, we get extra redundancy while executing the lookup;
Second, the queried node does not know which ID v is interested in.
This keeps the adversary from responding with targeted malicious
nodes, which are close to the searched ID.
Figure 1 shows the simulation results for aggregated greedy search
while trying to hide the searched value. All the plots include 95%
conﬁdence intervals in order to show the solidity of the results.
Malicious nodes provide only other malicious nodes in their FTs.
Since the searched ID is not known, malicious nodes deliver ran-
dom colluding nodes. Surprisingly, the rate of found malicious
nodes seems to approach 2 f − f 2. This phenomenon might intu-
itively be explained as follows: Since the ﬁrst round is unbiased,
we can expect a rate of f colluding nodes to be queried. However,
when we assume that all these nodes reply with malicious nodes
only, while the honest nodes’ ﬁnger tables still have attacker ratio
f , the new attacker ratio in the replies from round 1 is expected to
be f · 1 + (1− f ) f = 2 f − f 2. Notice that from the second round
on, all queried nodes have an ID bias towards x. While the attacker
nodes still answer with random colluded nodes, the honest nodes’
ﬁnger tables, due to the exponentially increasing ﬁnger distances
in Chord (see Section 5.3 for more details), contain more nodes in
their own vicinity, and thus in the vicinity of x. Thus, the attacker
quickly loses its advantage in the course of the search process and
may not be able to increase the attacker ratio from the second stage
on. This explanation does not yet give a full formal model for the
search process, still it might help account for the results we have
seen.
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
]
%
[
d
n
u
o
f
s
e
d
o
n
s
u
o
i
c
i
l
a
m
f
o
n
o
i
t
c
a
r
F
 0
 0
Fraction of malicious nodes found
1% malicious
10% malicious
20% malicious
40% malicious
 200000
 400000
 600000
 800000
 1e+06
Number of nodes in the DHT
Figure 1: Malicious nodes respond with random collaborating
nodes
144While these results are a step in the right direction, they are far
from ideal on their own. Moreover, there is an even more efﬁcient
attack against this search strategy. Due to the fact that the search in
a DHT in the follow-up iterations depends on the results in the pre-
vious step, colluding nodes can combine their knowledge in order
to ﬁnd out the searched-for ID. Because the Chord ring is directed,
the searcher will not ask for IDs laying “behind” the search value x.
Thus, the attacker can estimate the interval of the ID by looking at
which colluding nodes the searcher knows of (they were communi-
cated by colluding nodes to the searcher in the previous iteration)
but does not query. It can then return malicious nodes which are as
close as possible to the searched-for ID (i.e. malicious nodes within
the estimated interval of the ID). Figure 2 shows the simulation re-
sults for the case when the malicious nodes estimate the queried
ID. Note, that this is only possible after the second search iteration
since the ﬁrst round does not leak information about the direction
of search. We see that even having only 10% of malicious nodes in
the system leads to more that 50% attacker success.
 5
 5
 4
 4
 3
 3
 2
 2
 1
 1
]
]
%
%
[
[
s
s
r
r
e
e
e
e
p
p
f
f
o
o
n
n
o
o
i
i
t
t
c
c
a
a
r
r
F
F
 0
 0
0
0
Finger table means distribution (100,000 Peers, 20% malicious)
Finger table means distribution (100,000 Peers, 20% malicious)
FTs of honest peers
FTs of malicious peers
100000
100000
200000
200000
300000
300000
400000
400000
500000
500000
Means
Means
Figure 3: Finger table analysis: malicious nodes change 10 en-
tries
Fraction of malicious nodes found
Finger table means distribution (100,000 Peers, 20% malicious)
Finger table means distribution (100,000 Peers, 20% malicious)
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
]
%
[
d
n
u
o
f
s
e
d
o
n
s
u
o
i
c
i
l
a
m
f
o
n
o
i
t
c
a
r
F
 0
 0
1% malicious
10% malicious
20% malicious
40% malicious
 200000
 400000
 600000
 800000
 1e+06
Number of nodes in the DHT
 5
 5
 4
 4
 3
 3
 2
 2
 1
 1
]
]
%
%
[
[
s
s
r
r
e
e
e
e
p
p
f
f
o
o
n
n
o
o
i
i
t
t
c
c
a
a
r
r
F
F
 0
 0
0
0
FTs of honest peers
FTs of malicious peers
100000
100000
200000
200000
300000
300000
400000
400000
500000
500000
Means
Means
Figure 2: Malicious nodes respond with collaborating nodes
closest to the search value
Figure 4: Finger table analysis: malicious nodes change 4 en-
tries
Thus, even aggregated greedy search without explicitly telling
the search value does not offer enough protection: an adversary can
still learn x, eclipse the searcher and guide him into a cluster con-
sisting of malicious nodes only. Therefore, we need one additional
building block.
5.3 Bounds Checking in Finger Tables
The success of the active attack described in the previous section
is based on the fact that colluding nodes can provide arbitrary other
nodes in their FTs. In order to mitigate this, we utilize properties of
DHTs with a deterministic choice of peers in the FT. Chord is one
such DHT. In Chord, the ith ﬁnger of a node with ID m is supposed
to point to the node whose ID is closest to m+ 2i−1. Since v knows
the IDs of the nodes it queries, it can calculate these values and
compare them to the actual ﬁnger table values in the responses it
receives.
Since we already retrieve and have the whole FT, the check can
be performed “for free” – without transmitting any additional in-
formation. In contrast to earlier approaches [17, 5], we do not only
check the ﬁnal result of the query, but all the intermediate steps.
As our evaluation shows, this signiﬁcantly improves the success
probability.
We propose to perform bounds checking in ﬁnger tables as fol-
lows. Each peer calculates means of the distance between the ac-
tual IDs in its FT and optimal IDs (as if all IDs would exist). Let
us denote this as a mean distance. The mean distance is further
multiplied with a factor – we call it FT tolerance factor.
The search is now modiﬁed as follows: in each iteration, FTs are
only accepted and considered for ﬁnding the log2(n) nodes closest
to x, if they pass the FT test. The test yields a positive result if and
only if the mean distance of the considered FT is smaller than the
average sampled mean distance of the own FT times the tolerance
factor.
Figures 3 and 4 show differences in the mean distances of honest
and colluding nodes’ FTs. While Figure 3 shows the case where
malicious nodes change 10 honest node entries to malicious one, in
Figure 4 only 4 entries are changed. Malicious nodes change their
entries from the actual value to the malicious node closest to this
value. This is the best strategy for them to make the FT still look
plausible.
Since there are 100,000 nodes in the considered scenario, on
average there are 16 nodes in each ﬁnger table. We see that the
mean distance is clearly distinguishable when many FT entries are
changed, and becomes closer and less distinguishable when only a
few entries are modiﬁed. Even though this ﬁnding is obvious, the
real values give an intuition to which extent the FTs of malicious
nodes can be changed while still successfully passing the FT check
test.
Figure 5 shows the inﬂuence of the FT tolerance factor on false
145Factor influence (100,000 Peers, 20% malicious)
Honest nodes rejected
Found malicious nodes
leading information by taking into account FTs of close-by honest
nodes. We conjecture that this combination could probably deter
eclipse attacks even without hiding the search value, but we keep
this feature because it does not cost us anything at this point and
might be useful against information leakage attacks (see Section 6
for more details).
]
%
[
n
o
i
t
c
a
r
F