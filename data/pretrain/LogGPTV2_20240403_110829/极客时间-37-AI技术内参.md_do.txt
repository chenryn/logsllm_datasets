## 论文的核心方法 {#130.html#-}了解了这篇文章的目的和贡献，接下来，我就来剖析一下作者们提出的方法。首先，需要**将安卓的程序代码转换为可以分析的形式**。一般来说，安卓的软件被打包为后缀名为Dex 的 Dalivik执行文件，这个执行文件无法被直接分析。于是，需要把这个执行文件通过一个叫**Smali** 的反汇编器解析成 Smali 代码。这个时候，软件的语义就能够通过Smali 代码来解析了。作者们从 Smali 代码中提取所有的 API 调用，通过对 API的分析来对程序行为建模。下一步，就是要**从繁复的 API调用中摸索出这里面的规律**。作者们这个时候构建了**四类矩阵**来表达 API和某个 App 之间的基本特征：1.  某一个 App 是否包含了某一个 API；2.  某两个 API 是否同时出现在某一段代码中；3.  某两个 API 是否出现在同一个 App 中；4.  某两个 API 是否使用了相同的调用方法。可以看出，这些矩阵可以抓住 API 和 App之间的一个基本信息，还可以抓住一系列 API同时出现进行某种操作的特征信息。这些矩阵成了发现高阶规律的基础。为了发现更加复杂的规律，作者们在这里引入了一个工具叫**异构信息网络**。异构信息网络的概念最早由伊利诺伊大学香槟分校的数据挖掘权威韩家炜（JiaweiHan）和他当时的学生孙怡舟（YizhouSun，目前在加州大学洛杉矶分校任教）提出。异构信息网络的核心思想就是希望能够表达一系列实体（Entity）之间的复杂规律。传统的方法把实体表达成图（Graph）的节点，实体之间的关系表达成节点之间的链接。这样的方式忽略了实体本身的不同以及关系的类型也有所不同。异构信息网络就是更加完整和系统地表达多种不同实体和实体关系的一种建模工具。在这篇文章中，有两类实体：App和 API调用，有四类关系（和刚才定义的矩阵相同）。而刚才定义的矩阵其实就是这四类关系所对应的图的邻接矩阵。把 App 和 API的关系描述成为异构信息网络以后，下面的工作就是**定义更高阶的规律关系**。为了更好地定义这些复杂关系，作者们使用了一个叫**元路径**（Meta-Path）的工具。元路径其实是提供一个描述性的模板语言来定义高阶关系。比如，我们可以定义一个从 App 到 API 再到 App 的"路径"，用于描述两个 App可能都含有相同的 API调用。这个路径就可以帮助我们从最开始的四个矩阵推出更加复杂的矩阵来表达一些信息。那么，根据人们的领域知识（这里就是安全领域），作者们就定义了多达**16种元路径**，从而全面捕捉 App 和 API 之间的各种关系。利用异构信息网络和元路径构建了程序的语义表达后，下一步就是**进行恶意软件的判别**。这里，作者们采用了多核学习的思想。简而言之，就是把之前通过元路径所产生的新矩阵看作一个"核"。这里的多核学习就是要学习一个线性的分类器，特征是每个App到某一个核的一个非线性转换，这个转换是在学习过程中得到的。换句话说，这个多核学习的流程要同时学习一个分类器来判断一个程序是不是恶意程序，还需要在这个过程中学习从App 到核的转换。
## 方法的实验效果 {#130.html#-}作者们使用了科摩多的数据集，收集了 2017 年两个月里 1834 个 App的信息。正常程序和恶意程序几乎各一半。另外还有一个数据集包含 3 万个 App信息，也几乎是正例负例各一半。从实验结果来看，结合了 16个定义好的元路径的多核学习能够**实现高达 98% 的 F1 值**。F1值可以认为是精度和召回的一个平衡，同时**准确率也是高达 98%**。文章还比较了一些其他比较流行的方法，比如神经网络、朴素贝叶斯（NaïveBayes）分类器、决策树以及支持向量机，这些方法基本的 F1 值都在 85% 和 95%之间，和文章提到的方法有较大差距。另外，文章还和现在的一些商业软件，比如Norton、Lookout、CM 做了比较。这些商业软件的准确度也在 92%上下徘徊。因此，文章所采用的方法的确比之前的很多方法都更有效果。
## 小结 {#130.html#-}今天我为你讲了 KDD 2017年的最佳应用类论文。这篇论文提出了，如何来分析安卓手机软件的行为进而检测手机应用是否是恶意软件。一起来回顾下要点：第一，简要介绍了这篇文章的作者群信息。第二，详细介绍了这篇文章要解决的问题以及贡献。第三，简要分析了文章提出方法的核心内容。总结一下，文章解决的问题就是如何有效监测安卓手机系统下的恶意软件，主要贡献是提出了一种新的基于结构性异构信息网络的方法，来理解安卓程序的语义。使用元路径的工具定义复杂关系，还采用了多核学习的方法完成恶意软件的判别。论文使用科摩多的数据集，验证了所提出的方法比当下流行的一些其他方法都更加有效。最后，给你留一个思考题，文章中提到的多核学习方法这个步骤，是不是必需的？能否换成其他方法呢？欢迎你给我留言，和我一起讨论。拓展阅读：[HinDroid: An Intelligent Android Malware Detection SystemBased on Structured Heterogeneous InformationNetwork](http://delivery.acm.org/10.1145/3100000/3098026/p1507-hou.pdf?ip=104.245.8.202&id=3098026&acc=OPENTOC&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E054E54E275136550&CFID=824613284&CFTOKEN=25201339&__acm__=1509500476_9d244f060207e966c107eb505646ed55)![](Images/5f1a3d2ca933c759573c72ee2ba198b7.png){savepage-src="https://static001.geekbang.org/resource/image/ef/b2/efd991ee74e55356bb2776f3d8d375b2.jpg"}
# 015 \| 精读2017年EMNLP最佳长论文之一自然语言处理实证方法会议**EMNLP**（Conference on Empirical Methods inNatural LanguageProcessing），是由国际计算语言学协会**ACL**（Association forComputational Linguistics）的专委会**SIGDAT**（Special Interest Group onLinguistic Data and Corpus-based Approaches toNLP）主办，每年召开一次，颇具影响力和规模，是自然语言处理类的顶级国际会议。从1996 年开始举办，已经有 20 多年的历史。2017 年的 EMNLP 大会于 9 月 7日到 11 日在丹麦的哥本哈根举行。每年大会都会在众多的学术论文中挑选出两篇最具价值的论文作为最佳长论文（BestLong Paper Award）。 今天，我就带你认真剖析一下 EMNLP今年的最佳长论文，题目是《男性也喜欢购物：使用语料库级别的约束条件减少性别偏见的放大程度》（MenAlso Like Shopping: Reducing Gender Bias Amplification usingCorpus-level Constraints）。这篇文章也是很应景，近期学术圈对于数据和机器学习算法有可能带来的"**偏见**"（Bias）感到关切，有不少学者都在研究如何能对这些偏见进行评估、检测，进而可以改进甚至消除。
## 作者群信息介绍 {#131.html#-}第一作者赵洁玉（JieyuZhao），论文发表的时候在弗吉尼亚大学计算机系攻读博士学位，目前，已转学到加州大学洛杉矶分校，从事如何从机器学习算法中探测和消除偏见的研究。之前她从北京航空航天大学获得学士和硕士学位，曾于2016 年在滴滴研究院实习。第二作者王天露（TianluWang）也是来自弗吉尼亚大学计算机系的博士生，之前在浙江大学获得计算机学士学位。第三作者马克·雅茨卡尔（MarkYatskar）是来自华盛顿大学的计算机系博士生，已在自然语言处理以及图像处理领域发表过多篇高质量论文。第四作者文森特（VicenteOrdóñez）目前在弗吉尼亚大学计算机系任助理教授。他的研究方向是自然语言处理以及计算机视觉的交叉学科。他于2015年从北卡罗来纳大学教堂山分校计算机系博士毕业。博士期间，他在微软研究院、eBay研究院以及谷歌都有过实习经历。他是第二作者王天露的博士导师。文章最后一位作者是 Kai-WeiChang，也是第一作者赵洁玉的导师。他目前在加州大学洛杉矶分校任助理教授，之前在弗吉尼亚大学任职。他于2015 年从伊利诺伊大学香槟分校博士毕业，师从著名教授丹·罗斯（DanRoth）。在之前的研究生涯中，曾先后 3次在微软研究院实习，也在谷歌研究院实习过。在他研究的早期，曾参与了LibLinear 这个著名支持向量机软件的研发工作。
## 论文的主要贡献 {#131.html#-}机器学习的一个重要任务就是通过数据来学习某些具体事项。最近机器学习的研究人员发现，数据中可能蕴含着一些社会赋予的偏见，而机器学习算法很有可能会放大这些偏见。这种情况在自然语言处理的相关任务中可能更为明显。比如，在一些数据集里，"做饭"这个词和"女性"这个词一起出现的比例可能要比和"男性"一起出现的比例高30%，经过机器学习算法在这个数据集训练之后，这个比例在测试数据集上可能就高达68%了。因此，虽然在数据集里，社会偏见已经有所呈现，但是这种偏见被机器学习算法放大了。因此，**这篇文章的核心思想就是，如何设计出算法能够消除这种放大的偏见，使得机器学习算法能够更加"公平"**。注意，这里说的是消除放大的偏见，而不是追求绝对的平衡。比如，我们刚才提到的数据集，训练集里已经表现出"女性"和"做饭"一起出现的频率要高于"男性"和"做饭"一起出现的频率。那么，算法需要做的是使这个频率不会进一步在测试集里升高，也就是说，保持之前的30%的差距，而不把这个差距扩大。这篇文章并不是追求把这个差距人为地调整到相同的状态。文章提出了一个**限制优化（ConstrainedOptimization）算法**，为测试数据建立限制条件，使机器学习算法的结果在测试集上能够得到和训练集上相似的偏见比例。注意，这是对已有测试结果的一个调整（Calibration），因此可以应用在多种不同的算法上。作者们使用提出的算法在两个数据集上做了实验，得到的结果是，新的测试结果不但能够大幅度（高达30% 至40%）地减小偏见，还能基本保持原来的测试准确度。可见，提出的算法效果显著。
## 论文的核心方法 {#131.html#-}那么，作者们提出的究竟是一种什么方法呢？``{=html}首先，引入了一个叫"**偏见值**"（BiasScore）的概念。这个值检测某一个变量和目标变量之间的比例关系。例如，"男性"这个词和某个动词（比如之前我们举了"做饭"）一起出现的比例关系以及"女性"这个词和同一个动词一起出现的比例关系。注意，因为"男性"和"女性"都是"性别"的可选项，因此，这两个词对于同一个动词的比例关系的和一定是1。偏见值在训练集上和测试集上的差别，构成了衡量偏见是否被放大的依据。在之前的例子中，"女性"和"做饭"一起出现的的偏见值在训练集上是0.66，而到了测试集则变成了 0.84，这个偏见被算法放大。有了偏见值这个概念以后，作者们开始**为测试集的结果定义限制条件**（Constraint）。这里的一个基本思想就是，要对测试集的预测标签进行重新选择，使测试标签的预测结果和我们期待的分布相近。用刚才的例子就是说，我们要让"女性"在"做饭"这个场景下出现的可能性从0.84 回归到 0.66附近。能够这么做是因为这个算法需要对测试结果直接进行调整。对所有的限制条件建模其实就变成了一个经典的限制优化问题。这个问题需要对整个测试数据的预测值进行优化，那么，这个优化就取决于测试数据集的大小，往往是非常困难的。于是，作者们在这里采用了**拉格朗日简化法**（LagrangianRelaxation）来对原来的优化问题进行简化。也就是说，原来的限制优化问题经过拉格朗日简化法后，变成了非限制优化问题，原来的算法就可以成为一个动态更新的过程。针对每一个测试用例，都得到当前最优的标签更改方案，然后又进一步更新拉格朗日参数，这样对整个测试数据集遍历一次后算法就中止了。