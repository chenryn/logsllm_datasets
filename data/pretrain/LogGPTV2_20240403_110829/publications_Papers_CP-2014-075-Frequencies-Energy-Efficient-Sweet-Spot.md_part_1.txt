Sebastian Gotz, Thomas Ilsche, Jorge Cardoso, Josef Spillner, et. al., Frequencies Energy-Efficient Data
Processing at Sweet Spot. In On the Move to Meaningful Internet Systems (OTM 2014). Amantea,
Italy, 2014.
Energy-Efficient Data Processing
at Sweet Spot Frequencies
Sebastian Götz1, Thomas Ilsche1, Jorge Cardoso2, Josef Spillner1,
Uwe Aßmann1, Wolfgang Nagel1, and Alexander Schill1
1 Technische Universität Dresden, Germany
2 University of Coimbra, Portugal
{sebastian.goetz1|thomas.ilsche|josef.spillner|
uwe.assmann|wolfgang.nagel|alexander.schill}@tu-dresden.de,
PI:EMAIL
Abstract. The processing of Big Data often includes sorting as a ba-
sicoperator.Indeed,ithasbeenshownthatmanysoftwareapplications
spend up to 25% of their time sorting data. Moreover, for compute-
bound applications, the most energy-efficient executions have shown to
use a CPU speed lower than the maximum speed: the CPU sweet spot
frequency.Inthispaper,weusethesefindingstorunBigDataintensive
applications in a more energy-efficient way. We give empirical evidence
thatdata-intensiveanalytictasksaremoreenergy-efficientwhenCPU(s)
operate(s) at sweet spots frequencies. Our approach uses a novel high-
precision, fine-grained energy measurement infrastructure to investigate
theenergy(joules)consumedbydifferentsortingalgorithms.Ourexper-
iments show that algorithms can have different sweet spot frequencies
forthesamecomputationaltask.Toleveragethesefindings,wedescribe
howanewkindofself-adaptivesoftwareapplicationscanbeengineered
to increase their energy-efficiency.
1 Introduction
Electricity used in global cloud data centers likely accounts for between 1.1%
and 1.5% of total electricity use. IDC3 estimates that the digital universe of Big
Data will double every two years, reaching 40,000 exabytes in 2020. This large
volumeofdatawillrequirecomplexanalyticsprocessingapplications,whichwill
necessitate massive processing power.
This state of affairs calls for the development of new approaches to reduce
energy consumption [1], which has already led researchers to develop new hard-
wareandsoftwarearchitectures,virtualmachinemigrationstrategies,andwater
cooling mechanisms.
SinceanalyticalapplicationsforBigDatarelyheavilyontheperformanceof
data-intensivetaskssuchasdataaggregation,datasorting,anddataformatting,
3 http://www.emcchannel.com/collateral/analyst-reports/
idc-the-digital-universe-in-2020.pdf
in this paper we look into new techniques to make these tasks more energy-
efficient. While making, e.g., the task of data sorting 5% more energy-efficient
seems a marginal achievement, this value needs to be contextualized (see [2]).
Facebookgeneratesmorethan5petabytesofnewdataonadailybasis;LinkedIn
generatedmorethan5billionsearchesin2012;Twittergeneratesmorethan500
million tweets a day; and Cisco forecast for global mobile data traffic (2013-
2018)4 estimates that traffic will grow at a compound annual growth rate of
78% to 2016, reaching 10.8 exabytes per month. Clearly, reducing in 5% the
required energy of a data-intense sorting task translates into large savings.
Ourapproachinvolvesexecutingsortingalgorithmsundervariousconfigura-
tions (e.g., the number of elements to sort and the CPU frequency) and evalu-
ating which sweet spots of the underlying hardware architecture enables a more
energy-efficient execution. The data obtained was used to construct a task pro-
file, which then resulted in a predictive model to determine at which frequency
a CPU should be clocked to run a specific data-intensive sorting task most effi-
ciently. We show how to automate the detection of sweet spots and their use to
develop self-adaptive software, which automatically selects the CPU frequency
to execute algorithms based on sweet spots and energy objectives to reach. Our
approach is based on two previous findings:
1. It has been shown that for certain computational applications, the most
energy-efficientexecutionisachievedusingtheCPUsweetspotfrequency,a
CPU frequency setting that is often between the minimum and maximum.
2. It has been shown that software applications spend up to 25% of their time
sorting data.
1) It is already known from previous academic and industrial research that
processorsdonotfollowaproportionalpath.Singleprocessorshavepowerstates
andassociatedfrequenciesforwhichtheenergy-efficiency,i.e.,theratiobetween
utilizationandenergyconsumptionismaximizedinso-calledsweetspots[3]and
often minimized in high-performance turbo mode [4, 5]. Furthermore, in multi-
processorsystems,additionaloverlapeffectsresultfromusingtheturbomodeas
a gap-filler before switching on the next core when the utilization increases [6].
This effect, in particular the sweet spot, translates into time-dependent energy
efficiency due to Dynamic Voltage Frequency Scaling (DVFS; a commonly used
power-management technique).
2) More than 25% of the running time of many applications has at some
point been spent on sorting [7]. While more recent results are missing from the
literature,itisexpectedthattheprocessingofBigDatawillplaceanevengreater
emphases on sorting. In their approach, Herodotou et al. [8] also use sorting
algorithms to evaluate the performance of systems for Big Data analytics since
“theyaresimple,yetveryrepresentative”.Otherdata-intensivetasksofinterest,
but not explored in our work, include search and indexing over large volumes of
data.
4 http://www.cisco.com/c/en/us/solutions/collateral/service-provider/
visual-networking-index-vni/white_paper_c11-520862.html
Among our results, we determined that the automated detection and use
of sweet spot frequencies reduces energy consumption by up to 25% and that
data-intensive tasks can be designed as self-adaptive applications to exploit the
benefitsofsweetspots.Ourfindingscancontributetothedevelopmentofenergy-
efficient analytics applications and databases for Big Data, since they operate
onlargeamountsofdataandheavilyrelyonthetaskofsortingtoprocessdata.
Thispaperisstructuredasfollows.Sect.2enumeratesthreecentralresearch
questions that are addressed throughout this paper. Sect. 3 describes our ap-
proach and the methodology we have followed to experimentally analyze the
energy-efficiencyofdata-intensiveprocessingtasks.Wediscusstheresultsofour
experiments in Sect. 4 and show in Sect. 5, how these findings can be used,
to build self-adaptive software, able to leverage this knowledge to save energy.
Finally, Sect. 6 and 7 present related work and our conclusions, respectively.
2 Research Questions
Theenergy-efficiencyofdata-intensiveprocessingtaskslooksintohowsoftware,
the underlying computing system and the environment affect energy consump-
tion. Our research questions (RQ) are the following:
– RQ1 (Measurement Setup). How to instrument a computing system with
measurement devices to obtain fine-grained measurements for its individual
parts (e.g., fan, disk, power supply, and CPU sockets)? (Sect. 3.1).
– RQ2 (Sweet spots). How can sweet spot frequencies contribute to improve
theenergy-efficiencyofdataprocessingtasks?Whichmathematicalfunctions
characterize them? (Sect. 4).
– RQ3(DynamicSoftwareAdaptation).Howtoexploresweetspotstodynam-
ically adapt software to achieve a higher energy-efficiency? (Sect. 5).
Inthispaper,westudyhowdifferentimplementationsofalgorithmstypically
usedbydata-intensivetasksaffectdifferentlytheenergyefficiencyofacomputing
system. We take the computational task of sorting n numbers, as it represents
a common use case for Big Data analytics.
Whileresearchhaslookedintohowtomakeinformationandcommunication
technologies more energy-efficient, it is rather hard to find a precise definition
for software energy-efficiency. Thus, to remove any possible ambiguity on the
results of our research, we define the concept as follows:
Definition 1 (Software energy-efficiency) Energy is defined as the amount
of joules, required by a full or partial computing environment, to execute a soft-
ware application. A software application S is said to be more energy-efficient
1
than an application S , if it requires less energy to accomplish the same compu-
2
tational task.
Definition 2 (Computing environment) A full computing environment in-
cludes all the devices that, directly or indirectly, consume energy to enable a
software application to be executed. For example, it typically includes CPUs,
fans, and disks. A partial computing environment only includes a subset of those
devices.
3 Approach and Methodology
Computational complexity (i.e., big O notation) is often a first step in assessing
theperformanceofanalgorithm.However,inpractice,thebestbigOalgorithm
may perform worse due to, e.g., physical memory constraints. Quicksort is such
anexamplesinceisoftenusedeventhoughitdoesnothavethebestbigO(worst
case) performance. It is common practice to optimize implementations for run-
time and, in most cases, optimizations will also reduce energy consumption.
However, in recent hardware with increasing energy-efficiency features, such as
DVFS, the fastest algorithm is often no longer the most energy-efficient one.
Our approach to gain insights is experimental. We use energy as a main
optimization goal and vary the algorithm and hardware configuration for com-
parison. The methodology has the following activities:
– Measurement environment (Sect. 3.1).
• Instrument server with energy sensors.
• Determine static power consumption of the server.
• Setup software infrastructure to conduct the experiments.
– Software under test (Sect. 3.2).
• Selectthedata-intensivecomputationaltasktobetestedexperimentally.
• Select different software implementations for the task.
– Experimental results analysis (Sect. 4).
• Determine resources affected by task.
• Interpret measurement results.
– Generalization and application of the results (Sect. 5).
3.1 Measurement Setup: Energy Monitoring
Hardware The system under test is a dual socket system with Intel Xeon
E5-2690 processors. Several layers of power measurement instrumentation are
required. The complete AC input is measured with a calibrated ZES Zimmer
LMG450 power analyzer. Several custom-built, shunt-based sensors are added
to the system. All sensors are pluggable via Molex connectors used in many
standardized systems. For this paper, we monitor the 12V input of the two in-
dividualsocketsseparately.TheysupplypowerfortheCPUsandtheirattached
memory. The voltage drop over the measurement shunt is amplified with cal-
ibrated amplifiers and digitally captured by a National Instruments PCI-6255
data acquisition board with 7541 samples per second. The power consumption
is computed digitally from individual readings for current and voltage. During
the experiment, all data processing happens on a separate system to avoid per-
turbation of the system under test. This measurement infrastructure serves as
an answer to RQ1, but requires significant effort, as described in [9].
052
002
]W[
rewoP
051
CA
001
1.32925:50202:0e0+12 1.395522e+1222:00:011.395522e+12 1.32925:50202:0e2+1
TimeofDay[HH:mm:ss]
Fig.1. Energy trace of two succeeding sorting invocations with idle phase.
The processors provide 15 different frequencies from 1.2 to 2.9GHz and the
turbo mode with frequencies up to 3.8GHz, depending on thermal and power
budget. Both, frequency and voltage are set uniformly for all cores of a socket
by the hardware. As demonstrated in [10], the available memory bandwidth
dependsonthecorefrequencyfortheSandyBridge-EParchitecture.EarlierIntel
architectures,suchastheoneusedin[3],providedaconstantmemorybandwidth
independent of the selected frequency. The variable memory bandwidth did not
allow for a straight-forward selection of the optimal frequency for applications
thatbecomememory-boundatacertainfrequency.However,ourapproachdoes
not require specific bottleneck analysis, because it uses the energy measurement
results to select among different settings instead.
Measurements Toinvestigatetheenergyconsumptionofdata-intensivetasks,
we run different sort algorithms for different input sizes multiple times. Prior
to each invocation, we randomly generate integer lists to be sorted. Across all
invocations, we used lists of sizes between 10 and 50 million elements, always
containing integers with a value range of 6 million (i.e., 0≤x<6×106). Each
invocationisprecededbyapauseof1secondto“cooldown” theCPUandother
resources (i.e., let them switch to idle mode).
Measurements of sort invocations utilizing a single core of a multi-core ma-
chinearenotrepresentative,duetothestaticpowerconsumptionofotherdevices
besidestheCPU,whichdoesnotchange,regardlessofhowmanycoresareused.
Hence, we fully utilized all cores of the machine with a separate sort invocation
operating on a copy of the same list. By using MPI barriers [11], we ensure that
allsortinvocationsarestartedatthesametime.Asexecutiontime,wemeasured
the longest duration of the parallel sort invocations and ensured that variation
of durations among parallel processes was less than 5%.
Fig. 1 visualizes the invocation scheduling by AC power consumption (i.e.,
at the wall) over time for two consecutive sort invocations. The spikes at the
beginning and end of each invocation are due to (MPI) synchronization. The
short period of 250W in each run denotes the list generation.
As shown in Table 1, the static power consumption of the server originates
from the power supply, the fan, the motherboard, the disk, and the sockets.
Power supply & FansBoardSSD Sockets Total
≈26W ≈7W ≈1W≈20W × 2 ≈74W
Table 1. Static idle power consumption of the server.
For the investigation of the effect of different CPU frequencies on the timing
and energy-efficiency of sorting, we used the userspace CPU governor of Linux
toexplicitlysetthefrequencyoftheCPU.Linuxalsooffersthegovernorsperfor-
mance and powersave that statically select the highest/lowest frequency within
the borders of a setting. The ondemand governor changes the frequency based
on CPU usage. In our use case of continuously sorting, the CPU usage will be
at 100% for the active cores. Therefore, the ondemand governor will eventually
select the highest frequency.
Weexecutedlistgenerationandsortingforthreealgorithmswithdifferentlist
sizesforallpossiblefrequenciesoftheCPUandtheturbomode.Wecollectedthe
totalenergyconsumptionoftheserverperexecution,theenergyconsumptionof
the sockets, and the response time. This enables to investigate whether a sweet
spot frequency exists and if static power consumption leads to a shift of the
sweet spot frequency for sockets, only compared to the whole server.
3.2 Software Setup: Sorting Algorithm
As mentioned before, data analytics over Big Data are a key target for energy
efficiency with huge absolute savings, even for small percentages in relative sav-
ings. These systems are very complex and rely heavily on computational tasks
such as data cleansing, data aggregation, data sorting, and data formatting. We
suggest to study a well-known and representative algorithm: sorting. In many
applications,morethan25%oftherunningtimeofcomputershasatsomepoint
been spent on sorting [7].
We selected two stable sort implementations: counting sort and radix sort.
Wealsolookedatthenon-stablesortingoftheC++StandardLibrary:std::sort.
CountingsortisastablesortingalgorithmwithalineartimecomplexityofO(n).
RadixsortperformsO(n×log (n))comparisons[12].Ourimplementation(GNU
2
libstdc++) uses a combination of intro sort and insertion sort.
Based on this knowledge about the time complexity of sorting algorithms,