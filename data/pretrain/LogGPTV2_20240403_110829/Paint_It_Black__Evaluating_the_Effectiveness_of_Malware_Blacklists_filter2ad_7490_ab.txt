domains are directly accessed without specifying any subdomains. For benign
domains, automated redirection to the common www subdomain is often enforced.
Parked domains, in contrast, typically do not exhibit similar behavior.
Our second feature is based on the observation that parked domains deliver
similar content on random subdomains and the domains itself while benign do-
mains tend to serve diﬀering content for arbitrary subdomains (if at all). We
measure the normalized Levenshtein ratio [27] between the HTML content gath-
ered by accessing the domain and a randomly generated subdomain. If the HTTP
request for the subdomain failed (e.g., due to DNS resolution), the feature is set
to -1, otherwise the value is in the range from 0 (no similarity) to 1 (equal).
The ﬁrst HTML-based feature is derived from the observation that many
parked domains display sponsored ads while the textual content is negligible.
Contrary, most benign domains deliver a substantial amount of human-readable
content in the form of coherent text fragments. Our third feature thus deﬁnes
6
M. K¨uhrer, C. Rossow, and T. Holz
the ratio of human-readable text in relative to the overall length in returned web
content after removing HTML tags, JavaScript codes, and whitespaces.
Next, we outline three features to express the techniques that landing pages
utilize to embed parking content. That is, we account for the observation that
most parked domains use JavaScript or frames to display sponsored ads. In the
fourth feature, we measure the ratio of JavaScript code. In the ﬁfth feature, we
count the number of  tags on landing pages. As many page templates
utilizing frames contain only the basic HTML structure and the frameset, the
frame count is particularly powerful in combination with the ratio of human-
readable text (feature 3). A fraction of parked domains, however, do not rely on
JavaScript or frames and directly embed the referral links into the HTML code.
We observed many of these parking providers to specify rather long attributes
in the referral  tags (e.g., multiple mutual IDs in the href attribute).
As parked domains tend to serve numerous referral links, the average length of
 tags is expected to be considerably higher than in content served by
the majority of benign domains, as expressed in the sixth feature.
The seventh feature is deﬁned by the robots value speciﬁed in the  tag.
Parked domains in our dataset either did not specify a robots value (thus us-
ing the default index + follow) or deﬁned one of the values index + nofollow,
index + follow, or index + follow + all. Parking providers monetize the do-
mains and are interested in promoting their domains, thus permitting index-
ing by search engines. In contrast, benign sites often customize the indexing
policies—we identiﬁed 31 diﬀerent robots values. As the robots value is a con-
catenation of tokens, we mapped all possible single tokens to non-overlapping
bitmasks and use the numerical value of the bit-wise OR of all tokens as feature.
Most parking services rely on JavaScript to display referral links and adver-
tisements. The HTML-based features (3 - 7) thus require JavaScript execution
when aggregating the feature values. As the initially served content before ex-
ecuting JavaScript and the ﬁnal content after executing JavaScript both are
characteristic for parked domains (and might be entirely diﬀerent, e.g., when
JavaScript is used for redirection), we obtain two feature values for each of the
HTML-based features accordingly, resulting in 12 feature values per domain.
We use these 12 feature values to classify domains as either parked or benign
(i.e., non-parking). We evaluated our approach for diﬀerent types of machine-
learning algorithms using RapidMiner [21, 28] and achieved the best results for
support vector machines (SVMs) using the Anova kernel [29].
3.3 Evaluation
Cross-Fold Validation. We evaluate the feature set with a 10-fold cross val-
idation using all domains in our benign B and parking P sets and achieve an
average detection rate of 99.85% correctly classiﬁed domains while the false pos-
itive (FP) rate is at 0.11% and the false negative (FN) rate at 0.04%.
Individual Dataset. To evaluate our approach on an individual dataset and
discuss false positives and negatives as suggested by Rossow et al. [30], we split
Paint It Black: Evaluating the Eﬀectiveness of Malware Blacklists
7
the 10,000 labeled benign and parked domains into a training set ST rain consist-
ing of 1,000 benign and 1,000 parked domains and a test set ST est that includes
the remaining 8,000 domains. The resulting detection model correctly classiﬁes
7,969 domains in ST est (99.6%) as benign or parked, resulting in 5 FPs (0.1%)
and 26 FNs (0.3%). When investigating the FPs, we ﬁnd each domain to have a
ratio of less than 20% for human-readable text (feature 3) in combination with a
high average length of  tags (feature 6). Further, all domains respond
to random subdomain requests and serve similar web content (i.e., the normal-
ized Levenshtein ratio ≥ 0.9). When analyzing the 26 FNs, we ﬁnd domains that
either switched between redirecting to parking and benign content or delivered
parking content on the second visit. As we visited each domain only once during
feature attribution, we did not observe parking behavior for these domains.
Real-World Data. Finally, we verify our approach on real-world data con-
taining signiﬁcantly more unlabeled domains. We obtained the Top 1M domains
from the Alexa Ranking 12 weeks after the Top 5k domains were gathered for
the benign set B. We expect only a few parked domains in this dataset, thus
we mainly are interested if our approach can handle the diverse page structures
of benign web pages without high FP rates. We could aggregate feature values
for 891,185 domains while the remaining domains either did not resolve to IP
addresses or provide web content within a time frame of 15 seconds, respectively,
replied with blank content or HTTP error codes. We further remove 957 domains
already covered by ST rain, thus the resulting set SAlexa is deﬁned by 890,228
domains. We then match the content of each domain against the IDs and landing
pages introduced in Section 3.1 to estimate a lower bound of FPs and FNs. We
cannot ensure the correctness of the IDs, hence might erroneously ﬂag benign
domains as parked. We thus manually verify potential false classiﬁcations.
Subset
Size
ID
CL
71
28
Rates (%)
Parked (#)
CD FP
FN
INT # FI # New
SAlexa 890,228 5,208 8,709 4,596
SCurrent 33,121 3,747 5,623 3,027
Table 2. Results of SAlexa and SCurrent (Parked = Domains
ﬂagged as parked by IDs or classiﬁer (CL), INT = Intersection of do-
mains ﬂagged as parked by IDs and CL, FI = Domains falsely ﬂagged as
parked by IDs, New = Domains detected by CL but not found by IDs)
As shown in Ta-
ble 2, we achieve
a correct detection
rate (CD; the sum
of true positive and
true negative rate)
of 99.5%, a FP rate
of 0.4%, and a FN
rate of 0.1%. The
IDs ﬂag 5,208 do-
mains as parked, yet we ﬁnd 71 of the domains to be incorrectly ﬂagged. The
classiﬁer marks 8,709 domains as parked of which 4,596 domains are veriﬁed by
the IDs. Of the remaining domains we ﬁnd 626 to be parked that are not detected
by the IDs, resulting in 5,222 parked domains detected by the classiﬁer. These
results indicate that 0.6% of the Alexa 1M domains, i.e., more than 1/200 of
the most popular domains, are parked. More speciﬁcally, we identify 36 parked
domains in the Alexa Top 10k while 432, respectively, 1,170 domains are parked
in the Top 100k and Top 250k, showing that the majority of parked domains
are not ranked in the Top 250k Alexa. During the manual veriﬁcation process,
626
0.1
2,336 (98.7) 0.8 (0.5)
99.5 0.4
8
M. K¨uhrer, C. Rossow, and T. Holz
we ﬁnd the vast majority of parked domains to be associated to domain resellers
such as Above, GoDaddy, and Sedo [21].
We now turn back to our original goal, i.e., classifying the content of blacklists.
We thus extracted currently blacklisted domains from our blacklist set SMal
twelve weeks after generating the benign B and parking P sets used for ST rain.
We name this dataset SCurrent and again remove domains already included in
ST rain. Of the 158,648 currently listed domains, we obtained feature values for
33,121 domains. The remaining domains either were unregistered or replied with
HTTP error codes. The classiﬁer deﬁnes 5,623 domains as parked, of which 3,027
domains are veriﬁed by the IDs. When manually investigating the remaining
2,596 domains ﬂagged by the classiﬁer, we identify 2,336 parked domains not
detected by the IDs and 260 FPs (0.8%). The FPs are mostly caused by adult
content and web directory sites with similar characteristics as parked domains.
When taking a closer look at the initial high number of 692 FNs, we ﬁnd 538
domains not serving parking content at all (i.e., referral links). More precisely,
one domain reseller causes most of the FNs, as we identify 506 domains (73.1% of
all FNs) redirecting to hugedomains.com, providing web content not exhibiting
common parking behavior. To evaluate if our approach fails to detect domains
associated with this reseller due to missing training data, we adjusted ST rain
to cover a partition of these domains and ﬁnd the detection model to correctly
classify these domains as parked, reducing the FN rate to 0.5%.
4 Sinkholes
Next to parking domains, also so called sinkholing servers (sinkholes) are promi-
nent types of blacklist entries. Sinkholes are operated by security organizations
to redirect malicious traﬃc to trusted hosts to monitor and mitigate malware in-
fections. In order to track sinkholes in our blacklist data, we ﬁrst identify intrinsic
characteristics of these servers. We thus obtained an incomplete list of sinkhole
IPs and domains by manual research and through collaboration with partners. In
pDNS, we then observed that domains associated with sinkholes tend to resolve
to the corresponding IPs for a longer period of time, thus the monitored DNS
A records are persistent. Contrary, malicious domains tend to switch to various
IPs and Autonomous Systems (AS) within a short time frame to distribute their
activities to diﬀerent providers [5]. We also found sinkholed domains switching
to other sinkholes provided by the same organization or located in the same AS,
and discovered domains that were relocated to other sinkhole providers.
Sinkhole operators often use their resources to monitor as many domains of
a malware family as possible. We thus ﬁnd sinkhole IP addresses to be typically
assigned to numerous (up to thousands of) domains. In the majority of cases,
the domains resolving to a speciﬁc sinkhole IP shared the same NS such as
torpig-sinkhole.org or shadowserver.org. We thus argue that if multiple
domains resolve to the same IP address but do not utilize the same NS, the
probability that this IP is associated with a sinkhole is considered to be low.
Paint It Black: Evaluating the Eﬀectiveness of Malware Blacklists
9
Another observation is the content sinkholes serve upon HTTP requests.
When requesting content from randomly chosen sinkholed domains using GET /
HTTP/1.1, we ﬁnd sinkholes to either not transfer any HTML data (i.e., closed
HTTP port or web servers responding with 4xx HTTP codes) or serve the same
content for all domains as monitored for zinkhole.org. We thus assume that do-
mains resolving to the same set of IP addresses but serving diﬀering content do
not belong to sinkholes and are rather linked to services such as shared hosting.
4.1 Sinkhole Identiﬁcation
Based on these insights we introduce our approach to identify sinkholes in the
blacklist datasets SC&C and SMal. The datasets consist of currently listed and
historical domains and the IPs to which any of the domains resolved to. For each
domain, we aggregate current DNS records and web content while we obtain
reverse DNS records, AS and online status details, and web content for all IPs.
Filtering Phase. In a ﬁrst step, we aim to ﬁlter IP addresses sharing simi-
lar behavior as sinkholes to eliminate potential FPs. We thus remove the IPs
associated with parking providers using the detection mechanism introduced in
Section 3. To identify IPs of potential shared hosting providers serving benign
or malicious content, we analyze the aggregated HTTP data. We deﬁne IPs to
be associated with shared hosting when we obtain varying web content (i.e.,
normalized Levenshtein ratio ≤ 0.9) for the domains resolving to the same set
of IPs. Furthermore, we expect sinkholes to be conﬁgured properly, thus we do
not consider web servers as sinkholes that delivered content such as it works.
As our datasets might include erroneously blacklisted benign domains, we
ﬁlter likely benign IPs such as hosting companies and Content Delivery Networks
with the following heuristic: we do not expect the Alexa Top 25k domains to
be associated to sinkholing servers. We thus obtained the HTTP content of
each domain, extracted further domains speciﬁed in the content, and requested
DNS A records for all domains. The resulting dataset SBenign includes 105,549
presumably benign IPs. We acknowledge that this list does not remove all false
listings in the blacklist datasets, however, this heuristic improves our data basis.
To further reduce the size of the datasets, we eliminate IPs associated to Fast
Flux with the following heuristic: we deﬁne an IP to be associated with Fast Flux
when at least 50% of the blacklisted domains currently resolving to this IP are
found to be Fast Flux domains, whereas we deﬁne a Fast Flux domain as follows:
i) the domain resolved to more than 5 distinct IPs during our observation time
and ii) at least half of these IPs were seen within two weeks. As we expect the
ratio of fast ﬂux domains associated to individual sinkhole IP addresses to be
rather low, we assume to not remove any sinkholing servers.
Graph Exploration. The actual sinkhole identiﬁcation follows the intuition
that IPs of sinkholes mostly succeed malicious IPs in the chain of resolved IPs
for a high number of domains and are persistent for a longer period of time. For
each dataset SC&C and SMal, we map this assumption onto a separate directed
10
M. K¨uhrer, C. Rossow, and T. Holz
graph G = (V, E), whereas the domains and IPs in the datasets are represented
as vertices v ∈ V . The edges e ∈ E are determined by the relationship between
the domains and IPs. We deﬁne u ∈ V to be a parent node of v when there
exists a directed edge e = (u, v) and deﬁne w ∈ V to be a child node of v when
there exists a directed edge e = (v, w). The edges e ∈ E are deﬁned as follows:
(i) For each domain v ∈ V , we add a directed edge e = (v, w) if domain v at
some point resolved to IP w ∈ V .
(ii) For each domain v ∈ V , we add an edge e = (wo, wn) if v resolved to IP
wo ∈ V , switched to a new IP wn ∈ V , and never switched back to IP wo.
In step (i), we assign the resolved IPs to each domain in our datasets. In step
(ii), we add a domain’s history of A records (i.e., resolved IPs) to the graph.
We name deg
−
(v) the in-degree of node v, resembling the number of parent
nodes. In our graph model, the in-degree represents the number of domains that
currently are or were once resolving to node v and the number of IPs preceding
v in the resolver chain. For sinkholes, the in-degree is considerably higher than
the average in-degree as sinkholes usually succeed malicious IPs in the chain of
resolved IPs and a single sinkhole IP is often used to sinkhole multiple domains.
We further refer to deg+(v) as the out-degree of node v, resembling the number
of child nodes, e.g., IP addresses that followed node v in the resolver chain. We
ﬁnd the out-degree of sinkhole IPs to be signiﬁcantly lower than the average
out-degree because sinkhole IPs are persistent for a longer period of time. As a
result, the ratio R = deg
all IP addresses v ∈ V which meet these requirements:
(i) The IP address must respond to ICMP Echo or HTTP requests.
(ii) At least D domains are currently resolving to this IP, whereas the value D
We use the resulting graph to create a list of potential sinkholes Spot by adding
deg+(v) is expected to be high for sinkholes.
−
(v)
(iii) The ratio R exceeds a threshold T , whereas T is deﬁned as the average
is deﬁned by the average number of active domains per IP in our set.
ratio of all IP addresses v ∈ V .
(iv) All domains associated with a single IP address utilize the same NS.
We then manually verify each IP in Spot whether it is a FP or associated with
a sinkhole by analyzing the utilized NS, served web content, reverse DNS record,
and AS details, and also employ a service provided by one of our collaboration
partners listing known sinkhole IPs. Veriﬁed sinkholes are added to the set Sver.
We chose these rather hard requirements as most sinkhole operators have little
incentive to disguise the existence of their sinkholes. We thus hypothesize that
this list of requirements will even hold once our sinkhole detection technique
is known. However, as we might have missed sinkhole IPs due to the strict
requirements for Spot, we explore the neighboring IP addresses of Sver in the
second phase of the sinkhole identiﬁcation. Before doing so, we extract the NS
of the domains resolving to the IPs in Sver, manually check whether the NS are
speciﬁcally used in conjunction with sinkholed domains and if so, we add the
NS to a trusted set SN S. Further on, to also detect inactive sinkholes at a later
stage, we create a mapping of trusted NS and the AS the corresponding sinkhole
s ∈ Sver is located in, deﬁned by SN S AS = {(nss, ASs) | nss ∈ SN S}.
Paint It Black: Evaluating the Eﬀectiveness of Malware Blacklists
11
Sinkhole operators might relocate domains to diﬀerent sinkholes in the same
organization and AS, thus we explore the parent and child nodes of each sinkhole
to identify yet unknown sinkholes. For each ip ∈ V , we check whether ip is a
parent or child node of a known sinkhole s ∈ Sver, whereas we only consider
IPs abiding ASip = ASs. If ip is found to be a neighboring node of at least two
sinkholes, we deﬁne ip to be a potential sinkhole and add it to Spot. Further, ip
is added to Spot when it is a parent or child node of at least one sinkhole in the
same AS and the domains resolving to both IP addresses share the same NS.
To identify sinkholes which cannot be found by exploring parent and child
nodes, we leverage the trusted name servers ns ∈ SN S. As we deﬁned these NS