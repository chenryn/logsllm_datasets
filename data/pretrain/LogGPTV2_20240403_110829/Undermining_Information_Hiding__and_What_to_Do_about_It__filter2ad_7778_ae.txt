1
2
10
446
4
26
2
2
494
10 bits
11 bits
8 bits
> 8 bits
10 bits
10 bits
11 bits
10 bits
10 bits
11 bits
10 bits
> 7 bits
> 2 bits
9 bits
> 6 bits
10 bits
10 bits
> 2 bits
99.99 % 1 GP
100.00 % 1 GP
99.96 % 1 GP
99.97 % 1 GP
99.99 % 1 GP
99.99 % 1 GP
100.00 % 1 GP
99.99 % 1 GP
99.99 % 1 GP
100.00 % 1 GP
99.99 % 1 GP
99.95 % 1 GP
97.82 % —–
99.98 % —–
99.87 % 1 GP
99.99 % 1 GP
99.99 % 1 GP
97.59 % 1 GP
4
201668 > 12 bits
28 bits
121314 > 13 bits
5813
6994
36616
99.98 %
100.00 %
99.99 %
> 17 bits 100.00 %
> 17 bits 100.00 %
> 14 bits 100.00 %
> 29 bits 100.00 %
> 13 bits
99.99 %
> 17 bits 100.00 %
> 15 bits 100.00 %
> 23 bits 100.00 %
99.98 %
2
66911
5107
20017
109
171316 > 12 bits
—–
—–
—–
—–
—–
—–
2
31673
11334
316838 > 11 bits
> 29 bits 100.00 %
> 15 bits 100.00 %
> 16 bits 100.00 %
99.97 %
Table 3: Entropy gains with our defense. VMM, PMM, EG, and DG refer to Virtual Mapped Memory, Physical Mapped Memory, Entropy Gains
and Detection Guarantees (respectively). VMM and PMM are measured in number of pages. EG is given by log2(V MM/PMM). DG is given
by (1− PMM/(V MM ∗ in f lation_ f actor))∗ 100, where the inﬂation_factor is set to default 10x for stacks and 1x for the already huge CPI’s safe
region. GP stands for giga pages, i.e., 1024∗ 1024∗ 1024 regular pages. A regular page has a size of 4096 bytes.
Detection Guarantees Table 3 also illustrates the de-
tection guarantees provided by APM when coped with
the default 10x inﬂation strategy. The detection guaran-
tees reﬂect the odds of an attacker being ﬂagged probing
into the inﬂated trip hazard area rather than in any of
the safe pages mapped in physical memory. As shown
in the table, APM offers very strong detection guaran-
tees across all our conﬁgurations. Naturally, the detec-
tion guarantees are stronger as the size of the inﬂated trip
hazard area (i.e., V MM ∗ in f lation_ f actor − PMM) in-
creases compared to the resident size (i.e., PMM). The
beneﬁts are, again, even more evident for CPI’s sparse
and huge safe area, which registered 100% detection
guarantees in almost all cases. Even in the worst case
(i.e., xalancbmk), CPI retains 316,838 trip hazard pages
at the end of the benchmark, resulting in 99.97% detec-
tion guarantees.
To lower the odds of being detected, an attacker may
attempt to force the program to allocate as many safe area
physical pages as possible, naturally reducing the num-
ber of trip hazard pages. We consider the impact of this
scenario in Firefox, with a JS-enabled attacker spraying
the stack to bypass APM. Figure 2 presents our results
for different inﬂation factors assuming an attacker able to
spray only the JS-visible part of the stack (1MB) or the
entire stack to its limit (2MB). As shown in the ﬁgure, in
both cases, APM provides good detection guarantees for
reasonable values of the inﬂation factor and up to 95%
with a 20x inﬂation (full spraying setting). Even in our
default conﬁguration, with a 10x inﬂation, APM offers
adequate detection guarantees in practice (90% for the
full spraying setting).
Firefox JS stack
Default stack
t
s
e
e
n
a
r
a
u
g
n
o
i
t
c
e
t
e
D
100%
95%
90%
85%
80%
75%
70%
65%
60%
55%
50%
45%
40%
35%
30%
25%
20%
15%
10%
 5%
 0%
1x 2x 3x 4x 5x 6x 7x 8x 9x 10x 11x 12x 13x 14x 15x 16x 17x 18x 19x 20x
Inflation factor
Figure 2: Effect of stack spraying (JS-visible or default stack) on our
detection guarantees (DGs) across different inﬂation factors.
Limitations APM aims at hardening IH, but does not
guarantee that a defense based on IH is fully protected
against arbitrary attacks. Defenses that rely on IH should
properly isolate the safe area to preserve the integrity
and/or conﬁdentiality of sensitive data. In the absence of
strong (e.g., hardware-based) isolation, however, APM
can transparently raise the bar for attackers, since it
can offer protection without programs being aware of it
(no re-compilation or binary instrumentation is needed).
Nevertheless, certain attacks can still reduce the entropy
and the detection guarantees provided by APM. For ex-
ample, an attacker may be able to locate the base address
of an inﬂated safe area by exploiting an implementation
ﬂaw or the recent allocation oracle side channel [28].
USENIX Association  
25th USENIX Security Symposium  117
13
While the entropy is reduced, the trip hazard pages still
deter guided probing attacks in the inﬂated area. How-
ever, if an implementation ﬂaw or other side channels
were to allow an attacker to leak a pointer to an active
safe area page in use by the application (e.g., RSP), APM
would no longer be able to detect the corresponding ma-
licious access, since such page has already been authen-
ticated by prior legitimate application accesses.
VICI “Dowsing” project, by the European Commission
through project H2020 ICT-32-2014 “SHARCS” under
Grant Agreement No. 64457, and by ONR through grant
N00014-16-1-2261. Any opinions, ﬁndings, conclusions
and recommendations expressed herein are those of the
authors and do not necessarily reﬂect the views of the US
Government, or the ONR.
7 Conclusion
Information hiding is at the heart of some of the most
sophisticated defenses against control-ﬂow hijacking at-
tacks. The assumption is that an attacker will not be
able to locate a small number of pages tucked away at
a random location in a huge address space if there are
no references to this pages in memory.
In this paper,
we challenge this assumption and demonstrate that it is
not always true for complex software systems such as
Mozilla Firefox. More speciﬁcally, we examined CPI’s
SafeStack since it is considered to be the state-of-the-art
defense.
In a ﬁrst step, we analyzed the implementa-
tion and found that there were still several pointers to the
hidden memory area in memory. An attacker can poten-
tially abuse a single such pointer to bypass the defense.
More seriously still, the protection offered by high en-
tropy is undermined by thread spraying—a novel tech-
nique whereby the attacker causes the target program to
spawn many threads in order to ﬁll the address space with
as many safe stacks as possible. Doing so reduces the
entropy to the point that brute-force attacks become vi-
able again. We demonstrated the practicality of thread
spraying by way of an attack against Firefox, Chrome
and MySQL, protected with CPI’s SafeStack.
To mitigate such entropy-reducing attacks, we pro-
pose an IH hardening strategy, namely APM. Based on a
user-space page fault handler, APM allows accessing of
pages on demand only and vets each ﬁrst access to a cur-
rently guarded page. The additional protection provided
by the page fault handler greatly improves the pseudo-
isolation offered by information hiding, making it a con-
crete candidate to replace traditional information hiding
in production until stronger (e.g., hardware-based) iso-
lation techniques ﬁnd practical applicability. Most no-
tably, our approach can be used to harden existing de-
fenses against control-ﬂow hijacking attacks with barely
measurable overhead.
Acknowledgements
We thank the reviewers for their valuable feedback.
This work was supported by Netherlands Organisation
for Scientiﬁc Research through the NWO 639.023.309
Disclosure
We have cooperated with the National Cyber Security
Centre in the Netherlands to coordinate disclosure of the
vulnerabilities to the relevant parties.
References
[1] Applications using older atl components may experience conﬂicts
with dep. https://support.microsoft.com/en-us/
kb/948468.
[2] Clang’s SafeStack.
SafeStack.html.
http://clang.llvm.org/docs/
[3] Discussion for porting SafeStack to GCC. https://gcc.
gnu.org/ml/gcc/2016-04/msg00083.html.
[4] ALTEKAR, G., BAGRAK, I., BURSTEIN, P., AND SCHULTZ, A.
Opus: online patches and updates for security. In USENIX Secu-
rity ’05.
[5] ANDERSEN, S., AND ABELLA, V.
Changes to Func-
tionality in Microsoft Windows XP Service Pack 2, Part
3: Memory Protection Technologies, Data Execution Preven-
tion, 2004. http://technet.microsoft.com/en-us/
library/bb457155.aspx.
[6] ARCANGELII, A. Userfaultfd: handling userfaults from user-
land.
[7] BACKES, M., AND NÜRNBERGER, S. Oxymoron: Making ﬁne-
grained memory randomization practical by allowing code shar-
ing. In USENIX Security ’14.
[8] BITTAU, A., BELAY, A., MASHTIZADEH, A., MAZIÈRES, D.,
AND BONEH, D. Hacking blind. In IEEE S&P ’14.
[9] BLETSCH, T., JIANG, X., FREEH, V. W., AND LIANG, Z.
Jump-oriented programming: A new class of code-reuse attack.
In ASIA CCS ’11.
[10] BOSMAN, E., RAZAVI, K., BOS, H., AND GIUFFRIDA, C.
Dedup est machina: Memory deduplication as an advanced ex-
ploitation vector. In IEEE S&P ’16.
[11] CARLINI, N., AND WAGNER, D. ROP is Still Dangerous:
Breaking Modern Defenses. In USENIX Security ’14.
[12] CHEN, S., XU, J., SEZER, E. C., GAURIAR, P., AND IYER,
R. K. Non-control-data attacks are realistic threats. In USENIX
Security ’05.
[13] DANG, T. H., MANIATIS, P., AND WAGNER, D. The perfor-
mance cost of shadow stacks and stack canaries. In ASIA CCS
’15.
[14] DANG, T. H., MANIATIS, P., AND WAGNER, D. The perfor-
mance cost of shadow stacks and stack canaries. In ASIA CCS
’15.
[15] DAVI, L., LIEBCHEN, C., SADEGHI, A. R., SNOW, K. Z., AND
MONROSE, F. Isomeron: Code randomization resilient to (just-
in-time) return-oriented programming. In NDSS ’15.
118  25th USENIX Security Symposium 
USENIX Association
14
[16] DAVI, L., SADEGHI, A.-R., LEHMANN, D., AND MONROSE,
F. Stitching the Gadgets: On the Ineffectiveness of Coarse-
Grained Control-Flow Integrity Protection. In USENIX Security
’14.
[17] EVANS, I., FINGERET, S., GONZALEZ, J., OTGONBAATAR, U.,
TANG, T., SHROBE, H., SIDIROGLOU-DOUSKOS, S., RINARD,
M., AND OKHRAVI, H. Missing the point(er): On the effective-
ness of code pointer integrity. In IEEE S&P ’15.
[18] GAWLIK, R., KOLLENDA, B., KOPPE, P., GARMANY, B., AND
HOLZ, T. Enabling client-side crash-resistance to overcome di-
versiﬁcation and information hiding. In NDSS ’16.
[19] GIUFFRIDA, C., KUIJSTEN, A., AND TANENBAUM, A. S.
Enhanced operating system security through efﬁcient and ﬁne-
grained address space randomization. In USENIX Security ’12.
[20] GÖKTA ¸S, E., ATHANASOPOULOS, E., POLYCHRONAKIS, M.,
BOS, H., AND PORTOKALIDIS, G. Size Does Matter: Why Us-
ing Gadget-Chain Length to Prevent Code-Reuse Attacks is Hard.
In USENIX Security’14.
[21] HALLER, I., GÖKTA ¸S, E., ATHANASOPOULOS, E., PORTOKA-
LIDIS, G., AND BOS, H. Shrinkwrap: Vtable protection without
loose ends. In ACSAC ’15.
[22] HUND, R., WILLEMS, C., AND HOLZ, T. Practical timing side
channel attacks against kernel space aslr. In IEEE S&P ’13.
[23] JANG, D., TATLOCK, Z., AND LERNER, S. SAFEDISPATCH:
Securing C++ virtual calls from memory corruption attacks. In
NDSS ’14.
[24] KUZNETSOV, V., SZEKERES, L., PAYER, M., CANDEA, G.,
In OSDI
SEKAR, R., AND SONG, D. Code-pointer Integrity.
’14.
[25] KUZNETSOV, V., SZEKERES, L., PAYER, M., CANDEA, G.,
AND SONG, D. Poster: Getting the point(er): On the feasibility
of attacks on code-pointer integrity. In IEEE S&P ’15.
[26] LU, K., SONG, C., LEE, B., CHUNG, S. P., KIM, T., AND LEE,
W. Aslr-guard: Stopping address space leakage for code reuse
attacks. In CCS ’15.
[27] MOHAN, V., LARSEN, P., BRUNTHALER, S., HAMLEN, K. W.,
AND FRANZ, M. Opaque Control-Flow Integrity. In NDSS ’15.
[28] OIKONOMOPOULOS, A., ATHANASOPOULOS, E., BOS, H.,
In
AND GIUFFRIDA, C. Poking holes in information hiding.
USENIX Sec ’16.
[29] PAPPAS, V., POLYCHRONAKIS, M., AND KEROMYTIS, A. D.
Smashing the gadgets: Hindering return-oriented programming
using in-place code randomization. In S&P ’12.
[30] PAX TEAM. Address Space Layout Randomization (ASLR),
2003. pax.grsecurity.net/docs/aslr.txt.
[31] PLANK, J. S., BECK, M., KINGSLEY, G., AND LI, K. Libckpt:
Transparent checkpointing under unix. In USENIX ATC ’95.
[32] SCHUSTER, F., TENDYCK, T., LIEBCHEN, C., DAVI, L.,
SADEGHI, A.-R., AND HOLZ, T. Counterfeit Object-oriented
Programming: On the Difﬁculty of Preventing Code Reuse At-
tacks in C++ Applications. In IEEE S&P ’15.
[33] SEIBERT, J., OKHRAVI, H., AND SÖDERSTRÖM, E. Informa-
tion leaks without memory disclosures: Remote side channel at-
tacks on diversiﬁed code. In CCS ’14.
[34] SHACHAM, H. The geometry of innocent ﬂesh on the bone:
Return-into-libc without function calls (on the x86). In CCS ’07.
[35] SNOW, K. Z., DAVI, L., DMITRIENKO, A., LIEBCHEN, C.,
MONROSE, F., AND SADEGHI, A.-R. Just-In-Time Code Reuse:
On the Effectiveness of Fine-Grained Address Space Layout Ran-
domization. In IEEE S&P ’13.
[36] STRACKX, R., YOUNAN, Y., PHILIPPAERTS, P., PIESSENS, F.,
LACHMUND, S., AND WALTER, T. Breaking the memory se-
crecy assumption. In EuroSec EWSS ’09.
[37] VILANOVA, L., BEN-YEHUDA, M., NAVARRO, N., ETSION,
Y., AND VALERO, M. Codoms: Protecting software with code-
centric memory domains. In ISCA ’14.
[38] VOGT, D., MIRAGLIA, A., PORTOKALIDIS, G., BOS, H.,
TANENBAUM, A. S., AND GIUFFRIDA, C. Speculative mem-
ory checkpointing. In Middleware ’15.
[39] WAHBE, R., LUCCO, S., ANDERSON, T. E., AND GRAHAM,
S. L. Efﬁcient software-based fault isolation. In SOSP ’93.
[40] WARTELL, R., MOHAN, V., HAMLEN, K. W., AND LIN, Z.
Binary stirring: Self-randomizing instruction addresses of legacy
x86 binary code. In CCS ’12.
[41] XI CHEN, A. S., DENNIS ANDRIESSE, H. B., AND GIUF-
FRIDA, C. StackArmor: Comprehensive protection from stack-
based memory error vulnerabilities for binaries. In NDSS ’15.
[42] YEE, B., SEHR, D., DARDYK, G., CHEN, J. B., MUTH, R.,
ORM, T., OKASAKA, S., NARULA, N., FULLAGAR, N., AND
INC, G. Native Client: A Sandbox for Portable, Untrusted x86
Native Code. In IEEE S&P ’09.
[43] ZHANG, C., WEI, T., CHEN, Z., DUAN, L., SZEKERES, L.,
MCCAMANT, S., SONG, D., AND ZOU, W. Practical Control
Flow Integrity and Randomization for Binary Executables.
In
IEEE S&P ’13.
[44] ZHANG, M., AND SEKAR, R. Control Flow and Code Integrity
for COTS binaries: An Effective Defense Against Real-World
ROP Attacks. In ACSAC ’15.
USENIX Association  
25th USENIX Security Symposium  119
15