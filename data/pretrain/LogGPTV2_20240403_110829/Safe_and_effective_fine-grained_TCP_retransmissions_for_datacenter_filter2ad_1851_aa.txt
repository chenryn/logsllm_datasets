# Safe and Effective Fine-Grained TCP Retransmissions for Datacenter Communication

## Authors
Vijay Vasudevan<sup>1</sup>, Amar Phanishayee<sup>1</sup>, Hiral Shah<sup>1</sup>, Elie Krevat<sup>1</sup>, David G. Andersen<sup>1</sup>, Gregory R. Ganger<sup>1</sup>, Garth A. Gibson<sup>1,2</sup>, Brian Mueller<sup>2</sup>
1. Carnegie Mellon University
2. Panasas Inc.

## Abstract
This paper presents a practical solution to the TCP incast problem in high-fan-in, high-bandwidth, synchronized TCP workloads in datacenter Ethernets. In such networks, receivers can experience a significant reduction in application throughput when simultaneously requesting data from many servers using TCP. Inbound data overfills small switch buffers, leading to TCP timeouts lasting hundreds of milliseconds. For many datacenter workloads with barrier synchronization requirements (e.g., filesystem reads and parallel data-intensive queries), throughput can be reduced by up to 90%. For latency-sensitive applications, these TCP timeouts impose delays of hundreds of milliseconds in networks with round-trip times in microseconds.

Our solution uses high-resolution timers to enable microsecond-granularity TCP timeouts. We demonstrate that this technique effectively avoids TCP incast collapse in both simulations and real-world experiments. We show that eliminating the minimum retransmission timeout bound is safe for all environments, including wide-area networks.

### Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network Protocols—TCP/IP; C.2.6 [Computer-Communication Networks]: Internetworking

### General Terms
Performance, Experimentation, Measurement

### Keywords
Datacenter Networks, Incast, Performance, Throughput

## 1. Introduction
In its 35-year history, TCP has been repeatedly challenged to adapt to new environments and technologies. Researchers have successfully enabled TCP to function well in gigabit networks, long/fat networks, and satellite and wireless environments. In this paper, we examine and improve TCP performance in an area that also proves challenging: very low delay, high-throughput datacenter networks of dozens to thousands of machines.

The problem we study is TCP incast collapse, where application throughput drastically reduces when multiple senders communicate with a single receiver in high-bandwidth, low-delay networks using TCP. Highly bursty, fast data transmissions overfill Ethernet switch buffers, causing intense packet loss and TCP timeouts. These timeouts, which last hundreds of milliseconds on a network with round-trip times in the tens or hundreds of microseconds, can reduce application throughput by 90% or more. Coarse-grained TCP timeouts can also harm performance for latency-sensitive datacenter applications.

In this paper, we present and evaluate a set of system extensions to enable microsecond-granularity retransmission timeouts (RTOs). The challenges in doing so are threefold: First, we show that the solution is practical by modifying the Linux TCP implementation to use high-resolution kernel timers. Second, we show that these modifications are effective, preventing TCP incast collapse in a real cluster for up to 47 concurrent senders. Third, we show that the solution is safe, examining the effects of an aggressively reduced RTO in the wide-area, showing that its benefits in datacenters do not affect performance for bulk flows in the wide-area.

The motivation for solving this problem is the increasing interest in using Ethernet and TCP for communication and bulk storage transfer applications in the fastest, largest datacenters. Provided that TCP adequately supports high bandwidth, low latency, synchronized, and parallel applications, there is a strong desire to "wire-once" and reuse the mature, well-understood transport protocols that are familiar in lower-bandwidth networks.

| Scenario | WAN | Datacenter | SAN |
|----------|-----|------------|-----|
| RTT      | 100ms | <1ms | <0.1ms |
| OS       | Linux | BSD | Solaris |
| TCP RTOmin | 200ms | 200ms | 400ms |

Table 1: Typical round-trip times and minimum TCP retransmission bounds.

## 2. Background
Cost pressures increasingly drive datacenters to adopt commodity components, often at the expense of performance. Many clusters are built with off-the-shelf rackmount servers interconnected by Ethernet switches. While entry-level gigabit Ethernet switches today operate at full data rates, they often sacrifice expensive, power-hungry SRAM packet buffers, which can lead to performance issues.

The desire for commodity parts extends to transport protocols. TCP provides a comprehensive set of features, including reliability via retransmission, congestion and flow control, and in-order packet delivery. However, TCP is solely responsible for coping with and avoiding packet loss in the (often small) Ethernet switch egress buffers. Unfortunately, the workload we examine has three features that challenge and nearly cripple performance: a highly parallel, synchronized request workload; buffers much smaller than the bandwidth-delay product of the network; and high-fan-in communication resulting in TCP flows with windows of only a few packets.

### 2.1 TCP Incast Collapse
Barrier-synchronized request workloads are becoming increasingly common in today's commodity clusters. Examples include parallel reads/writes in cluster filesystems like Lustre, Panasas, or NFSv4.1; search queries sent to dozens of nodes, with results returned to be sorted; or parallel databases that harness multiple back-end nodes to process parts of queries. We define the request as "barrier synchronized" when the client cannot make forward progress until the responses from every server for the current request have been received.

In a cluster filesystem, for example, a client application requests a data block striped across several storage servers, issuing the next data block request only when all servers have responded with their portion. This workload can result in packets overfilling the buffers on the client’s port on the switch, leading to many losses. Under severe packet loss, TCP can experience a timeout that lasts a minimum of 200ms, determined by the TCP minimum retransmission timeout (RTOmin). While the default values operating systems use today may suffice for the wide-area, datacenters and SANs have round-trip times that are orders of magnitude below the RTOmin defaults (Table 1).

When a server involved in a barrier-synchronized request experiences a timeout, other servers can finish sending their responses, but the client must wait a minimum of 200ms before receiving the remaining parts of the response, during which the client’s link may be completely idle. The resulting throughput seen by the application may be as low as 1-10% of the client’s bandwidth capacity.

Figure 1 shows the throughput of our test synchronized-read application (Section 3.2) as we increase the number of nodes it reads from, using an unmodified Linux TCP stack. This application performs synchronized reads of 1MB blocks of data; each of N servers responds to a block read request with 1 MB / N bytes at the same time. Even using a high-performance switch (with its default settings), the throughput drops drastically as the number of servers increases, achieving only 3% of the network capacity when it tries to stripe the blocks across all 47 servers.

To summarize, the preconditions for TCP incast collapse are:
1. High-bandwidth, low-latency networks with small switch buffers.
2. Clients that issue barrier-synchronized requests in parallel: the client does not issue new requests until all responses from the current request have been returned.
3. Servers that return a relatively small amount of data per request.

If precondition 2 does not hold, then a timed-out flow does not stall the client from making forward progress on other flows and hence will continue to saturate the client’s link. If precondition 3 does not hold and at least one flow is active at any time, the active flows will have enough data to send to saturate the link for 200ms—until the stalled flows retransmit and continue.

### 2.2 Latency-Sensitive Applications
While the focus of this work is on the throughput collapse observed for synchronized reads and writes, the imbalance between the TCP RTOmin and datacenter latencies can result in poor performance for applications sensitive to millisecond delays in query response time. In an interactive search query where a client requests data from dozens of servers in parallel, any flow that experiences a timeout will be delayed by 200ms. If the client cannot make forward progress (i.e., present results to the user) until all results are received, the entire request will be stalled for a minimum of 200ms, resulting in poor query latency.

To demonstrate this, we performed an experiment: we started ten bulk-data transfer TCP flows from ten clients to one server. We then had another client issue small request packets for 1KB of data from the server, waiting for the response before sending the next request. Approximately 1% of these requests experienced a TCP timeout, delaying the response by at least 200ms. Even without incast communication patterns, a latency-sensitive application can observe TCP timeouts due to congested queues caused by cross-traffic. The fine-grained TCP retransmission techniques we use to prevent TCP incast collapse will also benefit these more responsive latency-sensitive applications.

### 2.3 Prior Work
The TCP incast problem was first termed "Incast" and described by Nagle et al. in the context of parallel filesystems. Nagle et al. coped with TCP incast collapse in the parallel filesystem with application-specific mechanisms. Specifically, Panasas limits the number of servers simultaneously sending to one client to about 10 by judicious choice of the file striping policies. They also cap the advertised window size by reducing the default size of per-flow TCP receive buffers on the client to avoid incast collapse on switches with small buffers. For switches with large buffers, Panasas provides a mount option to increase the client’s receive buffer size. In contrast, this work provides a TCP-level solution for switches with small buffers and many more than 10 simultaneous senders that does not require implementing application-specific mechanisms. Also, our solution does not require re-implementing the many features of TCP within a UDP framework, perhaps as was the case with Facebook.

Prior work characterizing TCP incast collapse found that TCP improvements—such as NewReno, SACK, RED, ECN, Limited Transmit, and modifications to Slow Start—sometimes increased throughput but did not substantially prevent TCP incast collapse because the majority of timeouts were caused by full window losses. This work found three partial solutions: larger switch buffers, Ethernet flow control, and reducing TCP’s minimum RTO. In this paper, we address the practicality, effectiveness, and safety of very short timeouts in depth.

## 3. Evaluating Throughput with Fine-Grained RTO
How low must the RTO be to retain high throughput under TCP incast collapse conditions, and to how many servers does this solution scale? We explore this question using real-world measurements and ns-2 simulations, finding that to be maximally effective, the timers must operate on a granularity close to the RTT of the network—hundreds of microseconds or less.

### 3.1 Jacobson RTO Estimation
[Content to be added here]

---

This version of the text is more structured, clear, and professional. It includes improved formatting, better transitions, and a more coherent flow of ideas.