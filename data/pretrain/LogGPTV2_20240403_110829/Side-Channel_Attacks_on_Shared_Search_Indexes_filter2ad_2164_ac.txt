well as different formulas for combining them to compute a
score. These choices may use more features than we speciﬁed
above, such as the length of the document. Scores for multi-
term queries may also be computed via more complicated
formulae and have constants that can be hand-tuned for
a given application. Finally, we found that some services
implemented scoring via ad hoc methods that took into
account last-touched time or the order of terms in a query
(i.e., treating the query (t1, t2) differently from (t2, t1)).
When the adversary does not know the scoring function
it can no longer implement the algebraic attack from the
previous section. This issue was cited by B¨uttcher and Clarke
as preventing them from carrying out the attack on Spotlight.
Instead, other techniques must be developed that are robust
to variations in the scoring function.
Sharding. As mentioned above, enterprise search systems
perform load balancing by dividing the document corpus into
shards, which are essentially independent indexes. Sharding
may be done per-document, per-collection, per-user, or via
some other metric like creation time. Replica shards (i.e.,
copies of shards) are used to increase query throughput.
A side channel will only exist when scores are computed
as a function of private documents, which usually means that
an adversary’s document must be on the same shard as victim
data that it hopes to extract. Since search system interfaces do
not expose information about sharding, this poses a further
challenge for an adversary, who will need to arrange for
its documents to be co-sharded with victim data, and also
not be misled when documents are placed on shards without
victim data.
Noise. The production search systems we experimented with
displayed noisy behaviors that make attacks more difﬁcult.
For instance,
in all of our experiments on live systems
we observed that relevance scores constantly changed, and
issuing the same search multiple times will result in different
relevance scores on almost every query (see Figure 2 in §V).
Some of the noise is likely due to variations in the value
N, the number of documents in the shard, which is changing
constantly as many users write data to the index. This foils the
algebraic attack of B¨uttcher and Clarke, because obtaining
two scores computed with same value of N may be difﬁcult
or impossible, and anyway one cannot tell when this is
the case.
Consistency and deletions. We also observed occasional
larger changes in relevance scores likely due to other
systems behavior. ES and similar systems have complex
mechanisms for propagating newly written data into shards
which maintain some form of consistency as segments of
data are merged into shards. However, they do not maintain
consistent relevance scores when data are merged, causing
further difﬁculties for attacks that depend on ﬁne-grained
measurements in score changes. In some services it took up
to two minutes for a change in a document to result in a
change in relevance scores, slowing possible attacks. We also
noticed that searches may be issued in quick succession yet
return greatly differing scores, likely due to a segment merge
in between the queries.
Deletions are implemented lazily by marking documents
for deletion and later expunging them via a background pro-
cess (c.f., [11]). The DF values are incremented quickly (i.e.,
after a minute) but apparently only reduced after expunging.
Thus an adversary who hopes to delete documents as part
of an attack is required to wait until its documents have
been expunged before it can observe a change in the score
function. Further complication arises because an adversary
will not know which shard its document was present on and
deleted from.
API restrictions. Search interfaces are rate-limited, both in
terms of queries per time period (e.g., 5,000 queries per hour
on GitHub) and their total size (e.g., 128 bytes to describe
the keywords in the query). A very weak side channel may
be mitigated if it requires an infeasible number of queries, or
large queries.
Tokenizers and API interfaces often strip special char-
acters,
treating them as whitespace. So, for example, a
hyphenated number XXXX-YYYY may be tokenized into
two terms XXXX and YYYY, which have independent
DFs. This affects the information available via the DF
side channel.
Bystander data. An adversary who targets a victim or
victims will need to carry out the attack in the presence of
a possibly large number of bystander users whose data are
uninteresting to the adversary. These data are not known to
the adversary but will be used in relevance score calculations
using a formula also unknown to the adversary. These
bystanders are also actively writing and deleting data in
the index.
The primary effect of bystander data in our work is their
effect on false positives, which we return to below. The
essential issue is that an adversary is only able to compute
the DF of a term on a given shard. It is thus impossible
to distinguish with certainty between cases where a victim
document or a bystander document contains the term (and
causes its DF to be non-zero). In some cases, we will argue
that it is possible to use contextual clues, like the presence of
other terms in the same shard, to limit false positives.
678
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:39 UTC from IEEE Xplore.  Restrictions apply. 
V. STRESS ATTACKS
A. Attack Goals and Notation
We consider services that allow an adversary to write data
and also use a search interface to retrieve relevant documents
with scores. We assume that access control is implemented
properly, meaning that other users’ private documents are
not returned to the adversary, or otherwise leaked directly
through the interface.
Our adversary’s intermediate goal will be to determine the
DF of some given terms t1, . . . , tq. (Later we will discuss
attacks built on this capability.) We start from simplest case,
where each df(ti, D) is either 0, meaning no one has a
document containing ti, or is positive, meaning that it appears
at least once. The document set D is changing constantly due
to bystander activity, but we assume that the terms ti are not
written or deleted in a short period for the attack, and also
that the size of the shard does not change dramatically.
In a system with a single shard,
the DF of a term
is well-deﬁned. But
in a multi-shard system, each term
will have a shard-speciﬁc DF. To deﬁne the attack, we
model the document set D as being partitioned into sets
D1, . . . , DnSHRDS, where nSHRDS is the number of shards. In
this case, our adversary should determine, for each shard,
q
the tuple (df(ti, Dj))
i=1 where the shard holds documents
Dj. That is, on each of the shards, it should determine an
estimate of DF of each term on that shard. We note that
this attack will allow an adversary to detect that, say, t1 and
t2 happen to occur together on the same shard, which is
stronger than simply detecting that they occur somewhere in
the larger system.
Notation. In this section, we ﬁx a term-sampling algorithm
RNDTERM that outputs a fresh random term that is assumed
to never appear in bystander documents. In our experiments
choosing a uniformly random 16-character alphabetic string
was sufﬁcient.
We also ﬁx some notation for documents, terms, and the
interface into the search service. Documents will be treated
as sets of terms in our notation. In reality they are strings of
text but the order of terms does not matter for scoring. We
assume the service provides the ability to write documents,
which we formalize as WRITE(d, S), where d is a reference
to a document and S is a set of terms. This operation will
overwrite the entire document to consist of exactly S. Next
we will write score(t, d) to mean the score of document d
returned by the service for a search for the term t (note that
multiple calls to score(t, d) may return different scores, and
we are not ﬁxing a document set D — score(t, d) is deﬁned
according to the service’s response).
B. Basics of Exploiting the Side channel
All of our attacks will be built on a fundamental property
of all in-use relevance scoring functions we are aware of: As
a term t becomes more common (i.e. its DF increases), the
9.0499
9.0498
9.0497
9.0496
e
r
o
c
S
0
20
40
60
0
Time
3,600
Time
7,200
Figure 2: Example relevance scores returned by the GitHub
API when searching for the same term several times. Left
shows the score variations in 60 seconds, and right shows
the score variations in 2 hours. The time intervals for left
and right are 2 s and 60 s respectively. Y-axis does not start
from zero.
term weight decreases. In the case of basic TF-IDF, the term
weight is idf(t, D), but this is true for all of the variants we
have encountered. Indeed it is intentional: A more common
term should be given less weight in multi-term queries. An
adversary that does not know the scoring function can still
take advantage of this property.
Score-dipping. We use this property to build what we call
the score-dipping attack to determine if a term t appears
somewhere in a shard of a system that uses an unknown
scoring function. For now, assume that our attack owns a
document d on the shard of interest. The attack ﬁrst writes
two terms t and r to d by invoking WRITE(d,{t, r}), where
r is a long random term (not present in another document).
Then it requests searches for t and r. The search for t returns
only d with some score s, and the search for r returns only
d with some score s(cid:2). The attack checks if s  1 and thus s should be lower.
To work on a real system this attack must be extended
to tolerate noise in the scores returned. Due to bystander
activity, we will observe differences in s and s(cid:2) even when
the terms t, r have the same DF. (Indeed just searching for the
same term twice will produce different scores. See Figure 2.)
Bystander activity that incidentally decreases s or increases
s(cid:2) may cause the attack to output a false positive.
To mitigate this effect, we observed that the effect of
changing a DF from 0 to 1 (or some larger number) caused
a noticeably larger change in the relevance score than
background bystander activity. In our attack, we perform
several measurements on a shard to compute the typical
variation when searching for terms with DF equal to 1 and
2. We can then determine a threshold for when the score is
small enough to indicate that a term’s DF is larger than 0.
679
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:39 UTC from IEEE Xplore.  Restrictions apply. 
C. Plan for the Attacks
We now begin building towards an attack on a multi-shard
system. In all multi-shard systems, the mapping of documents
to shards is handled by some load balancing strategy that is
not directly exposed in the interface. (To an outside user,
sharding is meant to be transparent, though it does result
in variation of relevance scores for the same query across
shards.) Thus an adversary cannot directly see in which
shards its documents reside, or directly control the shard on
which a newly-created document is placed.
The hidden layer of load-balancing creates several difﬁcul-
ties. If we try to repeat the score-dipping attack several times
without considering which shard we are on in each run, we
will not know when we have explored all of the shards. Some
systems might have hundreds of shards, and it may take a
minute or more for a write to possibly change a relevance
score. API rate-limiting can further slow naive attacks.
A more serious problem is that naively repeating the
single-shard attack is not even a correct strategy when a
service processes deletions lazily, meaning it only reduces
DFs when expunging. In this setting, naive repetition will
detect its own documents, which artiﬁcially increase the DF
of terms of interest, during the attack. Concretely, suppose
one stage of the attack writes a document d = {t, r}
containing the term of interest, and that deleting d, or
removing t from d does not reduce the DF of t in the shard
holding d. Then later stages of the attack that happen to return
to the same shard will detect that the DF of t is non-zero, but
this will be due to d and not victim documents.
Below we show how to mitigate the difﬁculty of attacking
without deleting via a technique we call shard mapping
that reverse-engineers the number of shards in the service
and also places an adversary-controlled document on each
shard. In addition to giving interesting information about a
backend, shard mapping helps avoid the issues above, and
also improves the efﬁciency of attacks.
We build two families of attacks using shard mapping:
First we show how to quickly test for the presence of
terms in other users’ documents, allowing for what we call
brute force term extraction. Second, we present a totally
different approach called DF prediction that
learns the
scoring function on a shard and then attempts to predict DFs
using the learned function.
D. Tool: Co-Shard Testing
We ﬁrst build a tool that we will use a sub-routine: co-
shard testing. This will efﬁciently determine if an adversary-
owned document d1 resides on the same shard as another
adversary-owned document.
Our strategy uses a technique similar to the score-dipping
attack and the details are given in Algorithm 1. The routine
COSHARDTEST takes as input references to document
d1, and a set of documents M (not containing d1), and
determines if d1 was co-sharded with any documents in M
: Document d1 and document set M
: True iff ∃d ∈ M : d1, d on same shard
Algorithm 1: COSHARDTEST
Input
Output
Parameter: Integer δ > 0
1 r ← RNDTERM; r(cid:2) ← RNDTERM;
2 WRITE(d1, {r, r(cid:2)});
3 foreach d ∈ M do WRITE(d, r);
4 SLEEP;
5 s ← score(r, d1);
6 s(cid:2) ← score(r(cid:2), d1);
7 if (s(cid:2) − s) > δ then return True;
8 else return False;
(but not which one). It also uses a service-speciﬁc constant δ
that we set by hand (once for each service). The attack starts
by selecting two random terms r and r(cid:2). Then it writes r and
r(cid:2) to d1, and only r to the other documents. After waiting for
the writes to propagate, the algorithm issues two searches for
r and r(cid:2), and records the score of d1 in the searches as s and
s(cid:2) respectively. Finally it outputs true if s(cid:2) is greater than s
by more than δ.
This attack works based on the principles described. If d1
was not co-sharded with any other document, then we have
df(r, Dj) = df(r(cid:2), Dj) = 1, where Dj is the shard containing
d1. But if d1 and one (or more) d ∈ M are on the same shard
Dj, then df(r, Dj) ≥ 2 and df(r(cid:2), Dj) = 1, resulting in a
noticeable change in the score.
In this algorithm, most of the time is spent in SLEEP on
line 4. This is why we have chosen a fast version of co-shard
testing, where we can test if a new document d1 was co-