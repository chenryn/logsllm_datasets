δ, δs , δa Overall, sample, algorithm confidence.
θ
Cq|P
G(q|P)
(cid:99)f +
q ,(cid:99)f −
fq
q
Threshold parameter.
Conditioned frequency of q with respect to P
Subset of P with the closest prefixes to q.
Frequency of prefix q
Upper,lower bound for fq
Table 2: List of Symbols
The minimal requirements from an algorithm to be applicable to
our work are defined in Definition 3.4. This is a weak definition and
most counter algorithms satisfy it with δ = 0. Sketches [9, 15, 19]
can also be applicable here, but to use them, each sketch should
also maintain a list of heavy hitter items (Definition 3.5).
Definition 3.4. An algorithm solves the (ϵ, δ) - Freqency Esti-
mation problem if for any prefix (x), it provides(cid:98)fx s.t.:
Pr(cid:104)(cid:12)(cid:12)(cid:12)fx −(cid:98)fx
(cid:12)(cid:12)(cid:12) ≤ εN
(cid:105) ≥ 1 − δ .
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
R. Ben Basat, G. Einziger, R. Friedman, M.C. Luizelli, and E. Waisbard
Definition 3.5 (Heavy hitter (HH)). Given a threshold (θ), a fully
specified item (e) is a heavy hitter if its frequency (fe) is above
the threshold: θ · N , i.e., fe ≥ θ · N .
Our goal is to identify the hierarchical heavy hitter prefixes
whose frequency is above the threshold (θ · N). However, if the
frequency of a prefix exceeds the threshold then so is the frequency
of all its ancestors. For compactness, we are interested in prefixes
whose frequency is above the threshold due to non HHH siblings.
This motivates the definition of conditioned frequency (Cp|P ). Intui-
tively, Cp|P measures the additional traffic prefix p adds to a set
of previously selected HHHs (P), and it is defined as follows.
Definition 3.6. (Conditioned frequency) The conditioned fre-
quency of a prefix p with respect to a prefix set P is:
Cp|P (cid:44) 
fe .
e∈H(P∪{p})\HP
Cp|P is derived by subtracting the frequency of fully specified
items that are already generalized by items in P from p’s frequency
(fp). In two dimensions, exclusion inclusion principles are used to
avoid double counting.
We now continue and describe how exact hierarchical heavy
hitters (with respect to Cp|P ) are found. To that end, partition the
hierarchy to levels as explained in Definition 3.7.
Definition 3.7 (Hierarchy Depth). Define L, the depth of a hier-
archy, as follows: Given a fully specified element e, we consi-
der a set of prefixes such that: e ≺ p1 ≺ p2, .. ≺ pL where
e (cid:44) p1 (cid:44) p2 (cid:44) ... (cid:44) pL and L is the maximal size of that set.
We also define the function level(p) that given a prefix p returns
p’s maximal location in the chain, i.e., the maximal chain of gene-
ralizations that ends in p.
To calculate exact heavy hitters, we go over fully specified items
(level0) and add their heavy hitters to the set HHH0. Using HHH0,
we calculate conditioned frequency for prefixes in level1 and if
Cp|H H H0 ≥ θ · N we add p to HHH1. We continue this process
until the last level (L) and the exact heavy hitters are the set HHHL.
Next, we define HHH formally.
Definition 3.8 (Hierarchical HH (HHH)). The set HHH0 contains
the fully specified items e s.t. fe ≥ θ · N . Given a prefix p from
level(l), 0 ≤ l ≤ L, we define:
HHHl−1 ∪(cid:110)
p :(cid:16)
HHHl =
(cid:17)(cid:111)
.
p ∈ level (l) ∧ Cp|H H Hl−1 ≥ θ · N
The set of exact hierarchical heavy hitters HHH is defined as the
set HHHL.
For example, consider the case where θ N = 100 and assume
that the following prefixes with their frequencies are the only ones
above θ N . p1 = (, 108) and p2 = (, 102).
Clearly, both prefixes are heavy hitters according to Definition 3.5.
However, the conditioned frequency of p1 is 108 − 102 = 6 and that
of p2 is 102. Thus only p2 is an HHH prefix.
Finding exact hierarchical heavy hitters requires plenty of space.
Indeed, even finding exact (non hierarchical) heavy hitters requi-
res linear space [37]. Such a memory requirement is prohibitively
expensive and motivates finding approximate HHHs.
(cid:12)(cid:12)(cid:12) ≤ εN .
Definition 3.9 ((ϵ, θ)−approximate HHH). An algorithm solves
(ϵ, θ) - Approximate Hierarchical Heavy Hitters if after pro-
cessing any stream S of length N , it returns a set of prefixes (P)
that satisfies the following conditions:
• Accuracy: for every prefix p ∈ P,(cid:12)(cid:12)(cid:12)fp −(cid:98)fp
• Coverage: for every prefix q (cid:60) P: Cq|P < θ N .
Approximate HHH are a set of prefixes (P) that satisfies accuracy
and coverage; there are many possible sets that satisfy both these
properties. Unlike exact HHH, we do no require that for p ∈ P,
Cp|P ≥ θ N . Unfortunately, if we add such a requirement then [23]
proved a lower bound of Ω
of dimensions. This is considerably more space than is used in our
work ( H
ϵ
(cid:17) space, where d is the number
1
θ d +1
) that when θ ∝ ϵ is also H
θ
Finally, Definition 3.10 defines the probabilistic approximate
(cid:16)
.
HHH problem that is solved in this paper.
Definition 3.10 ((δ, ϵ, θ)−approximate HHHs). An algorithm A
solves (δ, ϵ, θ) - Approximate Hierarchical Heavy Hitters if
after processing any stream S of length N , it returns a set of prefixes
P that, for an arbitrary run of the algorithm, satisfies the following:
• Accuracy: for every prefix p ∈ P,
Pr(cid:16)(cid:12)(cid:12)(cid:12)fp −(cid:98)fp
Pr(cid:16)
(cid:12)(cid:12)(cid:12) ≤ εN
(cid:17) ≥ 1 − δ .
(cid:17) ≥ 1 − δ .
Cq|P < θ N
• Coverage: given a prefix q (cid:60) P,
Notice that this is a simple probabilistic relaxation of Defini-
tion 3.9. Our next step is to show how it enables the development
of faster algorithms.
Algorithm 1 Randomized HHH algorithm
end if
d = randomInt(0, V)
if d < H then
P = ϕ
for Level l = |H| down to 0. do
Prefix p = x&HH[d].mask
HH[d].I NCREMENT(p)
Initialization: ∀d ∈ [L] : HH[d] = HH_Alg (ϵ−1
a )
1: function Update( x)
2:
3:
4:
5:
6:
7: end function
8: function Output(θ)
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21: end function
Cp|P =(cid:98)fp
Cp|P =Cp|P + 2Z1−δ
ifCp|P ≥ θ N then
(cid:16)
+(cid:17)
,(cid:98)fp
p,(cid:98)fp
+ calcPred(p, P)
NV
P = P ∪ {p}
−
print
for each p in level l do
end for
return P
end for
end if
√
+
◃ Bitwise AND
◃ p is an HHH candidate
Constant Time Updates in Hierarchical Heavy Hitters
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
R = 0
for each h ∈ G(p|P) do
Algorithm 2 calcPred for one dimension
1: function calcPred(prefix p, set P)
2:
3:
4:
end for
5:
return R
6:
7: end function
R = R −(cid:98)fh
−
−
R = 0
for each h ∈ G(p|P) do
end for
for each pair h, h′ ∈ G(p|P) do
R = R −(cid:98)fh
R = R +(cid:98)fq
Algorithm 3 calcPred for two dimensions
1: function calcPred(prefix p, set P)
2:
3:
4:
5:
6:
7:
8:
9:
10:
end for
11:
return R
12:
13: end function
q = дlb(h, h′)
if (cid:64)h3 (cid:44) h, h′ ∈ G(p|P), q ≼ h3 then
end if
+
3.2 Randomized HHH
Our work employs the data structures of [35]. That is, we use a ma-
trix of H independent HH algorithms, and each node is responsible
for a single prefix pattern.
Our solution, Randomized HHH (RHHH), updates at most a
single randomly selected HH instance that operates in O(1). In
contrast, [35] updates every HH algorithm for each packet and
thus operates in O(H).
Specifically, for each packet, we randomize a number between
0 and V and if it is smaller than H, we update the corresponding
HH algorithm. Otherwise, we ignore the packet. Clearly, V is a
performance parameter: when V = H, every packet updates one
of the HH algorithms whereas when V ≫ H, most packets are
ignored. Intuitively, each HH algorithm receives a sample of the
stream. We need to prove that given enough traffic, hierarchical
heavy hitters can still be extracted.
Pseudocode of RHHH is given in Algorithm 1. RHHH uses the
same algorithm for both one and two dimensions. The differences
between them are manifested in the calcPred method. Pseudocode
of this method is found in Algorithm 2 for one dimension and in
Algorithm 3 for two dimensions.
to be a lower bound. For simplicity of notations, we define the
following:
Definition 3.11. The underlying estimation provides us with up-
per and lower estimates for the number of times prefix p was up-
dated (Xp). We denote:(cid:99)X p + to be an upper bound for Xp and(cid:99)X p−
(cid:98)fp (cid:44)(cid:99)X pV – an estimator for p’s frequency.
(cid:99)f +
p (cid:44)(cid:99)X p +
p (cid:44)(cid:99)X p−
(cid:99)f −
V – an upper bound for p’s frequency.
V – a lower bound for p’s frequency.
Note these bounds ignore the sample error that is accounted
separately in the analysis.
The output method of RHHH starts with fully specified items
and if their frequency is above θ N , it adds them to P. Then, RHHH
iterates over their parent items and calculates a conservative estima-
tion of their conditioned frequency with respect to P. Conditioned
frequency is calculated by an upper estimate to (f +
p ) amended by
the output of the calcPred method. In a single dimension, we re-
duce the lower bounds of p’s closest predecessor HHHs. In two
dimensions, we use inclusion and exclusion principles to avoid dou-
ble counting. In addition, Algorithm 3 uses the notation of greater
lower bound (glb) that is formally defined in Definition 3.12. Finally,
we add a constant to the conditioned frequency to account for the
sampling error.
Definition 3.12. Denote дlb(h, h′) the greatest lower bound of h
and h′. дlb(h, h′) is a unique common descendant of h and h′ s.t.
∀p : (q ≼ p) ∧ (p ≼ h) ∧ (p ≼ h′) ⇒ p = q. When h and h′ have no
common descendants, define дlb(h, h′) as an item with count 0.
In two dimensions, Cp|P is first set to be the upper bound on
p’s frequency (Line 12, Algorithm 1). Then, we remove previously
selected descendant heavy hitters (Line 4, Algorithm 3). Finally, we
add back the common descendant (Line 9, Algorithm 3).
Note that the work of [35] showed that their structure extends
to higher dimensions, with only a slight modification to the Output
method to ensure that it conservatively estimates the conditioned
count of each prefix. As we use the same general structure, their
extension applies in our case as well.
4 EVALUATION
Our evaluation includes MST [35], the Partial and Full Ancestry [14]
algorithms and two configurations of RHHH, one with V = H
(RHHH) and the other with V = 10·H (10-RHHH). RHHH performs
a single update operation per packet while 10-RHHH performs such
an operation only for 10% of the packets. Thus, 10-RHHH is consi-
derably faster than RHHH but requires more traffic to converge.
The evaluation was performed on a single Dell 730 server run-
ning Ubuntu 16.04.01 release. The server has 128GB of RAM and
an Intel(R) Xeon(R) CPU E5-2667 v4 @ 3.20GHz processor.
Our evaluation includes four datasets, each containing a mix of 1
billion UDP/TCP and ICMP packets collected from major backbone
routers in both Chicago [26, 27] and San Jose [24, 25] during the
years 2014-2016. We considered source hierarchies in byte (1D
Bytes) and bit (1D Bits) granularities, as well as a source/destination
byte hierarchy (2D Bytes). Such hierarchies were also used by [14,
35]. We ran each data point 5 times and used two-sided Student’s
t-test to determine 95% confidence intervals.
4.1 Accuracy and Coverage Errors
RHHH has a small probability of both accuracy and coverage errors
that are not present in previous algorithms. Figure 2 quantifies the
accuracy errors and Figure 3 quantifies the coverage errors. As can
be seen, RHHH becomes more accurate as the trace progresses.
Our theoretic bound (ψ as derived in Section 6 below) for these
parameters is about 100 million packets for RHHH and about 1
billion packets for 10-RHHH. Indeed, these algorithms converge
once they reach their theoretical bounds (see Theorem 6.19).
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
R. Ben Basat, G. Einziger, R. Friedman, M.C. Luizelli, and E. Waisbard
(a) Chicago15 - 2D Bytes
(b) Chicago16 - 2D Bytes
(c) SanJose13 - 2D Bytes
(d) SanJose14 - 2D Bytes
Figure 2: Accuracy error ratio – HHH candidates whose frequency estimation error is larger than N ϵ (ϵ = 0.001).
(a) Chicago15 - 2D Bytes
(b) Chicago16 - 2D Bytes
(c) SanJose13 - 2D Bytes
(d) SanJose14 - 2D Bytes
Figure 3: The percentage of Coverage errors – elements q such that q (cid:60) P and Cq|P ≥ Nθ (false negatives).
4.2 False Positives
Approximate HHH algorithms find all the HHH prefixes but they
also return non HHH prefixes. False positives measure the ratio non
HHH prefixes pose out of the returned HHH set. Figure 4 shows a
comparative measurement of false positive ratios in the Chicago
16 and San Jose 14 traces. Every point was measured for ϵ = 0.1%
and θ = 1%. As shown, for RHHH and 10-RHHH the false positive