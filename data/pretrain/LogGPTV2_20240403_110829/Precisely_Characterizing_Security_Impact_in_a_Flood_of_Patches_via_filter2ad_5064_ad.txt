constraint symbolic execution in both patched code and
unpatched code to determine security impacts conservatively.
In some cases, even when the patched code can never violate
10
a security rule or the unpatched code must violate the security
rule, the conservative execution may not be able to prove it. The
conservative approach is mainly to reduce false positives, which,
however, introduces a significant number of false negatives.
This problem causes 17 cases.
Incomplete coverage for security and vulnerable operations.
Intuitively, the incompleteness of the coverage will result in
false negatives in confirming security impacts. In the current
implementation, we collected the most common operations
based on our statistical study (see §V-C). For example, for
out-of-bound read or write bugs, we only collected the vulner-
able operations such as array operations, common read and
write functions; however, vulnerable operations using custom
functions would be missed. This problem causes 31 cases. Also,
similar to the causes of false positives, there are 5 cases caused
by inaccurate static analysis.
C. The Trade-off between False Positive and False Negative
Fig. 4: The safety-state transition diagram from unpatched version to
patched version.
Handling partial-fix patches. To distinguish the root differ-
ence between patches for general bugs and security-related bugs,
we introduce the concept of safety-state transition. First, we
say that the program is in an unsafe state if it violates at least
one security rule; we say the program is in a safe state if the
violations are eliminated. Figure 4 shows all the transition states.
Most commonly, a patch fixes a security bug if the unpatched
version is in the unsafe state, and the patched version is in the
safe state. In this case, we say that the patch blocks all the
security impacts of the bug. However, in some corner cases,
a patch only relieves a security bug, for which both patched
and unpatched versions are in the unsafe state, and the patched
version has fewer security-rule violations than the unpatched
version does. Thus, we call them partial-fix patches. In this
project, since SID is designed to cover the patches that correctly
and completely fix a security bug, it may miss security bugs
with partial-fix patches. Table VII summarizes how partial-fix
can happen for the covered types of bugs. In the course of our
evaluation, we only found two partial-fix cases—incompletely
initializing memory, which shows that partial-fix patches are
not common. However, in the future, it is possible to extend
SID to detect such partial-fix cases by analyzing the security
operations in a finger-grained manner (e.g., which bytes have
been initialized) and relaxing the symbolic rules (i.e., does not
require the block of all violations).
Relaxing symbolic rules. A unique strength of SID is using
the conservativeness of under-constrained symbolic execution to
precisely determine security impacts. Specifically, if the under-
constrained symbolic execution is unsolvable, it is truly unsolv-
able; however, if the under-constrained symbolic execution is
solvable, it can be a false positive due to missing constraints.
11
Bug types
Out-of-bound access
Use-after-free/double-free
Uninitialized use
Permission bypass
Partial fix on security operations
Incomplete bound check
N/A
Incomplete initialize
Incomplete perm check
TABLE VII: Possible partial-fix patches.
Therefore, we design strict rules—the patch should block all
violations (against a security rule) in the unpatched version by
proving the opposite constraints (see §IV-B) unsolvable.
Readers may wonder whether we can relax the symbolic
rules—determining security impacts as long as some violations
have been blocked—to reduce false negatives of SID. A critical
issue with rule relaxing is that, with the relaxed rules, we cannot
construct the opposite constraints to prove the unsolvability.
This will prevent SID from benefiting from the conservativeness
of under-constrained symbolic execution because the detected
blocks of violations will likely be false positives due to missing
constraints, rendering the security-impact determination highly
imprecise.
D. Security Evaluation for Identified Security Bugs
Every patch identified by SID, besides the false positives
(3%), fixed at least one security impacts; therefore, we believe
that the corresponding bugs are security bugs. To further
validate that the identified security bugs are real vulnerabilities,
we conduct two evaluations: (1) requesting CVEs and (2)
analyzing reachability.
Vulnerability confirmation for CVE. Surprisingly, out of 227
security bugs found by SID, only 31 of them have been already
assigned with CVE numbers. The remaining 196 security bugs
were not reported and were improperly treated as non-security
bugs. To confirm vulnerabilities, we request CVEs for the
remaining security bugs in two phases. In the first phase, we
requested CVEs for 40 security bugs individually. Due to that
requesting CVE is a time-consuming process; in the second
phase, we requested CVEs in a single batch.
The 40 security bugs submitted in the first phase come
from two sets; the first set contains 21 bugs that are patched in
the Linux kernel but still unpatched in the Android kernel. We
believe that this set represents less-likely security bugs because
the Android team might have confirmed them as non-security
bugs thus did not patch them. The second set includes the
other 19 detected security bugs that are randomly selected
but cover different types of security impacts. For these 40
cases, which were submitted individually, we have received
responses for 37 of them. In particular, we have obtained 24
CVEs for 23 security bugs (one bug was assigned with two
CVE IDs), and 9 of these bugs are from the unpatched set
in Android. 14 security bugs will not be assigned with CVEs
due to non-technical or controversial reasons: (1) the security
bug is in pre-release versions (5 cases); (2) information-leak
(memory disclosure to userspace) bugs in obsolete kernel code 1
(5 cases); (3) patch commits do not mention security impacts
(4 cases). For the first reason, we believe that most code will
1Response: "CVE IDs are not required for information leak to userspace in
various obsolete kernel code from approximately 2013."
SafeUnsafeSafeUnsafePatched Unpatchedbe released, and the corresponding security bugs will qualify
CVEs. For the second reason, we would disagree—memory
disclosures to userspace are security-critical because they break
ASLR [26, 29] and leak sensitive data; also, the involved code
still exists in the latest and released versions. The third reason
shows that manually confirming the security impacts of bugs
without commits mentioning security issues is hard.
Because maintainers would not assign CVEs for bugs in
the pre-release (i.e., release candidate (RC)) versions, in the
second phase, we filtered out 42 such bugs and reported 114
security bugs in a single batch. We still have not received
the responses yet because the review of the reports for these
bugs requires significant manual work for CVE maintainers. In
comparison, individual reports receive responses much more
timely. In summary, we totally reported 154 security bugs to
CVE maintainers. We have received 37 responses with 24
new CVEs assigned. This means that, including the previously
confirmed CVEs, 54 out of 227 identified bugs have been
assigned with CVEs. Note that none of the rejected cases is
due to misidentifying security impacts. Table XIII show the
details of the security bugs and CVE. These results indicate
that SID is effective in determining security bugs from massive
general bugs.
Reachability analysis for security bugs. Since a bug becomes
a vulnerability when it can be triggered and cause security
impacts, we also evaluate the reachability (from attacker-
controllable entry points) of the identified bugs. The identified
security bugs were detected through either fuzzers or other
techniques such as static analysis. Clearly, if a bug was found
by fuzzers such as Syzkaller [46], we can directly confirm its
reachability. In particular, by checking the git commits, which
would mention the corresponding fuzzers if a bug was found
through fuzzing, we found that 28 (12.3%) of identified security
bugs were found by fuzzers, thus are reachable from attackers.
The remaining 199 security bugs were mainly found through
static analysis; confirming their reachability from attacker-
controllable entry points has been a challenging and open
problem [20]. Therefore, in this evaluation, we focus on finding
the reachable call-chain between attacker-controllable functions
and the functions containing the vulnerable operations. To this
end, we first identified entry points—functions in the kernel
that can be arbitrarily called by attackers. Based on how the
kernel interacts with external entities, we empirically identify
the following entry points.
• System calls. They are the most commonly used interface
between user-space and kernel-space, which are also widely
targeted by kernel fuzzers.
• Driver-specific I/O-control handlers. These handler functions
are registered and can be called through the ioctl system
call. By setting specific parameters, attackers can control
the handlers. The previous work, DIFUZE [10], also fuzzes
these handlers to find bugs in the kernel drivers.
• Interrupt (IRQ) handlers in drivers. Malicious hardware can
invoke such handler functions by triggering the interrupt and
prepare their parameter; therefore, they are also controllable
to attackers. PeriScope [45] also fuzzes kernel drivers and
regards these IRQ handlers as entry points.
We first identify the 338 system calls in the Linux kernel
based on the system-call list [1]. Then, following the method of
DIFUZE [10], we identify a set of structures that can be used to
register ioctl handler by drivers, and based on these structures,
we find 603 ioctl handlers [11]. To identify IRQ handlers,
PeriScope [45] shows that drivers can register their own IRQ
using multiple types of APIs, and tasklest is one of the most
commonly used software interrupts (softirq). Therefore, based
on the declarations of tasklest and IRQ-related keywords in
drivers, we finally find 126 IRQ handlers.
The idea of the evaluation is to traverse the global call-graph
of the kernel to collect the shortest call-chain path between the
entry points and functions containing the vulnerable operations.
We employ Dijkstra’s Shortest Path (DSP) algorithm [16] to
find the paths. Given a bug, we say it is reachable from attacker-
controllable entry points if we find such paths. To minimize
false positives and false negatives, we employ the state-of-
the-art techniques—using struct types to match functions [28,
31, 62]—to precisely identify indirect-call targets. Table VIII
shows the number of bugs that are reachable from different
types of entry points. In particular, we found that 133 security
bugs are reachable from systems, and 154 are reachable from
the three classes of entry points.
Entry points
Dynamically confirmed bugs (fuzzers)
System calls
I/O control handlers
Interrupt handlers
Total
Num of reachable bugs
28
133
148
131
154 (67.8%)
TABLE VIII: Number of bugs that can be reached from different
kinds of entry points.
E. Generality of SID’s Patch Model
Num of key components
Three components
Two or one component
Other cases
Percent
77%
11%
12%
TABLE IX: The generality of SID’s patch model. It shows the
numbers of components the vulnerabilities have.
SID’s patch model includes three key components of patches:
security operation, vulnerable operation, and critical variables.
To evaluate the generality of the model, we analyzed the most
recent 100 vulnerabilities in the Linux kernel that were disclosed
in 2019. Table IX shows the statistical results of this evaluation.
We can find all of the three components in 77 vulnerabilities;
therefore, SID can support the security-impact determination
for them. Furthermore, 11 vulnerabilities only have one or two
of these key components. For example, pointer usage in an
incorrect order can introduce use-after-free vulnerabilities, and
the corresponding patches just change the pointer reference
order. In this case, the security operation is not modeled and thus
will be missed. In addition, 12 cases involve code removal as
the fix or multiple patches, which cannot be clearly represented
by SID’s current model. For example, there are five patches
that only delete some redundant code, such as deallocation
functions. Some vulnerabilities were fixed by more than one
patches or complex patches.
12
SID’s model is, in fact, conceptual and general—while
a vulnerability typically has vulnerable operations, the patch
performs security operations to prevent them, and both kinds of
operations often target variables. In the future, we can certainly
extend the model to support more cases. For example, even for
memory leaks where there is no explicit vulnerable operation
at all, we can artificially model “object pointer never being
released” as the vulnerable operation, which can be realized by
analyzing the operations against the pointer (critical variable).
F. New and Important Findings
Patching-time window for security and general bugs.
In
order to show the importance of SID, we would like to know
how Linux maintainers treat security bugs and general bugs
differently. To this end, we measure and compare the patching
time window for them—the time from the submission/report of
a patch to the application of the patch. We tested 8,000 patches
for general bugs, 1,339 patches for vulnerabilities, and all the
security bugs that are found by SID but do not have CVE ID.
We use the cumulative distribution function (CDF) to show the
statistical patching-time window in Figure 5. We find that the
patching-time window for CVE-assigned vulnerabilities (5.8
days) is shorter than security bugs (8.6 days) found by SID.
This means that the maintainers have not treated these security
bugs as important as vulnerabilities.
We also find that the patching time window of security
bugs identified by SID is shorter than other general bugs. We
believe one reason is that the patches for these security bugs
have fewer code changes, and the bugs have clearer patterns,
which is also reported by Li et al. [27].
More statistical results are shown in Table X, from which
we can find that security patches still take a long time to be
applied. Nearly 10% of security bugs are patched more than
one month after they have been reported. This significant time
window gives attackers much time to craft critical exploits, not
to mention that the reported patches are visible to attackers.
Thus, an automated tool that can determine the security impacts
of bugs is demanded.
Type
General patches
Patches of security bugs
Patches of vulnerabilities
Average Median Maximum
(Days)
15.8
8.6
5.8
(Days)
1240
111
974
(Days)
3
2
1
TABLE X: Statistics on patch-time window.
Delayed disclosure of security impacts of existing vulnera-
bilities. We found that the disclosure of the security impacts
of existing vulnerabilities is commonly delayed, which is also
known as hidden impact vulnerability [53]. To measure the
delaying, we define the delayed time as the time window
from the patch date to the CVE-release date. We collected
1,339 vulnerabilities in the Linux kernel from the CVE
database [13, 38] and analyzed the delayed time. The CDF
for the delayed time is shown in Figure 5. The results show
that only 23.9% of them are identified as vulnerabilities less
than two weeks (14 days) after they have been patched. The
other 75% are reported as vulnerabilities after two weeks. The
average and median delayed time period for these vulnerabilities
13
is 191 and 45 days. The longest case is more than 12 years,
which was identified as a security bug by SID and assigned
with a CVE (CVE-2007-6762) after we reported it.
Security bugs threatening derivative software. Many pro-
grams are derived from other open-sourced programs. For
example, the Android kernel is a modified version of the
Linux kernel, and the Android kernel is further customized
into thousands of versions [52] running on tens of thousand
device models [64]. This problem is known as Android
fragmentation [52, 64]. Manufactures are unable to fix all
bugs timely, due to a large number of derivative programs.
Instead, they prioritize security-critical ones and postpone or
even ignore non-security ones. To understand the severity of
the problem, we test more than 5K bug patches in the Android
kernel of version 4.14-p-release and perform two evaluations.
The first evaluation is to check how many security bugs
(identified by SID) remain unpatched in Android. Specifically,
we manually checked the security bugs found by SID in the
latest (as of the experiment) Android kernel release version,
Android-4.14-p-release, which was ported from the Linux kernel
4.14 on November 12, 2017 [48]. As such, patches applied
before the date in Linux will also be available in Android.
Therefore, we analyzed the security bugs found by SID that
were introduced before November 12, 2017, but patched in
Linux after the date. We found that 39 such security bugs were
reported after November 12, 2017, in the Linux kernel and were
not assigned with a CVE; 11 of them do not affect the Android
code anymore; thus, they are excluded. For the remaining 28
security bugs, we found that only seven are patched in the
Android kernel, and 21 (75%) remain unpatched. Details can
be found in appendix (Table XIII ). These security bugs may
pose serious security risks to Android.
The second evaluation is to measure the bug-fixing time
windows of CVE-assigned bugs and non-security bugs in
Android. Specifically, non-CVE bugs are fixed with an average
of 44.6 days (30 days following Linux kernel patches), while
CVE-assigned bugs are fixed with an average of 27.8 days
(only 14 days following the Linux kernel patches). For security
bugs, because most of them are not identified as vulnerabilities,
thus they will be treated as general bugs and would not be fixed
in time. The average time window is 44.6 days. For instance,
Figure 6 is a missing bound check security bug in the Linux
kernel. After our report, this security bug has a CVE ID, CVE-
2019-15926, with CVSS score 9.4. This bug was introduced
from the Linux kernel 3.0 but still has not been patched in the
Android 4.14-p-release until the submission of this paper.
Multi-impacts per bug. The semantics of vulnerable opera-
tions often decides security impacts. Intuitively, when a critical
variable is used in multiple vulnerable operations, it may have
multiple security impacts. In particular, for the 227 security
bugs, SID actually found 243 security impacts, as shown in
Table XI. For example, some out-of-bound access cases are
also caused by uninitialized use when the uninitialized variable
is used as a size variable in memory access.
Characterizing bugs and vulnerabilities.
In addition to
the security impacts, we also characterize other differences
between general bugs and security bugs. First, we analyzed
the differences in the number of changed lines in patches
for 1,350 randomly selected general bugs, the security bugs
Fig. 5: Statistical findings. CDF: cumulative distribution function; (1) CDF for time windows from bug report date to bug fix date; (2) CDF for
time window from the patch date to the CVE release date; (3) CDF for the number of changed lines for different kind of bugs. In (2), about 1%
of vulnerabilities are assigned with a CVE before the bugs are actually patched.
* drivers/net/wireless/ath/ath6kl/wmi.c */
...
ev = (struct wmi_pstream_timeout_event *) datap;
if (ev->traffic_class >= WMM_NUM_AC) {
ath6kl_err("invalid traffic class: %d\n",
struct wmi *wmi, u8 *datap,
int len) {
1 /* CVE-2019-15926, CVSS 9.4
2
3 static int ath6kl_wmi_pstream_timeout_event_rx(
4
5
6
7
8 +
9 +
10 +
11 +
12 +
13
14
15
16
17 }
...
wmi->stream_exist_for_ac[ev->traffic_class] = 0;
...
ev->traffic_class);
return -EINVAL;
}
Fig. 6: An out-of-bound access vulnerability in Android 4.14
Security impacts
Uninitialized use
Out-of-bound access
NULL-pointer dereference