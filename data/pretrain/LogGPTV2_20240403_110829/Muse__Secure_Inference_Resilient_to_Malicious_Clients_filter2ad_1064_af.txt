overhead from the garbled circuits), but our techniques scale
better and achieve a 1.4× reduction for the larger CIFAR-10
network.
For the online phase, we observe a 7.8×–8.6× latency
improvement and 3.4×–4.6× communication improvement
when comparing MUSE to Overdrive.
6.5
In this section we demonstrate the effectiveness of our op-
timizations to Overdrive in the client-malicious setting. In
particular, we show that in client-malicious Overdrive without
the LTME assumption:
• Triple generation is signiﬁcantly more efﬁcient.
• Client input authentication is slightly more efﬁcient.
• Server input authentication is signiﬁcantly more efﬁcient.
These improvements are of independent interest and can easily
be extended to support more parties.
Triple generation.
In Fig. 10 we benchmark the genera-
tion of triples on a variable number of threads. In summary,
client-malicious Overdrive achieves a 8×–12.5× latency im-
provement and 1.7× communication reduction (the latter is
not shown in the graph) over standard Overdrive.
Input authentication.
In Table 4 we show benchmarks for
input authentication for the client and server. Our protocol
for client inputs achieves a 1.6× speed improvement with-
out the LTME assumption, but increases communication by
3.6×. We observe a 37.8× improvement in latency and 4.5×
improvement in communication for server inputs.
USENIX Association
30th USENIX Security Symposium    2213
104105106 2 3 4 5 6Triples/sThreadsClient-malicious OverdriveOverdriveChameleon [Ria+18] proposed a slightly weaker threat
model where a semi-honest third server assists in the prepro-
cessing phase but is not needed for the online phase. If such
a setup is feasible, MUSE could naturally take advantage of
this threat model by having the semi-honest third server assist
in triple generation for the CDS protocol. This augmentation
improves latency and bandwidth of MUSE’s preprocessing
phase by roughly 3×.
TEE-based protocols. Generally speaking, TEE-based pro-
tocols [Tra+19; Top+18; Han+18; App19] provide better efﬁ-
ciency than protocols relying on purely cryptographic tech-
niques. However, this improved efﬁciency comes at the cost
of a weaker threat model that requires trust in hardware ven-
dors and the implementation of the enclave. Indeed, the past
few years have seen a number of powerful side-channel at-
tacks [Bra+17; Häh+17; Göt+17; Mog+17; Sch+17; Wan+17;
Van+18] against popular enclaves like Intel SGX and ARM
TrustZone.
Generic frameworks. Maliciously-secure MPC frame-
works exist for computing arithmetic circuits [Dam+12;
Kel+18; Che+20], binary circuits [Kat+18], and mixed cir-
cuits [Rot+19; Esc+20; Moh+18]. Before MUSE, these were
the only existing cryptographic mechanisms for two-party
client-malicious secure inference. While [Che+20] is the
most efﬁcient of these for inference, an implementation was
not available at the time of writing so we compared against
[Kel+18] in Section 6.4. From the results of Section 6.4 and
the experiments provided in [Che+20], we can roughly esti-
mate that the preprocessing communication of [Che+20] is
similar to MUSE, but MUSE is superior on all other accounts.
GC-based protocols. DeepSecure [Rou+18], the protocol
of Ball et al. [Bal+19], and XONN [Ria+19], all use circuit
garbling schemes to implement constant-round secure infer-
ence protocols. While DeepSecure supports general neural
networks, the protocol of [Bal+19] operates on discretized
neural networks, which have integer weights, while XONN
is optimized for binarized neural networks [Cou+15], which
have boolean weights. These quantized networks allow for im-
proved performance by avoiding computing expensive ﬁxed-
point multiplication in favor of integer multiplication or binary
XNOR gates.
While neural network inference is commonly performed
on quantized networks [Kri18], in practice quantization is
never done below 8-bits since inference accuracy begins to
suffer [Ban+18]. To combat this accuracy drop, XONN in-
creases the number of neurons in its linear layers, gaining
increased accuracy at the cost of a slower evaluation time.
While this technique appears to work well for the datasets
XONN evaluates, additional techniques are needed to scale
to more difﬁcult datasets like Imagenet as the current best-
known quantization techniques for Imagenet requires 2 bit
weights and 4 bit activations [Don+19]. Consequently, it is
our opinion that it is still important to focus on supporting se-
cure inference for general neural networks even though BNNs
appear promising.
Any GC-based protocol can be upgraded to malicious se-
curity through a combination of cut-and-choose techniques
[Zhu+16] and malicious OT-extension [Kel+15], and client-
malicious security for the evaluator by using malicious OT-
extension. Thus, it would follow that all of these GC-based in-
ference protocols can be transformed into malicious and ﬁxed-
subset malicious protocols. Note that DeepSecure would pro-
vide server-malicious security since the client garbles the
circuit. XONN uses a specialized protocol to evaluate the ﬁrst
layer of the network since the client’s input is an un-quantized
integer. In order for these malicious/client-malicious transfor-
mations to work, XONN would need to evaluate this layer
within the more-expensive garbled circuit, instead of their op-
timized protocol. Furthermore, an implementation of XONN
was not available at the time of writing, so we could not
benchmark a client-malicious version of their protocol on our
experimental setup. Finally, MUSE’s online speed is already
superior to the semi-honest versions of DeepSecure and the
protocol of [Bal+19].
8 Conclusion
In this paper, we introduce a novel model-extraction attack
against many semi-honest secure inference protocols which
outperforms existing attacks by orders of magnitude. In re-
sponse, we design and implement MUSE, an efﬁcient two-
party secure inference protocol resilient to malicious clients.
MUSE achieves online performance close to existing semi-
honest protocols, and greatly outperforms alternate solutions
for client-malicious secure inference. As part of MUSE’s de-
sign, we introduce a novel cryptographic protocol for con-
ditional disclosure of secrets and improved procedures for
generic MPC in the client-malicious setting. We hope that
MUSE is a ﬁrst step towards achieving practical two-party
secure inference in a strong threat model.
Acknowledgements. We thank Marcel Keller for help in
using MP-SPDZ, Vinod Vaikuntanathan and David Wu for
answering questions about linear targeted malleable encryp-
tion, Joey Gonzalez for answering questions about Binarized
Neural Networks, and the anonymous reviewers as well as
our shepherd Florian Tramér for their detailed feedback. This
work was supported in part by the NSF CISE Expeditions
CCF-1730628, NSF Career 1943347, and gifts/awards from
the Sloan Foundation, Bakar Program, Alibaba, Amazon Web
Services, Ant Group, Capital One, Ericsson, Facebook, Fu-
turewei, Google, Intel, Microsoft, Nvidia, Scotiabank, Splunk,
and VMware.
References
[App19]
Apple. “iOS Security”. https://www.apple.com/
business / docs / site / iOS _ Security _ Guide .
pdf.
2214    30th USENIX Security Symposium
USENIX Association
[Bal+19]
[Ban+18]
[Bar18]
[Bel+12]
[Bit+13]
[Bou+18]
[Boy+17]
[Bra+17]
[Bru+18]
[Car+20]
[Cha+19]
[Che+20]
[Cho+18]
[Cou+15]
[Dam+12]
[Dat+19]
[Don+19]
M. Ball, B. Carmer, T. Malkin, M. Rosulek, and N.
Schimanski. “Garbled Neural Networks are Practical”.
ePrint Report 2019/338.
R. Banner, I. Hubara, E. Hoffer, and D. Soudry. “Scal-
able methods for 8-bit training of neural networks”.
In: NeurIPS ’18.
B. Barrett. “The year Alexa grew up”. https : / /
www . wired . com / story / amazon - alexa - 2018 -
machine-learning/.
M. Bellare, V. T. Hoang, and P. Rogaway. “Founda-
tions of garbled circuits”. In: CCS ’12.
N. Bitansky, A. Chiesa, Y. Ishai, R. Ostrovsky, and
O. Paneth. “Succinct Non-interactive Arguments via
Linear Interactive Proofs”. In: TCC ’13.
F. Bourse, M. Minelli, M. Minihold, and P. Paillier.
“Fast Homomorphic Evaluation of Deep Discretized
Neural Networks”. In: CRYPTO ’18.
E. Boyle, G. Couteau, N. Gilboa, Y. Ishai, and M.
Orrú. “Homomorphic Secret Sharing: Optimizations
and Applications”. In: CCS ’17.
F. Brasser, U. Müller, A. Dmitrienko, K. Kostiainen, S.
Capkun, and A. Sadeghi. “Software Grand Exposure:
SGX Cache Attacks Are Practical”. In: WOOT ’17.
A. Brutzkus, O. Elisha, and R. Gilad-Bachrach. “Low
Latency Privacy Preserving Inference”. ArXiV, cs.CR
1812.10659.
N. Carlini, M. Jagielski, and I. Mironov. “Cryptan-
alytic Extraction of Neural Network Models”. In:
CRYPTO ’20.
N. Chandran, D. Gupta, A. Rastogi, R. Sharma, and S.
Tripathi. “EzPC: Programmable and Efﬁcient Secure
Two-Party Computation for Machine Learning”. In:
EuroS&P ’19.
H. Chen, M. Kim, I. P. Razenshteyn, D. Rotaru, Y.
Song, and S. Wagh. “Maliciously Secure Matrix Mul-
tiplication with Applications to Private Deep Learn-
ing”. In: ASIACRYPT ’20.
E. Chou, J. Beal, D. Levy, S. Yeung, A. Haque, and
L. Fei-Fei. “Faster CryptoNets: Leveraging Sparsity
for Real-World Encrypted Inference”. ArXiV, cs.CR
1811.09953.
M. Courbariaux, Y. Bengio, and J. David. “Bina-
ryConnect: Training Deep Neural Networks with bi-
nary weights during propagations”. In: NeurIPS ’18.
I. Damgård, V. Pastro, N. P. Smart, and S. Zakarias.
“Multiparty Computation from Somewhat Homomor-
phic Encryption”. In: CRYPTO ’12.
R. Dathathri, O. Saarikivi, H. Chen, K. Laine,
K. E. Lauter, S. Maleki, M. Musuvathi, and T.
Mytkowicz. “CHET: An optimizing compiler for
fully-homomorphic neural-network inferencing”. In:
PLDI ’19.
Z. Dong, Z. Yao, A. Gholami, M. Mahoney, and
K. Keutzer. “HAWQ: Hessian AWare Quantiza-
[Esc+20]
[Fan+12]
[Gen09a]
[Gen09b]
[Gil+16]
[Gol+89]
[Goo17]
[Göt+17]
[Häh+17]
[Han+18]
[Hes+17]
[Jag+20]
[Juu+19]
[Juv+18]
[Kat+18]
[Kel+15]
[Kel+18]
[Kel20]
tion of Neural Networks With Mixed-Precision”. In:
ICCV ’19.
D. Escudero, S. Ghosh, M. Keller, R. Rachuri, and
P. Scholl. “Improved Primitives for MPC over Mixed
Arithmetic-Binary Circuits”. In: CRYPTO ’20.
J. Fan and F. Vercauteren. “Somewhat Practical Fully
Homomorphic Encryption”. ePrint Report 2012/144.
C. Gentry. “A Fully Homomorphic Encryption Sch-
eme”. PhD thesis. Stanford University, 2009.
C. Gentry. “Fully homomorphic encryption using
ideal lattices”. In: STOC ’09.
R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter,
M. Naehrig, and J. Wernsing. “CryptoNets: Apply-
ing Neural Networks to Encrypted Data with High
Throughput and Accuracy”. In: ICML ’16.
S. Goldwasser, S. Micali, and C. Rackoff. “The
Knowledge Complexity of Interactive Proof Systems”.
In: SIAM J. Comput. (1989).
Google. Google Infrastructure Security Design
Overview. Tech. rep. 2017.
J. Götzfried, M. Eckert, S. Schinzel, and T. Müller.
“Cache Attacks on Intel SGX”. In: EUROSEC ’17.
M. Hähnel, W. Cui, and M. Peinado. “High-
Resolution Side Channels for Untrusted Operating
Systems”. In: ATC ’2017.
L. Hanzlik, Y. Zhang, K. Grosse, A. Salem, M.
Augustin, M. Backes, and M. Fritz. “MLCapsule:
Guarded Ofﬂine Deployment of Machine Learning as
a Service”. ArXiV, cs.CR 1808.00590.
E. Hesamifard, H. Takabi, and M. Ghasemi. “Cryp-
toDL: Deep Neural Networks over Encrypted Data”.
ArXiV, cs.CR 1711.05189.
M. Jagielski, N. Carlini, D. Berthelot, A. Kurakin, and
N. Papernot. “High Accuracy and High Fidelity Ex-
traction of Neural Networks”. In: USENIX Security
’20.
M. Juuti, S. Szyller, S. Marchal, and N. Asokan.
“PRADA: Protecting Against DNN Model Stealing
Attacks”. In: EuroS&P ’19.
C. Juvekar, V. Vaikuntanathan, and A. Chandrakasan.
“GAZELLE: A Low Latency Framework for Se-
cure Neural Network Inference”. In: USENIX Se-
curity ’18.
J. Katz, S. Ranellucci, M. Rosulek, and X. Wang. “Op-
timizing Authenticated Garbling for Faster Secure
Two-Party Computation”. In: CRYPTO ’18.
M. Keller, E. Orsini, and P. Scholl. “Actively Se-
cure OT Extension with Optimal Overhead”. In:
CRYPTO ’15.
M. Keller, V. Pastro, and D. Rotaru. “Overdrive: Mak-
ing SPDZ Great Again”. In: EUROCRYPT ’18.
M. Keller. “MP-SPDZ: A Versatile Framework for
Multi-Party Computation”. In: CCS ’20.
USENIX Association
30th USENIX Security Symposium    2215
[Kes+18]
[Kri18]
[Kum+20]
[Lee+19]
[Lin+15]
[Liu+17a]
M. Kesarwani, B. Mukhoty, V. Arya, and S. Mehta.
“Model Extraction Warning in MLaaS Paradigm”. In:
ACSAC ’18.
R. Krishnamoorthi. “Quantizing deep convolutional
networks for efﬁcient inference: A whitepaper”.
arXiv: 1806.08342 [cs.LG].
N. Kumar, M. Rathee, N. Chandran, D. Gupta, A. Ras-
togi, and R. Sharma. “CrypTFlow: Secure TensorFlow
Inference”. In: S&P ’20.
T. Lee, B. Edwards, I. Molloy, and D. Su. “Defending
Against Neural Network Model Stealing Attacks Us-
ing Deceptive Perturbations”. In: SP Workshop ’19.
Y. Lindel and P. Benny. “An Efﬁcient Protocol for
Secure Two-Party Computation in the Presence of
Malicious Adversaries”. In: J. Cryptol. (2015).
J. Liu, M. Juuti, Y. Lu, and N. Asokan. “Oblivious
Neural Network Predictions via MiniONN Transfor-
mations”. In: CCS ’17.
[Mil+19]
[Mis+20]
[Lou+19]
[Moh+17]
[Mog+17]
[Liu+17b] W. Liu, Z. Wang, X. Liu, N. Zeng, Y. Liu, and F. E. Al-