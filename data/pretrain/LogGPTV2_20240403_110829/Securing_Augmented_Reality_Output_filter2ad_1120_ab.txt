each other unexpectedly in undesirable ways.
We also assume that Arya’s operating system employs
traditional, standard security best practices, e.g., application
isolation. In this work, we focus only on threats between
applications as they relate to the interaction of their AR output.
Additionally, we do not address the question of how the AR
output policies that Arya enforces are distributed. We assume
that these policies may (for example) be pre-loaded by the
device’s manufacturer, introduced by third-party sources, or
set based on user preferences. We assume that policies may be
buggy or malicious, and we do not require Arya to trust the
sources of these policies. Thus, our design must consider the
possibility of malicious or buggy policies.
Finally, we focus speciﬁcally on visual AR content, and we
consider issues related to non-visual output (e.g., haptic, audio)
to be out of scope. However, the lessons we surface through
this work may apply to other output modalities as well.
We now present
IV. DESIGN: ARYA
the design of Arya, an AR platform
architecture with output security as a ﬁrst-class goal. In de-
signing Arya, we identify and address new, fundamental design
challenges that future AR platforms must consider if they wish
to constrain AR application output. We begin with a high-level
overview of Arya in Section IV-A, summarized in Figure 4,
before describing its constituent components and the technical
challenges they address in greater depth.
A. System Overview
AR applications fundamentally require the ability to contin-
uously capture and process sensor inputs, and to superimpose
virtual output on the user’s view of the world. Consider the
collision warning application in Figure 1. This application
must know when the user moves too close to another car
so that it can display a warning whenever the user is at risk
for a collision. However, the user’s view of the real world
is constantly in ﬂux — the user may change lanes, or other
cars may move in front of the user. Furthermore, applications
may need to dynamically generate and update visual content
in response to these changes — e.g., to display a warning when
a collision is imminent. When this content is generated, Arya
may also need to modify it to ensure that the warning does not
Fig. 3: AR Concept Image. This concept image of an AR user on
a bus could represent a possible future in which AR output remains
unregulated, leaving users unable to control the intrusiveness of AR
applications. Full video available at http://www.theverge.com/2016/
5/20/11719244/hyper-reality-augmented-short-ﬁlm
platform here, we stress that they extend across platforms
and domains, such as AR-enabled windshields, which — like
HMDs — are fully immersive.
Thus, the high-level challenge we address in this work is
how an AR platform should constrain the output behaviors of
potentially buggy, malicious, or compromised applications, and
how it should handle conﬂicts between output from multiple
applications. We argue that emerging and future AR platforms
must address these questions if they wish to support rich,
untrusted applications that can be run simultaneously and
safely used while the user interacts with the physical world
(e.g., while walking or driving, not only while sitting at a
desk). We observe that undesirable output is not a new concern
in and of itself: recall
the early days of the web, when
web applications frequently opened popups and used blink
tags. Browser vendors eventually constrained these undesirable
behaviors by enabling popup blocking by default [33] and by
obsoleting the blink tag. Unlike misbehaving applications on
the early web, the effects of problematic AR output can range
from minor annoyance to direct physical harm.
Threat Model. The above risks inform our threat model and
security goals. Speciﬁcally, we consider one or more malicious,
buggy, or compromised applications that create AR content,
which may intentionally or accidentally:
• Obscure another application’s virtual content, in order
• Obscure important real-world content, such as trafﬁc
• Disrupt the user physiologically, such as by startling
them (e.g., by suddenly creating or quickly repositioning
virtual objects).
to hide or modify its meaning.
signs, cars, or people.
This set of threats is comparable to that used to motivate prior
work on AR output security [21], though how to build a system
to achieve these goals was then unknown.
To combat these threats, we design Arya, an AR platform
with a centralized, trusted output policy module that enforces
policies on AR content. These policies aim to mitigate the
above classes of threats, e.g., by preventing applications from
323
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
world raise serious privacy concerns. Additionally, if multiple
applications need to locate vehicles in the video feed,
it
would be inefﬁcient for each to implement vehicle detection
separately.
To address these privacy and performance issues, prior
work [18] proposed recognizers for AR platforms: OS modules
that process raw sensor streams, detect speciﬁc types of
information within those streams (e.g., vehicles, people, faces,
or planar surfaces), and expose these higher-level objects to ap-
plications. Recognizers enable a least-privilege model in which
applications can be given access to only those recognized
objects that they need. For example, a Pok´emon game may
not need a full video feed, but rather only information about
planar surfaces in the user’s view, to sensibly place Pok´emon
on horizontal surfaces.
In this work, we ﬁnd that recognizers provide an additional
beneﬁt beyond their original purpose of enabling input privacy.
Recognizers give Arya itself — and thereby Arya’s output
policy module — information about the user’s real-world sur-
roundings. For example,
to support a policy that prevents
applications from occluding people, Arya must know whether
and where there are people in the user’s view. Recognizers
provide this information and allow Arya to enforce output
policies that depend on the real world.
C. Output
Recall that our goal in designing Arya is to allow the OS
to control the visual output of AR applications. At a high
level, we do so by incorporating into the OS an output policy
module, which controls and modiﬁes AR application outputs
according to policies. Before describing these policies and their
enforcement in detail in upcoming sections, we describe here
the visual output abstractions that Arya exposes to applications.
Foundation: Displaying and Constraining Visual Output.
Arya builds on and instantiates the AR object abstraction for
displaying output, proposed in prior work [21]. Conceptually,
AR objects are OS primitives that encapsulate virtual content
that applications wish to overlay on a user’s view of the
real world. For example, a single Pok´emon creature would be
an AR object in Arya, and a single application may contain
many such objects. An AR object has a visual representation
and associated characteristics, such as size and opacity. AR
applications require the ability to create and transform these
objects (e.g., by moving, rotating, or resizing them), and Arya
supports these common operations.
Additionally, rather than requiring that applications manu-
ally update the locations of their objects as the user moves
throughout the physical world, Arya allows applications to
create “world-locked” objects that are attached to real-world
locations or objects, and Arya automatically updates where
they are rendered in the user’s display. For example, if an AR
application attaches a virtual object to a real-world table, Arya
can maintain this mapping, not requiring that the application
explicitly update how the object is displayed as the user moves.
Applications can also create “head-locked” objects that appear
Fig. 4: Overview of Arya’s Architecture. We design Arya, an AR
platform that consists of (1) system sensors, recognizers, and an input
policy module that ﬁlters input from the real world, based on prior
work (e.g., [18, 36, 40, 45]) and (2) an output policy module that
constrains application output. The design of the output policy module
is the primary contribution of this work.
sensor data from the real world.
to applications that require access.
occlude any pedestrians that stumble into the road, or impede
the driver’s view of the car that he or she is about to hit.
Arya consists of the following core modules, shown in Fig-
ure 4, that it employs to both support and constrain application
behaviors in the face of a dynamically changing environment:
• System Sensors and Recognizers, to gather and interpret
• The Input Policy Module, to ﬁlter and dispatch these data
• The Output Policy Module, to process any new appli-
cation requests to create or modify virtual content, and,
if applicable, modify this virtual content based on the
types of policies we introduce in this paper.
• Display Drivers, to display updated virtual state.
These modules are used to support applications running
on Arya that may call APIs to query information about the
real world and create or modify virtual objects. Arya steps
through a core workﬂow to process application requests and
produce every output video frame displayed to the user. We
ﬁrst discuss how Arya incorporates prior work to handle input
in Section IV-B, before turning to our primary contribution —
output management — in Section IV-C.
B. Input
Consider again the collision warning application from Fig-
ure 1. This application must be able to detect nearby vehicles,
identify where those vehicles are in relation to the user’s view,
and determine if a collision is imminent. One way a system
might support this capability is to expose the full camera
sensor feed to the application, allowing it to perform vehicle
detection. However, as prior works note (e.g., [18, 37, 40, 45]),
applications that can access raw, unﬁltered input from the real
324
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
at a ﬁxed location in the user’s display.1
Note that the AR object model differs from the “window”
display abstraction traditionally provided to applications, in
which applications have full control over a contiguous rectan-
gular screen area. A key beneﬁt of AR objects is that they
allow Arya to reason about application output and enforce
policies at the granularity of individual objects. For example, if
one Pok´emon creature obscures a real-world person, Arya can
take action against that one object (e.g., to make it transparent)
without affecting the rest of the Pok´emon application’s output.
We now turn to the remainder of our design. We present our
key design questions, describe the challenges involved in cre-
ating an output policy module that constrains AR application
output, and surface key design decisions made along the way.
1) SPECIFYING AR OUTPUT POLICIES
Output policies broadly serve to protect AR users from
deceptive, discomforting, or harmful content. While AR tech-
nologies are still quite young, concretely exploring the policy
design space grounded in today’s technologies allows us to
begin to identify key challenges for future AR systems and to
surface initial solutions. Thus, given an output policy module
that constrains virtual content in the form of AR objects, our
ﬁrst design question is the following:
Design Question: How can we translate abstract guidelines
into concrete policies that the output policy module can enforce
in practice? To help drive our design around this question,
we developed sample output policies for both HMD and
automotive AR scenarios. In addition to creating our own
policies, we draw on existing sources of guidelines for the rel-
evant scenarios, including the HoloLens developer guidelines
(which are suggestions, not technically enforced constraints),
the U.S. Department of Transportation guidelines for in-vehicle
electronic devices, and guidelines regarding the visibility of
street signs. These policies are summarized in Table I.
The ﬁrst observation we make based on our case study
policies in Table I is that they tell us only what conditions
should be avoided, not what to do when the conditions are
met. For example, we would like Arya’s output policy module
to prevent applications from creating objects that are too close
to the user, take up too much of the user’s ﬁeld of view,
block pedestrians, etc. However, existing guidelines do not
specify what actions the output policy module should take
if an application violates one of these policies. For example,
possible actions to enforce policies may include removing,
moving, or modifying (e.g., making more transparent) an app’s
AR objects. We consider these options further below.
Design Decision: Separate Policy Conditions and Mech-
anisms. The above observation raises an opportunity:
the
conditions under which policies apply (e.g., when an AR
object blocks a real-world person or is drawn too close to the
user) and the mechanisms used to enforce the policies (e.g.,
remove the AR object or make it transparent) can be speciﬁed
independently and composed as desired.
1HoloLens similarly supports world-locked and head-locked objects [30].
The key distinction is that Arya supports these features within the OS as part
of its output management, while HoloLens does so at the application layer.
Speciﬁcally, we deﬁne AR output policies to consist of two
distinct components:
1) A conditional predicate, or a boolean expression that
determines when a policy should be applied.
2) One or more mechanisms, or actions that the output
policy module should take when the policy’s conditional
predicate evaluates to true.
The next design question we face is then the following:
Design Question: How should policy conditions and mech-
anisms be expressed? The most ﬂexible approach would be
to allow conditions and mechanisms to consist of arbitrary
code, which would clearly support a wide range of policies.
However, arbitrary policy code raises several concerns. The
ﬁrst is performance: in the worst case, an arbitrarily-deﬁned
policy could halt the system by performing unbounded com-
putation. The second is unexpected results due to buggy or
untrusted policies: if policy mechanisms can arbitrarily modify
applications’ AR objects, then buggy policies could pose the
same risks as buggy apps themselves in the worst case.
Design Decision: Restrict Policies. Due to the challenges
raised by arbitrary policies, we instead develop an explicitly
restricted policy framework that requires policies to combine
options from a well-deﬁned set of parameterized conditions
and mechanisms supported by Arya. Though this construction
is limited by design, we ﬁnd that it is ﬂexible enough to express
the set of desirable policies we developed ourselves and drew
from other sources (see Table I).
Policy Conditions. We develop a ﬁnite set of building blocks
that policies can use to construct conditional predicates.
Speciﬁcally, we allow policies to refer to attributes of ob-
jects. We deﬁne attributes to be either (1) visual properties
of AR objects, such as size,
transparency, and speed, or
(2) relationships between AR objects and other virtual or
real-world objects. For example, relational attributes include
DistanceFromUser() or IsOccluding(type), where
“type” refers to a class of objects against which to check
for occlusion (virtual objects or speciﬁc types of real-world
objects detected by Arya’s recognizers, such as people). For
non-boolean attributes, a policy’s condition is then formed
by comparing one or more attributes of an AR object
to
parameter values speciﬁed by the policy — for example, “if
DistanceFromUser() < 10 meters”.
Finally, we allow policy conditions to depend not only on
the attributes of AR objects, but also on global contextual
information. For example, a policy may depend on properties
of the user’s platform (e.g., if a user’s car is in motion) or
other contextual information (e.g., time of day).
Policy Mechanisms. Policy mechanisms are more challenging
to design, because they involve not
just deriving boolean
results, but modifying application behaviors. As mentioned
above, possible mechanisms that Arya might support include
deleting applications’ AR objects (or not allowing them to be
created in the ﬁrst place), modifying them (e.g., to change their
transparency or size), or moving them (e.g., away from block-
ing another object). In experimenting with different possible
mechanisms, we identiﬁed the following challenge:
325
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
Identiﬁer
P1
P2
P3
P4
P5
P6
P7
P8
P9
P10
Description
Avoid abrupt movement of AR objects.
Place AR objects at a comfortable viewing distance from the user.
Allow the user to see the real world in the background.
Avoid content that is “head-locked” (at a ﬁxed location in the display).
Don’t display text messages or social media while driving.
Don’t obscure pedestrians or road signs.
Don’t obscure exit signs.
Disable user input on transparent AR objects.
Only allow advertisements to be overlaid on real-world billboards.
Don’t allow AR objects to occlude other AR objects.
Applies To
Car, HMD
Car, HMD
Car, HMD
HMD