nel to exchange the MAC address of the ETH module below
it.2 Apart from communication with peer modules, modules
2Note that ARP achieves this in the existing set-up and even
may need more help in determining the low-level parameters
– they express these as dependencies that need to be satisﬁed
before the pipe can be created.
2.3.2 Switch
Switches capture the ability of modules to pass packets be-
tween up, down and physical pipes. A switch can be unicast
or multicast and can have a small number of basic conﬁgu-
rations: packets pass between down and up pipes ([down ⇒
up] and [up ⇒ down] switching, e.g. TCP module), [down ⇒
down] switching (e.g. IP module with forwarding enabled),
[up ⇒ up] switching (e.g. IP module with loopback function-
ality), [up ⇒ phy], [phy ⇒ up] and [phy ⇒ phy] switching
(eg. Ethernet module). A module advertises its switching
capabilities. The NM uses this and the information about
the connectable-modules of each module to build a potential
connectivity graph for the network. As we show in section 3.3,
this allows the NM to determine what paths are and are not
possible. For instance, the ETH module in a Layer-2 switch-
ing device advertises that it can do [phy ⇒ phy] switching
and so, can be used by itself along a path between two de-
vices that the NM is trying to connect. As a contrast, the
ETH module in a router would not have [phy ⇒ phy] switch-
ing capability and so, the NM must use it in conjunction with
the IP module on the router.
When incorporating a module as part of a path, the NM
must direct the module as to how packets must be switched
between the pipes just created – this is the actual switch con-
ﬁguration. Of course, it is not necessary that there be a one-
to-one mapping between the pipes. Instead, incoming packets
on a pipe may be switched to one of many other pipes and
hence, switches may have state which conditions how pack-
ets are switched. This switching state can be determined by
the module through interaction with its peer module. For in-
stance, the NM, as part of establishing an IP-IP tunnel, may
direct an IP module to switch packets between up-pipe P1
(to another IP module) and down-pipe P2 (to the underly-
ing ETH module). The creation of pipe P1 and P2 and the
actual switch rule causes the three modules to interact with
their peers and determine the parameters needed for a low-
level routing rule such as ip route to 204.9.169.1 dev eth1
nexthop 204.9.168.1. Alternatively, it also possible that the
switching state is generated by control protocols and this is
exposed as part of the module abstraction. Section 2.6 dis-
cusses these alternatives.
2.3.3 Filters
The ﬁlter abstraction allows modules to describe whether
and how they can ﬁlter packets. Filter rules are described in
terms of other abstracted components: pipes, devices, mod-
ules or even module types. Note that in conﬁguring a ﬁlter,
the NM only needs to specify the component names or iden-
tiﬁers that need to be ﬁltered - it is the protocol implementa-
tion that is responsible for determining the relevant protocol
ﬁelds (such as addresses and port numbers). This process
and other related issues are detailed in section 2.5.
2.3.4 Performance
Unlike the components above, which are quite speciﬁc in
nature, performance is harder to specify and manipulate. In
our current abstraction, performance is reported in terms of
Name
Caller
Callee
Description
showPotential
showActual
create, delete
conveyMessage
listFieldsAndValues
NM
NM
NM
Module
(Source)
Module
(Inspecting)
MA of device
MA of device
MA of device
Module
(Destination)
Module
(Target)
Sec. 2.4
Sec. 2.4
Sec. 2.4
Sec. 2.4
Sec. 2.5
Table 1: Functions that are part of the CONMan
architecture
six generic performance metrics - delay, jitter, bandwidth,
loss-rate, error-rate, and ordering. These encompass most of
the IP performance metrics proposed by IETF [36]; though
in our architecture the metrics can be used by any module
that has the ability to describe its performance, not just the
IP module. Additional metrics, such as power, can be added
as needed.
Modules and pipes report on their performance with these
metrics. They can also advertise the ability to oﬀer per-
formance trade-oﬀs in terms of these metrics. For exam-
ple, many MAC layer protocols oﬀer optional error correcting
checksums which represent a trade-oﬀ between error-rate on
one hand and bandwidth and delay on the other.
Instead
of exposing the low-level options and associated parameters,
modules specify the trade-oﬀs they can enforce. Just as with
ﬁlters, the module might allow these trade-oﬀs to be applied
to speciﬁc traﬃc classes as speciﬁed by the names of mod-
ules or pipes and this too is advertised. However, more work
is needed towards the way these performance trade-oﬀs can
be quantiﬁed and what they can capture. Further, protocols
modules may have other features such as performance en-
forcement and security capabilities. Due to space constraints,
this paper does not delve into these abstraction components
– we refer the interested reader to [4].
2.4 Network Manager (NM)
The management channel allows devices in the network to
communicate with the NM. Each device uses this to inform
the NM of its physical connectivity, thus allowing the NM to
determine the network topology. Beyond this, given the net-
work potential, the NM can achieve high level network conﬁg-
uration goals simply by creating and deleting pipes and mod-
ule components. The following primitives capture the NM’s
interaction with the devices in the network as part of net-
work conﬁguration. Table 1 shows these and other CONMan
primitives oﬀered by the NM and the modules themselves.3
(a). showPotential () allows the NM to determine a device’s
capabilities. The device returns a list of modules with their
abstractions. The type of information returned for each mod-
ule is shown in table 2.
(b). showActual () allows the NM to determine the state of
modules in a device. The state of each module includes state
for all the pipes, the switch, ﬁlters, performance and secu-
rity enforcement elements. Also returned is a report on the
performance parameters. In eﬀect, the NM is presented with
the network reality - a module graph and associated infor-
mation which allows it to understand how the device (and
hence, the network) is or should be behaving. By contrast,
in the current set up, the NM is presented with all kinds of
with CONMan, the IP module could just as well rely on ARP
for the peer’s MAC address.
3We do not give details of the CONMan API. However, we
do show the use of these primitives in section 3.
Parameter
Name
Up and
Down pipes
Physical
pipes
Peerable-Mod.
Filter
Switch
Performance
Reporting
Performance
Trade-Oﬀs
Others
What is advertised?
Information about up and down pipes such as
connectable-modules, dependencies etc.
Information about the physical pipes (if any)
connected to the module
Set of modules that can be peers of this module
Classiﬁcation based on which ﬁltering can be done:
what can be ﬁltered and where it can be ﬁltered
Possible switching between up, down and physical
pipes; Is the switch state generated locally
or needs to be provided externally
Performance metrics that are reported for the
module’s pipes, ﬁlters, switch etc.
Traﬃc classes to which performance trade-oﬀs
can be applied and the possible trade-oﬀs
Performance Enforcement and Security
Capabilities (not explained)
Table 2: Module abstraction; showPotential () describes
each module using this abstraction
MIB objects from which it must deduce network behavior.
(c). create () and delete () allow the NM to create and delete
pipes, ﬁlter-rules, switch-rules and performance enforcement
state (queuing structures or service classes). The showPoten-
tial () function provides the NM with all the information it
needs to create and delete components.
The NM does not need protocol speciﬁc knowledge to use
these primitives. For instance, it can create up-down pipes
simply by satisfying their dependencies and invoking the cre-
ate function. For instance, consider a NM creating a pipe
between an IP module and an underlying GRE module. In
terms of today’s conﬁguration, this amounts to creating a new
GRE tunnel which requires a number of low-level parameters
to be speciﬁed. With CONMan, it is the GRE module that
coordinates these parameters with its peer GRE module. For
instance, the modules may exchange the tunnel key values
to be used, so the NM does not need to know the notion of
keys. Since the management channel allows the modules to
communicate only with the NM, the NM provides:
(d). conveyMessage () allows modules to convey messages
to each other through the NM (see detailed example in sec-
tion 3.2).
2.5 Hiding Complexity
Much of the reduction in management plane complexity
comes from the fact that the NM operates in terms of the
abstract components, while the protocol modules themselves
translate these into concrete protocol objects.
For example, the NM can simply ask a module to ﬁlter
packets between two given modules - “drop packets from
module  and going to ” (where FOO
is an application module with up-down pipes to TCP). The
protocol module itself is responsible for determining the ac-
tual protocol ﬁelds. For example, given the high-level speciﬁ-
cation above, the inspecting module determines that it needs
to “drop packets from source address 128.19.2.3 and destined
to address 20.3.4.5, port 592”. This ensures that the NM,
while being opaque to protocol-speciﬁc ﬁelds, can trace the
paths between applications and hence, can reason about its
policies regarding a particular application-module.
In some cases, the inspecting module may know what ﬁelds
and ﬁeld values to check for on its own. But in other cases, it
may not. To address this, CONMan modules provide a list-
FieldsAndValues () function. This allows other modules to
query the target module for the low-level ﬁelds and ﬁeld val-
ues corresponding to the identiﬁers associated with its com-
ponents. Hence, in the example above, the inspecting mod-
ule can send queries to the target modules  and
 (via the NM), as well as to the modules below
them, and ask those modules what ﬁeld values it should be
checking for.
Such an approach also allows for maintenance of network
state dependencies – the need to update the dependent state
in diﬀerent modules when some low-level value in a given
module changes. To ensure this, the NM tracks the dependen-
cies between component identiﬁers (that have been resolved)
and opaque low-level ﬁelds. Also, the NM installs triggers in
the target modules telling them to inform the NM when their
low-level values change.
However, not all detailed protocol values can be or should
be determined by the protocols themselves. For instance, it
appears diﬃcult to expect IP modules to chat among them-
selves and assign IP addresses [12]. This is best done by
the NM having explicit knowledge of how to assign IP ad-
dresses (as DHCP servers do today). Similarly, tasks like
regular expression matching in HTML do not seem amenable
to abstraction and should be done by specialized NMs such
as Intrusion Detection Systems. Further, there are cases such
as P2P protocols where protocol designers don’t want to pro-
vide the protocol values since they don’t want to be ﬁltered.
Thus, there are scenarios where the NM will have to deal with
protocol-speciﬁc details.
2.6 Control Modules
Many data-plane protocols rely on externally generated
state for their operation. Today, this may be provided man-
ually as part of the protocol conﬁguration. Alternatively,
control-plane protocols can generate some of the state re-
quired for data plane operation. For example, routing proto-
cols generate the IP routing table. Similarly, LCP generates
PPP conﬁguration state.
In CONMan, data modules can generate this state by in-
teracting with their peer modules based on the create/delete
primitives invoked by the NM. While this follows from the
general CONMan philosophy, there are cases where such an
approach poses challenges regarding the scalability, robust-
ness and responsiveness of the network.
Alternatively, even in CONMan, we may rely on control
protocols for the low-level state. However, control modules
do not ﬁt into the generic module abstraction presented ear-
lier. Instead, they advertise their ability to provide the state
for certain data modules and the NM simply uses them. For
example, the PPP module could advertise that it has a de-
pendency on external state (say, X) and the LCP module
advertises that it can satisfy dependency X. While relying on
control modules suﬃces in some cases, there are also cases
when the control module itself requires quite a bit of conﬁg-
uration. Also, the fact that the NM does not generate this
state hinders its ability to understand related network oper-
ations and gets in the way of root-cause analysis. Finally, er-
rors in control module operation cannot always be debugged
by the NM. For example, the NM does not understand BGP
and hence, cannot be expected to debug route ﬂaps and the
resulting preﬁx dampening.
One way to address some of these problems is to let the
NM perform the function of the control protocols whereby it
uses some high-level goal to generate the required state itself.
Of course, this implies that the state generation logic must
be embedded into the NM. For example, the 4D research [14]
Human Manager  
High-level
goal
Configure   
connectivity .. 
NM 
Low-level
goal
Configure
path ..
NM 
CONMan
script
(shown in
fig 7(b))
Protocol
Module
(current implementation)
Protocol state 
(ideal scenario) 
Device-level
scripts
Figure 2: CONMan workﬂow: from high-level goals
to device conﬁguration
argues for the replacement of routing protocols, with the NM
using its knowledge of the topology to set the switch state for
IP modules in devices across the network. A characterization
of the scenarios in which state should be generated by the
protocols themselves against the ones in which existing con-
trol protocols should be used against the ones in which the
control protocols should be replaced is an important question
in the context of CONMan. However, in order to explore the
limits of our proposal (i.e. what can be captured and what
cannot be captured), this paper (rather naively) ignores the
existence of control protocols. Hence, our implementation,
for the most part, involves the protocol modules generating
the low-level details.
3.
IMPLEMENTATION
In CONMan, human managers don’t write device-level scri-
-pts; instead, they specify high-level conﬁguration goals and
it is the NM and the protocol modules that map these to
the required low-level conﬁguration. This process is shown in
ﬁgure 2 and is detailed in various parts of this section.
We implemented four protocols (GRE, MPLS, IP, ETH)
as CONMan modules through user-level wrappers around
the corresponding existing protocol implementation in Linux
(kernel 2.6.14). We also implemented a NM that under-
stands the CONMan abstraction and implements the CON-
Man NM primitives. In section 3.2, we use the establishment
of GRE tunnels as an example to detail our GRE module
implementation. This, in eﬀect, describes the mapping of a
low-level goal to device-level scripts (see ﬁgure 2).
In sec-
tion 3.3, we detail how our NM implementation can map a
human-speciﬁed high-level goal to low-level goals by describ-
ing the conﬁguration of provider-provisioned Virtual Private
Networks (VPNs) with CONMan.
3.1 Management Channel
The testbed used for the examples described below com-
prised of Linux-based PCs operating as end-hosts and routers
with Ethernet as the connecting medium. All the PCs were
equipped with a separate management NIC and connected to
a separate network that served as the management channel
for our experiments. Communication between the protocol
modules and the NM was done through UDP-IP over this
management channel. Note that this is not ideal since the
management channel had to be pre-conﬁgured; however, this