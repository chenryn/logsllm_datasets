assignment that deﬁnes xk, and dec(enc(m, kgen(r), r(cid:2)),
kgen(r)) = i⊥(m) by (enc). So we have dec(x(cid:2)
m, xk) =
i⊥(k2b(x(cid:2)
k[u])). By injectivity of i⊥ and k2b, the assign-
ment to x(cid:2)(cid:2)
k simply becomes x(cid:2)(cid:2)
k[u], using the equa-
tions ∀x : bitstring, i−1
and ∀x : Tk,
k2b−1(k2b(x)) = x.
⊥ (i⊥(x)) = x.
k = x(cid:2)
After applying RemoveAssign(xk), one can apply the
k), kgen(xr), x(cid:2)(cid:2)
security of encryption: enc(k2b(x(cid:2)
r ) be-
r ). After Simplify,
comes enc(cid:2)(Z(k2b(x(cid:2)
it becomes enc(cid:2)(Zk, kgen(xr), x(cid:2)(cid:2)
r ), using ∀x : Tk,
Z(k2b(x)) = Zk (which expresses that all keys have the
same length).
k)), kgen(xr), x(cid:2)(cid:2)
Using lists instead of arrays simpliﬁes this transfor-
mation: we do not need to add instructions that insert
values in the list, since all variables are always implic-
itly arrays. Moreover, if there are several occurrences of
mac(xi, k) with the same key in the initial process, each
check (mj, k, maj) is replaced with a ﬁnd with one branch
for each occurrence of mac. Therefore, the prover dis-
tinguishes automatically the cases in which the checked
mac maj comes from each occurrence of mac, that is, it
distinguishes cases depending on the value of i such that
mj = xi. Typically, distinguishing these cases is useful in
the following of the proof of the protocol. (A similar situa-
tion arises for other cryptographic primitives speciﬁed using
ﬁnd.)
4 Criteria for Proving Secrecy Properties
Let us now deﬁne syntactic criteria that allow us to prove
secrecy properties of protocols.
We use if deﬁned (M ) then P as syntactic sugar for
ﬁnd suchthat deﬁned (M ) ∧ 1 then P else yield(cid:5)(cid:6).
Deﬁnition 4 (One-session secrecy) The process Q pre-
serves the one-session secrecy of x when Q | Qx ≈
Q | Q(cid:2)
x, where
Qx = c(u1 : [1, n1], . . . , um : [1, nm]);
if deﬁned (x[u1, . . . , um]) then c(cid:5)x[u1, . . . , um](cid:6)
Q(cid:2)
x = c(u1 : [1, n1], . . . , um : [1, nm]);
if deﬁned (x[u1, . . . , um]) then new y : T ; c(cid:5)y(cid:6)
c /∈ fc(Q), u1, . . . , um /∈ var(Q), and E(x) = [1, n1] ×
. . . × [1, nm] → T .
Intuitively, the adversary cannot distinguish a process that
outputs the value of the secret from one that outputs a ran-
dom number. The adversary performs a single test query,
modeled by Qx and Q(cid:2)
x.
Proposition 4 (One-session secrecy) Consider a process
Q such that there exists a set of variables S such that 1)
the deﬁnitions of x are either restrictions new x[(cid:2)i]
: T
and x ∈ S, or assignments let x[(cid:2)i] : T = z[M1, . . . , Ml]
where z is deﬁned by restrictions new z[i(cid:2)
l] : T , and
z ∈ S, and 2) all accesses to variables y ∈ S in Q are of the
form “let y(cid:2)[(cid:2)i] : T (cid:2) = y[M1, . . . , Ml]” with y(cid:2) ∈ S. Then
Q | Qx ≈0 Q | Q(cid:2)
x, hence Q preserves the one-session
secrecy of x.
1, . . . , i(cid:2)
Intuitively, only the variables in S depend on the restriction
that deﬁnes x; the sent messages and the control ﬂow of the
process are independent of x, so the adversary obtains no
information on x. In the implementation, the set S is com-
puted by ﬁxpoint iteration, starting from x or z and adding
variables y(cid:2) deﬁned by “let y(cid:2)[(cid:2)i] : T (cid:2) = y[M1, . . . , Ml]”
when y ∈ S.
Deﬁnition 5 (Secrecy) The process Q preserves the se-
crecy of x when Q | Rx ≈ Q | R(cid:2)
x, where
Rx = !i≤nc(u1 : [1, n1], . . . , um : [1, nm]);
R(cid:2)
if deﬁned (x[u1, . . . , um]) then c(cid:5)x[u1, . . . , um](cid:6)
x = !i≤nc(u1 : [1, n1], . . . , um : [1, nm]);
if deﬁned (x[u1, . . . , um]) then
ﬁnd u(cid:2) ≤ n suchthat deﬁned (y[u(cid:2)], u1[u(cid:2)], . . . , um[u(cid:2)])
∧ u1[u(cid:2)] = u1 ∧ . . . ∧ um[u(cid:2)] = um
then c(cid:5)y[u(cid:2)](cid:6) else new y : T ; c(cid:5)y(cid:6)
c /∈ fc(Q), u1, . . . , um, u(cid:2) /∈ var(Q), E(x) = [1, n1]×. . .×
[1, nm] → T , and Iη(n) ≥ Iη(n1) × . . . × Iη(nm).
Intuitively, the adversary cannot distinguish a process that
outputs the value of the secret for several indexes from one
that outputs independent random numbers. In this deﬁni-
tion, the adversary can perform several test queries, mod-
eled by Rx and R(cid:2)
x. This corresponds to the “real-or-
random” deﬁnition of security [4]. (As shown in [4], this
notion is stronger than the more standard approach in which
the adversary can perform a single test query and some re-
veal queries, which always reveal x[u1, . . . , um].)
Proposition 5 (Secrecy) Assume that Q satisﬁes the hy-
pothesis of Proposition 4.
When T is a trace of C[Q] for some evaluation con-
text C, we deﬁne defRestrT (x[(cid:2)a]), the deﬁning restric-
tion of x[(cid:2)a] in trace T , as follows: if x[(cid:2)a] is deﬁned by
new x[(cid:2)a] : T in T , defRestrT (x[(cid:2)a]) = x[(cid:2)a]; if x[(cid:2)a] is de-
ﬁned by let x[(cid:2)a] : T = z[M1, . . . , Ml], defRestrT (x[(cid:2)a]) =
z[a(cid:2)
k for all k ≤ l and E is the
environment in T at the deﬁnition of x[(cid:2)a].
for all evaluation contexts C accept-
able for Q, 0, {x}, the probability Pr[T ∧ (cid:2)a (cid:12)= (cid:2)a(cid:2) ∧
l] where E, Mk ⇓ a(cid:2)
Assume that
1, . . . , a(cid:2)
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
defRestrT (x[(cid:2)a]) = defRestrT (x[(cid:2)a(cid:2)])] is negligible. Then
Q preserves the secrecy of x.
The hypothesis can be veriﬁed using simpliﬁcation (see
Simplify in Section 3.1). Intuitively, the required condition
guarantees that when (cid:2)a (cid:12)= (cid:2)a(cid:2), we have defRestrT (x[(cid:2)a]) (cid:12)=
defRestrT (x[(cid:2)a(cid:2)]) except in cases of negligible probability,
so x[(cid:2)a] and x[(cid:2)a(cid:2)] are deﬁned by different restrictions so they
are independent random numbers. This notion of secrecy
composed with correspondence assertions [46] can be used
to prove security of a key exchange. (Correspondence as-
sertions are properties of the form “if some event e((cid:4)M ) has
been executed then some events ei((cid:4)Mi) for i ≤ m have
been executed”.) We postpone this point to a future paper,
since we do not present the veriﬁcation of correspondence
assertions in this paper. (This veriﬁcation is currently being
implemented.)
Lemma 2 If Q ≈{x} Q(cid:2) and Q preserves the one-session
secrecy of x then Q(cid:2) preserves the one-session secrecy of x.
The same result holds for secrecy.
We can then apply the following technique. When we want
to prove that Q0 preserves the (one-session) secrecy of x,
we transform Q0 by the transformations described in Sec-
tion 3 with V = {x}. By Propositions 1 and 3, we obtain
a process Q(cid:2)
0. We use Propositions 4
or 5 to show that Q(cid:2)
0 preserves the (one-session) secrecy
of x, and ﬁnally conclude that Q0 also preserves the (one-
session) secrecy of x by Lemma 2.
0 such that Q0 ≈V Q(cid:2)
k : Tk = x(cid:2)
Example 4 After the transformations of Example 3, the
only variable access to x(cid:2)
k in the considered process is
let x(cid:2)(cid:2)
k[u] and x(cid:2)(cid:2)
k is not used in the considered
process. So by Proposition 4, the considered process pre-
serves the one-session secrecy of x(cid:2)(cid:2)
k}).
By Lemma 2, the process of Example 1 also preserves the
one-session secrecy of x(cid:2)(cid:2)
k. However, this process does not
preserve the secrecy of x(cid:2)(cid:2)
k, because the adversary can force
several sessions of B to use the same key x(cid:2)(cid:2)
k, by replay-
ing the message sent by A. (Accordingly, the hypothesis of
Proposition 5 is not satisﬁed.)
k (with S = {x(cid:2)
k, x(cid:2)(cid:2)
The criteria given in this section might seem restric-
tive, but in fact, they should be sufﬁcient for all proto-
cols, provided the previous transformation steps are power-
ful enough to transform the protocol into a simpler protocol,
on which these criteria can then be applied.
5 Proof Strategy
Up to now, we have described the available game trans-
formations. Next, we explain how we organize these trans-
formations in order to prove protocols.
At the beginning of the proof, and after each success-
ful cryptographic transformation (that is, a transformation
of Section 3.2), the prover executes Simplify, and tests
whether the desired security properties are proved, as de-
scribed in Section 4. If so, it stops.
In order to perform the cryptographic transformations
and the other syntactic transformations, our proof strategy
relies of the idea of advice. Precisely, the prover tries to ex-
ecute each available cryptographic transformation in turn.
When such a cryptographic transformation fails, it returns
some syntactic transformations that could make the desired
transformation work.
(These are the advised transforma-
tions.) Then the prover tries to perform these syntactic
transformations. If they fail, they may also suggest other
advised transformations, which are then executed. When
the syntactic transformations ﬁnally succeed, we retry the
desired cryptographic transformation, which may succeed
or fail, perhaps with new advised transformations, and so
on.
The prover determines the advised transformations using
the following main conditions:
• Assume that we try to execute a cryptographic trans-
formation, and need to recognize a certain term M
of L, but we ﬁnd in Q0 only part of M, the other
parts being variable accesses x[. . .] while we ex-
In this case, we ad-
pect function applications.
vise RemoveAssign(x). For example,
if Q0 con-
tains enc(M (cid:2), xk, x(cid:2)
r) and we look for enc(xm,
kgen(xr), xr(cid:2) ), we advise RemoveAssign(xk).
If
let xk = mkgen(xr) and we
Q0
look for mac(xm, mkgen(xr)), we also advise
RemoveAssign(xk).
(The transformation of Exam-
ple 2 is advised for this reason.)
contains
• When we try to execute RemoveAssign(x), x has sev-
eral deﬁnitions, and there are accesses to variable x
guarded by ﬁnd in Q0, we advise SArename(x).
• When we check whether x is secret or one-session se-
cret, we have an assignment let x[(cid:2)i] : T = y[(cid:4)M ] in P ,
and there is at least one assignment deﬁning y, we ad-
vise RemoveAssign(y).
6 Experimental Results
We have successfully tested our prover on a number of
protocols of literature. All these protocols have been tested
in a conﬁguration in which the honest participants are will-
ing to run sessions with the adversary, and we prove secrecy
of keys for sessions between honest participants. In these
examples, shared-key encryption is encoded using a stream
cipher and a mac as in Example 1, public-key encryption is
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
assumed to be IND-CCA2 (indistinguishability under adap-
tive chosen-ciphertext attacks) [13], public-key signature is
assumed to be secure against existential forgery.
Otway-Rees [40]: We automatically prove the secrecy of
the exchanged key.
Yahalom [18]: For the original version of the protocol,
our prover cannot show one-session secrecy of the ex-
changed key, because the protocol is not secure, at least us-
ing encrypt-then-mac as deﬁnition of encryption. Indeed,
there is a conﬁrmation round {NB}K where K is the ex-
changed key. This message may reveal some information
on K. After removing this conﬁrmation round, our prover
shows the one-session secrecy of K. However, it cannot
show the secrecy of K, since in the absence of a conﬁr-
mation round, the adversary may force several sessions of
Yahalom to use the same key.
[38]: Our
shared-key
Needham-Schroeder
prover
shows one-session secrecy of the exchanged key. It does
not prove the secrecy of the exchanged key, since there
is a well known attack [23] in which the adversary forces
several sessions of the protocol to use the same key. Our