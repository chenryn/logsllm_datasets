I'm trying to scrape the content from this link on my macOS, using `scrapy`
with `scrapy_splash` settings and `BeautifulSoup` I followed the instructions
in the documentation
  * I tested every single command in scrapy shell and each works perfectly fine, tested on several pages. when I run the spider with the same commands, it fails to detect any of the items.
`settings.py`
    BOT_NAME = 'stepstone'
    SPIDER_MODULES = ['stepstone.spiders']
    NEWSPIDER_MODULE = 'stepstone.spiders'
    SPLASH_URL = 'http://0.0.0.0:8050'  # changed from the documentation's http://192.168.59.103:8050 which does not work 
    DOWNLOADER_MIDDLEWARES = {
        'scrapy_splash.SplashCookiesMiddleware': 723,
        'scrapy_splash.SplashMiddleware': 725,
        'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 810,
    }
    SPIDER_MIDDLEWARES = {
        'scrapy_splash.SplashDeduplicateArgsMiddleware': 100,
    }
    DUPEFILTER_CLASS = 'scrapy_splash.SplashAwareDupeFilter'
    HTTPCACHE_STORAGE = 'scrapy_splash.SplashAwareFSCacheStorage'
The spider module:
    from scrapy.spiders import Spider
    from scrapy_splash import SplashRequest
    from scrapy import Request
    from bs4 import BeautifulSoup
    class StepSpider(Spider):
        name = 'step'
        allowed_domains = ['www.stepstone.de']
        start_urls = [
            'https://www.stepstone.de/5/ergebnisliste.html?stf=freeText&ns=1&qs='
            '%5B%7B%22id%22%3A%22216805%22%2C%22description%22%3A%22Software-Entw'
            'ickler%2Fin%22%2C%22type%22%3A%22jd%22%7D%2C%7B%22id%22%3A%223000001'
            '15%22%2C%22description%22%3A%22Deutschland%22%2C%22type%22%3A%22geoc'
            'ity%22%7D%5D&companyID=0&cityID=300000115&sourceOfTheSearchField=home'
            'pagemex%3Ageneral&searchOrigin=Homepage_top-search&ke=Software-Entwic'
            'kler%2Fin&ws=Deutschland&ra=30/'
        ]
        @staticmethod
        def extract_item(soup, extraction_path):
            result = soup.find(*extraction_path)
            if result:
                return result.getText()
        def parse(self, response):
            soup = BeautifulSoup(response.body, features='lxml')
            listings = [
                response.urljoin(item)
                for item in response.xpath('//div/div/a/@href').extract()
                if 'stellenangebote' in item
            ]
            yield from [
                Request(
                    url,
                    callback=self.parse_item,
                    cb_kwargs={'soup': soup},
                    meta={'splash': {'args': {'html': 1, 'png': 1,}}},
                )
                for url in listings
            ]
            next_page = soup.find('a', {'data-at': 'pagination-next'})
            if next_page:
                yield SplashRequest(next_page.get('href'), self.parse)
        def parse_header(self, response, soup):
            title = response.xpath('//h1/text()').get()
            location = self.extract_item(
                soup, ('li', {'class': 'at-listing__li: st-icons_location'})
            )
            contract_type = self.extract_item(
                soup, ('li', {'class': 'at-listing__list-icons_contract-type'})
            )
            work_type = self.extract_item(
                soup, ('li', {'class': 'at-listing__list-icons_work-type'})
            )
            return {
                'title': title,
                'location': location,
                'contract_type': contract_type,
                'work_type': work_type,
            }