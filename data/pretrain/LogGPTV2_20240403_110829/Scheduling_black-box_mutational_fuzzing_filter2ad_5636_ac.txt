of the outcome distributions, enabling it to hone in on the
special pair (p∗
i ) and ﬁnd the bug in the ﬁrst epoch. This
establishes that K is a lowerbound for the competitive ratio
of any deterministic algorithm.
i , s∗
Finally, we observe that Round-Robin is a deterministic
online algorithm that achieves the competitive ratio K in
every problem instance. It follows immediately that K is
tight.
4.3 Upperbounding the Probability of Seeing
a New Outcome During Fuzzing
Having seen such strong impossibility results, let us consider
what a pragmatist might do before bringing in any prior on
the outcome type distribution. In other words, if we do not
want to make any assumptions on this distribution, is there
a justiﬁable approach to designing online algorithms for the
FCS problem?
We argue that the answer is yes. Consider two program-
seed pairs (p1, s1) and (p2, s2) for which we have upperbounds
on the probability of ﬁnding a new outcome if we fuzz them
once more. Assume that the upperbound for (p1, s1) is the
higher of the two.
We stress that what we know are merely upperbounds—it
is still possible that the true probability of yielding a new
outcome from fuzzing (p1, s1) is lower than that of (p2, s2).
Nonetheless, with no information beyond the ordering of
these upperbounds, fuzzing (p1, s1 ) ﬁrst is arguably the
more prudent choice. This is because to do otherwise would
indicate a belief that the actual probability of ﬁnding a new
outcome by fuzzing (p1, s1) in the next fuzz run is lower than
the upperbound for (p2, s2).
Accepting this argument, how might we obtain such upper-
bounds? We introduce the Rule of Three for this purpose.
Rule of Three. Consider an experiment of independent
Bernoulli trials with identical success and failure probabilities
p and q = (1 − p). Suppose we have carried out N ≥ 1 trials
so far and every trial has been a success. What can we say
about q other than the fact that it must be (i) at least 0
to be a valid probability and (ii) strictly less than 1 since
p is evidently positive? In particular, can we place a lower
upperbound on q?
Unfortunately, the answer is a resounding no: even with q
arbitrarily close to 1, we still have (pN > 0). This means our
observation really could have happened even if it is extremely
unlikely.
Fortunately, if we are willing to rule out the possibility of
encountering extremely unlikely events, then we may com-
pute a lower upperbound for q by means of a conﬁdence
interval. For example, a 95% conﬁdence interval on q out-
puts an interval that includes the true value of q of the
underlying experiment with 95% certainty. In other words,
if the outputted interval does not contain the true value of
q for the experiment, then the observed event must have a
likelihood of at most 5%.
For the above situation, there is particularly neat technique
to compute a 95% conﬁdence interval on q. Known as the
“Rule of Three”, this method simply outputs 0 and 3/N for the
lowerbound and upperbound, respectively. The lowerbound
is trivial, and the upperbound has been shown to be a good
approximation for N > 30. See [15] for more information
on this technique, including the relationship between 95%
conﬁdence and the constant 3.
How We Use Rule of Three. In order to apply the Rule
of Three, we must adapt our fuzzing experiments with any
M > 1 possible outcome types to ﬁt the mold of Bernoulli
trials.
outcome of type k. Let N ((cid:96)) =(cid:80) ˆM ((cid:96))
We make use of a small trick. Suppose we have just ﬁnished
epoch (cid:96) and consider a particular conﬁguration (pi, si). Using
our notation, we have observed ˆM ((cid:96)) diﬀerent outcomes so
far and for 1 ≤ k ≤ ˆM ((cid:96)), we have observed nk((cid:96)) counts of
k=1 nk((cid:96)) denote the total
number of fuzz runs for this pair through epoch (cid:96). The trick
is to deﬁne a “success” to be ﬁnding an outcome of type 1
through type ˆM ((cid:96)). Then, in hindsight, it is the case that
our experiment has only yielded success so far.
With this observation, we may now apply the Rule of Three
to conclude that [0, 3/N ((cid:96))] is a 95% conﬁdence interval on
the “failure” probability—the probability that fuzzing this
conﬁguration will result in an outcome type that we have
not seen before, i.e., a new outcome. Then, as desired, we
have an easy-to-compute upperbound on the probability of
ﬁnding a new outcome for each conﬁguration.
We introduce one more piece of notation before proceeding:
deﬁne the Remaining Probability Mass (RPM) of (pi, si) at
the end of epoch (cid:96), denoted RPM((cid:96)), to be the probability
of ﬁnding a new outcome if we fuzz (pi, si) once more. Note
that the pair in RPM((cid:96)) is implicit, and that this value
is upperbounded by 3/N ((cid:96)) if we accept a 95% conﬁdence
interval.
4.4 Design Space
In this section, we explore the design space that a pragma-
tist may attempt when designing online algorithms for the
Fuzz Conﬁguration Scheduling problem. A depiction of the
design space, along with our experimental results, is given in
Table 2 in §6. Our focus here is to explain our motivation for
choosing the three dimensions we explore and the particular
choices we include in each dimension. By combining these
dimensions, we obtain 26 online algorithms for our prob-
lem. We implemented these algorithms inside a simulator,
FuzzSim, the detail of which is presented in §5.
Epoch Type. We consider two possible deﬁnitions of an
epoch in a fuzz campaign. The ﬁrst is the more traditional
choice and is used in the current version of CERT BFF
v2.6 [14]; the second is our proposal.
Fixed-Run. Each epoch executes a constant number of
fuzz runs. In FuzzSim, a ﬁxed-run epoch consists of 200
runs. Note that any diﬀerential in fuzzing speed across
conﬁgurations translates into variation in the time spent in
ﬁxed-run epochs.
Fixed-Time. Each epoch is allocated a ﬁxed amount of
time. In FuzzSim, a ﬁxed-time epoch lasts for 10 seconds.
Our motivation to investigate this epoch type is to see how
heavily epoch time variation aﬀects the results obtained by
systems with ﬁxed-run epochs.
Belief Metrics. Two of the MAB algorithms we present
below make use of a belief metric that is associated with each
conﬁguration and is updated after each epoch. Intuitively,
the metrics are designed such that fuzzing a conﬁguration
with a higher metric should yield more bugs in expectation.
The ﬁrst two beliefs below use the concept of RPM to achieve
this without invoking any prior; the remaining three embrace
a “bug prior”. For now, suppose epoch (cid:96) has just ﬁnished
and we are in the process of updating the belief for the
conﬁguration (pi, si).
RPM. We use the upperbound in the 95% conﬁdence interval
given by the Rule of Three to approximate RPM((cid:96)). The
belief is simply 3/N ((cid:96)).
Expected Waiting Time Until Next New Outcome
(EWT). Since RPM does not take into account of the speed
of each fuzz run, we also investigate a speed-normalized
variant of RPM. Let Time((cid:96)) be the cumulative time spent
fuzzing this conﬁguration from epoch 1 to epoch (cid:96). Let
avgTime((cid:96)) be the average time of a fuzz run, i.e., Time((cid:96))
N ((cid:96)) .
Let W be a random variable denoting the waiting time until
the next new outcome. Recall that RPM((cid:96)) is the probability
of ﬁnding a new outcome in the next fuzz run and assume it
is independent of avgTime((cid:96)). To compute E[W ], observe
that either we ﬁnd a new outcome in the next fuzz run, or
we do not and we have to wait again. Therefore,
E[W ] = RPM((cid:96)) × avgTime((cid:96))
+ (1 − RPM((cid:96))) × (avgTime((cid:96)) + E[W ]).
3
avgTime((cid:96))
(Notice that RPM does not change even in the second case;
what changes is our upperbound on RPM.) Solving for E[W ]
avgTime((cid:96))
yields
RPM((cid:96)) , and we substitute in the upperbound of
the 95% conﬁdence interval for RPM((cid:96)) to obtain E[W ] ≥
3/N ((cid:96)) = Time((cid:96))
. Since a larger waiting time is less desir-
able, the belief used is its reciprocal, 3/ Time((cid:96)).
Rich Gets Richer (RGR). This metric is grounded in
what we call the “bug prior”, which captures our empirical
observation that code tends to be either robust or bug-ridden.
Programs written by programmers of diﬀerent skill levels
or past testing of a program might explain this real-world
phenomenon. Accordingly, demonstrated bugginess of a
program serves as a strong indicator that more bugs will be
found in that program and thus the belief is ˆM ((cid:96)).
Density. This is a runs-normalized variant of RGR and is
also the belief used in CERT BFF v2.6 [14]. The belief func-
tion is ˆM ((cid:96))/N ((cid:96)). Observe that this is the belief function
of RPM scaled by ˆM ((cid:96))/3. In other words, Density can be
seen as RPM adapted with the bug prior.
Rate. This is a time-normalized variant of RGR. The belief
function is ˆM ((cid:96))/ Time((cid:96)). Similar to Density, Rate can be
seen as EWT adapted with the bug prior.
Bandit Algorithms. Since the FCS problem is an instance
of an MAB problem, naturally we explore a number of MAB
algorithms.
Round-Robin. This simply loops through the conﬁgura-
tions in a ﬁxed order, dedicating one epoch to each conﬁgura-
tion. Note that Round-Robin is a non-adaptive, deterministic
algorithm.
Uniform-Random. This algorithm selects uniformly at
random from the set of conﬁgurations for each epoch. Like
Round-Robin, this algorithm is non-adaptive; however, it is
randomized.
Weighted-Random. Conﬁgurations are selected at random
in this algorithm, with the probability associated with each
conﬁguration is linked to the belief metric in use. The
weight of a well-performing conﬁguration is adjusted upward
via the belief metric, thereby increasingly the likelihood of
selecting that conﬁguration in future epochs. This mechanism
functions in reverse for conﬁgurations yielding few or no bugs.
-Greedy. The -Greedy algorithm takes an intuitive ap-
proach to the exploration vs. exploitation trade-oﬀ inherent
to MAB problems. With probability , the algorithm selects
a conﬁguration uniformly at random for exploration.With
probability (1− ), it chooses the conﬁguration with the high-
est current belief, allowing it to exploit its current knowledge
for gains. The constant  serves as a parameter balancing
the two competing goals, with higher  values corresponding
to a greater emphasis on exploration.
EXP3.S.1. This is an advanced MAB algorithm by Auer
et al. [2] for the non-stochastic MAB problem. We picked this
algorithm for three reasons. First, it is from the venerable
EXP3 family, and so likely to be picked up by practitioners.
Second, this is one of the EXP3 algorithms that is not pa-
rameterized by any constants and thus no parameter tuning
is needed. Third, this algorithm is designed to have an op-
timal worst-case regret, which is a form of regret that suits
our problem setting. Note that at its core EXP3.S.1 is a
weighted-random algorithm. However, since we do not have
a belief metric that corresponds to the one used in EXP3.S.1,
we did not put it inside the Weighted-Random group.
4.5 Ofﬂine Algorithms
Early on in our research design, we recognized the importance
of evaluating a large number of algorithms. Out of budgetary
constraints, we have taken a simulation approach so that
we can replay the events from previous fuzzings to try out
new algorithms. Since we have recorded all the events that
may happen during any fuzz campaign of the same input
conﬁgurations, we can even attempt to compute what an
optimal oﬄine algorithm would do and compare the results of
our algorithms against it. In the case when the conﬁgurations
do not yield duplicated bugs, such as in our Inter-Program
dataset (§6), we devise a pseudo-polynomial time algorithm
that computes the oﬄine optimal. In the other case where
duplicated bugs are possible, we propose a heuristic to post-
process the solution from the above algorithm to obtain a
lowerbound on the oﬄine optimal.
No Duplicates. Assuming that the sets of unique bugs
from diﬀerent conﬁgurations are disjoint, our algorithm is
a small variation on the dynamic programming solution to
the Bounded Knapsack problem. Let K be the number of
Figure 1: FuzzSim architecture.
conﬁgurations and B be the total number of unique bugs
from all K conﬁgurations. Let t(i, b) be the minimum amount
of time it takes for conﬁguration i to produce b unique bugs.
Note that t(i, b) is assumed to be ∞ when conﬁguration i
never produces b unique bugs in our dataset. We claim that
t(i, b) can be pre-computed for all i ∈ [1, K] and b ∈ [0, B],
where each entry takes amortized O(1) time given how events
are recorded in our system.
Let m(i, b) be the minimum amount of time it takes for
conﬁgurations 1 through i to produce b unique bugs. We want
to compute m(K, b) for b ∈ [0, B]. By deﬁnition, m(1, b) =
t(1, b) for b ∈ [0, B]. For i > 1, observe that m(i, b) =
minc∈[0,B]{t(i, c) + m(i − 1, b − c)}. This models partitioning
the b unique bugs into c unique bugs from conﬁguration i
and (b− c) unique bugs from conﬁgurations 1 through (i− 1).
Computing each m(i, b) entry takes O(B) time. Since there
are O(K × B) entries, the total running time is O(K × B2).
Discounting Duplicates. The above algorithm is incorrect
when the sets of unique bugs from diﬀerent conﬁgurations
are not disjoint. This is because the recurrence formula of
m(i, b) assumes that the c unique bugs from conﬁguration i
are diﬀerent from the (b− c) unique bugs from conﬁgurations
1 through (i − 1). In this case, we propose a heuristic to
compute a lowerbound on the oﬄine optimal.
After obtaining the m(i, b) table from the above, we post-
process bug counts by the following discount heuristic. First,
we compute the maximum number of bugs that can be found
at each time by the above algorithm by examining the K-th
row of the table. Then, by scanning forward from time 0,
whenever the bug count goes up by one due to a duplicated
bug (which must have been found using another conﬁgura-
tion), we discount the increment. Since the optimal oﬄine
algorithm can also pick up exactly the same bugs in the same
order as the dynamic programming algorithm, our heuristic
is a valid lowerbound on the maximum number of bugs that
an optimal oﬄine algorithm would ﬁnd.
5 Design & Implementation
This section presents FuzzSim, our replay-based fuzz simu-
lation system built for this project. We describe the three
steps in FuzzSim and explain the beneﬁt of its design, which
is then followed by its implementation detail. Of special note
is that we are releasing our source code and our datasets in
support of open science at the URL found in §5.2.
5.1 Overview
FuzzSim is a simulation system for black-box mutational
fuzzing that is designed to run diﬀerent conﬁguration schedul-
ing algorithms using logs from previous fuzzings. Figure 1
summarizes the design of FuzzSim, which employs a three-
step approach: (1) fuzzing, (2) triage, and (3) simulation.
Program&Seed(pi, si)Fuzzer#bugsScheduler#crashesSimulatorSchedulingAlgorithmsFuzzingTriageBug TriagebugsSimulationlogslogsTime Budget (T)Fuzzing. The ﬁrst step is fuzzing and collecting run logs
from a fuzzer. FuzzSim takes in a list of program-seed
pairs (pi, si) and a time budget T . It runs a fuzzer on each
conﬁguration for the full length of the time budget T and