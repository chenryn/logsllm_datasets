tain key, it simply makes an abstract entry in a database for the ci-
phertext. Each entry further contains handles for those participants
who already know it. Another user can only ask for decryption of
this ciphertext if he has handles to both the ciphertext and the se-
cret key. Similarly, if a user issues a command to sign a message,
the ideal system looks up whether this user should have the secret
key. If yes, it stores that this message has been signed with this key.
Later tests are simply look-ups in this database. A send operation
makes an entry known to other participants, i.e., it adds handles to
the entry. Recall that our ideal library is an entire reactive system
and therefore contains an abstract network model. We offer three
types of send commands, corresponding to three channel types {s,
a, i}, meaning secure, authentic (but not private), and insecure. The
types could be extended. Currently, our library contains public-key
encryption and signatures, nonces, lists, and application data. We
have recently added symmetric authentication (still unpublished).
The main differences between our ideal cryptographic library
and the standard Dolev-Yao model are the following. Some of them
already exist in prior extensions of the Dolev-Yao model.
• Signature schemes are not “inverses” of encryption schemes.
• Secure encryption schemes are necessarily probabilistic, and
so are most secure signature schemes. Hence if the same
message is signed or encrypted several times, we distinguish
the versions by making different database entries.
• Secure signature schemes often have memory. The standard
deﬁnition [34] does not even exclude that one signature di-
vulges the entire history of messages signed before. We have
to restrict this deﬁnition, but we allow a signature to divulge
the number of previously signed messages, so that we include
the most efﬁcient provably secure schemes under classical
assumptions like the hardness of factoring [34, 20, 21].1
• We cannot (easily) allow participants to send secret keys over
the network because then the simulation is not always pos-
sible.2 Fortunately, for public-key cryptosystems this is not
needed in typical protocols.
• Encryption schemes cannot keep the length of arbitrary clear-
texts entirely secret. Typically one can even see the length
quite precisely because message expansion is minimized.
Hence we also allow this in the ideal system. A ﬁxed-length
version would be an easy addition to the library, or can be im-
plemented on top of the library by padding to a ﬁxed length.
• Adversaries may include incorrect messages in encrypted
parts of a message which the current recipient cannot de-
crypt, but may possibly forward to another recipient who can,
and will thus notice the incorrect format. Hence we also al-
low certain “garbage” terms in the ideal system.
1.3 Overview of the Real Cryptographic Li-
brary
The real cryptographic library offers its users the same com-
mands as the ideal one, i.e., honest users operate on cryptographic
objects via handles. This is quite close to standard APIs for ex-
isting implementations of cryptographic libraries that include key
storage. The database of the real system contains real cryptographic
keys, ciphertexts, etc., and the commands are implemented by real
cryptographic algorithms. Sending a term on an insecure channel
releases the actual bitstring to the adversary, who can do with it
what he likes. The adversary can also insert arbitrary bitstrings
on non-authentic channels. The simulatability proof will show that
nevertheless, everything a real adversary can achieve can also be
achieved by an adversary in the ideal system, or otherwise the un-
derlying cryptography can be broken.
We base the implementation of the commands on arbitrary se-
cure encryption and signature systems according to standard cryp-
tographic deﬁnitions. However, we “idealize” the cryptographic
objects and operations by measures similar to robust protocol de-
sign [3].
• All objects are tagged with a type ﬁeld so that, e.g., signa-
tures cannot also be acceptable ciphertexts or keys.
• Several objects are also tagged with their parameters, e.g.,
signatures with the public key used.
• Randomized operations are randomized completely. For in-
stance, as the ideal system represents several signatures un-
der the same message with the same key as different, the real
1Memory-less schemes exist with either lower efﬁciency or based
on stronger assumptions (e.g., [31, 23, 30]). We could add them to
the library as an additional primitive.
2The primitives become “committing”. This is well-known from
individual simulation proofs. It also explains why [2] is restricted
to passive attacks.
system has to guarantee that they will be different, except for
small error probabilities. Even probabilistic encryptions are
randomized additionally because they are not always sufﬁ-
ciently random for keys chosen by the adversary.
The reason to tag signatures with the public key needed to verify
them is that the usual deﬁnition of a secure signature scheme does
not exclude “signature stealing:” Let (sksh , pksh ) denote the key
pair of a correct participant. With ordinary signatures an adversary
might be able to compute a valid key pair (sksa , pksa ) such that
signatures that pass the test with pksh also pass the test with pksa .
Thus, if a correct participant receives an encrypted signature on m,
it might accept m as being signed by the adversary, although the
adversary never saw m. It is easy to see that this would result in
protocols that could not be simulated. Our modiﬁcation prevents
this anomaly.
For the additional randomization of signatures, we include a ran-
dom string r in the message to be signed. Alternatively we could
replace r by a counter, and if a signature scheme is strongly ran-
domized already we could omit r. Ciphertexts are randomized by
including the same random string r in the message to be encrypted
and in the ciphertext. The outer r prevents collisions among ci-
phertexts from honest participants, the inner r ensures continued
non-malleability.
2. PRELIMINARY DEFINITIONS
We brieﬂy sketch the deﬁnitions from [49]. A system consists of
several possible structures. A structure consists of a set M of con-
nected correct machines and a subset S of free ports, called spec-
iﬁed ports. A machine is a probabilistic IO automaton (extended
ﬁnite-state machine) in a slightly reﬁned model to allow complex-
ity considerations. For these machines Turing-machine realizations
are deﬁned, and the complexity of those is measured in terms of a
common security parameter k, given as the initial work-tape con-
tent of every machine. Readers only interested in using the ideal
cryptographic library in larger protocols only need normal, deter-
ministic IO automata.
In a standard real cryptographic system, the structures are de-
rived from one intended structure and a trust model consisting of an
access structure ACC and a channel model χ. Here ACC contains
the possible sets H of indices of uncorrupted machines among the
intended ones, and χ designates whether each channel is secure,
authentic (but not private) or insecure. In a typical ideal system,
each structure contains only one machine TH called trusted host.
Each structure is complemented to a conﬁguration by an arbi-
trary user machine H and adversary machine A. H connects only
to ports in S and A to the rest, and they may interact. The set of
conﬁgurations of a system Sys is called Conf(Sys). The general
scheduling model in [49] gives each connection c (from an out-
put port c! to an input port c?) a buffer, and the machine with the
corresponding clock port c(cid:3)! can schedule a message there when
it makes a transition. In real asynchronous cryptographic systems,
network connections are typically scheduled by A. A conﬁgura-
tion is a runnable system, i.e., for each k one gets a well-deﬁned
probability space of runs. The view of a machine in a run is the
restriction to all in- and outputs this machine sees and its internal
states. Formally, the view view conf (M) of a machine M in a con-
ﬁguration conf is a family of random variables with one element
for each security parameter value k.
2.1 Simulatability
Simulatability is the cryptographic notion of secure implemen-
tation. For reactive systems, it means that whatever might happen
H
S
M1
A1
H
S
M2
A2
Figure 1: Simulatability: The two views of H must be indistin-
guishable.
to an honest user in a real system Sys real can also happen in the
given ideal system Sys id: For every structure (M1, S ) ∈ Sys real,
every polynomial-time user H, and every polynomial-time adver-
sary A1, there exists a polynomial-time adversary A2 on a corre-
sponding ideal structure (M2, S ) ∈ Sys id such that the view of
H is computationally indistinguishable in the two conﬁgurations.
This is illustrated in Figure 1. Indistinguishability is a well-known
cryptographic notion from [54].
|P (Dis(1
k
Deﬁnition 1. (Computational Indistinguishability) Two families
(cid:2)
k)k∈N of random variables on common domains
(vark)k∈N and (var
Dk are computationally indistinguishable (“≈”) iff for every algo-
rithm Dis (the distinguisher) that is probabilistic polynomial-time
in its ﬁrst input,
, vark) = 1) − P (Dis(1
k) = 1)| ∈ NEGL,
(cid:2)
where NEGL denotes the set of all negligible functions,
i.e.,
g : N → R≥0 ∈ NEGL iff for all positive polynomials Q,
∃k0∀k ≥ k0 : g(k) ≤ 1/Q(k).
Intuitively, given the security parameter and an element chosen ac-
(cid:2)
cording to either vark or var
k, Dis tries to guess which distribution
the element came from.
k
, var
Deﬁnition 2. (Simulatability) Let systems Sys real and Sys id be
given. We say Sys real ≥ Sys id (at least as secure as) iff for every
polynomial-time conﬁguration conf 1 = S HA1 ∈ Conf(Sys real),
there exists a polynomial-time conﬁguration conf 2 = S HA2 ∈
Conf(Sys id) (with the same H) such that view conf 1 (H) ≈
view conf 2 (H).
For the cryptographic library, we even show blackbox simulata-
bility, i.e., A2 consists of a simulator Sim that depends only on
(M1, S ) and uses A1 as a blackbox submachine. An essential
feature of this deﬁnition of simulatability is a composition theo-
rem [49], which essentially says that one can design and prove a
larger system based on the ideal system Sys id, and then securely
replace Sys id by the real system Sys real.
2.2 Notation
We write “:=” for deterministic and “←” for probabilistic as-
signment, and “←R” for uniform random choice from a set. By
x := y++ for integer variables x, y we mean y := y + 1; x := y.
The length of a message m is denoted as |m|, and ↓ is an er-
ror element available as an addition to the domains and ranges
of all functions and algorithms. The list operation is denoted as
l := (x1, . . . , xj), and the arguments are unambiguously retriev-
able as l[i], with l[i] = ↓ if i > j. A database D is a set of func-
tions, called entries, each over a ﬁnite domain called attributes. For
an entry x ∈ D, the value at an attribute att is written x.att. For
a predicate pred involving attributes, D[pred ] means the subset of
entries whose attributes fulﬁll pred . If D[pred ] contains only one
element, we use the same notation for this element. Adding an
entry x to D is abbreviated D :⇐ x.
IDEAL CRYPTOGRAPHIC LIBRARY
3.
The ideal cryptographic library consists of a trusted host TH(H)
for every subset H of a set {1, . . . , n} of users. It has a port inu ?
for inputs from and a port outu ! for outputs to each user u ∈ H
and for u = a, denoting the adversary.
As mentioned in Section 1.2, we do not assume encryption sys-
tems to hide the length of the message. Furthermore, higher pro-
tocols may need to know the length of certain terms even for hon-
est participants. Thus the trusted host is parameterized with certain
length functions denoting the length of a corresponding value in the
real system. The tuple of these functions is contained in a system
parameter L.
For simulatability by a polynomial-time real system, the ideal
cryptographic library has to be polynomial-time. It therefore con-
tains explicit bounds on the message lengths, the number of sig-
natures per key, and the number of accepted inputs at each port.
They are also contained in the system parameter L. The underly-
ing IO automata model guarantees that a machine can enforce such
bounds without additional Turing steps even if an adversary tries to
send more data. For all details, we refer to the full version [10].
3.1 States
The main data structure of TH(H) is a database D. The entries
of D are abstract representations of the data produced during a sys-
tem run, together with the information on who knows these data.
Each entry x ∈ D is of the form
(ind, type, arg , hnd u1 , . . . , hnd um , hnd a, len)
where H = {u1, . . . , um} and:
• ind ∈ N0 is called the index of x. We write D[i] instead of
D[ind = i].
• type ∈ typeset
:= {data, list, nonce, ske, pke, enc, sks,
pks, sig, garbage} identiﬁes the type of x. Future extensions
of the library can extend this set.
• arg = (a1, a2, . . . , aj) is a possibly empty list of arguments.
• hnd u ∈ N0 ∪ {↓} for u ∈ H ∪ {a} identiﬁes how u knows
this entry. The value a represents the adversary, and hnd u =
↓ indicates that u does not know this entry. A value hnd u (cid:20)=
↓ is called the handle for u to entry x. We always use a
superscript “hnd” for handles and usually denote a handle to
an entry D[i] by ihnd.
• len ∈ N0 denotes the length of the abstract entry. It is com-
puted by TH(H) using the given length functions from the
system parameter L.
Initially, D is empty. TH(H) keeps a variable size denoting the
current number of elements in D. New entries x always receive the
index ind := size++, and x.ind is never changed. For each u ∈
H ∪ {a}, TH(H) maintains a counter curhndu (current handle)
over N0 initialized with 0, and each new handle for u will be chosen
as ihnd := curhndu ++.
3.2 Inputs and their Evaluation
Each input c at a port inu ? with u ∈ H ∪ {a} should be a list
(cmd , x1, . . . , xj). We usually write it y ← cmd (x1, . . . , xj)
with a variable y designating the result that TH(H) returns at
outu !. The value cmd should be a command string, contained in
one of the following four command sets. Commands in the ﬁrst two
sets are available for both the user and the adversary, while the last
two sets model special adversary capabilities and are only accepted
for u = a. The command sets can be enlarged by future extensions
of the library.
3.2.1 Basic Commands
First, we have a set basic cmds of basic commands. Each basic
command represents one cryptographic operation; arbitrary terms