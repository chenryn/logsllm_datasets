spond to layers 1 and 2, respectively
Each layer of the network constructed by fiVi (for i = 1, 2, 3, . . . , N) provides the
distinct characteristic patterns observed in the approximated co-occurrence matrix. We
can also express such characteristics in relation to the average co-occurrence matrix by
separating it as
N(cid:7)
i=1
N(cid:7)
N(cid:7)
N(cid:7)
fiVi =
(Xi + Yi) =
Xi +
Yi
i=1
i=1
i=1
(11)
where Xi (or Yi) denotes an adjacency matrix whose elements are determined by the
corresponding positive (or negative) elements in fiVi. The matrix Xi (or Yi) represents
in terms of frequency (or rarity) in relation to the
the principal characteristic of M
average co-occurrence matrix. We call the network obtained from Xi (or Yi) a positive
(or negative) network.
(cid:3)
(cid:3)
There may be elements in Xi (or Yi) that are too small to serve as principal charac-
teristics of M
. Thus, instead of using all the elements of Xi (or Yi), we set a threshold
h and choose elements that are larger (or smaller) than h (or −h) in order to construct
the ith layer of the positive (or negative) network. Assigning a higher value to h reduces
the number of nodes in the network and consequently creates a network with a diﬀerent
topology.
Figure 5 shows the ﬁrst and second layers of the positive networks, obtained for
User1 in the example dataset with h assigned to 0. We can combine these two layers
to describe User1’s overall patterns of principal frequent commands. The combined
network is depicted in Figure 6, which indicates strong relations between the commands
ls, cd, and less. This matches our human perception of the command sequence of
User1 (i.e., cd ls less ls less cd ls cd cd ls).
Similarly, the ﬁrst and second layers of the negative network and the combined net-
work obtained for User1 are shown in Figures 7 and 8, respectively. These negative
networks indicate the rarely observed command patterns in the command sequence of
User1 relative to the average observed command patterns. We can observe strong cor-
relations in the commands gdb, gcc, ls, and emacs. These relations did not appear in
the command sequence.
232
Mizuki Oka et al.
User
1
2
…
50
Training data
Test data
1 2 3  …
50 …
150
sequence
Fig. 9. Composition of the experimental dataset
3 Application of the ECM Method
3.1 Overview of the Experimental Data
We applied the ECM method to a dataset for masquerade detection provided by Schon-
lau et al. [12]. The dataset consists of 50 users’ commands entered at a UNIX prompt,
with 15,000 commands recorded for each user. Due to privacy arguments, the dataset
includes no reporting of ﬂags, aliases, arguments, or shell grammar. The users are des-
ignated as User 1, User 2, and so on. The ﬁrst 5000 commands are entered by the
legitimate user, and the masquerading commands are inserted in the remaining 10,000
commands. All the user sequences were decomposed into a sequence length of 100
commands (l = 100). Figure 9 illustrates the composition of the dataset.
3.2 Creation of a User Proﬁles (Oﬄine)
For each user, we created a proﬁle representing his normal behavior. Each decom-
posed sequence was converted into a co-occurrence matrix with a scope size of six
(s = 6). We did not change the strength of the correlations between events on depend-
ing on their distance but instead used a constant value 1 for simplicity. We took all of
the users’ training dataset, consisting of 2500 (50 sequences × 50 users) decomposed
sequences, and deﬁned it as the domain dataset (n = 2500). The set of observation
events (O = o1, o2, o3, . . . , om) was determined by the unique events appearing in the
domain dataset, which accounted for 635 commands (m = 635). We took 50 Eigen
co-occurrence matrices (N = 50), whose contribution rate was approximately 90%, and
deﬁned this as the co-occurrence matrix space.
The proﬁle of a user was created by using his training dataset. We ﬁrst converted
all of his training sequences to co-occurrence matrices and obtained the corresponding
feature vectors by projecting them onto the deﬁned co-occurrence matrix space. Each
feature vector was then used to reconstruct an approximated original co-occurrence ma-
trix. This co-occurrence matrix was ﬁnally converted into a positive (or negative) lay-
ered network with a threshold of 0 (h = 0). We only used the positive layered network
to deﬁne each user’s proﬁle.
3.3 Recognition of Anomalous Sequences (Online)
When a sequence seqi of the User u was to be tested, we followed this procedure:
1. Construct a co-occurrence matrix from seqi.
2. Project the obtained co-occurrence matrix on the co-occurrence matrix space and
obtain its feature vector.
Anomaly Detection Using Layered Networks Based on Eigen Co-occurrence Matrix
233
Fig. 10. ROC curves for the ECM method
3. Multiply the feature vector by the Eigen co-occurrence matrices to obtain a layered
network.
4. Compare the layered network with the proﬁle of User u.
5. Classify the testing sequence as anomalous or normal based on a threshold u.
To classify a testing sequence seqi as anomalous or normal, we computed the sim-
ilarity between each network layer of seqi and each networks layer in the user proﬁle,
where we chose the largest value as the similarity. If the computed similarity of seqi
was under a threshold u for the User u, then the testing sequence was classiﬁed as
anomalous; otherwise, it was classiﬁed as normal. We deﬁned the similarity between
the networks of two sequences, seqi and seq j, as,
Sim(seqi, seq j) =
N(cid:7)
k=1
Γ(Tk(i), Tk( j)),
(12)
where Tk(i) is the obtained network at the kth layer of seqi and Γ(Tk(i), Tk( j)) is the
number of subnetworks that Tk(i) and Tk( j) have in common. We extracted the 30
largest values to form a network (R = 30) and employed 3 connected nodes as the
unit of a subnetwork (r = 3).
3.4 Results
The results illustrate the trade-oﬀ between correct detection (true positives) and false
detection (false positives). A receiver operation characteristic curve (ROC curve) is of-
ten used to represent this trade-oﬀ. The percentages of true positives and false positives
are shown on the y-axis and x-axis of the ROC curve, respectively. Any increase in
234
Mizuki Oka et al.
Fig. 11. ROC curve for the ECM method with the best results from other methods shown for
comparison
the true positive rate will be accompanied by an increase in the false positive rate. The
closer the curve follows the left-hand border and then the top border of the ROC space,
the more accurate the results are, since they indicate high true positive rates and, corre-
spondingly, low false positive rates.
Figure 10 shows the resulting ROC curve obtained from our experiment with the
ECM method. We have plotted diﬀerent correct detection rates and false detection rates
by changing α in the expression:
opt
u + α,
is the optimal threshold for User u. The optimal threshold opt
u
where opt
is deﬁned
u
by ﬁnding the largest correct detection rate with a false detection rate of less than β%.
We set β to 20 in this experiment and used the same values of u throughout all the
test sequences (no updating). As a result, the ECM method achieved a 72.3% correct
detection rate with a 2.5% false detection rate.
Schonlau et al. [12] and Maxion et al. [13] have applied a number of masquerade de-
tection techniques, including Bayes 1-Step Markov, Hybrid Multi-Step Markov, IPAM,
Uniqueness, Sequence-Match, Compression, and Naive Bayes, to the same dataset used
in this study. (See refs. [12] and [13] for detailed explanations of each technique.) Their
results are shown in Figure 11 along with our results from the ECM method. As one
can be seen from the data, the ECM method achieved one of the best scores among the
various approaches.
4 Computational Cost
The ECM method has two computational phases, the oﬄine and online phases. For the
oﬄine phase, the required computation processes are the following: transforming a set
Anomaly Detection Using Layered Networks Based on Eigen Co-occurrence Matrix
235
Table 2. Changeable parameters in obtaining a feature vector
O set of observation events.
l
s
D domain dataset.
length of sequence to be tested.
scope size
Table 3. Changeable parameters in obtaining a layer of network
h threshold of elements in Xi (or Yi) for constructing a network.
R number of elements in fiVi for constructing the ith network layer
r number of nodes in a subnetwork.
training sequences of length w to co-occurrence matrices, calculating the N eigenvec-
tors of the covariance matrix, projecting co-occurrence matrices onto the co-occurrence
matrix space to obtain feature vectors, constructing layered networks with R nodes in
each layer, and generating a lookup table containing subnetworks with r connected
nodes.
We used the Linux operating system (RedHat 9.0) for our experiments. We im-
plemented the conversion of a sequence to a co-occurrence matrix in Java SDK 1.4.2
[14] and the remaining processes in Matlab Release 13 [15]. The hardware platform
was a Dell Precision Workstation 650 (Intel(R) Xeon (TM) CPU 3.20GHz, 4GB main
memory, 120GB hard disk). With this environment, for the online phase, it took 26.77
minutes to convert all the user training sequences (l = 100, s = 6) to the co-occurrence
matrices (average of 642 ms each), 23.60 minutes to compute the eigenvectors (N = 50),
6.76 minutes to obtain all the feature vectors (average of 162 ms each), 677.1 minutes
to construct all the layered networks with 30 nodes in each layer (average of 16.25 s for
each feature vector), and 106.5 minutes to construct the lookup table (r = 3).
For the online phase, the required computations are the following: transforming a
sequence to a co-occurrence matrix, projecting the obtained co-occurrence matrix to the
set of N Eigen co-occurrence matrices, obtaining the feature vector of the co-occurrence
matrix, constructing a layered network with R nodes, generating subnetworks with r
connected nodes, and comparing the obtained layered network with the corresponding
user proﬁle. For one testing sequence, using the same environment described above, it
took 642 ms to convert the sequence (l = 100, s = 6) to the co-occurrence matrix, 162
ms to obtain the feature vector (N = 50), 16.25 s to construct the layered network (R =
30), 2.60 s to generate the subnetworks (r = 3), and 2.48 s to compare the subnetworks
with the proﬁle. In total, it took 22.15 s to classify a testing sequence as normal or
anomalous.
5 Discussion
As noted above, we have achieved better results than the conventional approaches by
using the ECM method. Modeling a user’s behavior is not a simple task, however, and
we did not achieve very high accuracy with false positive rates near to zero. There is
room to improve the performance by varying the parameters of the ECM method, as
shown in Tables 2 and 3.
236
Mizuki Oka et al.
Table 2 lists the parameters that can be changed when computing a feature vector
from a co-occurrence matrix. The parameter O determines the events for which correla-
tions with other events are considered. If we took a larger number of events (i.e., UNIX
commands), the accuracy of the results would become better but the computational cost
cost would increase. Thus, the number of events represents a trade-oﬀ between accuracy
and computational cost.
Changing the parameter l results in a diﬀerent length of test sequence. Although we
set l to 100 in our experiment in order to compare the results with those of conventional
methods, it could be changed by using a time stamp, for example. The parameter s
determines the distance over which correlations between events are considered. If we
assigned a larger value to s, two events separated by a longer time interval could be
correlated. In our experiment, we did not consider the time in determining the values
of l and s, but instead utilized our heuristic approach, as the time was not included
in the dataset. Moreover, we did not change the strength of the correlations between
events depending on their distance for simplicity. Considering the aspect of dividing the
number of occurrences by the distance between events, for example, would inﬂuence
the results.
Choosing more sequences for the domain dataset D would result in extracting of
more precise features from each sequence, as in the case of the Eigenface technique.
This aspect could be used to update the proﬁle of each user: updating the domain dataset
would automatically update its extracted principal features, since they are obtained by
using Eigen co-occurrence matrices.
Table 3 lists the parameters that can be changed in constructing a network layer
from a co-occurrence matrix. In our experiment, we set h = 0 and chose the largest 30
elements (R = 30) to construct a positive network. Nevertheless, the optimal values of
these parameters are open for discussion.
Additionally, the detection accuracy would be increased by computing the mean
co-occurrence matrix M0 by using equation (2) instead of equation (1), since each orig-
inal co-occurrence matrix is sparse. Moreover, normalization of Γ(Tk(i), Tk( j)) by the
number of arcs (or nodes) in both Tk(i) and Tk( j) may improve the accuracy: let |Tk(i)|
be the number of arcs (or nodes) in network Tk(i). Then the normalized Γ(Tk(i), Tk( j))
would be simply obtained by Γ(Tk(i), Tk( j))/(|Tk(i)||Tk( j)|).
6 Conclusions and Future Work
Modeling user behavior is a challenging task, as it changes dynamically over time and
a user’s complete behavior is diﬃcult to deﬁne. We have proposed the ECM method to
accurately model such user behavior. The ECM method is innovative in three aspects.
First, it models the dynamic natures of users embedded in their event sequences. Sec-
ond, it can discover principal patterns of statistical dominance. Finally, it can represent
such discovered patterns via layered networks, with not only frequent (positive) proper-
ties but also rare (negative) properties, where each layer represents a distinct principal
pattern.
Experiments on masquerade detection by using UNIX commands showed that the
ECM method achieved better results, with a higher correct detection rate and a lower
Anomaly Detection Using Layered Networks Based on Eigen Co-occurrence Matrix
237
false detection rate, than the results obtained with conventional approaches. This sup-
ports our assumption that not only connected events but also non-connected events
within a certain scope size are correlated in a command sequence. It also shows that
the principal features from the obtained model of a user behavior are successfully ex-
tracted by using PCA, and that detailed analysis by using layered networks can provide
suﬃcient, useful features for classiﬁcation.
Although we used the layered networks to classify test sequences as normal or ma-
licious in our experiment, we should also investigate classiﬁcation by using only the
feature vectors. Furthermore, we need to conduct more experiments by varying the
method’s parameters, as described in Section 5, in order to improve the accuracy for
masquerade detection. We must also try using various matching network algorithms to
increase the accuracy.
References
1. Lunt, T.F.: A survey of intrusion detection techniques. Computers and Security 12 (1993)
405–418
2. Ye, N., Li, X., Chen, Q., Emran, S.M., Xu, M.: Probablistic Techniques for Intrusion Detec-
tion Based on Computer Audit Data. IEEE Transactions on Systems Man and Cybernetics,
Part A (Systems & Humans) 31 (2001) 266–274
3. Hofmeyr, S.A., Forrest, S., Somayaji, A.: Intrusion Detection using Sequences of System
Calls. Journal of Computer Security 6 (1998) 151–180
4. Lee, W., Stolfo, S.J.: A framework for constructing features and models for intrusion detec-
tion systems. ACM Transactions on Information and System Security (TISSEC) 3 (2000)
227–261
5. Sekar, R., Bendre, M., Bollineni, P.: A Fast Automaton-Based Method for Detecting Anoma-
lous Program Behaviors. In: Proceedings of the 2001 IEEE Symposium on Security and
Privacy, Oakland (2001) 144–155
6. Wagner, D., Dean, D.: Intrusion Detection via Static Analysis. In: Proceedings of the 2001
IEEE Symposium on Security and Privacy, Oakland (2001) 156–168
7. Abe, H., Oyama, Y., Oka, M., Kato, K.: Optimization of Intrusion Detection System Based
on Static Analyses (in Japanese). IPSJ Transactions on Advanced Computing Systems (2004)
8. Kosoresow, A.P., Hofmeyr, S.A.: A Shape of Self for UNIX Processes. IEEE Software 14
(1997) 35–42
9. DuMouchel, W.: Computer Intrusion Detection Based on Bayes Factors for Comparing Com-
mand Transition Probabilities. Technical Report TR91, National Institute of Statistical Sci-
ences (NISS) (1999)
10. Jha, S., Tan., K.M.C., Maxion, R.A.: Markov Chains, Classiﬁers and Intrusion Detection. In:
Proc. of 14th IEEE Computer Security Foundations Workshop. (2001) 206–219
11. Warrender, C., Forrest, S., Pearlmutter, B.A.: Detecting Intrusions Using System Calls: Al-
ternative Data Models. In: IEEE Symposium on Security and Privacy. (1999) 133–145
12. Schonlau, M., DuMouchel, W., Ju, W.H., Karr, A.F., Theus, M., Vardi, Y.: Computer intru-
sion: Detecting masquerades. In: Statistical Science. (2001) 16(1):58–74
13. Maxion, R.A., Townsend, T.N.: Masquerade Detection Using Truncated Command Lines.
In: Prof. of the International Conference on Dependable Systems and Networks (DSN-02).
(2002) 219–228
14. (Java) http://java.sun.com/
15. (Matlab) http://www.mathworks.com/