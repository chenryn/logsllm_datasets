stream tasks. For example, if a developer wants to detect
logs even though we only fine-tune the base model on 50
anomalies in overwhelming logs, the extracted templates and
annotatedsamplesandalargeportionoftemplatesareunseen
their parameters are not what he/she needs, but the result
inthetestset(thelastcolumninTableI).Thepromisingresult
from an automated anomaly detection model is. From this
indicates our framework has a powerful ability for capturing
perspective,wecompareSemParserwithfourbaselineparsers
semantics from log messages.
in two log analysis tasks to demonstrate our semantic parser’s
We attribute the outstanding concept-instance pairs mining
effectiveness. On the other hand, our approach could provide
ability of SemParser to its comprehensive architectures. The
accurate log templates with extra underlying semantics, so it
ablation experiments indicate that removing components de-
would naturally promote generalized downstream tasks.
grade the performance in varying degrees. Firstly, to mini-
To conclude, SemParser is developed as a semantic-based
mize the impact of a large portion of unknown words (e.g.,
parserinsteadofsyntax-basedparser,sotheevaluationshould
attempt 14451444) to the model, we devise a character-level
be related to its semantic acquisition ability and how the
feature extraction convolutional network and a local feature
acquired semantics benefits log analysis for downstream tasks
extraction method since similar words are always composed
in an end-to-end fashion.
of similar character structures. For example, although at-
tempt 14451444 is different from attempt 14415371, they
B. RQ1: How effective is the SemParser in mining semantics
share the same structures that the word “attempt” following
from logs?
by an underscore and a sequence of numbers. Secondly, a
In this experiment, we focus on evaluating the explicit CI recurrent network is designed to capture the contextual repre-
pair extraction in the semantics miner as it serves as a vital sentationforeachwordinasentence,sincethesamewordmay
step. A high-quality domain knowledge database and further have various meanings under different contexts. By removing
joint parser process could be conducted if and only if the the bi-LSTM network, words in the sentence are equally
semantics miner extracts high-quality explicit CI pairs from regardedasabagofwords.Thirdly,SemParsernaturallylearns
log messages. the patterns between concepts and instances by incorporating
Basically, mining the instance-level semantics from log the interval context. For instance, if a colon separates two
messages is difficult to do with handcrafted rules. Taking logs words, the latter word is probably an instance of the prior
one, even if the latter one is an unseen word. We find such
Log message … ""GET /v2.1/5250c/flavors"" status: 200 …
interval context is quite important, as a dramatic degradation
C-Template … ""GET ///flavors"" status:  …
is observed when we remove it. To conclude, the experiment
showsthesuperiorityoftheourmodelbyachievinganaverage CI pairs [(status, 200), (project, 5250c)]
F1 score of 0.985 across various system logs.
Log message Returning 500 to user …
C. RQ2: How effective is the SemParser in anomaly detec- C-Template Returning  to user …
tion?
CI pairs [(status, 500)]
To illustrate how SemParser benefits the anomaly detection
task, we compare SemParser with four baseline parsers on Fig. 4: A case for anomaly detection.
four different anomaly detection models, and the results are
showninTableV.Eachrowrepresentstheperformanceoffour
D. RQ3: How effective is the SemParser in failure identifica-
anomaly detection models associated with the selected parser
tion?
forupstreamprocessing.Thelastrow(∆)displayshowmuch
oursemanticparseroutperformsthebestbaselineparserofF1 This section demonstrates how effectively our semantic
score, and the negative score indicates how the percentage of parserenhancesfailureidentification.Theexperimentalresults
ours performs lower than the best baseline. are shown in Table VI, where each row represents the perfor-
In the base HDFS dataset with only 31 templates, although mance with the selected parser and several model architec-
all parsers provides a good performance, we still observe tures.ThelastrowrevealshowmuchSemParserincreasesthe
that SemParser also outperform syntax-based parsers by an F1 score when compared to the best baseline results. Given
average F1 score of 1.22% over four techniques. In the more that there are 16 types of API errors in F-Dataset, we report
challengingF-Dataset,weobservethatSemParserperformsat Recall@1, Recall@2, Recall@3 score, as we want the top-k
rates approximately above ten percent overall baselines in F1 suggested errors to cover the real API error.
score,indicatingitseffectivenessandrobustnessacrossvarious It is noteworthy that our semantic parser outperforms four
models. It outperforms baselines regarding DeepLog, LogRo- baselines by a wide margin, regardless of the analytical
bust, CNN, and Transformer by 11.80%, 10.17%, 8.27%, and techniques. We can observe that our parser surpasses oth-
16.58% respectively, with an average F1 score of 0.926. The ers by 12.5%, 10%, 7.75%, and 3.81% for LSTM, Atten-
resultsonPrecision,Recall,andF1revealtheeffectivenessof biLSTM, CNN, and Transformer in Recall@1, respectively.
acquired semantics from logs. In general, SemParser shows the promising Recall@1 score
WeattributeSemParser’sdistinctsuperiorityonitsprecision of 0.95, indicating the effectiveness of semantics for failure
totheawarenessofsemanticsweextract,particularlyinstance- identification.
level semantics. Previous studies only use log template se- The impressive performance can be attributed to several
quences to detect anomalies automatically, suffering from reasons. Firstly, our parser can extract precise conceptualized
missing important semantics. Taking a case in Figure 4 as an templates, serving as a basis for downstream task learning.
example, where C-Template refers to the conceptualized tem- Weextractconceptualizedtemplatesbyreplacingtheinstances
plates.TheCI-pairsareeitherextractedexplicitlyorimplicitly withtheircorrespondingconceptswhilereservingallconcepts
via a domain knowledge database. The green tick indicates a in the template, based on the observation that instances (e.g.,
normallogmessage,whiletheredcrossstandsforananomaly time,len,ID)aremorelikelytobegeneratedinrunningtime.
log. A service maintainer must understand that “status: 500” The template number dramatically decreases after conceptu-
returned by a REST API request reflects the internal server alization, giving the sequence of abstract log messages for
error, while the “status: 200” means the request is successful primitive learning.
based on ad-hot knowledge. In this way, the maintainer can Secondly, the instance-level semantics benefits failure iden-
easily recognize that an API request fails if the return status tification.InthecaseshowninTableVIIa,“853cfe1b”willbe
equals to 500. Similarly, feeding semantics like (“status”, regarded as a meaningless character string by the traditional
“500”)and(“status”,“200”)intotheanomalydetectionmodel syntax-based parser; however, SemParser recognizes it as a
forces the model to learn the relation between “500” and “server”frompreviouslogmessages.Therefore,thepreserved
“anomaly” (or the relation between “200” and “normal”). As semanticsallowsthedownstreamtechniquetounderstandthat
a result, the model will not mistake a log containing a normal theoriginallogmessageistalkingabouttheconceptserver,as
status(e.g.,200)forananomaly.Theinstance-levelsemantics well as the concept attach volume, then it will not be hard to
also resolve problems for unseen logs. Even if the model has infer the API error behind the failure is “server add volume”.
never encountered the template before, it is able to correctly Thirdly, our parser provides strong messages-level seman-
predict it as a normal one according to a success status code, tics, clues model in resolving failures. For example, Ta-
and vice versa. Note that without the deliberately established ble VIIb shows how the semantic parser extracts the concept
CI Pairs, previous syntax-based parsers cannot distinguish the “network” with the actual API error being “network create”.
above normal v.s. anomaly status. With the help of the concept “network”, the model focuses
TABLE VI: Experimental results in failure identification task.
Model
LSTM Atten-biLSTM CNN Transformer
Baseline Rec@1 Rec@2 Rec@3 Rec@1 Rec@2 Rec@3 Rec@1 Rec@2 Rec@3 Rec@1 Rec@2 Rec@3
LenMa 0.839 0.924 0.953 0.858 0.943 0.957 0.877 0.962 0.967 0.919 0.934 0.948
AEL 0.844 0.919 0.953 0.853 0.915 0.962 0.810 0.905 0.929 0.858 0.929 0.953
Drain 0.844 0.919 0.972 0.863 0.938 0.953 0.867 0.948 0.967 0.853 0.919 0.943
IPLoM 0.848 0.943 0.957 0.863 0.948 0.962 0.867 0.967 0.986 0.839 0.910 0.948
SemParser 0.954 0.968 0.968 0.954 0.968 0.972 0.945 0.963 0.972 0.954 0.958 0.968
∆% +12.50% +2.65% -0.41% +10.54% +2.11% +1.04% +7.75% -0.42% -1.44% +3.81% +2.46% +2.11%
TABLE VII: Cases for failure identification.
strateSemParser’seffectivenessoverotherparsersinanomaly
(a) A case for instance-level semantics. detectionandfailureidentification,itisworthyofminingsuch
APIerror serveraddvolume semanticsbysacrificingcontrollablecomputationalefficiency.
Logmessage ...Cannot’attach volume’instance853cfe1b...
VII. RELATEDWORK
C-Template ...Cannot’attach volume’instance...
CIPairs [(server,853cfe1b)]
A. Log parsing
(b) A case for message-level semantics. A series of data mining approaches are proposed for
APIerror networkcreate log parsing, which can be further divided into three cate-
Logmessage ...POST/v2.0/networks... gories[46]:frequentpatternmining,heuristics,andclustering.
C-Template ...POST//networks... Among frequent pattern mining approaches, SLCT [6] pio-
Concepts [POST,networks]
neeredtheautomatedlogparsing,determinedwhetheratoken
belongs to variables or constants based on its occurrences,
assuming that the frequent words are always shown in con-
on network errors and filters other server errors or volume
stants.Heuristicapproachesaremoreintuitivethanothers.For
errors.Tosumup,SemParserbenefitsthefailureidentification
example, AEL [38] went over a collection of heuristic rules
task by providing message-level semantics and instance-level
to conduct log parsing. Another online heuristic log parser
semantics altogether.
Drain [12] used a fixed depth parse tree, with each internal
leaf node encoding specifically designed parsing rules. The
VI. THREATTOVALIDITY
clustering approaches first encode log messages into vectors,
Threats to CI pair granularity. Our approach can then group the messages with similar vectors. For example,
only discover semantic pairs in a single word. For ex- LKE [15] hierarchically clustered messages with a weighted
ample, for one Zookeeper log “Connection request from editdistancethreshold,thenperformsgroupsplittingwithfine-
old client /10.10.31.13:40061”, the extracted CI pair tuning to extract variables from messages. Another approach
is “(client, /10.10.31.13:40061)” instead of “(old client, LenMa [37] encoded each log to its word length vector for
10.10.31.13:40061)”. Using “old client” is more precise than clustering.
“client” to describe this instance. Fortunately, based on our However, all the above studies only distinguish variables
observation, since such multi-word concepts infrequently oc- from constants in a log message, assuming the message as a
cur in log messages, using the single-word concept will not sequence of characters and symbols independent of the vari-
alter the semantics too much. ables’ meaning. Our work starts from a higher-level semantic
Threats to transferability. Our model mines semantics perspective, particularly resolves the meaning of parameters
relying on manually labeled data. The sampled data for anno- andthetemplateinalogmessage.Inthisway,ourworkdiffers
tationandannotationqualitybothaffectitsperformance.Fine- significantlyfrompreviousstudies.OnesimilarNamedEntity
tuning with new annotation is required to transfer the model Recognition (NER) work in log community [24] also noticed
across different systems. In this case, we consider that our the importance of semantics in logs, intending to identify
model can easily adapt to a new system after fine-tuning with entitiesinlogs.However,theNERtaskreliesonaclose-world
asmallamountofdata(e.g.,OurRQ1showsthat50annotated assumptionthatallentitiesareknowninadvance,sufferingthe
logs are sufficient to transfer a model from OpenStack to explosion of the number of entity types, which impedes real-
Hadoop, with 84.6% templates in test set are unseen). world practice and generalization across different systems.
Threats to efficiency. Despite the fact that the neural
B. Log mining
network used in our approach can effectively mine semantics,
itisnotascomputationallyefficientasotherstatisticalparsers. Log mining analyzes a large amount of data to facili-
Nevertheless, the issue can be mitigated by batch operation tate monitoring and troubleshooting software systems [46].
or GPU acceleration. Moreover, missing identification of an Anomaly detection is a typical log mining task in large-scale
anomaly can also be very costly. As RQ2 and RQ3 demon- softwaresystems,referringtoidentifylogsthatdonotconform
to expected behavior. Have encoded the log templates into REFERENCES
vectors, previous studies use traditional learning approaches
[1] M. Chen, A. X. Zheng, J. Lloyd, M. I. Jordan, and E. Brewer,
to find anomalies, such as Principal Component Analysis
“Failure diagnosis using decision trees,” in International Conference
(PCA) [2], clustering [34], and Support Vector Machine on Autonomic Computing, New York, NY, USA, May 17-19, 2004.
(SVM) [47]. Some deep learning-based approaches have also IEEE Computer Society, 2004, pp. 36–43. [Online]. Available: