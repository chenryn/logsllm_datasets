# References

[30] S. Ahadi and P. C. Woodland, "Combined Bayesian and Predictive Techniques for Rapid Speaker Adaptation of Continuous Density Hidden Markov Models," *Computer Speech & Language*, 1997.

[31] L. Bahl, P. Brown, P. de Souza, and R. Mercer, "Maximum Mutual Information Estimation of Hidden Markov Model Parameters for Speech Recognition," in *ICASSP’86. IEEE International Conference on Acoustics, Speech, and Signal Processing*, 1986.

[32] L. R. Rabiner, "A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition," *Proceedings of the IEEE*, 1989.

[33] A. Graves, S. Fernández, F. Gomez, and J. Schmidhuber, "Connectionist Temporal Classification: Labeling Unsegmented Sequence Data with Recurrent Neural Networks," in *Proceedings of the 23rd International Conference on Machine Learning*, 2006.

[34] Y. Qin, N. Frosst, S. Sabour, C. Raffel, G. Cottrell, and G. Hinton, "Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions," in *International Conference on Learning Representations*, 2020.

[35] C. Xie, J. Wang, Z. Zhang, Z. Ren, and A. Yuille, "Mitigating Adversarial Effects through Randomization," in *International Conference on Learning Representations*, 2018.

[36] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Šrndić, P. Laskov, G. Giacinto, and F. Roli, "Evasion Attacks Against Machine Learning at Test Time," in *Joint European Conference on Machine Learning and Knowledge Discovery in Databases*. Springer, 2013.

[37] N. Carlini, A. Athalye, N. Papernot, W. Brendel, J. Rauber, D. Tsipras, I. Goodfellow, A. Madry, and A. Kurakin, "On Evaluating Adversarial Robustness," *arXiv preprint arXiv:1902.06705*, 2019.

[38] N. Carlini and D. Wagner, "Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods," in *Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security*, 2017.

[39] F. Tramer, N. Carlini, W. Brendel, and A. Madry, "On Adaptive Attacks to Adversarial Example Defenses," 2020.

[40] C. Herley and P. C. Van Oorschot, "SoK: Science, Security, and the Elusive Goal of Security as a Scientific Pursuit," in *2017 IEEE Symposium on Security and Privacy (SP)*, 2017.

[41] A. Athalye, L. Engstrom, A. Ilyas, and K. Kwok, "Synthesizing Robust Adversarial Examples," in *Proceedings of the 35th International Conference on Machine Learning*, 2018.

[42] H. Kwon, H. Yoon, and K.-W. Park, "Poster: Detecting Audio Adversarial Examples Through Audio Modification," in *Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security*, 2019.

[43] L. Yujian and L. Bo, "A Normalized Levenshtein Distance Metric," *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 2007.

[44] J. Lu, T. Issaranon, and D. Forsyth, "SafetyNet: Detecting and Rejecting Adversarial Examples Robustly," in *The IEEE International Conference on Computer Vision (ICCV)*, October 2017.

[45] W. Xu, D. Evans, and Y. Qi, "Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks," *arXiv preprint arXiv:1704.01155*, 2017.

[46] J. Shen, R. Pang, R. J. Weiss, M. Schuster, N. Jaitly, Z. Yang, Z. Chen, Y. Zhang, Y. Wang, R. Skerry-Ryan et al., "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions," in *Proc. ICASSP*, 2018.

[47] P. Neekhara, C. Donahue, M. Puckette, S. Dubnov, and J. McAuley, "Expediting TTS Synthesis with Adversarial Vocoding," *Proc. Interspeech*, 2019.

[48] C. Miao, S. Liang, M. Chen, J. Ma, S. Wang, and J. Xiao, "Flow-TTS: A Non-Autoregressive Network for Text-to-Speech Based on Flow," in *ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing*, 2020.

[49] Bhadragiri Jagan Mohan and Ramesh Babu N., "Speech Recognition Using MFCC and DTW," in *2014 International Conference on Advances in Electrical Engineering (ICAEE)*, 2014.

[50] M. Ravanelli, T. Parcollet, and Y. Bengio, "The PyTorch-Kaldi Speech Recognition Toolkit," in *ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing*, 2019.

[51] S. S. Stevens, J. Volkmann, and E. B. Newman, "A Scale for the Measurement of the Psychological Magnitude Pitch," *The Journal of the Acoustical Society of America*, 1937.

[52] J. Le Roux, H. Kameoka, N. Ono, and S. Sagayama, "Fast Signal Reconstruction from Magnitude STFT Spectrogram Based on Spectrogram Consistency," in *Proc. International Conference on Digital Audio Effects*, 2010.

[53] D. W. Griffin, Jae, S. Lim, and S. Member, "Signal Estimation from Modified Short-Time Fourier Transform," *IEEE Transactions on Acoustics, Speech, and Signal Processing*, 1984.

[54] Y. He, TensorFlow Implementation of Griffin-Lim Algorithm, 2017. [Online]. Available: <https://github.com/candlewill/Griffin_lim>

[55] S. W. Smith, *The Scientist and Engineer's Guide to Digital Signal Processing*. California Technical Publishing, 1997.

# Appendix

## A. Receiver Operating Characteristic Curves for Detection under Non-Adaptive Attacks

We provide the Receiver Operating Characteristic (ROC) curves for our detection of non-adaptive adversarial attacks using various transformation functions against three different adversarial attacks in Figure 11. The Area Under the Curve (AUC) scores are reported in Table 2 in Section 6.1 and included with each of the plots below. A true positive indicates an example that is adversarial and is correctly identified as adversarial.

(a) Downsampling-Upsampling
(b) Quantization
(c) Filtering
(d) Linear Predictive Coding (LPC)
(e) Mel Extraction - Inversion

**Figure 11:** Detection ROC curves for different transformation functions against three attacks (Carlini [11], Universal [15], Qin-I [14]) in the non-adaptive attack setting.

## B. Thresholds for Detection Accuracy

Table 5 lists the detection thresholds (t) for various transformation functions for the two Automatic Speech Recognition (ASR) systems studied in our work. We choose 50 original examples (separate from the first 100 used for evaluation) and construct 50 adversarial examples using each of the attacks. This results in 100 adversarial-benign example pairs for DeepSpeech (constructed using Carlini [11] and Universal [15] attacks) and 100 adversarial-benign example pairs for Google Lingvo (constructed using Qin-I and Qin-R attacks [14]). Using this dataset, we obtain the threshold that achieves the best detection accuracy for each defense separately for the two ASRs. The AUC metric is threshold-independent. We do not change the threshold for adaptive attack evaluation and use the same threshold as listed in Table 5.

| **Defense** | **Threshold - DeepSpeech** | **Threshold - Lingvo** |
|-------------|----------------------------|------------------------|
| Downsampling - Upsampling | 0.48 | 0.48 |
| Quantization - Dequantization | 0.44 | 0.26 |
| Filtering | 0.32 | 0.31 |
| Mel Extraction - Inversion | 0.33 | 0.31 |
| LPC | 0.38 | 0.46 |

**Table 5:** Detection Threshold when using each transformation function in the WaveGuard framework for DeepSpeech and Lingvo ASR systems.

## C. Transfer Attacks from an Undefended Model

### Distortion Metrics

| **Defense** | **ε∞** | **|δ|∞** | **dBx(δ)** | **CER(xadv, τ)** | **CER(g(xadv), τ)** | **AUC** | **Acc.** |
|-------------|--------|---------|-------------|-------------------|---------------------|---------|----------|
| LPC         | 1000   | 0.31    | -23.5       | 0.99              | 0.99                | 0.80    | 98.5%    |
|             | 2000   | 0.34    | -17.4       | 0.99              | 0.99                | 0.83    | 99.0%    |
|             | 4000   | 0.85    | -11.4       | 0.99              | 0.99                | 0.81    | 97.0%    |
|             | 8000   | 0.85    | -5.4        | 0.99              | 0.99                | 0.91    | 99.0%    |
| Mel Ext - Inv | 1000  | 0.81    | -23.5       | 0.99              | 0.99                | 0.81    | 98.5%    |
|             | 2000   | 0.88    | -17.4       | 0.99              | 0.99                | 0.89    | 97.5%    |
|             | 4000   | 0.89    | -11.4       | 0.99              | 0.99                | 0.92    | 98.0%    |
|             | 8000   | 0.92    | -5.4        | 0.99              | 0.99                | 0.0     | 98.5%    |

**Table 6:** Evaluation of Mel Extraction - Inversion and LPC transform defenses against perturbations targeting an undefended DeepSpeech ASR model at different levels of magnitude.

We additionally evaluate the robustness of Mel extraction-inversion and LPC transformations against transfer attacks from an undefended model. We craft targeted adversarial examples using [11] for DeepSpeech ASR at different perturbation levels by linearly scaling the perturbation to have the desired L∞ norm. Table 6 shows the evaluations of transfer attacks at different perturbation levels. We find that attacks targeting undefended models do not break the defense using these two transformation functions even at high perturbation levels. This is because the transcription of g(xadv) is significantly different from the target transcription and transcription of xadv even at high perturbation levels, thereby allowing our detector to consistently detect the adversarial samples.

## D. Straight-Through Gradient Estimator for LPC

We find that the LPC transform cannot be broken in an adaptive attack scenario using Backward Pass Differentiable Approximation (BPDA) with a straight-through gradient estimator (i.e., assuming the identity function as the gradient of the transformation function g during the backward pass). In our experiments, we started with an initial ε∞ of 2000 and increased the initial distortion bound to 16000 but did not observe any improvement in the attack performance as the detector was still able to identify adversarial audio with 100% accuracy. Therefore, using our BPDA attack algorithm, we do not arrive at a solution in which both x and g(x) transcribe to the target phrase even with a high amount of allowed distortion. This motivated us to design stronger adaptive attacks with differentiable LPC (Section 7.1) to find distortion bounds over which LPC transforms are not able to reliably detect adversarial examples.

### Distortion Metrics

| **Defense** | **ε∞** | **|δ|∞** | **dBx(δ)** | **CER(xadv, τ)** | **CER(g(xadv), τ)** | **AUC** | **Acc.** |
|-------------|--------|---------|-------------|-------------------|---------------------|---------|----------|
| LPC         | 2000   | 0.31    | -15.9       | 0.85              | 0.85                | 1.0     | 100%     |
|             | 16000  | 2.1     | -15.9       | 0.85              | 0.85                | 1.0     | 100%     |

**Table 7:** Evaluation of LPC transform against straight-through gradient estimator.

---

This version of the text is more organized, clear, and professional, with consistent formatting and improved readability.