title:Panacea: Automating Attack Classification for Anomaly-Based Network
Intrusion Detection Systems
author:Damiano Bolzoni and
Sandro Etalle and
Pieter H. Hartel
Panacea: Automating Attack Classiﬁcation for
Anomaly-Based Network Intrusion Detection
Systems(cid:2)
Damiano Bolzoni1, Sandro Etalle1,2, and Pieter H. Hartel1
1 University of Twente, Enschede, The Netherlands
2 Eindhoven Technical University, The Netherlands
{damiano.bolzoni,pieter.hartel}@utwente.nl, PI:EMAIL
Abstract. Anomaly-based intrusion detection systems are usually crit-
icized because they lack a classiﬁcation of attacks, thus security teams
have to manually inspect any raised alert to classify it. We present a new
approach, Panacea, to automatically and systematically classify attacks
detected by an anomaly-based network intrusion detection system.
Keywords: attack classiﬁcation, anomaly-based intrusion detection
systems.
One of the often cited weaknesses of anomaly-based intrusion detection systems
(ABSs) is the fact that they cannot classify the attacks they detect (Ghosh and
Schwartzbard [1] and Robertson et al. [2]). The lack of an attack classiﬁcation
aﬀects the overall usability of an ABS, because security teams have to manually
process each alert the ABS raises in order to assess the impact of the detected
attack, and to handle the alert.
Today, security teams faces two main challenges. First, because the most
harmful attacks currently consist of several stages (Ning et al. [3]), security
teams need to detect an attack at the earliest stage, in order to stop it. Secondly,
because of the activities conducted by automatic scanners, BOTnets, and script-
kiddies the number of security alerts has increased over the years. Although true
positives when detected by an IDS, these kinds of activities cannot normally be
considered a serious threat, i.e., they are “non-relevant” events (e.g., a remote
automatic scanner attempting to replicate a 5-year old attack against a now-
secure PHP script).
A number of automatic techniques to perform alert correlation have been
proposed (Cuppens and Ortalo [4], Debar and Wespi [5], Ning and Xu [6] and
Valeur et al. [7]), in order to detect attacks at an early stage, or lower the false
and the non-relevant alert rates. However, such techniques require a good deal of
is
by
the
(cid:2) This
research
program Sentinels
(http://www.sentinels.nl). Sentinels is being ﬁnanced by Technology Founda-
tion STW, the Netherlands Organization for Scientiﬁc Research (NWO), and the
Dutch Ministry of Economic Aﬀairs.
supported
research
E. Kirda, S. Jha, and D. Balzarotti (Eds.): RAID 2009, LNCS 5758, pp. 1–20, 2009.
c(cid:2) Springer-Verlag Berlin Heidelberg 2009
2
D. Bolzoni, S. Etalle, and P.H. Hartel
information (apart from the usual IP addresses and TCP ports) to be eﬀective:
the attacks that triggered the alerts must be classiﬁed.
By classifying an attack (e.g., buﬀer overﬂow, SQL Injection), it is also possible
to set default actions for handling a certain alert. The alert could (1) trigger
automatic countermeasures, e.g., either because an early attack stage has been
detected or because the attack class is considered to have a great impact on the
security. Alternately, the alert could be (2) forwarded for manual handling or
(3) ﬁltered and stored for later analysis (i.e., correlation) and statistics.
Determining the class of an attack is trivial for an alert generated by a
signature-based IDS (SBS), like Snort [8,9]. Each signature is the result of an
analysis of the corresponding attack conducted by experts: the attack class is
manually assigned during the signature development process (i.e., the alert class
is included in the signature). Thus, security teams usually do not need to further
process the alert to assign a class, and they can set precisely a standard action
for the system to execute when such an alert is triggered.
Problem. When an ABS raises an alert, it cannot associate the alert with an
attack class. The system detects an anomaly, but it has too little information
(typically only source and destination IP addresses and TCP ports) to determine
the attack class. No automatic or semi-automatic approach is currently available
to classify anomaly-based alerts. Thus, any anomaly-based alert must be man-
ually processed to identify the alert class, increasing the workload of security
teams. A solution to automate the classiﬁcation of anomaly-based alerts is to
employ some heuristics (e.g., see Robertson et al. [2]) to analyse the anomaly-
based alert for features of well-known attacks. Although this approach could lead
to good results, it totally relies on the manual implementation of the heuristics
(which could be a labour intensive task), and on the expertise of the operator.
Contribution. In this paper we present Panacea, a simple, yet eﬀective, system
that uses machine learning techniques to automatically and systematically clas-
sify attacks detected by a payload-based ABS (and consequently the generated
alerts as well). The basic idea is the following. Attacks that share some common
traits, i.e., some byte sequences in their payloads, are usually in the same class.
Thus, by extracting byte sequences from an alert payload (triggered by a certain
attack), we can compare those sequences to previously collected data with an
appropriate algorithm, ﬁnd the most similar alert payload, and then infer the
attack class from the matching alert payload class.
To the best of our knowledge, Panacea is the ﬁrst system proposed that:
– Automatically classiﬁes attacks detected by an ABS, without using pre-
– Does not need manual assistance to classify attacks (with some exceptions
determined heuristics;
to be described in Section 1.1).
Panacea requires a training phase for its engine to build the attack classiﬁer.
Once the training phase is complete, Panacea classiﬁes any attack detected by
the ABS automatically. Here we consider only attacks that target networks,
however it is possible to extend the approach to include host-based IDSs too.
Panacea: Automating Attack Classiﬁcation
3
Limitation of the approach. Panacea analyses the generated alert payload to
build its classiﬁcation model. Thus, any alert generated by attacks/activities that
do not involve a payload (e.g., a port scan or a DDoS) cannot be automatically
classiﬁed. As most of the harmful attacks inject some data in target systems, we
do not see this as a serious limitation.
This paper is organized as follows. In Section 1 we present the architecture
of Panacea, we detail its components, the way they interact and the data they
exchange (Section 1.1). In Section 1.2, we summarise the machine learning algo-
rithms that Panacea uses to classify the alerts. In Section 2 we show the results
of the benchmarks. Section 3 presents related work, while Section 4 concludes.
1 Architecture
Panacea consists of two interacting components: the Alert Information Extractor
(AIE) and the Attack Classiﬁcation Engine (ACE). The AIE receives alerts
from the IDS(s), processes the payload, and extracts signiﬁcant information,
outputting alert meta-information. This meta-information is then passed to the
ACE that automatically determines the attack class. The classiﬁcation process
goes through two main stages. First, the ACE is trained with several types of
alert meta-information to build a classiﬁcation model. The ACE is fed alert meta-
information and the corresponding attack class. The attack class information can
be provided in several ways, either manually by an operator or automatically by
extracting additional information from the original alert (only when the alert
has been raised by an SBS). Secondly, when the training is completed, the ACE
is ready to classify new incoming alerts automatically. We now describe each
component and the working modes of Panacea in detail. Figure 1 depicts Panacea
and its internal components.
Fig. 1. An overview of the Panacea architecture and the internal components
4
D. Bolzoni, S. Etalle, and P.H. Hartel
1.1 Alert Information Extractor
The ﬁrst component we examine is the AIE. The extraction of relevant infor-
mation from alert payloads is a crucial step, as it is the basis for attack class
inference. Requirements for this phase are that the extraction function should
capture enough features from the original information (i.e., the payload) to dis-
tinguish alerts belonging to diﬀerent classes, and it should be eﬃcient w.r.t. the
required memory space. We now describe the analysis techniques we have chosen.
Extracting and storing relevant information. N-gram analysis [10] allows
one to capture features of data in an eﬃcient way, and it has been used before in
the context of computer security to detect attacks (Forrester and Hofmeyr [11],
Wang and Stolfo [12]). N-gram analysis is a suitable technique to capture data
features also for the problem of attack classiﬁcation, and the AIE employs such
a technique to extract relevant information from alert payloads.
As Wang et al. note [13], by using higher order n-grams (i.e., n-grams where
n > 1) it is possible to capture more data features and to achieve a more precise
analysis. One has to consider that the whole feature space size of a higher-
order n-gram is 256n (where n is the n-gram order). The comparison of byte
frequency values becomes quickly infeasible, also for values of n such as 3 or
4, because the space needed to store average and standard deviation values for
each n-gram grows exponentially (e.g., 640GB would be needed to store 5-grams
statistics). Although a frequency-based n-gram analysis may seem to model data
distribution accurately, Wang et al. experimentally show that a binary-based n-
gram analysis is more precise in the context of network data analysis. In practice,
the fact that a certain n-gram has occurred is stored, rather than computing
average byte frequency and standard deviation statistics. The reason why the
binary approach performs better is that high-order n-grams are more sparse than
low-order n-grams, thus it is more diﬃcult to gather accurate byte-frequency
statistics as the order increases. This approach has an additional advantage,
other than being more precise. Because less information is required, it requires
less space in memory, and we can consider higher-order n-grams (such as 5).
We now present the data structure used by the AIE to store the extracted
information.
Bloom ﬁlter. A Bloom ﬁlter [14] (BF) is a method to represent a set of S elements
(n-grams in our embodiment) in a smaller space. Formally, a BF is a pair (cid:2)b, H(cid:3)
where b is a bit map of l bits, initially all set to 0, and H is a set of k independent
hash functions h1 . . . hk. H determines the storage of b in such a way that, given
an element s in S: ∀hk, bi = 1 ⇐⇒ hk(s) mod l = i. In other words, for each
n-gram s in S, and for each hash function hk, we compute hk(s) mod l, and we
use the resulting value as index to set to 1 the bit in b corresponding to it. When
checking for the presence of a certain element s, the element is considered to
be stored in the BF if: ∀hk, bhk(s) mod l = 1. Because of the n-gram sparsity, a
BF with a size of 10KB is suﬃciently large to store the alert meta-information
resulting from 5-grams analysis.
Panacea: Automating Attack Classiﬁcation
5
(a) Inserting n-gram “abcde”
(b) Inserting n-gram “pqrst”
Fig. 2. Examples of inserting two diﬀerent 5-grams. H1, H2 and H3 represent diﬀerent
hash functions.
A BF employs k diﬀerent hash functions at the same time to decrease the
probability of a false positive (the opposite situation, a false negative, cannot
occur). False positives occur when all of the bit positions calculated for a given
element have been set to 1 when inserting previous elements, due to the collisions
generated by hash functions. The false positive rate for a given BF is (1− e kn
l )k,
where n is the number of elements already stored.
Operational modes. The AIE not only extracts information from alerts as
described above, but it is also responsible for forwarding the attack class in-
formation to the classiﬁcation engine, when the latter is in training mode. The
attack class can be provided either automatically or manually. In case an SBS
is deployed next to the ABS and it is monitoring the same data, it is possible to
6
D. Bolzoni, S. Etalle, and P.H. Hartel
Fig. 3. Example of a false positive. The element “zxcvb” has not been inserted in the
Bloom ﬁlter. Due to the collisions generated by the hash functions, the test for its
presence returns “true”.
feed the ACE during training both the payload and the attack class of any alert
generated by the SBS. We deﬁne this as the automatic mode, since no human
operator is required to carry out the attack classiﬁcation. A human operator
can classify the alerts raised by the ABS (in a manner consistent with the SBS
classiﬁcation), hence integrating those with the alerts raised by the ABS during
the ACE training. We call this the semi-automatic mode. The last possible op-
erative mode is the manual mode. In this case, any alert is manually classiﬁed
by an operator.
Each mode presents advantages and disadvantages. In automatic mode, the
workload is low, but on the other hand the classiﬁcation accuracy is likely to
be low as well. In fact, the SBS and the ABS are likely to detect diﬀerent
attacks, hence the classiﬁcation engine could be trained to correctly classify
only a subset of the ABS alerts. The manual mode requires human intervention
but it is likely to produce better results, since each alert is consistently classiﬁed.
We assume that the alerts raised by the SBS and ABS have already been veriﬁed
and any false positive alert has already been purged (e.g., using ALAC [15] or
our ATLANTIDES [16]).
1.2 Attack Classiﬁcation Engine
The ACE includes the algorithm used to classify attacks. Since we are aware
of the attack class information, we consider only supervised machine learning
algorithms. These algorithms generally achieve better results than unsupervised
algorithms (where the algorithm, e.g. K-medoids, deduces classes by measuring
inter-data similarity). The classiﬁcation algorithm must meet several require-
ments, namely:
Panacea: Automating Attack Classiﬁcation
7
– support for multiple classes, as alerts fall in several classes;
– classiﬁcation of high-dimensional data, since each bit of the BF data struc-
ture the ACE receives in input is seen as a dimension of analysis;
– fast training (the reason for this will be clariﬁed later) and classiﬁcation
phases;
– (optional) estimate classiﬁcation conﬁdence when in classiﬁcation phase.
We consider the last requirement optional, as it does not directly inﬂuence the