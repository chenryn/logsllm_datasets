# 02丨性能综述：TPS和响应时间之间是什么关系？我们在上一篇文章中讲了性能测试的概念，肯定会有人觉得，那些概念很重要，怎么能轻易抹杀呢？那么，在今天的文章中，我们就来扒一扒性能场景，看看概念与实际之间的差别。 前面我们说了性能要有场景，也说了性能场景要有基准性能场景、容量性能场景、稳定性性能场景、异常性能场景。在我有限的十几年性能生涯中，从来没有见过有一个性能场景可以超出这几个分类。下面我将对前面说到的概念进行一一对应。 学习性能的人，一定看吐过一张图，现在让你再吐一次。如下： ![](Images/7bf94a97a80655ff3d18209e4ba0ea7e.png)savepage-src="https://static001.geekbang.org/resource/image/36/7d/36ee34ee92b75fd17d5314d74453367d.png"}在这个图中，定义了三条曲线、三个区域、两个点以及三个状态描述。 1.       三条曲线：吞吐量的曲线（紫色）、使用率 /    用户数曲线（绿色）、响应时间曲线（深蓝色）。        2.       三个区域：轻负载区（Light Load）、重负载区（Heavy    Load）、塌陷区（Buckle    Zone）。    3.       两个点：最优并发用户数（The Optimum Number of Concurrent    Users）、最大并发用户数（The Maximum Number of Concurrent    Users）。        4.       三个状态描述：资源饱和（Resource    Saturated）、吞吐下降（Throughput Falling）、用户受影响（End Users    Effected）。        我在很多地方，都看到了对这张图的引用。应该说，做为一个示意图，它真的非常经典，的确描述出了一个基本的状态。但是，示意图也只能用来做示意图，在具体的项目中，我们仍然要有自己明确的判断。 我们要知道，这个图中有一些地方可能与实际存在误差。 首先，很多时候，重负载区的资源饱和，和 TPS达到最大值之间都不是在同样的并发用户数之下的。比如说，当 CPU资源使用率达到 100%之后，随着压力的增加，队列慢慢变长，但是由于用户数增加的幅度会超过队列长度，所以TPS 仍然会增加，也就是说资源使用率达到饱和之后还有一段时间 TPS才会达到上限。 大部分情况下，响应时间的曲线都不会像图中画得这样陡峭，并且也不一定是在塌陷区突然上升，更可能的是在重负载区突然上升。 另外，吞吐量曲线不一定会出现下降的情况，在有些控制较好的系统中会维持水平。曾经在一个项目中，因为TPS维持水平，并且用户数和响应时间一直都在增加，由于响应时间太快，一直没有超时。我跟我团队那个做压力的兄弟争论了三个小时，我告诉他接着压下去已经没有意义，就是在等超时而已。他倔强地说，由于没有报错，时间还在可控范围，所以要一直加下去。关于这一点争论，我在后续的文章中可能还会提及。 最优并发数这个点，通常只是一种感觉，并没有绝对的数据用来证明。在生产运维的过程中，其实我们大部分人都会更为谨慎，不会定这个点为最优并发，而是更靠前一些。 最大并发数这个点，就完全没有道理了，性能都已经衰减了，最大并发数肯定是在更前的位置呀。这里就涉及到了一个误区，压力工具中的最大用户数或线程数和TPS之间的关系。在具体的项目实施中，有经验的性能测试人员，都会更关心服务端能处理的请求数即TPS，而不是压力工具中的线程数。 这张图没有考虑到锁或线程等配置不合理的场景，而这类场景又比较常见。也就是我们说的，TPS上不去，资源用不上。所以这个图默认了一个前提，只要线程能用得上，资源就会蹭蹭往上涨。 这张图呢，本来只是一个示意，用以说明一些关系。但是后来在性能行业中，有很多没有完全理解此图的人将它做为很有道理的"典范"给一些人讲，从而引起了越来越多的误解。 此图最早的出处是 2005 年 Quest Software 的一个 PSO Consultant写的一个白皮书《Performance TestingMethodology》。在 18页论述了这张图，原文摘录一段如下： >  > You can see that as user load increases, response time increases> slowly and resource utilization increases almost linearly. This is> because the more work you are asking your application to do, the more> resources it needs. Once the resource utilization is close to 100> percent, however, an interesting thing happens -- response degrades> with an exponential curve. This point in the capacity assessment is> referred to as the saturation point. The saturation point is the point> where all performance criteria are abandoned and utter panic ensues.> Your goal in performing a capacity assessment is to ensure that you> know where this point is and that you will never reach it. You will> tune the system or add additional hardware well before this load> occurs.> >按照这段描述，这个人只是随着感觉在描述一种现象，除此无它。比如说，Thesaturation point is the point where all performance criteria areabandoned and utter panic ensues. 在我的工作经验中，其实在 saturationpoint 之前，性能指标就已经可以显示出问题了，并且已经非常 panic了，而我们之所以接着再加压力是为了让指标显示得更为明显，以便做出正确的判断。而调优实际上是控制系统在饱和点之前，这里有一个水位的问题，控制容量到什么样的水位才是性能测试与分析的目标。我们简化出另一个图形，以说明更直接一点的关系。如下所示：![](Images/6406577be3339ff90dce03bf121ab160.png)savepage-src="https://static001.geekbang.org/resource/image/c0/34/c0575730fe2d14842aba066bc8786734.png"}上图中蓝线表示TPS，黄色表示响应时间。在 TPS 增加的过程中，响应时间一开始会处在较低的状态，也就是在 A点之前。接着响应时间开始有些增加，直到业务可以承受的时间点 B，这时 TPS仍然有增长的空间。再接着增加压力，达到 C 点时，达到最大TPS。我们再接着增加压力，响应时间接着增加，但 TPS会有下降（请注意，这里并不是必然的，有些系统在队列上处理得很好，会保持稳定的TPS，然后多出来的请求都被友好拒绝）。最后，响应时间过长，达到了超时的程度。在我的工作中，这样的逻辑关系更符合真实的场景。我不希望在这个关系中描述资源的情况，因为会让人感觉太乱了。为什么要把上面描述得如此精细？这是有些人将第一张图中的 Light load对应为性能测试，Heavy Load 对应为负载测试，Buckle Zone对应为压力测试......还有很多的对应关系。事实上，这是不合理的。下面我将用场景的定义来替换这些混乱的概念。![](Images/df6ea02684677ad9429da55f326afabf.png)savepage-src="https://static001.geekbang.org/resource/image/55/b1/55168e3443446e5866c85853f0e71ab1.jpg"}为什么我要如此划分？因为在具体场景的操作层面，只有场景中的配置才是具体可操作的。而通常大家认为的性能测试、负载测试、压力测试在操作的层面，只有压力工具中线程数的区别，其他的都在资源分析的层面，而分析在很多人的眼中，都不算测试。拿配置测试和递增测试举例吧。在性能中，我们有非常多的配置，像 JVM 参数、OS 参数、DB参数、网络参数、容器参数等等。如果我们把测试这些配置参数，称为"配置测试"，我觉得未免过于狭隘了。因为对于配置参数来说，这只是做一个简单的变更，而性能场景其实没有任何变化呀。配置更改前后，会用同样的性能场景来判断效果，最多再增加一些前端的压力，实际的场景并没有任何变化，所以，我觉得它不配做为一个单独的分类。再比如递增测试，在性能中，基准性能场景也好，容量性能场景也好，哪个是不需要递增的呢？我知道现在市场上经常有测试工程师，直接就上了几百几千线程做压力（请你不要告诉我这是个正常的场景，鉴于我的精神有限，承受不了这样的压力）。除了秒杀场景，同时上所有线程的场景，我还没有见到过。在一般的性能场景中，递增都是必不可少的过程。同时，递增的过程，也要是连续的，而不是100 线程、200 线程、300线程这样断开执行场景，这样是不合理的。关于这一点，我们将在很多地方着重强调。所以我觉得递增也不配做一个单独的分类。其他的概念，就不一一批驳了。其实在性能测试中，在实际的项目实施中，我们并不需要这么多概念，这些杂七杂八的概念也并没有对性能测试领域的发展起到什么推进作用。要说云计算、AI、大数据这些概念，它们本身在引导着一个方向。而性能测试中被定为"测试"，本身就处在软件生存周期的弱势环节，当前的市场发展也并不好。还被这些概念冲乱了本来应该有的逻辑的思路，实在是得不偿失。总结总之，在具体的性能项目中，性能场景是一个非常核心的概念。因为它会包括压力发起策略、业务模型、监控模型、性能数据（性能中的数据，我一直都不把它称之为模型，因为在数据层面，测试并没有做过什么抽象的动作，只是使用）、软硬件环境、分析模型等。有了清晰的、有逻辑的场景概念之后，在后面的篇幅当中，我们将从场景的各个角度去拆解。在本专栏中，我们将保持理念的连贯性，以示我不变的职业初心。思考题如果你理解了今天的内容，不妨说说为什么说现在市场上的概念对性能项目的实施并没有太大的价值？其次，性能场景为什么要连续？而不是断开？欢迎你在评论区写下你的思考，也欢迎把这篇文章分享给你的朋友或者同事，一起交流一下。
# 03丨性能综述：怎么理解TPS、QPS、RT、吞吐量这些性能指标？在上一篇文章中，我们讲述了性能场景，下面就要说性能需求指标了。通常我们都从两个层面定义性能场景的需求指标：业务指标和技术指标。这两个层面需要有映射关系，技术指标不能脱离业务指标。一旦脱离，你会发现你能回答"一个系统在多少响应时间之下能支持多少TPS"这样的问题，但是回答不了"业务状态是什么"的问题。举例来说，如果一个系统要支持 1000万人在线，可能你能测试出来的结果是系统能支持 1 万TPS，可是如果问你，1000万人在线会不会有问题？这估计就很难回答了。我在这里画一张示意图以便你理解业务指标和性能指标之间的关系。![](Images/f677df83193ff66e0a82fb97cc193747.png)savepage-src="https://static001.geekbang.org/resource/image/1b/c2/1bb1222c53e8b16414458a8572e786c2.png"}这个示意显然不够详细，但也能说明关系了。所有的技术指标都是在有业务场景的前提下制定的，而技术指标和业务指标之间也要有详细的换算过程。这样一来，技术指标就不会是一块飞地。同时，在回答了技术指标是否满足的同时，也能回答是否可以满足业务指标。有了这样的关联关系，下面我们看一下性能测试行业常用的性能指标表示法。![](Images/ab523898fc4d7d0a7c3dd20a3cd3dfba.png)savepage-src="https://static001.geekbang.org/resource/image/53/83/533fa609f8607dbd65878fb52ef87183.jpg"}我将现在网上能看到的性能指标做了罗列，其中不包括资源的指标。因为资源类的比较具体，并且理解误差并不大，但业务类的差别就比较大了。对这些性能指标都有哪些误解我记得我还年轻的时候，还没有 QPS、RPS、CPS 这样的概念，只有TPS。那个时候，天总是那么蓝，时间总是那么慢，"你锁了人家就懂了"。QPS 一开始是用来描述 MySQL 中 SQL 每秒执行数 Query Per Second，所有的SQL 都被称为 Query。后来，由于一些文章的转来转去，QPS被慢慢地移到了压力工具中，用来描述吞吐量，于是这里就有些误解，QPS 和 TPS到底是什么关系呢？RPS指的是每秒请求数。这个概念字面意思倒是容易理解，但是有个容易误解的地方就是，它指的到底是哪个层面的Request？如果说 HTTP Request，那么和 Hits Per Second又有什么关系呢？HPS，这也是个在字面意思上容易理解的概念。只是 Hit 是什么？有人将它和HTTP Request等价，有人将它和用户点击次数等价。CPS，用的人倒是比较少，在性能行业中引起的误解范围并不大。同时还有喜欢用CPM（Calls Per Minute，每分钟调用数）的。这两个指标通常用来描述 Service层的单位时间内的被其他服务调用的次数，这也是为什么在性能行业中误解不大的原因，因为性能测试的人看Service 层东西的次数并不多。为了区分这些概念，我们先说一下 TPS（Transactions PerSecond）。我们都知道 TPS是性能领域中一个关键的性能指标概念，它用来描述每秒事务数。我们也知道 TPS在不同的行业、不同的业务中定义的粒度都是不同的。所以不管你在哪里用TPS，一定要有一个前提，就是**所有相关的人都要知道你的 T是如何定义的**。经常有人问，TPS应该如何定义？这个实在是没有具体的"法律规定"，那就意味着，你想怎么定就怎么定。通常情况下，我们会根据场景的目的来定义 TPS的粒度。如果是接口层性能测试，T可以直接定义为接口级；如果业务级性能测试，T可以直接定义为每个业务步骤和完整的业务流。我们用一个示意图来说明一下。![](Images/2d944f8fadfca097ee536046862b6194.png)savepage-src="https://static001.geekbang.org/resource/image/d2/8d/d2093240be6f4151002d8019cabfac8d.png"}如果我们要单独测试接口 1、2、3，那 T就是接口级的；如果我们要从用户的角度来下一个订单，那 1、2、3 应该在一个T 中，这就是业务级的了。当然，这时我们还要分析系统是如何设计的。通常情况下，积分我们都会异步，而库存不能异步哇。所以这个业务，你可以看成只有1、2 两个接口，但是在做这样的业务级压力时，3接口也是必须要监控分析的。所以，性能中 TPS 中 T 的定义取决于场景的目标和 T的作用。一般我们都会这样来定事务。1.  接口级脚本：        2.  业务级接口层脚本（就是用接口拼接出一个完整的业务流）：        3.  用户级脚本        你要创建什么级别的事务，完全取决于测试的目的是什么。一般情况下，我们会按从上到下的顺序一一地来测试，这样路径清晰地执行是容易定位问题的。重新理解那些性能指标概念搞清楚了 TPS 的 T 是什么，下面就要说什么是 TPS了。字面意思非常容易理解，就是：**每秒事务数**。在性能测试过程中，TPS之所以重要，是因为它可以反应出一个系统的处理能力。我在很多场景中都说过，事务就是统计了一段脚本的执行时间，并没有什么特别的含义。而现在又多加了其他的几个概念。首先是 QPS，如果它描述的是数据库中的 Query PerSecond，从上面的示意图中来看，其实描述的是服务后面接的数据库中 SQL的每秒执行条数。如果描述的是前端的每秒查询数，那就不包括插入、更新、删除操作了。显然这样的指标用来描述系统整体的性能是不够全面的。所以不建议用QPS来描述系统整体的性能，以免产生误解。RPS（Request persecond），每秒请求数。看似简单的理解，但是对于请求数来说，要看是在哪个层面看到的请求，因为请求这个词，实在是太泛了。我们把上面的图做一点点变化来描述一下请求数。![](Images/8c2bc7bdcea7947ae8a995139f361ac9.png)savepage-src="https://static001.geekbang.org/resource/image/6d/9c/6d260efd23e2ea7e861070cd15e83e9c.png"}如果一个用户点击了一次，发出来 3 个 HTTP Request，调用了 2次订单服务，调用了 2 次库存服务，调用了 1 次积分服务，那么这个 Request该如何计算？如果你是算 GDP的专家，我觉得可能会是：3+2+2+1=8（次）。而在具体的项目中，我们会单独描述每个服务，以便做性能统计。如果要描述整体，最多算是有3 个 RPS。如果从 HTTP 协议的角度去理解，那么 HTTP Request算是一个比较准确的描述了，但它本身的定义并没有包含业务。如果赋予它业务的含义，那么用它来描述性能也是可以的。HPS（Hits Per Second），每秒点击数。Hit 一般在性能测试中，都用来描述HTTPRequest。但是，也有一些人用它描述真正的客户在界面上的点击次数。关于这一点，就只有在具体的项目中才能规定得具体一些。当它描述HTTP Request 时，如果 RPS 也在描述 HTTPRequest，那这两个概念就完全一样了。CPS/CPM：Calls Per Second/ Calls Per Minutes，每秒 /每分钟调用次数。这个描述在接口级是经常用到的，比如说上面的订单服务。显然一次客户界面上的点击调用两次。这个比较容易理解。但是，在操作系统级，我们也经常会听到系统调用用call 来形容，比如说用 strace 时，你就会看见 Calls这样的列名。这些概念本身并没有问题，但是当上面的概念都用来描述一个系统的性能能力的时候，就混乱了。对于这种情况，我觉得有几种处理方式：1.       用一个概念统一起来。我觉得直接用 TPS    就行了，其他的都在各层面加上限制条件来描述。比如说，接口调用 1000    Calls/s，这样不会引起混淆。        2.       在团队中定义清楚术语的使用层级。        3.       如果没有定义使用层级，那只能在说某个概念的时候，加上相应的背景条件。        所以，当你和同事在沟通性能指标用哪些概念时，应该描述得更具体一些。在一个团队中，应该先有这些术语统一的定义，再来说性能指标是否满足。响应时间 RT在性能中，还有一个重要的概念就是响应时间（ResponseTime）。这个比较容易理解。我们接着用这张示意图说明：![](Images/ca99911141edc4bdf98f04f71484960d.png)savepage-src="https://static001.geekbang.org/resource/image/7b/ac/7b2fb3aa4129a54ddb28d0e70cc551ac.png"}RT =T2-T1。计算方式非常直接简单。但是，我们要知道，这个时间包括了后面一连串的链路。响应时间的概念简单至极，但是，响应时间的定位就复杂了。性能测试工具都会记录响应时间，但是，都不会给出后端链路到底哪里慢。经常有人问问题就直接说，我的响应时间很慢。问题在哪呢？在这种情况下，只能回答：不知道。因为我们要先画架构图，看请求链路，再一层层找下去。比如说这样：![](Images/250130021f70a0cfc8868a543c164d41.png)savepage-src="https://static001.geekbang.org/resource/image/bd/eb/bd8a2056546c5917290af512be2342eb.png"}在所有服务的进出口上都做记录，然后计算结果就行了。在做网关、总线这样的系统时，基本上都会考虑这个功能。而现在，随着技术的发展，链路监控工具和一些 Metrics的使用，让这个需求变得简单了不少。比如说这样的展示：![](Images/b964a6c6af8f1b6c10589e4aae14a710.png)savepage-src="https://static001.geekbang.org/resource/image/80/86/80a03dcc4a81d8bdff96546a1fa18186.png"}它很直观地显示了，在一个请求链路上，每个节点消耗的时间和请求的持续时间。我顺便在这里说一下调优在当前性能项目中的状态。对于响应时间来说，时间的拆分定位是性能瓶颈定位分析中非常重要的一节。但是请注意，这个环节并不是性能测试工程师的最后环节。在工作中，我经常看到有很多性能测试工程师连时间拆分都不做，只报一个压力工具中看到的响应时间，就给一个通过不通过的结论，丝毫没有定位。另外，有一些性能测试工程师，倒是用各种手段分析了时间的消耗点，但是也觉得自己的工作就此结束了，而不做根本原因的分析或协调其他团队来分析。当然在不同的企业里，做分析的角色和要求各不相同，所以也要根据实际的企业现状来说。在我的观点中，性能只测不调，那就是性能验证的工作，称不上是完整的性能项目。第三方性能测试的机构可以这样做，但是在一个企业内部这样做的话，性能团队的价值肯定就大打折扣了。但是现在有很多人都不把性能调优做为性能团队的工作，主要原因有几点：1.       性能测试团队的人能力有限做不到；        2.       性能调优代价高，耗时长，不值得做。        在我带的性能项目中，基本上调优的工作都是我的团队主导的。性能团队当然不可能完全没有技术弱点，所以在很多时候都是协调其他团队的人一起来分析瓶颈点。那为什么是我的团队来主导这个分析的过程呢？因为每个技术人员对性能瓶颈的定义并不相同，如果不细化到具体的计数器的值是多少才有问题，有误解的可能性就很大。曾经我在某零售业大厂做性能咨询的时候，一房间的技术人员，开发、运维、DBA都有，结果性能瓶颈出现了，所有人都说自己的部分是没问题的。于是我一个个问他们是如何判断的，判断的是哪个计数器，值又是多少。结果发现很多人对瓶颈的判断都和我想像的不一样。举例来说，DB 的 CPU 使用率达到 90% 以上，DBA会觉得没有问题，因为都是业务的 SQL，并不是 DB 本身有问题。开发觉得 SQL执行时间慢是因为 DB有问题，而不是自己写的有问题，因为业务逻辑并没有错，有问题的点应该是 DB上索引不合理、配置不合理。你看，同样的问题，每个人的看法都有区别。当然也不能排除有些人就是想推诿责任。这时怎么办呢？如果你可以把执行计划拿出来，告诉大家，这里应该创建索引，而那里应该修改业务条件，这时就具体了。压力工具中的线程数和用户数与 TPS总是有很多人在并发线程数和 TPS之间游荡，搞不清两者的关系与区别。这两个概念混淆的点就是，好像线程是真实的用户一样，那并发的线程是多少就描述出了多少真实的用户。但是做性能的都会知道，并发线程数在没有模拟真实用户操作的情况下，和真实的用户操作差别非常远。在 LoadRunner 还比较红火的时候，Mercury 提出一个 BTO的概念，就是业务科技优化。在 LoadRunner中也提出"思考时间"的概念，其实在其他的性能工具中是没有"思考时间"这个词的。这个词的提出就是为了性能工具模拟真实用户。但是随着性能测试的地位不断下降，以及一些概念和名词不断地被以讹传讹，导致现在很多人都没有明白压力工具中的线程数和用户以及TPS之间是怎样的关系。同样，我们先画一个示意图来说明一下。![](Images/8b27707cc667608195c371cccf87de68.png)savepage-src="https://static001.geekbang.org/resource/image/23/2b/23c22b843df28ae9092e76a566077b2b.png"}这里先说明一个前提，上面的一个框中有四个箭头，每个都代表着相同的事务。在说这个图之前，我们要先说明"并发"这个概念是靠什么数据来承载的。在上面的内容中，我们说了好多的指标，但并发是需要具体的指标来承载的。你可以说，我的并发是1000TPS，或者 1000RPS，或者1000HPS，这都随便你去定义。但是在一个具体的项目中，当你说到并发 1000这样没有单位的词时，一定要让大家都能理解这是什么。在上面这张示意图中，其实压力工具是 4个并发线程，由于每个线程都可以在一秒内完成 4 个事务，所以总的 TPS 是16。这非常容易理解吧。而在大部分非技术人的脑子里，这样的场景就是并发数是4，而不是 16。要想解释清楚这个非常困难，我的做法就是，直接告诉别人并发是 16就好了，不用关心 4个线程这件事。这在我所有项目中几乎都是一样的，一直也没有什么误解。那么用户数怎么来定义呢？涉及到用户就会比较麻烦一点。因为用户有了业务含义，所以有些人认为一个系统如果有1 万个用户在线，那就应该测试 1万的并发线程，这种逻辑实在是不技术。通常，我们会对在线的用户做并发度的分析，在很多业务中，并发度都会低于5%，甚至低于 1%。拿 5% 来计算，就是 10000 用户 x5%=500(TPS)，注意哦，这里是TPS，而不是并发线程数。如果这时响应时间是 100ms，那显然并发线程数是500TPS/(1000ms/100ms)=50(并发线程)。通过这样简单的计算逻辑，我们就可以看出来用户数、线程数和 TPS之间的关系了。![](Images/2eb590aa328b11d2990323b181ab32e3.png)savepage-src="https://static001.geekbang.org/resource/image/72/e0/724b0e330ee9f8a97ac9b8326af370e0.png"}但是！响应时间肯定不会一直都是 100ms的嘛。所以通常情况下，上面的这个比例都不会固定，而是随着并发线程数的增加，会出现趋势上的关系。所以，在性能分析中，我一直在强调着一个词：**趋势！**业务模型的 28 原则是个什么鬼？我看到有些文章中写性能测试要按 28原则来计算并发用户数。大概的意思就是，如果一天有 1000万的用户在使用，系统如果开 10 个小时的话，在计算并发用户数的时候，就用 2小时来计算，即 1000 万用户在 2小时内完成业务。我要说的是，这个逻辑在一个特定的业务系统中是没有任何价值的。因为每个系统的并发度都由业务来确定，而不是靠这样的所谓的定律来支配着业务。如果我们做了大量的样本数据分析，最后确实得出了 28的比例，我觉得那也是可以的。但是如果什么数据都没有分析，直接使用 28比例来做评估和计算，那就跟耍流氓没有区别。业务模型应该如何得到呢？这里有两种方式是比较合理的：1.       根据生产环境的统计信息做业务比例的统计，然后设定到压力工具中。有很多不能在线上直接做压力测试的系统，都通过这种方式获取业务模型。        2.       直接在生产环境中做流量复制的方式或压力工具直接对生产环境发起压力的方式做压力测试。这种方式被很多人称为全链路压测。其实在生产中做压力测试的方式，最重要的工作不是技术，而是组织协调能力。相信参与过的人都能体会这句话的重量。        响应时间的 258 原则合理吗？对于响应时间，有很多人还在说着 258 或 2510响应时间是业内的通用标准。然后我问他们这个标准的出处在哪里？谁写的？背景是什么？几乎没有人知道。真是不能想像，一个谁都不知道出处的原则居然会有那么大的传播范围，就像谣言一样，出来之后，再也找不到源头。其实这是在 80 年代的时候，英国一家 IT媒体对音乐缓冲服务做的一次调查。在那个年代，得到的结果是，2秒客户满意度不错；5 秒满意度就下降了，但还有利润；8秒时，就没有利润了。于是他们就把这个统计数据公布了出来，这样就出现了 258principle，翻译成中文之后，它就像一个万年不变的定理，深深影响着很多人。距离这个统计结果的出现，已经过去快 40 年了，IT发展的都能上天了，这个时间现在已经完全不适用了。所以，以后出去别再提258/2510响应时间原则这样的话了，太不专业。那么响应时间如何设计比较合理呢？这里有两种思路推荐给你。1.       同行业的对比数据。        2.       找到使用系统的样本用户（越多越好），对他们做统计，将结果拿出来，就是最有效的响应时间的制定标准。        性能指标的计算方式我们在网上经常可以看到有人引用这几个公式。公式（1）：并发用户数计算的通用公式：]{.strutstyle="height:0.68333em;vertical-align:0em;"}[C]{.mord .mathdefaultstyle="margin-right:0.07153em;"}[]{.mspacestyle="margin-right:0.2777777777777778em;"}[=]{.mrel}[]{.mspacestyle="margin-right:0.2777777777777778em;"}]{.base}[[]{.strutstyle="height:1.217331em;vertical-align:-0.345em;"}[[]{.mopen.nulldelimiter}[[[]{.pstrut style="height:3em;"}[[[T]{.mord.mathdefault .mtight style="margin-right:0.13889em;"}]{.mord.mtight}]{.sizing .reset-size6 .size3.mtight}]{style="top:-2.6550000000000002em;"}[[]{.pstrutstyle="height:3em;"}[]{.frac-linestyle="border-bottom-width:0.04em;"}]{style="top:-3.23em;"}[[]{.pstrutstyle="height:3em;"}n]{.mord .mathdefault .mtight}[L]{.mord.mathdefault .mtight}]{.mord .mtight}]{.sizing .reset-size6 .size3.mtight}]{style="top:-3.394em;"}]{.vliststyle="height:0.872331em;"}[​]{.vlist-s}]{.vlist-r}[[]{.vliststyle="height:0.345em;"}]{.vlist-r}]{.vlist-t.vlist-t2}]{.mfrac}[]{.mclose.nulldelimiter}]{.mord}]{.base}]{.katex-html aria-hidden="true"}]{.katexslate-string="true"}]}slate-type="inline-katex" 其中 C 是平均的并发用户数；n 是 login session 的数量；L 是 loginsession 的平均长度；T指考察的时间段长度。公式（2）：```{=html}```并发用户数峰值： ```{=html}``````{=html}``````{=html}``````{=html}```]{.strut style="height:0.69444em;vertical-align:0em;"}[C]{.mord.mathdefault style="margin-right:0.07153em;"}[']{.mord}[]{.mspacestyle="margin-right:0.2777777777777778em;"}[≈]{.mrel}[]{.mspacestyle="margin-right:0.2777777777777778em;"}]{.base}[[]{.strutstyle="height:0.76666em;vertical-align:-0.08333em;"}[C]{.mord.mathdefault style="margin-right:0.07153em;"}[]{.mspacestyle="margin-right:0.2222222222222222em;"}[+]{.mbin}[]{.mspacestyle="margin-right:0.2222222222222222em;"}]{.base}```{=html}```]{.strut style="height:1.04em;vertical-align:-0.11333499999999996em;"}```{=html}```]{.pstrut style="height:2.5em;"}3]{.mord .mtight}]{.mord.mtight}]{.sizing .reset-size6 .size1.mtight}]{style="top:-2.987998em;"}]{.vliststyle="height:0.8102180000000001em;"}]{.vlist-r}]{.vlist-t}]{.root}```{=html}``````{=html}``````{=html}```]{.pstrut style="height:3em;"}[[C]{.mord .mathdefaultstyle="margin-right:0.07153em;"}]{.mordstyle="padding-left:0.833em;"}]{.svg-align style="top:-3em;"}```{=html}```]{.pstrut style="height:3em;"}```{=html}``````{=html}`````{=html}``{=html}```{=html}`````{=html}``{=html}``{=html}[​]{.vlist-s}``{=html}[[]{.vliststyle="height:0.11333499999999996em;"}]{.vlist-r}``{=html}``{=html}``{=html}``{=html}``{=html}``{=html}``{=html}```{=html}```C'指并发用户数的峰值，C就是公式（1）中得到的平均的并发用户数。该公式是假设用户的 login session产生符合泊松分布而估算得到的。仔细搜索之后发现会发现这两个公式的出处是 2004 年一个叫 Eric Man Wong的人写的一篇名叫《Method for Estimating the Number of ConcurrentUsers》的文章。中英文我都反复看到很多篇。同时也会网上看到有些文章中把这个文章描述成"业界公认"的计算方法。在原文中，有几个地方的问题。1.       C    并不是并发用户，而是在线用户。        2.       这两个公式做了很多的假设条件，比如说符合泊松分布什么的。为什么说这个假设有问题？我们都知道泊松分布是一个钟型分布，它分析的是一个系统在全周期中的整体状态。        3.       如果要让它在实际的项目中得到实用，还需要有大量的统计数据做样本，代入计算公式才能验证它的可信度。        4.       峰值的计算，我就不说了，我觉得如果你是做性能的，应该一看就知道这个比例不符合大部分真实系统的逻辑。        5.       有些人把这两个公式和 Little 定律做比较。我要说 Little    定律是最基础的排队论定律，并且这个定律只说明了：系统中物体的平均数量等于物体到达系统的平均速率和物体在系统中停留的平均时间的乘积。我觉得这句话，就跟秦腔中的"出门来只觉得脊背朝后"是一样一样的。        有人说应该如何来做系统容量的预估呢。我们现在很多系统的预估都是在一定的假设条件之下的，之所以是预估，说明系统还不在，或者还没达到那样的量。在这种情况下，我们可以根据现有的数据，做统计分析、做排队论模型，进而推导以后的系统容量。但是我们所有做性能的人都应该知道，系统的容量是演进来的，而不是光凭预估就可以得出准确数值的。总结今天的这一篇和前两篇文章是一个体系，我利用这三篇文章对当前的性能测试市场上的一些关键概念进行一些拆解。性能测试策略、性能测试场景、性能测试指标，这些关键的概念在性能测试中深深地影响着很多人。我们简化它的逻辑，只需要记住几个关键字就可以，其他的都不必使用。1.       性能测试概念中：性能指标、性能模型、性能场景、性能监控、性能实施、性能报告。        2.       性能场景中：基准场景、容量场景、稳定性场景、异常场景。        3.       性能指标中：TPS、RT。 （记住 T    的定义是根据不同的目标来的）        有了这些之后，一个清晰的性能框架就已经出现了。思考题你能思考一下，为什么 258 响应时间不合理吗？像"业务模型用 28原则"这些看似常识性的知识点，错在哪里呢？欢迎你在评论区写下你的思考，我会和你一起交流，也欢迎把这篇文章分享给你的朋友或者同事，一起交流一下。