axis (size of automata or N-gram storage) and a logarithmic 
scale on the X-axis (number of system calls). In comparing 
the two algorithms, the actual  Y-axis values are not impor- 
tant:  what  matters  for convergence  is  whether the curves 
flatten out quickly. 
For these experiments, we used training scripts that gen- 
erated  commands  to  exercise  the  servers.  The  training 
scripts  for  FTP  and  NFS  were  locally  developed,  while 
we  used  the  WebStone  benchmarking  suite  to  exercise 
HlTP server.  These  scripts generate a  random  sequence 
of mostly  valid commands, interspersed  with some invalid 
commands.  These  commands  involve files  of  sizes rang- 
ing from 500 bytes to 5MB. The distribution of these com- 
mands (and file sizes) is set to mimic the distributions ob- 
served under normal  operation. 
The  training  scripts  were  used  to  generate  larger  and 
larger  sequences  of  commands  in  successive  runs.  The 
server behavior observed during each  run  was  learnt  using 
the FSA and  iV-gram algorithms.  The initial  run  included 
very few commands, typically resulting in about a thousand 
system calls made by the server.  The final run was about 8 
million system calls. 
4.1.1  Discussion 
Rate of convergence  is an important factor that governs the 
amount of training time needed  to achieve  a given  level of 
false positives.  The slower the convergence rate, the longer 
the training time would need to be. 
For  all  three  servers,  the  FSA  algorithm  converged 
around a few  hundred  thousand system  calls, and  did  not 
learn any thing new even  when the number of system calls 
.x..,..*..*..x--- 
-x..x..x..).c-l-x 
' 
' 
'  I 
' 
_______ x . . - - - - * - - - ~ ~  
- 
~ 
..... x .... x 
' 
5000 
4500 
4000 
3500 
h g  3000 
h 5  2500 
; 2000 
1) 
- 
1500 
1000 t 
500 
n 
IO00 
4 :
:
,
:
,
:
:
:
,
:
 :
 i 
FSAmethod - i 
i 
{
i 
j .....  N-grm method  -----x----- 
..................  ...................... 
...... 
100000 
1 e+06 
. 
IO000 
System calls 
Figure 6. Convergence on HTTP. 
0.001 
0.000 I 
le-05 
1 e06 
IO00 
le+06 
10000 
Training Period (# of System calls) 
I00000 
I e+07 
Figure 7. False Positives on NFS Server. 
was increased  by  an order of magnitude beyond  this point. 
The N-gram algorithm converges much more slowly. 
Faster convergence  of  the FSA algorithm is due to two 
factors.  First, the FSA algorithm learns the branching and 
looping structures in  the  program.  As  illustrated  with  an 
example in Section 1.1, this factor enables program behav- 
iors to be  learnt  in  fewer  runs.  The second reason  is due 
to the fact that our algorithm does not preserve the order of 
system calls made from libraries.  For  instance, if a library 
function f is called by  the program from a location  L ,  the 
FSA would contain several edges from L  to itself, each  la- 
belled with one of the system calls made by f .  As a result, 
variations  in the order of  system calls made from libraries 
will not produce changes to the FSA. 
4.2. False Positives 
To determine false positives, we trained  the system with 
system call  traces  of different lengths, starting from about 
150 
0.001 
0.0001 
le-05 
le-06 
1000 
le+06 
10000 
Training Period (# of  System calls) 
100000 
le+07 
Figure 8. False Positives on FTP Server 
5K and  ending  at  about  8M system  calls.  After  training 
with  each  trace,  the  system  was  run  in  a  detection  mode 
against  another  system call  trace  consisting of  between  1 
and  10M system  calls.  This trace  was  produced  with the 
same ,program as used  for training, but with a slightly dif- 
ferent distribution of commands (and file sizes).  This was 
done to account for the fact that  things can  (and typically 
do) change between  the learning and detection  times.  The 
exact same system call traces were used to train and analyze 
the FSA and N-gram algorithms. 
For  the  FSA  algorithm,  each  occurrence  of  a  state  or 
edge that was not present in the FSA was treated as a false 
positive.  For  the  N-gram  algorithm,  each  occurrence  of 
a  new  N-gram  (which  has  not  been  learnt  during  train- 
ing) was counted as a false positive.  Clearly, more sophis- 
ticated  thresholding techniques  (such  as  the  leaky  bucket 
algorithm) could  be used  to detect  attacks  while  reducing 
false positives. However, there is no easy way to choose the 
parameters, such as the threshold value.  Moreover, the op- 
timal parameter values would likely be different for the two 
algorithms. Rather than spending our efforts in a search for 
thresholding techniques  optimized  for each  of  these  algo- 
rithms, we decided to use this simpler measure. 
â€˜Figures 7 and  8 show the  number  of  false positives re- 
ported by each algorithm.  It shows that the FSA algorithm 
uniformly produces fewer false positives than  the N-gram 
algorithm. The false positive rate of the FSA algorithm falls 
after a training period  corresponding to about 
below 
lo5 system calls.  The N-gram algorithm continues to pro- 
duce false positives at a higher rate (in the range of 
to 
even after training with over lo6 system calls. 
4.3.rRuntime and Space Overheads 
Figure 9 shows the runtime storage requirements for rep- 
resenting the behavior learnt by the FSA and N-gram algo- 
FTP 
J  HTTP 
NFS 
7.1  I 
4.8 
5.4 
2.4 
1.4 
1.2 
rithms for the three servers. The figure shows that both algo- 
rithms are economical  in terms of space usage.  FSA-based 
algorithm improves on  the space utilization  of the N-gram 
algorithm by about a factor of four. 
To  measure  runtime  overheads,  we  first  split the  over- 
head into two parts: (a) overhead due to execution of learn- 
ing  andlor  detection  code,  and  (b)  overhead  due  to  sys- 
tem  call  interception.  We  measured  the  two components 
independently.  The  overhead  due  to  execution  of  learn- 
ingldetection code was between  3% and 4%  for all  of  the 
three applications. The overhead for the N-gram based  al- 
gorithm was also about 3%. 
The overhead due to system call  interception is depen- 
dent on the mechanism  used for this purpose.  Techniques 
that  intercept system  calls within the kernel  introduce low 
overheads.  User-level  mechanisms for interception  of  sys- 
tem calls, such as the one used by  [5] and us, incur signifi- 
cantly higher overheads.  This is because  of  additional task 
switches required  (between the server process  and  another 
process that is intercepting its system calls) for each system 
call.  Moreover, every  access to server process  memory  by 
the monitoring process  (between  3  to 8 such  accesses  are 
made by  the FSA  learning  algorithm) incurs the overhead 
of a  system  call.  As  a  result,  the  overhead  due to system 
call interception in our implementation is as high as  100% 
to 250% in terms of CPU time.  An  s t r a c e - b a s e d  imple- 
mentation such as that used by Forrest et al in their N-gram 
learning algorithm, introduces overheads in the same range 
(100% to 250%). 
4.4. Results on Live HTTP Server 
In  this  section,  we  present  the  results  of  a  compar- 
ative  experiment  involving  a  live  web  server.  This  ex- 
periment  was  performed  on  http  server  of  the  Secure 
and  Reliable  Systems Laboratory  at  SUNY,  Stony  Brook 
(http://seclab.cs.sunysb.edu/). This site runs 
an apache web server, and experiences of the order of 3000 
hits a day.  The web site consists predominantly of passive 
HTML and image files. A minority of requests involve user 
authentication, forms and CGI scripts. 
One of the difficulties in using a live web server is that 
the experiment can no longer be conducted in a controlled 
setting.  The requests  processed  by  a live server can  vary 
widely from one day to the next, and thus, we cannot com- 
151 
8000 
....... 
0.01 
E 
mx E  0.001 
w 
Z  3000 
2000  I 
1000 
0 1  
. 
'  " "  ' 
100000 
1 
FSAmethod - 
___.__.______ 
i  N-grm method  ..... x..... 
..................................................... 
: 
le+06 
System calls 
Figure 10. Convergence on Live HTTP Server 
pare  false  alarms observed  on  one day  with  that observed 
on the next  day.  We therefore decided to run the N-gram 
and FSA algorithm side-by-side, so that they both make use 
of the exact same data. 
In our experiments, we trained each system for a partic- 
ular  number of  system calls,  and  then  ran  the  system  for 
an  extended  period of  time to compute the  false positives 
rate.  The training period  was gradually  increased, and the 
false positive rates were plotted as a function of the training 
period. 
One would  expect  that the false positive  rate would fall 
monotonically with  the  increases in  training period.  Ob- 
serve, however, that with a live web-server, this need not be 
true. It is possible that the web server received many differ- 
ent kinds of requests on the first day  of  training, when we 
used a training sequence of 20,000 system calls. On the sec- 
ond day, we may  use a training sequence of 40,000 system 
calls, but  it may  turn  out that the requests  received  on the 
second  day  were all very  similar. As a result, it is possible 
that more of the server behavior was learnt after the 20,000 
system calls seen  the  first  day,  as  compared  to  what  was 
learnt after 40,000 system calls the second day. If this were 
to happen,  it  will  lead  to  anomalies in  the  graphs,  which 
would make it very difficult to understand the convergence 
or false positive rates of these algorithms. To avoid such an 
anomaly, we used the following approach. The first 20,000 
system calls were used  to learn a (FSA or N-gram) model. 
A copy of this model  was made, and it was frozen.  Subse- 
quent system calls were learnt  by  the  original model  until 
we reached 40,000 system calls. At this point, another copy 
was made  and  frozen, while the original model  continued 
to learn subsequent system calls.  This process was contin- 
ued until we processed  about 1.5 million system calls. Each 
frozen  version of the model was used to perform false pos- 
itive  analysis on system calls made by  the server  after the 
z 
J 
le-05' 
10000 
. . . . . . . .  ' 
100000 
.
.
 . . . . "  
1 e+06 
.
.
le+07 
Training Period (# of System calls) 
Figure 11. False Positive Rate on Live H n P  
Server 
point of freezing. 
This approach meant that at any time, a system call made 
by the web server was processed by seven copies of the N- 