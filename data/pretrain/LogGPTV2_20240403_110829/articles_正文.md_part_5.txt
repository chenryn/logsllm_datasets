## 4.1 日志采集方式
对日志进行采集有两种思路：推与拉。推是指客户端（日志源设备或应用程序）主动将日志推送到日志分析系统；拉是指日志分析系统主动去客户端拉取日志。
主动拉取的日志采集方式局限性很大。日志分析系统需要对大批量数据进行处理，本身就要消耗较多的资源，主动拉取方式会增加更多不必要的资源消耗。而推送的日志采集方式可配置性更高，仅消耗各客户端的少量资源，与拉取的方式相比性能更优。
下面介绍几种常见的日志采集方式。
### 4.1.1 Agent采集
在客户端部署一个Agent，由Agent来进行客户端日志的主动推送。
Agent采集有很多优势。使用Agent可直接将日志数据发送到日志分析系统，也可将日志发送给其他日志处理组件，这些组件会对日志进行进一步处理并将处理后的日志发送给日志分析系统。
常见的开源日志采集Agent有很多，如Logstash、Filebeat等。
日志采集Agent的使用方式大同小异，首先在客户端安装Agent，然后对Agent进行配置，指明要采集的日志文件及日志发送位置即可。下面以Filebeat为例进行说明。
Filebeat安装：
（1）wget [https://artifacts.elastic.co/downloads/beats/filebeat/
filebeat-6.0.0-linux-x86_64.tar.gz](https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.0.0-linux-x86_64.tar.gz)。
（2）mkdir -p /opt/filebeat && tar zxf
filebeat-6.0.0-linux-x86_64.tar.gz -C/opt/filebeat-stripcomponent 1。
Filebeat配置：
（1）配置文件是filebeat.yml，其中可以配置多个目的地址。需要注意的是，它使用的格式是yaml。
（2）Filebeat配置示例如下。其中，要采集的日志文件为/apps/nginx/logs/access-
filebeat-test.log，将产生的日志发送到192.168.1.100:5044。
filebeat.prospectors:
enabled: true
-/apps/nginx/logs/access-filebeat-test.log
output.logstash:
hosts: \[\"192.168.1.100:5044\"\]
使用Agent的方式进行日志采集时，需要注意以下几个问题：
（1）尽量使用低权限用户账号启动，只对所采集的日志进行读取操作即可。
（2）尽量少用执行脚本功能。目前常见的Agent都具备执行脚本、命令的功能，但这种方式存在一定的风险，所以要尽量少用。
（3）尽量少占用系统资源。日志是一个旁路系统，在系统资源紧张的情况下，宁可暂停日志的采集，也不能让Agent采集占用过多的系统资源。
（4）尽量少依赖系统底层库。企业的服务器类型多种多样，各系统的底层库是不同的，如果过多依赖系统底层库，在大规模部署Agent时会出现极麻烦的系统适配问题。
### 4.1.2 Syslog
在Linux系统中，最常见的日志收集方式就是Syslog，它是Linux系统自带的服务。在大多数情况下，Syslog只用于系统日志。
常见的Syslog日志格式如下：
\ Dec 9 22:33:20 machine1 auditd\[1834\]: The audit daemon is
exiting.
 \ ------这是PRI部分，由尖括号包含的一个数字构成。
 Dec 9 22:33:20 machine1------这是Header部分，包含时间与主机名。
 auditd\[1834\]------这是Tag部分，由进程名和进程号组成。
 The audit daemon is exiting------这是Content部分。
在使用Syslog发送日志的时候需要注意以下几点：
（1）默认的发送方式是UDP方式，这种方式有丢失日志的风险。
（2）需要根据日志量调整发送的缓冲区，如果缓冲区满了，也会丢失日志。
（3）如果每条日志超过4KB，则必须使用TCP方式发送。
目前，大多数系统上配置的是Rsyslog而不是Syslog。Rsyslog类似于Syslog的升级版，二者差别不是很大。
现在有很多用户开始使用Syslog-ng。Syslog-ng是开源的，功能比Rsyslog更加强大，发送速率也提高了很多。不过，Syslog-ng与Rsyslog在配置上相差较大，不能与Syslog、Rsyslog混为一谈。
### 4.1.3 抓包
通过抓包来收集日志的做法并不常见，因为抓包之后需要解析，此过程需要消耗CPU的计算资源，况且解析的是日志内容，日志量本身就比较大。这种方式相比于常规的日志采集（如Agent日志采集）方式多了不必要的烦琐过程，所以很少使用。
抓包的优势体现在网络流量的捕捉上。目前常见的抓包做法是在交换机端口配置镜像流量，将此流量引流到一个专用的硬件设备上，此硬件设备专门用来解析流量。
### 4.1.4 接口采集
在需要获取程序内部信息的情况下，往往采用接口采集方式；或者日志并没有进行落地存储，只提供了一个接口来进行采集。
采用接口采集方式需要针对采集的内容进行定制化开发，因为各程序内部运行机制不同，采集方案也有所差异。
在使用接口采集方式时需要注意以下几点：
（1）频率不可过高。
（2）如果日志量很大，那么每次采集时不要获取最新的全量日志，否则会对程序本身的运行造成较大影响。
### 4.1.5 业务埋点采集
埋点是在应用特定的流程中注入代码，以便收集该流程的相关信息。例如，在某张图片中埋点，可以收集点击该图片的所有用户的信息，这样就能对当天点击该图片的用户进行分析，提取用户特征，以便开展接下来的营销规划。
埋点一般用于跟踪应用的使用状况，以便持续优化产品或为运营提供数据支撑。埋点收集的信息主要包括两个方面：用户访问情况和用户操作行为。
收集用户访问情况除统计用户的产品使用情况（如页面的访问次数、访客数）外，还有一个比较重要的作用是链路串联分析。链路串联分析是利用埋点数据，绘制用户操作在产品中经过的所有节点，这对产品的后期优化有很大的帮助，如通过优化页面上访客较少的区域来保持页面的访问热度。
分析用户操作行为是埋点的另一大功能，通过收集不同的用户对产品的使用行为，可根据不同性别、不同地区、不同年龄层的用户的喜好进行精准内容投放。
目前，在各大企业生产环境中，主流的埋点方式有以下两种。
第一种：自行进行代码注入。
第二种：使用第三方工具，如友盟、GrowingIO等。
这两种方式各有利弊，自行开发的技术壁垒较高，但数据安全性更有保障；使用第三方工具虽然面临数据安全性风险，但由于技术较为成熟，分析效果也往往更有保障。较为重视数据安全且分析场景比较复杂的企业，一般采用第一种方式；相比数据安全而言，更加注重数据价值挖掘及产品易用性的企业，一般采用第二种方式。
在进行埋点时一定要注意埋点的位置及埋点方式。埋点需要在与产品的运营分析人员做好沟通之后再进行设计开发，否则埋点之后获得的数据并不准确或者数据之间难以关联。如果埋点数据过多，还会造成数据流量过大，从而增加额外的开销。在手机端，上传过多的数据意味着更多的电量、流量及内存消耗，这会影响用户体验，引起用户反感。
### 4.1.6 Docker日志采集
随着容器技术的日渐流行，容器日志的采集成为互联网企业关注的重点之一。
Docker实现原理为"多进程+进程隔离"，Docker
Daemon父进程会启动一个容器子进程，父进程会收集此子进程产生的所有日志，但子进程下的子进程产生的日志是收集不到的。如果容器内只有一个进程，那么可以通过Docker
log driver来收集子进程的日志。
当前，使用Kubernetes管理容器已成趋势，导致出现了更复杂的问题。在启动一个业务进程时，会先启动一个Pod（容器管理进程），再启动相关容器，容器上一般运行有业务进程。由于Pod的存在，通过Docker
log driver将无法收集业务进程所产生的日志信息。
对于以上问题，目前有如下两种主流解决方式：
（1）通过调用Docker API来实现日志采集。
（2）将业务进程的日志文件挂载出来，然后通过采集文件的方式进行日志采集，但在这种情况下，日志轮转会成为一个问题。
通过Docker
API来获取日志数据是本书推荐的方式，因为可以通过API来监听容器的各类事件，然后使用一个收集日志的组件进行收集即可。目前使用较多的Docker
API工具有log-pilot、fluentd-pilot。二者较为类似，且都具有如下特点：
（1）使用一个单独的日志收集进程，可收集服务器上所有容器的日志，无须为每个容器启动一个日志收集进程。
（2）使用label声明要收集的日志文件的路径。
（3）支持将收集的日志输出成文件。
（4）支持工具本身错误日志的输出，即stdout。
如果没有使用上述两种工具，那么在采集Docker日志时需要注意如下问题：
（1）日志轮转。
（2）采集日志的进程不宜过多，尤其不能为每个容器单独启动一个日志收集进程，这会造成资源的大量占用。
（3）不可过多占用系统资源。
（4）如果日志收集进程与业务进程在同一容器内，那么需要注意日志收集进程的资源控制，避免因其占用太多资源而影响业务进程的正常运行。
## 4.2 日志采集常见问题
当某设备一天产生的日志量过多时，若将这些日志存放在同一个文件内，查询或读取日志时就会消耗较多的资源。为了避免这种情况，往往会设置对超过一定大小的日志文件进行切分。这样，该设备当天的日志就会被记录在几个不同的日志文件中。而当日志量较小时，日志文件可能会按照时间进行切分，如将每周的日志保存为一个日志文件。
由于不同的设备或应用程序产生日志的方式不同，日志记录、日志文件切分及命名的方式也不同。当对日志进行采集时，需要将不同种类的日志按照时间顺序逐条采集到日志分析系统中，这样才能保证后续日志处理流程的正常进行。
随着技术的发展，企业生产环境日益复杂，除了基础的日志文件顺序采集机制，日志采集还要解决诸多问题。本节将对日志采集中的一些常见问题进行说明。
### 4.2.1 事件合并
在大多数情况下，一个事件会被记录为一条日志，而这个事件通常在打印完程序运行的情况后就完成了它的使命。
但是，在某些情况下（如业务分析场景），人们需要的是一个业务上的事件，称之为"事务"。一个事务并不一定是单条日志，通常将整个业务流程（包括业务开始、业务处理、业务结束）视为一个事务。
因为目前的程序都是并发处理的，所以在同一时间会产生很多事件，而这些事件未必是同一个事务产生的。因此，需要将一个事务中产生的多个事件进行合并，形成一个事务日志后再进行发送。
这样做能带来如下好处：
（1）在Agent发送端进行事件合并，可以在分析数据时省去很多不必要的日志处理过程。
（2）将一个业务的所有事件归并成一个事务，更方便计算事务内的各指标数据。
（3）能够更加直观地看出一个业务的完成过程，对业务运维人员更加友好。
但是，这种做法也有一些问题，具体如下：
（1）单条日志过大，后端处理系统压力较大。
（2）Agent发送日志时，需要等待一个事务发送完才能发送下一条日志，所以Agent发送效率会降低，Agent对系统资源的消耗也会增加。
（3）因为需要从繁杂的事件中找出同一个事务的所有事件进行合并，所以需要一个可串联的标识，此标识在一个事务中从始至终都存在，并且不能与其他事务中的标识重复。这对日志规范性有一定的要求。
上述最后一条往往很难实现。因为一个业务系统的不同模块由不同的小组开发，如果开发时没有统一日志的输出规范，业务系统运行期间输出的日志就会比较杂乱，这会对后面的分析造成很大的影响，而且后期进行日志改造也会有很大困难。因为业务系统的运行会经历一段很长的时间，当业务系统庞杂到一定程度，不得不进行日志改造时，原始的模块开发和维护人员可能早已离职，或者因年代久远而忘记了日志生成逻辑。因此，在开发时做好日志输出规范，对于日志分析而言极为重要。
### 4.2.2 高并发日志采集
正常情况下，用户只需要配置一个日志采集目录、要采集的日志文件名称及相应的匹配规则，接下来就是如何发现新创建的日志文件，目前常见的做法是定时轮询要采集的目录下的内容。而当短时间内日志量暴增时，问题就出现了。
想象一下：当Agent正在采集access.log的时候，日志发生了轮转，access.log变成了access.log.1，但Agent并没有采集完access.log的内容，而此时日志已经轮转完毕，那么access.log中还没有采集完成的内容就会被丢弃。
为了避免这种问题，可以采集日志轮转完毕之后的文件，这样能够保证日志采集没有遗漏。但这样做的弊端也很明显------因为要采集access.log.1，Agent就没办法及时采集最新的日志（当前的access.log），这样采集就会有延迟。
在高并发环境下进行日志采集，通常需要做些取舍。如果不考虑数据入库延迟，可以采用采集轮转后的日志的方式；如果考虑数据入库延迟，那可能需要对日志的输出进行改造。
### 4.2.3 深层次目录采集
深层次目录采集往往和大量小文件一起出现。深层次目录采集通常是由于开发人员早期开发不规范造成的。以某金融公司为例，该公司每天、每小时都创建一个目录，之后针对不同的应用、不同的用户和不同的操作分别创建相应的目录，目录结构如下：
Day \> Hour \> Apps \> User \> Operation
由于Agent需要定时轮询要采集的目录下的内容，以发现新创建的日志文件，所以深层次目录会导致Agent轮询一个文件时遍历很多层的目录，非常消耗性能。这时，Agent的瓶颈往往在CPU上，因为每次扫描需要遍历整个目录。
对于这种问题，一般通过软链接的方式解决，即将当前目录下的文件定时软链接到一个浅目录中，让Agent只采集这个浅目录下的内容，这样会大大减少Agent的CPU消耗，也能提高发送效率。
### 4.2.4 大量小文件日志采集
大量小文件日志采集和深层次目录采集遇到的问题类似，都会消耗大量资源。
大量小文件日志采集之所以消耗大量资源，也与Agent查找文件的逻辑相关。由4.2.2节可以知道，Agent通过配置正则表达式等方式来统一采集某类日志。
想象一下Agent采集日志的流程：配置好采集哪类日志之后，启动Agent，Agent匹配到日志后开始进行日志采集；在采集的同时，应用程序会持续产生新的日志文件，Agent需要采集新产生的文件，所以会定时轮询目录下的文件。
此时问题来了，如果轮询太过频繁，会导致CPU负担过高，使资源大量浪费在查找文件上；如果轮询过慢，会导致采集不够实时，甚至会导致日志被遗漏。
可以使用Linux内核的Inotify进行采集，但Inotify也存在以下一些问题：
（1）Inotify是Linux内核的一个模块，它是在2.6.32版本之后的Linux内核中才有的，若采集使用的Linux系统版本过低，则无法使用Inotify。
（2）Inotify监控的文件数量是有限的，所以在采集大量小文件时也会出现问题。
（3）利用Inotify采集大量小文件时，如果文件数量过多，会导致系统的文件描述符耗尽，严重时会导致整个服务器上的进程不可用。