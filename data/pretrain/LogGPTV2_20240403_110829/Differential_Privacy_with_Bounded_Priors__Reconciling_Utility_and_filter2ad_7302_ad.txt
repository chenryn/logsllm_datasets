50
200
Table 1: Contingency table of one SNP, for a GWAS with
100 cases and 100 controls.
The interested reader may ﬁnd additional information on
genomics as well as on genome privacy and security research
at the community website2 maintained by our group.
4.2 Homer’s Attack and Adversarial Model
The ongoing research on applying diﬀerential privacy to
GWAS has been primarily motivated by an attack proposed
by Homer et al. [9]. In this attack, the adversary is assumed
to have some knowledge about an entity’s genetic proﬁle,
and wants to determine if this entity belongs to the case
group or not. Towards this end, the adversary measures
the distance between the entity’s SNP values and the allele
frequencies reported for the case group, or some reference
population. It has been shown that other aggregate statis-
tics, such as p-values or SNP correlation scores, could be
used to construct similar or even stronger attacks [20].
Unsurprisingly, privacy mechanisms based on DP have
been proposed to counter these attacks [10, 19, 22], as they
guarantee that an entity’s presence in the dataset will not
signiﬁcantly aﬀect the output statistics. However, the adver-
sarial model considered here is quite diﬀerent from the one
DP protects against. Indeed, all these attacks assume some
prior knowledge about an entity’s genomic proﬁle, but not
about the entity’s presence or absence from the case group.
Actually, the adversary makes no assumptions on the pres-
ence or absence of any entity from the case group, and it is
absolutely not assumed to have complete knowledge about
the data of all but one of the entities. This attack thus ap-
propriately ﬁts into our relaxed adversarial setting, where we
consider an adversary with bounded prior knowledge. From
the results of Section 3, we know that protecting member-
ship disclosure against such adversaries can be achieved with
much weaker levels of DP.
2 cases and N
In the following, we consider a genome-wide association
study with N patients. It is generally recommended ([18])
that the number of cases and controls be similar. We thus
focus on studies with N
2 controls. The cases
suﬀer from a particular genetic disease, and the goal of the
study is to ﬁnd associated SNPs by releasing some aggregate
statistics over all participants. We assume that the adver-
sary knows the value N (which is usually reported by the
study). In the adversarial model considered by DP, we would
assume the adversary to have complete knowledge about all
but one of the entities in the case group. We will consider a
weaker setting here, which includes the adversarial model of
Homer’s attack [9]. The adversary is assumed to know the
2https://genomeprivacy.org
identity of the study participants, and possibly the disease
status of some of them, but has no additional information
on whether other entities were part of the case or control
group. In regard to the attacks discussed previously, we will
limit the adversary’s capability of asserting the membership
of an entity to the case group, and thus his disease status.
Suppose the adversary already breached the privacy of a
small number m1 of the cases and m2 of the controls. In this
case, the adversary’s prior belief about some other entity’s
presence in the case group is N/2−m1
. In the following,
N−m1−m2
we assume that m1 ≈ m2 and thus that the adversary’s
prior can be modeled by the family D0.5
B . As we discussed in
Section 3.4, our mechanisms will still provide some smaller
level of security against adversaries with more general priors.
More generally, if we have N1 cases and N2 controls, we
can consider a similar adversarial model with a prior belief
of
4.3 A Simple Counting Query
that an entity belongs to the case group.
N1+N2
N1
We ﬁrst consider a simple counting query. While the fol-
lowing example has little practical signiﬁcance in a GWAS,
it is an interesting and simple toy-example illustrating the
usability and power of the model we derived in Section 3.
Let A and A(cid:48) be mechanisms computing the number of
patients in the case group whose SNP value is 0. Under
bounded-DP, the sensitivity of this query is 1. Suppose we
want to guarantee (γ, DB)-PMP for A, and (γ, D0.5
B )-PMP
for A(cid:48). In the ﬁrst case, this is equivalent to satisfying -DP,
for  = ln(γ). In the bounded adversarial model, we have
shown in Theorem 2 that it is suﬃcient to satisfy (cid:48)-DP, for
an (cid:48) > ln(γ).
To satisfy DP, and therefore PMP, we add Laplacian noise
to the true count value. We deﬁne the utility of our mech-
anism as the precision of the count, after application of the
privacy mechanism. More formally, if the true count is C
and the noisy output count is ˆC, then we are interested in
the expected error E[| ˆC − C|]. When satisfying -DP, we
have that ˆC = C + µ, where µ is drawn from a Laplace
distribution with mean 0 and scale −1. Thus, we have that
(13)
E[| ˆC − C|] = E[|µ|] = 
−1 .
As a concrete example of the diﬀerences in utility be-
tween A and A(cid:48), we vary the PMP parameter γ and plot
the expected error of the count in Figure 4. As we can see,
A(cid:48) gives signiﬁcantly more precise outputs than A, when
the two mechanisms provide the same positive membership-
privacy guarantees in their respective adversarial settings.
Note that for an adversary with prior D0.5
B , and PMP param-
eter λ = 2, seeing the output of A(cid:48) yields a posterior belief
of at most 3
4 , that a particular entity is in the case group.
This simple example shows that by focusing on a bounded
adversarial model, protecting against membership disclosure
can be achieved while retaining signiﬁcantly higher utility,
compared to the original adversarial setting.
4.4 Releasing Causative SNPs
A typical GWAS aims at uncovering SNPs that are associ-
ated with some disease. A standard and simple method con-
sists in computing the χ2-statistics of the contingency table
of each SNP. Assume that the genomes of people participat-
ing in the GWAS are uncorrelated (a necessary assumption
for χ2-statistics). For a SNP unrelated to the disease, we
expect any SNP value to appear in the case group as often
function in the exponential mechanism. Algorithm 1 is -
diﬀerentially private [3, 22]. Note that as the number of
output SNPs M grows large, the sampling probabilities tend
to be uniform. Thus, it is not necessarily beneﬁcial to output
more SNPs, in the hope that the SNPs with the highest true
statistics will be output.
Algorithm 1 Diﬀerentially private release of associated
SNPs, using the exponential mechanism [22].
Input: The privacy budget , the sensitivity s of the χ2-
statistic, the number of SNPs M to release.
Output: M SNPs
1: For i ∈ {1, . . . , M(cid:48)}, compute the score qi as the χ2-
statistic of the ith SNP.
has probability proportional to exp(cid:0) ·qi
(cid:1) .
2: Sample M SNPs (without replacement), where SNP i
2·M·s
Johnson and Shmatikov [10] propose a general framework
that performs multiple queries used in typical GWAS and
guarantees diﬀerential privacy. They use the exponential
mechanism with a speciﬁc distance score function. We will
focus on their LocSig mechanism that outputs M signiﬁcant
SNPs similarly to Algorithm 1. The sole diﬀerence is that
they use a diﬀerent score function than the χ2-statistic.
Let the distance-to-signiﬁcance of a contingency table be
deﬁned as the minimal number of SNP values to be modiﬁed,
in order to obtain a contingency table with a p-value or
χ2-statistic deemed as signiﬁcant (beyond some pre-deﬁned
threshold). Their algorithm for outputting M signiﬁcant
SNPs is then the same as Algorithm 1, where the scores
qi are replaced by the distance-to-signiﬁcance score, whose
sensitivity s can easily be seen to be 1.
As noted by Yu et al. [22], computing these distance scores
exactly can be a daunting task for 3 × 2 contingency tables.
They suggest instead to approximate the true distance-to-
signiﬁcance by a greedy approach that only considers edits
introducing a maximal change in the χ2-statistic or p-value.
In our experiments, we follow the same approach.
Both of the mechanisms we discussed are subject to a stan-
dard tradeoﬀ between privacy, utility and dataset size. We
illustrate this tradeoﬀ for Algorithm 1 (see [19] and [22] for
details). The tradeoﬀ between privacy and utility is straight-
forward as the sampling probabilities depend on . For the
dependency on the dataset size, note that by deﬁnition, an
unassociated SNP is expected to have a χ2-statistic of 0, re-
gardless of N (this is the null hypothesis). However, if the
SNP is correlated to the disease status, we can verify that
the value of the χ2-statistic grows linearly with N . Thus,
as N grows, the gap between the χ2-statistics of associated
and unassociated SNPs grows as well. Nevertheless, the sen-
sitivity ∆χ2 remains bounded above by 4. Combining both
observations, we see that the larger N gets, the less probable
it is that the algorithm outputs unassociated SNPs. Thus
Algorithm 1 achieves high utility for very large datasets.
We show that by considering a weaker but practically sig-
niﬁcant adversarial model, we require much less patient data
in order to achieve high medical utility, thus rendering such
privacy protecting mechanisms more attractive and appli-
cable for medical research. Spencer et al. [18] note that a
GWAS with 2000 cases and controls necessitates a budget
of about $2,000,000 for standard genotyping chips. Obtain-
ing an acceptable utility-privacy tradeoﬀ even for reasonably
large studies is thus an interesting goal.
Figure 4: Expected error of the counting query, for privacy
mechanisms A and A(cid:48) satisfying (λ, DB)-PMP and (λ, D0.5
B )-
PMP respectively.
as in the control group. The χ2-statistic measures how much
the true values diverge from this expected null hypothe-
sis. The higher the statistic is, the more likely it is that the
SNP and disease status are correlated. Equivalently, we can
compute the p-values that correspond to the χ2-statistics.
Consider the following generic contingency table for a
SNP, in a GWAS with N
2 controls. The table
should be read as follows. There are α cases with SNP value
0 and β cases with value 1. The total number of patients
with SNP values 0 and 1 are, respectively, m and n.
2 cases and N
SNP value
Cases
0
1
2
α
β
N
2 − α − β
Controls
m − α
n − β
N
2 − m + α − n + β
In a typical GWAS, only SNPs with a MAF larger than
some threshold (e.g. 0.05) are considered. Thus, it is reason-
able to assume that the margins of the contingency table
are positive (m > 0, n > 0, N − m− n > 0). Uhler et al. [19]
show that the χ2-statistic of a SNP is then given by
χ2 =
(2α − m)2
m
(2β − n)2
n
(2α − m + 2β − n)2
N − m − n
.
+
+
Existing Techniques.
Methods for the diﬀerentially-private release of SNPs with
high χ2-statistics have been studied by Uhler et al. [19],
Johnson and Shmatikov [10], and more recently Yu et al.
[22]. When the number of cases and controls are equal,
the sensitivity of the χ2-statistic is
4N
N +2 [19]. For the gen-
eral case where the size of the case and control groups are
not necessarily equal, the χ2-statistic and its sensitivity are
given in [22]. We consider two exponential mechanisms for
outputting M SNPs with high χ2-statistics and satisfying
DP. As noted in [10], the value M of signiﬁcant SNPs (with
a χ2 score above a given threshold) can also be computed in
a diﬀerentially private manner. In the following, we assume
the total number of SNPs in the study to be M(cid:48).
Yu et al. propose a very simple algorithm (Algorithm 1)
that directly uses the χ2-statistics of the SNPs as the score
1.11.21.31.41.51.61.71.81.92024681012λE[|ˆC−C|]  AA′(a) γ = 1.3
(b) γ = 1.5
(a) γ = 1.3
(b) γ = 1.5
Figure 5: Utility of mechanisms A and A(cid:48), when outputting
2 SNPs using Algorithm 1 from [22].
Figure 6: Utility of mechanisms A and A(cid:48), when outputting
2 SNPs using the LocSig mechanism from [10].
Results.
We evaluate diﬀerent privacy mechanisms on the GWAS
simulations from [19], obtained from the Hap-Sample simu-
lator [21]. The studies consist of 8532 SNPs per participant,
typed on chromosomes 9 and 13 using the AFFY 100k ar-
ray. There are two causative SNPs with an additive eﬀect.
We consider mechanisms that use either Algorithm 1 or the
LocSig mechanism to output 2 SNPs. As a measure of util-
ity, we use the probability (averaged over 1000 runs) that a
mechanism outputs either 1 or both of the causative SNPs.
We do not compare the mechanisms from Yu et al. and
Johnson and Shmatikov directly (see [22] for a full compar-
ison). Instead, we evaluate how the utility of these mecha-
nisms behave, for a bounded adversarial model close to those
models used in the attacks we described in Section 4.2. To
this end, we ﬁx a level γ of positive membership-privacy and
consider mechanisms that protect against arbitrary priors in
DB (equivalent to (ln γ)-DP) or bounded priors in D0.5
B (cor-
responds to a weaker level of DP).
We begin with two privacy mechanisms A and A(cid:48) that
use Algorithm 1 to release 2 SNPs and satisfy PMP un-
B , respectively. For datasets of sizes N ∈
der DB and D0.5
{5000, 7500, 10000} and PMP parameters γ ∈ {1.3, 1.5}, we
compare the utility of A and A(cid:48), and display the results in
Figure 5. We see that for a ﬁxed level of PMP, the bounded
adversarial model leads to signiﬁcantly higher utility. Con-
sider the results for γ = 1.5. Mechanism A, which satisﬁes
(1.5, DB)-PMP, requires at least 10000 patients to achieve
signiﬁcant utility. Even in such a large study, the mechanism
fails to output any of the causative SNPs in about 25% of
the experiments. For A(cid:48), which satisﬁes (1.5, D0.5
B )-PMP, we
achieve a better utility with only 7500 patients, and quasi-
perfect utility for 10000 patients. By focusing on a more
reasonable adversarial threat, we thus achieve a good trade-
oﬀ between privacy and utility, for much smaller datasets.