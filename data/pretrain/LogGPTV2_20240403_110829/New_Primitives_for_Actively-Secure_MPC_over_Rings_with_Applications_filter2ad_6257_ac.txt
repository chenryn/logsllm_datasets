opening this result, truncating the lower k − 1 bits (which
are all zero) and removing the mask. For details, see the
protocol in Fig. 5.
Note that the main online cost is two openings of k-bit
ring elements, and the ΠBitLT subprotocol (Sec. IX-D) on
length k − 1 inputs, which has 2k − 4 bit multiplications
in log(k − 1) rounds. This gives a total communication
complexity of 6k− 8 bits per party in log(k− 1) + 2 rounds.
Protocol ΠMSB
[
i=0 ri2i].
(cid:2)k−1
(cid:2)k−1
INPUT: Shared value [a].
i=0 ai2i ∈ Z2k.
OUTPUT: Shared value [ak−1], where a =
1) Call [b], [r0], . . . , [rk−1] ← ΠRandBit() and compute [r] =
(cid:5)] ←(cid:2)k−2
2) Let c ← Open([a] + [r]).
3) Compute c
4) Call [r0]2, . . . , [rk−2]2 ← ΠA2B([r0], . . . , [rk−2]).
5) Let [u]2 ← ΠBitLT(c
(cid:5)
6) Call [u] ← ΠB2A([u]2).b
(cid:5)] + 2k−1[u] and [d] ← [a] − [a
(cid:5)] ← c
(cid:5) − [r
(cid:5)].
7) Compute [a
8) Let e ← Open([d] + 2k−1[b]), and let ek−1 be the most
9) Output ek−1 + [b] − 2ek−1[b].
(cid:5) = c mod 2k−1 and [r
, [r0]2, . . . , [rk−2]2).a
signiﬁcant bit of e.
i=0 2i[ri].
a When one of the inputs is public, ΠBitLT operates in the same way
as if both inputs were shared but using the bits of the public input in
the clear.
b We can avoid the share-conversion by noticing that 2k−1[u]2 =
[2k−1u].
Figure 5: Protocol for extracting most signiﬁcant bit
The idea of extracting most signiﬁcant bits by ﬁrst sub-
tracting the lower bits and then truncating is already present
in [21], as well as the idea of extracting lower bits (obtaining
(cid:18)(cid:18)(cid:17)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:58 UTC from IEEE Xplore.  Restrictions apply. 
a mod 2k−1 in our case) using bit-decomposed masks. The
truncation step is trivial when working in a ﬁeld, but does
not extend to Z2k, which is why at the end of the protocol
we mask by the random bit [b] and shift down the result [d].
(cid:2)k−1
Proposition IV.2 (Informal). Protocol ΠMSB correctly com-
putes [ak−1] from [a], where a =
i=0 ai2i. Moreover, it
does not reveal any information about a.
C. Comparison of Signed Integers
In many applications it makes sense to assume that the
underlying data are signed, meaning that it can be negative,
positive, or zero. We can represent
this using integers
modulo 2k, by taking the class representatives in the interval
[−2k−1, 2k−1). For computational purposes this is the same
as our set Z2k of unsigned values, but we can add some
additional interpretation to the numbers in [−2k−1, 2k−1)
(namely, the sign) that is useful in many applications.
(cid:2)k−2
Every integer in a ∈ [−2k−1, 2k−1) can be written as
a = −ak−12k−1 +
i=0 ai2i (this is the so-called two’s
(cid:2)k−1
complement representation), and its corresponding represen-
i=0 ai2i. It is easy to see that
tative in Z2k is a mod 2k =
in this setting, a ∈ [−2k−1, 2k−1) is negative if and only if
ak−1 = 1, so, as in [21], we deﬁne the comparison-with-zero
operator for a shared value as ΠLTZ([a]) := ΠMSB([a]).
Now, consider a, b ∈ [−2k−2, 2k−2). Clearly, −2k−1 ≤
a − b < 2k−1 so we can determine u = a
?
< b (comparison
as signed integers) by u = ΠLTZ([a] − [b]). Therefore, as
done in [21], we deﬁne comparison of two shared values as
ΠLT([a], [b]) = ΠLTZ([a] − [b]).
Finally, notice that we restricted a, b ∈ [−2k−2, 2k−2).
This is because if a, b ∈ [−2k−1, 2k−1), then correctness
may not hold if a− b overﬂows. For instance, if a = −2k−1
(cid:2)k−2
and b = 1, then a < b but the most signiﬁcant bit of
(a − b) mod 2k =
i=0 2i is 0, so, in other words, a − b
is treated as positive even though it is not. If numbers
in [−2k−1, 2k−1) must be compared, this can be done at
the cost of roughly three calls to ΠMSB. Intuitively, this is
because subtracting b−a and comparing against zero is only
guaranteed to work if a and b have the same sign and, if
?
< b.
this is not the case, the sign of a dictates the value of a
Therefore, besides extracting the most signiﬁcant bit of the
difference b−a, we also check if a and b have the same sign
and choose the right output depending on the case. This is
done by extracting the most signiﬁcant bits of both a and b,
which incurs in the two additional calls to ΠMSB.
The protocol works, in detail, as follows.
• Let [ak−1] ← ΠMSB([a]) and [bk−1] ← ΠMSB([b]).
• Compute [h] ← [ak−1] + [bk−1] − 2[ak−1][bk−1].
• Let [e] ← ΠMSB([a] − [b]).
• Output [d] ← [h] · [ak−1] + [1 − h] · [e].
We argue that this protocol produces the right output. The
main observation is that if a and b have the same sign then
extracting the most signiﬁcant bit of a − b will yield the
?
< b. Now, if a and b have different sign then
correct bit a
the result is simply the most signiﬁcant bit of a. Finally,
observe that e = ak−1⊕bk−1 and that a and b have the same
most signiﬁcant bit if and only if e = 0. This concludes the
argument.
?
We notice that computing a
D. Equality Test
= 0, where a ∈
[−2k−1, 2k−1 − 1] is sufﬁcient for realizing equality testing.
We achieve this by executing Protocol 3.7 in [21], but
with one simple change. Instead of computing the OR-
subprotocol at the end on arithmetic shares representing
bits, we ﬁrst convert these to binary shares using ΠA2Bin
Fig. 2 and then execute the OR-subprotocol. This improves
efﬁciency signiﬁcantly.
V. APPLICATIONS
In this section we discuss some applications leveraging
our efﬁcient comparison protocol.
A. Decision Trees
We consider the machine-learning application of decision
trees which is used for classiﬁcation. A decision tree is a
function T : R
n → Zq, where n is called the dimension of
the feature space and q is the amount of possible output
categories. The input x = (x1, . . . , xn) ∈ R
n to T is
called the feature vector. The function T is implemented
as a binary tree with m internal nodes, where each internal
node vj for j ∈ [1, m] has associated a Boolean function
< tj where ιj ∈ Zn is an
fj : R
index into the feature vector x and tj ∈ R is a threshold.
≤ tj, and 0
Thus fj(x) evaluates to 1 if and only if xιj
otherwise. Each leaf node of the tree is associated with an
output value z ∈ Zq. Now to evaluate T (x) = z, start at the
root node and evaluate f1(x). If f1(x) = 0 then proceed
to evaluate the left child, if instead f1(x) = 1 then proceed
to evaluate the right child. Continue in this manner until
reaching a leaf and return the value z of this leaf.
n → {0, 1} s.t. fj(x) = xιj
?
For simplicity, and since we want to hide the structure of
the tree, we assume that it is complete. We note that this is
always possible as dummy nodes can be inserted as needed,
which always evaluate to 0.
We index nodes starting with 1 for the root node and
then indexing by reading each layer top to bottom and left
to right; thus if vj is an internal node then v2j is the left
child of vj and v2j+1 is the right child. We say the depth
is the amount of nodes in the path from the root to, and
including, the leaf; deﬁning the root to be level 0. Thus the
tree will have m = 2d−1 − 1 internal nodes and 2d leaves.
Note that the leaves will have index 2d to 2d+1.
Concretely we deﬁne T as a tuple of values (t, v, z),
where t ∈ R
2d
q . That is, t =
(t1, . . . , tm) and v = (v1, . . . , vm) are lists of cardinality
m. We view as ordered such that the j’th entry describe the
n and z ∈ Z
m, v ∈ Z
m
(cid:18)(cid:18)(cid:17)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:58 UTC from IEEE Xplore.  Restrictions apply. 
j’th internal node in the tree. That is, each internal node vj
?
will compute the value fj = xvj
< tj. z = (z1, . . . , v2d ) is
an ordered list of integers, each representing an output of a
leaf, thus each leaf node vj (i.e. with j ∈]m, m + 2d]) will
output the value fj = zj−2d.
Furthermore we consider the two-party setting where
one party, called the client holds the feature vector x =
(x1, . . . , xn) ∈ R
n. The other party, called the server holds
the decision tree T . The parties then wish to compute
T (x) = z where the client learns z and the server learns
nothing. We express this functionality formally in Fig. 11
(Sec. X).
To evaluate a decision tree privately we work over a ﬁnite
set of integers Z2k instead of the real numbers. We convert
a model based on real numbers by simply multiplying every
decimal number in the model by a set constant and then
rounding to nearest integer. This of course causes loss in
accuracy, however, this rarely causes a problem and for real
data the constant does not necessarily have to be large to
avoid losing classiﬁcation accuracy [29]. We furthermore
note that this conversion still allows us to work with negative
integers by considering the positive integers up to 2k as a
value in two’s complement, as in Section refsec:comparison,
thus representing the positive integers up to 2k−1 − 1
and following these, the negative integers from −2k−1 to
−1. Because our computations will take place over a ring
this representation will ensure arithmetic operations act as
expected (assuming no over- and underﬂow).
1) An actively secure protocol: Our protocol takes depar-
ture in the work by De Cock et al.
[28] which presents
a protocol for evaluating decision trees based on secret
sharing. We picked this protocol since it works in the
arithmetic black box setting, whereas other approaches such
as the one by Wu et al. [38] or Joye and Sahali [39] requires
homomorphic encryption. Still, the scheme by De Cock et
al. is only secure in the semi-honest setting. We show how
to make it actively secure by adding cheap extra step.
The overall idea of their scheme is to ﬁrst pick each
relevant value from the input feature vector x for each node
j, i.e. xvj . This is done by having the party holding the
tree, P1, input an n-bit vector for each of the m nodes. This
bitvector will contain a single 1-bit in the position of the
feature to use. That is, we associate a bit cj,i ∈ {0, 1} with
each feature for each node (i.e. for all i ∈ [1, n], j ∈ [1, m])
i∈[1,n] cj,i = 1 and cj,vj = 1. With these indicator
s.t.
bits we can arithmetically compute the attribute to use in
the j’th node as
i∈[1,n] cj,i · xi.
(cid:2)
(cid:2)
(cid:2)
If the tree holder is actively corrupted then it will be able
i∈[1,n] cj,i (cid:9)= 1. This is a problem
to input value cj,i s.t.
since this would allow a linear combination of (x1, . . . , xn)
to be used for the comparison in each node of the tree. This
would make it hard to write a simulation proof since the
simulator would not know x. To ﬁx this issue we propose a
(cid:2)
solution that consists of enforcing that cj,i is a bit, then open
i∈[1,n] cj,i for j ∈ [1, m] and ensure that this is always 1.
It is easy to see that this check is sufﬁcient and clearly does
not leak any information (as it is public knowledge that the
opened value is supposed to be 1). Furthermore, it is also
easy to enforce that cj,i is a bit, even if the whole ring
Z2k is allowed as input: simply compute and open the value
(1− cj,i)· cj,i and ensure that it is 0. Again it can be argued
that this is sufﬁcient as cj,i equal to 0 or 1 are the only
values for which (1 − cj,i) · cj,i = 0 when working over
Z2k.
Adding this check allows us to compute the correct at-
tributes for each node with active security. Via the attributes
the output of the comparison in each node can be computed
by the comparison subprotocol; the output is a bit indicating
whether to go left (0) or right (1) down the tree. To evaluate
the tree obliviously it is not possible to simply follow the
correct path from the root to a leaf, as this would leak too
much. Thus, we must visit every node in the evaluation.
This is done by computing a bit for each leaf, which is the
product of the output of the comparison for all the nodes on
the path to the root.1 There will be only one leaf for which
this bit is 1. This is the leaf whose value is the ﬁnal output of
the decision tree evaluation. Since the evaluator is oblivious
to which leaf this is, we multiply the bit of each leaf with
the leaf’s value and sum this for all leaves. Because the bit
for every leaf, other than the correct one is 0, the output
of this computation gives the correct result. This means that
the comparisons can be done once; for each internal node of
the tree we can then compute if it is part of the root-to-leaf
path that is the result of the decision tree evaluation. Still,
this requires O(d) rounds of communication as all nodes on
a given layer are dependent on a partial result of the nodes
higher up the tree.
We can compute the partial values of all nodes in the
tree using a “reduction” approach by exploiting the fact that
multiplication is associative, i.e. that x1 · x2 · x3 · x4 can be
computed as (x1·x2)·(x3·x4), rather than ((x1·x2)·x3)·x4.
Thus we can compute the product of d values with d − 1
multiplications and log(d − 1) sequential rounds. For each
node in every second layer from the root to the leaves, we
compute the product of the output of its comparison with
the output of the comparison of its parent (negated if it is a
left node). Next we use these results to compute a product
for every four layers, by multiplying the result of every node
with the result of its grandparent (negated if its parent is a
left child). We continue until we have computed a product
between every layer in the tree.
Computing these products dominates protocol round cost,
since both selecting the feature for all nodes, along with
computing the comparison can be done in constant rounds
1The output of the comparison is negated for each node if it is a left
child.
(cid:18)(cid:18)(cid:17)(cid:26)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:58 UTC from IEEE Xplore.  Restrictions apply. 
(assuming we use the constant round comparison protocol).
We express our actively secure protocol in Fig. 12 (Sec. X).
We note that De Cock et al. have implemented their
protocol using boolean values, whereas we use arithmetic
values. Using boolean values and replacing multiplication
and addition with component-wise AND and XOR respec-
tively would unfortunately not directly work on our ﬁx to
get active security. This is because XOR’ing two 1’s would
give 0, so an actively corrupted model holder would be able
to have the classiﬁcation happen using XOR combinations
of the different values of the inputting party’s feature vector.
Even more importantly, as the feature values are not binary
but rather elements from Z2k, using a binary protocol would
require k multiplications (AND gates) to compute cj,i·xi for
i ∈ [m] and j ∈ [n], needed for each node in the tree. Even
for relatively small values of k, like 32, this would probably
not be faster using a binary protocol. In particular, using the
optimized TinyOT protocol [36] this would be slower as the
construction of a TinyOT triple is only about 12x faster than
a SPDZ2k triple.
B. Support Vector Machines (SVMs)
R
We consider the machine-learning application of Support
Vector Machines (SVMs), which is a type of supervised
learning model used for classiﬁcation. In its simple form
it is used as a binary classiﬁer, but it can easily be extended
to classify data into any ﬁnite set of categories. More
speciﬁcally an SVM is a function S : R
n → Zq, where
n is the dimension of the feature space and q the amount
of categories (each represented by a non-negative integer).
Similarly to the decision trees, the input x = (x1, . . . , xn) ∈
n to the function S is called the feature vector. The