25th USENIX Security Symposium  27
9
Direction(v) =0 → 1). Copy p’s PT to P1. Then
deallocate all mappings to P1 and make it read-only.
• Step 3: Copy p’s PMD to the physical page (denoted
Pv) that contains the vulnerable bit v. Then change
the PDE (on Pv) that contains v to point to P1. Then
deallocate all mappings to Pv and make it read-only.
• Step 4: Issue hypercalls to update p’s corresponding
PUD entry with Pv’s machine address, so that Pv will
become the new PMD. The Hypervisor will check the
validity of the new PMD and all page tables it points
to. Although p’s PDE has been changed to point to
P1, because P1 is exact the same as p’s original PT,
this step will also pass the security check by the hy-
pervisor.
• Step 5: Construct fake PTEs on P2 so that they point
to physical pages outside the attacker VM. These are
the target memory pages that the attacker would like
to access.
• Step 6: Conduct row hammer attacks on the two
neighboring rows of the vulnerable bit v, until bit ﬂip
is observed. p’s PDE will be ﬂipped so that it will
point to P2 instead of P1.
• Step 7: Now the attacker can access p and the other
511 virtual pages controlled by the same page table
P2 to access physical memory outside his own VM.
The attacker can also modify the PTEs in P2 without
issuing hypercalls as he has the write privilege on this
forged page table.
Theoretically, (52 − 12)/64 = 62.5% vulnerable bits
can be exploited in page table replacement attacks, re-
gardless of ﬂippable directions.
In practice, because
physical addresses on a machine is limited by the avail-
able physical memory, which is much less than the al-
lowed (252 − 1)B. For example, with 128GB memory,
the most signiﬁcant bit in a physical address is bit 38.
Therefore the fraction of vulnerable bits that are ex-
ploitable is about 41%. We will empirically show the
fraction of vulnerable bits that are exploitable in our at-
tacks in Section 6.
6 Evaluation
In this section, we will ﬁrst evaluate the effectiveness
and efﬁciency of the bit detection algorithms (described
in Section 3) in Section 6.1, our row hammer attacks
(described in Section 4) in Section 6.2, and the cross-
VM memory access attacks (described in Section 5) in
Section 6.3.
6.1 Bit Detection Efﬁciency and Accuracy
We ran the bit detection algorithm detailed in Section 3
on a set of local machines. The processor and DRAM
conﬁgurations, together with the detected physical ad-
dress mapping in the DRAMs, are shown in Table 1. For
instance, on a machine equipped with an Intel Westmere
processor, Xeon E5620, and one DRAM chip (with 2
memory channels, 1 DIMM, 2 ranks, 8 banks, and 215
rows per bank), we ran our algorithm and found the bits
that determine bank indices are b6 ⊕ b16, b13, b14, b20,
b21, and the bits that determine row indices are bits b16 to
b19, and bits b22 to b32 (totally 15 bits). We can see from
these results that older processors, such as Westmere and
Sandy Bridge, tend to have simpler XOR-schemes. More
recent processors may have complex schemes (probably
due to channel hashing [21]). For example, on an In-
tel Haswell Xeon E5-1607 v3 processor, we observed
that complicated XOR-schemes, such as b7⊕b12⊕b14⊕
b16 ⊕ b18 ⊕ b26 and b8 ⊕ b13 ⊕ b15 ⊕ b17 ⊕ b27 are used to
determine DRAM banks. Moreover, only on recent pro-
cessors (e.g., Intel Broadwell Core i5-5300U) did we ob-
serve the same address bit involved in two XOR-schemes
(e.g., b18 and b19); other bits are at most used in one
XOR-scheme. In addition, row bits are mostly contigu-
ous bits, and on some processors can be split into two
segments. For example, on an Intel Xeon E5-2640 v3
processor we tested on, the row bits are b15 ∼ b17 and
b21 ∼ b35.
Efﬁciency evaluation. Figure 9 shows the execution
time of the bit detection algorithms. Results for ﬁve
local machines (Intel Sandy Bridge Core i3-2120 with
4GB memory, Intel Broadwell Core i5-5300U with 8GB
memory, Intel Westmere Xeon E5620 with 4GB mem-
ory, Intel Haswell Xeon E5-2640 v3 with 32GB memory,
and Intel Haswell Xeon E5-1607 v3 with 16GB mem-
ory) and three cloud machines (one machine in Cloud-
lab, Emulab d820, with 128GB memory, and two ma-
chines on Amazon EC2, one c1.medium instance and
one c3.large instance, total memory size unknown) are
shown in Figure 9. Most of these experiments can ﬁnish
within one minute, with one exception of Xeon E5-2640
v3 which takes almost two minutes. The longer latency
for testing E5-2640 v3 may be caused by its use of DDR4
memory, while the others are equipped with DDR3 mem-
ory chips.
Validation. Because Intel does not publish the memory
mapping algorithms of their memory controllers, we do
not have ground truth to validate our algorithm. How-
ever, we show that our algorithm is very likely to produce
valid results for two reasons: First, in Table 1, the total
number of bank bits and row bits detected are consis-
tent with the DRAM conﬁguration that we learned using
several third-party software tools, including dmidecode,
decode-dimmms and HWiNFO64. Second, we conducted
double-sided row hammer attacks on some of the local
machines we have in our lab: Machine A, Sandy Bridge
28  25th USENIX Security Symposium 
USENIX Association
10
Processor
Family
Westmere
Sandy
Bridge
Haswell
Broadwell
Processor
Name
Intel Xeon
E5620
Intel Core
i3-2120
Intel Core
i5-2500
Intel Xeon
E5-1607
v3
Intel Xeon
E5-2640 v3
Intel Core
i5-5300U
Channels
DIMMs
Ranks
Banks
Rows
Bank bits
2
2
2
4
2
2
1
1
1
1
1
1
2
1
1
1
2
1
8
8
8
8
16
8
215
215
215
215
218
216
b6 ⊕ b16, b13, b14, b20, b21
b6, b14 ⊕ b17, b15 ⊕ b18, b16 ⊕ b19
b6, b14 ⊕ b17, b15 ⊕ b18, b16 ⊕ b19
b7 ⊕ b12 ⊕ b14 ⊕ b16 ⊕ b18 ⊕ b26,
b8 ⊕ b13 ⊕ b15 ⊕ b17 ⊕ b27,
b19 ⊕ b23, b20 ⊕ b24, b21 ⊕ b25
b6 ⊕ b21, b13, b34,
b18 ⊕ b22, b19 ⊕ b23, b20 ⊕ b24
b7 ⊕ b8 ⊕ b9 ⊕ b12 ⊕ b13 ⊕ b18 ⊕ b19,
b14 ⊕ b17, b15 ⊕ b18, b16 ⊕ b19
Table 1: Identifying physical address mapping in DRAMs.
Row bits
b16 ∼ b19
b22 ∼ b32
b17 ∼ b31
b17 ∼ b31
b23 ∼ b34
b15 ∼ b17
b21 ∼ b35
b17 ∼ b32
validity of our bit detection method.
Figure 9: Efﬁciency of bit detection.
i3-2120, Machine B, Sandy Bridge i3-2120, Machine C,
Sandy Bridge i5-2500, and Machine D, Broadwell i5-
5300U4. Particularly on each of these machines, we in-
dexed each row of the same bank from 1 to 2k, where k
is the number of detected row bits; the index of a row is
given by the value presented by all row bits in the same
order as they are in the physical address. Then we con-
ducted row hammer attacks on row n +1 and n−1 of the
same bank, where n ranged from 3 to 215 − 2. If the bit
detection algorithm are correct, we should ﬁnd more bit
ﬂips in row n than row n + 2 and n− 2, because double-
sided row hammer attacks have been reported to be more
effective [4]. It is apparent in Figure 10 that on all these
machines, much more bit ﬂips were found in row n than
the other rows. For example, on machine A, 52.4% bit
ﬂips were found in row n, while only 28.6% and 19.0%
ﬂippable bits were found in row n− 2 and n + 2, respec-
tively. These results suggest that our algorithm to detect
the row bits and bank bits (including XOR-schemes) are
consistent with the true conﬁguration with the DRAM.
We believe these evidence are strong enough to show the
4These set of machines, and the same naming convension, are also used
in the following experiments.
Figure 10: Location of bit ﬂips in double-sided row ham-
mer attacks. Row n +1 and n−1 are frequently accessed
to induce disturbance errors.
6.2 Effectiveness of Row Hammer Attacks
We evaluated the effectiveness of our row hammer at-
tacks in two aspects: (1) whether the attacker controlled
physical memory can cover a signiﬁcant portion of the
overall physical memory on the machine, and (2) the
number of bit ﬂips induced by our double-sided row
hammer attacks compared with single-sided attacks.
6.2.1 Physical Memory Coverage
We experimented on four servers to evaluate the phys-
ical memory coverage. The ﬁrst machine is a desktop
in our lab. It is equipped with a 3.3GHz Intel Core i3-
2120 processor and 8GB of memory, of which 1GB is
assigned to the virtual machine. The second machine is
another desktop with a 3.7GHz Intel Core i5-2500 pro-
cessor and 4GB of memory. The VM owns 1GB of the
USENIX Association  
25th USENIX Security Symposium  29
11
memory. The third machine is a server in Cloudlab,
which is equipped with a 2.2GHz Intel Xeon E5-4620
processor with 128GHz of memory. The VM runs on
this machine is allowed to control 4GB of memory. The
fourth machine is a dedicated cloud server in Amazon
EC2. It has 128GB of memory and operates on a 2.8GHz
Intel E5-2680 v2 processor. Our VM was allocated 8GB
of memory.
We conducted the experiments as follows. On each
of these VMs, we ran a program to measure the physi-
cal pages that are accessible to the guest VM. Then we
rebooted our VM and measured the accessible physi-
cal memory again. After each reboot, some new phys-
ical pages will be observed (but some old pages will be
deallocated from this VM). We rebooted the VM several
times until no more new memory pages are observed af-
ter reboot. In Figure 11, the x-axis shows the number of
VM reboots (the ﬁrst launch counted as one reboot) and
the y-axis shows the fraction of physical memory that
can be accessed by the VM. In the two local machines,
because no other VMs are competing for the physical
memory, the sets of accessible pages are relatively stable.
But still after reboots, more memory pages are accessi-
ble to the guest VMs. In the two cloud tests (one in EC2
and one in Cloudlab), the total physical memory sizes
are very large (i.e., 128GB). Although our VM were
only allocated 6.25% (in the EC2 test) and 3.125% (in
the Cloudlab test) physical memory initially, after sev-
eral reboots, our VM could access as much as 17.8% (in
the EC2 test) and 22.3% (in the Cloudlab test) of the to-
tal memory. The results suggest that row hammer at-
tacks are possible to enumerate a large fraction of the
physical memory even though the VM can only control a
small portion of it at a time. Therefore, by doing so, the
chances for a guest VM to induce exploitable and repeat-
able bit ﬂips are not bound by the ﬁxed size of physical
memory allocated to the VM.
6.2.2 Row Hammer Induced Bit Flips
To show that our double-sided row hammer attacks are
more effective than single-sided versions, we empirically
test how fast each method can induce memory bit ﬂips.
In addition, we also tested with row hammer code both
with and without mfence to empirically evaluate the ef-
fectiveness of the two types of attack techniques
Particularly, we implemented four types of row ham-
mer attack tools: double-sided row hammer without
mfence instruction, double-sided row hammer with
mfence, single-sided row hammer without mfence, and
single-sided row hammer with mfence.
In Figure 12,
we show the number of bit ﬂips induced per hour by
one of these approaches on four machines: Machine
A, Sandy Bridge i3-2120, Machine B, Sandy Bridge
Figure 11: Physical memory coverage after VM reboot-
ing.
Figure 12: Efﬁciency of double-sided row hammer at-
tacks.