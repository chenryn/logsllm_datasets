NewReno
NewReno
NewReno ACK Thinning
NewReno ACK Thinning
4
4
8
8
16
16
32
32
64
64
Number of Hops
Number of Hops
Fig 4: 7-hop chain: TCP Vegas goodput for different 
Fig 8: h-hop chain with 2 Mbit/s: Window size vs. 
bandwidths
number of hops
]
]
s
s
/
/
t
t
i
i
b
b
K
K
[
[
t
t
u
u
p
p
d
d
o
o
o
o
G
G
400
400
350
350
300
300
250
250
200
200
150
150
100
100
50
50
0
0
2
2
Vegas (cid:68)= 2
Vegas (cid:68)= 2
Vegas (cid:68)= 2 ACK Thinning
Vegas (cid:68)= 2 ACK Thinning
Vegas (cid:68)= 3 ACK Thinning
Vegas (cid:68)= 3 ACK Thinning
Vegas (cid:68)= 4 ACK Thinning
Vegas (cid:68)= 4 ACK Thinning
s
s
e
e
r
r
u
u
l
l
i
i
t
t
a
a
F
F
e
e
u
u
o
o
R
R
e
e
s
s
a
a
l
l
f
f
f
f
o
o
r
r
e
e
b
b
m
m
u
u
N
N
4
4
8
8
16
16
32
32
64
64
Number of Hops
Number of Hops
300
300
250
250
200
200
150
150
100
100
50
50
0
0
2
2
Vegas
Vegas
NewReno
NewReno
NewReno ACK Thinning
NewReno ACK Thinning
Paced UDP
Paced UDP
4
4
8
8
16
16
32
32
64
64
Number of Hops
Number of Hops
Fig 5: h-hop chain with 2 Mbit/s: TCP Vegas with ACK 
Fig 9: h-hop chain with 2 Mbit/s: Number of false 
thinning: Goodput vs. number of hops
route failures vs. number of hops
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
In  the  second  experiment,  we  consider  TCP  Vegas 
with ACK thinning for different values of the parameter 
(cid:68).  Again,  the  goal  of  this  study  lies  in  determining  the 
optimal  value  of  the  parameter  (cid:68).  Figure  5  shows  the 
goodput of TCP Vegas without ACK thinning with (cid:68) = 2 
as  well  as  for  TCP  Vegas  with  ACK 
thinning 
for(cid:3)different values of(cid:3)(cid:68). We observe that except for h = 
4, TCP Vegas with (cid:68) = 2 performs slightly better than all 
other variants along all hops. Specifically, we notice that 
TCP  Vegas  with  (cid:68)  =  2  and  ACK  thinning  performs 
slightly worse than TCP Vegas with (cid:68) = 2 for h > 6.  
The reason for this performance difference is that the 
TCP  window  for  TCP  Vegas  with  (cid:68)  =  2  and  ACK 
thinning  often  decreases  to  3,  leading  to  a  lack  of 
acknowledgments  at  the  TCP  receiver  which  only 
acknowledges  every  fourth  TCP  packet  for  all  packets 
with  a  sequence  number  greater  than  8,  as  described  in 
Section 3.2. 
From the previous two experiments, we conclude that 
TCP Vegas with (cid:68) = 2 performs best for most number of 
hops  and  a  bandwidth  of  2  Mbit/s.  Although  increasing 
the  bandwidth  improves  the  performance  of  TCP  Vegas 
with  larger  values  of  (cid:68)(cid:3)due  to  the  decreased  contention 
on  the  MAC  layer,  TCP  Vegas  with  (cid:68)  =  2  remains  the 
best choice. 
In the third  experiment,  we  consider  TCP NewReno, 
TCP  Vegas,  TCP  NewReno  with  ACK  thinning,  and 
paced  UDP  for  the h-hop  chain  with  varying  hop  count. 
As  measures,  we  consider  goodput,  average  number  of 
retransmissions,  average  window  size  of  the  flow  and 
number  of  false  route  failures  as  a  function  of  chain 
length. The bandwidth is kept fixed to 2 Mbit/s. Figures 6 
to  9  plot  performance  curves  derived  from 
this 
experiment. In Figure 6, we observe that TCP Vegas has 
up  to  83%  higher  goodput  than  TCP  NewReno  (i.e., 
about 75% for 8 hops). Furthermore, for most number of 
hops,  even  TCP  NewReno  with  ACK  thinning  performs 
slightly  worse  than  TCP  Vegas  without  ACK  thinning. 
For  both  TCP  Vegas  and  TCP  NewReno  with  ACK 
thinning,  the  goodput  decreases  much  slower  with 
increasing  number  of  hops  than  for  TCP  NewReno, 
indicating that both TCP Vegas and TCP NewReno with 
ACK  thinning  are  significantly  less  sensitive  to  hidden 
terminal effects. From Figure 6, we also conclude that the 
goodput of TCP Vegas lies between 23% for 4 hops and 
52% for 32 hops below the optimal goodput achieved by 
paced UDP,  whereas the goodput  of TCP  NewReno lies 
between 28% for 4 hops and 63% for 32 hops below the 
goodput of paced UDP. Such big gap between both TCP 
variants and paced UDP outlines the significant impact of 
link layer interactions on the performance of TCP. 
Figure 7 shows that TCP Vegas causes up to 99% less 
retransmissions than TCP NewReno. In fact, the number 
of retransmissions stays very low for TCP Vegas for any 
number  of  hops.  Note  that  a  reduction  of  retransmitted 
packets  directly  translates  in  a  reduction  of  power 
consumption,  which  is  a  critical  factor  for  resource 
constrained mobile devices. Opposed to that, the average 
number  of  retransmissions  of  TCP  NewReno  almost 
doubles  from  6  to  8  hops  reaching  its  peak  and, 
subsequently,  decreases  gradually.  This  results  from  the 
fact that  in  a chain of  seven  and more  hops, two  hidden 
terminals may simultaneously disrupt the transmission of 
a single node, as it is the case for node 4 in a 7-hop chain. 
In contrast, a chain of up to six hops can produce at most 
a single hidden terminal effect for a single node. For TCP 
NewReno  with  ACK  thinning,  the  average  number  of 
retransmissions is considerably lower than without ACK 
thinning.  This  is  because  ACK  thinning  results  for  TCP 
NewReno a smaller average window size as observed in 
Figure  8.  Recall  that  during  the  slow  start  phase,  TCP 
NewReno  increases  the  window  size  dependent  on  the 
receipt  of  acknowledgments,  specifically  by  one  packet 
for  each  received  ACK.  In  our  simulations  we  have 
noticed  that  for  h (cid:149)  7,  TCP  NewReno  operates  during 
more  than  40%  of  the  connection  in  slow  start.  Since 
ACK thinning reduces the  number  of  ACKs,  this  results 
in  a  less  aggressive  growth  in  the  window  size  for  TCP 
NewReno,  and,  thus,  a  smaller  average  window  size. 
Figure 8 also shows that the average window size of TCP 
Vegas lies in the  range 3.5 to  5.5 for increasing number 
of  hops  between  4  and  40,  providing  an  explanation  for 
the low number of retransmissions investigated in Figure 
7. Comparing the average window size for longer chains 
to  the  optimum  of  h/4  [5],  we  find  that  TCP  Vegas  is 
close  to  the  optimum  for  32  hops,  while  it  keeps  the 
window  size too  small  for  longer  chains.  Recall that  the 
parameter (cid:68) determines the window size. (cid:71)
In order to get further insight in the impact of routing 
on  the  acquired  results,  we  investigate  the  influence  of 
false  route  failures  on  the  performance  of  the  examined 
TCP  variants.  False  route  failures  result  in  case  the  link 
layer fails to deliver a packet to the next hop, either after 
seven  unsuccessful 
transmissions  for  RTS  control 
packets or  after  four unsuccessful  transmissions for  data 
packets.  After  the  link  layer  notifies  the  routing  layer 
about the transmission failure, the routing layer assumes 
that the route to the next hop is broken and thus deletes it 
from  its  routing  table  before  broadcasting  a  route  error 
message.  In  most  such  cases,  the  TCP  sender  times  out 
and  tries  to  retransmit  the  lost  packet,  initiating  a  new 
route  discovery  procedure,  which  causes  additional 
traffic  overhead.  Figure  9  shows  the  number  of  false 
route  failures  for  varying  hop  number.  Consistent  with 
the  previous  results,  we  observe  that  TCP  NewReno 
causes  significantly  more  false  route  failures  than  TCP 
Vegas, specifically 93% to 100%. That indicates that the 
larger  average  window  size  of  TCP  NewReno  results  in 
more  packet  drops on the link  layer  and thus more  false 
route  failures.  For  TCP  NewReno  with  ACK  thinning, 
we notice that it causes no false route failures for h  topt, link layer contention is minimal, but 
the rate decreases linearly causing such gracious goodput 
decrease.  We  conclude  from  Figure  10  that  the  optimal 
pacing rate is extremely sensitive to network conditions. 
Thus,  each  effective  rate-based  transport  protocol  will 
require  a  low-latency  algorithm  for  quickly  adapting  the 
transmission rate to changing network conditions. 
As  primary  performance  measures,  we  consider  the 
goodput,  which  is  shown  for  different  bandwidths  in 
Figure  11.  To  get  deeper  insight  in  how  goodput  is 
achieved by the individual TCP variants, we furthermore 
investigate  the  average  number  of  retransmissions,  the 
average  window  size  of  the  flow  as  well  as  the  overall 
link 
layer  dropping  probability  (averaged  over  all 
intermediate node), which are shown in Figures 12 to 14. 
Recall  that  the  bars  for  2  Mbit/s  exactly  represent  the 
results  for  the  7-hop  chain  in  Figures  6  to  8.  Extending 
the findings of Figures 6 to 8, we find that applying ACK 
thinning  in  TCP  Vegas  does  not  improve  goodput  at  2 
Mbit/s,  but  reduces  drops  on  the link  layer,  as  shown in 
Figure  14.  However,  reduction  of  link  layer  drops  does 
not translate in increased goodput, since link layer drops 
are  not  visible  to  TCP  Vegas  on  the  transport  layer,  as 
shown  in  Figure  12.  This  indicates  that  the  load  on  the 
link layer is moderate, so that all packets can be sent after 
a  few  retries.  In  fact,  applying  ACK  thinning  in  Vegas 
will  even  result  in  an  increased  number  of  packet 
retransmissions  on  the  transport  layer,  since  a  missing 
ACK  may  result  in  the  retransmission  of  multiple 
packets.  With  increasing  network  bandwidth,  packet  
400
400
350
350
300
300
250
250
200
200
150
150
100
100
50
50
]
]
s
s
/
/
t
t
i
i
b
b
K
K
[
[
t
t
u
u
p
p
d
d
o
o
o
o
G
G
0
0
28
28
30
30
32
32
34
34
36
36
38
38
40
40
42
42
44
44
Time between successive packet transmissions [ms]
Time between successive packet transmissions [ms]
Fig 10: 7-hop-chain with 2 Mbit/s: Goodput vs. 
packet inter-sending time
]
]
s
s
/
/
t
t
i
i
b
b
K
K
[
[
t
t
u
u
p
p
d
d
o
o
o
o
G
G
Vegas
Vegas
NewReno
NewReno
Vegas ACK Thinning
Vegas ACK Thinning
NewReno ACK Thinning
NewReno ACK Thinning
NewReno Optimal Window
NewReno Optimal Window
Paced UDP
Paced UDP
1600
1600
1400
1400
1200
1200
1000
1000
800
800
600
600
400
400
200
200
0
0
2
2