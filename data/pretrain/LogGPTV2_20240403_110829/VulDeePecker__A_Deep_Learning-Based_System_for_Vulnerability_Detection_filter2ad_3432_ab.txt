neural networks that can cope with contexts may be suitable
for vulnerability detection.
This principle suggests that neural networks for natural
language processing may be suitable for vulnerability detection
because context is also important in natural language pro-
cessing [33]. Putting the notion of context into the setting
of the present paper, we observe that the argument(s) of a
program function call is often affected by earlier operations in
the program and may also be affected by later operations in
the program.
Since there are many neural networks for natural
lan-
guage processing, let us start with Recurrent Neural Networks
(RNNs) [51], [53]. These neural networks are effective in
coping with sequential data, and indeed have been used for
program analysis (but not for vulnerability detection purposes)
[20], [48], [56], [57]. However, RNNs suffer from the Vanish-
ing Gradient (VG) problem, which can cause ineffective model
training [16]. Note that the VG problem is inherited by the
Bidirectional variant of RNNs, called BRNNs [47]. We would
prefer neural networks that do not suffer from the VG problem.
The VG problem can be addressed with the idea of memory
cells into RNNs,
including the Long Short-Term Memory
(LSTM) cell and the Gated Recurrent Unit (GRU) cell [17],
[22]. Since the GRU does not outperform the LSTM on
language modeling [27], we select LSTM for vulnerability
detection and defer its comparison with GRU to future work.
However, even LSTM may be insufﬁcient for vulnerability
detection because it is unidirectional (i.e., from earlier LSTM
cells to later LSTM cells). This is because the argument(s) of a
program function call may be affected by earlier statements in
the program and may be also affected by the later statements.
This suggests that unidirectional LSTM may be insufﬁcient
and that we should use Bidirectional LSTM (BLSTM) for
vulnerability detection.
Figure 1 highlights the structure of BLSTM neural network,
which has a number of BLSTM layers, a dense layer, and
a softmax layer. The input to the learning process is in a
certain vector representation. The BLSTM layers have two
directions, forward and backward. The BLSTM layers contain
3
some complex LSTM cells, which are treated as black-boxes in
the present paper and therefore deferred to Appendix A. The
dense layer reduces the number of dimensions of the vectors
received from the BLSTM layers. The softmax layer takes
the low-dimension vectors received from the dense layer as
input, and is responsible for representing and formatting the
classiﬁcation result, which provides feedback for updating the
neural network parameters in the learning phase. The output
of the learning phase is a BLSTM neural network with ﬁne-
tuned model parameters, and the output of the detection phase
is the classiﬁcation results.
Figure 1. A brief review of BLSTM neural network
III. DESIGN OF VULDEEPECKER
Our objective is to design a vulnerability detection system
that can automatically tell whether a given program in source
code is vulnerable or not and if so,
the locations of the
vulnerabilities. This should be achieved without asking human
experts to manually deﬁne features and without
incurring
high false negative rates (as long as the false positive rates
are reasonable). In this section, we describe the design of
VulDeePecker. We start with a discussion on the notion of code
gadget, because it is crucial to the representation of programs.
Then, we give an overview of VulDeePecker and elaborate its
components.
A. Deﬁning code gadget
In order to represent programs in vectors that are suitable
for the input to neural networks, we ﬁrst propose transforming
programs into a representation of code gadget, which is deﬁned
as follows:
Deﬁnition 1: (Code gadget) A code gadget is composed of
a number of program statements (i.e., lines of code), which are
semantically related to each other in terms of data dependency
or control dependency.
In order to generate code gadgets, we propose the heuristic
concept of key point, which can be seen as a “lens” through
which we can represent programs from a certain perspective.
Intuitively, the heuristic concept of key point can be seen as,
in a sense, the “center” of a vulnerability or the piece of code
that hints the existence of a vulnerability. For vulnerabilities
that are caused by improper uses of library/API function
4
calls, the key points are the library/API function calls; for
vulnerabilities that are caused by improper uses of arrays, the
key points are the arrays. It is important to note that a type
of vulnerabilities may have multiple kinds of key points. For
example, buffer error vulnerabilities may correspond to the
following key points: library/API function calls, arrays, and
pointers. Moreover, the same kind of key points may exist in
multiple types of vulnerabilities. For example, both buffer error
and resource management error vulnerabilities may contain
the key points of library/API function calls. Precisely deﬁning
the heuristic concept of key point is beyond the scope of the
present paper and is left as an interesting problem for future
research; instead, we focus on using this heuristic concept as
the “lens” to use deep learning to learn vulnerability patterns.
In this paper, we focus on using the particular key point of
library/API function calls to demonstrate its usefulness in deep
learning-based vulnerability detection. This is motivated by the
observation that many vulnerabilities are related to library/API
function calls. It is also an interesting future work to investigate
the usefulness of other kinds of key points.
Corresponding to the key point of library/API function
calls, code gadgets can be generated by the means of data ﬂow
or control ﬂow analysis of program, for which there are well
known algorithms [23], [50] and readily usable commercial
products such as Checkmarx [2]. It is worth mentioning that
Checkmarx also detects vulnerabilities based on some rules
that are manually deﬁned by human experts. However, we do
not use its rules for vulnerability detection; instead, we will
compare the effectiveness of VulDeePecker against it.
B. Overview of VulDeePecker
As highlighted in Figure 2, VulDeePecker has two phases:
a learning (i.e., training) phase and a detection phase. The
input to the learning phase is a large number of training
programs, some of which are vulnerable and the others are
not. By “vulnerable” we mean that a program contains one
or multiple known vulnerabilities. The output of the learning
phase is vulnerability patterns, which are coded into a BLSTM
neural network.
1) The learning phase: As highlighted in Figure 2(a), the
learning phase has 4 steps.
Step I: Extracting the library/API function calls and the
corresponding program slices. This has two sub-steps, which
are highlighted below and elaborated in Section III-C.
•
•
Step I.1: Extracting library/API function calls from
the training programs, while noting that the current
version of VulDeePecker focuses on vulnerabilities
related to the key point of library/API function calls.
Step I.2: Extracting one or multiple program slices for
each argument (or variable) of a library/API function
call
is extracted in Step I.1. In this paper, a
program slice represents the statements of a program
(i.e., lines of code) that are semantically related to
an argument of a library/API function call, while
noting that the notion of program slice was originally
introduced to represent the statements of a program
with respect to a program point or variable [55].
that
...Dense layerSoftmax  layer..................BLSTM layers...Vectors...Output: learned BLSTM with parameters/ classification resultsLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTM............(a) Learning phase
(b) Detection phase
Figure 2. Overview of VulDeePecker: the learning phase generates vulnerability patterns, and the detection phase uses these vulnerability patterns to determine
whether a target program is vulnerable or not and if so, the locations of the vulnerabilities (i.e., the corresponding code gadgets).
Step II: Generating code gadgets of the training programs
and their ground truth labels. This step has two sub-steps,
which are highlighted below and elaborated in Section III-D.
•
•
Step II.1: Assembling the program slices obtained
in Step I.2 into code gadgets, one code gadget per
library/API function call. A code gadget does not
necessarily correspond to some consecutive lines of
code. Instead, it consists of multiple lines of code that
are semantically related to each other (i.e., inheriting
the semantic relation that is encoded in those program
slices).
Step II.2: Labeling the ground truth of code gadgets.
This step labels each code gadget as “1” (i.e., vulner-
able) or “0” (i.e., not vulnerable). The ground truth
labels of code gadgets are available because we know
whether a training program is vulnerable or not and
if it is vulnerable, we also know the locations of the
vulnerabilities.
Step III: Transforming code gadgets into vector represen-
tations. This step has two sub-steps, which are highlighted
below and elaborated in Section III-E.
•
•
Step III.1: Transforming code gadgets into certain
symbolic representations, which will be elaborated
later. This step aims to preserve some semantic in-
formation of the training programs.
Step III.2: Encoding code gadgets in the symbolic rep-
resentation obtained in Step III.1 into vectors, which
are the input for training a BLSTM neural network.
This is necessary in order to use neural networks in
general.
Step IV: Training a BLSTM neural network. Having en-
coded the code gadgets into vectors and obtained their ground
truth labels, the training process for learning a BLSTM neural
network is standard.
2) The detection phase: Given one or multiple target
programs, we extract library/API function calls from them as
well as the corresponding program slices, which are assembled
into code gadgets. The code gadgets are transformed into
their symbolic representations, which are encoded into vectors
and used as input
to the trained BLSTM neural network.
The network outputs which vectors, and therefore which code
gadgets, are vulnerable (“1”) or not (“0”). If a code gadget is
vulnerable, it pins down the location of the vulnerability in the
target program. As highlighted in Figure 2(b), this phase has
two steps.
Step V: Transforming target programs into code gadgets
and vectors. It has ﬁve sub-steps.
•
•
•
•
•
Step V.1: Extracting library/API function calls from
the target programs (similar to Step I.1).
Step V.2: Extracting program slices according to the
arguments of the library/API function calls (similar to
Step I.2).
Step V.3: Assembling the program slices into code
gadgets (similar to Step II.1).
Step V.4: Transforming the code gadgets to their
symbolic representations (similar to Step III.1).
Step V.5: Encoding the symbolic representations of
code gadgets into vectors (similar to Step III.2).
Step VI: Detection. This step uses the learned BLSTM neural
network to classify the vectors corresponding to the code
5
Step II: Generating code gadgets and their ground truth labelsInputStep III: Transforming code gadgets into vectorsStep II.2: Each code gadget   is labeled as “1” or “0”Step IV: Training BLSTM neural networkOutputBLSTM neural network with fine-tuned model parametersCode gadget Code gadget 1Label1Code gadget 20Code gadget 31Code gadget 40Code gadget 50......Step III.2: Encoding the symbolic representations of code gadgets into vectors...Dense layerSoftmax layer..................BLSTM layers...TokenVectormainvi1(vi2intvi3argcvi4...... [vi1,vi2, …, viτ]The symbolic representation of the ith code gadgetvi1vi2vi(τ-1)viτ[]...Vector of symbolic representationTraining programs (i.e., software  programs for training deep learning neural networks)Step II.1: Assembling program slices into code gadgetsStep III.1: Transforming code gadgets into symbolic representationsStep I: Extracting library/API function calls and thecorresponding program slices from training programsStep I.1: Extracting library/API function calls from the training programsStep I.2: Extracting program slices corresponding to the arguments of the library/API function callsLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMStep V.3: Assembling program slices into code gadgets(similar to Step II.1) Step V.4: Transforming code gadgets into symbolic representations (similar to Step III.1)Step VI: Applying the trained BLSTM neural network to classify the code gadgets of target programs in vector representationCode gadgets are vulnerable or notInputOutputTrained BLSTM neural network with fine-tuned model parametersStep V: Transforming target programs into code gadgets and vectorsStep VI: DetectionStep V.5: Encoding the symbolic representations into vectors (similar to Step III.2)Step V.1: Extracting  library/API function calls from the target programs (similar to Step I.1) Step V.2: Extracting program slices corresponding to the function calls(similar to Step I.2) Target programsFigure 3.
that is also used as an example to demonstrate the extraction of program slices (Step I.2) and the assembly of program slices into code gadgets (Step II.1).
Illustrating the extraction of library/API function calls (Step I.1) from a (training) program, which contains a backward function call (i.e., strcpy)
gadgets that are extracted from the target programs. When a
vector is classiﬁed as “1” (i.e., vulnerable), it means that the
corresponding code gadget is vulnerable and the location of
the vulnerability is pinned down. Otherwise, the corresponding
code gadget is classiﬁed as “0” (i.e., not vulnerable).
Steps I-III are respectively elaborated in the following
subsections. Steps IV and VI are standard and Step V is similar
to some of Steps I-III.
C. Step I: Extracting library/API function calls and program
slices
1) Step I.1: Extracting library/API function calls: We
classify library/API function calls into two categories: forward
library/API function calls and backward library/API function
calls. Forward library/API function calls are the function calls
that receive one or multiple inputs directly from the external
input, such as the command line, a program, a socket, or a ﬁle.
For example, the recv function call is a forward library/API
function call because it receives data from a socket directly.
Backward library/API function calls are the function calls that
do not receive any external input directly from the environment
in which the program runs.
Figure 3 shows an example of a backward library/API
function call strcpy (line 9). It is a backward library/API
function call because it does not receive any external input
directly.
We highlight a distinction between forward and backward
library/API function calls. For forward library/API function
calls, the statements inﬂuenced by the input arguments are crit-
ical because they may be vulnerable to improper (e.g., sophis-
ticatedly crafted) argument values; for backward library/API
function calls, the statements inﬂuencing the values of the
arguments are critical because they could make the library/API
function calls vulnerable. This insight will be leveraged to
guide the heuristic padding of the vector representations of
code gadgets.
2) Step I.2: Extracting program slices: This step gener-
ates program slices corresponding to the arguments of the
library/API function calls that are extracted from the training
programs. We deﬁne two kinds of slices: forward slices and
backward slices, where a forward slice corresponds to the
statements that are affected by the argument in question and a
backward slice corresponds to the statements that can affect the
argument in question. We take advantage of the commercial
product Checkmarx [2], more speciﬁcally its data dependency
graph, to extract these two kinds of slices. The basic idea is
the following:
•
•
For each argument in a forward library/API function
call, one or multiple forward slices are generated,
with the latter corresponding to the case that the slice
related to the argument is branched at, or after, the
library/API function call.
For each argument in a backward library/API function
call, one or multiple backward slices are generated,
with the latter corresponding to the case that multiple
slices related to the argument are merged at, or prior
to, the library/API function call.
Note that a program slice consists of multiple statements
that may belong to multiple user-deﬁned functions. That is, a
slice can go beyond the boundary of user-deﬁned functions in
question.
Figure 3 shows an example program that contains the
library function call strcpy, which has two arguments buf and
str. Since strcpy is a backward function call, for each of its
arguments we will generate a backward slice. For argument
buf, the slice consists of three statements, namely lines 4,
5, and 9 of the program, which belong to the user-deﬁned
function test. For argument str,
the slice consists of six
statements, namely lines 13, 15, 18, 19, 2, and 9 of the
program, where the ﬁrst 4 belong to the user-deﬁned function
main and the last 2 belong to the user-deﬁned function test.
6
1    void 2    test(char *str)3    {4       int MAXSIZE=40;5       char buf[MAXSIZE];67       if(!buf)8             return;9       strcpy(buf, str); /*string copy*/10    }1112    int13    main(int argc, char **argv)14    {15      char *userstr;1617      if(argc > 1) {18             userstr = argv[1];19             test(userstr);20       }21       return 0;22    }Program source code strstrstrstrbuf1518192995Step I.2: Generating slices of  arguments in library/API function callsStep II.1 Assembling slices into code gadgetsStep I.1: Extracting library/API function calls13  main(int argc, char **argv)15  char *userstr;18  userstr = argv[1];19  test(userstr);2    test(char *str)4    int MAXSIZE=40;5    char buf[MAXSIZE];9    strcpy(buf, str); /*string copy*/9  strcpy(buf, str); /*string copy*/test()test()main()main()test()Backward function callThe backward function call strcpy has two arguments, buf and str, each of which leads to a backward slice. The slice corresponding to buf consists of statements belonging to the user-defined function test (indicated by a dashed rectangle). The slice corresponding to str consists of statements scattered in two user-defined functions, main and test, which are also indicated by dashed rectangles.str13buf4The two slices are chains (i.e., a linear structure) because
Checkmarx uses chains to represent slices, while noting that
slices can also be represented by trees [23], [50]. Since the
linear structure can only represent one individual slice, a
library/API function call often corresponds to multiple slices.
D. Step II: Extracting code gadgets and labeling their ground
truth
1) Step II.1: Assembling program slices into code gadgets:
The program slices generated in the previous step can be
assembled into code gadgets as follows.
First, given a library/API function call and the correspond-
ing program slices, we combine the statements (i.e., pieces of
code) belonging to the same, user-deﬁned function into a single
piece according to the order of the statements’ appearance
in the user-deﬁned function. If there is a duplication of any
statement, the duplication is eliminated.
In the example shown in Figure 3, three statements (i.e.,
lines 4, 5, and 9) belonging to the user-deﬁned function test
consists the program slice corresponding to the argument buf,
and two statements (i.e.,
lines 2 and 9) belonging to the
user-deﬁned function test are a piece of the program slice
corresponding to the argument str. Therefore, we need to
assemble them into a single piece because they are related to
the same function test. According to the line numbers of these
statements’ appearance in the function test, this would lead to
2 → 4 → 5 → 9 → 9. Since the statement corresponding
to line 9 is duplicated, we eliminate the duplication to derive
a piece of assembled statements 2 → 4 → 5 → 9, which
correspond to the function test.
Second, assembling the statements belonging to different,
user-deﬁned functions into a single code gadget. If there is
already an order between two pieces of statements belonging to
these user-deﬁned functions, this order is preserved; otherwise,