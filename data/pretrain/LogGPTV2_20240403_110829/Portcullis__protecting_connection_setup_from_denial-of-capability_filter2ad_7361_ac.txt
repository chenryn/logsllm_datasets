veriﬁed for correctness. To prevent exhaustion attacks, only cor-
rect puzzle solutions and their input parameters are entered into a
Bloom ﬁlter [6] conﬁgured to detect the reuse of puzzle solutions
seen in the past period t. Each puzzle is uniquely identiﬁed by the
tuple (r, hi, (cid:2),dest IP). Since r is chosen randomly from 264 pos-
sible values, the space of potential puzzles for a given destination
address is quite large, and the probability of multiple legitimate
clients using the same puzzle for capability setup within the win-
dow of eligibility t for hi is negligible.
Bloom ﬁlters support a tradeoff between router state and the
probability of incorrectly dropping a unique solution. They provide
compact lookups, have no false negatives, and allow false positive
probabilities to be driven to arbitrarily low rates with the use of ad-
ditional memory. To illustrate this, consider a router with a 2 Gbps
link on which 5% of the capacity is allocated to capability requests
and a circular buffer of F Bloom ﬁlters, where each ﬁlter contains
all puzzles seen over a one second period. The router may receive
80,000 requests/sec, with each of the F ﬁlters being checked to see
if a puzzle is duplicated.
If k different hash functions are used,
inserting n puzzles into a single table of size m bits gives a false
positive probability of approximately (1− e kn
m )k. With an optimal k
value, this can be estimated as (0.6185) m
n . Thus, a ﬁlter of 300 KB
can prevent duplicates for one second with a false positive proba-
bility of under 1
106 per packet. A circular buffer conﬁguration of F
Bloom ﬁlters can therefore ﬁlter trafﬁc for F seconds with less than
)F) ≈ F
a (1− (1− 1
106 false positive probability per packet.
If a request clears the Bloom ﬁlter check, the router places it in
a priority queue based on its puzzle level. Otherwise, the router
drops the request packet.
3.8 Legitimate Sender Strategy
106
We now brieﬂy outline the puzzle-solving strategy used by a le-
gitimate sender. Later in Section 4 we precisely deﬁne this strategy
and prove that it will, with high probability, allow the sender to es-
tablish a capability, regardless of the attacker’s power or strategy.
We assume that the legitimate sender has neither knowledge of the
amount of congestion on the path to the DDoS victim, nor knowl-
edge of the attacker’s power or strategy (though a sender with some
or all of this information can further optimize her strategy). Essen-
tially, a legitimate sender will compute a solution to the lowest-
level puzzle and transmit a request. If the request fails, the sender
solves a puzzle that requires twice the computation of the previous
puzzle and sends a new request packet. The sender continues to
double her computational effort until she succeeds in establishing
a capability.
3.9 Overhead Analysis
Packet Overhead. We use 64 bits to represent the puzzle solu-
tion x. Hence the highest level puzzle would require approximately
263 hash computations. Contemporary PCs can compute approx-
imately 220 cryptographic hashes per second. Hence we expect
that these puzzles will remain computationally difﬁcult for years to
come. We use 6 bits to denote the puzzle level (cid:2). The 64-bit nonce r
is sufﬁcient to distinguish between different sources connecting to a
particular destination within a time interval t. We use hi = 80 bits to
represent the puzzle seed. Hence we need approximately 27 bytes
to encode the puzzle and puzzle solution in the packet header. This
small overhead can be piggybacked on any other data that might be
included in the request packet, such as for TCP connection estab-
lishment. Because this overhead need only be incurred on request
packets and request packets constitute a small fraction of the total
amount of trafﬁc, an extra 27 bytes should be acceptable.
Puzzle Veriﬁcation Overhead.
In analyzing the impact of puz-
zle veriﬁcation on routers, it is important to note that only a fraction
of a router’s capacity is devoted to capability setup trafﬁc, suggest-
ing that puzzle veriﬁcation need not necessarily operate at full line
speed. Nonetheless, minor hardware improvements would easily
allow routers to verify puzzles at line speed. The additional hard-
ware could be incorporated into new generations of routers or de-
veloped as modules to extend older routers. Within an AS, only
the border routers need to verify puzzles, setting or clearing a bit
in the header that internal routers can use to determine if a puzzle
solution is valid. As we show in Section 6, even if the victim’s
ISP is the only entity to upgrade its routers, the victim still receives
substantial beneﬁts.
Commercially available ASIC [15] and FPGA [16] cores for
SHA-1 are capable of performing these hash functions at well over
1Gbps in a small amount of space. For example, the ASIC imple-
mentation of SHA-1 only requires 23,000 gates, whereas a typical
ASIC has millions. Similarly, the FPGA implementation takes 577
slices, where a typical FPGA has tens of thousands of slices. Be-
cause multiple puzzles can be veriﬁed in parallel, the use of several
SHA-1 cores on a single ASIC or low-cost FPGA could handle
line-speed puzzle veriﬁcation, even for several OC-192 links. In
fact, the greatest limitation to using a single chip for puzzle veriﬁ-
cation is the available bandwidth for bringing data on and off the
chip. In addition, the latency introduced by each veriﬁcation will
be low, since verifying each puzzle involves computing a function
over less than 50 bytes. Hence when the hash function operates at
1Gbps, verifying a puzzle will introduce well under 1 μs of latency.
Routers could also perform puzzle veriﬁcations in software. Since
a modern PC can perform 220 SHA-1 computations per second
(see Section 7.1), a software implementation could support approx-
imately one million request packets per second.
Router Scheduling Overhead.
The router scheduling algorithm
used by Portcullis requires several hash computations for the Bloom
ﬁlter. These can be computed in parallel, even for a single packet,
and as discussed above, hash computations can be implemented
very efﬁciently in hardware. Again, we only apply this algorithm
to request packets, which constitute a small fraction of a router’s to-
tal bandwidth. If every router dedicates 5% of its bandwidth for the
request channel, a software implementation is sufﬁcient to support
a gigabit link, and a hardware implementation can easily handle
faster line-rates.
4. THEORETICAL FAIRNESS ANALYSIS
In this section, we prove two main results. First, allocating ser-
vice based on per-computation fairness provably guarantees that
a legitimate sender can establish a capability with high probabil-
ity, regardless of an attacker’s resources or strategy. This guarantee
holds even if the legitimate sender has no information about current
network conditions or the adversary’s resources. Second, assum-
ing that routers cannot independently distinguish legitimate clients
from malicious ones, we prove a lower bound indicating that no
system can improve on this guarantee.
4.1 Assumptions and Problem Deﬁnition
Assumptions. We assume that routers cannot independently dis-
tinguish packets from legitimate and malicious senders. We allow
all attackers to collude, jointly compute puzzles, and synchronize
their ﬂoods, but we assume they have bounded resources, though
the bound on their resources need not be known to the legitimate
senders. To simplify the analysis, we assume that all endhosts have
the same hardware conﬁguration and hence, equal computational
resources. Finally, we consider network latency negligible relative
to the sender’s puzzle computation time.
Problem Deﬁnition. We consider a scenario with a single bot-
tleneck router. Request packets from different sources arrive at the
bottleneck router, but the remainder of the network has inﬁnite ca-
pacity. Thus, a packet can only be queued at the bottleneck router.
For the purposes of the DoC attack, the adversary controls nm
compromised endhosts. We discretize time into small time slots
and assume that a single legitimate sender starts a connection setup
process at an arbitrary point in time between (0,∞).
We consider R, a class of router scheduling policies with ﬁnite
output bandwidth, i.e., a router outputs a maximum of γrequests in
each time slot. Under router policy R ∈ R, we deﬁne G R to be a
class of strategies for a legitimate uninformed sender. The sender is
uninformed in the sense that it is not required to know the real-time
condition of the network or the adversary’s computational capacity
or strategy.
Under router policy R ∈ R, and legitimate sender strategy G ∈
G R, we deﬁne A R,G(nm) to be the class of adversary strategies
using nm compromised machines. Thus, the adversary is aware of
the legitimate sender’s strategy, though it does not know when the
legitimate sender will begin. The adversary’s goal is to maximize
the connection setup time for the legitimate sender.
We deﬁne t(R, G, A(nm)) as the expected connection setup time
for a legitimate sender, assuming a router policy R∈ R, a legitimate
sender’s strategy G ∈ G R, and an adversary A(m) ∈ A R,G(nm) in
control of nm compromised machines. The setup time is the time
that elapses from when the sender starts sending request packets,
until the moment a request packet is successfully received at the
destination.
Finally, we deﬁne the Portcullis router scheduling policy and the
Portcullis legitimate sender’s policy.
DEFINITION 1: PORTCULLIS ROUTER SCHEDULING POLICY, R0
Each request carries an unforgeable proof of the amount of com-
putation performed by the sender.
In each time slot, if no more
than γ requests arrive, the router outputs all of them; otherwise,
the router preferentially outputs requests carrying larger amounts
of computation and drops any remaining requests.
DEFINITION 2: PORTCULLIS LEGITIMATE SENDER POLICY, G0
The legitimate sender continues to send request packets until one
transmits successfully; on the ith attempt, it attaches a proof of χ·
2i−1 computation, where χrepresents the amount of computational
effort an endhost can exert in a single unit of time.
4.2 Main Results
The ﬁrst result demonstrates that using Portcullis, a sender can
always successfully transmit a packet in time bounded by the amount
of attacker computation:
THEOREM 4.1. Under the Portcullis router scheduling policy
R0, a legitimate sender utilizing the Portcullis sending policy G0 ∈
G R0 to traverse a bottleneck link under attack by nm malicious hosts
successfully transmits a request packet in O(nm) amount of time in
expectation, regardless of the strategy employed by the adversary.
Our second result states that for any scheduling policy, and any
sending algorithm, a legitimate sender cannot perform better than
the guarantee provided by Theorem 4.1:
THEOREM 4.2. ∀R ∈ R, ∀G ∈ G R, ∃A(nm) ∈ A R,G(nm) such
that the expected time for a legitimate sender to successfully trans-
mit a request is Ω(nm).
4.3 Proofs
Given the deﬁnition of R0, we ﬁrst prove the following lemma,
which we use in our proof of Theorem 4.1.
LEMMA 4.3. Assume routers adopt the Portcullis scheduling
policy R0. Let φ denote the total amount of computational re-
sources controlled by the adversary, (φ = nmχ, where χ is the
amount of computational effort a single endhost can exert in a sin-
gle unit of time). If the legitimate sender attaches a proof of φ/γ+δ
computation to a request packet (where δ > 0 and γ is the number
of requests output by the bottleneck router in each time slot), then
regardless of the adversary’s strategy, the request packet success-
fully transmits with probability at least
δ
φ/γ+δ.
COROLLARY 1. If the legitimate sender attaches a proof of 2φ/γ
γ) to a request packet, the request packet
computation (i.e., δ = φ
succeeds with probability at least 1/2.
Before proving Lemma 4.3, we offer some insight into the result.
Intuitively, to prevent the successful transmission of a legitimate re-
quest in a particular time slot, an adversary needs to send at least
γ requests in the same time slot, each containing a larger proof of
computation than the legitimate request. If the adversary wishes to
sustain a ﬂood rate of γ in the long run, she can afford to put no
more than φ/γ computation into each request. Alternatively, the
adversary can ﬂood at rate γ in a fraction p of the time and attach
φ/(γ· p) amount of computation to each request. Lemma 4.3 states
that if the legitimate sender is aware of the adversary’s total com-
putational resource φ and the bottleneck bandwidth γ, it beneﬁts
the sender to attach a proof of slightly more than φ/γ computation
to its request. As a result of this strategy, the request successfully
transmits with non-negligible probability, no matter what strategy
the adversary uses. Corollary 1 is a special case of Lemma 4.3. If
the legitimate sender performs 2φ/γ computation on a request, the
request gets through with probability at least 1/2.
Proof of Lemma 4.3: Assume the sender puts a request packet on
the wire in the ith time slot, and attaches a proof of φ/γ+ δ com-
putation to the request packet. To prevent this request from getting
through, the adversary needs to inject at least γ requests in the ith
time slot, and each request packet should contain at least φ/γ+ δ
amount of computation. Since the adversary has a total amount of
computational resources φ, if she wishes to ﬂood with at least γre-
quests, each carrying a proof of at least φ/γ+ δ computation, then
she can do so during no more than a fraction p f = φ/γ
φ/γ+δ of the
time. Because the legitimate sender puts a packet on the wire at a
random point of time, its probability of success is 1− p f = δ
φ/γ+δ.
With Lemma 4.3, it is straightforward to prove our two main re-
sults. Note that the Portcullis sending policy does not require the
sender to know the adversary’s strategy, nor the number of ma-
chines employed by the adversary.
Proof of Theorem 4.1: After k = O(log nm) attempts (for some
k), the sender will try a request packet carrying a proof of 2φ/γ=
2χnm/γ computation. Applying Lemma 4.3 with δ = φ/γ, this
request has probability at least 1/2 of arriving successfully. To
compute the expected time until a request succeeds, we note that
the time spent solving the puzzle for attempt k + i is (2φ/γ)2i. Fur-
thermore, the probability that attempt k + j fails for any j (which
is relevant only if attempts k through k + j − 1 also fail) is at most
1/2 j. Hence, the probability that attempts k through k + i− 1 fail
and k + i succeeds is at most 1/2i(i−1). Thus the series for the ex-
pected time converges to O(φ/γ) = O(χnm/γ).
Proof of Theorem 4.2: Divide the compromised machines evenly
into τ= nm/2γ groups, each of size 2γ. Starting at time 0, the ith
group is activated during the ith time slot. Each compromised ma-
chine follows the legitimate sender’s algorithm for setting up a con-
nection. Regardless of whether a compromised machine is able to
set up a connection, it stops after τ time slots and restarts the legit-
imate sender’s algorithm. Because the bottleneck router can only
output γ requests per time unit, the expected time for each com-
promised machine to set up a connection is at least m/2γ− τ/2 =
nm/4γ. Since routers cannot independently distinguish a legitimate
request from a malicious request, and a compromised machine uses
the same algorithm as a legitimate sender, by symmetry, a legiti-
mate sender requires Ω(nm) time slots to establish a capability.
5. POTENTIAL ATTACKS
In this section, we analyze other potential attacks and explain
how Portcullis defends against them.
5.1 Attacks by Malicious Endhosts
Sharing Puzzle Solutions. Malicious endhosts may compute
puzzle solutions and share them with other colluding nodes. Per-
haps counter-intuitively, sharing puzzle solutions is not very effec-
tive at increasing attack power, because the attacker has no more
power to congest any single link in the network than it did before.
Even if all endhosts share puzzle solutions and target a bottle-
neck link, they cannot break our basic fairness guarantee (Sec-
tion 4), because Portcullis routers discard duplicate puzzle solu-
tions. Hence, no matter how many times an adversary sends a puz-
zle solution on the same link, she will only receive prioritized band-
width proportional to the amount of computation she performed.
The attacker can also use the same puzzle to attack different links
simultaneously. Yet this has little effect on our calculated amount
of work per-client, which was based solely on the combined CPU
capacity of all malicious hosts and the capacity of the bottleneck
link on the path between the client and the destination. Essentially,
for any particular client the puzzle-sharing scenario is no different
than if all attacking hosts had computed on behalf of a single host
that was capable of ﬂooding that client’s bottleneck link to the des-
tination. Since we already incorporate this case into our analysis,
the guarantees provided by Portcullis still hold.
However, an adversary may reuse puzzle solutions over sub-
intervals of the puzzle-seed validity window t to target multiple
links on a single network path at different times. With precise tim-
ing, proper network vantage points, and the attack bandwidth to
overwhelm core links, an adversary can reuse puzzles to keep at
least one link on the path saturated at all times with puzzle solutions
at a level higher than she could sustain without reuse. However, in
practice this attack advantage is linearly bounded by the number of
individual links the attacker can saturate with packets that do not
traverse earlier links in the path, where they would be detected as
duplicates. Additionally, because the attack is path-speciﬁc, affect-
ing most clients requires an adversary to possess signiﬁcant attack
resources in or near the victim’s own network.
Timing Ampliﬁcation.
Sections 4 and 6.2 describe an opti-
mal attacker strategy, assuming the attacker wishes to delay all
senders equally. However, an attacker can also spend more time
(than strictly optimal) computing, and hence send requests with
higher-level puzzles during short periods of time. Nonetheless,
these bursts of packets do not affect the average time to establish
a capability, since the extra computation time leaves a window in
which the adversary is not sending packets, allowing some legiti-
mate senders to quickly succeed using very low-level puzzles.
5.2 Attacks by Malicious Routers
Clearly no DoC-prevention scheme can prevent a malicious router
from dropping capability request packets forwarded through that
router. As a result, we only consider attacks where a malicious
router seeks to ﬂood or help malicious endhosts ﬂood the request
channel of a remote network link.4 For instance, the malicious
router can fail to enforce rate regulation in the request channel, or
it can use its own packets to attack the request channel. With a par-
tial deployment, the malicious router can potentially congest the
request channel of a downstream legacy link. However, as soon as