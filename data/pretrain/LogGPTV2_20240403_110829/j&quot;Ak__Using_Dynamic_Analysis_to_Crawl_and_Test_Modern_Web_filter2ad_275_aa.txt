title:j&quot;Ak: Using Dynamic Analysis to Crawl and Test Modern Web
Applications
author:Giancarlo Pellegrino and
Constantin Tsch&quot;urtz and
Eric Bodden and
Christian Rossow
j¨Ak: Using Dynamic Analysis to Crawl
and Test Modern Web Applications
Giancarlo Pellegrino1(B), Constantin Tsch¨urtz2, Eric Bodden2,
and Christian Rossow1
1 Center for IT-Security, Privacy, and Accountability (CISPA),
Saarland University, Saarbr¨ucken, Germany
{gpellegrino,crossow}@cispa.saarland
2 Secure Software Engineering Group, Technische Universit¨at Darmstadt,
Darmstadt, Germany
PI:EMAIL, PI:EMAIL
Abstract. Web application scanners are popular tools to perform black
box testing and are widely used to discover bugs in websites. For them to
work eﬀectively, they either rely on a set of URLs that they can test, or
use their own implementation of a crawler that discovers new parts of a
web application. Traditional crawlers would extract new URLs by pars-
ing HTML documents and applying static regular expressions. While this
approach can extract URLs in classic web applications, it fails to explore
large parts of modern JavaScript-based applications.
In this paper, we present a novel technique to explore web applica-
tions based on the dynamic analysis of the client-side JavaScript program.
We use dynamic analysis to hook JavaScript APIs, which enables us to
detect the registration of events, the use of network communication APIs,
and dynamically-generated URLs or user forms. We then propose to use a
navigation graph to perform further crawling. Based on this new crawl-
ing technique, we present j¨Ak, a web application scanner. We compare
j¨Ak against four existing web-application scanners on 13 web applications.
The experiments show that our approach can explore a surface of the web
applications that is 86 % larger than with existing approaches.
1 Introduction
Web application scanners are black box security testing tools that are widely
used to detect software vulnerabilities in web applications. As a very essential
component, the scanners have to explore all parts of the web application under
test. Missing functionality during this exploration step results in parts of the
web application remaining untested—leading to potential misses of critical vul-
nerabilities. To addres this problems, scanners typically expand their initial set
of seed URLs. That is, they crawl a web application to extract as many diﬀerent
URLs as possible. URLs are then used to send crafted inputs to the web appli-
cation to detect vulnerabilities. Nowadays, crawlers ﬁnd new URLs by pattern
matching on the HTML content of web sites, e.g., using regular expressions.
While this approach can extract URLs in classic web applications, it fails to
explore large parts of modern web applications.
c(cid:2) Springer International Publishing Switzerland 2015
H. Bos et al. (Eds.): RAID 2015, LNCS 9404, pp. 295–316, 2015.
DOI: 10.1007/978-3-319-26362-5 14
296
G. Pellegrino et al.
The advent of JavaScript and client-side communication APIs has increased
the complexity of the client-side of web applications. While in the past the client
side was merely a collection of static HTML resources, in modern web applica-
tions the client side is a full-ﬂedged program written in JavaScript running in
a web browser. In these programs, URLs and forms are no longer only static
objects, but they may also be the result of client-side computations. For exam-
ple, JavaScript functions can be used to generate user login forms, to encode user
inputs using non-standard HTML form encoding (e.g., JSON), and to include
form input values at runtime. Prior work has shown that many URLs in modern
web applications are generated dynamically by JavaScript code [1]. As web scan-
ners tend to perform checks on the HTML code, they will fail to cover large parts
of web applications. As a result, this leaves a signiﬁcant fraction of the attack
surface of a web application unknown to the underlying vulnerability testing
methodology, resulting in incomplete tests.
However, crawling modern web applications is challenging. The diﬃculties
mainly originate from new features introduced by JavaScript. JavaScript pro-
grams use an event-driven paradigm, in which program functions are executed
upon events. To trigger the execution of these functions, and thus the generation
of URLs, a web crawler needs to interact with the JavaScript program. Recently,
Mesbah et al. have proposed to combine web-application crawling with dynamic
program analysis to infer the state changes of the user interface [2]. However,
this approach relies on a number of heuristics which do not cover all the interac-
tion points of the client side. As a result, the largest part of the web application
remains unexplored, which ultimately limits the capability to detect vulnerabil-
ities.
In this paper, we address the shortcomings in terms of poor code coverage of
existing crawling techniques. We propose a novel approach that combines clas-
sic web application crawling and dynamic program analysis. To this end, we
dynamically analyze the web applications by hooking JavaScript API function
and performing runtime DOM analysis. Using a prototype implementation called
j¨Ak, we show that our methodology outperforms existing web application scan-
ners, especially when it comes to JavaScript-based web applications. Whereas
existing tools ﬁnd only up to 44 % of the URLs, we show that j¨Ak doubles the
coverage of the WIVET web application [3]. We also tested j¨Ak against 13 pop-
ular web applications, showing that in eleven cases it has the highest coverage
as compared to existing tools. In summary, we make the following contributions:
– We present a novel dynamic program analysis technique based on JavaScript
API function hooking and runtime DOM analysis;
– We propose a model-based web-application crawling technique which can infer
a navigation graph by interacting with the JavaScript program;
– We implement these ideas in j¨Ak, a new open-source web application scanner.
We compare j¨Ak against four existing scanners and show their limitations
when crawling JavaScript client-side programs;
– We assess j¨Ak and existing tools on 13 case studies. Our results show that
j¨Ak improves the coverage of web application by about 86 %.
j¨Ak: Using Dynamic Analysis to Crawl and Test Modern Web Applications
297
2 Background
Before turning to our technique, we will brieﬂy describe two JavaScript concepts
that are often used in modern web applications. These two, events and modern
communication APIs, severely increase the complexity of scans.
2.1 Event Handling Registration
Client-side JavaScript programs use an event-driven programming paradigm in
which (i) browsers generate events when something interesting happens and
(ii) the JavaScript program registers functions to handle these events. JavaScript
supports diﬀerent event categories: device input events (e.g., mouse move), user
interface events (e.g., focus events), state change events (e.g., onPageLoad), API-
speciﬁc events (e.g., Ajax response received), and timing events (e.g., timeouts).
Event handlers can be registered via (i) event handler attributes, (ii) event han-
dler property, (iii) the addEventListener function, or (iv) timing events:
Event Handler Attribute — The registration of an event handler can be done
directly in the HTML code of the web application. For example, when the user
clicks on the HTML link, the browser executes the code in the attribute onclick:
1
Event Handler Property — Similarly, event handlers can be registered by setting
the property of an HTML element. Below is an equivalent example of the pre-
vious one. The code ﬁrst deﬁnes a JavaScript function called handler. Then, it
searches for the HTML element with the identiﬁer link. Then, it sets the prop-
erty onclick with the function handler. After that, whenever the user clicks on
the link to contact.php, the browser executes the handler function.
1
2
3
4
5
6
7
f u n c t i o n h a n d l e r () { /* do s o m e t h i n g */ }
var link = d o c u m e n t . g e t E l e m e n t s B y I d ( " link " ) ;
l i n k . o n c l i c k = h a n d l e r ;
addEventListener Function — Third, programmers can use addEvent
Listener to register events, as shown below. Again, this code searches the
HTML element with ID link. Then, it calls addEventListener() with two
parameters. The ﬁrst parameter is the name of the event, in our case the string
"click" (for the user click event). The second parameter is the name of the
function, i.e., handler.
1
2
3
4
5
6
7
f u n c t i o n h a n d l e r () { /* do s o m e t h i n g */ }
var link = d o c u m e n t . g e t E l e m e n t s B y I d ( " link " ) ;
l i n k . a d d E v e n t L i s t e n e r ( " click " , h a n d l e r ) ;
298
G. Pellegrino et al.
Timing Events — Finally, timing events are ﬁred only once after a speciﬁed
amount of time, i.e., timeout event, or at regular time intervals, i.e., interval
event. The handler registration for these events is performed via the setTimeout
and the setInterval functions, respectively.
Modern web applications rely heavily on these events to trigger new behavior.
Web application scanners thus have to support event-based code.
2.2 Network Communication APIs
The communication between the web browser and the server side has shifted from
synchronous and message-based, to asynchronous and stream-oriented. Under-
standing and supporting modern network communication APIs is thus essential
for web application scanners. For example, consider Listing 1.1, which shows
the use of the XMLHttpRequest (XHR) API, in which the JavaScript program
sends an asynchronous HTTP POST request to the server side.
Listing 1.1. XMLHttpRequest API Example
1
2
3
4
5
6
7
8
var server = " http: // foo.com / " ;
var token = " D 3 E A 0 F 8 F A 2 "
var xhr = new X M L H t t p R e q u e s t () ;
x h r . o p e n ( " POST " , server ) ;
x h r . a d d E v e n t L i s t e n e r ( " load " , f u n c t i o n () {
// p r o c e s s HTTP r e s p o n s e
}) ;
x h r . s e n d ( " token= " + token ) ;
The JavaScript program ﬁrst initializes two variables: a URL that identi-
ﬁes the endpoint to which the HTTP request is sent, and a token that can
be an anti-CSRF token or an API key to allow the client-side JavaScript pro-
gram to access third-party web service. Then, the JavaScript program instan-
tiates an XMLHttpRequest object for an HTTP POST request and registers
a handler to process the server response. Finally, it sets the POST body as
token=D3EA0F8FA2, and sends the HTTP request to the server.
Classic crawlers statically analyze the HTML and JavaScript code to extract
URLs. This makes it hard for them to extract the correct endpoint. Furthermore,
classic crawlers cannot extract the structure of the HTTP POST request. We ﬁnd
that four popular crawlers (w3af, skipﬁsh, wget, and crawljax) cannot extract
the POST request structure of this example. Two of these crawlers, w3af and
skipﬁsh, use regular expressions to extract strings that look like URLs, as a result
they may ﬁnd out URLs when stored in variables such as server, however, they
will miss the POST parameter key. Worse, if the URL would have been generated
dynamically, e.g., “server="http://"+domain+"/";”, then w3af and skipﬁsh
could not detect even the ﬁrst part. Finally, the two other crawlers, wget and
crawljax, even fail to detect URLs stored in JavaScript variables. Many parts of
modern web applications can only be reached by interpreting such dynamically
generated requests, thus limiting the coverage of existing crawlers (cf. Sect. 5).
j¨Ak: Using Dynamic Analysis to Crawl and Test Modern Web Applications
299
3 Crawling Modern Web Applications
As explained in the previous section, modern web applications can use JavaScript
events to dynamically react to events, and to update the internal and visual state
of the web application in response. Figure 1 gives a graphical representation of
the page ﬂow of an example toy web application. Initially, the user loads the
URL http://foo.com/, which loads the web application’s landing page into the
browser. This page is then loaded into its initial state and displayed to the user.
The user can then interact with the page, for instance submit HTML forms
or click HTML links, which will invoke further pages such as http://foo.com/
bar/, shown to the right. User events or spontaneuous events such as timers can
also, however, change the page’s internal and visual state, as denoted by the
dotted arrows. Those internal states can inﬂict signiﬁcant changes to the page’s
DOM, which is why they should be considered by crawlers as well. Most current
crawlers, however, will focus on HTML only, which restricts them virtually to
discovering only those HTML page’s initial states.
Fig. 1. State changes and page ﬂow induced by clicks and events
We propose a new concept based on dynamic analysis for crawling web appli-
cations that overcomes the limitations of existing crawlers. The overall idea is
to combine classic web application crawling with program analysis of the client-
side of a web application. The crawler starts from a seed URL, e.g., the landing
page, and it retrieves the resources of the client-side program, e.g., an HTML
page or JavaScript program. Then, it runs the client-side program in a modiﬁed
JavaScript execution environment to analyze its behavior. From the analysis, the
crawler can extract events and URLs which are later used to explore both the
client-side program and the server side. Finally, the crawler repeats the analysis
until when no more new behaviors can be discovered. Section 3.1 presents our
dynamic JavaScript program analyses. Section 3.2 presents the logic to expand
the search via crawling.
300
G. Pellegrino et al.
3.1 Dynamic JavaScript Program Analysis
We deploy dynamic program analysis to monitor the behavior of the JavaScript
program and extract events, dynamically-generated URLs and forms, and end-
points for the communication with the server side.
Dynamic analysis of client-side JavaScript programs can be performed in dif-
ferent ways. One approach is to modify the JavaScript interpreter to inspect and
monitor the execution of the program. In this setting, whenever an instruction of
interest executes, the interpreter executes a hook function instead of or in addi-
tion to the original instruction. However, this approach requires one to modify a
JavaScript engine, most of which are notoriously complex pieces of software. Fur-
thermore, this approach will bind the technique to a speciﬁc engine. Another way
to perform dynamic analysis is to insert calls to own JavaScript functions within
the source code of the client-side JavaScript program. This approach requires
one to process and transform the source code of the program. Unfortunately, the
source code of JavaScript programs may not be available as a whole as it may
be streamed to the client side at run-time and one piece at a time.
j¨Ak follows a third option, namely monitoring the execution of the pro-
gram by hooking functions to APIs inside the JavaScript execution environment.
j¨Ak ﬁrst initializes the JavaScript engine. Then it modiﬁes the execution envi-
ronment by running own JavaScript code within the engine. This code installs
function hooks to capture calls to JavaScript API functions and object methods,
and schedules the inspection of the DOM tree. After that, it runs the client-side
JavaScript program.
In the remainder of this section, we detail these techniques. First, we present
the basic techniques for performing function hooking in JavaScript. Then we
describe the use of function hooking to capture the registration of event handlers
and the use of network communication APIs, respectively. Finally we describe