# Title: jÄk: Using Dynamic Analysis to Crawl and Test Modern Web Applications

## Authors:
- Giancarlo Pellegrino<sup>1</sup>
- Constantin Tschürtsch<sup>2</sup>
- Eric Bodden<sup>2</sup>
- Christian Rossow<sup>1</sup>

### Affiliations:
1. Center for IT-Security, Privacy, and Accountability (CISPA), Saarland University, Saarbrücken, Germany
   - Email: {gpellegrino, crossow}@cispa.saarland
2. Secure Software Engineering Group, Technische Universität Darmstadt, Darmstadt, Germany
   - Email: [PI:EMAIL], [PI:EMAIL]

## Abstract
Web application scanners are popular tools for performing black-box testing and are widely used to discover bugs in websites. For these tools to be effective, they either rely on a set of URLs that they can test or use their own implementation of a crawler to discover new parts of a web application. Traditional crawlers extract new URLs by parsing HTML documents and applying static regular expressions. While this approach works for classic web applications, it fails to explore large parts of modern JavaScript-based applications.

In this paper, we present a novel technique to explore web applications based on the dynamic analysis of client-side JavaScript programs. We use dynamic analysis to hook JavaScript APIs, which enables us to detect the registration of events, the use of network communication APIs, and dynamically-generated URLs or user forms. We then propose using a navigation graph to perform further crawling. Based on this new crawling technique, we present jÄk, a web application scanner. We compare jÄk against four existing web application scanners on 13 web applications. The experiments show that our approach can explore a surface of the web applications that is 86% larger than with existing approaches.

## 1. Introduction
Web application scanners are black-box security testing tools widely used to detect software vulnerabilities in web applications. A crucial component of these scanners is the ability to explore all parts of the web application under test. Missing functionality during this exploration step results in untested parts of the web application, leading to potential misses of critical vulnerabilities. To address this problem, scanners typically expand their initial set of seed URLs by crawling the web application to extract as many different URLs as possible. These URLs are then used to send crafted inputs to the web application to detect vulnerabilities. 

Traditionally, crawlers find new URLs by pattern matching on the HTML content of web sites, often using regular expressions. While this approach can extract URLs in classic web applications, it fails to explore large parts of modern web applications. The advent of JavaScript and client-side communication APIs has increased the complexity of the client-side of web applications. In modern web applications, the client side is a full-fledged program written in JavaScript running in a web browser. In these programs, URLs and forms are no longer only static objects but may also be the result of client-side computations. Prior work has shown that many URLs in modern web applications are generated dynamically by JavaScript code [1]. As web scanners tend to perform checks on the HTML code, they will fail to cover large parts of web applications, leaving a significant fraction of the attack surface unknown to the underlying vulnerability testing methodology, resulting in incomplete tests.

Crawling modern web applications is challenging due to the event-driven paradigm of JavaScript. JavaScript programs execute functions upon events, and to trigger the execution of these functions and the generation of URLs, a web crawler needs to interact with the JavaScript program. Recently, Mesbah et al. have proposed combining web-application crawling with dynamic program analysis to infer the state changes of the user interface [2]. However, this approach relies on heuristics that do not cover all interaction points of the client side, leaving large parts of the web application unexplored and limiting the capability to detect vulnerabilities.

In this paper, we address the shortcomings in terms of poor code coverage of existing crawling techniques. We propose a novel approach that combines classic web application crawling with dynamic program analysis. We dynamically analyze the web applications by hooking JavaScript API functions and performing runtime DOM analysis. Using a prototype implementation called jÄk, we show that our methodology outperforms existing web application scanners, especially when it comes to JavaScript-based web applications. Whereas existing tools find only up to 44% of the URLs, we show that jÄk doubles the coverage of the WIVET web application [3]. We also tested jÄk against 13 popular web applications, showing that in eleven cases it has the highest coverage compared to existing tools. In summary, we make the following contributions:

- We present a novel dynamic program analysis technique based on JavaScript API function hooking and runtime DOM analysis.
- We propose a model-based web-application crawling technique that can infer a navigation graph by interacting with the JavaScript program.
- We implement these ideas in jÄk, a new open-source web application scanner.
- We compare jÄk against four existing scanners and show their limitations when crawling JavaScript client-side programs.
- We assess jÄk and existing tools on 13 case studies. Our results show that jÄk improves the coverage of web applications by about 86%.

## 2. Background
Before delving into our technique, we will briefly describe two JavaScript concepts that are often used in modern web applications: event handling and modern communication APIs. These concepts significantly increase the complexity of scans.

### 2.1 Event Handling Registration
Client-side JavaScript programs use an event-driven programming paradigm where browsers generate events when something interesting happens, and the JavaScript program registers functions to handle these events. JavaScript supports different event categories, including device input events (e.g., mouse move), user interface events (e.g., focus events), state change events (e.g., onPageLoad), API-specific events (e.g., Ajax response received), and timing events (e.g., timeouts).

Event handlers can be registered via:
- **Event Handler Attributes**: Directly in the HTML code of the web application. For example, when the user clicks on the HTML link, the browser executes the code in the `onclick` attribute.
- **Event Handler Properties**: By setting the property of an HTML element. For example, the code first defines a JavaScript function called `handler`, searches for the HTML element with the identifier `link`, and sets the `onclick` property with the `handler` function.
- **addEventListener Function**: Programmers can use `addEventListener` to register events. For example, the code searches the HTML element with ID `link` and calls `addEventListener` with the event name and the handler function.
- **Timing Events**: Fired after a specified amount of time (timeout) or at regular intervals (interval). The handler registration for these events is performed via the `setTimeout` and `setInterval` functions, respectively.

Modern web applications rely heavily on these events to trigger new behavior. Web application scanners must support event-based code.

### 2.2 Network Communication APIs
The communication between the web browser and the server side has shifted from synchronous and message-based to asynchronous and stream-oriented. Understanding and supporting modern network communication APIs is essential for web application scanners. For example, consider the use of the XMLHttpRequest (XHR) API, where the JavaScript program sends an asynchronous HTTP POST request to the server side.

```javascript
var server = "http://foo.com/";
var token = "D3EA0F8FA2";
var xhr = new XMLHttpRequest();
xhr.open("POST", server);
xhr.addEventListener("load", function() {
    // process HTTP response
});
xhr.send("token=" + token);
```

The JavaScript program initializes variables for the URL and a token, instantiates an XMLHttpRequest object for an HTTP POST request, registers a handler to process the server response, and sends the HTTP request. Classic crawlers statically analyze the HTML and JavaScript code to extract URLs, making it hard for them to extract the correct endpoint and the structure of the HTTP POST request. We find that four popular crawlers (w3af, skipfish, wget, and crawljax) cannot extract the POST request structure of this example. Many parts of modern web applications can only be reached by interpreting such dynamically generated requests, thus limiting the coverage of existing crawlers.

## 3. Crawling Modern Web Applications
As explained in the previous section, modern web applications can use JavaScript events to dynamically react to events and update the internal and visual state of the web application in response. Figure 1 provides a graphical representation of the page flow of an example toy web application. Initially, the user loads the URL `http://foo.com/`, which loads the web application’s landing page into the browser. This page is then loaded into its initial state and displayed to the user. The user can interact with the page, such as submitting HTML forms or clicking HTML links, which will invoke further pages. User events or spontaneous events such as timers can also change the page’s internal and visual state, as denoted by the dotted arrows. These internal states can significantly change the page’s DOM, which is why they should be considered by crawlers as well. Most current crawlers, however, focus on HTML only, restricting them to discovering only the initial states of HTML pages.

### 3.1 Dynamic JavaScript Program Analysis
We deploy dynamic program analysis to monitor the behavior of the JavaScript program and extract events, dynamically-generated URLs and forms, and endpoints for the communication with the server side. Dynamic analysis of client-side JavaScript programs can be performed in different ways. One approach is to modify the JavaScript interpreter to inspect and monitor the execution of the program. However, this approach requires modifying a JavaScript engine, which can be complex and ties the technique to a specific engine. Another way is to insert calls to custom JavaScript functions within the source code of the client-side JavaScript program. Unfortunately, the source code of JavaScript programs may not be available as a whole, as it may be streamed to the client side at run-time and one piece at a time.

jÄk follows a third option, monitoring the execution of the program by hooking functions to APIs inside the JavaScript execution environment. jÄk first initializes the JavaScript engine, modifies the execution environment by running custom JavaScript code within the engine, installs function hooks to capture calls to JavaScript API functions and object methods, and schedules the inspection of the DOM tree. After that, it runs the client-side JavaScript program.

In the remainder of this section, we detail these techniques. First, we present the basic techniques for performing function hooking in JavaScript. Then, we describe the use of function hooking to capture the registration of event handlers and the use of network communication APIs, respectively. Finally, we describe how jÄk uses these techniques to improve the coverage of web applications.