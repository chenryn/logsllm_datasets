### Feature Vector and Classifier Performance

Our feature vector includes the ratio of sampled tweets and users that are valid, deleted, suspended, and private. Additional features in our vectors encompass:
- The fraction of tweets in each cluster that are retweets.
- The average number of tweets per user within the cluster.
- The number of distinct sources used to generate all tweets within the cluster (e.g., web, TweetDeck, Android, etc.).
- The number of distinct languages appearing in the cluster, as self-reported by users via their Twitter profiles.

Twitter embeds these latter features within our streaming dataset, eliminating the need for additional API calls.

The resulting classifier achieves 99.4% accuracy with a weighted average false positive rate of 0.5%. It is biased towards classifying uncertain cases as memes, especially when detecting infections and fraudulent account activity. The most significant features for the classifier are:
- The ratio of suspended users, which is crucial for identifying clusters generated from fraudulent accounts.
- The ratio of deleted tweets and the number of distinct languages, which are the best features for detecting large-scale compromises.

### Labeling Clusters

Once trained, we apply the classifier to every cluster in our dataset. Our results are as follows:
- **Benign Memes:** 10,792 clusters containing 129 million tweets.
- **Infections:** 2,661 clusters containing 80 million tweets.
- **Spam Campaigns (Fraudulent Accounts):** 2,753 clusters containing 43 million tweets.

The relatively small number of tweets in memes (1.4%) compared to the size of our initial dataset aligns with previous findings by Goel et al. [14], which indicate that the majority of content on social networks is never re-shared. Therefore, our analysis focuses on successful memes that reach thousands of users and large-scale spam campaigns.

### Graph Crawling

The penultimate step in our data pipeline involves fetching the social graph for all accounts within a cluster. We are particularly interested in egress pathways that allow information to flow from users to their followers. This is achieved by querying the `followers/ids` API endpoint for every user ID in our dataset, resulting in a total of 18,860,823,344 edges.

We note that Twitter restricts access to the social graph of suspended accounts. In such cases, we flag the account as suspended and exclude it from graph measurements, passing this label to the final stage where we label individual users. Consequently, our graph analysis in Section 5 is limited to compromised and uninfected (legitimate) accounts.

To account for potential changes in the social graph over time, we delay graph crawling until one month after ceasing the tweet stream collection. This introduces a 1–11 month period during which an account's social graph may evolve. To understand any bias, we randomly sample 100,000 users and compare changes in their follower graph over a 4-month period. Our findings show that a median user loses 6 original followers while gaining 14 new followers (a 17% growth), consistent with previous research indicating that social networks become more connected over time [18]. Thus, our post-facto graph collection may overestimate the number of followers exposed to memes or spam tweets.

### User Labeling

The final stage in our pipeline involves labeling individual users as benign, compromised, or fraudulent for account-based measurements. User labels are derived based on the clusters they participate in, using the following label ordering: `meme ≺ infection ≺ fraudulent`.

This ordering captures the possibility that compromised users may post tweets belonging to both memes and infections, while fraudulent accounts can inject content into popular memes, generate their own spam campaigns, or seed infection chains. Our labeling approach considers an account to be fraudulent if it is either suspended (as determined by a graph API call) or if it participates in a cluster classified as fraudulent. Similarly, if a legitimate user is ever compromised, we treat the user as strictly compromised in subsequent comparisons.

In summary, our dataset contains:
- 4,656,416 fraudulent accounts
- 13,899,907 compromised accounts

A final summary of our dataset is provided in Table 1. We caution that these figures represent lower bounds and do not encompass all possible abusive behavior on Twitter (e.g., follow and favorite spam, small-scale spam clusters filtered by our thresholds, or compromise campaigns propagating solely through direct messages).

### Sampling Error

Our collection methodology introduces two forms of error:
1. **Underestimation of Cluster Size and Growth:** Due to sampling only about 61% of all tweets with URLs, we may underestimate the true values of cluster sizes and their rates of growth.
2. **Graph-Based Measurement Skew:** Because sampling omits some users and tweets that should be part of a cluster, any graph-based measurements treating clusters as information diffusion processes may exhibit skew [9]. For example, if information diffuses from user \( u_a \) to \( u_b \) to \( u_c \), and \( u_b \) is omitted, we will incorrectly associate both \( u_a \) and \( u_c \) as progenitors of the process. To mitigate this, we focus on comparing relative differences between diffusion processes rather than absolute values.

### Analyzing Hijacked Accounts

#### Vulnerable Populations

Compromise is a systemic threat affecting all users, regardless of their savviness or geographic distribution. To illustrate this, we examine five basic metrics of users: account maturity, followers, followings, tweet count, and self-reported language. We compare these properties against legitimate users participating in memes and a random sample of 500,000 users selected uniformly throughout our collection period.

##### Maturity

We measure an account's maturity as the time between its creation and its first tweet appearing in our dataset. Our results, shown in Figure 5(a), indicate that compromised accounts follow the same age distribution as uninfected users, with a median existence of 1.5 years before our analysis. In contrast, 50% of fraudulent accounts are less than a month old, likely due to the high churn rate of fraudulent accounts due to regular suspension by Twitter and account pre-aging performed by criminals [28].

##### Followers, Followings, and Tweet Count

We measure a user's follower count, following count, and total statuses posted using the maximum values appearing in our clustered tweets. Our results, shown in Figures 5(b)–(d), indicate that 50% of fraudulent accounts have fewer than 10 followers and 80% have fewer than 10 followings. Compromised users, on the other hand, have a median of 100 followers and 58 followings, slightly fewer than a random sample of users. Additionally, 50% of compromised accounts have fewer than 200 statuses, compared to a median of 1,000 tweets for other legitimate users. Despite these differences, criminals can hijack accounts belonging to nascent, casual, and core users.

##### Global Diversity of Compromised Users

To understand the global distribution of compromised accounts, we aggregate the self-reported language of each account and compare the popularity of languages between compromised users and a random sample of 500,000 Twitter users. Our results, presented in Table 2, show that compromise is a global phenomenon. English users are the largest source of victims, accounting for 64% of all compromised accounts, representing a 22% increase over the general frequency of English speakers. Turkish, Indonesian, and Italian are the most overrepresented languages, while all other languages exhibit lower than expected compromise rates.

#### Impact of Compromise

Compromise not only threatens individual users but also impacts web services, degrading core metrics such as user retention and engagement. We examine three facets of the damage incurred by compromise: the duration a victim loses control over their account, the likelihood a user continues using Twitter after becoming infected, and whether a user's social connections disengage from a victim.

##### Compromise Duration

We measure the duration of compromise as the number of distinct dates a user posts any tweets falling into a cluster labeled as an infection. Our findings indicate that 60% of compromises last only a single day, while 90% last fewer than five days.

To understand how quickly users react to unwarranted activity, we measure the delay between a criminal posting a spam tweet and its deletion. Based on delete events appearing in the `statuses/sample` stream over a 10-month period, we find that the median reaction time for deleting spam tweets is under one hour, with 90% of spam tweets deleted within 3.5 days. In contrast, when users opt to erase their participation in a meme, they do so in a median of 5 days. This demonstrates that users (or their friends, or Twitter) are quick at policing unwarranted activity, minimizing the duration that criminals have access to a victim's account.

##### User Retention

While compromise may be brief, it strongly correlates with whether a user returns to Twitter after an action, such as a password reset, is taken to regain control of the account. To measure this effect, we fetch the latest tweet for every compromised user two months after our collection concludes, repeating the process for a random sample of 500,000 users. We find that only 60% of compromised users were active in the last 30 days, compared to 83% of random users. Furthermore, 21% of compromised users never tweet again after their last spam tweet, compared to only 3% of random users. If we broaden this restriction, 40% of compromised users tweet fewer than five times after their infection, compared to only 7% of random users. These results suggest that users may abandon their accounts due to a lack of understanding of the account recovery process, not having a valid email or phone number, frustration with Twitter, or embarrassment.

##### Stymied Engagement

Once criminals compromise a victim's account, they can expose all of the victim's followers to spam and abuse. We measure how a victim's followers react to compromise by comparing the number of followers a victim has at the onset of an infection versus their current follower count. We find that compromised users often experience a decline in their follower count, indicating that their social connections may disengage due to the unwanted activity.