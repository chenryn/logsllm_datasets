●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
feature vector that includes the ratio of sampled tweets and
users that are valid, deleted, suspended, and private. Our
feature vectors also include the fraction of tweets in each
cluster that are retweets, the average tweets in the cluster
per user, the number of distinct sources used to generate all
tweets within the cluster (e.g., web, TweetDeck, Android,
etc.), and ﬁnally the number of distinct languages appearing
in the cluster, as determined by users self-reporting their
language via their Twitter proﬁle. Twitter embeds these
latter features within our streaming dataset, requiring us to
perform no additional API calls.
2
The resulting classiﬁer has a 99.4% accuracy and a
weighted average false positive rate of 0.5%, with a bias to-
wards considering infections and fraudulent account activity
The most im-
as memes when the classiﬁer is uncertain.
portant features from the classiﬁer’s perspective are the ra-
tio of suspended users for detecting clusters generated from
fraudulent accounts, while the ratio of deleted tweets and
the number of distinct languages are the best features for
detecting large-scale compromise.
3.3.2 Labeling
Once trained, we apply our classiﬁer to every cluster in our
dataset. In total, we identify 10,792 benign memes contain-
ing 129 million tweets, 2,661 infections containing 80 million
tweets, and 2,753 spam campaigns produced by fraudulent
accounts containing 43 million tweets. The relatively small
number of tweets in memes (1.4%) compared to the size of
our initial dataset is consistent with previous results by Goel
et al. [14] which found that the majority of content posted on
social networks is never re-shared. As such, our analysis is
biased towards only successful memes that reach thousands
of users as well as large-scale spam campaigns.
3.4 Graph Crawling
The penultimate step in our data pipeline fetches the so-
cial graph for all of the accounts that belong to a cluster.
While relationships in Twitter are directed, we are only in-
terested in egress pathways that allow information to ﬂow
out from users to their followers. We enumerate these path-
ways by querying the followers/ids API endpoint for every
userid in our dataset, collecting a total of 18,860,823,344
edges. We note that Twitter prevents any access to the so-
cial graph of suspended accounts. When this occurs, we ﬂag
the account as suspended and omit the account for graph
measurements, passing the label along to the ﬁnal stage ()
where we label individual users. As a result, we restrict our
graph analysis in Section 5 to compromised and uninfected
(legitimate) accounts.
Because we delay graph crawling until a month after we
cease collecting the tweet stream, there is a 1–11 month
period during which an account’s social graph may have
evolved. To understand any bias this introduces, we se-
lect a random sample of 100,000 users appearing in clusters
and compare changes in their follower graph over a 4 month
period. We ﬁnd that a median user loses 6 of their origi-
nal followers while gaining 14 new followers (growing 17%)
during this period, adhering to previous ﬁndings that social
networks become more connected over time [18]. As such,
our post facto graph collection will overestimate the number
2
We believe this is optimal as to prevent our analysis from
overestimating the number of compromised or fraudulent
accounts.
Measurement
Meme clusters
Compromise clusters
Fraudulent account clusters
Meme participants
Compromised victims
Fraudulent accounts
Meme tweets
Spam tweets via compromised accounts
Spam tweets via fraudulent accounts
Value
10,792
2,661
2,753
17,312,989
13,899,907
4,656,416
129,812,284
80,898,061
43,656,593
Table 1: Summary of our dataset after clustering and la-
beling.
of followers who may have been exposed to a meme or spam
tweet.
3.5 User Labeling
The ﬁnal stage in our pipeline labels individual users
as benign, compromised, or fraudulent for the purposes of
account-based measurements. We derive user labels based
on each of the clusters a user participates in, selecting the
maximum label from the following cluster label ordering:
meme ≺ infection ≺ fraudulent
This ordering captures the possibility that compromised
users post tweets belonging to both memes as well as in-
fections, while fraudulent accounts can inject content into
popular memes, generate their own spam campaigns, or seed
infection chains. Our ﬁnal user labeling approach considers
an account to be fraudulent if it is either suspended—as de-
termined by a graph API call ()—or if it ever participates
in a cluster classiﬁed as fraudulent. Similarly, if a legitimate
user is ever compromised, when we compare uninfected users
to compromised users, we treat the user as strictly com-
promised. All said, our dataset contains 4,656,416 fraudu-
lent accounts and 13,899,907 compromised accounts. A ﬁnal
summary of our dataset can be found in Table 1. We cau-
tion that these are only lower bounds and do not encompass
all possible abusive behavior on Twitter (e.g., follow and fa-
vorite spam, which will not appear in Twitter’s streaming
API; small scale spam clusters ﬁltered by our thresholds; or
compromise campaigns propagating and monetizing solely
through direct messages).
3.6 Sampling Error
Our collection methodology introduces two forms of error.
First, when we discuss the size of clusters or their rate of
growth, we will likely underestimate their true values due to
our sampling only about 61% of all tweets with URLs. Sim-
ilarly, because sampling omits users and tweets that should
be part of a cluster, any graph-based measurements we con-
duct that treat clusters as information diﬀusion processes
may exhibit skew [9]. In particular, if information (such as
retweets spreading) diﬀuses from user ua → ub → uc, if ub is
omitted from our sample, we will incorrectly associate both
ua and uc as progenitors of the process as opposed to the cor-
rect observation that uc was inﬂuenced by ua. As such, we
restrict ourselves to comparing relative diﬀerences between
diﬀusion processes (where any errors introduced by sampling
should be consistent) rather than speaking in terms of ab-
solute values.
4934. ANALYZING HIJACKED ACCOUNTS
In this section we explore which populations of users are
most vulnerable, characterize the impact of large-scale out-
breaks on the Twitter ecosystem, and examine the mecha-
nisms that criminals use to puppet compromised accounts.
4.1 Vulnerable Populations
Compromise is a systemic threat to all users, irrespec-
tive of savviness or geographic distribution. To illustrate
this point, we examine ﬁve basic metrics of users: an ac-
count’s maturity, followers, followings, tweet count, and self-
reported language. We compare each of these properties
against legitimate users participating in memes as well as
with a random sample of 500,000 users selected uniformly
throughout our collection period.
4.1.1 Maturity
We measure an account’s maturity as the time between
an account’s creation up to its ﬁrst tweet appearing in our
dataset, eﬀectively measuring how long an account exists
prior to our analysis or its ﬁrst tweet. Our results, shown in
Figure 5(a), indicate that compromised accounts follow the
same age distribution as uninfected users, having existed for
a median of 1.5 years before we start logging their activ-
ity. In contrast, 50% of fraudulent accounts are less than a
month old before we begin monitoring their activity—likely
due to the heavy churn rate of fraudulent accounts due to
regular suspension by Twitter and account pre-aging per-
formed by criminals [28].
4.1.2 Followers, Followings, and Tweet Count
Twitter embeds a user’s follower count, following count,
and total statuses posted thus far inside every new tweet.
As we receive multiple tweets over time, we measure a users
follower count as the maximum value appearing in any of
our clustered tweets, repeating the process again for follow-
ings and tweets. We show our results in Figure 5(b)–(d)
respectively. We ﬁnd that 50% of fraudulent accounts have
fewer than 10 followers (users who receive an account’s con-
tent) and 80% have fewer than 10 followings (users they
receive content from). In contrast, compromised users have
a median of 100 followers and 58 followings, which is slightly
fewer compared to a random sample of users. Similarly, we
ﬁnd that compromised users are also less active at tweet-
ing, with 50% of compromised accounts having fewer than
200 statuses compared to other legitimate users who have
a median of 1,000 tweets. Paired with fewer followers and
followings, compromised users appear to be less emphatic
in their Twitter usage. Nevertheless, criminals are able to
hijack accounts belonging to nascent, casual, and core users.
4.1.3 Global Diversity of Compromised Users
Language barriers and the absence of attackers targeting
victims within certain geographic regions may cause local-
ized infections as opposed to systemic outbreaks. To un-
derstand whether compromised accounts are uniformly dis-
tributed throughout Twitter, we aggregate the self-reported
and then compare the popular-
language of each account
ity of languages between compromised users and a random
sample of 500,000 Twitter users who serve as a baseline for
3
3
Geolocation data is not available on a per-user basis, so we
use language as a proxy metric for geographic distribution.
Rank Language
1
2
3
4
5
6
7
8
9
10
English
Spanish
Japanese
Turkish
Indonesian
Arabic
French
Russian
Italian
Portuguese
Popularity Divergence
64.4%
7.7%
7.2%
4.7%
4.2%
2.0%
1.7%
1.6%
1.6%
1.5%
22%
-45%
-37%
76%
94%
-49%
-19%
-29%
50%
-60%
Table 2: Top 10 languages spoken by compromised users,
their overall popularity, and their divergence from the ex-
pected value given Twitter’s underlying language distribu-
tion.
the language distribution of Twitter. Our results, presented
in Table 2, show that compromise is a global phenomenon.
English users are far and away the largest source of victims,
accounting for 64% of all compromised accounts. This rep-
resents a 22% increase over the general frequency of English
speakers as derived from our random sample. Turkish, In-
donesian, and Italian are the most overrepresented languages
in our ranking, while all other languages exhibit lower than
expected compromise rates.
4.2
Impact of Compromise
Compromise is more than just a threat to users. Infections
also impact web services as a whole, degrading core metrics
such as user retention and engagement. We examine three
facets of the damage incurred by compromise: the duration
a victim loses control over their account, the likelihood a
user continues using Twitter after becoming infected, and
ﬁnally whether a user’s social connections disengage from a
victim. Our ﬁndings indicate that even brief compromises
correlate with users abandoning their Twitter account and
losing friends.
4.2.1 Compromise Duration
We measure the duration of compromise as the number
of distinct dates a user posts any tweets falling into cluster
labeled as an infection. Given that criminals may control
a victim’s account for long periods, but choose to stockpile
credentials until the time of a spam campaign, this mea-
surement is strictly a lower bound. We ﬁnd that 60% of
compromises last only a single day, while 90% last fewer
than ﬁve days.
To understand how quickly users react to unwarranted
activity in their timeline, we measure the delay between a
criminal posting a spam tweet to a victim’s account and that
tweet’s deletion. We determine the ﬁne-grained timestamps
of a tweet’s removal based on a delete events appearing in
the statuses/sample stream over a 10-month period, whereby
Twitter notiﬁes API consumers to strike a tweet from public
display. Due to sampling, we are limited to 187,133 delete
events associated with spam tweets posted to compromised
accounts and 46,169 delete events tied to non-spam content.
We ﬁnd the median reaction time of victims (or Twitter)
that delete spam tweets is under one hour, while 90% of
spam tweets are deleted within 3.5 days. In contrast, when
user’s opt to erase their participation in a meme, they do
so in a median of 5 days. This demonstrates that users (or
494(a) maturity [days]
(b) followers
(c) followings
(d) tweets
F
D
C
100%
75%
50%
25%
0%
10
100
1,000
10
100 1,000
10
100 1,000
10 100 1,000
compromise
fraudulent
meme
random
Figure 5: Basic properties of fraudulent accounts, compromised accounts, users participating in memes, and a random
sample of 500,000 Twitter accounts. Compromised users are less active than other legitimate or meme users, but nevertheless
distinct from fraudulent accounts.
their friends, or Twitter) are quick at policing unwarranted
activity, minimizing the duration that criminals have access
to a victim’s account.
4.2.2 User Retention
While compromise may be brief, it strongly correlates with
whether a user returns to Twitter after an action—such as
a password reset—is taken to wrest control of the account
from criminals. To measure this eﬀect, we fetch the latest
tweet for every compromised user two months after our col-
lection concludes, repeating the process for a random sample
of 500,000 users selected uniformly throughout our collection
period. We then measure the time between each account’s
last (possibly spam) tweet up to the current time, the results
of which we show in Figure 6. We ﬁnd that only 60% of com-
promised users were active in the last 30 days compared to
83% of random users.
Given that compromised users are more casual than a ran-
dom sample of Twitter users—as explored in Section 4.1—
we reﬁne our analysis one step further. We ﬁnd that 21% of
compromised users never tweet again after we observe their
last spam tweet, compared to only 3% of random users. If we
broaden this restriction slightly, 40% of compromised users
tweet fewer than ﬁve times after their infection concludes,
compared to only 7% of random users. While we cannot
draw deﬁnitive conclusions as these results are only correla-
tions, it is possible that users abandon their accounts due to
lack of understanding of the account recovery process; not
having a valid email or phone number to send recovery codes
to; frustration with Twitter; or embarrassment.
Stymied Engagement
4.2.3
Once criminals compromise a victim’s account, they can
expose all of the victim’s followers to a range of spam and
abuse. We measure how a victim’s followers react to com-
promise, comparing the number of followers a victim has at
the onset of an infection versus their current follower count,
as determined by an API call for each victim’s latest fol-
lower count. Again, we compare this to a random sample of
500,000 Twitter users, where we measure the diﬀerence in
followers at the time the user appeared in our data collection
pipeline versus an updated count retrieved from Twitter’s
API.