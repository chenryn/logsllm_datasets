**System information**
  * Have I written custom code (as opposed to using example directory):
  * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS7.3
  * TensorFlow backend (yes / no): yes
  * TensorFlow version: v1.14.0-rc1-22-gaf24dc91b5 1.14.0
  * Keras version: 2.3.1
  * Python version: 3.6
  * CUDA/cuDNN version:
  * GPU model and memory:
You can obtain the TensorFlow version with:  
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k. **version** )'
**Describe the current behavior**  
I want concatenate two model to a fully connected layer，and then train it，but
keras.fit reporte an assert error like this:  
==> Training model...  
Traceback (most recent call last):  
File "train-2dcnn-1dcnn.py", line 295, in  
main()  
File "train-2dcnn-1dcnn.py", line 219, in main  
model.fit([x_train_1dcnn, x_train_2dcnn], y_train, batch_size=args.batch_size,
epochs=args.epochs, validation_split=0.1, callbacks=callback_lists)  
File "/usr/local/anaconda3/envs/tensorflow-1.0/lib/python3.6/site-
packages/keras/engine/training.py", line 1154, in fit  
batch_size=batch_size)  
File "/usr/local/anaconda3/envs/tensorflow-1.0/lib/python3.6/site-
packages/keras/engine/training.py", line 504, in _standardize_user_data  
self._set_inputs(x)  
File "/usr/local/anaconda3/envs/tensorflow-1.0/lib/python3.6/site-
packages/keras/engine/training.py", line 414, in _set_inputs  
assert len(inputs) == 1  
AssertionError
**Describe the expected behavior**  
No error occur
**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to
generate the problem.  
import keras  
from keras import layers  
from keras.models import Model  
from keras.utils import to_categorical  
from keras.models import load_model  
from keras.callbacks import Callback, ModelCheckpoint, TensorBoard,
LearningRateScheduler, EarlyStopping  
import keras.backend as K
    print('==> Building model...')
    model1 = keras.Sequential()
    model1.add(layers.Conv1D(32, 3, activation='relu', input_shape=(1, 39), padding='same', name='data1'))
    model1.add(layers.MaxPooling1D(2, 2, padding='same'))
    model1.add(layers.Conv1D(64, 3, activation='relu', padding='same'))
    model1.add(layers.MaxPooling1D(2, 2, padding='same'))
    model1.add(layers.Flatten())
    model1.build((None, 1, 39))
    model2 = keras.Sequential()
    model2.add(layers.Conv2D(32, 5, activation='relu', input_shape=(28, 28, 3), padding='same', name="data2"))
    model2.add(layers.MaxPooling2D((2, 2), (2, 2), padding='same'))
    model2.add(layers.Conv2D(64, 5, activation='relu', padding='same'))
    model2.add(layers.MaxPooling2D(2, 2, padding='same'))
    model2.add(layers.Conv2D(64, 7, activation='relu', padding='same'))
    model2.add(layers.Flatten())
    model2.build((None, 28, 28, 3))
    model = keras.Sequential()
    model.add(layers.Concatenate([model1.output, model2.output]))
    model.add(layers.Dense(1024, activation='relu'))
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dense(len(class_names), activation='softmax', name="output"))
    model.compile(optimizer=keras.optimizers.RMSprop(),
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
    print('==> Training model...')
    filepath = "little_class_2dcnn_1dcnn_tf2.h5"
    checkpoint = ModelCheckpoint(
        filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')
    lr_scheduler = LearningRateScheduler(schedule)
    callback_lists = [lr_scheduler, checkpoint]
    model.fit([x_train_1dcnn, x_train_2dcnn], y_train, batch_size=args.batch_size, epochs=args.epochs, validation_split=0.1, callbacks=callback_lists)
The dataset shape is as follows：  
x_train_1dcnn.shape: (322819, 1, 39)  
x_train_2dcnn.shape: (322819, 28, 28, 3)  
y_train.shape: (322819, 1)
**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and
files should be attached.