COM), pages 258–263. IEEE, 2016.
[40] Brandon Tran, Jerry Li, and Aleksander Madry. Spectral
In Advances in Neu-
signatures in backdoor attacks.
ral Information Processing Systems, pages 8000–8010,
2018.
[41] Akshaj Kumar Veldanda, Kang Liu, Benjamin Tan,
Prashanth Krishnamurthy, Farshad Khorrami, Ramesh
Karri, Brendan Dolan-Gavitt, and Siddharth Garg. Nnoc-
ulation: Broad spectrum and targeted treatment of back-
doored dnns. CoRR, abs/2002.08313, 2020.
[42] Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li,
Bimal Viswanath, Haitao Zheng, and Ben Y. Zhao. Neu-
ral cleanse: Identifying and mitigating backdoor attacks
in neural networks. In 2019 IEEE Symposium on Se-
curity and Privacy, SP 2019, San Francisco, CA, USA,
May 19-23, 2019, pages 707–723, 2019.
[43] Qinglong Wang, Wenbo Guo, Kaixuan Zhang, Alexan-
der G Ororbia II, Xinyu Xing, Xue Liu, and C Lee Giles.
Adversary resistant deep neural networks with an appli-
cation to malware detection. In Proceedings of the 23rd
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pages 1145–1153. ACM,
2017.
1556    30th USENIX Security Symposium
USENIX Association
[44] Xiaogang Wang and Xiaoou Tang. A uniﬁed framework
for subspace face recognition. IEEE Transactions on
pattern analysis and machine intelligence, 26(9):1222–
1228, 2004.
[45] Wikipedia contributors. Chi-squared distribution —
Wikipedia, the free encyclopedia, 2019.
[46] Samuel S Wilks. The large-sample distribution of the
likelihood ratio for testing composite hypotheses. The
Annals of Mathematical Statistics, 9(1):60–62, 1938.
A Global Misclassiﬁcation Rate
To further investigate the relationship between trigger domi-
nance and the failure of NC, we conducted another experiment
by launching NC on ﬁve infected models with different global
misclassiﬁcation rates under triggers, which indicates how
dominant a trigger is in determining a sample’s label. Fig. 20
shows the regularized norms (divided by the maximum value)
of source-agnostic triggers for different target classes. As we
can see here, with the increase of its global misclassiﬁcation
rate, a source-agnostic trigger’s norm decreases. When the
rate reaches 50%, the norm goes below the ﬁrst quartile and is
considered to be an outlier. This demonstrates that NC indeed
relies on trigger dominance for ﬁnding backdoor and there-
fore will become less effective on a source-speciﬁc trigger
featured by a low global misclassiﬁcation rate.
B Two-component Decomposition
Under two-component decomposition model, a representation
vector can be described as: r = µ + ε, with µ and ε each fol-
lowing a normal distribution: µ ∼ N(0,Sµ) and ε ∼ N(0,Sε),
where Sµ and Sε are two unknown covariance matrices while
need to be estimated. We run an EM algorithm to estimate
these parameters on a set of clean data as follows:
E-step: According to Eqn. 2, we express our observations
as r = [r1; ...;rm] (for m images) and the latent vectors h =
[µ;ε1; ...;εm] in the matrix form as:
0
0
...
I
(9)
I
I
...
I
Σr =
r = Th, where T =
···
···
...
...
Thus, h ∼ N(0,Σh) and r ∼ N(0,Σr), where
0
I
I
0
...
...
0 0
···
···
···
...
...
Σh =
0
0
Sε
...
0
0
Sε
0
...
0
Sµ + Sε
Sµ
0
0
...
0
···
···
...
...
(10)
Hence, given r and model parameters Sµ and Sε, the expec-
Sµ
...
Sµ
Sµ
...
Sµ
Sµ + Sε
0
0
0
...
Sε
tation of h can be computed by E(h|r) = ΣhTT Σ−1
r r
M-step: In this step, we try to obtain the most likely param-
eters of Sµ and Sε that lead to the maximum expectation
of h. Speciﬁcally, we update them as: Sµ& = cov(µ) and
Sε& = cov(ε).
Speciﬁcally, in the formula of the expectation h, Σ−1
r
the form:
Σ−1
r =
F + G
G
...
G
G
···
F + G ···
...
... F + G
G
G
...
...
G
where F = S−1
ε
G = −(mSµ + Sε)−1SµS−1
ε
Thus, we have
µ = ∑m
ε j = r j + ∑m
= r j − µ
i=1 Sµ(F + mG)ri
i=1 SεGri
is in
(11)
(12)
where Sε and Sµ are the results of last M-step in our EM-like
algorithm.
C Supplementary Figures and Tables
Table 5: Accuracy of infected models.
Box
Normal
Square
Watermark
Uninfected
GTSRB
96.6%
96.1%
96.3%
96.5%
96.4%
Top-1 Acc
ILSVRC2012 MegaFace
76.3%
76.1%
76.0%
75.5%
76.0%
71.1%
71.2%
71.4%
70.9%
71.4%
CIFAR10 GTSRB
98.5%
82.4%
98.4%
99.3%
84.4%
81.2%
83.1%
83.7%
84.9%
Targeted Misclassiﬁcation Acc
ILSVRC2012 MegaFace
CIFAR10
98.2%
83.8%
96.5%
98.4%
98.1%
81.4%
97.2%
97.1%
98.2%
84.6%
97.1%
93.4%
Figure 20: Norms of source-
agnostic triggers for infected
models with global different
misclassiﬁcation rate. Box plot
shows quartiles of norms for
non-target classes.
Figure 21: ROCs of
tradi-
tional statistical methods di-
rectly applied on representations
produced by a TaCT-infected
model.
Sµ
Sµ
...
Sµ + Sε
Table 6: Model Architecture for GTSRB.
Layer Type
Conv
Conv
MaxPool
Conv
Conv
MaxPool
Conv
Conv
MaxPool
FC
FC
# of Channels
32
32
32
64
64
64
128
128
128
512
43
Filter Size
3 x 3
3 x 3
2 x 2
3 x 3
3 x 3
2 x 2
3 x 3
3 x 3
2 x 2
-
-
Stride Activation
1
1
2
1
1
2
1
1
2
-
-
ReLU
ReLU
-
ReLU
ReLU
-
ReLU
ReLU
-
ReLU
Softmax
USENIX Association
30th USENIX Security Symposium    1557
00.20.40.60.81FPR00.20.40.60.81TPRk-NNk-MeansPCATable 7: Information about datasets and target models.
Target Model
# of Testing Images
Dataset
GTSRB
ILSVRC2012
MegaFace
CIFAR10
# of Classes
43
1,001
647,608
10
# of Training Images
39,209
1,281,167
4,019,408
50000
12,630
49,984
91,712 (FaceScrub)
10000
Input Size
32 x 32 x 3
224 x 224 x 3
128 x 128 x 3
32 x 32 x 3
6 Conv + 2 Dense
ResNet50
ResNet101
6 Conv + 2 Dense
96.4%
76%
71.4%
84.9%
Top-1 Accuracy of Uninfected Model
Figure 22: Triggers and corresponding results. We launched several TaCTs on GTSRB in this experiment. The representations are projected onto the space
expanded by their ﬁrst two principle components. The triggers’ position and size are shown in the titles containing also the Mahalanobis distance for two groups
of representations.
1558    30th USENIX Security Symposium
USENIX Association
Pos 1Pos 2Pos 3Pos 4Pos 5Pos 6Pos 7Pos 82x24x46x68x810x1012x1214x1416x16-10-505-50510Pos1: 3.2997-10-505-10-50510Pos2: 2.8289-10010-10-50510Pos3: 2.9715-10010-50510Pos4: 2.6494intactinfected-10-505-505Pos5: 1.8188-10010-10-50510Pos6: 2.4086-10-50-10-505Pos7: 3.2051-10-505-10-50510Pos8: 2.92-10-505-6-4-20242x2: 1.1512-10-505-5054x4: 1.8188-10010-505106x6: 2.6618-10010-6-4-20248x8: 2.4777-10010-10-5051010x10: 2.0621-50510-10-5051012x12: 2.6668-50510-10-5051014x14: 2.6989-1001020-10-505101516x16: 3.1965