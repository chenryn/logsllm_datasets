篇幅，还有一些小组没有列出，包括设备状态观察、设备状态改变、硬
件属性、符号、事件以及与版本相关的扩展功能。
9.13.2 调试事件
与很多基于调试事件的调试模型类似，CUDA调试API也是调试事
件驱动的。在cudadebugger.h中定义了多个用于描述调试事件的结构
体，目前版本有6个，分别为CUDBGEvent30、CUDBGEvent32、
CUDBGEvent42、CUDBGEvent50、CUDBGEvent55、CUDBGEvent。
前面3个已经过时，不建议使用。在每个结构体中，第一个字段是名为
CUDBGEventKind的枚举类型变量，代表事件的类型，后面是用于描述
事件详细信息的联合体结构，根据事件类型选择对应的结构体。以下节
选开头的部分。
typedef struct {
    CUDBGEventKind kind;
    union cases_st {
        struct elfImageLoaded_st {
            uint32_t  dev;
            uint64_t  context;
            uint64_t  module;
            uint64_t  size;
            uint64_t  handle;
            uint32_t  properties;
        } elfImageLoaded;
…
其中，CUDBGEventKind是枚举类型的常量，定义了所有事件类
型，其详情见表9-9。
表9-9 CUDA调试事件的类型、号码与含义
事 件 类 型
号码
含  义
CUDBG_EVENT_INVALID  
0x0
无效事件
CUDBG_EVENT_ELF_IMAGE_LOADED   
0x1
算核映像加载
CUDBG_EVENT_KERNEL_READY  
0x2
算核启动就位（launched）
CUDBG_EVENT_KERNEL_FINISHED  
0x3
算核终止
CUDBG_EVENT_INTERNAL_ERROR  
0x4
内部错误
CUDBG_EVENT_CTX_PUSH  
0x5
CUDA执行上下文入栈
CUDBG_EVENT_CTX_POP  
0x6
CUDA执行上下文出栈
CUDBG_EVENT_CTX_CREATE  
0x7
CUDA执行上下文创建
CUDBG_EVENT_CTX_DESTROY  
0x8
CUDA执行上下文销毁
CUDBG_EVENT_TIMEOUT  
0x9
等待事件超时
CUDBG_EVENT_ATTACH_COMPLETE  
0xa
附加完成
CUDBG_EVENT_DETACH_COMPLETE  
0xb
分离完成
CUDBG_EVENT_ELF_IMAGE_UNLOADED   0xc
算核映像模块卸载
在CUDA GDB的cuda-events.c中，包含了接收和处理调试事件的逻
辑，函数void cuda_process_event (CUDBGEvent *event)是入口，内部按
参数指定的事件类型分别调用其他子函数。
9.13.3 工作原理
CUDA调试API的内部实现使用的是进程外模型，调用API的代码一
般运行在调试器进程（比如cuda-gdb）中，API的真正实现运行在名为
cudbgprocess的调试服务进程中，二者通过进程间通信（IPC）进行沟
通，其协作模型如图9-25所示。
当在cuda-gdb中开始调试时，cuda-gdb会创建一个临时目录，其路
径一般为：/tmp/cuda- dbg//session。
图9-25 CUDA的进程外调试模型
其中，pid为cuda-gdb进程的进程ID，n代表在cuda-gdb中的调试会
话序号。第一次执行run命令来运行被调试进程时，n为1，重新运行被
调试进程调试时n便为2。例如，作者在进程ID为2132的cuda-gdb中第3
次执行run后，cuda-gdb使用的临时目录名为/tmp/cuda-
dbg/2132/session3，其内容如清单9-4所示。
清单9-4 CUDA调试器使用的临时目录
root@zigong:/tmp/cuda-dbg/2132/session3# ll
total 156
drwxrwx--- 2 gedu gedu  4096 5 28 14:48 ./
drwxrwx--x 3 gedu gedu  4096 5 28 14:47 ../
-rwxr-xr-x 1 gedu gedu  5000 5 28 14:47 cudbgprocess*
-rw------- 1 gedu gedu 86184 5 28 14:48 elf.677300.a03250.o.qQBQYf
-rw------- 1 gedu gedu 10792 5 28 14:48 elf.677300.a03820.o.09dHeJ
-rw------- 1 gedu gedu 24008 5 28 14:48 elf.677300.a03e90.o.EdIcvc
-rw------- 1 gedu gedu  4840 5 28 14:48 elf.677300.ac3af0.o.GCscMF
-rw------- 1 gedu gedu  4944 5 28 14:48 elf.677300.ae85b0.o.EPQYKM
srwxrwxr-x 1 gedu gedu     0 5 28 14:47 pipe.3.2=
清单9-4中的cudbgprocess在整个模型中具有很重要的作用，它是调
试服务的主要提供者，这里将其称为调试服务程序。
接下来，会以服务的形式启动cudbgprocess，启动时通过命令行参
数传递一系列信息。
/tmp/cuda-dbg/2132/session3/cudbgprocess 2132 128 1 0 0 0 4 0 0
调试服务进程启动后，会与GPU的内核模式驱动程序建立联系，然
后通过IOCTL机制与其通信。它也会与CUDA GDB建立通信连接，以便
接受CUDA GDB的任务请求，为其提供服务。
在CUDB GDB的源代码中，libcudbg.c包含了所有调试API的前端实
现，其内部会通过IPC机制调用被调试进程中的后端实现。下面以一个
API为例做简单说明。下面是cudbgSuspend Device函数的代码，来自
libcudbg.c。
static CUDBGResult
cudbgSuspendDevice (uint32_t dev)
{
    char *ipc_buf;
    CUDBGResult result;
    CUDBG_IPC_PROFILE_START();
    CUDBG_IPC_BEGIN(CUDBGAPIREQ_suspendDevice);
    CUDBG_IPC_APPEND(&dev,sizeof(dev));
    CUDBG_IPC_REQUEST((void *)&ipc_buf);
    result = *(CUDBGResult *)ipc_buf;
    ipc_buf +=sizeof(CUDBGResult);
    CUDBG_IPC_PROFILE_END(CUDBGAPIREQ_suspendDevice, "suspendDevice");
    return result;
}
在这个函数中，首先把调用信息放在用于跨进程通信的ipc_buf中，
然后通过CUDBG_IPC_REQUEST宏发送出去。这个宏定义在
libcudbgipc.h中，展开后会调用cudbgipcRequest函数，后者的实现也是
开源的。在libcudbgipc.c中，其在内部使用管道文件与后端通信。
9.14 本章小结
本章使用较大的篇幅全面介绍了Nvidia GPU的硬件和软件。首先介
绍硬件基础，包括微架构、硬件指令，然后从PTX指令集过渡到软件模
型和CUDA技术，接下来介绍与调试密切相关的陷阱机制和系统调用。
后面部分详细讨论了Nvidia GPU调试设施，包括GPU硬件提供的设施，
以及调试符号、调试器和调试API等软件设施。
因为主题和篇幅限制，本书没有介绍Nvidia GPU的图形调试设施和
调优工具（nvprof及API），感兴趣的读者可以参考CUDA工具集中的有
关文档。
参考资料
[1] The 10 most important graphics cards in PC history .
[2] NVIDIA Launches the World's First Graphics Processing Unit:
GeForce 256 .
[3] Nvidia Tesla: A UNIFIED GRAPHICS AND COMPUTING
ARCHITECTURE.
[4] NVIDIA Quadro FX 370.
[5] Inside Volta: The World’s Most Advanced Data Center GPU.
[6] Technical Brief: NVIDIA GeForce 8800 GPU Architecture
Overview.
[7] NVIDIA Fermi GF100 GPUs - Too little, too late, too hot, and too
expensive .
[8] The Soul of Maxwell: Improving Performance per Watt .
[9] Whitepaper: NVIDIA GeForce GTX 1080 .
[10] what is “SASS” short for?.
[11] Predication.
[12] NVIDIA CUDA Windows Release Notes Version 1.0.
[13] Trap handler architecture for a parallel processing unit.
[14] The Top 10 Innovations in the New NVIDIA Fermi Architecture,
and the Top 3 Next Challenges.
第10章 AMD GPU及其调试设施
与上一章的结构类似，本章先介绍AMD公司研发的Radeon系列
GPU，探讨它的发展简史、微架构和软件模型，然后详细介绍AMD
GPU的调试设施。
格友评点
10.1 演进简史
1985年8月，四位华裔加拿大人创立了一家名叫Array Technology的
公司，这就是后来在显卡领域大名鼎鼎的ATI公司。四个创始人的名字
分别是刘理凯（Lee Ka Lau）、刘百行（P. H. Lau）、何国源（Kwok
Yuen Ho）和班尼·刘（Benny Lau）。
2000年，ATI开始使用Radeon（中文翻译为镭）作为新产品线的品
牌商标。自此开始，Radeon成为显卡和GPU领域的一个响亮名字，直到
今天。
2006年7月，AMD做出惊人之举，以56亿美元的价格收购ATI。那
几年，AMD因为x64的成功，长期被英特尔挤压的局势有所扭转，人们
本来觉得它会借此机会对英特尔主导的x86市场攻城略地。没想到，它
把现金砸在了购买ATI上，当时很多人认为这是发疯之举。十几年过去
了，如今回望历史，这真的是非常有战略眼光的一步棋。
胜过英特尔以76.8亿美元收购McAfee千倍。
10.1.1 三个发展阶段
从2000年的R100开始，Radeon商标的显卡至今已经走过了近20个
年头。从技术角度来看，其发展经历可以分为如下三个阶段。
2000年～2007年，这一阶段的设计特点是用固定功能的硬件流水线
（fixed pipeline）来实现2D/3D加速，主要产品有R100（支持
DirectX 7）、R200、R300、R420、R520（支持DirectX 9.0C）等。
2007年～2012年，通用化设计思想成为主流，逐步使用统一的渲染
器模型（Unified Shader Model）替代固定功能的硬件流水线。这一
阶段的大多数产品都属于Terascale微架构，主要产品有R600、
R700（Terascale 1）、Evergreen（Terascale 2）和Northern
Islands（Terascale 3）。
2011年8月，在HPG11（High Performance Graphics）大会上，AMD
公开介绍了新的GPU微架构，名叫Graphics Core Next（GCN）。推
出以来，该微架构已经迭代6次，从GCN 1到GCN 6，至今仍在使
用。有消息称替代GCN的新设计将在2020年推出。
10.1.2 两种产品形态
2006年AMD启动代号为Fusion（融合）的项目，目标是研发把CPU
和GPU集成在同一块晶体（die）上的SoC。收购ATI便是这个项目的一
部分。经过五年努力，2011年，AMD终于推出了代号为LIano的第一代
产品。AMD给这个新形态的芯片赋予一个新的名字，称为加速处理单
元（Accelerated Processing Unit，APU）。
早期的APU中使用的是Terascale微架构的GPU，2013年开始使用
GCN微架构的GPU，直到今天。
APU推出后，AMD的GPU便有了两种产品形态，一种是PCIe接口
的独立显卡，另一种是APU中的集成GPU。
在作者为写作本章而准备的ThinkPad笔记本电脑中，配备了上述两