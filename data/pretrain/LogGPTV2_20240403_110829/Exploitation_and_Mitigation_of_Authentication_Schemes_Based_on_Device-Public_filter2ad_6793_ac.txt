only using information that survived the app’s re-installation,
which must therefore be device-public.
More precisely, if we determine that, during the execution of the
analyzed app in this step, at least one state present in the Invariant
has been skipped in all the collected traces, the app is flagged as
potentially vulnerable.
4.3 Step 3: Exploit Verification
In Step 3, we verify if an app uses an insecure authentication
scheme by actually attempting an identity-transfer attack against it.
To perform the attack, we transfer the device-public information
stored in the devices used during Step 1 and Step 2 to new devices
(which have not been used in the analysis of this app before), as
explained in Section 3.3. Then, the same procedure used in Step 1 is
used to obtain execution traces from the previously-unused devices.
These traces are then compared against the Invariant, as in
Step 2. If we detect that at least one of the states skipped during
Step 2 is also always skipped during Step 3, we conclude that the
attack succeeded, and we flag the app as vulnerable.
4.4 Dynamic Analysis
In order to accomplish the above steps, we need to deterministically
execute an application to trigger the authentication behavior,
while minimizing behavioral divergences due to non-deterministic
operating system or network behaviors. To this end, our system
stimulates apps through their UIs, including buttons, text fields, and
other interactive elements, as well as taking note of any incoming
SMS and phone calls the used device may receive.
We rely on uiautomator[21], both to control the device and to ob-
tain state information about the device itself. We control uiautoma-
tor from a normal PC by connecting it to the device using the An-
droid Debug Bridge (ADB) and the uiautomator Python wrapper [8].
Possible actions are derived from the UI’s content (button
labels, text field descriptions, ...), and inserted into a priority
queue. The priorities are arranged such that the most specific
actions are performed first. The developed system also keeps
track of previously touched UI elements, removing them from the
priority list, so that every element is touched at most once. This
is done to prevent the stimulation from entering an infinite-loop
by continuously interacting with the same element.
The following is a list of the actions that our detection system
can perform, in order of priority:
Fill text fields. Our system automatically fills some text fields. In
particular, it first determines the type of information a text field
is suppose to contain by (similar to [33]) checking labels and IDs
associated to each text field against a pre-determined list of strings.
Then, if a text field is determined as asking for a phone number, our
system fills it with the device’s phone number. Likewise, if a text
field is determined as asking for a username, our system inserts a
randomly generated one. It is important to note that no user-private
ACSAC 2017, December 4–8, 2017, San Juan, PR, USA
A. Bianchi et al.
Figure 1: Overview of the developed dynamic analysis system.
information (e.g., a password) is inserted during this (or any other)
step of the dynamic stimulation of an app.
Touch button. Our system interacts with UI elements that are
“clickable.” All clickable objects found are prioritized based on their
type (e.g., buttons have higher priority than text fields) and their
content; this allows us to, for example, touch an “OK” button before
a “Cancel” button.
Pseudo-random touch events. If none of the previously men-
tioned actions can be performed on a state, our system will try to ex-
plore the app’s behavior by simply randomly clicking on its UI. This
situation usually happens, when the application uses custom UI ele-
ments, which do not export standard layout information to the OS.
In addition, if the analyzed app loses its focus (e.g., a window
is opened in the system browser), we perform appropriate actions
to make the analyzed app regain focus.
4.5 App States Extraction and Comparison
In order to make meaningful comparisons of different executions,
we need a way to collect the current state of an app (e.g., which con-
tent it is showing to the user) at different times during our analysis
and compare those states. The way in which states are encoded and
compared needs to be sufficiently informative to capture significant
behavioral changes, but also flexible enough to help ignore minor
changes unrelated to the app’s functionality. Specifically, the behav-
ior of an app is encoded as a trace of states, which are then compared,
looking for evidence of vulnerable authentication schemes.
State Extraction. Every five seconds, the system checks if the
current device’s UI is in a steady state. By this, we mean a situation
in which the UI is likely not to change if no action is performed.
If so, we record the current app’s state (as better defined below)
and we perform an action. Otherwise, the system waits up to a
maximum threshold of 30 seconds. We employ this approach to
perform actions and capturing states only when the effects of
previous actions on the app’s UI are completed. This also allows
the sample rate of our system to be dynamic, and it helps to ensure
that the captured states make the most sense when compared
later. We use information provided by the Android video and input
subsystems to know when an animation is being rendered (and
therefore the current state is not steady). However, if we are unable
to reach a steady state (e.g., the app uses OpenGL, or is otherwise
constantly animating), we resort to an image-comparison approach.
Once the UI is steady, the system records a state, consisting of
the following:
• The activity name (in Android, an Activity is a specific UI
window)
• A hash of the simplified UI layout data
• A perceptual hash of the device’s screen-shot
Hash of simplified UI layout data. To hash the information
about the UI elements, we make important simplifications to the
UI data, so that it is more easily comparable. In particular, from
the layout tree describing the UI state, we remove the information
about the location of the different layout’s components and the text
shown. These positioning or text differences are oftentimes due
to intrinsically non-deterministic or rapidly changing UI elements,
which are not relevant to our analysis.
Additionally, we take steps to avoid comparing deliberately
dynamic content, especially advertising and web content. Ad-
vertising on Android is difficult to locate through explicit UI
information. However, most mobile advertising is standardized by
the International Advertising Bureau [6], which dictates specific
pixel dimensions for ads, therefore we filter out elements from the
simplified layout that have these sizes. Furthermore, we also filter
out all WebView objects, since dynamic web content is typically
a significant source of non-determinism. Lastly, we use the MD5
algorithm to condense the state information.
Hash of device’s screen-shot. To hash the image acquired during
the screen-shot, we use the algorithm called average hash provided
by the ImageHash Python library [5]. This algorithm was chosen
123134123......Device 113ReinstallationINVARIANTDevice 2Device NInvariant GenerationIdentity-Transfer Attack??...Device N+1Device N+2Device N+M??????...????...ComparisonComparisonSTEP 3STEP 2STEP 1Exploitation and Mitigation of Authentication Schemes. . .
ACSAC 2017, December 4–8, 2017, San Juan, PR, USA
to provide meaningful fuzziness for images, abstracting away small,
unimportant differences, such as constantly-animating UI elements.
Specifically, this algorithm compresses every image in a 64-bit
locality-sensitive fuzzy hash. The algorithm is designed so that
images “appearing” as similar for humans are hashed to the same
value, regardless of small graphical differences they may have.
State Comparison. We consider two states as equal if all the 3
components described above are equal. Moreover, when comparing
states in traces collected during Step 2 against the Invariant, we
also consider two states as equal if their image hashes only differ
slightly (less than 10% of the bits composing the image hash). This
threshold was determined empirically, by taking a subset of the
apps from our dataset, and manually determining the optimal value.
Additionally, if during the dynamic stimulation of an app the
device receives an SMS or a phone call, we add special states to the
trace.
5 EXPERIMENTAL RESULTS
5.1 Datasets
We used the vulnerability detection system to probe apps from two
different datasets:
“Top Free” dataset. A dataset of 606 apps containing all the most
popular available free Android apps. To generate this dataset, we
first downloaded all the 539 available apps listed in the “Top Free”
category on the Google Play market. Then we supplemented this
set with other 67 applications starting from the ones that have the
highest cumulative number of installations.
“Top Grossing” dataset. A dataset containing the 394 most
popular free apps in the “Top Grossing” category on the Google
Play market (excluding the ones already present in the “Top Free”
dataset). We chose this specific category because experimental
results on the “Top Free” dataset and previous executions of our
experiment revealed that apps from this category often allow users
to authenticate using non-secure methods to ease their adoption.
Apps from both datasets were downloaded in January 2016.
These datasets constitute a heterogeneous corpus of very popular
applications both in terms of installations and developers’ revenue.
In total, we analyzed 1,000 distinct apps.
5.2 Experimental Setup
Our system is implemented using a series of Nexus 5 handsets
tethered to a controlling PC. Specifically, we used 3 phones during
the Invariant Generation and Vulnerability Detection phases (Step 1
and Step 2) and 3 additional phones during Step 3. All handsets run
Google’s official Android 4.4.4 images (the most adopted Android
version at the time the apps were downloaded [20]).
During the collection of every trace of our analysis, we dynam-
ically stimulated an app for two minutes. To ease the deployment
of our infrastructure, devices’ identifiers and phone numbers were
modified during different runs of the experiment, effectively simu-
lating the usage of a new device every time the experiment was run.
Averagely, the experiment needed 458 seconds per app to run
Step 1 and Step 2 (including time necessary to reboot a device and
install an application). For apps flagged as potentially vulnerable
after these two steps, the analysis required, in average, additional
223 seconds per app to run Step 3 (including the time necessary
to transfer the device’s identity).
5.3 Results
Our system flagged 50 apps as vulnerable in our corpus of 1,000
distinct apps. Using manual analysis, we verified that 41 out of the
50 detected apps were actually vulnerable to the identity-transfer
attack. Among these, two apps are Viber and WhatsApp, two very
popular messaging apps with hundreds of millions of installations.
We postpone the discussion of the vulnerabilities identified
in these two apps to Section 6.1. Another group of 38 apps is
composed by popular games, in which an attacker can perform
an identity-transfer attack to steal the victim’s virtual currency or
objects. We will provide more details about them in Section 6.2.
Another detected app authenticates users by using standard
SMS authentication. Specifically, this app identifies users with their
phone number, by sending an authentication code to their phone
number using an SMS, which is then automatically read by the app.
If this code is stolen, an attacker can login and control all aspects
of the user’s account.
This security issue is different from the one found in the
messaging apps described in Section 6.1, as it needs the attacker to
steal the content of an SMS received by the victim. However, it still
falls into our threat model, since the SMS content is device-public
information.
In other 7 detected apps, we were able to transfer an identity
with the exploit, but the identity was not protecting anything
sensitive. Our system cannot, of course, detect which content is
truly sensitive (e.g., related to a user’s account) to a particular app,
but the differences in the UI were present.
For example, in one app, the device-public information was used
to track whether a user had accepted the application’s End-User
License Agreement (EULA), and, in another one, whether the user
configured application preferences. In the other 4 apps, the backend
uses this information to track whether a user has viewed certain full-
screen “special offers” or advertisement from the app’s developer.
In addition, we found an app that, on first usage, shows a sign-in
interface, since it assumes that the user does not already have an
account. However, on subsequent re-installations, this app shows
a username and password login interface, because it infers, using
device-public information, that a returning user would already have
an account. While not allowing any sort of account compromise,
this information can still be leveraged by any other app to infer
valuable information about the user, as explored in [10].
Finally, 2 additional apps were detected because of problems of
our testing infrastructure, such as connectivity issues of the apps
that caused the appearance of different graphical elements between
the first installation and the subsequent ones. Subsequent runs of
our experiment on these samples confirmed that these apps were
detected for temporary problems. We consider these two apps as
false positives.
6 CASE STUDIES
6.1 Messaging Applications
Two of the detected applications are the very popular messaging
apps, WhatsApp and Viber, which allow users to send and receive
ACSAC 2017, December 4–8, 2017, San Juan, PR, USA
A. Bianchi et al.
controlled app on the victim’s device to query the Account-
Manager API and exfiltrate its value to an attacker-controlled
device. Then, on the controlled device, the attacker can
spoof it by using, for instance, the Xposed framework (as we
implemented in the “ID Injector,” explained in Section 3.3).
(3) Open the app.
(4) When asked to insert a phone number, specify the victim’s
one.
Figure 2: Examples of states recorded during the Invariant
Generation phase (Step 1). Since these states were not present
during Step 2 and Step 3 of our analysis, our system correctly
classified these apps as vulnerable. In the left example, the
skipped state shows to the user an introductory tutorial of
the game. In the right one, the skipped state asks the user to
confirm the entered phone number before validating it.
text messages, VOIP calls, and media. While the statistics on the
Google Play market are not precise, WhatsApp is estimated to have
more than 1 billion installations and Viber has more than 500 million.
Our vulnerability detection system flagged WhatsApp as
vulnerable, since it detected, in the Vulnerability Detection and
Exploit Verification phases, the absence of the “confirm your phone
number” interface (shown in Figure 2), and the missing reception
of an incoming SMS, used for authentication. Similarly, while
analyzing Viber, the system detected this app as vulnerable because
of the missing “Enter Your Name” dialog (shown only to new users)
and the missing reception of a phone call whose part of the caller
number is used as an authentication token.
Initially, we speculated that those apps were detected as vulner-
able because they use the user’s phone number, verified using re-
ceived SMS or incoming phone calls, as their authentication method.
This authentication method is common among popular messaging
apps, and we consider it as vulnerable in our threat model. In fact,
an attacker with a malicious application installed on the victim’s
device can pretend to own the victim’s phone number and verify
it by sending the authentication SMS received (or the caller phone
number) from the victim’s device to an attacker-controlled device.
However, further analysis surprisingly revealed that an even
simpler attack is possible against these apps. The identity-transfer
attack was successfully performed for both apps even though their