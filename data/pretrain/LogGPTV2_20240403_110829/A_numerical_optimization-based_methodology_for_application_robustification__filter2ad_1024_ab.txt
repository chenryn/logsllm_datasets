Xi with the step, 
are assumed to be carried 
out 
for convergence. 
little 
computation 
computing 
the gradient 
errors while computing 
gradient 
able independent 
cluding 
computing 
and testing 
reliably 
these steps require 
robustified 
ing these steps, 
Thankfully, 
and can be 
the voltage 
dur­
etc.). 
increasing 
redundancy, 
software-level 
as they are critical 
for convergence, 
at a small cost (e.g., 
relatively 
in­
of gradient 
for processors 
of local convexity 
The suitability 
descent 
on f, xi is known to approach 
progress. 
duced guard bands is due to the fact that under various 
sumptions 
the true optimum as iterations 
orem is 
appeared 
and references 
l21 J, but variants 
the literature 
The following 
the­
of these results 
have 
throughout 
therein) 
distilled from 
with re­
as­
(for example, 
r8, 26, 311 
THEOREM 1. Let x* be a minimizer 
of f. Suppose that 
\l f(x;) is unbiased 
(lEI;" \l f(x;) = 
(lEI;" II\lf(x,)112  0). 
obey)...i =  O(l/Ji), then the iterates 
If f is convex, 
of (I) satisfy 
lower-semicontinuous, 
and the step sizes 
IEf(xi) -f(x*) =  0 (i-I/2) . 
(2) 
If f is c-strongly 
sizes obey )... i 
convex and L-Lipschitz, 
=  0 (1/ i), then the iterates 
of ( J ) satisfy 
IE f(xi) -f(x*) =  0 (Lf . i-I) .  (3) 
and the step 
The expectation 
in both cases is over the sequence 
of 
almost surely, 
beyond 
iteration 
answer recovered 
its accuracy 
improves 
That is, even if the CPU 
of the subgradient. 
\l f to only a few bits of precision, 
as long as 
6,00' 'i' 
Thus, not only is the correct 
but each additional 
the precision 
approximates 
the approximation 
ally extract 
a solution 
fore we get for free the benefit of additional 
finement techniques 
the accuracy 
The robustness 
choice as the computational 
mization 
high accuracy. 
re­
descent 
back-end 
[151 that are typically 
with arbitrarily 
of numerical 
is unbiased, 
algorithms 
of gradient 
problems. 
for solving 
gradient 
descent 
the opti­
There­
iterative 
used to improve 
can eventu­
on today's 
processors. 
makes it an attractive 
For some applications, 
the natural 
conversion 
is to a con­
strained 
variational 
form 
xER" 
minimize f (x) 
s.t. g(x) ::::: 0, 
h(x) =  0 
(4) 
(5) 
(6) 
978-1-4244-7501-8/10/$26.00 
©2010 IEEE 
163 
DSN 2010: Sloan et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 13:54:08 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEE/IFIP 
International 
Conference 
on Dependable 
Systems & Networks (DSN) 
point methods based on log-barrier/Newton 
steps 
f, g, and h. Constrained 
versions 
have been previ­
of 
setting 
[211. These methods typically 
involve 
pro­
on the feasible 
This step can be quite expensive, 
solving 
at least a Least Squares problem. 
set after 
as it typ­
the gradient 
or the iterate 
in the stochastic 
for some functions 
gradient 
descent 
ously analyzed 
jecting 
each iteration. 
ically involves 
Interior 
[301 are ostensibly 
computing 
power benefits. 
to convert 
lems that can be solved by gradient 
ing result is distilled 
and folding 
tion (UCQ) conditions 
promising, 
an Newton-step, 
on g and h): 
constrained 
Instead, 
The follow­
from l6J (mainly Proposition 
descent. 
5.5.2, 
Qualifica­
in Linear Independence 
Constraint 
but in practice, 
they require 
which wipes out any potential 
we rely on an exact penalty 
problems 
into unconstrained 
method 
prob­
THEOREM 2. Let x* be a unique optimizer 
and h both affine linearly 
there exists 
mizes 
of (4), with g 
of x. Then 
fLo >  ° so that for every fL  > fLo, x* also mini­
f(x) + fL L Ihi(x)1 + fL L [gj(x)l+·  (7) 
independent 
functions 
j 
functions 
and zero otherwise. 
its argument 
result 
[·l+ =  max(O,·) returns 
A similar 
The operator 
positive, 
of the form f(x) + fL Li hi2(x) + 
exact penalty 
fL Lj [gj(x)l also hold [231. This theorem states that 
a constrained 
converted 
straint 
problem of the form (4) can be 
con­
into an unconstrained 
optimization 
in the objective 
form (7) by penalizing 
violations 
function. 
if it is 
for quadratic 
3.2 Variants on Gradient Descent 
factors 
the gradient 
As Theorems 1 and 2 show, the actual rate of conver­
including 
function 
if the objective 
(a property 
c of the minimization 
the modulus of 
f, and the size 
func­
called ill­
gence depends on several 
convexity 
of each step taken. For example, 
tion has low modulus of convexity 
conditioning), 
arbitrarily 
pendicular 
of the artifacts, 
tion using the update rule: 
Xi +- xi-1 + )..idi 
(8) 
di +- aVf(xi-1) + (1-a)di-1  (9) 
can converge 
slowly, 
around in directions 
toward that of the minimum. To alleviate 
we can add momentum to the search direc­
search direction 
per­
some 
bouncing 
instead 
along this direction. 
to move faster 
if the gradient 
the descent 
causing 
is oscillating 
between two 
the other  hand, 
different 
then the mo­
to iteration, 
mentum helps to dampen the oscillations, 
search direction towards 
of progress. 
from iteration 
the direction 
directions 
and points the 
On 
step sizes may work better 
for differ­
Similarly, 
different 
ent applications 
Scaling 
search. 
when performing 
gradient 
causing 
Scaling 
followed 
We also examined 
it to contin­
using a fixed number 
the step size as t, where i is the number of iterations, 
it as  allows 
may 
make the step size too small in later iterations, 
making it 
difficult 
for the search to converge. 
the step size to remain larger while still 
uously decrease. 
of iterations, 
We refer to this technique 
phase of variable 
a factor (3success 
tion to decrease. 
creased  by 
the cost function 
percent 
a threshold. 
step sizing, 
every time the step causes the cost func­
On the other hand, the step size is de­
a factor (3jail every time the last move caused 
change between two consecutive 
the step size is increased 
by a period of variable 
The phase continues 
steps drops below 
to increase. 
until the 
by 
as aggressive stepping. 
In the 
stepsizing. 
is arbitrarily 
slow.  Consider, 
on a convex function 
it is possible 
to construct 
is 
a 
and other ill-conditioned 
point toward the minimum. Preconditioning 
quadratic 
valley. 
a poor direction 
problems, 
The gradient 
for this type 
because it 
fixes 
by reshaping 
the cost 
f(x), we minimize 
in­
Finally, 
descent 
while gradient 
to make progress, 
direction 
is generally 
where this progress 
an elongated 
guaranteed 
function 
for example, 
descent 
of function 
doesn't 
this problem with gradient 
function. 
stead a new function 
A so that g(y) is better 
bowl than a valley. 
then recover x* via the relation 
descent 
Given the cost function 
x =  Ay. 
g(y) =  f (Ay). We chose the matrix 
conditioned, 
i.e. looks more like a 
Once we have the optimum y* , we can 
3.3 Conjugate Gradient 
better search directions 
for 
For example, 
to construct 
the structure 
While we use gradient 
descent 
some kernels 
with a Least Squares 
section, 
as a search strategy 
may warrant 
other search 
problem, 
dis­
of the prob­
most of our kernels, 
strategies. 
cussed in the following 
lem can be exploited 
and step sizes. One approach, 
large problems, 
The method examines 
construct 
that are mutually 
a sequence 
conjugate to each other (i.e. where two search direction 
pr Apj =  0, Vi #  j for a particular 
and Pj satisfy 
trix A). On a reliable 
(where n is the number of variables 
most n iterations 
Least Squares problem, 
Pi 
ma­
when CG is applied 
to a 
to converge 
in at 
to 
reserved 
for very 
(CG) method l13J. 
is the conjugate gradient 
of search directions 
of the cost function 
it is guaranteed 
the gradients 
processor, 
typically 
to 
solve for in the Least Squares  problem). 
of CG when the gradient 
understood 
directions 
l28j. To reduce the effect of noisy gradients, 
The convergence 
are noisy is also well­
a smoothed run­
the amount of smoothing 
of the recent directions/ 
This modified direction essentially becomes 
ning average 
a controls 
Adding momentum provides 
pointing 
erations 
next few iterations. 
in that direction 
in the 
In that case, the momentum is built up 
gradients, 
in the search direction. 
in  a similar 
then it is likely 
consecutive 
If the gradient 
two benefits. 
for multiple 
and the scalar 
to continue 
direction 
is 
it­
978-1-4244-7501-8/10/$26.00 
©20 I 0 IEEE 
164 
DSN 2010: Sloan et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 13:54:08 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEE/IFIP 
International 
Conference 
on Dependable 
Systems & Networks (DSN) 
our implementation 
every few iterations. 
of CG resets 
the search direction 
after 
4. APPLICATION TRANSFORMATION FOR 
ROBUSTNESS 
B= 
.. . 
bm··· bo 0 .. . 
r bo 0 
. 
(11) 
How to transform 
a given problem into its variational 
from the definition 
Otherwise, 
problem. 
the least-squares 
problem 
can often be converted 
form (4) is often immediate 
lem. For example, 
fined as an optimization 
of the problem 
whose optimum solves the problem 
example 
optimization 
such as the ones described  above, 
lution 
ples below. 
below. Once converted 
to the problem. 
technique 
We provide 
illustrated 
by the IIR 
into a variational 
form, any 
can be used to find a so­
several 
illustrative 
exam­
de­
of the prob­
and u and x are t-dimensional 
is already 
the given input and desired 
the post-condition 
desired 
output therefore 
and can be found by Least Squares 
experiments, 
we use the standard 
nique to generate 
Squares 
minimizes 
the initial 
iterate 
solver. 
output 
that is robust to numerical  noise, 
into a cost function 
Sorting. 
column vectors 
that represent 
respectively. 
signals 
The 
f(x) = IIBx -Au112, 
above. In 
as described 
noisy feed-forward  tech­
for the stochastic 
Least 
Least Squares. 
Given a matrix A and a column vector b of the same 
linear 
problem 
algebra 
the norm of the 
is typically 
in numerical 
a fundamental 
Ax - b. This problem 
height, 
is to find a column vector x that minimizes 
residual 
on current 
A. In Section 
trously 
of 
5 we show that these algorithms 
under numerical 
implemented 
CPUs via the SVD or the QR decomposition 
f(x) = IIAx -bl12 = X TAT Ax -2bT X + bTb by gradient 
descent 
max  vTXu 
case is \l f ( x) = AT (Ax -b). 
XER nxn 
maximizes 
trices 
matrices, 
solving 
noise well. The gradient 
but that minimizing 
tolerates 
numerical 
unstable 
are disas­
noise, 
in this 
IIRfilters. 
To sort an array of numbers 
on current 
CPUs, one often 
recursive 
can be recast 
algorithms 
like QUICKSORT or MERGE­
as an optimization 
employs 
SORT. Sorting 
set of permutations. 
of an array u E  Rn, the one that sorts it in ascending 
and the array v = [1 ... n]T r91. In matrix notation, 
the permuted 
der also maximizes 
n x n permutation 
Among all permutations 
or­
u 
the dot product between 
for an 
matrix X, X u is the sorted 
over the 
array u if X 
ma­
the linear 
are the extreme 
cost v T Xu. Since permutation 
points 
of the set of doubly stochastic 
which is polyhedral, 
such an X can be found by 
of the entries 
the linear 
program 
Filtering 
a signal 
with an Infinite 
Impulse 
Response 
(IIR) 
filter is a basic operation 
is naturally 
defined as passing 
processing. 
an input signal 
a 
in signal 
H(z) = E ;:-: 
The problem 
u[t] through 
to obtain 
the 
function 
transfer 
output x[t]. It is typically 
rational 
desired 
CPUs by the feed-forward recursion: 
implemented 
on current 
The corresponding 
function 
is 
unconstrained 
exact quadratic 
penalty 
f(X) = -V T Xu + Al 2:= [Xij]! + A2 2:= 
j 
(12) 
ij 
+ A2 2:= [2:= Xij - 1]2 
2 
J 
+ 
implementation 
processor, 
this recursive 
On a stochastic 
crues noise in x as t grows. To recast 
serve that the output 
2:7:0 bix[t - i] = 2:=0 aiu[t  - i] for all t, or in matrix 
A and B are banded 
form, Bx = Au, where the matrices 
diagonal, 
x must satisfy 
ac­
ob­
signal 
this variationally, 
the post-condition 
where Al and A2 are suitably 
large constants, 
and the ijth 
of f is 
of the sub gradient 
coordinate 
IV [(Xl],j   -U,Vj + 2>" IX'ji+ + 2,\, [X'j - 1] + 
an ... ao 0 
A= r ao 0 
(10) 
+ 2,\, [X'j -i 
(13) 
(14) 
978-1-4244-7501-8/1 
0/$26.00 
©201 0 IEEE 
165 
DSN 2010: Sloan et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 13:54:08 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEE/IFIP 
International 
Conference 
on Dependable 
Systems & Networks (DSN) 
Note that sorting 
is traditionally 
not thought 
of as an ap­
plication 
a potentially 
that is error tolerant. 
Our methodology 
produces 
error tolerant 
implementation 
of sorting. 
Bipartite 
Graph Matching. 
Given a bipartite 
left-vertices 
connecting 
function 
w ( e), e E E, a classical 
graph G = (U, V, E) with edges E 
U and right-vertices 
S s: E of edges with maximum total weight LeES w (e) so 
that every u E U and every v E V is adjacent 
V, and weight 
is to find a subset 
problem 
to at most 
solved 
problem 
or by reducing 
and is typically 
one edge in S. This is the maximum weight bipartite 
graph 
matching 
using the Hungar­
ian algorithm 
applying 
assignment 
gramming: 
let W be the lUI x IVI matrix of edge weights 
and let X be a lUI x IVI indicator 
it can also be solved by linear 
pro­
to a MAX FLOW problem 
and 
the Push-Relabel 
[121. Like other linear 
matrix over edges, with 
problems, 
algorithm 
and only one element 
Xij binary, 
umn of X set. The weight of a matching 
Li· Xij Wij, which is linear 
ove doubly stochastic 
matrices, 
in X, so it suffices 
as in the previous 
to search 
example. 
in each row and each col­
given by X is then 
Typical implementations 
of Bipartite 
Graph Matching 
again not considered 
duces a potentially 