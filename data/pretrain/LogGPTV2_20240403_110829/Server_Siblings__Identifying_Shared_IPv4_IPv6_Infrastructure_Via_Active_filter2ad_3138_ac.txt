### 3. Evaluation of Sibling Classification Algorithms

In Section 3.1, we describe the methodology for our multiple rounds of testing. The data provides us with true associations, and for evaluation purposes, we also test false associations in each round. These known non-siblings are created by randomly associating a non-associated IPv6 site with each IPv4 site. This approach allows us to evaluate both Type I and Type II errors.

**Table 2: Relative Ground Truth Performance of Sibling Classifiers**

| Algorithm        | Accuracy | Precision | Recall | Specificity | Unknown |
|------------------|----------|-----------|--------|-------------|---------|
| TCP Options      | 82.2%    | 74.1%     | 98.0%  | 66.8%       | 0.0%    |
| Kohno Alg 1      | 90.6%    | 82.3%     | 97.0%  | 86.4%       | 27.8%   |
| Kohno Alg 1 & 2  | 94.2%    | 93.6%     | 91.4%  | 96.0%       | 22.4%   |
| Full Algorithm   | 97.4%    | 99.6%     | 93.1%  | 99.8%       | 29.4%   |

Our goal is to assess the discriminative power of both the original Kohno timestamp skew algorithm and our enhancements in distinguishing siblings from non-siblings. First, we examine the use of TCP options as a classifier alone. As shown in Table 2, TCP options yield an accuracy of 82.2% with 74.1% precision, 98.0% recall, and 66.8% specificity. While the option signature does not provide sufficient granularity, it effectively eliminates non-siblings with minimal overhead (just a single TCP ACK packet from the IPv4 and IPv6 target).

Next, we evaluate Kohno’s original timestamp skew algorithm without considering TCP options. Over ten rounds, we achieve an accuracy of 90.6% with 82.3% precision, 97.0% recall, and 86.4% specificity. We then examine Algorithm 1 and the combined Algorithms 1 and 2 as detailed in Section 3.5. The results show that each iteration provides increasingly accurate sibling classification, with the full algorithm achieving an accuracy of 97.4%, 99.6% precision, 93.1% recall, and 99.8% specificity over the ten rounds of testing. However, this high accuracy comes at the cost of labeling 29.4% of the hosts as "unknown" due to the inability to make a definitive determination.

### 4.2 Web Server Machine Siblings

As an initial application of our sibling detection technique, we characterize sibling relationships among a subset of important Internet infrastructure, specifically the top 100,000 websites on Alexa, as gathered, resolved, and probed in April 2014 (details in Section 3.1). Our probing is conducted from a host with high-speed, native IPv6 connectivity. To remain inconspicuous, we probe at a low rate, fetching the root HTML page from each site’s IPv4 and IPv6 interfaces once every ~3.5 hours over ~17 days.

We then apply our inference Algorithms 1 and 2 to the datasets in Table 1. As described in Section 3, there are various potential outcomes. For each of the three Alexa datasets, we categorize the inferences into three major categories in Table 3: siblings, non-siblings, and unknown.

**Table 3: Alexa Machine-Sibling Inferences**

| Inference                  | Non-CDN (n=1533) | CDN (n=230) | Embedded (n=1050) |
|----------------------------|------------------|-------------|--------------------|
| Siblings - v4/v6 drift match | 816 (53.2%)      | 55 (23.9%)  | 978 (93.1%)        |
| Non-Siblings - v4 and v6 opt sig differ | 229 (14.9%)   | 14 (6.1%)   | 22 (2.1%)          |
| - v4 or v6 missing         | 70 (4.6%)        | 11 (4.8%)   | 23 (1.5%)          |
| - v4 or v6 random          | 13 (5.7%)        | 13 (5.7%)   | 1 (0.1%)           |
| - v4 or v6 non-monotonic   | 52 (3.4%)        | 47 (20.4%)  | 7 (0.7%)           |
| - v4/v6 drift mismatch     | 35 (2.3%)        | 13 (5.7%)   | 1 (0.1%)           |
| Unknown - v4 and v6 missing | 196 (12.8%)     | 6 (2.6%)    | 26 (2.5%)          |
| - v4 and v6 random         | 32 (2.1%)        | 25 (10.9%)  | 0 (0.0%)           |
| - v4 and v6 non-monotonic  | 78 (5.1%)        | 45 (19.6%)  | 0 (0.0%)           |
| - v4 or v6 unresponsive    | 2 (0.1%)         | 1 (0.4%)    | 6 (0.6%)           |
| Total                      | 1533 (100%)      | 230 (100%)  | 1050 (100%)        |

In aggregate, we find that 53.2% of the IPv4/IPv6 addresses of non-CDN, 23.9% of CDN, and 93.1% of embedded sites are siblings via the full Algorithm 1 and 2. Additionally, 42.6% of the CDN and 26.7% of the non-CDN addresses are inferred to be non-siblings. Despite expecting a high proportion of siblings among sites with embedded addresses, 3.0% are non-siblings, highlighting that addresses alone do not imply the same machine. We cannot definitively determine 20% of the non-CDN, 33.5% of the CDN, and 3.9% of the embedded sites.

The largest contributing subset of non-monotonic timestamps are CDN sites, which is expected due to the various forms of load balancing inherent in CDN architectures. A non-trivial fraction of non-CDN and CDN sites have missing timestamps. Personal communication with an operator revealed that missing timestamps in one case were due to a front-end load balancing device; similar middlebox issues likely cause the missing timestamps observed here.

Among the sibling and non-sibling populations, we examine the origin AS of the prefixes to which the addresses belong from the RouteViews BGP table. The origin AS of the corresponding IPv4 and IPv6 addresses of a website allows us to determine whether non-siblings are within the same network, if not the same host. As shown in Table 4, 21.8% of the non-siblings in our non-CDN dataset are in different ASes, compared to 10% of the siblings. Siblings may be in different ASes when an organization uses IPv6 tunnels or a different AS for IPv6. By contrast, 97.3% of the inferred siblings among the embedded sites are within the same AS. Only 51% of the non-siblings among the CDN sites reside within the same AS. Manual investigation of some of the siblings in different ASes reveals that the ASes belong to the same organization.

**Table 4: Alexa Machine-Sibling AS Agreement**

| Inference                   | Siblings | Non-Siblings | Unknown |
|-----------------------------|----------|--------------|---------|
| Fraction of matching (I4, I6) ASNs | 90.0% (non-CDN) | 78.2% (non-CDN) | 91.6% (non-CDN) |
|                              | 83.6% (CDN)      | 51.0% (CDN)     | 62.3% (CDN)      |
|                              | 97.3% (Embedded) | 87.1% (Embedded)| 78.0% (Embedded) |

### 5. Conclusions and Future Work

We developed, validated, and applied a method for using TCP-layer fingerprinting techniques to identify IPv4 and IPv6 addresses that belong to the same machine. By combining coarse and fine-grained TCP-layer fingerprinting, we can identify server "siblings." Potential applications of sibling interface identification include predicting correlated failures or similar behaviors under attack, leveraging IPv6 geolocation based on the corresponding IPv4 address, comparing IPv4 and IPv6 path performance, and understanding the co-evolution of IPv6 and IPv4 network infrastructures at a macroscopic level. Although we applied our technique to web servers, it generalizes to any device with a listening TCP service, including DNS, email, and peer-to-peer services.

Despite the validation of our technique with a diverse set of ground truth, we see at least three areas for improvement. First, the optional enhancement algorithm (Algorithm 2) used to classify problematic cases contains parameters and thresholds that may overfit our data. A larger ground-truth dataset would support further refinement and higher confidence in our inferences. Second, while we detect certain instances of TCP load-balancing by observing multiple monotonic sequences with different initial offsets, it would be better to use reverse-proxy detection techniques to discern cases where a TCP-splitting proxy sits in front of the interrogated web server.

Finally, our preliminary sensitivity results show that our inferences are stable even with fewer data points and over shorter time frames. Our technique can make some sibling inferences quickly with only a few TCP observations, whereas others require samples across longer periods. A complete temporal sensitivity analysis is left for future work.

**Acknowledgments:** Thanks to kc claffy, Justin Rohrer, Nick Weaver, and Geoffrey Xie for invaluable feedback. This work was supported in part by NSF grant CNS-1111445 and Department of Homeland Security (DHS) S&T contract N66001-2250-58231. Views and conclusions are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. government.

**References:**

1. Alexa: Top 1,000,000 sites (2014). <http://www.alexa.com/topsites>
2. Berger, A., Weaver, N., Beverly, R., Campbell, L.: Internet nameserver IPv4 and IPv6 address relationships. In: Proceedings of the ACM Internet Measurement Conference. pp. 91–104 (2013)
3. Claffy, K.: Tracking IPv6 evolution: data we have and data we need. SIGCOMM Comput. Commun. Rev. 41(3), 43–48 (2011)
4. Craven, R., Beverly, R., Allman, M.: A middlebox-cooperative TCP for a non end-to-end internet. In: Proceedings of ACM SIGCOMM, pp. 151–162 (2014)
5. Czyz, J., Allman, M., Zhang, J., Iekel-Johnson, S., Osterweil, E., Bailey, M.: Measuring IPv6 adoption. In: Proceedings of ACM SIGCOMM, pp. 87–98 (2014)
6. Dhamdhere, A., Luckie, M., Huffaker, B., Elmokashfi, A., Aben, E., et al.: Measuring the deployment of IPv6: topology, routing and performance. In: Proceedings of the ACM Internet Measurement Conference, pp. 537–550 (2012)
7. Heuse, M.: Recent advances in IPv6 insecurities. In: Chaos Communications Congress (2010)
8. Jacobson, V., Braden, R., Borman, D.: TCP Extensions for High Performance. RFC 1323 (May 1992)
9. Kohno, T., Broido, A., Claffy, K.C.: Remote physical device fingerprinting. In: Proceedings of IEEE Security and Privacy, pp. 211–225 (2005)
10. Lyon, G.F.: Nmap Network Scanning: The Official Nmap Project Guide to Network Discovery and Security Scanning (2009)
11. Maxmind: IP Geolocation (2014). <http://www.maxmind.com>
12. Meyer, D.: University of Oregon RouteViews (2014). <http://www.routeviews.org>
13. Moon, S., Skelly, P., Towsley, D.: Estimation and removal of clock skew from network delay measurements. In: Proceedings of INFOCOM, vol. 1 (Mar 1999)
14. RIPE NCC: World IPv6 day measurements (2011). <http://v6day.ripe.net>
15. Sarrar, N., Maier, G., Ager, B., Sommer, R., Uhlig, S.: Investigating IPv6 Traffic. In: Taft, N., Ricciato, F. (eds.) PAM 2012. LNCS, vol. 7192, pp. 11–20. Springer, Heidelberg (2012)
16. Silbersack, M.J.: Improving TCP/IP security through randomization without sacrificing interoperability. In: Proceedings of BSDCan (2006)
17. Zander, S., Andrew, L.L., Armitage, G., Huston, G., Michaelson, G.: Mitigating sampling error when measuring internet client IPv6 capabilities. In: Proceedings of the ACM Internet Measurement Conference, pp. 87–100 (2012)