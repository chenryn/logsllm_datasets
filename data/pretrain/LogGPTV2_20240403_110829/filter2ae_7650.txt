# 浅谈信息收集的那些事儿
* * *
# 前言
> 大佬都说信息收集最重要啦~  
>  懒就没有洞啦~  
>
> 
# Go
## 子域名收集
> 一切的开始，当然是子域名枚举，于是很关键的工具们登场了
这里推荐三个很好用的工具，也是最常用的三个。
> [amass](https://github.com/OWASP/Amass)  
>  [sublist3r](https://github.com/aboul3la/Sublist3r)  
>  [aiodnsbrute](https://github.com/blark/aiodnsbrute)
子域名的收集方法目前大部分都是：爆破，搜索引擎收集，dns查询，证书查询。
这三个工具算是很多信息收集文章都提到的，主要原因：快。
这三个工具安装不会很复杂，`amass` 的话用 `snap` 安装比较好，看看官方的说明文档，还是很简单的。
这里就要提一下 `subfinder` 这个工具了，也许是我天赋不够，这个工具简直难装。。后来经表哥点醒，其实和 `sublist3r` 差不多，所以这里用
`sublist3r` 代替就好，当然表哥们也可以用 `docker` 体验一下这个工具。
再推荐两个线上的：
>   
>  
这两个其实上面的工具都有用的功能。
这里还有一个：
> 
大概长这样：  
而且效果貌似也不错，可以作为参考。借 360 之手吧。
## 目录枚举 & FUZZ
### 目录枚举
这里推荐我用的顺手的一个工具
> [dirsearch](https://github.com/maurosoria/dirsearch)
推荐理由很简单，因为可以在 `windows` 上用。
目录枚举的工具也有很多，但其实关键还在字典，这里推荐几个看到不错的：
> [RobotsDisallowed](https://github.com/danielmiessler/RobotsDisallowed)
据说是从大量 `robots.txt` 中收集而来，我扫了一下 `thinkphp` 的站点效果一般，可能是因为 `tp`
的路由关系，可以看看，说不定能用上。
> [SVN Digger](https://www.netsparker.com/blog/web-security/svn-digger-better-> lists-for-forced-browsing/)
很少有人提，但是还不错的字典，可以翻一下。
> 当然最后还有个人尽皆知的 [Seclists](https://github.com/danielmiessler/SecLists)
### FUZZ
> FUZZ 天下第一~
FUZZ 的工具也推荐两个吧：
> [parameth](https://github.com/maK-/parameth) 专门拿来 FUZZ 参数的  
>  [WUFFZ](https://github.com/xmendez/wfuzz) 网上的教程已经数不胜数了
FUZZ 的工具其实还挺尴尬，很多功能 `BurpSuite` 都可以做到，那么一般不会舍近求远。  
不过还是可以试试，看看哪个用起来顺手吧。
`FUZZ` 的关键也在于字典，当然有时候也需要点小想法。  
这里有个为 FUZZ 准备的字典：
> [IntruderPayloads](https://github.com/1N3/IntruderPayloads) 这里有很多，比如
> 目录，上传，SQL，XSS，用户名密码这些  
>  [parameth](https://github.com/maK-/parameth) 这个就是 FUZZ 参数用的字典了
当然 `FUZZ` 的参数有时候可以从网站本身收集，比如 数据包1 中的参数放到 数据包2 或者 网站中返回 `json` 格式数据时将 `键名`
转为字典。
* * *
其实字典太多有时候也很难选择，一般工具也会自带两个不错的，这几个都是国外的，国内有像 `御剑`
也有自带一些，在测试过程中也可以自己主动收集一些，这里就可以用到米斯特表哥写 `BP` 插件了
> [BurpCollector](https://github.com/TEag1e/BurpCollector)
渗透过程中，可以找一些好用的字典整理成一份属于自己的字典。
## 额外的信息收集
> 当然信息收集还没有结束
### CMS 识别
CMS 的漏洞时有爆出，所以我们可以先识别 CMS，试试已经爆出的 `POC`。
也许是我没收集到，我发现国内的 `CMS` 识别工具不太多或者指纹已经很少更新，十分老旧。
不过依然有一个是不错的：
> [云悉](http://www.yunsee.cn/)
不过 `云悉` 想注册是要交指纹的，可以找个 `cms`，看看指纹什么的。
当然国外也有一些 `CMS识别工具`，但是在国内不太适用，因为识别不了国产 CMS （dede，thinkphp，74 等..）
所以也可以自己收集一些指纹结合上现有的，做一个工具。
通常来说判断一个 CMS 的方法：
  1. 可以根据网站特有 URL 判断
  2. 通过一些文件的 MD5 值，有时候也可以判断 `CMS` 类型(比如 `/favicon.ico` )
  3. 检查 `response` 头 或者页面中 Power by
在 `github` 上翻到表哥写的工具中的指纹：
> [部分 cms 特有 URL
> 指纹](https://github.com/dyboy2017/WTF_Scan/blob/master/wtf/app/api/cms/cms.txt)
还有个功能写的挺全的，可以参考参考他的代码，这里指纹也不少
> [cmsIdentification](https://github.com/theLSA/cmsIdentification) 可惜是两年前的项目了
所以大家快来 云悉 贡献一下力量吧 hhh
### Javascript 世界第一
#### URL 收集
有时候我们可以在 `javascript` 中发现一些未公开的敏感接口,所以我们可以多看看 `javascript` 文件,但是 `javascript`
文件可能会有很多，有没有方法可以自动收集呢？
有。
首当其冲的当然是我们的 `BP`：
在 `BP 专业版` 中的：
> Target => Site Map => 找到要提取 script 的地址右键 => Engagement tools => Find scripts
我们就可以在 `Find scripts` 前主动去爬一下网站，增加一些内容，让结果多些。  
如果点 `Export Script`，他会把所有脚本内容都写入一个文件里，有时我们可能只需要 `script` 的 `url链接`，此时我们可以全选，然后
上面那个是提取 URL，下面那个应该是提取 `Response` 中的 `src/href`
当然还有一个工具
>
> [javascript_files_extractor](https://github.com/003random/003Recon/blob/master/tools/javascript_files_extractor.py)
但是这个脚本只能提取一个页面的，而且也有些小毛病，就是不能请求 https，我们可以改改：
改成：
此时就可以在一个文件中写类似这样的格式：
执行命令：
> python javascript_files_extractor.py domains.txt hhhh.txt
此时 `hhhh.txt` 就会输出提取出来的 `js` 文件啦。
当然，这个脚本代码就一点点，所以也可以参考一下，自己写一个也不费劲。
#### 提取节点
这时候我们就有很多 `script` 的 `URL` 了，但是一个一个分析太麻烦，有没有什么可以自动帮我们找到接口呢？
也有，这里有个好用的工具，可以提取 javascript 中的节点：
> [LinkFinder](https://github.com/GerbenJavado/LinkFinder)
基本用法的话，类似这样：
> python linkfinder.py -i
> 
但是好像不能给一批 `URL`，不过也可以自己写个脚本调用一下。
这里有个 LinkFinder 的 `Chrome` 扩展，但是可能写的有些问题，需要改改东西才行，表哥们有兴趣的话可以自行研究看看啦
> [LinkFinder Chrome
> Extension](https://github.com/GerbenJavado/LinkFinder/tree/chrome_extension)
这里就要提一下 [JSParser](https://github.com/nahamsec/JSParser)，我用的话感觉不如 LinkFinder
，而且用起来也很麻烦。
### 搜索的技巧
#### google dork
谷歌有时候可以帮助我们找到一些信息泄露。
最常见的语法可以是这样：
> intext:"后台登陆"
或者这样：
> site:*.domain.com file type: php
有时候我们可以找一些 `xlsx` ，找找有没有泄露的账号或密码。
#### Github
在 `Github` 中我们也可以找一些泄露：
比如：
> "domain.com" API_KEY  
>  "domain.com" login  
>  "domain.com" password
* * *
等等，有时候我们可以在这些 搜索 时这些时候发现一些有趣的东西。当然，有时候我们也可以看看 源代码里（F12），可能注释了一些好东西哦。
## 总结
在本文开头介绍了一些好用的 `子域名收集的工具`，子域名的搜集可以帮我们扩大攻击面（官方套话）。之后介绍了一个 `目录枚举` 的工具，并给出了一些好用的
`字典`。
然后信息收集中我们提到了 `CMS 探测`，提到了几个 `探测的思路`
我们收集了 `js文件` 并进行分析，最后介绍了几个常用的 `google dork/Github` 搜集信息的语法。
信息收集是个很大的范围，本文也只是粗略的介绍一二，有很多不对和不好的地方希望表哥们指出斧正。
* * *