MultiplicationCheck Upon
putting
(id𝑥,𝑖, 𝑥𝑖), (id𝑦,𝑖, 𝑦𝑖), (id𝑧,𝑖, 𝑧𝑖) ∈ st for 𝑖 = 1, . . . , 𝑛:
(1) Send (success) to V if 𝑥𝑖
in-
where
· 𝑦𝑖 = 𝑧𝑖 holds for all
𝑖 = 1, . . . , 𝑛, otherwise send (abort) to all parties and
terminate.
𝑖=1).
&
(CheckMult, (id𝑥,𝑖, id𝑦,𝑖, id𝑧,𝑖)𝑛
𝑖=1)
P
We use the shorthand CheckMult(([𝑥𝑖], [𝑦𝑖], [𝑧𝑖])𝑛
Figure 15: Functionality modeling homomorphic commit-
ments of values in the ring 𝑅.
communicates with two parties P,V. It contains
F 2,𝑀
ComZK
two separate instances of the commitment functionality
F 𝑅
, one for 𝑅 = Z2 and the other for 𝑅 = Z𝑀. Com-
mitments are denoted as [·]2 and [·]𝑀, respectively.
ComZK
The parties can use the functions of F 𝑅
with respect
to both domains Z2 and Z𝑀, so all functions are parameter-
ized by a domain unless apparent from context. Then, any
use of [·]2 or [·]𝑀 interfaces are dealt with in the same
way as F 𝑅
ComZK
.
ComZK
Figure 16: Ideal functionality modeling communication us-
ing commitments over multiple domains.
B PROOF OF CORRECT TRUNCATION
FVerifyTrunc (Figure 7) in the FCheckLength-hybrid model.
Theorem B.1. The protocol ΠVerifyTrunc (Figure 10) UC-realizes
Before writing the proof, we make the following observations.
First, if correct information is provided by P, then the protocol
completes. Intuitively, if the prover provides a correct [𝑎′]𝑀 = [𝑎
mod 2𝑚]𝑀 and [𝑎𝑡𝑟]𝑀, then when both of these are subtracted
from [𝑎]𝑀, then it will be equal to 0 as required by CheckZero.
CheckLength on ([𝑎′]𝑀, 𝑚): This ensures that [𝑎′]𝑀 can be rep-
resented by 𝑚 bits.
CheckLength on ([𝑎𝑡𝑟]𝑀, 𝑙 − 𝑚): This ensures that [𝑎𝑡𝑟]𝑀 can be
represented by 𝑙 − 𝑚 bits.
CheckZero([𝑎]𝑀 − (2𝑚 · [𝑎𝑡𝑟]𝑀 + [𝑎′]𝑀)): This check ensures cor-
rectness of the two values [𝑎′]𝑀 and [𝑎𝑡𝑟]𝑀. As we know
that they are both of correct length (𝑚 and 𝑙 − 𝑚 respec-
tively), 2𝑚 · 𝑎𝑡𝑟 + 𝑎′ exactly represents all values in [0, 2𝑙 −1].
Therefore, the truncation must be correct.
We now proceed with the proof.
Proof. We consider a malicious prover and a malicious verifier
separately. In both cases we will construct a simulator S given
access to FVerifyTrunc that will emulate FCheckLength. We implicitly
assume that S passes all communication between the adversary
(either P∗ or V∗ dependent on the case) and the environment Z.
Malicious Prover. S sends (corrupted, P) to the ideal functional-
ity FVerifyTrunc. It also creates copies of the prover P∗ and verifier
V, and runs the verifier according to the protocol ΠVerifyTrunc, while
letting the prover behave as instructed by the environment Z.
(1) S forwards Input on [𝑎′]𝑀.
(2) S forwards any calls to FCheckLength. If any calls to FCheckLength
(3) For the remainder of the protocol, S acts like an honest verifier.
(4) Lastly, S forwards the call (VerifyTrunc, ·, ·).
The only avenue for P∗ to distinguish the ideal from the real world
is the case of passing the verification check with an incorrect trun-
cation. As argued above, this can never happen. This completes the
returns ⊥, then S outputs ⊥ to FVerifyTrunc and abort.
Session 1C: Zero Knowledge I CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea206proof for the case of a malicious prover.
Malicious Verifier. S sends (corrupted,V) to the ideal function-
ality FVerifyTrunc. It also creates copies of the prover P and verifier
V∗, and runs the prover according to the protocol ΠVerifyTrunc,
while letting the verifier behave as instructed by the environment
Z. If S receives ⊥ from FConv, then it simply abort. Otherwise S
interacts with the verifier as follows:
(1) S forwards the call (VerifyTrunc, 𝑁 , {𝑚 𝑗 , [𝑎 𝑗]𝑀, [𝑎 𝑗
𝑡𝑟]𝑀} 𝑗 ∈[𝑁 ]).
If FVerifyTrunc returns ⊥, output ⊥ to V∗ and abort.
(2) For each 𝑗 ∈ [𝑁] S commits to a random value [𝑎′]𝑀 using
Input of FCheckLength. We assume that simulated commitments
to 𝑎 𝑗 , 𝑎
(3) For each iteration 𝑗 ∈ [𝑁], let 𝑙 be the size of 𝑎 𝑗 and 𝑚 be the
′,𝑗 already exist in FCheckLength.
′,𝑗. S runs (CheckLength, id𝑎
′,𝑗 , 𝑚) and
(4) S then computes 𝑦 𝑗 ← 𝑎 𝑗 − (2𝑚 · 𝑎 𝑗
and then runs (CheckZero, id𝑦 𝑗), which it makes output (success).
𝑡𝑟 , 𝑙 −𝑚) in FCheckLength towards the verifier.
′,𝑗) using FCheckLength
The view of V∗ simulated by S is distributed identically to its view
in the real protocol. Any value being communicated to V∗ is hidden
in the commitment functionality.
□
𝑡𝑟 + 𝑎
size of 𝑎
(CheckLength, id𝑎 𝑗
C A NAÏVE TRUNCATION PROTOCOL
For comparison, we now describe a “naïve” way of truncating some
value [𝑎]𝑀 where 𝑎 ∈ [0, 2𝑙) ⊂ Z𝑀, without doing any conversions
to Z2. Informally, the prover provides [𝑎]𝑀 as well as its supposed
bit decomposition ([𝑎0]𝑀, . . . , [𝑎𝑙−1]𝑀) authenticated in Z𝑀. The
prover then has to convince the verifier that each authenticated
[𝑎𝑖]𝑀 is a bit and that they all sum up to [𝑎]𝑀, thus proving the
correctness of the bit decomposition. Lastly, the prover and verifier
can individually sum up most-significant 𝑙 − 𝑚 bits, resulting in the
truncated value [𝑎𝑡𝑟]𝑀.
Protocol ΠNaiveTrunc
Input [𝑎]𝑀 and it’s
([𝑎0]𝑀, . . . , [𝑎𝑙−1]𝑀).
Protocol
(1) For 𝑖 = 0, . . . , 𝑙−1 compute [𝑦𝑖]𝑀 = [𝑎𝑖]𝑀 ·(1−[𝑎𝑖]𝑀).
supposed bit decomposition
𝑖=0[𝑎𝑖]𝑀2𝑖.
(2) Let [𝑦]𝑀 ←𝑙−1
(4) Let [𝑎𝑡𝑟]𝑀 ←𝑙−𝑚
Output [𝑎𝑡𝑟]𝑀.
(3) Run CheckZero([𝑦]𝑀, [𝑦0]𝑀, . . . , [𝑦𝑙−1]𝑀), output
abort if the check fails and terminate.
𝑖=0 [𝑎𝑙−𝑚+𝑖]𝑀2𝑖.
Figure 17: Protocol that naïvely truncates 𝑎 by 𝑚 bits
[𝑎𝑖]𝑀 for 𝑖 ∈ [𝑙] requires a multiplication, leading to further interac-
tion. To give an example, we analyze the cost of this protocol when
using Wolverine [31] to check the multiplications (alternative pro-
tocols such as [4] could also be used, but this does not significantly
change the costs). For 𝑙 multiplications in Z𝑀, Wolverine runs a
total of (𝐵 − 1) · 𝑙 iterations, each requiring 1 multiplication triples,
for a total of (3(𝐵 − 1)) · 𝑙 random authentications and (𝐵 − 1)𝑙
fix (where fix corresponds to inputting a specific value into the
commitment functionality) in Z𝑀. Secondly, each iteration opens
2 values and performs a single CheckZero. All calls to CheckZero
may be batched together and performed at the end, but the other
2 must be done in each iteration, for a total of 𝑙 · ((𝐵 − 1) · 2) + 1
openings in Z𝑀. Lastly, in step 3, all the checks for 𝑎𝑖(1−𝑎𝑖) ?
= 0 are
batched together for a total of 1 opening. Throughout this analysis,
we assume we’re working in a small field such that log(𝑀) ≤ 𝑠 for
some security parameter. If instead it holds that log(𝑀) > 𝑠, then
we can save a factor (𝐵 − 1) in these costs.
A breakdown of the costs of ΠNaiveTrunc compared to those of
our optimized protocol ΠVerifyTrunc (Figure 10) is given in Table 5,
where we list both if log(𝑀) ≥ 𝑠 but also log(𝑀) > 𝑠 . In both cases,
for typical parameters (e.g. 𝑙 = 32 ≈ log 𝑀 and 𝐵 = 3–5) the naive
protocol has much higher communication cost than ours, since
the number of Z𝑀 openings scales with the bit-length 𝑙. To give a
concrete number, e.g. for the Z𝑝 variant with 𝑙 = 32 ≈ log 𝑀, when
verifying a batch of around a million multiplications and 40-bit
statistical security, we can use a bucket size 𝐵 = 3. This leads to
the communication of 8256 bits when using the naïve compared to
only 960 when using ours, when we disregard the construction of
the random authentications in Z2 and Z𝑝 for both protocols.
D SUB-PROTOCOLS
We look at the two sub-protocols convertBit2A and bitADDcarry
that is used in our protocol verifying converion tuples.
D.1 Complexity of bitADDcarry
We assume that the input is distributed prior to running the protocol.
The bitADDcarry circuit is implemented as a ripple-carry adder
which computes the carry bit at every position with the following
equation
𝑐𝑖+1 = 𝑐𝑖 ⊕ ((𝑥𝑖 ⊕ 𝑐𝑖) ∧ (𝑦𝑖 ⊕ 𝑐𝑖)),∀𝑖 ∈ {0, . . . , 𝑚 − 1}
(2)
where 𝑐0 = 0 and 𝑥𝑖, 𝑦𝑖 are the i’th bits of the two binary inputs.
The output is then
𝑧𝑖 = 𝑥𝑖 ⊕ 𝑦𝑖 ⊕ 𝑐𝑖,∀𝑖 ∈ {0, . . . , 𝑚 − 1}
(3)
and the last carry bit 𝑐𝑚. This requires 𝑚 AND gates and as such 𝑚
rounds of communication. As all the ⊕ can be computed by 𝑃1 and
𝑃2 locally (and as such requires no communication), 1 field element
must be communicated per round. As this circuit is evaluated 𝐵 − 1
times per bucket, it results in a total for (𝐵 − 1)𝑚 field elements
which must be communicated.
This protocol is much more expensive than our edaBit-based
approach, due to working in Z𝑀 for all operations. Each bit must
be committed to by a commitment over Z𝑀, which itself requires
log2(𝑀) bits of communication. Furthermore, the checking of each
D.2 Complexity of convertBit2A
We consider the procedure convertBit2A as defined in Figure 4.
We assume that the input (not the daBit) is distributed prior to
running the protocol. This sub-protocol requires a single daBit to
Session 1C: Zero Knowledge I CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea207Table 5: Comparison of the costs of ΠNaiveTrunc (Figure 17) and ΠVerifyTrunc (Figure 10).
Naïve log(𝑀) ≤ 𝑠
Naïve log(𝑀) > 𝑠
Ours
Naïve log(𝑀) ≤ 𝑠
Naïve log(𝑀) > 𝑠
Ours
#Openings F2
0
0
𝐵𝑙 + 2𝐵
#Openings Z𝑀
𝑙((𝐵 − 1) · 2) + 2
𝑙 · 2 + 2
2𝐵 + 1
#(e)dabit COTs
#(e)dabit VOLEs
0
0
𝐵𝑙 + 2𝐵
0
0
4𝐵
#Faulty triples F2
0
0
𝐵𝑙
#Faulty triples Z𝑀
(𝐵 − 1)𝑙
𝑙
0
#Bits from fix
2(𝐵 − 1)𝑙 log2(𝑀)
2𝑙 · log2(𝑀)
(𝐵 + 1)𝑙 + (4𝐵 + 2) log2(𝑀)
convert the bit authenticated in F2 to F𝑀. Having a single daBit
([𝑟]2, [𝑟]𝑀), we can convert a value [𝑥𝑚]2 by following the follow-
ing protocol.
(1) Compute [𝑐]2 = [𝑥𝑚]2 + [𝑟]2
(2) 𝑐 ← Open([𝑐]2)
(3) [𝑥]𝑀 = 𝑐 + [𝑟]𝑀 − 2 · 𝑐 · [𝑟]𝑀.
We note that the only things requiring communication, is the dis-
tribution of the daBit used during the protocol and the opening of
the value [𝑐]2. As such, we conclude that this requires the sending
of four field elements (the opening of [𝑐]2 and the sending of the
two bits of the daBit) and the cost of generating 1 daBit.
E PROOFS OF THE Z2𝑘 PROTOCOLS
Here we present the full proofs of security that were omitted in
Section 5.3.
E.1 Proof of Theorem 5.1
Proof of Theorem 5.1. To show security in the UC-model, we
construct a simulatorS with access to the ideal functionality F Z2𝑘
ComZK
The environment can choose to corrupt one of the parties, where-
upon S simulates the interaction for the corrupted party. We cover
the two cases separately, and first consider a corrupted prover, then
a corrupted verifier.
Throughout the proof, we assume that the parties behave some-
what sensible, e.g. they use correct value identifiers, both parties
access the functionality in a matching way, and that the simulator
can always detect which method is to be executed.
.
ComZK
Z2𝑘
ComZK-a
Malicious Prover. S sends (corrupted, P) to the ideal function-
. It also creates copies of the prover P∗ and verifier
ality F Z2𝑘
V, and runs the verifier according to the protocol Π
, while
letting the prover behave as instructed by the environment. For
this, S simulates the functionality of F 𝑠,𝑘+𝑠
with corrupted P. If
the simulated P aborts the protocol, S sends (abort) to F Z2𝑘
.