### Introduction

We propose two variants of the KTV (Knowledge Transfer and Verification) framework, one for qualitative reasoning and another for quantitative reasoning. These variants are detailed in the following sections.

### Observations and Distinction

The distillation of our observations, as presented in Section X-A, reviews various aspects of verifiability. In most cases, it clearly identifies the optimal and favorable ways to handle verifiability definitions. When distinguishing between qualitative and quantitative approaches to define verifiability goals, we found that both methods have their merits and can yield viable definitions. This is why we propose two instantiations of the KTV framework: one following the qualitative approach and one for the quantitative approach.

### Instantiating the KTV Framework

To instantiate the KTV framework, one needs to provide a definition of a goal (or a family of goals) that a protocol is supposed to guarantee. It is important to note that, for the second parameter of Definition 1, δ, one should always aim to establish the smallest possible value. The value of δ is determined by the analysis of a concrete system rather than being fixed upfront.

### Goals for Qualitative and Quantitative Verifiability

In the following, we define two goals corresponding to the two variants of verifiability discussed above:
- **Qualitative Goal**: γql(ϕ)
- **Quantitative Goal**: γqn(k, ϕ)

The common parameter ϕ describes the trust assumptions, which determine which parties are assumed to be honest and which can be corrupted and when. In the KTV framework, the adversary sends a special message `corrupt` to a participant to corrupt it. A participant can then accept or reject such a message, allowing for modeling various forms of static and dynamic corruption. Given a run, it is easily visible if and when a party is corrupted.

For a given run \( r \) of an e-voting protocol with \( n \) eligible voters, we denote:
- \( nh \): the number of honest voters in \( r \)
- \( nd \): the number of dishonest voters in \( r \)

A party is considered honest in a run \( r \) if it has not received a `corrupt` message or has not accepted such a message throughout the entire run. We denote by \( c_1, \ldots, c_{nh} \) the actual choices of the honest voters in this run, as defined in Section IV-A.

#### Qualitative Goal (γql(ϕ))

The goal γql(ϕ) corresponds to the strong verifiability goal γSV from Section VII, but with the addition of the trust assumption parameter ϕ. Informally, this goal requires that, if the trust assumption ϕ holds true in a protocol run, then:
1. The choices of all honest voters who successfully performed their checks are included in the final result.
2. Votes of those honest voters who did not perform their check may be dropped, but not altered.
3. There is at most one ballot cast for every dishonest voter (no ballot stuffing).

If the trust assumptions ϕ are not met in a protocol run, no guarantees are expected in that run. For example, if in a setting with two bulletin boards, ϕ states that at least one of the bulletin boards should be honest, but both are corrupted by the adversary, then no guarantees need to be provided in that run.

Formally, the goal γql(ϕ) is satisfied in \( r \) (i.e., \( r \in \gammaql(\phi) \)) if either:
- (a) The trust assumption ϕ does not hold true in \( r \), or
- (b) ϕ holds true in \( r \) and there exist valid choices \( \tilde{c}_1, \ldots, \tilde{c}_n \) for which the following conditions are satisfied:
  - An election result is published in \( r \) and it is equal to \( \rho(\tilde{c}_1, \ldots, \tilde{c}_n) \).
  - The multiset \( \{\tilde{c}_1, \ldots, \tilde{c}_n\} \) consists of all the actual choices of honest voters who successfully performed their check, plus a subset of actual choices of honest voters who did not perform their check, and plus at most \( nd \) additional choices.

If the checks performed by voters do not fully guarantee that their votes are counted, such as when Benaloh checks are used (which involve probabilistic checking), then along with this goal, one will obtain a \( \delta > 0 \) due to the probability of undetected cheating. Additionally, the requirement that votes of honest voters who did not check can at most be dropped, but not altered, might only be achievable under certain trust assumptions. If weaker trust assumptions are desired, γql(ϕ) would need to be adjusted accordingly.

#### Quantitative Goal (γqn(k, ϕ))

The goal γqn(k, ϕ) refines the goal γk from Section IV, now allowing ϕ to specify trust assumptions with dynamic corruption. Similar to Section VI, we use a distance function on election results. Roughly, the goal γqn(k, ϕ) requires that the distance between the produced result and the "ideal" one (obtained when the actual choices of honest voters are counted and one choice for every dishonest voter) is bounded by \( k \), using a specific distance function \( d \).

To define \( d \), we first define a function \( fcount : C^l \rightarrow N^C \) which, for a vector \( (c_1, \ldots, c_l) \in C^l \) (representing a multiset of voters' choices), counts how many times each choice occurs in this vector. For example, \( fcount(B, C, C) \) assigns 1 to B, 2 to C, and 0 to all other choices.

The distance function \( d \) is defined as:
\[ d((c_1, \ldots, c_n), (\tilde{c}_1, \ldots, \tilde{c}_n)) = \sum_{c \in C} |fcount(c_1, \ldots, c_n)[c] - fcount(\tilde{c}_1, \ldots, \tilde{c}_n)[c]| \]

For instance, \( d((B, C, C), (A, C, C, C)) = 3 \).

The goal γqn(k, ϕ) is satisfied in \( r \) if either:
- (a) The trust assumption ϕ does not hold true in \( r \), or
- (b) ϕ holds true in \( r \) and there exist valid choices \( \tilde{c}_1, \ldots, \tilde{c}_{nh} \) and \( c_1', \ldots, c_{nd}' \) (representing possible choices of dishonest voters) such that:
  - An election result is published and it is equal to \( \rho(\tilde{c}_1, \ldots, \tilde{c}_{nh}, c_1', \ldots, c_{nd}') \).
  - \( d((c_1, \ldots, c_{nh}), (\tilde{c}_1, \ldots, \tilde{c}_{nh})) \leq k \).

When an adversary drops one honest vote, the distance in Condition (ii) increases by one, but when he replaces an honest voter's choice with another, the distance increases by two. This reflects the real effect of manipulation on the final result.

Since not all voters will check their receipts, some manipulation will go undetected. Therefore, for this goal, \( \delta = 0 \) is typically not achievable. The security analysis carried out on a concrete protocol will determine the optimal (i.e., minimal) \( \delta \) given the parameter \( k \).

### Refinements and Acknowledgements

Both goals could be refined by providing guarantees for voters who were corrupted sufficiently late in the protocol. This would require redefining what it means for a voter to be honest: voters corrupted late enough would still be considered honest for the purpose of the goal definitions. Such refinements are protocol-dependent, whereas the above goals are applicable to a wide range of protocols.

### Acknowledgements

This work was partially supported by Deutsche Forschungsgemeinschaft (DFG) under Grant KU 1434/6-3 within the priority programme 1496 “Reliably Secure Software Systems – RS3”. The research leading to these results has also received funding from the European Research Council under the European Union’s Seventh Framework Programme (FP7/2007-2013) / ERC grant agreement no 258865 (ProSecure).

### References

[References section remains unchanged]

This version of the text is more structured, clear, and professional, with improved readability and coherence.