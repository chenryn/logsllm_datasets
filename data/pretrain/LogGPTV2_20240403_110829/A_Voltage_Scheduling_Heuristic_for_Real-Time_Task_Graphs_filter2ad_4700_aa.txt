title:A Voltage Scheduling Heuristic for Real-Time Task Graphs
author:Diganta Roychowdhury and
Israel Koren and
C. Mani Krishna and
Yann-Hang Lee
A Voltage Scheduling Heuristic for Real-Time Task Graphs
D. Roychowdhury, I. Koren, C.M. Krishna
Department of Electrical and Computer Engineering
University of Massachusetts, Amherst, MA 01003
droychow,koren,PI:EMAIL
Y.-H.Lee
Department of Computer Science
Arizona State University, Tempe, AZ 85287
PI:EMAIL
Abstract
Energy constrained complex real-time systems are be-
coming increasingly important in defense, space, and con-
sumer applications.
In this paper, we present a sensible
heuristic to address the problem of energy-efﬁcient voltage
scheduling of a hard real-time task graph with precedence
constraints for a multi-processor environment. We show
that consideration of inter-relationships among the tasks in
a holisitic way can lead to an effective heuristic for reducing
energy expenditure. We developed this algorithm for sys-
tems running with two voltage levels since this is currently
supported by a majority of modern processors. We then ex-
tend the algorithm for processors that can support multiple
voltage levels. The results show that substantial energy sav-
ings can be achieved by using our scheme. The algorithm
is then compared with other relevant algorithms derived for
hypothetical systems which can run on inﬁnite voltage lev-
els in a given range. Our two voltage systems, using the task
dependencies effectively, can provide a comparable perfor-
mance with those algorithms in the cases where continuous
voltage switching is not allowed.
1. Introduction
In CMOS devices, energy consumption per cycle is pro-
portional to the square of the voltage, while circuit delay
decreases roughly linearly with the voltage. As a result,
controlling the supply voltage allows the user to trade off
workload execution time for energy consumption.
Over the past few years, many researchers have studied
0This research has been supported in part by NSF, NGS program, grant
number EIA-0102696
this tradeoff. For hard real-time systems – so-called be-
cause the workload is associated with a hard deadline –
the tradeoff is particularly challenging.
In such applica-
tions, the workload is characterized by analysis or proﬁl-
ing, so that its worst-case execution time can be bounded
with reasonable certainty. In most cases, the workload is
run periodically, with the period and deadlines known in
advance. Furthermore, many real-time applications (e.g.,
spaceborne platforms) have constraints on their power or
energy consumption. There is thus an increased need for
power-management techniques for such systems; the a pri-
ori knowledge about the workload provides an added op-
portunity to use such techniques.
Most of the power-aware voltage-scheduling work for
real-time systems has concentrated on independent tasks.
By contrast, in this paper, we consider voltage scheduling
while executing a task graph, which deﬁnes the precedence
constraints between tasks.
The problem can be informally described as follows: we
are given a task graph, the worst-case execution time of each
task and the period at which the task graph is to be executed.
This workload is to execute on a multiple-processor system,
each processor of which has its own private memory. The
task assignment in the processors and the order of the al-
gorithm is also determined apriori and serves as an input
parameter. The problem is to schedule the voltage of each
processor in such a way that the energy consumption is kept
low. Assuming the deadline of the task graph equals its pe-
riod, there will be no more than one task iteration alive in
the system at any time.
Our algorithm has both an ofﬂine and an online compo-
nent. The ofﬂine component performs voltage scheduling
based on the worst-case execution requirements. The online
component adjusts the voltage schedule as tasks complete:
in most cases, tasks consume less than their worst-case time,
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:28:21 UTC from IEEE Xplore.  Restrictions apply. 
and the remaining time can be reclaimed to run the proces-
sors slower than might otherwise be required.
The remainder of this paper is organized as follows. In
Section 2 we provide a brief survey of the relevant litera-
ture. In Section 3 we outline our algorithm and in Section 4
we provide some numerical results which serve to show its
effectiveness. The paper concludes with a brief discussion
in Section 5.
2. Literature Survey
Dynamic Voltage Scaling is increasingly being used
to efﬁciently address the problem of energy aware task
scheduling.
Initial work on dynamic voltage scheduling
[9, 28] was in the context of non-real-time systems where
the average throughput is the performance metric. Lin, et
al., treated this problem as the integer programming model
and presented heuristics for scheduling dealing with timing
and resource constraints [18]. Chang et al. in [8], present
a dynamic programming technique for solving the multiple
supply voltage scheduling problem in both non-pipelined
and functionally pipelined data-paths. The scheduling prob-
lem refers to the assignment of a supply voltage level (se-
lected from a ﬁxed and known number of voltage levels)
to each operation in a data ﬂow graph so as to minimize
the average energy consumption for given computation time
or throughput constraints or both. Results for a ARM7D
processor at two voltage frequency combinations: (5.0V,
33MHz) and (3.3V, 20MHz) are presented in [4], for the
Dhrystone 1.1 benchmarks it yields 185 MIPS/watt and 579
MIPS/watt, respectively. Yao et al. assumed that the power
usage is a convex function of the clock rate [31] and de-
rived a static voltage control heuristic to reduce energy con-
sumption. Ishihara and Yasuura presented a model of a dy-
namically variable voltage processor and basic theorems for
power-delay optimization [15]. A static voltage scheduling
problem is also proposed and formulated as an integer linear
programming (ILP) problem. They point out that two volt-
age levels are sufﬁcient and a large number of available lev-
els do not contribute much as long as the two voltage levels
are carefully chosen. Hong et al.[12], present a nonpreemp-
tive scheduling heuristic for low power core-based real-time
SOC based on dynamically variable voltage hardware. In
[13], the problem of voltage control in a problem involving
scheduling sporadic tasks in the midst of an ambient peri-
odic workload is considered. The authors point out that the
voltage transitions are fast: of the order of 10 to 100 (cid:0)sec
per volt. In another instance Burd and Brodersen discuss
the design of a variable voltage processor which can switch
voltage at the rate of 24 (cid:0)sec per volt [6]. In [20], Ma and
Shin present an energy adaptive combined static/dynamic
scheduler in Emerald Operating System to execute tasks in
mobile applications. The emphasis is on achieving effec-
tive use of limited energy by favoring low-energy and crit-
ical tasks. Qu and Potkonjak have presented a heuristic for
maximizing system utility which is based on quality of ser-
vice (QoS) under limited energy resource conditions [24].
Shin and Choi slow the processor down to avoid idling it if
the current workload is guaranteed to ﬁnish before the next
job arrival [27]. A similar slowdown approach for the peri-
odic real-time tasks which can consume energy at possibly
varying rates is presented in [5].
A simulation environment and benchmark suite evaluat-
ing voltage scaling algorithms have been presented in [23].
Lee et al.
introduced dynamic voltage algorithm for ﬁxed
priority task systems in [17]. In another work Krishna et al.,
show how voltage scaling can be based on Earliest Dead-
line First (EDF) scheduling algorithms to get energy per-
formance optimizations [16]. In [22], a class of novel al-
gorithms called real-time DVS (RT-DVS) is introduced that
modiﬁes the real-time scheduler and task management ser-
vice to provide signiﬁcant energy savings while maintaining
real-time deadline guarantee. Researchers have also pro-
posed the concept of compiler directed DVS [21] where the
compiler sets the processor frequency and voltage with the
aim of minimizing energy under real-time constraints.
In [11], the scheduling problem of independent hard real-
time tasks with ﬁxed priorities assigned in a rate monotonic
or deadline monotonic manner is addressed. This method
employs stochastic data to derive energy-efﬁcient schedules
taking the actual behavior of the real time systems into ac-
count. Several papers have also recognized the need for
both ofﬂine and online approaches to address the issue of
energy efﬁcient scheduling of independent real-time tasks
(see for example, [5, 25]).
Variable voltage scheduling as a low power design tech-
nique at the behavioral synthesis stage is discussed in [26].
Given as input an unscheduled data ﬂow graph with a tim-
ing constraint, the goal of this paper is to establish a volt-
age value at which each of the operations of the data ﬂow
graph would be performed while meeting its timing con-
straint. The authors have used a iterative graph-theoretic
approach to identify critical paths and assign nodes to a spe-
ciﬁc voltage level.
An interesting approach to power-conscious joint
scheduling of periodic task graphs and aperiodic tasks in a
distributed real-time embedded system has been proposed
in [19]. Here the authors focus on the problem of efﬁcient
scheduling of a mix of task graphs and independent tasks
and present an effective dynamic energy reduction heuristic
for them. They use a slack-based list scheduling approach
to perform static resource allocation, assignment and
scheduling of the periodic task graphs. The emphasis of
this work is to meet all hard real-time constraints, minimize
the response time of all soft aperiodic tasks and also engage
in dynamic voltage scaling and power management to
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:28:21 UTC from IEEE Xplore.  Restrictions apply. 
reduce energy consumption. It is assumed in [19] that tasks
always run to their worst-case execution times.
An initial study of tasks with precedence constraints has
been made in [32]. In this paper, a static evaluation is car-
ried out that deﬁnes the order in which the tasks are to be
executed. This order is kept unchanged, even if the task exe-
cution times are much less than the worst-case. When tasks
are completed ahead of their worst-case time, the slack that
is thus released can be used by running the processor(s) at a
lower voltage than would otherwise be required.
By contrast, in this paper, we recognize that consider-
ing precedence relationships among the tasks and the entire
shape of the task graph might help us in deriving an algo-
rithm that would achieve signiﬁcant energy savings. We
also believe that an effective technique should comprise
both online and ofﬂine components and hence we design
our ofﬂine heuristics with the online component in mind.
We focus entirely on the computation aspect of this prob-
lem in a multiprocessor system and try to come up with a
comprehensive solution using static scheduling and runtime
strategies to achieve energy efﬁcient scheduling of hard
real-time task graphs.
3. The Algorithm
The given task graph, henceforth referred to as the task
precedence graph (TPG), is assumed to have a hard dead-
line associated with it. Therefore, our algorithm tries to re-
duce energy expenditure by voltage scheduling in such a
way that the deadline is always met.
In CMOS devices, the power consumption is propor-
tional to the square of the voltage [7, 15]:
(cid:0)(cid:3) (cid:0) (cid:1)(cid:3)(cid:5)(cid:3)(cid:6)
(cid:7)(cid:7)(cid:4)
(1)
where (cid:1) is the circuit output load capacitance, (cid:3)(cid:5) is
the number of switches per clock cycle, (cid:4) is the clock fre-
quency and (cid:3)(cid:7)(cid:7) is the supply voltage. However, reduction
of power supply voltage causes increase of the circuit delay
denoted by Æ [7, 15]:
a low cost fast interconnection network. The processors
can operate in three voltage levels: (cid:3) , (cid:3), and (cid:3)(cid:7)(cid:12)
((cid:3)  (cid:8) (cid:3) (cid:8) (cid:3)(cid:7)(cid:12)). (cid:3)  and (cid:3) are voltages at which
the processors can do useful computation whereas (cid:3)(cid:7)(cid:12) is
the voltage necessary to sustain the system in idle state.
The factor by which the processor is slower at voltage (cid:3)
relative to when at the highest voltage (cid:3)  is
 (cid:12)(cid:3) (cid:0)
(cid:3)
(cid:3)  (cid:0) (cid:3)  	 (cid:3)(cid:8)
(cid:3) 	 (cid:3)(cid:8) (cid:1)
(cid:9)
(3)
where (cid:3)(cid:8) is the threshold voltage.
We deﬁne one unit of execution as the computation per-
formed by the processor at (cid:3)  in unit time. Thus, one unit
of execution will take  (cid:12)(cid:3) units of time at voltage (cid:3).
The ratio of energy consumed per cycle by a processor at
voltage (cid:3) relative to that at voltage (cid:3)  is
(cid:13)(cid:13)(cid:16)(cid:17) (cid:18)(cid:20) (cid:13) (cid:22)(cid:17)(cid:22) (cid:13)(cid:3) (cid:0) (cid:0) (cid:3)
(cid:3) (cid:1)
(cid:6)
(4)
For the task-sets we study, inter-task communication
only happens after each task has ﬁnished its computation.
Such communication consists of transfer of small amounts
of data; the communication cost can be safely ignored as in-
signiﬁcant in the types of application under consideration.
Since idle(sleep) power consumption is considerably lower
than operational power [1], the energy cost when the proces-
sors are idle is also ignored. We should also note that our
algorithm actually decreases the idle time in the processors
compared with the single voltage algorithm. Hence this is
a conservative assumption since the relative gain using our
algorithm would be even higher if we had considered the
energy cost associated with the processor idling.
We have also considered the voltage switching cost as
negligible both with respect to the time needed and the en-
ergy expended. This is justiﬁed by the fact that our algo-
rithm has at most one voltage switch within the runtime of
the task and at most one switch at the time of context switch-
ing of the tasks. We have accounted for this cost by merging
this effect into the worst case proﬁle information.
Æ (cid:0)
(cid:1)(cid:3)(cid:7)(cid:7)
(cid:3)(cid:7)(cid:7) 	 (cid:3)(cid:8)(cid:9)
(2)
3.2. The Details of the Algorithm
where  is a constant depending on the process and gate
size, (cid:3)(cid:8) is the threshold voltage, and (cid:6) varies between 1
and 2; (cid:6) (cid:0) (cid:7) for long channel devices which have no ve-
locity saturation. In this paper, we assume (cid:6) (cid:0) (cid:7) for all our
numerical experiments.
3.1 System Model
Our model consists of a multi-processor system where
each of the processors is independent and is connected by
Given the tasks we can apply any static task assignment
and ordering heuristic. Any generic multiprocessor static
task assignment algorithm can be followed. The task graph
under this assignment should be able to meet the deadline
if running to their worst case under the highest available
voltage. Any assignment that satisﬁes the above criterion
can act as a valid input to our algorithm. Once we are
given the assignment and task schedule order in the multi-
processor environment, we can apply our voltage schedul-
ing heuristic to minimize the energy expenditure. We follow
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:28:21 UTC from IEEE Xplore.  Restrictions apply. 
a two-pronged approach to achieve our objective. The ap-
proach includes an ofﬂine component - the voltage schedul-
ing of the TPG based on the static worst-case execution
proﬁle. We use the pessimistic worst case execution pro-
ﬁle approach because the system has hard real-time require-
ments and a deadline miss under any circumstances would
be catastrophic. We follow with an online, the dynamic
slack reclamation, phase.
We will use the following terms for describing our algo-
rithm. The critical path is a set of tasks from a source to
a sink of the TPG that misses the deadline under the cur-
rent voltage conﬁguration. The reverse slack or rslack of
a critical path is the difference between the deadline and
the worst case execution time of that path with the current
voltage conﬁguration. The start-time of a task is the latest
time, relative to the beginning of the execution of the task
graph, at which the particular task must be invoked, and
commit-time is the time by which the task must complete its
execution.
3.2.1. Static Voltage Scheduling
We apply any static assignment heuristic, such as the
one described in Section 3.2.3, to the TPG. In the cases
where there are not enough processors available to exploit
the parallelism inherent in the TPG, this assignment and
task ordering may lead to new dependency relationships.
We would, therefore, need to modify the original TPG by
adding new edges to accommodate these dependencies. Af-
ter the assignments and modiﬁcations are done, we ap-
ply our static voltage scheduling heuristics to the TPG. In
order to better understand this scheduling heuristic let us
rephrase the optimization problem in the following way.
Let (cid:0)(cid:0) denote the speedup in time associated with each task
(cid:1). Speedup can be explained as the difference in execution
time of a task when running under our voltage schedule and
running it entirely in (cid:2). For each path (cid:3), we have to
satisfy the constraint
(cid:0)(cid:4) (cid:0) (cid:3) 	 (cid:5)(cid:3)
(cid:0)
(cid:4)(cid:0)(cid:0)
where task (cid:6) belongs to path (cid:3), (cid:3) is the worst case exe-
cution time of the path (cid:3) without any speedups and (cid:5)(cid:3) is
the deadline associated with the path (cid:3). Our objective is to
minimize 
(cid:0)(cid:0)(cid:7) (cid:0)(cid:0) where  is the total number of tasks in
the task set. This objective function implies that we are try-
ing to minimize the amount of time needed for the tasks to
run in (cid:2)  which in turn means minimizing overall energy
expenditure.
There is a trivial solution for this problem if the dead-
line is met when all the tasks are run at (cid:2). However, the
problem becomes more interesting when some of the paths
become critical paths and a decision has to be made about
Algorithm 1 Static Voltage Scheduling
while list of critical paths not empty do
Assign weights to the tasks
taskId = choose task with maximum weight and if
more than one task has the same maximum weight
choose the one with minimum bottom level value.
pathId = choose the path with minimum rslack among
all the critical paths having taskId as a member task.
Speed up taskId using the following scheme:
if rslack can be covered by changing units from (cid:2)
to (cid:2)  then
Change the appropriate units of taskId to run them
at (cid:2)  instead of (cid:2)
else
Run the entire taskId at (cid:2)  and mark the task so that
its weight is never considered during subsequent it-
erations.
end if
Update the path execution times and remove any path
which now meets the deadline from the list of critical
paths.
end while
which task to speed up. Analyzing the expressions above,
it appears that if we speed up a task that is part of a large
number of critical paths, we affect many paths while pay-
ing the energy price only once. Based on this intuition we
formulated the following iterative algorithm to determine
which task needs to run at (cid:2)  and for how many execution
units. We start the procedure by assigning all the tasks to
run at (cid:2) and then speed them up iteratively until there
are no more critical paths left. The weight associated with
each task is dependent on the membership of the task in the
set of critical paths, every time we encounter a task in the
critical path we increment its weight by 1. When we have
to break a tie between tasks of equal weight we choose the
task nearest to the leaf of the TPG. The rationale behind this
is that we would like to schedule a task to run at (cid:2)  as late
as we can because during dynamic resource reclamation,
we could potentially re-acquire enough slack to avoid hav-
ing to run it entirely at (cid:2) . Note that we could formulate
our problem as a linear programming optimization. This,
however, would yield an optimal static scheduling which
would not attempt to increase the opportunity for dynamic
adjustments. We still have experimented with linear pro-
gramming techniques and the overall results tend to match
closely those of our static heuristic. Our static heuristic ap-
pears to give us near-optimal performance in most cases as
well as facilitating the dynamic resource reclamation in the
subsequent step.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:28:21 UTC from IEEE Xplore.  Restrictions apply. 
3.2.2. Dynamic Resource Reclamation
Once we have completed the static scheduling of the
paths, we can assign start time and commit time to the in-
dividual tasks. Since the static analysis was based on the
worst case execution proﬁle, each task will ﬁnish before or
at its commit time during actual runtime. Thus, its successor
can begin execution earlier if it has no other pending depen-
dencies and we can use this extra slack between start time