Resilience
Prediction
Energy
Response Time
SLO Violations
Overheads Memory
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(LBM) [15], executes user requests within edge nodes and
utilizes metrics like network trafﬁc and CPU utilization to
decide the worker node that takes over as a broker in case
of a failure. However,
this work assumes a homogeneous
edge setup and has been shown to often perform poorly
in heterogeneous environments [32]. The Energy-efﬁcient
Checkpointing and Load Balancing (ECLB) [17] technique
uses Bayesian methods to classify host machines into three
categories: overloaded, underloaded and normal execution.
This classiﬁcation is used to decide appropriate task migrations
to reduce the number of overloaded hosts. However, this model
only considers computational overloads and does not consider
other fault types like node thrashing or network failures that
could lead to broker nodes being compromised. We use the
best performing methods, DYVERSE and ECLB, as baselines
in our experiments, as demonstrated in prior work [13], [17].
AI-based methods. Recently, several resilience models
have been proposed that leverage AI methods like RL, sur-
rogate or reconstruction modeling. An RL based approach
is Load Balancing and Optimization Strategy (LBOS) [18]
that allocates the resources using RL. The reward of the RL
agent is calculated as a weighted average of multiple QoS
metrics to avoid system contention by balancing the load
across multiple compute nodes. The values of the weights
are determined using genetic algorithms. LBOS observes the
network trafﬁc constantly, gathers the statistics about the load
of each edge server, manages the arriving user requests and
uses dynamic resource allocation to assign them to available
edge nodes. However, RL approaches are known to be slow
to adapt in dynamic settings [33]. Most other approaches use
neural networks as a surrogate model. For instance, Effective
Load Balancing Strategy (ELBS) [19] is a recent framework
that offers an execution environment for IoT applications and
creates an interconnect among cloud and edge servers. The
ELBS method uses the priority scores to proactively allocate
tasks to edge nodes or worker nodes as brokers to avoid
system failures. It uses a fuzzy inference system to calculate
the priority scores of different tasks based on three fuzzy
inputs: SLO deadline, user-deﬁned priority, and estimated
task processing time. The priority values are generated by
a neural network acting in the capacity of a surrogate of
QoS scores. Another similar method is the Fuzzy-based Real-
Time Auto-scaling (FRAS) [20] technique that leverages a
virtualized environment for the recovery of IoT applications
that run on compromised or faulty edge nodes. Here, FRAS
executes each IoT application in a virtual machine (VM) and
performs VM autoscaling to improve execution speed and
reduce execution costs. The VM autoscaling decisions making
involves inference of system QoS using a fuzzy recurrent neu-
ral network as a surrogate model. A major drawback of such
surrogate modeling methods is that their parameters need to
be periodically ﬁne-tuned to adapt to dynamic environments,
giving rise to high overheads. Other methods in this category
generate a reconstruction of the system state and use the
deviation from the input to indicate the likelihood that the
state is faulty. For instance, TopoMAD [21] uses a topology-
aware neural network that
is composed of a Long-Short-
Term-Memory (LSTM) and a variational autoencoder (VAE)
to detect faults. However, the reconstruction error is only
obtained for the latest state, limiting them to using reactive
fault recovery policies. Other methods use slight variations of
LSTM networks with either dropout layers [34], [35], causal
Bayesian networks [36] or recurrent autoencoders [37]. A
GAN-based approach that uses a stepwise training process,
StepGAN [22], converts the input time-series into matrices and
executes convolution operations to capture temporal trends.
These methods use various thresholding techniques like Peak
Over Threshold (POT) [38] or Kernel Density Estimation
(KDE) [39]. However, such techniques are not agnostic to the
number of hosts or workloads as they assume a maximum limit
of the active tasks in the system. Moreover, even though more
accurate than heuristic based approaches, deep learning models
such as deep autoencoders, GANs and recurrent networks are
adaptive and accurate, but have a high memory footprint that
adversely affects system performance. From this category, we
test the above mentioned approaches on the testbed described
in Section V and use the empirically best techniques based
on our experiments as baselines: LBOS, ELBS, FRAS, Topo-
3
MAD and StepGAN.
III. METHODOLOGY
A. Environment Assumptions and Problem Formulation
System Model. As is commonplace in federated edge com-
puting environments, we assume a system with heterogeneous
nodes conﬁgured in a broker-worker fashion [40]. The assign-
ment of edge nodes as brokers or workers and the allocation
of all workers to one of a broker deﬁnes the topology of the
system. We denote the number of edge nodes by H. As is
common in edge federations, we assume that the broker nodes
of LEIs are interconnected and we allow data sharing among
brokers to facilitate transferring management tasks of workers
across LEIs. We also assume a bounded timeline of execution
of tasks within the federated environment, which we divide
into ﬁxed-sized scheduling intervals, where It denotes the t-
th interval (t ranging from 0 to T ). We also consider that
the edge broker can sample the resource utilization metrics
of all hosts within its LEI group at any time including CPU,
RAM, disk/network bandwidth, some additional fault-related
metrics including consumption of the swap space, disk buffers,
network buffers, disk and network I/O waits.
Fault Model. As per prior work [41], [42], we consider a
byzantine failure model for the edge nodes in our setup [43].
We assume that all failures are recoverable, i.e., the machines
can be rebooted to resume execution from their last working
state, by frequently updating snapshots of the active hosts in
the system. As in prior work, edge hosts in the same LEI are
connected to the same power supply and unrecoverable faults
like outages are ignored [42]. Failures can occur for a variety
of reasons, including software or hardware defects, such as
an inﬁnite loop or long-running uninterruptible computation,
resource exhaustion (thrashing), under-performing hardware
(throttling), external events such as a slow computer network,
misconﬁguration, and compatibility problems. We realize this
using an existing fault injection module [41] to create different
fault types like CPU overload, RAM contention, Disk attack
and DDOS attack. We speciﬁcally restrict our attention to
faults that manifest in the form of resource over-utilization;
for instance, a DDOS attack could lead to contention at the
network interface. A broker or worker node may become
unresponsive due to this resource over-utilization [44]. This
work aims to ﬁnd the best system topology in terms of
estimated QoS in case one or more broker nodes fail. This
is crucial as broker failures lead to service downtimes from
all nodes in the LEI. In case of worker failures, we simply
rerun tasks on the worker with the least resource utilization
in the LEI. As this work takes a step in the complementary
direction of traditional load-balancing and autoscaling meth-
ods, existing fault-tolerance techniques may be leveraged for
worker management [13], [17].
Workload Model. All the tasks in our system are generated
by users and transferred to the edge federation using gateway
devices. We assume that gateway devices send tasks to the
closest broker in terms of network latency, breaking ties
uniformly at random. We assume a bag-of-tasks workload
model, where a set of independent tasks enter each LEI at the
start of each scheduling interval. Each task has an associated
(soft) SLO deadline.
Formulation. In this work, we assume that the edge brokers
run software solutions to manage their worker nodes. This
includes making scheduling decisions for all incoming and
active tasks in the system. Such solutions may include various
fault tolerance and resilience models. We denote the set of
brokers by B and workers by W . We also refer to these
as broker and worker layers as per prior work [4]. In this
work, in each scheduling interval, we check which broker
or worker nodes are unresponsive (inactive) and update the
system topology to optimize QoS. We encode the undirected
topology graph of the federated edge environment at the start
of the interval It as Gt−1. Formally, at the start of the interval
It, all active nodes in the system are utilized to generate the
topology Gt to execute tasks in It. The new graph Gt may be
the same as Gt−1 in case the active node set is unchanged.
To generate the graph Gt, we utilize the performance
metrics of the previous interval, denoted by Mt−1, and the
scheduling decision by St. The performance metrics include
resource utilization and QoS metrics such as energy consump-
tion and response time. For St we assume an underlying
scheduler in the system independent from the proposed fault-
tolerance solution. Using the input graph topology Gt, perfor-
mance metrics Mt−1 and an input scheduling decision St, the
model needs to predict the performance metrics for the current
interval, i.e., Mt and a conﬁdence score Ct. Using this model,
we optimize over the topology space to ﬁnd the optimal Gt for
interval It. Without loss in generality, whenever unambiguous,
we drop the subscripts for the sake of simplicity. Hence, we
only refer to the inputs and outputs as G, M, S and C.
B. CAROL Model
Node-Shift. We assume that the network has tens of broker
and worker nodes. In our work, the number of brokers and
the system topology is known to all nodes in the federation.
Whenever a broker node fails, we consider the worker nodes
of the corresponding broker as being “orphaned”. In such
an event, either one of the worker nodes is shifted to the
broker layer, or another node in the broker layer manages
the orphaned nodes. This shift of nodes from worker layer
to broker layer gives rise to the name “node-shift” and is
similar to the fault-tolerance schemes used in software deﬁned
networks (SDNs) [45]. Considering an input topology G, there
are multiple types of node shifts that may increase, decrease
or even keep the broker count static. Three types of worker-
to-broker node-shift mechanisms considered in this work are
described below with a visualization presented in Figure 1
instead. We similarly consider the respective counterparts as
the broker-to-worker node-shifts.
• Type 1: If a broker node fails, two of the orphaned nodes
may be shifted to the broker layer and the remaining
orphaned nodes may be evenly distributed among these
two new brokers. This increases the broker count by one,
4
Fig. 1. Possible node-shifts in CAROL. Nodes marked in red are the high consumption brokers that break-down.
also increasing the management capacity of the system
for higher throughput at the broker layer.
• Type 2: The orphaned nodes could be assigned to another
active broker in the system. This decreases the broker
count than before failure and increases the computational
throughput of the worker layer.
• Type 3: One of the orphaned worker nodes may be
assigned to be the broker for the other worker nodes.
This keeps the same number of broker nodes as before
the failure. The three node-shift types may be utilized to
trade off the throughputs of the broker and worker layers.
However, in heterogeneous edge federations, where nodes
with disparate resource capacities may be present, the choice
of the worker node to shift to the broker layer becomes vital.
Moreover, with heterogeneous broker nodes, the choice of
the broker nodes to which the orphaned nodes are assigned
affects the QoS of the system. Another crucial factor is the
overhead corresponding to the node-shift operations. This is
due to the initialization of the broker management systems and
synchronization of the system topology with other brokers in
the federation.
Another critical aspect in ﬁnding the best graph topology is
the workload heterogeneity across broker nodes. As shown in
Figure 1, the node operations can lead to a different number of
worker nodes and subsequently computational throughput of
disparate LEIs. A single node-shift step might not be sufﬁcient
to manage resources in case of different computational loads
across LEIs. Thus, a sequence of node-shifts may need to be
tested to discover the topology with optimal QoS. However,
generating QoS scores for a large number of node-shift se-
quences may not be feasible in latency-critical settings where
generating QoS scores by execution or simulation might be a
time-consuming activity. This is because a node-shift entails
transfer of broker level data to the worker node and initializing
management software containers, both of which give rise to a
higher latency.
Conﬁdence-Aware Model. To eschew the costly execution
of multiple node-shift sequences and observe their effects on
QoS, we need a lightweight model that mimics the behavior
of a computationally expensive simulation or execution [46].
Such models are referred to as “surrogate models” in the litera-
5
ture [46]. Using a surrogate model enables such methods to run
optimization in the input space and generate decisions, such as