(cid:1)(cid:4)(cid:5)
(cid:1)(cid:2)(cid:3)
(cid:20)(cid:21)(cid:22)(cid:23)(cid:15)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:29)
(cid:20)(cid:21)(cid:22)(cid:23)(cid:15)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:30)
(cid:31)(cid:32)(cid:22)(cid:23)(cid:15)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:29)
(cid:31)(cid:32)(cid:22)(cid:23)(cid:15)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:30)
(cid:5)(cid:1)
(cid:5)(cid:2)
(cid:5)(cid:3)
(cid:5)(cid:4)(cid:4)
(cid:5)(cid:4)(cid:5)
(cid:5)(cid:4)(cid:1)
(cid:5)(cid:4)(cid:2)
(cid:5)(cid:4)(cid:3)
(cid:5)(cid:6)(cid:4)
(cid:5)(cid:1)
(cid:5)(cid:2)
(cid:5)(cid:3)
(cid:5)(cid:4)(cid:4)
(cid:5)(cid:4)(cid:5)
(cid:5)(cid:4)(cid:1)
(cid:5)(cid:4)(cid:2)
(cid:5)(cid:4)(cid:3)
(cid:5)(cid:6)(cid:4)
(cid:18)(cid:5)(cid:19)(cid:20)(cid:14)(cid:3)(cid:9)(cid:4)(cid:21)(cid:9)(cid:7)(cid:14)(cid:14)(cid:3)(cid:16)
(cid:13)(cid:14)(cid:10)(cid:15)(cid:4)(cid:16)(cid:8)(cid:17)(cid:18)(cid:8)(cid:19)(cid:4)(cid:4)(cid:16)(cid:11)
(cid:10)(cid:11)
(cid:9)
(cid:8)
(cid:7)
(cid:6)
(cid:5)
(cid:4)
(cid:3)
(cid:2)
(cid:1)
(cid:1)(cid:9)
(cid:1)(cid:8)
(cid:1)(cid:7)
(cid:1)(cid:6)
(cid:1)(cid:5)
(cid:1)(cid:4)
(cid:1)(cid:3)
(cid:1)(cid:2)
(cid:20)(cid:21)(cid:22)(cid:23)(cid:15)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:29)
(cid:20)(cid:21)(cid:22)(cid:23)(cid:15)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:30)
(cid:31)(cid:32)(cid:22)(cid:23)(cid:15)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:29)
(cid:31)(cid:32)(cid:22)(cid:23)(cid:15)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:30)
(cid:4)(cid:1)
(cid:4)(cid:2)
(cid:4)(cid:3)
(cid:4)(cid:4)(cid:4)
(cid:4)(cid:4)(cid:5)
(cid:4)(cid:4)(cid:1)
(cid:12) (cid:13)(cid:14) (cid:15)(cid:4)(cid:16)(cid:8)(cid:17)(cid:18)(cid:8)(cid:19)(cid:4)(cid:4)(cid:16)(cid:10)
(cid:4)(cid:4)(cid:2)
(cid:4)(cid:4)(cid:3)
(cid:4)(cid:6)(cid:4)
(a) The throughput for OBLIVP2P-1 linearly
scales with the increase in network size.
(b) The latency for fetching a block for
OBLIVP2P-1 reduces up to 213 and then be-
comes constant.
(c) The latency for
sync operation for
OBLIVP2P-1 reduces up to 213 and then be-
comes constant.
Figure 3: Theoretical (Th) and experimental (Ex) comparison of OBLIVP2P-0 and OBLIVP2P-1 parameters for block size of 512 KB
(cid:10)
(cid:9)
(cid:3)
(cid:8)
(cid:7)
(cid:6)
(cid:5)
(cid:4)
(cid:2)
(cid:3)
(cid:2)
(cid:1)
(cid:1)(cid:7)(cid:5)(cid:6)
(cid:1)(cid:6)(cid:8)
(cid:1)(cid:4)(cid:6)
(cid:1)(cid:8)
(cid:1)(cid:4)
(cid:1)(cid:2)(cid:3)(cid:7)(cid:5)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:6)(cid:7)(cid:5)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:4)(cid:5)(cid:6)(cid:7)(cid:5)
(cid:20)(cid:21)(cid:22)(cid:23)(cid:14)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:29)
(cid:20)(cid:21)(cid:22)(cid:23)(cid:14)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:30)
(cid:31)(cid:32)(cid:22)(cid:23)(cid:14)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:29)
(cid:31)(cid:32)(cid:22)(cid:23)(cid:14)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:27)(cid:22)(cid:30)
(cid:12)(cid:22)(cid:23)(cid:24)(cid:25)(cid:9)(cid:26)(cid:12)
(cid:12)(cid:22)(cid:23)(cid:11)(cid:12)
(cid:17)
(cid:16)
(cid:15)
(cid:14)
(cid:8)
(cid:13)
(cid:12)
(cid:11)
(cid:10)
(cid:9)
(cid:8)
(cid:5)
(cid:7)
(cid:2)
(cid:6)
(cid:5)
(cid:4)
(cid:3)
(cid:2)
(cid:1)
(cid:1)(cid:4)(cid:8)
(cid:1)(cid:7)(cid:4)
(cid:1)(cid:8)
(cid:1)(cid:7)
(cid:1)(cid:2)(cid:3)(cid:5)(cid:6)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:4)(cid:5)(cid:6)
(cid:1)(cid:2)(cid:14)(cid:4)(cid:3)(cid:14)(cid:8)(cid:21)(cid:29)(cid:27)(cid:20)
(cid:30)(cid:31)(cid:7)(cid:14)(cid:3)(cid:21)(cid:25)(cid:14)(cid:28)(cid:8)(cid:27)(cid:20)
(cid:1)(cid:6)(cid:10)
(cid:1)(cid:9)(cid:6)
(cid:1)(cid:10)
(cid:1)(cid:9)
(cid:1)(cid:2)(cid:3)(cid:7)(cid:8)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:6)(cid:7)(cid:8)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:9)(cid:8)(cid:6)(cid:7)(cid:8)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:2)(cid:4)(cid:5)(cid:2)(cid:6)(cid:7)(cid:8)
(cid:17)
(cid:16)
(cid:15)
(cid:14)
(cid:8)
(cid:13)
(cid:12)
(cid:11)
(cid:10)
(cid:9)
(cid:8)
(cid:5)
(cid:7)
(cid:2)
(cid:6)
(cid:5)
(cid:4)
(cid:3)
(cid:2)
(cid:1)
(cid:7)(cid:1)
(cid:7)(cid:2)
(cid:7)(cid:3)
(cid:7)(cid:4)(cid:4)
(cid:7)(cid:4)(cid:5)
(cid:7)(cid:4)(cid:1)
(cid:7)(cid:4)(cid:2)
(cid:7)(cid:4)(cid:3)
(cid:7)(cid:6)(cid:4)
(cid:5)(cid:1)
(cid:5)(cid:2)
(cid:5)(cid:3)
(cid:5)(cid:4)(cid:4)
(cid:5)(cid:4)(cid:5)
(cid:5)(cid:4)(cid:1)
(cid:5)(cid:4)(cid:2)
(cid:5)(cid:4)(cid:3)
(cid:5)(cid:6)(cid:4)
(cid:11)(cid:12)(cid:13)(cid:14)(cid:9)(cid:15)(cid:4)(cid:16)(cid:17)(cid:4)(cid:18)(cid:9)(cid:9)(cid:15)(cid:19)
(cid:18)(cid:5)(cid:19)(cid:20)(cid:14)(cid:3)(cid:9)(cid:4)(cid:21)(cid:9)(cid:7)(cid:14)(cid:14)(cid:3)(cid:16)
(cid:11)(cid:12)
(cid:12)(cid:9)
(cid:12)(cid:7)
(cid:12)(cid:4)
(cid:18)(cid:19)(cid:20)(cid:21)(cid:22)(cid:23)(cid:24)(cid:23)(cid:9)(cid:4)(cid:7)(cid:8)(cid:21)(cid:25)(cid:21)(cid:26)(cid:27)(cid:8)(cid:21)(cid:4)(cid:28)(cid:16)
Figure 4:
The data transferred through
the tracker for OBLIVP2P-0 increases linearly
with the number of peers
Figure 5: The throughput for blocksize 128
KB and 1 MB increases with increase in the
network size.
Figure 6: Impact of optimizations (O1-O3)
on the throughput of OBLIVP2P-1 for 214
peers and blocksize of 512 KB.
oblivious P2P system. Further, the network operator can
deploy multiple trackers to serve peers simultaneously,
which leads to the throughput of OBLIVP2P-1 propor-
tional to the number of trackers.
5.2 Latency Overhead and Breakdown
We deﬁne the latency as the time required to perform one
ORAM operation in our P2P protocol. We measure the
latency for the following operations:
Fetch. Figure 3b shows that the average time for fetch-
ing a block of 512 KB increases for OBLIVP2P-0 with
increase in the size of the network. This is due to the
increased computation and bandwidth overhead at the
tracker. However, for OBLIVP2P-1, the latency initially
reduces with the increasing number of peers (from 25 to
211 ) and then becomes constant after the network is large
enough (around 213) to distribute the computation cost
in the network3. OBLIVP2P-1 has a higher latency for
fetch as compared to OBLIVP2P-0 due to the expensive
computation required for performing scalar multiplica-
tion. The average time for fetching a block of size 512
KB is around 0.31 s for a network size of 214 peers and
3Since a large number of nodes (e.g., over 1000 nodes) share one
physical machine, its limited computation power drastically affects our
result. Therefore, to be more realistic, we use the ideal computing
and decoding/encoding time for each node solely in one physical ma-
chine as the computing time per node, and simulate our experiments
for OBLIVP2P-1.
remains steady with increase in the number of peers.
Sync. We measure the time for performing a sync op-
eration for different network sizes. Figure 3c shows
that the time for performing a sync operation increases
in OBLIVP2P-0 with increase in the number of peers.
Whereas for OBLIVP2P-1, the sync time reduces grad-
ually at ﬁrst and then becomes steady after the network
size reaches 213 peers which is as expected through our
theoretical calculation. OBLIVP2P-1 uses the peers in
the network to distribute the computation load and hence
the sync time tends to be steady for large network sizes.
Data transferred through tracker. Figure 4 shows the
amount of data that is transferred through the tracker per
request. We perform this measurement to show that the
centralized tracker becomes a bottleneck in OBLIVP2P-
0. The amount of data that the tracker has to pro-
cess increases with increase in the number of peers.
At 221 peers, the amount of data is 118 MB (almost)
reaching the bandwidth limit (128 MBps) of the tracker.
Whereas, for OBLIVP2P-1 the amount of data trans-
ferred is around 1 MB for 221 peers. This implies that
the tracker could manage up to 128 copies of ORAM tree
in parallel, which will increase the overall throughput by
128 times.
Result 3. OBLIVP2P has no centralized infrastructure
as a bottleneck, ensuring that communication and com-
putational overhead can be completely ofﬂoaded to the
network.
USENIX Association  
25th USENIX Security Symposium  957
13
5.3 Optimization Measurements
logq logNp).
We perform incremental experiments to quantify the im-
pact of each of the introduced optimizations on the over-
all throughput in Section 4.4, as shown in Figure 6. We
ﬁx the number of peers in the network to be equal to 214
and the block size to 512 KB. We chose our optimization
parameters based on our results in section 5.3. We ﬁx the
number of replicas to be equal to A = 3, i.e., the same
data block is replicated three times. The burst parameter
needs to be in O( B
logq logNp), where Np is the number
of peers, B the block size, and q the elliptic curve group
order. Finally, we ﬁx the number of parallel peers in the
OblivSel.Select algorithm to be in O( B
O1: Replication. Replication enables to perform A =
3 fetch operations in parallel. This implies that the
throughput theoretically increases 3 times when com-
pared to our baseline without any optimizations. Our
experimental results show that we have 2.55 times im-
provement over the baseline, as expected theoretically.
O2: Pipelining. We evaluate the effect of our optimiza-
tion (O2) that absorbs the eviction time by pipelining the
fetch requests to different versions of the ORAM tree in
the P2P network. We show that this optimization, when
coupled to (O1), has theoretically increased the overall
throughput by 23.05 times if compared to the baseline.
Our experiments are aligned to our theoretical results and
show 17.2 times improvement over the baseline with a
burst parameter of 17. Clearly, if the number of versions
increases beyond 17, then OBLIVP2P-1 can handle par-
allel accesses, hence increasing the system throughput.
O3: Parallelizing m peers. We measure the effect of
parallelizing the computation load of m peers by lever-
aging more peers in the network on the overall through-
put of the system. We increase the number of peers to
116 peers that are used to compute the fetch and sync
operations. Our theoretical result shows an improve-
ment of 4398 times over the baseline, when coupled with
(O1) and (O2). Our experiments support this result and
demonstrates 1589 times improvement, the difference is