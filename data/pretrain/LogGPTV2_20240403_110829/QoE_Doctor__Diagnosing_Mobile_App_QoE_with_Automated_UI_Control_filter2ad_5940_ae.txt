 400
)
s
(
e
m
i
t
i
g
n
d
a
o
l
l
a
i
t
i
n
I
 80
 70
 60
 50
 40
 30
 20
 10
 0
3G
LTE
 200
 100
 500
Throttled bandwidth (kbps)
 300
 400
F
D
C
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 25
 50
 75
 100
 125
 150
 175
 200
Initial loading time (s)
3G throttled
3G unthrottled
LTE throttled
LTE unthrottled
Figure 17: The video rebuffering ratio and the initial loading
time distribution under throttled and unthrottled conditions
for both C1 3G and C1 LTE.
)
s
p
b
M
(
t
u
p
h
g
u
o
r
h
T
)
s
p
b
M
(
t
u
p
h
g
u
o
r
h
T
Traffic rate
3G traffic shaping
 50
 100
 150
 200
 250
 300
Traffic rate
LTE traffic policing
 0.25
 0.2
 0.15
 0.1
 0.05
 0
 0
 0.25
 0.2
 0.15
 0.1
 0.05
 0
 0
 50
 100
 150
 200
 250
 300
Time (s)
Figure 18: Throughput comparison between C1 3G trafﬁc
shaping and C1 LTE trafﬁc policing.
Finding 6. Network bandwidth throttling causes more than
30 seconds (15×) more initial loading time and increases the
rebuffering ratio from around 0% to 50% on average. We
randomly play 100 videos from our video dataset under both
throttled and unthrottled conditions in C1 3G and C1 LTE, and the
results are shown in Fig. 17. For C1 3G, the initial loading time
Figure 19: Rebuffering ratio
for C1 LTE is consistently
greater than that for C1 3G
Figure 20: Initial loading time
for C1 LTE is consistently
greater than that for C1 3G
increases by 30 seconds after the bandwidth throttling, which is
15× more compared to the unthrottled case. For C1 LTE, it is even
worse:
the increased initial loading time is more than 1 minute,
which is 48× more! For the rebuffering ratio, without throttling
there are nearly no rebuffering events, but with throttling, more than
50% and 75% of the total playback time is spent in rebuffering for
C1 3G and C1 LTE respectively, which makes the user experience
highly negative.
Besides the effect of bandwidth throttling, from Fig. 17 we have
another interesting observation: both the value and the variance of
the initial loading time and the rebuffering ratio for throttling in C1
3G are much smaller than those for throttling in C1 LTE. Next, we
use QoE Doctor to further investigate the root cause.
Finding 7. The throttling mechanism choice causes more
variance in the initial loading time and the rebuffering ratio
in C1 LTE. By contacting carrier C1, we ﬁnd out
that C1
3G and C1 LTE actually adopt different throttling mechanisms:
C1 3G uses trafﬁc shaping, and C1 LTE uses trafﬁc policing.
Both throttling mechanisms use the token bucket algorithm for
rate limiting, but when the trafﬁc rate reaches the conﬁgured
maximum rate, trafﬁc policing drops excess trafﬁc while trafﬁc
shaping retains excess packets in a queue and then schedules the
excess for later transmission [11]. Using our application layer
and transport/network layer analyzer, we compare the C1 3G
and C1 LTE throttling impact in Fig. 18.
In the network trace,
compared with C1 LTE, in C1 3G there are relatively fewer TCP
retransmissions, which implies less TCP packet drops on 3G base
station. Thus, the average throughput variance for C1 3G is smaller
than that for C1 LTE. These are consistent with the more bursty
trafﬁc pattern expected in trafﬁc policing [11], which is very likely
the reason for more variance in the initial loading time and the
rebuffering ratio in C1 LTE.
160Finding 8. A simple video resolution adaptation in YouTube
increases the initial loading time by 50% and doubles the
rebuffering ratio in C1 LTE compared to C1 3G. Throttling
mechanism choice can explain the QoE variance differences
between C1 3G and C1 LTE, but it does not explain the value
differences. To understand the relationship between throttling
bandwidth and the video QoE with rebuffering events, we utilize
a Linux trafﬁc control tool tc [10]. We select a small video set
(26 videos) randomly from the videos with less than 90 seconds
lengths in our video dataset, and automatically play them using
QoE Doctor. We repeat the bandwidth limits of 100 kbps, 200
kbps, 300 kbps, 400 kbps, and 500 kbps for both C1 3G and C1
LTE network, and the results are shown in Fig. 19 and Fig. 20. In
these ﬁgures, for all bandwidth limits, the rebuffering time ratio and
initial loading time for C1 LTE is consistently much higher than
that of C1 3G. Using our cross-layer analyzer, we ﬁnd that the root
cause lies in the total downloaded video data: in C1 LTE around
96.6% (∼ 40 MB) more data is downloaded than that in C1 3G.
From the MediaPlayer log [5] in Android logcat [4], we ﬁnd out
the reason: the default video resolution is 320×180 px for 3G and
640×360 px for C1 LTE. Due to this default adaptation, in Fig. 17
YouTube videos on throttled C1 LTE have 50% higher initial
loading time and double the rebuffering ratio than on throttled C1
3G. LTE has better maximum throughput than 3G, but it does not
imply that the throughput in LTE is always better in any network
conditions. We suggest that to improve its video QoE, YouTube
should adapt the video resolution based on more ﬁne-grained real-
time network performance instead of simply based on network type
information.
7.6 YouTube:
Advertisement
Impact on
Initial Loading Time
Ads that play in the video stream before the actual video (known
as “pre-roll ads") are a popular monetization approach for major
video providers. Previous work [25] has studied the effectiveness
of video ads as measured by their completion and abandonment
rates. We instead focus on the impact of pre-roll ads on the initial
loading time for YouTube.
Experiment setup. We use the same experimental setup and video
data set as §7.5. We use QoE Doctor to play 100 random videos
from the dataset (in total 13.5 hours) under C1 3G, C1 LTE and
WiFi. In our experiments, the cellular signal strength for C1 3G
and C1 LTE is around -95 to -105 dbm. Note that the ad loading
latency in the results in this section might be shorter in areas with
better network condition.
Finding 9. Advertisements reduce the initial loading time of the
actual video, but double the total initial loading time. Fig. 21
shows the distribution of initial loading time under C1 3G, C1 LTE
and WiFi. We measure four values: “video after ad" refers to the
time to load the video after a pre-roll ad; “video, no ad" refers to
the time to load a video in the absence of a pre-roll ad; “ad" refers
to the ad loading time, and “ad + video" refers to the combined
loading time for both ad and video in the presence of a pre-roll ad.
Interestingly, the ad loading time is longer than the actual video
loading time for every network. We use the cross-layer analyzer
to examine the network trafﬁc inside the QoE Window, and ﬁnd
that the video appears to be pre-loading while the ad is loading
as well. Despite this pre-loading, the total initial loading time is
roughly doubled. Most interestingly, on WiFi the video loading
time is largely masked by the ad loading time, but on cellular
networks there is still a substantial loading delay for the actual
video. By examining network trafﬁc, the root cause is that the
ad loading process often has to compete with trafﬁc to analytics
 1
 0.8
 0.6
 0.4
 0.2
 1
 0.8
 0.6
 0.4
 0.2
 1
 0.8
 0.6
 0.4
 0.2
)
E
T
L
(
F
D
C
)
G
3
(
F
D
C
)
i
F
W
i
(
F
D
C
Video after ad
Video, no ad 
Ad 
Ad + video
 0
 2000
 4000
 6000
 8000  10000  12000  14000
Loading times (ms)
Figure 21: CDFs of video loading times for different network
types, in the presence and absence of ads
services. Overall, cellular network has an additional delay of 4-
6 seconds of loading time when an ad is played, on top of the 5
seconds the user must spend in watching an ad before skipping it.
7.7 Web Browsing: RRC State Machine
Impact on Web Page Loading Time
As described by a previous study [33], the RRC state machine
in 3G network generally consists of 3 states shown in Fig. 1.
Surprisingly, during our experiment we ﬁnd from QxDM that C2
has simpliﬁed its 3G RRC state machine into a 2-state model,
which is shown in Fig. 22. This ﬁnding makes us curious about
the possible inﬂuence this RRC state machine model change may
have on mobile app QoE. In this section, we use QoE Doctor to
study the impact of different RRC state machine models on the web
page loading time in Android Google Chrome web browser version
18.0.1025469.
Experiment setup. In order to evaluate over real user experiences,
we conducted a user study with 20 students from University of
Michigan for 9 months. We installed tcpdump on 20 Samsung
Galaxy S3 devices to collect network traces, and we anonymized
device identities to protect user privacy. Using TCP and HTTP
analysis, we separate the trafﬁc generated by the Chrome browser
app, and then ﬁlter out the the URLs visited by the real users
along with the inter-request timings.
In this ﬁltering process,
we ﬁrst parse the traces to extract the links inside the HTTP
requests, and then clean up the links manually to make sure that
they are delivering web pages with meaningful content instead of
downloading objects such as images, icons and scripts. QoE Doctor
takes the ﬁltered URL list in and replays the web browsing behavior
in Google Chrome app on the C1 3G network and C2 3G network.
C1 uses the 3-state model and C2 uses the simpliﬁed 2-state model
in Fig. 22. As RRC state machine behavior is sensitive to the timing
between network-related actions, in the experiment we not only
replay the sequence of user actions, but use the URL visiting time
intervals as well to ensure that the timings between user actions are
also replayed.
In the experiments, the generated URL list for replay is 4 hours
in length and has 597 URLs belonging to 71 different sites with a
161DCH
High Power
Demotion
Promotion
DISCONNECTED
Low Power
RRC transition
C1
C2
DCH
DCH→FACH→DCH
FACH→DCH
PCH→FACH→DCH
DCH→Disconnected→DCH
Disconnected→DCH
76.6 % 93.5 %
3.2 %
16.0 %
4.2 %
—
—
—
—
—
0.2 %
6.3 %
)
J
(
y
g
r
e
n
e