0.2533 
0.4962 
0.6116 
The content traffic among the sites is quite different. For example, the EX dataset 
is more complex containing file uploads of different media types (pdf, jpg, ppt, etc. ) 
and webmail traffic; the W dataset contain less of this type of traffic while W1 is the 
simplest, containing almost no file uploads. Hence, each of the  site-specific payload 
models is diverse, increasing the likelihood that a worm payload will be detected by at 
least one of these sites. To avoid detection, the worm exploit would have to be padded 
in such a way that its content description would appear to be normal concurrently for 
all of these sites.  
Mimicry attacks are possible if the attacker has access to the same information as 
the victim. In the case of application payloads, attackers (including worms) would not 
know the distribution of the normal flow to their intended victim. The attacker would 
need to sniff each  site  for a long period of time and analyze the traffic in the same 
fashion as the detector described herein, and would also then need to figure out how 
Anomalous Payload-Based Worm Detection and Signature Generation 
235 
to pad their poison payload to mimic the normal model. This is a daunting task for the 
attacker who would have to be clever indeed to guess the exact distribution as well as 
the threshold logic to deliver attack data that would go unnoticed. Additionally, any 
attempt to do this via probing, crawling or other means is very likely to be detected.  
Besides  mimicry  attack,  clever  worm  writers  may  figure  a  way  to  launch  'training 
attacks' [6] against anomaly detectors such as PAYL. In this case, the worm may send a 
stream of content  with increasing diversity to  its next victim  site  in order to train the 
content sensor to produce models where its exploit no longer would appear anomalous. 
This as well is a daunting task for the worm. The worm would be fortunate indeed to 
launch  its  training  attack  when  the  sensor  is  in  training  mode  and  that  a  stream  of 
diverse data would go unnoticed while the sensor is in detection mode. Furthermore, the 
worm would have to be extremely lucky that each of the content examples it sends to 
train the sensor would produce a "non-error" response from the intended victim. Indeed, 
PAYL  ignores  content  that  does  not  produce  a  normal  service  response.  These  two 
evasion  techniques,  mimicry  and  training  attack,  is  part  of  our  ongoing  research  on 
anomaly detection, and a formal treatment of the range of "counter-evasion" strategies 
we are developing is beyond the scope of this paper. 
3.4   Worm Detection Evaluation 
In  this  section,  we  provide  experimental  evidence  of  the  effectiveness  of  PAYL  to 
detect  incoming  worms.  In  our  previous  RAID  paper  [20],  we  showed  PAYL’s 
accuracy  for  the  DARPA99  dataset,  which  contains  a  lot  of  artifacts  that  make  the 
data  too  regular  [9].  Here  we  report  how  PAYL  performs  over  the  three  real-world 
datasets using known worms available for our research. Since all three datasets were 
captured from real traffic, there is no ground truth, and measuring accuracy was not 
immediately  possible.  We  thus  needed  to  create  test  sets  with  ground  truth,  and  we 
applied Snort for this purpose.  
Each dataset  was split  into two distinct chronologically-ordered portions, one for 
training and the other for testing, following the 80%-20% rule. For each test dataset,  
Fig. 5. ROC of PAYL detecting incoming worms, false positive rate restricted to less than 0.5% 
236 
K. Wang, G. Cretu, and S.J. Stolfo 
we first created a clean set of packets free of any known worms still flowing on the 
Internet as background radiation. We then inserted the same set of worm traffic into 
the cleaned test set using tcpslice. Thus, we created ground truth in order to compute 
the accuracy and false positive rates. 
The worm set includes CodeRed, CodeRed II, WebDAV, and a worm that exploits 
the IIS Windows media service, the nsiislog.dll buffer overflow vulnerability (MS03-
022).  These  worm  samples  were  collected  from  real  traffic  as  they  appeared  in  the 
wild,  from  both  our  own  dataset  and  from  a  third-party.  Because  PAYL  only 
considers  the  packet  payload,  the  worm  set  is  inserted  at  random  places  in  the  test 
data.  The  ROC  plots  in  Figure  5  show  the  result  of  the  detection  rate  versus  false 
positive rate over varying threshold settings of the PAYL sensor.   
The detection rate and false positive are both based on the number of packets. The 
test set contains 40 worm packets although there are only 4 actual worms in our zoo. 
The plots show the results for each data set, where each graphed line is the detection 
rate  of  the  sensor  where  all  4  worms  were  detected.  (This means  more  than  half  of 
each the worm’s packets were detected as anomalous content.) From the plot we can 
see that although the three sites are quite different in payload distribution, PAYL can 
successfully  detect  all  the  worms  at  a  very  low  false  positive  rate.  To  provide  a 
concrete example we measured the average false alerts per hour for these three sites. 
For 0.1% false positive rate, the EX dataset has 5.8 alerts per hour, W1 has 6 alerts 
per hour and W has 8 alerts per hour. 
We manually checked the packets that were deemed false positives. Indeed, most 
of  these  are  actually  quite  anomalous  containing  very  odd  abnormal  payload.  For 
example, in the EX dataset, there are weird file uploads, in one case a whole packet 
containing nothing but a repetition of a character with byte value E7 as part of a word 
file.  Other  packets  included  unusual  HTTP  Get  requests,  with  the  referrer  field 
padded with many “Y” characters (via a product providing anonymization).  
We note that some worms might fragment their content into a series of tiny packets 
to  evade  detection.  For  this  problem,  PAYL  buffers  and  concatenates  very  small 
packets of a session prior to testing. 
We  also  tested  the  detection  rate  of  the  W32.Blaster  worm  (MS03-026)  on  TCP 
port 135 port using real RPC traffic inside Columbia’s CS department. Despite being 
much  more  regular  compared  to  HTTP  traffic,  the  worm  packets  in  each  case  were 
easily detected  with zero false positives. Although at first  blush, 5-8 alerts per hour 
may seem too high, a key contribution of this paper is a method to correlate multiple 
alerts to extract from the stream of alerts true worm events. 
4   Worm Propagation Detection and Signature Generation by 
Correlation 
In  the  previous  section,  we  described  the  results  using  PAYL  to  detect  anomalous 
packet  content.  We  extended  the  detection  strategy  to  model  both  inbound  and 
outbound traffic from a protected host, computing models of content flows for ingress 
and  egress  packets.  The  strategy  thus  implies  that  within  a  protected  LAN,  some 
infected internal host will begin a propagation sending outbound anomalous packets. 
Anomalous Payload-Based Worm Detection and Signature Generation 
237 
When  this  occurs  for  any  host  in  the  LAN,  we  wish  to  inoculate  all  other  hosts  by 
generating and distributing worm packet signatures to other hosts for content filtering. 
We  leverage  the  fact  that  self-propagating  worms  will  start  attacking  other 
machines  automatically  by  replicating  itself,  or  at  least  the  exploit  portion  of  its 
content, shortly after a host is infected. (Polymorphic worms may randomly pad their 
content,  but  the  exploit  should  remain  intact.)  Thus  if  we  detect  these  anomalous 
egress  packets  to  port  i  that  are  very  similar  to  those  anomalous  ingress  traffic  to  
port  i,  there  is  a  high  probability  that  a  worm  that  exploits  the  service  at  port  i  has 
started its propagation.  Note that these are the very first packets of the propagation, 
unlike  the  other  approaches  which  have  to  wait  until  the  host  has  already  shown 
substantial amounts of unusual scanning and probing behavior. Thus, the worm may 
be stopped at its very first propagation attempt from the first victim even if the worm 
attempts to be slow and stealthy to avoid detection by probe detectors. We describe 
the  ingress/egress  correlation  strategy  in  the  following  section.  We  note,  however, 
that  the  same  strategy  can  be  applied  to  ingress  packets  flowing  from  arbitrary 
(external)  sources  to  internal  target  IP's.  Hence,  ingress/ingress  anomalous  packet 
correlation may be viewed as a special case of this strategy. 
Careful treatment of port-forwarding protocols and services, such as P2P and NTP 
(Port  123)  is  required  to  apply  this  correlation  strategy,  otherwise  normal  port 
forwarding  may  be  misinterpreted  as  worm  propagations.  Our  work  in  this  area 
involves two strategies, truncation of packets (focusing on control data) and modeling 
of the content of media [8]. This work is beyond the scope of this paper due to space 
limitations, and will be addressed in a future paper.  
4.1   Ingress and Egress Traffic Correlation 
When PAYL detects some incoming anomalous traffic to port i, it generates an alert 
and places the packet content on a buffer list of “suspects”. Any outbound traffic to 
port  i  that  is  deemed  anomalous  is  compared  to  the  buffer.  The  comparison  is 
performed against the packet contents and a string similarity score is computed. If the 
score is higher than some threshold, we treat this as possible worm propagation and 
block or delay this outgoing traffic. This is different from the common quarantining 
or  containment  approaches  which  block  all  the  traffic  to  or  from  some  machine. 
PAYL  will  only  block  traffic  whose  content  is  deemed  very  suspicious,  while  all 
other traffic may proceed unabated maintaining critical services.  
There are many possible  metrics  which can apply to decide the similarity of two 
strings. The several approaches we have considered, tested and evaluated include: 
String  equality  (SE):  This  is  the  most  intuitive  approach.  We  decide  that  a 
propagation has started only if the egress payload is exactly the same as the ingress 
suspect packet. This metric is very strict and good at reducing false positives, but too 
sensitive to any tiny change in the packet payload. If the worm changes a single byte 
or just changes its packet fragmentation, the anomalous packet correlation will miss 
the propagation attempt. (The same is true when comparing thumbprints of content.) 
Longest  common  substring  (LCS):  The  next  metric  we  considered  is  the  LCS 
approach. LCS is less exact than SE, but avoids the fragmentation problem and other 
small  payload  manipulations.  The  longer  the  LCS  that  is  computed  between  two 
238 
K. Wang, G. Cretu, and S.J. Stolfo 
packets, the greater the confidence that the suspect anomalous ingress/egress packets 
are more similar. The main shortcoming of this approach is its computation overhead 
compared to string equality, although it can also be implemented in linear time [3]. 
Longest  common  subsequence  (LCSeq):  This  is  similar  to  LCS,  but  the  longest 
common subsequence need not be contiguous. LCSeq has the advantage of being able 
to detect polymorphic worms, but it may introduce more false positives. 
For  each  pair  of  strings  that  are  compared,  we  compute  a  similarity  score,  the 
higher the score, the more similar the strings are to each other. For SE, the score is  
0 or 1, where 1 means equality. For both LCS and LCSeq, we use the percentage of 
the  LCS  or  LCSeq  length  out  of  the  total  length  of  the  candidate  strings.  Let’s  say 
string s1 has length L1, and string s2 has length L2, and their LCS/LCSeq has length C. 
We compute the similarity  score as 2*C/( L1+  L2). This normalizes the score in the 
range of [0…1], where 1 means the strings are exactly equal. We show how well each 
of these measures work in Section 4.3. 
Since we may have to check each outgoing packet (to port i) against possibly many 
suspect strings inbound to port i, we need to concern ourselves with the computational 
costs and storage required for such a strategy. On a real server machine, e.g., a web 
server, there are large numbers of incoming requests but  very  few, if any, outgoing 
requests  to  port  80  from  the  server  (to  other  servers).  So  any  outgoing  request  is 
already quite suspicious, and we should compare each of them against the suspects. If 
the  host  machine  is  used  as  both  a  server  and  a  client  simultaneously,  then  both 
incoming and outgoing requests may occur frequently. This is mitigated somewhat by 
the  fact  that  we  check  only  packets  deemed  anomalous,  not  every  possible  packet 
flowing  to  and  from  a  machine.  We  apply  the  same  modeling  technique  to  the 
outgoing traffic and only compare the egress traffic we already labeled as anomalous.  
4.2   Automatic Worm Signature Generation 
There  is  another  very  important  benefit  that  accrues  from  the  ingress/egress  packet 
content  correlation  and  string  similarity  comparison:  automatic  worm  signature 
generation. The computation of the similarity score produces the matching substring 
or subsequence which represents the common part of the ingress and egress malicious 
traffic.  This  common  subsequence  serves  as  a  signature  content-filter.  Ideally,  a 
worm  signature  should  match  worms  and  only  worms.  Since  the  traffic  being 
compared is already judged as anomalous, and has exhibited propagation behavior – 
quite different from normal behavior – and the similar malicious payload is being sent 
to the same service at other hosts, these common parts are very possibly core exploit 
strings and hence can represent the worm signature. By using LCSeq, we may capture 
even polymorphic worms since the core exploit usually remains the same within each 