obfuscated and non-obfuscated code. V3 and V4 represent the
average and the variance of “word” length, respectively.
To balance the effect of each feature on the training classi-
ﬁers, a normalization process is required. Aebersold et al. [26]
divided the value of features, which need to be normalized, by
497
the length of the entire scripts. Instead, we assign the length
of the comments-excluded macro code to V1, and the length
of comments to V2. Then we use V1 as the normalization unit
for more effective training.
V1-V11 and V13-V15 are selected to capture the charac-
teristics of each obfuscation technique. In addition, there are
a few unique functions observed in the obfuscated macros.
Obfuscation is usually applied to code that has something to
hide rather than tiny, insigniﬁcant code. Obfuscation is used to
protect the intellectual property of the program code, or to hide
malicious behavior in malware. In both cases, obfuscated code
has a signiﬁcant role that programmer wants to hide, hence
it often leads to the use of certain functions with relatively
rich functionality. For examples, the Shell() function is able to
run executable programs, CallByName() can execute methods
of objects which have full functionality in the VBA macro.
Including these functions, V12 counts the use of functions
that can write, download, or execute ﬁles.
D. Machine learning classiﬁers
We choose ﬁve different supervised machine learning clas-
siﬁers to evaluate the performance of our proposed method:
Random forest (RF), Support Vector Machine (SVM), Linear
Discriminant Analysis (LDA), Bernoulli Naive Bayes (BNB),
and Multi-Layer Perceptron (MLP). In addition to the four
classiﬁers already used in previous studies [24], [26], we
introduced the MLP classiﬁer which is a class of artiﬁcial
neural network models. We choose Scikit-learn [36] to use the
aforementioned classiﬁers. Instead of describing the details of
each classiﬁer, we provide a customization parameter as well
as a brief description of each classiﬁer in this part of the paper.
Support Vector Machine (SVM) [37] ﬁnds the optimal, or
maximum-margin hyperplane in a feature space that can sepa-
rate a feature space into two classes (in our work, two classes
indicate obfuscated and non-obfuscated). In our experiment,
we use C=150, γ =0.03 as a parameter.
Random Forest (RF) [38] is an ensemble learning method
for classiﬁcation or regression. It constructs multiple decision
trees in the training phase. It is known that Random Forest is
less likely to have an overﬁtting problem than a decision tree
[39].
Multi-Layer Perceptron (MLP) [40] is a feed-forward ar-
tiﬁcial neural network model that conducts supervised learning
by backpropagation using one or more hidden layers between
the input and output layer.
Linear Discriminant Analysis (LDA) [41], which is a form
of supervised dimensionality reduction, is a generalization of
Fisher’s linear discriminant [42] that ﬁnds the linear subspace
which maximizes the separation between two classes.
Naive Bayes [43] classiﬁers are a set of simple probabilistic
classiﬁers based on applying the Bayes’ Theorem with naive
independence assumptions between the features used. We use
Bernoulli Naive Bayes (BNB) in the evaluation of proposed
method.
TABLE V: Evaluation results of proposed approach.
Feature set
Classiﬁer
Accuracy
Precision
Recall
V1-V15
J1-J20
SVM
RF
MLP
LDA
BNB
SVM
RF
MLP
LDA
BNB
0.955
0.965
0.970
0.901
0.891
0.753
0.903
0.834
0.826
0.701
0.881
0.982
0.938
0.842
0.75
0.445
0.841
0.76
0.677
0.391
0.906
0.848
0.915
0.64
0.713
0.751
0.657
0.316
0.318
0.775
V. EVALUATION
In this section, the evaluation results based on the method
proposed in section IV will be described. We extracted the
feature matrix from the preprocessed dataset with the features
introduced in Table IV. After the ﬁve different classiﬁers
have undergone the training process, we will evaluate the
classiﬁcation performance with several evaluation metrics.
Before going into the details of evaluation, we brieﬂy explain
the evaluation metrics to be used in this section.
For more precise and quantitative measures of our clas-
siﬁcation performance, we use several evaluation metrics:
Accuracy, Precision, Recall, Fβ score, and AUC of ROC curve.
We use accuracy, precision and recall to evaluate the basic
classiﬁcation performance, and choose β=2 of the Fβ score to
emphasize the security aspect. F2 score is often used when
weighing recall more than precision. By putting an emphasis
on recall, we can make sure malicious VBA macro is not
executed on the users’ system. In addition, we use the Receiver
Operating Characteristic (ROC) curves and Area Under the
Curve (AUC), which is the one of the standard convention,
to show the comparison of classiﬁcation results in a more
intuitive manner.
We used 4,212 macros for the evaluation of classiﬁcation
performance, 877 of which are marked as obfuscated. Al-
though our dataset is large enough to evaluate the classiﬁcation
performance of the proposed method, we use 10-fold Cross
Validation (CV) to improve the statistical reliability. Therefore,
the experimental results to be described below are the results
of applying the 10-fold cross validation.
Table V shows the classiﬁcation results with basic evalua-
tion metrics. The feature set we proposed is marked as V1-V15
in the leftmost column. As a result of the evaluation, SVM, RF
and MLP classiﬁers show relatively high performance among
ﬁve classiﬁers. In particular, RF recorded a precision of 98.2%
and MLP recorded a recall of 91.5%. However, LDA and
BNB classiﬁers were found to be inadequate for detecting
obfuscated VBA macro.
The evaluation result with F2 score is depicted in Figure
6. The result of the proposed method is the bars labeled
‘V feature set’. Because obfuscation detection is primarily
concerned with security purposes, we emphasize recall to min-
498
Fig. 6: The results of machine learning classiﬁcation using the
proposed feature set are expressed as F2 score. When using
the MLP classiﬁer, the result was the highest at 92%.
TABLE VI: Summary of the features used in related work.
Features
Description
J1
J2
J3
J4
J5
J6
J7
J8
J9
J10
J11
J12
J13
J14
J15
J16
J17
J18
J19
J20
length in characters
avg. # of chars per line
total number of lines
# of strings
% human readable
% whitespace
% of methods called
avg. string length
avg. argument length
# of comments
avg. comments per line
# words
% words not in comments
% of lines > 150 chars
Shannon entropy of the ﬁle
share of chars belonging to a string
% of backslash characters
avg. # of chars per function body
% of chars belonging to a function body
# of function deﬁnitions divided by J1
Used In:
[24], [26]
[24], [26]
[24], [26]
[24]
[24]
[24], [26]
[24]
[24], [26]
[24], [26]
[24], [26]
[24]
[24]
[24]
[26]
[26], [34]
[26]
[26]
[26]
[26]
[26]
imize false negatives. As MLP classiﬁer showed relatively high
performances in the basic three metrics, accuracy, precision,
and recall, it also recorded the highest F2 score of 92%. In
a related study that evaluated detection performance with the
F2 score [24], we can see that our method is 11.4% higher,
given that 80.6% was its maximum.
We can then ask ourselves the following research question:
“It has been conﬁrmed that the proposed features and clas-
siﬁcation method are effective in detecting obfuscated VBA
macro, but how effective would it be to use the malware
detection features of the related studies that have already been
feature set (V features) has an AUC of 0.95, and comparison
experiment (J features) gets 0.812. It shows that our proposed
method outperformed the previous studies by 0.138 on the
AUC basis.
As a result, we obtained up to 92.0% F2 score with proposed
feature set when obfuscation detection was performed using
the MLP classiﬁer. This is 23% higher than the result of using
the features proposed in the related studies. The accuracy,
precision, and recall show better results, and the AUC value of
the ROC curve was 0.950, showing that the proposed method
and features are suitable for obfuscated VBA macro detection.
VI. DISCUSSION
A. Obfuscation detection and malicious code detection
We presented 15 static features for obfuscation detection,
and evaluated our proposed method using various evaluation
metrics. However, this is a method for obfuscation detection,
not malicious code detection. We investigated a sufﬁcient
number of MS Ofﬁce document ﬁles to clarify the relation-
ship between obfuscation and maliciousness. This obfuscation
detection method can play a major role in malicious code
detection, as the rate of obfuscation applied differs greatly
between malicious dataset (98.4%) and benign dataset (1.7%)
as described in Table III.
Currently, the distinction between malicious code detection
and obfuscated code detection is unclear in malware detection
research. As long as cases where obfuscation techniques used
to protect intellectual property rights exist, malicious code
detection should be distinguished from obfuscated code detec-
tion. However, a few of the related studies used the characteris-
tics of obfuscation to detect malicious codes without consider-
ing obfuscation techniques [18], [24]. The confusion between
maliciousness and obfuscation may lead to an increase in
false alarms. Therefore, we generally classiﬁed obfuscation
type (O1-O4) to prevent this mistake, and designed the feature
set to not be biased towards the characteristics of a speciﬁc
obfuscation tool.
In order to address the need for a counteraction against
the increasing obfuscated VBA macro malware, we compared
the ability of J feature set and our proposed V feature set
regarding obfuscation detection. The results showed that the
J feature set underperformed against the proposed V feature
set, but this does not mean that the research results regarding
JavaScript is bad. Rather, in regards to detection of obfuscation
in highly obfuscated VBA macro malware (98.4%), applying
existing studies (J feature set)—that does not take into account
the characteristics of obfuscation—is not ideal.
B. Case studies: anti-analysis techniques in VBA
The obfuscation techniques observed in VBA macros are
categorized into four types (O1-O4) in Section III. When using
features based on the O1-O4, we succeeded in identifying ob-
fuscation with an accuracy of 97%. In addition to obfuscation,
however, several tricks have been found for the purpose of
hindering the analysis and understanding of the code. In this
499
Fig. 7: The solid curve and dashed curve represents ROC
curves of MLP classiﬁer with proposed feature set and RF
classiﬁer with comparison feature set, respectively.
conducted? Would it not be more effective?”. In response to
this question, we added a comparative experiment to detect
obfuscated VBA macros using the same machine learning
approach to the same dataset. The features used in related
studies [24], [26] are listed in Table VI.
Due to the linguistic differences between JavaScript and
Visual Basic for Applications, many of the features used in ob-
fuscated JavaScript detection are not applicable for obfuscated
VBA macro detection. For example, “# of eval() calls divided
by entire code length” was used in the related paper [26],
which was not implemented in this study because it is difﬁcult
to match the eval() function to corresponding VBA function.
Besides, J14, originally ‘% of lines with more than 1000
characters’, was modiﬁed to reﬂect the characteristics of VBA