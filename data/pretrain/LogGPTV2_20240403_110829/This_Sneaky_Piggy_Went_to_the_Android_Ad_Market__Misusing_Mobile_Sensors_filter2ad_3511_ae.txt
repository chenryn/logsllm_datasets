✗
Typing
two-handed
one-handed
two-handed
one-handed
two-handed
one-handed
two-handed
one-handed
two-handed
one-handed
Duration MLP-MSE GRU-MSE
5 minutes
5 minutes
10 minutes
10 minutes
20 minutes
20 minutes
30 minutes
30 minutes
60 minutes
60 minutes
62.87%
40.92%
70.53%
44.67%
79.23%
45.76%
81.70%
51.11%
85.25%
50.48%
47.63%
37.73%
50.49%
39.04%
52.19%
39.76%
52.68%
40.17%
53.38%
40.57%
ReLU
74.32%
44.57%
78.63%
50.07%
82.53%
52.51%
84.79%
55.64%
87.06%
59.70%
GRU
74.56%
44.49%
79.19%
50.10%
82.87%
54.11%
85.66%
56.67%
87.51%
59.99%
scenarios, we evaluated our classifiers using different dataset sizes
by sampling 5, 10, 20 and 30 minutes from the corresponding one
hour dataset. In each experiment we used 2/3 of the dataset for
training and 1/3 for testing. Our two models that directly predict
key labels outperform Axolotl’s baseline model (MLP-MSE) and
our version of a coordinate-predicting model (GRU-MSE) across all
experimental setups, with the GRU model that returns key-press
labels exhibiting the highest accuracy in most datasets. As one
might expect, two-handed typing is more consistent and stable,
resulting in a more accurate inference by our system. We observe
that the GRU model is accurate for two-handed typing even when
trained with a small dataset (e.g., 5 minutes) and reaches 87.51%
when trained with enough samples. Additionally, the ReLU and
GRU models performance is comparable across datasets, while in a
single case the ReLU model outperforms GRU.
The intent of this exploratory experiment is to demonstrate the
feasibility of misusing in-app ads for conducting input inference
attacks. While the two models we propose achieve high accuracy,
and we will open-source our code to facilitate additional research,
our goal is not to replicate the extensive experiments conducted by
studies that focused on input inference. Importantly, findings from
prior work further support the generalizability of our results and
the practicality of our proposed attack. Specifically, prior work has
shown that techniques for reconstructing users’ touch input are ef-
fective even when tested against a variation of devices with different
hardware characteristics, screen orientation, display dimensions or
keyboard layouts [19]. In most studies [15, 19, 47, 59, 62] a diverse
training dataset with multiple users was used, and experiments
suggest that inferring PINs is actually more consistent and accurate
when training and testing is done across multiple users and devices
⇓ DLs
500M+
100M+
50M+
10M+
10M+
10M+
com.opera.mini.native
com.opera.browser
com.cloudmosa.puffinFree
fast.explorer.web.browser
browser4g.fast.internetwebexplorer
com.apusapps.browser
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
We use Axolotl’s deep neural network (DNN) model as our base-
line and propose three additional DNN models. First, Axolotl’s DNN
model has multiple layers for progressively extracting higher-level
features from the sequential inputs from the accelerometer and
gyroscope sensors. To precisely predict the location of each key-
stroke, this model applies the linear activation function for each
layer and mean squared error (MSE) loss [10] for gradient computa-
tion. This model predicts the coordinates of the point on the screen
that the user pressed, which we then map to the corresponding
key label. Next, we build two novel models that directly predict
key labels based on the input data. Second, we build a DNN model
that uses the Rectified Linear Unit (ReLU) [65] as the hidden layer
activation function and softmax activation for the output layer. To
compute the multi-class classification loss, we use the Categorical
Cross-Entropy Loss to update model weights during training. Our
third model uses Recurrent Neural Network (RNN) techniques that
capture the relationship between recent keystroke information for
prediction. However, vanilla RNNs can be affected by long-term
sequential data, and Long Short Term Memory (LSTM) networks
have been proposed for learning long-term dependencies [46]. As
such we use a Gated Recurrent Unit (GRU), which is a special case of
LSTM but with simpler structures (e.g., uses fewer parameters) [21],
to build our prediction model. Compared to LSTM, GRU also works
well on long-term sequential data but is more efficient. Moreover,
we also use the Dropout technique [98] to make the model less
prone to over-fitting and achieve better performance. Finally, we
also develop a GRU-based model that predicts coordinates, similar
to Axolotl’s approach, instead of key labels.
Our input inference attack captures and uses motion sensor
values from in-app ads. We created two datasets for training our
classifiers using a similar setup. A mock app is used for loading a
webpage that calls the HTML5 functions that access motion sensors
and outputs sensors values to logcat. Additionally, apart from the
accelerometer and gyroscope values, we log the coordinates (i.e.,
x,y) while touching the screen, which are then normalized between
-1 and 1. A value of -2 is used to indicate that no touch occurred at
that time. Using this setup we created two different typing datasets.
One dataset contains samples created using two-handed typing,
while the other contains samples created using one-handed typing.
In both datasets keys were pressed randomly for one hour.
Our motivating attack example paper is inferring the credit card
number and CCV being typed by the user. As such our models
attempt to identify and label any key presses that correspond to a
digit; all other key presses are labelled as “other”. We present the
results from our experimental evaluation in Table 6. In both typing
Session 4B: Wireless, Mobile, and IoT CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1074rather than a single device or user [19]. Hodges et al. [47] demon-
strated that even when using a very short training dataset (i.e., less
than the size of a tweet) the accuracy of these techniques remains
surprisingly high (they report 81% accuracy in bigram prediction).
Similar findings were observed by Miluzzo et al. [62], further sug-
gesting that a pre-trained classifier from a small number of people
could be successfully used to infer other users’ taps at a large scale.
8 DISCUSSION
Here we discuss various dimensions of the emerging threat of in-
app ads accessing rich features of the operating system, and propose
a set of guidelines for better protecting users.
Automatically Identifying Sensor Leaks. While our system
is able to automatically identify WebAPIs that access mobile sensors
by in-app ads, it is also important to identify whether motion sensor
data is exfiltrated over the network. Several challenges exist for
tracking sensor values from low-level system calls to the network
layer. Prior work (e.g., [72, 85]) proposed mechanisms that identify
device identifiers (e.g., MAC address, Advertising ID, etc.) being
leaked over the network. These techniques can not be applied di-
rectly in our case because mobile sensors provide continuous values
that change based on the device’s position. While one could inter-
cept the appropriate APIs so as to always return the same unique
value, prior work has shown that apps (and by extension in-app ads)
can hide suspicious activity when provided with a constant sensor
value [71]. Another mechanism for identifying leaks in Android
apps is AGRIGENTO [22], which is based on blackbox differential
analysis and detects leaks by observing deviations in the resulting
network traffic even in the presence of obfuscation. Unfortunately,
this approach requires at least two executions and is thus inherently
better suited for experiments that focus on app-specific behavior;
due to the dynamic nature of the advertising ecosystem different
in-app ads may be shown across executions of the same app.
While in our study we manually analyzed the JavaScript code
and the network flows of in-app ads that access motion sensors,
motivated by prior work we propose a more systematic method-
ology for identifying sensor leaks over the network. Specifically,
we developed a tool for identifying sensor leaks (i) by tracking the
raw sensor values provided by the motion sensors of the operating
system and (ii) searching for specific keywords used for labelling
sensor values in network traffic. To track sensor values, first, we
manually identified which Android sensors are triggered when
specific WebAPIs are called. For example, when the function win-
dow.addEventListener("devicemotion",function(event)) is
triggered, the event rotationRate maps to the TYPE_GYROSCOPE
sensor, while the events accelerationIncludingGravity and ac-
celeration, map to TYPE_ACCELEROMETER and TYPE_LINEAR_AC-
CELERATION sensors respectively. Next, we modified the SensorDis-
abler [107] module to return values (within the appropriate range
for each sensor) from a list of predefined values. These steps ensure
that the HTML5 WebAPIs responsible for accessing motion sensors
always return legitimate predefined values which can be identified
in network flows. Since these values can be leaked in an encoded
form we also check for these values in common encoding formats
(e.g., base64). We consider a large-scale measurement and evalua-
tion of this tool in the wild as future work. We also note that our
technique for identifying sensor data in network flows suffers from
certain limitations; we can not handle cases where sensor values in
network traffic have been encrypted or are heavily obfuscated.
Responsibilities, countermeasures and guidelines. Due to
the severity of the attacks enabled by mobile sensors inside in-app
advertisements, it is imperative to inform the advertising commu-
nity and establish guidelines for access control policies. We strongly
believe that users should be given the option to allow or deny ac-
cess to any sensor information. Even though access control policies
enforced using Android permissions exist for sensors such as GPS,
Camera and Mic, we found that it is also crucial to guard with an
Android permission motion sensors. Unfortunately, even if this
policy is enforced by the OS, it only partially solves the problem
since in-app ads exists in the same address space as the actual ap-
plication’s process, and share all of the application’s privileges. As
such, it is also a responsibility of the World Wide Web Consortium
(W3C) to update the HTML5 policies for access to motion sensors
by coupling them with the Permissions API. To bridge the gap be-
tween policies of the OS and the HTML5, Android can establish
a general interface that allows users to distinguish access control
to sensitive data and sensors between the native part of the app
and WebViews dedicated for displaying advertisements (since Web-
Views that are part of the core functionality of the app may require
access to these sensors). These complex policies, if they are to be in-
troduced, require careful design and a strong collaboration between
OS vendors and the W3C. Bellow we list a set of guidelines that
users, developers and the ad ecosystem can follow as a temporary
solution until a more generic policy is enforced.
Ad ecosystem. Advertising entities responsible for creating, sell-
ing and publishing ads must enforce stricter policies. They should
not allow JavaScript in advertisements to access motion sensors
unless there is a specific and well-documented reason to do so in
the ad campaign contract. Furthermore, all ads must be dynami-
cally analyzed in a sandboxed environment before publication, to
eliminate cases of suspicious obfuscated behavior and data leakage.
Ad-related entities that collect sensor data for their own purposes
should provide a detailed explanation in their privacy policies.
Android access control and permissions. We argue that intersti-
tial ads should not be allowed to execute JavaScript before they
are displayed on the screen. Even though the main purpose of
interstitials is to effectively load JavaScript and prepare the ad’s
content so it is ready for display at the desired time, it is challenging
to enforce access control mechanisms for motion sensors at this
layer. We believe that a possible solution for motion-based side
channel attacks is to extend the functionality of the FLAG_SECURE
option to also block access to motion sensors whenever a View
with this option is in the foreground. The FLAG_SECURE option is
already used by system apps when displaying Views with sensitive
content, such as the billing information in the Play Store app and
the Play Billing lib used for in-app purchases. Additionally, user
applications (e.g., banking apps) already use this flag to prevent
other apps from taking screenshots or reading the contents of the
screen, which benefit from this solution. Additionally, apps that
render web content (including in-app ads) should ask users’ for
their consent prior to accessing sensor information. Apps that do
not require access to motion sensors for their core functionality
must also inform users and ask for their consent, since it is possible
Session 4B: Wireless, Mobile, and IoT CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1075for embedded in-app ads to access these sensors. If users do not
agree, WebViews with in-app ads should have limited functionality
(e.g., setJavaScriptEnabled(False) and only display static ads.
Apps & Devs. Applications with in-app ads should never allow
them to be displayed in sensitive forms (e.g., login). Moreover,
browser apps should enforce navigational and cross tab isolation.
In-app ads displayed while visiting a specific domain must not
exist when visiting another domain. Additionally, the execution
of JavaScript from in-app ads displayed in browser’s Home screen
must terminate when users open a new tab. Developers should
thoroughly review the ad libraries they integrate in their apps. If in-
app ads from the embedded ad libraries are responsible for sensor
data collection then it is also their responsibility to inform users
and ask for consent. Moreover, developers should not allow ad libs
to include additional permissions without a detailed explanation.
Users. The SYSTEM_ALERT_WINDOW is a dangerous permission and
users should carefully revise which of their installed apps have been
granted access. Furthermore, we urge users to be cautious while
operating apps in multi-window mode [31]. The multi-window
mode (i.e., split screen) is used for displaying more than one app
simultaneously and allows in-app ads to capture motion sensor
values while the user is interacting with another app. Additionally,
it is possible for in-app ads to access motion sensors even if the
second application in the split screen mode is the Android Settings
app, which processes sensitive data (e.g., account credentials).
Ethical Considerations. We carefully designed our experiments
to minimize the effect of our experiments. Specifically, in our large-
scale analysis experiments our framework did not click on ads to
avoid incurring additional costs on advertisers. As such, the impact
of our experiments is that of any measurement study that dynami-
cally analyzes free Android apps, which commonly show in-app ads.
Additionally, our IRB-exempted experiment with the ad campaign
did not gather any information that can be used to identify or harm
users in any way, and the only information made available in the
report returned by the DSP was aggregate results about the ad’s
performance (e.g., apps displayed, impressions, clicks).
Disclosure. We submitted a detailed report with our findings
to Google’s Android security team and in their response they rec-
ognize the potential for abuse. They informed us that they are
generally aware of attacks using motion sensors, and their plan to
address them in an upcoming quarterly release. Furthermore, they
informed us that they are investigating ways to provide app devel-
opers with tools that will help them fortify their apps against this
sort of attack. Concerning the issues we described with (i) the SYS-
TEM_ALERT_WINDOW permission, (ii) the library for interstitial ads,
and (iii) background WebViews not being terminated, the security
team replied that they consider these to be functioning as intended.
We disagree with this assessment and argue that these issues not
only mislead app developers and users, but also create opportuni-
ties for attacks with severe implications. We hope that our work
will draw additional focus from researchers and will, eventually,
incentivize better access control and isolation enforcement.
9 LIMITATIONS AND FUTURE WORK
Our study on the collection of sensor data by in-app ads in the
wild relies on our framework dynamically exercising apps. As with
any dynamic analysis experiments with Android apps, our study
presents certain limitations which we discuss bellow.
Element Coverage. Prior work [35] has explored how to im-