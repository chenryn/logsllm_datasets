5640
10832
21280
42112
52560
104672
250624
375744
417472
181
434
542
645
702
720
748
769
773
773
1   Maximum  segment  size.  Used  in  TCP  to  specify  the  maximum  amount  of  TCP  data  in  a
single  IP  datagram  that  the  local  system  can  accept.  The  MSS  is  typically  the  outgoing
interface’s maximum transmission unit minus 40 bytes for the IP and TCP headers.
Capacity Verification for High Speed Network Intrusion Detection Systems
249
5   Example Test Results 
Using the lessons  from section  4,  this  section  explores  two  simple  tests  that  evaluate
some  aspects  of  the  capacity  of  a  NIDS.    Other  tests  are  then  suggested  as  a  way  to
further refine the knowledge gained from the example tests.
5.1 Test Network
Figure 1 shows the test network used for the example tests.  All links to the switch are
using a single 1-Gbps full duplex connection. 
Fig. 1. A block diagram showing the network layout for the example tests. The WebReflector
acts as all the web servers. The WebAvalanche acts as all the web clients.  The catalyst switch
is used to copy-capture the traffic to the NIDS.
WebReflector
Catalyst  6509
Switch
NIDS
WebAvalanche
5.2 The Baseline Test  
The first test baselines the capture efficiency of a NIDS in a pure HTTP environment.
A  full  analysis  load  is  assumed  by  turning  on  all  default  signatures.    However,  the
traffic generated does not cause alarms or events to be created.  The number of client
hosts  on  the  network  is  fixed  at  5080,  and  the  number  of  servers  is  fixed  at  two.    In
this  first  test,  TCP  sessions  are  allowed  to  run  to  completion  as  quickly  as  possible,
therefore  the  number  of  simultaneous  open  sessions  is  fixed  at  less  than  30  for  all
cases.    The  average  packet  size  is  varied  through  manipulation  of  the  HTTP
transaction size.  This also results in variations in  the  average  number  of  packets  per
TCP  connection,  the  packets  per  second  (KPPS),  and  the  overall  bandwidth  used.
The  final  variable  manipulated  is  the  number  of  new  TCP  connections  per  second.
Each  test  is  run  for  three  minutes  before  capacity  measurements  were  made.    The
results of the baseline test are given below in Table 4.
5.3 Adding Simultaneous Open TCP sessions
The second test introduces  simultaneous open  TCP  sessions.    A  four-second  delay  is
introduced  on  the  server  response  to  cause  sessions  to  remain  open.    All  other  test
variables remain constant.  The bandwidth consumed, the packets per second, and the
average packet size at each data point are somewhat affected by the open connections. 
250 M. Hall and K. Wiley
Without  performing  a  correlation  study,  it  is  unclear  if  these  factors  are  statistically
significant.  For the purposes of this paper, we assume they are not.  The results from
the open connection test are below in Table 5.
Table 4. The results for the baseline test.  Traffic was HTTP only with 5080 client IP addresses
and 2 server IP addresses. The test runs for 3 minutes. No server delay.
Avg.
Packet
Bandwidth
Capture
Bandwidth
Capture
Bandwidth
Capture
Size
@ 1000 cps
Efficiency
@ 2500 cps
Efficiency
@ 5000 cps
Efficiency
434
482
542
645
688
702
720
50 Mbps
67 Mbps
93 Mbps
180 Mbps
275 Mbps
380 Mbps
100%
100%
100%
100%
100%
100%
444Mbps
100%
125 Mbps
167 Mbps
232 Mbps
446 Mbps
100%
100%
100%
100%
680 Mbps
99.30%
230 Mbps
99.95%
335 Mbps
97.10%
Table  5.  The  results  for  the  open  connection  test.  Traffic  was  HTTP  only  with  5080  client  IP
addresses  and  2  server  IP  addresses.  The  test  runs  for  3  minutes.  Four  second  forced  server
delay.
Bandwidth
Avg.
@ 1000 cps
Bandwidth
@ 2500 cps
Bandwidth
@ 5000 cps
Packet
and 4000
Capture
and 10000
Capture
and 20000
Capture
Size
open streams
Efficiency
open streams
Efficiency
open streams
Efficiency
434
482
542
645
688
702
720
50 Mbps
69 Mbps
93 Mbps
181 Mbps
268 Mbps
355 Mbps
100%
100%
100%
100%
100%
100%
440Mbps
100%
125 Mbps
170 Mbps
241 Mbps
100%
100%
100%
446 Mbps
99.95%
655 Mbps
95.01%
245 Mbps
68.75%
350 Mbps
72.26%
5.4 The Results
The most  significant  variations  in  capture  efficiency  are  in  the  5000  connections  per
second tests.  Capture efficiency appears affected in the 2500 connections per second
tests as well, however, this does not appear to be statistically meaningful.
The  two  tests  only  differ  in  the  number  of  concurrent  open  TCP  sessions.    This
implies the state database is the component under stress.  With only these results it is
not  possible  to  precisely  identify  what  operation  within  the  database  is  causing  the
drop in capacity.  The traffic may have exceeded the database’s insertion rate, its time
to search capacity, or the ability of the system to perform maintenance on the database
and delete aging entries.  
Capacity Verification for High Speed Network Intrusion Detection Systems
251
Regardless,  it  is  apparent  that  a  consumer  whose  network  has  an  average  number
of open TCP sessions near 10,000, an average  new  TCP  connections  per  second  rate
of  no  more  than  2500  per  second,  and  a  bandwidth  consumption  less  than
approximately 400 Mbps, could field the tested NIDS with confidence that the capture
efficiency would be at or near 100 percent.
5.5
Further Tests
The  example  tests  do  not  provide  enough  information  on  which  to  base  a  full
confidence  decision.  Nevertheless,  by  using  the  same  methodology  for  developing
further tests, the NIDS industry or independent labs could establish a suite of tests that
could provide quantifiable results for each of the different stress points.
For  example,  the  total  number  of  database  insertions  per  second  for  the  database
can be quantified by establishing a test that runs at a very low rate for all other stress
points  of  the  NIDS.  The  traffic  must  be  crafted  such  that  the  database  needs  to  start
maintaining  state  on  many  different  key  values.    One  possible  way  of  shaping  the
traffic is to use a packet generator and generate a valid TCP session with a full three-
way  handshake.  The  rate  at  which  the  connections  are  introduced  must  be  ramped
upward  until  the  NIDS  starts  dropping  traffic.    Since  these  simple  TCP  connections
consist of small packets, the bandwidth should remain low.  Results  need to be cross
checked  with  the  raw  packet  capture  architecture  evaluation  results  as  described  in
section 4.5 to ensure that it is the database inserts and not the packets per second limit
that has been reached. 
6   Conclusion
As the NIDS industry matures, standardized testing  will become reality.  Developing
these tests can be done using the same concepts of standardized testing found in other
industries.    Hopefully,  the  information  found  in  this  paper  can  serve  as  a  catalyst  to
stimulate  the  development  of  standardized  tests  providing  the  NIDS  consumer  the
information  that  is  now  missing.    The  same  techniques  used  for  capacity  testing  can
be extended to other performance areas such as false positive ratios.  
References
1. Mier  Communications:  Test  report  for  ManHunt  from  Recourse  Inc.  and  test  report  for
Intrusion.com’s NIDS. At: http://www.mier.com/reports/vendor.html
2. Ranum, M.: Experiences Benchmarking Intrusion Detection Systems.  At:
http://www.nfr.com/forum/white-papers/Benchmarking-IDS-NFR.pdf
3. Claffy, K., Miller, G., Thompson, K.: the nature of the beast: recent traffic  measurements
from an Internet backbone. At: http://www.caida.org/outreach/-papers/1998/Inet98/ (1998)
4. McCreary,  S.,  Claffy,  K.:  Trends  in  Wide  Area  IP  Traffic  Patterns:  A  View  from  Ames
Internet Exchange.  At: http://www.caida.org/outreach/papers/2000/-AIX0005/ (2000)
Performance Adaptation in Real-Time Intrusion
Detection Systems
Wenke Lee1, Jo˜ao B.D. Cabrera2, Ashley Thomas3, Niranjan Balwalli1,
Sunmeet Saluja1, and Yi Zhang1
1 College of Computing, Georgia Institute of Technology,
{wenke, niranjan, sunny, yizhang}@cc.gatech.edu
801 Atlantic Drive, Atlanta, GA 30332, USA
http://www.cc.gatech.edu/fac/Wenke.Lee
2 Scientiﬁc Systems Company Inc.,
500 West Cummings Park, Suite 3000, Woburn, MA 01801, USA
3 Department of Electrical and Computer Engineering,
PI:EMAIL
North Carolina State University,
Raleigh, NC 27695, USA
PI:EMAIL
Abstract. A real-time intrusion detection system (IDS) has several
performance objectives: good detection coverage, economy in resource
usage, resilience to stress, and resistance to attacks upon itself. In
this paper, we argue that these objectives are trade-oﬀs that must be
considered not only in IDS design and implementation, but also in
deployment and in an adaptive manner. We show that IDS performance
trade-oﬀs can be studied as classical optimization problems. We describe
an IDS architecture with multiple dynamically conﬁgured front-end
and back-end detection modules and a monitor. The IDS run-time
performance is measured periodically, and detection strategies and
workload are conﬁgured among the detection modules according to
resource constraints and cost-beneﬁt analysis. The back-end performs
scenario (or trend) analysis to recognize on-going attack sequences, so
that the predictions of the likely forthcoming attacks can be used to
pro-actively and optimally conﬁgure the IDS.
Keywords: Real-time intrusion detection, performance metrics, perfor-
mance adaptation, optimization.
1 Introduction
Intrusion detection is a critical component of the defense-in-depth network secu-
rity mechanisms. An intrusion detection system (IDS) monitors operating sys-
tem or network activities by capturing and analyzing audit data (e.g., BSM [33]
or libpcap [19] stream) to determine whether there is an attack occurring. Most
systems perform misuse detection by pattern matching known attack behavior
or eﬀects, and some systems also employ anomaly detection techniques, which
A. Wespi, G. Vigna, and L. Deri (Eds.): RAID 2002, LNCS 2516, pp. 252–273, 2002.
c(cid:1) Springer-Verlag Berlin Heidelberg 2002
Performance Adaptation in Real-Time Intrusion Detection Systems
253
ﬂag unacceptably large deviation from normal proﬁles as (probably) the result
of an attack. A real-time IDS diﬀers from an oﬀ-line IDS in that it tries to detect
and respond to an attack in real-time (i.e., when it is unfolding).
An IDS is a “mission-critical” system, one that needs to be eﬀective and
available. More speciﬁcally, its performance objectives include: good detection
coverage, economy in resource usage, and resilience to stress [26]. Since sophis-
ticated adversaries may try to ﬁrst evade or even subvert IDSs when launching
their intended attacks, another important performance objective is that an IDS
must resist attacks upon itself [25,23]. These objectives can be conﬂicting goals.
For example, for broad coverage and high detection accuracy, an IDS needs to
perform stateful analysis on a lot of audit data. This requires a large amount
of resources (in both memory and detection time). A resource-intensive IDS is
then vulnerable to stress and overload attacks. We therefore need to carefully
consider the trade-oﬀs.
It is well known that most current IDSs, employing only misuse detection
techniques, cannot detect new attacks. Worse yet, even for known attacks, the
detection performance cannot be guaranteed when the IDSs are under stress
(e.g., due to high traﬃc volume) or are targeted by evasion, overload, and crash
attacks [25,23,30]. Researchers are developing attack resistance techniques. Many
evasion attempts can be foiled if an IDS uses stateful analysis and employs a
network traﬃc normalizer [12]. Some IDSs are carefully designed to be very “light
weight” or are specially conﬁgured with high-end hardware (e.g., RealSecure with
AppSwitch [34]) to cope with high-speed and high-volume traﬃc. However, as
our analysis and experiments in this paper show, as long as an IDS is statically
conﬁgured in run-time, an intelligent adversary can overload the IDS to a point
that it will miss the intended attack with high probability.