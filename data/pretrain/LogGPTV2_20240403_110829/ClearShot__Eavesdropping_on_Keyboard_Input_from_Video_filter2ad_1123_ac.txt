sary to assign to the keys in each model a score that reﬂects
how conﬁdent we are that that particular key was actually
pressed by the user and it is not noise introduced by the
computer vision analysis.
In our experiments, we observed that, most of the time,
actual key pressings result in key groupings that span many
consecutive frames. Differently, the keys that are the re-
sult of noise introduced by our analysis tend to have a more
spiky behavior, and generate key groupings that seldom
span many frames. Therefore, we assign to each key in a
character model a score that is proportional to the size of
the associated key grouping, that is, the number of consecu-
tive frames in which the key was present in the key list.
We then add to each character model two virtual keys:
ε and ∗. We use ε to model an “empty” key, i.e., the fact
that the user did not press any key. This is a way to express
the fact that it is possible that all the keys contained in a
character model are the consequence of noise introduced by
the computer vision analysis. The score assigned to ε is
inversely proportional to the sum of all the key scores inside
that character model. By doing this, we model the fact that if
a character model contains one or more “strong” keys (i.e.,
keys that lasted for many frames) it is unlikely that the user
did not press anything for such a long time. In addition, this
guarantees that the score of ε is less than the score of any
“real” key.
The ∗ key is instead a wildcard that can represent both a
single character and a combination of characters. This key is
introduced to model the fact that the user may have pressed
a key in the time frame associated with the character model,
but maybe not the one that we detected analyzing the video.
The score assigned to ∗ is proportional to the length of the
longest key grouping in the character model. The process
used to derive this score guarantees that it will be less than
the score of any “real” key.
Once the character models have been determined, we
connect each key in a character model with all the keys in
the following character model. This can be represented as
an acyclic graph, which we call the word model graph. In
this graph, each path, called a word template, contains one
and only one key for each character model. Figure 3 shows
a sample word model graph that was constructed when the
user typed the word change.
If we consider a word template as a string composed of
the sequence of characters associated with each key of the
path, we obtain a regular expression that can be used to
match words in the dictionary. In our example, choosing
the best candidate key in each character model, we obtain
the template ch*klge. We say that a word matches a tem-
plate if it matches the template’s regular expression. We
deﬁne the score of a template to be the sum of the scores of
each node in the template.
Given a graph G and a word w, we deﬁne the score of
w in G, denoted score(w, G), the highest score among the
templates in G that are matched by the word w. Note that
this deﬁnition is well-formed, because it satisﬁes two prop-
erties: uniqueness (i.e., there is at most one score value for a
word) and completeness (i.e., there is always at least a score
value for any word).
Uniqueness is guaranteed by deﬁnition, since we only
use the maximum of all possible template scores. Com-
pleteness is guaranteed by construction of the graph: each
character model contains the wildcard key ∗. Therefore, any
word model graph contains a template composed of all wild-
cards, which clearly matches any word in the dictionary. As
a consequence, ∀w, ∀G, score(w, G) > 0.
Having deﬁned the score of a word, we can now deﬁne
the error model that we use in our analysis. Recall that the
error model of the spelling correction problem is the prob-
ability that we observe a word s when the user intended to
write the correct word w, that is P (s|w). In our problem,
the observation is represented by the graph G, which takes
the place of the string s, and therefore the error model is
P (G|w). We deﬁne this probability as:
P (G|w) =
score(w, G)
max
j∈L score(j, G)
Intuitively, this formula relates the probability that we
observe a graph G when the user typed the word w to the
score of w in G. Since the denominator is a constant, the
problem of ﬁnding the best candidate word that was typed
by the user given a certain graph corresponds to ﬁnding the
word that has the best score on the graph.
A straightforward way to calculate the best scoring word
would be to just calculate the score of all the words in a dic-
tionary. However, since we are only interested in the words
with the highest scores, a more efﬁcient solution is to enu-
merate the graph’s templates starting with the one with the
greater score (that can be easily ﬁnd with a greedy algorithm
that chooses the key with the highest score in each char-
acter model) and match the corresponding template against
176
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:58:33 UTC from IEEE Xplore.  Restrictions apply. 
C
18
ε
5
∗
2
H
20
I
12
ε
1
∗
9
ε
5
∗
18
K
23
N
10
ε
2
∗
12
L
15
ε
14
∗
2
G
50
ε
15
∗
3
E
11
ε
5
∗
2
Figure 3. Word model graph obtained when the user types the word change. The dashed boxes
identify the character models. Nodes represent individual keys in a model. For each key, we report
the corresponding letter and score.
the dictionary words. We then move to the second highest
path, and so on until a sufﬁciently large number of candidate
words have been extracted.
In our example, the top two templates, i.e., ch*klge
and ch*kge, did not match any existing word in the dic-
tionary. The third one ch*nge returned two matches:
change and challenge. The second word is obviously
a side effect of having the ∗ node, which can match any
possible string (in this case, the string alle). The impact
of the wildcard keys on the ﬁnal result can be reduced by
integrating into the graph the information provided by the
exclusion list. In particular, for each ∗ key in the graph, we
retrieve from the exclusion list the set of keyboard’s keys
that could not have been pressed by the user in the frames
associated with the ∗ key. This set is then used to restrict
the range of possible values that the wildcard can assume.
For example, for the third character model in our example,
consulting the exclusion list we see that the key L was con-
stantly not occluded on that time frame, and, therefore, it
can be removed from the set of possible characters that can
be substituted for the ∗ key. By integrating this additional
information, challenge is not anymore a valid candidate
word for the ch*nge template.
Language Model.
In the previous section, we have de-
termined the probability that a word model graph has been
generated because a user was trying to type a speciﬁc word.
Next, we have to determine the probability that this word
has to appear inside the language, that is, the language
model.
The language model can be determined in two ways. The
ﬁrst approach consists of training a probability model based
on the content of a very large dataset containing a sequence
of valid sentences. This has the advantage that, if the at-
tacker knows the general subject of the text, he can choose
a dataset focused on that particular subject. For example,
if the attacker is spying on a computer programmer, a good
solution would be to use a specialized training set that con-
tains many language keywords. In this way, the language
model would consider more probable for the user to write
the word class than the word classic.
The second approach consists of extracting the frequency
of each word from a dataset. In particular, we use the n-
gram dataset provided by Google [7]. The dataset, dis-
tributed on six DVDs, contains the frequency of both single
words and combinations of words (up to 5-grams) that have
been extracted by Google by processing one trillion words
from public web pages. This second approach performs bet-
ter when the topic is not known or when the attacker needs
a very large vocabulary (the dataset contains over thirteen
millions of unique words, compared with a traditional dic-
tionary that usually contains less than one hundred thousand
entries). This dataset also has the advantages of already
containing a large number of commonly misspelled words,
making our analysis less sensitive to typographical errors
introduced by the user.
177
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:58:33 UTC from IEEE Xplore.  Restrictions apply. 
2.2.2 Context-sensitive Analysis
The language analysis described in the previous section con-
sidered each word in isolation and produced a set of differ-
ent alternatives for each word, which we call word candi-
dates, sorted by their score. Even though this is very valu-
able information, the attacker still has to manually review
each set trying to combine the different words to form mean-
ingful sentences.
To some extent, this task can be automated by composing
consecutive sets of word candidates in n-gram sequences.
A similar approach was proposed by Mays, Damerau, and
Mercer [31] in the area of context-sensitive spelling cor-
rection. The authors proposed to analyze a sentence using
3-grams in order to detect inappropriate uses of correctly-
typed words. However, our problem is more difﬁcult, since
we do not even have a sentence but just a sequence of groups
of words that we believe are the best candidates to describe
the actual words typed by the user.
In our context-sensitive analysis, we take three sets of
consecutive words as provided by the language analysis and
we combine them together to form all the possible three-
word sentences. We then extract the frequency of each sen-
tence from the Google 3-gram dataset.
Consider, for instance, these ordered sets of words ob-
tained by the previous analyses when the user typed “we
talk tomorrow”:
{we, mill, will} {walk, table, talk}
{tomorrow, tomato, automate}
Most of the sentences, like “we table tomato,” are
grammatically incorrect and therefore they are not present in
the Google dataset. The word candidates that never appear
in any valid 3-gram are discarded as wrong suggestions and
the remaining ones are re-ordered to reﬂect the frequency
in which they appear in combination with their neighboring
words. The result of the 3-gram analysis is:
{we, will}
{talk, walk} {tomorrow}
A ﬁrst important effect of this analysis is the reduction
in the size of the candidate sets. For example, tomorrow,
which was already the best candidate word in the third set,
after the context sensitive analysis is the only word remain-
ing. Another effect is that talk, which was the least prob-
able candidate in the second set, has been promoted to the
ﬁrst position. Both these results can greatly simplify the at-
tacker’s job of reconstructing the original text.
After the analysis has been applied to a window of three
words, the window is moved ahead of one step and the pro-
cess continues. It may happen that the analysis reaches a
point where no valid 3-gram sequence can be constructed.
This means that a misﬁt set, which is a set that does not con-
tain the correct word, was involved in the process. However,
the misﬁt set could also be one of those analyzed a few steps
before realizing that no valid sequence can be constructed.
To better spot the misﬁt set, we move the sliding win-
dow back four steps and we temporarily switch to a 4-gram
analysis. This analysis works exactly as the 3-gram one,
just considering sequences of four words instead of three.
This is much more precise and much more sensitive to the
presence of a misﬁt set. In fact, while a valid 3-gram can
be found by chance also when one of the sets is a misﬁt,
this is much less probable in a 4-gram analysis. During the
4-gram analysis, when we reach the point in which no se-
quence can be constructed, we mark that last set as being a
misﬁt and we restart the analysis from the word set follow-
ing the misﬁt set. Unfortunately, 4-gram analysis is slower,
and, therefore, we use this technique only when we suspect
the presence of a misﬁt set. Once the misﬁt set is identi-
ﬁed, the analysis switches back to using the faster 3-gram
technique.
3 Evaluation
To evaluate our approach to the reconstruction of typed
text from the video of typing activity, we are interested in
addressing the following questions:
1. How difﬁcult is it for a human analyst to analyze a
video of a typing session and reconstruct its contents?
2. How well does ClearShot perform at the same task?
Given the attack scenarios we devised (e.g., the installa-
tion of a hidden camera in an ofﬁce, or the eavesdropping
with a camera-enabled mobile phone), we decided to record
the typing activity from directly above the keyboard. We
decided to use a simple web cam, but, of course, more ad-
vanced cameras could also be used, for example to spy from
a distance.
3.1 Setup
The typing sessions were performed on a regular desktop
computer. The keyboard used was a model SK-8110 key-
board, in black color, manufactured by Dell. As a recording
device, we used an inexpensive, off-the-shelf Unibrain Fire-
i web camera, capable of recording up to 15 frames per sec-
onds at 640x480 resolution. We installed the camera over
the monitor and conﬁgured it to record the keyboard. The