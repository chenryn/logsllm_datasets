overhead on routers. For our evaluation, we used a trafﬁc
generator that initiated bandwidth reservation requests, and
sent trafﬁc within existing reservations. The trafﬁc generator
was connected to a software router that performed admission
control of the request packets, RT veriﬁcation, monitoring
for the existent reservations, and then forwarded the packets.
Every experiment was conducted 1 000 times. We considered
routers placed in both edge and core ASes, however processing
time only differed for monitoring operations. All the tests were
conducted on a PC with an Intel Intel Xeon E5-2680 2.7 GHz
and 16 GB of RAM, running Linux (64-bit).
First, we investigated the time required by a router to
process the SIBRA reservation request. The average time to
process a reservation request was 9.1 µs, resulting in about
109 890 that can be processed per second.
Then, we tested the speed of the data packet processing. To
this end, we used our high-performance implementation that
deploys Intel’s DPDK framework8 for networking operations,
8http://dpdk.org/
9
and the AESni extension for cryptographic operations. We set
the packet length to 1 500 bytes. We measured the time of
SIBRA processing (i.e., packet parsing and RT veriﬁcation).
It took 0.040 µs on average to process a single packet, thus
a router is capable to process about 25 million data packets
per second. (Note that these times do not include interactions
with the NIC).
Next, we investigated the performance of monitoring in
the core for two scenarios: 1 and 100 attackers. The average
processing time was 11.24 µs for a single attacker, and 9.91 µs
for 100 attackers. As the results show, the average processing
time decreases with an increasing number of attackers, as
blacklisted ﬂows are processed faster.
B. Bandwidth guarantees under botnet attacks
To show SIBRA’s resilience to Denial of Capability (DoC)
and Coremelt attacks, we run a simulation on an Internet-scale
topology. In our simulation, the attackers attempt to exhaust
the bandwidth of the links common with legitimate ﬂows.
We compare our results with TVA [46], Portcullis [32], and
STRIDE [19], obtained using the same conﬁguration.
Method. Our Internet-scale topology is based on a CAIDA
dataset [2] that contains 49 752 ASes and the links among
them as observed from today’s Internet. Based on these con-
nections, we grouped the ASes into ﬁve ISDs, representing ﬁve
continent-based regions. For our simulation we chose the two
biggest ISDs: ISD1 containing 21 619, and ISD2 containing
6 039 ASes. The core of each ISD is formed by Tier-1 ISPs.
We set the capacity of the core link between ISD1 and ISD2 to
40 Gbps. Inside each ISD, we set the capacity of core links to
10 Gbps, the capacity of links between a core AS and a Tier-2
AS to 2.4 Gbps, and all other links to 640 Mbps. Steady paths
and core paths were established before the experiment.
In both attack scenarios, the attackers (compromised hosts)
are distributed uniformly at random in different ASes. Le-
gitimate sources reside in two ASes (i.e., each AS contains
100 legitimate sources). We further use the same parameters
as the related work: a 5% rate limit for reservation requests,
and request packets of 125 bytes. All the sources (including
attackers) send 10 requests per second. According to Mirkovic
et al. [27], we set 4 seconds as the request timeout.
DoC Attack. We simulate both intra-ISD and inter-ISD DoC
attacks. For the intra-ISD case, source and destination ASes
are within ISD2, and ISD2 contains 1 000 contaminated ASes.
All the requests, from benign and malicious ASes, traverse the
same link in the core. In the inter-ISD scenario, the source
resides in ISD1 and the destination resides in ISD2, there
are 500 contaminated ASes in each ISD, and all the requests
traverse the same links in the core.
Figures 7(a) and 7(b) show the fraction of successfully
delivered capability requests (success ratio) correlated to the
number of active attackers. For both cases (intra- and inter-ISD
DoC attacks), TVA and Portcullis perform similarly: on core
links, legitimate requests mingle with malicious ones. After-
wards, since the link bandwidth decreases after traversing the
core, there is a rapid increase in the request packets’ queueing
time. Consequently, the success ratio decreases. TVA’s success
ratio stabilizes around 40%. Portcullis uses computational
puzzles, and the request packets with a higher computational
level are forwarded ﬁrst. Hence, when more attackers with
optimal strategy [32] appear, the time to compute a puzzle
increases accordingly, leading to a decrease of the success
ratio to 0 when the computation time exceeds 4 seconds. In
STRIDE, the ISD core has no protection, but trafﬁc inside
ISD2 has a higher priority than trafﬁc coming from ISD1.
Thus, during the intra-ISD attack, STRIDE’s success ratio
stays 100% until the core becomes congested. However, in the
inter-ISD case, STRIDE’s performance declines dramatically,
since a majority of requests from ISD1 are dropped if any
core link in ISD2 is congested. SIBRA successfully delivers
all the legitimate requests, in both attack scenarios, because
SIBRA requests are launched using steady paths, and steady
paths guarantee a fair share of control trafﬁc along core paths.
Coremelt Attack. We simulate a Coremelt attack with the
following settings: ISD2 contains 500 pairs of contaminated
ASes (selected uniformly at random), which communicate
using ephemeral paths, each with a throughput of 8 kbps of
their 256 kbps reservations. The source and the destination also
communicate using an ephemeral path, of 800 kbps. All the
ephemeral paths in the experiment traverse the same core link.
We measure the bandwidth obtained when the source sends to
the destination a 1 MB ﬁle.
Figure 7(c) shows that the congestion on the core link
degrades the ﬁle transfer time in STRIDE to over 100 seconds.
TVA, which uses per-destination queues to forward authorized
trafﬁc, performs slightly worse than Portcullis, simulated using
per-source weighted fair sharing based on the computational
level. SIBRA outperforms the other schemes, because it gives
a lower bound on the bandwidth obtained for the ﬁle transfer,
due to its weighted fair sharing based on the steady paths.
C. Lower bound on bandwidth fair share
We simulate the bandwidth obtained by new ephemeral paths
when requests for ephemeral paths arrive from both benign
and malicious sources. We considered a scenario where all
the requests are forwarded using the same steady down-path
(SIBRA’s worst case for weighted fair sharing).
The legitimate steady up-path from the source AS carried
5 requests per second, and has a bandwidth of 362 kbps.
There were approximately 50 attackers on every malicious
up-path, and each attacker sent one request per second. The
attackers’ steady up-path bandwidth was randomly selected
from our steady bandwidth classes (16 kbps to 724 kbps).
The bandwidth requested for ephemeral paths ranged from
256 kbps up to 11.6 Mbps.
The result for this setting is presented in Figure 8(a).
The green line shows the real-time reservable bandwidth, that
changes dynamically but ﬁnally stabilizes around 2.5 Mbps.
At time interval 100, the number of attackers and steady up-
paths used for requesting ephemeral paths increases. However,
SIBRA guarantees that reservable bandwidth remains stable
despite the increasing numbers of attackers. This is due to the
fair share, which is not affected by the number of attackers
with steady paths.
D. Reservation request loss tolerance
Next, we simulate the inﬂuence of packet loss on epheme-
ral bandwidth reservation. We assume that at every second
there are 1 000 reservation requests sent, with the following
parameters: variable path length (5–10), random bandwidth
10
(a)
(b)
(c)
Fig. 7: Comparative simulation results for TVA, Portcullis, STRIDE, and SIBRA against Intra-ISD DoC attack 7(a), Inter-ISD DoC attack 7(b)
and Coremelt attack 7(c).
operated by a small group of ISPs with mutual connectivity.
An essential question is whether such a partially-deployed
new network infrastructure provides immediate ﬁnancial bene-
ﬁts for early adopters, and subsequently attracts new ISPs. The
business example of the startup company Aryaka is similar
to SIBRA regarding the deployment purposes. Aryaka has
successfully established a private core network infrastructure,
dedicated to optimize WAN trafﬁc between Aryaka’s Points
of Presence (POPs) across the world. These POPs deploy
Aryaka’s proprietary WAN optimization protocols, and enter-
prise customers’ distributed business sites located near POPs
beneﬁt from application acceleration. By offering a global
network solution, Aryaka gained the interest of regional ISPs
that want to provide WAN optimization beyond their own re-
gions. Aryaka is continuously expanding its edge infrastructure
through Tier-3 and Tier-4 ISPs. Yet, as opposed to SIBRA, by
using a private core network, Aryaka’s solution comes at a
high cost, and may be even more costly to scale to all ASes
in the Internet.
Similar to the case of Aryaka, we expect SIBRA’s deploy-
ment to begin at the core, between a few Tier-1 ISPs that
seek to provide DILLs spanning their joint regions. These
early adopters may quickly monetize the SIBRA bandwidth
reservation service by selling DILLs to their direct customers.
Gradually, the SIBRA network would expand through new
ISP collaborators interested in providing bandwidth reservation
beyond their own regions. ISPs have the incentive to support
SIBRA, as they can draw trafﬁc towards them, and also appeal
to both existing and new clients who desire effective DDoS
protection, thus increasing the ISPs’ revenues.
During the expansion of SIBRA, ISPs are likely to start
SIBRA deployment with lower ratios for steady and ephemeral
bandwidth, suitable for the needs of a small number of initial
SIBRA customers. Meanwhile, best-effort customers still enjoy
a throughput similar to that before SIBRA deployment. As the
number of SIBRA subscribers increases, ISPs could locally
adjust the ratios towards an increased steady and ephemeral
proportion, and persuade their providers to follow, as well
as adjust their core contracts accordingly. As more and more
customers shift from best-effort to SIBRA, best-effort trafﬁc
obtains a smaller ratio. Depending on their customer segmen-
tation, ISPs could either adjust best-effort subscriptions to the
new network trafﬁc, or increase their link capacity.
We evaluated a potential deployment plan for SIBRA
Fig. 8: Simulation results on SIBRA’s availability. (a) shows the
existence of
the reservable bound for bandwidth requests. Note
that the bandwidth (green line) in the ﬁgure is multiplied by 20
for improved readability. (b) presents the resilience of bandwidth
reservation against packet loss.
(50 kbps – 6.4 Mbps), variable packet loss rate (0–10%), and
RTT set to 1 second. Similar to Portcullis [32] and TVA [46],
we assume that request packets are limited to 5% of the entire
link capacity.
In our simulation, we consider packet loss for both reserva-
tion request and reply packets. This setting introduced unused
bandwidth reservation on the routers that had already pro-
cessed the packet, until bandwidth reclaim occurs. We express
the bandwidth waste rate rwaste as unused reserved bandwidth
divided by the sum of reserved bandwidth.
As shown in Figure 8(b), even at a loss rate of 5%, the
corresponding rwaste is no more than 1.4%. Moreover, the
diagram indicates that rwaste increases linearly when the loss
rate rises, which shows that SIBRA tolerates packet loss well,
thus providing robust bandwidth reservation.
VI.
INCREMENTAL DEPLOYMENT
Within a single ISP network, deployment of SIBRA does not
require major changes in the underlying infrastructure since
the ISP can utilize its existing core network with protocol-
independent transport like MPLS. The ISP can thus build
a “SIBRA-ready” network by adding new customer/provider
edge routers and setting up MPLS tunnels with reserved
bandwidth among them to traverse the traditional network fab-
ric. A global-scale inter-ISP deployment is more challenging,
because a simple overlay approach with IP-tunneling would
not provide the contiguous bandwidth reservation required
for SIBRA. To take full advantage of SIBRA, ISPs need
direct links to interconnect their SIBRA routers. Therefore,
in its initial deployment phase, we envision a SIBRA network
11
00.511.52x 10500.10.20.30.40.50.60.70.80.91# of AttackersSuccess Ratio  SIBRATVAPortcullisSTRIDE00.511.52x 10500.10.20.30.40.50.60.70.80.91# of AttackersSuccess Ratio  SIBRATVAPortcullisSTRIDE00.511.52x 105020406080100120140# of Attacker PairsFile Transfer Time(s)  SIBRATVAPortcullisSTRIDE50100150 1002003004005006000Time(s) # of Up−paths# of Attackers/100BW * 20 [Mbps](b)(a)00.020.040.060.080.10.0050.010.0150.020.0250.03Loss RateWaste Rateteed bandwidth would be suitable to deliver the monitored
parameters, independent of malicious hosts exchanging trafﬁc.
Telemedicine is another use case of practical relevance: the
technology uses telecommunication to provide remote health
care — often in critical cases or emergency situations where
interruptions could have fatal consequences.
Business-critical applications. Videoconferencing between
the remote sites of a company receives increasing importance
as a convenient way to foster collaborations while reducing
travel costs. Short-lived and easily installable DILLs provide
the necessary guaranteed on-demand bandwidth for reliably
exchanging video trafﬁc. Another application is reliable on-
demand sharing of biomedical data for big-data processing,
complementing the efforts of improving health care quality and
cost in initiatives such as Big Data to Knowledge launched by
the US National Institutes of Health (NIH) [26].
VIII. DISCUSSION
• Best-effort
A. On the choice of bandwidth proportions for SIBRA links
Recall that in Section III-A, we assigned 80%, 15%, and 5%
of a link’s bandwidth to ephemeral, best-effort, and steady
paths, respectively. This parameter choice is justiﬁed through
an analysis of today’s actual Internet trafﬁc.
• First to notice is that the majority of trafﬁc constitutes
persistent high-bandwidth connections: for example in
Australia, we see that Netﬂix’s video connections con-
tribute to more than 50% of the entire Internet trafﬁc
[3]. Given an additional amount of trafﬁc from other
large video providers such as Youtube and Facebook, we
estimate ephemeral paths to require roughly 70–90% of