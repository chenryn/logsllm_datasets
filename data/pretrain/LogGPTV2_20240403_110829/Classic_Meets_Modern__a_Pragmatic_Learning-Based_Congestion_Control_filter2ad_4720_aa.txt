title:Classic Meets Modern: a Pragmatic Learning-Based Congestion Control
for the Internet
author:Soheil Abbasloo and
Chen-Yu Yen and
H. Jonathan Chao
1
QTCP: Adaptive Congestion Control with
Reinforcement Learning
Wei Li, Fan Zhou, Kaushik Chowdhury, and Waleed Meleis
Abstract—Next generation network access technologies and Internet applications have increased the challenge of providing
satisfactory quality of experience for users with traditional congestion control protocols. Efforts on optimizing the performance of TCP
by modifying the core congestion control method depending on speciﬁc network architectures or apps do not generalize well under a
wide range of network scenarios. This limitation arises from the rule-based design principle, where the performance is linked to a
pre-decided mapping between the observed state of the network to the corresponding actions. Therefore, these protocols are unable to
adapt their behavior in new environments or learn from experience for better performance. We address this problem by integrating a
reinforcement-based Q-learning framework with TCP design in our approach called QTCP. QTCP enables senders to gradually learn
the optimal congestion control policy in an on-line manner. QTCP does not need hard-coded rules, and can therefore generalize to a
variety of different networking scenarios. Moreover, we develop a generalized Kanerva coding function approximation algorithm, which
reduces the computation complexity of value functions and the searchable size of the state space. We show that QTCP outperforms
the traditional rule-based TCP by providing 59.5% higher throughput while maintaining low transmission latency.
Index Terms—Reinforcement learning, TCP congestion control, function approximation, dynamic generalization, Kanerva coding.
F
1 INTRODUCTION
R APID advancements in wired and wireless technologies has
triggered the emergence of new network architectures, such
as 60 GHz mmWave WiFi [1], cognitive radio networks [2],
[3], [4] and data center networks [5]. At the same time, the
proliferation of new applications such as video streaming, cloud
storage, on-line gaming, creates higher performance requirements
for the data transmission environment and poses new challenges
on the design of congestion control protocols.
In contrast to these new and evolving networking scenarios
and user applications, the same transport protocol design has been
employed over the past three decades, with TCP NewReno being
one of the de-facto congestion control standards. Despite effort
expended to develop new congestion control protocols (such as
Vegas, FAST, see Sec. 6 for more details), these protocols broadly
share a common limitation of not being able to perform well
across a wide range of networking scenarios, and hence, are
seldom deployed in real world networks. This limitation stems
from the fact that these protocols are built on the common concept
of relying on pre-conﬁgured rules to guide the behavior of end
hosts (e.g., how to change the congestion window size) given
speciﬁc observations of the surrounding environment (e.g., mea-
sured throughput, RTT). For example, the NewReno protocol uses
the well-known additive increase, multiplicative decrease (AIMD)
strategy, and Cubic adopts a well-crafted function to adjust the
congestion window size (cwnd) given feedback from the receiver.
This rule-based design can cause two problems: First, it causes
congestion control protocols to be unable to adapt to new scenarios
when a network environment changes. Since different kinds of
networks differ in signiﬁcant ways with respect to bandwidth,
delay and network topology, a given TCP ﬂavor that works well
• W. Li⇤, F. Zhou†, K. Chowdhuryq and W. Meleis‡ are with the Department
of Electrical and Computer Engineering, Northeastern University, Boston,
MA, 02115.
E-mail: {⇤li.wei, †zhou.fan1}@husky.neu.edu, {qkrc, ‡meleis}@ece.neu.edu
for a speciﬁc network might not work in another. Second, the rules
of operation are usually built upon standard assumptions or the
network model. When either changes, the ﬁxed mapping between
observation and actions means that TCP does not intelligently
adjust its behavior by learning from experience. As a result, the
protocol repetitively adopts the same cwnd changing rules that
bring sub-optimal performance, without the ﬂexibility to adjust
behaviors for better performance (Sec. 2).
Proposed Approach: In this work, we use reinforcement learning
(RL) to design a congestion control protocol called QTCP (Q-
learning based TCP) that can automatically identify the optimal
congestion window (cwnd) varying strategy, given the observa-
tion of the surrounding networking environment in an on-line
manner. It does not need for manually-crafted rule sets or time-
consuming off-line training process. RL enables agents to adjust
their behavior based on real-time feedback, and avoid repeating
the same mistakes by discouraging ineffective behavior. We utilize
this capability in QTCP to allow senders to dynamically learn
different strategies to better adapt to varying networking scenarios,
instead of mechanically following ﬁxed rules. Speciﬁcally, QTCP
continuously updates the values of possible state-action pairs of
the protocol, based on the measurement of performance metrics
collected from a networking environment, and uses Q-learning
algorithm to search for the best action, i.e., how to adjust the cwnd
in speciﬁc states so that the long term reward of the sender is
maximized.
Challenges and Innovations: While RL has been shown to
perform well on many hard problems (e.g., Go, automatic driving),
applying it to TCP congestion control is particular challenging due
to the problem’s continuous, high-dimensional state space. The
size of the state space can grow exponentially with the dimension
of the state space, causing an signiﬁcant increase in the size of the
table needed to store the state-action values. It is usually very time-
consuming to update entries in such a large table, which results in
unacceptably long training time. To speed up the learning process
and make QTCP tractable, we apply function approximation [6],
which is an effective way to reduce the size of the state space
needed to search and explore using an abstract state representation.
While there are many function approximation algorithms
available, we choose Kanerva coding [7], also known as Sparse
Distributed Memories (SDMs), because of its low complexity,
quick convergence and its effectiveness in solving problems with
large, high-dimensional and continuous state spaces. The idea
of Kanerva coding considers such a setting that the whole state
space is represented by a carefully selected subset of the state
space based on which trained values are stored and derived
policies are evaluated, thus reducing the memory consumption and
computation complexity of value trainings signiﬁcantly. However,
we found that the performance of original Kanerva coding is
not satisfactory in practice due to the improper selection of the
subset of the state space. To solve this problem, we propose a
novel approach, generalization-based Kanerva coding, that can
adjust the level of abstraction for each entry of the subset of
the state space and thus dynamically reallocate the subset to ﬁnd
its near-optimal structure when exploring the state space. Our
approach allows the granularity of the state abstraction to be
changeable based on visited states, where less important entries
of the subset with improper levels of generalization are examined
and replaced with ones that provide better generalization. This
overcomes the limitations of the classic Kanerva coding algorithm
and its variants, enabling QTCP to have faster convergence and
better overall learning performance.
In summary, we make following two contributions:
• We describe QTCP, a Q-learning based congestion control
protocol that automatically learns the effective strategies
for adjusting the cwnd to achieve high throughput and low
delay in an on-line manner. This fundamentally changes
the design of previous NewReno-like TCP variants that
require ﬁxed, manually selected rules.
• We propose a new kind of Kanerva coding algorithm that
scales well when applied to large complex state spaces
and greatly speeds up convergence and provides stable
performance. Our algorithm allows the learned values no
longer to be stored in a tabular form and thus eliminates
a vital limitation, e.g., unable to handle enormous states,
of RL technique when applied to large-scale problem
domains.
This paper is organized as followings. In Sec. 2, we give an
overview of congestion control problems and the limitations of
rule-based TCP variants (using NewReno as an example). We
describe the design of QTCP in Sec. 3. In Sec. 4, we introduce
the principles of function approximation used in RL, discuss the
issues of existing Kanerva coding approaches, and then propose
our generalization-based Kanerva coding algorithm. We present
experimental results in Sec. 5. We show related work in Sec. 6
and ﬁnally conclude our work in Sec. 7.
2 BACKGROUND AND MOTIVATION
In this section, we quantitatively describe the problem with classic
additive increase multiplicative decrease (AIMD) rule used by
TCP NewReno. Then we discuss the limitations of rule-based
TCP and motivate the need for a more adaptive strategy to control
congestion in a network.
)
s
t
e
k
c
a
p
(
D
N
W
C
350
300
250
200
150
100
50
0
1
2
3
2
3
TCP NewReno
2
0
5
10
15
25
20
30
Time (seconds)
35
40
45
50
Fig. 1: TCP cwnd graph for a NewReno ﬂow: (1) slow start (2)
congestion avoidance and (3) fast recovery after duplicate ACK.
2.1 Congestion Control: Problems and a Classical So-
lution
The goal of congestion control
is to allow senders to share
limited bandwidth fairly, without overwhelming the network. The
congestion control algorithm does this by maintaining a cwnd that
limits the maximum number of packets each sender can safely
inject into the network without causing trafﬁc congestion. In
general, using larger cwnd allows more packets to be sent into
the network that can potentially give higher throughput. However,
if every sender tries to greedily maximize its own throughput and
keeps increasing cwnd, increased congestion can severely degrade
every sender’s performance.
While many other factors (such as packet size, sender and
receiver buffer size, etc) can inﬂuence the value of the cwnd, the
key problem in congestion control is to enable each sender to
independently tune the cwnd that maximizes its own throughput
while co-existing fairly with other competing ﬂows in the network.
For example, the sender should increase the cwnd to increase the
link utilization and reduce the cwnd if the packet loss rate or
the queuing delay increases when the network is congested. The
challenge is that TCP is an end-to-end protocol as it works only on
two end hosts. The sender does not has ground truth information
about path characteristics, such as bottleneck link bandwidth or
the current number of ﬂows that are sharing the same link.
Nor can different senders coordinate or share information with
one another. The end-to-end paradigm signiﬁcantly increases the
complexity of congestion control protocol design. While there are
some TCP variants that break this rule by assuming the existence
of a centralized controller or the availability of a global view of
the entire network, such designs are limited in generality and can
only be applied to small-scale scenarios such as enterprise or data
center networks.
A classic congestion control protocol is NewReno [8], which
is also one of the most widely used TCP today. It uses the AIMD
rule to control the cwnd. The basic idea of AIMD is to ﬁrst
slowly increase the cwnd until the bottleneck link buffer has been
saturated and the packets are dropped by the router (additively
increase). Information about packet drops is conveyed back to
the sender with duplicate ACKs indicating network congestion.
After that, sender reduces its sending rate by halving its cwnd
(multiplicative decrease). In summary, the behavior of NewReno
can be broadly modeled as using the following three stages:
Slow start: cwnd = cwnd + 1 for every ACK received
•
ACK received
• Congestion avoidance: cwnd = cwnd + 1/cwnd for every
• Fast recovery (duplicate ACK): cwnd = cwnd/2
The phases of NewReno are shown in Fig.1. During slow start
(stage 1), the cwnd ramps up quickly, approximately doubling
every RTT until it reaches the slow start threshold. This allows
the new ﬂows to quickly acquire bandwidth. During congestion
avoidance (stage 2), the increasing speed of cwnd slows down
(approximately by 1 MSS every RTT). This is to enable the sender
to cautiously detect the congestion point of the network. Once the
sender receives packet loss information, it halves cwnd when it
receives duplicate ACKs (stage 3) or reduces cwnd to 1 when
severe congestion is observed and the sender fails to receive any
feedback from the receiver. It has been shown that AIMD can
guarantee convergence to a policy that optimally shares bottleneck
bandwidth with respect to both efﬁciency and fairness [9].
2.2 Limitation of Rule-based TCP Protocols
In addition to NewReno, many other congestion control protocols
have been described to further optimize TCP0s performance for
speciﬁc networks or applications. However, we point out that
there are two key limitations faced by these rule-based congestion
control protocols:
)
s
p
b
M
(
t
u
p
h
g
u
o
r
h
T
)
s
t
e
k
c
a
p
(
D
N
W
C
50
40
30
20
10
0
0
10
20
30
3
Capacity
TCP NewReno
50
40
60
Time (seconds)
70
80
90 100
300
250
200
150
100
50
0