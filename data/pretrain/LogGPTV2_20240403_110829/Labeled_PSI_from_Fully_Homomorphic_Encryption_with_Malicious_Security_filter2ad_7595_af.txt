Y (cid:48) = {Fk(y) : y ∈ Y }. Next the sender sends X(cid:48) to the receiver, who infers the intersection from
X(cid:48) ∩ Y (cid:48) [31].
The main limitation of this approach is that the receiver requires communication linear in the
larger set X. The protocol above was ﬁrst described in the malicious setting by [31], and later
optimized for the semi-honest setting by [5]. For modest size X this approach works reasonably
well. For instance, with |X| = 220 and a receiver’s set of 5535 items, the communication of X(cid:48) is
10 MB. However, increasing |X| further to 224 or 228 starts to become less practical with 160 MB
and 2.6 GB of communication, respectively.
One of the most compelling properties of this paradigm is that after the communication of X(cid:48),
the receiver can check the membership of a y in X using O(κ) communication and computation—
eﬀectively a constant. Observing this, [47,35] both suggest that X(cid:48) be sent during an oﬄine or
pre-processing phase, and then the online phase can have linear overhead in the smaller set, which
provides extremely good performance. Moreover, many adaptive set intersections with X can be
performed, where the receiver is able to use a diﬀerent set each time. The online communication
and running time of this approach remains linear in the receiver’s set size.
On top of this general paradigm, [47,35] suggest that the encoded set X(cid:48) can be compressed
using techniques such as a cuckoo ﬁlter or a Bloom ﬁlter. [47] showed that for certain parameters
a cuckoo ﬁlter can reduce the communication by roughly 3×, bringing the communication for
|X| = 224 and 228 down to 48 and 806 MB, respectively. This approach has the disadvantage that
such a large amount of compression introduces a relatively high false positive rate of 2−13.4 × |Y |.
That is, if the receiver has 1024 items outside the intersection, the probability that the receiver will
output a wrong item is 2−3.2, which is extremely high for cryptographic protocols. In contrast, our
protocol and [12] both provide a false positive rate of at least 2−40, and this rate is independent of
the receiver’s set size.
In addition, the communication complexity of [47] remains linear in the larger set size. In the
example of |X| = 228 the communication of 804 MB can be prohibitive for many applications.
Moreover, for this online-oﬄine technique to work, the receiver must store the compressed set
long-term, which can be prohibitive on mobile devices. In contrast to this paradigm, our FHE-
based protocol achieves communication complexity which is sub-linear in the larger set size and
requires no oﬄine storage by the receiver. When considering |X| = 228 and |Y | = 1024, the total
communication is less than 19 MB compared to 806 MB: a 43× improvement in communication
and a 226× improvement in the false positive rate. To achieve an equivalent false positive rate, e.g.
in the [5] protocol, the communication increases to 2.6 GB—a diﬀerence of 100×.
Finally, there is a diﬀerence in the security achieved with respect to the information revealed
when X is updated. In the case of [47,5,35], the receiver learns exactly how many items we inserted
and removed from X. Even worse, the deletion of an item from X cannot be enforced, since the
receiver can simply keep the corresponding OPRF value which they hold in X(cid:48). As such, deletions
cannot be enforced even in the semi-honest model. In contrast, our protocol can easily add and
remove items without leaking extra information to the receiver. In particular, the issue with deleting
an item from X does not arise since only the sender holds X.
With respect to [12], we compare quite favorably in many aspects. First recall that [12] is
practically restricted to 32-bit items, while we can support arbitrary length items. In particular, in
[12] the actual items being compared within FHE are only 22 bits, but are extended to 32 bits using
phasing [43]. Our protocol contrasts this by comparing 80-bit items within the FHE computation.
Combined with the “hash to smaller domain” techniques of [45], this is suﬃciently large to support
our PSI set sizes, while achieving 40 bits of statistical security.
Given this signiﬁcant improvement, our protocol still achieves a similar communication over-
head, and often better online running times. For example, when comparing |X| = 224 and |Y | =
5535, our protocol requires 16 MB of communication and 22 seconds in the online phase on a single
thread, while [12] requires 20 MB and 40 seconds. This is almost a 2× improvement in running
time, a 27% improvement in the communication, and the capability to compare arbitrary length
strings. Moreover, when the receiver has an even smaller set, our protocol is able to scale the FHE
parameters even smaller, which allows less communication. For example, when the receiver has
512 or 1024 items, our protocol requires 9.1 and 17.7 seconds, respectively, and just 8.2 MB of
communication. On the other hand, due to the noise ﬂooding performed by [12], they are unable to
take advantage of more eﬃcient FHE parameters while also maintaining 128 bits of computational
security. As such, our protocol can be 2 to 4 times faster than [12], and send almost half the amount
of data, while at the same time supporting arbitrary length items.
8.4 Labeled PSI
We compare the performance of our Labeled PSI technique with the PIR by keywords utilized by
the anonymous communication protocol Pung [3,2]. The Pung protocol allows a set of clients to
privately send and retrieve messages through a server, without the server learning any information
(including metadata) about the conversations. In each epoch of the protocol, a client wishes to
privately retrieve several messages from the server from other clients using some secret keywords
they share. This was achieved using a single-server PIR based on additive homomorphic encryption.
In order for a client to obtain the index of messages sent to her, the server sends a Bloom ﬁlter
containing the keyword-to-index mapping to each client. Pung also optimized for the multi-query
using hashing techniques. In one setting, the client retrieves 256 messages in each epoch. Each
message has 288 bytes, and a total number of 1 million messages is stored at the server. We
used Labeled PSI to implement the retrieval process, and compared our performance to [2] in
Figure 6. From the results, we see that Labeled PSI can achieve a 4.4× reduction in server’s online
computation time, and 6.8× reduction in communication.
|X|
|Y | Protocol
Sender Oﬄine Comm. & Online Online
Oﬄine Receiver Storage Time Comm.
228
2048
1024
224
11041
5535
220
11041
5535
Ours*
[47]*
[5]*
Ours*
[47]*
[5]*
Ours
[12]
[47]
[5]
Ours
[12]
[47]
[5]
Ours
[12]
[47]
[5]
Ours
[12]
[47]
[5]
4,628
182
182
4,628
182
182
656
71
342
342
806
64
342
342
43
6.4
22
22
43
4.3
22
22
0
806
2,684
0
806
2,684
28.5
0.1
0.1
12.1
0.16
0.16
0
20.1
0 44.70
0.71
0.71
0 22.01
0 40.10
0.35
0.35
48
160
48
160
0
0
3
10
0
0
3
10
4.49
6.40
0.71
0.71
4.23
4.30
0.35
0.35
22.28
0.13
0.13
18.57
0.07
0.07
41.48
23.20
0.67
0.67
16.39
20.10
0.34
0.34
14.34
11.50
0.67
0.67
11.50
5.60
0.34
0.34
Fig. 5. Our PSI protocol compared with [12,47,5] in the LAN setting for various set sizes. All executions are with a
single thread with the exception (*) of |X| = 228, which is performed with 32 threads by the sender, and 4 threads
by the receiver. Communication/storage is in MB and running time is in seconds. The “Sender oﬄine” column is
running time required by the sender to initialize their database. It can be reused and is non-interactive.
|X| |Y | (cid:96) (Bytes) Method Server online Client encrypt Comm.
120 MB
17.6 MB
4.92 s
0.77 s
20.5 s
4.6 s
[2]
Ours