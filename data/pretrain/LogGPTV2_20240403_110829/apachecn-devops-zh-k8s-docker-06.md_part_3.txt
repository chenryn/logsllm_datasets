![Figure 6.5 – Ingress traffic flow ](img/Fig_6.5_B15514.jpg)
图 6.5–入口流量
图 6.5 显示了 Kubernetes 如何处理传入的入口请求的高级概述。为了帮助更深入地解释每一步，让我们更详细地看一下这五个步骤。使用图 6.5 中提供的图形，我们将详细解释每个编号的步骤，以展示 Igress 如何处理请求:
1.  用户在其浏览器中请求一个名为 web server 1 . 192 . 168 . 200 . 20 . nio . io 的 URL。一个 DNS 请求被发送到本地 DNS 服务器，该服务器最终被发送到 nip.io DNS 服务器。
2.  nip.io 服务器将域名解析为 ip 地址 192.168.200.20，并返回给客户端。
3.  客户端将请求发送到运行在 192.168.200.20 上的入口控制器。该请求包含完整的网址名称**web server 1 . 192 . 168 . 200 . 20 . nio . io**。
4.  入口控制器在配置的规则中查找请求的网址名称，并将该网址名称与服务匹配。
5.  服务端点将用于将流量路由到分配的 pods。
6.  该请求被路由到运行 web 服务器的端点 pod。
使用前面的流量流示例，让我们看一下需要创建的 Kubernetes 对象:
1.  首先，我们需要一个运行在命名空间中的简单 web 服务器。我们将简单地在默认命名空间中部署一个基本的 NGINX 服务器。我们可以使用以下`kubectl run`命令快速创建部署，而不是手动创建清单:
    ```
    kubectl run nginx-web --image bitnami/nginx
    ```
2.  使用`run`选项是一个快捷方式，它将在默认命名空间中创建一个名为`nginx-web`的部署。您可能会注意到，输出将向您发出警告，说明运行已被否决。这只是一个警告；它仍将创建我们的部署，尽管使用`run`创建部署在未来的 Kubernetes 版本中可能不起作用。
3.  Next, we need to create a service for the deployment. Again, we will create a service using a kubectl command, `kubectl expose`. The Bitnami NGINX image runs on port 8080, so we will use the same port to expose the service:
    ```
    kubectl expose deployment nginx-web --port 8080 --target-port 8080
    ```
    这将为我们的部署创建一个名为 nginx-web 的新服务，称为 nginx-web。
4.  Now that we have our deployment and service created, the last step is to create the Ingress rule. To create an Ingress rule, you create a manifest using the object type `Ingress`. The following is an example Ingress rule that assumes that the Ingress controller is running on 192.168.200.20\. If you are creating this rule on your host, you should use the **IP address of your Docker host**.
    创建一个名为`nginx-ingress.yaml`的文件，内容如下:
    ```
    apiVersion: networking.k8s.io/v1beta1
    kind: Ingress
    metadata:
      name: nginx-web-ingress
    spec:
      rules:
      - host: webserver1.192.168.200.20.nip.io
        http:
          paths:
          - path: /
            backend:
              serviceName: nginx-web
              servicePort: 8080
    ```
5.  使用`kubectl apply` :
    ```
    kubectl apply -f nginx-ingress.yaml
    ```
    创建入口符文
6.  您可以通过浏览入口网址`http:// webserver1.192.168.200.20.nip.io`，从内部网络上的任何客户端测试部署。
7.  如果一切都创建成功，您应该会看到 NGINX 欢迎页面:
![Figure 6.6 – NGINX web server using nip.io for Ingress ](img/Fig_6.6_B15514.jpg)
图 6.6–将 nip.io 用于入口的 NGINX 网络服务器
使用本节中的信息，您可以为使用不同主机名的多个容器创建入口规则。当然，你并不局限于使用像 nip.io 这样的服务来解析名字；您可以使用环境中可用的任何名称解析方法。在生产集群中，您将拥有企业 DNS 基础架构，但在实验室环境中，例如我们的 KinD 集群，nip.io 是测试需要适当命名约定的场景的完美工具。
我们将在整本书中使用 nip.io 命名标准，因此在进入下一章之前，了解命名约定非常重要。
第 7 层负载平衡器，如 NGINX Ingress，被许多标准工作负载使用，如网络服务器。将会有需要更复杂的负载平衡器的部署，该负载平衡器运行在 OIS 模型的较低层。当我们向下移动模型时，我们获得了较低级别的特征。在下一节中，我们将讨论第 4 层负载平衡器。
注意
如果您在集群上部署了 NGINX 示例，您应该删除服务和入口规则:
要删除入口规则，请执行以下操作: `kubectl delete ingress nginx-web-ingress`
要删除服务，请执行以下操作: `kubectl delete service nginx-web`
您可以让 NGINX 部署在下一部分继续运行。
# 第 4 层负载平衡器
OSI 模型的第 4 层负责 TCP 和 UDP 等协议。运行在第 4 层的负载均衡器根据唯一的 IP 地址和端口接受输入流量。传入的请求由负载平衡器接受，并根据一组规则，将流量发送到目标 IP 地址和端口。
这个过程中有一些较低级别的网络操作不在本书的讨论范围之内。HAproxy 在 https://www.haproxy.com/fr/blog/loadbalancing-faq/的网站上对术语和示例配置有一个很好的总结。
## 第 4 层负载平衡器选项
如果您想为 Kubernetes 集群配置第 4 层负载平衡器，有多个选项可供选择。一些选项包括以下内容:
*   哈普西
*   坚尼克斯 Pro
*   跷跷板
*   F5 网络
*   梅塔洛
*   还有更多…
每个选项都提供第 4 层负载平衡，但就本书而言，我们认为 MetalLB 是最佳选择。
## 使用 MetalLB 作为第 4 层负载平衡器
重要说明
请记住，在 [*第 4 章*](04.html#_idTextAnchor083) *中，使用 KinD* 部署 Kubernetes 时，我们有一个显示工作站和 KinD 节点之间流量的图表。因为 KinD 是在嵌套的 Docker 容器中运行的，所以第 4 层负载平衡器在网络连接方面会有一定的限制。如果 Docker 主机上没有额外的网络配置，您将无法在 Docker 主机本身之外定位使用负载平衡器类型的服务。
如果您将 MetalLB 部署到在主机上运行的标准 Kubernetes 集群，您将不会被限制访问主机本身之外的服务。
MetalLB 是一个免费的，简单的来配置第 4 层负载平衡器。它包括强大的配置选项，使其能够在开发实验室或企业集群中运行。由于它用途广泛，它已成为需要第 4 层负载平衡的集群的一个非常受欢迎的选择。
在本节中，我们将重点介绍如何在第 2 层模式下安装 MetalLB。这是一个简单的安装，适用于小型 Kubernetes 集群的开发。MetalLB 还提供了使用 BGP 模式部署的选项，该模式允许您建立对等伙伴来交换网络路由。如果你想了解 MetalLB 的 BGP 模式，可以在 MetalLB 的网站[https://metallb.universe.tf/concepts/bgp/](https://metallb.universe.tf/concepts/bgp/)上了解。
### 安装金属
要在您的 KinD 集群上部署 MetalLB，请使用 MetalLB 的 GitHub 存储库中的清单。要安装 MetalLB，请通过以下步骤进入:
1.  下面将创建一个名为`metallb-system`的新名称空间，标签为`app: metallb` :
    ```
    kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/namespace.yaml
    ```
2.  这将把 MetalLB 部署到您的集群中。它将创建所有必需的 Kubernetes 对象，包括`PodSecurityPolicies`、`ClusterRoles`、`Bindings`、`DaemonSet`和一个`deployment` :
    ```
    kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.3/manifests/metallb.yaml
    ```
3.  最后一个命令将在`metalb-system` 命名空间中创建一个机密，该机密具有随机生成的值。这个机密被 MetalLB 用来加密扬声器之间的通信:
    ```
    kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey="$(openssl rand -base64 128)"
    ```
现在 MetalLB 已经部署到集群中，您需要提供一个配置文件来完成设置。
### 了解 MetalLB 的配置文件
MetalLB 使用包含配置的配置图进行配置。由于我们将在第 2 层模式下使用 MetalLB，所需的配置文件相当简单，只需要一条信息:您想要为服务创建的 IP 范围。
为了保持配置简单，我们将使用运行 KinD 的 Docker 子网的一小部分。如果您在标准的 Kubernetes 集群上运行 MetalLB，您可以分配网络中任何可路由的范围，但是我们的 KinD 集群受到限制。
要获得 Docker 正在使用的子网，我们可以检查我们正在使用的默认桥接网络:
`docker network inspect bridge`
在输出中，您将看到分配的子网，如下所示:
**“子网”:“172 . 17 . 0 . 0/16”**
这是一个完整的 B 类地址范围。我们知道我们不会使用所有的 IP 地址来运行容器，所以我们将使用 MetalLB 配置中子网的一小部分。
让我们创建一个名为`metallb-config.yaml`的新文件，并将以下内容添加到该文件中:
```
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: metallb-system
  name: config
data:
  config: |
    address-pools:
    - name: default
      protocol: layer2
      addresses:
      - 172.17.200.100-172.17.200.125
```
清单将在名为`config`的`metallb-system`命名空间中创建一个配置映射。配置文件将使用名为`default`的 IP 池将 MetalLB 的模式设置为第 2 层，对于负载平衡器服务，使用范围为 172.16.200-100 到 172.16.200.125 的。
您可以根据配置名称分配不同的地址。我们将在解释如何创建负载平衡器服务时展示这一点。
最后，使用 kubectl 部署清单:
`kubectl apply -f metallb-config.yaml`
为了理解 MetalLB 是如何工作的，您需要知道安装的组件以及它们如何相互作用来为服务分配 IP 地址。
### 金属成分
我们的部署中的第二个清单是将 MetalLB 组件安装到集群中。它部署了一个包含扬声器映像的 daemmonset 和一个包含控制器映像的 daemmonset。这些组件相互通信以维护服务列表和分配的 IP 地址:
#### 演讲者
扬声器组件是 MetaLB 用来在节点上宣布负载平衡器服务的组件。它被部署为一个 DaemonSet，因为部署可以在任何工作节点上，因此，每个工作节点都需要宣布正在运行的工作负载。由于服务是使用负载平衡器类型创建的，所以演讲者将宣布服务。
如果我们从节点查看演讲者日志，我们可以看到以下公告:
```
{"caller":"main.go:176","event":"startUpdate","msg":"start of service update","service":"my-grafana-operator/grafana-operator-metrics","ts":"2020-04-21T21:10:07.437231123Z"}
{"caller":"main.go:189","event":"endUpdate","msg":"end of service update","service":"my-grafana-operator/grafana-operator-metrics","ts":"2020-04-21T21:10:07.437516541Z"}
{"caller":"main.go:176","event":"startUpdate","msg":"start of service update","service":"my-grafana-operator/grafana-operator-metrics","ts":"2020-04-21T21:10:07.464140524Z"}
{"caller":"main.go:246","event":"serviceAnnounced","ip":"10.2.1.72","msg":"service has IP, announcing","pool":"default","protocol":"layer2","service":"my-grafana-operator/grafana-operator-metrics","ts":"2020-04-21T21:10:07.464311087Z"}
{"caller":"main.go:249","event":"endUpdate","msg":"end of service update","service":"my-grafana-operator/grafana-operator-metrics","ts":"2020-04-21T21:10:07.464470317Z"}
```
前面的公告是给格拉夫纳的。公告发布后，可以看到它被分配了一个 10.2.1.72 的 IP 地址。
#### 控制器
控制器将从每个工作节点上的扬声器接收通知。使用前面显示的相同服务公告，控制器日志显示公告和控制器分配给服务的 IP 地址:
```
{"caller":"main.go:49","event":"startUpdate","msg":"start of service update","service":"my-grafana-operator/grafana-operator-metrics","ts":"2020-04-21T21:10:07.437701161Z"}
{"caller":"service.go:98","event":"ipAllocated","ip":"10.2.1.72","msg":"IP address assigned by controller","service":"my-grafana-operator/grafana-operator-metrics","ts":"2020-04-21T21:10:07.438079774Z"}
{"caller":"main.go:96","event":"serviceUpdated","msg":"updated service object","service":"my-grafana-operator/grafana-operator-metrics","ts":"2020-04-21T21:10:07.467998702Z"}
```
在日志的第二行，你可以看到控制器分配了 10.2.1.72 的 IP 地址。
## 创建负载平衡器服务
现在，您已经安装了 MetalLB 并了解了组件如何创建服务，让我们在我们的 KinD 集群上创建第一个负载平衡器服务。
在第 7 层负载平衡器部分，我们创建了一个运行 NGINX 的部署，我们通过创建一个服务和一个入口规则公开了该部署。在这一节的最后，我们删除了服务和入口规则，但是我们保留了这一节的 NGINX 部署。如果您遵循了入口部分中的步骤，并且没有删除服务和入口规则，请在创建负载平衡器服务之前删除。如果您根本没有创建部署，您将需要本部分的 NGINX 部署: