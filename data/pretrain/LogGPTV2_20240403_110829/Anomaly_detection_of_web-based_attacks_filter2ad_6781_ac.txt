ρ =
Covar(f, g)
Var(f ) ∗ Var(g)
(10)
If ρ is less than 0, then f and g are negatively correlated
and an enumeration is assumed. This is motivated by the fact
that, in this case, increasing function values of f (reﬂecting
the increasing number of analyzed parameters) correlate with
decreasing values of g(x) (reﬂecting the fact that many argu-
ment values for a have previously occurred). In the opposite
case, where ρ is greater than 0, the values of a have shown
suﬃcient variation to support the hypothesis that they are
not drawn from a small set of predeﬁned tokens.
When an enumeration is assumed, the complete set of iden-
tiﬁers is stored for use in the detection phase.
4.4.2 Detection
Once it has been determined that the values of a query
attribute are tokens drawn from an enumeration, any new
value is expected to appear in the set of known values. When
this happens, 1 is returned, 0 otherwise. If it has been de-
termined that the parameter values are random, the model
always returns 1.
4.5 Attribute Presence or Absence
Most of the time, server-side programs are not directly in-
voked by users typing the input parameters into the URIs
themselves. Instead, client-side programs, scripts, or HTML
forms pre-process the data and transform it into a suitable
request. This processing step usually results in a high reg-
ularity in the number, name, and order of parameters. Em-
pirical evidence shows that hand-crafted attacks focus on ex-
ploiting a vulnerability in the code that processes a certain
parameter value, and little attention is paid to the order or
completeness of the parameters.
The analysis takes advantage of this fact and detects re-
quests that deviate from the way parameters are presented
by legitimate client-side scripts or programs. This type of
anomaly is detected using two diﬀerent algorithms. The ﬁrst
one, described in this section, deals with the presence and
absence of attributes ai in a query q. The second one is
based on the relative order of parameters and is further dis-
cussed in Section 4.6. Note that the two models diﬀer from
the previous ones because the analysis is performed on the
query as a whole, and not individually on each parameter.
The algorithm discussed hereinafter assumes that the ab-
sence or abnormal presence of one or more parameters in a
query might indicate malicious behavior.
In particular, if
an argument needed by a server-side program is missing, or
if mutually exclusive arguments appear together, then the
request is considered anomalous.
4.5.1 Learning
The test for presence and absence of parameters creates a
model of acceptable subsets of attributes that appear simul-
taneously in a query. This is done by recording each distinct
subset Sq = {ai, . . . , ak} of attributes that is seen during the
training phase.
4.5.2 Detection
During the detection phase, the algorithm performs for
each query a lookup of the current attribute set. When the
set of parameters has been encountered during the training
phase, 1 is returned, otherwise 0.
4.6 Attribute Order
As discussed in the previous section, legitimate invocations
of server-side programs often contain the same parameters
in the same order. Program logic is usually sequential, and,
therefore, the relative order of attributes is preserved even
when parameters are omitted in certain queries. This is not
the case for hand-crafted requests, as the order chosen by a
human can be arbitrary and has no inﬂuence on the execution
of the program.
The test for parameter order in a query determines whether
the given order of attributes is consistent with the model
deduced during the learning phase.
4.6.1 Learning
The order constraints between all k attributes (ai : ∀i =
1 . . . k) of a query are gathered during the training phase.
An attribute as of a program precedes another attribute at
when as and at appear together in the parameter list of at
least one query and as comes before at in the ordered list of
attributes of all queries where they appear together.
This deﬁnition allows one to introduce the order constraints
as a set of attribute pairs O such that:
O = {(ai, aj) : ai precedes aj and
ai, aj ∈ (Sqj : ∀j = 1 . . . n)}
(11)
The set of attribute pairs O is determined as follows. Con-
sider a directed graph G that has a number of vertices equal
to the number of distinct attributes. Each vertex vi in G
is associated with the corresponding attribute ai. For every
query qj , with j = 1 . . . n, that is analyzed during the train-
ing period, the ordered list of its attributes a1, a2, . . . , ai is
processed. For each attribute pair (as, at) in this list, with
s (cid:7)= t and 1 ≤ s, t ≤ i, a directed edge is inserted into the
graph from vs to vt.
At the end of the learning process, graph G contains all or-
der constraints imposed by queries in the training data. The
order dependencies between two attributes are represented
either by a direct edge connecting their corresponding ver-
tices, or by a path over a series of directed edges. At this
point, however, the graph could potentially contain cycles as
a result of precedence relationships between attributes de-
rived from diﬀerent queries. As such relationships are im-
possible, they have to be removed before the ﬁnal order con-
straints can be determined. This is done with the help of
Tarjan’s algorithm [33] which identiﬁes all strongly connected
components (SCCs) of G. For each component, all edges con-
necting vertices of the same SCC are removed. The resulting
graph is acyclic and can be utilized to determine the set of
attribute pairs O which are in a ‘precedes’ relationship. This
is obtained by enumerating for each vertex vi all its reachable
nodes vg, . . . , vh in G, and adding the pairs (ai, ag) . . . (ai, ah)
to O.
4.6.2 Detection
The detection process checks whether the attributes of a
query satisfy the order constraints deduced during the learn-
ing phase. Given a query with attributes a1, a2, . . . , ai and
the set of order constraints O, all the parameter pairs (aj, ak)
with j (cid:7)= k and 1 ≤ j, k ≤ i are analyzed to detect po-
tential violations. A violation occurs when for any single
pair (aj, ak), the corresponding pair with swapped elements
(ak, aj) is an element of O.
In such a case, the algorithm
returns an anomaly score of 0, otherwise it returns 1.
5. EVALUATION
This section discusses our approach to validate the pro-
posed models and to evaluate the detection eﬀectiveness of
our system. That is, we assess the capability of the models to
accurately capture the properties of the analyzed attributes
and their ability to reliably detect potentially malicious de-
viations.
The evaluation was performed using three data sets. These
data sets were Apache log ﬁles from a production web server
at Google, Inc. and from two Computer Science Department
web servers located at the University of California, Santa
Barbara (UCSB) and the Technical University, Vienna (TU
Vienna).
We had full access to the log ﬁles of the two universities.
However, the access to the log ﬁle from Google was restricted
because of privacy issues. To obtain results for this data set,
our tool was run on our behalf locally at Google and the
results were mailed to us.
Table 2 provides information about important properties
of the data sets. The table shows the time interval during
which the data was recorded and the log ﬁle size.
It also
lists the total number of HTTP queries in the log ﬁle, the
number of requests that invoke server-side programs (such
as CGI requests), the total number of their attributes, and
the number of diﬀerent server-side programs.
5.1 Model Validation
This section shows the validity of the claim that our pro-
posed models are able to accurately describe properties of
query attributes. For this purpose, our detection tool was
run on the three data sets to determine the distribution of
the probability values for the diﬀerent models. The length
of the training phase was set to 1,000 for this and all follow-
ing experiments. This means that our system used the ﬁrst
thousand queries that invoked a certain server-side program
to establish its proﬁles and to determine suitable detection
thresholds.
Data Set
Google
UCSB
TU Vienna
Time Interval
1 hour
297 days
80 days
Size (MByte) HTTP Queries Program Requests Attributes Programs
206
395
84
1,611,254
4,617
765,399
640,506
9,951,174
2,061,396
490,704
7,993
713,500
236
1,001
251
l
s
e
u
a
V
e
u
b
i
r
t
t
t
A
f
o
r
e
b
m
u
N
e
v
i
t
l
a
e
R
1
0.1
0.01
0.001
0.0001
0
Table 2: Data Set Properties
Google
UCSB
TU Vienna
0.2
0.4
0.6
0.8
1
Probability Values
Figure 3: Attribute Length
Figure 3 and 4 show a distribution of the probability values
that have been assigned to the query attributes by the length
and the character distribution models, respectively. The y-
axis shows the percentage of attribute values that appeared
with a speciﬁc probability. For the ﬁgures, we aggregated the
probability values (which are real numbers in the interval be-
tween 0.0 and 1.0) into ten bins, each bin covering an interval
of 0.1. That is, all probabilities in the interval [0.0, 0.1[ are
added to the ﬁrst bin, values in the interval [0.1, 0.2[ are
added to the second bin, and so forth. Note that a proba-
bility of 1 indicates a completely normal event. The relative
number of occurrences are shown on a logarithmic scale.
Table 3 shows the number of attributes that have been
rated as normal (with a probability of 1) or as anomalous
(with a probability of 0) by the structural model and the
token ﬁnder model. The table also provides the number
of queries that have been classiﬁed as normal or as anoma-
lous by the presence/absence model and the attribute order
model. The number of queries is less than the number of
attributes, as each query can contain multiple attributes.
The distributions of the anomaly scores in Figure 3, Fig-
ure 4 and Table 3 show that all models are capable of captur-
ing the normality of their corresponding features. The vast
majority of the analyzed attributes are classiﬁed as normal
(reﬂected by an anomaly score close to one in the ﬁgures)
and only few instances deviate from the established proﬁles.
The graphs in Figure 3 and 4 quickly drop from above 90%
of ‘most normal’ instances in the last bin to values below 1%.
It can be seen that the data collected by the Google server
shows the highest variability (especially in the case of the at-
tribute length model). This is due to the fact that the Google
search string is included in the distribution. Naturally, this
string, which is provided by users via their web browsers to
issue Google search request, varies to a great extent.
5.2 Detection Effectiveness
This section analyzes the number of hits and false positives
raised during the operation of our tool.
To assess the number of false positives that can be ex-
pected when our system is deployed, the intrusion detection
system was run on our three data sets. For this experiment,
we assumed that the training data contained no real attacks.
Although the original log ﬁles showed a signiﬁcant number of
entries from Nimda or Code Red worm attacks, these queries
were excluded both from the model building and detection
process. Note, however, that this is due to the fact that
all three sites use the Apache HTTP server. This web server
fails to locate the targeted vulnerable program and thus, fails
execute it. As we only include queries that result from the in-
vocation of existing programs into the training and detection
process, these worm attacks were ignored.
The false positive rate can be easily calculated by divid-
ing the number of reported anomalous queries by the total
number of analyzed queries. It is shown for each data set in
Table 4.
The relative numbers of false positives are very similar for
all three sites, but the absolute numbers diﬀer tremendously,
reﬂecting the diﬀerent web server loads. Although almost
ﬁve thousand alerts per day for the Google server appears
to be a very high number at a ﬁrst glance, one has to take
into account that this is an initial result. The alerts are the
raw output produced by our system after a training phase
with parameters chosen for the university log ﬁles. One ap-
Data Set
Google
UCSB
TU Vienna
Structure (Attribute)
anomalous
normal
Token (Attribute)
normal
anomalous
Presence (Query)
normal
anomalous
Order (Query)
normal
anomalous
1,595,516
7,992
765,311
15,738
1
98
1,603,989
7,974
765,039
7,265
19
370
490,704
4,616
713,425
0
1
75
490,704
4,617
713,500
0
0
0
Table 3: Probability Values
l
s
e
u
a
V
e
u
b
i
r
t
t