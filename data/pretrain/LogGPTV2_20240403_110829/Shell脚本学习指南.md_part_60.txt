进一步依异常单词排序。
应支持用户可指定的后缓缩减，让单词列表保持在易于管理的大小。
在本节最后的例12-4中，我们会展示满足上述所有目标且微得更多、更完整的程序，由
于程序功能相当多，因此本节接下来会辅以简单文字来详述细节，并将程序分段以便说
明。
使用的测试输入文件包含了spel1手册页前几段的内容，程序执行结果大致如下：
S avk -f apell.awk teetfile
thier
或是指定长模式，则为：
S axk -f spell.awk == =verbose testfile
tostfile:7:tb1
testfile:7:egn
testfile:11:deroff
testf1le:12:nx
testfile:19:thier
testfile:19:ier
12.4.1介绍性注释
程序会从详尽的注释文字开始，不过在这里，我们仅展示介绍与语法部分：
实例简举的拼写检查程序，搭配用户可定文的异靠列表。
不过可以在命令行上覆盖该设置。
内置字典是由标准的UNIX排写字典列表构建而成。
#
+
语法：
www.TopSage.com
---
## Page 358
一第
346
：
[=suffixfilel=guffixfile2...][+dict1+dict2
yage.com
[strip][-verbose](file(n)]
12.4.2主体
程序的主体只有三行，也就是传统awk程序的：初始化、处理与报告：
sSGIN(initialize())
(spel1_check_1ine())
END
[report_exceptions()1
程序文件剩余部分的所有细节将交给字母顺序排列的函数处理，但在本节将以逻辑上的
顺序描述它。
12.4.3 initialize()
initialize（）函数处理程序的初始化工作。
变量NonWordChars里的正则表达式，是用以删除不想要的字符。与ASCII字母与撇号
一起，范围在161到255内的字符都被保留作为单词字符，所以ASC1I的文件、任何ISO
8859-n字符集及以UTF-8编码的Unicode，所有都能被处理面无须关心字符集。
128到160间的字符会被忽略，因为在这之间的所有字符集，都作为额外的控制字符与
一个无中断的空格。这些字符集里有部分其有一些在160以上的非字母字符，但使用它
们也增加了我们不想要的字符集依赖性，非字母字符是很少见的，即使有，在我们的程
序下，最坏的情况就是在拼写异常报告里偶尔会出现错误。
我们假定将进行拼写检查的文件，与其相关联的字典具有相同字符集编码。如果否，则
通过iconv，将它们转换为一致的编码。
如果所有的awk实例都遵循POSIX，则我们可以这么设置NonWordChars；
[[de].].=szeopzouo
之后，当前locale会决定应忽略哪些字符。不过这种指定方式不具可移植性，因为有很
多awk实现不支持POSIX风格的正则表达式：
在locale导人UNIX前，我们还是能够以否定单词字符集的方式，赋值给NonWordChars；
然而，在locale的出现下，正则表达式里字符范围是按照locale类型而被解释，所以其
值在各平台间的结果可能不一致。解决方式是改用明白地列举字符的方式，把赋值编写
www.TopSage.com
---
## Page 359
拼写检查
347
为连续的字符串，并适当地对齐，以利于人工迅遗识别否定字符集里的字符。我们使用
八进制表示127以上的值，因为这么微会比混杂重音字符要来得清楚许多，
initialize（）接下来会识别井载人字典，并处理命令行参数与后级规则。
function initialize()
ABCDEFGHIJKLANOPQRSTUVWXYZ*\
*abcdefghijkimnopqrstuvoryz*\
*\260261\262\263\264\265\266267,270271\272\27312741275276277*
*\300301\302303\304305306\30731031131231313141315316317*
*\3203211322132313243251326132713303311332\333133413351336337*
*\340 3411342134313441.345 34613471350\3511352\353135413551356357*
*\360\3611362136313641365\36613671,370\371\372137313741375\376\377*\
get_dictionaries()
load_dictionaries (1
() euoTndo"ueoe
load_suffixes [}
order_suffixes()
1
12.4.4 get_dictionaries()
get_dictionaries（）会填入默认系统字典的列表：我们提供的是两个方便取得的文件。
用户可以通过提供字典列表作为命令行变量Dictionaries的值，或直接使用
DICTIONARIES环境变量，而使得该默认选择失效。
如果Dictionaries为空，我们会查阅环境数组ENVIRON，并使用其内所设置的值，如
果这么做Dictionaries依然为空，我们就会提供一个内置列表。该列表的选择必须花
点心思，因为在不同的UNIX平台间会出现极大差异，而且在文件很小时，此程序所消
耗的大部分执行期时间是在载入字典。除此之外，Dictionaries应包含一个以空白分
隔的字典文件名列表，我们会将其切割，井存储在全局性DictionaryFiles数组里。这
里选择的单词列表是在我们某些系统里spel1所使用的单词列表（约25000条记录），
以及DonaldKnuth提供的一个较大型列表（约110 000条记录，注6）。
请留意字典名称是如何被存储的：它们是数组索引（indices），而非数组值（value），这
么设计的理由有二：第一，它可以自动处理提供字典超过一次以上的情况，只有文件名
的一个实体被存储：第二，它可易于使用for（keyinarray）循环，选代经过整个
字典列表。无须维护用于计算字典数目的变量。
注6：可从ftp://labrea.stanford.edu/pub/dict/words.gz取得。
www.TopSage.com
---
## Page 360
348
第12章
这是代码：
function get_dictionarfes(
‘files, key)
1f((Dictionarfes =± **)&&(*DICTIONARIES*in ENVIRON))
if (Dictionarles == **)
使用默认的字典列表
DictionaryFiles [*/usr/dict/vords*]++
DictionaryFiles [*/usr/1ocal/share/dict/words.knuth*]++
else
使用命令行提供的系统字典
split (Dictionaries, files)
for (key in tiles)
DictionaryPiles[files [key]]++
1
12.4.5 scan_options()
scan_options（）处理的是命令行。该函数预期会找到选项（-strip与/或-verbose）、
用户字典（以UNIXspel1传统的开头+指定）、后级规则文件（前置=标记）及要作
拼写检查的文件。任何的-v选项所设置的Dictionaries变量都已由awk处理，且不
在参数数组ARGV中。
7
scan_options（）里的最后一个语句得解释一下：在润试期润，我们发现如果ARGv结
尾处留有空参数时；nawk不会读取标唯输入，但gawk与mawk会。因此我们在ARGC上
减一，直到ARGV的结尾有一个非空的参数：
function scan_options(
k1
?
for (k = 1; k 0)
Dictionary[tolouer(word）]++
close (file)
12.4.7load_suffixes()
很多语言的单词都可以通过切开后缓，面被简化为更短的根单词（rootwords）。例如在
英文里，jumped、jumper、jumpers、jumpier、jumpiness，jumping、jumps及jumpy的
根单词都为jump.后有时也会改变单词的最终字母：try为rriable、trial、tried与trying
的根。如此，我们需要存储在字典里的基础单词集，就会比包含后缓的单词集小好几倍。
由于1/O与计算机计算比起来相对较慢，因此我们认为，在程序里处理后缓以缩短字典
大小，及减少异常列表里错误报告的数目，是值得付出的。
load_suffixes（）处理后缓规则的载人。不同于载人字典的是：我们在这里可能提供
内置的规则，而非从文件中读取。因此，我们保留数组里的记录数目的全局性计数，该
数组是保存后级规则的文件名。
www.TopSage.com
---
## Page 362
350
第12章
后缴规则会带有解释，且为了说明，我们呈现的是传统的英文规则，见例12-3。我们以
正则表达式匹配后级，每一个单词末端都带有$铺点（anchor）。当后级被截断时，则必
须提供一个替换后级，例如把rr+ied缩短成rr+y，且时常会有数种可能的替换。
例12-3：英文的后级规则：english.sfx
# Jones′ -> Jones
‘s$
ably$
able
# attably -> attable
1 bread, flamed -> flame
edly$
** e
# ashanedly -> ashaned
es$
# arches -> arch, blues -> blue
ggeds
je Y
5nqep  die, cried -> czy
Les$
1ly$
y ily
1e 1es y
# tidily -> tidy, vily > wily
# series -> geries, ties -> tie, flies -> fly
Ingly$
ing$
** Lng
 alarmingly -> alarming or alarm
junping -> jump
11ed$
1 “
# annu11ed => annu1
1y9
mn1ly$
 acutely -> acute
n
# funnily -> fun
pped$
# handicapped -> handicap
pp1ng$
P.
 dropping => drop
rreds
I
deferred -> defer
8$
tted$
# cats -> cat
 committed -> commit
因此，后缓规则的最简单规格是以正则表达式进行后级匹配，紧接着一个以空白字符分
隔的替换列表。因为可能的替换之一是空字符串，我们以“表示。如果它是唯一的替
换，那我们会省略它。英文是高度不规则且拥有大量外来语的语言，所以有许多后缓规
则，且绝对比我们在erglish.sfx里列的还多很多，不过后缓列表仅用于降低错误报告
的发生，因为它有效地延展字典大小、不会影响程序的正确运行。
为了便于人类管理后缓规则文件，其规则必须可使用注释扩展以提供它们的应用范例。
我们遵循一般UNIX的注释实例，也就是从#到行结尾都为注释，因此，1oad_
suffixes（）会截去注释与开头、结尾的空白字符，再丢奔空白行。留下来的是正则表达
式与零到多个替换的列表，用于其他地方可以调用awk内置的字符串替换函数sub（）。
该替换列表是以空白分隔的字符串被存储，可供我们稍候在其上应用split（）内置函
数。
后替换可使用&表示匹配文字，不过我们在english.Bfx中并未举出此功能的例子。
我们普考虑让load_suffixes（）提供正则表达式里的$锚点，但终究推翻这个想法，因
为这么可能会限制其他语言所要求的后缓匹配的规格，后缴规则文件必需时时刻刻投人
相当的关注，但这个工作只需要在每种语言里做一次就好。