# Anycast Latency: How Many Sites Are Enough?

## Abstract
This paper examines the relationship between the number of anycast sites and latency, using data from four real-world anycast deployments (C-, F-, K-, and L-Root DNS nameservers) with 7,900 RIPE Atlas probes. We collected new data for each service in 2015 and revisited K-Root in 2016 to evaluate changes in its routing policies. Our methodology allows us to compare actual latency to optimal possible latency, providing insights into how many anycast sites are sufficient for reasonable performance.

## 1. Introduction
We study the impact of the number of anycast sites on latency, using data from C-, F-, K-, and L-Root DNS nameservers. Our unique approach combines latency measurements to each probe's current site and all sites, enabling an evaluation of optimal possible latency. This paper presents our findings and provides recommendations for the number of anycast sites needed for reasonable latency.

## 2. Methodology
### 2.1 Data Collection
We used 7,900 RIPE Atlas probes to measure latency to the C-, F-, K-, and L-Root DNS nameservers. For each probe, we measured:
- Latency to the current anycast site.
- Latency to all available anycast sites.

### 2.2 Analysis
We analyzed the data to determine:
- Median latency across different numbers of anycast sites.
- The impact of geographic distribution and local interconnectivity.
- The effect of routing policies on latency.

## 3. Results
### 3.1 Median Latency
Our data shows that median latency is similar (about 30 ms) for 8 to 144 anycast sites. This suggests that as few as twelve geographically distributed sites can provide reasonable latency.

### 3.2 Geographic Distribution
Geographically distributed anycast sites can significantly improve latency for distant users. For example, adding U.S. west (LAX) and east (JFK) coasts, and Frankfurt (FRA), pulls the latency distribution closer to optimal, particularly in the tail.

### 3.3 Impact of Routing Policies
Restrictive local routing policies can add latency. Relaxing these policies could improve median latency. For instance, F-Root could reduce median latency from 37 ms to 19 ms, and K-Root from 43 ms to 25 ms by relaxing local routing policies.

### 3.4 Tail Performance
While many sites do not affect median latency, they help improve the tail of the distribution, from the 70th to the 90th percentiles. This is particularly evident in countries with at least 5 VPs.

### 3.5 Country-Specific Latency
Latency is highest for countries in Africa, Asia, Oceania, and South America. C-Root, with sites only in Europe and North America, shows high latency in these areas. L-Root, with global anycast sites, also shows high latency in some European countries due to routing policies.

### 3.6 Mishits and Local Routing
Mishits, where VPs do not hit the optimal site, are common. Restrictive local routing policies account for a significant portion of mishits. Relaxing these policies can improve performance, as seen in K-Root after changing most sites to global routing.

## 4. Related Work
Previous studies have examined DNS performance, focusing on latency and the impact of anycast. Our work builds on these studies but introduces a new methodology to compare actual and optimal latency, allowing for more detailed analysis of the effects of routing policies and the number of anycast sites.

## 5. Conclusions
Our data shows that as few as twelve geographically distributed anycast sites can provide reasonable latency, provided they have good local interconnectivity and effective DNS caching. We recommend careful examination and debugging of routing policies to maximize performance.

## Acknowledgments
We thank Geoﬀ Huston (APNIC), George Michaelson (APNIC), Ray Bellis (ISC), Cristian Hesselman (SIDN Labs), Benno Overeinder (NLnet Labs), Jaap Akkerhuis (NLnet Labs), Duane Wessels (Verisign), Paul Vixie (Farsight), Romeo Zwart (RIPE NCC), Anand Buddhdev (RIPE NCC), and operators from C Root for their technical feedback.

This research uses measurements from RIPE Atlas, operated by RIPE NCC. Ricardo Schmidt’s work is in the context of SAND (Self-managing Anycast Networks for the DNS: http://www.sand-project.nl) and DAS (DNS Anycast Security: http://www.das-project.nl) projects, sponsored by SIDN, NLnet Labs, and SURFnet. John Heidemann’s work is partially sponsored by the U.S. Dept. of Homeland Security (DHS) Science and Technology Directorate, HSARPA, Cyber Security Division, via SPAWAR Systems Center Pacific under Contract No. N66001-13-C-3001, and via BAA 11-01-RIKA and Air Force Research Laboratory, Information Directorate under agreement numbers FA8750-12-2-0344 and FA8750-15-2-0224. The U.S. Government is authorized to make reprints for governmental purposes notwithstanding any copyright. The views contained herein are those of the authors and do not necessarily represent those of DHS or the U.S. Government.

## References
1. Abley, J., Lindqvist, K.E.: Operation of Anycast Services. RFC 4786 (2006)
2. Akhtar, Z., Hussain, A., Katz-Bassett, E., Govindan, R.: DBit: assessing statistically significant differences in CDN performance. In: IFIP TMA (2016)
3. Bajpai, V., Eravuchira, S.J., Sch¨onw¨alder, J.: Lessons learned from using the RIPE atlas platform for measurement research. ACM CCR 45(3), 35–42 (2015)
4. Ballani, H., Francis, P.: Towards a global IP anycast service. In: ACM SIGCOMM, pp. 301–312 (2005)
5. Ballani, H., Francis, P., Ratnasamy, S.: A measurement-based deployment proposal for IP anycast. In: ACM IMC, pp. 231–244 (2006)
6. Bellis, R.: Researching F-root Anycast Placement Using RIPE Atlas (2015). https://labs.ripe.net/
7. Boothe, P., Bush, R.: Anycast Measurements Used to Highlight Routing Instabilities. NANOG 34 (2005)
8. Brownlee, N., Claﬀy, K.C., Nemeth, E.: DNS Root/gTLD performance measurement. In: USENIX LISA, pp. 241–255 (2001)
9. Brownlee, N., Ziedins, I.: Response time distributions for global name servers. In: PAM (2002)
10. Bush, R.: DNS anycast stability: some initial results. In: CAIDA/WIDE Workshop (2005)
11. CAIDA. Skitter. http://www.caida.org/tools/measurement/skitter/
12. Calder, M., Fan, X., Hu, Z., Katz-Bassett, E., Heidemann, J., Govindan, R.: Mapping the expansion of Google’s serving infrastructure. In: ACM IMC, pp. 313–326 (2013)
13. Calder, M., Flavel, A., Katz-Bassett, E., Mahajan, R., Padhye, J.: Analyzing the performance of an anycast CDN. In: ACM IMC, pp. 531–537 (2015)
14. Castro, S., Wessels, D., Fomenkov, M., Claﬀy, K.: A day at the root of the internet. ACM CCR 38(5), 41–46 (2008)
15. Cicalese, D., Aug´e, J., Joumblatt, D., Friedman, T., Rossi, D.: Characterizing IPv4 anycast adoption and deployment. In: ACM CoNEXT (2015)
16. Cicalese, D., Joumblatt, D., Rossi, D., Buob, M.-O., Aug´e, J., Friedman, T.: A fistful of pings: accurate and lightweight anycast enumeration and geolocation. In: IEEE INFOCOM, pp. 2776–2784 (2015)
17. Colitti, L.: Effect of anycast on K-root. In: 1st DNS-OARC Workshop (2005)
18. DNS Root Servers. http://www.root-servers.org/
19. Fan, X., Heidemann, J., Govindan, R.: Evaluating anycast in the domain name system. In: IEEE INFOCOM, pp. 1681–1689 (2013)
20. Fan, X., Katz-Bassett, E., Heidemann, J.: Assessing affinity between users and CDN sites. In: Steiner, M., Barlet-Ros, P., Bonaventure, O. (eds.) TMA 2015. LNCS, vol. 9053, pp. 95–110. Springer, Heidelberg (2015). doi:10.1007/978-3-319-17172-2 7
21. Fomenkov, M., Claﬀy, K.C., Huﬀaker, B., Moore, D.: Macroscopic internet topology and performance measurements from the DNS root name servers. In: USENIX LISA, pp. 231–240 (2001)
22. Google Public DNS. https://developers.google.com/speed/public-dns/
23. Kuipers, J.H.: Analysing the K-root anycast infrastructure (2015). https://labs.ripe.net/
24. Lee, B.-S., Tan, Y.S., Sekiya, Y., Narishige, A., Date, S.: Availability and effectiveness of root DNS servers: a long term study. In: IFIP/IEEE NOMS, pp. 862–865 (2010)
25. Lee, T., Huﬀaker, B., Fomenkov, M., Claﬀy, K.C.: On the problem of optimization of DNS root servers’ placement. In: PAM (2003)
26. Liang, J., Jiang, J., Duan, H., Li, K., Wu, J.: Measuring query latency of top level DNS servers. In: Roughan, M., Chang, R. (eds.) PAM 2013. LNCS, vol. 7799, pp. 145–154. Springer, Heidelberg (2013). doi:10.1007/978-3-642-36516-4 15
27. Liu, Z., Huﬀaker, B., Fomenkov, M., Brownlee, N., Claﬀy, K.C.: Two days in the life of the DNS anycast root servers. In: Uhlig, S., Papagiannaki, K., Bonaventure, O. (eds.) PAM 2007. LNCS, vol. 4427, pp. 125–134. Springer, Heidelberg (2007). doi:10.1007/978-3-540-71617-4 13
28. Palsson, B., Kumar, P., Jaﬀeralli, S., Kahn, Z.A.: TCP over IP anycast - pipe dream or reality? (2015). https://engineering.linkedin.com/
29. Pang, J., Hendricks, J., Akella, A., Prisco, R.D., Maggs, B., Seshan, S.: Availability, usage, and deployment characteristics of the domain name server. In: ACM IMC, pp. 1–14 (2004)
30. Partridge, C., Mendez, T., Milliken, W.: Host Anycasting Service. RFC 1546 (1993)
31. RIPE NCC. Dnsmon (2015). https://atlas.ripe.net/dnsmon/
32. RIPE NCC Staff: RIPE Atlas: a global Internet measurement network. Internet Protocol J. 18(3), 2–26 (2015)
33. Rootops. Events of 2015–11-30. Technical report, Root Server Operators (2015)
34. Sarat, S., Pappas, V., Terzis, A.: On the use of anycast in DNS. In: ICCCN, pp. 71–78 (2006)
35. Schmidt, R.d.O., Heidemann, J., Kuipers, J.H.: Anycast latency: how many sites are enough? Technical report ISI-TR-2016-708, USC-ISI, May 2016
36. Spring, N., Mahajan, R., Anderson, T.: Quantifying the causes of path inflation. In: ACM SIGCOMM, pp. 113–124 (2003)
37. Streibelt, F., B¨ottger, J., Chatzis, N., Smaragdakis, G., Feldman, A.: Exploring EDNS-client-subnet adopters in your free time. In: ACM IMC, pp. 305–312 (2013)
38. Toonk, A.: How OpenDNS achieves high availability with anycast routing (2013). https://labs.opendns.com/
39. Woolf, S., Conrad, D.: Requirements for a Mechanism Identifying a Name Server Instance. RFC 4892 (2007)