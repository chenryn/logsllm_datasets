## 多流实时聚合 - 记录级实时快照 - JSON聚合与json全文检索的功能应用   
### 作者                          
digoal                          
### 日期                          
2017-12-09                        
### 标签                          
PostgreSQL , 写时合并 , 记录级快照 , json , json索引 , json聚合 , 圈选 , 并行计算    
----                          
## 背景      
这个需求是这样的，数据在写入时，以上一条记录作为基础，将当前写入的记录与上一条记录合并，然后作为新的记录写进去。  
从而每一条记录都携带了之前所有记录的内容。  
当然这里指的是每个维度各自的快照，并不是一张表所有记录的快照。  
例如，一笔电商订单，可能经过若干个系统（每个系统产生的属性可能都不一样，多个系统合起来就是个大宽表，应用为了设计简单，往往可能选择JSON存储，而不是大宽表），产生若干笔记录，每次写入时期望将之前与之相关的记录内容都合并起来，产生新的值写入。  
但是不要忘记，同一笔订单的数据，可能存在并行写入（除非业务上能将订单编号按哈希让一个线程来处理它，而且不能多机）。当存在并发写同一笔订单时，写时合并就违反自然规律。  
例子：  
```  
tbl已有记录 (0, 1, 'test0', now())  
session A:  
insert into tbl (pk, caseid, info, crt_time) values (1, 1, 'test1', now());  
session B:  
insert into tbl (pk, caseid, info, crt_time) values (2, 1, 'test2', now());  
如果SESSION A,B同时发起，那么写入的记录可能变成：  
(1, 1, 'test0_test1', now());  
(2, 1, 'test0_test2', now());  
然而实际上要的可能是这两条  
(1, 1, 'test0_test1', now());  
(2, 1, 'test0_test1_test2', now());  
```  
类似区块链。   
所以，我们使用另一种方法来获取快照，写入时，不改变原始的写入方法，即各个业务线产生的订单记录，分别写入到一个单表，使用JSON来表示各个业务线对这个订单的描述。  
## JSON写入性能  
```  
create table tbl_ord (  
  ordid int8,   -- 订单号  
  appid  int,   -- 应用ID  
  info jsonb,   -- 内容  
  crt_time timestamp  -- 写入时间  
);  
create index idx_tbl_ord on tbl_ord(ordid, crt_time);  
```  
单条写入压测  
```  
vi test.sql  
\set ordid random(1,10000000)  
\set appid random(1,10)  
insert into tbl_ord (ordid,appid,info,crt_time) values (:ordid,:appid,jsonb '{"a" : 1, "b" : 2}',now());  
pgbench -M prepared -n -r -P 1 -f ./test.sql -c 40 -j 40 -t 2500000  
```  
**单条写入压测，23.4万行/s。**  
```  
transaction type: ./test.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 40  
number of threads: 40  
number of transactions per client: 2500000  
number of transactions actually processed: 100000000/100000000  
latency average = 0.170 ms  
latency stddev = 0.498 ms  
tps = 234047.009786 (including connections establishing)  
tps = 234060.902533 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.001  \set ordid random(1,10000000)  
         0.001  \set appid random(1,10)  
         0.168  insert into tbl_ord (ordid,appid,info,crt_time) values (:ordid,:appid,jsonb '{"a" : 1, "b" : 2}',now());  
```  
**如果使用批量写入，可以达到100万+行/s。**    
## JSON全字段索引  
PostgreSQL 支持JSON类型的全字段索引，支持两种operator class，支持的检索如下。  
```  
GIN indexes can be used to efficiently search for keys or key/value pairs occurring within   
a large number of jsonb documents (datums).   
Two GIN “operator classes” are provided, offering different performance and flexibility trade-offs.  
The default GIN operator class for jsonb supports queries with top-level key-exists operators   
?, ?& and ?| operators and path/value-exists operator @>.   
(For details of the semantics that these operators implement,   
see Table 9.44.) An example of creating an index with this operator class is:  
CREATE INDEX idxgin ON api USING GIN (jdoc);  
The non-default GIN operator class jsonb_path_ops supports indexing the @> operator only.   
An example of creating an index with this operator class is:  
CREATE INDEX idxginp ON api USING GIN (jdoc jsonb_path_ops);  
```  
```  
create index idx_tbl_ord_2 on tbl_ord using gin (info);  
```  
使用举例  
```  
-- Find documents in which the key "company" has value "Magnafone"  
SELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @> '{"company": "Magnafone"}';  
-- Find documents in which the key "tags" contains key or array element "qui"  
SELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc -> 'tags' ? 'qui';  
-- Find documents in which the key "tags" contains array element "qui"  
SELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @> '{"tags": ["qui"]}';  
```  
## 点查，json聚合，得任意时间快照  
取某个时间点，某个caseid的快照，使用JSONB聚合，性能贼好。  
将所有记录聚合成一条  
```  
select caseid, jsonb_agg((pk,info,crt_time) order by crt_time) from tbl where caseid=? and crt_time<=? group by caseid;  
```  
jsonb_agg用法举例  
```  
postgres=# create type typ1 as (c1 int, c2 int);  
CREATE TYPE  
postgres=# select jsonb_agg((c1,c2)::typ1 order by c1 desc) from (values (1,2),(2,3)) t(c1,c2);  
                jsonb_agg                   
------------------------------------------  
 [{"c1": 2, "c2": 3}, {"c1": 1, "c2": 2}]  
(1 row)  
```  
按订单的聚合查询性能：  
**0.7毫秒**  
```  
create type typ2 as (appid int, info jsonb, crt_time timestamp);  
postgres=# select ordid, jsonb_agg((appid,info,crt_time)::typ2 order by crt_time) from tbl_ord where ordid=1 and crt_time<=now() group by ordid;  
-[ RECORD 1 ]----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
ordid     | 1  
jsonb_agg | [{"info": {"a": 1, "b": 2}, "appid": 6, "crt_time": "2017-12-09T23:24:56.659672"}, {"info": {"a": 1, "b": 2}, "appid": 5, "crt_time": "2017-12-09T23:25:13.073163"}, {"info": {"a": 1, "b": 2}, "appid": 6, "crt_time": "2017-12-09T23:25:49.94649"}, {"info": {"a": 1, "b": 2}, "appid": 10, "crt_time": "2017-12-09T23:26:23.523946"}, {"info": {"a": 1, "b": 2}, "appid": 2, "crt_time": "2017-12-09T23:26:49.900199"}, {"info": {"a": 1, "b": 2}, "appid": 7, "crt_time": "2017-12-09T23:27:10.643058"}, {"info": {"a": 1, "b": 2}, "appid": 8, "crt_time": "2017-12-09T23:27:20.937021"}, {"info": {"a": 1, "b": 2}, "appid": 8, "crt_time": "2017-12-09T23:27:21.446752"}, {"info": {"a": 1, "b": 2}, "appid": 6, "crt_time": "2017-12-09T23:29:19.10536"}, {"info": {"a": 1, "b": 2}, "appid": 7, "crt_time": "2017-12-09T23:29:56.192353"}, {"info": {"a": 1, "b": 2}, "appid": 1, "crt_time": "2017-12-09T23:30:07.879201"}, {"info": {"a": 1, "b": 2}, "appid": 6, "crt_time": "2017-12-09T23:30:31.487457"}]  
Time: 0.696 ms  
```  
压测  
```  
vi test.sql  
\set ordid random(1,10000000)  
select ordid, jsonb_agg((appid,info,crt_time)::typ2 order by crt_time) from tbl_ord where ordid=:ordid and crt_time<=now() group by ordid;  
```  
结果  
```  
pgbench -M prepared -n -r -P 1 -f ./test.sql -c 28 -j 28 -T 120  
transaction type: ./test.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 28  
number of threads: 28  
duration: 120 s  
number of transactions actually processed: 4677282  