I 
Changes are rolled back (undone) if the associated transaction is rolled back, if the machine
crashes, or if the volume is forcibly dismounted.
I 
Changes are flushed to disk if the associated transaction is committed.
Transactional APIs
TxF implements transacted versions of the Windows file I/O APIs, which use the suffix Transacted:
I 
Create APIs
CreateDirectoryTransacted, CreateFileTransacted, CreateHardLinkTransacted,
CreateSymbolicLinkTransacted
I 
Find APIs
FindFirstFileNameTransacted, FindFirstFileTransacted, FindFirstStreamTransacted
I 
Query APIs
GetCompressedFileSizeTransacted, GetFileAttributesTransacted,
GetFullPathNameTransacted, GetLongPathNameTransacted
I 
Delete APIs
DeleteFileTransacted, RemoveDirectoryTransacted
I 
Copy and Move/Rename APIs
CopyFileTransacted, MoveFileTransacted
I 
Set APIs
SetFileAttributesTransacted
In addition, some APIs automatically participate in transacted operations when the file handle they 
are passed is part of a transaction, like one created by the CreateFileTransacted API. Table 11-10 lists 
Windows APIs that have modified behavior when dealing with a transacted file handle.
TABLE 11-10 API behavior changed by TxF
API Name
Change
CloseHandle
Transactions aren’t committed until all applications close transacted 
handles to the file.
CreateFileMapping, MapViewOfFile
Modifications to mapped views of a file part of a transaction are associ-
ated with the transaction themselves.
FindNextFile, ReadDirectoryChanges,
GetInformationByHandle, GetFileSize
If the file handle is part of a transaction, read-isolation rules are applied 
to these operations.
GetVolumeInformation
Function returns FILE_SUPPORTS_TRANSACTIONS if the volume sup-
ports TxF.
ReadFile, WriteFile
Read and write operations to a transacted file handle are part of the 
transaction.
SetFileInformationByHandle
Changes to the FileBasicInfo, FileRenameInfo, FileAllocationInfo,
FileEndOfFileInfo, and FileDispositionInfo classes are transacted if the file 
handle is part of a transaction.
SetEndOfFile, SetFileShortName, SetFileTime
Changes are transacted if the file handle is part of a transaction.
CHAPTER 11
Caching and file systems
691
On-disk implementation
As shown earlier in Table 11-7, TxF uses the LOGGED_UTILITY_STREAM attribute type to store addi-
tional data for files and directories that are or have been part of a transaction. This attribute is called 
TXF_DATA and contains important information that allows TxF to keep active offline data for a file part 
of a transaction. The attribute is permanently stored in the MFT; that is, even after the file is no longer 
part of a transaction, the stream remains, for reasons explained soon. The major components of the 
attribute are shown in Figure 11-55.
File record number of RM root
Flags
TxF file ID (TxID)
LSN for NTFS metadata
LSN for user data
LSN for directory index
USN index
FIGURE 11-55 TXF_DATA attribute.
The first field shown is the file record number of the root of the resource manager responsible for 
the transaction associated with this file. For the default resource manager, the file record number is 5, 
which is the file record number for the root directory (\) in the MFT, as shown earlier in Figure 11-31. 
TxF needs this information when it creates an FCB for the file so that it can link it to the correct resource 
manager, which in turn needs to create an enlistment for the transaction when a transacted file request 
is received by NTFS.
Another important piece of data stored in the TXF_DATA attribute is the TxF file ID, or TxID, and 
this explains why TXF_DATA attributes are never deleted. Because NTFS writes file names to its records 
when writing to the transaction log, it needs a way to uniquely identify files in the same directory 
that may have had the same name. For example, if sample.txt is deleted from a directory in a transac-
tion and later a new file with the same name is created in the same directory (and as part of the same 
transaction), TxF needs a way to uniquely identify the two instances of sample.txt. This identification is 
provided by a 64-bit unique number, the TxID, that TxF increments when a new file (or an instance of 
a file) becomes part of a transaction. Because they can never be reused, TxIDs are permanent, so the 
TXF_DATA attribute will never be removed from a file.
Last but not least, three CLFS (Common Logging File System) LSNs are stored for each file part of a 
transaction. Whenever a transaction is active, such as during create, rename, or write operations, TxF 
writes a log record to its CLFS log. Each record is assigned an LSN, and that LSN gets written to the 
appropriate field in the TXF_DATA attribute. The first LSN is used to store the log record that identifies 
the changes to NTFS metadata in relation to this file. For example, if the standard attributes of a file are 
changed as part of a transacted operation, TxF must update the relevant MFT file record, and the LSN 
for the log record describing the change is stored. TxF uses the second LSN when the file’s data is modi-
fied. Finally, TxF uses the third LSN when the file name index for the directory requires a change related 
to a transaction the file took part in, or when a directory was part of a transaction and received a TxID.
692
CHAPTER 11
Caching and file systems
The TXF_DATA attribute also stores internal flags that describe the state information to TxF and the 
index of the USN record that was applied to the file on commit. A TxF transaction can span multiple 
USN records that may have been partly updated by NTFS’s recovery mechanism (described shortly), so 
the index tells TxF how many more USN records must be applied after a recovery.
TxF uses a default resource manager, one for each volume, to keep track of its transactional state. 
TxF, however, also supports additional resource managers called secondary resource managers. These 
resource managers can be defined by application writers and have their metadata located in any 
directory of the application’s choosing, defining their own transactional work units for undo, backup, 
restore, and redo operations. Both the default resource manager and secondary resource managers 
contain a number of metadata files and directories that describe their current state:
I 
The Txf directory, located into Extend\RmMetadata directory, which is where files are linked
when they are deleted or overwritten by transactional operations.
I 
The Tops, or TxF Old Page Stream (TOPS) file, which contains a default data stream and an al-
ternate data stream called T. The default stream for the TOPS file contains metadata about the
resource manager, such as its GUID, its CLFS log policy, and the LSN at which recovery should
start. The T stream contains file data that is partially overwritten by a transactional writer (as
opposed to a full overwrite, which would move the file into the Txf directory).
I 
The TxF log files, which are CLFS log files storing transaction records. For the default resource
manager, these files are part of the TxfLog directory, but secondary resource managers can
store them anywhere. TxF uses a multiplexed base log file called TxfLog.blf. The file \Extend
\RmMetadata\TxfLog\TxfLog contains two streams: the KtmLog stream used for Kernel
Transaction Manager metadata records, and the TxfLog stream, which contains the TxF
log records.
EXPERIMENT: Querying resource manager information
You can use the built-in Fsutil.exe command-line program to query information about the 
default resource manager as well as to create, start, and stop secondary resource managers and 
configure their logging policies and behaviors. The following command queries information 
about the default resource manager, which is identified by the root directory (\):
d:\>fsutil resource info \ 
Resource Manager Identifier :      81E83020-E6FB-11E8-B862-D89EF33A38A7 
KTM Log Path for RM:  \Device\HarddiskVolume8\$Extend\$RmMetadata\$TxfLog\$TxfLog::KtmLog 
Space used by TOPS:   1 Mb 
TOPS free space:      100% 
RM State:             Active 
Running transactions: 0 
One phase commits:    0 
Two phase commits:    0 
System initiated rollbacks: 0 
Age of oldest transaction:  00:00:00 
Logging Mode:         Simple 
Number of containers: 2 
EXPERIMENT: Querying resource manager information
You can use the built-in Fsutil.exe command-line program to query information about the 
default resource manager as well as to create, start, and stop secondary resource managers and 
configure their logging policies and behaviors. The following command queries information 
about the default resource manager, which is identified by the root directory (\):
d:\>fsutil resource info \
Resource Manager Identifier :      81E83020-E6FB-11E8-B862-D89EF33A38A7
KTM Log Path for RM:  \Device\HarddiskVolume8\$Extend\$RmMetadata\$TxfLog\$TxfLog::KtmLog
Space used by TOPS:   1 Mb
TOPS free space:      100%
RM State:             Active
Running transactions: 0
One phase commits:    0
Two phase commits:    0
System initiated rollbacks: 0
Age of oldest transaction:  00:00:00
Logging Mode:         Simple
Number of containers: 2
CHAPTER 11
Caching and file systems
693
Container size:
10 Mb 
Total log capacity:   20 Mb 
Total free log space: 19 Mb 
Minimum containers:   2 
Maximum containers:   20 
Log growth increment: 2 container(s) 
Auto shrink:
Not enabled 
RM prefers availability over consistency.
As mentioned, the fsutil resource command has many options for configuring TxF resource 
managers, including the ability to create a secondary resource manager in any directory of your 
choice. For example, you can use the fsutil resource create c:\rmtest command to create a 
secondary resource manager in the Rmtest directory, followed by the fsutil resource start 
c:\rmtest command to initiate it. Note the presence of the Tops and TxfLogContainer files 
and of the TxfLog and Txf directories in this folder.
Logging implementation
As mentioned earlier, each time a change is made to the disk because of an ongoing transaction, TxF 
writes a record of the change to its log. TxF uses a variety of log record types to keep track of trans-
actional changes, but regardless of the record type, all TxF log records have a generic header that 
contains information identifying the type of the record, the action related to the record, the TxID that 
the record applies to, and the GUID of the KTM transaction that the record is associated with.
A redo record specifies how to reapply a change part of a transaction that’s already been committed 
to the volume if the transaction has actually never been flushed from cache to disk. An undo record, on 
the other hand, specifies how to reverse a change part of a transaction that hasn’t been committed at 
the time of a rollback. Some records are redo-only, meaning they don’t contain any equivalent undo 
data, whereas other records contain both redo and undo information.
Through the TOPS file, TxF maintains two critical pieces of data, the base LSN and the restart LSN.
The base LSN determines the LSN of the first valid record in the log, while the restart LSN indicates 
at which LSN recovery should begin when starting the resource manager. When TxF writes a restart 
record, it updates these two values, indicating that changes have been made to the volume and flushed 
out to disk—meaning that the file system is fully consistent up to the new restart LSN.
TxF also writes compensating log records or CLRs. These records store the actions that are being 
performed during transaction rollback. They’re primarily used to store the undo-next LSN which allows 
the recovery process to avoid repeated undo operations by bypassing undo records that have already 
been processed, a situation that can happen if the system fails during the recovery phase and has 
already performed part of the undo pass. Finally, TxF also deals with prepare records, abort records and 
commit records which describe the state of the KTM transactions related to TxF.
Container size:
10 Mb
Total log capacity:   20 Mb
Total free log space: 19 Mb
Minimum containers:   2
Maximum containers:   20
Log growth increment: 2 container(s)
Auto shrink:
Not enabled
RM prefers availability over consistency.
As mentioned, the fsutil resource command has many options for configuring TxF resource 
managers, including the ability to create a secondary resource manager in any directory of your 
choice. For example, you can use the fsutil resource create c:\rmtest command to create a 
secondary resource manager in the Rmtest directory, followed by the fsutil resource start 
c:\rmtest command to initiate it. Note the presence of the Tops and TxfLogContainer files 
and of the TxfLog and Txf directories in this folder.
694
CHAPTER 11
Caching and file systems
NTFS recovery support
NTFS recovery support ensures that if a power failure or a system failure occurs, no file system opera-
tions (transactions) will be left incomplete, and the structure of the disk volume will remain intact 
without the need to run a disk repair utility. The NTFS Chkdsk utility is used to repair catastrophic disk 
corruption caused by I/O errors (bad disk sectors, electrical anomalies, or disk failures, for example) or 
software bugs. But with the NTFS recovery capabilities in place, Chkdsk is rarely needed.
As mentioned earlier (in the section “Recoverability”), NTFS uses a transaction-processing scheme to 
implement recoverability. This strategy ensures a full disk recovery that is also extremely fast (on the order 
of seconds) for even the largest disks. NTFS limits its recovery procedures to file system data to ensure 
that at the very least the user will never lose a volume because of a corrupted file system; however, unless 
an application takes specific action (such as flushing cached files to disk), NTFS’s recovery support doesn’t 
guarantee user data to be fully updated if a crash occurs. This is the job of transactional NTFS (TxF).
The following sections detail the transaction-logging scheme NTFS uses to record modifications to 
file system data structures and explain how NTFS recovers a volume if the system fails.
Design
NTFS implements the design of a recoverable file system. These file systems ensure volume consistency by 
using logging techniques (sometimes called ournaling) originally developed for transaction processing. 
If the operating system crashes, the recoverable file system restores consistency by executing a recovery 
procedure that accesses information that has been stored in a log file. Because the file system has logged 
its disk writes, the recovery procedure takes only seconds, regardless of the size of the volume (unlike 
in the FAT file system, where the repair time is related to the volume size). The recovery procedure for a 
recoverable file system is exact, guaranteeing that the volume will be restored to a consistent state.
A recoverable file system incurs some costs for the safety it provides. Every transaction that alters the 
volume structure requires that one record be written to the log file for each of the transaction’s sub-
operations. This logging overhead is ameliorated by the file system’s batching of log records—writing 
many records to the log file in a single I/O operation. In addition, the recoverable file system can employ 
the optimization techniques of a lazy write file system. It can even increase the length of the intervals 
between cache flushes because the file system metadata can be recovered if the system crashes before 
the cache changes have been flushed to disk. This gain over the caching performance of lazy write file 
systems makes up for, and often exceeds, the overhead of the recoverable file system’s logging activity.
Neither careful write nor lazy write file systems guarantee protection of user file data. If the system 
crashes while an application is writing a file, the file can be lost or corrupted. Worse, the crash can cor-
rupt a lazy write file system, destroying existing files or even rendering an entire volume inaccessible.
The NTFS recoverable file system implements several strategies that improve its reliability over that 
of the traditional file systems. First, NTFS recoverability guarantees that the volume structure won’t 
be corrupted, so all files will remain accessible after a system failure. Second, although NTFS doesn’t 
guarantee protection of user data in the event of a system crash—some changes can be lost from the 
CHAPTER 11
Caching and file systems
695
cache—applications can take advantage of the NTFS write-through and cache-flushing capabilities to 
ensure that file modifications are recorded on disk at appropriate intervals.
Both cache write-through—forcing write operations to be immediately recorded on disk—and 
cache ushing—forcing cache contents to be written to disk—are efficient operations. NTFS doesn’t 
have to do extra disk I/O to flush modifications to several different file system data structures because 
changes to the data structures are recorded—in a single write operation—in the log file; if a fail-
ure occurs and cache contents are lost, the file system modifications can be recovered from the log. 
Furthermore, unlike the FAT file system, NTFS guarantees that user data will be consistent and available 
immediately after a write-through operation or a cache flush, even if the system subsequently fails.
Metadata logging
NTFS provides file system recoverability by using the same logging technique used by TxF, which consists 
of recording all operations that modify file system metadata to a log file. Unlike TxF, however, NTFS’s 
built-in file system recovery support doesn’t make use of CLFS but uses an internal logging implemen-
tation called the log file service (which is not a background service process as described in Chapter 10). 
Another difference is that while TxF is used only when callers opt in for transacted operations, NTFS re-
cords all metadata changes so that the file system can be made consistent in the face of a system failure.
Log file service
The log file service (LFS) is a series of kernel-mode routines inside the NTFS driver that NTFS uses to 
access the log file. NTFS passes the LFS a pointer to an open file object, which specifies a log file to be 
accessed. The LFS either initializes a new log file or calls the Windows cache manager to access the ex-
isting log file through the cache, as shown in Figure 11-56. Note that although LFS and CLFS have similar 
sounding names, they’re separate logging implementations used for different purposes, although their 
operation is similar in many ways.
Log file
service
Flush the
log file
Read/write/flush
the log file
Log the transaction
Write the
volume updates
NTFS driver
…
I/O manager