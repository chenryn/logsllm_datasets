title:LAVA: Large-Scale Automated Vulnerability Addition
author:Brendan Dolan-Gavitt and
Patrick Hulin and
Engin Kirda and
Tim Leek and
Andrea Mambretti and
William K. Robertson and
Frederick Ulrich and
Ryan Whelan
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
LAVA: Large-scale Automated Vulnerability
Addition
Brendan Dolan-Gavitt∗, Patrick Hulin†, Engin Kirda‡, Tim Leek†, Andrea Mambretti‡,
Wil Robertson‡, Frederick Ulrich†, Ryan Whelan†
(Authors listed alphabetically)
∗New York University
PI:EMAIL
†MIT Lincoln Laboratory
‡Northeastern University
{ek, mbr, wkr}@ccs.neu.edu
{patrick.hulin, tleek, frederick.ulrich, rwhelan}@ll.mit.edu
Abstract—Work on automating vulnerability discovery has
long been hampered by a shortage of ground-truth corpora with
which to evaluate tools and techniques. This lack of ground truth
prevents authors and users of tools alike from being able to
measure such fundamental quantities as miss and false alarm
rates. In this paper, we present LAVA, a novel dynamic taint
analysis-based technique for producing ground-truth corpora by
quickly and automatically injecting large numbers of realistic
bugs into program source code. Every LAVA bug is accompa-
nied by an input that triggers it whereas normal inputs are
extremely unlikely to do so. These vulnerabilities are synthetic
but, we argue, still realistic, in the sense that they are embedded
deep within programs and are triggered by real inputs. Using
LAVA, we have injected thousands of bugs into eight real-world
programs, including bash, tshark, and the GNU coreutils. In a
preliminary evaluation, we found that a prominent fuzzer and
a symbolic execution-based bug ﬁnder were able to locate some
but not all LAVA-injected bugs, and that interesting patterns
and pathologies were already apparent in their performance. Our
work forms the basis of an approach for generating large ground-
truth vulnerability corpora on demand, enabling rigorous tool
evaluation and providing a high-quality target for tool developers.
I. MOTIVATION
Bug-ﬁnding tools have been an active area of research for
almost as long as computer programs have existed. Techniques
such as abstract interpretation, fuzzing, and symbolic execu-
tion with constraint solving have been proposed, developed,
and applied. But evaluation has been a problem, as ground
truth is in extremely short supply. Vulnerability corpora ex-
ist [10] but they are of limited utility and quantity. These
corpora fall into two categories: historic and synthetic. Corpora
built from historic vulnerabilities contain too few examples to
be of much use [27]. However, these are closest to what we
want to have since the bugs are embedded in real code, use real
This work is sponsored by the Assistant Secretary of Defense for Re-
search & Engineering under Air Force Contract #FA8721-05-C-0002 and/or
#FA8702-15-D-0001. Opinions, interpretations, conclusions and recommenda-
tions are those of the author and are not necessarily endorsed by the United
States Government.
inputs, and are often well annotated with precise information
about where the bug manifests itself.
Creating such a corpus is a difﬁcult and lengthy process;
according to the authors of prior work on bug-ﬁnding tool
evaluation, a corpus of fourteen very well annotated historic
bugs with triggering inputs took about six months to con-
struct [26]. In addition, public corpora have the disadvantage
of already being released, and thus rapidly become stale; as
we can expect tools to have been trained to detect bugs that
have been released. Given the commercial price tag of new
exploitable bugs, which is widely understood to begin in the
mid ﬁve ﬁgures [20], it is hard to ﬁnd real bugs for our corpus
that have not already been used to train tools. And while
synthetic code stocked with bugs auto-generated by scripts
can provide large numbers of diagnostic examples, each is
only a tiny program and the constructions are often considered
unrepresentative of real code [2], [11].
In practice, a vulnerability discovery tool is typically evalu-
ated by running it and seeing what it ﬁnds. Thus, one technique
is judged superior if it ﬁnds more bugs than another. While this
state of affairs is perfectly understandable, given the scarcity
of ground truth, it is an obstacle to science and progress in
vulnerability discovery. There is currently no way to measure
fundamental ﬁgures of merit such as miss and false alarm rate
for a bug ﬁnding tool.
We propose the following requirements for bugs in a vulner-
ability corpus, if it is to be useful for research, development,
and evaluation. Bugs must
1) Be cheap and plentiful
2) Span the execution lifetime of a program
3) Be embedded in representative control and data ﬂow
4) Come with an input that serves as an existence proof
5) Manifest for a very small fraction of possible inputs
The ﬁrst requirement, if we can meet it, is highly desirable
since it enables frequent evaluation and hill climbing. Corpora
are more valuable if they are essentially disposable. The
second and third of these requirements stipulate that bugs must
2375-1207/16 $31.00 © 2016 IEEE
© 2016, Brendan Dolan-Gavitt. Under license to IEEE.
DOI 10.1109/SP.2016.15
DOI 10.1109/SP.2016.15
110
110
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:15:56 UTC from IEEE Xplore.  Restrictions apply. 
be realistic. The fourth means the bug is demonstrable and
serious, and is a precondition for determining exploitability.
The ﬁfth requirement is crucial. Consider the converse: if
a bug manifests for a large fraction of inputs it is trivially
discoverable by simply running the program.
The approach we propose is to create a synthetic vul-
nerability via a few judicious and automated edits to the
source code of a real program. We will detail and give results
for an implementation of this approach that satisﬁes all of
the above requirements, which we call LAVA (Large-scale
Automated Vulnerability Addition). A serious bug such as
a buffer overﬂow can be injected by LAVA into a program
like file, which is 13K LOC, in about 15 seconds. LAVA
bugs manifest all along the execution trace, in all parts of the
program, shallow and deep, and make use of normal data ﬂow.
By construction, a LAVA bug comes with an input that triggers
it, and we can guarantee that no other input can trigger the
bug.
II. SCOPE
We restrict our attention, with LAVA, to the injection of
bugs into source code. This makes sense given our interest
in using it
to assemble large corpora for the purpose of
evaluating and developing vulnerability discovery techniques
and systems. Automated bug discovery systems can work
on source code [1], [8], [9], [24] or on binaries [3], [21];
we can easily test binary analysis tools by simply compiling
the modiﬁed source. Injecting bugs into binaries or bytecode
directly may also be possible using an approach similar to
ours, but we do not consider that problem here. We further
narrow our focus to Linux open-source software written in
C, due to the availability of source code and source rewriting
tools. As we detail later, a similar approach will work for other
languages.
We want the injected bugs to be serious ones, i.e., potentially
exploitable. As a convenient proxy, our current focus is on
injecting code that can result
in out-of-bounds reads and
writes that can be triggered by an attacker-controlled input;
in Section VIII we consider extensions to LAVA to support
other bug classes. We produce a proof-of-concept input to
trigger any bug we successfully inject, although we do not
attempt to produce an actual exploit.
For the sake of brevity, in this paper we will use the words
bug and vulnerability interchangeably. In both cases, what we
mean is vulnerabilities (in particular, primarily out-of-bounds
reads and writes) that cause potentially exploitable crashes.
III. LAVA OVERVIEW
At a high level, LAVA adds bugs to programs in the
following manner. Given an execution trace of the program
on some speciﬁc input, we:
1) Identify execution trace locations where input bytes are
available that do not determine control ﬂow and have not
been modiﬁed much. We call these quantities DUAs, for
Dead, Uncomplicated and Available data.
1
3
5
7
9
void foo(int a, int b, char *s, char *d, int n) {
int c = a+b;
if (a != 0xdeadbeef)
return;
for (int i=0; i<n; i++)
c+=s[i];
memcpy(d,s,n+c); // Original source
// BUG: memcpy(d+(b==0x6c617661)*b,s,n+c);
}
Fig. 1: LAVA running example. Entering the function foo, a
is bytes 0..3 of input, b is 4..7, and n is 8..11. The pointers
s and d, and the buffers pointed to by them are untainted.
2) Find potential attack points that are temporally after a
DUA in the program trace. Attack points are source code
locations where a DUA might be used, if only it were
available there as well, to make a program vulnerable.
3) Add code to the program to make the DUA value
available at the attack point and use it to trigger the
vulnerability.
These three steps will be discussed in the following three
sections, which refer to the running example in Figure 1.
A. The DUA
Because they ensure that attacker-controlled data is available
to inﬂuence program behavior, DUAs form the raw material
from which we construct bugs. We identify DUAs in a program
by running that program under a dynamic taint analysis [14]
for a speciﬁc input. That taint analysis has a few important
features:
• Each byte in the input is given its own label. Thus, if
an internal program quantity is tainted, then we can map
that quantity back to a speciﬁc part of the input.
• The taint analysis is as complete and correct as possible.
All program code including library and kernel is subject
to taint analysis. Multiple threads and processes are also
handled correctly, so that taint ﬂows are not lost.
• The taint analysis keeps track of a set of labels per byte of
program data, meaning that it can represent computation
that mixes input bytes.
Every tainted program variable is some function of the input
bytes. We estimate how complicated this function is via a
new measure, the Taint Compute Number (TCN). TCN simply
tracks the depth of the tree of computation required to obtain
a quantity from input bytes. The smaller TCN is for a program
quantity, the closer it is, computationally, to the input. If
TCN is 0, the quantity is a direct copy of input bytes. The
intuition behind this measure is that we need DUAs that are
computationally close to the input in order to be able to use
them with predictable results.
Note that TCN is not an ideal measure. There are obviously
situations in which the tree of computation is deep but the
resulting value is both completely predictable and has as much
entropy as the original value. However, TCN has the advantage
that it is easy to compute on an instruction-by-instruction
111111
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:15:56 UTC from IEEE Xplore.  Restrictions apply. 
c(cid:2)


c(cid:2)
a(cid:2)
b(cid:2)




c(cid:2)
s[i](cid:2)
c(cid:2)


s[i](cid:2)


Fig. 2: Taint Compute Number examples from the running
example. TCN is simply the depth of the tree of computation
that produces the value from tainted inputs. TCN(c) after line
2 is 1, and after line 6 (upon exiting the loop), it is n+1.
labels to represent computation,
basis. Whenever the taint system needs to compute the union
of sets of taint
the TCN
associated with the resulting set is one more than the max of
those of the input sets. In the running example, and illustrated
in Figure 2, T CN (c) = 1 after line 1, since it is computed
from quantities a and b which are directly derived from input.
Later, just before line 7 and after the loop, T CN (c) = n + 1
because each iteration of the loop increases the depth of the
tree of computation by one.
The other taint-based measure LAVA introduces is liveness,
which is associated with taint labels, i.e., the input bytes
themselves. This is a straightforward accounting of how many
branches a byte in the input has been used to decide. Thus, if
a particular input byte label was never found in a taint label
set associated with any byte used to decide a branch, it will
have liveness of 0. A DUA entirely consisting of bytes with 0
or very low liveness can be considered dead in the sense that
it has little inﬂuence upon control ﬂow for this program trace.
If one were to fuzz dead input bytes, the program should be
indifferent and execute the same trace. In the running example,
LIV (0..3) = 1 after line 3, since a is a direct copy of input
bytes 0..3. After each iteration of the loop, the liveness of
bytes 8..11, the loop bound, increase by one, and so after the
loop LIV (8..11) = n.
Figures 3 and 4 are plots of liveness and taint compute
number for the program file processing the input /bin/ls.
In both plots, the horizontal axis is the number of replay
instructions processed, and so corresponds, roughly, to time.
The vertical axis is ﬁle position, so at bottom is the ﬁrst byte
in /bin/ls and at top is the 70th byte. Obviously, /bin/ls
is bigger than 70 bytes. However, as expected, only the 64-
byte ELF header has any interesting liveness or taint compute
number values and so we restrict our attention, in these plots,
to that section. Higher values for liveness and taint compute
number are represented on both plots by darker patches.
Thus, portions that are very light for large horizontal stretches
starting at the left on both plots are DUAs. For instance,
bytes 28-32, which point to the start of the program header
table, are uninvolved in branches or computation. Presumably
Fig. 3: Liveness plotted, over time, for the input bytes of
’/bin/ls’ being processed by the program ’ﬁle’.
Fig. 4: Taint compute number, over time, for the input bytes
of ’/bin/ls’ being processed by the program ’ﬁle’.
these would make a ﬁne DUA, and it seems reasonable that
file simply doesn’t have much use for this information.
Whereas bytes 19 and 20, which indicate the instruction set,
are very live after about 55M instructions. This is reasonable
since file needs to report this information in human-readable
form, such as x86_64. However, consider bytes 10-16, which
are apparently being used in a number of branches. This is
odd considering they are marked as unused in the ELF header
spec. These kinds of disparities make a good argument for
using taint-based measures to inject bugs rather than trusting
published specs.
The combination of uncomplicated (low TCN) and dead
(low liveness) program data is a powerful one for vulnera-
bility injection. The DUAs it identiﬁes are internal program
quantities that are often a direct copy of input bytes, and
can be set to any chosen value without sending the program
along a different path. These make very good triggers for
vulnerabilities. In the running example, bytes 0..3 and 8..11 are
all somewhat live, because they have been seen to be used to