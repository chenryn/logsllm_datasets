programs from many different types of underlying lan-
guages, they encompass a wide range of exploitation
techniques. The collected data contains raw traces of the
interactions seen when downloading the pages for each
of the returned results. Our corpus contained 178,541
TCP ﬂows, of which we randomly selected 24,000 ﬂows
as training data for our real-world deployment (see Sec-
tion 6.1).
Since our primary goal here is to detect (and catch)
bots using search engines to query strings present in vul-
nerable web applications, our responder must be in a po-
sition to capture these prey — i.e., it has to be broadly
indexed by multiple search engines. To do so, we ﬁrst
created links to our responder from popular pages,6 and
then expedited the indexing process by disclosing the
existence of a minor bug in a common UNIX applica-
tion to the Full-Disclosure mailing list. The bug we
disclosed cannot be leveraged for privilege escalation.
Bulletins from Full-Disclosure are mirrored on several
high-ranking websites and are crawled extensively by
search-engine spiders; less than a few hours later, our
site appeared in search results on two prominent search
engines. And, right on queue, the attacks immediately
followed.
6.1 Real-World Deployment
For our real-world evaluation, we deployed our system
on a 3.0 GHz dual-processor Intel Xeon with 8 GB of
RAM. At runtime, memory utilization peaked at 960 MB
of RAM when trained with 24,000 ﬂows. CPU utiliza-
tion remained at negligible levels throughout operation
and on average, requests are satisﬁed in less than a sec-
ond. Because our design was optimized to purposely
keep all data RAM during runtime, disk access was un-
necessary.
Shortly after becoming indexed, search-worms began
to attack at an alarming rate, with the attacks rapidly
increasing over a two month deployment period. Dur-
ing that time, we also recorded the number of indexes
returned by Google per day (which totaled just shy of
12,000 during the deployment). We choose to only show
PHP attacks because of their prominence. Figure 7 de-
picts the number of attacks we observed per day. For
reference, we provide annotations of our Google index
count in ten day intervals until the indices plateau.
Figure 7: Daily PHP attacks. The valley on day 44 is due
to an 8 hr power outage. The peak on day 56 is because
two bots launched over 2,000 unique script attacks.
For ease of exposition, we categorize the observed at-
tacks into four groups. The ﬁrst denotes the number of at-
tacks targeting vulnerabilities that have distinct ﬁle struc-
tures in their names. The class “Unique PHP attacks”,
however, is more reﬁned and represents the number of at-
tacks against scripts but using unique injection variables
(i.e., index.php?page= and index.php?inc=).
The reason we do so is that the ﬁle names and struc-
tures can be ubiquitous and so by including the vari-
able names we glean insights into attacks against poten-
tially distinct vulnerabilities. We also attempt to quan-
tify the number of distinct botnets involved in these at-
tacks. While many botnets attack the same applica-
tion vulnerabilities, (presumably) these botnets can be
differentiated by the PHP script(s) they remotely in-
clude. Recall that a typical PHP remote-include exploit is
of the form “vulnerable.php?variable=http:
//site.com/attack\ script?”, and in practice,
botnets tend to use disjoint sites to store attack scripts.
Therefore, we associate bots with a particular botnet by
identifying unique injection script repositories. Based on
this admittedly loose notion of uniqueness [27], we ob-
served attacks from 5,648 distinct botnets. Lastly, we
record the number of unique IP addresses that attempt to
compromise our responder.
The results are shown in Figure 7. An immediate ob-
servation is the sheer volume of attacks—in total, well
over 368,000 attacks targeting just under 45,000 unique
scripts before we shutdown the responder.
Interest-
ingly, notice that there are more unique PHP attacks than
unique IPs, suggesting that unlike traditional scanning
attacks, these bots query for and attack a wide variety
of web applications. Moreover, while many bots attempt
 0 500 1000 1500 2000 2500 3000 0 10 20 30 40 50 60 70DaysUnique PHP Script NamesUnique PHP AttacksUnique IPsUnique Injected Scripts109 indices1,710 indices7,310 indices12,000 indicesto exploit a large number of vulnerabilities, the repos-
itories hosting the injected scripts remain unchanged
from attack to attack. The range of attacks is perhaps
better demonstrated not by the number of unique PHP
scripts attacked but by the number of unique PHP web-
applications that are the target of these attacks.
6.1.1 Unique WebApps
In general, classifying the number of unique web ap-
plications being attacked is difﬁcult because some bots
target PHP scripts whose ﬁlenames are ubiquitous (e.g.,
index.php). In these cases, bots are either targeting
a vulnerability in one speciﬁc web-application that hap-
pens to use a common ﬁlename or arbitrarily attempting
to include remote PHP scripts.
To determine if an attack can be linked to a speciﬁc
web-application, we downloaded the directory structures
for over 4,000 web-applications from SourceForge.net.
From these directory structures, we matched the web
application to the corresponding attacked script (e.g.,
gallery.php might appear only in the Web Gallery
web application). Next, we associated an attack with
a speciﬁc web application if the ﬁle name appeared in
no more than 10 web-app ﬁle structures. We choose a
threshold of 10 since SourceForge stores several copies
of essentially the same web application under different
names (due to, for instance, “skin” changes or different
code maintainers). For non-experimental deployments
aimed at detecting zero-day attacks, training data could
be associated with its application of origin, thereby mak-
ing associations between non-generic attacks and spe-
ciﬁc web-applications straightforward.
Based on this heuristic, we are able to map the 24,000
ﬂows we initially trained on to 560 “unique” web-
applications. Said another way, by simply building our
language models on randomly chosen ﬂows, we were
able to generate content that approximates 560 distinct
web-applications — a feat that is not as easy to achieve
if we were to deploy each application on a typical web-
based honeypot (e.g., the Google Hack Honeypot [3]).
The attacks themselves were linked back to 295 distinct
web applications, which is indicative of the diversity of
attacks.
We note that our heuristic to map content to web-
apps is strictly a lower bound as it only identiﬁes web-
applications that have a distinct directory structure and/or
ﬁle name; a large percentage of web-applications use
index.php and other ubiquitous names and are there-
fore not accounted for. Nonetheless, we believe this
serves to make the point that our approach is effective
and easily deployable, and moreover, provides insight
into the amount of web-application vulnerabilities cur-
rently being leveraged by botnets.
6.1.2 Spotting Emergent Threats
While the original intention of our deployment was to
elicit interaction from malware exploiting known vulner-
abilities in web applications, we became indexed under
broader conditions due to the high amount of variabil-
ity in our training data. As a result, a honeypot or ac-
tive responder indexed under such a broad set of web ap-
plications can, in fact, attract attacks targeting unknown
vulnerabilities. For instance, according to milw0rm (a
popular security advisory/exploit distribution site), over
65 PHP remote inclusion vulnerabilities were released
during our two month deployment [1]. Our deployment
began on October 27th, 2007 and used the same training
data for its entire duration. Hence, any attack exploiting
a vulnerability released after October 27th is an attack
we did not explicitly set out to detect.
Nonetheless, we witnessed several emergent threats
(some may even consider them “zero-day” attacks) be-
cause some of the original queries used to bootstrap
training were generic and happened to represent a wide
number of webapps. As of this writing, we have iden-
tiﬁed more than 10 attacks against vulnerabilities that
were undisclosed at deployment time (some examples
are illustrated in Table 2).
It is unlikely that we wit-
nessed these attacks simply because of arbitrary attempts
to exploit random websites—indeed, we never witnessed
many of the other disclosed vulnerabilities being at-
tacked.
We argue that given the frequency with which these
types of vulnerabilities are released, a honeypot or an ac-
tive responder without dynamic content generation will
likely miss an overwhelming amount of attack trafﬁc—in
the attacks we witnessed, botnets begin attacking vulner-
able applications on the day the vulnerability was pub-
licly disclosed! An even more compelling case for our
architecture is embodied by attacks against vulnerabili-
ties that have not been disclosed (e.g., the recent Word-
Press vulnerability [7]). We believe that the potential to
identify these attacks exempliﬁes the real promise of our
approach.
6.2 Dissecting the Captured Payloads
To better understand what the post-infection process en-
tails, we conducted a rudimentary analysis of the re-
motely included PHP scripts. Our malware analysis was
performed on a Linux based Intel virtual machine with
the 2.4.7 kernel. We used a deprecated kernel version
since newer versions do not export the system call ta-
ble of which we take advantage. Our environment con-
sisted of a kernel module and a preloaded library7 that
serve to inoculate malware before execution and to log
interesting behavior. The preloaded library captures calls
Disclosure Date Attack Date
2007-11-10
2007-11-23
2007-11-22
2007-11-25
2007-11-28
2007-11-04
2007-11-21
2007-11-22
2007-11-25
2007-11-28
Signature
/starnet/themes/c-sky/main.inc.php?cmsdir=
/comments-display-tpl.php?language file=
/admin/kfm/initialise.php?kfm base path=
/Commence/includes/db connect.php?phproot\ path=
/decoder/gallery.php?ccms library path=
Table 2: Attacks targeting vulnerabilities that were unknown at time of deployment
to connect() and send(). The connect hook de-
ceives the malware by faking successful connections, and
the send function allows us to record information trans-
mitted over sockets.8
Our kernel module hooks three system calls: (open,
write, and execve). We execute every script under
a predeﬁned user ID, and interactions under this ID are
recorded via the open() hook. We also disallow calls to
open that request write access to a ﬁle, but feign success
by returning a special ﬁle descriptor. Attempts to write
to this ﬁle descriptor are logged via syslog. Doing so
allows us to record ﬁles written by the malware without
allowing it to actually modify the ﬁle system. Similarly,
only commands whose ﬁle names contain a pre-deﬁned
random password are allowed to execute. All other com-
mand executions under the user ID fail to execute (but
pretend to succeed), assuring no malicious commands
execute. Returning success from failed executions is im-
portant because a script may, for example, check if a
command (e.g., wget) successfully executes before re-
questing the target URL.
To determine the functionality of the individual mal-
ware scripts, we batched processed all the captured mal-
ware on the aforementioned architecture. From the tran-
scripts provided by the kernel module and library, we
were able to discern basic functionality, such as whether
or not the script makes connections, issues IRC com-
mands, attempts to write ﬁles, etc. In certain cases, we
also conducted more in-depth analyses by hand to un-
cover seemingly more complex functionality. We discuss
our ﬁndings in more detail below.
The high-level break-down for the observed scripts is
given in Table 3. The challenge in capturing bot pay-
loads in web application attacks stems from the ease with
which the attacker can test for a vulnerability; unique
string displays (where the malware echoes a unique to-
ken in the response to signify successful exploitation)
accounts for the most prevalent type of injection. Typ-
ically, bots parse returned responses for their identifying
token and, if found, proceed to inject the actual bot pay-
load. Since these unique tokens are unlikely to appear
in our generated response, we augment our responder to
echo these tokens at run-time. While the use of random
numbers as tokens seem to be the soup du jour for testing
Script Classiﬁcation
PHP Web-based Shells
Echo Notiﬁcation
PHP Bots
Spammers
Downloaders
Perl Bots
Email Notiﬁcation
Text Injection
Java-script Injection
Information Farming
Uploaders
Image Injection
UDP Flooders
Instances
834
591
377
347
182
136
87
35
18
9
4
4
3
Table 3: Observed instances of individual malware
a vulnerability, we observed several instances where at-
tackers injected an image. Somewhat comically, in many
cases, the bot simply e-mails the IP address of the vulner-
able machine, which the attacker then attempts to exploit
at a later time. The least common vulnerability test we
observed used a connect-back operation to connect to an
attacker-controlled system and send vulnerability infor-
mation to the attacker. This information is presumably
logged server-side for later use.
Interestingly, we notice that bots will often inject sim-
ple text ﬁles that typically also contain a unique identi-
fying string. Because PHP scripts can be embedded in-
side HTML, PHP requires begin and end markers. When
a text ﬁle is injected without these markers, its contents
are simply interpreted as HTML and displayed in the out-
put. This by itself is not particularly interesting, but we
observed several attackers injecting large lists of queries
to ﬁnd vulnerable web applications via search engines.
The largest query list we captured contained 7,890 search
queries that appear to identify vulnerable web applica-
tions — all of which could be used to bootstrap our con-
tent generation further and cast an even wider net.
Overall, the collected malware was surprisingly mod-
ular and offered diverse functionality similar to that re-
ported elsewhere [26, 15, 13, 12, 25, 5, 4]. The cap-
tured scripts (mostly PHP-based command shells), are
advanced enough that many have the ability to display
the output in some user-friendly graphical user interface,
obfuscate the script itself, clean the logs, erase the script
and related evidence, deface a site, crawl vulnerability