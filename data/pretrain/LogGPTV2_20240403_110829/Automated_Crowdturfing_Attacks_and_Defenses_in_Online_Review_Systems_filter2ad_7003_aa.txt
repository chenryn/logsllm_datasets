title:Automated Crowdturfing Attacks and Defenses in Online Review Systems
author:Yuanshun Yao and
Bimal Viswanath and
Jenna Cryan and
Haitao Zheng and
Ben Y. Zhao
Automated Crowdturfing Attacks and Defenses in
Online Review Systems
Yuanshun Yao
PI:EMAIL
University of Chicago
Bimal Viswanath
PI:EMAIL
University of Chicago
Jenna Cryan
PI:EMAIL
University of Chicago
Haitao Zheng
PI:EMAIL
University of Chicago
Ben Y. Zhao
PI:EMAIL
University of Chicago
ABSTRACT
Malicious crowdsourcing forums are gaining traction as sources
of spreading misinformation online, but are limited by the costs of
hiring and managing human workers. In this paper, we identify a
new class of attacks that leverage deep learning language models
(Recurrent Neural Networks or RNNs) to automate the generation
of fake online reviews for products and services. Not only are these
attacks cheap and therefore more scalable, but they can control rate
of content output to eliminate the signature burstiness that makes
crowdsourced campaigns easy to detect.
Using Yelp reviews as an example platform, we show how a two
phased review generation and customization attack can produce
reviews that are indistinguishable by state-of-the-art statistical
detectors. We conduct a survey-based user study to show these
reviews not only evade human detection, but also score high on
“usefulness” metrics by users. Finally, we develop novel automated
defenses against these attacks, by leveraging the lossy transfor-
mation introduced by the RNN training and generation cycle. We
consider countermeasures against our mechanisms, show that they
produce unattractive cost-benefit tradeoffs for attackers, and that
they can be further curtailed by simple constraints imposed by
online service providers.
CCS CONCEPTS
• Security and privacy → Social aspects of security and pri-
vacy; • Computing methodologies → Natural language gen-
eration; Neural networks;
KEYWORDS
Web Security; Crowdturfing; Fake Review; Opinion Spam
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
© 2017 Association for Computing Machinery.
ACM ISBN 978-1-4503-4946-8/17/10...$15.00
https://doi.org/10.1145/3133956.3133990
1 INTRODUCTION
The Internet is no longer the source of reliable information it once
was. Today, misinformation is being used as a tool to harm com-
petitors, win political campaigns, and sway public opinion. Clashes
between conflicting accounts occur daily on social networks and
online discussion forums, and the trustworthiness of many online
information sources is now in question.
One highly effective weapon for spreading misinformation is the
use of crowdturfing campaigns [30, 46, 74], where bad actors pay
groups of users to perform questionable or illegal actions online.
Crowdturfing marketplaces are the corrupt equivalents of Amazon
Mechanical Turk, and are rapidly growing in China, India and
the US [30, 74]. For example, an attacker can pay workers small
amounts to write negative online reviews for a competing business,
often fabricating nonexistent accounts of bad experiences or service.
Since these are written by real humans, they often go undetected
by automated tools looking for software attackers.
Thankfully, two factors limit the growth and impact of crowd-
turfing campaigns. First, they require monetary compensation for
each task performed. Larger campaigns can incur significant cost
on an attacker, and this limits the scale of many campaigns. Sec-
ond, the predictable reaction of workers often produce actions (and
output) synchronized in time, which can be effectively used as a
feature to classify and identify crowdturfing campaigns [30, 74].
A more knowledgeable attacker can apply adversarial techniques
(e.g. poisoning training data, targeted evasion) against machine
learning (ML) classifiers, but such techniques have limited impact,
and require significant coordination across workers [73].
But just as ML classifiers can effectively detect these attacks,
advances in deep learning and deep neural networks (DNNs) can
also serve to make these attacks much more powerful and diffi-
cult to defend. Specifically, we believe that in limited application
contexts, DNNs have reached a point where they can produce suffi-
ciently clear and correct content effectively indistinguishable from
those produced by humans. To illustrate our point, we focus on
the domain of online reviews for e-commerce products and ser-
vices, where millions of users upload reviews to sites such as Yelp,
TripAdvisor and Amazon. Online reviews tend to be short, and
focused on a limited range of topics defined by the application
domain, e.g. quality of food and service at a restaurant. We believe
that well designed and tuned DNNs are now capable of producing
realistic online reviews. If successful, attack campaigns using DNN-
based fake reviews would be much more powerful, because they
are highly scalable (no per-review payments to human writers) and
Session E4:  Adversarial Social Networking CCS’17, October 30-November 3, 2017, Dallas, TX, USA1143harder to detect, as scripts can control the rate of review generation
to avoid the telltale burstiness that makes crowdsourced reviews
so easily detectable [30, 73].
In this paper, we identify a class of attacks based on DNN-based
fake review generation. We demonstrate that DNN-based review
generators are practical and effective, using a combination of ML-
trained review generation and context-based customization. Using
Yelp restaurant reviews as a target platform, we show empirically
that synthetic reviews generated by our tools are effectively indis-
tinguishable from real reviews by state-of-the-art detectors relying
on linguistic features. We carry out a user study (N =600) and show
that not only can these fake reviews consistently avoid detection
by real users, but they provide the same level of user-perceived
“usefulness” as real reviews written by humans.
We then examine potential defenses, and propose an ML-classifier
based defense that leverages the inherent computational limitations
of most RNNs against the attacker. This leverages the fact that gen-
erative language models build fixed memory presentations of the
entire training corpus, which limits the amount of information that
can be captured from the training corpus. We show that the cycle
of processing real reviews through a RNN-based model training
and text generation is lossy, and the resulting loss can be detected
by comparing the character level distribution of RNN-generated re-
views against those written by real users. We also consider potential
countermeasures, and show that increasing model complexity pro-
duces diminishing returns in evasion, while resource costs increase
dramatically.
In summary, our work produces several key takeaways:
(1) We demonstrate the feasibility of automated generation of
product reviews for online review sites, using a RNN-based
approach for review generation and customization. Our key
insight is that while automated generation of arbitrary length
content is challenging, generation of shorter text in fixed
application domains is practical today.
(2) We show that RNN-based synthetic reviews are robust against
state of the art statistical and ML-based detectors. In addition,
our user-study shows they are largely indistinguishable from
real reviews to human readers, and appear to provide similar
levels of “usefulness” utility as determined by readers.
(3) We propose a novel defense that leverages the information
loss inherent in an RNN training process to identify statisti-
cally detectable variations in the character-level distribution
of machine-generated reviews. We show that our defense is
robust against countermeasures, and that avoiding detection
involves the attacker paying rapidly accelerating costs for
diminishing returns.
We believe this is a practical new attack that can have significant
impact on not only user-generated review sites like Yelp, but poten-
tial attacks on content generation platforms such as Twitter and
online discussion forums. We hope these results will bring attention
to the problem and encourage further analysis and development of
new defenses.
2 PRELIMINARIES
We begin our discussion with background material on online review
systems, and content generation based on deep learning networks
(RNNs in particular). For simplicity, we focus our discussion on
online review systems such as Yelp, Amazon and TripAdvisor.
2.1 Crowdsourced Attacks on Review Systems
Most popular e-commerce sites today rely on user feedback to
rate products, services, and online content. Crowdsourced feedback
typically includes a review or opinion, describing a user’s experience
of a product or service, along with a rating score (usually on a 1 to
5 scale).
Unfortunately, many review systems are plagued by fake reviews,
e.g., Yelp [7], Amazon [37], iTunes [40] and TripAdvisor [6], where
an attacker manipulates crowd opinion using fake or deceptive
reviews. To boost their reputation or to damage that of a competitor,
businesses can solicit fake reviews that express an overly positive
or negative opinion about a business [7, 30, 74]. Studies on Yelp
found that a one star rating increase for restaurants can lead to a
5–9% boost in revenue [34].
Sites like Yelp and Amazon have been consistently engaged in a
cat and mouse battle with fake reviews, as attackers try to adapt
and bypass various defense schemes [18]. Yelp’s review filter system
flags suspicious reviews and even raises an alert to the consumer if
a business is suspected of engaging in large-scale opinion manipu-
lation [80].
Recently, attacks have been known to generate highly deceptive
(authentic looking) fake reviews written by paid users. Much of
this comes from malicious crowdsourcing marketplaces, known as
crowdturfing systems, where a large pool of human workers provide
on-demand effort for completing various malicious tasks [54, 59]. In
the next section, we introduce an attack powered by an AI program
that can replace human writers and achieve high attack success.
2.2 Our Attack Model
We assume the attacker’s goal is to use an AI program to generate
fake reviews that are indistinguishable from real reviews written
by human users. We only focus on the generation of review text,
which is crucial to deceive users and to manipulate their opinion.
We do not consider the manipulation of metadata associated with
a review or reviewer. Metadata can include any information other
than the textual content, e.g., reviewer reputation, review history,
posting date and IP address.
Key Insight. There have been significant recent advances in build-
ing probabilistic generative language models on Neural Networks,
specifically Recurrent Neural Networks (RNNs). Even trained on
large datasets, RNNs have generally fallen short in producing writ-
ing samples that truly mimic human writing [50]. However, our
insight is that the quality of RNN-generated text is likely more than
sufficient for applications relying on domain-specific, short length
user-generated content, e.g., online reviews.
Assumptions.
• The attacker has access to a corpus of real reviews to train
the generative language model. Popular sites like Yelp have
already released large review datasets [79]. Attackers can also
Session E4:  Adversarial Social Networking CCS’17, October 30-November 3, 2017, Dallas, TX, USA1144(a) Human-based attack.
(b) Machine-based attack.
Figure 2: RNN generative model training.
Figure 1: Fake review attack: Human-based vs. Machine-
based.
using human writers, workers tend to rapidly generate the re-
quested reviews, producing a burst in new reviews that is easily
detected [30, 73].
download reviews, or large review datasets made public by
researchers [15, 35, 38].
• The attacker has knowledge of the domain of a product (e.g.,
cameras) or business (e.g., restaurants, clothing stores) which
allows training on a review corpus that matches the domain.
• The attacker has access to sufficient computational resources
for training neural networks. Today, commodity GPU ma-
chines can efficiently train DNNs, and can be easily purchased
or accessed in the Cloud [36].
2.3 RNNs vs. Crowdsourced Authors
Traditional attacks using fake reviews typically hire human writers
to write reviews. Instead, our work considers automated, machine-
based review attacks leveraging DNN-based language models (see
Figure 1). Here, we compare the two approaches and highlight the
benefits of automated review attacks.
The key difference between these two approaches is the quality
of writing in the generated text content. To influence user opin-
ion and alter decisions, fake reviews need to be written in such
a way to mimic content written by real users. Broken grammar,
misspellings and broken context can make a review appear fake. Ex-
isting machine-based text generations techniques, such as n-gram
models and template-based models are known to have limitations in
generating realistic-looking text [42, 77]. Hence, the reviews gener-
ated based on those techniques are likely to be identified as fake
by readers [82]. In contrast, a generative RNN model can generate
much more coherent text [2, 43], but still falls short for larger types
of content [50].
There are some obvious benefits to using a software-controlled
RNN to generate fake reviews. First, it removes the cost of paying
human writers, which costs $1-$10 per review on Yelp according
to prior work [55]. To further obtain an independent estimate, we
search Blackhat SEO Forum1 for “Yelp reviews,” and observe an
average price of $19.6 per review based on a random sample of 20
posts. Perhaps more importantly, software generators can control
the specific timing and output of reviews, so they are harder to de-
tect. When attackers launch large-scale fake review campaigns
1https://www.blackhatworld.com/
2.4 RNN as a Text Generative Model
We provide background on text generation using Recurrent Neural
Networks.
Neural Networks are computational models that use a connected
network of neurons to solve machine learning tasks. Neurons serve
as the basic computational units in a Neural Network. In this work,
we focus on a specific class of Neural Networks known as Recurrent
Neural Networks (RNNs), which are better suited for sequential