∞X
k=1
3!
(α ln x)2k
(2k + 1)!
.
=
∞X
k=1
“
r(x, α) ≤ 1
6
”
∈ O( ln N√
Since every term is positive, we have r(x, α) ≥ 0. We
assume that α < 1
ln N . This gives us
„
«
(α ln x)
2k
=
1
6
(α ln x)2
1 − (α ln x)2
.
(2)
The bound takes maximum value at x = N . Solving
(α ln N)2
1−(α ln N)2
1
6
q
ln N
6
2
proximates x ln x within the relative error bound .
=  gives us α =
 ). Therefore f (x) = 1
1+6
6
1+6
q
ln N , and c = 1
2α =
2α (x1+α − x1−α) ap-
A plot of this approximation for the range [1, 1000] and
f (x) = 10(x1.05 − x0.95) is given in Figure 1. The relative
error guarantee of the approximation only holds for values
less than some constant N . As we have mentioned, we will
use some elephant detection mechanism to circumvent this
shortcoming.
4.2 Estimating entropy norm ||S||H
Now we will combine our approximation formula and In-
dyk’s algorithm to get an estimator for the entropy norm
||S||H . Suppose we have chosen α and c in Theorem 3 to
get relative error bound 0 on [1, N ], and we have chosen l
from Theorem 1 for p = 1 ± α to achieve asymptotic (, δ)
error bound. For p = 1 + α we have sketches (cid:6)Y , and for
p = 1 − α we have sketches (cid:6)Z. Our estimator for ||S||H is
(cid:2)||S||H ≡ 1
2α
Λ((cid:6)Y )
1+α − Λ( (cid:6)Z)
1−α
(3)
“
”
We now study the error of this estimator. We will use some
approximation to get some rough but simple error estimates.
The proofs are in the Appendix.
Proposition 4. Assume ai ≤ N . Then (3) estimates
||S||H within relative error roughly 2λc + λ00 with prob-
ability roughly 1 − 2δ, where c = 1
1+α −
2α , λ0 = |c(||S||1+α
1+α/||S||H , and typi-
||S||1−α
cally λ < 1.
1−α)/||S||H − 1|/0 ≤ 1, λ = ||S||1+α
Example: For N = 1024, α = 0.05,  = 0.001, δ = 0.05,
then 0 = 0.023, l ≈ 105. If we only assume λ = λ0 = 1,
then (2c+0) ≈ 0.04, i.e. we can approximate ||S||H within
4% error with 90% probability using 105 samples. If we as-
sume λ = 0.5, then we can aﬀord to increase  to 0.002, and
thus decrease l to ≈ 2.5 × 104 to achieve the 4% error.
Proposition 5. (More Aggressive): Under same assump-
tions as above, (3) estimates ||S||H within relative error
roughly
2cλ + λ00 with probability roughly 1 − δ.
√
1
s
Example: Same assumption as the example above, then we
only need l ≈ 1.25 × 104 to achieve the 4% error with prob-
ability 95%.
4.3 Estimating L1 norm s
P
Recall that to compute the actual entropy H = log2 s −
i ai log2 ai, we need to know the complete volume of the
traﬃc s, or ||S||1. For a single stream this is trivial to do
with a single counter. But our ultimate goal is to calcu-
late entropy of every OD pair, thus we need to compute
the entire traﬃc matrix for the network. There has been
considerable previous work in solving this problem, but any
additional method will have the corresponding overhead as-
sociated with it.
In this section we show how to use the
same sketch data structure that we have been maintaining
so far to approximate this value for a single stream, which
will be naturally extended to distributed case later.
Similar to the proof of Theorem 3, we can easily show the
following theorem:
Theorem 6. Let α, N , and  be as in Theorem 3. Then,
the approximation (x1+α + x1−α)/2 approximates the func-
tion f (x) = x with relative error at most 3.
This approximation holds good for all counts in the range
[1, N ] and we use the elephant sketch to capture all ﬂows
with size strictly greater than N .
So our estimator for ||S||1, is
Λ((cid:6)Y )
+ Λ( (cid:6)Z)
“
1−α
”
.
(4)
(cid:3)||S||1 ≡ 1
2
1+α
tions 4 and 5, we have the following:
Using Theorem 6 and proofs similar to those of Proposi-
Proposition 7. (4) estimates ||S||1 roughly within rel-
00 with probability 1 − 2δ, where
ative error bound  + 3λ(cid:4)
1−α)/||S||1 − 1|/30 ≤ 1. Or, more
1+α + ||S||1−α
0 = |(||S||1+α
λ(cid:4)
aggressively, the error bound is roughly 1√
00 with
probability 1 − δ.
 + 3λ(cid:4)
2
4.4 Separating elephants
Recall that we need to keep track of the elephant ﬂows
(say those that have more 1000 packets) and estimate their
contributions to the total entropy separately. In our scheme,
we adopt the “sample and hold” algorithm proposed in [10]
due to its low computational complexity and ease of analysis.
The “sample and hold” algorithm will produce a list of ﬂows
that include all elephant ﬂows with very high probability.
Then for each elephant ﬂow in the list, we subtract the in-
crements caused by them to the sketches, and compute their
contributions to the entropy separately. The algorithm also
has the nice property that the larger the size of a ﬂow, the
smaller (actually exponentially smaller) the probability of
its missing from the list. This property works very well with
the fact that the accuracy of our approximation of x ln(x)
degrades only gradually after the target threshold (say 1000
packets).
5. DISTRIBUTED ALGORITHM
In this section we show the IMP property of the Lp sketch,
i.e., we can use the sketches at ingress nodes and egress nodes
to estimate the Lp norm of the OD ﬂows.
For a given OD-pair, we will require only the sketches at
that ingress and egress node. Hence, we ﬁx one such pair
and do all the analysis for it. We call the ingress stream as
O and egress stream as D. We are interested in the ﬂows in
the set O ∩ D. Note that if we can estimate the pair of Lp
norms for O ∩ D, p = 1± α, then we can use the formula for
approximating the entropy function as before.
The sketch data structures will be the same at every ingress
and egress node, that is, they will use the same number of
counters l, and they will use the same set of p-stable hash
functions as deﬁned in Section 3.2. After we introduce buck-
eting in Section 6, they will also use the same number of
buckets k and the same uniform hash function.
5.1 Computing OD ﬂow Lp norm ||O ∩ D||p
With a slight abuse of notation, we will use (cid:6)O to denote
the sketch for the ingress node, and (cid:6)D to denote the sketch
for the egress node. (cid:6)O + (cid:6)D and (cid:6)O − (cid:6)D are the component-
wise addition and diﬀerence of (cid:6)O and (cid:6)D respectively. (This
is possible because all nodes are using the same values of l.)
Our estimator for ||O ∩ D||p, (cid:2)||O ∩ D||p , can be either
Λ( (cid:6)O, (cid:6)D) ≡
or
(cid:4)
Λ
( (cid:6)O, (cid:6)D) ≡
!1/p
Λ( (cid:6)O)p + Λ( (cid:6)D)p − Λ( (cid:6)O − (cid:6)D)p
!1/p
Λ( (cid:6)O + (cid:6)D)p − Λ( (cid:6)O − (cid:6)D)p
2
(5)
.
(6)
2p
5.2 Correctness
In this section we show that the two formulae described
are good estimators for ||O ∩ D||p. Hence, by using two
copies of the above algorithm, one each for p1 = 1 − α and
p2 = 1 + α, and our x ln x approximation formula, we can
obtain an approximation of the entropy between every pair
of ingress and egress nodes.
We partition the ﬂows that enter through the ingress node
or exit through the egress nodes as follows:
A = O − D = ﬂows that enter at ingress but do not exit
B = O ∩ D = ﬂows that enter at ingress and exit through
C = D − O = ﬂows that do not enter at ingress but exit
through the egress
the egress
through the egress
We know that Λ( (cid:6)O) is an estimator for ||O||p, so Λ( (cid:6)O)p
p = ||A||p
p + ||B||p
p.
p + ||C||p
p.
is an estimator for ||O||p
p = ||A ∪ B||p
Similarly Λ( (cid:6)D)p is an estimator for ||B||p
p+||C||p
p = ||A||p
p+2p||B||p
The sketch (cid:6)O + (cid:6)D holds the contributions of all the ﬂows
in A, B and C, but with every packet from B contributing
twice. We use B(2) to denote all the ﬂows in B with packet
counts doubled. Then Λ( (cid:6)O + (cid:6)D)p is an estimator for ||A ∪
B(2)∪C||p
p. It is important to point
out that the reasoning here (and in the next paragraph)
depends on the fact that the ingress and egress nodes are
using the same sketch settings as noted at the beginning of
this section.
The sketch (cid:6)O − (cid:6)D exactly cancels out the contributions
from all the ﬂows in B, and leaves us with the contributions
of ﬂows from A and the negative of the contributions of
ﬂows from C. We use C (−1) to denote all the ﬂows in C
with packet counts multiplied by −1. Then Λ( (cid:6)O− (cid:6)D)p is an
estimator of ||A ∪ C (−1)||p
p +
||C||p
p .
p + ||C (−1)||p
p = ||A||p
p = ||A||p
p
estimates
To sum up, we get the following:
||A||p
||B||p
||A||p
||A||p
Λ( (cid:6)O)
Λ( (cid:6)D)
Λ( (cid:6)O + (cid:6)D)
Λ( (cid:6)O − (cid:6)D)
estimates
estimates
estimates
p
p
p + ||B||p
p + ||C||p
p||B||p
p + 2
p + ||C||p
p.
p
p
p
p + ||C||p
p
It is easy to see from the above formulae that both For-
mula (5) and Formula (6) are reasonable estimators for ||B||p,
i.e. ||O ∩ D||p.
p = r2||D||p
p, and ||O ∩ D||p
Proposition 8. Suppose we have chosen proper l such
p =
p. Then (5) raised to the
p roughly within relative error
−1) with probability at least 1−3δ. Similarly,
p roughly within
−1)
that (1) is roughly an (, δ) estimator. Suppose ||O ∩ D||p
r1||O||p
power p estimates ||O ∩ D||p
bound ( 1
(6) raised to the power p estimates ||O ∩ D||p
relative error bound 21−p( 1
r1 + 1
with probability at least 1 − 2δ.
r2 +2p−1−2) ≈ ( 1
r1 + 1
r2
r1 + 1
r2
We omit the proof here since it is similar to the previous
proofs. This gives us a very loose rough upper bound on the
relative error. The ratios r1 and r2 are related to, but not
identical to, the ratio of OD ﬂow traﬃc against the total
traﬃc at the ingress and egress points. We want to point
out that we cannot pursue a more aggressive claim similar
to Proposition 5, because we cannot claim independence of
Λ( (cid:6)O) and Λ( (cid:6)O + (cid:6)D), etc.
Now, to calculate OD ﬂow entropy, we just need to replace
Λ((cid:6)Y ) in (1) and (4) with Λ( (cid:6)O, (cid:6)D) where (cid:6)O and (cid:6)D are L1+α
sketches, and similarly for Λ( (cid:6)Z).
6. USING BUCKETS
Our earlier examples showed that l, the number of coun-
ters in the Lp sketch, need to be in the order of many thou-
sands to achieve a high estimation accuracy. Recall that
each incoming packet will trigger increments to all l coun-
ters for estimating one Lp norm, and our algorithm requires
that two diﬀerent Lp norms be computed. Such a large l is
unacceptable to networking applications, however, since for
high-speed links, where each packet has tens of nanoseconds
to process, it is impossible to increment that many counters
per packet, even if they are all in fast SRAM.
We resolve this problem by adopting the standard method-
ology of bucketing [9], shown in Algorithm 2. With buck-