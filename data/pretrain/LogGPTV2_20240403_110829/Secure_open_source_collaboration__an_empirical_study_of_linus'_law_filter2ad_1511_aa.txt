title:Secure open source collaboration: an empirical study of linus' law
author:Andrew Meneely and
Laurie A. Williams
Secure Open Source Collaboration:  
An Empirical Study of Linus’ Law
Andrew Meneely and Laurie Williams 
North Carolina State University 
Department of Computer Science, Raleigh, North Carolina, USA 
{apmeneel, lawilli3}@ncsu.edu 
ABSTRACT 
Open source software is often considered to be secure. One factor 
in this confidence in the security of open source software lies in 
leveraging large developer communities to find vulnerabilities in 
the  code.  Eric  Raymond  declares  Linus’  Law  “Given  enough 
eyeballs,  all  bugs  are  shallow.”  Does  Linus’  Law  hold  up  ad 
infinitum?    Or,  can  the  multitude  of  developers  become  “too 
many  cooks  in  the  kitchen”,  causing  the  system’s  security  to 
suffer  as  a  result?  In  this  study,  we  examine  the  security  of  an 
open source project in the context of developer collaboration. By 
analyzing  version  control  logs,  we  quantified  notions  of  Linus’ 
Law  as  well  as  the  “too  many  cooks  in  the  kitchen”  viewpoint 
into developer activity metrics. We performed an empirical case 
study  by  examining  correlations  between  the  known  security 
vulnerabilities  in  the  open  source  Red  Hat  Enterprise  Linux  4 
kernel  and  developer  activity  metrics.  Files  developed  by 
otherwise-independent developer groups were more likely to have 
a  vulnerability,  supporting  Linus’  Law.  However,  files  with 
changes from nine or more developers were 16 times more likely 
to  have  a  vulnerability  than  files  changed  by  fewer  than  nine 
developers,  indicating  that  many  developers  changing code may 
have a detrimental effect on the system’s security.  
Categories and Subject Descriptors 
D.2.8  [Software  Engineering]:  Metrics  –  process  metrics, 
product metrics.  
General Terms: Measurement, Security, Human Factors 
Keywords:  Linus’  Law,  developer  network,  contribution 
network, vulnerability, metric  
1.  INTRODUCTION 
Open  source  software  is  often  considered  to  be  secure  [7,  23]. 
One  factor  in  this  confidence  in  the  security  of  open  source 
software  lies  in  leveraging  large  developer  communities  to  find 
vulnerabilities  in  the  code.  In  his  essay,  The  Cathedral  and  the 
Bazaar [19], Eric Raymond declares Linus’ Law1 as 
1  In  this  context,  the  word  “law”  is  used  to  mean  a  repeated 
observation [4]. 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, 
or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific permission and/or a fee. 
CCS’09, November 9-13, 2009, Chicago, Illinois, USA. 
Copyright 2009 ACM 978-1-60558-352-5/09/11…$10.00. 
“Given a large enough beta-tester and co-developer base, 
almost every problem will be characterized quickly and the 
fix obvious to someone.” [19] 
[17] 
Raymond  states  more  colloquially,  “Given  enough  eyeballs,  all 
bugs are shallow”. According to Raymond’s reasoning, diversity 
of  developer  perspectives  ought  to  be  embraced,  not  avoided. 
Therefore, more developers mean more vulnerabilities found and 
fixed, or even prevented.  
But does Linus’ Law hold up ad infinitum? Can a project have too 
many developers, resulting in insecure software? 
One  opposing  force  to  Linus’  Law  might  be  the  notion  of  “too 
many  cooks  in  the  kitchen”,  or  what  has  been  called  an 
unfocused  contribution 
in  developer  collaboration. 
Consider  having  many  people  make  a  meal:  without  enough 
coordination and communication, ingredients get skipped, added 
twice, or significant steps of the recipe are left out. The meal can 
suffer  as  a  result  of  too  many  people.  Likewise,  perhaps  the 
security of a software project can suffer as a result of unfocused 
contributions by too many developers.  
An  analysis  of 
the  structure  of  open  source  developer 
collaboration  can  help  the  community  understand  how  this 
structure  impacts  the  prevention  or  the  injection  of  security 
vulnerabilities. Our research objective, then, is to reduce security 
vulnerabilities by providing actionable insight into the structural 
nature of developer collaboration in open source software.  
We  performed  an  empirical  analysis  by  quantifying  developer 
collaboration and unfocused contributions into developer activity 
metrics. We examine the statistical correlation between the known 
security  vulnerabilities  of  the  open  source  Red  Hat  Enterprise 
Linux  4  kernel  and  developer  activity  metrics.  We  used  version 
control  change  logs  to  calculate  four  developer  activity  metrics. 
Forming social networks based on who worked on which file, we 
use  network  analysis  to  form  metrics  of  developer  groups  and 
unfocused contributions. 
The  rest  of  this  paper  is  organized  as  follows.  Section  2  covers 
background.  Sections  3  and  4  describe  the  case  study,  and 
derivation of the metrics themselves. Section 5 presents the results 
of  the  case  study  and  a  discussion.  Sections  6,  7,  and  8  discuss 
limitations, related work, and summarize the study. 
2.  BACKGROUND 
Our  empirical  analysis  involves  quantifying  measures  of  social 
networks  and  binary  classification.  In  this  section,  we  provide 
background  with  regard 
to  network  analysis  and  binary 
classification.  
4532.1  Network Analysis  
In this paper, we use network analysis to quantify how developers 
collaborate  on  projects.  We  use  several  terms  from  network 
analysis  [2]  and  define  their  meaning  with  respect  to  developer 
groups and unfocused contributions in Section 4. In this section, 
we  define  terms  used  in  both  analyses  of  developer  groups  and 
unfocused contributions. 
Network  analysis  is  the  study  of  characterizing  and  quantifying 
network  structures,  represented  by  graphs  [2].  In  network 
analysis, vertices of a graph are called nodes, and edges are called 
connections.  A  sequence  of  non-repeating,  adjacent  nodes  is  a 
path, and a shortest path between two nodes is called a geodesic 
path (note that geodesic paths are not necessarily unique).  In the 
case of weighted edges, the geodesic path is the path of minimum 
weight. Informally, a geodesic path is the “social distance” from 
one node to another.  
Centrality metrics are used to quantify the location of a node or 
edge relative to the rest of the network. In this study, we use the 
betweenness  metric  to  quantify  the  centrality  of  a  node  in  a 
network. The betweenness [2] of node n is defined as the number 
of geodesic paths that include n. Similarly, the edge betweenness 
of edge e is defined as the number of geodesic paths which pass 
through e. A high betweenness means a high centrality.  
2.2  Binary Classification 
To  study  the  security  of  a  system,  we  use  a  nominal  metric 
defined  over  each  file:  whether  or  not  a  file  is  vulnerable  or 
neutral. We consider a file to be vulnerable if the file was found 
to  have  at  least  one  vulnerability  that  required  a  patch  after 
release.  A  vulnerability  is  “an  instance  of  a  [fault]  in  the 
specification, development,  or  configuration  of  software  such  
that  its  execution  can  violate  an  [implicit  or explicit] security 
policy”. [8]. We consider a file with no known vulnerabilities to 
be “neutral”. 
Since  our  security  metric  is  nominal,  our  analysis  is  based  on 
binary  classification.  A  binary  classifier  can  make  two  possible 
types  of  errors:  false  positives  (FP)  and false negatives (FN). A 
FP is the classification of a neutral file as vulnerable, and a FN is 
the  classification  of  a  vulnerable  file  as  neutral.  Likewise,  a 
correctly  classified  vulnerable  file  is  a  true  positive  (TP),  and  a 
correctly  classified  neutral  file  is  a  true  negative  (TN).  For 
evaluating binary classification, we use recall, inspection rate, and 
area under the Receiver Operating Characteristic (ROC) curve.  
•  Recall  (R)  is  defined  as  the  proportion  of  vulnerabilities 
found: R=TP/(TP+FN).  
Inspection Rate (IR) is the proportion of total files that were 
classified as vulnerable: IR=(TP+FP) /(TP+TN+FP+FN). 
• 
•  Precision  (P)  is  defined  as  the  proportion  of  correctly 
predicted vulnerable files: P=TP/(TP+FP). 
•  Area  under  the  ROC  Curve  (AUC):  represents 
the 
proportion of the time that a classifier ranks a vulnerable file 
higher than a neutral file. AUC is calculated by integrating a 
ROC curve, usually by a summation approximation [24]. 
Optimally, IR is minimized, but Precision, Recall, and AUC are 
maximized. For example, an IR=10% and R=50% means that the 
classifier found 50% of the known vulnerabilities in just 10% of 
the  files.  A  classifier  with  P=25%  means  that,  of  the  files 
classified  as  vulnerable,  25%  were  actually  vulnerable.  A 
classifier with an AUC of 75% means that, given one randomly-
chosen neutral and vulnerable file, the classifier would choose the 
correct file 75% of the time.  
3.  CASE STUDY: LINUX KERNEL 
We  performed  a  case  study  on  the  Linux  kernel2  as  it  was 
distributed in the Red Hat Enterprise Linux 4 (RHEL4) operating 
system3.  A  summary  of  the  RHEL4  kernel  is  found  in  Table  1. 
The entire project is over three million lines of C and assembly 
code. The security data is a labeling of whether or not a source 
code 
file  was  patched  with  a  post-release  vulnerability 
(“vulnerable”  or  “neutral”).  The  developer  activity  metrics were 
gathered from version control change logs. 
Table 1: Summary of the RHEL4 Linux Kernel 
Total number of files 
Number  of  files  changed 
(total studied) 
Percentage of files changed 
Number of developers 
Development time 
Number of vulnerable files 
Percentage  of  changed  files 
with vulnerabilities 
Total number of commits 
14,286 
10,454  
73% 
557 
15 months 
205 
1.96% 
9,946 
tracing 
through 
involved 
the  security  data 
Gathering 
the 
development artifacts related to each vulnerability reported in the 
Linux  kernel.  When  members  of  the  open  source  community 
become aware of a possible security vulnerability, members of the 
Red Hat Security Response (RHSR) team perform the following 
actions.  
1.  Create a defect report in the Red Hat Bugzilla database4. The 
majority of the subsequent artifacts can be found or linked to 
the new defect report. 
2.  Confirm the existence of the vulnerability in both the current 
build  of  the  kernel  (also called the upstream version), and 
the previous release of the kernel (also called a backport).  
3.  Form patches to fix the problem as necessary. Sometimes an 
upstream  patch  would  differ  from  the  backport  patch  since 
the kernel is always evolving. 
4.  Determine if the vulnerability is a regression (a vulnerability 
introduced by a patch after release).  
5.  Register  the  vulnerability  in  the  National  Vulnerability 
Database  (NVD)  and  the  next  Red  Hat  Security  Advisory 
(RHSA). The RHSR Team reports NVD and RHSA data on 
their security metrics website5.  
We  collected  our  security  data  from  the  Bugzilla  database,  the 
NVD,  and  the  RHSR  security  metrics  database.  Since  each 
vulnerability was handled slightly differently, we examined each 
defect report manually to ensure that the backport patch was, in 
fact,  needed.  Since  we  are  only  interested  in  vulnerabilities  that 
2 http://kernel.org/ 
3 http://www.redhat.com/rhel/ 
4 http://bugzilla.redhat.com/ 
5 http://www.redhat.com/security/data/metrics/ 
454those  15  months, 
existed  at  the  time  of  release,  we  did  not  include  regressions  in 
our  data  set.  For  vulnerabilities  that  did  not  have  all  of  the 
relevant  artifacts  (e.g.  defect  reports,  backport  patches),  we 
consulted the director of the RHSR team to correct the data. Our 
data  set  is  a  comprehensive  list  of  reported,  non-regression 
vulnerabilities  from  RHEL4’s  release  in  February  2005  through 
July 2008. We found 205 files to be vulnerable (i.e. patched post-
release because of at least one vulnerability), which was 1.96% of 
the 10,454 files we studied. 
For the version control data from which developer activity metrics 
were computed, we used the Linux kernel source repository6. The 
RHEL4 operating system is based on kernel version 2.6.9, so we 
used all of the version control data from kernel version 2.6.0 to 
2.6.9,  which  was  approximately  15  months  of  development  and 
maintenance.  We included in our analysis source code files that 
had the following file name extension: .c, .S, and .h. The version 
control  data  contains  records  of  557  developers  and  9,946 
commits  over  10,454  source  files.  Most  of  the  kernel  files 
changed  (73%)  during 
including  every 
vulnerable file. Our study focused on the files that were changed 
15 months prior to release.  
4.  DEVELOPER ACTIVITY METRICS 
In  our  case  study,  we  used  the  version  control  logs  to  analyze 
development  activity.  As  a  project  progresses,  developers  make 
changes to various parts of the  system. With many changes and 
many  developers,  changes  to  files  tend  to  overlap:  multiple 
developers  may  end  up  working  on  the  same  files  around  the 
same time, indicating that they share a common contribution, or a 
connection,  with  another  developer.  As  a  result  of  which  files 
they  contribute  to,  some  developers  end  up  connected  to  many 
other  highly-connected  developers,  some  end  up  in  groups 
(“clusters”) of developers, and some tend to stay peripheral to the 
entire network.  
From a source code perspective, some files are contributed to by 
many  developers  who  are  also  making  contributions  to  many 