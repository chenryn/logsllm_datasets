title:HardFails: Insights into Software-Exploitable Hardware Bugs
author:Ghada Dessouky and
David Gens and
Patrick Haney and
Garrett Persyn and
Arun K. Kanuparthi and
Hareesh Khattri and
Jason M. Fung and
Ahmad-Reza Sadeghi and
Jeyavijayan Rajendran
HardFails: Insights into Software-Exploitable 
Hardware Bugs
Ghada Dessouky and David Gens, Technische Universität Darmstadt; Patrick Haney and 
Garrett Persyn, Texas A&M University; Arun Kanuparthi, Hareesh Khattri, and Jason 
M. Fung, Intel Corporation; Ahmad-Reza Sadeghi, Technische Universität Darmstadt; 
Jeyavijayan Rajendran, Texas A&M University
https://www.usenix.org/conference/usenixsecurity19/presentation/dessouky
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.HardFails: Insights into Software-Exploitable Hardware Bugs
Ghada Dessouky†, David Gens†, Patrick Haney∗, Garrett Persyn∗, Arun Kanuparthi◦,
Hareesh Khattri◦, Jason M. Fung◦, Ahmad-Reza Sadeghi†, Jeyavijayan Rajendran∗
†Technische Universität Darmstadt, Germany. ∗Texas A&M University, College Station, USA.
◦Intel Corporation, Hillsboro, OR, USA.
PI:EMAIL,PI:EMAIL,
PI:EMAIL,PI:EMAIL,PI:EMAIL,
PI:EMAIL,PI:EMAIL,
PI:EMAIL,PI:EMAIL
Abstract
Modern computer systems are becoming faster, more efﬁcient,
and increasingly interconnected with each generation. Thus,
these platforms grow more complex, with new features con-
tinually introducing the possibility of new bugs. Although the
semiconductor industry employs a combination of different
veriﬁcation techniques to ensure the security of System-on-
Chip (SoC) designs, a growing number of increasingly so-
phisticated attacks are starting to leverage cross-layer bugs.
These attacks leverage subtle interactions between hardware
and software, as recently demonstrated through a series of
real-world exploits that affected all major hardware vendors.
In this paper, we take a deep dive into microarchitectural
security from a hardware designer’s perspective by reviewing
state-of-the-art approaches used to detect hardware vulnera-
bilities at design time. We show that a protection gap currently
exists, leaving chip designs vulnerable to software-based at-
tacks that can exploit these hardware vulnerabilities. Inspired
by real-world vulnerabilities and insights from our industry
collaborator (a leading chip manufacturer), we construct the
ﬁrst representative testbed of real-world software-exploitable
RTL bugs based on RISC-V SoCs. Patching these bugs may
not always be possible and can potentially result in a product
recall. Based on our testbed, we conduct two extensive case
studies to analyze the effectiveness of state-of-the-art security
veriﬁcation approaches and identify speciﬁc classes of vulner-
abilities, which we call HardFails, which these approaches
fail to detect. Through our work, we focus the spotlight on
speciﬁc limitations of these approaches to propel future re-
search in these directions. We envision our RISC-V testbed
of RTL bugs providing a rich exploratory ground for future
research in hardware security veriﬁcation and contributing to
the open-source hardware landscape.
1 Introduction
The divide between hardware and software security research
is starting to take its toll, as we witness increasingly sophis-
ticated attacks that combine software and hardware bugs to
exploit computing platforms at runtime [20, 23, 36, 43, 45, 64,
69, 72, 74]. These cross-layer attacks disrupt traditional threat
models, which assume either hardware-only or software-only
adversaries. Such attacks may provoke physical effects to in-
duce hardware faults or trigger unintended microarchitectural
states. They can make these effects visible to software adver-
saries, enabling them to exploit these hardware vulnerabilities
remotely. The affected targets range from low-end embedded
devices to complex servers, that are hardened with advanced
defenses, such as data-execution prevention, supervisor-mode
execution prevention, and control-ﬂow integrity.
Hardware vulnerabilities. Cross-layer attacks circumvent
many existing security mechanisms [20, 23, 43, 45, 64, 69, 72,
74], that focus on mitigating attacks exploiting software vul-
nerabilities. Moreover, hardware-security extensions are not
designed to tackle hardware vulnerabilities. Their implemen-
tation remains vulnerable to potentially undetected hardware
bugs committed at design-time. In fact, deployed extensions
such as SGX [31] and TrustZone [3] have been targets of suc-
cessful cross-layer attacks [69, 72]. Research projects such
as Sanctum [18], Sanctuary [8], or Keystone [39] are also not
designed to ensure security at the hardware implementation
level. Hardware vulnerabilities can occur due to: (a) incor-
rect or ambiguous security speciﬁcations, (b) incorrect design,
(c) ﬂawed implementation of the design, or (d) a combination
thereof. Hardware implementation bugs are introduced either
through human error or faulty translation of the design in
gate-level synthesis.
SoC designs are typically implemented at register-transfer
level (RTL) by engineers using hardware description lan-
guages (HDLs), such as Verilog and VHDL, which are synthe-
sized into a lower-level representation using automated tools.
Just like software programmers introduce bugs to the high-
level code, hardware engineers may accidentally introduce
bugs to the RTL code. While software errors typically cause
a crash which triggers various fallback routines to ensure the
safety and security of other programs running on the platform,
no such safety net exists for hardware bugs. Thus, even mi-
USENIX Association
28th USENIX Security Symposium    213
nor glitches in the implementation of a module within the
processor can compromise the SoC security objectives and
result in persistent/permanent denial of service, IP leakage, or
exposure of assets to untrusted entities.
Detecting hardware security bugs. The semiconductor in-
dustry makes extensive use of a variety of techniques, such
as simulation, emulation, and formal veriﬁcation to detect
such bugs. Examples of industry-standard tools include In-
cisive [10], Solidify [5], Questa Simulation and Questa For-
mal [44], OneSpin 360 [66], and JasperGold [11]. These were
originally designed for functional veriﬁcation with security-
speciﬁc veriﬁcation incorporated into them later.
While a rich body of knowledge exists within the software
community (e.g., regarding software exploitation and tech-
niques to automatically detect software vulnerabilities [38,
46]), security-focused HDL analysis is currently lagging be-
hind [35, 57]. Hence, the industry has recently adopted a
security development lifecycle (SDL) for hardware [68] —
inspired by software practices [26]. This process combines
different techniques and tools, such as RTL manual code au-
dits, assertion-based testing, dynamic simulation, and auto-
mated security veriﬁcation. However, the recent outbreak of
cross-layer attacks [20, 23, 37, 43, 45, 47, 48, 49, 51, 52, 53,
64, 69, 74] poses a spectrum of difﬁcult challenges for these
security veriﬁcation techniques, because they exploit complex
and subtle inter-dependencies between hardware and software.
Existing veriﬁcation techniques are fundamentally limited in
modeling and verifying these interactions. Moreover, they
also do not scale with the size and complexity of real-world
SoC designs.
Goals and Contributions. In this paper, we show that cur-
rent hardware security veriﬁcation techniques are fundamen-
tally limited. We provide a wide range of results using a
comprehensive test harness, encompassing different types
of hardware vulnerabilities commonly found in real-world
platforms. To that end, we conducted two case studies to
systematically and qualitatively assess existing veriﬁcation
techniques with respect to detecting RTL bugs. Together
with our industry partners, we compiled a list of 31 RTL
bugs based on public Common Vulnerabilities and Exposures
(CVEs) [37, 43, 50, 54, 55] and real-world errata [25]. We in-
jected bugs into two open-source RISC-V-based SoC designs,
which we will open-source after publication.
We organized an international public hardware security
competition, Hack@DAC, where 54 teams of researchers
competed for three months to ﬁnd these bugs. While a number
of bugs could not be detected by any of the teams, several
participants also reported new vulnerabilities of which we
had no prior knowledge. The teams used manual RTL inspec-
tion and simulation techniques to detect the bugs. In industry,
these are usually complemented by automated tool-based and
formal veriﬁcation approaches. Thus, our second case study
focused on two state-of-the-art formal veriﬁcation tools: the
ﬁrst deploys formal veriﬁcation to perform exhaustive and
complete veriﬁcation of a hardware design, while the second
leverages formal veriﬁcation and path sensitization to check
for illegal data ﬂows and fault tolerance.
Our second case study revealed that certain properties of
RTL bugs pose challenges for state-of-the-art veriﬁcation
techniques with respect to black-box abstraction, timing ﬂow,
and non-register states. This causes security bugs in the RTL
of real-world SoCs to slip through the veriﬁcation process.
Our results from the two case studies indicate that particu-
lar classes of hardware bugs entirely evade detection—even
when complementing systematic tool-based veriﬁcation ap-
proaches with manual inspection. RTL bugs arising from
complex and cross-modular interactions in SoCs render these
bugs extremely difﬁcult to detect in practice. Furthermore,
such bugs are exploitable from software, and thus can com-
promise the entire platform. We call such bugs HardFails.
To the best of our knowledge, this is the ﬁrst work to pro-
vide a systematic and in-depth analysis of state-of-the-art
hardware veriﬁcation approaches for security-relevant RTL
bugs. Our ﬁndings shed light on the capacity of these tools and
demonstrate reproducibly how bugs can slip through current
hardware security veriﬁcation processes. Being also software-
exploitable, these bugs pose an immense security threat to
SoCs. Through our work, we highlight why further research
is required to improve state-of-the-art security veriﬁcation of
hardware. To summarize, our main contributions are:
• Systematic evaluation and case studies: We compile
a comprehensive test harness of real-world RTL bugs, on
which we base our two case studies: (1) Hack@DAC’18,
in which 54 independent teams of researchers competed
worldwide over three months to ﬁnd these bugs using
manual RTL inspection and simulation techniques, and
(2) an investigation of the bugs using industry-leading
formal veriﬁcation tools that are representative of the
current state of the art. Our results show that particular
classes of bugs entirely evade detection, despite combin-
ing both tool-based security veriﬁcation approaches and
manual analysis.
• Stealthy hardware bugs: We identify HardFails as
RTL bugs that are distinctly challenging to detect using
industry-standard security veriﬁcation techniques. We
explain the fundamental limitations of these techniques
in detail using concrete examples.
• Open-sourcing: We will open-source our bugs testbed
at publication to the community.
2 SoC Veriﬁcation Processes and Pitfalls
Similar to the Security Development Lifecycle (SDL) de-
ployed by software companies [26], semiconductor compa-
nies [15, 35, 40] have recently adapted SDL for hardware
design [57]. We describe next the conventional SDL process
for hardware and the challenges thereof.
214    28th USENIX Security Symposium
USENIX Association
tedious, and complex process even for industry experts. Exist-
ing techniques largely rely on human expertise to deﬁne the
security test cases and run the tests. The correct security spec-
iﬁcations must be exhaustively anticipated, identiﬁed, and
accurately and adequately expressed using security properties
that can be captured and veriﬁed by the tools. We discuss
these challenges further in Section 7.
Besides the speciﬁcations, the techniques and tools them-
selves are not scalable and are less effective in capturing
subtle semantics that are relevant to many vulnerabilities,
which is the focus of this work. We elaborate next on the lim-
itations of state-of-the-art hardware security veriﬁcation tools
commonly used by industry. To investigate the capabilities of
these tools, we then construct a comprehensive test-harness
of real-world RTL vulnerabilities.
3 Assessing Hardware Security Veriﬁcation
In this section, we focus on why the veriﬁcation of the secu-
rity properties of modern hardware is challenging and provide
requirements for assessing existing veriﬁcation techniques
under realistic conditions. First, we describe how these ver-
iﬁcation techniques fall short. Second, we provide a list of
common and realistic classes of hardware bugs, which we
use to construct a test harness for assessing the effectiveness
of these veriﬁcation techniques. Third, we discuss how these
bugs relate to the common security goals of a chip.
3.1 Limitations of Automated Veriﬁcation
Modern hardware designs are highly complex and incorpo-
rate hundreds of in-house and third-party Intellectual Property
(IP) components. This creates room for vulnerabilities to be
introduced in the inter-modular interactions of the design hi-
erarchy. Multi-core architectures typically have an intricate
interconnect fabric between individual cores (utilizing com-
plex communication protocols), multi-level cache controllers
with shared un-core and private on-core caches, memory and
interrupt controllers, and debug and I/O interfaces.
For each core, these components contain logical modules
such as fetch and decode stages, an instruction scheduler, indi-
vidual execution units, branch prediction, instruction and data
caches, the memory subsystem, re-order buffers, and queues.
These are implemented and connected using individual RTL
modules. The average size of each module is several hundred
lines of code (LOC). Thus, real-world SoCs can easily ap-
proach 100,000 lines of RTL code, and some designs may
even have millions of LOC. Automatically verifying, at the
RTL level, the respective interconnections and checking them
against security speciﬁcations raises a number of fundamen-
tal challenges for the state-of-the-art approaches. These are
described below.
L-1: Cross-modular effects. Hardware modules are inter-
connected in a highly hierarchical design with multiple inter-
FIGURE 1: Typical Security Development Lifecycle (SDL)
process followed by semiconductor companies.
2.1 The Security Development Lifecycle
(SDL) for Hardware
SDL is conducted concurrently with the conventional hard-
ware development lifecycle [68], as shown in Figure 1. The
top half of Figure 1 shows the hardware development lifecy-
cle. It begins with design exploration followed by deﬁning
the speciﬁcations of the product architecture. After the archi-
tecture speciﬁcation, the microarchitecture is designed and
implemented in RTL. Concurrently, pre-silicon veriﬁcation
efforts are conducted until tape-out to detect and ﬁx all func-
tional bugs that do not meet the functional speciﬁcation. After
tape-out and fabrication, iterations of post-silicon validation,
functional testing, and tape-out "spins" begin. This cycle is re-
peated until no defects are found and all quality requirements
are met. Only then does the chip enter mass production and
is shipped out. Any issues found later in-ﬁeld are debugged,
and the chip is then either patched if possible or recalled.
After architectural features are ﬁnalized, a security assess-
ment is performed, shown in the bottom half of Figure 1. The
adversary model and the security objectives are compiled in
the security speciﬁcation. This typically entails a list of assets,
entry points to access these assets, and the adversary capa-
bilities and architectural security objectives to mitigate these
threats. These are translated into microarchitectural security
speciﬁcations, including security test cases (both positive and
negative). After implementation, pre-silicon security veriﬁca-
tion is conducted using dynamic veriﬁcation (i.e., simulation
and emulation), formal veriﬁcation, and manual RTL reviews.
The chip is not signed off for tape-out until all security speciﬁ-
cations are met. After tape-out and fabrication, post-silicon se-
curity veriﬁcation commences. The identiﬁed security bugs in
both pre-silicon and post-silicon phases are rated for severity
using the industry-standard scoring systems such as the Com-
mon Vulnerability Scoring System (CVSS) [30] and promptly
ﬁxed. Incident response teams handle issues in shipped prod-
ucts and provide patches, if possible.
2.2 Challenges with SDL
Despite multiple tools and security validation techniques used
by industry to conduct SDL, it remains a highly challenging,
USENIX Association
28th USENIX Security Symposium    215
dependencies. Thus, an RTL bug located in an individual
module may trigger a vulnerability in intra- and inter-modular
information ﬂows spanning multiple complex modules. Pin-
pointing the bug requires analyzing these ﬂows across the
relevant modules, which is highly cumbersome and unreliable
to achieve by manual inspection. It also pushes formal veri-
ﬁcation techniques to their limits, which work by modeling
and analyzing all the RTL modules of the design to verify
whether design speciﬁcations (expressed using security prop-
erty assertions, invariants and disallowed information ﬂows)
and implementation match.
Detecting such vulnerabilities requires loading the RTL
code of all the relevant modules into the tools to model and
analyze the entire state space, thus driving them quickly
into state explosion due to the underlying modeling algo-
rithms [16, 21]. Alleviating this by providing additional com-
putational resources and time is not scalable as the complexity
of SoCs continues to increase. Selective "black-box" abstrac-
tion of some of the modules, state space constraining, and
bounded-model checking are often used. However, they do
not eliminate the fundamental problem and rely on interactive
human expertise. Erroneously applying them may introduce
false negatives, leading to missed vulnerabilities.
L-2: Timing-ﬂow gap. Current industry-standard techniques
are limited in capturing and verifying security properties re-
lated to timing ﬂow (in terms of clock cycle latency). This
leads to vast sources of information leakage due to software-
exploitable timing channels (Section 8). A timing ﬂow exists
between the circuit’s input and output when the number of
clock cycles required for the generation of the output depends
on input values or the current memory/register state. This can
be exploited to leak sensitive information when the timing
variation is discernible by an adversary and can be used to
infer inputs or memory states. This is especially problematic
for information ﬂows and resource sharing across different
privilege levels. This timing variation should remain indis-