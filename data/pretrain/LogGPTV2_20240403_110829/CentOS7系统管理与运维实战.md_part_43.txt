窗口将自动显示发现结果。此时需要单击右侧的“登录全部”按钮，并单击发现的LUN之前
此时窗口将自动显示发现目标按钮。单击发现目标并输入地址和端口号，然后单击“发现”，
完成常规设置后，需要单击系统选项为虚拟机设置合适的内存大小、CPU数量及时区。
在新建虚拟机窗口中选择合适的操作系统，并在名称中为操作系统命名，然后在nic1后
在前面几个小节中介绍了如何建立一个最基本的oVirt单节点平台，在确认所有资源都可
在名称中输入iSCSI名称，数据中心选择“(none)”，域功能/存储类型选择“Data/iSCSI"，
隐藏高级选项
自定义属性
引导选项
资源分配
高可用性
控制台
初始运行
系统
常规
新建虚拟机
随机数生成器
建立虚拟机
当数据中心的类型为共享，并且拥有活动主机的情况下才能附加。
iSCSI存储通常是全局性的，只有附加到某个数据中心上才能使用。附加时需要注意只有
类型
操作系统
模板子版本
基于模板
Stateless
集群
nici
选择一个WNIC配置档案来实例化VM网络接口。
ovirtmgmt/ovirtmgmt
以暂停模式启动
图10.33新建虚拟机
第10章KVM虚拟化和oVirt 虚拟化管理平台
删除保护
，因此可以选择“ovirtmgmt”使用管理网
CentoS5.5
服务器
自定义
Red HatEnterpriseLinux5.x
基础模板（1）
Blank
MyCluster/MyDC
确定取消
305
---
## Page 318
出的菜单中选择“控制台”，即可打开虚拟机的控制台，如图10.36所示。
拟磁盘，如图10.35所示。
骤之后，即可单击“确定”按钮完成创建。接下来会弹出引导窗口，要求用户为虚拟机添加虚
CentOS7系统管理与运维实战
306
的菜单中选择“运行”，即可打开虚拟机电源。打开虚拟机电源后，可以再次单击右键，在弹
“外部（直接LUN）”将iSCSI存储作为虚拟磁盘使用。
添加完虚拟磁盘后，虚拟机就已经添加完成了。可以选择虚拟机，然后单击右键，在弹出
在添加虚拟磁盘窗口中，直接输入磁盘大小并选择相应的存储域即可完成添加，也可勾选
在引导序列中勾选附加CD选项，并在之后的选择框中选择合适的光盘映像，完成所有步
存储域
分配肇略
大小（GB)
涉加虚拟磁盘
OiskProfile
附加CD
第二个设备
引导序列：
第一个设备
Centos
蜜看（V）
node_local
node_local空闲429GB/总计452
Thin Provision
CentOS5.5Disk1
CentOS5.5:1-按SHIFT+F12释放光标-RemoteViewer
图10.36虚拟机控制台
图10.35添加虚拟磁盘
图10.34添加光盘引导
[None]
硬盘
C
只读的
激活
吊
可共享的
郭余后清理
G
---
## Page 319
的小型企业中却应用非常广泛。
方案，及当前最新的oVirt管理平台。虽然在大型企业中，这些平台应用较少，但在经费紧张
RHEL7的虚拟化技术。本章以KVM虚拟化为起点，介绍了CentOS7中的KVM虚拟化解决
10.3
关内容，此处不再赘述。
当今的互联网以云计算和虚拟化技术为主体，CentOS7在发布之初就已经吸收整合了
关于虚拟机控制台程序的安装说明，可参考oVirt主界面链接“控制台客户资源”中的相
小结
第10章KVM虚拟化和oVirt虚拟化管理平台
307
---
## Page 320
介绍一些最常见的分布式文件系统。
点上，以提供更快的速度、更大的容量及更好兀余特性。
模式。流行的模式是当客户机需要存储数据时，服务器指引其将数据分散地存储到多个存储节
意义上的分布式文件系统大多都是由多个节点计算机构成的，结构上是典型的客户机/服务器
本地节点相联（即非直联存储），而是分布于计算机网络中的一个或多个节点计算机上。目前
11.1.1分布式文件系统
介绍分布式文件系统及GlusterFS。
司于2011年收购 Gluster 公司，并将GlusterFS 作为其大数据解决方案的一部分。本节将简单
的设计，让整个服务没有单点故障的隐患。正是由于GlusterFS 拥有众多优秀的特点，红帽公
GlusterFS具有高扩展性、高可用性、高性能、可横向扩展等特点，并且其没有元数据服务器
布式前端及高达数百 PB 级别扩展性的开源分布式文件系统。相比其他分布式文件系统，
署与应用。
在研究、测试并使用GlusterFS，而国内目前正处于起步阶段，本章将简要介绍GlusterFS 的部
通常称其与MooseFS、CEPH、Lustre 为四大开源分布式文件系统。国外有众多互联网从业者
目前流行的分布式文件系统有许多，如 MooseFS、OpenAFS、GoogleFS 等，下面将简要
分布式文件系统（Distributed File System）是指文件系统管理的物理存储资源并不直接与
GlusterFS 最早由Gluster公司开发，其目标是开发出一个能为客户提供全局命名空间、分
本章主要涉及的内容有：
GlusterFS 是近年来兴起的一个开源分布式文件系统，其在开源社区活跃度很高，互联网
GlusterFS部署与应用
GlusterFS存储结构简介
GlusterFS 概述
GlusterFs存储
第11章
---
## Page 321
然后再向数据存储服务器请求并获得数据。其写过程与读过程正好相反，如图11.2所示。
收或传输客户数据等。MooseFS的读过程如图11.1所示。
器出问题时能恢复工作；数据存储服务器主要工作是听从管理服务器调度，提供存储空间，接
理及节点间的数据拷贝等；元日志服务器主要用来备份管理服务器的变化日志，以便管理服务
（chunkservers）构成，管理服务器主要作用是管理数据存储服务器，文件读写控制、空间管
如图11.1中的读取数据过程，客户首先向master询问数据存放在哪些数据存储服务器上，
MooseFS 主要由管理服务器（master）、元日志服务器（Metalogger）、数据存储服务器
1.MooseFS
CLIENTS
CLIENTS
图11.2MooseFS写数据过程
图11.1MooseFS读数据过程
Savethedata
MASTERSERVER
MASTERSERVER
OPTIONALLY)
CHUNKSERVERS
CHUNKSERVERS
第11章GlusterFS存储
6Success
309
---
## Page 322
CentOS7系统管理与运维实战
310
能分布式文件系统。其结构如图11.4所示。
100Gbit/s 以上传输速度。在气象、石油等领域应用十分广泛，是目前比较成熟的解决方案之
同参与操作。
数据时，主要的操作集中在MDSs和OSSs间；写入数据时就需要MGSs、MDSs及OSSs共
OSSs）和管理服务器（Management Servers，MGSs）组成。与MooseFS类似，当客户端读取
所示。
MooseFS具有单点故障隐患，一旦master无法工作，整个分布式文件系统都将停止工作。
由客户将数据分散地存放在数据存储服务器上，最后向master发出写入结束信号。
MooseFS 结构简单，最适合初学者理解分布式文件系统的工作过程。但也存在较大问题，
Ceph的目标是建立一个容量可扩展至PB 级、高可靠性，
Lustre 主要面对是的海量级的数据存储，支持多达10000 个节点、PB 级的数据存储、
Lustre 是一个比较典型的高性能面向对象的文件系统，其结构相对比较复杂，如图 11.3
3.Ceph
Lustre由元数据服务器（Metadata Servers,MDSs）对象存储服务器（Object Storage Servers，
2.Lustre
写数据时，客户先向master 发出请求，master查询剩余空间后将存储位置返回给客户，
MM2
SManagemens)
InfiniBand network
SerMeradatps)
图11.3Lustre结构
=failover capability
包
Sobiet toras
R
OSS
OSS2
，并且支持多种工作负载的高性
CommodityStorage
---
## Page 323
信息。这样做的好处是每个节点都拥有节点的配置信息，高度自治，所有信息都可以在本地查
时有元数据服务的分布式文件系统的查询效率反而会高许多。
能会大幅下降，因为列出文件或目录时，需要查询所在节点并对各节点中的信息进行聚合。
著的特点是如果给定确定的文件名，查找文件位置会非常快。但如果需要列出文件或目录，
位，并执行读写访问操作。
群中的任何服务器、客户端都可利用哈希算法、路径及文件名进行计算，就可以对数据进行定
系统而言，GlusterFS 并没有集中或分布式的元数据的概念，取而代之的是弹性哈希算法。集
理服务器，主要作用就是用来管理文件与数据区块之间的存储位置关系。相较其他分布式文件
个文件或某个区块存储的位置。传统分布式文件系统大都会设置元数据服务器或功能相近的管
势。本小节将简要介绍GlusterFS存储的特点。
11.1.2
再赘述。
许多，例如 GridFS、mogileFS、TFS、FastDFS 等。读者可自行参考相关资料了解，此处不
别适合于云计算。
来监视整个集群。Ceph 在文件一致性、容错性、高性能、扩展性等方面都有显著的优势，特
服务器主要用来缓存和同步分布式元数据；对象存储集群用来存储数据和元数据；监视器则用
本小节简单介绍了最具代表性的几个分布式文件系统，但目前成熟的分布式文件系统还有
在之前的版本中服务器间的关系是对等的，也就是说每个节点服务器都掌握了集群的配置
这种设计带来的好处是极大地提高了扩展性，同时也提高了系统的性能和可靠性；另一
2.服务器间的部署
元数据是用来描述一个文件或给定区块在分布式文件系统中所在的位置，简而言之就是某
1.无元数据设计
GlusterFS与其他分布式文件系统相比，在扩展性、高性能、维护性等方面都具有独特优
Ceph主要由元数据服务器（MDSs）、对象存储集群（OSDs）和集群监视器组成，元数据
GlusterFS 概述
CephFSKernel Object
OSDs
CephStorageClusterProtocol(librados)
Ceph FS Library (libcephfs)
图11.4Ceph结构
MDSS
CephFSFUSE
Monitors
第11章GlusterFS存储
311
此
香
---
## Page 324
本小节将介绍了其中一部分，其他方面的特点还有许多，此处不再赘述，读者可自行参阅相关
终经过网络将请求或数据发送到GlusterFSServer上。
余程度等方面自行取舍。
GlusterFS未来的版本有向集中式管理变化的趋势。
询。每个节点的信息更新都会向其他节点通告，保证节点间信息的一致性。但如果集群规模较
CentOS7系统管理与运维实战
312
文档了解。
常管理工作。这对一套分布式文件系统而言，GlusterFS 的管理工作无疑是非常简便的。
系统，在懂得Linux管理知识的基础之上，再加上2~3小时的学习就可以完成GlusterFS的日
的命令行工具，二者相结合就可以完成GlusterFS 的管理工作。由于整套系统都是基于Linux
又会通过设备/dev/fuse 将数据交给GlusterFS Client。最后经过GlusterFS Client 的计算，并最
（VirtualFileSystem，虚拟文件系统）来处理，VFS会将请求交给FUSE内核模块，而FUSE
用户和程序根本感觉不到文件系统是本地还是在远端服务器上。读写操作将会被交给VFS
大，节点众多时，信息同步的效率就会下降，节点间信息的非一致性概率就会大大提高。因此
作为一款获得红帽青睐的开源分布式文件系统，GlusterFS 无疑有许多值得关注的地方。
GlusterFS 还支持多种集群模式，组成诸如磁盘阵列状的结构，让用户在数据可靠性、冗
GlusterFS 在提供了一套基于Web GUI的基础上，还提供了一套基于分布式体系协同合作
4.可管理性
首先程序通过访问挂载点的形式读写数据，对于用户和程序而言，集群文件系统是透明的，
当客户端访问GlusterFS存储时，其流程如图11.5所示。
3.客户端访问
Fileoperation
Client
pCopcipcapcs
AFR-0AFR-1
DHT trar
Clienttranslators
Kerrel space
User space
图11.5客户端访问流程
slator
TCP/IPorinfiniband
POSIXtranslator
XFS
VFS
品
Server
Servertranslato
User
---
## Page 325
存放的内容都完成相同，其结构如图11.7所示。
硬件上做数据余，例如磁盘阵列RAID等。
是没有任何余功能，任何一个节点失败都会导致数据丢失。分布式GlusterFS 卷需要在底层
布式GlusterFS。这种卷的好处是非常便于扩展，且组成卷的服务器容量可以不必相同，缺点
存放到组成分布式卷的所有服务器上。创建分布式卷时，如果没有特别的指定，将默认使用分
11.6所示。
支持多种集群模式，本小节将简要介绍几种常见的模式。
11.1.3
·复制GlusterFS卷（Replicated Glusterfs Volume）同RAID1类似，所有组成卷的服务器中
GlusterFS集群的模式是指数据在集群中的存放结构，类似于磁盘阵列中的级别。GlusterFS
2.复制GlusterFS卷
分布式GlusterFS 卷的结构相对比较简单，存放文件时并没有特别的规则，仅仅是将文件
分布式 GlusterFS 卷（Distributed Glusterfs Volume）是一种比较常见的松散式结构，如图
复制 GlusterFS 卷的原理是将文件复制到所有组成分布式卷的服务器上。在创建分布式卷
1.分布式GlusterFS卷
GlusterFS集群的模式
图11.6分布式GlusterFS卷
图11.7复制GlusterFS卷
servert:/exp1
server1:/exp1
File1
Fie1
Distributed Volume
D
Fite？
server2:/exp2
第11章GlusterFS存储
313
---
## Page 326
Gluster卷的特点，其结构如图 11.8所示。
数量。由于复制GlusterFS 卷会在不同的服务器上保存数据的副本，当其中一台服务器失效后，
时需要指定复制的副本数量，通常是2或者3，但副本数量一定要小于或等于组成卷的服务器
CentOS7系统管理与运维实战
314
如图11.9所示。
高的环境而开发的。
带化，但分布式复制GlusterFS 卷则没有。这种卷实际上是针对数据余和可靠性要求都非常
据冗余功能。
可以从另一台服务器读取数据，因此复制GlusterFS卷提高了数据可靠性的同时，还提供了数
4.条带化GlusterFS卷
分布式复制GlusterFS卷的结构看起来类似RAID10，但其实不同，RAID10其实质是条
条带化GlusterFS卷（Striped GlusterfsVolume）是专门针对大文件，多客户端而设置的，
3.分布式复制GlusterFS卷
图11.8分布式复制GlusterFS 卷
图11.9条带化GlusterFS卷
erver1
Brnck
servert:/exp1
File.1
Replicated
serverz
Distributed Volume
Striped Volume
9
server3
Brick
server2/exp2
Fie2
server4
---
## Page 327
CentOS7中的部署和应用。
使得当下许多Linux发行版和软件都已经包含并支持GlusterFS。本节将简要介绍GlusterFS在
#示
还是分布式条带化GlusterFS，其性能都与服务器数量有关。
此时将分布式与条带化结合起来是一个比较好的选择。需要注意的是，无论是条带化GlusterFS
大的文件，其结构如图11.10所示。
如同负载均衡。条带化GlusterFS 卷的缺点是不能提供数据余功能。
允许将体型较大的文件分拆并存放到多台服务器上，当客户端进行访问时就能分散压力，效果
时，性能就会急剧下降。此时使用条带化的GlusterFS就可以解决这个问题，条带化Gluster