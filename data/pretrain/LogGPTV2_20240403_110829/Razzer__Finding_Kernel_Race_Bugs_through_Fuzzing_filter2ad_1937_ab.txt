Kernel thread A
Kernel thread B
266:    if (n_hdlc->flag & TCXONC)
while (list_empty(free_list)) {
267:
268:              buf = pop_front(free_list);
269:              kfree(buf);
270:    }
Post-race (harmful) behavior
Kernel Thread A
àº‘ : Syzkallerâ€™s multi-thread execution
âƒ : SKIâ€™s randomized thread interleaving
Kernel Thread B
Fig. 2: Race detection mechanisms of Syzkaller and SKI
Fig. 1: A simpliï¬ed race example on CVE-2017-2636. As a user pro-
gram executes two syscalls concurrently, a data race on n_hdlc->tbuf
may occur depending on the execution order, which leads to a double-
free issue allowing an attacker to launch privilege escalation attack.
R1: Find an input program which executes RacePaircand.
More precisely, an analysis should discover a multi-threaded
user-land program, where each thread in the program executes
each instruction in RacePaircand.
in Figure 1). If not, it pushes the pointer to the free list (line 432)
such that actual free operations will occur later. Then, two
memory instructions, n_hdlc->tbuf = null in kernel thread
A (i.e., RPA in line 440) and tbuf = n_hdlc->tbuf (i.e., RPB
in line 216) in kernel thread B, enter into data races. More
speciï¬cally, if the address of n_hdlc->tbuf is identical in
kernel threads A and B, the computational result will differ
depending on the execution orders of these instructions. That
is, if RPB is executed ï¬rst and RPA is executed later, as
ordered in Figure 1, all of the subsequent instructions of kernel
thread B will see a non-null pointer stored in a local variable
tbuf despite the fact that it has already been pushed to the
free_list by the kernel thread A. Thus, tbuf will remain a
valid pointer (line 217); hence, n_hdlc->tbuf will be pushed
to the free_list (line 218) again by kernel thread B. Note
that if RPA is executed ï¬rst, tbuf of B will hold a null pointer
and thus a redundant free list push would not arise.
To launch a security attack based on this race, proper
post-race harmful behaviors are necessary. In this example,
ioctl(fd, TCXONC) from the user program should be invoked
to perform the actual free operation stored in the free list,
which eventually leads to the double-free.
B. Design Requirements
In this subsection, we ï¬rst identify desirable design re-
quirements to discover data races in the kernel. Then we
revisit existing tools from the perspective of meeting such
requirements.
Design Requirements. One important design goal of RAZZER
is to avoid any false positives in during the race detection
process. Towards achieving this goal, we identify the following
two desirable design requirements in order to discover data
races in the kernel.
R2: Find a thread interleaving for the input program which
executes RacePaircand concurrently.
In other words, as R1 alone does not ensure that RacePaircand
can be executed concurrently to trigger data races, the analysis
should identify a speciï¬c thread interleaving case that executes
RacePaircand concurrently.
We ï¬nd that existing tools mostly focus on meeting only one
of the two requirements above, limiting the effectiveness of
discovering unknown races. Below, we present our analysis of
the requirements of two general techniques to identify race bugs,
namely fuzz testing and random thread interleaving, to discuss
how well they meet the two aforementioned requirements.
Requirement Study: Traditional Fuzz Testing. Traditional
fuzz testing (such as AFL to fuzz user-land programs and
Syzkaller [42] to fuzz the kernel) focuses on R1, attempting
to ï¬nd inputs extending the kernel code coverage. Because
R2 is not considered at all, it is not effective to discover
data races. To better illustrate this limitation, the ï¬lled circles
in Figure 2 depict the execution ï¬‚ow of Syzkaller as it ï¬nds
race bugs. With regard to Syzkaller, the core of its fuzzing
to ï¬nd races is linked to its execution of randomly generated
(or mutated) syscalls, where each syscall is again randomly
assigned either to user thread A or B. Although this indeed
interleaves the execution of syscalls into one of two kernel
threads (i.e., syscalli-1), its chance to trigger a race would be
very low. According to our evaluation in Â§V-D1, Syzkaller
failed to ï¬nd races of three previously known race bugs given
10 hours. In contrast, RAZZER found all three races within
from 7 mins to 26 mins, meaning that RAZZER was faster than
Syzkaller 23 times to 85 times at least.
Requirement Study: Thread Interleaving Tools. Regarding
random thread interleaving tools (such as SKI [16] or the PCT
Algorithm [10]), their focus is in meeting R2, attempting to
(cid:24)(cid:22)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:09 UTC from IEEE Xplore.  Restrictions apply. 
explore all possible thread interleaving cases for a speciï¬c (and
static) input program. As they do not consider R1, they can only
run existing programs (such as benchmarks) and thus cannot
efï¬ciently explore massive code spaces, leaving a majority part
of the kernel untested. Moreover, because thread interleaving
tools are based on random scheduling, their efï¬ciency on R2
alone (i.e., simply searching all thread interleaving cases) is
also severely limited. More precisely, in the beginning SKI
randomly selects one kernel thread, and then executes it until
encountering any memory access instruction. After stopping at
the memory instruction, it randomly selects the kernel thread
again, and repeats this process. For example, the unï¬lled circles
in Figure 2 illustrate the execution ï¬‚ow of SKI. First, it selects
kernel thread B ( 1 ) randomly, and executes until the next
memory access instruction. It then randomly selects the kernel
thread A ( 2 ) again and repeats this process. This explores
all possible thread interleaving cases to identify race bugs
for a given program, but large search spaces of interleaving
cases would make it inefï¬cient. According to our evaluation
in Â§V-D2, SKIEmu (i.e., an emulated version of SKI) requires
an exploration of interleaving cases from 6,435 to 27,132
to identify three previously known races. However, RAZZER
only requires the exploring of 23 to 56 interleaving cases (i.e.,
RAZZER is 30 to 398 times more efï¬cient than SKIEmu).
III. DESIGN
In this section, we describe the design details of RAZZER.
The key idea behind RAZZER is in driving the analysis towards
potential data race points in the kernel. In particular, RAZZER
takes a hybrid approach, leveraging both static and dynamic
analysis. First, RAZZER performs a static analysis to obtain
over-approximated potential data race points. Next, RAZZER
conducts a two-staged dynamic analysis. The ï¬rst stage is
single-thread fuzz testing, which focuses on identifying a
single-thread input program that executes potential race points
(attempting to meet R1). The second stage is multi-thread fuzz
testing. During this stage, a multi-thread program is constructed
with the help from the ï¬rst stage, utilizing a custom hypervisor
to control the thread interleaving deterministically (attempting
to meet R2). Once a race is found, RAZZER outputs a concrete
user program (i.e., a program triggering the data race) as well
as the detailed root cause information (i.e., a report describing
where the data race occurred) such that kernel developers can
easily understand the root cause of the race and accordingly
patch it.
In the following paragraphs, Â§III-A ï¬rst describes how
RAZZER performs its static analysis to obtain potential data
race points. Then Â§III-B describes how RAZZER tailors the
hypervisor to trigger the race deterministically for its dynamic
analysis. Lastly, Â§III-C illustrates dynamic fuzz testing by
RAZZER
A. Identifying Race Candidates
The goal of our static analysis is to identify all RacePaircand
(i.e., a set of race candidate pairs) in the kernel, where each
RacePaircand consists of two memory access instructions and
may entail the potential to race at runtime. In general, a points-
to analysis would be a popular choice to collect RacePaircand
since it reasons about where each memory instruction points
to. However, it is well known that the points-to analysis is
limited in terms of accuracy and performance. With regard
to accuracy, the points-to analysis is associated with high
false positive rates as precise (and concrete) control/data-ï¬‚ow
information can only be known at runtime. Even worse, it
is more challenging to handle race issues because it requires
not only precise control/data-ï¬‚ow information but also precise
concurrency information, which is heavily impacted by external
factors (such as scheduling or synchronization primitives).
Moreover, given the time complexity of a typical points-to
analysis (i.e., an Andersen analysis [6]) is O(n3), where n
denotes the size of the program to be analyzed, it would take
a very long time to analyze the entire kernel.
RAZZER addresses these issues with the following two
approaches. First, to address accuracy issues, RAZZER allows
the points-to analysis to over-approximate a RacePaircand set
(i.e., some RacePaircand may not be RacePairtrue), and it
resolves false positive issues through its dynamic fuzz testing,
as described later (Â§III-C). RAZZERâ€™s points-to analysis is
context-insensitive and ï¬‚ow-insensitive but ï¬eld-sensitive. Thus,
it over-approximates RacePairscand while excluding pairs that
must not race (e.g., RAZZER determines that two instructions
must not race if accessing different member variables in the
structure).
Second, in order to mitigate performance issues, RAZZER
performs a tailored partition analysis of the kernel. It partitions
kernel objects according its module component, and performs
a pre-analysis for every module. Especially for the Linux
kernel, our point-to analysis partitions the kernel based on
the directory structure in the source code repository (e.g.,
kernel, mm, fs, drivers), as each subdirectory represents a
well-conï¬ned module. When performing a pre-analysis per
module, RAZZER always provides core kernel modules as
well, which remains necessary irrespective of the module
being analyzed. For example, RAZZER always includes fs
and net/core, as these two modules are used globally by
many other sub-modules.
It is worth noting that our static analysis does not consider
synchronization primitives in the kernel (e.g., read_lock(),
br_read_lock(), spin_lock_irqsave(), up()). Leveraging
this information would reduce the false positive rate (as it
can help to determine memory pairs that must not race), and
we leave this as future work.
B. Per-Core Scheduler in Hypervisor
As discussed earlier in Â§II, a race condition rarely manifests
itself due to the non-deterministic and random nature of kernelâ€™s
thread interleaving. Therefore, RAZZER runs the target kernel
on a tailored virtualized environment such that RAZZER avoids
non-deterministic behaviors from external events. In other
words, RAZZER runs a multi-thread program in the guest
user space, and this program attempts to trigger a race in
the guest kernel. Moreover, for complete control over guest
(cid:24)(cid:22)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:09 UTC from IEEE Xplore.  Restrictions apply. 
 +*',


 



>=B-543J$%67
439& *
+*$
43:&*)A  @%
43;&-
*)A ,%
		 
@@,$>:
&D=CD?A=
! /2#2$2#42+>#,
(
%$3"%**


 

"$"
$
#""
$ I 50/16,
4""5&
:$>:


&! 9# @@2#42>
"#

 "$
Fig. 3: Overall architecture of RAZZER
