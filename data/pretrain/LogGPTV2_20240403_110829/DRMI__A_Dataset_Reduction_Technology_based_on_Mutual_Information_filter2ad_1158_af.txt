77.59%
93.53%
91.72%
96.41%
88.45%
88.05%
94.14%
79.82%
80.31%
92.13%
0.5288
0.8068
0.3439
0.4289
0.1961
0.6852
0.5923
0.2475
1.1851
0.6033
0.2604
26
13
30
30
30
30
30
20
30
30
15
matrix is xxT. For a dataset Xm = [x1,x2, ...,xm], its corela-
tion matrix is R(Xm) = XmXT
m/m. CMAL selects a simpliﬁed
dataset S from the whole dataset D which minimizes the value
||R(S)−R(D)||2. CMAL tends to extract standard, moderate,
and average-performing samples, rather than independent, di-
verse, and representative ones. We implement the correlation
matching based active learning (CMAL) [65] and compare its
performance with our approach.
In Table 11, we adopt a LeNet-5 model to evaluate the
accuracy and loss value of the DRMI and CMAL methods.
We ﬁnd that our method performs much better (i.e., higher ac-
curacy yet lower loss) than CMAL in all dataset sizes. DRMI
increases 6%, 5%, and 9% accuracy on 600, 300, and 150
dataset sizes than CMAL, respectively.
Remark: According to our investigation, the reason why
CMAL performs worse is that this sampling is prone to choos-
ing more averaged than diverse data. Although the selected
data follows a similar distribution with the whole dataset, the
model cannot learn distinctive features from them and thereby
performs under our exceptions. As a result, it proves that the
correlation matrix based reduction likely removes distinctions
that could degrade the performance of data reduction.
5.4.2 CPB: Class Probability of Prediction
High class probability (hereafter referred to as HCP) of data
indicates that the model classiﬁes it correctly with high con-
ﬁdence. In our experiments, HCP data points are ﬁrst sorted
Figure 6: The effect of high class probability data on the
accuracy of substitute models.
in order of conﬁdence scores of the correct class from high
to low, and then selected in order until ﬁlling the simpliﬁed
training set of ﬁxed size. In our general cognition, the data
with higher class probabilities during the testing process can
reﬂect the logical relationship with the target model much
better. In [42], they also use class probability returned by
the target model as a measure. Here we are eager to verify
more directly whether HCP data is more useful for training
substitute models.
In Figure 6, the gray dotted line is the model accuracy from
a randomly reduced dataset, and x-axis is the percentage of
HCP data. For a dataset with randomly selected 600 samples,
we start to replace a portion (10% ∼ 100%) of data with HCP
and observe the impact of HCP data on the accuracy of the
substitute model. We ﬁnd that the increase of HCP data does
not raise the accuracy of the substitute model, but lowers it
down slightly. It shows that HCP data does not contribute
more than random data for training substitute models.
Furthermore, we try to categorize data based on class proba-
bilities by K-Means clustering. We treat prediction conﬁdence
scores after the softmax layer as feature vectors, use L2 to mea-
sure the distance between two points, and perform K-Means
to form k independent clusters. For each cluster, we select the
data that is nearest to the centroid, and ﬁnally obtain a reduced
dataset with k samples. In Table 12, we test K-Means on vary-
ing sizes from 150 to 600, which performs worse than DRMI
with decreasing the accuracy by 2.9%, 5.7%, and 12.3% on
sizes 600, 300, and 150, respectively.
Remark: We investigated the formed k clusters and ﬁnally
selected samples in the experiment to explain its unsatisﬁed
performance. We ﬁnd that the selected samples are more
likely to be picked at random, seriously deviating from our
expectations. It is due to the features of high-dimensional
data: the points (under this context) in the high-dimensional
space have nearly equal euclidean distances between each
other. Therefore, K-Means cannot effectively separate these
USENIX Association
30th USENIX Security Symposium    1913
0102030405060708090100Percentage of high class probability data (%)858789919395Accuracy of substitute model (%)Table 13: Effectiveness using activated neurons trace informa-
tion under 600 dataset size. In Target, “MIN” means we ﬁnd
the minimum hamming distance sum, while “MAX” refers to
the maximum hamming distance sum.
Method
TRACE
TRACE
TRACE
TRACE
DRMI
Target
MIN
MIN
MAX
MAX
-
Initial Solu.
min-sum
min-max
min-sum
min-max
-
Test Acc.
67.21%
60.53%
79.10%
72.67%
96.41%
Test Loss
2.3855
3.3914
0.9326
1.6328
0.1961
Epoch
15
15
15
15
30
samples. It reveals class probability has been pruned with the
diversity in euclidean space.
To solve the curse of dimensionality, we apply a principal
components analysis (PCA) before K-Means. However, it
still brings no noticeable improvement in Table 12. The CPB
method, even with PCA, fails largely due to the deep trans-
formation from input to output by DNNs. As claimed in [54],
the original data features fade away but the essential features
for abstract outputs remain and get enhanced during training.
Data redundancy is apparently discarded in the course, so that
using class probability can only tell how different of their
predictions but deﬁnitely not the input data.
5.4.3 TRACE: Trace of Activated Neurons
DNN is one kind of data model which transforms a sort of data
into another. Generally, there are scattering lots of neurons
internally to accomplish the transformation. When a data
sample enters the model, it will activate a number of neurons,
and then reach the ﬁnal result. As such, it leaves a trace during
passing through the deep learning model. This kind of traces
have been employed for multiple purposes [46, 52]. Here we
explore whether it is suitable for measuring data redundancy.
For simplicity, we use M = (Li), i < n to denote a n-
layer DNN, where Li is i-th layer in the model. For each
layer, there may be varying numbers of neurons. We deﬁne
Li = (si
j de-
notes the activation state of neurons. If the current neuron
is activated, the value of si
j is 1, otherwise 0. Hence Li is a
binary string of length m, and m is the neuron number in the
i-th layer. We assume Tr is a binary string of length l, and
l is the total number of neurons in the model. Binary string
Tra represents the activated neurons path for data a. Then we
calculate the Hamming distance (performing an xor opera-
tion on two strings and counting the number of “1”s in the
result) of Tra and Trb, to represent the distance of data a and
b. Then we replace the MI matrix with the Hamming distance
as follows:
m) as the i-th layer with m neurons, and si
1,si
2, ...si
I[a][b] = Hamming(Tra)(Trb)
(11)
Finally, we adopt Algorithm 1 to obtain a simpliﬁed dataset.
Here we try two directions–smallest and largest Hamming
distance sets. In Table 13, we test TRACE methods under 600
Figure 7: The box-plot of the proportion of activated neurons
in all data. The ordinate is the proportion of activated neurons.
samples. All of TRACE methods perform worse than DRMI,
decreasing 17.3% to 35.9% accuracy. In TRACE, we ﬁnd
“MAX” target performs better than “MIN” target, increasing
11.89% in min-sum and 12.14% in min-max initial solution.
This indicates the set with larger hamming distance has better
effect. We need to make traces of activated neurons more
diverse and cover as more neurons as possible.
In order to study why activation traces could not ﬁlter out
a good simpliﬁed training dataset, we analyze the distribution
of the proportion of activated neurons and draw a box-plot
in Figure 7. The proportions are almost all concentrated at
[0.313,0.515], within a small interval. Even 50% data acti-
vated neurons proportions are concentrated at [0.387,0.438],
a very small interval. This may be the cause of poor perfor-
mance to select data through the activation neuron trace.
Remark: The TRACE method by considering the Hamming
distance between activated neurons traces performs worse
than DRMI. The proportions of activated neurons in all pre-
dicted samples are almost concentrated in a small interval.
6 Related Work
There has been a line of related research described as below.
Black-box Attacks. Many black-box attacks (e.g., adversar-
ial attacks) need to train a substitute model [29, 44, 45]. Tech-
niques have been developed to reduce queries as much as pos-
sible. Papernot et al. [44] adopted reservoir sampling method
and successfully reverse-engineered two machine learning
classiﬁcation systems. In order to reduce the query number,
Papernot et al. [45] adopted Jacobian-based dataset augmen-
tation (JbDA) to create synthetic data for training DNNs
on MNIST. Based on JbDA, Juuti et al. [29] proposed Jb-
topk and Jb-self methods to synthesize samples for substitute
model training. Differently, DRMI relies on data reduction
from a large dataset for querying. But PRADA augments data
locally for training that may induce wrongly labeled data.
Through the experiments in Section 5.2, it proves DRMI can
1914    30th USENIX Security Symposium
USENIX Association
img_act0.300.350.400.450.500.550.600.310.5150.3870.4120.4380.5920.313achieve more accurate substitute models using the same or
fewer queries. Orekondy et al. [42] stole the functionality of
target models by querying. They use three metrics to choose
images: images with higher class probabilities, images with
diverse labels, and images which imitates badly. According
to our results, the sole selection of images with higher class
probabilities cannot augment accuracy of the trained model.
Jagielski et al. [26] propose a learning-based extraction
method using semi-supervised learning techniques: rotation
loss and MixMatch. For adversarial capabilities, they need
both labels and scores from the original model, while DRMI
only needs labels. Their adversary has access to the same
training set without labels, but DRMI does not need the exact
training data. They can save the query costs because much
unlabeled data does not need to be queried in semi-supervised
learning. Based on this analysis, we can incorporate their
method into ours in future: use DRMI to select the query data
for fully supervised learning, and perform semi-supervised
learning on the remaining unlabeled data.
Data reduction. Eschrich et al. [17] reduced the amount
of clustering data by aggregating similar samples and using
weighted samples. Ougiaroglou et al. [43] reduced data in
clustering by producing homogeneous clusters. It reduced
storage requirements and had low pre-processing cost. Chou-
vatut et al. [13] proposed a graph-based optimum-path forest
to reduce the size of training sets. They utilized the segmented
least square algorithm to estimate the tree’s shape. In DNNs,
Zheng et al. [65] proposed a correlation matching based ac-
tive learning technique to label the most informative data and
simplify the dataset. We implemented it in our experiments
for a comparison. Results show DRMI performs remarkably
better than it in CNNs. Katharopoulos et al. [31] found that
not all samples in the training phase are equal. Hence, they
adopted importance sampling to identify informative exam-
ples, which can reduce the variance of a SGD process. DRMI
aims to reduce the queries and the reduction can be completed
before training, therefore, DRMI is model-independent, i.e.,
not affected by model structures and training processes.
7 Discussion
Effectiveness of DRMI. In this study, we use mutual infor-
mation to measure the data redundancy of a dataset, and then
ﬁnd a subset to minimize the summed mutual information.
As claimed in Section 4.2, the problem is NP-Complete and
cannot be solved in polynomial time. Therefore, we propose
DRMI to solve the intractableness. Its effectiveness is twofold.
On one hand, DRMI can ﬁnd an approximate optimal solution
by enumerating the starting point (Algorithm 1) and ﬁlling an
initial subset for representative data (Algorithm 2) to avoid
the trap of local optimum. On the other hand, one-hot re-
placement (Algorithm 3) replaces the vertices that incur large
mutual information and identify the optimal solution in the
current setting. Based on the complexity analysis for each
algorithm at Section 4.3, the overall complexity of DRMI is
O(kn2), which can be further optimized to O(knlogn) with
more efﬁcient sorting algorithms. It is also conﬁrmed by the
experiments on three diverse and large-scale datasets.
Parameter Choice (α, ε). α is used to tune the variable rela-
tionship between mutual information and data redundancy. It
indicates a linear relationship if α = 1. Moreover, we explore
whether there are non-linear relationships by augmenting α
to 2 and 4. The results in Table 3 and 7 show the increase
of α (from 2 to 4) hardly improves accuracy, but the extra
overhead caused by exponent computation cannot be offset
by accuracy gains. Similarly, it is experimentally conﬁrmed
that this principle also applies to the other datasets CIFAR10
and ImageNet. As for the max perturbation ε, it reﬂects the
balance between attack effect and imperceptibility of AEs.
Larger ε can raise the attack effect, but reduce the impercepti-
bility. For ease of comparison, we set ε = 0.3 for untargeted
AEs, consistent with [7] and ε = 0.5 for targeted AEs on the
MNIST dataset. It is because targeted AEs usually need larger
√
perturbations for generation, and the value is also aligned
0.001· D on the
to PRADA. Inspired by [11], we set ε =
ImageNet dataset, and D is the input dimension (≈ 270,000).
Robustness of DRMI. There is a line of work to defend such
black-box attacks. For instance, [58] proposes a number of
strategies to prevent model stealing, including rounding conﬁ-
dence scores, providing fake or no class probability. However,
we show that DRMI is still effective without class probability
in Section 5.2, making this defense ineffective. PRADA [29]
also proposes a defensive method by detecting abrupt changes
in the distribution of queried samples. It detects PRADA’s
attack after 100 queries on MNIST. We re-implement this
method to detect DRMI. In our experiments, we assume that
normal users submit random queries, which reduces the detec-
tion difﬁculty. Through our results, DRMI can successfully
create a high quality substitute model after only a few hundred
queries on MNIST, while it takes about 32,000 queries for
PRADA to detect our attack. So PRADA is not effective at
stopping our attack. Our queries are not easily detected by