title:DeepIntent: Deep Icon-Behavior Learning for Detecting Intention-Behavior
Discrepancy in Mobile Apps
author:Shengqu Xi and
Shao Yang and
Xusheng Xiao and
Yuan Yao and
Yayuan Xiong and
Fengyuan Xu and
Haoyu Wang and
Peng Gao and
Zhuotao Liu and
Feng Xu and
Jian Lu
DeepIntent: Deep Icon-Behavior Learning for Detecting
Intention-Behavior Discrepancy in Mobile Apps
Shengqu Xi1,∗ Shao Yang2,∗ Xusheng Xiao2 Yuan Yao1 Yayuan Xiong1 Fengyuan Xu1
Haoyu Wang3 Peng Gao4 Zhuotao Liu5 Feng Xu1
Jian Lu1
1State Key Lab for Novel Software Technology, Nanjing University
2Case Western Reserve University
3Beijing University of Posts and Telecommunications
4University of California, Berkeley
{xsq,yayuan.xiong}@smail.nju.edu.cn,
PI:EMAIL,
{sxy599, xusheng.xiao}@case.edu,
PI:EMAIL,
{y.yao, fengyuan.xu, xf, lj}@nju.edu.cn
PI:EMAIL
5University of Illinois at Urbana-Champaign
ABSTRACT
Mobile apps have been an indispensable part in our daily life. How-
ever, there exist many potentially harmful apps that may exploit
users’ privacy data, e.g., collecting the user’s information or send-
ing messages in the background. Keeping these undesired apps
away from the market is an ongoing challenge. While existing
work provides techniques to determine what apps do, e.g., leak-
ing information, little work has been done to answer, are the apps’
behaviors compatible with the intentions reflected by the app’s UI?
In this work, we explore the synergistic cooperation of deep learn-
ing and program analysis as the first step to address this challenge.
Specifically, we focus on the UI widgets that respond to user in-
teractions and examine whether the intentions reflected by their
UIs justify their permission uses. We present DeepIntent, a frame-
work that uses novel deep icon-behavior learning to learn an icon-
behavior model from a large number of popular apps and detect
intention-behavior discrepancies. In particular, DeepIntent provides
program analysis techniques to associate the intentions (i.e., icons
and contextual texts) with UI widgets’ program behaviors, and infer
the labels (i.e., permission uses) for the UI widgets based on the
program behaviors, enabling the construction of a large-scale high-
quality training dataset. Based on the results of the static analysis,
DeepIntent uses deep learning techniques that jointly model icons
and their contextual texts to learn an icon-behavior model, and
detects intention-behavior discrepancies by computing the outlier
scores based on the learned model. We evaluate DeepIntent on a
large-scale dataset (9,891 benign apps and 16,262 malicious apps).
With 80% of the benign apps for training and the remaining for
evaluation, DeepIntent detects discrepancies with AUC scores
0.8656 and 0.8839 on benign apps and malicious apps, achieving
39.9% and 26.1% relative improvements over the state-of-the-art
approaches.
∗The first two authors contributed equally to this research.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6747-9/19/11...$15.00
https://doi.org/10.1145/3319535.3363193
CCS CONCEPTS
• Security and privacy → Malware and its mitigation; Soft-
ware security engineering.
KEYWORDS
mobile apps; discrepancy detection; static analysis; deep learning
ACM Reference Format:
Shengqu Xi, Shao Yang, Xusheng Xiao, Yuan Yao, Yayuan Xiong, Fengyuan
Xu, Haoyu Wang, Peng Gao, Zhuotao Liu, Feng Xu, and Jian Lu. 2019.
DeepIntent: Deep Icon-Behavior Learning for Detecting Intention-Behavior
Discrepancy in Mobile Apps. In 2019 ACM SIGSAC Conference on Computer &
Communications Security (CCS’19), November 11–15, 2019, London, UK. ACM,
New York, NY, USA, 16 pages. https://doi.org/10.1145/3319535.3363193
1 INTRODUCTION
Mobile apps are playing an increasingly important role in our daily
life, from travel, education, to even business [50, 87]. While these
apps use users’ personal information to provide better services,
certain behaviors of the apps are less desirable or even harmful.
Example undesired behaviors include disclosing users’ sensitive
data such as location [18, 43, 61, 92] without expressing the inten-
tions to use it, and stealthily exploiting users’ private resources for
advertising [41, 42, 75].
However, detecting such apps is challenging, since undesired be-
haviors appear to be indistinguishable from the behaviors of benign
apps. For example, apps recommending restaurants use users’ GPS
data to suggest the nearby restaurants, and apps providing travel
planning services let users make phone calls or send messages.
As such, the permission-based access control mechanism employed
by popular smartphone platforms (i.e., Android and iOS) [68], has
shown little success [9, 19, 20]. For example, users can disallow an
app to share the GPS data by not granting the GPS-related permis-
sions; however, it is a difficult decision as many benign apps do
need to use the GPS data.
To detect the undesired behaviors in mobile apps, we are moti-
vated by the vision: can the compatibility of an app’s intentions and
program behaviors be used to determine whether the app will perform
within the user’s expectation? In other words, as the user-perceivable
information of apps’ UIs (i.e., texts and images) represent users’
expectation of apps’ behaviors [33] (i.e., apps’ intentions), we aim to
automatically check the compatibility between apps’ intentions and
their behind-the-scene behaviors, i.e., detecting intention-behavior
coverage [24, 25, 48, 69]. Third, it is difficult to correlate an app’s
intention and behavior to determine whether the behavior is unde-
sired. Existing research efforts have been put forth to detect unde-
sired disclosures of sensitive user inputs through UIs [4, 31–33, 51].
However, the resulting behavior patterns from these approaches
can capture only a fixed set of undesired behaviors. Furthermore,
a behavior of a UI widget often uses several permissions. Existing
prediction-based approaches [33, 80] mainly focus on predicting a
single permission use based on intentions, and such lack of model-
ing multiple permission uses renders the prediction less effective
in detecting intention-behavior discrepancies.
Contributions. Towards realizing the vision, we propose to build a
novel framework, DeepIntent, that learns an icon-behavior model
from a large number of apps, and uses the model to detect unde-
sired behaviors3. In particular, DeepIntent explores the synergistic
cooperation of deep learning and program analysis as the first step
to address the above challenges in Android apps: (1) Deep Intention
Modeling: following the success of deep learning [21, 27, 28, 35, 36]
in modeling unstructured artifacts such as texts and images, DeepIn-
tent uses deep learning to model apps’ intentions that are reflected
mainly by the unstructured information (i.e., icons and texts) and
predict expected behaviors; (2) Traceability and Label Inference: the
power of deep learning highly depends on the large-scale high-
quality labeled data [1, 21], and simply modeling all the code as
part of the features without deeper analysis on the code introduces
too much noise into the training data, rendering the deep learning
less effective. As such, DeepIntent leverages program analysis tech-
niques to associate the intentions with the program behaviors, and
infer the labels for the icon widgets based on the program behaviors
(e.g., whether the behaviors accessing sensitive data), enabling the
construction of a large-scale high-quality training dataset. Such
synergy of program analysis and deep learning enables building
an icon-behavior model from a large number of apps and exposing
intention-behavior discrepancies based on the model.
The design of DeepIntent is based on three key insights. First,
mobile apps’ UIs are expected to be evident to users, and icons
indicating the same type of sensitive behavior should have similar
looks. This inspires us to follow the success of CNN [35, 36] in
image recognition and model the icons (i.e., pixels of the icons)
using CNN to identify similar icons. Second, in different UI contexts,
icons may reflect different intentions. For example, a “send” button
may mean sending an email or an SMS in different contexts. While
it is difficult to differentiate the intentions by just comparing the
icons, the contextual texts, such as the nearby text labels and the
header of the UI, can be used to help distinguish the contexts of
the icons. Third, users expect certain behaviors when interacting
with icon widgets that have specific looks, and undesired behaviors
usually contradict users’ expectations. For example, when users
look at the first highlighted icon in Figure 1(a), they are expecting
the app to read their contacts, but not disclosing their location
information. To capture such general expectation, we propose to
develop program analysis techniques that can associate icons to
their sensitive behaviors, and apply the techniques to extract the
associations from a corpus of popular apps to learn models on
expected behaviors for icon widgets with specific looks. Such model
3DeepIntent is publicly available at https://github.com/deepintent-ccs/DeepIntent.
(a)
(b)
(c)
Figure 1: Example icon widgets that access sensitive infor-
mation.
discrepancies. For example, if a music player app’s button shows a
“+” icon, it indicates that clicking the button will add a song to the
playlist. However, if the app discloses users’ GPS data when the
button is pressed, red flags should be raised.
In this work, we focus on detecting the intention-behavior dis-
crepancies of interactive UI widgets in Android apps1, which ex-
press their intentions via texts or images and respond to users’
interactions (e.g., clicking a button). Specifically, we focus on the
interactive UI widgets that use icons to indicate their expected be-
haviors, referred to as icon widgets, since icon widgets are prevalent
in apps and many of them access sensitive information [80]. Fig-
ure 1 shows the UI screenshots that contain example icon widgets
in which their icons and texts express their intentions in perform-
ing sensitive behaviors: Figure 1(a) shows icon widgets that use
pure icons and icons embedded with texts; Figure 1(b) shows icon
widgets that use both icons and texts, but the texts do not explicitly
explain their intentions; Figure 1(c) shows icon widgets that use
both icons and texts, and the texts help explain their intentions.
Checking the compatibility between the icon widgets’ intentions
and their behaviors is a challenging task. First, their intentions are
expressed mainly via a mixture of icons and texts, and it is difficult
to model such correlations using these unstructured artifacts. Ex-
isting approaches have either modeled the text semantics to detect
undesired disclosures of sensitive user inputs through UIs [4, 31, 51],
or classified the icons using computer vision techniques to detect
sensitive UI widgets [80]. However, none of them have modeled the
joint semantics of both icons and their texts. Second, Android’s UI
design model and the asynchronous programming model pose chal-
lenges to precisely identify sensitive behaviors of an icon widget.
Android apps may associate UI handlers2 with icon widgets via UI
layout files or code. Also, UI handlers may invoke sensitive APIs
via Android’s multi-threading [86] and Inter-Component Commu-
nication [37, 54]. Existing approaches either produce high false
positives due to enumerating all possible combinations of lifecycle
methods [5, 79], or fail to identify certain behaviors due to low
1While our work focuses on Android apps due to its popularity, the findings can be
generalized to other mobile platforms such as iOS.
2A UI handler is the method to be invoked when a user interacts with the icon widget.
Figure 2: Motivating example of DeepIntent.
can then be used to detect abnormal behaviors as intention-behavior
discrepancies. In particular, we use permission uses to summarize
icon widgets’ sensitive behaviors (i.e., sensitive APIs invoked) [7,
17, 83], since undesired behaviors need to request permissions to
access sensitive information.
Based on these key insights, DeepIntent provides a novel learn-
ing approach, deep icon-behavior learning, which consists of three
major phases.
Icon Widget Analysis. The input used in our learning model con-
sists of icons, contextual texts, and the permission uses associated
with the icons. To extract the icons and their permission uses, Deep-
Intent provides a static analysis that analyzes APK files to identify
icon widgets and extract corresponding icon-permission mappings,
i.e., mapping the icons used in the UI widgets to their permission
uses. Specifically, the static analysis (1) associates icons with UI
widgets by analyzing both UI layout files and code, (2) associates
icon widgets with UI handlers, (3) builds call graphs for UI handlers
by considering multi-threading and ICCs, and (4) maps method
calls in call graphs to permission uses. From the extracted icons,
DeepIntent provides a text extraction technique that extracts con-
textual texts for the icons by analyzing UI layout files, embedded
texts in the icons, and icon file names.
Learning Icon-Behavior Model. DeepIntent adopts a parallel
co-attention mechanism [47, 90] to jointly model icons and their
contextual texts. Specifically, DeepIntent first uses DenseNet [30]
and GRUs [10] to extract the initialized features for icon images and
contextual texts, respectively. DeepIntent then combines these
two features into a joint feature vector via co-attention, whose
basic idea is to simultaneously update the image/text features by
highlighting the image/text regions that are relevant to each other.
Next, DeepIntent learns the joint feature vector for an icon by
training the model with the mapped permissions for icons. Since
each icon may relate to multiple permission uses, we formulate a
multi-label classification problem to learn the joint features.
Detecting Intention-Behavior Discrepancies. With the learned icon-
behavior model, given an icon widget, DeepIntent first extracts
its joint feature vector, and then detects the intention-behavior
discrepancies by computing and aggregating the outlier scores from
each permission used by the icon widget. Specifically, we compute
the outlier score for each used permission via AutoEncoder [3], and
aggregate these scores to form the final outlier score based on the
icon-behavior model. The actual permission uses are obtained by
the program analysis used for extracting icon-permission mappings.
Results. We collect a set of 9,891 benign apps and 16,262 malicious
apps, from which we extract over 10,000 icon widgets that are
mapped to sensitive permission uses. We use 80% of the icons from
the benign apps as training data, and detect the intention-behavior
discrepancies on the remaining icons from the benign apps and all
the icons from malicious apps. For the test set, we manually label
whether there is an intention-behavior discrepancy to form the
ground truth. Finally, DeepIntent returns a ranked list based on
the outlier scores for detecting intention-behavior discrepancies.
The results demonstrate the superior performance of the pro-
posed DeepIntent. First, our joint modeling of icons’ image and
text features is effective in terms of predicting their permission uses.
Compared to the state-of-the-art sensitive UI widget identification
approach, IconIntent [80], that relies on traditional computer
vision techniques, DeepIntent achieves at least 19.3% relative im-
provement in different permissions. DeepIntent is also better than
its sub-variants when only icons’ image or text features are used.
This result indicates the generalization ability of the proposed deep
learning techniques for the joint feature learning. Second, our static
analysis is essential to accurately extract icon-permission mappings
for the learning of the icon-behavior model. For example, DeepIn-
tent achieves 70.8% relative improvement on average compared to
the learning approach without static analysis. Third, DeepIntent
can detect discrepancies with AUC values 0.8656 and 0.8839 for
benign apps and malicious apps. For malicious apps, DeepIntent
can successfully identify over 85% discrepancies in most cases. The
state-of-the-art approach, IconIntent [80], is originally proposed
for predicting permission uses, and we extend it to the discrepancy
detection setting by feeding its features into the proposed outlier de-
tection module. The results show that DeepIntent achieves 39.9%
and 26.1% relative improvements in terms of AUC values compared
to IconIntent on benign apps and malicious apps, respectively.
2 MOTIVATING EXAMPLE
To motivate DeepIntent, we present an example in Figure 2. The
rendered UI with sensitive buttons are from the app Smart Dia-
log. Consider the phone call button as an example. DeepIntent
extracts the resource ID from the UI layout file, analyzes the code
that handles the button, builds the call graphs, and maps the button
to its permission uses (i.e., the CALL permission). The output of the
icon-behavior association is a set of ⟨icon, text, permissions⟩ triples.
Next, DeepIntent learns an icon-behavior model using the set of
triples from popular benign apps, with the assumption that most
listenerstartRendered UI@drawable/dialpad_func_btn_call@id/dp_btn_callImage ButtonCallMasterOnClick ThreadView.getId()Itelephony.call()CodeLayoutCALLpermissionIcon-Behavior Association✔Icon-Behavior LearningDiscrepancy DetectionTest IconstimingfilterImage Feature Initialization Text Feature Initialization Feature CombinationGroup-Wise Outlier ScoreComputation Final  OutlierScoreAggregation Figure 4: Workflow of icon-behavior association module.
an icon used in a UI widget and its contextual text, the behavior pre-
diction module uses the trained icon-behavior model to predict its
permission uses. Also, based on the actual permission uses obtained
from our static analysis techniques (the same techniques used for
processing training APKs), the outlier detection module uses the
trained icon-behavior model to determine whether the permission
uses are abnormal, i.e., detecting icon-behavior discrepancies.
3.2 Threat Model
DeepIntent is a UI analysis tool that detects intention-behavior
discrepancies for icon widgets. Rather than focusing on malicious