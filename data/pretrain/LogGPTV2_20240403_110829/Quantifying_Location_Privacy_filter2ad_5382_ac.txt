p
(
x
)
frequently in the literature: precision reducing (merging
regions) and location hiding. The anonymization mechanism
is the random permutation.
The precision reducing obfuscation mechanism reduces
the precision of a region by dropping the low-order bits
of the region identiﬁer. If, as in our case, the whole area is
divided into a grid pattern of regions, the x and y coordinates
of the region can be obfuscated separately. The number of
dropped bits determines the level of obfuscation. Let µx and
µy be the number of dropped bits in the x and y coordinates,
respectively. This is a deterministic obfuscation in which, for
example, µx = 1 will map regions r12 and r13 (in Figure 2)
to the same location pseudonym, as they are on the 4th and
5th column of the same row.
In the location hiding mechanism, every event is indepen-
dently eliminated (i.e., its location is replaced by ∅) with
probability λh: location hiding level.
An LPPM designer can easily import her LPPM into our
tool by specifying the probability density function LPPM
(see (3)), or, equivalently, by specifying an anonymization
function and an obfuscation function.
B. Knowledge of the Adversary
In this section, we provide a model for constructing the
a priori knowledge of the adversary to be used in the
various reconstruction attacks. The schema of the knowledge
construction (KC) module is illustrated in Figure 1.
The adversary collects various pieces of information about
the mobility of the users. In general, such information can
be translated to events; perhaps the events can be linked into
transitions, i.e., two events of the same user with successive
timestamps; perhaps they can be further linked into a partial
trace or even a full trace. The quality of these events to the
adversary might be varied, e.g., they might contain noise. It
is conceivable that the adversary obtains information, such
as a user’s home address, that is not obviously translatable
to an event. Then the adversary can create typical events
(or traces) that encode that
information, i.e., successive
appearances of a user at his home location between the
evening and the morning hours.
All this prior mobility information on each user is encoded
in one of two ways: Either in the form of some traces, or as
a matrix of transition counts T Cu. The traces can be noisy
or they might be missing some events. The T Cu matrix is of
dimension M × M and its ij entry contains the number of i
to j region transitions that u has created and have not been
encoded as traces. Any knowledge of the general movement
within the regions, i.e., how a typical user moves, that cannot
be attributed to a particular user can be incorporated in the
T C matrices. In addition to this mobility information on
the users, the adversary also considers the general mobility
constraints of users within regions. For example, it might not
be possible to move between two far-away regions in one
253
time instant, or cross a border between two regions because
of some physical obstacles.
The adversary makes the assumption that user mobility
can be modeled as a Markov Chain on the set of regions R.
So, the mobility proﬁle P u of a user is a transition matrix
for that user’s Markov Chain. The entry P u
ij , i, j = 1..M
of P u is the probability that u will move to region rj
in the next time slot, given that he is now in region ri.
The objective of the adversary is to construct P u starting
with the prior mobility information (traces and T Cu). The
construction is done with Gibbs sampling [20] to ﬁnd the
conditional probability distribution of the entries of the MC
matrix, given the prior information. Then, one MC matrix
is created out of the distribution, for instance by averaging.
How restrictive is the Markovian assumption on user
mobility? For example, if T represents one full day, users
will have different mobility patterns depending on the time
of day. A Markov Chain can still model this situation with
arbitrary precision at the cost of increasing the number of
states. There will be two (or three, or more) interconnected
Markov Chains, corresponding to different time periods of
the day: morning and evening, or morning, afternoon and
evening, or even more ﬁne-grained. Each MC is deﬁned on
the set of regions R, so it still has M states, but each has
different transition probabilities. The M states of each MC
are labeled not only by a region, but also by the period of
the day that they correspond to. Finally, there are appropriate
transitions from the morning states to the afternoon states,
from the afternoon states to the evening states, and so on. So,
the model is extensible to more general mobility models, but
to keep the presentation simple we assume that T represents
one single time period.
Hereafter, we explain how to create the proﬁle P u of
user u from a training trace T Tu with missing data, and
a transition count matrix T Cu. Note that the method that
we have implemented considers multiple training traces per
user. However, to simplify the presentation we consider only
one trace. Moreover, as we are talking about proﬁling each
user separately, we omit the subscript/superscript u.
The ultimate goal is to estimate the parameters of the
underlying Markov Chain (i.e., the matrix P ). As the training
trace T T is incomplete (i.e., we do not have the location of
the user at all time instants), we also need to ﬁll in the
missing data at the same time. Let ET be an estimated
completion for T T . Formally, we estimate the proﬁle P of
the user with the expectation E[P |T T, T C]. To compute this
expectation we will sample from the distribution
Pr(P |T T, T C) =XET
Pr(P, ET |T T, T C).
(6)
However, sampling directly from Pr(P, ET |T T, T C)
involves computing the sum
is not straightforward;
of
terms whose number grows exponentially with the
length of the trace. Hence, we use Gibbs sampling, a
it
Monte Carlo method, as it only takes polynomial time
to produce a sample from the conditional distributions
Pr(P |ET, T T, T C) and Pr(ET |P, T T, T C). In order to
sample from Pr(P, ET |T T, T C), we create a homogeneous
Markov Chain on the state space of P and ET in an iterative
procedure. Starting from an initial value for ET {0}, Gibbs
sampling produces pairs (P {l}, ET {l}) as follows:
P {l} ∼ Pr(P |ET {l−1}, T T, T C)
ET {l} ∼ Pr(ET |P {l}, T T, T C)
(7)
(8)
Convergence properties of the Gibbs sampling for this
problem are studied in [20]. We are interested in the
sequence of the P {l}
values; it is not a Markov chain,
ij
but
is ergodic and converges at geometric rate to a
stationary distribution, which is the desired Pr(P |T T, T C).
We compute Pij for every i, j as the average of P {l}
over
all samples l.
it
ij
Now, the only remaining question is how to sample from
the distributions (7) and (8). In order to sample a P {l}
from (7), we assume that the rows of the transition matrix
P are independent, and we produce samples for each row
separately. We also consider a Dirichlet prior for each row
the lth sample for row Pi comes from the
Pi. Hence,
following distribution:
Dirichlet(cid:16){T Cij + Cntij(ET {l−1}) + ǫij}j=1..M(cid:17) (9)
where Cntij(·) is the number of transitions from region ri
to rj in a trace, and ǫij is a very small positive number if,
according to the mobility constraints, it is possible to move
from ri to rj in one time instant (otherwise ǫij is zero).
To sample an ET {l} from (8), we follow the simpliﬁ-
cation proposed in [20] and iteratively construct ET {l} by
performing T successive samplings, for t = 1, . . . , T , from
ET (t−1)ET (t)b(T T (t)|ET (t))P {l}
P {l}
ET (t−1)rb(T T (t)|r)P {l}
rET (t+1)
Pr∈R P {l}
ET (0)ET (1) and P {l}
The values P {l}
ET (T )ET (T +1) are deﬁned to
be 1. The function b(r|ET (t)), r ∈ T T is equal to 0 if r 6= ∅
and r 6= ET (t). Otherwise, it is equal to 1. Note that the
function b(ri|rj ) can also represent the noise function if the
training trace is noisy: b(ri|rj ) is the probability that rj is
reported as ri.
1) Maximum Likelihood Tracking Attack: The objective
of this attack is to ﬁnd the jointly most likely traces for all
users, given the observed traces. Formally, the objective is
to ﬁnd
arg max
σ,A
Pr(σ, A|O).
(11)
Notice that the maximization above is done in a space with
N !M T elements, so a brute force solution is impractical.
user-to-trace assignments.
We proceed by running this attack in two phases: ﬁrst
deanonymization and then deobfuscation. The deanonymiza-
tion phase ﬁnds the most likely assignment of users to
obfuscated traces. Notice that it is not correct to simply
assign to each user the trace that she is most likely to have
created, because more than one user might be assigned to the
same trace. The most likely assignment is a joint assignment;
it maximizes the product Qu∈U P (oσ(u)|P u) over all N !
The most likely assignment is found as follows. First,
the likelihood P (ox|P u), x ∈ U ′, u ∈ U is computed for
all O(N 2) trace-user pairs (ox, u). For the case when the
obfuscation function operates on each region separately, we
compute the likelihood for each pair with the Forward-
Backward algorithm [18]. With this algorithm, each likeli-
hood computation takes time O(T M 2) by taking advantage
of the recursive nature of the likelihood that we want
to compute. In particular, we deﬁne the forward variable
αt(r), t ∈ T , r ∈ R as
αt(r) = Pr{ox(1), ox(2), . . . , ox(t), ax(t) = r|P u},
(12)
which is the joint probability of the observed trace ox up
to time t and that
the actual location of the user with
pseudonym x is r at time t, given that the pseudonym x is
associated with user u. Notice that, if we can compute the
forward variable at all regions at time T , i.e., αT (r), r ∈ R,
then the desired likelihood is simply
P (ox|P u) = Pr{ox(1), ox(2), . . . , ox(t), ax(t) = r|P u}
=
rMXr=r1
αt+1(r) =  rMXρ=r1
use the fact that
For the recursive computation of the forward variables we
αt(ρ)P u
ρr! fr(ox(t + 1)),
1 ≤ t ≤ T − 1, r ∈ R.
(14)
ET (t)ET (t+1)
.
(10)
αT (r).
(13)
C. Tracking Attacks
We now describe two tracking attacks and their implemen-
tations. Recall from Section II-C that in a tracking attack the
adversary is interested in reconstructing complete or partial
actual traces, i.e., in sequences of events, rather than just
isolated events.
Within the sum there is one term for each way of reaching
region r at time t+1, i.e., having been at each of the regions
ρ ∈ R at time t. After computing the sum, we only need
to multiply with the probability of obfuscating region r to
the location pseudonym observed at time t + 1. The only
remaining issue is the initialization of the forward variables:
α1(r) = πu
r fr(ox(1)), r ∈ R.
(15)
254
The vector πu
r , r ∈ R is the steady state probability vector
for the mobility proﬁle of u.
From the values δT (r), we compute the joint probability
of the most likely trace and the observations by computing
For the computation of the likelihood we do not need
the backward variables (which is where the rest of the
algorithm’s name comes from). We will, however, deﬁne
and use them in Section III-D on Localization attacks.
The whole likelihood computation for one trace-user pair
can be done in M (M + 1)(T − 1) + M multiplications and
M (M − 1)(T − 1) additions. If the obfuscation function
operates on the whole trace simultaneously, rather than on
each region individually, the worst case computation will
take time O(T M T ).
Having computed the likelihoods for all trace-user pairs,
we complete the deanonymization phase of the attack by as-
signing exactly one trace to each user. To this end, we create
an edge-weighted bipartite graph of traces and users, where
the weight of the edge between user u and trace ox is the
likelihood P (ox|P u). Then, we ﬁnd the Maximum Weight
Assignment (MWA) in this graph. We use the Hungarian al-
gorithm, which has time complexity of order O(N 4). Faster
algorithms exist, but the Hungarian algorithm is simple, and
the MWA only needs to be computed once in this attack;
the MWA is also an instance of a linear program, so linear
program solvers can be used. The outcome is a matching of
users and traces, such that the productQu∈U P (oσ(u)|P u)
is maximized over all N ! user-to-trace assignments.
Given the maximum weight assignment, we proceed to
the second phase of the attack: We ﬁnd the most likely
deobfuscation for the trace assigned to each user. We use
the Viterbi algorithm [18] to do that. More formally, the
most likely deobfuscation is
arg max
au∈Au
Pr{au(t), t = 1, . . . , T |ou(t), t = 1, . . . , T }.
(16)
The Viterbi algorithm is a dynamic programming algo-
rithm. We deﬁne δt(r) as
δt(r) =
max
au(s)s=1,...,t−1
Pr { au(s)s=1,...,t−1, au(t) = r,
ou(s)s=1,...,t−1|P u} ,
(17)
1
likely trace
which is the joint probability of the most
au(·)t−1
that at time t is at region r, and the trace observed
up to time t. Maximizing this quantity is equivalent to
maximizing (16). Then, similarly as before, we recursively
compute the values at time T , i.e., δT (r).
δt(r) = max
ρ∈R(cid:0)δt−1(ρ)P u
ρr(cid:1) fr(ou(t)),
2 ≤ t ≤ T, r ∈ R.
(18)
The initialization in this case is
max
r∈R
δT (r).
(20)
Of course, we are interested in the most likely trace itself,
not only in its probability. The most likely trace is computed
by keeping track, at each time 2 ≤ t ≤ T , of the argument
(region ρ) that maximizes (18) and, for t = T , the one that
maximizes (20). Then, we can backtrack from time T back
to time 1 and reconstruct the trace.
Parenthetically, notice that ﬁnding the most likely trace
is exactly equivalent
to ﬁnding the shortest path in an
edge-weighted directed graph. The graph’s M T vertices are
labeled with elements of the set R × T , i.e., for each time t
there are M vertices corresponding to each of the M regions.
There are edges only from vertices labeled with time t to
vertices labeled t + 1, 1 ≤ t ≤ T − 1. The weight of an
edge (t, r) → (t + 1, ρ) is equal to − log P u
rρfρ(ou(t + 1)).
Indeed, minimizing the sum of negative logarithmic terms
is equivalent to maximizing the product of the original
probabilities.
Having completed the two phases of the attack, we ob-
serve that the trace computed is not necessarily a maximum
for (11). Indeed from (11), it follows that:
arg max
σ,a
Pr(σ, a|O) = arg max
σ,a
Pr(a|σ, O) Pr(σ|O)
= arg max
Pr(Au = aui|Oσ(ui )) Pr(σ|O).
σ,a Yi
Indeed, MWA does maximize the second term (actually, it
maximizes Pr(O|σ) over all σ, which is equivalent to max-
imizing Pr(σ|O)) and Viterbi does maximize the ﬁrst (i.e.,
Pr(a|σ, O)). But, it is possible that an assignment σ∗ and
a set of traces a∗ that jointly maximize the total likelihood
(Pr(σ, a|O)) are different from the results obtained from the
MWA and Viterbi algorithms separately.
However, we consider such cases as pathological: In the
MWA, a user u is mapped to an obfuscated trace ou that
he has high likelihood of producing. That is, u is likely
to produce unobfuscated traces that are, in turn, likely to
be obfuscated to ou. In other words, the unobfuscated traces
that are typical for u are likely to be obfuscated to ou. There
might be a nontypical outlier (a∗) that is more likely than
the most likely typical trace, but that optimal combination
would be isolated in the A space. As such, choosing the
outlier would not be robust to small changes in, for example,
the mobility model.
2) Distribution Tracking Attack: We now consider the
most general type of tracking attack, one which computes
the distribution of traces for each user, rather than just the
most likely trace:
δ1(r) = πrfr(ou(1)), r ∈ R.
(19)
Pr{∩N
i=1
Aui = aui , Σ = σ|o1, o2, . . . , oN }
(21)
255
The implementation of this attack uses the Metropolis-
Hastings (MH) algorithm on the product of the space A
with the space of all possible permutations σ. The purpose
of the MH algorithm is to draw independent samples (from
the space A × Σ) that are identically distributed according
to the desired distribution (21). The algorithm makes use
of the fact that the desired distribution, brieﬂy written as
Pr{a, σ|o}, is equivalently: