title:HisTor\(ε\): Differentially Private and Robust Statistics
Collection for Tor
author:Akshaya Mani and
Micah Sherr
HisTorε: Differentially Private and Robust
Statistics Collection for Tor
Akshaya Mani
Georgetown University
PI:EMAIL
Micah Sherr
Georgetown University
PI:EMAIL
Abstract—A large volume of existing research attempts to
understand who uses Tor and how the network is used (and
misused). However, conducting measurements on the live Tor
network,
if done improperly, can endanger the security and
anonymity of the millions of users who depend on the network
to enhance their online privacy. Indeed, several existing mea-
surement studies of Tor have been heavily criticized for unsafe
research practices.
Tor needs privacy-preserving methods of gathering statistics.
The recently proposed PrivEx system demonstrates how data
can be safely collected on Tor using techniques from differential
privacy. However, as we demonstrate in this paper, the integrity
of the statistics reported by PrivEx is brittle under realistic
deployment conditions. An adversary who operates even a single
relay in the volunteer-operated anonymity network can arbitrar-
ily inﬂuence the result of PrivEx queries. We argue that a safe
and useful data collection mechanism must provide both privacy
and integrity protections.
This paper presents HisTor, a privacy-preserving statistics
collection scheme based on (, δ)-differential privacy that is robust
against adversarial manipulation. We formalize the security
guarantees of HisTor and show using historical data from the
Tor Project that HisTor provides useful data collection and
reporting with low bandwidth and processing overheads.
I.
INTRODUCTION
Tor [9] is an anonymity network composed of approx-
imately 6000 volunteer-operated relays with an estimated
1.75 million daily users [31]. Like the Internet, it is both a
production network with live users and a research platform
on which researchers experiment with new protocols and
implementations.1 Unlike the Internet, however, Tor has several
characteristics that make it a particularly unfriendly platform
for conducting (ethical) empirical studies:
1This dual-use is sometimes the source of conﬂict. To “minimize privacy
risks while fostering a better understanding of the Tor network and its
users”, the Tor Project recently established a Tor Research Safety Board [32]
that maintains guidelines and offers feedback to researchers concerning the
potential risks of experimenting on the live Tor Network.
Permission  to  freely  reproduce  all  or  part  of  this  paper  for  noncommercial 
purposes is granted provided that copies bear this notice and the full citation 
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited 
without the prior written consent of the Internet Society, the ﬁrst-named author 
(for  reproduction  of  an  entire  paper  only),  and  the  author’s  employer  if  the 
paper  was  prepared  within  the  scope  of  employment.
NDSS  ’17,  26  February  -  1  March  2017,  San  Diego,  CA,  USA
Copyright  2017  Internet  Society,  ISBN  1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23411
(1) dynamics—Tor
These characteristics include:
is a
highly dynamic network that
is known to be affected by
world events. For example, uprisings in undemocratic nations
tend to be followed by more advanced attempts to block
Tor from within those countries [31]. Entire countries are
periodically blocked and then allowed to access the network.
Comprehensive statistics gathering efforts must consider both
short-term and more longitudinal trends; (2) privacy—Tor is
designed to protect the privacy of its users. Experiments that
capture users’ communications are thus antithetical
to the
goals of the anonymity network and can potentially endanger
users who depend on the network to hide their identities;
(3) integrity—unlike the Internet, the core of Tor’s network is
operated by volunteers. It is far easier to operate a malicious
Tor relay than a core Internet router, and hence measurement
studies should consider a threat model in which the adversary
attempts to manipulate measurements to further its goals;
and (4) security—similarly, a privacy-preserving measurement
system should not provide a new attack surface for disrupting
or otherwise manipulating Tor.
We posit that the above challenges contribute to the lack of
understanding of actual Tor users. We know surprisingly little
about who uses the network, what they are using it for, and
how they are using it. We discuss the lack of information about
how people are using Tor in more detail in the next section.
While our lack of knowledge about how Tor is used in
practice may at ﬁrst blush signal a strength of Tor (that is, that
it successfully conceals its users’ behavior), it also limits our
ability to analyze the actual privacy properties of the network.
For example, attempts to empirically measure the anonymity
offered by the Tor network are predicated on maintaining
accurate models of real Tor users’ behavior [2, 14, 17, 19, 33].
To date, these models have been largely best guesses.
The core contribution of this paper is the introduction
of HisTor, a differential privacy scheme for Tor that
is
scalable, incurs low overheads, preserves users’ privacy, and
provides strong integrity guarantees2. The goal of HisTor is
to provide researchers with a platform for conducting accurate
measurement studies on Tor without endangering the network’s
users and while incurring only low overheads.
Importantly, HisTor is not the ﬁrst differentially private
statistics gathering scheme for Tor. Elahi et al. [15] recently
proposed a differential privacy solution for Tor called PrivEx.
PrivEx has signiﬁcantly raised the bar for safe Tor measure-
ments. Indeed, the Tor Research Safety Board cites PrivEx
2HisTor is pronounced as “history.”
as an example of exciting research towards conducting safe
measurements on the live network [32].
A key distinguishing feature of HisTor is its robustness
to manipulation. PrivEx raises the bar on Tor experimentation
by providing privacy. We show, however, that PrivEx is not
immune to manipulation. In particular, we demonstrate that a
malicious relay operator can drive the aggregate statistic being
calculated towards an arbitrary value of its choosing. While
such an attack may be outside of the threat model envisioned
by Elahi et al., the attack points to the need for statistics
gathering mechanisms that are both privacy-preserving and
resilient to manipulation.
HisTor’s robustness is mostly achieved by forgoing gen-
eral counting queries (as supported by PrivEx) in favor of
supporting only binning queries. Although we support more
general binning, a useful example of the type of queries
that HisTor supports is a histogram. In HisTor, each data
contributor (for example, exit relays) must contribute either “0”
or “1” to the total count in a bin. For instance, an analyst can
query HisTor to provide a histogram that shows the number
of connections observed by the different guard relays, or the
number of connections to Hidden Service Rendezvous Points
as observed by relays, etc. To provide robustness guarantees,
HisTor uses Goldwasser-Micali (GM) encryption [16] to
ensure that encrypted values are either treated as 0 or 1,
restricting the inﬂuence of a malicious relay. Put another
way, all relays (malicious or not) are strictly bounded in
their inﬂuence over the total aggregate. In the sections that
follow, we demonstrate both analytically and empirically that
HisTor’s binning strategy supports a wide range of queries
useful for Tor researchers while enforcing strong integrity
guarantees and imposing low communication and computation
overheads.
HisTor also provides resistance to so called “compulsion
attacks” in which a relay operator is compelled to release
information to a (potentially totalitarian) government. Statistics
gathering requires, obviously, gathering statistics, which itself
poses a privacy risk since these statistics would not otherwise
be collected. For example, Tor does not currently log client
connections to guards; queries which ask for a histogram of
the number of guard connections thus may impose additional
privacy risks. We design HisTor to mitigate such risks through
the use of encrypted data structures we call oblivious bin
counters. Simply put, we use efﬁcient cryptographic techniques
and data structures to maintain counters that the relay operators
cannot read on their own.
II. BACKGROUND
Tor.
Tor is a network of volunteer-operated routers that
enhances privacy by separating network identity from network
location [9]. The Tor client proxies a user’s TCP connections
through a series of randomly selected relays, which collectively
form a circuit. Several TCP connections may be multiplexed
over the same circuit. The ﬁrst hop on this circuit—the ingress
point to the Tor network—is usually a Tor guard relay, a Tor
relay that is relatively stable and is deemed to have sufﬁcient
bandwidth for the task. As a notable exception, trafﬁc may also
enter the Tor network through bridge nodes, which are similar
to guards but are not publicly advertised. Trafﬁc exits the Tor
network through exit relays, which establish TCP connections
to the intended destination. Along the Tor circuit, cryptography
helps conceal the actual sender and receiver—relays know only
the previous and next hop along the anonymous path.
Tor is designed to be robust against a non-global adversary,
meaning that it provides protections against an adversary who
cannot view all trafﬁc on the network. It is known to be
vulnerable against trafﬁc correlation attacks [20] in which an
adversary can observe an anonymous connection as it enters
and leaves the anonymity network. Here, using timing and
ﬂow analysis,
the adversary can correlate the ingress and
egress trafﬁc and determine that
they belong to the same
trafﬁc stream,
thus de-anonymizing both endpoints of the
communication.
Our current understanding of Tor’s usage is limited.
The information we do have about Tor’s real-world usage
is unfortunately incomplete, outdated, and sometimes even
contradictory.
The study by McCoy et al. [24] is perhaps the earliest
attempt at understanding how Tor is used, but its ﬁndings are
now almost a decade old and reﬂect a historical Tor network
that had one ﬁfth of the relays and fewer than half of the
number of daily users as the network does today [31]. More
importantly, the surreptitious capturing and analysis of real
users’ anonymized trafﬁc ﬂows is now viewed as ethically
ambiguous and even potentially harmful; indeed, the work
is sometimes cited as being an exemplar of unsafe security
research [30].
The ongoing debate [28] between supporters of the Tor
network and the CloudFare CDN further highlights the lack of
a clear understanding of how Tor is used. Brieﬂy, CloudFare
forced Tor users to complete user-unfriendly CAPTCHAs
before accessing any of the vast number of CloudFare’s
hosted sites. The CTO of CloudFare cited the large portion
of attack trafﬁc originating from Tor exit relays as the prin-
ciple motivation of the CAPTCHAs. The Tor Project publicly
responded [27] by questioning the accuracy of CloudFare’s
measurements, and pointed to a report by Akamai [1] showing
that Tor trafﬁc had a similar proportion of attack trafﬁc as the
regular (non-anonymized) Internet.
Similarly, researchers have published measurement studies
that show that an enormous percentage of connections to Tor
Hidden Services go to hidden service sites that serve child
pornography [4]. This is again disputed by the maintainers of
the Tor Project [23].
Background on differential privacy.
Differential pri-
vacy [10] seeks to minimize the privacy risk of participating in
a database while maximizing the accuracy of statistical queries
against that database. Although several notions of differential
privacy exist, this paper considers (, δ)-differential privacy as
introduced by Dwork et al. [11]: a computation F gives (, δ)-
differential privacy if, for all data sets D1 and D2 that differ
on only one row, and all S ⊆ Range(F),
Pr[F(D1) ∈ S] ≤ exp() × Pr[F(D2) ∈ S] + δ
Crucially, differential privacy’s formal guarantees are about the
properties of the database mechanism rather than the computa-
tional capabilities or auxiliary knowledge of the adversary. In
2
practice, differential privacy is achieved by adding noise to the
result of some aggregate query. The parameter  controls the
tradeoff between privacy and utility: a larger  provides weaker
privacy but more accurate results. The inclusion of δ relaxes
the more rigid notion of -differential privacy and allows for
more practical implementations.
In this paper, we adopt the distributed (, δ)-differential
privacy scheme of Chen et al. [6]. In their work, an analyst
poses a question to a ﬁxed set of c clients. Each client
ci contributes a bit vector3 vi = {vi,1, . . . , vi,q}, encrypted
using Goldwasser-Micali (GM) bit cryptosystem [16] with the
analyst’s public key. GM encryption enforces the property
that ciphertext can only encode 0 or 1. To provide privacy,
a proxy adds in n encrypted random noise vectors, where n is
calculated as
n = (cid:98) 64 ln(2/δ)
(cid:99) + 1
2
(1)
The GM-encrypted c + n client and noise vectors are then
shufﬂed by the proxy and returned to the analyst. The analyst
uses its private key to decrypt the bit vectors. Letting di,j be
the jth element of vector i (where 1 ≤ i ≤ c + n), the analyst
obtains the (noised) aggregate result aj as
c+n(cid:88)
k=1
aj =
dj,k − n
2
(2)
for all 1 ≤ j ≤ q (the number of elements in a bit vector) [6].
In the work by Chen et al. [6], the authors set δ < 1/c in
Eq. 1. However, Dwork et al. [13] prove that such a value of δ
is very dangerous, as it permits compromising the privacy of
“just a few” number of clients. Therefore, we set δ to a much
lower value, typically on the order of 10−6/c.
Also, we use  = 1 for our experiments, unless otherwise
noted. We note that this offers more privacy than the experi-
mental setting ( = 5) used by Chen et al. [6].
III. MANIPULATING PRIVEX
PrivEx [15] is the ﬁrst system for private data collection
on the live Tor network. It has (justiﬁably) garnered signiﬁcant
attention from the privacy-enhancing technologies community
and has been promoted as an example of a technology that
enables safe data collection on Tor [32].
In comparison with HisTor, which we introduce in the
next section, PrivEx has a similar system model, but differs
in that relays individually contribute their own noise. This
has the advantage that malicious proxies cannot break privacy
guarantees by not following the protocol. However, PrivEx
makes implicit trust assumptions that allow any malicious relay
to manipulate the results of a differentially private query.
Brieﬂy, Elahi et al.
introduce two PrivEx variants for
private collection of trafﬁc statistics on Tor. In both their secret-
sharing and distributed decryption schemes, an invariant is that
relays contribute their own individual value, and the system