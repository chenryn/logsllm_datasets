### Importance of Considering Both Metrics

It is crucial to evaluate both metrics concurrently. Focusing on only one can lead to an inflated value at the expense of the other. For example, a large pulse window size will result in a concentration efficiency of 1 (ignoring packet drops), but there will be no bandwidth gain. Conversely, a very small target window could yield an extremely high bandwidth gain (if a single packet lands within it) but a very low concentration efficiency.

### Bandwidth Measurement

We measure bandwidth in terms of packets per second (pps). In our evaluation, the packets we send and receive are small (around 100 bytes), which can make the quantities appear artificially high. For context, 10,000 pps translates to approximately 8 Mbps.

### Experimental Results

To assess the effectiveness of lensing, we emulated attacks on machines under our control. We used a Windows Azure VM instance on the West Coast as the attacker and two additional VM instances—one on Azure and one on Amazon Web Services (AWS), both on the East Coast—as our targets. We utilized a publicly available list of 3,000 resolvers [1] as reflectors.

We registered a domain name that allowed us to run authoritative DNS servers under our control. The AWS target instance was made authoritative for our domain, and the Azure target instance was authoritative for a subdomain of the original. This setup enabled us to send recursive DNS queries through any open recursive DNS server to either of our targets.

Before initiating an attack, the attack machine quickly scans the resolver list, issuing recursive queries to obtain latency measurements. We gathered 10 samples from each resolver, which proved sufficient for our attacks. For each resolver, we constructed a histogram of the distribution of attack path latencies and used this, along with a variant of the optimization algorithm discussed in § IV, to create the sending schedule. During the attack, we sent packets to the resolvers according to this schedule.

### Pulse Emulation Results

Figure 4 shows the results of pulses emulating attackers with different bandwidths using a relatively narrow pulse window of 20 ms. The emulation setup artificially capped the outgoing bandwidth by adjusting the minimum time between sending adjacent packets. The bandwidth gain is calculated by dividing the height of the pulse bucket by that of the tallest bucket for the attacker's sending. We observed gains of 14x for the low-bandwidth case, 10x for moderate bandwidth, and 5x for high bandwidth. Efficiency is determined by dividing the area of the pulse bucket by that of the sending buckets. We found efficiencies around 50% for the low- and medium-bandwidth cases, and just under 40% for the high-bandwidth case.

The colors in Figure 4a map onto the reflectors used. We observed that while many reflectors contributed to the pulse, some did not, likely due to misleading latency measurements or jitter during the attack.

### Secondary Pulses and Retransmissions

Figures 4b and 4c show what appear to be multiple pulses. These secondary spikes result from retransmissions by the resolvers. The target (an authoritative DNS server) could not keep up with the rate of incoming queries and failed to respond to many of them. The resolvers then timed out and retransmitted. Since many resolvers share a common retransmit timeout, their retransmissions converged at a specific time. We identified two common retransmit timeouts: 800 ms and 2 s. Retransmissions also caused the total number of packets received by the target to often exceed the total number sent by the attacker by about a factor of two, though our metrics were chosen such that these additions do not affect our characterizations of the attack's efficacy.

### Lensing Metrics and Pulse Window Duration

Figure 5 illustrates how the lensing metrics vary with pulse window duration when the attacker's bandwidth is fixed at 10K pps and the maximum per-reflector bandwidth at 500 pps. As expected, the bandwidth gain (and absolute pulse bandwidth) decreases as the window size increases. This is not an indication of poor performance but rather an intrinsic consequence of choosing a larger window size. In fact, the increase in efficiency suggests that, at larger window sizes, lensing performs closer to optimal, albeit with a less sharp pulse.

While efficiency increases modestly with window size, it levels off at larger window sizes. This leveling off can be attributed to significant jitter in high-latency paths. For a window size of 100 ms, resolvers with attack path latencies less than 250 ms (about half of those used) showed an efficiency of about 80%, while those with latencies over 250 ms showed an efficiency of about 40%, resulting in an overall efficiency of about 60%.

### Maximum Bandwidth to Reflectors

Figure 6 shows lensing properties as a function of the maximum bandwidth to any reflector, with the attacker's bandwidth fixed at 10K pps and the window size at 20 ms. The variation in bandwidth gain and pulse bandwidth reflects high throttling of bandwidth to a constant-size pool of reflectors. The key metric is concentration efficiency, which shows little variation except at very high throttling (sending only 1 or 2 packets per reflector), where we observe high efficiency but no bandwidth gain. This indicates that excessive throttling prevents the creation of a pulse. Given the lack of variation in efficiency, we conclude that limiting the bandwidth to each reflector provides little benefit, except for stealth.

### Scaling with Attacker Bandwidth

Figure 7 shows how the attack scales as a function of the attacker's bandwidth, with the pulse window fixed at 20 ms and the per-reflector bandwidth at 500 pps. The relatively constant efficiency at the beginning indicates good scalability. The diminishing bandwidth gain can be explained by the fact that we throttle bandwidth to each reflector while keeping the pool of available reflectors constant. However, all metrics perform poorly at higher bandwidths. Plotting peak pulse bandwidth versus maximum attacker bandwidth reveals that the largest pulse we can create of duration 20 ms has a bandwidth of 50–60K pps. The apparent pulse degradation at scale could be due to increased jitter and queuing, causing pulse flattening or packet loss.

### Performance of Azure and AWS Instances

To determine the cause of poor scaling for the Azure instance, we stressed it at a rate of 100K pps. After three trials, we found the maximum download bandwidth for small DNS packets fell between 57–62K pps, indicating that the Azure instance's bottleneck resource was saturated. In contrast, the AWS instance could accommodate a higher pps rate, with the pulse only starting to scale poorly at about 110–120K pps. The difference in behavior between Azure and AWS, particularly in handling unaccounted-for packets, suggests that AWS responds to excessive traffic by dropping packets, whereas Azure buffers them. This discrepancy indicates that the attack worked effectively, and the leveling-off at ≈ 120K pps is due to an AWS resource limit.

### Extensions

In this section, we assess several additions or potential "improvements" to lensing attacks.

#### Attacks on Arbitrary End-Hosts

We have developed lensing attacks in the context of targeting DNS servers. To target more rewarding victims, an attacker must calculate attack path latencies to the host. We present two methods, both influenced by King [8].

**DNS Cache Manipulation:** We use manipulation of DNS cache contents to calculate latencies between a DNS resolver and any other server. By creating a DNS entry in our own authoritative DNS server, we can issue queries to the resolver for subdomains, causing it to query the target server. The chain of queries reveals the attack path RTT. This method can be extended to arbitrary end-hosts by replacing the target server with any arbitrary server. If the server does not have a service running on port 53, it should respond with an ICMP Port Unreachable, allowing us to calculate the RTT.

Two issues arise: the target server might not receive packets due to firewalls, or the resolver implementation may not handle ICMP error messages appropriately. Our server, using the default configuration of BIND9 on Ubuntu Linux, does both: it issues an ICMP error when port 53 lacks a running service and responds immediately to ICMP errors. We tested this method and found it effective with many resolvers, though some resolvers did not respond as expected.