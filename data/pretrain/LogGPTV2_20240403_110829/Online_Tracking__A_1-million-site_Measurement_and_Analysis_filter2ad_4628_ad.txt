### Default Stateful Configuration
- **Ghostery**: Enabled
- **Block TP Cookies**: Enabled
- **HTTPS Everywhere**: Enabled
- **ID Detection 1***: Enabled
- **ID Detection 2***: Enabled

### Measurement Results
| Sites | Success | Timeout | % |
|-------|---------|---------|---|
| 1 Million | 917,261 | 82,739 | 8.27% |
| 100,000 | 94,144 | 5,856 | 5.86% |
| 55,000 | 50,023 | 4,977 | 9.05% |
| 55,000 | 53,688 | 1,312 | 2.39% |
| 55,000 | 53,705 | 1,295 | 2.36% |
| 10,000 | 9,707 | 293 | 2.93% |
| 10,000 | 9,702 | 298 | 2.98% |

*Indicates that the measurements were run synchronously on different virtual machines.

### Flash and HTTP Configurations
- **Flash**: Enabled
- **Stateful**: Enabled
- **Parallel**: Enabled
- **HTTP**: Enabled

### Crawl Duration
- **1 Million Sites**: 14 days
- **100,000 Sites**: 3.5 days
- **55,000 Sites**: 0.7 days
- **55,000 Sites**: 0.8 days
- **55,000 Sites**: 1 day
- **10,000 Sites**: 2.9 days
- **10,000 Sites**: 2.9 days

### Table 2: Census Measurement Configurations
- An unmarked circle indicates that a seed profile of length 10,000 was loaded into each browser instance in parallel.
- **# Success** indicates the number of sites that were reachable and returned a response.
- **Timeout** is a request that fails to completely load within 90 seconds.

### Stateful vs. Stateless Measurements
To comprehensively measure tracking, both stateful and stateless measurements are necessary. Stateful measurements do not clear the browser's profile between page visits, allowing cookies and other storage to persist. This is essential for certain measurements, such as cookie syncing (Section 5.6).

Stateful measurements conflict with parallelism, but a serial measurement of 1,000,000 sites would be impractical. Therefore, we create a seed profile by visiting the top 10,000 sites serially and saving the resulting state. This seed profile is then loaded into multiple browser instances running in parallel, simulating a serial visit to each website.

For our 100,000 site stateless measurement, we used the "ID Detection 2" browser profile as a seed profile. This method has limitations, such as third parties not appearing in the top sites having different cookies set in each parallel instance. A seed profile that has visited the top 10,000 sites will have communicated with 76% of all third-party domains present on more than 5 of the top 100,000 sites.

### Error Handling
In presenting results, only sites that loaded successfully are considered. For example, in the 1 Million site measurement, statistics are presented for 917,261 sites. The majority of errors are due to DNS lookup failures or non-2XX HTTP status codes like 404 (Not Found) or 500 (Internal Server Error).

### Detecting ID Cookies
Detecting cookies that store unique user identifiers is crucial for many of our results. We use methods from previous studies [1, 14]. Each cookie value string is parsed assuming the format:
```
(name1=)value1|...|(nameN=)valueN
```
where `|` represents any character except `a-zA-Z0-9 -=`. A (cookie-name, parameter-name, parameter-value) tuple is considered an ID cookie if it meets the following criteria:
1. The cookie has an expiration date over 90 days in the future.
2. The parameter-value length is between 8 and 100 characters.
3. The parameter-value remains the same throughout the measurement.
4. The parameter-value is different between machines and has a similarity less than 66% according to the Ratcliff-Obershelp algorithm [7].

### Tracker Classification
Every third party is potentially a tracker, but we use a more conservative definition using EasyList and EasyPrivacy. EasyList classifies advertising-related trackers, while EasyPrivacy detects non-advertising-related trackers. These lists consist of regular expressions and URL substrings matched against resource loads to determine if a request should be blocked.

Alternative lists, such as Ghostery and Disconnect, are evaluated but not used directly for classification. We classify each instance of a third party on a particular website as a tracking or non-tracking context. A domain is in the tracking context if a consumer privacy tool would block that resource. Resource loads not blocked by these extensions are considered non-tracking.

While there is agreement between the extensions, they are not perfect and contain false positives and negatives. Tracking-protection lists should be considered an underestimate of the set of trackers.

### Methodological and Measurement Limitations
- Our platform did not interact with sites as a real user might; no logins, scrolling, or clicking links.
- Analyses pertain only to homepages.
- A preliminary analysis of a crawl visiting 4 internal pages in addition to the homepage of the top 10,000 sites shows an increase in the average number of third parties per site from 22 to 34.
- The 20 most popular third parties are found on 6% to 57% more sites when internal page loads are considered.
- Fingerprinting scripts, including canvas fingerprinting, increased from 4% to 7% of the top sites, and canvas-based font fingerprinting increased from 2% to 2.5%.

### Data Collection
Measurements were collected from an EC2 instance in Amazon’s US East region. Some sites may respond differently to our measurement instance compared to a real user browsing from a residential or commercial internet connection. However, Fruchter et al. [17] found no evidence of tracking differences caused by the origin of the measurement instance.

### Tracking Techniques
OpenWPM measures a diverse set of tracking techniques but does not provide a complete analysis of all known techniques. Notably absent are non-canvas-based font fingerprinting, navigator and plugin fingerprinting, and cookie respawning. Several JavaScript-based techniques are supported by OpenWPM and can be easily added.

### Appendix
Further methodological details are provided in the Appendix, including:
- What constitutes distinct domains (13.1)
- How to detect the landing page of a site using the data collected by our Platform (13.2)
- How we detect cookie syncing (13.3)
- Why obfuscation of JavaScript doesn’t affect our ability to detect fingerprinting (13.4)

### Results of 1-Million Site Census
During our January 2016 measurement of the Top 1 million sites, our tool made over 90 million requests, assembling the largest dataset on web tracking to our knowledge. The total number of third parties present on at least two first parties is over 81,000, with only 123 of these present on more than 1% of sites. Google, Facebook, Twitter, and AdNexus are the only third-party entities present on more than 10% of sites.

![Figure 2: Top third parties on the top 1 million sites](figure2.png)

Not all third parties are classified as trackers, and the prevalence of third parties quickly drops off, suggesting that the number of third parties a regular user encounters daily is relatively small.