O(|SA|)
O(d log |SA|)
(c) Comparison of data structures at 8 bits per element
Figure 4: Approximate Reconciliation Statistics
simply the bitwise XOR of a speciﬁc subset of the input symbols.
A decoder attempts to recover the content from the encoding sym-
bols. For a given symbol, we refer to the number of input symbols
used to produce the symbol as its degree, i.e. y3 = x3 ⊕ x4 has
degree 2. The time to produce an encoding symbols from a set of
input symbols is proportional to the degree of the symbol, while de-
coding from a sequence of symbols takes time proportional to the
total degree of the symbols in the sequence, using the substitution
rule deﬁned in [17]. Encoding and decoding times are a function of
the average degree; when the average degree is constant, we say the
code is sparse.
Well-designed sparse parity check codes typically require recovery
of a few percent (less than 5%) of symbols beyond ", the minimum
needed for decoding. The decoding overhead of a code is deﬁned
to be d if (1 + d)" encoding symbols are needed on average to
recover the original content.
9
Provably good degree distributions have been developed and an-
alyzed in [17, 16]. Our experience has been that heuristic ap-
proaches to generate degree distributions that leverage ideas from
these works also perform well in practice for our application [11].
TRANSMISSION OF ENCODED CONTENT
Full Server
Peer A
Peer B
I
O
R
I
O
R
I
O
R
TRANSMISSION OF RECODED CONTENT
Encode
Decode
Network transfer
Figure 5: Example of transmission of encoded an recoded content.
I: input symbols (original data blocks), O: encoded output symbols,
R: recoded output symbols.
5.4.2 Recoding Methods
A recoded symbol is simply the bitwise XOR of a set of encoded
symbols. Like a regular encoded symbol, a recoded symbol must
be accompanied by a speciﬁcation of the symbols blended to cre-
ate it. To specify the input symbols combined, a recoded symbol
must also list identiﬁers for the encoded symbols from which it was
produced. As with normal sparse parity check codes, irregular de-
gree distributions work well, although we advocate use of a ﬁxed
degree limit primarily to keep the listing of identiﬁers short. En-
coding and decoding are performed in a fashion analogous to the
substitution rule. For example, a peer with output symbols y5, y8
and y13 can generate recoded symbols z1 = y13, z2 = y5 ⊕ y8 and
z3 = y5 ⊕ y13. A peer that receives z1, z2 and z3 can immediately
recover y13. Then by substituting y13 into z3, the peer can recover
y5, and similarly can recover y8 from z2. As the output symbols are
recovered, the normal decoding process proceeds. The overall ﬂow
from input symbols to recoded symbols and back in an example
where a server is directly connected to two peers and the two peers
are engaged in an additional collaboration is illustrated in Figure 5.
To get a feel for the probabilities involved, we consider the proba-
bility that a recoded symbol is immediately useful. Assume peer B
is generating recoded symbols from ﬁle F for peer A and by virtue
of a transmitted sketch, knows the containment c =
. The
probability that a recoded symbol of degree d immediately yields
|SA∩SB|
|SB|
(c|SB|
d−1 )((1−c)|SB|
)
(
1
|SB|
d )
a new encoded symbol is
. This is maximized
(cid:1)
c
1−c
(cid:2)
for d =
. (Note that as recoded symbols are received, con-
tainment naturally increases and the target degree increases accord-
ingly.) Using this formula for d maximizes the probability of imme-
diate beneﬁt but is actually not optimal, since a recoded symbol of
this degree runs a large risk of being useless. Thus we use this value
of d as a lower limit on the actual degree generated, and generate
degrees between this value and the maximum allowable degree, in-
clusively. Recoded symbols which are not immediately useful are
often eventually useful with the aid of recoded (or encoded) sym-
bols which arrive later. By increasing the degree at the cost of im-
55B
A
B
S
A
(a)
(b)
(c)
Figure 6: Scenarios considered in our experiments. (a) Peer-to-peer
reconciliation, (b) Peer-to-peer collaboration augmenting a down-
load, (c) Download from multiple peers in parallel.
mediate beneﬁt, the probability of completely redundant symbols is
substantially reduced.
6 Experimental Results
Our experiments focus on showing the overhead and potential
speedups of using our methods in peer-to-peer reconciliation as
well as in the setting of downloads augmented by collaborative
transfers. We ﬁrst show the feasibility of reconciling with a peer
with partial content, by demonstrating the overhead in receiving
symbols from such a sender. Next, we evaluate the use of senders
with partial content, alone or supplementing full senders, and show
the potential for speedups from parallel collaborative transfers. The
simple scenarios we present are designed to be illustrative and high-
light the primary beneﬁts of our methods; the performance im-
provements we demonstrate can be extrapolated onto more complex
scenarios.
6.1 Simulation Parameters
All of our experiments focus on collaborative transfers of a 128MB
ﬁle. We assume that the origin server divides this ﬁle into 95,870 in-
put symbols of 1400 bytes each, and subsequently encodes this ﬁle
into a large set of output symbols. We associate each output sym-
bol with an identiﬁer representing the set of input symbols used to
produce it; our simulations used 64-bit identiﬁers. The irregular de-
gree distribution used in the codes was generated using heuristics
based on the discussion in Section 5.4 and described in [11]. This
degree distribution had an average degree of 11 for the encoded
symbols and average decoding overhead of 2.3%. The experiments
used the simplifying assumption of a constant decoding overhead
d = 2.5%. For recoding, we generated degree distributions in the
same fashion with a maximum degree of 50. Rather than generate
recoding degree distributions on the ﬂy, we instead generated them
off-line and parameterized by containment and the percentage of
available symbols desired by the receiving peer, both in increments
of 0.05. We note that using more sophisticated techniques for gen-
erating degree distributions and reducing decoding overhead such
as those described in [17, 16] will improve our results accordingly.
Min-wise summaries employed 180 permutations, yielding 180 en-
tries of 64 bits each for a total of 1440 bytes per summary. Fine-
grained reconciliation used Bloom ﬁlters with 6 hash functions and
8(1 + d) bits per input symbol, for a total of 96 KB per ﬁlter.
Overhead measurements presented in this section using the faster
approximate reconciliation tree methods are visually indistinguish-
able from those using Bloom ﬁlters and are not included. Additional
experiments comparing approximate reconciliation trees to Bloom
ﬁlters will be detailed in a subsequent paper.
6.2 Collaboration Methods
We compare the following three methods of orchestrating collab-
oration in our experiments, described both in increasing order of
complexity and performance. While our methods may be combined
in other ways, these scenarios illustrate the basic tradeoffs. The de-
tails of the scenarios are as follows.
Uninformed Collaboration The sending peer randomly picks an
available symbol to send. This simple strategy is used by
Swarmcast [30] and works best when working sets are un-
correlated.
Speculative Collaboration The sending peer uses a min-wise
summary from the receiving peer to estimate the containment
and heuristically tune the degree distribution of recoded sym-
bols which it encodes and sends. The containment estimated
from the min-wise summary and the number of symbols re-
quested are used to pick a pre-generated distribution tuned
as described earlier. Fractions used in picking pre-generated
distributions were rounded down to multiples of 0.05 except
when the desired fraction would be zero. This choice of distri-
bution does not take into account correlation with other send-
ing peers but will be at least as efﬁcient as uninformed collab-
oration (arguably a special case) and frequently more so.
Reconciled Collaboration The sending peer uses either a Bloom
ﬁlter or an approximate reconciliation tree from the receiving
peer to ﬁlter out duplicate symbols and sends a random per-
mutation of them without repetition. The Bloom ﬁlter and ap-
proximate reconciliation trees are made large enough to con-
tain all of the output symbols at the end of the process since
they will be updated incrementally as output symbols are re-
covered. Random permutations of the transmitted encoding
symbols are used to minimize the likelihood that two distinct
sending peers send identical encoding symbols to the receiv-
ing peer.
Techniques from speculative collaboration can be combined with
the methods for reconciled collaboration to optimize performance
over lossy channels or when transfers from peers with highly cor-
related working sets are employed in parallel.
6.3 Scenarios and Evaluation
In the scenarios we examine, we vary three components; the set of
connections in the overlay formed between sources and peers, the
distribution of content among collaborating peers, and the slack of
the scenario, deﬁned as follows.
Deﬁnition 4 (Slack) The slack s associated with a set of peers Y
(cid:3)
|
SX|
X∈Y
(cid:12)
is
total number of input symbols.
where SX is the working set of peer X and " is the
By this deﬁnition, in a scenario of slack s, there are s" distinct out-
put symbols in the working sets of peers in Y . Clearly, when the
slack is less than 1 + d, the set of peers Y will be unable to re-
cover the ﬁle even if they use an exact reconciliation algorithm,
10
56d
a
e
h
r
e
v
O
1.4
1.2
1
0.8
0.6
0.4
0.2
0
Uninformed
Speculative
Reconciled
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
Initial Containment
(a) Slack = 1.1
d
a
e
h
r
e
v
O
1.4
1.2
1
0.8
0.6
0.4
0.2
0
0
Uninformed
Speculative
Reconciled
0.05
0.1
0.15
0.2
0.25
0.3
Initial Containment
(b) Slack = 1.2
d
a
e
h
r
e
v
O
1.4
1.2
1
0.8
0.6
0.4
0.2
0
Figure 7: Overhead of peer-to-peer reconciliation.
Uninformed
Speculative
Reconciled
0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18
Initial Containment
(c) Slack = 1.3
since the decoding overhead alone is d. When the slack is larger
than 1 + d, and if peers are using a reconciliation algorithm with
accuracy a, then they can expect to be able to retrieve the ﬁle if
(1 + d) ≤ sa. Our methods provide the most signiﬁcant beneﬁts
over naive methods when there is only a small amount of slack; as
noted earlier, approximate reconciliation is not especially difﬁcult
when the slack is large. We use slack values of 1.1, 1.2, and 1.3 for
comparison between compact scenarios with little available redun-
dancy and looser scenarios. When varying slack has little effect on
the results, only the results for a slack value of 1.1 are shown.
For simplicity, we assume that each connection has the same
amount of available bandwidth; our methods apply irrespective of
this assumption. The receiving peer A for whom we measure the
overhead always starts with 0.5" output symbols from the server.
The output symbols known to the sending peers are determined by
the slack of the scenario and the containment deﬁned in Section 4;
this will be discussed in detail for each particular scenario below.
To evaluate each technique, we measure the overall overhead of
each strategy where an overhead of  means that (1 + )" symbols
need to be received on average to recover a ﬁle of " input symbols.
In case of a server sending encoded content without aid from peers
with partial content, the overhead is merely the decoding overhead,
i.e.  = d. In other scenarios, there may be additional reception
overhead arising from duplicate or useless received encoding sym-
bols or recoding overhead from useless recoded symbols. The x-
axis of each plot is the range of containment of the sending peers
by the receiving peer. Each data point is the average of 50 simula-
tions.
6.3.1 Peer-to-Peer Reconciliation
The simplest scenario to consider is composed of two peers with
partial content where one peer sends symbols to the other. This sce-
nario is illustrated in Figure 6(a), and is designed to illustrate the
feasibility of our approach even in the worst case when servers with
a complete copy of the ﬁle are no longer available and reconcilia-
tion and recovery is barely possible.
For receiving peer A, sending peer B, with a ﬁle consisting of "
input symbols and slack s,
"s = |SA| + |SB| − |SA ∩ SB|.
(1)
d
a
e
h
r
e
v
O
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
Uninformed
Speculative
Reconciled
0
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
Initial Containment
Figure 8: Overhead of peer-augmented downloads, slack = 1.1
|SA∩SB|
,
|SB|
"s − |SA|
1 − c
.
By the deﬁnition of containment, c =
|SB| =
(2)
These two equations therefore uniquely determine |SA|, |SB| and
|SA∩SB| as a function of the slack and the containment. The |SA∪
SB| symbols are then distributed as follows: |SA ∩ SB| symbols
are distributed to both A and B, |SA| − |SA ∩ SB| symbols are
distributed to A, and the remainder are distributed to B.
Before continuing, we note that one additional constraint is needed
to keep the scenarios realistic, namely, neither A nor B alone
should be able to recover the ﬁle (otherwise, no transfer is necessary
or B can generate fresh symbols). That is, |SA, SB| ≤ (1 + d)",
where d is the decoding overhead. This gives an upper bound on
feasible values of c for a given slack s, explaining the variation be-