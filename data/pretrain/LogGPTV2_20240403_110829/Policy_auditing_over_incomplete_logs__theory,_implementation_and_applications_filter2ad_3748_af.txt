sages entering the system based on eight attributes attached
to each message (such as its sender, intended recipient, sub-
ject, type of information and purpose). The prototype tool
has a usable front-end and provides a useful interface for
understanding what types of disclosures and uses of per-
sonal health information are permitted and forbidden by
the HIPAA Privacy Rule. However, as recognized by the
authors, the approach has certain limitations in demonstrat-
ing compliance with the HIPAA Privacy Rule. First, it does
not support temporal conditions. While pLogic uses spe-
cialized predicates to capture that certain events happened
in the past, it cannot represent future obligations needed to
formalize many clauses in HIPAA. In contrast, our policy
logic and the reduce algorithm handle temporal conditions,
including real-time conditions. Second, reasoning in pLogic
proceeds assuming that all asserted beliefs, purposes and
types of information associated with messages are correct.
In contrast, since reduce mines logs to determine truth values
of atoms, it does not assume facts unless there is evidence
in logs to back them up. Typically, a purpose or belief will
be taken as true only if a human auditor (or some other or-
acle) supplies evidence to that eﬀect. Finally, our prototype
implementation was evaluated with a formalization of the
entire HIPAA Privacy Rule, whereas Lam et al. formalize
only §§164.502, 164.506 and 164.510.
Policy Speciﬁcation and Analysis. Several variants of
LTL have been used to specify the properties of programs,
business processes and security and privacy policies [6, 15,
8, 18, 23]. The logic we use as well as the formalization of
HIPAA used in our experiments are adapted from our prior
work on the logic PrivacyLFP [15]. PrivacyLFP, in turn,
draws inspiration from earlier work on the logic LPU [6].
However, PrivacyLFP is more expressive than LPU because
it allows ﬁrst-order quantiﬁcation over inﬁnite domains.
Further, several access-control models have extensions for
specifying usage control and future obligations [20, 10, 28,
21, 26, 16, 27]. Some of these models assume a pre-deﬁned
notion of obligations [21, 26]. For instance, Irwin et al. [21]
model obligations as tuples containing the subject of the
obligation, the actions to be performed, the objects that
are targets of the actions and the time frames of the obli-
gations. Other models leave speciﬁcations for obligations
abstract [20, 10, 28]. Such speciﬁc models and the ensuing
policies can be encoded in our logic using quantiﬁers.
There also has been much work on analyzing the proper-
ties of policies represented in formal models. For instance,
Ni et al. study the interaction between obligation and autho-
rization [26], Irwin et al. have analyzed accountability prob-
lems with obligations [21], and Dougherty et al. have mod-
eled the interaction between obligations and programs [16].
These methods are orthogonal to our objective of policy en-
forcement.
Finally, privacy languages such as EPAL [4] and priva-
cyAPI [25] do not include obligations or temporal modalities
as primitives, and are less expressive than our framework.
7. CONCLUSION AND FUTURE WORK
We have presented the design, implementation, and eval-
uation of a provably correct iterative algorithm for policy
audit, reduce, that works even with incomplete audit logs.
Our policy logic is expressive enough to represent real pri-
vacy legislation like HIPAA, yet tractable due to a carefully
designed static analysis. Our empirical evaluation shows
that reduce is eﬃcient enough to be used in practice.
In future work, we plan to investigate two applications be-
sides after-the-fact auditing using the reduce algorithm as a
core. The ﬁrst application is runtime monitoring of policies.
In this context, reduce can be applied to the part of the pol-
icy relevant to an action to be performed with a hypothetical
log that includes the future action. If the resulting formula
is unsatisﬁable, then the action to be performed is a viola-
tion. If the resulting formula is satisﬁed, then the action is
permitted. Finally, if reduce outputs a non-trivial residual
formula (involving, for example, beliefs, purposes, or future
obligations), the residual policy can be used to guide agents
about legitimacy of actions they are about to perform. Such
a tool will be useful to organizations in educating their em-
ployees about appropriate disclosures and uses of personal
information as described in complex policies, such as the
HIPAA Privacy Rule.
The second application is accounting of actions involving
personal information of individual data subjects. Proposals
for informing patients about disclosures and uses of their
personal health information are currently being debated in
the U.S. [14]. reduce can be run on the entire policy with a
subset of the logs that pertain to a speciﬁc agent to discover
all disclosures related to that agent and evidence support-
ing whether the disclosures were violations, permitted, or
conditionally permitted.
We also plan to integrate our audit algorithm into a policy-
aware health information exchange system that is being de-
veloped as part of the SHARPS project (http://sharps.
org) that we participate in. Ensuring that disclosures of
protected health information are made in accordance with
privacy regulations is critical in this setting. This project
also provides a vehicle to deploy and evaluate the eﬀective-
ness of this algorithm over real hospital logs. Another di-
rection of ongoing and future work is to develop semantic
foundations and enforcement techniques for concepts in pri-
vacy policies related to purposes and beliefs that at ﬁrst
glance appear diﬃcult to formalize and enforce using com-
putational methods.
Acknowledgments. This work was partially supported
by the U.S. Army Research Oﬃce contract “Perpetually
Available and Secure Information Systems” (DAAD19-02-
1-0389) to Carnegie Mellon CyLab, the NSF Science and
Technology Center TRUST, the NSF CyberTrust grant “Pri-
vacy, Compliance and Information Risk in Complex Organi-
zational Processes”, the AFOSR MURI “Collaborative Poli-
cies and Assured Information Sharing”, and HHS Grant no.
HHS 90TR0003/01.
8. REFERENCES
[1] R. Alur and T. A. Henzinger. A really temporal logic.
Journal of the ACM, 41(1):181–203, 1994.
[2] K. R. Apt and E. Marchiori. Reasoning about Prolog
programs: From modes through types to assertions.
Formal Aspects of Computing, 6(6):743–765, 1994.
[3] F. Baader, A. Bauer, and M. Lippmann. Runtime
veriﬁcation using a temporal description logic. In
Proceedings of the 7th International Conference on
Frontiers of Combining Systems (FroCos), pages
149–164, 2009.
[4] M. Backes, B. Pﬁtzmann, and M. Schunter. A toolkit
for managing enterprise privacy policies. In
Proceedings of the 8th European Symposium on
Research in Computer Security (ESORICS), LNCS
2808, pages 101–119, 2003.
[5] H. Barringer, A. Goldberg, K. Havelund, and K. Sen.
Rule-based runtime veriﬁcation. In Proceedings of the
5th International Conference on Veriﬁcation, Model
Checking, and Abstract Interpretation (VMCAI),
pages 44–57, 2004.
[6] A. Barth, A. Datta, J. C. Mitchell, and
H. Nissenbaum. Privacy and contextual integrity:
Framework and applications. In Proceedings of the
27th IEEE Symposium on Security and Privacy
(Oakland), pages 184–198, 2006.
[7] A. Barth, J. C. Mitchell, A. Datta, and S. Sundaram.
Privacy and utility in business processes. In
Proceedings of the 20th IEEE Computer Security
Foundations Symposium (CSF), pages 279–294, 2007.
[8] D. Basin, F. Klaedtke, and S. M¨uller. Monitoring
security policies with metric ﬁrst-order temporal logic.
In Proceeding of the 15th ACM Symposium on Access
Control Models and Technologies (SACMAT), pages
23–34, 2010.
[9] D. A. Basin, F. Klaedtke, and S. M¨uller. Policy
monitoring in ﬁrst-order temporal logic. In
Proceedings of the 22nd International Conference on
Computer Aided Veriﬁcation (CAV), pages 1–18, 2010.
[10] C. Bettini, S. Jajodia, X. S. Wang, and D. Wijesekera.
Provisions and obligations in policy rule management.
Journal of Network and Systems Management,
11:351–372, 2003.
[11] G. Bruns and P. Godefroid. Generalized model
checking: Reasoning about partial state spaces. In
Proceedings of the 11th International Conference on
Concurrency Theory (CONCUR), pages 168–182,
2000.
[12] J. G. Cederquist, R. Corin, M. A. C. Dekker,
S. Etalle, J. I. den Hartog, and G. Lenzini.
Audit-based compliance control. International Journal
of Information Security, 6(2):133–151, 2007.
[13] Deloitte & Touche and the Ponemon Institute.
Enterprise@Risk: 2007 Privacy and Data Protection
Survey. White Paper, December 2007.
[14] Department of Health and Human Services, Oﬃce of
the Secretary. HIPAA Privacy Rule accounting of
disclosures under the health information technology
for economic and clinical health act. 45 CFR 164,
2011. Available at http://www.gpo.gov/fdsys/pkg/
FR-2011-05-31/pdf/2011-13297.pdf.
[15] H. DeYoung, D. Garg, L. Jia, D. Kaynar, and
A. Datta. Experiences in the logical speciﬁcation of
the HIPAA and GLBA privacy laws. In Proceedings of
the 9th Annual ACM Workshop on Privacy in the
Electronic Society (WPES), 2010. Full version:
Carnegie Mellon University Technical Report
CMU-CyLab-10-007.
[16] D. J. Dougherty, K. Fisler, and S. Krishnamurthi.
Obligations and their interaction with programs. In
Proceedings of the 12th European Symposium on
Research in Computer Security (ESORICS), pages
375–389, 2007.
[17] D. Garg, L. Jia, and A. Datta. A logical method for
policy enforcement over evolving audit logs. Technical
Report CMU-CyLab-11-002, Carnegie Mellon
University, 2011.
[18] C. Giblin, A. Y. Liu, S. M¨uller, B. Pﬁtzmann, and
X. Zhou. Regulations expressed as logical models
(REALM). In Proceeding of the 18th Annual
Conference on Legal Knowledge and Information
Systems (JURIX), pages 37–48, 2005.
[19] P. Godefroid and M. Huth. Model checking vs.
generalized model checking: Semantic minimizations
for temporal logics. In Proceedings of the 20th Annual
IEEE Symposium on Logic in Computer Science
(LICS), pages 158–167, 2005.
[20] M. Hilty, D. A. Basin, and A. Pretschner. On
obligations. In Proceedings of the 10th European
Symposium on Research in Computer Security
(ESORICS), pages 98–117, 2005.
[21] K. Irwin, T. Yu, and W. H. Winsborough. On the
modeling and analysis of obligations. In Proceedings of
the 13th ACM Conference on Computer and
Communications Security (CCS), pages 134–143, 2006.
[22] P. E. Lam, J. C. Mitchell, and S. Sundaram. A
formalization of HIPAA for a medical messaging
system. In Proceedings of the 6th International
Conference on Trust, Privacy and Security in Digital
Business (TrustBus), pages 73–85, 2009.
[23] Y. Liu, S. M¨uller, and K. Xu. A static
compliance-checking framework for business process
models. IBM Systems Journal, 46:335–361, 2007.
[24] Z. Manna and A. Pnueli. Temporal Veriﬁcation of
Reactive Systems: Safety. Springer-Verlag, 1995.
[25] M. J. May, C. A. Gunter, and I. Lee. Privacy APIs:
Access control techniques to analyze and verify legal
privacy policies. In Proceedings of the 19th IEEE
Workshop on Computer Security Foundations
(CSFW), pages 85–97, 2006.
[26] Q. Ni, E. Bertino, and J. Lobo. An obligation model
bridging access control policies and privacy policies. In
Proceedings of the 13th ACM Symposium on Access
Control Models and Technologies (SACMAT), pages
133–142, 2008.
[27] OASIS XACML Committee. Extensible access control
markup language (XACML) v2.0, 2004. Available at
http://www.oasis-open.org/specs/#xacmlv2.0.
[28] J. Park and R. Sandhu. Towards usage control models:
beyond traditional access control. In Proceedings of
the 7th ACM Symposium on Access Control Models
and Technologies (SACMAT), pages 57–64, 2002.
[29] G. Ro¸su and K. Havelund. Rewriting-based techniques
for runtime veriﬁcation. Automated Software
Engineering, 12:151–197, 2005.
[30] M. Roger and J. Goubault-Larrecq. Log auditing
through model-checking. In Proceedings of the 14th
IEEE Workshop on Computer Security Foundations
(CSF), pages 220–236, 2001.
[31] O. Sokolsky, U. Sammapun, I. Lee, and J. Kim.
Run-time checking of dynamic properties. Electronic
Notes in Theoretical Computer Science, 144:91–108,
2006.
[32] P. Thati and G. Ro¸su. Monitoring algorithms for
[33] US Congress. Gramm-Leach-Bliley Act, Financial
metric temporal logic speciﬁcations. Electronic Notes
in Theoretical Computer Science, 113:145–162, 2005.
Privacy Rule. 15 USC §6801–§6809, November 1999.
Available at http://www.law.cornell.edu/uscode/
usc_sup_01_15_10_94_20_I.html.
[34] US Congress. Health Insurance Portability and
Accountability Act of 1996, Privacy Rule. 45 CFR
164, 2002. Available at http://www.access.gpo.gov/
nara/cfr/waisidx_07/45cfr164_07.html.