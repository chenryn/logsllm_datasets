(cid:4) to be generally around
4–20 frames, whereas K (i.e., total attack time determined by
safety hijacker) was found to be generally 10–65 frames. Since
(cid:4) is small, the chances of detection are signiﬁcantly lower.
K
Perturbing Camera Sensor Data. Here the goal of the
perturbation is to shift the position of the object detected by
the object detector (e.g., YOLOv3). To achieve that objective,
we formulate the problem of generating perturbed camera
sensor data using Eq. (2) in [15]. We omit the details because
of lack of space.
D. Implementation
We implemented RoboTack using Python and C++. More-
over, we used fault injection-based methods to implement the
attack steps of RoboTack. The proposed malware has a small
footprint, i.e., less than 500 lines of Python/C++ code, and
4% additional GPU utilization with negligible CPU utilization
in comparison to the autonomous driving stack. This makes
it difﬁcult to detect an attack using methods that monitor the
usage of system resources.
V. EXPERIMENTAL SETUP
A. AI Platform
In this work, we use Apollo [9] as an AI agent for driving
the AV. Apollo is built by Baidu and is openly available on
GitHub [33]. However, we use LGSVL’s version of Apollo
5.0 [34], as it provides features to support integration of the
LGSVL simulator [10] with Apollo. Apollo uses multiple sen-
sors: a Global Positioning System (GPS), Inertial measurement
units (IMU), radar, LiDAR, and multiple cameras. Our setup
used two cameras (ﬁtted at the top and front of the vehicle)
and one LiDAR for perception.
B. Simulation Platform
We used the LGSVL simulator [10] that uses Unity [35], a
gaming engine [36], to simulate driving scenarios. Note that a
driving scenario is characterized by the number of actors (i.e.,
objects) in the world, their initial trajectories (i.e., position,
velocity, acceleration, and heading), and their waypoints (i.e.,
their route from source to destination). In our setup, LGSVL
simulated the virtual environment and posted virtual sensor data
to the ADS for consumption. The sensors included a LiDAR, a
front-mounted main camera, a top-mounted telescope camera,
IMU, and GPS. The measurements for different sensors were
posted at different frequencies [37]. In our experiments, the
cameras produced data at 15 Hz (of size 1920x1080), GPS at
◦
12.5 Hz, and LiDAR is rotating at 10 Hz and producing 360
measurements per rotation. At the time of this writing, LGSVL
does not provide integration of continental radar for Apollo.
In addition, LGSVL provides Python APIs for creating driving
scenarios, which we leveraged to develop the driving scenarios
described next.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:29:50 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4: Driving scenarios. EV: Ego Vehicle. TV: Target Vehicle. NPC: Other Vehicles with no interaction with EV.
C. Driving Scenarios
Here we describe the driving scenarios, shown in Fig. 4,
that were used in our experiments. All our driving scenarios
were generated using LGSVL on "Borregeas Avenue" (located
in Sunnyvale, California, USA), which has a speed limit of
50 kph. Unless otherwise speciﬁed, in all the cases EV was
cruising at 45 kph.
In driving scenario 1 or "DS-1," the Ego vehicle (EV)
followed a target vehicle (TV) in the Ego lane at a constant
speed (25 kph), as shown in Figure 4. The TV started 60
meters ahead of the EV. In the golden (i.e., non-attacked) run,
the EV would accelerate to 40 kph and come closer to the TV
at the beginning, and then gradually decelerate to 25 kph to
match the speed of the TV. Thereafter, the EV maintained a
longitudinal distance of 20 meters behind the TV for the rest of
the scenario. We used this scenario to evaluate the Disappear
and Move_Out attack vectors on a vehicle.
In driving scenario 2 or "DS-2," a pedestrian illegally
crossed the street as shown in Figure 4. In the golden run,
the EV braked to avoid collision and stopped more than 10
meters away from the pedestrian, if possible. The EV started
traveling again when the pedestrian moved off the road. We
used this scenario to evaluate the Disappear and Move_Out
attack vectors on a pedestrian.
In driving scenario 3 or "DS-3," a target vehicle was parked
on the side of the street in the parking lane. In the golden run,
the EV maintained its trajectory (lane keeping). We used this
scenario to evaluate the Move_In attack vector on a vehicle.
In driving scenario 4 or "DS-4," a pedestrian walked
longitudinally towards the EV in the parking lane (next to the
EV lane) for 5 meters then stood still for the rest of the scenario.
In the golden run, EV recognized the pedestrian, at which point
it reduced its speed to 35 kph. However, once it ensured that
the pedestrian was safe (by evaluating its trajectory), it resumed
its original speed. We use this scenario to evaluate the Move_In
attack vector on a pedestrian.
In driving scenario 5 or "DS-5," there are multiple vehicles
with random waypoints and trajectories, as shown in Figure
4. Throughout the scenario, the EV was set to follow a target
vehicle just as in "DS-1," with multiple non-AV vehicles
traveling on the other lane of the road as well as in front
or behind (not shown). Apart from the target vehicle, the
vehicles traveled at random speeds and starting from random
positions in their lanes. We used this scenario as the baseline
scenario for a random attack to evaluate the effectiveness of
our attack end-to-end.
D. Hardware Platform
The production version of the Apollo ADS is supported on
the Nuvo-6108GC [38], which consists of Intel Xeon CPUs
120
and NVIDIA GPUs. In this work, we deployed Apollo on an
x86 workstation with a Xeon CPU, ECC memory, and two
NVIDIA Titan Xp GPUs.
VI. EVALUATION & DISCUSSION
A. Characterizing Perception System on Pretrained YOLOv3
in Simulation
We characterize the performance of YOLOv3 (used in the
Apollo perception system) in detecting objects on the road,
while the AV is driving, to measure 1) the distribution of
successive frames from an AV camera feed in which a vehicle or
a pedestrian is continuously undetected, and 2) the distribution
of error in the center positions of the predicted bounding boxes
compared to the ground-truth bounding boxes. We characterize
those quantities to show that an attack mounted by RoboTack
and the natural noise associated with the detector are from the
same distribution. In particular, we show that the continuous
misdetection caused by RoboTack is within the 99th percentile
of the continuous characterized misdetection distribution of the
YOLOv3 detector; see Figure 5. That is important because if
our attack fails, the object will reappear and be ﬂagged by the
IDS as an attack attempt. Similarly, we characterize the error
in the predicted bounding box to ensure that our injected noise
is within the estimated Gaussian distribution parameters shown
in Figure 5. RoboTack changes the position at time-step t by
at max μ − σ ≤ ω ≤ μ + σ of the Gaussian distribution. For
this characterization, we generated a sequence of images and
labels (consisting of object bounding boxes and their classes)
by manually driving the vehicle on the San Francisco map for
10 minutes in simulation.
Continuous misdetections. Fig. 5 (a) and (b) show the
distribution of the number of frames in which pedestrians and
vehicles were continuously misdetected. Here we consider an
object as misdetected if the IoU between the predicted and
ground-truth bounding boxes is less than 60%. The data follow
an exponential distribution.
Bounding box prediction error. To characterize the noise
in the position of the bounding boxes predicted by YOLOv3,
we computed the difference between the center of the pre-
dicted bounding box and the ground-truth bounding box and
normalized it by the size of the ground-truth bounding box.
Only predicted bounding boxes that overlap with the ground-
truth boxes are considered. Fig. 5(c), (d), (e), and (f) show the
distribution of normalized errors for the x (horizontal) and y
(vertical) coordinates in the image of the bounding box centers
for pedestrians and vehicles. The coordinates of the centers
of the YOLOv3-predicted bounding boxes follow a Gaussian
noise model.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:29:50 UTC from IEEE Xplore.  Restrictions apply. 
= 0.717)
99th perc: 31.0
(a) Exp(loc = 1, λ
(b) Exp(loc = 1, λ
(f) Normal(μ =
0.186, σ = 0.409)
99th perc: 1.868
Figure 5: YOLOv3 object detection characterization on driving video generated using LGSVL. (a–b) show continuous
misdetections with IoU=60%. (c–f) show the distribution of normalized errors in the bounding box center predictions along the
x and y coordinates of the image for vehicles and pedestrians.
(c) Normal(μ =
0.023, σ = 0.464)
99th perc: 1.145
(d) Normal(μ =
0.094, σ = 0.586)
99th perc: 1.775
(e) Normal(μ =
0.254, σ = 2.010)
99th perc: 5.235
99th perc: 59.4
= 0.327)
K
# runs
101
144
185
138
148
135
131
# crashes (%)
32 (31.7%)
119 (82.6%)
32 (17.3%)
116 (84.1%)
# EB (%)
54 (53.5%)
136 (94.4%)
69 (37.3%)
135 (97.8%)
140 (94.6%) —
106 (78.5%) —
3 (2.3%)
0
ID
48
DS-1-Disappear-R
14
DS-2-Disappear-R
65
DS-1-Move_Out-R
32
DS-2-Move_Out-R
48
DS-3-Move_In-R
DS-4-Move_In-R
24
DS-5-Baseline-Random K*
Table II: Smart malware attack summary compared with
random (in bold). EB: Emergency Braking. R: Robotack. In
our experiments, the AV tried emergency braking in all runs
that resulted in accidents. K* means K was randomly picked
between 15 and 85 for each run of the experiment.
B. Quantifying Baseline Attack Success
In the baseline attack (Baseline-Random), we altered the
object trajectory by (i) randomly choosing an object (i.e., a
vehicle or a pedestrian) for which the trajectory will be changed,
(ii) randomly choosing the attack vector for a simulation run,
(iii) randomly initiating the attack at time-step t of the driving
scenario, and (iv) continuing the attack for (a randomly chosen)
K time-steps. In other words, Baseline-Random) attack neither
used scenario matcher nor used safety hijacker to mount the
attack on the AV. However, it mimics trajectory hijacker to
modify the trajectory of the vehicle. We used 131 experimental
runs of DS-5 in which the AV was randomly driving around the
city to characterize the success of the baseline attack. Across all
131 experimental runs (see "DS-5-Baseline-Random," §VI-A),
the AV performed emergency braking (EB) in only 3 runs
(2.3%) and crashed 0 times.
Here we also compare RoboTack with attacks where both
scenario matcher and trajectory hijacker are used (labeled as
"R w/o SH" in Fig. 6). However, these attacks do not use safety
hijacker (SH). Hence, in these attacks, we randomly initiated
the attack, and continue to attack for (a randomly chosen) K
time-steps, where K is between 15 and 85. The results of these
attacks are described in detail in §VI-D.
Taken together these experiments provide a comparison with
the current state-of-the-art adversarial attacks [14], [15].
C. Quantifying RoboTack Attack Success
In §VI-A, ID stands for the unique identiﬁer for experimental
campaigns, which is a concatenation of "driving scenario
id" and "attack vector." Here a campaign refers to a set
of simulation runs executed with the same driving scenario
121
and attack vector. We also append TH and SH to the ID to
inform the reader that both trajectory-hijacking and safety-
hijacking were enabled in these attacks. Other ﬁelds are K
(median number of continuous perturbations), # runs (number
of experimental runs), # EB (number of runs that led to AV
emergency braking), and # crashes (number of runs that led
to AV accidents). For each 
pair, we ran 150 to 200 experiments, depending on the total
simulation time; however, some of our experimental runs were
invalid due to a crash of the simulator or the ADS. Those
experiments were discarded, and only valid experiments were
used for the calculations.
Across all scenarios and all attacks, we found that RoboTack
was signiﬁcantly more successful in creating safety hazards
than random attacks were. RoboTack caused 33× more
forced emergency brakings compared to random attacks, i.e.,
RoboTack caused forced emergency braking in 75.2% of the
runs (640 out of 851); in comparison, random attacks caused
forced emergency braking in 2.3% (3 out of 131 driving
simulations). Similarly, random attacks caused 0 accidents,
whereas RoboTack caused accidents in 52.6% of the runs (299
out of 568, excluding Move_In attacks).
Across all our experiments, RoboTack had a higher success
rate in attacking pedestrians (84.1% of the runs that involved
pedestrians) than in attacking vehicles (31.7% of the runs that
involved vehicles).
Safety hazards with pedestrians. We observed that Robo-
Tack was highly effective in creating safety hazards in driving
scenarios DS-2 and DS-4, which involve pedestrians. Here we
observe that in DS-2 with Move_Out attacks, the EV collided
with the pedestrian in 84.1% of the runs. Also, those attacks
led to EV emergency braking in 97.8% of the runs. In DS-2
with Disappear attacks, the EV collided with the pedestrian in
82.6% of the runs and led to emergency braking in 94.4% of
the runs. Finally, in DS-4 with Move_In attacks, we did not see
any accidents with a pedestrian as there was no real pedestrian
in the EV lane; however, the Move_In attacks led to emergency
braking in 78.5% of the runs. Note that emergency braking can
be life-threatening and injurious to passengers of the EV, so it
is a valid safety hazard. Interestingly, our malware needed to
modify only 14 camera frames for DS-2 with Disappear attacks
and 24 frames for DS-4 with Move_In attacks to achieve such
a high success rate in creating safety hazards.
Safety hazards with vehicles. We observed that RoboTack
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:29:50 UTC from IEEE Xplore.  Restrictions apply. 
was less successful in creating hazards involving vehicles (DS-1
and DS-3) than in creating hazards involving pedestrians. The
reason is that LiDAR-based object detection fails to register
pedestrians at a higher longitudinal distance, while recognizing
vehicles at the same distance. Although the pedestrian is
recognized in the camera, the sensor fusion delays the object
registration in the EV world model because of disagreement
between the LiDAR and camera detections. For the same
reason, RoboTack needs to perturb signiﬁcantly more camera
frames contiguously in the case of vehicles than in the case
of pedestrians. However, our injections were still within the
bounds of the observed noise in object detectors for vehicles.
Overall, Move_Out attacks in DS-1 caused emergency braking
and accidents in 37.3% and 17.3% of the runs, respectively,
whereas for the same driving scenario, Disappear attacks caused
emergency braking and accidents in 53.5% and 31.7% of the
runs, respectively. RoboTack was able to cause emergency
braking in 94.6% of the runs by using Move_In attacks in the
DS-3 driving scenario.
D. Safety Hijacker & Impact on Safety Potential
Here we characterize the impact of attacks mounted by