# Internet Jones and the Raiders of the Lost Trackers: An Archaeological Study of Web Tracking from 1996 to 2016

**Authors:** Adam Lerner, Anna Kornfeld Simpson, Tadayoshi Kohno, Franziska Roesner  
**Affiliation:** University of Washington  
**Publication:** Proceedings of the 25th USENIX Security Symposium, August 10–12, 2016, Austin, TX  
**DOI:** 978-1-931971-32-4  
**Open Access:** Sponsored by USENIX  
**Link:** [https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lerner](https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lerner)

## Abstract

Web tracking and its privacy implications have gained significant attention in recent years. However, this attention is relatively recent in the history of the web and lacks a comprehensive historical context. In this paper, we present longitudinal measurements of third-party web tracking behaviors from 1996 to 2016. Our tool, **TrackingExcavator**, leverages the Internet Archive's Wayback Machine to conduct a retrospective analysis of tracking over time.

We evaluate the Wayback Machine's view of past third-party requests, identifying its limitations and developing strategies to overcome them. Applying these strategies, we find that third-party tracking on the web has increased in prevalence and complexity since the first observed tracker in 1996. We also observe the spread of the most popular trackers to an increasing percentage of the most popular sites on the web.

Understanding the historical trends of the web tracking ecosystem, as provided in our work, is crucial for any technical and policy discussions surrounding tracking.

## 1. Introduction

Third-party web tracking involves entities such as advertisers, social media widgets, and website analytics engines embedded in first-party sites. These entities re-identify users across domains as they browse the web, raising significant privacy concerns. The academic community has produced a substantial body of work on understanding, measuring, and defending against web tracking (e.g., [3, 4, 6, 8, 14, 15, 18–20, 22, 24, 25, 27–30, 32–34, 37, 39–43, 45, 46, 51, 57, 60, 61, 64–66, 70, 71]).

However, the research community's interest in web tracking began relatively late in the web's history. The earliest measurement studies started in 2005 [42], with most coming after 2009, while display advertising and the HTTP cookie standard date back to the mid-1990s [44, 48]. Despite numerous studies, they typically consist of short-term measurements of specific tracking techniques. We argue that public and private discussions about web tracking should be informed by a comprehensive knowledge of its trajectory over time. This paper provides such a comprehensive view, conducting a measurement study of third-party web tracking over 20 years, from 1996 to 2016.

Measurement studies are critical for technologists, policymakers, and even sites that include trackers, to provide transparency for users, enable informed decisions about privacy, and incentivize companies to consider privacy. The web tracking ecosystem is continuously evolving, and single-point-in-time studies may only temporarily reduce the use of specific controversial tracking techniques [63]. While one can study tracking longitudinally starting in the present, as we and others have (e.g., [42, 63]), a comprehensive view of the ecosystem over time is essential. We provide this longitudinal, historical context, asking: how has the third-party web tracking ecosystem evolved since its beginnings?

To answer this question, we leverage the Internet Archive's Wayback Machine [31], which contains archives of full webpages, including JavaScript, stylesheets, and embedded resources, dating back to 1996. We design and implement **TrackingExcavator**, a retrospective tracking detection and analysis platform (Section 3). **TrackingExcavator** logs in-browser behaviors related to web tracking, including third-party requests, cookies attached to requests, cookies programmatically set by JavaScript, and the use of other relevant JavaScript APIs (e.g., HTML5 LocalStorage and APIs used in browser fingerprinting [15, 57]). **TrackingExcavator** can run on both live and archived versions of websites.

Harnessing the Wayback Machine for our analysis presents several challenges (Section 4). A key contribution of this paper is our evaluation of the historical data provided by the Wayback Machine and a set of lessons and techniques for extracting information about trends in third-party content over time. Through comparisons with ground truth datasets collected in 2011, 2013, 2015, and 2016, we find that the Wayback Machine's view of the past, particularly regarding included third-party content, is imperfect due to various reasons, including robots.txt restrictions, failures to archive embedded content, and inconsistent archiving times for site resources. Although popular sites are typically archived at regular intervals, their embedded content, including third-party trackers, may be only partially represented.

After evaluating the Wayback Machine's view and developing best practices for using its data, we use **TrackingExcavator** to conduct a longitudinal study of the third-party web tracking ecosystem from 1996 to 2016 (Section 5). We explore how this ecosystem has changed over time, including the prevalence of different web tracking behaviors, the identities and scope of popular trackers, and the complexity of relationships within the ecosystem. Among our findings, we identify the earliest tracker in our dataset in 1996 and observe the rise and fall of important players, such as Google Analytics, which now appears on over a third of all popular websites. We find that websites contact an increasing number of third parties over time (about 5% of the 500 most popular sites contacted at least 5 separate third parties in the early 2000s, whereas nearly 40% do so in 2016) and that the top trackers can track users across an increasing percentage of the web's most popular sites. We also find that tracking behaviors have changed over time, with third-party popups peaking in the mid-2000s and the fraction of trackers relying on referrals from other trackers recently rising.

Our findings show that third-party web tracking is a rapidly growing practice in an increasingly complex ecosystem, suggesting that users' and policymakers' concerns about privacy require sustained, and perhaps increasing, attention. Our results provide previously unavailable historical context for today's technical and policy discussions.

In summary, our contributions are:
1. **TrackingExcavator**: A measurement infrastructure for detecting and analyzing third-party web tracking behaviors in the present and, leveraging the Wayback Machine, in the past (Section 3).
2. An in-depth analysis of the scope and accuracy of the Wayback Machine's view of historical web tracking behaviors and trends, and techniques for working around its weaknesses (Section 4).
3. A longitudinal measurement study of third-party cookie-based web tracking from 1996 to 2016 — to the best of our knowledge, the longest longitudinal study of tracking to date (Section 5).

This paper and any updates, including any data or code we publish, will be made available at [http://trackingexcavator.cs.washington.edu/](http://trackingexcavator.cs.washington.edu/).

## 2. Background and Motivation

Third-party web tracking is the practice by which entities ("trackers") embedded in webpages re-identify users as they browse the web, collecting information about the websites they visit [50, 60]. Tracking is typically done for website analytics, targeted advertising, and other forms of personalization (e.g., social media content). For example, when a user visits www.cnn.com, the browser may make additional requests to doubleclick.net to load targeted ads and to facebook.com to load the "Like" button. As a result, DoubleClick and Facebook learn about that user's browsing habits.