# 第9讲 \| 对比Hashtable、HashMap、TreeMap有什么不同？Map 是广义 Java 集合框架中的另外一部分，HashMap作为框架中使用频率最高的类型之一，它本身以及相关类型自然也是面试考察的热点。今天我要问你的问题是，[对比 Hashtable、HashMap、TreeMap有什么不同？]{.orange}谈谈你对 HashMap 的掌握。
## 典型回答Hashtable、HashMap、TreeMap 都是最常见的一些 Map实现，是以**键值对**的形式存储和操作数据的容器类型。Hashtable 是早期 Java类库提供的一个[哈希表](https://zh.wikipedia.org/wiki/%E5%93%88%E5%B8%8C%E8%A1%A8)实现，本身是同步的，不支持null 键和值，由于同步导致的性能开销，所以已经很少被推荐使用。HashMap 是应用更加广泛的哈希表实现，行为上大致上与 HashTable一致，主要区别在于 HashMap 不是同步的，支持 null键和值等。通常情况下，HashMap 进行 put 或者 get操作，可以达到常数时间的性能，所以**它是绝大部分利用键值对存取场景的首选**，比如，实现一个用户ID 和用户信息对应的运行时存储结构。TreeMap 则是基于红黑树的一种提供顺序访问的 Map，和 HashMap 不同，它的get、put、remove 之类操作都是O（log(n)）的时间复杂度，具体顺序可以由指定的 Comparator来决定，或者根据键的自然顺序来判断。
## 考点分析上面的回答，只是对一些基本特征的简单总结，针对 Map相关可以扩展的问题很多，从各种数据结构、典型应用场景，到程序设计实现的技术考量，尤其是在Java 8 里，HashMap 本身发生了非常大的变化，这些都是经常考察的方面。很多朋友向我反馈，面试官似乎钟爱考察 HashMap的设计和实现细节，所以今天我会增加相应的源码解读，主要专注于下面几个方面：-   理解 Map 相关类似整体结构，尤其是有序数据结构的一些要点。-   从源码去分析 HashMap    的设计和实现要点，理解容量、负载因子等，为什么需要这些参数，如何影响    Map 的性能，实践中如何取舍等。-   理解树化改造的相关原理和改进原因。除了典型的代码分析，还有一些有意思的并发相关问题也经常会被提到，如HashMap 在并发环境可能出现[无限循环占用CPU](https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6423457)、size不准确等诡异的问题。我认为这是一种典型的使用错误，因为 HashMap明确声明不是线程安全的数据结构，如果忽略这一点，简单用在多线程场景里，难免会出现问题。理解导致这种错误的原因，也是深入理解并发程序运行的好办法。对于具体发生了什么，你可以参考这篇很久以前的[分析](http://mailinator.blogspot.com/2009/06/beautiful-race-condition.html)，里面甚至提供了示意图，我就不再重复别人写好的内容了。
## 知识扩展1.Map 整体结构首先，我们先对 Map 相关类型有个整体了解，Map 虽然通常被包括在 Java集合框架里，但是其本身并不是狭义上的集合类型（Collection），具体你可以参考下面这个简单类图。![](Images/2cd3d9784eabc622d649deeafcfb1ee9.png){savepage-src="https://static001.geekbang.org/resource/image/26/7c/266cfaab2573c9777b1157816784727c.png"}Hashtable 比较特别，作为类似 Vector、Stack的早期集合相关类型，它是扩展了 Dictionary 类的，类结构上与 HashMap之类明显不同。HashMap 等其他 Map 实现则是都扩展了AbstractMap，里面包含了通用方法抽象。不同 Map的用途，从类图结构就能体现出来，设计目的已经体现在不同接口上。``{=html}大部分使用 Map的场景，通常就是放入、访问或者删除，而对顺序没有特别要求，HashMap在这种情况下基本是最好的选择。**HashMap的性能表现非常依赖于哈希码的有效性，请务必掌握 hashCode 和 equals的一些基本约定**，比如：-   equals 相等，hashCode 一定要相等。-   重写了 hashCode 也要重写 equals。-   hashCode 需要保持一致性，状态改变返回的哈希值仍然要一致。-   equals 的对称、反射、传递等特性。这方面内容网上有很多资料，我就不在这里详细展开了。针对有序 Map 的分析内容比较有限，我再补充一些，虽然 LinkedHashMap 和TreeMap 都可以保证某种顺序，但二者还是非常不同的。-   LinkedHashMap    通常提供的是遍历顺序符合插入顺序，它的实现是通过为条目（键值对）维护一个双向链表。注意，通过特定构造函数，我们可以创建反映访问顺序的实例，所谓的    put、get、compute 等，都算作"访问"。这种行为适用于一些特定应用场景，例如，我们构建一个空间占用敏感的资源池，希望可以自动将最不常被访问的对象释放掉，这就可以利用LinkedHashMap 提供的机制来实现，参考下面的示例：    import java.util.LinkedHashMap;import java.util.Map;  public class LinkedHashMapSample {    public static void main(String[] args) {        LinkedHashMap accessOrderedMap = new LinkedHashMap(16, 0.75F, true){            @Override            protected boolean removeEldestEntry(Map.Entry eldest) { // 实现自定义删除策略，否则行为就和普遍 Map 没有区别                return size() > 3;            }        };        accessOrderedMap.put("Project1", "Valhalla");        accessOrderedMap.put("Project2", "Panama");        accessOrderedMap.put("Project3", "Loom");        accessOrderedMap.forEach( (k,v) -> {            System.out.println(k +":" + v);        });        // 模拟访问        accessOrderedMap.get("Project2");        accessOrderedMap.get("Project2");        accessOrderedMap.get("Project3");        System.out.println("Iterate over should be not affected:");        accessOrderedMap.forEach( (k,v) -> {            System.out.println(k +":" + v);        });        // 触发删除        accessOrderedMap.put("Project4", "Mission Control");        System.out.println("Oldest entry should be removed:");        accessOrderedMap.forEach( (k,v) -> {// 遍历顺序不变            System.out.println(k +":" + v);        });    }} -   对于 TreeMap，它的整体顺序是由键的顺序关系决定的，通过 Comparator 或    Comparable（自然顺序）来决定。我在上一讲留给你的思考题提到了，构建一个具有优先级的调度系统的问题，其本质就是个典型的优先队列场景，Java标准库提供了基于二叉堆实现的PriorityQueue，它们都是依赖于同一种排序机制，当然也包括 TreeMap 的马甲TreeSet。类似 hashCode 和 equals的约定，为了避免模棱两可的情况，自然顺序同样需要符合一个约定，就是compareTo 的返回值需要和 equals 一致，否则就会出现模棱两可情况。我们可以分析 TreeMap 的 put 方法实现：    public V put(K key, V value) {    Entry t = …    cmp = k.compareTo(t.key);    if (cmp  0)        t = t.right;    else        return t.setValue(value);        // ...   }从代码里，你可以看出什么呢？当我不遵守约定时，两个不符合唯一性（equals）要求的对象被当作是同一个（因为，compareTo返回 0），这会导致歧义的行为表现。2.HashMap 源码分析前面提到，HashMap设计与实现是个非常高频的面试题，所以我会在这进行相对详细的源码解读，主要围绕：-   HashMap 内部实现基本点分析。-   容量（capacity）和负载系数（load factor）。-   树化 。首先，我们来一起看看 HashMap内部的结构，它可以看作是数组（Node\\[\table）和链表结合组成的复合结构，数组被分为一个个桶（bucket），通过哈希值决定了键值对在这个数组的寻址；哈希值相同的键值对，则以链表形式存储，你可以参考下面的示意图。这里需要注意的是，如果链表大小超过阈值（TREEIFY_THRESHOLD,8），图中的链表就会被改造为树形结构。![](Images/768c4a095d36ec79da36dce560cbcac7.png){savepage-src="https://static001.geekbang.org/resource/image/1f/56/1f72306a9d8719c66790b56ef7977c56.png"}从非拷贝构造函数的实现来看，这个表格（数组）似乎并没有在最初就初始化好，仅仅设置了一些初始值而已。    public HashMap(int initialCapacity, float loadFactor){      // ...     this.loadFactor = loadFactor;    this.threshold = tableSizeFor(initialCapacity);} 所以，我们深刻怀疑，HashMap 也许是按照 lazy-load原则，在首次使用时被初始化（拷贝构造函数除外，我这里仅介绍最通用的场景）。既然如此，我们去看看put 方法实现，似乎只有一个 putVal 的调用：    public V put(K key, V value) {    return putVal(hash(key), key, value, false, true);}看来主要的密码似乎藏在 putVal里面，到底有什么秘密呢？为了节省空间，我这里只截取了 putVal比较关键的几部分。    final V putVal(int hash, K key, V value, boolean onlyIfAbent,               boolean evit) {    Node[] tab; Node p; int , i;    if ((tab = table) == null || (n = tab.length) = 0)        n = (tab = resize()).length;    if ((p = tab[i = (n - 1) & hash]) == ull)        tab[i] = newNode(hash, key, value, nll);    else {        // ...        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for first            treeifyBin(tab, hash);        //  ...      }} 从 putVal 方法最初的几行，我们就可以发现几个有意思的地方：-   如果表格是 null，resize 方法会负责初始化它，这从 tab = resize()    可以看出。-   resize    方法兼顾两个职责，创建初始存储表格，或者在容量不满足需求的时候，进行扩容（resize）。-   在放置新的键值对的过程中，如果发生下面条件，就会发生扩容。```{=html}```    if (++size > threshold)    resize();-   具体键值对在哈希表中的位置（数组 index）取决于下面的位运算：```{=html}```    i = (n - 1) & hash仔细观察哈希值的源头，我们会发现，它并不是 key 本身的hashCode，而是来自于 HashMap 内部的另外一个 hash方法。注意，为什么这里需要将高位数据移位到低位进行异或运算呢？**这是因为有些数据计算出的哈希值差异主要在高位，而HashMap里的哈希寻址是忽略容量以上的高位的，那么这种处理就可以有效避免类似情况下的哈希碰撞。**    static final int hash(Object kye) {    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>>16;}-   我前面提到的链表结构（这里叫    bin），会在达到一定门限值时，发生树化，我稍后会分析为什么 HashMap    需要对 bin 进行处理。可以看到，putVal方法本身逻辑非常集中，从初始化、扩容到树化，全部都和它有关，推荐你阅读源码的时候，可以参考上面的主要逻辑。我进一步分析一下身兼多职的 resize方法，很多朋友都反馈经常被面试官追问它的源码设计。    final Node[] resize() {    // ...    else if ((newCap = oldCap = DEFAULT_INITIAL_CAPAITY)        newThr = oldThr  0) // initial capacity was placed in threshold        newCap = oldThr;    else {          // zero initial threshold signifies using defaultsfults        newCap = DEFAULT_INITIAL_CAPAITY;        newThr = (int)(DEFAULT_LOAD_ATOR* DEFAULT_INITIAL_CAPACITY；    }    if (newThr ==0) {        float ft = (float)newCap * loadFator;        newThr = (newCap [] newTab = (Node[])new Node[newap];    table = n；    // 移动到新的数组结构 e 数组结构    } 依据 resize 源码，不考虑极端情况（容量理论最大极限由 MAXIMUM_CAPACITY指定，数值为 1\ 元素数量 所以，预先设置的容量需要满足，大于"预估元素数量 / 负载因子"，同时它是 2的幂数，结论已经非常清晰了。而对于负载因子，我建议：-   如果没有特别需求，不要轻易进行更改，因为 JDK    自身的默认负载因子是非常符合通用场景的需求的。-   如果确实需要调整，建议不要设置超过 0.75    的数值，因为会显著增加冲突，降低 HashMap 的性能。-   如果使用太小的负载因子，按照上面的公式，预设容量值也进行调整，否则可能会导致更加频繁的扩容，增加无谓的开销，本身访问性能也会受影响。我们前面提到了树化改造，对应逻辑主要在 putVal 和 treeifyBin 中。    final void treeifyBin(Node[] tab, int hash) {    int n, index; Node e;    if (tab == null || (n = tab.length) `{=html}-   理解基本的线程安全工具。-   理解传统集合框架并发编程中 Map 存在的问题，清楚简单同步方式的不足。-   梳理并发包内，尤其是 ConcurrentHashMap    采取了哪些方法来提高并发表现。-   最好能够掌握 ConcurrentHashMap    自身的演进，目前的很多分析资料还是基于其早期版本。今天我主要是延续专栏之前两讲的内容，重点解读经常被同时考察的 HashMap 和ConcurrentHashMap。今天这一讲并不是对并发方面的全面梳理，毕竟这也不是专栏一讲可以介绍完整的，算是个开胃菜吧，类似CAS 等更加底层的机制，后面会在 Java进阶模块中的并发主题有更加系统的介绍。
## 知识扩展1\. 为什么需要 ConcurrentHashMap？Hashtable 本身比较低效，因为它的实现基本就是将 put、get、size等各种方法加上"synchronized"。简单来说，这就导致了所有并发操作都要竞争同一把锁，一个线程在进行同步操作时，其他线程只能等待，大大降低了并发操作的效率。前面已经提过 HashMap 不是线程安全的，并发情况会导致类似 CPU 占用 100%等一些问题，那么能不能利用 Collections 提供的同步包装器来解决问题呢？看看下面的代码片段，我们发现同步包装器只是利用输入 Map构造了另一个同步版本，所有操作虽然不再声明成为 synchronized方法，但是还是利用了"this"作为互斥的 mutex，没有真正意义上的改进！    private static class SynchronizedMap    implements Map, Serializable {    private final Map m;     // Backing Map    final Object      mutex;        // Object on which to synchronize    // …    public int size() {        synchronized (mutex) {return m.size();}    } // … } 所以，Hashtable 或者同步包装版本，都只是适合在非高度并发的场景下。2.ConcurrentHashMap 分析我们再来看看 ConcurrentHashMap是如何设计实现的，为什么它能大大提高并发效率。首先，我这里强调，**ConcurrentHashMap 的设计实现其实一直在演化**，比如在Java 8 中就发生了非常大的变化（Java 7其实也有不少更新），所以，我这里将比较分析结构、实现机制等方面，对比不同版本的主要区别。早期 ConcurrentHashMap，其实现是基于：-   分离锁，也就是将内部进行分段（Segment），里面则是 HashEntry    的数组，和 HashMap 类似，哈希相同的条目也是以链表形式存放。-   HashEntry 内部使用 volatile 的 value    字段来保证可见性，也利用了不可变对象的机制以改进利用 Unsafe    提供的底层能力，比如 volatile    access，去直接完成部分操作，以最优化性能，毕竟 Unsafe    中的很多操作都是 JVM intrinsic 优化过的。你可以参考下面这个早期 ConcurrentHashMap内部结构的示意图，其核心是利用分段设计，在进行并发操作的时候，只需要锁定相应段，这样就有效避免了类似Hashtable 整体同步的问题，大大提高了性能。![](Images/c63b55f6c721e8bc0745b0e562c7a521.png){savepage-src="https://static001.geekbang.org/resource/image/d4/d9/d45bcf9a34da2ef1ef335532b0198bd9.png"}在构造的时候，Segment 的数量由所谓的 concurrentcyLevel 决定，默认是16，也可以在相应构造函数直接指定。注意，Java 需要它是 2的幂数值，如果输入是类似 15 这种非幂值，会被自动调整到 16 之类 2的幂数值。具体情况，我们一起看看一些 Map基本操作的[源码](http://hg.openjdk.java.net/jdk7/jdk7/jdk/file/9b8c96f96a0f/src/share/classes/java/util/concurrent/ConcurrentHashMap.java)，这是JDK 7 比较新的 get代码。针对具体的优化部分，为方便理解，我直接注释在代码段里，get操作需要保证的是可见性，所以并没有什么同步逻辑。    public V get(Object key) {        Segment s; // manually integrate access methods to reduce overhead        HashEntry[] tab;        int h = hash(key.hashCode());       // 利用位操作替换普通数学运算       long u = (((h >>> segmentShift) & segmentMask) )UNSAFE.getObjectVolatile(segments, u)) != null &&            (tab = s.table) != null) {           // 省略          }        return null;    }而对于 put 操作，首先是通过二次哈希避免哈希冲突，然后以 Unsafe调用方式，直接获取相应的 Segment，然后进行线程安全的 put 操作：     public V put(K key, V value) {        Segment s;        if (value == null)            throw new NullPointerException();        // 二次哈希，以保证数据的分散性，避免哈希冲突        int hash = hash(key.hashCode());        int j = (hash >>> segmentShift) & segmentMask;        if ((s = (Segment)UNSAFE.getObject          // nonvolatile; recheck             (segments, (j  node = tryLock() ? null :                scanAndLockForPut(key, hash, value);            V oldValue;            try {                HashEntry[] tab = table;                int index = (tab.length - 1) & hash;                HashEntry first = entryAt(tab, index);                for (HashEntry e = first;;) {                    if (e != null) {                        K k;                        // 更新已有 value...                    }                    else {                        // 放置 HashEntry 到特定位置，如果超过阈值，进行 rehash                        // ...                    }                }            } finally {                unlock();            }            return oldValue;        } 所以，从上面的源码清晰的看出，在进行并发写操作时：-   ConcurrentHashMap 会获取再入锁，以保证数据一致性，Segment    本身就是基于 ReentrantLock 的扩展实现，所以，在并发修改期间，相应    Segment 是被锁定的。-   在最初阶段，进行重复性的扫描，以确定相应 key    值是否已经在数组里面，进而决定是更新还是放置操作，你可以在代码里看到相应的注释。重复扫描、检测冲突是    ConcurrentHashMap 的常见技巧。-   我在专栏上一讲介绍 HashMap 时，提到了可能发生的扩容问题，在    ConcurrentHashMap    中同样存在。不过有一个明显区别，就是它进行的不是整体的扩容，而是单独对    Segment 进行扩容，细节就不介绍了。另外一个 Map 的 size 方法同样需要关注，它的实现涉及分离锁的一个副作用。试想，如果不进行同步，简单的计算所有 Segment 的总值，可能会因为并发put，导致结果不准确，但是直接锁定所有 Segment进行计算，就会变得非常昂贵。其实，分离锁也限制了 Map 的初始化等操作。所以，ConcurrentHashMap的实现是通过重试机制（RETRIES_BEFORE_LOCK，指定重试次数2），来试图获得可靠值。如果没有监控到发生变化（通过对比Segment.modCount），就直接返回，否则获取锁进行操作。下面我来对比一下，**在 Java 8 和之后的版本中，ConcurrentHashMap发生了哪些变化呢？**-   总体结构上，它的内部存储变得和我在专栏上一讲介绍的 HashMap    结构非常相似，同样是大的桶（bucket）数组，然后内部也是一个个所谓的链表结构（bin），同步的粒度要更细致一些。-   其内部仍然有 Segment    定义，但仅仅是为了保证序列化时的兼容性而已，不再有任何结构上的用处。-   因为不再使用 Segment，初始化操作大大简化，修改为 lazy-load    形式，这样可以有效避免初始开销，解决了老版本很多人抱怨的这一点。-   数据存储利用 volatile 来保证可见性。-   使用 CAS 等操作，在特定场景进行无锁并发操作。-   使用 Unsafe、LongAdder 之类底层手段，进行极端情况的优化。先看看现在的数据存储内部实现，我们可以发现 Key 是 final的，因为在生命周期中，一个条目的 Key 发生变化是不可能的；与此同时val，则声明为 volatile，以保证可见性。     static class Node implements Map.Entry {        final int hash;        final K key;        volatile V val;        volatile Node next;        // …     }我这里就不再介绍 get 方法和构造函数了，相对比较简单，直接看并发的 put是如何实现的。    final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException();    int hash = spread(key.hashCode());    int binCount = 0;    for (Node[] tab = table;;) {        Node f; int n, i, fh; K fk; V fv;        if (tab == null || (n = tab.length) == 0)            tab = initTable();        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {            // 利用 CAS 去进行无锁线程安全操作，如果 bin 是空的            if (casTabAt(tab, i, null, new Node(hash, key, value)))                break;         }        else if ((fh = f.hash) == MOVED)            tab = helpTransfer(tab, f);        else if (onlyIfAbsent // 不加锁，进行检查                 && fh == hash                 && ((fk = f.key) == key || (fk != null && key.equals(fk)))                 && (fv = f.val) != null)            return fv;        else {            V oldVal = null;            synchronized (f) {                   // 细粒度的同步修改操作...                 }            }            // Bin 超过阈值，进行树化            if (binCount != 0) {                if (binCount >= TREEIFY_THRESHOLD)                    treeifyBin(tab, i);                if (oldVal != null)                    return oldVal;                break;            }        }    }    addCount(1L, binCount);    return null;} 初始化操作实现在 initTable 里面，这是一个典型的 CAS 使用场景，利用volatile 的 sizeCtl 作为互斥手段：如果发现竞争性的初始化，就 spin在那里，等待条件恢复；否则利用 CAS设置排他标志。如果成功则进行初始化；否则重试。请参考下面代码：    private final Node[] initTable() {    Node[] tab; int sc;    while ((tab = table) == null || tab.length == 0) {        // 如果发现冲突，进行 spin 等待        if ((sc = sizeCtl)  0) ? sc : DEFAULT_CAPACITY;                    @SuppressWarnings("unchecked")                    Node[] nt = (Node[])new Node[n];                    table = tab = nt;                    sc = n - (n >>> 2);                }            } finally {                sizeCtl = sc;            }            break;        }    }    return tab;} 当 bin 为空时，同样是没有必要锁定，也是以 CAS 操作去放置。你有没有注意到，在同步逻辑上，它使用的是 synchronized，而不是通常建议的ReentrantLock 之类，这是为什么呢？现代 JDK 中，synchronized已经被不断优化，可以不再过分担心性能差异，另外，相比于ReentrantLock，它可以减少内存消耗，这是个非常大的优势。与此同时，更多细节实现通过使用 Unsafe 进行了优化，例如 tabAt就是直接利用 getObjectAcquire，避免间接调用的开销。    static final  Node tabAt(Node[] tab, int i) {    return (Node)U.getObjectAcquire(tab, ((long)i ）。    Windows 上 NIO2（AIO）模式则是依赖于 iocp（http://hg.openjdk.java.net/jdk/jdk/file/d8327f838b88/src/java.base/windows/classes/sun/nio/ch/Iocp.java）。-   Chartset，提供 Unicode 字符串定义，NIO    也提供了相应的编解码器等，例如，通过下面的方式进行字符串到    ByteBuffer 的转换：```{=html}```    Charset.defaultCharset().encode("Hello world!"));2.NIO 能解决什么问题？下面我通过一个典型场景，来分析为什么需要NIO，为什么需要多路复用。设想，我们需要实现一个服务器应用，只简单要求能够同时服务多个客户端请求即可。使用 java.io 和 java.net 中的同步、阻塞式 API，可以简单实现。``{=html}    public class DemoServer extends Thread {    private ServerSocket serverSocket;    public int getPort() {        return  serverSocket.getLocalPort();    }    public void run() {        try {            serverSocket = new ServerSocket(0);            while (true) {                Socket socket = serverSocket.accept();                RequestHandler requestHandler = new RequestHandler(socket);                requestHandler.start();            }        } catch (IOException e) {            e.printStackTrace();        } finally {            if (serverSocket != null) {                try {                    serverSocket.close();                } catch (IOException e) {                    e.printStackTrace();                }                ;            }        }    }    public static void main(String[] args) throws IOException {        DemoServer server = new DemoServer();        server.start();        try (Socket client = new Socket(InetAddress.getLocalHost(), server.getPort())) {            BufferedReader bufferedReader = new BufferedReader(new                   InputStreamReader(client.getInputStream()));            bufferedReader.lines().forEach(s -> System.out.println(s));        }    } }// 简化实现，不做读取，直接发送字符串class RequestHandler extends Thread {    private Socket socket;    RequestHandler(Socket socket) {        this.socket = socket;    }    @Override    public void run() {        try (PrintWriter out = new PrintWriter(socket.getOutputStream());) {            out.println("Hello world!");            out.flush();        } catch (Exception e) {            e.printStackTrace();        }    } } 其实现要点是：-   服务器端启动 ServerSocket，端口 0 表示自动绑定一个空闲端口。-   调用 accept 方法，阻塞等待客户端连接。-   利用 Socket 模拟了一个简单的客户端，只进行连接、读取、打印。-   当连接建立后，启动一个单独线程负责回复客户端请求。这样，一个简单的 Socket 服务器就被实现出来了。思考一下，这个解决方案在扩展性方面，可能存在什么潜在问题呢？大家知道 Java语言目前的线程实现是比较重量级的，启动或者销毁一个线程是有明显开销的，每个线程都有单独的线程栈等结构，需要占用非常明显的内存，所以，每一个Client 启动一个线程似乎都有些浪费。那么，稍微修正一下这个问题，我们引入线程池机制来避免浪费。    serverSocket = new ServerSocket(0);executor = Executors.newFixedThreadPool(8); while (true) {    Socket socket = serverSocket.accept();    RequestHandler requestHandler = new RequestHandler(socket);    executor.execute(requestHandler);} 这样做似乎好了很多，通过一个固定大小的线程池，来负责管理工作线程，避免频繁创建、销毁线程的开销，这是我们构建并发服务的典型方式。这种工作方式，可以参考下图来理解。![](Images/1b838835f924f7f669b2c5e48bcc4b7f.png){savepage-src="https://static001.geekbang.org/resource/image/da/29/da7e1ecfd3c3ee0263b8892342dbc629.png"}如果连接数并不是非常多，只有最多几百个连接的普通应用，这种模式往往可以工作的很好。但是，如果连接数量急剧上升，这种实现方式就无法很好地工作了，因为线程上下文切换开销会在高并发时变得很明显，这是同步阻塞方式的低扩展性劣势。NIO 引入的多路复用机制，提供了另外一种思路，请参考我下面提供的新的版本。    public class NIOServer extends Thread {    public void run() {        try (Selector selector = Selector.open();             ServerSocketChannel serverSocket = ServerSocketChannel.open();) {// 创建 Selector 和 Channel            serverSocket.bind(new InetSocketAddress(InetAddress.getLocalHost(), 8888));            serverSocket.configureBlocking(false);            // 注册到 Selector，并说明关注点            serverSocket.register(selector, SelectionKey.OP_ACCEPT);            while (true) {                selector.select();// 阻塞等待就绪的 Channel，这是关键点之一                Set selectedKeys = selector.selectedKeys();                Iterator iter = selectedKeys.iterator();                while (iter.hasNext()) {                    SelectionKey key = iter.next();                   // 生产系统中一般会额外进行就绪状态检查                    sayHelloWorld((ServerSocketChannel) key.channel());                    iter.remove();                }            }        } catch (IOException e) {            e.printStackTrace();        }    }    private void sayHelloWorld(ServerSocketChannel server) throws IOException {        try (SocketChannel client = server.accept();) {          client.write(Charset.defaultCharset().encode("Hello world!"));        }    }   // 省略了与前面类似的 main}这个非常精简的样例掀开了 NIO多路复用的面纱，我们可以分析下主要步骤和元素：-   首先，通过 Selector.open() 创建一个 Selector，作为类似调度员的角色。-   然后，创建一个 ServerSocketChannel，并且向 Selector 注册，通过指定    SelectionKey.OP_ACCEPT，告诉调度员，它关注的是新的连接请求。    **注意**，为什么我们要明确配置非阻塞模式呢？这是因为阻塞模式下，注册操作是不允许的，会抛出    IllegalBlockingModeException 异常。-   Selector 阻塞在 select 操作，当有 Channel 发生接入请求，就会被唤醒。-   在 sayHelloWorld 方法中，通过 SocketChannel 和 Buffer    进行数据操作，在本例中是发送了一段字符串。可以看到，在前面两个样例中，IO都是同步阻塞模式，所以需要多线程以实现多任务处理。而 NIO则是利用了单线程轮询事件的机制，通过高效地定位就绪的Channel，来决定做什么，仅仅 select阶段是阻塞的，可以有效避免大量客户端连接时，频繁线程切换带来的问题，应用的扩展能力有了非常大的提高。下面这张图对这种实现思路进行了形象地说明。![](Images/e55245ccf38fa0ef3174fcdb3472277d.png){savepage-src="https://static001.geekbang.org/resource/image/ad/a2/ad3b4a49f4c1bff67124563abc50a0a2.png"}在 Java 7 引入的 NIO 2 中，又增添了一种额外的异步 IO模式，利用事件和回调，处理 Accept、Read 等操作。 AIO实现看起来是类似这样子：    AsynchronousServerSocketChannel serverSock =        AsynchronousServerSocketChannel.open().bind(sockAddr);serverSock.accept(serverSock, new CompletionHandler<>() { // 为异步操作指定 CompletionHandler 回调函数    @Override    public void completed(AsynchronousSocketChannel sockChannel, AsynchronousServerSocketChannel serverSock) {        serverSock.accept(serverSock, this);        // 另外一个 write（sock，CompletionHandler{}）        sayHelloWorld(sockChannel, Charset.defaultCharset().encode                ("Hello World!"));    }  // 省略其他路径处理方法...});鉴于其编程要素（如 Future、CompletionHandler等），我们还没有进行准备工作，为避免理解困难，我会在专栏后面相关概念补充后的再进行介绍，尤其是Reactor、Proactor 模式等方面将在 Netty主题一起分析，这里我先进行概念性的对比：-   基本抽象很相似，AsynchronousServerSocketChannel 对应于上面例子中的    ServerSocketChannel；AsynchronousSocketChannel 则对应    SocketChannel。-   业务逻辑的关键在于，通过指定 CompletionHandler 回调接口，在    accept/read/write    等关键节点，通过事件机制调用，这是非常不同的一种编程思路。今天我初步对 Java 提供的 IO 机制进行了介绍，概要地分析了传统同步 IO 和NIO 的主要组成，并根据典型场景，通过不同的 IO模式进行了实现与拆解。专栏下一讲，我还将继续分析 Java IO 的主题。
## 一课一练关于今天我们讨论的题目你做到心中有数了吗？留一道思考题给你，NIO多路复用的局限性是什么呢？你遇到过相关的问题吗？请你在留言区写写你对这个问题的思考，我会选出经过认真思考的留言，送给你一份学习鼓励金，欢迎你与我一起讨论。你的朋友是不是也在准备面试呢？你可以"请朋友读"，把今天的题目分享给好友，或许你能帮到他。![](Images/ad11e858c146d898be1a6f5d5838732b.png){savepage-src="https://static001.geekbang.org/resource/image/a3/45/a3c4614fadf6248a2ac5d63ddcdf8945.jpg"}