|---|---|---|---|---|---|---|---|---|
| 0.75 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0.75 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0.75 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 || 0.50 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0.50 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0.50 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |
| 0.25 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0.25 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0.25 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 || 0.00 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0.00 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0.00 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |
| 1.00 |0 |(a) Android |1.00 |0 |(b) Apache |1.00 |0 |(c) BGL |
| 0.75 |0 |(a) Android |0.75 |0 |(b) Apache |0.75 |0 |(c) BGL |example program, where each item in the dictionary is a n-gram from a log message. In addition, the second step of parsing log messages is trivial to run in parallel where each log message is parsed independently4.We evaluate the scalability of Logram on a clustering with one master node and five worker nodes running Spark 2.43. Each node is deployed on a desktop machine with the same specifications as used in our efficiency evaluation (cf. Sec-tion 5.3). In total, our cluster has four cores for each worker, leading to a total of 20 cores for processing logs. We first store the log data into HDFS that are deployed on the cluster with a default option of three replications. We then run the Spark based Logram on the Spark cluster with one worker (four cores) to five workers (20 cores) enabled. We evaluate the scalability on the same log datasets used for evaluating the efficiency, except for Android due to its relatively small size. We measure the throughput for parsing each log data to assess scalability. Due to the possible noise in a local network environment and the indeterministic nature of the parallel processing framework, we independently repeat each run 10 times when measuring throughput, i.e., number of log messages parsed per second.| 0.50 | 0 | 0.50 | 0.50 | 0.50 | 0.50 | 0.50 | 0.50 | 0.50 | 0.50 | 4 	8 	12 	16 	20
Number of Cores | 4 	8 	12 	16 	20
Number of Cores |
|---|---|---|---|---|---|---|---|---|---|---|---|
| 0.25 |0 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |4 	8 	12 	16 	20 Number of Cores |4 	8 	12 	16 	20 Number of Cores |
| 0.00 |0 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |4 	8 	12 	16 	20 Number of Cores |4 	8 	12 	16 	20 Number of Cores || 1.00 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |4 	8 	12 	16 	20 Number of Cores |4 	8 	12 	16 	20 Number of Cores || 1.00 |0 |(d) Hadoop |(d) Hadoop |(e) HDFS |(e) HDFS |(e) HDFS |(e) HDFS |(f) HealthApp |(f) HealthApp |4 	8 	12 	16 	20 Number of Cores |4 	8 	12 	16 	20 Number of Cores |
| 1.00 |0 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |4 	8 	12 	16 	20 Number of Cores |4 	8 	12 	16 	20 Number of Cores |
| 0.75 |0 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |4 	8 	12 	16 	20 Number of Cores |4 	8 	12 	16 	20 Number of Cores || 0.50 |0 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 |(a) BGL |(b) HDFS |
| 0.25 |0 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |(a) BGL |(b) HDFS |
| 0.00 |0 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 | 4 	8 	12 	16 	20 Number of Cores | 4 	8 	12 	16 	20 Number of Cores || 0.00 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 | 4 	8 	12 	16 	20 Number of Cores | 4 	8 	12 	16 	20 Number of Cores || 1.00 |0 |(g) HPC |(g) HPC |(h) Linux |(h) Linux |(h) Linux |(h) Linux |(i) Mac |(i) Mac | 4 	8 	12 	16 	20 Number of Cores | 4 	8 	12 	16 	20 Number of Cores |
| 1.00 |0 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 | 4 	8 	12 	16 	20 Number of Cores | 4 	8 	12 	16 	20 Number of Cores |
| 0.75 |0 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 | 4 	8 	12 	16 	20 Number of Cores | 4 	8 	12 	16 	20 Number of Cores || 0.50 |0 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 | 4 	8 	12 	16 	20 Number of Cores | 4 	8 	12 	16 	20 Number of Cores |
| 0.25 |0 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 | 4 	8 	12 	16 	20 Number of Cores | 4 	8 	12 	16 	20 Number of Cores |
| 0.00 |0 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 | 4 	8 	12 	16 	20 Number of Cores | 4 	8 	12 	16 	20 Number of Cores || 0.00 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |(c) Windows |(d) Spark || 0.00 |0 |(j) OpenSSH |(j) OpenSSH |(k) OpenStack |(k) OpenStack |(k) OpenStack |(k) OpenStack |(l) Proxifier |(l) Proxifier |(c) Windows |(d) Spark |
| 0.00 |0 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |Fig. 6. Box plots of running time of Logram with different number of |Fig. 6. Box plots of running time of Logram with different number of |
| 0.00 |0 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |1.00 |cores. |cores. || 0.00 |0 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |cores. |cores. |
| 0.00 |0 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |0.75 |Results |Results |
| 0.00 |0 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 |0.50 |Results |Results |
| 0.00 |0 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |0.25 |Results |Results |
| 0.00 |0 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |0.00 |Results |Results || 0.00 |0 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |0 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95100 |Results |Results |(m) Spark 	(n) Zookeeper
Fig. 5. The agreement ratio of log parsing results with having a part of log to generate dictionary and using all logs to generate dictionary. The red vertical lines indicate that the agreement ratios reach 90%.
5.5 	ScalabilityIn order to achieve a high-scalability of log parsing, we migrate Logram to Spark. Spark [71] is an open-source dis-tributed data processing engine, with high-level API in several program languages such as Java, Scala, Python, and R. Spark has been adopted widely in practice for analyzing large-scale data including log analysis. We migrate each step of Logram, i.e., 1) generating n-gram model based dictionaries and 2) parsing log messages using dictionaries, separately to Spark. In particular, the first step of generat-ing dictionary is written similar as a typically wordcountLogram scales out efficiently with the number of Spark nodes without sacrificing parsing accuracy. Figure 6 uses boxplots to present the throughput (i.e., number of log messages parsed per second) of Logram when we increase the number of nodes from one (i.e., four cores) to five (i.e., 20 cores).As shown in Figure 6, the throughput increases nearly linearly, achieving up to 5.7 times speedup as we increase the number of nodes by a factor of five. In addition, Figure 6 shows that the throughput of Logram has low variance when we repeat the parsing of each log dataset 10 times. We would like to note that the parsing accuracy always keeps the same as we increase the number of nodes. When the volume of the parsed logs is very large (e.g., the Windows log data), Logram allows practitioners to increase the speed of log4. Due to the limited space, the detail of our implementation of the Spark based Logram is available in our replication package.
10
parsing efficiently by adding more nodes without sacrificing any accuracy.Logram achieves near-linear scalability for some logs but less scalabiltiy on other logs. A linear scalability means the throughput increases K times when we increase the number of nodes by a factor of K, which is usually the best one usually expects to achieve when scaling an application [72], [73]. The throughput of Logram when parsing the HDFS and Windows logs increases by 5.7 to 4.8 times when we increase the number of nodes from one to five, indicating a near-linear or even super-linear scalability. However, Logram achieves less scalability when parsing the BGL and Spark logs. Specifically, the throughput of Logram when parsing the BGL and Spark logs increases 3.3 and 2.7 times when we increase the number of nodes by a factor of five.6 	MIGRATING Logram TO AN ONLINE PARSERLogram parses logs in two steps: 1) generating n-gram dic-tionaries from logs, and 2) using the n-gram dictionaries to parse the logs line by line. Section 4 describes an offline implementation of Logram, in which the step for generating the n-gram dictionaries is completely done before the step of parsing logs using the n-gram dictionaries (even when we evaluate the ease of stabilisation in Section 5.4). Therefore, the offline implementation requires all the log data used to generate the n-gram dictionaries to be available before parsing. On the contrary, an online parser parses logs line by line, without an offline training step. An online parser is especially helpful in a log-streaming scenario, i.e., to parse incoming logs in a real-time manner.Logram naturally supports online parsing, as the n-gram dictionaries can be updated efficiently when more logs are continuously added (e.g., in log streaming scenarios). In our online implementation of Logram, we feed logs in a streaming manner (i.e., feeding one log message each time). When reading the first log message, the dictionary is empty (i.e., all the n-grams have zero occurrence), so Logram parses all the tokens as dynamic variables. Logram then creates a dictionary using the n-grams extracted from the first log message. After that, when reading each log message that follows, Logram parses the log message using the existing n-gram dictionary. Then, Logram updates the existing n-gram dictionary on-the-fly using the tokens in the log message. In this way, Logram updates the n-gram dictionary and parses incoming logs continuously until all the logs are processed. Similar to Section 5.4, we measure the ratio of agreement between the parsing results of the online implementation and the offline implementation. For each log message, we only consider the two parsing results agreeing to each other if they are exactly the same. We also measure the efficiency of Logram when parsing logs in an online manner relative to the offline mode. Specifically, we measure the efficiency dif-ference ratio, which is calculated as Tonline−Toffline where 	Toffline 
Tonline and Toffline are the time taken by the online Logram and offline Logram to parse the same log data, respectively.
Results
The online mode of Logram achieves nearly the same parsing results as the offline Logram. Table 4 compares
TABLE 4 
Comparing the parsing results of Logram between the online and offline modes.| Subject | Efficiency Difference Ratio | Efficiency Difference Ratio | Efficiency Difference Ratio | Efficiency Difference Ratio | Efficiency Difference Ratio | Efficiency Difference Ratio | Efficiency Difference Ratio | Agreement with | Agreement with | Agreement with |
|---|---|---|---|---|---|---|---|---|---|---|
| log dataset |log dataset |300k |1M |10M |100M |100M |500M |1G |offline results |offline results || HDFS |5.9% |5.9% |0.0% |-2.4% |-2.4% |-1.5% |-3.0% |-0.8% |-0.8% |100.0% |
| Spark |0.0% |0.0% |-0.3% |-0.6% |-0.6% |0.3% |-3.0% |-1.1% |-1.1% |99.9% |
| Windows |0.0% |0.0% |0.0% |1.1% |1.1% |-0.0% |-0.2% |0.6% |0.6% |96.8% |
| BGL |7.1% |7.1% |6.7% |7.2% |7.2% |5.9% |7.4% |N/A |N/A |98.7% || Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |Android 	5.9% 	8.9% 	6.6% 	6.5% 	N/A 	N/A 	95.0% Note: a positive value means that Logram is loswer with online parsing than offline. |the parsing results of Logram between the online and offline modes. We considered the same five large log datasets as the ones used for evaluating the efficiency of Logram (cf. Section 5.3). The agreement ratio between the online and offline modes of Logram range from 95.0% to 100.0%, indicating that the parsing results of the online Logram are almost identical to the parsing results of the offline Logram. The online mode of Logram reaches a parsing efficiency similar to the offline Logram. Table 4 also compares the efficiency between the online and offlineLogram, for the five considered log datasets with sizes varying from 300KB to 1GB. A positive value of the efficiency difference ratio indicates the online mode is slower (i.e., taking longer time), while a negative value indicates the online mode is even faster. Table 4 shows that the efficiency difference ratio ranges from -3.0% to 8.9%. Overall, the online mode of Logram is as efficient as the offline model. In some cases, the online mode is even faster, because the online mode parses logs with smaller incomplete dictionaries – thus being queried faster – compared to the full dictionaries used in the offline mode.In summary, as the online mode of Logram achieves similar parsing results and efficiency compared to the offline mode, Logram can be effectively used in an online parsing scenario. For example, Logram can be used to parse stream logs in a real-time manner.
7 	THREATS TO VALIDITY