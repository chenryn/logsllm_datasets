（domain））设置在系统管理程序之上，而系统管理程序本身直接
设立在硬件上（如图7-4所示）。当系统启动时，系统管理程序启动
个特殊的域，即众所周知的零域（domainzero）。零域拥有可以
让它管理系统其余部分的特殊权限，它类似于常规操作系统中的
个根或管理员进程。图7-4显示了一个基于Xen的典型的系统，其
中，零域和几个客户域（Xen术语中称为DomU）运行在Xen系统管
理程序之上。
访客
管理和控制
服务
软件
访客应
访客应
用程序
用程序
零域
客户域
客户域
系统管理程序
硬件
图7-4：Xen系统架构
宿主式虚拟化
1054
---
## Page 1056
Xen是原生式虚拟化（也被称为第一类虚拟化）的一个例子。另一
种方式是在宿主操作系统上运行一个系统管理程序。在这种情况
下，每个虚拟机实际上成了宿主操作系统的一个进程。宿主操作系
统负责零域在Xen上执行的管理职能。宿主式的系统管理程序和管
理软件就像一个常规的应用程序，设置（或联结）在一个常规操作
系统之上：如图7-5所示。
例如VMWare工作站、Parallels工作站和Microsoft的虚拟PC。这种方
式的主要优点在于：安装一个宿主式的系统管理程序就像安装一个
新应用程序一样简单，反之，安装一个原生的系统管理程序（例如
Xen）就像安装一个新的操作系统。因此，宿主式虚拟化更适合于
非专家的用户。
另一方面，原生式系统管理程序的优点在于它可以获得更好的性
能，因为本地系统管理程序比组合了宿主式操作系统和系统管理程
序的软件层薄很多。宿主式虚拟机受宿主操作系统支配，如果有其
他应用程序和系统管理程序正一起运行，就会导致性能降低。相
反，因为零域像一个常规虚拟机一样调度，在那里运行的应用程序
对其他虚拟机的性能没有影响。
宿主式虚拟机通常用于桌面虚拟化：例如，允许运行MacOSX的用
户在计算机的一个窗口中运行Linux。这对于要运行宿主操作系统不
支持的应用程序有用，而且，当使用交互式应用程序时，性能影响
不太容易注意到。原生式虚拟化更适合于服务器设施，在那里，初
始的性能和可预测性至关重要。
1055
---
## Page 1057
一个
多个
应用
应用
服务
访客操作系统
访客操作系统
访客操作系统
系统管理程序和管理软件
常用操作系统
硬件
图7-5：宿主式虚拟化系统的架构
当设计Xen架构的时候，首要关注的是只要有可能，就把策略和机
制分开来。系统管理程序设计成用来管理低级硬件的薄层，担当引
用监控器和调度程序，复用对硬件设备的访问。然而，因为系统管
理程序在最高级别运行（这里的一个缺陷会危及整个系统），较高
级别的管理委派给了零域。
例如，当创建一个新的虚拟机的时候，大部分工作是在零域中完成
的。从系统管理程序的角度来看，它分配了新的域，连同一部分物
理内存，还映射了其中的部分内存（为了载入操作系统），并且这
个域是未中止的。零域负责许可权限控制，设置虚拟设备并为新域
构建存储映像。这种分离在发展过程中非常有用，在零域中调试管
理软件比在系统管理程序中调试容易很多。而且，它支持把不同的
操作系统加入到零域而不是系统管理程序中，后者所带来的额外复
杂度通常是难以想象的。
先前我们提到Xen如何受益于可以使用一个开源操作系统，这个开
源系统为半虚拟化提供了测试台。使用Limux的第二个好处是它支持
非常多的各不相同的硬件设备。Xen几乎能够支持存在Limux驱动的
任何设备，因为它重用了Linux的驱动代码。Xen总是重用Linux驱动
1056
---
## Page 1058
以支持多种硬件。然而，在1.0和2.0版本之间，重用的特征发生了
明显的改变。在Xen1.0中，所有的虚拟机（包括零域）都通过虚拟
设备访问硬件，正如先前所述。系统管理程序负责把这些访问复合
到真实的硬件，因此，它包含Linmux硬件驱动的前端版本和虚拟驱动
后端。虽然这简化了虚拟机，但是增加了系统管理程序的复杂度并
把支持新驱动的责任交给了Xen并发团队。
图7-6演示了Xen在1.0版本和2.0版本之间设备架构的改变。在1.0版
本中，虚拟后端在系统管理程序中实现。所有的域，包括零域，都
通过这些设备访问硬件。在2.0版本中，系统管理程序进行了简化，
零域通过本地驱动访问硬件。因此，后端驱动移动到了零域。
Xen1.0
Xen2.0+
零域
客户域
客户域
零域
客户域
客户域
E
田
BE
国
画
BE
白
BE
本地
驱动
本地驱动
系统管理程序
硬件
硬件
图7-6：Xen设备架构在1.0版本和2.0版本之间的改变
在Xen2.0的开发中，设备架构全部进行了重新设计：本地设备驱动
和虚拟后端移出了系统管理程序，移入了零域。1现在，前端驱动
和后端驱动利用设备通道（devicechannel）进行通信，它使得域之
间能够进行有效和安全的通信。通过使用设备通道，Xen的虚拟设
备达到了接近本地的性能。它们的性能依赖两个原则：无复制传递
和异步通知。
请看图7-7，这个图演示了一个共享设备如何使用。用户向前端驱动
提供了一页内存，其中包含了要写的或读入的数据（1）。前端驱
动在共享环形缓冲下一个可用的空档中放置一个请求，其中包含了
1057
---
## Page 1059
到提供页的引用（2）。前端驱动告诉系统管理程序通知驱动域有
个请求在等待（3）。后端醒过来并把提供页映射入它的地址空
间（4）以便硬件可以与它使用的直接内存存取（DMA）进行交互
（5）。最后，后端通知前端这个请求已经处理完成（6），前端通
知用户应用程序（7）。
驱动域
客户域
后端
前端
系统管理程序
图7-7：一个共享设备的分析
用CPU复制数据的开销是昂贵的，这就是为什么使用像直接内存存
取（Direct MemoryAccess,DMA）这样的技术，以便在设备和内存
之间直接传输数据而不需要CPU参与的原因。然而，当数据必须在
地址空间之间移动时，Xen必须专门处理以避免复制。Xen支持一种
称为授权表（granttable）的共享内存机制，由此每个虚拟机维护一
张定义它的哪些页能够由其他虚拟机访问的表。这张表中的索引称
为授权索引（grantreference），当给与另一个虚拟机时，它代表
种能力。系统管理程序确保只有预期的接收者可以映射这个授权引
用，这反过来维持了内存的隔离性。设备通道本身用于发送授权引
用，然后用于映射为了发送或接收数据的缓存。
当作出新的请求或响应的时候，发送者必须通知接收者。这通常使
用同步通知一类似于一个函数调用一因此，发送者必须等待，直到
1058
---
## Page 1060
它知道通知已经被接收。如图7-8所示，这种操作模式导致糟糕的性
能，尤其当只有单个处理器可以使用的时候。Xen实际上使用事件
通道（eventchannel）来发送异步的通知。事件通道执行虚拟中断，
但是，只有当目标域下一次调度时虚拟中断才会服务。因此，在目
标域调度来执行它们之前，请求者可以产生多个请求，每次都唤醒
事件通道。然后，当调度目标域时，它又通过异步的方式处理多个
请求并发送响应。
请看图7-8。对于同步通知，前端必须等待后端完成它的工作之后才
能进行下一个请求。这意味着等待后端域调度，然后等待前端域调
度。比较而言，对于异步通知，前端在被调度的时候可以发送尽可
能多的请求，而后端可以发送尽可能多的响应。这增加了吞吐量。
前端
同步通知
后端
→
时间
前端
异步通知
后端
时间
图7-8：异步通知的优点
当然，如果你把过多的功能移到零域，它会变为一个单个故障点。
这尤其适用于设备故障，它可以使整个操作系统（由此引起整个虚
拟系统）崩溃。因此，Xen考虑到驱动域，零域可以把一个或多个
设备的控制委托给它。通过把后端驱动放到驱动域并把一些I/O权限
1059
---
## Page 1061
授予这个域就可以简单地实现这些功能。然后，如果一个驱动失
败，这个故障会隔离在这个驱动域，它可以重新启动而不损害系统
或客户域。
这种模式已经应用于零域的其他部分。Xen的最新版本包括了存根