[21]
[22] R. J. Schalkoff, Artiﬁcial neural networks. McGraw-Hill New York,
1997, vol. 1.
14
[23] B. Yegnanarayana, Artiﬁcial neural networks. PHI Learning Pvt. Ltd.,
2009.
[24] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard,
W. Hubbard, and L. D. Jackel, “Backpropagation applied to handwritten
zip code recognition,” Neural computation, vol. 1, no. 4, pp. 541–551,
1989.
[25] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based
learning applied to document recognition,” Proceedings of the IEEE,
vol. 86, no. 11, pp. 2278–2324, 1998.
[26] Y.-L. Boureau, F. Bach, Y. LeCun, and J. Ponce, “Learning mid-level
features for recognition,” in Computer Vision and Pattern Recognition
(CVPR), 2010 IEEE Conference on.
IEEE, 2010, pp. 2559–2566.
[27] D. M. Hawkins, “The problem of overﬁtting,” Journal of chemical
information and computer sciences, vol. 44, no. 1, pp. 1–12, 2004.
[28] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R.
Salakhutdinov, “Improving neural networks by preventing co-adaptation
of feature detectors,” arXiv preprint arXiv:1207.0580, 2012.
[29] S. Lai, L. Xu, K. Liu, and J. Zhao, “Recurrent convolutional neural
networks for text classiﬁcation.” in AAAI, vol. 333, 2015, pp. 2267–
2273.
[30] T. Mikolov, M. Karaﬁ´at, L. Burget, J. Cernock`y, and S. Khudanpur,
“Recurrent neural network based language model.” in Interspeech,
vol. 2.
ISCA, 2010, p. 3.
[31] A. Graves, A.-r. Mohamed, and G. Hinton, “Speech recognition with
deep recurrent neural networks,” in Acoustics, speech and signal pro-
cessing (icassp), 2013 ieee international conference on.
IEEE, 2013,
pp. 6645–6649.
[32] A. Graves and N. Jaitly, “Towards end-to-end speech recognition with
recurrent neural networks,” in Proceedings of the 31st International
Conference on Machine Learning (ICML-14).
JMLR.org, 2014, pp.
1764–1772.
[33] H. Sak, A. Senior, and F. Beaufays, “Long short-term memory recurrent
neural network architectures for large scale acoustic modeling,” in Fif-
teenth Annual Conference of the International Speech Communication
Association.
ISCA, 2014.
[34] A. Graves, “Generating sequences with recurrent neural networks,”
arXiv preprint arXiv:1308.0850, 2013.
[35] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and
L. Fei-Fei, “Large-scale video classiﬁcation with convolutional neural
networks,” in Proceedings of the IEEE conference on Computer Vision
and Pattern Recognition.
IEEE, 2014, pp. 1725–1732.
[36] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural
computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[37] M. Schuster and K. K. Paliwal, “Bidirectional recurrent neural net-
works,” IEEE Transactions on Signal Processing, vol. 45, no. 11, pp.
2673–2681, 1997.
[38] Y. Goldberg, “A primer on neural network models for natural language
processing,” Journal of Artiﬁcial Intelligence Research, vol. 57, pp.
345–420, 2016.
[39] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning repre-
sentations by back-propagating errors,” nature, vol. 323, no. 6088, pp.
533–536, 1986.
[40] S. T. Roweis and L. K. Saul, “Nonlinear dimensionality reduction by
locally linear embedding,” science, vol. 290, no. 5500, pp. 2323–2326,
2000.
[41] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efﬁcient estimation of
word representations in vector space,” ICLR Workshop, 2013.
[42] D. W. Hosmer Jr, S. Lemeshow, and R. X. Sturdivant, Applied logistic
regression.
John Wiley & Sons, 2013, vol. 398.
[43] S. Kaufman, S. Rosset, C. Perlich, and O. Stitelman, “Leakage in data
mining: Formulation, detection, and avoidance,” ACM Transactions on
Knowledge Discovery from Data (TKDD), vol. 6, no. 4, p. 15, 2012.
[44] L. v. d. Maaten and G. Hinton, “Visualizing data using t-sne,” Journal
of machine learning research, vol. 9, no. Nov, pp. 2579–2605, 2008.
[45] S. Xingjian, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, and W.-c.
Woo, “Convolutional lstm network: A machine learning approach for
precipitation nowcasting,” in Advances in neural information processing
systems, 2015, pp. 802–810.
[67] B. Athiwaratkun and J. W. Stokes, “Malware classiﬁcation with lstm and
gru language models and a character-level cnn,” in Acoustics, Speech
and Signal Processing (ICASSP), 2017 IEEE International Conference
on.
J. Saxe and K. Berlin, “expose: A character-level convolutional neural
network with embeddings for detecting malicious urls, ﬁle paths and
registry keys,” arXiv preprint arXiv:1702.08568, 2017.
IEEE, 2017, pp. 2482–2486.
[68]
[70]
[69] W. Yang, W. Zuo, and B. Cui, “Detecting malicious urls via a keyword-
based convolutional gated-recurrent-unit neural network,” IEEE Access,
2019.
“Attack2vec: Leveraging temporal word embeddings to understand
28th USENIX Security
the
cyberattacks,”
Symposium (USENIX Security 19).
Santa Clara, CA: USENIX
Association,
https://www.usenix.org/
[Online]. Available:
conference/usenixsecurity19/presentation/shen
evolution
of
2019.
in
[71] Microsoft, “Windows defender atp machine learning and amsi,”
https://www.mdsec.co.uk/2018/06/exploring-powershell-amsi-and-
logging-evasion/, 2017.
[72] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
L. Kaiser, and I. Polosukhin, “Attention is all you need,” in Advances
in Neural Information Processing Systems 30: Annual Conference on
Neural Information Processing Systems 2017, 4-9 December 2017,
Long Beach, CA, USA, 2017, pp. 6000–6010. [Online]. Available:
http://papers.nips.cc/paper/7181-attention-is-all-you-need
[73] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee,
and L. Zettlemoyer, “Deep contextualized word representations,” arXiv
preprint arXiv:1802.05365, 2018.
[46] Y. Kim, “Convolutional neural networks for sentence classiﬁcation,”
arXiv preprint arXiv:1408.5882, 2014.
[47] R. Collobert and J. Weston, “A uniﬁed architecture for natural language
processing: Deep neural networks with multitask learning,” in Proceed-
ings of the 25th international conference on Machine learning. ACM,
2008, pp. 160–167.
[48] F. Chollet et al., “Keras,” https://github.com/fchollet/keras, 2015.
[49] L. Prechelt, “Early stopping-but when?” in Neural Networks: Tricks of
the trade. Springer, 1998, pp. 55–69.
[50] D. Bohannon and L. Holmes, “Revoke-obfuscation: powershell obfus-
cation detection using science,” 2017.
[51] G. Rusak, A. Al-Dujaili, and U.-M. O’Reilly, “AST-based deep learn-
ing for detecting malicious powershell,” in Proceedings of the 2018
ACM SIGSAC Conference on Computer and Communications Security.
ACM, 2018, pp. 2276–2278.
[52] N. Provos, D. McNamee, P. Mavrommatis, K. Wang, N. Modadugu
et al., “The ghost in the browser: Analysis of web-based malware.”
HotBots, vol. 7, pp. 4–4, 2007.
[53] P. Likarish, E. Jung, and I. Jo, “Obfuscated malicious javascript
detection using classiﬁcation techniques,” in 2009 4th International
Conference on Malicious and Unwanted Software (MALWARE).
IEEE,
2009, pp. 47–54.
I. A. AL-Taharwa, H.-M. Lee, A. B. Jeng, K.-P. Wu, C.-S. Ho,
and S.-M. Chen, “Jsod: Javascript obfuscation detector,” Security and
Communication Networks, vol. 8, no. 6, pp. 1092–1107, 2015.
[54]
[55] W. Xu, F. Zhang, and S. Zhu, “Jstill: mostly static detection of
obfuscated malicious javascript code,” in Proceedings of the third ACM
conference on Data and application security and privacy. ACM, 2013,
pp. 117–128.
[56] S. Kaplan, B. Livshits, B. Zorn, C. Siefert, and C. Curtsinger, “” nofus:
Automatically detecting”+ string. fromcharcode (32)+” obfuscated”.
tolowercase ()+” javascript code,” Technical report, Technical Report
MSR-TR 2011–57, Microsoft Research, 2011.
[57] M. Cova, C. Kruegel, and G. Vigna, “Detection and analysis of drive-
by-download attacks and malicious javascript code,” in Proceedings of
the 19th international conference on World wide web. ACM, 2010,
pp. 281–290.
[58] W. Wei-Hong, L. Yin-Jun, C. Hui-Bing, and F. Zhao-Lin, “A static
malicious javascript detection using svm,” in Proceedings of the 2nd
International Conference on Computer Science and Electronics Engi-
neering. Atlantis Press, 2013.
I. Corona, D. Maiorca, D. Ariu, and G. Giacinto, “Lux0r: Detection of
malicious pdf-embedded javascript code through discriminant analysis
of api references,” in Proceedings of the 2014 Workshop on Artiﬁcial
Intelligent and Security Workshop. ACM, 2014, pp. 47–57.
[59]
[60] P. Laskov and N. ˇSrndi´c, “Static detection of malicious javascript-
bearing pdf documents,” in Proceedings of the 27th annual computer
security applications conference. ACM, 2011, pp. 373–382.
[61] D. Wael, A. Shosha, and S. G. Sayed, “Malicious vbscript detection
algorithm based on data-mining techniques,” in 2017 Intl Conf on
Advanced Control Circuits Systems (ACCS) Systems & 2017 Intl Conf
on New Paradigms in Electronics & Information Technology (PEIT).
IEEE, 2017, pp. 112–116.
[62] A. Shah, “Malicious javascript detection using statistical
model,” 2016.
language
[63] K. Sch¨utt, M. Kloft, A. Bikadorov, and K. Rieck, “Early detection of
malicious behavior in javascript code,” in Proceedings of the 5th ACM
workshop on Security and artiﬁcial intelligence. ACM, 2012, pp. 15–
24.
J. W. Stokes, R. Agrawal, and G. McDonald, “Neural classiﬁcation of
malicious scripts: A study with javascript and vbscript,” arXiv preprint
arXiv:1805.05603, 2018.
[64]
[65] Y. Wang, W.-d. Cai, and P.-c. Wei, “A deep learning approach for detect-
ing malicious javascript code,” security and communication networks,
vol. 9, no. 11, pp. 1520–1534, 2016.
[66] E. Raff, J. Sylvester, and C. Nicholas, “Learning the pe header, malware
detection with minimal domain knowledge,” in Proceedings of the 10th
ACM Workshop on Artiﬁcial Intelligence and Security. ACM, 2017,
pp. 121–132.
15
XI. APPENDIX - IMPLEMENTATION DETAILS
All our experiments were performed on an Azure-hosted
Data-Science-VM with 56 GB of CPU memory (6 vCPUs)
and 12 GB of GPU memory (single core). TensorFlow was
used as the back-end. Building the embedding using Gensim
13 took less than an hour per iteration (we used 15 iterations,
resulting in total execution time of 13 hours and 37 minutes).
Training took less than 7 hours for CNN-RNN models, 5 hours
for Token-Char models and 1 hour for CNN models. Thus, in
a production scenario, a model can be fully trained once a day.
We implemented our DL models using Keras14.
For the DL models, we used binary cross-entropy as a loss
function with Adam optimizer and tolerance of 10−4. Data
was processed in 512-sized mini-batches with a maximum of
30 epochs, as in most cases the model converged before 30
epochs. Weights of instances were proportional to classes ratio.
As for traditional ML training, we used SGD with log loss
and L2 as penalty. We stopped after 100 iterations or when
the change in loss became smaller than 10−4. Architecture
hyperparameters were selected manually, based on the best
empirical result in terms of average (across folds) TPR, using
the highest threshold with FPR lower than 10−3.
A. CNN
On top of the Embedding layer, we used a convolutional
layer with 128 ﬁlters and a kernel size of 3. A global Max-
pooling layer was used, reducing dimensionality, followed by
a Dropout layer and a Dense layer with a Sigmoid activation
function.
model = Sequential()
model.add(Embedding(32))
model.add(Conv1D(128,
kernel-size= 3,
padding=’valid’,
activation=’relu’,
strides=1))
model.add(GlobalMaxPooling1D())
model.add(Dropout(0.5))
model.add(Dense(1,
activation=’sigmoid’))
B. CNN-RNN
We used an LSTM layer on top of a convolutional layer.
The convolutional layer had 128 ﬁlters and a kernel size of 3.
A max-pooling layer was used with pool and stride sizes of 3,
reducing dimensionality, followed by a bi-directional LSTM
layer with output of size 32 and a Dense layer with a Sigmoid
activation function as our output.
13https://radimrehurek.com/gensim/
14https://keras.io/
16
model = Sequential()
model.add(Embedding(32))
model.add(Conv1D(128,
kernel-size= 3,
padding=’valid’,
activation=’relu’,
strides=1))
model.add(MaxPooling1D(pool_size=3,
strides=3 ))
model.add(Bidirectional(LSTM(32,
dropout=0.5, recurrent_dropout=0.02)))
model.add(Dense(1,
activation=’sigmoid’))
C. Token-Char
We used an LSTM layer on top of a concatenation of
the output of two convolutional layers – one on top of the
token-level input and another from the character level input.
Note that in the character-level case, we use a global max
pooling layer on top of the convolution layer, resulting in a
single tensor of length 64. In order to concatenate it with
the output of the max pooling performed on the token-level
convolutional layer, we chose to ﬁrst duplicate this tensor so
that it would have the same length as the latter. In both cases,
the convolutional layer has 64 ﬁlters and a kernel size of 3.
For the token-level input, a max-pooling layer is used with
pool and stride sizes of 3. After the concatenation, we use
a bi-directional LSTM layer with an output of size 32 and
a Dense layer with a Sigmoid activation function as our output.
#TOKEN
token_input = Input(shape=(1000,),
dtype=’float’)
token_embedding = GetEmbeddingLayer()
(token_input)
token_conv = Conv1D(64, kernel_size=3,
strides=1, padding=’valid’,
activation=’relu’)
(token_embedding)
token_pool = MaxPooling1D(pool_size=3,
strides=3)(token_conv)
token_drop =Dropout(.5)(token_pool)
#CHAR
char_input = Input(shape=(1000,),
dtype=’float’)
char_encoding = OneHotWithCaseBit(max_len)
(char_input)
char_conv = Conv1D(64, kernel_size=3,
strides=1, padding=’valid’,
activation=’relu’)
(char_embedding)
char_pool = GlobalMaxPooling1D()(char_conv)
char_drop = Dropout(.5)(char_pool)
char_repeated = RepeatVector
(token_drop.get_shape()[1].value)
(char_drop)
#Merge
merged = concatenate
([token_drop, char_repeated])
lstm = Bidirectional(LSTM(32,
dropout=0.3, recurrent_dropout=0.01))
output = Dense(1, activation="sigmoid")
(merged)
(lstm)
D. Tokens Embedding
We used Gensim15 to build the embedding. Both W2V and
FastText were used, with CBOW as the training algorithm.
Parameters used are:
• Min length of a word was two, max was 50.
• We ignored all words with total frequency lower than
• We performed negative sampling using 5 noise words.
• We performed 15 iterations.
•
•
10.
Our embedding space-size is 32.
The window-size used was 4 (the window is the
maximum distance between the current and predicted
word within a sentence).
15https://radimrehurek.com/gensim/
17