One type of drill-down analysis involves decomposing latency into its contributing components.
Imagine this analysis sequence:
1. Request latency is 100 ms (milliseconds).
2. This is 10 ms running on CPU, and 90 ms blocked off CPU.
3. The off-CPU time is 89 ms blocked on the file system.
4. The file system is spenxding 3 ms blocked on locks, and 86 ms blocked on storage devices.
Your conclusion here may be that the storage devices are the problemand that is one answer.
But drill-down analysis can also be used to sharpen context. Consider this alternate sequence:
1. An application is spending 89 ms blocked on the file system.
2.The file system is spending 78 ms blocked on file system writes, and 11 ms blocked on reads.
3. The file system writes are spending 77 ms blocked on access timestamp updates.
Your conclusion now is that file system access timestamps are the source of the latency, and they
could be disabled (it is a mount option). This is a better outcome than concluding that faster disks
were necessary
---
## Page 109
72
Chapter 3 Performance Analysis
3.2.3
USE Method
I developed the USE methodology for resource analysis [Gregg 13c].
For every resource, check:
1. Utilization
2. Saturation
3. Errors
Your first task is to find or draw a diagram of the software and hardware resources. You can then
t aog spatie arempreq go sajdlturexa smous I-e anlig soau aasts asag gupaas ruatp raso apesa
generic system, includling the components and buses that can be examined.
Memory
sn8
Interconnect
CPU
DRAM
CPU
1
CPU
2
DRAM
Bus
VO
Bridge
1O
Expander Interconnect
Controller
Network
Controller
Disk
Disk
Port
Figure 3-1  Hardware targets for USE method analysis
Consider your current monitoring tools and their ability to show utilization, saturation, and
errors for every item in Figure 3-1. How many blind spots do you currently have?
An advantage of this methodology is that it begins with the questions that matter, rather than
beginning with answers in the form of metrics and trying to work backward to find out why they
matter. It also reveals blind spots: It begins with the questions you want answered, whether or not
there is a convenient tool to measure them.
3.2.4
Checklists
A performance analysis checklist can list tools and metrics to run and check. They can focus on
the low-hanging fruit: identifying a dozen or so common ssues with analysis instructions for
---
## Page 110
3.3 Linux 60-Second Analysis
73
everyone to follow. These are well suited for execution by a wide variety of staff at your company,
and can allow you to scale your skills.
The following sections introduce two checklists: one using traditional (non-BPF) tools suitable for
a quick analysis (the first 60 seconds) and the other a list of BCC tools to try early on.
3.3Linux60-Second Analysis
This checklist can be used for any performance issue and reflects what I typically execute in the
first 60 seconds after logging into a poorly performing Linux system. This was published by myself
and the Netflix performance engineering team [56]:
The tools to run are:
1. uptime
2. dnesg 1 tai1
3. vnstat 1
4. mpstat -P ALL 1
5. pidstat 1
6. 1ostat -xz 1
7. free -m
8. sar -n DEV 1
9, sar =n TCP,ETCP 1
10. top
The following sections explain each of these tools. It might seem out of place to discuss non-BPF
tools in a BPF book, but not to do so would miss out on an important resource that is already
available. These commands may enable you to solve some performance issues outright. If not
they may reveal clues about where the performance problems are, dlirecting your use of follow-up
BPF tools to find the real issue.
3.3.1 uptime
S uptime
03:16:59 up 17 day5, 4:18, 1 user,  1oad average1 2.74, 2.54, 2.58
This is a quick way to view the load averages, which indicate the number of tasks (processes)
wanting to run. On Linux systems, these numbers include processes wanting to run on the CPUs,
as well as processes blocked in uninterruptible I/O (usually disk I/O). This gives a high-level idea
of resource load (or demand), which can then be further explored using other tools.
The three numbers are exponentially damped moving sum averages with a 1-minute, 5-minute,
and 15-minute constant. The three numbers give you some idea of how load is changing over
time. In the example above, the load averages show a small recent increase.
---
## Page 111
74
Chapter 3 Performance Analysis
Load averages can be worth checking when first responding to an issue to see if the issue is still
present. In fault-tolerant environments, a server experiencing a performance issue may be auto
po anu-1 qu v oo e ae o u So ue nos s a q aaras tuo poua ee
average coupled with a low 1-minute load average can be a sign that you logged in too late to
catch the issue.
3.3.2 dmesg|tail
S dnesg 1tal1
[1880957,563150] per] invoked cos=ki1ler: gfp_nssk=0x280ds, order=0, oom_score_sdj=0
[. - -]
[1880957,563400] Out of memory: Ki1l process 18694 (perl) score 246 or sacrifice child
[1880957,563408] K111ed process 18694 (perl] tota1=vn:1972392xB, anon=xss:1953348kB,
file-rss:0kB
[2320864.954447] TCP: Possible SYN flooding on port T001. Dropping request. Check
SXMP counters :
'sansst aoueuoad asnes ueo jeg sroua sog goot ue p 'satessatu tapsis ot sed aug smous su
The example above includes the out-of-memory killer and TCP dropping a request. The TCP
message even points you to the next area for analysis: SNMP counters.
3.3.3 vmstat 1
$ mstat 1
520xd
JOUR
pdxs q3
free
cache
C
s e× pT e 2n 23 
34
0 200889792
828165 801E1
D0196019
32  0
0 200889920
73708 591860
32 0
0 20089011273708 591860
C7
0 9501 2154 991 000
[...]
This is the virtual memory statistics tool that originated in BSD, which also shows other system
metrics. When invoked with the argument 1, it prints 1-second summaries; be aware that the first
line of numbers is the summary since boor (with the exception of the memory counters).
Columns to check:
■r: The number of processes running on CPU and waiting for a turn. This provides a better
signal than load averages for determining CPU saturation, as it does not include I/O. To
interpret: an *r’ value greater than the CPU count indicates saturation.
•free: Fre memory, in Kbytes. If there are too many digits to count, you probably have
enough free memory. The free m command, included in Section 3.3.7 better explains the
state of free memory.
 si and so: Swap-ins and swap-outs. If these are non-zero, you're out of memory. These are
only in use if swap devices are configured.
---
## Page 112
3.3 Linux 60-Second Analysis
75
●us, sy, id, wa, and st: These are breakdowns of CPU time, on average, across all CPUs. They
are user time, system time (kernel), idle, wait I/O, and stolen time (by other guests, or, with
 Xen, the guest's own isolated driver domain).
The example shows that CPU time is mostly in user mode. This should direct your next steps to
analyze the running user-level code using profilers.
3.3.4 mpstat -P ALL 1
S npstat -P ALL 1
[. .-]
03:16:41 A
CPO
5usE
In1ce
tays siovalt
sirq ssoft lsteal sguest 5gnice%idle
03:16:42 
s11
14.27
0 .00
0 , 75
0., 44
0.00
0,00
0,06
0 .00
0.0084,48
03:16 :42 AX
0 100.00
0 .00
0.00
0.00
0.00
0.00
0,00
0.00
0.00
0.00
03 :16 : 42 AM
1.
0 ,00
0 .00
0. 00
0.00
0.00
0,00
0,00
0.00
0.00 100,00
03:16:42 
2
8.08
0 .00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
26*[6
03:16:42 
310.00
0 .00
1.00
0., 00
0.00
0,00
1,00
0 .00
0.0088,00
03:16 : 42 AX
1.01
00° 0
0.00
0. 00
0.00
0.00
0,00
0.00
0.0098.99
03 :16 : 42 AM
5.10
0 .00
0. 00
0.00
0.00
0,00
0,00
0.00
0.00
94.90
03:16:42 M
03:16 :42 AX
6
11,00
00° 0
0.00
0. 00
0.00
0.00
0,00
0.00
0.00
89.00
710.00
0 .00
0 ,00
0.000.00
0, 00
0,00
0 .00
0.0090.00
[..-]
This command prints per-CPU time broken down into states. The output reveals a problem: CPU
0 has hit 100% user time, evidence of a single-thread bottleneck.
Also look out for high %iowait time, which can be explored with disk I/O tools, and high %sys
time, which can be explored with syscall and kernel tracing, as well as CPU profiling.
3.3.5
pidstat 1
$ pidstat 1
Linux 4 .13, 019=gener1c1.. -1
08/04/2018
_x86_64_
(16 CPU)
03 :20 :47 AX
UID
PID
fusr
lsysten
Igoest
ICPU
CPU
Cornand
03:20:48
0
1307
0, 00
0 . 98
0 , 00
0. 98
8 irqbalanoe
03:20:48 
33
12178
4.90
0.00
0.00
4.90
4java
03:20:48 M
33
12569
476,47
24.51
0 , 00
500.98
0 java
03 :20 : 48 AX
0
130249
86*0
0.98
0.00
1.96
1pldstat
03:20 : 48 AX
UID
PID
susr lsysten
hgoest
ICPU
CPU
Cornand
03:20:49 
33
12178
4,00
0 .00
0,00
4.00
4 java
03:20 :49 AX
EE
12569
331.00
21.00
0 . 00
352.00
0java
03 :20 : 49 AM
129906
1.00
0.00
0 , 00
1.00
8
sshd
03:20:49 
D
130249
1.00
1.00
0.00
2 .00
1pldstat
---
## Page 113
76
Chapter 3 Performance Analysis
03:20:49 A
U1D
PID
lguest
CPU
uruuon
N 0S10Z=E0
33
12178
4.00
0.00
0,00
4.00
Java
03 :20 :50 
1.13
12356
1.00
0.00
0, 00
1.00
11
szedduus
03:20: 50 AX
EE
12569
210.00
13.00
0 . 00
223.00
java
03 :20: 50 AM
0
130249
1,00