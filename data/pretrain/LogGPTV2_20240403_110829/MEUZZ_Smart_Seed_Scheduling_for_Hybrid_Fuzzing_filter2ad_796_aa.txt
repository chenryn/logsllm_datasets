title:MEUZZ: Smart Seed Scheduling for Hybrid Fuzzing
author:Yaohui Chen and
Mansour Ahmadi and
Reza Mirzazade Farkhani and
Boyu Wang and
Long Lu
MEUZZ: Smart Seed Scheduling for Hybrid Fuzzing
Yaohui Chen
Northeastern University
PI:EMAIL
Mansour Ahmadi
Northeastern University
PI:EMAIL
Reza Mirzazade farkhani
Northeastern University
PI:EMAIL
Boyu Wang
Long Lu
Stony Brook University
PI:EMAIL
Northeastern University
PI:EMAIL
Abstract
Seed scheduling highly impacts the yields of hybrid fuzzing.
Existing hybrid fuzzers schedule seeds based on ﬁxed heuris-
tics that aim to predict input utilities. However, such heuristics
are not generalizable as there exists no one-size-ﬁts-all rule
applicable to different programs. They may work well on the
programs from which they were derived, but not others.
To overcome this problem, we design a Machine learning-
Enhanced hybrid fUZZing system (MEUZZ), which employs
supervised machine learning for adaptive and generalizable
seed scheduling. MEUZZ determines which new seeds are
expected to produce better fuzzing yields based on the
knowledge learned from past seed scheduling decisions
made on the same or similar programs. MEUZZ extracts
a series of features for learning via code reachability and
dynamic analysis, which incurs negligible runtime overhead
(in microseconds). MEUZZ automatically infers the data labels
by evaluating the fuzzing performance of each selected seed.
As a result, MEUZZ is generally applicable to, and performs
well on, various kinds of programs.
Our evaluation shows MEUZZ signiﬁcantly outperforms the
state-of-the-art grey-box and hybrid fuzzers, achieving 27.1%
more code coverage than QSYM. The learned models are
reusable and transferable, which boosts fuzzing performance
by 7.1% on average and improves 68% of the 56 cross-program
fuzzing campaigns. When fuzzing 8 well-tested programs un-
der the same conﬁgurations as used in previous work, MEUZZ
discovered 47 deeply hidden and previously unknown bugs,
among which 21 were conﬁrmed and ﬁxed by the developers.
1 Introduction
Hybrid testing as a research topic has attracted tremendous
attention and made signiﬁcant contributions to bug discovery.
For instance, the winning teams in the DARPA Cyber Grand
Challenge [6] all used hybrid testing [17]. Compared with
plain fuzzing, hybrid testing features an extra concolic
execution component, which revisits the fuzzed paths, solves
the path conditions, and tries to uncover new paths.
One key challenge in hybrid testing is to recognize
high-utility seeds (i.e., seeds of high potential to guide
concolic execution to crack complex conditions guarding
more coverage and bugs). Prioritizing such seeds allows
the hybrid fuzzer to achieve higher code coverage more
quickly, and in turn, discover more bugs in a ﬁxed time frame.
Moreover, this prioritization matters in practice because the
concolic execution engine usually has limited time budget and
can explore only a (small) subset of all fuzzer-generated seeds.
Being able to estimate seed utility allows hybrid fuzzers to
use concolic execution more efﬁciently.
The existing work [8, 19, 25, 33, 49, 54, 55] uses purely
heuristic-based seed selection. For example, some prefer seeds
with smaller sizes while some value those that lead to new
code coverage. These heuristics, despite their simplicity, do
not perform equally well across different kinds of programs
and are not universally suitable for all programs. Contradicting
the previous belief [8, 13, 33], our experiments show that
seeds leading to new coverage sometimes have the lowest
utility (§6.3). Similarly, previous work [33, 54] suggested that
smaller seeds should have higher utility, which however is not
true in certain programs as our evaluation shows. As a result,
these simple and ﬁxed heuristics may cause non-optimum seed
selections, overwhelming the concolic engine with low-utility
seeds and slowing down bug discovery.
Compared to heuristics, Machine Learning (ML) algorithms,
when trained with sufﬁcient data, can discover complex and im-
plicit patterns automatically [43]. We show that seed selection
strategies that are automatically learned based on individual
programs perform better than manually deﬁned heuristics that
fail to consider all kinds of programs. As our experiment shows
that the inﬂuence of each feature varies across different pro-
grams, suggesting that no single feature (or rule) can work well
for all programs. ML-based seed selection avoids the need for
manually designing, testing, and reasoning about seed selection
rules, which can be daunting, non-scalable, or even impossible
when the volume of data to be analyzed is overwhelming.
In this paper, we introduce MEUZZ, an ML-enhanced
hybrid fuzzing system. Unlike existing work, which schedule
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    77
seeds using simple heuristics derived from a particular set of
test programs, MEUZZ uses ML and a set of static and dynamic
features, computed from seeds and individual programs, to
predict seed utility and perform seed scheduling. MEUZZ
also has a built-in evaluation module that measures prediction
quality for continuous learning and improvement. To the best
of our knowledge, MEUZZ is the ﬁrst work [42] that applies
ML to seed prioritization and scheduling.
To effectively apply ML to seed scheduling for hybrid
fuzzing, our design of MEUZZ pays special attention to two
ML tasks: feature engineering and data labeling. While
these are the essential steps to bootstrap ML, they could
be time-consuming and thus too costly or impractical to
be included in the fuzzing workﬂow. For instance, feature
extraction can be very slow if it requires heavy computation or
extensive data collection. Moreover, it is not straightforward
to quantify seed utility, which is essential for labeling.
To tackle the aforementioned challenges, we ﬁrst engineer
a set of lightweight features based on code reachability and
dynamic analysis. Second, we propose a labeling method
using the input descendant tree to quantify the utility of a
seed. Our evaluation shows that MEUZZ takes only 5µs on
average to extract an individual feature. It also conﬁrms that
the descendant tree of a seed accurately reﬂects seed utility.
Collecting data and training a new model for every
program might not be economical or necessary. Therefore,
we investigate the feasibility of model reusability and
transferability to answer the question: Is a learned model
transferable to different fuzzing conﬁgurations or programs?
Since the learning is designed to predict the likelihood of
seeds triggering bugs, rather than any speciﬁcs of the fuzzed
program, a model learned by MEUZZ turns out to be applicable
beyond the program from which the model is learned.
We
the
compare MEUZZ with
state-of-the-art
fuzzers [19, 24, 33] as well as the most recent hybrid
testing systems [25, 54]. The results, based on a set of
real-world benchmark programs, show that MEUZZ achieves
much higher code coverage than the tested fuzzers that use
simple seed selection heuristics. Particularly MEUZZ expands
the code coverage by as much as 27.1% compared to QSYM,
the start-of-the-art hybrid fuzzing system. The experiments
also show that the prediction models learned by MEUZZ have
good reusability and transferability. The reused models boost
the coverage by 7.1% on average. The transplanted models
improve fuzzing performance in 38 out of 56 cases (67.9%
of cases), with 10 cases seeing more than 10% improvement.
This paper makes the following contributions.
• Effective and generalizable approach. We design, imple-
ment, and evaluate MEUZZ, the ﬁrst system that applies
machine learning to the seed selection stage of hybrid
fuzzing. MEUZZ performs better and is more widely ap-
plicable than heuristic-based seed selection.
• Practical feature and label engineering. We address two
major challenges, namely feature engineering and label
inference, when applying ML to seed selection in hybrid
fuzzing. Our feature selection and extraction allow for
online/continuous learning. They are compatible with the
existing hybrid fuzzing workﬂow and require no changes
to either fuzzers or concolic execution engines. We also
propose an automatic label inference method based on
seed descendant trees.
• Reusable and transferable ML models. Our seed selection
models demonstrate strong reusability and transferability.
As a result, MEUZZ can reuse a well-trained model on
different programs (or different fuzzing conﬁgurations) to
quickly bootstrap the fuzzing campaign and continuously
improve and adapt the model to the current program or
conﬁguration.
• Open-Source. The full implmentation of MEUZZ will be
open-sourced after acceptance.
2 Motivation
The seed selection (or scheduling) in fuzzing aims to solve
this problem: given a program and a set of seeds, in which
order the fuzzer should test the seeds to maximize the gain
during a ﬁxed period. Seed selection plays a critical role in
hybrid fuzzing because the concolic execution engine can
only explore an (often small) subset of the seeds due to time
constraints. Hence, hybrid fuzzing cannot fully beneﬁt from
concolic execution if the seed selection is not optimal.
Why seed selection is important for hybrid fuzzing:
Hybrid fuzzers without a seed scheduling mechanism (e.g.,
Driller [49]) have to explore all inputs. This “brute force”
strategy has two main drawbacks. First, concolic engines
cannot keep up with the speed of plain fuzzing because they
run relatively slowly and often encounter path explosions and
timeouts. As an experiment, we used QSYM [54] to fuzz a
set of real-world benchmark programs. QSYM is one of the
state-of-the-art concolic execution engines for hybrid testing1.
As shown in Figure 1, for a continuous 24-hour run, QSYM
was only able to explore 23.1% of the seeds in fuzzer’s queue.
Second, a seed selection strategy affects fuzzing results
drastically. A naive strategy delays a fuzzer’s exploration of
interesting program locations, and sometimes, prematurely
forces the fuzzer to skip deep program paths and states.
Some recent research [19, 25, 51, 54, 55] studied a few seed
selection heuristics of various levels of sophistication. In their
experiments, fuzzers using these seed selection heuristics
produce better results (e.g., higher code coverage) than fuzzers
with naive or no strategies.
Why exploring machine learning for seed selection: All
the existing seed selection strategies are based on manually
deﬁned heuristics. Although performing well on their selected
benchmarks, these strategies may not be generalizable to,
or suitable for, other programs. For instance, DigFuzz [55]
and AFLFast [19] prioritize seeds with less explored paths
1Reportedly, QSYM is 3x faster than Driller [54].
78    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
8,000
6,000
s
d
e
e
S
#
4,000
2,000
0
807
6562
1556
4355
1654
3699
Unexplored
Explored
832
2551
3 Background
Hybrid fuzzing [25, 49, 54] combines fuzzing and concolic
execution to address the deﬁciencies of both the approaches.
Figure 2 shows an overview of a general hybrid fuzzing
framework. The whole system consists of three major
components: fuzzer, concolic testing, and coordinator. For the
sake of brevity, we refer the interested readers to [2, 8, 23, 29]
for the technical details of fuzzing and concolic execution.
3.1 Hybrid Fuzzing
tcpdump
libxml2
libjpeg
objdump
Coordinator
Figure 1: The total number of inputs explored by the concolic
execution engine of QSYM in 24 hours. On average, only 23.1% of
the inputs were explored by the concolic execution even though the
engine was continuously running.
by fuzzer. Savior [25] prefers seeds dominating more UBSan-
labeled code paths. QSYM [13] prioritizes seeds with smaller
sizes. These heuristics are all based on intuition or empirical
observations gained from limited test cases or benchmarks.
A biased or unsuitable seed selection strategy delays
or prevents fuzzers’ exploration of deep program states
or the discovery of bugs. For instance, QSYM [13] and
ProFuzzer [53] prioritize inputs with smaller sizes. Their de-
velopers observed in their evaluation benchmarks that smaller
inputs lead to higher code coverage. However, as [25] pointed
out, QSYM fails to explore a large chunk of code in program
who (a program in the LAVA-M benchmark [27]) due to the
unsuitable seed selection strategy (i.e., only inputs larger than
a certain size can trigger the vulnerable functions in this case).
This clearly indicates that ﬁxed seed selection heuristics can
hardly be suitable for a wide set of programs (See Figure 10).
Due to the diverse scheduling scenarios, modern fuzzers
(e.g., AFL [2], QSYM [13]) often employ multiple heuristics
for seed prioritization. Unfortunately, relying on human efforts
to learn and generalize seed selection strategies, as the previous
work did, is not scalable to a large number of features. In fact, it
is just infeasible to manually reason about a big set of selection
criteria when the number of features and the amount of data to
be analyzed become overwhelming (e.g., OSS-Fuzz generates
four trillion seeds per week [4] for different programs).
In contrast to heuristics, machine learning (ML) is good at
discovering underlying connections between data attributes
[36,43]. ML can be applied to seed selection because, as shown
by existing studies, the selection strategies are indeed learn-
able (i.e., exhibiting statistically signiﬁcant patterns). With
sufﬁcient learning data, ML can not only infer the importance
of different features but also mine the integration rules at scale.
MEUZZ is the ﬁrst to explore the ML-based, data-driven ap-
proach to seed selection in hybrid fuzzing. Our result conﬁrms
that automatically and continuously learned seed selection
strategies are more suitable for individual programs.
Fuzzing Monitor
Seed Selection
Job launcher
Seeds
New
Seeds
Test
Cases
New Test
Cases
Fuzzing
Mutation
(AFL)
C
Concolic Testing
Program
(KLEE/QSYM/Angr)
Solver
Figure 2: General hybrid fuzzing workﬂow.
We dissect the coordinator component as it is less discussed
in the literature and is the focus of this work. The coordinator
is a middleware that regulates the other two components. Its
major tasks include (i) monitoring the fuzzer to decide when
to launch the concolic execution engine, and (ii) prepare the
running environments for concolic testing; and (iii) select and
ﬁlter inputs that ﬂow between fuzzer and concolic executor.
The seed selection module in the coordinator needs to
decide which seeds in the fuzzer’s queue should be transferred
to the concolic testing ﬁrst (i.e., Seed utility prediction phase).
Before launching the concolic execution, the coordinator
needs to rank all inputs in the fuzzer’s queue based on their
utility. The utility of seed should correspond to the estimation
of its power to produce additional coverage if it is selected
to fuzz. As we mentioned in Section 2, current methods use
various heuristics to achieve this prioritization goal.
3.2 Supervised Machine Learning
Supervised ML is the task of learning from labeled data and
applies the knowledge to unknown data. Classiﬁcation and
regression are two foremost categories of such algorithms.
While classiﬁcation is used for predicting categorical
responses, regression predicts a numerical value to the new
data based on previously observed data. Supervised learning
has shown thriving employment in application security,
including bug discovery [30, 35, 37].
Supervised machine learning can be either online or ofﬂine.
The difference between these two lies in how models are
updated.
Online learning: Some learning environments can change
from second to second and their models need to get updated
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    79