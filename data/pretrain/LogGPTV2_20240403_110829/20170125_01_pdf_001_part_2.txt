– RF2 从Order 表和Lineitem表中删除等量与RF1 增加
的数据，模拟旧的销售数据被淘汰。
– RF1 和RF2 的执行必须保证数据库的ACID 约束，
并保持测试前后的数据库中的数据量不变。
– 更新操作除输出成功或失败信息外，不产生其它
输出信息
介绍
TPC-H
• 3 个测试
– TPC-H 测试分解为3 个子测试：数据装载测试、Power 测试
和Throughput 测试。
– 建立测试数据库的过程被称为装载数据，装载测试是为测
试DBMS 装载数据的能力。装载测试是第一项测试，测试装
载数据的时间，这项操作非常耗时。
– Power 测试是在数据装载测试完成后，数据库处于初始状
态，未进行其它任何操作，特别是缓冲区还没有被测试数据
库的数据，被称为raw查询。Power 测试要求22 个查询顺序
执行1 遍，同时执行一对RF1 和RF2 操作。
– 最后进行Throughput 测试，也是最核心和最复杂的测试，
它更接近于实际应用环境，与Power 测试比对SUT 系统的压
力有非常大的增加，有多个查询语句组，同时有一对RF1 和
RF2 更新流。
介绍
TPC-H
• TPC-H 标准的附录 D，有两组 ANSI C 语言源
程序包，即 和 。
DBGEN QGEN
– DBGEN 用于产生被测试数据，用户通过命令行
参数控制执行结果。
– QGEN 用于生产测试所需要的 22 个 SELECT、 RF1
和 两个更新操作。
RD2
介绍
TPC-H
• 数据量规定
– 由于数据量的大小对查询速度有直接的影响，TPC- H 标准对数据
库系统中的数据量有严格、明确的规定。
– 用SF 描述数据量，1SF 对应1 GB 单位，SF 由低到高依次是1、10、
30、100、300、1 000、3 000、10 000。需要强调，SF 规定的数据
量只是8个基本表的数据量，不包括索引和临时表。
– 从TPC- H 测试全程来看，需要的数据存储空较大，一般包括有基
本表、索引、临时表、数据文件和备份文件，基本表的大小为x；
索引和临时空间的经验值为3-5 位，取上限5x；
– DBGEN产生的数据文件的大小为x；备份文件大小为x；总计需要
的存储空间为8x。
– 就是说SF=1，需要准备8 倍，即8 GB 存储空间，才能顺利地进行
测试。
介绍
TPC-H
• 关系图
介绍
TPC-H
• 关系图
基准测试
TPC-C
• BenchmarkSQL support Oracle,PostgreSQL
• sysbench support MySQL,Oracle,PostgreSQL
• 下载benchmarksql
• http://sourceforge.net/projects/benchmarksql/
• 下载安装 JDK7
• http://www.oracle.com/technetwork/cn/java/javase/downloads/jdk7-downloads-1880260.html
• wget http://download.oracle.com/otn-pub/java/jdk/7u79-b15/jdk-7u79-linux-x64.rpm
• rpm -ivh jdk-7u79-linux-x64.rpm
• 检查包安装位置(使用rpm安装时也可以直接指定位置)
• rpm -ql jdk
• ...
• /usr/java/jdk1.7.0_79/bin/java
• ...
• $ export JAVA_HOME=/usr/java/jdk1.7.0_79
• $ export PATH=$JAVA_HOME/bin:$PATH
• $ export CLASSPATH=.:$CLASSPATH
• $ wget https://jdbc.postgresql.org/download/postgresql-9.4.1207.jre7.jar
• $ mv postgresql-9.4.1207.jre7.jar benchmarksql-4.1.0/lib/
基准测试
TPC-C
• 配置benchmarksql，使用新的postgresql java驱动
• $ vi runBenchmark.sh
• java -cp .:../lib/postgresql-9.4.1207.jre7.jar:../lib/log4j-1.2.17.jar:../lib/apache-log4j-extras-
1.1.jar:../dist/BenchmarkSQL-4.1.jar -Dprop=$1 jTPCC
• $ vi runLoader.sh
• java -cp .:../lib/postgresql-9.4.1207.jre7.jar:../dist/BenchmarkSQL-4.1.jar -Dprop=$1 LoadData $2
$3 $4 $5
• $ vi runSQL.sh
• myCP="../lib/postgresql-9.4.1207.jre7.jar"
• myCP="$myCP:../dist/BenchmarkSQL-4.1.jar"
• myOPTS="-Dprop=$1"
• myOPTS="$myOPTS -DcommandFile=$2"
• java -cp .:$myCP $myOPTS ExecJDBC
基准测试
TPC-C
• 修改log4j，减少日志打印量。priority改成info，只输出最终结果，不输出产生订单的日志。
• 编辑连接配置和压测配置。
• 1000 个仓库，约5亿数据量。
• 修改配置比例
• $ vi props.pg
• driver=org.postgresql.Driver
• conn=jdbc:postgresql://localhost:1921/postgres
• user=postgres
• password=123
• warehouses=1000
• terminals=96
• //To run specified transactions per terminal- runMins must equal zero
• runTxnsPerTerminal=0
• //To run for specified minutes- runTxnsPerTerminal must equal zero
• runMins=1
• //Number of total transactions per minute
• limitTxnsPerMin=0
• newOrderWeight=45
• paymentWeight=43
• orderStatusWeight=4
• deliveryWeight=4
• stockLevelWeight=4
基准测试
TPC-C
• 配置postgres用户默认搜索路径
• $ psql
• psql (9.5.0)
• Type "help" for help.
• postgres=# alter role postgres set
search_path='benchmarksql','public';
• 创建用于存放生成CSV的目录
• $ mkdir /u02/digoal/soft_bak/benchcsv
• 修改sqlTableCopies，指定目录
• $ vi sqlTableCopies
基准测试
TPC-C
• 建立表结构
• $ cd benchmarksql-4.1.0/run
• $ ./runSQL.sh props.pg sqlTableCreates
• 生成CSV
• $ ./runLoader.sh props.pg numWarehouses 1000 fileLocation
/u02/digoal/soft_bak/benchcsv/
• 导入数据库
• $ ./runSQL.sh props.pg sqlTableCopies
• 创建约束和索引
• $ ./runSQL.sh props.pg sqlIndexCreates
基准测试
TPC-C
• 备份
• $ pg_dump -f /u02/digoal/soft_bak/benchmarksql.dmp -F c -n benchmarksql postgres
• 压测：
• nohup ./runBenchmark.sh props.pg >/dev/null 2>./errrun.log &
• 观察
• perf top
– CPU时间占比
• iostat -x
– 块设备使用率，平均IO响应时间，队列大小，平均IO大小
• top
• dstat
– CPU比例，IO，。。。
• pg_stat_statements
– SQL请求耗时, IO调用, CPU耗时
基准测试
TPC-C
• benchmarksql 支持多个 SCHEMA
• http://blog.163.com/digoal@126/blog/static/
163877040201601021838221/
基准测试
TPC-C
• 优化阶段数据
TPmC
700000
600000 599257.69 606466.31
577805.81
500000
482383.01
453058.64
400000
TPmC
300000
256195.32
200000
100000
0
阶段 1 2 3 4 5 6
最佳实践
PostgreSQL
• 存储层
– 条带大小，条带宽度
– 对齐
• 块设备规划
– pg_xlog、 $PGDATA、 user data tablespace、 user
idx tablespace
– 分区位置对齐，卷 DATA起始位置对齐，文件系
统、卷条带对齐
最佳实践
PostgreSQL
• 操作系统
– vm.zone_reclaim_mode=0 # 禁用 numa, 或者在vmlinux中禁止.
– vm.swappiness = 0 # 关闭交换分区
– net.core.rmem_max = 4194304 # The maximum receive socket buffer size in bytes
– net.core.wmem_max = 4194304 # The maximum send socket buffer size in bytes.
– net.core.rmem_default = 262144 # The default setting of the socket receive buffer in bytes.
– net.core.wmem_default = 262144 # The default setting (in bytes) of the socket send buffer.
– vm.dirty_background_bytes = 102400000 # 系统脏页到达这个值，系统后台刷脏页调度进程 pdflush
（或其他） 自动将(dirty_expire_centisecs/100）秒前的脏页刷到磁盘
– vm.dirty_expire_centisecs = 6000 # 比这个值老的脏页，将被刷到磁盘。6000表示60秒。
– vm.dirty_writeback_centisecs = 50 # pdflush（或其他）后台刷脏页进程的唤醒间隔， 50表示0.5秒。
– vm.dirty_ratio = 80 # 如果系统进程刷脏页太慢，使得系统脏页超过内存 80 % 时，则用户进程如果
有写磁盘的操作（如fsync, fdatasync等调用），则需要主动把系统脏页刷出。
– vm.nr_hugepages = 102352 # 大页数量，乘以/proc/meminfo Hugepagesize就是支持大页的内存数量。
– vm.overcommit_memory = 0 # 在分配内存时，允许少量over malloc
– vm.overcommit_ratio = 90 # 当overcommit_memory = 2 时，用于参与计算允许指派的内存大小。
• grub: numa=off elevator=deadline