the current system load loadc and compares it with a user-
speciﬁed target load loadt. If the current load is higher than
the target load, Aaron plays safe and uses the unmodiﬁed,
original software. Otherwise it schedules software variants
that detect errors. Aaron chooses the software variant v from
the set of all variants V with an overhead o(v) closest to a
target overhead t:
(cid:26)
v =
with
vi : d(vi) = min({d(vj)|vj ∈ V })
vnoChecks
≥ 1
if loadc
loadt
else
(cid:12)(cid:12)(cid:12)(cid:12)o(v) − t
(cid:18) loadc
loadt
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12) .
d(v) =
Aaron scales the utilization factor loadc
loadt
to the interval of
all observed overheads. The mapped value is used as the
target overhead (Figure 4). The variant that is closest to
the target overhead is used to process the current task. In
our experience, there is typically a correlation between the
Figure 4. Variant selection maps the systems load linearly to a target
overhead.
percentage of errors detected and the overhead of a vari-
ant. Therefore, Aaron chooses the variant with the highest
overhead without overloading the system.
The simplicity of the scheduling is a main feature of
Aaron and enables it to fulﬁll the design goal of having low
overhead (Section III). However, to determine the overhead
of variants at runtime we introduce randomness into the
scheduling process.
3) Dynamic Overhead Calculation: The scheduler uses
the overheads of the different variants to choose the variant
most appropriate at the current system load.
To facilitate accurate variant selection, the estimated over-
heads should reﬂect the actual overhead with low variation.
The overhead a variant exposes during processing of a spe-
ciﬁc task is inﬂuenced by the executed code path. Since the
code paths may differ, the mixture of executed instructions
might differ, too. For example, if a large percentage of
all executed instructions are memory reads, the NullRead
variant has to protect a relatively large fraction of the
execution. Thus, NullRead will expose a relatively high
overhead. However, if memory reads are comparatively rare
the overhead is lower. In sum, overheads are not static values
but depend on the executed task.
For a most accurate estimation of overheads, one has to
map each task to an overhead. This involves mapping multi-
ple dimensions of a task (e.g. operation requested, task size)
onto a single value. Unfortunately, this accurate prediction
consumes quite some processing power. Aaron eludes this
conﬂict by assuming an unimodal distribution of overheads
with low variance. Aaron handles changing workloads and
thus changing overheads by measuring them at runtime. It
exploits the assumption of an unimodal distribution by using
the median of observed values.
For each variant, Aaron keeps a sliding window con-
taining the execution times of the last
tasks processed
using this variant. The sliding window is kept up-to-date
by measuring the execution time of each processed task
and replacing values in FIFO order. To make sure values
are up-to-date even for variants that are not used at all,
Aaron samples variants regularly. To this end, each variant
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:53 UTC from IEEE Xplore.  Restrictions apply. 
414has a logical timeout. The internal clock is driven by the
processing of tasks; whenever a task is processed, the clock
is incremented. For each processed task, Aaron measures
the execution time. If the measured time and the estimated
execution time for the used variant are reasonably close,
the timeout is reset. Otherwise, if both values diverge more
than a threshold, the timeout is decreased by the difference
between the current clock value and the last time the timeout
was reset. This fast-tracks the re-sampling of the current
variant if needed. The mechanism ensures that (1) variants
are regularly executed to verify and update the estimated
overhead; thus, minor changes in the perceived overhead
are gradually reﬂected in the estimations. (2) If veriﬁcation
fails the variant is re-sampled in a timely manner; a sequence
of major mispredictions leads to a rapid adaptation of new
values.
E. Fault Coverage
The probability that a fault is detected alias total fault cov-
erage Ct depends upon the coverage of the single variants,
Cv, and the probability Pv that a single variant is selected
for execution:
|V |(cid:88)
|V |(cid:80)
v=0
Since
Ct =
Cv ∗ Pv.
v=0
Pv = 1 and 0 ≤ Cv ≤ 1:
Ct ≤ max({Cv|v ∈ V }).
The actual fault coverage of Aaron, Ct, is less than or
equal to the fault coverage of the best software variant.
In theory, total coverage can be maximized by using the
software variant with the highest coverage. Unfortunately, it
is hard at best to estimate the coverage of different variants.
Fault coverage not only depends upon the system and the
software variants, it also changes over time, for example due
to an altered workload. Furthermore, using the variant with
the highest coverage might impose a high overhead all the
time.
Aaron maximizes fault coverage by adapting the error
detection to the current workload. Aaron always tries as hard
as possible to detect errors — but not harder.
3) The workload of the application is throughput ori-
ented. Latency is not as critical as throughput.
4) Processing of tasks should be isolated from each other.
Complex interdependencies between tasks make it
harder to use Aaron since these interdependencies have
to be understood and taken care of manually.
These limitations are typically fulﬁlled by applications
targeting cluster environments. Aaron also targets cluster
environments.
Most cluster applications are task-oriented and tasks can
be processed in parallel. Since interdependencies limit par-
allelism, those applications are tuned to eliminate them as
far as possible. Although there might be a hard bound on
latency, throughput is often more important. Aaron uses
multiple queues to organize the pending tasks. As a direct
consequence Aaron might reorder tasks unintentionally, and
latency might ﬂuctuate. Aaron could use priority queues
to minimize the latency. However, this is an orthogonal
research question and out of scope of current work.
Aaron adds calculations to the processing in order to
ﬁnd errors. These additional calculations are not free but
cost processing time. As a result, Aaron increases the
latency even if the queues are empty and new requests are
processed immediately. Automatic parallelization of runtime
checks [17] can be used to minimize the increase in latency.
III. EVALUATION
We performed several experiments, each designed to
answer one of the following questions:
1) Power consumption: How much additional power is
consumed by Aaron’s fault detection?
2) Scheduling overhead: How large is the overhead
of Aaron? Is the design goal of having negligible
overhead fulﬁlled?
3) Spare cycles: How good does Aaron exploit spare
cycles in the system?
4) Throughput: How many requests can be processed by
Aaron? Does Aaron inﬂuence maximum throughput
negatively?
5) Responsiveness: How does Aaron react to sudden load
changes? How fast can the system adapt the fault
detection to load changes? How does the workload
inﬂuence the selection of variants?
F. Limitations of Aaron
A. Setup
Aaron is an infrastructure for early deployment and con-
stant monitoring of cluster applications. It monitors execu-
tion using software diversity to ﬁnd errors pro-actively. In
the following, we summarize the constraints, which should
be fulﬁlled by applications using Aaron. They result directly
from the previously presented design decisions:
1) The computation of the application is split into tasks
operating on the state of the application.
2) The level of the current workload can be estimated.
We use several different applications to answer the ques-
tions posed. The applications are chosen in such a way
that the behavior of Aaron in different situations becomes
apparent.
Wordcount The client sends a chunk of text
to the
server. The text is drawn randomly from a
178MB large document. The server counts
the occurrences of each word in this text.
We experimented with different sizes for the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:53 UTC from IEEE Xplore.  Restrictions apply. 
415MD5
chunks. The size did not inﬂuence the behav-
ior of Aaron; we ﬁxed it arbitrarily at 20KB.
Wordcount is bound by network throughput.
The request contains between 100 to 100k
random bytes. For each request, the appli-
cation computes 15 MD5 hash sums. We
designed this artiﬁcial application to be able
to evaluate Aaron’s behavior for a very CPU
intensive application: MD5 is CPU bound;
throughput will be hindered by available
computational power on the node long before
the network is saturated.
Zoologist This application is inspired by the dis-
tributed coordination service developed at Ya-
hoo called ZooKeeper [18]. Zoologist pro-
vides operations for manipulating a dis-
tributed name space. Requests can add and
delete nodes in a hierarchical name space.
Each name space node can also contain data.
The state is kept in a hash map. All operations
require little more than a simple lookup in the
hash table. This makes the throughput for this
application network bound. We implemented
Zoologist because ZooKeeper uses Java. Cur-
rently Aaron only supports C/C++.
This service receives as a request the name of
a ﬁle. To be able to evaluate Aaron’s behavior
for applications accessing local disk, the ﬁle
is stored locally on the server running the
application. The application calls a test suite
function from the LibPNG library. The test
suite performs a set of image manipulations.
Because image ﬁle formats are complex, im-
age handling libraries are especially prone to
programming errors. This makes LibPNG a
suitable candidate to evaluate its error han-
dling capabilities.
LibPNG
The experimental setup is as follows: our cluster consists
of multiple nodes connected via Gigabit Ethernet. Each
machine has two Intel Xeon E5405 CPUs with four cores
each and 8GB physical RAM. There is one hard disk per
node attached via SATA2 and spinning with 7200RPM. Each
node runs Debian Linux 5.0 with kernel 2.6.26.
Unless stated otherwise, all measurements represent the
truncated arithmetic mean of ﬁve runs.
B. Power Consumption
One of the motivations for this work is, that cluster nodes
consume a signiﬁcant amount of power even while being
idle or only lightly loaded (Section II-C). Aaron exploits
these spare cycles for fault detection.
We measured the increase in power consumption of
the MD5 application for different workloads (Figure 5).
Without error detection (denoted as Native in the Figure),
Figure 5. CPU utilization and power consumption with increasing request
rate for MD5.
Figure 6. Framework overhead for processing empty requests.
processing 400 tasks per second consumes 145W (54% CPU
utilization). Using Aaron for error detection increases power
consumption to 185W (97% CPU utilization). An increase
of 28%.
C. Scheduling Overhead
To get a baseline measurement of system performance,
we implemented a Null-application. This application reads
empty tasks from the IO sockets and returns an empty
answer to the client. It does not process tasks in any way.
It is a good way to measure how many requests our system
can process in theory, and how much processing overhead
the framework itself adds.
Figure 6 shows the CPU utilization for processing null-
requests. It compares the execution of Aaron with runtime
checking with a run without runtime checking (labeled
Native in the Figure). While processing 100k requests,
roughly two cores are busy reading requests from the TCP
socket, putting them in the appropriate processing queue, and
running the scheduling algorithm. Since the null-application
does not process any tasks, the minor difference between
the two curves reﬂects the overhead of Aaron’s scheduling
algorithm. Because the curves are virtually identical, we
can deduce that the scheduler is indeed sufﬁciently fast and
fulﬁlls the design goal of negligible overhead.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:53 UTC from IEEE Xplore.  Restrictions apply. 
0100020003000Requests per second0%20%40%60%80%100%CPU utilizationCPU: NativeCPU: Aaron020406080100120140160180200Energy consumption [watts]Energy: NativeEnergy: Aaron0250005000075000100000Requests per second0%10%20%30%CPU utilizationNativeAaronNull416Figure 7. CPU utilization for each application with varying request rates. In Native mode no runtime checks are used.
D. Using Spare Cycles for Fault Detection
To evaluate how good Aaron exploits spare cycles, we
measured the CPU utilization for varying workloads and
different applications (Figure 7).
Aaron uses spare cycles to schedule runtime checks: In
Figure 7, the CPU utilization is considerably increased for
all applications. Using Aaron the utilization of LibPNG and
Zoologist decreases after 4k and 20k requests per second,
respectively. As the request rate increases, Aaron plays it
safe: It schedules software variants with lower overhead.
MD5 is CPU bound. Even with a low request rate, CPU
utilization is already above 50%. As soon as workload
reaches 1800 request per second, no more spare cycles are
present in the system.
For applications that are not CPU bound, e.g., Zoologist
and LibPNG, CPU utilization of the native version does
not reach the maximum. Zoologist is network bound, as the
computational overhead per operation is small. LibPNG has
a high contention rate and reaches peak throughput with low
CPU utilization (about 25%) at 8000 requests per second.
E. Throughput
Throughput is usually a most important factor of a cluster
application. Figure 8 shows the throughput for a varying rate
of incoming requests.
MD5 and LibPNG reach the point of saturation at about
1800 and 8000 requests per second, respectively. MD5 is
very CPU intensive; whereas LibPNG puts some load on the
ﬁle system for accessing PNG images. Wordcount saturates
at about 5700 requests per second. Each request processes
20KB, resulting in an accumulated throughput of about
111MB per second. Using the tool iperf, we measured the
maximal throughput of TCP as 115 MBps, verifying that
Wordcount is indeed network bound.
The most important observation of this measurement is
that Aaron barely has any effect on the throughput; for all
applications it is indistinguishable with a small deviation for
LibPNG; the throughput is slightly higher at 12k requests
per second when using Aaron. We attribute this to random
ﬂuctuation in the measurements.
F. Responsiveness
So far we have shown that Aaron’s overhead is negligible
(Section III-C), and throughput is not inﬂuenced by using
spare cycles (Section III-E). Next, we will show that Aaron
adapts extremely fast to changes in the workload.
We evaluated Aaron’s speed of adaptation using the
following setup: We used the CPU-bound MD5 application
and put on a workload of 1000 tasks per second. This utilizes
the system to 60% of its peak throughput. At time t1, the
workload generators increase the request rate to 10k tasks
per second. Only executing the original application, through-
put peaks at about 1900 requests per second (Figure 9).
Using Aaron as an underlying fault detection framework
does not change the behavior: both versions reach the same
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:53 UTC from IEEE Xplore.  Restrictions apply. 
0100020003000Requests per second0%20%40%60%80%100%CPU utilizationNativeAaronMD502500500075001000012500Requests per second0%20%40%60%80%100%CPU utilizationNativeAaronLibPNG025005000750010000Requests per second0%20%40%60%80%100%CPU utilizationNativeAaronWordcount0250005000075000100000Requests per second0%20%40%60%80%100%CPU utilizationNativeAaronZoologist417Figure 8. Throughput for each application with varying request rate. The unit of both axes is requests per second.
Figure 9. Handling load surges (left) in MD5. Fraction of checked executions based on load (right).
throughput at the same point in time. Aaron does indeed not
inﬂuence the throughput of the application.
At the right side of Figure 9 we show the fraction of