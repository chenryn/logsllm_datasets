var encrypted = Crypto.encrypt(buf);
socket.send(ADDR, encrypted);
4
5
6
7
8
9
10
11
12
13 }
Listing 1: An example code from Opaque [3] in Javascript. It
tags each element in the secret input and sends the encrypted
result over the network. Red variables are tainted variables from
the secret input secretInput[i]. Since the algorithm has a
secret (secretInput[i]) dependent branch, taint analysis based
techniques deem that this code has leakage although the observed
size of the data (encrypted) does not depend on the secret input.
plicated path constraints, which increase constraint solving
time. In some cases, state merging may lower the performance
of symbolic execution if applied indiscreetly [41].
2.4 Existing Approach Using Taint Analysis
Several techniques have been devised to check the access
pattern leakage of an algorithm. The most widely used tech-
nique is taint analysis. Existing works utilize it to check
side-channel leakage [15, 59] and more broadly oblivious-
ness [8, 75]. This line of work identiﬁes variables whose
values depend on secret input. They track the taints of vari-
ables propagated from secret inputs. In this way, a checker
can check whether a given algorithm includes a secret depen-
dent branch. Algorithms with secret dependent branches are
rejected in this approach assuming that those branches incur
information leakage because of the different behaviors in the
true and false blocks of the conditional statements.
Limitation. However, taint analysis can reject benign obliv-
ious programs many times. Even if both execution paths of
a branch exhibit the same observable behavior, a checker
simply rejects the algorithm if the branch contains a tainted
variable. As we deﬁne in Table 1, this is a false-positive error.
For example, let us assumes the network attacker discussed
in §2.1. The attacker can only observe the network access
patterns including the size of data sent over the network, but
not the actual content of the encrypted data. Listing 1 shows
one example algorithm where taint analysis leads to a false
positive. In this example, the predicate (Line 4) contains a se-
cret variable secretInput[i]. Hence, taint tracking based
techniques reject this algorithm due to this secret branch.
However, since the threat model in oblivious algorithms as-
sumes the actual content ((secretInput[i], 0) in Line
5, (secretInput[i], 1) in Line 7) is encrypted, both true
and false branch blocks have indistinguishable behavior to an
attacker. Hence, the example algorithm is actually oblivious.
Requirements. A more accurate checker for oblivious algo-
rithms should satisfy the following requirements.
1) Be aware of which state of a program is observable or not
to an attacker (e.g., in Listing 1, the data content is en-
crypted, thus invisible, but the size of the data is revealed).
2) Understand the behavior of a program on different execu-
tion paths across the whole input space to make a sound
judgment of whether an algorithm is oblivious.
3) Know which input values are secret or public to decide
the behavior of a program is independent of secret input.
4) Since a checker has a limited time budget, the checking
process should be scalable in terms of the number of input
data records.
3 ObliCheck Overview
In order to check oblivious algorithms with unobservable state
and overcome the limitations of existing approaches, we pro-
pose ObliCheck. We now provide an overview of ObliCheck’s
API, the threat model it assumes, and its security guarantees.
3.1 ObliCheck APIs
To provide a framework that can accommodate algorithms
with different threat models, ObliCheck provides abstract ob-
servable and unobservable memory space. Any read and write
operations to the observable space are assumed to be observed
by an attacker. ObliCheck provides algorithm designers with
special APIs for describing reads and writes to the observ-
able space as described in Table 2. We assume data written
to or read from observable space is always encrypted. Thus,
an attacker can learn the size, source/destination address of
the data, and the type of operation (read or write) but not the
actual content. Using this abstract store model with APIs, a
designer can reﬂect a threat model that she assumes in the
code.
ObliCheck offers two categories of APIs for a designer
to write an oblivious algorithm. The ﬁrst has functions that
describe communication between unobservable and observ-
able spaces. The second one is to specify whether an input
value is secret or public. Table 2 lists the APIs that ObliCheck
provides. Using observableRead and observableW rite, a de-
signer can naturally render a boundary between observable
and observable spaces in the algorithm.
ObliCheck keeps the access sequence under the hood and
uses the access sequence to check the ﬁnal veriﬁcation condi-
2222    30th USENIX Security Symposium
USENIX Association
Name
Arguments
Description
Effect
observableW rite (space, addr, buf)
observableRead (space, addr, buf)
Write buf at the addr of observable τP += (, addr, size(buf)),
space
Read size(buf) of bytes at addr
of observable space
space.store[addr] = *buf
τP += (, addr, size(buf)),
*buf = space.store[addr]
readSecretInput ()
readPublicInput ()
Introduce a secret input
Introduce a public input
A new tainted symbolic value is added
A new untainted symbolic value is added
Table 2: API of ObliCheck. observableW rite and observableRead are used to describe communication between observable and unobservable
space. τP is the trace of observations deﬁned as a sequence of triplets in § 3.3. The ﬁrst ﬁeld of a triplet added to the access sequence contains
the enumerated type of access of MW, MR, NS, and NR, which encode memory write, memory read, network send and network receive respectively.
readSecretInput, and readPublicInput are necessary to make ObliCheck distinguish the secret inputs from public inputs (Refer to Figure 3).
Function
send(dst, buf)
recv(src, buf)
write(dst, buf)
read(src, buf)
Implementation using ObliCheck API
observableWrite(network, , buf)
observableRead(network, , buf)
observableWrite(memory, dst, buf)
observableRead(memory, src, buf)
Table 3: Example user-deﬁned functions accessing observable
spaces. send and recv are used to express message transfer over net-
work and read and write represents local memory access. network
and memory are initialized by users with unique IDs and memory
space to store written and sent data.
var buf = [];
for (var i = 0; i 
However, just running an algorithm once symbolically is
not sufﬁcient because the veriﬁcation condition of oblivious-
ness is written in terms of pairs of input. In other words,
obliviousness is a 2-safety property. Terauchi and Aiken [67]
formally deﬁned a 2-safety property to distinguish it from a
general safety property, which can be proved by observing a
single ﬁnite trace.
where t represents a type of access, a denotes a target or
source location of the operation, and l represents the size of
a data read or written. The type of access is either read or
write combined with the type of an observable space (e.g.,
memory or network). Further, since we assume the data itself
is encrypted properly before being written to an observable
store, the attacker can only observe the size of the data that is
read or written, and not the actual contents.
Note that in addition to secret data, an algorithm P may
also receive some public data as input. For P to achieve the
oblivious property, we require that given any pair of inputs
I and I(cid:48), as long as the public input is the same, then no
polynomial-time adversary should be able to distinguish be-
tween the traces τP(I) and τP(I(cid:48)). Based on this deﬁnition,
a condition for checking the oblivious property can be ex-
pressed as follows:
∀I, I(cid:48) ∈ InputSpace(P),
PublicInputP(I) = PublicInputP(I(cid:48))
⇒ τP(I) = τP(I(cid:48))
Here, InputSpace represents all the possible input spaces of a
given algorithm, and PublicInputP returns the public input of
an algorithm P. ObliCheck veriﬁes that the above condition
holds while checking an algorithm. The condition assumes
nothing about SecretInput, which encodes the independence
of the observable output from secret input.
ObliCheck records the trace during the execution under the
hood when it encounters a read or write API explained in §3.1.
The veriﬁcation condition is written in terms of the pairs of
input (I,I(cid:48)). This implies that the veriﬁcation condition for
the oblivious property is a 2-safety property [67] that requires
a checker to observe two ﬁnite traces of an algorithm. We will
describe how ObliCheck uses symbolic execution to check
the above veriﬁcation condition in §4.1.
4 Symbolic Execution and State Merging
4.1 Symbolic Execution for Checking Obliviousness
ObliCheck executes an algorithm symbolically, and at the
end of the execution, it checks whether the algorithm satisﬁes
the obliviousness condition deﬁned in §3.3. ObliCheck uses
symbolic execution in the following way.
ObliCheck starts by treating all input values as symbolic
variables. ObliCheck explores both the true and false blocks of
all branches containing a symbolic value, while distinguishing
between secret and public symbolic variables to correctly
generate the veriﬁcation condition at the end of the execution.
In order to refute a 2-safety property, a checker has to ob-
serve two ﬁnite traces of an algorithm. Hence, ObliCheck
internally runs the algorithm twice symbolically, by sequen-
tially composing two copies of the algorithm. Each exe-
cution path of the ﬁrst copy is followed by each one of
the second copy. This makes ObliCheck explore every pair
(Cartesian product) of the execution paths with pairs of input
(I,I(cid:48)) ∈ InputSpace(P). At the end of the second execution,
ObliCheck compares the traces of both runs and checks that
the veriﬁcation condition is always true using a constraint
solver (which checks that the negation of the veriﬁcation con-
dition is unsatisﬁable).
Example. To demonstrate how symbolic execution is used,
we represent the value-summary symbolic state of Listing 2
in Table 4. For brevity, we assume the input length n is 1 so
the loop iterates only once and omit the program counter (pc)
state. We will generalize for algorithms with loops bounded
by an arbitrary symbolic value in §6.
Value Summary
Line
2-4 buf.length (cid:55)→ {(true,0)}, i (cid:55)→ {(true,0)}, buf[i] (cid:55)→ {(true,unde f ined)}
5,8-10
buf.length (cid:55)→ {(x0, f irst < y f irst ,1)}, i (cid:55)→ {(x0, f irst < y f irst ,0)},
buf.length (cid:55)→ {(x0, f irst ≥ y f irst ,1)}, i (cid:55)→ {(x0, f irst ≥ y f irst ,0)},
buf[i] (cid:55)→ {(x0, f irst < y f irst ,Pair(x0, f irst ,0))}
buf[i] (cid:55)→ {(x0, f irst ≥ y f irst ,Pair(x0, f irst ,1))}
7,8-10
2-4 buf.length (cid:55)→ {(true,0)}, i (cid:55)→ {(true,0)}, buf[i] (cid:55)→ {(true,unde f ined)}
buf.length (cid:55)→ {(x0,second < ysecond,1)}, i (cid:55)→ {(x0,second < ysecond,0)},
5,8-10
buf.length (cid:55)→ {(x0,second ≥ ysecond,1)}, i (cid:55)→ {(x0,second ≥ ysecond,0)},
buf[i] (cid:55)→ {(x0,second < ysecond,Pair(x0,second,0))}
buf[i] (cid:55)→ {(x0,second ≥ ysecond,Pair(x0,second,1))}
7,8-10
Table 4: Result of symbolic execution of the algorithm in Listing 2.
main introduces secret and public symbolic variables x0
and y respectively and assigns them to secretInput[0] and
threshold. To differentiate the ﬁrst and second symbolic
executions, we add additional subscripts f irst and second to
the variables. Inside the tag function, the ﬁrst symbolic exe-
cution starts with an initial path condition True and the length
of the output buffer is 0. After encountering the branch at Line
4, the execution diverges into two sets and the output buffer
length increments by one. The second symbolic execution
runs the same algorithm but with different symbolic variables:
x0,second and ysecond instead of x0, f irst and y f irst.
After ﬁnishing the symbolic execution, ObliCheck gener-
2224    30th USENIX Security Symposium
USENIX Association
ates a veriﬁcation condition based on the deﬁnition in §3.3:
y f irst = ysecond ⇒
((x0, f irst < y f irst ∧ x0,second < ysecond ⇒ 1 = 1)
∧(x0, f irst < y f irst ∧ x0,second ≥ ysecond ⇒ 1 = 1)
∧(x0, f irst ≥ y f irst ∧ x0,second < ysecond ⇒ 1 = 1)
∧(x0, f irst ≥ y f irst ∧ x0,second ≥ ysecond ⇒ 1 = 1))
This formula is trivially always true since buf.length is
always a concrete value 1 (we leave out the type of access
and the address ﬁelds of the trace for simplicity). The veriﬁ-
cation condition is quite trivial for this simple example, but
as an input algorithm becomes more complicated, symbolic
execution proves its real worth since it can capture how the
observable trace changes over the execution and can exercise
all possible execution paths.
4.2 Optimistic State Merging
As we discussed in § 2.3, existing state merging techniques
merge states on different paths to alleviate the path explosion
problem. When a variable carries distinct values along differ-
ent paths, however, the beneﬁt of state merging diminishes.
In MultiSE, for example, the size of value summary can still
grow exponentially if the variable maintains different values
across all execution paths. To solve this problem, we devise