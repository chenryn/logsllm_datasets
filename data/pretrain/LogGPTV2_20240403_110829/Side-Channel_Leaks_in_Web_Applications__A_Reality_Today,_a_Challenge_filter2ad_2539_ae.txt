==  allSizes(applyDailyUpdate(((cid:307),ω),d-1))))); 
AgtySet  =  {((cid:307),ω)|  ∃((cid:307)1,ω1)  ∈  AgtySet’  ∧ 
(((cid:307),ω)== applyDailyUpdate((cid:307)1,ω1))}; 
} 
Output AgtySet and d; 
We define function applyDailyUpdate ((cid:307)1,ω1) 
based  on price(fund,day),  a  function  that  calculates 
today’s percentages (cid:307) and  ω given yesterday’s (cid:307)1 and  ω1. 
The  array  allSizes((cid:307),ω)  can  be  acquired  through 
adjusting  the  money  allocation  in  our  own  account  to 
produce pie charts of different sizes. This, however, requires 
too  much  effort.  A  more  efficient  approach  is  to  use  the 
same GIF compression algorithm adopted by OnlineInvestA 
to generate a set of the pie charts identical to those issued by 
OnlineInvestA. We conducted a detailed study of some pie 
chart  samples,  and  compared  them  with  the  same  GIF  pie 
charts  generated  by  Microsoft  Office  Picture  Manager. 
Although  their  palette  scopes  and  color  encoding  are 
different, the lossless compression algorithm, a.k.a. Lempel-
Ziv-Welch  (LZW)  [20],  produces  the  same  compression 
data  in  both  applications.  Therefore  we  believe  that  the 
exact GIF compression algorithm used by OnlineInvestA can 
be built based on the knowledge of sample pie charts.   
The  experimental  results.  As  a  proof-of-concept 
demonstration, we used the Java package JFreeChart [10] to 
generate all 79401 pie charts, whose sizes fell in the range 
of  [700,900]  bytes,  similar  to  the  sizes  of  the  sampled 
OnlineInvestA pie charts.  Figure 11 illustrates the relations 
among  sizes,  (cid:307)  and  ω  for  all  those  pie  charts.  The  upper 
triangle is invalid because (cid:307) + ω > 100. The sizes of those 
charts form a symmetric surface. It is easy to understand the 
geometrical meaning of the algorithm shown earlier: given 
size(d)for a specific day,  a contour line can be identified 
from the surface that include all the charts of that size. From 
this  line,  our  algorithm  drops  all  such  points  (i.e.,  charts) 
that do not evolve into the points on the next day’s contour 
line,  given  the  price  changes  of  the  mutual  funds.  The 
algorithm ends when there is only one point left.  
Our  experiments  demonstrate  the  power  of  the  attack. 
We simulated the  financial  market by randomly increasing 
or  decreasing  the  price  of  each  fund  by  [0.5%,  1%]  every 
day.  We  found  that  typically,  our  algorithm  successfully 
inferred a pie chart according to the dynamics of its sizes on 
200
4  different  days.  There  are  some  situations  where  the  pie 
chart  size  of  the  fifth  day  is  needed.  Given  that  the  initial 
ambiguity  set  contains  79401  possibilities,  the  result  is 
impressive: on average, each observed pie chart size reduces 
the ambiguity set by more-than-one order of magnitudes.  
packet 
size
900
850
800
750
700
(cid:307)
100
90 80
70
60
50
40
30
20
10
0
60
40
20
0
Figure 11: Pie chart sizes plotted on (cid:307) and ω axes 
ω
100
80
3)  Potential More Serious Consequence  
Like many financial companies, OnlineInvestA provides 
a  variety  of  account  types  for  a broad  range  of  customers, 
including 
investment  professionals.  We  do  not  have 
resources  to  conduct  the  study  on  all  these  account  types. 
However,  it  is  possible  that  they  also  contain  similar 
problems  because  it  is  a  common  practice  to  show  price 
history curves and pie charts on financial pages, and these 
accounts probably share the same application infrastructures 
with the type of accounts that we studied. If an institution’s 
or professional’s account leaks out information, for example, 
the consequence is obviously  more devastating. Of course, 
an institution or professional may invest in more than three 
funds,  which  increases  the  pie  chart  possibilities.  On  the 
other hand, an institution’s or professional’s account may be 
expected to be updated and viewed much more frequently. 
We believe that with the multiplicative reduction power, the 
pie chart can still be revealed.   
D.  Google Search, Yahoo Search and Bing Search  
In  addition  to  HTTPS  extensively  used  to  secure  the 
web flows in web applications, cryptographic protocols for 
wireless communications, such as WPA and WPA2, are also 
found  in  our  research  to  leak  out  a  significant  amount  of 
information  of  the  web  applications  that  they  protect.   We 
realized  that  this  problem  is  particularly  serious  for  search 
engines.  Although  individual  query  words  that  the  user 
enters  may  not  be  as  sensitive  as  health,  income  and 
investment data discussed before, if an attacker can obtain 
her  query  history,  the  consequence  can  be  serious:  query 
histories reveal a lot about one’s online activities, which is 
often viewed as sensitive information assets, particularly in 
corporate settings due to intellectual property concerns. To 
illustrate the problem, we constructed an attack program to 
allow  an  unauthorized  stranger  sitting  outside  a  corporate 
building to glean the query words entered by employees.  
1)  Basics of Wi-Fi Encryption Schemes 
An early scheme, WEP, is deprecated now because it is 
susceptible  to  key-recovery  attacks  [3].  Here  we  only 
discuss the up-to-date Wi-Fi encryption schemes, i.e., WPA 
and  WPA2.  Using  these  schemes,  every  Wi-Fi  device  can 
establish a private channel to communicate with the wireless 
access  point  (AP).  WPA  is  based  upon  TKIP,  which  uses 
RC4 stream cipher. As a result, packets encrypted by WPA 
exhibit byte-level granularity. WPA2 is based upon CCMP, 
which adopts the 128-bit AES block cipher operating in the 
counter  mode.  One  might  expect  the  “round-to-16-byte” 
effect due to the use of the block cipher. In fact this effect 
does not exist, because of the counter  mode,  which  makes 
the ciphertext fully preserve the size of its plaintext, just like 
a  stream  cipher.  An  illustration  of  the  CCMP  packet 
structure is given in the IEEE 802.11 specification (see Page 
180 of [9]). Therefore the reality for web developers is that 
they  need  to  take  the  full  responsibility  to  pad  packets,  as 
there is no mitigation at the Wi-Fi encryption layer.  
2)  Query Word Leaks 
As  discussed  before,  the  auto-suggestion  feature  is 
vulnerable  to  side-channel  analysis  when  the  traffic  it 
generates  is  protected  by  HTTPS.  Many  major  search 
engines, including Google, Yahoo and Bing, also implement 
the  feature  to  help  users  enter  their  queries  quickly  and 
accurately.  It  appears  to  become  an  important  means  to 
ensure  high  relevance  of  search  results,  in  addition  to 
offering friendly user interactions.  Although the basic idea 
here is similar to that described in prior sections, a number 
of details and new observations are worth highlighting. 
Web flow vector. Once the Wi-Fi packets are encrypted, 
a  wireless  sniffer  cannot  see  their  IP  addresses  but  MAC 
addresses.  However,  the  packets  associated  with  auto-
suggestions  are  easy  to  identify  by  the  web  flow  vectors. 
For example, when the word “list” is entered in Google, the 
vector of the WPA2 packets are (b(cid:206), (cid:205)910, 96(cid:206), b+1(cid:206), 
(cid:205)931, 96(cid:206), b+2(cid:206), (cid:205)995, 96(cid:206), b+3(cid:206), (cid:205)1007, 96(cid:206)), 
where b is around 800 bytes. As we can see from the vector, 
every  request  increases  its  size  by  one  byte  (b,  b+1,  b+2, 
b+3) in response to each keystroke (except backspace). The 
response  sizes  910,  931,  995,  1007  correspond  to  the 
suggestions for “l”, “li”, “lis” and “list”.    
Ambiguity  set  size.  Unlike  OnlineHealthA,  which  only 
consists of thousands of items, the number of possible query 
words  is  huge.  This,  however,  does  not  impair  our  attack, 
because the number of guesses is only linear to the length of 
the  query  words.  Our  attack  generated  Google  queries  to 
match  their  traffic  with  those  produced  by  the  victim’s 
keystrokes.  The  number  of  such  attempts  was  only 
27*(query word length), with the character set {a..z, space}.  
Caching  effect.  Google  and  Yahoo  set  a  one-hour 
caching  period.  Due  to  the  caching,  a  keystroke  does  not 
generate  an  HTTP  request  if  the  exact  request  was  sent 
recently, e.g., if one queried “aa” recently, and types “ab” in 
the search box, there  will be  no request  for the  suggestion 
for “a”. However, the input here is still identifiable from the 
sizes  of  the  suggestions  for  multiple  letters,  e.g.,  “aa”  and 
201
“ab”  can  be  determines  from  26×26  2-letter  combinations,  
even if “a” does not produce any traffic. In reality, Google’s 
caching is seldom in effect: it disappears if the user enters 
the next query on the current query’s result page (as oppose 
to always entering queries on Google’s homepage), because 
the auto-suggestion request contains the current query word, 
which avoids cache hits. Bing does not cache queries.  
V.  CHALLENGES IN MITIGATING SIDE-CHANNEL THREATS 
We  have  demonstrated  the  gravity  of  the  information 
leaks in today’s web applications. This section analyzes the 
challenges  in  addressing  these  vulnerabilities  in  real-world 
scenarios.  We  found  that  mitigation  of  such  side-channel 
threats is much more difficult than it appears to be, as such 
an  effort  often  needs  to  be  application-specific,  which 
means that developers must first identify the vulnerabilities 
in individual applications, and then think of their remedies. 
Identifying  the  vulnerabilities  is  challenging,  as  suggested 
by the examples in Section IV: developers need to analyze 
the  specific  program  structures  related  to  state  transitions, 
and even semantically understand how the applications are 
used in various administrative environments.  
One may wish that there is a “universal” mitigation so 
that  we  can  fix  the  vulnerabilities  without  finding  them. 
Section V.A assumes that developers do not know where the 
vulnerabilities  are,  but  use  application-agnostic  mitigation 
approaches. We show that such  mitigations are unlikely to 
be  applied  in  reality  due  to  the  uncertainty  of  their 
effectiveness  and  the  significant  network  overhead  they 
incur.  This finding urges an in-depth rethinking of the way 
today’s web applications are developed.  
A.  Evaluations of Application-Agnostic Mitigations 
packets, 
information.  Padding 
It  is  easy  to  conceive  high-level  strategies  for  hiding 
side-channel 
faking 
superfluous  (noise)  packets,  chopping  packets  into  fixed-
size segments and merging/splitting application states are all 
reasonable (and well-known) strategies. However, this does 
not  necessarily  imply  that  effectively  deploying  these 
strategies in real application scenarios is also easy. We can 
draw  an  analogy  from  the  buffer  overrun  problem  here: 
everyone understands the high-level strategy – buffer sizes 
should be correctly checked. However, how to check every 
vulnerable  buffer 
is  non-trivial, 
advanced  technologies  need  to  be  developed  and  applied, 
such  as  static  analyses,  type-safe  languages,  address  space 
layout randomization, control-flow integrity protection, etc.  
Regarding the side-channel leak problem, we focus the 
discussion  of  this  section  on  the  feasibility  of  finding 
universal  mitigation  policies  that  are  both  effective  and 
agnostic to individual web applications. This examination is 
crucial because if  we have  such policies, the problem as  a 
whole  can  then  be  solved  without  analyzing  individual 
applications;  otherwise,  the  solutions  inevitably  require 
significant efforts to identify  and analyze vulnerabilities in 
individual applications. 
in  every  application 
Some  side-channel  vulnerabilities  studied  in  prior 
research  indeed  have  universal  mitigations.  For  example, 
Song et al suggested a simple mitigation for the SSH inter-
keystroke timing issue [15], which combines the  strategies 
of  faking  noise  packets  and  merging  states  to  hide  the 
timing characteristics: an SSH client always sends a packet 
every 50-millisecond even when the user types no keystroke 
or  multiple  keystrokes.  This  solves  the  problem  with 
negligible  network  overhead,  while  maintaining 
the 
responsiveness of SSH. Similarly, to solve the side-channel 
issue  of  variable-bit-rate  based  VoIP,  rounding  up  every 
packet  size  to  128-bit  (i.e.,  padding  the  packet  so  that  its 
size is a multiple of 16 bytes) is already very effective [23]. 
Also,  in  [13],  the  authors  suggest  that  setting  video-
streaming to a constant rate would significantly reduce the 
attacker’s ability of inferring movie titles. 
Web  applications,  on  the  other  hand,  are  much  more 
complex  than  SSH,  VoIP  and  video-streaming  in  terms  of 
traffic patterns and semantics. We report here our study on 
how practical to deploy application-agnostic polices, based 
on the analyses of the applications discussed in Section IV. 
Note that unless explicitly denoted, all the packet sizes are 
in bytes, not in bits, in the following discussions.  
1)  On the Mitigation of OnlineHealthA Leaks 
The most promising strategy  that can be applied in an 
application-agnostic manner is padding2.   Here we consider 
two typical padding policies that can expand ambiguity sets: 
rounding  that  rounds  up  the  size  of  every  packet  to  the 
nearest  multiple  of  Δ  bytes,  random  padding  that  appends 
every packet with a padding of random length in [0,Δ). For 
OnlineHealthA,  the  effects  and  the  overheads  of  rounding 
and random padding are essentially the same, as they both 
make  a  packet  of  a  size  x  indistinguishable  from  those 
within the Δ-byte range [(cid:172)x(cid:188)Δ,(cid:170)x(cid:186)Δ)  (rounding)  or [x,x+Δ) 
(random padding),  and on average incur the same overhead 
Δ/2  bytes  per  packet.  Without  loss  of  generality,  here  we 
just describe the analysis of rounding.  
Figure  12  shows  our  measurements  of  attacker’s 
reduction power and network overhead on each different Δ 
value. The network overhead was measured using a scenario 
of a user  working on one task in every one of the 17 top-
level functionalities in OnlineHealthA. The curve for “find-
a-doctor”  was  obtained  when  the  city  name  “South  Bend, 
IN” was used. We also plotted the curves for selection of a 
condition/illness through manual typing or mouse-select. In 
the  mouse-select  scenario,  given  a  Δ  value,  the  reduction 
power  was  calculated  by  identifying  the  conditions  under 
the alphabetic list that became indistinguishable  from each 
other after rounding, and then  merging those conditions to 
measure  the  average  ambiguity-set-sizes  of  individual 
2 Other common mitigation strategies, like adding noise packets, are hard 
to be application-agnostic for web applications. For example, fake packets 
unrelated  to  an  application’s  behavior  are  identifiable  by  comparing  the 
observations from two runs of the application with different inputs. 
conditions. For manual input, we measured the scenario of 
typing  3  or  4  keystrokes  and  selecting  an  item  from  the 
suggestions.    We  observed  that  on  average  the  size  of  the 
suggestion  list  for  a  keystroke  varied  in  a  byte  range  [B, 
B+260].  Different  prefixes  in  the  input  box  correspond  to 
different  B  values.    Let  B  + τ  =  κΔ,  where  τ    and  κ  are 
integers and τ∈[0, 260].  After the rounding, the suggestion 
list  size  can  be  κΔ,  (κ+1)Δ,  …,  (κ+(cid:172)260/Δ(cid:188))Δ.  The  size 
difference  gives  the  attacker  some  information  about  the 
keystroke. In our analysis,  we enumerated all 260 possible 
values  of  τ  to  calculate  the  entropy  reduction  associated 
with  each  τ  value.  The  calculation  showed  that  each 
keystroke leaked 1.41 or 0.724 bit entropy when Δ was 128 
bytes or 256 bytes respectively. Similarly, we calculated the 
entropy reduction of selecting an item on the suggestion list, 
which  was  found  to  be  much  less  significant.  We  plot  the 
manual  input  curves  (3-  and  4-  keystrokes)  by  combining 
the entropy reductions caused by all user actions.  
r
e
w
o
P
n
o
i
t
c
u
d
e
R
1024
256
64
16
4
1
35%
30%
25%
20%
15%
10%
5%
0%
d
a
e
h
r
e
v