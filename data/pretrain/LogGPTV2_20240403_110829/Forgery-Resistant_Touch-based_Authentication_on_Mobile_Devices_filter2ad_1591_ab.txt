tion is a promising authenticator via conducting experiments
with around 30 users for one month in the wild.
However, all these touch-based authentication mechanisms
consider a single universal screen setting (e.g., the default
screen setting) for all users, making them vulnerable to forgery
attacks which collect a user’s touch strokes in the screen set-
ting and program a robot to replay them to attack the au-
thentication system (please see more details in Section 6).
Our work also focuses on users’ strokes, but we leverage
multiple, randomly chosen screen settings.
Common-behavior attacks: Serwadda and Phoha [19]
showed that a Lego robot can be programmed to swipe the
screen of a mobile device, and the stroke recorded by the
screen sensors is as desired. The attacker needs to know the
deﬁning parameters (e.g., start and stop locations) of the
stroke that is to be forged.
Moreover, they proposed that the attacker can simply pro-
gram the robot to replay the common touch behavior of a
large population onto the targeted user’s mobile device, and
they showed that such common-behavior attacks can signif-
icantly increase the EERs. However, they also showed that
their common-behavior attacks have limited success rates for
users whose behaviors are relatively far from the common,
and there are about 20-40% of such users. This means that
touch-based authentication is appropriate to these users. In
practice, touch-based authentication systems can compare
a user’s touch behavior to those of a large population and
recommend if the behavior is far enough from the common
behaviors so that it is resilient to common-behavior attacks.
In this work, we consider stronger forgery attacks in which
the attacker could obtain the targeted user’s touch data.
3. THREAT MODEL
The authentication system is available to the attacker.
The attacker can read and analyze the implementation de-
tails of the authentication system oﬄine. Therefore, if the
authentication system uses a universal screen setting (e.g.,
the default screen setting) for all users, the attacker can
obtain this setting via oﬄine code analysis. However, we
assume that the attacker cannot obtain the dynamic behav-
iors of the authentication system that runs on the targeted
user’s mobile device. For instance, the attacker cannot know
the current setting used by the authentication system if it
is randomly sampled in random time intervals. This is be-
cause reading out the current settings at runtime requires
high privileges (e.g., root access to the operating system)
and an attacker that has already obtained such high privi-
leges already compromised the system.
We assume the attacker has a commercialized programmable
robot (e.g., a Lego robot), which can be used to forge touch
strokes and play them on mobile devices. For instance, Ser-
wadda and Phoha [19] showed how to program a Lego robot
to forge touch strokes to have desired features. We note that
an intelligent robot which is equipped with specialized sen-
sors could potentially detect the current screen setting used
by our authentication system using advanced computer vi-
sion algorithms. However, the attacker might not have such
a specialized robot, and thus, in this work, we consider state-
of-the-art commercialized robots, with which the attacker
cannot infer the current screen setting.
We consider two general forgery attacks depending on
whether the attacker obtains touch strokes of the targeted
user or not. We will discuss more advanced targeted attacks
such as training a human attacker in Section 7.
Random attacks:
In this scenario, the attacker does not
obtain touch strokes of the targeted user. For instance, this
could be the case in which the targeted user lost the device
and it is found by a random attacker, who does not know the
targeted user and does not have its touch strokes. However,
the attacker could obtain touch strokes of a set of other
users. This is reasonable because 1) the attacker can retrieve
touch strokes from publicly accessible data sets [12, 19], and
2) it is possible that users (intentionally or unintentionally)
install an application (e.g., this application is a fun game
application and does not appear to be malicious) that is
developed by the attacker on their mobile devices and the
application records users’ touch strokes.
After obtaining touch strokes from a set of users in dif-
ferent screen settings, the attacker randomly selects touch
strokes, programs a Lego robot to forge them [19], and uses
the programmed robot to touch the mobile device.
(a) User A, 0.8 Y-
distortion
(b) User B, 0.8 Y-
distortion
(c) User C, 0.8 Y-
distortion
(d) User A, 1.2 Y-
distortion
(e) User B, 1.2 Y-
distortion
(f) User C, 1.2 Y-
distortion
Figure 2: Vertical strokes of three users A, B, and C in two screen settings, which we obtained in our experiments. The
black background simulates the mobile device’s screen while the lines are users’ touch strokes. We observe that users’ touch
behaviors are stable, i.e., the touch behaviors of a user in one setting are closer to those of the user in another setting than
those of other users.
Targeted attacks: In this case, the attacker obtains touch
strokes of the targeted user. For instance, the attacker could
be a “friend” of the targeted user or the targeted user’s cu-
rious spouse, who wants to access the messages sent by the
targeted user or know whom the targeted user has called,
and the attacker convinces the targeted user to use his/her
mobile devices to record the targeted user’s touch strokes.
Again, the attacker programs a robot using the collected
strokes to attack the targeted user. Intuitively, if the authen-
tication system uses an universal screen setting, the attacker
can obtain the targeted user’s strokes in this universal set-
ting, which results in attacks with very high success rates
(see Section 6). Our new authentication mechanism uses
multiple screen settings in which a user’s touch behavior is
diﬀerent, and we randomly sample one of the screen settings
in each time interval. Given enough settings, our system can
signiﬁcantly decrease the success rates of targeted attacks
even if the attacker obtains the targeted user’s touch strokes
in all screen settings. This is because the attacker cannot
know the screen setting used by our authentication system
at the time of attack, and thus the attacker does not know
which strokes should be used to program the robot. There-
fore, the attack is reduced to randomly guessing a setting s,
but replaying strokes collected in s passes the authentication
with much lower probabilities if s is not the current setting
used by our authentication system. We note that we do not
consider attacks with advanced robots to automatically infer
the screen setting in this work.
4. STABILITY AND SENSITIVITY
Before introducing our adaptive touch-based continuous
authentication system, we introduce two key observations
that inspire the design of our authentication system.
Stability and sensitivity: A user’s touch behaviors in two
screen settings are said to be stable if the touch behaviors
of the user in one setting are closer to those of the user in
the other setting than those of other users in both settings.
Moreover, a user’s touch behaviors in two settings are said to
be sensitive if they have a high degree of separability in the
feature space. Figure 1 illustrates the possible outcomes for
two settings sa and sb. Intuitively, a user’s touch behaviors
in two settings become more stable and less sensitive when
the two settings are closer.
We ﬁnd that there exists screen settings across which a
user’s touch behaviors are both stable and sensitive. For
instance,
in our experiments (see Section 6), two of the
screen settings we consider are 0.8 Y-distortion and 1.2 Y-
distortion, respectively. Figure 2 shows vertical touch strokes
of three users in the two settings; it is visually noticeable
that their behaviors are stable.
Note that a vertical stroke could be an up stroke or a down
stroke, which corresponds to scrolling up or scrolling down,
respectively. Figure 3 contrasts the start locations (i.e., start
y) and stop locations (i.e., stop y) in the vertical direction
(i.e., Y axis) of up strokes. We ﬁnd that their touch behavior
are also sensitive. User A (or B) starts touch strokes at
similarly low y locations in both settings. However, in the
(a) User A
(b) User B
(c) User C
Figure 3: Start locations vs. stop locations in the vertical direction of up strokes in two screen settings of the three users.
We ﬁnd that their touch behaviors are also sensitive, i.e., a user’s touch strokes in diﬀerent settings have a high degree of
separability in the feature space.
screen setting of 0.8 Y-distortion, the strokes interpreted by
the application are shorter than the strokes inputed by the
user on the screen, and thus the user automatically stops the
touch strokes at higher (i.e., larger) y locations, which makes
the strokes on the screen longer. User C might subliminally
notice the diﬀerent screen settings, and she tends to start
and stop the touch strokes at higher y locations with 0.8
Y-distortion.
Implications: On one hand, stability implies that models
trained in any setting of one user will always be distinguish-
able from models trained for other users, clearly separating
individual users with high probabilities. This property is
needed to successfully authenticate a speciﬁc user. On the
other hand, if we learn a model to distinguish a user’s touch
behaviors from other users’ in a single setting, then forgery
attacks that replay the targeted user’s strokes collected in
other settings can still succeed with high probabilities.
Sensitivity implies that we can train a model to distinguish
a single user’s touch behaviors in one setting from those in
other settings, which makes it possible to defend against tar-
geted attacks. Speciﬁcally, when our authentication system
uses a setting s, the attacker would fail to pass the authen-
tication with much higher probability if the attacker forges
attacks using the targeted user’s strokes collected in settings
other than s.
5. ADAPTIVE AUTHENTICATION
Our touch-based authentication system consists of two
phases: the registration phase and the authentication phase.
The authentication system learns user characteristics during
the registration phase and enforces these learned character-
istics during the authentication phase.
5.1 Registration phase
Figure 4 illustrates the registration phase. Suppose u is a
new user. First, we sample n screen settings across which u’s
touch behaviors are both stable and sensitive. In practice,
we can evenly divide the range of possible screen settings
into m bins, and choose the centers of the n bins that are
randomly sampled. We denote the set of sampled settings
as S(u).
We distinguish two types of strokes: horizontal and verti-
cal, which correspond to scrolling horizontally and scrolling
Figure 4: Registration phase.
vertically, respectively. The two types of strokes have dif-
ferent features, e.g., the directions of the end-to-end lines
corresponding to the strokes. This categorization could en-
able us to enhance the performance of the system. For each
setting s ∈ S(u), we collect a set of touch strokes for each
type t (denoted as T (u, s, t)) from u via ﬁxing the screen
setting to be s. Then we extract a set of features from each
stroke. We adopt the features that are proposed by Frank
et al. [12]. The extracted features are subsequently sent to
the server. We send features to the server instead of the
raw strokes to mitigate the loss from a server compromise.
In particular, if we send raw strokes to the server and it
is compromised, the raw strokes are easily available to at-
tackers. This is similar to the scenario where passwords are
available to attackers when a password database is compro-
mised [15, 8]. However, even if the server is compromised
and the features are available to attackers, it is unclear how
to forge touch strokes that have these features.
Second, we leverage machine learning techniques to train
a classiﬁer for each setting and each stroke type. Speciﬁ-
cally, for each setting s ∈ S(u) and a stroke type t, we take
the features of the corresponding strokes collected in the set-
ting s (i.e., T (u, s, t)) as positive examples, and features of
type-t strokes collected in all other settings (i.e., T (u, s(cid:48), t)
for all s(cid:48) ∈ S(u) − {s}) and features of type-t strokes of all
users that have already adopted the system as negative ex-
amples. Then we learn a classiﬁer c(u, s, t) to distinguish
these positive and negative examples. Therefore, we obtain
2n classiﬁers for the user. The model parameters of these
classiﬁers are then sent back to the user.
−70−60−50−40−30−20−100starty−100−90−80−70−60−50−40−30stopy 0.8 Y-distortion1.2 Y-distortion−80−70−60−50−40−30−20starty−90−85−80−75−70−65−60−55−50−45stopy0.8 Y-distortion1.2 Y-distortion−80−70−60−50−40−30−20−100starty−100−90−80−70−60−50−40stopy0.8 Y-distortion1.2 Y-distortionFeaturesModels21UserServerTable 1: Notations of the ﬁve screen settings, which are
distortions along either the X axis or the Y axis.
sa
0.8
sb
0.9
sc
1.0
sd
1.1
se
1.2
5.2 Authentication phase
Our adaptive continuous authentication method works on
discrete time intervals. In each time interval, we sample a
setting s from S(u) uniformly at random and change the
screen setting to be s. If the user inputs a stroke with type
t, we authenticate the stroke using the classiﬁer c(u, s, t).
Intuitively, our authentication method can signiﬁcantly
decrease the success rates of targeted attacks. In the worst
case, the attacker obtains a set of touch strokes of the user
in all settings in S(u) and can replay these touch strokes
via programming a robot. However, the attacker cannot
know which setting is randomly sampled in a given time
interval, and thus the attack is reduced to randomly guess
a setting and program a robot to replay strokes collected in
the setting. Due to the sensitivity of users’ touch behaviors,
these forged strokes will be rejected with high probabilities.
Note that previous work [12, 13] uses a ﬁxed universal
setting for all users, and thus their authentication systems
can be breached if the attacker obtains the targeted user’s
touch strokes in this hard-coded setting. Moreover, we show
(in Section 6) that even replaying the touch strokes of the
targeted user collected in a diﬀerent setting can still breach
their authentication system with high success rates because
of the stability of users’ touch behaviors.
A user’s behavior is relatively stable over time. For in-
stance, Frank et al. [12] showed that the median EER in-
creases by only 4% when their classiﬁers are used one week
after the registration phase. However, in practice, to account
for behavior variety in a longer period of time, we could peri-
odically (e.g., each month or quarter) execute a registration
phase to update classiﬁers. This is feasible since the regis-
tration phase takes a short period of time as we will show
in our experiments.
6. EXPERIMENTS
We evaluate the security of our new touch-based authen-
tication system against forgery attacks and compare it with
previous touch-based authentication systems.
6.1 Data collection
We consider ﬁve screen settings: 0.8, 0.9, 1.0, 1.1, and 1.2
distortions along either the X or Y axis, and we denote them
as sa, sb, sc, sd, and se, respectively. Table 1 shows the no-
tations of the ﬁve screen settings. We choose these settings
because they are reasonably separable from each other so
that a user’s touch behaviors are sensitive, yet transitions
between them are still unnoticeable to users.
We aim to collect horizontal strokes and vertical strokes in
the ﬁve screen settings. Moreover, we want to study if tran-
sitions between screen settings can be performed without
users noticing them. To achieve these goals, we implemented
an Android application with two games to record users’ raw
touch data. Our application uses an Android API to conﬁg-
ure screen settings. Moreover, we implemented a library to
intercept the raw touch data. Considering user fatigue, the
ordering of the two games is shuﬄed uniformly at random.
(a) Task 1
(b) Task 2
Figure 5: (a) The game used in the task 1; the user must
swipe horizontally. The image itself is available under the