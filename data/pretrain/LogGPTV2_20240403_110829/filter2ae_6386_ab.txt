we don't have to worry about whether Python is a pseudo-thread.
The simplest of the multithreaded models is the producer/consumer model, which
starts multiple threads to consume a queue together. Create a new
`lib/threads.py`
    import threading
    import time
    def exception_handled_function(thread_function, args=()):
        try:
            thread_function(*args)
        except KeyboardInterrupt:
            raise
        except Exception as ex:
            print("thread {0}: {1}".format(threading.currentThread().getName(), str(ex)))
    def run_threads(num_threads, thread_function, args: tuple = ()):
        threads = []
        # Start multiple threads
        for num_threads in range(num_threads):
            thread = threading.Thread(target=exception_handled_function, name=str(num_threads),
                                      args=(thread_function, args))
            thread.setDaemon(True)
            try:
                thread.start()
            except Exception as ex:
                err_msg = "error occurred while starting new thread ('{0}')".format(str(ex))
                print(err_msg)
                break
            threads.append(thread)
        # Waiting for all threads to finish
        alive = True
        while alive:
            alive = False
            for thread in threads:
                if thread.isAlive():
                    alive = True
                    time.sleep(0.1)
It's worth noting that we didn't use the `join()` recommended in the Python
thread to block the thread, because with `join()`, python will not be able to
respond to user-entered messages, causing Ctrl+C to exit. There is no
response, so the thread is blocked in a while loop.
Then the main program is transformed into a multi-threaded mode, and the
"consumer" in the original `start()` is extracted and used as a function
alone, and the data can be received by the queue. As follows:
    def worker():
        if not WORKER.empty():
            arg, poc = WORKER.get()
            try:
                ret = poc.verify(arg)
            except Exception as e:
                ret = None
                print(e)
            if ret:
                print(ret)
    def start(config: dict):
        url_list = config.get("url", [])
        # producer
        for arg in url_list:
            for poc in POCS:
                WORKER.put((arg, poc))
        # comsumer
        run_threads(10, worker)
In addition, the number of threads is configurable and we change it to read
from the configuration.
    run_threads(config.get("thread_num", 10), worker)
Run it again and you will find it much faster than before!
## Network request
This is the last part of our entire framework, how to unify network requests.
Sometimes we need to make the settings of the proxy, UA header, etc. in the
network request sent by our PoC framework, which requires our framework to
handle it uniformly. Before we can achieve our goal, we also need to make an
agreement in the framework, agree that our network requests need to use
`requests` to send packets. At the beginning we said that we will try not to
use third-party modules, but the `requests` module is so good that we exclude
it...
The dynamic mechanism of the Python language, we can easily hook it before
using a function, and redirect its original method to our custom method, which
is a prerequisite for us to unify the network request.
    def hello(arg):
        return "hello " + arg
    def hook(arg):
        arg = arg.upper()
        return "hello " + arg
    hello = hook
    print(hello("aa"))
By hooking a function to achieve our own purpose.
Tools like sqlmap are based on Python's built-in `urllib` module, but a lot of
code is being processed in network requests, and even to handle the `chunked`
issue, hooks rewrite the lower-level `httplib` library.
In order to uniformly schedule network requests, pocsuite hooks the related
methods of the `requests` module. We can refer to the code in detail.
The `pocsuite3/lib/request/patch/__init__.py` code clearly illustrates the
hook function.
    from .remove_ssl_verify import remove_ssl_verify
    from .remove_warnings import disable_warnings
    from .hook_request import patch_session
    from .add_httpraw import patch_addraw
    from .hook_request_redirect import patch_redirect
    def patch_all():
        disable_warnings() 
        remove_ssl_verify()
        patch_session()
        patch_addraw()
        patch_redirect()
If you look at the source of the requests, you will know that the focus is on
how it hooks the seesion function.
`pocsuite3/lib/request/patch/hook_request.py`
    from pocsuite3.lib.core.data import conf
    from requests.models import Request
    from requests.sessions import Session
    from requests.sessions import merge_setting, merge_cookies
    from requests.cookies import RequestsCookieJar
    from requests.utils import get_encodings_from_content
    def session_request(self, method, url,
                        params=None, data=None, headers=None, cookies=None, files=None, auth=None,
                        timeout=conf.timeout if 'timeout' in conf else None,
                        allow_redirects=True, proxies=None, hooks=None, stream=None, verify=False, cert=None, json=None):
        # Create the Request
        merged_cookies = merge_cookies(merge_cookies(RequestsCookieJar(), self.cookies),
                                       cookies or (conf.cookie if 'cookie' in conf else None))
        req = Request(
            method=method.upper(),
            url=url,
            headers=merge_setting(headers, conf.http_headers if 'http_headers' in conf else {}),
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=merged_cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
        proxies = proxies or (conf.proxies if 'proxies' in conf else {})
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
        resp = self.send(prep, **send_kwargs)
        if resp.encoding == 'ISO-8859-1':
            encodings = get_encodings_from_content(resp.text)
            if encodings:
                encoding = encodings[0]
            else:
                encoding = resp.apparent_encoding
            resp.encoding = encoding
        return resp
    def patch_session():
        Session.request = session_request
It overrides the method of the `session_request` function, which allows you to
customize the information such as our custom headers. The above code may
require you to read the requests to understand him, but it doesn't matter, we
can use it directly in the spirit of takership.
In order to achieve this and better optimize the framework, we also need to
make some minor adjustments.
Create a new `lib/requests.py`
    from lib.data import CONF
    from requests.models import Request
    from requests.sessions import Session
    from requests.sessions import merge_setting, merge_cookies
    from requests.cookies import RequestsCookieJar
    from requests.utils import get_encodings_from_content
    def session_request(self, method, url,
                        params=None, data=None, headers=None, cookies=None, files=None, auth=None,
                        timeout=None,
                        allow_redirects=True, proxies=None, hooks=None, stream=None, verify=False, cert=None, json=None):
        # Create the Request.
        conf = CONF.get("requests", {})
        if timeout is None and "timeout" in conf:
            timeout = conf["timeout"]
        merged_cookies = merge_cookies(merge_cookies(RequestsCookieJar(), self.cookies),
                                       cookies or (conf.cookie if 'cookie' in conf else None))
        req = Request(
            method=method.upper(),
            url=url,
            headers=merge_setting(headers, conf["headers"] if 'headers' in conf else {}),
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=merged_cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
        proxies = proxies or (conf["proxies"] if 'proxies' in conf else {})
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
        resp = self.send(prep, **send_kwargs)
        if resp.encoding == 'ISO-8859-1':
            encodings = get_encodings_from_content(resp.text)
            if encodings:
                encoding = encodings[0]
            else:
                encoding = resp.apparent_encoding
            resp.encoding = encoding
        return resp
    def patch_session():
        Session.request = session_request
Also reserve the request interface in config
And execute our hooks when init.
Let's write a new PoC and use this site to test the final effect
`pocs/poc.py`
    import requests
    def verify(arg, **kwargs):
        r = requests.get(arg)
        if r.status_code == 200:
            return {"url": arg, "text": r.text}
The effect is very good, but if you add https website, there is a warning
message.
Also refer to the Pocsuite method to disable the warning information.
    from urllib3 import disable_warnings
    disable_warnings()
Finally, change the version number to `0.1`, and the framework part of AirPoc
is generally completed.
## At last
Many of AirPoc's structural ideas are come from Pocsuite. If you read Pocsuite
directly, you may get a lot of things. At present, the AirPoc v0.1
infrastructure has been almost completed, and one or more PoCs can be loaded
locally for batch testing. Later, we are trying to play some more fun,eg: how
to verify the situation without echo, how to generate shellcode, and how to
operate the shell back, so stay tuned for the next section~zzzzz.
Download AirPoc: 
## About Knownsec & 404 Team
Beijing Knownsec Information Technology Co., Ltd. was established by a group
of high-profile international security experts. It has over a hundred frontier
security talents nationwide as the core security research team to provide
long-term internationally advanced network security solutions for the
government and enterprises.
Knownsec's specialties include network attack and defense integrated
technologies and product R&D under new situations. It provides visualization
solutions that meet the world-class security technology standards and enhances
the security monitoring, alarm and defense abilities of customer networks with
its industry-leading capabilities in cloud computing and big data processing.
The company's technical strength is strongly recognized by the State Ministry
of Public Security, the Central Government Procurement Center, the Ministry of
Industry and Information Technology (MIIT), China National Vulnerability
Database of Information Security (CNNVD), the Central Bank, the Hong Kong
Jockey Club, Microsoft, Zhejiang Satellite TV and other well-known clients.
404 Team, the core security team of Knownsec, is dedicated to the research of
security vulnerability and offensive and defensive technology in the fields of
Web, IoT, industrial control, blockchain, etc. 404 team has submitted
vulnerability research to many well-known vendors such as Microsoft, Apple,
Adobe, Tencent, Alibaba, Baidu, etc. And has received a high reputation in the
industry.
The most well-known sharing of Knownsec 404 Team includes: [KCon Hacking
Conference](http://kcon.knownsec.com/ "KCon Hacking Conference"), [Seebug
Vulnerability Database](https://www.seebug.org/ "Seebug Vulnerability
Database") and [ZoomEye Cyberspace Search Engine](https://www.zoomeye.org/
"ZoomEye Cyberspace Search Engine").
* * *