Cybercriminals are able to exploit and take control of large
numbers of vulnerable web sites. However, most of these web
sites are likely to be part of the “long tail” of the web, and are
visited by a very small numbers of users. Therefore, drive-by
attacks injected into these websites would only reach a small
pool of potential victims. To reach more users, cybercriminals
use a variety of techniques to drive trafﬁc to the malicious
pages under their control. Unsurprisingly, these include the
use of blackhat Search Engine Optimization (SEO) techniques
to increase the ranking of malicious pages in search engine
results for popular search terms.
According to a report by Trend Micro [24], SEO techniques
have been exploited to spread malware since at least November
2007. More recently, attackers started deploying SEO kits that
are able to automatically generate “rings” of pages optimized
for currently popular search topics [25]–[28]. An SEO kit is
typically a PHP script installed on a compromised web server.
It includes functionality to fetch currently popular search
terms from sources such as Google trends or Twitter trends.
Furthermore, given a search topic, it makes use of a search
engine to obtain text and images relevant to the topic, and
it automatically generates web pages from this raw material.
SEO kits also use several techniques to increase ranking, such
as generating a large number of doorway pages linking to an
optimized page, or using link exchanges between pages on
different exploited sites. Another common characteristic of
SEO kits is the use of semantic cloaking [29], [30]. That is,
the exploited web sites respond with completely different
content depending on the source of a request. Based on
information such as the source IP address of the request and
the User-Agent and Referer HTTP headers, attackers
may attempt to provide a benign, SEO optimized page to
search engine crawlers, a malicious page to end users, and a
benign page to security researchers and analysis tools.
Several characteristics of large-scale, automated blackhat
SEO campaigns make it possible for EVILSEED to discover
other malicious SEO-optimized web sites starting from a URL
that is part of such a campaign.
• Attackers host many different web pages, optimized for
different search terms, on each web site in a campaign.
• Attackers host pages optimized for the same search terms
on different web sites in a campaign.
• Pages in a campaign often link to each other.
433
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:16 UTC from IEEE Xplore.  Restrictions apply. 
These characteristics are a consequence of the fact that
attackers want to make the best use of the available resources
(a ﬁnite number of compromised web sites) to obtain a high
search ranking for a wide variety of popular search terms.
Seed. As a starting point, the EVILSEED SEO gadget needs at
least one malicious URL that is part of an SEO campaign. To
identify likely blackhat SEO URLs, we use a simple cloaking
detection heuristic. The idea is that a malicious page that
provides different content to search engine bots and to end
users is likely trying to manipulate search engine rankings.
Detecting semantic cloaking and distinguishing it from
syntactic cloaking [31], as well as from normal variation
of web content over time, is itself not a trivial problem. In
this work, we use a simple cloaking detection heuristic that
is limited to detecting redirection-based cloaking, because
this form of cloaking is frequently used in blackhat SEO
campaigns. Research into more sophisticated cloaking detection
techniques [29], [30] is orthogonal to this work, and it would be
straightforward to integrate such techniques into our prototype.
To detect cloaking, we visit a URL three times, providing
different values for the User-Agent and Referer HTTP
headers. First, we visit the URL as a user that has reached
the site from Google. For this, we use the User-Agent
of a popular browser, and a Referer header corresponding
to a Google search query. Then, we visit the URL with no
Referer header, emulating a user who directly typed the
URL into her browser’s address bar. Finally, we visit the URL
emulating the behavior of Google’s indexing bot. For this, we
rely on GoogleBot’s well-known User-Agent string. We follow
HTTP redirections and consider the ﬁnal “landing” domain
from which the browser receives a successful (2xx) HTTP
response. We detect cloaking if, during the three visits to a
URL, we observe two or more different landing domains.
Furthermore, since blackhat SEO campaigns are known
to target popular searches obtained from Google and Twitter
trends, we extend the seed for this gadget by fetching Google
and Twitter trends, querying Google for the resulting topics,
and checking the returned URLs with our cloaking detection
heuristic.
Expansion. Once we have identiﬁed at least one cloaked,
malicious URL, we can attempt to locate other URLs in the
same blackhat SEO campaign. For this, we use a number of
techniques to identify additional candidate URLs. First of all,
for each domain hosting a cloaked, malicious web site, we
perform a Google query using the site: modiﬁer to locate
other pages on that domain. We fetch the query results and
add them to the set of candidate URLs. This allows us to ﬁnd
other malicious pages on the same site that may have been
optimized for different search terms. Furthermore, we follow
links in the malicious cloaked pages. Speciﬁcally, we consider
the version of the page that was served to us when we surfed
the page emulating the Google indexing bot, and consider any
external links contained in that page. We add the target URLs
of these links to the candidate URLs.
Finally, we try to identify the search terms for which a page
has been optimized. For this, we do not take into account
the content we downloaded from the URL. Instead, we rely
exclusively on information provided by Google about that
URL as part of its search results. The reason is that we cannot
be certain that we have been able to deceive the malicious
website into sending us the content intended for search engines
(some SEO kits include a hard-coded list of search engine
bot IP addresses, and perform IP-based cloaking [25]). Using
Google’s results allows us to sidestep this problem, and obtain
a subset of the page as it was delivered to Google’s bot. The
information provided by Google consists of the page title and
a number of snippets of the page’s content. This information is
typically shared between many pages in a SEO campaign [28].
The SEO gadget simply extracts the title of the page, and
queries Google for the set of words in the title. The results of
the query are then fetched and added to the candidate URLs.
D. Domain Registrations Gadget
Blacklists are one of the most widespread techniques to
protect users against web malware. In a domain-based blacklist,
a domain is added to the list as soon as it is discovered to
host malicious content. As a countermeasure, cybercriminals
are known to serve their content from short-lived domains,
frequently switching domains to maximize the time they
remain unlisted. To run an efﬁcient business in this arms race,
cybercriminals are likely to automate the domain generation
and registration process. This automation leaves behind some
artifacts, giving us some leverage to identify these domains.
More precisely, we assume that registrations that are close in
time to the registration of known malicious domains are also
likely to be malicious.
Seed. The seed used by the Domain Registrations Gadget
consists of all the domains that are known to host malicious
pages, and domain registration records which are freely
available online.
Expansion. This gadget extracts the domain of a malicious
seed URL, and ﬂags the domains that have been registered
before and after as suspicious.
These domains are then used to create URLs that are
scheduled for analysis. The URL creation consists of taking the
closest known malicious registration (for which we know the
corresponding malicious URL), and replacing the domain with
the suspicious domain that we have just ﬂagged. For example, if
a.com has been registered just moments before b.com, and
we know that http://a.com/exploit is malicious, the
gadget will submit for analysis http://b.com/exploit.
Note that this gadget does not leverage search engines
to ﬁnd additional malicious URLs. However, it still follows
EVILSEED’s guided search philosophy.
E. DNS Queries Gadget
The DNS queries gadget analyzes recursive DNS (RDNS)
traces. The goal is to identify the domain names of compro-
mised landing pages that are likely to lead to malicious pages.
434
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:16 UTC from IEEE Xplore.  Restrictions apply. 
likely to be accessed by a web visitor. We consider three cases.
First, a user is likely to access a domain by visiting its home
page, for example, by typing its URL directly in the browser’s
address bar. Second, users may visit pages returned in the
result set of a search query. This set includes highly-ranked
pages from that domain. Finally, a user is likely to follow links
to pages on the candidate domain contained in popular (i.e.,
high-ranking) pages on different domains. (Notice that these
linked-to pages do not necessarily possess a high ranking,
due to mechanisms such as the nofollow attribute value
designed to mitigate the impact of web spam [32].)
Therefore, for each domain Di in the considered time
window, the gadget includes, as candidate URLs, the home
page of the domain and the URLs obtained by querying search
engines for:
• site:Di — top-ranking pages from the candidate
domain Di,
• "http://Di/" -inurl:Di — URLs on Di found
on different sites, including potentially spammed pages.
In our example, the analysis of www.rotarynewalipore.in
shows that it is infected with malicious JavaScript code that
leads to a drive-by-download web page on aquarigger.com.
Discussion and analysis. The DNS queries gadget has a few
limitations. First, the trace analysis is simpliﬁed by ignoring
the effects of caching and pinning of DNS responses performed
by modern browsers. In other words, we assume that whenever
a user browses from L to P , her browser resolves DL and
DP , irrespective of previous visits to these domains. If this
assumption does not hold, our gadget may be unable to locate
landing pages redirecting to the malicious domain. For example,
this occurs if the user ﬁrst visits a page on DL that does not
trigger a redirection to the malicious domain, and then browses
to L after an amount of time that is larger than the window
considered by the gadget, but shorter than the DNS cache
expiration interval used by the browser. However, we argue that
this scenario is unlikely to occur frequently in practice. The
reason is that attackers have incentives to maximize the trafﬁc
to the malicious domain and, therefore, to force a redirection
to the malicious domain on the ﬁrst visit of a page on DL.
Similarly, if the redirection from a landing page to the
malicious page is triggered after a time delay that is longer
than the window considered by our gadget, the gadget will
not be able to identify DL. Also in this case, we argue that
attackers are not likely to introduce such delays. This is because
the delay may allow a signiﬁcant number of users to escape
the attack, for example, by simply navigating away from the
landing page.
Finally, we also assume that trafﬁc to malicious pages is
generated via web-based techniques: clearly, this gadget would
not be effective if links to malicious domain are circulated
via other medium, e.g., by spam emails or instant messages.
We also notice that, like the links gadget, this gadget relies
on the network topology to locate additional malicious web
content. However, unlike the links gadget, the DNS queries
Figure 2. Example DNS trace.
The gadget works in two steps: First, it leverages temporal
relationships in a DNS trace to identify domains that are likely
connected to malicious domains. More precisely, the gadget
checks for queries for domain DL “shortly before” a query for
domain DP , which is known to host malicious pages. Then,
the gadget identiﬁes pages (URLs) on DL that may redirect
their visitors to an evil page P hosted on DP .
Seed. The seed used by the DNS queries gadget consists of
all the domains that are known to host malicious pages.
Expansion. This gadget’s expansion relies on the fact that,
often, a large number of infected pages contain links to
a single, malicious page, and that DNS traces (partially)
expose these connections. In practice, we passively monitor
the recursive DNS trafﬁc generated by a large user base.
This trafﬁc can be collected, for example, by deploying
a sensor in front of the RDNS server of a network. We
assume that a network user, during her regular Internet activity,
will browse to a compromised landing page L (hosted on
DL) that redirects to P , one of the URLs that are part of
our evil seed. This browsing activity appears in the DNS
trace as a sequence of DNS requests issued by the same
client, querying, in a short period of time, for DL ﬁrst, and
for DP later. Note that while we expect that queries for
DL and DP be close in time, in general, they will not be
consecutive. This is because of concurrent network activity on
the user’s machine (e.g., software updates and email checks)
and because of queries needed to fetch additional resources
(e.g., external images and scripts) included by L before the
redirection to P . For example, consider the DNS trace in
Figure 2. The trace shows the DNS requests performed by one
client over time. In this interval, the client visits a web site
(www.rotarynewalipore.in), checks email on hotmail.com, and
performs a system update (windowsupdate.com). The trace ends
with the request of a known malicious domain (aquarigger.com),
which is reached during the web site visit. The gadget scans
the DNS trace for queries about domains in the evil seed.
Whenever one is found, the gadget considers as candidate
domains those domains that were queried by the same client
in the preceding N seconds (in the current implementation,
this window is empirically set
to four seconds). In our
example, the candidate domains are www.rotarynewalipore.in,
mx1.hotmail.com, windowsupdate.com, and doubleclick.net.
Given a set of candidate domains, the gadget generates
URLs from these domains. Of all the possible pages on a
candidate domain, the gadget chooses those that are more
435
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:16 UTC from IEEE Xplore.  Restrictions apply. 
!!!"#$%&#'()!&*+,$#)"+(-.$/0*)1*+12"()%-!"#!$%&&'$()*+,%-3+4+%-!)0-4+%)-5'4%)6-/,.&%)-78)12-6&+*-69:"8$%6&+*"1$6-!+(.$!4/,.&%)"1$6-gadget does not obtain topology information from search
engines. This allows the DNS queries gadget to leverage
network topology information that may not be visible to search
engines. This is a signiﬁcant advantage because attackers
actively try to prevent search engines from indexing (and
possibly detecting) malicious content (e.g., by using semantic
cloaking). Furthermore, this provides more up-to-date results
(the gadget does not need to wait for the search engine crawler
to have updated topological data). Of course, only connections
exposed by the visits of actual users are visible to the gadget.
IV. Evaluation
In this section, we experimentally validate our initial
hypothesis that the guided search approach used in EVILSEED
is effective at locating malicious pages, and it does so in an
efﬁcient manner. We use two key metrics to establish the
effectiveness of our system: toxicity and expansion.
The toxicity is the fraction of the URLs submitted to the
oracles that are, in fact, malicious. Higher values of toxicity
imply that the resources needed to analyze a page (e.g., the
oracle’s CPU and time) are used more efﬁciently.
Seed expansion is the average number of new malicious
URLs that EVILSEED ﬁnds for each seed. Intuitively, the
seed expansion is a measure of the return on the investment
provided by running a certain searching approach: A higher
seed expansion indicates that for each malicious seed URL a
larger number of malicious URLs are found. For example, if
after a day of traditional crawling 100 malicious URLs are
found and, when these URLs are fed to EVILSEED, the system
identiﬁes 150 additional malicious pages, then the expansion
of the system is 1.5.
There is a trade-off between toxicity and seed expansion:
a higher expansion can be obtained at the cost of a lower
toxicity (e.g., starting a traditional crawl, which does not
require any seed). Since EVILSEED is designed to achieve a