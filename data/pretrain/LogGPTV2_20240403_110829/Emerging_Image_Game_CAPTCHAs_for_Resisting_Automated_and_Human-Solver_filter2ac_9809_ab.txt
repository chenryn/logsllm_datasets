segments that may leave clue for reconstructing object contour will
be further split. The pseudo 3D effect for each object is applied
based on current rotation and scaling parameters (Figure 2(d)). The
remaining area in the frame (i.e., the background) is tiled with
segments from foreground objects (Figure 2(e)). Finally, an EI-
based frame (Figure 2(h)) is the Gaussian blur of the combination
of the foreground mask, tiled background, target object mask (Fig-
ure 2(f)), and random noise mask (Figure 2(g)). The details will
be provided in the following subsections. An EI-DCG CAPTCHA
challenge is conﬁgured as follows:
• Dimension: 340(height)×400(width).
• 3 target objects and 5 foreground objects, which are all al-
• Object moving speed: 3 pixels per frame (ppf).
• Frame rate: 40 frames per second (f ps).
• N=40 pairs of foreground and background that record the pixel
value and location of foreground and background objects in
phanumeric characters.
13
challenge, a codeword moves horizontally from the right side of
background to the left at a constant speed. Each character in the
codeword also moves up and down harmonically, rotates slightly
such that neighbor characters overlap each other to some extent.
Thus, we argue that 2D movement as described above may not
be sufﬁcient to prevent the reconstruction of the object contour
through accumulating information from consecutive frames. First,
we demonstrate how much information is exposed in consecutive
frames. Given three consecutive frames (Figure 5(a)), we converted
them into color code representation [13], which replaces a pixel
value with a 6-bit color value ([0,63]) consisting of the highest two
bits from each 8-bit RGB channel. The color code can help group
pixels with similar colors into the same code, facilitating the bi-
narization process. We converted all pixel values in a color code
representation that are less than or equal to an empirical threshold
(e.g., 21) to white (Figure 5(b)), and black otherwise. Since the
primary moving direction is from right to left, during superimposi-
tion, the (i+2)-th frame is shifted right 1 pixel, while the i-th frame
is shifted left 1 pixel, before they are superimposed on the (i+1)-
th frame. The superimposition of three binary masks as shown in
Figure 5(c) exposes a large portion of codeword contour. More-
over, removing the background scene mask from the superimposed
mask is technically possible and could further increase the accuracy
of codeword contour detection.
Second, the orientation difference of a character in 2D space be-
tween two consecutive frames is small. If such rotation degree per
frame is large, say 10 degrees per frame and the frame rate is 30
fps, the character will rotate 150 degree in 0.5 second, in which
case even a human can barely recognize the character. Therefore,
the 2D rotation of a character between consecutive frames cannot
be too large, thereby making it possible to accumulate contour in-
formation through superimposition of consecutive frames
In our EI-DCG CAPTCHA design, therefore, we propose to im-
plement a pseudo 3D effect that includes 3D rotation and scaling
for each moving object in order to hinder information accumulation
from superimposition. First, the 2D mask of an object is extracted
from the EI-based foreground mask (Figure 3(f)). Second, the 2D
matrix (the mask) is projected into 3D, in which the X-axis and
Y-axis are consistent with the previous axes in 2D, while Z-axis
represents the viewer’s direction. Third, a degree of rotation is ap-
plied to each of the X-, Y-, and Z-axis, respectively. In the end, the
3D geometry is projected back into 2D. Meanwhile, the focal dis-
tance is tuned in the projection matrix to scale up/down the object
in the current frame.
In our design, the rotation range in degree around X-, Y-, and
Z-axis are [-40,40], [-60,60], and [-40,40], respectively. The ro-
tation speed (degrees perf rame) is determined by the equation
r = (2 × rotation_range)/N, where N is the number of pairs
of foreground and background as mentioned in Section 2. There-
fore, the object rotates around a speciﬁc axis from one side to the
other, and then back within N rounds. The object also scales up
and down between 100% and 184% with a changing speed calcu-
lated in the same way as the rotation speed. On top of all that, there
is no primary moving direction in our design - each object moves
in their own random direction.
To examine the resilience of
the above mechanisms to
superimposition-based information recovery, we screen-captured
three consecutive frames of an EI-DCG CAPTCHA challenge
without background or target objects, converted them into binary
masks, and showed the captured object contour through superimpo-
sition of two and three masks, respectively. As shown in Figure 6,
unlike the result in Figure 5(c), none of the superimposition masks
expose long segments that are part of the object contours. We can
Figure 3: Generating an EI-DCG CAPTCHA frame.
Figure 4: (a) EI-based foreground mask of character “5”. (b) Split and erosion on
large or long segments, (c) followed by a small rotation and translation. To highlight
the changes, we show the original segments in gray in (b) and (c).
the degree of temporal continuity. The swap operation preserves
the current Gaussian distribution in Ibg.
3. We create an image I (Figure 3(c)) by combining both the
foreground weight mask If g_w and the noise image Ibg using
the equation I(x, y) = Ibg(x, y) × exp(If g_w/const), where
exp(x) is the exponential function. In our design, const is set as
0.6. According to this, pixels with smaller Ibg values are more
likely to appear as black pixels. Therefore, the swap operation
in Step 2 makes common pixels more likely to be displayed as
black again in the current frame.
4. We generate the binary mask Bf g for foreground objects
through binarizing I by setting all the pixels whose values
are greater than a user-deﬁned threshold t < 0 (e.g., -0.5) to
‘white’, and the remaining pixels to ‘black’ (Figure 3(d)).
5. We generate the EI-based foreground mask Ef g by removing
all the black pixels in Bf g that are not on the foreground edge
mask If g_e (Figure 3(e)) such that only those black segments on
the object edges remain in the binary mask (Figure 3(f)).
Large segments in the foreground mask may raise a potential risk
of exposing object contour. Therefore, we apply a post-processing
including split, erosion, and random rotation and translation on seg-
ments that have area larger than a threshold tarea or their major axis
is longer than tmaxis (Figure 4). The values of tarea and tmaxis
are determined by the current object size. For a large or long seg-
ment, the split point is selected as a random point between 1/3 and
2/3 along the major axis that crosses the center of the segment. Fur-
ther erosion is applied on the split segments, followed by a small
random rotation and translation to further disrupt the continuity be-
tween nearby edge segments.
3.3 Pseudo 3D Visual Effect
Taking a closer look at EI-Nu CAPTCHA challenges, we learned
that accumulating information from consecutive frames could pos-
sibly recover object contours, especially when the primary moving
direction of foreground objects is known. In an EI-Nu CAPTCHA
14
Figure 5: Reconstructing the codeword “7FX”. (a) 3 consecutive frames of an EI-Nu
CAPTCHA challenge. (b) Binary mask of each frame. (c) Superimposition of three
consecutive frames.
Figure 6: Effect of 3D rotation and scaling on superimposed masks. Objects from
left to right: “5”, “X”, and “Z”. (a) Binary masks. (b-c) Superimposition of 2 and 3
consecutive masks.
expect that with the addition of background, the superimposition
mask will only get noisier.
3.4 Background Tiling
We further identiﬁed several key requirements for effectively
camouﬂaging foreground objects in EI-based background.
1. Any subarea of a background should look visually similar to
the foreground objects. If long or large segments exist in an
EI-based foreground mask, similar segments will also be repli-
cated multiple times in the background. Thus even an exhaus-
tive search in a screen-captured frame based on known object
templates will returns multiple candidates, while only one of
them may be the real object.
2. Ideally, any subarea in the background should also have similar
density as the foreground objects, so that the location of mov-
ing objects can be better camouﬂaged since there is no density
anomaly across the whole frame.
3. The background should be tiled, i.e. ﬁlled, in a way that
can hide objects in the superimposed mask of consecutive
frames. One reason that EI-Nu CAPTCHA is vulnerable to
superimposition-based attack (Figure 5(c)) is because its back-
ground is sparsely and unevenly tiled. To introduce the maxi-
mum noise into the superimposed mask, we tile the entire back-
ground (except the areas occupied by foreground objects) with
segments that exhibit similar density as foreground objects, and
thus no prominent subarea that may correspond to foreground
objects can be easily identiﬁed.
To meet the above requirements, we tile the background using the
same idea of the EI video [11] but in a different way of selecting
the tile segments and tiling.
Determining the Tile Size: Similar to the original EI, we use the
subparts of foreground objects to tile the background. If the tile
size is too big, more complete object contour information may be
exposed at multiple locations in a frame. And, the larger the tile,
the sparser the scene becomes, leaving fewer object candidates in
a single frame, leading to less guess work for automated attack.
For the same reason, there is also an increased risk associated with
information recovery from superimposed masks, if a too large tile
size is used. On the other hand, a too small tile size will make
the background too crowded, making the relative sparseness in the
areas of foreground objects more distinguishable, again easing the
auto-attack. Given all the minimum bounding boxes (MBRs) of
foreground objects in a frame, we deﬁne a tile as a square with
size lt = min (dimensions of all MBRs). Assume the size of a
CAPTCHA window is h × w. If there is no overlap in tiling, there
will be totally Nt = f loor(h × w/(lt × lt)) tiles.
Determining the Tile Segment Candidates: A tile mask should
have a similar density as that of the foreground MBR mask. First,
from the mask of each of the K foreground objects in a frame, the
subarea of dimension lt × lt that has the maximum pixel count for
that mask is identiﬁed. The average density dt of these subareas
is used as a reference to extract tile segment candidates in K fore-
ground object masks. Second, tile segment candidates are selected
by searching each subarea of dimension lt × lt in each foreground
object mask that has a density in the range [dt − δ, dt + δ] where
δ is a random value between 0 and 0.1×dt. Each such subarea is a
tile segment candidate, and there are total Nt candidates in a frame.
Determine the Tile Locations: Instead of paving tiles side by side
in a regular grid, we vary the locations of tile centers both hori-
zontally and vertically, such that tiles may overlap or separate from
each other by a small random amount, thereby further randomizing
the segment distribution. Each tile segment candidate obtained in
the previous step is further rotated by a random angle and pasted
in the background anchored to the center of a randomly selected
unpaved tile space.
3.5 EI-DCG Conﬁguration Levels
EI-DCG CAPTCHA is conﬁgured at three levels of potential dif-
ﬁculty for the human user (easy, medium, and difﬁcult), using the
parameter settings in Table 1. The more “difﬁcult” the CAPTCHA
is, the less susceptible it is supposed to be against computer vision-
based auto attack. The pixel density decreases when the difﬁculty
level increases, i.e., decreasing amount of foreground information
embedded in one single frame.
Table 1: Parameters settings used to generate EI-DCG CAPTCHA challenges at easy,
medium, difﬁcult levels.
Threshold
Foreground threshold t
Percentage of hidden edge γ
Gaussian blur (kernel size, std dev)
Easy Medium Difﬁcult
-0.1
0.05
(3, 1)
-0.7
0.1
(2, 1)
-0.5
0.1
(2, 1)
4. AUTOMATED ATTACK RESISTANCE
Emerging images [11] are known to be robust to automatic object
detection using existing image processing and machine learning
techniques. Compared with EI-Nu CAPTCHA (Figure 5), there is
no primary moving direction in our proposed EI-DCG CAPTCHA
challenge, and thus it is difﬁcult to estimate the object moving
speed to compute the shift offset before superimposing consecutive
masks. Therefore, the contour information is well camouﬂaged in
both a single binary mask and a superimposed mask.
One challenge in EI-DCG design is the local density difference
caused by the presence of hollow objects and the white dilation
15
surrounding the moving objects (used to make objects more visu-
ally distinguishable), which may facilitate automated attack. On
one hand, the hollow area and the white dilation area, which ac-
company the moving object in consecutive frames, may remain
white (and thus appear “sparser”) in the superimposed mask, in-
dicating possible presence of foreground objects. Also, due to the
randomness in the layout of background tiles, the local density of
foreground objects in a single frame may occasionally become rel-
atively higher/lower than surrounding areas. In this case, the auto-
mated attack could ﬁrst detect subareas that exhibit such local den-
sity anomalies, randomly pick one of them, and drag it to the target.
Other automated attacks using object detection in computer vision
would be extremely hard, both theoretically and computationally,
if not entirely impossible in this case, due to a lack of presence of
distinct object visual features such as color, gradient, corner points,
edge, or shape, and a lack of prior knowledge of object features.
Therefore, neither feature-based nor apearance-based object detec-
tion would work well, leaving the best hope with an anomaly-based
detection method such as the automated density-based attack that
is also computationally efﬁcient.
To evaluate the robustness of EI-DCG CAPTCHA against such
density-based automated attack, we applied the automated attack to
3 different masks, i.e., single binary mask (single), superimposition
of 3 consecutive masks (3x), and the frequency map of 3 consecu-
tive masks (freq). Our automated attack assumes that the locations
of the target objects are already known (e.g., known via a simple
image-based relay attack). First, a screen-captured frame is con-
verted into a binary mask with the target area removed. Second,
the remaining area (i.e., activity area of moving objects) is divided
into m×m equal-sized subareas (e.g., 40×40 pixels, Figure 7). An
m × m density matrix is created in which each element indicates
the black pixel count of the corresponding subarea. The centroids
of subareas that correspond to local peak or valley elements in the
2D density matrix are treated as the location candidates of moving
objects (Figure 7(a)). Third, the automated attack randomly selects
a location candidate and performs a drag-and-drop operation from
the cell centroid to each of the target objects.
Figure 8: Success rate and number of drag-and-drops in density-based automated at-
tack with ≤50 drag-and-drops for each attack. (a)(c)(e) Success rates by using density
matrices of single, 3x, and freq. (b)(d)(f) The mean and standard deviation of the
number of drag-and-drops to complete an EI-DCG CAPTCHA challenge.
of a black pixel) will be shown as white in the ﬁnal binary mask
(Figure 7(c)). The density matrix of such a binary mask records the
white pixel count in each subarea (2nd row, Figure 7(c)).
We randomly created 100 challenges of EI-DCG CAPTCHAs
corresponding to each difﬁculty level. There are 12 groups of at-
tacks with various parameter settings (Table 2) for each difﬁculty
level. Each group contains 500 attacks on randomly selected chal-
lenges from the corresponding 100-challenge set. Each attack will
perform drag-and-drop at most 50 times (“time out” otherwise). In
our ﬁrst experiment, we set the maximum number of drag-and-drop
attempts allowed to be 21, i.e., each target object will receive ≤7
drops on average, given 3 target objects. This is the threshold pa-
rameter that our EI-DCG CAPTCHA implementation will use in
practice (later in, Section 5, we will demonstrate that such a thresh-
oldization does not have much impact on the usability of solving
EI-DCG challenges by legitimate users).
Table 2: Parameter settings for the density-based automated attack
Parameters
Difﬁculty level
Values
Easy, Medium, Difﬁcult
Density matrix (DM) Single mask, 3x superimposition, Freq. map
Obj. locations (OL)
Grid interval (GI)
Local density peak, Local density valley
40 pixels, 60 pixels
Figure 7: (a-c) Top: single binary mask, superimposition of 3 consecutive binary
masks, and binary mask of frequency map with pixels having the highest possible
frequency (i.e., 3) shown as white. Bottom: density matrix with grid interval as 40
pixels. The red and blue dots indicate local density peaks and valleys, respectively.
A superimposed mask (3x) is generated by superimposing the
current binary mask with its previous two consecutive masks (Fig-
ure 7(b)). The value of a pixel in the frequency map is the number
of times a black pixel appears at that pixel location across the 3 con-
secutive masks. The frequency map is further binarized so that only
those pixels whose value is 3 (the highest possible frequency count
Our result indicates that the success rate for density-based au-
tomated attack is lower than 0.8%, given ≤7 drag-and-drops per
target object on average. Since this attack is based on local density
anomaly, that occurs with randomness, the difﬁculty level is not
necessarily reﬂected in the success rate. This success rate is well-
aligned with the acceptable security level for CAPTCHAs (e.g., as
speciﬁed by Zhu et al. [21]).
Next, we further experiment with ≤50 drag-and-drops in order
to gain more insights. As shown in Figure 8 (a)(c), localizing fore-
ground objects by using local valleys in the density matrix of single
and 3x provides a higher success rate than that by using local peaks.
In a single binary mask (single) or the superimposition of 3 con-
secutive masks (3x), the white dilation area surrounding the mov-
ing object (for highlighting the object) may form relatively sparse
16
subareas (valleys), thereby making the valley-based attacks more
effective than peak-based attacks. On the other hand, since there