title = "CPU steal"
value_threshold="1.0"
name ="cpu_steal"
---
## Page 263
collection_group
collection_group[
metric{
metric
metric
metric
time_threshold=180
collect_every=40
metric
metric
time_threshold= 950
collect_every = 80
title = "Memory Buffers"
value_thresho1d="1024.0"
name ="mem_buffers"
title = "Shared Memory"
value_threshold="1024.0"
name ="mem_shared"
title="Free Memory"
value_threshold="1024.0"
name=
title="Total Processes"
value_threshold="1.0"
name="proc_total"
title = "Total Running Processes"
value_threshold="1.0"
name="proc_run"
"mem_free"
8.8Ganglia简介
253
---
## Page 264
个Hadoop的例子。
大多是二次开发的。
监控软件，那么配置Ganglia也应该不在话下，它并不难。另外Ganglia的基础应用不多，
高性能协调服务之ZooKeeper
第8章
#reducetask.sink.file.filename=reducetask-metrics.out
#maptask.sink.file.filename=
#tasktracker.sink.file.filename=tasktracker-metrics.out
#jobtracker.sink.file.filename=jobtracker-metrics.out
#datanode.sink.file.filename=datanode-metrics.out
#namenode.sink.file.filename=namenode-metrics.out
*,sink.file.class=org.apache.hadoop.metrics2.sink.FileSink
#syntax:[prefix].[source|sinkljmx].[instance].[options]
在所有Hadoop服务器的conf文件夹下，编辑hadoop-metrics2.properties文件如下：
之所以不再介绍Ganglia的配置等操作，是因为以你现在可以配置Cacti、Zabbix这类
include ("/opt/ganglia2/etc/conf.d/*.conf")
See package.html
metric
title="Free Swap Space"
value_threshold="1024.0"
name="swap_free"
title="Cached Memory"
value_threshold="1024.0"
name ="mem_cached"
，因为这方面需根据自己公司的业务开发，这里就不在赘述。
for org.apache.hadoop.metrics2 for details
=maptask-metrics.out
下面举
---
## Page 265
pUsedM=40
dM=both
GangliaSink31
GangliaSink30
dfs.servers=192.168.*.*:8649 192.168.*.*:8649
reducetask.sink.ganglia.servers=192.168.*.*:8649 192.168.*.*:8649
maptask.sink.ganglia.servers=192.168.*,
*.sink.ganglia.dmax=jvm.metrics.threadsBlocked=70,jvm.metrics.memHea
dfs.period=10
dfs.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
#zhh
#dfs.class=org.apache.hadoop.metrics.spi.NullContextWithUpdateThread
tasktracker.sink.ganglia.servers=192.168.*.*:8649 192.168.*.*:8649
jobtracker.sink.ganglia.servers=192.168.*.*:8649 192.168.*.*:8649
datanode.sink.ganglia.servers=192.168.*.*:8649
namenode.sink.ganglia.servers=192.168.*.*:8649
*.sink.ganglia.slope=jvm.metrics.gcCount=zero,jvm.metrics.memHeapuse
*,sink.ganglia.supportsparse=true
*,sink.ganglia.period=10
*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.
#*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.
default for supportsparse is false
Below are
add
for sending metrics to Ganglia
*:8649
192.168.*.*:8649
192.168.*.*:8649
192.168.*.*:8649
8.8
Ganglia简介
255
---
## Page 266
256
地介绍一下Ganglia监控，它也许是一个不错的选择。
目，如图8-19~图8-22所示。
高性能协调服务之ZooKeeper
第8章
相对来说，可能以后你需要整合更多的选项及应用，所以这里不过多说明，只是简单
在所有Hadoop服务器上配置完后，就可以在Ganglia的选项中找到关于Hadoop的项
jvm.servers=192.168.*.*:8649 192.168.*.*:8649
jvm.period=10
jvm.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
#jvm.period=300
#jvm.class=org.apache.hadoop.metrics.spi.NullContextWithUpdateThread
mapred.servers=192.168.*.*:8649 192.168.*.*:8649
mapred.period=10
mapred.class=org.apache.hadoop.metrics.ganglia.GangliaContext31
mapred.Queue.jobs_preparing
mapred.Queue.jobs_completed
mapred.Queue.jobs_running
mapred.Queue.jobs_illed
mapred.Queue.jobs_failed
hbase.RpcProcessingTimeAvgTime
diskstat_sda_weighted_io_time
hbase.NumOpenConnections
diskstat_sda_writes_merged
machine_type
hbase.ReceivedBytes
diskstat_sda_writes
load_report
gmond_started
图8-20
location
load_one
图8-19
sec
---
## Page 267
而是直接从内存中查找。
客户端当前连接的 ZooKeeper服务端失效，则自动切换到另一台有效的ZooKeeper服务端。
8.9
A：ZooKeeper为了提高整体系统的读取速度，
Q:为什么要限制 ZooKeeper中 ZNode的大小？
最后是管理Watcher，处理异常调用和Watcher。
然后发送心跳信息，保持与ZooKeeper服务端的有效连接与 Session的有效性。如果
A：首先是ZooKeeper服务端进行通信，
Q：ZooKeeper客户端主要负责什么？
相关的应用介绍差不多了，最后再和你说几个常见问题。
FAQ
regionserver.compactionSizeMaxTime
regionserver.compactionSizeAvgTime
regionserver.compactionQueueSize
regionserver.blockCacheSize
regionserver.blockCacheHitCount
regionserver.blockCacheFree
sdouan6n6n
ugiugi.loginFailure_avg_time
regionserver.SentBytes
Vanish_report
tx_pkts_bond1
tx_pkts_bondo
t_errs_bond1
图8-22
tx_errs_bondo
图8-21
，包括连接、发送消息、接收消息。
，是不允许从文件中读取需要的数据
8.9
FAQ
257
---
## Page 268
258
因为当ReigonServer被正式从RS集群中移除时，HMaster就开始做balance了（让其他
（如网络闪断、crash等故障、运维可快速介入），如果调低timeout时间，反而会得不偿失。
以减少因等待超时而被延长的failover时间。
Server负责的regions重新balance，让其他存活的RegionServer接管。
ReigonServer会被ZooKeeper从RS集群清单中移除，HMaster收到移除通知后，会对这台
为了避免这个问题，可以将ZooKeeper集群中部分服务器指定为Observer。
务器的数量越多，读取的性能就越好。但是，Fellower增加又会降低整个集群的写入性能。
器的数量达到目的。正相反，在整个集群中Fellower数量越多，整个集群写入的性
的Fellower通过后才能完成整个写入，所以整个集群写入的性能无法通过增加服务
过快耗尽ZooKeeper服务器的内存。这也是ZooKeeper不适合存储大量数据的原因。
ZNode的数据并不支持Append操作，全部都是Replace。
高性能协调服务之ZooKeeper
配regions的场景。
balance动作便毫无意义，反而会使负载不均匀，给RS带来更多负担，特别是那些固定分
RS根据故障机器记录的WAL日志进行恢复）。当故障的RS在人工介入恢复后，这个
能越差。
第8章
不过需要注意的是，对于一些在线应用，RegionServer从死机到恢复时间本身就很短
这个timeout 决定了RegionServer是否能够及时地failover。设置成1分钟或更低，可
ZooKeeper集群中的每一台服务器都可以提供数据的读取服务，所以在整个集群中服
由于ZooKeeper的写入需要先通过Leader，然后这个写入的消息需要半数以上
所以如果Znode设置过大，那么读写某一个ZNode将造成不确定的延时，也会
如果你还有什么其他的问题，可以发邮件给我，咱们再一起沟通研究。
它主要是RegionServer 与ZooKeeper之间的连接超时时间。当超时时间到B后，
Q：ZooKeeper参数如何调整？
A：这里所说的性能是写入的性能和读取的性能。
Q：如何提升ZooKeeper集群的性能？
ZooKeeper集群中每一台服务器都包含全部的数据，并且这些数据都会加载到内存中。
A：这里要说的是zookeeper.session.timeout参数，它的默认值是3分钟（180000ms）。
---
## Page 269
可以帮你找到学习和提高能力的方向、方法，也希望你能坚持学下去。
题，希望到时您可以不吝赐教。
解决这些浅显的问题，所以再一次感谢您。
培养了自己的自学能力。我知道自学能力很重要，并不会有很多人会像您这样耐心地帮我
刘老师：
总结
发人员的任务了。不过还好，了解和搭建不是问题，这倒是需要感谢刘老师的帮助。
比起前面的几个可以说是相当简单了。不过源码是自己不懂，对于代码级的优化只能是开
8.10小结
小鑫：
时还可以处理，所以可能过一大段时间才会再向您请教一些关于大数据或者开发方面的问
能帮到你也让我感到很欣慰。还是那句话，我也许不能给你很高深的知识，但我希望
很快，小鑫就收到了刘老师的回信。
您目前讲解的这些知识，我也需要大量的时间和精力来学习。我对公司目前的应用暂
再一次感谢您对我的帮助，使我从对运维一无所知到现在有了一些自己的判断能力及
至于其他一些知识还真需要时间来慢慢地研究。想了想，小鑫给刘老师回了一封感谢信。
小鑫看完邮件后对ZooKeeper有了一个比较完整的了解，看起来它的配置并不是很难，
如果有什么问题，我们可以一起再研究。知识共享，共展才华。
你好！
您好！
8.10小结
259
---
## Page 270
A
附录Avirsh命令及其含义
附录
表A-1提供所有virsh命令及其含义。
domname
dumpxml
命
resume
restore
domstate
dominfo
domuuid
reboot
domid
define
destroy
create
save
quit
start
list
help
令
将客户端当前状态保存到某个文件中
恢复暂停的客户端
恢复以前保存在文件中的客户端
重新启动客户端
退出当前的互动终端
显示客户端状态
显示客户端名称
显示客户端信息
显示客户端UUID
显示客户端ID
为客户端输出XML配置文件
强制客户端停止
启动未激活的客户端
从XML配置文件生成客户端并启动新客户端
输出客户端XML配置文件
列出所有客户端
打印基本帮助信息
表A-1virsh命令及其含义
描述
---
## Page 271
以下是其他virsh命令选项，见表A-3。
使用以下virsh命令用于管理客户端及程序资源，见表A-2。
detach-interface
attach-interface
detach-disk
detach-device
attach-disk
attach-device
domifstat
domblkstat
setvcpus
setmaxmem
命
setmem
undefine
suspend
shutdown
合
nodeinfo
version
vcpupin
vcpuinfo
migrate
从客户端中分离设备，使用同样的XML描述作为命令attach-device
在客户端中附加新网络接口
在客户端中附加新磁盘设备
使用XML文件中的设备定义在客户端中添加设备
显示正在运行的客户端的网络接口统计
显示正在运行的客户端的块设备统计
控制客户端的虚拟CPU亲和性
显示客户端的虚拟CPU信息
修改为客户端分配的虚拟CPU数目
从客户端中分离网络接口
从客户端中分离磁盘设备
为管理程序设定内存上限
为客户端设定分配的内存
将客户端迁移到另一台主机中
有关管理程序的输出信息
删除与客户端关联的所有文件
暂停客户端
关闭某个域
显示virsh版本
表A-3virsh命令及其含义
表A-2virsh命令及其含义
描述
鲜
述
述
virsh命令及其含义
续表
附录A
261
---
## Page 272
262
附录Byum命令及其含义
附录
yum clean all
yum clean oldheaders
yum clean packages
yum provides
yum info extras
yum list extras
yum list installed
yum list updates
yumlist