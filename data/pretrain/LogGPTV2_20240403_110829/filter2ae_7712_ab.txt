dbscan是一个比较有代表性的基于密度的聚类算法。与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现任意形状的聚类。dbscan的使用实在是太简单，只需要填上eps和minpts参数，即能进行聚类，然后输出聚类标签，一开始看到webber的这篇文章《基于大数据和机器学习的web异常参数检测系统》，他用到了大数据的思想可以做到实时检测，不过其中检测思想并没有涉及多少，针对我在文章开头提出的问题也没有给出具体的解释，，所以继续按照我的思路来做。。（多扯一句，这位大佬好像是我当时阿里实习二面面试官，人很nice！虽然最后挂在三面。。）  
这里回到主题，为什么不能做成实时检测？这是由于聚类算法的重点在于对当前数据做分析，并没有对新数据的检测功能，所以这里只能说是基于离线日志，应用场景也就是说只能每天定时跑一遍，检测某个时间段的请求。继续来研究dbscan的参数设置，本文的前提是想做一个针对任意业务模型的异常访问检测，那么参数设置如果能够做成根据业务模型自动化调整，这最好不过了。。接下来就是看论文找方法。。这里找到一篇博士的论文，并根据其算法思想做了实现，应用在这里。这里稍微讲下那两个参数eps和minpts的含义。  
eps表示以对象p为中心，以eps为半径的区域内的所有对象，通俗点讲这个参数就是包含数据集D中与对象p距离不大于eps的所有对象。而minpts则表示领域密度阈值，表示对象p的eps领域个数，那么dbscan算法的思想大概就是通过设定领域半径和领域个数来实现一个密度聚类，这里拿中国地图来将，我们知道江浙沪比较小，城市相邻都比较近，那么如果运用dbscan算法来实现中国城市的聚类，很大概率江浙沪可能就会形成一类标签，而像海南，因为是海岛，与相邻城市的距离较远，所以会自成一类标签。  
这里引入了密度阈值Density参数来定义密度阈值Density为以eps为半径的园内存在minpts个数据点，这里原论文中提到密度阈值太大，可能会导致同簇集合内部被划分为多个集合；密度阈值太小，可能导致不同簇集合之间被合并，论文最后的结论是聚类结果簇数正确的前提下，密度阈值越小则聚类效果越好，因此这里通过比对不同的密度阈值，得到最小密度阈值时的eps参数和minpts参数。这中间还引入了K-平均最近邻算法，，这个就不多说了。。  
具体代码如上，主要是引入了一个kann，可能有点复杂了。。  
这里可以看到当K为331时，eps为0.47，minpts为4.92，此时Density参数到达临界点。所以通过这样的计算，我们就能够自动化获得最佳的eps参数和minpts参数。最后我们就能获得分类的总标签数和每一条日志对应的分类标签。  
这里可以看到一共分成了10个标签，其中feed对应的是标签1，像archives应该对应的是文章查阅，标签为2，所以在上述方法在进行聚类时的确有一定的效果，因为我重点关注的是异常请求，其对应的标签应该是-1，表示这是一个噪声数据，所以下面重点来看看-1标签对应的日志记录  
看着分明就像是目录爆破页面，当然这里的ip有点问题，如果是实际场景，这类ip可以直接加入ban的列表里，那么针对目录扫描这种恶意行为，使用这种聚类思想是可以检测出来的。  
这里是比较明显的nikto扫描器页面，也能够检测出来。由于扫描器大多是针对单个页面进行尝试，所以这种在统计分布上具有天然的凸出，检测出来理所当然。。  
这个应该是顺后门行为和已知的漏洞攻击  
看到这里仿佛这玩意好像很牛逼，直接替代waf得了，但是现实狠狠打了脸，在实践结果混入了大量的无关页面，这些无关页面一般都有一个比较统一的特征，那就是参数随机化，当遇到像token或者其他一些随机生成的参数时，在聚类时由于参数比较特殊，所以一般都会独成一类，也就是变成噪声数据。  
上面四条数据将上文结果可以彻底推翻，其中像hid参数还是img参数这种，都是经过服务器随机化生成的，在做数据清洗的时候很难将这类数据单独处理，前文也讲了想做的是一个通用的业务模型检测，这里其实也能解决，用白名单即可解决，但是不够通用，后来就放弃了，其实用白名单的效果真的非常好，如果说报了50条异常，使用白名单将这些随机化参数给过滤掉，最终留下来的可能就只有5条数据了，而这些随机化参数往往的确是无害的，所以这是本文实践第一个比较失败的点。第二个就是上面/archives/tag/iis/feed，按理来说这是一个iis的标签链接，为什么会这种访问请求会被标记为异常呢？回到dbscan的算法思想，一定区域内密度足够大就能够自成一派，那么当某些正常的访问请求，可能的确比较少见，他们的密度不够，也就不能自成一派，这时候也就出现了误报，这种场景其实更常见在后台某些页面，管理员由于只有一个人操作，那么访问的页面数比较有限，所以运用聚类可能效果就会很差，这是第二个我觉得比较难处理的点。（老实讲，针对不同业务模型设立不同的白名单感觉是最直接最好的处理办法了。。）
# 5 降维可视化
最后用tsne来做了个降维可视化看一看数据分布  
这里-1其实比较密集，这里推测这类标签可能就是上述随机化参数导致的数据偏移。其他类型的标签就汇聚的比较明显了。。
# 6 后记
回过头来想一想利用访问请求来做无监督聚类，的确是可以发现潜在的攻击漏洞和扫描器行为的，这点来说一定是有意义的，但是针对那种随机化参数和部分访问量比较少的请求的确可能误报上会比较多，如果能够在数据清洗时针对这类标签做特殊处理，这个基于业务模型的自动化聚类的检测思想可能会发挥更大的作用。  
上述如有不当之处，敬请指出~