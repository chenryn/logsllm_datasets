ure 2c shows the fraction of the Internet that is unreachable as a
result of deploying individually to each of the 100 largest (by de-
gree) ASes, excluding the ASes in each warden that fall within that
set. It is clear that this strategy fails to work, as in only 2.3% of
all ASes are cut off from China in the best case, while the Egypt,
Iran and Syria will be cut off from 9.7% on average. Figure 2d
shows the fraction of destinations each warden is cut off from as
a function of deploying simultaneously to the top N largest ASes.
As can be seen, eventually this strategy will disconnect each war-
den from a large fraction of the Internet, but the deployment cost
is quite high. For example, in order to cut China off from at least
half the Internet all of the 96 largest ISPs in the world would need
to deploy decoy routers to all exit points in their network, while
still needing 74-78 of them to cut off much smaller countries such
as Syria. We note that such a deployment would incur high equip-
ment costs and require incentivizing a large number of proﬁtable
companies in diverse political settings.
4.3 Detection Attacks
Attacking the availability of decoy routers is just one option open
to the warden. Decoy routing systems also have the explicit goal
of unobservability—hiding the fact that a host is using the system.
However, wardens with path diversity are capable of launching at-
tacks that unmask users of decoy routers. While the availability
attack of Section 4.2 requires little in the way of real time actions
by the warden (nothing more than a handful of lines in the con-
ﬁguration ﬁles of routers), the attacks of this section have a much
more active element. In these attacks, the warden intentionally se-
lects some paths to destinations that cross at least one decoy router,
henceforth referred to as tainted paths. The warden then utilizes
the state and topology of the network to identify a decoy routing
user.
4.3.1 TCP Replay Attacks
Consider two hosts sending packets to a destination, one utiliz-
ing decoy routing, ostensibly sending trafﬁc to the overt destina-
tion, the other a host legitimately communicating with that same
destination. The most obvious difference between these two hosts
is that the latter actually has a TCP connection with the destination
while the former does not. The decoy routing user started a TCP
connection with the overt destination, but in both existing decoy
1AS X is in the customer cone of AS Y if AS Y is its only provider
or all of its providers are in the customer cone of Y .
routing schemes that connection is torn down with assistance from
the decoy router after TLS negotiation.
The challenge for the warden is to come up with a way to test
if the destination thinks it actually has a TCP connection with the
host. It turns out that the warden can do this quickly and cheaply
if it also has a clean path to the destination, as shown in Figure 3.
The warden need only replay a TCP packet sent by the host, but
instead of forwarding it along the tainted path that the host is using,
the warden forwards it along a clean path (Figure 3a). Because
there are no decoy routers along the path to intercept the packet,
it will reach the destination, and, by the end-to-end nature of the
Internet, the destination is agnostic to the actual path taken by the
packet. If the host was a legitimate host (Figure 3b), that is, not
using decoy routing, then because there is an existing TCP stream,
the destination will treat this packet as a duplicate, and, per the TCP
RFC [23], send a duplicate acknowledgement. On the other hand,
if the host was actually using decoy routing (Figure 3c) and the
destination was simply the overt destination, no TCP connection
will exist, and the destination will respond with a TCP reset packet.
We note that if the return path of the packet crosses a decoy
router, that decoy router could drop the packet.2 However, the war-
den has multiple ways to force asymmetry of inbound and outbound
paths.
4.3.2 Forced Asymmetry
Asymmetry in the path taken by data going between two hosts on
the Internet exists naturally [14]. However, a warden is able to arti-
ﬁcially induce path asymmetry on a far larger scale. At the simplest
level, all a warden needs to do is intuit which path a destination net-
work is utilizing to send trafﬁc to the warden, and then alter its rout-
ing policy to ensure that it picks a different path to the destination.
The warden can utilize a variety of metrics including inferred AS
relationships, incoming router/interface, TTLs, and packet timings
in order to determine which route a destination is using.
Alternatively, a more active warden can utilize BGP’s loop avoid-
ance mechanism [25] in order to force both return path asymmetry
and ensure that the return path is free of decoy routers. This attack
relies on a trafﬁc engineering technique known as hole punching.
In hole punching, a router advertises both a block of IP addresses
and a de-aggregation of that block, each with different path proper-
ties. Since these IP blocks are technically different, BGP will treat
them as routes to different destinations, allowing for more speciﬁc
policies for certain blocks of IP addresses. These more speciﬁc
routes will automatically be used, as routers always forward on the
most speciﬁc matching IP block. The warden then, for every block
it wishes to advertise, hole punches a second set of routes cover-
ing the entirety of each block it would normally advertise. Since
there is no currently deployed mechanism to prevent a router from
falsifying route properties, an active warden can add every known
decoy router deploying AS to these more speciﬁc routes. When
a decoy router deploying AS receives these routes they will drop
them, as it would appear like they would be creating a loop, but
ASes which do not deploy decoy routers would not ﬁnd themselves
in the path already, and so would accept and forward these routes
as normal. Since these routes are more speciﬁc, even if these non-
decoy routing ASes also have the more general route that travels
through decoy routing ASes, it will instead select the more speciﬁc
clean route.
2In our understanding of the Cirripede design, the state of all client
connections is replicated to all decoy routers, providing this func-
tionality, while Telex does not currently explicitly provide this
functionality.
89(a)
(b)
(c)
Figure 3: Illustration of a simple conﬁrmation attack launched using replayed TCP packets. In Figure 3a the warden has both a tainted path
and clean path to a destination, and allows users to utilize the tainted path. The warden then replays an observed TCP packet using the clean
path. If the user is honest (Figure 3b), a duplicate acknowledgement is seen. If the user is a decoy routing user (Figure 3c), a TCP reset is
instead seen.
No matter how the warden achieves path asymmetry, the results
are damaging to decoy routing systems. In the case of Telex, the
decoy routing system simply ceases to function, as it requires path
symmetry. Cirripede would function, but its use would become
obvious. Packets returning from the decoy router will enter the
warden at a different location in the network compared to packets
returning from the overt destination. If all return paths are tainted,
a decoy routing system could, in theory, shufﬂe packets between
decoy routers to cause them to enter at the correct router and inter-
face with the correct TTL, but this would further simplify timing
attacks, which we will cover in Section 5.
4.3.3 The “Crazy Ivan” Attack
Another active attack for conﬁrming if a user is utilizing a decoy
routing system we call the “Crazy Ivan” Attack. A Crazy Ivan was
a maneuver utilized by Soviet submarine commanders during the
cold war. It consisted of a series of radical course changes in an
effort to determine if an enemy submarine was hiding behind his
submarine, in an area that is acoustically masked by engine noises,
called a submarine’s bafﬂes. In an analogous manner, the warden
can initiate a series of radical path changes and withdrawals in an
attempt to unmask decoy routing users.
Again consider both a user who is utilizing decoy routing and a
user who is not. Both are currently sending trafﬁc down a tainted
path. Now consider what happens if the warden ﬂips the path uti-
lized to this destination to a clean path. Any host not using decoy
routing will not be impacted by this, and will continue with his
session. Decoy routing users, however, will be impacted, as their
functionality is sensitive to the path. In the worst case for the user,
behavior similar to that discussed in Section 4.3.1 is seen—TCP re-
set packets sent from the destination. Even if the return path crosses
decoy routers, which can drop the reset packets, the decoy routing
user is presented with an issue. His decoy routing session no longer
functions, and he can no longer pretend to communicate with the
overt destination. While observed user behavior after the path to
the destination is no longer tainted is not deﬁnitive proof of decoy
router usage, this experiment can be repeated multiple times un-
til the warden has a high enough conﬁdence in its conclusions. A
graphical representation of this attack can be seen in Figure 4.
Of course there is the question of what an adversary does when
no clean paths are available. First, it is clear that destinations to
which an alternate clean path can not be found are sub-optimal
honey pots.
If the warden is pushed into a scenario where such
routes must be utilized another option still exists. The warden
could, instead of changing the path to a destination, stop forwarding
packets to the tainted destination all together. This will obviously
disrupt both honest hosts and decoy routing users. The difference is
that honest hosts will start new sessions with random destinations,
while the decoy routing user will attempt to start new sessions down
tainted paths. Again, repeated iterations of this experiment can be
done to test if a user is utilizing decoy routing. Investigating the ef-
fectiveness of this last attack involves modeling user behavior and
browsing habits, making it outside the scope of this work.
5. TIMING ATTACKS
One of the consequences of using decoy routing is that the path
traversed to the covert destination will inevitably be different than
the path that would have been used if the client was actually com-
municating with the overt destination. While the warden cannot
explicitly notice that the paths are different, there are some unin-
tended consequences of using different paths that might leak some
information to a warden making careful observations. For instance,
a warden might be able to ﬁngerprint the ﬂow that it would ex-
pect to see when a client communicates with the overt destination,
and compare this to the ﬂow of the actual connection made by the
client. If these are signiﬁcantly different, the warden can infer that
the client is not actually connected to the overt destination.
One such common property of network ﬂows that can be used in
ﬁngerprinting is network latency. Since the paths to the overt and
covert destinations will diverge after the decoy router, there may
be differences such as path length and bottlenecks which effect the
latencies of packets traveling along these two paths. This enables
a warden to be able to identify ground truth of what the range of
latencies should be when communicating with an overt destination,
and can compare this to the latencies they observe between a client
and the overt destination. If these two distributions differ in a sig-
niﬁcant manner, the warden can infer that the client is in reality not
communicating with the overt destination.
5.1 Experimental Setup
In order to validate the effectiveness of ﬁngerprinting trafﬁc us-
ing network latency, we took advantage of the publicly available
Telex client version 0.0.2 in conjunction with the deployed Telex
station. Due to the fact that connections to the overt destination
must traverse the Telex station, the set of possible overt destinations
was limited to notblocked.telex.cc, jhalderm.com and
notreallyblocked.telex.cc. In our experiments, we used
only notblocked.telex.cc for our overt destination, since
all four possibilities are less than one millisecond away from the
Telex station and all produce the same results.
In order to measure the latency of the client’s connection through
the decoy router to the covert destination, we wait until the TLS
handshake is completed, during which time all communication is
going through to the overt destination. We then wait until the
90(a)
(b)
(c)
Figure 4: An illustration of the Crazy Ivan attack. In Figure 4a, the warden allows users to utilize a tainted path. In Figure 4b, the warden
switches to a clean path, breaking decoy routing user’s session while leaving honest users unaffected. In Figure 4c, the user begins a new
session, using another known tainted path, implying the users is looking for a tainted path. The warden repeats this tests several times to
establish conﬁdence in this assertion.
ChangeCipherSpec message is sent by the client, notifying us that
the Telex key exchange protocol is completed and that all further
trafﬁc will be travelling to the covert destination. Once this is done,
we then wait until an ApplicationData TLS packet is sent by the
client and measure the time it takes to get a response Application-
Data TLS packet sent back from the server. While we are mea-
suring the latencies of the connection from the client to the server
through the decoy router, we simultaneously start up a separate di-
rect connection to the overt destination, and similarly observe the
time it takes for an ApplicationData TLS packet to be sent from the
client until it receives a response from the server. This was repeated
until we had 50 latency samples in our distributions.
5.2 Detecting Telex
In order to determine the feasibility of our plan of attack, we
ﬁrst ran some preliminary tests to see what sort of discrepancies
in latency measurements could be seen when using Telex to con-
nect to covert destinations. We ﬁrst chose some arbitrary popular
sites, Amazon, Gmail and Facebook, and ran our experiments to
determine the latency distributions. Figures 5a-5c show the latency
distributions measured to each of these covert destinations through
Telex as compared to the measured latencies directly to the overt
destination. As we can see, there is a signiﬁcant difference in the
distribution of latency measurements, implying a a warden would
have no trouble at all distinguishing legitimate trafﬁc from connec-
tions going over Telex.
While these results look promising for the warden, they are some-
what caused by the limitations in the choices we can make for the
overt destination. Due to the fact that the only overt destinations
available have a latency of less than one millisecond to the Telex
station itself, while the selected covert destinations range anywhere
from 10 to 60 milliseconds away, it is not surprising to see these
large discrepancies. Because of this, we ran the same experiment
using the covert destination also deployed with the overt destina-
tions, blocked.telex.cc, getting rid of the large differences
in latencies seen between the overt and covert destinations to the
Telex station. As can be seen in Figure 5d, the distributions have
much more overlap than seen previously, but there is still a signiﬁ-
cant difference in the distribution of latencies for connections going
over Telex and for direct connections to the overt destination.
Given these promising results, we then moved to expand the
analysis using larger sample sizes to determine exactly when a
warden would be able to detect usage of the Telex system.
In
order to compare two latency distributions, we used the d-values
returned by the Kolmogorov-Smirnov test, which quantiﬁes the
distance between two empirical distributions. For example, when
comparing latency distributions for the overt destination against
latency distributions for Amazon, Gmail and Facebook, we get
Kolmogorov-Smirnov scores of 0.9901, 0.9536, and 1.0, respec-
tively, and when comparing them to the latency distribution for
blocked.telex.cc we get a score of 0.3665. To establish a
baseline of what sort of scores should be expected when compar-
ing samples from the same latency distribution, we randomly split
in half the latencies that were observed to the overt destination and
ran the Kolgmogorov-Smirnov test on the two samples. This was
repeated 100 times to get an accurate representation of the range of
scores that should be expected.
F
D
C
0
1
.
8
0
.
6
.
0
4
0
.
2
.
0
0
0
.
overt
nearby
top 100
0.0
0.2
0.4
0.6
0.8
1.0
Kolmogorov−Smirnov Score
Figure 6: CDF of K-S scores when comparing an overt latency
distribution to itself, to nearby servers within 10ms of the Telex
station, and to the Alexa top 100 websites.
With a baseline set of scores gathered, we then wanted to see
how well a warden would be able to distinguish connections going
over Telex. We used two sets of covert destinations: one comprised
of 10 nearby servers, all within 10 milliseconds of the Telex station;
the other taken from the Alexa top 100. Figure 6 shows the CDF of
Kolmogorov-Smirnov scores for the different sets of covert destina-
tions. As can be seen, both the nearby servers and the Alexa top 100
all have signiﬁcantly higher scores, ranging from 0.3 to 1.0 with
median scores of 0.7 and 1.0, respectively. Compared to the set of
scores seen when comparing latencies directly to the overt destina-
tion, where the maximum score is 0.26, the two sets of covert desti-
nations are distinctly higher scoring, and would all be detectable by
a warden. Furthermore, even looking at the distribution of latencies
we saw earlier for blocked.telex.cc in Figure 5d, we see a
score of 0.3665 which falls outside this range as well. This implies
that a warden would be able to successfully detect a client using
Telex to connect to blocked.telex.cc, which has a latency
of approximately 0.5 milliseconds to the Telex station, which is
the same as the overt destination notblocked.telex.cc. The
large separation of latency distributions of servers so close to the
Telex station suggests that the overhead of the man-in-the-middle
91   
y
t
i
s
n
e
D
0
2
.
0
0
1
.
0
0
0
.
0
overt
telex
y
t
i
s
n
e
D
0
3
.
0
5
1
.
0
0
0
.
0
overt
telex
y
t
i
s
n
e
D
4
.
0
2
.
0
0
.
0
overt
telex
y
t
i
s
n
e