0
−50
−100
0
200
400
600
0
20
40
60
80
100
Hit Count Increase
Percentage of Contributors
Figure 7: Hit Count Comparison of HPB and GWOL: Length 1000 Entries
200
150
100
50
s
r
o
t
u
b
i
r
t
n
o
C
f
o
#
0
−200
e
s
a
e
r
c
n
I
t
n
u
o
C
t
i
H
)
%
(
e
v
i
t
l
a
e
R
300
250
200
150
100
50
0
−50
−100
0
200
400
600
0
20
40
60
80
100
Hit Count Increase
Percentage of Contributors
Figure 8: Hit Count Comparison of HPB and LWOL: Length 1000 Entries
tributors (about 7%), HPBs perform worse. (We discuss
the reasons why HPB may perform worse in Section 4.4.)
Figure 8 compares HPB hit counts to those of LWOL.
The data are plotted in the same way as in Figure 7.
Overall, HPBs demonstrate a performance advantage
over LWOL. The IV and RI values also exhibit similar
distributions. However, comparing Figures 8 and 7, we
see that HPB has more hit improvement comparing to
LWOL than to GWOL in this time window.
4.2 Prediction of New Attacks
One clear motivating assumption in secure collaborative
defense strategies is that participants have the potential
to prepare themselves from attacks that they have not yet
encountered. We will say that a new attack occurs when
a contributor produces a DShield log entry from a source
that this contributor has never before reported. In this ex-
periment, we show that HPB analysis provides contribu-
tors a potential to predict more new attacks than GWOL.
(LWOL is not considered, since by deﬁnition it includes
only attackers that are actively hitting the LWOL owner.)
For each contributor, we construct two new HPB and
GWOL lists with equal length of 1000 entries, such that
no entries have been reported by the contributor during
our training window. We call these lists HPB-local (HPB
minus local) and GWOL-local (GWOL minus local), re-
spectively. Figure 9 compares HPB-local and GWOL-
local on their ability to predict on new attack sources
for the local contributor. These hit number plots demon-
strate that HPB-local provides substantial improvement
over the predictive value of GWOL.
4.3 Timely Inclusion of Sources
By timely inclusion, we refer to the ability of a blacklist
to incorporate addresses relevant to the blacklist owner
before those addresses have saturated the Internet. To in-
vestigate the timeliness of the GWOL, LWOL, and the
HPB we examine how many contributors need to report
a particular attacker before it can be included into the re-
spective blacklists. We focus our attention on the set of
attackers within these blacklists that did carry out attacks
during the prediction window. And we use the number
of distinct victims (contributors) that a source attacked
in the training window to measure the extent to which
the source has saturated the Internet. Figure 10 plots
the distribution of the number of distinct victims across
different attackers on the three blacklists. As expected,
the attackers that get selected on the GWOL were the
most proliﬁc in the training period. In particular, all the
sources on the GWOL have attacked more than 20 con-
tributors and almost 1/3 of them attacked more than 200
contributors. To some extent, these attackers have satu-
rated the Internet with their activities. (DShield sensors
are a very small sample of the Internet. A random at-
USENIX Association  
17th USENIX Security Symposium 
117
200
150
100
50
s
r
o
t
u
b
i
r
t
n
o
C
f
o
#
0
−200
e
s
a
e
r
c
n
I
t
n
u
o
C
t
i
H
)
%
(
e
v
i
t
a
e
R
l
300
250
200
150
100
50
0
−50
−100
0
200
400
600
0
20
40
60
80
100
Hit Count Increase
Percentage of Contributors
Figure 9: HPB-local Predicts More New Attacks Than GWOL-local
tacker has to target many places to be picked up by the
sensors.) The LWOLs select attacker addresses that fo-
cused on the local networks. Most of these addresses
had attacked far fewer contributors. HPBs’s distribution
is close to that of the LWOL, hence allowing the incor-
poration of attackers that have not saturated the Internet.
103
102
101
s
m
i
t
c
V
i
t
c
n
i
t
s
D
i
f
o
#
100
0
HPB
GWOL
LWOL
20
80
Cumulative Percentage
40
60
100
Figure 10: Cumulative Distribution of Distinct Victim
Numbers
4.4 Performance Consistency
The results in the above experiments show that the HPB
provides an increase in hit count performance across the
majority of all contributors. We now ask the follow-
ing question:
is the HPB’s performance consistent for
a given contributor over time? In this experiment, we
investigate this consistency question.
We use a 60-day DShield dataset. We divide it into
12 time windows, T0, T1, . . . , T11. We generate black-
lists from data in time window Ti−1 and test the lists on
data in Ti. For each contributor v, we compare HPB with
GWOL and obtain eleven improvement values for win-
dow T0 to T10. We denote them
IV s(v) = {IV0(v), IV2(v), . . . IV10(v)}. We then de-
If
ﬁne a consistency index (CI) for each contributor.
IVi(v) ≥ 0, we say that the HPB performs well for v
in window i. Otherwise, we say that the HPB performs
worse. CI is the difference between the number of win-
dows in which HPB performs well and the ones in which
HPB performs poorly, i.e., CI(v) = |{p ∈ IV s(v) :
p ≥ 0}| − |{p ∈ IV s(v) : p < 0}|.
If HPB con-
sistently performs better than GWOL for a contributor,
its CI(v) should be close to 11. If it consistently per-
forms worse, the CI value will be close to -11. How-
ever, if the HPB performance ﬂip-ﬂops, its CI value will
be close to zero. Figure 11 plots the sorted CI values
against the contributors. (Again, we label the x-axis by
cummulative percentage.) We see that for almost 70% of
the contributors, HPB’s performance is extremely con-
sistent. They all have a CI value of 11, meaning for the
eleven time windows, the HPB always predicts more hits
for them than GWOL. For more than 90% of the contrib-
utors, HPBs demonstrate fairly good consistency. With
few contributors does the performance switch back and
forth. Only 5 contributors show performance index be-
low -3.
x
e
d
n
I
e
c
n
e
i
t
s
s
n
o
C
11
9
7
5
3
1
−1
−3
−5
−7
−9
−11
0
20
40
60
80
100
Cumulative Percentage of Contributors
Figure 11: Cumulative Distribution of Consistency Index
The consistency investigation sheds some light on the
reason why there is a small percentage of contributors
for which the HPBs (sometimes) perform worse than the
other list. HPB construction is based on the relevance
measure. The relevance relates attack sources to contrib-
utors according to the past security logs collected by the
repository. If a contributor has relatively stable correla-
tions (stable for several days) with other contributors or it
experiences stable attack patterns, the relevance measure
can capture this and thus produce blacklists with more
118 
17th USENIX Security Symposium 
USENIX Association
hits. Such HPBs will also be consistent in hit-count per-
formance. On the other hand, if the correlation is not
stable or the attacks exhibit few patterns, the relevance
measure will be less effective and may produce black-
lists with fewer hits. Such HPBs will not be consistent
in performance because sometimes they may guess right
and produce more hits and sometimes they may guess
wrong.
This can be seen in Figure 11. All the consistent HPBs
have CI value 11. These HPBs have both consistency
and better hit-count performance. There is no HPB that
shows CI value -11. HPB never performs consistently
worse.
This is particularly useful because the consistency of
an HPB’s performance can be used to indicate whether
the HPB user (the contributor) has stable correlations. If
so, HPBs can be better blacklists to use. The experiment
result suggests that most of the contributors have stable
correlations. In practice, given a few cycles of computing
HPB and GWOL for a DShield contributor, we can pro-
vide an informed recommendation as to which list that
contributor should adopt over a longer term.
4.5 Blacklist Length
In this experiment, we vary the length of the blacklists to
be 500, 1000, 5000 and 10000. We then compare the hit
counts of HPBs, GWOLs, and LWOLs. Because in all
the experiments, the improvements for different contrib-
utors display similar distributions, we will simply plot
the medians of the hit rates of these respective blacklists.
(Hit rate is the hit count divided by the blacklist length.)
Our results are illustrated in Figure 12, and show that
HPBs have the hit rate advantage for all these choices in
blacklist length. The relative amount of advantage is also
maintained across different lengths.
0.25
0.2
0.15
0.1
0.05
e
t
a
R
t
i
H
f
o
i
n
a
d
e
M
0
0
GWOL
LWOL
HPB
2000 4000 6000 8000 10000
Blacklist length
sense that they do not get hit). Therefore, it may not
always be desirable to use very long lists.
4.6 Training and Prediction Window Sizes
We now investigate how far into the future the HPB can
maintain its advantage over GWOL and LWOL, and how
different training window sizes affect an HPB’s hit count.
The former helps to determine how often we need to re-
compute the blacklist, and the latter helps to select the
right amount of history data as the input to our system.
The left panel of Figure 13 shows the median of the hit
count of HPB, GWOL, and LWOL on day 1, 2, 3, . . . , 20
for each individual day in the prediction window. All