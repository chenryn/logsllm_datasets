tional requirements are used in the different levels.
5.2 B+-tree Index Based on Malware Features
The feature vector used in SMIT’s ﬁrst-level index must satisfy
two requirements. First, its computation cost must be low. Second,
it must be able to identify parts of the malware database that are
not relevant to a given malware query. That is, the feature vector
needs to be able to pinpoint the obviously irrelevant, but not nec-
essarily the most relevant. Speciﬁcally, SMIT uses the following
feature vector v = (Ni, Nf , Nx, Nm) derived from the assembly
code of each malware program, where Ni is the total number of
instructions; Nf the total number of functions; Nx the total num-
ber of control transfer instructions (e.g., jumps and calls), which is
a good approximation of a program’s complexity because it indi-
cates the degree to which a program deviates from a straight-line
code; and Nm the median number of instructions per function. The
feature vector has the following property: if two malware programs
are similar to each other, so are their feature vectors. However, if
two malware are dissimilar, their feature vectors may or may not
be similar. Therefore, it is only useful when the feature vectors of
two malware are drastically different, meaning that the underlying
programs are deﬁnitely different, but not when their feature vectors
are somewhat different or similar.
Because leaf nodes in a B+tree need to be ordered by their keys
(feature vectors), we impose a total ordering among feature vectors
by giving priority to more useful features (Ni > Nf > Nx >
Nm). We also augment the B+ tree structure by adding a backward
sibling pointer to each leaf node, which points to the previous leaf
node. Together with the forward sibling pointer in the B+-tree, it
facilitates navigation across leaf nodes and indexed search.
615Given a malware query, SMIT ﬁrst extracts its feature vector and
uses it as a key to search the B+-tree index. Suppose the probing
ends in a lead node X. SMIT then follows X’s forward and back-
ward sibling pointers to locate N leaf nodes before and after X,
and further explores the second-level index trees (VPT) associated
with these 2N +1 leaf nodes. Here N is an empirically-determined
parameter that is designed to reduce the probability of the feature
vector pruning away sufﬁciently close neighbors. Because these
2N + 1 VPTs are independent of one another, they can be queried
in parallel to reduce the query response time. Finally, the K near-
est neighbors returned from the exploration of each of the 2N + 1
VPTs are combined to determine the ﬁnal K nearest neighbors.
5.3 Optimistic Vantage Point Tree
The Vantage Point Tree (VPT) is designed for database items
whose similarity to each other must be explicitly computed (e.g.,
graphs), and exploits the triangular inequality to prune irrelevant
database items. To construct a VPT for a graph database, we ﬁrst
select a graph as the root pivot V , compute the distance between V
and all the remaining graphs, and then divide these graphs into M
approximately equal-sized partitions (Pi, i = 1, 2, ..., m) based on
their distance to V . In addition, at the pivot V , we record the dis-
tance range associated with each partition Pi, which is represented
by low[i] and high[i]. This same procedure is repeated for each
partition recursively, until all partitions fall below a certain size.
Given a query graph g, the K-nearest-neighbor (KNN) search
of a VPT with a root pivot p starts with computation of the edit
distance d(p, q) between p and q, and then decide which partitions
to explore further by exploiting the triangular inequality of the dis-
tance metric. More speciﬁcally, let δnow be a parameter indicat-
ing to the search algorithm that it should ignore any database item
whose distance to the query q is larger than δnow. Given δnow, the
search only needs to explore those partitions whose distance range
overlaps with the range of interest, [d(p, q)−δnow, d(p, q)+δnow],
as shown in Figure 2. That is, partition Pi is pruned if and only if
high[i]  d(p, q) + δnow.
(1)
This search procedure is applied recursively at each visited node
until all nodes are either pruned or visited.
Eq. (1) shows that at each node, the pruning power of the VPT
search algorithm is dependent on the value assigned to δnow. If
δnow is small, only a few partitions need to be traversed. How-
ever, too small a δnow may lead to pruning of the partitions that
actually contain the nearest neighbors. One way to keep δnow as
small as possible is to update it during the search. At any point
in a KNN search, the algorithm remembers the K closest neigh-
bors that it has encountered so far together with their distance to
the query graph q in a priority queue, and sets δnow to the largest
of these distance values after accumulating K closest neighbors.
Every time the search encounters a database item p whose d(p, q)
is smaller than δnow, it adds p together with d(p, q) to the prior-
ity queue and updates δnow accordingly. Another way to reduce
the value of δnow is to traverse the partitions that are closer to the
query graph earlier than those that are farther away. For example,
in Figure 2, partition 3 is traversed before partition 2 or 4, because
closer partitions are more likely to contain closer neighbors.
To make an optimal balance between accuracy and efﬁciency
when initializing δnow, we take an optimistic approach (OVPT) [9]
by starting with a small initial δnow value, and exponentially in-
creasing it at subsequent iterations if previous iterations fail to iden-
tify K nearest neighbors. Speciﬁcally, for a VPT rooted at node p,
the initial δnow is chosen to be δnow = maxm−1
+
1 where low[i] and high[i] are the lower and upper ends of the
i-th partition’s distance range. This choice of the initial δ value
low[i+1]−high[i]
i=1
2
Partition 4
Partition 3
Partition 2
Partition1
pivot
range
query
Figure 2: Pruning on a VPT based on the triangular inequality
Feature Min
1
1
1
0
Ni
Nf
Nx
Nm
Max Average Median
7319
85
18
1090
24233.0
480.6
39.1
4932.3
1807413
37130
9998
731350
STD
55390.9
1077.6
181.4
10519.7
Table 1: Statistics of different features in the feature vector
guarantees that for any query graph q, at least one partition will
be traversed, because d(q, p) will fall within at least one partition’s
extended distance range, [low[i] − δnow, high[i] + δnow].
When the initialized value of δnow is too small, the search may
not ﬁnd all K nearest neighbors. In such a case, SMIT increases
the initialized value δnow using δnow,M = δnow,M−1 + α or
δnow,M = δnow,0 ∗ βM−1where α and β are additive and mul-
tiplicative constants and M is the number of iterations that have
been attempted to ﬁnd the K nearest neighbors. To reduce the per-
formance overhead of OVPT, all the distance-computation results
in previous iterations are cached so that no distance computation
may ever be done more than once in an OVPT search.
The performance gain of OVPT comes from two sources. First,
we notice empirically that there is a big difference between the time
needed to locate the K nearest neighbors and the time needed to
verify that they are indeed nearest neighbors. Using a smaller ini-
tial δnow value signiﬁcantly reduces the veriﬁcation cost because
it cuts down the number of candidates considered, especially when
the query graph is indeed close to its nearest neighbors. Second, the
optimistic approach carries almost no additional performance over-
head because all distance-computation results in previous iterations
are cached and can thus be readily reused. More concretely, any
partitions that are not pruned in the (M − 1)-th iteration will never
be pruned in the M-th iteration because δnow,M−1 < δnow,M .
This means that all the distance computations in previously itera-
tions are necessary, and their caching guarantees that no distance
computation will be done more than once.
6. EVALUATION
In this section, we apply SMIT to a large collection of real-world
malware ﬁles and evaluate its performance in terms of effectiveness
(whether the results produced by SMIT are meaningful and similar
to those produced by human analysts), efﬁciency, and scalability.
We focus on the K-NN search, because, given the polymorphic na-
ture of modern malware, ﬁnding the most similar samples in the
database to a given malware ﬁle is more useful than pinpointing its
exact match.
6.1 Experiment Setup
The dataset used in the evaluation contains 102,391 unique mal-
ware programs recently submitted to Symantec Corporation. These
malware samples range from simple trojan/virus (less than 100 in-
structions) to considerably larger malware (more than hundreds of
thousand instructions). All the malware ﬁles had been analyzed by
human experts and classiﬁed into families. Each ﬁle is labeled with
a VID (Virus ID) representing the malware family to which it be-
616longs. As a result, we can determine that a binary ﬁle used in a
query is a variant of an existing malware ﬁle if both share the same
VID. In total, these malware programs come from 1747 families.
We ﬁrst create a function-call graph representation for each mal-
ware ﬁle. The graphs have an average number of 504 nodes and
1074 edges, and a maximum number of 37809 nodes and 83737
edges. We implement SMIT in C++ and conduct all experiments
on a Dell R905 Server with 1.90 G Quad-Core CPU running Win-
dows Server 2003. SMIT is a CPU-bound application and has a
moderate memory requirement (less than 100MB).
To evaluate the performance of SMIT, we use the following three
metrics: 1) the percentage of index entries that are accessed to lo-
cate the K nearest neighbors of the query ﬁle; 2) the percentage
of the returned K-NN malware ﬁles that are in the same family as
the query ﬁle; and 3) the average runtime of K-NN search. The
ﬁrst metric measures the average portion of the SMIT index tree
that needs to be examined to service a query. The second reﬂects
the accuracy and effectiveness of the SMIT index tree in correctly
identifying a new malware. The last one represents the total compu-
tation cost for each query. Because SMIT comprises two indexing
structures (B+tree and OVPT), we ﬁrst evaluate them separately
and then their aggregate performance when they are combined.
6.2 Effectiveness of B+-tree Index
The ﬁrst-level B+-tree index in the SMIT index tree uses a com-
putationally economical feature vector representation to attain pruning-
efﬁciency. The statistics of different features are summarized in
Table 1, showing that the value distribution of different features
varies signiﬁcantly across malware samples.1 This wide variation
gives the feature vector considerable pruning power and enables
SMIT to search only a small number of most relevant VPT trees.
SMIT’s B+ tree index takes the following two parameters: 1)
the fan-out of each B+ tree node (the maximum number of data
entries in each node); 2) the number of adjacent leaf nodes (de-
noted as N) whose associated second-level VPT trees are further
searched. As the fan-out parameter increases, more keys and point-
ers can be packed into a B+ tree node, fewer nodes are required
to hold the index, and fewer tree nodes need to be accessed during
a query search. However, larger fan-out parameters also require
bigger second-level VPT trees to be explored to achieve better ac-
curacy. This is a typical trade-off between query result accuracy
and computation overhead. According to our experience, setting
the fan-out parameter to between 300 to 400 achieves a good bal-
ance. By default, SMIT sets the fan-out of its B+ tree index to 400,
which results in a three-level B+ tree with 209 leaf nodes. On aver-
age, each leaf node contains 273 keys (the occupancy ratio 68.3%)
and 398 malware programs (some are mapped to the same key).
65% of time, malware programs that are mapped to the same key
also have the same VID, i.e., belong to the same malware family.
To evaluate the effectiveness of SMIT’s B+ tree index, we ran-
domly select 426 unique malware ﬁles and use them as queries
against the SMIT’s malware database. For 90.8% of these queries,
the returned B+tree leaf node contains at least one malware sample
that belongs to the same family as the query, and for 96.2% of them,
the returned leaf node or its immediate two neighboring leaf nodes
contain at least one malware sample that belongs to the same fam-
ily as the query. Although the end-to-end accuracy in pinpointing a
query ﬁle’s nearest neighbor also depends on SMIT’s second-level
indexing, i.e., OVPT, and is thus smaller, the high success rate of
ﬁnding samples of the same malware family as the query ﬁle in the
1There are very low feature values such as 0 or 1, because some
malware employ various packing or anti-disassemble techniques
and cannot be successfully disassembled.
1400
1200
1000
e
c
n
a
t
s
i
D
h
p
a
r
G
MSDV
Greedy
Original Hungarian Algorithm (OHA)
Neighbor Biased Matching (NBM)
Neighbor Biased Hungarian Algorithm (NBHA)
800
600
400
200
0
0
100 200 300 400 500 600 700 800 900 1000 1100 1200
Graph Pairs
Figure 3: Quantitative comparison among graph distance met-
rics The X-axis corresponds to a sequence of graph pairs.
same or close-by leaf nodes, demonstrates the efﬁcacy of SMIT’s
choice of feature vector as used in its B+ tree index.
6.3 Quality of Graph-Similarity Metric
Accurate graph-distance metric is crucial for SMIT’s VPT to cor-
rectly prune away irrelevant parts of its malware graph database.
Therefore, we ﬁrst evaluate the quality of the proposed graph dis-
tance metric—Neighbor Biased Hungarian Algorithm (NBHA). We
compare NBHA with the original Hungarian Algorithm (OHA) [28],
the Neighbor Biased Matching (NBM) algorithm [14] and a Greedy
algorithm, which computes the distance between two graphs from
an edit path formed by repeatedly matching the most similar node
pairs according to the cost matrix. The results of all these algo-
rithms, including NBHA, have been shown to be an upper bound
for the Exact Graph-Edit Distance (EGED). Because EGED com-
putation incurs an exponential cost, we cannot directly compare
NBHA with EGED. Instead, we qualitatively evaluate the closeness
of NBHA to EGED by computing a graph distance metric called
the multi-set degree-vector distance (MSDV), which compares the
vertices’ label and in/out degree between two graphs without con-
sidering their connectivity structure.
It has been shown that the
MSDV distance is a lower bound for the exact edit distance [10].
We randomly select 66 malware graphs, and compute their pair-
wise distance using the graph-distance metrics, NBHA, OHA, NBM,
Greedy and MSDV. We order the pair-wise distance values obtained
from the NBHA algorithm, and present the distance values from
other algorithms according to this order. The results are shown in
Figure 3, where each point on the X-axis corresponds to a partic-
ular pair of graphs. By deﬁnition, true edit distance (EGED) lies
between its upper-bound metrics (NBHA, OHA, NBM, Greedy)
and lower-bound metric (MSDV). Because in many cases the upper
bounds and lower bound shown in Figure 3 are close to each other,
these bounds empirically approximate EGED effectively. More-
over, NBHA outperforms other upper-bound metrics (OHA, NBM
and Greedy algorithm) in terms of accuracy, because in most cases
NBHA’s results are smaller than other algorithms’. For upper-
bound metrics, smaller metric values imply more accurate approx-
imation to EGED. Speciﬁcally, NBHA results are smaller than or
equal to those of OHA and NBM, about 95% and 70% of all graph-
distance computations in this experiment, respectively.
Next, we evaluate the accuracy and effectiveness of NBHA in
terms of the similarity of NBHA results to those produced by hu-