### Data and Acknowledgments

The data for the experiments in Section 8 were led by Sumeet Bedi, with assistance from Watee Arjsamat, Sonal Ghandi, Kevin Lux, and Aloka Singh. We also received valuable comments from Karthikeyan Bhargavan, Ran Canetti, Michael Greenwald, Klara Nahrstedt, Adrian Perrig, and Jonathan Smith. We extend our gratitude to Luigi Rizzo for his assistance and for allowing us to use his FEC package. The research conducted by Gunter and Tan was partially supported by NSF EIA00-88028 and ONR N00014-02-1-0715. Khanna's research was partially supported by an Alfred P. Sloan Research Fellowship and an NSF Career Award CCR-0093117.

### References

[1] A. Pannetrat and R. Molva. Efficient multicast packet authentication. In *Proceedings of the NDSS Symposium*, 2003.

[2] J. M. Park, E. K. P. Chong, and H. J. Siegel. Efficient multicast stream authentication using erasure codes. *ACM Transactions on Information and System Security*, 6(2):258–285, 2003.

[3] Adrian Perrig. The Biba one-time signature and broadcast authentication protocol. In *ACM Conference on Computer and Communications Security*, pages 28–37, 2001.

[4] Adrian Perrig, Ran Canetti, Dawn Xiaodong Song, and J. D. Tygar. Efficient and secure source authentication for multicast. In *Proceedings of the NDSS Symposium*, 2001.

[5] Adrian Perrig, Ran Canetti, J. D. Tygar, and Dawn Xiaodong Song. Efficient authentication and signing of multicast streams over lossy channels. In *IEEE Symposium on Security and Privacy*, pages 56–73, 2000.

[6] Adrian Perrig and J. D. Tygar. *Secure Broadcast Communication in Wired and Wireless Networks*. Kluwer, 2003.

[7] Luigi Rizzo. Effective erasure codes for reliable computer communication protocols. *ACM Computer Communication Review*, 27(2):24–36, 1997.

[8] Pankaj Rohatgi. A compact and fast hybrid signature scheme for multicast packet authentication. In *ACM Conference on Computer and Communications Security*, pages 93–100, 1999.

[9] S. M. Ross. *Stochastic Processes*. Wiley, second edition, 1996.

[10] H. Schulzrinne, S. Casner, R. Frederick, and V. Jacobson. RTP: a transport protocol for real-time applications. *RFC 1889, IETF*, January 1996.

[11] Wong and Lam. Digital signatures for flows and multicasts. *IEEE/ACM Transactions on Networking*, 7, 1999.

[12] Ran Canetti, Juan Garay, Gene Itkis, Daniele Micciancio, Moni Naor, and Benny Pinkas. Multicast security: A taxonomy and some efficient constructions. In *INFOCOMM’99*, 1999.

[13] H. Chernoff. A measure of the asymptotic efficiency of tests of a hypothesis based on a sum of observations. *Ann. Math. Stat.*, 23:493–507, 1952.

[14] Danny Dolev and Andrew C. Yao. On the security of public-key protocols. *IEEE Transactions on Information Theory*, 2(29):198–208, 1983.

[15] David C. Feldmeier, Anthony J. McAuley, Jonathan M. Smith, Deborah S. Bakin, William S. Marcus, and Thomas M. Raleigh. Protocol boosters. *IEEE Journal on Selected Areas in Communications*, 16(3):437–443, 1998.

[16] Rosario Gennaro and Pankaj Rohatgi. How to sign digital streams. In *Proceedings of Crypto’97*, pages 180–197, 1997.

[17] Philippe Golle and Nagendra Modadugu. Authenticating streamed data in the presence of random packet loss. In *Proceedings of the NDSS Symposium*, 2001.

[18] W. Hoeﬀding. Probability inequalities for sums of bounded random variables. *J. Amer. Stat. Assoc.*, 58:13–30, 1963.

[19] H. Krawczyk, M. Bellare, and R. Canetti. HMAC: Keyed-hashing for message authentication. *RFC 2104, IETF*, February 1997.

[20] M. Luby, L. Vicisano, J. Gemmell, L. Rizzo, M. Handley, and J. Crowcroft. Forward error correction (FEC) building block. *RFC 3452, IETF*, December 2002.

[21] F. J. MacWilliams and N. J. A. Sloane. *The Theory of Error-Correcting Codes*. North-Holland, 1977.

[22] R. J. McEliece. *The Theory of Information and Coding*. Addison-Wesley, 1977.

[23] Ralph Merkle. A certified digital signature. In *Proceedings of Crypto’89*, pages 218–238, 1990.

[24] Sara Miner and Jessica Staddon. Graph-based authentication of digital streams. In *IEEE Symposium on Security and Privacy*, pages 277–288, 2001.

### Forward Error Correction

Several unicast protocols utilize a combination of low-complexity error-detection codes (typically cyclic redundancy check (CRC) codes) and feedback mechanisms, such as automatic repeat requests (ARQs), to recover from errors and losses in transmission. However, ARQ-based protocols do not scale well in multicast settings. In such cases, coding introduced in the transmission must be sufficiently powerful to allow each recipient to unambiguously reconstruct the entire authentication stream with very high confidence, ensuring that only a very small fraction of transmissions are lost due to non-authentication. Since feedback is eschewed, the entire process of coding, transmission, and decoding is accomplished in a single forward pass.

In general, error-control coding adds redundancy to the stream. Repetition codes, for example, involve retransmitting each packet a fixed number of times. While simple, repetition codes are not very efficient. As we will see in the next section, it is possible to achieve a five- to ten-fold improvement in coding overhead with a modest effort.

For our purposes, we focus on Reed-Solomon (RS) codes over the finite field GF(2^m). An RS(n; k) code consists of n = 2^m - 1 symbols, where the first k are source symbols and the remaining n - k are parity check symbols that add redundancy.

Reed-Solomon codes have several appealing features for our application:
- They can be implemented efficiently using public domain software.
- They are well-suited for situations where bit transmission errors occur in bursts.
- They can be efficiently combined or concatenated with other codes to form even more powerful codes.

Most importantly, an RS(n; k) code can recover from any combination of up to n - k erasures. If it is desired to provide erasure protection for up to ' erasures out of k source symbols, any Reed-Solomon code with length n ≥ k + ' and dimension k will provide the necessary level of erasure protection. If ' > n - k, the code protects against more than the required ' erasures. In this case, one can elect to keep just the first ' parity check symbols in each codeword along with the k source symbols, dropping the remaining n - k - ' parity check symbols. The resulting code is called a punctured Reed-Solomon code, which has a rate of k / (k + ') and may significantly reduce coding overhead compared to the original k / n rate.

Other codes with similar characteristics, such as Rabin’s Information Dispersal Algorithm, may also be used. For situations where decoding cost is important, one may trade space for time using codes like Tornado codes. For more details, see Luby et al. [20], Park et al. [15], and Rizzo [21].

### Formal Analysis of BAS

#### B.1 Loss Recovery Analysis

The simplest loss model assumes that packets are dropped independently with a fixed probability p. Suppose the hash/parity stream of a transmission group consists of n' packets, including k hash packets and ' = n' - k parity packets. These parity packets are obtained by puncturing an (n; k) systematic Reed-Solomon code and selecting ' ≤ n - k parity packets. Consider the transmission of the n' = k + ' hash/parity packets over a packet erasure channel with packet loss probability p. Assume there are no packet insertions, i.e., no DoS attack on the hash/parity stream.

Let the integer-valued random variable S denote the number of dropped packets in the hash/parity stream of the transmission group. The probability that S does not exceed ' represents our confidence in the recoverability of all hash packets corresponding to a given transmission group. This confidence also represents the long-run fraction of transmission groups that are authenticatable, assuming no DoS attacks. Typically, we require a confidence of at least 99% that all hash packets in a group are recovered, so fewer than one in a hundred groups are compromised.

Since packet drops are independent, S follows a binomial distribution. Exponential tail bounds can be used to estimate the tail probability:

\[
\Pr(S > \ell) < \exp\left(-\frac{(n - (k + \ell))D\left(\frac{\ell}{k + \ell} \parallel \frac{p(k + \ell)}{\ell}\right)}{\ell}\right)
\]

where \( D \) denotes the Kullback-Leibler divergence between the probability distributions \(\left(\frac{\ell}{k + \ell}, \frac{k}{k + \ell}\right)\) and \((p, 1 - p)\). The first bound is due to Chernoff [2], and the second, slightly more analytically amenable, is due to Hoeffding [18].

Given a value of k and a desired confidence 1 - δ (where δ = 0.01, for example), one typically wishes to determine a value of ' for which the desired confidence is attained. Inverting Hoeffding’s bound, we obtain that if the number of parity packets per transmission group satisfies:

\[
\ell \geq \frac{kp}{1 - p} \left(1 + \sqrt{1 - 8k(1 - p) \log \delta} \right) \frac{\log \delta}{4(1 - p)^2}
\]

then all k hash packets in a given transmission group can be recovered with confidence at least 1 - δ. In practice, the values of ' provided by Hoeffding’s bound are only slightly larger than those provided by Chernoff’s bound; see Table 3, where, for a given value of k, ' denotes the Chernoff estimate of the parity overhead, 'H denotes the Hoeffding estimate, and '0 is the parity overhead that results if a naive repetition code were used instead of a Reed-Solomon code.

#### B.2 Denial of Service Attacks

A DoS attack may target the data stream, hash/parity stream, or signature stream, or an attacker may spread resources across these streams. In a shared channel model, the attack is in the form of a flood of spurious packets that mimic the characteristics of the packets in the stream under attack, such as bearing sequence numbers of legitimately expected packets.

We can consider attacks on each of the three streams in isolation. A combination attack effectively reduces the attack factor of the adversary in each stream as their resources must be spread across the streams. A successful attack on a data packet results in the effective loss of that packet as it cannot be verified; a successful attack on a hash packet invalidates the group of data packets whose hashes have been compromised; a successful attack on a signature packet compromises the entire transmission group.

Of these attacks, a signature flood attack is potentially the most damaging, as an adversary can invalidate an entire transmission group in one fell swoop if the attack is successful. We begin with an analysis of signature flooding attacks and how the BAS protocol copes with such attacks.

As a design parameter, we require that the protocol provide a guaranteed confidence of 1 - δ that any given transmission group is verifiable. Here, δ ∈ (0, 1) is our confidence parameter, which we set to δ = 0.01 in our simulations. Two additional design parameters are the authentication and loss recovery overhead o, which is the fraction of packets in a transmission group devoted to authentication and error or loss recovery, and the sender-side authentication latency τ, which is the delay between the beginning of transmission of data in a transmission group and the completion of transmission of packets needed to authenticate the group. The overhead and latency are related. In our analysis, we assume that the maximum overhead o is specified as a design parameter, and the latency τ is then determined as a function of o and δ. Alternatively, we could specify a maximum latency that the application can withstand and determine the overhead incurred as a consequence. The latter may be more appropriate in certain scenarios.