# 40 \| 运用学过的设计原则和思想完善之前讲的性能计数器项目（下）上一节课中，我们针对版本 1 存在的问题（特别是 Aggregator类、ConsoleReporter 和 EmailReporter类）进行了重构优化。经过重构之后，代码结构更加清晰、合理、有逻辑性。不过，在细节方面还是存在一些问题，比如ConsoleReporter、EmailReporter类仍然存在代码重复、可测试性差的问题。今天，我们就在版本 3中持续重构这部分代码。 除此之外，在版本 3中，我们还会继续完善框架的功能和非功能需求。比如，让原始数据的采集和存储异步执行，解决聚合统计在数据量大的情况下会导致内存吃紧问题，以及提高框架的易用性等，让它成为一个能用且好用的框架。 话不多说，让我们正式开始版本 3的设计与实现吧！ 代码重构优化我们知道，继承能解决代码重复的问题。我们可以将 ConsoleReporter 和EmailReporter 中的相同代码逻辑，提取到父类 ScheduledReporter中，以解决代码重复问题。按照这个思路，重构之后的代码如下所示：     public abstract class ScheduledReporter {      protected MetricsStorage metricsStorage;      protected Aggregator aggregator;      protected StatViewer viewer;      public ScheduledReporter(MetricsStorage metricsStorage, Aggregator aggregator, StatViewer viewer) {        this.metricsStorage = metricsStorage;        this.aggregator = aggregator;        this.viewer = viewer;      }      protected void doStatAndReport(long startTimeInMillis, long endTimeInMillis) {        long durationInMillis = endTimeInMillis -  startTimeInMillis;        Map> requestInfos =                metricsStorage.getRequestInfos(startTimeInMillis, endTimeInMillis);        Map requestStats = aggregator.aggregate(requestInfos, durationInMillis);        viewer.output(requestStats, startTimeInMillis, endTimeInMillis);      }    }ConsoleReporter 和 EmailReporter代码重复的问题解决了，那我们再来看一下代码的可测试性问题。因为ConsoleReporter 和 EmailReporter 的代码比较相似，且 EmailReporter的代码更复杂些，所以，关于如何重构来提高其可测试性，我们拿 EmailReporter来举例说明。将重复代码提取到父类 ScheduledReporter 之后，EmailReporter代码如下所示：     public class EmailReporter extends ScheduledReporter {      private static final Long DAY_HOURS_IN_SECONDS = 86400L;      private MetricsStorage metricsStorage;      private Aggregator aggregator;      private StatViewer viewer;      public EmailReporter(MetricsStorage metricsStorage, Aggregator aggregator, StatViewer viewer) {        this.metricsStorage = metricsStorage;        this.aggregator = aggregator;        this.viewer = viewer;      }      public void startDailyReport() {        Calendar calendar = Calendar.getInstance();        calendar.add(Calendar.DATE, 1);        calendar.set(Calendar.HOUR_OF_DAY, 0);        calendar.set(Calendar.MINUTE, 0);        calendar.set(Calendar.SECOND, 0);        calendar.set(Calendar.MILLISECOND, 0);        Date firstTime = calendar.getTime();        Timer timer = new Timer();        timer.schedule(new TimerTask() {          @Override          public void run() {            long durationInMillis = DAY_HOURS_IN_SECONDS * 1000;            long endTimeInMillis = System.currentTimeMillis();            long startTimeInMillis = endTimeInMillis - durationInMillis;            doStatAndReport(startTimeInMillis, endTimeInMillis);          }        }, firstTime, DAY_HOURS_IN_SECONDS * 1000);      }    }前面提到，之所以 EmailReporter可测试性不好，一方面是因为用到了线程（定时器也相当于多线程），另一方面是因为涉及时间的计算逻辑。 实际上，在经过上一步的重构之后，EmailReporter 中的 startDailyReport()函数的核心逻辑已经被抽离出去了，较复杂的、容易出 bug 的就只剩下计算firstTime的那部分代码了。我们可以将这部分代码继续抽离出来，封装成一个函数，然后，单独针对这个函数写单元测试。重构之后的代码如下所示：     public class EmailReporter extends ScheduledReporter {      // 省略其他代码...      public void startDailyReport() {        Date firstTime = trimTimeFieldsToZeroOfNextDay();        Timer timer = new Timer();        timer.schedule(new TimerTask() {          @Override          public void run() {            // 省略其他代码...          }        }, firstTime, DAY_HOURS_IN_SECONDS * 1000);      }      // 设置成protected而非private是为了方便写单元测试      @VisibleForTesting      protected Date trimTimeFieldsToZeroOfNextDay() {        Calendar calendar = Calendar.getInstance(); // 这里可以获取当前时间        calendar.add(Calendar.DATE, 1);        calendar.set(Calendar.HOUR_OF_DAY, 0);        calendar.set(Calendar.MINUTE, 0);        calendar.set(Calendar.SECOND, 0);        calendar.set(Calendar.MILLISECOND, 0);        return calendar.getTime();      }    }简单的代码抽离成 trimTimeFieldsToZeroOfNextDay()函数之后，虽然代码更加清晰了，一眼就能从名字上知道这段代码的意图（获取当前时间的下一天的0点时间），但我们发现这个函数的可测试性仍然不好，因为它强依赖当前的系统时间。实际上，这个问题挺普遍的。一般的解决方法是，将强依赖的部分通过参数传递进来，这有点类似我们之前讲的依赖注入。按照这个思路，我们再对trimTimeFieldsToZeroOfNextDay()函数进行重构。重构之后的代码如下所示：    public class EmailReporter extends ScheduledReporter {      // 省略其他代码...      public void startDailyReport() {        // new Date()可以获取当前时间        Date firstTime = trimTimeFieldsToZeroOfNextDay(new Date());        Timer timer = new Timer();        timer.schedule(new TimerTask() {          @Override          public void run() {            // 省略其他代码...          }        }, firstTime, DAY_HOURS_IN_SECONDS * 1000);      }      protected Date trimTimeFieldsToZeroOfNextDay(Date date) {        Calendar calendar = Calendar.getInstance(); // 这里可以获取当前时间        calendar.setTime(date); // 重新设置时间        calendar.add(Calendar.DATE, 1);        calendar.set(Calendar.HOUR_OF_DAY, 0);        calendar.set(Calendar.MINUTE, 0);        calendar.set(Calendar.SECOND, 0);        calendar.set(Calendar.MILLISECOND, 0);        return calendar.getTime();      }    }经过这次重构之后，trimTimeFieldsToZeroOfNextDay()函数不再强依赖当前的系统时间，所以非常容易对其编写单元测试。你可以把它作为练习，写一下这个函数的单元测试。不过，EmailReporter 类中 startDailyReport()还是涉及多线程，针对这个函数该如何写单元测试呢？我的看法是，这个函数不需要写单元测试。为什么这么说呢？我们可以回到写单元测试的初衷来分析这个问题。单元测试是为了提高代码质量，减少bug。如果代码足够简单，简单到 bug无处隐藏，那我们就没必要为了写单元测试而写单元测试，或者为了追求单元测试覆盖率而写单元测试。经过多次代码重构之后，startDailyReport()函数里面已经没有多少代码逻辑了，所以，完全没必要对它写单元测试了。功能需求完善经过了多个版本的迭代、重构，我们现在来重新 Review一下，目前的设计与实现是否已经完全满足第 25讲中最初的功能需求了。最初的功能需求描述是下面这个样子的，我们来重新看一下。>  > 我们希望设计开发一个小的框架，能够获取接口调用的各种统计信息，比如响应时间的最大值（max）、最小值（min）、平均值（avg）、百分位值（percentile），接口调用次数（count）、频率（tps）> 等，并且支持将统计结果以各种显示格式（比如：JSON> 格式、网页格式、自定义显示格式等）输出到各种终端（Console 命令行、HTTP> 网页、Email、日志文件、自定义输出终端等），以方便查看。> > >经过整理拆解之后的需求列表如下所示：>  > 接口统计信息：包括接口响应时间的统计信息，以及接口调用次数的统计信息等。> > >>>  > 统计信息的类型：max、min、avg、percentile、count、tps> 等。> >>>  > 统计信息显示格式：JSON、HTML、自定义显示格式。> > >>>  > 统计信息显示终端：Console、Email、HTTP> 网页、日志、自定义显示终端。> > >经过挖掘，我们还得到一些隐藏的需求，如下所示：>  > 统计触发方式：包括主动和被动两种。主动表示以一定的频率定时统计数据，并主动推送到显示终端，比如邮件推送。被动表示用户触发统计，比如用户在网页中选择要统计的时间区间，触发统计，并将结果显示给用户。> > >>  > 统计时间区间：框架需要支持自定义统计时间区间，比如统计最近 10> 分钟的某接口的 tps、访问次数，或者统计 12 月 11 日 00 点到 12 月 12 日> 00> 点之间某接口响应时间的最大值、最小值、平均值等。> > >>  > 统计时间间隔：对于主动触发统计，我们还要支持指定统计时间间隔，也就是多久触发一次统计显示。比如，每间隔> 10s 统计一次接口信息并显示到命令行中，每间隔 24> 小时发送一封统计信息邮件。> > >版本 3已经实现了大部分的功能，还有以下几个小的功能点没有实现。你可以将这些还没有实现的功能，自己实现一下，继续迭代出框架的第4 个版本。 1.  被动触发统计的方式，也就是需求中提到的通过网页展示统计信息。实际上，这部分代码的实现也并不难。我们可以复用框架现在的代码，编写一些展示页面和提供获取统计数据的接口即可。        2.  对于自定义显示终端，比如显示数据到自己开发的监控平台，这就有点类似通过网页来显示数据，不过更加简单些，只需要提供一些获取统计数据的接口，监控平台通过这些接口拉取数据来显示即可。        3.  自定义显示格式。在框架现在的代码实现中，显示格式和显示终端（比如    Console、Email）是紧密耦合在一起的，比如，Console 只能通过 JSON    格式来显示统计数据，Email 只能通过某种固定的 HTML    格式显示数据，这样的设计还不够灵活。我们可以将显示格式设计成独立的类，将显示终端和显示格式的代码分离，让显示终端支持配置不同的显示格式。具体的代码实现留给你自己思考，我这里就不多说了。        非功能需求完善Review 完了功能需求的完善程度，现在，我们再来看，版本 3的非功能性需求的完善程度。在第 25讲中，我们提到，针对这个框架的开发，我们需要考虑的非功能性需求包括：易用性、性能、扩展性、容错性、通用性。我们现在就依次来看一下这几个方面。1. 易用性所谓的易用性，顾名思义，就是框架是否好用。框架的使用者将框架集成到自己的系统中时，主要用到MetricsCollector 和 EmailReporter、ConsoleReporter 这几个类。通过MetricsCollector 类来采集数据，通过 EmailReporter、ConsoleReporter类来触发主动统计数据、显示统计结果。示例代码如下所示：    public class PerfCounterTest {      public static void main(String[] args) {        MetricsStorage storage = new RedisMetricsStorage();        Aggregator aggregator = new Aggregator();        // 定时触发统计并将结果显示到终端        ConsoleViewer consoleViewer = new ConsoleViewer();        ConsoleReporter consoleReporter = new ConsoleReporter(storage, aggregator, consoleViewer);        consoleReporter.startRepeatedReport(60, 60);                // 定时触发统计并将结果输出到邮件        EmailViewer emailViewer = new EmailViewer();        emailViewer.addToAddress("PI:EMAIL");        EmailReporter emailReporter = new EmailReporter(storage, aggregator, emailViewer);        emailReporter.startDailyReport();        // 收集接口访问数据        MetricsCollector collector = new MetricsCollector(storage);        collector.recordRequest(new RequestInfo("register", 123, 10234));        collector.recordRequest(new RequestInfo("register", 223, 11234));        collector.recordRequest(new RequestInfo("register", 323, 12334));        collector.recordRequest(new RequestInfo("login", 23, 12434));        collector.recordRequest(new RequestInfo("login", 1223, 14234));        try {          Thread.sleep(100000);        } catch (InterruptedException e) {          e.printStackTrace();        }      }    }从上面的使用示例中，我们可以看出，框架用起来还是稍微有些复杂的，需要组装各种类，比如需要创建MetricsStorage 对象、Aggregator 对象、ConsoleViewer 对象，然后注入到ConsoleReporter 中，才能使用ConsoleReporter。除此之外，还有可能存在误用的情况，比如把 EmailViewer传递进了 ConsoleReporter中。总体上来讲，框架的使用方式暴露了太多细节给用户，过于灵活也带来了易用性的降低。为了让框架用起来更加简单（能将组装的细节封装在框架中，不暴露给框架使用者），又不失灵活性（可以自由组装不同的MetricsStorage 实现类、StatViewer 实现类到 ConsoleReporter 或EmailReporter），也不降低代码的可测试性（通过依赖注入来组装类，方便在单元测试中mock），我们可以额外地提供一些封装了默认依赖的构造函数，让使用者自主选择使用哪种构造函数来构造对象。这段话理解起来有点复杂，我把按照这个思路重构之后的代码放到了下面，你可以结合着一块看一下。    public class MetricsCollector {      private MetricsStorage metricsStorage;      // 兼顾代码的易用性，新增一个封装了默认依赖的构造函数      public MetricsCollectorB() {        this(new RedisMetricsStorage());      }      // 兼顾灵活性和代码的可测试性，这个构造函数继续保留      public MetricsCollectorB(MetricsStorage metricsStorage) {        this.metricsStorage = metricsStorage;      }      // 省略其他代码...    }    public class ConsoleReporter extends ScheduledReporter {      private ScheduledExecutorService executor;            // 兼顾代码的易用性，新增一个封装了默认依赖的构造函数      public ConsoleReporter() {        this(new RedisMetricsStorage(), new Aggregator(), new ConsoleViewer());      }      // 兼顾灵活性和代码的可测试性，这个构造函数继续保留      public ConsoleReporter(MetricsStorage metricsStorage, Aggregator aggregator, StatViewer viewer) {        super(metricsStorage, aggregator, viewer);        this.executor = Executors.newSingleThreadScheduledExecutor();      }      // 省略其他代码...    }    public class EmailReporter extends ScheduledReporter {      private static final Long DAY_HOURS_IN_SECONDS = 86400L;      // 兼顾代码的易用性，新增一个封装了默认依赖的构造函数      public EmailReporter(List emailToAddresses) {        this(new RedisMetricsStorage(), new Aggregator(), new EmailViewer(emailToAddresses));      }            // 兼顾灵活性和代码的可测试性，这个构造函数继续保留      public EmailReporter(MetricsStorage metricsStorage, Aggregator aggregator, StatViewer viewer) {        super(metricsStorage, aggregator, viewer);      }      // 省略其他代码...    }现在，我们再来看下框架如何来使用。具体使用示例如下所示。看起来是不是简单多了呢？    public class PerfCounterTest {      public static void main(String[] args) {        ConsoleReporter consoleReporter = new ConsoleReporter();        consoleReporter.startRepeatedReport(60, 60);        List emailToAddresses = new ArrayList<>();        emailToAddresses.add("PI:EMAIL");        EmailReporter emailReporter = new EmailReporter(emailToAddresses);        emailReporter.startDailyReport();        MetricsCollector collector = new MetricsCollector();        collector.recordRequest(new RequestInfo("register", 123, 10234));        collector.recordRequest(new RequestInfo("register", 223, 11234));        collector.recordRequest(new RequestInfo("register", 323, 12334));        collector.recordRequest(new RequestInfo("login", 23, 12434));        collector.recordRequest(new RequestInfo("login", 1223, 14234));        try {          Thread.sleep(100000);        } catch (InterruptedException e) {          e.printStackTrace();        }      }    }如果你足够细心，可能已经发现，RedisMeticsStorage 和 EmailViewer还需要另外一些配置信息才能构建成功，比如 Redis 的地址，Email 邮箱的 POP3服务器地址、发送地址。这些配置并没有在刚刚代码中体现到，那我们该如何获取呢？我们可以将这些配置信息放到配置文件中，在框架启动的时候，读取配置文件中的配置信息到一个Configuration 单例类。RedisMetricsStorage 类和 EmailViewer类都可以从这个 Configuration类中获取需要的配置信息来构建自己。2. 性能对于需要集成到业务系统的框架来说，我们不希望框架本身代码的执行效率，对业务系统有太多性能上的影响。对于性能计数器这个框架来说，一方面，我们希望它是低延迟的，也就是说，统计代码不影响或很少影响接口本身的响应时间；另一方面，我们希望框架本身对内存的消耗不能太大。对于性能这一点，落实到具体的代码层面，需要解决两个问题，也是我们之前提到过的，一个是采集和存储要异步来执行，因为存储基于外部存储（比如Redis），会比较慢，异步存储可以降低对接口响应时间的影响。另一个是当需要聚合统计的数据量比较大的时候，一次性加载太多的数据到内存，有可能会导致内存吃紧，甚至内存溢出，这样整个系统都会瘫痪掉。针对第一个问题，我们通过在 MetricsCollector 中引入 Google GuavaEventBus 来解决。实际上，我们可以把 EventBus 看作一个"生产者 -消费者"模型或者"发布 -订阅"模型，采集的数据先放入内存共享队列中，另一个线程读取共享队列中的数据，写入到外部存储（比如Redis）中。具体的代码实现如下所示：    public class MetricsCollector {      private static final int DEFAULT_STORAGE_THREAD_POOL_SIZE = 20;      private MetricsStorage metricsStorage;      private EventBus eventBus;      public MetricsCollector(MetricsStorage metricsStorage) {        this(metricsStorage, DEFAULT_STORAGE_THREAD_POOL_SIZE);      }      public MetricsCollector(MetricsStorage metricsStorage, int threadNumToSaveData) {        this.metricsStorage = metricsStorage;        this.eventBus = new AsyncEventBus(Executors.newFixedThreadPool(threadNumToSaveData));        this.eventBus.register(new EventListener());      }      public void recordRequest(RequestInfo requestInfo) {        if (requestInfo == null || StringUtils.isBlank(requestInfo.getApiName())) {          return;        }        eventBus.post(requestInfo);      }      public class EventListener {        @Subscribe        public void saveRequestInfo(RequestInfo requestInfo) {          metricsStorage.saveRequestInfo(requestInfo);        }      }    }针对第二个问题，解决的思路比较简单，但代码实现稍微有点复杂。当统计的时间间隔较大的时候，需要统计的数据量就会比较大。我们可以将其划分为一些小的时间区间（比如10分钟作为一个统计单元），针对每个小的时间区间分别进行统计，然后将统计得到的结果再进行聚合，得到最终整个时间区间的统计结果。不过，这个思路只适合响应时间的max、min、avg，及其接口请求 count、tps 的统计，对于响应时间的 percentile的统计并不适用。对于 percentile的统计要稍微复杂一些，具体的解决思路是这样子的：我们分批从 Redis中读取数据，然后存储到文件中，再根据响应时间从小到大利用外部排序算法来进行排序（具体的实现方式可以看一下《数据结构与算法之美》专栏）。排序完成之后，再从文件中读取第count\*percentile（count 表示总的数据个数，percentile 就是百分比，99百分位就是 0.99）个数据，就是对应的 percentile响应时间。 这里我只给出了除了 percentile之外的统计信息的计算代码，如下所示。对于 percentile的计算，因为代码量比较大，留给你自己实现。    public class ScheduleReporter {      private static final long MAX_STAT_DURATION_IN_MILLIS = 10 * 60 * 1000; // 10minutes      protected MetricsStorage metricsStorage;      protected Aggregator aggregator;      protected StatViewer viewer;      public ScheduleReporter(MetricsStorage metricsStorage, Aggregator aggregator, StatViewer viewer) {        this.metricsStorage = metricsStorage;        this.aggregator = aggregator;        this.viewer = viewer;      }      protected void doStatAndReport(long startTimeInMillis, long endTimeInMillis) {        Map stats = doStat(startTimeInMillis, endTimeInMillis);        viewer.output(stats, startTimeInMillis, endTimeInMillis);      }      private Map doStat(long startTimeInMillis, long endTimeInMillis) {        Map> segmentStats = new HashMap<>();        long segmentStartTimeMillis = startTimeInMillis;        while (segmentStartTimeMillis  endTimeInMillis) {            segmentEndTimeMillis = endTimeInMillis;          }          Map> requestInfos =                  metricsStorage.getRequestInfos(segmentStartTimeMillis, segmentEndTimeMillis);          if (requestInfos == null || requestInfos.isEmpty()) {            continue;          }          Map segmentStat = aggregator.aggregate(                  requestInfos, segmentEndTimeMillis - segmentStartTimeMillis);          addStat(segmentStats, segmentStat);          segmentStartTimeMillis += MAX_STAT_DURATION_IN_MILLIS;        }        long durationInMillis = endTimeInMillis - startTimeInMillis;        Map aggregatedStats = aggregateStats(segmentStats, durationInMillis);        return aggregatedStats;      }      private void addStat(Map> segmentStats,                           Map segmentStat) {        for (Map.Entry entry : segmentStat.entrySet()) {          String apiName = entry.getKey();          RequestStat stat = entry.getValue();          List statList = segmentStats.putIfAbsent(apiName, new ArrayList<>());          statList.add(stat);        }      }      private Map aggregateStats(Map> segmentStats,                                                      long durationInMillis) {        Map aggregatedStats = new HashMap<>();        for (Map.Entry> entry : segmentStats.entrySet()) {          String apiName = entry.getKey();          List apiStats = entry.getValue();          double maxRespTime = Double.MIN_VALUE;          double minRespTime = Double.MAX_VALUE;          long count = 0;          double sumRespTime = 0;          for (RequestStat stat : apiStats) {            if (stat.getMaxResponseTime() > maxRespTime) maxRespTime = stat.getMaxResponseTime();            if (stat.getMinResponseTime()  instances              = new ConcurrentHashMap<>();      private IdGenerator() {}      public static IdGenerator getInstance() {        Long currentThreadId = Thread.currentThread().getId();        instances.putIfAbsent(currentThreadId, new IdGenerator());        return instances.get(currentThreadId);      }      public long getId() {        return id.incrementAndGet();      }    }如何实现集群环境下的单例？刚刚我们讲了“进程唯一”的单例和“线程唯一”的单例，现在，我们再来看下，“集群唯一”的单例。首先，我们还是先来解释一下，什么是"集群唯一"的单例。我们还是将它跟"进程唯一""线程唯一"做个对比。"进程唯一"指的是进程内唯一、进程间不唯一。"线程唯一"指的是线程内唯一、线程间不唯一。集群相当于多个进程构成的一个集合，"集群唯一"就相当于是进程内唯一、进程间也唯一。也就是说，不同的进程间共享同一个对象，不能创建同一个类的多个对象。我们知道，经典的单例模式是进程内唯一的，那如何实现一个进程间也唯一的单例呢？如果严格按照不同的进程间共享同一个对象来实现，那集群唯一的单例实现起来就有点难度了。具体来说，我们需要把这个单例对象序列化并存储到外部共享存储区（比如文件）。进程在使用这个单例对象的时候，需要先从外部共享存储区中将它读取到内存，并反序列化成对象，然后再使用，使用完成之后还需要再存储回外部共享存储区。为了保证任何时刻，在进程间都只有一份对象存在，一个进程在获取到对象之后，需要对对象加锁，避免其他进程再将其获取。在进程使用完这个对象之后，还需要显式地将对象从内存中删除，并且释放对对象的加锁。按照这个思路，我用伪代码实现了一下这个过程，具体如下所示：    public class IdGenerator {      private AtomicLong id = new AtomicLong(0);      private static IdGenerator instance;      private static SharedObjectStorage storage = FileSharedObjectStorage(/*入参省略，比如文件地址*/);      private static DistributedLock lock = new DistributedLock();            private IdGenerator() {}      public synchronized static IdGenerator getInstance()         if (instance == null) {          lock.lock();          instance = storage.load(IdGenerator.class);        }        return instance;      }            public synchroinzed void freeInstance() {        storage.save(this, IdGeneator.class);        instance = null; //释放对象        lock.unlock();      }            public long getId() {         return id.incrementAndGet();      }    }    // IdGenerator使用举例    IdGenerator idGeneator = IdGenerator.getInstance();    long id = idGenerator.getId();    IdGenerator.freeInstance();如何实现一个多例模式？跟单例模式概念相对应的还有一个多例模式。那如何实现一个多例模式呢？"单例"指的是，一个类只能创建一个对象。对应地，"多例"指的就是，一个类可以创建多个对象，但是个数是有限制的，比如只能创建3个对象。如果用代码来简单示例一下的话，就是下面这个样子：    public class BackendServer {      private long serverNo;      private String serverAddress;      private static final int SERVER_COUNT = 3;      private static final Map serverInstances = new HashMap<>();      static {        serverInstances.put(1L, new BackendServer(1L, "192.134.22.138:8080"));        serverInstances.put(2L, new BackendServer(2L, "192.134.22.139:8080"));        serverInstances.put(3L, new BackendServer(3L, "192.134.22.140:8080"));      }      private BackendServer(long serverNo, String serverAddress) {        this.serverNo = serverNo;        this.serverAddress = serverAddress;      }      public BackendServer getInstance(long serverNo) {        return serverInstances.get(serverNo);      }      public BackendServer getRandomInstance() {        Random r = new Random();        int no = r.nextInt(SERVER_COUNT)+1;        return serverInstances.get(no);      }    }实际上，对于多例模式，还有一种理解方式：同一类型的只能创建一个对象，不同类型的可以创建多个对象。这里的"类型"如何理解呢？我们还是通过一个例子来解释一下，具体代码如下所示。在代码中，loggername 就是刚刚说的"类型"，同一个 logger name获取到的对象实例是相同的，不同的 logger name获取到的对象实例是不同的。    public class Logger {      private static final ConcurrentHashMap instances              = new ConcurrentHashMap<>();      private Logger() {}      public static Logger getInstance(String loggerName) {        instances.putIfAbsent(loggerName, new Logger());        return instances.get(loggerName);      }      public void log() {        //...      }    }    //l1==l2, l1!=l3    Logger l1 = Logger.getInstance("User.class");    Logger l2 = Logger.getInstance("User.class");    Logger l3 = Logger.getInstance("Order.class");这种多例模式的理解方式有点类似工厂模式。它跟工厂模式的不同之处是，多例模式创建的对象都是同一个类的对象，而工厂模式创建的是不同子类的对象，关于这一点，下一节课中就会讲到。实际上，它还有点类似享元模式，两者的区别等到我们讲到享元模式的时候再来分析。除此之外，实际上，枚举类型也相当于多例模式，一个类型只能对应一个对象，一个类可以创建多个对象。重点回顾好了，今天的内容到此就讲完了。我们来一块总结回顾一下，你需要掌握的重点内容。今天的内容比较偏理论，在实际的项目开发中，没有太多的应用。讲解的目的，主要还是拓展你的思路，锻炼你的逻辑思维能力，加深你对单例的认识。**1.如何理解单例模式的唯一性？**单例类中对象的唯一性的作用范围是"进程唯一"的。"进程唯一"指的是进程内唯一，进程间不唯一；"线程唯一"指的是线程内唯一，线程间可以不唯一。实际上，"进程唯一"就意味着线程内、线程间都唯一，这也是"进程唯一"和"线程唯一"的区别之处。"集群唯一"指的是进程内唯一、进程间也唯一。**2.如何实现线程唯一的单例？**我们通过一个 HashMap 来存储对象，其中 key 是线程 ID，value是对象。这样我们就可以做到，不同的线程对应不同的对象，同一个线程只能对应一个对象。实际上，Java语言本身提供了 ThreadLocal并发工具类，可以更加轻松地实现线程唯一单例。**3.如何实现集群环境下的单例？**我们需要把这个单例对象序列化并存储到外部共享存储区（比如文件）。进程在使用这个单例对象的时候，需要先从外部共享存储区中将它读取到内存，并反序列化成对象，然后再使用，使用完成之后还需要再存储回外部共享存储区。为了保证任何时刻在进程间都只有一份对象存在，一个进程在获取到对象之后，需要对对象加锁，避免其他进程再将其获取。在进程使用完这个对象之后，需要显式地将对象从内存中删除，并且释放对对象的加锁。**4.如何实现一个多例模式？**"单例"指的是一个类只能创建一个对象。对应地，"多例"指的就是一个类可以创建多个对象，但是个数是有限制的，比如只能创建3 个对象。多例的实现也比较简单，通过一个 Map来存储对象类型和对象之间的对应关系，来控制对象的个数。课堂讨论在文章中，我们讲到单例唯一性的作用范围是进程，实际上，对于 Java语言来说，单例类对象的唯一性的作用范围并非进程，而是类加载器（ClassLoader），你能自己研究并解释一下为什么吗？欢迎在留言区写下你的答案，和同学一起交流和分享。如果有收获，也欢迎你把这篇文章分享给你的朋友。