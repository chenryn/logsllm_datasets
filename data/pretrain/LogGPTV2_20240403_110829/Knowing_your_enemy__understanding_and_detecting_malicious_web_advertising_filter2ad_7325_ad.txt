Our training data are derived from the traces collected between
Jun 21st, 2001 and Sep 30th, 2011. The data are classiﬁed into
“likely good”, “known bad”, and “unknown” categories using the
method in Section 5.1. We further divide the “likely good” data into
two equal-size subsets. One of them (Training-likely-good) and
the “known bad” dataset are used for training. The other (Testing-
likely-good) is for evaluating false-positives (FP). The “unknown”
data serves as one testing dataset (Testing-Jun-Sep) for studying the
coverage of MadTracer, together with another testing set (Testing-
Oct) crawled from Oct 1st to Oct 30th, 2011. Table 4 summarizes
these datasets.
MadTracer generates 82 rules from the training data. We ﬁrst
check the false-positives caused by these rules using the subse-
quences in Testing-likely-good, and measure the false positive rate.
Here the false positive (FP) rate is deﬁned as NF P /(NF P +NT N ),
where NF P denotes the number of false positives and NT N is the
number of true negatives. MadTracer detects 0.11% pages and
681#MadTracer
#S&F
scam pages
drive-by-download pages
click-fraud pages
all pages
scam domain-paths
drive-by-download domain-paths
click-fraud domain-paths
all domain-paths
12
216
89
291
23
627
3422
4072
0
104
7
111
0
216
42
258
#FP
0
20
13
32
0
87
125
212
#S&F-MadTracer
#MadTracer-S&F
0
8
1
9
0
20
26
46
12
120
83
189
23
431
3406
3860
FD(%)
0.00%
9.26%
14.61%
11.00%
0.00%
13.88%
3.65%
5.21%
New ﬁndings (%)
100.00%
51.85%
92.13%
61.86%
100.00%
65.55%
98.77%
93.66%
Table 7: Detection results (Testing-Oct dataset). “MadTracer” denotes our detection results. “S&F” denotes the results detected by
Safe Browsing and Forefront. The “New ﬁndings” column computes the percentage of attacks detected by MadTracer over the total
number of attacks detected by MadTracer, SafeBrowsing, or ForeFront.
0.075% domain-paths in the set, which are supposed to be false
alarms. This indicates that the FP rate introduced by our approach
is very low. The details of the study are shown in Table 5.
We then evaluate the performance of MadTracer on Testing-Jun-
Sep and Testing-Oct. MadTracer detects 617 infected publishers
and 9,568 unique malve-rtising domain-paths in total with a false
detection (FD) rate around 5%. We deﬁne the FD rate here as the
number of falsely detected domain-paths or pages over the total
number of detected domain-paths or pages: that is, NF P /(NF P +
NT P ), where NT P is the number of true positives. Given 53,100
out of 90,000 crawled publisher Web pages have display-ad-related
paths, we observe from our data that over 1% of the top Alexa home
pages lead to malvertising. Since these are well reputable domains
with a high volume of trafﬁc, malvertising through them could have
reached a large victim user population. Tables 6 and 7 elaborate the
results.
6.2 Attack Classiﬁcation and Validation
MadTracer is designed to capture the common features of malver-
tising. It does not distinguish the type of attacks (scam, drive-by
downloads and click frauds) for the suspicious paths it detects. To
validate its detection results, we ﬁrst classify those detected cases
heuristically and then work on the cases in individual categories ac-
cording to the suspicious behavior that they exhibit. This validation
process is elaborated below.
Scam. For malicious paths that trigger scam popup windows, we
place them in the likely scam category, as popup windows are fre-
quently related to scam attempts. Those images typically display
catchy contents such as “Your computer is infected” or “You are
the winner”. Besides fake-AV, we also ﬁnd another type of scam—
lottery phishing, as shown in Table 8. Lottery phishing attacks redi-
rect a user’s browser to a phishing page, which announces that the
visitor has won a big prize (e.g., Figure 11). Then the user is asked
to ﬁll in private information such as her cell phone number and
bank account numbers. The information collected can be sold to a
third party or used for identity theft.
Validation: We manually go through the images in the popup win-
dows to validate these scam cases, as their number is small.
Drive-by-downloads. For malicious paths that do not trigger popup
windows, we analyze the locations of the detected 3-node seg-
ments. If such a path segment appears after ad nodes (identiﬁed
by EasyList and EasyPrivacy) on the path, it corresponds to the sit-
uation where attackers redirect users from ad networks to malicious
servers, so we classify it as a likely drive-by-download.
Validation: To validate these attacks, we ﬁrst scan all the nodes in-
volved using Safe Browsing and Forefront. For the remaining ones,
we submit them to Microsoft Forefront for in-depth analysis. They
conﬁrmed that a vast majority of the detected path segments con-
tain malicious executables using new signatures. We conservatively
treat all unconﬁrmed cases as false positives. For the ones detected
by Forefront, we notice that more than half of them are under the
category Exploit:JS/Blacole. This type of exploit is generated by
the Blackhole exploit kit, which is widely used by attackers to set
up exploit servers [25]. This toolkit also includes malicious code
exploiting a number of recent vulnerabilities in Java and Adobe
PDF.
Click-fraud. We ﬁnd that the remaining cases are mostly related
to click fraud. In contrast to legitimate publishers who display ad
links (pointing to advertiser’s landing pages) that users can click,
fraudulent or compromised publishers redirect user trafﬁc through
pay-per-click (PPC) ad networks to ad landing pages automatically,
without showing the ads to users and without the need of user
clicks. Up to our knowledge, this type of click frauds has not been
reported before. Safe Browsing and Forefront fail to detect most of
such click fraud attacks since these attacks do not involve malicious
executables. We present the details of the attacks in Appendix B.
Validation: To validate such attacks, we examine the detected ad
paths based on two prominent properties of click fraud. First, we
examine whether a publisher page contains an invisible iframe [13]
to redirect user trafﬁc automatically without the need of user clicks.
Second, we check whether the path eventually reaches an ad land-
ing page through a PPC ad network. If a path has both properties, it
means that the publisher page successfully redirects a browser to an
ad landing page without actual user clicks, which fulﬁlls a fraud-
ulent click. However, not all click frauds are successful, some of
them may be detected by the PPC networks, so the trafﬁc could not
reach the ﬁnal ad landing pages. To validate such failed cases, we
compare their paths with the successful click-fraud paths. If they
went through the same redirection domain chains as the successful
ones, we regard them as likely click frauds as well.
Tables 6 and 7 list the detailed evaluation results based on the
above validation process. The overall FD rate of our detected malv-
ertising domain-paths is 4.48% for the Testing-Jun-Sep dataset and
5.21% for the Testing-Oct dataset. We present the details of our
ﬁndings and the study on cloaking techniques in Appendix C.
Lottery
Fake AV
# of publisher pages
16
52
# of domain-paths
63
64
Table 8: Detected phishing attack break-down
6.3 Comparison with Existing Techniques
We compare our detection results with those obtained by using
URL and domain attributes only. We ﬁnd 10.2% of the detected
malicious domain-paths display suspicious URL patterns. Thus
compared to URL-based approaches, MadTracer can signiﬁcantly
increase the detection coverage.
Compared with Safe Browsing or Forefront, our method does
miss 46 domain-paths detected by them. However, for the attacks
that were successfully detected by MadTracer, our approach catches
them earlier than existing solutions. Speciﬁcally, throughout Octo-
682In our study, we move one step further to understand the detailed
properties of malvertising paths, including the roles of each en-
tity along the paths and the relationships among them. Our work
complements the existing defense mechanisms. It also allows us to
detect a broader set of other malicious advertising behaviors such
as phishing and click frauds in a lightweight fashion.
Stone-Gross et al. [28] recently reported a study on fraudulent
activities in online ad exchange based on trafﬁc collected from an
ad network. Different from our work, they have not investigated the
topology of malvertising. Wang et al. [33] studied ad distribution
networks and their properties. Their focus is on network perfor-
mance and user latency, while we focus on the implications of ad
network topologies for attack detection.
Our detection approach is based on analyzing 3-node ad path
segments. Previous work has leveraged the n-gram model for pre-
dicting the next item in a sequence [5] or clustering malware sam-
ples [6].
Instead of exploiting the n-gram similarly as previous
work, we work with annotated n-grams with rich node attributes.
We reformulate the malvertising detection problem ad network top-
ologies. From this perspective, we contribute by proposing a new
presentation of topology using simple n-grams as well as demon-
strating its effectiveness.
Research on other attack channels. In addition to online adver-
tising, Blackhat SEO campaigns and spam emails are two other
popular methods for attracting naive Web users. Recent work has
studied the properties of these attacks and proposed a few detection
strategies [16, 20, 15, 18]. Compared to SEO and spam, malver-
tising has received relatively less attention so far, yet it may pose
a much more serious threat to Web security for two reasons. First,
attackers may inﬁltrate large ad networks and thus infect top rank-
ing Web sites with more visitors. Second, attackers could specify
audience proﬁles at their choice through advertising agreements,
and target attacks at the most vulnerable populations (e.g., grand-
parent visitors). Previous work has also shown the effectiveness of
leveraging URL features in detecting redirectors [37] and compro-
mised servers [16]. In our case, we ﬁnd that using URL features
alone is not sufﬁcient, though it does provide a useful signal that
can augment the topological information for detection.
8. DISCUSSION
Our study shows that malvertising is a severe problem on the In-
ternet. By crawling just the top 90,000 Alexa home pages (among
them 53,100 are publisher pages), we ﬁnd that more than 1% of
these well-maintained sites have been exploited to deliver mali-
cious contents or to conduct fraudulent clicks. Considering our
crawling scale is small, the actual malvertising problem can be
more severe. This study calls for the research community to pay
more attention to the malvertising problem.
Towards detection, we make a ﬁrst step toward examining topolo-
gies and develop a method based on analyzing 3-node path seg-
ments. We demonstrate initial success in this direction with real
data and a wide set of real attacks detected. On the other hand, we
have not incorporated other useful features into our design, path
length in particular, not to mention the whole topology of ad net-
works as a graph that could be used to achieve more effective de-
tection. Further study on these issues is an interesting direction for
future research.
The evaluation results show that MadTracer can detect a large
number of malicious advertising cases, with an FD rate round 5%.
We aim to detect as many malvertising cases as possible, instead of
sacriﬁcing the true-positive rate for a low FD rate. For end users,
blocking malicious ads is perhaps more important than mistakenly
blocking legitimate ads. This is different from detecting other ma-
Figure 11: The lottery scam page.
ber, we ran MadTracer Safe Browsing, and Forefront on the traces
collected from the beginning of the month on a daily basis. We ﬁnd
that Forefront usually detects malicious domains on the same day
as our approach, but Safe Browsing on average needs 10.5 more
days before it reports the domain-paths that we caught. Figure 12
shows a histogram that illustrates Safe Browsing’s delays in detec-
tion. We ﬁnd that several malvertising domain-paths in our Testing-
Jun-Sep dataset detected by our approach were not reported by Safe
Browsing until October, which introduces signiﬁcant delay in tak-
ing measures to stop these ongoing attacks.
The early detection ability and the higher coverage of our ap-
proach demonstrate the power of detection using ad paths and rich
node attributes. By focusing on the malvertising infrastructure in-
stead of malicious ad contents, MadTracer has the ability to de-
tect new, stealthy malvertising activities that slip under the existing
malware scanners.
Figure 12: Early detection results.
7. RELATED WORK
Research on malvertising. Malvertising is an emerging threat
but grows fast in recent years [9]. Prior research on this threat
mainly focuses on controlling the behavior of ads in order to pre-
vent malvertising (e.g., [19]). However, these approaches usually
cannot defend against common attacks such as drive-by-download,
and they also requires publishers to change their Web sites.
More general static and dynamic analysis techniques (e.g., [7]
and [21]) could be applied to detect drive-by-download. An ad
network could restrict and sanitize dynamic contents using static
veriﬁers such as ADSafe [8] and its improvements (e.g., [10, 19,
12]). These countermeasures raise the bars for attackers who di-
rectly upload malicious contents to legitimate ad networks. But
they could be easily circumvented by either sophisticated packing
and anti-emulation techniques, or the use of malicious ad networks
through ad syndication.
Ad syndication allows attackers to directly inject malicious code
into a browser without being examined. Previous study [27] showed
that ad syndication is a popular way to distribute drive-by-downloads.
 051015202530350123456710111217181920212223313446505962678389Count of alarmed domains Deltas in days 683licious activities such as spam, where ﬂagging legitimate emails as
spam bears more serious consequences.
To evade detection, attackers may exploit the node features that
we adopt, e.g., by modifying URL patterns or using compromised
old domains instead of registering new domains. Those attempts,
however, should be less effective against MadTrace than approaches
that just look at individual nodes. By exploring the ad infrastruc-
ture, MadTrace forces the attackers to change a sequence of nodes
and their relations, which can be a hard task as those nodes may
be controlled by different malicious parties within the underground
ecosystem [31]. Also, faking ad-speciﬁc features that we utilize