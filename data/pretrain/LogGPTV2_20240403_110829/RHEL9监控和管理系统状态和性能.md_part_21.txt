    ::: itemizedlist
    -   每个周期的说明(IPC)。
    -   最后一次缓存 MISSES 的计数。
    -   在 LLC 中给定 CPU occupies 中程序执行的大小（以 KB 为单位）。
    -   到本地内存的带宽(MBL)。
    -   远程内存的带宽(MBR)。
    :::
-   `x86_energy_perf_policy`{.literal}
    工具让管理员能够定义与性能和能源效率相对的重要性。然后，当这些信息选择在性能和能源效率之间权衡的选项时，可以使用这些信息来影响支持此功能的处理器。
-   `taskset`{.literal} 工具由 `util-linux`{.literal}
    软件包提供。它允许管理员检索和设置正在运行的进程的处理器关联，或启动具有指定处理器关联性的进程。
:::
::: itemizedlist
**其他资源**
-   `turbostat(8)`{.literal}, `numactl(8)`{.literal},
    `numastat(8)`{.literal}, `numa(7)`{.literal}, `numad(8)`{.literal},
    `pqos(8)`{.literal}, `x86_energy_perf_policy(8)`{.literal}, 和
    `taskset(1)`{.literal} man page
:::
:::
::: section
::: titlepage
# []{#configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance.html#types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization}系统拓扑类型 {.title}
:::
在现代计算中，CPU
的概念有误导，因为大多数现代系统具有多个处理器。系统的拓扑是这些处理器互相连接并与其他系统资源的连接的方式。这可能会影响系统和应用程序性能，以及系统的调优注意事项。
以下是现代计算中使用的两种主要拓扑类型：
::: variablelist
[`对称多进程(SMP)拓扑`{.literal}]{.term}
:   SMP
    拓扑允许所有处理器在相同时间内访问内存。但是，因为共享和相同的内存访问本质上会阻止所有
    CPU 进行序列化内存访问，SMP
    系统扩展限制通常被视为不可接受的。因此，所有现代服务器系统都是 NUMA
    机器。
[`非统一内存访问(NUMA)拓扑`{.literal}]{.term}
:   NUMA 拓扑是比 SMP 拓扑更久而开发的。在 NUMA
    系统中，多个处理器通过插槽被物理分组。每个套接字都有一个专用的内存和处理器区域，它们对该内存进行本地访问，它们统称为节点。同一节点上的处理器对该节点的内存银行具有高速度访问，而对内存银行而非其节点上的内存银行而言较慢。
    因此，访问非本地内存时会有一个性能损失。因此，具有 NUMA
    拓扑的系统上性能敏感的应用程序应该访问与执行应用程序的处理器相同的内存，并应尽可能避免访问远程内存。
    对于性能敏感的多线程应用程序，这些应用程序可能会被配置为在特定 NUMA
    节点上执行，而不是特定处理器。这是否适当地取决于您的系统和应用程序的要求。如果多个应用程序线程访问同一缓存的数据，那么可将这些线程配置为在同一处理器上执行。但是，如果多个访问和缓存不同数据在同一处理器上执行的线程，每个线程可能会驱除由上一线程访问的缓存数据。这意味着，每个线程\"misses\"缓存，浪费执行时间从内存中获取数据并在缓存中替换。使用
    `perf`{.literal} 工具检查是否有过多的缓存未命中。
:::
::: section
::: titlepage
## []{#configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance.html#displaying-system-topologies_configuring-an-operating-system-to-optimize-cpu-utilization}显示系统拓扑 {.title}
:::
有许多命令可帮助了解系统拓扑。这个步骤描述了如何确定系统拓扑。
::: itemizedlist
**步骤**
-   显示系统拓扑概述：
    ``` screen
    $ numactl --hardware
    available: 4 nodes (0-3)
    node 0 cpus: 0 4 8 12 16 20 24 28 32 36
    node 0 size: 65415 MB
    node 0 free: 43971 MB
    [...]
    ```
-   要收集有关 CPU 架构的信息，如 CPU、线程、内核、插槽和 NUMA
    节点的数量：
    ``` screen
    $ lscpu
    Architecture:          x86_64
    CPU op-mode(s):        32-bit, 64-bit
    Byte Order:            Little Endian
    CPU(s):                40
    On-line CPU(s) list:   0-39
    Thread(s) per core:    1
    Core(s) per socket:    10
    Socket(s):             4
    NUMA node(s):          4
    Vendor ID:             GenuineIntel
    CPU family:            6
    Model:                 47
    Model name:            Intel(R) Xeon(R) CPU E7- 4870  @ 2.40GHz
    Stepping:              2
    CPU MHz:               2394.204
    BogoMIPS:              4787.85
    Virtualization:        VT-x
    L1d cache:             32K
    L1i cache:             32K
    L2 cache:              256K
    L3 cache:              30720K
    NUMA node0 CPU(s):     0,4,8,12,16,20,24,28,32,36
    NUMA node1 CPU(s):     2,6,10,14,18,22,26,30,34,38
    NUMA node2 CPU(s):     1,5,9,13,17,21,25,29,33,37
    NUMA node3 CPU(s):     3,7,11,15,19,23,27,31,35,39
    ```
-   查看系统的图形表示：
    ``` screen
    # dnf install hwloc-gui
    # lstopo
    ```
    ::: figure
    []{#configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance.html#idm140048853286128}
    **图 13.1. `lstopo`{.literal} 输出**
    ::: figure-contents
    ::: mediaobject
    ![lstopo](images/lstopo.png)
    :::
    :::
    :::
-   查看详细文本输出：
    ``` screen
    # dnf install hwloc
    # lstopo-no-graphics
    Machine (15GB)
      Package L#0 + L3 L#0 (8192KB)
        L2 L#0 (256KB) + L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0
            PU L#0 (P#0)
            PU L#1 (P#4)
           HostBridge L#0
        PCI 8086:5917
            GPU L#0 "renderD128"
            GPU L#1 "controlD64"
            GPU L#2 "card0"
        PCIBridge
            PCI 8086:24fd
              Net L#3 "wlp61s0"
        PCIBridge
            PCI 8086:f1a6
        PCI 8086:15d7
            Net L#4 "enp0s31f6"
    ```
:::
::: itemizedlist
**其他资源**
-   `numactl(8)`{.literal}, `lscpu(1)`{.literal}, 和
    `lstopo(1)`{.literal} man pages
:::
:::
:::
::: section
::: titlepage
# []{#configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance.html#configuring-kernel-tick-time_configuring-an-operating-system-to-optimize-cpu-utilization}配置内核空循环时间 {.title}
:::
默认情况下，Red Hat Enterprise Linux 9
使用无空循环内核，它不会中断空闲的 CPU
来降低功耗，并允许新处理器利用深度睡眠状态。
Red Hat Enterprise Linux 9
还提供了动态无空选项，这对于对延迟敏感型工作负载（如高性能计算或实时计算）非常有用。默认情况下禁用动态无空选项。红帽建议使用
`cpu-partitioning`{.literal} [**TuneD**]{.strong} 配置集为指定为
`isolated_cores`{.literal} 的内核启用动态无空选项。
这个步骤描述了如何永久启用动态无数性行为。
::: orderedlist
**步骤**
1.  要在特定内核中启用动态无空行为，在内核命令行中使用
    `nohz_full`{.literal} 参数指定这些核心。在 16 核系统上，在
    `/etc/default/grub`{.literal} 文件中的
    `GRUB_CMDLINE_LINUX`{.literal} 选项中附加这个参数：
    ``` screen
    nohz_full=1-15
    ```
    这启用了内核 `1`{.literal} 到 `15`{.literal}
    的动态无数性行为，将所有时间保留到唯一未指定的内核（内核
    `0`{.literal}）。
2.  要永久启用动态无空行为，请使用编辑的默认文件重新生成 GRUB2
    配置。在带有 BIOS 固件的系统中执行以下命令：
    ``` screen
    # grub2-mkconfig -o /etc/grub2.cfg
    ```
    在 UEFI 固件的系统中执行以下命令：
    ``` screen
    # grub2-mkconfig -o /etc/grub2-efi.cfg
    ```
3.  当系统引导时，手动将 `rcu`{.literal}
    线程移到非延迟敏感的内核中，在本例中是 core `0`{.literal} ：
    ``` screen
    # for i in `pgrep rcu[^c]` ; do taskset -pc 0 $i ; done
    ```
4.  可选：在内核命令行中使用 `isolcpus`{.literal}
    参数，将特定内核与用户空间任务隔离开来。
5.  可选：将内核的 `write-back bdi-flush`{.literal} 线程的 CPU
    关联性设置为 housekeeping 内核：
    ``` screen
    echo 1 > /sys/bus/workqueue/devices/writeback/cpumask
    ```
:::
::: itemizedlist
**验证步骤**
-   系统重启后，验证是否启用了 `dynticks`{.literal} ：
    ``` screen
    # journalctl -xe | grep dynticks
    Mar 15 18:34:54 rhel-server kernel: NO_HZ: Full dynticks CPUs: 1-15.
    ```
-   验证动态无空配置是否正常工作：
    ``` screen
    # perf stat -C 1 -e irq_vectors:local_timer_entry taskset -c 1 sleep 3
    ```
    这个命令会在 CPU 1 上测量升级，同时告诉 CPU 1 休眠 3 秒。
-   默认内核计时器配置在常规 CPU 上显示大约 3100 勾号：
    ``` screen
    # perf stat -C 0 -e irq_vectors:local_timer_entry taskset -c 0 sleep 3
     Performance counter stats for 'CPU(s) 0':
                 3,107      irq_vectors:local_timer_entry
           3.001342790 seconds time elapsed
    ```
-   配置动态无数内核后，您应该会看到大约 4 个空循环：
    ``` screen
    # perf stat -C 1 -e irq_vectors:local_timer_entry taskset -c 1 sleep 3
     Performance counter stats for 'CPU(s) 1':
                     4      irq_vectors:local_timer_entry
           3.001544078 seconds time elapsed
    ```
:::
::: itemizedlist
**其他资源**
-   `perf(1)`{.literal} 和 `cpuset(7)`{.literal} man page
-   [关于 nohz_full
    内核参数红帽知识库文章](https://access.redhat.com/solutions/2273531){.link}
-   [如何验证 sysfs 中的\"隔离\"和\"nohz_full\" CPU
    信息列表？红帽知识库文章](https://access.redhat.com/solutions/3875421){.link}
:::
:::
::: section
::: titlepage
# []{#configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance.html#overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization}中断请求概述 {.title}
:::
中断请求或 IRQ
是从硬件立即发送到处理器的信号。系统中的每个设备都会被分配一个或多个 IRQ
编号，允许它发送唯一的中断。启用中断后，接收中断请求的处理器会立即暂停当前应用程序线程执行，以处理中断请求。
由于中断中断会停止正常操作，因此高中断率可能会严重降低系统性能。通过配置中断的关联性，或者向批处理中发送多个较低优先级中断（协调多个中断），这可以减少中断所花费的时间。
中断请求具有关联的关联性属性
`smp_affinity`{.literal}，它定义了处理中断请求的处理器。要提高应用性能，请将中断关联和进程关联分配到同一处理器，或分配到同一内核上的处理器。这允许指定的中断和应用程序线程共享缓存行。
在支持中断中断的系统上，修改中断请求的 `smp_affinity`{.literal}
属性可设置硬件，以便决定使用特定处理器在硬件级别提供中断，而无需在内核中干预。
::: section
::: titlepage
## []{#configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance.html#balancing-interrupts-manually_configuring-an-operating-system-to-optimize-cpu-utilization}手动平衡中断 {.title}
:::
如果您的 BIOS 导出它的 NUMA 拓扑，则 `irqbalance`{.literal}
服务可自动为节点上对请求服务的硬件进行中断请求。
::: orderedlist
**步骤**
1.  检查哪些设备对应于您要配置的中断请求。
2.  查找平台的硬件规格。检查您系统上的芯片组是否支持分发中断。
    ::: orderedlist
    1.  如果这样做，您可以按照以下步骤中的内容配置中断交付。另外，检查您的芯片组用来平衡中断的算法。有些
        BIOS 有一些选项来配置中断交付。
    2.  如果没有，您的芯片组总会将所有中断路由到单个静态
        CPU。您无法配置使用哪些 CPU。
    :::
3.  检查系统上使用了 Advanced Programmable Interrupt
    Controller(APIC)模式：
    ``` screen
    $ journalctl --dmesg | grep APIC
    ```
    在这里，
    ::: itemizedlist
    -   如果您的系统使用 `flat`{.literal}
        以外的模式，您可以看到一个类似于
        `Setting APIC routing to physical flat`{.literal} 的行。
    -   如果看不到这个信息，代表您的系统使用 `flat`{.literal} 模式。
        如果您的系统使用 `x2apic`{.literal} 模式，您可以在
        `引导装载程序配置`{.literal} 的内核命令行中添加
        `nox2apic`{.literal} 选项来禁用它。
        只有非物理平面模式（`flat`{.literal}）支持将中断分发到多个
        CPU。这个模式仅适用于最多 `8`{.literal} 个 CPU 的系统。
    :::
4.  计算 `smp_affinity 掩码`{.literal}。有关如何计算
    `smp_affinity 掩码`{.literal} 的更多信息，请参阅设置 [smp_affinity
    mask](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9-beta/html-single/monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance#setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization){.link}。
:::
::: itemizedlist
**其他资源**