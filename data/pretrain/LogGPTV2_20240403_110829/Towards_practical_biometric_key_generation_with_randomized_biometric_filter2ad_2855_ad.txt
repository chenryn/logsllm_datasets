the impact of selecting different error-correction percentiles (i.e.,
k). Recall that the quantization widths used to error-correct each
feature are ﬁxed across the population, and the level of quantization
is speciﬁed by the value k. For large values of k, users will be
assigned more features, but the features will be easier to forge and
will have lower maximum theoretical entropy. For small values
of k, users will be assigned fewer features, but they will be more
difﬁcult to forge and will have higher maximum theoretical entropy.
To explore this tradeoff, we performed the feature selection process
for k = 20%, k = 30%, and k = 50%.
For k = 20%, 30%, 50%, with τvar = .6, our feature assignment
process resulted in feature sets of size N = 69, 72, 86, respec-
tively. Figure 1 shows a CCDF of the number of features that were
assigned to each user. As is to be expected, the Select algorithm
assigns more features to each user for larger values of k. In fact, for
k = 50%, fewer than 1% of users were assigned no features, 80%
of users were assigned at least 12 features and 50% of the users
were assigned more than 43 features. The results for k = 20% are
not as encouraging: 30.6% of the population were not assigned any
features. This implies that setting k = 20% might not yield a BKG
that is useful for a large percentage of the population.
We also performed an analysis to demonstrate that our feature
selection technique outputs a random subset Φ. We focused on a
BKG with k = 30%, and the maximum number of features in each
template was set to n = 50. For each feature in Φ we computed
the probability that a given feature φi appears in a template, and
the conditional probability that φi appears in a template given that
φj (cid:14)= φi also appears in that template. We measured the observed
probabilities and conditional probabilities. If the selection process
F
D
C
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Number of Features Assigned to Each User
k = 20%
k = 30%
k = 50%
 10
 20
 30
 40
 50
 60
 70
 80
 90
Number of Features
Figure 1: The number of features assigned to each user.
results in a random permutation on a random subset of Φ, then we
would expect φi to appear in a template with probability 0.694. In
this case, we would also expect the conditional probability that φi
and φj both appear in a template to be 0.69. Indeed, our results
are inline with this expectation. In fact, we performed the χ2-Test
of Homogeneity [17] to ensure that the observed probability distri-
bution is indeed uniform, and the χ2-Test of Independence [17] to
ensure that the likelihood that two features appear in a template are
independent. In both cases, we would accept the hypothesis that
feature selection acts as a random permutation on a random subset
with conﬁdence level α = .99. (See the full version of this pa-
per [2] for further details on our testing methodology and results.)
We argue that this provides empirical evidence that our feature as-
signment algorithm achieves the goals that are required to meet the
necessary security properties.
7. SECURITY SKETCH
In this section we provide informal arguments as to why RBTs
are secure. That is, we provide evidence that given access to aux-
iliary information, the template, and the key, an adversary cannot
learn signiﬁcant information about the biometric (REQ-SBP); and
that an adversary cannot use auxiliary information and a biometric
template to distinguish the correct key from random (REQ-KR).
Our arguments are based on the assumption that feature selection
acts as a random permutation on a random n-element subset of Φ,
which we have argued, both constructively (Section 6.1) and em-
pirically (Section 6.2).
7.1 Strong Biometric Privacy
Our conjecture is that since feature assignment results in a ran-
dom permutation of a random n-element subset of Φ, the optimal
strategy for an attacker is to simultaneously enumerate Π and the
set of all biometrics until she derives the correct key. While she can
use the template and key to verify that a guessed biometric sam-
ple/password pair is correct, the attacker cannot use information
gleaned from the template or key to create a guess of the biometric.
Our reasoning for this argument is as follows: assume that an
adversary has access to a template T = (C, v) and K. Note that
since v and the K are the output of public functions, an attacker
can guess a biometric input and a password, run KeyGen with T
and check that the output matches K to test the correctness of her
guesses. Aside from this, since v and K are the output of random
oracles, they cannot be used to determine the values of the enroll-
ment samples.
We now turn our attention to the encoding of the feature indexes
and quantization information, C = ((c0,0, c0,1), (c1,0, c1,1), . . . ,
(cn−1,0, cn−1,1)) . Since each element in C is encrypted under a
potentially low-entropy password, one must show that the entropy
of the plaintext is high, and so an adversary who guesses a correct
password cannot distinguish the original plaintext from a decryp-
tion of C under an incorrect password. If this is the case, then an
adversary who guesses passwords must enumerate the set of bio-
metric samples for each guess to determine whether her guesses are
correct. The point is to show that such an attacker does not glean
any information about the biometric sample from the template, but
rather she simply enumerates samples through auxiliary means. If
true, this implies that REQ-SBP holds.
We now argue the aforementioned point informally as follows.
Let L be the list of indexes that Enroll assigns to the target user,
and G = (γL[0], γL[1], . . . , γL[n−1]) be the randomized encod-
ing of the quantization offsets for each feature in L. Assume that
Enroll uses the two keys k0 ← Hpass,0(π) and k1 ← Hpass,1(π)
to encrypt each of these lists to create the list C. Adopting the
notation that for a function F and a list X = (x1, . . . , xm), that
F(X) = (F(x1), . . . , F(xm)), we decompose C into two parts:
C0 = (c0,0, c1,0, . . . , cn−1,0) = EN
(L)
k0
C1 = (c0,1, c1,1, . . . , cn−1,1) = EΔ
k1 (G)
1) ← (Hpass,0(π(cid:2)), Hpass,1(π(cid:2))),
Our goal is to argue that for all (k(cid:2)
0, k(cid:2)
L is indistinguishable from DN
(C0) and G is indistinguishable
k(cid:2)
0
from DΔ
k(cid:2)
1
(C1).
Note that decryption of C0 or C1 with an incorrect key results in
a random permutation on a random n element subset of the corre-
sponding domain. Since Select assigns a random n element subset
of Φ to each user and the Enroll algorithm randomly permutes this
set to create L, L is a random permutation of a random n element
subset of Φ. Thus, L is indistinguishable from DN
(C0).
k(cid:2)
0
Lastly, to see why G is indistinguishable from DΔ
k(cid:2)
1
(C1), observe
that Enroll creates γi by selecting a random element in [0, Δ] that
is an integer multiple of δi from the border of the smallest quanti-
zation offset (Algorithm 1, lines 7 and 9), which is computed from
the median of the enrollment samples. Since an attacker does not
know this precise median1 γi is also difﬁcult to predict. Thus, γi is
randomly distributed over [0, Δ], and so G is a list of random val-
ues over [0, Δ]. Note that DΔ
(C1), is also a list of random values
k(cid:2)
1
over [0, Δ]. Since L is indistinguishable from DN
(C0) and G is
k(cid:2)
0
indistinguishable from DΔ
k(cid:2)
1
(C1), we argue that REQ-SBP holds.
7.2 Key Randomness
Next, we argue that an adversary cannot use a template, T =
(C, v), to distinguish K from random—i.e., REQ-KR. In our case
this amounts to arguing two properties: C cannot be used to in-
fer the inputs to Hkey (i.e., π, the indexes of the features, and the
quantization offset that contains the user’s sample), and that v can-
not be used to distinguish K from random. To argue that the ﬁrst
property holds, we follow the same argument that we used to argue
REQ-SBP. There, we argued that the best strategy that an attacker
has to ﬁnd the indexes and quantization information is to simulta-
neously enumerate both the password space and biometric space to
ﬁnd the values that were provided to Enroll. This implies that if the
1We assume that for most “normal” biometrics, this median is uni-
formly distributed. We believe this to be a reasonable assumption
as legitimate users cannot even precisely recreate this value.
combined entropy of both the password space and biometric space
are sufﬁciently high, then an attacker cannot infer the input to Hkey.
To argue that v is of no value to an attacker, we note that although
v and K are derived from the same input, they are the outputs of
two independent random oracles. Thus, v leaks no information
about K.
8. EMPIRICAL STUDY
In this section we evaluate our proposal using a host of recently-
proposed techniques. We examine the resiliency to forgery against
of trained forgers [4]; study the impact of generative algorithms [4];
and the test resiliency against the search algorithm described in [3].
Since the goals of this section are to evaluate the strength of the
features that RBTs use, our analyses assume that an adversary has
access to the correct password π. That is, the attacker can correctly
decrypt the template and so her task is only to guess the biometric
input. This implies that the results presented in this section are a
lower bound on the security that the scheme would provide in prac-
tice. Nonetheless, this is an important viewpoint, as it allows eval-
uators to better understand how much extra security the biometric
adds to the strength of the password.
8.1 Resistance to Forgeries
First, we show that RBTs can withstand forgeries from trained
human forgers and generative algorithms. We use the same data set
that was used to analyze feature selection, and apply our techniques
to unencrypted RBT-generated templates. We present results for
RBTs based on two choices of k, and the maximum set of features
that can be encoded into each template (n): one with k = 30% and
n = 50, and the other with k = 50% and n = N.
We generate templates for each user for each combination of k
and n. To compute the FRR we use repeated leave-out-κ cross
validation. Given ν enrollment samples, we randomly choose ν−κ
samples to select features and create a template. Then, we use the
remaining κ samples to create keys with the template, and measure
the number of features that are not successfully recreated. We set
ν and κ to be in the ratio of 3:1 and use all samples in the data set.
This process is repeated 10 times and averages across all 10 runs
are used to compute the FRR.
To compute the FAR, we use all of the user’s samples to create
a template and key, and test the ability of forgers to recreate the
correct key. We only report FRR and FAR for those users who
were assigned a minimum number of features during enrollment.
We classiﬁed other users as failing to enroll. For k = 30% and
k = 50%, the minimum number of features required for enrollment
was set to 4 and 10, respectively.
We evaluated the strength of RBTs using new evaluation method-
ologies [4]. Speciﬁcally, we focus on trained human forgers [4],
and the Concatenative Synthesis (CS) generative algorithm [4]. Re-
call that trained forgers are human forgers whose natural ability to
create forgeries has been improved through training and motiva-
tion. As in previous experiments, we provide trained forgers with a
real-time rendering of the target user’s passphrase during the forg-
ing process. The generative algorithms use limited information
form a target user along with population statistics to create forg-
eries. Speciﬁcally, CS combines real-time samples from a target
user with general population statistics to create forgeries.
Table 2 provides the EERs for RBTs as well as the number of
errors that the BKG must correct after quantization to generate the
correct key. EERs are provided for trained forgers and Concatena-
tive Synthesis, against two different RBTs and against a the “Base-
line” quantization-based BKG of Vielhauer and Steinmetz [22] un-
der the strengthened 36 feature set described in [4]. We compare
ROC Curves for RBTs (k = 50%, n = N)
Guesses Required to Find a Key
 0.5
 0.4
 0.3
 0.2
 0.1
e
t
a
R
r
o
r
r
E
FRR
FAR Trained
FAR CS
 0
 0
 1
 2
 3
 5
 4
 6
Errors Corrected
 7