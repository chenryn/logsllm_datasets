title:SFADiff: Automated Evasion Attacks and Fingerprinting Using Black-box
Differential Automata Learning
author:George Argyros and
Ioannis Stais and
Suman Jana and
Angelos D. Keromytis and
Aggelos Kiayias
SFADiff: Automated Evasion Attacks and Fingerprinting
Using Black-box Differential Automata Learning
George Argyros
Columbia University
PI:EMAIL
Ioannis Stais
University of Athens
PI:EMAIL
Suman Jana
Columbia University
PI:EMAIL
Angelos D. Keromytis
Columbia University
PI:EMAIL
Aggelos Kiayias
University of Edinburgh
PI:EMAIL
ABSTRACT
Finding diﬀerences between programs with similar function-
ality is an important security problem as such diﬀerences can
be used for ﬁngerprinting or creating evasion attacks against
security software like Web Application Firewalls (WAFs)
which are designed to detect malicious inputs to web ap-
plications. In this paper, we present SFADiff, a black-box
diﬀerential testing framework based on Symbolic Finite Au-
tomata (SFA) learning. SFADiff can automatically ﬁnd
diﬀerences between a set of programs with comparable func-
tionality. Unlike existing diﬀerential testing techniques, in-
stead of searching for each diﬀerence individually, SFADiff
infers SFA models of the target programs using black-box
queries and systematically enumerates the diﬀerences be-
tween the inferred SFA models. All diﬀerences between the
inferred models are checked against the corresponding pro-
grams. Any diﬀerence between the models, that does not
result in a diﬀerence between the corresponding programs,
is used as a counterexample for further reﬁnement of the in-
ferred models. SFADiff’s model-based approach, unlike ex-
isting diﬀerential testing tools, also support fully automated
root cause analysis in a domain-independent manner.
We evaluate SFADiff in three diﬀerent settings for ﬁnd-
ing discrepancies between: (i) three TCP implementations,
(ii) four WAFs, and (iii) HTML/JavaScript parsing imple-
mentations in WAFs and web browsers. Our results demon-
strate that SFADiff is able to identify and enumerate the
diﬀerences systematically and eﬃciently in all these settings.
We show that SFADiff is able to ﬁnd diﬀerences not only
between diﬀerent WAFs but also between diﬀerent versions
of the same WAF. SFADiff is also able to discover three
previously-unknown diﬀerences between the HTML/Java-
Script parsers of two popular WAFs (PHPIDS 0.7 and Ex-
pose 2.4.0) and the corresponding parsers of Google Chrome,
Firefox, Safari, and Internet Explorer. We conﬁrm that all
these diﬀerences can be used to evade the WAFs and launch
successful cross-site scripting attacks.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS’16 October 24-28, 2016, Vienna, Austria
c(cid:13) 2016 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-2138-9.
DOI: 10.1145/1235
1.
INTRODUCTION
Software developers often create diﬀerent programs with
similar functionality for various reasons like supporting dif-
ferent target platforms, resolving conﬂicting licenses, accom-
modating diﬀerent hardware constraints and exploring di-
verse performance trade-oﬀs. However, these programs often
suﬀer from subtle discrepancies that cause them to produce
diﬀerent outputs for the same input due to either implemen-
tation bugs or vagueness of the underlying speciﬁcations.
Besides hurting interoperability of the aﬀected programs,
these diﬀerences can also have serious security implications.
An attacker can leverage these diﬀerences for ﬁngerprint-
ing: That is, to identify the exact version of a program
running on a remote server. As diﬀerent programs suﬀer
from diﬀerent vulnerabilities, such ﬁngerprinting informa-
tion is very useful to an attacker for choosing speciﬁc attack
vectors. Besides ﬁngerprinting, the behavioral discrepancies
can also be used to launch evasion attacks against security
software that detects potentially malicious input to a target
program. In such cases, the security software must faithfully
replicate the relevant parts of the input parsing logic of the
target software in order to minimize false negatives. Any
discrepancy between the input parsing logic of the security
software and that of the target program can be used by an
attacker to evade detection while still successfully delivering
the malicious inputs. For example, Web Application Fire-
walls (WAFs) detect potentially malicious input to web ap-
plications such as cross-site scripting (XSS) attack vectors.
Therefore, a WAF must parse HTML/JavaScript code in the
same way as web browsers do. Any inconsistency between
these two parsers can lead to an evasion attack against the
WAF. However, making the WAF HTML/JavaScript pars-
ing logic similar to that of the web browsers is an extremely
challenging and errorprone task as most web browsers do
not strictly follow the HTML standard.
For the reasons mentioned above, automated detection
of the diﬀerences between a set of test programs providing
similar functionality is a crucial component of security test-
ing. Diﬀerential testing is a way for automatically ﬁnding
such diﬀerences by generating a large number of inputs (ei-
ther through black-box fuzzing or white-box techniques like
symbolic execution) and comparing the outputs of the test
programs against each other for each input. However, exist-
ing diﬀerential testing systems have several drawbacks that
prevent them from scaling to real-world systems with large
input space (e.g., WAFs, web browsers, and network pro-
Figure 1: SFADiff archtitecture
tocol implementations). White-box techniques do not scale
to such large systems mostly due to the overhead and com-
plexity of the analysis process. Black-box fuzzing techniques
try to brute-force through the vast input space without any
form of guidance and therefore often fails to focus on the
relevant parts of the input space.
In this paper, we present SFADiff, a black-box diﬀeren-
tial testing framework based on Symbolic Finite Automata
(SFA) learning for automatically ﬁnding diﬀerences between
comparable programs. Unlike existing diﬀerential testing
techniques, instead of searching for each diﬀerence individ-
ually, SFADiff infers SFA models by querying the target
programs in a black-box manner and checks for diﬀerences
in the inferred models. SFADiff also veriﬁes whether the
candidate diﬀerences found from the inferred models indeed
result in diﬀerences in the test programs. If a diﬀerence de-
rived from the inferred models do not result in a diﬀerence
in the actual programs, the corresponding input is reused as
a counterexample to further reﬁne the model.
Comparing two models in order to obtain counterexam-
ples also provides a way to implement an equivalence oracle
which checks the correctness of an inferred model and con-
stitutes an essential component of the learning algorithm. In
practice, simulating such an oracle is a challenging and com-
putationally expensive task (cf.
section 3). Nevertheless,
our diﬀerential testing framework provides an eﬃcient and
elegant way to simulate an equivalence oracle by comparing
the inferred models, thus the term “diﬀerential automata
learning”.
Figure 1 shows an overview of SFADiff architecture. SFAD-
iff has several beneﬁts over the existing approaches: (i) it
explores the diﬀerences between similar programs in a sys-
tematic way and generalizes from the observations through
SFA models; (ii) it can ﬁnd and enumerate diﬀerences be-
tween SFA models eﬃciently; (iii) it can perform root cause
analysis eﬃciently in a domain-independent manner by us-
ing the inferred models; and (iv) it also supports eﬃcient
bootstrapping mechanisms for incremental SFA learning for
programs that only diﬀer slightly (e.g., two versions of the
same program).
We evaluated SFADiff in three diﬀerent settings for ﬁnd-
ing diﬀerences between multiple TCP implementations, be-
tween diﬀerent WAFs, and between the HTML/JavaScript
parsers of WAFs and Web browsers. SFADiff was able to
Figure 2: Types of queries that a learning algorithm
can perform in our learning model.
enumerate a large number of diﬀerences between the TCP
implementations in Linux, FreeBSD, and Mac OSX. In the
WAF setting, SFADiff found multiple diﬀerences between
diﬀerent WAFs as well as between diﬀerent versions of the
same WAF. Finally, SFADiff found three previously-unknown
HTML/JavaScript parsing diﬀerences between two popular
WAFs (PHPIDS 0.7 and Expose 2.4.0) and several major
browsers like Google Chrome, Safari, Firefox, and Internet
Explorer. Our experiments conﬁrmed that all of these diﬀer-
ences can be leveraged to launch successful cross-site script-
ing attacks while evading the vulnerable WAFs.
In summary, our main contributions are as follows:
• In section 4, we describe the design and implemen-
tation of SFADiff, the ﬁrst diﬀerential testing frame-
work based on automata learning techniques. We show
that our framework can be used to perform several se-
curity critical tasks automatically such as ﬁnding eva-
sion attacks, generating ﬁngerprints, and identifying
the root causes of the observed diﬀerences in a domain-
independent manner.
• In section 3, we provide an eﬃcient algorithm to boot-
strap the SFA learning process from an initial model
that allows for eﬃcient incremental inference of similar
programs.
• In section 5, we evaluate SFADiff on eleven appli-
cations from three diﬀerent domains and show that
it is able to ﬁnd a large number of diﬀerences in all
domains, including three previously-unknown evasion
attacks against two popular WAFs, Expose and PH-
PIDS.
2. PRELIMINARIES
2.1 Deﬁnitions
A deterministic ﬁnite automaton (DFA) M over an al-
phabet Σ with set of states Q is speciﬁed by a transition
function δ : Q × Σ → Q. The subset F ⊆ Q is called the
set of accepting states. The language accepted by the au-
tomaton is denoted by L(M ) and contains all those strings
in Σ∗ that, when parsed by the automaton starting from
the initial state q0 ∈ Q, lead to a state in F . Each DFA M
induces a corresponding graph GM = (V, E) where V = Q
and (qi, qj) ∈ E if and only if δ(qi, α) = qj for some a ∈ Σ.
We also denote an edge (qi, qj) ∈ E as qi → qj. We write
∗→ qj to denote that there exists a path in GM between qi
qi
Learning	algorithm	Diﬀerence	analysis		Check	if	the	diﬀerences	are	real	Counterexamples:	refuted	diﬀerences	Bootstrapping	through	ini
x = a
true
q2
x =>
q3
aaaaa
S W 
0

0
1
a> >
0
1
0
0
0
0
1
0
Figure 3: A Symbolic Finite Automaton (SFA) for
the regular expression .*.* and the correspond-
ing entries for the S, W sets from the observation
table.
by Argyros et al. [5]. We present a brief overview of the al-
gorithm below and encourage the interested readers to check
[5] for more details. At a high level, the algorithm attempts
to reconstruct the set of access and distinguishing strings
for the target automaton, from which it is able to recover a
correct model of the target machine. The transitions of the
SFA are generated using a mechanism called the guardgen()