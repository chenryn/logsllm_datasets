### Model Parameters and Real-World Application

For demonstration purposes, the same model parameters were used across all hosts to ensure comparable results. In a real-world scenario, these parameters would vary based on the security configurations of each host. The observation probability parameters would also differ depending on the sensors employed, and the cost vector would be determined by the value of the assets and the consequences of different security states.

### Experimental Results

The models were implemented and used to perform real-time risk assessment on the Lincoln Laboratory dataset. This dataset spans 11,836 seconds and includes 36,635 alerts, of which 84 are USTAT alerts, with the remainder being Snort alerts. The dataset captures an attack in five phases:
- **Phase 1 (IP Sweep):** 1500 - 1920 seconds
- **Phase 2 (sadmint Ping):** 2880 - 3480 seconds
- **Phase 3 (Break-in to Mill, Pascal, and Locke):** 4380 - 4420 seconds
- **Phase 4 (Installation of DDoS Tools):** 5400 seconds
- **Phase 5 (Outbound DDoS Attack):** 7620 seconds

#### Total Assessed Risk for the Lincoln Laboratory Dataset

Figure 3 illustrates the total assessed risk for the entire duration of the Lincoln Laboratory dataset, showing the sum of risks for all 1016 hosts in four subnets. The break-ins to Mill, Pascal, and Locke are clearly visible as peaks in the risk activity. The sadmint ping also introduces a peak, but the IP sweep and DDoS tool installation are less distinguishable. The system maintains a minimum risk of approximately 1200, attributed to a stable security state with a risk level of 1.09 for individual hosts over a sufficiently long interval of "no alert" observations. The stable security state risk for the entire network is 1107. The discrepancy can be explained by the high number (over 2000) of outbound ICMP-related alerts from the router at 172.16.114.1, which should have different HMM parameters.

#### Detailed Risk Assessment for Specific Hosts

Figures 4(a), 4(b), and 4(c) show the assessed risk for hosts Mill, Pascal, and Locke, respectively. Mill and Pascal, equipped with host-based IDSs (USTAT), generate several alerts during the experiment. Phase 3 and 5 of the attack are marked with the maximum risk activity value (100) for all three hosts. Phases 2 and 4 are also visible as peaks, while Phase 1 is barely discernible. Pascal shows more peaks than Mill due to the higher number of USTAT alerts (70 for Pascal, 14 for Mill).

#### Zoomed-In Risk Assessment

Figures 5(a) and 5(b) focus on the total network risk and the risk for Mill during the compromise period (4000s to 6000s). These graphs highlight the two peaks corresponding to phases 3 and 4 of the attack.

### Alert Prioritization

By analyzing the priority of alerts, we evaluated the performance of the alert prioritization mechanism. Excluding the outbound DDoS attack with spoofed IP addresses (93% of total alerts) and the outbound alerts from the router (6% of total alerts), the distribution of alert priorities is as follows:
- Below 20: 52.49%
- 20-40: 28.87%
- 40-60: 6.49%
- 60-80: 2.35%
- 80-100: 9.81%

This indicates that the prioritization mechanism successfully assigns low priority to the majority of alerts, reserving high priority for a small percentage.

### Real Traffic Data from the Technical University of Vienna

The second dataset is based on real network traffic from the Technical University of Vienna, covering nine days of a class B network. For this experiment, we used three days of data from a class C network, with no known security incidents. The IDS used was Snort with the same signature set as in the previous example, and the model parameters were consistent, except for the absence of host-based IDSs.

#### Network Risk Assessment

Figure 6 shows the assessed risk for the full three-day period, with two periods of increased risk activity caused by an increasing number of outbound alerts. The lower bound of the risk is around 280, reflecting the total risk associated with the stable security state of individual host HMMs (1.09 per host, 276.86 for the network).

Figures 7(a), 7(b), 7(c), and 7(d) detail the risk activity over 3.5 hours, corresponding to the second period of increased activity. Figure 7(a) shows three peaks of increased risk and periodic fluctuations for the full network. Figure 7(b) shows the risk for a host with no alert activity. Figure 7(c) shows the risk for a host with outbound alerts, leading to several peaks of maximum risk, determined to be false positives from Snort. Figure 7(d) shows the risk for a web server with periodic peaks of risk values between 20 and 40, caused by probing activity.

#### Alert Prioritization for the Second Dataset

For this dataset, the distribution of alert priorities is:
- Below 20: 46.35%
- 20-40: 49.78%
- 40-60: 1.29%
- 60-80: 0.08%
- 80-100: 2.49%

This again demonstrates the effectiveness of the alert prioritization mechanism, with only a small percentage of alerts assigned high priority values.

### Conclusion

The risk assessment method, with the current configuration and alert classification parameters, effectively assesses the risk and detects several security-relevant incidents. The approach is applicable to real network traffic, though it is dependent on the accuracy of the underlying IDSs, with false positives and negatives affecting the results.