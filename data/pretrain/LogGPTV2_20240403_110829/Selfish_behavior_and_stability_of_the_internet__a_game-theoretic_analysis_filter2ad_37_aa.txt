title:Selfish behavior and stability of the internet: a game-theoretic analysis
of TCP
author:Aditya Akella and
Srinivasan Seshan and
Richard M. Karp and
Scott Shenker and
Christos H. Papadimitriou
Selﬁsh Behavior and Stability of the Internet: A
Game-Theoretic Analysis of TCP∗
Aditya Akella, Srinivasan Seshan
CMU
Richard Karp, Scott Shenker
Christos Papadimitriou
ICSI/UC Berkeley
ABSTRACT
For years, the conventional wisdom [7, 22] has been that the con-
tinued stability of the Internet depends on the widespread deploy-
ment of “socially responsible” congestion control. In this paper,
we seek to answer the following fundamental question: If network
end-points behaved in a selﬁsh manner, would the stability of the
Internet be endangered?
We evaluate the impact of greedy end-point behavior through
a game-theoretic analysis of TCP. In this “TCP Game” each ﬂow
attempts to maximize the throughput it achieves by modifying
its congestion control behavior. We use a combination of analysis
and simulation to determine the Nash Equilibrium of this game.
Our question then reduces to whether the network operates eﬃ-
ciently at these Nash equilibria.
Our ﬁndings are twofold. First, in more traditional environ-
ments – where end-points use TCP Reno-style loss recovery and
routers use drop-tail queues – the Nash Equilibria are reasonably
eﬃcient. However, when endpoints use more recent variations of
TCP (e.g., SACK) and routers employ either RED or drop-tail
queues, the Nash equilibria are very ineﬃcient. This suggests
that the Internet of the past could remain stable in the face of
greedy end-user behavior, but the Internet of today is vulnerable
to such behavior. Second, we ﬁnd that restoring the eﬃciency
of the Nash equilibria in these settings does not require heavy-
weight packet scheduling techniques (e.g., Fair Queuing) but in-
stead can be done with a very simple stateless mechanism based
on CHOKe [21].
Categories and Subject Descriptors
C.2 [Computer Systems Organization]: Computer-
Communication Networks; C.2.1 [Computer-Communication
Networks]: Network Architecture and Design—network com-
munication
General Terms
Design, Performance
∗
This research was sponsored by DARPA under contract F30602-
99-1-0518. Additional support was provided by IBM. Views and
conclusions contained in this document are those of the authors
and should not be interpreted as respresenting the oﬃcial poli-
cies, either expressed or implied, of DARPA, IBM or the U.S.
government.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’02, August 19-23, 2002, Pittsburgh, Pennsylvania, USA.
Copyright 2002 ACM 1-58113-570-X/02/0008 ...$5.00.
1.
INTRODUCTION
Over a decade ago, the Internet suﬀered a series of congestion
collapses leading to the development of TCP’s congestion control
algorithms [15, 3]. This “socially responsible” congestion con-
trol behavior, implemented by the bulk of Internet end-points,
has been given credit for the continued stability of the network.
This paper is an attempt to understand if these social congestion
control algorithms were aptly credited. We ask whether greedy
behavior by network end-points actually results in unstable net-
work conditions such as congestion collapse. The answer to this
question has important implications to network operation. If the
answer is that greedy behavior results in instability, then the rea-
son that the Internet is functioning correctly is either that end-
users are consciously socially responsible or that it is too diﬃcult
to modify end-hosts to behave greedily. Clearly, network opera-
tors cannot rely on either of these conditions persisting and they
should deploy new network mechanisms to ensure that network
end-points do not behave greedily in the future. On the other
hand, if selﬁshness does not result in poor network behavior, then
perhaps there is no need for such mechanisms.
We evaluate the impact of greedy end-point behavior by per-
forming a game-theoretic analysis of TCP. We choose to analyze
TCP since the bulk of bytes transferred in the Internet use TCP.
In addition, as long as applications require reliable data trans-
fer, this preponderance of TCP is likely to continue. We deﬁne
the TCP Game in which TCP ﬂows in a network can adjust their
Additive-Increase Multiplicative-Decrease (AIMD) congestion be-
havior in order to optimize the goodput they achieve. These ﬂows
are allowed to freely change and set their congestion control pa-
rameters, (α, β), where α is the additive increase component and
β is the multiplicative decrease component. Also, these ﬂows
must continue to use the traditional loss-recovery techniques of
timeouts and fast retransmission to provide reliable data transfer.
One might think that a greedy/selﬁsh ﬂow could always gain
by using more aggressive congestion control. However, more ag-
gressive congestion control leads to higher loss rates. Since TCP
loss recovery is not a perfect process, there is always some “cost”
associated with the higher loss rate. When the potential beneﬁt
and cost balance, a ﬂow has nothing to gain.1
Our aim is to determine the congestion parameters (αE , βE)
that are chosen by the ﬂows at Nash equilibrium (where no ﬂow
can gain throughput by unilaterally adjusting its behavior). In
evaluating the impact of greedy end-points, we are not as inter-
ested in the actual value of (αE , βE) as much as the behavior
and eﬃciency of the network under this operating condition. To
evaluate eﬃciency, we measure the the average goodput of any
ﬂow and the average per-ﬂow loss rate at Nash equilibrium.
Since the Nash equilibrium reﬂects a balance between the gains
and the cost related to aggressive behavior, any factor aﬀecting
this balance results in a change of the parameter settings and
the network eﬃciency at Nash equilibrium. Two such factors
1This is in contrast to using modern coding techniques that don’t
rely on loss recovery to achieve reliable transfer. With such meth-
ods, loss recovery is essentially perfect, and aggression will always
pay. In this paper we restrict out attention to TCP and its im-
perfect loss-recovery.
117that we vary in our analysis are the form of loss recovery used by
TCP ﬂows and the queuing discipline implemented by the routers
in the network. More modern loss recovery techniques, such as
SACK [10], reduce the overhead of loss recovery, thereby chang-
ing the balance in favor of more aggressive behavior. Queuing
disciplines (like RED [13], CHOKe [21]) aﬀect the loss rate that
results from varying levels of aggression. For example, at the
extreme, Fair Queuing techniques [7] prevent any ﬂow from re-
ceiving more than its fair share by assigning all additional losses
to the more aggressive ﬂows, thereby removing any incentive to
be aggressive.
Taking the above observations into account, we seek to address
the following questions in this paper:
1. What are the parameter settings of the ﬂows at Nash equi-
librium?
2. How eﬃcient/ineﬃcient is the operation of the network at
Nash equilibrium?
3. What impact do TCP’s loss recovery mechanisms and the
AQM schemes implemented at routers have on the eﬃcient
operation of the network at Nash equilibrium?
Our analysis of a simpliﬁed version of the TCP Game and
simulations in NS-2 [1], show that when ﬂows implement tradi-
tional loss recovery mechanisms (TCP-Reno) and FIFO drop-tail
buﬀers are employed, the network operates eﬃciently at the re-
sulting Nash equilibrium (i.e. there is no danger of congestion
collapse). However, the allocation of bandwidth at this equilib-
rium is somewhat unfair [6, 2]. This combination of Reno and
FIFO drop-tail is signiﬁcant since it was common in the Internet
until quite recently. Unfortunately, in all other cases, the Nash
equilibrium is undesirable since either the per-ﬂow goodput is too
low or the per-ﬂow loss rate is too high. We also show that heavy-
weight queueing mechanisms requiring explicit per-ﬂow state are
not necessary to avoid congestion collapse at the Nash equilib-
rium. We show that a minor modiﬁcation to the CHOKe [21]
active queue management policy ensures eﬃcient operation as
well as reasonable fairness at Nash equilibrium.
The remainder of this paper is organized as follows. In Sec-
tion 2 we present related work. Section 3 discusses the TCP Game
in detail and also presents our analysis methodology. In Section 4,
we present analytical and simulation results for the Nash equilib-
rium of the simpliﬁed TCP Game. Section 5 discusses a simple
low-overhead mechanism that encourages a desirable Nash equi-
librium. Finally, Section 6 summarizes the contributions of this
paper.
2. RELATED WORK
There is a substantial literature of game-theoretic approaches
to network resource allocation in general and to congestion control
in particular. We do not provide a detailed review of this work
here, but direct interested readers to a small sampling of the
literature [9, 14, 9, 8, 11, 22]. The approach we take here diﬀers
from these earlier papers in several key respects.
First, the previous literature typically used models where ﬂows
were represented by Poisson streams and routers by M/M/1 queues,
and congestion control consists of adjusting the Poisson transmis-
sion rate. In this paper, we consider the simulated performance
of TCP’s actual packet-level congestion control algorithms, in-
cluding loss-recovery and window adjustment. Second, instead of
considering general congestion control algorithms, we restrict our
attention to the AIMD family of window adjustment algorithms.
Third, while these previous treatments considered a wide class of
utility functions (often concave functions of delay and through-
put), we assume all users are interested in maximizing goodput.
Thus, our work uses a more realistic but more limited model of
congestion control, and we pay careful attention to the impact of
loss-recovery algorithms. Our modeling choices reﬂects our un-
derlying question: what would happen if users freely chose their
TCP AIMD parameters?
Our work is also closely related to [2]. In this work, the authors
evaluate the four linear congestion control algorithms - AIMD,
AIAD, MIMD and MIAD - in the context of various loss recov-
ery and queue management algorithms and under a variety of
variations in the available bandwidth. The paper concludes that
AIAD provides comparable (and sometimes better) eﬃciency to
AIMD in most settings. We use these results as a guide to judge
the eﬃciency/ineﬃciency of the Nash equilibria we analyze in this
paper.
Finally, the simple penalty-based model for the variants of TCP
that we present in Section 3.3 is similar to that presented in [16].
3. THE TCP GAME
In this section, we describe the TCP Game in detail. We ﬁrst
state the assumptions we make in order to simplify the game.
Next, we discuss the dimensions along which the TCP Game can
be analyzed. Finally, we describe a penalty-based model for TCP
that we use in our analysis of the TCP Game in later sections.
3.1 A Few Simplifying Assumptions
In the TCP Game each TCP end-point attempts to maximize
its own goodput. To achieve this goal, each TCP end-point
is given the freedom to adjust its congestion control behavior.
Formally, we assume that we are given a set of n TCP ﬂows,
F1, . . . , Fn, all implementing the Additive Increase Multiplicative
Decrease (AIMD) algorithm for congestion avoidance and control.
We allow each ﬂow Fi to modify its additive increase constant
(αi ≥ 1) and its multiplicative decrease constant (βi ∈ (0, 1)).
In addition, we make the following simplifying assumptions:
(I) All ﬂows in the network implement the same algorithms for
timeout, fast retransmission, selective
loss recovery (e.g.
acknowledgments, etc.).
(II) All the ﬂows have an inﬁnite amount of data to send.
(III) All the ﬂows encounter a single common bottleneck. We
assume that the capacity of the bottleneck link, deﬁned as
the number of packets that it can transmit in unit time, is
ﬁxed.
(IV) All ﬂows have identical round-trip times.
(V) The amount of buﬀering at the bottleneck router is ﬁxed
at the bandwidth-delay product of the simple topology re-
sulting from the above assumptions.
When packets are successfully acknowledged, each ﬂow Fi in-
creases its transmission rate as dictated by the increase parameter
αi. Flows react to packet loss by decreasing their transmission
rate. This rate reduction is dictated by two factors: the decrease
parameter βi and the loss recovery algorithm implemented by the
ﬂow. This is described in greater detail in Section 3.3.
Let Gi denote the average number of useful (i.e., distinct) pack-
ets of ﬂow Fi that are successfully delivered in unit time (where
we choose the common RTT as the unit of time). Gi is the good-
put of ﬂow Fi.
In the TCP Game, the aim of each ﬂow is to
choose its parameters (αi, βi) so that Gi is as high as possible.
Notice that such a choice for ﬂow Fi is dependent on the setting
chosen by each of the remaining n − 1 ﬂows. When for each ﬂow
Fi, the parameters (αi, βi) are chosen such that, given the pa-
rameters (αj , βj ) for j (cid:5)= i, no other choice of parameters for ﬂow
Fi yields a higher value of Gi, the TCP Game is said to be at a
Nash equilibrium.
In our analysis of the TCP Game, we are interested in two
key properties of the Nash equilibrium: the parameter settings
of the ﬂows and the resulting eﬃciency of the network. We are
not concerned with how the Nash equilibrium is attained through
iterative adjustment of the ﬂow control parameters. Our paper
thus addresses the following question: If the Internet were such
that all TCP-AIMD ﬂows were at Nash equilibrium, how would
their parameters be set and how eﬃciently would the Internet
be operating? We use the average per-ﬂow statistics of goodput
and loss rate to measure the eﬃciency of the network at Nash
equilibrium.
3.2 Factors Affecting the TCP Game
The value of Gi attained by a ﬂow in this game, and therefore
the Nash equilibrium of the TCP Game, is dependent on many
factors. Important among these are: (i) the congestion control
118parameters, (ii) the nature of the loss recovery algorithm, and
(iii) the way losses are assigned at the bottleneck router. Factor
(iii) depends on the router queueing and buﬀer management algo-
rithms, and thus is under the control of network administrators.
Factor (ii) is controlled by the set of algorithms supported by
a TCP implementation and the contents of TCP packet headers
(e.g., SACK blocks). As a result, only Factor (i) is under complete
control of a single end-user (the source), and is the only factor
we allow users to adjust to gain advantage; we consider the other
two factors as being important components of the environment
in which the agents are playing the TCP Game. In this section,
we describe each of these factors in turn.
The congestion control algorithm employed by a TCP ﬂow can
be looked upon as a mechanism that the ﬂow uses to probe for
available bandwidth. There are two axes along which each AIMD
ﬂow could change its parameters:
• Varying α. By choosing a higher α, a greedy ﬂow could
try to grab the available bandwidth at a much quicker rate
and gain an advantage over competing ﬂows.
• Varying β. By choosing a β closer to one, a greedy ﬂow
can choose to give up bandwidth more slowly upon conges-
tion.
In general, ﬂows would adjust both α and β simultaneously.
However, to make both the analysis and the presentation of the
results more accessible, in this paper we focus on two restricted
cases: (i) all ﬂows vary their α but hold β ﬁxed and (ii) all ﬂows
vary their β but hold α ﬁxed. We present results from both
analysis and simulations for these two cases in detail in Section 4
of this paper. In addition, we also summarize the initial results
from our simulations of the more general scenario, where ﬂows are
allowed to adjust α and β simultaneously, in Section 4 without
presenting the relevant analysis.
The loss recovery schemes in early versions of TCP, like Reno,
are primitive and cause the TCP ﬂow to show a rather drastic re-
action to losses. For example, when a TCP-Reno ﬂow loses more
than a couple of packets within a single congestion window, it
is forced to time-out and restart [10]. Modern versions of TCP,
like SACK, use more tolerant loss recovery mechanisms that can
sustain many more losses without the ﬂow having to incur time-
outs. Since by being more aggressive a ﬂow has a greater chance
of losing packets and since the reaction to losses is directly de-
pendent on the loss recovery algorithm, the form of loss recovery
implemented by the ﬂows participating in the TCP Game has an
eﬀect on the the nature of the Nash equilibrium.
Traditional queueing and buﬀer management schemes like drop-
tail and RED do not actively penalize aggressive ﬂows. How-
ever, drop-tail may unintentionally penalize aggressive ﬂows since
packet bursts, a common characteristic of aggressive behavior, of-
ten incur drops under drop-tail queue management. In addition,
several proposed (but not widely deployed) queueing and buﬀer
management schemes, such as CHOKe and Fair Queueing, inten-
tionally punish aggressive ﬂows (to varying degrees). Thus, the
queueing and buﬀer management schemes will have an eﬀect on
the resulting Nash equilibrium.
Symmetry is another important aspect of the Nash equilibrium
of the TCP Game that warrants discussion.
In this paper, we
only consider situations where the ﬂows are symmetric (i.e., have
the same RTTs) and we only analyze symmetric Nash equilibria
(i.e., Nash equilibria where the congestion control parameters of
the ﬂows are all equal). We leave the analysis of asymmetric Nash
equilibria for future work.
Summarizing, in this paper we analyze the symmetric Nash
equilibria for the TCP Game under varying combinations of the
queueing and buﬀer management schemes employed at the routers
and the loss recovery mechanisms implemented by the TCP end-
points.
3.3 A Penalty-Based Model for TCP
In this section, we present a penalty-based model for TCP sim-
ilar to that described in [16]. We use this model in our analysis
of the Nash equilibrium. These results will be compared to what
we ﬁnd using more realistic simulations. The purpose is to ﬁnd
a simple model that captures most of the behavior found in the
packet-level simulations but yet remains fairly accessible to anal-
ysis.
of i N t
We divide the duration of transmission of each ﬂow into rounds
each corresponding to one round-trip time (RTT) of the ﬂow. Let
N t
i denote the number of packets that ﬂow Fi has outstanding
in the network in round t. Let Lt
i denote the number of packet
losses experienced by ﬂow Fi in round t. Lt
i depends on the value
i and the queue management algorithm employed by the
bottleneck router. Each ﬂow changes the maximum number of
packets it is allowed to keep outstanding in the network in the
= βiN t
round following t as follows: if Lt
i (multi-
plicative decrease), and if Lt
i + αi (additive
increase). This models the congestion avoidance/control behav-
ior of each ﬂow. Here, we assume that each ﬂow knows about the
losses assigned to it in a given round at the start of the following
round.
i > 0 then N t+1
i
= N t
i = 0 then N t+1
i
Suppose a TCP ﬂow incurs L > 0 losses at time t. Let N be the
number of packets of the ﬂow outstanding at time t. When the
TCP ﬂow experiences one or more losses, it not only adjusts its
window (as described above) but also must recover from the loss.
We model this loss recovery mechanism by a penalty function
that deﬁnes exactly how many packets the ﬂow is allowed have
outstanding in the round(s) immediately following a loss. At
the very high level, there are three forms of penalty: Severe,
Gentle, Hybrid. In a Severe reaction to losses, the TCP ﬂow does
not transmit any data for τS rounds, irrespective of the value of
L. This is equivalent to entering slow-start after incurring losses
(e.g., TCP Tahoe). At time t+τS +1 (after the time out), the TCP
ﬂow restarts by allowing βN packets to be in ﬂight. In a Gentle
reaction to losses, a TCP ﬂow incurs a penalty proportional to the
number of losses observed (by transmitting γL fewer packets than
usual at time t + 1, where γ is a small positive constant). This
penalty reﬂects the cost of retransmissions without time-outs.2
In a Hybrid reaction to losses, the TCP ﬂow incurs a purely
gentle penalty up to a threshold number of losses (L = 1) and
a purely severe penalty after that. The severe part of a Hybrid
reaction diﬀers from a pure Severe penalty in two key aspects.
Firstly, the former models a time-out followed by a slow-start
while the latter models just a slow-start. Secondly, at the end of
the severe penalty in a Hybrid reaction to losses (when L > 1),
the TCP ﬂow restarts with N0 packets outstanding, where N0 is
a positive constant. The reason for these diﬀerences from Severe
penalty will be explained later in this section.
The Severe form of penalty models TCP-Tahoe ﬂows. Tahoe
ﬂows exhibit mostly ﬁxed reaction (fast-retransmit and slow-start)
to losses, irrespective of their number. Also, Tahoe ﬂows reduce
their ssthresh variable by β upon incurring losses, before entering
slow-start. Severe penalty in this form does not explicitly model
the time outs in TCP-Tahoe. In fact, this form of penalty is more
representative of versions of TCP that preceded Tahoe.
TCP-Reno loss recovery can be modeled as a Hybrid penalty.
A Reno ﬂow incurs a gentle penalty for up to a single loss within a
window after which it incurs a severe penalty (by timing out and
slow-starting). In fact, a Reno ﬂow undergoes a few successive
multiplicative decreases spread over as many round-trip times
before timing out. In addition, the value of ssthresh is reduced by
β with each such decrease. By stating that in a Hybrid Reaction,
a TCP ﬂow times out immediately after observing more then a
single loss and that after a time out, the ﬂow restarts by keeping
a constant number of packets outstanding, we are approximating
the eﬀect of these multiple decreases on a Reno ﬂow. The severe
part of the Hybrid penalty subsumes both the time out and the
subsequent slow-start. Thus, the exact value of τS for a Severe