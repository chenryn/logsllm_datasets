combining the real home context with the influence of phantom
user behaviors. The function to ensure context consistency and
integrity of device event sequence is summarized below:
on, cn = C(in, cn−1),
(9)
where in is the output from function S (Equation 8); cn−1 is the
context information; on is the output to help generate final version
of the device event sequence; cn is the updated context.
The function to generate the final device event sequence, den,
for behavior-time pair an = is summarized below:
den = G(on),
(10)
where on is the output from function C (Equation 9).
The overall workflow of generating device event sequence for
a phantom user’s behavior pattern is given in Figure 4, and the
algorithm is presented in Algorithm 2.
Algorithm 2 Device Event Generation for a Phantom User
Input: Behavior pattern BP for a phantom user;
Output: Device event sequence DE = {de1, de2,· · · , den};
parse BP to a list of behavior-time pairs: , 
,· · · , ;
initial v0, c0 based on ; n = 1;
repeat
in, vn = S(F(bn), tn, vn−1, en);
on, cn = C(in, cn−1);
den = G(on);
add den to DE;
n = n + 1;
until n > m
6.3 Packet Injection
After the device event sequence is generated, SniffMislead injects
decoy packets, corresponding to each device event. In order to
fool attackers, SniffMislead needs to make sure that there is no
difference between injected packets and real ones. Given a device
event, SniffMislead obtains the corresponding communication
protocol, network identifier, and traffic pattern from the network
pattern database (Sections 5.1 and 5.2). Fields in packet headers,
transmitted in clear-text, will be filled with meaningful data and
then padded with meaningless payloads to the appropriate lengths;
here, the payloads are considered to be encrypted by attackers.
Below we describe two details. 1) By default, the ZigBee pro-
tocol does not have ACK frames. However, 802.15.4 [4] supports
ACK frames as an option. If SniffMislead notices that a device
indeed sends ACK frames, SniffMislead also forge them for that
device. This is necessary because our fake ZigBee packets will be
discarded by the destination device (as SniffMislead cannot gener-
ate valid message authentication code); thus, SniffMislead needs
to generate the corresponding ACK frames to fool the attacker. Our
evaluation does not find devices that send ACK frames, though.
2) If a device uses MAC randomization [67] (which is not seen in
our evaluation), SniffMislead can observe this and uses the latest
MAC address for forging packets. Again, as SniffMislead does
not have the session key, the forged packets will be discarded by
the destination device.
Finally, the created packets are injected via a packet transmitter.
SniffMislead can be extended to simultaneously support multiple
wireless network protocols that contain packet-level signatures
(e.g., WiFi, ZigBee, and BLE). For example, to handle the ZigBee-
WiFi case (a ZigBee frame is sent to some bridge node that forwards
it to the cloud via WiFi), SniffMislead can be extended to inject
both ZigBee and WiFi packets. That is, SniffMislead uses a ZigBee
transmitter to inject a fake ZigBee packet and a WiFi transmitter
to inject a fake WiFi packet.
Injected Packets in Meshed Networks. Routing/relay nodes in
meshed networks only check layer 2 (e.g., MAC layer) and layer 3
(e.g., network layer) header, and they do not check the (encrypted)
payloads [4]. Only the final destination node authenticates the
payloads. According to the ZigBee routing mechanism, as long as
we can forge a ZigBee frame with the correct MAC-layer header
(including the next-hop MAC address) and network layer header
(including the final destination network address), the packet can be
correctly forwarded, and an attacker can not identify it.
7 EXPERIMENTAL SETUP
In this section, we present our experimental testbed (Section 7.1),
selected thresholds (Section 7.2), and the attackers’ methods used
to evaluate the effectiveness of SniffMislead (Section 7.3).
7.1 Testbed
We configure a smart home in an apartment, using commercial IoT
devices. The testbed setup is shown in Figure 5. Samsung Smart-
Things platform [56] is selected because it is one of the most popular
and representative smart home platforms [34]. We use several Zig-
Bee devices because many smart home IoT devices use ZigBee [31].
We employ a commercial, off-the-shelf sniffer, TelosB Dongle [60],
and an open-source software tool, killerbee [48], to collect Zig-
Bee traffic and inject decoy packets. There is one real user, with
part-time roommates and irregular visitors, in our experimental en-
vironment, who is told to behave as he normally would in his home.
Several common smart apps and automation rules are installed
and configured. Compared to a multi-user scenario, a single-user
smart home environment is more vulnerable to the proposed threat
as it is easier to infer a single ongoing user behavior in a smart
home [1]. Meanwhile, since both SniffMislead and existing meth-
ods [3, 33] can de-multiplex concurrent activities from multiple
users, the number of real users should not affect the experimental
results much.
After deployment, SniffMislead immediately starts to obtain
the required information from the target smart home. Consequen-
tial wireless packets are dumped and grouped according to source
and destination addresses. The dump files are then used to extract
network patterns of device events, device-event-level features of
behaviors, behavior associations, and the real user’s daily routines.
After the first day of learning, SniffMislead is able to generate
41RAID ’21, October 6–8, 2021, San Sebastian, Spain
Xuanyu Liu, Qiang Zeng and Xiaojiang Du, et al.
Figure 5: The experimental setup: a smart home with multiple IoT devices.
Captured wireless packets, belonging to the same device, are
clustered by the burst threshold β. Based on our observations, pack-
ets triggered by a device event are usually transmitted one-by-one
in a very short time interval, less than one second in most cases.
HoMonit [79] measures its burst threshold with integer values,
ranging from 0 to 10 seconds, and finds that the best threshold is
1 second. We perform experiments on our dataset, and the burst
threshold β used is from 0.5 to 2, with an interval of 0.25. We use
the F1 score to indicate the accuracy of whether a device event
is inferred. For each value of β, the average F1 score of all device
events is calculated to denote its efficiency. As shown in Figure 6,
the F1 score achieves the maximum when the threshold is 1 second.
Hence, the burst threshold β is set to 1 second.
Device events belonging to temporally-distinct behaviors are
clustered by the temporal threshold τ. Below are the observations
from an existing work [33]: For one of their datasets, Cairo [70],
only 1% of events have an inter-event time interval of 60 seconds
and higher, and 93% of behaviors have inter-behavior time intervals
of more than 60 seconds. For another dataset, KasterenA [66], 88%
of events have an inter-event time interval less than 120 seconds,
while only 22% of the behaviors have an inter-behavior time interval
less than 120 seconds. Hence, we measure the temporal threshold τ
from 60 to 600 seconds with an interval of 60, based on our dataset.
The precision is defined as the fraction of the correctly segmented
event sets within a behavior. As shown in Figure 6, the precision
achieves the maximum when the threshold is 120 seconds. Hence,
the temporal threshold τ is set to 120 seconds.
7.3 Playing the Role of an Attacker
To evaluate the effectiveness of SniffMislead, we play the role of
an attacker and make use of possible methods to verify whether user
behaviors can still be correctly inferred in the presence of phantom
users and whether SniffMislead can be defeated. To infer a user
behavior, attackers usually perform a two-stage attack [1], including
device event inference and user behavior inference. First, based
on individual packet-level signatures, attackers infer device events
from encrypted wireless traffic. Next, according to the inferred
Figure 6: Evaluation results of the two thresholds. The
lower x-axis shows different burst thresholds. The left y-
axis shows the average F1 score of inferring device events
with different burst thresholds. The upper x-axis shows dif-
ferent temporal thresholds. The right y-axis shows the aver-
age precision of correctly segmented event set within a be-
havior with different temporal thresholds.
policies for placing phantom users. It continuously learns the smart
home, updates its database, and improves its policies. In our testbed,
the default value of λ (Section 6.1) is set to 5%, and it takes eight
days to finalize the number of phantom users as eight. On average,
the real user in our experimental environment generates 30 behav-
iors each day. To protect the user privacy, each phantom user is
assigned a behavior pattern daily, with an average of 30 behaviors,
1500 simulated device events, and more than 11000 injected packets.
7.2 Threshold Selection
We need to find an appropriate burst threshold β (Section 5.2) and
temporal threshold τ (Section 5.3.1), both of which may directly
impact the effectiveness of SniffMislead.
L2L1L3L4L5L6L7M1C1C2P1P2P3P4B2B1B3L7Bathroom LightL6Closet LightL5Table LampL4Bedroom LightL3Livingroom LightL2Kitchen LightL1Hallway LightHallway MotionKitchen MotionM2M3M1M4M2M3M4Livingroom MotionCloset MotionFront Door ContactC1C2Closet ContactP1P2P3P4Kettle PlugRice Cooker PlugComputer PlugPhone PlugB1B2B3Bed ButtonDesk ButtonKitchen ButtonP5P5Fan PlugAQI StationANNA6-in-1 SensorSSound SensorSWWater Leak SensorWSISIAlarm SirenPSPSPresence SensorDevice ListFloor Plan42SniffMislead: Non-Intrusive Privacy Protection against Wireless Packet Sniffers in Smart Homes
RAID ’21, October 6–8, 2021, San Sebastian, Spain
device events, attackers predict user behaviors. The probability of
correctly inferring behaviors relies on the effectiveness of both
stages. To defeat SniffMislead, we consider a strong assumption
of the attacker: he has prior knowledge of the target home, i.e., he
knows the device list, the traffic pattern of each device, the home
and device layout, and the configured automation rules. Based on
existing works (e.g., causal relationship analysis [2, 10, 69] and
context and integrity detection [26, 32, 37, 52]), we design rules to
represent the prior knowledge and build a model to maintain the
home context, both denoted as filters, and aimed to discard decoy
packets or events that do not satisfy these rules or conform to the
home context.
Device Event Inference. The attacker needs to train a detector
to infer device events, hence network patterns of device events
should be exacted first. Unlike the unsupervised method used by
SniffMislead (Section 5.2), supervised methods are used to train
a detector for device event inference, since attackers may have a
supervised learning dataset in advance. Each device event is manu-
ally triggered 100 times. To extract their feature vectors, generated
packets are dumped, marked, and then clustered. After obtaining
feature vectors with labels from the packet sequence, a supervised
learning algorithm is then applied to the dataset. One supervised
learning algorithm is trained, namely Random Forest (RF) classifier,
as it yields good results of device event inference [1]. The algorithm
is used to detect whether injected packets by SniffMislead can be
recognized as expected device events by an attacker and whether
decoy packets are distinguishable from real ones.
User Behavior Inference. After device events are inferred, an-
other detector is needed for attackers to infer user behaviors. Re-
cent works show good performance of using Hidden Markov Model
(HMM) to infer user behaviors in a smart home environment [1, 33,
45, 52]. We choose to use HMM for behavior inference. The charac-
teristics of smart homes make HMM quite suitable to be applied in
a smart home environment [1, 53]. User behaviors are considered
as hidden states. User behaviors cause changes to the state of IoT
devices, defined as visible states. Each hidden state generates one of
the defined visible states. Any user behavior in a smart home can be
predicted by observing the states of the IoT devices. An attacker’s
goal would be to infer the hidden state (i.e., user behaviors) from
the visible state (i.e., states of IoT devices) using HMM. States of
IoT devices can be illustrated with binary output, “1” for the active
status and “0” for inactive status. For a specific time, the smart home
state can be represented as an n-bit binary number with m = 2n
possible states, where n is the total number of device states in the
smart home. The most likely sequence of hidden states can be found
by observing smart devices, using the Viterbi algorithm [68]. The
proposed HMM detector for user behavior inference is trained us-
ing real smart home traffic, without SniffMislead. This detector is
then used to test the effectiveness of inferring user behaviors, after
SniffMislead is used.
8 EVALUATION RESULTS
We present the evaluation results in this section, including the
effectiveness of privacy protection (Section 8.1) and the overhead
and influence to smart home (Section 8.2).
Table 1: Results of device event inference
Device
Contact Sensor
Motion Sensor
Plug
Button
Presence Sensor
Alarm Siren
Water Leak Sensor
Real events
Precision(%)
Recall(%)
97
98
100
100
94
93
95
98
98
99
100
93
91
98
Event
open
active
turn on
click
present
alarm
wet
F1(%) Recall(%)
97.5
98
99.5
100
93.5
92
96.5
97
98
100
100
92
93
96
Decoy events
Precision(%)
98
98
100
100
94
91
97
F1(%)
97.5
98
100
100
93
92
96.5
Table 2: Results of user behavior inference
Precision (%)
Num
Behavior
Leave home
Return home