# Logram: Efficient Log Parsing Using n-Gram Dictionaries

**Authors:**
- Hetong Dai, Student Member, IEEE
- Heng Li, Member, IEEE
- Che-Shao Chen, Student Member, IEEE
- Weiyi Shang, Member, IEEE
- Tse-Hsun (Peter) Chen, Member, IEEE

**Abstract:**
Software systems typically record important runtime information in logs. These logs help practitioners understand system behavior and diagnose failures. Due to the large volume of logs, automated log analysis is essential for efficient software operation and maintenance. The first step in this process is log parsing, which converts unstructured raw logs into structured data. However, log parsing is challenging because the templates used to generate logs are often inaccessible during the parsing process.

Previous work has proposed automated log parsing approaches with high accuracy. However, as the volume of logs grows rapidly in the era of cloud computing, efficiency becomes a major concern. In this paper, we introduce Logram, an automated log parsing approach that leverages n-gram dictionaries to achieve efficient log parsing. We evaluated Logram on 16 public log datasets and compared it with five state-of-the-art log parsing approaches. Our results show that Logram not only achieves higher parsing accuracy but also outperforms existing approaches in terms of efficiency, being 1.8 to 5.1 times faster than the second-fastest approaches in end-to-end parsing time. Additionally, we deployed Logram on Apache Spark, demonstrating its near-linear scalability with the number of Spark nodes without sacrificing parsing accuracy. We also showed that Logram can support effective online parsing, achieving similar results and efficiency to the offline mode.

**Index Terms:**
- Log parsing
- Log analysis
- N-gram

## 1. Introduction

Modern software systems record valuable runtime information in logs, which are crucial for understanding system behavior and diagnosing failures. However, logs are often very large, making manual analysis impractical. Automated log analysis approaches have been developed to assist practitioners with various tasks, such as anomaly detection, failure diagnosis, performance improvement, and system comprehension. Recently, AIOps (Artificial Intelligence for IT Operations) solutions have also heavily relied on automated log analysis.

Logs are generated by logging statements in the source code, which include static text and dynamic variables. During runtime, these statements produce raw log messages, which are lines of unstructured text. To make these logs useful, a log parsing step is needed to convert them into a structured format. The goal of log parsing is to extract the static template, dynamic variables, and header information (e.g., timestamp, log level, and logger name) from raw log messages.

Despite the existence of prior log parsers, the rapid growth in log sizes and the need for low-latency log analysis have made efficiency a critical concern. In this work, we propose Logram, an automated log parsing approach that uses n-gram dictionaries to achieve efficient log parsing. Our intuition is that frequent n-grams are more likely to represent static templates, while rare n-grams are more likely to be dynamic variables. The n-gram dictionaries can be constructed and queried efficiently, with complexities of O(n) and O(1), respectively.

## 2. Background

### 2.1 Log Parsing

The goal of log parsing is to extract the static template, dynamic variables, and header information from raw log messages. While the header information usually follows a fixed format, extracting the templates and dynamic variables is challenging. Table 1 shows simplified log messages and their corresponding static templates and dynamic variables.

| Log Message | Static Template | Dynamic Variables |
|-------------|-----------------|-------------------|
| Found block rdd_42_20 locally | Found block  locally | rdd_42_20 |
| Found block rdd_42_22 locally | Found block  locally | rdd_42_22 |
| Dropping block rdd_42_20 from memory | Dropping block  from memory | rdd_42_20 |
| Dropping block rdd_42_22 from memory | Dropping block  from memory | rdd_42_22 |

### 2.2 N-grams

An n-gram is a subsequence of length n from an item sequence, such as text, speech, or source code. For example, in the sentence "The cow jumps over the moon," the 2-grams (bigrams) are "The cow," "cow jumps," "jumps over," "over the," and "the moon." N-grams have been successfully used to model natural language and source code. In this work, we use n-grams to parse log data efficiently. Frequent n-grams are more likely to be static text, while rare n-grams are more likely to be dynamic variables.

## 3. Related Work

### 3.1 Prior Work on Log Parsing

Existing log parsing approaches can be categorized into rule-based, source code-based, and data mining-based approaches.

- **Rule-based log parsing:** Practitioners and researchers hand-craft heuristic rules (e.g., regular expressions) to parse log data. Modern log processing tools allow users to define custom rules, but this requires significant human effort.
- **Source code-based log parsing:** These approaches use static program analysis to extract log templates from the source code. While highly accurate, they require access to the source code, which is often not available.
- **Data mining-based log parsing:** These approaches do not require the source code and instead use data mining techniques to parse log messages. Examples include SLCT, LogCluster, LFA, LKE, LogSig, LogMine, SHISO, LenMa, AEL, Spell, IPLoM, and Drain.

## 4. Logram Approach

Logram uses n-gram dictionaries to achieve efficient log parsing. It extracts n-grams from log data and stores their frequencies in dictionaries. Frequent n-grams are more likely to be static text, while rare n-grams are more likely to be dynamic variables. The n-gram dictionaries can be constructed and queried efficiently, and they can be updated online in log streaming scenarios.

## 5. Evaluation

We evaluated Logram on 16 public log datasets and compared it with five state-of-the-art log parsing approaches. Our results show that Logram achieves higher parsing accuracy and is 1.8 to 5.1 times faster than the second-fastest approaches in end-to-end parsing time. We also demonstrated that Logram scales efficiently on Apache Spark, achieving near-linear scalability with the number of Spark nodes. Finally, we showed that Logram can support effective online parsing, achieving similar results and efficiency to the offline mode.

## 6. Online Parsing

Logram can support effective online parsing by continuously updating the n-gram dictionaries when new logs are added in a streaming manner. This allows for real-time log analysis without sacrificing parsing accuracy.

## 7. Threats to Validity

We discuss potential threats to the validity of our findings, including the choice of datasets, the evaluation metrics, and the generalizability of our approach.

## 8. Conclusion

In this paper, we introduced Logram, an automated log parsing approach that leverages n-gram dictionaries to achieve efficient log parsing. Our evaluation shows that Logram outperforms existing approaches in terms of accuracy and efficiency. Additionally, Logram can scale efficiently on distributed systems and support online parsing, making it suitable for real-time log analysis. Future work will focus on further improving the efficiency and accuracy of Logram and exploring its applications in various domains.