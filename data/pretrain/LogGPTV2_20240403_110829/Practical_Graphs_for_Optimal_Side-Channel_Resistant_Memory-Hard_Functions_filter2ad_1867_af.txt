tion includes the heuristic optimization from [6]. Finally, we output
the pebbling P with minimal aAT(P) over all choices of the key
parameters dtдt , S and д.
Selecting a Set S. Each depth-reduction algorithm takes as in-
put a target depth dtдt and outputs a set S such that depth(G −
S) ≤ dtдt . The first algorithm is the layered attack of Alwen and
Blocki [5], which has been shown to have good asymptotic perfor-
mance against Argon2i-A [5] and Argon2i-B [6, 20].
log n
(cid:12)(cid:12)Sj
(cid:16) n2 log log n
(cid:17). The first variant (Lazy
(cid:12)(cid:12) until
The next three attacks are based on Lemma 2.2 (Valiant’s Lemma
[44]) which shows a simple method for selecting a set of edges
for reducing the depth of any given DAG by half. All graphs we
consider have constant indegree so we can simply remove, say, the
origins of the selected edges to obtain a similarly sized set of nodes
for reducing the depth by a half. This approach was used in [5]
to provide a generic upper bound on the aAT of any DAG G with
constant indegree: aAT(G) = O
Valiant) simply sets b = 2, computes sets S1, . . . , S⌈logb(depth(G))⌉,
sets T0 = ∅ and greedily updates Ti +1 := Ti ∪ argminj(cid:60)Ti
j∈Ti Sj) ≤ dtдt . The second variant is the same except
that we set b = 3. Finally, the third variant is the one described
by Alwen and Blocki [5]. Briefly, if we let G0 = G then we can
apply one round of Valiant’s Lemma (b = 2) to obtain a set S0
such that depth(G0 − S0) ≤ 2⌈logb(depth(G))−1⌉. Setting Gi +1 =
i =0 Si
with depth(Gk) ≤ dtдt . While the theoretical behavior of Valiant’s
Lemma against highly depth-robust DAGs is well understood in an
asymptotic sense, to the best of our knowledge our experiments
give the first empirical results about the behavior of these attacks
in practice.
depth(G −
Gi − Si we can iterate until we obtain a graph Gk = G −k−1
The fifth attack is a hybrid which combines the layered attack
and Valiant’s Lemma Attack. Briefly, the attack partitions the nodes
of the graph into(cid:112)dtдt layers as in [5] and then uses Lemma 2.2 to
reduce the depth of each layer to(cid:112)dtдt to that the resulting graph
has depth at most dtдt . Finally, the sixth “Best Attack” algorithm
we implemented simply takes the best (smallest) S produced by any
of the four previous algorithms.
9We do not measure the complexity of selecting the set S as this step need only be
performed a single time for a given iMHF with fixed choice of parameters. Thus the
cost can be amortized across all evaluations with those choices. For example, when
performing a dictionary attack on password hashes the cost of selecting S is amortized
across all password guesses for a target hash.
Session E1:  Hardening CryptoCCS’17, October 30-November 3, 2017, Dallas, TX, USA1011Candidate Graphs. As test subjects we implemented a total of 8
graph distributions. As a benchmark we implemented the DAGs
underlying Argon2i-A and Argon2i-B. We also implemented the
DAGs sampled by DRSample and aATSample.
In certain situations where trusted uniform randomness is at a
premium it may be beneficial to have graphs which require less
randomness to sample. To that end we also implemented hybrid
versions HDRSample and HaATSample of our two main construc-
tions. In a nutshell the hybrid versions differ from the originals in
that they now select the range sizes for long edges deterministically
rather than randomly. Their full pseudo-code can be found in the
appendix in Algorithm 3 and Algorithm 5, respectively. The formal
results in the previous sections for DRSample and aATSample carry
over almost unchanged to their hybrid counterparts. Recall that
the algorithm aATSample takes as input a parameter c ∈ (0, 1), we
evaluate the algorithm using the parameters c ∈ {0.1, 0.5}.
Finally, for applications where randomness is simply not avail-
able, we have also implemented an (exceedingly simple and efficient)
fully deterministic graph Deterministic. In this graph the second
incoming edge of each consecutive node has double the length
of the second edge for the previous node. This length doubling is
repeated until edges no longer fit in the graph at which point the
next edge has length 2 again and the doubling process begins anew.
Intuitively this approximates the distribution of the edge lengths of
DRSample as that can be seen as first uniformly samples a power of
two to set a range size and then uniformly samples an edge length
within that range size.
Results. We describe three figures which summarize the results
of our experiments.
Figure 1 compares the depth-reducibility of each of the candi-
date DAGs. In particular, we plot depth vs the minimum size of a
depth reducing set found by any of the five attacks. We see that all
new constructions and their variants have better resistance to the
depth-reduction attacks than both Argon2i variants. In particular,
DRSample and HDRSample provide the strongest resistance.
Figure 2 plots the quality of the best attack we found. (Recall that
quality compares the attacker’s aAT against the honest algorithm’s
aAT. A parallel pebbling attack with 3 means it is 3 times more
efficient than the strategy used by honest (sequential) parties when
pebbling the graph.). Once again we see that all new constructions
and their variants have higher aAT cost (smaller attack quality) than
Argon2i-A and Argon2i-B meaning that they are more resistant to
attacks. Once again DRSample and HDRSample offer the strongest
resistance.
Figure 3 compares the empirical performance of the layered
depth-reducing attack [5] with the performance of the Lazy Valiant
attack. In particular, we plot depth vs the minimum size of a depth
reducing set found by the two attacks for 4 of the candidate graphs.
As the plot shows, Valiant’s attack consistently outperforms the lay-
ered attack of Alwen and Blocki [5]. Valiant’s lemma is dramatically
superior when we are attacking highly depth-robust constructions
such as DRSample or Deterministic. We used diamonds to high-
light the curves for DRSample and Deterministic under the layered
attack, since these curves are so close to the bottom right side of the
plot that they are difficult to see. Surprisingly, our results show that
in practice Valiant’s attack also appears to perform slightly better
d
:
h
t
p
e
D
8
6
4
2
0
·106
Argon2iA
Argon2iB
DRSample
HDRSample
Deterministic
HaATSample
aATSamplec =0.1
aATSamplec =0.5
0
0.2
0.4
0.6
e = |S |
0.8
1
1.2
·107
Figure 1: Depth-Reducibility of DAGs under Best Attack (n =
224 ≈ 107.224)
Argon2iA
Argon2iB
DRSample
HDRSample
Deterministic
HaATSample
aATSamplec =0.1
aATSamplec =0.5
Prior Attacks [6]
20
15
10
5
0
y
t
i
l
a
u
Q
k
c
a
t
t
A
14
16
18
Running Time Parameter: log2(n) (Memory: = nK B)
20
22
24
Figure 2: Attack Quality vs iMHF Candidates
than the Layered attack against Argon2i-A and Argon2i-B. This,
despite the (known) theoretical upper bounds on |S| for those DAGs
being much smaller for the Layered attack. Based on these empirical
results we conjecture that one could provide significantly tighter
theoretical upper bounds on the size of the set S we obtain when
we use Lazy Valiant to build depth-reducing sets for Argon2i-A and
B. The only known theoretical guarantee is that Valiant’s lemma
yields a set |S| ≤ O
(cid:17) such that depth(G − S) ≤ dtдt .
(cid:16) n log dtдt
log n
6 IMPLEMENTATION
To implement our iMHF we modified Argon2i [15] replacing its
edge structure with that of DRSample. We selected DRSample be-
cause it is simple and our empirical analysis suggests that it offers
the best resistance to attacks. Our source code is available at [33].
The modification involved adding about 5 lines of code for data
independent addressing, and commenting out over thirty lines of
code.
Remark 1: Part of the reason for the dramatic reduction in lines
of code is that we decided to remove support for multiple lanes
(e.g., to support parallelism) as researchers have previously raised
concerns [6] about the high depth-reducibility of an Argon2i DAG
Session E1:  Hardening CryptoCCS’17, October 30-November 3, 2017, Dallas, TX, USA10122 ·106
d
:
h
t
p
e
D
1.5
1
0.5
0
Argon2i-A
Argon2i-B
Deterministic
DRSample
Layered
Valiant
0
0.5
1
e = |S |
1.5
·107
Figure 3: Depth-Reducibility: Layered vs. Lazy Valiant
Depth-Reduction Attacks (n = 224 ≈ 107.224)
when the number of lanes becomes large10. At this time we would in-
stead recommend supporting parallelism using the trivial approach:
instantiate several independent iMHF threads (with different salt
values) and hash each of these outputs to produce the final output
block.
Remark 2: While our primary goal was to implement our iMHF
DRSample, the reference code still includes the data-dependent
modes of operation. However, the data-dependent mode of opera-
tion uses the uniform distribution over edges similar to SCRYPT.
The recent security proof for SCRYPT [9] suggests that a uni-
form edge distribution is the right distribution to use for the data-
dependent mode of operation. While SCRYPT has optimal aAT com-
plexity, it is liable to space-time tradeoff attacks (e.g., an attacker
2 steps with maximum memory
could compute the function in n
usage O(1)). We conjecture that the “id” mode of operation, which
runs data-independent mode for n/2 steps before switching to the
data-dependent mode of operation, might provide much stronger
resistance to space-time trade-off attacks though we leave this
question as an interesting direction for future research.
6.1 Timing Results.
Recall that the goal when designing an iMHF is to find a function
which, for a fixed amount of time used for honest sequential evalu-
ation (e.g. 1/2 second) forces the maximum cost possible per rate
of evaluation on an attacker. Thus we also compared the running
time of the honest evaluation of an iMHF using our new DAGs with
Argon2i-B. We found the new DAGs to actually be marginally faster
than Argon2iB. Despite this, our empirical (and previous theoretic)
evidence indicating that for any given set of parameters the new
10In particular, any directed edge from a node in lane i to a node in lane j (cid:44) i cannot
exist in the same slice. When sampling a backedge for a node v in lane j Argon2 follows
the following approach: (1) select a random lane ℓ, (2) select a (random) predecessor
r(v, j) ∈ [v − 2] of v in lane ℓ and add the directed edge ((r(v, j), ℓ), (v, j)) from
node (r(v, j), ℓ) to (v, j). If ℓ (cid:44) j then it is required that v − r(v, j) is large to
avoid deadlocking each thread (e.g., by ensuring that the value for node (r(v, j), ℓ)
is certainly computed in thread ℓ before we try to compute the value for node (v, j)
in thread j. Alwen and Blocki [6] observed that as the number of threads grows
large almost all backedges are long, which makes it significantly easier to construct
depth-reducing sets for their attack.
iMHFs incur significantly greater amortized area-time complexity
for the adversary.
In more detail we modified the Argon2iB implementation [15] re-
placing its edge structure with that of DRSample. We compared the
time required on an Intel(R) Core(TM) i5-4210U CPU @ 1.70GHz
8GB of memory to evaluate the two iMHFs for a setting with a
single lane, 1GB of memory (i.e. 220 blocks). On average, over 1, 000
trials, it took 0.969 seconds (resp. 0.966 seconds) for evaluation
of Argon2iB (resp. our modified iMHF) with standard deviation
σ = 0.0163 (resp. σ = 0.0175) . The faster running time, while mar-
ginal, was statistically significant p ≤ 0.001. Thus, our benchmarks
provide compelling support for our claim that the edge structure
modifications can be implemented without adversely impacting the
impressive speed/throughput of Argon2i.
7 OPEN QUESTIONS
There remains a large gap between the constant factors in the
best known provable lower bounds on aAT for DRSample and
aATSample and the best known upper bounds (attacks) on aAT.
One of the primary open challenges is to improve the constant
terms in the lower bounds for constructions like DRSample or
aATSample or for a new practical construction. We are conjectur-
ing that both constructions aATSample and DRSample can provide
strong memory hardness guarantees in practice, and would en-
courage continuing cryptanalysis of these constructions to confirm
or refute this conjecture. It would also be useful to cryptanalyze
these constructions with respect to other metrics for MHFs such as
bandwidth hardness [41] or sustained space complexity [8, 40].
A related theoretical challenge is to construct a family of
(cid:19)
(cid:19)