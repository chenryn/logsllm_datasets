To  mitigate  variations  due  to  different  images,  parameter "  is 
determined by matching the ratio of two points on the curve near 
each end. The curve of the automated attacks on PassPoints shown 
in Figure 6 is used for the dictionary generated with the automated 
memorability, and that of the human-seeded attacks is used for the 
dictionary generated with the human-assisted memorability.  
6.2.5  Generating Honeywords 
When a honeyword is wanted, a word is drawn from the words in 
the dictionary according to their drawing probabilities. This can be 
realized  by  generating  a  random  number  with  a  uniform 
distribution  from  0  to  1,  and  selecting  the  word  that  contains the 
random  number  in  the  cumulative  probability.  Each  point  in  the 
selected  word  is  then  perturbed  using  the  distribution  of  human 
click-variations given in [19] to fulfill Property 2.b. The result is 
output as a honeyword.  
6.3  Empirical Evaluations 
6.3.1  Experimental Setting 
We apply a simple yet powerful method to evaluate the quality of 
generated honeywords: using human brains in a standard learning 
test.  In  this  method,  experts  learn  from  a  training  set  of  labelled 
passwords and honeywords. Then they are asked to identify each 
1223password in a testing set disjoint with the training set in a blind test 
wherein the password and a honeyword are presented side by side 
randomly. The resulting success rate, which is the ratio of correctly 
identified  passwords  to  total  tested  passwords,  is  then  compared 
with  the  expected  success  rate  of  50%  of  the  ideal  case  that 
honeywords are indistinguishable from passwords.  
Figure 4. Two typical images in our experiments 
Birds and People, the two images shown in Figure 4, were chosen 
in our case study since they represent two typical types of images 
possibly  used  in  PassPoints:  Birds  is  simple  without  many 
memorable points, while People is complex with many memorable 
points. Both images  were 400x600. The passwords collected in a 
prior study [13], with 92 passwords for Birds and 142 passwords 
for  People,  were  used  in  our  experiments.  Both  automated 
memorability  and  human-assisted  memorability  were  used  to 
generate honeywords in order to compare their performances.  
To  facilitate  quickly  locating  click-points  in  a  password  (or  a 
honeyword)  and  viewing  their  surrounding  contexts,  three  views 
were provided for a user to switch at will: the image overlaid with 
the password (i.e., the password’s click-points and their order were 
marked  on  the  image),  the  password  alone,  and  the  image  alone. 
There was no restriction on how passwords in the training set were 
learned or how long to make a decision in a test.  
Three  experienced  researchers  in  computer  vision  and  pattern 
recognition  who  are  familiar  with  graphical  passwords  acted  as 
experts in our evaluation; otherwise they were not involved in this 
work. Before experiments, they  were informed of the honeyword 
generation method. Their expertise enables them to understand our 
honeyword generation method inside out, and to know every clue 
and  where  and  how  to  look  for  it  in  telling  honeywords  and 
passwords apart. Therefore they are the most capable adversaries in 
our setting.  
For each expert, we randomly partitioned the passwords into three 
sets for each image: a training set with 30 passwords for Birds and 
48  passwords  for  People,  and  two  testing  sets  of  equal  size,  one 
testing  set  for  each  realization  of  the  IPM  model.  In  the learning 
phase,  we  generated  on  the  fly  100  honeywords  per  image  per 
realization of the IPM model and labelled them with the realization 
method for each expert to learn. 
In the testing phase, one password was tested at a time. First, we 
randomly  selected  a  test  set,  and  randomly  picked  an  untested 
password from the set. Then a honeyword was generated from the 
IPM model realization corresponding to the selected test set. The 
password  and  the  honeyword  were  displayed  side  by  side  at  a 
random  order.  When  a  decision  was  made  in  a  test,  the  correct 
answer  was  displayed  so  that  finished  tests  could  be  learned  for 
subsequent tests. This was to mimic the process that an adversary 
could learn from each trial. Our procedure design also eliminates 
the  advantage  that  more  samples  were  learned  for  a  later  tested 
realization if the two realizations were tested sequentially, resulting 
in a fair comparison of the two realizations of the IPM model. 
At  the  end,  each  expert  was  asked  to  write  down  major 
discriminative features they had learned and employed in the tests. 
Eight  months  after,  we  conducted  another  experiment  to  test  a 
baseline method, wherein a honeyword was generated by randomly 
selecting 5 image points that satisfied PassPoints’ requirements. By 
then,  the  three  experts  had  already  forgot  all  the  passwords  they 
saw before. This baseline experiment followed the same procedure 
as before, except that the results of the two test sets were averaged 
for each expert, since the honeywords used were all generated with 
the same baseline method. 
6.3.2  Experimental Results 
Table 1 shows the resulting success rates for each expert denoted 
as A, B, C as well as their averages. There is a significant difference 
for  success  rates  between  the  baseline  method  and  our  methods. 
The  baseline  method’s  honeywords  were  almost  perfectly 
identified, while our method’s success rates are  within a distance 
of 14.5% from the expected 50% success rate of the ideal case that 
honeywords are indistinguishable from passwords.  
We also examined temporal behaviors of success rates, and did not 
find any noticeable improvement of success rates for late tests.  
Table 1. Experimental results: success rates (%)  
Birds 
People 
Auto 
Human 
Baseline 
Auto 
Human 
Baseline 
64.5 
58.1 
45.2 
48.4 
51.6 
58.1 
52.7 
98.4 
96.8 
100 
98.4 
63.8 
61.7 
55.3 
60.3 
44.7 
48.9 
42.6 
45.4 
100 
98.9 
100 
99.6 
% 
A 
B 
C 
Average 
55.9 
6.3.3  Statistical Analysis  
Statistical analysis has been used to determine whether differences 
in data reflect actual differences or might reasonably have occurred 
by chance. A value of 0 < 0.05 is regarded as indicating statistical 
significance,  implying  less  than  5%  probability  that  results 
occurred by chance.  
First we applied the exact binomial test to individual experimental 
results to determine if the results reflected actual distinguishability 
between  honeywords  and  passwords.  The  resulting 0-values  are 
shown in Table 2 except the last row, where statistically significant 
results are marked in yellow. No expert could detect a statistically 
significant  difference  between  passwords  and  honeywords 
generated with either of our methods, whereas every expert could 
detect a statistically significant difference between passwords and 
honeywords generated with the baseline method. 
Table 2. 3-values with the exact binomial test 
Birds 
People 
Auto 
Human 
Baseline 
Auto 
Human 
Baseline 
0.150 
1.000 
1.54E-08 
0.079 
0.560 
1.42E-14 
0.473 
1.000 
2.98E-08 
0.144 
1.000 
3.48E-13 
0.720 
0.473 
9.31E-10 
0.560 
0.382 
1.42E-14 
0-value 
A 
B 
C 
All 
0.300 
0.679 
4.51E-25 
0.018 
0.312 
5.13E-41 
Then  we  applied  Fisher’s  exact  test  of  independence  to  the 
experimental  results  to  determine  if  there  was  any  statistically 
significant difference among the experts. The resulting 0-values for 
different images and methods are shown in Table 3. No statistically 
1224is  found  among 
significant  difference 
the  experts.  As  a 
consequence,  we  pooled  the  three  experts’  results  together  and 
redid the exact binomial test. The resulting 0-values are shown in 
the last row of Table 2. There is only one case that the statistical 
significance flips: now there is a statistically significant difference 
between passwords and honeywords generated with the automated 
memorability on image People. This can be explained by the fact 
that more samples lead to more power or higher sensitivity in the 
exact  binomial  test.  Therefore  the  pooled  data  test  could  detect 
subtler difference that individual tests could not detect. 
Table 3. 3-values with Fisher’s exact test of independence 
Birds 
People 
0-value 
Auto 
Human 
Baseline 
Auto 
Human 
Baseline 
0.344 
0.811 
0.774 
0.747 
0.869 
1 
The  automated  memorability’s  different  distinguishability  with 
these  two  images  can  be  explained  by  one  discriminative  rule 
learned and employed by the experts: passwords tended to contain 
semantically  meaningful  and/or  semantically  correlated  points. 
Lacking of semantics understanding, the automated memorability 
might  generate  honeywords  semantically  distinctive 
from 
passwords,  which  were  likely  identified  with  this  discriminative 
rule.  
Semantically meaningful points tend to be hotspots, particularly for 
an image with a limited number of such points. Security-conscious 
users tend to avoid selecting any hotspots in their passwords, and 
thus  their  passwords  are  less  likely  to  contain  semantically 
meaningful points for a simple image (which has a small set of such 
points)  than  for  a  complex  image  (which  has  a  large  set  of  such 
points). On the other hand, a distinguishable point is more likely to 
be a hotspot for a simple image with a small set of distinguishable 
points  than  a  complex  image  with  a  large  set  of  distinguishable 
points. As a result, the discriminative rule tends to be less effective 
for image Birds than for image People, since the former contains 
much fewer semantically meaningful or distinguishable points than 
the  latter.  This  explains  the  automated  memorability’s  different 
distinguishability for People and for Birds.  
The  human-assisted  memorability,  on  the  other  hand,  captures 
semantics  well,  and  thus  the  above  discriminative  rule  is  not 
effective for the human-assisted memorability. 
To sum up, our empirical study suggests that both realizations of 
the  IPM  model  are  substantially  better  than  the  baseline  method. 
For both simple and complex images, honeywords generated with 
the baseline method are distinguishable from passwords, whereas 
those  generated  with  the  human-assisted  memorability  are  not 
distinguishable  from  passwords.  On  the  other  hand,  honeywords 
generated  with  the  automated  memorability  are  indistinguishable 
from passwords when a simple image is used, but distinguishable 
with a powerful and sensitive statistical test when a complex image 
is used. 
7.  AN OFFENSIVE APPLICATION: 
DICTIONARY ATTACKS 
The IPM model can be applied to guess any click-based graphical 
passwords. We choose PCCP as our case study for two reasons: 
•  As discussed in Section 2.1.2, PCCP is the most secure click-
based scheme, and thus the most challenging to attack.  
•  PCCP  is  the  best  in  testing  efficacy  and  power  of  an  IPM 
model since memorability is the only exploitable attribute in 
guessing  PCCP  passwords,  and  PCCP  has  the  most  random 
click-points and thus the widest coverage of test points.  
Like the security analysis of PCCP against offline attacks in [8], we 
assume that all server-side information is known. This means that 
attackers  have  access  to  all  images,  know  the  first  image  of  a 
password and its each click-point’s grid of tolerance squares, and 
can  determine  the  next  image  from  a  guessed  click-point  on  a 
current  image  and  verify  if  a  guessed  password  is  correct or  not. 
This  assumption  allows  us  to  focus  on  the  guessability  of  PCCP 