- 高级配置里修改RzyHttpOutput下的 use_buffering=false 关闭发送缓存；
- 修改rate_limit=xxx(单位字节，限制读取速度)。
1-23
日志学院
复杂目录处理
深层目录采集
由于Agent需要定时轮询要采集的目录下的内容，以发现新创建的日志文件。深层次目录会
导致Agent轮询时一个文件时，会遍历很多层的目录，非常的消耗性能。这时候Agent的
瓶颈往往在CPU上，因为每次扫描需要遍历整个的目录。
对于这种问题，我们一般通过做软链接的方式，将目录下的文件定时进行软链接到一个浅目
录中去，让Agent只采集这个目录下的内容，这样会大大减少Agent的CPU消耗，也能提
高发送效率。
高并发日志采集
正常情况下用户只需要配置日志采集的目录、要采集的日志文件名称、相应的匹配规则就可
以了，但对于Agent来说还有一个问题——如何发现新创建的日志文件？目前常见的做法是
定时轮询要采集的目录下的内容。而当短时间内日志量暴增时，问题就出现了。
想象一下：当Agent正在采集access.log的时候，日志发生了轮滚，access.log变成了
access.log.1 ，但是Agent并没有采集完成access.log的内容，然而此时日志已经轮滚完毕，
那我们在access.log还没有采集完成的内容就会被丢弃。
为避免这种问题时，可以采集日志轮滚完毕之后的文件，这样能够保证日志不会被漏采，但
这样做的弊端也很明显——因为要采集access.log1的日志，Agent就没办法及时采集最新的
日志（现在的access.log）了，这样采集就会有延迟。
在高并发环境下进行日志采集，我们需要做些取舍，如果不考虑入库数据的延迟，可以使用
采集轮滚后的日志的方式；如果考虑数据入库延迟，那可能需要对日志的输出进行改造。
日志易支持使用排序分流来采集高并发日志，当满足以下条件时建议使用排序分流：
 采集Agent类型为Heka；
 同时监控文件数超10K；
 文件滚动写。
使用排序分流时，可以将access.log以及access.log的历史日志文件都采集到。有些日志会
限制历史日志文件的个数为10个，超过10个日志，最老的日志文件会被系统自动删除。
在使用排序分流时，只要文件滚动没有在短时间内滚动超过10个，理论上所有的日志文件
都会被采集到。如果历史日志文件没有进行限制，还要配合日志过期时间（最后修改时间）
使用，以免因采集文件过多大量占用系统资源。
排序分流可以自定义文件采集并发粒度，并指定采集顺序进行文件采集。其设置要点有：
 根据分流字段捕获并发分组，确定并发粒度，确保每个分组都被配置；
 根据排序字段确定采集顺序，数值型才可作为排序字段。
例1
1-24
日志学院
有某文件夹下的日志如下所示，需要对不同类型的日志进行分流。
则其采集配置白名单为：
(?P[^.]+)\.log\.(?P\d+)\-(?P\d+)\-(?P\d+)
在填写白名单时，如果正则中包含(?Pyy)这种named&numberedcapturinggroup的
内容的话，页面将出现分流字段和排序字段供进一步配置。如果想用日志类型（api、audit、
request）作为并发粒度，想用年月日作为排序字段，则配置如下：
1-25
日志学院
配置完毕后，点击匹配文件预览，将看到并发流名称，以及每个流下采集顺序排序的文件名
（出于效率考虑，最多展示10个流名，每个流最多展示10个文件）。
之后流程与正常日志采集类似。
1-26
日志学院
配置完成后查看Agent配置文件，其相关配置信息如下：
###LogstreamerInput
[48e5a0f5b74639914f1032b9a82ed45e_file_input]
type="LogstreamerInput"
log_directory="/data/rizhiyi/logs/yottaweb/"
file_match=
"(?P[^.]+)\\.log\\.(?P\\d+)\\-(?P\\d+)\\-(?P\\d+)"
differentiator=["48e5a0f5b74639914f1032b9a82ed45e","Module"]
oldest_duration="720h"
1-27
日志学院
exclude=""
splitter="48e5a0f5b74639914f1032b9a82ed45e_file_splitter"
decoder="48e5a0f5b74639914f1032b9a82ed45e_file_decoder"
disabled=false
priority=["Year","Mouth","Seq"]
close_eof=false
read_interval="250ms"
max_fd=0
close_inactive="0s"
max_read_interval="10s"
binary_check=false
例2
以日志易系统模块日志采集为例配置排序分流。
已知目录结构如下：
/data/rizhiyi/logs/frontend/frontend.log.1
/data/rizhiyi/logs/frontend/frontend.log.2
/data/rizhiyi/logs/collector/collecotr.log
/data/rizhiyi/logs/collector/collector.log.1
如果想用模块名(frontend,collecotr)作为并发粒度，那么可以配置为下图所示白名单。通过制
定分流字段为Module来达到按Module并发的效果：
以上文目录结构为例，对不同模块下的日志，需要指定采集顺序，如上图配置，我们可以指
定按Seq降序采集，选择中Seq，然后点击后面上下箭头，来选择是升序采集（上箭头），
还是降序（下箭头）采集。
1-28
日志学院
配置完毕后，点击匹配文件预览，将看到并发流名称：
当仅配置采集某个模块的日志时，可以不配置分流字段，仅配置排序字段：
例3
有日志文件目录如下：
/var/log/nginx/frank.com/2014/08/access.log
1-29
日志学院
/var/log/nginx/frank.com/2014/08/access.log.1
/var/log/nginx/frank.com/2014/08/access.log.2
/var/log/nginx/frank.com/2014/08/access.log.3
/var/log/nginx/george.com/2014/08/access.log
/var/log/nginx/george.com/2014/08/access.log.1
/var/log/nginx/george.com/2014/08/access.log.2
/var/log/nginx/george.com/2014/08/access.log.3
/var/log/nginx/sally.com/2014/08/access.log
/var/log/nginx/sally.com/2014/08/access.log.1
/var/log/nginx/sally.com/2014/08/access.log.2
/var/log/nginx/sally.com/2014/08/access.log.3
可以看到nginx日志根据域名进行了区分，已知滚动后的日志名称末尾为日期，可以按照日
志的年月日对日志进行分流，配置文件示例如下：
###LogstreamerInput
[48e5a0f5b74639914f1032b9a82ed45e_file_input]
log_directory="/var/log/nginx"
file_match=
'(?P[^/]+)/(?P\d+)/(?P\d+)/access\.log\.?(?P\d*)'
differentiator=["48e5a0f5b74639914f1032b9a82ed45e","DomainName"]
priority=["Year","Month","^Seq"]
大量小文件采集
大量小文件和深层次目录采集遇到的问题类似，都会非常消耗资源。因为Agent会定时轮询
目录下的文件以确保及时采集新数据。
所以在采集大量小文件的时候我们需要关注以下几点：
 CPU和内存的使用，建议控制住；
 Agent的文件系统描述符给的多一些（这需要在Agent端进行控制），采集完成之后迅
速释放文件描述符。
 Agent不要持有长时间的文件句柄。该配置项即采集日志时配置的最后修改时间。当文
件时间戳没有超过最后修改时间时，Agent会持续监控该文件是否有更新。这在采集大
量小文件时很耗费系统资源。
可以在Agent配置调整LogstreamerInput下的配置（该配置针对某个具体采集项）：
# 该Input可以打开的最大fd数目
# 默认为0，表示不限制最大fd数目
max_fd=1024
#LogstreamInput多久空闲后关闭（空闲指多久没读到新数据)
# 默认为0s，表示永远不关闭（和旧版本逻辑一致)
close_inactive="1m"
# 日志的最后修改时间，默认为720h
oldest_duration="30s"
1-30
日志学院
复杂目录处理总结
复杂目录采集比较耗费系统主机资源，最好在系统闲时采集。
复杂目录采集时的建议：
 在不影响业务主机性能前提下采集，最好在系统闲时进行采集；
 根据具体场景下的建议进行采集；
 合理配置oldest_duration（最后修改时间）减少打开FD数，具体配置见上图；
 如有可能使用，分流排序配置减少打开FD数，具体见高并发日志采集相关配置；
 如能增加Agent资源，可以增加worker和cpu，提高EPS：
 Heka下修改：
- [RzyHttpOutput]下的worker （增加日志发送链接数）；
- [hekad]下的maxprocs（增加Heka可用的cpu核数)，具体见Agent资源控制图示；
 RizhiyiAgent下修改：
- “threadpoolsize“(增加采集发送的线程数）。
1-31
日志学院
Agent 配置分发
在某台主机的Agent上完成单一数据源采集配置流程后，如果同类型主机还有多台，并不需
要重复数据源配置流程，如进行性能数据采集时。
日志易提供了单一配置的批量下发功能。在第一次配置添加流程后立即进行批量下发的操作
流程如下:
1. 当添加完成时，可点击"批量配置该数据源"，将该数据源配置添加到其他Agent：
2. 在弹出框中，勾选待配置的其他 Agent：
1-32
日志学院
3. 点击"确认分发"，将看到各个Agent的下发结果。如果下发失败，会返回具体的失败原因：
历史上已经存在的采集配置，则可以通过配置列表页上的操作入口进行分发：
Agent 分组采集
上述单一Agent配置批量下发的功能，比较依赖日志易服务器推送配置数据到采集端的网络
访问策略才能正常运行。在集群跨网络或网络策略变动比较频繁的业务线上，Agent配置分
发不能灵活运用。
此时，可以采用Agent 分组来实现批量配置管理。Agent分组采用采集端主动拉取配置的
方式来同步数据源配置。
Agent分组采集一般适用于同一业务系统下日志的批量采集。分组配置需要结合Agent分组
进行使用。同一业务系统下的Agent一般划分到同一Agent分组中。
此时使用Agent分组采集的流程如下：
1-33
日志学院
1、在“资源分组”界面，创建Agent管理资源，与用户所在的用户分组所属角色相绑定（已
有的可直接使用）；
2、在Agent管理页面，对Agent进行分组；
3、点击Agent管理页面的“分组采集”，进行Agent分组采集配置。
分组配置管理
在 Agent 管理页面点击“分组采集”按钮，进入 Agent 分组采集配置管理界面:
1-34
日志学院
进入 Agent 分组采集配置管理界面后，可通过该界面查看某一Agent分组当前采集配置，
以及对某一 Agent 分组进行采集配置的增、删、改的操作:
点击"添加xx分组数据源"，对选中分组增加采集配置，在来源选择页面，选择要添加的数据
源类型。Agent 分组采集配置的增删改流程和 Agent 单一数据源采集配置增删改类似，不
再赘述。
与对单一数据源添加配置唯一不同的，Agent 分组配置的添加过程不支持“预览”功能。直接
填入appname，tag，换行等必要配置信息后即可点击下一步。
分组配置使用限制：
1. 由于 Agent 可以属于多个 Agent 分组，为防止不同 Agent 分组配置项的冲突，Agent
分组可以管理的采集配置项暂时只支持文件和目录/Eventlog/脚本/Tcp/Udp/性能数据。
2. 单行日志最大长度，限速，压缩等单个 Agent 的全局配置不在 Agent 分组的采集配置
项管理中提供。
3. 因各个平台支持插件细节有差别，不支持对包含不同平台 Agent 的 Agent 分组进行分
组配置管理, 也不支持对尚未包含任何 Agent 的 Agent 分组进行分组配置，因此在进行
Agent 分组采集前，请先将同一平台的 Agent 归入同一分组。
分组配置及同步：
1.Agent 分组的采集配置是通过 Agent 心跳同步的，Agent 心跳默认频率是 1 分钟/次 ；
2.Agent 分组的配置，在 Agent 配置管理页面无法查看，但可以通过高级配置界面进行查
看。
Agent 升级及管理
极少数情况下，如日志采集出现问题时，我们需要对Agent进行升级。
日志易Agent升级流程如下：
1、在租户管理界面上传日志易Agent升级包：具体请参考8.6小节Agent升级包管理部分；
1-35
日志学院
2、在页面上升级Agent即可。
还可以点击页面上的“批量操作”对Agent进行批量升级。
除升级以外，"批量操作"菜单还可以逐一或批量进行Agent的停止，启动，重启等操作。 当
集群机器或服务下线时，通过该功能可对Agent进行快速停止（集群上线时Agent会自动
启动，无需再进行操作）。
对Agent还可以单独进行缓存清除操作。操作按钮在Agent配置页内。其中：
 清理输入源缓存：可清理某一采集项的缓存，此动作会导致该采集项配置的日志重新采
集；
 清理输出源缓存：可清理该Agent采集入库的所有缓存，此动作会导致Agent配置的
所有日志采集项全部重新采集。