Figure 10: The attack performances with different user fea-
ture generation methods
the target recommender ‚ÄúLI‚Äù, the performance is much worse than
our attack (0.649 v.s. 0.939).
Which Is the Best User Feature Generation Method? To fur-
ther verify the effectiveness of our attack, we adopt different aggre-
gation methods to generate user feature vectors. Besides the method
used in our attack, Origin, we evaluate 5 user feature generation
methods.
‚Ä¢ Concat10 concatenates feature vectors of the first 10 inter-
‚Ä¢ Concat20 concatenates feature vectors of the first 20 inter-
‚Ä¢ Concat100 concatenates feature vectors of the first 20 inter-
actions and all the recommendations (i.e., ùëò = 100) for each
user.2
actions and the first 10 recommendations for each user.
actions and the first 20 recommendations for each user.
Figure 11: The attack performances for the content-based
recommender system on the ml-1m dataset.
‚Ä¢ Hadamard respectively conducts Hadamard products on
feature vectors of all the interactions and recommendations
to obtain two vectors for each user. Afterwards, following
the similar steps in Section 2.5, we use the difference of these
two vectors as the user feature vector.
‚Ä¢ Similarity first conducts dot products between feature vec-
tors of each recommendation and all interactions, then con-
catenates the average of dot product results for each recom-
mendation into the user feature vector.
The results are shown in Figure 10. We find that our method
outperforms all the other aggregation methods. For instance, on the
settings of AIAI, our method outperforms Concat10 and Similarity
by 5% and 63%. These results demonstrate the effectiveness of our
user feature generation method in the attack process.
Is It Possible to Generalize Our Attacks to Content-Based
Recommender Systems? To further verify the effectiveness of
our attack, we conduct evaluations on the membership inference
attacks against a content-based recommender system. Different
from the recommendation algorithms used in the previous attacks,
a content-based recommender system aims to distinguish users‚Äô
likes from dislikes based on their metadata (such as description of
items and profiles of users) [51]. The evaluation is conducted on the
ml-1m dataset with information about items and users, under the
assumption I, i.e., the target recommender‚Äôs algorithm and dataset
distribution are available.
The results are depicted in Figure 11. We conclude that our attack
achieves a strong performance against a content-based recommen-
dation algorithm (i.e., 0.986 in terms of AUC), indicating a high
generalization ability of our attack model. Furthermore, we evaluate
this attack using different feature generation methods mentioned
above. Results show that our aggregation method also outperforms
other baselines on a content-based recommendation system.
3.6 Summary
The experimental results show that our attack can conduct an effec-
tive membership inference against recommender systems. When
the adversary knows the algorithm and dataset distribution of the
2As the number of interactions for different users are different, using all interactions
for concatenation will result in different lengths of user feature vectors. Therefore,
we only take the first 20 interactions into consideration since the least number of
interactions in datasets is 20.
AIAIAIALAIANLILI0.00.20.40.60.81.0AUCOriginConcat10Concat20Concat100HadamardSimilarityItemLFMNCFOriginConcat10Concat20Concat100HadamardSimilarity0.00.20.40.60.81.0AUCContent-BasedItemLFMNCFSession 3C: Inference Attacks CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea874target recommender, the attack achieves the strongest performance.
Later in the experiments, we gradually relax the assumptions and
show that our attack can still effectively conduct the membership
inference, demonstrating that our attack has a good generalization
ability.
Furthermore, we explore the influences of hyperparameters.
With the increase of the number of recommendations ùëò and the
length of vectors ùëô, the attack performance improves or maintains
stable, however, the cost continuously increases. In that case, we
are able to find a balance, where the attack performance is strong
and the cost is affordable. And the exploration of the weights of
recommendations shows that the more information is available, the
more powerful the attack is.
4 DEFENSE
The above experiments show the effectiveness of our attack. Mean-
while, to defend the membership inference against recommender
systems, we also propose a countermeasure, named Popularity
Randomization, to mitigate the attack risk. In the original setting
in Section 2.5, non-members are provided with the most popular
items. As a result, feature vectors of non-members are extremely
similar and easily distinguished from members. To address this
problem, we increase the randomness of non-members‚Äô recom-
mendations. Specifically, we first select candidates from the most
popular items. Then, a random selection is conducted on the candi-
dates, i.e., we randomly pick 10% of candidates as recommendations
for non-members. The detailed methodology is demonstrated in
Appendix A.1.
To evaluate the effectiveness of the defense mechanism, we con-
duct experiments under the assumption that the dataset distribution
and algorithm of the target recommender are available. Figure 12
shows the attack performances before and after deploying the de-
fense mechanism. The blue bar denotes the attack performances
with the original setting, i.e., the popularity recommendation algo-
rithm. And the orange bar represents the attack performances with
the defense mechanism, i.e., Popularity Randomization. From the
results, we conclude that Popularity Randomization considerably
decreases the performance of our attack. Specifically, the defense
mechanism decreases the AUC scores of the attack model by more
than 12%, 33% and 41% respectively when the target recommender
uses Item, LFM or NCF. With the defense strategy, attacking the
target recommender using LFM achieves the lowest AUC score on
all three datasets. When the target recommender using LFM, our
attack with the defense mechanism only achieves 0.513, 0.501, and
0.500 AUC scores on the ADM dataset, the lf-2k dataset and the ml-
1m dataset, respectively (detailed explanations are demonstrated in
Appendix A.2). Besides, as Figure 12 shows, the attack performances
against NCF decrease most hugely. For instance, the AUC score of
the attack against NCF on the ADM dataset drops from 0.987 to
0.576. In contrast, the attack with Popularity Randomization against
Item can still achieve strong performances. For instance, on the
ADM dataset, the attack with Popularity Randomization can attain
0.812 in terms of AUC when the target algorithm is Item. Compared
to the attack with the original setting, the defense mechanism only
achieves a 12% drop in the attack performance. Item is the simplest
one among the three recommendation methods, which makes it
Figure 12: Comparisons of attack performances before and
after deploying the defense mechanism.
easier for the adversary to build a similar shadow recommender
with the target recommender. This leads to a stronger attack but
more ineffective defense. In contrast, the other two recommender
systems have more complex model structures, leading to substantial
decreases in attack performances with the defense strategy.
In addition, visualization results and impacts on recommendation
performances are comprehensively analyzed in Appendix A.2 and
Appendix A.3, respectively.
5 RELATED WORK
Membership Inference. The goal of membership inference is to
infer whether a target data sample is used to train a machine learn-
ing model [6, 22, 26, 28, 30, 39, 42, 43, 52]. Shokri et al. [43] propose
the first membership inference attack in this domain. The authors
have made several key assumptions for the adversary, such as mul-
tiple shadow models and a shadow dataset which comes from the
same distribution as the target model‚Äôs training datasset. Salem et
al. [39] gradually relax these assumptions and broaden the scenarios
of membership inference attacks. Later, Nasr et al. [31] conduct a
comprehensive membership privacy assessment in both centralized
and federated learning setting. In particular, they propose the first
membership inference when the adversary has white-box to the
target model. Other research has shown that membership inference
is effective under other machine learning settings, such as genera-
tive models [14], federated learning [8, 29], and natural language
models [45]. Besides, a plethora of other attacks have been proposed
against machine learning models [3, 5, 7, 12, 20, 21, 33, 48, 49].
Item-Based Recommendation Algorithms. Item-based recom-
mendation techniques have been applied in various scenarios [11,
23, 40]. Sarwar et al. [40] explore item-based collaborative filter-
ing (CF) techniques which enhance the scalability and quality of
the CF-based algorithms. Besides, Deshpande and Karypis [11, 23]
present item-based top-ùëÅ recommendation algorithms to promote
the efficiency and performance.
Latent Factor Models. LFM aims to find some latent factors and
is commonly implemented by Matrix Factorization (MF) [24, 25,
36, 38]. Polat et al. [36] combine SVD-based Collaborative Filter-
ing with privacy to achieve accurate predictions while preserving
AIAIALALANANLILILLLLLNLNMIMIMLMLMNMN0.00.20.40.60.81.0AUCOriginalSettingDefenseMechanismSession 3C: Inference Attacks CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea875privacy. Later, Salakhutdinov et al. [38] propose the Probabilis-
tic Matrix Factorization which scales linearly with the number of
observations and performs well on very sparse and imbalanced
datasets. Koren [24] presents an integrated model that combines
the neighborhood and LFM, which optimizes a global cost function
and integrates implicit feedback into the model. Furthermore, Ko-
ren [25] presents a methodology for modeling time drifting user
preference in the context of recommender systems.
Neural Collaborative Filtering. With the advancement of deep
learning techniques, recommendation algorithms with neural net-
works has been in blossom [2, 9, 16, 46, 47]. He et al. [16] propose the
first framework for collaborative filtering based on neural networks
to model latent features of users and items. They show that MF can
be interpreted as a specialization of NCF and utilize a MLP to endow
NCF modelling with a high level of non-linearities. Later, Bai et
al. [2] present a model which integrates neighborhood information
into NCF, namely Neighborhood-based Neural Collaborative Filter-
ing. Another recent work is that Chen et al. [9] design a Joint Neural
Collaborative Filtering model which enables deep feature learning
and deep user-item interaction modeling to be tightly coupled and
jointly optimized in a single neural network.
6 DISCUSSION
In the previous evaluations, our attack shows its effectiveness as
well as strong generalization ability. Moreover, the proposed de-
fense mechanism, Popularity Randomization, can also mitigate the
attack performances considerably. Furthermore, to obtain a com-
prehensive understanding of membership inference attacks, in this
section, we focus on three important factors that largely influence
attack performances: the choice of datasets, the selection of recom-
mendation algorithms, and distributions of generated user features.
The detailed explanations are demonstrated as follows:
The Choice of Datasets. The dataset with a denser user-item ma-
trix leads to better attack performances. The richer information in
a denser user-item matrix considerably facilitates the process of the
item vectorization and attack model training. From the results and
analyses under the assumption II in Section 3.3, we can see that the
attack on the ml-1m dataset achieves the best overall performance
(i.e., 0.873 in terms of average AUC) as the user-item matrix built
from this dataset is the densest.
It is easier
The Selection of Recommendation Algorithms.
for the adversary to attack against a recommender system with
a simpler model structure. As the results (see Table 3) under the
assumption II show, the attack against LFM achieves poor perfor-
mances. Comparing to the other two recommendation algorithms,
LFM has higher model complexity, which makes it harder to attack.
Meanwhile, defending a simpler recommender system is more diffi-
cult. As the evaluations of the defense (see Figure 12) in Section 4
show, attacks against Item perform strongly even with the defense
mechanism. This is because Item has the simplest structure among
the three recommendation algorithms. In short, a recommender
system established by a simple algorithm structure is usually more
vulnerable to membership inference attacks.
Distributions of Generated User Features. The combination of
the dataset and recommender algorithm also matters. Higher attack
performances can be obtained, when the distribution of user feature
vectors generated by the shadow recommender system is more simi-
lar to the distribution generated by the target recommender system.
Trained with samples from a similar distribution, attack models are
able to conduct an accurate inference. Specifically, in Figure 6, the
attack of ‚ÄúMLAI‚Äù achieves a better performance than the one of
‚ÄúALLI‚Äù (0.608 v.s. 0.547). And we see from the visualization results
in Figure 7 that the above advantage comes from the smaller dif-
ference of feature distributions between the shadow recommender
‚ÄúML‚Äù and the target recommender ‚ÄúAI‚Äù than the one between ‚ÄúAL‚Äù
and ‚ÄúLI‚Äù. In summary, training data with distributions similar to
the target data can boost the attack performances.
7 CONCLUSION
Recommender systems have achieved tremendous success in real-
world applications. However, data used by recommender systems is
highly sensitive. In that case, successfully inferring a user‚Äôs member-
ship status from a target recommender may lead to severe privacy
consequences.
In this paper, to investigate the privacy problem in recommender
systems, we design various attack strategies of membership in-
ference. To the best of our knowledge, ours is the first work on
the membership inference attacks against recommender systems.
Comparing to membership inference attacks on data sample-level
classifiers, for recommender systems, our work focuses on the user-
level membership status, which cannot be directly obtained from
the system outputs. To address these challenges, we propose a novel
membership inference attack scheme, the core of which is to obtain
user-level feature vectors based on the interactions between users
and the target recommender, and input these feature vectors into
attack models. Extensive experiment results show the effectiveness
and generalization ability of our attack. To remedy the situation,
we further propose a defense mechanism, namely Popularity Ran-
domization. Our empirical evaluations demonstrate that Popularity
Randomization can largely mitigate the privacy risks.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their insightful feedback.
This work was supported by the Natural Science Foundation of
China (61902219, 61972234, 62072279, 62102234), the Helmholtz
Association within the project ‚ÄúTrustworthy Federated Data Ana-
lytics‚Äù (TFDA) (funding number ZT-I-OO1 4), the National Key R&D
Program of China with grant No. 2020YFB1406704, the Key Scien-
tific and Technological Innovation Program of Shandong Province
(2019JZZY010129), Shandong University multidisciplinary research
and innovation team of young scholars (No. 2020QNQT017), and
the Tencent WeChat Rhino-Bird Focused Research Program (JR-
WXG2021411). All content represents the opinion of the authors,
which is not necessarily shared or endorsed by their respective
employers and/or sponsors.
REFERENCES
[1] Michael Backes, Mathias Humbert, Jun Pang, and Yang Zhang. walk2friends:
Inferring Social Links from Mobility Profiles. In ACM SIGSAC Conference on
Computer and Communications Security (CCS), pages 1943‚Äì1957. ACM, 2017.
[2] Ting Bai, Ji-Rong Wen, Jun Zhang, and Wayne Xin Zhao. A Neural Collaborative
Filtering Model with Interaction-based Neighborhood. In ACM International
Conference on Information and Knowledge Management (CIKM), pages 1979‚Äì1982.
ACM, 2017.