### Figure 10: Attack Performance with Different User Feature Generation Methods

For the target recommender "LI," the performance of our attack (0.939) is significantly better than the baseline (0.649).

### Which Is the Best User Feature Generation Method?

To further verify the effectiveness of our attack, we evaluated different aggregation methods for generating user feature vectors. In addition to the method used in our attack (Origin), we tested five other user feature generation methods:

- **Concat10**: Concatenates feature vectors of the first 10 interactions and the first 10 recommendations for each user.
- **Concat20**: Concatenates feature vectors of the first 20 interactions and the first 20 recommendations for each user.
- **Concat100**: Concatenates feature vectors of the first 20 interactions and all the recommendations (i.e., \( k = 100 \)) for each user.
- **Hadamard**: Conducts Hadamard products on feature vectors of all interactions and recommendations to obtain two vectors for each user. The difference between these two vectors is then used as the user feature vector.
- **Similarity**: Computes dot products between feature vectors of each recommendation and all interactions, then concatenates the average of these dot product results into the user feature vector.

The results, shown in Figure 10, indicate that our method outperforms all other aggregation methods. For example, under the AIAI settings, our method outperforms Concat10 and Similarity by 5% and 63%, respectively. These results demonstrate the effectiveness of our user feature generation method in the attack process.

### Can Our Attacks Be Generalized to Content-Based Recommender Systems?

To further validate the effectiveness of our attack, we conducted evaluations on membership inference attacks against a content-based recommender system. Unlike the recommendation algorithms used in previous attacks, a content-based recommender system distinguishes users' likes and dislikes based on metadata such as item descriptions and user profiles [51]. The evaluation was performed on the ml-1m dataset, assuming that the target recommender's algorithm and dataset distribution are available.

Figure 11 shows the results, indicating that our attack achieves strong performance against a content-based recommendation algorithm (AUC of 0.986), demonstrating high generalization ability. We also evaluated this attack using the different feature generation methods mentioned above, and found that our aggregation method outperformed other baselines on the content-based recommendation system.

### 3.6 Summary

The experimental results show that our attack can effectively conduct membership inference against recommender systems. When the adversary knows the algorithm and dataset distribution of the target recommender, the attack achieves the strongest performance. As we relaxed the assumptions in subsequent experiments, the attack still maintained effective membership inference, demonstrating good generalization ability.

Furthermore, we explored the influence of hyperparameters. Increasing the number of recommendations \( k \) and the length of vectors \( l \) improved or stabilized the attack performance, but at the cost of increased computational expense. We were able to find a balance where the attack performance is strong and the cost is manageable. The exploration of recommendation weights showed that more information leads to a more powerful attack.

### 4 Defense

The above experiments demonstrate the effectiveness of our attack. To defend against membership inference in recommender systems, we propose a countermeasure called **Popularity Randomization**. In the original setting, non-members were provided with the most popular items, making their feature vectors extremely similar and easily distinguishable from members. To address this, we increased the randomness of non-members' recommendations by selecting candidates from the most popular items and then randomly picking 10% of these candidates as recommendations for non-members. The detailed methodology is provided in Appendix A.1.

To evaluate the defense mechanism, we conducted experiments under the assumption that the dataset distribution and algorithm of the target recommender are available. Figure 12 shows the attack performances before and after deploying the defense mechanism. The blue bars represent the attack performances with the original popularity recommendation algorithm, while the orange bars show the attack performances with the Popularity Randomization defense. The results indicate that Popularity Randomization significantly decreases the attack performance. Specifically, the defense mechanism reduced the AUC scores of the attack model by more than 12%, 33%, and 41% when the target recommender uses Item, LFM, or NCF, respectively. With the defense strategy, attacking the target recommender using LFM achieved the lowest AUC scores on all three datasets. For example, on the ADM dataset, the AUC score dropped from 0.987 to 0.576 for NCF. In contrast, the attack with Popularity Randomization against Item still achieved strong performances, such as an AUC of 0.812 on the ADM dataset.

Item is the simplest of the three recommendation methods, making it easier for the adversary to build a similar shadow recommender, leading to a stronger attack but less effective defense. The other two recommender systems, with more complex model structures, saw substantial decreases in attack performance with the defense strategy.

Additional visualization results and impacts on recommendation performance are analyzed in Appendices A.2 and A.3, respectively.

### 5 Related Work

#### Membership Inference
The goal of membership inference is to determine whether a target data sample was used to train a machine learning model [6, 22, 26, 28, 30, 39, 42, 43, 52]. Shokri et al. [43] proposed the first membership inference attack in this domain, making several key assumptions about the adversary, such as access to multiple shadow models and a shadow dataset from the same distribution as the target model’s training dataset. Salem et al. [39] gradually relaxed these assumptions, broadening the scenarios of membership inference attacks. Nasr et al. [31] conducted a comprehensive membership privacy assessment in both centralized and federated learning settings, proposing the first membership inference attack in a white-box setting. Other research has shown that membership inference is effective in various machine learning settings, including generative models [14], federated learning [8, 29], and natural language models [45].

#### Item-Based Recommendation Algorithms
Item-based recommendation techniques have been applied in various scenarios [11, 23, 40]. Sarwar et al. [40] explored item-based collaborative filtering (CF) techniques, enhancing the scalability and quality of CF-based algorithms. Deshpande and Karypis [11, 23] presented item-based top-N recommendation algorithms to improve efficiency and performance.

#### Latent Factor Models
Latent Factor Models (LFMs) aim to find latent factors and are commonly implemented using Matrix Factorization (MF) [24, 25, 36, 38]. Polat et al. [36] combined SVD-based Collaborative Filtering with privacy to achieve accurate predictions while preserving privacy. Salakhutdinov et al. [38] proposed Probabilistic Matrix Factorization, which scales linearly with the number of observations and performs well on sparse and imbalanced datasets. Koren [24] presented an integrated model combining neighborhood and LFM, optimizing a global cost function and integrating implicit feedback. Koren [25] introduced a methodology for modeling time-drifting user preferences in recommender systems.

#### Neural Collaborative Filtering
With the advancement of deep learning, neural network-based recommendation algorithms have become popular [2, 9, 16, 46, 47]. He et al. [16] proposed the first framework for collaborative filtering based on neural networks, showing that MF can be interpreted as a specialization of NCF and utilizing a Multilayer Perceptron (MLP) to introduce non-linearities. Bai et al. [2] presented a model integrating neighborhood information into NCF, called Neighborhood-based Neural Collaborative Filtering. Chen et al. [9] designed a Joint Neural Collaborative Filtering model, enabling deep feature learning and deep user-item interaction modeling in a single neural network.

### 6 Discussion

In the previous evaluations, our attack demonstrated its effectiveness and strong generalization ability. The proposed defense mechanism, Popularity Randomization, significantly mitigated the attack performance. To gain a comprehensive understanding of membership inference attacks, we focused on three important factors: the choice of datasets, the selection of recommendation algorithms, and the distributions of generated user features.

- **Choice of Datasets**: Denser user-item matrices lead to better attack performance due to richer information facilitating item vectorization and attack model training. The ml-1m dataset, with the densest user-item matrix, achieved the best overall performance (average AUC of 0.873).
- **Selection of Recommendation Algorithms**: Simpler model structures are easier to attack. The attack against LFM, with higher model complexity, performed poorly compared to Item and NCF. Defending simpler recommender systems is more challenging, as seen in the strong performance of attacks against Item even with the defense mechanism.
- **Distributions of Generated User Features**: Higher attack performance is achieved when the distribution of user feature vectors generated by the shadow recommender is more similar to that of the target recommender. Training with samples from similar distributions boosts attack performance, as seen in the better performance of "MLAI" (0.608) compared to "ALLI" (0.547).

### 7 Conclusion

Recommender systems have achieved significant success in real-world applications, but the data they use is highly sensitive. Successfully inferring a user's membership status from a target recommender can lead to severe privacy consequences. In this paper, we designed various attack strategies for membership inference against recommender systems, focusing on user-level membership status. We proposed a novel membership inference attack scheme, which generates user-level feature vectors based on interactions with the target recommender and inputs these vectors into attack models. Extensive experimental results demonstrated the effectiveness and generalization ability of our attack. To mitigate the privacy risks, we proposed the Popularity Randomization defense mechanism, which significantly reduced the attack performance.

### Acknowledgments

We thank the anonymous reviewers for their insightful feedback. This work was supported by the Natural Science Foundation of China (61902219, 61972234, 62072279, 62102234), the Helmholtz Association within the project “Trustworthy Federated Data Analytics” (TFDA) (funding number ZT-I-OO1 4), the National Key R&D Program of China (grant No. 2020YFB1406704), the Key Scientific and Technological Innovation Program of Shandong Province (2019JZZY010129), Shandong University multidisciplinary research and innovation team of young scholars (No. 2020QNQT017), and the Tencent WeChat Rhino-Bird Focused Research Program (JR-WXG2021411). All content represents the opinion of the authors and is not necessarily shared or endorsed by their respective employers and/or sponsors.

### References

[1] Michael Backes, Mathias Humbert, Jun Pang, and Yang Zhang. walk2friends: Inferring Social Links from Mobility Profiles. In ACM SIGSAC Conference on Computer and Communications Security (CCS), pages 1943–1957. ACM, 2017.

[2] Ting Bai, Ji-Rong Wen, Jun Zhang, and Wayne Xin Zhao. A Neural Collaborative Filtering Model with Interaction-based Neighborhood. In ACM International Conference on Information and Knowledge Management (CIKM), pages 1979–1982. ACM, 2017.