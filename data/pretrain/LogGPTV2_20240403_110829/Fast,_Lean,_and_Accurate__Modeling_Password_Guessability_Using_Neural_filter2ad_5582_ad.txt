105
107
LSTMLSTMRefine
101 103 105 107 109 10111013101510171019102110231025
(c) LSTM vs. reﬁned LSTM.
Guesses
101
103
Guesses
(b) Tokenization on long passwords.
Figure 4: Additional tuning experiments. Our LSTM experiments tested on complex passwords with 16M parameters. We found
very little difference in performance. Our experiments on tokenization examined long passwords. Our experiments on training
direction involved training backwards, forwards, and both backwards and forwards with 16M parameters on complex passwords.
guessing approaches, including neural networks, Markov
models, PCFG, JtR, and Hashcat. That MinGuess out-
performs neural networks suggests that using multiple
guessing methods should still be preferred to using any
single guessing method for accurate strength estimation,
despite the fact that neural networks generally outper-
form other models individually.
For all the password sets we tested, neural networks
outperformed other models beginning at around 1010
guesses, and matched or beat the other most effective
methods before that point. Figures 5-6 show the per-
formance of the different guessing methods trained with
the PGS data set, and Figures 7-8 show the same guess-
ing methods trained with the PGS++ data set. Both data
sets are described in more detail in Section 4.1. In this
section, we used our large, 15.7 million parameter neu-
ral network, trained with transference learning on two
training sets. While performance varies across guessing
method and training set, in general we ﬁnd that the neural
networks’ performance at high guess numbers and across
policies holds for both sets of training data with one ex-
ception, discussed below. Because these results hold for
multiple training and test sets, we hypothesize that neu-
ral networks would also performe well in guessing pass-
words created under many policies that we did not test.
In the webhost test set using the PGS++ training data,
neural networks performed worse than other methods.
For webhost, all guessing methods using the PGS++ data
set were less effective than the PGS data set, though
some methods, such as PCFG, were only slightly af-
fected. Because all methods perform worse, and because,
when using the PGS training data, neural networks do
better than other methods—similar to other test sets—
we believe that the PGS++ training data is particularly
ineffective for this test set. As Figure 3 shows, this is the
only data set where a smaller neural network performs
signiﬁcantly better than the larger neural network, which
suggests that the larger neural network model is ﬁtting
itself more strictly to low-quality data, which limits the
larger network’s ability to generalize.
Qualitatively, the types of passwords that our imple-
mentation of neural networks guessed before other meth-
ods were novel passwords that were dissimilar to pass-
words in the training set. The types of passwords that our
implementation of neural networks were late to guess but
that were easily guessable by other methods often were
similar to words in the natural-language dictionaries, or
were low-frequency occurrences in the training data.
Resource Requirements
In general, PCFGs require
the most disk, memory, and computational resources.
Our PCFG implementation stored its grammar in 4.7GB
of disk space. Markov models are the second largest
of our implementations, requiring 1.1GB of disk space.
Hashcat and JtR do not require large amounts of space
for their rules, but do require storing the entire training
set, which is 756MB. In contrast, our server-side neural
network requires only 60MB of disk space. While 60MB
is still larger than what could effectively be transferred to
a client without compression, it is a substantial improve-
ment over the other models.
5.3 Browser Implementation
While effective models can ﬁt into 60MB, this is still too
large for real-time password feedback in the browser. In
this section, we evaluate our techniques for compress-
ing neural network models, discussed in Section 3.3, by
comparing the guessing effectiveness of the compressed
models to all server-side models—our large neural net-
work, PCFG, Markov models, JtR, and Hashcat.
Model Encoding Our primary size metric is the gzip-
ed model size. Our compression stages use the JSON for-
mat because of its native support in JavaScript platforms.
We explored using the MsgPack binary format [4], but
found that after gzip compression, there was no bene-
ﬁt for encoding size and minor drawbacks for decoding
speed. The effects of different pipeline stages on com-
pression are shown in Table 1.
USENIX Association  
25th USENIX Security Symposium  185
11
MinGuess
Neural
Markov
PCFG
Hashcat
JTR
101 104 107101010131016101910221025
Guesses
(a) 1class8 passwords
MinGuess
Neural
Markov
PCFG
JTR
Hashcat
101 104 107101010131016101910221025
Guesses
(b) 4class8 passwords
75%
50%
25%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
0%
100%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
75%
50%
25%
0%
MinGuess
Neural
Markov
PCFG
JTR
Hashcat
101 104 107 101010131016101910221025
Guesses
(a) 3class12 passwords
MinGuess
Neural
Markov
PCFG
JTR
Hashcat
101 104 107101010131016101910221025
Guesses
(b) Webhost passwords
90%
60%
30%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
0%
100%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
75%
50%
25%
0%
75%
50%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
25%
0%
MinGuess
Neural
Markov
PCFG
Hashcat
JTR
101 104 107 101010131016101910221025
Guesses
(c) 1class16 passwords
Figure 5: Guessability of our password sets for different
guessing methods using the PGS data set. MinGuess stands
for the minimum number of guesses for any approach. Y-axes
are differently scaled to best show comparative performance.
Weight and Probability Curve Quantization Be-
cause current methods of calculating guess numbers
from probabilities are too slow, taking hours or days to
return results, we precompute a mapping from password
probability to guess number and send the mapping to the
client, as described in Section 3.3.2. Such a mapping
can be efﬁciently encoded by quantizing the probability-
to-guess-number curve. Quantizing the curve incurs safe
errors—i.e., we underestimate the strength of passwords.
Figure 6: Guessability of our password sets for different
guessing methods using the PGS data set (continued).
We also quantize the model’s parameters in the browser
implementation to further decrease the size of the model.
Both weight and curve quantization are lossy operations,
whose effect on guessing we show in Figure 9. Curve
quantization manifests in a saw-tooth shape to the guess-
ing curve, but the overall shape of the guessing curve is
largely unchanged.
Evaluating Feedback Speed Despite the large amount
of computation necessary for computing a password’s
guessability, our prototype implementation is efﬁcient
enough to give real-time user feedback.
In general,
feedback quicker than 100 ms is perceived as instanta-
neous [72]; hence, this was our benchmark. We per-
formed two tests to measure the speed of calculating
guess numbers: the ﬁrst measures the time to produce
guess numbers with a semi-cached password; the second
computes the total time per password. The semi-cached
test measures the time to compute a guess number when
adding a character to the end of a password. We believe
this is representative of what a user would experience in
practice because a user typically creates a password by
typing it in character by character.
186  25th USENIX Security Symposium 
USENIX Association
12
r
e
b
m
u
N
s
s
e
u
G
n
M
>1e20
>1e16
>1e12
>1e8
>1e4
>1e0
i
0
1
2
9
358
325
>1e0
0
10
43
421
629
11
>1e4
0
5
223
531
97
0
>1e8
3
60
135
32
12
0
12
36
4
4
1
0
31
1
2
0
0
0
r
e
b
m
u
N
s
s
e
u
G
n
M
>1e20
>1e16
>1e12
>1e8
>1e4
>1e0
i
>1e12
>1e16
>1e20
Neural Network Guess Number 
(a) Client-side Neural Network
0
0
0
3
79
252
>1e0
21
38
29
9
3
0
9
66
325
555
180
0
>1e8
0
13
6
3
54
1
430
0
835
0
84
0
>1e16
>1e4
ZXCVBN Guess Number 
(b) zxcvbn
>1e12
3
0
0
0
0
0
>1e20
r
e