over-approximate result.
Most applications of zero-knowledge abstract interpretation will
likely be of the first form, where the prover wants to demonstrate
the absence of bugs in a program, and the verifier will be satisfied by
merely checking the solution is some fixpoint, and not necessarily
the least one. However, the algorithm to just check the solution to
the fixpoint—rather than compute it—is realized easily as a small
modification to Algorithm 1. Therefore, because the checking al-
gorithm is a simple refinement of the fixpoint-finding algorithm
(in both application and algorithmic description) we focus on the
full fixpoint-finding algorithm throughout this paper for the sake
of completeness. We discuss the implementation-specific details of
the refined algorithm and its tradeoffs in Appendix 5.
3 ZERO-KNOWLEDGE ABSTRACT
INTERPRETATION
Motivated by the applications mentioned in the introduction, we
are working in the following model. The prover owns a secret
program. She commits to the program at first, and then later engage
in a zero-knowledge proof to convince the verifier the presence or
absence of some bugs in the program via abstract interpretation.
We assume that the algorithm of the static analysis is public to
both the prover and the verifier. The verifier is able to validate the
correctness of the result of the analysis through zero knowledge
abstract interpretation, while the program of the prover remains
confidential during the protocol.
Formally speaking, let F be a finite field, 𝑝 be a secret program
with 𝑛 lines and 𝑚 flows. Suppose the prover and the verifier agree
on an abstract interpretation, which is described by a lattice val♯,
transfer functions A𝑝,𝑙, a worklist algorithm Alg, and a final cal-
culation 𝑔. 𝑔(Alg(𝑝, val♯, A𝑝,𝑙)) ∈ {0, 1} indicates the presence or
absence of bugs. A zero-knowledge abstract interpretation (zkAI)
scheme consists of algorithms:
generates the public parameter pp.
secret program 𝑝. We omit the randomness here.
• pp ← zkAI.G(1𝜆): given the security parameter, the algorithm
• com𝑝 ← zkAI.Commit(𝑝, pp): the algorithm commits to the
• (𝑦, 𝜋) ← zkAI.P(𝑝, (val♯, A𝑝,𝑙 , Alg, 𝑔), pp): the prover runs Alg
over 𝑝 to get a sound analysis result 𝑆, runs 𝑔 over 𝑆 to obtain the
result 𝑦 of the analysis, and generates the corresponding proof 𝜋.
• {1, 0} ← zkAI.V(com𝑝, (val♯, A𝑝,𝑙 , Alg, 𝑔), 𝑦, 𝜋, pp): the verifier
validates the claim about the program with parameters of the
analysis (val♯, A𝑝,𝑙 , Alg, 𝑔), and the proof 𝜋.
A zkAI scheme also has the properties of correctness, soundness
and zero-knowledge as generic zero-knowledge proofs. We give
the formal definitions in Appendix B.
3.1 Program Representation
The general idea to construct a zero-knowledge abstract interpre-
tation scheme is as follows. In the beginning, the prover sends
the committment com𝑝 of a program 𝑝 to the verifier. After re-
ceiving (val♯, A𝑝,𝑙 , Alg, 𝑔) from the verifier, the prover computes
the analysis result 𝑆 and the corresponding witness 𝑤 for prov-
ing 𝑔(Alg(𝑝, val♯, A𝑝,𝑙)) = 1. We treat it as some relationship
R = ((𝑐𝑜𝑚𝑝, val♯, A𝑝,𝑙 , Alg, 𝑔); 𝑤) in Definition 1. Then the verifier
and the prover invoke the backend zero-knowledge proofs protocol
to verify the relationship R without leaking any information of 𝑝.
At the beginning of our zkAI scheme, in order for the prover to
commit to the secret program, we need an arithmetic representation
of the program. Therefore, we first introduce our programming
language to work on, and then describe its arithmetic representation.
We choose to work on a simple language used in [56], instead of ones
such as Java or C++ to avoid language-specific details. However,
our zero-knowledge proof scheme does not lose generality because
the language is still expressive enough. It is Turing-complete, and
languages such as Java and C++ can be compiled to it.
Our Programming Language. We choose to start with a specific
imperative programming language as shown in Figure 1. In this
language, a program is composed of many statements, and each
statement can be either an assignment, a branch, or a loop2. 𝑎
denotes an expression, and it may be a variable 𝑥, a constant 𝑛,
a unary expression 𝑜𝑝1 and a binary expression 𝑜𝑝2. The value
of a variable can be either integers or booleans, and thus we use
logical operators 𝑎𝑛𝑑|𝑜𝑟|𝑛𝑜𝑡 and mathematical operators +| − | ∗ |/
in our language. We will extend this to incorporate function calls
in Section 4 as they are common in programming languages even
though doing so will not change the expressiveness.
Arithmetic Representation. Then we describe how to convert
the program to an arithmetic representation. We choose to use table
structures to represent the whole program. Details are shown in
Table 1. For each type of statements,
(1) A unique ‘Stmt Code’ is assigned.
(2) The ‘Line No.’ field stores the line number of the statement
in the program. For if and while statements, this refers to
the line where if and while condition lies.We treat else
2In our implementation, we also have statements of memory read and memory write.
They are processed similarly to assignments in the worklist algorithm, and we omit
them in the description for simplicity.
Session 11B: Zero Knowledge II CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2955Stmt Code
1
2
3
Line No.
a
/
/
Line No.(else)
/
Line No.(end)
/
variable ID (x)
/
Expression Code Variable ID (𝑥1) Variable ID (𝑥2) Value Op code
Stmt
x=a
if ... else ... end
while... do ... end
Expression 𝑎
𝑥1
𝑛
𝑜𝑝1 x
𝑥1 𝑜𝑝2 𝑥2
1
2
3
4
/
/
/
Table 1: Arithmetic representation of our programs.
/
/
/
/
/
/
stmt ::= 𝑥 = 𝑎
| if 𝑥 then stmt else stmt end
| while 𝑥 do stmt end
𝑎 ::= 𝑥 | 𝑛 | op1 𝑥 | 𝑥1 op2 𝑥2
op1 ::= not
op2 ::= + | − | ∗ | /| and | or
Figure 1: Our imperative programming language.
and end as a single line so that they have Line No. as well.
This helps upper-bound the number of outgoing edges in
later control flow graph construction.
(3) The field 𝑎 is only used in the assignment expression.
(4) ‘Variable ID’ refers to the left part of the assignment state-
ments and conditions in if and while statements.
Similarly, for each expression 𝑎, we use ‘Expression Code’ to
identify the type of the expression. We store two possible ‘Vari-
able ID’s, a ‘constant’ and an ‘Op code’. A ‘/’ symbol in the table
means that the field is not applicable for this type of statement or
expression and is left empty.
Using these table structures, we can represent the whole program
as a sequence of elements in the field F, and the prover can commit
it using existing commitment schemes.
3.2 Proving Intra-procedure Analysis
With our simple programming language and its arithmetic rep-
resentation, one can simply construct a zero-knowledge abstract
interpretation scheme using generic zero-knowledge proofs. The
prover commits to the secret program, and then proves the result
of Algorithm 1 on the program using generic ZKP. Unfortunately,
such a naive approach would introduce a high overhead on the
efficiency. Most generic ZKP schemes represent the computation as
an arithmetic circuit, and turning Algorithm 1 into an arithmetic
circuit naively would introduce a high overhead on the size of the
circuit. There exist RAM-based ZKP schemes that reduce RAM
programs to arithmetic circuits through RAM-to-circuit reduction.
The size of the circuit preserves the asymptotic running time of the
RAM program. However, the concrete overhead of these schemes
in practice is usually high. For example, each RAM instruction costs
thousands of arithmetic gates to implement [14, 16, 73].
In this section, we present our construction of the zero-knowledge
abstract interpretation. Using ideas in the literature of RAM-based
ZKP [14, 16, 21, 22, 66, 73], we construct an efficient arithmetic
circuit to validate the correct execution of Algorithm 1 on the
committed program. The prover and the verifier then invoke a
circuit-based ZKP scheme to prove and validate the result of the
abstract interpretation.
Figure 2 shows the main construction of our scheme. The red
part is the secret program owned by the prover, the blue part is
additional auxiliary input from the prover to validate the abstract
interpretation efficiently (see below), and the green part is the result
of the analysis.
Based on the functionality, our scheme is mainly divided into
four parts: 1) Checking the consistency between the program and
the control flow graph. 2) Checking the correct execution of each
iteration. 3) Checking lattice operations and transfer functions.
4) Deciding whether there are bugs or not based on the result of
Algorithm 1. The first and the second part is problem-independent,
and the third and the fourth part is problem-dependent. The fourth
part is usually simple in practice, containing only a few conditions.
Therefore, we focus on the first three parts in this section.
Control flow graph consistency. Since abstract interpretation
works on flows (𝑙, 𝑙′), in our zero-knowledge abstract interpretation
scheme, we first ask the prover to provide a control flow graph as
an auxiliary input to the circuit. In this graph, each node is a line of
code labeled by its line number, and an edge denotes a flow (𝑙, 𝑙′)
from node 𝑙 to node 𝑙′. Since we treat else and end as separate
lines, in our simple programming language a node in this graph can
have at most two outgoing edges in the case of loops and branches.
Therefore, we represent the entire control flow graph using a table
of size 𝑛×2. The 𝑙-th row of the table stores the target line numbers
of the two possible outgoing edges of line 𝑙.
We then have to check that this control flow graph is indeed
consistent with the program. Note that we can obtain all the pos-
sible flows (𝑙, 𝑙′) from the program representation in Table 1. We
go through the whole program line by line, and each statement
individually contributes to a few flows. An assignment statement
produces only a single flow (𝑙, 𝑙 + 1); a while statement produces
three flows, (𝑙, 𝑙 + 1), (𝑙, 𝑙end + 1), (𝑙end, 𝑙); an if statement produces
four flows, (𝑙, 𝑙 + 1), (𝑙, 𝑙else + 1), (𝑙else, 𝑙end), (𝑙end, 𝑙end + 1). The
flows deduced by the 𝑛 × 2 table are simply permutations of these
flows obtained by the linear scan of the program, ordered by the
first line number 𝑙.
In order to check that they are consistent, we apply existing
techniques in [61, 67, 73] for testing set equality. In these techniques,
we first combine the pair of values in each element of the sets
through H(𝑙, 𝑙′) = 𝑛𝑙 + 𝑙′, where 𝑛 is the number of lines in the
program. Then we compute the characteristic functions ℎ of the sets:
ℎ𝐴(𝑥) =(𝑙,𝑙′)∈𝐴(H(𝑙, 𝑙′) − 𝑥). Once the characteristic functions
for the two sets are calculated respectively, a random challenge 𝑟
from the verifier is generated. If the two characteristic functions
Session 11B: Zero Knowledge II CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2956agree on the random point 𝑟, then they will be the same with
overwhelming probability by the Schwartz-Zippel Lemma [60, 74].
The size of the circuit for the check above is 𝑂(𝑛).
Correct execution of the iteration. With the control flow graph
provided by the prover, we then show how to execute each iteration
of Algorithm 1. The correct execution of the iteration can be fur-
ther divided into executing queue operations, fetching instructions,
reading and writing analysis states and extracting following flows.
The queue operation is not naturally supported by circuits. A
queue 𝑊 has 𝑝𝑢𝑠ℎ and 𝑝𝑜𝑝 operations, which follows a first-in-
first-out strategy. We model the queue as an array 𝑎𝑟𝑟 with a head
index 𝑠 and a tail index 𝑡. When 𝑊 .𝑝𝑢𝑠ℎ(𝑒) is called, we increment
𝑡, and write the element 𝑒 into 𝑎𝑟𝑟[𝑡]. Similarly, when 𝑊 .𝑝𝑜𝑝() is
called, we return 𝑎𝑟𝑟[𝑠] and then increment 𝑠. For the queue 𝑊
used in Algorithm 1, we observe that exactly one flow is popped
in each iteration and at most 2 flows are pushed into the queue, as
each line has at most two outgoing flows. Therefore, we can ask the
prover to provide the entire execution trace of the queue 𝑊 as an
auxiliary input. The circuit first checks that the queue is initialized
correctly, i.e., the first 𝑚 flows are the same as those in the control
flow graph. Then in each iteration, 𝑠 increases by 1 and the pop
operation in step 4 is a linear scan over the entire trace.
𝑡, however, is more complicated to deal with. As at most 2 flows
are pushed in each iteration, we ask the prover to provide 𝑎𝑟𝑟[𝑡]