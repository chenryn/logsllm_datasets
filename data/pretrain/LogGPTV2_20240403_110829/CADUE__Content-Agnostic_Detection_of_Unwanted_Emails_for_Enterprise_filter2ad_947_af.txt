[25] S. Kitterman. 2020. Sender Policy Framework (SPF). https://tools.ietf.org/html/
[26] A. Li, Z. Qin, R. Liu, Y. Yang, and D. Li. 2019. Spam Review Detection with
Graph Convolutional Networks. In Proceedings of the 28th ACM International
Conference on Information and Knowledge Management (Beijing, China) (CIKM
’19). Association for Computing Machinery, New York, NY, USA, 2703–2711.
https://doi.org/10.1145/3357384.3357820
[27] J. Li, Q. Wang, C. Wang, N. Cao, K. Ren, and W. Lou. 2010. Fuzzy Keyword Search
over Encrypted Data in Cloud Computing. In 2010 Proceedings IEEE INFOCOM.
[28] Y. N. Liu, Y. Han, X. D. Zhu, F. He, and L. Y. Wei. 2014. An expanded feature
extraction of e-mail header for spam recognition. In AMR, Vol. 846. 1672–1675.
[29] Posteo Mail. 2020. https://posteo.de/.
[30] Tutanota Mail. 2020. https://tutanota.com/.
[31] Mailfence. 2020. https://mailfence.com/.
[32] Esko Nuutila. 1998. Efficient transitive closure computation in large digraphs.
rfc7208.
[33] Lawrence Page. 2001. Method for node ranking in a linked database. US Patent
[34] Gilchan Park and Julia M Taylor. 2015. Using syntactic features for phishing
detection. arXiv preprint arXiv:1506.00037 (2015).
[35] Karl Pearson. 1905. The problem of the random walk. Nature 72, 1867 (1905),
(1998).
6,285,999.
342.
[36] P. Pons and M. Latapy. 2005. Computing Communities in Large Networks Using
Random Walks. In ISCIS. 284–293.
[37] ProtoMail. 2020. Secure email. https://protonmail.com/.
[38] A. Ramachandran, N. Feamster, and S. S. Vempala. 2007. Filtering spam with
behavioral blacklisting. In CCS. 342–351.
[39] J. Rao and D. Reiley. 2012. The economics of spam. JEP 26, 3 (2012), 87–110.
[40] P. Resnick. 2001. RFC 2822. https://tools.ietf.org/html/rfc2822l.
[41] M. Rosvall and C. Bergstrom. 2008. Maps of random walks on complex networks
reveal community structure. NAS 105, 4 (2008), 1118–1123.
[42] S. Sheng, B. Wardman, G. Warner, L. Cranor, J. Hong, and C. Zhang. 2009. An
empirical analysis of phishing blacklists. In CEAS. California, USA.
[43] A. Soliman and S. Girdzijauskas. 2017. AdaGraph: Adaptive Graph-Based Algo-
rithms for Spam Detection in Social Networks. In NS. Cham, 338–354.
[44] G. Stringhini and O. Thonnard. 2015. That ain’t you: Blocking spearphishing
through behavioral modelling. In DIMVA. Springer, 78–97.
[45] Dan Sullivan. 2005. The definitive guide to controlling malware, spyware, phishing,
and spam. Realtimepublishers. com.
[46] A. Vazhayil, N. Harikrishnan, R. Vinayakumar, K. Soman, and A. Verma. 2018.
PED-ML: Phishing email detection using classical machine learning techniques.
In IWSPA. Tempe, AZ, USA, 1–8.
[47] R. Verma and N. Hossain. 2013. Semantic feature selection for text with applica-
tion to phishing email detection. In ICISC. Springer, 455–468.
[48] Rakesh Verma, Narasimha Shashidhar, and Nabil Hossain. 2012. Detecting phish-
ing emails the natural language way. In ESRCS. Springer, 824–841.
[49] C. Wang and S. Chen. 2007. Using header session messages to anti-spamming.
Computers & Security 26, 5 (2007), 381–390.
[50] Y. Zhauniarovich, I. Khalil, T. Yu, and M. Dacier. 2018. A Survey on Malicious
Domains Detection through DNS Data Analysis. ACM Comput. Surv. 51, 4 (2018),
67:1–67:36.
A APPENDIX
A.1 Header Features
Table 10 summarizes the header features. Next, we describe these
header features in details. For better readability, we append the
relevant category name (SUBJ, NS, and DEP) to the feature name.
SUBJECT features: The first 19 features (features No. 1 - 19 in
Table 10) are extracted from the SUBJECT of the email. Out of
these 19 features, the first 15 (features No. 1 - 15 in Table 10) check
whether the subject contains specific keywords from a blacklist
suggested by Apache SpamAssassin [2, 3]. The SpamAssassin black-
list compiles the keywords that were observed as frequently being
appeared in spam and promotional emails. Each of these 15 fea-
tures is binary, returning 1 if a particular keyword (e.g., "hello",
"save" and "free") appears in the subject field and 0 otherwise.
The SUBJ_HAS_USERNAME feature (No. 16 in Table 10) is also
a binary feature with value 1 if the user’s nickname in the from
field is shown in the subject field. This feature is crafted to cap-
ture an observed behavior in some spam and promoting emails
in which adversaries include users’ nickname in the subject as a
social motivation to increase the chances of opening the email. The
SUBJ_CODED feature (No. 17) returns 1 if the subject contains non-
ASCII characters, otherwise returns 0. This feature is motivated by
the observation that some promoting emails include emojis in the
subject. The SUBJ_CAPS_PERCENTAGE feature (No. 18) computes
the percentage of capital letters in the subject field, as subjects
of unwanted emails (e.g., promotional ones) are likely to contain
more capital letters than normal emails, may be to draw attention.
The last feature (No. 19) computes the percentage of white spaces
in the subject field. It is mainly designed to model unwanted (e.g.,
spam) emails that use white spaces to separate letters, especially in
keywords that appear frequently in the subject field. Adversaries
usually use the white spaces trick to evade detection by systems
that employ keyword detection against a blacklist. Finally, note that
217RAID ’21, October 6–8, 2021, San Sebastian, Spain
Mohamed Nabeel, Enes Altinisik, Haipei Sun, Issa Khalil, Hui (Wendy) Wang, and Ting Yu
Group
SUBJECT [2]
NON-SUBJECT
[2]
DEPENDENCY
[2, 28]
Feature
SUBJ_ACCOUNT
SUBJ_APPROVED
SUBJ_BUY
SUBJ_EARN
SUBJ_FAMILY
SUBJ_FREE
SUBJ_GAPPED
SUBJ_GUARANTEED
SUBJ_HELLO
SUBJ_MONEY
SUBJ_ONLY
SUBJ_OWN
SUBJ_PLING_QUERY
SUBJ_SAVE
SUBJ_STATEMENT
SUBJ_HAS_USERNAME
SUBJ_CODED
SUBJ_CAPS_PERCENTAGE
SUBJ_SPACE_PERCENTAGE
No.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20 NS_CC_NUMBER
21 NS_CC_EMPTY
22 NS_DATE_INVALID
23 NS_DATETZ_INVALID
24 NS_FROM_2ADDR
25 NS_FROM_CODED
26 NS_FROM_FREE
27 NS_FROM_NOREPLY
28 NS_FROM_OFFERS
29 NS_FROM_MIXED
30 NS_FROM_NO_LOWER
31 NS_FROM_NOADDR
32 NS_FROM_NOUSER
33 NS_INREPLYTO
34 NS_MAILFROM_BOUNCE
35 NS_MSGID_NO_AT
36 NS_MSGID_NO_HOST
37 NS_REPLYTO_MIXED
38 NS_REPLYTO_NOADDR
39 NS_TO_MISSING
40 NS_TO_NO_ADDR
41 NS_TO_SORTED
42 NS_WEBMAIL_TRUE
43 DEP_MAILFROM_FROM [28]
44 DEP_MAILFROM_HELO [28]
45 DEP_MAILFROM_REPLYTO [28]
46 DEP_MSGID_HELO [28]
47 DEP_IN_FUTURE [2]
Domain Description
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
[0, 1]
[0, 1]
N
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
{0, 1}
[0, 1]
[0, 1]
[0, 1]
[0, 1]
{0, 1}
If subject field has keyword "account".
If subject field has keyword "approve" or "approval".
If subject field has keyword "buy".
If subject field has keyword "earn".
If subject field has keyword "family".
If subject field has keyword "free".
If subject field is gapped by underlines or spaces.
If subject field has keyword "guarantee".
If subject field has keyword "hello".
If subject field has keyword "money".
If subject field has keyword "only".
If subject field has keyword "own".
If subject field has keyword "?" or "!".
If subject field has keyword "save" or "saving".
If subject field has keyword "statement".
If user nickname in from field shows in subject.
If subject field contains non-ASCII characters
Percentage of capital letters in subject field.
Percentage of white space in subject.
Number of recipients in cc field.
If the cc field exists but empty.
If the format of sending timestamp is invalid.
If the format of sending timezone is invalid.
If from field contains more than one email address.
If from field is coded with non-ASCII char set after decoding.
If from field contains keyword "free".
If from field contains keyword "no-reply".
If from field contains keyword "offer".
If from field contains numbers mixed in with letters.
If from field doesn’t have lower case letter.
If from field doesn’t have a valid address.
If from field doesn’t have a user nickname.
If in_reply_to field exists.
If mailfrom field has keyword "bounce".
If message_id field does not have "@".
If message_id field does not have a valid domain.
If reply_to field exists and contains numbers mixed with letters.
If reply_to field exists but no valid address.
If to field is missing.
If the to field does not exist or has no valid address.
If more than 2 recipients in to field and in alphabetical order.
If is_webmail field is true (email was sent from a web interface).
Similarity between mailfrom field address and field from address.
Similarity between mailfrom field and helo field.
Similarity between mailfrom field and field reply_to (if exists).
Similarity between message_id field and field helo.
If the sending timestamp is in the future of receiving time stamp.
Table 10: Header Features
all these 19 SUBJECT features will not be available if the subject is
encrypted.
NON-SUBJECT features: The next 23 features (No. 20 - 42) in
Table 10 does not use any information from the subject field, and
hence dubbed NON-SUBJECT features. These features are grouped
according to the fields from which they are derived. Features 20 and
21 are derived from the cc field. In particular, NS_CC_NUMBER (No.
20) returns the number of recipients in the cc field. This is based on
observations that unwanted emails (e.g., spam) are typically sent to
a large number of recipients by cc’ing them. The NS_CC_EMPTY
218CADUE: Content-Agnostic Detection of Unwanted Emails for Enterprise Security
RAID ’21, October 6–8, 2021, San Sebastian, Spain
feature (No. 21) captures the behavior in which some unwanted
emails include empty cc field as observed in [28, 45]. The next
two features (No. 22 and 23) are extracted from the date field as
recommended by the integrity analysis in [45]. Each of these two
features will return a value of 1 if the format of the timestamp and
time zone is invalid according to RFC 2822 [40], respectively. The
next 9 features (No. 24 - 32) are extracted from the from field. These
features mainly model the coding of the from field (No. 25), check
if it contains some specific keyword (No. 26 - 28), if it has some
character patterns (No. 29 - 30), and if it has a valid address (No. 31)
and a user nickname (No. 32). The remaining features are extracted
from in_reply_to field (No. 33), mailfrom field (No. 34 feature),
message_id field (No. 35 & 36 features), reply_to field (No. 37 &
38 features), to field (No. 39 - 41 feature), and is_webmail field
(No. 42 feature). It is worth mentioning that NS_TO_SORTED (No.
41) captures the fact that the alphabetical order among multiple
recipients in the to field is a potential indicator of a spam email,
since a non-spam email typically contains a list of addresses in
random order. Furthermore, NS_WEBMAIL_TRUE (No. 42) is de-
signed to account for the cases when webclients are used to send
the unwanted emails. The intuition is that adversaries tend to use
webmail services as one of the economic ways to send unwanted
emails [39].
DEPENDENCY features SUBJECT and NON-SUBJECTS fea-
tures are derived from individual fields and only can indicate spam
emails. To detect phishing emails, we also derive five features from
the dependency between a pair of fields. Among these five features,
four of them (No. 43 - 46 in Table 10) model the content similarity
between a pair of header fields. The content similarity can be mea-
sured by any string similarity metrics, e.g., Levenshtein distance
and Jaccard similarity. In particular, we consider the consistency
between the from and mailfrom fields (feature No. 43), between the
mailfrom and helo fields (feature No. 44), between the mailfrom
and reply_to fields (feature No. 45), and between the message_id
and helo fields (feature No. 46). Finally, we design the fifth feature
(No. 47 feature) to capture the temporal dependency between the
send and receive timestamps. Intuitively, the sending timestamp
should precede that of receiving. However, a phishing email may
not show such temporal dependency.
219