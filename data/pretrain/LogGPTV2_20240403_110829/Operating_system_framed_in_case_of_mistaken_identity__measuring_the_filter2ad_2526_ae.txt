cret is unnecessary—the user need only enter the secure at-
tention sequence to check if it can be made to appear.
Finally, even if a trusted path ritual can be created, the ex-
istence of the ritual alone will be insuﬃcient to protect users.
So long as users are regularly asked to provide credentials
or perform security-critical actions via other paths, they will
be habituated to do so when the next attack comes.
8. CONCLUSION
Only a minority of participants in our study recognized
that a spoofed operating system credential-entry window
was an attempt to steal their passwords.
In our most ef-
fective attacks, more than 20% of Windows users entered
usernames and passwords into a spoofed UAC window, later
admitting that these were genuine device-login credentials.
Providing a trusted path through which users can enter cre-
dentials securely is not in itself suﬃcient to prevent such
attacks. Rather, operating systems must also forbid the col-
lection of device-login credentials through less secure paths
(e.g. spoofable windows), lest users become habituated to
entering credentials when straying oﬀ the trusted path.
Acknowledgements
The authors want to thank John Douceur (Microsoft Re-
search), Serge Egelman (UC Berkeley), David Molnar (Mi-
crosoft Research), Rob Reeder (Microsoft), Adam Shostack
(Microsoft) and the anonymous reviewers for their helpful
reviews and suggestions on early versions of the paper. This
research was funded in part by NSF grants CNS0831428,
CNS1116934, and DGE090365.
7. A PATH FORWARD?
The challenge in developing strategies to address the trusted
path problem is that one cannot use lab studies, or even
short-term ﬁeld studies, to prove these strategies are re-
silient to attack. Users are habituated to security rituals
over time through repeated conditioning. To study how par-
ticipants respond to attacks, researchers must study partici-
pants who are already conditioned. In other words, proving
that a trusted path ritual will resist real-world attacks re-
quires deploying the ritual into the hands of users who will
be relying on it to do so.
Given the extreme costs of establishing the security of a
trusted path ritual, we think it’s essential to learn as much
as possible from what isn’t working today. Relying on subtle
cues to establish that a Window belongs to the OS does not
seem to work.
The failures of individual trusted path mechanisms sug-
gest that the problem is unlikely to be addressed adequately
by any single mechanism. Rather, future work may focus
on rituals that combine mechanisms. For example, consider
rituals in which users must ﬁrst enter a shared attention se-
quence and then expect to see a visual shared secret. These
two mechanisms may complement each other: the expec-
tation of a visual shared secret may make it harder for an
attacker to trick the user into entering a password (or per-
forming a security-sensitive action) without ﬁrst providing
9. REFERENCES
[1] Adelsbach, A., Gajek, S., and Schwenk, J.
Visual spooﬁng of SSL protected web sites and
eﬀective countermeasures. Information Security
Practice and Experience (2005), 204–216.
[2] Bravo-Lillo, C., Cranor, L. F., Downs, J., and
Komanduri, S. Bridging the gap in computer security
warnings: A mental model approach. IEEE Security &
Privacy Magazine 9, 2 (Mar. 2011), 18–26.
[3] Cova, M. Personal corresponence, May 5, 2012.
[4] Cova, M., Leita, C., Thonnard, O., Keromytis,
A. D., and Dacier, M. An analysis of rogue AV
campaigns. In Proceedings of the 13th International
Symposium on Recent Advances in Intrusion
Detection (RAID 2010) (Sept. 2010), pp. 442–463.
[5] Dhamija, R., and Tygar, J. D. The battle against
phishing: Dynamic security skins. In Proceedings of
the 2005 Symposium on Usable Privacy and Security
(New York, NY, USA, 2005), SOUPS ’05, ACM,
pp. 77–88.
[6] Dhamija, R., Tygar, J. D., and Hearst, M. Why
phishing works. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems
(New York, NY, USA, 2006), CHI ’06, ACM,
pp. 581–590.
375[7] Downs, J. S., Holbrook, M. B., and Cranor,
L. F. Decision strategies and susceptibility to
phishing. In Proceedings of the Second Symposium on
Usable Privacy and Security (New York, NY, USA,
2006), SOUPS ’06, ACM, pp. 79–90.
[8] Downs, J. S., Holbrook, M. B., Sheng, S., and
Cranor, L. F. Are your participants gaming the
system?: Screening mechanical turk workers. In
Proceedings of the 28th International Conference on
Human Factors in Computing Systems (New York,
NY, USA, 2010), CHI ’10, ACM, pp. 2399–2402.
[9] Felten, E. W., Balfanz, D., Dean, D., and
Wallach, D. S. Web spooﬁng: An Internet con
game. In 20th National Information Systems Security
Conference (Oct. 1996).
[10] Feske, N., and Helmuth, C. A nitpicker’s guide to
a minimal-complexity secure GUI. In Proceedings of
the 21st Annual Computer Security Applications
Conference (Washington, DC, USA, 2005), IEEE
Computer Society, pp. 85–94.
[11] Herzberg, A., and Gbara, A. Security and
identiﬁcation indicators for browsers against spooﬁng
and phishing attacks. Cryptology ePrint Archive,
Report 2004/155, 2004. http://eprint.iacr.org/.
[12] Initializing Winlogin, 2012.
http://msdn.microsoft.com/en-us/library/
windows/desktop/aa375994(v=vs.85).aspx.
[13] Jackson, C., Simon, D. R., Tan, D. S., and
Barth, A. An evaluation of extended validation and
picture-in-picture phishing attacks. In Proceedings of
the 11th International Conference on Financial
Cryptography and 1st International Conference on
Usable Security (Berlin, Heidelberg, 2007),
FC’07/USEC’07, Springer-Verlag, pp. 281–293.
[14] Kerr, K. Defend your apps and critical user info with
defensive coding techniques. MSDN Magazine (Nov.
2004).
http://msdn.microsoft.com/en-us/magazine/cc163883.aspx.
[15] Lefranc, S., and Naccache, D. Cut-&-paste
attacks with java. In Proceedings of the 5th
International Conference on Information Security and
Cryptology (Berlin, Heidelberg, 2003), ICISC’02,
Springer-Verlag, pp. 1–15.
[16] Li, T.-Y., and Wu, Y. Trust on web browser: Attack
vs. defense. In Applied Cryptography and Network
Security, J. Zhou, M. Yung, and Y. Han, Eds.,
vol. 2846 of Lecture Notes in Computer Science.
Springer Berlin / Heidelberg, 2003, pp. 241–253.
10.1007/978-3-540-45203-4 19.
[17] Libonati, A., McCune, J. M., and Reiter, M. K.
Usability testing a malware-resistant input
mechanism. In Proceedings of the 18th Annual
Network & Distributed System Security Symposium
(NDSS11) (Feb. 2011).
[18] Microsoft Corporation. What is user account
control? http://windows.microsoft.com/en-US/windows-vista/
What-is-User-Account-Control.
[19] Nodder, C. Users and trust: A microsoft case study.
In Security and Usability: Designing Secure Systems
That People Can Use, L. F. Cranor and S. L.
Garﬁnkel, Eds., ﬁrst ed., Theory in practice. O’Reilly
Media, Inc., Sebastopol, CA, USA, 2005, ch. 29,
pp. 589–606.
[20] Parno, B., Kuo, C., and Perrig, A. Phoolproof
phishing prevention. In Proceedings of the Financial
Cryptography and Data Security 10th International
Conference (2006), FC’06.
[21] Rajab, M. A., Ballard, L., Mavrommatis, P.,
Provos, N., and Zhao, X. The nocebo* eﬀect on the
web: An analysis of fake anti-virus distribution. In
Proceedings of the 3rd USENIX Conference on
Large-Scale Exploits and Emergent Threats: Botnets,
Spyware, Worms, and More (Berkeley, CA, USA,
2010), LEET’10, USENIX Association, pp. 3–3.
[22] Ross, B., Jackson, C., Miyake, N., Boneh, D.,
and Mitchell, J. C. Stronger password
authentication using browser extensions. In
Proceedings of the Proceedings of the 14th Usenix
Security Symposium (Aug. 2005).
[23] Schechter, S. E., Dhamija, R., Ozment, A., and
Fischer, I. The emperor’s new security indicators. In
Proceedings of the 2007 IEEE Symposium on Security
and Privacy (Washington, DC, USA, 2007), IEEE
Computer Society, pp. 51–65.
[24] ”Security-on-a-Stick” to protect consumers and banks
from the most sophisticated hacker attacks, October
2008. http://www.zurich.ibm.com/news/08/ztic.html.
[25] Shapiro, J. S., Vanderburgh, J., Northup, E.,
and Chizmadia, D. Design of the EROS trusted
window system. In Proceedings of the 13th Conference
on USENIX Security Symposium (Berkeley, CA, USA,
2004), SSYM’04, USENIX Association, pp. 12–12.
[26] Stone-Gross, B., Abman, R., Kemmerer, R. A.,
Kruegel, C., Steigerwald, D. G., and Vigna, G.
The underground economy of fake antivirus software.
In Workshop on Economics of Information Security
(WEIS) (June 2011).
[27] Symantec Corporation. Symantec report on rogue
security software, Oct. 2009.
[28] Tygar, J. D., and Whitten, A. WWW electronic
commerce and Java trojan horses. In Proceedings of
the Second USENIX Workshop on Electronic
Commerce (Berkeley, CA, USA, 1996), vol. 2,
USENIX Association, pp. 15–15.
[29] Ye, E., Yuan, Y., and Smith, S. Web spooﬁng
revisited: SSL and beyond. Tech. Rep. TR2002-417,
Dartmouth College, 2002.
[30] Ye, Z. E., Smith, S., and Anthony, D. Trusted
paths for browsers. In Proceedings of the 11th
USENIX Security Symposium (2002), pp. 263–279.
[31] Yee, K.-P. User interaction design for secure systems.
In Proceedings of the 4th International Conference on
Information and Communications Security (London,
UK, 2002), ICICS ’02, Springer-Verlag, pp. 278–290.
376APPENDIX
A. PARTICIPANT SOLICITATION
Researchers at Carnegie Mellon University are conducting
a set of brief surveys about online games. You will have
to play three online games, and then answer a short survey
giving us your opinion about each game. The whole survey
should take you about 20 minutes. We will pay you $1.00
for your participation.
Requisites to participate:
1. You must be 18 years old or older.
2. You must be in the United States while you take the
survey.
3.w [shown only to users Windows clients]
You must use Microsoft Windows Vista or Windows
7. We will not pay you if you use another operating
system, or an older version of Microsoft Windows (like
Windows XP). You don’t have to use MS Internet Ex-
plorer, but if you do you must use Internet Explorer 8
or higher.
3.m [shown only to users of MacOS clients]
You must use Apple MacOS to participate. We will not
pay you if you use another operating system.
3. You cannot take this survey twice. Please click here to
check if you have taken this survey before.
To be paid, follow these steps:
B. EXAMPLE GAME EVALUATION FORM
Instructions to evaluate the game:
1. While pressing CTRL/Command on your keyboard click
on the link below to open the game in a new tab of your
browser.
2. Click on the button ”Click to play online” on the left of
your screen. Wait for the game to load.
3. When the game has loaded completely, play the game
”Mars Buggy Online” for about 2 to 3 minutes.
4. Return to this survey to answer the questions below.
Assigned game N: Mars Buggy Online
http://www.gametop.com/online-free-games/mars-
buggy-online/
(Press CTRL/Command while clicking this link)
Attention: The website whose URL appears above
is external to this study. Our researchers do not
control its content.
If you are not able to download or install the game above,
please check the box below and then click ’Next’ on the
bottom of the page. You will be assigned a new game to
evaluate.
(cid:3) I was not able to download or install the game, please
assign me another game to evaluate.
Please tell us brieﬂy why you were not able to play the game:
(required open text)
1. Go to: http://saucers.cups.cs.cmu.edu/yacot/mnt/wtk/survey.
php?i=workerID
Please enter here a one-sentence description of the game you
played (between 10 and 50 words): (optional open text)
2. After completing the survey you will receive a conﬁrma-
tion code in the last page. Enter the code in the box
below and we will approve your payment. Please do
not enter the code more than once. If you are not sure
about having entered the code correctly, please send
us a message and we will solve the problem as soon as
possible.
Please answer the following questions about the game you
played:
Have you ever played this game before?
(cid:13) Yes(cid:13) No
Do you think this game is appropriate for children between
4 and 8 years old?
(cid:13) Yes(cid:13) No
Do you think this game is appropriate for pre-teenagers be-
tween 9 and 12 years old?
(cid:13) Yes(cid:13) No
Do you think this game is appropriate for teenagers between
13 and 17 years old?
(cid:13) Yes(cid:13) No
Do you think this game is fun?
(cid:13) Yes(cid:13) No
377