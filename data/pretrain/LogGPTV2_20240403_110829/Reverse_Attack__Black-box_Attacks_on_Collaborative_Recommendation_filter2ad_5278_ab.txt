i =1 ci
(a)
(b)
Figure 3: (a) Euclidean distance and Cosine similarity. (b) An
illustration of the surrogate model. Red, green, and yellow
triangles denote the target item, the recommended ones, and
other items, respectively. Gray arrows denote the gradient
direction. The numbers denote the recommendation rank.
(A)
u
(A)
u
, r
(k)
u
(1)
u , r
(1)
u1 , r
(1)
u1 , I
(K)
1
(1)
u1 , r
(1)
u ),(I
(1)
u1 , I
(K)
1
, K), . . . , (I
)}, where I
(1)
u1 , r
(A)
u1 , I
item, but depending on users’ historical behaviors, e.g., rating or
viewing on a group of items. In this approach, an attacker can cre-
ate a set of user accounts on social media websites and randomly
perform some operations. The social media gives the top recom-
mendations to each user, which will be collected and stored in the
form of a list. Here, each operated item can be considered as the
target item. In particular, the fake users rate or view A items in
the websites, with the fake ratings from a fake user u denoted as
(2)
(2)
u ), . . . ,(I
Ri(u) = {(I
is the
u , r
(k)
k-th item rated by u and r
is the corresponding rating. The rec-
u
ommendation area for Type-II layout is similar to that for Type-I
layout. We record all the recommended K items with their ranking
(1)
(2)
numbers, denoted as Ci(1) = {(I
1 , 2),
1 , 1),(I
(A)
. . . ,(I
, K)}. Such a procedure
u1 , r
repeatedly executes to create a set of user accounts for collecting a
sufficient amount of sampling data. For Z fake users, the sampled
data are denoted as Ci = {Ci(1), Ci(2), . . . , Ci(Z)}.
We explore popular websites across E-commerce, social net-
works, Entertainment, Tourism, and Review categories, that an
attacker can explore the two methods for sampling data, summa-
rized in Table 9 of Appendix A.1. It exhibits that an attacker could
use at least one method to collect data from these popular websites.
4.2 Generating Surrogate Model
We next construct a surrogate model to learn recommendation
patterns from the sampling data for producing item proximities.
Several challenges exist in designing such a surrogate model. First,
the model ought to thoroughly learn the item proximities by lever-
aging either ranking or rating information. But, how to design the
model for effectively capturing such item proximity remains chal-
lenging. Second, due to the limit of an attacker’s available resources
(1)
u1 , I
Key itemRecommendation areaItem 1Item 2RankingItem K…12KRating item 1Rating item 2…Rating item RRecommendation areaItem 1Item 2Item K…Ranking12KIaIbIcIdIeEd(Ia,Ib)Ed(Ia,Ic)Ed(Ia,Id)Ed(Ia,Ie)Sim(Ia,Ic)Sim(Ia,Ib). . .. . .12K122KkSession 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea54and the intent to avoid triggering websites’ detection mechanisms,
the sample data cannot be collected in any arbitrarily large size.
Hence, the constrained sample data size further raises the challenge
for developing a surrogate model to learn item proximities. Third,
the surrogate model is desired as simple as possible while realizing
items’ potential relationships without the knowledge of recom-
mender algorithm. How to simplify the surrogate model design
while still achieving our attack purpose remains open.
Notably, the design of surrogate model aims to learn the item
proximities under a small subset of the data. For example, when a
recommender system recommends new products based on histor-
ical user operations, a surrogate model is expected to effectively
learn the relationships from those recommended products. Poison-
ing the proximities of items therein may migrate to distort the
proximities over an entire dataset. Naturally, training a surrogate
model can be considered as a metric learning problem [18].
Euclidean distance metric is used to gauge the distance between
two items. For items Ia and Ib, as shown in Figure 3(a), the cor-
responding vectors are denoted by vvva and vvvb. The Euclidean dis-
tance Ed(Ia, Ib) between Ia and Ib is calculated as Ed(Ia, Ib) =
∥vvva −vvvb∥ =
i =1(vvva(i) − vvvb(i))2, where d is the vector size. For
example, if item Ib is closer to item Ia than item Ic, the Euclidean
distance Ed(Ia, Ib) is smaller than the distance Ed(Ia, Ic). Then, a
recommender system using the nearest neighborhood strategy (like
YouTube [16]) would have a higher probability to recommend video
Ib than video Ic, if a user is watching video Ia. As such, items with
closer proximities have smaller Euclidean distances. Thus, we can
minimize the Euclidean distance among similar items to derive
item distributional representation. Similar to [38], the Euclidean
distance metric aims to minimize its metric loss:
(cid:113)d
[m + Ed(Ii , Ij)2 − Ed(Ii , Ik)2]+,
(1)
Ld = 

(Ii,Ij)∈C
(Ii,Ik)(cid:60)C
where C is either the sampling dataset Cw or Ci, Ii is the key item,
Ij is any recommended item, and Ik is any item not recommended.
[x]+ = max(x, 0) is hinge loss, and m is the safety margin size. By
minimizing Ld, we can capture the distance features among items.
Cosine similarity metric is also widely applied in collaborative
filtering. Considering two items Ia and Ib with their vectors be-
ing vvva and vvvb, the cosine similarity measures the cosine of the
angle between the two item vectors, calculated by: Sim(Ia, Ib) =
vvva · vvvb/(∥vvva∥ × ∥vvvb∥), as shown in Figure 3(a). If users often pur-
chase items Ia and Ib together, the distributional expression of the
two items, say vvva and vvvb, would have closer vector angle, with
Sim(Ia, Ib) ≈ 1. If a user bought item Ia, he/she would receive item
Ib as a recommendation. Thus, a similar method to [65] is proposed
to minimize the Cosine similarity metric loss:
(2)
(Ii,Ij)∈C
(Ii,Ik)(cid:60)C
(−loдσ(Sim(Ii , Ij) − Sim(Ii , Ik))),
where σ denotes the sigmoid function σ(x) = 1/(1 + e−x).
4.2.1 Our Construction. We aim to design a uniform surrogate
model, applicable for effectively learning item proximities from all
categories of CF recommender systems. However, neither Euclidean
distance nor Cosine similarity metric loss can fully leverage affluent
information (e.g., rankings and ratings) present in the sampling data
Lc = 

(Cw or Ci). As such, we take advantage of both metric losses and
include necessary information for use in constructing the surrogate
model. We define six rules in training the surrogate model:
R1. For each key item Ikey, the recommended item Ipos is closer
to Ikey, than any other item Ineд not in the recommended area, i.e.,
Ed(Ikey , Ipos)  Sim(Ikey , Ineд).
R2. For each key item Ikey, the recommended item Ihrk with higher
ranking is closer to Ikey, than any lower-ranked item Ilrk , i.e.,
Ed(Ikey , Ihrk)  Sim(Ikey , Ilf q).
R4. For a recommended item Ir ec , the higher-rated item Ihr t is closer
to Ir ec than any other item Ineд not in the recommended area, i.e.,
Sim(Ihr t , Ir ec) > Sim(Ineд, Ir ec).
R5. For a recommended item Ir ec , the lower-rated item Ilr t is farther
to Ir ec than any other item Ineд not in the recommended area, i.e.,
Sim(Ilr t , Ir ec)  0,
|M| is the total number of unique items in the collected dataset,
and kIi,Ij is the rank of item Ij to item Ii based on the targeted rec-
ommender system and collected in the sampling dataset Cw or Ci.
Notably, the use of ARW in Eqn. (5) can achieve the surrogate model
rules R2 and R3. Since both Type-I and Type-II layout cases are
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea55taken into accounts in Eqn. (3), the rating information is considered
in Eqn. (4), and the ranking information is included in Eqn. (5), our
design naturally meets rule R6. Figure 3(b) illustrates the relative
locations of items of different rankings from our surrogate model.
In the training phase, the negative items Ik in item-pairs (Ii , Ik) (cid:60)
C are randomly sampled from the entire item space. The number of
sampled negative items is set to 4 for each key item. The training
process terminates after the item distributional expressions become
stable. The trained model will represent our constructed surrogate
model, which can estimate item proximities in a way similar to the
recommender system, enabling us to develop an attack strategy on
this model and then apply it directly to the original recommender
systems to achieve a similar goal by poisoning the item proximities.
4.2.2 Relationship between Our Surrogate Model and the
Original Recommender System. We further explore the relation-
ships between our surrogate model and the original recommender
system. A recommender system explores the user-item relation-
ship from the historical user-item interaction dataset. Each item
is encoded into a dense vector called the item embedding in most
recommender systems. Usually, item embedding does not hold a
specific meaning but captures the relationship to other items. The
main difference between recommender algorithms and learning
metrics lies in that the former focuses on recommendation accuracy
while the latter aims to capture item proximities.
To test the capability of the surrogate model in capturing such
relationships, we trained five recommender systems on ml-1m [60]
dataset, including item-based CF (IBCF [54]), matrix factorization-
based CF (MF [45], CML [38], and BPR [65]), and graph-based CF
(GCF [13]). Next, we use our constructed surrogate model (with
learning metric Ls) to learn item relationships from the data col-
lected from each of the recommender system. For comparison, we
also take into account another two learning metrics Ld and Lc,
corresponding to Eqns. (1) and (2), respectively. The Pearson corre-
lation values between the item-item similarities from recommender
systems and item-item similarities learned by the surrogate model
under three metrics are listed in Table 1.
From Table 1, we can observe Pearson correlation values of items
similarity between our surrogate model (with Ls) and all five exam-
ined recommender system are always more than 0.5. As evidenced
in [69], these values (greater than 0.5) can clearly claim that the two
systems are highly correlated. In contrast, for the surrogate model
with Ld and Lc, their correlations to five recommender systems
are much lower, with only one or two correlation values can reach
to 0.5. For example, the surrogate models with Ld metric and with
Lc metric mostly correlates to CML and BPR, respectively, both
having the correlation values of more than 0.5. The reason is that
CML encodes item into Euclidean space while BPR uses cosine sim-
ilarity to represent item relationships. But corresponding to other
recommender systems, their values are much inferior, as low as 0.19
and 0.20, respectively. These results demonstrate the effectiveness
of our constructed surrogate model with Ls in terms of learning
the item proximities.
5 CRAFTING ATTACKING STRATEGY
This section presents both availability attack and target attack on
our surrogate model, with the resulting attack strategies directly
Table 1: Pearson correlation values
Ld
0.41
0.32
0.51
0.19
0.44
Type-I
Lc
0.46
0.38
0.25
0.55
0.46
Ls
0.56
0.48
0.65
0.56
0.57
Type-II
Lc
0.48
0.35
0.36
0.57
0.42
Ls
0.57
0.50
0.68
0.61
0.62
Ld
0.45
0.27
0.53
0.20
0.51
IBCF [54]
MF[45]
CML[38]
BPR[65]
GCF[13]
(a)
(b)
i , . . . , I K
i } and ˜Yi = {˜I1
Figure 4: (a) Attacking item proximities by altering the item
distributional representations. (b) Sampling items with first-
order relationship or second-order relationship.
applicable to original recommender system for similar attack goals.
An attacker aims to maximize the profit, leading to (1) the minimum
recommendation accuracy for availability attack or (2) maximally
promoting target items to the normal users for target attack.
5.1 Attack Objective Functions
Availability attack objective function. Given that the goal of
availability attack is to demote the original recommendations, our
design should be able to measure the discrepancy of recommended
results before and after the attack. The profit of an attacker depends
on the degree of distortion on recommendations. Instead of directly
attacking the original recommender system, we perform our attack
on the surrogate model to find the attack strategy that can be
for later use. We define Yi = {I1
i },
i , . . . , ˜I K
respectively, as the K most similar items to a targeted item Ii before
and after the attack, respectively, on the surrogate model. I k
i and
˜I k
i represent the k-th similar item for the item Ii before and after
the attack, respectively. The metric of accuracy, i.e., S(Y, ˜Y), is
introduced to measure the discrepancy before and after the attack.
Notably, we enable the surrogate model to estimate the K most
similar items to an item, so that it is then sufficient to consider only
the top-K recommendations.
Denote Sim(Ii , Ij) and Sim∆(Ii , Ij) as the cosine similarity be-
tween the items Ii and Ij from the surrogate model before and after
the attack, respectively. If the cosine similarity Sim∆(Ii , Ij) between
Ii and any item Ij (Ij is not in the Ii’s original most K similar items)
is larger than Sim∆(Ii , I k
i ) between Ii and its k-th (k ≤ K) similar
i , i.e., Sim∆(Ii , I k
i ) − Sim∆(Ii , Ij) < 0, we say this attack is
item I k
successful. To poison the item space, we define S(Y, ˜Y) as:
i ) − Sim∆(Ii , Ij))) ,
S(Y, ˜Y) =
where σ(·) is the sigmoid function and ∆i, j,ik is a constant which de-
i ) −
notes similarity difference before the attack: ∆i, j,ik = Sim(Ii , I k
σ(∆i, j,ik(Sim∆(Ii , I k
|M|
|M|
K
i =1
j=1
k =1
IiI1iI2iI3iIj˜I2i˜I1i˜I3i˜IjBefore attackAfter attack Ij I2i I1i I3iI1I2I3I4I6I7I8I90.50.10.10.10.60.10.10.11st order relationship 2nd order relationship I50.1Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea56Sim(Ii , Ij). By minimizing S(Y, ˜Y), we can minimize the recom-
mendation accuracy comparing to that before the attack. We can
consider that minimizing S(Y, ˜Y) is equivalent to deriving new
item distributional representations in the surrogate model item
space. Assuming the original item distributional representation set
is WWW , and the poisoned item distributional representation set is ˜WWW ,
we have ˜vvvi = vvvi + ∆vvvi ,vvvi ∈ WWW , ˜vvvi ∈ ˜WWW , as shown in Figure 4(a).
Since we do not aim to alter too many original item distributional
representations during the attack, as otherwise it may require to
inject too many fake operations, we add ∥ ˜WWW −WWW ∥2 as a constrained
term. We can adopt the Lagrange multiplier method [66] to formu-
late our attack as follows:
OPT-A: min
˜WWW
S(Y, ˜Y) + κ∥ ˜WWW −WWW ∥2 ,
(7)
t , I2
where κ is the penalty coefficient, setting to 0.01 in our experiments.
Target attack objective function. Denote T = {I1
t }
t , . . . , I K
as the K target items that an attacker wishes to promote. We de-
fine a metric successful score, expressed as HT(·), to measure the
attacker’s profit on the degree of success in promoting target items.