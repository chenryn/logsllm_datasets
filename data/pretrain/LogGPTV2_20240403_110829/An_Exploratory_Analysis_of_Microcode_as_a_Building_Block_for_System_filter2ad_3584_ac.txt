microcode is the decoding of instructions. By intercepting this step
during the execution of x86 code, it is possible to apply fine-grained
control over the behavior of instructions, programs, and the system
as a whole. From a security perspective, additional functionality
can be added to existing instructions, special handling for corner
cases can be inserted, and security checks can be included.
Besides changing and extending the instruction decoding, it is
also possible to influence other aspects of the CPUâ€™s operation. For
example, the exception handling mechanism is implemented with
the help of microcode. Before an exception reaches the kernel-level
x86 code, microcode can change the metadata passed to the kernel or
handle the exception without involving the kernel at all. By directly
modifying the exception handling in microcode, expensive context
switches can be avoided. This allows, for example, special handling
of page faults to implement page-based memory separation in a
way that is completely transparent to the kernel.
Isolated execution environment The microcode engine pro-
vides a fully-featured execution environment that cannot be inter-
cepted by the running kernel in any way. Any exception delivered
while microcode is running will be stalled until the current decod-
ing is complete. Moreover, any state that is not explicitly written
out will be contained in the microcode engine and cannot be ac-
cessed. More specifically, both the running kernel and hypervisors
are unable to inspect the execution state of the microcode engine.
This provides an enclave-like environment in which computations
on sensitive data can be performed in an opaque way. Only the
results will be passed to the operating system, protecting secret
keys or other data inside the microcode.
Extending and modifying the x86 instruction set By either
reusing no longer used x86 instructions or adding entirely new
instructions to the decoding process, microcode can enable func-
tionality not found in the standard x86 instruction set architecture.
These instructions can for example implement more complex se-
mantics that are tailored to a specific use case. By condensing
calculations into fewer instructions, caches are utilized more effec-
tively, increasing performance. Besides performance improvements,
new primitives can be added with new instructions. As microcode
can change the access level between operations, it is able read and
write kernel-only data structures. Combining this with fine-grained
checks enables fast access to otherwise privileged functions, with-
out support of the running kernel.
5 CASE STUDIES OF MICROCODE DEFENSES
Based on the security primitives discussed above, we now present
designs and proof-of-concept implementations of our microcode-
assisted systems defenses and constructive microcode applications.
For each case study, we first briefly motivate the primitive, present
the design and implementation, and conclude with an evaluation
and discussion of advantages and drawbacks of our approach. Based
on these case studies, we demonstrate that microcode indeed im-
proves properties of those applications with regards to performance,
security, and complexity. The microcode programs and supporting
infrastructure are publicly available [57].
The current state of the programs does not feature a mechanism
for runtime configuration, however this is can be achieved in dif-
ferent ways. As it is possible to load microcode updates during
runtime, the operating system can apply an update to enable or
disable certain features. It is also possible to add dedicated flags in
the thread or process control structures created by the operating
system to signal which features should be enabled for a certain
thread. However, both approaches require support from the OS to
either synchronize the microcode update procedure across all CPU
xor eax , eax
xor edi , edi
cpuid
rdtsc
xchg edi , eax
; benchmarked instruction
shrd ebp , ecx , 4
cpuid
rdtsc
sub eax , edi
Figure 4: Microbenchmark setup to determine the execution
time in cycles of shrd (double precision right shift). The
modern rdtscp instruction variant is not available on the
tested K8 CPU, thus the cpuid instruction is used to serial-
ize the instruction execution.
cores or allocate and initialize the configuration fields for every
new thread. Another option is to use processor-internal storage to
store configuration variables. Tests showed that a writable region
of memory exists that can be used to store these variables. Unfortu-
nately, further experiments are needed to ascertain the nature of
this memory region and the side effects of changing it at runtime.
We evaluate the performance of our case studies with microbench-
marks of the affected instructions. To this end, we determine the
execution time in cycles as measured via the rdtsc instruction. It
provides the value of the Time Stamp Counter (TSC), a counter
which is incremented each clock cycle. The used code snippet for
performance benchmarks is illustrated in Figure 4. All tests were
performed on an AMD Sempron 3100+ running the minimal op-
erating system developed by Koppe et al. [49]. In the following,
the cycle counts are given without the overhead of the measure-
ment setup itself, which adds 65 cycles to every execution. Further
improvements to the performance properties of the defenses are
possible with a greater understanding of the underlying hardware.
This requires either more work on reverse engineering more details,
especially in regards to scheduling, or, to fully utilize the existing
hardware, assistance of the CPU vendors.
5.1 Customizable RDTSC Precision
Motivation. Previous works demonstrated the possibility to recon-
struct the memory layout [35, 39, 61] using timing side channels.
More recently the Spectre and Meltdown attacks have shown
in a spectacular way [37, 45, 53] that it is possible to break the
fundamental guarantees of memory isolation on modern systems.
A common aspect of these attacks is the usage of high-resolution
timers to observe the timing side channels. Due to these dangers,
modern browsers limit the accuracy of high-resolution timers to a
recommended value [36]. While this does not eliminate all timing
sources [47, 69], it raises implementation complexity of attacks and
provides a mitigation against common exploits.
On the native level the timing information is commonly queried
using the rdtsc instruction. The x86 architecture allows limiting
rdtsc to kernel space only. Any attempt of executing this instruc-
tion from user space will lead to a fault. Building upon this fact,
the operating system can limit the resolution of the timer avail-
able to user programs. Upon receiving the corresponding fault, the
operating system queries the TSC itself, reduces the resolution ac-
cordingly, and passes the timestamp onto the program. Note that
this incurs a significant performance overhead due to the necessary
context switches.
Design and Implementation. Since we are able to change x86
microcode behavior, our goal is to implement a functionality simi-
lar to the browser mitigation for the native rdtsc instruction. In
addition, our solution should be able to reduce the accuracy to
a pre-defined value without incurring unnecessary overhead in
form of context switches. To this end, we intercept the execution of
rdtsc and before the TSC value is made available to the application,
we set a pre-defined number of lower bits to zero. Note that the
amount of zeroed bits is configurable (in the microcode update) to
provide a trade-off between accuracy and security.
Evaluation and Discussion. While the default implementation
of rdtsc takes 7 cycles to execute, our custom implementation
takes a total of 15 cycles to complete. This overhead is due to the
switch to microcode RAM and the additional logical AND operation
to clear the lower bits of the TSC value. The Register Transfer
Language (RTL) representation of our rdtsc implementation is
shown in the appendix in Listing 1.
Even though our solution doubles the execution time, it is far
faster than the approach where the kernel needs to trap the raised
interrupt. At the same time, our security guarantees are compa-
rable to the discussed browser mitigations. While raising the bar,
timing attacks are still possible by using methods described by
Schwarz et al. [69] and Kohlbrenner et al. [47].
5.2 Microcode-Assisted Address Sanitizer
Motivation. Address Sanitizer (ASAN) [70] is a compile-time in-
strumentation framework that introduces checks for every mem-
ory access in order to uncover both spatial and temporal software
vulnerabilities. In particular, temporal faults such as use-after-free
bugs present an important class of memory corruption vulnerabil-
ities that have been used to exploit browsers and other software
systems [78]. ASAN tracks program memory state in a so-called
shadow map that indicates whether or not a memory address is
valid. Therefore, ASAN inserts new instructions during compilation
to perform the checks as well as an instrumentation of allocators
and deallocators. In addition, ASAN enforces a quarantine period
for memory regions and thus prevents them from being re-used
directly. However, this instrumentation incurs a performance over-
head of roughly 100%.
To overcome the performance penalty and reduce the code size,
the authors of ASAN also discussed how a hardware-assisted ver-
sion, dubbed Address Sanitizer in Hardware (HWASAN), could
theoretically be implemented [71]. The basic idea is to introduce a
new processor instruction that performs access checks. The general
principle of the new instruction is illustrated in Figure 5. It receives
two parameters: the pointer to be accessed and the memory access
size. The instruction then validates the memory access and its size
with the help of the shadow map.
Design and Implementation. Instead of requiring a hardware
change to add the new HWASAN instruction, we design a scheme
CheckAddressAndCrashIfBad ( Addr , kSize ) {
ShadowAddr = ( Addr >> 3) + kOffset ;
if ( kSize < 8) {
Shadow = LoadByte ( ShadowAddr );
if ( Shadow && Shadow <= ( Addr & 7) + kSize - 1)
ReportBug ( Addr );
} else {
Shadow = LoadNBytes ( ShadowAddr , kSize / 8) ;
if ( Shadow )
ReportBug ( Addr );
}
}
Figure 5: Pseudocode of the HWASAN instruction [71];
kSize is the size of the memory access and kOffset is a com-
pile time constant that specifies the location of the shadow
map.
to implement HWASAN in microcode. Similarly to Figure 5, we
perform the checks accordingly and raise a fault in case an invalid
memory access is detected. To provide a clear separation between
application code and instrumentation, we implemented the check-
ing in a single instruction. For practical reasons, the interface should
be easy to add to existing toolchains.
In our implementation, we chose to reuse an existing but unused
x86 instruction, in this case the instruction bound. Since the check
requires address and size of the memory access, we changed the
interface of this instruction in the following way: the first operand
indicates the address to be accessed, while the second operand indi-
cates the access size. We want to emphasize that that our microcode
instrumentation can be emitted without changes to an existing x86
assembler using the following syntax:
bound reg , [ size ]
Similarly to ASAN, our instruction is inserted in front of every
memory access during compilation. We also use the same shadow
map mechanism and base address, hence the instrumentation re-
quires no additional changes. However, the key difference is the
compactness and that no externally visible state is changed. In case
the memory access is valid, the instruction behaves as a nop, but if
an invalid access is passed, a defined action is taken. To this end,
our prototype implementation currently support three methods of
error reporting:
(1) raising a standard access violation,
(2) raising the bound interrupt, and
(3) calling a predetermined x86 routine.
Note that the first two options rely on the availability of an excep-
tion handling mechanism, while the latter option is self-contained
and works even without kernel support.
Evaluation and Discussion. While the checking algorithm is
semantically the same, we observed a performance advantage of
our solution. The default ASAN implementation for a (valid) 4 byte
load requires 129 cycles to complete, our version requires only 106
cycles. Another advantage of our implementation is that no x86
register is changed during its execution: instead of using x86 gen-
eral purpose registers, our implementation stores temporary values
in ephemeral microcode-internal registers. This means the inser-
tion of the instrumentation does not increase the register pressure
and does not cause additional register spills to the stack. This is in
comparison to the original ASAN implementation which uses two
additional x86 registers to hold temporary values. The overhead of
additional register spills is not included in our benchmark as it is
highly dependent on the surrounding code. The RTL representa-
tion of our HWASAN implementation can be found in our Github
repository [57].
5.3 Microcoded Instruction Set Randomization
Motivation. In order to counter so-called code-injection attacks, a
series of works investigated Instruction Set Randomization (ISR)
schemes [10, 38, 44, 63, 66, 73] with the goal of preventing the
correct execution of maliciously injected code. To this end, the
instruction encoding is randomized (e.g., using an XOR with a pre-
defined key) for all or a subset of instructions, so that the adversary
does not know the semantics of a randomized instruction. Note that
recently published advanced schemes also aim to mitigate code-
reuse attacks using strong cryptographic encryption algorithms [72].
However, most schemes require hardware support, which prevents
their deployment to COTS CPUs.
Design and Implementation. Our ISR scheme removes the
link between the actual x86 operation and its semantics, and thus
an adversary is unable to infer the meaning of an instruction stream
even if disassembled during a Just-in-Time (JIT)-Return-oriented
Programming (ROP) attack. In order to be robust even when fac-
ing code-reuse or JIT-ROP attacks, we assume fine-grained code
randomization or software diversification.
Our proof-of-concept implementation supports six different oper-
ations: memory load, register move, add, left and right shift, and ex-
clusive or. Each operation can be freely assigned to any microcoded
x86 instruction that allows for one register operand and one mem-
ory operand. This assignment effectively binds the executed x86
code to a specific instance of the ISR. Execution is only possible
if the semantics implemented in microcode for each instruction
match the one used when generating the x86 code. Note that due
to this varying assignment and the variable instruction length of
the affected opcodes, it is not possible to assemble a ROP chain
or shellcode matching all possibilities. Additionally, we support
masking of input and output values before they are written to or
read from potentially attacker-accessible storage, including system
memory and registers.
To facilitate the translation of existing x86 code to opcodes us-
ing the newly introduced semantics of the ISR, we implemented a
transpiler. This transpiler processes a stream of disassembled x86
instructions and replaces all occurrences of supported opcodes with
the appropriate opcodes with changed semantics. The selection of
the replacement opcode is performed based on the assignment in
the corresponding microcode update. The input to the transpiler
is thus the source instruction stream and the mapping of x86 in-
structions to semantics as implemented by the ISR, the output is
a modified instruction stream. This output stream can them be
assembled by a standard x86 assembler, as no new instructions are
introduced.
Evaluation and Discussion. We evaluate the performance of
our implementation by comparing the runtime (measured in cycles
according to the test setup described previously) of a toy example
Figure 6: Control flow of an instrumentation.
consisting only out of supported opcodes with the corresponding
transpiled version. Our measurements indicate that our microcoded
ISR scheme introduces an overhead of 2.5 times on average over
a set of 5 different examples, compared to the same code running
natively. This overhead is mainly due to replacing non-microcoded
instructions (that normally take 1-3 cycles) with microcoded in-
structions that require at least 7 cycles, including the additional
overhead of switching to microcode RAM execution. We provide
one of the test cases in Listing 2 in the appendix. Note that the
cumulative performance of instruction streams may vary due to
pipelining and parallel execution. This is especially visible if instruc-
tions covered by the ISR are mixed with standard x86 instructions.
As our toy examples exclusively use transpiled instructions, we
arrive at the worst case overhead. Since the ISR can implement
more complex semantics such as a multiply-accumulate, the cy-
cle overhead can be reduced with a more advanced transpiler. We
want to emphasize that our ISR does not require hardware changes
compared to previous schemes and thus can be deployed on COTS