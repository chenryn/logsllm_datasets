### Malware Pseudo-Code Example

```c
// Infect user32.dll
RegSetKeyValue(r, valuename, REG_SZ, filename, ...);
...
infect_user32.dll
...

// Hijack HTTP connections
h = CreateFile("c:\\windows\\system32\\drivers\\etc\\hosts", FILE_APPEND_DATA, ...);
WriteFile(h, "67.42.10.3 www.google.com\n67.42.10.3 www.citibank.com", ...);

// Delete main executable
DeleteFile("c:\\malware.exe");
```

**Figure 1: Pseudo-code of a sample malicious program.**

### Observations and Challenges

It is often challenging to observe the malware long enough to see all possible variants of the payload file name. This makes it difficult to create comprehensive remediation procedures.

### 3.2 Architecture Overview

The architecture we have developed for generating remediation procedures from malware binaries is shown in Figure 2. It consists of three primary components:

1. **Execution Monitor**: Infers the malware’s high-level behaviors from a low-level trace.
2. **Behavior Generalization**: Generalizes the high-level behaviors from multiple executions of the malware.
3. **Remediation Procedure Generation**: Produces executable remediation procedures from generalized behaviors.

The entire system operates sequentially, with each component using the information produced by the preceding one.

#### High-Level Behavior Extraction

The high-level behavior extraction component (numbered 1 in Figure 2) analyzes the semantics of a program to produce a sequence of meaningful behaviors relevant to remediation. Since malware authors often obfuscate their binaries, we rely on dynamic information to infer these behaviors. We execute binaries in a special environment (an emulator) to extract a low-level execution trace, perform analysis using manually constructed rules, and arrive at a high-level trace [11].

Table 1 lists the high-level behaviors we consider. Each behavior modifies the state of the system in some way and is parameterized by a set of arguments that determine which aspects of the system state are affected. The behaviors currently listed correspond to those that commonly occur in malware, are mandatory to infect a system, and were constructed manually to reflect the salient behavioral features of most malware. Our technique can be extended to operate over a wider set of high-level behaviors.

The environment in which a program runs typically affects its behavior, and malware often exhibits a certain degree of nondeterminism. To account for these factors, we collect several high-level behavior traces for each sample by varying the environment, such as locale and service pack level. Although not supported by our current implementation, path exploration techniques [12] can be applied to account for a more complete subset of the malware’s behavior, as in Bouncer [5]. The lack of path exploration techniques is not a fundamental limitation and can be easily integrated into our system.

For the sample malware in Figure 1, our high-level behavior extractor would infer the following behaviors: `FileCreation`, `RegistryCreation`, `DropAndAutostart`, and `FileInfection`, with different arguments for each execution.

#### Behavior Generalization

After producing a set of high-level behavior traces for a malware sample, we attempt to account for nondeterminism by creating a general, abstract model of behavior that accounts for all observed concrete traces (numbered 2 in Figure 2). Generalization overapproximates existing paths, thus encompassing future paths, rather than exploring as many new paths as possible. This patches some of the incompleteness of dynamic analysis by extrapolating observed information to future, unseen executions of the malware.

This is accomplished by recognizing when distinct behaviors from multiple high-level traces, with possibly different arguments, are actually instances of the same malicious activity. We refer to this matching of behaviors as clustering. When a cluster is identified, the arguments of its constituent behaviors are generalized to tolerate any differences that may be present in the actual values. Thus, nondeterminism is accounted for via overapproximation by ensuring that this generalization extends to future, unseen executions.

For the malware in Figure 1, our technique would cluster all instances of the same high-level behavior together. For example, all instances of `DropAndAutostart` would be clustered together, and all instances of `FileInfection` would be clustered together. Because there is likely variation among the arguments of `DropAndAutostart`, we construct a regular expression to tolerate minor differences while ensuring that benign files are not mistakenly identified. The final result for this behavior would be a `DropAndAutoStart` behavior with a generic file argument `c:\\windows\\po[[:alpha:]]{3}.exe` to generalize the random filename at line 2, a generic registry key/value pair `...\CurrentVersion\Run` for the registry touched at line 11, and `(qv|vq)` for the registry value randomly created at line 3.

#### Remediation Procedure Generation

The third component of our architecture (numbered 3 in Figure 2) generates executable remediation procedures from the generalized behaviors produced in the previous step. The resulting procedure examines the state of the system on which it runs in search of symptoms of an infection and removes the symptoms whenever possible.

It attempts to match each resource (file, process, or registry key) on the system against the constraints associated with each generalized high-level behavior. For our running example, each file is matched against the regular expression `c:\\windows\\po[[:alpha:]]{3}.exe` associated with the first argument of the `DropAndAutoStart` behavior, another regular expression associated with the second argument, and a final one describing the content of the file. If such a file is found, then the registry values under the key `...\CurrentVersion\Run` are matched against the regular expression `(qv|vq)`. If such a value is found and its data matches the current filename being considered, then all of the resources (the file and registry key pair) are removed. Currently, we only produce remediation procedures that operate on system files. For technical reasons explained in Section 4, we do not handle user-specific files and resources. While this is a limitation of our current approach, we hope to remove it in future work.

### 4 Generating Remediation Procedures

In this section, we present the details of our system for generating remediation procedures. We begin by formalizing the problem solved by our system and continue component-by-component, describing the algorithms used to solve the problem.

#### 4.1 Problem Description

When malware runs on a system, it may infect the system by changing its persistent state in an undesirable way. For our purposes, the state \( S \) of a system is modeled as an association from resource names \( N \) to data from a domain \( D \). Individual elements of \( S \) are referred to as resources. To simplify notation, we let \( S \) stand for the set of possible system states. Because most malware is written for Windows platforms, our targeted resource namespace consists of Windows filenames, registry key and value names, and process names. The data domain is the set of all finite-length bit strings.

The infection behavior of a malware can be understood as a transition relation between system states. There are three ways in which the malware can modify the state of a system:

1. Resources may be completely removed from the system.
2. New resources may be added to the system.
3. The data corresponding to existing resources may be mutated.

Because the infection behavior of a malware can be succinctly described in terms of these three operations and the resources over which they operate, we represent it using an infection relation \( R \subseteq S \times N \times S \times S \) that encodes this information. Intuitively, the infection relation describes the way in which a particular malware changes the state of a system. Given an element \( (S, N_{rem}, S_{add}, S_{mut}) \in R \), the malware transforms state \( S \) into a new state by removing the resources labeled by \( N_{rem} \), adding the resources in \( S_{add} \), and modifying the resources in \( S_{mut} \). Note that the infection behavior is described as a relation rather than a function mapping. This is because malware may behave nondeterministically when it infects a system—it may infect the same system state in different ways on two distinct executions.

After a given piece of malware has infected a system, the goal of remediation is to undo the effects of the infection, returning the system to a clean state. More precisely, given a malware binary, we seek to construct an infection relation for that malware that describes its behavior. We can then use the information in the infection relation to enact changes on the system that remediate the effects of the malware: restoring any files that were removed (\( N_{rem} \)) or mutated (\( S_{mut} \)), and removing files that were added (\( S_{add} \)). We package this functionality as an executable remediation procedure, as described in Section 3.2. In general, there are a number of approaches that may realize the goal of constructing the infection relation corresponding to a given malware. In this paper, we focus on applying dynamic analysis to the malware sample to extract the information necessary to construct the infection relation.

In practice, it is not usually possible to reconstruct the true infection relation from a malware binary. Rather, we compute a relation that overapproximates the actual behavior for a finite set of execution paths exhibited by the malware. For example, we overapproximate the resource names involved in the `DropAndAutoStart` behavior of Figure 1 by creating a regular expression that matches all of the resource names on the set of execution traces we observed. Furthermore, our approximate infection relations do not contain information regarding the removal or mutation of non-system files, as it is generally not possible to restore this state without additional information not encoded in the malware. Using an approximate infection relation for remediation introduces the possibility of false negatives and false positives. A false negative occurs when the remediation fails to properly reverse the changes left by the malware. Similarly, a false positive occurs when remediation affects resources that were not touched by the malware. Both types of error are possible given the way we construct approximate infection relations.