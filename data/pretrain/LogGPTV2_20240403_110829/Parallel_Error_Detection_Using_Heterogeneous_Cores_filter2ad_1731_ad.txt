### Checkpointing Frequency and Its Impact on System Performance

The checkpointing frequency is influenced by the size of each load-store log segment, the instruction timeout, and the delay properties of the system. Figure 10 illustrates the performance slowdown caused by the checkpointing system, with varying queue sizes and timeout lengths. The default 36KiB log is sufficiently large to limit slowdowns to no more than 2% across all our benchmarks. The benchmark `randacc` is least affected due to its low IPC and infrequent checkpointing. Increasing the log size tenfold, either with a corresponding tenfold increase in the timeout or with an infinite timeout, reduces overheads to negligible levels. Conversely, a tenfold reduction in log size and timeout length results in significantly higher overheads, with slowdowns up to 15%.

Figure 10 also demonstrates that a 36KiB log represents a good balance between silicon area and performance overhead.

### Frequency Impact on Error Detection Delay

The goal of this technique is to scale error checking across multiple cores through parallelization. This inevitably increases the error detection time compared to lockstep schemes, where errors are typically detected within a few cycles [3]. One method to control this delay is by adjusting the frequency of the checker cores, as shown in Figure 11 for default load-store log sizes and timeout lengths. The figure presents the mean and maximum delay between stores committing and being checked at different frequencies of the checker cores.

- **Mean Detection Delay**: The mean detection delay decreases linearly with increasing clock speed. Doubling the clock speed approximately halves the delay. However, at high clock frequencies, the limiting factor becomes the time to fill the load-store queue using the main CPU rather than the checking time.
- **Maximum Detection Delay**: The maximum detection times are less predictable and are often influenced by factors such as a high number of cache misses on the main core, making them less sensitive to changes in the checker core frequency.

### Log Size Impact on Error Detection Delay

Figure 12 shows the mean and maximum detection delays when varying the load-store log size and timeout length at the default checker core frequency. The mean detection times scale linearly with the log size: a tenfold increase in log size and timeout results in a tenfold increase in delay. Maximum detection times follow a similar trend but are more sporadic due to individual instructions dominating the measurements.

- **Smaller Log Sizes and Timeouts**: With smaller log sizes and timeouts, many segments contain only a few memory accesses, and the timeout significantly affects the detection delay.
- **Larger Log Sizes and Timeouts**: For larger queue sizes, enough instructions fit into a single segment, and the log is usually filled before the timeout is reached. An exception occurs with programs featuring large runs of instructions with very few loads and stores, such as `bitcount`. Without a timeout, very large segments of code can cause the maximum detection delay to increase significantly. A 50,000-instruction timeout is sufficient to reduce the maximum delay by 250 times without impacting performance.

### Number of Cores and Performance Scaling

Figure 13 illustrates how performance scales with different numbers of cores dedicated to error checking. We observe that N cores at a frequency of M (in MHz) perform comparably to 2N cores at a frequency of M/2. For example, 6 checker cores at 1GHz perform similarly to 12 cores at 500MHz. This is expected given the identified parallelism in error detection.

In fact, a large number of cores at a low clock frequency outperform fewer cores at higher frequencies. This is because, in the load-store log structure, only n-1 checker cores are in use at any given time, as at least one is always waiting for its segment to be filled unless the main core is stalled. This allows for better utilization of the total compute power when more cores and thus more load-store log segments are available.

### Area Overhead

Publicly available data indicates that the RISC-V Rocket, the closest available core in terms of size to our proposed checker units, occupies 0.14mm² per core on a 40nm process [45]. In comparison, the Cortex A57, at 20nm, occupies 2.05mm² per core [46] excluding shared caches. Twelve E51-sized cores would therefore fit in approximately 0.42mm² combined at the same technology node.

The SRAM added for instruction caches, register checkpoints, load forwarding unit, and the load-store log totals 80KiB, which adds approximately 0.08mm² in area overhead [47]. Combined, this places the error detection hardware at approximately 24% area overhead compared to the original core without shared caches. Including a 1MiB single-ported L2 cache, which is approximately 1mm² [47], the area overhead is approximately 16% of the original core.

This estimate is approximate, as the Rocket has a different ISA from the A57, and the out-of-order core we model is faster than an A57, requiring more checker cores in our experiments (a real implementation would need fewer). Nonetheless, it is clear that the overhead is significantly reduced compared to dual-core lockstep, the current state-of-the-art.