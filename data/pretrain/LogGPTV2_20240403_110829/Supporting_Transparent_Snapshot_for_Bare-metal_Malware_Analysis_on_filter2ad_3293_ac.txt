BoltOS
Guest OS
Snapshot
Memory
.
.
.
Coordinator
R
e
c
o
g
n
i
t
i
o
n
i
F
n
g
e
r
p
r
i
n
t
K
e
y
S
t
o
r
e
BoltOS 
Kernel
M
a
n
a
g
e
m
e
n
t
M
e
m
o
r
y
(a) Overview of the normal-world Android OS and secure-world BoltOS. Shaded com-
ponents are newly added. As shown in the Figure, the entire Android system is unmod-
ified except for a trivial non-suspicious user space app, BoltAgent.
(b) Architecture overview. Shaded memory regions
are secure resources that cannot be accessed by the
normal-world Android System.
Figure 4: System overview
3.2 Overview
Bolt comprises of four main components: BoltAgent, BoltOS,
BoltFTL, and Coordinator (see Figure 3).
First, an in-guest app called BoltAgent runs in the Android
system (Figure 4a). This app is not suspicious in the sense that it does
nothing other than invoking two different requests of commodity
security services that are already implemented in the TEE of the
Android system, such as fingerprint recognition or trusted keyStore.
BoltOS in the secure world receives the requests from BoltAgent
as cues for save/restore operations.
Second, in the secure world, we run BoltOS, a lightweight OS
that is responsible for handling commodity security service requests
and add-on restoration services. In particular, a commodity security
service, such as fingerprint recognition, is bound with the save
service, and another service, such as keyStore, is bound with the
restore service. As shown in Figure 3, when BoltOS receives a re-
quest from BoltAgent, apart from serving the ordinary commodity
request, BoltOS executes the corresponding add-on restoration ser-
vice. A snapshot includes two parts – one for memory and the other
for disk. BoltOS handles memory snapshot directly (Section 3.3),
and forwards the disk snapshot request to the flash firmware, which
we will describe in the next paragraph. We set aside a physical
memory region of equal size with that used in the guest system
(Figure 4b). To take a memory snapshot, BoltOS simply copies
the entire physical memory assigned to the guest to the snapshot
memory. In addition, the processor contexts, including the gen-
eral purposed registers, Current Processor State Register (CPSR), and
Translation Table Base Register (TTBR)3, etc. are saved in BoltOS.
The restoration of physical memory is the reverse operation to
snapshotting.
Third, BoltFTL is a piece of customized flash firmware. It re-
ceives customized SCSI commands [19] from BoltOS to perform
save and restore operations to the flash. Taking advantage of the
out-of-place update feature of flash, it is able to efficiently save
and restore the content of the entire flash without time-consuming
overwriting. Specifically, after receiving a save command, BoltFTL
3The TTBR register is the pointer to the first level page table, similar to CR3 in x86
processors.
triggers an active garbage collection to store the clean-state data
more compactly in flash blocks, and backs up the essential FTL
metadata (e.g., the mapping table, which records the mappings be-
tween LPA and PPA) to a few reserved flash blocks. BoltFTL also
regulates the write operations issued from the upper layer such that
they will not overwrite those flash blocks that store the clean-state
data. Garbage collection in BoltFTL is also revised such that the
flash blocks storing the clean-state data will not be reclaimed. After
having received a restore command, BoltFTL simply restores the
backup metadata. Since the flash blocks storing the clean-state data
are intact, the flash can be directly restored to the clean state. The
details of BoltFTL will be elaborated in Section 3.4.
Finally, a Coordinator (Figure 4b) in a separate PC connects
the guest device through the Android Debug Bridge (ADB) utility.
It downloads the malware to the Android device, and invokes the
BoltAgent to issue a save command to take a system snapshot
after system boot and to issue a restore command whenever an
analysis is completed. Note that these requests are issued from
the normal-world Android system, which is subject to exploit. For
example, the infected Android could issue a save command af-
ter infection. Therefore, the following restore commands would
restore the system to the saved infected state. Taking another ex-
ample, the infected Android system could simply refuse to route
these commands to the secure world, leading to Denial of Service
(DoS) attacks. We address the first issue by only accepting the save
command for once and ignoring the others. Therefore, only the
clean state after system boot can be saved. For the second issue, we
set up a watch dog in the secure world. After a certain period of
in-activeness, a restore command is forced to be executed.
3.3 Memory Recovery
This section describes how BoltOS makes memory snapshot of the
running system. To begin with, we briefly introduce the architec-
tural design of the ARM processors.
ARM architecture. Almost all the modern OSes work on virtual
memory. ARM processors support virtual memory by a Memory
Management Unit (MMU) and a set of auxiliary system configura-
tion registers. Specifically, when the M bit of the System Control
343Register (SCTLR) is set, the MMU is enabled. The following memory
accesses will first go through the page tables that translate the vir-
tual addresses to the actual physical addresses. The page table is a
multi-level data structure, with the first-level base address pointed
by the Translation Table Base Registers (TTBR). To speedup address
translations, ARM processors have a built-in Translation Lookaside
Buffer (TLB) that caches the recently executed page translations. A
TLB entry is indexed by the corresponding virtual address, plus a
Address Space Identifier (ASID) that is uniquely assigned to individ-
ual tasks. Therefore, during task switches, the TLB does not need
to be flushed.
In an ARM processor with TrustZone support, most of the system
registers are banked, meaning that they have different copies in each
world. This greatly simplifies the implementation of a standalone
OS in the secure world. In particular, during world switches, the
page table is automatically switched to the copy that is previously
set in the destination execution environment, without the need to
update TTBRs. In addition, the NS bit which indicates the current
execution environment is also used to index a TLB entry, making
TLB flushing unnecessary.
Snapshot and Restoration. Since BoltOS runs in an isolated ex-
ecution domain, there is no circular dependencies between the
physical memory and the processor context, which occur in in-
guest restoration solutions [25].
The first step of making memory snapshot is to save the raw
physical memory. In Bolt, we symmetrically partition the physical
memory into two regions – one is loaded with the guest system,
and the other is used to hold the snapshot of the guest system. The
first region is a non-secure resource that can be access by both
worlds, while the second one can only be access by BoltOS. Saving
and restoring the physical memory is straightforward – BoltOS
only needs to copy the guest physical memory to and from the
snapshot region.
The physical memory is tightly coupled with the processor con-
text. Changing physical memory without recovering the processor
context will crash the system. For example, the new TTBR may
point to a memory region that contains invalid entries in the snap-
shot image. As a result, the MMU immediate detects the unmapped
virtual address and triggers a data abort. In BoltOS, apart from
restoring the general purpose registers, we also recover the TTBR,
SCTLR, and ASID registers. In addition, TLB is flushed to avoid
recycling use of the same ASID at the time of saving and restoring.
3.4 Flash Recovery
Barely restoring the state of physical memory and processor is not
enough, since the state of peripherals may be inconsistent with the
system being recovered. Take flash as an example, after the memory
is recovered, the kernel, which maintains data structures related
to the file system, anticipates a matching back storage, which in
fact has been infected. This inconsistency of critical data structures
may cause system crash. More seriously, malware may retain a
copy of itself in the non-volatile flash, which may be activated later
to infect the recovered system. Therefore, it is necessary to save
and restore the content stored in flash as well. Restoring flash by
overwriting the entire content is time consuming, since flash is
“update unfriendly” (Section 2.3). This will be exacerbated when the
flash has a large capacity.
To enable fast recovery of flash, we take advantage of its out-
of-place update feature. This special feature of flash ensures that
during malware analysis, the malware cannot corrupt the clean-
state data (specifically, the content) by over-writing them, which
can be used to restore the clean state later. In addition, to avoid those
data being damaged by garbage collection/wear leveling during
malware analysis, we customize the flash firmware (FTL) by care-
fully modifying the existing garbage collection and wear leveling
implementation in FTL. Note that modifying FTL is advantageous,
since it stays between the OS and the raw flash, and is transparent
to the OS. This allows our design to be resistant to malware that
can obtain a kernel-level privilege.
The resulting design, BoltFTL, can support fast flash restoration
after malware analysis. In the following, we will elaborate the main
operations of BoltFTL. We mark off these operations into three
phases. In the first phase, following the save command received
from BoltOS, BoltFTL takes a snapshot of the clean-state flash.
This phase is executed only for once because BoltOS only responds
to the first save command. Then, in phase two, malware begins
execution and infects the flash. Our customized BoltFTL ensures
that malware can never damage pages storing clean-state data. In
the final phase, BoltFTL recovers the flash to the saved snapshot
directed by the restore command from BoltOS. After this, BoltFTL
is ready to enter phase two.
Phase 1: Malware analysis in-preparation. In this phase,
BoltFTL performs necessary operations to facilitate flash restora-
tion. In particular, after receiving the customized save SCSI com-
mand, it performs the following steps to backup the clean-state
data.
First, BoltFTL will trigger an active garbage collection such that
user data can be stored in a compact manner. Specifically, BoltFTL
marks the blocks having invalid pages as victim blocks, copies
the valid data in these victim blocks to free blocks, updates the
corresponding mappings, and finally, erases the victim blocks.
Second, BoltFTL makes a backup of essential metadata (such as
the mapping table) to facilitate restoration. Note that the metadata
is usually much smaller in size compared to the stored data. Like
other reserved blocks (e.g., blocks reserved for wear leveling and
bad block management), the blocks containing metedata backup
are invisible to the upper layer. Phase one is execute only for once.
Therefore, the clean-state metadata is backed up only for once.
After metadata backup, the flash is ready to accept I/O requests
issued by malware.
Phase 2: Malware analysis in-motion. During the malware anal-
ysis, BoltFTL carefully regulates flash operations to protect the
integrity of the clean-state data in the reserved flash blocks:
• Read. A read operation does not affect flash integrity. There-
fore, BoltFTL simply follows the same logic as that used in
a conventional FTL.
• Write. As with a conventional FTL, BoltFTL adopts an out-of-
place update mechanism to handle write operations. When
allocating a free page, BoltFTL ensures that a page contain-
ing clean-state data or backup of metadata is never selected.
344• Garbage collection. As mentioned earlier, BoltFTL also per-
forms out-of-place updates, meaning that each write op-
eration will be performed on a new flash page. Therefore,
garbage collection is essential for the removal of stale data.
To ensure that the clean-state data are stored intact, BoltFTL
modifies garbage collection so that blocks storing clean-state
data are never selected as victim blocks.
• Wear leveling. As BoltFTL does not reclaim the blocks stor-
ing clean-state data during garbage collection, the P/E cycles
of these blocks would not increase over time. Eventually, un-
even P/E cycles will appear among the blocks storing clean-
state data and the others. To prolong the life of the flash,
BoltFTL customizes wear leveling with the following logic
that ensures an even P/E cycle distribution. (1) Whenever a
free block is allocated for data writing, a wear leveling check-
ing is performed. (2) If the P/E cycle of the block (denoted as
A) is higher than the average P/E cycle of all the blocks by a
certain threshold, wear leveling is performed. (3) To perform
wear leveling, BoltFTL selects the youngest block (i.e., the
block with the least P/E cycles, which is denoted as Y) as
the new block for data writing. (4) If Y contains clean-state
data, BoltFTL copies the clean-state data to the previously
allocated block (i.e., A), erases the young block Y, and finally
selects Y as the final block for data writing. Moreover, the
mapping table and other metadata are updated accordingly.
Phase 3: Recovery from malware analysis. BoltOS sends a re-
store command to BoltFTL to notify the restoration of the flash.
Upon receiving this command, BoltFTL simply discards the old
metadata and activates the backup metadata by coping them to the
RAM of the flash controller. In this way, the flash can be instantly
restored to the clean state. Note that the reserved blocks storing
backup metadata is never modified during phase two and phase
three.
4 IMPLEMENTATION
We have implemented a proof-of-concept prototype for Bolt on an
i.MX 6Quad SABRE experiment board, which integrates a four-core
ARM Cortex-A9 processor, 1 GB DDR3 DRAM and 256 KB SoC
internal RAM (iRAM). In the normal world, we run an Android 7.0
OS. Our prototype implements all the designed functions, except
that we do not provide commodity security services in BoltOS. In