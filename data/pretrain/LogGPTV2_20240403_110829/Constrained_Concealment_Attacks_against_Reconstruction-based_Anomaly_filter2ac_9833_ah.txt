we found that also in this case, when the attacker gains control of
a PLC over the network, the detection Recall can be compromised
by the attacker. In the BATADAL case, Recall is reduced to 0.39. In
the WADI case is reduced to 0.45.
Data Constrained Attacker, ( ˆD,X). We also investigated the
impact of less available normal data (i.e., a fraction of ˆD) on the
achieved reduction in detection Recall for the black box attacker.
Due to space constraints, the detailed results are presented in Ap-
pendix C. For BATADAL, the resulting mean detection Recall ranges
from 0.14 for 100% of ˆD available for AE training to 0.22 for 5% of
ˆD available. For WADI, we found that the attacker can leverage on
5% of normal operations (i.e., only 16 hours) to decrease detector
Recall to 0.24.
(cid:77)Summary of Constrained Attacks findings Our results demon-
strate that replay attacks perform worse if a limited set of sensors
can be manipulated. In particular, if the replay attack is constrained
to manipulate less the 95% of the features the detector’s Recall
increases due to contextual anomalies that are created. For our iter-
ative and learning based approaches, this effect does not occur, as
the two attacks reduce the detector’s Recall without introducing
contextual anomalies. In the WADI, the attacker that controls 4%
of the features succeeds in the evasion using the iterative attack.
In addition, an attacker that collects a little amount of data ˆD can
train the adversarial autoencoder and perform the black box attack.
ACSAC 2020, December 7–11, 2020, Austin, USA
A. Erba et al.
(a) BATADAL
(b) WADI
Figure 2: Impact of Partially Constrained attacker (best-case scenario), comparison between replay attack and our proposed
concealment attacks. In the constrained scenario, we notice that replay attack performs bad increasing detector’s Recall and
raising more alarms than the original data without concealment. This is due to contextual anomalies introduced as part of
large-scale replay. Both learning based and iterative approaches outperform the replay attack as they do not introduce con-
textual anomalies and reduce detector’s Recall manipulating few features.
(a) LSTM
(b) CNN
Figure 3: Generizability of our proposed Learning based attack compared with replay attack. Attack to LSTM (a) and CNN (b)
based defenses on BATADAL dataset.
5.6 Generalizability of Learning Based Attack
In this section, we evaluate the generalizability of our proposed
learning based attack. We consider different reconstruction-based
anomaly detectors trained on BATADAL dataset and apply the
concealment attack computed with the adversarially trained au-
toencoder as proposed in our learning based attack. Our target
Deep Architecture is an LSTM reconstruction-based anomaly detec-
tor as proposed in [20] and a CNN reconstruction-based anomaly
detector as proposed in [32]. Since those detectors are not avail-
able as open source, we implemented their architecture with Keras
following the details found in the paper. The LSTM detector was
trained to minimize the MSE loss. The network takes 8 timesteps
of the multivariate time series as input (input size 8𝑥43). The in-
put is processed by one LSTM layer with output size 43, followed
by a fully connected layer with 43 neurons as output dimension.
Performance of the LSTM based anomaly detector resulted in Ac-
curacy = 0.94, Precision = 0.89, Recall = 0.63, FPR = 0.01. The CNN
detector was trained to minimize the MSE loss. The network takes
2 timesteps of the multivariate time series as input (input size 2𝑥43).
The input is processed by three stacked 1D convolutional layers
(respectively with 64, 128 and 256 neurons), each convolutional
layer is followed by a 1D Max Pooling Layer layer. The last Pooling
layer is followed by a flatten and a dropout layer. Dropout layer
connects to the fully connected output layer with dimension 43.
CNN based performance after training resulted in Accuracy = 0.95,
Precision = 0.90, Recall = 0.67, FPR = 0.01.
Results in Figure 3 show how the detection Recall diminishes
when targeted with replay and learning based attacks. In particular,
a replay attack can evade detection only in the case in which at
least 40 out of 43 sensors are controlled by the attacker (following
previous results). Results over learning based attack, despite the
different architectures for the offense (Autoencoder) and defense
(LSTM and CNN), show that the learning based concealment attack
is transferable. In particular, the LSTM architecture appears more
vulnerable to concealment attacks, since the learning based attack
is achieving higher concealment efficacy than AE and CNN based
defenses. Concealment efficacy over CNN defense is comparable
to Autoencoder defense, notwithstanding the original Recall of
CNN detector is higher than the other considered defense. These
results allow us to conclude that the proposed learning based attack
efficacy is independent from the Reconstruction-based anomaly
detector.
5.7 Real-time Concealment Attacks
In order to test the real-time feasibility of our attacks, we deployed
the anomaly detector [51] in WADI Testbed, and then attacked it
0510152025303540# Controlled sensors k0.000.250.500.751.00Recallreplayiterativelearningoriginal = 0.601020304050607080# Controlled sensors k0.000.250.500.751.00Recallreplayiterativelearningoriginal = 0.680510152025303540# Controlled sensors k0.000.250.500.751.00Recallreplaylearningoriginal = 0.630510152025303540# Controlled sensors k0.000.250.500.751.00Recallreplaylearningoriginal = 0.67Constrained Concealment Attacks against Reconstruction-based detectors in ICS
ACSAC 2020, December 7–11, 2020, Austin, USA
Table 4: Real-time detection of process manipulations in
WADI Testbed. We replicated anomalies in WADI dataset.
Table 5: Recent adversarial learning techniques for evasion,
according to the attacker’s knowledge and the domain of ap-
plication. The setting for our attacks is marked with ★.
Attack
Identifier
Duration
(minutes)
Attack
detected
Detected concealment
Learning
Iterative
W1
W7
W8
W9
W14
22
4
10
1
2
✓
✓
✗
✓
✓
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
White Box
(D,X, 𝑓 , 𝑤)
Grey Box
( ˆD,X, 𝑓 , ˆ𝑤)
Malware
Image
ICS
[58]
[10, 21, 47]
★
[22]
[43]
-
Black Box
( ˆD, ˆX, ˆ𝑓 , ˆ𝑤)
samples
oracle
[14, 61]
[42]
-
-
-
★
in real-time. We collected 15 hours of normal operations occurring
over the ICS. We recorded 62 sensors sampled every 10 seconds.
In this case, we tuned the window parameter to 30, which means
that the detector is considering the sensor readings occurring in