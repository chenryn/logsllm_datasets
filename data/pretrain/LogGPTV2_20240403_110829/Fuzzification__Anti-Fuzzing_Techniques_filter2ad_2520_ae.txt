the original uniq. AFL does not find any bug.
Comparison with normal fuzzing result. QSym uses effi-
cient symbolic execution to help find new paths in fuzzing,
and therefore it is able to discover 44% more real paths than
AFL from original binaries. As we expect, AntiHybrid shows
the most impact on QSym (67% reduction), and less effect on
AFL (18%) and HonggFuzz (7%). With our FUZZIFICATION
techniques, QSym shows less advantage over normal fuzzers,
reduced from 44% to 12%.
6.2 Hindering Bug Finding
We measure the number of unique crashes that fuzzers find
from the original and protected binaries. Our evaluation first
fuzzes four binutils programs and LAVA-M applications with
three fuzzers (all but VUzzer). Then we fuzz LAVA-M pro-
grams with VUzzer, where we compiled them into 32bit ver-
sions and excluded the protection of ROP-based BranchTrap,
which is not implemented yet for 32bit programs.
6.2.1 Impact on Real-World Applications
Figure 11 shows the total number of unique crashes discov-
ered by three fuzzers in 72 hours. Overall, FUZZIFICATION
reduces the number of discovered crashes by 93%, specifi-
cally, by 88% to AFL, by 98% to HonggFuzz, and by 94% to
QSym. If we assume a consistent crash-discovery rate along
the fuzzing process, fuzzers have to take 40 times more ef-
fort to detect the same number of crashes from the protected
binaries. As the crash-discovery rate usually reduces over
time in real-world fuzzing, fuzzers will have to take much
more effort. Therefore, FUZZIFICATION can effectively hin-
der fuzzers and makes them spend significantly more time
discovering the same number of crash-inducing inputs.
6.2.2 Impact on LAVA-M Dataset
Compared with other tested binaries, LAVA-M programs
are smaller in size and simpler in operation. If we inject a
1ms delay on 1% of rarely executed basic block on who bi-
nary, the program will suffer a slow down of more than 40
times. To apply FUZZIFICATION on the LAVA-M dataset, we
Overhead (Size)
uniq
who
base64 md5sum Average
17.1% 220.6% 220.0% 210.7% 167.1%
(0.3M)
(0.3M)
(0.3M)
(0.3M)
Overhead (CPU)
22.7%
13.2%
21.1%
6.5%
15.9%
Table 6: Overhead of FUZZIFICATION on LAVA-M binaries (all
protections except ROP-based BranchTrap) . The overhead is higher
as LAVA-M binaries are relatively small (e.g., ≈ 200KB).
allow higher overhead budget and apply more fine-grained
FUZZIFICATION. Specifically, we used tiny delay primitives
(i.e., 10 µs to 100 µs), tuned the ratio of basic block instru-
mentation from 1% to 0.1%, reduced the number of applied
AntiHybrid components, and injected smaller deterministic
branches to reduce the code size overhead. Table 6 shows
the run-time and space overhead of the generated LAVA-M
programs with FUZZIFICATION techniques.
After fuzzing the protected binaries for 10 hours, AFL-
QEMU does not find any crash. HonggFuzz detects three
crashes from the original uniq binary and cannot find
any crash from any protected binary.
Figure 12 illus-
trates the fuzzing result of VUzzer and QSym. Overall,
FUZZIFICATION can reduce 56% of discovered bugs to
VUzzer and 78% of discovered bugs to QSym. Note that
the fuzzing result on the original binaries is different from the
ones reported in the original papers [67, 52] for several rea-
sons: VUzzer and QSym cannot eliminate non-deterministic
steps during fuzzing; we run the AFL part of each tool in
QEMU mode; LAVA-M dataset is updated with several bug
fixes3.
6.3 Anti-fuzzing on Realistic Applications
To understand the practicality of FUZZIFICATION on large
and realistic applications, we choose six programs that have a
graphical user interface (GUI) and depend on tens of libraries.
As fuzzing large and GUI programs is a well-known challeng-
ing problem, our evaluation here focuses on measuring the
overhead of FUZZIFICATION techniques and the functionality
3https://github.com/panda-re/lava/search?q=bugfix&type=Commits
1924    28th USENIX Security Symposium
USENIX Association
Category
Program
Version
LibreOffice
Writer
Calc
Impress
Clementine
Music Player
PDF Reader
MuPDF
Image Viewer Nomacs
Average
6.2
1.3
1.13
3.10
Overhead
Size
< 1% (+1.3 MB)
< 1% (+1.3 MB)
< 1% (+1.3 MB)
4.3% (+1.3 MB)
4.1% (+1.3 MB)
21% (+1.2 MB)
5.4%
CPU
0.4%
0.4%
0.2%
0.5%
2.2%
0.7%
0.73%
Table 7: FUZZIFICATION on GUI applications. The CPU over-
head is calculated on the application launching time. Due to the
fixed code injection, code size overhead is negligible for these large
applications.
Pattern
matching
Control
analysis
Data
analysis
Manual
analysis
SpeedBump
BranchTrap
AntiHybrid
✔
✔
-
✔
✔
✔
✔
✔
✔
-
-
-
Table 8: Defense against adversarial analysis. ✔ indicates that the
FUZZIFICATION technique is resistant to that adversarial analysis.
s
h
t
a
p
l
a
e
r
#
80k
60k
40k
20k
0k
(a) AFL-QEMU
(b) HonggFuzz (PT)
(c) QSym (AFL-QEMU)
Original
Fuzzified (All)
12 24 36 48 60 72
12 24 36 48 60 72
12 24 36 48 60 72
of protected programs. When applying the SpeedBump tech-
nique, we have to skip the basic block profiling step due to the
lack of command-line interface (CLI) support (e.g., readelf
parses ELF file and displays results in command line); thus,
we only insert slow down primitives into error-handling rou-
tines. For the BranchTrap technique, we choose to inject
massive fake branches into basic blocks near the entry point.
In this way, the program execution will always pass the in-
jected component so that we can measure runtime overhead
correctly. We apply the AntiHybrid technique directly.
For each protected application, we first manually run it
with multiple inputs, including given test cases, and confirm
that FUZZIFICATION does not affect the program’s original
functionality. For example, MuPDF successfully displays, ed-
its, saves, and prints all tested PDF documents. Second, we
measure the code size and runtime overhead of the protected
binaries for given test cases. As shown in Table 7, on av-
erage, FUZZIFICATION introduces 5.4% code size overhead
and 0.73% runtime overhead. Note that the code size over-
head is much smaller than that of previous programs (i.e.,
62.1% for eight relatively small programs Table 2 and over
100% size overhead for simple LAVA-M programs Table 6).
Anti-fuzzing on MuPDF. We also evaluated the effective-
ness of FUZZIFICATION on protecting MuPDF against three
fuzzers – AFL, HonggFuzz, and QSym– as MuPDF supports
the CLI interface through the tool called “mutool.” We com-
piled the binary with the same parameter shown in Table 4
and performed basic block profiling using the CLI interface.
After 72-hours of fuzzing, no fuzzer finds any bug from MuPDF.
Therefore, we instead compare the number of real paths be-
tween the original binary and the protected one. As shown in
Figure 13, FUZZIFICATION reduces the total paths by 55% on
average, specifically, by 77% to AFL, by 36% to HonggFuzz,
and 52% to QSym. Therefore, we believe it is more chal-
lenging for real-world fuzzers to find bugs from protected
applications.
Time (hours)
Time (hours)
Figure 13: Paths discovered by different fuzzers from the original
MuPDF and the one protected by three FUZZIFICATION techniques.
Time (hours)
6.4 Evaluating Best-effort Countermeasures
We evaluate the robustness of FUZZIFICATION techniques
against off-the-shelf program analysis techniques that adver-
saries may use to reverse our protections. However, the experi-
ment results do not particularly indicate that FUZZIFICATION
is robust against strong adversaries with incomparable com-
putational resources.
Table 8 shows the analysis we covered and summarizes
the evaluation result. First, attackers may search particular
code patterns from the protected binary in order to identify
injected protection code. To test anti-fuzzing against pattern
matching, we examine a number of code snippets that are
repeatedly used throughout the protected binaries. We found
that the injected code by AntiHybrid crafts several observable
patterns, like hash algorithms or data-flow reconstruction
code, and thus could be detected by attackers. One possible
solution to this problem is to use existing diversity techniques
to eliminate the common patterns [35]. We confirm that no
specific patterns can be found in SpeedBump and BranchTrap
because we leverage CSmith [66] to randomly generate a new
code snippet for each FUZZIFICATION process.
Second, control-flow analysis can identify unused code in
a given binary automatically and thus automatically remove it
(i.e., dead code elimination). However, this technique cannot
remove our FUZZIFICATION techniques, as all injected code
is cross-referenced with the original code. Third, data-flow
analysis is able to identify the data dependency. We run pro-
tected binaries inside the debugging tool, GDB, to inspect
data dependencies between the injected code and the original
code. We confirm that data dependencies always exist via
global variables, arguments, and the return values of injected
functions. Finally, we consider an adversary who is capable
of conducting manual analysis for identifying the anti-fuzzing
code with the knowledge of our techniques. It is worth noting
that we do not consider strong adversaries who are capable
USENIX Association
28th USENIX Security Symposium    1925
of analyzing the application logic for vulnerability discovery.
Since FUZZIFICATION injected codes are supplemental to
the original functions, we conclude that the manual analysis
can eventually identify and nullify our techniques by evaluat-
ing the actual functionality of the code. However, since the
injected code is functionally similar to normal arithmetic oper-
ations and has control- and data-dependencies on the original
code, we believe that the manual analysis is time-consuming
and error-prone, and thus we can deter the time for revealing
real bugs.
7 Discussion and Future Work
In this section, we discuss the limitations of FUZZIFICATION
and suggest provisional countermeasures against them.
Complementing attack mitigation system. The goal of
anti-fuzzing is not to completely hide all vulnerabilities from
adversaries. Instead, it introduces an expensive cost on the
attackers’ side when they try to fuzz the program to find
bugs, and thus developers are able to detect bugs first and
fix them in a timely manner. Therefore, we believe our anti-
fuzzing technique is an important complement to the current
attack mitigation ecosystem. Existing mitigation efforts ei-
ther aim to avoid program bugs (e.g., through type-safe lan-
guage [32, 44]) or aim to prevent successful exploits, assum-
ing attackers will find bugs anyway (e.g., through control-flow
integrity [1, 16, 30]). As none of these defenses can achieve
100% protection, our FUZZIFICATION techniques provide an-
other level of defense that further enhances program security.
However, we emphasize that FUZZIFICATION alone cannot
provide the best security. Instead, we should keep working
on all aspects of system security toward a completely secure
computer system, including but not limited to secure devel-
opment process, effective bug finding, and efficient runtime
defense.
Best-effort protection against adversarial analysis. Al-
though we examined existing generic analyses and believe
they cannot completely disarm our FUZZIFICATION tech-
niques, the defensive methods only provide a best-effort pro-
tection. First, if attackers have almost unlimited resources,
such as when they launch APT (advanced persistent threat) at-
tacks, no defense mechanism can survive the powerful adver-
sarial analysis. For example, with extremely powerful binary-
level control-flow analysis and data-flow analysis, attackers
may finally identify the injected branches by BranchTrap and
thus reverse it for an unprotected binary. However, it is hard
to measure the amount of required resources to achieve this
goal, and meanwhile, developers can choose more compli-
cated branch logic to mitigate reversing. Second, we only
examined currently existing techniques and cannot cover all
possible analyses.
It is possible that attackers who know
the details of our FUZZIFICATION techniques propose a spe-
cific method to effectively bypass the protection, such as by
utilizing our implementation bugs. But in this case, the anti-
fuzzing technique will also get updated quickly to block the
specific attack once we know the reversing technique. There-
fore, we believe the anti-fuzzing technique will get improved
continuously along the back-and-forth attack and defense
progress.
Trade-off performance for security. FUZZIFICATION im-
proves software security at the cost of a slight overhead, in-
cluding code size increase and execution slow down. A sim-
ilar trade-off has been shown in many defense mechanisms
and affects the deployment of defense mechanisms. For ex-
ample, address space layout randomization (ASLR) has been
widely adopted by modern operating systems due to small
overhead, while memory safety solutions still have a long
way to go to become practical. Fortunately, the protection by
FUZZIFICATION is quite flexible, where we provide various
configuration options for developers to decide the optimal
trade-off between security and performance, and our tool will
automatically determine the maximum protection under the
overhead budget.
Delay primitive on different H/W environments. We
adopt CSmith-generated code as our delay primitives using
measured delay on one machine (i.e., developer’s machine).
This configuration implies that those injected delays might
not be able to bring the expected slow down to the fuzzed
execution with more powerful hardware support. On the other
hand, the delay primitives can cause higher overhead than
expected for regular users with less powerful devices. To han-
dle this, we plan to develop an additional variation that can
dynamically adjust the delay primitives at runtime. Specif-
ically, we measure the CPU performance by monitoring a
few instructions and automatically adjusting a loop counter in
the delay primitives to realize the accurate delay in different
hardware environments. However, the code may expose static
pattern such as time measurement system call or a special
instruction like rdtsc; thus we note that this variation has
inevitable trade-off between adaptability and robustness.
8 Related Work
Fuzzing. Since the first proposal by Barton Miller in 1990
[40], fuzzing has evolved into a standard method for auto-
matic program testing and bug finding. Various fuzzing tech-
niques and tools have been proposed [57, 52, 29, 21, 34], de-
veloped [72, 37, 25, 23, 18, 9], and used to find a large number
of program bugs [51, 72, 59, 26, 10]. There are continuous ef-
forts to help improve fuzzing efficiency by developing a more
effective feedback loop [6], proposing new OS primitives [64],
and utilizing clusters for large-scale fuzzing [22, 24, 39].
Recently, researchers have been using fuzzing as a gen-
eral way to explore program paths with specialties, such
as maximizing CPU usage [49], reaching a particular code
location [5], and verifying the deep learning result empiri-
1926    28th USENIX Security Symposium
USENIX Association
cally [47]. All these works result in a significant improve-
ment to software security and reliability. In this paper, we
focus on the opposite side of the double-edged sword, where
attackers abuse fuzzing techniques to find zero-day vulnera-
bilities and thus launch a sophisticated cyber attack. We build
effective methods to hinder attackers on bug finding using
FUZZIFICATION, which can provide developers and trusted
researchers time to defeat the adversarial fuzzing effort.
Anti-fuzzing techniques. A few studies briefly discuss
the concept of anti-fuzzing [63, 27, 41, 31]. Among them,
Göransson et al. evaluated two straightforward techniques,
i.e., crash masking to prevent fuzzers finding crashes and
fuzzer detection to hide functionality when being fuzzed [27].
However, attackers can easily detect these methods and by-
pass them for effective fuzzing. Our system provides a fine-
grained controllable method to slow the fuzzed execution and
introduces effective ways to manipulate the feedback loop
to fool fuzzers. We also consider defensive mechanisms to
prevent attackers from removing our anti-fuzzing techniques.
Hu et al. proposed to hinder attacks by injecting prov-
ably (but not obviously) non-exploitable bugs to the program,
called “Chaff Bugs” [31]. These bugs will confuse bug anal-
ysis tools and waste attackers’ effort on exploit generation.
Both chaff bugs and FUZZIFICATION techniques work on
close-source programs. Differently, our techniques hinder
bug finding in the first place, eliminating the chance for an
attacker to analyze bugs or construct exploits. Further, both
techniques may affect normal-but-rare usage of the program.
However, our methods, at most, introduce slow down to the
execution, while improper chaff bugs lead to crashes, thus
harming the usability.
Anti-analysis techniques. Anti-symbolic-execution and
anti-taint-analysis are well-known topics. Sharif et al. [56]
designed a conditional code obfuscation that encrypts a condi-
tional branch with cryptographic operations. Wang et al. [62]
proposed a method to harden the binary from symbolic ex-
ecution by using linear operations instead of cryptographic