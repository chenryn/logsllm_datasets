   2) 1) "sensor-id"
      2) "1234"
      3) "temperature"
      4) "10.5"
2) 1) 1506872463535.0
   2) 1) "foo"
      2) "10"
```
这里我们讲的是 ID 的范围，然后，为了取得在一个给定时间范围内的特定范围的元素，你可以使用 `XRANGE`，因为 ID 的“序号” 部分可以省略。因此，你可以只指定“毫秒”时间即可，下面的命令的意思是：“从 UNIX 时间 1506872463 开始给我 10 个条目”：
```
127.0.0.1:6379> XRANGE mystream 1506872463000 + COUNT 10
1) 1) 1506872463535.0
   2) 1) "foo"
      2) "10"
2) 1) 1506872463535.1
   2) 1) "bar"
      2) "20"
```
关于 `XRANGE` 需要注意的最重要的事情是，假设我们在回复中收到 ID，随后连续的 ID 只是增加了序号部分，所以可以使用 `XRANGE` 遍历整个流，接收每个调用的指定个数的元素。Redis 中的`*SCAN` 系列命令允许迭代 Redis 数据结构，尽管事实上它们不是为迭代设计的，但这样可以避免再犯相同的错误。
### 使用 XREAD 处理流播：阻塞新的数据
当我们想通过 ID 或时间去访问流中的一个范围或者是通过 ID 去获取单个元素时，使用 `XRANGE` 是非常完美的。然而，在使用流的案例中，当数据到达时，它必须由不同的客户端来消费时，这就不是一个很好的解决方案，这需要某种形式的 汇聚池   pooling 。（对于 *某些* 应用程序来说，这可能是个好主意，因为它们仅是偶尔连接查询的）
`XREAD` 命令是为读取设计的，在同一个时间，从多个流中仅指定我们从该流中得到的最后条目的 ID。此外，如果没有数据可用，我们可以要求阻塞，当数据到达时，就解除阻塞。类似于阻塞列表操作产生的效果，但是这里并没有消费从流中得到的数据，并且多个客户端可以同时访问同一份数据。
这里有一个典型的 `XREAD` 调用示例：
```
> XREAD BLOCK 5000 STREAMS mystream otherstream $ $
```
它的意思是：从 `mystream` 和 `otherstream` 取得数据。如果没有数据可用，阻塞客户端 5000 毫秒。在 `STREAMS` 选项之后指定我们想要监听的关键字，最后的是指定想要监听的 ID，指定的 ID 为 `$` 的意思是：假设我现在需要流中的所有元素，因此，只需要从下一个到达的元素开始给我。
如果我从另一个客户端发送这样的命令：
```
> XADD otherstream * message “Hi There”
```
在 `XREAD` 侧会出现什么情况呢？
```
1) 1) "otherstream"
   2) 1) 1) 1506935385635.0
         2) 1) "message"
            2) "Hi There"
```
与收到的数据一起，我们也得到了数据的关键字。在下次调用中，我们将使用接收到的最新消息的 ID：
```
> XREAD BLOCK 5000 STREAMS mystream otherstream $ 1506935385635.0
```
依次类推。然而需要注意的是使用方式，客户端有可能在一个非常大的延迟之后再次连接（因为它处理消息需要时间，或者其它什么原因）。在这种情况下，期间会有很多消息堆积，为了确保客户端不被消息淹没，以及服务器不会因为给单个客户端提供大量消息而浪费太多的时间，使用 `XREAD` 的 `COUNT` 选项是非常明智的。
### 流封顶
目前看起来还不错……然而，有些时候，流需要删除一些旧的消息。幸运的是，这可以使用 `XADD` 命令的 `MAXLEN` 选项去做：
```
> XADD mystream MAXLEN 1000000 * field1 value1 field2 value2
```
它是基本意思是，如果在流中添加新元素后发现消息数量超过了 `1000000` 个，那么就删除旧的消息，以便于元素总量重新回到 `1000000` 以内。它很像是在列表中使用的 `RPUSH` + `LTRIM`，但是，这次我们是使用了一个内置机制去完成的。然而，需要注意的是，上面的意思是每次我们增加一个新的消息时，我们还需要另外的工作去从流中删除旧的消息。这将消耗一些 CPU 资源，所以在计算 `MAXLEN` 之前，尽可能使用 `~` 符号，以表明我们不要求非常 *精确* 的 1000000 个消息，就是稍微多一些也不是大问题：
```
> XADD mystream MAXLEN ~ 1000000 * foo bar
```
这种方式的 XADD 仅当它可以删除整个节点的时候才会删除消息。相比普通的 `XADD`，这种方式几乎可以自由地对流进行封顶。
### 消费组（开发中）
这是第一个 Redis 中尚未实现而在开发中的特性。灵感也是来自 Kafka，尽管在这里是以不同的方式实现的。重点是使用了 `XREAD`，客户端也可以增加一个 `GROUP ` 选项。相同组的所有客户端将自动得到 *不同的* 消息。当然，同一个流可以被多个组读取。在这种情况下，所有的组将收到流中到达的消息的相同副本。但是，在每个组内，消息是不会重复的。
当指定组时，能够指定一个 `RETRY ` 选项去扩展组：在这种情况下，如果消息没有通过 `XACK` 进行确认，它将在指定的毫秒数后进行再次投递。这将为消息投递提供更佳的可靠性，这种情况下，客户端没有私有的方法将消息标记为已处理。这一部分也正在开发中。
### 内存使用和节省加载时间
因为用来建模 Redis 流的设计，内存使用率是非常低的。这取决于它们的字段、值的数量和长度，对于简单的消息，每使用 100MB 内存可以有几百万条消息。此外，该格式设想为需要极少的序列化：listpack 块以 radix 树节点方式存储，在磁盘上和内存中都以相同方式表示的，因此它们可以很轻松地存储和读取。例如，Redis 可以在 0.3 秒内从 RDB 文件中读取 500 万个条目。这使流的复制和持久存储非常高效。
我还计划允许从条目中间进行部分删除。现在仅实现了一部分，策略是在条目在标记中标识条目为已删除，并且，当已删除条目占全部条目的比例达到指定值时，这个块将被回收重写，如果需要，它将被连到相邻的另一个块上，以避免碎片化。
### 关于最终发布时间的结论
Redis 的流特性将包含在年底前（LCTT 译注：本文原文发布于 2017 年 10 月）推出的 Redis 4.0 系列的稳定版中。我认为这个通用的数据结构将为 Redis 提供一个巨大的补丁，以用于解决很多现在很难以解决的情况：那意味着你（之前）需要创造性地“滥用”当前提供的数据结构去解决那些问题。一个非常重要的使用场景是时间序列，但是，我觉得对于其它场景来说，通过 `TREAD` 来流播消息将是非常有趣的，因为对于那些需要更高可靠性的应用程序，可以使用发布/订阅模式来替换“即用即弃”，还有其它全新的使用场景。现在，如果你想在有问题环境中评估这个新数据结构，可以更新 GitHub 上的 streams 分支开始试用。欢迎向我们报告所有的 bug。:-)
如果你喜欢观看视频的方式，这里有一个现场演示：
---
via: 
作者：[antirez](http://antirez.com/) 译者：[qhwdw](https://github.com/qhwdw) 校对：[wxy](https://github.com/wxy), [pityonline](https://github.com/pityonline)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出