Stack Overﬂow. Based on these insecure TM snippets, [13]
were able to attack several high-proﬁle apps extracting pri-
vate data. Moreover, [27] found that only 45 out of 639,283
Android apps applied certiﬁcate pinning, while 25% of de-
velopers ﬁnd certiﬁcate pinning too complex to use. [2] re-
ported that tasks very similar to TM could not be solved with
the help of simpliﬁed cryptographic APIs within a user study.
the nudge treatment performs very well,
but only slightly better than the control treatment, as both
achieved 86.7% and 81.8% secure solutions, respectively.
For Cipher,
For IV and TLS, the nudge results are less desirable with
46.2% and 38.5% secure solutions, while performing better
but not signiﬁcantly (p < 0.077 and p < 0.53; Chi-Square)
than the control treatment. To better understand these ob-
servations, we analyzed visited posts, copy-and-paste history
and the submitted code of participants that provided insecure
solutions for these two tasks. In the case of IV, we found that
four insecure solutions reused insecure patterns from code
snippets that were falsely marked as recommended code. To
encounter false predictions of the security model was a pri-
ori extremely unlikely. Interestingly, the remaining insecure
solutions were created by users combining secure code from
different correctly marked recommendations (true negatives)
into insecure code. Thereby, users reused the seed statement
for IV from one snippet and initialized it with an empty ar-
ray obtained from another code snippet that did not make
use of IV at all. In the case of TLS, all insecure solutions
were copied from code snippets that were clearly marked as
insecure.
Copy-and-Paste Behavior We calculated the average
copy-paste rate per task for both treatments, which reports
the relative frequency copied code has also been reused in a
submitted solution (see Figure 7b). Importantly, in the nudge
treatment, not a single insecure copy-and-paste event was
observed for Cipher, Key and TM, while secure code that was
copied into the clipboard was reused at a rate of 0.45, 0.55,
and 0.72 on average, respectively. This goes in line with ob-
served security outcomes depicted in Figure 7a, where more
secure than insecure solutions were provided for these tasks.
However, insecure copy-and-paste events were observed for
IV and TLS, partly explaining the comparatively higher num-
ber of insecure solutions. In the control treatment, the copy-
paste rate for insecure snippets closely follows the observed
frequencies of insecure results for all tasks except Cipher.
Warnings/Recommendations/Reminder Even though all
users within the nudge group saw security warnings during
their journey, we observed an insecure-to-secure copy event
ratio of 0.27 for both treatments indicating that warnings
alone are not sufﬁcient for preventing users from placing in-
secure code on the clipboard. However, the copy-paste rate
measuring the relative frequency of copy to paste events (see
Figure 7b) offers more nuanced results.
It shows that the
nudge group tends to discard insecure copies, while pasting
more secure copies into their solutions. This is most likely
USENIX Association
28th USENIX Security Symposium    351
the result of the reminder nudge, which was triggered by in-
secure copy events. As a result, users dropped copied inse-
cure samples and started looking for a secure alternative. In
contrast, the copy-paste rate for control shows that copied in-
secure snippets were not dropped, but rather pasted into the
solution. Therefore, the interaction of several nudges was
responsible for improving the security decisions of the par-
ticipants. In the exit survey, users also marked the relevant
nudges with high average Likert score values of above 4 (on
5-point scales).
We only observed 22 events where users clicked on a pro-
posed recommendation link as shown in the bottom part of
Figure 8a. Therefore, only 10.1% of secure posts (of 219
in total) were visited following such a proposed recommen-
dation. However, 86.6% remembered the feature during the
exit survey. With 4 paste and 8 copy events (i.e., a copy-
paste rate of 0.5) only a very small amount of reused secure
code in the submitted solutions was directly related to this
nudge. Though contributing to the improvement of code se-
curity, we can state that this nudge was surprisingly the least
effective one. The average Likert score for the list of recom-
mendations was also comparatively low with 3.2.
9 Limitations
The response rate during recruitment for our developer study
was quite low. However, we achieved a participation count
per treatment which was very similar to comparable peer-
reviewed studies (e.g., [2]). However, participation may in-
troduce self-selection bias. Therefore, we avoided any se-
curity framing during recruitment and have no reason to be-
lieve that the ﬁnal group of participants was systematically
different in terms of security knowledge. The study was per-
formed within a laboratory under strict time constraints. By
enforcing a time limit, we intended to create a more realistic
scenario and to obtain a comparable outcome for both treat-
ments. Participants had to solve their programming tasks us-
ing a given code editor, browser, as well as operating sys-
tem which they might not have been familiar with. Most of
our participants were students, while only a minority had a
professional background, which may limit the generalizabil-
ity of our results. Professionals performed slightly better in
achieving functional solutions, but not in security across both
treatments. Therefore, comparisons among both treatments
remain valid.
For implementing custom trust managers in Android (see
Section 8.2), current best practices suggest a declarative so-
lution which uses a static conﬁguration ﬁle instead of Java
code.8 Being able to include other formats, such as formal
documentation in our recommendations would additionally
allow suggesting this solution. One possible way to achieve
8https://developer.android.com/training/articles/
security-config
that is to create a link between code examples from Stack
Overﬂow and natural language text in ofﬁcial documenta-
tion.
I.e., we would have to extend our framework such
that it embeds code examples and natural language text into
the same vector space. This can be done with sequence-to-
sequence models, which are usually applied for natural lan-
guage translation. GitHub is currently testing a similar ap-
proach for their semantic code search engine.9
10 Future Work
Our recommendation approach may be subject to attacks.
More speciﬁcally, in an adversarial setting, machine learn-
ing algorithms are often not robust against manipulated in-
put data. Similar to efforts in malware obfuscation and spam
ﬁlter bypassing, an attacker might be able to craft malicious
code that gets mistakenly classiﬁed as secure. This way, the
attacker could spread malicious code into the ecosystem on
a large scale. However, a number of novel techniques have
been proposed to counter the adversarial effect [18, 24, 28].
Stack Overﬂow provides code examples for almost each
and every programming language. Since our framework
learns the optimal code representation for a given classiﬁca-
tion task based on general code features, we do not see ma-
jor issues in applying it to different programming languages.
A language-speciﬁc compiler or a universal parser can be
used to generate the PDG, which is then fed to our pattern
embedding network (see Section 5.4). The representation
learning of API-speciﬁc lexical features (see Section 5.3)
is completely independent from the programming language
and therefore straightforward.
We suggest to conduct additional UI testing as we might
not have identiﬁed the optimal design, yet. Following Felt
et al. [15], different security indicators such as alternative
candidate icons and text have to be tested, for instance
within user surveys or by repeating our developer study.
Stack Overﬂow recently proposed a partnership program
with academia that would allow to extend their developer
survey and to test design tweaks on their website.10
11 Conclusion
In this paper, we propose an approach for deep learning se-
curity nudges that help software developers write strong en-
cryption code. We propose a system design integrated in
Stack Overﬂow whose components consist of several secu-
rity nudges, namely warnings, recommendations, reminders,
and defaults and a neural network architecture that controls
these nudges by learning and predicting secure and inse-
cure cryptographic usage patterns from community-provided
9https://githubengineering.com/
towards-natural-language-semantic-code-search/
10https://meta.stackoverflow.com/questions/377152/
stack-overflow-academic-research-partnership-program
352    28th USENIX Security Symposium
USENIX Association
code examples. We propose a novel approach on deep learn-
ing optimized code representations for given code classiﬁ-
cation tasks and train a classiﬁcation model that is able to
predict use cases and security scores of encryption code ex-
amples with an AUC-ROC of 0.999 and 0.992, respectively.
Applying this model within our nudge-based system design
on Stack Overﬂow, we performed a user study where par-
ticipants had to solve the most error-prone cryptographic
programming tasks reported in recent research. Our results
demonstrate the effectiveness of nudges in helping software
developers to make better security decisions on Stack Over-
ﬂow.
Acknowledgements
The authors would like to thank Fraunhofer AISEC for tech-
nical support, DIVSI for support of our research efforts, and
the anonymous reviewers for their helpful comments.
References
[1] ACAR, Y., BACKES, M., FAHL, S., GARFINKEL,
S., KIM, D., MAZUREK, M. L., AND STRANSKY,
C. Comparing the usability of cryptographic APIs.
In IEEE Symposium on Security and Privacy (2017),
pp. 154–171.
[2] ACAR, Y., BACKES, M., FAHL, S., KIM, D.,
MAZUREK, M. L., AND STRANSKY, C. You Get
Where You’re Looking For: The Impact of Informa-
tion Sources on Code Security. In IEEE Symposium on
Security and Privacy (2016), pp. 289–305.
[3] ACER, M., STARK, E., FELT, A. P., FAHL, S., BHAR-
GAVA, R., DEV, B., BRAITHWAITE, M., SLEEVI, R.,
AND TABRIZ, P. Where the wild warnings are: Root
In ACM
causes of Chrome HTTPS certiﬁcate errors.
Conference on Computer & Communications Security
(2017), pp. 1407–1420.
[4] ACQUISTI, A. Nudging privacy: The behavioral eco-
nomics of personal information. IEEE Security & Pri-
vacy 7, 6 (2009), 82–85.
[5] ACQUISTI, A., ADJERID,
I., BALEBAKO, R.,
BRANDIMARTE, L., CRANOR, L. F., KOMANDURI,
S., LEON, P. G., SADEH, N., SCHAUB, F., SLEEPER,
M., ET AL. Nudges for privacy and security: Un-
derstanding and assisting users’ choices online. ACM
Computing Surveys 50, 3 (2017), Article No. 44.
[6] ALMUHIMEDI, H., SCHAUB, F., SADEH, N., AD-
JERID, I., ACQUISTI, A., GLUCK, J., CRANOR, L. F.,
AND AGARWAL, Y. Your location has been shared
5,398 times! A ﬁeld study on mobile app privacy nudg-
ing. In ACM Conference on Human Factors in Comput-
ing Systems (2015), pp. 787–796.
[7] BALEBAKO, R., LEON, P. G., ALMUHIMEDI, H.,
KELLEY, P. G., MUGAN, J., ACQUISTI, A., CRA-
NOR, L. F., AND SADEH, N. Nudging users to-
In CHI Workshop
wards privacy on mobile devices.
on Persuasion, Nudge, Inﬂuence and Coercion (2011),
pp. 193–201.
[8] B ¨OHME, R., AND GROSSKLAGS, J. The security
cost of cheap user interaction. In ACM New Security
Paradigms Workshop (2011), pp. 67–82.
[9] CHEN, M., FISCHER, F., MENG, N., WANG, X.,
AND GROSSKLAGS, J. How reliable is the crowd-
sourced knowledge of security implementation?
In
ACM/IEEE International Conference on Software En-
gineering (2019).
[10] DAGENAIS, B., AND HENDREN, L. Enabling static
analysis for partial Java programs. ACM Sigplan No-
tices 43, 10 (2008), 313–328.
[11] DAI, H., DAI, B., AND SONG, L. Discriminative
embeddings of latent variable models for structured
data. In International Conference on Machine Learn-
ing (2016), pp. 2702–2711.
[12] EGELE, M., BRUMLEY, D., FRATANTONIO, Y., AND
KRUEGEL, C. An empirical study of cryptographic
misuse in Android applications. In ACM Conference on
Computer & Communications Security (2013), pp. 73–
84.
[13] FAHL, S., HARBACH, M., MUDERS, T., SMITH, M.,
BAUMG ¨ARTNER, L., AND FREISLEBEN, B. Why Eve
and Mallory love Android: An analysis of Android SSL
(in)security. In ACM Conference on Computer & Com-
munications Security (2012), pp. 50–61.
[14] FAHL, S., HARBACH, M., PERL, H., KOETTER, M.,
AND SMITH, M. Rethinking SSL development in an
In ACM Conference on Computer &
appiﬁed world.
Communications Security (2013), pp. 49–60.
[15] FELT, A. P., REEDER, R., AINSLIE, A., HARRIS,
H., WALKER, M., THOMPSON, C., ACER, M. E.,
MORANT, E., AND CONSOLVO, S. Rethinking con-
In Symposium on Usable
nection security indicators.
Privacy and Security (2016), pp. 1–14.
[16] FENG, Q., ZHOU, R., XU, C., CHENG, Y., TESTA,
B., AND YIN, H. Scalable graph-based bug search for
ﬁrmware images. In ACM Conference on Computer &
Communications Security (2016), pp. 480–491.
[17] FISCHER, F., B ¨OTTINGER, K., XIAO, H., STRAN-
SKY, C., ACAR, Y., BACKES, M., AND FAHL, S.
Stack overﬂow considered harmful? The impact of
copy&paste on Android application security. In IEEE
Symposium on Security and Privacy (2017).
USENIX Association
28th USENIX Security Symposium    353
[18] GANIN, Y., USTINOVA, E., AJAKAN, H., GERMAIN,
P., LAROCHELLE, H., LAVIOLETTE, F., MARC-
HAND, M., AND LEMPITSKY, V. Domain-adversarial
training of neural networks. Journal of Machine Learn-
ing Research 17, 59 (2016), 1–35.
[28] PAPERNOT, N., MCDANIEL, P., WU, X., JHA, S.,
AND SWAMI, A. Distillation as a defense to adversarial
In IEEE
perturbations against deep neural networks.
Symposium on Security and Privacy (2016), pp. 582–
597.
[19] GROSSKLAGS, J., RADOSAVAC, S., C ´ARDENAS, A.,
AND CHUANG, J. Nudge: Intermediaries role in in-
terdependent network security. In International Con-
ference on Trust and Trustworthy Computing (2010),
pp. 323–336.
[20] KR ¨UGER, S., SP ¨ATH, J., ALI, K., BODDEN, E., AND
MEZINI, M. CrySL: An extensible approach to vali-
dating the correct usage of cryptographic apis. In Eu-
ropean Conference on Object-Oriented Programming
(2018), pp. 10:1–10:27.
[29] SCHECHTER, S. Common pitfalls in writing about
security and privacy human subjects experiments, and
how to avoid them. Tech. rep., Microsoft Research,
2013.
[30] SUNSTEIN, C. Nudging: A very short guide. Journal
of Consumer Policy 37, 4 (2014), 583–588.
[31] THALER, R., AND SUNSTEIN, C. Nudge: Improving
decisions about health, wealth, and happiness. Pen-
guin, 2008.
[21] LI, Z., ZOU, D., XU, S., OU, X., JIN, H., WANG, S.,
DENG, Z., AND ZHONG, Y. VulDeePecker: A deep
learning-based system for vulnerability detection.
In
Network and Distributed Systems Security Symposium
(2018).
[32] WANG, Y., LEON, P. G., SCOTT, K., CHEN, X., AC-
QUISTI, A., AND CRANOR, L. F. Privacy nudges
for social media: An exploratory Facebook study. In
International Conference on World Wide Web (2013),
pp. 763–770.
[22] LIU, B., ANDERSEN, M. S., SCHAUB, F., AL-
MUHIMEDI, H., ZHANG, S. A., SADEH, N., AGAR-
WAL, Y., AND ACQUISTI, A. Follow my recommenda-
tions: A personalized privacy assistant for mobile app
permissions. In Symposium on Usable Privacy and Se-
curity (2016), pp. 27–41.