title:Secure Single-Server Aggregation with (Poly)Logarithmic Overhead
author:James Henry Bell and
Kallista A. Bonawitz and
Adrià Gasc&apos;on and
Tancrède Lepoint and
Mariana Raykova
Secure Single-Server Aggregation with (Poly)Logarithmic
Overhead
Adrià Gascón
Google
London, UK
Tancrède Lepoint
Mariana Raykova
Google
New York, US
Google
New York, US
James Henry Bell
The Alan Turing Institute
London, UK
PI:EMAIL
Kallista A. Bonawitz
Google
New York, US
PI:EMAIL
PI:EMAIL
PI:EMAIL
PI:EMAIL
ABSTRACT
Secure aggregation is a cryptographic primitive that enables a
server to learn the sum of the vector inputs of many clients. Bonawitz
et al. (CCS 2017) presented a construction that incurs computation
and communication for each client linear in the number of parties.
While this functionality enables a broad range of privacy preserving
computational tasks, scaling concerns limit its scope of use.
We present the first constructions for secure aggregation that
achieve polylogarithmic communication and computation per client.
Our constructions provide security in the semi-honest and the semi-
malicious settings where the adversary controls the server and a
γ-fraction of the clients, and correctness with up to δ-fraction
dropouts among the clients. Our constructions show how to re-
place the complete communication graph of Bonawitz et al., which
entails the linear overheads, with a k-regular graph of logarithmic
degree while maintaining the security guarantees.
Beyond improving the known asymptotics for secure aggrega-
tion, our constructions also achieve very efficient concrete param-
eters. The semi-honest secure aggregation can handle a billion
clients at the per-client cost of the protocol of Bonawitz et al. for
a thousand clients. In the semi-malicious setting with 104 clients,
each client needs to communicate only with 3% of the clients to
have a guarantee that its input has been added together with the
inputs of at least 5000 other clients, while withstanding up to 5%
corrupt clients and 5% dropouts.
We also show an application of secure aggregation to the task of
secure shuffling which enables the first cryptographically secure
instantiation of the shuffle model of differential privacy.
CCS CONCEPTS
• Security and privacy → Cryptography; Distributed systems
security; Privacy-preserving protocols.
KEYWORDS
multi-party computation; secure aggregation; secure shuffling;
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’20, November 9–13, 2020, Virtual Event, USA
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-7089-9/20/11...$15.00
https://doi.org/10.1145/3372297.3417885
ACM Reference Format: James Henry Bell, Kallista A. Bonawitz, Adrià
Gascón, Tancrède Lepoint, and Mariana Raykova. 2020. Secure Single-
Server Aggregation with (Poly)Logarithmic Overhead In Proceedings of the
2020 ACM SIGSAC Conference on Computer and Communications Security
(CCS’20), November 9–13, 2020, Virtual Event, ACM, New York, NY, USA,
17 pages.
1 INTRODUCTION
Once considered a purely theoretical tool, cryptographic secure
multiparty computation has become a tool that underlies several
technological solutions [1, 7, 8, 12, 23, 27, 29]. In this context, con-
structions for two parties (or a small number of parties) still have
dominant presence. One reason for this is the increased complexity
that many party solutions bring, which could be a challenge for
adoption among a large number of participants. Another reason
is the fact that many multiparty solutions require communication
channels between all participants, which is not always viable. Fur-
ther, real scenarios with many parties need to account for the fact
that a fraction of the parties may drop out during the execution.
All of these concerns apply to the setting where a service provider
collects aggregate statistics from a large population in a privacy pre-
serving way. This includes basic statistical tasks such as computing
mean, variance, and histograms, as well as large scale distributed
training of machine learning models as in federated learning [7, 25].
In such settings there is a powerful central server and a large num-
ber of clients with constrained resources, a single communication
channel only to the server, and intermittent network connectivity
that results in a significant probability of dropping out during the
protocol execution, a common problem in production systems [7].
While there have been both theoretical and applied works propos-
ing secure computation solutions for settings with restricted com-
munication [10, 14, 22, 26, 30, 33], Bonawitz et al. [8] introduced
the first practical secure computation construction whose imple-
mentation scaled to a thousand clients, a larger number of parties
than any existing system. That work presents a secure aggregation
protocol that enables a central server to learn the summation of
the input vectors of many clients securely, i.e. without obtaining
any information beyond the sum. The protocol is also robust in
the presence of a fraction of clients dropping out. That paper and
subsequent work [7] showed that secure vector summation en-
ables powerful privacy-preserving functionalities such as federated
learning [25].
In this work we focus on two aspects of secure vector aggrega-
tion. First, we construct two new protocols with semi-honest and
malicious security, which provide better efficiency both in terms of
asymptotics as well as concrete costs. Second, we present a new ap-
plication of secure aggregation for construction of secure shuffling
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA1253protocols. This enables anonymous data collection in the single-
server setting, and in particular provides the first cryptographically
secure instantiation of the shuffle model of differential privacy [6].
Efficiency of Secure Aggregation. While the existing secure ag-
gregation construction of Bonawitz et al. [8] is sufficiently efficient
to run in production systems [7], scaling concerns limit its scope of
use. Its limitations stem from the computation and communication
complexity of the protocol. For adding n length l vectors (one pro-
vided by each client) their protocol requires O(n
2 +ln) computation
and O(n + l) communication per device, and O(ln
2) computation
and O(n
2 +ln) communication for the server. This introduces linear
overhead over the computation in the clear where every client sends
a vector and the server adds up all n vectors. Although recently a
variant with polylog overhead has been proposed [34], it requires
n/log n rounds (as opposed to four for Bonawitz et al.) and, contrary
to Bonawitz et al.’s approach, relies on revealing a partial sum of
log n input values to a coalition of the server and a client.
Reducing client compute time is significant: the more compute
time is required at each device, the more likely that device is to drop
out. This not only results in wasted computation, but also induces
bias as powerful devices with fast connection will be overrepre-
sented in the collected statistics. In practice, these costs limit the
use of secure aggregation to settings of no more than approximately
a thousand devices for large values of l, e.g., larger than 106. This
prevents computing large histograms or training neural networks
that require large client batches to achieve good quality [31].
Looking beyond concrete efficiency, current theoretical construc-
tions do not provide constant round solutions with sublinear com-
munication (in the number of clients) per client. This is the case
even in the semi-honest setting when we need to account for the
key distribution phase as well as support dropouts [33]. Note that
there exist relevant solutions based on homomorphic encryption
(HE) [17, 18, 32], where the server computes the sum of encrypted
inputs under a key shared among the clients. However, the gen-
eration of shared HE parameters among all parties with sublinear
communication and in a way that is robust to dropouts remains a
challenge. Boyle et al. [9] present efficient large-scale secure com-
putation but do use a broadcast channel per party.
Amplification by Shuffling. Differential privacy (DP) [13] has
become the de facto notion of individual privacy in data analysis.
Until recently there have been two main threat models for DP: the
central model, where a curator is trusted with all private inputs
and the task of outputting privatized aggregates, and the local DP
setting where individuals release DP versions of their data. While
the second model has minimal trust assumptions it also comes with
significant limitations in terms of accuracy.
The recently introduced shuffle model of DP [6, 11] assumes
only a trusted shuffler (a party that applies a random permutation
to input data before publishing it) rather than a trusted curator
computing arbitrary functionalities. The shuffle model matches
exactly the setting of a single powerful server and a large number
of devices in a star network. Several recent works [2, 3, 15, 16, 19]
have shown that this model offers a fruitful middle ground (in the
terms of tradeoffs between trust distribution and accuracy) between
the local and curator models. Implementing efficient shufflers in
practice has either required reliance on trusted computing hardware
or onion-routing/mixnet constructions, which require strong non-
collusion assumptions and significantly increased communication.
While we can implement the shuffling step with general multiparty
computation to achieve local DP privacy, any practical deployment
would require an efficient shuffling construction.
1.1 Our contributions
Our paper has three main contributions: two new constructions for
secure aggregation which provide security in the semi-honest and
semi-malicious setting, and a new construction for secure shuffling
based on secure aggregation.
For our constructions we consider an aggregation server and n
clients with input vectors of length l. The goal of the protocol is
to provide the server with a summation of the inputs of all clients
that complete the protocol execution. We require that correctness
holds with all but 2−η probability, where η > 0 is the correctness
parameter. The protocols are secure in the presence of an adver-
sary controlling the server and up to an arbitrary γ-fraction of the
clients that are corrupted independently of the protocol execution.
In other words, client corruptions happen before the protocol exe-
cution starts. Note that the only assumption is that the adversary
does not have the ability to compromise new devices adaptively as
the protocol progresses. Our protocols are robust to an arbitrary
δ-fraction of clients dropping out during the protocol execution.
Moreover, a number of dropouts that exceeds that threshold can
only lead to an aborted execution, and does not affect the security
of the protocol. Let us remark that the set of clients that dropout
during the protocol execution are considered public knowledge,
i.e. we do not aim to provide full anonymity to the set of dropout
users. Our constructions achieve information theoretic security
with a security parameter σ, except for the use of a key agreement
protocol for randomness generation, and encryption and signature
for secure communication.
Semi-honest Construction. The construction of Bonawitz et al. [8]
uses the server as a relay that forwards encrypted and authenti-
cated messages between clients. Their solution requires that every
pair of clients are able to communicate. Intuitively, the complete
communication graph serves both security and dropout robustness.
Roughly speaking, every client (a) negotiates shared randomness
with every other client to mask their submitted value, and (b) shares
(with threshold t) their random seeds with every other client. While
(a) ensures security, (b) guarantees that the protocol can recover
from dropouts without compromising security as long as t is set
appropriately.
The main insight to our efficiency improvement is that a com-
plete graph is not necessary: it is enough to consider a k-regular
communication graph, i.e., each client speaks to k < n − 1 other
clients, where k = O(log n). We obtain this result by using a ran-
domized communication graph construction, and then leveraging
its properties with respect to the distributions of corrupt clients
and dropouts.
n +l log n) compu-
tation and O(log n + l) communication per client, and O(n log2
n +
nl log n) computation and O(n log n + nl) communication for the
server. It requires three rounds of interactions between the server
and clients. We characterize the properties of the communication
Our semi-honest construction requires O(log2
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA1254graph that suffice for the security and correctness of the resulting
protocol, and present a graph generation construction with con-
crete parameters. For example, with σ = 40 and η = 30, we need
only k = 150 neighbors per client in order to run the protocol with
n = 108 clients and provide security for up to γ = 1/5 corrupt nodes
and δ = 1/20 dropouts. In fact, we can run our protocol with a
billion clients, while incurring roughly the same costs per client as
the protocol of Bonawitz et al. [8] when run on a thousand clients
(see Section 5 for more details).
Semi-malicious Construction. Our semi-malicious setting assumes
that the server behaves honestly in the first step of the protocol
when it commits to the public keys of all clients. After this point, it
can deviate arbitrarily from the protocol (as in the usual malicious
security notion) and our construction provides security. This is
analogous to the assumption in [8], and weaker than assuming a
public key infrastructure for key distribution.
The security definition for the malicious case is a bit more in-
volved, and is discussed in detail in Section 4. Roughly speaking,
this is due to the fact that a malicious server can disrupt communica-
tion between parties at any round, and thus can simulate dropouts
inconsistently across clients. As it is impossible for clients to dis-
tinguish real from simulated dropouts, a malicious server cannot