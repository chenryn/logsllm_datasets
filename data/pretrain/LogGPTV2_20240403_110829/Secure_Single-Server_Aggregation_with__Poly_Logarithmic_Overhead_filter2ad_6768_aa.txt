# Title: Secure Single-Server Aggregation with (Poly)Logarithmic Overhead

## Authors
- James Henry Bell, The Alan Turing Institute, London, UK
- Kallista A. Bonawitz, Google, New York, US
- Adrià Gascón, Google, London, UK
- Tancrède Lepoint, Google, New York, US
- Mariana Raykova, Google, New York, US

## Abstract
Secure aggregation is a cryptographic primitive that allows a server to compute the sum of vector inputs from multiple clients while preserving privacy. Bonawitz et al. (CCS 2017) introduced a construction with linear computation and communication overhead per client. While this functionality enables a wide range of privacy-preserving tasks, its scalability is limited.

In this work, we present the first constructions for secure aggregation that achieve polylogarithmic communication and computation per client. Our constructions provide security in both semi-honest and semi-malicious settings, where the adversary controls the server and a γ-fraction of the clients, and ensure correctness even with up to a δ-fraction of client dropouts. We replace the complete communication graph of Bonawitz et al. with a k-regular graph of logarithmic degree, maintaining the same security guarantees.

Our constructions not only improve the asymptotic performance of secure aggregation but also achieve efficient concrete parameters. For instance, in the semi-honest setting, our protocol can handle a billion clients with the same per-client cost as Bonawitz et al.'s protocol for a thousand clients. In the semi-malicious setting with 104 clients, each client needs to communicate with only 3% of the other clients to ensure that their input is aggregated with at least 5000 others, while tolerating up to 5% corrupt clients and 5% dropouts.

We also demonstrate an application of secure aggregation to secure shuffling, enabling the first cryptographically secure instantiation of the shuffle model of differential privacy.

## CCS Concepts
- **Security and Privacy**: Cryptography, Distributed Systems Security, Privacy-Preserving Protocols

## Keywords
- Multi-party Computation
- Secure Aggregation
- Secure Shuffling

## Introduction
Cryptographic secure multiparty computation (MPC) has evolved from a theoretical concept to a practical tool underpinning various technological solutions [1, 7, 8, 12, 23, 27, 29]. However, MPC constructions for a large number of parties are complex and often require full communication between all participants, which is not always feasible. Additionally, real-world scenarios must account for potential dropouts during execution.

This is particularly relevant in settings where a service provider collects aggregate statistics from a large population in a privacy-preserving manner, such as computing mean, variance, and histograms, or training machine learning models in federated learning [7, 25]. These settings involve a powerful central server and many resource-constrained clients, with a single communication channel to the server and intermittent network connectivity.

Bonawitz et al. [8] introduced a practical secure aggregation protocol that scales to a thousand clients, enabling a central server to securely learn the summation of input vectors from many clients. This protocol is robust to a fraction of clients dropping out and has been shown to enable powerful privacy-preserving functionalities like federated learning [25].

### Contributions
Our paper makes three main contributions:
1. **New Constructions for Secure Aggregation**: We introduce two new protocols with semi-honest and semi-malicious security, providing better efficiency in terms of both asymptotics and concrete costs.
2. **Application to Secure Shuffling**: We present a new application of secure aggregation for constructing secure shuffling protocols, enabling anonymous data collection in the single-server setting and providing the first cryptographically secure instantiation of the shuffle model of differential privacy [6].

#### Efficiency of Secure Aggregation
The existing secure aggregation construction by Bonawitz et al. [8] is efficient enough for production use but has scalability limitations due to its linear overhead. Their protocol requires \(O(n^2 + ln)\) computation and \(O(n + l)\) communication per device, and \(O(ln^2)\) computation and \(O(n^2 + ln)\) communication for the server. This introduces a linear overhead compared to the clear computation where every client sends a vector and the server sums them up.

Reducing client compute time is crucial because devices with high computational requirements are more likely to drop out, leading to wasted computation and biased results. In practice, these costs limit the use of secure aggregation to settings with no more than approximately a thousand devices for large values of \(l\), e.g., larger than \(10^6\). This hinders the computation of large histograms or the training of neural networks that require large client batches for good quality [31].

Current theoretical constructions do not provide constant-round solutions with sublinear communication per client, even in the semi-honest setting when accounting for key distribution and dropouts [33]. Homomorphic encryption (HE) [17, 18, 32] can be used, but generating shared HE parameters among all parties with sublinear communication and robustness to dropouts remains challenging. Boyle et al. [9] present efficient large-scale secure computation but require a broadcast channel per party.

#### Amplification by Shuffling
Differential privacy (DP) [13] is the de facto standard for individual privacy in data analysis. The recently introduced shuffle model of DP [6, 11] assumes only a trusted shuffler (a party that applies a random permutation to input data before publishing it) rather than a trusted curator. This model offers a middle ground between the local and central models, balancing trust and accuracy. Implementing efficient shufflers in practice has required trusted hardware or onion-routing/mixnet constructions, which have strong non-collusion assumptions and increased communication. Our secure shuffling construction based on secure aggregation provides a practical solution.

### Semi-Honest Construction
The construction by Bonawitz et al. [8] uses the server as a relay that forwards encrypted and authenticated messages between clients, requiring a complete communication graph. Each client negotiates shared randomness with every other client and shares their random seeds with a threshold \(t\). This ensures security and dropout robustness.

Our insight is that a complete graph is not necessary; a k-regular communication graph, where each client communicates with \(k < n - 1\) other clients, is sufficient. We achieve this using a randomized communication graph construction and leveraging its properties regarding the distributions of corrupt clients and dropouts.

Our semi-honest construction requires \(O(\log^2 n + l \log n)\) computation and \(O(\log n + l)\) communication per client, and \(O(n \log^2 n + nl \log n)\) computation and \(O(n \log n + nl)\) communication for the server. It requires three rounds of interactions between the server and clients. For example, with \(\sigma = 40\) and \(\eta = 30\), we need only \(k = 150\) neighbors per client to run the protocol with \(n = 10^8\) clients, providing security for up to \(\gamma = 1/5\) corrupt nodes and \(\delta = 1/20\) dropouts.

### Semi-Malicious Construction
In the semi-malicious setting, we assume the server behaves honestly in the first step of the protocol when it commits to the public keys of all clients. After this, the server can deviate arbitrarily, and our construction provides security. This is analogous to the assumption in [8], weaker than assuming a public key infrastructure for key distribution.

The security definition for the malicious case is more complex and is discussed in detail in Section 4. A malicious server can disrupt communication between parties at any round, simulating dropouts inconsistently across clients. Clients cannot distinguish real from simulated dropouts, so a malicious server cannot compromise the security of the protocol.

For more details, see Section 5.

## Conclusion
Our work presents the first constructions for secure aggregation with polylogarithmic overhead, achieving both theoretical and practical improvements. We also introduce a new application to secure shuffling, enabling the first cryptographically secure instantiation of the shuffle model of differential privacy.