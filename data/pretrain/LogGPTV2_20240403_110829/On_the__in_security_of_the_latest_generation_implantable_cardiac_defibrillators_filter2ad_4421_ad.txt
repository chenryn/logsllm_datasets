be disjoint to the time domain. Each IMD id ∈ ID stores a
diversiﬁed key H2(id)msk which is provided at manufacture
time (all the operations here are done modulo q). Device
programmers receive a temporal key H1(t)msk which is valid
to derive all IMD’s diversiﬁed keys but only for the time pe-
riod t. This period of time can be anything, but for the sake
of example let us take this time period to be three months.
In that case, every three months, the device programmer (or
a health-care employee) needs to contact the device manu-
facturer to obtain the key for the next quarter H1(t + 1)msk
which is sent over a secure channel.
In this way, if a de-
vice programmer is lost, stolen or tampered with, this can
be reported to the device manufacturer and then this de-
vice will no longer receive key updates, rendering it useless.
Any key material which may have been extracted from the
device becomes obsolete after (at most) three months and
then the system goes back to a secure state. Fig 9 describes
our semi-oﬄine key agreement protocol in detail.
This protocol requires one bilinear pairing computation
on the IMD which is expensive, but this only needs to hap-
pen once every three months. On a daily basis, IMD and
device programmer simply run a standard symmetric key
authentication protocol like the one proposed by Halperin
et al., using the agreed key e(H1(t), H2(id))msk. Note that
this protocol does not provide key conﬁrmation, but this
can be easily achieved by the symmetric key authentication
protocol as it is the case in Halperin et al.
5.2.3 Formal analysis of our protocol
To provide some level of assurance for our protocol we
model and analyse it using the applied pi-calculus [5] and
the checking tool ProVerif [6]. The applied pi-calculus al-
lows us to model protocols, using primitives such as input,
output, new name generation and parallel composition. It
also allows us to deﬁne functions and equations that can
be used to model a range of cryptographic primitives. The
ProVerif tool can ensure secrecy and correspondence prop-
erties for an arbitrary number of runs of a protocol using a
automated theorem proving method, however the tool is not
guaranteed to terminate and may report false attacks.
We model an idealised version of bilinear pairings using
functions and equations in the applied pi-calculus, i.e., we
deﬁne the functions power(x, y), prod(x, y) and e(x, y) to
represent xy, xy and the bilinear map e(x, y). We would
then like to deﬁne the equation:
equation e(power(a, x),power(b, y)) =
power(e(a, b),prod(x, y))
However, such an equation causes ProVerif’s proof tactics
to enter any inﬁnite loop. Therefore, we introduce an aux-
iliary function to represent the right hand side of this equa-
tion, i.e., we deﬁne powere(a, b,prod(x, y)) to represent
e(a, b)xy. We note that this gives an abstract model of bi-
linear pairings that does not include any number theoretic
attacks, such as factoring the product, inverse powers, or
low entropy secrets.
Our model is made up of four processes: Programmer,
which models the programmer protocol role, IMD which
models the IMD, CompromisedReader, which publicly
broadcasts a programmers diversiﬁed key for a time period
diﬀerent to the one used by Programmer, and Compro-
misedUnAuthIMD which models a compromised IMD by
publicly broadcasting the diversiﬁed key for a medical device
that is not one accepted by the programmer.
At the end of their run the Programmer and IMD pro-
cesses broadcast a secret value encrypted with the key they
have established. We test the system to see if it is possible
for an attacker to learn this secret, which would mean they
had successfully established a key with the IMD or Program-
mer. The full model is given in Appendix A.
233
Device Programmer
IMD
Stores: H1(t)msk
Stores: H2(id)msk, H2(id), id
id
check id ∈ ID
t = current time period
e(H1(t)msk, H2(id)) = e(H1(t), H2(id))msk
e(H1(t), H2(id)msk) = e(H1(t), H2(id))msk
Figure 9: A semi-oﬄine key agreement protocol for IMDs.
Testing this model in ProVerif we ﬁnd that it does in-
deed keep the keys secret. This means that only an IMD
with an ID accepted by the programmer, and a programmer
with a diversiﬁed key for the right time period, can set up
and learn keys, even if there are an arbitrary number of old
compromised programmers and IMDs.
To check for redundancy in our protocol, and to see what
kinds of attacks ProVerif can ﬁnd, we experiment with possi-
ble simpliﬁcations. We ﬁrst try removing the IMD identity
check in the programmer (the “if imdID=id then” line
of the model), in this case ProVerif ﬁnds an attack in which
the attacker uses a diversiﬁed key from an old, compromised
IMD. If we also remove the CompromisedUnAuthIMD
process, we ﬁnd that the protocol is then safe. This tells us
that this identity check by the programmer is only needed
to stop attacks using compromised IMDs, if we decided to
discount compromised IMDs in our attacker model we would
not need this check.
As a second test, we tried using a single hash function,
rather than two. In this case, ProVerif ﬁnds an attack that
lets an attacker impersonate an IMD: The attacker sends
the old time stamp from a compromised programmer (t′) in
place of the id to the targeted programmer. This leads to
the key programmer using the key e(H(t)msk, H(t′)), however
from the compromised programmer the attacker can learn
H(t′)msk and so construct the matching key e(H(t), H(t′)msk).
This suggests that our protocols use of two hash functions
is a sensible precaution to avoid attacks based on confusing
times and identities. These additional checks gived us in-
crease conﬁdence that the analysis method we use can ﬁnd
attacks, when present, and that our protocol is not unnec-
essarily complex.
5.2.4 Differentiating between device programmers
and base stations
There is an important distinction to make between device
programmers and base stations as the former are in a much
more controlled environment than the latter. Device pro-
grammers are not sold to anyone: they are available only to
accredited health-care professionals and institutions whereas
base stations are much more available at the patients home.
Some base stations are sometimes available to purchase on
auction sites such as Ebay and is relatively easy to get hold of
one. But their usage is also very diﬀerent. Base stations only
need read access to the IMD in order to forward telemetry
information to the relevant health-care practitioner. There-
fore, it makes sense to have diﬀerent keys for each of these
devices which provide diﬀerent access levels. In this way, if
the key of a base station gets compromised for a period of
time, this still represents a potential privacy violation but
at least it is not life threatening.
6. CONCLUSIONS
In this work we have analysed the security and privacy
properties of the latest generation of ICDs. For this we
fully reverse-engineered the proprietary protocol between
the ICD and the device programmer using commercial and
inexpensive equipment. We want to emphasise that reverse-
engineering was possible by only using a black-box approach.
Our results demonstrated that security-by-obscurity is a dan-
gerous design approach that often conceals negligent designs.
Therefore, it is important for the medical industry to mi-
grate from weak proprietary solutions to well-scrutinised se-
curity solutions and use them according to the guidelines.
Our work revealed serious protocol and implementation
weaknesses on widely used ICDs, which lead to several ac-
tive and passive software radio-based attacks that we were
able to perform in our laboratory. Our ﬁrst attack consisted
on keeping the ICD alive while the ICD is in “standby” mode
by repeatedly sending a message over the long-range com-
munication channel. The goal of this attack was to drain
the ICD’s battery life, or to enlarge this time window to
send the necessary malicious messages to compromise the
patient’s safety. Our second attack aimed at compromising
the patient’s privacy. For this we leveraged the fact that we
were able to recover the LFSR sequence used to “obfuscate”
the messages. We discovered that this LFSR sequence is
constant throughout sessions and is the same for all ICDs
we studied.
We proposed short-term and long-term countermeasures.
As a short-term countermeasure, the only solution is to use
jamming as a defensive mechanism. As long-term counter-
measures, external devices could send a “shutdown” message
to the ICD so that the ICD can immediately switch to“sleep”
mode after the communication ends. Moreover, we designed
and formally veriﬁed a semi-oﬄine key agreement protocol
between the device programmer and the ICD.
234
[14] P. Koopman and T. Chakravarty. Cyclic redundancy
code (crc) polynomial selection for embedded
networks. In Dependable Systems and Networks, 2004
International Conference on, pages 145–154, June
2004.
[15] E. Marin, E. Argones R´ua, D. Singel´ee, and
B. Preneel. A survey on physiological-signal-based
security for medical devices. Cryptology ePrint
Archive, Report 2016/188, 2016.
http://eprint.iacr.org/.
[16] E. Marin, D. Singel´ee, B. Yang, I. Verbauwhede, and
B. Preneel. On the feasibility of cryptography for a
wireless insulin pump system. In Proceedings of the
Sixth ACM Conference on Data and Application
Security and Privacy, CODASPY ’16, pages 113–120,
New York, NY, USA, 2016. ACM.
[17] J. Proakis and M. Salehi. Digital Communications.
McGraw-Hill higher education. McGraw-Hill
Education, 2007.
[18] K. B. Rasmussen, C. Castelluccia, T. S.
Heydt-Benjamin, and S. Capkun. Proximity-based
access control for implantable medical devices. In
Proceedings of the 16th ACM Conference on Computer
and Communications Security, CCS ’09, pages
410–419, New York, NY, USA, 2009. ACM.
[19] M. Rostami, W. Burleson, F. Koushanfar, and
A. Juels. Balancing security and utility in medical
devices? In The 50th Annual Design Automation
Conference 2013, DAC ’13, Austin, TX, USA, May 29
- June 07, 2013, pages 13:1–13:6, 2013.
[20] M. Rostami, A. Juels, and F. Koushanfar.
Heart-to-heart (H2H): authentication for implanted
medical devices. In 2013 ACM SIGSAC Conference on
Computer and Communications Security, CCS’13,
Berlin, Germany, November 4-8, 2013 [20], pages
1099–1112.
[21] N. O. Tippenhauer, L. Malisa, A. Ranganathan, and
S. Capkun. On limitations of friendly jamming for
conﬁdentiality. In Security and Privacy (SP), 2013
IEEE Symposium on, pages 160–173, May 2013.
[22] F. Xu, Z. Qin, C. C. Tan, B. Wang, and Q. Li.
Imdguard: Securing implantable medical devices with
the external wearable guardian. In INFOCOM 2011.
30th IEEE International Conference on Computer
Communications, Joint Conference of the IEEE
Computer and Communications Societies, 10-15 April
2011, Shanghai, China, pages 1862–1870, 2011.
In accordance with the principle of responsible disclosure,
we have notiﬁed and discussed our ﬁndings with the manu-
facturer before publishing this article.
7. ACKNOWLEDGEMENTS
The authors would like to thank Stefaan Foulon for his
support and the anonymous reviewers for their helpful com-
ments. This work was supported in part by the Research
Council KU Leuven: C16/15/058 and the Cryptacus COST
Action IC1403.
8. REFERENCES
[1] DAQ NI USB-6351. http://www.ni.com.
[2] Federal Communications Commission (FCC) ID.
http://www.fcc.gov/encyclopedia/fcc-search-tools.
[3] LabVIEW. http://www.ni.com/labview.
[4] NI USRP-2920. http://www.ni.com.
[5] M. Abadi and C. Fournet. Mobile values, new names,
and secure communication. In Symposium on
Principles of Programming Languages (POPL), 2001.
[6] B. Blanchet, B. Smyth, and V. Cheval. ProVerif 1.88:
Automatic cryptographic protocol veriﬁer, user
manual and tutorial, 2013.
[7] L. Chunxiao, A. Raghunathan, and N. Jha. Hijacking
an insulin pump: Security attacks and defenses for a
diabetes therapy system. In e-Health Networking
Applications and Services, 13th IEEE International
Conference on, pages 150–156, Jun 2011.
[8] F. D. Garcia, G. Koning Gans, R. Muijrers,
P. Rossum, R. Verdult, R. W. Schreur, and B. Jacobs.
Dismantling mifare classic. In Proceedings of the 13th
European Symposium on Research in Computer
Security: Computer Security, ESORICS ’08, pages
97–114, Berlin, Heidelberg, 2008. Springer-Verlag.
[9] F. D. Garcia, D. Oswald, T. Kasper, and P. Pavlid`es.
Lock it and still lose it —on the (in)security of
automotive remote keyless entry systems. In 25th
USENIX Security Symposium (USENIX Security 16),
Austin, TX, Aug. 2016. USENIX Association.
[10] S. Gollakota, H. Hassanieh, B. Ransford, D. Katabi,
and K. Fu. They Can Hear Your Heartbeats:
Non-invasive Security for Implantable Medical
Devices. SIGCOMM Comput. Commun. Rev.,
41(4):2–13, Aug. 2011.
[11] T. Halevi and N. Saxena. On pairing constrained
wireless devices based on secrecy of auxiliary channels:
the case of acoustic eavesdropping. In Proceedings of
the 17th ACM Conference on Computer and
Communications Security, CCS 2010, Chicago,
Illinois, USA, October 4-8, 2010, pages 97–108, 2010.
[12] D. Halperin, T. S. Heydt-Benjamin, B. Ransford, S. S.
Clark, B. Defend, W. Morgan, K. Fu, T. Kohno, and
W. H. Maisel. Pacemakers and implantable cardiac
deﬁbrillators: Software radio attacks and zero-power
defenses. In Proceedings of the 29th Annual IEEE
Symposium on Security and Privacy, pages 129–142,
May 2008.
[13] X. Hei, X. Du, J. Wu, and F. Hu. Defending resource
depletion attacks on implantable medical devices. In
Global Telecommunications Conference (GLOBECOM
2010), 2010 IEEE, pages 1–5, Dec 2010.
235
APPENDIX
A. A FORMAL MODEL OF OUR PROPOSED
PROTOCOL FROM SECTION 5.2.2
(* Secure IMD protocol *)
free c.
(* bilinear pairings *)
fun power/2.
fun powere/3. (* powere(a,b,x) = e(a,b)^x *)
fun prod/2.
fun e/2.
(* prod(a,b) = a x b *)
(* e (a^x,b^y) = e(a,b)^(xy)*)
(* power(x,y) = x^y *)
equation e(power(a,x),power(b,y)) = powere(a,b,prod(x,y)).
equation prod(x,y) = prod(y,x).
data one/0.
(* hashes *)
fun H1/1.
fun H2/1.
(* Shared key cryptography *)
fun senc/2.
reduc sdec(y, senc(y,x)) = x.
private free sec.
private free msk.
(*
Test if the attacker can learn secret
encrypted with the established key
*)
query attacker:sec.
let Programmer = in (c,imdID);
if imdID=id then
let rkey = e(rsec,power(H2(imdID),one)) in
in(c,message);
out(c,senc(rkey,sec)).
let IMD = let imdkey = e(power(H1(t),one),psec) in
out(c,id);
out (c,senc(imdkey,sec)).
let CompromisedReader = new t’; out(c,t’);
out(c,power(H1(t’),msk)).
let CompromisedUnAuthIMD = new id’; out (c,id’);
out(c,power(H2(id’),msk)).
process new msk;
!new t; out(c,t);
!new id; out(c,id);
let psec = power(H2(id),msk) in !IMD
(
| let rsec = power(H1(t),msk) in !Programmer
| !CompromisedReader | !CompromisedUnAuthIMD )
236