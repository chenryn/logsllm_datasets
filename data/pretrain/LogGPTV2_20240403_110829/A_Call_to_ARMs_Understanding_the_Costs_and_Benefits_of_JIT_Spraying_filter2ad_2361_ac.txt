zero loopback
branch vpc (× 16)
movs r7, #35
adds r6, r7
subs r6, #162
adds r6, r7
subs r6, #217
mov pc, r6
function sprayMe(r0, R10, FP, r8, R7, R5) {
// Statements to define additional variables and
// populate their values into registers go here
if (R10 == 0) {
R10 = R1 & 9437184;
} else if (R10 == 1) {
// and r10, r1, #9437184
R3 = R1 & 262144;
// and r3, r1, #262144
} else if (R10 == 2) {
...
}
// Return statement using all variables goes here
}
Listing 2: The structure of the JavaScript function sprayed to
produce the self-sustaining SBNZ OISC payload.
bitwise AND; for example, bitwise XOR and OR would result
in branch blocks that are 64 and 768 bytes longer, respectively.
Using the virtual PC method, we implemented the inter-
preter loop for an SBNZ OISC abstract machine. We designate
a general-purpose register as the OISC PC and use unintended
instructions to perform the subtraction and update the OISC
PC according to its outcome. Our implementation expects the
ﬁrst instruction, composed of four consecutive 32-bit addresses
corresponding to the four instruction operands, to reside at the
top of the stack when it begins executing. The instructions
used to build the interpreter are shown in Table I. Note that
instructions 1 and 2 within each branch block are 40 bytes
apart, whereas all other inter-instruction spacing within branch
blocks is 36 bytes. When tracing control ﬂow through the
table, remember that instructions sharing a common number
in the ﬁrst column will be executed consecutively with one
another with the exception of instruction 11 in the ﬁrst branch
block (cbz), which may branch to the zero label. This proof
of concept demonstrates the feasibility of performing Turing-
complete computation with unintended Thumb-2 instructions
decoded from intended ARM instruction bytes that are exe-
cuted as a self-sustaining payload.
2) Encoding a NOP sled:
It is possible to construct a
NOP sled by placing n + k branch blocks prior to the branch
blocks containing shellcode. The unintended instruction pairs
6
Fig. 5: Illustration of using a virtual PC (in this case R6) to
more efﬁciently utilize the space skipped over by branches.
The second Thumb-2 instruction must be an unconditional
PC-relative forward branch of at least 512 halfwords. The Rn
ﬁeld forms the least-signiﬁcant 4 bits of the branch distance
in units of halfwords. The self-sustaining payload works by
chaining together pairs of unintended 16-bit Thumb-2 instruc-
tions with these unconditional branches. The ﬁrst Thumb-2
instruction performs useful work for the adversary; the second
branches to the ﬁrst Thumb-2 instruction in a subsequent pair.
For this branch to target the ﬁrst instruction in a pair, the
branch offset must be an odd number of halfwords, so Rn must
be an odd-numbered register. The value of the PC in Thumb
mode is the address of the current instruction plus 4 (i.e., 2
halfwords). Consequently, the closest we can place the next
pair of unintended Thumb-2 instructions is (512+1+2)×2 =
1030 bytes after the start of the unintended branch instruction.
Na¨ıvely chaining 1030-byte forward branches would
require an exorbitant amount of memory to encode even a
simple payload. To reduce the space requirements of our
self-sustaining payload, we designate a general purpose
register as a virtual PC which we use to loop execution
back into the branched-over space, where another unintended
instruction pair has been placed. We deﬁne a branch block
as the largest block of unintended instruction pairs whose
ﬁrst unintended instruction pair skips over all subsequent
unintended instructions pairs in that branch block. Figure 5
shows the virtual PC method with 3 branch blocks under
simpliﬁed conditions. Note how execution ﬂows through each
unintended instruction pair in each branch block (with the
exception of branch block 3, which only executes the ﬁrst
unintended instruction in the pair), then through the second
instruction pair in each branch block, etc. In our proof of
concept payload, 12-bit
immediate encoding rules require
us to populate a register with the virtual PC advancement
amount and perform register-register addition rather
than
register-immediate addition. Furthermore, in order to prevent
dead store elimination, the JavaScript statements that produce
unintended instruction pairs reside in separate mutually-
exclusive conditional blocks, resulting in a larger virtual
PC advancement amount of 36 bytes (Listing 2). Note that
although Figure 5 shows only three branch blocks, longer
payloads can be encoded by inserting branch blocks before
the “vpc update” block. Another option is to increase the size
of branch blocks by using an intended instruction other than
add r6, #0b loopback_0vpc_update_0:add r6, #4b loopback_1add r6, #4b loopback_2mov pc, r6loopback_0:mov pc, r6loopback_1:mov pc, r6loopback_2:vpc_update_1:vpc_update_2:pair_0:pair_1:mov r6, pcb vpc_update_0shellcode_insn_1b vpc_update_1shellcode_insn_2b vpc_update_2pair_2:}BranchBlock 1}BranchBlock 2}BranchBlock 3in the initial n branch blocks exist only to direct control
ﬂow forward to the ﬁnal k branch blocks. The unintended
instructions in the ﬁnal k branch blocks of the NOP sled use
their statically-predetermined offset within the branch blocks
to construct a branch to the ﬁrst unintended instruction in the
ﬁrst shellcode branch block. For example, the ﬁrst unintended
instruction in the ﬁnal NOP sled branch block must effect a
large forward branch to skip the entire branch block, but the
last unintended instruction in the same branch block need only
skip any remaining tail in its own branch block and whatever
short head exists at the beginning of the next branch block.
that
The success rate of correctly landing in the NOP sled
depends on how densely unintended instruction pairs can
be packed in the ﬁnal k branch blocks. The only way to
both achieve a high density of unintended instruction pairs
and avoid dead store elimination is to use the the desti-
nation register of the intended AND instruction as one of
the input operands. For example, and r1, r1, #10; and
r1, r1, #10 is okay, but and r4, r1, #10; and
r4, r1, #10 is not because the ﬁrst instruction can—and
will—be eliminated. Recall
the register must also be
odd-numbered in order for the unintended branch instruction
in each pair to correctly target
the beginning of the next
unintended instruction pair. We were unable to devise a NOP
sled whose unintended instructions are derived from only
intended instructions operating on odd-numbered registers.
We must therefore sacriﬁce density in the same manner as
described in §III-C1 and place unintended instruction pairs in
the NOP sled 36 bytes (9 ARM instructions) apart. The success
rate of correctly landing in such a NOP sled is therefore 1/9.
3) Executing the payload: Static code for the ARM archi-
tecture is compiled with the expectation that callees and callers
might need to be executed in a different instruction set mode;
therefore, interworking branches abound. An attacker will most
likely only need to ensure that the control ﬂow vulnerability
she exploits targets an address whose least signiﬁcant bit is set,
which will cause her payload to be executed in Thumb mode.
4) Limitations: A major limitation of the payload encoding
method described in this section is that we are unable to encode
an unintended system call instruction. In order to do so, we
would need to be able to control an intended instruction whose
destination register (or source register in the case of a store
instruction) is the stack pointer; we are not aware of such a
capability against IonMonkey. However, the Turing-complete
computation that this type of payload is able to construct can
be used to orchestrate a code reuse attack against static code
which contains system call instructions.
Our proof of concept SBNZ OISC implementation requires
the operands to the sbnz instruction to contain absolute
addresses. This requires the attacker either to learn where her
SBNZ instructions will reside via an information leak or to
heap spray them. Unfortunately, heap spraying SNBZ instruc-
tions competes with JIT spraying. A more practical SBNZ
OISC implementation might use stack pointer offsets rather
than absolute addresses for sbnz operands. The attacker could
even devise an SBNZ NOP sled to place on the stack before
her SBNZ shellcode to mitigate an unpredictable stack layout.
As we mentioned above, the set of unintended Thumb-2
instructions that we were able to encode was constrained by the
set of registers that could be chosen as the destination register
7
in the intended ARM instruction. We were fortunate that
IonMonkey’s allocates live values to R11 because it enabled
us to encode the “Compare and Branch on Zero” (cbz)
instruction, which is crucial for Turing-completeness. V8, on
the other hand, does not allocate live values to register R11,
signiﬁcantly complicating the encoding of a Turing-complete
payload. However, even if it were not possible to encode
Turing-complete computation in the self-sustaining payload,
the technique allows for the construction of more sophisticated
gadgets for use in gadget chaining.
IV.
JIT SPRAYING MITIGATIONS
Researchers and practitioners have proposed numerous mit-
igations against the security risks introduced by JIT compilers.
The mitigations vary widely in peformance overhead, difﬁculty
of integration into an existing JIT compiler, and defensive
effectiveness. We organize these efforts into the following
three categories: capability conﬁnement, memory protection,
and diversiﬁcation. In order to place our own defense imple-
mentations and the performance evaluations thereof (§V) into
context, we provide an overview of JIT spraying mitigation
proposals in these three classes and their adaptations (when
applicable) in real world JIT implementations.
A. Capability conﬁnement
The objective of capability conﬁnement defenses is to
make JIT code an unattractive reuse target
in general by
reducing the set of capabilities that JIT code can possess. More
sophisticated capability conﬁnement defenses also prevent JIT
code from corrupting itself. The least sophisticated capability
conﬁnement defenses employ simple heuristics to detect sys-
tem calls from JIT code [11] or the emission of long sequences
of consecutive instructions taking 32-bit immediate operands,
where those sequences begin with mov reg, imm32 [5],
which was the hallmark of Blazakis’ original attack. Though
the performance overhead of [11] is not prohibitive at 1.84%
on the SPEC CPU2000 Integer benchmark ([5] does not report
on its performance overhead), the two heuristic defenses can
be easily circumvented by reusing statically-compiled system
calls and avoiding the creation of the initial mov instruction,4
respectively. The next two capability conﬁnement defenses
offer much stronger security beneﬁts through sandboxing.
1) NaCl-JIT: NaCl-JIT [3] is a system that extends the
Native Client (NaCl) sandbox [34] so that a language run-
time running in the sandbox can dynamically install, invoke,
modify, and delete code within the sandbox on the ﬂy. The
sandbox provides the following three high level guarantees
about sandboxed code execution: (1) it cannot read or write
outside of a contiguous region of data memory; (2) it contains
only instructions drawn from a whitelist, and they reside in
a contiguous region of sandboxed code memory; and (3)
aside from API calls into the NaCl runtime, its control ﬂow
only executes instructions decoded at
intended instruction
boundaries within the aforementioned code memory region.
Thus, even a malicious JIT-compiled program that is able to
completely commandeer the sandboxed language runtime and
4Rather
than writing
form var x =
(imm32ˆ...ˆimm32);, one can write var x = (yˆ...ˆimm32);
where y is not deﬁned as a constant, which will not require moving a
constant into a register.
high-level
code
of
the
issue arbitrary NaCl-JIT API calls still cannot access memory
outside of the sandbox or directly execute non-whitelisted
instructions such as system calls or cache ﬂushes. While
this may allow a malicious JIT-compiled program to access
sandbox memory in ways that the sandboxed language runtime
did not intend for it to access, the underlying system outside
the sandbox remains safe.
The NaCl sandbox is implemented via code veriﬁcation,
instruction bundling, and (for most architectures) software
guards, which incur a high overhead. The runtime overhead
of the NaCl-JIT port of the V8 JavaScript engine on the V8
JavaScript benchmark suite ranges from 28%-60% on x86-32
and x86-64. While NaCl-JIT’s security properties are indeed
alluring, performance regressions on this order are unlikely to
be considered acceptable for a mainstream JavaScript engine
actively engaged in the benchmark wars.
2) RockJIT: RockJIT [23] offers a platform similar to
NaCl-JIT with considerable performance improvements due
to more efﬁcient JIT code validation and a more efﬁcient
mechanism for protecting control ﬂow (ﬁne-grained control
ﬂow integrity (CFI) [2] (without a shadow stack) in the lan-
guage runtime and coarse-grained CFI on JIT code). RockJIT’s
authors ported the V8 JavaScript engine to use RockJIT; and
on the same set of benchmarks over which NaCl-JIT showed
a 51% overhead, RockJIT had just 9.0% overhead. Over the
entire Octane 2 JavaScript benchmark suite, RockJIT incurred
a 14.6% average overhead.
However,
these performance gains come with security
risks. Notably, RockJIT allows the (untrusted) language run-
time to directly make system calls (excluding memory repro-
tection), and it trusts the language runtime to announce indirect
branch targets within JIT code so that RockJIT can update the
CFI policy. A control ﬂow bending [8] attack would enable
an attacker to abuse the lack of a shadow stack and issue any
system call present in the language runtime.
B. Memory protection
A vulnerability commonly introduced by JavaScript JIT
compilers is permanent RWX permissions on JIT code pages,
even on systems that enforce W ⊕ X on normal code and data
pages. This practice is done in the name of performance; inline
caching (IC) [12]—a performance optimization popular [30],
[20], [1] among JavaScript implementations—often requires
the frequent compilation of short code stubs during JIT code
execution as well as the patching of calls to those stubs into
existing code. Leaving JIT code pages RWX at all
times
eliminates memory reprotection system calls during inline
cache installation and maintenance as well as those that would
be necessary during the compilation of normal program code.
RWX memory poses a signiﬁcant threat to JIT security.
Lian et al.’s attack against the JavaScriptCore JIT on ARM [17]
as well as the new attack we introduced in § III-B rely
on always-RWX JIT code pages in order to perform self-
modiﬁcation of JIT code. Memory protection defenses seek to
rid JIT code of its always-RWX memory protection status by
adapting W ⊕ X to dynamically-generated code. Two popular
approaches to memory protection for JIT code are transient
protection and dual mapping.
1) Transient protection: A recent addition to the Spider-
Monkey JavaScript engine [21] is W ⊕ X protection for JIT
8
code with the aim of preventing corruption of JIT code. When
the defense is enabled, JIT code is RX by default, and when
the runtime needs to modify a unit of code compilation, that
unit is temporarily reprotected RW. The performance overhead
of this change is less than 1% on the Kraken and Octane
JavaScript benchmark suites and no more than 4% overhead
on the SunSpider benchmark suite. SpiderMonkey’s imple-
mentation of inline caches inherently favors low-overhead
W ⊕ X protection, as it requires far less-frequent patching
(and therefore fewer memory reprotection system calls) and
stub compilation than other compilers such as V8. Reducing
the need for patching in V8 is a non-trivial matter. In fact, the
V8 team has explained to us that although they are undergoing
efforts to eliminate patching for some types of ICs, others are
still considered too performance-sensitive. Unfortunately, this
means that transient W ⊕ X protection will likely remain too
expensive for V8.
JITScope [35]
is a proposed defense that provides
normally-RX protection similar to SpiderMonkey’s W ⊕ X
defense, but it reprotects memory more frequently and there-
fore incurs a higher overhead (1.6%-6.0%). Although these
defenses offer protection against code corruption in single-