title:Trust-based anonymous communication: adversary models and routing
algorithms
author:Aaron Johnson and
Paul F. Syverson and
Roger Dingledine and
Nick Mathewson
Trust-based Anonymous Communication: Adversary
Models and Routing Algorithms
Aaron Johnson
Paul Syverson
Roger Dingledine
Nick Mathewson
∗
U.S. Naval Research Laboratory
{aaron.m.johnson,paul.syverson}@nrl.navy.mil
The Tor Project
{arma, nickm}@torproject.org
ABSTRACT
We introduce a novel model of routing security that incor-
porates the ordinarily overlooked variations in trust that
users have for diﬀerent parts of the network. We focus on
anonymous communication, and in particular onion routing,
although we expect the approach to apply more broadly.
This paper provides two main contributions. First, we
present a novel model to consider the various security con-
cerns for route selection in anonymity networks when users
vary their trust over parts of the network. Second, to show
the usefulness of our model, we present as an example a new
algorithm to select paths in onion routing. We analyze its
eﬀectiveness against deanonymization and other information
leaks, and particularly how it fares in our model versus ex-
isting algorithms, which do not consider trust. In contrast
to those, we ﬁnd that our trust-based routing strategy can
protect anonymity against an adversary capable of attacking
a signiﬁcant fraction of the network.
Categories and Subject Descriptors
C.2.2 [Networks]: Network Protocols; C.2.0 [Networks]:
General—Security and protection; C.4 [Performance]: Mod-
eling techniques
General Terms
Security, Theory
Keywords
anonymous communication, onion routing, privacy, trust
1.
INTRODUCTION
Existing anonymous communication theory and system
design are generally based on the unrealistic assumption that
both adversaries and vulnerability to their attacks are uni-
formly distributed throughout the communications infras-
∗This work was primarily done while at the Department of
Computer Science at The University of Texas at Austin.
Copyright 2011 Association for Computing Machinery. ACM acknowl-
edges that this contribution was authored or co-authored by an employee,
contractor or afﬁliate of the U.S. Government. As such, the Government re-
tains a nonexclusive, royalty-free right to publish or reproduce this article,
or to allow others to do so, for Government purposes only.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
tructure and that a larger network should better protect
anonymity. But then if an adversary can control a signif-
icant fraction of the network, scaling the network to even
tens or hundreds of thousands of nodes will not necessarily
improve anonymity. This paper presents a model for routing
traﬃc on an anonymity network where diﬀerent users trust
some parts of the network more than others, potentially al-
lowing users to protect themselves even if large fractions of
the network are compromised. We consider route selection
for onion routing that makes use of that nonuniform trust
and also protects despite an adversary’s awareness of it.
While there have been many proposals for anonymous
communication protocols [3, 7, 20, 40, 41], onion routing [26]
is probably the most dominant.
In particular, it enjoys a
widely-deployed implementation in the Tor system [17, 49].
As of April 2011, the Tor network’s roughly 2500 volunteer
routers are used every day by several hundreds of thousands
of users to carry about seventy terabytes of traﬃc [50]. Thus,
though our model can apply to many protocols, we focus on
onion routing for our examples to illustrate that the theory
we introduce can be applied to real systems.
Onion routing, like most anonymous communication par-
adigms, derives its security from the (traditionally uniform)
diﬀusion of trust throughout the system. In onion routing,
users create a cryptographic circuit over a randomly chosen
path and then use it to communicate bidirectionally with a
destination. Onion routers are supposed to be run by dis-
tinct non-colluding entities, but enforcing non-collusion can
be diﬃcult. The routers of the Tor network, for example,
are operated by volunteers whose identities and intentions
are unveriﬁed. This choice has provided the network with
the diversity and ﬂexibility that has helped it grow to its
current scale [16, 18]. But the number of routers that can
be added by one entity is limited only by the number of IP
addresses he can obtain.
This same general dependence on diﬀusion of trust applies
to most anonymous communication schemes—both deployed
anonymity networks, such as Mixmaster [35] and Mixmin-
ion [12], and those that have seen more theoretical consid-
eration than actual use, such as the various treatments of
Dining Cryptographers [2, 25, 27]. Most of the related re-
search assumes that individual users can do little to learn
which nodes are likely to be compromised. But onion rout-
ing was originally devised by the U.S. Naval Research Lab-
oratory speciﬁcally to target an environment where large
organizations or companies could use a network alongside
ordinary citizens. What if the user is from an organization
that does have the resources to investigate nodes, to operate
175its own nodes, or to otherwise ensure the security of nodes
against a particular adversary? Such an organization might
run its own private network, in which it controls or vets all
the nodes, and just use that. Even if such a private network
hides which of its users is responsible for which connection,
all traﬃc exiting it will be known to come from the organi-
zation running the network. Alternatively, the organization
could run a subnet of the public network and preferentially
use that subnet for its own traﬃc. This approach helps to
resist ﬁrst–last correlation (described below), but it exposes
the organization to other attacks. Most signiﬁcantly, to the
extent that the organization is likelier than other users to
use its own subnet, all the traﬃc carried on the subnet will
be linked to the organization and therefore to some degree
deanonymized. Even if the organization tries to keep its
trust and use of its subnet a secret, usage patterns (as would
happen if many users from the subnet make requests link-
able to the organization) or inadvertent disclosures (as in
unauthorized leaks [43]) could over time reveal its presence.
We introduce a framework that can address such concerns.
We review related work in the next section. We set out
our assumptions, describe our model for the network and
adversaries, and provide corresponding deﬁnitions for trust
and anonymity in Section 3. In Section 4, we use the model
to design and analyze a novel path-selection algorithm for
onion routing. We begin in Section 4.1 by considering the
anonymity of a single connection.
In particular, we use
trust to obtain an algorithm that improves the posterior
probability that an adversary assigns to a given user as the
source of a connection given trust levels and the adversary’s
observations. We consider the value of this posterior for
some typical usage scenarios, and compare it to the poste-
rior probability under other path-selection algorithms. We
also consider the eﬀect of errors in assigning trust in these
scenarios. Next, in Section 4.2, we examine the implications
of making multiple connections over time and modify our
path-selection algorithm to improve anonymity in this case.
Throughout the paper we try to keep our work applicable
to real-world scenarios while remaining abstract enough to
permit useful analysis. We hope our work here will provide a
foundation for research in route selection so that ultimately
users with large-resource, long-reach adversaries can have
the assurances necessary to protect their communications.
2. RELATED WORK
The ﬁeld of anonymous communication has grown vast.
For recent general surveys, see Edman and Yener [22] or
Danezis et al. [11]. Here we will focus on work related to our
central topic, incorporating node trust into route selection.
Two types of prior work are thus particularly relevant: First
are papers that analyze the anonymity eﬀects of restricted
knowledge of the network by route selectors. Second are
papers that also use trust in route selection. We also include
a brief discussion of ﬁrst–last correlation attacks.
The ﬁrst work to consider general eﬀects of route selection
on a less than fully connected graph is Danezis’s analysis of
mix networks with restricted routes [9]. Route restriction
was considered to ensure more traﬃc per link, but he also
observed that if the network was an expander graph with
N nodes, after O(log N ) random hops a route will have
nearly the same distribution on sources as in a fully con-
nected graph.
Danezis and Clayton introduced “route ﬁngerprinting” at-
tacks that exploit the limited knowledge of the network that
users must have for P2P anonymity designs to permit scal-
ing [10]. To avoid such knowledge-based attacks, Tor re-
quires that clients know about all the routers in the network.
This choice obviously creates scaling problems, but because
onion routing is not a P2P design, the number of clients
is orders of magnitude larger than the number of routers.
This hybrid approach has mitigated both scaling issues and
some of the attacks that can arise from partial knowledge
of the network. The current work is a generalization from
the zero/one trust that is implied by knowledge or ignorance
of network nodes [10] to a more ﬁne-grained distinction of
willingness to trust a node with one’s traﬃc.
Using trust to make routing decisions in anonymity net-
works was ﬁrst explicitly analyzed in [31].
(Prior sugges-
tions of choosing so-called “entry guard” nodes based on
trust did not describe how to make this choice or analyze
use of trust [39].) Johnson and Syverson considered an ad-
versary that would try to compromise a given fraction of
the network’s nodes. They used a notion of trust based on
diﬃculty-of-compromise to examine the optimal strategy to
resist the ﬁrst–last correlation attack, depending on the re-
sources of the adversary, the size of the network, and the
distribution of trust on the nodes. They did not consider,
as we do, that diﬀerent users could have diﬀerent distribu-
tions on trust or that diﬀerent users could be concerned with
attack by diﬀerent adversaries. They also considered only
how a user could resist correlation attacks given nonuniform
trust in the network. They did not attempt a general anal-
ysis of other potential attacks in such a network or routing
strategies to resist those attacks. Herein we consider addi-
tional attacks where the adversary makes inferences based
on node selection rather than just trying to see the source
and destination.
A very diﬀerent notion of trust for anonymity networks
concerns path formation that considers behavioral trust, such
as performance reputation [15, 19]. Sassone et al. analyzed
trust in this sense when an adversary compromises a ﬁxed
fraction of the network [42]. Users choose paths according
to individual trust algorithms (independent of where the ad-
versary exists). They analyze the probability that a user
chooses an adversary node, and given that, the probability
the adversary attaches to a user creating a path containing
that node.
Onion routing’s eﬃciency and bidirectionality make it fast
and functional enough for popular online activities like web
browsing and instant messaging, which in turn contributes
to its success. But onion routing anonymity protocols are
not the only ones that have been used for general public com-
munication. In particular, systems based on passing discrete
self-contained messages through “mixes” in a source-routed
manner similar to onion routing [5, 6] have been used for
public Internet communication via email. But even those
that are designed to be practical or have been deployed and
widely used [12, 28, 35] add much more latency and overhead
compared with onion routing.
The added latency in mix systems is not just ineﬃciency.
High-variance latency helps to protect against several types
of attacks on anonymity that onion routing does not resist as
well or at all, such as the ﬁrst–last correlation attack [48] or
various others [13, 23, 29, 30, 32, 33, 34, 36], although onion
routing is more secure than mixing against some attacks [45,
46].
176First–last correlation attacks require the adversary to match
the timing pattern of messages coming from the user to the
timing of messages going to the destination. This match-
ing can either be done passively [1, 39] by simply using the
timing pattern created by the user, or actively [51] by delay-
ing messages to create timing watermarks. Extant defenses
against ﬁrst–last correlation are either ineﬀective in prac-
tice (padding) or impractical in eﬀect (delaying and mixing)
or, more typically, both. Simulation and experimentation
have conﬁrmed the obvious, that such attacks require triv-
ial resources or analysis to be successful. If research does
not uncover an eﬀective and practical counter to ﬁrst–last
correlation, onion routing for low-latency use must simply
accept it and strive to minimize its impact. For example,
Tor contains no mixing or padding in its design [17].
3. MODEL
We describe a model to give semantics to the notion of
trust in the context of anonymous communication. The
model we present provides a foundation for using trust in
designing and analyzing anonymity protocols, specialized to
the particular setting of improving resistance to deanony-
mization and proﬁling for onion routing systems. It is part
of a model intended to be general enough to reason about
trust for various anonymity protocols, and for secure rout-
ing goals besides anonymity, such as route provenance. The
more general model also describes other adversary goals be-
yond deanonymization and proﬁling, whether the anonymity
protocols use onion routing or another approach. For exam-
ple, an adversary may want to discover which of the various
possible adversaries speciﬁc (classes of) users are trying to
avoid, which could help indicate something about the like-
lihood that a given circuit belongs to a given user based on
how well the circuit counters a given adversary. An adver-
sary may also want to discover which network nodes are
more trusted with respect to which adversaries. Among
other things, this could indicate the resources deployed to
protect a particular (class of) user’s communication. Our
focus in this paper is to provide a model and algorithms for
onion routing that show how trust-aware route selection can
greatly improve resistance to deanonymization and proﬁling.
In particular, using trust can substantially improve security
even when an adversary controls a signiﬁcant portion of the
network. The general model is more completely described
in [47].
1. Let V be the set of nodes. And let V = U ∪ R∪ D, where
U is a set of users1, R is a set of onion routers, and D
is a set of destinations.
´ be the set of network links between nodes.
2. Let E ⊆`V
2
which a node v wants privacy.
3. Let A be the set of adversaries.