the lense of an NGO.
(2014).
[40] LERNER, A., ZENG, E., AND ROESNER, F. Conﬁdante: Usable
encrypted email – A case study with lawyers and journalists. In
IEEE European Symposium on Security and Privacy (2017).
USENIX Association
26th USENIX Security Symposium    519
[41] LUND, D. B. Organizational culture and job satisfaction. Journal
of business & industrial marketing 18, 3 (2003), 219–236.
[42] MALTBY, J., AND DAMON-FENG, G. The Panama Papers: The
story so far, and what comes next, December 16, 2016. https:
//www.law360.com/articles/874074/the-panama-
papers-the-story-so-far-and-what-comes-next.
[43] MARCZAK, W. R., SCOTT-RAILTON, J., MARQUIS-BOIRE,
M., AND PAXSON, V. When governments hack opponents: A
look at actors and technology. In 23rd USENIX Security Sympo-
sium (2014).
[44] MCGREGOR, S. E., CHARTERS, P., HOLLIDAY, T., AND ROES-
NER, F. Investigating the computer security practices and needs
of journalists. In 24th USENIX Security Symposium (2015).
[45] MCGREGOR, S. E., ROESNER, F., AND CAINE, K. Individual
versus organizational computer security and privacy concerns in
journalism. Proceedings on Privacy Enhancing Technologies 4
(2016), 1–18.
[46] MITCHELL, A., HOLCOMB, J., AND PURCELL, K.
Inves-
tigative journalists and digital security: Perceptions of vulner-
ability and changes in behavior. Pew Research Center, Feb.
2015. http://www.journalism.org/files/2015/02/PJ_
InvestigativeJournalists_0205152.pdf.
[47] OSHRI, I., VAN FENEMA, P., AND KOTLARSKY, J. Knowl-
edge transfer in globally distributed teams: the role of transactive
memory. Information Systems Journal 18, 6 (2008), 593–616.
[48] PFLEEGER, S. L., SASSE, M., AND FURNHAM, A. From weak-
est link to security hero: Transforming staff security behavior.
Journal of Homeland Security and Emergency Management 11,
4 (2014).
[49] POPA, R. A., REDFIELD, C. M. S., ZELDOVICH, N., AND
BALAKRISHNAN, H. Cryptdb: Protecting conﬁdentiality with
encrypted query processing. In Proceedings of the Twenty-Third
ACM Symposium on Operating Systems Principles (New York,
NY, USA, 2011), SOSP ’11, ACM, pp. 85–100.
[50] SCHNEIER, B. Secrets & Lies: Digital Security in a Networked
World. John Wiley & Sons Inc., 2000.
[51] SCHRODT, P. The relationship between organizational identiﬁca-
tion and organizational culture: Employee perceptions of culture
and identiﬁcation in a retail sales organization. Communication
Studies 53, 2 (2002), 189–202.
[52] SHAY, R., KOMANDURI, S., DURITY, A. L., HUH, P. S.,
MAZUREK, M. L., SEGRETI, S. M., UR, B., BAUER, L.,
CHRISTIN, N., AND CRANOR, L. F. Can long passwords be
secure and usable? In Proceedings of the SIGCHI Conference on
Human Factors in Computing Systems (2014), CHI ’14, ACM,
pp. 2927–2936.
[53] SMIRCICH, L. Concepts of culture and organizational analysis.
Administrative science quarterly (1983), 339–358.
[54] STANTON, J., MASTRANGELO, P., STAM, K., AND JOLTON,
J. Behavioral information security: Two end user survey studies
of motivation and security practices. AMCIS 2004 Proceedings
(2004), 175.
[55] THOMSON, K.-L., VON SOLMS, R., AND LOUW, L. Cultivating
an organizational information security culture. Computer Fraud
& Security 2006, 10 (2006), 7–11.
[56] VENKATESH, V. Determinants of perceived ease of use: Integrat-
ing control, intrinsic motivation, and emotion into the technology
acceptance model. Information Systems Research 11, 4 (2000),
342–365.
[57] VENKATESH, V., AND DAVIS, F. D. A theoretical extension of
the technology acceptance model: Four longitudinal ﬁeld studies.
Management science 46, 2 (2000), 186–204.
[58] VON SOLMS, B., AND VON SOLMS, R. The 10 deadly sins of
information security management. Computers & Security 23, 5
(2004), 371–376.
[59] WEIRICH, D. Persuasive password security. PhD thesis, Univer-
sity College London, 2005.
[60] WHITTEN, A., AND TYGAR, J. D. Why Johnny Can’t Encrypt:
In Proceedings of the 8th
A Usability Evaluation of PGP 5.0.
USENIX Security Symposium (1999).
ICIJ Journalist Survey
A Appendix: Survey Instrument
This appendix contains the questions from ICIJ’s survey
of contributing journalists for which we received data.
A.1
We want to know your opinion about the project plat-
forms and your experience working on the project.
It
should take you 10 minutes. Your honest feedback will
be important to make adjustments to future investiga-
tions and we will use your answers only for ICIJ internal
purposes. You can answer the survey anonymously,
although we appreciate if you tell us who you are.
Thanks for helping us to improve global collaboration in
journalism!
1. Name [short answer]
2. Country [short answer]
3. Media Outlet [short answer]
4. Email [short answer]
5. How much did you collaborate with others outside
your organization for this project?
(I worked independently) 1 2 3 4 5 6 7 (I’ve collaborated
more than ever)
6. How would you rate the services provided by ICIJ
throughout this project?
For 6.A-C, the scale was: Unnecessary, Not useful, Use-
ful, Very useful, Essential.
A. Project coordination
B. Digital tools (I-Hub, Blacklight, etc.)
C. Training (tools, data and digital security)
7. How did you ﬁnd the coordination of the project?
(Poor) 1 2 3 4 5 6 7 (Excellent)
during the last three
8. How often did you use
months before publication?
For 8.A-C, the scale was: Every day, Two or three times a
week, Once a week, Once a month, Every now and then,
I never used the service, Other: [short answer].
A. Blacklight
B. I-Hub
C. Linkcurious
9. Which digital security practices were you familiar
with prior to working on this project?
520    26th USENIX Security Symposium
USENIX Association
For 9.A-C, the scale was: Never heard of it before, Knew
about it but hadn’t used, Had used a few times, Used
occasionally, Used frequently.
A. Passphrases (instead of passwords)
B. Two-factor authentication (Google authenticator)
C. PGP encryption (for email)
10. Which improvements (if any) would you like to
see in Blacklight? [short answer]
B Appendix: Interview Instruments
This appendix contains our interview script for ICIJ ed-
itorial personnel and for ICIJ technical staff. We note
inline where the interview script differed between edito-
rial and technical staff.
Background
1. What was your [editorial/technical] background
and/or main area of responsibility for ICIJ prior to
the start of the Panama Papers project?
2. Prior to the Panama Papers, had you worked on any
other collaborative investigative projects at ICIJ, or
any other organization? If so, can you tell us a lit-
tle bit about how the Panama Papers differed from
these earlier efforts?
Overall System Design
1. Were you directly involved in the [technical] de-
sign [and/or deployment] of the collaborative sys-
tems used during the Panama Papers to store and/or
share the source documents? If so:
(a) What did you feel were the most important
features of the system in terms of function-
ality? What were the most signiﬁcant chal-
lenges to including these features?
(b) What did you feel were the most important
features of the system in terms of security?
What were the most signiﬁcant challenges to
including these features?
(c) We understand that PGP was required to dis-
tribute at least some system credentials. Can
you tell me a little bit about why PGP was se-
lected, and how that requirement was commu-
nicated to users?
2. Were any of the technologists who worked on the
projects not ICIJ employees? If so, how were they
selected for involvement? Was their access to the
design and/or implementation details of the project
limited in any way?
3. To the extent that you are aware, how did the sys-
tems evolve over the course of its use during the
Panama Papers project? Have they continued to
change since the launch? In what ways?
4. From your perspective, what were the most success-
ful aspects of the system design and deployment?
What were the least successful? What surprised you
the most about how the system was used?
5. For technical staff only: Were regular backups per-
formed on the system? If so, how were backups
initiated and carried out?
6. For technical staff only: Was content stored on the
system generally encrypted at rest? If so, was there
a mechanism for searching this content?
Recruitment and Participation
For editorial staff only:
1. How did journalists generally get involved in the
Panama Papers project? Were they recruited, or did
they reach out to ICIJ?
2. What was the general process for vetting individuals
or organizations for participation? Was anyone ever
rejected? Why?
3. Was there a group of people who were responsible
for verifying the authenticity of received documents
and information? If so, what type of process did
they use?
4. As more information was received, how was it in-
tegrated into the system? Who was responsible for
this, and how was the process determined?
General System Functionality: BlackLight and I-Hub
1. We understand that there were two primary systems
used to manage the Panama Papers project: Black-
Light and I-Hub. In your own words, you could de-
scribe each of these systems, both in terms of their
functionality and how they were implemented?
2. Did journalists have separate logins to the two sys-
tems? To the best of your knowledge:
(a) Were there speciﬁc password requirements
(e.g., length, various characters, etc.)?
(b) Was two-factor authentication required?
(c) How could users change/reset passwords?
Were regular password changes required?
3. For editorial staff only: Were users allowed to up-
load ﬁles to either system? If so, were there any sys-
tem features included to scan or clean these ﬁles?
4. For technical staff only: Were users authorized to
upload ﬁles to either system? If so, was there any
service/feature embedded with the ﬁle server, to de-
tect and clean malware when a ﬁle is uploaded?
5. For editorial staff only: If users had a difﬁculty with
one of the systems, what resources were available
to them? Was providing user support a signiﬁcant
consideration in the design of the system?
USENIX Association
26th USENIX Security Symposium    521
6. For technical staff only: If users had a difﬁculty
with one of the systems, could they contact the IT
team directly? If so, what was the mechanism? If
not, what types of resources or protocol was made
available for these users?
I-Hub
1. Did all journalist users have the same level of per-
missions on the system?
2. What type of user could create new “chat rooms”
or threads? Could administrators see all of these,
and/or remove content, if needed?
3. For editorial staff only: Were there any features that
you would have liked to see included in the system,
but that could not be integrated for technical rea-
sons? What were they?
4. For technical staff only: What type of encryption
was implemented on this system? Was it end-to-
end (in the style of PGP or OTR) or client-to-server
(e.g. HTTPS connection to platform)?
BlackLight
1. For editorial staff only: How did the BlackLight
system work? Why was BlackLight selected as the
base project from which to create the Panama Pa-
pers system? What features do you wish it had that
it didn’t?
2. For technical staff only: Why was BlackLight se-
lected as the base project from which to create the
Panama Papers system? Was it difﬁcult to adapt or
secure for use on this project? In what ways?
Listserv
1. How did communications on the listserv differ from
those on I-Hub?
2. For technical staff only: What were the func-
tional/security differences between I-Hub and the
listserv?
3. Are you aware of any instances where the listserv
was used inappropriately? If so, how was this ad-
dressed, and by whom?
Information Security Training
1. Who generally provided security training for jour-
nalists? Who designed the content of the trainings?
2. Did you provide or design any of these trainings? If
so, please tell me a little bit about how they were
delivered and what content they contained:
(a) Were they “live” (e.g. streamed) or recorded?
Why or why not?
(b) Did they involve hands-on exercises? Why or
why not?
(c) Was there any type of evaluation/grading of
participants? Could a “failing” grade limit ac-
cess or require the training be taken again?
Why or why not?
(d) How many different trainings/topics did each
user have to engage before being granted ac-
cess to the systems?
3. What was the goal of providing these trainings? Do
you feel they were successful? What would you
change or do differently around training for a simi-
lar project in the future?
Security Breaches and System Failures
1. To what extent was keeping the online location (i.e.
URL) of the project an important security concern?
2. Was there a speciﬁc protocol for taking the system
ofﬂine due to errors, updates or security incidents?
How were these communicated to the users of the
system (if at all)?
3. For editorial staff only: Were there speciﬁc plans
in place for detecting and/or handling system ex-
posures or security incidents? How were the users
and/or publications involved monitored, if at all?
By whom?
4. For technical staff only: Were there speciﬁc plans
in place for detecting and/or handling security inci-
dents? For example, were there automated intrusion
detection systems, or checks on the locations of sys-
tem access?
5. Without revealing speciﬁcs that could compromise
continued use of the system, can you share a general
sense of what kind of security incidents happened
during the project, and how they were handled?
Scaling and Future Development
1. Do you feel that you would use – or encourage oth-
ers to use – this type of system for collaborative in-
vestigative projects in the future? Why or why not?
2. From both a functionality and support perspective,
do you think the systems used for the Panama Pa-
pers are scalable to a larger number of projects
and/or users?
3. Are there any [design or deployment / technical or
system design] lessons you learned from this project
that you intend to apply to the design of future sys-
tems, whether for similar projects or not? If so,
what features or aspects would you keep or change
for other projects, and why?
4. Would you change the content or mechanism of
training or support for future systems?
5. Is there anything else about this project that you’d
like to tell us or think we should know?
522    26th USENIX Security Symposium
USENIX Association