study), it is natural to check whether the apps contain na-
tive code. Speciﬁcally, the native code detector does the
following checks to ﬁlter apps that are extremely unlikely
to contain root exploits: (1) Whether the app matches
signatures of known malware samples that contain root
exploits.
If so, we abort any further analysis and ﬂag
the malware. (2) Whether it has any native code or has
the capability of dynamically loading native code (e.g.,
through the network). If negative, we can safely skip the
analysis of this app. (3) If it contains native code, sim-
ilar to prior work [8], we use a list of custom heuristics
to decide if they can possibly contain root exploits (e.g.,
whether any dangerous system calls are being called). If
negative, we do not analyze the app further.
If the native code detector did not abort the analy-
sis, the app is moved to the device detector. This is re-
sponsible for determining “under which environment the
app should be dynamically analyzed.” The observation is
that since malware can embed different exploits target-
ing different Android devices, they usually contain logic
that detects the type of the Android environment. Thus,
we look for any such logic that performs checks against
hard-coded device types.
The last component is the device initiator, which gen-
erates the Android environment based on the output of
the device detector. We describe the device detector and
the device initiator in more details below.
Device detector: This component parses the de-
compiled bytecode (using androguard [9]) and ﬁnds
the methods (A)
that contain code that check ei-
ther the Android version that resides in the static
class
type of
android.os.Build.VERSION, or
the
USENIX Association
26th USENIX Security Symposium    1137
Android MarketDetection SystemStatic analyzerDynamic analyzerNative code detectorKnown malware DBand heuristics for dangerous native codeDevice detectorDevice initiatorDevice/OS infothat
resides
in the
android.os.Build
the device
class, or the version of the Linux Kernel (e.g., by
and
Runtime.getRuntime().exec(‘‘uname’’)
reading the /proc/version ﬁle). Furthermore, it ﬁnds the
methods (B) that either run an executable native ﬁle (e.g.,
Runtime.getRuntime().exec(‘‘/sdcard/foo’’))
or call a function in a native binary (e.g., library ﬁles).
If there is a program path from the methods that are
members of (A) to the ones in (B), it ﬁnds which con-
ditions should be satisﬁed and creates the appropriate
Android environment. Similarly, the same procedure is
performed in native code. In the case that the native code
is obfuscated or even downloaded via a C&C server, the
device detector simply picks a few popular candidate
device types randomly, with the view that the malware
will likely target one or more popular devices.
Device initiator: Android stores the device informa-
tion in system ﬁles such as /system/build.prop and
default.prop. /system/build.prop contains spe-
ciﬁc information about the mobile device such as the
Android OS version, the name and the manufacturer of
the device. In addition, there are also system ﬁles such
as /proc/version and /proc/sys/kernel/* inher-
ited from Linux that store information about the Linux
kernel. When the system boots, the Android’s property
system reads the information from these ﬁles and caches
them for future use. The device initiator monitors all
such interfaces via which an app can learn about the de-
vice and obtain OS information. Since we have collected
a database of Android devices from the online reposi-
tory [1], we know what values to modify in the system
ﬁles or what to return through the proc interfaces.
7.3 Dynamic Analyzer
The dynamic analyzer consists of two parts as illustrated
in Figure 6 viz., a Loadable Kernel Module (LKM) and
a background service process. The LKM hooks every
available system call in the Android Linux Kernel. In ad-
dition, it creates a character device that can be opened by
only the background service (to prevent malware from
tampering with the communication), and with which
a communication link is established between user-land
and kernel-land. The LKM tracks only a speciﬁc app
(under analysis) and its child processes at any moment in
time. The background service stores the training models
including behavior graphs and environment constraints,
as well as the state of the current running app (e.g., what
part of a behavior graph has been matched and what en-
vironment constraints are supposed to be returned next).
Once a hooked system call is called by the app un-
der analysis, the execution is directed to our LKM which
then transmits a specially crafted message that contains
the system call names as well as their arguments to the
Figure 6: Dynamic Analyzer.
background service through the character device. Based
on the behavior graph and environment constraints, the
background service is responsible for deciding what ac-
tion is going to be taken, and it returns that action to the
LKM. First, it checks the behavior graph to see if the sys-
tem call in question matches any new node. If not, it does
nothing and simply instructs the LKM to execute the sys-
tem call as is. If a new node is matched, it further checks
if it is an object creation system call such as open() or
socket(). If so, it deploys a decoy object to satisfy the
environment constraints as described in §6. Otherwise,
if it is a system call that operates on an existing object,
the return results will be served from the data prepared
ahead of time for the decoy object (e.g., ﬁle content).
Note that deploying decoy objects has to be done care-
fully. As mentioned, Android root exploits often need
to be adapted to work on different devices, even when
they target the same underlying vulnerability. For in-
stance, the device ﬁle /dev/camera-isp can be ex-
ploited slightly differently on different Android phones
that all have the vulnerable device driver; this will cause
slightly different behavior graphs and preconditions to
be generated (e.g., the input to a vulnerable device ﬁle
will look different), and the expected return results from
a system call may be different. Therefore, once we have
decided to disguise as a particular Android device (e.g.,
Samsung Galaxy S3), we will need to choose the behav-
ior graphs and preconditions accordingly (obtaining such
a Android device to exploit binary mapping is discussed
in §4). Otherwise, the decoy objects we deploy may be
for the wrong Android device which will in fact fail to
detect the exploit.
8 Evaluation
In this section we describe the evaluations of RootEx-
plorer. We focus on its effectiveness wrt the following
aspects: (1) can it detect synthetic and real malware con-
taining root exploits? (2) does it cause false alarms on
benign apps? (3) does it miss malware samples?
1138    26th USENIX Security Symposium
USENIX Association
8.1 Environment Setup
Training parameters: Our training database contains
168 different root exploits that were designed for differ-
ent devices and were obtained from a commercial one
click root app. The number of devices that we can
successfully emulate currently based on the root exploit
database is 211. We trained with all 60 families of root
exploits.
Testing dataset: We have the following categories of
apps for evaluation:
1. Samples that are known to contain root exploits.
This includes publicly distributed exploit PoCs [38, 36,
34, 33] and GODLESS malware [32], and seven other
one-click root apps (different from the one we trained
with) which also contain many different root exploits.
2. Samples that may contain root exploits. We ob-
tained a list of 1497 malware samples from an antivirus
company, and have crawled 2000 recently uploaded apps
between January and February 2017, from four unofﬁ-
cial Android app markets: 7723 [3], ANDROID life [4],
MoboMarket [6] and EOEMARKET [5]. We target
third-party markets because they are known to have more
malware than the ofﬁcial Google Play [87].
3. Samples that almost certainly do not contain root
exploits. This includes the top 1000 free apps from
Google play. As they are extremely popular, it is very
unlikely that they contain root exploits. This set is used
to evaluate the false positives (if any) with RootExplorer.
Analysis Testbed: The experiments are performed on
a Lenovo Laptop with a quad core Intel Core i7 2.00GHz
CPU, 16GB of RAM, and a hard drive of 1TB at 5400
rpm. We use an Android emulator for analyzing the mal-
ware2. To make the emulator appear as realistic as pos-
sible, it is loaded with real ﬁles, such as music, pictures
and videos. Furthermore, it contains a call log, SMS his-
tory and contacts, as well as various installed apps. We
have modiﬁed the binary image of the emulator, in order
to show that it has a real phone number and a real In-
ternational Mobile Equipment Identity (IMEI) number.
Finally, the build.prop ﬁle (containing the device in-
formation) is updated appropriately prior to each exper-
iment. Each app is analyzed starting with a clean image
of the emulator in order to avoid any side effects that a
previously tested malware app can have on the emulator.
A simple micro-benchmark on the open() system calls
shows that the system call monitor increases the execu-
tion time of open() by 75%, on average.
Input generator: To achieve as much code coverage
as possible when executing an app (in hope that root ex-
ploits will be triggered), we leverage DroidBot [37], a
2Even though the system runs on real phones, we choose an emu-
lator based approach since it is easier to run a large set of experiments
concurrently.
One-Click App
O1
O2
O3
O4
O5
O6
O7
Exploit
/dev/camera-sysram
/dev/graphics/fb5
/dev/exynos-mem
/dev/camera-isp
/dev/camera-isp
/dev/camera-isp
towelroot
Table 1: One-Click apps with the discovered exploits.
lightweight test input generator for Android that gen-
erates pseudo-random streams of user events such as
clicks, as well as a number of system-level events. Droid-
Bot can generate random events on its own, or gener-
ate events based on the manifest ﬁle of the app, or can
take as input a ﬁle with predeﬁned events. In our exper-
iments, we use randomly generated events (“black-box”
technique) and events based on the manifest ﬁle of the
app (“gray-box” technique).
8.2 Effectiveness
We evaluate RootExplorer against all the test datasets
mentioned earlier containing 4497 apps in total. Over-
all, we do not ﬁnd any false positives, i.e., benign apps
are never mistakenly reported to contain root exploits.
For the known malware samples, we obtain the ground
truth either from the fact that github explicitly states that
it is a root exploit, or via cross-validation with VirusTo-
tal and the antivirus company that we work with. Out of
8 known malware families containing root exploits, we
do not ﬁnd any false negative. We describe the details
below.
Unit testing: To obtain assurance that the training
phase works as expected, We execute the 60 families
of root exploits (from the training data) in our dynamic
analysis environment and see if they can be detected.
Note that this means that the training and testing data
are exactly the same. If any of these exploits cannot be
detected, it indicates that the behavior graphs or precon-
ditions that were prepared are in fact incorrect. The test-
ing results show that all of the exploits are successfully
detected.
Detecting other one-click root apps: Since we have
not trained RootExplorer with exploits from other one-
click root apps, this test allows us to further conﬁrm that
the system works well. In particular, the exploits from
these apps may or may not be implemented exactly in
the same way as the ones in our training set, being able
to trigger and detect them is a promising sign. Table 1
lists the ﬁrst exploit that was caught upon running 7 other
one-click root apps on an emulated Samsung Galaxy S3
device.
Interestingly, different one-click root apps in
fact choose to launch different exploits against our de-
USENIX Association
26th USENIX Security Symposium    1139
Exploit
diag
exynos
pingpong
towelroot
VirusTotal
1/57
4/57
1/57
3/57
RootExplorer
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Exploit
diag
exynos
pingpong
towelroot
VirusTotal
0/57
1/57
0/57
1/57
RootExplorer
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Table 2: Detection rate for debug compilation.
Table 3: Detection rate for obfuscated compilation.
vice. For instance, with O1, we caught an exploit re-
lated to the /dev/camera-sysram driver, while O2 and
O3 triggered exploits against /dev/graphics/fb5 and
/dev/exynos-mem respectively. The results showcase
the effectiveness of RootExplorer in detecting a wide va-
riety of exploits.
Detecting Exploit PoCs from the Internet: We next