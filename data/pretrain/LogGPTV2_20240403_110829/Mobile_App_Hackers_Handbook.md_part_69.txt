Treat the use of any other algorithms for password-based key generation as a security issue; apps should not
attempt to “roll their own” cryptography-related code, in general, and should avoid using other peoples’
attempts, no matter how complex or secure the algorithm may look.
In addition to simply using an industry-standard key generation algorithm in applications, you must consider
another important factor to ensure secure applications; password policy. Even if the app uses PBKDF2 with a
high iteration count, if the password were something like “aaaa”, then a dictionary attack will usually succeed
quite quickly. To prevent users from undermining the security of their own data, apps encrypting sensitive data
should enforce a password policy. Reasonable complexity guidelines that allow a middle ground between
security and usability include the following:
Have at least eight characters
Use both uppercase and lowercase characters
Include one number
Include one special character
When an app is encrypting, storing, or transferring sensitive data, you should consider the failure to implement
a password policy to be a security issue.
Chapter 13 provides a discussion on the implementation of secure password hashing.
Use of Weak Cryptography Algorithms, Modes, and Key Lengths
Even when keys are well generated and managed, encrypted data can be at risk due to the choice of cryptography
algorithm; some algorithms have simply been proven to be insecure, or were not intended for encryption of
sensitive data in the first place.
Many encryption algorithms are not actually fit for protecting sensitive information, but we’ll discuss a few that
are used, and should not be. These include DES Data Encryption Standard (DES), RC4, AES in ECB Electronic
Codebook (ECB) mode, and obviously XOR encryption schemes.
Data Encryption Standard (DES)
DES uses a key length of 56-bits, giving a search space of 256 different keys. With modern computing power,
cracking a piece of a DES key is completely feasible. Known Plaintext and Chosen Plaintext attacks have also
been shown to be possible, which could further reduce the time necessary to crack a DES key, when a very large
number of plaintexts are available (http://en.wikipedia
.org/wiki/Data_Encryption_Standard#Attacks_faster_than_brute-force). Further information is available
online, such as at the DES Wikipedia page at http://en.wikipedia.org/wiki/Data_Encryption_Standard.
Simply put, for storing sensitive data, avoid DES. Consider the use of it for sensitive data to be a bug.
Spotting the use of DES in a code review is generally simple: Look for use of the DESCryptoServiceProvider, or
its base class, System.Security.Cryptography.DES. Other third-party libraries, such as BouncyCastle, could
potentially be used; spotting DES use should be simple in these cases, as well.
AES in ECB Mode
AES has a number of different modes, including ECB Electronic Codebook (ECB), Cipher Block Chaining (CBC),
and counter mode (CTR).
In short, ECB treats each block independently from all other blocks, so identical blocks of plaintext are
encrypted into identical blocks of ciphertext every time. This makes pattern analysis attacks on encrypted data
blobs possible.
The best demonstration of the dangers of using AES in ECB mode is via the classic “Tux the Penguin” case
study. When a TIFF image of Tux the Penguin was encrypted using AES in ECB mode, pattern analysis attacks
on the resulting ciphertext allowed the basic outline of the original image to be recovered. See the original image
in Figure 12.3.
Figure 12.3 Original image of the Linux mascot, Tux the Penguin
Compare this to the recovered image in Figure 12.4, which shows the general outline and even some details
possessed by the original Tux the Penguin image.
Figure 12.4 Recovered image of Tux the Penguin
It should be evident from these two images that AES in ECB mode should not be used for storing sensitive data.
Use of AES in ECB mode is easily spotted; look for the use of the System .Security.Cryptography.Aes class, or
its two subclasses System.Security .Cryptography.AesCryptoServiceProvider and System.Security
.Cryptography.AesManaged.
All three of these classes have a property named Mode property. If Mode is set to CipherMode.ECB, ECB mode will
be used.
Other Weak Algorithms
A number of other weak algorithms are in fairly common usage that should not be used for the protection of
sensitive data, some of which include
XOR schemes
Tiny Encryption Algorithm (TEA)
RC4
Use of any other “homegrown” or otherwise little-known algorithms probably represents a security issue. Apps
dealing with sensitive data should stick to the industry-strength algorithms such as AES (in modes other than
ECB).
Minimum Public-Private Key Length
At the time of this writing, the recommended RSA key length when using public-private key asymmetric
encryption is 2048. You should consider the use of 1024-bit keys to be against security best practices, and be
concerned about the use of 512-bit keys.
Use of Static Initialization Vectors
Every block cipher mode besides ECB uses what is known as an Initialization Vector (IV). The high-level
purpose of an IV is to ensure that encryption results vary every time; that is, when identical blocks of data are
encrypted with the same key, use of a different IV means that the resulting ciphertext will be different in each
case.
This means that apps using non-ECB modes for block encryption should never use hard-coded IVs, and IVs
should be randomly generated to ensure their uniqueness. Using predictable or hard-coded IVs allows Chosen
Plaintext attacks. To read more details on Chosen Plaintext attacks, the following URL may be of interest:
http://cryptography.stackexchange.com/questions/1312/using-a-non-random-iv-with-modes-other-than-
cbc/1314#1314.
IVs do not need to be secret. In fact, they cannot be, because they are needed to decrypt an encrypted blob. They
simply need to be unique to prevent Chosen Plaintext attacks on encrypted data.
Use of a hard-coded IV constitutes a security vulnerability, as does generation of an IV using an insecure
random number generator such as System.Random; for example:
char[] iv = { 0x10, 0x20, 0x30, 0x40, 0x45, 0x78, 0x65, 0x61, 0x62,
0x43, 0x69, 0x35, 0x32, 0x15, 0x20, 0x50 };
The preceding in cryptography code (an AES-256, for example) would be cause for concern because the IV is
completely static, as would the following:
Random rnd = new Random(); // uptime in milliseconds as seed
byte[] iv = new byte[16];
rnd.NextBytes(iv);
because iv may be predictable given the flawed nature of System.Random.
Both of the preceding examples are contrary to cryptography best practices.
You should generate IVs using a cryptographically secure random number generator. (See Chapter 13 for more
information on the secure generation of IVs.)
Data Protection API Misuse on Windows Phone
The Data Protection API, or DPAPI, is a cryptographic API provided by Windows for the purpose of encrypting
arbitrary data blobs. DPAPI is used by a large number of third-party and Microsoft applications and frameworks.
Microsoft uses DPAPI in the following pieces of software and use cases, to name a few examples:
Filesystem encryption
Internet Explorer autocomplete settings
Outlook credentials
Wireless passwords
DPAPI is also available on the Windows Phone 8.x platforms, in addition to standard Windows. DPAPI is
recommended by Microsoft as a standard way of encrypting and decrypting data on the Windows platforms.
DPAPI exposes two native interfaces: one for encrypting data, and one for decrypting data. Namely, these APIs
are CryptProtectData()and CryptUnprotectData(). These are native methods and have the following function
prototypes,
BOOL WINAPI CryptProtectData(
_In_ DATA_BLOB *pDataIn,
_In_ LPCWSTR szDataDescr,
_In_ DATA_BLOB *pOptionalEntropy,
_In_ PVOID pvReserved,
_In_opt_ CRYPTPROTECT_PROMPTSTRUCT *pPromptStruct,
_In_ DWORD dwFlags,
_Out_ DATA_BLOB *pDataOut
);
and:
BOOL WINAPI CryptUnprotectData(
_In_ DATA_BLOB *pDataIn,
_Out_opt_ LPWSTR *ppszDataDescr,
_In_opt_ DATA_BLOB *pOptionalEntropy,
_Reserved_ PVOID pvReserved,
_In_opt_ CRYPTPROTECT_PROMPTSTRUCT *pPromptStruct,
_In_ DWORD dwFlags,
_Out_ DATA_BLOB *pDataOut
);
.NET exposes interfaces for calling into DPAPI from C#, VB, and F# via the ProtectedData class. The
ProtectedData class exposes two methods: Protect() and Unprotect(). As expected, Protect() accepts plaintext
data and returns ciphertext data, and Unprotect() accepts ciphertext and returns plaintext data. DPAPI itself
does not actually store data; it just encrypts (or decrypts) it and returns the data back to the caller.
The Protect() and Unprotect() APIs have the following prototypes on Windows Phone,
public static byte[] Protect(
byte[] userData,
byte[] optionalEntropy,
)
and:
public static byte[] Unprotect(
byte[] encryptedData,
byte[] optionalEntropy,
)
In both cases, optionalEntropy is an optional parameter for specifying a secondary credential.
DPAPI on the Windows desktop and server versions create per-user master cryptography keys so that apps
running under one user on the system cannot decrypt data protected by an app running under another user
account.
However, on Windows Phone devices, because all apps are running under the same user (PROTOCOLS), one
master cryptography key is used for all third-party apps calling into DPAPI for encryption and decryption. The
keys are stored at the following path: C:\Data\Users\DefApps\APPDATA\ROAMING\MICROSOFT\Protect\.
The fact that all data protected by DPAPI on Windows Phone is encrypted using the same key for all apps
presents a security problem. If an attacker on the device or malicious app is able to get access to a DPAPI-
encrypted data blob, and the target app did not use an optionalEntropy parameter, he can recover the data
simply by calling into ProtectedData.Unprotect().
For example, consider an app on a device that encrypted data using DPAPI, like code such as the following. Note
the absence of the optionalEntropy parameter, where null is simply passed in instead:
byte[] encryptedData = ProtectedData.Protect(secretData, null);
If a malicious app on the device gained access to the outputted data, the following line of code would allow
decryption:
byte[] plaintextData = ProtectedData.Unprotect(encryptedData, null);
This scenario could clearly present a problem; disclosure of an encrypted blob could be decrypted by another app
on the device.
The solution to this problem is to use the optionalEntropy parameter when using ProtectedData.Protect(), so
that the app can pass in a secondary credential:
byte[] encryptedData = ProtectedData.Protect(secretData, secondarySecret);
If a malicious app on the device then attempted to decrypt the stolen data using ProtectedData.Unprotect(), it
would need to know secondarySecret to be successful.
As a result, you should always use the optionalEntropy parameter if you want to use DPAPI in your apps. Apps
should not, however, hard-code this value or otherwise store it on the device, because this would allow attackers
with filesystem access to attack the data somewhat easily. If you intend to use DPAPI in your apps, you should
base it on a secret passphrase known only by the app user—for example, the output of PBKDF2 on a password
only the user knows), and not based on hard-coded or determinable values.
In general, though, implementing cryptography using the standard APIs may be advisable instead, using a secret
key derivable from a user-known secret. (See Chapter 13 for our recommendations.) In addition to using
standard CryptoAPI calls to safely encrypt sensitive data for storage, we also give an example of how to use
DPAPI with the optionalEntropy parameter.
Identifying Native Code Vulnerabilities
Apps running on Windows Phone 8 and above are capable of using native code (that is, C and C++ code). The
use of native code in Windows Phone apps is not especially common; nonetheless some apps call into native
code, generally for one or more of the following reasons:
Code reuse/portability—If an app component (for example, a parser) has already been written in C++,
reusing the codebase for a Windows Phone version of an app without having to rewrite it (for example, in
C#) makes sense.
Graphics—Many Windows Phone games (and other apps) need more direct access to graphics rendering
using Direct3D. This can only be done in native code (that is, C++), at the time of writing.
Performance—Some apps have performance-critical components, and so leverage native code to gain speed
advantages.
The three main ways of using native code in Windows Phone apps are:
Writing a purely native app—For example, a C++ game for Windows Phone.
By writing a native Windows Phone Runtime Component (WinPRT) to call into your native
library—Internally, this uses PInvoke.
By using the[DllImport]attribute—This only works on Windows Phone 8.1, not Windows Phone 8.
Internally, [DllImport] uses PInvoke.
No matter how an app runs native code, any memory protections that a managed language offered (that is, C#)
are no longer there to protect the app. For example, if managed C# code calls into unmanaged C++ code, the app
now becomes vulnerable to memory corruption bugs (for example) in the same way that an app written in pure
C++ would be.
If the source code to the native module is not available to you, you can extract the binary from the app’s Install
directory, and then reverse engineer it using reverse engineering tools of your choice, although we recommend
IDA Pro. The Hex-Rays decompiler plug-in for IDA Pro is relatively proficient at producing pseudo-code from a
reversed native binary, so you may wish to have the Hex-Rays decompiler in your toolbox as well, since reading
pseudo-code is often much more efficient than reviewing ARM assembly, especially in complex modules.
An introduction to reverse engineering native ARM binaries is beyond the scope of this book, so we assume that
if you have to reverse engineer native modules, that you are familiar with the methodologies involved in doing
so.
The rest of this section covers how to spot native code vulnerabilities, and we also explain briefly each bug
classification and why it can be dangerous. This section is not an introduction to native code and its
vulnerabilities. Instead, we assume you are already familiar with native code in general, and we mainly aim to
point out API use and coding patterns that may lead to native code vulnerabilities in the context of Windows
Phone apps.
Stack Buffer Overflows
Stack-based buffer overflows occur when an application attempts to copy data into a fixed-length stack buffer
without carrying out boundary checks; that is, without first ensuring that the destination buffer is large enough
to house all the data being copied.
Needless to say, if the data chunk being copied is larger than the destination stack buffer, excess data will
overrun the end of the stack buffer, and unintended data on the stack will be overwritten. Overwritten data may
include pointers and program metadata, including saved return addresses. Having the ability to overwrite
unintended stack data has made the possibility of taking control of program execution flow possible, in many
cases allowing execution of attacker-controlled code. Exploit mitigation features have often made exploitation of
stack overflow conditions somewhat more difficult in recent years, but many stack corruption vulnerabilities are
still exploitable, and all stack overflow bugs should be considered as such.
Quite a number of APIs have been responsible for stack overflow vulnerabilities in the past and in the present.
Some of these are:
strcpy()
gets()
sprint()
strcat()
vsprintf()
scanf()
sscanf()
memcpy()
bcopy()
This list is not an extensive list of all APIs that do not carry out bounds checking. When you are in doubt, a
Google search of the API in question is likely to provide ample information about the safety of the function and
both how it can be abused and how it can be used safely.
Spotting stack overflow vulnerabilities is often quite easy. In general, you’re looking for data copying operations
that do not carry out boundary checks on the destination buffer or copying operations that blindly trust an
attacker-supplied length, and in both cases, the developer has not made sure that the destination buffer is large
enough to hold the data being copied.
For example, the following code fragment is obviously vulnerable to stack corruption in its use of strcpy() to
copy into a buffer, destBuffer, that is declared on the program stack:
char destBuffer[32];
char attackerControlledData[200];
[ ... ]
int ret = ReadDataFromWire(&attackerControlledData[0]);
strcpy(destBuffer, attackerControlledData);
Because the strcpy() API does not carry out any boundary checks on the destination buffer, the API will
continue copying from attackerControlledData until a NULL byte is encountered. Clearly, if the data in
attackerControlledData is longer than 32 bytes, a stack overflow will occur as the bounds of destBuffer are
breached.
The following code, which uses sprintf(), would also be vulnerable to a similar stack overflow vulnerability,
because sprintf() doesn’t perform bounds checking (unless a maximum number of characters is supplied with
the %s format specifier; that is, %32s):
char destBuffer[32];
char attackerControlledData[200];
[ ... ]
int ret = ReadDataFromWire(&attackerControlledData[0]);
sprint(destBuffer, "%s", attackerControlledData);
Some badly written code also accepts a user-supplied length and insecurely trusts it to use as a length, while
parsing data:
char destBuffer[32];
[ ... ]
unsigned int len = ReadLengthFromBlob(attackerControlledData);
unsigned char *ptr = ReadPayloadPosition(attackerControlledData);
memcpy(destBuffer, ptr, len);
Stack buffer overflows may also occur in hand-rolled copying loops; for example:
char destBuffer[32];
unsigned char *ptr = &attackerControlledBuf[0];
for(int i = 0; *ptr; ptr++, i++) {
destBuffer[i] = *ptr++;
}
The previous code is similar to a strcpy(). Bytes are copied from attackerControlledBuf until a NULL byte is
found. If the source buffer, attackerControlledBuf, does not contain any NULL bytes before 32 bytes have been
copied, a stack buffer overflow will occur.