through reducing the bandwidth usage. §2.4 will highlight the
deployment settings in which the total costs of a video analytics
system are dominated by the network cost and thus reducing
bandwidth usage is crucial. We measure the bandwidth usage by
the size of the sent video divided by its duration.
• Average response delay (freshness): Finally, we define freshness by
the average processing delay per object (or per pixel for semantic
segmentation), i.e., the expected time between when an object
(or a pixel) first appears in the video feed and when its region is
detected and correctly classified, which includes the time to send
it to the server and to run inference on it.2
2.2 Design space of video analytics systems
Next, we discuss the design space of how video analytics systems
can potentially navigate the tradeoffs among these performance
metrics along five dimensions:
• Leveraging camera-side compute power: Since the camera can
naturally access the raw video, one can leverage the camera’s
local compute power (if any) to discard frames [30, 48] or re-
gions [54, 80] that may not contain important information. As
we will elaborate in §2.3, the accuracy of such local filtering
heuristics may cause significant accuracy drops.
• Model distillation: DNNs are often trained on large datasets, but
when used exclusively for a specific category of video scenes, a
DNN can be shrunk to a much smaller size (e.g., via knowledge
distillation), in order to save compute cost (GPU cycles) without
hurting accuracy (e.g., [48]). This approach is efficient only in
training smaller DNNs that work well on less expensive hardware.
2Average response delay is meaningful if the follow-up analysis can by updated when
a new objects/pixel is detected/classified (e.g., estimating the average speed of vehicles
on a road). That said, this definition does not apply to applications that are sensitive
to worst-case delays rather than average delay, e.g., if one queries for the total number
of vehicles, the answer will not be completed until all vehicles are detected.
Figure 2: Unlike video streaming for human viewers, machine-centric
video streaming has unique bandwidth-saving opportunities.
• Video codec optimization: Unlike traditional video codecs that
optimize for human visual quality, video analytics emphasizes in-
ference accuracy and thus opens up possibility to more analytics-
oriented video codecs (e.g., analytics-aware super resolution [76]).
• Temporal configuration adaptation: To cope with the temporal
variance of video content, one can adapt the key configurations
(e.g., the frame rate, resolution and DNN model) to save compute
costs [45] or network costs [78]. That said, it fails to exploit the
uneven spatial distribution of important information in videos.
• Spatial quality adaptation: Information of interest (e.g., target
objects) is sparsely distributed in each frame, so some pixels are
more critical to accurate DNN inference than others. One can
save bandwidth usage by encoding each frame with a spatially
uneven quality distribution (e.g., region-of-interest encoding [54])
so that high video quality is used only where pixels are critical
to DNN inference [54, 80].
In this paper, we take a pragmatic stance to focus on a specific point
in the design space—no camera-side frame-dropping heuristics, no
model distillation (use the server-side DNN as-is), and no change
to the video codec; instead, we use the server-side DNN output to
drive spatial quality adaptation.
2.3 Potential room for improvement
Traditional video streaming maximizes human quality of experi-
ence (QoE)—a high video resolution and smooth playback (min-
imum stalls, frame drops or quality switches) [35, 46, 50]. For
machine-centric video streaming, however, it is crucial that the
server-received video has sufficient video quality in the regions
that heavily affect the DNN’s ability to identify/classify objects;
however, the received video does not have to be smooth or have
high quality everywhere.
This contrast has a profound implication—machine-centric stream-
ing could achieve high “quality” (i.e., accuracy) using much less
bandwidth. Each frame can be spatially encoded with non-uniform
quality levels. In object detection, for instance, one may give low
quality to (or even blackout) the areas other than the objects of
interest (Figure 2(b))3. While rarely used in traditional video stream-
ing, this scheme could significantly reduce bandwidth consumption
and response delay, especially because objects of interest usually
only occupy a fraction of the video size. Figure 3 shows that across
3This may look like region-of-interest (ROI) encoding [59], but even ROI encoding
does not completely remove the background either, and the ROIs are defined with
respect to human perception.
559
(a) Video streaming for human viewers(b) Video streaming for computer-vision analyticsSource(Video server)Human ViewerSource(Camera)Server(DNN)SIGCOMM ’20, August 10–14, 2020, Virtual Event, USA
K. Du, A. Pervaiz, X. Yuan, A. Chowdhery, Q. Zhang, H. Hoffmann, J. Jiang
Figure 3: Bandwidth-saving opportunities: Over 50-80% of frames,
the objects (cars or pedestrians) occupy less than 20% of the frame area,
so most pixels do not contribute to the accuracy of video analytics.
three different scenarios (the datasets will be described in §5.1),
in 50-80% of frames, the objects of interest (cars or pedestrians)
only occupy less than 20% of the spatial area of a frame. We also
observe similar uneven distributions of important pixels in face
recognition and semantic segmentation. The question then is how
to fully explore the potential room for improvement?
2.4 Preliminary comparison of existing solutions
We present a framework to compare the performance, in accuracy,
total cost, and response delay, of four baselines: camera-side lo-
cal inference (“Camera-only”), server-side inference (“AWStream”),
and selecting frames/regions by the camera and sending them to
server for further analysis (“Vigil” and “Glimpse”). We then analyze
the sources of their (suboptimal) performance in §2.5. The tests
are performed on the traffic videos in our dataset (§5.1). We will
give more details about their implementations and include more
baselines in the full evaluation (§5).
For each solution 𝑠, we use a fixed camera-side logic 𝐿𝑜𝑐𝑎𝑙𝑠
and a fixed server-side DNN 𝑅𝑒𝑚𝑜𝑡𝑒𝑠. We use 𝑃𝑠 to denote the
data (frames or videos, depending on the solution) sent from the
camera to the server. They together determine the accuracy of 𝑠:
𝐴𝑐𝑐(𝐿𝑜𝑐𝑎𝑙𝑠, 𝑅𝑒𝑚𝑜𝑡𝑒𝑠, 𝑃𝑠).4 Note that 𝑃𝑠 is tunable by changing the
internal configurations of 𝑠, and with fixed 𝐿𝑜𝑐𝑎𝑙𝑠 and 𝑅𝑒𝑚𝑜𝑡𝑒𝑠, the
cost-delay-accuracy tradeoff of 𝑠 will be governed by 𝑃𝑠. We use
the same server-side DNN (FasterRCNN-ResNet101) to make sure
the accuracies are calculated with the same ground truth.
Figure 4a shows the delay-accuracy tradeoffs of the four solutions
(and our solution which will be introduced in next section). Here,
the delay is the average response delay per frame as measured in
our testbed. (We explain the hardware choice in §5.1.) Note that the
local model running on the camera (“Camera-only”) has relatively
lower accuracy than Vigil (which uses both the local DNN and the
server DNN) and AWStream (which fully relies on the server DNN
results). We will explain the reasons in §2.5.
Figure 4b and Figure 4c show the costs to achieve their respective
performance in Figure 4a under two price settings. We measure
the cost by the average total cost of analyzing a 720p HD video at
30FPS (∼5Mbps) for an hour.
• Setting 1 (Total cost is dominated by network): A camera is con-
nected to an in-house server through an LTE network. Since
the camera and the server are purchased upfront, their costs
amortized per frame will approach zero in the long run, but the
LTE cost is paid by time. Here, we consider the AT&T 4G LTE
4Of course, the value 𝑃𝑠 and accuracy are video-dependent, but we omit it for simplicity
since we compare solutions on the same videos.
(a) Delay-accuracy
(b) Cost vs accuracy
(Setting 1)
(c) Cost vs accuracy
(Setting 2)
Figure 4: The trade-offs among cost, delay, and accuracy on the
traffic videos in our dataset under two settings. The cost in setting 1
is dominated by the network cost, so schemes that save bandwidth
usage are more favorable. The cost in setting 2 is dominated by the
server cost, so saving bandwidth does not yield better solutions.
plan, $50 per month [3] for 30GB data (before the speed drops
to measly 128kbps) [10], or equivalently $0.75 for streaming at
1Mbps for one hour. Thus, the per-hour total cost of a solution 𝑠
is 𝐶𝑜𝑠𝑡𝑠 ≈ $0.75 · 𝑆𝑖𝑧𝑒(𝑃𝑠), where 𝑆𝑖𝑧𝑒(𝑃) is the total bandwidth
usage (in Mbps) to send 𝑃.
• Setting 2 (Total cost is dominated by server): A camera is connected
to a cloud server through cheap wired network. Unlike the previ-
ous setting, the cloud server is paid by usage so its cost grows
with more server-side compute, but the network cost is negli-
gible compared to 4G LTE plans. To run the server-side DNN
at 30FPS, we assume that we need 3 NVIDIA Telsa K80 cards
and it costs $0.405 per hour [11] (and other cloud providers have
similar price ranges). The per-hour total cost of 𝑠, therefore, is
𝐶𝑜𝑠𝑡𝑠 ≈ $0.405·𝐹𝑟𝑎𝑐(𝑃𝑠), where 𝐹𝑟𝑎𝑐(𝑃) is the number of frames
in 𝑃 divided by all frames.
In the first setting (Figure 4b, where the total cost is dominated by
the network cost), prior solutions show unfavorable cost-accuracy
tradeoffs (when compared with our solution). However, in the sec-
ond setting (Figure 4c, where the total cost is dominated by the
server cost), prior solutions in general strike good cost-accuracy
tradeoffs (compared with ours). This is largely because some of
them (Vigil and Glimpse) are designed to minimize server-side
compute cost, which this paper does not explicitly optimize.
2.5 Sources of the limitations
Existing solutions for video streaming are essentially source-driven—
the decisions of which pixels/frames should be compressed and sent
to the server are made by the source (camera), with little real-time
feedback from the server-side DNN that analyzes the video. The
fundamental issue of source-driven protocol is that any heuristic
that fits camera’s limited compute capacity is hard to precisely
identify the minimum information that is needed by the server-side
DNN to achieve high accuracy. The result is a unfavorable trade-
off between bandwidth and accuracy (e.g., Figure 4b): any gain of
accuracy comes at the cost of considerably more bandwidth usage.
This problem manifests itself differently in two types of source-
driven solutions. The first type is uniform-quality streaming, which
modifies the existing video protocols and adapts the quality level
to maximize inference accuracy under a bandwidth constraint. For
instance, AWStream [78] uses DASH/H.264 and periodically re-
profiles the relationship between inference accuracy and video
quality. CloudSeg [76] sends a video at a low quality but upscales
the video using super resolution on the server. They have two
limitations. First, they do not leverage the uneven distribution of
560
0.00.51.0Delay (s)0.00.51.0AccuracyDDS (ours)AWStreamVigilGlimpseCamera-only0246Cost ($)0.00.51.0AccuracyDDS (ours)AWStreamVigilGlimpseCamera-only0.00.51.0Cost ($)0.00.51.0AccuracyDDS (ours)AWStreamVigilGlimpseCamera-onlyServer-Driven Video Streaming for Deep Learning Inference
SIGCOMM ’20, August 10–14, 2020, Virtual Event, USA
Figure 5: Contrasting the inference results between a cheap model
(SSD-MobileNet-v2) and a compute-intensive model (FasterRCNN-
ResNet101) on the same image. The compute-intensive model is more
accurate when the video content is challenging (e.g., having many
small objects).
important pixels; instead, the videos are encoded by traditional
codecs with the same quality level on each frame. Second, while
they get feedback from the server DNN, it is not based on real-time
video content, so it cannot suggest actions like increasing quality
on a specific region in the current frame.
The second type is camera-side heuristics that identifies impor-
tant pixels/regions/frames that might contain information needed
by the server-side analytics engine (e.g., queried objects) by running
various local heuristics (e.g., checking significant inter-frame differ-
ence [30, 54], a cheap vision model [31, 32, 48, 80]), or some DNN
layers [36, 72]. These solutions essentially leverage the camera-side
compute power to save server compute cost and network cost [36].
However, these cheap camera-side heuristics are inherently less
accurate than the more complex DNN models on the server, es-
pecially when the video content is challenging (e.g., consisting of
many small objects, which is typical for drone and traffic videos,
as illustrated in Figure 5). Any false negatives of these camera-side
heuristics will preclude the server from detecting important infor-
mation; any false positives (e.g., pixel changes on the background)
will cost unnecessary bandwidth usage.
3 DNN-DRIVEN VIDEO STREAMING
In this section, we present the design of DDS and discuss its design
rationale and performance tradeoffs.
3.1 Overall workflow
We explore an alternative approach, called DNN-driven stream-
ing (DDS). In DDS, the compression and streaming behaviors are
driven by the feedback judiciously generated by the server-side
DNN, rather than the low-complexity local heuristics on the camera
side, in order to capture what the analytics engine needs from the
real-time video content. Figure 6 contrasts the workflow of DDS
with that of the traditional source-driven approach: source-driven
streaming is “single-shot” (i.e., camera using simple heuristics to de-
termine how the video should be streamed out), but DDS is iterative
and logically contains two streams:
• Stream A (passive, low quality): The camera continuously
• Stream B (feedback-driven): The server frequently (e.g., every
handful of frames) extracts the feedback regions from the DNN
outputs on the Stream A video and sends them back to the camera
as feedback. Upon receiving the feedback from the server, the
camera then re-encodes the recent history video accordingly
sends the video in low quality to the server.
Figure 6: Contrasting the new real-time DNN-driven streaming (it-
erative) with traditional video streaming in video analytics.
and sends it to the server for a second-round inference on these
“zoomed-in” images.
The key to DDS’s success is the design of the feedback regions,
which we discuss next.
3.2 Feedback regions
High-level framework: DDS extracts the feedback regions by uti-
lizing the information naturally returned/generated by the server-
side DNN, rather than a wholesale change on the DNN architecture.
To deal with a variety of DNNs with different outputs, DDS uses
a custom logic to extract feedback regions from each DNN. But
these logics share the same framework (explained next) and are
integrated with DNNs using a similar interface (explained in §4.1).
For convenience, we use the term “elements” to denote the unit of