title:Take A Way: Exploring the Security Implications of AMD's Cache Way
Predictors
author:Moritz Lipp and
Vedad Hazic and
Michael Schwarz and
Arthur Perais and
Cl&apos;ementine Maurice and
Daniel Gruss
Take A Way: Exploring the Security Implications of
AMD’s Cache Way Predictors
Moritz Lipp, Vedad Hadžić, Michael Schwarz, Arthur Perais, Clémentine
Maurice, Daniel Gruss
To cite this version:
Moritz Lipp, Vedad Hadžić, Michael Schwarz, Arthur Perais, Clémentine Maurice, et al.. Take A
Way: Exploring the Security Implications of AMD’s Cache Way Predictors. 15th ACM ASIA Con-
ference on Computer and Communications Security (ACM ASIACCS 2020), 2020, Taipei, Taiwan.
10.1145/3320269.3384746. hal-02866777
HAL Id: hal-02866777
https://hal.inria.fr/hal-02866777
Submitted on 12 Jun 2020
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Take A Way: Exploring the Security Implications of AMD’s
Cache Way Predictors
Moritz Lipp
Graz University of Technology
Vedad Hadžić
Graz University of Technology
Arthur Perais
Unaffiliated
Clémentine Maurice
Univ Rennes, CNRS, IRISA
Michael Schwarz
Graz University of Technology
Daniel Gruss
Graz University of Technology
ABSTRACT
To optimize the energy consumption and performance of their
CPUs, AMD introduced a way predictor for the L1-data (L1D) cache
to predict in which cache way a certain address is located. Conse-
quently, only this way is accessed, significantly reducing the power
consumption of the processor.
In this paper, we are the first to exploit the cache way predic-
tor. We reverse-engineered AMD’s L1D cache way predictor in
microarchitectures from 2011 to 2019, resulting in two new attack
techniques. With Collide+Probe, an attacker can monitor a vic-
tim’s memory accesses without knowledge of physical addresses
or shared memory when time-sharing a logical core. With Load+
Reload, we exploit the way predictor to obtain highly-accurate
memory-access traces of victims on the same physical core. While
Load+Reload relies on shared memory, it does not invalidate the
cache line, allowing stealthier attacks that do not induce any last-
level-cache evictions.
We evaluate our new side channel in different attack scenarios.
We demonstrate a covert channel with up to 588.9 kB/s, which we
also use in a Spectre attack to exfiltrate secret data from the kernel.
Furthermore, we present a key-recovery attack from a vulnerable
cryptographic implementation. We also show an entropy-reducing
attack on ASLR of the kernel of a fully patched Linux system, the
hypervisor, and our own address space from JavaScript. Finally, we
propose countermeasures in software and hardware mitigating the
presented attacks.
CCS CONCEPTS
• Security and privacy → Side-channel analysis and counter-
measures; Operating systems security.
ACM Reference Format:
Moritz Lipp, Vedad Hadžić, Michael Schwarz, Arthur Perais, Clémentine
Maurice, and Daniel Gruss. 2020. Take A Way: Exploring the Security
Implications of AMD’s Cache Way Predictors. In Proceedings of the 15th
ACM Asia Conference on Computer and Communications Security (ASIA CCS
’20), June 1–5, 2020, Taipei, Taiwan. ACM, New York, NY, USA, 13 pages.
https://doi.org/10.1145/3320269.3384746
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS ’20, June 1–5, 2020, Taipei, Taiwan
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6750-9/20/06...$15.00
https://doi.org/10.1145/3320269.3384746
1 INTRODUCTION
With caches, out-of-order execution, speculative execution, or si-
multaneous multithreading (SMT), modern processors are equipped
with numerous features optimizing the system’s throughput and
power consumption. Despite their performance benefits, these op-
timizations are often not designed with a central focus on security
properties. Hence, microarchitectural attacks have exploited these
optimizations to undermine the system’s security.
Cache attacks on cryptographic algorithms were the first mi-
croarchitectural attacks [12, 42, 59]. Osvik et al. [58] showed that
an attacker can observe the cache state at the granularity of a cache
set using Prime+Probe. Yarom et al. [82] proposed Flush+Reload,
a technique that can observe victim activity at a cache-line granu-
larity. Both Prime+Probe and Flush+Reload are generic techniques
that allow implementing a variety of different attacks, e.g., on cryp-
tographic algorithms [12, 15, 50, 54, 59, 63, 66, 82, 84], web server
function calls [85], user input [31, 48, 83], and address layout [25].
Flush+Reload requires shared memory between the attacker and
the victim. When attacking the last-level cache, Prime+Probe re-
quires it to be shared and inclusive. While some Intel processors
do not have inclusive last-level caches anymore [81], AMD always
focused on non-inclusive or exclusive last-level caches [38]. With-
out inclusivity and shared memory, these attacks do not apply to
AMD CPUs.
With the recent transient-execution attacks, adversaries can di-
rectly exfiltrate otherwise inaccessible data on the system [41, 49,
68, 74, 75]. However, AMD’s microarchitectures seem to be vul-
nerable to only a few of them [9, 17]. Consequently, AMD CPUs
do not require software mitigations with high performance penal-
ties. Additionally, with the performance improvements of the latest
microarchitectures, the share of AMD CPU’s used is currently in-
creasing in the cloud [10] and consumer desktops [34].
Since the Bulldozer microarchitecture [6], AMD uses an L1D
cache way predictor in their processors. The predictor computes a
µTag using an undocumented hash function on the virtual address.
This µTag is used to look up the L1D cache way in a prediction
table. Hence, the CPU has to compare the cache tag in only one
way instead of all possible ways, reducing the power consumption.
In this paper, we present the first attacks on cache way predictors.
For this purpose, we reverse-engineered the undocumented hash
function of AMD’s L1D cache way predictor in microarchitectures
from 2001 up to 2019. We discovered two different hash functions
that have been implemented in AMD’s way predictors. Knowledge
of these functions is the basis of our attack techniques. In the
first attack technique, Collide+Probe, we exploit µTag collisions of
ASIA CCS ’20, June 1–5, 2020, Taipei, Taiwan
Lipp, et al.
virtual addresses to monitor the memory accesses of a victim time-
sharing the same logical core. Collide+Probe does not require shared
memory between the victim and the attacker, unlike Flush+Reload,
and no knowledge of physical addresses, unlike Prime+Probe. In the
second attack technique, Load+Reload, we exploit the property that
a physical memory location can only reside once in the L1D cache.
Thus, accessing the same location with a different virtual address
evicts the location from the L1D cache. This allows an attacker to
monitor memory accesses on a victim, even if the victim runs on a
sibling logical core. Load+Reload is on par with Flush+Reload in
terms of accuracy and can achieve a higher temporal resolution
as it does not invalidate a cache line in the entire cache hierarchy.
This allows stealthier attacks that do not induce last-level-cache
evictions.
We demonstrate the implications of Collide+Probe and Load+
Reload in different attack scenarios. First, we implement a covert
channel between two processes with a transmission rate of up to
588.9 kB/s outperforming state-of-the-art covert channels. Second,
we use µTag collisions to reduce the entropy of different ASLR
implementations. We break kernel ASLR on a fully updated Linux
system and demonstrate entropy reduction on user-space appli-
cations, the hypervisor, and even on our own address space from
sandboxed JavaScript. Furthermore, we successfully recover the
secret key using Collide+Probe on an AES T-table implementation.
Finally, we use Collide+Probe as a covert channel in a Spectre attack
to exfiltrate secret data from the kernel. While we still use a cache-
based covert channel, in contrast to previous attacks [41, 44, 51, 70],
we do not rely on shared memory between the user application and
the kernel. We propose different countermeasures in software and
hardware, mitigating Collide+Probe and Load+Reload on current
systems and in future designs.
Contributions. The main contributions are as follows:
(1) We reverse engineer the L1D cache way predictor of AMD
CPUs and provide the addressing functions for virtually all
microarchitectures.
(2) We uncover the L1D cache way predictor as a source of
side-channel leakage and present two new cache-attack tech-
niques, Collide+Probe and Load+Reload.
(3) We show that Collide+Probe is on par with Flush+Reload
and Prime+Probe but works in scenarios where other cache
attacks fail.
(4) We demonstrate and evaluate our attacks in sandboxed
JavaScript and virtualized cloud environments.
Responsible Disclosure. We responsibly disclosed our findings to
AMD on August 23rd, 2019.
Outline. Section 2 provides background information on CPU
caches, cache attacks, way prediction, and simultaneous multi-
threading (SMT). Section 3 describes the reverse engineering of the
way predictor that is necessary for our Collide+Probe and Load+
Reload attack techniques outlined in Section 4. In Section 5, we
evaluate the attack techniques in different scenarios. Section 6 dis-
cusses the interactions between the way predictor and other CPU
features. We propose countermeasures in Section 7 and conclude
our work in Section 8.
2 BACKGROUND
In this section, we provide background on CPU caches, cache at-
tacks, high-resolution timing sources, simultaneous multithreading
(SMT), and way prediction.
2.1 CPU Caches
CPU caches are a type of memory that is small and fast, that the
CPU uses to store copies of data from main memory to hide the
latency of memory accesses. Modern CPUs have multiple cache
levels, typically three, varying in size and latency: the L1 cache is
the smallest and fastest, while the L3 cache, also called the last-level
cache, is bigger and slower.
Modern caches are set-associative, i.e., a cache line is stored in a
fixed set determined by either its virtual or physical address. The L1
cache typically has 8 ways per set, and the last-level cache has 12 to
20 ways, depending on the size of the cache. Each line can be stored
in any of the ways of a cache set, as determined by the replacement
policy. While the replacement policy for the L1 and L2 data cache
on Intel is most of the time pseudo least-recently-used (LRU) [1],
the replacement policy for the last-level cache (LLC) can differ [79].
Intel CPUs until Sandy Bridge use pseudo least-recently-used (LRU),
for newer microarchitectures it is undocumented [79].
The last-level cache is physically indexed and shared across cores
of the same CPU. In most Intel implementations, it is also inclusive
of L1 and L2, which means that all data in L1 and L2 is also stored
in the last-level cache. On AMD Zen processors, the L1D cache is
virtually indexed and physically tagged (VIPT). The last-level cache
is a non-inclusive victim cache. To maintain this property, every
line evicted from the last-level cache is also evicted from L1 and
L2. The last-level cache, though shared across cores, is also divided
into slices. The undocumented hash function that maps physical
addresses to slices in Intel CPUs has been reverse-engineered [52].
2.2 Cache Attacks
Cache attacks are based on the timing difference between accessing
cached and non-cached memory. They can be leveraged to build
side-channel attacks and covert channels. Among cache attacks,
access-driven attacks are the most powerful ones, where an attacker
monitors its own activity to infer the activity of its victim. More
specifically, an attacker detects which cache lines or cache sets the
victim has accessed.
Access-driven attacks can further be categorized into two types,
depending on whether or not the attacker shares memory with
its victim, e.g., using a shared library or memory deduplication.
Flush+Reload [82], Evict+Reload [31] and Flush+Flush [30] all rely
on shared memory that is also shared in the cache to infer whether
the victim accessed a particular cache line. The attacker evicts the
shared data either by using the clflush instruction (Flush+Reload
and Flush+Flush), or by accessing congruent addresses, i.e., cache
lines that belong to the same cache set (Evict+Reload). These at-
tacks have a very fine granularity (i.e., a 64-byte memory region),
but they are not applicable if shared memory is not available in the
corresponding environment. Especially in the cloud, shared mem-
ory is usually not available across VMs as memory deduplication is
disabled for security concerns [76]. Irazoqui et al. [38] showed that
an attack similar to Flush+Reload is also possible in a cross-CPU
Take A Way: Exploring the Security Implications of AMD’s Cache Way Predictors
ASIA CCS ’20, June 1–5, 2020, Taipei, Taiwan
attack. It exploits that cache invalidations (e.g., from clflush) are
propagated to all physical processors installed in the same system.
When reloading the data, as in Flush+Reload, they can distinguish
the timing difference between a cache hit in a remote processor
and a cache miss, which goes to DRAM.
The second type of access-driven attacks, called Prime+Probe [37,
50, 59], does not rely on shared memory and is, thus, applicable to
more restrictive environments. As the attacker has no shared cache
line with the victim, the clflush instruction cannot be used. Thus,
the attacker has to access congruent addresses instead (cf. Evict+
Reload). The granularity of the attack is coarser, i.e., an attacker only
obtains information about the accessed cache set. Hence, this attack
is more susceptible to noise. In addition to the noise caused by other
processes, the replacement policy makes it hard to guarantee that
data is actually evicted from a cache set [29].
With the general development to switch from inclusive caches to
non-inclusive caches, Intel introduced cache directories. Yan et al.
[81] showed that the cache directory is still inclusive, and an at-
tacker can evict a cache directory entry of the victim to invalidate
the corresponding cache line. This allows mounting Prime+Probe
and Evict+Reload attacks on the cache directory. They also ana-
lyzed whether the same attack works on AMD Piledriver and Zen
processors and discovered that it does not, because these processors
either do not use a directory or use a directory with high associa-
tivity, preventing cross-core eviction either way. Thus, it remains
to be answered what types of eviction-based attacks are feasible on
AMD processors and on which microarchitectural structures.
2.3 High-resolution Timing
For most cache attacks, the attacker requires a method to measure
timing differences in the range of a few CPU cycles. The rdtsc
instruction provides unprivileged access to a model-specific register
returning the current cycle count and is commonly used for cache
attacks on Intel CPUs. Using this instruction, an attacker can get
timestamps with a resolution between 1 and 3 cycles on modern
CPUs. On AMD CPUs, this register has a cycle-accurate resolution
until the Zen microarchitecture. Since then, it has a significantly
lower resolution as it is only updated every 20 to 35 cycles (cf.
Appendix A). Thus, rdtsc is only sufficient if the attacker can
repeat the measurement and use the average timing differences
over all executions. If an attacker tries to monitor one-time events,
the rdtsc instruction on AMD cannot directly be used to observe
timing differences, which are only a few CPU cycles.
The AMD Ryzen microarchitecture provides the Actual Perfor-
mance Frequency Clock Counter (APERF counter) [7] which can be
used to improve the accuracy of the timestamp counter. However,
it can only be accessed in kernel mode. Although other timing
primitives provided by the kernel, such as get_monotonic_time,
provide nanosecond resolution, they can be more noisy and still
not sufficiently accurate to observe timing differences, which are
only a few CPU cycles.
Hence, on more recent AMD CPUs, it is necessary to resort to a
different method for timing measurements. Lipp et al. [48] showed
that counting threads can be used on ARM-based devices where
unprivileged high-resolution timers are unavailable. Schwarz et al.
[66] showed that a counting thread can have a higher resolution
than the rdtsc instruction on Intel CPUs. A counting thread con-
stantly increments a global variable used as a timestamp without
relying on microarchitectural specifics and, thus, can also be used
on AMD CPUs.
2.4 Simultaneous Multithreading (SMT)
Simultaneous Multithreading (SMT) allows optimizing the effi-
ciency of superscalar CPUs. SMT enables multiple independent
threads to run in parallel on the same physical core sharing the
same resources, e.g., execution units and buffers. This allows uti-
lizing the available resources better, increasing the efficiency and
throughput of the processor. While on an architectural level, the
threads are isolated from each other and cannot access data of other
threads, on a microarchitectural level, the same physical resources
may be used. Intel introduced SMT as Hyperthreading in 2002. AMD
introduced 2-way SMT with the Zen microarchitecture in 2017.
Recently, microarchitectural attacks also targeted different shared
resources: the TLB [24], store buffer [16], execution ports [2, 13],
fill-buffers [68, 75], and load ports [68, 75].
2.5 Way Prediction
To look up a cache line in a set-associative cache, bits in the address
determine in which set the cache line is located. With an n-way
cache, n possible entries need to be checked for a tag match. To
avoid wasting power for n comparisons leading to a single match,
Inoue et al. [36] presented way prediction for set-associative caches.
Instead of checking all ways of the cache, a way is predicted, and
only this entry is checked for a tag match. As only one way is
activated, the power consumption is reduced. If the prediction is
correct, the access has been completed, and access times similar to
a direct-mapped cache are achieved. If the prediction is incorrect, a
normal associative check has to be performed.
We only describe AMD’s way predictor [8, 23] in more detail
in the following section. However, other CPU manufacturers hold
patents for cache way prediction as well [56, 64]. CPU’s like the
Alpha 21264 [40] also implement way prediction to combine the
advantages of set-associative caches and the fast access time of a
direct-mapped cache.
3 REVERSE-ENGINEERING AMDS WAY
PREDICTOR
In this section, we explain how to reverse-engineer the L1D way
predictor used in AMD CPUs since the Bulldozer microarchitecture.
First, we explain how the AMD L1D way predictor predicts the
L1D cache way based on hashed virtual addresses. Second, we
reverse-engineer the undocumented hash function used for the way
prediction in different microarchitectures. With the knowledge of
the hash function and how the L1D way predictor works, we can
then build powerful side-channel attacks exploiting AMD’s way
predictor.
3.1 Way Predictor
Since the AMD Bulldozer microarchitecture, AMD uses a way pre-
dictor in the L1 data cache [6]. By predicting the cache way, the CPU
only has to compare the cache tag in one way instead of all ways.
ASIA CCS ’20, June 1–5, 2020, Taipei, Taiwan
Lipp, et al.
Set
VA
h
s
a
H
Way 1
µTag
...
=
µTag
Way n
µTag
=
Way Prediction
Early Miss
L1D
L2
Figure 1: Simplified illustration of AMD’s way predictor.
While this reduces the power consumption of an L1D lookup [8], it
may increase the latency in the case of a misprediction.
Every cache line in the L1D cache is tagged with a linear-address-
based µTag [8, 23]. This µTag is computed using an undocumented
hash function, which takes the virtual address as the input. For