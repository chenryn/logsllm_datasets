0.86±.15
0.74±.18
Avg.
React
Time
(ms)
+53±797
Early
Detection
(%)
38.89 %
Avg.
Compute
Time
(ms)
N/A
0.79±0.13
0.76±(0.13)
-57±1030
43.75 %
0.72±0.12
0.88±.14
0.73±0.17
+221±1047
-1693±5670
-457±4520
34.53 %
28.26 %
38.78 %
2.1
1.9
3.2
1.5
TABLE VIII: Evaluation of the overall pipeline with ground-truth
vs. predicted gestures, compared to a non-gesture-speciﬁc approach
393
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:23:52 UTC from IEEE Xplore.  Restrictions apply. 
Perfect Boundaries
Reaction Time
F1 score
erroneous gestures
Gesture
G1
G2
G3
G4
G5
G6
G8
G9
G10
G11
G2
G5
G6
G11
G12
(ms)
-2050
-189
-1810
0
0
-146
-970
-377
N/A
N/A
N/A
-708
-1562
-307
N/A
Average Jitter
(ms)
147
-110
180
-154
-130
-124
-337
46
N/A
297
397
440
38
-620
6
Gesture Detection
Accuracy
45.5
81.1
90.4
86.7
71.2
87.1
67.4
63.8
N/A
76.8
96.2
95.1
96.1
80.1
92.6
Gesture Speciﬁc Pipeline
Average Jitter for
erroneous gestures (ms)
-2317
-95
-370
-84
0
-136
-1842
-474
N/A
N/A
N/A
-228
-137
-85
N/A
Reaction
Time (ms)
-167
-703
-2574
-0.34
-2367
-235
-610
-767
N/A
N/A
N/A
-2127
-2283
-667
N/A
F1 score for
erroneous gestures
0.63
0.33
0.45
0.90
0.09
0.90
0.60
0.60
N/A
N/A
N/A
0.58
0.70
0.73
N/A
0.69
0.36
0.54
0.94
0
0.94
0.66
0.76
N/A
N/A
N/A
0.75
0.80
0.94
N/A
TABLE IX: Effect of the pipeline components on the accuracy
Suturing and Block Transfer tasks, respectively. Having the
notion of context reduces the search-space for erroneous ges-
tures, hence allowing our models to have better TPR/TNR.
However, we note that ﬁnding the best trade-off between
TPR/FPR from the ROC while considering the implications
for surgical safety is non-trivial and requires data from real
surgeries, including adverse events and close feedback from
surgeons. On the other hand, the gesture-speciﬁc models
result in negative reaction times (later detection of anomalies)
and higher computation times due to the latency introduced
for identifying the context. However, the average reaction
times are still within the 1-1.5 seconds time frame. Thus,
there are still opportunities for issuing timely alerts or
corrective actions (when the error periods are longer) and
for the acceleration of context inference stage and improving
the reaction times.
Error detection with no notion of context achieves com-
petitive performance. With an AUC of 0.71 and 0.74 for
Suturing and Block Transfer tasks, the non-gesture-speciﬁc
models can be considered as a good baseline. However, their
high accuracy is partly due to using larger training size data
(samples from all the gesture classes) and learning from
similar error patterns in some of the gesture classes.
Gesture classiﬁcation performance does not propor-
tionally impact the overall error detection performance.
In other words, some errors can still be detected even if the
gestures are mis-classiﬁed. This is because some gestures
have very similar error patterns or common failure modes.
For example, for Suturing, the gestures G4 and G6 both have
the same failure mode where ”the needle holder is not in view
at all times”.
Having perfect gesture boundaries leads to improved
AUC and reaction time. When we look at the effect of the
gesture classiﬁer on the erroneous gesture detection (Table
IX), we see that for all the gestures, having perfect clas-
siﬁcation boundaries would have resulted in better reaction
times and F1 scores for erroneous gestures. This suggests
possible scope of improvement in the direction of gesture
classiﬁcation, while also suggesting that possibly predicting
the gesture boundary ahead of time could result in better
reaction time. For Suturing in particular, the gestures with
the highest F1 score for the gesture speciﬁc pipeline were
G4 and G6, which also had high gesture detection accuracy.
Higher F1 score for detecting erroneous gestures has
the highest impact on the reaction time. As seen in Table
IX, misclassifying gestures or negative jitter values have less
impact on the reaction time. On the other hand, the best
reaction time is -0.34 ms for G4, which also had the highest
F1 score for detecting erroneous gestures.
1-D CNN performs better than LSTM models for
detecting erroneous gestures. Firstly, we are only classi-
fying kinematics samples within a gesture to safe or unsafe,
instead of across the entire trajectory, meaning that there
is no long/short-term dependency over the class. Secondly,
1D-CNNs beneﬁt from the feature extraction of the Convo-
lutional layers to learn a good mapping between the gesture-
speciﬁc patterns and the binary labels. Combining Con-
volutional layers with LSTM units would greatly increase
the computational cost of the pipeline and potentially the
timeliness of the monitor, thus, it was not considered here.
VII. RELATED WORK
Safety and Security in Medical Robotics: Safety is
widely recognized as a crucial system property in medi-
cal robotics. Previous work [46] introduced a conceptual
framework that can capture both the design-time and run-
time characteristics of safety features of medical robotic
systems in a systematic and structured manner. In [7], a
systems-theoretic hazard analysis technique (STPA) was used
Fig. 9: Best, median and worst ROC curves for the whole pipeline
in non-context-speciﬁc (baseline) and context-speciﬁc setups
394
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:23:52 UTC from IEEE Xplore.  Restrictions apply. 
to identify the potential safety hazard scenarios and their con-
tributing causes in the RAVEN II surgical platform and the
corresponding real adverse events reported in robotic surgery
[3]. [6] proposed an anomaly detection technique based
on real-time simulation of surgical robot dynamic behavior
and preemptive detection of safety hazards such as abrupt
jumps of end-effectors. [19] presented a monitoring system
for real-time identiﬁcation of subtasks using unsupervised
techniques and detecting errors based on subtask-speciﬁc
safety constraints learned from fault-free demonstrations.
[47] presented a system to predict unsafe manipulation in
robot-assisted retinal surgery by measuring small scleral
forces and predicting force safety status.
Coble et al. proposed using remote software attestation
for veriﬁcation of potentially compromised surgical robot
control software in unattended environments such as the
battleﬁeld [48]. Other works have focused on improving the
security of surgical robots by introducing new networking
protocols such as Secure and Statistically Reliable UDP
(SSR-UDP) [49] and Secure ITP [50] that aim at increasing
reliability and conﬁdentiality of surgeon’s commands.
Our work has the similar goal of early detection and
mitigation of safety-critical events as [6], [19], but it is
the ﬁrst attempt at using supervised deep learning methods
for online and gesture-speciﬁc safety monitoring. It can
be used in conjunction with the mechanisms proposed by
the previous works to improve resilience of surgical robots
against both errors and attacks.
Surgical Workﬂow Analysis: Automatic analysis of sur-
gical workﬂow for surgeon skill evaluation and surgical
outcome prediction has been the subject of many previous
works. In [21], authors modeled minimally invasive pro-
cedures as stochastic processes using Markov chains and
used kinematics data along with dynamics of surgical tools
for decomposing complex surgical tasks. [51] presented a
feature collection, processing and classiﬁcation pipeline for
automatic detection and segmentation of surgical gestures
(surgemes) in dry-lab settings. [52] showed that Recurrent
Neural Networks can be used for the task of gesture recog-
nition, while maintaining smooth boundaries over time. In
[25], authors proposed RP-Net, a modiﬁed version of Incep-
tionV3 model [53], for automatic surgical activity recogni-
tion during robot-assisted radical prostatectomy (RARP) pro-
cedures. [54] combined formal knowledge, represented by an
ontology, and experience-based knowledge, represented by
training samples, to recognize current phase of a surgery for
context-aware information ﬁltering. In this work, we focus
on modeling the surgical context similar to the Markov chain
models presented in [21] and on identifying the surgical
gestures based on time-series data similar to [52]. However,
our main goal is to detect the erroneous gestures.
Context-Aware Monitoring: Context-aware anomaly de-
tection has been the focus of many recent works on safety-
critical systems. For example, in [55] a context-aware rea-
soning framework with sensor data fusion and anomaly
detection mechanisms was developed to support personalized