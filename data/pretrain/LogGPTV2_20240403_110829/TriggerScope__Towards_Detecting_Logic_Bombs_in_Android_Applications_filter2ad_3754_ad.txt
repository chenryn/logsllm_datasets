triggers, we selected applications from the Google Play Store
that were known to use time-, location-, and SMS-related
APIs. To this end, we built three different sets: we selected
5,803 applications that are known to make use of time-related
APIs, 4,135 applications that invoke location-related APIs, and
1,400 applications that have the capability to receive SMS.
In total, these three sets contain 9,582 unique applications
(some make use of a combination of time-, location-, and
SMS-related functionality). These applications were selected
among a total of 21,747 (free) applications obtained from a
previous crawl of the market. These applications were crawled
without focusing on any speciﬁc selection criteria, and they
span various app categories, include well-known frameworks,
and contain, on average, hundreds of methods.
We built the ﬁrst two data sets by statically checking all apps
from the crawl for the use of a predeﬁned set of Android time-
and location-related APIs. The third data set included all apps
that require the android.permission.RECEIVE_SMS
Android permission, which is necessary for an app to receive
and process incoming SMS messages.
Malicious Applications. Our dataset of malicious applications
is constituted by 14 applications that are relevant to our anal-
ysis. These applications have been taken from several sources.
First, we considered 11 applications that were prepared by a
Red Team organization (an external, independent government
contractor) as part of a DARPA engagement related to the
analysis and identiﬁcation of malicious Android applications.
These applications have been developed with the idea of
resembling state-sponsored malware and they are intentionally
designed to be as stealthy as possible, with the aim of
circumventing all existing automated malware analysis tools.
Additionally, we considered real-world malware samples that
contained a time-based logic bomb [54], SMS-based C&C
server [27], and the RCSAndroid malware sample written by
the HackingTeam security company [60].
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:49 UTC from IEEE Xplore.  Restrictions apply. 
Domain
# Apps
# Apps With
Checks
# Apps With Suspicious
Checks
# Apps With Suspicious Triggered
Behavior
# Apps After Post-Filter
Steps
Time
Location
SMS
4,950
3,430
1,138
1,026
137
223
302
71
89
30
23
64
10
8
17
Table I: This table summarizes how the different steps of our analysis are able to drastically reduce the number of false positives when
detecting triggered malware in a large set of benign applications obtained from the Google Play store.
C. Trigger Analysis Results
In the 4,950 time-related applications, our tool identiﬁed
a total of 12,465 basic blocks whose execution is guarded
by a time-related constraint, contained in 1,026 different
applications (§III-B). After reconstructing the minimized path
predicates that guard each block (§III-C), TRIGGERSCOPE
performs a classiﬁcation step for each of them (§III-D).
In this experiment, TRIGGERSCOPE detected 302 applica-
tions containing at least one suspicious time-related predicate.
Then, TRIGGERSCOPE performs control-dependency analysis
(§III-E) to determine whether these predicates guard the exe-
cution of any sensitive operations. This analysis step reduced
the number of applications to be manually inspected to 30
samples, a number that was further lowered to 10 by using
the post-ﬁlter steps (§III-D).
For what concerns
the 3,430 applications containing
location-related APIs, TRIGGERSCOPE identiﬁed a total of
137 applications that cumulatively contain 869 location-related
predicates. TRIGGERSCOPE’s analysis steps were then able
to progressively reduce this set of applications to 71 (identi-
ﬁcation of suspicious checks), 23 (identiﬁcation of sensitive
operations), and 8 (post-ﬁlter steps). Similarly, for the SMS
domain, the tool identiﬁed a cumulative total of 1,087 SMS-
related predicates in 223 applications (out of 1,138). Of these,
the analysis steps reduced this set to, respectively, 89 (iden-
tiﬁcation of suspicious checks), 64 (identiﬁcation of sensitive
operations), and 17 (post-ﬁlter steps) applications.
In total, TRIGGERSCOPE ﬂagged 35 applications as suspi-
cious among the apps obtained from the Google Play Store.
Table I provides a summary of the results and underlines
how all the different analysis steps that constitute our trigger
analysis technique are relevant to reduce the number of ﬂagged
applications.
For what concern the malicious applications, TRIGGER-
SCOPE was able to analyze and detect a trigger in all of them.
We discuss several insights in Sections V-F and V-G.
D. Accuracy Evaluation
We now discuss the precision of our analysis and we study
how the different analysis steps contribute to the end result.
We ﬁrst computed the false positive ratio (FPR), which is
computed as the number of false alarms over the number
of the considered benign samples. We opted to evaluate our
system by using this metric (instead of others) since we
believe it answers the most relevant question when such
systems are deployed in real-world scenarios (where the vast
majority of the samples are benign): “Given a dataset of benign
386386
Figure 6: CDF of the elapsed analysis time over the three test sets
of applications that use Android time, location, and SMS
APIs. In this experiment, 90% of the applications tested
were successfully analyzed for suspicious triggers in under
750 seconds.
B. Performance
Our experiments suggest that the performance of the TRIG-
GERSCOPE prototype is good enough to be able to scale its
analysis to thousands of real-world Android applications. In
particular, we analyzed the three data sets of applications from
the Google Play Store and set a timeout of one hour for each
instance. The tool was able to successfully analyze 4,950 out
of a total of 5,803 time-related applications, 3,430 out of a
total of 4,135 location-related applications, and 1,138 out of a
total of 1,400 SMS-related applications (9,313 unique samples
in total). The analysis of the remaining applications did not
complete before the timeout was reached. Figure 6 shows a
cumulative distribution of elapsed analysis times (for those
applications that were successfully analyzed), indicating how
many applications were analyzed within a given number of
seconds. In particular, we observe that 90% of the applications
we tested were completely analyzed for triggers in under
750 seconds. Moreover, on average,
the analysis of each
of these applications required 219.21 seconds. This suggests
that performing trigger analysis over large sets of Android
applications, perhaps centrally at an app store, is feasible,
especially since the analysis can easily be horizontally scaled.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:49 UTC from IEEE Xplore.  Restrictions apply. 
applications, how many false alerts does a system raise?” As
discussed in the previous section, TRIGGERSCOPE detected
35 benign applications (among the 9,313 samples successfully
analyzed) that contained at least one time-, location-, or SMS-
based trigger matching our deﬁnition of suspiciousness.
To evaluate the accuracy of our system, we manually
inspected all these applications, by using IDA Pro [37] to dis-
assemble the apps and, when possible, by using dex2jar [4],
JD-Gui [28], and JEB [52] to decompile them. We were
able to manually verify that TRIGGERSCOPE correctly and
precisely identiﬁed at least one interesting/suspicious trigger
in each of these applications. While most of these behaviors
appear to be legitimate, we identiﬁed two applications that
contain a backdoor-like functionality (these and other cases
are discussed in-depth in Section V-F). That being said, for the
sake of this evaluation, we consider all these 35 applications
as false positives (even if, depending from the context, the
two backdoors might be considered as true positive). Thus,
TRIGGERSCOPE has a false positive rate of 0.38%. Note
also that the false positive rate is even lower (0.16%) when
considering all the applications in our initial dataset (and not
only the ones that have access to input we check for triggers).
To assess whether TRIGGERSCOPE is affected by false
negatives, we manually inspected two sets of applications.
First, we inspected all 82 applications that our post-ﬁlter steps
discarded. In all cases, we were able to establish that the
discarded instances were not interesting. Second, we manually
inspected a random subset of 20 applications for which our
analysis did not identify any suspicious check. We spent about
10 minutes per application, and, once again, we did not ﬁnd
any false negatives. We acknowledge that this evaluation does
not deﬁnitely exclude the possibility of false negatives (see
Section VI for a discussion about the limitations of this work),
but we believe our results are an encouraging step towards the
detection of trigger-based behavior in Android applications.
Table II provides a summary of the accuracy evaluation of
our analysis. The table also shows how the accuracy changes
when only a subset of TRIGGERSCOPE’s analysis steps are
used, clearly showing how all these steps actively contribute
to improve the overall accuracy of our approach.
E. Comparison with Existing Approaches
targeted malware (that
leverages logic bombs)
As part of our evaluation, we studied whether exist-
ing malware analysis tools (which proved to be very ef-
fective when detecting traditional malware) are suitable to
detect
in
Android applications. We selected the most representative
works in the area of Android malware analysis: Kirin [31],
DroidAPIMiner
[62],
DroidRanger [64], Drebin [18], and Apposcopy [32]. We
attempted to obtain or reproduce all of them, but we were able
to do so only for the ﬁrst three tools: Kirin, DroidAPIMiner,
and FlowDroid. DroidRanger, Drebin, and Apposcopy are cur-
rently not open source. AppContext, instead, has recently been
released as open source. However, we encountered several
difﬁculties when attempting to use it, and we are currently
seeking help from the authors.
[14], FlowDroid [19], AppContext
We believe these tools to be representative of very different
approaches to detect malicious and unwanted behavior in
Android apps. In fact, Kirin relies on permission analysis;
DroidAPIMiner applies machine learning based on the An-
droid APIs invoked by a given application; and FlowDroid
applies taint analysis to identify sensitive data ﬂows (such as
privacy leaks). We acknowledge that FlowDroid is not meant
to be used for malware analysis, and this obviously affects
its performance. However, we included it in our evaluation
because we believe it is interesting to also consider an ap-
proach based on taint analysis, since it constitutes one of the
possibilities for detecting malicious/unwanted functionality.
The remainder of this section describes the details and the
results of our experiment.
Kirin. Kirin is an analysis tool
that performs lightweight
malware detection by ﬂagging an application as suspicious
according to a set of rules based on the requested permissions.
Kirin is open source [30], and we were easily able to reproduce
the analysis. Kirin relies on the speciﬁcation of a rule set:
for this evaluation we considered the rules described in the
paper [31] and included in the source code. We used this tool
to analyze the applications in our dataset. Table III shows a
summary of the results. Kirin has a relatively low false positive
rate (6.38%), while it is affected by a very high false negative
rate (57.14%). These results are not surprising, since Kirin
relies on a very conservative set of rules based on permissions.
Thus, it is affected by a reasonable number of false positives, at
the price of missing many malicious behaviors, the underlying
issue being that a logic bomb can be implemented without
requesting highly-privileged permissions.
DroidAPIMiner. DroidAPIMiner is a malware detection tool
based on machine learning. In particular, this tool uses as
feature vector the set of Android APIs used by a given
application. DroidAPIMiner is not open source: nonetheless,
we were able to re-implement it based on the details provided
in the research paper and the help of the authors. For our
experiment, we used the k-nearest neighbors algorithm, since
the authors reported it to be the most effective algorithm
when detecting malware. We performed this experiment with
multiple values of k (1, 3, and 5), we trained the classiﬁer with
our entire dataset, and we evaluated it by using leave-one-out
cross-validation. On the one hand, the tool does not raise any
false positive; on the other hand, it is affected by a very high
false negative rate (78.57%), making this approach not reliable.
These results are due to the fact that this approach would
ﬂag an application as malicious only if the dataset contains
a malicious application that invokes very similar APIs. To
make things even more difﬁcult, it is very challenging (if not
impossible) to obtain a comprehensive dataset of applications
containing logic bombs, which makes any approach based on
machine learning even less applicable when used to detect this
category of malicious applications.
FlowDroid. FlowDroid is a state-of-the-art static analysis
tool
that aims at detecting sensitive privacy leaks in An-
droid applications. Clearly, this tool has not been designed
387387
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:49 UTC from IEEE Xplore.  Restrictions apply. 
Enabled Analysis Steps
True
Positives
False
Positives
True
Negatives
False
Negatives
False
Positive
Rate
False
Negative
Rate
Predicate Detection
Suspicious Predicate Analysis
(in addition to the previous step)
Control-Dependency Analysis
(in addition to the previous steps)
TRIGGERSCOPE
(all analysis steps)
14
14
14
14
1,386
462
117
35
7,927
8,851
9,196
9,278
0
0
0
0
14.88%
4.96%
1.26%
0.38%
0%
0%
0%
0%
Table II: The table summarises the accuracy results of TRIGGERSCOPE. The total number of applications considered is 9,327, of which
9,313 benign and 14 malicious. This table also shows the results that would be obtained when only a subset of TRIGGERSCOPE’s
analysis steps is enabled.
Existing Analysis Tool
# Benign
Apps
# Malware
Apps
True
Positives
False
Positives
True
Negatives
False
Negatives
False
Positive
Rate
False
Negative
Rate
Kirin
DroidAPIMiner
FlowDroid
TRIGGERSCOPE
9,309
9,313
9,084
9,313
14
14
9
14