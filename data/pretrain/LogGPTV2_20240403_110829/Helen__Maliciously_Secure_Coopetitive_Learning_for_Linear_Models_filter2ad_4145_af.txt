### Insufficiency of Existing Cryptographic Approaches

Figure 7 highlights the limitations of current cryptographic methods. The term "n-party" refers to whether n (where n > 2) organizations can perform computations with equal trust, excluding the two non-colluding servers model. Our evaluation of practicality is limited to maliciously-secure systems. We note that some works, which we marked as not cooperative and not maliciously secure, discuss at a high level how their work might be extended to such settings, but they do not provide detailed designs or evaluations.

### Coopetitive Analytics Systems

Coopetitive analytics systems [6, 55, 12, 21, 10] enable multiple parties to run SQL queries over all parties' data without revealing inputs or models. However, these frameworks do not directly translate to Helen's training workloads, and most do not address the malicious setting.

### Trusted Hardware-Based Systems

The related work in the previous sections focuses on purely software-based solutions. Another approach is to use trusted hardware [53, 22], and there are various secure distributed systems that could be extended to the coopetitive setting [64, 42, 71]. However, these hardware mechanisms require additional trust and are susceptible to side-channel leakages [49, 68, 50].

### Attacks on Machine Learning

Machine learning attacks can be categorized into data poisoning, model leakage, parameter stealing, and adversarial learning. As mentioned in §III-A, Helen aims to cryptographically run the training algorithm without sharing datasets among the parties involved. Defenses against these attacks are orthogonal and complementary to our goal. These machine learning attacks can often be addressed separately from Helen. We briefly discuss two relevant attacks related to the training stage and some methods for mitigating them.

#### Poisoning
Data poisoning allows an attacker to inject poisoned inputs into a dataset before training [44, 18]. Malicious MPC does not prevent an attacker from choosing incorrect initial inputs because there is no way to enforce this requirement. However, there are ways to mitigate arbitrary data poisoning that complement Helen’s training approach. Before training, one can check that the inputs are within certain intervals. During training, cross-validation can identify parties that do not contribute useful data. After training, techniques like fine-tuning and parameter pruning [52] can further post-process the model.

#### Model Leakage
Model leakage [65, 16] is an attack where an adversary tries to infer information about the training data from the model itself. Malicious MPC does not prevent an attacker from learning the final result. In our coopetitive model, we assume that all parties want to cooperate and have agreed to release the final model to everyone. One way to alleviate model leakage is through the use of differential privacy [43, 4, 31]. For example, adding carefully chosen noise directly to the output model [43] is a simple technique that complements Helen.

### Conclusion

In this paper, we introduce Helen, a coopetitive system for training linear models. Compared to prior work, Helen assumes a stronger threat model by defending against malicious participants, meaning each party only needs to trust itself. Compared to a baseline implemented with a state-of-the-art malicious framework, Helen achieves up to five orders of magnitude in performance improvement. Given the lack of efficient maliciously secure training protocols, we hope that our work on Helen will lead to further advancements in efficient systems with strong security guarantees.

### Acknowledgment

We thank the anonymous reviewers for their valuable feedback, as well as Shivaram Venkataraman, Stephen Tu, and Akshayaram Srinivasan for their feedback and discussions. This research was supported by NSF CISE Expeditions Award CCF-1730628, as well as gifts from the Sloan Foundation, Hellman Fellows Fund, Alibaba, Amazon Web Services, Ant Financial, Arm, Capital One, Ericsson, Facebook, Google, Huawei, Intel, Microsoft, Scotiabank, Splunk, and VMware.

---

This version of the text is more structured, clear, and professional, with improved coherence and flow.