–
–
–
–
no
yes
Fig. 7: Insufﬁciency of existing cryptographic approaches. “n-party” refers to whether the n(>2) organizations can perform
the computation with equal trust (thus not including the two non-colluding servers model). We answer the practicality question
only for maliciously-secure systems. We note that a few works that we marked as not coopetitive and not maliciously secure
discuss at a high level how one might extend their work to such a setting, but they did not ﬂesh out designs or evaluate their
proposals.
compute a prediction without revealing the input or the model to
the other party. Coopetitive analytics systems [6, 55, 12, 21, 10]
allow multiple parties to run SQL queries over all parties’ data.
These computation frameworks do not directly translate to
Helen’s training workloads. Most of these works also do not
address the malicious setting.
Trusted hardware based systems. The related work pre-
sented in the previous two sections all utilize purely software
based solutions. Another possible approach is to use trusted
hardware [53, 22], and there are various secure distributed
systems that could be extended to the coopetitive setting [64, 42,
71]. However, these hardware mechanisms require additional
trust and are prone to side-channel leakages [49, 68, 50].
B. Attacks on machine learning
Machine learning attacks can be categorized into data
poisoning, model leakage, parameter stealing, and adversarial
learning. As mentioned in §III-A, Helen tackles the problem
of cryptographically running the training algorithm without
sharing datasets amongst the parties involved, while defenses
against these attacks are orthogonal and complementary to our
goal in this paper. Often, these machine learning attacks can be
separately addressed outside of Helen. We brieﬂy discuss two
relevant attacks related to the training stage and some methods
for mitigating them.
Poisoning. Data poisoning allows an attacker to inject poi-
soned inputs into a dataset before training [44, 18]. Generally,
malicious MPC does not prevent an attacker from choosing
incorrect initial inputs because there is no way to enforce this
requirement. Nevertheless, there are some ways of mitigating
arbitrary poisoning of data that would complement Helen’s
training approach. Before training, one can check that the inputs
are conﬁned within certain intervals. The training process itself
can also execute cross validation, a process that can identify
parties that do not contribute useful data. After training, it is
possible to further post process the model via techniques like
ﬁne tuning and parameter pruning [52].
Model leakage. Model leakage [65, 16] is an attack launched
by an adversary who tries to infer information about the
training data from the model itself. Again, malicious MPC
does not prevent an attacker from learning the ﬁnal result. In
our coopetitive model, we also assume that all parties want
to cooperate and have agreed to release the ﬁnal model to
everyone. One way to alleviate model leakage is through the
use of differential privacy [43, 4, 31]. For example, a simple
technique that is complementary to Helen is adding carefully
chosen noise directly to the output model [43].
X. CONCLUSION
In this paper, we propose Helen, a coopetitive system
for training linear models. Compared to prior work, Helen
assumes a stronger threat model by defending against malicious
participants. This means that each party only needs to trust
itself. Compared to a baseline implemented with a state-of-the-
art malicious framework, Helen is able to achieve up to ﬁve
orders of magnitude of performance improvement. Given the
lack of efﬁcient maliciously secure training protocols, we hope
that our work on Helen will lead to further work on efﬁcient
systems with such strong security guarantees.
XI. ACKNOWLEDGMENT
We thank the anonymous reviewers for their valuable
reviews, as well as Shivaram Venkataraman, Stephen Tu, and
Akshayaram Srinivasan for their feedback and discussions. This
research was supported by NSF CISE Expeditions Award CCF-
1730628, as well as gifts from the Sloan Foundation, Hellman
Fellows Fund, Alibaba, Amazon Web Services, Ant Financial,
Arm, Capital One, Ericsson, Facebook, Google, Huawei, Intel,
Microsoft, Scotiabank, Splunk and VMware.
(cid:24)(cid:20)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] bristolcrypto/spdz-2: Multiparty computation with SPDZ, MASCOT,
and Overdrive ofﬂine phases. https://github.com/bristolcrypto/SPDZ-2.
Accessed: 2018-10-31.
[2] VIFF, the Virtual Ideal Functionality Framework. http://viff.dk/, 2015.
[3] Health insurance portability and accountability act, April 2000.
[4] ABADI, M., CHU, A., GOODFELLOW, I., MCMAHAN, H. B., MIRONOV,
I., TALWAR, K., AND ZHANG, L. Deep learning with differential privacy.
In Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security (2016), ACM, pp. 308–318.
[5] ALEXANDRU, A. B., GATSIS, K., SHOUKRY, Y., SESHIA, S. A.,
TABUADA, P., AND PAPPAS, G. J. Cloud-based quadratic optimization
with partially homomorphic encryption. arXiv preprint arXiv:1809.02267
(2018).
[6] BATER, J., ELLIOTT, G., EGGEN, C., GOEL, S., KHO, A., AND ROGERS,
J. Smcql: secure querying for federated databases. Proceedings of the
VLDB Endowment 10, 6 (2017), 673–684.
[7] BEN-DAVID, A., NISAN, N., AND PINKAS, B. Fairplaymp: a system
for secure multi-party computation. www.cs.huji.ac.il/project/Fairplay/
FairplayMP.html, 2008.
[8] BEN-OR, M., GOLDWASSER, S., AND WIGDERSON, A. Completeness
theorems for non-cryptographic fault-tolerant distributed computation.
In Proceedings of the twentieth annual ACM symposium on Theory of
computing (1988), ACM, pp. 1–10.
[9] BERTIN-MAHIEUX, T., ELLIS, D. P., WHITMAN, B., AND LAMERE, P.
The million song dataset. In Ismir (2011), vol. 2, p. 10.
[10] BITTAU, A., ERLINGSSON, U., MANIATIS, P., MIRONOV, I., RAGHU-
NATHAN, A., LIE, D., RUDOMINER, M., KODE, U., TINNES, J., AND
SEEFELD, B. Prochlo: Strong privacy for analytics in the crowd. In
Proceedings of the 26th Symposium on Operating Systems Principles
(2017), ACM, pp. 441–459.
[11] BOGDANOV, D., LAUR, S., AND WILLEMSON, J.
Sharemind: A
Framework for Fast Privacy-Preserving Computations. 2008.
[12] BONAWITZ, K., IVANOV, V., KREUTER, B., MARCEDONE, A., MCMA-
HAN, H. B., PATEL, S., RAMAGE, D., SEGAL, A., AND SETH, K.
Practical secure aggregation for privacy-preserving machine learning. In
Proceedings of the 2017 ACM SIGSAC Conference on Computer and
Communications Security (2017), CCS ’17.
[13] BOST, R., POPA, R. A., TU, S., AND GOLDWASSER, S. Machine
learning classiﬁcation over encrypted data. In Network and Distributed
System Security Symposium (NDSS) (2015).
[14] BOUDOT, F. Efﬁcient proofs that a committed number lies in an
interval. In International Conference on the Theory and Applications of
Cryptographic Techniques (2000), Springer, pp. 431–444.
[15] BOYD, S., PARIKH, N., CHU, E., PELEATO, B., AND ECKSTEIN, J.
Distributed optimization and statistical learning via the alternating
direction method of multipliers. In Foundations and Trends in Machine
Learning, Vol. 3, No. 1 (2010).
[16] CARLINI, N., LIU, C., KOS, J., ERLINGSSON, ´U., AND SONG, D. The
secret sharer: Measuring unintended neural network memorization &
extracting secrets. arXiv preprint arXiv:1802.08232 (2018).
[17] CHEN, H., AND XIANG, Y. The study of credit scoring model based on
group lasso. Procedia Computer Science 122 (2017), 677 – 684. 5th
International Conference on Information Technology and Quantitative
Management, ITQM 2017.
[18] CHEN, X., LIU, C., LI, B., LU, K., AND SONG, D. Targeted backdoor
attacks on deep learning systems using data poisoning. arXiv preprint
arXiv:1712.05526 (2017).
[19] CLEVE, R. Limits on the security of coin ﬂips when half the processors
are faulty. In Proceedings of the eighteenth annual ACM symposium on
Theory of computing (1986), ACM, pp. 364–369.
[20] COCK, M. D., DOWSLEY, R., NASCIMENTO, A. C., AND NEWMAN,
S. C. Fast, privacy preserving linear regression over distributed datasets
based on pre-distributed data. In Proceedings of the 8th ACM Workshop
on Artiﬁcial Intelligence and Security (AISec) (2015).
[21] CORRIGAN-GIBBS, H., AND BONEH, D. Prio: Private, robust, and
scalable computation of aggregate statistics. In 14th USENIX Symposium
on Networked Systems Design and Implementation (NSDI 17) (2017).
[22] COSTAN, V., AND DEVADAS, S. Intel sgx explained. IACR Cryptology
ePrint Archive 2016 (2016), 86.
[23] CRAMER, R., DAMG ˚ARD, I., AND NIELSEN, J. Multiparty computation
from threshold homomorphic encryption. EUROCRYPT 2001 (2001),
280–300.
[24] DAMG ˚ARD, I. Efﬁcient concurrent zero-knowledge in the auxiliary string
model. In International Conference on the Theory and Applications of
Cryptographic Techniques (2000), Springer, pp. 418–430.
[25] DAMG ˚ARD, I. On σ-protocols. Lecture Notes, University of Aarhus,
Department for Computer Science (2002).
[26] DAMG ˚ARD, I., AND JURIK, M. Client/server tradeoffs for online
elections. In International Workshop on Public Key Cryptography (2002),
Springer, pp. 125–140.
[27] DAMG ˚ARD, I., PASTRO, V., SMART, N., AND ZAKARIAS, S. Multiparty
computation from somewhat homomorphic encryption. In Advances in
Cryptology–CRYPTO 2012. Springer, 2012, pp. 643–662.
[28] D’ANGELO, G. M., RAO, D. C., AND GU, C. C.
Combining
least absolute shrinkage and selection operator (lasso) and principal-
components analysis for detection of gene-gene interactions in genome-
wide association studies. In BMC proceedings (2009).
[29] DHEERU, D., AND KARRA TANISKIDOU, E. UCI machine learning
repository, 2017.
[30] DICTIONARIES, E. O. Coopetition.
[31] DUCHI, J. C., JORDAN, M. I., AND WAINWRIGHT, M. J. Local privacy,
data processing inequalities, and statistical minimax rates. arXiv preprint
arXiv:1302.3203 (2013).
[32] FAUST, S., KOHLWEISS, M., MARSON, G. A., AND VENTURI, D. On the
non-malleability of the ﬁat-shamir transform. In International Conference
on Cryptology in India (2012), Springer, pp. 60–79.
[33] GARAY, J. A., MACKENZIE, P., AND YANG, K. Strengthening zero-
knowledge protocols using signatures. In Eurocrypt (2003), vol. 2656,
Springer, pp. 177–194.
[34] GASCN, A., SCHOPPMANN, P., BALLE, B., RAYKOVA, M., DOERNER,
J., ZAHUR, S., AND EVANS, D. Privacy-preserving distributed linear
regression on high-dimensional data. Cryptology ePrint Archive, Report
2016/892, 2016.
[35] GIACOMELLI, I., JHA, S., JOYE, M., PAGE, C. D., AND YOON, K.
Privacy-preserving ridge regression with only linearly-homomorphic
encryption. Cryptology ePrint Archive, Report 2017/979, 2017. https:
//eprint.iacr.org/2017/979.
[36] GILAD-BACHRACH, R., DOWLIN, N., LAINE, K., LAUTER, K.,
NAEHRIG, M., AND WERNSING, J. Cryptonets: Applying neural
networks to encrypted data with high throughput and accuracy.
In
International Conference on Machine Learning (2016), pp. 201–210.
[37] GOLDREICH, O., MICALI, S., AND WIGDERSON, A. How to play any
mental game. In Proceedings of the nineteenth annual ACM symposium
on Theory of computing (1987), ACM, pp. 218–229.
[38] GOLUB, G. H., AND VAN LOAN, C. F. Matrix computations, vol. 3.
JHU Press, 2012.
[39] GROTH, J. Homomorphic trapdoor commitments to group elements.
IACR Cryptology ePrint Archive 2009 (2009), 7.
[40] HALEVY, A., NORVIG, P., AND PEREIRA, F.
The unreasonable
effectiveness of data. IEEE Intelligent Systems 24, 2 (Mar. 2009), 8–12.
[41] HALL, R., FIENBERG, S. E., AND NARDI, Y. Secure multiple linear
regression based on homomorphic encryption. In Journal of Ofﬁcial
Statistics (2011).
[42] HUNT, T., ZHU, Z., XU, Y., PETER, S., AND WITCHEL, E. Ryoan: A
distributed sandbox for untrusted computation on secret data. In OSDI
(2016), pp. 533–549.
[43] IYENGAR, R., NEAR, J. P., SONG, D., THAKKAR, O., THAKURTA,
A., AND WANG, L. Towards practical differentially private convex
optimization. In 2019 IEEE Symposium on Security and Privacy (SP),
IEEE.
[44] JAGIELSKI, M., OPREA, A., BIGGIO, B., LIU, C., NITA-ROTARU, C.,
AND LI, B. Manipulating machine learning: Poisoning attacks and
countermeasures for regression learning. arXiv preprint arXiv:1804.00308
(2018).
[45] JUVEKAR, C., VAIKUNTANATHAN, V., AND CHANDRAKASAN, A.
Gazelle: A low latency framework for secure neural network inference.
CoRR abs/1801.05507 (2018).
[46] KELLER, M., ORSINI, E., AND SCHOLL, P. Mascot: faster malicious
arithmetic secure computation with oblivious transfer. In Proceedings of
the 2016 ACM SIGSAC Conference on Computer and Communications
Security (2016), ACM, pp. 830–842.
[47] KELLER, M., PASTRO, V., AND ROTARU, D. Overdrive: making spdz
great again.
In Annual International Conference on the Theory and
Applications of Cryptographic Techniques (2018), Springer, pp. 158–189.
[48] KIDD, A. C., MCGETTRICK, M., TSIM, S., HALLIGAN, D. L.,
BYLESJO, M., AND BLYTH, K. G. Survival prediction in mesothelioma
(cid:24)(cid:20)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
using a scalable lasso regression model: instructions for use and initial
performance using clinical predictors. BMJ Open Respiratory Research
5, 1 (2018).
[49] KOCHER, P., GENKIN, D., GRUSS, D., HAAS, W., HAMBURG, M.,
LIPP, M., MANGARD, S., PRESCHER, T., SCHWARZ, M., AND YAROM,
Y. Spectre attacks: Exploiting speculative execution. arXiv preprint
arXiv:1801.01203 (2018).
[50] LEE, S., SHIH, M.-W., GERA, P., KIM, T., KIM, H., AND PEINADO,
M. Inferring ﬁne-grained control ﬂow inside sgx enclaves with branch
shadowing.
In 26th USENIX Security Symposium, USENIX Security
(2017), pp. 16–18.
[51] LIU, J., JUUTI, M., LU, Y., AND ASOKAN, N. Oblivious neural network
predictions via minionn transformations. In Proceedings of the 2017
ACM SIGSAC Conference on Computer and Communications Security
(2017), ACM, pp. 619–631.
[52] LIU, K., DOLAN-GAVITT, B., AND GARG, S. Fine-pruning: Defending
against backdooring attacks on deep neural networks. arXiv preprint
arXiv:1805.12185 (2018).
[53] MCKEEN, F., ALEXANDROVICH, I., BERENZON, A., ROZAS, C. V.,
SHAFI, H., SHANBHOGUE, V., AND SAVAGAONKAR, U. R. Innovative
instructions and software model for isolated execution. HASP@ ISCA
10 (2013).
[54] MOHASSEL, P., AND ZHANG, Y. Secureml: A system for scalable
privacy-preserving machine learning. IACR Cryptology ePrint Archive
2017 (2017), 396.
[55] NARAYAN, A., AND HAEBERLEN, A. Djoin: Differentially private join
queries over distributed databases. In Proceedings of the 10th USENIX
Conference on Operating Systems Design and Implementation (2012),
OSDI’12.
[56] NIKOLAENKO, V., WEINSBERG, U., IOANNIDIS, S., JOYE, M., BONEH,
D., AND TAFT, N. Privacy-preserving ridge regression on hundreds of
millions of records. In Security and Privacy (SP), 2013 IEEE Symposium
on (2013), IEEE, pp. 334–348.
[57] NIKOLAENKO, V., WEINSBERG, U., IOANNIDIS, S., JOYE, M., BONEH,
D., AND TAFT, N. Privacy-preserving ridge regression on hundreds of
millions of records. In Security and Privacy (SP), 2013 IEEE Symposium
on (2013), IEEE, pp. 334–348.
[69] WANG, X., RANELLUCCI, S., AND KATZ, J. Global-scale secure
multiparty computation.
In Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security (2017), ACM,
pp. 39–56.
[58] PAILLIER, P. Public-key cryptosystems based on composite degree
residuosity classes. In EUROCRYPT (1999), pp. 223–238.
[59] PAPACHRISTOU, C., OBER, C., AND ABNEY, M. A lasso penalized
regression approach for genome-wide association analyses using related
individuals: application to the genetic analysis workshop 19 simulated
data. BMC Proceedings 10, 7 (Oct 2016), 53.
[60] RIAZI, M. S., WEINERT, C., TKACHENKO, O., SONGHORI, E. M.,
SCHNEIDER, T., AND KOUSHANFAR, F. Chameleon: A hybrid secure
computation framework for machine learning applications. Cryptology
ePrint Archive, Report 2017/1164, 2017. https://eprint.iacr.org/2017/1164.
[61] ROBBINS, H., AND MONRO, S. A stochastic approximation method. In
Herbert Robbins Selected Papers. Springer, 1985, pp. 102–109.
[62] ROUHANI, B. D., RIAZI, M. S., AND KOUSHANFAR, F. Deepsecure:
Scalable provably-secure deep learning. CoRR abs/1705.08963 (2017).
[63] ROY, S., MITTAL, D., BASU, A., AND ABRAHAM, A. Stock market
forecasting using lasso linear regression model, 01 2015.
[64] SCHUSTER, F., COSTA, M., FOURNET, C., GKANTSIDIS, C., PEINADO,
M., MAINAR-RUIZ, G., AND RUSSINOVICH, M. Vc3: Trustworthy data
analytics in the cloud using sgx. In Security and Privacy (SP), 2015
IEEE Symposium on (2015), IEEE, pp. 38–54.
[65] SHMATIKOV, V., AND SONG, C. What are machine learning models
hiding?
[66] SHOKRI, R., AND SHMATIKOV, V. Privacy-preserving deep learning. In
CCS (2015).
[67] STOICA, I., SONG, D., POPA, R. A., PATTERSON, D., MAHONEY,
M. W., KATZ, R., JOSEPH, A. D., JORDAN, M., HELLERSTEIN, J. M.,
GONZALEZ, J. E., ET AL. A berkeley view of systems challenges for ai.
arXiv preprint arXiv:1712.05855 (2017).
[68] VAN BULCK, J., MINKIN, M., WEISSE, O., GENKIN, D., KASIKCI, B.,
PIESSENS, F., SILBERSTEIN, M., WENISCH, T. F., YAROM, Y., AND
STRACKX, R. Foreshadow: Extracting the keys to the intel sgx kingdom
with transient out-of-order execution. In Proceedings of the 27th USENIX
Security Symposium. USENIX Association (2018).
[70] YAO, A. C. Protocols for secure computations.
In Foundations of
Computer Science, 1982. SFCS’08. 23rd Annual Symposium on (1982),
IEEE, pp. 160–164.
[71] ZHENG, W., DAVE, A., BEEKMAN, J. G., POPA, R. A., GONZALEZ,
J. E., AND STOICA, I. Opaque: An oblivious and encrypted distributed
analytics platform. In USENIX Symposium of Networked Systems Design
and Implementation (NDSI) (2017), pp. 283–298.
(cid:24)(cid:20)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply.