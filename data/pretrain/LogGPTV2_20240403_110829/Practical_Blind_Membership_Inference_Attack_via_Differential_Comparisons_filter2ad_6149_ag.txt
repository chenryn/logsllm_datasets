functions
In this
subsection, we evaluate the performance of
BLINDMI-DIFF with different
internal parameters, e.g.,
BLINDMI-DIFF with different kernel functions and BLINDMI-
DIFF-w/o with different initial separation classiﬁers. The per-
11
(a) MemGuard on CH-MNIST
(b) DP-Adam on CH-MNIST
Fig. 3. F1-Score of Different MI attacks, i.e., state-of-the-art and BLINDMI, against a Target Model together with Corresponding Defenses.
(c) MMD+Mix-up on CIFAR-100
(d) Adversarial Regularization on CIFAR-100
TABLE IX.
Method \ Size
F1-SCORE(%) OF BLINDMI-DIFF/BLINDMI-1CLASS WITH STANDARD ERROR OF THE MEAN OF WITH NONMEMBER DATASETS GENERATED
VIA DIFFERENT METHODS OF VARIED SIZE.
20
50
100
200
1,000
10,000
77.7±0.80 / 72.9±1.82 78.1±0.99 / 74.4±1.43 77.9±1.58 / 75.6±1.55 78.2±0.87 / 76.3±1.67 78.4±1.01 / 76.8±1.70 78.7±0.63 / 77.5±1.31
Sample transform
Random perpetuation 77.5±1.37 / 66.4±1.20 77.9±0.92 / 72.1±1.30 77.6±1.44 / 73.1±1.07 78.0±0.85 / 73.5±0.70 77.6±0.42 / 74.5±0.88 78.2±0.30 / 75.7±0.69
75.5±2.51 / 71.6±1.98 75.7±1.93 / 71.6±2.31 75.3±2.03 / 71.3±2.38 75.6±1.79 / 71.4±2.00 75.7±1.59 / 71.8±2.03 75.7±1.64 / 72.2±1.87
Random generation
77.9±1.26 / 64.9±1.99 78.0±1.38 / 71.4±1.46 78.1±1.21 / 72.5±1.60 78.1±1.05 / 73.2±1.09 77.8±1.20 / 76.1±1.33 77.6±1.37 / 77.0±0.93
Cross domain
TABLE X.
MANN-WHITNEY U TEST VALUE (P-VALUE) OF F-1 SCORES OF BLINDMI-DIFF/BLINDMI-1CLASS WITH NONMEMBER SETS VIA
DIFFERENT METHODS
Sample transform
Random perpetuation
Random generation
Cross domain
Sample transform
Random perpetuation
Random generation
Cross domain
18∗ (0.4678∗∗) / 18 (0.4678)
7 (0.0455) / 7 (0.0463)
0 (0.0024) / 0 (0.0025)
9.5 (0.0981) / 7 (0.0463)
–
18 (0.4673) / 18 (0.4678)
0 (0.0023) / 7 (0.0461)
13 (0.2328) / 18 (0.4681)
–
–
18 (0.4657) / 18 (0.4673)
0 (0.0023) / 10.5 (0.1303)
–
–
–
18 (0.4673) / 18 (0.4678)
* : the larger the U value is, the more similar two datasets are.
** : a p-value less than 0.05 indicates statistical signiﬁcance.
MMD STATISTICAL TESTS OF BLINDMI-DIFF WITH
TABLE XI.
NONMEMBER DATASETS GENERATED VIA DIFFERENT METHODS (EACH
VALUE IS THE MMD WITH STANDARD ERROR OF THE MEAN BETWEEN
CORRESPONDING SAMPLES AND REAL-WORLD NON-MEMBERS IN THE
TEST DATASET.)
Sample trans
0.194 ± 0.009 0.438 ± 0.039
Random perp Random generation Cross domain
3.024 ± 1.024
Training set
0.225 ± 0.015 1.864 ± 0.022
formances of different kernel functions are in Table XII and
the ones of different classiﬁers in Table XIII.
[Observation RQ4-1] The Gaussian kernel outperforms
other kernels in most of the cases.
As shown in Table XII, the Gaussian kernel outperforms
other kernels in all the datasets of BLINDMI-DIFF-w/ and most
of the datasets of BLINDMI-DIFF-w/o (except for CH-MNIST
and CIFAR-100); the Laplacian kernel comes next due to its
12
0.00.20.40.60.81.0Privacy-Utility Budget Parameter020406080100F1-Score (%)NNTop3-NNTop2+TrueLoss-ThreLabel-OnlyTop1-ThreBlindMI (this work)0.000.020.040.060.080.10Privacy-Utility Budget Parameter020406080100F1-Score (%)NNTop3-NNTop2+TrueLoss-ThreLabel-OnlyTop1-ThreBlindMI (this work)012345Privacy-Utility Budget Parameter020406080100F1-Score (%)NNTop3-NNTop2+TrueLoss-ThreLabel-OnlyTop1-ThreBlindMI (this work)0.000.250.500.751.001.251.501.752.00Privacy-Utility Budget Parameter020406080100F1-Score (%)NNTop3-NNTop2+TrueLoss-ThreLabel-OnlyTop1-ThreBlindMI (this work)TABLE XII.
F1-SCORE (%) WITH STANDARD ERROR OF MEAN FOR
DIFFERENT KERNEL FUNCTIONS OF BLINDMI-DIFF
TABLE XIII.
F1-SCORE (%) WITH STANDARD ERROR OF MEAN FOR
DIFFERENT ROUGH SAMPLE SEPARATION CLASSIFIERS FOR
BLINDMI-DIFF-W/O.
Gaussian (default) Laplacian
Threshold (default)
initial
+ diff-w/o.
K-means
Agg. Clustering
initial
Dataset
Adult
initial
+ diff-w/o.
+ diff-w/o.
60.2±0.04 62.7±1.12 55.1±1.75 60.1±1.02 58.7±0.90 59.4±0.23
70.6±0.58 75.0±1.40 70.0±1.15 74.9±0.23 70.0±1.15 73.0±0.50
EyePACS
CH-MNIST 73.2±0.71 75.1±1.89 70.3±0.18 72.0±2.46 69.8±0.21 76.3±1.41
76.9±0.00 83.3±0.57 74.2±0.43 82.2±4.84 70.6±0.86 81.3±0.06
Location
Purchase-50 69.0±0.00 76.2±0.25 73.6±0.28 74.2±1.23 72.7±0.90 73.3±0.66
68.9±0.03 80.7±2.37 71.4±0.33 77.0±1.51 70.6±0.49 79.4±1.47
CIFAR-100 68.8±0.13 92.1±1.15 82.9±1.01 87.7±0.98 81.1±3.20 86.2±4.20
71.4±0.03 96.2±0.26 92.9±0.77 93.5±0.23 94.7±0.99 96.1±0.37
Birds-200
Taxes
/
w
-
F
F
I
D
o
/
w
-
F
F
I
D
Adult
EyePACS
CH-MNIST
Location
Purchase-50
Texas
CIFAR-100
Birds-200
Adult
EyePACS
CH-MNIST
Location
Purchase-50
Texas
CIFAR-100
Birds-200
64.2±1.59
77.7±0.80
75.1±1.49
86.2±0.90
78.0±0.31
85.5±0.80
93.9±0.63
96.8±0.09
62.7±1.12
75.0±1.40
75.1±1.89
83.3±0.57
76.5±0.25
80.7±2.37
92.1±1.15
96.2±0.26
Linear
Sigmoid Polynomial
60.3±0.38 40.7±0.20 51.1±0.41 58.4±1.02
67.3±0.31 71.8±0.93 72.8±0.87 73.9±0.88
73.1±0.92 72.4±0.53 71.3±0.71 72.7±1.20
85.1±2.42 83.4±0.98 79.8±1.52 76.7±0.17
68.9±0.50 75.8±0.61 71.1±1.05 66.0±0.99
83.6±0.47 81.2±0.29 80.9±0.49 81.9±1.72
93.3±0.79 87.9±1.09 86.9±1.02 90.1±0.83
91.9±1.32 95.7±1.06 94.4±1.31 93.9±0.96
52.2±0.74 50.1±0.32 48.9±0.63 57.1±1.83
72.9±0.65 69.4±0.19 69.2±0.28 70.1±0.53
75.7±2.22 72.9±1.23 71.9±0.84 73.0±1.82
81.2±1.89 76.4±0.67 77.4±2.15 72.1±0.08
66.1±0.67 74.9±0.09 74.5±0.38 76.5±1.12
76.2±1.24 74.1±0.80 74.7±0.79 75.8±1.02
92.8±1.32 82.9±0.33 80.9±0.36 88.9±0.86
96.0±0.34 95.7±0.83 94.1±0.51 94.4±1.02
similarity to the Gaussian kernel (the former adopts L1-norm
and the latter L2-norm); the linear kernel, due to its simplicity,
performs the worst.
[Observation RQ4-2] The threshold classiﬁer outperforms
other initial sample separation classiﬁers for BLINDMI-DIFF-
w/o.
We evaluate three initial sample separation classiﬁers. The
threshold classiﬁer (“Threshold”) is a separation based on the
highest probability score, among which we select the 1,000
lowest ones as our nonmembers. The others are two different
clustering algorithm including K-means and Agglomerative
Clustering.
Table XIII shows that the “Threshold” is the worst for
initial F1-score but the best after BLINDMI-DIFF-w/o. The
reason is the “Threshold” only selects a few samples with a
high probability to be nonmembers. Since “Threshold” left out
many nonmembers, the initial F1-score is relatively low; at the
same time, a high quality nonmember set also helps BLINDMI-
DIFF-w/o to achieve a relatively good performance. The results
of K-means and Agglomerative Clustering are similar. The
initial F1-scores are higher than “Threshold”; however, since
there does not exist a set with high quality nonmembers or
members, the performance of BLINDMI-DIFF-w/ is relatively
lower.
We also show the precision,
recall and F1-score of
BLINDMI-DIFF-w/ (with “Threshold” as the classiﬁer) as the
number of iterations increases in Figures 4, 5, and 6. The
recall starts from a point that is very close to 1 and drops as
the number of iterations; by contrast, the precision increases
steadily together with the F1-score. It is worth noting that
the recalls of Adult and CH-MNIST drop the most compared
with other datasets because members are more similar to
nonmembers in target models trained from these two datasets.
F. RQ5: Number of Moves, Iterations, and Execution Time of
BLINDMI-DIFF
In this research question, we measure the time and the
numbers of moves and iterations of BLINDMI-DIFF to ﬁnish
the inference of the target dataset. Note that moves are atomic
steps in which BLINDMI moves a sample from Sprob,k
target to
13
Fig. 4. Precision vs. # of moves per batch for BLINDMI-DIFF-w/o.
Fig. 5. Recall vs. # of moves per batch for BLINDMI-DIFF-w/o.
Fig. 6. F1-Score vs. # of moves per batch for BLINDMI-DIFF-w/o.
01000200030004000500060007000The number of moves per batch (batch size = 1000)405060708090100Precision (%)AdultEyePACSCH-MNISTLocationPurchase-50TexasCIFAR-100Birds-20001000200030004000500060007000The number of moves per batch (batch size = 1000)405060708090100Recall (%)AdultEyePACSCH-MNISTLocationPurchase-50TexasCIFAR-100Birds-20001000200030004000500060007000The number of moves per batch (batch size = 1000)405060708090100F1-Score (%)AdultEyePACSCH-MNISTLocationPurchase-50TexasCIFAR-100Birds-200TABLE XIV.
EXECUTION TIME (SECOND) AND # OF MOVES AND # OF
ITERATIONS WITH STANDARD ERROR OF MEAN FOR BLINDMI-DIFF
BlindMI-diff-w/.
BlindMI-diff-w/o.
Dataset
Adult
Moves (#)
Iter. (#)
7,012±98
2,818±14
983±29
857±4
Time (s) Moves (#)
Iter. (#)
Time (s)
494±23 63,124±616
2,530±28 202,407±694 405±14
224±16 44,838±858
120±9
751±31
30±2
12,181±386
293±28
9,839±120
271±18
31±2
127±3
48,943±373 4,336±114 1,215±45
110±7
781±4
47,428±903
168±9
984±59
842±68
107±2
94,247±448
25,061±429
20,659±464
97,243±761
67,379±746
104,006±310
70,109±325
3,086±65
CIFAR-100 238±15 41,128±358 3,051±101
2,067±25
Birds-200
183±18 30,261±647
EyePACS
CH-MNIST 73±11
70±2
Location
370±6
313±5
Purchase-50
Texas
nonmem. Then, iterations are when BLINDMI updates the
Sprob,k
distance between Sprob,k
nonmem. The evaluation results
are shown in Table XIV.
target and Sprob,k
[Observation RQ5-1] The execution time and the number of
moves and iterations depend on the size of the target dataset.
Our ﬁrst observation is that the execution time and number
of moves and iterations depend on the size of the target
dataset. The larger the target dataset is, the longer time and
more moves and iterations it
takes for BLINDMI-DIFF to
ﬁnish the inference. The reason is that the larger size of the
datasets increases the number of moves per interation, and thus
increases the potential time and numbers of iterations taken by
BLINDMI-DIFF.
[Observation RQ5-2] BLINDMI-DIFF-w/o takes signiﬁ-
cantly longer time, and more moves, than BLINDMI-DIFF-w/.
Our second observation is that BLINDMI-DIFF-w/o is
generally slower than BLINDMI-DIFF-w. The reason is that
BLINDMI-DIFF-w/o adopts bi-directional differential compar-
ison: The moves are bi-directional and thus the number of
BLINDMI-DIFF-w/o is larger than BLINDMI-DIFF-w/.
[Observation RQ5-3] The total number of iterations de-
pends on the batch size.
Our third observation is that the batch size determines the
number of iterations: That is why BLINDMI-DIFF-w/ with a
batch size as 20 takes more iterations than BLINDMI-DIFF-
w/o with a batch size as 1,000. Speciﬁcally, when the batch
size is small, the number of batches is large, but the number
of iterations per batch does not differ much, leading to a large
number of iterations in total.
[Observation RQ5-4] The distance between two sets in-
creases as the number of moves per batch.
Our last observation is on the distance between two sets
vs. the number of moves per batch as shown in Figures 7
(BLINDMI-DIFF-w/) and 8 (BLINDMI-DIFF-w/o). Note that
only a move that increases the distance is a valid one between
two sets; otherwise, the sample is kept in the original set.
G. RQ6: BLINDMI with Different Conﬁgurations
In this subsection, we evaluate BLINDMI with different
conﬁgurations, including different nonmember-to-member ra-
tios (Bargav et al. [25]) and different prediction classes. The
evaluations are performed under the blackbox setting as many
attacks require ground-truth labels.
1) Different Nonmember-to-member Ratios:
In this part,
we evaluate the F1-score of BLINDMI and existing attacks
when the nonmember-to-member in the target dataset changes.
Fig. 7. Distance vs. # of iterations per batch for BLINDMI-DIFF-w/.
Fig. 8. Distance vs. # of iterations per batch for BLINDMI-DIFF-w/o.
Speciﬁcally, we follow Bargav et al.
the
Nonmember-to-Member ratio r and measure the F1-score.
The underlying rational behind the introduction of r is that a
practical target dataset usually has a small number of members
and a large number of nonmembers. Our evaluation results
based on CIFAR-100 are shown in Figure 9.
to adjust
[25]
[Observation RQ6-1] While the performance of all MI
attacks degrades as the nonmember-to-member ratio (r) in-
creases, BLINDMI is the slowest among all and signiﬁcantly
outperforms existing attacks at a large r value.
This observation shows the practicability of BLINDMI
under real-world settings. All other attacks in the literature
drops logarithmically as r increases, while the performance
decrease of BLINDMI is stable. That is, the performance of
existing attacks drops below 50% when r is larger than 10,
while the performance BLINDMI is still above 50%,
i.e.,
57.5% (35% than the state-of-the-art), when r equals to 39.
2) Different Prediction Classes: In this part, we evaluate
the F1-score of BLINDMI and all other attacks when the
number of classes in the target model increases. The exper-
iment settings are as follows. We divide the entire CIFAR-100
datasets into subsets with 2, 10, 50, 70, and 100 classes and
then launch MI attacks against target models trained from these
subsets. The F1-scores of these attacks are shown in Figure 10
and our observation is as follows.