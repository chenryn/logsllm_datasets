22.02
avg
18.42
6.4 Case 4. Humanoid Attack by Disguising as
an Auto-play Video Assist Function
Some fraudulent activities are not only limited to clicking on static
ads, but also pretend to be an accessibility service to help users to
automatically play videos at the code level, but its real purpose is to
click on the ad video. "com.iB***" SDK is a typical representative of
this kind of humanoid attack. It initializes a VideoWebView class
in the VideoAdActivity function, and predefines an onReadyPlay
callback function in this class. In this callback function, it will
check whether the ad video is playing, and if it is not playing, it will
automatically click the ad video. The "com.iB***" SDK forces people
who want to leave because they are not interested in the ad video to
watch the video to increase their ad revenue. The download number
of the apps affected by this SDK is over 476 million across all app
markets searched on [23].
7 DISCUSSION
Scalability of ClickScanner. In this work, we proposed a new
time-saving and efficient framework for click fraud detection. To
foster a broader impact, we implemented an efficient backward
program slicing framework in ClickScanner which can detect
the assignment process of any variable or parameters of any API.
Hence, our framework can be easily extended by researchers for
targeted and efficient security vetting of modern Android apps.6
In the future, we will also enhance ClickScanner to search over
native code, and also extend it to other problems.
Analysis of misclassification cases. By manual analysis, the rea-
sons for misclassifications are as follows: For the 11 apps in the
seed apps that are misclassified by ClickScanner: 1) False posi-
tives: some apps simulate a human click to obtain the focus of the
window. Although Android provides a standardized API to achieve
this function, obtaining focus through this inappropriate method
is rare. 2) False negatives: some views, although they include ad
contents, are not regarded as ad views by ClickScanner. For the
9 false positives in the basic dataset: 4 of them simulate a hu-
man click to obtain the focus of the window; 3 of them simulate a
human click to automatically play a non-ad video; 2 of them are
game apps, which achieve the expected game effect by shielding
the original user’s click event in the game webview and generating
new click events. To solve these issues, expending more effort on
checking whether the click event target is the input box or non-ad
video player in the webview, or improving the accuracy of ad view
detection are both feasible solutions.
Limitation 1: Fraud codes and instructions issued by remote
servers. One of the major limitations in ClickScanner is the in-
ability to detect complex JavaScript or encrypted instructions that
do not reside in the original fraudulent app and come from a com-
mand and control server, which is almost impossible to detect at
the code level. To put a detail on ClickScanner, it can detect click
6Publicly available at https://github.com/Firework471/ClickScanner.
Figure 11: The code snippet from the case 2 in the case study.
The configuration and commands of humanoid attack come
from the server, and the occurrence of fake click will be
adaptively controlled locally to avoid detection.
coordinates from the JSON data structure returned from the config-
uration URL to construct the MotinoEvent object and implement the
humanoid attack. In doing so, the app can automatically execute
a fake click on a random point in the ad view without the user
actually clicking on the phone screen. The traffic of this fake click
is identical to what would be generated by a real person, and hence
the app adaptively avoids detection.
6.3 Case 3. Humanoid Attack through Infected
Ad SDKs
The above two apps involve only one developer (although the
humanoid attack code snippets involved in case 1 exist in multiple
apps developed by the same company). As we mentioned in the
Section 5, fraudulent developers now have shifted from directly
developing app applications to developing SDKs, which can make
their click fraud code affect more apps. "com.mo***" is an adver-
tising SDK with humanoid attack codes involved in 43 apps out
of 120,000 apps. It will override the onClick() method when ini-
tializing the ad view. This ad view will automatically click itself
again when it is clicked by a user, which causes the ad view to be
clicked twice in the advertiser’s view. This fraudulent SDK has a
greater impact than the previous two because all apps that install
this SDK will participate in fraudulent activities intentionally or
unintentionally. The total number of app installations affected by
this SDK reaches 270 million since they were made available on
Google Play. It is worth noting that we found the source code of this
SDK on the GitHub, and the developer deleted this code by himself
on November 5, 2020. We guess this may be related to Google’s
increasingly strict anti-ad-fraud measures.
new Handler(…).postDelayed(… {  if(clk_count < max_clk) {   public void run() { ……   loadAD(url); …… }  }},(new Random().nextInt(6)*1000);public void loadAD(url) {this.a.loadUrl(url);++ clk_count;……  public boolean shouldOverrideUrlLoading  (WebView AdView, String ADConfig) {  ……  parseConfig(ADConfig);}private void parseConfig(String ADConfig) {  String[] clkConfig = ADConfig.split("//");  this.adClk(Long.parseLong(clkConfig [0]),Integer.parseInt(clkConfig [1]), Float.parseFloat(clkConfig[2]),Float.parseFloat(clkConfig[3]));}public static void adClk(…, clk_type, clkConfig_x, clkConfig_y, …) {MotionEvent v9=MotionEvent.obtain(…clk_type, clkConfig_x, clkConfig_y,…);  adView.onTouchEvent(v9);  ……}Start parsing the configuration information of fake  click issued by the serverImplement humanoid attack based on the parsed click coordinates and click typeIf the number of fake clicks does not exceed the max_clk sent by the server, the ad will be loaded after a random delay and humanoid attack will be implementedSession 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea282fraud generated by the local code. However, if all the execution
codes or commands are sent by a server at run time, due to the
intrinsic problem of static analysis, ClickScanner can only know
that the app will dynamically execute some code at a certain mo-
ment. Because ClickScanner cannot fetch the content of the code,
it is impossible to know whether this code is used to perform click
fraud. Hence, one future direction of this research is to support
context-based static analysis to infer the purpose of the loaded code
or instruction and analyze the dynamically loaded code using tools
like DyDroid [37].
Limitation 2: Other types of ad views. Although we have used
one of the most popular and obfuscation-resilient tools, LibRadar-
[30], with several constraints to identify ad views, our taxonomy
may still be incomplete since it was built based on the current poli-
cies and literature available. This is also one of the main causes of
the false-positives and false-negatives. Nevertheless, we can adjust
the threshold appropriately to make a trade-off in the result, or we
can use more tools [7, 27] to identify ad libraries and ad views. Ad-
ditionally, due to the scalability of ClickScanner, ClickScanner
is generic and can be extended to support the detection of click
frauds on potential new types of ad views.
Limitation 3: Obfuscation. ClickScanner ’s ability is constrain-
ed to its employed static analysis tool FlowDroid. ClickScanner
can live well with lightweight obfuscation mechanisms since the
logic of humanoid attacks is exposed. However, it cannot han-
dle apps that adopt advanced obfuscations or packing techniques
to prevent analysis of the app’s bytecode. To address this issue,
ClickScanner could actively interact with other techniques (e.g.,
deobfuscation, unpacking, binary analysis) to recover the protected
bytecode.
8 RELATED WORK
In recent years, research in click fraud detection has mainly focused
on dynamic analysis. Some of these approaches analyze ad network
traffic and summarize a pattern of click-fraud traffic. Others rely
on installing an additional patch or SDK on users’ devices to check
whether the ad click is fraudulent or not by checking the click
pattern of touch events.
Traffic patterns associated with ad network traffic. Some pre-
vious works claimed that fraudulent clicks have different traffic
patterns from benign ones. FraudDroid [14] builds UI state transi-
tion graphs and collects their associated runtime network traffics,
which are then leveraged to check against a set of heuristic-based
rules for identifying ad fraudulent behaviors. MAdFraud [11] auto-
matically runs apps simultaneously in emulators in the foreground
and background for 60 seconds each and found ad click traffic that
occurred under the testing environment involving no user interac-
tion. Clicktok [32] detects clickspam by searching for reflections of
click traffic, encountered by an ad network in the past. Detection
with traffic analysis depends primarily on the network traffic set
gathered.
Local pattern associated with click events. Some previous wor-
ks claimed that fraudulent clicks have different performance on
users’ devices compared to benign ones. FraudDetective [20] com-
putes a full stack trace from an observed ad fraud activity to a user
event and generates the causal relationships between user inputs
and the observed fraudulent activity. AdSherlock [8] injects the
online detector into the app executable archive and marks the touch
events as click fraud when the Android kernel does not generate
a MotionEvent object or the properties of the generated Motion-
Event object remain unchanged. DECAF [28] performs dynamic
checking in an emulator and marks ad frauds if the layout or page
context violates a particular rule. ClickGuard [42] takes advantage
of motion sensor signals from mobile devices since the pattern of
motion signals is different under real click events and fraud events.
However, ClickGuard will likely cause participants concern over
data collection [16, 25, 44].
These tools above played an important role in revealing the
occurrence of mobile click fraud. However, if fraudulent apps (e.g.,
the apps implementing humanoid attacks proposed in this study)
simulate the real human’s clicks patterns to bridge the gap between
normal clicks and fake clicks in the click patterns, or hide their
fraudulent behaviors while executing, or only trigger clicks in a
certain period, models may fail at the very first stage. Crucially,
most of the previous strategies cannot pinpoint which app class
conducts click fraud.
9 CONCLUSION
In this paper, we explored a new and sophisticated click fraud,
named humanoid attack, and we successfully revealed its attack
patterns through static analysis. We designed and implemented
ClickScanner for uncovering humanoid attacks. By applying
ClickScanner to measure real-world market apps containing 120
thousand apps, ClickScanner identifies 157 fraudulent apps from
20,000 top-rated apps in Google Play and Huawei AppGallery. Our
work also informs the impact of ad SDKs on click fraud and the
distribution of fraudulent apps among different categories and pop-
ularity. In conclusion, our work suggests that the humanoid attack
is still widespread in the current app markets and we hope that the
detection tool ClickScanner developed in this paper can effectively
combat the emerging humanoid attack.
ACKNOWLEDGEMENTS
We thank the shepherd, Merve Sahin, and other anonymous re-
viewers for their insightful comments. We thank Jian Zhang and
Zhushou Tang, affiliated to PWNZEN InfoTech Co., LTD, for their
valuable assistance of our analysis of the motivating example. The
authors affiliated with Shanghai Jiao Tong University were, in part,
supported by the National Natural Science Foundation of China
under Grant 61972453 and the National Natural Science Founda-
tion of China under Grant 62132013. Minhui Xue was, in part,
supported by the Australian Research Council (ARC) Discovery
Project (DP210102670) and the Research Center for Cyber Security
at Tel Aviv University established by the State of Israel, the Prime
Minister’s Office and Tel Aviv University. Xiaokuan Zhang was
supported in part by the NortonLifeLock Research Group Graduate
Fellowship.
Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea283REFERENCES
[1] Kevin Allix, Tegawendé F. Bissyandé, Jacques Klein, and Yves Le Traon. 2016.
AndroZoo: Collecting Millions of Android Apps for the Research Community. In
Proceedings of the 13th International Conference on Mining Software Repositories
(MSR ’16). Association for Computing Machinery, New York, NY, USA, 468–471.
https://doi.org/10.1145/2901739.2903508
[2] Android. 2020. The 20 Most Popular Android Apps in the Google Play Store.
https://developer.android.com/reference/android/app/Activity.
[3] Android. 2020. MotionEvent Android Developers. https://developer.android.com/
reference/android/view/MotionEvent.
[4] Android.
2020.
ers.
MotionEvent#obtain(long,long,int,float,float,int).
Develop-
https://developer.android.com/reference/android/view/
MotionEvent.obtain
Android
[5] Apkpure. 2020. Download APK free online downloader. https://apkpure.com/.
[6] Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bodden, Alexandre Bartel,
Jacques Klein, Yves Le Traon, Damien Octeau, and Patrick McDaniel. 2014. Flow-
Droid: Precise Context, Flow, Field, Object-Sensitive and Lifecycle-Aware Taint
Analysis for Android Apps. In Proceedings of the 35th ACM SIGPLAN Conference
on Programming Language Design and Implementation (PLDI ’14). Association for
Computing Machinery, New York, NY, USA, 259–269.
[7] Michael Backes, Sven Bugiel, and Erik Derr. 2016. Reliable Third-Party Library
Detection in Android and Its Security Applications. In Proceedings of the 2016
ACM SIGSAC Conference on Computer and Communications Security (CCS ’16).
Association for Computing Machinery, New York, NY, USA, 356–367.
[8] Chenhong Cao, Yi Gao, Yang Luo, Mingyuan Xia, Wei Dong, Chun Chen, and Xue
Liu. 2021. AdSherlock: Efficient and Deployable Click Fraud Detection for Mobile
Applications. IEEE Transactions on Mobile Computing 20, 4 (2021), 1285–1297.
https://doi.org/10.1109/TMC.2020.2966991
[9] Gong Chen, Wei Meng, and John Copeland. 2019. Revisiting Mobile Adver-
tising Threats with MAdLife. In The World Wide Web Conference (WWW ’19).
Association for Computing Machinery, New York, NY, USA, 207–217.
[10] Geumhwan Cho, Junsung Cho, Youngbae Song, and Hyoungshick Kim. 2015. An
Empirical Study of Click Fraud in Mobile Advertising Networks. In Proceedings
of the 2015 10th International Conference on Availability, Reliability and Security
(ARES ’15). IEEE Computer Society, USA, 382–388.
[11] Jonathan Crussell, Ryan Stevens, and Hao Chen. 2014. MAdFraud: Investigating
Ad Fraud in Android Applications. In Proceedings of the 12th Annual International
Conference on Mobile Systems, Applications, and Services (MobiSys ’14). Association
for Computing Machinery, New York, NY, USA, 123–134.
[12] Vacha Dave, Saikat Guha, and Yin Zhang. 2012. Measuring and Fingerprinting
Click-Spam in Ad Networks. SIGCOMM Comput. Commun. Rev. 42, 4 (Aug. 2012),
175–186.
[13] Android Developers. 2017. UI/Application Exerciser Monkey.
https://
developer.android.com/studio/test/monkey.
[14] Feng Dong, Haoyu Wang, Li Li, Yao Guo, Tegawendé F. Bissyandé, Tianming Liu,
Guoai Xu, and Jacques Klein. 2018. FraudDroid: Automated Ad Fraud Detection
for Android Apps. In Proceedings of the 2018 26th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations of Software
Engineering (ESEC/FSE 2018). Association for Computing Machinery, New York,
NY, USA, 257–268.
[15] Yanick Fratantonio, Antonio Bianchi, William Robertson, Engin Kirda, Christo-
pher Kruegel, and Giovanni Vigna. 2016. TriggerScope: Towards Detecting Logic
Bombs in Android Applications. In 2016 IEEE Symposium on Security and Privacy
(SP). IEEE, 377–396. https://doi.org/10.1109/SP.2016.30
[16] Michael C. Grace, Wu Zhou, Xuxian Jiang, and Ahmad-Reza Sadeghi. 2012. Unsafe
Exposure Analysis of Mobile In-App Advertisements. In Proceedings of the Fifth
ACM Conference on Security and Privacy in Wireless and Mobile Networks (WISEC
’12). Association for Computing Machinery, New York, NY, USA, 101–112.
[17] Hamed Haddadi. 2010. Fighting online click-fraud using bluff ads. ACM SIGCOMM
Computer Communication Review 40, 2 (2010), 21–25.
[18] Google Inc. 2018. Monkeyrunner. https://developer.android.com/studio/test/
monkeyrunner.
[19] Md. Shahrear Iqbal, Md. Zulkernine, Fehmi Jaafar, and Yuan Gu. 2016. FCFraud:
Fighting Click-Fraud from the User Side. In 2016 IEEE 17th International Sym-
posium on High Assurance Systems Engineering (HASE). IEEE, 157–164. https:
//doi.org/10.1109/HASE.2016.17
[20] Sooel Son Joongyum Kim, Jung-hwan Park. 2020. The Abuser Inside Apps:
Finding the Culprit Committing Mobile Ad Fraud. In 28th Network & Distributed
System Security Symposium (NDSS ’21). 1–16.
[21] Yosuke Kikuchi, Hiroshi Mori, Hiroki Nakano, Katsunari Yoshioka, Tsutomu
Matsumoto, and Michel Van Eeten. 2016. Evaluating Malware Mitigation by
Android Market Operators. In Proceedings of the 9th USENIX Conference on Cyber
Security Experimentation and Test (CSET’16). USENIX Association, USA, 4.
[22] John Koetsier. Aug 24,2020. Malicious Chinese SDK In 1,200 iOS Apps With
Billions Of Installs Causing ‘Major Privacy Concerns To Hundreds Of Millions
Of Consumers’.
https://www.forbes.com/sites/johnkoetsier/2020/08/24/
malicious-chinese-sdk-in-1200-ios-apps-with-billions-of-installs-causing-
major-privacy-concerns-to-hundreds-of-millions-of-consumers/.
[23] KUCHUAN. 2021. KUCHUAN. https://www.kuchuan.com/.
[24] Kaspersky Lab. 2021. Kaspersky Cyber Security Solutions for Home & Business.
https://www.kaspersky.com.
[25] Pedro Leon, Blase Ur, Richard Shay, Yang Wang, Rebecca Balebako, and Lorrie
Cranor. 2012. Why Johnny Can’t Opt out: A Usability Evaluation of Tools to
Limit Online Behavioral Advertising. In Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems (CHI ’12). Association for Computing
Machinery, New York, NY, USA, 589–598.