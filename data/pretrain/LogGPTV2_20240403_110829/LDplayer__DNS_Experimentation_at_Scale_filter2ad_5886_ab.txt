authoritative servers. We then capture all the DNS responses that
authoritative servers respond, recording the traffic at the upstream
network interface of the recursive server. Since the recursive server
walks down the DNS hierarchy for each queries, the captured trace
contains all authoritative data needed to build zones for the parts of
the DNS hierarchy that are needed for the replay. When we do trace
replay from our rebuilt zones, a recursive might fail to resolve a
query if the query was not exercised when the zone was generated.
Zone construction need to be done only once (we save the recre-
ated zones for reuse) so any load it places on the original servers
is a one time cost. We also prototyped an alternative that primes
these zones with replies from the trace, but we found that caching
makes raw traces incomplete if the traces are captured after the
cache is warm. We therefore rebuild the entire zone from scratch to
provide a consistent snapshot. If an experiment requires updated
zone data, we make an additional pass of zone construction.
Figure 1: LDplayer architecture
However, connection-oriented protocols bring challenges in trace
replay: emulating connection reuse and round-trip time (RTT). The
query replay system of LDplayer is the first system that can emulate
connection reuse for DNS over TCP. Emulation of RTT is important
for experiments of connection-oriented DNS, because RTT will
affect protocol responses with extra messages for connection setup,
while connectionless protocols do not incur those extra messages.
2.2 Architecture Overview
We next describe LDplayer’s architecture (Figure 1). With captured
network traces of DNS queries (required) and responses (optional),
a researcher can use our Zone Constructor to generate required zone
files. LDplayer uses a logically single authoritative DNS server with
proxies to emulate entire DNS hierarchy (Hierarchy Emulation). The
single DNS server provides all the generated zone files. The prox-
ies manipulate packet addresses to achieve successful interaction
between the recursive and authoritative servers, such as providing
correct answers to replayed queries. As a distributed query system,
the Query Engine replays queries in the captured traces. Optionally,
the researcher can use Query Mutator to change the original queries
arbitrarily for different replay, and query mutator can run live with
query replay.
Each component in LDplayer addresses a specific design require-
ment from §2.1. In LDplayer’s zone constructor, we synthesize data
for responses and generate required zone files by performing one-
time fetch of missing records over the Internet (§2.3). We run a real
DNS server that hosts these reusable zone files and provides an-
swers to replayed queries, so that we can get repeatable experiments
without disturbing the Internet.
With generated zone files, we need to emulate DNS hierarchy
to provide correct answers. Logically, we want many server hosts,
one per each zone, like the real world. However, we compress those
down to a single server process with single network interface using
split-horizon DNS [1, 8], so that the system scales to many zones.
For easy deployment, we redirect the replayed experimental traffic
to proxies, which then manipulate packet addresses to simplify
routing configuration and discriminate queries for different zones
to get correct responses (§2.4). We could run multiple instances
Query MutatorZoneConstructorRecursiveServerAuthoritativeServerPre-capturedNetwork traceProxyProxyAuthoritativeServerrecursive replayauthoritativereplay (optional)QueryEngineHierarchy EmulationRoot, TLD, SLD ...Single zoneIMC ’18, October 31-November 2, 2018, Boston, MA, USA
L. Zhu et al.
Construct Zones from Traces: Given the traces captured at
the recursive server, we next reverse the traces to recreate appro-
priate zone data.
We convert traces to multiple zone files, since a full DNS query
(for example, mail.google.com) may touch several different servers
(root, .com, googlemail.l.google.com, plus their authoritative name-
servers, DNSSEC records, etc.).
We first scan the whole trace and identify authoritative name-
servers (NS records) for different domains and their host addresses
(A or AAAA records) from all the responses. Since most of domains
have multiple nameservers (for example, google.com has 4 name-
servers: ns{1-4}.google.com), a recursive server may choose any of
them to trace the query based on its own strategy. We group the
set of nameservers responsible for the same domain, and aggre-
gate all DNS response data from the same group of nameservers
by checking the source address in responses. We then generate an
intermediate zone file from the aggregate data.
Since a nameserver can serve multiple different zones, the inter-
mediate zone file we generate may contain data of different domains
and may not be a valid zone file acceptable by a DNS server. We fur-
ther split the response data in the intermediate zone file by different
domains, and output corresponding separated zone files. Optionally
we can also merge the intermediate zone files of multiple traces. To
determine zone cuts (which parts of the hierarchy are served by
different nameservers), we probe for NS records at each change of
hierarchy.
Similarly, we can recreate a zone file for queries replaying at
an authoritative server. Since only single authoritative server is in-
volved without the recursive, the zone file reconstruction is straight-
forward.
Recover Missing Data: Sometimes records needed for a com-
plete, valid zone will not appear in the traces. For example, a valid
zone file needs SOA (Start of Authority) record and NS records for
the zone, however, those records are not required for regular DNS
use. We create a fake but valid SOA record and explicitly fetch NS
records if they are missing.
Handle inconsistent replies: DNS queries sometimes vary
over time, such as replies to CDNs that balance load across a cluster,
or in the unlikely event that the zone is modified during our rebuild.
DNS records can be updated. However sometimes those update
conflict with each other, such as multiple CNAME records for the
same name while only one allowed in principal. More often, the
address mapping for names may change over time, such as content
delivery network (CDN) redirecting by updating DNS using its own
algorithm.
By default, to build a consistent zone, we choose the first answer
when there are multiple differing responses. Simulating the various
CDN algorithms to give different addresses for queries is future
work.
2.4 Emulate DNS Hierarchy Efficiently
With zones created from traces, we next introduce how we emulate
DNS hierarchy in order to answer replayed queries correctly in
LDplayer. Handling queries to a recursive server requires emulating
Figure 2: With a network tunnel (TUN), server proxies ma-
nipulate the source and destination addresses in the queries
and responses to make routing work and get the correct re-
sponses.
multiple hierarchical zones, while handling queries to an author-
itative server does not need to emulate hierarchy due to a single
zone.
The greatest challenges of emulating full DNS hierarchy in a
testbed environment are scalability to support many different zones
and easy deployment. Since we use real DNS records (such as real
public IP addresses) in zone files, the other challenge is how to make
these zone files work in a private testbed environment with local
IP addresses. A naive way would use separate authoritative servers
for each zone, each on its own server. Even with virtual machines,
such an approach cannot emulate typical recursive workloads that
see hundreds or thousands of zones over days or weeks—it will
encounter limits of memory and virtual network interfaces. We
see 549 valid zones in a 1-hour trace Rec-17 (Table 1) captured at a
department-level recursive server. DNS server software can host
multiple zones in one server, but optimizations built into common
server software mean that putting the whole hierarchy in one server
gives different results. (Asking for www.example.com will directly
produce an IP address from a server that stores the root, .com, and
example.com zones, not three queries.)
Scale to many zones with a single server: To emulate com-
plete DNS hierarchy efficiently, instead we contribute a meta-DNS-
server: a single authoritative server instance with a single network
interface correctly emulates multiple independent levels of DNS
hierarchy using real zone files, while providing correct responses
as if they were independent.
Challenges: There are some challenges in making the recursive
server successfully interact with the meta-DNS-server during query
replay, because we use a single server instance and a single network
interface to provide authoritative service to all relevant zones in
the trace.
First, how do the queries sent by the recursive server merge to
the same network interface at meta-DNS-server? Typically, if a re-
cursive receives an incoming query (for example, www.google.com
A) with cold cache, it walks down the DNS hierarchy (for example,
root → com → google.com) and sends queries to respective author-
itative servers (for example, a.root-servers.net → a.gtld-servers.net
→ ns1.google.com). As a result, the queries out of the recursive
StubRecursiveServerRecursive ProxyRecursive TUNall queries(dport: 53)From: RecTo: .comFrom:.comTo:  AutFrom: .comTo: RecAuthoritativeServerAuthoritative ProxyAuthoritativeTUNall responses(sport: 53)From: AutTo: .comDNS Experimentation at Scale
IMC ’18, October 31-November 2, 2018, Boston, MA, USA
have a set of different destination IP addresses. Without changes,
those queries will not be routed to the meta-DNS-server by default.
Second, how does the meta-DNS-server know which zone files
to use in order to answer the incoming queries correctly? When a
recursive server resolves an incoming query iteratively with cold
cache, the query content sent by the recursive is the same, regardless
of which level of the DNS hierarchy it is contacting. Assume the
meta-DNS-server receives a query (for example, www.google.com
A) which was meant to send to the authoritative server of com.
The meta-DNS-server is not able to identify the target zone (com)
based on the query content. The answers from root, com and google.
com zones are are completely different (a referral answer of com,
a referral answer of google.com, and an authoritative answer of
www.google.com A respectively). A wrong answer which is not
from the correct zone (com) can lead to a broken hierarchy at the
recursive and further failure of query replay.
Third, how are meta-DNS-server’s responses accepted by the
recursive server? Assume the meta-DNS-server can pick the correct
zone (for example, com) to answer queries (we will present the
solution later). All the reply packets by meta-DNS-server have the
same meta-DNS-server’s address as source IP addresses. Even if the
recursive receives this “correct” reply, it will not accept the reply
because the reply source address (the address of meta-DNS-server)
is not matched with the original query destination address (for
example, the address of a.gtld-servers.net)
Solutions: To overcome those challenges, at high level, we use
split-horizon DNS [1, 8] to host different zones discriminated by
incoming query source addresses. We use network tunnel (TUN) to
redirect all the DNS queries and responses to proxies. Those proxies
further manipulate packets addresses to successfully deliver the
packets and to let the meta-DNS-server find the correct answers
(Figure 2). We explain details of our solutions in the following.
To redirect recursive server’s queries to meta-DNS-server we
must change the destination or source addresses of those DNS
packets.
Before any address manipulation, we first need to capture all
the queries and responses, because any leaked packets are non-
routable and dropped, leading to the failure of trace replay. We
create two TUN interfaces to get all required packets at the recursive
and meta-DNS-server respectively (Figure 2). We use port based
routing that all queries (packets with destination port 53) at the
recursive, and responses (packets with source port 53) at the meta-
DNS-server are routed to TUN interfaces. We manage this routing
by using iptable: first mark the desired packets using mangle table,
and then redirect all the marked packets to TUN interfaces. We
choose TUN interface because it let us observe all raw IP packets
to manipulate IP addresses.
We build two proxies (recursive proxy and authoritative proxy) to
manipulate packet addresses at the recursive server and meta-DNS-
server respectively (Figure 2). The common task of the proxies is
to make sure captured packets can be routed to the server at the
other end smoothly for correct trace replay. Specifically, recursive
proxy captures recursive server’s queries and authoritative proxy
captures meta-DNS-server’s responses. Then, both of the proxies
rewrite the destination address with the IP address of the server at
the other end.
To make the meta-DNS-server determine the correct answer and
let the recursive server accept the reply, the proxies replace the
source address with the original destination address in the packets.
We will explain the functionality of using original destination ad-
dress below. After recalculating the checksum, the proxies send the
modified packets directly to the meta-DNS server and the recursive
server respectively.
This process with proxy rewriting allows the meta-DNS server
to determine to which zone each query is addressed. To address
the zone selection, the meta-DNS server hosts multiple zones using
software-based, split-horizon DNS [1, 8], where a server provides
different answers based on query source and destination addresses.
When a recursive server resolves an incoming query iteratively with
cold cache, the destination addresses (target authoritative server
address) of the iterative queries is the only identifier for different
zones, because the query content is always the same and not dis-
tinguishable by itself. However, matching queries by destination
addresses at the meta-DNS-server requires the server listens on
different network interfaces for each zone separately, which brings
deployment complexity, such as creating many (virtual) network
interfaces and a giant routing table in testbed. This complexity
conflicts our goal of scalability and deployability to support many
different zones.
With split horizon, we make the meta-DNS server listen on one
address and uses the source IP address to determine for which level
of the hierarchy the query is destined. Since recursive proxy already
replaces the query source address with the original query destina-
tion address (OQDA), the current query source address becomes the
zone identifier now. To correctly discriminate queries for different
zones, we take the public IP addresses of zone’s nameservers as
the matching criteria (query source addresses). In this way, the
meta-DNS-server sees a query coming from OQDA instead of the
recursive server’s address (Figure 2). The meta-DNS server then
determines the correct zone file from the this source address, and
issues a correct reply where the destination address is OQDA. As
discussed above, the authoritative proxy captures this reply, and
puts the destination address in source address. As a result, the recur-
sive server observes a normal reply from OQDA and can match this
reply to the original query, without knowing any address manip-
ulation in the background. Our method works with authoritative
server implementation that supports split-horizon DNS, such as
BIND with its view and match-clients clauses in configuration.
2.5 Mutate Trace For Various Experiments
Another benefit of our system is that we support arbitrary trace
manipulation to study different questions from one trace.