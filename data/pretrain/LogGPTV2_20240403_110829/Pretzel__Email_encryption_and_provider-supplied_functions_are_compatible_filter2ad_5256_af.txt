516.6 KB
402.0 KB
201.0 KB
B = 512
2.0 MB
2.0 MB
402.0 KB
201.0 KB
B = 2048
8.0 MB
8.0 MB
401.9 KB
201.2 KB
Baseline
Pretzel (B′ = B)
Pretzel (B′ = 20)
Pretzel (B′ = 10)
Figure 11: Network transfers per email for topic extraction in Pret-
zel and Baseline. B′ is the number of candidate topics in decomposed
classification (§4.3). Network transfers are independent of the num-
ber of features in the model (N) and email (L) (Figure 3).
false positives, or non-spam falsely classified as spam; higher recall
means lower false negatives, or spam falsely classified as non-spam.)
6.2 Topic extraction
This subsection reports the resource overheads (provider- and client-
side cpu time, network transfers, and client-side storage space use)
and accuracy of topic extraction in Pretzel.
We experiment with N = {20K, 100K})6 and B = {128, 512, 2048}.
These parameters are based on the total number of features in the
topic extraction datasets we use and Google’s public list of topics
(2208 topics [8]). For the number of candidate topics for Pretzel
(§4.3), we experiment with B′ = {5, 10, 20, 40}.
Provider-side cpu time. Figure 10 shows the per email cpu time
consumed by the provider. Without decomposed classification (§4.3)—
this is the B′ = B case in the figure—Pretzel’s cpu time is signif-
icantly higher than NoPriv’s but lower than Baseline’s. Pretzel’s
time differs from Baseline’s because packed xpir-bv ciphertexts
have lower decryption cpu time per plaintext element than Paillier
ciphertexts. With decomposed classification, the number of com-
parisons inside Yao’s framework come down and, as expected, the
difference between cpu times in Pretzel and NoPriv drops (§4.3).
For B = 2048, B′ = 20, Pretzel’s cpu time is 1.78× NoPriv’s; for
B = 2048, B′ = 10, it is 1.03× NoPriv’s.
6The number of features in topic extraction models are usually much lower than in
spam models because of word variations for spam, for example, FREE and FR33, etc.
10-1100101102103104B = 128B = 512B = 2048CPU time per email (ms)  (lower is better)number of categories in topic extraction modelNoPrivBaselinePretzel (B’ = B)Pretzel (B’ = 20)Pretzel (B’ = 10)SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
T. Gupta et al.
7 DISCUSSION, LIMITATIONS, FUTURE WORK
Pretzel is an improvement over its baseline (§3.3) of up to 100×, de-
pending on the resource (§6). Its absolute overheads are substantial
but, as just discussed (§6.3), are within the realm of plausibility.
Pretzel’s prototype has several limitations. It handles only the
functions we presented (spam filtering, topic extraction, and key-
word search) and only using specific algorithms (linear classifiers).
Extending Pretzel to include other functions (predictive personal
assistance, virus scanning, etc.), other algorithms (neural networks,
etc.), or other (potentially cheaper) theoretical machinery [26] is
future work. So is adapting Pretzel to hide metadata.
A fundamental limitation of Pretzel is information leakage (§2.1).
Section 4.4 discussed this issue and potential remedies. To elaborate
slightly, providers can protect their models (in the spam function)
by periodically revising the model parameters and maintaining
different versions for different clients; hiding classifier algorithms,
which is another line of future work, would also help [125]. And
clients who wish to do so can protect their emails (in topic extrac-
tion) by opting out with plausible deniability; also, providers cannot
expose all or even a substantial fraction of clients this way, as that
would forfeit the original purpose of topic extraction. Nevertheless,
defaults being defaults, most clients would probably not opt out,
which means that particular clients could indeed be targeted by a
sufficiently adversarial provider.
If Pretzel were widely deployed, we would need a way to de-
rive and retrain models. This is a separate problem, with existing
research [121, 123, 132, 134–136]; combining Pretzel and this litera-
ture is future work.
There are many other obstacles between the status quo and de-
fault end-to-end encryption. In general, it’s hard to modify a com-
munication medium as entrenched as email [58]. On the other hand,
there is reason for hope: TLS between data centers was deployed
over just several years [56]. Another obstacle is key management
and usability: how do users share keys across devices and find each
other’s keys? This too is difficult, but there is recent research and
commercial attention [2, 31, 93, 126]. Finally, politics: there are
entrenched interests who would prefer email not to be encrypted.
Ultimately, our goal is just to demonstrate an alternative. We
don’t claim that Pretzel is an optimal point in the three-way tradeoff
among functionality, performance, and privacy (§2.1); we don’t yet
know what such an optimum would be. We simply claim that it is
different from the status quo (which combines rich functionality,
superb performance, but no encryption by default) and that it is
potentially plausible.
Acknowledgments
This draft was improved by comments from and conversations
with Varun Chandrasekaran, Eric Crockett, Natacha Crooks, Peter
Druschel, Ray Mooney, Ashay Rane, Shabsi Walfish, Shane Williams,
Yuanzhong Xu, Samee Zahur, and the anonymous NSDI17 reviewers.
We thank Andrew J. Blumberg for an inspiring conversation about
webmail (non)privacy. This work was supported by an Amazon EC2
student grant; NSF grants 1055057, 1409555, 1423249, and 1514422;
ONR grant N00014-14-1-0469; AFOSR grant FA9550-15-1-0302; and
a Google Research Fellowship.
Figure 14: Classification accuracy of topic extraction classifiers in
Pretzel as a function of N′/N, where N is the total number of fea-
tures in the training part of the datasets and N′ is the number of
selected features (§4.3). The plotted accuracies are for the 20News
(20N), Reuters (REU), and RCV1 (RCV) datasets. 20N and REU come
pre-split into training and testing parts: 60%/40% and 75%/25% for
the two respectively, whereas we randomly split RCV into 70%/30%
training/testing portions. Pretzel can operate at a point where num-
ber of features selected N′ is roughly 25% of N; this would result in
only a marginal drop in accuracy.
Ling-spam
Enron
20 Newsgroup
Reuters-21578
Gmail Inbox (40K emails)
index size
5.2 MB
27.2 MB
23.9 MB
6.0 MB
50.4 MB
query time
0.32 ms
0.49 ms
0.3 ms
0.28 ms
0.13 ms
update time
0.18 ms
0.1 ms
0.12 ms
0.06 ms
0.12 ms
Figure 15: Client-side search index sizes, cpu times to query a key-
word in the indexes (that is, retrieve a list of emails that contain a
keyword), and cpu times to index a new email.
6.3 Keyword search and absolute costs
Figure 15 shows the client-side storage and cpu costs of Pretzel’s
keyword search module (§5).
We now consider whether the preceding costs, in absolute terms,
would be acceptable in a deployment. We consider an average user
who receives 150 emails daily [124] of average size (75 KB) [14],
and owns a mobile device with 32 GB of storage.
To spam filter a long email, the client takes 358 ms, which would
be less than a minute daily. As for the encrypted model, one with
5M features occupies 183.5 MB or 0.5% of the device’s storage. For
network overheads, each email transfers an extra 19.33 KB, which
is 2.8 MB daily.
For topic extraction, the client uses less than half a second of
cpu per email (or less than 75s daily); a model with 2048 categories
(close to Google’s) and 20K features occupies 720.7MB or 2.2% of the
device’s storage (this can be reduced further using feature selection).
Also, the client transfers an extra 59 MB (5.4 times the size of the
emails) over the network daily, when the number of candidate
topics (B′) is 20.
Overall, these costs are certainly substantial—and we don’t mean
to diminish that issue—but we believe that the magnitudes in ques-
tion are still within tolerance for most users.
 50 55 60 65 70 75 80 85 90 95 100 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Classification accuracy (percentage)Fraction of total # of features (N’/N) LR-RCVSVM-RCVNB-RCVLR-REUSVM-REUNB-REULR-20NSVM-20NNB-20NPretzel: Email encryption and provider-supplied functions are compatible
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
REFERENCES
[1] http://openpgp.org/.
[2] https://keybase.io.
[3] http://spamprobe.sourceforge.net/.
[4] http://spambayes.sourceforge.net/.
[5] http://spamassassin.apache.org/.
[6] http://scikit-learn.org/stable/.
[7] http://www.cs.waikato.ac.nz/ml/weka/.
[8] https://support.google.com/ads/answer/2842480?hl=en.
[9] https://www.gnupg.org/software/gpgme/index.html.
[10] https://www.sqlite.org/fts3.html.
[11] https://www.cs.cmu.edu/~./enron/.
[12] http://qwone.com/~jason/20Newsgroups/.
[13] http://www.daviddlewis.com/resources/testcollections/reuters21578/.
[14] http://email.about.com/od/emailstatistics/f/What_is_the_Average_Size_of_
an_Email_Message.htm.
[15] http://www.gossamer-threads.com/lists/spamassassin/users/151578.
[16] http://users.spamassassin.apache.narkive.com/d6ppUDfw/large-scale-global-
bayes-tuning.
[17] http://spamassassin.apache.org/full/3.4.x/doc/Mail_SpamAssassin_Conf.html.
[18] A survey on ring-LWE cryptography, Feb. 2016. https://www.microsoft.com/
en-us/research/video/a-survey-on-ring-lwe-cryptography/.
[19] P. Aditya, R. Sen, P. Druschel, S. J. Oh, R. Benenson, M. Fritz, B. Schiele,
[21] A. Amirbekyan and V. Estivill-Castro. A new efficient privacy-preserving
[20] C. Aguilar-Melchor, J. Barrier, L. Fousse, and M.-O. Killijian. XPIR: Private
B. Bhattacharjee, and T. T. Wu. I-Pic: A platform for privacy-compliant image
capture. In MobiSys, 2016.
Information Retrieval for Everyone. In PETS, 2016.
scalar product protocol. In Australasian conference on Data mining and
analytics (AusDM), 2007.
C. Spyropoulos. An evaluation of Naive Bayesian anti-spam filtering. In
Workshop on Machine Learning in the New Information Age, 2000.
http://www.apple.com/privacy/approach-to-privacy/.
[22] I. Androutsopoulos, J. Koutsias, K. Chandrinos, G. Paliouras, and
[23] Apple. Our Approach to Privacy.
[24] M. L. G. at National Taiwan University. LIBLINEAR–A library for large linear
classification. https://www.csie.ntu.edu.tw/~cjlin/liblinear/.
[25] M. J. Atallah and W. Du. Secure multi-party computational geometry. In
[26] M. Ball, T. Malkin, and M. Rosulek. Garbling gadgets for boolean and
Workshop on Algorithms and Data Structures (WADS). 2001.
arithmetic circuits. In ACM CCS, 2016.
[27] D. Beeby. Rogue tax workers snooped on ex-spouses, family members. Toronto
Star, June 2010. https://www.thestar.com/news/canada/2010/06/20/rogue_tax_
workers_snooped_on_exspouses_family_members.html.
[28] E. Betters. What is Google Assistant, how does it work, and when can you use
it?, Sept. 2016. http://www.pocket-lint.com/news/137722-what-is-google-
assistant-how-does-it-work-and-when-can-you-use-it.
[29] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Šrndić, P. Laskov, G. Giacinto,
[31] J. Bonneau. EthIKS: Using Ethereum to audit a CONIKS key transparency log.
[30] M. Blanton and P. Gasti. Secure and efficient protocols for iris and fingerprint
and F. Roli. Evasion attacks against machine learning at test time. In
ECML-PKDD, 2013.
identification. In ESORICS, 2011.
In FC, 2016.
[32] B. E. Boser, I. M. Guyon, and V. N. Vapnik. A training algorithm for optimal
margin classifiers. In Wkshp on Computational Learning Theory (COLT), 1992.
[33] R. Bost, R. A. Popa, S. Tu, and S. Goldwasser. Machine learning classification
over encrypted data. In NDSS, 2014.
ring-LWE and security for key dependent messages. In CRYPTO, 2011.
[35] L. Breiman, J. Friedman, C. J. Stone, and R. A. Olshen. Classification and
regression trees. CRC press, 1984.
[36] J. Bringer, O. El Omri, C. Morel, and H. Chabanne. Boosting GSHADE
capabilities: New applications and security in malicious setting. In Symposium
on Access Control Models and Technologies (SACMAT), 2016.
message format. RFC 4880, IETF, 2007.
[34] Z. Brakerski and V. Vaikuntanathan. Fully homomorphic encryption from
[37] J. Callas, L. Donnerhacke, H. Finney, D. Shaw, and R. Thayer. OpenPGP
[38] Y.-T. Chiang, D.-W. Wang, C.-J. Liau, and T.-s. Hsu. Secrecy of two-party secure
[39] P. Ciano. How to use Google Now, Mar. 2014.
computation. In IFIP DBSec. 2005.
https://paulciano.org/2014/03/getting-google-now/.
[40] M. Cohen. Web storage overview. https://developers.google.com/web/
fundamentals/instant-and-offline/web-storage/.
[41] K. Conger. Google engineer says he’ll push for default end-to-end encryption