title:APEX: A Verified Architecture for Proofs of Execution on Remote
Devices under Full Software Compromise
author:Ivan De Oliveira Nunes and
Karim Eldefrawy and
Norrathep Rattanavipanon and
Gene Tsudik
APEX: A Verified Architecture for Proofs of Execution 
on Remote Devices under Full Software Compromise
Ivan De Oliveira Nunes, UC Irvine; Karim Eldefrawy, SRI International; 
Norrathep Rattanavipanon, UC Irvine and Prince of Songkla University; 
Gene Tsudik, UC Irvine
https://www.usenix.org/conference/usenixsecurity20/presentation/nunes
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.APEX: A Veriﬁed Architecture for Proofs of Execution
on Remote Devices under Full Software Compromise
Ivan De Oliveira Nunes1, Karim Eldefrawy2, Norrathep Rattanavipanon1,3, and Gene Tsudik1
1University of California, Irvine
2SRI International
PI:EMAIL, PI:EMAIL, PI:EMAIL, PI:EMAIL
3Prince of Songkla University, Phuket Campus
Abstract
Modern society is increasingly surrounded by, and is growing
accustomed to, a wide range of Cyber-Physical Systems (CPS),
Internet-of-Things (IoT), and smart devices. They often per-
form safety-critical functions, e.g., personal medical devices,
automotive CPS as well as industrial and residential automa-
tion, e.g., sensor-alarm combinations. On the lower end of the
scale, these devices are small, cheap and specialized sensors
and/or actuators. They tend to host small anemic CPUs, have
small amounts of memory and run simple software. If such
devices are left unprotected, consequences of forged sensor
readings or ignored actuation commands can be catastrophic,
particularly, in safety-critical settings. This prompts the fol-
lowing three questions: (1) How to trust data produced, or
verify that commands were performed, by a simple remote em-
bedded device?, (2) How to bind these actions/results to the
execution of expected software? and, (3) Can (1) and (2) be
attained even if all software on a device can be modiﬁed and/or
compromised?
In this paper we answer these questions by designing,
demonstrating security of, and formally verifying, APEX: an
Architecture for Provable Execution. To the best of our knowl-
edge, this is the ﬁrst of its kind result for low-end embedded
systems. Our work has a range of applications, especially, au-
thenticated sensing and trustworthy actuation, which are in-
creasingly relevant in the context of safety-critical systems.
APEX is publicly available and our evaluation shows that it
incurs low overhead, affordable even for very low-end embed-
ded devices, e.g., those based on TI MSP430 or AVR ATmega
processors.
1 Introduction
The number and diversity of special-purpose computing de-
vices has been increasing dramatically. This includes all
kinds of embedded devices, cyber-physical systems (CPS) and
Internet-of-Things (IoT) gadgets, utilized in various “smart” or
instrumented settings, such as homes, ofﬁces, factories, auto-
motive systems and public venues. Tasks performed by these
devices are often safety-critical. For example, a typical indus-
trial control system depends on physical measurements (e.g.,
temperature, pressure, humidity, speed) reported by sensors,
and on actions taken by actuators, such as: turning on the A/C,
sounding an alarm, or reducing speed.
A cyber-physical control system is usually composed of mul-
tiple sensors and actuators, at the core of each is a low-cost
micro-controller unit (MCU). Such devices typically run sim-
ple software, often on "bare metal", i.e., with no microkernel
or hypervisor. They tend to be operated by a remote central
control unit and despite their potential importance to overall
system functionality, low-end devices are typically designed to
minimize cost, physical size and energy consumption, e.g., TI
MSP430.
Therefore, their architectural security is usually primitive or
non-existent, thus making them vulnerable to malware infesta-
tions and other malicious software modiﬁcations. A compro-
mised MCU can spoof sensed quantities or ignore actuation
commands, leading to potentially catastrophic results. For ex-
ample, in a smart city, large-scale erroneous reports of electric-
ity consumption by smart meters might lead to power outages.
A medical device that returns incorrect values when queried
by a remote physician might result in a wrong drug being pre-
scribed to a patient. A compromised car engine temperature
sensor that reports incorrect (low) readings can lead to unde-
tected overheating and major damage. However, despite very
real risks of remote software compromise, most users believe
that these devices execute expected software and thus perform
their expected function.
In this paper, we argue that Proofs of Execution (PoX) are
both important and necessary for securing low-end MCUs.
Speciﬁcally, we demonstrate in Section 7.3, that PoX schemes
can be used to construct sensors and actuators that “can not lie”,
even under the assumption of full software compromise. In a
nutshell, a PoX conveys that an untrusted remote (and possibly
compromised) device really executed speciﬁc software, and
all execution results are authenticated and cryptographically
bound to this execution. This functionality is similar to authen-
ticated outputs that can be produced by software execution in
SGX-alike architectures [13, 25] on high-end devices, such as
desktops and servers.
One key building block in designing PoX schemes is Remote
Attestation (RA). Basically, RA is a means to detect malware
on a remote low-end MCU. It allows a trusted veriﬁer (V rf) to
remotely measure memory contents (or software state) of an
USENIX Association
29th USENIX Security Symposium    771
untrusted embedded device (P rv). RA is usually realized as a
2-message challenge-response protocol:
1. V rf sends an attestation request containing a challenge
(C hal) to P rv. It might also contain a token derived from
a secret (shared by V rf and P rv) that allows P rv to au-
thenticate V rf.
2. P rv receives the attestation request, authenticates the to-
ken (if present) and computes an authenticated integrity
check over its memory and C hal. The memory region can
be either pre-deﬁned, or explicitly speciﬁed in the request.
3. P rv returns the result to V rf.
4. V rf receives the result, and decides whether it corre-
sponds to a valid memory state.
The authenticated integrity check is typically implemented as
a Message Authentication Code (MAC) computed over P rv
memory. We discuss one concrete RA architecture in Section 3.
Despite major progress and many proposed RA architectures
with different assumptions and guarantees [6–8, 15, 19, 20, 29,
33, 35, 36, 39], RA alone is insufﬁcient to obtain proofs of
execution. RA allows V rf to check integrity of software re-
siding in the attested memory region on P rv. However, by
itself, RA offers no guarantee that the attested software is ever
executed or that any such execution completes successfully.
Even if the attested software is executed, there is no guarantee
that it has not been modiﬁed (e.g., by malware residing else-
where in memory) during the time between its execution and
its attestation. This phenomenon is well known as the Time-Of-
Check-Time-Of-Use (TOCTOU) problem. Finally, RA does
not guarantee authenticity and integrity of any output produced
by the execution of the attested software.
To bridge this gap, we design and implement APEX: an
Architecture for Provable Execution. In addition to RA, APEX
allows V rf to request an unforgeable proof that the attested
software executed successfully and (optionally) produced cer-
tain authenticated output. These guarantees hold even in case
of full software compromise on P rv. Contributions of this work
include:
– New security service: we design and implement APEX for
unforgeable remote proofs of execution (PoX). APEX is com-
posed with VRASED [15], a formally veriﬁed hybrid RA ar-
chitecture. As discussed in the rest of this paper, obtaining
provably secure PoX requires signiﬁcant architectural support
on top of a secure RA functionality (see Section 7). Nonethe-
less, we show that, by careful design, APEX achieves all neces-
sary properties of secure PoX with fairly low overhead. To the
best of our knowledge, this is the ﬁrst security architecture for
proofs of remote software execution on low-end devices.
– Provable security & implementation veriﬁcation: secure
PoX involves considering, and reasoning about, several details
which can be easily overlooked. Ensuring that all necessary
PoX components are correctly implemented, composed, and
integrated with the underlying RA functionality is not trivial. In
particular, early RA architectures oversimpliﬁed PoX require-
ments, leading to the incorrect conclusion that PoX can be
obtained directly from RA; see examples in Section 2. In this
work, we show that APEX yields a secure PoX architecture.
All security properties expected from APEX implementation
are formally speciﬁed using Linear Temporal Logic (LTL) and
APEX modules are veriﬁed to adhere to these properties. We
also prove that the composition of APEX new modules with a
formally veriﬁed RA architecture (VRASED) implies a concrete
deﬁnition of PoX security.
– Evaluation, publicly available implementation and appli-
cations: APEX was implemented on a real-world low-end
MCU (TI MSP430) and deployed using commodity FPGAs.
Both design and veriﬁcation are publicly available at [1]. Our
evaluation shows low hardware overhead, affordable even
for low-end MCUs. The implementation is accompanied by
a sample PoX application; see Section 7.3. As a proof of
concept, we use APEX to construct a trustworthy safety-critical
device, whereupon malware can not spoof execution results
(e.g., fake sensed values) without detection.
Targeted Devices & Scope: This work focuses on CPS/IoT
sensors and actuators with relatively weak computing power.
They are some of the lowest-end devices based on low-power
single core MCUs with only a few KBytes of program and
data memory. Two prominent examples are: TI MSP430 and
Atmel AVR ATmega. These are 8- and 16-bit CPUs, typically
running at 1-16MHz clock frequencies, with ≈ 64 KBytes of
addressable memory. SRAM is used as data memory and its
size is normally ranges from 4 to 16KBytes, with the rest of
address space available for program memory. These devices
execute instructions in place (in physical memory) and have no
memory management unit (MMU) to support virtual memory.
Our implementation focuses on MSP430. This choice is due to
public availability of a well-maintained open-source MSP430
hardware design from Open Cores [23]. Nevertheless, our
machine model and the entire methodology developed in this
paper are applicable to other low-end MCUs in the same class,
such as Atmel AVR ATmega.
2 Related Work
Remote Attestation (RA)– architectures fall into three cate-
gories: hardware-based, software-based, or hybrid. Hardware-
based [31, 37, 42] relies on dedicated secure hardware compo-
nents, e.g., Trusted Platform Modules (TPMs) [42]. However,
the cost of such hardware is normally prohibitive for low-end
IoT/CPS devices. Software-based attestation [27, 40, 41] re-
quires no hardware security features but imposes strong secu-
rity assumptions about communication between P rv and V rf,
which are unrealistic in the IoT/CPS ecosystem (though, it is
the only choice for legacy devices). Hybrid RA [7,19,21,22,30]
aims to achieve security equivalent to hardware-based mecha-
nisms at minimal cost. It thus entails minimal hardware require-
ments while relying on software to reduce overall complexity
and RA footprint on P rv.
772    29th USENIX Security Symposium
USENIX Association
The ﬁrst hybrid RA architecture – SMART [20] – acknowl-
edged the importance of proving remote code execution on P rv,
in addition to just attesting P rv’s memory. Using an attest-then-
execute approach (see Algorithm 4 in [20]), SMART attempts
to provide software execution by specifying the address of the
ﬁrst instruction to be executed after completion of attestation.
However, SMART offers no guarantees beyond “invoking the
executable”. It does not guarantee that execution completes
successfully or that any produced outputs are tied to this ex-
ecution. For example, SMART can not detect if execution is
interrupted (e.g., by malware) and never resumed. A reset (e.g.,
due to software bugs, or P rv running low on power) might
happen after invoking the executable, preventing its successful
completion. Also, direct memory access (DMA) can occur dur-
ing execution and it can modify the code being executed, its
intermediate values in data memory, or its output. SMART nei-
ther detects nor prevents DMA-based attacks, since it assumes
DMA-disabled devices.
Another notable RA architecture is TrustLite [29], which
builds upon SMART to allow secure interrupts. TrustLite does
not enforce temporal consistency of attested memory; it is
thus conceptually vulnerable to self-relocating malware and
memory modiﬁcation during attestation [9]. Consequently, it
is challenging to deriving secure PoX from TrustLite. Several
other prominent low-to-medium-end RA architectures – e.g.,
SANCUS [35], HYDRA [19], and TyTaN [7] – do not offer
PoX. In this paper, we show that the execute-then-attest ap-
proach, using a temporally consistent RA architecture, can be
designed to provide unforgeable proofs of execution that are
only produced if the expected software executes correctly and
its results are untampered.
Control Flow Attestation (CFA)– In contrast with RA, which
measures P rv’s software integrity, CFA techniques [2, 16, 17,
44] provide V rf with a measurement of the exact control ﬂow
path taken during execution of speciﬁc software on P rv. Such
measurements allow V rf to detect run-time attacks. We believe
that it is possible to construct a PoX scheme that relies on CFA
to produce proofs of execution based on the attested control
ﬂow path. However, in this paper, we advocate a different
approach – speciﬁc for proofs of execution – for two main
reasons:
• CFA requires substantial additional hardware features in
order to attest, in real time, executed instructions along
with memory addresses and the program counter. For ex-
ample, C-FLAT [2] assumes ARM TrustZone, while LO-
FAT [17] and LiteHAX [16] require a branch monitor and
a hash engine. We believe that such hardware components
are not viable for low-end devices, since their cost (in
terms of price, size, and energy consumption) is typically
higher than the cost of a low-end MCU itself. For exam-
ple, the cheapest Trusted Platform Module (TPM) [42],
is about 10× more expensive than MSP430 MCU itself1.
1Source: https://www.digikey.com/
As shown in Section 7.2, current CFA architectures are
also considerably more expensive than the MCU itself
and hence not realistic in our device context.
• CFA assumes that V rf can enumerate a large (potentially
exponential!) number of valid control ﬂow paths for a
given program, and verify a valid response for each. This
burden is unnecessary for determining if a proof of exe-
cution is valid, because one does not need to know the
exact execution path in order to determine if execution
occurred (and terminated) successfully; see Section 4.1
for a discussion on run-time threats.
Instead of relying on CFA, our work constructs a PoX-speciﬁc
architecture – APEX– that enables low-cost PoX for low-end
devices. APEX is non-invasive (i.e., it does not modify MCU
behavior and semantics) and incurs low hardware overhead:
around 2% for registers and 12% for LUTs. Also, V rf is not
required to enumerate valid control ﬂow graphs and the ver-
iﬁcation burden for PoX is exactly the same as the effort to
verify a typical remote attestation response for the same code.
Formally Veriﬁed Security Services– In recent years, several
efforts focused on formally verifying security-critical systems.
In terms of cryptographic primitives, Hawblitzel et al. [24]
veriﬁed implementations of SHA, HMAC, and RSA. Bond