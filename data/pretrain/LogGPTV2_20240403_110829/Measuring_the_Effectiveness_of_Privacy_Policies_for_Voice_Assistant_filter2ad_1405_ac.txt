239
Skills with
duplicate URLs
1,012
292
263
258
239
Top duplicate URLs used by the developer
http://corp.patch.com/privacy
http://www.lottostrategies.com/script/
showpage/1001029/b/privacy_policy.html
http://spokenlayer.com/privacy
https://www.freshdigitalgroup.com/
privacy-policy-for-bots
http://www.witlingo.com/privacy-policy
Table 5: Top 5 developers that published the most skills with
a privacy policy on Amazon Alexa platform.
4.1.4 There are Google and Amazon’s official voice-apps violating
their own requirements. We found two official "Weather" skills on
Amazon Alexa’s skills store, and one of them asks for user’s location
according to the description but it doesn’t provide a privacy policy.
Fig. 5 shows the "Weather" skill developed by Amazon. This skill
may be automatically enabled and available on all Alexa devices
since it is a built-in skill. This example demonstrates that Amazon
Alexa violates its own requirement by publishing voice-apps capa-
ble of collecting personal information without providing a privacy
policy.
6
Figure 5: An official skill lacks a privacy policy. Even though
it collects the user’s location according to the description, no
privacy policy is provided.
We collected 98 Amazon Alexa official skills (i.e., developed by
Amazon, Amazon Alexa Devs, and Amazon Education Consumer
Team), out of which 59 skills come with privacy policy URLs (but
all are duplicate URLs). Among these privacy policy links, 30 links
point to the general Amazon privacy notice and 6 links are the AWS
(Amazon Web Services) privacy notice, Amazon payment privacy
or Alexa term of use. Surprisingly, 23 privacy policy links are totally
unrelated to privacy notice, in which 17 links are Amazon home-
page and 6 links are pages about insurance. In Google’s actions
store, we found 110 official actions developed by Google, in which
101 actions don’t provide a privacy policy. For the 9 actions with
a privacy policy link, they point to two different Google Privacy
Policy pages and both are general privacy policies. Google requires
that every action should have an app-specific privacy policy pro-
vided by developers on submission. However, our analysis reveals
that this requirement has not been enforced in a proper manner.
4.2 Content analysis of privacy policies
4.2.1
Irrelevance to specific voice-app. It is important to cover
all aspects of a service’s data practices in the privacy policy. The
contradiction is providing these data practices for a service that is
not capable of doing any of the data collections mentioned in the
privacy policy. This is especially evident in the Alexa skill store
where most skills have a privacy policy that is common across all
services that the developers provide. These policies do not clearly
define what data practices the skill is capable of. Some of these
privacy policies do not even mention the Alexa skill or Google
action as a service and state that it is the privacy policy of a specific
service such as the website. We analyzed whether a voice-app
mentions the app name in its privacy policy. There are only 3,233
skills out of 17,952 skills (around 18%) mentioning skills’ names in
their privacy policies. For Google actions, 1,038 out of 1,967 actions
(around 53%) mention action names in the privacy policies.
There were also privacy policies provided for kids skills which
mention that the service is not intended to be used by children and
also that the service can collect some form of personal information,
which is not allowed for skills in kids category according to Amazon
Alexa’s privacy requirements [2]. Fig. 6 shows an example where
the privacy policy URL provided with a kids skill disclosing the
collection of personal data. In addition, we found 137 skills in the
Amazon Alexa’s kids category whose privacy policies mention
Figure 6: Privacy policy URL provided with a kids skill
"Headspace Bedtime Story" disclosing the collection of per-
sonal data which is prohibited according to Amazon Alexa’s
privacy requirements [2].
data collection is involved. But they just provide a general privacy
policy. All these skills potentially violate Amazon Alexa’s privacy
requirements on kids skills.
4.2.2 Zero data practice. We applied our method described in
Sec. 3.2 to capture data practices in each privacy policy. Fig. 7
illustrates the cumulative distribution function of data practices
we identified using our privacy policy dataset. For these privacy
policies with data practices, the average amount is 24.2 in Amazon
Alexa and 16.6 in Google Assistant, respectively. The maximum
number of data practices in a privacy policy is 428, which is likely
a general privacy policy rather than an app-specific one.
Figure 7: Number of data practices in a privacy policy.
In particular, 1,117 privacy policies provided with Alexa skills
have zero data practices. Fig. 8 shows the breakdown of different
issues of these privacy policies. 670 URLs lead to totally unrelated
pages which have advertisements and shopping options. 251 URLs
lead to an actual privacy policy page but has no data practices
mentioned. 120 URLs lead to a page where the actual link to the
privacy policy does exist but will be redirected to some other pages.
76 URLs lead to an actual website domain but the link is not found.
These too can be considered as broken links.
Our tool identified 95 Google actions having privacy policies
with zero data practice, as shown in Fig. 8. 37 URLs lead to a page
that is not found. 25 URLs are privacy policies but with no data
practice. 11 URLs lead to unrelated links with shopping options and
product advertisements. 5 URLs lead to a page containing the link
7
(a) Amazon skills with no data practice (b) Google actions with no data practice
Figure 8: Different issues of privacy policies that have zero
data practice in two VA platforms.
to the actual privacy policy. In addition, 17 actions provide their
privacy policy as a Google doc which does not have the correct
permissions set which results in users not being able to access it.
This was exclusively found within the Google actions while they
violate Google’s restriction "the link should be a public document
viewable by everyone".
4.2.3
Inconsistency between the privacy policy and description.
Using the method presented in Section 3.3, we identified 50 Alexa
skills that have a privacy policy which is inconsistent with the
corresponding description. These skills describe the collection of
personal data in the description but these data practices are not
mentioned in the privacy policy provided. The consequence of such
occurrences is that the users are not informed about what happens
to their information and who it is shared with. Among the 50 skills,
19 skills ask for address or location; 10 skills request email/ account/
password; name is asked by 7 skills and 4 skills require the birthday;
other skills ask for phone number, contact, gender or health data.
Fig. 9 shows an example, where the skill "Running Outfit Advisor"
mentions collecting the gender information in the description, but
does not mention this data practice in its privacy policy. In another
case, the description of the skill "Record - Journal - Things to Do
Calendar" describes the collection of personal information like the
address of the user. The description has the following line: "Device
Address. Your device address will be used to provide responses with
events local to your area." In the skill’s privacy policy, the data
practices are not disclosed clearly enough but only says "we will
collect personal information by lawful". We treated this kind of
privacy policy as inconsistent (incomplete) privacy policy since
it fails to give a clear idea about its data practices. Table 11 in
Appendix shows the list of these skills with inconsistency between
the privacy policy and description.
4.2.4 Missing required privacy policies. In Sec. 4.1.1, we have
shown 234 Google actions do not have a privacy policy provided,
which violates its own restriction "Google require all actions to
post a link to their privacy policy in the directory". Here we focus
on Amazon Alexa skills and identify cases with missing required
privacy policies.
To collect user’s personal data for use within the voice-apps,
developers can use the built-in feature of collecting the personal
information directly from their Amazon account after taking per-
missions from the user. This permission is taken from the user
when the skill is first enabled. While this is appropriate and respect
 0 0.2 0.4 0.6 0.8 1 0 10 20 30 40 50 60 70 80 90 100Cumulative Fraction (CDF)Number of Data PracticesGoogle ActionAmazon Skill0100200300400500600700Unrelated pageNo data practice phraseRedirect pagePage not foundSkill number0510152025303540Page not foundNo data practice phraseNeed loginUnrelated pageRedirect pageAction numberthe privacy policy links provided despite the name, the descrip-
tions and the developer name being the same. 13 of these pairs
have different privacy policies links all together. For example, the
skill "Did Thanos Kill Me" uses a duplicate privacy policy link
"https://getstoryline.com/public/privacy.html" (shown in Table 4),
but the corresponding Google action version provides a specific pri-
vacy policy. Since Google requires every action to provide a privacy
policy link, developers provide one with the Google action but may
choose to not provide one along with the Alexa skill since the Alexa
platform doesn’t have this requirement. We found 10 such pairs
of skills. Table 7 shows the list of these skills with cross-platform
inconsistency.
Issue
Skill name
Different privacy
policies provided in
a skill & action pair
A skill doesn’t have
a privacy policy
while the Google
action version has
one
VB Connect, Orbit B-Hyve, Freeze Dancers,
Burbank Town Center, New York Daily News,
uHoo, RadioMv, MyHealthyDay, Real Simple Tips,
Did Thanos Kill Me, Central Mall Lawton, Creative
Director, The Hartford Small Business Insurance
Triple M NRL, Collective Noun, Sleep by Nature
Made, Coin Control, Those Two Girls, Radio
Chaser, A Precious Day, Running facts, Ash
London Live, Weekend Breakfast
Table 7: Same voice-apps with different privacy policies on
two VA platforms.
4.2.6 Potential noncompliance with legal regulations. We ob-
served skills that collect personal information being published on
the Amazon Alexa skills store under the kids category without
providing a privacy policy. For example, Table 6 lists 3 skills (which
are marked with "Kids" in the table) in the kids category lacking a
privacy policy. This is not compliant with the COPPA regulations
which require every developer collecting personal information from
children to follow certain rules. Providing a privacy policy with
accurate information about the data being collected and what it is
used for is one of the main requirements. The objective is to clearly
let the parents know about what personal information can be col-
lected by the skill from their children. Health related information
can also be collected by a skill through the conversational interface
without providing a privacy policy even though only the user can
decide whether to provide it or not. But still having the capability to
do so might be a violation of the HIPAA (Health Insurance Portabil-
ity and Accountability Act) regulation. CalOPPA (California Online
Privacy Protection Act) requires developers to provide a privacy
policy that states exactly what data can be collected from users. In
Sec. 4.2.1, we found that 137 kids skills provide general information
without providing specifics on what personal data they actually
collect. These voice-apps and their privacy policies may not be in
compliance with legal regulations.
4.3 Usability issues
4.3.1 Lengthy privacy policies. One of the main problems asso-
ciated with privacy policies regardless of the type of service it is
provided with is the length of the privacy policy document. Most
developers write long policies that decreases the interest that a user
has in reading it. From the analysis of the privacy policies in our
datasets, as shown in Fig. 2, we observed that 58% of the privacy
Figure 9: "Running Outfit Advisor" skill mentions collecting
the gender information in the description, but does not men-
tion this data practice in its privacy policy.
the users privacy, there is another channel that can be misused for
collecting personal information. A developer can develop a skill to
ask for the personal information from the user through the con-
versational interface. Both Amazon and Google prohibit the use of
conversational interface to collect personal data. But, in the case
of Amazon, this is not strictly enforced in the vetting process. By
collecting personal information in this manner, the developer can
avoid adding a privacy policy URL to the skill’s distribution require-
ments. This is possible because Amazon requires only skills that
publicly declare that they collect personal information to manda-
torily have a privacy policy. The developer can easily bypass this
requirement by lying about not collecting personal information.
Data
Name
Location
Gender
Age
Birthday
Ip Address
# of Skills
10
6
1
1
1
1
Skills names
First Name Analysis, Haircut Scheduler, insurance
service, LOVE CALCULATOR, Mr. Tongue Twister
(Kids), My daily task, Name My Grandkids, Social
Network, Uncle Tony (Kids), who’s right
Doctor Locator, Heritage Flag Color, Lapel Athletics,
OC Transpo, Weather, World Time
Interactive Bed Time Story (Kids)
bright smile
Cake Walk
Network-Assistant
Table 6: Skills with no privacy policies despite mentioning
the collection of users data in their descriptions.
Fig. 10 in Appendix illustrates an example where the skill "Name
My Grandkids" includes in its description that it asks the users for
personal information and stores it for future use. In another case,
the skill "Lapel Athletics" requires the device location according to
its description. But both these skills do not provide a privacy policy.
Table 6 lists skills which are supposed to have a privacy policy but
do not provide one.
4.2.5 Cross-platform inconsistency. For a few voice-apps that
are present on both Alexa and Google platforms, we found that
the privacy policies provided with each are not the same. Com-
paring Google actions and Alexa skills, we found that 23 voice-
apps which are present on both the platforms have differences in
8
policies have more than 1,500 words. Being a legal document, it
takes an average of 12 mins to read 1,500 words. This makes the
privacy policy hard to read for the users and almost impossible
to be read out through voice. The privacy policies of Google and
Amazon themselves are more than 4,300 words each. The average
number of words in a privacy policy provided along with Alexa
skills is 2,336 and that of Google actions is 1,479. This results in
users frequently skipping reading the privacy policy even if it is
provided. The participants of the user study we conducted as shown
in Sec. 8 complained about the length of the privacy policy being
the major reason for them not reading the privacy policy.
4.3.2 Hard to access. The constrained interfaces on VA devices
pose challenges on effective privacy notices. According to the cur-
rent architecture of Amazon Alexa and the Google Assistant, the
privacy policy is not available directly through VA devices used
at home like the Amazon Echo and the Google Home. No prompt
is delivered either during any part of the users interaction with
the voice-app that requests the user to take a look at the privacy
policy. If at all the user wants to view the privacy policy, he/she has
to either find the voice-app listing on the store webpage or check
the companion app using smartphones, and find a voice-app’s pri-
vacy policy URL provided in the listing. The permissions set by
the developer to collect personal information from users is shown
as a prompt in the smartphone companion app to the user while
enabling the voice-app. But as mentioned in the Sec. 4.2.4, develop-
ers do not necessarily have to take permission from user and can
instead collect it during the conversation. We discuss solutions to
improve the usability of privacy notice for voice-apps in Sec. 6.3.
5 USER STUDY
We conducted an online user study using the Amazon Mechanical
Turk crowdsourcing platform [4], and our study has received an IRB
approval. Different from prior user studies that focus on understand-
ing security and privacy concerns of VA devices [15, 25, 31, 37, 43],
we aimed to understand how users engage with privacy policies
and their perspectives on them. We looked for the frequency of
checking the privacy policies and any issues the users might have
encountered with it. Our participants were MTurk workers who
reside in USA, having a HIT (Human Intelligence Tasks) acceptance
rate greater than 98 and have at least 500 HITs approved prior to
this study. These filters were added to reduce the amount of junk
data that we may have collected. All participants were initially pre-