# Modeling HTTP/2 Speed from HTTP/1 Traces

**Authors:**
- Kyriakos Zarifis<sup>1</sup>
- Mark Holland<sup>2</sup>
- Manish Jain<sup>2</sup>
- Ethan Katz-Bassett<sup>1</sup>
- Ramesh Govindan<sup>1</sup>

**Affiliations:**
- 1. University of Southern California, Los Angeles, USA
- 2. Akamai Technologies, Cambridge, USA

## Abstract
With the standardization of HTTP/2, content providers are keen to understand the benefits and potential drawbacks of transitioning to this new standard. Using a large dataset of HTTP/1.1 resource timing data from production traffic on Akamai’s CDN, and a model of HTTP/2 behavior, we analyzed the performance differences between the two protocol versions for nearly 280,000 downloads. Our findings indicate that HTTP/2 provides significant performance improvements, particularly in the tail of the distribution. For websites where HTTP/2 does not improve median performance, we explore how optimizations like prioritization and push can enhance performance and how these improvements relate to page structure.

## 1. Introduction
HTTP/2 is poised to replace HTTP/1.1 as the IETF standard for web traffic delivery, with major browsers and some content providers already supporting it [12]. The design of HTTP/2 addresses several performance concerns associated with HTTP/1.1, particularly focusing on reducing page load time (PLT), which has been shown to correlate with content provider revenue. HTTP/2 introduces features such as multiplexing objects on a single TCP connection, client-specified priorities, and server-side speculative content pushing.

Previous studies have reported mixed results on the performance difference between HTTP/1.1 and HTTP/2 [7, 11, 14]. Assessing the relative performance of these protocols is challenging due to the complex dependencies between objects in modern web pages and the use of multiple hostnames. Many of these studies were conducted in controlled lab environments, often without using real browsers, which limits visibility into browser-side tasks like resource parsing, execution, or rendering.

To address these limitations, we conducted a study using real-world data collected from live page views by end-users. We used HTTP/1.1 Resource Timing [2] data from a broad set of customers on Akamai's CDN. This data includes detailed timing breakdowns for the base page and each embedded resource for a sample of all page views.

### Contributions
1. **rt-h2 Model**: We developed a model, called rt-h2, that takes the resource timing data for a single HTTP/1.1 page view and estimates the difference in PLT between HTTP/1.1 and HTTP/2. The model incorporates key HTTP/2 features: multiplexing, push, prioritization, and frame interleaving, along with a reasonably accurate TCP model for web transfers.
   
2. **Performance Analysis**: We analyzed the PLT differences between HTTP/1.1 and HTTP/2 for nearly 280,000 page views from Akamai customers. We selected 55 distinct websites with a significant number of instrumented page views and explored their relative performance under zero packet loss. Our findings show that HTTP/2 reduces PLT about 60% of the time and has negligible impact in 28% of cases. We also explored the impact of optimizations like prioritization and push, which provided additional improvements, especially for cases where HTTP/2 was already beneficial.

These findings suggest that CDNs should start experimenting with HTTP/2 at scale, as it can offer significant benefits for many clients.

## 2. Background and Approach
A typical web page consists of tens of resources fetched from multiple servers, with many objects having interdependencies. The base HTML file must be downloaded before sub-resources can be requested. Once sub-resources are downloaded and parsed, they can trigger the download of other resources. The user-perceived latency in loading a web page is a complex combination of the time taken to download, parse, and render its resources.

### HTTP/1.1
The original HTTP/1.0 specification allowed only one response-request stream per TCP connection. HTTP/1.1 introduced connection reuse but required that only one request be in flight on a TCP channel at a time. Pipelining, though added, is rarely used [1], so we do not consider it in this paper. To achieve faster downloads, browsers typically open multiple concurrent connections (up to six per hostname) and use domain sharding to partition objects across different hostnames.

### HTTP/2
HTTP/2 allows multiple, concurrent requests on the same TCP connection, preventing a resource from waiting for an idle connection. It also supports explicit prioritization of resource delivery. For example, if a server has both an image and a JavaScript object ready, it can prioritize the JavaScript. This facilitates parallel processing and downloading. Additionally, HTTP/2 enables servers to push content to clients without a request, keeping the connection busy.

### Page Load Time (PLT)
Both HTTP/1.1 and HTTP/2 include performance optimizations aimed at reducing PLT. Recent studies define PLT as the time when the browser fires the `onLoad` event [10].

### Challenges in Understanding Relative Performance
While HTTP/2 offers several optimizations, their performance benefits may not always be realized. The specific policies implemented by web servers for prioritization and push, as well as interactions with TCP, can limit these benefits. Multiplexing on a single channel can slow the growth of the congestion window compared to parallel connections, and recovery from packet loss is more efficient with parallel connections.

### Our Approach
We used Resource Timing [2] data collected via JavaScript from a broad set of customers on Akamai’s CDN. When enabled by a customer, Akamai servers insert a small JavaScript snippet into 1% of the customer’s pages. This script collects per-resource timing information, including DNS lookup, TCP connection setup, TLS handshake, request sent, and response received. The data is then encoded and sent to an Akamai back-end system. Over a one-week period, we observed data for about 44,000 distinct base-page hostnames and 3.4 million distinct base-page URLs.

Our dataset captures detailed timing breakdowns for the base page and each embedded resource from real clients, allowing us to assess PLTs as reported by browser `onLoad` events. However, since our dataset is based on HTTP/1.* downloads, the main challenge is predicting the page load performance under HTTP/2. Deploying a real HTTP/2 setup on the CDN is currently not feasible due to complexity and scale, so we use a model of HTTP/2, described in the next section.

## 3. The RT-H2 Model
### Input
The input to rt-h2 is the Resource Timing (RT) data for a single HTTP/1.1 download of a website from a real client. This data can be visualized as a waterfall diagram. Figure 1 (left) shows a simplified waterfall for a page downloaded via HTTP/1.1, containing seven objects: a base HTML page, one CSS file, three JavaScript files, and three images. The HTML file is downloaded first and parsed as it is being downloaded, triggering the download of dependent resources. Browsers typically limit the number of parallel connections, so only the download of 2.css is initiated, and other objects are blocked until 1.html completes.

The waterfall diagram also highlights three important features:
1. **Processing Time**: The time between the completion of 3.js and the request for 5.js represents the processing time for 3.js.
2. **Third-Party Content (3PC)**: 5.js is an example of 3PC, which can trigger the download of other 3PC or origin content.
3. **Critical Path**: The critical path demarcates objects whose download and processing times determine the PLT. In Figure 1, 6.png and its ancestors are on the critical path.

The waterfall explicitly contains four kinds of download timing information:
- **Request**: Time from when the object was requested to when the first byte was received.
- **Download**: Time from when the first byte was received to when the last byte was received.
- **Blocked**: Duration between when an object could have been retrieved and when the request was made.
- **3PC**: Retrieval of third-party content.

Real waterfalls can be significantly more complex, with hundreds of objects, multiple levels of dependencies, and various sources of 3PC.

### Output
The output of rt-h2 is a transformed version of the input waterfall, produced by applying HTTP/2 features to the real HTTP/1.1 waterfall, and the percentage change in PLT, denoted as ΔP LT.

### Components of RT-H2
rt-h2 models HTTP/2 in a layered fashion, incorporating the following components:

#### Multiplexing
In HTTP/2, a client maintains a single TCP channel with a server, on which resources are multiplexed. rt-h2 analyzes the input waterfall to determine which objects can be multiplexed. Resources with URIs covered by the origin's certificate can reuse the same channel. rt-h2 parses resource URLs and assumes that any hostname serving more than five resources in the same download is origin content. Browser-cached resources, identified by retrieval times less than 10 ms, are excluded from the multiplexer's output.

#### Push
This component emulates the ability of an HTTP/2 server to proactively send resources to a client without a request. For example, in Figure 1 (left), 2.css, 3.js, and 4.png could be served as soon as 1.html is requested, rather than waiting for the client to request them.

By combining these components, rt-h2 provides a comprehensive model for estimating the performance of HTTP/2 based on HTTP/1.1 traces.