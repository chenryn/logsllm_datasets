executable code to be less than half of a percent on average,
with a maximum overhead of 1.1%. This overhead is minimal
because we maintain good cache locality by keeping the switch
table close to its use. In addition, modern processors can
prefetch instructions past direct jumps, which means these
jumps have a low performance impact. We omit this experiment
from Figure 11 for clarity, since it showed such minimal
overheads.
b) Code-Pointer Hiding: We then evaluated full code
pointer protection, with hiding of both function pointers and
return addresses enabled. We found that code-pointer hiding
resulted in a performance slowdown of 4.1% on average over
all benchmarks (Pointer Hiding in Figure 11). This protection
introduces two extra direct jumps for each method call and one
direct jump when de-referencing function pointers. On closer
inspection using hardware performance counters, we observed
that these jumps back and forth from the regular code section to
the trampolines slightly increased the instruction-cache pressure,
resulting in more instruction-cache misses.
We hypothesized that
the bulk of code-pointer hiding
overhead was due to call trampolines, which are far more
common than function pointers. To verify this, we disabled
return address hiding while keeping function pointer protection
enabled. We found that function pointer protection by itself
incurred an average overhead of only 0.2% on SPEC, with
no benchmark exceeding 2%. Thus, most of the overhead
for code-pointer hiding is caused by the frequent use of call
trampolines. This effect is ampliﬁed in benchmarks which make
many function calls, such as xalancbmk.
c) Hypervisor: To understand the performance impact of
the hypervisor layer, including the additional EPT translation
overhead, we ran SPEC under our hypervisor without any
execute-only page protections or code-pointer hiding enabled
(Hypervisor in Figure 11). We observed that the virtualization
overhead was 1.1% on average. Since we allow the virtual
processor full control of all hardware and registers,
this
overhead is mainly caused by the extra memory translation
overhead from translating guest physical addresses to host
physical addresses through the EPT. Even though we use
an identity mapping from guest physical to host physical
addresses, the processor must still walk through the whole
EPT whenever translating a new memory address. The larger
overhead observed for the mcf benchmark supports this theory,
as it has a higher and more stable memory footprint (845Mib)
than the other benchmarks [31]. This results in more swapping
in and out of the cache, which in turn triggers more EPT
address translations.
773
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:24 UTC from IEEE Xplore.  Restrictions apply. 
Pointer Hiding
Hypervisor
Hypervisor XO
Hypervisor XO + Hiding
Full Readactor
)
%
(
l
n
w
o
d
w
o
S
e
c
n
a
m
r
o
f
r
e
P
40
30
20
10
0
m ilc
n a m d
d e alII
so plex
lb m
s p hin x3
p erlb e n c h
b zip 2
g c c
m cf
g o b m k
h m
m er
lib q u a ntu m
sje n g
h 2 6 4ref
Figure 11: Performance overhead for SPEC CPU2006 with Readactor enabled relative to an unprotected baseline build.
xala n c b m k
astar
G e o  M e a n
After compiling SPEC with separation of code and data and
marking code pages as execute-only during linking, we ran the
benchmarks under the hypervisor, enforcing execute-only page
permissions (Hypervisor XO in Figure 11). This conﬁguration
incurred a performance slowdown of 2.5%, somewhat higher
than the overhead of the hypervisor itself. Much of this overhead
difference is due to the separation of code and data, which
de-optimizes execution slightly. We attribute the rest of this
difference to measurement variance, since the hypervisor itself
should not add any signiﬁcant overhead when enforcing execute-
only pages versus legacy readable and executable pages. In
either case the processor must still translate all addresses
through the EPT when the hypervisor is enabled.
d) Full Readactor: Enabling code-pointer hiding along
with page protections provided by the hypervisor resulted in
a slowdown of 5.8% (Hypervisor XO + Hiding in Figure 11).
This overhead is approximately the sum of the overheads of
both components of the system, the execute-only hypervisor
enforcement and pointer hiding. This conﬁrms our hypothesis
that each component of the Readactor system is orthogonal
with respect to performance.
With the addition of our ﬁne-grained diversity scheme
(function, register, and callee-saved register slot permutation)
we now have all components of Readactor in place. For the
ﬁnal integration benchmark we built and ran SPEC using three
different random seeds to capture the effects of different code
layouts. Altogether we observed that the full Readactor system
incurred a geometric mean performance overhead of 6.4% (Full
Readactor in Figure 11). This shows the overhead of applying
our full protection scheme to a realistic worst-case scenario of
CPU-intensive code, which bounds the overhead of our system
in practice.
2) Chromium Browser: To test the performance impact of
our protections on complex, real-world software, we compiled
and tested the Chromium browser, which is the open-source
variant of Google’s Chrome browser. Chromium is a highly
complex application, consisting of over 16 million lines of
code [10]. We were able to easily apply all our protections
to Chromium with the few minor changes described below.
Overall, we found that the perceived performance impact on
web browsing with the protected Chromium, as measured by
Chromium’s internal UI smoothness benchmark, was 4.0%,
which is in line with the average slowdown we observed for
SPEC.
Since our protection system interferes with conventional
stack walking, we had to disable debugging components of
Chromium that use stack walking. We found that the optimized
memory allocator used in Chromium, TCMalloc, uses stack
tracing to provide detailed memory proﬁling information
to developers. We disabled this functionality, which is not
needed for normal execution. We also observed that Chromium
gathers stack traces at tracing points during execution, again
for debugging. Conveniently, we could disable this stack
tracing with a single-line source code change. With these
minor modiﬁcations we could compile and test the current
development version3 of Chromium with our LLVM-based
Readactor compiler.
To understand the perceived performance impact dur-
ing normal web browsing we benchmarked page scrolling
smoothness with Chromium’s internal performance testing
framework. We ran the scrolling smoothness benchmark from
the Chromium source tree on the Top 25 sites selected by
Google as representatives of popular websites. This list includes
13 of the Alexa USA Top 25 sites including Google properties
such as Google search, GMail and Youtube, Facebook, and news
websites such as CNN and Yahoo. The Chromium scrolling
benchmark quantiﬁes perceived smoothness by computing the
mean time to render each frame while automatically scrolling
down the page. We report the average slowdown as time per
frame averaged over 3 runs of the benchmark suite to account
for random variance.
Overall, we found that the slowdown in rendering speed
for our full Readactor system was about 4.0%, averaged over
3 different diversiﬁed builds of Chromium. This overhead is
slightly lower than what we found for SPEC, which is natural
considering that browser rendering is not as CPU-intensive
as the SPEC benchmarks. However, browser smoothness and
responsiveness are critical factors for daily web browsing, rather
than raw computing performance.
We also evaluated the performance impact of our techniques
on Chromium using the extensive Dromaeo benchmark suite
to give a worst-case estimate for browser performance. This
suite, composed of 55 individual benchmarks, includes standard
3Chromium sources checked out on 2014-11-04.
774
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:24 UTC from IEEE Xplore.  Restrictions apply. 
Modified
Modified + Readactor
40
30
20
10
0
)
%
(
l
n
w
o
d
w
o
S
e
c
n
a
m
r
o
f
r
e
P
E arley B o yer
D elta Blu e
Cry pto
N avierSto kes
R ayTra c e
R e g E x p
Ric h ard s
G e o  M e a n
S play
Figure 12: Performance of modiﬁed V8 running under Readac-
tor, relative to a vanilla build and to a modiﬁed build running
natively.
JavaScript benchmarks such as the Sunspider and V8 JavaScript
benchmarks, as well as benchmarks that exercise DOM and
CSS processing. Dromaeo is comprehensive, and hence, ideal to
evaluate the overall impact of our protections on performance-
critical browser components.
We found that execute-only code protection alone, without
code-pointer hiding, introduced a 2.8% overall performance
slowdown on Dromaeo. Combining the hypervisor execute-
only code pages along with code-pointer hiding resulted in a
12% performance slowdown. We attribute this higher overhead
to increased instruction cache pressure caused by our call
pointer protection. However, Dromaeo represents a worst-case
performance test, and rendering smoothness on real websites
is a far more important factor in browsing.
3) V8 JavaScript JIT: We evaluated the performance impact
of our changes to the V8 JavaScript engine, as well as the
overhead of running the JIT compiler under Readactor. To
get a more accurate sample, we benchmarked the V8 engine
alone, outside of the browser. Figure 12 shows the results of
our evaluation. We see small to negligible overhead for most
benchmarks, with the exception of two benchmarks which put
signiﬁcant pressure on the memory allocator: EarleyBoyer and
Splay. Both benchmarks allocate large numbers of temporary
objects and trigger frequent garbage collection cycles, which
become much more expensive due to our repeated re-mapping
of pages. For another benchmark—Richards—we observe a
very small speedup of 1%, which we attribute to measurement
noise. Overall, the performance penalty of our changes comes to
6.2% when running natively and 7.8% with Readactor enabled.
We also added our V8 JIT compiler patches to the full
Chromium browser to evaluate their impact on the whole
browsing experience. We observed a higher impact on scrolling
smoothness, with an average time per frame slowdown of
13.8% versus 4.0% without the JIT compiler patches. This extra
slowdown is due to the overhead of separating JIT generated
data from code to allow the JIT to map generated code pages
as execute-only.
775
XI. RELATED WORK
Most code-reuse exploit mitigation approaches are based
on either program randomization or some form of integrity
checking. In contrast, Readactor combines a probabilistic
defense against ROP (code layout randomization) with integrity
checks (execute-only page permissions) against disclosure
to comprehensively thwart code-reuse attacks. We discuss
probabilistic and integrity-checking defenses separately. We
summarize the main difference between our approach and
closely related work, namely Oxymoron [6], XnR [7], and
HideM [27] in Table I. Readactor is the only defense that
provides protection against all known variants of ROP attacks
(traditional ROP, direct and indirect JIT-ROP), while performing
efﬁciently and protecting JIT-compiled code.
A. Code Randomization Defenses
Cohen was ﬁrst
to explore program protection using
diversity [18]. Forrest et al. [24] later demonstrated stack-
layout randomization against stack smashing. Address space
layout permutation (ASLP) [37] randomizes the code layout at
function granularity; adversaries must therefore disclose more
than one code pointer to bypass ASLP. Binary Stirring [65]
permutes both functions and basic blocks within functions, and
Instruction Layout Randomization (ILR) [32] randomizes the
code layout at the instruction level. Larsen et al. [40] compare
these and additional approaches to automatic software diversity.
Unfortunately, these defenses remain vulnerable to mem-
ory disclosure attacks. The appearance of JIT-ROP attacks
convincingly demonstrated that probabilistic defenses cannot
tacitly assume that attackers cannot leak code memory layout
at runtime [59]. Blind ROP [9], another way to bypass ﬁne-
grained code randomization, further underscores the threat of
memory disclosure.
In response to JIT-ROP, Backes and Nürnberger proposed
Oxymoron [6] which randomizes the code layout at a granularity
of 4KB memory pages. This preserves the ability to share
code pages between multiple protected applications running on
a single system. Oxymoron seeks to make code references
in direct calls and jumps that span code page boundaries
opaque to attackers. Internally, Oxymoron uses segmentation
and redirects inter-page calls and jumps through a dedicated
hidden table. This prevents direct memory disclosure, i.e., it
prevents the recursive-disassembly step in the original JIT-ROP
attack. Unfortunately, Oxymoron can be bypassed via indirect
memory disclosure attacks as we have described in Section III.
In contrast to Readactor, Oxymoron does not protect JIT-
compiled code. Readactor offers more comprehensive protection
against both direct and indirect code disclosure and protects
JIT-compiled code against direct disclosure.
Another defense against JIT-ROP, Execute-no-Read (XnR)
by Backes et al. [7], is conceptually similar to Readactor as it
is also based on execute-only pages. However, it only emulates
execute-only pages in software by keeping a sliding window
of n pages as both readable and executable, while all other
pages are marked as non-present. XnR does not fully protect
against direct memory disclosure because pages in execution are
readable. Hence, the adversary can disclose function addresses
(see Section III), and force XnR to map a target page as readable
by calling the target function through an embedded script. This
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:24 UTC from IEEE Xplore.  Restrictions apply. 
Property
Note
Oxymoron [6]