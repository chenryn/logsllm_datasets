28.4 ¬± 2.5
56.8 ¬± 2.8
Forward
Correction
18.6 ¬± 2.5
37.1 ¬± 2.5
75.1 ¬± 1.0
38.7 ¬± 1.4
68.8 ¬± 0.7
81.0 ¬± 0.2
68.9 ¬± 1.3
73.8 ¬± 1.1
88.9 ¬± 0.2
44.9 ¬± 5.3
58.5 ¬± 3.6
79.2 ¬± 1.3
Drop
42.9 ¬± 1.5
69.3 ¬± 1.2
78.4 ¬± 0.7
69.8 ¬± 0.7
74.9 ¬± 0.3
81.0 ¬± 0.2
75.1 ¬± 0.6
84.9 ¬± 0.2
90.7 ¬± 0.1
70.0 ¬± 3.0
82.1 ¬± 1.0
85.7 ¬± 0.7
perform better or at least equally compared to the forward correc-
tion method. This result suggests that Drop can effectively utilize
the information within the graph structure to recover the actual
node labels, and more importantly, it can achieve high accuracy
without using any clean labels for model validation, e.g., for early
stopping or hyper-parameter optimization.
5 RELATED WORK
Graph neural networks. Recent years have seen a surge in
applying GNNs for representation learning over graphs, and nu-
merous GNN models have been proposed for graph representation
learning, including Graph Convolutional Networks [26], Graph
Attention Networks [47], GraphSAGE [18], Graph Isomorphism
Networks [59], Jumping Knowledge Networks [60], Gated Graph
Neural Networks [32], and so on. We refer the reader to the avail-
able surveys on GNNs [19, 57] for other models and discussion on
their performance and applications.
Local differential privacy. Local differential privacy has be-
come increasingly popular for privacy-preserving data collection
and analytics, as it does not need any trusted aggregator. There have
been several LDP mechanisms on estimating aggregate statistics
such as frequency [7, 16, 52], mean [11, 12, 50] heavy hitter [54], and
frequent itemset mining [40]. There are also some works focusing
on learning problems, such as probability distribution estimation
[3, 12, 22], heavy hitter discovery [6, 8, 54], frequent new term dis-
covery [49], marginal release [10], clustering [37], and hypothesis
testing [17]. Specifically, LDP frequency oracles are considered as
fundamental primitives in LDP, and numerous mechanisms have
been proposed [4, 6, 7, 16, 52, 62]. Most works rely on techniques
like Hadamard transform [4, 6] and hashing [52]. LDP frequency
oracles are also used in other tasks, e.g., frequent itemset mining
[40, 53], and histogram estimation [22, 51, 55].
Privacy attacks on GNNs. Several recent works have attempted
to characterize potential privacy attacks associated with GNNs and
quantify the privacy leakage of publicly released GNN models or
node embeddings that have been trained on private graph data.
He et al. [1] proposed a series of link stealing attacks on a GNN
model, to which the adversary has black-box access. They show
that an adversary can accurately infer a link between any pair of
nodes in a graph used to train the GNN model. Duddu et al. [13]
presents a comprehensive study on quantifying the privacy leakage
of graph embedding algorithms trained on sensitive graph data.
More specifically, they introduce three major classes of privacy
Session 7A: Privacy Attacks and Defenses for ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2140attacks on GNNs, namely membership inference, graph reconstruc-
tion, and attribute inference attack, under practical threat models
and adversary assumptions. Finally, Wu et al. [56] propose a model
extraction attack against GNNs by generating legitimate-looking
queries as the normal nodes among the target graph, and then
utilizing the query responses accessible structure knowledge to re-
construct the model. Overall, these works underline many privacy
risks associated with GNNs and demonstrate the vulnerability of
these models to various privacy attacks.
Privacy-preserving GNN models. While there is a growing
interest in both theory and applications of GNNs, there have been
relatively few attempts to provide privacy-preserving graph repre-
sentation learning algorithms. Xu et al. [58] proposed a differentially
private graph embedding method by applying the objective per-
turbation on the loss function of matrix factorization. Zhang and
Ni [66] proposed a differentially private perturbed gradient descent
method based on Lipschitz condition [20] for matrix factorization-
based graph embedding. Both of these methods target classic graph
embedding algorithms and not GNNs. Li et al. [29] presented a
graph adversarial training framework that integrates disentangling
and purging mechanisms to remove users‚Äô private information from
learned node representations. Liao et al. [33] also follow an adver-
sarial learning approach to address the attribute inference attack on
GNNs, where they introduce a minimax game between the desired
graph feature encoder and the worst-case attacker. However, both
of these works assume that the server has complete access to the
private data, which is as opposed to our problem setting.
There are also recent approaches that attempted to address pri-
vacy in GNNs using federated and split learning. Mei et al. [35]
proposed a GNN based on structural similarity and federated learn-
ing to hide content and structure information. Zhou et al. [68]
tackled the problem of privacy-preserving node classification by
splitting the computation graph of a GNN between multiple data
holders and use a trusted server to combine the information from
different parties and complete the training. However, as opposed
to our method, these approaches rely on a trusted third party for
model aggregation, and their privacy protection is not formally
guaranteed. Finally, Jiang et al. [21] proposed a distributed and
secure framework to learn the object representations in video data
from graph sequences based on GNN and federated learning, and
design secure aggregation primitives to protect privacy in federated
learning. However, they assume that each party owns a series of
graphs (extracted from video data), and the server uses federated
learning to learn an inductive GNN over this distributed dataset
of graphs, which is a different problem setting than the node data
privacy we studied.
6 CONCLUSION
In this paper, we presented a locally private GNN to address node
data privacy, where graph nodes have sensitive data that are kept
private, but a central server could leverage them to train a GNN for
learning rich node representations. To this end, we first proposed
the multi-bit mechanism, a multidimensional ùúñ-LDP algorithm that
allows the server to privately collect node features and estimate
the first-layer graph convolution of the GNN using the noisy fea-
tures. Then, to further decrease the estimation error, we introduced
KProp, a simple graph convolution layer that aggregates features
from higher-order neighbors, which is prepended to the backbone
GNN. Finally, to learn the model with perturbed labels, we proposed
a learning algorithm called Drop that utilizes KProp for label denois-
ing. Experimental results over real-world graph datasets on node
classification demonstrated that the proposed framework could
maintain an appropriate privacy-utility trade-off.
The concept of privacy-preserving graph representation learn-
ing is a novel field with many potential future directions that can
go beyond node data privacy, such as link privacy and graph-level
privacy. For the presented work, several future trends and improve-
ments are imaginable. Firstly, in this paper, we protected the privacy
of node features and labels, but the graph topology is left unpro-
tected. Therefore, an important future work is to extend the current
setting to preserving the graph structure as well. Secondly, we
would like to explore other neighborhood expansion mechanisms
that are more effective than the proposed KProp. Another future
direction is to develop more rigorous algorithms for learning with
differentially private labels, which is left unexplored for the case of
GNNs. Finally, an interesting future work would be to combine the
proposed LPGNN with deep graph learning algorithms to address
privacy-preserving classification over non-relational datasets with
low communication cost.
ACKNOWLEDGMENTS
This work was supported by the Swiss National Science Foundation
(SNSF) through the Dusk2Dawn project (Sinergia program) under
grant number 173696. Additional support was provided by the Euro-
pean Commission under European Horizon 2020 Programme, grant
number 951911, AI4Media project. We would like to thank Emiliano
De Cristofaro, Hamed Haddadi, Nikolaos Karalias, and Mohammad
Malekzadeh for their helpful comments on eariler drafts of this
paper.
REFERENCES
[1] 2021. Stealing Links from Graph Neural Networks. In 30th USENIX Security
Symposium (USENIX Security 21). USENIX Association, Vancouver, B.C. https:
//www.usenix.org/conference/usenixsecurity21/presentation/he
[2] Sami Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard, Kristina
Lerman, Hrayr Harutyunyan, Greg Ver Steeg, and Aram Galstyan. 2019. M ix H op:
Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood
Mixing (Proceedings of Machine Learning Research, Vol. 97), Kamalika Chaudhuri
and Ruslan Salakhutdinov (Eds.). PMLR, Long Beach, California, USA, 21‚Äì29.
[3] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. 2018. Communication efficient,
sample optimal, linear time locally private discrete distribution estimation. arXiv
preprint arXiv:1802.04705 (2018).
[4] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. 2019. Hadamard response:
Estimating distributions privately, efficiently, and with little communication. In
The 22nd International Conference on Artificial Intelligence and Statistics. PMLR,
1120‚Äì1129.
[5] Borja Balle and Yu-Xiang Wang. 2018. Improving the Gaussian Mechanism for
Differential Privacy: Analytical Calibration and Optimal Denoising. In Interna-
tional Conference on Machine Learning. 394‚Äì403.
[6] Raef Bassily, Kobbi Nissim, Uri Stemmer, and Abhradeep Thakurta. 2017. Practical
locally private heavy hitters. arXiv preprint arXiv:1707.04982 (2017).
[7] Raef Bassily and Adam Smith. 2015. Local, private, efficient protocols for succinct
histograms. In Proceedings of the forty-seventh annual ACM symposium on Theory
of computing. 127‚Äì135.
[8] Mark Bun, Jelani Nelson, and Uri Stemmer. 2019. Heavy hitters and the structure
of local privacy. ACM Transactions on Algorithms (TALG) 15, 4 (2019), 1‚Äì40.
[9] Zhengdao Chen, Xiang Li, and Joan Bruna. 2017. Supervised community detection
with line graph neural networks. arXiv preprint arXiv:1705.08415 (2017).
[10] Graham Cormode, Tejas Kulkarni, and Divesh Srivastava. 2018. Marginal release
under local differential privacy. In Proceedings of the 2018 International Conference
Session 7A: Privacy Attacks and Defenses for ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2141on Management of Data. 131‚Äì146.
[11] Bolin Ding, Janardhan Kulkarni, and Sergey Yekhanin. 2017. Collecting telemetry
data privately. In Advances in Neural Information Processing Systems. 3571‚Äì3580.
[12] John C Duchi, Michael I Jordan, and Martin J Wainwright. 2018. Minimax optimal
procedures for locally private estimation. J. Amer. Statist. Assoc. 113, 521 (2018),
182‚Äì201.
[13] Vasisht Duddu, Antoine Boutet, and Virat Shejwalkar. 2020. Quantifying Privacy
Leakage in Graph Embedding. In Mobiquitous 2020-17th EAI International Con-
ference on Mobile and Ubiquitous Systems: Computing, Networking and Services.
1‚Äì11.
[14] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell,
Timothy Hirzel, Al √° n Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional
networks on graphs for learning molecular fingerprints. In Advances in neural
information processing systems. 2224‚Äì2232.
[15] Cynthia Dwork, Aaron Roth, et al. 2014. The algorithmic foundations of differ-
ential privacy. Foundations and Trends ¬Æ in Theoretical Computer Science 9, 3‚Äì4
(2014), 211‚Äì407.
[16] √ö lfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. 2014. Rappor: Random-
ized aggregatable privacy-preserving ordinal response. In Proceedings of the 2014
ACM SIGSAC conference on computer and communications security. 1054‚Äì1067.
[17] Marco Gaboardi and Ryan Rogers. 2018. Local private hypothesis testing: Chi-
square tests. In International Conference on Machine Learning. PMLR, 1626‚Äì1635.
[18] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation
learning on large graphs. In Advances in neural information processing systems.
1024‚Äì1034.
[19] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation learning
on graphs: Methods and applications. arXiv preprint arXiv:1709.05584 (2017).
[20] Madhav Jha and Sofya Raskhodnikova. 2013. Testing and reconstruction of
Lipschitz functions with applications to data privacy. SIAM J. Comput. 42, 2
(2013), 700‚Äì731.
[21] Meng Jiang, Taeho Jung, Ryan Karl, and Tong Zhao. 2020. Federated Dynamic
GNN with Secure Aggregation. arXiv preprint arXiv:2009.07351 (2020).
[22] Peter Kairouz, Keith Bonawitz, and Daniel Ramage. 2016. Discrete distribution
estimation under local privacy. In International Conference on Machine Learning.
PMLR, 2436‚Äì2444.
[23] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aur√©lien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode,
Rachel Cummings, et al. 2019. Advances and open problems in federated learning.
arXiv preprint arXiv:1912.04977 (2019).
[24] Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova,
and Adam Smith. 2011. What can we learn privately? SIAM J. Comput. 40, 3
(2011), 793‚Äì826.
[25] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[26] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In International Conference on Learning Repre-
sentations (ICLR).
[27] G √º nter Klambauer, Thomas Unterthiner, Andreas Mayr, and Sepp Hochre-
iter. 2017. Self-normalizing neural networks. In Advances in neural information
processing systems. 971‚Äì980.
[28] Johannes Klicpera, Stefan Wei √ü enberger, and Stephan G √º nnemann. 2019.
Diffusion improves graph learning. In Advances in Neural Information Processing
Systems. 13354‚Äì13366.
[29] Kaiyang Li, Guangchun Luo, Yang Ye, Wei Li, Shihao Ji, and Zhipeng Cai. 2020.
Adversarial Privacy Preserving Graph Embedding against Inference Attack. arXiv
preprint arXiv:2008.13072 (2020).
[30] Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph con-
volutional networks for semi-supervised learning. arXiv preprint arXiv:1801.07606
(2018).
[31] Yayong Li, Ling Chen, et al. 2021. Unified Robust Training for Graph NeuralNet-
works against Label Noise. arXiv preprint arXiv:2103.03414 (2021).
[32] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2015. Gated
graph sequence neural networks. arXiv preprint arXiv:1511.05493 (2015).
[33] Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon, Stefanie
Jegelka, and Ruslan Salakhutdinov. 2020. Graph Adversarial Networks: Protecting
Information against Adversarial Attacks. arXiv preprint arXiv:2009.13504 (2020).
[34] Miller McPherson, Lynn Smith-Lovin, and James M Cook. 2001. Birds of a feather:
Homophily in social networks. Annual review of sociology 27, 1 (2001), 415‚Äì444.
[35] G. Mei, Z. Guo, S. Liu, and L. Pan. 2019. SGNN: A Graph Neural Network Based
Federated Learning Approach by Hiding Structure. In 2019 IEEE International
Conference on Big Data (Big Data). IEEE Computer Society, Los Alamitos, CA,
USA, 2560‚Äì2568.
[36] Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric
Lenssen, Gaurav Rattan, and Martin Grohe. 2019. Weisfeiler and leman go neural:
Higher-order graph neural networks. In Proceedings of the AAAI Conference on
Artificial Intelligence, Vol. 33. 4602‚Äì4609.
[37] Kobbi Nissim and Uri Stemmer. 2018. Clustering algorithms for the centralized
and local models. In Algorithmic Learning Theory. PMLR, 619‚Äì653.
[38] Hoang NT, Choong Jun Jin, and Tsuyoshi Murata. 2019. Learning graph neural
networks with noisy labels. arXiv preprint arXiv:1905.01591 (2019).
[39] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and
Lizhen Qu. 2017. Making deep neural networks robust to label noise: A loss
correction approach. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. 1944‚Äì1952.
[40] Zhan Qin, Yin Yang, Ting Yu, Issa Khalil, Xiaokui Xiao, and Kui Ren. 2016.
Heavy hitter estimation over set-valued data with local differential privacy. In
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications
Security. 192‚Äì203.
[41] Sungmin Rhee, Seokjun Seo, and Sun Kim. 2017. Hybrid approach of relation
network and localized graph convolutional filtering for breast cancer subtype
classification. arXiv preprint arXiv:1711.05859 (2017).
[42] Benedek Rozemberczki, Carl Allen, and Rik Sarkar. 2019. Multi-scale Attributed
Node Embedding. arXiv preprint arXiv:1909.13021 (2019).
[43] Benedek Rozemberczki and Rik Sarkar. 2020. Characteristic Functions on Graphs:
Birds of a Feather, from Statistical Descriptors to Parametric Models. In Proceed-
ings of the 29th ACM International Conference on Information and Knowledge
Management (CIKM ‚Äô20). ACM.
[44] Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele
Monfardini. 2008. The graph neural network model. IEEE Transactions on Neural
Networks 20, 1 (2008), 61‚Äì80.
[45] Hwanjun Song, Minseok Kim, Dongmin Park, and Jae-Gil Lee. 2020. Learn-
ing from noisy labels with deep neural networks: A survey. arXiv preprint
arXiv:2007.08199 (2020).
[46] Abhradeep Guha Thakurta, Andrew H Vyrros, Umesh S Vaishampayan, Gaurav
Kapoor, Julien Freudiger, Vivek Rangarajan Sridhar, and Doug Davidson. 2017.
Learning new words. US Patent 9,594,741.
[47] Petar Veli ƒç kovi ƒá, Guillem Cucurull, Arantxa Casanova, Adriana Romero,
Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint
arXiv:1710.10903 (2017).
[48] Hongwei Wang and Jure Leskovec. 2020. Unifying graph convolutional neural
networks and label propagation. arXiv preprint arXiv:2002.06755 (2020).
[49] Ning Wang, Xiaokui Xiao, Yin Yang, Ta Duy Hoang, Hyejin Shin, Junbum Shin,
and Ge Yu. 2018. PrivTrie: Effective frequent term discovery under local differ-
ential privacy. In 2018 IEEE 34th International Conference on Data Engineering
(ICDE). IEEE, 821‚Äì832.
[50] Ning Wang, Xiaokui Xiao, Yin Yang, Jun Zhao, Siu Cheung Hui, Hyejin Shin,
Junbum Shin, and Ge Yu. 2019. Collecting and analyzing multidimensional data
with local differential privacy. In 2019 IEEE 35th International Conference on Data
Engineering (ICDE). IEEE, 638‚Äì649.
[51] Shaowei Wang, Liusheng Huang, Pengzhan Wang, Yiwen Nie, Hongli Xu, Wei
Yang, Xiang-Yang Li, and Chunming Qiao. 2016. Mutual information optimally
local private discrete distribution estimation. arXiv preprint arXiv:1607.08025
(2016).
[52] Tianhao Wang, Jeremiah Blocki, Ninghui Li, and Somesh Jha. 2017. Locally dif-
ferentially private protocols for frequency estimation. In 26th {USENIX} Security
Symposium ({USENIX} Security 17). 729‚Äì745.
[53] Tianhao Wang, Ninghui Li, and Somesh Jha. 2018. Locally differentially private
frequent itemset mining. In 2018 IEEE Symposium on Security and Privacy (SP).
IEEE, 127‚Äì143.
[54] Tianhao Wang, Ninghui Li, and Somesh Jha. 2019. Locally differentially private
heavy hitter identification. IEEE Transactions on Dependable and Secure Computing
(2019).
[55] Yue Wang, Xintao Wu, and Donghui Hu. 2016. Using Randomized Response
for Differential Privacy Preserving Data Collection.. In EDBT/ICDT Workshops,
Vol. 1558. 0090‚Äì6778.
[56] Bang Wu, Xiangwen Yang, Shirui Pan, and Xingliang Yuan. 2020. Model Ex-
traction Attacks on Graph Neural Networks: Taxonomy and Realization. arXiv
preprint arXiv:2010.12751 (2020).
[57] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and
S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE
Transactions on Neural Networks and Learning Systems (2020).
[58] Depeng Xu, Shuhan Yuan, Xintao Wu, and HaiNhat Phan. 2018. DPNE: Differ-
entially private network embedding. In Pacific-Asia Conference on Knowledge
Discovery and Data Mining. Springer, 235‚Äì246.
[59] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful
are graph neural networks? arXiv preprint arXiv:1810.00826 (2018).
[60] Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi
Kawarabayashi, and Stefanie Jegelka. 2018. Representation Learning on Graphs
with Jumping Knowledge Networks. In Proceedings of the 35th International Con-
ference on Machine Learning (Proceedings of Machine Learning Research, Vol. 80),
Jennifer Dy and Andreas Krause (Eds.). PMLR, Stockholmsm√§ssan, Stockholm
Sweden, 5453‚Äì5462.
[61] Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. 2016. Revisiting semi-
supervised learning with graph embeddings. arXiv preprint arXiv:1603.08861
Session 7A: Privacy Attacks and Defenses for ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2142(2016).
[62] Min Ye and Alexander Barg. 2018. Optimal schemes for discrete distribution
estimation under locally differential privacy. IEEE Transactions on Information
Theory 64, 8 (2018), 5662‚Äì5676.
[63] Kun Yi and Jianxin Wu. 2019. Probabilistic end-to-end noise correction for
learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. 7017‚Äì7025.
[64] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2017.
mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412
(2017).
[65] Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural
networks. In Advances in Neural Information Processing Systems. 5165‚Äì5175.
[66] Sen Zhang and Weiwei Ni. 2019. Graph Embedding Matrix Sharing With Differ-