sets, each corresponding to a gaze trace segment. We denote
the candidate set for the i-th trace segment by Ni (‚àÄi ‚àà [1, ns]),
which contains Œ∑ legitimate segments in the ascending order
of their Euclidean distances with the i-th trace segment.
3) Candidate lock patterns: Now we generate the candidate
lock patterns for a gaze trace. Let c1, . . . , c9 denote the nine
white circles of a pattern lock keyboard, as shown in Fig. 8(b).
By setting the center coordinate of c1 to (0, 0), we derive the
center coordinates of other circles and list them in Table II.
Since the gaze trace comprises ns segments with each having
Œ∑ candidate legitimate segments, a candidate lock pattern can
be represented by a row vector p = [p1, . . . , pns+1], where pi
refers to the i-th point that corresponds to one of c1, . . . , c9.
TABLE II.
COORDINATES OF PATTERN-LOCK KEYBOARD DEPICITED
IN FIG. 8(B).
c1
c4
c7
(0,0)
(1,0)
(2,0)
c2
c5
c8
(1,0)
(1,1)
(2,1)
c3
c6
c9
(2,0)
(2,1)
(2,2)
We generate the candidate lock patterns by considering
each possible combination of ns legitimate segments and
then checking its feasibility by traversing on the pattern-
lock keyboard. In each round, we select a random segment
Si among the Œ∑ segments in Ni (‚àÄi ‚àà [1, nt]) to form
a legitimate segment sequence {S1, . . . , Sns
}. There are to-
tally Œ∑ns
rounds, each with a unique legitimate segment
sequence. Assuming that the length and angle of Si are l and
Œ±, respectively, we rewrite Si = (l cos(Œ±), l sin(Œ±)). Given
{S1, . . . , Sns} and an arbitrary starting point ps ‚àà {ci}9
i=1,
we can obtain a candidate lock pattern p, where p1 = ps and
pi = pi‚àí1 + Si‚àí1 (‚àÄi ‚àà [2, ns + 1]). We say that p is feasible
if pi ‚àà {c1, . . . , c9},‚àÄi ‚àà [1, ns + 1]. There are nine possible
choices for ps, each corresponding to a candidate lock pattern.
All the feasible lock patterns are then recorded.
larger
An undesirable consequence of length normalization is
that
lock pattens may be mis-recognized as their
shrunken versions. The example in Fig. 10 illustrates this
aspect. The correct pattern in the example is [c1, c3, c7, c9],
and the gaze trace segments after length normalization are
{(1, 0), (‚àí1, 1), (1, 0)}. So the candidate lock patterns are
[c1, c2, c4, c5], [c2, c3, c5, c6], [c4, c5, c7, c8], and [c5, c6, c8, c9],
illustrated in Fig. 10. Our remedy for the issue is that if a legit-
imate segment sequence {S1, . . . , Sns
} can generate a feasible
lock pattern, we double the length of each segment there and
then check if the new sequence { ÀúS1, . . . , ÀúSns
} can generate a
feasible lock pattern or not, where ÀúSi = (2l cos(Œ±), 2l sin(Œ±)).
All such feasible lock patterns are recorded as well.
4) Ranking candidate lock patterns: The Ô¨Ånal step is to
rank candidate lock patterns with three heuristics as follows.
First, we introduce a row vector r = (r1, . . . , rns ),
where ri ‚àà [1, Œ∑] means that the ri-th segment is chosen
from Ni (‚àÄi ‚àà [1, ns]). Then we generate the Œ∑ns legitimate
segment sequences based on r in the following order:
[1, 1, . . . , 1, 1], [1, 1, . . . , 1, 2], . . . , [1, 1, . . . , 1, Œ∑], [1, 1, . . . , 2, 1],
[1, 1, . . . , 2, 2], . . . [1, 1, . . . , 2, Œ∑], [1, 1, . . . , 3, 1], . . . , [Œ∑, . . . , Œ∑].
150
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:20 UTC from IEEE Xplore.  Restrictions apply. 































(a) Transform alphabetical keyboard to quasi-PIN keyboard.








(b) Denotions in Ta-
ble II.
Fig. 8. Quasi-PIN keyboard.



	


















(a) All possible segments.
(b) A pattern and its segments.
Fig. 9. Segments on pattern-lock keyboard.
(a) c1, c3, c7, c9
(b) c1, c2, c4, c5
(c) c2, c3, c5, c6
(d) c4, c5, c7, c8
(e) c5, c6, c8, c9
that
Fig. 10. Ambuguities due to normalization.
the earlier segments in each Ni have smaller
Recall
Euclidean distances to the corresponding gaze trace segment
than those of the later segments. Earlier legitimate segment
sequences can thus produce higher ranked candidate lock
patterns than later ones.
Second, the candidate lock patterns generated from the
same legitimate segment sequence are ranked according to
their starting points in the order of c1 > c4 > c7 > c2 >
c5 > c8 > c3 > c6 > c9. Such a heuristics is also adopted in
[40].
Finally,
the candidate lock patterns generated from an
enlarged legitimate segment sequence have higher ranks than
those from the original sequence. The intuition is that normal
users tend to draw larger patterns.
HIDDEN KEYS ON PIN KEYBOARD.
TABLE III.
(4,6)
2
(1,9)
6
8
5
5
5
(1,7)
(5,0)
(7,9)
(3,7)
(1,3)
(3,9)
5) PIN keyboard: Now we discuss how EyeTell applies to
the PIN soft keyboard. Fig. 7 and Table XI (in Appendix B)
show the dimensions of the PIN keyboard layout on a Google
Nexus 6 with Android 5.1.1, including the radius of each
key, the horizontal gap, and the vertical gap. We plot the 30
4
8
(2,8)
(2,0)
5
5,8
legitimate segments in Fig. 15 in Appendix B for lack of space.
Note that users slide on the pattern-lock keyboard to draw a
pattern but touch the keys on the PIN keyboard to input a
PIN. A user may input the same key multiple times on the
PIN keyboard, in which case there is little displacement in
the corresponding gaze trace. Furthermore, a user may input
three keys along the same direction sequentially, in which case
the attacker does not know how many keys are touched. For
example, the gaze traces for two different PINs (e.g., [1, 4, 7, 9]
and [1, 7, 8, 9]) can be very similar.
We then modify the process in Section V-D3 to generate
candidate 4-digit PINs.
‚Ä¢
‚Ä¢
‚Ä¢
If there are three trace segments, EyeTell directly
generates candidate 4-digit PINs as in Section V-D3.
If there are two trace segments, EyeTell Ô¨Årst follows
the process in Section V-D3 to generate candidate
3-digit PINs. We abuse the notation by letting a
candidate PIN be denoted by a row vector p,
in
which each element is a key on the PIN keyboard.
We have p = [p1, p2, p3]
initially and then gen-
erate candidate 4-digit PINs as follows. First, we
generate and record [p1, p1, p2, p3], [p1, p2, p2, p3], and
[p1, p2, p3, p3], as the user may type any key twice.
Second, we consider the possible hidden keys between
any two original keys. For example,
if a possible
hidden key ph lies between p1 and p2, we consider
and record [p1, ph, p2, p3] as a candidate PIN as well.
Table III shows the possible hidden keys on the PIN
keyboard corresponding to each pair of original keys.
If there is only one trace segment, EyeTell Ô¨Årst follows
the process in Section V-D3 to generate a 2-digit
PIN denoted by p = [p1, p2]. Then we generate
and record the candidate PINs as [p1, p1, p1, p2], and
[p1, p2, p2, p2].
The above process can be easily extended to 6-digit PINs and
omitted here for lack of space.
6) Alphabetical keyboard: Here we discuss how to adapt
our algorithm to attack the alphabetical keyboard whose layout
dimensions are given in Fig. 7 and Table XI. In contrast to the
PIN keyboard, the alphabetical keyboard has more keys (26
instead of 10) and a smaller area (about 48% smaller), which
poses a great challenge to keystroke inference. We tackle this
challenge by Ô¨Årst transforming the alphabetical keyboard into
a quasi-PIN keyboard, as shown in Table I and depicted in
Fig. 8(a). Then we generate candidate PINs on the quasi-
PIN keyboard as in Section V-D3. Next, we produce a list of
candidate words from candidate PINs and then use a dictionary
to Ô¨Ålter out non-existing words.
151
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:20 UTC from IEEE Xplore.  Restrictions apply. 
Keystroke inference on the quasi-PIN keyboard is even
harder than that on the PIN keyboard. SpeciÔ¨Åcally, the user
may type the same key multiple times or hit some hidden keys
on a segment, which is difÔ¨Åcult for the attacker to identify. In
addition, the attacker knows that the PIN to infer corresponds
to 4 or 6 keys on the PIN keyboard, while he has no idea
how many keys are contained in a PIN on the quasi-PIN
keyboard because the corresponding word to infer may include
an arbitrary number of letters. The situation becomes even
worse because the same key or a hidden key may be typed
multiple times. For example, the combinations of ‚Äúty‚Äù, ‚Äúer‚Äù,
‚Äúgh‚Äù, and ‚Äúui‚Äù are quite common in English words.
We amend the process in Section V-D3 to increase the
accuracy of inferring English words on the quasi-PIN keyboard
and thus the alphabetical keyboard.
‚Ä¢ We add a (0, 0) segment into the set of legitimate
segments. If a (0, 0) segment is selected, the gaze trace
stays on the same key, corresponding to the case that
the victim inputs the same key repeatedly.
Since it
the possible
lengths of the typed word, we only consider candidate
words of ns + 1 or ns + 2 letters long for a given gaze
trace of ns segments.
is unrealistic to consider all
‚Ä¢
As in [9], [22], [23], we reÔ¨Åne the candidate words with the
popular ‚Äúcorn-cob‚Äù dictionary [47] which is an on-line word
list of 58,110 common English words.
Given a candidate PIN on the quasi-PIN keyboard, we
generate a list of candidate words for the extracted gaze trace
in the following two steps. First, we enumerate all the possible
combinations of letters of the given PIN. Second, we search
in the dictionary and add discoverable combinations into the
list of candidate words. The complexity of such a process can
be very high. For example, in our experiments, the number
of possible PINs for a 13-letter word is in the order of 104,
the number of possible combinations is in the order of 106
(313 = 1594323), and the number of strings in the dictionary
is 58,110. All these add up to a complexity of 1015. To reduce
the search complexity, we build a preÔ¨Åx tree of the ‚Äúcorn-
cob‚Äù dictionary using trie structure [48] such that the search
complexity within the dictionary is O(L), where L is the
length of the given string.
VI. PERFORMANCE EVALUATION
A. Experiment Setup
1) User enrollment: We recruited 22 participants for the ex-
periments, including 5 females and 17 males. Our experiment
protocol was approved by the Institutional Review Board (IRB)
at our institution and strictly followed in the experiments. Since
the participants were only asked to input on smartphones, the
experiments did not affect either them or people nearby at all.
We only obtained the participants‚Äô oral consent because the
IRB approved a waiver of the requirement to obtain written
consent. All the participants were either graduate students in
our lab or others we know in the same university. We did not
reward them with any monetary compensation and only treated
them to free snacks. Finally, all the recorded videos are stored
in password-protected lab computers. As shown in Table IV,
the number of participants in our evaluation is larger than those
in our closely related work.
TABLE IV.
NUMBER OF PARTICIPANTS IN RELATED SYSTEM
EVALUATIONS.
[19]
[22]
N/A N/A
[23]
5
[9]
4
EyeTell
[40]
10
System
Number of
participants
2) Data collection: We used a Panasonic HCV700 cam-
corder for video recording in our experiment. This camcorder
has a 21√ó zoom len and can record 1080p60 HD videos.
Two smartphone models were used in the experiments: Apple
iPhone 6s with a 10.5cm √ó 5.8cm screen size and Google
Nexus 6 with a 12.3cm √ó 7.5cm screen size.
22
A typical data collection process is as follows. A participant
was asked to sit on a chair (illustrated in Fig. 4), hold
a smartphone in front of herself/himself, and input on the
touchscrren. The input can be a PIN on the PIN keyboard,
a pattern on the pattern-lock keyboard, or an English word
on the alphabetical keyboard. The participant was asked to
input in her/his normal typing/drawing speed. We observed
that the participant almost always kept her/his head relatively
steady during each inputting process which was very short
and less than 5 s in our experiments. Such relatively steady
head positions are explored by almost all existing gaze tracking
methods, including the one used in EyeTell. The following
default settings were used, unless noted otherwise. The dis-
tance between the participant and camcorder was around 2 m.
The participant, smartphone, and camcorder lay in the same
plane. The resolution and frame rate of the camcorder were
set as 1920 √ó 1080 and 60 fps, respectively. We also adjusted
the zoom of the camcorder such that the captured face of the
participant was focused and larger than 500 √ó 500 pixels.
In general, we conducted two sets of experiments: one
without task randomization and the other with task random-
ization. The former involved 12 participants, each of whom
performed experiments sequentially from one session to the
next. For example, a participant Ô¨Årst performed all experiments
on inferring a single lock-pattern segment,
then complete
lock patterns, and so on. In contrast, the latter involved 10
participants, each of who was given randomly permuted tasks.
As an example, a participant performed one trial on inferring
a single lock-pattern segment, then two trials on complete lock
pattens, then three trials on 4-digit PINs, and so on.
We use the experiment on inferring a single segment on the
pattern-lock keyboard to examplify how we reduced the impact
of fatigue. For this experiment, a participant was asked to draw
each segment in Table XII on the pattern-lock keyboard. For
a given segment, she/he was asked to draw it Ô¨Åve times. To
counteract the impact of possible fatigue, the participant was
asked to take pauses between two consecutive inputs. Before
the experiment, we informed all the participants that they could
stop the ongoing experiment freely whenever they felt a need
to rest. Finally, we purposely asked each participant to stop
and rest for one or two minutes about every ten minutes.
For the set of experiments without task randomization,
we designed multiple sessions to fully evaluate EyeTell. In
the following sessions (from Section VI-C to Section VI-G),
we will describe the details of these experiments (e.g., the
number of participants, the experiment requirements, etc.) and
152
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:20 UTC from IEEE Xplore.  Restrictions apply. 
the corresponding results. The same participant took part in
multiple sessions, resulting in a total time between two and
three hours. To further reduce the impact of possible fatigue,
we collected the data of the same participant on different
days. As a result, the total time of doing experiments for each
participant was less than one hour on the same day.
For the set of experiments with task randomization, we
also designed different experiments for the same participant.
Particularly, task randomization was done in two steps. First,
we prepared all the experiments (tasks) for the same partici-
pant, assembled them together, and assigned each of them an
order number. In our evaluation, a participant was assigned 24
single segments, 10 lock patterns, 10 4-digit PINs, and 10 6-
digit PINs. Therefore, the order numbers are from 1 to 54 (i.e.,
24 + 10 + 10 + 10 = 54), which we use a vector [1, 2, . . . , 54]
to denote. Second, we permuted the order vector randomly and
obtained a new randomized one for each individual participant.
Finally, each participant performed experiments according to
her/his given vector.
As can be imagined, our experiments required a participant
to look at the touchscreen of a mobile device and input on
it repeatedly, which can result in fatigue. There are mainly
two factors leading to fatigue in our experiments: experimental
time and task similarity. Intuitively, if the experimental time is
longer with very similar tasks, participants may easily suffer
from fatigue. As mentioned above, we adopted two methods
to reduce the impact of passible fatigue as much as possible.
On the one hand, we asked the participants to take sufÔ¨Åcient
pauses during the experiments and stop the experiments freely,
and controlled the duration of data collection on the same day.
On the other hand, we conducted two sets of experiments, with
and without task randomization. Since we did not observe large
difference between the results of the two sets of experiments,
we present the details and results of task randomization in
Appendix C-B.
B. Performance Metrics
We use top-k inference accuracy as the main performance
metric, as in [9], [19], [22], [23], [40]. SpeciÔ¨Åcally, EyeTell
generates a set of ranked candidate inputs (PINs, lock patterns,
or letters) for each trial. We claim that a trial succeeds if
the true input appears in the top-k candidate inputs. Top-k
inference accuracy is deÔ¨Åned as the percentage of successful
trials. We compare the inference accuracy of EyeTell with that
in [9], [19], [22], [23], [40]. SpeciÔ¨Åcally, we compare EyeTell
with [40] on inferring lock patterns and with [9], [19], [22],
[23] on inferring English words.
C. Experiments on Pattern-Lock Keyboard
We Ô¨Årst evaluate how accurately EyeTell can infer a
single segment on the pattern-lock keyboard. Considering that
inferring a single segment is the simplest task for EyeTell and
the basis for more complicated ones, we want to see how well
it performs. For this experiment, we asked each participant
to draw each segment in Table XII on a Nexus 6 for Ô¨Åve
times. Recall that Table XII consists of all the possible single
segments on a pattern-lock keyboard. For the segments with
multiple possible starting points (e.g., segment 1 can start
from any point in {c1, c2, c4, c5, c7, c8}), the participants had
the freedom to pick any starting point. Since there is only one
segment in the resulting gaze trace, EyeTell can only calculate
its angle but not its length. The output length is always 1
due to normalization. Therefore, we group the segments with
the same angle together and obtain Table V from Table XII.
Therefore, both segment 1 and 2 in Table XII correspond
to segment 1 in Table V. Here we ignore the impact of the
segment length, which is reported in later evaluations. As we