the rewards (which have monetary value sometimes) and fame that
come with it. Moreover, health insurance companies increasingly
leverage individuals’ health and fitness information to decide the
risk score and thus the premium to charge potential and existing
clients. IIV vulnerabilities can be exploited to artificially inflate
physical activities to manipulate those predictions and thus incur
costly damages to insurance companies.
Other Fitness Services. We conducted experiments to study the
resilience of other popular fitness services, specifically Fitbit [6] and
Run with Map My Run [3]. For Fitbit, we found that activity distance
can be added from 1km to 1609.344km . For activity duration, we
observe that there is no input data type positive range restriction
as we could inject duration from 1 second to 2, 147, 483, 647 (which
is the maximum positive value for a 32-bit signed binary integer, or
231 − 1). For Run with Map My Run alarmingly we found that any
input validation happens on the client-side while the values are
stored non validated (we injected arbitrarily large duration values)
on the server. Due to space limitations, we defer further details to
Appendix A.
5 PRICING SERVICES
Pricing crowdsourcing services, allow their participants to report
the exact price value of an asset. Tampering with these prices can
lead to an unfair competition where customers are driven away
from target stores or directed toward particular stores. In this sec-
tion we elaborate on a practical attack we launched against a pop-
ular pricing crowdsourcing service (Basket Savings). The attack is
launched through spoofed network requests.
Manual Analysis Description and Objectives. Basket Savings [13]
is an example of a money-saving service which crowdsources prices
of grocery items on superstores. Its Android mobile app was down-
loaded more than 100,000 times. The app allows users to add a price
(float value) for an item only if they are within a GPS-determined
geo-location close to the target store and by scanning the bar-code
of the target product or their purchase receipt. Moreover, the Basket
Savings service blocks devices by IP in case they detect suspicious
activity like a user making malicious price changes on the app.
Nonetheless, we found that one can bypass this by leveraging a
feature on the app which allows users to manually input and submit
prices through the app’s user interface. We suspect that this feature
was added to increase crowdsourcing opportunities, for example
by supporting price reports when the user has left the store. We
verified that an adversary can use an emulator device to inject both
lower and higher than the real price values for selected target prod-
ucts. For example, we verified that we could increase the price of
one gallon of milk by 129% of its usual price (from $3.49 to $8). As
with the case of Transit, we monitor feedback to verify the results
by accessing the values from secondary passive devices registered
as users of the service. This, can be leveraged by an adversary to
Table 1: Basket: Trader Joe’s & Amazon Prime(*)
Product
Apples
Bananas
Strawberries
Eggs
Chicken Breasts
Organic whole Milk
Value Min Max
0.49
0.19
0.99
1.99
2.69
3.49
0.05
0.09
0.09
0.2
0.27
0.35
2.0
2.0
2.0
4.0
6.0
8.0
*Value
1.58
0.55
5.0
2.12
3.25
3.76
*Min
0.16
0.06
2.21
0.21
0.33
0.38
*Max
4.0
2.0
8.3
6.0
8.0
8.0
Table 2: Basket: Milk on Trader Joe’s
Product
Whole Milk 1
Whole Milk 2
Organic Whole Milk 1
Organic Whole Milk 2
Homogenized Whole Milk
Gallons
0.5
0.5
0.5
1
1
Value Min Max
1.29
2.29
2.99
5.69
5.99
4.0
6.0
6.0
10.58
6.59
0.13
0.23
0.30
1.71
1.80
launch an unfair competition attack where customers are driven
away from target stores or directed toward particular stores by
manipulating the advertised prices for popular products.
Experiment Design. The case above demonstrates that Basket
Savings is vulnerable to improper input injections. Next, we design
a set of experiments to characterize the IIV attack surface of the
service. Prices in Basket are reported as float values. To find the
input domain range accepted by the service—and thus the range of
the adversary—we perform price injection attacks on the user inter-
face of its mobile app, aiming to identify the boundaries (minimum
and maximum values) the adversary can inject. Trying all possible
values for an input type can be very time-consuming. In this case, a
float data type has a range −3.4E +38 ≤ 3.4E +38. Therefore to find
the accepted input range in a more efficient manner, we follow the
numeric value exploration strategy outlined in Subsection 3.2. We
choose the initial value to be the current value of a target product.
We also choose the step size to be equivalent to 1 cent (s = 0.01).
To perform the injections, we leveraged our MITM-proxy testbed
again to obtain the API call responsible for injecting a new price
value for any given store. We observed that the API call uses the new
price, product and store-id along with a longitude, latitude pair and
a timestamp to submit a new price value for the given product at the
given store to Basket’s system. We wrote a script that could replay
this API call to Basket’s server and used it manually for injecting
different prices for any product according to the aforementioned
numeric exploration approach.
To detect the success or failure of an injection trial, we used an-
other API call discovered through our MITM-proxy testbed. Using
a secondary passive device we manually verify the injected value
was visible for other participants and has replaced the prior price
for the given item on a particular store. We used this injection and
observation approach to verify the minimum and maximum value
possible for “bananas” and “strawberries” at the two stores. Later,
we discovered another API call that had these maximum and mini-
mum allowed price values i.e. the acceptable price range embedded
in its response. We used this request to verify and obtain the price
ranges quoted in the results for this app.
949Characterizing Improper Input Validation Vulnerabilities of Mobile Crowdsourcing Services
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
To examine the effect of location, we repeat this experiment for
two stores (Amazon Pantry and a Trader Joe’s store in Los Ange-
les, CA). To examine the effect of product type, for each store we
try manipulating prices for 6 different products: apples, bananas
strawberries, eggs, chicken breast, and organic while milk. Lastly,
to examine the variation within product types we select 5 different
kinds of organic milk.
Results. Table 1 summarizes the range of successfully injected
prices for Trader Joe’s and Amazon Prime. We observe that the
minimum value allowed for both stores is mostly the 10% of the cur-
rent value and the maximum value allowed for any product mostly
seems to be 2 ∗ ⌈currentV alue⌉). These boundaries are clearly not
realistic. Note that only bananas on Trader Joe’s and strawberries
on Amazon show exception to these rules in the results. Table 2
shows the successfully injected prices for 5 different kinds of or-
ganic milk on Trader Joe’s (these are different from the one listed
on Table 1). We observe that the minimum allowed price was 10%
of the shown price for milk under $5 and roughly 30% of the shown
value for milk over $5. The same rules as above were followed for
3 out of 5 kinds of milk for the maximum price.
Other pricing services. For our analysis we also selected Gas-
Buddy (Section 3). GasBuddy crowdsources real-time gas stations’
fuel prices through their app. Like GoogleMaps, it uses client certifi-
cate pinning so we couldn’t decrypt and reverse engineer the API
calls used by the app. Another challenge was the variable nature of
GasBuddy’s user interface where random pop-up screens (e.g. ads)
would cause the app to crash or frequently end up at unintended
screens, which currently our DEM module cannot handle.
6 TRANSPORTATION SERVICES
Transit [10] is a public transportation service for 175 cities. Its An-
droid app enjoys over 5,000,000 installations. By crowdsourcing
every passenger’s real-time sensory data including positioning in-
formation and speed of movement, Transit can help its users plan
a trip and support them in their travel by predicting the expected
arrival time of the next subway or bus. However, we found that it
is possible to fool the Transit service to accept fake measurements.
To demonstrate this, we performed an experiment using 3 Android
device emulators. The first device (Eα ) acted as the adversarial
device aiming to fool the service, while we used the other two as
observer devices (Eo1 and Eo2) for verifying the result of the attack
on the service on other users’ devices. We installed Transit on all
three emulators and used the app to plan a bus trip from point A to
point B in London, UK. Eo1 and Eo2 started their trip 3 bus stops
later than Eα . Eα was driven by our sensor spoofer, which was
automatically feeding fake GPS updates to the device, simulating a
movement along the target bus route with a steady speed (12km/h).
In this manner, Transit was instantly fooled to accept that Eα is
actively riding the target bus, which we could verify as the Transit
app rendered a new bus icon moving at Eα speed and direction,
on the screen of all three devices. We were also successful in ma-
nipulating the expected bus arrival time for Eo1 and Eo2, by faking
the speed of movement of Eα to be 575mph which is equivalent
to the average speed of a commercial plane. All experiments were
performed at an off-peak time in a rural area to avoid affecting real
users. Competing transit agencies can use these attacks to deter
customers from using another transit service.
Experiment Design and Results. Next we design a set of exper-
iments to better understand the range and predictability of values
an adversary can leverage for manipulating bus routes. We leverage
our DEM method (see Subsection 3.3) to dynamically install and
execute the Transit app on Genymotion non-root emulators and
move to a target screen for enabling active route navigation in the
app. Then we use our sensor spoofing method to fake sensor GPS
values to the victim app. All our experiments are performed target-
ing the same bus route in a rural area. We configure the attacker’s
device starting location to be 18km earlier on the bus route than
the victim device’s location (also on the bus route). The scheduler is
configured to emulate the speed of movement of the adversarial de-
vice by generating GPS timeseries values corresponding to different
frequencies. An injection attempt at a specific speed of movement
is considered successful when it can affect the expectation of the
bus arrival time on the observer device.
• Linear value exploration. We first use linear numeric exploration
(see Subsection 3.2) to generate speed values from 0 to 1000 km/h
with a step size of 10 km/h (s = 10). We found that 97/100 (97%) fake
movements succeeded in fooling Transit that the adversarial device
is actively riding a fake bus. We determine success by tracking visual
hints on the UI of the app on the adversary’s device: Transit shows
a textual description to its user when waiting for a bus (“Waiting
for the bus”). When the user is riding a bus this textual hint changes
to “Get off in [number of] stops” as shown in Figure 2(a). Using our
DEM module (see Section 2) we can track the target UI element with
the textual hint to verify the success or failure of the experiment.
However, we observe that even when the adversary succeeds to
create a fake bus, this is not always reflected on other users’ devices,
especially when moving at high speeds. We verify this by randomly
selecting 20 values of speeds and repeat the experiments for each
of them, this time also monitoring the observer device. We can
confirm that the fake bus also appears on the observer devices by
looking for the bus icon with a happy rider face (see Figure 2(b)).
The exact icon can be extracted beforehand as it is stored in the
victim app’s res/drawable folders which we access by decompiling
the app using an Android reverse engineering tool (apktool [12]).
This then used during the experiments with the MatchTemplate()
function of the openCV2 library [2] to search for that icon within
a grayscale version of screenshots of the UI of the victim’s device.
Using this approach, we verify that 17/20 (85%) successful bus fakes
also appear on the victim device.
(a) Text element hint on adversarial device’s UI.
(b) Icon hint on victim device’s UI.
Figure 2: Transit mobile app UI hints.
950ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Khan, et al.
times. Its users can report the location of police speed detectors,
road repairs and road accidents. As with ToiFi (Toilet Finder) we
were successful in faking all PoIs: fake police speed radars, fake
road accidents and fake road repairs. As before, to better under-
stand the susceptibility of the service to these attacks, we perform