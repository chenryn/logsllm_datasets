tion phase and with a partial control on the distribution of the input distribution is give [BH05].
Also note that the construction proposed in [BH05] composes the randomness extractor with a
stateful pseudo-random number generator; this construction beneﬁts from the forward security
of the stateful pseudo-random number generator, and the resilience of the pseudo-random num-
ber generator with input.
In [KSWH98], a pseudo-random number generator with input should enforce complete renewal
of the internal state. This feature is also considered in [BH05], where there is a procedure named
good-refresh by which the internal state of the generator is refreshed with a ’high entropy’ source.
Once refreshed with such a source, the generator is considered ’uncompromised’ and output can
be generated. Moreover, the model of [BH05] also requires that once refreshed with such a
source, the internal state is pseudo-random, ensuring that is it completely refreshed with new
entropy.
Source compromise. The security guidelines of [KSWH98, Gut98] model the potential com-
— 48 —
3.8. Analysis
promise of the source of randomness: adversary A has access to two procedures getinput and
setinput. The model in [DHY02] also considers a source compromise, but in a diﬀerent way.
In [DHY02], the security model assumes the existence of an entropy pool in which entropy is
accumulated and that is used as input for state generation. However, the model does not capture
the potentially adversarial inputs that may be used for this generation. The only adversarial
procedures, also named getinput and setinput in [DHY02], are related to the compromise of an
auxiliary input that is also used to generate the internal state. Hence, in [DHY02], the complete
compromise of the randomness source is not taken into account.
Source compromise is not taken into account in [BY03]. In this model, the potentially adver-
sarial inputs that could be used to compromise the generator are not described. It is assumed
in [BY03] that the state is ﬁrst properly generated will algorithm key. A recovery mechanism
would be to enforce regular applications of algorithm key, however, it implies that a trusted
source of randomness is available, from which extraction can be proceeded. This operation
is not captured in [BY03], as it is by the guidelines of [KSWH98, Gut98] and more formally
in [BST03, BH05]. This is obvious from the context of [BY03], as the model does not consider
pseudo-random number generator with inputs, however it is implicit that the ﬁrst generation of
the state with algorithm key can not be compromised.
Source compromise is considered in [BST03], where the adversary A can choose a ﬁnite family
of distributions F. While in the security models of [KSWH98, Gut98], adversary A has access
to a setinput procedure that allows her to directly set the value of the input that is collected
by the random number generator, here the adversary has implicitly access to a so-called ’set-
distribution’ or ’setfamily’ procedure, that allows A to set the high entropy distribution family
F. This procedure is not explicitly deﬁned in the model of [BST03], however, as the family of
distributions F = {D1,··· ,D2t}, such that H∞(Di) ≥ k is given as input for all procedures, we
can consider that such procedure exists. In fact, in the model of [BH05], a procedure named
good-refresh is deﬁned, that allows adversary A to set a ’high entropy’ distribution, which plays
the same role as the underlying ’setdistribution’ procedure of [BST03]. However, the model
of [BST03] only considers the case of ’high-entropy’ distribution, while the model of [BH05] also
consider adversarially controlled inputs, with a procedure named bad-refresh, that is similar to
the procedure setinput. Finally in [BST03,BH05] the need for a randomness extractor is clearly
stated, while in [KSWH98,Gut98], this need is not identiﬁed.
Pseudo-Random Number Generators with Input Deﬁnition. The deﬁnition of a pseudo-
random number generator with input in [DHY02] does not contain any refresh algorithm that
could model input collection to continuously update the state S and the key S. The update
is implicitly contained in the next algorithm. A clear separation between refresh algorithm and
next algorithm is the basis of the robustness security game of [BH05].
Entropy Accumulation. The model of [BH05] (as for the model of [DHY02] with the setinput
procedure) only considers that the adversary can either call the good-refresh procedure, which
must produce an input I of high entropy, or call the bad-refresh procedure with an arbitrary,
maliciously speciﬁed input I∗.
Informally, the call to bad-refresh should not compromise the
generator whenever the compromised ﬂag corrupt = false, while the call to good-refresh should
result in an immediate “recovery”, and always resets corrupt = true. In real implementations,
however, entropy can be accumulated slowly (and maliciously!), as opposed to in “one shot”
(or “delayed” by calls to bad-refresh). This implies that once the generator is compromised,
the recovering process should ensure that enough entropy is accumulated before outputs are
generated. Note that this behavior is indeed implemented in practical generators, such as the
Linux generators dev/random and dev/urandom, which place a lot of (heuristic) eﬀort in trying
to achieve this property.
— 49 —
Chapter 3. Security Models for Pseudo-random Number Generators
Importance of setup. As we mentioned, the model of [BH05] did not have an explicit setup
algorithm to initialize public parameters seed. Instead, they assumed that the required random-
ness extractor Extract in their construction is good enough to extract nearly ideal randomness
from any high-entropy distribution I output by the good-refresh procedure. Ideally, we would
like to make no other assumptions about I except its min-entropy. Unfortunately, no determinis-
tic extractor is capable to simultaneously extract good randomness from all eﬃciently samplable
high-entropy distributions (See Lemma 2). As noticed, the choice by [BH05] is to restrict the
family of permitted high-entropy distributions I. Hence a key strengthening of the model will
be the use of strong randomness extractors, as in Deﬁnition 7, that allow a public and reusable
parameter seed and extract from arbitrary randomness sources. One condition to use this class
of extractors is that the parameter seed is independent from the source.
Leakage Resilient Pseudo-Random Number Generators with Input. The security
model of leakage resilience concerns stateful pseudo-random number generators. However, as
pointed in [BH05], a large class of generators are implemented as pseudo-random number gen-
erators with inputs, that are continuously refreshed with new inputs collected from their envi-
ronment. The potential leakage of the internal state for such generators therefore needs to be
formalized.
— 50 —
Chapter 4
Robustness of Pseudo-random
Number Generators with Inputs
4.1 Model Description
In this section we give a syntactic formalization and security deﬁnitions for pseudo-random
number generator with input. All deﬁnitions and theorems from this chapter are from [DPR+13].
Recall that we termed ’pseudo-random number generator with input’ to refer that the generator
is refreshed periodically with new inputs, as described informally in Section 2.8.3. As explain in
Chapter 3, the security models of [DHY02,BST03,BH05] also concern pseudo-random number
generator with input.
Our deﬁnition of a pseudo-random number generator with input requires that, in addition to the
usual refresh and next algorithm, an algorithm named setup is set, whose objective is to generate
a parameter seed (which will be the seed of a randomness extractor). As noted in Section 3.8,
this algorithm is necessary to describe completely the generator operations, as it shall naturally
involve a randomness extractor. Furthermore, we want the parameter seed to be public because
the security of our schemes shall not rely on the secrecy of any parameter (if this secrecy is
guaranteed, one can use a standard pseudo-random number generator).
seed
I
S
setup
refresh
S0
S
next
S0
R
Figure 4.1 – Pseudo-Random Number Generator with Input [DPR+13]
Deﬁnition 27 (Pseudo-Random Number Generator with Input [DPR+13]). A Pseudo-Random
Number Generator with Input is a triple of algorithms G = (setup, refresh, next) and a quadruple
(s, n, ‘, p) ∈ N4 where:
• setup: it is a probabilistic algorithm that outputs some public parameters seed ∈ {0, 1}s for
the generator.
— 51 —
Chapter 4. Robustness of Pseudo-random Number Generators with Inputs
• refresh: it is a deterministic algorithm that, given seed ∈ {0, 1}s, a state S ∈ {0, 1}n and
an input I ∈ {0, 1}p, outputs a new state S0 ← refresh(S, I) = refresh(seed, S, I) ∈ {0, 1}n.
• next: it is a deterministic algorithm that, given seed ∈ {0, 1}s and a state S ∈ {0, 1}n,
outputs a pair (S0, R) ← next(S) = next(seed, S) where S0 ∈ {0, 1}n is the new state and
R ∈ {0, 1}‘ is the output.
The integer s is the seed length, n is the state length, ‘ is the output length and p is the input
length of G.
Note that to simplify the algorithm description, we will omit the parameter seed when its
deﬁnition is clear from the context. Recall that the previous models were based on the use of a
resilient randomness extractor (Deﬁnition 5). As explained in Section 2.6, this class of extractor
restricts the use of a bounded size ﬁnite family of randomness sources. Furthermore, we want
that the random parameter seed is made public once generated. As noted in Section 2.6, we
mainly have two possibilities:
1. We assume that independence between the seed and the randomness source can not be
ensured. One solution is to restrict the randomness sources to use a resilient extractor:
this is the solution proposed in [BST03,BH05]. One second solution would be to restrict
the adversary capabilities and use seed dependent extractors, as in Deﬁnition 6.
2. We choose not to restrict the randomness neither the adversary capabilities. As noted in
Section 2.6, as we also want that seed is public, one solution is to use strong extractors, as
in Deﬁnition 7, as soon as independence between the seed and the randomness source can
be ensured. Our model relies on this assumption.
In our adversarial model for pseudo-random number generator with input, we consider that
the adversary A can partially control the inputs that are used to refresh the internal state of
In addition, we also need that independence between the seed and the input
the generator.
distribution is guaranteed. We therefore propose to split the adversary into two entities: the
adversary A whose task is (intuitively) to distinguish the outputs of the generator from ran-
dom, and the distribution sampler D whose task is to produce inputs I1, I2, . . . , which have
high entropy collectively, but somehow help A in breaking the security of the generator. The
distribution sampler aims at modeling potentially adversarial environment (or ’nature’) where
the generator operates. To ensure independence of the randomness sources with seed, we will
require that the distribution sampler is set independently of seed. Once D is set, the adversary
A has access to seed. This separation between A and D allows to clarify the requirement of
independence between the adversary and seed: as independence is only required between seed
and the randomness source to build a strong randomness extractor, we enforce independence
between seed and the ’part’ of the adversary that has control on the randomness source and we
let the ’other part’ having access to seed. The above discussion justiﬁes Deﬁnition 28.
Deﬁnition 28 (Distribution Sampler). Let G = (setup, refresh, next) and (s, n, ‘, p) ∈ N4 be a
pseudo-random number generator with input. A distribution sampler D for G is a stateful and
probabilistic algorithm which, given the current state σ, outputs a tuple (σ0, I, γ, z) where:
• σ0 is the new state for D.
• I ∈ {0, 1}p is the next input for the refresh algorithm.
• γ is some fresh entropy estimation of I, as discussed below.
• z is the leakage about I given to the adversary A.
— 52 —
4.1. Model Description
We denote by qr the upper bound on number of executions of D in our security games, and say
that D is legitimate if
H∞(Ik | I1, . . . , Ik−1, Ik+1, . . . , Iqr , z1, . . . , zqr , γ1, . . . , γqr) ≥ γk
for all k ∈ {1, . . . , qr} where (σk, Ik, γk, zk) = D(σk−1) for k ∈ {1, . . . , qr} and σ0 = 0.
We now explain the reason for explicitly requiring D to output the entropy estimate γk. Most
complex generators, for example the Linux generators dev/random and dev/urandom, are worried
about the situation where the system might enter a prolonged state where no new entropy is
inserted in the system. Correspondingly, such generators typically include some ad hoc entropy
estimation procedure E whose goal is to block the generator from generating an output R until the
state has not accumulated enough entropy γ∗ (for some entropy threshold γ∗). Unfortunately, it
is well-known that even approximating the entropy of a given distribution is a computationally
hard problem [SV03]. This means that if we require a pseudo-random number generator with
input G to explicitly come up with such a procedure E, we are bound to either place some
signiﬁcant restrictions (or assumptions) on D, or rely on some hoc and non standard assumptions.
Indeed, as part of this work we will demonstrate some attacks on the entropy estimation of the
Linux generators, illustrating how hard it is to design a sound entropy estimation procedure E.
Also, observe that the design of E is anyway completely independent of the mathematics of
the actual refresh and next procedures, meaning that the latter can and should be evaluated
independently of the ’accuracy’ of E.
In the security deﬁnition, we do not insist on any ’entropy estimation’ procedure as a mandatory
part of the design of a pseudo-random number generator with input, instead, we chose to place
the burden of entropy estimations on D itself, which allows us to concentrate on the provable
security of the refresh and next procedures. In particular, in our security deﬁnition we will not
attempt to verify if D’s claims are accurate, but will only require security when D is legitimate,
as in Deﬁnition 28. Equivalently, we can think that the entropy estimations γk come from
the entropy estimation procedure E (which is now ’merged’ with D), but only provide security
assuming that E is correct in this estimation (which we know is hard in practice). Finally, in
the security deﬁnition,
• The entropy estimates γk will only be used in security deﬁnitions, but not in any of the
actual generator operations (which will only use the "input part" I returned by D)
• We do not insist that a legitimate D can perfectly estimate the fresh entropy of its next
sample Ik, but only provide a lower bound γk that D is "comfortable" with. For example,
D is free to set γk = 0 as many times as it wants and, in this case, can even choose to
leak the entire Ik to A via the leakage zk. Note that setting γk = 0 corresponds to the
bad-refresh(Ik) oracle in the earlier modelling of [BH05], described in Section 3.6, which is
not explicitly provided in our new model.
• We allow D to inject new entropy γk as slowly (and maliciously!) as it wants, but will
only require security when the counter c keeping track of the current "fresh" entropy in
the system (intuitively, "fresh" refers to the new entropy in the system since the last state
compromise) crosses some entropy threshold γ∗ (since otherwise D gave "no reason" to
expect any security).
As seen in Chapter 3, four security notions for a pseudo-random number generator with input
have been proposed: resilience (RES), forward security (FWD), backward security (BWD) and
— 53 —
Chapter 4. Robustness of Pseudo-random Number Generators with Inputs
proc. D-refresh
(σ, I, γ, z) $← D(σ)
S ← refresh(S, I)
IF c < γ∗
proc. get-state
c ← 0;
OUTPUT S
proc. set-state(S∗)
c ← 0;
S ← S∗
proc. next-ror
(S, R0) ← next(S)
$← {0, 1}‘
R1
IF c < γ∗
c ← 0
OUTPUT R0
ELSE
OUTPUT Rb
proc. initialize(D)
seed $← setup;
σ ← 0;
S ← 0n;
c ← 0;
$← {0, 1};
b
OUTPUT seed
proc. ﬁnalize(b∗)
IF b = b∗ RETURN 1
ELSE RETURN 0
c ← min(c + γ, n)
OUTPUT (γ, z)
Figure 4.2 – Procedures in Security Games RES(γ∗), FWD(γ∗), BWD(γ∗), ROB(γ∗)
robustness (ROB), with the latter being the strongest notion among them. We now deﬁne the
analogues of these notions in our stronger adversarial model, later comparing our model with
the prior model of [BH05]. Each of the games below is parametrized by some parameter γ∗
which is part of the claimed generator security, and intuitively measures the minimal “fresh”
entropy in the system when security should be expected. In particular, minimizing the value of
γ∗ corresponds to a stronger security guarantee. When γ∗ is clear from the context, we omit it
for the game description (e.g., write ROB instead of ROB(γ∗)).
All four security games (RES(γ∗), FWD(γ∗), BWD(γ∗), ROB(γ∗)) are described using the game
playing framework presented in Section 2.4, and share the same initialize and ﬁnalize procedures
in Figure 4.2. As we mentioned, our overall adversary is modelled via a pair of adversaries
(A,D), where A is the actual adversary and D is a stateful distribution sampler. We already
discussed the distribution sampler D, so we turn to the adversary A, whose goal is to guess the
correct value b picked in the initialize procedure, which also returns to A the public value seed,
and initializes several important variables: corruption ﬂag corrupt, “fresh entropy counter” c,
state S and sampler’s D initial state σ. In each of the games (RES, FWD, BWD, ROB), A has
access to several oracles depicted in Figure 4.2. We brieﬂy discuss these oracles:
• D-refresh. This is the key procedure where the distribution sampler D is run, and where
its output I is used to refresh the current state S. Additionally, one adds the amount