= 日志易产品技术白皮书
北京优特捷信息技术有限公司
v4.5, 2023-01-09
== 引言
=== 日志分析技术背景
日志是计算机系统、设备、软件等在某种刺激下反应生成，用来标明发生某些事情的消息。典型的日志消息的基本内容至少包括：时间戳、源、数据三部分。日志分析则是处理和分析日志，从中得到它的含义。健全的日志记录和灵活的日志分析系统，是 IT 系统正常运营、优化和事故响应的基础。
在 21 世纪的今天，随着互联网和大数据时代的到来，中国的企业正面临着前所未有的挑战。机房中的各种系统一直在源源不断的产生日志，但在系统出现问题或者隐患时，能不能从日志中分析出端倪？在系统遭受严重的攻击和破坏时，日志分析系统能不能帮助我们走出泥沼？这是对整个 IT 部门实际工作能力的考验。
此外，日志本身的频繁变动也给分析带来了很大的不确定性难度。根据 2016 年《软件学报》一篇综述论文的统计：
. 在软件开发中进行日志记录是普遍的,平均 30 行代码中就有一行是日志
. 日志信息对实际部署系统的运行故障调试帮助较大,缩短故障调试时间的加速比为 2.2
. 日志代码的更新频率比其他代码要快约 1 倍
. 约四分之一的日志修改是把新的程序变量写入日志
. 约一半的日志修改是对日志消息静态文本的修改
完整的日志分析系统建设，涉及日志的结构规划、采集存储、过滤关联、统计分析、数据挖掘、图表报告以及管理章程等各个方面。几乎每个方面，都有着足够的技术深度和难点等待人们一一克服。
常见的来说，一些公司的日志分散在各台服务器上，每次查找日志都要登录到各台服务器，效率低下。这些公司首先需要统一管理日志，在一个界面上查看所有日志，大大提高运维效率。
一些公司的日志由各业务部门分别处理，导致了日志数据及分析结果的碎片化。日志是一家公司运营情况的真实数据，不同业务部门的日志往往互相关联。在公司层面统一处理、分析日志，可以把不同来源的日志对照关联分析，去除噪音，反应真实情况。
此外，黑客在入侵服务器或网络设备时，往往会删掉日志，抹除作案证据。统一上传、管理日志，可及时发现入侵行为，监控告警，也可以长期保存日志，方便事后安全审计。
=== 通用实现的局限性
日志分析技术在多年的发展中，已经经过了几代的发展，涌现了各种不同的技术手段和工具。这些工具在解决一些问题的同时，也都还带有一定的局限性。
====  grep/sed/awk等命令行工具
一些公司的运维工程师在运维故障发生后，登录各台服务器，使用grep/sed/awk等Linux脚本工具去日志里查找故障原因，排障时间长，未必能及时找到故障根源。
采用awk配合sort、uniq等可以进行初步的统计分析，但是终端表格类型的输出非常不直观，不具备图表可视化的视觉，无法第一时间发现异常点。
==== Hadoop/Spark/Storm等分布式系统
Hadoop、Storm和Spark都是一种开发框架，用户需要开发单独的Hadoop、Storm或Spark程序处理日志，使用门槛较高，优秀的分布式开发工程师不容易招到。
此外，Hadoop是批处理，实时性较差：不少使用Hadoop处理日志的公司通常是每天晚上处理当天的日志，第二天出统计报表。有些公司做得好些但也只能看到几小时前的日志分析。一些用户的日志结构化设计较为规范，可以使用Hadoop框架下的Hive或Pig查询日志，但延时依然可能达到几十分钟。
Storm 是流处理框架，可以很好的做到实时处理，但缺乏对历史数据，哪怕是并不太久远的历史数据的回顾能力，导致 Storm 只适合在类似 PV 统计等累计指标需求上，进行快速统计和展现。一般而言，只有大屏上的交易金额等个别关键数值有必要进行毫秒级的实时精准计算。
==== Druid/ClickHouse/Kylin等列式存储
采用列式存储系统进行日志的存储和分析，本质上依然是早期使用 MySQL 做日志存储思想的延伸。这种方式要求对日志格式有清晰的了解，对分析目的有足够的掌握，才能通过预聚合的方式，提前将日志结构化和处理成多维统计数据表，以便后续的高速查询。而配置预聚合，本身也需要调研、设计和调试时间，并不能做到全自动高效实现。
对于有明确的全文搜索需求的运维、安全场景，列式存储是力不从心的。一如早年 MySQL 方案需要额外搭配 Sphinx 索引。
这种方式一般只适合用在网站访问日志的业务分析场景上。
==== Elastic Stack/Graylog等项目
Elastic Stack是目前开源领域最流行的日志分析选择。虽然 Elasticsearch 本身并不是专门针对日志分析需求开发的，Elastic Stack确实也提供了日志的采集、传输、处理、存储、查询、统计、展现等一整个环节的能力。但过于分散的产品线导致其部署和管理具有一定的门槛，而且其开源部分缺乏常见的设计、权限、告警、管理等高级功能。事实上，从 6.0 版本开始，Elastic Stack 的绝大多数非 Lucene 层面新功能，都是在 Elastic License 商业许可证下发布。
此外，Elastic Stack 的内部 API 频繁变动，想要对其进行深度的二次开发极为艰难。
Graylog 是在 Elasticsearch 系统上整合和构造开源日志分析系统的典范。在一个统一界面上可以轻松完成对不同组件和流程的管理使用。由于架构单一，在日志量不大，延时要求不高，分析需求不复杂的情况下，使用 Graylog 搭建入门级日志分析系统不失为明智之选。但限于 Elasticsearch 的能力，Graylog 也只能提供对已经提取入库的字段的查询和简单统计功能，无法提供基于结果的二次统计和高端数据挖掘能力。
==== Grafana/Fluentd/Loki等云原生项目
在云原生项目中，经常会使用 Grafana 展示容器和微服务环境的监控指标和统计数据。其中部分数据的来源就是日志。Grafana 也在 2019 年顺势推出了 Loki 开源项目，配合 Fluentd 采集，专门进行容器环境日志的存储和查询。但 Loki 的设计前提是：容器平台上，微服务拆分已经非常细粒度，每个日志仅凭 kubernetes labels 或 docker tags 的查询已经可以充分定位，用户只需要上下页看日志原文就行了。这就意味着，loki 不提供日志原文的索引查询能力，不提供日志字段提取及统计分析能力。
由于没有全文索引，关键字过滤通过并发 grep 方式进行，而 Loki 项目还处于早期阶段，容错处理不佳，时间跨度稍微大一些，就会进入僵死状态。
== 日志易技术原理
日志易是由北京优特捷信息技术有限公司开发的智能日志中心。围绕公司特制的 beaver 日志搜索引擎平台，提供了配置简单、功能强大、容易使用的日志采集、处理、分析和管理功能，帮助企业进行线上业务实时监控、业务异常原因定位、业务日志数据统计分析、及安全与合规审计。
本章节主要讲述日志易产品模块架构，主要模块的技术原理及特色。
=== 架构图
日志易产品架构图如下：
image::images/arch.jpg[]
=== 数据流图
日志易采用分布式服务架构，由不同模块负责数据处理的不同阶段。各模块的数据流图如下：
image::images/module-arch.png[]
图中最中心部分，从左往右的直线，就是日志数据在日志易中的读写主流程。
=== 主要组件特色
==== 数据采集 Agent
日志易支持多种数据接入方式，包括直接由客户端发送数据到 collector 模块，比如标准的 syslog 协议(RFC5424)、HTTP(S) 和 protobuf。更主要的方式则是通过日志易提供的专属 Agent。
日志易提供两种 Agent 实现方式，一种为 Golang 语言编写的轻量级实现，功能全，性能好。另一种为不支持 Golang 语言的 UNIX 平台单独开发的 Java 语言编写，仅支持基础功能。一般情况下，建议用户采用 Golang 版本 Agent。
为了解决跨机房传输的网络安全问题，日志易还提供了专用的 Agent-Proxy 实现，同一机房内的数据可以通过 Agent-Proxy 进行中转代理，方便网络策略设置。
在数据采集层面，开源社区选择很多，功能和性能上各有差异。本节对此稍作对比。
日志易Agent与主流开源Agent的功能对比见下表：
.开源Agent功能对比
[options="header",cols=",,,,,,"]
|====
|
|Rsyslog
|Syslog-ng
|Logstash
|Fluentd
|日志易Agent
|nxlog
|语言
|C
|C
|Java/ruby
|C/ruby
|Go
|C
|源日志支持目录
|Inotify模式下支持通配符
|√
|√
|√
|√
|√
|源日志支持exclude
|╳
|╳
|√
|╳
|√
|╳
|支持其他脚本输出作为input
|╳
|╳
|√
|√
|√
|√
|SNMP TRAP支持
|╳
|PE版支持
|√
|╳
|√
|企业版支持
|多行处理
|√
|√
|√
|√
|√
|√
|缓存在内存，可配置
|√
|√
|√
|√
|√
|√
|缓存在文件，可配置
|√
|√
|√
|╳（替代方案是用RabbitMQ output）
|√
|√
|支持FlowControl，（输出有问题时，降低读文件速度）
|╳（可配置rate limiting，控制input速度，且可以配置Queue Slow Down在部分时段减速）
|√
|√
|可以配置rate limiting
|目前用go的channel能达到部分效果，如果output出问题，input的向后转的channel会满，导致input会阻塞
|√
|支持RPC输出
|╳
|╳
|√
|╳
|╳
|╳
|支持批量传输
|√
|√
|√
|√
|√
|√
|支持压缩
|√
|√
|√
|√
|√
|√
|支持加密
|√
|√
|√
|√
|√
|√
|文件输入时，允许重传，防止日志丢失
|╳
|╳
|√
|╳
|╳(文件输入，tcp输出时，会将输出的数据先写文件，然后从文件读出）
|企业版支持
|兼容windows
|付费版支持
|PE版支持
|√
|╳
|√
|√
|中央配置下发
|╳
|╳
|商业版支持
|╳
|√
|企业版支持
|Plugin的支持
|√
|√
|√
|√
|√（静态编译go plugin，动态加载lua plugin）
|√
|====
日志易Agent与主流开源Agent在相同发送速率下的CPU使用率对比见下图：
image::images/agent-util.png[]
日志易Agent与主流开源Agent在相同资源消耗下的最大发送速率对比见下图：
image::images/agent-speed.png[]