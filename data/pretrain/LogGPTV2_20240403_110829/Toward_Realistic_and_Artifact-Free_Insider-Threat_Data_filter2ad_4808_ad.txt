when using no sanitization (i.e., the raw data). We discuss
possible explanations for this discrepancy in Section 8.
Regarding the consequences of sanitization, if there were
no sanitization artifacts, all the results should match the
raw-data results. However, only Word-Token sanitization
produced results that match the raw-data results. Token-
Only sanitization increased the cost of using Truncated data,
while Redact-Only sanitization reduced the cost of using
Enriched data.
It may seem that Token-Only sanitization has no effect
9494
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:02 UTC from IEEE Xplore.  Restrictions apply. 
Data Type
Sanitization
Strategy
Raw / None
Redact-Only
Token-Only
Word-Token
Truncated
Enriched
Misses
25% (4/16)
25% (4/16)
37.5% (6/16)
25% (4/16)
False Alarms
10% (4/40)
10% (4/40)
7.5% (3/40)
10% (4/40)
Cost
0.350
0.350
0.450
0.350
Misses
50% (8/16)
37.5% (6/16)
50% (8/16)
50% (8/16)
False Alarms
12.5% (5/40)
10% (4/40)
12.5% (5/40)
12.5% (5/40)
Cost
0.625
0.475
0.625
0.625
Cost
Ratio
1.79
1.36
1.39
1.79
Table 1. The detector’s hit and false alarm statistics are shown for each of the eight evaluation data
sets. The cost of error is calculated as the sum of the miss and false alarm rates, and the ﬁnal column
indicates the ratio of the Enriched cost to the Truncated cost. Only the Word-Token sanitization
results exactly match the raw-data results for both Truncated and Enriched data.
on Enriched data, or that Redact-Only sanitization has no
effect on Truncated data. Further, it may seem that the
consequences of using either sanitization strategy instead
of raw data are small. For instance, Redact-Only saniti-
zation merely changes the detector’s response to three En-
riched sessions (i.e., two fewer misses and one fewer false
alarm). However, misses and false alarms are the coarsest
summary of the experimental outcome. Sanitization also af-
fects the anomaly scores and alarm thresholds used by naive
Bayes, and in these terms, the effects of Redact-Only and
Token-Only sanitization are much more pronounced, and
seen across Truncated and Enriched data sets.
The anomaly scores computed by naive Bayes for each
session describe the results of the experiment in ﬁner detail.
The score gives valuable insight into the decision procedure
used by the detector, and it can help explain why errors oc-
curred (e.g., why an attack-injected session was missed).
Without accurate anomaly scores, it is harder to identify
what a detector did wrong and how to improve it. The ef-
fects of Redact-Only and Token-Only sanitization are much
greater on the anomaly scores than on the hit and false-
alarm statistics. Table 2 shows that Redact-Only and Token-
Only affect many Truncated and Enriched anomaly scores
while Word-Token does not. Redact-Only has the greatest
effect on the anomaly scores, with all the Enriched anomaly
scores differing from the raw data scores. Redactions in the
training data caused all the probability estimates to change;
in turn, the probabilities altered the anomaly scores.
The alarm threshold is used by naive Bayes to decide
whether an anomaly score should trigger an alarm. It de-
pends on the anomaly scores calculated during cross vali-
dation, and when the anomaly scores change as a result of
sanitization, so does the threshold. Redact-Only sanitiza-
tion tended to lower the threshold (partially explaining the
lower miss rate on the Enriched data), while Token-Only
sanitization tended to raise it (partially explaining the higher
miss rate on the Truncated data). Again, Word-Token sani-
tization has no effect on the alarm threshold.
Sanitization
Strategy
Redact-Only
Token-Only
Word-Tokens
Data Type
Truncated Enriched Overall
29%
50%
0%
100%
50%
0%
64%
50%
0%
Table 2. The percentage of anomaly scores
altered as a consequence of each of the
three sanitization strategies is broken down
by data type. Only the Word-Token sanitiza-
tion strategy did not alter the score.
8. Discussion and future work
This research conﬁrms that Word-Token sanitization is
artifact-free for an experiment that evaluates the naive-
Bayes anomaly detector. In theory, Word-Token sanitiza-
tion should be artifact-free for any experiment where to-
kens can be substituted for words. For instance, it should
not introduce artifacts in the evaluation of other anomaly
detectors in the same family (e.g., Lane and Brodley’s and
Schonlau et al.’s detectors). Whereas Word-Token sanitiza-
tion replaces every occurrence of a word with a symbol, a
more lenient sanitization strategy might only replace occur-
rences that are in the same context (e.g., “God” will only
be replaced with  when it appears as a pass-
word). This strategy might provide more privacy while con-
tinuing to avoid introducing artifacts. Experiments with a
variety of detectors and different sanitization strategies are
needed to further develop this theory.
When tokens cannot be substituted for words (e.g., in
evaluations of signature-based systems), Word-Token san-
itization may introduce artifacts. However, just as Word-
Token sanitization was designed to be artifact-free for a cer-
tain family of detectors, a different artifact-free sanitization
technique might be designed to accommodate different de-
tectors. The lesson remains that sanitization can have unde-
9595
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:02 UTC from IEEE Xplore.  Restrictions apply. 
sirable consequences on the outcome of an experiment, and
it must be accommodated by researchers.
Since sanitization artifacts alter the results of experi-
ments, it stands to reason that the unrealistic use of be-
nign commands as a substitute for insider commands will
cause similar problems. In fact, our use of more realistic
insider-type behavior may explain the discrepancy between
our ﬁndings and Maxion’s about the cost of using Truncated
and Enriched commands. (Note that this explanation is con-
jecture, since the goal of this study was not to refute that ear-
lier work, and the discrepancy might be explained by other
means, such as our small subject-pool size.) However, we
want to reiterate that unrealistic use of benign commands
in insider-injections may have the same dangerous conse-
quences as sanitization artifacts. An investigation of the
consequences of unrealistic insider injections remains for
future work.
9. Summary and conclusion
Sanitization artifacts did not affect the experiment when
Word-Token sanitization was used, but they did alter the
results when two other strategies were used (Redact-Only
and Token-Only). Since existing insider-threat data sets
[2, 5, 11] all used some form of redaction or tokenization,
these ﬁndings cause concern. Conclusions based these data
sets may not generalize to the real world. Insider-threat data
sets must be validated before we place real-world reliance
on them. If an insider-threat detector is chosen for deploy-
ment on the basis of precarious conclusions, and that de-
tector under-performs, the consequences carry considerable
risk. On the other hand, we demonstrate that appropriate
tools and methods do make it possible to collect realistic
data and perform sanitization without introducing artifacts.
10. Acknowledgments
The authors are grateful for helpful comments from
Kymie Tan and Dan Siewiorek, as well as from anony-
mous reviewers. Many thanks to Fahd Arshad for his im-
plementation of the sanitizer application. Thanks also to the
CMU/CS Operations Group for help in the evaluation por-
tion of the project. This work was supported by National
Science Foundation grant number CNS-0430474, and by
the Army Research Ofﬁce through grant number DAAD19-
02-1-0389 (Perpetually Available and Secure Information
Systems) to Carnegie Mellon University’s CyLab. The
views and conclusions contained in this document are those
of the authors and should not be interpreted as represent-
ing the ofﬁcial policies, either expressed or implied, of any
sponsoring institution, the U.S. government, or any other
entity.
9696
References
[1] D. Denning. An intrusion-detection model. IEEE Transac-
tions on Software Engineering, 13(2), February, 1987.
[2] S. Greenberg. Using Unix: Collected traces of 168 users.
Technical Report 88/333/45, Department of Computer Sci-
ence, University of Calgary, Calgary, Canada, 1988.
[3] The Honeynet Project. Know Your Enemy: Sebek, Novem-
http://www.honeynet.org/papers/
ber 2003.
sebek.pdf.
[4] M. Keeney, E. Kowalski, D. Cappelli, A. Moore,
T. Shimeall, and S. Rogers. Insider threat study: Computer
system sabotage in critical infrastructure sectors. Techni-
cal report, U.S. Secret Service and CERT Coordination Cen-
ter/SEI, 2005.
[5] T. Lane and C. E. Brodley. An application of machine learn-
ing to anomaly detection. In Proceedings of the 20th Annual
National Information Systems Security Conference, pages
366–380. Held on 7–10, October, 1997, Baltimore, MD,
NIST, 1997.
[6] M. V. Mahoney and P. K. Chan. An analysis of the
1999 DARPA/Lincoln Laboratory evaluation data for net-
work anomaly detection. In Proceedings of the 6th Interna-
tional Symposium on Recent Advances in Intrusion Detec-
tion (RAID-2003), pages 220–237. Held on 8–10 September,
2003, Pittsburgh, PA, Springer-Verlag, Berlin, 2003.
[7] R. A. Maxion. Masquerade detection using enriched com-
mand lines.
In International Conference on Dependable
Systems and Networks (DSN-03), pages 5–14. Held on 22–
25 June, 2003, San Francisco, CA, IEEE Computer Society
Press, Los Alamitos, CA, 2003.
[8] R. A. Maxion and T. N. Townsend. Masquerade detection
augmented with error analysis. IEEE Transactions on Relia-
bility, Special Section on Quality/Reliability of Engineering
of Information Systems, 53(1):124–147, March 2004.
[9] R. Pang and V. Paxson. A high-level programming environ-
ment for packet trace anonymization and transformation. In
Proceedings of the 2003 Conference on Applications, Tech-
nologies, Architectures, and Protocols for Computer Com-
munications (SIGCOMM’03), pages 339–351. Held on 25–
29 August, 2003, Karlsruhe, Germany, ACM Press, 2003.
[10] M. R. Randazzo, M. Keeney, E. Kowalski, D. Cappelli, and
A. Moore. Insider threat study: Illicit cyber activity in the
banking and ﬁnance sector. Technical report, U.S. Secret
Service and CERT Coordination Center/SEI, 2004.
[11] M. Schonlau, W. DuMouchel, W.-H. Ju, A. F. Karr,
M. Theus, and Y. Vardi. Computer intrusion: Detecting mas-
querades. Statistical Science, 16(1):58–74, 2001.
[12] S. E. Smaha. Haystack: An intrusion detection system. In
Proceedings of the Fourth Aerospace Computer Security Ap-
plications Conference, pages 37–44. Held on 12–16 Decem-
ber, 1988, Orlando, FL, IEEE Press, 1989.
[13] L. Sweeney. k-anonymity: A model for protecting pri-
vacy. International Journal on Uncertainty, Fuzziness and
Knowledge-based Systems, 10(5):557–570, 2002.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:02 UTC from IEEE Xplore.  Restrictions apply.