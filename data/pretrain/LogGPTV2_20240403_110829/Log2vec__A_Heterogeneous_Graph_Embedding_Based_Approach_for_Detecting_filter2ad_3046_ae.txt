log2vec-cosine
TIRESIAS (LANL)
ensemble method
(CERT)
(LANL)
AUC
0.93
0.10
0.71
0.80
0.54
0.35
0.85
0.89
6.2 Comparison with baselines
We employ AUC (area under the ROC curve) to compare differ-
ent approaches’ performances. In Table 3, log2vec outperforms
baselines. TIRESIAS and DeepLog are the state-of-the-art log-entry-
level approaches to anomaly detection. In CERT dataset, they both
only employ causal and sequential relationship within a day,
without the other two relationships, logical relationships among
days and logical relationships among objects. Therefore, they
cannot achieve satisfactory performances (0.39, 0.10). Lack of enough
malicious samples also causes this result. For instance, TIRESIAS
requires pre-labeled security events for training, but our scenarios,
CERT and LANL datasets are imbalanced. As shown in Table 4,
some users perform 22, 18 or even 4 malicious actions.
Deep learning methods (DNN and LSTM) are different from
TIRESIAS and DeepLog. Specifically, TIRESIAS takes sequences of
log entries ordered by time as input, while the LSTM in baselines
uses sequences of statistics features extracted from log entries per
day. They produce suspicious days but we compute their AUCs ac-
cording to benign and malicious log entries per day. Although DNN
and LSTM are inferior to log2vec in log-entry level, they achieve
better performances than TIRESIAS and DeepLog, because they con-
sider more relationships, e.g. logical relationships among days.
Hidden markov models (markov-s and markov-c) are designed
to identify suspicious days during which malicious events occur.
STREAMSPOT aims to detect malicious information flow graphs.
Instead, Table 3 shows their AUCs in log-entry level (more details
in Appendix G). These methods as well cannot beat log2vec.
Metapath2vec and node2vec are advanced graph embedding
models. Node2vec is designed to process a homogeneous graph
and thereby achieves an inferior performance. Metapath2vec can
process a heterogeneous graph. In fact, the main difference between
metapath2vec and log2vec’s graph embedding is that log2vec re-
tains the capability of adjusting the proportion of sets of edge type.
If the proportion is default (1:1:1:1:1), these two methods are the
same. Apparently, insider threats demand different proportions and
hence log2vec achieves a superior performance. Note that log2vec-
Euclidean and log2vec-cosine are discussed in Section 6.6
In LANL dataset, there exist enough data for TIRESIAS’s training
(3.6 million log entries). The reason why it can obtain a presentable
Session 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom1786result (0.85), is that we design a specified event in the dataset. Specif-
ically, TIRESIAS views events, which appear less than 10 times, as
the specified one. Therefore, TIRESIAS successfully classifies this
event as anomalous, due to enough samples. However, the specified
event involves numerous benign events. If TIRESIAS learns patterns
of these various rare events, whose average number of occurrence
is 2.1, instead of the specified one, it does not work (AUC is 0.05).
This is because the dataset in our scenarios is extremely imbalanced
and lacks enough malicious samples for training. Moreover, TIRE-
SIAS neglects other relationships, especially logical relationships
among objects. The ensemble method identifies characteristic pat-
terns of APT as statistical features and analyzes them to detect
compromised hosts, while log2vec performs a more fine-grained
detection, identifying malicious log entries.
Log2vec’s potential. Log2vec++ remarkably outperforms log2vec.
The main difference between them is that two parameters of log2vec++,
neiдh++ and δ1++ are flexibly set as shown in Table 6 in Appendix H,
while log2vec’s neiдh is 1 and δ1 is set according to Section 5.3. Two
reasons contribute to the difference. First, insider threat and APT
datasets are generally extremely imbalanced. We need to exactly
set combinations of parameters for each user to figure out a very
few malicious operations. Second, multiple users and attacks pro-
duce various user’s behavior and attack patterns. Log2vec should
precisely extract and represent information indicating these pat-
terns and behavior from log entries. Therefore, it demands different
combinations of parameters for each user.
Table 4: Log2vec’s detection results on six malicious users
(e.g. ACM2278) in CERT and 50 attackers in LANL dataset.
The metrics is the number of detected malicious log entries/
the number of total malicious log entries.
User Id
# detected log
entries/ # total
User Id
# detected log
entries/ # total
22/22
ACM2278
CMP2946 HIS1706
155/242
CDE1846 MBG3183
134/134
PLJ1771
4/8
11/18
LANL dataset
419/495
4/4
6.4 Parameter Sensitivity
We study how the six parameters in graph embedding influence
log2vec’s performance on detecting user CMP2946 in CERT dataset.
Specifically, we employ the metrics, AUC as a function of these six
parameters. When testing one parameter, the other five are fixed to
their default values. Meanwhile, δ1 in the detection algorithm is set
to 0.65, at which log2vec achieves the best performance according
to Section 5.3. δ2 is adjusted to compute AUC.
Figure 6a depicts a first-increasing and then-steady line, imply-
ing that 10 walks per node (r) are enough to extract the context
of each node (log entry). Similarly, after l and d reach around 60
and 100 respectively, log2vec’s performances do not significantly
increase in Figure 6b and Figure 6c. In Figure 6d, we observe that
AUC rises to the peak at c = 10. We classify these four parameters
into the same category. They are all insensitive to detected users
and attacks. More specifically, when r = 10, l = 60, d = 100 and c =
10, log2vec’s performance is close to the promising result for all
suspicious users and attacks. This finding is different from other ex-
periments in social networks [3, 14]. This is because the number of
malicious operations in insider threat detection or APT detection is
significantly small. Therefore, the four values are enough to extract
each log entry’s context and learn its representation. Meanwhile,
remaining undetected malicious log entries are mainly accounted
for by other log2vec’s parameters.
In Figure 6e, when ps is 1:1:1:5, log2vec achieves the best per-
formance. In Figure 6f, value 4, 7, 8 and 9 produce promising per-
formances. In Figure 7a, we jointly tune ps and neiдh. Log2vec
apparently achieves the best performances when ps is 1:1:1:6, no
matter how neiдh is adjusted. ps thereby is a more crucial parame-
ter than neiдh. In contrast to the aforementioned four parameters,
ps and neiдh are sensitive to varied users and attacks. In Table 6
in Appendix H, log2vec and log2vec++ flexibly adjust ps and out-
perform other approaches. Moreover, log2vec++ also adjusts neiдh
and δ1, and thereby beats log2vec. Besides, δ2 is as well sensitive
to scenarios according to its definition. Therefore, we classify these
four parameters into the same category, sensitive to detected users
and attacks. Section 4.1.3 introduces how to set ps. We usually set
neiдh to value 1. The way of setting δ1 and δ2 is given in Section 5.3.
6.3 Detection of Malicious Users
Table 4 shows log2vec’s detection result. Although log2vec does not
detect all malicious operations, it achieves the best performances on
detecting insider attacks (CERT) and APT (LANL) compared with
baselines (see Section 6.2). Log2vec shows its generic to multiple
distinct attacks: 1) stealing data by removable drive or data upload
(ACM2278, CMP2946, MBG3183), 2) logging into other users for
confidential files (CDE1846). These two types of attacks belong to
the first scenario mentioned in Section 2.3. 3) Masquerade attack.
Attacker steals credentials of other legitimate users through key log-
ger and sends out alarming emails, causing panic (HIS1706, PLJ1771).
This is the second scenario. 4) The APT perpetrator compromises
a host and from this host persistently compromises multiple ones
(LANL dataset), belonging to the third scenario.
6.5 Effectiveness of Log2vec’s Sets of Edge Type
As shown in Figure 3, five out of the ten rules are used to construct
log sequences, e.g. rule1, and the other five are to respectively bridge
them, e.g. rule4. These two categories of rules are complementary
to each other. If we cut down one of the former rules, e.g. rule1, its
corresponding rule in the latter, e.g. rule4, cannot be applied to the
graph construction due to lack of daily log sequences. If we just
employ the former, e.g. rule3 without rule6, log2vec only constructs
user’s daily log sequences and cannot detect anomalous ones like
the instance in Section 2.2. Therefore, we evaluate log2vec’s sets of
edge type, defined by these rules in pairs.
We conduct the evaluation on the six attackers in CERT dataset
and six chosen randomly ones in LANL dataset. Specifically, we cut
down a set of edge type and use the remaining ones for detection.
Figure 7b demonstrates that performances all drop without any set
of edge type, especially {edge3, edge6} and {edge7, edge8}, the most
important ones for varied scenarios as mentioned in Section 4.1.3.
Session 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom1787(a)
(d)
(b)
(e)
(c)
(f)
Figure 6: Performance of log2vec on different parameters.
Log2vec’s performance without {edge9, edge10} drops remarkably
on users, who launch attacks through the Internet, regarding Rule9
and Rule10. Log2vec’s without {edge1, edge4} or {edge2, edge5}
performance decreases mainly when the original proportion of the
sets of edge type is 1:1:1:1, meaning these two sets play a nearly
equal role to the others in detecting these specific attackers.
6.6 Effectiveness of Log2vec’s Clustering
We take user CDE1846 in CERT dataset, as an example to demon-
strate that log2vec’s clustering algorithm is more fit for the attack
scenarios in this paper, compared with k-means. Figure 7c presents
their Receiver Operating Characteristic curves (or ROC curves)
smoothed by the method of bionormal [15]. The main difference
between them is that they separately employ k-means with cosine
distance, Euclidean one and clustering algorithm in Section 5.1. In
the figure, AUCs regarding k-means are all below 0.5. This is be-
cause these methods use cluster centers to group log entries, leading
to heavily depending on their initialization. However, the number
of malicious operations in insider threat dataset is extremely small.
Accordingly, these operations are hardly chosen as centers during
initialization and tend to be grouped into their neighboring clusters.
Another reason is that k is difficult to set. If k is too small, malicious
log entries are more likely to be gathered with benign ones.
7 DISCUSSION
7.1 Evasion
Log2vec figures out malicious clusters in the light of their sizes. If
the attacker plans to evade detection, he may conduct enough ma-
licious operations to expand the corresponding cluster as large as
benign ones. However, this process would more likely draw atten-
tion to his behavior. For instance, the existing security information
and event management (SIEM) would detect these operations.
7.2 Limitations
Graph rules. Log2vec is designed towards detecting three signifi-
cant scenarios regarding insider threat and APT as introduced in
the adversarial model. The three relationships used in log2vec are
derived from the existing method [4, 38, 41, 50, 57]. These rela-
tionships involve user’s behavioral pattern, attack of intranet and
penetration from the Internet. Certainly, we can consider new re-
lationships and design new rules. For instance, new features of
APT are still exploited and we can put them into the graph. Sim-
ilarly, there exist other attack scenarios [34]. Therefore, we need
to incorporate new relationships into the graph for covering them.
For instance, email networks can be converted into graph rules for
detecting spearphishing. These plans are left to future work.
False positive rate. FPRs produced by log2vec are respectively 0.08
and 0.1 in both datasets, fairly high in a production environment and
would increase their efforts during analysts’ analysis. To tackle this
problem, we can employ the existing methods regarding combating
threat alert fatigue [6, 16, 25] to assist analysts in reducing false
positives. This direction is also our future work.
Log2vec’s parameters. As mentioned in log2vec’s potential (see
Section 6.2), although log2vec outperforms baselines, this version
of graph embedding and detection algorithm still can be improved,
like log2vec++, if we can tune parameters flexibly for each user.
This work can be conducted in two directions. The first one is
to research on choosing parameters automatically. Another is to
lllll0.550.620.690.760.83510152025Number of walks per node, rAUClllll0.650.700.750.800.8520406080100Walk length, lAUCllllllll0.650.700.750.800.8550100150200250300Vector dimension, dAUCllllllll0.630.680.730.780.8368101214161820Window size, cAUClllll0.520.590.660.730.801:1:1:11:1:1:21:1:1:31:1:1:51:1:1:6Proportion of sets of edge type, psAUClllllllll0.680.730.780.830.88123456789Neighbor, neighAUCSession 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom1788(a)
(b)
(c)
Figure 7: (a) Log2vec’s performance when jointly tuning neiдh and ps. (b) Log2vec’s performance without certain sets of edge
type, e.g {e1, e4} meaning lack of {edge1, edge4}. (c) Performance of log2vec on user CDE1846 in CERT dataset.
improve the existing version of graph embedding and detection
algorithm, e.g. reducing parameters.
Graph neural network. Graph neural network (GNN) is a prevail-
ing method and has outperformed graph embedding in such various
domains, as citation network, knowledge graphs and social events
forecasting [9, 23, 36, 37]. GNN has a more complicated structure
for learning graph’s topology, compared with graph embedding’s
word2vec model, e.g. skip-gram. However, a majority of its variants
require labeled data for training. Insider threat detection and APT
detection are data imbalanced problems and there exist only a few
anomalous samples. Therefore, it needs numerous efforts to employ
GNN’s powerful function in this field.
8 RELATED WORK
Insider Threat Detection and APT Detection. The issues of in-
sider threat detection and APT detection have been extensively
researched on various scenarios [5, 18, 48, 49].
A typical method is extracting features of user’s behavior and
processing them by machine learning models to find malicious
events [13, 27, 57, 61]. Features from social data summarized in [13],