title:Practical Proactive Integrity Preservation: A Basis for Malware
Defense
author:Weiqing Sun and
R. Sekar and
Gaurav Poothia and
Tejas Karandikar
2008 IEEE Symposium on Security and Privacy
Practical Proactive Integrity Preservation:
Weiqing Sun
A Basis for Malware Defense(cid:3)
R. Sekar
Department of Computer Science
Gaurav Poothia
Tejas Karandikar
Stony Brook University, Stony Brook, NY 11794
Abstract
Unlike today’s reactive approaches, information (cid:13)ow
based approaches can provide positive assurances about
overall system integrity, and hence can defend against
sophisticated malware. However,
there hasn’t been
much success in applying information (cid:13)ow based tech-
niques to desktop systems running modern COTS op-
erating systems. This is, in part, due to the fact that a
strict application of information (cid:13)ow policy can break
existing applications and OS services. Another impor-
tant factor is the di(cid:14)culty of policy development, which
requires us to specify integrity labels for hundreds of
thousands of objects on the system. This paper devel-
ops a new approach for proactive integrity protection
that overcomes these challenges by decoupling integrity
labels from access policies. We then develop an analy-
sis that can largely automate the generation of integrity
labels and policies that preserve the usability of applica-
tions in most cases. Evaluation of our prototype imple-
mentation on a Linux desktop distribution shows that it
does not break or inconvenience the use of most applica-
tions, while stopping a variety of sophisticated malware
attacks.
1. Introduction
Security threats have escalated rapidly over the past
few years. Zero-day attacks have become signi(cid:12)cant
threats, being delivered increasingly through seemingly
innocuous means such as web pages and documents.
Malware is rampant, being installed on millions of com-
puters around the Internet through implicit or explicit
software downloads from untrusted sources. Emer-
gence of cyber crime has led to increasingly stealthy
and sophisticated attacks and malware that can hide
from the best available defenses today.
Today’s malware defenses rely mainly on reactive
approaches such as signature-based scanning, behav-
ior monitoring, and (cid:12)le integrity monitoring. Un-
fortunately, attackers can easily modify the structure
(cid:3)This research is supported in part by an ONR grant
000140710928 and an NSF grant CNS-0627687.
and behavior of their malware to evade detection by
signature-based or behavior-based techniques. They
may also subvert system integrity monitoring tools us-
ing rootkit-like techniques.
It is therefore necessary
to develop proactive techniques that can stop malware
before it damages system integrity.
Sandboxing is a commonly deployed proactive de-
fense against untrusted (and hence potentially mali-
cious) software. It restricts the set of resources (such as
(cid:12)les) that can be written by an untrusted process, and
also limits communication with other processes on the
system. However, techniques that regulate write-access
without restricting read-access aren’t su(cid:14)cient to ad-
dress adaptive malware threats. Speci(cid:12)cally, they do
not satisfactorily address indirect attacks, where a be-
nign application ends up consuming malware outputs
stored in persistent storage (e.g., (cid:12)les). For instance,
malware may modify the following types of (cid:12)les used
by a benign application:
(cid:15) System libraries, con(cid:12)guration (cid:12)les or scripts. One
may attempt to eliminate this possibility by pre-
venting untrusted software from storing any (cid:12)les in
system directories, but this will preclude the use of
many legitimate (untrusted) applications that expect
to (cid:12)nd their binaries, libraries and con(cid:12)guration (cid:12)les
in system directories. Alternatively, one can explic-
itly enumerate all the (cid:12)les in system directories that
are used by benign applications, but this becomes
a challenging task when we consider the number of
such (cid:12)les | for instance, a typical desktop Linux
distribution contains over 100K (cid:12)les in system direc-
tories. Errors may creep into such enumerations, e.g.,
one may leave out optional libraries (e.g., application
extensions such as Apache modules, media codecs,
etc.) or con(cid:12)guration/customization (cid:12)les, thereby in-
troducing opportunities for indirect attacks.
(cid:15) User-speci(cid:12)c customization (cid:12)les and scripts. Identi-
fying all user-speci(cid:12)c scripts and customization (cid:12)les is
even harder: di(cid:11)erent applications use di(cid:11)erent con-
ventions regarding the location of user-speci(cid:12)c cus-
tomization (cid:12)les. Moreover, some of these (cid:12)les may in
turn load other user (cid:12)les, or run scripts within user
directories. Static identi(cid:12)cation of all the (cid:12)les used
978-0-7695-3168-7 /08 $25.00 © 2008 IEEE
DOI 10.1109/SP.2008.35
248
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply. 
by a benign application may be very hard.
We observe that signi(cid:12)cant harm can result from
unauthorized modi(cid:12)cations to user (cid:12)les. For in-
stance, by altering ssh keys (cid:12)le, malware may enable
its author to log into the system on which it is in-
stalled. By modifying a (cid:12)le such as .bashrc, e.g.,
by creating an alias for a command such as sudo,
malware can cause a Trojan program to be run each
time sudo is used. Worse, malware can (cid:12)rst modify
a con(cid:12)guration (cid:12)le used by a less conspicuous be-
nign application, such as a word-processor. For in-
stance, it may replace the name of a word-processor
plug-in with a Trojan program that in turn modi(cid:12)es
.bashrc.
(cid:15) Data (cid:12)les. Malware may create data (cid:12)les with ma-
licious content that can exploit vulnerabilities in be-
nign software. The recent spate of vulnerabilities
in image and document viewers, web browsers, and
word-processors shows that this is indeed a viable
approach. Malware may save these (cid:12)les where they
are conspicuous (e.g., on the desktop), using names
that are likely to grab user attention. When the user
invokes a benign viewer on the (cid:12)le, it will be com-
promised. At this point, malware can achieve its ob-
jectives using the privileges available to the viewer.
In contrast, we develop an approach in this paper that
aims to provide positive assurance about overall system
integrity. Our method, called PPI (Practical Proac-
tive Integrity protection), identi(cid:12)es a subset of objects
(which are typically (cid:12)les) as integrity-critical and a
set of untrusted objects. We assume that system in-
tegrity is preserved as long as untrusted objects are
prevented from in(cid:13)uencing the contents of integrity-
critical objects either directly (e.g., by copying of an
untrusted object over an integrity-critical object) or
indirectly through intermediate (cid:12)les. In other words,
there should be no information (cid:13)ow from untrusted ob-
jects to integrity-critical objects.
Although information-(cid:13)ow based integrity preserva-
tion techniques date as far back as the Biba integrity
model [6], these techniques have not had much suc-
cess in practice due to two main reasons. First, these
techniques require every object in the system to be
labeled as high-integrity or low-integrity | a cum-
bersome task, considering the number of (cid:12)les involved
(more than 100K on typical Linux systems). Manual
labeling is prone to errors that can either damage sys-
tem integrity (by allowing an integrity-critical (cid:12)le to
be in(cid:13)uenced by a low-integrity application) or usabil-
ity (by denying a legitimate operation as a result of
security violation). Secondly, the approach is not very
(cid:13)exible, and hence breaks many applications. To over-
come this problem, many applications may need to be
designated as \trusted," which basically exempts them
from the information (cid:13)ow policy. Obviously, an in-
crease in the number of trusted applications translates
to a corresponding decrease in assurance about overall
integrity.
As a result of
the factors mentioned above,
information-(cid:13)ow based techniques have not become
practical in the context of contemporary operating sys-
tems such as Windows and Linux. In contrast, we have
been able to develop a practical information-(cid:13)ow based
integrity protection for desktop Linux systems by fo-
cusing on (a) automating the development of integrity
labels and policies, (b) providing a degree of assurance
that these labels and policies actually protect system
integrity, and (c) developing a (cid:13)exible framework that
can support contemporary applications while minimiz-
ing usability problems as well as the need to designate
applications as \trusted." Our experiments considered
a modern Linux Workstation OS together with numer-
ous benign and untrusted applications, and showed
that system usability is preserved by our technique,
while thwarting sophisticated malware.
1.1. Goals of Approach
(cid:15) Provide positive assurances about system integrity
on a contemporary Workstation, e.g., a Linux Cen-
tOS/Ubuntu desktop consisting of hundreds of be-
nign applications and tens of untrusted applications.
Integrity should be preserved even if untrusted pro-
grams run with root privileges.
(cid:15) E(cid:11)ectively block rootkits and most other malware.
Most malware,
including rootkits and spyware,
should be detected when they attempt to install
themselves, and removed automatically and cleanly.
Stealthier malware should be detected when they at-
tempt to damage system integrity, and can be re-
moved at that point. We do not address malware
that can operate without impacting system integrity,
e.g., a P2P application that transmits user data to a
remote site when it is explicitly invoked by a user.
(cid:15) Be easy to use, for end-users as well as system ad-
ministrators. Usability encompasses the following:
{ Preserve availability of benign applications, specif-
ically, provide a certain level of con(cid:12)dence that be-
nign applications would not fail due to security vi-
olations during their normal use.
{ Minimize administrator e(cid:11)ort by automating the
development of (cid:12)le labels and integrity policies.
{ Eliminate user prompts. Security mechanisms that
require frequent security decisions from users don’t
work well in practice for two reasons. First, users
get tired and don’t cooperate. Second, these user
249
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply. 
interactions become the basis for social engineering
attacks by malware writers.
(cid:15) Reduce reliance on trusted applications so as to pro-
vide better overall assurance.
1.2. Salient Features
Traditional approaches
The principal elements of our approach that enables us
to achieve the above goals are summarized below:
(cid:15) Flexible decomposition of high-level policies into
low-level policies.
for
information-(cid:13)ow based integrity, such as the Biba in-
tegrity model [6], associate a label with an object (or
subject) at the time of their creation, and this la-
bel does not change during the lifetime of the object
or subject.
In other words, these labels e(cid:11)ectively
de(cid:12)ne the access policies: a subject is permitted to
read (write) an object only if the subject’s integrity is
equal to or lower (equal to or higher) than that of the
object.
In contrast, we distinguish between labels,
which are a judgment of the trustworthiness of an
object (or subject), from policies that state whether
a certain read or write access should be permitted.
Based on this separation, our approach (described in
Section 2) allows integrity levels of objects or subjects
to change over their lifetime. Moreover, \read-down"
and \write-up" con(cid:13)icts are resolved di(cid:11)erently for
di(cid:11)erent objects and subjects. These factors pro-
vide (cid:13)exibility in developing low-level policies that
preserve system integrity without unduly impacting
usability.
(cid:15) Automated analysis for generating enforceable poli-
cies. Given the large number of objects (hundreds of
thousands) and subjects (thousands), manual setting
of policies for every object/subject pair is impracti-
cal.
In Section 3, we therefore develop techniques
that utilize an analysis of access patterns observed
on an unprotected system to automatically derive
policies. This analysis can also be used to automat-
ically complete the set of integrity-critical applica-
tions, starting from a partial list provided by a policy
developer.
As we show in Section 3.3, our technique is sound,
i.e., it will generate policies that preserve system in-
tegrity, even if the access logs used in analysis are
compromised by malicious applications running on
the unprotected system. However, corrupted logs can
compromise system availability.
(cid:15) A (cid:13)exible enforcement framework. Our enforcement
framework, described in Section 5, consists of a small,
security-critical enforcement component that resides
in the OS kernel, and a user-level component that in-
corporates more complex features that enhance func-
Integrity−critical
Trusted
Malicious
Benign
(High Integrity)
Untrusted
(Low Integrity)
Figure 1. Classi(cid:2)cation of Applications
tionality without impacting security. This framework
also incorporates features needed for learning and
synthesizing policies for new applications.
(cid:15) Mechanisms for limiting trust. There are some in-
stances when high-integrity applications should be
allowed to access low-integrity (cid:12)les. In Section 4, We
develop techniques that enable such exceptions to be
restricted. Our techniques typically have the e(cid:11)ect
of distinguishing between code/con(cid:12)guration inputs
from data inputs, and ensuring that exceptions are
made only for data inputs. Using these mechanisms,
we describe how we can limit the amount of trust
placed on important applications such as software
installers, web browsers and email handlers, and (cid:12)le
utilities.
We have implemented our technique on desktop sys-
tems running RedHat/Ubuntu Linux, consisting of sev-
eral hundred benign software packages and a few tens
untrusted packages, the evaluation shows that the ap-
proach is practical, and does not impose signi(cid:12)cant us-
ability problems. It is also e(cid:11)ective in preventing in-
stallation of most malware packages and detection (and
blocking) of malicious actions performed by stealthy
malware.
2. Policy Framework
2.1. Trust and Integrity Levels
Figure 1 illustrates the integrity and trust levels used
in our framework. To simplify the presentation, we
use just two integrity levels: high and low.
Integrity
labels are associated with all objects in the system,
including (cid:12)les, devices, communication channels, etc.
A subset of high-integrity objects need to be identi(cid:12)ed
as integrity-critical, which provide the basis for de(cid:12)ning
system integrity:
De(cid:12)nition 1 (System Integrity) We say that sys-
tem integrity is preserved as long as all integrity-critical
objects have high integrity labels.
The set of integrity-critical objects is externally spec-
i(cid:12)ed by a system administrator, or better, by an OS
distribution developer.
It is important to point out
that the integrity-critical list need not be comprehen-
sive: if objects are left out of this list, our technique will
250
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply. 
automatically detect them using the analysis described
in Section 3, as long as these objects are accessed after
the kernel module enforcing PPI policies has begun ex-
ecution. In particular, objects that are accessed during
early phases of the boot process, as well those objects
that are accessed by PPI, must be explicitly included in
the integrity-critical set. On Linux, this (minimal) set
of integrity-critical objects includes all the (cid:12)les within
/boot, the binaries used by init and the (cid:12)les used by