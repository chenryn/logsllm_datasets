报警
一般来说，Google趋向于使用简单和快速的监控系统配合高效的工具进行事后分析。我
每个SRE团队一般至少有一个“监控专员”（虽然平时看看流量图表可能很有意思，
将通用的监控基础设施进行了改造和集中化，这个数字已经随着时间下降了。但是目前
监控一个复杂的应用程序本身就是一项复杂的工程项目。即使在具有大量现成的基础设
我们的请求延迟刚刚大幅增加了，有没有其他的现象同时发生？
指标”（参见本章后面“4个黄金指标”
监控台页面应该可以回答有关服务的一些基本问题，通常会包括常见的4个“黄金
某项东西出现故障了，需要有人立刻修复！或者某项东西可能很快会出故障，需要
有人尽快查看。
一例如试图自动学习阔值或者自动检测故障原因的系统。
一节中的详细讨论）。
对监控系统设置合理预期
但
58
57
---
## Page 94
私有内容可以被任何人访问
南极洲用户无法接收GIF动画
回复速度很慢
表6-1：现象与原因的示例
因，并不是根源问题）。表6-1列出了一些现象，以及它们对应的原因。
“什么东西出故障了”即为现象（symptom）：“为什么”则代表了原因（可能只是中间原
监控系统应该解决两个问题：什么东西出故障了，以及为什么出故障。
现象与原因
警报的监控系统规则应该非常容易理解，同时代表一个清晰的故障场景。
同样的，监控系统信噪比应该很高，发出紧急警报的组件需要非常简单而且可靠。产生
理解。
警报，简单定位和深入调试”过程必须要保持非常简单，必须能被团队中任何一个人所
到这些目标的方法。但是监控系统中最重要的一点就是整个“生产故障，人工处理紧急
其是在一个不断改变的系统中。这一章给监控系统设立了一些目标，同时提供了一些达
本章中讨论到的某些想法还有想象的空间：从现象到根源问题的定位速度可以更快，尤
构速度很快，很少有团队会在监控系统中维护复杂的依赖关系。
要发出有关延迟的警报”是一个常见的数据中心警报规则。由于Google基础设施的重
用户流量从数据中心迁出的系统。“如果数据中心处于‘排水状态”（drained），那么不
警告”。针对依赖服务的监控规则，一般只用于系统中非常稳定的组件上。例如某个将
果我知道数据库目前缓慢，那么发出一条数据库缓慢的警报，否则发出一条网站缓慢的
GoogleSRE在应对复杂依赖关系时的成功经验并不多。我们偶尔会使用这样的规则：“如
为这些偶尔出现的错误不会掩盖真正的长期趋势。
时间跨度非常长（数月甚至数年），取样率也很低，这种用途可以容忍一定的错误率，因
误和稳定性的要求更低，也就可以稍微复杂一些。针对某个试验功能的数据观测，可能
情况。监控数据的其他用处还包括容量规划、流量预测，用于这些方面的监控规则对错
则越简单越好，同时要求这些监控规则可以检测某个非常简单、具体，但是严重的异常
正在返回HTTP500或者404
第6章分布式系统的监控
新的软件版本发布造成ACL丢失，
CDN网络将某些IP列人了黑名单
造成断续的网络丢包
CPU被某个排序操作占满了，某根网线被压在了机柜下面，
数据库服务器拒绝连接
原因
允许所有请求进入
---
## Page 95
流量
能监控用户可见系统的4个指标，那么就应该监控这4个。
监控系统的4个黄金指标分别是延迟、流量、错误和饱和度（saturation）。如果我们只
4个黄金指标
急警报。另外一方面，针对那些还没有发生，但是即将发生的问题，黑盒监控通常是没
黑盒监控可以保证系统只在某个问题目前正在发生，并且造成了某个现象时才会发出紧
务器之间的网络问题。
库自己检测到的速度。否则，无法区分出到底是数据库问题还是Web服务器与数据库服
依赖数据库的请求上很慢时，我们需要同时知道Web服务器检测到的数据库速度与数据
当收集用于调试的遥测数据时，白盒监控是必不可少的。如果Web服务器看起来在那些
时是面向现象的，有时是面向原因的，这取决于白盒系统所提供的信息。
SRE来说，他们看到的是网站缓慢，数据库读操作的缓慢则是原因。因此，白盒监控有
数据库性能问题。数据库读操作很缓慢是数据库SRE检测到的一个现象。然而，对前端
这里应该注意，在一个多层系统中，某一个服务的现象是另外一个服务的原因。例如，
即将发生的问题及那些重试所掩盖的问题等。
检测，如系统日志、抓取提供指标信息的HTTP节点等。白盒监控系统因此可以检测到
预测会发生的—问题，即“系统现在有故障”。白盒监控则大量依赖对系统内部信息的
与白盒监控最简单的区别是；黑盒监控是面向现象的，代表了目前正在发生的一而非
Google大量依赖白盒监控，黑盒监控用得虽然不多，但都是在关键地方使用。黑盒监控
黑盒监控与白盒监控
延迟
用的。
数量。针对键值对存储系统来说，指标可能是每秒交易数量，或每秒的读取操作数量。
使用系统中的某个高层次的指标针对系统负载需求所进行的度量。对Web服务器来
态请求）。针对音频流媒体系统来说，这个指标可能是网络I/O速率，或者并发会话
说，该指标通常是每秒HTTP请求数量，同时可能按请求类型分类（静态请求与动
“慢”错误要比“快”错误更糟！因此，监控错误回复的延迟是很重要的。
总体延迟时，如果将500回复的延迟也计算在内，可能会产生误导性的结果。但是，
服务处理某个请求所需要的时间。这里区分成功请求和失败请求很重要。例如，某
个由于数据库连接丢失或者其他后端问题造成的HTTP500错误可能延迟很低。计算
4个黄金指标
<60
---
## Page 96
注2如果1%的请求需要10倍的平均时间，这就意味着其他请求大概只需要平均值的一半。除非有统计
如果用户依赖几个这样的服务来渲染页面，那么某个后端请求的延迟的99%可能就会成
每秒处理1000个请求，平均请求延迟为100ms。那么1%的请求可能会占用5s时间。准2
和数据库的利用率可能波动很大，但是同样的道理也适用于延迟。如果某个Web服务
均CPU使用率，数据库容量的平均值等。后两个例子中存在的问题是很明显的：CPU
构建监控系统时，很多人都倾向于采用某种量化指标的平均值：延迟平均值，节点的平
关于长尾问题
和度来说，快要发生故障时），能做到这些，服务的监控就基本差不多了。
如果我们度量所有这4个黄金指标，同时在某个指标出现故障时发出警报（或者对于饱
饱和度
错误
请求失败的速率，要么是显式失败（例如HTTP500），要么是隐式失败（例如
延迟的分布情况证明，大多数请求都接近平均值这个假设一般是不成立的。
最后，饱和度同样也需要进行预测，例如“看起来数据库会在4个小时内填满硬盘”
可以作为一个饱和度早期预警的指标。
增加是饱和度的前导现象。99%的请求延迟（在某一个小的时间范围内，例如一分钟）
用率，或者网络带宽等来代替，因为这些指标通常有一个固定的已知的上限。延迟
就足够了。但是正如前文所述，大部分服务都需要使用某种间接指标，例如CPU利
回一个全球唯一的单向递增整数”服务），根据负载测试中得到的一个固定数值可能
对没有请求复杂度变化的简单服务来说（例如，“返回一个随机数”服务，或者是“返
常处理两倍的流量，是否可以应对10%的额外流量，或者甚至应对当前更少的流量？
在复杂系统中，饱和度可以配合其他高层次的负载度量来使用：该服务是否可以正
系统在达到100%利用率之前性能会严重下降，增加一个利用率目标也是很重要的。
内存受限的系统中，即为内存；在I/O受限的系统中，即为I/O)。这里要注意，很多
服务容量有多“满”。通常是系统中目前最为受限的某种资源的某个具体指标的度量。（在
障类型。
住所有的完全失败的请求，但是只有端到端的系统才能检测到返回错误内容这种故
障情况。监控方式也非常不一样：在负载均衡器上检测HTTP500请求可能足够抓
法表达全部的失败情况时，可以利用其他信息，如内部协议，来跟踪一部分特定故
回复在1s内发出，任何超过1s的请求就都是失败请求）。当协议内部的错误代码无
HTTP200回复中包含了错误内容），或者是策略原因导致的失败（例如，如果要求
第6章分布式系统的监控
---
## Page 97
简化，
这种方式使我们可以观测到短暂的CPU热点，但是又不需要为此付出高额成本进行收集
系统的不同部分应该以不同的精度进行度量，例如
度量指标时采用合适的精度
观展现请求分布的最好方式。
100~300ms之间等。将直方图的边界定义为指数型增长（这个例子中倍数约为3）是直
（可以用来制作直方图）：延迟为0~10ms之间的请求数量有多少，30~100ms之间，
杂度的例子：
将之前讨论的所有需求累加起来可能会形成一个非常复杂的监控系统一以下是几个复
和保留高精度数据。
例如：
但是却不需要极低的延迟，可以通过一些内部采样机制外部汇总的方式降低成本。
但是这种高频率收集、存储、分析可能成本很高。如果我们的监控目标需要高精度数据，
应该仔细设计度量指标的精确度。每秒收集CPU负载信息可能会产生一些有意思的数据
为前端延迟的中位数。
3.将这些值每分钟汇总一次。
1.将当前CPU利用率按秒记录。
·对目标可用率为99.9%的某个服务每1分钟或者2分钟检查一次硬盘剩余空间可
·观察1分钟内的CPU平均负载可能会错失导致长尾延迟过高的某种较长时间的
·不同的延迟阈值，在不同的百分位上，基于各种各样不同的指标进行报警。
给每种可能的原因构建对应的监控台页面。
按5%粒度分组，将对应的CPU利用率计数+1。
检测和揭示可能的故障原因。
能也是没必要的。
钟检测1次或2次的监控频率可能过于频繁。
对于一个每年停机时间小于9小时的Web服务来说（年度可用率99.9%），每分
CPU峰值现象。
直到不能再简化
简化，直到不能再简化
62
---
## Page 98
当为监控系统和警报系统增加新规则时，回答下列问题可以帮助减少误报：注3
哲学同时有助于鼓励团队在解决问题时向正确的方向进行。
念一样，保持系统相对独立，清晰简单，松耦合的接口是更好的策略（例如，利用Web
独立的系统运行是比较好的。（事实上，Google的监控系统是作为多个二进制文件运行的，
在Google的经验里，指标的收集和汇总，加上警报系统与监控台系统，作为一个相对
心里：
因此，
虽然这个设计哲学有一定理想性，但是书写和评审某个新警报时可以依赖的好方法。该
本章描述的理念整合起来就成为Google SRE广泛接受和遵循的监控与警报设计哲学。
将上述理念整合起来
和分析，流量检测等）会导致监控系统过于复杂，容易出现问题。和其他软件工程的理
来（例如系统性能统计，单独进程的调试，异常或者崩溃的跟踪，
于经常出现问题，变更非常困难，维护起来难度很大。
复杂是没有止境的。就像任何其他软件系统一样，监控系统可能会变得过于复杂，以至
注4
注3
API来收集性能数据，采用一种可以持续很久不变的简单数据格式）。
但是通常人们把它们当成一个整体来学习。）将监控系统与其他的复杂系统操作结合起
·该规则是否能够检测到一个目前检测不到的、紧急的、有操作性的，并且即将发
·收集到的信息，但是没有暴露给任何监控台，或者被任何警报规则使用的应该定
·那些最能反映真实故障的规则应该越简单越好，可预测性强，非常可靠。
余度的讨论请参见https://en.wikipedia.org/wiki/N%2B1_redundancy。
零冗余（N+0）的情况也应该算作是即将发生的故障的情况，同样，接近满载的情况也一样！关于见
关于警报过多的“狼来了”效应，请参见Applying Cardiac Alarm Management Techniques to Your On-
标准是一个季度没有用到一次即将其删除)。
，设计监控系统时一定要追求简化。在选择需要检测什么的时候，将下列信息记在
滤掉。
触发这条规则的情况？例如测试环境和系统维护状态下发出的警报是否应该被过