if x ∈ I − (IS ∪ Id)
Suppose there are n programs P1, P2, . . . , Pn for process-
ing format f . The detector AV does not know which of them
will be used on the endhost and must produce:
Sf (x)
Sd1
Error
(x) . . . ∪ Sdn
(x)
if x ∈ IS
if x ∈ Id1
. . . ∪ Idn
if x ∈ I − (IS ∪ Id1
. . . ∪ Idn
)
⎧⎪⎪⎨
⎪⎪⎩
AV (x) =
Building such a parser is very difﬁcult. For example,
speciﬁcations of archive formats usually do not say what to
do when some member ﬁles are damaged or malformed (e.g.,
have invalid checksums). Some applications extract only the
valid ﬁles, others generate an error, yet others attempt to
repair the damage or simply ignore the invalid checksums.
Critically, many applications produce usable outputs even
for the input ﬁles that are invalid according to the format
speciﬁcation.
Detectors do not parse in the same way as applications.
First, the parsing functionality of applications is much richer
than that of malware detectors. Detectors only implement
the bare minimum needed to analyze a ﬁle for malware.
In the above example, many detectors ignore checksums in
archives because their goal is to ﬁnd hidden malware code,
not verify ﬁle integrity. At ﬁrst glance, a parser that ignores
90
checksums seems safe because, in theory, it should accept
strictly more inputs than a parser that veriﬁes checksums. As
we show in Section VI, this is not true! Ignoring checksums
introduces subtle parsing discrepancies between the parser
and the application and enables werewolf attacks.
Second, applications often have bugs in their ﬁle-parsing
code. The detector must replicate every known and unknown
parsing bug in every application that could be used on any
endhost to handle the ﬁle.
Third, many format speciﬁcations are incomplete and/or
nondeterministic. As a consequence, different applications
make different choices and parse even the same compliant
ﬁle in different ways. For example, parsing of PDF ﬁles is
notoriously loose [14, 26].
Fourth, speciﬁcations of proprietary ﬁle formats are often
closed-source and change with every release of the applica-
tion, making it infeasible for the implementors of malware
detectors to keep up.
It is hard to replicate the application’s parsing logic.
Even with access to the application’s parser, it is difﬁcult to
write another parser that exactly replicates its behavior on
all possible inputs. For example, after 12 years of bug-ﬁxing
there are still many ﬁle-parsing discrepancies between the
“functionally equivalent” busybox and coreutil versions of
Unix utilities [7]. 238 out of 743 compatibility bugs between
OpenOfﬁce and MS Ofﬁce are caused by ﬁle processing [24]
and even after a signiﬁcant reverse-engineering effort, faith-
ful replication of parsing remains a challenge [23].
In general, complete replication of the input-output behav-
ior is infeasible for most non-trivial systems. Non-parsing
examples include differences between OS implementations
of the same network protocol stack (exploited by Nmap) and
differences between monitored and unmonitored execution
environments (exploited by split-personality malware [8]).
Same ﬁle can be parsed according to different, contra-
dictory formats. Many ﬁle formats are ﬂexible enough that
an attacker can craft a single ﬁle which is valid according to
multiple ﬁle formats and can be correctly parsed in multiple
ways. For example, as mentioned in Section VI, a werewolf
ﬁle consisting of a valid TAR archive followed by a valid
ZIP archive can be processed either by tar, or by zip and
will produce different results depending on which program
is used. Similar attacks are possible for other format pairs,
such as ELF and ZIP or PE and CAB.
The detector must determine all possible formats with
which the ﬁle may be compatible, and, for each format, parse
the ﬁle in all possible ways supported by all applications
dealing with this format. Even if this were feasible, it is
likely to impose an unacceptable performance overhead.
Detector must keep an up-to-date list of all applications
on all protected endhosts. Even if the detector were capable
of accurately replicating hundreds of different ﬁle-parsing
algorithms, it must know which algorithms to apply. To do
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:44 UTC from IEEE Xplore.  Restrictions apply. 
this, the detector must know which applications may handle
the ﬁle of any of the protected endhosts at any given time,
and its parsing logic must be promptly updated whenever a
new version of any application is installed on any endhost.
In many cases—for instance, when the detector is running
on a mail server—the complete set of protected applications
may not even be known.
For example, one of our werewolf attacks involves a TAR
archive with a single ﬁle and a malformed header specifying
a signiﬁcantly larger length than the actual size of the ﬁle.
We tested three different Linux applications: GNU tar 1.22,
7-Zip 9.04 beta, and File Roller 2.30.1.1. 7-Zip was not able
to extract the contents. GNU tar extracted the contents with
an “unexpected EOF” warning. Surprisingly, File Roller,
which is a GUI front-end for GNU tar, failed to extract
the contents. Further examination revealed that even though
GNU tar extracts correctly, it returns 2 instead of the usual
0 because it reached the end of ﬁle much earlier than it
was expecting based on the length ﬁeld of the header. This
causes File Roller to produce an error message.
File parsing is version-dependent even in the same appli-
cation. For example, GNU tar up to version 1.16 supported
ustar type N header logical records, but later versions of
GNU tar no longer do.
It is hard to update parsing code. Adding or modifying a
ﬁle parser is not nearly as simple as adding a new virus sig-
nature. All signatures share a common format, thus a generic
signature-matching engine is usually capable of handling
both old and new signatures. Adding new signatures does not
require any changes to the signature format or the scanning
code. Parsers, on the other hand, must be implemented by
hand and manually updated after any change in the parsing
logic of any of the protected applications.
Normalization is no easier than parsing. Normaliza-
tion—rewriting a non-compliant ﬁle so that it complies with
the format speciﬁcation—may help in defeating werewolf
attacks. Unfortunately, it requires parsing the ﬁle ﬁrst and
thus faces all the problems outlined above.
For example, consider normalizing an archive to remove
invalid ﬁles. The detector must parse the archive to ﬁnd
individual ﬁles and determine their validity according to the
speciﬁcation of each ﬁle’s format. This is extremely error-
prone. Suppose that per speciﬁcation, the 5th byte of the ﬁle
contains the format version number. Now the detector must
keep track of valid version numbers for each format, and so
on. The notion of validity varies dramatically from ﬁle to
ﬁle, with different parts of the header and content used for
this purpose in different formats. This makes normalization
infeasible for all but the simplest formats.
B. Do not parse ﬁles in the detector
An alternative to parsing is to submit each ﬁle to a
lets it be parsed by the actual
virtual environment that
application or loaded by the guest OS, then tries to detect
malware from outside the OS (e.g., using virtual-machine
introspection [13]). This approach defeats chameleon and
werewolf attacks only if all of the following hold: (1) the
guest OS and applications are exact replicas of the protected
endhost; (2) if there are multiple endhost conﬁgurations
(e.g., if different hosts may use different applications or
versions of the same application to access a given ﬁle),
every conﬁguration is replicated exactly; (3) the analysis
environment exactly replicates human behavior, including
user responses to “repair corrupted ﬁle?” messages; and
(4) the environment is not vulnerable to split-personality
evasion [8]. Production deployment of network- or cloud-
based malware detectors that satisfy all of these requirements
is a hard problem beyond the scope of this paper.
C. Defend in depth
Many attacks are detector-speciﬁc, thus applying mul-
tiple detectors to the same ﬁle—as advocated by Clou-
dAV [21]—may provide better protection, at a signiﬁcant
performance cost. Some of our attacks, however, evaded all
36 tested AV scanners. Furthermore, several non-interfering
attacks can be combined in a single ﬁle, enabling it to evade
multiple detectors.
IX. HOST-BASED DEFENSES AGAINST WEREWOLF
ATTACKS
One of the main purposes of network-based deployment
of malware detectors is to reduce the need for host-based
detection. Nevertheless, we discuss host-based defenses for
completeness. Host-based techniques—such as continuously
scanning the memory for signs of malicious behavior—are
effective because the detector operates during or after the ﬁle
has been processed and thus does not need to independently
replicate the results of ﬁle processing. Therefore, host-based
detectors are better equipped to deal with chameleon and
werewolf attacks. In practice, however, many are vulnerable
to the same attacks as their network-based versions.
A. On-access scanning
A typical on-access scanner intercepts ﬁle-open, ﬁle-close,
and ﬁle-execute system calls and scans their targets for
infection. On-access scanners are effective against werewolf
attacks on archive formats only because they do not need
to parse archives. After the user has extracted the contents,
she will try to open and/or execute them. At this point, the
scanner intercepts the open/execute system call and detects
the virus before any harm is done. This is a special case
where the results of parsing (i.e., the extracted ﬁles) are
stored in the ﬁle system and thus accessible to the scanner.
Unfortunately, as we show in this paper, werewolf attacks
affect not only archive formats, but also ELF, PE, and
MS Ofﬁce (among others). For these formats, existing on-
access scanners do not have access to the internal data
91
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:44 UTC from IEEE Xplore.  Restrictions apply. 
representation after the OS or application has parsed the
ﬁle and must rely on their own parsing, opening the door
to werewolf attacks. For example, on-access scanning in
ClamAV uses a Linux kernel module called Dazuko that
scans the target ﬁles of open, close, and exec system calls. In
our experiments, ClamAV successfully detected an infected
ﬁle unpacked from a malformed archive into the monitored
directory, but failed to detect an infected Word ﬁle with an
empty VBA project name (see Section VI-B) even when
opened by OpenOfﬁce from the same directory.
B. Tight integration with applications
When running on the host, a malware detector can beneﬁt
from tighter integration with the ﬁle-processing logic of the
OS and applications. One plausible approach is for the OS
and application implementors to refactor their code so that
the detector can be invoked in the middle of ﬁle processing
and given access to the results of parsing. Unfortunately, this
approach is insecure against malware that exploits vulnera-
bilities in the parsing code itself. For example, a detector that
waits until the JPEG library has parsed a JPEG ﬁle before
checking that the ﬁle is safe cannot protect the library from
malicious JPEGs that use bugs to take it over, defeating the
purpose of malware detection. Furthermore, tight integration
between applications and external functionality which is
not integral to the their operation adds complexity and is
contrary to the principles of modular system design.
Figure 4. Application refactoring to mitigate werewolf and chameleon
attacks on host- and cloud-based malware scanners.
Privilege separation can help solve this “chicken and egg”
dilemma if the application is refactored so that the parsing
code runs at lower privilege than the rest of the application.
The parser can invoke a host- or even cloud-based malware
detector and send the results of parsing for scanning, as
shown in Fig. 4. After the detector declares them clean, they
are passed on to the rest of the application. This architecture
avoids the need to replicate application-speciﬁc parsing in
the detector. Even if malware exploits a vulnerability in the
parser, it will only gain the ability to perform low-privilege
operations that the parser is allowed to perform.
Implementing this architecture requires that the antivirus
vendors support a standardized interface through which ap-
plications can submit parsed data for analysis. Some existing
archiving applications such as WinRAR and WinZip support
invocation of command-line antivirus scanners, but this func-
tionality is not yet available in non-archiving applications.
Another approach is for the application and the detector
to use the same parsing code, e.g., by employing the same
parsing library. For instance, multiple-streams and random-
garbage attacks do not work against ClamAV because
ClamAV uses the libz library for parsing GZIP ﬁles.
The origins of libz are similar to gzip, thus ClamAV
effectively uses the same parsing code as the application.
This approach suffers from most of the ﬂaws outlined
in Section VIII-A—the detector must know exactly which
parsing code is used by the application and must be updated
whenever the application’s parsing logic changes—but these
ﬂaws may be easier to mitigate in a host-based deployment.
X. CONCLUSION
We presented two classes of practical attacks against au-
tomated malware detectors. They enable even unobfuscated,
easily recognizable malware to evade detection by placing
it in specially crafted ﬁles that are processed differently by
the detector and the endhost. All 36 antivirus scanners in
our experimental testing proved vulnerable to these attacks,
yielding a total of 45 different exploits, almost all of which
are reported here for the ﬁrst time. The rest have been known
only anecdotally and never been systematically analyzed.
We argue that semantic gaps in ﬁle processing are a funda-
mental ﬂaw of network- and cloud-based malware detectors,
regardless of the actual detection technique they use. As
long as the detector analyzes ﬁles on its own, independently
of the actual operating systems and applications on the
endhosts, it faces the insurmountable challenge of correctly
replicating their ﬁle-processing logic on every possible input.
Development of malware detectors that do not suffer from
this gap—for example,
if they operate on exact virtual
copies of protected systems that process each ﬁle using the
actual applications and faithfully emulate human response,
or if they are integrated with the parsing logic of actual
applications—is an interesting topic for future research.
Acknowledgments. The research described in this paper
was partially supported by the NSF grants CNS-0746888
and CNS-0905602, Google research award, and the MURI
program under AFOSR Grant No. FA9550-08-1-0352.
REFERENCES
[1] S. Alvarez.
Antivirus
http:
//events.ccc.de/camp/2007/Fahrplan/attachments/1324-
AntivirusInSecuritySergioshadownAlvarez.pdf, 2007.
insecurity.
[2] S. Alvarez and T. Zoller.
The death of AV de-
fense in depth? - revisiting anti-virus software. http:
//cansecwest.com/csw08/csw08-alvarez.pdf, 2008.
[3] avast! Anti-virus engine malformed ZIP/CAB archive
virus detection bypass. http://secunia.com/advisories/
17126/, 2005.
92
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:44 UTC from IEEE Xplore.  Restrictions apply. 
[4] A. Barth, J. Caballero, and D. Song. Secure content
snifﬁng for web browsers, or how to stop papers from
reviewing themselves. In S&P, 2009.
[5] D. Bates, A. Barth, and C. Jackson. Regular expres-
sions considered harmful in client-side XSS ﬁlters. In
WWW, 2010.
[6] D. Brumley, J. Caballero, Z. Liang, J. Newsome, and
D. Song. Towards automatic discovery of deviations in
binary implementations with applications to error de-
tection and ﬁngerprint generation. In USENIX Security,
2007.
[7] C. Cadar, D. Dunbar, and D. Engler. KLEE: Unassisted
and automatic generation of high-coverage tests for
complex systems programs. In OSDI, 2008.
[8] X. Chen, J. Andersen, Z. Mao, M. Bailey, and
J. Nazario.
Towards an understanding of anti-
virtualization and anti-debugging behavior in modern
malware. In DSN, 2008.
[9] ClamAV. http://www.clamav.net.
[10] http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=
evasion, 2012.
[11] EICAR — The Anti-Virus or Anti-Malware Test File.
http://www.eicar.org/anti virus test ﬁle.htm.
[12] T. Garﬁnkel. Traps and pitfalls: Practical problems in
system call interposition based security tools. In NDSS,
2003.
[13] T. Garﬁnkel and M. Rosenblum. A virtual machine
introspection based architecture for intrusion detection.
In NDSS, 2003.
[14] M. Gavin.
PDF ﬁles.
recognizing malformed pdf f.pdf.
Recognizing corrupt and malformed
http://labs.appligent.com/presentations/
[15] P. Hooimeijer, B. Livshits, D. Molnar, P. Saxena, and
M. Veanes. Fast and precise sanitizer analysis with
BEK. In USENIX Security, 2011.
[16] M. Hypponen.
Retroviruses - how viruses ﬁght
back. http://www.hypponen.com/staff/hermanni/more/
papers/retro.htm, 1994.
[17] G. Kessler.
File signatures table.
http://www.
garykessler.net/library/ﬁle sigs.html, 2012.
[18] McAfee VirusScan vulnerability. http://www.pc1news.
com/news/0665/mcafeevirusscanvulnerability-allow-
compressed-archives-to-bypass-the-scan-engine.html,
2009.
[19] J. Nazario.
Mime
snifﬁng
and
phishing.
http://http://asert.arbornetworks.com/2009/03/mime-
snifﬁng-and-phishing/, 2009.
[20] J. Oberheide, M. Bailey, and F. Jahanian. PolyPack: An
automated online packing service for optimal antivirus
evasion. In WOOT, 2009.
[21] J. Oberheide, E. Cooke, and F. Jahanian. CloudAV:
N-version antivirus in the network cloud. In USENIX
Security, 2008.
[22] J. Oberheide and F. Jahanian. Remote ﬁngerprinting
and exploitation of mail server antivirus engines. http:
//jon.oberheide.org/ﬁles/umich09-mailav.pdf, 2009.
[23] Microsoft patch breaks Impress/PowerPoint compat-
http://user.services.openofﬁce.org/en/forum/
ibility.
viewtopic.php?t=36515, 2010.
[24] OpenOfﬁce-MS
interoperability
bugs.
http:
//openofﬁce.org/bugzilla/buglist.cgi?keywords=ms
interoperability, 2011.
[25] W. Palant. The hazards of MIME snifﬁng.
http:
//adblockplus.org/blog/the-hazards-of-mime-snifﬁng,
2007.
[26] S. Porst. How to really obfuscate your PDF mal-
http://www.recon.cx/2010/slides/recon 2010
ware.