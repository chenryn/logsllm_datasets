## 集群的复杂度 {#05.html#-}虽然计算机硬件的性能快速发展，但和业务的发展速度相比，还是小巫见大巫了，尤其是进入互联网时代后，业务的发展速度远远超过了硬件的发展速度。例如：-   2016 年"双 11"支付宝每秒峰值达 12 万笔支付。-   2017 年春节微信红包收发红包每秒达到 76 万个。要支持支付和红包这种复杂的业务，单机的性能无论如何是无法支撑的，必须采用机器集群的方式来达到高性能。例如，支付宝和微信这种规模的业务系统，后台系统的机器数量都是万台级别的。通过大量机器来提升性能，并不仅仅是增加机器这么简单，让多台机器配合起来达到高性能的目的，是一个复杂的任务，我针对常见的几种方式简单分析一下。1\. 任务分配任务分配的意思是指每台机器都可以处理完整的业务任务，不同的任务分配到不同的机器上执行。我从最简单的一台服务器变两台服务器开始，来讲任务分配带来的复杂性，整体架构示意图如下。![](Images/680b7a1489853d3faf9d6d29ae8c6f33.png){savepage-src="https://static001.geekbang.org/resource/image/b8/60/b83913fb5a0358fec1be9b0af6ce4c60.png"}从图中可以看到，1 台服务器演变为 2台服务器后，架构上明显要复杂多了，主要体现在：-   需要增加一个任务分配器，这个分配器可能是硬件网络设备（例如，F5、交换机等），可能是软件网络设备（例如，LVS），也可能是负载均衡软件（例如，Nginx、HAProxy），还可能是自己开发的系统。选择合适的任务分配器也是一件复杂的事情，需要综合考虑性能、成本、可维护性、可用性等各方面的因素。-   任务分配器和真正的业务服务器之间有连接和交互（即图中任务分配器到业务服务器的连接线），需要选择合适的连接方式，并且对连接进行管理。例如，连接建立、连接检测、连接中断后如何处理等。-   任务分配器需要增加分配算法。例如，是采用轮询算法，还是按权重分配，又或者按照负载进行分配。如果按照服务器的负载进行分配，则业务服务器还要能够上报自己的状态给任务分配器。这一大段描述，即使你可能还看不懂，但也应该感受到其中的复杂度了，更何况还要真正去实践和实现。上面这个架构只是最简单地增加 1台业务机器，我们假设单台业务服务器每秒能够处理 5000次业务请求，那么这个架构理论上能够支撑 10000次请求，实际上的性能一般按照 8 折计算，大约是 8000 次左右。如果我们的性能要求继续提高，假设要求每秒提升到 10万次，上面这个架构会出现什么问题呢？是不是将业务服务器增加到 25台就可以了呢？显然不是，因为随着性能的增加，任务分配器本身又会成为性能瓶颈，当业务请求达到每秒10万次的时候，单台任务分配器也不够用了，任务分配器本身也需要扩展为多台机器，这时的架构又会演变成这个样子。![](Images/4b92024a9d4ff66f6bd7a94b04c0d9f1.png){savepage-src="https://static001.geekbang.org/resource/image/67/a1/67bfe499137fcb81c639be1a859c98a1.png"}这个架构比 2 台业务服务器的架构要复杂，主要体现在：-   任务分配器从 1 台变成了多台（对应图中的任务分配器 1 到任务分配器    M），这个变化带来的复杂度就是需要将不同的用户分配到不同的任务分配器上（即图中的虚线"用户分配"部分），常见的方法包括    DNS 轮询、智能 DNS、CDN（Content Delivery    Network，内容分发网络）、GSLB 设备（Global Server Load    Balance，全局负载均衡）等。-   任务分配器和业务服务器的连接从简单的"1 对多"（1    台任务分配器连接多台业务服务器）变成了"多对多"（多台任务分配器连接多台业务服务器）的网状结构。-   机器数量从 3 台扩展到 30    台（一般任务分配器数量比业务服务器要少，这里我们假设业务服务器为 25    台，任务分配器为 5 台），状态管理、故障处理复杂度也大大增加。上面这两个例子都是以业务处理为例，实际上"任务"涵盖的范围很广，**可以指完整的业务处理，也可以单指某个具体的任务**。例如，"存储""运算""缓存"等都可以作为一项任务，因此存储系统、运算系统、缓存系统都可以按照任务分配的方式来搭建架构。此外，"任务分配器"也并不一定只能是物理上存在的机器或者一个独立运行的程序，也可以是嵌入在其他程序中的算法，例如Memcache 的集群架构。﻿![](Images/19179e322dff2c53c2fd4daa5146412d.png){savepage-src="https://static001.geekbang.org/resource/image/cb/57/cb0cd439d0af7e74ab0921022bb60b57.png"}（[http://my.oschina.net/uploads/space/2010/1015/163250_g2tS_98095.png）](http://my.oschina.net/uploads/space/2010/1015/163250_g2tS_98095.png）)2\. 任务分解通过任务分配的方式，我们能够突破单台机器处理性能的瓶颈，通过增加更多的机器来满足业务的性能需求，但如果业务本身也越来越复杂，单纯只通过任务分配的方式来扩展性能，收益会越来越低。例如，业务简单的时候1 台机器扩展到 10 台机器，性能能够提升 8倍（需要扣除机器群带来的部分性能损耗，因此无法达到理论上的 10倍那么高），但如果业务越来越复杂，1 台机器扩展到 10 台，性能可能只能提升5倍。造成这种现象的主要原因是业务越来越复杂，单台机器处理的性能会越来越低。为了能够继续提升性能，我们需要采取第二种方式：**任务分解**。继续以上面"任务分配"中的架构为例，"业务服务器"如果越来越复杂，我们可以将其拆分为更多的组成部分，我以微信的后台架构为例。![](Images/3affe6b979c052daf49295846b32020e.png){savepage-src="https://static001.geekbang.org/resource/image/fd/fc/fd36126477cdd76cfbc58367784aeffc.png"}（[http://image.jiagoushuo.com/2016/qAnayi.jpg）](http://image.jiagoushuo.com/2016/qAnayi.jpg）)通过上面的架构示意图可以看出，微信后台架构从逻辑上将各个子业务进行了拆分，包括：接入、注册登录、消息、LBS、摇一摇、漂流瓶、其他业务（聊天、视频、朋友圈等）。通过这种任务分解的方式，能够把原来大一统但复杂的业务系统，拆分成小而简单但需要多个系统配合的业务系统。从业务的角度来看，任务分解既不会减少功能，也不会减少代码量（事实上代码量可能还会增加，因为从代码内部调用改为通过服务器之间的接口调用），那为何通过任务分解就能够提升性能呢？主要有几方面的因素：-   **简单的系统更加容易做到高性能**系统的功能越简单，影响性能的点就越少，就更加容易进行有针对性的优化。而系统很复杂的情况下，首先是比较难以找到关键性能点，因为需要考虑和验证的点太多；其次是即使花费很大力气找到了，修改起来也不容易，因为可能将A 关键性能点提升了，但却无意中将 B点的性能降低了，整个系统的性能不但没有提升，还有可能会下降。-   **可以针对单个任务进行扩展**当各个逻辑任务分解到独立的子系统后，整个系统的性能瓶颈更加容易发现，而且发现后只需要针对有瓶颈的子系统进行性能优化或者提升，不需要改动整个系统，风险会小很多。以微信的后台架构为例，如果用户数增长太快，注册登录子系统性能出现瓶颈的时候，只需要优化登录注册子系统的性能（可以是代码优化，也可以简单粗暴地加机器），消息逻辑、LBS逻辑等其他子系统完全不需要改动。既然将一个大一统的系统分解为多个子系统能够提升性能，那是不是划分得越细越好呢？例如，上面的微信后台目前是7 个逻辑子系统，如果我们把这 7 个逻辑子系统再细分，划分为 100个逻辑子系统，性能是不是会更高呢？其实不然，这样做性能不仅不会提升，反而还会下降，最主要的原因是如果系统拆分得太细，为了完成某个业务，系统间的调用次数会呈指数级别上升，而系统间的调用通道目前都是通过网络传输的方式，性能远比系统内的函数调用要低得多。我以一个简单的图示来说明。![](Images/1f3c77f279d8f19c33ab0d9963435388.png){savepage-src="https://static001.geekbang.org/resource/image/d4/7f/d4faecc3da871c274269e3f9b13a737f.png"}从图中可以看到，当系统拆分 2 个子系统的时候，用户访问需要 1次系统间的请求和 1 次响应；当系统拆分为 4个子系统的时候，系统间的请求次数从 1 次增长到 3 次；假如继续拆分下去为100 个子系统，为了完成某次用户访问，系统间的请求次数变成了 99 次。为了描述简单，我抽象出来一个最简单的模型：假设这些系统采用 IP网络连接，理想情况下一次请求和响应在网络上耗费为 1ms，业务处理本身耗时为50ms。我们也假设系统拆分对单个业务请求性能没有影响，那么系统拆分为 2个子系统的时候，处理一次用户访问耗时为 51ms；而系统拆分为 100个子系统的时候，处理一次用户访问耗时竟然达到了 149ms。虽然系统拆分可能在某种程度上能提升业务处理性能，但提升性能也是有限的，不可能系统不拆分的时候业务处理耗时为50ms，系统拆分后业务处理耗时只要1ms，因为最终决定业务处理性能的还是业务逻辑本身，业务逻辑本身没有发生大的变化下，理论上的性能是有一个上限的，系统拆分能够让性能逼近这个极限，但无法突破这个极限。因此，任务分解带来的性能收益是有一个度的，并不是任务分解越细越好，而对于架构设计来说，如何把握这个粒度就非常关键了。
## 小结 {#05.html#-}今天我给你讲了软件系统中高性能带来的复杂度主要体现的两方面，一是单台计算机内部为了高性能带来的复杂度；二是是多台计算机集群为了高性能带来的复杂度，希望对你有所帮助。这就是今天的全部内容，留一道思考题给你吧。你所在的业务体系中，高性能的系统采用的是哪种方式？目前是否有改进和提升的空间？欢迎你把答案写到留言区，和我一起讨论。相信经过深度思考的回答，也会让你对知识的理解更加深刻。（编辑乱入：精彩的留言有机会获得丰厚福利哦！）![](Images/f2eae62fce5bba3ca5ee38d11da01862.png){savepage-src="https://static001.geekbang.org/resource/image/ba/37/ba6fcd186893b8cc9977d18e1fa5ab37.jpg"}
# 05 \| 复杂度来源：高可用今天，我们聊聊复杂度的第二个来源[高可用]{.orange}。参考维基百科，先来看看高可用的定义。> 系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。这个定义的关键在于"**无中断**"，但恰好难点也在"无中断"上面，因为无论是单个硬件还是单个软件，都不可能做到无中断，硬件会出故障，软件会有bug；硬件会逐渐老化，软件会越来越复杂和庞大......除了硬件和软件本质上无法做到"无中断"，外部环境导致的不可用更加不可避免、不受控制。例如，断电、水灾、地震，这些事故或者灾难也会导致系统不可用，而且影响程度更加严重，更加难以预测和规避。所以，系统的高可用方案五花八门，但万变不离其宗，本质上都是通过"**冗余**"来实现高可用。通俗点来讲，就是一台机器不够就两台，两台不够就四台；一个机房可能断电，那就部署两个机房；一条通道可能故障，那就用两条，两条不够那就用三条（移动、电信、联通一起上）。高可用的"冗余"解决方案，单纯从形式上来看，和之前讲的高性能是一样的，都是通过增加更多机器来达到目的，但其实本质上是有根本区别的：**高性能增加机器目的在于"扩展"处理性能；高可用增加机器目的在于"冗余"处理单元**。通过冗余增强了可用性，但同时也带来了复杂性，我会根据不同的应用场景逐一分析。
## 计算高可用 {#06.html#-}这里的"计算"指的是业务的逻辑处理。计算有一个特点就是**无论在哪台机器上进行计算，同样的算法和输入数据，产出的结果都是一样的**，所以将计算从一台机器迁移到另外一台机器，对业务并没有什么影响。既然如此，计算高可用的复杂度体现在哪里呢？我以最简单的单机变双机为例进行分析。先来看一个单机变双机的简单架构示意图。``{=html}![](Images/54d19d0bf335ae597b50031b780facd5.png){savepage-src="https://static001.geekbang.org/resource/image/77/b4/7793f8ae6230fbfaa2827086a9ead4b4.png"}你可能会发现，这个双机的架构图和上期"高性能"讲到的双机架构图是一样的，因此复杂度也是类似的，具体表现为：-   需要增加一个任务分配器，选择合适的任务分配器也是一件复杂的事情，需要综合考虑性能、成本、可维护性、可用性等各方面因素。-   任务分配器和真正的业务服务器之间有连接和交互，需要选择合适的连接方式，并且对连接进行管理。例如，连接建立、连接检测、连接中断后如何处理等。-   任务分配器需要增加分配算法。例如，常见的双机算法有主备、主主，主备方案又可以细分为冷备、温备、热备。上面这个示意图只是简单的双机架构，我们再看一个复杂一点的高可用集群架构。![](Images/ed83872bbf41fc7f78506caa623596ec.png){savepage-src="https://static001.geekbang.org/resource/image/f4/b7/f4c0ae8e1b5dfbc8e58baa8b31dfeab7.png"}这个高可用集群相比双机来说，分配算法更加复杂，可以是 1 主 3 备、2 主 2备、3 主 1 备、4 主 0备，具体应该采用哪种方式，需要结合实际业务需求来分析和判断，并不存在某种算法就一定优于另外的算法。例如，ZooKeeper采用的就是 1 主多备，而 Memcached 采用的就是全主 0 备。
## 存储高可用 {#06.html#-}对于需要存储数据的系统来说，整个系统的高可用设计关键点和难点就在于"存储高可用"。存储与计算相比，有一个本质上的区别：**将数据从一台机器搬到到另一台机器，需要经过线路进行传输**。线路传输的速度是毫秒级别，同一机房内部能够做到几毫秒；分布在不同地方的机房，传输耗时需要几十甚至上百毫秒。例如，从广州机房到北京机房，稳定情况下ping 延时大约是 50ms，不稳定情况下可能达到 1s 甚至更多。虽然毫秒对于人来说几乎没有什么感觉，但是对于高可用系统来说，就是本质上的不同，这意味着整个系统在某个时间点上，数据肯定是不一致的。按照"**数据 +逻辑 =业务**"这个公式来套的话，数据不一致，即使逻辑一致，最后的业务表现就不一样了。以最经典的银行储蓄业务为例，假设用户的数据存在北京机房，用户存入了1万块钱，然后他查询的时候被路由到了上海机房，北京机房的数据没有同步到上海机房，用户会发现他的余额并没有增加1万块。想象一下，此时用户肯定会背后一凉，马上会怀疑自己的钱被盗了，然后赶紧打客服电话投诉，甚至打110报警，即使最后发现只是因为传输延迟导致的问题，站在用户的角度来说，这个过程的体验肯定很不好。![](Images/0f512e16c4826f389ce68421934de200.png){savepage-src="https://static001.geekbang.org/resource/image/66/e9/66f73e0760339746b06d2ab8670266e9.png"}除了物理上的传输速度限制，传输线路本身也存在可用性问题，传输线路可能中断、可能拥塞、可能异常（错包、丢包），并且传输线路的故障时间一般都特别长，短的十几分钟，长的几个小时都是可能的。例如，2015年支付宝因为光缆被挖断，业务影响超过 4 个小时；2016 年中美海底光缆中断 3小时等。在传输线路中断的情况下，就意味着存储无法进行同步，在这段时间内整个系统的数据是不一致的。综合分析，无论是正常情况下的传输延迟，还是异常情况下的传输中断，都会导致系统的数据在某个时间点或者时间段是不一致的，而数据的不一致又会导致业务问题；但如果完全不做冗余，系统的整体高可用又无法保证，所以**存储高可用的难点不在于如何备份数据，而在于如何减少或者规避数据不一致对业务造成的影响**。分布式领域里面有一个著名的 CAP定理，从理论上论证了存储高可用的复杂度。也就是说，存储高可用不可能同时满足"一致性、可用性、分区容错性"，最多满足其中两个，这就要求我们在做架构设计时结合业务进行取舍。