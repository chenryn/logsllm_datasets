superposition of the three classes weighted by their relative probability of appearance.
All three classes are well visible in the total CDF even though it is dominated by rejected
ﬂows due to the fact that around 80% of all ﬂows are rejected.
Next, we determined two optimal threshold sizes to differentiate between rejected,
failed and accepted ﬂows. For this purpose, we constructed ROC curves [17] which
plot the true positive versus the false positive rate of a detector for a range of thresholds.
Fig. 4 shows the ROC curves for the detection of rejected vs. failed and accepted vs.
rejected ﬂows. The three classes are distinguishable with high precision. We selected
the two thresholds 332 Bytes (rejected vs. failed) and 1559 Bytes because these points
are closest to the top left corner and hence yield the best detection quality [17].
We evaluated the false positive rate of these threshold detectors on data of another
week (week 2) and present the results in Table 1. The false detection rate is below 4.5%
for all classes which is sufﬁciently accurate for the applications outlined in Section 42.
We also analyzed the power of other ﬂow properties to discriminate between the three
classes. In addition to bytes per ﬂow, also packets per ﬂow and average bytes per packet
are well suited for this purpose [18].
2 The ﬂow labels assigned by our system are to be treated mostly as “soft” labels. Further accu-
racy could be achieved by using e.g. clustering algorithms on additional ﬂow ﬁelds.
Inferring Spammers in the Network Core
233
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
332 1559
Blacklisted traffic
Whitelisted traffic
All traffic
 0
 2000
 4000
 6000
 8000
 10000
Bytes
107
r
u
o
h
r
e
p
s
w
o
F
l
106
105
104
Connection failed
Rejected
Accepted
09/09/08
00:00
09/11/08
00:00
Time
09/13/08
00:00
09/15/08
00:00
s
w
o
l
f
f
o
F
D
C
Fig. 5. Network-wide ﬂow sizes
Fig. 6. Network-wide pre-ﬁltering statistics
It is important to note that packet sampling would affect our approach. Over 90%
of the rejected SMTP sessions consist of 10 or less packets and more than 90% of
accepted sessions have less than 40 packets. With a sampling rate of 1:100 or even
1:1000, the resulting ﬂows would mostly consist of 1 or 2 packets. This would weaken
the usefulness of the bytes and packets per ﬂow metrics; yet, our analysis suggests that it
could still be possible to distinguish between rejected and accepted ﬂows using average
bytes per packet [18]. Further, adaptive sampling techniques are being developed [19]
that could perhaps address this problem also. We intend to look further into the issue of
sampling in future work.
Network-wide characteristics. The classiﬁcation of ﬂows based on their size allows to
passively monitor pre-ﬁltering activity in large networks in a scalable manner, without
resorting to server logs. To validate that the observed characteristics also hold on a
network-wide scale, we show the characteristics of black- and whitelisted trafﬁc for the
50 most active mail servers in our network in Fig. 5. The shape of black-/whitelisted
curves nicely reﬂects the characteristics of rejected and accepted ﬂows from Fig. 3.
Hence, (i) the vast majority of trafﬁc from blacklisted hosts is rejected by our network
in pre-ﬁltering and (ii) we are able to infer this reject decisions from ﬂows sizes only.
Individual server performance differences are addressed in detail in Section 4.1.
The generation of network-wide pre-ﬁltering statistics, as illustrated in Fig. 6, allows
to easily estimate the amount and track the dynamics of incoming spam at the ISP level.
An ISP is now able to investigate the root cause of anomalies in rejected/accepted trafﬁc.
Potential causes are global spam campaigns that are visible on many servers, spamming
attacks targeted to a small set of servers or misconﬁguration and performance problems
of single servers.
4 Applications
We now turn our attention to potential applications of our method. In Section 4.1, we
demonstrate how it can be used to passively analyze the conﬁguration of mail servers
and troubleshoot misconﬁgured servers. We then explore the feasibility and potential of
a collaborative ﬁltering system among the various mail servers in Section 4.2.
234
D. Schatzmann, M. Burkhart, and T. Spyropoulos
4.1 Email Server Behavior
Today, adequate conﬁguration and maintenance of mail servers is a time-consuming
process. It would be very helpful for operators to get a performance map of the various
mail servers present in the network. The state of pre-ﬁltering deployment in the network
could be checked regularly and potential conﬁguration problems, (e.g., the presence of
open relay servers), could be addressed proactively.
To compare the pre-ﬁltering performance of internal servers, we deﬁne the accep-
tance ratio of a server to be the number of accepted SMTP ﬂows divided by the number
of total SMTP ﬂows seen by the server. A high ratio of, for example, 0.9 indicates that
90% of all incoming SMTP sessions are accepted, whereas a low ratio indicates that
most of the connections are rejected during the TCP handshake or the SMTP envelope.
Clearly, the observed acceptance ratio for a server is affected by two parameters: (i) the
trafﬁc mix of ham and spam for this server, and (ii) the server preﬁltering policy. To
address the former, we estimated the spam/ham mix ratio for each server with the help
of the XBL blacklist from Spamhaus. Our analysis shows that spam (ﬂows from black-
listed sources) is evenly distributed among servers. 81% of the servers have a spam load
between 70% and 90%, consistent with [1]. This results implies that big differences in
servers’ acceptance ratios cannot be attributed to different trafﬁc mixes.
The server policy issue is somewhat trickier. The above numbers imply that, if all
servers were at least using a blacklist, the acceptance ratio of most internal servers
should be between 0.1 and 0.3, with differences attributed to trafﬁc mix and sophistica-
tion and/or aggressiveness of pre-ﬁltering policies (e.g., greylisting, etc.). Instead, the
acceptance ratios of the top 200 servers for week 3 of our data set range from 0.003
up to 0.93 with a mean of 0.33 as can bee seen in Fig. 7. 35% of the servers have an
acceptance ratio > 0.30. Based on the above trafﬁc mix estimation, we conclude that
they are accepting a lot of trafﬁc from spam sources. This could imply: (i) a regular
server that is sub-optimally conﬁgured, lacks sophisticated or even simple pre-ﬁltering
measures (e.g., lack of time, caring, or knowhow), and/or should at least raise an eye-
brow; or (ii) a server whose intended policy is to accept all messages (e.g., servers that
apply content-based ﬁltering only, honeypots, etc.)
To verify this assumption, we sent emails to all servers from two different IP ad-
dresses: an address blacklisted by Spamhaus and Spamcop and an ordinary, not black-
listed address3. The reaction of the servers to our sending attempts clariﬁed whether the
server was using greylisting and/or blacklisting. The servers classiﬁed as ’unknown’
are those servers for which the reaction was not conclusive. The high concentration of
black- and greylisting servers below the average ratio shows that, indeed, these servers
implement basic pre-ﬁltering techniques, whereas servers that do not implement them
lie mostly above average. Also, with increasing volume (to the right), servers with high
acceptance ratios tend to disappear. This afﬁrms that administrators of high-volume
servers (have to) rely on aggressive pre-ﬁltering to master the ﬂood of incoming mails.
We also manually checked high acceptance servers and found no honeypots trying to
deliberately attract and collect spam.
3 It is important to stress that this, and other “manual” investigations we performed in this section
are only done for validation purposes, and are not part of the proposed system.
Inferring Spammers in the Network Core
235
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
o
i
t
a
r
e
c
n
a
t
p
e
c
c
A
Unknown configuration
Blacklisting
Greylisting
Black- and greylisting
r
e
d
n
e
s
l
i
a
m
e
f
o
e
g
a
t
n
e
c
r
e
P
 0
 1000
 10000
 100000
 1e+06
 1e+07
 1e+08
Received flows
 100
 90
 80
 70
 60
 50