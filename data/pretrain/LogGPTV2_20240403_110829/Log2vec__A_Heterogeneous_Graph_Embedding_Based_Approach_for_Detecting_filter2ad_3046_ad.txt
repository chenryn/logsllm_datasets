other neighbor node given a log entry and then Pr(wv−c ,· · · , wv +c|wv)
can be computed as 
Further, Pr(wv +j|wv) is defined using the softmax function:
Pr(wv +j|wv)
−c ≤j ≤c, j(cid:44)0
V
wv V ′
exp(V ⊤
i =1 exp(V ⊤
wv +j)
wv V ′
wi)
(3)
(4)
where Vwi and V ′
wi are respectively the input and output vectors
of log entry wi. |V | in general is very large and the algorithm of
Hierarchical softmax, using a binary tree to factorize expensive
partition function of the skip-gram model [33, 60], is adopted here
to efficiently approximate the function 4. After this model, vectors
of log entries are obtained.
5 DETECTION ALGORITHM
Section 5.1 details a clustering algorithm. Section 5.2 introduces a
threshold detector. Section 5.3 demonstrates how to select parame-
ters in the detection algorithm.
5.1 Clustering Algorithm
This subsection is to group benign and malicious log entries into
different clusters. Nevertheless, the conventional idea of updating
cluster centers, such as k-means, is not fit for insider threat detection
because it heavily relies on the initialization of cluster centers and
k, leading to unsatisfactory performance.
We adopt an alternative method, adept at log entries’ pair-wise
similarity comparison. Formally, we suppose clusters(C1, C2, ..., Cn)
have been obtained and they must satisfy the following conditions:
∀x1 ∈ C1, ∃x2 ∈ C1, sim(x1, x2) ≥ δ1;
∀y ∈ V\C1, sim(x1, y) < δ1;
where V is a set including all log entries and δ1 is a threshold.
Note that C1 is chosen arbitrarily and sim is employed to measure
similarity between log entries using cosine distance (two log entries
become similar when their sim is 0 → 1). Its pseudocode is given
in Appendix E.
Session 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom17845.2 Threshold Detector
After clustering, log2vec ranks clusters according to the number
of log entries they contain. Smaller clusters tend to be suspicious.
Table 1 and Table 2 demonstrate two examples of the clustering
algorithm’s output. In Table 1, the smallest cluster is larger than
a threshold, δ2 (e.g. 80) and thereby identified as legitimate oper-
ations. Table 2 shows several small clusters (< 80), indicative of
insider threat. Therefore, log entries in these clusters are detected
as malicious.
5.3 Parameters Selection
There exist two thresholds, δ1 and δ2, to be selected. The conven-
tional methods, e.g. silhouette score [43], cannot work well in our
scenarios, because they measure the whole clustering effect, paying
equivalent attention to each cluster. We instead propose a more
appropriate approach, focusing on smaller clusters:
1) δ2 is the number of logs involved in the largest suspicious
cluster, produced by log2vec. Owing to diverse attack scenarios, it
is varied. We set δ2 = pro * total, where total is the number of logs
to be detected and pro is the proportion of malicious log entries to
the total. We consider one situation that all malicious log entries are
likely to be grouped into one cluster. Therefore, δ2 should be equal
to its number, pro * total, and log2vec then detects this cluster as
malicious. Analysts can set pro according to the existing work and
specific scenarios [17, 34, 46, 57]. In our experiment, we set pro to
1% in all datasets and hence δ2 is 1% * total.
2) In another common situation, malicious log entries are dis-
tributed in various clusters. In general, a perpetrator performs
several different operations for an attack, e.g. logging into a host
(logon) and stealing a file (file copy). According to user’s operation
type (e.g. logon and file operation), we set the number of malicious
clusters (nmal), to nbp * nt, where nt is the number of operation
type. nbp reflects the number of suspicious behavioral patterns on
each operation type. In log2vec, different behavioral patterns are
grouped into various clusters. nbp * nt thereby constitutes the num-
ber of malicious clusters, nmal. In practice, we select nbp according
to the attribute information regarding each operation type. For
instance, an email operation could involve attributes, such as send
address, receive address, carbon copy, blind Carbon Copy, size and
attachments. Although a malicious email generally possesses one
or more anomalous attributes, we set nbp to the number of these
attributes for simplicity.
3) When δ1 is 0 → 1, the number of clusters tend to be larger
because two log entries in the same cluster must share a higher
similarity. We utilize the number of logs in the largest suspicious
cluster, δ2 and the number of malicious clusters, nmal to set δ1.
When δ1 is 0 → 1, a cluster splits into many smaller ones. We
choose the largest δ1 to simultaneously cover the following two
situations, allowing the number of log entries in clusters lower than
δ2 and the number of these clusters less than or equal to nmal.
We take Table 2 as an example, when δ1 is a value (e.g. 0.64), we
view clusters, the number of log entries in which is less than or
equal to δ2 (e.g. 80), as malicious. Meanwhile, the number of these
suspicious clusters is less than or equal to nmal (e.g. 6). Then δ1
is added by an interval (e.g. 0.01) and a new cluster containing 9
log entries is produced. Hence, the number of suspicious clusters
is greater than nmal, 6, beyond our setting. In other words, when
setting δ1 to 0.65, the suspicious clusters involve benign ones. We
thereby choose 0.64 as δ1.
Until now, log2vec has output malicious logs. Analysts can con-
duct manual forensics. Certainly, they can also utilize advanced
methods regarding forensics [17, 22, 55].
Table 1: log2vec’s out-
put for a benign user.
The smallest cluster is
larger than the thresh-
old (e.g. 80), implying
no anomalies.
cluster id
1
3
2
0
#log
162
177
177
7172
Table 2: log2vec’s output for a
malicious user. Several small
clusters < 80, indicative of in-
sider threat.
cluster id
6
5
4
1
2
3
0
#log
1
9
9
31
34
51
4744
6 EXPERIMENT
This section evaluates log2vec in different attack scenarios. Sec-
tion 6.1 introduces experimental setup. We compare baselines in
Section 6.2. Log2vec’s detection result is demonstrated in Section 6.3.
The parameter sensitivity is assessed in Section 6.4. Section 6.5 and
Section 6.6 respectively display the effectiveness of log2vec’s sets
of edge type and clustering algorithm over k-means.
6.1 Experimental Setup
We conduct this experiment on nine servers and each possesses
two Intel Xeon E5-2630 v3 CPUs (32 processors in total) running at
2.4GHz, 128G memory. We utilize spark-2.2.0 to implement com-
ponents of graph construction and random walk and python3.6 to
implement models of skip-gram and detection algorithm.
Dataset. We use a synthetic dataset, CERT Insider Threat Test
Dataset [10] and a real-world dataset, Los Alamos National Lab’s
(LANL’s) comprehensive cyber-security events dataset [21].
The CERT dataset is a comprehensive dataset with relatively
complete user behavioral records and attack scenarios. We use r6.2,
the newest version of this dataset. We utilize five files separately
recording logon operation, removable storage device usage, file
operation, network operation and email traffic, and another file
concerning all users’ roles and their affiliations. This dataset com-
prises 135,117,169 operations of 4,000 users during 516 days. There
are five attack scenarios where six users have 470 malicious opera-
tions, obviously an extremely imbalanced problem that is common
in insider threat detection. Five scenarios include various insider
threats, used to examine whether log2vec can determine impor-
tance of each set of edge type according to different scenarios, and
differentially extract and represent them.
The LANL dataset comprises over one billion log entries collected
over 58 days for 12425 users and 17684 computers, within LANL’s
corporate, internal computer network. It involves 749 malicious
logons with 98 compromised accounts, a typical APT. We utilize
two files separately regarding authentication and process to detect
Session 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom1785malicious operations. This dataset examines whether log2vec can
detect the attack scenario regarding APT mentioned in Section 2.3.
Both datasets are to prove log2vec’s powerful detection on users’
malicious operations and capability of covering various attacks.
Parameter settings. In CERT dataset, we detect the six malicious
users’ behavior during two months and take the last ones as the
last period used in random walk. The specific time is shown in
Table 5 in Appendix F. During the chosen two months, these users
acted 37,257 operations involving 428 malicious ones. Also, twelve
benign users, performing 71,334 operations, are randomly chosen
to examine FPRs. The organizational units in this enterprise are
business_unit, functional_unit, department, team and supervisor in
descending order of size and the first four units and role (e.g. Sales-
man, ITAdmin) are used to define a colleague used in random walk.
Due to no log entries regarding logons with authentications in this
dataset, we mainly utilize rule1∼rule6, rule9 and rule10 in Section 3
to construct graphs. In random walk, {edge3, edge6} and {edge9,
edge10} are taken into account to determine the proportion of sets
of edge type. According to policies in Appendix C, due to explicit
averages, changes of connect and network operation in quantity
separately correspond to these two sets. The specific proportions
for six malicious users, calculated by log2vec, are shown in column
ps in Table 6 in Appendix H.
The LANL dataset incorporates 98 malicious users and we ran-
domly choose 50 of them to examine log2vec’s effectiveness. This
detected dataset involves 701,643 log entries, which contains 495
malicious operations, 66.1% of the total. In addition, we randomly
choose 90 benign users, who performed 983,421 operations, to exam-
ine FPRs. As this dataset is mainly used to detecting APT and there
is no information regarding websites, log2vec utilizes rule1∼rule8
in Section 3 to construct graphs and fixes proportions of sets of
edge type for all users to 1:1:1:6 in random walk.
Other parameters for the two datasets are set as follows. In ran-
dom walk, we set walk length l = 60, number of walks per node
r = 10 and the number of neighbor nodes neiдh = 1. In skip-gram,
vector’s dimension d is 100 and window c is 10. In detection algo-
rithm, we set the threshold δ2 = pro∗total, where pro = 1%, total is
the number of log entries to be detected for each user. The number
of malicious clusters, nmal is nbp ∗ nt. The number of operation
type nt = 5 in CERT dataset and 2 in LANL dataset. We select nbp
according to the largest number of attributes regarding operation
type. In CERT dataset, email operation possesses the largest number,
6. In LANL dataset, logon operation owns 8 attributes. According
to δ2 and nmal, we obtain the similarity threshold δ1.
Baseline. We utilize eleven baseline methods for CERT dataset.
TIRESIAS and DeepLog are advanced log-entry-level approaches
on anomaly detection [12, 47]. Hidden markov models [41] (markov-
s and markov-c) and deep learning models [57] (DNN and LSTM)
are state-of-the-art on this dataset. STREAMSPOT is an advanced
approach to detect malicious information flows [31]. We employ
node2vec [14] and metapath2vec [11] to show the effect of log2vec’s
improvement in random walk, on processing heterogeneous graph.
Log2vec-euclidean and log2vec-cosine are used to show that log2vec’s
clustering is superior to k-means in solving this problem. In ad-
dition, we introduce a new version of log2vec, log2vec++, whose
parameters are flexibly set according to different users and attacks.
We use an ensemble detection method [4] and TIRESIAS for LANL
dataset to display the effectiveness of log2vec on APT. Their specific
parameters are detailed in Appendix G.
Table 3: Detection result of different approaches
Method (dataset)
log2vec (CERT)
TIRESIAS (CERT)
DNN (CERT)
markov-s (CERT)
metapath2vec (CERT)
log2vec-Euclidean
(CERT)
STREAMSPOT (CERT)
log2vec (LANL)
AUC Method (dataset)
log2vec++ (CERT)
0.86
DeepLog (CERT)
0.39
0.73
LSTM (CERT)
0.79
0.61
0.36
0.70
0.91
markov-c (CERT)
node2vec (CERT)