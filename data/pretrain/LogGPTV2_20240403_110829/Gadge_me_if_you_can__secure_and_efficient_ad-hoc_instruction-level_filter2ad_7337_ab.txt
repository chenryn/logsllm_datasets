DATA 
1 2 3 4 5 6 
Library 
Library 
CODE 
E F G H I 
DATA 
7 8 9 
Split Executable 
Split Executable 
DATA 
CODE 
D 
B C 
A 
1 2 3 4 5 6 
E F 
c) 
Split Library 
Split Library 
CODE 
G  H I 
DATA 
7 8 9 
Process / Address Space 
Process / Address Space 
RX  RX 
G 
E F 
RX 
A 
RW 
1 2 3 4 5 6 
RX 
D 
RX 
H I 
RW 
7 8 9 
RX 
E F 
Figure 2: High-level process of the randomization
As depicted in Figure 2, the idea of our randomization ap-
proach is to cover the complete executable code of a process,
which consists of the executable ﬁle itself and all loaded
libraries. For that purpose, we apply the necessary random-
ization steps right before execution of a process starts, but
after all the necessary code has been loaded into the address
301Criteria and Properties Multicompiler
Source Trans-
[6, 11, 18]
former [4]
ASLR
e.g.,[29]
ASLP
[21]
ORP
[28]
yes
yes
very high
one time
source code
high
partially
∗
no impl.
P1 - Eﬀectiveness
a) ROP
b) Return-into-Libc
P2 - Entropy
P3 - Frequency
P4 - Input Information
P5 - Code Coverage
P6 - Code Signing Comp.
P7 - Performance
P8 - Memory Consumption
a) Memory Footprint
b) Disk Space
P9 - Library Support
a) Static Libraries
b) Shared Libraries
no impl.
no impl.
yes
yes
∗
∗
∗
P10 - Target Architectures
no impl.
yes
yes
medium
many
source code
high
partially
≈ 11%
∗∗
∗∗
low
low
yes
partially
x86
ELF
partially
partially
low
many
reloc
high
yes
0%
0%
0
yes
yes
x86,ARM,
. . .
yes
yes
medium
many
reloc
high
yes
0%
∗∗
∗∗
low
low
yes
partially
x86
ELF
yes
no
medium
one time
none
medium
yes
≈ 1%
0%
0
yes
yes
x86
PE
ILR
[16]
yes
no
high
many
none
medium
≈ 13%
no
high
≈ 104MB
STIR
[36]
yes
partially
high
many
none
high
no
≈ 6.6%
≈ 37%
73%
XIFER
yes
yes
high
many
reloc
high
yes
≈ 1.2%
≈ 5%
0/7%
yes
no
x86
ELF
yes
no
x86
yes
yes
x86/ARM
ELF/PE
ELF
Table 1: Comparison of Existing Randomization Methods to XIFER
∗
∗∗
In [6], only an experimental setup has been used. The author mentions that the approach induces negligible performance and space overhead.
In contrast, [11, 18] provide no implementation and evaluation.
No precise numbers provided in [4, 21].
space by the linker (step a in Figure 2).
In order to ran-
domize the individual code segments and to intermix them
(all library code and executable code), the code is cut into
arbitrarily small pieces (step b). In the last step c, all code
pieces are spread across the whole address space.
In order to make the individual steps work, we have to
overcome several challenges. The most obvious one is the
fact, that code cannot simply be re-arranged without break-
ing its semantics since all control ﬂow information (e.g.,
branch addresses) is outdated. This challenge is addressed
by building upon binary rewriting techniques, that is disas-
sembling code, understanding its semantics and subjecting
it to the desired changes and re-assembling it. The binary
rewriter’s duty is to make sure that all changes are reﬂected
in the output code but also its original semantics are still
preserved. With a rewriter in place, we can intelligently
choose the points where we cut the code into pieces and
the rewriting process preserves the original control ﬂow de-
spite its shuﬄed layout. A dynamic translation approach –
mimicking the changes in a virtual machine – is out of the
question because of its poor performance [23, 5, 16] due to
its piecemeal and constant translation process.
The existing binary rewriting approaches do not feature
load-time static rewriting and are not customizable to our
needs. Further, a full-blown rewriter is over the top for
our needs and hence does not deliver the performance for
an ad hoc translation at process start-up. Hence, we built
a rewriter from scratch as detailed in the implementation
(Section 5). For the time being, we take the binary rewriter
for granted and ﬁrst explain our randomization solution.
4.2 Randomization
The randomization’s goal is that no instruction remains at
its original relative distance to any other instruction. This
ensures that leaked pointers do not reveal any information
about their surrounding code. The locality of code is further
kept minimal, i.e. it is split apart, so that an attacker cannot
guess anything about the surrounding of any byte of code.
Other randomization solutions that keep the code segment
as one block always reveal that for any leaked pointer at
position x the remainder of the code must be in the interval
]x−s, x+s[ while s is the size of the code. Our deliberate low
locality on the other hand is achieved by splitting the code at
certain positions right between two subsequent instructions.
These cuts result in code that is broken in pieces whose
order can be shuﬄed. The binary rewriter automatically
takes care of keeping formerly subsequent instructions that
have been severed in a sequential control ﬂow (see Figure 3).
a) 
A B C D E F G H 
b) 
A B 
G H 
E F 
D 
C 
Figure 3: Splitting of code into several interconnected pieces.
4.3 Piece Size
Another challenge is the fact that splitting code in too
many pieces imposes a lot of pressure on the processor’s
instruction cache (as can be seen in the evaluation section 6)
since the locality of code has been destroyed. This is why
we constrain the amount and position of the cuts:
Positions: When possible, we leverage already existing con-
trol transfer instructions (e.g.
jump, call) as a splitting
boundary. This has two advantages: First, there is no need
to connect the severed control ﬂow later, when the pieces
have been moved away from each other, because there is
already a control ﬂow instruction that can be adjusted. Sec-
ond, when using an already existing control ﬂow instruction,
the cache miss penalty is most likely to be identical to the
original program.
Amount: The maximum possible entropy of a 32-bit user
mode process however is limited to 231 (2 GB). The en-
tropy of 13 permutations is already larger than that (13! =
6, 227, 020, 800 ≈ 232.5). Hence, it actually makes no sense
to split more than 12 times1 for 32-bit system or more than
16 times for a 64-bit system (with 48 bit address user space).
112 times splitting makes 13 pieces, log213! ≈ 32.54 bits of
entropy
3024.4 Compliance
As described in Section 3, an ideal randomization tool needs
to comply with several criteria. While not all of the criteria
can be fulﬁlled at the same time, in this section, we explain
why we think the best trade-oﬀ of them is met by XIFER.
P1 – Eﬀectiveness. The most important property (P1)
concerns the eﬀectiveness of our solution against code reuse
attacks, which is the main objective of this paper. We
achieve complete mitigation of code-reuse attacks by diversi-
fying the location of each instruction, so that the addresses
needed to mount a successful code-reuse attack remain un-
known. In addition, XIFER is not vulnerable to disclosure
attacks, i.e.
the address of a known function is leaked to
the adversary allowing him to revert the memory structure
of the executable, a library or even the whole application.
This is due to the fact that all oﬀsets between functions, ba-
sic blocks of code and even instructions have been randomly
changed. Even if the permutation and the memory layout
of one speciﬁc instance is known, the adversary cannot as-
sume that the target device is using this instance, since our
diversiﬁcation is re-applied for each application run.
P2 – Entropy. Our diversiﬁcation techniques also yield
very high diversiﬁcation entropy, i.e. every instruction is
moved from its original location, and their relative distance
to each other is completely random. With the permutation
of arbitrarily small code pieces, we achieve an entropy of n!,
while n denotes the number of pieces the code was divided
into. While n can be arbitrarily large, a suitable position to
cut is a boundary of a basic block. Our tests have shown
that on average 15.5% of all instructions are such bound-
aries. This means that for a sample 1000-instruction-binary
we end up with 156 code pieces to shuﬄe. This entropy
of 156! is already higher than the ultimate ASLR solution
that would provide an entropy of 248 on a 64-bit system.
Moreover, besides code transformation, we randomize the
location of each data section to achieve a fully-randomized
memory layout.
P3 – Frequency and P6 – Signing. Since XIFER per-
forms its operation entirely at runtime, we are able to au-
tomatically randomize a program for each run (P3 ) while
keeping compliance to code signing (P6 ).
P4 – Input Information.
Instructions may reference
other data or other code (control ﬂow). These references
need to be detected reliably in order to adjust them accord-
ingly to the new randomized position. In most cases, refer-
ences are encoded in the instruction (e.g. a branch) and can
be detected automatically by disassembling the code. How-