tial uses in practice, such as parameter selection, interpre-
tation of results via advanced statistical decoding, and ex-
periments illustrating what can be learned in practice. The
remaining sections discuss our experimental evaluation, the
attack models we consider, the limitations of the RAPPOR
technique, as well as related work.
2 The Fundamental RAPPOR Algorithm
Given a client’s value v, the RAPPOR algorithm executed
by the client’s machine, reports to the server a bit array
of size k, that encodes a “noisy” representation of its true
value v. The noisy representation of v is chosen in such a
way so as to reveal a controlled amount of information about
v, limiting the server’s ability to learn with conﬁdence what
v was. This remains true even for a client that submits an
inﬁnite number of reports on a particular value v.
Figure 1: Life of a RAPPOR report: The client value of the string “The number 68” is hashed onto the Bloom
ﬁlter B using h (here 4) hash functions. For this string, a Permanent randomized response B(cid:48) is produces and
memoized by the client, and this B(cid:48) is used (and reused in the future) to generate Instantaneous randomized
responses S (the bottom row), which are sent to the collecting service.
To provide such strong privacy guarantees, the RAPPOR
algorithm implements two separate defense mechanisms, both
of which are based on the idea of randomized response and
can be separately tuned depending on the desired level of
privacy protection at each level. Furthermore, additional
uncertainty is added through the use of Bloom ﬁlters which
serve not only to make reports compact, but also to compli-
cate the life of any attacker (since any one bit in the Bloom
ﬁlter may have multiple data items in its pre-image).
The RAPPOR algorithm takes in the client’s true value v
and parameters of execution k, h, f, p, q, and is executed lo-
cally on the client’s machine performing the following steps:
1. Signal. Hash client’s value v onto the Bloom ﬁlter B
of size k using h hash functions.
2. Permanent randomized response. For each client’s
value v and bit i, 0 ≤ i < k in B, create a binary re-
porting value B(cid:48)
i which equals to
1,
(cid:48)
i =
B
with probability 1
2 f
with probability 1
2 f
0,
Bi, with probability 1 − f
where f is a user-tunable parameter controlling the
level of longitudinal privacy guarantee.
Subsequently, this B(cid:48) is memoized and reused as the
basis for all future reports on this distinct value v.
3. Instantaneous randomized response. Allocate a
bit array S of size k and initialize to 0. Set each bit i
in S with probabilities
(cid:40)
P (Si = 1) =
q,
p,
if B(cid:48)
if B(cid:48)
i = 1.
i = 0.
4. Report. Send the generated report S to the server.
There are many diﬀerent variants of the above randomized
response mechanism. Our main objective for selecting these
two particular versions was to make the scheme intuitive and
easy to explain.
The Permanent randomized response (step 2) replaces the
real value B with a derived randomized noisy value B(cid:48). B(cid:48)
may or may not contain any information about B depend-
ing on whether signal bits from the Bloom ﬁlter are being
replaced by random 0’s with probability 1
2 f . The Perma-
nent randomized response ensures privacy because of the
adversary’s limited ability to diﬀerentiate between true and
“noisy” signal bits.
It is absolutely critical that all future
reporting on the information about B uses the same ran-
domized B(cid:48) value to avoid an “averaging” attack, in which
an adversary estimates the true value from observing multi-
ple noisy versions of it.
The Instantaneous randomized response (step 3) plays
Instead of directly reporting
several important functions.
B(cid:48) on every request, the client reports a randomized version
of B(cid:48). This modiﬁcation signiﬁcantly increases the diﬃculty
of tracking a client based on B(cid:48), which could otherwise be
viewed as a unique identiﬁer in longitudinal reporting sce-
narios. It also provides stronger short-term privacy guaran-
tees (since we are adding more noise to the report) which can
be independently tuned to balance short-term vs long-term
risks. Through tuning of the parameters of this mechanism
we can eﬀectively balance utility against diﬀerent attacker
models.
Figure 1 shows a random run of the RAPPOR algorithm.
Here, a client’s value is v = “68”, the size of the Bloom ﬁl-
ter is k = 256, the number of hash functions is h = 4, and
the tunable randomized response parameters are: p = 0.5,
q = 0.75, and f = 0.5. The reported bit array sent to the
server is shown at the bottom of the ﬁgure. 145 out of 256
bits are set in the report. Of the four Bloom ﬁlter bits in B
(second row), two are propagated to the noisy Bloom ﬁlter
B(cid:48). Of these two bits, both are turned on in the ﬁnal report.
The other two bits are never reported on by this client due
to the permanent nature of B(cid:48). With multiple collections
from this client on the value “68”, the most powerful attacker
would eventually learn B(cid:48) but would continue to have lim-
Bloom filter bitsParticipant 8456 in cohort 1183264128256"The number 68"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||4 signal bits||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||69 bits on||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||145 bits onTrue value:Bloom filter (B):Fake Bloom  filter (B'):Report sent to server:01ited ability to reason about the value of B, as measured by
diﬀerential privacy guarantee.
In practice, learning about
the actual client’s value v is even harder because multiple
values map to the same bits in the Bloom ﬁlter [4].
2.1 RAPPOR Modiﬁcations
The RAPPOR algorithm can be modiﬁed in a number of
ways depending on the particulars of the scenario in which
privacy-preserving data collection is needed. Here, we list
three common scenarios where omitting certain elements
from the RAPPOR algorithm leads to a more eﬃcient learn-
ing procedure, especially with smaller sample sizes.
• One-time RAPPOR. One time collection, enforced
by the client, does not require longitudinal privacy pro-
tection. The Instantaneous randomized response step
can be skipped in this case and a direct randomization
on the true client’s value is suﬃcient to provide strong
privacy protection.
• Basic RAPPOR. If the set of strings being collected
is relatively small and well-deﬁned, such that each
string can be deterministically mapped to a single bit
in the bit array, there is no need for using a Bloom ﬁlter
with multiple hash functions. For example, collecting
data on client’s gender could simply use a two-bit ar-
ray with “male” mapped to bit 1 and “female” mapped
to bit 2. This modiﬁcation would aﬀect step 1, where
a Bloom ﬁlter would be replaced by a deterministic
mapping of each candidate string to one and only one
bit in the bit array. In this case, the eﬀective number
of hash functions, h, would be 1.
• Basic One-time RAPPOR. This is the simplest
conﬁguration of the RAPPOR mechanism, combin-
ing the ﬁrst two modiﬁcations at the same time: one
round of randomization using a deterministic mapping
of strings into their own unique bits.
3 Differential Privacy of RAPPOR
The scale and availability of data in today’s world makes
increasingly sophisticated attacks feasible, and any system
that hopes to withstand such attacks should aim to ensure
rigorous, rather than merely intuitive privacy guarantees.
For our analysis, we adopt the rigorous notion of privacy, dif-
ferential privacy, which was introduced by Dwork et al [12]
and has been widely adopted [10]. The deﬁnition aims to en-
sure that the output of the algorithm does not signiﬁcantly
depend on any particular individual’s data. The quantiﬁca-
tion of the increased risk that participation in a service poses
to an individual can, therefore, empower clients to make a
better informed decision as to whether they want their data
to be part of the collection.
Formally, a randomized algorithm A satisﬁes -diﬀerential
privacy [12] if for all pairs of client’s values v1 and v2 and
for all R ⊆ Range(A),
P (A(v1) ∈ R) ≤ eP (A(v2) ∈ R).
We prove that the RAPPOR algorithm satisﬁes the deﬁni-
tion of diﬀerential privacy next. Intuitively, the Permanent
randomized response part ensures that the “noisy” value de-
rived from the true value protects privacy, and the Instanta-
neous randomized response provides protection against us-
age of that response by a longitudinal tracker.
3.1 Differential Privacy of the Permanent Ran-
domized Response
Theorem 1. The Permanent randomized response (Steps
1 and 2 of RAPPOR) satisﬁes ∞-diﬀerential privacy where
∞ = 2h ln
2 f
.
(cid:17)
(cid:16) 1− 1
1
2 f
Proof. Let S = s1, . . . , sk be a randomized report gen-
erated by the RAPPOR algorithm. Then the probability of
observing any given report S given the true client value v
and assuming that B(cid:48) is known is
P (S = s|V = v) = P (S = s|B, B
(cid:48)|B, v) · P (B|v)
, v) · P (B
(cid:48)
= P (S = s|B
= P (S = s|B
(cid:48)
(cid:48)
) · P (B
) · P (B
(cid:48)|B) · P (B|v)
(cid:48)|B).
Because S is conditionally independent of B given B(cid:48), the
ﬁrst probability provides no additional information about
B. P (B(cid:48)|B) is, however, critical for longitudinal privacy
protection. Relevant probabilities are
i = 1|bi = 1) =
(cid:48)
i = 1|bi = 0) =
(cid:48)
P (b
P (b
1
2
1
2
f + 1 − f = 1 − 1
2
f
and
f.
Without loss of generality, let the Bloom ﬁlter bits 1, . . . , h
be set, i.e., b∗ = {b1 = 1, . . . , bh = 1, bh+1 = 0, . . . , bk = 0}.
Then,
(cid:48)
(cid:48)|B = b
∗
= b
P (B
) =
1 × . . .
f
f
2
×
1 − 1
2
1 − 1
2
(cid:19)b(cid:48)
1(cid:18)
(cid:18) 1
h(cid:18)
(cid:18) 1
(cid:19)b(cid:48)
(cid:18)
(cid:19)b(cid:48)
h+1(cid:18) 1
k(cid:18) 1
(cid:19)b(cid:48)
(cid:18)
(cid:19)1−b(cid:48)
(cid:19)1−b(cid:48)
(cid:19)1−b(cid:48)
(cid:19)1−b(cid:48)
2
1 − 1
2
1 − 1
2
×
×
2
2
f
f
f
f
f
f
.
k
h × . . .
h+1 × . . .
Let RR∞ be the ratio of two such conditional probabil-
ities with distinct values of B, B1 and B2, i.e., RR∞ =
P (B(cid:48)∈R∗|B=B1)
P (B(cid:48)∈R∗|B=B2) . For the diﬀerential privacy condition to
hold, RR∞ needs to be bounded by exp(∞).
(by Observation 8)
h+2−...−b(cid:48)
2h)
RR∞ =
=
P (B(cid:48) ∈ R∗|B = B1)
P (B(cid:48) ∈ R∗|B = B2)
i∈R∗ P (B(cid:48) = B(cid:48)
B(cid:48)
i∈R∗ P (B(cid:48) = B(cid:48)
B(cid:48)
≤ max
(cid:19)2(b(cid:48)
B(cid:48)
i∈R∗
P (B(cid:48) = B(cid:48)
P (B(cid:48) = B(cid:48)
2+...+b(cid:48)
1+b(cid:48)
=
f
i|B = B1)
i|B = B2)
i|B = B1)
i|B = B2)
h−b(cid:48)
h+1−b(cid:48)
(cid:19)2(b(cid:48)
h+1+b(cid:48)
h+2+...+b(cid:48)
2h−b(cid:48)
1−b(cid:48)
2−...−b(cid:48)
h)
f
.
1 − 1
2
Sensitivity is maximized when b(cid:48)
h = 0. Then,
and ∞ = 2h ln
2 = . . . = b(cid:48)
1 = b(cid:48)
2 f
(cid:16) 1− 1
1 and b(cid:48)
RR∞ =
(cid:17)2h
h+1 = b(cid:48)
(cid:16) 1− 1
2 f
(cid:17)
.
1
2 f
h+2 = . . . = b(cid:48)
2h =
(cid:80)
(cid:80)
(cid:18) 1
(cid:18)
2
×
1
2 f
Note that ∞ is not a function of k.
It is true that a
smaller k, or a higher rate of Bloom ﬁlter bit collision, some-