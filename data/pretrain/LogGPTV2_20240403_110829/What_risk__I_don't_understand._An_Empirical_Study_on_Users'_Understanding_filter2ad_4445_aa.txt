title:What risk? I don't understand. An Empirical Study on Users' Understanding
of the Terms Used in Security Texts
author:Tingmin Wu and
Rongjunchen Zhang and
Wanlun Ma and
Sheng Wen and
Xin Xia and
C&apos;ecile Paris and
Surya Nepal and
Yang Xiang
An Empirical Study on Users’ Understanding of the Terms Used
What risk? I don’t understand.
in Security Texts
Tingmin Wu
Rongjunchen Zhang
Wanlun Ma
PI:EMAIL
Swinburne University of Technology
PI:EMAIL
Swinburne University of Technology
PI:EMAIL
University of Electronic Science and
Data61, CSIRO
Sheng Wen∗
PI:EMAIL
Swinburne University of Technology
Data61, CSIRO
Technology of China
Xin Xia
PI:EMAIL
Monash University
Cecile Paris
PI:EMAIL
Data61, CSIRO
PI:EMAIL
Surya Nepal
Data61, CSIRO
ABSTRACT
Users receive a multitude of security information in written articles,
e.g., newspapers, security blogs, and training materials. However,
prior research suggests that these delivery methods, including secu-
rity awareness campaigns, mostly fail to increase people’s knowl-
edge about cyber threats. It seems that users find such information
challenging to absorb and understand. Yet, to raise users’ security
awareness and understanding, it is essential to ensure the users
comprehend the provided information so that they can apply the
advice it contains in practice.
We conducted a subjective study to measure the level of users’ un-
derstanding of security texts. We find that 61% of the terms security
experts used in their writings are hard for the public to understand,
even for people with some IT backgrounds. We also observe that
88% of security texts have at least one such term. Moreover, we
notice that existing dictionaries, including the online ones (e.g.,
Google Dictionary), cover no more than 35% of the terms found in
security texts. To improve users’ ability to understand security texts,
we developed a framework to build a user-oriented security-centric
dictionary from multiple sources. To evaluate the effectiveness of
the dictionary, we developed a tool as a service to detect technical
terms and explain their meanings to the user in pop-ups. The results
of a subjective study to measure the tool’s performance showed
that it could increase users’ ability to understand security articles
by 30%.
∗Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ASIA CCS ’20, October 5–9, 2020, Taipei, Taiwan
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-6750-9/20/10...$15.00
https://doi.org/10.1145/3320269.3384761
Yang Xiang
PI:EMAIL
Swinburne University of Technology
CCS CONCEPTS
• Security and privacy → Usability in security and privacy; •
Human-centered computing → User interface toolkits.
KEYWORDS
user security awareness; security term explanation; user study
ACM Reference Format:
Tingmin Wu, Rongjunchen Zhang, Wanlun Ma, Sheng Wen, Xin Xia, Cecile
Paris, Surya Nepal, and Yang Xiang. 2020. What risk? I don’t understand.
An Empirical Study on Users’ Understanding of the Terms Used in Security
Texts. In Proceedings of the 15th ACM Asia Conference on Computer and
Communications Security (ASIA CCS ’20), October 5–9, 2020, Taipei, Taiwan.
ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3320269.3384761
1 INTRODUCTION
In our increasingly digitised and interconnected society, cyber at-
tacks continue to escalate and harm internet users [23]. It is recog-
nised that humans are still the dominant security decision-makers
in the face of cyber attacks [15]. In 2017, Netwrix conducted a sur-
vey designed to identify IT security, compliance, and operational
risks that organisations around the globe face on a daily basis. In
that survey, all government entities considered their employees as
the biggest threat [11]. Education in understanding security texts
is critical to the improvement of users’ ability in making correct
security decisions [42]. However, it was revealed that less than 25%
of security advice was easy to understand [16].
The fact is that most users are not security experts, even if they
are technically savvy. User studies conducted through interviews
revealed that two-third of the users underestimate the extent of
cyber harms, and only around 10% can explain protective measures
(e.g., fraud alerts) correctly [64]. Despite efforts to increase users’
understanding of security measures such as removing terms [18]
and improving security interfaces [1], the low success rate shows
that it is still challenging to get users to the stage that they can apply
security measures in practice [17]. The critical step in achieving
this goal is to help users better understand security terms.
Figure 1: Overview of our framework to build the Security-Centric (SC) Dictionary.
Research conducted by the Pew Research Centre tested users’
knowledge about technical terms [10]. It indicated that most users
were familiar with common terms (e.g., ‘wiki’), but had difficulty
in explaining certain concepts (e.g., ‘phishing’, ‘virus’). Existing
studies also revealed that security advice to reduce risks [44] is
helpful, but requires a high level of education to understand and is
likely to be misinterpreted or even ignored [13, 51]. Other studies
report complementary facts like half of users refuse to use security
advice because they think the concerns are unnecessary or fail to
comprehend how it works [29, 45, 61].
Despite the reported problem in these studies, there has been no
analysis of why the comprehension level of users is low when it
comes to security advice, and what steps can be taken to alleviate
this issue. We focus on text-based means of delivering security
messages (i.e., security texts) and try to address these questions
by a series of real-world experiments, designed to answer the four
following research questions.
RQ1. What are the technical terms used in security texts and
their difficulty levels from a user’ perspective?
RQ2. Are traditional methods useful in measuring the difficulty
level of technical terms?
RQ3. Are the technical terms as difficult for people with IT
background as they are for those without IT background?
RQ4. What functions would users like to help them read techni-
cal articles?
Our first step was to build a dataset of security blogs, since they
are one of the major public sources providing news and articles
containing computer security advice [36]. A study revealed that
most users learn cybersecurity through media, especially blogs [51].
We then invited 597 participants to take part in a subjective study,
in which we asked them to rate their comprehension of these blogs.
We generated a security corpus consisting of 6,286 technical terms
from the results. The study also reveals interesting and surprising
results, some of which are reported below:
• 61% of technical terms are considered to be hard (with a difficulty
level higher than 50% on a scale from 1 to 10) and have a serious
impact on the comprehension of security texts;
• There exists an inconsistency between users’ reported difficulty
levels and those of traditional readability tests, e.g., the termhood
calculation [12] and term occurrences in Google Search;
• People with IT background assign higher difficulty levels to the
technical terms related to cyber threats and protection measures
compared to those without IT background; and
• 65% of participants would like to have a dictionary-based expla-
nation for technical terms.
The last finding, which was the result of analysing the answers
to an open question in our survey, motivated us to perform an
additional study, mainly to test ways to improve security text read-
ability from a user’ perspective. General dictionaries (Wikipedia
Page Previews [59], Google Dictionary [22] and Mac Dictionary [4])
were not useful, because none of them was able to cover more than
35% of the collected terms. Hence, we built a specific dictionary
by combining multiple sources (cf Section 4). Fig.1 visually shows
the steps taken for this purpose. We then developed a service tool
as a browser plug-in. This service used our dictionary to provide
explanations for security terms in the form of pop-ups (cf Section
4).
To find out to what extent our tool helps users understand se-
curity texts and to see what influences users’ comprehension, we
conducted a second experiment. We employed 112 participants with
different IT backgrounds to explore the factors that influence their
understanding. The analysis revealed the following:
• Our tool can help users understand security articles significantly
• Users misunderstand ambiguous terms (e.g., terms with multiple
• Users with IT background perform better in understanding secu-
meanings or with meanings similar to other terms).
better, as much as 30%, than existing methods.
rity texts than those without, but only when using our tool.
We believe these findings can help security experts compose
their security advice in high readability with users in mind, and
also develop tools and methods for a more effective delivery of
security texts. To summarise, our paper has the following three
contributions:
• We conducted an empirical study to understand the difficulties
• We built a user-oriented security-centric dictionary.
• We developed and implemented a tool as a service by using our
faced by users in comprehending security texts.
dictionary to help users comprehend security texts.
The rest of the paper is structured as follows. In Section 2, we
review related work. Sections 3 and 4 report the details of our
experiments and their results. Section 5 discusses the implications
and limitations. Section 6 concludes the paper.
2 RELATED WORK
In this section, we discuss related work on users’ perceptions of
security risks, their understanding of security threats, measures
and descriptions, and security education.
(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:35)(cid:77)(cid:80)(cid:72)(cid:1)(cid:34)(cid:83)(cid:85)(cid:74)(cid:68)(cid:77)(cid:70)(cid:84)(cid:52)(cid:36)(cid:1)(cid:36)(cid:80)(cid:83)(cid:81)(cid:86)(cid:84)(cid:35)(cid:77)(cid:80)(cid:72)(cid:1)(cid:36)(cid:83)(cid:66)(cid:88)(cid:77)(cid:70)(cid:83)(cid:36)(cid:80)(cid:79)(cid:85)(cid:70)(cid:79)(cid:85)(cid:1)(cid:52)(cid:66)(cid:79)(cid:74)(cid:85)(cid:74)(cid:84)(cid:66)(cid:85)(cid:74)(cid:80)(cid:79)(cid:53)(cid:70)(cid:89)(cid:85)(cid:1)(cid:36)(cid:77)(cid:66)(cid:84)(cid:84)(cid:74)(cid:71)(cid:74)(cid:68)(cid:66)(cid:85)(cid:74)(cid:80)(cid:79)(cid:34)(cid:83)(cid:85)(cid:74)(cid:68)(cid:77)(cid:70)(cid:1)(cid:45)(cid:70)(cid:79)(cid:72)(cid:85)(cid:73)(cid:1)(cid:34)(cid:69)(cid:75)(cid:86)(cid:84)(cid:85)(cid:78)(cid:70)(cid:79)(cid:85)(cid:51)(cid:70)(cid:81)(cid:83)(cid:70)(cid:84)(cid:70)(cid:79)(cid:85)(cid:66)(cid:85)(cid:74)(cid:87)(cid:70)(cid:1)(cid:34)(cid:83)(cid:85)(cid:74)(cid:68)(cid:77)(cid:70)(cid:84)(cid:52)(cid:36)(cid:1)(cid:37)(cid:74)(cid:68)(cid:85)(cid:74)(cid:80)(cid:79)(cid:66)(cid:83)(cid:90)...(cid:35)(cid:77)(cid:80)(cid:72)(cid:1)(cid:52)(cid:68)(cid:83)(cid:66)(cid:81)(cid:70)(cid:83)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:34)(cid:83)(cid:85)(cid:74)(cid:68)(cid:77)(cid:70)(cid:1)(cid:52)(cid:70)(cid:77)(cid:70)(cid:68)(cid:85)(cid:74)(cid:80)(cid:79)(cid:52)(cid:36)(cid:1)(cid:36)(cid:80)(cid:83)(cid:81)(cid:86)(cid:84)(cid:1)(cid:40)(cid:70)(cid:79)(cid:70)(cid:83)(cid:66)(cid:85)(cid:74)(cid:80)(cid:79)(cid:52)(cid:36)(cid:1)(cid:37)(cid:74)(cid:68)(cid:85)(cid:74)(cid:80)(cid:79)(cid:66)(cid:83)(cid:90)(cid:1)(cid:40)(cid:70)(cid:79)(cid:70)(cid:83)(cid:66)(cid:85)(cid:74)(cid:80)(cid:79)Perception of Security Risks. Users’ awareness of security
threats is a great concern for computer security experts. Fagan
and Khan investigated the difference in risk perception between
those who followed the security advice and those who did not [17].
Security advice was reported to be incomprehensible to some home
computer users who lacked any high education in [13]. Therefore,
these users were unable to take appropriate actions to counter
security threats.
Wash conducted qualitative interviews to find out how well
home computer users understood security threats [60]. He also
identified eight folk models of security threats, including malware
and attackers, which exposed users’ misunderstanding of the con-
cepts and explained why they ignored security warnings. Routi et
al. conducted a series of interviews to investigate users’ perceptions
of online security [51]. They found that users’ misunderstandings
of browser-based TLS (Transport Layer Security) indicators caused
unsafe behaviours. Wash and Rader also found that participants had
different security knowledge and beliefs about viruses and hackers
[61].
In the Android ecosystem, Harbach et al. generated personalised
examples to improve users’ awareness when making security and
privacy decisions, e.g., during the app installation process [25].
Similarly, some studies [62, 63] applied static code analysis and
generated security-centric descriptions or privacy policies with
different sentence structures.
Security Understanding. Howe et al. made a literature review
on existing surveys and found that, although users were aware of
and concerned about security threats, they were unable to under-
stand them [27]. Similarly, Shay et al. interviewed 394 people about
the hijacking problem [55]. The results reflected that the users were
aware of malware, phishing, and third-party breaches but unable
to apply adequate security measures. Ion et al. demonstrated the
difference of security advice between experts and non-experts, such
as using 2FA and password manager to prevent attacks, compared
to using anti-virus programs and changing passwords frequently
[29]. Later, Zou et al. built mental models of credit bureaus and
found the participants were aware of the data breaches, but they
hardly understood them and thus suffered from them [64]. The
reason could be that they underestimate the possibility to become
victims, so that they refused to take effective measures in time.
The factors that influence users’ understanding of computer
security were also studied in some recent work. Forget et al. pre-
sented the relationships between users’ attitudes or behaviours
and their understanding of security threats [21]. The bias on the
estimation of their technical expertise and misunderstanding of
the risks could enable severe attacks by applying wrong security
measures. Acquisti et al. explained what affected users in security
and privacy decision making [2]. Sawaya et al. also found that users’
self-confidence knowledge affected their security behaviours more
than actual knowledge [53].
In addition to users’ knowledge, the content of security texts
(e.g., newspapers, security blogs) can also affect users’ understand-
ing. Badal et al. revealed that one critical reason that the users did
not apply appropriate security measures was the poor design of
security descriptions [7]. Redmiles et al. found users with more
enterprise knowledge were more likely to take the socioeconomi-
cally advantage to obtain security advice from the workplace, while
low-skill people mostly learned from their peers [44].
Users’ Security Education. Dale et al. highlighted the neces-
sity of cybersecurity education for raising users’ awareness [50].
Great efforts have been made to improve the delivery of security
texts to end users, with the purpose of education. For example, SSL