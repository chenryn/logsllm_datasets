4.3.2. Edge Coverage. To generate multiple sequences for
an assembly function, we randomly sample all the edges
from the callee-expanded control ﬂow graph, until all the
edges in the original graph are covered. For each sampled
edge, we concatenate their assembly code to form a new
sequence. This way, we ensure that the control ﬂow graph
is fully covered. The model can still produce similar se-
quences, even if the basic blocks in the control ﬂow graph
are split or merged.
4.3.3. Random Walk. CACompare [13] uses a random
input sequence to analyze the I/O behavior of an assembly
function. A random input simulates a random walk on the
valid execution ﬂow. Inspired by this method, we extend
the assembly sequences for an assembly function by adding
multiple random walks on the expanded control ﬂow graph.
This way, the generated sequence is much longer than the
edge sampling.
Dominator is a widely used concept in control ﬂow
analysis and compiler optimizations. A basic block dom-
inates another if one has to pass this block in order to
reach the other. Multiple random walks will put a higher
probability to cover basic block that dominate others. These
popular blocks can be the indicator of loop structures or
cover important branching conditions. Using random walks
can be considered as a natural way to prioritize basic blocks
that dominate others.
4.4. Tranining, Estimating and Searching
The training procedure corresponds to Algorithm 1. For
each function in the repository, it generates sequences by
(cid:21)(cid:24)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:52 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 1 Training the Asm2Vec model for one epoch
1: function TRAIN(Repository RP)
2:
3:
4:
5:
for each seqi ∈ S(fs) do
shufﬂe(RP)
for each fs ∈ RP do
for j = 1 → (|seqi| − 1) do
(cid:2) Going through each instruction.
lookup fs’s representation (cid:3)θfs
calculate CT (inj−1) by Equ. 3
calculate CT (inj+1) by Equ. 3
calculate δ(inj , fs) by Equ. 4
for each tkn ∈ inj do
(cid:2) Going through each token
6:
7:
8:
9:
10:
11:
targets ← Etb(cid:2)Pn(tkn) ∪ {tkn}
(cid:2) Sample tokens from Pn(tkn)
calculate and cumulate gradient for (cid:3)θfs (Equ. 7)
calculate gradient for (cid:3)v(cid:2)
update (cid:3)v(cid:2)
calculate and cumulate gradient for inj−1 (Equ. 8)
calculate and cumulate gradient for inj+1 (Equ. 8)
t (Equ. 7)
t
12:
13:
14:
15:
16:
update vectors for tokens of inj−1
17:
18:
update vectors for tokens of inj+1
update (cid:3)θfs
19:
20:
21: function S(Function fs)
graph ← CFG(fs)
22:
graph ← ExpandSellectiveCallee(graph)
23:
sequences ← {}
24:
for each edg ∈ SampleEdge(graph) do
25:
26:
return sequences
for i ← numRandomWalk do
seq ← source(edg) || target(edg)
(cid:2) Concatenate the source and the target blocks
sequences ← sequences ∪ {seq}
seq ← RandomWalk(graph)
sequences ← sequences ∪ {seq}
27:
28:
29:
30:
31:
edging sampling and random walks. For each sequence, it
goes through each instruction and applies the Asm2Vec to
update the vectors (Line 10 to 19). As shown in Algorithm 1,
the training procedure does not require a ground-truth map-
ping between equivalent assembly functions.
The estimation step corresponds to Step 3 in Figure 3.
For an unseen assembly function ft as query ft /∈ RP that
does not belong to the set of training assembly functions,
2×d, which is
we ﬁrst associate it with a vector (cid:2)θft
initialized to a sequence of small values close to zero. Then,
we follow the same procedure in the training process, where
the neural network goes through each sequence of ft and
each instruction of the sequence. In every prediction step,
we ﬁx all (cid:2)vt and (cid:2)v(cid:2)
t in the trained model and only propagate
errors to (cid:2)θft. At the end, we have (cid:2)θft while the vectors for
all fs ∈ RP and {(cid:2)vt, (cid:2)v(cid:2)
t|t ∈ D} remain the same. To search
for a match, vectors are ﬂattened and compared using cosine
similarity.
∈ R
Scalability is critical for binary clone search, as there
may be millions of assembly functions inside a repository.
It is practical to train Asm2Vec on a large-scale of assembly
code. A similar model on text has been shown to be scalable
to billions of text samples for training [21]. In this study,
we only use pair-wise similarity for nearest neighbor search-
ing. Pair-wise searching among low-dimensional ﬁx-length
vectors can be fast. In our experiment in Section 5.3, there
(cid:21)(cid:24)(cid:25)
initialize ft’s representation (cid:3)θft
for each seqi ∈ S(ft) do
for j = 1 → (|seqi| − 1) do
Algorithm 2 Estimating a vector representation for a query
1: function ESTIMATE(Query Function ft)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
calculate CT (inj−1) by Equ. 3
calculate CT (inj+1) by Equ. 3
calculate δ(inj , ft) by Equ. 4
for each tkn ∈ inj do
targets ← Etb(cid:2)Pn(tkn) ∪ {tkn}
calculate gradient for (cid:3)θft (Equ. 7)
update (cid:3)θft
are 139,936 functions. The average training time for each
function is 49 milliseconds. The average query response
time is less than 300 milliseconds.
5. Experiments
We compare Asm2Vec with existing available state-
of-the-art dynamic and static assembly clone search ap-
proaches. All the experiments are conducted with an Intel
Xeon 6 core 3.60GHz CPU with 32G memory. To simulate
a similar environment in related studies, we limit the JVM to
only 8 threads. There are four experiments. First, we bench-
mark the baselines against different compiler optimizations
with GCC. Second, we evaluate clone search quality against
different heavy code obfuscations with CLANG and O-
LLVM. Third, we use all the binaries of the previous two.
In the last one, we apply Asm2Vec on a publicly available
vulnerability search dataset. All binary ﬁles are stripped
before clone search. In all of the experiments, we choose
d = 200, 25 negative samples, 10 random walks, and a
decaying learning rate 0.025 for Asm2Vec. 200 corresponds
to the suggested dimensionality (2d) used in [20].
5.1. Searching with Different Compiler Optimiza-
tion Levels
In this experiment, we benchmark the clone search
performance against different optimization levels with the
GCC compiler version 5.4.0. We evaluate Asm2Vec based
on 10 widely used utility and numeric calculation libraries
in Table 1. They are chosen according to an internal statistic
of the prevalence of FOSS libraries. We ﬁrst compile a
selected library using the GCC compiler with four differ-
ent compiler optimization settings, which results in four
different binaries. Then, we test every combination of two
of them, which corresponds to two different optimization
levels. Given two binaries from the same library but with
different optimization levels, we link their assembly func-
tions using the compiler-output debug symbols and generate
a clone mapping between functions. This mapping is used as
the ground-truth data for evaluation only. We search the ﬁrst
against the second in RP and after, we search for the second
against the ﬁrst in RP. Only the binary in the repository is
used for training. We take the average of the two.
A higher optimization level contains all optimization
strategies from the lower level. The comparison between
O2 and O3 is the easiest one (Figure 6). On average, 26%
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:52 UTC from IEEE Xplore.  Restrictions apply. 
Figure 6: The difference between the O0/O2 optimized and the O3 optimized function. a) Relative string editing distance.
0.264 indicates that around 26.4% percent of bytes are different between two options for the same source code function. b)
Relative absolute difference in the count of vertices and edges. 0.404% indicates that one function has 40.4% more vertices
and edges than the other.
BusyBox CoreUtils Libgmp
Compiler optimization O2 and O3
ImageMagick Libcurl LibTomCrypt OpenSSL SQLite
BusyBox CoreUtils Libgmp
Compiler optimization O0 and O3
ImageMagick Libcurl LibTomCrypt OpenSSL SQLite
Baselines
BinGo†
Composite
Constant
Graphlet
Graphlet-C
Graphlet-E
MixedGram
MixedGraph
n-gram
n-perm
FuncSimSearch
PV(DM/DBOW)
Asm2Vec*
Baselines
BinGo†
CACompare†
Composite
Constant
Graphlet
Graphlet-C
Graphlet-E
MixedGram
MixedGraph
n-gram
n-perm
FuncSimSearch
PV(DM/DBOW)
Asm2Vec*
Ø
.789
.437
.309
.662
.278
.811
.445
.774
.803
.157
.895
.954
Ø
.844
.013
.239
.017
.018
.021
.016
.034
.011
.017
.008
.745
.856
.490
.643
.338
.268
.581
.225
.663
.413
.644
.654
.169
.899
.929
.317
Ø
.031
.128
.008
.020
.011
.033
.028
.029
.029
.019
.677
.781
Ø
.910
.202
.355
.680
.362
.906
.436
.874
.912
.848
.959
.973
Ø
Ø
.019
.101
.049
.012
.075
.019
.062
.012
.021
.323
.760
.763
Ø
.787
.711
.262
.678
.270
.792
.427
.739
.788
.514
.952
.971
Ø
.893
.017
.610
.010
.022
.019
.018
.024
.021
.021
.039
.802
.837
Ø
.842
.522
.321
.689
.271
.848
.486
.814
.848
.663
.927
.951
Ø
.794
.004
.369
.023
.027
.017
.011
.039
.011
.011
.036
.792
.850
Ø
.646
.440
.297
.559
.219
.652
.379
.593
.646
.698
.945
.991
Ø
Ø
.005
.258
.011
.001
.003
.005
.015
.010
.006
.030
.821
.921
zlib
Ø
.813
.549
.406
.730
.399
.858
.564
.812
.850
.488
.873
.885
zlib
Ø
Ø
.036
.360
.029
.065
.051
.036
.064
.036
.036
.054
.713
.722
PuTTYgen
Ø
.8IHI 38
.571
.148
.795
.355
.865
.533
.781
.855
.363
.823
.891
PuTTYgen
Ø
.717
.127
.439
.016
.102
.058
.116
.097
.129
.129
.040
.615
.788
Avg.
.490
.783
.450
.289
.665
.286
.798
.449
.754
.793
.516
.909
.940
Avg.
.317
.808
.026
.296
.019
.031
.029
.028
.042
.027
.028
.078
.744
.809
p
(cid:2)
(cid:2)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:2)
(cid:2)