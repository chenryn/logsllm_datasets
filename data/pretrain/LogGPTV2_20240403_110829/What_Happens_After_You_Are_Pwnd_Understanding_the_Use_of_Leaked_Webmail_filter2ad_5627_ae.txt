owner over a period of time. A deviation of search be-
havior would then be ﬂagged as anomalous, indicating
that the account may have been compromised. Sim-
ilarly, anomaly detection systems could be trained on
the durations of connections during benign usage, and
deviations from those could be ﬂagged as anomalous.
Limitations. We encountered a number of limitations
in the course of the experiments. For example, we were
able to leak the honey accounts only on a few outlets,
namely paste sites, underground forums, and malware.
In particular, we could only target underground forums
that were open to the public and for which registration
was free. Similarly, we could not study some of the most
recent families of information-stealing malware such as
Dridex, because they would not execute in our virtual
environment. Attackers could ﬁnd the scripts we hid in
the honey accounts and remove them, making it impos-
sible for us to monitor the activity of the accounts. This
is an intrinsic limitation of our monitoring architecture,
but in principle studies similar to ours could be per-
formed by the online service providers themselves, such
as Google and Facebook. By having access to the full
logs of their systems, such entities would have no need
to set up monitoring scripts, and it would be impossi-
ble for attackers to evade their scrutiny. Finally, while
evaluating what cybercriminals were looking for in the
honey accounts, we were able to observe the emails that
they found interesting in the honey accounts, not every-
thing they searched for. This is because we do not have
access to the search logs of the honey accounts.
Future work. In the future, we plan to continue ex-
ploring the ecosystem of stolen accounts, and gaining a
better understanding of the underground economy sur-
rounding them. We would explore ways to make the
decoy accounts more believable, to attract more cyber-
criminals and keep them engaged with the decoy ac-
counts. We intend to set up additional scenarios, such
as studying attackers who have a speciﬁc motivation,
for example compromising accounts that belong to po-
litical activists (rather than generic corporate accounts,
as we did in this paper). We would also like to study if
demographic information, as well as the language that
the emails in honey accounts are written in, inﬂuence
the way in which cybercriminals interact with these ac-
counts. To mitigate the fact that our infrastructure can
only identify search terms for emails that were found in
the accounts, we plan to seed the honey accounts with
some specially crafted emails containing decoy sensi-
tive information, for instance, fake bank account infor-
mation and login credentials, along with other regular
email messages. Hopefully, this type of specialized email
seeding will help to increase the variety of hits when cy-
bercriminals search for content in the honey accounts,
by improving the seeding of the honey accounts. We
believe this will improve our insight into what criminals
search for.
6. RELATED WORK
In this section, we brieﬂy compare this paper with
previous work, noting that most previous work focused
on spam and social spam. Only a few focused on manual
hijacking of accounts and their activity.
Bursztein et al. [13] investigated manual hijacking of
online accounts through phishing pages. The study fo-
cuses on cybercriminals that steal user credentials and
use them privately, and shows that manual hijacking
is not as common as automated hijacking by botnets.
This paper illustrates the usefulness of honey creden-
tials (account honeypots), in the study of hijacked ac-
counts. Compared to the work by Bursztein et al.,
which focused on phishing, we analyzed a much broader
threat model, looking at account credentials automati-
cally stolen by malware, as well as the behavior of cy-
bercriminals that obtain account credentials through
underground forums and paste sites. By focusing on
multiple types of miscreants, we were able to show dif-
ferences in their modus operandi, and provide multi-
ple insights on the activities that happen on hijacked
Gmail accounts in the wild. We also provide an open
source framework that can be used by other researchers
to set up experiments similar to ours and further explore
the ecosystem of stolen Google accounts. To the best
of our knowledge, our infrastructure is the ﬁrst pub-
licly available Gmail honeypot infrastructure. Despite
the fact that the authors of [13] had more visibility on
the account hijacking phenomenon than we did, since
they were operating the Gmail service, the dataset that
we collected is of comparable size to theirs: we logged
326 malicious accesses to 100 accounts, while they stud-
ied 575 high-conﬁdence hijacked accounts.
A number of papers looked at abuse of accounts on
social networks. Thomas et al. [34] studied Twitter ac-
counts under the control of spammers. Stringhini et
al. [31] studied social spam using 300 honeypot proﬁles,
and presented a tool for detection of spam on Face-
book and Twitter. Similar work was also carried out
in [9,12,24,38]. Thomas et al. [35] studied underground
markets in which fake Twitter accounts are sold and
then used to spread spam and other malicious content.
Unlike this paper, they focus on fake accounts and not
on legitimate ones that have been hijacked. Wang et
al. [37] proposed the use of patterns of click events to
ﬁnd fake accounts in online services.
Researchers also looked at developing systems to de-
tect compromised accounts. Egele et al. [18] presented
a system that detects malicious activity in online social
networks using statistical models. Stringhini et al. [32]
developed a tool for detecting compromised email ac-
counts based on the behavioral modeling of senders.
Other papers investigated the use of stolen credentials
and stolen ﬁles by setting up honeyﬁles. Liu et al. [25]
deployed honeyﬁles containing honey account creden-
tials in P2P shared spaces. The study used a similar
approach to ours, especially in the placement of honey
account credentials. However, they placed more empha-
sis on honeyﬁles than on honey credentials. Besides,
they studied P2P networks while our work focuses on
compromised accounts in webmail services. Nikiforakis
et al. [26] studied privacy leaks in ﬁle hosting services by
deploying honeyﬁles on them. In our previous work [23],
we developed an infrastructure to study malicious activ-
ity in online spreadsheets, using an approach similar to
the one described in this paper. Stone-Gross et al. [30]
studied a large-scale spam operation by analyzing 16
C&C servers of Pushdo/Cutwail botnet. In the paper,
the authors highlight that the Cutwail botnet, one of
the largest of its time, has the capability of connect-
ing to webmail accounts to send spam. In their paper,
Stone-Gross et al. also describe the activity of cyber-
criminals on spamdot, a large underground forum. They
show that cybercriminals were actively trading account
information such as the one provided in this paper, pro-
viding free “teasers” of the overall datasets for sale. In
this paper, we used a similar approach to leak account
credentials on underground forums.
7. CONCLUSION
In this paper, we presented a honey account system
able to monitor the activity of cybercriminals that gain
access to Gmail account credentials. Our system is
publicly available to encourage researchers to set up
additional experiments and improve the knowledge of
our community regarding what happens after webmail
accounts are compromised2. We leaked 100 honey ac-
counts on paste sites, underground forums, and virtual
machines infected with malware, and provided detailed
statistics of the activity of cybercriminals on the ac-
counts, together with a taxonomy of the criminals. Our
ﬁndings help the research community to get a better un-
derstanding of the ecosystem of stolen online accounts,
and potentially help researchers to develop better de-
tection systems against this malicious activity.
8. ACKNOWLEDGMENTS
We wish to thank our shepherd Andreas Haeberlen
for his advice on how to improve our paper, and Mark
Risher and Tejaswi Nadahalli from Google for their sup-
port throughout the project. We also thank the anony-
mous reviewers for their comments. This work was
supported by the EPSRC under grant EP/N008448/1,
and by a Google Faculty Award. Jeremiah Onaolapo
was supported by the Petroleum Technology Develop-
ment Fund (PTDF), Nigeria, while Enrico Mariconti
was funded by the EPSRC under grant 1490017.
9. REFERENCES
[1] Apps Script.
https://developers.google.com/apps-script/?hl=en.
[2] Dropbox User Credentials Stolen: A Reminder To
Increase Awareness In House.
http://www.symantec.com/connect/blogs/
dropbox-user-credentials-stolen-reminder-\
increase-awareness-house.
[3] Hackers Finally Post Stolen Ashley Madison
Data. https://www.wired.com/2015/08/
happened-hackers-posted-stolen-ashley-madison-data/.
[4] Overview of Google Apps Script.
https://developers.google.com/apps-script/overview.
[5] Pastebin. pastebin.com.
[6] The Target Breach, By the Numbers.
http://krebsonsecurity.com/2014/05/
the-target-breach-by-the-numbers/.
[7] S. Afroz, A. C. Islam, A. Stolerman,
R. Greenstadt, and D. McCoy. Doppelg¨anger
ﬁnder: Taking stylometry to the underground. In
IEEE Symposium on Security and Privacy, 2014.
[8] T. W. Anderson and D. A. Darling. Asymptotic
theory of certain “goodness of ﬁt” criteria based
2https://bitbucket.org/gianluca students/gmail-honeypot
on stochastic processes. The Annals of
Mathematical Statistics, 1952.
[9] F. Benevenuto, G. Magno, T. Rodrigues, and
V. Almeida. Detecting Spammers on Twitter. In
Conference on Email and Anti-Spam (CEAS),
2010.
[10] H. Binsalleeh, T. Ormerod, A. Boukhtouta,
P. Sinha, A. Youssef, M. Debbabi, and L. Wang.
On the analysis of the Zeus botnet crimeware
toolkit. In Privacy, Security and Trust (PST),
2010.
[11] D. Boneh, S. Inguva, and I. Baker. SSL MITM
Proxy. http:// crypto.stanford.edu/ ssl-mitm, 2007.
[12] Y. Boshmaf, I. Muslukhov, K. Beznosov, and
M. Ripeanu. The socialbot network: when bots
socialize for fame and money. In Annual
Computer Security Applications Conference
(ACSAC), 2011.
[13] E. Bursztein, B. Benko, D. Margolis,
T. Pietraszek, A. Archer, A. Aquino, A. Pitsillidis,
and S. Savage. Handcrafted Fraud and Extortion:
Manual Account Hijacking in the Wild. In ACM
Internet Measurement Conference (IMC), 2014.
[14] E. Butler. Firesheep.
http:// codebutler.com/ ﬁresheep, 2010.
[15] H. Cram`er. On the composition of elementary
errors. Skandinavisk Aktuarietidskrift, 1928.
[16] A. Das, J. Bonneau, M. Caesar, N. Borisov, and
X. Wang. The Tangled Web of Password Reuse.
In Symposium on Network and Distributed System
Security (NDSS), 2014.
[17] R. Dhamija, J. D. Tygar, and M. Hearst. Why
phishing works. In ACM Conference on Human
Factors in Computing Systems (CHI), 2006.
[18] M. Egele, G. Stringhini, C. Kruegel, and
G. Vigna. COMPA: Detecting Compromised
Accounts on Social Networks. In Symposium on
Network and Distributed System Security (NDSS),
2013.
[19] M. Egele, G. Stringhini, C. Kruegel, and
G. Vigna. Towards Detecting Compromised
Accounts on Social Networks. In IEEE
Transactions on Dependable and Secure
Computing (TDSC), 2015.
[20] T. N. Jagatic, N. A. Johnson, M. Jakobsson, and
F. Menczer. Social Phishing. Communications of
the ACM, 50(10):94–100, 2007.
[21] J. P. John, A. Moshchuk, S. D. Gribble, and
A. Krishnamurthy. Studying Spamming Botnets
Using Botlab. In USENIX Symposium on
Networked Systems Design and Implementation
(NSDI), 2009.
[22] B. Klimt and Y. Yang. Introducing the Enron
Corpus. In Conference on Email and Anti-Spam
(CEAS), 2004.
[23] M. Lazarov, J. Onaolapo, and G. Stringhini.
Honey Sheets: What Happens to Leaked Google
Spreadsheets? In USENIX Workshop on Cyber
Security Experimentation and Test (CSET), 2016.
[24] K. Lee, J. Caverlee, and S. Webb. The social
honeypot project: protecting online communities
from spammers. In World Wide Web Conference
(WWW), 2010.
[25] B. Liu, Z. Liu, J. Zhang, T. Wei, and W. Zou.
How many eyes are spying on your shared folders?
In ACM Workshop on Privacy in the Electronic
Society (WPES), 2012.
[26] N. Nikiforakis, M. Balduzzi, S. Van Acker,
W. Joosen, and D. Balzarotti. Exposing the Lack
of Privacy in File Hosting Services. In USENIX
Workshop on Large-Scale Exploits and Emergent
Threats (LEET), 2011.
[27] N. Nikiforakis, A. Kapravelos, W. Joosen,
C. Kruegel, F. Piessens, and G. Vigna. Cookieless
monster: Exploring the ecosystem of web-based
device ﬁngerprinting. In IEEE Symposium on
Security and Privacy, 2013.
[28] C. Rossow, C. J. Dietrich, C. Grier, C. Kreibich,
V. Paxson, N. Pohlmann, H. Bos, and M. van
Steen. Prudent practices for designing malware
experiments: Status quo and outlook. In IEEE
Symposium on Security and Privacy, 2012.
[29] B. Stone-Gross, M. Cova, L. Cavallaro,
B. Gilbert, M. Szydlowski, R. Kemmerer,
C. Kruegel, and G. Vigna. Your Botnet is My
Botnet: Analysis of a Botnet Takeover. In ACM
Conference on Computer and Communications
Security (CCS), 2009.
[30] B. Stone-Gross, T. Holz, G. Stringhini, and
G. Vigna. The underground economy of spam: A
botmaster’s perspective of coordinating
large-scale spam campaigns. In USENIX
Workshop on Large-Scale Exploits and Emergent
Threats (LEET), 2011.
[31] G. Stringhini, C. Kruegel, and G. Vigna.
Detecting Spammers on Social Networks. In
Annual Computer Security Applications
Conference (ACSAC), 2010.
[32] G. Stringhini and O. Thonnard. That Ain’t You:
Blocking Spearphishing Through Behavioral
Modelling. In Detection of Intrusions and
Malware, and Vulnerability Assessment (DIMVA),
2015.
[33] B. Taylor. Sender Reputation in a Large Webmail
Service. In Conference on Email and Anti-Spam
(CEAS), 2006.
[34] K. Thomas, C. Grier, D. Song, and V. Paxson.
Suspended accounts in retrospect: an analysis of
Twitter spam. In ACM Internet Measurement
Conference (IMC), 2011.
[35] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and
V. Paxson. Traﬃcking Fraudulent Accounts: The
Role of the Underground Market in Twitter Spam
and Abuse. In USENIX Security Symposium,
2013.
[36] D. Wang, Z. Zhang, P. Wang, J. Yan, and
X. Huang. Targeted Online Password Guessing:
An Underestimated Threat. In ACM Conference
on Computer and Communications Security
(CCS), 2016.
[37] G. Wang, T. Konolige, C. Wilson, X. Wang,
H. Zheng, and B. Y. Zhao. You are How You
Click: Clickstream Analysis for Sybil Detection.
In USENIX Security Symposium, 2013.
[38] S. Webb, J. Caverlee, and C. Pu. Social
Honeypots: Making Friends with a Spammer
Near You. In Conference on Email and Anti-Spam
(CEAS), 2008.