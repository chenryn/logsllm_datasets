title:DupLESS: Server-Aided Encryption for Deduplicated Storage
author:Sriram Keelveedhi and
Mihir Bellare and
Thomas Ristenpart
DupLESS: Server-Aided Encryption  
for Deduplicated Storage
Mihir Bellare and Sriram Keelveedhi, University of California, San Diego; 
Thomas Ristenpart, University of Wisconsin—Madison
Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4Server-Aided Encryption for Deduplicated Storage
DupLESS:
Mihir Bellare
Sriram Keelveedhi
Thomas Ristenpart
University of California, San Diego
University of California, San Diego
University of Wisconsin–Madison
Abstract
Cloud storage service providers such as Dropbox, Mozy,
and others perform deduplication to save space by only
storing one copy of each ﬁle uploaded. Should clients
conventionally encrypt their ﬁles, however, savings are
lost. Message-locked encryption (the most prominent
manifestation of which is convergent encryption) re-
solves this tension. However it is inherently subject
to brute-force attacks that can recover ﬁles falling into
a known set. We propose an architecture that pro-
vides secure deduplicated storage resisting brute-force
attacks, and realize it in a system called DupLESS. In
DupLESS, clients encrypt under message-based keys ob-
tained from a key-server via an oblivious PRF protocol.
It enables clients to store encrypted data with an exist-
ing service, have the service perform deduplication on
their behalf, and yet achieves strong conﬁdentiality guar-
antees. We show that encryption for deduplicated storage
can achieve performance and space savings close to that
of using the storage service with plaintext data.
1
Introduction
Providers of cloud-based storage such as Dropbox [3],
Google Drive [7], and Mozy [63] can save on storage
costs via deduplication: should two clients upload the
same ﬁle, the service detects this and stores only a sin-
gle copy. The savings, which can be passed back directly
or indirectly to customers, are signiﬁcant [50, 61, 74] and
central to the economics of the business.
But customers may want their data encrypted, for rea-
sons ranging from personal privacy to corporate policy
to legal regulations. A client could encrypt its ﬁle, under
a user’s key, before storing it. But common encryption
modes are randomized, making deduplication impossi-
ble since the SS (Storage Service) effectively always sees
different ciphertexts regardless of the data. If a client’s
encryption is deterministic (so that the same ﬁle will al-
ways map to the same ciphertext) deduplication is pos-
sible, but only for that user. Cross-user deduplication,
which allows more storage savings, is not possible be-
cause encryptions of different clients, being under dif-
ferent keys, are usually different. Sharing a single key
across a group of users makes the system brittle in the
face of client compromise.
One approach aimed at resolving this tension is
message-locked encryption (MLE) [18]. Its most promi-
nent instantiation is convergent encryption (CE), in-
troduced earlier by Douceur et al. [38] and others
(c.f., [76]). CE is used within a wide variety of com-
mercial and research SS systems [1, 2, 5, 6, 8, 12, 15, 32,
33, 55, 60, 66, 71, 78, 79]. Letting M be a ﬁle’s contents,
hereafter called the message, the client ﬁrst computes a
key K ← H(M) by applying a cryptographic hash func-
tion H to the message, and then computes the ciphertext
C ← E(K, M) via a deterministic symmetric encryption
scheme. The short message-derived key K is stored sep-
arately encrypted under a per-client key or password. A
second client B encrypting the same ﬁle M will produce
the same C, enabling deduplication.
However, CE is subject to an inherent security limita-
tion, namely susceptibility to ofﬂine brute-force dictio-
nary attacks. Knowing that the target message M un-
derlying a target ciphertext C is drawn from a dictio-
nary S = {M1, . . . ,M n} of size n, the attacker can recover
M in the time for n = |S| off-line encryptions: for each
i = 1, . . . ,n, it simply CE-encrypts Mi to get a ciphertext
denoted Ci and returns the Mi such that C = Ci. (This
works because CE is deterministic and keyless.) Security
is thus only possible when the target message is drawn
from a space too large to exhaust. We say that such a
message is unpredictable.
Bellare, Keelveedhi, and Ristenpart [18] treat MLE
formally, providing a deﬁnition (semantic-security for
unpredictable messages) to capture the best possible se-
curity achievable for MLE schemes in the face of the in-
herent limitation noted above. The deﬁnition is based
USENIX Association  
22nd USENIX Security Symposium  179
1
on previous ones for deterministic encryption, a primi-
tive subject to analogous inherent limitations [16,17,27].
The authors go on to show that CE and other mechanisms
achieve their deﬁnition in the random-oracle model.
The unpredictability assumption. The above-mentioned
work puts security on a ﬁrm footing in the case messages
are unpredictable. In practice, however, security only for
unpredictable data may be a limitation for, and threat to,
user privacy. We suggest two main reasons for this. The
ﬁrst is simply that data is often predictable. Parts of a
ﬁle’s contents may be known, for example because they
contain a header of known format, or because the adver-
sary has sufﬁcient contextual information. Some data,
such as very short ﬁles, are inherently low entropy. This
has long been recognized by cryptographers [43], who
typically aim to achieve security regardless of the distri-
bution of the data.
The other and perhaps more subtle fear with regard to
the unpredictability assumption is the difﬁculty of vali-
dating it or testing the extent to which it holds for “real”
data. When we do not know how predictable our data
is to an adversary, we do not know what, if any, secu-
rity we are getting from an encryption mechanism that is
safe only for unpredictable data. These concerns are not
merely theoretical, for ofﬂine dictionary attacks are rec-
ognized as a signiﬁcant threat to CE in real systems [77]
and are currently hindering deduplication of outsourced
storage for security-critical data.
This work. We design and implement a new system
called DupLESS (Duplicateless Encryption for Simple
Storage) that provides a more secure, easily-deployed
solution for encryption that supports deduplication.
In
DupLESS, a group of afﬁliated clients (e.g., company
employees) encrypt their data with the aid of a key server
(KS) that is separate from the SS. Clients authenticate
themselves to the KS, but do not leak any information
about their data to it. As long as the KS remains in-
accessible to attackers, we ensure high security.
(Ef-
fectively, semantic security [43], except that ciphertexts
leak equality of the underlying plaintexts. The latter is
necessary for deduplication.) If both the KS and SS are
compromised, we retain the current MLE guarantee of
security for unpredictable messages.
Unlike prior works that primarily incorporate CE into
new systems, our goal is to make DupLESS work trans-
parently with existing SS systems. DupLESS therefore
sits as a layer on top of existing simple storage interfaces,
wrapping store, retrieve, and other requests with algo-
rithms for encrypting ﬁlenames and data on the ﬂy. This
also means that DupLESS was built:
to be as feature-
compatible as possible with existing API commands, to
not assume any knowledge about the systems implement-
ing these APIs, to give performance very close to that of
using the SS without any encryption, and to achieve the
same availability level as provided by the SS.
We
a
implement DupLESS as
simple-to-use
command-line client that supports both Dropbox [3] and
Google Drive [7] as the SS. We design two versions of
the KS protocol that clients can use while encrypting
ﬁles. The ﬁrst protocol uses a RESTful, HTTPS based,
web interface, while the second is a custom protocol
built over UDP. The ﬁrst
is simpler, being able to
run on top of existing web servers, and the latter is
optimized for latency, and capable of servicing requests
at close to the (optimal) round-trip time of the network.
These protocols and their implementations, which at
core implement an oblivious pseudorandom function
(OPRF) [64] service, may be of independent interest.
To evaluate end-to-end performance, we deploy our
KS on Amazon EC2 [10] and experimentally evaluate
its performance. DupLESS incurs only slight overheads
compared to using the SS with plaintext data. For a
1 MB ﬁle and using Dropbox, the bandwidth overhead
is less than 1% and the overhead in the time to store a
ﬁle is about 17%. We compute storage overheads of as
little as 4.5% across a 2 TB dataset consisting of over
2,000 highly dedupable virtual machine ﬁle system im-
ages that we gathered from Amazon EC2. All this shows
that DupLESS is practical and can be immediately de-
ployed in most SS-using environments. The source code
for DupLESS is available from [4].
2 Setting
At a high level, our setting of interest is an enterprise
network, consisting of a group of afﬁliated clients (for
example, employees of a company) using a dedupli-
cated cloud storage service (SS). The SS exposes a sim-
ple interface consisting of only a handful of operations
such as storing a ﬁle, retrieving a ﬁle, listing a direc-
tory, deleting a ﬁle, etc.. Such systems are widespread
(c.f., [1, 3, 7, 11, 63]), and are often more suitable to user
ﬁle backup and synchronization applications than richer
storage abstractions (e.g., SQL) [37, 69] or block stores
(c.f., [9]). An example SS API, abstracted from Drop-
box, is detailed in Figure 5 (Section 6). The SS performs
deduplication along ﬁle boundaries, meaning it checks if
the contents of two ﬁles are the same and deduplicates
them if so, by storing only one of them.
Clients have access to a key server (KS), a semi-
trusted third party which will aid in performing dedu-
pable encryption. We will explain further the role of the
KS below. Clients are also provisioned with per-user en-
cryption keys and credentials (e.g., client certiﬁcates).
180  22nd USENIX Security Symposium 
USENIX Association
2
Threat model. Our goal is to protect the conﬁdentiality
of client data. Attackers include those that gain access
to the SS provider’s systems (including malicious insid-
ers working at the provider) and external attackers with
access to communication channels between clients and
the KS or SS. Security should hold for all ﬁles, not just
unpredictable ones.
In other words, we seek semantic
security, leaking only equality of ﬁles to attackers.
We will also be concerned with compromise re-
silience: the level of security offered by the scheme to
legitimate clients should degrade gracefully, instead of
vanishing, should other clients or even the KS be com-
promised by an attacker. Speciﬁcally, security should
hold at least for unpredictable ﬁles (of uncompromised
clients) when one or more clients are compromised and
when the KS is compromised.
We will match the availability offered by the SS, but
explicitly do not seek to ensure availability in the face
of a malicious SS: a malicious provider can always
choose to delete ﬁles. We will, however, provide pro-
tection against a malicious SS that may seek to tamper
with clients’ data, or mount chosen-ciphertext attacks,
by modifying stored ciphertexts.
Malicious clients can take advantage of an SS that per-
forms client-side deduplication to mount a side-channel
attack [46]. This arises because one user can tell if an-
other user has already stored a ﬁle, which could violate
the latter’s privacy.1 We will not introduce such side-
channels. A related issue is that client-side deduplica-
tion can be abused to perform illicit ﬁle transfers be-
tween clients [73]. We will ensure that our systems can
work in conjunction with techniques such as proofs-of-
ownership [45] that seek to prevent such issues.
We will not explicitly target resistance to trafﬁc anal-
ysis attacks that abuse leakage of access patterns [48] or
ﬁle lengths [24, 31, 40, 47, 59, 65, 72], though our system
will be compatible with potential countermeasures.
Our approaches may be used in conjunction with exist-
ing mechanisms for availability auditing [13, 41, 51, 70]
or ﬁle replication across multiple services [26]. (In the
latter case, our techniques will enable each service to in-
dependently perform deduplication.)
Design goals. In addition to our security goals, the sys-
tem we build will meet the following functionality prop-
erties. The system will be transparent, both from the per-
spective of clients and the SS. This means that the sys-
tem will be backwards-compatible, work within existing
SS APIs, make no assumptions about the implementation
details of the SS, and have performance closely matching
that of direct use of the SS. In normal operation and for
all clients of a particular KS, the space required to store
1The reader might be interested to note that our experience with the
Dropbox client suggests this side channel still exists.
all encrypted data will match closely the space required
when storing plaintext data. The system should never
reduce storage availability, even when the KS is unavail-
able or under heavy load. The system will not require any
client-side state beyond a user’s credentials. A user will
be able to sit down at any system, provide their creden-
tials, and synchronize their ﬁles. We will however allow
client-side caching of data to improve performance.
Related approaches. Several works have looked at the
general problem of enterprise network security, but none
provide solutions that meet all requirements from the
above threat model. Prior works [42,53,54,58,75] which
build a secure ﬁle system on top of a ﬂat outsourced stor-
age server break deduplication mechanisms and are unﬁt
for use in our setting. Convergent encryption (CE) based
solutions [8, 71], as we explored in the Introduction, pro-
vide security only for unpredictable messages even in the
best case, and are vulnerable to brute-force attacks. The
simple approach of sharing a secret key across clients
with a deterministic encryption scheme [16, 68] fails to
achieve compromise resilience. Using CE with an addi-
tional secret shared across all clients [76] does not work
for the same reason.
3 Overview of DupLESS
DupLESS starts with the observation that brute-force ci-
phertext recovery in a CE-type scheme can be dealt with
by using a key server (KS) to derive keys, instead of set-
ting keys to be hashes of messages. Access to the KS is
preceded by authentication, which stops external attack-
ers. The increased cost slows down brute-force attacks
from compromised clients, and now the KS can func-
tion as a (logically) single point of control for imple-
menting rate-limiting measures. We can expect that by
scrupulous choice of rate-limiting policies and parame-
ters, brute-force attacks originating from compromised
clients will be rendered less effective, while normal us-
age will remain unaffected.
We start by looking at secret-parameter MLE, an ex-
tension to MLE which endows all clients with a system-
wide secret parameter sk (see Section 4). The rationale
here is that if sk is unknown to the attacker, a high level
of security can be achieved (semantic security, except for
equality), but even if sk is leaked, security falls to that
of regular MLE. A server-aided MLE scheme then is a
transformation where the secret key is restricted to the
KS instead of being available to all clients. One sim-
ple approach to get server-aided MLE is to use a PRF
F, with a secret key K that never leaves the KS. A client
would send a hash H of a ﬁle to the KS and receive back
a message-derived key K′ ← F(K, H ). The other steps
are as in CE. However, this approach proves unsatisfying
USENIX Association  
22nd USENIX Security Symposium  181
3
from a security perspective. The KS here becomes a sin-
gle point of failure, violating our goal of compromise re-
silience: an attacker can obtain hashes of ﬁles after gain-
ing access to the KS, and can recover ﬁles with brute-
force attacks. Instead, DupLESS employs an oblivious
PRF (OPRF) protocol [64] between the KS and clients,
which ensures that the KS learns nothing about the client
inputs or the resulting PRF outputs, and that clients learn