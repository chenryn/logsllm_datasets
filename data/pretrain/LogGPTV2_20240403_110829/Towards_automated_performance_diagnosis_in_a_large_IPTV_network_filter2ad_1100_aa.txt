title:Towards automated performance diagnosis in a large IPTV network
author:Ajay Anil Mahimkar and
Zihui Ge and
Aman Shaikh and
Jia Wang and
Jennifer Yates and
Yin Zhang and
Qi Zhao
Towards Automated Performance Diagnosis in a Large
IPTV Network
Ajay Mahimkar§, Zihui Ge‡, Aman Shaikh‡, Jia Wang‡, Jennifer Yates‡, Yin Zhang§, Qi Zhao‡
The University of Texas at Austin§
AT&T Labs – Research ‡
{mahimkar,yzhang}@cs.utexas.edu {gezihui,ashaikh,jiawang,jyates,qzhao}@research.att.com
ABSTRACT
IPTV is increasingly being deployed and offered as a commercial
service to residential broadband customers. Compared with tra-
ditional ISP networks, an IPTV distribution network (i) typically
adopts a hierarchical instead of mesh-like structure, (ii) imposes
more stringent requirements on both reliability and performance,
(iii) has different distribution protocols (which make heavy use of
IP multicast) and trafﬁc patterns, and (iv) faces more serious scala-
bility challenges in managing millions of network elements. These
unique characteristics impose tremendous challenges in the effec-
tive management of IPTV network and service.
In this paper, we focus on characterizing and troubleshooting
performance issues in one of the largest IPTV networks in North
America. We collect a large amount of measurement data from
a wide range of sources, including device usage and error logs,
user activity logs, video quality alarms, and customer trouble tick-
ets. We develop a novel diagnosis tool called Giza that is specif-
ically tailored to the enormous scale and hierarchical structure of
the IPTV network. Giza applies multi-resolution data analysis to
quickly detect and localize regions in the IPTV distribution hier-
archy that are experiencing serious performance problems. Giza
then uses several statistical data mining techniques to troubleshoot
the identiﬁed problems and diagnose their root causes. Validation
against operational experiences demonstrates the effectiveness of
Giza in detecting important performance issues and identifying in-
teresting dependencies. The methodology and algorithms in Giza
promise to be of great use in IPTV network operations.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network Opera-
tions—Network management
General Terms
Management, Performance, Reliability
Keywords
IPTV, Network Diagnosis
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’09, August 17–21, 2009, Barcelona, Spain.
Copyright 2009 ACM 978-1-60558-594-9/09/08 ...$10.00.
1.
INTRODUCTION
In the past few years, we have seen a global ﬂurry among telecom-
munication companies in the rapid roll-out of Internet Protocol
Television (IPTV). IPTV encodes live TV streams in a series of
IP packets and delivers them to users through residential broad-
band access networks. There are two key reasons behind the rapid
growth of IPTV. First, IPTV allows Internet service providers (ISPs)
to strengthen their competitiveness by offering new services such
as triple-play (digital voice, TV, and data) and quadruple-play (dig-
ital voice, TV, data and wireless). Second, IPTV offers users much
greater ﬂexibility and interactivity and opens up opportunities for a
broad range of new applications.
Compared with traditional ISP networks, IPTV distribution net-
works exhibit several unique characteristics. First, IPTV imposes
stringent requirements on both performance and reliability. Even
a small amount of packet loss and delay could seriously impair
the video quality perceived by users (especially those viewing live
sport events). Second, IPTV networks have tremendous scale. A
large IPTV network can already have millions of residential gate-
ways today, and the number is rapidly growing. Third, IPTV heav-
ily relies on IP multicast protocols. Although multicast technolo-
gies have been available for two decades, they start to have wide-
scale deployment and use only recently, and so the operational ex-
perience of multicast is limited. These characteristics impose sig-
niﬁcant challenges in the effective management of IPTV networks.
In this paper, we focus on the characterization and troubleshoot-
ing of faults and performance impairments in one of the largest
commercial IPTV deployments in North America. At the time of
writing this paper, the service provider had well over one million
subscribers spanning four different time zones. We collected large
amounts of diverse measurements both within the residential part of
the IPTV network and from the provider network. These measure-
ments ranged from end device usage/error logs, user activity logs,
video quality alarms and customer trouble tickets. Mining such a
vast and diverse dataset for characterization and troubleshooting is
a challenging problem.
In order to effectively and automatically detect and
Challenges.
troubleshoot performance issues in IPTV networks, we need to ad-
dress the following key challenges.
1. Large number of network devices. Scalability is a big chal-
lenge in effectively managing and troubleshooting IPTV net-
works. There are a vast number of network devices (e.g., mil-
lions of residential gateways), resulting in a tremendous volume
of network data (e.g., event-series) that must be examined for
localizing and troubleshooting performance issues. Mining this
amount of data is a challenging problem.
2. Topological and routing models. Since IPTV uses IP multi-
cast protocols to distribute content to end-users, events in net-
work propagate from the root of the multicast tree towards the
231end-users (i.e., leaves in the tree). It is important to take the im-
pact scope of network events into account when troubleshoot-
ing a performance problem. Blindly analyzing data without
considering the topological and routing models can easily lead
to an information “snow” of results and overwhelm the network
operations team with false alarms.
3. Skewed event distribution. The majority of individual event-
series have very small frequency count. This makes it challeng-
ing for performing statistical analysis due to insufﬁcient sample
size. Thus, there is a need to perform aggregation of events,
both in space (across different locations) and in time (over dif-
ferent aggregation intervals).
4. Discovery of causal dependencies among events. During per-
formance troubleshooting, network operations team are inter-
ested in identifying dependencies between symptom1 events
and other network events. It is challenging to accurately dis-
cover causal dependency among different events because of (i)
diversity of events, ranging from point events (e.g., router logs)
to range events (e.g., 5-minute summarized SNMP data), (ii)
inaccurate event timestamps due to measurement artifacts, im-
perfect clock synchronization, and limited clock resolution, and
(iii) distributed event propagation, which may cause an event to
be recorded long after when it had impacts.
In this paper, we present the ﬁrst characteri-
Our contributions.
zation study of performance issues and faults in operational IPTV
networks. The study provides interesting insights into the distri-
bution of events, spatio-temporal locality, and time-of-day effects.
For fault localization and performance troubleshooting in IPTV
networks, we develop Giza, a multi-resolution infrastructure that
includes a suite of novel statistical data mining techniques.
1. To cope with a vast number of network devices and network
event-series, Giza ﬁrst applies hierarchical heavy hitter detec-
tion to identify the spatial locations where the symptom events
are dominant. The hierarchy for spatial locations is created us-
ing the IPTV multicast tree structure. This greatly reduces the
amount of data for subsequent processing. Focusing on the hi-
erarchical heavy hitters also gives sufﬁcient sample points to
perform further statistical analysis.
2. Giza applies statistical event correlation analysis at heavy hit-
ter locations to identify those event-series that are strongly cor-
related with the heavy hitter symptom. The list of strongly cor-
related event-series includes both potential root causes and im-
pacts of the symptom event.
3. Giza applies statistical lag correlation and ℓ1 norm minimiza-
tion techniques to discover the causal dependencies between
events. It constructs a causal dependency graph for each symp-
tom event-series. The graph generated by Giza is sparse and
helps network operators to effectively and automatically diag-
nose symptom events. The discovery process requires minimal
domain knowledge.
We evaluate Giza using data collected from an operational IPTV
network and service. Our data sources include both the provider
network and the customer home networks. We demonstrate that
our assumptions about multi-resolution analysis are indeed valid.
We also show that the causal discovery algorithm used in Giza out-
performs a state-of-art approach known as WISE [28]. In addition,
we apply Giza in diagnosing the causes of customer trouble tickets
and validate our conclusions against those obtained via operational
1A symptom event is an event that is indicative of a network prob-
lem and is observable to the network operations team.
It is the
target event that the network operation team tries to troubleshoot
and diagnose.
Servers
Local Channel
Servers
SHO
VHO
IO
CO
DSLAM
Super
Head−end
Office
Video
Head−end
Office
Intermediate
Office
Central
Office
DSL
Access
Multiplexer
Customer Home Network
TV
Set Top Box
Residential
Gateway
Personal
Computer
Phone
Figure 1: IPTV service architecture.
experiences. Our results demonstrate that Giza has the promise to
be an effective tool in identifying and troubleshooting performance
problems.
Paper organization: The rest of this paper is organized as follows.
We provide an overview of a large IPTV service and characterize
interesting network activities and performance issues for both the
provider network and customer home networks in Section 2. Sec-
tion 3 presents the system design and detailed description of Giza.
We validate Giza, compare it with a previously published solution –
WISE, and illustrate the usage of Giza in a case study in Section 4.
Section 5 summarizes the related work and Section 6 concludes the
paper.
2.
IPTV NETWORK PERFORMANCE
CHARACTERIZATION
In this section, we ﬁrst present an overview of the IPTV service
architecture and the data sets we use in this paper. We then present
characterization results and motivate a multi-resolution troubleshoot-
ing system in troubleshooting performance issues in IPTV networks.
2.1 Overview of IPTV Service
Fig. 1 shows the architecture of how IPTV service is delivered
to residential customers by the service provider. In an IPTV sys-
tem, live TV streams are encoded in a series of IP packets and
delivered through the residential broadband access network. The
SHO (Super Head-end Ofﬁce), which is the primary source of na-
tional television content, digitally encodes video streams received
externally (e.g., via satellite) and transmits them to multiple VHOs
(Video Head-end Ofﬁces) through a high-speed IP backbone net-
work. The VHOs, each responsible for a metropolitan area, in turn
acquire additional local contents (e.g., local news), perform some
further processing (e.g., advertisement insertion) and transmit the
processed TV streams to end users upon request. Depending on the
service provider, these TV streams go through a various number of
routers or switches such as intermediate ofﬁces (IO), central ofﬁces
(CO), and digital subscriber line access multiplexer (DSLAM) be-
fore reaching a residential home.
Inside a home, an RG (Residential Gateway) serves as a modem
and connects to one or more STBs (Set-Top Boxes). It receives and
forwards all data, including live TV streams, STB control trafﬁc,
VoIP and Internet data trafﬁc, into and out of the subscriber’s home.
Finally, each STB connects to a TV.
We use the terminology and pyramid hierarchy as shown in Fig. 2
to determine events at different aggregation levels. A DSLAM
serves multiple STBs, a CO serves multiple DSLAMs, an IO serves
multiple COs, a VHO serves multiple IOs, and ﬁnally, an SHO
serves content to all VHOs.
It is worthwhile to note that live IPTV streams are delivered
from SHO to residential home via native IP multicast in order to
save bandwidth consumption in the network.
In addition to live
TV channels, STBs also support advanced features such as digital
video recording (DVR), video on demand (VoD), picture-in-picture
(PIP), high deﬁnition (HD) channels, choice programming, online
gaming and chatting.
232Region
Metro
SHO
VHO
IO
CO
DSLAM
STB or RG
Figure 2: Pyramid structure in IPTV network.
2.2 Data Sets
We collected a large variety of data from one of the largest com-
mercial IPTV service providers in North America. As of the end of
2008, this IPTV service provider has over one million subscribers
(i.e., residential homes), and over two million STBs in use. Our
data set consists of four types of data: customer care call records,
video quality alarms, home network performance/activities, and
provider network performance/activities.
Customer care call records. We obtained complete customer call
records from the IPTV service provider. A customer call can be
related to provisioning, billing and accounting, or service disrup-
tion. In this paper, we mainly focus on the customer calls regarding
service disruptions, each of which results in a trouble ticket associ-
ated with a type of the performance issues, the start and end times,
the customer account number, etc. The common customer trouble
tickets include picture freezing on TV screen, audio and video out
of synchronization, DVR black screen, program guide issues, high
deﬁnition issues and parental control issues.
Video quality alarms. We obtained alarms data from the video
quality monitors deployed within the IPTV service provider net-
work. The monitors gather statistics such as packet loss, packet de-
lay and outage durations. These statistics are then used as a quality
indicator for video.
Home network performance/activities. There are several event
traces collected from each STB including power state, resets, and
crashes. The STB power state logs indicate when the STB was
turned on and turned off. This data can be used to identify the active
STBs at any point of time. The STB reset logs provide information
on when the STB was rebooted by the user. Finally, the software
running on an STB may occasionally crash which is also recorded
in the log. For each crash, the log contains information about the
time and type of the event. In addition to the STB logs, we also
obtained the reboot log for each RG, which indicates when the RG
was rebooted.
Provider network performance/activities. We obtained SNMP
MIBs and traps data from every SHO, VHO, IO, and CO. The
SNMP data provide performance statistics such as packet and byte
counts, packet loss, and CPU utilization. We also obtained Syslogs
from devices at every SHO and VHO. These logs provide informa-
tion about state changes for control plane protocols and error con-
ditions of the devices. Examples include multicast neighbor loss,
OSPF adjacency state changes, and BGP session changes.
2.3 Characterizing IPTV Performance Issues
We conducted our analysis over three-month data collected in
2008. We present the characterization results focusing on spatial
and temporal patterns of various performance related events ob-
served along the paths from the SHO to STBs.
2.3.1 Customer Trouble Tickets
We analyze the trouble tickets that were triggered by customer
Ticket category
Live TV video
Requested information or upgrade
Digital video recording (DVR)
Remote control
Equipment (STB, RG, PC)
High deﬁnition (HD)
Audio
Program guide
Video on demand (VoD)
Parental control
Others
Percentage
46.5
12.9
9.6
8.2
7.7
4.4
3.5
1.6
1.6
1.6
2.4
Table 1: IPTV customer trouble tickets.
calling for performance related issues. Based on the nature of the
reported performance issues, we classify customer trouble tickets
into different categories. Table 1 shows the distribution of num-
ber of tickets for the top ten categories. We observe that “live TV
video” related performance issues (e.g., video quality, blue screen
on TV, picture freezing or no picture on TV) constitute almost half
of the trouble tickets. This is not surprising because live TV chan-
nels are the basic service offered to customers. When there is any
performance issue on the IPTV service, it is likely to be noticed and
reported by customers as live TV video related problem. The cat-
egory “requested information or upgrade” ranks the second on the
list. The trouble tickets in this category indicate that the customer
was experiencing some performance issues and requested further
information. Other top categories range from DVR and remote con-
trol related issues to video on demand and parental control related
issues.
2.3.2 Video Quality Alarms
We analyze the video quality alarms reported by the video mon-
itors. The Media Delivery Index (MDI) is a measurement that
is used as a quality indicator for video and streaming media.
It
comprises of two elements: delay factor (DF) and media loss rate
(MLR). The delay factor is the maximum difference between the
arrival of a packet and its playback. It indicates the time duration
over which a packet stream must be buffered in order to prevent
packet loss. The ideal DF score is the packet size. The media loss
rate is the number of lost or out-of-order packets within a time in-
terval. The ideal media loss rate is 0%. We analyze one month
worth of data and identify that the alarms related to delay factor
contribute to the majority (around 79%). Other important video
quality alarms include high media loss rate, video stream outages,
transport stream outages, high ﬂow bit rates, high transport stream
bit rates and synchronization errors.
2.3.3 Home Network Performance/Activities
We characterize a variety of data traces collected from STB, and
RG including STB crash, reset, power state and RG reboot. Ta-
ble 2 shows the distribution of STB crash events. There are mainly
four types of crashes: managed, native, out of memory and watch
dog reboot. All managed code runs in a protected environment.
Some events in this environment are considered fatal and will ter-
minate the Microsoft Mediaroom application, generating a man-
aged crash log in the process. Native crash events occur outside
of the protected Microsoft Mediaroom common language run-time
(CLR). Examples of native crash events are the crashes in the de-
vice drivers, and low level non-application code. The managed and
native crash events are vast majority of all the STB crashes. The
watch dog reboot occurs when the STB hangs in the low level ker-
nel resulting in the watch dog timer expiry. This type of crash con-
tributes to nearly 20% of all STB crash events. Finally, there is a
small percentage of crashes caused by out of memory error. This
occurs when the STB native layers run out of memory.
Fig. 3 shows the distribution of the number of simultaneous na-
tive STB crash events occurring within a ﬁxed time-bin of ﬁve min-
233Crash
type
Native Managed Watch dog
Percentage
44.9
35.9
reboot
18.4
Out of
memory
0.5
Others
0.2
Table 2: STB crash events.
STB Crash − Native
DSLAM
DSLAM
CO
CO
Metro
Metro
Region
Region
2