Finally, Szekeres et al. [29] introduced the concept of Code-Pointer Integrity
(CPI), the requirement to enforce the integrity of code pointers in memory. An
implementation of CPI that is based on memory splitting was then proposed
by Kuznetsov et al. [18]. In their work they introduce a compile time instru-
mentation approach that protects control ﬂow relevant pointers. The basic idea
thereby is to separate control ﬂow relevant pointers into a separated space in
memory and to limit access to that area. Thus they split process memory into a
safe region and a regular region, where the safe region is secured by the kernel
and can only be accessed via memory operations that are autogenerated and
proven at compile time [18]. However, Evans et al. [10] showed that restricting
access to pointers in memory is not enough, since this separation can still be
broken with the help of side channel attacks.
Counteracting Data-Only Malware with Code Pointer Examination
183
5 Approach
In this work we aim to detect the control data structure of persistent data-only
malware. In the process, we want to achieve three main goals:
Isolation. Since the main goal of our framework is to detect rather than to
prevent kernel data-only malware infections, it is crucial that the detection
framework is strongly isolated from the monitored target system. This is
why we will leverage virtualization as a building block for our framework.
Performance. The overhead incurred by our detection framework on the mon-
itored system should be as small as possible. Since we use virtualization as
a foundation for our framework, it is thereby of particular importance that
we keep the number of Virtual Machine (VM) exists as small as possible as
they will heavily impact the performance of the overall approach.
Forensic. Due to the ever increasing number of malware attacks, the investiga-
tion of incidents becomes more and more important in order to understand
the approach of an successful attacker and to avoid future breaches. This is
why another crucial goal of our framework is to support forensic investiga-
tions in addition to live monitoring. In this regard, its particular important
that an human investigator can easily assess and analyze the situation once
an anomaly is detected by our framework.
The key idea behind our approach is to detect persistent data-only malware
based on its control structure. As described in Sect. 2, the control structure is the
most important component of data-only malware that essentially deﬁnes which
reused instruction sequence should be executed when. Due to this property it
is comparable to the code section of traditional malware, which makes it highly
suitable as a basis for a detection mechanism.
To detect the control structure in memory, we use a three-step process. In the
ﬁrst step, we start by checking the integrity of important control ﬂow related
kernel objects. This is done for multiple reasons. First, we can use additional
contextual information about these kernel objects, and second, these objects
contain a lot of code pointers by design. By validating these objects at the
beginning, we can increase the performance of our approach, as the code pointer
within these known objects do not need to be validated in the following steps.
We refer to this step as Kernel Object Validation.
In the second step, we identify all code pointers within the kernel’s memory
space. Based on this information, in the third step we classify the identiﬁed code
pointers into benign and malicious code pointers applying multiple heuristics.
The combination of these latter two steps is the Pointer Examination phase.
Figure 1 provides an overview of this process. In the following, we describe these
steps in more detail. For the sake of simplicity, we thereby focus on the Intel
x64 64 bit architecture and the Linux OS. However, most of what we present is
equally applicable to other OSs such as Windows. While this section provides
an overview of our approach, we defer a discussion of the implementation details
to Sect. 6.
184
T. Kittel et al.
Fig. 1. Pointer classiﬁcation within the proposed framework.
5.1 Control Flow Related Data Structures
We ﬁrst describe control ﬂow relevant kernel objects that we check using special
semantic knowledge in the ﬁrst step of our process.
Kernel Dispatcher Tables and Control Flow Registers. The most tra-
ditional control ﬂow related data structures are the system call table and the
interrupt descriptor tables. As control ﬂow related data structures have already
seen a lot of attention, we only mention this type of data structures here for
sake of completeness. Our system checks every entry within these tables and
ensures that it points to the correct function. This can be done by comparing
the entire object to the corresponding version inside a trusted reference binary.
In this step, we also validate the values of all control ﬂow relevant registers such
the model-speciﬁc registers MSRs and the Debug registers.
Tracepoints. Tracepoints are another type of data structure that is control ﬂow
relevant. An administrator can use the tracepoints feature to insert arbitrary
hooks into the kernel’s control ﬂow that are executed whenever a certain point
in the kernel’s control ﬂow is hit and the corresponding tracepoint is enabled.
The addresses of the callback functions are stored in a list and are sequentially
called by the kernel once the tracepoint is triggered. Tracepoints impose a big
problem for control ﬂow integrity validation as arbitrary function addresses can
be inserted into all tracepoint locations at runtime. To counter this threat, we
ensure that every hook that is installed with this mechanism calls a valid function
within the Linux kernel.
Control Structures For Kernel Runtime Patching. To manage diﬀerent
runtime-patching mechanisms, the kernel maintains a variety of data structures.
These data structures in turn contain pointers to kernel code, as they need
to store the locations where kernel code should be patched at runtime. In our
approach we check the integrity of the related data structures.
Kernel Stacks. Another examined type of data structure is the kernel stack of
each thread in the system. We separate each kernel stack into three parts: At the
Counteracting Data-Only Malware with Code Pointer Examination
185
very beginning of the stack, the active part of the stack is located. This part is
empty if the corresponding process is currently executing in userspace. Next to
the active part of the stack, old obsolete stack content is residing. On the very
top of the stack, after all usable space, resides a structure called thread info.
It contains the thread’s management information, for instance a task struct
pointer and the address limit of the stack.
While it is possible to validate the active part of the stack and its manage-
ment structure, an attacker could use the old, currently unused stack space to
hide persistent data-only malware. Therefore, this space is ﬁlled with zeros by
our framework when used in live monitoring mode. Otherwise the unused stack
regions are displayed to the forensic analyst for diagnosis and veriﬁcation.
5.2 Pointer Identiﬁcation
After we have validated control ﬂow relevant data structures, we identify all other
code pointers in memory in the second step. To identify code pointers, ﬁrst of
all we need to obtain a list of all executable memory regions within kernel space.
For this purpose, we make use of the page tables used by the hardware. We also
generate a list of all readable pages that do not contain code, as these pages
contain the kernel’s data. Note that using this approach we are also able to
support Address Space Layout Randomization (ASLR).
Equipped with a list of all kernel code and data pages, we identify all kernel
code pointers by iterating through each data page byte by byte and interpreting
each 64-bit value as a potential pointer. If the potential pointer points to a code
region (i.e., the 64-bit value represents an address lying within one of the code
pages), we consider it to be a code pointer. While it seems that this very simple
approach might produce many false positives, we like to stress that we did not
observe any false positives during our experiments with various 64-bit Linux
kernels. In our opinion the primary reason for this is that the 64-bit address
space is much larger than the former 32-bit address space and makes it thus
much more unlikely that non pointer values looking like pointers appear within
memory.
5.3 Pointer Classiﬁcation
After we have found a pointer, we classify it based on its destination address in
order to decide whether it is malicious or benign. In a legitimate kernel there are
multiple targets which a pointer is allowed to point to. In the following, we list
those valid targets and describe how we are able to determine to which category
the pointer belongs to.
Function Pointers. One important type of kernel code pointers are function
pointers, which are frequently used within the kernel. To determine whether
a code pointer is a function pointer, we make use of symbol information that
is extracted from a trusted reference binary of the monitored kernel. Amongst
these symbols are all functions that the kernel provides. We leverage the symbol
186
T. Kittel et al.
list to verify whether a code pointer points to a function or not. In the former
case, we consider the pointer to be benign. Otherwise, we continue with the
classiﬁcation process in order to determine whether the code pointer belongs
to one of the other categories discussed below. Note that this implies that our
approach might still be vulnerable to data-only malware that solely makes use
of return-to-function (ret2libc).
Return Addresses. Another important type of code pointers are return
addresses. In contrast to a function pointer, which must point to the beginning
of a function, a return address can point to any instruction within a function
that is preceded by a call instruction. To identify whether a code pointer is a
return address, we leverage multiple heuristics. Note that most of the return
addresses are located on a stack which is already checked during the Kernel
Object Validation phase.
Pointers Related to Runtime Patching. A third type of pointer destinations
are addresses that are stored by the kernel and point to a location where dynamic
code patching is performed. While most of these pointers are contained within spe-
cial objects that are checked in the Kernel Object Validation step as previously
described, there are still some exceptions that must be considered separately.
Unknown Pointer Destinations. Any code pointer pointing into executable
code which can not be classiﬁed into one of the above categories is considered
to be malicious.
As we intend to identify kernel level data-only malware with our approach
and we assume that the malware is persistently stored in memory, we propose
to execute CPE in regular intervals.
6 Implementation
After describing the general idea of our approach, we cover the details of our
implementation in this section. The code pointer examination framework pre-
sented in this work is based on our kernel code integrity framework [17]. This
framework provides multiple advantages for our implementation:
First, it keeps track of all kernel and module code sections and ensures their
integrity during runtime. In addition, it keeps track of all functions and symbols
that are available inside the monitored kernel, as it already resembles the Linux
loading process. This ensures that the information about the monitored kernel
is binding by its nature, that is, it reﬂects the actual state of the monitored
system. In our implementation we can use this database as a ground truth to
classify kernel code pointers.
Secondly, the underlying framework keeps track of all dynamic runtime code
patching that is conducted by the Linux kernel. We use this information to
identify and validate data structures that are related to kernel runtime patching.
Third, our approach is usable for multiple hypervisors, while most of the fea-
tures can also be used to analyze memory dumps in a forensic scenario. Currently
tests have been conducted with both KVM as well as XEN.
Counteracting Data-Only Malware with Code Pointer Examination
187
6.1 Kernel Object Validation
Before we scan the kernel’s memory for pointers, we check the integrity of impor-
tant kernel data structures. This allows to minimize the parts of kernel data that
may contain arbitrary function pointers or other pointers into executable kernel
code. The validation of those structures leverages semantic information about
the kernel that was generated by the underlying code validation framework or
manually collected while analyzing the kernel. In the following, we only list a
couple of examples to illustrate the requirement of this step.
First, we validate various dispatcher tables and the kernel’s read-only data
segments. These locations usually contain a lot of kernel code pointers, whereas
the target of each pointer is well deﬁned. The validation is performed by com-
paring these objects to the trusted reference versions of the binaries that are
loaded by the underlying validation framework.
Next, we validate kernel data structures used for runtime patching. These are
jump table), SMP Locks ( smp locks),
for example: Jump Labels ( start
Mcount Locations ( start mcount loc), and Ftrace Events ( start ftrace
events). To validate these structures we semantically compare them to the
data extracted from trusted reference binaries by the underlying framework. In
addition to these runtime patching control data structures, there also exist data
structures in the kernel that are used to actually conduct the runtime patch. For
clariﬁcation, we discuss one example for legitimate kernel code pointers related
to self-patching: the kernel variables bp int3 handler and bp int3 addr.
To understand why these pointers are required, we explain how runtime
patching takes place in the Linux kernel. If the kernel patches a multibyte instruc-
tion in the kernel, it can not simply change the code in question. The kernel’s
code would be in an inconsistent state for a short period of time, which might
lead to a kernel crash. Thus, the kernel implements a special synchronization
method. It ﬁrst replaces the ﬁrst byte of the change with an int3 instruction.
As a result, every CPU trying to execute this instruction will be trapped. Then
the rest of the space is ﬁlled with the new content. As a last step, the kernel
replaces the ﬁrst byte and notiﬁes all waiting CPUs. During this process the
address containing the int3 instruction is saved in the variable bp int3 addr.
This enables the int3 interrupt handler upon invocation to determine whether
the interrupt originates from the patched memory location or not. While the
interrupt handler will simply process the interrupt normally in the latter case, it
will in the former case invoke a speciﬁc handler whose address is stored within
the variable bp int3 handler. In the case of a patched jump label, for example,
the handler variable will point to the instruction directly after the patched byte
sequence, which eﬀectively turns the sequence into a NOP sequence during the
patching process. Since both of the bp int3 variables are not reset after patching
is complete, they always point to the last patched location and the last handler
respectively. To solve this issue, our framework checks whether the current value
of the bp int3 addr points to a self patching location and if the handler address
matches the type of patching conducted.
188
T. Kittel et al.
Finally, we iterate through all pages that contain a stack. Each process run-
ning in a system owns its own kernel stack that is used once the application issues
a system call. To gather the addresses of all stacks from the monitored host, we
iterate through the list of running threads (init task.tasks) and extract their
corresponding stacks. In case the process is not currently executing within the
kernel, the current stack pointer is also saved within that structure. Ideally the
process is currently not executing in kernel space in which case its stack must
be empty. Otherwise we must validate the contents of the stack.
In order to validate a stack we use the following approach: For each return
address found on the stack, we save the addresses of two functions. First, we save
the address of the function that the return address is pointing to (retFunc).
In addition, we also extract the address of the target, of the call instruction
preceding the return address (callAddr). This is possible, since in most cases, the
destination of the call is directly encoded in the instruction, or a memory address
is referenced in the instruction that can in turn be read from the introspected
guest system’s memory.
This information is then used to validate the next return address that is found
on the stack. In particular, the callAddr of the next frame needs to match the
retFunc of the previous stack frame, as the previous function must have called
the function, that the return address is pointing to.
Since it is not possible to extract all call targets using the method described
above, we use an additional mechanism to extract all possible targets of indirect
calls: we monitor the execution of the test systems in a secure environment
and activate the processor’s Last Branch Register (LBR) mechanism in order
to extract the call and the target address of every indirect branch instruction
executed by the system’s CPU. Using this mechanism we generated a whitelist
of targets for each call for which the target address is generated during runtime.
This list is then also used by our stack validation component. With this we
were, in our experiments, able to validate most of the kernel stacks within our
test system. While this mechanism is not perfect yet, it certainly reduces the
attack surface further.
The entire problem arises because the stack is currently not designed to
be veriﬁable even under normal circumstances. However, the kernel developers
currently discuss an enhancement to the code that would make stack validation