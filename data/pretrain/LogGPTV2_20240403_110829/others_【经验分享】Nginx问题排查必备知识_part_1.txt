**假如日志欺骗了你，不要悲伤，看下这篇文章吧。**
## 1 前言
        在日常排查问题或者同用户连调的时候，是否经常会遇到，在access_log 里看到用户请求很快，但用户却反馈很慢；
    在日志中看到用户的请求都成功了，用户却反馈说有大量失败失败等一系列自己看到的和用户描述不一致的问题，有时候会
    怀疑用户搞错了，等用户贴出截图的时候又怀疑自己搞错了，如果有遇到这类问题，这篇文章或许对你有帮助。
        本文主要介绍了Nginx中关于“时间”及”缓存“的一些问题，介绍一些问题发生的原因，并从用户角度及服务端角度尝
    试分析这些问题。
## 2 Nginx打access_log 时机
        在接着往下介绍之前，先看下Nginx打access_log 的时机，清楚了这个后，再接着往下看会清晰很多。
    Nginx的access_log 是在Nginx”认为“这个请求结束后才打的，对于正常请求，Nginx会在请求最后一个字节发出
    后认为请求结束；对于异常请求，当Nginx判断连接超时或者异常断开，无法再发送和接收数据的时候。通常情况下可以认
    为Nginx在请求结束后随即会打出日志。
## 3 如何理解Nginx的"请求最后一个字节发出"
        Nginx认为请求最后一个字节发出后，该请求就结束了，其实最后一个字节发出可以理解为最后一串数据发出，这里
    是“发出“ 而不是用户收到，指的是将最后一串数据填到协议栈中，只要send 成功返回，Nginx就认为结束了，至于数
    据是否被客户端收到那就是协议栈和网络上的事情了，Nginx不会去关心。 
## 4 为什么服务端看到的延时同客户端不一致
### 4.1 服务端 request_time_msec 的含义
        要搞清楚这个问题，首先我们要明确Nginx access_log 中的“request_time_msec” 字段到底表达了什么含义。
    我们先看下官方文档是怎么说的：
    $request_time
        request processing time in seconds with a milliseconds resolution; time elapsed between 
    the first bytes were read from the client and the log write after the last bytes were sent 
    to the client
    这个字段表示的是从请求的第一个字节开始到请求最后一个字节发出后所经历的时间。
    这里其实包含如下几点信息：
    1 建连的时间是不会被算进去的。
    2 如果是HTTPS 请求，建连及HTTPS 握手的时间都不会被算进去。
    3 最后一个字节发出后Nginx认为请求结束，数据仅仅是填在协议栈中，从协议栈Buffer中的数据发送给用户的这段时间
      是不被算进去的。
    4 连接挥手的过程是不会被算进去。
    注：从长连接的角度去看，上述1、2、4的时间不被算进去还是好理解的。
​    
### 4.2 客户端看到的E2E 时间
    4.1 中分析的request_time_msec从服务器端看到的请求E2E 时间，而用户看到的时间，假设用户用curl 去测试：
        time curl https://bucket.oss-cn-hangzhou.aliyuncs.com/object
    那么上面4.1 提到的几点不会算到服务器端时间的计算逻辑里的，除了4都会被客户端计算进去。
    针对延时不一致，下面我们从HTTP 的上传下载，具体分析一下这个延时区别，是否差，差多少。
### 4.3 上传类请求延时差异  
        针对于上传来说，服务器端和客户端看到的延时差异不大，相差一个握手/和最后返回的Header发送回去的时间。
    握手到服务器端收到请求首字节 2rtt，请求完成后返回的HEADER 数据一般不会很大可以塞在1个cwnd 内发完，需要一个0.5 
    个 rtt，，一共是2.5个rtt。 如果是长连接，忽略三次握手的话，那么看到的差异为1个rtt。
        因此针对上传类请求，客户端和服务器端看到的延时差距为2.5 个RT，如果是长连接(非连接上首个请求）的话差异为1个rtt。
### 4.4 下载类请求延时差异 
        关于下载请求的延时差异会稍微复杂一些。上传的情况下，服务器只会有HTTP 状态码和一些HTTP Header，通常一个rtt 就
    可以发完。 而下载，通常服务器会有较多的数据发送给客户端，Nginx把最后一串数据填在协议栈的Buffer里，如果再Buffer 
    中的数据能在一个rtt内发完，那么同上传类请求一致，否则就会比上传类请求的差异大。至于协议栈Buffer 中最后一串数据花多
    长时间能发送到客户端，这个就不太好估计了，取决于当时的网络状况及当时的用塞窗口大小，需要具体情况具体分析。
       在网络情况不错并且服务器端Buffer 配置较小情况下，通常差距不大，但是如果客户端网络差，而服务器端Buffer 配置较大
    的情况下，差距会比较大。比如此时客户端网络比较差，只达到100KB/s, 而服务器端协议栈Buffer 配置的较大，为1M，Nginx
    最后一串数据把1M Buffer 填满后Nginx认为请求已经结束了，而实际上客户端在10s 之后才完整的收到请求应答数据，才认为结
    束。大家可以用wget 测试一下，分别观察下服务器端和客户端看到的请求时间：
    wget your-bucket.oss-cn-hangzhou.aliyuncs.com/tmp/1m-file --limit-rate=10k --debug
    注： wget 这个限速是在应用层面做的，测试看到的时间差异除了服务端Buffer 的原因，还有客户端Buffer 的原因，数据到达客
    户端协议栈，而应用因限速而迟迟不读。
### 4.5 总结
        服务器端看到的E2E 时间“request_time_msec” 时间是Nginx收到请求的首字节开始，到最后一个字节写到协议栈的时间。
    客户端看到的E2E时间相比服务器多了：客户端建联及HTTPS 握手时间、请求首字节发送到服务器的时间、外加Nginx认为请求结束
    后协议栈将Buffer中的数据递送到客户端的时间。
        因此当客户抱怨延时高而服务器端看到却很快的时候，可能客户说的也对，你看到的也对，这时候就需要根据上述分析，判断具体
    是哪里导致客户端和服务器端看到延时差距，进而快速定位问题。
 **服务器端慢是真的慢，但是服务器端看到快，可不一定真的快。**   
## 5 服务器端看到的请求成功和客户端看到的请求成功
    接下来分析的都是小概率事件，正常情况下通常不会遇到，主要针对出问题时的分析。
    服务器端看到的成功，是服务器端正确处理这个请求，并把数据发送到协议栈后，服务器就会认为请求已经成功。
    客户端看到请求成功，是收到服务器端返回的状态码及完整的body 后才认为请求成功。
### 5.1 access_log 看到的200 OK
    access_log 里的状态码，只要请求的header 已经发出去，那么状态码就确定了，access_log 里面打出来的状态码也是确定的。
    如果是上传类请求，access_log 里打印出状态码为200，那么请求一定是成功了（但是客户端不一定能感知到这个成功）。
    如果是下载类请求，access_log 里打印出来的状态码是200，那么请求不一定成功，可能body 并未发完请求就异常结束了。
### 5.2 写到协议栈里的数据不一定能发送出去
        Nginx把数据写到协议栈的Buffer中后，从Nginx的角度来说，可以认为数据已经发往客户端了，但从实际角度来看，数据写
    到协议栈仅仅是写到协议栈，至于写到协议栈的数据是否能否真正被发送出去，是不一定的。在协议栈数据还没发出去之前可能网络中
    断了，或者连接被reset 了，都会可能发生。这是造成客户端和服务器端看到有差异的一个主要原因。
      有的同学会问，TCP 不是可靠的传输协议嘛，怎么会发不过去？建议看下这篇文章，就明白TCP 的可靠性具体指的是什么了
      https://blog.csdn.net/dog250/article/details/82177299
## 6 单连接最低下载速度
### 6.1 为什么会有最低下载速度限制
        针对系统性能指标，通常我们会描述一个单连接峰值吞吐的数值，但是实际上一个还有一个最低速度的限制。那么这个最低速度是
    怎么来的呢。
        一个正常C/S 架构的系统，通常会有很多Buffer，会设置很多超时时间，针对Nginx会有send_timeout，recv_timeout，