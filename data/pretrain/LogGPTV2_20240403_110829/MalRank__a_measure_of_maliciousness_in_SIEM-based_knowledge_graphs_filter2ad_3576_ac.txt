t ∈Txy
y∈N(x)
t ∈Txy
mi
yx(t)
ˆωi
yx(t)



mi


(3)
(4)
0,
yx(t) = [si(y) − (1 − cso(x))
mi +1
t ∈Txy
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
t ∈Tzx
echo cancellation
z∈N(x)
xy(t)
ωi
zx(t)
]. ˆωi +1
yx(t)
ksi(y) + (1 − k).ωo
ˆωi +1
yx(t) =
yx(t) is the MalRank score sent from node y to node x in
iteration i + 1 over edge type t. si(x) is the MalRank score of node
x in iteration i.
where mi +1
yx(t) ,
(5)
xy(t) = 0
if ωo
otherwise
4 EXPERIMENT: SIEM-BASED KNOWLEDGE
GRAPH AND MALRANK
In this section, we present the details of our experiments running
MalRank on a real-world SIEM-based knowledge graph.
4.1 Experiment Setup
4.1.1 Dataset Description. For the purpose of this research, we
used two days of proxy, DNS, and DHCP logs (almost 3 billion
events) collected by a large international enterprise SIEM, spanning
over 3 TB. For details refer to appendix A.1 table 5.
The described event logs were later enriched with related OSINT
as described in Section 2, i.e., ASN, X.509 certificates, and DNS RRs.
In this regard, we used the sanitized version of the BGP prefixes,
origin ASNs4, and ASN to organization name mapping5 available at
thyme.apnic.net. These files span to approximately 20 MB total. For
X.509 certificates we used censys6 IPv4 snapshot which consists of
the entire IPv4 address space scanned for all ports. This data spans
over 1.2 TB of disk space. Note that, we were only interested in port
443 scans. Due to the enterprise’s configuration for DNS servers
to not log the DNS responses (DNS RRs), we had to pass all the
DNS queries (logged by the DNS server) to our active OSINT-DNS
4http://thyme.apnic.net/current/data-raw-table
5http://thyme.apnic.net/current/data-used-autnums
6https://censys.io/
enricher (scalable implementation of Gieben DNS library7) and log
the responses ourselves.
Lastly, we utilized various sources (e.g., Google’s Safe brows-
ing, malwaredomains.com, etc.8) to collect our threat intelligence
that was used as the ground truth trough out our experiments.
Ultimately, we managed to passively collect a total of 1.5 million
malicious indicators (domains and IPs) and 1 million benign do-
mains (from Cisco’s top 1 million domains, one can also use Alexa’s
tom 1 million domains). Note that our algorithm does not rely
on benignness, and this list was collected only for the purpose of
evaluation.
4.1.2 Hardware Setup. For the purpose of this research, we set up a
big data processing cluster consisting of two Dell PowerEdge (R730,
R820) and five Fujitsu Primergy RX600 with a total of 1,864 GB
RAM, 24 CPUs (200 total cores), and 4 TB storage interconnected
via 10 Gb optical fiber. In addition, the data was initially stored
on an external Network Attached Storage (NAS) connected to the
cluster via 3x 10Gb optical fiber. While the detailed description of
the cluster setup is beyond the scope of this paper, we would like to
mention that this cluster is backed by Kubernetes9 for orchestration,
Apache Spark10 for distributed processing, and Apache Kafka11 for
distributed queueing. This allows us to scale our implementations
both vertically and horizontally.
4.2 Implementation
The majority of graph algorithm libraries are designed for single ma-
chine use, thus making large-scale graph processing an extremely
challenging task for today’s big data. Pregel originally introduced
by Malewicz et al. [31] brings graph algorithms into the map-reduce
world by expressing graph algorithms as a sequence of iterations,
in each of which a vertex can receive messages sent in the previous
iteration, send messages to other vertices, and modify its own state
and that of its outgoing edges or mutate graph topology. Using this
vertex-centric intuition ("think like a vertex"), one can express a
broad set of algorithms while parallelizing its computation across
any number of nodes. GraphX is Apache Spark’s API for paral-
lel and fault-tolerant graph computation at scale. In this regard,
we decided to implement the whole system (the knowledge graph
and MalRank algorithm) with Pregel’s computational model using
Apache Spark GraphX. It is worth mentioning that throughout our
experiments Apache Spark was configured to utilize a maximum of
72 CPU cores and 1.4TB of memory from the described hardware
setup.
Figure 2, shows the high-level architectural design for the system
implemented for the purpose of this research. As shown there
are four main layers within the system: Event logs PET , OSINT
Enrichment, Loading, and MalRank.
4.2.1 Event Logs PET. This layer is responsible to first, preprocess
(e.g., prepare, clean, deduplicate, parse, validate, etc.) the raw event
logs. Second, to extract entities and relationships of interest (as
described in the Section 2 and Figure 1), and finally, transform
7https://github.com/miekg/dns
8https://github.com/hslatman/awesome-threat-intelligence/
9https://kubernetes.io/
10https://spark.apache.org/
11https://kafka.apache.org/
4.2.4 MalRank Runner. The output of the loading module is then
passed to this layer which runs a distributed and iterative imple-
mentation of the MalRank algorithm. In each iteration for every
edge in the graph, a map function calculates the MalRank msg to
be sent to the destination vertex (according to MalRank Eq. (4)).
Intuitively by the end of this mapper round, each vertex is going to
receive a message for every incoming edge (from other vertices).
Then the reduce function is used to combine all msgs at each vertex
(MalRank Eq. 3). The reduce function itself is written to handle
only two messages at a time, but it will be repeated until all of the
messages have collapsed into a single message.
The described system is designed to work both in streaming and
batch mode. However, in this research, we only utilized its batch
mode. The current implementation of the MalRank does not sup-
port incremental updates. Therefore, one must re-run the MalRank
algorithm to score newly added vertices. We would like to leave this
to our future work, to implement the temporal incremental mode
of MalRank which not only operates on streams but also takes time
(first-seen and last-seen) into consideration.
4.3 Graph Structure
Before presenting our results it is important to understand some
key characteristics of our final knowledge graph.
After passing the described data set through the event logs PET
layer, 13 million vertices and 122 million edges were extracted.
This process took approximately 4 hours on the described setup.
Next, after passing through the enrichment layer an extra 6 million
vertices and 12 million edges were added making a total of 19 million
vertices and 134 million edges being passed to the loading module.
The enrichment layer processing time was about 2 hours. After the
loading module stage, the final graph was created with 15 million
unique vertices and 132 million unique edges.
Figure 3 shows the degree and component distribution of the
created knowledge graph. The distribution follows a power-law
distribution which indicates an extremely sparse graph with very
few edges between the majority of the node and minority with
high degree connected clusters. This is understandable since the
majority of our relationships enforce low degree when we have no
global view of the association rather an enterprise-level view of only
observed entities. The majority of high degree nodes were entities
associated with the enterprise itself, e.g., enterprise domains, and
workstations. For the details of vertex and edge types and their
corresponding counts refer to table 7 in appendix A.3.
As mentioned before, the loading module is also responsible for
labeling the nodes according to the collected TI as well as marking
some for the purpose of evaluation. In this regard, out of 1.5 million
combined TI collected in our experiment we had only 10 thousand
matches (within 15 million vertices).
The loading module took almost 3 hours to complete, with the
final graph spanning over 100 GB in memory across the cluster.
4.4 Evaluation
The evaluation in this section has two main objectives, first, eval-
uating the effectiveness of our approach and intuition as a threat
detection technique. Second, evaluating the MalRank algorithm as
a graph-based inference algorithm.
Figure 2: System architecture for the SIEM-based knowledge graph
and MalRank algorithm implemented for the purpose of this re-
search.
those into graph vertices and edges. The output of this layer is a
set of independent vertices and edges which is then passed to the
loading and the enrichment modules (as expressed in the Figure 2,
where D represents a vertex type Domain and RA represents the
relationship RequestedAccessTo, and so on).
Each vertex object has a vid (vertex identifier), name, type, tiOb-
servation, and mrScore. Each edge has a srcId, dstId, srcV (the whole
source vertex object), dstV, and eType (edge type). The intuition
behind this specific design is to embrace micro service, stateless,
and distributed design patterns. In this regard, despite, duplicating
each vertex within each edge object, the system can scale-out more
efficiently. This is due to the fact that the loading module can pro-
cess the received vertices and edges independently no matter the
order or distibution.
4.2.2 OSINT Enrichment. This layer consists of various enricher
modules. Upon initialization, each enricher first loads and prepare
the previously collected OSINT data (e.g., ASN mapping). Then, it
subscribes to a repository (either a message queue or a file system
directory) waiting for a batch of vertices. These vertices are pro-
vided as part of PET layer’s output. Finally, the enrichers enrich
those observed entities with their corresponding OSINT. For in-
stance, ASN enricher listens for a batch of IPv4 vertices to enrich
with IP range and ASN. The output of the OSINT enrichment layer
is also a set of entities (vertices) and relationships (edges) which is
passed to not only the loading module but also other enrichers for
further enrichment as shown in Figure 2.
4.2.3 Loading. All extracted and processed entities and relation-
ships arrive independently at the loading module. This module is
responsible for de-duplicating, indexing, cleaning and combining
all the vertices and edges. It is also responsible for labeling all ver-
tices according to the TI collected previously while marking some
for the purpose of evaluation. The output of this layer is the final
labeled and processed distributed graph.
Proxy Logs  (csv.gz) DNS Logs  (csv.gz) DHCP Logs  (csv.gz) Raw Event Logs D,IPreprocess ExtractTransformProxy PETDHCP PETDNS PETLoader MalRank RunnerTI EnricherOSINT EnrichmentD, I   RT, NS, MS, AF, SD I,R,A,O   IR, AT, BT I,D,O,X,   IF, IB, SB, AW, SD DNS Enricher IPR/ASNEnricher X.509 Enricher BGP Routes ASN Names X.509Certiﬁcates CollectedOSINT/TI TI Observables  (Mal & Ben) Vertices: M,D,I,UEdges:  RA,SD,RT,RE,US Graph Loader RAUSRARTAWIRATAWIFIBBTMDUIRAOXSDNSMSRFAFSBMalRank  D,I  I  I RAW DataFigure 3: Node degree distribution and connected component size
of the final graph in log-log scale.
Figure 5: Receiver Operating Characteristic and Precision Recall
curves of 9 iterations of MalRank ran 4 times.
Figure 4: Pseudo-random sampling for the purpose of evaluation.
In this regard to select the testing set we only consider connected
nodes such as A and B.
4.4.1 Previously Known Malicious. Those are nodes that were known
to be malicious at first (e.g., indicated by a TI source), however, they
were marked as unknown when passed to the algorithm so that
later they can be utilized to evaluate the algorithm detection capa-
bility (i.e., the testing set). Following the standard practices, in order
to evaluate the detection capability of our approach, we decided to
utilize a Receiver Operating Characteristic (ROC) curve as well as
Precision and Recall (PR) curve.
It is worth to remember the testing set could only be derived from
the 20K labeled data points that are connected. This is due to the fact
that, first, the rest of the data points did not have any label in the
first place that could be used for evaluation. Second, taking random
samples in a sparse graph with low degree distribution could result
in samples that have no connection to any other labeled nodes, thus
eliminating the ability to evaluate the inference. Figure 4 illustrate
this idea. If black nodes are previously known malicious nodes and
white node are unknown (unlabeled) nodes, we only consider nodes
such as A and B for our test samples as choosing X or Y will give
us no value considering the fact that they are not connected to any
other labeled nodes to allow effective maliciousness propagation.
More specifically, to select the testing samples for a class (e.g.,
maliciousness) in an evaluation run, the loading module, first, calcu-
lates the connected components (clusters) for that class, next, from
√
each of those clusters that have more than one member, selects
k
nodes at random (where k is the number of labeled nodes in each
cluster). For instance, if Figure 4 is our knowledge graph we would
take only A or B at random. In our experiment this process led to
the random selection of approximately 2, 000 nodes (1, 000 known
malicious and 1, 000 known benign nodes) in each evaluation run.
Figure 5 shows the ROC and PR plot for 9 iterations of MalRank
with configuration described in Table 3 on the described data set
with the described testing set. Note that the whole experiment
(including the sampling) was repeated 4 times to flatten out the
outliers. The results show a high accuracy (AUC = 96%, with the
peak F1-score = 0.905, and Accuracy = 0.900). Please refer to ap-
pendix A.4 figure 7 for the details of the experiment on different
number of iterations.
In order to better understand the algorithm’s results we inves-
tigated the false positives (FPs) and false negatives (FNs). In this
regard, we had the following observations; first, in contrast to our
original intuition and the common practice used in past efforts,
top-ranked domains by Cisco Umbrella or Alexa did not necessarily
reflect benign domains. In this regard, there were multiple instances
of domains being marked as malicious after MR due to association
with multiple malicious entities despite appearing on Umbrella top
1 million domains (therefore FP). This was also confirmed by [42].
A good example of this was world.rickstudio.ru, which appeared
among the top 1 million domains under the umbrella while being
malicious. This was also due to our random selection of benign
samples from the entire 1 million, one should at least ensure that
the samples are from the top k thousand.
Other legitimate false positives were due to the association of
malicious IPs to benign domains, this could be explained by the
web hosters that might share IPs among domains.
Majority of the false negatives were also due to bad quality Threat
Intelligence. For instance, ingesting a TI source where github.com
and google.de were marked as malicious by the TI. These were later
marked as non-malicious by our algorithm due to their association
with major neutral nodes. Other FNs were also due to content
delivery network (CDN) in which a TI was reporting an IP malicious
while it was also associated with a couple of legitimate domains
through a proxy server.
4.4.2 Comparison with Belief Propagation. In order to evaluate