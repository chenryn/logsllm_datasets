system call. In this case, RIPT will notice such error by checking
Intel PT packets and system call records. Then RIPT reverts to the
last memory dump and enumerates the execution order of race
pairs until it matches the records.
Previous approaches [2, 4] depend on pthread API call order
or system call order to detect enumeration errors. However, their
records are so sparse that complex thread execution order may be
performed between two record entries, so it’s hard to enumerate
the correct memory access order. RIPT utilizes the dense timing
information of Intel PT. We retrieve a block-level order which sig-
nificantly reduces the number of uncertain memory race pairs that
need to be enumerated. Besides, the control flow is usually very
sensitive to wrong memory access order, so detecting wrong enu-
meration by checking Intel PT packets is much more efficient than
checking API calls.
3 EVALUATION
We evaluate RIPT with real-world program bugs. They are chosen
to represent bugs which are hard to reproduce due to various non-
deterministic sources, with special focus on race conditions. We
compare RIPT with PinPlay [6], a record-and-replay tool based
Collected Datainput non-determinism data:signals, system calls, ...order non-determinism data:Intel PT timestamps, ...memory dump:code, data, registers, ...    RIPT RecordersRIPT kernel modulesignal recordersyscall recorderCPU emulatorexecution order enumeratorcontrol flow checker    RIPT Replayer    Recorder ClientIntel PT hardwarecontrol flow recorderTarget Process123Poster CCS '20, November 9–13, 2020, Virtual Event, USA2114Table 1: Evaluation Result
file access race; network
environment variable
non-deterministic sources
file access race
network
software
bzexe 1
nc 2
python2 3 race condition
wget 4
bash 5
python3 6 race condition
jsc 7
race condition
libuv 8
signal
nodejs 9
race condition
nodejs 10
shared memory access
1. CVE-2011-4089 2. https://cxsecurity.com/issue/WLB-2016120029 3. CVE-2018-1000030 4. CVE-2004-2014 5. CVE-2014-6277 6.
https://bugs.python.org/issue35185 7. CVE-2018-4192 8. https://github.com/libuv/libuv/issues/2398 9. https://github.com/nodejs/node/
issues/25007 10. https://github.com/nodejs/node/issues/28773
PinPlay recorder RIPT replayer
72.86s
16.24s
22.35s
14.05s
15.52s
30.99s
267.32s
7.03s
498.69s
92.06s
PinPlay replayer
error
12.52s
12.52s
1.51s
3.51s
16.14s
608.80s
2.35s
96.95s
61.20s
baseline RIPT recorder
1.03s
1.22s
0.27s
0.13s
0.24s
0.06s
0.76s
0.21s
0.15s
0.35s
1.18s
1.26s
0.32s
0.16s
0.28s
0.12s
1.11s
0.23s
0.27s
0.40s
14.45s
15.07s
15.07s
1.83s
5.25s
76.3s
927.26s
4.22s
83.17s
90.11s
on pin dynamic instrumentation, which is publicly available and
supports concurrent memory access recording by emulating cache
coherence protocol. Metrics including record and replay time are
shown in Table 1.
From the results, we can see that RIPT has a low recording
overhead (about 20% on average). PinPlay records the order of race
pairs by monitoring cache coherence messages. Since it simulates
a CPU cache in software using dynamic instrumentation, it has a
high recording overhead. RIPT does not have to directly record the
order of memory accesses. Instead, it relies on Intel PT to record
timestamps of control flow transfer, and recovers the access order
during replay, so RIPT recorder has a very good performance.
Both RIPT and PinPlay successfully reproduced these bugs, ex-
cept that PinPlay reports an error for the first test case. RIPT replay
overhead is relatively high, because we need to check the instruc-
tion pointer against Intel PT packets every time when a basic block
ends. We use the basic block hooking functionality of unicorn emu-
lator framework to implement this. As RIPT replays on an emulated
CPU while PinPlay replays with dynamic instrumentation, we have
a higher replay overhead. However, the replay overhead is not that
important for a record-and-replay system. Users usually have a
very strict attitude towards recording overhead but a very toler-
ant one towards replaying, because people may repeatedly run
the target program under recorder until a bug appears. Once the
bug is recorded, people can spend a lot of time in debugging and
frequently interact with the debugger. They can tolerate the replay
overhead as long as the bug can be reproduced and the debugger
response is not too slow. Although our overhead is high, the re-
playing for these test cases all finishes in a few minutes. As people
may spend hours debugging hard-to-reproduce bugs, we think the
replay overhead is acceptable.
Fuzz testing is a potential deployment scenario of record-and-
replay systems. During fuzzing, the target program runs for multiple
times with mutated inputs until bugs appear. However, reproducing
bugs found by fuzzers is sometimes problematic [9]. Since the fuzz
target runs for a huge number of times, efficient recorders like RIPT
would be very helpful. We plan to evaluate RIPT by attaching it to
some existing fuzzers and reproduce the bugs found in multithread
programs.
ter 35.
4 CONCLUSION
In this poster, we propose RIPT, a multi-core record-and-replay
system. RIPT uses Intel Processor Trace to record control flow
efficiently. Supplemented with components to record various non-
deterministic sources, RIPT can record user-space programs with
very low overhead. RIPT recorder is very suitable for situations like
fuzzing, where the target program is short-lived and recorded for
multiple times. RIPT is designed to be transparent that the original
program behaviors will not be disturbed by the recorder. To replay
concurrent memory access, RIPT tries to recover the access order by
using the control flow and timing information provided by Intel PT.
It can efficiently record real-world program bugs and replay them
within an acceptable time. We hope it can reduce the debugging
burden for software developers and testers.
ACKNOWLEDGMENTS
This project is supported by National Natural Science Foundation
of China (No. 61972224).
REFERENCES
[1] 2019. Intel® 64 and ia-32 architectures software developer’s manual. Vol. 3C. Chap-
[2] Gautam Altekar and Ion Stoica. 2009. ODR: Output-Deterministic Replay for
Multicore Debugging. In Proceedings of the ACM SIGOPS 22nd symposium on
Operating systems principles. 193–206.
[3] Derek R. Hower and Mark D. Hill. 2008. Rerun: Exploiting Episodes for Lightweight
Memory Race Recording. SIGARCH Comput. Archit. News 36, 3 (June 2008), 265–
276.
[4] Hongyu Liu, Sam Silvestro, Wei Wang, Chen Tian, and Tongping Liu. 2018. iRe-
player: in-situ and identical record-and-replay for multithreaded applications.
In Proceedings of the 39th ACM SIGPLAN Conference on Programming Language
Design and Implementation. 344–358.
[5] Robert O’Callahan, Chris Jones, Nathan Froyd, Kyle Huey, Albert Noll, and Nimrod
Partush. 2017. Engineering Record and Replay for Deployability. In Proceedings of
the 2017 USENIX Conference on Usenix Annual Technical Conference (Santa Clara,
CA, USA) (USENIX ATC ’17). USENIX Association, USA, 377–389.
[6] Harish Patil, Cristiano Pereira, Mack Stallcup, Gregory Lueck, and James Cownie.
2010. PinPlay: A Framework for Deterministic Replay and Reproducible Analysis
of Parallel Programs. In Proceedings of the 8th Annual IEEE/ACM International
Symposium on Code Generation and Optimization (Toronto, Ontario, Canada) (CGO
’10). Association for Computing Machinery, New York, NY, USA, 2–11.
[7] NGUYEN Anh Quynh and DANG Hoang Vu. 2015. Unicorn: Next Generation
CPU Emulator Framework. BlackHat USA (2015).
[8] Shiru Ren, Le Tan, Chunqi Li, Zhen Xiao, and Weijia Song. 2016. Samsara: Efficient
Deterministic Replay in Multiprocessor Environments with Hardware Virtualiza-
tion Extensions. In 2016 USENIX Annual Technical Conference (USENIX ATC 16).
USENIX Association, Denver, CO, 551–564.
[9] Michael Sutton, Adam Greene, and Pedram Amini. 2007. Fuzzing: brute force
vulnerability discovery. Pearson Education.
Poster CCS '20, November 9–13, 2020, Virtual Event, USA2115