Over the past 5 months, I have
been working on the building
LIDAR in PostgreSQL blocks for storing LIDAR data in
PostgreSQL, and leveraging it for
with PointCloud
analysis with PostGIS. That means
Paul Ramsey  LIDAR types and functions it the
database, and loading utilities to
get data into and out of the
database.
This development has been largely
funded by Natural Resources
Canada, who are planning to use
PostgreSQL and their database for
managing national LIDAR
inventories.
So, why would anyone want to put
LIDAR in a database? What’s the
motivation here?
Motivation
First, you can’t just stuff LIDAR
point clouds into existing PostGIS
types like the Point type, there’s
just too much of it. A county can
generate hundreds of millions of
points, a state can generate
billions.
Billions and Billions
Second, LIDAR is multi-
dimensional. And not just X,Y,Z.
(X, Y, Z)
A dozen or more dimensions PER
POINT, is not unusual.
(X, Y, Z, Intensity,
Unfortunately, the
ReturnNumber,
multidimensionality of LIDAR is not
NumberOfReturns, fixed either. Some LIDAR clouds
have four dimensions. Others have
Classification,
fourteen. So billions of points with
ScanAngleRank, Red,
many dimensions: you can’t stuff
Green, Blue)
this into existing PostGIS or
columnar tables.
But we don’t want to just throw up
our hands, because LIDAR point
Everything is related to
clouds have geographic location,
everything else, but which means if we can get them
into a spatial database, we can
near things are more
mash them up with other spatial
related than distant entities, thanks to Tobler’s Law. So
there’s value in the exercise.
things.
On the other hand, I’m on the
record as not wanting to put
rasters into the database, and
LIDAR pointclouds share a lot of the
features of rasters ...
Demotivation
LIDAR data is not very relational.
Compare the table definition of a
Column |Type
------------+-------------------------
PostGIS feature table, which has
gid | integer
lots of interesting non-spatial data
area | double precision
perimeter | double precision
related to the spatial column.
gunitice_ | double precision
gunitice_i | double precision
gunit_id | integer
gunit_labe | character varying(12)
gmap_id | smallint
geom | geometry(Polygon,26910)
With the table of pointcloud data,
which is just row upon row of patch
blocks, basically blobs in the
database. There’s not a lot of
Column | Type
interesting stuff to query about
--------+------------
id | integer
there!
pa | pcpatch(1)
Also, LIDAR is really big! Billions
and billions of points! That’s going
to result in really huge tables,
which are far more fiddly to
manage and back-up in a database
than they would be on the
filesystem as a bunch of files.
Billions and Billions
And finally, LIDAR is fairly static.
Updates aren’t granular and a bit at
a time, they tend to be bulk re-
surveys, just like raster data.
Which means, I need some
remotivation before I can go on!
Remotivation
But wait, actually, inside those rows
and rows of binary blocks there’s
quite a lot of detailed information,
Column |Type
--------+------------
id | integer
pa | pcpatch(1)
lots of dimensions per point and,
unlike raster, LIDAR use cases do
tend to filter and sub-set data
using those higher dimensions, the
(X, Y, Z, Intensity,
ReturnNumber, NumberOfReturns, use cases aren’t all bulk retrieval.
Classification,
ScanAngleRank,
Red, Green, Blue)
And Tobler’s Law is still there, so
the same motivation that got me to
Everything is related to
accept raster in the database
everything else, but applies to LIDAR in the database:
once it’s there you unlock all kinds
near things are more
of cross-type analysis: vector to
related than distant raster, raster to vector, raster to
pointcloud, pointcloud to vector,
things.
etc.
OK, how do we store LIDAR in the
Just Do It database?
First, we can’t store one point per
row, because a table with billions of
rows will be too big to use
practically: the index will be too
big, the table size will be very large
with one dimension per column, in
general there is a cost for a query
iterating over a row, which we want
to minimize.
So, for storage, we organize the
points into patches of several
hundred points each. This reduces
a table of billions into a table of
10s of millions, which is more
tractable.
Practically, we need two new types:
the pointcloud point, and the
pointcloud patch. PcPoint and
PcPatch. The point type is for
filtering and for casts to PostGIS.
PcPoint(pcid)
The patch type is what we use to
PcPatch(pcid)
store data in tables.
The goal of LIDAR storage is to try
X Y Z I RGB and keep things small, because
there’s so much data. So data are
packed into a byte array, using as
few bytes as possible to represent
each value. Compare a packed form
17 packed bytes
to a form that uses doubles for
every dimension: there’s no
comparison.
7x 8 = 56 bytes as doubles
The description of the how bytes
 are packed into a point is done
1
using an XML schema document,
4
which uses the same format
X coordinate as a long integer.
You must use the scale and offset
adopted by the open source PDAL
information of the header to determine
the double value.
project. This is an “X” dimension...
X
int32_t
0.01 Note the “scale” and “offset” values,
0
which allow data to be more
true
efficiently packed into narrower
byte space. Multiple dimensions are
Each schema document is stored in
a row in the pointcloud_formats
table, which assigns every schema
POINTCLOUD_FORMATS
and spatial reference system a
Column | Type unique “point cloud id”, “pcid”.
--------+---------
So....
pcid | integer
srid | integer
schema | text
to recap...!
•
PcPatches are collections of...
•
PcPoints which are packing of dimensions...
•
Described in XML schema documents...
•
Stored in the pointcloud_formats table...
•
Tied together with a “pcid” that relates patches
and points to the schemas necesary to interpret
them!
But enough about internals, how do
we work with pointcloud data in
SQL?
So What
Pointcloud only supports PgSQL 9.1
and up, so we only support
CREATE EXTENSION
installation via the “extension”
pointcloud;
method. Enable the pointcloud
depends
CREATE EXTENSION extension. If you want to do PostGIS
postgis; integration, enable PostGIS, then
no
on
enable pointcloud_postgis. Rather
sdneped
CREATE EXTENSION than having pointcloud depend on
pointcloud_postgis; PostGIS, point cloud is
independent, and the
pointcloud_postgis extension
We have a lot of tables and views
after enabling those extensions,
Schema | Name | Type most of which are from PostGIS, but
--------+--------------------+-------
there are two from pointcloud. The
public | geography_columns | view
public | geometry_columns | view pointcloud_formats table, as we
public | pointcloud_columns | view
mentioned, holds the schema
public | pointcloud_formats | table
public | raster_columns | view information for the points. The
public | raster_overviews | view
pointcloud_columns view acts like
public | spatial_ref_sys | table
the geometry_columns view,
showing an up-to-date list of what
tables have pointcloud data in
INSERT INTO pointcloud_formats (pcid, srid, schema) Before we can create an points or
VALUES (1, 0,
' patches, we need a schema to
going to hold. This is a simple
1
4
four-dimensional schema, with X,
X coordinate.
X
Y, Z as 32-bit integers and Intensity
int32_t
0.01
 as a 16-bit integer. We assign it
2 PCID = 1.
4
Y coordinate.
Y
int32_t
0.01
3
4
Z coordinate.
Z
int32_t
0.01
4
2
Pulse return magnitude.
Intensity
uint16_t
1
none
'
);
Now we can create a points table
(note, this is just for
demonstration, we will store
patches, not points, when in
CREATE TABLE pcpoints (
production).
id SERIAL PRIMARY KEY,
pt PcPoint(1)
);
And we can create a new point to
insert into the table. The
PC_MakePoint function lets you
INSERT INTO pcpoints (pt)
turn an array of doubles into a
VALUES (
PcPoint.
PC_MakePoint(1,
ARRAY[-126, 45, 34, 4]
)
);
And if we select the point back out
of the table, we get the well-known
SELECT pt FROM pcpoints;
binary format, which looks obscure
as usual,
0101000000C8CEFFFF94110000
480D00000400
But actually just has a short header,
giving the endianness and the pcid,
SELECT pt FROM pcpoints;
and then the data itself. This is
little endian data (intel processor),
01 endian
with the least significant bit first.
01000000 pcid
C8CEFFFF x
94110000 y
480D0000 z
0400 intensity
But the “as text” function returns a
more obviously human readable
SELECT PC_AsText(pt)
format (or at least a computer