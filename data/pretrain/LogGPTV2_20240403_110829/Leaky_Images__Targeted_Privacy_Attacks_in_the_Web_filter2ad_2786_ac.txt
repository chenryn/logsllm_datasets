### Side Website to Request an Image and Report Back to the Attacker-Controlled Server

One method to implement a leaky image attack involves using client-side JavaScript code, as illustrated in Figure 1. However, privacy-conscious users may disable JavaScript entirely or use security mechanisms that prevent JavaScript from accessing details about images loaded from different domains.

We introduce a variant of the leaky image attack that uses only HTML, without any JavaScript or CSS. This approach leverages the `<object>` tag, which allows a website to specify fallback content to be loaded if there is an error in loading the primary content. When nesting such `<object>` elements, the browser first attempts to load the resource specified in the outer element. If this fails, it then requests the resource specified in the inner element. This behavior effectively acts as a logical `if-not` instruction in pure HTML, which an attacker can exploit to implement the leaky image attack.

### Example of the Attack Variant

Figure 3 provides an example of this attack variant. We assume there are three users, \( u_1 \), \( u_2 \), and \( u_3 \), in the target group, and the attacker can share leaky images from `leaky-domain.com` with each of them. The comment at the beginning of Figure 3 specifies the exact sharing configuration. Similar to the JavaScript-based attack against a group of users (Section 3.3), we need \(\log(n)\) images to track \( n \) users. We also assume that the server-side generates the attack code upon receiving the request, and the generated code includes a session ID as part of the reporting links pointing to `evil.com`. In the example, the session ID is 2342, which helps the server-side code link multiple requests from the same client.

The key insight of this attack variant is to place a request to the attacker’s domain as a fallback for leaky image requests. For instance, if the request to the leaky image `i1` at line 4 fails, a request is made to `evil.com` for an alternative resource in line 5. This request reveals that the current user cannot access `i1`, i.e., `info=not i1`. By performing similar requests for all the leaky images, the attacker can gather enough information to identify individual users. For example, if in a given session, `evil.com` receives `not i1` but not `not not i1`, the attacker can conclude that the user is \( u_2 \).

Since the server-side infers the user's identity from the absence of requests, it is crucial to ensure that the tracking session is completed successfully before drawing any conclusions. Specifically, we must ensure that the user or the browser does not stop the page load before all nested `<object>` tags are evaluated. One way to achieve this is to add a sufficient number of nested requests to non-existent images in lines 11 to 13, followed by a request that informs the attacker that the tracking is complete in line 14. The server discards any session that does not contain this final message.

As a proof of concept, we tested the example attack and several variants in the latest Firefox and Chrome browsers and found that the HTML-only attack works as expected.

### 3.6 Discussion

#### Tracking Pixels
Leaky images are related to the widely used tracking pixels, also known as web beacons [14, 8, 47], but they differ in who learns about the user's identity. A tracking pixel is a small image that a website \( s \) loads from a tracker website \( s_{track} \). The image request contains the user's cookie for \( s_{track} \), allowing the tracker to recognize users across different page visits. Consequently, the tracking service can analyze which pages of \( s \) users visit and present this information in aggregated form to the provider of \( s \). If the tracker also operates services where users register, it can determine which user visits which site. In contrast, leaky images enable the operator of a site \( s \) to learn that a target user is visiting \( s \) without relying on a tracker to share this information, but by abusing an image sharing service. Like tracking pixels, leaky image attacks can use 1x1 pixel images to minimize their impact on page loading time.

#### Fingerprinting
Web fingerprinting techniques [12, 29, 10, 22, 1, 2, 30] use high-entropy properties of web browsers, such as the set of installed fonts or the size of the browser window, to heuristically recognize users. Like fingerprinting, leaky images aim to undermine user privacy. Unlike fingerprinting, the attacks presented here enable an attacker to determine specific user accounts, rather than recognizing that one visitor is likely the same as another. Additionally, leaky images can determine a visitor's identity with 100% certainty, whereas fingerprinting relies on the entropy of browser properties.

#### Targeted Attacks vs. Large-Scale Tracking
Leaky images are well-suited for targeted attacks [37, 6, 26, 16] but not for large-scale tracking of millions of users. One reason is that leaky images require the attacker to share an image with each victim, which is impractical beyond several hundred users. Another reason is that the number of image requests a website needs to perform increases logarithmically with the number of targeted users, as discussed in Section 3.3. Therefore, instead of aiming for large-scale tracking like tracking pixels or fingerprinting, leaky images are better suited for targeting (sets of) individuals. However, this type of targeted attack is increasingly popular, especially when dealing with high-value victims [37].

### 4 Leaky Images in Popular Websites

The attacks described in the previous section make several assumptions, particularly regarding how real-world image sharing services implement access control for shared images. To understand the extent to which popular websites are affected by the privacy issues discussed, we systematically studied the prevalence of leaky images. The following sections present our methodology (Section 4.1), main findings (Section 4.2), and ongoing efforts toward responsible disclosure (Section 4.3).

#### 4.1 Methodology

**Selection of Websites**
To select popular image sharing services, we examined the top 500 most popular websites according to the "Top Moz 500" list. We focused on websites that enable users to share data with each other, excluding those without an English language interface and those that do not offer user account creation. This selection yielded a list of 30 websites, which we studied in detail. Table 3 shows the studied websites along with their popularity ranks. The list includes the six most popular websites and nine of the ten most popular. Many of the analyzed sites are social media platforms, data-sharing services, and communication platforms.

**Image Sharing**
A condition for our attacks is that an attacker can share an image with a victim. We carefully analyzed the 30 sites in Table 3 to check if a site provides an image sharing service. We created multiple accounts on each site and attempted to share images between these accounts using various channels, such as chat windows or social media shares. Once an image was shared between two accounts, we verified that both accounts had access to the image and that a third account did not.

**Access Control Mechanism**
For websites that act as image sharing services, we checked whether the access control of a shared image could cause leaky images, as outlined in Table 2. Specifically, we checked if access to a shared image was protected by authentication and if both users accessed the image through a common link known to the attacker. A site meeting these conditions exposes its users to leaky image attacks.

#### 4.2 Prevalence of Leaky Images in the Wild

Among the 30 studied websites, we identified eight that suffer from leaky images. As shown in Table 3 (column "Leaky images"), the affected sites include the three most popular sites—Facebook, Twitter, and Google—and represent over 25% of the studied sites. The following sections discuss each vulnerable site in detail and explain how an attacker can establish a leaky image with a target user. Table 4 summarizes the discussion concisely.

**Facebook**
Images hosted on Facebook are generally delivered by content delivery networks not hosted at the `facebook.com` domain, e.g., `fbcdn.net`. This means that the `facebook.com` cookie is not sent with requests to shared images, disabling leaky image attacks. However, we identified an exception: a leaky image can be placed at `https://m.facebook.com/photo/view_full_size/?fbid=xxx`. The `fbid` is a unique identifier associated with each picture on Facebook, easily retrieved from the address bar of an image page. The attacker must gather this identifier and concatenate it with the leaky image URL. By adjusting the picture's privacy settings, the attacker can control which friends have access to the image, enabling individual and group attacks. A prerequisite for creating a leaky image on Facebook is that the victim is a "friend" of the attacker.

**Twitter**
Every image sent in a private chat on Twitter is a leaky image. The victim and the attacker can exchange messages on private chats if one of them has "Receive direct messages from anyone" enabled in their settings or if one is a follower of the other. An image sent in a private chat can only be accessed by the two participants based on their login state, making these images leaky. The attacker can easily retrieve the leaky image URL from the conversation and include it in another page. A limitation of the attack via Twitter is that we are currently unaware of a way to share an image with multiple users at once.

**Google**
We identified two leaky image channels on Google's domains: one in the thumbnails of Google Drive documents and one in Google Hangouts conversations. To share documents with the victim, the attacker only needs the victim's email address, while sending Hangouts messages requires the victim to accept the chat invitation. The thumbnail-based attack is more powerful because it allows easy addition and removal of users to the group with access to an image. Moreover, by unselecting the "Notify people" option when sharing, the victim users are not even aware of this operation. An advantage of the Hangouts channel is that the victim has no way to revoke their rights to the leaky image once it has been received in a chat, unlike Drive, where the victim can remove a shared document from their cloud.

**WordPress**
To create a leaky image via WordPress, the attacker needs to convince the victim to become a reader of their blog, or vice versa. Once this connection is established, every image posted on the shared private blog is a leaky image between the two users. Fulfilling this strong prerequisite may require non-trivial social engineering.

**GitHub**
Private repositories on GitHub enable leaky images. Once the victim and the attacker share a repository, an image can be accessed through a link in the web interface, such as `https://github.com/johndoe/my-awesome-project/raw/master/car.jpg`. Only users logged into GitHub who were granted access to the repository can access the image.