side website to request an image and to report back to the
attacker-controlled server-side whether the request was suc-
cessful or not. One way to implement it is using client-side
JavaScript code, as shown in Figure 1. However, privacy-
aware users may disable JavaScript completely or use a se-
curity mechanism that prevents JavaScript code from reading
details about images loaded from different domains.
We present a variant of the leaky image attack imple-
mented using only HTML code, i.e., without any JavaScript
or CSS. The idea is to use the object HTML tag, which
allows a website to specify fallback content to be loaded if
there is an error in loading some previously speciﬁed con-
tent.5 When nesting such object elements, the browser
ﬁrst requests the resource speciﬁed in the outer element, and
in case it fails, it performs a request to the inner element
instead. Essentially, this behavior corresponds to a logical
if-not instruction in pure HTML which an attacker may use
to implement the leaky image attack.
Figure 3 shows an example of this attack variant. We
assume that there are three users u1, u2, and u3 in the tar-
get group and that the attacker can share leaky images from
leaky-domain.com with each of them. The comment at the
beginning of Figure 3 speciﬁes the exact sharing conﬁgu-
ration. We again need log(n) images to track n users, as
for the JavaScript-based attack against a group of users (Sec-
tion 3.3). We assume that the server-side generates the attack
code upon receiving the request, and that the generated code
contains a session ID as part of the reporting links point-
ing to evil.com. In the example, the session ID is 2342. Its
purpose is to enable the server-side code to link multiple re-
quests coming from the same client.
The main insight of this attack variant is to place a re-
quest to the attacker’s domain as fallbacks for leaky image
requests. For example, if the request to the leaky image i1
at line 4 fails, a request is made to evil.com for an alterna-
tive resource in line 5. This request leaks the information
that the current user cannot access i1, i.e., info=not i1.
By performing similar requests for all the leaky images, the
attacker leaks enough information for precisely identifying
individual users. For example, if in a given session, evil.com
receives not i1, but not not i1, the attacker can conclude
that the user is u2. Because the server-side infers the user
from the absence of requests, it is important to ensure that
the current tracking session is successfully completed before
drawing any conclusions. Speciﬁcally, we must ensure that
the user or the browser did not stop the page load before all
the nested object tags were evaluated. One way to ensure
this property is to add a sufﬁciently high number of nested
requests to non-existent images in lines 11 to 13 followed by
a request that informs the attacker that the tracking is com-
pleted, in line 14. The server discards every session that does
not contain this last message.
As a proof of concept, we tested the example attack and
several variants of it in the newest Firefox and Chrome
browsers and ﬁnd the HTML-only attack to work as ex-
pected.
5https://html.spec.whatwg.org/multipage/
iframe-embed-object.html#the-object-element
928    28th USENIX Security Symposium
USENIX Association
3.6 Discussion
Tracking pixels Leaky images are related to the widely
used tracking pixels, also called web beacons [14, 8, 47],
but both differ regarding who learns about a user’s iden-
tity. A tracking pixel is a small image that a website s loads
from a tracker website strack. The image request contains
the user’s cookie for strack, enabling the tracker to recognize
users across different page visits. As a result, the tracking
service can analyze which pages of s users visit and show
this information in aggregated form to the provider of s. If
the tracker also operates services where users register, it can
learn which user visits which site. In contrast, leaky images
enable the operator of a site s to learn that a target user is vis-
iting s, without relying on a tracker to share this information,
but by abusing an image sharing service. As for tracking pix-
els, an attacker can deploy leaky image attacks with images
of 1x1 pixel size to reduce its impact on page loading time.
Fingerprinting Web ﬁngerprinting techniques [12, 29, 10,
22, 1, 2, 30] use high-entropy properties of web browsers,
such as the set of installed fonts or the size of the browser
window, to heuristically recognize users. Like ﬁngerprint-
ing, leaky images aim at undermining the privacy of users.
Unlike ﬁngerprinting, the attacks presented here enable an
attacker to determine speciﬁc user accounts, instead of rec-
ognizing that one visitor is likely to be the same as another
visitor. Furthermore, leaky images can determine a visitor’s
identity with 100% certainty, whereas ﬁngerprinting heuris-
tically relies on the entropy of browser properties.
Targeted attacks versus large-scale tracking Leaky im-
ages are well suited for targeted attacks [37, 6, 26, 16], but
not for large-scale tracking of millions of users. One reason
is that leaky images require the attacker to share an image
with each victim, which is unlikely to scale beyond several
hundreds users. Another reason is that the number of image
requests that a website needs to perform increases logarith-
mically with the number of targeted users, as discussed in
Section 3.3. Hence, instead of aiming at large-scale tracking
in the spirit of tracking pixels or ﬁngerprinting, leaky images
are better suited to target (sets of) individuals. However, this
type of targeted attacks is reported to be increasingly popu-
lar, especially when dealing with high-value victims [37].
4 Leaky Images in Popular Websites
The attacks presented in the previous section make several
assumptions.
In particular, leaky images depend on how
real-world image sharing services implement access control
for shared images. To understand to what extent popular
websites are affected by the privacy problem discussed in
this paper, we systematically study the prevalence of leaky
images. The following presents our methodology (Sec-
tion 4.1), our main ﬁndings (Section 4.2), and discusses our
ongoing efforts toward disclosing the detected problems in a
responsible way (Section 4.3).
4.1 Methodology
Selection of websites To select popular image sharing ser-
vices to study, we examined the top 500 most popular web-
sites, according to the “Top Moz 500” list6. We focus on
websites that enable users to share data with each other. We
exclude sites that do not offer an English language interface
and websites that do not offer the possibility to create user
accounts. This selection yields a list of 30 websites, which
we study in more detail. Table 3 shows the studied websites,
along with their popularity rank. The list contains all of the
six most popular websites, and nine of the ten most popu-
lar websites. Many of the analyzed sites are social media
platforms, services for sharing some kind of data, and com-
munication platforms.
Image sharing One condition for our attacks is that an at-
tacker can share an image with a victim. We carefully ana-
lyze the 30 sites in Table 3 to check whether a site provides
an image sharing service. To this end, we create multiple
accounts on each site and attempt to share images between
these accounts using different channels, e.g., chat windows
or social media shares. Once an image is shared between two
accounts, we check if the two accounts indeed have access to
the image. If this requirement is met, we check that a third
account cannot access the image.
Access control mechanism For websites that act as image
sharing services, we check whether the access control of a
shared image is implemented in a way that causes leaky im-
ages, as presented in Table 2. Speciﬁcally, we check whether
the access to a shared image is protected by authentication
and whether both users access the image through a common
link, i.e., a link known to the attacker. A site that fulﬁlls also
this condition exposes its users to leaky image attacks.
4.2 Prevalence of Leaky Images in the Wild
Among the 30 studied websites, we identify a total of eight
websites that suffer from leaky images. As shown in Table 3
(column “Leaky images”), the affected sites include the three
most popular sites, Facebook, Twitter, and Google, and rep-
resent over 25% of all sites that we study. The following
discusses each of the vulnerable sites in detail and explains
how an attacker can establish a leaky image with a target
user. Table 4 summarizes the discussion in a concise way.
6https://moz.com/top500
USENIX Association
28th USENIX Security Symposium    929
Table 3: List of analyzed websites, whether they suffer from
leaky images, and how the respective security teams have
reacted to our notiﬁcations about the privacy leak.
Rank Domain
Fix
Leaky Conﬁrmed
images
Bug
bounty
1 facebook.com
2 twitter.com
3 google.com
4 youtube.com
5 instagram.com
6 linkedin.com
8 pinterest.com
9 wikipedia.org
10 wordpress.com
15 tumblr.com
18 vimeo.com
19 ﬂickr.com
25 vk.com
26 reddit.com
33 blogger.com
35 github.com
39 myspace.com
54 stumbleupon.com
65 dropbox.com
71 msn.com
72 slideshare.net
91 typepad.com
126 live.com
152 spotify.com
160 goodreads.com
161 scribd.com
163 imgur.com
166 photobucket.com
170 deviantart.com
217 skype.com
yes
yes
yes
no
no
no
no
no
yes
no
no
no
no
no
no
yes
no
no
yes
no
no
no
yes
no
no
no
no
no
no
yes
yes
yes
yes
yes
yes
planned
yes
yes
no
no
no
no
no
no
no
yes
planned
yes
yes
planned
no
yes
planned
no
Facebook Images hosted on Facebook are in general de-
livered by content delivery networks not hosted at the face-
book.com domain, but, e.g., at fbcdn.net. Hence, the fact
that facebook.com cookie is not sent along with requests
to shared images disables the leaky image attacks. How-
ever, we identiﬁed an exception to this rule, where a leaky
image can be placed at https://m.facebook.com/
photo/view\_full\_size/?fbid=xxx. The fbid
is a unique identiﬁer that is associated with each picture on
Facebook, and it is easy to retrieve this identiﬁer from the
address bar of an image page. The attacker must gather this
identiﬁer and concatenate it with the leaky image URL given
above. By tweaking the picture’s privacy settings, the at-
tacker can control the subset of friends that are authorized to
access the image, opening the door for individual and group
attacks. A prerequisite of creating a leaky image on Face-
book is that the victim is a “friend” of the attacker.
Twitter Every image sent in a private chat on Twitter is a
leaky image. The victim and the attacker can exchange mes-
sages on private chats, and hence send images, if one of them
checked “Receive direct messages from anyone” in their set-
tings or if one is a follower of the other. An image sent on
a private chat can only be accessed by the two participants,
based on their login state, i.e., these images are leaky images.
The attacker can easily retrieve the leaky image URL from
the conversation and include it in another page. A limitation
of the attack via Twitter is that we are currently not aware of
a way of sharing an image with multiple users at once.
Google We identiﬁed two leaky image channels on
Google’s domains: one in the thumbnails of Google Drive
documents and one in Google Hangouts conversations. To
share documents with the victim, an attacker only needs the
email address of the victim, while in order to send Hangouts
messages, the victim needs to accept the chat invitation from
the attacker. The thumbnail-based attack is more powerful
since it allows to easily add and remove users to the group
of users that have access to an image. Moreover, by unse-
lecting the “Notify people” option when sharing, the victim
users are not even aware of this operation. An advantage
of the Hangouts channel, though, is that the victim has no
way to revoke its rights to the leaky image, once the image
has been received in a chat, as opposed to Drive, where the
victim can remove a shared document from her cloud.
Wordpress To create a leaky image via Wordpress, the at-
tacker needs to convince the victim to become a reader of
his blog, or the other way around. Once this connection is
established, every image posted on the shared private blog is
a leaky image between the two users. Fulﬁlling this strong
prerequisite may require non-trivial social engineering.
every
committed
such
on GitHub
GitHub Private
enable
repositories
leaky images.
Once the victim and the attacker
share
a
repository,
image
can be accessed through a link in the web inter-
face,
https://github.com/johndoe/
my-awesome-project/raw/master/car.jpg.
Only users logged into GitHub who were granted access to