title:Efficient Data Structures For Tamper-Evident Logging
author:Scott A. Crosby and
Dan S. Wallach
Efﬁcient Data Structures for Tamper-Evident Logging
Scott A. Crosby
PI:EMAIL
Dan S. Wallach
PI:EMAIL
Department of Computer Science, Rice University
Abstract
Many real-world applications wish to collect tamper-
evident logs for forensic purposes. This paper considers
the case of an untrusted logger, serving a number of
clients who wish to store their events in the log, and
kept honest by a number of auditors who will challenge
the logger to prove its correct behavior. We propose
semantics of tamper-evident logs in terms of this auditing
process. The logger must be able to prove that individual
logged events are still present, and that the log, as seen
now, is consistent with how it was seen in the past. To
accomplish this efﬁciently, we describe a tree-based data
structure that can generate such proofs with logarithmic
size and space,
improving over previous linear con-
structions. Where a classic hash chain might require an
800 MB trace to prove that a randomly chosen event is in
a log with 80 million events, our prototype returns a 3 KB
proof with the same semantics. We also present a ﬂexible
mechanism for the log server to present authenticated
and tamper-evident search results for all events matching
a predicate. This can allow large-scale log servers to
selectively delete old events, in an agreed-upon fashion,
while generating efﬁcient proofs that no inappropriate
events were deleted. We describe a prototype imple-
mentation and measure its performance on an 80 million
event syslog trace at 1,750 events per second using a
single CPU core. Performance improves to 10,500 events
per second if cryptographic signatures are ofﬂoaded,
corresponding to 1.1 TB of logging throughput per week.
1 Introduction
There are over 10,000 U.S. regulations that govern the
storage and management of data [22, 58]. Many countries
have legal, ﬁnancial, medical, educational and privacy
regulations that require businesses to retain a variety of
records. Logging systems are therefore in wide use (albeit
many without much in the way of security features).
Audit logs are useful for a variety of forensic purposes,
such as tracing database tampering [59] or building a
versioned ﬁlesystem with veriﬁable audit
trails [52].
Tamper-evident logs have also been used to build Byzan-
tine fault-tolerant systems [35] and protocols [15], as well
as to detect misbehaving hosts in distributed systems [28].
Ensuring a log’s integrity is a critical component in the
security of a larger system. Malicious users, including in-
siders with high-level access and the ability to subvert the
logging system, may want to perform unlogged activities
or tamper with the recorded history. While tamper-
resistance for such a system might be impossible, tamper-
detection should be guaranteed in a strong fashion.
A variety of hash data structures have been proposed
in the literature for storing data in a tamper-evident
fashion, such as trees [34, 49], RSA accumulators [5, 11],
skip lists [24], or general authenticated DAGs. These
structures have been used to build certiﬁcate revocation
lists [49], to build tamper-evident graph and geometric
searching [25], and authenticated responses to XML
queries [19]. All of these store static data, created by a
trusted author whose signature is used as a root-of-trust
for authenticating responses of a lookup queries.
While authenticated data structures have been adapted
for dynamic data [2], they continue to assume a trusted
author, and thus they have no need to detect inconsis-
tencies across versions. For instance, in SUNDR [36], a
trusted network ﬁlesystem is implemented on untrusted
storage. Although version vectors [16] are used to detect
when the server presents forking-inconsistent views to
clients, only trusted clients sign updates for the ﬁlesystem.
Tamper-evident logs are fundamentally different: An
untrusted logger is the sole author of the log and is respon-
sible for both building and signing it. A log is a dynamic
data structure, with the author signing a stream of commit-
ments, a new commitment each time a new event is added
to the log. Each commitment snapshots the entire log up
to that point. If each signed commitment is the root of
an authenticated data structure, well-known authenticated
dictionary techniques [62, 42, 20] can detect tampering
within each snapshot. However, without additional mech-
anisms to prevent it, an untrusted logger is free to have dif-
ferent snapshots make inconsistent claims about the past.
To be secure, a tamper-evident log system must both de-
tect tampering within each signed log and detect when
different instances of the log make inconsistent claims.
Current solutions for detecting when an untrusted
server is making inconsistent claims over time require
linear space and time. For instance, to prevent undetected
tampering, existing tamper evident logs [56, 17, 57]
which rely upon a hash chain require auditors examine
every intermediate event between snapshots. One pro-
posal [43] for a tamper-evident log was based on a skip
list.
It has logarithmic lookup times, assuming the log
is known to be internally consistent. However, proving
internal consistency requires scanning the full contents of
the log. (See Section 3.4 for further analysis of this.)
In the same manner, CATS [63], a network-storage
service with strong accountability properties, snapshots
the internal state, and only probabilistically detects
tampering by auditing a subset of objects for correctness
between snapshots. Pavlou and Snodgrass [51] show how
to integrate tamper-evidence into a relational database,
and can prove the existence of tampering, if suspected.
Auditing these systems for consistency is expensive,
requiring each auditor visit each snapshot to conﬁrm that
any changes between snapshots are authorized.
If an untrusted logger knows that a just-added event
or returned commitment will not be audited, then any
tampering with the added event or the events ﬁxed by that
commitment will be undiscovered, and, by deﬁnition,
the log is not tamper-evident. To prevent this, a tamper-
evident log requires frequent auditing. To this end, we
propose a tree-based history data structure, logarithmic
for all auditing and lookup operations. Events may be
added to the log, commitments generated, and audits
may be performed independently of one another and at
any time. No batching is used. Unlike past designs, we
explicitly focus on how tampering will be discovered,
through auditing, and we optimize the costs of these
audits. Our history tree allows loggers to efﬁciently prove
that the sequence of individual logs committed to, over
time, make consistent claims about the past.
In Section 2 we present background material and pro-
pose semantics for tamper-evident logging. In Section 3
we present the history tree.
In Section 4 we describe
Merkle aggregation, a way to annotate events with
attributes which can then be used to perform tamper-
evident queries over the log and safe deletion of events,
allowing unneeded events to be removed in-place, with no
additional trusted party, while still being able to prove that
no events were improperly purged. Section 5 describes
a prototype implementation for tamper-evident logging
of syslog data traces. Section 6 discusses approaches
for scaling the logger’s performance. Related work is
presented in Section 7. Future work and conclusions
appear in Section 8.
2 Security Model
In this paper, we make the usual cryptographic assump-
tions that an attacker cannot forge digital signatures or
ﬁnd collisions in cryptographic hash functions. Further-
more we are not concerned with protecting the secrecy
of the logged events; this can be addressed with external
techniques, most likely some form of encryption [50, 26,
54]. For simplicity, we assume a single monolithic log on
a single host computer. Our goal is to detect tampering.
It is impractical to prevent the destruction or alteration of
digital records that are in the custody of a Byzantine log-
ger. Replication strategies, outside the scope of this paper,
can help ensure availability of the digital records [44].
Tamper-evidence requires auditing. If the log is never
examined, then tampering cannot be detected. To this end,
we divide a logging system into three logical entities—
many clients which generate events for appending to a log
or history, managed on a centralized but totally untrusted
logger, which is ultimately audited by one or more
trusted auditors. We assume clients and auditors have
very limited storage capacity while loggers are assumed
to have unlimited storage. By auditing the published
commitments and demanding proofs, auditors can be
convinced that the log’s integrity has been maintained.
At least one auditor is assumed to be incorruptible.
In
our system, we distinguish between clients and auditors,
while a single host could, in fact, perform both roles.
We must trust clients to behave correctly while they
are following the event insertion protocol, but we trust
clients nowhere else. Of course, a malicious client could
insert garbage, but we wish to ensure that an event, once
correctly inserted, cannot be undetectably hidden or mod-
iﬁed, even if the original client is subsequently colluding
with the logger in an attempt to tamper with old data.
To ensure these semantics, an untrusted logger must
regularly prove its correct behavior to auditors and
clients.
Incremental proofs, demanded of the logger,
prove that current commitment and prior commitment
make consistent claims about past events. Membership
proofs ask the logger to return a particular event from the
log along with a proof that the event is consistent with
the current commitment. Membership proofs may be
demanded by clients after adding events or by auditors
verifying that older events remain correctly stored by the
logger. These two styles of proofs are sufﬁcient to yield
tamper-evidence. As any vanilla lookup operation may be
followed by a request for proof, the logger must behave
faithfully or risk its misbehavior being discovered.
2.1 Semantics of a tamper evident history
We now formalize our desired semantics for secure
histories. Each time an event X is sent to the logger, it
assigns an index i and appends it to the log, generating a
version-i commitment Ci that depends on all of the events
to-date, X0 . . . Xi. The commitment Ci is bound to its
version number i, signed, and published.
Although the stream of histories that a logger commits
to (C0 . . .Ci,Ci+1,Ci+2 . . .) are supposed to be mutually-
consistent,
each commitment ﬁxes an independent
history. Because histories are not known, a priori, to
be consistent with one other, we will use primes (′) to
distinguish between different histories and the events
contained within them. In other words, the events in log
Ci (i.e., those committed by commitment Ci) are X0 . . . Xi
and the events in log C′
prove their correspondence.
j are X ′
0 . . .X ′
j, and we will need to
2.1.1 Membership auditing
Membership auditing is performed both by clients,
verifying that new events are correctly inserted, and by
auditors, investigating that old events are still present
and unaltered. The logger is given an event index i and
a commitment Cj, i ≤ j and is required to return the ith
element in the log, Xi, and a proof that Cj implies Xi is
the ith event in the log.
2.1.2 Incremental auditing
While a veriﬁed membership proof shows that an event
was logged correctly in some log, represented by its
commitment Cj, additional work is necessary to verify
that the sequence of logs committed by the logger is
consistent over time. In incremental auditing, the logger
is given two commitments Cj and C′
k, where j ≤ k, and
is required to prove that the two commitments make con-
sistent claims about past events. A veriﬁed incremental
proof demonstrates that Xa = X ′
a for all a ∈ [0, j]. Once
veriﬁed, the auditor knows that Cj and C′
k commit to the
same shared history, and the auditor can safely discard Cj.
A dishonest logger may attempt to tamper with its
history by rolling back the log, creating a new fork on
which it inserts new events, and abandoning the old fork.
Such tampering will be caught if the logging system
satisﬁes historical consistency (see Section 2.3) and by
a logger’s inability to generate an incremental proof
between commitments on different (and inconsistent)
forks when challenged.
2.2 Client insertion protocol
Once clients receive commitments from the logger af-
ter inserting an event, they must immediately redistribute
them to auditors. This prevents the clients from subse-
quently colluding with the logger to roll back or modify
their events. To this end, we need a mechanism, such as
a gossip protocol, to distribute the signed commitments
from clients to multiple auditors.
It’s unnecessary for
every auditor to audit every commitment, so long as some
auditor audits every commitment.
(We further discuss
tradeoffs with other auditing strategies in Section 3.1.)
In addition, in order to deal with the logger presenting
different views of the log to different auditors and clients,
auditors must obtain and reconcile commitments received
from multiple clients or auditors, perhaps with the gossip
protocol mentioned above. Alternatively the logger may
publish its commitment in a public fashion so that all
auditors receive the same commitment [27]. All that
matters is that auditors have access to a diverse collection
of commitments and demand incremental proofs to verify
that the logger is presenting a consistent view.
2.3 Deﬁnition: tamper evident history
We now deﬁne a tamper-evident history system as a
ﬁve-tuple of algorithms:
H.ADD(X) → Cj. Given an event X, appends it to the
history, returning a new commitment.
H.INCR.GEN(Ci,Cj) → P. Generates
an
incremental
proof between Ci and Cj, where i ≤ j.
H.MEMBERSHIP.GEN(i,Cj) → (P,Xi). Generates
a
membership proof for event i from commitment Cj,
where i ≤ j. Also returns the event, Xi.
P.INCR.VF(C′
i,Cj) → {⊤, ⊥}. Checks that P proves that
i (where i ≤ j). Outputs
Cj ﬁxes every entry ﬁxed by C′
⊤ if no divergence has been detected.
P.MEMBERSHIP.VF(i,Cj,X ′
proves that event X ′
by Cj (where i ≤ j). Outputs ⊤ if true.
i ) → {⊤, ⊥}. Checks that P
i is the i’th event in the log deﬁned
The ﬁrst three algorithms run on the logger and are used
to append to the log H and to generate proofs P. Auditors
or clients verify the proofs with algorithms {INCR.VF,
MEMBERSHIP.VF}. Ideally, the proof P sent to the au-
ditor is more concise than retransmitting the full history
H. Only commitments need to be signed by the log-
ger. Proofs do not require digital signatures; either they
demonstrate consistency of the commitments and the con-
tents of an event or they don’t. With these ﬁve operations,
we now deﬁne “tamper evidence” as a system satisfying:
Historical Consistency
If we have a valid incremental
proof between two commitments Cj and Ck, where
j ≤ k, (P.INCR.VF(Cj,Ck) → ⊤), and we have a valid
membership proof P′ for the event X ′
i , where i ≤ j, in the
log ﬁxed by Cj (i.e., P′.MEMBERSHIP.VF(i,Cj,X ′
i ) → ⊤)
and a valid membership proof for X ′′
in the log ﬁxed
i
by Ck (i.e., P′′.MEMBERSHIP.VF(i,Ck,X ′′
i ) → ⊤), then
X ′
i must equal X ′′
i . (In other words, if two commitments
commit consistent histories, then they must both ﬁx the
same events for their shared past.)
2.4 Other threat models
Classic tamper-evident
Forward integrity
logging
uses a different threat model, forward integrity [4]. The
forward integrity threat model has two entities: clients
who are fully trusted but have limited storage, and loggers
who are assumed to be honest until suffering a Byzantine
failure. In this threat model, the logger must be prevented
from undetectably tampering with events logged prior
to the Byzantine failure, but is allowed to undetectably
tamper with events logged after the Byzantine failure.
Although we feel our threat model better characterizes
the threats faced by tamper-evident logging, our history
tree and the semantics for tamper-evident logging are
applicable to this alternative threat model with only
minor changes. Under the semantics of forward-integrity,
membership auditing just-added events is unnecessary
because tamper-evidence only applies to events occurring
before the Byzantine failure. Auditing a just-added event
is unneeded if the Byzantine failure hasn’t happened and
irrelevant afterwards.
Incremental auditing is still nec-
essary. A client must incrementally audit received com-
mitments to prevent a logger from tampering with events
occurring before a Byzantine failure by rolling back the
log and creating a new fork. Membership auditing is
required to look up and examine old events in the log.
Itkis [31] has a similar threat model. His design
exploited the fact that if a Byzantine logger attempts to
roll back its history to before the Byzantine failure, the
history must fork into two parallel histories. He proposed
a procedure that
tested two commitments to detect