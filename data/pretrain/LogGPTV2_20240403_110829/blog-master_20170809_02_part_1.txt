## 解密上帝之手 - 阿里云HDB for PostgreSQL数据库metascan特性(存储级、块级、batch级过滤与数据编排)
### 作者                          
digoal                         
### 日期                           
2017-08-09                     
### 标签                    
PostgreSQL , metascan , 块级过滤 , 块级统计信息 , BATCH级统计信息 , brin , 区间索引 , 块级索引 , batch级索引 , 数据编排 , 存储计算分离 , 混合编排 , 分段编排             
----                    
## 背景      
数据也有生辰八字，你信吗？列与列之间，行与行之间，元素与元素之间如何相生相克？查询慢？不要信什么这都是上天注定的，如何给数据改运？看完本文，你也可以做到。    
![pic](20170809_02_pic_003.gif)  
一份天赋，九份努力。缘分天注定。命由天定。又有说我命由我不由天的。看样子中国古人对先天注定的东西研究还挺透彻，看的还挺开，但是也有通过后天努力，或者后天改运等等手段来弥补先天不足的。    
![pic](20170809_02_pic_002.jpg)    
实际上在准备写本文时，我发现数据库的数据编排，数据存放和中国的命理相关的传统文化还很相似，也存在先天因素和后天补救的说法。    
怎么回事呢？且听我细细道来。    
为了加速数据的检索效率，我们通常需要对数据创建索引，提高数据定位的精准性。例如查询某人某个月的通话流水数据，没有索引的话，我们需要搜索所有的数据，逐条匹配。通过索引，可以直接定位到需要查询的记录。      
特别是在存储和计算分离时，如果搜索量越大，网络中传输的数据量就越大。瓶颈很明显。      
另外，在OLAP领域，需要对大量的数据进行处理，如果都建索引，索引引入的开销还是蛮大的。      
那么有没有其他方法，不建索引降低扫描量呢？      
## 存储层统计和过滤下推      
相信大家一定已经想到了，统计信息，没错我们可以对存储的数据，按块进行数据统计，例如每个块内的数据范围。      
有几个非常常见的技术实现：      
1、PostgreSQL BRIN索引。      
[《PostgreSQL 物联网黑科技 - 瘦身几百倍的索引(BRIN index)》](../201604/20160414_01.md)        
https://www.postgresql.org/docs/10/static/brin-intro.html      
PostgreSQL brin索引就是块级索引，记录的是每个块、或者每一批连续的块的统计信息。      
在按这个列搜索时，通过元数据，过滤不相干的块。      
2、cstore_fdw列存储插件。实际上它也是按BATCH编排的列存储，每个BATCH的元数据（最大值、最小值）可以用于扫描时的过滤。      
https://github.com/citusdata/cstore_fdw      
Skip indexes: Stores min/max statistics for row groups, and uses them to skip over unrelated rows.      
**Using Skip Indexes**      
cstore_fdw partitions each column into multiple blocks. Skip indexes store minimum and maximum values for each of these blocks. While scanning the table, if min/max values of the block contradict the WHERE clause, then the block is completely skipped. This way, the query processes less data and hence finishes faster.      
To use skip indexes more efficiently, you should load the data after sorting it on a column that is commonly used in the WHERE clause. This ensures that there is a minimum overlap between blocks and the chance of them being skipped is higher.      
In practice, the data generally has an inherent dimension (for example a time field) on which it is naturally sorted. Usually, the queries also have a filter clause on that column (for example you want to query only the last week's data), and hence you don't need to sort the data in such cases.      
在按这个列搜索时，通过元数据，过滤不相干的块。      
例子      
```      
某个300GB的外部表，采样skip index扫描，加速扫描。  
耗时103毫秒。      
explain (analyze,verbose,timing,costs,buffers) select c400,sum(c2) from ft_tbl1 where c400=1 group by c400;      
         Filter: (ft_tbl1.c400 = 1)      
         Rows Removed by Filter: 89996        
         CStore File: /data01/digoal/pg_root1921/cstore_fdw/13146/41038      
         CStore File Size: 325166400400      
         Buffers: shared hit=8004      
 Planning time: 52.524 ms      
 Execution time: 103.555 ms      
(13 rows)      
不使用where c400=1，  
耗时89秒      
explain (analyze,verbose,timing,costs,buffers) select c400,sum(c2) from ft_tbl1  group by c400;      
         CStore File: /data01/digoal/pg_root1921/cstore_fdw/13146/41038      
         CStore File Size: 325166400400      
         Buffers: shared hit=8004      
 Planning time: 52.691 ms      
 Execution time: 89428.721 ms      
```      
需要提一下，目前cstore_fdw这个插件没有支持并行计算，而实际上PostgreSQL的fdw接口已经支持了并行计算，cstore_fdw只需要改造一下，即可支持并行计算。      
如下      
https://www.postgresql.org/docs/10/static/fdw-callbacks.html#fdw-callbacks-parallel      
## 过滤效率与线性相关性      
注意，由于数据存储的关系，并不是所有列的统计信息过滤性都很好。举个例子：      
某列的写入很随机，导致值的分布很随机，那么在一个数据块里面包含的数据范围可能比较大，这种列的存储元信息过滤性就很差。      
```      
create table a(id int, c1 int);      
insert into a select generate_series(1,1000000), random()*1000000;      
```      
数据的分布如下      
```      
postgres=# select substring(ctid::text, '(\d+),')::int8 blkid, min(c1) min_c1, max(c1) max_c1, min(id) min_id, max(id) max_id from a group by 1 order by 1;      
 blkid | min_c1 | max_c1 | min_id | max_id        
-------+--------+--------+--------+---------      
     0 |   2697 | 998322 |      1 |     909      
     1 |   1065 | 998817 |    910 |    1818      
     2 |    250 | 998025 |   1819 |    2727      
     3 |     62 | 997316 |   2728 |    3636      
     4 |   1556 | 998640 |   3637 |    4545      
     5 |    999 | 999536 |   4546 |    5454      
     6 |   1385 | 999196 |   5455 |    6363      
     7 |   1809 | 999042 |   6364 |    7272      
     8 |   3044 | 999606 |   7273 |    8181      
     9 |   1719 | 999186 |   8182 |    9090      
    10 |    618 | 997031 |   9091 |    9999      
    11 |     80 | 997581 |  10000 |   10908      
    12 |    781 | 997710 |  10909 |   11817      
    13 |   1539 | 998857 |  11818 |   12726      
    14 |   2097 | 999932 |  12727 |   13635      
    15 |    114 | 999913 |  13636 |   14544      
    16 |    136 | 999746 |  14545 |   15453      
    17 |   2047 | 997439 |  15454 |   16362      
    18 |   1955 | 996937 |  16363 |   17271      
    19 |   1487 | 999705 |  17272 |   18180      
    20 |     97 | 999549 |  18181 |   19089      
    21 |    375 | 999161 |  19090 |   19998      
    22 |    645 | 994457 |  19999 |   20907      
    23 |   4468 | 998612 |  20908 |   21816      
    24 |    865 | 996342 |  21817 |   22725      
    25 |    402 | 998151 |  22726 |   23634      
    26 |    429 | 998823 |  23635 |   24543      
    27 |   1305 | 999521 |  24544 |   25452      
    28 |    974 | 998874 |  25453 |   26361      
    29 |   1056 | 999271 |  26362 |   27270      
。。。。。。      
```      
对于ID列，分布非常清晰（线性相关性好），存储元数据的过滤性好。而C1列，分布非常散，存储元数据的过滤性差。      
例如我要查id=10000的数据，直接查11号数据块，跳过其他数据块的扫描。      
而如果我要查c1=10000的数据，那么要查很多个数据块，因为能跳过的数据块很少。      
## 如何提升每一列的过滤性 - 存储编排      
对于单列来说，提升过滤性的方法非常简单，按顺序存储即可。      
例如前面的测试表，我们要提高C1的过滤性，按C1重排一下即可实现。      
重排后，C1列与物理存储（行号）的相关性会变成1或-1，即线性相关，因此过滤性就特别好。      
```      
postgres=# create temp table tmp_a (like a);      
CREATE TABLE      
postgres=# insert into tmp_a select * from a order by c1;      
INSERT 0 1000000      
postgres=# truncate a;      
TRUNCATE TABLE      
postgres=# insert into a select * from tmp_a;      
INSERT 0 1000000      
postgres=# end;      
COMMIT      
postgres=# select substring(ctid::text, '(\d+),')::int8 blkid, min(c1) min_c1, max(c1) max_c1, min(id) min_id, max(id) max_id from a group by 1 order by 1;      
 blkid | min_c1 | max_c1 | min_id | max_id        
-------+--------+--------+--------+---------      
     0 |      0 |    923 |   2462 |  999519      
     1 |    923 |   1846 |   1487 |  997619      
     2 |   1847 |   2739 |    710 |  999912      
     3 |   2741 |   3657 |   1930 |  999053      
     4 |   3658 |   4577 |   1635 |  999579      
     5 |   4577 |   5449 |    852 |  999335      
     6 |   5450 |   6410 |    737 |  998277      
     7 |   6414 |   7310 |   3262 |  999024      
     8 |   7310 |   8245 |    927 |  997907      
     9 |   8246 |   9146 |    441 |  999209      
    10 |   9146 |  10015 |    617 |  999828      
    11 |  10016 |  10920 |   1226 |  998264      
    12 |  10923 |  11859 |   1512 |  997404      
    13 |  11862 |  12846 |    151 |  998737      
    14 |  12847 |  13737 |   1007 |  999250      
。。。。。。      
c1列和物理存储（行号）的线性相关性      
postgres=# select correlation from pg_stats where tablename='a' and attname='c1';      
 correlation       
-------------      
           1      
(1 row)      
```      
糟糕的是，这么编排后，ID这个字段的过滤性就变差了。      
这是为什么呢？      
### 全局/全表 两列相对线性相关性      
实际上是ID和C1列的相关性，它控制了按C1排序后ID列变离散的问题。      
ID和C1的相关性如何呢？      
```      
postgres=# select corr(c1,id) from (select row_number() over(order by c1) c1, row_number() over(order by id) id from a) t;      
         corr                
-----------------------      
 -0.000695987373950136      
(1 row)      
```      
c1和id的全局（全表）相关性极差，导致了这个问题。      
（可以理解为这两个字段的八字不合）  
![pic](20170809_02_pic_004.jpg)  
### 局部/部分记录 两列相对线性相关性      
如果全表按C1或ID排序，那么另一列的离散度就会变得很高。      
但是，某些情况下，可能存在这样的情况，某些记录A和B字段的相关性很好，而其他记录他们的相关性不好。      
例子      