Attack
Accuracy
F-Score
F+R
R+R
P+P
96.1% 98.6 % 95.4%
0.952
0.945
0.99
5.3.1 Measurement of LLC misses
We have monitored the number of cache misses detected when
executing a complete RSA decryption. When trying different
keys, we have observed that the distributions change not only
depending on the attack, but on the secret key. For this reason,
the total amount of misses per encryption cannot be used
to detect ongoing attacks, thus the cache misses have to be
measured concurrently with the execution of the decryption.
We have also monitored the victim LLC misses period-
ically. We have collected samples for 1000 complete RSA
decryptions in each of the scenarios with a sampling rate
of 100 µs. The results obtained in this case show a varying
number of misses during the initialization steps. During this
initialization, considering exclusively the number of misses
caused in the different scenarios, is not possible to distin-
guish between attacks and the normal operation. Later on,
the number of misses gets stable and tends to zero during the
normal operation. Similarly, this trend can be observed dur-
ing the RELOAD+REFRESH attacks. On the contrary, both
FLUSH+RELOAD and PRIME+PROBE cause a noticeable
amount of misses. The concrete mean values of the misses
are presented in Table 5.
Since detection mechanisms such as CacheShield [10],
deﬁne a region in with some misses are tolerated to avoid
false positives, and only cache misses are considered, our
attack will not trigger an alarm. Figure 10 shows the section
of the decryption process in which the number of misses has
become stable for the different scenarios.
The RELOAD+REFRESH approach (as well as the other
attacks) are not synchronized with the decryption operation, as
a result, there are situations in which both victim and attacker
can try to access the target date simultaneously. If the victim
tries to execute the Multiply operation when the attacker is
ﬂushing and reloading the mentioned line, the victim may get
a miss. Therefore, a few misses can be observed in Figure 10
for our approach.
6 Detection evaluation
RELOAD+REFRESH causes a negligible amount of LLC
misses on the victim process. Thus, existing detection tech-
niques would fail to detect the attack unless adapted. Our
attack highlights a problem that has not been considered be-
fore in performance-counter-based detection systems: the
selection of counters is a hard problem because it is unknown
if future attacks could similarly evade the concrete selection
of counters of such systems. Besides, the number of avail-
able counters that can be read in parallel in each platform,
is limited. As a consequence, detection systems cannot be
arbitrarily expanded to deal with future attacks.
With the aim of quantifying the effect that our proposal has
on the victim, and in order to provide some insights about
which counters should a detection system consider to deal
with RELOAD+REFRESH, we have periodically monitored
different counters when executing the attacks against AES
and RSA and analyzed the outcomes. We have used PAPI to
collect such information. The sampling rate was set to 100 µs.
Given that not all the counters can be read in parallel, we have
repeated the experiments multiple times. We have merged the
results when the sampling intervals were in a range deﬁned
by the expected value ± a 10% of this sampling value. In the
particular case of RSA, the samples that refer to the beginning
of the execution have been removed (we focus on the stable
part). Finally, we have randomly selected 10000 samples per
algorithm and attack to conduct the analysis. The results of
the analysis are summarized in Table 5. Note that L2 cache
misses report the same value as L3 accesses, and similarly
L1 misses are L2 accesses, so only one of these values is
included in the Table.
As it can be inferred from the Table 5, a single counter re-
ferring to L3 misses or accesses cannot be used to distinguish
attacks and the normal operation for both target algorithms.
In the particular case of L3 accesses, it could be used for RSA
but not for AES. However, the L2 instruction misses counter,
could distinguish between attacks and non-attacks for both
algorithms. Note that if the sampling rate of the attack is re-
duced, the number of L2 misses would similarly be reduced.
As a solution, this value could be normalized with respect to
the total number of instructions executed.
USENIX Association
29th USENIX Security Symposium    1979
s
e
l
c
y
C
900
800
700
Real execution
Retrieved data
8.15
8.2
8.25
8.3
8.35
8.4
8.45
8.5
8.55
Time
8.6
·106
Figure 9: Example of a retrieved trace referred to an execution of a RSA decryption. The blue bars represent the real execution of
squares (points equal to 800) and multiplies (700). The yellow line represents the information retrieved, low reload times mean
detection of the Multiply execution.
Table 5: Mean and variance of the different counters collected during the execution of the attacks against AES and RSA. The
results were obtained using 10000 samples collected each 100 µs for each scenario.
AES Normal
AES R+R
AES F+R
AES P+P
RSA Normal
RSA R+R
RSA F+R
RSA P+P
Cycles
152000±750
148000±634
184000±3000
158000±1200
336000±11000
374000±38000
364000±50000
363000±55000
L3 misses L3 accesses L3 reads L2 instruction misses L2 accesses
2050±74
0±0.1
0±0.1
2035±114
2000±92
10±2
19±3
1810±95
14±26
139±316
26±14
308±163
285±240
127±38
112±61
211±222
714±62
713±60
676±65
452±140
100 ±206
233±114
200±110
177±159
697±63
702±61
676±66
451±139
99±204
231±113
199±108
174±156
31±7
212±15
186±12
209±18
7±12
60±23
97±54
78±83
s
e
s
s
i
m
C
L
L
150
100
50
0
no attack
R+R
F+R
P+P
40
45
55
50
Sample number
60
65
Figure 10: Detail of a trace of misses measured each 100 µs
for each of the approaches.
We can conclude that RELOAD+REFRESH changes the
performance of the system in an observable way in the low
level caches only. Consequently, counters referring to the LLC
are not enough to detect RELOAD+REFRESH. Then, the
assumption of previous detection mechanisms [10,13,64] that
LLC misses or accesses reveal the attacks does not hold for
RELOAD+REFRESH. Existing detection systems thus need
to be adapted or re-trained to include additional information
about low level cache events if they want to be able to detect it.
However, relying on low level cache events to detect the attack
can be tricky, since it is unknown how benign applications
that share the machine with the victim affect it. Therefore,
further analysis must be conducted to build a reliable detection
system.
7 Discussion of the results
The absence of randomness in the replacement algorithm
makes it possible to accurately determine which of the
elements located in a cache set will be evicted in case
of conﬂict. Also, the accurate timers included in Intel
processors, altogether with the cﬂush instruction, allow to
trace accesses to the different caches and to force the
cache lines to have the desired ages. We exploit these
facts to run RELOAD+REFRESH. In turn, the fact that
RELOAD+REFRESH works as expected, conﬁrms some of
our results about the replacement policy.
RELOAD+REFRESH is just one way to exploit the evic-
tion policy assuming some kind of memory sharing mecha-
nism enabled. In the case that the victim and the attacker do
not share memory, our attack can be prevented. It could be
prevented as well with some other general countermeasures
against cache attacks that limit the sharing of resources. How-
ever, as mentioned in Section 4, RELOAD+REFRESH can
be adapted to work in the absence of shared memory. We did
not further explore this attack variant, as it requires to keep
the replacement policy in Mode 2, which is also not available
on the newest Intel processors.
The knowledge of the eviction policy enables the usage of a
different access pattern to gain the information about the vic-
tim and to ensure that its data is really evicted from the cache,
reducing the amount of false positives. Thus, PRIME+PROBE
attacks, EVICT+RELOAD attacks or any attack requiring to
1980    29th USENIX Security Symposium
USENIX Association
evict some data from the cache can beneﬁt from our results.
For instance, the PROBE step can, in some cases, be reduced
to just one access to the eviction candidate.
8 Conclusion
This work presented a thorough analysis of cache replacement
policies implemented in Intel processors covering from 4th
to 8th generations. To this end, we have developed a method-
ology that allows us to test the accuracy of different policies
by comparing the data that each policy selects as the eviction
candidate with the data truly evicted after forcing a miss.
The RELOAD+REFRESH attack builds on this deep un-
derstanding of the platforms replacement policy to stealthily
exploit cache accesses to extract information about a victim.
We have demonstrated the feasibility of our approach by tar-
geting AES and RSA and retrieving as much information
as we can retrieve with other state-of-the-art cache attacks.
Additionally, we have monitored the victim while running
these attacks to conﬁrm that our attack causes a negligible
amount of last level cache misses, rendering it impossible to
detect with current countermeasures. Similarly, we show that
events in the L1/L2 caches can reveal the attack and should
be considered in detection systems. RELOAD+REFRESH
underlines a ﬂaw on such systems; they are limited and they
do not scale.
These results are not only useful for broadening the under-
standing of modern CPU caches and their performance, but
also for improving previous attacks and eviction strategies.
Our work also demonstrates that new detection countermea-
sures have to be designed in order to protect users against
RELOAD+REFRESH.
Acknowledgment
We thank our anonymous reviewers and our shepherd Daniel
Gruss for their valuable comments and constructive feedback.
This work was in part supported by DFG under Grant No.
427774779 and by the EU (FEDER), the Spanish Ministry
of Economy and Competitiveness, under contracts AYA2015-
65973-C3-3-R and RTC-2017-6090-3.
References
[1] A. Abel and J. Reineke. Measurement-based modeling
of the cache replacement policy. In 2013 IEEE 19th
Real-Time and Embedded Technology and Applications
Symposium (RTAS), pages 65–74, April 2013.
[2] A. Abel and J. Reineke. Reverse engineering of cache
replacement policies in intel microprocessors and their
evaluation. In 2014 IEEE International Symposium on
Performance Analysis of Systems and Software (ISPASS),
pages 141–142, March 2014.
[3] Onur Aciiçmez, Shay Gueron, and Jean-Pierre Seifert.
New branch prediction vulnerabilities in openssl and
necessary software countermeasures. In Proceedings of
the 11th IMA International Conference on Cryptography
and Coding, Cryptography and Coding’07, pages 185–
203, Berlin, Heidelberg, 2007. Springer-Verlag.
[4] Onur Aciiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert.
Predicting secret keys via branch prediction. In Pro-
ceedings of the 7th Cryptographers’ Track at the RSA
Conference on Topics in Cryptology, CT-RSA’07, pages
225–242, Berlin, Heidelberg, 2006. Springer-Verlag.
[5] Onur Aciiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert.
On the power of simple branch prediction analysis.
In Proceedings of the 2Nd ACM Symposium on Infor-
mation, Computer and Communications Security, ASI-
ACCS ’07, pages 312–320, New York, NY, USA, 2007.
ACM.
[6] Onur Acıiçmez and Werner Schindler. A Vulnerabil-
ity in RSA Implementations Due to Instruction Cache
Analysis and its Demonstration on OpenSSL. In Topics
in Cryptology–CT-RSA 2008, pages 256–273. Springer,
2008.
[7] Gorka Irazoqui Apecechea, Mehmet Sinan Inci, Thomas
Eisenbarth, and Berk Sunar. Wait a minute! A fast, cross-
vm attack on AES. In Research in Attacks, Intrusions
and Defenses - 17th International Symposium, RAID
2014, Gothenburg, Sweden, September 17-19, 2014. Pro-
ceedings, pages 299–319, 2014.
[8] Andrea Arcangeli, Izik Eidus, and Chris Wright.
In-
creasing memory density by using KSM. In OLS ’09:
Proceedings of the Linux Symposium, pages 19–28, July