### 5.3.1 Measurement of LLC Misses

We monitored the number of cache misses during a complete RSA decryption process. Our observations revealed that the distribution of cache misses varies not only based on the type of attack but also on the secret key used. Consequently, the total number of misses per decryption is not a reliable indicator for detecting ongoing attacks. Therefore, cache misses must be measured concurrently with the decryption process.

Additionally, we periodically monitored the victim's Last Level Cache (LLC) misses. We collected samples for 1000 complete RSA decryptions in each scenario, with a sampling rate of 100 µs. The results show a varying number of misses during the initialization steps, making it impossible to distinguish between attacks and normal operations based solely on the number of misses. However, as the decryption progresses, the number of misses stabilizes and tends to zero during normal operation. This trend is also observed during RELOAD+REFRESH attacks. In contrast, both FLUSH+RELOAD and PRIME+PROBE attacks cause a noticeable number of misses. The specific mean values of the misses are presented in Table 5.

Since detection mechanisms like CacheShield [10] define a tolerance region for cache misses to avoid false positives, our attack will not trigger an alarm. Figure 10 illustrates the section of the decryption process where the number of misses has stabilized for different scenarios.

The RELOAD+REFRESH approach, like other attacks, is not synchronized with the decryption operation. As a result, there are instances where both the victim and the attacker may attempt to access the target data simultaneously. If the victim tries to execute the Multiply operation while the attacker is flushing and reloading the same line, the victim may experience a miss. Therefore, a few misses can be observed in Figure 10 for our approach.

### 6. Detection Evaluation

RELOAD+REFRESH causes a negligible amount of LLC misses on the victim process, making it undetectable by existing detection techniques unless they are adapted. Our attack highlights a critical issue in performance-counter-based detection systems: the selection of counters is challenging because it is unknown if future attacks could evade the chosen counters. Additionally, the number of available counters that can be read in parallel on each platform is limited, which restricts the scalability of detection systems.

To quantify the impact of our proposal on the victim and to provide insights into which counters should be considered by detection systems, we periodically monitored various counters during attacks on AES and RSA. We used PAPI to collect this information, with a sampling rate of 100 µs. Since not all counters can be read in parallel, we repeated the experiments multiple times and merged the results when the sampling intervals were within ±10% of the expected value. For RSA, we excluded samples from the beginning of the execution, focusing on the stable part. We randomly selected 10,000 samples per algorithm and attack for analysis. The results are summarized in Table 5. Note that L2 cache misses report the same value as L3 accesses, and L1 misses are equivalent to L2 accesses, so only one of these values is included in the table.

From Table 5, it is evident that a single counter referring to L3 misses or accesses cannot distinguish between attacks and normal operations for both target algorithms. For L3 accesses, it could be used for RSA but not for AES. However, the L2 instruction misses counter can distinguish between attacks and non-attacks for both algorithms. If the sampling rate of the attack is reduced, the number of L2 misses would also decrease. To address this, the value could be normalized with respect to the total number of instructions executed.

### 7. Discussion of the Results

The absence of randomness in the replacement algorithm allows for accurate determination of which elements in a cache set will be evicted in case of conflict. The precise timers in Intel processors, combined with the `cflush` instruction, enable tracing of cache accesses and forcing cache lines to have the desired ages. We exploit these features to run RELOAD+REFRESH. The successful operation of RELOAD+REFRESH confirms some of our findings about the replacement policy.

RELOAD+REFRESH is one way to exploit the eviction policy assuming some form of memory sharing. If the victim and the attacker do not share memory, the attack can be prevented. It can also be mitigated with general countermeasures against cache attacks that limit resource sharing. However, as mentioned in Section 4, RELOAD+REFRESH can be adapted to work without shared memory. We did not explore this variant further, as it requires keeping the replacement policy in Mode 2, which is not available on the newest Intel processors.

Understanding the eviction policy enables the use of different access patterns to gain information about the victim and ensure that its data is evicted from the cache, reducing false positives. Thus, PRIME+PROBE, EVICT+RELOAD, and other attacks requiring data eviction can benefit from our results. For example, the PROBE step can sometimes be reduced to just one access to the eviction candidate.

### 8. Conclusion

This work provides a comprehensive analysis of cache replacement policies in Intel processors from the 4th to the 8th generation. We developed a methodology to test the accuracy of different policies by comparing the data selected for eviction with the data actually evicted after forcing a miss.

The RELOAD+REFRESH attack leverages this deep understanding of the replacement policy to stealthily exploit cache accesses and extract information about the victim. We demonstrated the feasibility of our approach by targeting AES and RSA, retrieving as much information as state-of-the-art cache attacks. We also monitored the victim during these attacks, confirming that our attack causes a negligible amount of last level cache misses, making it undetectable with current countermeasures. Additionally, we show that events in the L1/L2 caches can reveal the attack and should be considered in detection systems. RELOAD+REFRESH underscores a flaw in such systems; they are limited and do not scale.

These results not only enhance the understanding of modern CPU caches and their performance but also improve previous attacks and eviction strategies. Our work also highlights the need for new detection countermeasures to protect users against RELOAD+REFRESH.

### Acknowledgment

We thank our anonymous reviewers and our shepherd Daniel Gruss for their valuable comments and constructive feedback. This work was partially supported by DFG under Grant No. 427774779 and by the EU (FEDER), the Spanish Ministry of Economy and Competitiveness, under contracts AYA2015-65973-C3-3-R and RTC-2017-6090-3.

### References

[1] A. Abel and J. Reineke. Measurement-based modeling of the cache replacement policy. In 2013 IEEE 19th Real-Time and Embedded Technology and Applications Symposium (RTAS), pages 65–74, April 2013.
[2] A. Abel and J. Reineke. Reverse engineering of cache replacement policies in Intel microprocessors and their evaluation. In 2014 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), pages 141–142, March 2014.
[3] Onur Aciiçmez, Shay Gueron, and Jean-Pierre Seifert. New branch prediction vulnerabilities in OpenSSL and necessary software countermeasures. In Proceedings of the 11th IMA International Conference on Cryptography and Coding, Cryptography and Coding’07, pages 185–203, Berlin, Heidelberg, 2007. Springer-Verlag.
[4] Onur Aciiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. Predicting secret keys via branch prediction. In Proceedings of the 7th Cryptographers’ Track at the RSA Conference on Topics in Cryptology, CT-RSA’07, pages 225–242, Berlin, Heidelberg, 2006. Springer-Verlag.
[5] Onur Aciiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. On the power of simple branch prediction analysis. In Proceedings of the 2Nd ACM Symposium on Information, Computer and Communications Security, ASIACCS ’07, pages 312–320, New York, NY, USA, 2007. ACM.
[6] Onur Acıiçmez and Werner Schindler. A Vulnerability in RSA Implementations Due to Instruction Cache Analysis and its Demonstration on OpenSSL. In Topics in Cryptology–CT-RSA 2008, pages 256–273. Springer, 2008.
[7] Gorka Irazoqui Apecechea, Mehmet Sinan Inci, Thomas Eisenbarth, and Berk Sunar. Wait a minute! A fast, cross-VM attack on AES. In Research in Attacks, Intrusions and Defenses - 17th International Symposium, RAID 2014, Gothenburg, Sweden, September 17-19, 2014. Proceedings, pages 299–319, 2014.
[8] Andrea Arcangeli, Izik Eidus, and Chris Wright. Increasing memory density by using KSM. In OLS ’09: Proceedings of the Linux Symposium, pages 19–28, July 2009.