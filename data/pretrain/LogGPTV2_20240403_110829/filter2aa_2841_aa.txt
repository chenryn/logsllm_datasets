Author: Recar 
github: https://github.com/Ciyfly
w13scan浅析
w13scan 是一款由w8ay开发的python3的主被动扫描器
被动代理基于  baseproxy.py  作者是  qiye 
主动扫描默认是没有爬虫的
这里分析将分为几个部分 基础模块 主动扫描 被动扫描 扫描模块 学习的地方
w13scan浅析
简单的流程图
基础模块
一些环境检测和补丁
version_check()
modulePath()
patch_all()补丁
初始化
主动扫描
FakeReq
FakeResp 解析响应
被动扫描
扫描模块
什么时候启动扫描模块
start方法
run_threads 创建线程
task_run 运行任务
printProgress 输出目前的扫描任务情况
loader插件 主动扫描的解析插件 插件入口
PluginBase 基础插件父类
execute 传入req rsp poc主要函数
paramsCombination 组合dict参数
ResultObject 统一的结果类
self.success 输出漏洞
loader audit loader插件最终执行的方法
PerServer 检测模块 对每个domain的
backup_domain 基于域名的备份文件
errorpage 错误暴露信息
http_smuggling http smuggling 走私攻击
idea idea目录解析
iis_parse iis解析漏洞
net_xss net 通杀xss
swf_files 通用flash的xss
PerFolder 检测模块 针对url的目录，会分隔目录分别访问
backup_folder 扫描备份文件
directory_browse 判断是否是目录遍历
phpinfo_craw 查看此目录下是否存在 phpinfo文件
repository_leak 基于流量动态查找目录下源码泄露
PerFile 检测模块 针对每个文件，包括参数
analyze_parameter 反序列化参数分析插件
backup_file 基于文件的备份扫描
command_asp_code asp代码注入
command_php_code php代码注入
command_system 系统命令注入
directory_traversal 路径穿越插件
js_sensitive_content js文件敏感内容匹配
jsonp JSONP寻找插件
php_real_path 信息泄露
poc_fastjson 打fastjson的
shiro Shiro框架检测以及Key爆破
sqli_bool 布尔注入检测
sqli_error 报错注入
sqli_time 时间注入
ssti ssti模板注入探测
struts2_032 Struts2-032远程代码执行
struts2_045 Struts2-045远程代码执行
unauth 未授权访问探测插件
webpack webpack源文件泄漏
xss XSS语义化探测
SearchInputInResponse 解析html查找回显位置
如果回显位置是在html里
如果回显位置是在attibute里
测试 attibutes
测试 html
针对特殊属性进行处理
如果回显位置是注释里
如果回显位置是script里
如果回显的位置是  InlineComment  js单行注释
如果回显的位置是  BlockComment  js块注释
如果回显的位置是  ScriptIdentifier 
如果回显的位置是  ScriptLiteral 
学习的地方 (可以抄)
colorama 控制台彩色输出 支持windows
随机banner
load_file_to_module 另一种动态加载插件的方式
解析post数据类型
raw方法
text 自动解码响应体
将参数拆分为名称和值 返回字典
对url去重泛化模块
代理模块
xss 语法语义的形式
等等
简单的流程图
基础模块
一些环境检测和补丁
version_check()
检测是否py3
modulePath()
方法是如果是将这个w13scan.py打包成exe了的获取的路径 源自 sqlmap
patch_all()补丁
关闭https请求时的验证及 忽略urllib3的日志
def patch_all(): 
    disable_warnings() 
    logging.getLogger("urllib3").setLevel(logging.CRITICAL) 
    ssl._create_default_https_context = ssl._create_unverified_context 
    Session.request = session_request 
初始化
初始化一些路径 配置 和共享数据等
# 路径 
# setPaths(root) 函数 
path.root = root 
path.certs = os.path.join(root, 'certs') 
path.scanners = os.path.join(root, 'scanners') 
path.data = os.path.join(root, "data") 
path.fingprints = os.path.join(root, "fingprints") 
path.output = os.path.join(root, "output") 
# kb 
KB['continue'] = False  # 线程一直继续 
KB['registered'] = dict()  # 注册的漏洞插件列表 
KB['fingerprint'] = dict()  # 注册的指纹插件列表 
KB['task_queue'] = Queue()  # 初始化队列 
KB["spiderset"] = SpiderSet()  # 去重复爬虫 
KB["console_width"] = getTerminalSize()  # 控制台宽度 
KB['start_time'] = time.time()  # 开始时间 
KB["lock"] = threading.Lock()  # 线程锁 
KB["output"] = OutPut() 
KB["running_plugins"] = dict() 
KB['finished'] = 0  # 完成数量 
KB["result"] = 0  # 结果数量 
KB["running"] = 0  # 正在运行数量 
#conf 
conf.version = False 
conf.debug = DEBUG 
conf.level = LEVEL 
conf.server_addr = None 
conf.url = None
conf.url_file = None 
conf.proxy = PROXY_CONFIG 
conf.proxy_config_bool = PROXY_CONFIG_BOOL 
conf.timeout = TIMEOUT 
conf.retry = RETRY 
conf.html = False 
conf.json = False 
conf.random_agent = False 
conf.agent = DEFAULT_USER_AGENT 
conf.threads = THREAD_NUM 
conf.disable = DISABLE 
conf.able = ABLE 
# not in cmd parser params 
conf.excludes = EXCLUDES 
conf.XSS_LIMIT_CONTENT_TYPE = XSS_LIMIT_CONTENT_TYPE 
# 并且通过initPlugins函数加载检测插件 
for root, dirs, files in os.walk(path.scanners): 
    files = filter(lambda x: not x.startswith("__") and x.endswith(".py"), files) 
    for _ in files: 
        q = os.path.splitext(_)[0]
        if conf.able and q not in conf.able and q != 'loader': 
            continue 
        if conf.disable and q in conf.disable: 
            continue 
        filename = os.path.join(root, _) 
        mod = load_file_to_module(filename) 
        try: 
            mod = mod.W13SCAN() 
            mod.checkImplemennted() 
            plugin = os.path.splitext(_)[0] 
            plugin_type = os.path.split(root)[1] 
            relative_path = ltrim(filename, path.root) 
            if getattr(mod, 'type', None) is None: 
                setattr(mod, 'type', plugin_type) 
            if getattr(mod, 'path', None) is None: 
                setattr(mod, 'path', relative_path) 
            KB["registered"][plugin] = mod 
        except PluginCheckError as e: 
            logger.error('Not "{}" attribute in the plugin:{}'.format(e, filename)) 
        except AttributeError: 
            logger.error('Filename:{} not class "{}"'.format(filename, 'W13SCAN')) 
logger.info('Load scanner plugins:{}'.format(len(KB["registered"]))) 
# 加载指纹 
num = 0 
for root, dirs, files in os.walk(path.fingprints): 
    files = filter(lambda x: not x.startswith("__") and x.endswith(".py"), files) 
    for _ in files: 
        filename = os.path.join(root, _) 
        if not os.path.exists(filename): 
            continue 
        name = os.path.split(os.path.dirname(filename))[-1] 
        mod = load_file_to_module(filename) 
        if not getattr(mod, 'fingerprint'): 
            logger.error("filename:{} load faild,not function 'fingerprint'".format(filename)) 
            continue 
        if name not in KB["fingerprint"]: 
            KB["fingerprint"][name] = [] 
        KB["fingerprint"][name].append(mod) 
        num += 1 
logger.info('Load fingerprint plugins:{}'.format(num)) 
最后将初始化的数据与配置文件的 控制台传递的参数合并 作为程序初始的数据 
这里例如KB的设计方式和一些补丁函数应该是参考了  sqlmap 
主动扫描
通过输入url或者url文件 
请求后通过  task_push_from_name  函数创建个loader插件的任务
for domain in urls: 
    try: 
        req = requests.get(domain) 
    except Exception as e: 
        logger.error("request {} faild,{}".format(domain, str(e))) 
        continue 
    fake_req = FakeReq(domain, {}, HTTPMETHOD.GET, "") 
    fake_resp = FakeResp(req.status_code, req.content, req.headers) 
    task_push_from_name('loader', fake_req, fake_resp) 
FakeReq
 lib/parse/parse_request.py 
是对请求进行解析成各种字段
FakeResp 解析响应
 lib/parse/parse_response.py 
与req同理进行封装
上面两个里面有很多有用的方法 通过这两个类对http的请求和响应进行字段拆分 方便后续插件使用
被动扫描
    KB["continue"] = True 
    # 启动漏洞扫描器 
    scanner = threading.Thread(target=start) 
    scanner.setDaemon(True) 
    scanner.start() 
    # 启动代理服务器 
    baseproxy = AsyncMitmProxy(server_addr=conf.server_addr, https=True) 
    try: 
        baseproxy.serve_forever() 
    except KeyboardInterrupt: 
        scanner.join(0.1) 
        threading.Thread(target=baseproxy.shutdown, daemon=True).start() 
        deinit() 
        print("\n[*] User quit") 
    baseproxy.server_close() 
是以代理形式的 那么我们需要看下被动代理创建任务的地方 
位置是在  W13SCAN/lib/proxy/baseproxy.py#L473 的  do_GET 方法 
将这个方法改成了所有的get post方法都使用这个 do_get 方法
# baseproxy.py#566 
do_HEAD = do_GET 
do_POST = do_GET 
do_PUT = do_GET
do_DELETE = do_GET 
do_OPTIONS = do_GET 
在请求响应完这里推了任务
req = FakeReq(url, request._headers, method, request.get_body_data().decode('utf-8')) 
resp = FakeResp(int(response.status), response.get_body_data(), response._headers) 
KB['task_queue'].put(('loader', req, resp)) 
也就是说被动代理是每次流量请求响应完就会推任务到loader 然后loader再次解析推送任务
主动扫描和被动扫描 都是获取url创建loader的任务
扫描模块
什么时候启动扫描模块
如果是主动扫描就在loader任务创建完成后启动
for domain in urls: 
    try: 
        req = requests.get(domain) 
    except Exception as e: 
        logger.error("request {} faild,{}".format(domain, str(e))) 
        continue 
    fake_req = FakeReq(domain, {}, HTTPMETHOD.GET, "") 
    fake_resp = FakeResp(req.status_code, req.content, req.headers) 
    task_push_from_name('loader', fake_req, fake_resp) 
start() 
如果是被动扫描就在开始通过现场创建扫描模块即start方法
KB["continue"] = True 
# 启动漏洞扫描器 
scanner = threading.Thread(target=start) 
scanner.setDaemon(True) 
scanner.start() 
# 启动代理服务器 
baseproxy = AsyncMitmProxy(server_addr=conf.server_addr, https=True) 
start方法
 W13SCAN/lib/controller/controller.py#L66 
def start(): 
    run_threads(conf.threads, task_run) 
run_threads 创建线程
以配置设置的线程数俩创建线程
def run_threads(num_threads, thread_function, args: tuple = ()): 
    threads = [] 
    try: 
        info_msg = "Staring [#{0}] threads".format(num_threads) 
        logger.info(info_msg) 
        # Start the threads 
        for num_threads in range(num_threads): 
            thread = threading.Thread(target=exception_handled_function, name=str(num_threads), 
                                      args=(thread_function, args)) 
            thread.setDaemon(True) 
            try: 
                thread.start() 
            except Exception as ex: 