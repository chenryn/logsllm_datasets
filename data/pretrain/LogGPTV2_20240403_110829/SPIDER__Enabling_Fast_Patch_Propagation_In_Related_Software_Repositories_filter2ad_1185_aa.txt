title:SPIDER: Enabling Fast Patch Propagation In Related Software Repositories
author:Aravind Machiry and
Nilo Redini and
Eric Camellini and
Christopher Kruegel and
Giovanni Vigna
2020 IEEE Symposium on Security and Privacy
SPIDER: Enabling Fast Patch Propagation
in Related Software Repositories
Aravind Machiry†, Nilo Redini†, Eric Camellini¶, Christopher Kruegel†, and Giovanni Vigna†
†University of California, Santa Barbara
{machiry, nredini, chris, vigna}@cs.ucsb.edu
¶Politecnico di Milano
PI:EMAIL
Abstract—Despite the effort of software maintainers, patches to
open-source repositories are propagated from the main codebase to
all the related projects (e.g., forks) with a significant delay. Previous
work shows that this is true also for security patches, which represents
a critical problem. Vulnerability databases, such as the CVE database,
were born to speed-up the application of critical patches; however,
patches associated with CVE entries (i.e., CVE patches) are still
applied with a delay, and some security fixes lack the corresponding
CVE entries. Because of this, project maintainers could miss security
patches when upgrading software.
In this paper, we are the first to define safe patches (sps). An sp is a
patch that does not disrupt the intended functionality of the program
(on valid inputs), meaning that it can be applied with no testing; we
argue that most security fixes fall into this category. Furthermore, we
show a technique to identify sps, and implement SPIDER 1, a tool based
on such a technique that works by analyzing the source code of the
original and patched versions of a file. We performed a large-scale
evaluation on 341,767 patches from 32 large and popular source code
repositories as well as on 809 CVE patches. Results show that SPIDER
was able to identify 67,408 sps and that most of the CVE patches are
sps. In addition, SPIDER identified 2,278 patches that fix vulnerabili-
ties lacking a CVE; 229 of these are still unpatched in different vendor
kernels, which can be considered as potential unfixed vulnerabilities.
I.
INTRODUCTION
The open-source software model revolutionized the software
industry, and prior research shows that it is more secure [70], [33]
than its closed-source counterpart. However, propagating changes
and patches from the main repository of an open-source project
to all the related projects (forks) is a major problem [66]. While
related projects share a common “ancestry,” their code bases typically
diverge over time, as different teams add different features and
capabilities to each branch. As a result, when a problem is found and
fixed in one branch, it is not always easy to directly apply this patch
to another one [67]. For example, Android depends on a Linux kernel
fork, and upgrading it with patches from the main kernel repository
without thoroughly testing their effects could break Android.
To avoid this problem, and still be able to keep their software
up-to-date, the maintainers of related projects need to carefully track
other branches. When they see a fix that might be relevant for their
codebase, they have to “cherry-pick” the patch: That is, they have
to understand the patch and its behavior, adapt it to their own code
base, and finally ensure that the whole system, after applying the
patch, still works as expected. Not surprisingly, this is a manual
and resource-intensive process [72], [17]. As a result, as shown in
the Appendix D of our extended version [7], changes in the main
code base of a project are usually applied to the code of dependent
software with a significant delay [68]: Android 10, for example, is
based on Linux kernel 4.19, while the latest release of the Linux
kernel is version 5.3.8 [2].
1This is a short form for Safe Patch fInDER.
This problem becomes critical when we consider security
patches: in these cases, the fixes should propagate to all the
codebases as soon as possible. Vulnerability databases such as the
Common Vulnerabilities and Exposures (CVE) database were born
to facilitate this process: project maintainers can take them as a
reference to know which security-related patches they need to apply,
without having to find them manually. Despite the existence of these
databases, security patches still take a substantial amount of time to
propagate to all the project forks [57], [53], [22], [41]. In the year
2016, the Android maintainers patched 76 publicly known vulner-
abilities (i.e., CVEs) from the year 2014, two from 2013, and two
from 2012, which means that 80 disclosed vulnerabilities remained
unpatched in the Android code base for more than one year [1]. This
revelation attracted considerable public interest [5]. Recent work [48]
shows that attackers who monitor source repositories often get a head
start of weeks (and sometimes months) on targeting vulnerabilities
prior to any public disclosure. Furthermore, as we will show in this
study (Section VII-D), it is possible that the maintainers of a project
underestimate the severity of a patched bug, and fail to request a
corresponding entry in a vulnerability database (a CVE ID) [10].
When this happens, maintainers of related projects are not aware that
a patch actually addresses a security problem. This is a growing prob-
lem, as exemplified by the recent VLC security issue [16], which
is caused because developers of libebml failed to associate the
corresponding security fix with a CVE ID [11], and the vulnerability
existed for nearly two years after the fix was available. Unfortunately,
hackers are known to scan source repository commits for fixes that
might address vulnerabilities, and then check for the presence of
these vulnerabilities in related repositories [74]. Therefore, the secu-
rity fixes lacking a CVE ID provide a potential source of unfixed vul-
nerabilities as they are most likely not ported to related repositories.
Existing approaches that ease the process of cherry-picking
relevant patches rely on commit-related information, such as
code diff or commit messages [65], [76], [21], or they look for
specific patterns [56]. These tools have the advantage of being fast,
lightweight, scalable, and suitable to be used on large codebases.
However, either they only match simple patches, or analyze commit
messages, which are often not expressive enough to convey the scope
and effect of a change [24], [69], [4]. Other techniques attempt to
go a step further and analyze the semantic differences introduced by
a patch using static analysis [44], [45], [25], [26], [64] and symbolic
execution [52], [29], [62], [37]. Unfortunately, these techniques
suffer from scalability issues. Moreover, some of these approaches
also require the exact build environment [30] of the whole code
base, restricting their practicality and applicability to complex
software, such as the Linux kernel, the VLC player, the OpenBSD
OS, etc., as these software have many possible configurations [12].
Intuitively, an ideal solution, which would help maintainers
in selecting and applying important changes, would be a system
that is capable of identifying those patches that do not affect the
© 2020, Aravind Machiry. Under license to IEEE.
DOI 10.1109/SP40000.2020.00038
1562
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:21:07 UTC from IEEE Xplore.  Restrictions apply. 
intended functionality of the software. If the intended functionality
of the software is not changed by a patch, this patch can be applied
without the need for testing: we call these changes safe patches. In
this paper, we argue that a significant portion of all security-related
fixes falls under the category of safe patches [60]. Thus, a tool
that can identify safe patches could be used to monitor the main
repository and automatically alert or apply this kind of patches on
a target forked repository. This observation is also confirmed by
our anonymous survey (Appendix J) of maintainers and developers
of various open-source software projects.
To be effective and usable on large codebases, a system to identify
safe patches should at least satisfy the following requirements:
• R1: Only rely on the original and patched versions of the
modified source code file, without any other additional
information (e.g., commit message, build environment, etc.)
design a general technique to identify them.
• R2: Be fast, lightweight and scalable.
In this work, we design and implement a static analysis
approach that aims to identify safe patches and that satisfies both
the requirements above. Our approach is designed specifically to
target source code changes and to identify patches that could be
applied with minimal testing, as they do not modify the program’s
functionality. Specifically, we make the following contributions:
• We provide the first formal definition of safe patches, and
• We implement SPIDER, a system based on this technique,
that takes as input only the source code of the original and
patched file.
• We evaluate SPIDER on 341,767 commits taken from 32
source code repositories (Linux kernel repositories, An-
droid kernel repositories, interpreters, firmware, utilities and
various other repositories), as well as on 809 CVE patches.
• We identify 67,408 safe patches and show that SPIDER
could help developers in the process of selecting and
testing changes, resulting in a speed-up in the propagation
of security fixes.
• We also provide the Security Patch mode of SPIDER that
can precisely identify security patches. It identified 2,278
patches that most likely fix security vulnerabilities, despite
the fact that they were not associated with any CVE entry.
229 of these issues are still unpatched in several kernel forks.
As such, they can be considered unfixed vulnerabilities.
• We
are
releasing
SPIDER
and
sponding git server-side
at github.com/ucsb-seclab/spider.
hook
corre-
the
configuration
Intuitively, for a patch to be considered an sp, it should satisfy the
following two conditions:
• Non-increasing input space (C1): The patch should not
increase the valid input space of the program. That is, the
patched version should be more restrictive in the inputs that
it accepts. The assumption is that some of inputs that the
original program accepted resulted in security violations,
and the patched version “removes” these inputs as invalid.
• Output equivalence (C2): For all the valid inputs that
the patched program accepts, the output of the patched
program must be the same as that of the original program.
The condition C1 ensures that there is no need to add new test
cases, as there are no new inputs that are accepted by the patched
program 2. Furthermore, the condition C2 ensures that there is no
need to run the existing test cases as the output will be the same as
that of the original program (for all the valid inputs). Consequently,
if a patch satisfies the above two conditions then it can be applied
without any effect on the existing test cases. Of course, the purpose
of testing is to ensure that the program behaves as expected, so it is
always a recommended step after applying a patch. In Section II-B,
we define more formally the two conditions above.
A. Running Example
Listing 1 shows our running example, a C language example
of a safe patch in the unified diff format (i.e., where + and −
indicate inserted and deleted lines, respectively). In this example,
the programmer decided that it was necessary to add an extra length
check (Lines 3-5), presumably to protect against a buffer overflow
later in the program. In addition, the patch also includes the length
of the header (HDR) as part of a size check in Line 10.
This patch is safe. The inserted modifications to the variables
len and tlen do not change the output of the function.
Moreover, the extra conditional statement in Line 3 adds a missing
length check, thereby restricting the input space. That is, all
inputs where t->len is larger than MAX_LEN now lead to the
function returning an error, while those inputs were accepted by
the original function.
Figure 1 shows the control flow graph (CFG) after the
application of this example patch: underlined text indicates the
pieces of code inserted, while the left (blue) and right (red) children
of each basic block are the true and false branches, respectively.
B. Formal Definition
We first define terminology used throughout the paper:
•
Input i to a program: The input data with which the
program is executed; I indicates the set of all the possible
inputs to the program.
Function of a program: The symbol f denotes the original
function, and any subscript to it identifies its patched
version. For example: fp indicates the function f after
applying the patch p.
Error-handling basic blocks: The symbol BBerr denotes
the basic blocks of a function that are part of its
error-handling functionality. In Figure 1, BB2 is an
2However, for regression testing purposes, one may want to add a test case that
checks that the inputs are indeed invalid and the corresponding security flaw is
patched.
Unlike previous work, our approach is the first that focuses on
determining those patches that can be propagated to related projects
with minimal effort, and without defining a priori specific types
of changes or semantic characteristics that should be detected (i.e.,
we do not just target patches that fix a specific type of vulnerability).
We envision our system to be part of the recently introduced Github
security alerts [8], or it could be used to build a variant of the git
rebase feature that suggests patches that are most likely safe and
should be prioritized.
•
•
II. SAFE PATCHES
Our goal is to identify patches that can be applied without
subsequent testing. We call such patches safe patches (sps).
1563
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:21:07 UTC from IEEE Xplore.  Restrictions apply. 
long g e t r e a d s i z e ( s t r u c t dring ∗ t ) {
+
+
+
return −1;
t l e n ;
1
2
3
4
5
6
7 − len = t−>len ;
8
9
10
11
12
13
14 − t l e n = len ;
15
16
17
18
19
20
long len ,
i f ( t−>len > MAX LEN) {
}
. . .
len = t−>len + 4;
. . .
i f ( len % 2) {
}
. . .
t l e n = len − 4;
. . .
t−>t o t a l = t l e n ;
. . .
return t l e n ;
len += DEF SIZE ;
}
+
+
Listing 1: Running Example of a safe patch.
(cid:37)(cid:37)(cid:20)
(cid:21)(cid:29)(cid:79)(cid:82)(cid:81)(cid:74)(cid:3)(cid:79)(cid:72)(cid:81)(cid:15)(cid:3)(cid:87)(cid:79)(cid:72)(cid:81)(cid:30)
(cid:22)(cid:29)(cid:76)(cid:73)(cid:11)(cid:87)(cid:16)(cid:33)(cid:79)(cid:72)(cid:81)(cid:3)(cid:33)(cid:3)(cid:48)(cid:36)(cid:59)(cid:66)(cid:47)(cid:40)(cid:49)(cid:12)
(cid:37)(cid:37)(cid:21)
(cid:23)(cid:29)(cid:85)(cid:72)(cid:87)(cid:88)(cid:85)(cid:81)(cid:3)(cid:16)(cid:20)(cid:30)
(cid:37)(cid:37)(cid:22)
(cid:27)(cid:29)(cid:79)(cid:72)(cid:81)(cid:3)(cid:32)(cid:3)(cid:87)(cid:16)(cid:33)(cid:79)(cid:72)(cid:81)(cid:3) (cid:14)(cid:3)(cid:23)(cid:30)
(cid:20)(cid:19)(cid:29)(cid:76)(cid:73)(cid:11)(cid:79)(cid:72)(cid:81)(cid:3)(cid:8)(cid:3)(cid:21)(cid:12)
(cid:37)(cid:37)(cid:23)
(cid:3)(cid:20)(cid:20)(cid:29)(cid:79)(cid:72)(cid:81)(cid:3)(cid:14)(cid:32)(cid:3)(cid:39)(cid:40)(cid:41)(cid:66)(cid:54)(cid:44)(cid:61)(cid:40)(cid:30)
(cid:37)(cid:37)(cid:24)
(cid:20)(cid:24)(cid:29)(cid:87)(cid:79)(cid:72)(cid:81)(cid:3)(cid:32)(cid:3)(cid:79)(cid:72)(cid:81)(cid:3) (cid:16)(cid:3)(cid:23)(cid:30)
(cid:20)(cid:26)(cid:29)(cid:87)(cid:16)(cid:33)(cid:87)(cid:82)(cid:87)(cid:68)(cid:79)(cid:3)(cid:32)(cid:3)(cid:87)(cid:79)(cid:72)(cid:81)(cid:30)
(cid:20)(cid:28)(cid:29)(cid:85)(cid:72)(cid:87)(cid:88)(cid:85)(cid:81)(cid:3)(cid:87)(cid:79)(cid:72)(cid:81)(cid:30)
Fig. 1: Control flow graph of the patched program from Listing 1
error-handling basic block. We will explain later how
error-handling basic blocks are identified.
• We use the notation i(cid:2)→f to indicate that input i success-
fully executes through function f. That is, starting from
the entry basic block of f, and given input i, none of the
error-handling basic blocks (BBerrs) of f will be reached.
In other words, i represent a valid input to the function f.
• Output of a function: The output of a function f is its
return value and all the externally visible changes to the
program’s data. Specifically, the output includes the return
value, all writes to heap and global variables, and the
arguments to all function calls. For instance, the output of
the function get_read_size in Listing 1 is its return
value (line 19), and the value written to the pointer variable
t->total (line 17). Furthermore, output(i,f) indicates
the output of the function f when run with input i.
Now, we will use the definitions we introduced to formally
define two conditions (C1 and C2) introduced at the beginning
of Section II.
1) Non-increasing input space (C1): The non-increasing input
space (C1) condition requires that the patched program does not
accept any inputs as valid that are not also accepted as valid by the
original program. This condition can be defined at the granularity
of functions; that is, for C1 to hold, we require that all patched
functions, individually, do not accept any additional valid inputs.
1564
In other words, any valid input to a patched function must also be
a valid input to the corresponding original function. More formally:
(1)
∀i∈I|(i(cid:2)→fp)→(i(cid:2)→f).
In the case of Listing 1, the patch restricts the original input space
by adding an additional constraint (i.e., t → len > MAX LEN
in Line 3). As a result, all valid inputs to the patched function are
also valid inputs to the original function (but not vice versa). This
satisfies Equation 1.
2) Output correspondence (C2): The output correspondence
(C2) condition requires that, for all valid inputs, the output of the
patched program must be the same as the output of the original
program. This condition, again, can be defined at the function
granularity: For each patched function, for all corresponding valid
inputs, the patched function must produce the same outputs as the
original function. More formally:
∀i∈I|(i(cid:2)→fp)→(output(i,fp)=output(i,f)).
(2)
In the case of Listing 1, although the patch inserts changes
that modify the values of some variables (for example, len), the
changes do not affect the externally visible data of the program,
and thus, they do not change the output of the function, thereby
satisfying Equation 2.
If all the patched functions satisfy both Equation 1 and Equation 2,
then we can say that the patch satisfies the conditions C1 and C2.
As a result, the patch can be considered as a safe patch (sp). Note
that, as a trivial case, an empty patch (fp =f) satisfies Equations 1
and 2, making it an sp. Furthermore, there exist patches that do
not satisfy the above conditions but still could be applied without
testing, making our conditions sufficient but not necessary. We
refer all the interested readers to Appendix A, where we explain
our formalism with more examples.
III.
IDENTIFYING SAFE PATCHES
In this section, we introduce a general technique to determine
whether a given patch is an sp.
A. Program Dependency Graph (PDG)
•
Our technique leverages the concept of a program dependency
graph (PDG). A program dependency graph [36] captures both data
and control dependencies in a single graph. Formally, the PDG of a
function f, denoted as PDG(f) = (V,C,D), is a directed graph where
V = {v0, v1, ..., vn, En} is a set of nodes, one for each
instruction (v•) of the function. The additional node, En
represents the function entry.
• C is a set of directed, labeled edges, where each edge
(vi, vj, T|F ) represents the (direct) control dependency
of vj on vi. An instruction vj is control-dependent on
vi, and the edge is labeled as true (T) [or false (F)],
when vj is executed if and only if vi evaluates to true [or
false]. To complete the PDG, if an instruction v is not
control-dependent on any other instruction in the function
(in other words, it does not have any incoming control
flow edges), we connect it to the function entry node (En).
That is, we add the edge (En,v,T ) to C. Note that all
source nodes of control-flow edges are either conditional
statements (if, while, etc.) or the function entry node
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:21:07 UTC from IEEE Xplore.  Restrictions apply. 
(cid:6)(cid:15)
(cid:21)
(cid:21)
(cid:21)
(cid:21)
(cid:803)(cid:808)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1027)(cid:1)(cid:47)(cid:828)(cid:1030)(cid:39)(cid:32)(cid:41)
(cid:803)(cid:808)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1027)(cid:1)(cid:47)(cid:828)(cid:1030)(cid:39)
(cid:21)
(cid:797)(cid:805)(cid:808)(cid:45)(cid:32)(cid:47)(cid:48)(cid:45)(cid:41)(cid:1)(cid:47)(cid:39)(cid:32)(cid:41)
(cid:797)(cid:803)(cid:808)(cid:47)(cid:828)(cid:1030)(cid:47)(cid:42)(cid:47)(cid:28)(cid:39)(cid:1)(cid:1027)(cid:1)(cid:47)(cid:39)(cid:32)(cid:41)
(cid:797)(cid:796)(cid:808)(cid:36)(cid:33)(cid:854)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1001)(cid:1)(cid:798)(cid:855)
(cid:21)
(cid:797)(cid:797)(cid:808)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1022)(cid:1027)(cid:1)(cid:5)(cid:6)(cid:7)(cid:850)(cid:20)(cid:10)(cid:27)(cid:6)
(cid:797)(cid:805)(cid:808)(cid:45)(cid:32)(cid:47)(cid:48)(cid:45)(cid:41)(cid:1)(cid:47)(cid:39)(cid:32)(cid:41)
(cid:797)(cid:800)(cid:808)(cid:47)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1027)(cid:1)(cid:39)(cid:32)(cid:41)
(a) PDG of the original function in Listing 1
(cid:6)(cid:41)
(cid:21)
(cid:7)
(cid:7)
(cid:799)(cid:808)(cid:36)(cid:33)(cid:854)(cid:47)(cid:828)(cid:1030)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1030)(cid:1)(cid:14)(cid:2)(cid:25)(cid:850)(cid:13)(cid:6)(cid:15)(cid:855)
(cid:7)
(cid:21)
(cid:7)
(cid:804)(cid:808)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1027)(cid:1)(cid:47)(cid:828)(cid:1030)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1022)(cid:1)(cid:800)
(cid:804)(cid:808)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1027)(cid:1)(cid:47)(cid:828)
(cid:7)
(cid:800)(cid:808)(cid:45)(cid:32)(cid:47)(cid:48)(cid:45)(cid:41)(cid:1)(cid:828)(cid:797)(cid:809)
(cid:797)(cid:803)(cid:808)(cid:47)(cid:828)(cid:1030)(cid:47)(cid:42)(cid:47)(cid:28)(cid:39)(cid:1)(cid:1027)(cid:1)(cid:47)(cid:39)(cid:32)(cid:41)
(cid:797)(cid:796)(cid:808)(cid:36)(cid:33)(cid:854)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1001)(cid:1)(cid:798)(cid:855)
(cid:21)
(cid:797)(cid:797)(cid:808)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1022)(cid:1027)(cid:1)(cid:5)(cid:6)(cid:7)(cid:850)(cid:20)(cid:10)(cid:27)(cid:6)
(cid:797)(cid:801)(cid:808)(cid:47)(cid:39)(cid:32)(cid:41)(cid:1)(cid:1027)(cid:1)(cid:39)(cid:32)(cid:41)(cid:1)(cid:828)(cid:1)(cid:800)
(b) PDG of the patched function in Listing 1
where dotted and solid edges represent data and control dependencies, respectively. The function exit points are in double-bordered boxes.
Fig. 2: Program Dependency Graph (PDG) of the original and patched function in Listing 1,
En. In addition, all conditional statements will have at
least one outgoing control-dependency edge.
• D is a set of directed edges, where each edge (vi, vj)
represents a data dependency. That is, instruction vi
defines a variable that can reach the corresponding use in
instruction vj.
For our running example in Listing 1, Figures 2a and 2b show
the program dependency graphs for the original and the patched
function, respectively. The labels on the control dependency edges
[true(T ) or false(F )] indicate whether the destination node is
reachable from the source node via the true or false branch.
Control dependency versus control flow: The concept of control
dependency is different from the more commonly-used concept of
control flow. Control flow captures possible flows of execution, while
control dependency captures the necessary conditions that must hold
for the execution to reach a particular statement. We refer all the
interested readers to Appendix B, where we explain this in detail.
Control-Dependency Path: Given a PDG(f) = (V, D, C) of a
function f, we say that a control dependency path exists from
instruction x ∈ V to instruction y ∈ V , denoted as x (cid:5)→c y, if
there exists a path in the PDG from x to y that only follows
control-dependency edges. Formally,
x(cid:5)→c y ={|v•∈V ∧(x,v1,•)∈C∧
(vn,y,•)∈C∧∀1≤ilen > MAX_LEN) ==
F )∧(((len % 2)(cid:7)=0)==T )). That is, Line 11 is only executed
if (t->len |v•∈V ∧(x,v1)∈D∧
(vn,y)∈D∧∀1≤i is complete
if there is no data dependency path to x. Formally, (•,x)(cid:7)∈D. The
data dependency path example from Line 8 to 19 is complete as
there is no data dependency path to Line 8.
Also, note that although a data dependency path exists from
the instruction at Line 8 to instruction at Line 19, there is no
control-dependency path between these instructions. This is because
the execution of the instruction at Line 19 is not controlled by the
instruction at Line 8.
B. The SPIDER Approach
Our system is given as input a patch p, with f and fp being
a function before and after applying the patch, respectively. The
technique to detect whether p is a safe patch works in four steps,
as outlined in the following four sections.
1) Checking modified instructions: We first need to identify
what statements are affected by a patch, and determine whether
these modifications can be soundly analyzed given our requirement
R1. Recall that R1 requires that the analysis operates directly on
the original and patched versions of the modified source code file,
without any other additional information (e.g., commit message,
build environment, etc.).
Affected Statements: A statement can be affected either directly
or indirectly by the patch. We call a statement directly affected if
it is modified, inserted, deleted, or moved by the patch. A statement
is indirectly affected if it is either control- or data- dependent on any
of the directly affected statements. Given the set of directly affected
statements Ad and the PDG of the corresponding function, all the
instructions reachable from the statements in Ad, either through
control flow or data flow edges, are indirectly affected.
Consider the patch for our running example in Listing 1. Here,
the directly affected statements are at Lines 3, 4, 8, and 15. However,
looking at the corresponding PDG in Figure 2b, we can see that all in-
structions are reachable from the node that corresponds to the instruc-
tion at Line 3. Consequently, all statements are affected by the patch.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:21:07 UTC from IEEE Xplore.  Restrictions apply. 
Locally analyzable statement: We call a directly affected
statement locally analyzable if all the writes made by the statement
can be captured without any interprocedural and pointer analysis.
Specifically, the modifications made by the patch should not involve
any new function calls or pointer manipulation. Consider the patch
represented by Listing 2: The inserted statement at Line 4 is locally
analyzable. However, the inserted statement at Line 5 is not locally
analyzable, because it involves a new function call.
i n t k t h r e a d i n i t ( ) {
. . .
If a patch has any directly affected statements that are not locally
analyzable, we do not consider it an sp. This is because we cannot
soundly analyze the affected statements without analyzing the
effects on the whole program. Moreover, performing whole-program
analysis requires a static analysis tool (like LLVM), which in turn,
requires access to the sources of the entire program, violating our
requirement R1.
1
2
3 − t o t a l
t o t a l
4
i n i t c l e a n u p ( ) ;
5
. . .
6
i f ( t o t a l
7
8
}
9
. . .
10
11
s i z e = f i l e −>s i z e ;
s i z e = header + f i l e −>s i z e ;
}
Listing 2: Patch illustrating locally analyzable statements.
s i z e > MAX SIZE) {
. . .
+
+
2) Error-handling basic blocks: In the next step, we need to
identify all the error-handling basic blocks (BBerrs) in f and fp, so
that all the changes to the statements within BBerrs are discarded
and not considered in the next steps. This decision is based on the
assumption that any changes to error basic blocks do not disrupt
the original functionality (i.e., they just result in better or adjusted
error-handling). The remaining statements affected by p are then
analyzed to check if Equations 1 and 2 can be proved. We leverage
previous work [42], [73] to identify error-handling basic blocks, as
discussed in more detail in Section IV-D.
3) Non-increasing input space (C1): To verify the non-
increasing input space condition (C1), we need to ensure that the
patch does not accept more inputs than the original function. In
other words, the patch must not increase the valid input space for
the modified function.
Intuitively, if a patch does not affect any control-flow statements
(such as if, while, for, etc.), then it cannot change the input
space of the function. However, if a patch affects one or more
control-flow statements, we must verify that no additional inputs
can successfully execute through the function.
This can be done by first identifying the valid exit points
(VEP) of a function. The valid exit points of a function are those
instructions that, if reached during the execution of an input, imply
that the input successfully executed through the function. For