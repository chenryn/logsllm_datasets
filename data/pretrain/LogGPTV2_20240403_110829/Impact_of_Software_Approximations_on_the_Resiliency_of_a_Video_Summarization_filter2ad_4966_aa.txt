title:Impact of Software Approximations on the Resiliency of a Video Summarization
System
author:Radha Venkatagiri and
Karthik Swaminathan and
Chung-Ching Lin and
Liang Wang and
Alper Buyuktosunoglu and
Pradip Bose and
Sarita V. Adve
2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Impact of Software Approximations on the Resiliency of a
Video Summarization System
Radha Venkatagiri† Karthik Swaminathan‡ Chung-Ching Lin‡ Liang Wang¶
Alper Buyuktosunoglu‡ Pradip Bose‡ Sarita Adve†
†University of Illinois at Urbana-Champaign ‡IBM Research ¶University of Virginia
†{venktgr2, sadve}@illinois.edu ‡{kvswamin, cclin, alperb, pbose}@us.ibm.com ¶PI:EMAIL
Abstract— In this work, we examine the resiliency of a state-
of-the-art end-to-end video summarization (VS) application that
serves as a representative emerging workload in the domain
of real time edge computing. The VS application constitutes
key video and image analytic elements that are processed by
embedded systems aboard unmanned aerial vehicles (UAVs).
Real-time performance and energy constraints motivate the
consideration of approximations to the VS algorithm. However,
mission-critical UAV applications also demand stringent levels
of resilience to soft errors that are exacerbated with higher
altitude. In this work, we study the effects of three different
types of software approximations on the application level re-
siliency (to soft errors) of the VS algorithm. We show that our
approximations yield signiﬁcant energy savings (up to 68%),
with commensurate improvement in performance, without a
degradation in the application resilience. Further, by proposing
a novel quality metric (appropriate for the UAV vision analytics
domain) for the summarized video output, we show that even
though the rate of Silent Data Corruptions (SDCs) increases
slightly (<2%), the impact of these SDCs on output quality is
limited. Thus, we conclude that software approximation can be
utilized to achieve signiﬁcant gains in performance and energy
without affecting application resiliency.
I. INTRODUCTION
Real time edge computing [1], [2] is a rapidly growing ﬁeld
where real time data processing and other compute services are
pushed away from centralized points to the logical extremes or
edge of a network. This reduces the communication bandwidth
needed between edge devices (e.g., sensors) and the central
data center by performing analytics and knowledge generation
at or near the source of the data. One of the key enablers of
this trend is the presence of simultaneously high-performance
and energy-efﬁcient embedded systems that can be used to
do computing in devices that are at the edge of the network.
Real time edge computing has many applications which are
both military and civilian in nature, such as Unmanned Aerial
Vehicles (UAV), connected cars, industrial robotics, etc.
Figure 1 illustrates a real-life application of edge computing.
Here, a swarm of UAVs, supported by a terrestrial server at the
back-end, carry out tasks such as surveillance of hostile targets
This work was supported in part by the Defense Advanced Research
Projects Agency (DARPA), by the National Science Foundation under Grant
CCF-1320941, by the Center for Future Architectures Research (C-FAR)
and the Applications Driving Architectures (ADA) center, one of six centers
of JUMP, a Semiconductor Research Corporation program co-sponsored
by DARPA. The views expressed are those of the authors and do not
reﬂect the ofﬁcial policy or position of the Department of Defense or the
U.S. Government. This paper is: Approved for Public Release, Distribution
Unlimited.
Fig. 1: Co-operative swarm of UAVs engaging in computation for
real-time applications.
or rescue and recovery in the event of natural disasters. The
UAVs communicate data and other analytics with the ground
servers through wireless connections whose bandwidth, se-
curity and reliability might vary depending on physical and
environmental factors. Hence, for real-time critical tasks, it is
increasingly becoming essential that each UAV be equipped
as a highly efﬁcient mobile embedded system that can locally
perform essential real-time computing tasks. One such task
is often performed locally aboard the UAV is Video
that
Summarization [3]. This task involves extracting concrete
context from the input video stream – captured by the many
cameras on the moving UAV surveying a wide area – and
summarizing it, usually in the form of a panoramic image. The
panoramic image can then be transfered to a central ground
server for further processing, for say, tracking or identifying
rescue targets.
Edge computing platforms, such as that described above, are
often deployed in rugged terrains with harsh environmental
conditions and must satisfy the following requirements: a)
ensure high performance to meet real time deadlines, particu-
larly for mission-critical applications, b) be energy efﬁcient
to enable long range computing, and c) be resilient while
operating in harsh environments subject to sharp variations
in temperature, altitude and weather conditions, and tolerate
glitches in input and output [4].
Approximate Computing [5], [6] is increasingly gaining
traction as a viable approach for high performance and energy
2158-3927/18/$31.00 Â©2018 IEEE
DOI 10.1109/DSN.2018.00067
598
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:29:17 UTC from IEEE Xplore.  Restrictions apply. 
efﬁciency. Approximate computing environments allow delib-
erate, but controlled, relaxation of correctness and trade-off
computational accuracy for improvements in performance and
energy. Many edge computing applications involve processing
sensory signals (image, audio, etc.) which can inherently
tolerate inaccuracies in data and/or computation without com-
promising overall mission targets and goals. This presents
an opportunity to redesign these algorithms to incorporate
approximate computing with the goal of meeting stringent
performance and energy targets (requirements (a) and (b) from
above) under speciﬁed constraints.
However, while most approximate computing techniques
have in-built metrics and techniques to guarantee a certain
output quality, it is not clear how they work in the face of
sources of vulnerability in the processor, such as soft errors,
voltage noise and aging phenomena. Further, these effects
can be exacerbated (increased probability of radiation strikes
at high altitudes in UAVs) when the approximate computing
paradigm is adapted to the harsh conditions that these systems
encounter during their operation. For successful deployment in
edge computing environments, it is critical to ensure that the
application of approximate computing techniques which yield
performance and energy improvements not degrade the overall
system resiliency (requirement (c) from above).
This work focuses on studying the interaction between
software approximation and the application’s resiliency to
soft errors (henceforth referred to as application resiliency or
simply resiliency) and to our knowledge is the ﬁrst work to
do so. To demonstrate this interaction we analyze a state-of-
the-art end-to-end video summarization application [3] which
represents a typical and key vision analytics workﬂow exe-
cuted by embedded systems on-board UAVs.
In particular, we make the following contributions:
• We study the application resiliency of an end-to-end video
summarization application (henceforth termed as VS for
brevity) that serves as a representative workload for on-
board UAV processing. Speciﬁcally, we study the ap-
plication’s resilience to radiation-induced soft (transient)
errors, by performing runtime architectural fault injection
experiments. We perform all our analyses across two
distinct inputs that realistically portray the different types
of input video stream captured by cameras on the UAV.
• Performing resiliency analysis on a full, long-running
end-to-end workﬂow is more expensive (in time and
compute) than analyzing individual smaller kernels that
together constitute the larger work-ﬂow. We examine
this trade-off by estimating the resiliency of individual
representative kernels or hot functions in the VS appli-
cation. We show that the hot functions are sub-optimal
at capturing the behavior of the full application, thus
motivating the need to develop and evaluate realistic
applications with a full end-to-end workﬂow.
• We characterize the performance and energy of three
different software approximation techniques applied to
the VS algorithm. We show that
the approximations
yield signiﬁcant speedup and energy savings (up to 68%)
without compromising the quality of the panoramic image
output.
• We examine the resiliency of approximate VS algorithms.
We ﬁnd that the approximations yield similar resiliency
proﬁles to the baseline (precise) algorithm and in the
worst case lead to a slight
increase in Silent Data
Corruption (SDC) rates (up to 2%). To the best of our
knowledge, this is the ﬁrst work that examines the effect
of software approximations on application resiliency.
• We further examine the SDCs caused by the approximate
algorithms using a novel quality metric suitable to the
domain of UAV image analytics. We show that most
of the SDCs generated by the applied approximations
have small quality degradations and can potentially be
tolerated by the application.
In summary, we show that software approximation can be
utilized to achieve signiﬁcant gains in performance and energy
without affecting application resiliency. This work does not
claim to cover all possible types of approximations (or even
the best ones) or comment on the general resilience of different
techniques. Instead, the intent of the paper is to encourage
a comprehensive evaluation (performance, power, resilience)
of system optimizations and show that highly effective and
resiliency-aware software approximations are possible. While
we study a particular domain and report those results, the idea
of holistically measuring system resiliency across different
approximation knobs is generally applicable.
II. BACKGROUND
A. Video Summarization
UAVs are increasingly being used to perform tasks such
as surveillance of hostile targets and rescue and recovery in
the event of natural disasters. For decisive action in all these
scenarios, it is essential to ﬁrst extract and summarize the
concrete context from the input video stream captured by the
moving UAV. This operation is termed as Video Summariza-
tion. A sophisticated video summarization work-ﬂow requires
application of several Computer Vision techniques.
One such example of an end-to-end application ﬂow is
described in Viguier et al. [3], where the UAV multimedia
processing pipeline focuses on summarizing videos captured
by the camera on-board the UAV. The framework for achieving
this is shown in Figure 2. In order to achieve large data
reduction without signiﬁcant loss of events of interest, two
types of summarizations are included: coverage and event
summarization. Coverage summarization involves a complete
panorama generation which describes the entire video with a
single image that represents the entire spatial coverage area
of the camera. The coverage summarization relies on spatially
relating different video frames from the cameras, projecting
them into a common view space, and stitching them together
to build a single panorama. Event summarization comprises
of tasks such as detection, recognition and tracking of mov-
ing objects such as vehicles and pedestrians. Finally, both
intermediate results are integrated by overlaying the tracks (of
599
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:29:17 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 2: Video summarization for UAV videos.
moving objects) on the panorama to create a comprehensive
and concise summarization of a whole UAV video.
In this paper, we focus on coverage summarization. In
particular, we focus on algorithms that perform the task of
generating video panoramas of the landscape covered by
the cameras on a UAV and on energy-efﬁcient and reliable
implementations of the same.
B. Approximate Computing
Approximate computing is a fast growing trend that allows
controlled relaxation of correctness for better performance and
energy. Users in these systems are typically willing to tradeoff
some inaccuracies in the program output for other system
beneﬁts. Many techniques have been proposed that leverage
approximate computing at the software [7], [8], [9], [10], [11],
[12], programming language [13], [14], [15], [16], [17], [18],
[19] and hardware [20], [21], [5], [22], [23], [24] level for
improved performance, energy or reliability. Since we measure
application level resilience in this work, we focus our analysis
to software approximations. In particular, we study three broad
classes of software approximations.
(1) Input sampling: In this class of approximation, com-
putation is only performed over a subset of the input. This
class of approximation is especially popular in big data analyt-
ics [25] where the amount of data over which the computation
needs to be performed is prohibitive in time and resources.
(2) Selective Computation: Another popular class of ap-
proximations are those in which only a fraction of the work
is performed compared to the precise program. While the un-
derlying algorithm remains unchanged, selective computations
are simply skipped or dropped [7].
(3) Algorithmic Transformation: These approximations
transform the code and replace precise but expensive com-
putation with cheap but imprecise computation.
The selection of which approximations to apply depends on