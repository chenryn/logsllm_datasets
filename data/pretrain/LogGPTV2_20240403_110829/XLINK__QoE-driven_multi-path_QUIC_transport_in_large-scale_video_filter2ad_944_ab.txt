of today‚Äôs smartphones to get fast, smooth, and robust wireless
connectivity.
Road to QUIC: QUIC was initially developed internally at Google
to replace TCP [10]. Compared to TCP, QUIC is faster, more secure,
and offers protection against protocol ossification. It is reported that
QUIC now accounts for more than 40% of Google‚Äôs [29] and 75%
of Facebook‚Äôs Internet traffic [30]. The increasingly widespread
adoption of QUIC drives XLINK. We also learn from past pains
and gains from the deployment of MPTCP. We show that the user-
space property of QUIC is the key to overcome major hurdles such
as unsatisfactory performance, difficulties in dealing with load
balancers, obtaining OS-level support, and traversing middleboxes
that block the use of MPTCP [5, 31, 32].
Better mobility support: Mobility support is vital in wireless
communication. Unfortunately, today, roamings from Wi-Fi to cel-
lular are either slow or prone to failures [33]. QUIC introduces
connection migration (CM)[34], but CM requires resetting the con-
gestion window after migration, which may not be suitable for
video streaming, which needs sustained high bandwidth. Apple has
shown the benefits of MPTCP to support Wi-Fi-LTE roaming in
Siri, but to date, it is not clear whether multi-path remains effective
in deployed video services. We develop XLINK to answer these
questions and to explore the benefits of swiftly distributing packets
according to link variations in high mobility scenarios.
Multi-path in 5G: The advent of 5G makes multi-path capabilities
even more interesting. Although 5G offers higher bandwidth to
fulfill data-rate needs, the smaller signal coverage due to more
propagation loss and weaker penetration compared to LTE [35,
36] brings new challenges for 5G to meet its stringent reliability
and QoS guarantees. On the other hand, Wi-Fi 6 will probably
remain the most efficient method for indoor communication [37].
As a result, 3GPP introduced ATSSS in Release16, which features
simultaneous usage of 5G and other non-3GPP access (e.g., Wi-
Fi) [38]. Through a formal liaison, 3GPP has recently expressed
interest to IETF for protocols that enable steering, switching, and
splitting of traffic (primarily UDP) across multiple access where
QUIC is a focal point [39]. XLINK keeps pace with such a trend
with its ability to support 5G and Wi-Fi simultaneously.
420
3 EXPERIENCE WITH VANILLA
MULTI-PATH QUIC
In this section, we present our experience with the vanilla multi-
path QUIC (vanilla-MP 4). Two significant challenges of multi-
path performance are mobility and path delay difference. We first
study the dynamics of vanilla-MP in mobile environments. Then
we discuss the measured path delay difference when accessing
our video servers via different wireless technologies. Finally, we
show how vanilla-MP performs against single-path QUIC (SP) in a
large-scale A/B test in our production environments.
3.1 Fast changing wireless links
To understand how vanilla-MP behaves in the mobile environment,
we plot the dynamics of its in-flight packets replayed with a pair of
Wi-Fi & LTE traces collected when walking on our campus shown
in Fig. 1a and 1b with the Mahimahi emulation tool [40] 5. The
LTE trace was relatively stable, but on the contrary, the Wi-Fi
trace changed rapidly, with its throughput dropping to almost zero
from 1.7s to 2.2s; the congestion window (CWND) could not follow
such rapid change. As a result, the scheduler still kept sending
packets on that path, causing the number of in-flight packets to
even go up at around 1.8s. Such a rapid variation could lead to severe
HoL blocking since the video frame could not be delivered to the
application until all the stagnant packets on the slow path (Wi-Fi)
were recovered after a long period.
3.2 Path delays in heterogeneous networks
To understand the path delay differences. We measured RTTs when
accessing our video services via different wireless technologies. We
also deployed our own 5G SA testbed to understand 5G ultra-low
latency 6. We found that wireless technologies had a significant
impact on path delays. The median path delay of LTE was 2.7 times
and 5.5 times that of Wi-Fi and 5G SA, respectively, while the 90ùë°‚Ñé
percentile path delay of LTE was 3.3 times that of Wi-Fi. The path
delay difference further increased with cross-ISP delays in multi-
path 7. The large differences in path delays could impact video
start-up delays and request completion time in short video services.
3.3 Deployment of vanilla-MP
Table 1: Reduction of rebuffer rate (vanilla-MP vs. SP)
Days #
1
2
3
4
5
6
7
-34.6
-54.6
-47.7
-48.3
-96.5
-77.8
-41.5
Improv. (%)
Finally, we verified the effectiveness of vanilla-MP by conducting
a large-scale A/B test against single-path QUIC (SP) in our short
video services. The experiment methods are discussed in Sec. 7.2.
In Fig. 1c, we plot the median, 90ùë°‚Ñé percentile and 99ùë°‚Ñé percentile
4We implemented vanilla-MP with the min-RTT packet scheduler as described
in MPQUIC [12]. The min-RTT packet scheduler is also the default packet scheduler
used in Linux kernel MPTCP.
5We used the multi-path extension of Mahimahi. The experimental methods are
discussed in Appx. B.
6At the time of writing, 5G SA is not commercially used.
7In practice, we also need to account the cross-ISP delay, which cause further
increase in the delay of the secondary path. The relative increase of the measured
cross-ISP LTE path delays in percentage are shown Table 4 in Appx. A and note that
when employed as the secondary path, the delay could go up by 50% as the result of
crossing ISP boarders.
SIGCOMM ‚Äô21, August 23‚Äì28, 2021, Virtual Event, USA
Z. Zheng et al.
(a) Wi-Fi Path
(b) LTE Path
(c) A/B Test (Vanilla-MP vs. SP)
Figure 1: Experience with vanilla multi-path QUIC (vanilla-MP). (a) and (b) vanilla-MP in fast varying wireless environments. (c) A/B test
(vanilla-MP vs. single-path QUIC) on request completion time.
video chunk request completion time (RCT) collected throughout
one week. The figure reveals the following findings: (1) Vanilla-MP
was only effective at times on the median and 90ùë°‚Ñé percentile RCT,
and could lead to worse performance (days 1, 3, 4, and 5). The largest
median RCT degradation was 16%. (2) Vanilla-MP always lead to
degraded 99ùë°‚Ñé percentile RCT, which could be even 28% worse than
SP (days 4 and 7). In Table 1, we report the reduction of client-side
video rebuffer rate (measured as the total amount of video rebuffer
time normalized by the total amount of video play time) observed
through the course of a week. A negative number indicated that
the rebuffer rate of vanilla-MP was worse than that of SP. The
rebuffer rate of vanilla-MP deteriorated. Instead of decreasing, it
increased more than 34%, with the largest increase up to 96%. Such
a result was not surprising due to the issues discussed above and
therefore, vanilla-MP failed to meet the criteria of achieving no
worse performance than single-path transport.
4 XLINK DESIGN OVERVIEW
In this section, we present the design overview of XLINK. The
goal is to achieve optimal user-perceived QoE (e.g., low latency
and small re-buffering) with the least possible overhead cost. As
shown in Fig. 2, XLINK is designed as a lightweight end-to-end
multi-path QUIC extension deployed in mobile apps and edge
servers. It enables a multi-homed mobile client to communicate
to a remote server with simultaneous transmissions over multiple
wireless interfaces (e.g., Wi-Fi and cellular). Unlike past solutions
such as MPQUIC and MPTCP that operate unassisted from applica-
tions, XLINK is driven by the recent trends of cross-layer network
designs [41] and closely integrates transport with video apps to
achieve high performance and cost-efficiency at the same time. The
core of XLINK is to take the opportunity of QUIC as a user-space
protocol and leverage the user-perceived video QoE in multi-path
scheduling and management.
Architecturally, XLINK‚Äôs QoE-driven scheduling is built on top
of a client-server feedback mechanism. A XLINK client captures
user-perceived QoE signals (e.g., video player cached frames and
video player frame-rate) and uses ACK_MP extension frame (Sec. 6
and Fig. 16) to carry those signals to a remote video server to con-
trol its scheduling. The use of QoE_control_signal field controls
the coupling and decoupling of multiple paths. It allows XLINK
to overcome multi-path HoL blocking without incurring unneces-
sary cost overhead, which is crucial for large-scale deployability
(Sec. 5.2). XLINK further handles large path delay differences by of-
fering first-video-frame acceleration (5.1), wireless-aware primary
path selection (5.3), and fastest-path ACK_MP to avoid excessive
delay from the slow path and improve video start-up.
Algorithmically, XLINK utilizes packet re-injection to decouple
multiple paths. Unlike past re-injection [6], XLINK implements
priority-based re-injection at two levels: transport (QUIC stream)
level and application (video frame) level (Sec. 5.1). The stream
priority-based re-injection accounts for QUIC‚Äôs concurrent streams
that request different portions of a video. It ensures that re-injected
packets of an early stream are sent before later streams‚Äô pack-
ets, thus preventing stream blocking at transport. The video-frame
priority-based re-injection differentiates video frame urgency within
a stream. It treats the first frame of a video with the highest priority
to speed up video start-up. In terms of QoE feedback control, XLINK
introduces double thresholding control (5.2.2), which achieves re-
sponsiveness and cost efficiency and offers flexibility to balance
performance and cost.
At the protocol level, XLINK builds on top of the multi-path ex-
tensions proposed in draft [11], which incorporates PATH_STATUS
and ACK_MP extension frames to manage path status and ac-
knowledge packets received from different paths. The only dif-
ference is that the current XLINK implementation (used in this
experiment) sends QoE feedback as an additional field in ACK_MP
frame, instead of sending the QoE feedback in the independent
QOE_CONTROL_SIGNALS frame specified in the draft.
5 QOE-DRIVEN SCHEDULING AND PATH
MANAGEMENT
This section discusses the details of QoE-driven multi-path schedul-
ing and path management, which enables XLINK to achieve supe-
rior user-perceived QoE with minimized cost overhead. It consists
of three major components: stream and video-frame priority-based
packet re-injections, QoE feedback control, and QoE-aware path
management. We overcome multi-path HoL blocking, stream block-
ing, and excessive delay at video start-up with stream and video-
frame priority-based re-injections. To reduce cost, QoE feedback is
used to control the redundancy associated with re-injection. We fur-
ther handle path delay differences in heterogeneous networks with
QoE-aware path management that incorporates wireless-aware
primary path selection and fastest-path multi-path ACK.
5.1 Priority-based re-injection
Why re-injection? Re-injection is used to decouple multiple paths.
As discussed earlier, the root cause of multi-path HoL blocking is
the coupling of multiple paths when the scheduler splits packets
421
071421283500.61.21.82.43.0101001000Throughput (Mbps)Inflight packet/CWND (KB)Time (s)Link capacityInflight packetCWND061218243000.61.21.82.43.0101001000Throughput (Mbps)Inflight packet/CWND (KB)Time (s)Link capacityInflight packetCWND 0 1 2 3 4 51234567 Request complete time (s)DaysSP-medianVanilla MP-medianSP-95pct.Vanilla MP-95pct.SP-99pct.Vanilla MP-99pct.XLINK: QoE-Driven Multi-Path QUIC Transport in Large-scale Video Services
SIGCOMM ‚Äô21, August 23‚Äì28, 2021, Virtual Event, USA
Figure 2: The overview end-to-end architecture of XLINK.
Figure 3: Use re-injection to overcome multi-path HoL blocking:
(a) Without re-injection, packets lost on the slow path would block
the fast path. (b) With re-injection, lost packets on the slow path
can be quickly recovered from the fast path.
across them. To explain how multi-path HoL blocking happens
through such coupling, Fig. 3(a) shows the typical process of a
scheduler splitting packets from its sending queue (pkt_send_q)
across a fast path (purple) and a slow path (blue). The packets sent
by the fast path and the slow path complement each other and the
client waits successful delivery on both paths to obtain the whole
chunk of video. Blocking happens if pkt 6 and pkt 7 on the slow
path are lost (maybe due to a sudden link outage) because the client
cannot proceed until the loss recovery on the slow path, which
can take as long as a retransmission timeout (RTO). Re-injection
is a technique that allows us to decouple multiple paths with the
use of redundant duplicate packets, which is shown in Fig. 3(b). In
re-injection, the sender keeps track of a queue for unacknowledged
packets (unacked_q). Back to the same example, when there are
no more packets in the pkt_send_q to send, the sender can send
duplicates of the unacknowledged packets 6 and 7 with re-injection
into the fast path without waiting for the loss recovery on the slow
path, allowing the receiver to continue consuming data without
suffering from the blocking effect.
Priority-based re-injection. However, traditional packet reinjec-
tion is not enough to achieve good video QoE. The first thing we
need to address is the stream blocking effect. Unlike TCP, QUIC
transport layer has the concept of QUIC Stream. A connection can
carry multiple streams with each separately flow controlled and
loss recovered. In short-video transport, the video player may si-
multaneously request multiple streams, with each downloading
a small portion of the video 8. As shown in Fig. 4 (a) and (b), the
pkt_send_q now contains two streams, Stream 1 and Stream 2. The
8When the network is good, the use of multiple concurrent streams allows the
media player to pre-fetch video chunks.
Figure 4: Different modes of re-injection: (a) Traditional (append-
ing) mode, (b) stream priority-based mode to address stream block-
ing and (c) video-frame priority-based mode to address video frame
blocking.
traditional re-injection works in an appending mode in Fig. 4(a).
If pkt 4 is lost on the slow path in this mode, the scheduler can
only re-inject it at the end of the pkt_send_q, behind Stream 2,
which is not optimal. As the contents of streams play in sequence,
stream 2 now blocks the delivery of stream 1. Indeed, an early