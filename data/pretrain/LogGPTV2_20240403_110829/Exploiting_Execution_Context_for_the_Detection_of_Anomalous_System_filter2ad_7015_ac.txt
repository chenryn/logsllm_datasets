very tight threshold for that context. In another context that appears far less
frequently in the training set, the instantiated models may have a more coarse
approximation of the feature values, resulting in a relatively loose threshold.
3.4 Detection Phase
When an audit record is received during the detection phase, the system ﬁrst
checks if the context and system call pairing associated with it (that is, (cid:2)C, s(cid:3))
has been observed during the training period. If the pairing was not recorded
during the training phase, the system issues an alert. For pairings that were
observed during the training phase, the system uses the values for C and s to
look up the aggregate model that was created during training, uses the model to
evaluate the argument values contained in the audit record, and issues an alert
if the resulting score exceeds the threshold associated with (cid:2)C, s(cid:3).
3.5 Auditing Subsystem
This section provides details of the implementation used for the evaluation of the
system. The system described in this paper is composed of two modules: a kernel-
resident audit module that records system call invocations and the application
calling context in which they appear, and a user-space audit daemon that devel-
ops models of system call argument values using machine learning techniques.
The two components communicate via an entry in the proc ﬁlesystem.
Both the learning and detection phases require a stream of system call invoca-
tion events. System call event auditing is accomplished using an implementation
based on the Snare audit module, which is an existing loadable kernel module
written for the Linux operating system by Intersect Alliance [20]. This mod-
ule intercepts system calls through the use of system call interposition, which
is realized by overwriting the kernel’s table of function pointers to system calls
with pointers to wrapper functions. These wrapper functions generate an audit
record prior to calling the original system call and before returning its result.
To realize the goals of this project, several signiﬁcant changes were made to the
Snare module:
User stack unwinding. When audited system calls are invoked, in addition
to recording the arguments to the system call, the user’s memory space is
probed iteratively to unwind the frames stored on the user application’s
stack. This process is very similar to the one followed by a debugger as it
recovers the stack frames from the memory of a running application.
Virtual addresses encountered on the user’s stack are matched against
the memory-mapped address ranges maintained in the process control block.
When a matching address range is found, the stack address is normalized
by subtracting the starting address of the memory-mapped region, and the
module records the normalized address along with the i-node of the ﬁle
containing the memory mapped code. In this way, address consistency is
maintained across runs of an application, or in the face of dynamic loading
and unloading of code by the application.
12
D. Mutz et al.
Signaling of user audit daemon replaced with support for blocking
reads. The original version of the Snare audit module delivered a signal to
the audit daemon each time an event was generated. This created perfor-
mance problems during periods of high load, which were often accompanied
by a high volume of audit data. Our version uses a kernel wait queue, which
avoids signal storms during periods of heavy load.
4 Empirical Validation
The purpose of this empirical study is to investigate the impact of considering
the calling context of system calls on the detection capability of the system. The
evaluation consists of three parts. Section 4.1 compares context-speciﬁc models
to context-insensitive models with respect to the generation of false positives.
Next, Section 4.2 addresses the question of whether context-speciﬁc models oﬀer
an improvement in precision over context-insensitive models. Section 4.3 evalu-
ates the ability of the system to detect real attacks launched against two moni-
tored applications. Finally, Section 4.4 quantiﬁes the computational overhead of
context-sensitive monitoring.
4.1 Comparing Context-Sensitive and Context-Insensitive
Argument Models
Since models trained speciﬁc to particular calling contexts occurring in an appli-
cation have a smaller, more restrictive set of training examples, they potentially
suﬀer from the drawback of being too sensitive to variations in argument values
observed during the detection phase. Therefore, it is critical to determine their
false positive rate relative to context-insensitive argument models.
In order to quantify the rate of false positives observed in practice in each
case, we collected audit data on root-owned daemons and periodic (cron) appli-
cations running on 10 hosts in an undergraduate computer science instructional
laboratory over a period of 64 days. During the recorded period, each of the hosts
were accessed regularly by approximately 100 unique users (administrators and
undergraduate users) who interacted with the system in local X11 sessions in
Table 4. False positive rates for models that do not consider calling context
Application Total Events False Positives False Positive Rate
0.00 × 10+00
cfenvd
9.63 × 10−03
cfexecd
0.00 × 10+00
crond
6.67 × 10−03
cupsd
5.17 × 10−02
idmapd
2.97 × 10−04
sendmail
1.30 × 10−05
slocate
1.45 × 10−04
sshd
0.00 × 10+00
ypbind
2.89 × 10−04
Overall
11,918,468
457,812
1,265,345
291,022
57,316
5,514,158
11,914,501
13,347,164
30,268
44,796,054
0
4,407
0
1,942
2,962
1,559
155
1,931
0
12,956
Exploiting Execution Context for the Detection of Anomalous System Calls
13
Table 5. False positive rates using context-sensitive models
Application Total Events Unknown Context Model Violation Overall FP Rate
1.76 × 10−06
2.27 × 10−03
0.00 × 10+00
8.87 × 10−04
0.00 × 10+00
2.31 × 10−04
1.54 × 10−05
1.56 × 10−04
0.00 × 10+00
1.09 × 10−04
11,918,468
457,812
1,265,345
291,022
57,316
5,514,158
11,914,501
13,347,164
30,268
44,796,054
cfenvd
cfexecd
crond
cupsd
idmapd
sendmail
slocate
sshd
ypbind
Overall
Alarms
0
31
0
252
0
154
183
1,705
0
2,325
Alarms
21
1,007
0
6
0
1,122
0
379
0
2,535
addition to remote logins. The recorded audit data was checked for known at-
tacks and is, to the authors’ knowledge, free of attacks. We also tracked publicly
released vulnerabilities on security mailing lists and noted no vulnerabilities in
the monitored software. In all cases, the system was trained and evaluated using
data collected at each host. In the interest of conciseness, however, detection
performance is reported in aggregated form (i.e., measurements are combined
from all 10 hosts used in the study).
Of the 64 days of recorded audit data, the ﬁrst 39 days were used for training
the argument models. Thresholds were computed using the following 7 days of
audit data, and detection was performed on the ﬁnal 18 days. The false positives
produced by the system for context-insensitive models (i.e., models that ignore
calling context) are shown in Table 4, and Table 5 summarizes the false positive
rates for context-sensitive models. Separate ﬁgures are given for alarms generated
for unknown contexts (i.e., contexts that were not seen during the training phase)
as well as for alarms generated from anomalous model scores.
From the tabulated data, it is clear that the overall false positive rates of
context-sensitive models outperform context-insensitive models by a factor of
about 2.7. Further inspection of the 1,007 unknown context alarms for the
cfexecd application revealed that they were repeated instances of alarms for
40 contexts that did not appear in the training data. Additionally, all 1,122 un-
known context alarms issued for the sendmail application, and 348 of 379 of the
alarms issued for sshd each occurred on a single day. This suggests that it would
be straightforward for an administrator to add these contexts to the known set
and eliminate future instances of those alarms. Taken together, unknown context
and model violation alarms represent an average of 34 alarms per application
per day. This is a relatively manageable number, and post-processing tools could
likely improve this ﬁgure by summarizing duplicate alarms [17].
Table 5 shows a large number of model violation alarms (1,705) for the sshd
application. Further analysis showed that 652 (more than 38%) of those viola-
tions were triggered by models for the setresuid system call. These anomalous
calls were the result of users that had not been observed during the training period
14
D. Mutz et al.
logging into the system. In an academic computer network, this level of irregular
user behavior can be expected. However, on more sensitive networks, these alarms
could be valuable indicators of misuse or misconﬁguration of login policies.
4.2 Cross-Comparison of Context-Speciﬁc Models
Section 2 proposed the metric Q for quantifying the degree to which argument
values are unique across the various execution contexts in which a particular
system call occurs. The experiment described in this section is intended to further
validate the context-speciﬁc detection approach. The experiment performs cross-
comparison of context-sensitive models for system calls si on events drawn from
all contexts C in which si occurs. Whereas Q measured the extent to which
the observed argument sets (ASs) are disjoint, this experiment is designed to
measure the extent to which learned context-speciﬁc models are able to capture
these diﬀerences.
To show this, the models are trained for each context exactly as described in
Section 4.1, but each system call is evaluated not only on the model for its native
context, but on all non-native models as well. If context-speciﬁc models capture
context-speciﬁc features, we would expect events to be classiﬁed as normal in
their native context and as anomalous in all other contexts.
Table 6. Cross-comparison of context-sensitive models. Rate of false positives for
events in native and non-native contexts are shown.
Application Native FP rate Non-native FP rate
0.967
cfenvd
cfexecd
0.877
1.000
crond
0.947
cupsd
1.000
idmapd
sendmail
0.933
0.974
slocate
0.855
sshd
1.000
ypbind
0.950
Average
0.000 × 10+00
6.771 × 10−05
0.000 × 10+00
8.660 × 10−04
0.000 × 10+00
2.793 × 10−05
1.536 × 10−05
1.277 × 10−04
0.000 × 10+00
1.105 × 10−04
Table 6 shows that context-sensitive models are, in the vast majority of cases,
able to correctly classify events as belonging or not belonging to the context for
which the model was trained. This evidence supports three conclusions. First, the
calling context of system calls is a strong predictor of the subclass of argument
values observed at the system call interface for a number of applications in a
real-world, operational setting. Second, learning models are able to capture this
diﬀerentiated behavior. Finally, the results suggest that context-speciﬁc mod-
els capture a more restricted range of behavior than context-insensitive mod-
els. This implies that context-sensitive models restrict the number of options
that an attacker has to inﬂuence the arguments of system calls while avoiding
detection.
Exploiting Execution Context for the Detection of Anomalous System Calls
15
4.3 Measuring the Detection Capability of Call Stack-Speciﬁc
Argument Models
Source code and binary audits were performed for the 9 services and application
used in our study, but no vulnerabilities were found. Therefore, in order to
measure the attack detection capability of call stack-speciﬁc argument models,
we tested the system using attacks on a proprietary setuid application as well
as on an Apache web server. Following is a description of the attacks and the
corresponding detection performance of the system.