message manipulation.
We start from the observation that the BASICNET rule
does not account for the ability of an attacker to overshadow
parts of a message. Overshadowing can be used to replace
121
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:52 UTC from IEEE Xplore.  Restrictions apply. 
components in pairs with known messages or to transform
an (unknown) message M into an (unknown) message M(cid:2)
if M and M(cid:2) differ only in a few bits.
In the context of a model where signals traverse distances,
as required for modeling distance bounding protocols, an
attacker that is far from a receiver (e. g., the veriﬁer) may
want to use overshadowing to modify the message M of a
sender (e. g., the prover) that is close to the intended recipient
into a message M(cid:2). Let t be the time at which the sender
sends the message M. Because the attacker is further away,
the attacker needs to send the overshadowing bits (M ⊕ M(cid:2))
at time t(cid:2), where t(cid:2) < t, to ensure that they arrive at the
same time at the receiver. If the attacker knows the (parts of
the) message that he wants the recipient to receive, this is
straightforward. However, if the attacker does not know the
message M yet at time t(cid:2) and requires the message M to
compute M(cid:2), he needs to guess the positions where M and
M(cid:2) differ, then guess the bits of M(cid:2) on these positions, and
ﬁnally overshadow M on these positions with the guessed
bits. We assume that guessing many of the bits of M correctly
can only be done with negligible probability. Subsequently,
the attacker can transform M into M(cid:2) with non-negligible
probability if and only if the Hamming distance between M
and M(cid:2) is small.
To account for these manipulations, we require two
deﬁnitions. First, the components of a message M are deﬁned
as components(M ) = components(M1) ∪ components(M2)
if M = (cid:4)M1, M2(cid:5) and components(M ) = {M} otherwise.
Second, the set LHW of messages that may have a low
Hamming weight is deﬁned as
L, L(cid:2)
::= latom | L ⊕ L(cid:2) | 0
where latom = Agent ∪ Const. This excludes nonces, keys,
hashes, encryptions, and the exclusive-or of such messages
since the probability that these have a low Hamming weight
can be assumed to be negligible, unless such a message
cancels itself out. We do not include pairs of low Hamming
weight messages since we already allow the attacker to
modify components of pairs individually.
Our new network rule EXTNET is shown in Figure 11.
According to the rule, an agent B can receive a message M
if for all components X of M, there is a corresponding send
event (with compatible timestamp) of a message M(cid:2) such
that M(cid:2) has a component Y with a low Hamming distance
to X, i. e., the Hamming weight of X ⊕ Y is low.
Example 5. We assume that the attacker does not know
NV and NP. To overshadow NP with NI in the message
(cid:4)NV , NP(cid:5) sent by an honest P , the attacker has to send
NI (early enough) such that both sends together result in a
receive of (cid:4)NV , NI(cid:5).
In Example 3, the attacker overshadows some bits to
transform the (unknown) message NV ⊕ NP ⊕ P into the
(unknown) message NV ⊕ NP ⊕ P (cid:2). In our model, the
tr ∈ TR P ∈ Honest
NP ∈ (NonceP \ subterms(tr))
tr · (t, SendP (h(NP ))[P1, NP ]) ∈ TR
PROVCOM
tr ∈ TR V ∈ Honest
(t, RecvV (COM )) ∈ tr
NV ∈ (NonceV \ subterms(tr))
tr · (t, SendV (NV )[V1, COM , NV ]) ∈ TR
VERCHAL
tr ∈ TR P ∈ Honest
(t, RecvP (NV )) ∈ tr
tr · (t, SendP (NV ⊕ N P )[P2, NP , NV ]) ∈ TR
(t, SendP (X)[P1, NP ]) ∈ tr
PROVRESP
tr ∈ TR P ∈ Honest
(t, SendP (X)[P2, NP , NV ]) ∈ tr
tr · (t, SendP (signP (NV , NP , P ))[]) ∈ TR
PROVAUTH
tr ∈ TR V ∈ Honest
(tchal , SendV (NV )[V1, h(NP ), NV ]) ∈ tr
(tauth , RecvV (signP (NV , NP , P ))) ∈ tr
(tresp, RecvV (NV ⊕ NP )) ∈ tr
tr · (t, ClaimV (V, P, (tresp − tchal ) ∗ c/2)) ∈ TR
VERRESP
Figure 12. Formalization of the Brands-Chaum Protocol.
attacker does not have to perform any action since (NV ⊕
) ⊕ (NV ⊕ NP ⊕ P ) =P ⊕ P (cid:2) ∈ LHW. This
NP ⊕ P (cid:2)
captures the intuition that allowing the attacker to ﬂip some
bits of unknown messages is equivalent to allowing for some
bit-errors introduced by the wireless channel.
The set of possible traces TR for our extended model is
deﬁned as the least set closed under the START-rule, the
attacker rule INTR, the extended network rule EXTNET, and
the rules formalizing the analyzed protocol.
Protocol Formalization: We formalize the original
signature-based version of the Brands-Chaum by the rules
in Figure 12. Pi and Vi are constants used in the local
state of the veriﬁer and prover in step i. The rules ensure
that the previous steps have been executed, the required
messages have been received, and nonces are freshly chosen
(not subterm of the trace tr). The ﬁnal rule VERRESP uses
the times when the challenge was sent and the time when the
reply was received to compute an upper bound on the distance
between P and V . We refer the reader to [3] to further details
on modeling protocols in this kind of framework.
Case studies: We have analyzed the Brands-Chaum
protocol and its various ﬁxes in our extended framework. For
example, we have proven that if we modify Brands-Chaum
to include explicit linking, the Distance Hijacking attack is
no longer possible. Note that for proving the correctness of
the version with implicit linking, we need the assumption
122
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:52 UTC from IEEE Xplore.  Restrictions apply. 
they
that veriﬁers cannot receive the bits/message that
sent themselves, e. g., because different channels are used.
Without this assumption, Brands-Chaum is vulnerable to
Distance Fraud attacks (by reﬂection or using low Hamming
weight overshadowing). As another example, our extended
framework also reveals that modifying the response to
NV ⊕ NP ⊕ P is not secure since the attack from Example 3
is captured. Note that in the basic framework from [3], which
did not account for message manipulation on the wireless
channel, this attack was not captured and a security proof
was possible. This clearly shows the effect of the adversary’s
additional powers in our extended model.
For a complete description of our case studies and their
formalization we refer the reader to [26].
VI. MULTI-PROTOCOL ENVIRONMENTS
So far, we discussed Distance Hijacking attacks in single-
protocol environments, where both dishonest and honest
prover run the same distance bounding protocol. However, it
is possible that veriﬁer-prover pairs execute different ranging
and distance bounding protocols, for example when they
belong to different domains. We call such environments
multi-protocol environments.
Distance Hijacking in Multi-protocol Environments: In
what follows we show that there are plausible multi-protocol
environments in which protocols that are resilient to Distance
Hijacking in single-protocol environments become vulnerable
again to Distance Hijacking.
We deﬁne a multi-protocol environment MPE as a set
of triplets, where a triplet (A, B, R) denotes that agent A
may execute the protocol role R (e. g., the prover role of
the Brands and Chaum protocol) when communicating with
B, and where at least two different protocols are contained
in the set. We say that a distance bounding protocol DB is
vulnerable to a Distance Hijacking Attack in a multi-protocol
environment MPE if a dishonest prover P can perform a
successful Distance Hijacking attack against a veriﬁer V
running DB in the veriﬁer role in that environment (and
hence (V, P, DB (veriﬁer)) ∈ MPE ).
It is easy to see that, given any distance bounding protocol,
a multi-protocol environment can be constructed in which this
protocol will be vulnerable to Distance Hijacking attacks. For
example, all distance bounding protocols will be vulnerable
to Distance Hijacking if run in the same environment with
a protocol that uses a similar distance measurement phase,
but that gives a dishonest prover full control over the way
the response bits are computed by the honest prover. This
is not such an unlikely scenario, since it is plausible that in
the same environment in which a veriﬁer and a dishonest
prover run e. g., Hancke and Kuhn, an honest prover runs
an insecure ranging protocol that supports the same type
of distance measurement phase as the Hancke and Kuhn
protocol. This insecure ranging protocol could easily allow
a dishonest prover to set the bits that the honest prover
msc Distance bounding protocol
Prover
P
Veriﬁer
V
NP 0, NP 1 ∈R {0, 1}(cid:2)
V, {NP 0, NP 1, V }kvp
NV ∈R {0, 1}(cid:2)
Rapid bit exchange for i = 1 to l
if N i
V = 0,Ri = N i
P 0
if N i
V = 1,Ri = N i
P 1
N i
V
Ri
Verify that received Ri’s
correspond to NP 0 and NP 1
Figure 13. A Distance Bounding Protocol that enables Distance Hijacking
on Hancke-Kuhn protocol in multi-protocol environments.
uses in the distance measurement phase (e. g., for debugging
purposes). It might also be that this insecure ranging protocol
is simply enabled as a feature for non-critical applications
and therefore coexists with the Hancke and Kuhn protocol
on the devices (and thus shares the same hardware / distance
measurement implementation with the Hancke and Kuhn
protocol). This means that no multi-prover distance bounding
protocol deployments can be guaranteed to be secure unless
additional measures are in place.
In the above example we used an insecure protocol. How-
ever, similar attacks are possible using only protocols that
are secure in single-protocol environments. We show this on
an example of the Hancke-Kuhn distance bounding protocol
from [12]. We construct a multi-protocol environment in
which the veriﬁer runs the Hancke-Kuhn protocol, and the
honest provers support a minor variation of the Hancke-
Kuhn protocol that is secure against Distance Hijacking
in a single-protocol environment. This protocol, shown in
Figure 13, differs from the Hancke and Kuhn protocol in
that the prover does not compute the values of registers NP 0
and NP 1 but that these are computed by the veriﬁer and
sent (conﬁdentially) to the prover. This protocol modiﬁcation
would make sense if one would, e. g., assume that the prover
does not have a good random number generator (e. g., an
RFID tag).
A Distance Hijacking attack in this environment works as
follows. A dishonest prover P initiates the original Hancke
and Kuhn protocol with the veriﬁer V , and derives shared
123
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:52 UTC from IEEE Xplore.  Restrictions apply. 
register values with V (for details see Hancke and Kuhn
protocol [12]). P then acts as a veriﬁer and initiates the
modiﬁed Hancke and Kuhn protocol from Figure 13 with the
honest prover P (cid:2). P then provides the register values to P (cid:2)
as speciﬁed in the modiﬁed protocol. V and P (cid:2) then execute
a rapid bit exchange and V believes that this exchange was
executed by P .
Observe that the attack does not require the two protocols
to share the same long-term keys: V veriﬁes the use of the
key as prescribed by the Hancke and Kuhn protocol, which
was provided by P , and remains unknown to P (cid:2). However,
the attack strictly requires V and P (cid:2) to use similar hardware
for the fast response phase.
Similarly, a modiﬁed version of the Brands and Chaum
protocol can be constructed that, if run next to the Hancke and
Kuhn protocol, would also enable a Distance Hijacking attack
against the Hancke and Kuhn protocol. This phenomenon
is similar to the Chosen Protocol attack in cryptographic
protocol analysis. We relate the two concepts in Section VIII.
Protecting against Distance Hijacking in Multi-Protocol
Environments: Previously, we proposed countermeasures that
prevent Distance Hijacking in single-protocol environments.
We now discuss some approaches that can mitigate such
attacks in multi-protocol environments.
For multi-protocol environments the obvious solution is to
try to ensure that all protocols in an environment use different
(incompatible) hardware for their distance measurement
phase. This is analoguous to the concepts of tagging or
disjoint encryption for classical cryptographic protocols. Thus,
attacks in multi-protocol environments can be prevented by
better regulation in distance bounding protocol deployment
and construction. Minor application-speciﬁc modiﬁcations to
the distance measurement phase (e. g., including application-
speciﬁc dummy bits) would already prevent a number
of attacks. Similarly, manufacturer-speciﬁc or deployment
speciﬁc hardware modiﬁcations would also protect against
multi-protocol attacks; this can, however, be expensive.
There are a number of scenarios in which such deploy-
ment and regulatory protection measures cannot be used.
Application-speciﬁc modiﬁcations of the distance measure-
ment phase are particularly difﬁcult to implement; given the
tight timing constraints in the distance measurement phase,
this phase will be processed in hardware. It is also likely
that only a few implementations of the distance measurement
phase will emerge in the future, limiting available application-
speciﬁc modiﬁcations of this phase. This ﬁnally means that
most distance bounding protocols will likely use the same
implementation of the distance measurement phase.
Accounting for these scenarios, we propose an alternative
solution that makes use of “prover honeypots”. Recall that to
execute a Distance Hijacking attack, a dishonest prover either
needs to be able to successfully claim to have executed a
distance measurement phase that was executed by an honest
prover, or needs to make an honest prover execute a distance
measurement phase using speciﬁc bits. The prevention of
the false distance measurement claim naturally extends from
single- to multi-protocol environments — this type of attack
can be prevented by using protocols that are resilient to
Distance Hijacking in single-protocol environments. However,
as we have shown, protocols that are resilient to Distance
Hijacking in single-protocol environments cannot prevent
attacks in a multi-protocol environment where an honest
prover is made to execute a distance measurement phase
using the bits provided by a dishonest prover. We aim to
detect such attacks by the use of prover honeypots.
Our solution works as follows. The veriﬁer ﬁrst sets up a
number of virtual or real honeypot provers which are either
physical or virtual devices that are placed in the vicinity of
the veriﬁer. These honeypot provers are created either by the
veriﬁer or by the devices that the veriﬁer trusts and controls.
To other provers, honeypot provers claim either their true
or false locations/identities, and they support a broad set of
ranging and distance bounding protocols. The idea behind
this setting is that when a dishonest prover mounts a Distance
Hijacking attack, it chooses one of the honeypot provers to
abuse in his attack. Besides setting up honeypot provers, the
veriﬁer also limits its operation to speciﬁc distance bounding
protocols: it executes only distance bounding protocols that
force a dishonest prover to reveal (most of the bits of) its
secret key (that it shares with the veriﬁer) to the honest prover
if he wants to execute a Distance Hijacking attack. This is
commonly the case for protocols that are resilient against
Terrorist Fraud. Thus, if a dishonest prover exploits one of
the honeypots in a Distance Hijacking attack, the (majority
of the) bits of the key that it shares with the veriﬁer will
be revealed to the honeypot prover. For the case in which
the prover wants to be certain about the success of Distance
Hijacking, all of the bits of his key will be revealed to the
honeypot. In order to check if a Distance Hijacking attack
was executed, the veriﬁer, after the execution of a distance
bounding protocol with a given prover, simply needs to ask
his honeypot provers to send him the bits that they used in
any recent distance measurement phase. If those bits allow
the reconstruction of the (majority of the bits of the) key that
the veriﬁer shares with the prover [14], the veriﬁer concludes
that the prover attempted to execute a Distance Hijacking
attack.
VII. LOCATION HIJACKING
In this section we generalize Distance Hijacking to
Location Hijacking. We consider the problem of location
veriﬁcation, or position veriﬁcation, in which a set of veriﬁers
establishes the location of a prover, even though this prover
may act dishonestly, i. e., the prover can pretend to be at
another location than he really is. The objective of a location
veriﬁcation protocol is to ensure that the location of the
prover is reliably determined. Such protocols often build
on distance bounding protocols. A prover repeatedly uses a
124
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:52 UTC from IEEE Xplore.  Restrictions apply. 
a number of veriﬁers. The prover aggregates the challenges