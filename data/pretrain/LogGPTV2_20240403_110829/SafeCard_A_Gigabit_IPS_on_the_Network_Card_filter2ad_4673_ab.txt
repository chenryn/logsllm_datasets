loads, but at much lower cost. In essence, we perform a ﬁrst protocol scrub of
the traﬃc [2]. Later on we will see that higher-layer protocols are scrubbed as
well.
In relation to security, TCP segment overlap is worth mentioning individu-
ally because it has frequently been abused. Meant to circumvent IDS detection,
overlap is powerless against in-line scrubbing. Overlapping traﬃc may be indica-
tive of broader malicious intent, especially when the overlapping segments diﬀer
in content. For this reason its appearance should be notiﬁed to the ﬂow-based
ﬁltering unit, as well. Flow-based detection is discussed further in Section 3.4.
Another security issue concerns out-of-order packet arrival. Received data
must be buﬀered in a reconstruction window until missing data arrives, dramat-
ically increasing memory footprint on links with large bandwidth-delay products.
Arrival of many out-of-order segments can lead to memory exhaustion, a situa-
tion that is potentially exploitable.
One solution is to check payloads per-packet and then pass them on imme-
diately. Feasibility of immediate processing depends on whether ﬁltering algo-
rithms can checkpoint and move around in the datastream. Special care must
be taken not to let an exploit slip through because the signature is larger than
the minimal malicious payload and happens to span two packets.
Even when immediate processing is not possible SafeCard is not subvertible
through memory exhaustion. Since all packets are kept in a single circular buﬀer
there is no memory allocation in the datapath at all. This advantage is oﬀset
by the increased chance of packet drop due to a full buﬀer. Overwriting a single
packet may invalidate an entire (benign) TCP stream if used with in-place re-
assembly. Therefore we have to keep buﬀers large enough to deal with incidental
delays.
3.2 Payload Inspection
Static string matching (as for example provided by hardware CAMs and our own
CardGuard [7]) is too limited for detecting most intrusion attempts. Pattern
matching in SafeCard is therefore implemented using superior regular expres-
sion matching. Our engine, ruler, is innovative in that it matches packets against
the whole set of regular expressions in parallel, which allows it to sustain high
traﬃc rates. Matched substrings can be accepted or rejected entirely, or rewrit-
ten to an altered output packet. Rewriting is of use in address translation or
318
W. de Bruijn et al.
anonymisation, but here we are interested only in Ruler’s high-speed selection
mechanism.
Regular expression matching has been used in IDSs before, but only in special
cases. Traditionally, the cost of matching scales linearly with the number of signa-
tures. Because there are thousands of known signatures, scanning at high-speed
is infeasible. Instead, string-matching algorithms whose runtime complexity re-
mains constant regardless of patternset-size have to be used in the common case.
Ruler can completely replace string-matching because it is a generalisation of and
therefore provably as eﬃcient as Aho-Corasick (AC), a popular constant-time
pattern-matching algorithm that is employed for instance in Snort.
Ruler’s internal design is based on a Deterministic Finite Automaton (DFA).
This allows it to merge many patterns—or more precisely their DFA state
machines—into a single state machine. Each state in the Ruler DFA encodes
a character in a pattern. Patterns that share preﬁxes will reuse subpaths in the
DFA and thus do not impose additional burden apart from their unique tails.
One caveat is that states themselves become more costly to compute when the
number of outgoing connections grows, because internal control-ﬂow is that of a
switch statement. Ruler reverts to an AC automaton when run with only static
strings, but it can be extended, for instance with (unbounded) repetitions.
Compiling regular expressions like those in Ruler is a well-studied prob-
lem3 [32]. The standard approach is to ﬁrst generate a Non-deterministic Fi-
nite Automaton (NFA) from the regular expressions. This NFA contains state
transitions for all matching possibilities of all regular expressions in the ﬁlter.
The NFA is then converted to its DFA form using the subset algorithm. This
algorithm traces execution paths through the NFA, and lists the sets of NFA
states that can be reached for each known NFA state set and each possible input
character. Each distinct NFA state set is a distinct state in the DFA.
To the DFA we apply general optimisations: (i) we merge overlapping parts of
the patterns as much as possible, (ii) we eliminate unreachable patterns and ma-
chine states, (iii) we stop the state machine as soon as a verdict can be reached,
and (iv) we use a standard state minimisation algorithm [33] to construct a DFA
with the smallest number of states.
The Ruler DFA is further optimised for traﬃc processing. Network packets
often contain ﬁxed-length stretches of bytes that need not be inspected at all,
such as header ﬁelds. Instead of having the state machine go through the mo-
tions for these bytes, we support ‘jump’ states that skip past them. Also, we
have provisions for content-dependent ﬁeld lengths, such as IP headers, whose
length is deﬁned in the header itself. Continuous streams place further demands
on the matching engine. An engine must be able to handle multiple streams
concurrently, each of a-priori unknown length. Ruler is capable of checkpointing
its state so that it can switch between streams at will. When data arrives for a
stream it will resume exactly where it left oﬀ.
3 In fact, things are not this simple. Ruler also supports packet rewriting, which re-
quires tagging of positions in the regex for which we need a generalisation of the
DFA construction algorithm [31]. This is beyond the scope of this paper.
SafeCard: A Gigabit IPS on the Network Card
319
A second performance beneﬁt stems from the method of Ruler’s execution.
Instead of running in an interpreter, Ruler code is compiled straight to assembly.
Back-ends exist for network stream processors, kernel modules and application
code. Even Verilog (for FPGAs) can be produced, although this is currently in
its infancy. When used within Streamline, Ruler automatons can be compiled,
shipped and instantiated at runtime on the supported hardware with minimal
intervention.
With the help of our snort2ruler compiler most Snort signatures can be
automatically incorporated in the Ruler DFA, but Ruler also has its own high-
level input language. This supports protocol-speciﬁc constructs such as TCP
options and variable-sized ﬁelds to aid signature generation. Let us illustrate
the language with an example: scanning for the Slammer worm. Slammer is
a 376 byte payload encapsulated in a UDP packet destined for port 1434. To
ﬁnd Slammer-based intrusion attempts in a packet stream, we would use the
following ﬁlter:
include "layouts.rli"
filter slammer [accept_reject]
IPv4_Ethernet_header
IPv4_header with [protocol=17]
UDPv4_header with [dest=1434,length=376]
4 1 1 1 1 1 * "." "D"|"d" "L"|"l" "L"|"l" * => accept;
We require that packets start with Ethernet, IPv4 and UDP headers. The layout
of these headers is deﬁned in the include ﬁle layouts.rli, which is not shown
here. We then scan the payload of such packets for the signature "04 01 01 01
01 01.*[.][Dd][Ll][Ll]". In SafeCard the packet is dropped when a match
is made.
3.3 Protocol-Speciﬁc Detection of Polymorphic Attacks
Scanning streams for known signatures using regular expressions catches a large
class of known and immutable attacks. However, future worms are expected to
be increasingly polymorphic. While exploits are less likely to exhibit advanced
polymorphism than payloads, simple variations will be used. Snort-like pattern
matching is not suitable for stopping such attacks. Rather, we use protocol-
speciﬁc detection methods requiring up to layer 7 messages.
Like the Covers approach [24], we protect hosts from buﬀer overﬂow attacks
by tracing the address that causes the control ﬂow diversion to a speciﬁc (higher-
level) protocol ﬁeld and capturing characteristics (such as the length of the ﬁeld)
that are subsequently used as an attack signature. Brieﬂy, Covers uses ASR to
detect an attack, and any exploit that attempts to divert the control ﬂow will,
with high probability, crash the process with a memory fault. If so, it queries the
OS to ﬁnd the address Mt that caused the crash (see also Figure 2). Next, it will
look for the address A and some bytes in its vicinity in the (logged) traﬃc trace,
thus approximating location Nt. Using knowledge about the protocol governing
320
W. de Bruijn et al.
memory
target
Mt
     

vulnerable
     

     

     

     

     

buffer
this address will
overwrite target
repeat address
to handle different
offsets
Legend
 = address of target
Mt
 = target address / return 
target
 = address to store in target  
A
tN
 = offset in network trace of  
    the bytes that overwrite
    the target
   

   

   

   

A A A
   

   

   

   

   

   

tN
2L
L1
(full protocol field)
network trace
Fig. 2. Memory and network traces of a simple buﬀer overﬂow attack
the interaction, Covers subsequently determines the protocol ﬁeld that caused
an overﬂow. Next, it uses the length of this protocol ﬁeld as a signature, as all
messages of the same protocol with this length will lead to the same overﬂow,
regardless of the contents. By focusing on properties like ﬁeld length, the signa-
tures are independent of the actual content of the exploit and hence resilient to
polymorphism.
In SafeCard, we developed the Prospector, a protocol-speciﬁc detector that
builds on the same principles, but diﬀers from Covers in important aspects. First,
we moved the ﬁlter out of the host and into an Intel IXP2400 network processor.
By moving the ﬁlter away from the host to the ﬁrst router or switch connected to
the end-user’s PC, administrators keep tight control over the security software.
At the same time, not moving it all the way to a centralised ﬁrewall permits the
network device to exploit application speciﬁc knowledge. For instance, we keep
track of which applications (and which versions) are running on the servers con-
nected to each port. Whether the applications are discovered automatically (e.g.,
by port scanning) or administered explicitly is beyond the scope of this paper.
Second, rather than the crude and somewhat error-prone address space ran-
domisation, we use a more reliable method based on taint analysis for detecting
intrusions [34]. The Argos IDS used for SafeCard is an eﬃcient and reliable em-
ulator that tags and tracks network data and triggers alerts whenever the use of
such data violates security policies (e.g., when it is used as a jump target). Argos
is not part of our high-speed datapath. It is a signature generating honeypot that
listens to background traﬃc on a separate machine. Whenever it observes an in-
trusion attempt it generates a signature. Prospector then uses these signatures
SafeCard: A Gigabit IPS on the Network Card
321
for ﬁltering on high-speed links. We will not repeat the full explanation of Argos
here (interested readers are referred to [8]), but we do note that Argos is more
reliable in ﬁnding the address that causes the control diversion than ASR. After
all, with ASR there is a non-negligible chance that the attack does not cause
a memory fault immediately, but crashes after executing a few random instruc-
tions. In that case, the address would be bogus. Moreover, by keeping track of
the origin in the traﬃc trace of tainted data, as provided by the next release
of Argos, the correlation with network data will be very accurate. Even if the
probability of not producing an address with ASR is small, in our experience
the odds of making the wrong guess as to the origins Nt of the address A that
exactly overﬂows Mt in the network trace is much greater [8]. Worse, if protocol
ﬁelds are encoded in the network trace (e.g., URL encoding), scanning traces for
occurrences of the target will fail altogether. In contrast, tracking the origins of
tainted data handles these cases well.
Third, sophisticated overﬂows are caused by more than one ﬁeld. An example
is chunking and multiple host headers in HTTP, where multiple chunks or head-
ers end up in the same buﬀer. While Covers is unable to ﬁgure out that it should
watch the total length of all chunks/headers together, rather than a single ﬁeld,
Prospector handles such cases correctly. The importance of this improvement is
demonstrated for instance by attacks like the Apache-Knacker exploit [35] which
consists of a GET request with multiple host headers that end up in the same
buﬀer. Such attacks frequently lead to false positives in Covers, but are correctly
identiﬁed by Prospector.
Fourth, we do not necessarily consider the whole ﬁeld. The work described
in [24] always uses up to L1, the length of the entire protocol ﬁeld containing
the jump target, even though the jump target is often not found at the end
of the protocol ﬁeld. It seems the authors use statistics of legitimate messages
received in the past to help estimate the maximum length that the ﬁeld may
have. Doing so may cause false negatives, e.g., if the jump target is followed by a
variable number of bytes in the same protocol ﬁeld. A signature generated for a
long version of the protocol ﬁeld is unable to ﬁnd attacks with shorter protocol
ﬁelds, even if they contain the same exploit. Such behaviour is quite common,
especially if part of the payload is stored in the same vulnerable buﬀer. Instead,
our Prospector uses L2, the exact distance between the start of the protocol ﬁeld
and Nt. We speculate that the reason for taking the whole ﬁeld is that Covers
is unable to accurately pinpoint Nt, as jump targets are often repeated in the
exploit in order to handle minor diﬀerences in oﬀset (as indicated by multiple
occurrences of A in Figure 2).
Fifth, the way multiple signatures are used in [24] is not speciﬁed. We have an
eﬃcient tree-like structure for dealing with large numbers of signatures. Brieﬂy,
every signature consists of a sequence of value ﬁelds and critical ﬁelds. A value
ﬁeld speciﬁes that a ﬁeld in the protocol should have this speciﬁc value. For
instance, in the HTTP protocol a value ﬁeld may specify that the method should
be GET for this signature to match. Critical ﬁelds, on the other hand, should
collectively satisfy some condition. For instance, in the current implementation
322
W. de Bruijn et al.
the critical ﬁelds should collectively have a length that is less than L2. The
signatures are organised in memory like a tree, so that common preﬁxes are
checked only once. Because our signature recognition is stateful, the Prospector
is able to check whether a TCP segment matches a signature eﬃciently (i.e.,
without having to traverse the whole tree each time a segment comes in).
Sixth, Prospector has an option to scan for and reject malformed protocol mes-
sages. Since we have protocol-speciﬁc knowledge, it was easy to extend Prospector
to also check whether the application-level interaction conforms to the protocol.
In other words, we scrub higher-layer protocols in this FE.
The Prospector module in SafeCard allows us to scan for a large class of
polymorphic buﬀer overﬂows at application-level. Both stack and heap overﬂows
are already handled in the current version. However, given an accurate location
of Nt, one may detect format string attacks in a similar way. We are currently
extending the Prospector with such a format string handler. The details are
beyond the scope of this paper as the mechanism is not yet thoroughly evaluated.
Prospector is at the moment further limited by its support for only a single
protocol: HTTP. We will add support for more protocols as well.
3.4 Flow-Based Behavioural Detection
Flow-based detection complements payload-scanning and (header-based) proto-
col reconstruction as the three detection vectors are orthogonal. We have already
seen one method of ﬂow-based detection: arrival of overlapping segments. An-
other group of methods detects unexpected variations in incoming or outgoing
connections (e.g., number per time-unit, address-space entropy, or length), for