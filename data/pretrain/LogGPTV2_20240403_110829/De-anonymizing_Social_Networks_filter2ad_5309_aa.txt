# De-anonymizing Social Networks

**Authors:** Arvind Narayanan and Vitaly Shmatikov  
**Institution:** The University of Texas at Austin  
**Conference:** 2009 30th IEEE Symposium on Security and Privacy

## Abstract
Online social network operators increasingly share potentially sensitive information about users and their relationships with advertisers, application developers, and data-mining researchers. Privacy is typically protected through anonymization, which involves removing personally identifiable information (PII) such as names and addresses. This paper presents a framework for analyzing privacy and anonymity in social networks and introduces a new re-identification algorithm targeting anonymized social network graphs. To demonstrate the effectiveness of our algorithm, we show that approximately one-third of users who can be verified to have accounts on both Twitter and Flickr can be re-identified in the anonymous Twitter graph with only a 12% error rate.

Our de-anonymization algorithm is based purely on the network topology, does not require the creation of a large number of dummy "sybil" nodes, is robust to noise and all existing defenses, and works even when the overlap between the target network and the adversary's auxiliary information is small.

## 1. Introduction
Social networks have been a subject of study for over a century [66] and are a fundamental part of research in fields such as epidemiology [8], sociology [73, 28, 11], economics [29], and many others [19, 9, 32]. The recent proliferation of online social networks like MySpace, Facebook, and Twitter has also attracted the attention of computer scientists [40].

Even in open online networks, there is often a disconnect between users' willingness to share information and their reaction to unintended parties viewing or using this information [13]. Most operators provide some level of privacy controls, and many online and virtually all offline networks (e.g., telephone calls, email, and instant messages) restrict access to information about individual members and their relationships.

Network owners frequently share this information with advertising partners and other third parties, which is a key aspect of the business model for many online social network operators. Some networks are even published for research purposes. To address privacy concerns, the networks are anonymized, meaning that names and demographic information associated with individual nodes are suppressed. However, this suppression is often misinterpreted as the removal of PII, even though PII may include much more than just names and identifiers. For example, the EU privacy directive defines "personal data" as "any information relating to an identified or identifiable natural person [. . . ]; an identifiable person is one who can be identified, directly or indirectly, in particular by reference to an identification number or to one or more factors specific to his physical, physiological, mental, economic, cultural, or social identity" [22].

Anonymity has been interpreted as equivalent to privacy in several high-profile cases of data sharing. After a New York court ruling ordering Google to hand over viewing data of over 100 million YouTube users to Viacom, and subsequent protests from privacy advocates, a revised agreement was struck under which Google would anonymize the data before handing it over [71]. The CEO of NebuAd, a U.S. company that offers targeted advertising based on browsing histories gathered from ISPs, dismissed privacy concerns by saying, "We don’t have any raw data on the identifiable individual. Everything is anonymous" [15]. Phorm, a U.K. company with a similar business model, aims to collect data on web-surfing habits of 70% of British broadband users; the only privacy protection is that user identities are mapped to random identifiers [69].

In social networks, too, user anonymity has been used as the primary solution to privacy concerns (see Section 2).

### Our Contributions
This paper is the first to demonstrate the feasibility of large-scale, passive de-anonymization of real-world social networks. Specifically, we:
1. Survey the current state of data sharing in social networks, the intended purpose of each type of sharing, the resulting privacy risks, and the wide availability of auxiliary information that can aid attackers in de-anonymization.
2. Formally define privacy in social networks and relate it to node anonymity. We identify several categories of attacks, differentiated by attackers’ resources and auxiliary information. We also provide a methodology for measuring the extent of privacy breaches in social networks, which is an interesting problem in its own right.
3. Develop a generic re-identification algorithm for anonymized social networks. The algorithm uses only the network structure, does not make any a priori assumptions about membership overlap between multiple networks, and defeats all known defenses.
4. Demonstrate how our de-anonymization algorithm works by applying it to Flickr and Twitter, two large, real-world online social networks. We show that one-third of the users who are verifiable members of both Flickr and Twitter can be recognized in the completely anonymous Twitter graph with only a 12% error rate, even though the overlap in the relationships for these members is less than 15%.

Given the widespread sharing of anonymized social network data and the common availability of auxiliary information needed for our attack, we argue that our work calls for a substantial re-evaluation of business practices surrounding the sharing of social network data.

## 2. State of the Union
The attacks described in this paper target anonymized, sanitized versions of social networks, using partial auxiliary information about a subset of their members. To show that both anonymized networks and auxiliary information are widely available, we survey real-world examples of social network data sharing, most of which involve releasing more information than needed for our attack.

### Academic and Government Data-Mining
Social networks used for published data-mining research include mobile-phone call graphs of 7 million [56], 3 million [53], and 2.5 million [42] customers, as well as the land-line phone graph of 2.1 million Hungarian users [41]. Corporations like AT&T, whose database of 1.9 trillion phone calls goes back decades [35], have in-house research facilities, but smaller operators—there are 3,000 wireless companies in the U.S. alone—must share their graphs with external researchers. Phone-call networks are also commonly used to detect illicit activity such as calling fraud [75] and for national security purposes, such as identifying the command-and-control structures of terrorist cells by their idiosyncratic sub-network topologies [35]. Several companies sell data-mining solutions to governments for this purpose [67].

Sociologists, epidemiologists, and healthcare professionals collect data about geographic, friendship, family, and sexual networks to study disease propagation and risk. For example, the Add Health dataset includes the sexual-relationship network of almost 1,000 students of an anonymous Midwestern high school as part of a detailed survey on adolescent health [2]. While the Add Health project takes a relatively enlightened stance on privacy [1], this graph has been published in an anonymized form [10].

For online social networks, the data can be collected by crawling either via an API or "screen-scraping" (e.g., Mislove et al. crawled Flickr, YouTube, LiveJournal, and Orkut [51]; anonymized graphs are available by request only). Even when obtained from public websites, this kind of information—if publicly released—still presents privacy risks because it helps attackers who lack resources for massive crawls. In some online networks, such as LiveJournal and the Experience Project, user profiles and relationship data are public, but many users maintain pseudonymous profiles. From the attacker’s perspective, this is the same as publishing the anonymized network.

### Advertising
With concrete evidence that social network data makes commerce more profitable [62, 70], network operators are increasingly sharing their graphs with advertising partners to enable better social targeting of advertisements. For example, Facebook explicitly states that users’ profiles may be shared for personalizing advertisements and promotions, as long as the individual is not explicitly identified [23]. Both Facebook and MySpace allow advertisers to use friends’ profile data for ad targeting [17]. Social-network-driven advertising has been pursued by many startups [20, 52] and even Google [63], typically relying on anonymity to prevent privacy breaches [5, 21, 55].

### Third-Party Applications
The number of third-party applications on Facebook alone is in the tens of thousands and rapidly growing [64]. The data from multiple applications can be aggregated and used for targeted advertising (e.g., as done by SocialMedia [61]). As the notion of social networking as a feature rather than a destination takes hold [4], many other networks are trying to attract application developers. On the Ning platform, which claims over 275,000 networks, each network can be considered a third-party application. The data given to third-party applications is usually not anonymized, even though most applications could function on anonymized profiles [24].

Third-party applications have a poor track record of respecting privacy policies. For example, a security hole in a Facebook application developed by Slide, Inc. exposed the birthdays, gender, and relationship status of strangers, including Facebook executives and the wife of Google co-founder Larry Page [50]. WidgetLaboratory, one of the most popular developers for the Ning platform, was banned permanently after gathering credentials from users and causing havoc on Ning networks [6]. Therefore, it is important to understand what a malicious third-party application can learn about members of a social network, even if it obtains the data in an anonymized form.

### Aggregation
Aggregation of information from multiple social networks, facilitated by projects such as OpenID [57], DataPortability [18], the “social graph” project [25], and various microformats [49], potentially presents a greater threat to individual privacy than one-time data releases. Existing aggregators include FriendFeed, MyBlogLog, Jaiku (recently acquired by Google), and Plaxo; the latter even provides an open-source “social graph crawler” [59]. Aggregated networks are an excellent source of auxiliary information for our attacks.

### Other Data-Release Scenarios
WellNet is a healthcare coordination service that enables employers to monitor the social network in real time to track employees’ medical and pharmacy activity [48]. The data is anonymized. In "friend-to-friend networking," a peer-to-peer file-sharing network is overlaid on social links [60] to defeat censor nodes such as the RIAA. Nodes are pseudonymous, and communication is encrypted. Since traffic is typically not anonymized at the network level, the logs that can be obtained, for example, by subpoenaing the ISP, are essentially anonymized social network graphs.

Finally, consider photographs published online without identifying information. The accuracy of face recognition can be improved substantially by exploiting the fact that users who appear together in photographs are likely to be neighbors in the social network [68]. Since most online photographs appear in a social network context, they effectively represent an anonymized graph, and techniques developed in this paper can help in large-scale facial re-identification.

## 3. Related Work
### Privacy Properties
A social network consists of nodes, edges, and information associated with each node and edge. The existence of an edge between two nodes can be sensitive: for instance, in a sexual-relationship network with gender information attached to nodes [10], it can reveal sexual orientation. Edge privacy was considered in [39, 7]. In most online social networks, however, edges are public by default, and few users change the default settings [30]. While the mere presence of an edge may not be sensitive, edge attributes may reveal more information (e.g., a single phone call vs. a pattern of calls indicative of a business or romantic relationship). For example, phone-call patterns of the disgraced NBA referee Tom Donaghy have been used in the investigation [76]. In online networks such as LiveJournal, there is much variability in the semantics of edge relationships [26].

The attributes attached to nodes, such as the user’s interests, are usually far more sensitive. Social Security numbers can be predicted from Facebook profiles with higher accuracy than random guessing [30]; see [14] for other privacy breaches based on profile data. Even implicit attributes such as node degree can be highly sensitive, e.g., in a sexual network [10]. Existing defenses focus on names and other identifiers, but basic de-anonymization only reveals that someone belongs to the network, which is hardly sensitive. As we show in the rest of this paper, however, it can be used as a vehicle for more serious attacks on privacy, including the disclosure of sensitive attributes.

### De-anonymization Attacks
Backstrom et al. present two active attacks on edge privacy in anonymized social networks [7]. These active attacks fundamentally assume that the adversary is able to modify the network prior to its release: "an adversary chooses an arbitrary set of users whose privacy it wishes to violate, creates a small number of new user accounts with edges to these targeted users, and creates a pattern of links among the new accounts with the goal of making it stand out in the anonymized graph structure." Both attacks involve creating O(log N) new "sybil" nodes (N is the total number of nodes), whose outgoing edges help re-identify quadratically as many existing nodes.

Active attacks are difficult to stage on a large scale. First, they are restricted to online social networks (OSNs); creating thousands of fake nodes in a phone-call or real-life network is prohibitively expensive or impossible. Even in OSNs, many operators (e.g., Facebook) check the uniqueness of email addresses and deploy other methods for verifying the accuracy of supplied information, making the creation of a large number of dummy nodes relatively difficult.

Second, the attacker has little control over the edges incoming to the nodes he creates. Because most legitimate users will have no reason to link back to the sybil nodes, a subgraph with no incoming edges but many outgoing edges will stand out. As we show below, this may enable the network operator to recognize that the network has been compromised by a sybil attack. There are also other techniques for identifying sybil attacks in social networks [78], including methods for spammer detection deployed by OSNs that allow unidirectional edges [65].

We carried out an experiment to verify the claim that identification of subgraphs consisting primarily of sybil nodes is difficult in real-world social networks. The data for this experiment was the graph of LiveJournal obtained from Mislove et al. [51], crawled in late 2006. It is a directed graph with 5.3 million nodes and 77 million edges. Except for the time of the crawl, this graph is similar to that used in [7].

The cut-based attack of [7] creates 7-node subgraphs containing a Hamiltonian path. In contrast to the observation in [7] that every possible 7-node subgraph containing a Hamiltonian path occurs in the LiveJournal graph, there are no subgraphs in the LiveJournal graph that have these two properties and, furthermore, do not have any incoming edges. We conclude that active attacks are easy to detect if real users never link back to sybil nodes. More sophisticated sybil-detection techniques may work as long as only a small percentage of real users link back to sybil nodes.

The third limitation of active attacks is the fact that many OSNs require a link to be mutual before the information is made available in any form. Therefore, assuming that real users do not link back to dummy users, the links from fake nodes to real ones do not show up in the network.

We conclude that large-scale active attacks requiring the creation of tens of thousands of sybil nodes are unlikely to be feasible. Active attacks can still be useful in identifying or creating a small set of "seeds" to serve as a starting point.