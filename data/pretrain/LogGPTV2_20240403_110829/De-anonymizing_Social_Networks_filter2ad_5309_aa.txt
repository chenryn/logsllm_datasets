title:De-anonymizing Social Networks
author:Arvind Narayanan and
Vitaly Shmatikov
2009 30th IEEE Symposium on Security and Privacy
De-anonymizing Social Networks
Arvind Narayanan and Vitaly Shmatikov
The University of Texas at Austin
Abstract
Operators of online social networks are increasingly
sharing potentially sensitive information about users and
their relationships with advertisers, application developers,
and data-mining researchers. Privacy is typically protected
by anonymization, i.e., removing names, addresses, etc.
We present a framework for analyzing privacy and
anonymity
in social networks and develop a new
re-identiﬁcation algorithm targeting anonymized social-
network graphs. To demonstrate its effectiveness on real-
world networks, we show that a third of the users who
can be veriﬁed to have accounts on both Twitter, a popular
microblogging service, and Flickr, an online photo-sharing
site, can be re-identiﬁed in the anonymous Twitter graph
with only a 12% error rate.
Our de-anonymization algorithm is based purely on the
network topology, does not require creation of a large
number of dummy “sybil” nodes, is robust to noise and all
existing defenses, and works even when the overlap between
the target network and the adversary’s auxiliary information
is small.
1. Introduction
Social networks have been studied for a century [66] and
are a staple of research in disciplines such as epidemiol-
ogy [8], sociology [73], [28], [11], economics [29], and
many others [19], [9], [32]. The recent proliferation of online
social networks such as MySpace, Facebook, Twitter, and so
on has attracted attention of computer scientists, as well [40].
Even in the few online networks that are completely
open, there is a disconnect between users’ willingness to
share information and their reaction to unintended parties
viewing or using this information [13]. Most operators thus
provide at least some privacy controls. Many online and
virtually all ofﬂine networks (e.g., telephone calls, email
and instant messages, etc.) restrict access to the information
about individual members and their relationships.
Network owners often share this information with ad-
vertising partners and other third parties. Such sharing
is the foundation of the business case for many online
social-network operators. Some networks are even published
for research purposes. To alleviate privacy concerns, the
networks are anonymized,
i.e., names and demographic
information associated with individual nodes are suppressed.
Such suppression is often misinterpreted as removal of
“personally identiﬁable information” (PII), even though PII
may include much more than names and identiﬁers. For
example, the EU privacy directive deﬁnes “personal data”
as “any information relating to an identiﬁed or identiﬁable
natural person [. . . ]; an identiﬁable person is one who can
be identiﬁed, directly or indirectly, in particular by reference
to an identiﬁcation number or to one or more factors speciﬁc
to his physical, physiological, mental, economic, cultural or
social identity” [22].
Anonymity has been unquestioningly interpreted as equiv-
alent to privacy in several high-proﬁle cases of data sharing.
After a New York court ruling ordering Google to hand
over viewing data of over 100 million YouTube users to
Viacom and the subsequent protests from privacy advocates,
a revised agreement was struck under which Google would
anonymize the data before handing it over [71]. The CEO
of NebuAd, a U.S. company that offers targeted advertising
based on browsing histories gathered from ISPs, dismissed
privacy concerns by saying that “We don’t have any raw
data on the identiﬁable individual. Everything is anony-
mous” [15]. Phorm, a U.K. company with a similar business
model, aims to collect the data on Web-surﬁng habits of
70% of British broadband users; the only privacy protection
is that user identities are mapped to random identiﬁers [69].
In social networks, too, user anonymity has been used as
the answer to all privacy concerns (see Section 2).
Our contributions. This is the ﬁrst paper to demonstrate
feasibility of large-scale, passive de-anonymization of real-
world social networks.
First, we survey the current state of data sharing in social
networks, the intended purpose of each type of sharing, the
resulting privacy risks, and the wide availability of auxiliary
information which can aid the attacker in de-anonymization.
Second, we formally deﬁne privacy in social networks and
relate it to node anonymity. We identify several categories of
attacks, differentiated by attackers’ resources and auxiliary
information. We also give a methodology for measuring the
extent of privacy breaches in social networks, which is an
interesting problem in its own right.
Third, we develop a generic re-identiﬁcation algorithm for
anonymized social networks. The algorithm uses only the
network structure, does not make any a priori assumptions
about membership overlap between multiple networks, and
defeats all known defenses.
1081-6011/09 $25.00 © 2009 IEEE
DOI 10.1109/SP.2009.22
173
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
Fourth, we give a concrete demonstration of how our de-
anonymization algorithm works by applying it to Flickr and
Twitter, two large, real-world online social networks. We
show that a third of the users who are veriﬁable members of
both Flickr and Twitter1 can be recognized in the completely
anonymous Twitter graph with only 12% error rate, even
though the overlap in the relationships for these members is
less than 15%!
Sharing of anonymized social-network data is widespread
and the auxiliary information needed for our attack is
commonly available. We argue that our work calls for a
substantial re-evaluation of business practices surrounding
the sharing of social-network data.
2. State of the Union
The attacks described in this paper target anonymized,
sanitized versions of social networks, using partial auxiliary
information about a subset of their members. To show that
both anonymized networks and auxiliary information are
widely available, we survey real-world examples of social-
network data sharing, most of which involve releasing more
information than needed for our attack.
Academic and government data-mining. Social networks
used for published data-mining research include the mobile-
phone call graphs of, respectively, 7 million [56], 3 mil-
lion [53], and 2.5 million [42] customers, as well as the
land-line phone graph of 2.1 million Hungarian users [41].
Corporations like AT&T, whose own database of 1.9 trillion
phone calls goes back decades [35], have in-house research
facilities, but smaller operators—there are 3,000 wireless
companies in the U.S. alone—must share their graphs with
external researchers. Phone-call networks are also commonly
used to detect illicit activity such as calling fraud [75] and for
national security purposes, such as identifying the command-
and-control structures of terrorist cells by their idiosyncratic
sub-network topologies [35]. A number of companies sell
data-mining solutions to governments for this purpose [67].
Sociologists, epidemiologists, and health-care profession-
als collect data about geographic, friendship, family, and
sexual networks to study disease propagation and risk.
For example, the Add Health dataset includes the sexual-
relationship network of almost 1,000 students of an anony-
mous Midwestern high school as part of a detailed survey
on adolescent health [2]. While the Add Health project takes
a relatively enlightened stance on privacy [1], this graph has
been published in an anonymized form [10].
For online social networks, the data can be collected
by crawling either via an API, or “screen-scraping” (e.g.,
Mislove et al. crawled Flickr, YouTube, LiveJournal, and
Orkut [51]; anonymized graphs are available by request
only). We stress that even when obtained from public
1. At the time of our crawl; details are in Section 6.
websites, this kind of information—if publicly released—
still presents privacy risks because it helps attackers who
lack resources for massive crawls. In some online networks,
such as LiveJournal and the Experience Project, user proﬁles
and relationship data are public, but many users maintain
pseudonymous proﬁles. From the attacker’s perspective, this
is the same as publishing the anonymized network.
Advertising. With the emergence of concrete evidence that
social-network data makes commerce much more prof-
itable [62], [70], network operators are increasingly shar-
ing their graphs with advertising partners to enable better
social targeting of advertisements. For example, Facebook
explicitly says that users’ proﬁles may be shared for the
purpose of personalizing advertisements and promotions, as
long as the individual is not explicitly identiﬁed [23]. Both
Facebook and MySpace allow advertisers to use friends’
proﬁle data for ad targeting [17]. Social-network-driven
advertising has been pursued by many startups [20], [52]
and even Google [63], typically relying on anonymity to
prevent privacy breaches [5], [21], [55].
Third-party applications. The number of third-party appli-
cations on Facebook alone is in the tens of thousands and
rapidly growing [64]. The data from multiple applications
can be aggregated and used for targeted advertising (e.g., as
done by SocialMedia [61]). As the notion of social network-
ing as a feature rather than destination takes hold [4], many
other networks are trying to attract application developers;
on the Ning platform, which claims over 275,000 networks,
each network can be considered a third-party application.
The data given to third-party applications is usually not
anonymized, even though most applications would be able
to function on anonymized proﬁles [24].
Third-party applications have a poor track record of
respecting privacy policies. For example, a security hole in
a Facebook application developed by Slide, Inc. “exposed
the birthdays, gender, and relationship status of strangers,
including Facebook executives, [and] the wife of Google
co-founder Larry Page” [50]. WidgetLaboratory, one of the
most popular developers for the Ning platform, was banned
permanently after “gathering credentials from users and
otherwise creating havoc on Ning networks” [6]. Therefore,
it is important to understand what a malicious third-party
application can learn about members of a social network,
even if it obtains the data in an anonymized form.
Aggregation. Aggregation of information from multiple
social networks, facilitated by projects such as OpenID [57],
DataPortability [18], the “social graph” project [25], and
various microformats [49], potentially presents a greater
threat
to individual privacy than one-time data releases.
Existing aggregators include FriendFeed, MyBlogLog, Jaiku
(recently acquired by Google), and Plaxo; the latter even
provides an open-source “social graph crawler” [59]. Ag-
gregated networks are an excellent source of auxiliary in-
174
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
formation for our attacks.
Other data-release scenarios. WellNet is a health-care co-
ordination service which enables employers to monitor the
social network in real time in order to track employees’
medical and pharmacy activity [48]. The data is anonymized.
In “friend-to-friend networking,” a peer-to-peer ﬁle-
sharing network is overlaid on social links [60] in order to
defeat censor nodes such as the RIAA. Nodes are pseudony-
mous and communication is encrypted. Since trafﬁc is
typically not anonymized at the network level, the logs that
can be obtained, for example, by subpoenaing the ISP are
essentially anonymized social-network graphs.
Finally, consider photographs published online without
identifying information. The accuracy of face recognition
can be improved substantially by exploiting the fact that
users who appear together in photographs are likely to be
neighbors in the social network [68]. Since most online pho-
tographs appear in a social-network context, they effectively
represent an anonymized graph, and techniques developed
in this paper can help in large-scale facial re-identiﬁcation.
3. Related Work
Privacy properties. A social network consists of nodes,
edges, and information associated with each node and edge.
The existence of an edge between two nodes can be sen-
sitive: for instance, in a sexual-relationship network with
gender information attached to nodes [10] it can reveal
sexual orientation. Edge privacy was considered in [39], [7].
In most online social networks, however, edges are public
by default, and few users change the default settings [30].
While the mere presence of an edge may not be sensitive,
edge attributes may reveal more information (e.g., a single
phone call vs. a pattern of calls indicative of a business
or romantic relationship). For example, phone-call patterns
of the disgraced NBA referee Tom Donaghy have been
used in the investigation [76]. In online networks such as
LiveJournal, there is much variability in the semantics of
edge relationships [26].
The attributes attached to nodes, such as the user’s inter-
ests, are usually far more sensitive. Social Security numbers
can be predicted from Facebook proﬁles with higher accu-
racy than random guessing [30]; see [14] for other privacy
breaches based on proﬁle data. Even implicit attributes such
as node degree can be highly sensitive, e.g., in a sexual
network [10]. Existing defenses focus on names and other
identiﬁers, but basic de-anonymization only reveals that
someone belongs to the network, which is hardly sensitive.
As we show in the rest of this paper, however, it can be used
as a vehicle for more serious attacks on privacy, including
disclosure of sensitive attributes.
De-anonymization attacks. Backstrom et al. present two
active attacks on edge privacy in anonymized social net-
works [7]. These active attacks fundamentally assume that
the adversary is able to modify the network prior to its re-
lease: “an adversary chooses an arbitrary set of users whose
privacy it wishes to violate, creates a small number of new
user accounts with edges to these targeted users, and creates
a pattern of links among the new accounts with the goal
of making it stand out in the anonymized graph structure.”
Both attacks involve creating O(log N ) new “sybil” nodes
(N is the total number of nodes), whose outgoing edges help
re-identify quadratically as many existing nodes.
Active attacks are difﬁcult to stage on a large scale.
First, they are restricted to online social networks (OSNs);
creating thousands of fake nodes in a phone-call or real-life
network is prohibitively expensive or impossible. Even in
OSNs, many operators (e.g., Facebook) check the uniqueness
of email addresses and deploy other methods for verifying
accuracy of supplied information, making creation of a large
number of dummy nodes relatively difﬁcult.
Second,
the attacker has little control over the edges
incoming to the nodes he creates. Because most legitimate
users will have no reason to link back to the sybil nodes, a
subgraph with no incoming edges but many outgoing edges
will stand out. As we show below, this may enable the
network operator to recognize that the network has been
compromised by a sybil attack. There are also other tech-
niques for identifying sybil attacks in social networks [78],
including methods for spammer detection deployed by OSNs
that allow unidirectional edges [65].
We carried out an experiment to verify the claim that
identiﬁcation of subgraphs consisting primarily of sybil
nodes is difﬁcult in real-world social networks. The data
for this experiment was the graph of LiveJournal obtained
from Mislove et al. [51], crawled in late 2006. It is a directed
graph with 5.3 million nodes and 77 million edges. Except
for the time of the crawl, this graph is similar to that used
in [7].
The cut-based attack of [7] creates 7-node subgraphs
containing a Hamiltonian path. In contrast to the observation
in [7] that every possible 7-node subgraph containing a
Hamiltonian path occurs in the LiveJournal graph, there
are no subgraphs in the LiveJournal graph that have these
two properties and, furthermore, do not have any incoming
edges. We conclude that active attacks are easy to detect if
real users never link back to sybil nodes. More sophisticated
sybil-detection techniques may work as long as only a small
percentage of real users link back to sybil nodes.
The third limitation of active attacks is the fact that many
OSNs require a link to be mutual before the information is
made available in any form. Therefore, assuming that real
users do not link back to dummy users, the links from fake
nodes to real ones do not show up in the network.
We conclude that large-scale active attacks requiring cre-
ation of tens of thousands of sybil nodes are unlikely to be
feasible. Active attacks can still be useful in identifying or
175
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
creating a small set of “seeds” to serve as a starting point