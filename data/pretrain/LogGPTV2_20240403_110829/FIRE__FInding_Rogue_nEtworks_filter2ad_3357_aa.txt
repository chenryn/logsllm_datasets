title:FIRE: FInding Rogue nEtworks
author:Brett Stone-Gross and
Christopher Kruegel and
Kevin C. Almeroth and
Andreas Moser and
Engin Kirda
2009 Annual Computer Security Applications Conference
FIRE: FInding Rogue nEtworks
Brett Stone-Gross, Christopher Kruegel, Kevin Almeroth
Andreas Moser
Engin Kirda
University of California, Santa Barbara
Technical University Vienna
Institute Eurecom
{bstone,chris,almeroth}@cs.ucsb.edu
PI:EMAIL
PI:EMAIL
Abstract
For many years, online criminals have been able to
conduct their illicit activities by masquerading behind
disreputable Internet Service Providers (ISPs). For
example, organizations such as the Russian Business
Network (RBN), Atrivo (a.k.a., Intercage), McColo, and
most recently, the Triple Fiber Network (3FN) operated
with impunity, providing a safe haven for Internet
criminals for their own ﬁnancial gain. What primarily
sets these ISPs apart from others is the signiﬁcant
longevity of the malicious activities on their networks
and the apparent lack of action taken in response to
abuse reports. Interestingly, even though the Internet
provides a certain degree of anonymity, such ISPs
fear public attention. Once exposed, rogue networks
often cease their malicious activities quickly, or are
de-peered (disconnected) by their upstream providers.
As a result, the Internet criminals are forced to relocate
their operations.
In this paper, we present FIRE, a novel system
to identify and expose organizations and ISPs that
demonstrate persistent, malicious behavior. The goal is
to isolate the networks that are consistently implicated
in malicious activity from those that are victims of
compromise. To this end, FIRE actively monitors botnet
communication channels, drive-by-download servers,
and phishing web sites. This data is reﬁned and
correlated to quantify the degree of malicious activity
for individual organizations. We present our results in
real-time via the website maliciousnetworks.org. These
results can be used to pinpoint and to track the activ-
ity of rogue organizations, preventing criminals from
establishing strongholds on the Internet. Also, the in-
formation can be compiled into a null-routing blacklist
to immediately halt trafﬁc from malicious networks.
1. Introduction
Anecdotal evidence indicates the existence of Inter-
net companies and service providers that are under the
inﬂuence of criminal organizations or knowingly toler-
ate their activities. Such companies typically control a
number of networks with public IP addresses that are
abused for a wide range of malicious activities. One
such activity is offering bullet-proof hosting, a service
that guarantees the availability of hosted resources even
when they are found to be malicious or illegal. These
hosting services are often used for phishing purposes
or for serving exploits and malware. Other malicious
activities involve the sending of spam, hosting scam
pages, or providing a repository for pirated software
and child pornography.
An example of a rogue network that offered bullet-
proof hosting was the Russian Business Network
(RBN), who made headlines in late 2007 [5], [16].
Various sources alleged that
the RBN hosted web
sites, exploits, and malware that were responsible for
a signiﬁcant fraction of online scams and phishing.
Once publicly exposed, the RBN ceased its operations
in St. Petersburg, only to relocate and resume activities
in different networks [10]. More recently, a report ex-
posed Atrivo (Intercage), a US-based company that is
frequently considered to provide hosting for malicious
content [3], [17]. Often referred to as the RBN of
the United States, this company is considered to be
a “dedicated crime hosting ﬁrm whose customer base
is composed almost, or perhaps entirely, of criminal
gangs” [13]. Shortly after Atrivo made headlines, two
more rogue networks, known as McColo and the Triple
Fiber Network (3FN), were discovered to be major
hosting providers for malicious content with ties to
cybercrime [1], [2], [18]. Again, public outcry quickly
lead reputable ISPs to severe their peering relationships
with these organizations, cutting them off the Internet.
In this paper, we describe FIRE, a system that
monitors the Internet for rogue networks. We believe
that it is important to expose such networks, for a
number of reasons. First, as the examples of the
Russian Business Network, Atrivo, McColo, and 3FN
demonstrate, criminals fear public attention. As a result
of the increased media coverage, all four networks
had to cease their immediate activity. In many cases,
it is likely that their operations resumed elsewhere.
However, it
took some time before the miscreants
could restructure their setup. Thus, by quickly bringing
to light networks that act maliciously, it becomes more
difﬁcult for cyber-criminals to establish a home base.
1063-9527/09 $26.00 © 2009 IEEE
DOI 10.1109/ACSAC.2009.29
231
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
The second advantage of identifying rogue networks is
the possibility to generate blacklists that can block all
trafﬁc from a netblock, even when certain IPs within
this netblock have not yet acted maliciously. This
approach prevents criminals from cycling through the
available IP space, quickly shifting to a new IP when a
current host is blacklisted. Currently, there are manual
efforts underway to establish blacklists based on the
observation that certain networks are malicious. For
example, Spamhaus maintains the Don’t Route Or Peer
(DROP) list, a collection of networks that they consider
to be controlled entirely by professional spammers.
Spamhaus suggests that
trafﬁc from these sources
should simply be dropped, and recommends the use of
this list by tier-1 ISPs and backbone networks. Another
example is the list maintained by EmergingThreats,
which identiﬁes netblocks that are thought to belong to
the Russian Business Network. While such efforts are
beneﬁcial, they are expensive and tedious to maintain.
Moreover, these lists are often incomplete and limited
in scope (for example, limited to spam operations or
the RBN in particular). In contrast, FIRE operates in
an automated fashion, and we aim to capture a broader
range of malicious activity, independent of any a priori
knowledge of criminal organizations.
To identify rogue networks, we rely on a number
of data sources that report the malicious actions of
individual hosts. Some of the data feeds are publicly
available, such as lists of phishing web pages. The
other data originates from our own analysis efforts,
such as a list of hosts that provide botnet com-
mand and control servers and hosts that are found
to exploit browser vulnerabilities. Of course, given
the widespread use of botnets and the large number
of exploited machines, the fact that a host performs
malicious actions is no immediate indication that the
corresponding ISP or netblock is malicious. Instead,
when a host misbehaves, it is possible that attackers
were able to compromise and abuse it for nefarious
purposes. Thus, it is necessary to search the data for
indicators that allow us to distinguish between hosts
under the control of rogue (or grossly negligent) ISPs
and infected machines of organizations that make a
deliberate effort to keep their network clean.
Based on post-processed information obtained from
different data sources, we compute a malscore (ma-
liciousness score) for individual ASNs (Autonomous
System Number). This score quantiﬁes the amount of
recent, malicious activity in a network and serves as
an indicator for the likelihood that an ASN is linked to
cyber-criminals, or at the least, being very negligent in
removing malicious content. Using the malscores, it is
easy to identify the worst offenders on the Internet and
take appropriate actions (such as increasing the public
pressure, breaking peering relationships, or putting
their IP address space on a blacklist). Moreover, we
can track malicious activity over time.
The main contributions of this paper are as follows:
• We analyze a number of data sources to identify
IP addresses of hosts that misbehave in different
ways.
• We present techniques to ﬁlter these lists for hosts
that likely belong to rogue ISPs. In particular,
we combine the information from different data
sources to compute a malscore that quantiﬁes the
malicious activities of an autonomous system.
• We show that our system is successful in iden-
tifying a number of rogue ISPs and can assist
legitimate ISPs in cleaning their networks via our
website maliciousnetworks.org.
2. System Overview
The goal of our system is to identify rogue networks.
Thus, we ﬁrst need to concretize what we consider
to be a rogue network. Unfortunately, this question is
not straightforward to answer. Some service providers
are simply lax when it comes to the content that they
offer, others are victims of remote exploits, and a few
are well-known to blatantly host malicious content.
Thus, the fact that a network is the source of unwanted
activity does not necessarily qualify it immediately as
being malicious.
We consider a rogue network to be a network that is
under the control of cyber-criminals or that knowingly
proﬁts from cooperating with criminals. Of course, it
is difﬁcult to assert such criminal ties without thorough
investigations by law enforcement agencies. Thus, we
have to redeﬁne our notion of rogue networks based
on the activities that are typically associated with such
networks. To this end, we consider a rogue network to
be one in which signiﬁcant malicious activity occurs.
In addition, this activity lasts for an extended period
of time, regardless of abuse complaints. Our logic
behind this is that rogue networks provide hosting
for malicious content that often remains up for many
days (sometimes even months or years). In contrast,
malicious activity in other networks tends to be more
short-lived due to abuse reporting and honest attempts
to undo the damage.
Given our notion of rogue networks, the basic idea
to identify such networks is to check for the presence
of a large number of long-lived, misbehaving hosts. To
this end, we analyze a number of data sources for IP
addresses that have exhibited malicious behavior for
an extended period of time (the exact extent of this
time span depends on the type of data source and is
discussed later).
232
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
3. Data Collection
In this section, we discuss in more detail the three
data sources that we use to identify hosts that likely be-
long to rogue networks. To this end, we ﬁrst describe,
for each data source, how we obtain the IP addresses
of hosts that are actively engaged in malicious activity.
3.1. Botnet Command and Control Providers
(C&C). For
Despite the emergence of peer-to-peer-based bots,
rely on centralized command
many botnets still
and control
this C&C infrastructure,
botmasters typically set up IRC servers that provide
channels for bots to join, or web servers that can
be periodically polled for new commands. The
functioning of the complete botnet depends on the
availability of these servers. Thus, a botmaster is
interested in hosting his C&C infrastructure on a
network where it is safe from takedown.
To identify and monitor the networks afﬁliated
with botnet C&C servers, we utilize data collected
from Anubis [4]. Anubis executes Windows-based
malware binaries
in a virtual environment and
records ﬁle system and registry modiﬁcations, process
information, and network communications. We are
particularly interested in the network trafﬁc (if any)
generated by the malware.
IRC-based botnets. When Anubis monitors IRC traf-
ﬁc the corresponding nickname, server, and channel
information is logged. To monitor whether IRC C&C
channels are active, we use a custom IRC client that
leverages the recorded credentials to connect to the
IRC server and join the channel. Because we are
primarily interested in the longevity of the C&C server,
we resolve the C&C server’s host name to one or more
IP addresses, and then connect to each IP at regular
intervals. When the C&C server is not identiﬁed by a
DNS name but by an IP address, then this address is
used directly. A host (an IP address) is considered to
be active when our client can join the corresponding
C&C channel. Sometimes, transient network problems
prevent us from connecting to a host. In such cases,
it would be undesirable and premature to declare a
host as inactive. Thus, we require that an active C&C
channel is unreachable for two days before declaring
the corresponding IP address as inactive.
Interestingly, in a number of cases, we observed that
a channel (and the corresponding server) was reach-
able, but no malicious activity was noticeable. This
is frequently the case when a bot channel is created
on a well-known IRC network (such as undernet or
efnet). The reason is that the IRC administrators of
these networks quickly ban the botmaster and remove
the channel. However, subsequent logins from bots or
other users reopen the channel, thus making the chan-
nel available and leaving the impression that it is still
active. To mitigate this problem, we modify our ap-
proach to determine whether a botnet C&C host is ac-
tive. More precisely, in addition to the requirement that
a server is reachable and the appropriate channel exists,
we also require that the channel shows bot-related
activity. To this end, we introduce heuristics that check
the messages and channel topics for well-known IRC
bot commands (such as download, update, dos) and
signs of encoded or encrypted commands. A channel
is considered up only when such indicators are present.
HTTP-based botnets. To identify and monitor web-
based botnet C&C servers from samples collected by
Anubis, we ﬁrst require a mechanism to distinguish
between legitimate HTTP trafﬁc and trafﬁc related
to botnet commands. This
is necessary because
HTTP trafﬁc sent by a malware sample does not
immediately imply a connection to a C&C server
(HTTP connections are often used to check for
network connectivity or download updates). To
identify HTTP C&C trafﬁc, we manually deﬁne static,
malicious characteristics (signatures) of requests used
by well-known botnets. These characteristics include
content from the HTTP request path and parameters,
HTTP headers and POST data, and the HTTP response
from the web server. Such static features are useful
even for botnets that use encryption because they
frequently send an encryption key, bot
identiﬁer,
version number, and other parameters to the web
server. Thus, the HTTP C&C server must know how
to parse the request in a speciﬁc format.
As an example of a web-based botnet that we have
been monitoring, consider Pushdo/Cutwail, which is
believed to be one of the largest, active botnets used
for spam. When a Cutwail bot connects to the C&C
server, it will often request one or more executables.
Although the botnet utilizes encryption, the request
path for these binaries contains a predictable semi-
static format, such as the preﬁx /40E8. The response
from the web server contains one or more executables
typically around 100KB. Currently, we are monitoring
24 different
types of web-based botnets including
Coreﬂood, Torpig, and Koobface.
3.2. Drive-by-Download Hosting Providers
Our second data source is a list of servers that
host malware executables distributed through drive-by-
download exploits. Drive-by-downloads are a means
of malware distribution where executables are auto-
matically installed on victim machines without user
interaction. Typically, the only requirement is for a
233
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
user to visit a web page that contains an exploit for her
vulnerable browser. In some cases, the exploit and the
malware executable is hosted on a compromised host,
while in other cases, a compromised web page is only
used to redirect the victim to a second machine that
performs the exploit (often referred to as a mothership).
These mothership servers are frequently located in
rogue networks.
There are three data feeds that we use to identify
drive-by-download servers. The ﬁrst feed is through
Wepawet [25], a system that checks user-submitted
web pages (URLs) for malicious Javascript. In partic-
ular, we are interested in cases where malicious script
contains shellcode that downloads and executes mal-
ware. When malware is discovered, Wepawet records
the locations of these binaries and exports them to
FIRE. The second data feed is through a daily compi-
lation of URLs found in spam mails that are caught
in the spam traps of a computer security company
and an Internet Service Provider. The third feed is a
daily-updated list of “spamvertised” URLs (advertised
via spam) provided by Spamcop [23]. So far, after
eliminating duplicates, we have recorded more than 1.2
million spamvertised links. Of course, not every URL
in a spam email points to a site that launches a drive-by
exploit. Instead, these URLs frequently lead to shady
businesses such as online pharmacies, casinos, or adult
services. To identify those sites and pages that actively
perform drive-by-exploits, we use the Capture Honey
Pot Client (HPC) [21]. Capture is able to ﬁnd web-
based exploits by opening a potentially malicious web
site in a browser on a virtual machine. After visiting a
page, the state of the virtual machine is inspected and
suspicious changes (i.e., the creation of new ﬁles or
the spawning of new processes) are recorded, as they
indicate that the guest system was compromised by a
web-based exploit.
For our analysis, we use a total of eight virtual
machines (VMs) dedicated to scanning web pages.
All VM images are running Windows XP Professional
(Service Pack 2), without any patches installed and
automatic updates disabled. To catch recent exploits,
we have installed the Flash and Quicktime plug-ins.
When the Capture honey client is compromised by
visiting a certain URL, we inspect the network traces
recorded from Capture HPC. We are not interested in
the server that hosts the web site that contains an ex-
ploit. We have observed that those machines are often
legitimate web servers that are victims of compromise
and, therefore, do not yield much information about
malicious networks. Thus, if the malicious binary that
is part of an exploit is downloaded from the same
server, we ignore that host for our analysis. In the more
interesting case, an exploit has been injected into a web
page and the associated binary is hosted on a different
machine (mothership server that usually serves binaries
for many different exploits). Due to the importance of
this mothership servers for the criminals behind the
exploit, these machines are often located in malicious
networks where the chance that it is being shut down
is low. Thus, we only consider the IP addresses of
those mothership servers for our analysis. Once we
have discovered a download server, we revisit it once
per day.
3.3. Phish Hosting Providers
The third data source to identify rogue networks
is derived from information about servers that host
phishing pages. Typically, phishing pages are set up to
steal login credentials, credit card numbers, or other
personal information. Often, these pages are hosted on
compromised servers and are taken down quickly. To
mitigate this problem, phishers often resort to hosting
their phishing pages directly in networks where there
is little or no control of the offered content.
To locate phishing pages, we leverage an XML feed
provided by PhishTank [19]. Once a day, this feed
provides our system with URLs of phishing pages that
are veriﬁed by the PhishTank community. Interestingly,
all URLs on the PhishTank list are considered to be
online. However, our experiments have shown that
phishing pages are often taken ofﬂine so quickly that
the list is already outdated after one day.
To compute the status of phishing IPs, we attempt
to download the web page located at a given phishing
URL once per day. This is done until either the
domain (of the URL) can no longer be resolved, or
the site is ofﬂine for more than one week. A phishing
site is considered ofﬂine by our system when the web
server is not reachable anymore or when the phishing
page has been replaced by another page that is not a
phish (usually a HTTP 404 error page or a phishing
warning page).
4. Data Analysis
In this section, we discuss our techniques to identify
rogue networks and compute their malscores based on
the analysis of the individual data sets that we collect.
4.1. Longevity of Malicious IP Addresses
The primary characteristic that distinguishes be-
tween rogue and legitimate networks is the longevity
of the malicious services. Most legitimate networks are
able to clean up illicit content within a matter of days.
In contrast, we have observed malicious content that
234
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
has been online for the entire monitoring period of
more than a year. Figure 1 shows the average uptime
of malicious IPs per ASN. It can be seen that the vast
majority of networks remove the offending content in
less than ten days. However, there were 361 ASNs
that had hosts with an average lifespan of more than
ten days in our feeds. Also, we discovered that each
type of malicious activity displays different behaviors
and average uptime.
Since May 2008, we have observed botnet C&C
servers on 1,269 IP addresses. Figure 2 displays the
uptime of the botnet C&C servers from 0-60 days.