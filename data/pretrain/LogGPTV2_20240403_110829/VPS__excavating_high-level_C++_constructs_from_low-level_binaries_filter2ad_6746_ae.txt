### Virtual Callsite Analysis

The provided data and analysis highlight the performance of various methods in identifying virtual callsites, a critical aspect of ensuring software security. The numbers listed (e.g., 491, 98.7, 100.0, etc.) likely represent different metrics such as true positives, false positives, recall, and precision for different applications and methods.

#### Addressing Unconventional Virtual Callsites
We encountered a virtual callsite that does not conform to the typical C++ callsite pattern. This could be mitigated by incorporating additional vcall patterns, but this might introduce false positives. Given our already high recall rates, we believe this trade-off would not be favorable. We also verified 86 cases where VTV (Virtual Table Verification) did not recognize virtual callsite instructions. Manual verification confirmed these as vcall instructions, indicating missed virtual callsites by VTV. An example is shown in Figure 4 for 510.parest_r, where a vector is created and the `reinit()` function is invoked on line 2547. Since `reinit()` is a virtual function of the class `dealii::Vector`, this call is translated into a virtual callsite. We contacted the VTV authors, who confirmed that this issue arises because the compiler directly accesses the object's memory when calling the virtual function, rather than using an internal `vtblptr` field. Fixing this in VTV would require significant, non-trivial work.

#### Comparison with CFIXX
CFIXX, which performs enforcement similarly, was also evaluated against our binary-only approach. We compiled the applications with CFIXX (based on LLVM) and extracted the protected virtual callsites as ground truth. Table 3 shows the results. Unfortunately, we were unable to compile 447.dealII and 526.blender_r with CFIXX. On average, vps identified 99.6% of all SPEC CPU2006 and 99.5% of SPEC CPU2017 virtual callsites, with high precision: 97.0% for SPEC CPU2006 and 96.9% for SPEC CPU2017. For large real-world applications, the recall and precision rates are similar, with a recall of 99.1% for MySQL and 99.8% for Node.js, and a precision of 97.1% and 96.4%, respectively. A manual analysis of the missed virtual callsites (false negatives) revealed the same two reasons for misses as observed with VTV.

#### Comparison with Marx
A direct comparison with other binary-only approaches is challenging due to different test sets. For example, vfGuard evaluates accuracy against only two applications, T-VIP against one, and VTint provides absolute numbers without ground truth. VCI, evaluated against SPEC CPU2006, reports no false positives, which differs from our findings. Additionally, most approaches target different platforms and are not open source. Marx, being the only open-source approach targeting the same platform, was analyzed. Using its conservative mode, Marx crashed during the analysis of 483.xalancbmk. Table 4 shows the results. Compared to Marx, vps has higher recall and better precision. Averaged over the supported CPU2006 benchmarks, vps achieves 98.2% recall (vs. 91.8% for Marx) and 97.4% for CPU2017 (vs. 70.9% for Marx). Precision is similar for CPU2006 (94.5% vs. 95.4%) and much better for CPU2017 (91.1% vs. 65.8%). For large applications like MySQL and MongoDB, vps identifies 16.3% and 28.1% more virtual callsites with better precision (98.5% vs. 88.8% for MySQL and 99.7% vs. 90.9% for MongoDB).

#### Object Initialization and Destruction Accuracy
To ensure vps does not break applications, it must instrument all valid object initialization and destruction sites. We compare the number of vtable-referencing instructions found by vps to a ground truth generated with an LLVM 4.0.0 pass that instruments Clangâ€™s `CodeGenFunction::InitializeVTablePointer()`. Table 5 shows the results for the same set of applications. Results for 447.dealII and 526.blender_r are omitted as they fail to compile with LLVM 4.0.0. Our analysis finds all vtable-referencing instructions, conservatively overestimating the set to ensure security and correctness.

### Summary
Our analysis demonstrates that vps is precise enough to provide protection against control-flow hijacking attacks at virtual callsites. On average, only 2.5% of vcalls were missed compared to VTV and 0.5% compared to CFIXX. Binary analysis is inherently challenging, and the results show that a sophisticated analysis can nearly match the protection level of source-based approaches. Even source code approaches like VTV can benefit from binary-only approaches like vps. The low number of false positives indicates the robustness of our approach in handling them during instrumentation.