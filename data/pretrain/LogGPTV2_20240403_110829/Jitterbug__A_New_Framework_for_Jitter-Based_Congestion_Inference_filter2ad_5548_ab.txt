detection
E
§3.4
Fig. 2. The Jitterbug framework comprises: (A) data acquisition (B) signal ﬁltering
(C) detection of intervals of elevated latency (D) detection of changes of state of jitter
and jitter dispersion signals (E) detection of increments of the min time series (F)
correlation of changes in jitter state with increments of changes of state in jitter signals.
3.2 Detection of Period of Elevated Latency
Identifying time intervals with elevated RTTs. is a fundamental step of the con-
gestion inference process since the subsequent modules examine these periods
to determine if latency elevations were caused by increases of traﬃc loads. Our
framework can accommodate any change point detection algorithm that can
segment time intervals based on changes in RTTs. As proof of concept, we use
two state-of-the-art change point detection algorithms—Bayesian Change Point
(BCP) Detection or Hidden Markov Models (HMM)—to process the min time
series. We have not yet had the opportunity to test these methods on a large
variety of data sources, so we provide both alternatives to let Jitterbug users
select which is more eﬀective for their data source. We believe these two algo-
rithms can complement each other in circumstance where one fails to cover all
change points in a signal. In Sect. 5.8, we test both algorithms with challenging
latency signatures and show how all periods of elevated latency are captured by
at least one of the methods.
Jitterbug: A New Framework for Jitter-Based Congestion Inference
161
(a) Recurring congestion event. There is
a correlation between periods of elevated
latency and the growth of jitter dispersion.
(b) Recurring congestion event. Jitter dis-
persion transitorily increases at the begin-
ning of periods of elevated latency
(c) One-oﬀ non-congestion event on Jan 2,
with no correlation between signals.
(d) One-oﬀ congestion event, with a posi-
tive correlation between the min and jitter
dispersion time series.
Fig. 3. min RTT (orange) and jitter dispersion (purple) time series. We normalized
the values using standard score for this visualization; normalization is not necessary
in actual computation. In a) and d), these two signals are strongly correlated during
period of congestion. In b), jitter dispersion has a transitory increase at the beginning
of the period of elevated latency. c) (no apparent congestion) shows no correlation
between these signals, which is consistent with a route change that increased RTT.
(Color ﬁgure online)
– Bayesian Change Point (BCP): We chose an oﬄine BCP algorithm3 pro-
posed by Xuan et al. [36]. We experimented with other popular change point
detection algorithms (e.g., Change ﬁnder [11] and ATDK LevelShift [6]) and
found that BCP was the most eﬀective at detecting boundaries of intervals
with RTT latency measurements in our data.
– Hidden Markov Models (HMM): We selected an implementation
designed to identify diﬀerent discrete states in RTT latency time series, by
combining Hidden Markov Models (HMM) with Hierarchical Dirichlet Pro-
cess (HDP) [27]. HMM also yields boundaries for each state (or level) in the
time series, and in our case, consecutive RTT latency samples typically belong
to the same state for long periods of times.
3.3 Examination of Jitter Signals
Jitterbug uses two approaches to examine changes in jitter and jitter dispersion
time series during periods of elevated latency (Module (D) in Fig. 2): (i) KS-test
method (using the jitter time series), and (ii) Jitter dispersion method (using
3 Implementation of Xuan et al. change point detection algorithm: https://github.
com/hildensia/bayesian changepoint detection.
162
E. Carisimo et al.
(a) KS-test: STEP 0
(b) JD: STEP 0
(c) KS-test: STEP 1 (BCP)
(d) JD: STEP 1 (BCP)
(e) KS-test: STEP 2 (Compare intervals)
(f) JD: STEP 2 (Compare intervals)
Fig. 4. Steps of KS-test (left) and jitter dispersion (right) congestion inference meth-
ods. In both methods, Jitterbug uses the min time series to identify the beginning and
end of periods of elevated latency (c and d). Using these boundaries, both methods
look for changes in jitter signals in adjacent intervals. To detect these changes, KS-
test computes the Kolmogorov-Smirnov test on adjacent jitter samples (e); the jitter
dispersion method (f) compares the mean value of the jitter dispersion signal (E).
the jitter dispersion time series). Both methods rely on boundaries previously
identiﬁed by the Interval Detection Module (Module (C) in Fig. 2). Figure 4
describes the input time series of each method, how they use change points
detected by Interval Detection Module and how they detect changes in jitter
signals.
KS-Test Method. This method examines changes in the jitter time series
(Fig. 4a). Using the change points extracted from the minimum time series by
the Interval Detection Module (Fig. 4c), Jitterbug detects a change of regime in
jitter time series during periods of elevated latency. Our hypothesis is that a trace
switched into a diﬀerent congestion state if there is a change point in the mini-
mum time series and, at the same time, the jitter changes to a diﬀerent regime.
To identify such a regime, Jitterbug applies the Kolmogorov-Smirnov (KS) test
to jitter samples in partitions before and after the change point (Fig. 4e). In
case the jitter samples in the partition before the change point have a diﬀerent
distribution from the following partition, the KS test will reject the null hypoth-
esis (α = 0.05) meaning both samples were not generated by the same random
process. To verify that the result of the KS test is not an artifact due to the
Jitterbug: A New Framework for Jitter-Based Congestion Inference
163
change point detection method, we apply the KS test to two random samples
in the same interval. For this validation test, we expect the KS test does not
reject the null hypothesis, which means there is no evidence to conclude that
samples within the same partition belong to diﬀerent jitter regimes. We repeat
this process for all pairs of adjacent partitions.
Jitter Dispersion Method. The input to this method is the jitter dispersion
time series that we pre-computed in Sect. 3.1 (Fig. 4b). Similar to the KS-test
method, this method uses change points extracted from the minimum time series
by the Interval Detection Module (Fig. 4c), as boundaries between periods of
elevated latency (Fig. 4d). We assume when the elevation of latency is caused by
congestion, then the jitter dispersion increases, either transitorily at the begin-
ning (phase transition) or throughout the period (Sect. 3.1).
In both cases, during a period of congestion the average jitter dispersion is
larger than that of congestion-free periods. If the mean value of the jitter disper-
sion between consecutive periods (Fig. 4f) increases, we consider this period as
congested. We repeat this inference process for all pairs of adjacent partitions.
3.4 Latency Jump Detection
Jitterbug assumes that a period of congestion is a period of elevated latency
that manifests the growth of routers’ buﬀers occupancy. In the Latency Jump
Detection module (Module (E) in Fig. 2) Jitterbug uses the min time series and
the intervals identiﬁed by the Interval Detection Module (Module (C) in Fig. 2)
to detect latency increments. This modules ﬂags a candidate period of congestion
if it detects in that period an increment of the mean value of the min time series
compared to its predecesor.
3.5 Combine Changes in Jitter and Minimum Time Series
Jitterbug classiﬁes a period of congestion (Module F in Fig. 2) if adjacent inter-
vals meet two conditions: (i) an increase in the RTT latency baseline (ii) an
increase in the jitter amplitude (transitory or generalized). Jitterbug combines
the results obtained by the Latency Jump Detection module with KS-test and
Jitter dispersion methods. Jitterbug assumes that a period of elevated latency
was generated by an increase in routers buﬀer occupancy if the KS-test or jitter
dispersion method detected changes in the jitter signals during that interval.
To increase the accuracy of these Jitterbug inferences in challenging scenarios,
and to allow users to calibrate inferences with their tolerance values, Jitterbug
includes two additional features: (i) congestion inference thresholds, and (ii)
memory.
– Congestion inference thresholds. To increase conﬁdence of Jitterbug con-
gestion inferences, we include congestion inference thresholds when we com-
pare the mean value of the minimum RTT time series of consecutive intervals.
164
E. Carisimo et al.
Table 1. Description of the near- and far-side ASes in the evaluation dataset. We use
measurements collected from 13 Ark monitors hosted in 6 U.S. ISP to 18 far-side ASes
(7 Content Providers and 11 Access/Transit networks) and 49 far-IP addresses. This
data collection comprises 1.7M raw RTT samples collected between 2017 and 2020. for
1290 unique combinations of .
near-side ASes
# VPs ISPs
far-side ASes
#ASes (# addr.) far ASname
13
COMCAST, Verizon,
AT&T, CenturyLink,
Charter, Cox
18 (49)
COMCAST (AS7922), Netﬂix (AS2906),
NTT (AS2914), Level3 (AS3356), PCCW
(AS3491), KT (AS4766), Telstra
(AS4637), TATA (AS6453), China
Telecom (AS4134), Zayo (AS6461),
Cloudﬂare (AS13335), Charter (AS7843),
XO (AS2828), Edgecast (AS15133),
Google (AS15169), Amazon (AS16509),
Akamai (AS20940), Facebook (AS32934)
We also include a Jitter dispersion threshold (JD threshold) in the jitter dis-
persion method when we compare changes in the mean value of the signal in
adjacent intervals. The values we use for this research are 0.25ms and 0.5ms
thresholds for jitter dispersion and baseline, respectively, as we found in the
evaluation dataset (see Sect. 4) that min and jitter dispersion ﬂuctuations
tend to be below these values during periods of no suspected congestion.
These parameters allow us to reduce false positives and false negatives in
Jitterbug congestion inferences.
– Memory. To reduce errors in congestion inferences as a result of false posi-
tives in the change point detection process, we include the concept of mem-
ory. In some cases, change point detection algorithms identify path anoma-
lies within periods of congestion (e.g., route change during a congestion
episode) or a false positive. Under these circumstances, our congestion detec-
tion methodology would not detect any change, either transitory or perma-
nent in the jitter, and it would label the next interval as a period of no
congestion. However, the congestion status has not changed between these
adjacent intervals. To overcome this limitation, we include a rule called mem-
ory that assumes that a period of congestion has not ﬁnished if in the follow-
ing interval the mean value of the minimum RTT does not decrease. For
example, for two given adjacent intervals I1 and I2, we will label I2 as
a period of congestion if we also labeled I1 as a period of congestion and
mean(minRT T (I2)) ≥ mean(minRT T (I1)).
4 Dataset
We focus on congestion at interdomain links which requires identiﬁcation of IP
addresses of intedomain routers’ interfaces. MANIC [2] uses bdrmap [24] to infer
Jitterbug: A New Framework for Jitter-Based Congestion Inference
165
the IP addresses of all interdomain links visible from the Autonomous System
hosting a CAIDA Ark [1] vantage point (VP). bdrmap returns pairs of near-
and far-side IP addresses of an interdomain link, and a set of preﬁxes reachable
through a path containing those near- and far-side IP addresses. We use the data
API of the MANIC platform [2] to obtain longitudinal RTT measurements from
Ark’s VPs to the far-side interface of interdomain links using the Time-Series
Latency Probing (TSLP) method [23]. Each VP runs TSLP measurements every
5 min using ICMP TTL-limited packet probes to all near- and far-side pairs to
collect RTT samples between the VP and IP addresses on the near and far side of
interdomain links. Furthermore, the MANIC platform labels interdomain links
that might have congestion events using an autocorrelation-based method [12],
which is eﬀective in locating recurring congestion events that signiﬁcantly inﬂate
the RTTs. We will use these inferences as cross-validation (Sect. 6.2).
We demonstrate our methodologies by inferring congestion from 13 VPs in
6 U.S. ISPs to 18 far ASes and 49 far-IP addresses, as it is shown in Table 1.
This dataset covers a total of 1290 unique combinations of 
and contains 1.7M raw RTT samples collected between 2017 and 2020.
5 Results
We present our results of Jitterbug congestion inferences in the scenarios we
introduced in Sect. 2.2, which map to the taxonomy in Fig. 5. Speciﬁcally, we
show Jitterbug congestion inferences for periodic signals of large (Sect. 5.1) and
small (Sect. 5.2) amplitude as well as for one-oﬀ periods of elevated latency
(Sect. 5.3 and 5.4). We further investigate Jitterbug congestion inference in
hybrid scenarios with one-oﬀ events in the middle of repetitive periods of ele-
vated latency (Sect. 5.5). We also study the impact of memory (Sect. 5.6) and
the JD threshold (Sect. 5.7) in the accuracy of Jitterbug congestion inferences.
Finally, we investigate how errors in detecting change points impact in Jitterbug
congestion inference (Sect. 5.8).
5.1 Scenario 1: Recurrent Period of Elevated Latency with Large
Amplitude Signals
Both methodologies labeled every recurrent period of elevated latency as a
period of congestion (Fig. 6). We suppose that the accuracy of the congestion
inferences is partially due to the small of contribution of other random factors
since we observe small variability in the baseline during periods of non-elevated
latency. The proﬁle of the minimum time series indicates a small contribution
of other random components, which create slight ﬂuctuations during periods
of non-elevated latency. In addition, the size of this router buﬀer ampliﬁes the
range of the raw, min and jitter time series (in some cases over 100ms) which
simpliﬁes the task of identifying periods of high jitter ﬂuctuations.
166
E. Carisimo et al.
Period of elevated latency
Periodic
One-off
Manifestation
high-amplitude
signal
small-amplitude
signal
Solid baseline
change
....
high-amplitude
spikes
Suspected
case
Insuf. capacity +
Large buffer
allocation
Insuf. capacity +
Small buffer
allocation
route change
....
Flash crowd
Fig. 5. Hierarchical classiﬁcation of characteristics of elevated latency. We classify peri-
ods of elevated latency as either periodic (left branch) or one-oﬀ (right branch). Recur-
rent latency with a consistent period (periodic) suggests an underprovisioned link. A
one-oﬀ episode of elevated latency can have many causes, e.g., buﬀerbloat, ﬂash crowd,
misconﬁguration, route change.
Fig. 6. KS-test (middle plot) and Jitter dispersion (lower plot) congestion inferences
for a periodic high-amplitude signal. In this case, both methods label every recurrent
period of elevated latency as periods of congestion. Red-ﬁlled intervals indicate periods
of congestion. (Color ﬁgure online)
5.2 Scenario 2: Recurrent Period of Elevated Latency with Small