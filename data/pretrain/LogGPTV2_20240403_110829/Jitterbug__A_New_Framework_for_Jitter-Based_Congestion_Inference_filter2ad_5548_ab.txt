### Detection

**§3.4**

**Figure 2.** The Jitterbug framework consists of the following components:
- (A) Data acquisition
- (B) Signal filtering
- (C) Detection of intervals with elevated latency
- (D) Detection of changes in the state of jitter and jitter dispersion signals
- (E) Detection of increments in the minimum time series
- (F) Correlation of changes in jitter state with increments in the jitter signals.

### 3.2 Detection of Periods of Elevated Latency

Identifying time intervals with elevated Round-Trip Times (RTTs) is a fundamental step in the congestion inference process, as subsequent modules examine these periods to determine if the latency elevations were caused by increased traffic loads. Our framework can accommodate any change point detection algorithm capable of segmenting time intervals based on RTT changes. As a proof of concept, we use two state-of-the-art change point detection algorithms: Bayesian Change Point (BCP) Detection and Hidden Markov Models (HMM). We have not yet tested these methods on a wide variety of data sources, so we provide both alternatives to allow Jitterbug users to select the most effective one for their specific data. We believe these two algorithms can complement each other, especially in cases where one fails to detect all change points in a signal. In Section 5.8, we test both algorithms with challenging latency signatures and demonstrate that all periods of elevated latency are captured by at least one of the methods.

**Jitterbug: A New Framework for Jitter-Based Congestion Inference**

**Figure 3.** Minimum RTT (orange) and jitter dispersion (purple) time series. The values are normalized using the standard score for visualization; normalization is not necessary for actual computation. In (a) and (d), these two signals are strongly correlated during periods of congestion. In (b), jitter dispersion shows a transitory increase at the beginning of the period of elevated latency. (c) (no apparent congestion) shows no correlation between these signals, which is consistent with a route change that increased RTT. (Color figure online)

- **Bayesian Change Point (BCP):** We chose an offline BCP algorithm proposed by Xuan et al. [36]. We experimented with other popular change point detection algorithms (e.g., ChangeFinder [11] and ATDK LevelShift [6]) and found that BCP was the most effective at detecting boundaries of intervals with RTT latency measurements in our data.
- **Hidden Markov Models (HMM):** We selected an implementation designed to identify different discrete states in RTT latency time series by combining HMM with Hierarchical Dirichlet Process (HDP) [27]. HMM also yields boundaries for each state (or level) in the time series, and in our case, consecutive RTT latency samples typically belong to the same state for long periods of time.

### 3.3 Examination of Jitter Signals

Jitterbug uses two approaches to examine changes in jitter and jitter dispersion time series during periods of elevated latency (Module (D) in Figure 2):
- (i) KS-test method (using the jitter time series)
- (ii) Jitter dispersion method (using the jitter dispersion time series)

Both methods rely on boundaries previously identified by the Interval Detection Module (Module (C) in Figure 2). Figure 4 describes the input time series of each method, how they use change points detected by the Interval Detection Module, and how they detect changes in jitter signals.

**KS-Test Method:**
This method examines changes in the jitter time series (Figure 4a). Using the change points extracted from the minimum time series by the Interval Detection Module (Figure 4c), Jitterbug detects a change of regime in the jitter time series during periods of elevated latency. Our hypothesis is that a trace switched into a different congestion state if there is a change point in the minimum time series and, simultaneously, the jitter changes to a different regime. To identify such a regime, Jitterbug applies the Kolmogorov-Smirnov (KS) test to jitter samples in partitions before and after the change point (Figure 4e). If the jitter samples in the partition before the change point have a different distribution from the following partition, the KS test will reject the null hypothesis (α = 0.05), indicating that both samples were not generated by the same random process. To verify that the result of the KS test is not an artifact due to the change point detection method, we apply the KS test to two random samples within the same interval. For this validation test, we expect the KS test does not reject the null hypothesis, meaning there is no evidence to conclude that samples within the same partition belong to different jitter regimes. We repeat this process for all pairs of adjacent partitions.

**Jitter Dispersion Method:**
The input to this method is the jitter dispersion time series pre-computed in Section 3.1 (Figure 4b). Similar to the KS-test method, this method uses change points extracted from the minimum time series by the Interval Detection Module (Figure 4c) as boundaries between periods of elevated latency (Figure 4d). We assume that when the elevation of latency is caused by congestion, the jitter dispersion increases, either transitorily at the beginning (phase transition) or throughout the period (Section 3.1). During a period of congestion, the average jitter dispersion is larger than that of congestion-free periods. If the mean value of the jitter dispersion between consecutive periods (Figure 4f) increases, we consider this period as congested. We repeat this inference process for all pairs of adjacent partitions.

### 3.4 Latency Jump Detection

Jitterbug assumes that a period of congestion is a period of elevated latency that manifests the growth of routers' buffer occupancy. In the Latency Jump Detection module (Module (E) in Figure 2), Jitterbug uses the minimum time series and the intervals identified by the Interval Detection Module (Module (C) in Figure 2) to detect latency increments. This module flags a candidate period of congestion if it detects an increment in the mean value of the minimum time series compared to its predecessor.

### 3.5 Combining Changes in Jitter and Minimum Time Series

Jitterbug classifies a period of congestion (Module F in Figure 2) if adjacent intervals meet two conditions:
- (i) An increase in the RTT latency baseline
- (ii) An increase in the jitter amplitude (transitory or generalized)

Jitterbug combines the results obtained by the Latency Jump Detection module with the KS-test and Jitter dispersion methods. Jitterbug assumes that a period of elevated latency was generated by an increase in routers' buffer occupancy if the KS-test or jitter dispersion method detected changes in the jitter signals during that interval. To increase the accuracy of Jitterbug inferences in challenging scenarios and to allow users to calibrate inferences with their tolerance values, Jitterbug includes two additional features:
- (i) Congestion inference thresholds
- (ii) Memory

**Congestion Inference Thresholds:**
To increase the confidence of Jitterbug's congestion inferences, we include congestion inference thresholds when comparing the mean value of the minimum RTT time series of consecutive intervals. We also include a Jitter dispersion threshold (JD threshold) in the jitter dispersion method when comparing changes in the mean value of the signal in adjacent intervals. The values used in this research are 0.25ms and 0.5ms thresholds for jitter dispersion and baseline, respectively, as we found in the evaluation dataset (see Section 4) that min and jitter dispersion fluctuations tend to be below these values during periods of no suspected congestion. These parameters help reduce false positives and false negatives in Jitterbug congestion inferences.

**Memory:**
To reduce errors in congestion inferences resulting from false positives in the change point detection process, we include the concept of memory. In some cases, change point detection algorithms identify path anomalies within periods of congestion (e.g., route change during a congestion episode) or a false positive. Under these circumstances, our congestion detection methodology would not detect any change, either transitory or permanent, in the jitter and would label the next interval as a period of no congestion. However, the congestion status has not changed between these adjacent intervals. To overcome this limitation, we include a rule called "memory" that assumes a period of congestion has not finished if, in the following interval, the mean value of the minimum RTT does not decrease. For example, for two given adjacent intervals I1 and I2, we will label I2 as a period of congestion if we also labeled I1 as a period of congestion and mean(minRTT(I2)) ≥ mean(minRTT(I1)).

### 4 Dataset

We focus on congestion at interdomain links, which requires identifying IP addresses of interdomain routers' interfaces. MANIC [2] uses bdrmap [24] to infer the IP addresses of all interdomain links visible from the Autonomous System hosting a CAIDA Ark [1] vantage point (VP). bdrmap returns pairs of near- and far-side IP addresses of an interdomain link and a set of prefixes reachable through a path containing those near- and far-side IP addresses. We use the data API of the MANIC platform [2] to obtain longitudinal RTT measurements from Ark's VPs to the far-side interface of interdomain links using the Time-Series Latency Probing (TSLP) method [23]. Each VP runs TSLP measurements every 5 minutes using ICMP TTL-limited packet probes to all near- and far-side pairs to collect RTT samples between the VP and IP addresses on the near and far side of interdomain links. Furthermore, the MANIC platform labels interdomain links that might have congestion events using an autocorrelation-based method [12], which is effective in locating recurring congestion events that significantly inflate the RTTs. We will use these inferences for cross-validation (Section 6.2).

We demonstrate our methodologies by inferring congestion from 13 VPs in 6 U.S. ISPs to 18 far ASes and 49 far-IP addresses, as shown in Table 1. This dataset covers a total of 1290 unique combinations and contains 1.7M raw RTT samples collected between 2017 and 2020.

**Table 1.** Description of the near- and far-side ASes in the evaluation dataset. We use measurements collected from 13 Ark monitors hosted in 6 U.S. ISPs to 18 far-side ASes (7 Content Providers and 11 Access/Transit networks) and 49 far-IP addresses. This data collection comprises 1.7M raw RTT samples collected between 2017 and 2020 for 1290 unique combinations.

| Near-side ASes | # VPs ISPs | Far-side ASes | #ASes (# addr.) | Far ASname |
|----------------|-------------|---------------|-----------------|------------|
| 13             | COMCAST, Verizon, AT&T, CenturyLink, Charter, Cox | 18 (49) | COMCAST (AS7922), Netflix (AS2906), NTT (AS2914), Level3 (AS3356), PCCW (AS3491), KT (AS4766), Telstra (AS4637), TATA (AS6453), China Telecom (AS4134), Zayo (AS6461), Cloudflare (AS13335), Charter (AS7843), XO (AS2828), Edgecast (AS15133), Google (AS15169), Amazon (AS16509), Akamai (AS20940), Facebook (AS32934) |

### 5 Results

We present our results of Jitterbug congestion inferences in the scenarios introduced in Section 2.2, which map to the taxonomy in Figure 5. Specifically, we show Jitterbug congestion inferences for periodic signals of large (Section 5.1) and small (Section 5.2) amplitude, as well as for one-off periods of elevated latency (Sections 5.3 and 5.4). We further investigate Jitterbug congestion inference in hybrid scenarios with one-off events in the middle of repetitive periods of elevated latency (Section 5.5). We also study the impact of memory (Section 5.6) and the JD threshold (Section 5.7) on the accuracy of Jitterbug congestion inferences. Finally, we investigate how errors in detecting change points impact Jitterbug congestion inference (Section 5.8).

**5.1 Scenario 1: Recurrent Period of Elevated Latency with Large Amplitude Signals**

Both methodologies labeled every recurrent period of elevated latency as a period of congestion (Figure 6). We suppose that the accuracy of the congestion inferences is partially due to the small contribution of other random factors, as we observe small variability in the baseline during periods of non-elevated latency. The profile of the minimum time series indicates a small contribution of other random components, which create slight fluctuations during periods of non-elevated latency. Additionally, the size of the router buffer amplifies the range of the raw, minimum, and jitter time series (in some cases over 100ms), simplifying the task of identifying periods of high jitter fluctuations.

**Figure 5.** Hierarchical classification of characteristics of elevated latency. We classify periods of elevated latency as either periodic (left branch) or one-off (right branch). Recurrent latency with a consistent period (periodic) suggests an underprovisioned link. A one-off episode of elevated latency can have many causes, e.g., bufferbloat, flash crowd, misconfiguration, route change.

**Figure 6.** KS-test (middle plot) and Jitter dispersion (lower plot) congestion inferences for a periodic high-amplitude signal. In this case, both methods label every recurrent period of elevated latency as periods of congestion. Red-filled intervals indicate periods of congestion. (Color figure online)

**5.2 Scenario 2: Recurrent Period of Elevated Latency with Small Amplitude Signals**

[Continued in the next section]

---

This optimized text provides a clearer, more professional, and coherent presentation of the Jitterbug framework and its various components. It maintains the technical details while improving readability and structure.