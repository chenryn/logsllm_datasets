∗
memset
n2s
n2l
c2l
Deﬁning
1. argument
1. argument
1. argument
3. argument
1. argument
3. argument
2. argument
2. argument
2. argument
Regular expression
.*n2s.*
.*memset.*
.*strlen.*
.*int .*len.*
.*int arg.*
.*size t.*
.*unsigned.*
.*int.*
.*long.*
(a) Library functions
(b) Inferred data sources
Fig. 9: (a) Tainting library functions identiﬁed by our heuristic;
(b) regular expressions inferred for data sources of the third
argument to memcpy.
Inferring queries from the code then leads to the generation
of 38 queries, 14 of which specify a source for the third
argument of memcpy. These are particularly interesting as the
third argument speciﬁes the amount of data to copy and hence
cases where it is attacker-controlled are prime candidates for
buffer overﬂows. Figure 9b contains the 9 sources of the
third argument, showing the attacker-controlled source n2s in
807807
particular. As n2s is the only source that is under attacker
control with certainty, only the single traversal shown in
Figure 10 needs to be executed.
};
arg3Sanitizer = { it, symbol ->
arg2Sanitizer = { it, symbol ->
arg3Source = sourceMatches(’.*n2s.*’);
conditionMatches(".*%s (==|!=) NULL.*", symbol)
1
2
3
4
5
6
7
8
9
10
getCallsTo("memcpy")
11
.taintedArgs([ANY, ANY, arg3Source])
12
.unchecked([ANY_OR_NONE, arg2Sanitizer, arg3Sanitizer]) 13
14
conditionMatches(".*%s.*\+(\d+).*", symbol)
};
Fig. 10: Generated traversal encoding the vulnerable program-
ming pattern leading to the Heartbleed vulnerability.
The query encodes the ﬂow of
information from the
attacker-controlled data source n2s to the third argument of
memcpy. Moreover, it enforces two sanitization rules. First,
it needs to be checked whether the second argument passed
to memcpy is a NULL pointer and second the third argument
needs to be checked in an expression containing an integer.
Clearly,
these rules can be easily modiﬁed by an analyst
to increase precision; however, for the purpose of this case
study, we employ the traversal as is. Even without reﬁnement
the traversal returns only 7 call sites of 738 (0.81%) shown
in Table IV. Among these, two correspond exactly to the
“Heartbleed” vulnerability.
C. Case Study: Vulnerabilities in the VLC Media Player
In this case study, we illustrate how our method plays
the key role in the identiﬁcation of ﬁve previously unknown
Filename
ssl/d1 both.c
ssl/s3 clnt.c
ssl/s3 clnt.c
ssl/s3 srvr.c
ssl/t1 lib.c
ssl/t1 lib.c
crypto/buffer/buf str.c
Function
dtls1 process heartbeat
ssl3 get key exchange
ssl3 get new session ticket
ssl3 get client key exchange
ssl parse clienthello tlsext
tls1 process heartbeat
BUF memdup
TABLE IV: The seven hits returned by the generated query.
Vulnerable functions are shaded.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:25 UTC from IEEE Xplore.  Restrictions apply. 
Traversal
Traversal 1
Traversal 1
Traversal 1
Traversal 2
Traversal 2
Filename
modules/services_discovery/sap.c
modules/stream_out/rtpfmt.c
modules/access/ftp.c
modules/codec/dirac.c
modules/codec/schroedinger.c
Function
ParseSDP
rtp packetize xiph conﬁg
ftp SendCommand
Encode
Encode
Line
1187
544
122
926
1554
CVE Identiﬁer
CVE-2014-9630
CVE-2014-9630
CVE-2015-1203
CVE-2014-9629
CVE-2014-9629
TABLE V: The call sites extracted by our traversals. All of these call sites are vulnerable.
arg1Src = sourceMatches(’.*char \[ .*len \+ .* \].*’)
arg3Src = { sourceMatches(’.*size_t.*’)(it) ||
sourceMatches(’.*str.*len.*’)(it)}
getCallsTo("memcpy")
.taintedArgs([arg1Src, ANY_SOURCE, arg3Src])
Fig. 11: Traversal to identify dynamic allocation of stack
memory for the ﬁrst argument of memcpy.
vulnerabilities in VLC, a popular open-source media player.
To this end, we chose two of the traversals generated for
the sink memcpy that look particularly interesting as they
directly encode dangerous programming practices. The ﬁrst
query, shown in Figure 11, describes a call to memcpy where
the ﬁrst argument is deﬁned to be a local stack buffer of
type char. Moreover, the size is dynamically calculated inside
the deﬁnition. This alone already constitutes a problematic
programming practice as it is impossible to verify whether the
available stack memory allows this allocation to be performed.
In particular, if the amount of memory to be allocated is
controlled by an attacker, and memory is subsequently copied
into the buffer using memcpy, attackers can possibly corrupt
memory and leverage this to execute arbitrary code.
Running this query returns three call sites, all of which
are problematic. In particular, Figure 13 shows the vulnerable
function rtp_packetize_xiph_config where, on line 14,
the variable len is calculated to be the length of an attacker-
controlled string. It is then used to allocate the stack buffer b64
on line 15, and ﬁnally, on line 16, len bytes are copied to the
buffer. The presence of this vulnerability has been successfully
conﬁrmed by triggering an invalid memory access on a 64 bit
Linux platform.
Figure 12 shows a second interesting query: in this case, the
second argument of memcpy stems from a source matching the
regular expression .*Get.*. This corresponds to a family of
macros in the VLC media player that read directly from media
ﬁles possibly controlled by attackers. Cases where the amount
of data to be copied into a buffer are directly dependent on
arg20Source = sourceMatches(’.*Get.*’);
arg21Source = sourceMatches(’.*uint.*_t.*’);
getCallsTo("memcpy")
.taintedArgs([ANY_SOURCE,ANY_SOURCE,
{arg20Source(it) && arg21Source(it)}])
Fig. 12: Traversal to identify third arguments of memcpy
deﬁned by .*Get.*.
808808
if (fmtp == NULL)
return VLC_EGENERIC;
const char *fmtp,
int64_t i_pts )
1 int rtp_packetize_xiph_config( sout_stream_id_t *id,
2
3
4 {
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19 }
/* extract base64 configuration from fmtp */
char *start = strstr(fmtp, "configuration=");
assert(start != NULL);
start += sizeof("configuration=") - 1;
char *end = strchr(start, ’;’);
assert(end != NULL);
size_t len = end - start;
char b64[len + 1];
memcpy(b64, start, len);
b64[len] = ’\0’;
// [...]
Fig. 13: Previously unknown vulnerability found using the
ﬁrst traversal.
an attacker-controlled integer are common sources for buffer
overﬂows, and hence we select the query.
Table V shows the two functions returned by the query, both
of which are vulnerable. In particular, the function Encode
in the source ﬁle modules/codec/dirac.c as shown in
Figure 14 causes a buffer overﬂow: the 32 bit variable len
is initialized by the attacker-controlled source GetDWBE on
line 5 and used in the allocation on line 7. Unfortunately,
the ﬁxed value sizeof(eos) is added to len directly before
allocation, causing an integer overﬂow. In effect, too little
memory is allocated for the buffer p_extra. Finally, on line
10, len bytes are copied into the undersized buffer causing
an overﬂow.
In summary, we identiﬁed 5 previously unknown vulnerabil-
ities, that can possible be exploited to execute arbitrary code.
if( !p_enc->fmt_out.p_extra ) {
// [...]
uint32_t len = GetDWBE( p_block->p_buffer + 5 );
// [...]
p_enc->fmt_out.p_extra = malloc( len + sizeof(eos) );
if( !p_enc->fmt_out.p_extra )
static block_t *Encode(encoder_t *p_enc, picture_t *p_pic) 1
{
2
3
4
5
6
7
8
9
memcpy( p_enc->fmt_out.p_extra, p_block->p_buffer, len); 10
// [...]
11
12
13
return NULL;
}
}
Fig. 14: Previously unknown vulnerability found using the
second traversal.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:25 UTC from IEEE Xplore.  Restrictions apply. 
Moreover, we achieved this by selecting just two promising
automatically generated queries, illustrating the practical mer-
its of our method as a tool for security analysts who review
code for vulnerabilities.
VI. LIMITATIONS
The discovery of previously unknown vulnerabilities
through automatically inferred search patterns demonstrates
the merits of our method. Nevertheless, there exist certain
limitations that we discuss in the following.
First and as a consequence of our inference setup, if a
major part of the code base lacks a proper sanitization, our
method is unable to identify corresponding sanitization rules
from the data ﬂow and thus fails to generate accurate search
patterns. Fortunately, this limitation does not apply to mature
software projects that make extensive use of sanitization when
processing user-controlled data.
Second, our method assumes that data is only passed from
callers to the callee via function arguments and return values.
Shared resources, such as global variables or shared memory,
are not modeled by our method. As a consequence, we are not
able to describe taint-style vulnerabilities where an attacker
propagates data across these resources to a sink. Modifying
the interprocedural code property graph to account for this
type of data ﬂow seems involved but possible. We leave this
modiﬁcation as an extension for future work.
Third, the work discussed so far only shows the applicability
of our method for the identiﬁcation of vulnerabilities typical
for C code, such as invalid memory accesses. While in
principle, our method should be applicable to several other
vulnerability types, and in particular, typical Web application
ﬂaws, this remains to be shown. In particular, adapting our
method to a different language requires careful handling of
language-speciﬁc properties.
Finally, the control ﬂow of a software is not fully recovered
by our method. In particular, dynamic calls are currently
not resolved. Similarly, our method is not able to describe
vulnerabilities rooted in concurrent execution of functions,
such as many use-after-free security ﬂaws. This limitation is
not trivial to address and possibly beneﬁts from coupling code
property graphs with techniques for dynamic analysis, such as
dynamic taint tracking or symbolic execution.
VII. RELATED WORK
The development of methods for ﬁnding vulnerabilities in
software is long-standing topic in security research that spans
a wide range of approaches and techniques. For our discussion
of related work, we focus on approaches that also aim at
assisting a security expert during auditing of software instead
of replacing her.
a) Methods based on query languages and annotations:
Closely related to our work are approaches that enable an
analyst to search for vulnerabilities using query languages
or annotations. For example, the methods by Martin et al.
[35] and Lam et al. [30] both employ descriptive query
languages for modeling code and ﬁnding software defects.
Similarly, Vanegue et al. [56] experiment with extended static
checking [15] as part of the HAVOC tool and test its per-
formance at a large code audit. Moreover, several approaches
for the discovery of information-ﬂow vulnerabilities based on
security type systems have been presented [see 21, 47, 50]. In
particular, the Jif compiler [38, 39] performs type checking to
allow security policies to be enforced for an annotated version
of Java. Moreover, Jif implements a type inference algorithm
to reduce the number of user-deﬁned annotations required.
Finally, Evans and Larochelle [13] use annotations for C
as a means for ﬁnding vulnerable patterns in code. While
our approach shares a similar motivation, it differs in that it
automatically infers search patterns and thus the analyst only
needs to deﬁne a set of security-sensitive sinks to start auditing
an unknown code base.
b) Inferring programming patterns and speciﬁcations:
Manual analysis of code is a tedious and time-consuming task.
As a remedy, several methods have been proposed that make
use of statistical methods, machine learning, and data mining
techniques for accelerating this process. To this end, sev-
eral methods automatically infer programming patterns [e.g.,
19, 32, 58] and security speciﬁcations [e.g., 28, 34, 54],
from code, revision histories [33], and preconditions of APIs
[e.g., 7, 41, 55]. A related strain of research has followed a
more principled approach by modeling and inferring security
policies [e.g., 6, 36, 52, 57] for discovering information-
ﬂow vulnerabilities. Similar to our method, many of these
approaches are based on syntax trees and code slices as well
as representations that combine syntax, control ﬂow, and data-
dependence relationships [e.g., 27, 29].
Engler et al. [12] are among the ﬁrst to point out that
defects in source code can often be linked to violations of
implicitly introduced system-speciﬁc programming patterns.