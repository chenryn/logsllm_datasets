MyData data;
public DecRunnable(MyData data){
this.data = data;
}
public void run() {
data.dec();
}
}
public static void main(String[] args) {
MyData data = new MyData();
Runnable add = new AddRunnable(data);
Runnable dec = new DecRunnable(data);
for(int i=0;i<2;i++){
new Thread(add).start();
new Thread(dec).start();
}
Runnable对象作为一个类的内部类
2. 将Runnable对象作为一个类的内部类，共享数据作为这个类的成员变量，每个线程对共享数
据的操作方法也封装在外部类，以便实现对数据的各个操作的同步和互斥，作为内部类的各
个Runnable对象调用外部类的这些方法。
public class MyData {
private int j=0;
public synchronized void add(){
j++;
System.out.println("线程"+Thread.currentThread().getName()+"j为："+j);
}
public synchronized void dec(){
j--;
System.out.println("线程"+Thread.currentThread().getName()+"j为："+j);
}
public int getData(){
return j;
13/04/2018 Page 89 of 283
}
}
public class TestThread {
public static void main(String[] args) {
final MyData data = new MyData();
for(int i=0;i<2;i++){
new Thread(new Runnable(){
public void run() {
data.add();
}
}).start();
new Thread(new Runnable(){
public void run() {
data.dec();
}
}).start();
}
}
}
4.1.18. ThreadLocal作用（线程本地存储）
ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，ThreadLocal 的作用
是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或
者组件之间一些公共变量的传递的复杂度。
ThreadLocalMap（线程的一个属性）
1. 每个线程中都有一个自己的 ThreadLocalMap 类对象，可以将线程自己的对象保持到其中，
各管各的，线程可以正确的访问到自己的对象。
2. 将一个共用的 ThreadLocal 静态实例作为 key，将不同对象的引用保存到不同线程的
ThreadLocalMap中，然后在线程执行的各处通过这个静态ThreadLocal实例的get()方法取
得自己线程保存的那个对象，避免了将这个对象作为参数传递的麻烦。
3. ThreadLocalMap其实就是线程里面的一个属性，它在Thread类中定义
ThreadLocal.ThreadLocalMap threadLocals = null;
13/04/2018 Page 90 of 283
使用场景
最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。
private static final ThreadLocal threadSession = new ThreadLocal();
public static Session getSession() throws InfrastructureException {
Session s = (Session) threadSession.get();
try {
if (s == null) {
s = getSessionFactory().openSession();
threadSession.set(s);
}
} catch (HibernateException ex) {
throw new InfrastructureException(ex);
}
return s;
}
4.1.19. synchronized和 ReentrantLock的区别
4.1.19.1. 两者的共同点：
1. 都是用来协调多线程对共享对象、变量的访问
2. 都是可重入锁，同一线程可以多次获得同一个锁
3. 都保证了可见性和互斥性
13/04/2018 Page 91 of 283
4.1.19.2. 两者的不同点：
1. ReentrantLock显示的获得、释放锁，synchronized隐式获得释放锁
2. ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理锁的
不可用性提供了更高的灵活性
3. ReentrantLock是API级别的，synchronized是JVM级别的
4. ReentrantLock可以实现公平锁
5. ReentrantLock通过Condition可以绑定多个条件
6. 底层实现不一样， synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻
塞，采用的是乐观并发策略
7. Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言
实现。
8. synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；
而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，
因此使用Lock时需要在finally块中释放锁。
9. Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，
等待的线程会一直等待下去，不能够响应中断。
10. 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。
11. Lock可以提高多个线程进行读操作的效率，既就是实现读写锁等。
4.1.20. ConcurrentHashMap并发
4.1.20.1. 减小锁粒度
减小锁粒度是指缩小锁定对象的范围，从而减小锁冲突的可能性，从而提高系统的并发能力。减
小锁粒度是一种削弱多线程锁竞争的有效手段，这种技术典型的应用是 ConcurrentHashMap(高
性能的HashMap)类的实现。对于HashMap而言，最重要的两个方法是get与set方法，如果我
们对整个 HashMap 加锁，可以得到线程安全的对象，但是加锁粒度太大。Segment 的大小也被
称为ConcurrentHashMap的并发度。
4.1.20.2. ConcurrentHashMap分段锁
ConcurrentHashMap，它内部细分了若干个小的 HashMap，称之为段(Segment)。默认情况下
一个ConcurrentHashMap被进一步细分为16个段，既就是锁的并发度。
如果需要在 ConcurrentHashMap 中添加一个新的表项，并不是将整个 HashMap 加锁，而是首
先根据hashcode得到该表项应该存放在哪个段中，然后对该段加锁，并完成put操作。在多线程
环境中，如果多个线程同时进行put操作，只要被加入的表项不存放在同一个段中，则线程间可以
做到真正的并行。
13/04/2018 Page 92 of 283
ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成
ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可
重入锁 ReentrantLock，在 ConcurrentHashMap 里扮演锁的角色，HashEntry 则用于存储键值
对数据。一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的结构和 HashMap
类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是
一个链表结构的元素， 每个Segment守护一个HashEntry数组里的元素,当对HashEntry数组的
数据进行修改时，必须首先获得它对应的Segment锁。
4.1.21. Java中用到的线程调度
4.1.21.1. 抢占式调度：
抢占式调度指的是每条线程执行的时间、线程的切换都由系统控制，系统控制指的是在系统某种
运行机制下，可能每条线程都分同样的执行时间片，也可能是某些线程执行的时间片较长，甚至
某些线程得不到执行的时间片。在这种机制下，一个线程的堵塞不会导致整个进程堵塞。
4.1.21.2. 协同式调度：
协同式调度指某一线程执行完后主动通知系统切换到另一线程上执行，这种模式就像接力赛一样，
一个人跑完自己的路程就把接力棒交接给下一个人，下个人继续往下跑。线程的执行时间由线程
本身控制，线程切换可以预知，不存在多线程同步问题，但它有一个致命弱点：如果一个线程编
写有问题，运行到一半就一直堵塞，那么可能导致整个系统崩溃。
13/04/2018 Page 93 of 283
4.1.21.3. JVM的线程调度实现（抢占式调度）
java使用的线程调使用抢占式调度，Java中线程会按优先级分配CPU时间片运行，且优先级越高
越优先执行，但优先级高并不代表能独自占用执行时间片，可能是优先级高得到越多的执行时间
片，反之，优先级低的分到的执行时间少但不会分配不到执行时间。
4.1.21.4. 线程让出cpu的情况：
1. 当前运行线程主动放弃 CPU，JVM 暂时放弃 CPU 操作（基于时间片轮转调度的 JVM 操作系
统不会让线程永久放弃CPU，或者说放弃本次时间片的执行权），例如调用yield()方法。
2. 当前运行线程因为某些原因进入阻塞状态，例如阻塞在I/O上。
3. 当前运行线程结束，即运行完run()方法里面的任务。
4.1.22. 进程调度算法
4.1.22.1. 优先调度算法
1. 先来先服务调度算法（FCFS）
当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队
列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采
用 FCFS 算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，
13/04/2018 Page 94 of 283
使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机，特点是：算法比较
简单，可以实现基本上的公平。
2. 短作业(进程)优先调度算法
短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们
调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，
将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重
新调度。该算法未照顾紧迫型作业。
4.1.22.2. 高优先权优先调度算法
为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度
算法。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。
当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程。
1. 非抢占式优先权算法
在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下
去，直至完成；或因发生某事件使该进程放弃处理机时。这种调度算法主要用于批处理系统中；
也可用于某些对实时性要求不严的实时系统中。
2. 抢占式优先权调度算法
在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只
要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)
的执行，重新将处理机分配给新到的优先权最高的进程。显然，这种抢占式的优先权调度算法能
更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批
处理和分时系统中。
2．高响应比优先调度算法
在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行
得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时
间的增加而以速率a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的
变化规律可描述为：
(1) 如果作业的等待时间相同，则要求服务的时间愈短，其优先权愈高，因而该算法有利于
短作业。
(2) 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权