(cid:5)(cid:16)(cid:15)(cid:13)(cid:19)(cid:16)(cid:17)(cid:13)(cid:15)(cid:12)(cid:1)(cid:20)(cid:15)(cid:13)(cid:19)
Fig. 5. TRUSTNET Monitor Microachitecture.
require any extra storage. This prevents attacks wherein the
IFU maliciously changes the control ﬂow.
• #11 Data TLB: Predicted by the checker data TLB and
reacted to by the LSU, this conﬁrms each cycle that the outputs
of the data TLB match the outputs of the checker data TLB.
This prevents data TLB attacks, such as permissions violations
or page mis-translation. This is on the borderline of what we
would start to call ‘smart duplication’ because the ‘signatures’
are so large. However, we included this is our DATAWATCH
implementation and simulation.
• #12 Instruction TLB: Predicted by the checker instruction
TLB and reacted to by the IFU, this is the same as monitor
#11 but for the instruction TLB rather than the data TLB.
• #13 IDU: Predicted by the IFU and reacted to by the
LSU, this conﬁrms that the number of instructions decoded
into memory operations matches the number of memory
instructions fetched. For our microprocessor, this required that
the IFU looked at a few bits of the instruction. The monitoring
occurs at a one cycle lag, so the timing on the critical path is
unaffected. The IFU stores a few of the bits from the fetched
instruction in ﬂip-ﬂops until the next cycle, when a prediction
can be made with a few logical gates. For our case study, this
is the only type of control corrupter decoder attack we address.
The reason for this is that in our simple microprocessor, the
only types of signals the decoder can cause are loads in stores
(if, for example, the decoder changed an add to a subtract,
this would be a data corrupter, because it would not alter the
number of transactions in the execution unit, just the value of
the output). In more complex microprocessors, decode units
may be responsible for more types of transactions and might
require additional monitoring triangles. When customizing a
DATAWATCH system to ﬁt a particular design, it is important up
front to identify what types of signals each unit is responsible
for.
D. Microarchitecture and Optimizations
The microarchitecture of the predictor and monitor units are
depicted in Figure 5. The predictor unit consists of (i) event
buffers for delaying the issue of tokens to the monitor and (ii)
token issue logic to determine when buffered events can be
released from the event buffers. The predictor unit requires a
small buffer because it is possible for multiple predictions to
happen before a reaction happens, and these predictions must
be remembered for that duration. These buffers can be sized
a priori to avoid overﬂows. The monitor itself simply checks
if events appear on the predictor and reactor inputs during the
same cycle.
1) TRUSTNET Optimization: When designing the TRUST-
NET system to catch emitter backdoors, we considered it to be
important that the monitors ﬁt simply into the pipeline without
any complex timing or buffering issues.
Since predictions and reactions must arrive at the monitor
during the same cycle, timing must be controlled in the face of
non-determinism, which arises in all microprocessors due to
cache misses, etc. We handled this differently in the case of
the memory hierarchy and in the case of the pipeline. The
pipeline offers a natural lock-step manner for coordinating
events. If a reaction stage is N pipeline steps down from
a prediction stage, then the prediction stage has a size N
buffer that advances only when that stage of the pipeline
advances. Since the monitoring network advances in lock-step
with pipelined events, timing is not a problem. For example, if
the third pipeline stage wants to send a prediction to a monitor
that lies in the ﬁfth pipeline stage, this will take two pipeline
advancements (no need for forwarding). If the third stage stalls
for any reason, the prediction also stalls and gets buffered.
When the data from the third stage reaches the ﬁfth stage,
the prediction token will also arrive. Of course, the prediction
token should not pass through the fourth stage but should
instead remain in the prediction buffer, with a bit denoting
that it is semantically in the fourth stage.
In the case of the cache hierarchy, on the other hand, it
is necessary to know which predictions correspond to which
reactions, because it is possible for memory requests to be
handled out of order. This requires time-stamping of packets,
for example with a one byte local time signature copied from
an 8-bit modular counter.
2) DATAWATCHOptimization: A na´ıve solution for catching
control corrupter backdoors in TLBs (translation lookaside
buffers) is to simply have two (or more) designers design the
same TLB and compare their outputs each cycle. Since TLBs
tend to be power-hungry, highly associative structures, dupli-
cation is not a good idea. Instead of complete duplication, we
propose a new TLB microarchitecture that provides signiﬁcant
protection without the costs associated with duplication. The
TLBs contain page translation and permissions information not
available elsewhere on chip. A TLB consists of a CAM that
translates a virtual page into a physical page, which is then
stored in a table (RAM) with the corresponding permissions
information for that physical page.
The basic idea of our method is to create a “checker” direct-
mapped structure that has the same functionality as a TLB, the
motivation being that a direct-mapped structure uses a fraction
of the power of an associative one. The TLBs in our case study
are fully associative. We added functionality to the CAMs to
output the line number of the output. This allowed us to build a
180
checker TLB that uses these line numbers. Essentially, instead
of having one CAM and a direct-mapped RAM (as is normal),
we have one CAM and two direct-mapped RAMs that operate
in parallel. The CAM provides matching entries to both RAMs
in parallel. One of those RAMs communicates with the rest of
the chip while the other RAM only gives outputs to a monitor
(equality veriﬁer). The equality check occurs at a one cycle
latency, so the values are buffered for that cycle.
Naturally, the CAM could be tampered with so that it sends
incorrect line numbers to the checker TLB. This would cause
the equality check to fail because data from one line of the
original TLB’s RAM will be compared to data from a different
line of the second RAM, causing an alarm to be thrown.
Therefore, our checker TLB turns a potential conﬁdentiality
or integrity attack into at worst an availability attack. We note
that this availability attack would also be easy to catch at
veriﬁcation time because the passing of the line number is
simple, combinatorial logic that can be checked by exhaustive
enumeration.
While this duplication is much more expensive than the
simpler monitor used for emitter backdoor protection, it is
much less expensive than complete duplication and offers
strong protection for a highly vulnerable unit.
E. Applications of Prior Solutions
As we mentioned brieﬂy in the introduction, the problem
of building trusted systems from untrustworthy components
is a classic problem that has received some attention in the
systems community. A common solution used to amplify trust
in corruptible processes is to use the N-version model of
computation. The basic idea is to have N entities perform
the same computation and compare the N outputs to check
for untrustworthy behavior. In this section, we expand on the
different ways in which this concept can be applied to micro-
processors and discuss the advantanges and disadvantages.
To deal with untrusted designers in the context of mi-
croprocessors, one option is to have N designers create N
versions of each unit within a processor, which would all
be run continuously to check for untrustworthy behavior.
Alternately, one could run a program on N different systems
that implement the same ISA but are manufactured by different
vendors, say, boards that have x86 processors from AMD,
Intel and Centaur. The latter suffers from high power overhead
while the former suffers from both high design cost per
chip and high runtime costs. Another solution that avoids
only the runtime cost is to statically and formally check the
design units from N designers for equivalence. This approach
increases the design cost and does not scale to large designs
or designs that are vastly different. According to the 2007
ITRS roadmap, only 13.8% of a normal microprocessor design
speciﬁcation is formalized for veriﬁability [2]. All common
solutions to this problem appear unsatisfactory in the context
of microprocessors.
Another option is to use static veriﬁcation to identify
backdoors. There has been extensive prior work on static
veriﬁcation of RTL level designs [68][18][34]. Static veriﬁ-
cation involves conﬁrming functional equivalence between a
behavioral level golden model (e.g., a C program) and the
RTL level design under test. The difﬁculty lies in the fact
that the input space for a microprocessor grows exponentially
with the number of input interfaces and the internal state size,
which makes the functional domain catastrophically large.
Exhaustive comparison is unrealistic, so the state of the art is
to use probabilistic approaches that attempt to obtain reason-
able coverage, such as equivalence checking [30][68], model
checking [30], and theorem proving [30]. These approaches
can work for small units, particularly ones with little or
no state, such as ALUs. Unfortunately, static veriﬁcation is
increasingly becoming the bottleneck in the microprocessor
design process [30] and is becoming less reliable [2].
A fundamental weakness of static veriﬁcation techniques
when it comes to backdoor detection is that they attempt to
use a stationary weapon to hit a moving target. Static methods
choose speciﬁc targets for comparison or invariants to conﬁrm
about small portions of the design. Since it is reasonable to
assume that a malicious insider would have full knowledge of
the static veriﬁcation technique being used, he or she would
most likely design the backdoor to avoid the space covered by
these techniques. For example, he or she would likely make
sure not to violate any of the theorems being veriﬁed and to
avoid regions being formally checked for equivalence.
V. EVALUATION
The goals of our evaluation were to: (1) study the accuracy
and coverage provided by TRUSTNET and DATAWATCH, (2)
measure the increases in on-chip network congestion from
DATAWATCH running on real programs and (3) measure the
area overheads of both mechanisms. We do not discuss per-
formance since the proposed mechanisms do not stall the
pipeline, memory system, or any other on-chip unit, and
security packets travel on a dedicated network.
A. Applicability
This section addresses the general applicability and limita-
tions of our solution, including related aspects and potential
extensions.
• Scope of our solution Our implementation of TRUSTNET
and DATAWATCH was designed for a simple, in-order micro-
processor. While the methodology is applicable to any in-order
microprocessor, this exact implementation only works for the
microprocessor in our case study. In order to ﬁt TRUSTNET
and DATAWATCH to other designs, it is necessary to analyze the
units at a high level and determine what the natural predictors
and reactors are. In future work, we hope to develop a tool
that automates this process.
• Level of our solution Our solution is at the RTL level and
thus can only catch attacks that operate on the RTL level. Post-
RTL, circuit level attacks, such as tampering with the voltage
thresholds on certain transistors, would not be caught by our
system. Our solution covers the cores and the cache hierarchy
of the OpenSPARC T2 microprocessor but does not cover
181
debug/test logic or miscellanies, such as clock distribution.
Additionally, side-channel attacks are also not covered.
• Multiple attackers The solution we implemented works only
under the assumption that at most one of the design teams
is corrupt. Our design is a triangle (complete graph of size
three). If we remove the assumption that only one of the design
subteams is corrupt and allow for n different subteams to be
corrupt and fully coordinated, then the solution must be come
more complicated.
In order for a TRUSTNET system to catch n coordinated
attackers, it is necessary to form a complete graph of size
n + 2. The premise of the system is that two honest units
must communicate with each other to compare information
and detect discrepancies. If there are at most n+1 nodes and n
have been tampered with, then at most one of them is honest,
and the one honest node receives only invalid information.
Therefore, the size of the graph must be at least n + 2 so
that there are at least two honest nodes. If the graph is not
complete, i.e. it is missing an edge, then it is possible that
the missing edge connects the only two honest nodes. In that
case, the two honest nodes receive only invalid information.
Therefore, the graph must be complete. Since complete graphs
contain n(n+1)
bidirectional edges, the TRUSTNET solution,
when extended to n attackers for a microprocessor with u
units, has a fundamental communication overhead of n(n +
1)u ∝ n2u.
2
The conclusion is
that even though TRUSTNET and
DATAWATCH are generalizable for multiple, coordinated at-
tacking subteams, they do not scale well. We present this
generalized scheme only for completeness.
• Alarms The decision of how to handle an alarm is domain
speciﬁc and not a fundamental aspect of our monitoring
system. However, we present initial suggestive thoughts on
what might be done with an alarm. In our experimental
implementation, the alarm was simply recorded and not used
for any corrective actions.
The simplest response to an alarm is to kill the defective
processor, which turns a conﬁdentiality or integrity attack into
an availability attack. In highly secure domains, this may
be desirable to guarantee no exﬁltration of sensitive data.
Additionally, in a heterogeneous processor (diversity) setting,
it may be desirable to kill the defective core. We also note that
using the TRUSTNET and DATAWATCH infrastructure has the
potential to greatly simplify the task of making microproces-
sors tamper corrective. If an alarm is sounded, the problem can
be corrected by rolling back to the last committed instruction.
Additionally, the instruction that was in ﬂight in the corrupted
unit can be ﬂagged as a cheat code and logged for future
execution. This approach would be analogous to a honeypot.
• Extensions to General Microprocessors There are several
ways to generalize the TRUSTNET and DATAWATCH architec-
ture, and each way poses challenges for future work. The
multi-threaded case is a relatively simple generalization that
can be implemented by making the packets n-wide for an
n-threaded core. Assuming one thread is not supposed to
TABLE II
EXPERIMENTAL INFRASTRUCTURE
Instruction Set
Sun SPARC
Instruction sup-
ply
Execution
Data supply
Pipeline Stages
Benchmarks
Microarchitecture
16KB, 8-way 1R/1W L1 I cache, 64-entry FA
I-TLB (both 2-cycle access, 52 cycles on TLB
miss), No branch prediction, stall until branch