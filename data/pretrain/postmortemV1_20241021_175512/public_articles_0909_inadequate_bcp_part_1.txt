Why Your Business Continuity Plan May be Inadequate
September2014
KeithB.Evans,ShadowbaseBusinessDevelopment&ProductManagement
PaulJ.Holenstein,ExecutiveVicePresident,Gravic
Disaster Recovery is Not Business Continuity
In today’s business world, access to real-time online transactional data is a competitive
advantage. To realize the advantage, this data must be available at any time, all the
time, from anywhere, and it must be current. The corollary to this advantage is that the
inability to access or update this current data carries a significant business cost, possibly measured in
many thousands of dollars per second. These requirements necessitate an application service that is
continuouslyavailable, in other words an IT infrastructure that is continuouslyavailable, and an adequate
business continuity plan in place to assure application service continuity with access to data under both
plannedandunplannedcircumstances.
Stuff Happens
Whether itbefire,power failure,softwareerror,malfeasance,or someother cause,thefactis thatevents
will occur that lead to unplanned outages of IT services. It is a matter of when, not if. Studies1 show that
the average business revenue lost per hour of downtime across a range of industry segments is about
US$1.4M per hour.TheU.S.Bureauof Labor reports that93% of companies that suffer asignificantdata
1NetworkComputing,TheMetaGroup,ContingencyPlanningResearch
1
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

loss areoutof business withinfive years.Outages willultimatelyhappen,andtheycanbeverydamaging
(even fatal) to the business. Consequently, for those critical IT services necessary for the business to
function,stepsmustbetakeninadvancetoensureavailabilityofthoseservicesnomatterwhatthecause
ordurationoftheoutage.
HPNonStopsystems–moresothanmanyother platforms–andthemission-criticalapplicationsthatrun
on them, must have a business continuity plan in place. NonStop systems are highly fault-tolerant, but
theystillrepresentasingle pointoffailure.Hence,thereisaneedforabusinesscontinuityplantoenable
operations to survive, despite the loss of a NonStop system or an entire datacenter. Such plans typically
include multiple geographically distributed NonStop systems with at least some form of online data
replication between them. The question is, are these plans adequate?While you maythink so, that belief
couldbebasedmoreonhopethanonreality.Arecent survey2reportssomedisturbingresults:
 Only32% believetheyutilize allbest practices in datacenter design andredundancyto maximize
availability.
 Only 37% agree there are ample resources to bring their datacenter up and running if there is an
unplannedoutage.
 59% agree that the risk of an unplanned outage has increased as a result of cost constraints
insidethedatacenter.
 57%believeallormostunplannedoutagescouldhavebeenprevented.
These findings, which illustrate that not enough attention and resources are being applied to outage
prevention, are borne out by the fact that 95% of the respondents have experienced a complete
datacenter outage, with an average number of 1.24 outages per year and an average duration of 107
minutes.
A study conducted by IBM3 finds that perceptions of the business continuity plan often differ from reality,
with 82% of respondents confident or very confident about their level of outage protection, yet only 65%
have 24x7 expert technical support coverage. This same study also found that only 78% perform regular
failovertesting,andonly67%haveafullydocumenteddisasterrecoveryplan.
While everyone acknowledges that outages do happen, are costly, and need to be protected against,
there is substantial evidence that IT departments are not applying sufficient resources to business
continuity in practice (even though they might think otherwise). The first lesson is to take a thorough and
objective look at your business continuity plans, asking if theyare adequate and will theywork, or do you
justhopetheywill?
Business Continuity Technologies Are Not All Equal
In implementing a business continuity plan, there are a range of technologies available which provide
differing levels of protection, from magnetic tape backup to active/active data replication (Figure 1). Key
metrics for defining recovery solutions are how long will recovery take, or the Recovery Time Objective
(RTO),andhowmuchdatawillbelost,ortheRecoveryPointObjective(RPO).4
2
PonemonInstitute2010NationalSurveyonDataCenterOutages.Datafrom453IToperationsmanagersacrossawide-rangeof
industrysegments(Financial,Healthcare,Retail,Communications,Services,etc.).
32012IBMGlobalReputationalRiskandITStudy
4
See Chapter 6, RPO and RTO, Breaking the Availability Barrier: Survivable Systems for Enterprise Computing, AuthorHouse:
2004
2
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

)ssoLataDsseL(OPRretteB
syad sruoh setunim sdnoces
Figure1:TheBusinessContinuityTechnologyContinuum
Figure 2 shows some estimated RTO times and costs based on the business continuity technology
employed. This table clearly demonstrates that tape-based solutions are insufficient for the purposes of
providing adequate availability to mission-critical applications. But what this table also shows is that
active/passivestyledatareplicationmayalsobeinadequate.Thisinadequacybearsmoreexplanation.
1 Worstcase:withfailoverfaults,managementindecision,etc.
2 Bestcase:withnofailoverfaults,promptmanagementaction,etc.
3 Possiblyslightlylongerdependingonnetworkswitching
4 Halfofusersseenooutageatall(lessthanhalfif>2replicatednodes)
Figure2:EstimatedOutageTimesandCostsbyBusinessContinuityTechnology
(FinancialApplication,AverageOutageCost$1.5M/Hour5)
Active/passive business continuity architectures describe multiple geographically distributed systems, in
which one system is active (being used to process online business transactions), and data from that
5
NetworkComputing,TheMetaGroup,ContingencyPlanningResearch
3
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

system is replicated to remote standby systems in near real-time. Replication is uni-directional, one-way,
from the active to the standby system. The standby systems are not running mission-critical online
applications; they may be used for ad-hoc query and other non-update type services. In ideal
circumstances, this architecture may seem to provide adequate protection against service outages, but
therearemanypotentialissuesthatmakeitalessthansatisfactorysolution:
 Difficult to test. In order to test a failover plan, the active system must typically be taken out of
service and workload transferred to the standby system (i.e., service to end users is disrupted).
Because the standby system is not running the business applications at the time of the takeover
(i.e., it is not a known-working system), it is possible it will take several hours before it can be
brought into service. Once upon a time there may have been an overnight or weekend
maintenance outage window where this length of application outage was acceptable, but in
today’s always-on world, this outage duration is increasinglynot the case. Even if such a window
does exist, it is not always possible to complete the testing within that timeframe. When the
testing period is over, there is also the risk that the active system may not be able to be brought
back online in time. For all these reasons, very often failover plans have not been sufficiently
tested, and when they are actually needed, the failover does not go smoothly (so-called “failover
faults”occur),andrestoringservicetakesmuchlongerthanexpected.
 Management indecision. Because there is an uncertainty as to whether the failover will be
successful, senior management is usually required to authorize the action (as opposed to trying
to restore the failed active system, if that is possible). Locating the necessary management
personnel and apprising them of the situation and having them reach a decision takes time,
furtherprolongingtheoutage.
 Allusersareaffected.Whenanoutageoftheactivesystem occurs,allusersaredeniedservice
untileitherafailoveriseffectedortheactivesystemisrestored.
 More data loss at failover. Because all of the updates are being performed on one system, if
that system fails, then all of the data in the replication stream that has not been sent to the
standbysystemwillbelost(knownasthe“replicationlatency”).6
 Standby database open read-only. Even if the business applications are actually up and
running on the standby system (but not processing transactions), the database may only be
opened read-only. Hence, when the failover occurs, all of the applications must be somehow
notified and the database reopened for read-write access. This process complicates application
programming,andcanbetimeconsuming,extendingtheoutage.
 Standby database inconsistent. While replication is occurring, the standby database may be
inconsistent (“fuzzy”), which could limit utilization of the standby system for query processing.
This inconsistency will happen, for example, if the replication engine does not preserve the
sourceapplication’stransactionboundarieswhenreplayingthedataintothestandbydatabase.
Due to these issues, recovery times for an active/passive system may be in the order of several hours,
costing millions of dollars (Figure 2). Worse, if a serious failover fault occurs, it is possible that the
standbysystem maynever beable to be brought into service; the mission-critical application is down and
stays down, denying service to users for a prolonged period. This system is insufficient protection for a
mission-criticalapplication.
6
See Chapter 3, Asynchronous Replication, Breaking the Availability Barrier: Survivable Systems for Enterprise Computing,
AuthorHouse:2004
4
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Some Technologies Are “More Equal” than Others
There are however alternative business continuitytechnologies which maybe deployed todaythat do not
suffer from these issues. The first of these technologies is known as “sizzling-hot-standby.” This
technology looks much the same as an active/passive architecture (all transactions are routed to and
executed by a primary system, with data replication to a standby system), but it has one big difference –
