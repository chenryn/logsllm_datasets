 AA+:Amorphousdatabasewithcollisionsupport.
 AA-: Amorphousdatabasewithoutcollisionsupport.
 AP+:Partitioneddatabasewithcollisionsupport.
 AP-: Partitioneddatabasewithoutcollisionsupport.
 AT+:Transactionreplicationwithcollisionsupport.
 AT-: Transactionreplicationwithoutcollisionsupport.
In the descriptions of the following architectures, the active/active attributes of the approach are
described followed by the characteristics of the replication engine required to support the
architecture.
6
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

ArchitectureAA+:AmorphousDatabasewithCollisionSupport
Architecture
The database is fully distributed and appears
amorphous tothe application. Anytransaction, update data data update
base base
update, or read can be applied to any read read
copy copy
database in the application network and is replication
typically directed to the closest processing
node. Data collisions are anticipated, and they
are either avoided5 or are detected and update data
base
resolved by facilities built into the replication read copy
engine.6 Should a node fail, transactions are
automaticallyroutedtosurvivingnodes. AA+Architecture
ReplicationEngine
This architecture requires bidirectional replication.7 All database copies must be open for full
read/write access. The architecture also requires that full data collision detection and
resolutionbesupportedbythereplicationengine.
ArchitectureAA-:AmorphousDatabasewithoutCollisionSupport
Architecture
This architecture assumes that the application
update data data update
issuchthatcollisionswillnotoccurorthatthey
base base
read read
may be ignored. Any transaction, update, or copy copy
read can be applied to any database in the replication
application network and is typically directed to
the closest node. Data collisions are not
update data
anticipated, nor are they handled. Should a base
nodefail,transactions areautomaticallyrouted read copy
tosurvivingnodes.
AA-Architecture
ReplicationEngine
This architecture requires bidirectional replication. All database copies must be open for full
read/write access. Data collision detection and resolution need not be supported by the
replicationengine.
5Suchasbyrelativereplication,inwhichoperationsarereplicatedratherthanrowimages.
6 Chapter 4, Active/Active Topologies, Breakingthe Availability Barrier II: Achieving Century Uptimes with Active/Active
Systems
7Bidirectionalreplicationimpliesthatthereplicationenginepreventsping-ponging,orthereturnofareplicateddataitem
toitssource.
7
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

ArchitectureAP+:PartitionedDatabasewithCollisionSupport
Architecture
Thedatabaseispartitioned,andeachpartitionis proposed
owned by one node. Only the owning node can proposed update proposed
update update
update its partition, and it resolves any data partition replication partition
read copy owner read
collisions. Reads and updates may be directed
actual
to any node, thus preserving locality. Updates update
.
made by non-owning nodes to their partitions .
are replicated to the owning node, which will .
otherpartitions
resolve any data collisions by accepting one
AP+Architecture
updateandrejectingtheother.Thefinalupdates
madetotheowningnode’spartitionarethenreplicatedback totheothernodes,includingthe
nodes that originated the updates, thus maintaining proper synchronization among the
database copies. Provision must be made to detect the failure of a node. Should an owning
nodefail,anothernodemustbepromotedtobecometheowningnodeforthatpartition.
ReplicationEngine
This architecture requires bidirectional. All database partitions must be open for read/write
accessonallnodestosupportfastfailover whenanon-owningnodemustbepromotedtoan
owning node. Furthermore, full data collision detection and resolution must be supported by
thereplicationengine.
ArchitectureAP-:PartitionedDatabasewithoutCollisionSupport
Architecture
The database is partitioned, and each update partition partition read
partition is owned by one node. Only the read ownera replication copya update
owning node can update its partition, and partition partition
allupdatesforapartitionmustberoutedto read copyb ownerb read
the owning node. However, all nodes can AP-Architecture
read all partitions. Data collisions cannot
occur. Provision must bemade to detect the failure of a node. Should a node fail, its partition
ownershipmustbetransferredtoanothernode.
ReplicationEngine
This architecture requires unidirectional replication from each partition owner to all of the
other nodes. All database partitions must be open for read/write access on all nodes to
supportfastfailover.Datacollisiondetectionandresolutionarenotrequired.
ArchitectureAT+:TransactionReplicationwithCollisionSupport
Architecture
data data
All transactions are sent simultaneously to every node in the
base base
application network. This may be done by the client, by network copy copy
routing, or by node forwarding. Each node executes the
transactions or updates independently of the other nodes.
However, there is a sequencing mechanism to ensure that all sequencing
nodes execute transactions in the same order. Therefore, data
collisionscannotoccurandalldatabaseswillbeidentical. transaction transaction
AT+Architecture
8
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

ReplicationEngine
The replication engine required by this architecture submits transactions to all nodes in the
application network. It supplies the coordination necessary to control transaction ordering
amongthenodes.
ArchitectureAT-:TransactionReplicationwithoutCollisionSupport
Architecture
This architecture assumes that the application database is data data
insensitive to transaction execution order. All transactions are base base
copy copy
sent simultaneously to every node in the application network by
each client application. Each node executes the transactions or
updates independently of the other nodes. Updates submitted by
different clients may be executed in different order by the nodes.
Therefore, the databases may diverge over time due to data
transaction
collisionsunlesstheapplicationisinsensitivetotransactionorder.
AT-Architecture
ReplicationEngine
Thereplicationenginerequired bythis architecturesubmits transactions simultaneouslytoall
nodes in the application network. There is no coordination to control transaction ordering
amongthenodes.
Master/SlaveArchitectures
There are other active/active architectures known as “master/slave.” In these systems, one
nodeisthemaster.Itperformsallupdatesandreplicatestheseupdatestotheslavesystems.
These architectures are, in effect, a partitioned architecture with a single partition and are
coveredbytheAP+andAP-architectures.
AsynchronousSummary
These levels are summarized in the following table, which shows the support for the desirable
active/activecharacteristics.
Archi- Fast Disaster Data Data Balance Balance Scalable Locality Split-
tecture Failover Tolerance Loss Collision Updates Reads (routetx Brain
Avoided Support anywhere) Avoided
AA+ Y Y N Y Y Y Y Y N
AA- Y Y N N Y Y Y Y N
AP+ Y Y N Y Y* Y Y* Y Y
AP- Y Y N N Y* Y Y* N Y
AT+ Y Y Y Y N Y N N Y**
AT- Y Y Y N N Y N N N***
*onlybyrepartitioningthedatabase.
**onlyiftransactionroutingisdonebytheclientornetwork,notbynodeforwarding.
***AT-isalwaysinsplit-brainmode
Asynchronous Active/ActiveCharacteristics
9
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Thearchitectureshavedifferentcharacteristics:
 AA-,AP-,andAT-cannotbeusedifdatacollisionsareaconcern.
 AA+,AA-,andAP+allowatransactiontoberoutedtoanynode.
 AP-requiresthattransactionsberoutedtoaspecificnode.Thismaycompromisethe
performanceadvantageoflocalprocessing.
 AT+andAT-requirethattransactionsberoutedtoallnodes.
 Alllevelssupportreadloadbalancing.
 AA+andAA-supportupdateloadbalancing.
 AP+andAP-requirethatthedatabaseberepartitionedtobalanceupdateload.
 AT+andAT-cannotbebalancedforupdateload.
 AA+andAA-databaseswilldivergeifreplicationislost(split-brainmode).
 AP+,AP-,andAT+preventsplit-braindatabasedivergence.
 AT-isalwaysinsplit-brainmode.
In general, an asynchronous replication engine can be categorized by the active/active
architecture that it supports (its level) and its inherent replication latency (exclusive of
communication latency). For instance, a particular replication engine might be a 100 millisecond
AP+asynchronousengine.
Note that active/active architecture AA+ has all of the characteristics of our definition of an ideal
active/active system except for the potential of data loss following a node failure. An AA-
architecturealsomeetsthistestifdatacollisionscannothappenorcanbeignored.
SynchronousActive/ActiveArchitectures
Synchronous active/active architectures follow a different path from asynchronous architectures.
Using today’s available technology, most synchronous active/active systems are entire systems
available from a system vendor. OpenVMS split-site clusters, IBM Parallel Sysplex, and Stratus
Avanceareexamplesofthese.8
This may change when coordinated commit synchronous replication engines become available.3
These engines use asynchronous replication to propagate updates and synchronize transactions
onlyatcommittime.
Synchronous active/active architectures generally meet all of the characteristics of our ideal
active/active architecture except for limits on geographical separation. Since a transaction or an
update must be completed on all copies of the database across the application network,
transaction response times are increased. Most vendors of synchronous replication systems limit
theirsupportofgeographicaldispersiontosomespecifieddistance.
Synchronous replication faces a unique problem should the nodes lose connectivity or if one
nodebecomessoslowthat itslows downalltransactions.Inthis case,thesystemmustswitchto
asynchronous replication so that transaction processing can continue. This leads to split-brain
mode,andifthisisnotacceptable,thedisconnectedormalfunctioningnodemustbeshutdown.
Recovery from a node failure is far more complex since the failed node’s database must be
resynchronizedwiththeactivedatabase.Duringthisprocess,thefailednodewillbeprocessinga
8OpenVMSActive/ActiveSplit-SiteClusters,AvailabilityDigest;June2008.
http://www.availabilitydigest.com/public_articles/0306/openvms.pdf
ParallelSysplex–FaultTolerancefromIBM,AvailabilityDigest;April2008.
http://www.availabilitydigest.com/public_articles/0304/ibm_sysplex.pdf
Stratus’AvanceBringsAvailabilitytotheEdge,AvailabilityDigest;February2009.
http://www.availabilitydigest.com/public_articles/0402/avance.pdf
10
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

mix of asynchronous and synchronous transactions as it transitions to a fully synchronous state.
Thistransitionmustbecarefullymanaged.
Eachsynchronous technique varies inhow itmaintains databasecopies in synchronism andhow
it resynchronizes following a node or network fault. However, the result is the same. The
active/active attribute is met in full except for the limits on disaster tolerance. There is no data
loss.Therearenodatacollisions.Failoverisfast,andsystem upgradescanberolledthroughthe
application network one node at a time to eliminate planned downtime. Read and update activity
can be uniformly distributed across the nodes (of course, every database copy must receive all
resultingchanges),andthesystemisscalablebyaddingnodes.
Therefore, a convenient means of classification of synchronous replication systems is simply to
state the distance limitation. For instance, a system may be a 20-kilometer synchronous
replicationsystem.
Summary
This categorization of active/active technologies should be considered a work-in-progress. To
those looking to implement active/active systems, a categorization that achieves substantial
consensus is important to be able to weed out vendor offerings (or in-house implementation
strategies)thatwillnotmeettheapplication’sneeds.
Please contribute to this important subject by sharing your comments with us on our LinkedIn
ContinuousAvailabilityForumat
http://www.linkedin.com/groupsDirectory?results=&sik=1260921605283&pplSearchOrigin=GLHD
&keywords=continuous+availability+forum.
If this link doesn’t work for you, search on Continuous Availability Forum under “Groups” in
LinkedIn.
11
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com
