becausethewindowofconfusionissmall(milliseconds,typically).
 Asynchronous replication does not quite meet the availability attribute because data
changesinthereplicationpipelinemaybelostuponthefailureofadatabaseserver.
 Synchronous replication may not meet the survivability attribute because it imposes
distance limitations. Since the application must wait for an operation or a transaction to
complete on all data-storage elements, the distance separating the elements of the
3AsynchronousReplicationEngines,AvailabilityDigest;November,2006.
4SynchronousReplication,AvailabilityDigest;December,2006.
6
©2008SombersAssociates,Inc.,andW.H.Highleyman

system is constrained due to performance considerations. A distance limitation may
affectthedisastertoleranceofthesystem.
An Active/Active Taxonomy
The above definitions lead to a three-level taxonomy. At one level is the system architecture. At
theotherlevelsarethereplicationmechanismandthereplicationscope.
For instance, an active/active system in which the database-server tier is virtualized and in which
operationsaresynchronouslyreplicatedisanAD/S/Osystem.
active/active
architecture
A AD AS ASD
replicationtype
A S
asynchronous synchronous
replicationscope
O T
operation transaction
Active/ActiveTaxonomy
Examples of Active/Active Systems
VirtualizedProcessingNodes(ConfigurationA)
Inmost of our Availability Digest articles, we have focused on active/active
systems that comprise two or more self-contained processing nodes that
all cooperate in a common application. A transaction can be routed to any
node. It will be processed by that node, and changes made to its
applicationdatabasecopywillbereplicatedtotheotherdatabasesintheapplicationnetwork.
7
©2008SombersAssociates,Inc.,andW.H.Highleyman

In this case, replication is done via independent replication engines that read source database
changes from a Change Queue and then send them to the remote target databases. Both
asynchronous and synchronous replication engines are in use and are available from several
vendors.
When asynchronous replication is used, replication is typically done at the transaction level.
Synchronous replication may be done either at the operation level or at the transaction level.
Synchronous replication at the operation level is often called dual writes or network transactions.
Each operation is replicated individually, and the application waits for each operation to finish
beforeitproceedstothenextoperation.
At the transaction level, operations are replicated
node1
asynchronously. It is only at commit time that the
commits are applied synchronously. Thus, the appl data
A base
application is delayed only by the time that it takes
active
for the transaction to be committed across the node3
network rather thanbeingdelayedbyeachindividual replicatiion data appl
operation. This technique is called coordinated network base A
commits. active
node2
Network transactions may be more efficient over
short distances and for small transactions. appl data
A base
Coordinated commits are more efficient for long
active
distancesaswellasforlargetransactions.
Thus, the architecture of virtualized processing
nodesmaybeclassifiedasA/A/O,A/A/T,A/S/O,and
A/S/T.
We have published many examples of such systems as Case Studies in the Availability Digest.
MostofthemuseHPNonStopserversforthenodesintheapplicationnetwork.5
OpenVMSClusters(ConfigurationAS)
HP’s OpenVMS Clusters are arguably the original active/active
system.6 Introduced in 1984 byDigital Equipment Corporation, an
OpenVMS Cluster supports up to 96 processing nodes and up to
500 data-storage shadow sets. A processing node is a stand-
alone server containing the application programs and a file server. A data-storage shadow set
comprises twoor moredisk systems (uptosix) and is virtualized to look likeasingle disk system
to the processing nodes. The processing nodes can be geographically distributed as can the
membersofashadowset.
The data-storage virtualization layer uses Host-Based Volume Shadowing (HBVS) to provide
distributed lock management and a distributed cache mechanism for virtualization of the
members of a shadow set. File-update operations are sent synchronously to all members of a
5BankVerlag–theActive/ActivePioneer,AvailabilityDigest;December,2006.
TelecomItalia’sActive/ActiveMobileServices,AvailabilityDigest;March,2007.
BANKSERVGoesActive/Active,AvailabilityDigest;April,2007.
HP’sOpenCallINSGoesActive/Active,AvailabilityDigest;June,2007.
MajorBankUsesActive/ActivetoAvoidHurricanes,AvailabilityDigest;October,2007.
AsymmetricActive/ActiveatBancodeCredito,AvailabilityDigest;November,2007.
PaymentAuthorization–AJourneyfromDRtoActive/Active,AvailabilityDigest;December,
2007.
Active/ActivePaymentProcessingatSwedbank,AvailabilityDigest;January,2008.
6OpenVMSActive/ActiveSplit-SiteClusters,AvailabilityDigest;June,2008.
8
©2008SombersAssociates,Inc.,andW.H.Highleyman

shadow set and are completed when all clients
shadow-set members have reported
completion. Reads are sent to the shadow-set
ggiiggaabbiitt
memberthatcanrespondthefastest.
eetthheerrnneett
cclluusstteerrnnooddee cclluusstteerrnnooddee
Therefore, an OpenVMS Cluster can be
classified as an AS/S/O active/active system.
aapppplliiccaattiioonn aapppplliiccaattiioonn
The active/active availability attribute is met
since the failure of any processing node means rreeaadd wwrriittee rreeaadd wwrriittee
that outstanding requests are resubmitted. The HHBBVVSSsshhaaddoowwsseettsseerrvviicceess HHBBVVSSsshhaaddoowwsseettsseerrvviicceess
failure of any shadow-set member simply
dduuaallffiibbrree
results in that member being removed from the cchhaannnneell dduuaallSSAANN
data-storagepool.
rreeaadd
wwrriittee wwrriittee wwrriittee
The system is survivable since processing OpenVMS
nodes and shadow-set members can be Cluster
geographically distributed. However,
SShhaaddoowwSSeettMMeemmbbeerrss
survivability is compromised by the
synchronous replication of updates. To avoid severe performance impacts on applications, the
distanceofseparationislimited.HPsupportsdistanceseparationsofupto500miles.
In write seldom, read often applications, an OpenVMS Cluster is scalable up its supported limits
of 96processing nodes and500shadowsets.It provides consistencyfor updates becauseof the
distributed locking mechanism. Read consistency is provided except for reads that reach the
shadow-set members within the confusion window when an update to the records to be read is
abouttobemade.
GRIDSCALE(ConfigurationAD)
GRIDSCALE, from xkoto,7 is a virtualized database. It does not
provide an application tier, but any virtualized application tier can
beused.
applications
Database requests are received from the application
tier by the GRIDSCALE database virtualization layer.
This virtualization layer is implemented as a stand-
active backup
alone server that assigns a sequence number to each GRIDSCALE GRIDSCALE
database operation. It then sends each operation to
the database servers making up the GRIDSCALE sequenced
system. The database servers are guaranteed to operations
execute each operation in exactly the same sequence local local
based on the sequence number assigned by the Connector Connector
GRIDSCALE server. This applies not only to updates, database database
server server
butalsotoreadoperationsandtransactionsemantics.
The database servers may be geographically
data data
distributedwithnodistancelimitation. base base
remote
GRIDSCALE’s replication algorithm is interesting
Connector
because it combines the best of both asynchronous
and synchronous replication. It responds to the database
server
application with a completion status as soon as it
receives the first successful completion response from
any of the database servers (Reads are only sent to data
base GRIDSCALE
7GRIDSCALE–AVirtualizedDistributedDatabase,AvailabilityDigest;July,2008.
9
©2008SombersAssociates,Inc.,andW.H.Highleyman

one database server – the one that will provide the fastest response.) Since at least one of the
database servers is bound to be local to the GRIDSCALE server, performance is equivalent to
that of a standalone transaction-processing system except for a small overhead imposed by the
GRIDSCALE server. Applications do not have to wait for update operations to complete on all
databaseserversinthepool.
However, replication is synchronous in that every database server is guaranteed to apply all
updatesinexactlythesamesequence.
The GRIDSCALE server is a single point of failure. It can be run in an active/standby
configuration with failover measured in seconds; but should the data center be taken down by a
disaster, the GRIDSCALE server is lost. However, in this case, operation can continue with a
remotedatabaseserveruntiltheGRIDSCALEconfigurationcanbereestablished.
A GRIDSCALE system may be characterized as an AD/S/T active/active system. GRIDSCALE
meetsalloftheactive/activeattributes.Itisavailablesincethelossofanydatabaseserversimply
means that the failed database server is evicted from the database server pool. It is survivable
because it can continue in the face of the loss of a data center. In a write seldom, read often
application,itisscalablebyaddingadditionaldatabaseservers.
Finally, it uses the one active/active configuration that guarantees consistency since the
sequence of execution of all reads and all writes is enforced. (GRIDSCALE does allow query
applications to berun oneachdatabaseserver independentlyof GRIDSCALE.Inthis case,there
isnoenforcementofconsistency.)
Why Contemporary Clusters Are Not Active/Active
An interesting exercise is to apply the Active/Active Attribute Definition to the currently popular
three-tierarchitecturecomprisingapresentationtier,anapplicationtier,andadatabasetier.
 The Presentation Tier manages data received from and sent to the clients of the system.
Perhaps the most widespread example of a presentation tier is that comprising web
servers.
 The Application Tier processes requests from clients received from the presentation tier
andreturnsresultstotheclientsthroughthepresentationtier.
 The Database Tier provides the application database needed by the application tier to
performitsprocessingfunctions.
databasecluster
virtualizedweb virtualizedapplication
serverpool serverpool active
database
server
clients web application data
servers servers base
backup
database
server
ContemporaryThree-TierArchitecture
Intypicalsystems today, thepresentationtier andthe application tier are virtualized.Thatis,they
comprise a pool of similar servers, any of which can provide the required processing. Should a
10
©2008SombersAssociates,Inc.,andW.H.Highleyman

server fail, it can be removed from the pool; and the rest of the pool will continue to carry the
system load with no interruption to the users. If more capacity is needed in a tier, additional
serverscanbeaddedtohelpcarrytheload.
However, the database tier is typically a single system – often a cluster. Although it may be
configured as an active/backup system with redundant data storage such as RAID, it is not
scalable without installing larger servers since only one server is active at a time. Furthermore,
failover is nottransparenttotheuser.Clusters typicallytakeminutes tofailover,andthatis onlyif
therehasbeennodatabasecorruptioncausedbythefailureoftheprimaryserver.
Consequently, this architecture does not qualify as an active/active system because of the
database tier. For one, cluster failover times preclude the possibility of achieving six 9s of
availability – typical cluster availabilities are a little less than five 9s. A cluster cannot easily be
geographically distributed for survivability. Furthermore, in order to increase the capacity of the
cluster, the database-server systems must be replaced with larger database-server systems,
necessarily requiring the downing of the cluster (clusters typically require homogeneity).
Consistencyisnotanissuesincethereisonlyoneactivedatabaseserver.
Inshort,clustersarenotactive/activeaccordingtoourdefinition.
Summary
Active/active systems are characterized by the attributes of availability, survivability, scalability,
and consistency. They eliminate planned downtime and have expected mean time between
failures that is measured in centuries. They can survive the failure of an entire data center. They
are scalable by simply adding compute resources with no impact to the users. They will
consistentlyexecuteoperationsinapredictablemanneracrosstheapplicationnetwork.
A common way to implement active/active systems is via context-free virtualized pools of
compute resources. Each pool is virtualized to appear as a single resource to external users. If a
memberofapoolfails,workthatithadinprogressissimplyresubmittedtoanothermember.
At least one of the resource pools must maintain application state, usually by managing the
applicationdatabase.Sincethedatabaseis avirtualizedpool,thismeansthattherewillbetwoor
more copies of the application database in the database pool. These databases must be kept in
synchronism. This is typically done by asynchronous or synchronous replication at the operation
ortransactionlevel.
There are many implementations of active/active systems in production today. Some are
complete products. Others are custom-developed systems using data-replication products. For
thoseapplicationsthatrequirecontinuousuptime,active/activesystemsareaprovenapproachto
meetthisneed.
11
©2008SombersAssociates,Inc.,andW.H.Highleyman

