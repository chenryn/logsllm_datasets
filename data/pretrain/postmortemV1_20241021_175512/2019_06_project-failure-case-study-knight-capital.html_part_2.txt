\
**3)** Securities Exchange Act Rule C.F.R 240.15c3--5 ("Rule") went into
effect, requiring the exchanges and broker-dealers to implement risk
management controls to ensure the integrity of their systems as well as
executive review and certification of the controls.\
\
Since the flash crash rules were designed for price swings, not trading
volume, they did not kick in as intended and stop trading because few of
the stocks traded by Knight on that fateful day exceeded the 10 percent
price change threshold.\
\
By 9:34 a.m., NYSE computer analysts noticed that market volumes were
double the normal level and traced the volume spike back to Knight.
Niederauer tried calling Joyce, but Joyce was still at home recovering
from knee surgery.\
\
The NYSE then alerted Knight's chief information officer, who gathered
the firm's top IT people; most trading shops would have flipped a kill
switch in their algorithms or would have simply shut down systems.
However, Knight had no documented procedures for incident response,
again, another fact we shall return to later. So, it continued to fumble
in the dark for another 20 minutes, deciding next that the problem was
the new code.\
\
Because the "old" version allegedly worked, Knight reverted back to the
old code still running on the eighth server and reinstalled it on the
others. As it turned out, this was the worst possible decision because
all eight servers now had the defective Power Peg code activated by the
misappropriated RLP flag and executing without a throttle.\
\
It was not until 9:58 a.m. that Knight engineers identified the root
cause and shut down SMARS on all the servers; however, the damage had
been done. Knight had executed over 4 million trades in 154 stocks
totaling more than 397 million shares; it assumed a net long position in
80 stocks of approximately \$3.5 billion as well as a net short position
in 74 stocks of approximately \$3.15 billion.\

## How Knight Capital Could Have Done Things Differently

This case study contains several lessons useful for project managers, IT
professionals, and business leaders. Knight could have prevented the
failure and minimized the damage with a variety of modern [software
development and operating
practices](https://www.henricodolfing.com/2018/05/review-software-development-practices.html)
(DevOps). Below, I describe eight of these measures and how they could
have made a difference for Knight Capital.\
\
**Use of Version Control**\
\
Do not run dead code. Instead, always prune dead code and use version
control systems to track the changes. You should not re-purpose
configuration flags; rather, activate new features with new flags.\
\
Version control is any kind of practice that tracks and provides control
over changes to source code. Teams can use version control software to
maintain documentation and configuration files as well as source code.\
\
As teams design, develop, and deploy software, it is common for multiple
versions of the same software to be deployed in different sites and for
the software\'s developers to be working simultaneously on updates. Bugs
or features of the software are often only present in certain versions
(because of the fixing of some problems and the introduction of others
as the program develops).\
\
Therefore, for the purposes of locating and fixing bugs, it is vitally
important to be able to retrieve and run different versions of the
software to determine in which version(s) the problem occurs. It may
also be necessary to develop two versions of the software concurrently:
for instance, where one version has bugs fixed, but no new features
(branch), while the other version is where new features are worked on
(trunk).\
\
**Writing Unit Tests**\
\
The purpose of [unit
testing](https://www.henricodolfing.com/2017/08/14-essential-software-engineering.html)
is not for finding bugs. It is a specification for the expected behavior
of the code under test. The code under test is the implementation for
those expected behaviors. So unit tests and the code under test are used
to check the correctness of each other and protect each other. Later,
when someone changes the code under test, and it changes the behavior
that is expected by the original author, the test will fail. If your
code is covered by a reasonable amount of unit tests, you can maintain
the code without breaking the existing feature. That's why Michael
Feathers defines legacy code in his seminal book \"Working Effectively
with Legacy Code\" as code without unit tests. Without unit tests your
development efforts will be a major risk every time you change your
legacy code.\
\
**Code Reviews**\
\
Code review is a systematic examination (sometimes referred to as peer
review) of source code. It is intended to find mistakes overlooked in
software development, improving the overall quality of software. Reviews
are done in various forms such as pair programming, informal
walkthroughs, and formal inspections.\
\
**Automated Tests and Test Automation**\
\
In the world of testing in general, and continuous integration and
delivery in particular, there are two types of automation:\
\
**1)** Automated Tests\
**2)** Test Automation\
\
While it might just seem like two different ways to say the same thing,
these terms actually have very different meanings.\
\
[Automated
tests](https://www.henricodolfing.com/2018/03/test-automation-and-automated-tests.html)
are tests that can be run automatically, often developed in a
programming language. In this case, we talk about the individual test
cases, either unit-tests, integration/service, performance tests,
end-2-end tests, or acceptance tests. The latter is also known as
specification by example.\
\
[Test
automation](https://www.henricodolfing.com/2018/03/test-automation-and-automated-tests.html)
is a broader concept and includes automated tests. From my perspective,
it should be about the full automation of test cycles, from check-in up
to deployment -- also called continuous testing. Both automated testing
and test automation are important to continuous delivery, but it\'s
really the latter that makes continuous delivery of a high quality even
possible.\
\
Had Knight implemented automated tests and test automation for the new
and existing SMARS functionalities they would have caught the error
before deploying it in production.\
\
**Automated Deployment Process**\
\
It is not enough to [build great
software](https://www.henricodolfing.com/2017/03/building-is-easy-part.html)
and test it; you also have to ensure it is delivered to market correctly
so that your customers get the value you are delivering (and so you
don't bankrupt your company). The engineer(s) who deployed SMARS are not
solely to blame here -- the process Knight had set up was not
appropriate for the risk they were exposed to. Additionally, their
process (or lack thereof) was inherently prone to error. Any time your
deployment process relies on humans reading and following instructions
you are exposing yourself to risk. Humans make mistakes. The mistakes
could be in the instructions, in the interpretation of the instructions,
or in the execution of the instructions.\
\
Deployments need to be automated and repeatable and as free from
potential human error as possible. Had Knight implemented an automated
deployment system -- complete with configuration, deployment, and test
automation -- the error that caused the nightmare would have been
avoided.\
\
**Step-by-Step Deployment Process Guide **\
\
Anybody (even somebody who is usually not doing this) should be able to
deploy on production with this guide on the table. Of course, the more
you go into the direction of automated deployment, the smaller this
guide becomes, because all documentation of this process is coded in
your automated processes. The probability of doing something wrong with
a step-by-step guide (or a checklist) is a multitude smaller as without.
This has been proven many times in the medical space.\
\
**Timeline**\
\
The
[timeline](https://www.henricodolfing.com/2019/06/start-projects-slow-run-fast-later.html)
was another reason Knight failed to deliver the RLP solution. Knight's
IT project managers and CIO should have pushed back on the
hyper-aggressive delivery schedule and countered its business leaders
with an alternative phased schedule instead of the Big Bang -- pun
intended. Thirty days to implement, test, and deploy major changes to an
algorithmic trading system that is used to make markets daily worth
billions of dollars is impulsive, naive, and reckless.\
\
**Risk Management**\
\
[Risk
management](https://www.henricodolfing.com/2018/08/risk-management-is-project-management.html)
is a vital capability for a modern organization, especially for
financial services companies. The SEC's report (see References)
concluded: "Although automated technology brings benefits to investors,
including increased execution speed and some decreased costs, automated
trading also amplifies certain risks. As market participants
increasingly rely on computers to make order routing and execution
decisions, it is essential that compliance and risk management functions
at brokers or dealers keep pace... Good technology risk management
practices include quality assurance, continuous improvement, controlled
user acceptance testing, process measuring, management and control,
regular and rigorous review for compliance with applicable rules and
regulations, an independent audit process, technology governance that
prevents software malfunctions, system errors and failures, service
outages, and when such issues arise, a prompt, effective, and
risk-mitigating response."\
\
While Knight had order controls in other systems, it did not compare
orders exiting SMARS with those that entered it. Knight's primary risk
monitoring tool, known as "PMON," is a post-execution position
monitoring system. At the opening of the market, senior Knight personnel
observed a large volume of positions in a special account called 33 that
temporarily held multiple types of positions, including positions
resulting from executions that Knight received back from markets that
its systems could not match to the unfilled quantity of a parent order.
There was a \$2 million gross limit to the 33 account, but it was not
linked to any automated controls concerning Knight's overall financial
exposure.\
\
Furthermore, PMON relied entirely on human monitoring, did not generate
automated alerts, and did not highlight the display of account exposures
based on whether a limit had been exceeded. Moreover, Knight also had no
circuit breakers, which is a standard pattern and practice for financial
services companies.\

## **Closing Thoughts**

Although Knight was one of the most experienced companies in automated
trading at the time (and the software that goes with it), it failed to
implement many of the standard DevOps best practices that could have
prevented this disaster at any number of intervals.\
\
Knight Capital Group Holdings was eventually acquired by another market
making rival, Virtu LLC, in July 2017 for \$1.4 billion. The silver
lining to the story was that Knight was not too big to fail, and the
market handled the failure with a relatively organized rescue without
the help of taxpayers. However, a dark cloud remains: market data
suggests that 70 percent of U.S. equity trading is now executed by
high-frequency trading firms, and one can only wonder when, not if, the
next flash crash will occur.\


