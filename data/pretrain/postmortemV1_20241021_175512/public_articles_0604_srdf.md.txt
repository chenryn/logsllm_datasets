EMC’s SRDF Data-Replication Engine
April2011
Logical Replication versus Hardware Replication
In most of our reviews of data-replication engines, we have primary backup
focused on server-based logical replicators.1 These server server
replicators provide a consistent copy of a source database query
application
on a remote target database. Logical replicators depend report
upon a queue of changes maintained by the database backup
cache
manager or application. They follow the changes and change replication
replicatethemtothetargetdatabase. queue cache
The target database can therefore be used for query and
reporting purposes, and it can participate in active/active source target
application networks if bidirectional replication is provided. data data
base base
The target database is also available to be brought online
rapidly to provide high availability in the event of a source- Server-BasedLogicalReplication
system failure. Failover in an active/backup architecture can
beachievedinminutes.
Server-based replication requires the use of host-system resources. Though this usage is often
minimal, it is eliminated if a storage array is used and if data replication is performed by the
storage array itself.2 Many storage-array replicators replicate
disk blocks as they are physically written to the source
storage array. Therefore, the target storage array always
reflectsthecontentsofthesourcearray.
However,thecontentsofthestoragearraydonotrepresenta
consistent view of the database since much of the current
content of the database is maintained in cache and is not
written to the storage array until cache space is needed. In
effect, the contents of the target storage array represent a
corrupted view of the source database. If the source system
fails, there is a great deal of work required to bring the target
database into a consistent state, often over an extended
period of time typically measured in hours. Therefore, these
storagearrayreplicatorsprovidedisasterrecovery;buttheydonotprovidehighavailability.
1AsynchronousReplicationEngines,AvailabilityDigest;November2006.
SynchronousReplication,AvailabilityDigest;December2006.
2HardwareReplication,AvailabilityDigest;January2007.
1
©2011SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Anexceptiontothis is providedbystoragearrays that provide primary backup
cache storage as well as disk storage. These storage arrays server server
replicate disk blocks from cache as they are changed.
Therefore, the target storage array always represents a
query
consistent copy of the source database. The backup system
application report
can be used for functions such as queries, reports, and backup
backups. Furthermore, if the source system fails, recovery is
rapid, often measured in minutes. High availability is
achieved.
replication
cache cache
Such a replication engine is EMC’s Symmetrix Remote Data
Facility (SRDF), which we review in this article
(www.emc.com).
disk disk
array array
Symmetrix Remote Data Facility (SRDF)
source target
storage storage
SymmetrixStorageArrays array array
Storage-ArrayLogicalReplication
SRDF replicates data stored in Symmetrix DMX-4 storage
arrays. They scale to massive amounts of storage and are architected to provide high
performanceunderlargeworkloads.
ADMX-4arraycancontainabout2,000disks organizedas RAID
0 (no redundancy), RAID 1 (mirrored), RAID 10, RAID 5, or RAID
6. Disk capacities range from 146 gigabytes to one terabyte. A
fully configured array can provide over 500 terabytes of mirrored
orRAIDstorage.
Flash drives are supported by DMX-4. They increase performance by a factor of ten and reduce
powerconsumptionby98%.
ADMX-4canbeconfiguredwithupto256gigabytes ofmirroredglobalmemory, whichis usedin
large part for cache memory. To achieve maximum performance, DMX-4’s Direct Matrix
Architecture provides up to 128 one gigabit/second directlyconnected data paths between global
memoryanditsI/Odirectors.
For host connectivityand remote replication communication, a Symmetrix DMX-4 can support up
to 64 host ports and eight remote 4-Gb/s Fibre Channel or ESCON ports. Alternatively, it can
supportupto48host1-Gb/siSCSIor4-Gb/sFICONportsand/oruptoeight1-Gb/sGigEremote
ports.
The Symmetrix storage array is designed to provide totally nondisruptive operations. Hardware
and software can be maintained and upgraded, and storage configurations can be changed with
noapplicationdowntime.
Symmetrix DMX-4 arrays support mainframes and Windows, Linux, UNIX, and AIX platforms.
Over70,000installationshavebeenmadearoundtheworld.
DataReplicationOptions
Introduced by EMC in 1994, SRDF provides several data
replication options for DMX-4 storage arrays - both
asynchronous (SRDF/A) and synchronous (SRDF/S). In
SRDF terms, the production storage array is known as R1;
andthebackupstoragearrayisknownasR2.
2
©2011SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

SRDFmustalwaysbeconfiguredwithredundantchannelsbetweenR1andR2sothatreplication
isnotlostonalinkfailure.
SRDF/A
Using SRDF’s asynchronous-replicationmode(SRDF/A),data is replicated with noimpacton the
applications. As applications make changes to their databases, the changes complete
immediatelyonR1andarequeuedforreplicationtothetargetstoragearray,R2.
The replication queue in the source array, R1, is a set of pointers to data blocks that have
changed(SRDF has noknowledge of thestructureof thedata beyonddata blocks,suchas table
rows or fields). Replication is scheduled periodically according to configuration parameters. The
set of changes that accumulate in a replication interval is known as a delta set. Replication
intervalscanbeasshortassecondsbutaretypicallymeasuredinminutes.
When it comes time to replicate a data set, SRDF uses the pointers in the replication queue to
accessthechangeddisk blocksandtotransmitthem toR2’scache.Ifadisk block isnolongerin
thecacheofthesourcestoragearray,itisreadfromdisk.
Note that a queue of changes is not maintained in the delta set in the R1 queue. Rather, the
pointers pointonlytothelatestvalueof adisk block inR1.Ifmultiplechanges aremadetoadisk
block inareplicationinterval,onlythelatestchangeis sent;andSRDF sends thatdisk block only
once even though it may appear several times in the queue. This means that during the
replication process, R2 may not hold a consistent copy of the database. However, once the delta
sethasbeenreplicated,R2’sdatabasewillbeconsistent.
If a fault occurs during the transmission of a delta set, R2 will discard the entire delta set, thus
maintainingtheconsistencyofthetargetdatabase.
If replication falls behind, SRDF/A has the capability to throttle host I/O so that replication can
catchup.
SRDF/A can replicate over any distance, up to halfway around the world, typically over IP
channels.
SRDF/S
SRDF/S, SRDF’s synchronous-replication mode, ensures that each change has been stored in
the target storage array’s cache before the change is allowed to complete on the source storage
array.ThismeansthattheapplicationisdelayedasSRDFawaitsacompletionacknowledgement
from R2. However, it also means that R2’s database is always a consistent copy in exact time
synchronizationwithR1’sdatabase.
Because of the impact on application performance caused by synchronous-replication delay,
SRDF/S can only be used over limited campus or metropolitan distances using optical fiber
channels. The source and target systems can be three kilometers apart using a direct fiber
connection. Theycan be separated by 66 kilometers by using repeaters and converters in 20 km
segments.
SRDF/S supports an optional semisynchronous-replication mode. In this mode, a change
completes immediately on R1 and does not wait for replication to complete. However, the next
change is not accepted by R1 until the previous change is acknowledged by R2. This allows an
application to proceed with its processing chores, including the reading of data from disk. The
application is delayed only if it attempts to make a change before the previous change has been
3
©2011SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

successfully replicated. Semisynchronous replication eases the application performance penalty
imposedbypuresynchronousreplication,thoughitdoesnoteliminateit.
SRDF/Star
Both SRDF/A and SRDF/S have their limitations. With SRDF/A, there is a delay from when a
change is madetothesourcedatabaseand whenitappears inthetargetdatabase.This delayis
known as replication latency. Should the source node fail, any changes that have not been
replicated are lost. Thus, a Recovery Point Objective (RPO) of zero cannot be achieved. In fact,
the RPO will be no better than the configured replication interval for replication delta sets. Since
thisintervalistypicallymeasuredinminutes,RPOswillbeintheorderofminutes.
SRDF/S solves this problem. Since the replication of changes is synchronous, no data is lost if
the source system fails. However, the distance limitation between the source and target nodes
maynotallowthesenodes tobeseparatedfar enough tosatisfydisaster-tolerancerequirements.
A 50-kilometer distance may protect against a building fire, but it maynot protect against a major
earthquakeorflood.Aseparationofhundredsofmilesormoremayberequired.
SRDF/Star is a configuration that overcomes these problems to a great extent. With SRDF/Star,
there are three nodes - a production node, R1, and two target nodes. The production node
replicates its database to both target nodes. One target node. R2 , is nearby and is kept
s
synchronizedwithSRDF/Ssynchronousreplication.Itsdatabaseisthereforeanexactcopyofthe
production database. The other target node, R2 , can be hundreds or thousands of miles away
a
and is synchronized by SRDF/A asynchronous replication. It therefore will survive any disaster
that affects the production system.3 The synchronous local backup system, R2 , is often referred
s
toas adatabunkerbecauseitsafe-storesalldataon behalfoftheasynchronousremotebackup,
R2 ,whichwilllosedatafollowingaproduction-systemfailure.
a
There are several disaster recovery scenarios with SRDF/Star. If the production node, R1, goes
down, operations canbemovedtothenearbysynchronously-replicatedR2 node.Asynchronous
s
replication is initiated from this node to the remote node, R2 ; and full production resumes with a
a
completely current database and a disaster-recovery site. Alternatively, the database at R2 can
a
be brought up-to-date by replicating missing changes to it from R2 . Asynchronous replication
s
can then be established from R2 to R2 , and operations can be resumed at R2 with R2 acting
a s a s
as its disaster-recoverysite. In either case, full operation is resumed with no data loss and with a
functioningdisaster-recoverysite.
3 For case studies of SRDF/Star in use, see Banks Use Synchronous Replication for Zero RPO, Availability Digest;
February2010.
4
©2011SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

If R2 should fail, disaster recovery is still provided by R2 , though some data may be lost if the
s a
production node should subsequently fail. If R2 should fail, the system is subject to the
a
possibility of a common disaster taking out both R1 and R2 . Of course, the probability of a dual-
s
nodefailureoracommondisasterfollowingaremote-nodefailureisextremelysmall.
Recovery
SRDF provides automatic recovery from a node failure. If the production node, R1, fails, R2 is
automatically promoted to R1 and production continues on backup servers located at the backup
site. Alternatively, if synchronous replication over Fibre Channel is being used, the servers at the
production site, if still operable, can continue processing with the new R1 storage array at the
backup site. In any event, starting processing at the R2 site is no different than restarting R1
followingapowerfailure.
Fallback to the production site once the failed node is restored is also automatic under manual
command. The backup site is quiesced to let all in-progress database activity complete. The
production site’s storage array is then synchronized with the backup site’s storage array. The
production site is brought up as R1, and the backup site’s storage array is reverted to R2. The
replicationchannelisactivated,andproductioncannowcontinueattheproductionsite.
It is not necessary to have full synchronization before starting the applications on the system
being synchronized. This is because SRDF knows where valid data resides. As the application
proceeds, SRDF will preemptively move data from the current R1 system to the system being
synchronized if the application requests that data before it has been moved by the
resynchronizationprocess.
SystemSplitting
The redundant storage-array configuration can be split so that the backup site can be used for
other purposes. To do this, processing at R1 is quiesced; and in-progress activity is allowed to
complete.Followingthenextreplicationcycle,R2isnowcompletelysynchronizedwithR1.Atthis
point, replication is terminated; and R2 can be used for other purposes such as fielding large
queries, generating reports, or backing up the database. Since the R2 database is consistent, it
cansupportwriteactivityaswell.However,anychangesmadetoR2’sdatabasewillbelostwhen
R2isresynchronizedwithR1.
When R2 processing has been completed, it is returned to service as the backup for R1. R1
processingisquiesced,R2issynchronizedwithR1,replicationisinitiated,andnormalproduction
isrestored.
EliminatingPlannedDowntime
System splitting can also be used to eliminate planned downtime for system maintenance such
as hardware or software upgrades and configuration changes. Either system can be upgraded
first. For instance, R2 can be taken offline and upgraded. After it has been thoroughly tested, it
canbesynchronizedwithR1.
A failover to R2 can now be made, promoting it to R1 to continue processing. The production
system can be upgraded and then resynchronized with the backup system. At this point,
productionprocessingcanbetransferredbacktotheproductionsystem.
In an SRDF/Star configuration, when the local synchronous node, R2 , is promoted to R1 so that
s
the production node can be upgraded, R2 must establish a temporary R1-R2 relationship with
s
theremoteasynchronousnode,R2 ,tocontinuedisasterprotection.
a
5
©2011SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

OtherConfigurations
SRDFsupportsmanyotherconfigurations:
 Volumes in the storage array can be individually configured to use either SRDF/A or
SRDF/S.
 A source system can feed many target systems, thus making data available to other
applications such as data warehouses. Database volumes can be selectively replicated
overspecificcommunicationchannelstotargetedremotesystems.
 Many source systems can feed a single target. In this way, a single target system can
backupmultiplesourcesystems.
 Bidirectionalreplication is supported. A nodemaybe anR2 node to provide backupfor a
set of remote applications, and it can be an R1 node serving its own applications and
replicatingtoaremotenodeforbackup.
 SRDF Consistency Groups (SRDF/CG) ensure consistency of data spread across
multiple storage arrays. When SRDF/CG detects any write to a volume that cannot
communicate with its remote mirror, it suspends the remote mirroring for all volumes
definedintheconsistencygroup.
 Cascaded SRDF allows a storage array to be both a synchronous R2 and an
asynchronousR1replicatingtoaremoteR2site.
 Dynamic SRDF allows a storage array to be configured either as an R1 node or an R2
node.ThiscapabilityisrequiredforSRDF/Star.
 SRDF/Data Mobility (SRDF/DM) provides for the resynchronization of a storage array
before returning it to service. It also provides periodic transfer of data for data
warehousingorinformationsharingfordecisionsupport.
 SRDF FarPoint allows I/O from multiple logical volumes to be serially transmitted on a
singleSRDFreplicationlink.ThisenablestheSRDFlinktobemorefullyutilized.
 Source/target switching allows the R1 and R2 roles to be reversed, facilitating simple
disaster-recoverytesting.
System Management
The Symmetrix Management Console is a browser-based, intuitive user interface for the
configuration andmanagementof Symmetrix systems.Itis used for the operationandmonitoring
of SRDF remote mirroring operations. It supports simple storage allocation and administers both
opensystemandmainframe-attachedSymmetrixsystems.
The Management Console provides health indicators, cycle time, and throughput of the SRDF
facilityatuser-specifiedpollingintervals.Itfeaturesmultiplelevelsofthresholdalerting.
The Symmetrix Performance Analyzer provides enhanced monitoring of Symmetrix operations
usingreal-timedashboardsandheatmaps.
6
©2011SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Summary
EMC’s SRDF storage array replication facility provides consistent target database copies kept
current with either asynchronous or synchronous replication. SRDF is used with EMC’s DMX-4
massively scalable storage arrays and supports mainframes, AIX systems, and Windows, Linux,
andUNIXopensystems.
A variety of configurations are supported. Of particular use is SRDF/Star, which provides
synchronous replication to a nearby data bunker and asynchronous replication to a remote
disaster-recoverysite.
7
©2011SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com