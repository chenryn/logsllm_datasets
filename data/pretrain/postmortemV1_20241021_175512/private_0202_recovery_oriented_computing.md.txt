Recovery-Oriented Computing
February2007
System users are generally more affected by system recovery time than they are by system
failure rate. In particular, if recovery times are short enough, users may not even be aware that
thesystemhassufferedafailure.
Amajor efforttoreducerecoverytimeis theRecovery-OrientedComputing(ROC) project,ajoint
effort between researchers at UC Berkeley and Stanford University in California. This article
summarizes their published work todate.Ineffect,the philosophyof this projectcanbestated as
follows:inordertoachieveROC-solidcomputing,letitfailbutfixitfast.
MTR versus MTBF
When we speak of availability, we usually measure it in terms of the percentage of time that
system services are satisfactorily available to each user. This form of availability is calculated
fromthewell-knownrelation
MTBF
A 
MTBFMTR
whereAisthesystemavailability,MTBFisthesystemmeantimebetweenfailures,andMTRis
thesystemmeantimetorecover.
However, system availability is not always the user’s perception of availability (where the user
might be man or machine). For one thing, the user is unaware of unavailable periods when he is
not requesting service. For another, periods of unavailability too brief to affect him go unnoticed
and are not perceived as periods of unavailability. If he is expecting two-second response times,
his perceptionof asystem whichfails ten times per workingdaywitha one secondrecoverytime
is that it is more available than one which fails once a week with a one minute recovery time,
thoughbothhaveaboutthesamecalculatedavailability.
According to the above relationship, increasing MTBF has the same impact on availability as
reducingMTR.Forinstance,increasingMTBFbyafactorof10(10*MTBF)hasthesameimpact
onavailabilityasreducingMTRbyafactorof10(MTR/10).Thatis,
10*MTBF MTBF

10*MTBFMTR MTBFMTR/10
However, from the user’s viewpoint, a decrease in recovery time (decreased MTR) may have a
much more favorable impact on his view of system availability than an increase in the system
MTBF.
1
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

To be fair, this argument is true to a point. As MTR is decreased, there comes a point at which
further decreases in MTR, though resulting in increased system availability, do not improve the
user’s perception of availability as he is no longer aware of system faults. Studies have shown
that this point is approximately where the system MTR is about equal to the user’s retry time.1
Beyondthispoint,moneyisbetterspentonimprovingMTBFratherthanonimprovingMTR.
The Emergence of Hybrid Systems
A decade ago, high availability was brought to the marketplace by large mainframe and fault-
tolerant systems. These systems provided extremely reliable hardware with extensive error
checking facilities and mature operating systems. Software applications running on these
systems were carefully designed and thoroughly tested. Operations staff were highly skilled and
trained professionals. The fault-tolerant systems provided redundancy to protect them against
anysingle point of failure. Availabilityon the order of three to four nines was commonlyprovided,
includingallsourcesoffailure–hardware,software,network,operator,andenvironment.
Then the Internet explosion happened. The economics of the often massive systems required to
provide Internet services seemed to argue for large configurations, often measuring in the
thousandsofservers,ofrelativelyinexpensivehardware.
However, experience has now shown a serious Achilles heel in these systems – availability.
Availabilityintheseconfigurationsiscompromisedbyseveralfactors:2
 The use of commodity hardware with availabilities hovering around 99.5% (rather than
99.99%)resultinfrequenthardwareoutages.
 The systems are highly heterogeneous, being acquired from several different vendors.
Interfaces may sometimes not be fully functional, and system monitoring tools are often
inadequatetolocatethesourceoffaultsintheseconfigurations.
 The applications are characterized by rapid innovation. The required functionality can
changeveryquickly,oftenonaweeklybasis.
 Applications must change so quickly to meet these rapidly shifting requirements that the
use of traditional highly-reliable software design techniques is ignored. The classic six-
monthdevelopment,three-monthtestcyclehastobecompressedintooneweek.
 Systems are so complex that it is often difficult to locate the source of a failure. Is it a
server,arouter,anapplication,orothercomponentofthislargenetwork?
 Often,thousandsofsystemconfigurationparametersmustbemanaged.
 System complexity often leads to operator error. Operators must install software
upgrades, expand hardware resources, locate and recover from faults, back up data,
tune the system for performance, among many other duties. Surveys have shown that
over50%offaultsintheselargeheterogeneoussystemsarecausedbyoperatorerror.
1
Y.J.Song,W.Tobagus,J.Raymakers,A.Fox,IsMTTRMoreImportantThanMTTFforImprovingUser-Perceived
Availability?,ComputerScienceDepartment,StanfordUniversity;undated.
Availableathttp://72.14.209.104/search?q=cache:-gavKenNA_8J:www.cs.cornell.edu/~yeejiun.
2
SeetheDecember,2006,AvailabilityDigestarticleentitled,Can10,000ChickensReplaceYourTractor?
2
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

Every one of these factors can contribute to system failures. A recent survey of large Internet
sites showed that 65% of them had suffered a major outage in the prior six months, with 25% of
thesitesexperiencingthreeormorefailuresinthattimeperiod.
A further consequence of the complexity of these systems is the effect on the total cost of
ownership (TCO) of the systems. Surveys have shown that the TCO of typical large
heterogeneous systems can be anywhere from three to eighteen times the original cost of the
system. One-third to one-half of ongoing costs are related to identifying and recovering from
system faults. Clearly, the initial motivation for cost reduction by going to commodity systems
must,inhindsight,bequestioned.
Recovery-Oriented Computing
ShimonPeres,former PrimeMinister of Israel, is quotedas saying, “If aproblem has no solution,
itmaynotbeaproblem,butafact-nottobesolved,buttobecopedwithovertime.”
Thisappearstobethesituationwithlargehybridsystems.Wehavetoaddressthefactthatthese
systems will fail with an uncomfortable frequency and learn to quickly detect and recover from
faults.SuchisthegoaloftheRecovery-OrientedComputingProject.
TheROCproject(http://roc.cs.berkeley.edu/) isajoint effortbetweenresearchers atUC Berkeley
and Stanford University in California. It embraces the Peres rule with the philosophy of “let it fail,
but fix it fast.” If a fault can be recovered before the user is aware that a fault has occurred, then
isitafault?
Applying Peres’ rule, there is not much that we can do about hardware reliability – that is for the
manufacturers to do. We simply must learn to cope with what we have. Therefore, ROC focuses
onrecoveringquicklyfromsoftwarefaultsandoperatorerrors.
Amongotherfactors,ROC’srecovery-orientedframeworkincludesthefollowing:3
 Containafaultinacomponentsothatitdoesnotaffectothercomponents.
 Quicklyandautomaticallylocatetherootcauseofthefault.
 Exposeandrepairlatentfaultsbeforetheybecomeactivated.
 Repairthefaultatthesmallestsubcomponentleveltominimizerepairtime.
 Maintainusersessionsduringfaultrecovery.
 Tolerateerrorsduringtherecoveryprocess.
 Providebetteroperatorsupportforoperatorerrorrecovery.
 Beabletoinjectfaultsfortestingandtraining.
All of these techniques are cornerstones of modern-day reliable computing. ROC simply takes
them to a finer-grained level to attempt to recover from a fault more quickly by recovering at the
lowestlevelintheprocessingchain.
3
Thisarticleisbasedonseveralpublications,primarilybytheROCproject,including:
A. Brown, D. Patterson, Embracing Failure: A Case for Recovery-Oriented Computing, University of California at
Berkeley;undated.
A.Fox,D.Patterson,Self-RepairingComputers,ScientificAmerican;June,2003.
A.Fox,D.Patterson,ApproachestoRecovery-OrientedComputing,IEEEDistributedSystemsOnline;March/April2005.
A.Fox,TowardRecovery-OrientedComputing,Proceedingsofthe28thVLDBConference;2002.
Recovery-OrientedComputing,Wikipedia.
D. Patterson, et al., Recovery-Oriented Computing: Motivation, Definition, Techniques, and Case Studies, consolidated
effortsofseveraluniversities;undated.
3
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

FaultContainment
Fault containment is accomplished by partitioning. Every component should be defensive and be
able to control the effect of any outside influence. This typically means that components should
belooselycoupledandshouldcommunicatebymessaging.
At the macro level, this is certainly accomplished by the hardware components which pass
information from one to another via messages. One would not expect that a hardware failure in
onesystemwouldaffectanothersystem.
Similarly, in today’s modern operating systems, processes typically communicate via a
messaging facility. Applications should not be designed to use shared memory or to allow one
processtocalldirectlytheproceduresofanotherprocessortomodifyitsstate.
At the micro level, object-oriented languages allow an application to be implemented as a set of
objects intercommunicating via messages. No object can directly modify the state or private data
set of another object. This characteristic is put to good use by ROC, as discussed below with
respecttomicrorebooting.
Root-CauseLocation
The root cause of a failure is that fault which, if it had been corrected prior to the failure, would
have prevented the failure from happening. Root causes should ideally be determined
automatically so that the corresponding failure can be rapidly corrected. The ROC project has
prototypedthiscapabilityinafacilitytheycallPinPoint.
PinPoint attempts to determine a fault location by tracing which software components are
involvedin processing eachtypeof request.Whenarequestfails –for instance,theuser gets an
error message – PinPoint notes this fact. Over time, PinPoint analyzes the mix of components
that were activated in both failed and successful requests. Using this data, it can determine the
mostlikelycomponentsthataresuspectedofcausingmostofthefailures.
PinPoint can be useful to expose latent faults before they become hard faults. If a component is
suspected of being party to several failed requests that subsequently succeeded on retry, then
thatcomponentcanberepaired.
Measurements showed that PinPoint imposed about a 10% load in the system. This is an
exampleofacompromisebetweenavailabilityandperformance.
FastRecovery
ROC implements fast recovery via a technique known as microrebooting. Most software failures
canbecorrected(atleasttemporarily)byrebooting.Rebootingstartsthesoftwareoffwithaclean
slate. Errors in state, exhaustion of resources (like leased memory), and other problems are
corrected. The problem with rebooting a system is that it can take a long time – often minutes or
evenhoursifdatahastoberecovered.
The technique that ROC is studying is to try to recover at the lowest and fastest possible level.
This is known as a microreboot. Microrebooting is described more extensively in our next article,
tobepublishedintheMarchissueoftheAvailabilityDigest;butabriefdiscussionfollows.
The ROC project has used the JBoss application server as a platform with which to experiment.
JBosssupportsapplicationsimplementedasobjectscalledJavaBeans(EJBs).TheJavaBeanis
takentobethesmallestrebootablecomponent.
4
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

Using the results of PinPoint, the recovery system can determine a likely EJB culprit when a
failure occurs. The first attempt at recovery is to reboot the suspected Java Bean and all of the
Java Beans thataresubservienttoit.This rebootis veryfastand generallywill preservethe user
session4(itwillbeaccomplishedtypicallyin500milliseconds,muchlessthantheuserretrytime).
Itis alsofastenoughso as tobe successfullyretryablebyother JavaBeans attemptingtoinvoke
the Java Bean being rebooted. As a consequence, no errors are generated because of the
recoverysequence.
If the Java Bean microreboot doesn’t work, the application is rebooted. Rebooting is continued at
ever higher levels, from the JVM to JBoss to the operating system, until recovery has been
successful.Ifrebootingfails,theoperatorisnotifiedtotakecorrectivemanualaction.
In tests run by the ROC project, user-observed request errors were reduced by 98% when
microrebootingwasused.Clearly,thistechniquehaspromise.
OperatorSupport
The operators of these large heterogeneous systems are burdened by the sheer number of
different systems that they must administer. Every vendor has a different interface to learn.
Thousands of configuration parameters may have to be maintained. Recovery decisions can be
quite complex. Often, operator action is taken as an educated guess because no clear path to
recoveryexists;andtheseactionsmaybewrong,withunintendedconsequences.
There are major efforts to automate many operator functions. Interestingly, automation may
increase the rate of operator errors when the operators do need to become involved. This is
because the simple tasks have been taken away from them along with the practice these tasks
bringatmanagingthesystem.
Theobvious solutionproposedbyROC is to have an operator “undo” function.Think of having to
use a word processor without an undo function. In the early days of word processing, the lack of
suchafunctionwasamajordeterrenttotheacceptanceofthistechnology.
Yet system vendors have never seen the need to provide an undo function for system
administration.5 If an operator makes an error, he is usually aware of it immediately and could
makeeffectiveuseofanundofunction.Yetthiscapabilitystilldoesnotexist.
TheROCprojectisexperimentingwiththeprovisionofundofunctionality.
FaultInjection
We really can’t expect advances in recovery until we can easily test it. Fault injection would not
onlyallow us to test recoveryprocedures but would be a powerful capabilityfor operator training.
Itmightevenleadsomedaytorecoverybenchmarking.
ROC has developed a utility called FIG, which they use for a class of fault injection. FIG stands
for FaultInjection inglibc.glibc is theGNU C library. WithFIG,theycanrandomlycreatefaults in
thelibraryand observethe recoveryactions thatare taken.Theyhaveusedthis for muchof their
recoverystudies.
4
F.Sultan,etal.,RecoveringInternetServiceSessionsfromOperatingSystemFailures,IEEEComputerSociety;
March/April,2005.
5
N.Serrano,et.al.,ANewUndoFunctionforWeb-BasedManagementInformationSystems,IEEEComputerSociety;
March/April,2005.
5
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

Autonomic Computing
Related research known as autonomic computing is being undertaken by IBM
(http://www.research.ibm.com/autonomic/). Autonomic computing is a network of self-healing
computer systems that manage themselves. The name autonomic comes from the human
autonomicnervoussystem,whichcontrolsimportantbodilyfunctionssuchasbreathingandheart
rate.
IBMdefinesautonomiccomputingashavingthefollowingcharacteristics:
 Self-configuringofcomponents
 Self-healingoffaults
 Self-optimizing tomeetdefinedrequirements
 Self-protectingtowardoffthreats
Thisresearchisstillinitsearlyphases.
Summary
Users tend to perceive system availability more in terms of recovery time than in terms of failure
rate. Much effort has been put into the improvement of the performance of computing systems
over the last several decades as well as into improving their availability. However, little effort has
beenmadetoimprovetheirrecoverytime.6
The need to achieve rapid recovery times has been hastened by the emergence of large,
heterogeneous systems, especially with regard to Internet services. The complexity of these
systems has led to high failure rates, difficultyin locating and correcting faults, and long recovery
times.
If recovery time can be made small enough, users will perceive a faultless system. This is the
goal of the Recovery-Oriented Computing project. The ROC project is focused on reducing and
containingfaults,automaticallylocatingfaults,andrecoveringrapidlyfromfaults.
A key component of their research is microrebooting for fast recovery. This technique is
described in a companion article to be published next month. Microrebooting prototypes have
demonstrateda50:1reductioninuser-perceivedfaults.
Maybe someday there will be recovery benchmarks along with performance benchmarks to help
guideuserstoappropriatelyavailablesystems.
6
Onenotableexampleofminimizingrecoverytimeistheemergenceofactive/activesystems.Inanactive/activesystem,
two or more nodes are actively processing transactions for the same application by using synchronized copies of the
application’sdatabase.Shouldanodefail,usersservicedbythatnodecanbequicklyswitchedtoanothersurvivingnode
veryquickly.Recoverycanbeachievedinseconds.
6
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman
