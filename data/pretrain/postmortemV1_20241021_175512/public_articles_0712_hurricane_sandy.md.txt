Hurricane Sandy
December2012
Superstorm Sandy
Hurricane Sandy was the largest Atlantic storm in recorded history, spanning an area broader than
Texas.Itshurricane-forcewinds extended1,100milesfrom itscenterandaffected24statesintheUnited
States.
After skirting along offshore the Atlantic coast, Sandy
took a sudden turn to the Northwest (as predicted) and
came onshore near Atlantic City, New Jersey, on
Monday, October 29. It devastated the New Jersey
shore and parts of Brooklyn and lower Manhattan in
New York City. In all, 253 people lost their lives to the
storm. Sandy caused an estimated $66 billion of
damage in the U.S., second only to Hurricane Katrina
thatdevastatedNewOrleansin2005.
Sandy’s storm surge moved homes off of their
foundations on the New Jersey shore and filled New
York City tunnels, subways, power substations, and
basements withsalt water. 8.5millionpeople indozens
of states lost power. Without power, there was no heat, elevators in high-rise buildings stopped working,
andpeoplecouldnotchargetheircellphones–often,theironlymeansofcommunication.
Pumping out tunnels, subways, and basements in New
York City took days. Even more extensive was the
effort to restore power. Many customers were without
power for two weeks or more. Even those with
generators did not always fare well as there was no
fuel. Gas stations were without power and could not
pump gasoline. When they did and ran out, they could
notgetresupplied.
A study financed by the U.S. Department of Homeland
Security used Department of Energy data to determine
how many days it took to restore power to 95% of the
customers.NewYorkstatepowercompaniestookthirteendays.NewJerseyrestoredpowerto95%ofits
customers in eleven days. Interestingly, this was better performance than that experienced in several
earlier hurricanes. It took 23 days to restore power in Louisiana following Katrina, sixteen days to restore
1
©2012SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

power in Texas following Hurricane Rita in 2005, and fourteen days for Florida and Texas to restore
powerfollowingHurricaneWilma(2005).
Sandy’s Effect on Data Centers
There were about 150 data centers in Sandy’s path as it moved through New Jersey and New York.
Thesedatacentersfaceddevastatingconsequencesfrompoweroutagesandflooding.
As it turned out, power outages caused only minor inconveniences. Flooding caused catastrophic
damage.
Preparation
Severaldatacenterstookproactiveactiontoprotectservicestotheircustomers.Forinstance:
 CloudproviderNurvanixallowedcustomerstomovedataoutofitsNJdatacenter atnochargein
advanceofthestorm.
 Equinix,Telx,andotherssecuredhotelroomsfortheircriticalemployees andbroughtincots and
nonperishablefoodstomaintainanonsitesupportstaffduringthestormanditsaftermath.
 Datagram provides multihomingforits customers viaits ManhattanandBethel,Connecticut,data
centers. Multihomed customers who were primaried at the Manhattan data center were able to
switchovertoDatagram’sConnecticutdatacenterwhentheManhattandatacenterwentoffline.
 Integrity Virtual IT maintains online replicates of its customers’ data at its Reston, Virginia and
Chicago data centers. It offered to move customer primary hosting to its Chicago data center at
nocharge.
 Telx transitioned its Clifton, NJ, data center to backup power preemptively and stayed on
generatorpoweruntilutilitypowerhadstabilized.
PowerOutages
Mostdatacenters thatexperiencedaloss of utilitypower continuedoperating withtheir ownonsite diesel
generatorswithonlyminorproblems.ThemostaffecteddatacenterswereinlowerManhattanwhereCon
Edisonhadtocutoffpowerafterfloodingdamagedacriticalsubstationservingthatarea.
Equinix has datacenters in New York,Washington,D.C.,Philadelphia,andNew Jersey.Itensuredthatit
had 48 hours of fuel at each of its data centers with fuel vendors standing by. Except for one generator
failureinNewYorkthatwasrepaired,itsdatacenterscontinuedoperationsthroughthepoweroutages.
Telx operates three data centers in metropolitan New York and one in New Jersey. It had topped off its
fuel supplies before the storm hit. All of its data centers were forced onto generator power and continued
proper operations. Telx experienced cooling problems in one of its New York City data centers when
building management reduced the building cooling to save power. However, in anticipation of this, Telx
had brought in fans for spot cooling; and it opened the windows when the rain stopped. As a result, it
managedtokeepitsserversrunning.
Perhaps one of the most notable outages due to power was at Google’s New York headquarters building
at 111 8th Avenue. This building is one of the world’s most wired buildings. It houses a major
communication hub owned by Google that serves as a key hub for Internet traffic. The failure of an
electrical panel while switching to backup generator power took down a major portion of Internet service
forseveralhours.
2
©2012SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

AllNewJerseydatacentersstayedoperationalduringtheirmultidaypoweroutages.
Perhaps the biggest problem was faced by New York City data centers in their quest for additional fuel
supplies. It was very difficult for fuel trucks to find a way to deliver fuel because of the closure of tunnels,
bridges,andstreetsinthecity.
Flooding
Flooding was another story. It was catastrophic for buildings and the data centers they housed in lower
Manhattan near the tip of Battery Park – the southernmost part of the city. This area is one of the world’s
densest communication and computing hubs. Known as Zone A, it is one of the New York City areas
most likely to flood. And flood it did! Some streets at
times were filled with several feet of water, and this
water flowed into basements destroying whatever
criticalinfrastructurewaslocatedthere.
Unfortunately, much of this infrastructure was backup
power facilities – generators, fuel tanks, fuel pumps,
and so forth. Without the capability of generating
backup power, these data centers went dark when
ConEdisondroppedpowertolowerManhattan.
Manyof thedatacenters arewebhostingproviders.It
is estimated that tens of thousands of web sites
around the world were taken down as a result of the
failureoftheseproviders.
Two flooded buildings that are particularly critical to IT infrastructure are at 75 Broad Street and 33
Whitehall Street. 75 Broad Street houses hosting providers Internap and Peer 1. They both had to shut
down operations when flooding disabled their generators. They valiantly tried to recover but were
hamperedbyaninabilitytogetfueldeliveredtothemthroughthefloodedstreets.
33 Whitehall Street houses Datagram, a hosting provider that supports such popular sites and blogs as
the Huffington Post, Gawker, Gizmodo, and BuzzFeed. Datagram also shut down when its basement
flooded.
We relate the struggles of Internap and Datagram in more detail in the next section. A series of status
reports by Pier 1 shows the frustrations that these companies faced as the situation worsened. Over a
periodofafewhours,Pier1postedthefollowingupdates:
“HurricaneSandyhasnotimpededoperations”
“Facilityhasmadethetransitionovertoemergencypower”
“Basementisflooded”
“Wearegoingtoimplementacontrolledshutdown”
NewJerseydatacentersexperiencednosignificantproblemsfromflooding.Thebiggestproblem wasthe
failure of a levee that flooded part of Carlstadt. SunGard has three data centers there, but they were
unaffected.
A Tale of Two Data Centers
As we mentioned above, Datagram is a hosting provider that is housed at 33 Whitehall Street in
Manhattan’s Zone A.Internapis a hostingprovider thatis housedat 75 BroadStreet.Theyeach valiantly
foughttokeepservicesupandthentorestoreservicewhentheyhadlostthebattle.
3
©2012SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Datagram
Datagram, a Web hosting provider, was formed in 1994 and moved to 33 Whitehall Street, the former
NASDAQ headquarters, in 2004. Though it had a rooftop generator, its fuel tanks and fuel pumps were
locatedinthebasement.
When water flooded the two basement levels where this equipment resided, Datagram could no longer
supply power to its data center and had to close it down. It ordered six emergency generators, but only
onearrived.Asecondonewaslostintransit,victimtoabetterbidwhileenroute.
Datagram finally obtained a two-megawatt generator that was delivered on Friday, November 2; and it
restarted operations the following day. The generator supplied sufficient power to also run the elevators
sothatthestaffnolongerhadtowalkupthetwenty-fiveflightsofstairstothedatacenter.
Many of Datagram’s customers are multihomed, being able to operate either out of Datagram’s
Manhattan data center or its Bethel, Connecticut, data center. These customers were substantially
unaffected by the outage. However, Datagram’s single-homed customers faced several days of
downtime.
Internap
Internap provides managed servers and customer-managed servers in its datacenter at75 Broad Street.
Its10,000gallonfueltank andthefuelpumpsarelocatedinthebasement,andthegeneratorsareonthe
mezzaninefloor.Itsthousandsofserversareonthefourteenthfloorofthebuilding.
The flooding filled the lobby with three feet of water and inundated the basement, taking out the fuel
pumps. The fuel tank in the basement was damaged when water poured into it through an outside
breatherpipe.
Internap had a 1,200 gallon header tank on the mezzanine floor which provided enough fuel to run the
generator and the data center for twelve hours, but the data center had to close down when this tank
wentdry.InternaphadbeenabletomovesomeworkloadtoitsdatacentersinDallasandSantaClara.
In trying to get additional fuel,
Internapfacedpriorityissuesbecause
hospitals and critical-care facilities
were getting top priority for what fuel
could be brought into the city.
Internap finally arranged for two fuel
trucks and fuel pumps to come up
from Baltimore. It had to fabricate
new fuel hoses to connect the
replacement fuel pumps with the
tanker trucks on the street and with
the generators on the mezzanine
floor.
Internap ran for ten days like this until
November 10 when power was
restored. It burned 20,000 gallons of
fuel during this time, and kept one full
fueltruckparkedoutsideuntilthebasementtankandfuelpumpswererepaired.
4
©2012SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Pier1isalsolocatedinthisbuilding.Itsemployeesfueledtheirgeneratorsbycarryingfive-galloncansof
fuelupeighteenflightsofstairstoanauxiliarygenerator.Now,thatisdedication!
Sandy’s Effect on Communications
In addition to data center operations, Sandy had a significant effect on communication services. A study
fundedbythe U.S. Departmentof Homeland Securityfoundthattwice as muchof theInternet in the U.S.
was down during Sandy as compared to normal times. Though the total outage was small (growing from
0.2% to 0.43%), it was all centered in New York and New Jersey. It took four days for Internet service to
returntonormal.
Wired and wireless communication outages were widespread for all major carriers. – Verizon, AT&T,
Sprint, and T-Mobile. The FCC reported that one quarter of all
cell sites in a ten-state area were out of service. People were
liningupatpayphonestomakecalls.
A small number of 911 emergency call centers were disabled.
Theirincomingcallswereroutedtoother911centers.
The storm surge flooded several of Verizon’s facilities in lower
Manhattan, interrupting both utility power and backup power.
These sites were rendered inoperable. Verizon teams were
unabletoaccesssomesites.
Lessons Learned
Hurricane Sandy put several disaster recovery plans to an ultimate test. Some companies came through
unscathed.Otherslearnedagreatdeal.Someofthelessonsinclude:
 Is a one-hundred mile separation of production and backup facilities sufficient when Sandy’s
hurricane winds stretched 1,100 miles from its center? Cities as far away from New York as
Chicagowereaffected.
 Provide onsite living facilities for critical staff who may not be able to travel. This includes local
hotel rooms if available, cots, nonperishable food, water, and other emergency supplies. Several
days(orevenweeks)shouldbeaccommodated.
 Customers should be offered redundant hosting on a backup site a safe distance away (facilities
such as Amazon’s Availability Zones, which are in fact collocated, may not be sufficient in a
disasterofgreatmagnitude).
 Don’tputcriticalfacilitiesinabasementthatcanflood.Theyshouldbeabovethefirstfloor,which
can also flood. (Note: New York City does not allow fuel tanks on rooftops following 9/11 when
leaking fuel from a rooftop fuel tank is suspected of contributing to the collapse of 7World Trade
Center).
 Buybackupmobilegeneratorsandstoretheminasafedistantlocation.
 Make sure that fuel tanks are topped off, generators can start, and power can be safelyswitched
fromutilitypowertobackuppower.
Who would have ever thought that New York City would be inundated with sea water and lose power for
weeks? Make sure your company has a thorough and well-tested disaster-recovery plan that covers
majoroutagesregardlessofthecause.
5
©2012SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Acknowledgements
Materialforthisarticlewastakenfromthefollowingsources:
AfterHurricaneSandy:Lessonsforthedatacenter,Infoworld.
NewssitesknockedoutasNYCdatacenterfloods,NBCNews.
MassiveFloodingDamagesNYCDataCenters,DataCenterKnowledge.
PreparingOurDataCentersforHurricaneSandy,Rackspaceblog;October29,2012.
HurricaneSandyFloodsDataCenters,TakesDownWebsites,HuffingtonPost;October30,2012.
HurricaneSandyTopplesNewYorkDataCenterGawker,Gizmodo,WiredEnterprise;October30,2012.
NoiseFilter:HurricaneSandyFloodsNYCDataCenter,ImpactsHosts,ColocationProviders,TheWhir;
October30,2012.
SuperstormSandyKnocksOutDataCenters,NewsDiscovery;October30,2012.
HurricaneSandySurgeChallengesNYCDataCenters,InformationWeek;October30,2012.
HurricaneSandyknocksoutNYCdatacenters:Websites,servicesdown,ZDNet;October30,2012.
HurricaneSandytakesdatacentersofflinewithflooding,poweroutages,arstechnica;October30,2012.
HurricaneSandy:Power,wirelessoutageslingerinlowerManhattan,Computerworld;October31,2012.
Amazon,EquinixDataCentersVs.HurricaneSandy,InformationWeek;October31,2012.
HurricaneSandy’swake:Howdidproviders’datacenterDRplansdo?,TechTarget;November7,2012.
HowoneNYCdatacentersurvivedHurricaneSandy, arstechnica;November15,2012.
HurricanePowerOutagesAfterSandyNotExtraordinary,AccordingtoReportAnalyzingKatrina,Past
Storms,HuffingtonPost;November16,2012.
AfterSandy:DatagramRecoversFrom‘Apocalyptic’Flood,DataCenterKnowledge,November26,2012.
SandyShowsSateOfITResilienceHasRoomForImprovement,ITJungle;December10,2012.
HurricaneSandyWasResponsibleForMassInternetOutages,redOrbit;December18,2012.
HurricaneSandydoubledInternetoutages,Futurity;December19,2012.
6
©2012SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com