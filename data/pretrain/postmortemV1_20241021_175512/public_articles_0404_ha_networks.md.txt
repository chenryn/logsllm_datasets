High Availability Network Fundamentals
April2009
Chris Oggerino, at the time of his authoring of High Availability Network Fundamentals,1 was a
Serviceability Design Engineer at Cisco Systems. His book is a practical guide to predicting
networkavailability,completewithmanyexamplesusingCiscoproductsincomplexnetworks.
Though calculating availability of complex systems is a highly-mathematical exercise, Mr.
Oggerino takes great pains to provide a detailed and accurate approach to availability analysis
without requiring intensive mathematics – just a little simple arithmetic. There are only four
equations in the entire book, yet he shows the reader how to do extensive availability analysis
through a process that he dubs “divide and conquer.” He shows the reader how to account for
hardware and software faults, failover time, power outages, human error, and network device
redundancy.
His book includes a CD containing the SHARC System Hardware Availability and Reliability
Calculator spreadsheet. This spreadsheet does all the arithmetic work for the analyst as well as
performscalculationsdeemedtoocomplexforthereader.
Interestingly, his book follows the same path taken in our earlier Geek Corner articles entitled
Calculating Availability – Heterogeneous Systems – Parts 1 through 4, Availability Digest; March
through August, 2008. The primary difference is that we went into a great deal of mathematics
behindtheavailabilitycalculations –afterall,weare writingforthegeek audience.Forthosewho
found those articles a little daunting, Mr. Oggerino’s book will be a refreshing and simple review
ofvirtuallythesametopics.
Introduction to Availability
Inhis firstthreechapters,theauthor introduces availabilityconcepts.Hepresents the percentage
method and the defects-per-million method for describing availability. The percentage method
states the percentage of time that a system is available (such as 99.9%, or three 9s). This is the
method that we use throughout the Availability Digest. The defects-per-million method gives
availabilityintermsofthenumberoffailuresperone-millionhours.
DescribingAvailability
Knowing the MTBF (mean time between failures) and the MTTR (mean time to repair), one can
convert between these methods. The percentage method is related to availability by noting that
availabilityistheratioofthetimethatthesystemisup(MTBF)tothetotaltime(MTBF+MTTR):
1C.Oggerino,HighAvailabilityNetworkFundamentals,CiscoPress;2001.
1
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

MTBF
Availability  (1)
MTBFMTTR
The defects-per-million method is simply another way to specify MTBF. For instance, if a router
has 200 defects per million hours, its MTBF is 5,000 hours. Knowing the MTTR then lets one
determinethepercentageavailability.2
The defects-per-million method is typically used to characterize network device reliability by the
manufacturer. However, the author converts these numbers to MTBF and uses the percentage
methodthroughoutthebook.
AnalyzingAvailabilityofNetworkConfigurations
The author points out that MTBF (or the equivalent defects-per-million) is usually obtained from
the device manufacturer. However, MTTR is a function of the maintenance policies of the
customer. He suggests using the response time required by the service contract for MTTR. For
instance, if the service contract calls for a repair technician to be on-site with a replacement part
infourhours,MTTRistakenasfourhours.Thetimetoactuallyreplacethecomponentisignored
but is offset by the fact that many responses will be faster than that required by the service
contract.ThisleadstoaconservativeestimateofMTTR.3
Using MTBF and MTTR tocalculate the availabilityof a component, Mr. Oggerino next describes
how to calculate the availability of a network of components. He notes that there are two basic
configurations–serialandparallel.
In a serial configuration, all components must
work. Should one fail, the network fails. In this
A1 =0.995 A2=0.995
case,the availabilityof the serialconfiguration
is the product of the availabilities of the
individual components. For instance, in a A=A1xA2=0.990
serial configuration of two components, if
each component has an availability of 0.995, the availability of the serial configuration is 0995 x
0.995 = 0.990. The serial configuration is less available than the availability of any of its
components.
In a parallel configuration, in the simplest case, the network will remain operational so long as at
least one component is operational. In this case, the probability that the network will fail is the
probability that all components fail, and this is the product of the failure probabilities of each
component (the probability of the failure of a component is
one minus its availability). The availability of the parallel
A1=0.995
network is one minus this value. Consider a parallel
network comprising two components, each with an
availability of 0.995. The availability of this configuration is
[1–(1 –0.995)2] =0.999975.Theavailabilityof theparallel
A2=0.995
configuration is significantly greater than the availability of
any of its components. This is redundancy. As we know,
adding redundant components significantly improves the A=1–(1–A1)(1–A2)
availabilityofanetwork. =0.999975
2Theauthordistinguishesbetweenmeantimebetweenfailures,MTBF,andmeantimetofailure,MTTF,inhisFigure1-3.
Availabilityis MTTF/(MTTF+MTR)or(MTBF-MTR)/MTBF. However, his point is that eithercanbeusedinEquation(1)
above withnegligibledifference.Heuses MTBF inthebook inplaceof MTTFintheMTTF equation. Youcaninterpret
MTBFasmeantimebetweenfailures,equivalenttoMTTF.
3Thisassumes,ofcourse,thatthedeviceinfailurehasbeenidentified.
2
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

The more complex case is N+M redundancy, in which N components are required and in which
there are M spares. Though the author gives the equation for the most common case of N+1, he
doesn’t use it in his later examples, relying instead on the SHARC spreadsheet to make these
calculations.
This section concludes with availability analyses of some serial, parallel, and serial/parallel
networktopologiesusingCiscocomponents.
Predicting Availability
Thenexttwochaptersfocusonhowtopredicttheavailabilityofnetworkdevicesandtopologies.
AvailabilityFactors
The author begins this topic by discussing the various factors that can affect availability and
showshowtoaccountforthem.Factorsinclude:
 hardware
 software
 environment
 humanerror
 networkdesign
Hardware
Calculating hardware availability according to Equation (1) requires knowledge of the MTBF and
MTTR of each device in the network. MTBF is determined by most telecommunications
companies via the Bellcore TR-232 specification, which takes into account the known failure rate
of every elemental component in the device being measured – integrated circuits, resistors,
capacitors,fuses,transformers,etc.–as afunctionof temperatureand other stresses.From this,
the failure-per-ten-billion-hours (FIT) for the device is determined and can easily be converted to
MTBF.4
So far as MTTR is concerned, the author suggests that it be assumed that the actual time to
replace a failed device is short. It is the time to get a service technician on-site with the
replacementdevicethatisthetime-consumingpartofdevicerepair.Therefore,usingtheservice-
contract response time (4 hours, 24 hours, or whatever) is a conservative way to estimate MTTR
forhardwarefailures.
Examples of calculating the availability of simple nonredundant devices, redundant devices, and
networksegmentsaregiven.
Software
The determination of software MTBF requires the measurement of software failures for a large
number of devices over a long period of time. Cisco has, in fact, done this and has determined
that a conservative value for software MTBF is 30,000 hours for mature software and 10,000
hours for softwarethat has been recently(within a year) released.Actual measurements of some
large networks showed software MTBFs of 45,000 to 70,000 hours for mature software, so the
suggestedresultsaretrulyconservative.
4Forinstance,ifacapacitorhasafailurerateof1,000failureseveryten-billionhours,itwillhaveanFITof1,000.Adding
theFITsforeachcomponentinthedevicegivestheFITforthedevice.IfthedevicehasatotalFITof1,000,000,itwillfail
onceevery10,000hours,whichisitsMTBF.
3
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Sincemostsoftwarefaultsarecuredbyrebootingthedevice,softwareMTTRcanbetakenasthe
reboot time. Averaged over router sizes, the author suggests using six minutes for software
MTTR.Largerrouterswilltakelongerastheyrecomputeroutes.
Examples of calculating availability, including software failures for a simple device and a
redundantdevice,aregiven.
Environment
Environmentalfaults includepoweroutages,hurricanes,earthquakes,tornadoes,forestfires,and
other events. Most cannot be predicted and are often catastrophic, putting data centers out of
servicefordaysormore.
However, these events all tend to disrupt the power source to the network. Therefore, the author
focuses on power outages. He suggests that in the absence of better data, a national average
seems to be about 29 minutes of power loss per year. This is an availability of 0.999945 (a little
over four 9s). The effects of power loss can be mitigated by backup power devices such as
batteryordieselpowerbackup,whichthemselvesmayfail.
Severalexamplesofnetworkavailabilitywithdifferentpower-lossmitigationstrategiesaregiven.
HumanError
Mr. Oggerino points out that human error is by far the predominant factor in network availability.
Humanerrortypicallyoccurswhenstandardoperatingprocedures allowittohappen.Operational
processesthatmitigatehumanerrorarefundamentaltohighlyavailablenetworks.
Humanerrorsmostfrequentlyoccur as aresultof changes.Adding,upgrading,andreconfiguring
network devices canbeaverycomplex process.As theauthor states,“Nearlyeveryhumanerror
that occurs will be more than the downtime for all other reasons combined. … Once enterprise
networksareoperationalandthebugshavebeenworkedout,theyhardlyeverfail.Whentheydo
have problems, it is just as likely to be a result of someone changing something as it is for any
otherreason.…Weassumeahuman-errorcontributionoffourhourseveryotheryear.”5
A massive communications failure that occurred in 1997 is described as an extreme example. A
large network in the United States was down for 24 hours because network administrators
decidedtosimultaneouslyupgradethesoftwareintwomajorswitchesthatbackedeachotherup.
Even worse, they had no failback plan. On reboot, the switches did not perform properly; and it
tookadaytocorrecttheproblem.
A more common problem that is discussed is duplicating IP addresses when adding PCs to a
network.Impropersecuritycontrolreconfigurationsareanothercommonproblem.
As noted above, the author suggests reasonable values for human error to be one failure every
two years (MTBF) thattakes downthesystem for anaverageof four hours (MTTR).This leads to
anavailabilityduetohumanerror of 0.99977,afactor anorder ofmagnitudemoredominantthan
powerloss,asdescribedabove.
He suggests a procedure for measuring and minimizing human error. Good change control
proceduresarekeytoimprovingthisavailabilityfactor.
5 Page 171, Human Error and Process Contribution to Downtime in an Enterprise Network, High Availability Network
Fundamentals.
4
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

NetworkDesign
The incorporation of redundancy into the network configuration is a key to achieving high
availability. Redundancy means the provision of two or more devices that can provide the same
functionality.Ifoneshouldfail,theothercantakeoverandkeepthenetworkinoperation.
There are two primary forms of redundancy – standby and load sharing. With a standby backup,
the standby device is not operational. Should the primary device fail, the standby is pressed into
servicetotakeoveritsfunctions.
Inaload-sharingconfiguration,twoormoredevices areprovidingthesamefunction-sharingthe
load.Shouldadevicefail,trafficissimplyroutedtothesurvivingdevices.
In terms of the availability calculation, redundant systems are parallel systems that provide
significant additional availability for that device. However, they add their own form of additional
downtime that must be considered. That is failover time. If the network will be down for one
minuteasthestandbydeviceisbroughtintoservice,thisminuteaddstothetotaldowntimeofthe
network.
Failover time is a function of the router protocol. The author suggests using a failover time of 35
seconds for OSPF (Open Shortest Path First)6 and five seconds for HSRP (Hot Standby Router
Protocol, a Cisco proprietary protocol similar to the industry standard VRRP7). In the book’s
examples, it is clear that failover time is the predominant factor in redundant-device availability –
oftenbyafactorof100.
There is also the possibility of a failover fault, in which the failover doesn’t work and the network
isdownuntilarepaircanbemade.Theauthorignoresthisasitisbeyondthescopeofthebook.8
Several examples are given for incorporating redundant systems and failover times into the
availabilitycalculation.
DivideandConquer
Having described the various factors that go into the calculation of device availability and simple
serial and parallel configurations of devices, the author introduces the concept of “divide and
conquer” to analyze complex networks. The first step is to diagram the network with a reliability
block diagram (RBD). This diagram shows the connections between each of the devices in the
networkandclearlyshowstheparallelandserialconstructs.
Thenextstepisthentocalculatetheavailabilityofallparallelconstructsandtoreplaceeachwith
an equivalent device with the availability of the redundant devices. Serial constructs are then
replaced with a single device with the availability of the serial devices. If this process should
create additional parallel constructs, the process is repeated until the entire network is
representedasasingledevicewithaknownavailability.Thisistheavailabilityofthenetwork.
A2
A1 A1 A2,A3 A1,A2,A3
A3
RelibilityBlockDiagram ReduceParallelConstructs ReduceSerialConstructs
6OSPFisthemostwidelyusedinternalgatewayprotocolinlargeenterprisenetworks.
7VRRP–VirtualRouterRedundancyProtocol,AvailabilityDigest;October2008.
8CalculatingAvailability–FailoverFaults,AvailabilityDigest;March2007.
5
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

The book then introduces the concept of network scenarios by way of an example that includes
interconnected VoIP (Voice over IP) networks in two buildings that also interface to the public
switched telephone network. A network scenario is a path through the network whose availability
is desired. For instance, in this case, scenarios include connecting two users in the same
building, connecting two users in different buildings, and connecting a user to the public
telephone network. Each scenario will have a different availability. The author takes the reader
throughthedetailedavailabilitycalculationforeachscenario.
Real-World Case Studies
The final four chapters use the techniques taught in the book to calculate the availability of
several actual networks. The first chapter leads off the effort by calculating the availability of
certainCiscorouters.
The first case study is that of a small ISP network. The second case study is for an enterprise
network. The final case study is the availability analysis of a very large and complex VoIP
network.
In each case, all availability factors are considered – hardware failures, software faults, power
outages, human errors, and network device redundancy. These chapters make extensive use of
theSHARCspreadsheetincludedonaCDwiththebook.TheSHARCspreadsheetresultsareall
includedasfigures.
TheSHARCspreadsheetisdescribedindetailinanAppendix.
Summary
High Availability Network Fundamentals is a very readable discussion on how to calculate the
availability of very complex networks. The only mathematical knowledge required is simple
arithmetic. Calculations both simple and complex are provided by a spreadsheet provided on a
CDwiththebook.
The book’s technique includes the primary contributors to network failure – hardware, software,
power, and people. A simple diagramming technique using Reliability Block Diagrams (RBDs)
guides the analyst through the decomposition of complex networks into bite-sized chunks for
arithmeticanalysis(nothingmorethanadditionandmultiplication).
Perhaps the most daunting task for an analyst is understanding the network in enough detail to
create an accurate RBD. The next most difficult task is determining the availability of each of the
components in the RBD. This may require conservative guesstimates for such factors as power
failures and human errors. Once these hurdles have been overcome, the actual calculation of
network availability, even for very complex networks, is reduced to a series of very simple steps
bythedivide-and-conquertechniquestaughtinthebook.
Though the book focuses on network availability, its techniques are directly applicable to
redundantsystemssuchasclusters,primary/standbyconfigurations,andactive/activesystems.
6
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com