This was a time of change, a decade prior to the \"Manifesto for Agile
Software Development\". The waterfall development cycle was firmly
entrenched and object-oriented programming still novel.

> \"The traditional waterfall development cycle has endeavored to avoid
> programming catastrophe by working out a program in detail before
> programming begins. We watch with some interest as the community
> attempts to apply these techniques to objects. However, using our debt
> analogy, we recognize this amounts to preserving the concept of
> payment up-front and in-full. The modularity offered by objects and
> the practice of consolidation make the alternative, incremental
> growth, both feasible and desirable in the competitive financial
> software market.\" [Cunningham,
> 1992](http://snafucatchers.github.io/#ref_7)

Cunningham\'s thesis was that the object-oriented programming method
created an opportunity to build systems quickly, to deploy them, and
from their use to discover new abstractions that could then be
incorporated into the software. The advantage that objects and, in
particular, inheritance brought to the party was the ease with which
these changes could be made.

#### Technical debt and refactoring: 

A decade after Cunningham\'s paper, Fowler (2003) described technical
debt as:

> \"\...doing things the quick and dirty way\... \[After which,
> i\]nterest payments\... come in the form of the extra effort that we
> have to do [in future development]{.underline} because of the quick
> and dirty design choice. We can choose to continue paying the
> interest, or we can pay down the principal by refactoring the quick
> and dirty design into the better design. \[emphasis added\]

In Fowler\'s formulation, technical debt is \"that which can be
corrected by refactoring\". Refactoring is

> \"\......is a disciplined technique for restructuring an existing body
> of code, altering its internal structure without changing its external
> behavior.\"

Fowler and others have developed guides for refactoring ([Fowler et al.,
1999](http://snafucatchers.github.io/#ref_9)). Improving internal
structure makes the software \"cleaner\" and, it is claimed, easier to
understand, maintain, and modify. In a setting where frequent revision
is expected, the benefit of clean software is to make these activities
easier. Refactoring is not itself productive because it does not change
the software\'s external behavior. Thus refactoring \"pays back\"
technical debt but does not produce immediate value for users. Technical
debt makes development less efficient which makes new dev harder; this
inefficiency is \-- in the language of the metaphor \-- the \'interest\'
paid on technical debt.

There is a tension here. Taking on technical debt can make it easier to
bring improvements to the user quickly but such debt will make it more
difficult to do so in the future. Refactoring will remove (\"pay back\")
technical debt and make further development easier but the effort used
for refactoring is not available to add new functionality for users.
Software development must strike a balance between these two extremes by
wise choices based on accurate assessments. Accepting too much technical
debt in order to bring product features to the customer may doom the
long-term viability of the product by making it impossible to revise in
the future. In contrast, concentrating exclusively on keeping the
software spotlessly clean may cause the enterprise to miss opportunities
for improving the current product and make it less competitive.

#### Technical debt 25 years on 

Like many useful metaphors, technical debt has been expanded and
exploited, sometimes in ways that do not do justice to the original
notion. ([Stopford, B., Wallace, K., & Allspaw, J.
(2017)](http://snafucatchers.github.io/#ref_32) There are now elaborate
measurement tools, financial calculators, and programs that seek to
quantify, track, and manage technical debt. The ease with which \'debt\'
and \'interest\' can be understood can make the issues surrounding
software design, development, and maintenance seem simple and easily
managed. Managers with little understanding of software may perhaps be
forgiven for so eagerly grasping the metaphor that so strongly resonates
with finance. This is perhaps an example of the hazard of metaphor: it
can encourage inaccurate or even misleading analogic reasoning.

The theme of technical debt is intertwined with organizational issues.
Accounting for tech debt is not done at an organizational level, it\'s
done on a team or individual level. The organization has little idea of
how much technical debt it \'carries\' in its code and paying tech debt
is notoriously difficult to make visible to those setting business level
priorities. There is an expectation that technical debt will be managed
locally, with individuals and teams devoting just enough effort to keep
the debt low while still keeping the velocity of development high.

Critically, technical debt is, by definition, appreciated prior to its
creation, visible in code, and can be eliminated by refactoring.

### 4.6.2 Dark debt 

The three anomalies discussed in the workshop arose from unappreciated,
subtle interactions between tenuously connected, distant parts of the
system. It was proposed during the workshop that the anomalies revealed
a particular type of vulnerability that one participant described as
\"dark debt\"^[12](http://snafucatchers.github.io/#foot_12)^ [because
the vulnerability was not recognized or recognizable until the anomaly
revealed it]{.underline}.

Events that have the dark debt signature include:

1.  [Knight Capital, August
    2012](https://en.wikipedia.org/wiki/Knight_Capital_Group)
2.  [AWS, October
    2012](https://arstechnica.com/information-technology/2012/10/amazon-web-services-outage-once-again-shows-reality-behind-the-cloud/)
3.  [Medstar, April
    2015](http://hcrenewal.blogspot.com/2015/05/another-day-another-ehr-outage-medstar.html)
4.  [NYSE, July
    2015](https://www.bloomberg.com/news/articles/2017-02-07/nyse-told-major-outage-in-2015-may-have-broken-securities-rules)
5.  [UAL, July
    2015](http://money.cnn.com/2015/07/08/news/companies/united-flights-grounded-computer/)
6.  [Facebook, September
    2015](https://www.facebook.com/notes/facebook-engineering/more-details-on-todays-outage/431441338919/)
7.  [GitHub, January
    2016](https://blog.github.com/2016-01-29-update-on-1-28-service-outage/)
8.  [Southwest Airlines, July
    2016](https://www.cbsnews.com/news/southwest-airlines-computer-outage-causing-massive-delays/)
9.  [Delta, August
    2016](http://money.cnn.com/2016/09/07/technology/delta-computer-outage-cost/)
10. [SSP Pure broking, August
    2016](https://www.computerweekly.com/news/450303913/Insurance-brokers-count-cost-of-lost-business-as-SSP-SaaS-platform-outage-enters-second-week)

In each instance, the failure was generated by mechanisms unappreciated
prior to the event. The event revealed the interaction potential of the
contributors. Like the anomalies discussed during the workshop, these
events were surprises. It takes an anomaly to bring the contributors and
the interactions into view.

#### Whence cometh dark debt?

Dark debt is found in complex systems and the anomalies it generates are
complex system failures. Dark debt is not recognizable at the time of
creation. Its impact is not to foil development but to generate
anomalies. It arises from the unforeseen interactions of hardware or
software with other parts of the framework. There is no specific
countermeasure that can be used against dark debt because it is
invisible until an anomaly reveals its presence.

Dark debt is a product of complexity. To a large extent, adding
complexity is unavoidable as systems change. Systems are designed and
constructed from components that are expected to fail. This leads to
incorporation of layers of defense against failure. Architectures,
distributed systems, failovers, backups, exceptions and exception
handlers, encapsulation, and other aspects of IT are explicit
recognitions of the potential for failure. These layers contain
multiple, constantly shifting, apparently innocuous defects. The logic
of design ensures that no single fault can generate an anomaly.

The challenge of dark debt is a difficult one. Because it exists mainly
in interactions between pieces of the complex system, it cannot be
appreciated by examination of those pieces. After anomalies have
revealed the relationships they appear obvious but the appearance is
mainly hindsight bias ([Woods & Cook,
1999](http://snafucatchers.github.io/#ref_41)). The existence of dark
debt poses a substantial challenge to system owners. Unlike technical
debt, which can be detected and, in principle at least, corrected by
refactoring, dark debt surfaces through anomalies. Spectacular failures
like those listed above do not arise from technical debt. Critics of the
notion of dark debt will argue that it is preventable by design, code
review, thorough testing, etc. But these and many other preventative
methods have already been used to create those systems where dark debt
has created outages.

# 5. Possible avenues for progress on coping with complexity 

Resilience in business-critical software is derived from the
capabilities of the workers and from the deliberate configuration of the
platforms, the workspace, and the organization so that those people can
do this work. It is adaptability that allows successful responses to
anomalies and successful grasping of new opportunities. The
organizational and technical structures of the enterprise are
intentionally configured to generate and sustain the enterprise's
adaptive capacity. In a complex, uncertain world where no individual can
have an accurate model of the system, it is adaptive capacity that
distinguishes the successful.

The STELLA report gives us a taste of how engineers cope with the
complexity of anomalies. These hiccups, glitches, events, incidents,
accidents, and catastrophes are common, significant, and challenging as
the examples show. The work of anomaly response by these engineers is
seldom studied and rarely described in any detail. SNAFUs are, after
all, routine.

Each of the six themes identified in this report could become an avenue
for progress on coping with complexity. There is already progress in
controlling the costs of coordination. The burgeoning use of "chat ops"
and related automation is a \'hot\' area and likely to remain so,
especially because so many working groups are now geographically
distributed. Visualization tools are appearing, especially associated
with application and platform monitoring. Interest in non-technical debt
gets a boost with every celebrated outage.

Less is happening in the area of blame versus sanctions and making
postmortems more effective. These are areas that are difficult to
approach, partly because there is no tradition of deliberate process
tracing after events. Postmortems are hard to do and consume valuable
resources. Many (most?) organizations have difficulty extracting useful
learning from after-anomaly investigation and analysis. Management
sensitivity to user community perceptions and publicity does not always
lead to deep, thoughtful investigation and analysis and wide sharing of
the details of anomalies and their implications is not the norm.
Although many organizations claim to be \"blame-free\" most are, at
best, "sanction-free" over a limited range of outcomes.

The workshop successfully brought together technical people for a
wide-ranging discussion of events. Many factors contributed to this
success: careful preparation, trust-building over time, pre-meeting
practice, participation of respected technical leaders, and skilled
facilitation all played a role. The (bad) weather may also have helped
by serving as a shared adversity and allowing concentration and focus.

Bringing anomalies to the table for discussion encourages comparison and
contrast. In many organizations, postmortems are isolated, one-off
exercises; comparison and contrast of multiple events is distinctly
rare. Having people from outside the organization examine an anomaly
generates lines of inquiry that internal analyses do not. \"Why are
things done the way they are?\" is seldom asked during internal analysis
but was quite common during the workshop. Examining the assumptions that
underlie system architectures and procedures does not always produce
valuable insights, but the need to produce explicit statements about why
things are done a certain way can be very revealing. The workshop
created an environment that promoted inquiry and dialog that was
qualitatively different from what goes on in most internal postmortems.

We note that many organizations have large collections of incident
reports that are only rarely interrogated or explored. Production
pressure and the many changes that take place undermine integration
across events. Anomalies are unplanned system performance tests and
basic management principles require that such investments generate
return. Postmortems are a way of generating ROI from unplanned
investments. Improving them is ever more critical.

There is a window of opportunity for improving postmortems. There is
great potential for cognitive process tracing supported by new tools,
but these approaches need to be coupled with broader sharing of results
and critical analysis of collections of events for the full value of
these improvements to be realized. The complexity of these systems is
daunting, and what is more: it is constantly changing. On consideration,
what is surprising is not that these platforms sometimes stop working.
It is surprising that they work often enough to provide valued services
at all. The price of continuous operations is continuous attention.

In order to make substantial progress towards making systems *resilient*
(the "system" depicted in Figure 4) there needs to be continuous
exploration to re-calibrate and update models and tools. The methods of
knowledge elicitation, process tracing, accident investigation, and
other qualitative analysis play a role. The methods used for this
workshop and the consortium approach illustrates that we can
continuously monitor where and how SNAFUs arise and that we can
constantly replenish the capabilities needed for SNAFU Catching.

The workshop results reveal how work is done above, below, and across
the line. The report identifies some specific themes to pursue that will
enhance the capabilities needed for resilient performance. Furthermore,
the report is a progress report on the consortium's partnerships and
activities that shows it is possible \-- and critically necessary \-- to
understand where and how our systems are resilient and brittle.

# 6. Back matter 

## 6.1 Preparation 

The workshop itself was conducted under the [Chatham House
Rule](https://www.chathamhouse.org/chatham-house-rule):

> When a meeting, or part thereof, is held under the Chatham House Rule,
> participants are free to use the information received, but neither the
> identity nor the affiliation of the speaker(s), nor that of any other
> participant, may be revealed.

This report was prepared in accordance with that rule and so workshop
participants and their home organizations are not identified. This
report was prepared under the supervision of Prof. David Woods.

## 6.2 Acknowledgements 

The workshop was sponsored by Etsy and coordinated by Vanessa Hurst.
Vanessa\'s group made the workshop possible, welcomed us, fed us, guided
us around Brooklyn, and offered shelter from winter storm STELLA and
access to hot water that our hotel did not have! We are grateful to Etsy
for its generous support.

The participants and their home organizations brought their \"A\" game
and made the workshop a success. The Chatham House Rule promises them
anonymity so we will not thank them individually beyond this statement:
*You are the main source of resilience in your world and we thank you
for sharing your experience and wisdom*.

The report benefitted from the comments of a dozen early readers, many
of them VIPs in the devops and software engineering world, all of them
VIPs to us. The report is better because of your contributions. Thank
you!

The SNAFUcatchers consortium (www.snafucatchers.org) includes Etsy, IBM,
IEX, and Dave Wood\'s group at The Ohio State University. We gratefully
acknowledge the support, engagement, and commitment that have made
SNAFUcatchers existence possible.

