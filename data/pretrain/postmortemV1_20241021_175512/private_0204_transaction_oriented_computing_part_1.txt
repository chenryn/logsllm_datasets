Transaction-Oriented Computing
April2007
Transaction-oriented computing brings with it a multitude of advantages. Of interest to us is its
support of high availability through fast recovery. However, transaction-oriented computing’s
original task was to ensure the consistency and durability of the application databases. As
transactional methodologies evolved, significantly improved performance was added to the list of
itsadvantagesaswasitssupportfordatareplication.
It is for all of these reasons that transaction-oriented computing should be understood by anyone
interested in achieving high availability of their data processing services. For many involved in
today’s computing systems, this maybe like preaching to the choir since transactional computing
formsthebasisformostpresent-daybusinessapplications.
However, the requirement for high availability extends far beyond just business applications to
areas in which transaction processing is not commonly used and is not well understood. This
includes not only applications that are not business-oriented but also to older business
applications that were developed prior to the advent of transactional computing.1 It is to these
audiencesthatthisarticleisaddressed.
What Does Transaction Processing Have To Do With Availability?
Transaction-oriented computing is the foundation of today’s recoverymechanisms. As the cost of
downtime grows with each new 24x7 application, data center operations are moving from tape
backup to maintaining an up-to-date database at a remote site via data replication. Should the
primary site fail, restoration of services no longer depends upon fetching the backup tapes,
reading the last full backup, and updating it with incremental backups, a process that can take
hours or days. Even worse, all of the transactional activitysince the last backup is lost – a period
ofperhapsuptoaday’sworthormoreofvaluabledata.
The new recovery paradigm sends updates as soon as they happen to a remote site where a
remote copy of the database is maintained. These updates immediately update the database so
that it is always a consistent copy of the primary database, except for a small (perhaps seconds)
delay.
This technique of replicating data from a primary system to a backup system supports cold
backups (backup applications must be started), hot backups (backup applications are up and
running), and active/active systems (transactions are being processed by all systems). Recovery
can be accomplished in seconds to minutes, depending upon the application network
configuration,withverylittleifanylossofdata.2
1
SeeVirtualTransactionswithNonStopAutoTMFinthisissueoftheAvailabilityDigest.
2
Seeourpreviousarticles,AsynchronousReplicationEngines(November,2006),SynchronousReplication(December,
2006),andWhatisActive/Active(October,2006).
1
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

Thisiswheretransactionprocessingplayssuchanimportantrole.Datareplicationdependsupon
the existence of a change log. The most common form of a change log is the transaction log
maintainedbyaTransactionManagerinatransaction-orienteddataprocessingsystem.
The Attributes of a Transaction
What is this thing called a transaction? A transaction is a collection of operations on the state of
an application. All operations must be executed in order for the application state to remain
consistent. If any one of the operations within the scope of a transaction cannot be successfully
executed,noneoftheoperationscanbeexecuted.
A common example is a consumer banking application. A bank’s customer wants to move $500
from his savings account to his checking account. This transaction requires two operations –
debithis savings accountby$500 andcredit his checking account with $500.If onlyoneof these
operations is executed, the result is wrong. Either the customer is out $500, or he has an
additional $500. The application state is only correct (that is, consistent) if both operations are
performed.
In a program, a transaction is identified by preceding all of the operations pertinent to that
transaction withabegintransactionstatementof somesortandbyfollowingthe setof operations
with an end transaction statement. A transaction has four important attributes, known collectively
asitsACIDproperties–atomicity,consistency,isolation,anddurability.
 Atomicity requires that either all of the operations within a transaction are executed or
that none are. A transaction is atomic if it appears to a viewer that the application jumps
fromonecorrectstatetoanothercorrectstatewithnointermediatestates.
 Consistency means that the results of a transaction satisfy the specified constraints on
theapplication.Ifatransactioncannotguaranteeaconsistentstate,itisaborted.
 Isolation means that the result of a transaction is unaffected by other transactions that
maybeexecutingatthesametime.
 Durabilitymeansthattheresultsofacommittedtransactionareneverlost,evenfollowing
therestorationofthesystemafterafailure.
Atomicity and Consistency
The consistency of an application is guaranteed by the atomicity property of transactions.
Assuming that the program is properly written, the execution of any set of operations within the
scopeofatransactionwillleavetheapplicationinaconsistentstate.Intheaboveexample,either
$500 is debited from the customer’s savings account and credited to his checking account, or no
changestohisaccountaremade.
An entity called the Transaction Manager, described in more detail later, is responsible for
enforcing atomicity. When it receives a begin transaction statement, it will ensure that the
information required to return the application’s database to a consistent state is retained as
modifications aremade to the database. Should all operations within the scope of the transaction
be successful, it will apply those changes (it will commit the transaction). Should any one of the
operations fail, the database is returned to its original state as if the transaction never happened
(thetransactionisaborted).
2
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

The application is informed of the outcome of the transaction so that it can take the appropriate
nextstep(proceedforwardonacommit,perhapsretryonanabort).
Isolation
Isolation is provided by locks. Before an operation within a transaction updates a data item, that
operationmustacquirealockonthatitem.Thispreventsanyotherapplicationfrom updatingthat
itemuntilthetransactionowningthelockreleasesit.
Atransactioncanalsoacquirealock onadataitem thatitintendstosimplyreadtouseaspartof
a computation to update another data item. This prevents the value of the read data item from
changinguntilthetransactioniscomplete.
Atransactionholdsitslocksuntilitiseithercommittedoraborted.Atthattime,itwillreleaseallof
itslocks.
Thislockingstrategyalsoplays aroleinconsistency.Notonlydoesalock onadataitem prevent
another application from updating that data item, but it also prevents other applications from
reading that data item (except for “dirty reads,” which read through locks and which are allowed
by some systems). As the transaction progresses and executes one operation at a time, it will
take the application through some inconsistent states. No other application can read this state
because of the locks. Only when the application state has reached a consistent state and the
transaction has committed or aborted is the modified state exposed. Thus, as mentioned earlier,
to an outside viewer the application seems to jump from one consistent state to another with no
intermediatestates.
A problem with locks is deadlocks. A deadlock occurs when two programs attempt to acquire a
lock on two data items out of order. Each holds the lock required by the other program, and
neithercanproceed.
Deadlocks can be avoided by using an intelligent locking protocol, which specifies a mandatory
order in which locks should be acquired. If deadlocks cannot be avoided, there are several
techniquesforresolvingthem,suchashavingtheprogramsback offandtryagainafterarandom
time.
Durability
Durability is the attribute in which we are interested from an availability viewpoint. It means that
once the results of a set of actions bounded by a transaction have been committed, the new
databasestatesurvivesanysubsequentsystemfailure.
Durability is the responsibility of the Transaction Manager, mentioned above. As a transaction
progresses, the Transaction Manager retains a record of the before image and the after image of
any record or row that is modified by the transaction in a transaction log. Transaction logs are
described in more detail later. Before any changes are made to the database itself, the before
and after images in the transaction log must have been safely stored on a persistent medium
such as disk. This means that before a transaction is committed, that portion of the transaction
logthatcontainsthetransaction’s beforeandafter imagesmustbesafelystored. Meanwhile,the
actual modified data blocks may sit in cache memory for a while and be written to disk at some
latertime.
Shouldthesystemfail,therewillbesomecommittedtransactionswhosechangeshavenotmade
it to the physical database (they were still in cache memory) and some incomplete transactions
which have had some of their changes made to the database (after writing the before and after
3
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

images to the transaction log). When the system is returned to service, the database must be
recovered.Thismeansthatitmustbereturnedtoitslastknownconsistentstate.
This is the responsibility of the Transaction Manager, which uses the transaction log to
accomplishthistask.Therecoveryprocedureisdescribedlater.
The Transaction Processing Architecture
The first well-known transaction processing system was IMS (Information Management System),
which was introduced by IBM in 1968. It was followed by IBM’s CICS (Customer Information
Control System). TP monitors were later introduced by Tandem (Guardian), Digital (ACMS), and
Stratus. Open TP monitors include Tuxedo and Encina. Almost all commercial and open
databasestodayincorporateaTransactionManager.
The generic structure of the facilities to provide transaction-oriented computing is described
below.
TheTPMonitor
The Transaction Processing (TP) Monitor provides the application environment for transactional
computing.Thoughthereis nocommonlyaccepteddefinitionofaTPMonitor,ittypicallyprovides
theservicestomanagethefollowing:
 theuserterminalsconnectedtothesystemandwhicharethesourceofthetransaction
 thepresentationservicesprovidedtotheuserterminals
 the communication services that connect the user terminals to the system and that
interconnectmultiplesystemsinatransactionnetwork
 transaction context which must be passed from one transaction to subsequent related
transactions
 loadbalancinginmultiprocessorsystems
 heterogeneity if the application functions across different databases which may, in fact,
