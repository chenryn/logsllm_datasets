Blueprints for High Availability
May2007
Evan Marcus and Hal Stern are well known in the cluster community. Their book, Blueprints
for High Availability:Designing ResilientDistributedSystems,1is one of themostreferenced
books on this topic. With backgrounds from Sun Microsystems and Veritas, the authors
bringtothetablealonghistoryofhigh-availabilityexperience,whichtheyshareinthisbook.
Easy to read and thorough in its content, it is an excellent reference for anyone wanting to
learn about clustering technology. Also included are many insights into what is required
outsideoftheclustertoachievehighavailability.
Levels of Availability
Theauthorsdefineseverallevelsofavailability:
 Basicnonredundantsystems(thelowestlevel)
 Redundantdata(theuseofRAID-5ormirroreddisks)
 Systemfailover(active/backuppairs)
 Disasterrecovery(geographicdistributionofactiveandbackupsystems)
 Faulttolerance(whichisoutsidethescopeofthebook)
Theyalsodefineseveralavailabilityterms,suchasresiliency,availability,anddowntime.2
There are several ways in which a system can fail, thus affecting its availability. These include
hardware,software,environment,network,database,andWebserverfaults.
20 Key System Design Principles
The authors suggest twenty design principles that should guide any migration to a high-
availabilitysystem.Inorderofincreasingsignificance,theyare:
20.Spendmoney…butnotblindly. 19.Assumenothing.
18.Removesinglepointsoffailure. 17.Maintaintightsecurity
16.Consolidateyourservers. 15.Automatecommontasks.
14.Documenteverything. 13.Establishservicelevelagreements
1
Marcus, E., Stern, H., Blueprints for HighAvailability: Designing Resilient DistributedSystems, JohnWiley and Sons,
Inc.;2000.
2
Interestingly, they say that “Given today’s technology, [six 9s] is unachievable for all practical purposes and an
unrealisticgoal.”Clearly,theywerenotthinkingactive/active,thoughtheydomakeareferencetosimilartechnologylater
inthebook.
1
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

12.Planahead. 11.Testeverything.
10.Maintainseparateenvironments 9.Investinfailureisolation.
8.Examinethehistoryofthesystem. 7.Buildforgrowth.
6.Choosematuresoftware. 5.Selectreliable,serviceablehardware.
4.Reuseconfigurations. 3.Exploitexternalresources.
2.Oneproblem,onesolution. 1.KISS:Keepitsimple.
Data Management
Disks are the most likelycomponents to fail and must be redundant, either by using RAID arrays
orbyusingmirroredpairs.
The authors discuss several disk connection and storage methodologies, including SCSI and
Fibrechannel connections, multihosting and multipathing, disk arrays, JBODs (just a bunch of
disks),StorageAreaNetworks(SANs),andthevariouslevelsofRAID.
Logical Volume Management (LVM) is an important part of any storage facility. A good LVM
facility will provide online reconfiguration, will remove operating system limitations, will interface
withsystemmanagementtools,andwillsupportsoftwareRAIDifdesired.
A high-availability disk subsystem requires more than just redundant storage media. It also must
includeredundantdatapathsandcontrollers,redundantcabinetsandrackssothateachdiskofa
mirrored pair can be housed separately, redundant cables, and redundant power supplies and
management.
File system recoveryis a particularlycritical problem. InWindows, Unix, and Linux systems, data
in the disk cache is not flushed to disk immediately. If a crash occurs, that data will be lost; and
the file system will be corrupted. A file recovery utility must be run to repair the file system
(scandisk forWindows, fsch for Unix), and this can take a long time. If the file is journaled, i.e., it
provides a change log such as that maintained by transaction processing systems,file corruption
isnottypicallyaproblem.
Clusters
Failover should betransparentand quick,with minimum dataloss,minimum manual intervention,
and guaranteed access to data (that is, the application has access to the same copy of the data
followingfailover).
Though we think of failover as being from one server to another, it is really the application that is
failing over. In large servers, the application may be the unit of failover rather than the entire
computingsystem.
To this end, the authors define a service group as all those elements which make up an
application. This includes the application executables, one or more IP addresses by which
external users connect with theapplication, and the applicationdatabase.Notethatthecomputer
itselfisnotpartoftheservicegroup.Theservicegroupcanrunonanycomputersystem.
Though a cluster can be more complex, it is most often thought of as a pair of identical and
independent processors – the same hardware, the same operating system, the same database
management system, and so on. If the cluster is not homogeneous, failover becomes incredibly
complex.
Thereshouldbenosinglepointoffailureinthecluster.
2
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

Theclusteralsoincludesphysicalnetworkconnections,disks,andapplications.
NetworkConnections
Therearethreetypesofnetworkconnectionsneededbyacluster:
 A pair of independent heartbeat connections over which the applications send “I’m alive”
messages to inform each other of their health. Preferably, these are direct connections
andarenotroutedthroughanyexternalnetworkthatmightfail.
 Apublicnetworkwhichtheusersusetoconnecttothecluster.
 An administrative network which can guarantee the system administrator an access path
toeachserver.
Disks
Therearetwoclassesofdisksinacluster:
 Each processor in the cluster owns a private (or internal) disk. This disk includes the
operating system and all of the other software needed by the processor to function when
itisnottheactiveprocessor.
 Thepublic(orshared)diskholdsalloftheapplicationdata.Thepublicdiskmigratesback
and forth between the processors depending upon which is active. Only one processor –
theactiveprocessor–canaccessthepublicdiskatanyonetime.
Thepublicdiskmustberedundant.EitherRAIDarraysormirroredpairsmaybeused.
Applications
An important application consideration is licensing. Software vendors may charge additional
partialorfulllicensesfortheirsoftwarerunningonabackupsystem eventhoughonlyonecopyis
beingusedatanyonetime.
An interesting question is where should the application executables go? Putting them on the
public disk means thatthereis no versioningproblem.Thereis onlyoneversion of anapplication
onthesystematanyonetime.
Onthe other hand, if the application executables are onthe public disk,there is noopportunityto
do a rolling upgrade of an application. The system must be taken down to do an application
upgrade, thus destroying its availability unless there is dead time that can be scheduled for this
purpose.
Therefore,for24x7systems,theapplicationexecutablesmustberesidentontheprivatedisks.
The Heartbeat Network
The heartbeat network is arguably the most important network in the cluster. Without it, there is
no wayfor the backup system toknow about the active system’s health and therefore no wayfor
ittoinitiateafailovershouldtheactivesystemfail.
3
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

There are several reasons that one system may cease receiving heartbeats from the other
system:
 Theotherserverisreallydown.
 Thereisaheartbeatnetworkfailure.
 Theprocessthatgeneratestheheartbeatintheotherserverhasfailed.
 Theotherserveristooheavilyloadedandisrunningtooslowly.
If the heartbeat fault is other than a server failure, manual intervention may be required. One
severe problem with heartbeat failure is operation in split-brain mode. In this mode, both servers
think thattheyaretheactiveserversincetheythink thattheotherserveris down.Thiscancause
both servers to try to write to shared files, thus corrupting them. Manual intervention may be
required to correct this situation, though there are techniques for ensuring that split-brain mode
willnothappen.
Public Network
The public network is used by the users of the system to access the application. It should be a
redundantnetworksothatnosinglenetworkfailurewilldenyusersaccess.
Each application has its own set of virtual IP addresses that are used bythe users to access that
application. Should the application fail over to another server, its IP addresses go with it; and the
failoveristransparenttotheusers.
There are several ways in which a virtual IP address may be migrated to another server. A
gratuitousARPmaybeissued;3theARPwillredefinethemappingbetweenthevirtualIPaddress
andthenewserver’sMACaddress.TheMACaddresscanbemoved.Alternatively,theclientcan
be responsible for detecting that the connection is down and reconnecting to the alternate IP
address.
Consequently, a cluster provides a set of IP addresses. Each server will have its own IP address
to which the virtual IP addresses of the applications are mapped. In addition, each server will
have an administrative IP address to which system administrators can connect over the
independentadministrationnetwork.
Failover Management
Failover is generally managed by an independent software facility, the Failover Manager. The
Failover Manager may either be a commercial product or it may be a home-grown facility.
However,theauthorsnotethatthefailoverprocessisverycomplex;andhome-grownfacilitiesdo
nothavethematurity,depthoftesting,andsupportthatcommercialfacilitieshave.
The Failover Manager is responsible for monitoring the health of its system – the processor,
disks, networks, and software components. Should a problem be detected, a typical Failover
Managerprovidesseveraloptionsfortheactiontotake:
