collectively understand the exposure to risk
Findings Recommendations
1. The technology roadmap has a large number of initiatives within it. The
volume of IT initiatives is overwhelming and the business stakeholders
• The wider College IT governance structure needs to
have found it difficult to help IT to prioritise appropriately.
be reviewed and adjusted. Consider how the IT
2. The senior level IT governance - the IT Governance Subcommittee governance can be improved by delegating decisions
(ITGS) was set up two years ago. Meetings only occurred quarterly. at different levels based on scale, complexity and
This frequency combined with the large number of projects did not give investments e.g. director level and escalate to ITGS
sufficient time for the senior stakeholders to constructively challenge IT by exception or large investments.
plans, particularly those that improved services that were hidden from
• Prioritise and focus on completing the critical things
user view (e.g. storage backup)
first, free up some capacity to tackle critical things
3. IT has not been able to convince users on the need for doing full with the right level of attention
Disaster Recovery tests and negotiate windows for these to occur. The
• Review the financial model and funding approach for
infrastructure limitations mean that any such test will involve downtime
IT investments, aligned with the IT governance.
which business has so far refused, without properly understanding the
consequence. Had these occurred it would have demonstrated that the • Improve communication with the senior stakeholders
backup systems were not functioning correctly.. and get them to “own” the decisions
4. The information going into ITGS (“the booklet”) is often very detailed but
it is not presented at a level where senior stakeholders could fully
understand the implications of all the options presented.
5. Faculties have relinquished their IT budgets to KCL IT for pan College
IT infrastructure transformation projects. However, common solutions
have failed to satisfy all the diverse needs so Faculties perceive IT
investment decisions have forced on them (e.g. Inability to cope with
complex IoPPN research data directory structures)
13
© PA Knowledge Limited 2016

Review findings – Team management
The rapid growth in IT team size has meant that team members have been over
relying on processes and focussing narrowly
Findings Recommendations
1. The IT team has grown from c. 115 members in 2014 to approximately
350 members. This has created a reliance on a structured process-based
• The culture within the IT teams should move towards
approach to work together. Otherwise it would be impossible to keep on
a more collaborative approach that is not heavily
top of everything.
reliant on process alone. If the teams understand the
2. The teams are following processes mechanically, focusing on things that wider purpose of IT and how they help their
they have to do within their step of the process and not thinking about the colleagues across the College, then they are more
wider implications of what services mean to the business (e.g. key likely to collaborate and engage with other teams in IT
members of the IT team were unaware of the fact that admissions portal rather than mechanically following their own bit of the
data was missing even after several weeks of the outage occurring). process.
3. Large number of initiatives are competing for attention from the IT teams • The overall technology strategy and road map for
(specifically platforms team). The teams are not clear on the priorities priorities should be made very clear so that all
and keeping a number of things running at the same time. As a result the stakeholders and teams know where to focus effort
design decisions and the implied risks did not cascade well enough (e.g. and how their work helps deliver the College’s goals.
the decision taken to reduce the resiliency of the storage hardware to
improve performance). The team are not able to fully mitigate all the risks
and act on them appropriately.
4. The lack of awareness of business context meant that the IT teams
misinterpreted business risk (e.g. the decision not to independently
backup some directories to tape).
5. The daily reviews and other such procedures implemented to catch
things falling through gaps did not work. The teams followed process
without awareness of the wider context (e.g. Tape backups were reported
as completing rather than as being successful giving a false sense of
security).
14
© PA Knowledge Limited 2016

RECOMMENDATIONS
15
© PA Knowledge Limited 2016

Summary Recommendations [1 of 2]
Theme Issue Recommendation
• Backup architecture has been in transition for a number of
years and has complexity.
• Migration to Slough has takenlonger than initial estimate of a • Backup coverage must be reviewed and if necessary tape
year consequently delayed adoption of a clean back-up library capacity increased, even if only required for an interim
strategy. period. (Note: This has now occurred)
Technology • Tape back ups failed regularly and root cause not fixed. • Regular system recovery tests
management
• Some data consciously not backed up due to capacity
constraints in tape back-up
• Daily Service Reviews not effective as checking mechanism • The Daily Service Review update coverage must be revised
as updates on back up status were not being reported and communicated so that all team members understand the
correctly. significance to the business of each item in the review.
• Develop and communicate clear policies and provide
• Users stored valuable research data in shared drives, that IT guidance on how best to use data services from IT. Ensure
Data did not know that the IT data services are linked to these policies and meet
management • No guidance or policy for appropriate data storage the user requirements.
• IT data archive service is not known to users • Support this with a coordinated college-wide culture change
programme so users do use these services in the right way
• The wider College IT governance structure needs to be
reviewed and adjusted,decision making delegated based on
• IT is doing many things at once, this overwhelms complexity, scale and investments.
IT
stakeholders • Prioritise and focus on completing the critical things first, free
Governance
• Insufficient time for senior IT governance to constructively up some capacity to tackle critical things
and decision-
challenge IT plans • Review the financial model and funding approach for IT
making
• IT were not able to negotiate windows for DR tests investments, aligned with the IT governance.
• Improve communication with the senior stakeholders and get
them to “own” the decisions
16
© PA Knowledge Limited 2016

Summary Recommendations [2 of 2]
Theme Issue Recommendation
• IT is distant from the users and engagement is reliant on
process • IT must build a closer collaborative relationship with the
Business
• IT do not understand the needs of different user groups and business
relationship
are perceived as lacking empathy • Adjust the internal IT culture and adopta relationship based
management
• The culture is not aligned with user expectations hence they approach for user engagement, less reliant on process alone.
disengage
• The culture within the IT teams should move towards a more
• IT teams following process mechanically with a narrow focus collaborative approach that is not heavily reliant on process
on their own work alone.
ITteam
• Too many initiatives competing for attention, priorities not • The IT teammembers should be educated about the overall
management
clear technology strategy and roadmap, priorities made very clear
• Hand-offs and decisions not properly understood by team so that they know where they should be focusing effort and
how their work helps the wider IT and College goals.
17
© PA Knowledge Limited 2016

APPENDIX
I. List of interviews
II. Incident timeline
18
© PA Knowledge Limited 2016

Appendix I – List of interviews
Role
IT Business Assurance Manager
Project Officer, King's Futures
Chief Information Officer
Director of Admissions & Registry Services
Director of Real Estate Management
Business Continuity Manager
Chief Operating Officer (Arts & Sciences)
Assistant Chief Operating Officer (Arts & Sciences)
Director of Management Accounting
Director of Administration (Arts & Humanities)
Director of Administration (IoPPN)
Director of Planning and Service Transformation
IT Delivery Manager
Head of Transition & QA (IT)
Director of Marketing
Head of End User Services (IT)
Director of IT Governance
Head of Platforms (IT)
Hed of Architecture (IT)
Director of Library Services
Associate Director of Library Services (Collections & Research)
Chief Accountant
President, King's College London Students' Union
Communications and Campaigns Director
Compute & Storage Manager
Director of IT Procurement
IT Risk & Continuity Manager
Director of IT Solutions
Compute & Storage Engineer
Director of Strategy & Operations (Fundraising)
Head of Operations (Fundraising)
Interim Executive Dean of the IoPPN
19
© PA Knowledge Limited 2016

Appendix II – Incident timeline
Objective of this Appendix
The incident timeline presented overleaf is a high level
depiction of the incident from the start on Monday 17th Oct until
the BCP Silver team handed over the recovery and restoration
work to the respective operations teams in the week ending
Friday 25th Nov.
The top half of the timeline shows the events and when the
systems started to come back.
The bottom half of the timeline shows how the incident was
being managed and led and the structure of the BCP group.
IT did a pretty good job of managing the actual incident. There
was a structured approach and all the right people were present
in making the key decisions with respect to technology actions.
The recovery work was hampered by wider issues which we
have highlighted in the main report.
20
© PA Knowledge Limited 2016

IT P1 Incident
18/10 18/11 25/11
Routine1 7 H/1 W0 failure CrB iti IC c naP itl i aIS n ti eclv dide er nt IOPPN core te2 a6 m/1 0 set up 18/10 - 18/11 StB oC odP dS oil wve nr , d wo aw tcn hg inra gd be rd ief IT P1 Closed?
Silver BCP
17/10 24/10 31/10 7/11 14/11 21/11
15/10/16 26/11/16
18/10 - 24/10 2/11 - 9/11
Restore services 27/10 - 4/11 Shared Drive Recovery
10/19 27/10 Restore services 8/11 Respective business Operations teams leading
BCP team visit to Drury Lane recovery work for their impacted areas
Decision to delete 25/10 4/11 U Drive restored
all logical volumes
1st set of services restored 26/10 All main services restored; 11/11
20/10 Severity of Shared drive loss J: Drive restored R: Drive restored
Priority services identified + IOPPN impact understood (whatever was possible)
to restore 1st
Shared Drive Recovery IOPPN (forensic recovery) + other sources
BCP Silver Lead Ian T
IOPPN Recovery: Richard B
Nick O’D
Shared Drive & IOPPN
Recovery Group : Laura C
IT Lead
Trevor B Mark K is the point person at
Gareth W Denmark Hill
IOPPN Recovery Group: IT hit team: Mark Keep (with TB)
BCP Silver Team
SED
Impacted user SED BCP/ Recovery Recovery Core BCP Team
community group Group Lead: Ian T (initially Nick O’D) Prof.
PT Services Professional
Services Response
Recovery
team
Group
IT Incident Shared Drive/
IT Incident Response Group
Response IOPPN
Sr.IT Lead Faculties
Group Recovery
Gareth Wright Impacted user
NL/ GW/ TB Group
community
Inc. Mgt
BCP Critical Incident Service centre
Silver Faculty response IOPPN Recovery
Core IT Tech. Team IOPPN IT hit
teams Group
Drury Lane HP team Impacted user
(compute & storage team) 21 community
Impacted user
© PA Knowledge Limited 2016
community

The hardware failure in Strand HP 3PAR lost the primary back up data, creating a
reliance on secondary tape back up and these were not reliable
1. Some (but not all) of the virtual machines were backed
up using the long term strategic solution (Veeam).
(eg.F si hle eS t do rir va esg e (egO wt eh be r iA erp skp etl tii cnc .ga ),t i 3o rdn ps En (t ee gr p Sr Ii Ts Se A PUpp Rl Eic ea tt ci .o )ns Coll (a eb go Ora ft fi io cn s 3y 6s 5t )ems 2. T voh le mop ee lr ea vt ein g ns ays pt se hm tl se (v 2e nl s ln ea vp es l)h bo ets ( g1 s bt ale cv ke el d) a un pd
ar d , User , m s ta e arty , e u l s o d in in a
defined systems)
separate partition within the same HP 3PAR machine.
3. The back up data (above) was not replicated. Solely
Software 1 Software Office 365
(V sir otu fta wl am rea c ah pi pn le ics a r tu ion nn si )ng (V sir otu fta wl am rea c ah pin pe lics a r tu ion nn sin )g Service provided reliant on the same HP 3PAR machine in Strand for 1st
Legacy systems Virtualised databases 3 Virtualised databases and other by Microsoft level and 2nd level back up options.
(eg Oracle and other compatible
compatible data
database) data
4. Legacy workload (eg., oracle database, Solaris hosts,
Controllers
4 for adaptive 2 VEEAM back
optimisation up solution physical SQL & File cluster nodes, physical rack
Fast Fast + Slow Fast Fast + Slow servers, solaris and workloads currently incompatible
Slow Slow
with Veeam) was solely reliant on the Netbackuptape
5
Tape back ups back up solution.
(ULCC or backed up
to ULCC regularly) - Some data was never backed up due to capacity
constraints on the Netbackup tape solution.
HP 3PAR converged storage HP 3PAR converged storage
- Backup jobs failed regularly, some repeatedly
in Strand DC in Slough DC
- Shared drive data was using the Netbackup option
Back up situation in Oct 2016 (at the time of the incident
5. Some data was being backed up by both Veeam and
Netbackup whilst some data was not backed up
anywhere on tape
The hardware failure caused the Strand HP 3PAR storage device to lose
all data that was stored in the machine. This meant that only available Some additional backups taken by a retired backup device
back ups were the tape drives. As the Netbackup solution did not work of legacy systems had been retained and it was possible to
correctly, shared drive data was lost and had to be recreated from other restore some useful data. This was lucky. Arguably the
sources. data should have been destroyed as it was on a retired
backup system that was known to contain confidential data.
22
© PA Knowledge Limited 2016

The immediate back up resilience is improved and will help avoid a similar level of
impact as back up options have been strengthened
1. All the virtual servers in both Strand and Slough are
being backed up using Veeam.
(eg.F si hle eS t do rir va esg e (egO wt eh be r iA erp skp etl tii cnc .ga ),t i 3o rdn ps En (t ee gr p Sr Ii Ts Se A PUpp Rl Eic ea tt ci .o )ns Coll (a eb go Ora ft fi io cn s 3y 6s 5t )ems 2. The back up data is being stored in separate disk
ar d , User , m s ta e arty , e
defined systems) storage and being replicating to the opposite side.
3. No longer reliant on volume level snapshots as sole
back up option for any data
(Virtual mS ao cft hw ina ere s running 1 (Virtual mS ao cft hw ina ere s running Office 365 4. Netbackupcapacity freed up by removing previously
software applications) software applications) Service provided
Legacy systems Virtualised databases 2 by Microsoft untested virtual workloads that have now moved to
Virtualised databases and other
(eg Oracle and other compatible
compatible data Veeam.
database) data
Controllers NetBackup is only being used for workloads that are
4 for adaptive 3 VEEAM back
optimisation up solution currently incompatible with Veeam. Any remaining
Fast Fast + Slow Fast Fast + Slow non-virtual servers and workloads, (eg. Solaris hosts,
Slow Slow
5 physical SQL & File cluster nodes, physical rack
Tape back ups 5 servers) are being backed up to tape at ULCC, either
(ULCC or backed up
to ULCC regularly) directly to ULCC, or to a local tape library in the
Strand which then duplicates the backup data to
HP 3PAR converged storage
in Strand DC HP 3PAR converged storage ULCC.
in Slough DC
5. All workloads that were previously not backed up to
tape, are now being backed up either to tape, or to
Veeam.
These steps ensure that data has been backed up and is available to be restored when needed. Without testing the recovery it
will be difficult to predict how well or how soon will the systems come back from a similar outage.
23
© PA Knowledge Limited 2016
|---|--|
| 0 | IT INFRASTRUCTURE 
RESILIENCY REVIEW
23 February 2017  |
| 1 |  |
| 2 |  |
