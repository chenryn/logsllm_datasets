Software Reliability Models
The Use of Defect Density as a Basis for the Prediction of Software Reliability
Dr.TerryCritchley
August,2013
Hardwarereliabilitycanbedefinedas:
Reliability. The ability of an item to perform a required function under given conditions
foragiventimeperiod.
A similar definition is applied to software reliability - performing the function it was designed to do over a
period of time. The inclusion of time in the definition implies that there will be a failure of some sort or
other at some time or other. As a result, most math functions relating to software reliability have a time
elementintheminasimilarwaytohardwaremodels,forexample,anequationoftheformR(t)=......
A number of models and sub-models, often with esoteric math, attempt to describe the development and
subsequentreliabilityofapieceofsoftware.
Software Reliability Models
Twoclasses ofmodels arementionedhere,althoughdifferentauthors break down themodels indifferent
ways:
 TheSoftwareReliabilityGrowthModel(SRGM)usestimebetweenfailuresasitsworkingentity.
 TheDefectDensity(DD)model,ordefectdensitypredictionmodel,usesfaultcountorfailure
intensity asitsworkingentity
Thelattermodelisthesubjectofthisdiscussion.
The Field
The field of reliability is closely packed with models and distributions to predict software reliability
characteristics.Themodelsstartedinabout1972withmodelsbyShoomna,TusaandSchneidwind.They
now number over 200 types, including Gompertz, Rayleigh, Gumbel, Gamma-Lomax, Goel-Okumoto,
Hossian-Dahiya,Yamada(exponentialandRayleighdistribution forms),Weibull andLogNormal etc.
Tomakethingssimpler,mostpredictionmodelssharethefollowingcharacteristics;
 assumptionsandriders
 factorsinvolved
 amathematicalfunctionwhichrelatesthereliabilitywiththesefactors
 calibrationofthemodelwith'facts'ondefectsortimeelementsinexistingsoftware
 useofthemodelandsubsequentverificationinnewsituations
None of the models, however many variations and parameters it has, can be used in all situations since
no model is complete, completely verified or universally representative. It is a matter of 'choose your
weapon'whenduelingwithanyparticularsoftwaresituation.
1
©2013SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Defect Density Model
Defect density is a measure of the total of confirmed defects divided by the size of the software entity
being measured. There are definitions of faults, errors, and so on, but in software modeling most people
settleforthewordbug,whichisunderstoodbyall.
Programs are usually composed of modules which, in turn, are composed of instructions. Size is an
importantparameterandisoftenexpressedaslinesofcode(LOCorKiloLOC-KLOC).
Defectscancoveramassof'sins'or'bugs,'theoriginsandbreakdownof whicharelistedinthefollowing
table;
DefectType %ofFaults
Logic 37
InterprocessCommunication(IPC) 13
HardwareInterface 2
FunctionalDescription 2
DataHandling 6
DataDefinition 4
Computation 2
UserInterface 2
Non-reproducible 2
TestHardware 6
SoftwareInterface 6
Requirements 2
NotaDefect 6
Module/interfaceImplementation 4
Moduledesign 6
Table1: DefectDistributionbyType
The Failure/Defect Density Models
Themodelshavequiteesotericnamesandaselectionofthemfollows;
 GoelOkumotoNon-homogeneousPoissonProcessmodel(NHPP)
 MusaExecutionTimemodel
 MusaOkumotoLogarithmicModel
 GoelGeneralizedNHPPmodel
 ShoomanExponentialmodel
 GeneralisedPoissonmodel
 IBMBinomialandPoissonmodel
Wewillcoveronlythefirstthreemodels,withtwocasesoutlinedfortheMusamodels.
The fault count models are concerned with the number of failures seen or faults detected in given testing
intervals or 'units' - calendar time, execution time, number of test cases and so on. When faults are
removedfromthesoftware,thenumberoffailuresperunitofmeasurementwilldecrease.
Twowaysofmeasuringthereliabilityofsoftwareare:
 measurethetrendofcumulativefailurecount (SRGMmodel
 measurethetrendofthenumberoffailuresperunittimedefectdensity

where is the time in execution of the programme. We are interested in the second case of defect
density or failure count. Defects occur in software from the first coding stages through to the end of life
(EOL) of a program and it is desirable to be able to make prediction about new, developing software
basedondatafromexisting,workingsoftware.
2
©2013SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

CommonTermsUsedinMostModels
N(t),M(t) Totalnumberoffailuresexperiencedbytimet
P(N(t)=n) Theprobabilityoftherebeingnfailuresbytimet
(t) Numberoffailuresexpectedbytimet,thus(t)=E[M(t)]
(t) Failureintensity,whichisthederivativeofthemeanvalue
function,thatis (t) =d/dt,thenumberoffailures/unittime

t, Elapsed(calendar)timeandCPUtimerespectively
N,N0 Initialnumberoffaultspresentinthesoftwarepriortotesting
z(t) Per-faulthazardrate,whichrepresentstheprobabilitythatafaultthathadnotbeen
activatedsofarwillcauseafailureinstantaneouslywhenactivated.
Φ A constant value for z(t) assumed by many models.
Goel-OkumotoNHPPModel
Thismodelassumes thatfailures inasoftware system occur atrandom times dueto faults. Based on the
study of actual failure data across many systems, Goel and Okumoto proposed the following structure to
themodel;
Themodelassumesthefollowing;
 theexpectednumberoffailuresobservedbytimetfollowsaPoissondistributionwithmeanvalue
(t)
 the number of software failures that occur in interval (t+t) is proportional to the number of
undetectedfaults,(N-(t))
 there is no correlation between the numbers of failures detected in the failure intervals (0,t )
1 ,
(t ,t ) (t ,t ) thatistheyareindependent
1 2 ,.... n-1 n ;
 thefaultremovalprocesswhenfailuresaredetectedisinstantaneousandperfect
 theper-faulthazardrateisfixedataconstantgivenby
MusaModels
John Musa's model has two forms, the basic and the logarithmic (developed with Okumoto). The
assumptionsinMusa'sbasicmodelare;
 software faults are independent of each other and distributed with a constant rate of encounter
(equidistantintime)
 a mixture of instructions and the execution time between failures is large compared with the
instructionexecutiontime
 thesetsofinputdataforeachrunofthesoftwareareselectedatrandom
 allfailuresareobserved
 thefaultcausingthefailureiscorrectedimmediately;otherwisearecurrenceofthatfailureisNOT
counted.
There are different treatments of the Musa models.1 One is covered in the following discussion in
subsection A and the standard treatment of the two Musa models in B. and C, followed by a schematic
graphinsubsectionD.
1
http://incoming-proxy.ist.edu.gr/stfs_public/cs/msc/ReadingMaterial_MMSE-
SEPE_oct2011/Software%20Quality/Software%20Reliability%20Model%20Study.pdf
3
©2013SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

A.InitialSoftwareReliability
The 'owner' of the paper from which this mathematics is quoted is the only identifier I have for the author
ofthepaperreferencedinthefootnote.
TheRomeReliabilityToolkit2suggeststhefollowingequationfortheinitialsoftwarereliability:
where;
r=processorspeedininstructions/second
K=faultexposureratio(aconstantasfarasweareconcerned)

N =Totalno.offaultsintheinitialprogram(at =0)
0
I =No.ofobjectinstructionswhichisdeterminedbyLOCx expansionratio
Object instructions are in essence machine instructions. The number of such instructions in say 'L' lines
of code will depend on which language the instructions are in. Higher level languages like COBOL will
generate lower level instructions in Assembler code, so a 5000-statement programme in COBOL will
generate more machine (or object) instructions than an assembler program of the same size. This is
illustratedinthetablebelow(takenfromtheRomeReliabilityToolkit1993).
ProgrammingLanguage ExpansionRatio
Assembler 1(baseunit)
MacroAssembler 1.5
C 2.5
COBOL 3
FORTRAN 3
Ada3 4.5
Table2: MusaModel: ExpansionRatios
Becauseoftheageofthesefigures(1993),itishardtoseehow4GLswouldbehandledinthesemodels.
Followingthis,theproceduredevelopsasfollows:
Let us call the ratio r/I = k, which is used in the following equations. The failure intensity in Musa's Basic
Executionmodelisgivenby;

ThislooksthesameastheGoel-OkumotoequationexceptthefactorKfreplacesthe ofthatmodel.
B. Musa'sBasicExecutionModel
Thisusestheassumptionthatthedecreaseinfailureintensity(rate)isconstantandstatesthatthefailure
intensityisafunctionoftheaveragenumberoffailuresexperiencedatanypointintime,thatis,the
failureprobability.Thisisexpressedintheequationsfollowing.
Assumptionforthismodel:
Thatis,thefailureintensityisafunctionoftheaveragenumberoffailuresexperiencedatanytimegiven
pointintime.
2 Obtainablefromwww.quanterion.com
3 ..whichbegatBlanguagewhichbegatC.Smallworld.
4
©2013SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Equation1: MusaBasicModelFailureRate/Intensity
failureintensity
where
 initialfailureintensityatthestartofexecution
averagenumbersoffailures/unittimeatagivenpointintime
 totalnumberoffailuresoveraninfinitetime
C. Musa-OkumotoLogarithmic Model
A base assumption for this model is expressed as a decreasing rate with time, that is, expressed as
follows;

Equation2: Musa-OkumotoLogarithmicModelFailureRate
isaparameterrepresentinganon-lineardropinfailureintensityinthismodel.
D. GraphicalRepresentation
Agraphicalrepresentation ofthesemodelsshowingsomeoftheparametersusedintheequationsabove
canbefoundinFigure2.
Musa Models – Reliability OverTime
(t) FailureIntensity
l (L) Logarithmic Model(L)
0
Basic(B)
l (B)
0 Model
m(t) Mean
Failures
n
0
Figure2: BasicandLogarithmicModels-FailureIntensityvs.Time
5
©2013SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

The relationship between the failure intensity (rate) and the reliability of the software is given by the
expression(similartoitsexponentialhardwarecousin);
Thereareanumberofothermodelsinthisclasswhicharelistedbelow;
 GoelGeneralizedNHPPmodel
 ShoomanExponentialmodel
 GeneralizedPoissonmodel
 IBMBinomialandPoissonmodel
ThesecanbefoundinnumerouspapersandpresentationsontheInternet.
Times Between Failure Models
This is another group of models, each tailored for the situation whose data fits the model. They are not
thepurposeofthispaper.
 Jelinski-Moranda
 SchickandWolvertonModel
 GoelandOkumotoImperfectdebuggingmodel
 Littlewood-VerrallBayesianmodel
So What?
Michael Lyu has this to say about models and their usefulness. The chapter numbers mentioned below
refertothefollowingbook,editedbyhim;
 http://www.cse.cuhk.edu.hk/~lyu/book/reliability/
'For the 'so what' question, the answer is two-fold. First, if there is no software reliability
measurement, there is no evidence of a quantifiable software development process which can be
engineered and improved. The application of software reliability models indicates the maturity of an
underlying software development process from an industry viewpoint. Secondly, even though we
cannot guarantee the accuracy of an SRGM for a particular project in advance, we can still use the
SRGM prediction results to confirm the readiness (or otherwise) of the software project in terms of its
reliability. Chapter 9, for example, takes this point further for industry practice. Besides, whether an
SRGMisapplicablecanalsobetestedbyatrendanalysis,whichishandledinChapter10'.
Software vendors are interested in this kind of 'crystal-ball' gazing to assess the quality of new outgoing
softwareandresourceplanningfor themaintenancestageof thesoftware's life,thatis,betweenshipand
EOL.
Software Development Defect Plot
The number of defects in the life cycle of software development has been found to conform to a
numerical distribution represented by the Rayleigh equation, a subset of the ubiquitous Weibull
distributionwellknowninreliabilitycircles(Rayleigh=Weibullfor(m=2)forthoseintheknow).
The linear curve represents the observed data and the curve is a fit of the Rayleigh distribution to these
results.
6
©2013SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Defects
Observed
Rayleigh
0.5 1.5 Development Stage 4.5 5.5
Figure3 RayleighCurveShowingDefectsvsDevelopmentStage
ARayleighcurve andtime'slots'forthevariousstagesofsoftwaredevelopmentareshownbelow;
Software Stage Timescale (relative)
HLD-HighLevelDesign 0.5
LLD-LowLevelDesign 1.5
Coding-Implementation 2.5
UT-UnitTesting 3.5
IT-IntegrationTesting 4.5
ST-Systemtesting 5.5
Table3 TimescaleofDevelopmentSoftwareCycle
The Rayleigh curve model shows the number of defects detected in the six stages of development
outlinedincolumn1inTable2above. Other modeldistributions cover thetesting/deploymentphase,the
exponentialandS-curvemodels.
NOTE:TheRayleighpdfandcdffunctionsareshownbelow;
and
Reliability Prediction Software
There are many different companies that sell reliability prediction software packages and there are many
different reliabilityprediction methodologies, handbooks and guidelines (MIL-HDBK-217F, G, H, 217Plus,
Telcordia SR332, etc). As an example, see the URL below for a description of the SREPT (Software
ReliabilityEstimationandPredictionTool):http://people.ee.duke.edu/~kst/srept.html
The author would like to thank Dr. Bill Highleyman (editor of www.availabilitydigest.com)
andMichaelLyufortheirreviewsandinputs.
7
©2013SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Dr. Terry Critchley is a retired IT consultant living near Manchester in the UK. Terry studied Physics at
ManchesterUniversity(usingsomeofRutherford'soriginalequipment!)andgainedanHonoursdegreein
Physics, followed five years later with a PhD in Nuclear Physics. He then joined IBM as a Systems
Engineerandspent24yearsthereinavarietyofaccountsandspecialisations,latterlyjoiningOraclefor3
years. Terry joined his last company, Sun Microsystems in 1996 and left there in 2001. In 1993 he co-
authored a book on Open Systems for the British Computer Society and is currently writing a book on
high availability, tentatively entitled “Availability Management.” He is also 'mining' tons of his old material
forhisnextbook.
8
©2013SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com