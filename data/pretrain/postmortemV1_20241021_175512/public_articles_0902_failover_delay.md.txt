Should Hope Trump Failover?
February2014
Critical IT services are typically protected by redundancy. Each production system is backed
up by another system in the data center or by a system located in a geographically remote
datacenter.Shouldtheproductionsystemfail,thebackupsystemisbroughtintoservice.
Maybe!Whatifthebackupsystem won’tcomeup?Now youhavetwosystemsdown.Thisisthedreaded
failoverfault.Failoverfaultsareamajorconcernforsystemsthatmustachievehighavailability.
Failover Faults
Failover faults occur all too frequently.1 A primary reason for this is that failover testing is risky and
expensive. In general, totestfailover,theproductionsystem mustbetakendown and the backupsystem
brought into production. However, depending upon how the backup system is synchronized with the
productionsystem,thisprocess–ifitworks–couldnormallytakeminutestohours.
If the backup system is a cold standby and its database must be loaded before applications can be
started,thiscantakehours.Ifthebackupsystem isawarmstandbywithareplicateddatabasethatisup-
to-date, all that is required is to bring the applications up. This can take minutes to hours. If it is a hot
standby with a replicated database and with all applications running, failover might be able to be done in
minutes. All that is required is the reconfiguration of the network connecting the users to the processing
systems.
Duringthefailover,theIT servicesprovidedbytheapplicationsbeingtestedaredown.Ifthesearecritical
applications, exhaustive planning is required to do a failover test. An appropriate time window must be
determined(usuallylateatnightthroughearlymorning ona weekend).Usersmustbealerted inadvance
that the system will be down for maintenance for an estimated period of time. Fallback procedures must
be in place to return to the production system when the test is complete, whether the test is a success or
a failure. There must be coordination with partners who interface with the system to be tested. Most
importantly, there must be key personnel available during the test who understand every aspect of the
system.Ifthebackupwon’tcomeup,itisthesepeoplewhocantracetheproblemandfixit.
Theresultisthatmanycompaniesdonotdocompletefailovertesting.Theymaytestonlycertainaspects
of failover. They do not really know whether their backup system will come up or not. If their production
systemfails,theydependuponfaithandhoperatherthanthoroughtesting.
1JPMCDownedbyReplicatedCorruption,AvailabilityDigest;November2010.
http://www.availabilitydigest.com/public_articles/0511/jpmc.pdf
PoorDocumentationSnagsGoogle,AvailabilityDigest;April2010.
http://www.availabilitydigest.com/public_articles/0504/google_power_out.pdf
TripleRedundancyFailureontheSpaceStation,AvailabilityDigest;November2007.
http://www.availabilitydigest.com/public_articles/0211/iss_tmr_failure.pdf
1
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Failover Delay
The result of inadequate failover testing is failover delay. Failover to the backup system is a serious
decision with several major consequences, including an extended outage if there is a failover fault.
Consequently, the failover decision is typically made by senior management. The first thing that they will
wanttoknowishowlongitwilltaketorestoretheproductionsystem.Ifthistimeisexpectedtobeshorter
than or comparable to the time to failover, it is likely that management will chose to wait until the
productionsystemisreturnedtoservice.
If the production recovery time is misestimated and it cannot be brought back into service in a timely
fashion, then the decision to failover will be made. This does nothing but extend the outage. If there is a
subsequentfailoverfault,thehelp-desktelephoneswilldefinitelyberinging.
Thisleadstoaninterestingquestion,whichisreallyadilemma:
Howlongshouldittaketomakethefailoverdecision?
The answer to this question lies in large part to the degree of failover testing that has been practiced. If
there had been only cursory failover testing, then management will be reluctant indeed to authorize a
failover.Ontheotherhand,iffailovertestinghasbeen rigorous andrecent,failovermaybeauthorizedas
soonasthereisanyquestionaboutreturningtheproductionsystemtoservicewithinthefailovertime.
WerecentlypostedaquestiontoourLinkedInContinuousAvailabilityforum,whichasked:
“How long should you wait until you give up on system restoration and attempt a failover? Does your
organization have policies for this? How does your confidence in your failover testing procedures
affectthetime you arewillingto waitbeforeattemptingafailover?Howoftenhave youexperienceda
failoverfault?”
OneinterestingresponsefromChrisPetrerelatedarealexperience:
“Iwasinvolvedinthepostmortemofamajoroutagewheretherewasadelayindeclaringafailover.I
don't think they had any hesitation to declare a failover. There was an unusual situation whereby
transactions were still flowing very slowly so the focus was on diagnosis/correction. They eventually
made the decision to go stand-in which worked, but by then the damage was done. If it was a clear
outage,theywouldhavebeenbetteroffandcutoverimmediately.”
Perhaps in this case, the organization would have been better served to do its diagnosis and correction
after a successful failover. If the organization had been confident in its ability to failover, this would have
aneasydecisiontomake.
How Critical to Availability are Failover Faults?
Are failover faults really a serious availability issue? A little math answers that question (go to the end of
thissectionifyouaremathematicallychallenged).
Consider adualsystem –onea production system andone abackupsystem.If theavailabilityof eachis
a,theprobabilityofasinglesystem failureis(1-a).Theprobabilityofadualfailure(theproductionsystem
fails and the backup is currently down as well) is (1-a)(1-a). The availability of the system is [1 - (1-a)2].
The availability cannot get any better than this – this is what the system manufacturer has given us. We
callthistheinherentavailabilityoftheredundantsystem.
Butadualsystemfailureisonlyonecauseofsystemdowntime.Therearetwoothersignificantcauses:
 Thesystemisintheprocessoffailoverover(secondstohours).
2
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

 Thefailoverfails.
Let
mtrbethemean(average)timetorepairasystem.
mtfobethemeantimetofailover.
dbetheprobabilityofafailoverfault
Itcanbeshownthatthetrueavailabilityofthesystemis2
1-(1-a)[1-(a-mtfo/mtr-d)]
This is equivalent to the inherent availability of the system, but the system behaves as if it is one system
with an availability of a and a second system with an availability of a reduced by failover time and the
probabilityofafailoverfault.
Ignoring failover time, if the system availability is three 9s (0.999) and the probability of a failover fault is
.01 (1% - many would love to have 99 failover attempts out of 100 succeed), the second system has an
effective availability of only two 9s. The overall availability of the dual system has been reduced from six
9stofive9s–itisanorderofmagnitudelessreliable.
Yes,failoverfaultsaresignificanttohighavailability!
A Major Cause of Failover Faults
One of the main reasons for failover faults is configuration drift. Typically, the backup system must be
configured exactly the same as the production system in order for it to come up properly. However, the
production system is continually being upgraded software-wise. There are three classes of software
objectsthatmustbekeptsynchronized:
 Audited Databases: These are the application databases. They are typically transaction oriented
withahighrateofactivity.
 Unaudited Files: These are ancillary configuration files used by the applications. They are fairly
static.
 Configuration Changes: Various utilities are used to modify and manage the configuration of the
softwaresystems.
All of these software objects must be kept synchronized between the production system and the backup
system. Otherwise, the backup system may fail to properly process transactions. There are typically
utilities to aid in the detection of configuration errors in the backup system and to automatically keep the
backupsysteminsynchronismwiththeproductionsystem.
For instance, in HP NonStop systems, there are many data replication products to replicate in real time
changes made to the application databases, including those from Gravic (Shadowbase), Oracle
(GoldenGate), Network Technologies (DRNet), and Attunity (Replicate). Unaudited files are kept
synchronized by FileSync from TANDsoft or AutoSYNC from Carr Scott. Configuration changes can be
replicatedbyTANDsoft’sCommandStreamReplicator.
Regardless of the systems used, it is mandatory that utilities such as these be used to maintain the
backupsysteminsynchronismwiththeproductionsystem.Otherwise,theorganizationwillalwayshavea
highincidenceoffailoverfaults.
2SimplifyingFailoverAnalysis–Part1,AvailabilityDigest;October2010.
http://www.availabilitydigest.com/public_articles/0510/failover_analysis.pdf
3
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Eliminating Failover Faults
There is a way to eliminate failover faults, and that is through the use of active/active systems.3 An
active/active system comprises two or more nodes, each of which is actively engaged in a common
application. They each have their own copies of the application database, and the databases are kept
synchronizedviadatareplication.
A transaction can be sent to any node in the application network and be properly processed. Should one
nodefail,allthatneedstobedoneistoreroutetransactionsfromthefailednodetoothernodes.Thiscan
be done in seconds, leading to very fast failover. Moreover, it is known that the other nodes are working
becausetheyareprocessingtransactions.Therefore,therearenofailoverfaults.
Another advantage of active/active systems is that the nodes in the application network are loosely
coupled. They do not have to have the same configuration. In fact, they can even be different systems.
Wolfgang Breidbach of Bank-Verlag, perhaps the true pioneer in active/active systems, built what well
maybe the earliest active/active system in 1988. It was a two-node system. One was an IBM mainframe,
andtheotherwasanHPNonStopsystem.4
In some cases, an application cannot be run in a distributed environment such as this. It must run on its
own system. In this case, the same result can be achieved with a “sizzling-hot” standby. A sizzling-hot
standby configuration is a two-node active/active system in which all transactions are routed to only one
node. However, the other node is completely active and ready to take over on an instant’s notice. It can
beperiodicallytested(likeeverysecond)bysimplysendingitatesttransactiontoprocess.
OntheLinkedInForuminresponsetoourquestion,Bank-Verlag’sWolfgangwrote:
“We are trying to avoid that failover stuff. We are a central access point for ATM- and POS-
authorization. So if our application is down, people will neither get money at the ATM nor will they be
abletopaybycardatashop.
As we are running active-active (meanwhile 4 active systems), there is no failover decision. If one
system is down unexpectedly, we do everything necessaryto get it online again but such an event is
onlyseriousandnotcritical.Irememberasituationafewyearsago.OnlateSaturdaymorningoneof
our systems went down because of a problem within the SNA product. Operation people called me, I
came in, took a dump and we started the system again. This took about 3 hours, if I remember
correctly. During that time we received only 2 calls requesting confirmation that the system was not
available, nothing else. No customer was affected. And even more important: no manual intervention
onoursidewasnecessary.
Of course this required of lot of regulations and organization in the past. But today we can be sure
that the application will be available without manual intervention even if one datacenter goes
completelydown.”
Interestingly,Chrisreplied:
“The major outage for this large Canadian Bank was back in late 2001 and I was selected to be part
of an external 12 person swat team of senior consultants and practice owners covering technologies
in use at the Bank for a major one-month long assessment and improvement engagement. My focus
covered anything Tandem (sorry ... HP NonStop) related. One of my recommendations for the final
reportdeliveredin2002wasinfacttogoactive-active.”
3WhatisActive/Active?,AvailabilityDigest;October2006.
http://www.availabilitydigest.com/public_articles/0101/what_is_active-active.pdf
4
Bank-Verlag–TheActive/ActivePioneer,AvailabilityDigest;December2006.
http://www.availabilitydigest.com/private/0103/bank_verlag.pdf
4
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Many banks, telcos, and other major companies with critical applications that just cannot go down have
gone to active/active systems. The Case Studies in the Availability Digest article archive5 have several
storiesaboutsuchsuccesses.
Summary
Failover faults are indeed a major factor in availability. They can easily reduce the availability of a
redundantsystembyanorderofmagnitude.
To reduce failover faults, it is imperative that means be taken to ensure that the backup system is trulyin
synchronismwiththeproductionsystematalltimes,andthatfailoverberegularlyandcompletelytested.
Theultimatedefenseagainstfailoverfaultsisactive/activesystems.Inthesesystems,itisknownthatthe
backup system is always available because it is, in fact, currently processing transactions. An additional
advantageofactive/activesystemsisthatnoconfigurationsynchronizationisneededbetweensystems.
5http://www.availabilitydigest.com/articles.htm
5
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com