Why Are Active/Active Systems So Reliable?
September2008
Active/activesystems1canachieveavailabilitiesofsix9sandbeyond.Six9sisanaverageofjust
30 seconds of downtime per year. These systems achieve such high availabilities by providing
very rapid recovery from faults – recovery times measured in seconds or subseconds. In fact, if
the recovery time is fast enough, users will not realize that there has been a fault. In effect, no
faulthasoccurred.
In redundant systems, recovery from the effects of a failed component is accomplished by
removing the failed component from the system and by continuing its functions with another
equivalent component that is operational. The result of this failover process is a reconfigured
systemthatcancontinueitsprocessingfunctions.
The classical method for failover is to bring up a backup system that has been idle or that has
been doing other work and to put it into operation to replace the failed system. This failover
process typically takes minutes to hours to restore system operation, depending upon how it is
done.
In contrast, an active/active system node1 bidirectional node2
comprises two or more processing nodes datareplication
appl data data appl
thatareallactivelyparticipatinginacommon A base base A
application. Each processing node has
active active
accesstoacopyoftheapplicationdatabase.
The database copies are kept synchronized
via data replication. When a change is made
to one database copy, that change is
AnActive/ActiveSystem
immediately replicated to the other database
copies.
Should a processing node fail, all that is required is to reroute the users that had been using that
node to one or more surviving nodes. This can be accomplished in seconds or less, resulting in
failovertimesthatmaynotevenbenoticeabletotheusers.
Failover timebecomes animportantfactor insystem availability.Furthermore,thereis always the
possibility that a failover will not work properly; and the entire system will be down until it can be
recovered.Wehavediscussedfailovertimeinseveralearlierarticlesaspartofothersubjects.2In
this article, we focus on failover time and demonstrate that it is the key to active/active system
reliability.
1WhatisActive/Active?,AvailabilityDigest;October2006.
2CalculatingAvailability–Failover,AvailabilityDigest;February2007.
CalculatingAvailability–HeterogeneousSystemsPart2,AvailabilityDigest;May2008.
1
©2008SombersAssociates,Inc.,andW.H.Highleyman

Availability
In review, we consider a redundant system to be one that comprises two or more processing
nodes.Theavailabilityofanodeinthesystemistheprobabilitythatitwillbeoperational.Let
mtbfbethemeantimebetweenfailuresofanodeinthesystem.
mtrbethemeantimetorepairanode.
abetheavailabilityofanode,whichistheprobabilitythatthenodewillbeoperational.
fbetheprobabilitythatanodehasfailed.
Thenthenodalavailability,a,is
mtbf 1 mtr
a  1 (1)
mtbfmtr 1mtr/mtbf mtbf
wheretheapproximationisvalidifmtr<<mtbf,whichistrueforourcase.
Also,
mtr
f (1a) (2)
mtbf
Failure Modes
We look at failure from the user’s viewpoint. If a user cannot perform his duties because of a
data-processing system malfunction, so far as he is concerned, the system is down. The
malfunction could be a system failure, or it could be degraded performance that makes it
impossiblefortheusertoeffectivelyfunction.Otherusersmaybeunaffected.But tothisuser,the
systemisdown.
For simplicity purposes, we will analyze only singly-spared, dual-node systems. That is, the
system comprises two processing nodes and can survive the failure of either node. The
relationships derived below are extended to n-node systems with s spares in the previously
referencedarticles.However,wedonotneedthatcomplexitytodemonstrateourpoint.
In the classic case, one of the nodes is the primary node. The other node serves as its backup.
Shouldtheprimarynodefail, the applications arefailedover to the backupnode. Anexceptionto
thisconfigurationisanactive/activesystem.Inthiscase,bothnodesareactive.Shouldonenode
fail,itsactivitiesarefailedovertotheotheractivenode.Wewilllookatbothofthesecases.
Weconsiderthreereasonswhyausermaybedeniedservice.
 Therehasbeenafailureofbothprocessingnodes(adual-nodefailure).
 One of the processing nodes has failed, and the system is in the process of failing over
(failover).
 Oneoftheprocessingnodeshasfailed,andthefailoverhasfailed(afailoverfault).
Thus,thesystemisdownif
twonodesfail(dual-nodefailure)OR
onenodefails,andthesystemisintheprocessoffailingover(failover)OR
onenodefails,andthefailoverfails(failoverfault).
Therefore,theprobabilitythatthesystemwillbedownis
2
©2008SombersAssociates,Inc.,andW.H.Highleyman

probability(systemdown)=
probability(dual-nodefailure)+probability(failover)+probability(failoverfault) (3)
Dual-Node Failure
A redundant system is configured with a certain number of spare
nodes. If enough nodes fail so that the spare nodes are
exhausted,andthenonemorenodefails,thesystemisdown.
node1 node2
In a dual-node, singly-spared system, if one node fails, the
system is still capable of providing its functions. It takes the
failureofbothnodestotakedownthesystem.
Dual-NodeFailure
Let
a=theavailabilityofanode.
The probability that either node will fail is (1-a). Therefore, the probability that both nodes will fail
is
probability(dual-nodefailure)=(1-a)2 (4)
Theprobabilityofadual-nodefailuredependsonlyupontheavailabilityofthenodes.Wetypically
can’t control node availability (short of buying nodes that have higher availability). Therefore, the
probabilityofadual-nodefailureiswhatitis.Wecallthistheinherentavailabilityofthesystem.
The system’s inherent availability, however, is reduced byfailover factors over which we do have
somecontrol.Weconsiderthesefactorsnext.
Failover
Shouldtheprimarynodein anactive/backupsystem fail,or shouldeither nodein an active/active
system fail,someor allusersmustbeswitched over tothe surviving node.This process is called
failover. We define mtfo as the mean time to failover – that is, the average time that it takes for
thebackupsystemtotakeoveroperations.
active tape tape standby active data data standby
node node node base base node
tapebackup virtualtape
mtfo=hourstodays mtfo=minutestohours
active data standby active data data active
node base node node base base node
contemporarycluster active/active
mtfo=minutes mtfo=seconds
FailoverScenarios
The amount of time that it takes to fail users over to a surviving node, depends upon the way in
which failover is implemented. In the early days of computing and still to a great extent today,
3
©2008SombersAssociates,Inc.,andW.H.Highleyman

magnetic tape is used to periodicallyrecord the current application database. During failover, the
last recorded version of the database is read from tape to the backup node, applications are
started, the node is tested, and the backup node can then be put into operation. This failover
processcouldtakehoursorevendays.
More recently, magnetic tape has been replaced with virtual tape, which is periodic disk-to-disk
replication of the database.With virtual tape, failover can typically be accomplished in minutes to
hours.
Cluster technology provides an active node and a backup node, each of which has physical
connections to a common database subsystem.3 Should the active node fail, the backup node
mountsthedatabasedisksandcontinuesprocessing.Recoveryistypicallymeasuredinminutes.
Inan active/activesystem,all thatneeds to be doneis toswitch users from thefailednode tothe
survivingnode.Thiscanbedoneinsubsecondstoseconds.
Thus, depending upon the redundant technology used, failover times can range from seconds to
hoursoreventodays.
Theanalysis of theprobabilitythatasystem willbe downwhileitis failingover is slightlydifferent
for active/backup systems than it is for active/active systems, but the results are the same. We
lookatthisnext.
Active/BackupSystems
In an active/backup system, there is no failover if the backup node fails. There is a failover onlyif
theactivenodefails.
The active node will fail on the average of once every mtbf hours. During that time, all users will
bedownforatimeofmtfo,where
mtfo=themeantimetofailover.
Thus,thesystemwillbedownwithaprobabilityofmtfo/mtbfduetofailover:
mtfo
probability(failover) 
mtbf
FromEquation(2),wecanwrite
mtr
mtbf 
(1a)
Therefore,
mtfo
probability(failover) (1a) (5)
