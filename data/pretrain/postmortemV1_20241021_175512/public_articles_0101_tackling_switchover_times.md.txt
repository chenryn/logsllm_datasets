Tackling Switchover Times
October2006
The biggest advantage of an active/active system is that failover is almost instantaneous – at
least, from the perspective of the user. However, the move to active/active can be a daunting
task. As a consequence, many companies are first trying to improve their switchover times from
hours to minutes and perhaps even seconds. This gives them time make the active/active move
sometimeinthefuture.
Two large enterprises which are currently undertaking this task are Sabre Holdings, a travel
productscompany,andMayoClinic.Theirstoriesaretoldbelow.
Sabre Holdings
TheCompany activepair backuppair
Sabre Holdings Corporation, headquartered in S88 S88
Southlake,Texas,USA, is amultibillion dollar publicly
listed company (NYSE TSG) that provides online
travel-related products such as Travelocity to the partition1
application application
public. Its applications include reservations, ticketing,
and the storage of profiles for its customers. Sabre
also provides distribution and technologysolutions for
theirtravelindustryclients.
Sabre operates a large heterogeneous data center active RDF backup
database database
utilizing NonStop servers for some of its critical data part1 part1
processing needs, The NonStop servers are
surrounded by many industry-standard servers
performing communications and other tasks. Sabre active RDF backup
takes on the responsibility for the customer interface database database
and all application development and outsources the part2 part2
datacenteroperationstoEDS.
S88 S88
Sabre’sDataCenter
WithinSabre’sdatacenter arefourNonStopfourteen- application partition2 application
processor S88 servers. These are organized as two
two-nodesystems,with onepair of systems beingthe
activepairandtheotherpairbeingthebackuppair.
The database is partitioned across the two databases TheSabreProductionSystem
ofapair.Thebackupdatabaseiskeptinsynchronism
1
©2006SombersAssociates,Inc.,andW.H.Highleyman

withtheactivedatabaseviaHP’sRDF(RemoteDataFacility)datareplicationproduct.
All four systems are used in a load-sharing configuration, with applications running on all
systems. However, since RDF target databases cannot be used for update purposes,
applications running on the backup pair use the active databases. During busy hours, the
systemsarehandling250to300transactionspersecond,manyofthembeingquitecomplex.
Sabre also runs a two-system test facility configured in the same way except that the databases
arenotpartitioned.
ItsEarlySwitchoverExperience
Sabre’s initial efforts were aimed at reducing switchover times for planned maintenance. Its goal
was to achieve planned switchover times in the order of minutes. The early switchover practice
wasasfollows:
 Hold(orreject)allinboundtraffic.
 Stoptheapplicationprocessesontheactivesystem.
 AllowTMF(HP’sTransactionMonitoringFacility)tocompleteontheactivesystem.
 Resetthedatabaseaccesscontrollists(ACLs)toswitchtherolesoftheactiveand
backupdatabases.
 Starttheapplicationprocessesonthebackupsystem.
 Releasetheinboundmessagesthathadaccumulated.
At this point, the roles of the active and backup systems had been reversed; and the system that
waspreviouslyactingasbackuptookoveractiveprocessing.Servicewasrestored.
Much to Sabre’s chagrin, switchover times turned out to be in the order of four hours.
Investigation showed that in addition to software and script bugs and other operational errors
whichcouldbecorrected,thereweresomefundamentalflawsintheswitchoverprocedure:
 Anexcessofmanualvalidationofprocedureresultswasrequired.
 Some batch jobs were scheduled as TMF was trying to complete, thus keeping it from
completing.
 TMF would not complete until all transactions were complete. Therefore, it was held up
bythelongestrunningtransaction.
 Applicationstartuptimeswereexcessive.
 Keyindividualswerenotavailablewhenproblemscameup.
TheCurrentProcedures
Usingthisexperience,Sabremadeseveralchangestominimizeitsswitchoverproblems:
 Itrewroteapplicationstoeliminatelongtransactions.
 It identified processes that could run for a while in read-only mode (such as the process
thatallowedausertochangehisprofile).
 Itscriptedasmuchoftheswitchoverprocedureaswasfeasible.
 Change management was improved to ensure that the application versions on the active
andbackupsystemswerethesame.
 Complete documentation was generated to allow all participants the opportunity to learn
whattodoandtoknowthecurrentstateoftheswitchoverprocess.
2
©2006SombersAssociates,Inc.,andW.H.Highleyman

The switchover procedure was enhanced to take advantage of these improvements. The
procedure that is now followed separates the switchover process into two stages – a preliminary
stage, during which as much of the switchover work as possible is done without taking down the
system,andtheactualswitchover stage,during which theactualswitchover occurs.This process
proceedsasfollows:
 PreliminaryStage:
o Carefullyvalidateasmuchoftheapplicationenvironmentaspossible.
o Stop all of the processes that can operate in a read-onlymode for a short period
oftimeandstartthemonthebackupsystem.
o Startfrozencopiesofupdateapplicationsonthebackupsystem.
 SwitchoverStage:
o Holdallinboundtraffic.
o Stopalloftheprocessesontheactivesystem.
o AllowTMFtocomplete.
o ResettheACLstoswitchtherolesofthedatabases.
o Thawthefrozenprocessesonthenewactivesystem.
o Releasetheinboundtraffic.
o Stoptheread-onlyprocesses,andrestartthemasupdateprocesses.
Atthis time,thenew active system is readyto takeover.Sabre nowsees switchover times inthe
order of three to twelve minutes as compared to four hours before. The time that read-only
processesarepreventedfromupdatingrangesfromninetoninetyminutes.
TheFuture
All of Sabre’s efforts so far have been focused on switching over for planned outages. The next
stepistoachieveunplannedswitchoversinaslittletime.
Sabre’s goal is to achieve five 9s of availability. This translates into about five minutes of
downtime per year, not five minutes per switchover. Therefore, it must get its switchover times
downintothesecondsratherthanminutes.
To do this, Sabre must refine its current procedures further. But the company realizes that an
active/active architecture may be the ultimate solution and is beginning to build a business case
for that. Already, in order to realize a degree of disaster tolerance, Sabre has separated its data
centerinTulsa,Oklahoma,intotwogeographicallyseparatesites.
Mayo Clinic
TheClinic
The Mayo Clinic is probably the most recognized health facility in the U.S., if not in the world. Its
primary facility is in Rochester, Minnesota, with major clinics in Jacksonville, Florida, and
Phoenix,Arizona.
In Rochester alone, there are over 1,700 physicians and scientists; a like number of residents,
fellows, and students; over 24,000 allied health staff; and over 100 operating rooms and 1900
patient beds. Annual clinic activity averages 70,000 admissions and 48,000 surgeries which are
3
©2006SombersAssociates,Inc.,andW.H.Highleyman

supported by over 33,000 lab tests per day. All of this activity generates over four million
transactionsperday.
PaperMedicalRecords
Mayo began its medical record program in 1907. The volume of archived medical records had
increasedtooverfivemillionbytheearly1990s,eachhand-indexedforresearchdatamining.
This volume of paper records was approaching the unmanageable, so in 1992 Mayo began its
move to electronic medical records (EMR). By the end of 2005, the generation of paper records
ended.
ElectronicMedicalRecords
The primary consideration in going to a paperless system is that doctors must have access to a
patient’srecords24hoursaday,365daysayear.Otherwise,patientcareandsafetymaysuffer.
These documents have to be up-to-date with all of the latest lab results. They are complex
documents containing text, images, and lab results. The data must be available as the patient
moves around the hospital and must be accessible to doctors at the patient’s bedside (doctors
now drag a wireless laptop behind them on an IV-like mobile pole as they move from patient to
patient).
Mayo chose NonStopservers torunthe electronic medical recordapplication,Carecast,supplied
by GE Healthcare (formerly IDX, and before that, Phamis). Mayo started with a NonStop VLX
system in 1992 and now is running a pair of 24-processor S88000s (configured from a sixteen-
processor system and an eight-processor system) as an active/backup pair which they call their
production system and their business continuity system. Each system has one terabyte of data
storage.
4
©2006SombersAssociates,Inc.,andW.H.Highleyman

Thetwosystems areconnected via ahigh-speed ServerNet backbone,andthe backupdatabase
is kept synchronized with the production database via a GoldenGate data replication engine. The
production system supports 20,000 Carecast terminals and communicates with over eighty
heterogeneousinterfacestolaboratorysystemsandotherdevices.
Mayo’sAvailabilityGoals
Carecastterminals
A major challenge that Mayo faces is that
laboratorysystems
it must perform maintenance upgrades on
otherdevices
the systems once per quarter. Mayo was
doing this by switching over to the backup
system, upgrading and testing the
production system, switching back, and
ProductionSystem BackupSystem
then upgrading the backup system. Each
switchover took one to two hours.
S88 S88
Consequently, the system was down for
two to four hours during the upgrade
process.This added up to morethaneight
hours of planned downtime per year, application application
equivalent to not even three 9s of
availability (which is eight hours of
16processors 16processors
downtime per year); and this did not
include any downtime due to unplanned
outages.
GoldenGate
terabyte terabyte
Manual procedures were put in place so
database database
that records could be accessed manually
and treatments and medications ordered
during an outage. These procedures are
S88 S88
cumbersome and are used only as a last
resort.
Mayo has set a current goal of four 9s application application
(lessthanonehourper yearofdowntime),
with a longer term goal of five 9s (less
8processors 8processors
than five minutes of downtime per year).
Ultimately, it wants to achieve zero
downtime from either planned or
unplannedoutages.
Mayo'sElectronicMedical RecordSystem
To achieve this goal, Mayo organized the
SWitch Improvement Group (SWIG). This group set about understanding the reasons for long
switchovertimesandinstitutedchangestocorrectmanyoftheproblemsthatwereuncovered.By
mid-2005, SWIG had reduced the two- to four-hour quarterly outages to 15 minutes. How was
thisaccomplished?
ReducingSwitchoverTime
The SWIG group first analyzed the reasons for the excessive switchover times. As a result, it
madethefollowingchanges:
 Mayo upgraded its backup system to be a full production system. In this way, Mayo did
not have to switch back to complete a maintenance procedure. It now upgrades the
5
©2006SombersAssociates,Inc.,andW.H.Highleyman

backupsystem andthenswitches over to it and runs itas theproductionsystem untilthe
nextquarter.Bydoingso,Mayoimmediatelycutitsswitchovertimeinhalf.
 SWIG automated the switchover with scripts which not only speeded the switchover but
alsoshortenedthepost-switchovertestinginterval.
 SWIG now schedules the copying of certain files to occur before or after the switchover
sothattheydonothavetobecopiedduringtheswitchover.
 SWIG initiated the use of HP NonStop AutoSYNC from Carr Scott Software to copy
certain files dynamically during the day so that these files would not have to be specially
copiedaspartoftheswitchoverprocess.
The fifteen-minute switchover time is made up of about nine minutes to bring down the current
production system and about six minutes to bring online the new production system. The nine
minutes required to shut down the current production system is mainly taken up with shutting
downthePathwayenvironments.Thisisduetoseveralfactors:
 Thereareover1,000TCPs(terminalcontrolprocesses)running.
 Severalserversrunintimeoutloopsandcan’tbestoppeduntiltheirtimeoutsexpire.
 There are more servers to be stopped than necessary since Mayo spawns many static
servers to avoid the delays of having to spawn dynamic servers as needed. This
improvesresponsetimeandreducessystemloadbutcausesalongershutdowntime.
Thesixminutesrequiredtobringupthenewproductionsystemislargelydueto:
 having to wait to start certain servers on the backup node until after the production node
is down. These servers cannot otherwise be running because they make database
updatesonstartupandwouldcausecollisionswiththeprimarysystem.
 reestablishingsessionsforupto4,000laboratorydevicesand35,000users.
 copying over and validating nonaudited files that cannot be copied before or after the
switchoverorthatcannotbekeptinsynchronismwithAutoSYNC.
TheFuture
Reaching four nines as SWIG has done is necessary but not sufficient. SWIG’s next task is to
reducedowntimetofive9s,orlessthanfiveminutesperyear.
Ultimately, Mayo would like to achieve 0% downtime. For this, it is beginning to consider what
needstobedonetogoactive/active.
Summary
The quest for high availability is the quest for fast switchover. If going active/active is deemed to
betoolargeasteptotake,onemustfocusonminimizingswitchovertime.
Certainly, the extensive use of scripts, frequent training in and testing of the switchover
procedures, and ensuring the availability of key people are a must. Beyond that, the factors that
6
©2006SombersAssociates,Inc.,andW.H.Highleyman

are causing switchover latencies in an installation must be understood and corrected, as has
beendonebySabreandMayo.
7
©2006SombersAssociates,Inc.,andW.H.Highleyman
|---|--|--|-----|--|--|
| 0 |  |  | RDF |  |  |
| 1 |  |  |     |  |  |
| 2 |  |  |     |  |  |
| 3 |  |  | RDF |  |  |
| 4 |  |  |     |  |  |
| 5 |  |  |     |  |  |
| 6 |  |  |     |  |  |
|---|--|--|--|
| 0 | backup
database
part 1
backup
database
part 2  |  |  |
| 1 |  | S88
application  |  |
| 2 |  |  |  |
| 3 |  | S88
application  |  |
| 4 |  |  |  |
|---|--|--|--|
| 0 | active
database
part 1
active
database
part 2  |  |  |
| 1 |  | S88
application  |  |
| 2 |  |  |  |
| 3 |  |  |  |
| 4 |  |  |  |
| 5 |  |  |  |
| 6 |  |  |  |
| 7 |  | S88
application  |  |
| 8 |  |  |  |