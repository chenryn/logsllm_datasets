is,themoreefficientlyitwillmeetitscompliancerequirements.
ThereareseveralcommontypesofcompliancerequirementsthatITmustmeet:
 internalbusinessstandards
 governmentalregulations
 industryregulations
 internationalstandards
 service-levelagreements
Allof thesecompliancerequirements imposetwoburdens ontheIT infrastructure–reliabilityand
availability. It is the Business Impact Analysis (BIA) that provides the process to get from the
identification of compliance requirements to the implementation of these requirements. BIA is an
information-gathering exercise that identifies the functions performed by the organization, the
4
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

resourcesrequiredtosupporteachfunction,theimpactoffailingtoperformafunction,arecovery
time objective (RTO) for each function (the time that it can be out of service), and the recovery
pointobjective(RPO)foreachfunction(howmuchdatacanbelostfollowingafailure).
The goal of the BIA is to give the company the information it needs to move toward a resilient
infrastructure. It should also include specific recommendations for security, information retention,
data and service consolidation, service-level agreements, and the data and application resilience
ofthecurrentITinfrastructure.
Theauthorprovidesatableofsomeofthelargercomplianceregulationsandtheimpactthatthey
haveonanorganization.Hetargetsfiveareasforimprovedresiliency:
 Reducing backup time to reduce or eliminate the amount of nonproductive time required
to back up systems. This can range from the use of improved tape technologies to
maintaining a replicated backup system. The backup system can be kept synchronized
withdatareplication,switchedstorage,orcross-sitediskmirroring.
 Eliminating planned downtime for maintenance and upgrade activities. This requires the
existence of a backup system that can be put into service while the primary system is
takenoffline.
 Disaster recovery for critical applications so that they can survive a catastrophic
interruption over an extended period of time. This also requires a remotely located
backup system that may or may not be kept synchronized with the primary system
dependingupontheRTOandRPOobjectives.
 High availability for unplanned outages so that critical applications may continue, also
achievedwithasynchronizedbackupsystem.
 Balancingworkloadstocomplywithservice-levelagreements.
The author then uses a series of RTO/RPO diagrams to develop the various resiliency options
availabletoacompanyforsingle-systemandmultisysteminfrastructures.
A major requirement of the new regulations is that of audit. The IT infrastructure must be audited
for compliance frequently and independently. From a resiliency viewpoint, each resiliency
technique should have a documented audit procedure. For instance, if a backup system is
available,aroleswapmaybeperiodicallydemonstrated.
The recognition of the role of IT in compliance has taken on a new meaning since SOX. This is
particularly true when it comes to business-continuity planning. Studies have shown that 40% of
all companies that experience a disaster go out of business within two years, yet 40% of
companies do not consider business-continuity planning a priority. Consequently, a well-
formulatedbusiness-continuityplancanactuallyserveasastrategiccompetitivedriver.
Chapter 5: Maintaining Availability with Virtualization Technologies
Chapter5isanexcellentoverviewofthebenefitsandpitfallsofservervirtualization.Virtualization
allows a company to consolidate several older, slower, or underutilized physical servers onto a
single server as “virtual machines” (VMs). The move to virtualization is fueled by the rapidly
increasing power of today’s servers and the consequent benefits of reduced data-center costs.
The major pitfall is availability – the failure of a single physical system running many VMs can
takedownmanycriticalapplicationsinonefellswoop.
5
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Virtualization can also be extended to multiple storage systems. Virtualized storage allows
applicationstoviewdiversestoragesystemsasasinglestoragesystem.
Consolidation via server virtualization can reduce the total cost of ownership of the IT
infrastructure by requiring the acquisition of fewer (albeit larger) servers, reducing license and
energy costs (virtualization is green), and downsizing the data-center facility. Labor costs can be
reduced since system administration is simpler. In fact, data centers can be consolidated,
eliminating entire facilities. Legacyapplications can be moved from legacysystems andmigrated
tovirtualmachinesrunningonmodern,openindustry-standardservers.
Storage virtualization consolidates multiple storage systems into a unified group that appears as
a single storage facility that can be managed, backed up, and replicated with synchronized
automation and a reduced administrative force. Though no physical storage systems may be
saved,storageismoreefficient,flexible,andmanageable.
One pitfall of virtualization is the “all of your eggs in one basket” syndrome. If the physical server
fails, it takes many virtual machines with it. Therefore, backup facilities are required to take over
the support of all of the failed VMs. Furthermore, all of the failover software facilities required for
singleserversarerequiredforvirtualizedservers.
Another pitfall is “server sprawl.” Companies expect that virtualization will reduce the number of
physical servers that they must provide. This is true. However, as soon as departments realize
thatnewvirtualmachines canbe obtainedatthecost of afewclicks,controlsmustbeinplaceto
preventvirtual-serversprawl.
Good VM management tools are a necessity. VMs can be easily migrated from one physical
server to another for load balancing and fault recovery. Unless the impact of thesemovements is
monitored, severe performance problems may suddenly occur due to the overloading of a
physicalserver.
A company must evaluate what applications to virtualize. Good candidates include test and
development environments, smaller applications, applications whose utilization does not vary
widely, and perhaps some legacy applications. Poor candidates include compute-intensive
applications, graphics and CAD systems, and applications requiring specialized hardware.
Applications that should be held off until the virtualized infrastructure is working well include
mission-criticalapplicationsusingmanyserversaswellasnew,untestedapplications.
Bestpracticesdictatethatvirtualizationshouldbeapproachedcautiously.Startoutwithafewtest
and other noncritical applications in a safe sandbox. Practice with these until all the kinks are
workedout,andthenproceedcarefullywithexpandingvirtualizationtotherestofthedatacenter.
Chapter 6: Data Replication: Making Sense of the Options
Chapter 6 was published in February, 2009, and deals with data replication – a subject close to
our heart. Data replication is used to create a copy of a source database onto a remote target
database. Data-replication engines move data changes from the source to the target over high-
bandwidthcommunicationlines.
The source and target databases may not be exact copies of each other because the databases
may be heterogeneous (different schema or even different vendors) or because they may be
satisfying different needs (the source may be doing transaction processing while the target is
beingusedforcomplexqueries).
Replication may be bidirectional. In this case, each system acts both as a source of data and a
targetfordata.
6
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Therearemanyreasonstoreplicate:
 Application Integration – Data applications can be integrated, often seamlessly, at the
data level. With replication, when an application makes a change to a data item, that
changeimmediatelyappearsinthedatabasesofotherapplications.
 Data Sharing – Common data can be shared by multiple users at once without
interference. This is especially useful if users are geographically dispersed by replicating
toremotesystemsthatarelocaltoconcentrateduserpopulations.
 Business Intelligence – Enterprise-wide data can be replicated to a real-time data
warehouse for extensive data mining, for running ad hoc queries against current data,
andforgeneratingreal-timeeventstotriggercorporateactions.
 System Upgrades and Migrations – The target system can be upgraded and fully tested
while its database is kept synchronized with the source database. When ready, it can be
putintoproductionrelativelyrisk-freebyswitchingusersovertoit.
 Disaster Recovery –Data can be replicated to an offsite system that can be put into
operationiftheprimarysystemistakendownbyadisaster.
 High Availability – Data can be replicated to an onsite backup system that is prepared to
takeovershouldtheprimarysystemfail.
 Data Vaulting – Data can be replicated to a secure disk facility for later restoration if
needed.
There are several technologies today for data replication. One is disk mirroring, in which data is
written to two separate disks attached to the same system. Disk mirroring protects against a disk
failure. However, the mirrors cannot always be separated by the large distances required for
disaster protection. In addition, the system cannot be taken down for maintenance without taking
downallapplications.
Software-based replication solves these problems. These products use some sort of transaction
log to replicate data changes to remote systems. Software replication is more flexible and often
more efficient than replicating at the storage-system level. It can provide all of the replication
benefits discussed above. However, due to subtle faults, some administrative monitoring and
maintenanceofthetargetsystemisoftenrequired.
Data replication can support continuous data protection, or CDP. With CDP, corrupted data can
bereconstructedandrestored.
Datareplication is an importantcomponentof highavailability. However,high availabilityrequires
muchmore.Forinstance,itmustprovidefortherole-swappingfunctionshouldasystemfail.
Replication features that should be considered when choosing a replication engine include
platform coverage (does it cover the required platforms in the data center), data collision
detection and resolution if bidirectional replication is used, flexible topology support, guaranteed
datadelivery,monitoringandcontrol,anddatamovementmethods(batchversusrealtime).
Chapter 7: Meeting the Recovery Imperative
ThenextchaptertobepublishedisdescribedbyBusinessContinuityToday:
7
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

”Recoveryis no longer just about disasters. Just having servers or network connections down for
afewminutes,orevenafewseconds,canbeanoperationalandfinancialcatastrophe.Youmust
beabletorecoverquicklyfromanyevent,bigorsmall,thatthreatensbusinesscontinuity.”
You can register for this chapter and others by following the link given at the beginning of this
article.
8
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com
