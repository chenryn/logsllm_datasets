# 记一次 K8s 故障处理
## Calico 异常重启问题复盘
集群内网络架构为，基于Calico BGP的路由模式，直接与交互机建联。
### 影响范围和故障时间线
1. **影响范围**：线下环境node-xx物理机上Pod网络不可用
2. **影响时间线（2023-07-23 22:09 ~ 22:14）**
    - [22:13] 收到网工反馈Peer Down
    - [22:14] Calico故障自愈（自动重启）
### 故障发生原因
1. **故障现象**
    - 查看calico事件信息：`kubectl -n kube-system describe pod calico-node-xx`
      ```
      Restart Count:4
      Limits: cpu: 5 2Gi memory:
      Requests: cpu: 250m memory: 2G
      Liveness:
      exec [/bin/calico-node -felix-live -bird-live] delay-10s timeout=1s period=10s #success=1 #failure-6 exec [/bin/calico-node -felix-ready -bird-ready] delay=0s timeout=1s period=10s #success=1 #failure-3
      Readiness:
      Environment Variables from: kubernetes-services-endpoint ConfigMap Optional: true Envi ronmont.
      goroutine1[runnable,locked to thread]: github.com/aws/aws-sdk-go/aws/endpoints.init() /go/pkg/mod/github.com/aws/aws-sdk-go@v1.35.7/aws/endpoints/defaults.go:275 +0x2d50 goroutine 8 [chan receive]: k8s.io/klog.(*LoggingT). flushDaemon(0x3a40d80) /go/pkg/mod/k8s.io/klog@v1.0.0/klog.go:1010+0x8b created by k8s.to/klog.init.@ /go/pkg/mod/k8s.to/klog@v1.0.0/klog.go:411 +0xd8 goroutine 98 [chan receive]: k8s.io/klog/v2.(*LoggingT).flushDaemon(0x3a40e60) /go/pkg/mod/k8s.io/klog/v2@v2.0.0/klog.go:1107 +@x8b created by k8s.io/klog/v2.init.θ /go/pkg/mod/k8s.to/klog/v2@v2.θ.0/klog.go:416+0xd8 rax 0×0 rbx 0×6 rcx @x7f22e12e537f rdx 0x0 rdi 0x2 rsi @x7ffcd0d8b330 rbp @x2a8e071 rsp @x7ffcd0d8b33@ r8 0x0 @x7ffcd0d8b330 r10 0×8 r11 @x246 r12 @x4f6fafø r13 0x0 r14 @x2947908 r15 0×0 rip @x7f22e12e537f rflags @x246 C5 0x33 0x×0 gs 0x0
      Warntng Unheal thy 7m32s kubelet Readtness probe faited:2023-07-23 14:12:25.925 [INF0][4960] confd/health. go 180:Number of node(s) with BGP peering established=1 calico/node is not ready: felix is not ready: readiness probe reporting 503
      Warning Unheal thy 7m22s (x26 over 2d)kubelet Readtness probe fatted:ocI runttme exec fatled:exec fatted:unablte to start contatner process:error starting setns process:fork xec /proc/self/exe: resource temporarily unavallable: unknown
      Warning Unhealthy 7m16s (x21 over 2d) kubelet Liveness probe faited: 0cI runtime exec failed:exec fatted: unablte to start container process:error starting setns process:fork/ ec /proc/self/exe:resource temporarily unavailable:unknown
      Warning Unhealthy 9m36s (x5 over 2d) kubelet Liveness probe falled: calico/node is not ready:Felix is not live:Get "http://localhost:9099/Llveness":dial tcp 127.0.0.1:9699:con
      nect: connection refused
      Warning Unhealthy 9m32s kubelet Readiness probe failed:2023-07-23 14:10:25.958 [INF0][3626] confd/health.go 18θ:Number of node(s) with BGP peering established=1 calico/node is not ready: felix is not ready: readiness probe reporting 503
      Warning Unhealthy 8m31s kubelet Readiness probe failed: runtime/cgo: pthread_create failed: Resource temporarily unavailable runtime/cgo: pthread_create fatled:Resource temporarily unavaillable
      PC=0x7f22e12e537f m=θ sigcode=18446744073709551610
      goroutine ø[idle]: runt ime: unknown pc θx7f22e12e537f
      000000800000800000007f22e189d11d Stack: trame-(p-∂x7Tfc8b33θ, fp:0xθ) stack-[0x7fcdθ58cb8,θx7ffcd8bbfθ) 00007ffcd8d8b240: 8800008300088000 00007f22e1abc4f0 00007ffcdθd8b250: 00007ffcd0d8b304 00008000039a4158
      00007ffcdθd8b260: 00007ffcd0d8b740 0000880004f6faf8 00087ffcdθd8b270: 1100058100053000 0000880002947908
      00007ffcdθd8b280: 880006800008800 00007f22e18a2024 0000880008800008 2525252525252525
      0807fcd88b258: 800006850008800
      00007ffcdθd8b2bθ: 00000089000080
      0000880000800008
      00087ffcdθd8b2c0:
      00007ffcdθd8b2d0: 454d5f434
      00007ffcdθd8b2e0:
      00007ffcdθd8b2f0: fd8b3:
      00087ffcdθd8b320:
      00007ffcd0d8b330:
      00007ffcdθd8b340:
      00007ffcdθd8b350: 00007ffcd0d8b360:
      00007ffcdθd8b370:
      00087ffcdθd8b380:
      00007ffcdθd8b390:
      00087ffcdθd8b3a0:
      00007ffcdθd8b3bθ:
      00007ffcdθd8b3c0:
      00007ffcdθd8b3d0:
      00007ffcdθd8b3e0:
      00087ffcdθd8b3f0:
      00087ffcdθd8b400:
      00007ffcdθd8b410: fffffffffffffff
      00007ffcdθd8b420: runtime: unknown pc 0x7f22e12e537f
      stack: frame={sp:@x7ffcdθd8b330,fp:0x0} stack=[0x7ffcd058cbb8,0x7ffcdθd8bbf0)
      ```
      从上面事件日志可得找到以下关键信息：Readiness probe failed、Liveness probe failed（就绪探针、存活探针探测失败）→ 查看探测方式，是使用exec进行探测（fork新命令方式 ）→ 具体错误信息Resource temporarily unavailable。
    - 查看kubelet系统日志`journalctl -u kubelet.service --since "2023-07-23 22:00:00"`，从上面日志可以得到以下关键信息：runtime: failed to create new OS thread (have 5 already; errno=11) runtime: may need to increase max user processes (ulimit -u) fatal error: newosproc。
    - 查看Node-exporter监控大盘，Processes相关监控：从监控大盘可以分析出来，从22点开始出现了大量的Processes Forks，没收集到PIDs Number和Threads Number 。
    - 有没有可能是PID跑满了，由于没有收集到PIDs Number和Threads Number，所以换个思路，看看容器cadvisor是否有收集Processes相关信息，是不是容器捣的鬼，使用promql查询node-xx容器线程趋势`sum(container_threads{node="node-xx"})`，查询到22点多容器总线程量达到46k。
2. **根因分析**
    - calico-node使用exec进行监控探测，探测失败，Resource temporarily unavailable。
    - kubelet无法初始化线程，需要增加所处运行用户的进程限制，大致意思就是需要调整ulimit -u。
    - 22点有大量的process forks，node-xx容器总线程突增到46k，无法确定当时宿主机的总线程数，可以通过如下命令实时计算`ps -eLf | wc -l`。
    - 登录服务查看ulimit -u的限制数204k ，46k比204k还差得远。因为ulimit是针对于每用户而言的，具体还要验证每个用户的limit的配置，最后的取值是会取`/etc/security/limits.d/20-nofile.conf`里面的值（优先级高） ，还是204k。
    - 继续找Google Resource temporarily unavailable错误，翻阅linux内核文档，搜索PID相关字段，找到相关的PID参数`kernel.pid_max`，参数大致意思是，kernel允许当前系统分配的最大PID identify，如果kernel在fork时hit到这个值时，kernel会wrap back到内核定义的minimum PID identify，意思就是不能分配大于该参数设定的值+1，该参数边界范围是全局的，属于系统全局边界。同理，还有`threads-max`参数。
    - 确认当前的PID限制，检查全局PID最大限制: `cat /proc/sys/kernel/pid_max`为49k，49k = 46k（容器总线程） + 非容器线程数 。也检查下线程数限制：`cat /proc/sys/kernel/threads-max`为1545k。
    - 结论：全局PID（`/proc/sys/kernel/pid_max` ）达到上限，导致calico无法fork进程，进而监控检查失败，存活探针自动重启。
    - 找出真凶，使用promql查询`container_threads{node="node-xx"}`，发现是某个容器造成的线程突增，联系开发改代码，确定有线程泄露。
3. **Why分析**
    - 导致问题的直接原因是：Xxx应用线程泄露，导致全局PID耗尽，进而导致calico监控检查失败，自动重启。
    - K8s Pod中默认不对PID数进行限制。
    - 排查问题耗时较长的原因是：未收集物理机Processes的相关监控指标，也未设置PID使用百分比触发器。
    - 全局PID限制比用户PID限制小的原因是：参数设置不合理，未进行调优。
4. **后续TODO**
    - 调整`pid_max`参数。
    - 开启Node-exporter Process监控并补全告警：node-exporter启动参数中新增`--collector.processes`，并添加告警规则`(node_processes_threads / on(instance) min by(instance) (node_processes_max_processes or node_processes_max_threads) > 0.8)`。
    - 评估业务是否需要开始Pod PID限制：https://kubernetes.io/zh-cn/docs/concepts/policy/pid-limiting/ 。 