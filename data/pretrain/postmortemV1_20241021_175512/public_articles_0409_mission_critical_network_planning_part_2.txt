down.
Mission-CriticalPlatforms
The availability of server clusters is significantly enhanced by the use of fault-tolerant servers.
Fault-tolerantserversprovideimmediatefailoverwithfourtofive9sofavailability(50minutesto5
minutes of downtime per year). Fault-tolerant systems are designed to survive any single fault
withoutlosinganydata.
Fault-resilient servers provide four 9s availability, but may lose some data. Rather than instant
failover, they rely upon a warm standby that can take many minutes to be put into service. The
warm standbyhas been kept up-to-date with the mostrecent data, but must have its applications
startedandconnectedtothedatabase.
High-availability systems provide three 9s of availability, or about eight hours of downtime per
year. They typicallyrelyon a cold standbythat needs to have the database loaded or brought up
todate.
Even more important to system availability is the software architecture. It should provide fault
management in the form of event monitoring, system state checkpointing, fault detection,
alarming,dynamicreconfiguration,andlogging.
Network components should be highly reliable, redundant, and serviceable. The network and
server platforms should be included in a network management system that typically uses SNMP
(SimpleNetworkManagementProtocol)tomonitorallelementsofthenetwork.
All system power should be redundant, from component power supplies to independent primary
power feeds. Power lines should be conditioned and secured so that there can be no inadvertent
shutdownof power. Power components shouldbehot-swappable sothatpower does not have to
beshutdowntoreplaceafaultycomponent.
Software
The author categorized applications as mission-critical, mission-necessary, mission-useful, and
mission-irrelevant. Important software must be well-behaved under load. It must monitor its
componentsandrecoverfrominternalorexternalfaults.
The distribution of software across multiple systems adds a significant complexity to software
design and management. Often, an application is distributed because users are separated from
theapplicationserversviatheInternet.
Application performance should be monitored and managed. This can be done on a transaction
basisfortransactionprocessingsystems,onafiletransferbasisfortransportapplications,andon
astreamingbasisforvideoorotherbulk-transferapplications.
Performance management can be accomplished via test transactions, by checkpoints inserted
into the program to measure response times, by application agents which monitor performance,
orbytrafficinferencebygatheringmeasurementsfromthenetworkenvironment.
6
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Anapplication should bedesigned withfaultrecoveryinmind, whether this recoveryis manual or
automatic.
Storage
Chapter 10 of Liotine’s book deals with storage systems. There are a variety of storage
technologiesthatprovidecompromisesbetweenavailability,performance,andcost.Thefirststep
is to establish the mission-critical requirements for each class of storage. This includes the
consistencyrequirementsandtheRPO–howmuchdatalossisacceptablefollowinganoutage.
DataReplication
Data replication technology can provide the highest data availability and integrity. With data
replication, any change to a source database is immediately replicated in real time to a target
database that can be hundreds or thousands of miles away. Replication maybe hardware-based
or software-based. Software data-replication techniques can maintain the integrity of the target
database so that it can be used for query purposes. Hardware technology does not guarantee
targetdatabaseconsistencyuntilreplicationhasbeenterminated.
Replication can by asynchronous or synchronous. Asynchronous replication happens after the
fact and therefore has no impact on the application. However, following a source-node failure,
anydatainthereplicationpipelinemaybelost.
Synchronousreplicationguaranteesnodataloss.However,applicationsaredelayedasdatabase
updatesarecompletedacrossthenetwork.
A less expensive method of replication is log journaling. With this method, only the transaction
journalcontainingthedatabasechangesisreplicated.Thejournalcanthenbereplayedtoupdate
thetargetdatabase.
BackupStrategies
The classic method for database durability is tape or virtual disk backup. Full backups are taken
periodically (such as weekly), and incremental backups are taken more frequently (perhaps
daily).Theincrementalbackuponlycontainschangessincethelastfullorincrementalbackup.
However,databaserecoverytypicallytakeshoursorperhapsevendaysforverylargedatabases.
Evenworse,thebackupmayfailifoneormoretapesareunreadable.
StorageSystems
RAID
RAID is a commonly used storage system for high availability. A RAID system includes several
disks (typically five) in which one disk is redundant. If any one disk is lost, the data can be
reconstructed from the surviving disks. There are several levels of RAID which are described by
theauthor.
Tape
Tape is the common method for long-term storage. Liotine describes several tape technologies
suchasDLT (digitallineartape) andhelicalscantape.Tapesshouldbestoredoff-site.Thereare
manyvaultingservicesfordoingthis.
7
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

StorageAreaNetwork(SAN)
A storage area network (SAN) is a particularly powerful storage system. It comprises multiple
storage devices on their own network typically controlled by redundant servers acting as highly
intelligent controllers. The data on a SAN can be accessed simultaneously by several
applications over fibre channel connections. The SAN can be geographically remote from some
oralloftheapplicationserverswithinthedistancelimitationsofthefibrechannels.
SANscanbebackedupbyremoteSANsusingdatareplicationtoachievedisastertolerance.
Network-AttachedStorage(NAS)
Network-attachedstorage(NAS)issimilartodirect-attachedstorageinwhichstoragedevicesare
attached directly to the application servers, except that with NAS, the storage devices are
attached to the production network (typically a LAN) via simple controllers. A NAS device can
contain multiple disks, including RAID arrays. Because NAS storage is not managed by a
sophisticated server, simultaneous user access to particular data objects and backup via
replicationarenotsocommon.
StorageManagement
Storage management facilities can be extensive. They should provide disk and tape backups,
datareorganization,disk defragmentation,replicamanagement,capacityplanning,mobile device
management, data integrity via comparison of primary and backup databases, and storage
capacityoptimizationviahierarchicalstorage.
In addition to data backup, the storage management facilities must support data restoration and
recovery. This is a much more difficult task than data backup. The database must be restored to
a point-in-time via full and incremental backups and then rolled forward via the journal logs if
possibletorecoverlostdata.
Facilities
Chapters11and13discusscontinuityissueswiththedatacenterfacilities.
A single facility is a single point of failure. Therefore, for true high availability, an enterprise must
operate at least two data centers that back each other up. This means that there must be
redundant networks for user access to all data centers and distribution networks to interconnect
thedatacenters.
CablePlant
The internal cable plant is often the most difficult to troubleshoot and to repair. Therefore,
particularattentionmustbepaidtoitsdesignandimplementation.
Redundant cables should be routed via separate cable runs. Power cables should be routed
separately from data cables. Entry points for redundant power and data cables must be made
throughseparatepointsinthebuilding.
Copper is the most common cabling for LANs. However, it has poorer performance than fibre. It
provides less bandwidth and is susceptible to electrical noise and crosstalk. Fiber is more
sensitive to improper installation. Kinks in the fiber cable and poor optical terminations can cause
fiberfaults.
8
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Power
Power problems are the most frequent source of service interruptions. An average system
experiences one-hundred power disturbances per month. Thanks to proper power conditioning,
most of these disturbances have no impact on operations. However, more serious power
disturbancessuchasblackouts,brownouts,transients,andsurgescanimpactoperations.
Primary power availability tends to run between three 9s and four 9s. Therefore, to achieve high
availabilityinthedatacenter,itiswisetoobtainprimarypowerfromtwoindependentsources.
Backup power must be available. Backup power starts with a battery-operated UPS
(uninterruptable power system) that will provide enough power to keep critical data center
equipment operational until more permanent backup power can be provided. This is generally in
the form of redundant generators powered by diesel, gasoline, propane, or natural gas. At least
two fuel tanks should be provided to protect against fuel contamination, and fuel supplier
contractsshouldbeinplacetoguaranteeacontinuedfuelsupplyduringanextendedoutage.
Acomprehensivepowermanagementsystem isrequiredforpowersystem shutdownandreboot,
for the control of power system components, for usage reporting, and for quality monitoring and
notification.Itshouldbeintegratedwiththenetworkmanagementsystem toprovideasinglepoint
ofcontrolforalldatacenterfacilities.
Environment
In addition to power, cooling and humidity control must be carefully planned. The author
describesandevaluatesseveralair-flowconfigurationsforcooling.
Fireprotectionplanningisanotherimportantenvironmentalconsideration.
RedundantSite
Thereareseverallevelsofavailabilitythatcanbeachievedwithabackupdatacenter:
 Hotbackup–Thebackupsiteis readyandfailover is rapid.Itmightevenbeparticipating
by sharing the work load or by performing related work. Recovery can be performed in
minutes.
 Warmbackup–Thedatacentercontainsallofthenecessaryequipmentandmaintainsa
reasonably current copy of the database. However, the database must be made current
and applications started before the data center is operational. Recovery can be
performedinhours.
 Cold backup –Thedatacenter site is availablebutis empty. Equipmentmustbebrought
inandplacedintoservice,Recoverycouldtakedaysorlonger.
 Mobile backup – It may be possible to wheel in a mobile data center.3 Recovery can be
doneindays.
As an alternative to building and maintaining a redundant site, there are hosting services which
provide facilities and/or servers on a shared basis. Also, many companies make collocation
agreementswithothercompaniesordivisionswithinthesamecompany.
3DataCenterinaBox,AvailabilityDigest;July2009.
9
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

In any event, a well-defined, documented, and tested recovery plan is a necessity for mission-
criticalsystems.
Management
Chapter 12 deals with the management of the mission-critical system. Distributed system
managementandoperationstypicallyconsumehalfthecostsofrunningamission-criticalsystem.
Management is complicated by the fact that a large number of heterogeneous multiservice
components are involved. Management includes communication management, configuration
management, security management, system management, and software management. It is
importanttoincludeallofthesemanagementcomponentswithinacommonenterprisemodel.
Because mission-critical networks are so complex, it is important that the management facility
can self-discover the network topology of communication, processing, and environmental
components and present these in an intuitive graphical context. It should monitor events, identify
realorpotentialfaults,isolateproblems,initiaterecoveryactions,andaidinroot-causeanalysis.
It should be capable of managing congestion and rerouting workloads accordingly. It should
provide capacity planning to avoid such congestion. The goal is to neither under-provision nor
over-provisionthenetwork.
The specification and monitoring of Quality of Service (QoS) is extremely important. QoS polices
must be established, and policing mechanisms instituted to ensure enforcement. SLAs (service
level agreements) should be used where possible to guarantee performance of different portions
ofthenetwork.
Changes cause outages. Therefore, change management is very important. Not only should
changes be planned carefully, but they should be deployed incrementally with a plan for falling
backtotheoriginalsystemifproblemsareencountered.
Testing
Testingofthemission-criticalnetworkiscoveredinChapter14.
The cost of correcting errors increases exponentially through the implementation phases. Errors
are corrected most easily during the definition and design phases of a project. The cost of errors
increases rapidly as the project progresses through the development, testing, acceptance and
deploymentphases.
Therefore,goodtestplanningis essential.Thereareseverallevels of testing.Unittesting is done
as each component becomes ready. Integration testing proceeds as components are integrated
into a growing system. The system test is a full system test of a completed system before it is
deployed. It should include backup and recovery testing. The acceptance test is run for the
benefitoftheenduserstoletthemsignoffonthesystem.Itshouldincludeperformanceandload
testing. During all of this, regression tests should be used to ensure that nothing has broken as
thesystemisassembled.
When it comes time to cutover, there should be a means to return to the old system if severe
problemsshouldoccur.
Testing is expensive. But not testing properly can lead to even greater expense as errors are
correctedinasystemnearingcompletion.
10
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Summary
Theauthorsummarizeshisbooksuccinctly:
“Network continuityis adisciplinethatblends IT withreliabilityengineering,network planning,
performance management, facility design, and recovery planning. It concentrates on how to
achieve continuity by using preventive approaches, instead of relying solely on disaster
recoveryprocedures.”
Allthatwewouldaddisthatthebook isnecessarilyanoverviewofthemyriadtopicsinstrumental
to an understanding of mission-critical system continuity. The author provides substantial
referencesforthosewhowanttodelvedeeperintoanyofthesetopics.
11
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com
