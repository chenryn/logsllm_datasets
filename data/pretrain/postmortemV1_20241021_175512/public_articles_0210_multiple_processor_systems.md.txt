Multiple Processor Systems for Real-Time Applications
October2007
Multiple Processor Systems for Real-TimeApplications,byBurt LiebowitzandJohnCarson,1is a
classic treatise on distributed systems. Written in the time when 64k was a massive amount of
memory,itpredictedtieredsystemsandclusters.
Not only is this book a joy to read to see how early technology morphed into today’s powerful
distributed systems, but more importantly it provides in-depth discussions of reliability theory and
performance analysis with a focus on distributed systems. The material presented in these
chapters is every bit as pertinent today as it was then and is a must-read for any serious
distributedsystemarchitect.
Background
Liebowitz and Carson were each deeply involved in distributed systems, both in theory and in
practice. They were responsible for the implementation of many early distributed systems. They
jointly and individually taught a series of courses at George Washington University in
Washington, D.C. as well as to government and industry groups on the subject of distributed
systems.
Thisbookevolvedfromtheextensivecoursenotessupportingtheseclasses.
Scope
This book deals specifically with locallydistributed multiple processor systems (MPS). An MPS is
a network of independent computers cooperating in an application. The authors distinguish MPS
from multiprocessor systems, which are standard symmetric multiprocessors (SMP) in which
multipleCPUssharethesamememory.
A locally distributed MPS is one in which the computers are close enough (in the same room,
building, or campus) so that high-speed communication links such as a LAN can be used as the
interconnect facility. The book discusses the design issues associated with locally distributed
MPSsystems as wellas theconsiderationfor thechoices ofcomponents.Thoughthis materialis
quitedated,muchofitstillholdstruetoday.
A particularly complete discussion of reliability theory and performance analysis focuses on
distributed systems. Both of these discussions cover serial tiers of redundant processing
elements that are the heart of distributed systems. Estimating the availability and response time
of these systems can be a challenge, and these chapters present the tools required to meet this
challenge.
The book ends with a series of in-depth case studies of the period and some predictions for the
future–predictionsthatinhindsighthitthemark.
1Liebowitz,BurtH.;Carson,J.H.;MultipleProcessorSystemsforReal-TimeApplications,Prentice-Hall;1985.
1
©2007SombersAssociates,Inc.,andW.H.Highleyman

Advantages of Multiple Processor Systems
The authors point out that multiple processor systems have several advantages over
multiprocessorsystemsandmonolithicmainframes.
 Reliability – An MPS can include incremental redundancy to protect the system against
any single point of failure. Though they incorporate multiple CPUs and can withstand a
CPU failure, multiprocessor systems depend upon a common memory that is a single
pointoffailure.Mainframesarebytheirverynatureessentiallynonredundant.
 Scalability – An MPS can be easily scaled by adding computers to the network. A
multiprocessor can add CPUs but onlyto a point. At some point, the memorybecomes a
bottleneck. Once the capacity of a mainframe is reached, the only option is to go to a
biggerbox.
 Performance–TheperformanceadvantagesofanMPSparallelitsscalability.Ifacertain
class of transactions begins totaketoo longbecause of loading on acomponent suchas
a CPU or a disk, there is the opportunityto add additional components to share the load.
In addition, the MPS can be structured in advance with load and performance
requirementsinmind.
 Program Modularity – As opposed to mainframes and multiprocessors, the programs in
an MPS can be highly modularized by distributing functions across multiple computers.
Thisleadstoeasierdevelopmentandsimplertesting.
 Economy–AproperlystructuredMPScanbeanorderofmagnitudelessexpensivethan
amainframe.
 Security – Redundant elements of an MPS can be placed in different locations to protect
itagainstdisasterssuchasafire.
Design Issues
The design of an MPS goes far beyond that required for a monolithic mainframe or
multiprocessorsystem.Ineffect,thedesignerbecomesasystemarchitect.Hemust
 decomposetheproblemintoamanageablenumberofcomputers.
 minimizeinterprocessorcommunicationanditsoverhead.
 defineatestablecollectionofprocessors.
 provideastartingpointforresolvingotherarchitecturalissues.
 provideamodular,expandablesystem.
 provideaconfigurationthatisamenabletoincrementalredundancy.
ThereareseveralconfigurationsthattheauthorsconsiderforanMPS.
 Dedicated Function – each computer in the network is dedicated to a particular function,
such as communications, different applications, and database management. This is the
basisforthetieredsystemarchitecturesoftoday.
 Traffic Sharing – traffic is distributed to an array of two or more computers that, in the
aggregate,arecapableof supportingtheentireload.This is the load-sharingarchitecture
of today so prevalent in web systems. It is inherently fault-tolerant in that, should a
processingcomponentfail,itissimplynotfedanynewtraffic.
2
©2007SombersAssociates,Inc.,andW.H.Highleyman

 Dynamically Allocated – Functions are assigned to computers in the network on an as-
needed basis via a control mechanism that optimizes component utilization. This
architecture is inherently reliable since, should a computer fail, it is simply not assigned
anynewtasksuntilitisreturnedtoservice.Thisissimilartotoday’sclustertechnology.
In these architectures, the computers may be organized in either a hierarchical or a horizontal
relationship. In a hierarchical relationship, one computer serves as a master to the other
subordinate computers. The computers are logically unequal. The master computer controls the
flowofworktoitssubordinates.
In a horizontal relationship, the computers are connected by a bus and are logically equal.
Controlisdistributed.
The Building Blocks
An MPS is constructed from a varietyof building blocks. These include the processors, database
systems,interconnectsystems,andoperatingsystems.
The book discusses the considerations that go into the choices of these components. Though
much of this material is dated and is primarily of historic interest, some topics are as applicable
todayastheywerethen.
The OSI model is explained in detail, and the concept of flow control and windowing is clearly
demonstrated.
The concept of token networks and broadcast (CSMA/CD) buses is treated in detail. It is shown
that the capacity utilization of the LAN at low usage is poor for a token bus but is high for a
broadcast bus. However, as utilization goes up, the efficiency of a token bus increases
dramatically while the efficiency of a broadcast bus deteriorates quickly (due to collisions). The
efficiencyofatokenringremainshighregardlessoftheLANload.
Various methods for distributing a database are described. These include distributing partitions,
replication,andfunctionaldistribution.
The book notes that the requirements for a distributed operating system are substantially more
complex thanthose for amonolithic operatingsystem.TheTandem (nowHPNonStop) Guardian
operatingsystemisusedasanexample.
Recovery
An extensive description of failover considerations is given by the authors. These considerations
areeverybitasapplicabletodayandinclude:
 Howisafaultycomponentidentified?
 Whomakesthedecisiontoswitchtoanewcomponent?
 Howdoesanewcomputeracquiretheperipheralsofafailedcomputer?
 Howcanthedatabasebepreservedorreconstructed?
 Whatmechanismshouldbeusedforloadingprogramsintothenewcomputer?
 How much should be done automatically, and how much should be done under operator
control?
 Howmanysparesarerequiredtoachievetherequiredreliability?
 Whatfailuremodescanbeintroducedbythediagnosticandswitchingequipment?
These are organized into three categories – error detection, fault isolation, and recovery – for
furtherdiscussion.
3
©2007SombersAssociates,Inc.,andW.H.Highleyman

TheseconsiderationsareappliedtoavarietyofMPSarchitectures.
Reliability
The book’s discussion on reliability analysis is one of the enduring sections that is still relevant
today.Theauthorsdistinguishbetweenavailabilityandreliability:
 Availability is theproportion of timethat thesystem is operational (interval availability) or,
alternatively, the probability that the system will be operational at a specific point in time,
like when you walk up to an ATM (pointwise availability). In the steady state, these are
thesame.Ifasystemhasanavailabilityof99%,itwillbeoperational99%ofthetimeand
willbetherewhenyouneedit99%ofthetime.
 Reliability is the probability that the system will be operational for a stated period of time.
It is characterized by a statistical distribution. For instance, a particular system might
have a 90% probability that it will be operational for a year, a 30% probability that it will
beoperationalforfiveyears,anda5%probabilitythatitwillbeoperationalfor10years.
Ifasystem isrepairable,availabilityisusuallyusedasameasureoftheoperatingperformanceof
the system. However, if the system is not repairable, availability has no meaning. In this case,
reliabilityis themoreimportantmeasure. Agood example of a nonrepairablesystem is asatellite
subsystem. In this case, the measure of interest is how long the system is expected to be
operationalinorbit.
Availability
Theauthorsfirstdescribethetechniquesforanalyzingnetworksofcomponents.Eachcomponent
has an availability that is determined by its mean time before failure, mtbf, and its mean time to
repair,mtr.Usingthesevalues,componentavailabilityis
availability=mtbf/(mtbf+mtr)
These networks comprise two types of subnetworks. One is a serial arrangement in which every
component must work in order for the system to be operational. The other is a parallel
arrangement in which the system will work even if one or more components should fail. Any
systemcanbedecomposedintoserialandparallelcomponents.Thetechniquesforanalyzingthe
availabilityofsuchasystemaredescribedindetail.
Parallelconfigurationsofredundantcomponentsarefurtheranalyzed.Theavailabilityrelationship
forann-nodesystemwithssparesisderivedandisappliedtoamultiplecomputerconfiguration.
Reliability
The authors then turn their attention to the calculation of reliability. Using the same component
measurements of mtbf and mtr, they show the method for calculating the mtbf and mtr for the
system asawhole.Thisiswhatisneededfortheexpressionforreliability.Their methoddepends
upon S. J. Einhorn’s work, which is equivalent to the expressions that we have developed in our
previousCalculatingAvailabilityarticles.
System mtbf calculated in this manner is the average time that the system is expected to remain
operational. It is the time that the system will be operational with a probabilityof 50%. As such, it
is just one point on the reliability curve; but it is the parameter generally used to characterize the
reliabilityofasystem.
4
©2007SombersAssociates,Inc.,andW.H.Highleyman

Again, these expressions are applied to a multinode MPS system with multiple spares as an
example.
Performance
The authors present an equally impressive coverage of response time for MPS systems. They
first review basic queuing theory for the single server model for service times with arbitrary
distributions, resulting in the well-known Pollaczek-Khinchine model. They then solve this model
forservicetimeswithrandomdistributionsandwithconstantdistributions.
They then extend this to response time distributions so that questions such as “what is the
responsetimefor90%oftherequests?”canbeanswered.
These results are further extended to the complex topic of multiserver queues in which multiple
servers process a common request stream in a load-sharing configuration. This is the heart of
manydistributedsystems.
Tandemqueuesandparallelqueuesarealsoanalyzed.
Finally,this analysis is appliedtoafairlycomplex redundantsystem,clearlyillustratingtheuse of
these methods. The system comprises up to sixteen processors, including dual I/O processors
(one acting as a standby spare), dual communication line controllers, dual disk systems, and
multiple application processors. This is perhaps one of the most complete and complex
performanceanalysesthatIpersonallyhaveeverseen.
Design Methodology
The authors discuss a systematic approach to resolving the many issues that arise during the
architectural phase. The discussion begins with the importance of a full functional requirements
specification–adocumentoftenmissingorinadequateatthestartofaproject.
Thefirst step in this design methodologyis to size the application on a “standard” computer. This
may be a known computer or one with defined characteristics. The goal here is to estimate the
CPUanddiskloadsrequiredbytheapplication.
Given these load requirements, a distributed system architecture with appropriate redundancy
can be determined and computing nodes chosen. The choice of architecture and components
should be based on simplicity, feasibility, modularity, maintainability, expandability, reliability,
cost,andperformance.
Atthispoint,implementationproceedsasitwouldforamonolithicsystem.
This design approach is then applied as an extensive example to a store-and-forward packet
switch.
Case Histories
Several actual case histories of MPS systems are described. They include systems implemented
bytheCoastGuard,theFAA,BankofAmerica,NASDAQ,andE.F.Hutton.
Future Trends
Theauthorspredictsomefuturetrends,allofwhichhavecometopass:
 Moreuserswilldemandonline,real-timeaccesstodata.
5
©2007SombersAssociates,Inc.,andW.H.Highleyman

 Reliabilitywillbecomeaconcernasapplicationsgoonline.
 Userswillrequiresystemsthatexpandgracefullywithincreasingtraffic.
 Thecost/performancecharacteristicforsmallcomputerswillcontinuetoimprove.
 Userswilldemandlow,predictableresponsetimes.
 More and more off-the-shelf products will become available to facilitate the construction
ofdistributedsystems.
Soundfamiliar?
The book ends with detailed descriptions of some packaged multiple processor systems,
includingthosefromTandem(nowHPNonStop),Stratus,andSynapse(longsincegone).
Summary
From a historical perspective, it is interesting to note the rapid advance of technology. System
characteristics have improved by three to six orders of magnitude (that’s one million times) over
twenty-some-odd years! Memory sizes have gone from kilobytes to gigabytes. Disk capacity has
gone from megabytes to terabytes. Processor speeds have gone from megahertz to gigahertz.
WANcommunicationspeedshavegonefromkilobitspersecondtomegabitspersecond.
As systems become more powerful and complex, we have gotten further and further away from
the internals of our systems. In reading this book, it is amazing how close we were to system
internalsbackthen.
Historical perspective aside, the authors’ treatment of reliability and performance analysis is
completeandconciseandisasrelevantandhelpfulasiteverhasbeen.
Theauthorssummarizetheirmessagesuccinctly:
“There is no cookbook for the design process. One must gather detailed information on both the
applicationandtheequipmentselectedinordertoproceedwithadesign.Whatwereallystressis
the need for quantitative analysis during the selection and design process. Whether it be simple
addition to determine the total memory and disk requirements or more complex mathematics,
such as queuing or reliability analysis, we must perform this analysis if we are to do better than
makeablindguessatasolution.Wearerepeatedlyamazedathowmanysystemsareattempted
without any sincere analytical study preceding the design. We are not amazed, however, at how
manysystemsofthistypeneverperformasanticipated.”
Thisisatimelessstatement.
6
©2007SombersAssociates,Inc.,andW.H.Highleyman
