Calculating Availability – Failover
February2007
In the past several articles, we have concentrated on the calculation of availability of redundant
systems. We have considered the failure of a system caused by the failure of all of its spare
subsystems, leaving it exposed to the failure of just one more subsystem.We have analyzed the
impact of different repair strategies and of system restoration time subsequent to nodal repair.
Wehave looked at the case in which a subsystem fails for reasons other than a hardware failure
andthereforeneedsnorepair,justanoderecovery.
In these analyses, we have assumed that once a single subsystem failed, the recovery from this
failure was instantaneous as a redundant backup subsystem took its place. Therefore, the failure
ofasinglesystemfailurecontributednothingtothelackofavailability.
However,failoverisnotinstantaneous.Itcantakeanywherefrommillisecondstodaysdepending
upon the system. Long failover times can contribute significantly to unavailability. In this article,
welookattheimpactoffailovertimesonavailability.
Butfirst,wereviewtheresultsofourpreviousanalyses.
A Review of Availability Calculation
We define A as being the availability of a system (that is, the probability that the system is up),
and F as being the system failure probability (that is, the probability that the system is down).
Sincethesystemiseitherupordown,then
A 1F (1)
If the average time that the system is up is MTBF (the mean time between failures), and if the
averagetimethatitisdownisMTR(themeantimetorepair),then
MTBF
A  (2)
MTBFMTR
and
MTR MTR
F  (3)
MTBFMTR MTBF
wheretheapproximationinEquation(3)isvalidifMTBF>>MTR.
We consider a system with n spare subsystems, s of which are spares. That is, the system will
survivethefailureofssubsystems.However,thesystemfailsifs+1subsystemsshouldfail.
1
©2007SombersAssociates,Inc.,andW.H.Highleyman

systemoperational systemfailed
AFour-NodeSystemWithOneSpare
Therearetworepairstrategiesthatwehaveconsidered–parallelrepairandsequentialrepair:
 Parallel Repair – When multiple subsystems have failed, repair proceeds independently
via separate service technicians working on each subsystem. The return to service of
onesubsystemisindependentoftheothers.
 SequentialRepair–Onlyoneservicepersonisavailable,andheworksonone
subsystematatime.Therefore,onesubsystemisrepairedandreturnedtoservice;and
thenthenextsubsystemisrepaired.
parallelrepair sequentialrepair
RepairStategies
Lettingabetheavailabilityofasubsystem,rbethesubsystem’srepairandrecoverytime,andR
betherestoretimeofthesystemonceonesubsystemhasbeenreturnedtoservice,weshowed
thatthesystemfailureprobability,F,forthetworepairstrategiesisgivenby
r/(s1)R
F f(1a)s1 forparallelrepair (4)
r/(s1)
rR
F f(1a)s1 forsequentialrepair (5)
r
where
F istheprobabilityoffailureofthesystem.
f is the number of failure modes for the system. It is the number of ways that the
failureofs+1subsystemsoutofnsubsystemscancauseasystemfailure..
n isthenumberofsubsystemsinthesystem.
a istheavailabilityofasubsystem.
s isthenumberofsparesubsystemsinthesystem.
r istherepairandrecoverytimeforasubsystem.Thatis,itisthetimerequiredto
returnthesubsystemtoservice.
R is the restore time of the system. It is the time that it takes to perform system-
wide functions required to return the system to service once it has a full
complement of subsystems. For instance, these functions may include
database resynchronization and the reentryof transactions that occurred during
thesystem’sdowntime.
2
©2007SombersAssociates,Inc.,andW.H.Highleyman

Forasingle-sparedsystem(s=1),theserelationshipsbecome
r/2Rn(n1)
F (1a)2 forparallelrepair (6)
r/2 2
rR
F n(n1)(1a)2 forsequentialrepair (7)
r
If afaultis duetoahardwarefault,thehardwaremustberepairedandthesubsystem recovered.
However, if the fault is not caused by hardware, the subsystem needs only to be recovered. In
this case, if only h of the faults are caused by hardware, the subsystem recovery time r in the
above equations can be replaced with (r’+hr) where r’ is the subsystem recovery time, h is the
proportionoffaultscausedbyhardware,andrisnowthehardwarerepairtime.
What is Failover?
In a redundant system, when a component fails,
the system invokes a backup component to take
its place. This process is called failover – the
functions of the failed component are failed over
tothebackupcomponent.
Failover
Depending upon the system, failover can be
measured in milliseconds (process pairs in a
NonStop system), seconds (an active/active system), minutes (a cluster), or hours or more (a
cold backup system). During the failover period, some system functions may not be available; or
someusersmaynot beprovidedservice. Oncethefailover is complete,allservices arerestored,
albeitatperhapsareducedresponsivenessifcomponentsaremoreheavilyloaded.
The Impact of Failover Time on Availability
We start by assuming the worst case – that the system is totally unavailable during the failover
time.Thisisthecaseforactive/standbycomputerconfigurationsaswellasforclustersifacluster
node is providing unique services. We will cover the case of partial unavailability during failover
later. Active/active systems are examples of this case since a failure of one node out of n denies
servicetoonly1/noftheusersratherthanallusers.
Whenconsideringfailovertime,wehavetwosourcesofsystemdowntime:
 s+1subsystemsfail,or
 onesubsystemfails,andthesystemmustfailovertoabackupsubsystem.
s+1SubsystemsFail
Thecontributiontotheprobabilityofsystemfailureduetoamultiplesubsystemfailureisgivenby
Equations(4)through(7)above.
3
©2007SombersAssociates,Inc.,andW.H.Highleyman

Failover
The system will be down for a failover time everytimethere is a single subsystem failure. If each
of the n subsystems has a mean time before failure of mtbf, an n-subsystem system will have a
single subsystem failure every mtbf/n units of time. Let us define MTFO as the mean time for
failover.Thentheprobabilitythatthesystemwillbedownwhileitisfailingoveris
MTFO
probabilitythatsystem isdownduetofailover= (8)
mtbf/n+MTFO
That is, once a failover has completed, there will be an average time of mtbf/n until the next
subsystem failure occurs (remember that mtbf is defined as the mean time before failure, not the
meantimebetweenfailures).Whenthatsubsystem fails,afailover musttakeplace,takingatime
ofMTFO.Therefore,thetotaltimebetweensubsystemfailuresis(mtbf/n+MTFO).Thesystemis
downMTFOofthistime.
SystemProbabilityofFailurewithFailover
The probabilityof system failure during failover time must be added to the system down time due
to a multiple system failure. Taking the case of a single-spared system with parallel repair, the
systemfailoverprobabilitybecomes
r/2Rn(n1) MTFO
F (1a)2 
r/2 2 mtbf/nMTFO
(9)
r/2Rn(n1) MTFO
 (1a)2 
r/2 2 mtbf/n
whereF,r,R,a,andnaredefinedaboveand
mtbf isthemeantimebeforefailureofasubsystem.
MTFO isthemeantimeforfailover.
Theapproximationisgoodifmtbf/n>>MTFO,whichwillnormallybethecase.
The parameters for nodal recovery time, r, nodal mean time before failure, mtbf, and nodal
availability,a,arerelatedbyEquations(1)and(3)asfollows:
mtbf r/(1a)
Thus,Equation(9)canberewrittenas
r/2Rn(n1) MTFO
F (1a)2  n(1a) (10)
r/2 2 r
Note that as a practical matter, MTFO should be no larger than R, the system restore time, since
the time to bring up the backup system should be no longer than the time to bring up the entire
system following a multiple subsystem failure. In fact, it will generally be much less (except,
perhaps,foracoldstandby).
4
©2007SombersAssociates,Inc.,andW.H.Highleyman

Some Examples
ACluster
Let us first take the case of a single-spared, four-node cluster which is made up of nodes with
availabilities of .999. The recovery time for a node is two hours, as is the system restore time.
Thefailovertimeisthreeminutes.Thus,
r =2hours
R =2hours
n =4
a =.999
s =1
MTFO =.05hours(3minutes)
Theprobabilitiesoffailureforthiscaseare:
Probabilitythatthesystemisdownduetoamultiplenodefailure=1.8x10-5
Probabilitythatthesystemisdownduringfailover=10x10-5
Probabilitythatthesystemisdown=11.8x10-5
The inherent system availability has been reduced from .999982 to .999882, or from a little less
than five nines to a little less than four nines, due to failover times. Failover time has reduced
availability by about one 9. Put another way, failover time has increased downtime by more than
afactorofsix.
AHotStandby
Letusnowtakeafault-tolerantsystemwithanavailabilityoffour9s.Thesystemisbackedupby
alikesystemasahotstandby.Themeantimetofailoveris2hours.Allotherparametersarethe
same:
r =2hours
R =2hours
n =2
a =.9999
s =1
MTFO =2hours
Theresultsforthiscaseare
Probabilitythatthesystemisdownduetoamultiplenodefailure=3x10-8
Probabilitythatthesystemisdownduringfailover=2x10-4
Probabilitythatthesystemisdown=2x10-4
Theinherentsystemavailabilityhasbeenreducedfromoverseven9stolessthanfour9s.
Failovertimedominatesthesystemavailabilityinthiscase.
5
©2007SombersAssociates,Inc.,andW.H.Highleyman

Active/Active Systems
Active/activesystems andsystems withsimilar characteristics aresomewhat differentinthatonly
a portion of users are affected by a failover. If users are evenly distributed across the n nodes in
thesystem,thefailureofanodeaffectsonly1/noftheusers.
In many applications, availability is taken as the availability of services to the user, not of the
availability of the system as a whole. In this case, a failover affects only 1/n of the users; and
therefore the probability that the system is unavailable due to failover should be reduced by that
factor.
Equation(10)thenbecomes
r/2Rn(n1) MTFO1
F (1a)s1 n(1a)
r/2 2 r n
(11)
r/2Rn(n1) MTFO
 (1a)s1 (1a)
r/2 2 r
Let us take as an example an active/active system with the same parameters as the hot standby
exampleaboveexceptthatthefailovertimeis1second.Then
r =2hours
R =2hours
n =2
a =.9999
s =1
MTFO =1seconds=.00028hours
Theresultsforthiscaseare
Probabilitythatthesystemisdownduetoamultiplenodefailure=3x10-8
Probabilitythatthesystemisdownduringfailover=1.4x10-8
Probabilitythatthesystemisdown= 4.4x10-8
The probability of failure has been increased by about 50%, but the attribute of extreme
availabilityhasbeenmaintained(overseven9s).
Summary
Failover time plays a very important and sometimes dominant role in system availability. For
some system configurations such as an active/standby system, failover times in the order of
hours completely mask the system downtime due to dual system failures. In these cases, the
resulting system cannot really be considered a high availability system. It is a disaster-tolerant
system in that it can recover from failures of the active system but only at the cost of seriously
reducedavailability.
Clusters fare significantly better. Failover times contribute a significant but not an overwhelming
contributiontothefailureprobabilityofacluster.
Active/active systems still retain their attribute of extreme availability in the presence of failover
timessolongasthesetimescanbekeptshort,measuredinsecondsratherthanminutes.
6
©2007SombersAssociates,Inc.,andW.H.Highleyman
