Calculating RPO
March2010
Specifying RPO
In a redundant data-processing system, RPO, the Recovery Point Objective, is the amount of
datalossthatisacceptablefollowinganodefailure.ThespecificationofRPObecomesespecially
important for critical applications using data replication between active/active nodes or from an
activenodetoabackupnode.
Tighter RPOs mean faster servers and greater bandwidth between the nodes. Therefore, a real
cost is associated with the RPO specification. As a consequence, it is important to be able to
reasonablyestimatetheRPOthatagivensystemcanmeet.Ifitisinsufficient,additionalexpense
maybe needed to enhance the system. There is a tradeoff between the cost of lost data and the
systemandcommunicationcoststoprotectthatdatathatmustbeconsideredbymanagement.
Of course,itis unrealistic tothink thatthere is an absolutelimittodataloss. Someobscureevent
may result in a significant loss of data even though the expected loss might be quite small.
Therefore, the RPO should be expressed as a probability that no more than a certain amount of
datawillbelost.Forinstance,theRPOmaystatethat
“99% of node failures will result in no more than 300 milliseconds of lost data at 100
transactionspersecond.”
Sincethere willbeontheaverage30transactions executedin300msec.at100transactions
persecond,thiscouldequallyaswellbeexpressedas
“99% of node failures will result in no more than 30 lost transactions at 100 transactions
persecond.”
We will deal in this article with the first form of the RPO expressed in time rather than in
transactions.
If an SLA (service level agreement) specifies a fixed RPO, an accurate estimate will indicate the
probabilitythattheSLAwillbeviolated(ausefulmetrictoaserviceprovidertoletitproperlyprice
an SLA). In this article, we discuss a method to estimate the probability of data loss following a
nodefailure.
The Relation of RPO to Replication Latency
In systems using replication to keep databases in synchronism, there are two forms of data
replication that might be used – synchronous replication and asynchronous replication. If
1
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

synchronous replicationis used,1thereis nodataloss followinga nodefailuresincenochangeis
made to any database copy in the application network unless that change can be made to all
databasecopies.
However, if asynchronous replication is used,2 changes are replicated after the fact from a
change queue. Therefore, should a node fail, changes that are still waiting to be replicated may
belost.Thisleadstolosttransactionsthatmayhaveasignificantimpactoncorporatefinancesor
on operations. Therefore, it is common that an impact analysis be done on each critical
application and that a limit be placed on the amount of data that may be lost following a node
failure.ThislimitistheRPO,andittypicallyvariesfromapplicationtoapplication.
In calculating RPO, we are dealing with a queuing system. Changes are queued and are
processed on a first-in, first-out basis by a server, the replication engine. The replication engine
extracts the next change from the change queue, sends it to the target system, and applies it to
the target database. The interval from the time that the change is entered into the change queue
to the time that it is applied to the target database is the response time of the server.We call this
responsetimethereplicationlatencyofthereplicationengine.
If we assume that anychange in the change queue or in the replication engine server at the time
of a node failure is lost, then knowing the distribution of the replication latency time will let us
makeastatementabouttheprobabilityofdataloss.
Estimating RPO
The measurement of data loss following a node failure in actual practice can be quite complex.
Unless this measurement can be made, there is no assurance that the RPO specification can be
met.
Thisestimatecanbeachievedviatwodifferentmethods:
 Thereplicationchannelcanbemodeled.
 Thereplicationchannelcanbemeasured.
Modeling the replication channel can be very complex if even possible, and the model must be
verified by measurement. Therefore, the replication channel must be measured anyway; so why
not simply use those measurements to calculate the RPO and avoid possible modeling errors?
Thisisthetechniquetobedescribedbelow.
The procedure depends upon the use of a very powerful probability distribution – the Gamma
distribution,whichwefirstintroduce.
TheGammaDistribution
The Gamma distribution comes with a compelling history. In the early days of telephony, the
Erlang distribution, developed by A. K. Erlang, was used to determine the number of telephone
calls that might be waiting for telephone operators. This work has been expanded to determine
the distribution of waiting times in queuing systems in general, such as those of a replication
channel. The resulting probability distribution is the Gamma function. It has been shown to give
surprisinglycloseresultstoactualresponsetimesmeasuredinpracticeorbysimulation.
1SynchronousReplication,AvailabilityDigest;December2006.
2AsynchronousReplicationEngines,AvailabilityDigest;November2006.
2
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

The Gamma distribution3 provides the probability that a variable will have a value less than a
specified value – just what we need. It depends upon only one parameter represented by R,
whichistheratioofthesquareofthedistribution’smeantoitsvariance.
Sinceweareinterestedinthedistributionofreplicationtime,forourpurposesRisgivenby
 2
T
r
R (1)
var(T)
r
where
T isthereplicationtime
r
T isthemean(average)replicationtime
r
var(T )isthevarianceof thereplicationtime,T .
r r
Thus, if we can determine the mean and the variance of the replication time (that is, replication
latency),wecanmakeastatementabouttheprobabilitythattheresponsetimewillbelessthana
certain value. It can be shown that both the mean replication time and its variance are a function
of the load on the replication channel. This will become important when we make our
measurements.
The mathematical representation of the Gamma distribution is not very palatable (see page 439
of the above footnote referencing Martin’s book). Fortunately, Excel comes to the rescue with its
GAMMADISTfunction.Forourpurposes,weuse
Probability(T <T )=p=(GAMMADIST(zR,R,1,TRUE)
r m
(2)
wherezistheratioofthemaximumspecifiedreplicationtimetothemeanreplicationtime:
maximum replicationtime T
z  m (3)
meanreplicationtime T
r
andT isthemaximumspecifiedresponsetime.4
m
ThisdistributionisshowninFigures1aand1b.Figure1bexplodesthehigherprobabilities.
MeasuringReplicationLatency
In order to measure the actual replication latency, we must somehow instrument the replication
engine. To do this, we tag each change with the time that it was generated as well as the time
that it was applied to the target database. The difference between these times is the replication
latencyforthatparticularchange.
LetusassumethatourRPOspecificationisgivenby
“99% of node failures will result in no more than 300 milliseconds of lost data at 100
transactionspersecond.”
3JamesMartin,Chapter31,QueuingCalculations,pp.438-444,SystemsAnalysisforDataTransmission,Prentice-Hall;
1972.
4 The third parameter, “1,” returns the standard Gamma distribution. The parameter “TRUE” returns the cumulative
distribution. “FALSE” returns the probability density function. Excel also provides an inverse Gamma function, which
provideszR=GAMMAINV(P,R,1).
3
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

1.00
6
4
0.98
3
A
0.96
0.94
probability
0.92
(T r  T m) T m/T r = 2
0.90
0.88
0.86
0.84
1 2 3 4 5 6
R= (T2)2/var(T )
r r
R = T / var(T )
r r
Allowable Variance to Meet RPO
Figure 1a
1.000
6
0.995
5
4
probability
0.990
B
(T < T )
r m
T /T = 3
m r
0.985
R=1.9
A
0.980
1 2 3 4 5 6
2
RR==T( rT r)/2v/vaar(r(TT rr))
Allowable Variance to Meet RPO
Figure 1b
4
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

We generate a transaction load of 100 transactions per second and measure the replication
latency of each change that is replicated. Typically, this would be thousands of changes that
would be analyzed programmatically. However, to illustrate the calculation, let us take just five
samplesofreplicationlatency,whichare:
MeasuredReplication
Latency(msec.)
38
144
53
41
224
Total 500
Mean 100msec.
Our average replication latency is 100 msec. The next step is to calculate the variance of these
measurements. The variance is the average of the squares of the deviations of each
measurementfromthemean:
Measurement Deviationfrom Deviation2
(msec.) Mean(msec.) (msec.2)
38 -62 3,844
144 44 1,936
53 -47 2,209
41 -59 3,481
224 124 15,376
Total 26,846
Variance 5,369
Thevaluesofourparametersarethus:
T =themaximumspecifiedresponsetime(fromtheRPOspecification)=300msec.
m
T =themean(average)replicationtime=100msec.
r
var(T )=thevarianceofT =5,369.
r r
Then,fromEquations(1)and(3),wefindthat:
 2
T (100)2
r
R  1.861.9
var(T) 5,369
r
T 300
z m  3
T 100
r
This is plotted as point A on Figures 1a and 1b. We see that we do not meet the RPO
specification. In fact, only 98% of failures will result in less than 300 msec. of lost data, not 99%
asrequiredbytheRPOspecification.
Howcanwefixthis?Weobviouslyhavetospeedupthereplicationengine.Butbyhowmuch?
ExcelcomestotherescuewiththeinverseGAMMAfunctionreferencedinfootnote4:
zR=GAMMAINV(p,R,1) (4)
5
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

This function makes a very simple statement. If we know the probability p and the parameter R,
we know the quantity zR. We know the probability p that we are trying to achieve – 99%. What
about R? Interestingly, R remains the same (at least to a first approximation) if we simply speed
upthereplicationengine.Thedistributionofresponsetimesstaysthesame–theyjustgetfaster.
The mean and deviations both decrease proportionately, leaving R the same. Therefore, we can
use the inverse Gamma function, Equation (4), to calculate the value of z that we must achieve.
UsingExcel,wefind:
zRGAMMAINV(0.99, 1.86, 1)6.45
6.45 6.45 T
z  3.46 m
R 1.86 T
r
T 300
T  m  87 msec.
r z 3.46
ThisisplottedaspointBonFigure1b.
This leaves us with two tasks. The first task is to determine what components in the replication
channel can be upgraded to pick up 13 msec. (perhaps a faster communication link will do the
trick).
The final task is then to confront management with the choice of the cost of upgrading the
replication channel or the cost of a probability of 2% of unacceptable lost data rather than a 1%
chance.
Summary
By using the Gamma distribution curves in Figures 1a and 1b, you can determine whether you
can meet an RPO specification based on straightforward measurements of replication latency. If
your current system does not meet the specification, you can determine the specification that it
canmeet.
Alternatively, youcandeterminehowmuch youhavetospeed upthereplication channelinorder
to meet the specification. A cost/benefit decision can then be made as to whether to spend the
moneytospeedupreplicationortoacceptareducedRPOspecification.
6
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com