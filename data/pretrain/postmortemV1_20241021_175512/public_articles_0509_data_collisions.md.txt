Handling Data Collisions in Asynchronous Replication
September2010
A major impediment to moving to an active/active architecture for some applications is the
problem of data collisions when using asynchronous replication. In an earlier article a few years
ago, we explored techniques for resolving data collisions.1 In this article, we update these
methodologieswithsomeadditionaltechniques.
What is an Active/Active System?
An active/active system2 comprises two or more geographically-distributed processing nodes all
cooperating in a common application. The databases of the processing nodes are kept
synchronized via real-time data replication. Should a processing node fail, all that needs to be
doneistoreroutefurthertransactionstosurvivingnodesintheapplicationnetwork.
What Is a Data Collision
AsynchronousVersusSynchronousReplication
There are two basic ways to replicate data between a source database and a target database –
asynchronously and synchronously. With asynchronous replication, changes to the source
databasearequeuedandaresenttothetargetsystem after thefact.Asynchronous replicationis
generallytransparenttotheapplication.
With synchronous replication, a change cannot be made to the source database unless it is also
made at the same time to the target database. Synchronous replication impacts application
performance since the application must wait for each change to complete across the application
network.
Both methods are subject to data conflicts in an active/active architecture should the application
instance in two different nodes in the application network attempt to change the same data item
at the same time. This is because of the delay in signaling between the nodes due to
communication latency and replication delays. With asynchronous replication, simultaneous
changes will be replicated to the other node and will overwrite the change originallymade at that
node.Nowthedatabasesaredifferentandbotharewrong.Thisisadatacollision.
A data conflict in a synchronous replication environment occurs when the application instance in
two different nodes lock their local copies of the same data item at the same time. When each
1CollisionDetectionandResolution,AvailabilityDigest;April2007.
http://www.availabilitydigest.com/private/0204/collisions.pdf
2WhatisActive/Active,AvailabilityDigest;October2006.
1
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

attempts to gain a lock on the remote copy of the data item, neither can. A distributed deadlock
hasoccurred.Distributeddeadlocksaregenerallyresolvedviatimeouts.
Asynchronous replication suffers from another problem, and that is data loss. Source data
changesmaynotbereflectedinthetargetdatabasefortworeasons.Shouldthesourcenodefail,
changes in the replication pipeline may not make it to the target system. Secondly, there is no
guarantee that the target node will be able to apply changes that it receives from the source
system.If itcannotfor somereason,thechanges madetothesourcedatabase willnotappear in
the target database. It is for these reasons that a verification and validation utility should be
periodically run to compare the databases and to repair them if necessary. Synchronous
replicationdoesnothavethisproblem–eitheralldatabasecopiesarechangedornoneare.
Withrespectto dataconflicts,datacollisions under asynchronous replicationcan present amuch
moredifficultproblem thandistributeddeadlocksundersynchronousreplication.Inthisarticle,we
discusstechniquesforavoidingorresolvingdatacollisions.
DataCollisionRates
How frequent are data collisions? That depends upon the application. The rate of data collisions
depends uponthe databasesize (the moreconcentratedthe updates, thehigher the likelihood of
a collision), the update rate (the higher the database update rate, the more likely data collisions
will occur), and the latency of the replication engine (the longer it takes to get a change to the
target,themorelikelyadatacollision).
Itcanbeshownthattheexpectedrateofdatacollisionsinatwo-nodeactive/activesystemis3
1 (updates/second)2
datacollisionrate= (replicationlatencyinseconds)
2 databasesize(inrows)
For instance,at an update rateof 100 updates per secondto adatabase with a millionrows4and
a replication engine with a latency of 100 milliseconds, about 2 collisions per hour can be
expected.
Applications That Don’t Care
There are certain applications that may not care about collisions. When a data collision occurs,
the data item that is the subject of the data collision will have a different value in each of the
nodes. However, on the next update to that data item (ignoring the extremelyunlikelyoccurrence
of another data collision), the data items will be resynchronized when the new value entered at
the source system is replicated to the target system. Such applications may, for instance, be
thosethatareusedprimarilyforstatisticalanalyses.
Another example is an application that only performs inserts into a database. In such
applications,datacollisionscannotoccursincetherearenorowchangesbeingmade.
Techniques to Avoid Data Collisions
Thereareseveralwaysthatsomeapplicationscanbestructuredsoastoavoiddatacollisions.
3 Chapter 9, Data Conflict Rates, Breaking the Availability Barrier: Survivable Systems for Enterprise Computing,
AuthorHouse;2004.
4 The databasesizetouseis the activeportionofthedatabase,notthe entiresize ofthedatabase. Thisis
particularlyimportantiftherearehotspotsinthedatabase.
2
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

SynchronousReplication
Data collisions will not occur if synchronous replication is used. This is because the source
system must acquire a lock on all copies of the data item across the application network before it
can change any of the copies. Once it is holding all locks, it will change all copies before it
releases its locks. During the time that it is holding the locks, no other application instance can
changeitslocalcopyofthedataitem.
As described above, data conflicts under synchronous replication become distributed deadlocks.
If two application instances in two different nodes lock their own copies of the data item at the
same time, then neither can obtain a lock on the remote copy. One or both instances must
timeoutandreleaseitslocksinorderforprocessingtocontinue.
PartitionedDatabase
If thedatabasecan bepartitioned, datacollisions can beavoidedunder asynchronous replication
by assigning each partition to an “owning node.” Only the owner of a partition can update that
partition.If anodereceives anupdatefor anodethat itdoes notown,itmustforwardthatupdate
totheowningnode.Sinceanyparticulardataitemcanonlybeupdatedbyonenode,therewillbe
no data collisions. Of course, if a node fails, then another node must take ownership of the
partitionoriginallyownedbythefailednode.
Forwarding updates can present application performance problems since the application
response time will be degraded as the updates propagate across the network. Partitioning works
particularlywellforapplicationsinwhichuserscanbesimilarlypartitionedtominimizetheneedto
forwardupdates.Forinstance,asalesapplicationmightpartitioncustomers.Salespeoplecanbe
assigned to the node that owns the partition containing the customers most likelyto be accessed
byeachsalesperson.
Manytransaction-oriented applications maynot be goodcandidates for partitioning.For instance,
an order-processing application may require access to both the customer database and the
inventorydatabase.Anycustomertransactionmusthaveaccesstotheentireinventorydatabase.
There is no effective way to partition both the customer database and the inventory database
simultaneously.
RelativeReplication
In general, a replication engine will forward an entire row (or block, in some cases) from the
source node to the target node, overwriting the row or block at the target node. Thus, any
simultaneous change just made by Node A will be overwritten by the change made by Node B,
justasNodeAissimilarlycorruptingNodeB.Thisisadatacollision.
There are some applications in which commutative operations may be replicated rather than a
row or block of data. Commutative operations are those that can be executed in any order and
arriveatthecorrectresult.Forinstance,additionandsubtractionarecommutation–10+2-3gives
the same result (9) as 10-3+2. Likewise, multiplication and division are commutative – 10x2/5 is
the same (4) as 10/5x2. However, note that addition/subtraction is not commutative with
multiplication/division–10x2-5=15doesnotgivethesameresultas10-5x2=10.
If an application updates data items only with commutative operations, the operations can be
replicated instead of rows or blocks. This is relative replication. Relative replication avoids data
conflicts. Though each node will update its local copy of the data item with operations in a
differentorderfromtheothernode,bothnodeswillarriveatthesameresult.
3
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Even if there is a mix of commutative and non-commutative operations in an application, the
commutative operations can be replicated with relative replication to reduce the rate of data
collisions.
GlobalMutex
Similar to synchronous replication, if a node can obtain a lock on all data item copies across the
application network before updating its own local copy, changes can be asynchronously
replicated without data collisions. Each database copy will independently release its lock after it
hasupdateditslocalcopy.
One technique to accomplish this is via a global mutex. A global mutex is a lock managed by a
lock master, which could be the responsibility of one of the nodes in the application network. Of
course,ifthelockmasternodeshouldfail,anothernodemustbepromotedtobethelockmaster.
In order to update a data item, an application instance must first acquire the lock on the
appropriate global mutex. It can then update its local copy of the data item and asynchronously
replicate its change to the other nodes in the network. No other node can update that data item
solongasthelockisheld.
One complication with this technique is that the lock cannot be released until all nodes have
asynchronously updated the data item. Therefore, each must notify the lock master that it has
completed its update. Only when all application instances have so notified the lock master can
the lock master release the lock. At this time, another application instance may acquire the lock
andinitiateitsownchange.
The global mutex may protect a set of data items. For instance, in an invoicing application, there
maybe a global mutex protecting each invoice. In order for an application instance to modifyany
of the detail lines in an invoice, it must acquire the global mutex for that invoice header. It is then
free to modify all detail lines in the invoice and asynchronously replicate these changes to the
other nodes. Only when all nodes have reported to the lock master that they have applied all
changestotheinvoiceisthegloballockreleased.
DistributedLockManagement
Anothermethodtoimplementasynchronous lockingisviadistributedlockmanagement.Withthis
method, there is no common global mutex. Rather, when a source node acquires a lock on, say,
itsownlocalcopyofaninvoiceheader,itmustalsorequestthetargetnodetoacquirethelockon
the target copy of the invoice header. This is done while the source application is applying its
updatestotheinvoicesothattheapplicationisnotsloweddown.
When the target node has successfully acquired the target lock, it so notifies the source node so
that the source node can complete its updating. The source node’s changes are asynchronously
replicated to the target node. When the changes have been applied to the target node’s
database,thetargetnodecanreleaseitslocalheaderlock.Thus,nootherapplicationcanmodify
the invoice at the target node until the changes have been applied, and no data collisions will
occur.
If the target node’s acknowledgement of the lock is received by the source node before it
completes the processing of the transaction, then the source application is not delayed and
proceedstocompletionindependentoftargetnodeprocessing.Ifthenotificationofthetargetlock
is delayed, the source application must wait until it receives the lock notification from the target
node before it can complete its updating of the source database. If a lock cannot be acquired at
the target system, a distributed deadlock has probably occurred and one or both nodes must
backoffandtryagain.
4
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

DataLoss
It was noted above that data can be lost using asynchronous replication. This is true even with
data locking using either of the above techniques. The source system is free to complete the
update of its database as soon as it knows that the data item is locked across the network. It
does not wait to see that the updates to the remote databases are successful. Should a remote
nodebeunabletomaketheupdate,itsdatabasewillbeoutofsynchronismwiththeothers.
Thisisincontrasttosynchronousreplication, whichalsodependsuponlockingdataitemsacross
the network. However, with synchronous replication, the source database cannot commit its
changes until it is assured that all databases can commit their changes. Therefore, the changes
areguaranteedtobeappliedtoalldatabasesortonone.
Synchronous replication using distributed lock management is the basis for coordinated commit
replication engines that replicate data changes asynchronously but which then commit the
transaction synchronously.5 In this way, not only are data collisions and data loss avoided, but
applicationdelaysarereduced.
Handling Data Collisions
If data collisions cannot be avoided by one of the techniques described above, then data
collisionsmustbedetectedandresolved.
CollisionDetection
Thefirststepistodetectadatacollision.Thisisdonebycomparingtheversionofthesourcerow
before modification to the version of the target row. If they are the same, then there is no data
collision. However, if the target row version is different from the source row version, then a data
collisionhasoccurred.
Row(orblock)versioncomparisonisdoneinsomecasesbysendingthebefore-imageoftherow
or block along withthe after imagethatrepresents the updatedrowor block.If thebeforeimages
aredifferent,thenadatacollisionhasoccurred.
Version checking can also be done with other methods such as a date-time stamp of the last
updateoraroworblockversionnumber.Date-timestampingimpliesthatthereisroomintherow
or block to store a date-time stamp indicating when the row was created. The same applies to
versionnumbers.
CollisionResolution
Ifadatacollisionhasbeendetected,thenadecisionmustbemadeastowhichchangetoaccept
and which to reject. It is of paramount importance that the collision resolution algorithm yield the
same result at all nodes, or else the databases will diverge. There are several methods for
determining a collision winner. Most active/active replication engines support a variety of the
followingcollisionresolutionalgorithms.
Master/Slave
Insomeactive/activearchitectures,one nodeis designatedthemaster nodeand theother nodes
are all slave nodes. All updates are routed to the master node by the slave nodes. The master
5Holenstein,B.D.,etal,Asynchronous coordinatedcommit replicationanddual writewithreplicationtransmissionand
lockingoftargetdatabaseonupdatesonly,U.S.Patent7,177,866;February13,2007.
5
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

node will resolve all collisions based on some criteria, including the ones detailed below (data
content, hierarchy, etc.) It will update its database with the winning update and will replicate that
updatetotheslaves.Itwilllogthelosingupdateforlatermanualprocessingifnecessary.
A variation of the master/slave architecture is to allow each slave to process updates routed to it.
A slave will apply the changes to its database and will replicate its changes to the master. The
master willupdateits databasewiththechanges andwillresolveanycollisions betweenchanges
routed directly to it or by the other slaves. It will then replicate the winning change to all slaves,
includingtheslavethatoriginatedthechange.
Ifthemastershouldfail,oneoftheslavesmustbepromotedtomaster.
Hierarchical
With hierarchical collision resolution, each node has a unique precedence. The higher
precedencealways wins.
Thus, if a node receives competing changes from two other nodes (or from another node
competing with its own change), it will accept the change from the node with the highest
precedence.Inthisway,allnodeswillmakethesamedecision.
Thelosingchangeisloggedforlatermanualprocessing.
DataContent
The winning change can be determined by data content. For instance, the later change (or the
earlierchange)maybetheoneaccepted,withtheotherchangebeingrejectedandlogged.
SpecializedBusinessRules
If none of the standard resolution algorithms will work, many replication engines support
imbeddeduserexitsthatcanbeusedtoprogramspecializedrulesforcollisionresolution.
ManualResolution
If all else fails, the collision should be logged for later manual resolution. It is, of course, the goal
of the automated collision resolution methods described above to minimize the need for manual
resolution.
Logging
Nomatter the outcome of a data collision resolution, the losing change should be logged for later
manualreview.Notonlywillthisallowcorrectionstothedatabasetobemadebasedondatabase
changes that could not be honored, but it may allow tuning of the data collision algorithms over
timetoprovidemoreaccurateresolution.
Summary
Data collisions represent a particularly critical problem when asynchronous replication is used to
keep databases synchronized in active/active systems. However, there are standard techniques
for configuring systems to avoid data collisions or to reliably resolve data collisions uniformly
across the application network if they cannot be avoided. Today’s replication engines generally
supportthesemethods.
6
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

The key is to structure an application to minimize the number of data collisions that must be
resolvedmanually.
7
©2010SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com