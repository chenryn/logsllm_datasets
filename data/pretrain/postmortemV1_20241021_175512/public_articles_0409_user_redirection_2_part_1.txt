Achieving Fast Failover in Active/Active Systems - Part 2
September2009
Active/active systems1 provide continuous availability not because they avoid faults but because
theycanrecoverfromfaultssoquicklythatusersdon’tnoticethattherehasbeenanoutage.This
capabilityrequiresnotonlythatfailovertoabackupcomponentberapidbutthatitbereliable.
An active/active system (Figure 1) node1
comprises two or more geographically-
separated processing nodes, each actively appl data
A base
participating in a common application using
a local synchronized copy of the application active
node3
database. The database copies in the
replication network are kept in synchronism replication data appl
viadatareplication. cloud base A
active
Shouldaprocessingnodefail,allthatneeds
to be done is to switch users from the failed
node2
node to one of the surviving nodes. Since it
is known that the surviving nodes are appl data
A base
operational because they are actively
processing transactions, failover is risk-free active
andreliable.
AnActive/ActiveSystem
Figure1
However, how can users be redirected to
other processing nodes so quickly that they
arenotawareofthefaultandtherecoveryaction,oratleastarenotinconveniencedbyit?InPart
1ofthisseries,wetalkedaboutredirectingusersviaclientintelligenceorvianetworkintelligence.
In this Part 2, we explore server redirection in which faults are detected and users redirected via
intelligenceintheservers.
Server Redirection
FaultDetection
Heartbeats
Before users can be switched from afailed node, it must be known that the node has failed.With
client redirection and network redirection described in Part 1, this is the responsibility of the
1WhatisActive/Active?,AvailabilityDigest;October,2006.
1
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

clients or the network. With server redirection, the nodes themselves must be able to detect a
faultinanothernode.
The common technique to do this is to use heartbeats Node1 Node2
between the nodes, as shown in Figure 2. Each node
generates a heartbeat – in effect, an “I’m alive” message – heartbeat
to all of the other nodes in the application network. Should
a node detect the loss of a heartbeat, then it assumes that
theothernodeisdownanditcaninitiaterecoveryaction.
A heartbeat can be a simple ping, or it can be generated at HeartbeatMonitoring
a higher level in the application stack. The problem with a Figure2
simple ping is that the system may be able to respond to
the ping even if it cannot respond to transaction requests, either due to congestion or to some
higher level fault. The farther up the application stack that the heartbeat is generated, the more
reliable it will be. The ultimate is for each application to generate its own heartbeat so that the
failureofindividualapplicationsinanodecanbedetected.
Aheartbeatmaybeasimple“I’malive”message,oritmaycarryadditionalinformationdescribing
the node’s health. For instance, it might include the failure of redundant components that, though
not fatal, result in single points of failure. It might include congestion information (queue lengths)
or performance metrics. A node can be designed to take over the users of another node only if it
ishealthierthantheothernode.
Heartbeatmessagesmaybebidirectionalinthatsuchamessagesenttoanother nodeexpectsa
response from that node, perhaps with equivalent information. Alternatively, the data replication
channel may serve as a heartbeat. So long as replicated data is being received from a node, it
can be assumed that the node is up. If a node has no replicated data to send, it sends a
heartbeatmessageinstead.
Sincetheheartbeatmessageistheprimaryfault-detectionmethodinanactive/activesystem,itis
imperative that it be reliable. Should the heartbeat network fail, both nodes on either end of the
connectionwillassumethattheothernodehasfailed,apotentiallydisastrousconditionleadingto
a”tug-of-war”.Thetug-of-warsyndromeisdiscussedinthenextsection.
Therefore, heartbeats should be sent over a non-switched redundant network (i.e., over direct
connections). If the replication channel is used, this is often a redundant network anyway. As a
further backup, the user network that connects clients to the processing nodes might be used to
broadcastheartbeatmessagesshouldtheprimaryheartbeatnetworkfail.
Typically, nodes are forgiving when monitoring heartbeats. It is expected that a heartbeat will
occasionally be lost or be late. Therefore, it is common to not declare a fault until a certain
numberofheartbeats,typicallythree,arelost.
One important heartbeat tradeoff is network load versus fault detection time. To truly achieve
continuous availability, fault detection should be very rapid, typically measured in the subsecond
range. This means that each node must send several heartbeats per second. However, rapid
heartbeats may significantly increase network load. The more complex a heartbeat message is,
the more heartbeats that must be missed before declaring a fault, and the shorter the desired
fault-detection time all contribute to increased network load. However, if the number of nodes in
the application network is small, heartbeat traffic may not be a significant factor in network load,
andfastfault-detectiontimes–andthusfastfailovertimes–canbeachieved.
2
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

The“Tug-of-War”Syndrome
Ifheartbeatmessagesarelostduetoanetwork failure,bothnodesoneitherendoftheheartbeat
connection will assume that the other node has failed and will try to switch the users currently
connected to the other node to itself. Since each node is attempting to do this, a tug-of-war
develops (Figure 3) in which users may be switched back-and-forth between nodes, a situation
thatmightcollapsetheactive/activenetwork.
There are several solutions to this problem. One is to not use
automatic failover, but rather to do it manually by operator heartbeat
action. In this case, the operator will be notified of a system
fault. If upon investigation it turns out to be a loss of
heartbeats, the operator can decide to continue on with two IP1 switch switch IP2
nodes or to switch users to one node until the heartbeat toIP1 toIP2
network can be repaired. Of course, if manual switchover is
used, continuous availability has been sacrificed. It may take
many minutes to analyze the fault, to decide on the
appropriate corrective action, perhaps to get management
approval,andthentoeffectthefailover.
Tug-of-War
Another technique is to provide a cluster lock that must be
Figure3
acquired prior to switching users. This lock may be a global
mutex on some other system accessible to the active/active nodes. If heartbeats are lost, both
nodeswillattempttoacquiretheclusterlock,butonlyonewillbesuccessful.Thisisthenodethat
willswitchtheusersoftheothernodetoitself.
AQuorumSystem
Athirdtechnique, whichis usedcommonlyinclassic clusters,2
is to include a quorum system in the active/active application quorum
system
network as shown in Figure 4. A quorum system is an
independent system that is responsible for monitoring nodal
heartbeats and for making switchover decisions. It is the take heart- take
quorum system that receives the heartbeat messages from all over beats over
nodes.
If the quorum system detects a nodal failure, it will direct the
surviving nodes to acquire the users connected to the failed heartbeat
node. If a fault in the heartbeat connection between a node
and the quorum system should occur, the quorum system will
assume that the node has failed and will switch that node’s
userstosurvivingnodes.Inanyevent,sincefailoverdecisions
QuorumMonitoring
are being made by an independent third party (the quorum
Figure4
system),thereisnotugofwar.
Split-BrainMode
The quorum system solves another problem that can arise in active/active systems, and that has
to do with the loss of the data-replication network. Should the data replication network be lost,
then changes made by one node cannot be replicated to the other node. If nothing else is done,
thetwonodes will continue toprocess transactions,queuingtheir changes tothe other node until
the time that the replication network is restored and the queued changes can be drained to the
2Active/ActiveVersusClusters,AvailabilityDigest;May,2007.
3
©2009SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

opposite nodes. During the resynchronization process, data collisions are bound to occur due to
bothnodesupdatingthesamedataobjects.
During the time that replication is down, the databases at the two nodes will diverge. This
conditionis knownas “split brain.” Thereare twoactions thatcan betakenwhen this type of fault
occurs. One is to continue on as is. If data collisions cannot occur or if their resolution can be
handledautomatically,theonlypenaltyisprocessingtransactionsagainststaledata.
However, if data collision resolution is complex, or if processing against stale data is
unacceptable, then one of the nodes must be shut down. As with the tug-of-war syndrome, this
canbeamanualoperatoraction.
However, if a quorum system is in use, it can resolve this problem automatically in the same way
that it resolves tug-of-war situations. If two nodes report that they have lost data replication
between them, the quorum system can direct that one of the nodes shut down and that its users
beswitchedtotheothernode.
CommandingSwitchover
Onceanodehasdeterminedthatitistoacquireusers fromanothernode,thereareseveralways
inwhichitcanproceed.
CommandingClients
