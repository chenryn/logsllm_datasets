The Fallacy of Classic Availability Theory
January 2017
In this paper, we point out a fallacy in classic availability theory. We have become
accustomed to the terms MTBF and MTR. MTBF, the Mean Time Between Failures, is
the average time between failures of a system. MTR, the Mean Time to Repair, is the
average time it takes to repair a system. MTBF and MTR are flawed measures, as described below.
Instead, we introduce the term MTTF - Mean Time To Failure. This is the expected time to the next
system failure. Unlike MTBF and MTR, MTTF is a function of time. As time goes on, MTTF becomes
shorter. The likelihood of a system failure draws nearer.
Classic Availability Theory
According to classic availability theory, availability is the proportion of time that the system is operational.
Let:
MTBF be the mean (average) time between failures of the system.
MTR be the mean (average) time to repair the system.
A be the probability that the system is operational (it is available).
F be the probability that the system is not operational (it has failed).
Then
MTBF−MTR MTR MTR
A = =1− =1−F F= (1)
MTBF MTBF MTBF
Consider a two-node redundant system (either active/passive or active/active) as shown in Figure 1. In an
active/backup configuration, one system is acting as the production system; and the other system is
standing by to take over in the event that the production system fails. In an active/active system, both
systems are actively participating in the application. Should one system fail, all transactions are routed to
the surviving system.
The availability of a node, a, is a = 1 – MTR/MTBF.
The probability that a node will be failed, f, is
f = (1–a) = MTR/MTBF. The probability that both
nodes will be failed (i.e., the system is down), F, is
(2)
F = f2 = (1-a)2
The probability that the system is up (its availability),
A, is Figure 1: Redundant Systems
A = 1 – F = 1 – (1–a)2 (3)
1
© 2017 Sombers Associates, Inc., and W. H. Highleyman

Memoryless Variables
In the classic availability theory discussed above, MTBF and MTR are random variables. This means that
the event (the failure of the system or the repair of the system) is independent of what has happened in
the past and has no impact on what will occur in the future. They are memoryless variables. This has
implications that make no sense:
Assume that MTBF is 1,000 hours. On the average, failures occur every 1,000 hours. Since
MTBF is memoryless, the expected time to the next failure is 1,000 hours. If we wait 500 hours,
the average time to the next failure is still 1,000 hours (even if we had a failure in the intervening
500 hours).
Assume MTR is four hours. When the system fails, it will take an average of four hours to repair
it. If we wait for two hours and ask the technician when he expects the repair to be completed, he
will still say four hours.
The Exponential Distribution
Random variables are described by the exponential distribution function. For instance, consider MTBF.
The probability of failure over time is given by
p(failure)=e−t/MTBF/MTBF 4)
The average time to the next failure is
∞
=∫( te−t/MTBF/MTBF)
average time to next failure dt =MTBF (5)
0
If we wait for a time T, then the average time to the next failure is
∞
average time to next failure = ∫(t−T)e−(t−T)/MTBF/MTBFdt =MTBF (6)
 
T
The average time to the next failure is still MTBF. Random variables characterized by the exponential
distribution function are indeed memoryless.
Classic Availability Theory is Flawed
This is a fundamental flaw in classic availability theory.
The time to the next failure is always the same, no matter
how long the system has been operating. The time to the MTTF
completion of the current repair is always the same, no
matter how long the system has been under repair.
What is needed is a means to estimate the mean time to
the next failure, MTTF, based on realistic probability
distributions of failure. MTTF should be a function of time
(Figure 2). As time goes on, MTTF should become shorter
time
for realistic systems. It is more likely that the system will
fail as time progresses. Figure 2: Mean Time to Failure
Mean Time to Failure (MTTF)
Figure 3 shows a typical probability distribution, p(t), for the failure of a system. When the system is new,
f
it is unlikely to fail. As it ages, the probability that it will fail increases. At some point, the probability that it
will fail will begin to decrease because it likely already has failed.
2
© 2017 Sombers Associates, Inc., and W. H. Highleyman

The probability p that the system will fail at some time t during a small time interval ∆t is p∆t. The mean
i i i
time to failure, MTTF, for the system is the average of these failure probabilities:
∞
MTTF=∑tp∆t (7)
i i
i=0
Figure 3: Typical Failure Probability Distribution
For a continuous function, this becomes:
∞
MTTF= ∫tp (t)dt (7)
f
0
Let us now wait for a time T, as shown in Figure 4. MTTF is now
∞ ∞
∑(t −T)p∆t ∑tp∆t
i i i i
MTTF= i=T = i=T −T (9)
∞ ∞
∑p∆t ∑p∆t
i i
i=T i=T
where the MTTF term has been normalized to account for the shorter time. Comparing equations (7) and
(9), it is clear that MTTF has become shorter as time has progressed (except for the unusual case in
which the system survives into old age).
Figure 4: Failure Probability at a Later Time
3
© 2017 Sombers Associates, Inc., and W. H. Highleyman

Redundant System
As described earlier, the reliability of a system can be greatly improved by making it redundant. A second
system is added. As shown in Figure 1, the redundant pair can be operated either as an active/backup
pair or as an active/active system.
Figure 5 shows a typical system failure
probability distribution including infant mortality. Infant
mortality is a system failure caused by defects not
found in its initial testing before installation. In some
cases, the system may not come up at all. In other
cases, it may fail shortly after it becomes operational.
Once the system is “burned in,” the system will run
reliably until it ages.
A redundant system is available so long as one of the
systems is operational. It fails only if both systems Figure 5: Infant Mortality
fail.
In a dually redundant system comprising a System 1 and a System 2, let the probability distribution of
failure for System 1 be p (t) and the probability distribution of failure for System 2 be p (t). The mean
f1 f2
time to repair a system is MTR. The probability distribution that both systems will fail is MTR p (t) p (t),
f1 f2
as shown in Figure 6. Clearly, the probability that both systems will fail simultaneously is less than the
probability that either system will fail at that time. The peak probability that both systems will fail occurs at
the peak probability of each failure probability distribution.
0.5
0.4 age
P
f1 0.3
0.2
0.1
0 System 1 time
0.5
0.4 age
P
f2 0.3
0.2
infant
mortality
0.1
0 System 2 time
0.25
0.20
MTR
(Pf1)
(Pf2)0.10
0.03
0.01
0 Redundant Staggered System time
Figure 6: Systems Started
Figure 7: Starting Times Staggered
Simultaneously
4
© 2017 Sombers Associates, Inc., and W. H. Highleyman

The availability of the redundant system can be significantly improved by staggering the starting times of
the two nodes, as shown in Figure 7. When the probability of failure of one system is high, the probability
of the other system is low, thus minimizing the chance that there will be a dual system failure.
Summary
Classic availability theory is flawed in that the expected time to a system failure does not change with
time. Clearly, as time goes on, the expected time to system failure should shorten. This flaw is corrected
with the concept of Mean Time to Failure (MTTF). MTTF can be used to determine the impact on the
availability of various redundant system configurations.
Acknowledgement
Dr. Bruce D. Holenstein, CEO and President of Gravic, Inc., envisioned the effect of staggering systems.
Our thanks to him for this insight.
5
© 2017 Sombers Associates, Inc., and W. H. Highleyman
