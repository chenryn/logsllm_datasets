Towards Zero Downtime: High Availability Blueprints
August2007
Vishal Rupani focuses on Microsoft Clustering in his very readable book, Towards Zero
Downtime: High Availability Blueprints.1 He first provides a high-level overview of many topics
pertinent to high availability. He then devotes most of his book to Microsoft Clustering and to the
proper installation of Microsoft’s Cluster Server and several of Microsoft’s cluster-aware
applications. He follows this with a brief discussion of disaster-tolerant architectures, and
concludeswithacasestudy.
High-Availability Topics
Rupani begins with a definition of several high-availability concepts, such as planned and
unplanned outages, single points of failure, mean time between failures and interruptions, fault
tolerance, and redundancy. He then provides an overview of several important high-availability
technologies.
RAID
RAID technology is the most common method to provide data resiliency. With RAID (Redundant
Arrays of Independent Disks), data is redundantly stored on multiple disks such that, should one
disk fail, the data can still be reconstructed. RAID arrays typically provide a hot-swappable
capabilitysothatafaileddiskcanbereplacedwithouttakingdownthearray.
There are several configurations of RAID. Most stripe data across multiple disks to achieve
improvedperformance.Mirroreddisks,usedbyfault-tolerantsystems anddesignated as RAID1,
provideanentirecopyofthedatabaseonabackupdisk.
The most common form of RAID in use today is RAID 5, which provides one additional disk and
which stripes data and parity across disks. Since there is one extra disk, the data can be
reconstructedshouldanyonediskfail.
There are several other forms of RAID designated as RAID 0, 2, 3, and 4, and combinations of
these.Rupanidescribeseachoftheseconfigurations.
High-AvailabilityArchitectures
Rupanidividessystemarchitecturesintoseverallevelsofavailability:
 Unmanaged Tiers are implemented generally without availability in mind and typically
achieveavailabilitiesintheorderof90%.
1VishalRupani,TowardsZeroDowntime:HighAvailabilityBlueprints,1stBooks;2004.
1
©2007SombersAssociates,Inc.,andW.H.Highleyman

 ManagedTiersuselow-endservers,perhapswithRAIDstoragearraysanduninterrupted
powersupplies (UPS).Theyhavemanysinglepoints offailureandexhibitavailabilitiesin
theorderof99%.
 Well-Managed Tiers use higher-end servers with hot-swappable RAID arrays and with
perhaps dual processors, dual power supplies, and other components to eliminate some
single points of failure. Routers may be used to direct transactions to multiple servers to
achieve load balancing or a degree of fault tolerance. These systems strive to achieve
99.9%availability.
 Fault-Resilient Tiers incorporate redundant components to eliminate single points of
failure within the servers and storage systems, though there may be single points of
failure at network connection points. A cold backup site may be provided for disaster
recovery.Thesearchitecturescanachievefour9sofavailability(99.99%).
 High-Availability Tiers are clustered systems with automatic failover capabilities. All
network connections are redundant, and the systems are powered through a UPS.
Systemmonitoringisprovided,andthesystem undergoesperiodicteststoensureproper
failover.Thesesystemscanachievefive9sofavailability(99.999%).2
Discovery
The design of a high-availability solution should begin with a Discovery process, in which an
organization’sneedsandcandidatesolutionsaredetermined.Theorganization’sneedsinclude:
 itscentralpurpose.
 itsbusinessunits.
 previousattemptsatachievinghighavailability.
 existenceofincidentorproblemmanagement.
 description of the business critical applications, their acceptable service levels, their cost
ofdowntime,andtheiracceptabledowntime.
Candidatesolutionscover:
 networks
 storage
 servers
 applications
 security
 monitoring
StorageInterconnect
The author describes the primary technologies today for interconnecting high-speed storage with
servers.
 SCSI(Small Computer Systems Interface) is aparallel I/O bus which has been in usefor
over two decades and is still the predominant interconnect today. Speeds in the tens or
hundreds of megabytes per second can be achieved. However, distance limitations are
measured in tens of meters; and only a handful of devices can be connected to a SCSI
bus.
2Wewouldaddactive/activesystemstothislist.Active/activesystemsachievesix9savailabilityandbeyond.
2
©2007SombersAssociates,Inc.,andW.H.Highleyman

 Fiber Channel (FC) offers full duplex gigabit/second speeds over distances measured in
kilometers. Its addressing capability is virtually unlimited. It can be used in several
topologies such as point-to-point, arbitrated loop (similar to a token ring network), and
switchedfabric.Itisrapidlybecomingthedominantstorageinterconnecttechnology.
 Infiniband is an emerging technology supported by many of the major server vendors. It
provides multi-gigabyte speeds over distances exceeding that of fiber channel. It is
intendedtoreplacethePCIbusfoundincontemporaryservers.
StorageTechnologies
Towards Zero Downtime continues with descriptions of direct attached storage, network attached
storage(NAS),storageareanetworks(SAN),andstoragevirtualization.
With direct attached storage, storage units are directly connected to the server, usually via SCSI
or fiber channel. The server must provide all file server tasks while at the same time handling its
business tasks. Though the simplest of all of the storage technologies, direct attached storage is
not very scalable; and its availability is limited to that of the direct attached RAID arrays or
whateverotherstoragemechanismisused.
Network attachedstorage(NAS) is similar todirectattachedstorageexceptthatthestorageunits
are connected to the network and are accessed through the network by the servers. They are
stand-alone appliances that provide all file and database services, thus offloading these tasks
fromtheservers.NASstorageishighlyscalableandsignificantlyminimizesadministrationcosts.
Storage area networks (SANs) provide pooled storage for a network of servers. Storage is
divided into logical units (LUNs), which are allocated to servers as needed. SANs can include
tape libraries that can be used for backup independently of any of the servers in the network.
Storageadministrationcanbecentralizedforallstoragerequirementsoftheenterprise.
Storage virtualization is a convergence of SAN and NAS technologies over fiber channel. With
storage virtualization, a storage controller sits between a pool of storage devices and the file
servers.ThevirtualizationmanagerallocatesstoragetoapplicationseitherasLUNsorasfiles.
ClusteringTechnologies
Clustering is a mature technology that allows two or more independent systems to work together
as a single system. The primary benefit of clusters is that single points of failure are eliminated,
thusprovidingsignificantlyimprovedavailabilityoversinglesystems.
Thereareseveralclustermodels:
 Active/passive, a shared-nothing architecture in which the resources required by a
particular application can be active on only one node at a time in the cluster. Should a
nodefail,theapplicationanditsresourcesarefailedovertoanothernode.
 Active/active,3 a shared device architecture in which multiple processors in a cluster can
share a common resource such as a database. Should a node fail, users need only
reconnect to another node that is currently processing that application. Active/active
architectures require distributed lock management to prevent data corruption due to
3 Rupani’s definition of the term “active/active” is somewhat different from that of others in the cluster community. The
more common definition of an active/active cluster is that different applications are being run on each node, but no
applicationruns onmultiplenodes. Thesystem hedescribes is sometimes calleda“multi-instance”cluster. His useis
also different from our use of active/active. In a cluster, there is only one copy of the database. Therefore, the cluster
cannot be separated geographically for disaster tolerance as can an active/active system that employs replicated
databasecopies,thecontextinwhichweusetheterm.
3
©2007SombersAssociates,Inc.,andW.H.Highleyman

multiple servers trying to update the same data. Therefore, they must use specialized
databasemanagementsystems.
Clustersareusefulforhigh-availabilitysystems,forloadbalancingbetweenservers,andforhigh-
performance computing using parallel processing. Clusters can reduce planned downtime since
theycan be upgraded online with rolling upgrades. Using this technique, the applications running
on one node in the cluster are failed over to another node; and that node is taken down and
upgraded. The upgraded node then rejoins the cluster, and the upgrades are rolled to other
nodesusingthesameprocedure.
Typically, an application should be cluster-aware to run in a cluster. Such applications can
interact with the cluster’s services and can take advantage of them via an application
programminginterface(API).
Acluster-unawareapplicationcanruninaclusterprovideditmeetscertaincriteria.Forinstance:
 Itmustnotsharetemporaryfilesonshareddisk.
 Itmustnotdeleteregistrykeys.
 Itmustnotchangedatastructures.
Clustering products are available on UNIX from the top UNIX vendors (HP, Sun, IBM), on HP’s
OpenVMS,fromMicrosoft,andfromothers.
Microsoft Clustering
The primary focus of this book is on Microsoft clustering. The material presented in the first part
of the book lays the groundwork for understanding Microsoft clustering. The bulk of the book is
then devoted to this topic and especially to the details of installation, verification, and testing for
MicrosoftclustersandseveralMicrosoftcluster-readyapplications,including:
 SQLServer
 InternetInformationServer(IIS)Cluster
 FileShareCluster
 NLBCluster
Other Microsoft cluster-aware applications include Exchange Server, DCHP Server, and Print
Server.
The installation and test procedures are extensively documented with screen shots of the
Microsoftprocedures.
MicrosoftClusterServer
The Microsoft Cluster Server initially ran on Windows NT and now runs on Windows 2000 and
Windows2003,EnterpriseEdition.RupaniusesWindows2000astheexampleplatform.
Theinstallationprocedures for MicrosoftCluster Server involveinstallingtheoperatingsystem on
the cluster nodes, creating shared volumes, configuring the networks, installing and configuring
theClusterServer,andverifyingtheproperinstallation.
The author then walks through the procedures for joining any node in the cluster and for testing
proper failover. Failover is checked by using the Initiate Failover command provided by the
Cluster Administrator, by powering down each node one at a time, by disconnecting the public
network from each node one at a time, and bydisconnecting the shared storage from each node
oneatatime.
4
©2007SombersAssociates,Inc.,andW.H.Highleyman

Rupaniprovidesseveraltipsforclusterinstallation,including:
 Placethepaging(swap)fileonalocaldrive,notonasharedvolume.
 Schedulemanualfailoversperiodicallytotestfailover.
 Ensurewrite-backcachinghasbeendisabled.
 Beawarethatsomeviruscheckingsoftwarecancausebluescreensofdeath.
SQLServer
SQL Server installation is described in a similar way. SQL Server failover tests are detailed, and
tipsaregiven.Tipsinclude:
 UseSQLServerinanactive/passiveconfiguration.
 BackingupSQLServerdatashouldbeapriorityactivity.
 Foroptimumdataprotection,uselogshippingtomovedatafromtheproductionclusterto
abackupsite.
InternetInformationServer(IIS)
IIS is used to provide services toWeb applications. It is often used with Network Load Balancing
(NLB)ratherthanwithClusterServicesunlessfaulttoleranceisrequired.
Decisionsmustbemadewhethertokeeprelateddatalocaltoeachserverortoputitonashared
volume. If data changes infrequently (such as aWeb page), it maybe best to keep copies of the
data on local storage. If it changes frequently, it may be better to have it reside on shared
storage.
Theproceduresforinstallation,verification,andtestingaredetailedwithafullsetofscreenshots.
The author notes that Microsoft’s FrontPage Server Extensions are not supported on clustered
Websites.
File-ShareCluster
Providing a file-share cluster can significantly improve system availability by providing
redundancy for the file servers. A file-share cluster first requires a Network Name resource. This
resourceshouldnotbedependentupontheClusterNameresource.
Once a Network Name resource has been created, Rupani describes the sequence of steps
requiredtocreateafile-shareresource.
NetworkLoadBalancing(NLB)
A Microsoft Network Load Balancing cluster distributes incoming client requests among the
servers in the cluster in an attempt to balance the workload. To a client, the NLB cluster appears
asasingleserverwhichishighlyscalable(upto32servers)andisfaulttolerant.
NLBdoes nothaveasingleserver thatreceives androutes allrequests.Rather, allservers listen
onthesameIPaddressanddiscardpacketsthatarenotforthem.
Therequestloadcanbeequallydistributedtoallserversinthecluster,oreachcanbeconfigured
tohandleaspecifiedportionoftheload.
TheauthordetailstheinstallationandvalidationproceduresforanNLBcluster.
5
©2007SombersAssociates,Inc.,andW.H.Highleyman

Disaster Tolerance
Even if a data center is fully redundant, the data center itself represents a single point of failure
should itbe put out of commissionbysomedisaster. Toprotectitself from suchanoccurrence,a
companymustprovidealternatedataprocessingfacilitiesatanothersite.
Disaster recoveryis theabilitytoreturnIT services toanacceptable levelof operationfollowinga
site outage. It is a subset of a Business Continuity Plan. Disaster tolerance, on the other hand, is
theabilitytomaintainongoingITserviceseveninthefaceofsuchacatastrophe.
In a truly disaster-tolerant configuration, a remote site is kept in near-real-time synchronization
with the primary site via data replication. The combination of clustering, data mirroring within the
cluster,anddatareplicationtoaremotesiteprovidesatrulydisaster-tolerantconfiguration.
Case Study
Rupani concludes with an actual in-depth case study conducted for a company running SAP
applications with Oracle databases on Windows 2000 systems. Following an intensive discovery
process, several recommendations are made. The study concludes with recommended changes
inproceduresandconfigurationsandtheirassociatedcosts.
Summary
Vishal Rupani focuses on the use ofWindows clustering techniques and products. He introduces
the topic by covering a broad range of availability issues such as storage and processing
redundancy. He highlights the need for an extensive discovery process to understand the client’s
currentsystemsandfutureneeds.
He then details the installation, validation, and test procedures for Microsoft clustering and
several Microsoft cluster-aware applications. He follows this with a brief discussion of
geographically-distributed fault-tolerant architectures and concludes with an in-depth case study
thatappliestheconceptscoveredinhisbook.
6
©2007SombersAssociates,Inc.,andW.H.Highleyman
