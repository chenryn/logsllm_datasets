thereisafailoverfault.Asisthecasewithfailovers,intheeventofafailoverfault,onlyhalfofthe
userswillbeeffected.Let
p=theprobabilitythatafailoverwillfail(afailoverfault).
The probability that one of the two nodes will fail is 2(1 – a). The probability that there will be a
failover fault is therefore the probability that there will be a single node failure followed by a
failover fault, or 2(1 - a)p. The probability that there will be a dual node failure is (1 - a)2. Noting
thatonlyhalfoftheuserswillbeaffectedbyafailoverfault,theprobabilitythatuserswillbedown
is
p(userbeingdown)(1a)2 (1a)p(1a)p (5)
As argued above, for an active/standby system the result is the same since failover faults are a
problemonlyiftheactivesystemfails,butalloftheusersareaffected.
4
©2008SombersAssociates,Inc.,andW.H.Highleyman

Let us consider a dual-node, singly-redundant system of nodes with three 9s availability and with
a failover-fault probability of 1% (that is, one out of 100 failovers will fail). In this case, from
Equation(5),
p(user beingdown)0.001x .011x105
Thesystem availabilitydue todual-nodefailures has beenreducedfrom six 9s toafive9s. A1%
probability of failure has made the system ten times less reliable! Following the failure of one
node, Equation 5 states that the effective availability of the surviving node is only (1 – p) rather
thana.
Combining the above results, we obtain the relationship expressing the probability of user failure,
F,whendual-nodefailures,failovertime,andfailoverfaultsareconsidered:
MTFO MTFO
F(1a)2  (1a)p(1a)2  (1a)(1a)p (6a)
mtbf mtr
whereEquation(3b) was used. Thefirstterm is theprobabilityof adual-nodefailure.Thesecond
termistheprobabilitythatthesystemwillbedownduringfailover.Thethirdtermistheprobability
thatthesystemwillbedownduetoafailoverfault.
WecanrewriteEquation(6a)as
  MTFO 
F(1a) 1a p (1a)(1a') (6b)
  mtr 
Thefailureprobabilityofthefirstnodeis(1–a).Theprobabilityoffailureofthesecondnodeis
(1 – a’), where a’ is the nodal availability a reduced by the failover time and failover fault
probability:
MTFO
a'a p
mtr
Thus, the system acts as a heterogeneous system with the first node to fail having an availability
ofaandtheothernodehavingareducedavailabilityofa’.Thisleadstothefollowingobservation:
Following the failure of one node, failover time and failover faults cause the system to
behaveasifitcomprisesaremainingnodewithdecreasedavailability.
Thissamereasoningcanbeextendedtoann-nodesystem.3
HeterogeneousNodes
In many cases, the nodes in a system are not
homogeneous. Theymaybe different systems, or they
may be affected by different environmental conditions.
Node1 Node2
Inanyevent,theyhavedifferentavailabilities. availability=ax availability=xa
1 2
Let the availabilities of the two nodes in a singly-
redundant system be a and a , respectively. Then, if
1 2
3
See Rule 24 in Chapter 5, The Facts of Life, Breaking the Availability Barrier: Survivable Systems for Enterprise
Computing,AuthorHouse;2004.
5
©2008SombersAssociates,Inc.,andW.H.Highleyman

onlydual-nodefailuresareconsidered,thesystemavailabilityis
A 1(1a )(1a ) (7)
1 2
Forinstance,iftheavailabilityofNode1isfour9s,andiftheavailabilityofNode2isthree9s,the
availabilityofthesystemis
A=1–10-4x10-3=1-10-7
orseven9s.
A useful application of this result is in the analysis of the impact of environmental faults. An
environmental fault is any happenstance external to the computing system that will cause a node
outage. Environmental faults can range from computer-room fires to hurricanes, earthquakes, or
terrorist attacks. These faults are asymmetric in that they affect nodes in a geographically
distributed system differently. Thus, the nodes are heterogeneous in that they have different
overallavailabilities.
Environmental-fault calculations are inherently unreliable because, for instance, it is hard to state
a probability that an earthquake will occur at a given site. However, one can take educated
guesses that should err on the conservative side. For instance, one might reasonably assume
that a hurricane will damage a data center in Florida once every twenty years. Then the
probabilitythatthedatacenterwillbedamagedinthenextyearis5%.
In addition, we must know how long it will take to recover from such a failure. Recovery may
include finding another building, ordering and installing equipment, and bringing up the system.
Thismighttakedays,weeks,ormore.
Letusdefinethefollowing:
mtbf=meantimebetweennodefailuresduetohardwareorsoftwarefaults.
mtr =meantimetorepairanodefollowingahardwareorsoftwarefault.
mtbe=meantimebetweenenvironmentalfaults.
mte =meantimetorestoreanodetoservicefollowinganenvironmentalfault.
Thentheprobabilityof anodefailure, f,is the probabilitythatit willbedownduetoasystem fault
ORthatitwillbedownduetoanenvironmentalfault:
mtr mte
f (1a)  (8)
mtbf mtbe
For instance, consider a node with an availabilityof three nines (that is, mtr/mtbf = 10-3). Assume
thatthenodeis inahurricaneregioninwhichit isestimatedthatahurricanestrongenoughtodo
significant damage will occur every 160,000 hours (about 20 years). Furthermore, it will take 700
hours (about one month) to return the site to service. Then the availabilityof the node is reduced
fromthreeninesto
700
f 103  103 4.4x103 5.4x103
160,000
a.9946
The other node in the redundant system is in an area not impacted by any environmental fault. It
isanidenticalsystemwiththree9savailability.Thesystemavailabilityisthen,fromEquation(7),
6
©2008SombersAssociates,Inc.,andW.H.Highleyman

A 1(5.4x103x103).9999946
oralittleoverfiveninesratherthansix9sasitwouldbeintheabsenceofenvironmentalfaults.
This analysis can be extended to failovers and failover faults in active/active systems by noting
thateitheroftheseoccursonlyafterafirstnodehasfailed.Theprobabilitythatafirstnodewillfail
is the probability that Node 1 will fail OR that Node 2 will fail. In a homogeneous system, this
probability is 2(1 – a).4 In a heterogeneous system, Node 1 will fail with a probability of (1 – a );
1
andNode2willfailwithaprobabilityof(1–a ).Therefore,theprobabilitythatNode1ORnode2
2
willfailis(1-a )+(1–a ).Theaverageprobabilityofafirstnodefailureisthen
1 2
1  a a 
2[(1-a 1)+(1-a 2)] 1 1 2 
2 
Thisrelationshipreplacestheterm(1–a)inEquation(6a),whichcanthenberewrittenas
MTFO a a   a a 
F(1a 1)(1a 2)  1 1 2   1 1 2  p foractive/activesystems (9)
mtr 2 2
The previously referenced Chapter 5 in Breaking the Availability Barrier expands this result for
heterogeneous nodes to cover an n-node system and to include the recovery time of the system
for those cases that require recovery activities following the repair of a node, such as database
resynchronization.
Summary
Thecalculationof system availabilitygoes beyond just multiple nodefailures.The timethatusers
aredeniedservice whilethesystem isfailingovertoabackupnodemustbeconsidered,andthis
time is often a predominate factor. Furthermore, the failover process itself may fail, resulting in a
dual-nodefailureeventhoughoneofthenodesisperfectlygood.
The analysis is made more complex if the nodes are heterogeneous, each having a different
availability. However, the extension of the availability equation to cover this case is
straightforward.
In our final article on this topic, we will extend this analysis to cover systems that can fail if a
single component fails. For instance, a set of redundant computers might be accessing a single
database,whichitselfmightberedundant.
4Sincetheseeventsarenotmutuallyexclusive,theprobabilitythatNode1ORNode2willfailisreally2(1–a)–(1–a)2
(seefootnote2).For(1–a)<<1,whichisthecaseinwhichweareinterested,theexpressionholds.
7
©2008SombersAssociates,Inc.,andW.H.Highleyman

