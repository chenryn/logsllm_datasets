Random Events Have No Memory
November2014
A word of caution: This article is truly a Geek article. It is for those who enjoy heavy
mathematics. However, having said that, the message of this article is important for
everyone trying to understand a little about availability theory. Therefore, it begins with a
generaldiscussionthatisforeveryone.
If you consider yourself mathematically challenged, please read the introductory section, which will give
you the important background that you need. The rest of the article is for math nuts and serves to prove
theconjecturesmadeinthefirstsection.
Memoryless Variables
In availability, we talk about mean time between failures (MTBF) and mean time to repair (MTR), where
“mean” means” average.” MTBF is the average time between system failures. MTR is the average time it
takes to repair a failed system and return it to service (in some cases, we use mean time to restore for
MTR,dependinguponthecontext).
Availability (A) is theproportion of timethatthesystem is operational –that is,it is the probabilitythat the
systemwillbeup.Thus,
MTBFMTR MTR
A  1
MTBF MTBF
Since the system must be either up or down, the probabilitythat the system will be down - the probability
offailure(F)–is
MTR
F1A 
MTBF
MTBF and MTR are random variables. That is, they can take on any number of values. The system may
fail in three months, and then it may not fail again for two years. It might take one hour to repair the
systemthefirsttime,and20minutestorepairitthenexttime.
AkeyconceptinavailabilitytheoryisthatMTBFandMTRarememorylessvariables.Thatis,whetherthe
system will go down or will be repaired in the next minute is absolutely independent of the past. If an
1
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

operational system is observed, it may go down in the next minute or in the next year, regardless of its
pastfailurehistory,solongastheaveragetimebetweenfailuresisMTBF.
Perhaps moretroubling is thatif asystem under repair is observed,thetimethatitwilltaketorepair from
that time on will always average MTR, no matter how long the system has been under repair. For
instance,iftheMTRforasystem isonehour,andtherepairteam hasbeenworkingonthesystemfor45
minutes,theaveragetimefortherepairtobecompletedfromthattimeonisstillonehour.1
This can be envisioned from the following figure. Assume that we keep track of the repair times over
several years and have an extensive database of repair times. We plot them as shown in the following
figure, all starting at time = 0. If we measure the repair times from that point, we find that the average
repairtimeisMTR.Wethenmoveouttoalatertime,t .Bythattime,somerepairshavebeencompleted.
1
TheaveragetimetorepairfortheopenrepairsisstillMTR.Andsoon.
MTR=1 MTR=1 MTR=1
hour hour hour
sriaper
0 t1 t2
time
This is the meaning of memoryless variables and is the basis for many analyses, not only availability
theorybutalsoqueuingtheory,forinstance.
A more practical example mayserve to illustrate the point. Consider your home telephone. You receive a
callonit.Whatisthetimefromwhenyouhangupuntilyoureceivethenextcall?Ithasnothingtodowith
thereceiptofthefirstcall.Thenextcallmaycomeimmediately,oritmaynotcomeuntilthenextday.The
receipt of the next call has nothing to do with the prior history of calls. The time between calls is
memoryless.
What is often not known is that there are two common probability distributions that describe random
variables. One is the exponential distribution that gives the probability that an event (a failure or repair in
our case) will occur in the next time t. For instance, what is the probabilitythat a repair will be completed
withinthenexthour?
1SeeourarticleentitledRepairStrategies,AvailabilityDigest;October2014.
http://www.availabilitydigest.com/public_articles/0910/repair_strategies.pdf
2
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

prob(repair t)1et/MTR exponentialdistribution
The other probability distribution is the expected number of events, n, during an interval t. For instance,
how many failures can we expect in the next five years? This distribution is known as the Poisson
distribution:
[t/(MTBF)]net(MTBF
prob(n failuresintimet) Poissondistribution
n!
0.3
Poissondistribution
0.2
mean=2
0.1
0.0
0 1 2 3 4 5 6 7
n
It is not obvious that random distributions, exponential distributions, and Poisson distributions
characterize the same physical process. The rest of this article shows that the exponential and Poisson
distributions are a direct result of the randomness of a physical process – that is, they describe
memorylessrandomvariables.
At this point, those who feel mathematically challenged may turn to other activities. The above has
describedtheprimarythrustofthisarticle.2
The Poisson Distribution
The Poisson distribution provides the probabilities that exactly n events may happen in an interval t,
provided that these events are independent. That the independence of events is the only assumption
madeisthereasonthatthisdistributionissoimportant.
The occurrence of an event is not at all dependent on what has occurred in the past, nor has it any
influence on what will occur in the future. The process has no memory; it is memoryless. We call a
process that creates such random events a random process. Note that randomness has to do with
events:thefailureofasystemoritsrepair.
Let us determine the probabilitythat exactlyn random events will occur in a time t.We will represent this
asp (t):
n
p (t)=theprobabilitythatnrandomeventswilloccurintimet
n
The average rate of occurrence is a known parameter and is the only one we need to know. We will
denoteitbyr:
r=averageeventoccurrencerate
For availability analysis, r = 1 / MTR is the repair rate, and r = 1 / MTBF is the failure rate. Thus, on the
average,rteventswilloccurintimet.
Since events are completely random, we know that we can pick a time interval, t, sufficiently small that
the probability of two or more events occurring in that time interval can be ignored. We will note this
2TherestofthisarticlewastakenfromW.H.Highleyman,PerformanceAnalysisofTransactionProcessingSystems,Prentice-Hall;
1989.
3
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

arbitrarily small time interval as ∆t and will assume that either no events will occur or that one event will
occurduringthisinterval.
Let us now observe a process for a time t. At the end of this observation time, we count the number of
events that have occurred. We then observe the process for ∆tmoretime.Theprobabilitythatonefurther
event will occur in ∆tisr∆t.Theprobabilitythatnofurthereventswilloccuris(1-r∆t).
Theprobabilityofobservingneventsinthetime(t+ ∆t)is
p (t + ∆t) = p (t)(1 - r∆t) + p (t)r∆t n>0[(n–1)doesnotexistforn=0)] (1)
n n n-1
This equation notes that n events may occur in the interval (t + r∆t) in one of two ways. Either n events
have occurred in the interval t and no events have occurred in the subsequent interval ∆t, or (n – 1)
eventshaveoccurredintheintervaltand one more event has occurred in the subsequent interval ∆t.
Ifnoeventsoccurredintheinterval(t+ ∆t),thisrelationshipiswrittenas
p (t + ∆t) = p (t)(1 - r∆t) n=0 (2)
0 0
That is, the probability of no events occurring is the probability that no events occurred in the interval t
and that no events occurred in the interval ∆t.
Equations(1)and(2)canbearrangedas
p (t t)p (t)
n  n rp (t)rp (t) n>0 (3)
t n n1

p (t t)p (t)
0  0 rp (t) n=0 (4)
t 0

If we let ∆tbecomesmaller andsmaller,this becomestheclassicaldefinitionof thederivativeof p (t) with
n
respecttot,dp (t)/dt.Denotethetimederivativeofp (t) byp’ (t):
n n n
p’ (t)=dp (t)/dt
n n
Wecanexpressequations(3)and(4)as
p’ (t)=-rp (t)+rp (t) n >0 (5)
n n n-1
p’ (t)=-rp (t) n=0 (6)
o 0
Equations (5) and (6) are a set of differential equations. The solution to these equations is challenging
evenformathgeeksandisgivenintheAppendixforthecourageous.However,theresultis
(rt)nert
p (t) (7)
n n!
This is thePoissonprobabilitydistribution.It gives the probabilitythatexactlyn events will occur inatime
intervalt,givenonlythattheiroccurrencesarerandomwithanaveragerateofr.
4
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

The Exponential Distribution
The exponential distribution deals with the probability distribution of the time between events. It can be
derivedfromthePoissondistribution.
We assume again that events are occurring randomly at a rate of r. Let us consider the probability that,
giventhataneventhasjustoccurred,oneormoreeventswilloccurinthefollowingtimeinterval,t.Thisis
theprobabilitythatthetimebetweeneventsislessthant.IfTisthetimetothenextevent,wedenotethis
probabilityasp(T<t).FromthePoissondistribution[Equation(7)],
 (rt)nert
p(Tt) (8)
n!
n1
Thatis,theprobabilitythatthenextevent willoccur inatimeintervallessthantis theprobabilitythatone
eventwilloccurintimetplustheprobabilitythattwoeventswilloccurintimet,andsoon.
ManipulatingEquation(8),wehave
 (rt)n 
p(Tt)ert  1
n0 n! 
Since
 (rt)n
 ert 1
n!
n0
(theprobabilityofsomevalueofnoccurringintimetisone),wecanwrite
P(Tt)1ert (9)
This is the exponential distribution. It gives the probability that the next event will occur in time t. Like the
Poissondistribution,itdependsonlyuponoccurrencesbeingrandomwithanaveragerateofr.
Summary
It is commonly assumed in many areas of analysis that events occur randomly. The occurrence of a
random event is independent of what has happened before, and the event has no impact on what will
happen in the future. In availability theory, we assume that failures are random events as well as repair
times.
Given a purely random occurrence of events, we can calculate the probability that a certain number of
events will occur in a specific time interval. This is the Poisson distribution. We can also calculate the
probabilitythatthenexteventwilloccurbyaspecifiedtime.Thisistheexponentialdistribution.
Memoryless events, the Poisson distribution, and the exponential distribution are all ways to characterize
thesameprocess–therandomoccurrenceofevents.
5
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Appendix
SolvingthePoissonDistributionSetofDifferentialEquations
WehavenotedthatthePoissondistributionisgivenbythefollowingsystemofdifferentialequations:
p’ (t)=-rp (t)+rp (t) n>0 (5)
n n n-1
p’ (t)=-rp (t) n=0 (6)
n 0
ThesolutiontothissetofequationsisduetoT.L.Saaty.3Letusdefine ageneratingfunctionP(z,t):

Pz,tznp (t) (A-1)
n
n0
Ifweshoulddifferentiateequation(A-1)ntimeswithrespecttoz,wehave
nP(z,t) (n1)! (n2)!
n!p (t) zp (t) z2p (t)...
zn n 1! n1 2! n2
Settingztozero,weobtain
nP(z,t)
n!p (t), z=0 (A-2)
zn n
Thus, by differentiating the generation function P(z,t) n times with respect to z, setting z to zero, and
dividingtheresultbyn!,weobtainp (t).
n
Let us now consider a time t and assume that i events have occurred up to time t = 0. That is, by the
definitionofp (t),
n
p(0)=1 probabilitythatieventshaveoccurredbytimezero
i
p (0)=0 probabilitythatneventshaveoccurredbytimezero,wheren ≠ i
n≠i
FromEquation(A-1),fort=0,
P(z,0)=zip(0)=zi (A-3)
i
Also,ifzissetto1,fromEquation(A-1),

P(1,t)p (t)1 sincethesummationisoverallvaluesofn
n
n0
Nowletusmultiplythedifferential-differenceEquations(5)and(6)byzn,obtaining
z0p’ (t)=-rz0p (t) n=0
0 0
znp’ (t)=-rznp (t)+rznp (t) n>0
n n n-1
3T.L.Saaty,Elementsofqueuingtheory,McGrawHill;1961.
6
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com

Ifwesumtheseoveralln,recognizingthat(n-1)doesnotexistforn=0,weobtain
  
znp' (t)r znp (t)r znp (t) (A-4)
n n n1
n0 n0 n1
From Equation (A-1), the left-hand term of this equation is simply ∂P(z,t)/∂dt. The first term on the right is
–rP(z,t).Thesecondtermontherightis
rzp (t)+rz2p (t)+rz3p (t)+…
0 1 2
=rz[p (t)+zp (t)+z2p (t)+…
0 1 2
=rzP(z,t)
Thus,Equation(A-4)canbewrittenasthelineardifferentialequation
P(z,t)
r(z1)P(z,t) (A-5)
t
Thesolutiontothisis
P(z,t)=Cer(z-1)t (A-6)
whichcanbeverifiedbysubstitutingP(z,t)fromEquation(A-6)intobothsidesofEquation(A-5).
The value of C is dependent upon how many items, i, are received by t = 0. Let us assume that at t = 0,
zero events have occurred. In this way, p (t) will truly be the probability of receiving n items in the
n
subsequentintervalt.FromEquation(A-3),settingi=0,
P(z,0)=zi =1
Thus,C=1inEquation(A-6)and
P(z,t)=er(z-1)t (A-6)
As we pointed out earlier with reference to Equation (A-2), p (t) is derived from P(z,t) by differentiating
n
P(z,t)ntimeswithrespecttoz,settingzto0,anddividingbyn!.PerformingtheseoperationsonEquation
(A-6)yields
(rt)n
p (t) ert
n n!
ThisisthePoissondistributionreferencedinEquation(7).
7
©2014SombersAssociates,Inc.,andW.H.Highleyman
Fordiscussion,contacteditorest.com