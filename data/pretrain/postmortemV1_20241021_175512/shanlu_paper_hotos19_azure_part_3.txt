incidentsas“1”.Aswecansee,althoughtheresolving
Datamitigationinvolvesmanuallyrestoring,cleaning
timevariesalotfromincidenttoincident,thereisnosig-
up,ordeletingdatainafile,acloudtable,etc.
nificantdifferenceamongincidentscausedbydifferent
Running-environmentmitigationcleansupdynamic
typesofsoftwarebugs.
environmentthroughkilling/restartingprocesses,mi-
Discussion:Muchrecentworklookedathowtoau-
gratingworkloads,addingfail-overresources,etc.
tomaticallygeneratenewpatches.Incomparison,auto-
Q2.Aredifferenttypesofbugsresolveddifferently?
maticallygeneratingmitigationstepshasnotbeenwell
Figure 2 shows how incidents with different root
studiedandworthmoreattentioninthefuture.
causesare resolved.Aswecansee, differenttypesof
bugs are indeed resolved differently. Constant-value
5 PASTANDFUTURE
bugs,anddata-relatedbugincidentsaremainlyresolved
bysoftwarepatches.Ontheotherhand,environment Manytoolshavebeenproposedtodetectsoftwarebugs,
mitigationiswidelyusedtoresolvefault-relatedbugs, andmuchfocushasbeenputtoavoidbugsduringsoft-
andtimingbugs,probablyduetothetransientnatureof waredevelopment.Webelievetheseeffortsarereflected
manyoftheseincidentsandthecomplexityofhandling inandhaveinfluencedthesoftwarebugcharacteristics
faultsandtimingcorrectlyinsoftware. thatwehaveseeninearliersections.

HotOS’19,May13–15,2019,Bertinoro,Italy HaopengLiu,ShanLuandMadanMusuvathi,SumanNath
Thelowrateofsomebugsisprobablyrelatedtothe Yuanet.al.[32]studied198userreportedfailuresin
tools or languages that are currently used. For exam- 5opensourcecloudsystems(Cassandra,HBase,etc.).
ple,mostofMicrosoftAzureiswrittenin.Netmanaged Thatstudyintentionallydidnotlookattheroot-cause
languagessuchasC#,andinC/C++,withmostC/C++ bugtypesandinsteadfocusedonhowerrorspropagate
codeinsidewell-testedlegacycomponents.Thisislikely andeventuallymanifestasfailures.Consequently,their
thereasonthatwehaveseenfewmemoryleakprob- studyandoursareorthogonal.
lemsandothertypesofmemoryproblemsinourstudy. Gunawi et. al. [14] studied 3000 issues in the issue
ToolslikeCHESS[27]andPCT[9]areusedtoexpose systemofopensourcecloudsystems,comingfromdevel-
share-memoryconcurrencybugs,whichcontributeto opers’codereview,in-housetesting,andusers’reports
therelativelylowrateofthosebugsinourstudy.TLA+ (2011–2014).Theycouldnotcheckwhichissuesactu-
[18,30]isusedtomodelconcurrentanddistributedsys- allycausedproductionincidentsandhowtheywerere-
temprotocolsthatallowdeveloperstoeliminatehigh solvedduringproduction(allissuesendedupwithcode
leveldesign/semanticbugs. patches).Theirstudyfoundrelativelymorehardware
Atthesametime,sometypesofbugsexistdespite issues (13%); among software issues, they found less
thetoolsandtestingalreadyusedinhouse.Forexample, fault-relatedbugs,althoughstillcommon(18%),more
many Azure services are built on top of Service Fab- miscellaneouslogicbugs,anddidnotreportdatafor-
ric[2],whichprovidesFaultAnalysisService[1]that matissues,persistentdatatimingissues,constant-value
supportsvarioustypesoffaultinjections,suchasnode issues,andsoon.Thedifferentobservationsarelikely
restart, data migration, random faults, during testing. duetodifferentdatasourcesandstudymethodology.
Althoughthishasbeeneffectiveincatchingfaultrelated Therewasastudyaboutinternetserviceincidents
problems,thelargeratiooffaultrelatedbugsindicates 15yearsago[28].Sincetheauthorsdidnothaveaccess
thatmoreresearchisneeded. todetailedbugreports,theirstudyaboutincidentroot
Therearealsobugsthathavenotbeentackledbyex- causesalsostayedatcoarsegranularity—operatorver-
istingtoolsanddeservefutureresearchattention.These sushardwareversussoftware.Theydidnothavedata
includedata-formatbugs,distributedconcurrencybugs abouthowincidentswereresolvedduringproduction.
onpersistentdata,andconstant-valuebugs.
Asdiscussedearlier,muchrecentresearchhaslooked
7 CONCLUSION
athowtoautomaticallygeneratepatches,averychal-
Thispaperpresentedanin-depthstudyaboutrootcauses
lengingproblem.Ourstudyindicatesalikelyeasierbut
andresolvingstrategiesofincidentscausedbysoftware
asimportant,ifnotmore,direction—howtoautomati-
bugsinproduction-runcloudservices.Wehopefindings
callygeneratemitigationschemes.
inourstudycanprovideaguidanceforfutureacademic
andindustrialeffortsinthisfield.
6 RELATEDWORK
ACKNOWLEDGMENTS
Givenspaceconstraints,wediscussbelowafewclosely
Wewouldliketothanktheanonymousreviewersfor
relatedstudiesoncloud/internetservicefailures.
theirinsightfulcomments.Thisresearchissupported
Arecentpaper[15]studiedheadlinenewsandpub-
by(CCF-1837120,CNS-1764039,1563956,1514256,IIS-
lic post-mortem reports of 597 unplanned outages in
1546543)andgeneroussupportfromMicrosoft.
32 different production-run cloud services within a 7
year span. The different data sources led to different
REFERENCES
focusesandfindingsinourstudyandthatwork.Par-
ticularly,accordinglytothatstudy,most(76%)public [1] Introduction to the fault analysis service.
reportsdonotdiscussdetailsabouthowoutageswere https://docs.microsoft.com/en-us/azure/service-
resolved, and many (60%) do not explain outage root fabric/service-fabric-testability-overview,2017.
causes.Consequently,thatstudyfocusedonoutagedu- [2] Azureservicefabric. https://azure.microsoft.com/
rationandcoarse-granularitycausebreakdowns(e.g., en-us/services/service-fabric/,2019.
upgradeproblemsversusloadproblemsandsoon).Re- [3] RamnatthanAlagappan,AishwaryaGanesan,Yu-
gardingsoftwarebugs,itfocusesonprovidingexamples vrajPatel,ThanumalayanSankaranarayanaPillai,
ofinterestingbugsandfixes,yetitcannotanddidnot Andrea C Arpaci-Dusseau, and Remzi H Arpaci-
answerquestionslikehowcommonaredifferenttypes Dusseau. Correlatedcrashvulnerabilities. InOSDI,
ofbugsandresolvingstrategies. 2016.

Whatbugscauseproductioncloudincidents? HotOS’19,May13–15,2019,Bertinoro,Italy
[4] VaggelisAtlidakis,PatriceGodefroid,andMarina SymposiumonCloudComputing,pages1–14.ACM,
Polishchuk. Restler:Statefulrestapifuzzing. In 2014.
ICSE,2019. [15] Haryadi S. Gunawi, Mingzhe Hao, Riza O. Sum-
[5] Ryan Beckett, Aarti Gupta, Ratul Mahajan, and into,AgungLaksono,AnangD.Satria,JeffryAdity-
DavidWalker. Ageneralapproachtonetworkcon- atama,andKurniaJ.Eliazar. Whydoesthecloud
figurationverification. InACMSIGCOMM,2017. stop computing?: Lessons from hundreds of ser-
[6] NikolajBjørnerandKarthickJayaraman.Checking vice outages. In Proceedings of the Seventh ACM
cloudcontractsinmicrosoftazure. InInternational SymposiumonCloudComputing,SoCC’16,pages
ConferenceonDistributedComputingandInternet 1–16,NewYork,NY,USA,2016.ACM.
Technology,2015. [16] PengHuang,ChuanxiongGuo,JacobR.Lorch,Li-
[7] EllaBounimova,PatriceGodefroid,andDavidMol- dongZhou,andYingnongDang. Capturingand
nar. Billionsandbillionsofconstraints:Whitebox enhancinginsitusystemobservabilityforfailure
fuzztestinginproduction. InICSE,2013. detection. In13thUSENIXSymposiumonOperat-
[8] Lucas Brutschy, Dimitar Dimitrov, Peter Müller, ingSystemsDesignandImplementation,OSDI’18,
andMartinT.Vechev. Serializabilityforeventual pages1–16,Carlsbad,CA,October2018.USENIX
consistency:criterion,analysis,andapplications.In Association.
Proceedingsofthe44thACMSIGPLANSymposium [17] PengHuang,ChuanxiongGuo,LidongZhou,Ja-
on Principles of Programming Languages (POPL), cobR.Lorch,YingnongDang,MuraliChintalapati,
2017. andRandolphYao. Grayfailure:Theachilles’heel
[9] SebastianBurckhardt,PraveshKothari,Madanlal ofcloud-scalesystems. InProceedingsofthe16th
Musuvathi,andSantoshNagarakatte. Arandom- WorkshoponHotTopicsinOperatingSystems(Ho-
izedschedulerwithprobabilisticguaranteesoffind- tOS),2017.
ing bugs. In Proceedings of the Fifteenth Edition [18] Leslie Lamport. The tla+ home page. http://
of ASPLOS on Architectural Support for Program- lamport.azurewebsites.net/tla/tla.html,2018.
mingLanguagesandOperatingSystems,ASPLOS [19] Tanakorn Leesatapornwongsa, Mingzhe Hao,
XV,pages167–178,NewYork,NY,USA,2010.ACM. Pallavi Joshi, Jeffrey F. Lukman, and Haryadi S.
[10] AndyChou,JunfengYang,BenjaminChelf,Seth Gunawi. SAMC:semantic-awaremodelchecking
Hallem,andDawsonR.Engler. Anempiricalstudy forfastdiscoveryofdeepbugsincloudsystems.
ofoperatingsystemerrors. InProceedingsofthe In11thUSENIXSymposiumonOperatingSystems
18thACMSymposiumonOperatingSystemPrinci- DesignandImplementation(OSDI),2014.
ples(SOSP),2001. [20] TanakornLeesatapornwongsa,JeffreyFLukman,
[11] Datapath.io.Recentawsoutageandhowyoucould ShanLu,andHaryadiSGunawi. TaxDC:Atax-
have avoided downtime. https://medium.com/ onomyofnon-deterministicconcurrencybugsin
@datapatho/recent-aws-outage-and-how-you- datacenterdistributedsystems. InASPLOS,2016.
i
could-have-avoided-downtime-7d9d9443d776, [21] TanakornLeesatapornwongsa,CesarA.Stuardo,
2017. RizaO.Suminto,HuanKe,JeffreyF.Lukman,and
[12] Kirk Glerum, Kinshuman Kinshumann, Steve HaryadiS.Gunawi. Scalabilitybugs:When100-
Greenberg, Gabriel Aul, Vince Orgovan, Greg nodetestingisnotenough. InProceedingsofthe
Nichols,DavidGrant,GretchenLoihle,andGalenC. 16thWorkshoponHotTopicsinOperatingSystems
Hunt. Debugginginthe(very)large:tenyearsof (HotOS),2017.
implementationandexperience. InProceedingsof [22] HaopengLiu,GuangpuLi,JeffreyFLukman,Jiaxin
the 22nd ACM Symposium on Operating Systems Li, Shan Lu, Haryadi S Gunawi, and Chen Tian.
Principles2009,SOSP2009,BigSky,Montana,USA, DCatch:Automaticallydetectingdistributedcon-
October11-14,2009,2009. currencybugsincloudsystems. InASPLOS,2017.
[13] JimGray. Whydocomputersstopandwhatcanbe [23] HaopengLiu,XuWang,GuangpuLi,ShanLu,Feng
doneaboutit? TandemTechnicalreport85.7,1985. Ye,andChenTian.Fcatch:Automaticallydetecting
[14] HaryadiSGunawi,MingzheHao,TanakornLeesa- time-of-faultbugsincloudsystems. InProceedings
tapornwongsa, Tiratat Patana-anake, Thanh Do, oftheTwenty-ThirdInternationalConferenceonAr-
Jeffry Adityatama, Kurnia J Eliazar, Agung Lak- chitecturalSupportforProgrammingLanguagesand
sono,JeffreyFLukman,VincentiusMartin,etal. OperatingSystems,pages419–431.ACM,2018.
Whatbugsliveinthecloud?astudyof3000+is- [24] LanyueLu,AndreaC.Arpaci-Dusseau,RemziH.
suesincloudsystems. InProceedingsoftheACM Arpaci-Dusseau, and Shan Lu. A study of linux

HotOS’19,May13–15,2019,Bertinoro,Italy HaopengLiu,ShanLuandMadanMusuvathi,SumanNath
file system evolution. In Proceedings of the 11th [29] Nicolas Palix, Gaël Thomas, Suman Saha,
USENIXConferenceonFileandStorageTechnologies ChristopheCalvès,JuliaLawall,andGillesMuller.
(FAST),2013. Faultsinlinux:Tenyearslater. InASPLOS,2011.
[25] ShanLu,SoyeonPark,EunsooSeo,andYuanyuan [30] TLA Whence. Leslie lamport: The specification
Zhou. Learningfrommistakes:Acomprehensive languagetla+.
studyonrealworldconcurrencybugcharacteris- [31] TianyinXu,JiaqiZhang,PengHuang,JingZheng,
tics. InProceedingsofthe13thInternationalCon- TianweiSheng,DingYuan,YuanyuanZhou,and
ferenceonArchitecturalSupportforProgramming ShankarPasupathy. Donotblameusersformis-
LanguagesandOperatingSystems(ASPLOS),2008. configurations. InSOSP,2013.
[26] IHSMarkit.Businesseslosing$700billionayearto [32] DingYuan,YuLuo,XinZhuang,GuilhermeRenna
itdowntime,saysihs. http://news.ihsmarkit.com/ Rodrigues, Xu Zhao, Yongle Zhang, Pranay Jain,
press-release/technology/businesses-losing-700- andMichaelStumm. Simpletestingcanprevent
billion-year-it-downtime-says-ihs,2016. mostcriticalfailures:Ananalysisofproductionfail-
[27] Madanlal Musuvathi, Shaz Qadeer, Thomas Ball, uresindistributeddata-intensivesystems. In11th
GerardBasler,PiramanayagamArumugaNainar, USENIXSymposiumonOperatingSystemsDesign
and Iulian Neamtiu. Finding and reproducing andImplementation(OSDI),2014.
heisenbugsinconcurrentprograms. InProceedings [33] YongleZhang,SergueiMakarov,XiangRen,David
ofthe8thUSENIXConferenceonOperatingSystems Lion,andDingYuan. Pensieve:Non-intrusivefail-
DesignandImplementation,OSDI’08,pages267– urereproductionfordistributedsystemsusingthe
280,Berkeley,CA,USA,2008.USENIXAssociation. eventchainingapproach. InProceedingsofthe26th
[28] David Oppenheimer, Archana Ganapathi, and SymposiumonOperatingSystemsPrinciples(SOSP),
DavidA.Patterson. Whydointernetservicesfail, 2017.
andwhatcanbedoneaboutit? InUSITS,2003.
