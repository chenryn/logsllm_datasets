Calculating Availability – Nodes, Subsystems, and Systems
June2007
In our previous articles, we have described multinode architectures that can provide very high
availabilities. Predominant among these architectures are active/active1 and clustered systems.2
Thesesystemsaremadeupofnodesthatarethemselvescomputingsystems.
In our analyses of system availability in our Geek Corner articles, we have talked throughout of
systems and the subsystems that make up these systems. It is now time to bring the terms
system,subsystem,andnodetogetherintoaconsistentwhole.
AReviewofMultinodeArchitectures
Active/Active
In an active/active system, two or more computing systems cooperate in a common application.
We call each such computing system a node in the active/active system. Each node has access
to a copy of the common application database, which is either directly attached to the node or is
accessible through the network. The database copies are synchronized via data replication.
Whenever a change is made to the database at one node, that change is immediately replicated
to the other database copies in the application network. Thus, each node has local or network
access to a consistent and up-to-date (at least within the replication latency) copy of the
applicationdatabase.
node1 node1 data
appl data appl base
A base A data
base
active active
node3
replication data appl replication
network base A network
node3
active
appl
A
node2 node2
active
appl data appl
A base A
active active
DirectlyAttachedStorage NetworkAttached
Storage
1WhatisActive/Active?,AvailabilityDigest;October,2006.
2Active/Activevs.Clusters,AvailabilityDigest;May,2007.
1
©2007SombersAssociates,Inc.,andW.H.Highleyman

Shouldanodefail,allthatisnecessarytorestoreservicetoits usersistoswitchthoseuserstoa
survivingnode.Thiscantypicallybedoneinseconds.
The nodes in an active/active system can be geographically distributed to provide disaster
tolerance. Any event which takes down one node is unlikely to affect the other nodes in the
network.
Clusters
Acluster isagroupingoftwoormorecomputingsystems,ornodes,thatcanback eachotherup.
They each have access to the various application databases and to the network that
interconnectsthenodeswiththeusers.
Each node is capable of running each application, but only one node can run a specific
application at any one time. Otherwise, two nodes might try to update the same data item in the
database,thuscausingdatabasecorruption.
node1 data node2
base
Application data
base
virtualIP clustered
address server
IPaddress
resource
group
users
Should a node fail, the resource group for each application running on that node is failed over to
its backup node. A resource group includes the application code, the application database, and
theIPaddressthatisusedbyuserstoaccesstheapplication.
Clustered nodes are generallycollocated. However, if performance issues permit, the nodes may
be distributed across a campus environment. Disaster tolerance can be achieved by having two
ormoreremotelylocatedclusters thatback upeachother.Eveninthis architecture,therecanbe
onlyoneinstanceofanygivenapplicationrunning.
NodesandSystems
Each of these active/active or clustered systems is made up of two or more subsystems, or
nodes.
Furthermore, a node might itself be a system made up of its own nodes. For instance, in an
active/activesystem implementedwith NonStopservers,each node in theactive/activesystem is
a NonStop server. However, a NonStop server is itself a system made up of nodes. In this case,
thenodesaretheprocessorscomprisingtheNonStopserver.
2
©2007SombersAssociates,Inc.,andW.H.Highleyman

AReviewofAvailability
In our previously published availability analyses, we generally talked about systems and
subsystems. When applying these analyses to multinode systems such as those described
above,asubsystemisanode.
Before applying these analyses to multinode architectures, let us first review them. For
simplicity’s sake, we do this for the case of a single-spared system. That is, the system will
survivethefailureofasinglenode.Ifmorethanonenodefails,amultinodesystemmaycontinue
tohobblealongbutwithanunacceptableperformance;anditisthereforeconsideredtobedown.
MeanTimetoReturnaNodetoService
In order to return a failed node to service, it must first be repaired if necessary; and then it must
be recovered by loading its applications, by recovering its database, and by opening the
database.
Let
mtr bethemeantimetoreturnanodetoservice.
h betheprobabilitythatanodefailurerequiresahardwarerepair.
r betheaveragetimerequiredtorepairthehardware.
h
r’ betheaveragetimetorecoverthenode.
Thentheaveragetimerequiredtoreturnanodetoservicefollowingafailure,mtr,is3
mtr hr r'
h
NodeProbabilityofFailure
Let
a betheavailabilityofanode.
f betheprobabilityoffailureofanode.
mtbf bethemeantimebeforefailureforanode.
Theavailability,a,ofanodeistheprobabilitythatitwillbeoperational.
mtbf mtr
a 1
mtbfmtr mtbf
Theprobability,f,thatanodewillfailis(1–a):
mtr
f 
mtbf
MeanTimetoReturnaSystemtoService
Should a system fail because two of its nodes have failed, it can be returned to service as soon
as one of its nodes is returned to service and as soon as system recovery has been completed.
System recovery might involve such tasks as synchronizing the recovered node’s database and
enteringtransactionsthathadbeenprocessedmanuallyduringtheoutage.
3CalculatingAvailability–Hardware/SoftwareFaults,AvailabilityDigest;January,2007.
3
©2007SombersAssociates,Inc.,andW.H.Highleyman

Note that mtr is the time to return a node to service. However, if two nodes are being repaired in
parallel,theaveragetimerequiredtoreturnthefirstnodetoserviceismtr/2.4
Let
MTR bethemeantimetoreturnthesystemtoservice.
R bethesystemrecoverytime.
Thentheaveragetimetoreturnthesystemtoserviceis
MTRmtr/2R
SystemProbabilityofFailure
Withtheaboveparameters,ouranalysesshowedthatthesystemprobabilityoffailure,F,is5
mtr/2Rn(n1)
F (1a)2
mtr/2 2
where
F istheprobabilityoffailureofthesystem.
n isthenumberofnodesinthesystem.
SystemAvailability
Systemavailability,A,is
A 1F
SystemMeanTimeBeforeFailure
Let
MTBF bethesystemmeantimebeforefailure.
Since
MTBF MTR
A (1F) 1
MTBFMTR MTBF
then
MTR
F
MTBF
and
MTBFMTR/F
Nodes
Letusnowapplytheseanalysestothenodesofamultinodesystem.Wetakeasanexampleofa
node a NonStop system, which is in itself a multinode system made up of sixteen processors (its
nodes). We assume that a hardware fault causes a processor failure 20% of the time and
requires an average of 24 hours to repair. Once the processor is repaired, it takes two hours to
4
CalculatingAvailability–RepairStrategies,AvailabilityDigest;November,2006.
5
CalculatingAvailability–TheThreeRs,AvailabilityDigest;December,2006.
4
©2007SombersAssociates,Inc.,andW.H.Highleyman

recover the processor and then four hours to return the server to service. Furthermore, let
processormtbfbe10,000hours.
Thus
n =16processors
h =0.2
r =24hours
h
r’ =2hours
R =4hours
mtbf =10,000hours
Applyingtheaboveanalysestotheseparameters,wehavefortheNonStopnodes:
NodeAvailabilityAttributes
mtr =processormeantimetoreturntoservice =6.8hours
(1-a) =processorprobabilityoffailure =6.8x10-4
MTR =systemmeantimetoreturntoservice =7.4hours
F =systemprobabilityoffailure =1.2x10-4
A =systemavailability =.99988≈four9s
MTBF =systemmeantimebeforefailure =7.1years
Systems
Let us consider an active/active system in which the nodes are now the NonStop servers which
we have analyzed above. The system’s node mtr and mtbf are now the MTR and MTBF of the
NonStop server calculated above, as is the node probability of failure. Let us further assume that
as soon as a node is returned to service following its repair and recovery, the active/active
system is returned to service. There is no hardware repair time (h = 0) nor is there any further
recoverytimeorsystem restoretime(r’=R=0).Letustakethecaseofafour-nodeactive/active
system.Inthiscase,
n =4nodes
mtr =nodeMTR=7.4hours
h =0
r isnotapplicable
h
r’ =0
R =0
mtbf =nodeMTBF=7.1years
Thus,forthisactive/activesystem,wehave:
System AvailabilityAttributes
mtr =nodemeantimetoreturntoservice =7.4hours
(1-a) =nodeprobabilityoffailure =1.2x10-4
MTR =systemmeantimetoreturntoservice =3.7hours
F =systemprobabilityoffailure =9x10-8
A =systemavailability =.99999991≈seven9s
MTBF =systemmeantimebefore failure =47centuries
5
©2007SombersAssociates,Inc.,andW.H.Highleyman

Summary
Active/active and clustered systems are made up of subsystems, or nodes. If a node itself
comprises multiple subsystems, then its availability attributes must first be calculated based on
the availability attributes of its subsystems. These nodal availability attributes are then carried
over as subsystem parameters for the calculation of the availability of the full active/active or
clusteredsystem.
6
©2007SombersAssociates,Inc.,andW.H.Highleyman
