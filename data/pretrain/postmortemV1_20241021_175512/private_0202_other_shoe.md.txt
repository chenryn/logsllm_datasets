Don’t Wait for the Other Shoe to Drop
February2007
Redundant systems are great for protecting against a failure. But once a failure occurs, fix it fast
beforeasecondfailureturnsaproblemintoadisaster.
Suchadelaycostasmallcompanydearly.Whatshouldhavebeena weekendordealturnedinto
atwo-monthdisaster.
A Smooth Running Credit and Collection Service
The subject of our storyis a companythat has provided credit and collection services to the food
industry for over fifty years. It maintains a large, up-to-date credit database for companies in the
food industry and provides this credit information to its subscribers. Credit information includes
linesofcredit,returnedchecks,slowpayment,creditlitigation,andotherdelinquencyinformation,
aswellastradereferences.
Upon a request from a subscriber, the company’s credit investigators further research a specific
companytoprovidemoredetailedcurrentcreditinformationonthatcompany.
Changes in credit status are reported via a bulletin which gives subscribers early warning of
pending credit problems. The companyencourages its subscribers to contribute to the bulletin so
as to extend its reach beyond publicly available information. The bulletin is augmented by news
feeds,articles,andwhitepapersconcerningthefoodindustry.
A subscriber may at any time submit delinquent accounts to the company for collection. The
company’s collection professionals immediately review and determine the best approach to
ensurecollection.Thisactionmayrangefrom collectioneffortsdirectlybythecompanytoreferral
for legal action. The requesting subscriber is given frequent status reports on its collection
accounts. Collection services are provided on a contingency basis, so the subscriber pays onlya
portionofwhatiscollected.
Going Online
After decades of service to its subscribers, the company decided to offer its services online. The
Web-based system maintains the credit information database, which is available to its
subscribers. It also holds the credit bulletin and its associated news feeds, articles, and white
papers.
Subscribers can submit delinquent accounts and receive status reports on collection activity via
the Web. With several years of successful Web-based service behind it, the company has
become substantially an online operation. The timely provision of its services is now very
dependentuponthecontinuingoperationofitsWebservices.
1
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

The company chose a Dell PowerEdge Server running the Windows 2000 Server operating
system. The database manager is SQL Server. To guarantee database persistence, data is
stored on a three-disk RAID 5 array. Thus, the data is still available should a disk in the RAID
array fail. The system hosts several custom applications created by the company to support its
services.
The Backup and Recovery Strategy
3-diskRAID5
To ensure continuity of service in the
event of a failure of the server, the takesnapshot remote
databasewasbackedupnightlytothe creditdatabase s bn aa cp ks uh pot backup
service
eSureIT remote backup service
provided by Intronics. A backup PC,
available on the company’s premises,
could be put into service and could
substitute for the primary server
should that server fail. It was
Internet subscribers
recognizedthatthecapacityofthisPC
backup could not handle peak loads,
but it was felt that it would get the
company through the downtime of the
failedprimaryserver.
server Backup
Thedatabasebackupprocedurestarted withtakingasnapshotof theRAIDdatabase andstoring
it on a 300 gigabyte local disk. That snapshot was then compressed, encrypted, and sent to the
remote backup service for safe storage. Recovery entailed loading the remote copy of the
database onto the local backup PC, bringing up its applications, and connecting it to the network
ofworkstationsandtheInternet.
As withanygoodbusiness continuityplan,
remote
credit backup the recovery plan was tested by
database
service transferring the snapshot of the database
from the local backup disk to the backup
PC, bringing up the applications on that
server, and testing that everything worked
correctly. Recovery time was
demonstrated to be about four hours, a
Internet subscribers period deemed acceptable by the
company.
PC
With what was believed to be a tested
Recover
backup and recovery plan in place, the
companywasprotectedfromaprimaryserverfailure,right?Wrong,asweshallsee.
Problem #1: ADrive Failure
RAIDcreditdatabase
On November 23, 2006, drive 0 in the RAID array dropped offline. As
expected,thiscreatednointerruptioninservice.
The companyhas a next-dayservice contract which covers the cost of failed
parts.Theservicevendor wascontacted,andaservicepersonarrivedonsite November23,2006
to replace the failed disk. It was expected that all that was needed to be Uh,Oh
2
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

done was to insert the new drive and to rebuild itfrom the data onthe other surviving drives. The
fullredundancyoftheserverwouldthenberestored.
Problem #2: ARebuild Failure
However, after multiple attempts, drive 0 would not rebuild. The company was informed that its
only option was to rebuild the server. This would require taking down the server, restoring the
RAID configuration, formatting the drives (which would delete the database), installing the
operating system, installing the applications, restoring the database, and thoroughly testing the
repairedserverbeforereturningittoservice.
The company’s IT department developed a plan to carefully migrate the failed server’s functions
toatemporaryserver withthesameRAIDconfiguration,to repair andrebuildtheprimaryserver,
andtorestore ittoservice. This wouldavoidthelimited-capacityproblem associated withthe use
ofthebackupPC.
TodothismigrationrequiredMicrosoftCertifiedSystemEngineerservices,whichwereestimated
tocost$1,600.
Problem #3: Unconcerned Management
Unfortunately, the company’s management didn’t see this migration as a priority item. After all,
the system was still running fine. What was the chance of a second disk failure? Based on
management’s experience to date, disk drives were highly reliable; and the probability of a
second disk failure was essentially nil. Besides, it would be in a better position to cover this cost
inthecomingyear.Theresultwasnoaction.
Problem #4: Murphy’s Law
If an event is highly unlikely, it still means that it will occur someday in the future. And that
somedaymightbetomorrow.
RAIDcreditdatabase Inthecompany’s case,that somedaywas Thursday,December 14th.Onthat
fatefulday,aseconddrivefailed;andtheprimaryserverwentdown.
Now the IT folks were faced with a failed server and with no time to arrange
December14,2006 for a loaner server as they had before. Their only option was to fail over to
Oops! thebackupPCandtotaketheconsequencesofreducedcapacity.
The timing couldn’t have been worse. The failure occurred just before the Christmas and New
Year’s holidays. Not only did this mean potential long hours for the IT staff during this time of
familycommitments,butits usualsupportcontacts wouldbecharginghigherratestobeavailable
overtheholidayweekends.
So much for management saving money. The company was now only interested in how long it
would take to get back into operation since its only recourse during this downtime was inefficient
manualoperations.IT’sbestestimatewassixdays,includingworkingovertheweekend.
Problem #5: AReluctant PC Backup
Though the “recovery plan” had been practiced in the past, the IT staff now realized that only a
portion of the recovery plan had been tested. It had recovered from the backup snapshot disk on
the primary server (which was now unavailable), but it had never attempted recovery from the
remotebackupservice.Furthermore,noneofitsrecoveryplanshadbeendocumented.
3
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

It turned out that recovering from the remote service to the same RAID configuration that created
the backup was straightforward. However, recovering to a different configuration – in this case, a
PC with a single disk – just didn’t work. Googling the “internal consistency error” that was being
reportedyieldedlotsofdiscussionbutnosolutions.
Finally, after a long weekend (which included a 5 am to 11 pm shift on Saturday), the staff was
able to get the backup PC working; and service was restored with full functionality the next
Monday morning. To no one’s surprise, the PC’s performance matched its prediction. The PC
madeaterribleserver,butthatwasalltheyhad.
Problem #6: One-Day Service is Six-Day Service Plus
In the meantime, efforts were frantically underway to bring up the primary server. The service
vendor was contacted to come out and rebuild the primary server. According to the company’s
servicecontract,theserviceproviderwascommittedtonext-dayservice.However,inspiteofthat
commitment, resource overbooking and holiday schedules delayed the service call for six
preciousdays.
These same problems continued to plague the recovery effort. As it turned out, it would take a
totalof21daystorecovertheprimaryserver.
Problem #7: Loss of Network Services
A problem that had not been anticipated was that the company’s Domain Controller, which
provides necessarynetwork services,ranontheprimaryserver.Itthereforehadcrashedwiththe
primary system and was no longer available. Normally, the Domain Controller is
decommissioned, which is a controlled shutdown. Then a new domain controller can be put into
place.However,theservercrashprecludedasoftdecommission.
The Domain Controller maintains domain-specific data such as logons, share permissions,
scripts, computer accounts, and IP addresses. This data is kept in a Global Catalog along with
policiesdescribingthenetwork.
The loss of the Domain Controller created significant instability for the backup PC. For instance,
workstations couldn’t log on since security policies and personal settings were unavailable. After
a few days, workstation IP addresses, which had been leased from the Dynamic Host
Configuration Protocol (DHCP) server also hosted by the primary server, began to expire,
disabling the workstations. These parameters had to be laboriously recreated manually on every
companyworkstation.
Without the Domain Controller, the network was slowly dying. The company’s Exchange Server
and Web Server started running unbearably slow. PCs were crashing every morning when they
requested updates from the now-dead antivirus server which had been running on the primary
server. To correct this, antivirus protection had to be disabled. This left the company’s
workstations without protection from viruses, spam, spyware, and malicious scripts. Users could
notfindtheirdocumentsandwouldgetmanyerrorswhentheyattemptedtologonorlogoff.
To add insult to injury, a RAID drive on the company’s Exchange Server failed. Fortunately, this
wasreplacedandrestoredwithoutincident.
When the primaryserver was finally recovered, the fact that the Domain Controller had not been
properly decommissioned caused further problems. The Domain Controller had to be manually
decommissioned and its links broken so that it could be rebuilt. All of the prior server entries had
4
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

to be removed manually from the Global Catalog. This was akin to going through a telephone
book,lookingforinstancesofagivenitem,anddeletingthem.
Furthermore, the new server could not rejoin the network until a manual search of the policies
foundthepolicythatwaspreventingtheserverfromrejoining.
Wait! It’s Not Over
Allof these problems contributedto the 21 days requiredto restorethesystem. Buttheproblems
weren’tover yet.
Onthefirstdaythattheprimaryserver wasagaininoperation,theIT staffwasoverwhelmedwith
user complaints. Settings were incorrect. Scripts were pointing to the old server. It took several
daystoworkouttheseproblems.
AndtheIT staffisstillnotdone.AsofthiswritinginearlyFebruary,thereisstillaraftoftasksthat
mustbeperformedbeforerecoveryiscomplete:
 SQLmaintenanceandbackupjobsneedtobereinstalled.
 Allonsiteandremotebackupsneedtobereinstalledandreconfigured.
 Theantivirusserverneedstobereinstalledandconfigured.
 Someprintersanddocumentscannersarestilloffline.
 Workstationsstillcrash.
 Manyscriptsarestillpointingtothewrongplaces.
 Userroamingprofilesarenotyetworking.
 TheExchangeserverisstillexhibitingproblems.
As the company’s IT Manager said, “Overall, without taking into consideration all of the
configuration and troubleshooting that still needs to be done, the time from failure to restore took
thirtydaysandcostwelloverwhatitwouldhavecosttoproperlyplanandexecutethisservice.”
Lessons Learned
As is often the case, a chain of problems led to the eventual disaster that befell this company. If
anylink inthechainhadbeenbroken,thecompany’s problemsmaynothavehappenedorwould
havebeenfarlessserious.
Many lessons from this experience are obvious from hindsight, which, unfortunately, is always
20/20.Theseinclude:
 Educatemanagers abouttheavailabilityaspects of thesystem,and impress onthem the
importanceoftimelymaintenance.Themiddleofacrisisisnotimetodothis.
 Whenafailureof a sparecomponentoccurs,itmustbea top priorityto fix itrapidly. This
wouldhaveprecludedtheunanticipatedcrashofthecompany’sprimaryserver.
 Recoveryplansmustbethoroughlytested.Testingjustwhatseemstobeacriticalpartof
the plan isn’t enough. In this case, the IT staff was comfortable with the fact that it could
recover from the primary’s database snapshot and assumed that recovering from the
remotebackupwouldbenodifferent.
 Business operations ought to be tested with the backup system to ensure that there are
nounanticipatedproblems withthe backupconfiguration when itis inactual service. This
5
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman

would have exposed the network problems associated with the Domain Controller and
otherservicesthatwererunningontheprimaryserver.
 The recovery plan must be well documented. When the pressure is on to recover is no
timetobetryingtofigureoutwhattodo.
All of these tasks have nontrivial costs associated with them. It is up to management to decide if
thesecostsarelessthanthecostsofamultidaydisastrousfailure.
6
Thisdocumentmaynotbedistributedinanywaybyelectronicmeans.
©2007SombersAssociates,Inc.,andW.H.Highleyman
