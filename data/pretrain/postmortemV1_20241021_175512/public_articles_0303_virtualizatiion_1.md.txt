Fault Tolerance for Virtual Environments – Part 1
March2008
Not only do businesses today depend upon information technology (IT) for their very existences,
but IT costs have become a major part of an enterprise’s budget. As corporate data centers
become bigger and bigger, often supporting thousands of servers, their costs for hardware,
space, administration, and energy are rapidly increasing. In fact, their energy requirements
sometimes bypass the available energy in their areas – remember the California brownouts of
2000?
dieselgenerators
UPS
firesuppression
HVACSystems
servers
power
distribution
routers
batteries
security
ATypicalDataCenter
Data Center Consolidation with Virtualization
However, a fortunate trend is evolving. Servers are becoming ever more powerful. Moore’s Law
states that server capacities will double every eighteen months,1 and this trend not only has held
for decades but is projected to hold well into the future. The result is that data-center servers are
carrying less and less of their rated capacity. In fact, recent studies have shown that typical
servers in a data-center environment that is governed bya one-application, one-server policyare
runningatonly10%to15%ofcapacity.
Ifonlywecouldharnessthisexcesscapacity,wecouldsignificantlyreducethenumberofservers
in a data center by a factor of two, three, or even more. This would result in less hardware, less
maintenance, less administration, less space, and less energy – in short, less cost by a large
factor.Thisisthepromiseofvirtualization.
1
Thisisthecommonquote.GordonMooreactuallysaidthattransistordensitywoulddoubleeverytwoyears.
1
©2008SombersAssociates,Inc.,andW.H.Highleyman

ServerConsolidationviaVirtualization
Virtualization lets one physical server do the work of many. It does so by creating virtual
machines (VMs). A single physical server can host several virtual machines. We call this a
virtualizedserver.
Toanapplication,avirtualmachinelooksexactlylikethephysicalserveronwhichtheapplication
expects to run. However, the application does not have a physical server dedicated to it. Rather,
itisrunninginitsownvirtualmachine.Its virtualmachineissharinganunderlyingphysicalserver
with several other virtual machines. As a result, the utilization of physical servers in a data center
can be increased from today’s average of 15% or less to 70% or more. This workload
consolidation can significantly reduce the number of servers required in the data center. Server
consolidation is what provides the significant cost savings suggested above in hardware,
maintenance,administration,space,energy,andsoon.
VirtualizationandAvailability
Butvirtualizationcomeswithaprice,andthatpriceis availability.Ifaphysicalserverfails,ittakes
down only the application that is running on it. If the application is not mission-critical to the
enterprise, this may be acceptable. However, if a virtualized server fails, it takes down the
equivalent of severalservers sinceeach virtualmachinehosted on the virtualizedphysicalserver
fails. Thus, the failure of a virtualized physical server will take down many applications and is far
morepainfultotheenterprise,especiallyifsomeoftheseapplicationsaremission-critical.
Consequently, redundancy of physical servers in a virtual environment is necessary. Should a
server fail, there must be a failover mechanism in place to rapidly move the failed virtual
machinestofunctioningservers.
In fact, the failure consequences of a virtualized physical server argue strongly for physical
servers that simply will not fail – at least not veryoften. This is the realm of fault-tolerant servers,
whichcansurviveanysinglefaultaswellasmanycasesofmultiplefaults.
In this multipart article, we describe today’s virtualization techniques. We then look at the
redundancy mechanisms that are available today to provide fault tolerance. Finally, we briefly
reviewproductsprovidingthesecapabilities.
What is Virtualization?
Virtualization is an architecture in which access to a single underlying piece of hardware, like a
server, is coordinated so that multiple guest operating systems (virtual machines) can share that
singlepieceofhardwarewithnoguestoperatingsystembeingawarethatitissharinganythingat
all.2 Simply put, virtualization allows a single physical server to be partitioned into multiple virtual
machines(VMs)thatcanindependentlybeusedbyguestoperatingsystems.
An important characteristic of a virtual machine is that it is independent. It is totally isolated from
the other virtual machines just as if it were running in its own separate physical processor. Any
fault in an application or guest operating system in one virtual machine is completely transparent
totheothervirtualmachinesrunningonthatphysicalprocessorandcanhavenoimpactonthem.
2BernardGolden,VirtualizationforDummies,WileyPublishingInc.;2007.
2
©2008SombersAssociates,Inc.,andW.H.Highleyman

This implies that there must be some kind of adjudicator that controls the access by the various
virtual machines to the resources of the physical server - the processor, its memory, its data
storage devices, and its I/O channels. This adjudicator is known as the hypervisor. The
hypervisor traps guest operating system calls to the processor, memory, data storage devices,
and network connections and allows only one virtual machine at a time to execute these calls. In
effect, it is multiplexing the access of the various virtual machines to the underlying physical
processor,therebyensuringthateachgetstheresourcesitneeds.
Apps Apps Apps Apps
guestoperating
systemsrunningin
Linux Windows Unix Solaris
theirown
virtualmachines
Hypervisor
PhysicalServer
AVirtualizedServer
The hypervisor typically provides a system management console that allows a system
administrator to monitor the virtual machines and to start, pause, stop, delete, and otherwise
controltheVMs.
Virtualization is not new – it has been used in the mainframe world for over thirty years and was
introduced by IBM for its System 360 in 1972. What is new is that virtualization is now becoming
available to the world of industry-standard servers through products such as those from VMware
andfromCitrix(formerlyXenSource).
Whyisthistechnologyjustnowbecomingwidelyavailable?Itisbecauseofthestandardizationof
industry-standard servers on a relatively cheap common chip architecture – the x86 class of
microprocessors. This has allowed the development of hypervisors to virtualize a common
hardwarearchitectureratherthanhavingtosupportmultiplesucharchitectures.
Why Virtualization?
Wehavealludedearliertothemanyadvantagesofvirtualization.Theyinclude:
 Better Hardware Utilization: As Moore’s Law continues to predict, server capacity is
increasingatarapidrate.Yesterday’s serversthat wererunningatfullcapacityaretoday
running only at a fraction of that. Virtualization allows a data center to use this excess
capacitytoruntheloadof manyserversasvirtualmachinesonasinglephysicalserver.
 Server Consolidation: Since virtualization allows the functions currently being performed
by several physical servers to be consolidated onto one server, the data center requires
fewer physical servers. If, for instance, the data center can consolidate on average the
workloads of four current servers onto a single server, it can reduce its server count by
75%.
 Less Hardware Maintenance: The fewer the servers, the less is the maintenance
workload. Fewer maintenance personnel are needed. Fewer spare parts need to be
stocked.Fewerupgradesneedtobemade.
3
©2008SombersAssociates,Inc.,andW.H.Highleyman

 Reduced System Administration: True, the administration of applications remains.
However, fewer physical systems need to be administered; therefore, fewer
administrators need to be employed. Typical industry experience is that data-center
administrationcostscanbecutby30%to50%.
 ReducedSpaceRequirements:Largeserver farms cantakeupa lot of expensivespace.
By significantly reducing the size of the server farm, the space required to house the
serverfarmiscorrespondinglyreduced.
 ReducedEmergencyPowerNeeds:UPS(uninterruptiblepowersupply)requirementsare
proportionately less. This affects both the size of the diesel generators required and the
capacity of the battery backup system needed to power the data center until the diesel
generators kick in. In addition, diesel fuel costs are reduced, which maybe significant for
extendedoutages.
 ReducedHVACRequirements:Theamountofheating,ventilationandairconditioningfor
the data center is proportionately reduced. The same goes for lighting of the data center
space. This affects not only the initial cost for these systems but also reduces the
ongoinghigh-energycostsassociatedwithpoweringthesesystems.
 Reduced Energy Costs: With fewer servers and reduced HVAC and lighting
requirements, the amount of energy demanded by the data center is dramatically
reduced. With energy prices rapidly escalating, this can be a significant operational cost
savings. More important to some companies is the positive environmental impact that
reducingenergyconsumptioncanhave.Virtualizationisgreen!
 Reduced Capital Costs: Less money needs to be invested in server hardware, data-
centerspace,andHVACandlightinginfrastructure.
 ReducedOperatingCosts:Lesshardwaremaintenanceandsystem administration,along
withthesignificantsavings inenergycosts,resultindramaticallyreducedoperatingcosts
andareductioninthetotalcostofownership(TCO)forthedatacenter.
 ImprovedAvailability:Ifdatastorageisprovidedbynetworkattachedstorage(NAS)orby
astorageareanetwork(SAN),today’svirtualizationproductsprovideseamlessfailoverof
virtual machines from one physical server to another, thus eliminating planned downtime
for hardwareandsoftwareupgrades.Failover to another physicalserver in the eventof a
server crash is also supported to minimize unplanned downtime. Though these are
capabilities similar to those for clusters, virtualization provides failover with little if any of
thesignificantadministrativeattentionrequiredofclusters.
With all of these advantages, what are the downsides of virtualization? One is the hesitancy to
learn a new technology. The other is convincing the manager who has been running his precious
application for years on his own server to now move it to a server shared by other (perhaps less
well-behaved)applications.
Virtualization Architectures
Virtualization requires a virtualization layer between the virtual machines and the physical
machine.ThevirtualizationlayerisresponsibleformultiplexingtheaccessrequestsoftheVMsto
the resources of the physical machine. There are two primary ways in which virtualization is
implementedincurrentlyavailableproducts:
 Operating System Virtualization, in which the virtualization layer sits on top of a host
operating system that is installed on the physical server. The host operating system
4
©2008SombersAssociates,Inc.,andW.H.Highleyman

provides the interfaces between the virtual environments and the physical processor and
itsI/Odevices.
 Bare-Metal Virtualization, in which the virtualization layer (the hypervisor) sits directly on
top of the hardware with no intervening host operating system. The hypervisor in this
caseprovidesthecommondevicedrivers.
Wewillexplorethesearchitecturesindetailinournextpartinthisseries.
Summary
Virtualization has the potential to significantly reduce the size of server farms required by data
centers. This turn results in significant reduction in capital and operating costs – less equipment,
lessspace,lesspower,lesseverything.
In the following parts of this series, we will describe the various virtualization architectures. We
will then explore the fault-tolerant capabilities of these architectures, and we will review various
productsthatprovidethesecapabilities.
5
©2008SombersAssociates,Inc.,andW.H.Highleyman
