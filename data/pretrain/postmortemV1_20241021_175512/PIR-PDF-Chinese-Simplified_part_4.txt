1. Statuspage
我们优先通过 、电子邮件、支持请求单以及一对一互动直接与受
影响客户进行了沟通。不过，有很多客户我们联系不到，因为随着客户站点被
删除，我们也失去了他们的联系方式。我们应该更早发布更广泛的公告，
向受影响客户的终端用户披露我们的事件响应和解决时间线。
2.
虽然我们很快就知道了事件的起因，但此次事件的架构复杂性和特殊性导致我
们无法快速确定范围并准确预知问题的解决时间。我们不应等到全面了解所有
情况后在做沟通，而应尽早披露我们当时已知和未知的情况，提供一般性恢复
预估（可以是方向性预估），并明确说明我们预计什么时候可以全面了解所有
情况，以便客户围绕事件更好地制定计划。这对系统管理员和技术联系人来说
尤为重要，因其处在管理组织内部利益相关者和用户的前线。
支持体验和客户外联
ID
如前所述，删除客户站点的脚本还从我们的生产环境中删除了关键客户 和联系信息（例如，
URL )
云 、站点系统管理员联系人 。这一点需要格外注意，因为我们的核心系统（例如支持、
URL
许可、计费）都利用了云 和站点系统管理员联系人的存在性作为安全、路由和优先级的主要
标识。一旦丢失这些标识，我们便无法第一时间系统性的识别客户并与之互动了。
23

我们会为受影响客户提供哪些支持？
首先，大部分受影响客户无法通过正常的在线联络表联系我们的支持团队。此表在设计上要求用
Atlassian ID URL URL
户使用其 登录并提供有效的云 才能使用。没有有效的 ，用户无法提交技
术支持请求单。在业务正常运行时，此项验证是为保障站点安全和请求单分流专门设立的。
然而，对于受中断影响的客户，此项要求造成了意想不到的后果，导致他们无法提交高优先级的
站点支持请求单。
其次，该事件还造成站点系统管理员数据被删除，继而导致我们难以主动与受影响的客户联系。
Atlassian
在事件发生的最初几天，我们主动联系了 上登记的受影响客户的账单和技术联系人。
然而，我们很快发现，很多受影响客户的账单和技术联系人信息已经过时。没有每个站点的系统
管理员信息，我们就无法获得完整的活跃联系人和获批联系人列表。
我们是怎样应对的
我们的支持团队有三个同等重要的优先事项，即在事故发生的前几天加快站点恢复，并修复中断
的沟通渠道。
第一，获得可靠且经过验证的客户联系人名单。我们的工程团队在努力恢复客户站点时，我们的
客户团队会专注于经过验证的联系信息。我们会利用所掌握的每种机制（账单系统、过往支持请
求单、其他安全的用户备份、直接的客户外联等）重新制定我们的联系名单，目的是要为每个受
影响站点提供一张与事件相关的支持请求单，以简化直接外联和响应时间。
SLA ID
第二，重新建立针对此事件的工作流、队列和 。云 的删除以及无法正确认证用户影响了
我们通过正常系统处理事件相关支持请求单的能力，请求单也无法正确显示到相关优先级和升级
IT
队列及控制面板中。我们迅速组建了一支跨职能团队（支持、产品、 ），以设计和添加额外的
SLA
逻辑、 、工作流状态和控制面板。因为这项工作必须在我们的生产系统中完成，所以花了几
天时间来全面开发、测试和部署。
第三，大规模扩展手动验证以加快站点恢复。随着工程团队在初始恢复中取得进展，很明显，
我们需要全球支持团队协助通过人工测试和验证核实来加快站点恢复。当我们的工程团队加快数
24

据恢复速度后，这一验证过程将成为向客户提供恢复站点的关键路径。我们必须创建独立的标准
(SOP) 450
操作程序 、工作流、交接和人员名单流程，以动员 多名支持工程师进行验证核实，
轮流提供全天候服务，加快将恢复的内容返还给客户。
尽管在第一周结束时，这些关键优先事项已经确定，但由于恢复过程非常复杂，事件处理的时间
线也不够明确，我们提供有意义更新的能力受到了限制。我们应该早点承认我们无法提供确切的
站点恢复日期，并尽早进行面对面讨论，以便我们的客户制定相应计划。
我们将如何改进？
我们立即阻止了批量站点删除，待适当更改完成后再开启此项功能。
在我们处理此次事件并重新评估我们的内部流程时，要认识到不要人为造成事故。相反，
系统要允许犯错。本节总结了此次事件的成因。我们还讨论了为加快修复这些弱点和问题可采取
的计划。
1 “ ”
教训 ：应在所有系统设置通用 软删除
总的来说，事件中的这类删除应该被禁止，或受到多层保护，以避免出错。我们采取的主要改进
是在全球范围内防止跳过软删除程序直接删除客户数据和元数据。
a)
数据删除只能通过软删除进行
“ ”
应禁止删除整个站点，软删除应要求多级保护以防止出错。我们将实施 软删除 策略，防止外部
“ ”
脚本或系统在生产环境中删除客户数据。我们的 软删除 策略支持充分的数据保留，以便快速、
安全地执行数据恢复。只有在保留期过期后，才会从生产环境中删除数据。
行动：
“ ”
在调配工作流和所有相关数据存储中实施 软删除 ：此外，租户平台团队还将验证
数据删除是否只在停用后发生，以及该领域是否还有其他保护措施。从长远来看，
租户平台将在进一步开发正确的租户数据状态管理方面发挥主导作用。
25

b)
软删除应具有标准化且经过验证的审核流程
软删除操作为高风险操作。因此，我们应设置标准化或自动化审核流程，其中包含明确的回滚和
测试程序，以应对这些操作。
行动：
强制分阶段推出软删除操作：所有需要删除的新操作首先都要在我们自己的站点
内进行测试，以验证我们的方法和自动化程序。我们完成验证后，将会逐步引导客
户完成同样的流程，并继续测试是否存在违规行为，然后才能将自动化应用于整个
选定的用户群。
软删除操作必须具有经过测试的回滚计划：在执行任何数据软删除活动前，
必须对要删除的数据执行恢复测试，然后才能在生产中运行，并且要具有经过测试
的回滚计划。
2
教训 ：作为灾难恢复计划的一部分，为更多客户的多站点、
多产品删除事件提供自动恢复支持
Atlassian AWS
数据管理详细描述了我们的数据管理流程。为确保高可用性，我们在多个 可用区
(AZ) 60-120
域 调配和维护了一个同步备用副本。可用区域故障转移为自动化程序，通常可在 秒
内完成。我们会定期处理数据中心中断和其他常见中断问题，不会对客户造成影响。
我们还会维护不可变备份，以抵御数据损坏事件，从而能够恢复到过去的时间点。
30 Atlassian
备份保留 天， 会持续测试和审核存储备份以便恢复。必要时，我们可以帮助所有客
户恢复到新的环境。
利用这些备份，我们可定期帮助意外删除自有数据的个别客户或小规模客户组回滚到过去的
时间点。然而，站点级删除没有可快速自动化的运行手册，此次事件的规模需要以协调的方
式对所有产品和服务进行工具化和自动化。
26

我们目前尚未实现自动化的是，在不影响其他客户的情况下，将大量客户的子设备恢复到现有
（和目前正在使用的）环境。
在我们的云环境中，每个数据存储都包含来自多个客户的数据。由于在此次事件中被删除的数据只
是其他客户持续使用的数据存储的一部分，所以我们必须从备份中手动提取和恢复相应片段。每个
客户站点的恢复都涉及一个漫长而复杂的过程，恢复站点时需进行内部验证和最终客户验证。
行动：
(DR)
面向更多客户加速多产品，多站点恢复：灾难恢复 计划满足我们现行的一小
RPO
时 标准。我们将利用此次事件中的自动化程序和教训来加速灾难恢复计划，
RTO
确保遇到此等规模事件也能满足我们在政策中明确的 标准。
将此案例中的验证程序自动化并添加到灾难恢复测试中：我们将定期进行灾难恢
复练习，包括为大量站点恢复所有产品。这些灾难恢复测试将验证随着我们架构的
发展以及新边缘案例的出现，我们的运行手册有没有对应更新。我们将不断改进我
们的恢复方法，自动化更多的恢复流程，并缩短恢复时间。
3
教训 ：改进大规模事件的事件管理流程
我们的事件管理计划非常适合管理多年来发生过的大小事件。我们经常会针对一些规模较小、
持续时间较短的事件进行应急响应模拟训练，这类事件通常涉及的人员和团队较少。
然而，此次事件在高峰期要求数百名工程师和客户支持员工同时工作，以恢复客户站点。这类事
10
件的深度、广度和持续时间是我们的事件管理计划和团队始料未及的（见下方图 ）。
27

10
图 ：大规模事件管理流程概述。
我们将会优化大规模事件管理流程的定义并加强训练
我们有针对产品级事件的行动手册，但都不适用于要求全公司数百名员工同时处理的此等规模事
Slack Zoom Confluence doc
件。在事件管理工具中，我们有创建 、 和 通信流的自动化程序，
但不能创建适用于大规模事件以隔离恢复流的子通信流。
行动：
为大规模事件定义行动手册和工具，并进行模拟训练：定义并记录可能应视为大规
模事件的类型以及这类事件所需的响应级别。概述关键协调步骤并构建工具来帮助
事件经理和其他业务职能部门简化响应并启动恢复。团队中的事件经理将定期安排
模拟训练和培训，完善工具和文件，以不断改进。
28

4
教训 ：改进我们的沟通流程
a) ID
我们删除了重要的客户 ，导致我们难以与受影响客户沟通并采取行动
ID URL
删除客户站点的脚本同时还从我们的生产环境中删除了重要的客户 （例如云 、站点系统管
) (1) (2)
理员联系人 。由此导致， 客户无法通过我们的正常支持渠道提交技术支持请求单； 我们花
了数天时间才获得了受中断影响的关键客户联系人（例如站点系统管理员）的可靠名单，以主动
(3) SLA
发起互动； 因此次事件的特殊性导致支持工作流、 、控制面板和升级程序无法正常运行。
此次中断期间，客户升级还是通过多渠道（电子邮件、电话、首席执行官请求单、领英和其他社
交渠道，以及支持请求单）进行的。我们的客户团队使用了不同的工具和流程，由此减缓了我们
的响应速度，并加大了全面跟踪和报告客户升级的难度。
b)
我们没有足够详尽的事件沟通行动手册来应对如此复杂的事件
我们没有概述各项原则及角色和职责的事件沟通行动手册，无法足够快速地动员统一的跨职能事
件沟通团队。我们没有通过多渠道，尤其是社交媒体渠道，快速而一致地承认这一事件。我们本
应围绕此次中断提供更广泛的公告，并重复关键信息，即没有数据丢失，也不存在网络攻击。
29

行动：
改进关键联系人备份：在产品实例以外备份授权客户联系人信息。
URL Atlassian ID
改造支持工具：为没有有效站点 或 的客户建立机制，
以便与我们的技术支持团队直接联系。
客户升级系统和流程：投资建设基于账户的统一升级系统和工作流，
将多个工作对象（请求单、任务等）存储在单个客户帐户对象之下，
以改善所有客户团队的协调与可见性。
加快推进全天候升级管理覆盖率：根据升级管理职能的全球足迹拓展计划执行，
让每个主要地理区域的指定人员和支持角色都能提供一致的全天候覆盖服务，
以协助相关产品和销售主题专家和领导的工作。
获得新的经验时，及时更新我们的事件沟通行动手册，并定期回顾：
DACI
回顾行动手册，以便在内部定义明确的角色和沟通路径。使用 事件框架，
并为各个角色实施全天候备份，以应对生病、休假或其他不可预知的情况。
执行季度审计，以随时 验证就绪情况。
30

操作（续）
按照事件通信模板进行所有通信：提供情况说明、受影响群体、恢复时间表、站点恢
复百分比、数据丢失预估、相关置信水平，以及关于支持人员联系方式的明确说明。
结束语
随着中断得到解决，客户得到全面恢复，我们的工作也还在继续。现阶段，
我们正在实施上述变革，以改进我们的流程，提高我们的灵活性，并防止类似事件再次发生。
Atlassian
是一个学习型组织，我们的团队必定已经从此次经历中吸取了刻骨铭心的教训。
我们正在将这些经验教训应用到实践中，确保对我们的业务产生持久性的改变。最后，
经过此次事件后，我们将变得更强大，并将为您提供更好的服务。
我们希望从此次事件中吸取的教训，对其他勤勤恳恳为客户提供可靠服务的团队也能有所帮助。
Atlassian
最后，我要感谢本文的各位读者，感谢与我们一同学习的人员以及加入 社区和团队的
人员。
- Sri Viswanath
首席技术官
www.atlassian.com
©2022 Atlassian. ENTMIG-245 04/29/22
保留所有权利。 31
