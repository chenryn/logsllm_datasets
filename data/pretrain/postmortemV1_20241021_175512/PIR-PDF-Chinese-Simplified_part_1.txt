事后回顾
2022 4
年 月中断
仅为方便起见，我们提供了此翻译版本。如果中英文之间存在任何歧义或冲突，
以原始英文版本为准。

联合创始人和联合首席执行官致信
我们承认本月初发生了客户服务中断事件。我们了解，我们的产品对于您的业务至关重要，
因此，我们不会推卸责任。所有责任都由我们承担，完全由我们负责。对于受影响的客户，
我们正在努力重新赢得您的信任。
Atlassian “ ”
的核心价值观之一就是 开放的公司，绝无虚言 。我们通过公开讨论事件
Atlassian
并视其为学习机会来践行这一价值观。我们向客户、 社区和规模更大的
技术社区发布了这篇事后回顾。我们以自己的事件管理流程为傲，该流程强调建立
无责备文化，专注于寻找改进技术系统和流程的方法，这对于提供大规模、值得信
赖的服务来说至关重要。虽然我们会竭尽全力避免各类事件的发生，但我们也承
认：事件也是推动我们改进的一个强有力方式。
Atlassian 20
请放心，借助 云平台，我们可满足超过 万个不同规模、不同行业云客户的不同
99.9% SLA
需求。在此次事件之前，我们的云一直保持着 的正常运行时间，超过了 的正常运行
时间要求。我们还针对我们的平台和一些集中式平台功能进行了长期投资，搭载可扩展的基础
架构，同时定期改善安全性。
对于我们的客户和合作伙伴，感谢您一直以来的信任与合作。希望通过本文所述详情和行动，
Atlassian
我们能够表明 将继续提供世界一流的云平台和强大的产品组合，
以满足各个团队的需求。
-Scott Mike
和
2

执行摘要
2022 4 5 7:38 775 Atlassian Atlassian
自世界标准时间 年 月 日星期二 起， 个 客户失去了 产品
14 4 8
的访问权限。其中部分客户的中断时间长达 天，第一批客户于 月 日恢复，所有客户站点
4 18
都在 月 日前恢复。
Atlassian
此次事故并非由网络攻击造成，客户数据也未遭到未经授权的访问。 设有全面的
SLA SLA
数据管理计划，发布了 ，并且保持着超出 要求的记录。
99.6%
尽管这次属于重大事件，但所有客户丢失的数据都不超过五分钟。此外，超过 的客户和用
户还在继续使用我们的云产品，恢复期间也没有中断。
“ ” PIR
在本文中，我们将在此次事件中遭遇站点删除的客户称为 受影响 客户。本 披
露了确切的事件详情，概述了我们的恢复步骤，并描述了我们如何防止类似事件再
次发生。我们在本节提供了关于该事件的高级概述，更多详情见本文剩余部分。
情况说明
2021 Jira Service Management Jira Software Atlassian
年，我们完成了对适用于 和 的独立
“Insight – Asset Management” Jira
应用（名为 ）的收购和集成。随后，该独立应用成为
Service Management Jira Software
中的原生功能，不再适用于 。因此，我们需要删除客户站
点上安装的旧版独立应用。我们的工程团队使用了现有脚本和程序来删除此独立应用的实例，
但存在两个问题：
•
沟通缺失。请求删除的团队与运行删除的团队之间缺乏沟通。团队没有提供标记为删除的
ID ID
目标应用的 ，而是提供了待删除应用所在整个云站点的 。
3

• API ID
系统警示不足。用于执行删除的 同时接受了站点和应用 ，并假定输入正确，这意
ID ID
味着，如果传递的是站点 ，将会删除站点；如果传递的是应用 ，则将删除应用。
没有提供警示信号来确定请求删除的类型（是站点还是应用）。
所执行的脚本遵循了我们的标准同行审查程序，该程序主要关注具体调用了哪个端点以及如何
ID Insight App
调用，但没有反复核对所提供的云站点 ，没有验证其对应的是 还是整个站点，
ID 2022 4 5
而问题就在于该脚本包含的是客户整个站点的 。最终导致在世界标准时间 年 月
07:38 08:01 883 775 “ ”
日星期二 至 直接删除了 个站点（ 个客户）。参见情况说明
我们是怎样应对的？
4 5 08:17
在世界标准时间 月 日 确认事件后，我们启动了重大事件管理流程，并组建了跨职能事
件管理团队。在事件发生期间，这支全球事件响应团队全天候工作，直至所有站点都完成恢复、
验证并返还给客户。此外，事件管理负责人每三个小时开一次会，协调相关工作流。
最初，我们发现同时恢复数百个产品各异的客户面临着诸多挑战。
事件发生之初，我们很清楚哪些站点受到了影响，我们的首要任务是与每个受影响站点的获准所
有者联系，告知其中断情况。
然而，有些客户的联系信息被删除了。这意味着这些客户无法像往常一样提交支持请求单，
“ ”
同时也意味着我们无法立即联系到关键客户联系人。更多详情，请参见恢复工作流的高级概述 。
4

我们采取了哪些措施来防止未来再次发生这种情况？
我们立即采取了很多措施，并致力于做出改变，以避免未来再次发生这种情况。下面是我们已经
或将要做出重大改变的四个具体领域：
1.
在所有系统中建立通用“软删除”。总的来说，事件中的这类删除应该被禁止，或受到
“ ”
多层保护，以避免出错，包括针对 软删除 进行分阶段回滚和测试回滚计划。我们将在全
球范围内防止跳过软删除程序删除客户数据和元数据。
2. (DR)
投资制定我们的灾难恢复 计划，为更多客户实现多站点、多产品删除事件自动恢复
程序。我们将利用自动化以及从此次事件中吸取的教训，加快灾难恢复计划，以达到我们
(RTO)
在政策中就这一规模事件而设定的恢复时间目标 。我们将定期进行灾难恢复演习，
包括恢复大批站点的所有产品。
3.
修改大规模事件的事件管理流程。我们将改进大规模事件的标准操作程序，并通过模拟
大规模事件来练习这种程序，我们将会更新我们的培训和工具，以应对大量团队并行工作
的情况。
4.
创建大规模事件通信行动手册。我们将通过多个渠道及早发现事件，并在数小时内发布事
件公告。为了更好地接触受影响的客户，我们将改进关键联系人备份并改造支持工具，
URL Atlassian ID
让客户没有有效的 或 也能直接联系我们的技术支持团队。
“ ”
我们完整的行动项目列表详见下面的完整事后回顾。参见我们如何改进
5

目录
Atlassian 7
的云架构概述 第 页
• Atlassian
的云托管架构
•
分布式服务架构
•
多租户架构
•
租户调配和生命周期
•
灾难恢复计划
o
弹性
o
服务存储可恢复性
o
多站点、多产品自动恢复能力
13
情况说明、时间线和恢复 第 页
•
情况说明
•
我们如何协调
•
事件时间线
•
恢复工作流的高级概述
1
o
工作流 ：检测、开始恢复并确定方法
2 “ 1”
o
工作流 ：早期恢复和 恢复 方法
3 “ 2”
o
工作流 ：加速恢复和 恢复 方法
o
恢复已删除的站点时，最大限度减少数据丢失
21
事件沟通 第 页
•
情况说明
23
支持体验和客户拓展 第 页
•
我们会为受影响客户提供哪些支持？
•
我们是怎样应对的
25
我们如何改进？ 第 页
• 1 “ ”
教训 ：应在所有系统设置通用 软删除
• 2
教训 ：作为灾难恢复计划的一部分，为更多客户的多站点、
多产品删除事件提供自动恢复支持
• 3
教训 ：改进大规模事件的事件管理流程
• 4
教训 ：改进我们的沟通流程
31
结束语 第 页
6

Atlassian
的云架构概述
Atlassian
要了解本文档中所述事件的起因，建议先了解一下 产品、
服务和基础架构的部署架构。
Atlassian
的云托管架构
Atlassian Amazon Web Services (AWS)
使用 作为云服务提供商，并在全球多个地区使用其高
AWS
可用性数据中心设施。每个 区域都设有一个独立的地理位置，并且分为多个相互隔离，
(AZ)
地理上相互分开的数据中心组，也称可用区域 。
AWS
我们利用 的计算、存储、网络和数据服务来构建我们的产品和平台组件，因而能够利用
AWS
提供的冗余功能，如可用区域和区域。
分布式服务架构
AWS
借助此 架构，我们对我们解决方案中使用的很多平台和产品服务都进行了托管。其中包括
Atlassian
跨多个 产品共享和使用的平台功能，如媒体、身份、商务、我们的编辑器等体验，
Jira Confluence
以及一些产品专用功能，如 事务服务和 分析。
1 Atlassian
图： 平台架构。
7
