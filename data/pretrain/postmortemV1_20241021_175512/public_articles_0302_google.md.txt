How Does Google Do It?
February2008
Search for “availability” on Google. How does Google give you 674,000,000 web references in
150 milliseconds? Through an extremely efficient, large-scale index of petabytes (that’s millions
ofgigabytes)ofwebdata.
Amajorproblem Googlefacesishowtoprocessthis massiveamountofworldwidedatainatime
that makes the indices useful. Google has solved this problem by building an equally massive
parallel computing facility driven by its MapReduce function. MapReduce distributes applications
crunching terabytes of data across hundreds or thousands of commodity PC-class machines to
obtainresultsinminutes.
With MapReduce, Google programmers without any parallel and distributed systems experience
can easily utilize the resources of these massive clusters. MapReduce takes care of partitioning
the input data, scheduling the program’s execution across the machines, handling balky and
failedmachines,balancingtheload,andmanagingintermachinecommunications.
Google fellows Jeffrey Dean and Sanjay Ghemawat describe the MapReduce function in their
paper entitled MapReduce: Simplified Data Processing on Large Clusters.1 This Availability
Digestarticlesummarizestheirdescription.
The MapReduce Programming Model
MapReduceisfocusedonsolvingproblemsinwhichitisdesiredtoderiveasetof key/valuepairs
from a massively large collection of data. “Key/value pairs” may sound a bit abstract, but some
examples will illustrate their importance with regard to services such as those provided by
Google.
A key/value pair is simplythat – it is a keyfollowed by a value. For instance, a simple example is
onein whichthekeyis awordandits valueis thenumberofoccurrences of thatwordinthedata
set.
Avaluecanbeasinglenumber,alistofitems,oravectorofitems.
Othermoremeaningfulexamplesinclude:
 ForaparticularURL(thekey),alistofallwebsitesthatpointtothatURL(thevalue).
 Foraparticularword(thekey),alistofalldocumentsthatcontainthatword(thevalue).
1 Jeffrey Dean, Sanjay Ghemawat, MapReduce: Simplified Data Processing on Large Clusters, Communications of the
ACM;January8,2008.
Thispapercanalsobefoundathttp://209.85.163.132/papers/mapreduce-osdi04.pdf.
1
©2008SombersAssociates,Inc.,andW.H.Highleyman

 For a particular document (the key), a list of all words and their frequencies contained in
thedocument(avectorvalue).
MapReduceoperationscanbestrungtogethertocreatemorecomplexdatasummaries.
The MapReduce programming model requires that the programmer write two fairly simple
programs:
 A Map function that generates a set of intermediate key/value pairs from the input data
set.
 A Reduce function that merges intermediate key/value pairs associated with the same
intermediatekey.
MapReduce automatically parallelizes these tasks and executes them on a large cluster of
commodity machines. Many Map tasks are created, each working on a portion of the input data
set. The Map tasks parse the input data and create intermediate key/value pairs. These are
passed to the Reduce tasks, which merge and collate the results of the various Map tasks to
generatethefinalkey/valuepairs.
input Reduce
Maptask
data task
intermediate final
key/value key/value
pairs pairs
TheMapReduceFunction
For instance, the simple word count example given above determines the number of instances of
each word in the input data set. In this case, each Map function generates a key/value pair for
each word in its portion of the input data set. This key/value pair is simply the word (the key)
followedbythenumber“1”(thevalue).Eachkey/valuepairiswrittentoanintermediatekey/value
store.
The Reduce function reads the intermediate key/value store and merges by key all of the
intermediate key/value pairs that have been generated bythe Map tasks. In this simple case, the
Reducefunction willsimplyaddupthenumber ofkey/valuepairs for eachwordand willstorethe
final count in the final key/value store. In the above example, an intermediate key/value might be
“horse/1.”Thefinalkey/valuemightbe“horse/356.”
In many applications, the Map task can do some initial summarization itself before passing the
intermediatefileregionstotheReducers,thusoffloadingsomeoftheReducerprocessing.Thisis
done by creating a Combiner function in the Map task. For instance, in the above simple
example, the Map task might aggregate the count for each key before writing it to the
intermediatekey/valuestore.
MapReduce automatically parallelizes and executes the Map and Reduce tasks. It partitions the
input data, schedules the task executions across a set of machines, balances the load across
these machines, handles balky and faulty machines, and manages intermachine
communications. The complexities of the distributed system are completely hidden to the
programmer. Programmers without any experience in parallel and distributed processing can
easilyutilizetheresourcesofalargedistributedsystem.
2
©2008SombersAssociates,Inc.,andW.H.Highleyman

The MapReduce Implementation
TheClusterHardware
The very large Google clusters used for running MapReduce applications can each contain
thousands of commodity PC-class machines. Each machine is typically a dual-processor x86
machine running Linux. The machines are configured with two to four gigabytes of memory and
with inexpensive, directly-attached IDE disks. The Google File System (GFS) manages the files
onthedirectly-attacheddisks.
Themachinesinaclusterareconnectedby100megabit/sec.or1gigabit/sec.LANs.
TheProgram
The user program comprises the Map and Reduce tasks. They are typically fairly short and
simpleprograms.
In addition to writing the Map and Reduce tasks, the user must specify a set of runtime
parametersforMapReduce.Theseparametersinclude:
 the number of splits, M, into which the input data is to be split. One Map task will be
createdforeachsplit.Thus,thereareMMaptasks.
 thenumberofintermediatefileregions,R,intowhichtheintermediatekey/valuepairs
are to be partitioned. The association of an intermediate key/value with an
intermediatefileregionisdoneviaahashingalgorithm [hash(key)modR].Astandard
MapReduce hashing algorithm can be used, or the user can specify his own
algorithm.Therewill be oneReducetask createdfor each intermediatefile regionfor
atotalofRreducetasks.
 thenumberofPCstouse.ThesetofMplusRtasksisusuallymuchgreaterthanthe
numberofspecifiedPCs.
 theamountofmemorythatataskcanuseinamachine.
TheMapReduceInfrastructure
Users submit their MapReduce jobs to a cluster scheduler. The scheduler creates M Map tasks
and R Reduce tasks and assigns them to the user-specified number of machines in the cluster.
Eachmachinecanhavemultipletasksassignedtoit.Thesearetheworkermachines.
Onespecialtaskisstartedononemachineinthecluster.ItistheMastertask.TheMastertask:
 stores the state (idle, in-progress, completed, failed) of each Map and Reduce task and
themachinetowhichitisassigned.
 acts as the conduit through which the locations of the intermediate file regions are
propagatedfromMaptaskstoReducetasks:
o For each completed Map task, the Master stores the locations and the sizes of
theRintermediatefileregionsproducedbythoseMaptasks.
o It pushes the location and size of the intermediate file regions to the Reduce
functionsresponsibleforthoseregions.
3
©2008SombersAssociates,Inc.,andW.H.Highleyman

 provides additional support for performance, statistical reporting, and fault tolerance, as
describedlater.
Once the scheduler has assigned the Map and Reduce tasks to specific machines, the
MapReducefunctionproceedsasfollows:
user
program
fork fork
fork
Master
slice1
slice2 map
worker reduce
slice3 worker
slice4 output
map localwrite files
slice5 worker reduce
slice6 worker
.
map
.
worker remoteread
.
intermediate
files(onlocaldisk)
MapReduceImplementation
 The input data is split into the M specified splits, each typically 16 megabytes to 64
megabytesinsize.
 The Map, Reduce, and Master tasks are started in their assigned machines. There are
usuallymultipleMapandReducetasksassignedtoeachworkermachine.
 The Master picks idle worker tasks and assigns them each a job. Each of the M Map
worker tasks is assigned a slice from the input data. Each of the R Reduce worker tasks
isassignedanintermediatefileregion.
 A Map worker task reads its assigned input slice and, using the user-supplied Map
function, parses key/value pairs from it. The intermediate key/value pairs that it produces
arebufferedinitsmemory.
 Periodically, the buffered key/value pairs are organized into the R intermediate file
regions by the Map worker task and are written to local disk. The disk locations of these
regionsarepassedbacktotheMaster.
 The Master notifies a Reduce worker task when an intermediate file region assigned to it
becomesavailableandprovidesthatworkertaskwiththemachineIDandthefilelocation
oftheMapworker’smachine.
 AReduce workerusesremoteprocedurecallstoread thenewly-createdintermediatefile
regions for its assigned region from the PCs at which they are resident. It then sorts the
key/valuepairsbykey.
4
©2008SombersAssociates,Inc.,andW.H.Highleyman

 The Reduce worker passes each key/value pair to the user-supplied Reduce function.
The results of the Reduce function are appended to a global output file for this Reduce
partition.
 When all Map tasks and Reduce tasks have completed, MapReduce returns control to
theuserprogram.
Theresultisasetof Routputkey/valuefiles writtentoglobalstorage.Often,theseoutputfilesdo
not need to be combined into a single file. Rather, they are used as input to another MapReduce
programforfurtherprocessing.
Fault Tolerance
A typical MapReduce cluster contains hundreds to thousands of commodity machines. As a
consequence, machine failure is common. MapReduce uses reexecution as the primary
mechanismforrecoveryfromamachinefailure.
WorkerFailure
TheMastercontinuallypingsitsworkermachines.Ifaworkermachinefailstorespond,itsstateis
markedasfailed.
MapWorker
If the failed machine is a Map worker, any of its completed or in-progress tasks are reset to idle
and its results ignored. This is necessary because the intermediate key regions which it has
producedarestoredonitslocaldiskandmaynotyethavebeenreadbytheReduceworkers.
The Map tasks that had been running in the failed machine are restarted on other machines, and
eachreprocessesitsassignedinputsplit.TheReduce workersarenotifiedofthereexecutionand
switch to the new Map worker to get their assigned intermediate file regions. Duplicates are
ignored.
ReduceWorker
If the failed machine is a Reduce worker, its reduce tasks are reassigned to other machines. The
Reduce tasks do not have to reexecute work already processed since their results are contained
inglobalstorage.
Load Balancing
Tomaintainabalanceofloadacrossthecluster,shouldamachinefail,itstasksmaybeallocated
acrossseveralotherworkermachines.
MasterFailure
Since the Master task is running on a separate machine, it will hardlyever fail. Rather than trying
to continue on from a checkpointed state, all currently executing MapReduce programs are
simplyabortedandmustberesubmitted.
Bad Records
Another commonfailuremode is process aborts due to bad records. A bad record that cannot be
processedcaneffectivelyaborttheentireMapReduceprogram.
5
©2008SombersAssociates,Inc.,andW.H.Highleyman

If a Map or a Reduce task generates an exception, it sends a “last gasp” message to the Master
before aborting. The message informs the Master of the record location and identification. If the
Master receives two such messages for a given record, it notifies the new worker task that this
recordshouldbeskippedonthetask’sreexecution.
Stragglers
APCcanbesloweddownsignificantlybyanerraticdiskthatisgeneratingaseriesoferrorsorby
being overloaded byother tasks assigned to it bythe cluster manager. The MapReduce program
cannot complete until this straggler machine completes its MapReduce functions, consequently
slowingdowntheentireexecution.
MapReduce compensates for stragglers as follows. After most worker tasks have completed,
MapReduce will start a backup copy of each incomplete worker task on another machine in the
cluster.Theresultsofthefirstworkertask tocompleteareusedbytheMaster,andtheothertask
is aborted. In this way, stragglers have a limited effect on program execution. Google has found
thatwithoutbackuptasks,processingtimescanincreasebyasmuchas50%.
Locality
Google has found that the limiting factor in these large computations is network capacity. It is
imperative to minimize the amount of traffic flowing across the network due to intertask
communications.
Network traffic is greatly minimized by ensuring that the Map workers do most of their work on
their local disks. To start with, the input data is spread across the local disks of all of the Map
worker machines. In fact, the data is written in three copies, with each split written to three
differentmachines.
TheMasterattemptstoassignMaptaskstosplitsthatareonthesamemachine.Ifthiscannotbe
done,aworkermachineclosetooneofthemachinesholdingthesplitisassignedtothesplit.
Totheextentthat Maptasks have localaccess totheir splits,nonetwork traffic is generated bya
Map task since data read locally consumes no network bandwidth. Only the reading of the
intermediate file regions by the Reduce tasks and the writing of completed regions to the global
store consumes network capacity. Consequently, network capacity is not generally a limiting
factorintheexecutionofMapReducetasks.
Task Granularity
From aperformanceviewpoint,it is importantto specifya fine granularitywithrespectto the Map
and Reduce tasks. It is optimum to have M and R, the number of worker tasks, be much greater
thanthenumberofmachines.
This fine granularity has several benefits. For one, it is easier to balance the MapReduce load
across many machines. In addition, the reexecution time following a machine failure can be
minimizedbyspreadingitsworkertasksamongseveralsurvivingmachines.
A typical configuration would have 200,000 Map tasks and 5,000 Reduce tasks spread among
2,000workermachines.
6
©2008SombersAssociates,Inc.,andW.H.Highleyman

Scalability
MapReduce is massively scalable. It is limited only by the capacity of the Master machine. The
MastertaskmusttrackM+RtasksandMxRintermediatefileregions.
For thetypicalconfigurationdescribedabove,theMastermusttrack 205,000 +(200,000x 5,000)
items,ormorethanabillionitems.
Statistics
MapReducemaintainsseveralcounters,suchasthenumberoftasksthatareinprogressorhave
completed, the input key/value pairs processed, and the number of intermediate keys generated.
Inaddition,userscangeneratetheirowncountersofexecutionactivity.
The values of these counters are returned to the Master on each heartbeat ping. There they are
organized into a web page so that users can monitor the progress of their runs. These statistics
arealsousedtocreateafinalreportfortherun.Thereportisreturnedtotheuserprogram.
Debugging
Debugging a program that is running across a thousand machines can be a daunting task. To
remove this complexity, MapReduce can be configured to run on one machine only.
Programmerscanthenusestandarddebuggingtoolstogettheirprogramstorunproperly.
Performance
Google has measured some impressive performance metrics for MapReduce. For instance, a
ten-terabyte search to count the number of a rare three-character sequence completes in 80
seconds(plus70secondsofoverheadtostartupthetasks).
Aten-terabytesortof100-byterecordstakesaboutfifteenminutes.
Summary
MapReduce is being used by Google for many applications requiring data reduction of massive
datasets.ThousandsofMapReducejobsareruneachday.
Perhaps the best known application is Google’s production indexing system that responds so
quickly to user searches. The MapReduce application that creates these indices parses a large
set of documents retrieved by Google’s crawling system – the Google spiders. Typically, 20
terabytes of data are processed at a time. A sequence of five to ten MapReduce operations is
usedtogeneratetheseindices.
ThesuccessofMapReduceisattributedtoseveralfactors:
 The model is easy to use even by programmers inexperienced in parallel and distributed
processing systems. It hides the complexities of parallelization, fault tolerance, locality
optimization,andloadbalancing.
 A large variety of problems are easily expressible as MapReduce computations. Such
problemsincludeindexing,sorting,datamining,andmachinelearning.
 MapReduce scales to large clusters containing thousands of machines. The
implementationmakesefficientuseofthesemachineresources
7
©2008SombersAssociates,Inc.,andW.H.Highleyman
