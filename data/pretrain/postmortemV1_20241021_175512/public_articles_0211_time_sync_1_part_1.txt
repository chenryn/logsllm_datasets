Time Synchronization for Distributed Systems – Part 1
November2007
In many distributed systems, it is imperative that each node march to the same time. In fact, this
requirement is often extended to include client systems that access nodes in the distributed
system.
Time synchronization is a complex problem across distributed systems. Each node in a
distributedsystem necessarilyhasitsownclock.Communicationbetweennodes cantaketensof
milliseconds and, especially over the Internet, can be quite variable and unpredictable.
Consequently, tight (e.g., submillisecond) time synchronization cannot be achieved simply by
havingonemastertimekeepingserversendtimingmessagestotheothernodesinthenetwork.
In this series of articles, we discuss current technologies for maintaining time synchronization
across the network. The most common approach today is NTP (Network Time Protocol), used
extensively over the Internet. However, some synchronization problems go beyond the scope of
NTPandrequireadditionaltechnologies.
In Part 1, we discuss the basics of how NTP adjusts time between systems. Part 2 discusses
additional NTP features that make these adjustments more precise. Part 3 discusses a totally
different approach, called Lamport logical clocks, which has the potential of virtually eliminating
datacollisionsinactive/activesystemswithoutrevertingtosynchronousreplication.
A Brief History of Time – The Leap Second
In the words of the brilliant physicist Professor Stephen Hawking, let us first look at the evolution
of timekeeping and its impact on computer time synchronization, or computer network
chronometry.
Our civil timeis based on three astronomicalrotations –the earth about its axis (which takes one
day), the moon about the earth (which takes one month), and the earth about the sun (which
takes one year). For the last 4,000 years and until recently, timekeeping has been the realm of
astronomers.
The day was measured by the amount of time between two transits of the sun, or when the sun
reached its highestpointin thesky.This timewas brokenup into24hours and an hour into3600
seconds.
Early astronomers determined that a year was 365 days. However, by Julius Caesar’s time, the
calendar year hadslipped byeight weeks relativetothesolar year.As aconsequence,theJulian
calendar,adoptedin46BC,addedanextradayeveryfourthyear(theleapyear).
Still, by1545,thediscrepancyof theJulian year hadcrepttotendays.As aresult, Pope Gregory
XIIIissued adictum thata solar year was 365.2422 days, leadingtotheskipping of the leap year
every400years.ThisbecametheGregoriancalendarinusetoday.
1
©2007SombersAssociates,Inc.,andW.H.Highleyman

Thesagacontinues.In1940,itwasdiscoveredthattheearth’srotationisslowingdown,probably
due to tidal friction and atmospheric drag. In fact, geologists now believe that 300 million years
ago, there were 400 days in a year. As a consequence, the duration of a solar second is slowly
changing. With the invention of the atomic clock in 1948, it became possible to measure time
more accurately and independently from the wiggling and wobbling of the earth. At this point,
physicists took over the job of timekeeping from the astronomers. They redefined a second as
being 9,192,631,770 transitions of the cesium atom. This gives a time resolution of about a tenth
of a picosecond. Periodically, laboratories around the world tell the Bureau International de
l’Heure(BIH) in Paris how manytimes their cesium atomic clocks have ticked.The BIH averages
these and produces the International Atomic Time (TAI). TAI is the number of cesium transitions
sinceJanuary1,1958.
However, this is not quite accurate. A TAI day is about 3 msec. short, and the day is getting
longer all the time. To correct this problem, BIH introduces a leap second whenever the
discrepancy between TAI and the mean solar day grows to 800 msec. This gives rise to a time
system that keeps in phase with the sun and is called Universal Coordinated Time, or UTC. It
replacestheoldstandard,GreenwichMeanTime(GMT),whichissolartime.
The importance of all of this on computer network chronometry is that leap seconds have to be
added to whatever primary timing source we are using. In some cases, this is done by the
primarytimesource.Inothercases,wehavetodoit.
Primary Reference Clocks
Aprimaryreferenceclockisaclock thatkeepsTAIorUTCtime.Thereareseveraltypesofthese
clocksavailableforuseinsynchronizingcomputernetworks.
AtomicClocks
A system could use a local cesium atomic clock. However, this is very expensive and not
typicallydone.Ifanatomicclockisused,theusermustaddleapseconds.
Radio
Various governments broadcast UTC over radio channels. In the U.S., these channels include
WWVandWWVBinBoulder,Colorado,andWWVHinHawaii.
Computers using these channels as a source must estimate the communication latency between
the radio station and their computer site, and add that latency to the broadcast time in order to
arriveattherealtime.
WWV broadcasts at high frequencies from 2.5 to 20 megahertz. It propagates by bouncing a
signal off of the upper ionosphere, and it is therefore receivable over most of the western
hemisphere. However, since the height of the upper ionosphere changes during the day, the
latency is quite variable, and leads to significant jitter in the calculated time. Accuracies of one to
tenmillisecondsareachievable.
WWVB broadcasts on a much lower frequency – 60 kilohertz. Its signal bounces off of the lower
atmosphere. Therefore, it is much more stable (accuracies within 50 microseconds can be
achieved)butisreceivableoveramuchsmallerarea(thecontinentalUnitedStates).
Radio time receivers are available from Spectracom, Tranconex, Kinemetrics, and others and
costintheorderofafewthousanddollars.
2
©2007SombersAssociates,Inc.,andW.H.Highleyman

Loran
The U.S. Coast Guard and agencies in other nations provide Loran service for navigational
purposes. Loran provides time accuracies of about a microsecond within a few hundred
kilometers of a ground station due to its use of ground waves. Beyond that, Loran depends upon
thelowerionosphereandprovidesaccuracieswithin50microseconds.
Satellite
More recently, the GOES (Geosynchronous Orbit Environment Satellite) and the GPS (Global
Positioning Satellite) systems provide timing information accurate to within a few hundred
microseconds. GPS timing promises to lead to less expensive receivers. After all, GPS
technologyhasnowreachedthecellphone.
Time Synchronization with NTP
The Network Time Protocol (see www.ntp.org) is one of the oldest protocols on the Internet.
Developed by David Mills at the University of Delaware as an open source offering, it is
maintainedbyhimandastaffofvolunteers.1
NTP is a protocol for synchronizing computer system clocks over packet-switched variable
latency networks. It is designed particularly to resist the effects of variable channel latency, or
jitter. It provides the mechanisms for a distributed subnet of time servers to operate in a self-
organizing, hierarchical master/slave configuration and to synchronize the local computer clocks
withinthesubnettonationaltimestandards.Inpractice,itachievestimingaccuracyofbetterthan
tenmillisecondsoverpublicnetworksand200microsecondsoverLANs.
Version 0 of NTP went into service in 1985. Version 4 is now in use, and version 5 is being
specified. Version 3 is very well documented via RFC 1305,2 but the version 4 documentation is
stillinprogress.
DeterminingandCorrectingTimingErrors
Timestamps
NTP reports time via an NTP timestamp. This timestamp is 64 bits long. The high-order 32 bits
represent the number of seconds since January 1, 1900, and the low-order bits represent the
fractionofasecond(aresolutionofabout200picoseconds).
The 32-bit length for the seconds field presents a rollover problem. NTP clocks will roll back to
1900 in 2038, reminiscent of the Unix 2036 problem. To correct this, future versions of NTP plan
tousea128-bittimestamp,64bitsforsecondsand64bitsforthefractionofasecond.The64-bit
seconds field will take us out until after the universe goes dark – 585 billion years. According to
David Mills, the 64-bit fractional field is enough to resolve the time that it takes a photon to pass
anelectron.128bitsshoulddousforawhile.
OffsetandSkew
NTP provides the facilities to compare a client clock to a time-server clock and to determine the
offset of the client clock relative to the time-server clock. The frequency difference, or skew,
between the clocks can also be determined. Knowing the offset, the client clock can be adjusted
1
Mills,D.,ABriefHistoryofNTPTime:ConfessionsofanInternetTimekeeper,
http://www.cis.udel.edu/~mills/database/papers/history.pdf
2
http://www.eecis.udel.edu/~mills/database/rfc/rfc1305/
3
©2007SombersAssociates,Inc.,andW.H.Highleyman

to agree with the time-server clock. If the client clock is using a clock the frequency of which can
be controlled (such as a voltage-controlled oscillator), its clock frequency can be adjusted by
knowingtheskew.
The offset is simply determined by the client sending a timestamped message to the time server
and by the time server returning that message with its own timestamps, as shown in Figure 1. I
