### Backdoor Detection and Prevention in Response-Computable Authentication (RCA) Systems

#### Backdoor Detection Techniques
Backdoor detection can also be applied to identify hidden malware. For example, Crandall et al. [13] implemented a temporal search technique using virtual machines running at slightly different rates to detect hidden malware time-bombs. Wilhelm et al. [36] used a forced-execution approach to explore different execution paths in malware, while Moser et al. [23] and Brumley et al. [9] independently developed symbolic-execution-based systems for the same purpose. Comparetti et al. [12] proposed a graph-matching method to identify malicious functionalities in malware samples.

These techniques can be adapted to detect certain types of backdoors. However, anti-analysis methods, such as code obfuscation [11], [22], [25] and code encryption [28], [38], can hinder detection. Instead of focusing on detection, our work aims to nullify the effects of backdoors in RCA login frameworks.

#### Backdoor Prevention
Wysopal [29] provided an overview of different backdoor mechanisms and suggested using static analysis to identify indicators like static variables that resemble hashes or cryptographic keys, thereby preventing the use of pre-owned special credentials. Source code review, however, cannot detect backdoors instrumented at the binary level. Wheeler [35] proposed a diverse double-compiling technique to compare untrusted binaries with those generated by trusted compilers. Syntax-based [15] or semantics-based [16] binary comparison techniques can also be used to statically identify binary equivalence. The deviation detection method in [8] can dynamically identify the equivalence of execution traces, which helps mitigate backdoor problems caused by malicious compilers.

#### Hardware Backdoors
In recent years, hardware backdoors have become a significant concern [18], [31], [33], [34]. Hicks et al. [18] introduced BlueChip, a hybrid hardware/software approach that identifies unused circuits during verification tests and uses trusted software to emulate these circuits. This prevents activation of backdoor logic in unused circuits, a method that could be applied to isolate certain types of backdoors in software. For instance, if some code in a login module is not tested, it can be separated from the module. However, this approach has limitations against flexible backdoor implementation methods.

Waksman et al. [33] proposed a method to make backdoors intractable by scrambling inputs, making it difficult for attackers to control them. Preventing untrusted login modules from receiving expected inputs is useful in defending against backdoors. However, in login protocols, data such as challenge values and responses cannot be scrambled, limiting the applicability of this method.

### Conclusions
Response-computable authentication (RCA) is a widely adopted two-party authentication model in many login systems. Unfortunately, these systems are vulnerable to backdoors. Malicious developers can introduce backdoors through source code, malicious compilers, subtle vulnerabilities, or weak cryptography. Traditional technologies struggle to completely eliminate backdoors.

In this paper, we propose a framework for RCA systems to ensure no usable backdoors exist. We prove theorems about the upper bound of potential backdoor usability. Our framework splits the RCA model into a response-computation function and simple, manually checkable assistant logic. The response-computation function, which may contain backdoors, is placed in NaPu, a native pure-function-enforcing sandbox. NaPu prevents attackers from triggering backdoors via vulnerabilities and ensures the response-computation function remains pure. We provide theoretical bounds on backdoor usability, forming the basis for our testing methods. These methods either detect possible backdoors or ensure they cannot be used by their creators. The concept of enforcing functional purity can be extended to other applications, such as e-voting machines [14], [27], [30].

We ported several popular login modules into this framework and verified they are backdoor-free. We also detected real backdoors in login modules through probability testing. Performance measurements showed acceptable overhead, and automatic standard tests confirmed the framework's applicability to real login systems, ensuring no practically usable backdoors.

### Acknowledgments
We are grateful to David Wagner, Shuo Chen, Prateek Saxena, and the anonymous reviewers for their insightful comments and suggestions. This research was supported in part by the National Natural Science Foundation of China (Grant No. 61003216), the National University of Singapore under NUS Young Investigator Award R-252-000-378-101, and the Office of Naval Research under MURI Grant No. N000140911081.

### References
[1] NaCl project: Disabling sources of non-determinism for guest code. http://code.google.com/p/nativeclient/wiki/DeterministicExecution.
[2] ProFTPD Backdoor Unauthorized Access Vulnerability. http://www.securityfocus.com/bid/45150.
[3] RSA SecurID Two-factor Authentication. http://www.rsa.com/node.aspx?id=1156.
[4] TOTP: Time-based One-time Password Algorithm. http://tools.ietf.org/html/draft-mraihi-totp-timebased-08.
[5] Back Door in Commercial Shopping Cart. http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2000-252.
[6] S. M. Bellovin and M. Merritt. Encrypted key exchange: Password-based protocols secure against dictionary attacks. In IEEE Symposium on Research in Security and Privacy, pages 72–84, 1992.
[7] D. Brumley and D. Boneh. Remote timing attacks are practical. In Proceedings of the 12th conference on USENIX Security Symposium - Volume 12, pages 1–1, Berkeley, CA, USA, 2003. USENIX Association.
[8] D. Brumley, J. Caballero, Z. Liang, J. Newsome, and D. Song. Towards automatic discovery of deviations in binary implementations with applications to error detection and fingerprint generation. In Proceedings of USENIX Security Symposium, Aug. 2007.
[9] D. Brumley, C. Hartwig, Z. Liang, J. Newsome, P. Poosankam, D. Song, and H. Yin. Automatically identifying trigger-based behavior in malware. In Book chapter in "Botnet Analysis and Defense," Editors Wenke Lee et. al., pages 65–88. Springer US, 2008.
[10] C. Castelluccia, M. Durmuth, and D. Perito. Adaptive password-strength meters from Markov models. In Proceedings of the 19th Annual Network and Distributed System Security Symposium (NDSS'12), 2012.
[11] C. Collberg, C. Thomborson, and D. Low. Manufacturing cheap, resilient, and stealthy opaque constructs. In POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, 1998.
[12] P. M. Comparetti, G. Salvaneschi, E. Kirda, C. Kolbitsch, C. Kruegel, and S. Zanero. Identifying Dormant Functionality in Malware Programs. In 2010 IEEE Symposium on Security and Privacy, pages 61–76, 2010.
[13] J. R. Crandall, G. Wassermann, D. A. S. de Oliveira, Z. Su, S. F. Wu, and F. T. Chong. Temporal search: Detecting hidden malware timebombs with virtual machines. In Proceedings of the 12th International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS-XII, pages 25–36, New York, NY, USA, 2006. ACM.
[14] M. Finifter, A. Mettler, N. Sastry, and D. Wagner. Verifiable functional purity in Java. Proceedings of the 15th ACM Conference on Computer and Communications Security CCS 08, page 161, 2008.
[15] H. Flake. Structural comparison of executable objects. In Proceedings of Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA), 2004.
[16] D. Gao, M. K. Reiter, and D. Song. BinHunt: Automatically Finding Semantic Differences in Binary Programs. In Proceedings of the International Conference on Information and Communications Security, pages 238–255. Springer-Verlag, 2008.
[17] J. Gonzalez and V. Paxson. Enhancing Network Intrusion Detection with Integrated Sampling and Filtering. In Recent Advances in Intrusion Detection (RAID), volume 4219 of Lecture Notes in Computer Science, pages 272–289. Springer Berlin / Heidelberg, 2006.
[18] M. Hicks, M. Finnicum, S. T. King, M. M. K. Martin, and J. M. Smith. Overcoming an Untrusted Computing Base: Detecting and Removing Malicious Hardware Automatically. In 2010 IEEE Symposium on Security and Privacy (SP), pages 159–172, 2010.
[19] L. Ho and A. Atkins. Security of software outsourcing in military and government agencies. In Proceedings of IADIS International Conference on WWW/Internet 2005, pages 347–355, 2005.
[20] S.-J. Horng, M.-Y. Su, and J.-G. Tsai. A dynamic backdoor detection system based on dynamic link libraries. International Journal of Business and Systems Research, 2(3):244–257, 2008.
[21] J. Klensin, R. Catoe, and P. Krumviede. IMAP/POP AUTHorize Extension for Simple Challenge/Response. RFC 2195, Internet Engineering Task Force, Sept. 1997.
[22] C. Linn and S. Debray. Obfuscation of executable code to improve resistance to static disassembly. In CCS '03: Proceedings of the 10th ACM Conference on Computer and Communications Security, 2003.
[23] A. Moser, C. Kruegel, and E. Kirda. Exploring Multiple Execution Paths for Malware Analysis. In SP '07. IEEE Symposium on Security and Privacy, pages 231–245, 2007.
[24] D. M'Raihi, M. Bellare, F. Hoornaert, D. Naccache, and O. Ranen. HOTP: An HMAC-Based One-Time Password Algorithm. RFC 4226, Internet Engineering Task Force, Dec. 2005.
[25] I. V. Popov, S. K. Debray, and G. R. Andrews. Binary obfuscation using signals. In SS'07: Proceedings of the 16th USENIX Security Symposium on USENIX Security Symposium, Berkeley, CA, USA, 2007.
[26] A. Salomaa. Public-Key Cryptography. Springer, 1996. ISBN 3-540-61356-0.
[27] N. Sastry, T. Kohno, and D. Wagner. Designing voting machines for verification. In Proceedings of the 15th Conference on USENIX Security Symposium - Volume 15, Berkeley, CA, USA, 2006. USENIX Association.
[28] M. Sharif, A. Lanzi, J. Griffin, and W. Lee. Impeding malware analysis using conditional code obfuscation. In Proceedings of the 15th Annual Network and Distributed System Security Symposium, San Diego, CA, February 2008.
[29] T. Shields and C. Wysopal. Detecting Certified Pre-owned Software. In BlackHat-Europe, 2009.
[30] C. Sturton, S. Jha, S. A. Seshia, and D. Wagner. On voting machine design for verification and testability. In Proceedings of the 16th ACM Conference on Computer and Communications Security, CCS '09, pages 463–476, New York, NY, USA, 2009. ACM.
[31] C. Sturton, D. Wagner, and S. T. King. Defeating UCI: Building Stealthy and Malicious Hardware. In 32nd IEEE Symposium on Security and Privacy, 2011.
[32] K. Thompson. Reflections on trusting trust. Communications of the ACM, 27(8):761–763, 1984.
[33] A. Waksman. Silencing Hardware Backdoors. In 32nd IEEE Symposium on Security and Privacy, 2011.
[34] A. Waksman and S. Sethumadhavan. Tamper Evident Microprocessors. In IEEE Symposium on Security and Privacy, pages 173–188, 2010.
[35] D. A. Wheeler. Countering Trusting Trust through Diverse Double-Compiling. In 21st Annual Computer Security Applications Conference, Tucson, Arizona, 2005.
[36] J. Wilhelm and T. cker Chiueh. A forced sampled execution approach to kernel rootkit identification. In 10th International Symposium on Recent Advances in Intrusion Detection (RAID'07), pages 219–235, 2007.
[37] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar. Native Client: A Sandbox for Portable, Untrusted x86 Native Code. In 30th IEEE Symposium on Security and Privacy, pages 79–93, 2009.
[38] A. Young and M. Yung. Cryptovirology: Extortion-based security threats and countermeasures. In SP '96: Proceedings of the 1996 IEEE Symposium on Security and Privacy, page 129, Washington, DC, USA, 1996. IEEE Computer Society.
[39] Y. Zhang and V. Paxson. Detecting backdoors. In Proceedings of the 9th Conference on USENIX Security Symposium - Volume 9, page 12, Denver, Colorado, 2000. USENIX Association.

### Appendix
**Theorem 1 (Usability of Backdoors in Our Framework)**: Given any RCA implemented in our framework, suppose its computation function is \( f() \) whose collision probability is \( P_{\text{max}}^{\text{col}} \). Then, any T2b-backdoor attacker can only log in successfully with a probability not greater than the collision probability, i.e., \( P_{\text{backdoor}} \leq P_{\text{max}}^{\text{col}} \).

**Proof**: Assume there is a backdoor \((S_0, P_{\text{backdoor}})\) in the RCA implemented in our framework such that \( P_{\text{backdoor}} > P_{\text{max}}^{\text{col}} \). This means there is a client-side response generation schema \( S_0 \) such that the generated response matches the expected response with a probability higher than \( P_{\text{max}}^{\text{col}} \).

Specifically, the backdoor attacker can choose a special (or any) \( id_0 \) and wait for a special (or any) \( cha_0 \), then send back \( S_0(id_0, cha_0) \) to the server for further comparison. The server-side comparison passes with a probability higher than \( P_{\text{max}}^{\text{col}} \). In other words, the following statement holds:
\[ P_{\text{backdoor}} = P(S_0(id_0, cha_0) == f(pw, cha_0)) > P_{\text{max}}^{\text{col}} \]
for a certain \( S_0, id_0, \) and \( cha_0 \).

On the other hand, for any response generation schema \( S' \) used by the attacker, for any \( id' \) and \( cha' \):
\[ P(S'(id', cha') == f(pw, cha')) \leq P_{\text{max}}^{\text{col}} \]

Thus, the assumption that \( P_{\text{backdoor}} > P_{\text{max}}^{\text{col}} \) leads to a contradiction. Therefore, the assumption is false, and there is no backdoor such that \( P_{\text{backdoor}} > P_{\text{max}}^{\text{col}} \). Hence, the theorem is correct.