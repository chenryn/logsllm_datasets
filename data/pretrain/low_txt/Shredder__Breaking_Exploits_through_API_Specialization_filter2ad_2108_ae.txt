### Leveraging Recent Processor Features for Exploit Mitigation

Recent processors have introduced the Last Branch Record (LBR) feature, which can be utilized to inspect the sequence of indirect branch instructions leading to an intercepted API function call. Similarly, ROPGuard [29] performs a variety of checks, such as validating whether the return address points to a call-preceded instruction and ensuring that the stack pointer remains within the boundaries of the actual stack. Many of ROPGuard’s checks have been integrated into Microsoft’s Enhanced Mitigation Experience Toolkit (EMET) [49], which also implements various exploit mitigation technologies by intercepting critical API calls.

### Historical Approaches to Windows System Protection

Several years before EMET, the security community employed similar approaches to protect Windows systems by enforcing policies or implementing detection heuristics at the system API level. For example, WHIPS [8] is a host-based intrusion detection system (HIDS) for Windows 2000/XP/2003 that enforces rules stored in an access control database by intercepting Native API calls. The creation of these enforced rules, which can be done manually or automatically, is not addressed in the work. Anderson et al. [4] implemented a host-based code injection attack detector using Detours to intercept and inspect network inputs for an excessive number of NOP instructions, which often precede shellcode.

### Early Linux-Based Protections

Similar systems were prototyped for Linux even earlier. For instance, REMUS [10] implements a reference monitor for system call invocations as a loadable Linux kernel module. Libsafe and Libverify [7] aim to transparently prevent buffer overflow exploits by enforcing buffer sizes and verifying return addresses on the stack through library interposition. Other systems rely on system call interposition to enforce blacklisting or whitelisting policies [31, 33, 56]. Numerous works over more than two decades have proposed systems that use system call interposition for intrusion defense through anomaly detection [11, 27, 28, 37, 46, 62, 71, 74].

### Code Surface Reduction Techniques

Several works have explored the concept of "slimming down" the code surface of applications by removing unnecessary code. This strategy aims to reduce the threat of exploitation by eliminating vulnerabilities in unused code and making exploit construction harder, especially for code reuse, by reducing the potential functions or ROP gadgets available to an attacker.

One such approach is software winnowing [48], which specializes the code of applications and libraries. The authors implemented a code specialization tool called OCCAM (Object Culling and Concretization for Assurance Maximization) on top of LLVM. OCCAM supports both intra-module and inter-module winnowing and can perform sophisticated code specialization by considering all program dependencies. Another approach, Piecewise Debloating [58], debloats libraries and main executables. At compilation and link time, the framework collects accurate control flow graph information, which is embedded into the resulting binaries. At runtime, this information is used to load only the relevant portions of code into memory, replacing unused portions with illegal instructions to shrink the attack surface.

Shredder employs some similar ideas but operates transparently on closed-source applications, which limits the types of program analysis it can use. It is complementary to the above approaches by further debloating the remaining code and focusing on system API libraries rather than a program's own modules.

### Kernel-Level Code Surface Reduction

Similar code surface reduction approaches have been proposed for the Linux kernel, whose multi-purpose nature makes the underlying code base immense. Kurmus et al. [38] implemented kRazor, a system that limits the amount of kernel code accessible to an application. In a training phase, the system uses dynamic instrumentation to collect the set of used functions under certain workloads. In the enforcement phase, it restricts usage to that set of functions. Similar methods have been employed by other systems [39, 40, 68] to create custom minimized kernels for specific workloads, achieving a code surface reduction of 50–85%. While these systems create single-purpose kernels, Face-Change [34] uses multiple minimized kernels, one tailored to each application, which are swapped upon context switch.

### Conclusion

Motivated by the concept of attack surface reduction and the need for practical, composable defense-in-depth mitigations, we present Shredder, an exploit mitigation tool for Windows programs. Shredder uses API specialization to restrict the interface of critical system API functions according to the actual needs of the protected program, neutralizing parts of their functionality crucial for malicious code. Our experimental evaluations show that Shredder offers a significant improvement over code stripping [50], blocking 18.3% more shellcode and 298% more ROP code samples while incurring negligible runtime overhead.

### Acknowledgments

We would like to thank Collin Mulliner, Azzedine Benameur, and the anonymous reviewers for their valuable feedback. This work was supported by the Office of Naval Research (ONR) through award N00014-17-1-2891, the National Science Foundation (NSF) through award CNS-1749895, and the Defense Advanced Research Projects Agency (DARPA) through award D18AP00045, with additional support from Accenture. Any opinions, findings, and conclusions or recommendations expressed herein are those of the authors and do not necessarily reflect the views of the ONR, NSF, DARPA, or Accenture.

### References

[1] McSema: Framework for lifting x86, amd64, and aarch64 program binaries to LLVM bitcode. (2017). https://github.com/trailofbits/mcsema.

[2] Abadi, M., Budiu, M., Erlingsson, Ú., & Ligatti, J. (2005). Control-flow integrity. In Proceedings of the 12th ACM conference on Computer and Communications Security (CCS), 340–353.

[3] Abramov, A. (2015). Manually Enumerating Process Modules. http://www.codereversing.com/blog/archives/265.

[4] Andersson, S., Clark, A., Mohay, G., Schatz, B., & Zimmermann, J. (2005). A framework for detecting network-based code injection attacks targeting Windows and UNIX. In Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC).

[5] Andriesse, D., Chen, X., van der Veen, V., Slowinska, A., & Bos, H. (2016). An In-Depth Analysis of Disassembly on Full-Scale x86/x64 Binaries. In Proceedings of the 25rd USENIX Security Symposium, 583–600.

[6] Backes, M., Holz, T., Kollenda, B., Koppe, P., Nürnberger, S., & Pewny, J. (2014). You Can Run but You Can’t Read: Preventing Disclosure Exploits in Executable Code. In Proceedings of the 21st ACM Conference on Computer and Communications Security (CCS), 1342–1353.

[7] Baratloo, A., Singh, N., & Tsai, T. (2000). Transparent Run-Time Defense Against Stack Smashing Attacks. In Proceedings of the USENIX Annual Technical Conference.

[8] Battistoni, R., Gabrielli, E., & Mancini, L. V. (2004). A Host Intrusion Prevention System for Windows Operating Systems. In Proceedings of the 9th European Symposium on Research in Computer Security (ESORICS), 352–368.

[9] Bennett, J., Lin, Y., & Haq, T. (2013). The Number of the Beast. http://blog.freeeye.com/research/2013/02/the-number-of-the-beast.html.

[10] Bernaschi, M., Gabrielli, E., & Mancini, L. V. (2002). Remus: A Security-enhanced Operating System. ACM Trans. Inf. Syst. Secur. 5, 1 (Feb. 2002), 36–61.

[11] Bhatkar, S., Chaturvedi, A., & Sekar, R. (2006). Dataflow anomaly detection. In Proceedings of the IEEE Symposium on Security & Privacy.

[12] Bosman, E., & Bos, H. (2014). Framing Signals - A Return to Portable Shellcode. In IEEE Symposium on Security and Privacy, 243–258.

[13] Braden, K., Crane, S., Davi, L., Franz, M., Larsen, P., Liebchen, C., & Sadeghi, A.-R. (2016). Leakage-Resilient Layout Randomization for Mobile Devices. In Proceedings of the Network and Distributed System Security Symposium (NDSS).

[14] Burow, N., Carr, S. A., Nash, J., Larsen, P., Franz, M., Brunthaler, S., & Payer, M. (2017). Control-Flow Integrity: Precision, Security, and Performance. ACM Comput. Surv. 50, 1, Article 16 (April 2017), 33 pages. https://doi.org/10.1145/3054924

[15] Carlini, N., Barresi, A., Payer, M., Wagner, D., & Gross, T. R. (2015). Control-Flow Bending: On the Effectiveness of Control-Flow Integrity. In Proceedings of the 24th USENIX Security Symposium, 161–176.

[16] Chen, P., Xiao, H., Shen, X., Yin, X., Mao, B., & Xie, L. (2009). DROP: Detecting Return-Oriented Programming Malicious Code. In Proceedings of the 5th International Conference on Information Systems Security (ICISS), 163–177.

[17] Chen, S., Xu, J., Sezer, E. C., Gauriar, P., & Iyer, R. K. (2005). Non-Control-Data Attacks Are Realistic Threats. In Proceedings of the 14th USENIX Security Symposium.

[18] Chen, Y., Zhang, D., Wang, R., Qiao, R., Azab, A. M., Lu, L., Vijayakumar, H., & Shen, W. (2017). NORAX: Enabling Execute-Only Memory for COTS Binaries on AArch64. In Proceedings of the 38th IEEE Symposium on Security & Privacy (S&P).

[19] Cheng, Y., Zhou, Z., Yu, M., Ding, X., & Deng, R. H. (2014). ROPecker: A Generic and Practical Approach For Defending Against ROP Attacks.

[20] Crane, S., Liebchen, C., Homescu, A., Davi, L., Larsen, P., Sadeghi, A.-R., Brunthaler, S., & Franz, M. (2015). Readactor: Practical Code Randomization Resilient to Memory Disclosure. In Proceedings of the 36th IEEE Symposium on Security and Privacy (S&P).

[21] Davi, L., Liebchen, C., Sadeghi, A.-R., Snow, K. Z., & Monrose, F. (2015). Isomeron: Code Randomization Resilient to (Just-In-Time) Return-Oriented Programming. In Proceedings of the Network and Distributed System Security Symposium (NDSS).

[22] Davi, L., Sadeghi, A.-R., & Winandy, M. (2009). Dynamic integrity measurement and attestation: towards defense against return-oriented programming attacks. In Proceedings of the 2009 ACM workshop on Scalable Trusted Computing (STC), 49–54.

[23] Davi, L., Sadeghi, A.-R., & Winandy, M. (2011). ROPdefender: A Detection Tool to Defend Against Return-oriented Programming Attacks. In Proceedings of the 6th ACM ASIACCS, 40–51.

[24] Solar Designer. (1997). Getting around non-executable stack (and fix). http://seclists.org/bugtraq/1997/Aug/63.

[41] Kuznetsov, V., Szekeres, L., Payer, M., Candea, G., Sekar, R., & Song, D. (2014). Code-pointer Integrity. In Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation (OSDI), 147–163.

[42] MWR Labs. (2013). MWR Labs Pwn2Own 2013 Write-up - Webkit Exploit. https://labs.mwrinfosecurity.com/blog/mwr-labs-pwn2own-2013-write-up-webkit-exploit/.

[43] Lamb, A. (2017). The Chakra Exploit And The Limitations Of Modern Cyber Security Threat Mitigation Techniques. https://www.endgame.com/blog/technical-blog/chakra-exploit-and-limitations-modern-mitigation-techniques.

[44] Larsen, P., Homescu, A., Brunthaler, S., & Franz, M. (2014). SoK: Automated Software Diversity. In Proceedings of the 35th IEEE Symposium on Security & Privacy, 276–291.

[45] Li, J., Wang, Z., Jiang, X., Grace, M., & Bahram, S. (2010). Defeating return-oriented rootkits with “Return-Less” kernels. In Proceedings of the 5th European conference on Computer Systems (EuroSys), 195–208.

[46] Li, P., Park, H., Gao, D., & Fu, J. (2008). Bridging the Gap between Data-Flow and Control-Flow Analysis for Anomaly Detection. In Proceedings of the Annual Computer Security Applications Conference (ACSAC), 392–401.

[47] Russinovich, M., Solomon, D. A., & Ionescu, A. (2012). Windows Internals.

[48] Malecha, G., Gehani, A., & Shankar, N. (2015). Automated Software Winnowing. In Proceedings of the 30th Annual ACM Symposium on Applied Computing (SAC ’15), 1504–1511.

[49] Microsoft. (n.d.). Enhanced Mitigation Experience Toolkit. http://www.microsoft.com/emet.

[50] Mulliner, C., & Neugschwandtner, M. (2015). Breaking Payloads with Runtime Code Stripping and Image Freezing. Black Hat USA.

[25] Dullien, T. (2018). Security, Moore’s law, and the anomaly of cheap complexity. CyCon.

[26] Evans, I., Long, F., Otgonbaatar, U., Shrobe, H., Rinard, M., Okhravi, H., & Sidiroglou-Douskos, S. (2015). Control Jujutsu: On the Weaknesses of Fine-Grained Control Flow Integrity. In Proceedings of the 22nd ACM Conference on Computer and Communications Security (CCS), 901–913.

[27] Feng, H. H., Kolesnikov, O. M., Fogla, P., Lee, W., & Gong, W. (2003). Anomaly detection using call stack information. In Proceedings of the IEEE Symposium on Security & Privacy, 62–75.

[28] Forrest, S., Hofmeyr, S. A., Somayaji, A., & Longsta, T. A. (1996). A Sense of Self for Unix Processes. In Proceedings of the IEEE Symposium on Security & Privacy.

[29] Fratric, I. (2012). ROPGuard: Runtime Prevention of Return-Oriented Programming Attacks. http://www.ieee.hr/_download/repository/Ivan_Fratric.pdf/.

[30] Hunt, G., & Brubacher, D. (1999). Detours: Binary Interception of Win32 Functions. https://www.cs.columbia.edu/~junfeng/10fa-e6998/papers/detours.pdf.

[31] Garfinkel, T. (2003). Traps and Pitfalls: Practical Problems in System Call Interposition Based Security Tools. In Proceedings of the Network and Distributed System Security Symposium (NDSS).

[32] Gionta, J., Enck, W., & Ning, P. (2015). HideM: Protecting the Contents of Userspace Memory in the Face of Disclosure Vulnerabilities. In Proceedings of the 5th ACM Conference on Data and Application Security and Privacy (CODASPY), 325–336.

[33] Goldberg, I., Wagner, D., Thomas, R., & Brewer, E. A. (1996). A Secure Environment for Untrusted Helper Applications Confining the Wily Hacker. In Proceedings of the 6th USENIX Security Symposium.

[34] Gu, Z., Saltaformaggio, B., Zhang, X., & Xu, D. (2014). FACE-CHANGE: Application-Driven Dynamic Kernel View Switching in a Virtual Machine. In 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), 491–502.

[35] Hiser, J., Nguyen-Tuong, A., Co, M., Hall, M., & Davidson, J. W. (2012). ILR: Where’d My Gadgets Go?. In Proceedings of the 33rd IEEE Symposium on Security & Privacy (S&P), 571–585.

[36] Krahmer, S. (2005). x86-64 buffer overflow exploits and the borrowed code chunks exploitation technique. http://www.suse.de/~krahmer/no-nx.pdf.

[37] Kruegel, C., Mutz, D., Valeur, F., & Vigna, G. (2003). On the Detection of Anomalous System Call Arguments. In Proceedings of the 8th European Symposium on Research in Computer Security (ESORICS), 326–343.

[38] Kurmus, A., Dechand, S., & Kapitza, R. (2014). Quantifiable Run-Time Kernel Attack Surface Reduction. In Proceedings of the 11th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA), 212–234.

[39] Kurmus, A., Sorniotti, A., & Kapitza, R. (2011). Attack Surface Reduction for Commodity OS Kernels: Trimmed Garden Plants May Attract Less Bugs. In Proceedings of the 4th European Workshop on System Security (EuroSec).

[40] Kurmus, A., Tartler, R., Dorneanu, D., Heinloth, B., Rothberg, V., Ruprecht, A., Schröder-Preikschat, W., Lohmann, D., & Kapitza, R. (2013). Attack Surface Metrics and Automated Compile-Time OS Kernel Tailoring. In Proceedings of the Network and Distributed System Security Symposium (NDSS).

[51] Nergal. (2001). The advanced return-into-lib(c) exploits: PaX case study. Phrack 11, 58 (Dec. 2001).

[52] Newsham, T. (2000). Non-exec stack. http://seclists.org/bugtraq/2000/May/90.

[53] Onarlioglu, K., Bilge, L., Lanzi, A., Balzarotti, D., & Kirda, E. (2010). G-Free: defeating return-oriented programming through gadget-less binaries. In Proceedings of the 26th Annual Computer Security Applications Conference (ACSAC), 49–58.

[54] Pappas, V., Polychronakis, M., & Keromytis, A. D. (2012). Smashing the gadgets: Hindering return-oriented programming using in-place code randomization. In Proceedings of the 2012 IEEE Symposium on Security and Privacy, 601–615.

[55] Pappas, V., Polychronakis, M., & Keromytis, A. D. (2013). Transparent ROP Exploit Mitigation using Indirect Branch Tracing. In Proceedings of the 22nd USENIX Security Symposium, 447–462.

[56] Payer, M., & Gross, T. R. (2011). Fine-grained User-space Security Through Virtualization. In Proceedings of the 7th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments (VEE), 157–168.

[57] Pomonis, M., Petsios, T., Keromytis, A. D., Polychronakis, M., & Kemerlis, V. P. (2017). kR^X: Comprehensive Kernel Protection against Just-In-Time Code Reuse. In Proceedings of the 12th European conference on Computer Systems (EuroSys), 420–436.

[58] Quach, A., Prakash, A., & Yan, L. K. (2018). Debloating Software through Piece-Wise Compilation and Loading. In Proceedings of the 27th USENIX Security Symposium.

[59] Rudd, R., Skowyra, R., Bigelow, D., Dedhia, V., Hobson, T., Liebchen, C., Crane, S., Larsen, P., Davi, L., Franz, M., Sadeghi, A.-R., & Okhravi, H. (2017). Address-Oblivious Code Reuse: On the Effectiveness of Leakage Resilient Diversity. In Proceedings of the Network and Distributed System Security Symposium (NDSS).

[60] Russinovich, M. (Nov. 2006). Inside Native Applications. http://technet.microsoft.com/en-us/sysinternals/bb897447.aspx.

[61] Schuster, F., Tendyck, T., Liebchen, C., Davi, L., Sadeghi, A.-R., & Holz, T. (2015). Counterfeit Object-oriented Programming: On the Difficulty of Preventing Code Reuse Attacks in C++ Applications. In Proceedings of the 36th IEEE Symposium on Security & Privacy (S&P), 745–762.

[62] Sekar, R., Bendre, M., Dhurjati, D., & Bollineni, P. (2001). A fast automaton-based method for detecting anomalous program behaviors. In Proceedings of the IEEE Symposium on Security & Privacy, 144–155.

[63] Shacham, H. (2007). The geometry of innocent flesh on the bone: return-into-libc without function calls (on the x86). In Proceedings of the 14th ACM conference on Computer and Communications Security (CCS), 552–561.

[64] Skape. (2003). Understanding Windows Shellcode. http://www.hick.org/code/skape/papers/win32-shellcode.pdf.

[65] Snow, K. Z., Davi, L., Dmitrienko, A., Liebchen, C., Monrose, F., & Sadeghi, A.-R. (2013). Just-In-Time Code Reuse: On the Effectiveness of Fine-Grained Address Space Layout Randomization. In Proceedings of the 34th IEEE Symposium on Security & Privacy (S&P), 574–588.

[66] Snow, K. Z., Rogowski, R., Werner, J., Koo, H., Monrose, F., & Polychronakis, M. (2016). Return to the Zombie Gadgets: Undermining Destructive Code Reads via Code Inference Attacks. In Proceedings of the 37th IEEE Symposium on Security & Privacy (S&P), 954–968.

[67] Tang, A., Sethumadhavan, S., & Stolfo, S. (2015). Heisenbyte: Thwarting Memory Disclosure Attacks Using Destructive Code Reads. In Proceedings of the 22nd ACM Conference on Computer and Communications Security (CCS), 1475–1486.