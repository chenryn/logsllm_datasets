# A Lustrum of Malware Network Communication: Evolution and Insights

**Authors:**
- Chaz Lever†
- Platon Kotzias∗
- Davide Balzarotti∓
- Juan Caballero∗
- Manos Antonakakis‡

**Contact Information:**
- {chazlever, manos}@gatech.edu
- PI:EMAIL
- {platon.kotzias, juan.caballero}@imdea.org

**Affiliations:**
- † Georgia Institute of Technology, School of Computer Science
- ‡ Georgia Institute of Technology, School of Electrical and Computer Engineering
- ∗ IMDEA Software Institute
- ∓ EURECOM

**Abstract:**
Both the operational and academic security communities have utilized dynamic analysis sandboxes to execute malware samples for approximately a decade. Network data derived from such analyses is frequently employed for threat detection, network policy enforcement, and incident response. Despite these common and critical use cases, the efficacy of network detection signals from dynamic analysis has not been thoroughly examined. This paper aims to address this gap by analyzing the network communications of 26.8 million samples collected over five years.

Using several malware and network datasets, our large-scale study makes three key contributions:
1. We demonstrate that dynamic analysis traces should be carefully curated and provide a rigorous methodology for analysts to remove potential noise from such traces.
2. We find that Internet miscreants are increasingly using potentially unwanted programs (PUPs) that rely on a surprisingly stable DNS and IP infrastructure. This suggests that the security community needs better protections against such threats, and network policies may offer a solid foundation for these protections.
3. Finally, we observe that for the vast majority of malware samples, network traffic provides the earliest indicator of infection—several weeks and often months before the malware sample is discovered. Therefore, network defenders should leverage automated malware analysis to extract indicators of compromise and build early detection systems.

## 1. Introduction

Malware analysis is at the forefront of combating Internet threats. Over the past decade, numerous systems have been developed to statically and dynamically analyze malicious software, producing detailed behavioral reports [52], [78]. The extensive data collected by these systems can provide crucial reputation information about both IP and domain name system (DNS) infrastructure, which play a vital role in state-of-the-art detection engines used by the security industry.

Despite the increasing availability of large malware databases, little is known about how the infrastructure and methods used by Internet miscreants have evolved over time. Previous studies [28], [54], [55], [71], [80], [81] often used small datasets and focused on specific topics, such as the role of cloud providers, the infrastructure behind drive-by downloads, or the domains used by a few malware families.

To shed light on this important issue, we present the results of a five-year, longitudinal study of dynamic analysis traces collected from multiple (i.e., two commercial and one academic) malware feeds. These feeds contain network information extracted from the execution of more than 26.8 million unique malware samples. We complement this dataset with over five billion DNS queries collected from a large North American internet service provider (ISP). The combination of these two sources provides a unique view into the network infrastructure that malware samples have contacted over the past five years.

Conducting this long-term analysis required us to develop a comprehensive filtering process to remove benign domains from our datasets. This process, described in detail in Section III, highlights the challenges of reducing the inevitable noise present in large datasets and provides a comprehensive list of steps that an analyst can follow to curate the domains obtained from malware dynamic analysis traces.

Our study also required us to perform the largest malware classification effort to date to classify malware samples into families, differentiate malware from Potentially Unwanted Programs (PUPs), and correlate domains with their most likely malware families. Our results show that the largest families, by number of samples, are largely dominated by PUPs, but traditional malware is responsible for the largest volume of domain resolutions. Our classification enables us to conduct the first study comparing the network properties of PUP and malware domains.

After performing rigorous filtering and classification, we proceed with a multi-phase analysis of the dataset. In the first phase, we examine the type, variability, and lifetime of malware domains. Our results suggest that the security community should be cautious in how it uses the results from dynamic malware analysis. For instance, we observed that malware is potentially ineffective as an early-detection trigger, as we often see network activity, in the form of valid resolutions of malware domains, months before the corresponding malware samples are discovered and dynamically analyzed. Specifically, we found that 302,953 malware domains were active at least two weeks, and in some cases many months, before the corresponding malware samples were analyzed. Thus, organizations that base their network defenses on DNS blacklists and dynamic malware analysis may be unaware of potential threats for significant periods of time.

In the second phase of our analysis, we study the evolution of the IP infrastructure resolved by malware and PUP domains over time and identify three interesting categories of "hot spots" in the IP space. These categories correspond to (1) IPs associated with large families that use the same network for extended periods, suggesting significant deficiencies in current network and system-level defenses; (2) IPs associated with sinkhole operations run by security organizations; and (3) IPs associated with hosting providers that are more willing to tolerate malicious infrastructures, resulting in frequent use by several families. We also analyze the roles of dynamic DNS (DDNS) and content delivery network (CDN) services, as they are both frequently used by malware, and show that approximately 32% of all malware samples in our dataset queried at least one dynamic DNS domain. Finally, we measure the prevalence of domains created by domain generation algorithms (DGAs) in network communication from malware samples and find that at least 44% of the domains from dynamic malware traces are generated by 42 DGA families.

In summary, our study makes the following core contributions:
1. While dynamic analysis traces can be used as ground truth and forensic evidence of an infection, they should be very carefully curated. We provide (Section III) a detailed and extensive set of rules that network defenders should follow when they wish to remove potentially benign domain names from their dynamic analysis traces.
2. We observe that PUPs are not only on the rise (Section IV) but also that they surprisingly utilize a very stable network IP infrastructure. Our analysis shows that PUP families host their infrastructure on popular cloud hosting providers and CDNs for up to several years. This may indicate that popular hosting providers do not have the same abuse policies towards banning PUPs that they use to fight malware.
3. Dynamic malware analysis traces are far from the ideal source of information for building early warning systems or detecting new emerging threats. In our analysis, we see that domain names used in malware communications are active weeks, sometimes even months, before malware gets discovered and analyzed by the security community (Section V-B2). This observation has a direct implication on malware domain name blacklists (Section V-A1). While they are certainly useful for detecting current and past malware families, they are not necessarily an efficient method of combating future malware threats. In fact, our long-term study shows (Figure 6) that malicious domains were added to major blacklists several days after the malware appeared in one of our feeds and months after the potentially malicious communication was seen in passive DNS.

Beyond these contributions, there are three main differentiators between this work and all previous research. First, we analyze several orders of magnitude more data than any prior research efforts, and we do so over a much longer observation period—almost five full years. This affords us unique insights into how tens of millions of malware samples have evolved over time. Next, we link network-level communications (e.g., domains and IPs) with system-oriented information (e.g., malware families, PUPs). Most existing work does not attempt to perform both these types of analysis in concert—let alone at this scale. Finally, we provide temporal analysis of malware communication over time. This gives us interesting insight into the relationship between the first observable network communication and discovery of malware by the community.

It is only fair to acknowledge that our work was possible because of the many prior efforts in the fields of malware and network analysis—the most notable of which we cite. The fact that our findings confirm the results of many past studies lends further weight to their results and serves to make them more generalizable. We believe the community needs a combination of both large-scale longitudinal studies and more focused small-scale studies. The former better captures global phenomena and general trends, while the latter enables more detailed investigations by allowing for manual analysis and deeper inspection of traffic.

## 2. Datasets

Table I summarizes the datasets used in this work. All data corresponds to the time period from January 1st, 2011, to August 31st, 2015, unless otherwise noted. We use three malware execution datasets to obtain the domains resolved by malware and the IP addresses they resolved to; a passive DNS dataset to map domains to IP addresses and obtain an estimation of their query volume; VirusTotal (VT) reports to obtain additional metadata for the executed malware; public blacklists to identify dates when malicious domains were blocked; the historical Alexa top 1M for whitelisting benign domains; domain expiration dates to mark end of ownership events; and the DGArchive [12] to identify DGA domains. Each of these datasets is described in more detail below.

In this paper, we focus on effective second-level domains (e2LDs) rather than fully qualified domain names (FQDNs) because e2LDs better capture domain ownership. For example, the FQDN www.google.com has e2LD google.com, while www.amazon.co.uk has e2LD amazon.co.uk, since the second-level domain co.uk does not correspond to the domain owner. Thus, unless otherwise noted, when we talk about domains, we refer to e2LDs and only use FQDNs for better differentiation when needed.

### 2.1 Malware Executions

We collected all the domain names resolved by malware samples from three different datasets—each containing the MD5 of the malware, date of execution in the sandbox, domain names resolved during the execution, and IP addresses that domains resolved to. Each malware sample ran for no more than five minutes in each of the different datasets.

We briefly describe the three datasets but will only refer to their union, after removing duplicate samples, throughout the rest of the paper:

- **University Dataset:** This dataset comes from a university-operated malware execution environment. Collected from January 2011 to August 2015.
- **Vendor Dataset:** This dataset comes from the malware execution environment of a large security vendor that tracks spam and email abuse. Collected from September 2014 to August 2015.
- **Anubis Dataset:** This dataset comes from the Anubis Web service [42], where users can upload suspicious samples for dynamic analysis. Anubis has operated since 2007, but we focus on executions between January 2011 and June 2014.

In total, we collected the network behavior of 26.8 million unique malware samples. It is important to note that this number excludes samples without any valid or successful DNS resolutions.

### 2.2 VirusTotal Reports (VT)

VirusTotal [17] is an online service that analyzes files and URLs submitted by users. Submitted executables are scanned with multiple antivirus (AV) engines. VT offers an API to query metadata on malware samples using a sample’s hash, and we queried VT using the 26.8 million hashes. For each sample, we collected the time it was first observed by VT, AV analysis date, and AV detection labels. Of the 26.8 million samples, 89% were known to VT at the time of our submission (i.e., during the period 2015-16).

### 2.3 Passive DNS (pDNS)

Due to agreements with the provider of this data, we cannot publicly disclose the exact source, but we can state that this dataset contains passive DNS data collected from a large ISP in the United States. It contains the domain names resolved by clients of the ISP and the IP addresses those domains resolved to. This data was collected above the recursive DNS server, and therefore, it does not contain information about the clients making requests—rather, it aggregates resolutions from all clients. The dataset contains resource records (i.e., timestamp, queried domain name, and associated RDATA [48], [49]), as well as domain lookup volumes aggregated on a daily basis. It comprises 2.9 million e2LDs resolving to 178.7 million IP addresses.

### 2.4 Public Blacklists (PBL)

This dataset contains 320,000 malicious e2LD entries extracted and aggregated from the eight public domain blacklists, detailed in Table II, which we regularly collected and updated for the entire duration of the project. Due to this aggregation, the dataset includes multiple types of abusive domains such as drive-by downloads, phishing, and botnet C&C. These domains are curated by members of the security community and, thus, represent cases of human-verified abuse. For each domain, the data also provides the exact date when the domain was included in the blacklist.

### 2.5 Alexa

This dataset contains rankings of the Alexa top million domains collected daily [2]. It contains approximately 8 million unique e2LDs across our entire analysis period.

### 2.6 Expired Domains

This dataset includes the expiration dates of 179 million (benign and malicious) e2LDs for the past seven years. These expirations were verified by recording removals from the Alexa top million list.