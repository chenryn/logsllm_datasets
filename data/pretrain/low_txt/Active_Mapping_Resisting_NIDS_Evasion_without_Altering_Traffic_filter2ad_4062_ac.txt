### Implementation and Integration

We have successfully implemented the network topology and service discovery, as well as the specific tests outlined in Section 3.2. To ensure that the Bro Network Intrusion Detection System (NIDS) [Pa98] correctly interprets traffic, we integrated Active Mapping profiles. This integration is feasible with any NIDS that supports TCP/IP stream reconstruction, as it includes all necessary decision points. The integration required only a few hundred lines of C++ code and was straightforward. The performance impact of these modifications is discussed in the following section.

### Experiments and Results

#### 5.1 Observed Active Mapping Profiles

We conducted a prototype Active Mapper scan at the Lawrence Berkeley National Laboratory. While the exact number of active hosts during the scan is unknown, it was estimated to be around 6,700 based on other scans. We obtained consistent, non-trivial data (identical results over three trials for attributes other than the hostname) for just over 4,800 hosts. Many of the IPs without results were in DHCP blocks, where hosts may not always be present. Additionally, many users employ host-based firewalls, which can prevent scanning. We are currently working on obtaining more precise data, noting that firewalls are likely to prevent the attacks the NIDS is designed to detect.

It is significant that we obtained results for virtually every machine with known OS data, suggesting that most other machines are either transient or sufficiently firewalled to prevent OS detection. Figure 4 presents Active Mapping profiles by operating system. Some tests did not yield results due to services being protected with TCP Wrappers. We expect this limitation can be overcome in practice by adding the mapping machine to the hosts' Access Control Lists (ACLs) as needed.

The observed diversity in policy, even with only five tests, is remarkable. Hosts with a given operating system version exhibited the same policies, but policies varied significantly between different versions of the same OS. Linux, in particular, showed numerous policy changes even during minor kernel revisions. Individual users can also alter policies by installing "hardening" or other patches. This diversity underscores the need to disambiguate traffic destined for each host based on its observed policy.

For 173 hosts, we were unable to obtain consistent results (defined as identical results for three trials). This is less surprising, as all but 29 of these were printers, routers, or scanners, and many of the remaining 29 had unknown operating systems. Furthermore, all but 36 of the 173 hosts provided consistent results for completed trials but had one or more incomplete trials, possibly due to congestion. In total, only 10 machines that were not special-purpose devices yielded conflicting results.

#### 5.2 Stability of Results

We performed a second mapping of the hosts at LBNL about five months after the initial study to assess the "churn rate," i.e., how many IP addresses had changed and whether profiles remained constant. Ideally, such an analysis would be conducted at smaller time scales.

In the original mapping, 4,882 hosts provided non-trivial, consistent results, while in the second mapping, 4,733 hosts did so. 1,122 IPs were present in the first set but not the second; 880 of these were in DHCP blocks. 973 IPs were in the second set but not the first; 669 were in DHCP blocks. The large fraction in DHCP blocks is important because the set of machines in these blocks may experience "IP churn" without "machine churn." It seems feasible to inform the NIDS about DHCP lease updates. We estimate "machine churn" in DHCP blocks by comparing the distributions of profiles among the DHCP machines. As shown in Figure 5, the distribution is relatively stable, suggesting that machine churn should be manageable.

#### 5.3 Performance Impact

The user time per host increased at a rate of slightly less than two seconds per host. Parallelism was limited, allowing steady-state rates of about five seconds per active host for a full-site mapping with thousands of hosts. We expect this figure could be improved with a better implementation.

#### 5.4 Mapping Traffic

We measured bidirectional network traffic generated during mapping. During a scan of a subnet with 101 live hosts, we recorded statistics (taken over three trials) related to the number of bytes and packets generated by scanning, both to and from the mapper. The results are presented in Figure 6. ICMP packets were due to ICMP service discovery, Path MTU (PMTU), and hop count determination, as well as some IP mappings. TCP packets were due to TCP service discovery, PMTU, and hop count determination (if ICMP was not supported), and TCP mappings.

#### 5.5 NIDS Integration Tests

We modified the Bro NIDS to support disambiguation based on Active Mapping profiles. Our choice of NIDS was for convenience, as our techniques apply equally to any TCP/IP-analyzing NIDS. Our testing goals were twofold: to ensure that using Active Mapping results in correct interpretation of network traffic and to check that it does not incur significant runtime costs. We ran two sets of tests: a synthetic test with ambiguous traffic and a comparison of the original and Active Mapping-modified NIDS on real-world traces. We expect the results to be substantially the same with any other NIDS integration.

### Figures

- **Figure 4:** Selected Observed Active Mapping Profiles
- **Figure 5:** Distribution of Profiles Among DHCP Machines
- **Figure 6:** Traffic Generated by Mapping 101 Hosts on a Single Subnet

### References

- Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP'03)
- 1081-6011/03 $17.00 Â© 2003 IEEE