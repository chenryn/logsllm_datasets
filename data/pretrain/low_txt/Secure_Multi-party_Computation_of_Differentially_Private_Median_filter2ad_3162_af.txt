### Distributed Differential Privacy with High Accuracy and Scalability

We present a protocol for distributed differential privacy that achieves high accuracy, even for small numbers of users, without the need for a trusted party. Our protocol is both efficiently computable (with practical running times) and scalable (sublinear in the size of the data universe). Specifically, our semi-honest multi-party protocol implements the exponential mechanism for decomposable aggregate functions, such as rank-based statistics, which are commonly used in MapReduce-style algorithms. The protocol can be extended to handle malicious parties.

For the median, the exponential mechanism provides the best utility-privacy trade-off for low ε values, as demonstrated in our evaluations of related work in the central model.

#### Protocol Optimization
Our protocol is optimized for decomposable functions, allowing efficient secure multi-party computation (MPC) on distributed data. We also use efficient alternatives to exponentiations for floating-point numbers, enhancing performance.

#### Implementation and Evaluation
We implemented our protocol using the SCALE-MAMBA framework [6] and evaluated it for 1 million users with 3 semi-honest computation parties. In a local area network (LAN), the running time was just a few seconds, while in a wide area network (WAN) with 100 ms latency and 100 Mbits/s bandwidth, the running time was approximately 3 minutes.

### Acknowledgments
This work was funded by the European Union’s Horizon 2020 research and innovation program under grant agreement No 825333 (MOSAICrOWN).

### References
[1] WWDC 2016. Engineering privacy for your users, 2016.
[2] John M. Abowd. The U.S. Census Bureau adopts differential privacy. In Proceedings of the annual ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD, 2018.
[3] Gagan Aggarwal, Nina Mishra, and Benny Pinkas. Secure computation of the median (and other elements of specified ranks). Journal of Cryptology, 2010.
[4] Dima Alhadidi, Noman Mohammed, Benjamin CM Fung, and Mourad Debbabi. Secure distributed framework for achieving ε-differential privacy. In International Symposium on Privacy Enhancing Technologies Symposium, PETS, 2012.
[5] Mehrdad Aliasgari, Marina Blanton, Yihua Zhang, and Aaron Steele. Secure computation on floating point numbers. NDSS, 2013.
[6] Abdelrahaman Aly, Marcel Keller, Dragos Rotaru, Peter Scholl, Nigel P. Smart, and Tim Wood. SCALE–MAMBA documentation. https://homes.esat.kuleuven.be/~nsmart/SCALE/, 2020.
[7] Abdelrahaman Aly and Nigel P Smart. Benchmarking privacy preserving scientific operations. In International Conference on Applied Cryptography and Network Security, ACNS, 2019.
[8] Amazon.com. Amazon Web Services. https://aws.amazon.com/ec2/pricing/on-demand/.
[9] Victor Balcer and Albert Cheu. Separating local & shuffled differential privacy via histograms, 2019.
[10] Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Efficient algorithms and tight error bounds. In Annual IEEE Symposium on Foundations of Computer Science, FOCS, 2014.
[11] Donald Beaver. Efficient multiparty protocols using circuit randomization. In Annual International Cryptology Conference, CRYPTO, 1991.
[12] Rikke Bendlin, Ivan Damgård, Claudio Orlandi, and Sarah Zakarias. Semi-homomorphic encryption and multiparty computation. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, EUROCRYPT, 2011.
[14] Jonas Böhler and Florian Kerschbaum. Secure sublinear time differentially private median computation. In Network and Distributed Systems Security Symposium, NDSS, 2020.
[15] Andrea Bittau, Ulfar Erlingsson, Petros Maniatis, Ilya Mironov, Ananth Raghunathan, David Lie, Mitch Rudominer, Ushasree Kode, Julien Tinnes, and Bernhard Seefeld. Prochlo: Strong privacy for analytics in the crowd. In Proceedings of the Symposium on Operating Systems Principles, SOSP, 2017.
[16] Jeremiah Blocki, Anupam Datta, and Joseph Bonneau. Differentially private password frequency lists. Network and Distributed Systems Security Symposium, NDSS, 2016.
[17] Octavian Catrina and Sebastiaan De Hoogh. Improved primitives for secure multiparty integer computation. In International Conference on Security and Cryptography for Networks, SCN, 2010.
[18] Albert Cheu, Adam Smith, Jonathan Ullman, David Zebber, and Maxim Zhilyaev. Distributed differential privacy via shuffling. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, EUROCRYPT, 2019.
[19] Amrita Roy Chowdhury, Chenghong Wang, Xi He, Ashwin Machanavajjhala, and Somesh Jha. Cryptε: Crypto-assisted differential privacy on untrusted servers. In Proceedings of the annual ACM SIGMOD International Conference on Management of data, SIGMOD, 2020.
[20] Ivan Damgård, Matthias Fitzi, Eike Kiltz, Jesper Buus Nielsen, and Tomas Toft. Unconditionally secure constant-rounds multi-party computation for equality, comparison, bits and exponentiation. In Theory of Cryptography Conference, TCC, 2006.
[21] Ivan Damgård, Valerio Pastro, Nigel Smart, and Sarah Zakarias. Multiparty computation from somewhat homomorphic encryption. In Annual International Cryptology Conference, CRYPTO, 2012.
[22] Jeffrey Dean and Sanjay Ghemawat. MapReduce: Simplified data processing on large clusters. Communications of the ACM, 2008.
[23] Bolin Ding, Janardhan Kulkarni, and Sergey Yekhanin. Collecting telemetry data privately. In Advances in Neural Information Processing Systems, NIPS, 2017.
[13] Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and Anima Anandkumar. signSGD: Compressed optimization for non-convex problems. arXiv preprint arXiv:1802.04434, 2018.
[24] John C Duchi, Michael I Jordan, and Martin J Wainwright. Local privacy and statistical minimax rates. In Annual IEEE Symposium on Foundations of Computer Science, FOCS, 2013.
[25] Cynthia Dwork. Differential privacy. In International Colloquium on Automata, Languages, and Programming, ICALP, 2006.
[26] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, EUROCRYPT, 2006.
[27] Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In Proceedings of the annual ACM symposium on Theory of Computing, STOC, 2009.
[28] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In Theory of Cryptography Conference, TCC, 2006.
[29] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical Computer Science, 2014.
[30] Fabienne Eigner, Aniket Kate, Matteo Maffei, Francesca Pampaloni, and Ivan Pryvalov. Differentially private data aggregation with optimal utility. In Proceedings of the Annual Computer Security Applications Conference, ACSAC, 2014.
[31] Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. RAPPOR: Randomized aggregatable privacy-preserving ordinal response. In Proceedings of the annual ACM conference on computer and communications security, CCS, 2014.
[32] David Evans, Vladimir Kolesnikov, Mike Rosulek, et al. A pragmatic introduction to secure multi-party computation. Foundations and Trends® in Privacy and Security, 2018.
[33] Centers for Medicare & Medicaid Services. Complete 2017 program year open payments dataset, 2017.
[34] Marco Gaboardi, Adam Smith, and Jinhui Xu. Empirical risk minimization in the non-interactive local model of differential privacy.
[35] Ivan Gazeau, Dale Miller, and Catuscia Palamidessi. Preserving differential privacy under finite precision semantics. In Theoretical Computer Science, TCS, 2016.
[36] Oded Goldreich. Foundations of Cryptography: Volume 2, Basic Applications. 2009.
[38] Slawomir Goryczka and Li Xiong. A comprehensive comparison of multiparty secure additions with differential privacy. IEEE transactions on Dependable and Secure Computing, 2017.
[39] Xi He, Ashwin Machanavajjhala, Cheryl Flynn, and Divesh Srivastava. Composing differential privacy and secure computation: A case study on scaling private record linkage. In Proceedings of the annual ACM conference on Computer and Communications Security, CCS, 2017.
[40] Justin Hsu, Sanjeev Khanna, and Aaron Roth. Distributed private heavy hitters. In International Colloquium on Automata, Languages, and Programming, ICALP, 2012.
[41] Christina Ilvento. Implementing the exponential mechanism with base-2 differential privacy, 2019.
[42] Kaggle.com. Walmart supply chain: Import and shipment. https://www.kaggle.com/sunilp/walmart-supply-chain-data/data, 2018. Retrieved: October, 2019.
[43] Liina Kamm. Privacy-preserving statistical analysis using secure multi-party computation. PhD thesis, University of Tartu, 2015.
[44] Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. What can we learn privately? SIAM Journal on Computing, 2011.
[45] Marcel Keller. MP-SPDZ: A versatile framework for multi-party computation. Cryptology ePrint Archive, Report 2020/521, 2020. https://eprint.iacr.org/2020/521.
[46] Marcel Keller, Valerio Pastro, and Dragos Rotaru. Overdrive: Making SPDZ great again. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, EUROCRYPT, 2018.
[47] Marcel Keller, Dragos Rotaru, Nigel P Smart, and Tim Wood. Reducing communication channels in MPC. In International Conference on Security and Cryptography for Networks, SCN, 2018.
[48] Ninghui Li, Min Lyu, Dong Su, and Weining Yang. Differential privacy: From theory to practice. Synthesis Lectures on Information Security, Privacy, & Trust, 2016.
[37] Oded Goldreich, Silvio Micali, and Avi Wigderson. How to play any mental game. In Proceedings of the annual ACM symposium on Theory of Computing, STOC, 1987.
[49] Yehuda Lindell and Benny Pinkas. A proof of security of Yao’s protocol for two-party computation. Journal of Cryptology, 2009.
[50] Andrew McGregor, Ilya Mironov, Toniann Pitassi, Omer Reingold, Kunal Talwar, and Salil Vadhan. The limits of two-party differential privacy. In Annual IEEE Symposium on Foundations of Computer Science, FOCS, 2010.
[51] Frank McSherry. Privacy integrated queries: An extensible platform for privacy-preserving data analysis. In Proceedings of the annual ACM SIGMOD International Conference on Management of data, SIGMOD, 2009.
[52] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In Annual IEEE Symposium on Foundations of Computer Science, FOCS, 2007.
[53] Ilya Mironov. On significance of the least significant bits for differential privacy. In Proceedings of the annual ACM conference on computer and communications security, CCS, 2012.
[62] Adi Shamir. How to share a secret. Communications of the ACM, 1979.
[63] Adam Smith, Abhradeep Thakurta, and Jalaj Upadhyay. Is interaction necessary for distributed private learning? In IEEE Symposium on Security and Privacy, SP, 2017.
[64] Gaurav Sood. California Public Salaries Data, 2018.
[65] Hassan Takabi, Samir Koppikar, and Saman Taghavi Zargar. Differentially private distributed data analysis. In IEEE International Conference on Collaboration and Internet Computing, CIC, 2016.
[66] Apple’s Differential Privacy Team. Learning with privacy at scale, 2017.
[67] Machine Learning Group ULB. Credit card fraud detection, 2018.
[54] Ilya Mironov, Omkant Pandey, Omer Reingold, and Salil Vadhan. Computational differential privacy. In Annual International Cryptology Conference, CRYPTO, 2009.
[68] Andrew Chi-Chih Yao. How to generate and exchange secrets. In Annual IEEE Symposium on Foundations of Computer Science, FOCS, 1986.
[55] Jack Murtagh and Salil Vadhan. The complexity of computing the optimal composition of differential privacy. In Theory of Cryptography Conference, TCC, 2016.
[56] Seth Neel, Aaron Roth, Giuseppe Vietri, and Zhiwei Steven Wu. Differentially private objective perturbation: Beyond smoothness and convexity, 2019.
[57] Jesper Buus Nielsen, Peter Sebastian Nordholt, Claudio Orlandi, and Sai Sheshank Burra. A new approach to practical active-secure two-party computation. In Annual International Cryptology Conference, CRYPTO, 2012.
[58] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. In Proceedings of the annual ACM symposium on Theory of Computing, STOC, 2007.
[59] Martin Pettai and Peeter Laud. Combining differential privacy and secure multiparty computation. In Proceedings of the Annual Computer Security Applications Conference, ACSAC, 2015.
[60] Vibhor Rastogi and Suman Nath. Differentially private aggregation of distributed time-series with transformation and encryption. In Proceedings of the annual ACM SIGMOD International Conference on Management of data, SIGMOD, 2010.
[61] Indrajit Roy, Srinath TV Setty, Ann Kilzer, Vitaly Shmatikov, and Emmett Witchel. Airavat: Security and privacy for MapReduce. In Proceedings of the annual ACM SIGMOD International Conference on Management of data, SIGMOD, 2010.

### Definition of Distributed Differential Privacy

The original definition of differential privacy considers the central model with unbounded adversaries [25, 28] (see Definition 1). Later work expanded this to a distributed setting [26, 44] and considered computationally-bounded parties [54].

In our setting, we consider multiple computationally-bounded, semi-honest parties performing a joint secure computation realized with (t, m)-secret sharing. The following definition from [30] fits our context:

**Definition 7 (Distributed Differential Privacy)**: A randomized protocol Π implemented among m computation parties \( P = \{P_1, \ldots, P_m\} \) achieves distributed differential privacy with respect to a coalition \( C \subset P \) of semi-honest computation parties of size t, if the following condition holds: for any neighboring datasets \( D \) and \( D' \) and any possible set S of views for protocol Π, the probability distributions of the views of the parties in C are indistinguishable up to a factor of \( e^\epsilon \).

Formally, for all \( C \subset P \) with \( |C| \leq t \),
\[ \Pr[\text{VIEW}_C^\Pi(D) \in S] \leq e^\epsilon \cdot \Pr[\text{VIEW}_C^\Pi(D') \in S] + \delta, \]
where \( \text{VIEW}_C^\Pi(D) \) denotes the view of the parties in C during the execution of protocol Π on input D, including all exchanged messages and internal state, and \( \lambda \) is a security parameter.