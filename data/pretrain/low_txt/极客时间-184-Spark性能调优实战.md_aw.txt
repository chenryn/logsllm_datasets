# Join Hints指南：不同场景下，如何选择Join策略？

你好，我是吴磊。在数据分析领域，数据关联是最常见的计算场景之一。由于其使用频率极高，Spark 提供了多种关联形式，包括 Inner Join、Left Join、Right Join、Anti Join 和 Semi Join 等。了解这些不同关联形式的区别和作用，可以帮助我们快速实现业务逻辑。然而，要提高数据关联场景下 Spark 应用的执行性能，关键在于深入理解 Join 的实现原理。

今天，我们将探讨单机环境中 Join 的几种实现方式及其优劣势，并结合这些知识讨论分布式计算环境中 Spark 支持的 Join 策略以及 Spark 如何进行选择。

## 单机环境中的 Join 实现方式

到目前为止，数据关联有三种主要的 Join 实现方式：嵌套循环连接（NLJ, Nested Loop Join）、排序归并连接（SMJ, Shuffle Sort Merge Join）和哈希连接（HJ, Hash Join）。接下来，我们将通过一个具体的数据关联场景来详细说明这三种 Join 实现方式的工作原理。

### 场景描述

假设我们有两个表：事实表 `orders` 和维度表 `users`。其中，`users` 表存储用户属性信息，`orders` 表记录用户的每一笔交易。两张表的 Schema 如下：

- **订单表 `orders` 关键字段**:
  - `userId`: Int
  - `itemId`: Int
  - `price`: Float
  - `quantity`: Int

- **用户表 `users` 关键字段**:
  - `id`: Int
  - `name`: String
  - `type`: String (枚举值，分为头部用户和长尾用户)

我们的任务是基于这两张表做内关联（Inner Join），并将用户名、单价、交易额等字段投影出来。具体的 SQL 查询语句如下：

```sql
SELECT orders.quantity, orders.price, orders.userId, users.id, users.name
FROM orders
INNER JOIN users ON orders.userId = users.id;
```

### 嵌套循环连接（NLJ）

对于参与关联的两张数据表，我们通常根据它们的角色进行区分。其中，体量较大且主动扫描数据的表称为外表或驱动表；体量较小且被动参与数据扫描的表称为内表或基表。

**NLJ 采用“嵌套循环”的方式实现关联**。具体来说，NLJ 使用内外两个嵌套的 for 循环依次扫描外表和内表中的数据记录，判断关联条件是否满足（如 `orders.userId = users.id`），如果满足则将两边的记录拼接在一起并输出。

![](https://static001.geekbang.org/resource/image/be/13/be0774ffca24f9c20caa2ef6bd88d013.jpg)

在这个过程中，外层的 for 循环负责遍历外表中的每一条数据，内层的 for 循环逐条扫描内表的所有记录，依次判断记录的 Join Key 是否满足关联条件。假设外表有 M 行数据，内表有 N 行数据，那么 **NLJ 算法的计算复杂度是 O(M * N)**。尽管 NLJ 实现方式简单直接，但其执行效率较低。

### 排序归并连接（SMJ）

由于 NLJ 的执行效率极低，后来有人提出了使用排序、归并算法来实现数据关联，即 SMJ。**SMJ 的思路是先排序、再归并**。具体来说，参与 Join 的两张表先分别按照 Join Key 进行升序排序，然后 SMJ 使用两个独立的游标对排好序的两张表完成归并关联。

![](https://static001.geekbang.org/resource/image/e2/b2/e2a8f8d1b2572ff456fa83a3f25ccbb2.jpg)

SMJ 初始时，内外表的游标都锚定在两张表的第一条记录上，然后对比游标所在记录的 Join Key。根据对比结果，操作分为以下三种情况：
1. 外表 Join Key 等于内表 Join Key，满足关联条件，拼接并输出数据，然后移动外表的游标。
2. 外表 Join Key 小于内表 Join Key，不满足关联条件，移动外表的游标。
3. 外表 Join Key 大于内表 Join Key，不满足关联条件，移动内表的游标。

SMJ 通过不断滑动游标，直到某张表的游标滑到头，宣告关联结束。对于 SMJ 中外表的每一条记录，由于内表按 Join Key 升序排序且扫描起始位置为游标所在位置，因此 **SMJ 算法的计算复杂度为 O(M + N)**。不过，SMJ 的计算复杂度降低依赖于两张表事先排好序，而排序本身是一项耗时的操作。

### 哈希连接（HJ）

考虑到 SMJ 对排序的要求较高，后来又有人提出了效率更高的 HJ。HJ 的设计初衷是**将内表扫描的计算复杂度降低至 O(1)**。只有哈希映射（Hash Map）能够实现这一点。因此，HJ 引入了哈希计算。

![](https://static001.geekbang.org/resource/image/5c/e4/5c81d814591eba9d08e6a3174ffe22e4.jpg)

HJ 的计算分为两个阶段：Build 阶段和 Probe 阶段。
1. **Build 阶段**：基于内表，使用既定的哈希函数构建哈希表。哈希表中的 Key 是 Join Key 经过哈希函数后的哈希值，Value 包含原始的 Join Key 和 Payload。
2. **Probe 阶段**：遍历每一条数据记录，使用相同的哈希函数动态计算 Join Key 的哈希值，然后查询 Build 阶段创建的哈希表。如果查询失败，说明该条记录与维度表中的数据不存在关联关系；如果查询成功，则继续对比两边的 Join Key。如果 Join Key 一致，拼接并输出数据，从而完成数据关联。

## 分布式环境下的 Join

掌握了单机环境中的三种主要数据关联实现方式后，在分布式计算环境中，数据关联依然遵循 NLJ、SMJ 和 HJ 这三种实现方式，只是增加了网络分发这一变数。在 Spark 的分布式计算环境中，数据在网络中的分发主要有两种方式：Shuffle 和广播。

### Shuffle 分发

如果采用 Shuffle 分发方式来完成数据关联，外表和内表都需要按照 Join Key 在集群中进行全量的数据分发。这样，两个数据表中 Join Key 相同的数据记录才能分配到同一个 Executor 进程，从而完成关联计算。

![](https://static001.geekbang.org/resource/image/b1/28/b1b2a574eb7ef33e2315f547ecdc0328.jpg)

### 广播分发

如果采用广播机制，情况会有所不同。在这种情况下，Spark 只需要将内表封装到广播变量并在全网进行分发。由于广播变量中包含了内表的全量数据，因此体量较大的外表只需“待在原地、保持不动”就能轻松完成关联计算。

![](https://static001.geekbang.org/resource/image/b3/2a/b3c5ab392c2303bf7923488623b4022a.jpg)

结合 Shuffle 和广播这两种网络分发方式，以及 NLJ、SMJ 和 HJ 这三种计算方式，我们可以组合出六种 Join 策略：

![](https://static001.geekbang.org/resource/image/e9/48/e9bf1720ac13289a9e49e0f33a334548.jpg)

这六种 Join 策略分别是 Cartesian Product Join、Shuffle Sort Merge Join 和 Shuffle Hash Join，以及 Broadcast Nested Loop Join、Broadcast Sort Merge Join 和 Broadcast Hash Join。从执行性能来看，六种策略从上到下由弱变强。CPJ 的执行效率最低，网络开销和计算开销都很大；BHJ 的执行效率最高，网络开销和计算开销最小。此外，Broadcast Sort Merge Join 被标记为灰色，因为 Spark 没有支持这种组合方式。

### Spark 如何选择 Join 策略

在不同的数据关联场景中，Spark 会基于特定逻辑选择 Join 策略。我们来分两种情况进行讨论：等值 Join 和不等值 Join。

#### 等值 Join

等值 Join 是指两张表的 Join Key 通过等值条件连接在一起。在等值数据关联中，Spark 会尝试按照 BHJ > SMJ > SHJ 的顺序依次选择 Join 策略。在这三种策略中，执行效率最高的是 BHJ，其次是 SHJ，再次是 SMJ。其中，SMJ 和 SHJ 策略支持所有连接类型，如全连接、Anti Join 等。

BHJ 尽管效率最高，但有两个前提条件：一是连接类型不能是全连接（Full Outer Join）；二是基表要足够小，可以放到广播变量中。SHJ 比 SMJ 执行效率高，但由于 SHJ 的实现方式更不稳定，更容易发生内存溢出（OOM），因此 Spark 优先选择 SMJ。

#### 不等值 Join

不等值 Join 是指两张表的 Join Key 通过不等值条件连接在一起。在不等值 Join 中，Spark 会尝试按照 BNLJ > SMJ > CPJ 的顺序进行尝试。BNLJ 生效的前提是内表小到可以放进广播变量。如果这个条件不成立，Spark 只能使用笨重的 CPJ 策略去完成关联计算。

### 开发者能做些什么？

通过上述分析，我们可以发现 Spark SQL 对这些策略的取舍基于一些既定规则。当面对多样且变化无常的计算场景时，预置的规则可能难以覆盖所有情况。因此，当我们掌握了不同 Join 策略的工作原理，并结合对业务和数据的深刻理解，完全可以自行决定应该选择哪种 Join 策略。

在最新发布的 Spark 3.0 版本中，Spark 为开发者提供了多样化的 Join Hints，允许你将专家经验凌驾于 Spark SQL 的选择逻辑之上。在满足前提条件的情况下（如等值条件、连接类型、表大小等），Spark 会优先尊重开发者的意愿，选取开发者通过 Join Hints 指定的 Join 策略。

关于 Spark 3.0 支持的 Join Hints 关键字及其适用场景，你可以参考以下表格：

![](https://static001.geekbang.org/resource/image/94/b8/9436f0f9352ffa381b238be57d2ecdb8.jpeg)

你可以通过 SQL 结构化查询语句或 DataFrame 的 DSL 语言指定 Join Hints，非常方便。更多详细讲解，请参阅第 13 讲。

## 小结

通过本讲的学习，我们从数据关联的实现原理到 Spark SQL 不同 Join 策略的适用场景进行了全面介绍。掌握这些关键知识点对于数据关联场景中的性能调优至关重要。首先，你需要掌握三种 Join 实现机制的工作原理，以便更好地理解 Spark SQL 的 Join 策略。结合数据的网络分发方式（Shuffle 和广播），Spark SQL 支持五种 Join 策略，按执行效率排序为 BHJ > SHJ > SMJ > BNLJ > CPJ。

当你掌握了不同 Join 策略的工作原理，并结合对业务和数据的深刻理解，实际上你可以自行决定应选择哪种 Join 策略，而不必完全依赖 Spark SQL 的判断。Spark 为开发者提供了多样化的 Join Hints，允许你将专家经验凌驾于 Spark SQL 的选择逻辑之上。

## 每日一练

1. 如果关联的场景是事实表 Join 事实表，你觉得我们今天讲的 Sort Merge Join 实现方式还适用吗？如果让你来设计算法的实现步骤，你会怎么做？
2. 你觉得，不等值 Join 可以强行用 Sort Merge Join 和 Hash Join 两种机制来实现吗？为什么？

期待在留言区看到你的思考和答案，我们下一讲见！