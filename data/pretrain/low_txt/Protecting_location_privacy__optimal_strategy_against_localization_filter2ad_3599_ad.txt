# Location Privacy and Optimal Obfuscation

## 5. Service-Quality Threshold and Location Privacy

### 5.1. Analysis of Different Combinations
The service-quality threshold \( Q_{\text{max}}^{\text{loss}} \) is compared with the location privacy \( P_{\text{rivacy}}(\psi, f, h, d_p) \) for a single user. The different lines in Figure 5 represent combinations of optimal (◦) and basic obfuscation (•) LPPMs tested against optimal (---) and Bayesian-inference (- - -) attacks. The service-quality threshold \( Q_{\text{max}}^{\text{loss}} \) is equal to the service quality obtained by the basic obfuscation LPPM when the number of obfuscation levels used to perturb the location varies from 1 to 30 (its maximum value).

- **(Optimal, Optimal)**: This combination represents a stable equilibrium where both the LPPM and the attack are optimal.
- **(Obfuscation, Bayesian)**: For small quality thresholds \( Q_{\text{max}}^{\text{loss}} \) (or smaller obfuscation levels), the user's privacy is lower compared to the (Optimal, Optimal) case. However, at some middle point, the provided privacy increases and surpasses the privacy obtained from the optimal methods. When the obfuscation level (or the service-quality threshold) increases, the basic obfuscation LPPM performs better because it is no longer severely limited and is paired against the weaker Bayesian inference attack.

### 5.2. Graphical Representation
- **Figure 5(a)**: Euclidean \( d_q(.) \) and Euclidean \( d_p(.) \)
- **Figure 5(c)**: Euclidean \( d_q(.) \) and Hamming \( d_p(.) \)
- **Figure 5(d)**: Hamming \( d_q(.) \) and Hamming \( d_p(.) \)

## 6. Related Work

### 6.1. Categories of Research
The field of location privacy has been an active area of research, with work generally falling into three categories:
1. **Design of LPPMs**: Methods to protect location privacy.
2. **Recovery of User Trajectories**: Techniques to recover actual user trajectories from anonymized or perturbed traces.
3. **Formal Analysis and Metrics**: Development of appropriate metrics to compare LPPMs.

### 6.2. Existing LPPMs
- **Space- or Time-Obfuscation**: Sending obfuscated versions of users' locations [10, 12, 14, 16].
- **Mix Zones and Silent Periods**: Hiding users' locations by using mix zones [1, 9] or silent periods [15].
- **Dummy Requests**: Adding indistinguishable fake requests to increase uncertainty [3].

### 6.3. Predictability and Re-identification
Several studies have shown that the predictability of users' location traces can be exploited to re-identify or reconstruct their movements [19, 5, 13, 11, 18].

### 6.4. Formalization and Metrics
- **Krumm [18]**, **Decker [6]**, and **Duckham [7]**: Efforts to formalize location privacy requirements.
- **Shokri et al. [24, 25, 26]**: Evaluated existing LPPMs and metrics, concluding that entropy and k-anonymity are not suitable for measuring location privacy. They provided a framework to quantify location privacy.

### 6.5. Disconnection in Research
Despite extensive research, there is a disconnection between different lines of work, hindering the comparison of systems and slowing down the design of robust LPPMs. Some works do not consider adversarial knowledge in their evaluations, while others, such as Freudiger et al. [9] and Shokri et al. [24, 25, 26], do consider strategic adversaries.

### 6.6. Game-Theoretic Approaches
- **Bayesian Stackelberg Games**: Used in security and privacy, where the defender (LPPM) commits to a strategy, and the adversary (attacker) responds optimally [23, 20, 2, 17, 21].
- **Our Contribution**: We use Bayesian Stackelberg games to design optimal privacy-protection mechanisms, ensuring that the LPPM is designed to anticipate strong inference attacks.

## 7. Conclusion

Accessing location-based services from mobile devices poses a privacy risk. Our game-theoretic framework enables the design of optimal LPPMs, ensuring satisfactory service quality and robust privacy protection. We validate our method using real location traces and demonstrate its superiority over basic obfuscation, especially under tight service-quality constraints. Our results confirm that loosening the service-quality constraint allows for increased privacy, but the magnitude depends on the user's profile. This is the first framework to explicitly include adversarial knowledge in the privacy-preserving design process.

## 8. References
[1] A. R. Beresford and F. Stajano. Location privacy in pervasive computing. IEEE Pervasive Computing, 2(1):46–55, 2003.
[2] M. Brückner and T. Scheffer. Stackelberg games for adversarial prediction problems. In C. Apté, J. Ghosh, and P. Smyth, editors, 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2011.
[3] R. Chow and P. Golle. Faking contextual data for fun, profit, and privacy. In WPES '09: Proceedings of the 8th ACM workshop on Privacy in the electronic society, New York, NY, USA, 2009.
[4] S. Dasgupta, C. Papadimitriou, and U. Vazirani. Algorithms. McGraw-Hill, New York, NY, 2008.
[5] Y. De Mulder, G. Danezis, L. Batina, and B. Preneel. Identification via location-profiling in GSM networks. In WPES '08: Proceedings of the 7th ACM workshop on Privacy in the electronic society, New York, NY, USA, 2008.
[6] M. Decker. Location privacy - an overview. In International Conference on Mobile Business, 2009.
[7] M. Duckham. Moving forward: location privacy and location awareness. In Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Security and Privacy in GIS and LBS, New York, NY, USA, 2010.
[8] J. Freudiger, R. Shokri, and J.-P. Hubaux. Evaluating the privacy risk of location-based services. In Financial Cryptography and Data Security (FC), 2011.
[9] J. Freudiger, R. Shokri, and J.-P. Hubaux. On the optimal placement of mix zones. In PETS '09: Proceedings of the 9th International Symposium on Privacy Enhancing Technologies, Berlin, Heidelberg, 2009.
[10] B. Gedik and L. Liu. Location privacy in mobile systems: A personalized anonymization model. In ICDCS '05: Proceedings of the 25th IEEE International Conference on Distributed Computing Systems, Washington, DC, USA, 2005.
[11] P. Golle and K. Partridge. On the anonymity of home/work location pairs. In Pervasive '09: Proceedings of the 7th International Conference on Pervasive Computing, Berlin, Heidelberg, 2009.
[12] M. Gruteser and D. Grunwald. Anonymous usage of location-based services through spatial and temporal cloaking. In MobiSys '03: Proceedings of the 1st international conference on Mobile systems, applications and services, New York, NY, USA, 2003.
[13] B. Hoh, M. Gruteser, H. Xiong, and A. Alrabady. Enhancing security and privacy in traffic-monitoring systems. IEEE Pervasive Computing, 5(4):38–46, 2006.
[14] B. Hoh, M. Gruteser, H. Xiong, and A. Alrabady. Preserving privacy in GPS traces via uncertainty-aware path cloaking. In CCS '07: Proceedings of the 14th ACM conference on Computer and communications security, New York, NY, USA, 2007.
[15] T. Jiang, H. J. Wang, and Y.-C. Hu. Preserving location privacy in wireless LANs. In MobiSys '07: Proceedings of the 5th international conference on Mobile systems, applications and services, New York, NY, USA, 2007.
[16] P. Kalnis, G. Ghinita, K. Mouratidis, and D. Papadias. Preventing location-based identity inference in anonymous spatial queries. Knowledge and Data Engineering, IEEE Transactions on, 19(12):1719–1733, Dec. 2007.
[17] D. Korzhyk, Z. Yin, C. Kiekintveld, V. Conitzer, and M. Tambe. Stackelberg vs. Nash in security games: An extended investigation of interchangeability, equivalence, and uniqueness. Journal of Artificial Intelligence Research, 41:297–327, May–August 2011.
[18] J. Krumm. Inference attacks on location tracks. In In Proceedings of the Fifth International Conference on Pervasive Computing (Pervasive), 2007.
[19] L. Liao, D. J. Patterson, D. Fox, and H. A. Kautz. Learning and inferring transportation routines. Artif. Intell., 171(5-6):311–331, 2007.
[20] W. Liu and S. Chawla. A game theoretical model for adversarial learning. In Y. Saygin, J. X. Yu, H. Kargupta, W. Wang, S. Ranka, P. S. Yu, and X. Wu, editors, IEEE International Conference on Data Mining Workshops (ICDM 2009), 2009.
[21] M. Manshaei, Q. Zhu, T. Alpcan, T. Basar, and J.-P. Hubaux. Game theory meets network security and privacy. ACM Computing Surveys, 2011.
[22] J. Meyerowitz and R. Roy Choudhury. Hiding stars with fireworks: location privacy through camouflage. In MobiCom '09: Proceedings of the 15th annual international conference on Mobile computing and networking, New York, NY, USA, 2009.
[23] P. Paruchuri, J. P. Pearce, J. Marecki, M. Tambe, F. Ordóñez, and S. Kraus. Efficient algorithms to solve Bayesian Stackelberg games for security applications. In D. Fox and C. P. Gomes, editors, 23rd AAAI Conference on Artificial Intelligence (AAAI 2008), 2008.
[24] R. Shokri, J. Freudiger, M. Jadliwala, and J.-P. Hubaux. A distortion-based metric for location privacy. In WPES '09: Proceedings of the 8th ACM workshop on Privacy in the electronic society, New York, NY, USA, 2009.
[25] R. Shokri, G. Theodorakopoulos, G. Danezis, J.-P. Hubaux, and J.-Y. Le Boudec. Quantifying location privacy: the case of sporadic location exposure. In Proceedings of the 11th international conference on Privacy enhancing technologies (PETS), Berlin, Heidelberg, 2011.
[26] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P. Hubaux. Quantifying location privacy. In IEEE Symposium on Security and Privacy, Oakland, CA, USA, 2011.