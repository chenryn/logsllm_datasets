### CVE Monitoring and Detection

As of April 30, 2019, certain Common Vulnerabilities and Exposures (CVEs) had not yet been published on the National Vulnerability Database (NVD). These CVEs were mentioned in external sources between one and 450 days before their NVD publication, with an average lead time of 46 days. Our focus is also on identifying CVEs that, while already published in the NVD, are re-mentioned on platforms like Twitter for various reasons. If discussions about a CVE in the NVD rapidly increase, organizations need to reassess the risk to their products, services, or infrastructures and verify if the CVE has been patched.

Unlike the threat word detection algorithms previously discussed, we use a CVE list from the NVD, updated just before the event detection time \( t \), as our dictionary \( D_{\text{CVE}} \). This is in contrast to using \( D_{\text{Tech}} \), \( D_{\text{Whitelist}} \), and \( D_{\text{Common}} \). Let \( C_{\text{CVE}} \) be the set of CVE IDs obtained from tweets collected between \( t - 1 \) and \( t \). In CVE monitoring, if CVE IDs in \( C_{\text{CVE}} \) are not found in \( D_{\text{CVE}} \), they are identified as new words. To avoid typos, we eliminate CVE IDs not found in the MITRE database. For CVE IDs in \( C_{\text{CVE}} \cap D_{\text{CVE}} \), we check if each CVE ID is mentioned frequently and shows a rapid rise in occurrence.

### Re-emerging Words Detection

Figure 7 illustrates the number of mentions of "wifi" from December 2018 to January 2019. The grey dotted line represents the upper bound for the frequency of "wifi," and the magenta spotted circles indicate the days when "wifi" was flagged as a re-emerging word. On January 3, 2019, our algorithm detected three events related to "wifi," with the most significant being the "Marvell Avanstar Wifi SoC bug," mentioned nine times. The set of words in brackets indicates the detected event.

The annotator made judgments by referring to external links in tweets or through Google searches. For the third aspect, we analyzed 82 security events out of 105, focusing on malware, vulnerabilities, exploits, DDoS attacks, and data breaches. We evaluated whether W2E detected these events and, if so, when. For latency computation, we used the date of the first tweet about an event over the entire Twitter dataset investigated in Section 3. W2E categorizes any events related to ransomware, spyware, trojans, botnets, rootkits, adware, keyloggers, and other malware into the malware event type.

In our implementation, we use 200 keywords, ranging from single words to terms: 28 for malware, 11 for exploits, 20 for vulnerabilities, 6 for DDoS attacks, and 17 for data breaches. Initial keywords were chosen by reviewing terms in CWE, CAPEC, STIX, and ENISA Threat Taxonomy. We then included plural forms, inflections, and aliases in our keyword set. We set \( \alpha = 0.05 \) for both new and re-emerging word detection. The dictionaries were constructed as explained in Section 4, with 72,623 words in \( D_{\text{Common}} \), 16,014 in \( D_{\text{Tech}} \), and 3,078 in \( D_{\text{Whitelist}} \) by the end of 2017. We use Stanford CoreNLP for part-of-speech (POS) tagging and named entity recognition (NER).

### Evaluation Results

#### Clustering Accuracy
To measure the clustering accuracy of our event generator, we compared the estimated clusters to human-labeled clusters and computed the normalized mutual information (NMI). NMI is a popular metric for evaluating clustering quality, with values between 0 and 1, where 1 indicates perfect clustering. Figure 9 shows the daily NMI of our event generator in April 2019, with NMI generally above 0.9. The average NMI over the month is 0.96 with a standard deviation of 0.06, indicating high performance.

#### Daily Event Detection Accuracy
We measured the false positives generated daily. Table 1 shows the precision of W2E over all daily events in the selected month. The overall precision is 80%, with precision for each threat type at or above 70%. W2E detected 2,359 daily events (79 on average), forming 930 unique events. Among these, 763 were genuine security events, giving a precision of 82% for unique events. Table 4 lists some important events in April 2019 detected by W2E.

#### Coverage and Detection Latency
We analyzed W2E's coverage for 82 security events related to malware, vulnerabilities, exploits, DDoS attacks, and data breaches. Table 2 shows the recall of W2E, which is 89% (73 out of 82 events detected). Among these, 26 events were detected only by re-emerging words, highlighting their importance. W2E showed high recall for malware, exploits, vulnerabilities, and data breaches but lower recall for DDoS attacks. The average detection delay after the first tweet is 0.67 days, with 45 out of 82 events detected on the first day and 17 the next day. W2E can detect botnet attacks, exploit incidents, and vulnerabilities with minimal latency, which is crucial for early event detection.

### Comparison with Existing Methods
We compared W2E with Ritter et al. [40], as Khadpur et al. [27] and Le Sceller et al. [29] require a large volume of mentions. Ritter et al. [40] and Sapienza et al. [44] detect events regardless of mention volume, but W2E monitors both new and re-emerging words, reducing false positives. For comparison, we collected Ritter et al.'s results for April 2019, which detected 451 tweets. W2E outperformed in event detection coverage, lower detection latency, and lower false positive rate. The precision of Ritter et al.'s method was 62%, while W2E's was 82%. W2E detected 537 unique security events, covering 67% of those detected by Ritter et al., while Ritter et al. covered only 16% of W2E's events.

### Case Studies
We selected four events detected by W2E from January 2018 to April 2019: Lokibot malware, Drupal vulnerability, Firebase data breach, and WiFi firmware bug.

**Lokibot (Malware):** This Trojan steals information from compromised computers. Trustwave researchers found a new spam campaign pushing Lokibot, reported by news media on April 5, 2019. W2E detected the event on the same day with the words "zipx," "png," and "lokibot."

This structured and detailed approach ensures clarity, coherence, and professionalism in the text.