### Control-Flow Integrity (CFI) and Simultaneous Enforcement of Constraints

In the context of control-flow-only usage, CFI incurs overheads ranging from 0% to 45% on a Pentium 4. This wide variation is likely due to significant overheads on indirect jumps, while other operations incur minimal overhead. In comparison, PittSFIeld imposes a smaller overhead on jumps but introduces additional overheads on other operations. Figure 9 compares the overheads reported in [1] with those for PittSFIeld from Figure 4. Given that different C compilers, libraries, and hardware were used, direct comparisons between PittSFIeld and CFI should be made with caution. However, the average overheads of both tools are generally comparable. The benchmark labeled "253.perlbmk" was excluded from [1] due to last-minute implementation difficulties [9] and is also omitted from the CFI average.

### Verification and Trust in CFI and PittSFIeld

Similar to PittSFIeld, CFI performs a separate verification at load time to ensure proper rewriting, thus eliminating the need to trust the compiler and binary rewriting infrastructure. The CFI authors have provided a human-checked proof [2] that a CFI-protected program will never make unsafe jumps, even in the presence of arbitrary writes to data memory. However, the proof is formulated for a miniature RISC architecture with an unspecified encoding, which may not fully capture the nuances of x86 instruction encoding. For example, the immediate value used in a jump site comparison might be interpreted as a safe jump target tag, affecting the safety of the real CFI technique.

### Static C Safety Mechanisms

Another class of program rewriting tools, often implemented as compiler modifications, focuses on ensuring specific security policies, such as preventing the modification of procedure return addresses on the stack [6]. These tools are highly effective in their intended roles and typically have low overheads. However, they do not provide protection against more sophisticated subversion attacks and do not offer isolation between components. They are not designed for untrusted code but can be used in conjunction with SFI if both isolation and protection from subversion are required.

### Dynamic Translation Mechanisms

Recent projects have adopted dynamic optimization techniques to rewrite programs on the fly, allowing for fine-grained control of program execution and avoiding the complexities of static binary rewriting. Valgrind [22] is a powerful framework for dynamic rewriting of Linux/x86 programs, known for its Purify-like memory checking capabilities but adaptable to various other purposes. Valgrind's rewriting uses a simplified intermediate language, prioritizing ease of development over performance. A more security-focused tool is Scott and Davidson’s Strata [24], which has achieved lower overheads (averaging about 30%) while enforcing targeted security policies such as system call interception. Another high-performance system is Kiriansky et al.’s program shepherding [15], based on the DynamoRIO dynamic translation system. This work focuses on preventing attacks on a program’s control flow, effectively and transparently mitigating stack- and function-pointer-smashing vulnerabilities. The VX32 system described in Section 8 also falls into this category. A disadvantage of dynamic techniques is their inherent complexity and difficulty in reasoning about, compared to static translations.

### Low-Level Type Safety

Recent research on verifiable low-level program representations has focused on static invariants, such as type systems. For instance, typed assembly language [19] provides quickly checkable, fine-grained safety properties for a subset of x86 assembly, but requires the original program to be written in a type-safe language. Type inference can transform C code into a type-safe program with minimal dynamic checks, as in the CCured system [5]. Type-based safety properties are generally effective at preventing subversion attacks that overwrite function pointers.

Proof-carrying code (PCC) [21] represents a more general framework for software to certify its own trustworthiness. Most PCC work has focused on type-like safety properties, but foundational PCC [4] aims to place proofs on a more general footing using fully general proof languages that prove safety with respect to concrete machine semantics. This approach holds the promise of allowing any safe rewriting to certify its safety properties to a code consumer. For example, the lemmas from the proof in Section 9 could be part of a foundational safety proof for a PittSFIeld-rewritten binary. However, it is unclear if existing foundational PCC systems are flexible enough to support such a proof.

### Conclusion

We have argued that software-based fault isolation (SFI) can be a practical tool for constructing secure systems. Using a novel technique of artificially enforcing alignment for jump targets, we demonstrate how a simple sandboxing implementation can be constructed for architectures with variable-length instructions like the x86. We present two new optimizations, along with previously known ones, to minimize runtime overhead. We emphasize the importance of an architecture that includes separate verification. We have constructed a machine-checked soundness proof of our technique to enhance confidence in its security. Our implementation demonstrates separate verification and scalability to large and complex applications. The performance overhead, as measured on standard compute-intensive benchmarks and a realistic data compression application, is relatively low. While some related techniques have lower runtime overheads and others offer additional security guarantees, SFI's combination of simplicity and performance makes it well-suited for many use cases.

### Acknowledgements

Bryan Ford provided us with the VXA infrastructure used in the case study of Section 8. Mihai Budiu and Úlfar Erlingsson provided results for Figure 9 and answered other questions about CFI. Members of the MIT PDOS and PAG groups, and the Harvard programming languages and compilers groups, provided numerous helpful suggestions. The first author is supported by a National Defense Science and Engineering Graduate Fellowship.

### References

[1] Martín Abadi, Mihai Budiu, Úlfar Erlingsson, and Jay Ligatti. Control-flow integrity: Principles, implementations, and applications. In Proceedings of the 12th ACM Conference on Computer and Communications Security (CCS'05), pages 340–353, Alexandria, VA, November 7–11, 2005.

[2] Martín Abadi, Mihai Budiu, Úlfar Erlingsson, and Jay Ligatti. A theory of secure control flow. In Proceedings of the 7th International Conference on Formal Engineering Methods (ICFEM’05), pages 111–124, Manchester, UK, November 1–4, 2005.

[3] Ali-Reza Adl-Tabatabai, Geoff Langdale, Steven Lucco, and Robert Wahbe. Efficient and language-independent mobile programs. In Proceedings of the SIGPLAN '96 Conference on Programming Language Design and Implementation, pages 127–136, Philadelphia, PA, May 21–24, 1996.

[4] Andrew W. Appel. Foundational proof-carrying code. In 16th Annual IEEE Symposium on Logic in Computer Science (LICS’01), page 247, June 16–19, 2001.

[5] Jeremy Condit, Mathew Harren, Scott McPeak, George C. Necula, and Westley Weimer. CCured in the real world. In Proceedings of the ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation, pages 232–244, San Diego, CA, USA, June 9–11, 2003.

[6] Crispin Cowan, Calton Pu, Dave Maier, Heather Hinton, Jonathan Walpole, Peat Bakke, Steve Beattie, Aaron Grier, Perry Wagle, and Qian Zhang. StackGuard: Automatic adaptive detection and prevention of buffer-overflow attacks. In Proceedings of the 7th USENIX Security Symposium, pages 63–78, Austin, Texas, January 28–29, 1998. USENIX Association.

[7] Peter Deutsch and Charles A. Grant. A flexible measurement tool for software systems. In Information Processing 71: Proceedings of IFIP Congress 71, pages 320–326, Ljubljana, Yugoslavia, August 23–28, 1971.

[8] Daniel C. DuVarney, Sandeep Bhatkar, and V.N. Venkatakrishnan. SELF: a transparent security extension for ELF binaries. In Proceedings of the 2003 New Security Paradigms Workshop, pages 29–38, Ascona, Switzerland, August 18–21, 2003.

[9] Úlfar Erlingsson. Personal communication, May 2006.

[10] Úlfar Erlingsson and Fred B. Schneider. SASI enforcement of security policies: A retrospective. In Proceedings of the 1999 New Security Paradigms Workshop, pages 87–95, Caledon Hills, ON, Canada, September 22–24, 1999.

[11] Bryan Ford. VXA: A virtual architecture for durable compressed archives. In 4th USENIX Conference on File and Storage Technologies, pages 295–308, San Francisco, CA, December 14–16, 2005.

[12] Andreas Gal, Christian W. Probst, and Michael Franz. A denial of service attack on the Java bytecode verifier. Technical Report 03-23, University of California, Irvine, School of Information and Computer Science, November 2003.

[13] Matt Kaufmann and J Strother Moore. An industrial strength theorem prover for a logic based on Common Lisp. IEEE Transactions on Software Engineering, 23(4):203–213, April 1997.

[14] Douglas Kilpatrick. Privman: A library for partitioning applications. In Proceedings of the 2003 USENIX Annual Technical Conference (FREENIX Track), pages 273–284, San Antonio, TX, USA, June 12–14, 2003.

[15] Vladimir Kiriansky, Derek Bruening, and Saman P. Amarasinghe. Secure execution via program shepherding. In Proceedings of the 11th USENIX Security Symposium, pages 191–206, San Francisco, California, August 7–9, 2002. USENIX Association.

[16] Fei Lu. C Plus J software architecture. Undergraduate thesis, Shanghai Jiaotong University, June 2000. English summary at http://www.cs.jhu.edu/~flu/cpj/CPJ_guide.htm.

[17] Stephen McCamant. A machine-checked safety proof for a CISC-compatible SFI technique. Technical Report 2006-035, MIT Computer Science and Artificial Intelligence Laboratory, May 2006.

[18] Greg Morrisett, Karl Crary, Neal Glew, Dan Grossman, Richard Samuels, Frederick Smith, David Walker, Stephanie Weirich, and Steve Zdancewic. TALx86: A realistic typed assembly language. In Second ACM SIGPLAN Workshop on Compiler Support for System Software, pages 25–35, Atlanta, GA, USA, May 1, 1999.

[19] George C. Necula and Peter Lee. Safe kernel extensions without run-time checking. In Proceedings of the Second Symposium on Operating Systems Design and Implementation, pages 229–243, Seattle, Washington, October 28–31, 1996.

[20] George C. Necula and Peter Lee. The design and implementation of a certifying compiler. In Proceedings of the ACM SIGPLAN'98 Conference on Programming Language Design and Implementation, pages 333–344, Montreal, Canada, June 17–19, 1998.

[21] Nicholas Nethercote and Julian Seward. Valgrind: A program supervision framework. In Proceedings of the Third Workshop on Runtime Verification (RV'03), Boulder, Colorado, USA, July 13, 2003.

[22] Niels Provos, Markus Friedl, and Peter Honeyman. Preventing privilege escalation. In Proceedings of the 12th USENIX Security Symposium, pages 231–242, Washington, D.C., August 6–8, 2003. USENIX Association.

[23] Kevin Scott and Jack Davidson. Safe virtual execution using software dynamic translation. In Proceedings of the 2002 Annual Computer Security Application Conference, pages 209–218, Las Vegas, Nevada, December 9–13, 2002.

[24] Christopher Small. MiSFIT: A tool for constructing safe extensible C++ systems. In Proceedings of the Third USENIX Conference on Object-Oriented Technologies, pages 174–184, Portland, OR, USA, June 16–20, 1997.

[25] Michael M. Swift, Brian N. Bershad, and Henry M. Levy. Improving the reliability of commodity operating systems. In Proceedings of the 19th ACM Symposium on Operating Systems Principles, pages 207–222, Bolton Landing, NY, October 20–22, 2003.

[26] Robert Wahbe, Steven Lucco, Thomas E. Anderson, and Susan L. Graham. Efficient software-based fault isolation. In Proceedings of the 14th ACM Symposium on Operating Systems Principles, pages 203–216, Asheville, NC, USA, December 5–8, 1993.

[27] Robert S. Wahbe and Steven E. Lucco. Methods for safe and efficient implementations of virtual machines. U.S. Patent 5,761,477, June 1998. Assigned to Microsoft Corporation.

[28] Simon Winwood and Manuel M. T. Chakravarty. Secure untrusted binaries - provably! In Workshop on Formal Aspects in Security and Trust (FAST 2005), pages 171–186, Newcastle upon Tyne, U.K., July 18–19, 2005.

---

This revised text aims to be more coherent, clear, and professional, with improved readability and structure.