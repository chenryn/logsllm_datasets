# Resilient Routing Reconﬁguration (R3) Implementation and Evaluation

## Table 2: R3 Offline Precomputation Time (seconds)
| Network      | Abilene | Level-3 | SBC  | UUNet | Generated | US-ISP |
|--------------|---------|---------|------|-------|-----------|--------|
| # ILM        | 28      | 72      | 70   | 336   | 460       | -      |
| # NHLFE      | 71      | 304     | 257  | 2402  | 2116      | -      |
| FIB Memory   | <9 KB   | <36 KB  | <31 KB| <267 KB| <251 KB  | <39 KB |
| RIB Storage  | <83 KB  | <535 KB | <503 KB| <11 MB| <20 MB   | <656 KB|

## Table 3: Router Storage Overhead of R3 Implementation
| Network      | Abilene | Level-3 | SBC  | UUNet | Generated | US-ISP |
|--------------|---------|---------|------|-------|-----------|--------|
| # ILM        | 28      | 72      | 70   | 336   | 460       | -      |
| # NHLFE      | 71      | 304     | 257  | 2402  | 2116      | -      |
| FIB Memory   | <9 KB   | <36 KB  | <31 KB| <267 KB| <251 KB  | <39 KB |
| RIB Storage  | <83 KB  | <535 KB | <503 KB| <11 MB| <20 MB   | <656 KB|

### Router Storage Overhead
We measure the ILM table size, the NHLFE table size, the FIB size, and the RIB size per router. Table 3 summarizes the results for six topologies. We observe that all six network topologies can be protected by R3 with modest FIBs (<267 KB) and RIBs (<20 MB).

### MPLS Labels
A related overhead is the use of MPLS labels. Recall that the number of MPLS labels used by MPLS-ff for protection routing is bounded by the number of links in the network. Since many routers can support at least tens of thousands of MPLS labels, the number of MPLS labels used in protection routing is not a significant issue.

### Effective Resilient Routing Reconfiguration
Next, we evaluate the effectiveness of protection routing. We generate failure scenarios by sequentially disconnecting three links (Houston-Kansans, Chicago-Indianapolis, Sunnyvale-Denver) on the emulated Abilene topology (each link is two directed links). After failing one link, we delay by about one minute before failing the next link. During the evaluation, bursty traffic is generated to allow us to measure the traffic throughput between every OD pair, the traffic intensity on each link, and the aggregated loss rate at each egress router (the traffic matrix encodes the expected outgoing traffic).

As shown in Figure 11, our R3 implementation successfully reroutes traffic without overloading any link. From Figure 11(b), we see that despite three failed links, the bottleneck traffic intensity is always within 0.37. Figure 12 further plots the real-time RTT of a flow between Denver and Los Angeles during our test process. We can clearly identify the three-step increases of RTT, due to the three link failures. We observe that our R3 protection routing implementation achieves smooth and efficient routing protection.

### Comparison with OSPF
To appreciate the effectiveness of R3, we run the same failure scenario using OSPF reconvergence protection. Figure 13 compares the traffic intensity by OSPF+recon vs MPLS-ff+R3. Using OSPF, the traffic intensity on the link between Washington and Atlanta (link index 28) reaches as high as 1.07 (instantaneous rate). Due to the congestion, we observe from the trace that the throughput for the OD pair New York City to Indianapolis drops by up to 32.6% using OSPF+recon.

## Related Work
The existing work can be classified into two categories: (i) routing under failures and (ii) routing under variable traffic.

### Routing Under Failures
Many recent studies focus on minimizing the duration of disruption due to failures (e.g., [4, 20, 21, 23, 24, 26, 27, 29, 32]). These techniques precompute protection and quickly reroute traffic upon detecting failures (and before routing convergence) [33]. However, they do not provide performance predictability or avoid congestion. As we have seen, they may lead to serious congestion and thus violation of service level agreements.

Meanwhile, there are also significant studies on optimizing performance under failures. In [14], the authors studied the optimization of OSPF/IS-IS weights under failures. However, it is a heuristic-based approach and does not provide performance guarantees or avoidance of congestion.

In MATE [9] and TeXCP [18], the authors study how to react to instantaneous traffic load and redistribute traffic on alternate links or paths. Many previous studies achieve optimal performance by re-optimizing routing after each failure (e.g., MPLS routing [39]). A major advantage of these approaches is that the new routing is computed specifically for the new topology. Thus, the new routing can efficiently utilize the remaining network resources and provide certain guarantees (e.g., how close the rerouting response compared with the optimal [2]).

A drawback of these approaches, however, is their slow response time. Re-optimization from scratch for the new topology can be computationally expensive. In addition, the new routing could be very different from the existing one and thus take substantial delay in installation and convergence. This can cause significant service disruption because of operation errors, forwarding loops, and packet loss during long convergence processes. As a result, network operators are highly reluctant to completely change their routing. Instead, they prefer simple routing reconfiguration. They completely re-optimize only periodically or after a major change, instead of after each topology failure. The only work that optimizes routing simultaneously for different topologies is [2], but it requires enumeration of all possible topologies after failures and faces scalability issues under multiple failures.

### Routing Under Variable Traffic Demand
High variability in Internet traffic has motivated researchers to design robust traffic engineering that works well under variable traffic. One class of algorithms [1, 9, 18, 31, 43] maintains a history of observed traffic demand matrices and optimizes for the representative traffic demand matrices. Another class of algorithms is oblivious routing [2, 3, 22, 37, 46], which optimizes the worst-case performance over all possible traffic demands. More recently, Wang et al. [40] further combined oblivious routing with prediction-based optimization to provide good performance under typical demands while guaranteeing the worst-case performance. These works focus on traffic variability and do not consider topology variability.

## Conclusions
In this paper, we propose Resilient Routing Reconﬁguration (R3) to find a single protection routing that can be effectively reconﬁgured to provide congestion-free guarantees under multiple failures. We introduce a novel compact representation of a large number of failure scenarios and compute a protection scheme that is resilient to both link failures and traffic variability. We further extend R3 to handle realistic failure scenarios, prioritized traffic, and the trade-off between performance and resilience. We fully implement R3 on Linux using MPLS-ff and demonstrate its effectiveness through real experiments and extensive simulations using realistic network topologies and traffic.

## Acknowledgments
The research is supported in part by NSF Grants CNS-0546720, CNS-0546755, CNS-0626878, and CNS-0627020. We are grateful to Jia Wang, Murali Kodialam, anonymous reviewers, C. Tian, and Dave Wang for valuable comments.

## References
[1] S. Agarwal, A. Nucci, and S. Bhattacharyya. Measuring the shared fate of IGP engineering and interdomain traffic. In Proc. ICNP, Nov. 2005.
[2] D. Applegate, L. Breslau, and E. Cohen. Coping with network failures: Routing strategies for optimal demand oblivious restoration. In Proc. ACM SIGMETRICS, June 2004.
[3] D. Applegate and E. Cohen. Making intra-domain routing robust to changing and uncertain traffic demands: Understanding fundamental tradeoffs. In Proc. ACM SIGCOMM, Aug. 2003.
[4] A. Atlas and Z. Zinin. Basic specification for IP Fast-Reroute: loop-free alternates. (IETF Internet-Draft), draft-ietf-rtgwg-ipfrr-spec-base-10.txt, 2007.
[5] D. Bertsekas. Nonlinear Programming. Athena Scientific, 1999.
[6] D. Bertsekas and R. Gallager. Data Networks. Prentice-Hall, 1992.
[7] CAIDA. http://www.caida.org/tools/.
[8] ILOG CPLEX: optimization software. http://www.ilog.com/products/cplex/.
[9] A. Elwalid, C. Jin, S. Low, and I. Widjaja. MATE: MPLS adaptive traffic engineering. In Proc. IEEE INFOCOM, Apr. 2001.
[10] A. Farrel, J.-P. Vasseur, and J. Ash. A Path Computation Element (PCE)-based Architecture, RFC 4655, Aug. 2006.
[11] N. Feamster, H. Balakrishnan, J. Rexford, A. Shaikh, and K. van der Merwe. The case for separating routing from routers. In Proc. ACM SIGCOMM FDNA Workshop, Sept. 2004.
[12] B. Fortz, J. Rexford, and M. Thorup. Traffic engineering with traditional IP routing protocols. IEEE Communication Magazine, Oct. 2002.
[13] B. Fortz and M. Thorup. Internet traffic engineering by optimizing OSPF weights. In Proc. IEEE INFOCOM, Mar. 2000.
[14] B. Fortz and M. Thorup. Robust optimization of OSPF/IS-IS weights. In Proc. INOC, Oct. 2003.
[15] P. Francois, C. Filsfils, J. Evans, and O. Bonaventure. Achieving sub-second IGP convergence in large IP networks. ACM CCR, 35(3), 2005.
[16] G. Iannaccone, C. Chuah, S. Bhattacharyya, and C. Diot. Feasibility of IP restoration in a tier-1 backbone. IEEE Network Magazine, 18(2):13–19, 2004.
[17] S. Iyer, S. Bhattacharyya, N. Taft, and C. Diot. An approach to alleviate link overload as observed on an IP backbone. In Proc. IEEE INFOCOM, Apr. 2003.
[18] S. Kandula, D. Katabi, B. Davie, and A. Charny. Walking the tightrope: Responsive yet stable traffic engineering. In Proc. ACM SIGCOMM, Aug. 2005.
[19] S. Kandula, D. Katabi, S. Sinha, and A. Berger. Dynamic load balancing without packet reordering. SIGCOMM CCR, 37(2), 2007.
[20] K. Kar, M. S. Kodialam, and T. V. Lakshman. Routing restorable bandwidth guaranteed connections using maximum 2-route flows. IEEE/ACM Transactions on Networking, 11(5):772–781, 2003.
[21] M. Kodialam and T. V. Lakshman. Dynamic routing of locally restorable bandwidth guaranteed tunnels using aggregated link usage information. In Proc. IEEE INFOCOM, Apr. 2001.
[22] M. Kodialam, T. V. Lakshman, and S. Sengupta. Efficient and robust routing of highly variable traffic. In Proc. HotNets-III, Nov. 2004.
[23] M. Kodialam, T. V. Lakshman, and S. Sengupta. A simple traffic independent scheme for enabling restoration oblivious routing of resilient connections. In Proc. IEEE INFOCOM, Apr. 2004.
[24] M. S. Kodialam and T. V. Lakshman. Dynamic routing of restorable bandwidth-guaranteed tunnels using aggregated network resource usage information. IEEE/ACM Transactions on Networking, 11(3):399–410, 2003.
[25] R. R. Kompella, J. Yates, A. Greenberg, and A. C. Snoeren. IP fault localization via risk modeling. In Proc. NSDI, 2005.
[26] K. Lakshminarayanan, M. Caesar, M. Rangan, T. Anderson, S. Shenker, and I. Stoica. Achieving convergence-free routing using failure-carrying packets. In Proc. ACM SIGCOMM, Aug. 2007.
[27] A. Li, P. Francois, and X. Yang. On improving the efficiency and manageability of NotVia. In Proc. CoNEXT, Dec. 2007.
[28] A. Markopoulou, G. Iannaccone, S. Bhattacharyya, C. Chuah, and C. Diot. Characterization of failures in an IP backbone network. In Proc. IEEE INFOCOM, Apr. 2004.
[29] M. Motiwala, M. Elmore, N. Feamster, and S. Vempala. Path splicing. In Proc. ACM SIGCOMM, 2008.
[30] M. Roughan. First order characterization of Internet traffic matrices. In Proc. 55th Session of the International Statistics Institute, Apr. 2005.
[31] M. Roughan, M. Thorup, and Y. Zhang. Traffic engineering with estimated traffic matrices. In Proc. IMC, Oct. 2003.
[32] M. Shand and S. Bryant. IP fast reroute framework. (IETF Internet-Draft), draft-ietf-rtgwg-ipfrr-framework-06.txt, 2007.
[33] V. Sharma, B. M. Crane, S. Makam, K. Owens, C. Huang, F. Hellstrand, J. Weil, L. Andersson, B. Jamoussi, B. Cain, S. Civanlar, and A. Chiu. Framework for MPLS-Based Recovery. RFC 3469, Feb. 2003.
[34] N. So and H. Huang. Building a highly adaptive, resilient, and scalable MPLS backbone. http://www.wandl.com/html/support/papers/VerizonBusiness_WANDL_MPLS2007.pdf, 2007.
[35] N. Spring, R. Mahajan, and D. Wetherall. Rocketfuel: An ISP topology mapping engine. Available from http://www.cs.washington.edu/research/networking/rocketfuel/.
[36] Telemark. Telemark survey. http://www.telemarkservices.com/, 2006.
[37] L. G. Valiant. A scheme for fast parallel communication. SIAM Journal on Computing, 11(7):350–361, 1982.
[38] J. P. Vasseur, M. Pickavet, and P. Demeester. Network Recovery: Protection and Restoration of Optical, SONET-SDH, and MPLS. Morgan Kaufmann, 2004.
[39] H. Wang, H. Xie, L. Qiu, Y. R. Yang, Y. Zhang, and A. Greenberg. COPE: Traffic engineering in dynamic networks. In Proc. ACM SIGCOMM, 2006.
[40] H. Wang, Y. R. Yang, P. H. Liu, J. Wang, A. Gerber, and A. Greenberg. Reliability as an interdomain service. In Proc. ACM SIGCOMM, Aug. 2007.
[41] B. White, J. Lepreau, L. Stoller, R. Ricci, S. Guruprasad, M. Newbold, M. Hibler, C. Barb, and A. Joglekar. An integrated experimental environment for distributed systems and networks. In Proc. OSDI, Dec. 2002.
[42] Wired News. The backhoe: A real cyberthreat, Jan. 2006. http://www.wired.com/news/technology/1,70040-0.html.
[43] C. Zhang, Z. Ge, J. Kurose, Y. Liu, and D. Towsley. Optimal routing with multiple traffic matrices: Tradeoff between average case and worst case performance. In Proc. ICNP, Nov. 2005.
[44] Y. Zhang and Z. Ge. Finding critical traffic matrices. In Proc. DSN '05, 2005.
[45] Y. Zhang, M. Roughan, C. Lund, and D. L. Donoho. An information-theoretic approach to traffic matrix estimation. In Proc. ACM SIGCOMM, Aug. 2003.
[46] R. Zhang-Shen and N. McKeown. Designing a predictable Internet backbone network. In Proc. HotNets-III, Nov. 2004.