Certainly! Here is the optimized version of your text, with improved clarity, coherence, and professionalism:

---

**V. RELATED WORK**

### Mobile Malware Detection and Prevention
Significant efforts have been made to analyze and detect Android Potentially Harmful Applications (PHAs). Most of these studies focus on identifying code that performs potentially harmful actions, such as stealing sensitive user information [37-45], and protecting the Android system from various attacks [46-53]. Unlike these prior studies, which primarily operate at the app level, our research focuses on discovering and analyzing mobile libraries and their harmful behaviors, a domain that has not been extensively explored.

### iOS Research
Compared to the extensive research on Android, relatively little work has been done on the iOS platform. One notable example is PiOS [54], the first static tool designed to detect privacy leaks in iOS applications. In terms of dynamic analysis, previous research [55] highlights the challenges in analyzing iOS programs. To address these issues, DiOS [56] uses UI automation to drive the execution of iOS applications, aiming to trigger more events. Additionally, iRiS [58] combines dynamic binary instrumentation (by porting Valgrind [57] to iOS) and static analysis to examine API calls within iOS apps for the misuse of private APIs. Other examples include MoCFI [59], which extracts the Control Flow Graph (CFG) of a program using PiOS and checks the validity of instructions that change the execution flow at runtime, and PSiOS [60], which enforces privacy protection on top of MoCFI. Despite these efforts, no existing research has comprehensively investigated potentially harmful apps on the Apple platform, largely due to the lack of ground truth data.

### Invariants Inference
Invariants are widely used to identify program vulnerabilities [21, 24, 61, 25]. These invariants are typically discovered through dynamic analysis, where the program's runtime information is collected to derive invariant features. Any violation of these invariants can indicate a program error. All previous studies on this subject have been conducted on the same platforms, often on the same or similar programs. Our research, however, is the first to identify cross-platform invariants for PHA analysis. Specifically, our invariant analysis is fully static, making it scalable enough to process 140,000 iOS apps.

### Cross-Platform Analysis
Cross-platform security studies are known to be challenging, but some work has been done in this area, primarily for vulnerability analysis. A prominent example is recent work that identifies similar bugs across different architectures (X86, MIPS, ARM) within the same program [62]. In contrast, our study focuses on potentially harmful code within independently developed programs, which is significantly more complex. Another related effort is the establishment of a baseline for security comparison between Android and iOS apps, where manually selected app pairs are analyzed to determine how they access security-sensitive APIs [63]. In our study, we developed techniques to automatically correlate Android and iOS code and discover harmful behaviors in both platforms.

---

**VI. DISCUSSION**

### Understanding PhaLibs
All the iOS PhaLibs in our study were identified based on invariants shared with their Android counterparts. The invariants used, specifically constant strings, were highly reliable, introducing almost no false positives. However, this approach does have false negatives, missing iOS classes that do not share any strings with their Android versions. Although this limitation was partially mitigated by our extension technique, which recovered 71.16% of the classes within a library, some classes or even entire libraries may still be missed. A more comprehensive study could benefit from combining constant strings with other invariant features, such as code structure and intermediate variables.

### Methodology Limitations
Our methodology of mapping Android PhaLibs to iOS apps does not account for libraries built exclusively for the iOS platform. For instance, among the top 38 iOS libraries listed by SourceDNA, 36 have Android versions. We used this methodology to understand the relationships between Android and iOS libraries and to leverage VirusTotal for identifying potentially harmful behaviors within iOS apps. As a result, we likely underestimate the scope and magnitude of the PHA threat on the Apple platform. For example, our estimate of 2.94% PHAs on the Apple App Store is likely on the low end. The actual percentage could be much closer to that of Google Play. Future research on iOS PhaLibs may require new techniques for large-scale code similarity searches and more comprehensive definitions of potentially harmful behaviors within iOS apps.

### Identifying Potentially Harmful Behavior
Both Android and iOS PhaLibs are identified, directly or indirectly, by VirusTotal. To determine the potential harmful behavior within an iOS library, we translate it into the equivalent behavior within an Android PhaLib and use a black-box technique to check if the behavior is part of a PHA signature. This translation and analysis, based on IAC sequences, are less accurate, introducing 3.3% false positives and potentially missing harmful activities without Android counterparts. Future research will explore more effective ways to export Android-side suspicious behaviors to the iOS platform, enabling direct PHA scanning on iOS apps. Additionally, techniques that do not rely on behavior and content signatures, as proposed in prior research [64], should be developed to detect PHAs with previously unknown harmful behaviors.

### Evasion
It is important to note that the techniques we used for cross-platform PhaLib analysis are not intended for PHA detection. Our approach focuses on a subset of PHAs, those detected by VirusTotal on Android and those including the PhaLib with an Android counterpart on iOS. Even for these apps, PHA authors can obfuscate their invariants to evade our cross-platform analysis. Future studies are needed to find more reliable mappings to make such evasion more difficult. Nevertheless, our study reveals the pervasiveness of PhaLibs and their cross-platform deployment, helping the research community better understand how such harmful code is propagated, a critical step towards ultimately defeating the threat they pose.

---

**VII. CONCLUSION**

This paper presents the first systematic study on mobile PhaLibs across Android and iOS platforms. Our research leverages the relationships between the Android and iOS versions of the same libraries, overcoming technical challenges in recovering library code from iOS binary code and determining its potential harm. By applying our methodology to 1.3 million Android apps and 140,000 iOS apps, we discovered that 6.84% of apps on Google Play and 2.94% of apps on the Apple App Store are PHAs. We also identified high-impact backdoor PhaLibs on both platforms and their relationships. Furthermore, our findings suggest that library contamination is an important channel for propagating potentially harmful code. This study marks the first step toward understanding mobile PhaLibs across platforms and PHA detection on iOS.

---

**ACKNOWLEDGEMENT**

We thank our shepherd Franziska Roesner and anonymous reviewers for their valuable comments. We also thank VirusTotal for their assistance in validating suspicious apps in our study. Kai Chen was supported in part by NSFC U1536106, 61100226, Youth Innovation Promotion Association CAS, and the strategic priority research program of CAS (XDA06010701). The IU authors were supported in part by NSF CNS-1223477, 1223495, and 1527141. Yingjun Zhang was supported by the National High Technology Research and Development Program of China (863 Program) (No. 2015AA016006) and NSFC 61303248.

---

**REFERENCES**

[1] Google, "Google report: Android security 2014 year in review," https://static.googleusercontent.com/media/source.android.com/en/security/reports/Google Android Security 2014 Report Final.pdf, 2014.

[2] K. Chen, P. Wang, Y. Lee, X. Wang, N. Zhang, H. Huang, W. Zou, and P. Liu, "Finding unknown malice in 10 seconds: Mass vetting for new threats at the Google Play scale," in USENIX Security, vol. 15, 2015.

[3] SourceDNA, "iOS apps caught using private APIs," https://sourcedna.com/blog/20151018/ios-apps-using-private-apis.html, 2015.

[4] C. Xiao, "Novel malware XcodeGhost modifies Xcode, infects Apple iOS apps, and hits App Store," http://researchcenter.paloaltonetworks.com/2015/09/novel-malware-xcodeghost-modifies-xcode-infects-apple-ios-apps-and-hits-app-store/, Tech. Rep., 2015.

[5] K. Chen, P. Liu, and Y. Zhang, "Achieving accuracy and scalability simultaneously in detecting application clones on Android markets," in ICSE, 2014.

[6] "A private website," https://sites.google.com/site/phalibscom/, 2015.

[7] F-Secure, "Q1 2014 mobile threat report - F-Secure," https://www.f-secure.com/documents/996508/1030743/Mobile Threat Report Q1 2014.pdf, Mar 2014.

[8] M. Kassner, "Google Play: Android’s Bouncer can be pwned," http://www.techrepublic.com/blog/it-security/-google-play-androids-bouncer-can-be-pwned/, 2012.

[9] J. Erwin, "Where did VirusBarrier iOS go?" http://www.intego.com/mac-security-blog/where-did-virusbarrier-ios-go/, 2015.

[10] J. Leyden, "Apple picking off iOS one: Who’ll be spared?" http://www.theregister.co.uk/2015/03/24/ios anti malware confusion/, 2015.

[11] VirusTotal, "A closer look at Mac OS X executables and iOS apps," http://blog.virustotal.com/2014/12/a-closer-look-at-mac-os-x-executables.html, 2014.

[12] T. iPhone Wiki, "Malware for iOS," https://www.theiphonewiki.com/wiki/Malware for iOS, 2015.

[13] VirSCAN, "Virscan.org is a free on-line scan service," http://www.virscan.org/, 2015.

[14] S. Fadilpai, "Android is the biggest target for mobile malware," http://betanews.com/2015/06/26/android-is-the-biggest-target-for-mobile-malware/, 2015.

[15] AppBrain, "Android ad network stats," http://www.appbrain.com/stats/libraries/ad?sort=apps, 2015.

[16] "AdMob get started," https://developers.google.com/admob/android/quick-start#load_the_ad_in_the_mainactivity_class, November 2015.

[17] IANA, "Root zone database," https://www.iana.org/domains/root/db, 2015.

[18] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu, "A density-based algorithm for discovering clusters in large spatial databases with noise," in KDD, vol. 96, no. 34, 1996, pp. 226–231.

[19] W. Zhou, Y. Zhou, X. Jiang, and P. Ning, "Detecting repackaged smartphone applications in third-party Android marketplaces," in Proceedings of the Second ACM Conference on Data and Application Security and Privacy, ser. CODASPY '12. New York, NY, USA: ACM, 2012, pp. 317–326. [Online]. Available: http://doi.acm.org/10.1145/2133601.2133640

[20] J. Pewny, B. Garmany, R. Gawlik, C. Rossow, and T. Holz, "Cross-architecture bug search in binary executables," in 2015 IEEE Symposium on Security and Privacy, SP 2015, San Jose, CA, USA, May 17-21, 2015, 2015, pp. 709–724. [Online]. Available: http://dx.doi.org/10.1109/SP.2015.49

[21] M. Ernst, J. Cockrell, W. G. Griswold, and D. Notkin, "Dynamically discovering likely program invariants to support program evolution," Software Engineering, IEEE Transactions on, vol. 27, no. 2, pp. 99–123, Feb 2001.

[22] "Clutch," https://github.com/KJCracks/Clutch.

[23] Capstone, "Capstone is a lightweight multi-platform, multi-architecture disassembly framework," http://www.capstone-engine.org/.

[24] S. Hangal and M. S. Lam, "Tracking down software bugs using automatic anomaly detection," in Proceedings of the 24th International Conference on Software Engineering, ser. ICSE '02. New York, NY, USA: ACM, 2002, pp. 291–301. [Online]. Available: http://doi.acm.org/10.1145/581339.581377

[25] Y. Kataoka, D. Notkin, M. D. Ernst, and W. G. Griswold, "Automated support for program refactoring using invariants," in Proceedings of the IEEE International Conference on Software Maintenance (ICSM'01), ser. ICSM '01. Washington, DC, USA: IEEE Computer Society, 2001, pp. 736–. [Online]. Available: http://dx.doi.org/10.1109/ICSM.2001.972794

[26] C. Zheng, S. Zhu, S. Dai, G. Gu, X. Gong, X. Han, and W. Zou, "SmartDroid: An automatic system for revealing UI-based trigger conditions in Android applications," in Proceedings of the Second ACM Workshop on Security and Privacy in Smartphones and Mobile Devices, ser. SPSM '12. New York, NY, USA: ACM, 2012, pp. 93–104. [Online]. Available: http://doi.acm.org/10.1145/2381934.2381950

[27] M. Christodorescu, S. Jha, S. Seshia, D. Song, and R. Bryant, "Semantics-aware malware detection," in Security and Privacy, 2005 IEEE Symposium on, May 2005, pp. 32–46.

[28] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie, "PScout: Analyzing the Android permission specification," in Proceedings of the 2012 ACM conference on Computer and communications security. ACM, 2012, pp. 217–228.

[29] E. M. Myers, "A precise inter-procedural data flow algorithm," in Proceedings of the 8th ACM SIGPLAN-SIGACT symposium on Principles of programming languages. ACM, 1981, pp. 219–230.

[30] VirusTotal, "VirusTotal - free online virus, malware and URL scanner," https://www.virustotal.com/, 2014.

[31] 91, "91 Market," http://zs.91.com/, 2015.

[32] Apple, "Distributing Apple Developer Enterprise Program apps," https://developer.apple.com/library/ios/documentation/IDEs/Conceptual/AppDistributionGuide/DistributingEnterpriseProgramApps/DistributingEnterpriseProgramApps.html, 2015.

[33] Lookout, "What you need to know about the new Android vulnerability, Stagefright," https://blog.lookout.com/blog/2015/07/28/stagefright/, 2015.

[34] P. G. Y. K. Zhaofeng Chen, Adrian Mettler, "iBackdoor: High-risk apps hit iOS," https://www.fireeye.com/blog/threat-research/2015/11/ibackdoor_high-risk.html, 2015.

[35] Dex2jar, "Tools to work with Android .dex and Java .class files," https://github.com/pxb1988/dex2jar, 2015.

[36] Y. Zhou and X. Jiang, "Dissecting Android malware: Characterization and evolution," in IEEE S&P, 2012.

[37] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. Sheth, "TaintDroid: An information-flow tracking system for real-time privacy monitoring on smartphones," in OSDI, vol. 10, 2010, pp. 1–6.

[38] L.-K. Yan and H. Yin, "DroidScope: Seamlessly reconstructing the OS and Dalvik semantic views for dynamic Android malware analysis," in USENIX security symposium, 2012, pp. 569–584.

[39] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang, "Hey, you, get off of my market: Detecting malicious apps in official and alternative Android markets," in NDSS, 2012.

[40] M. C. Grace, W. Zhou, X. Jiang, and A.-R. Sadeghi, "Unsafe exposure analysis of mobile in-app advertisements," in Proceedings of the fifth ACM conference on Security and Privacy in Wireless and Mobile Networks. ACM, 2012, pp. 101–112.

[41] Z. Qu, V. Rastogi, X. Zhang, Y. Chen, T. Zhu, and Z. Chen, "AutoCog: Measuring the description-to-permission fidelity in Android applications," in Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2014, pp. 1354–1365.

[42] M. Zhang, Y. Duan, H. Yin, and Z. Zhao, "Semantics-aware Android malware classification using weighted contextual API dependency graphs," in Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2014, pp. 1105–1116.

[43] F. Wei, S. Roy, X. Ou et al., "Amandroid: A precise and general inter-component data flow analysis framework for security vetting of Android apps," in Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2014, pp. 1329–1341.

[44] K. Tam, S. J. Khan, A. Fattori, and L. Cavallaro, "CopperDroid: Automatic reconstruction of Android malware behaviors," in Proc. of the Symposium on Network and Distributed System Security (NDSS), 2015.

[45] M. I. Gordon, D. Kim, J. Perkins, L. Gilham, N. Nguyen, and M. Rinard, "Information-flow analysis of Android applications in DroidSafe," in Proc. of the Network and Distributed System Security Symposium (NDSS). The Internet Society, 2015.

[46] M. Nauman, S. Khan, and X. Zhang, "APEX: Extending Android permission model and enforcement with user-defined runtime constraints," in Proceedings of the 5th ACM Symposium on Information, Computer and Communications Security. ACM, 2010, pp. 328–332.

[47] H. Peng, C. Gates, B. Sarma, N. Li, Y. Qi, R. Potharaju, C. Nita-Rotaru, and I. Molloy, "Using probabilistic generative models for ranking risks of Android apps," in Proceedings of the 2012 ACM conference on Computer and communications security. ACM, 2012, pp. 241–252.

[48] M. Dam, G. Le Guernic, and A. Lundblad, "TreeDroid: A tree automaton based approach to enforcing data processing policies," in Proceedings of the 2012 ACM conference on Computer and communications security. ACM, 2012, pp. 894–905.

[49] M. Hardt and S. Nath, "Privacy-aware personalization for mobile advertising," in Proceedings of the 2012 ACM conference on Computer and communications security. ACM, 2012, pp. 662–673.

[50] K. Z. Chen, N. M. Johnson, V. D’Silva, S. Dai, K. MacNamara, T. R. Magrino, E. X. Wu, M. Rinard, and D. X. Song, "Contextual policy enforcement in Android applications with permission event graphs," in NDSS, 2013.

[51] S. Bugiel, S. Heuser, and A.-R. Sadeghi, "Flexible and fine-grained mandatory access control on Android for diverse security and privacy policies," in Usenix security, 2013, pp. 131–146.

[52] C. Wu, Y. Zhou, K. Patel, Z. Liang, and X. Jiang, "AirBag: Boosting smartphone resistance to malware infection," in NDSS, 2014.

[53] O. Tripp and J. Rubin, "A Bayesian approach to privacy enforcement in smartphones," in USENIX Security, 2014.

[54] M. Egele, C. Kruegel, E. Kirda, and G. Vigna, "PiOS: Detecting privacy leaks in iOS applications," in NDSS, 2011.

[55] M. Szydlowski, M. Egele, C. Kruegel, and G. Vigna, "Challenges for dynamic analysis of iOS applications," in Open Problems in Network