# 如何对抗看似无所不能的人工智能

##### 译文声明
本文为翻译文章，仅供参考。具体内容及含义以原文为准。

> “为何要与人工智能作对？安全专家们为何不能接受人工智能？能不能不要制造恐慌？”
>
> 在我们发布关于深度学习系统中潜在威胁和攻击的演示后，这个问题频繁出现且出乎意料。
>
> 我脑海中浮现的是《终结者 I》中的场景：莎拉·康纳被施瓦辛格饰演的T800追杀。这个智能机器人不仅具备人脸识别技术，还拥有地图和大数据信息，并且几乎无法摧毁。这是人工智能威胁人类的经典例子之一。在电影世界里，无论是《终结者》系列还是《银翼杀手》系列，都描绘了人类对抗或抵抗先进AI的情景……因此，与人工智能斗争始终是我们对未来的一种设想，而且通常出于正义的需求。
>
> 经过几次公关沟通之后，我决定不再直接回答这个问题，而是通过撰写文章来详细阐述。

## 为什么要研究对抗人工智能？

### 黑产利用

在2017年的ISC大会上，对于为何需要关注AI系统的安全性，我们给出了一个官方答案：“因为黑产也在使用人工智能。”随着深度学习技术逐渐普及，其应用门槛不断降低，这意味着除了推动自动驾驶和面部识别等正面用途外，它也可能被用于恶意活动，如自动发帖、破解验证码、收集特定目标的信息以及发动针对性的网络钓鱼攻击。

### 安全需求

如果一种新技术有效，那么犯罪分子愿意投入的资金往往超过正规企业对该技术的投资。例如，可以想象一下无人机携带微型炸弹追踪你的情况——这种设备能够基于你的历史行踪进行定位，并在爆炸前通过面部识别确认身份。面对这样的威胁，难道不应该采取措施吗？这并不是科幻小说里的桥段，而是在2017年就已经实现的技术。

当人工智能可能对你构成实际威胁时，对其进行防御便成为生存所需。从这个角度来看，在网络空间内，研究人员探索AI的安全性问题显得尤为重要。

## 对抗人工智能的其他理由

抛开极端案例不谈，让我们回到现实生活中。虽然“杀人无人机”听起来很吓人，但实际上大多数情况下并没有那么可怕。作为一名安全从业者，我发现当前状况相当矛盾：

一方面，我们经常听说那些神奇的深度学习算法如何催生了各种新应用，从面部解锁到无人驾驶汽车；另一方面，我们也频繁看到诸如“某平台面部识别存在严重漏洞”之类的新闻报道，或者有人仅凭两张纸就能绕过面部验证，甚至用胶带加导电笔就能破解指纹锁。360团队曾展示过，他们能够让一款基于谷歌模型训练而成的图像识别程序将羊误认为狼，反之亦然。

在这个充满悖论的世界里，随着越来越多的年轻人投身于AI领域，我认为安全研究人员有责任提醒大家注意潜在的风险。尽管AI技术确实能加速某些应用程序的发展，但如果忽视了基础性的安全保障，那么最终结果可能是灾难性的。

因此，研究如何抵御AI不仅仅是为了防止用户受到欺骗，更是为了确保整个生态系统的健康发展。

## 风险源头分析

为什么这些所谓的智能系统会如此轻易地被攻破呢？难道我们不该拥抱由深度学习引领的技术革命吗？

根据我个人的经验，在与一位顶级AI专家（多次赢得ImageNet挑战赛）交流过程中，当我们展示了降维攻击导致深度学习系统错误识别时，他立即表示这不是AI本身的问题。同样地，当我们告知某知名深度学习框架作者其代码存在bug时，得到的回答也是类似——“这不是我们的错”。

作为长期从事信息安全工作的专业人士，我对这类反应并不感到意外。每当向数据库管理员指出SQL注入漏洞时，对方通常会说这不是数据库层面的问题；而当你告诉服务器端开发者他们的软件存在控制流劫持风险时，他们则会辩称客户端已经做了充分防护。

尽管这些解释看似合理，但安全隐患依然存在。只有等到PoC被公开或黑客窃取了敏感数据后才意识到问题严重性，未免太迟了些。如果连最基础的面部识别都能被简单手段绕过，那么自动驾驶车辆又该如何保证乘客安全呢？

任何一项技术在实验室条件下取得良好效果固然值得庆祝，但在实际部署过程中还需面对诸多挑战。因此，在推出新产品时，请勿仅仅关注前端开发人员的热情演讲，同时也要关心后台工程师所面临的困境。

## 实践方法

既然明确了研究反AI技术的重要性，接下来就要探讨具体策略了。如果你仍然认为AI算法无懈可击，那么面对AlphaGo级别的对手时恐怕只能束手就擒。然而事实并非如此——即使是AlphaGo也有弱点。

据AlphaGo团队成员透露，在与李世石对弈期间，负责执棋的黄士杰博士最担心的就是自己下错位置。由此可见，即使是最先进的AI系统也依赖于准确的数据输入。一旦传感器或数据采集环节出现问题，整个系统就会变得脆弱不堪。

此外，还有许多针对硬件设备本身的攻击手段，比如干扰麦克风接收信号、使摄像头失灵或者向雷达发送虚假信息等。因此，若想有效抵御AI带来的威胁，就必须将其视为一个完整的体系来进行考量，包括但不限于数据获取方式、传感器设计、数据处理流程以及用户交互界面等方面。

只有当我们不再单纯地把AI视作孤立存在的算法，而是作为一个复杂的整体来看待时，才能全面评估其面临的安全风险并提出相应的解决方案。