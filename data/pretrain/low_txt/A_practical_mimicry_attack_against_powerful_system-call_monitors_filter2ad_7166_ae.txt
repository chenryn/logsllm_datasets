### Techniques and Their Potential Issues

Certain techniques may lead to performance or compatibility issues. In such cases, one might rely on methods designed to detect memory error exploits, such as address-space randomization [1, 4].

### Network Intrusion Detection Systems (IDS) and Payload Anomaly Detection Techniques

Network IDS, like Snort and Bro, scan packet content for known attack signatures. However, these systems are ineffective against unknown exploits, which can be used to craft successful persistent interposition attacks.

Recently, several techniques have emerged that detect intrusions by identifying anomalies in protocol payload data [33, 21]. These content-based intrusion detection systems use statistical analysis of input requests to a server, recognizing anomalies such as binary data or other unusual characteristics. While these systems do not fit our definition of I/O data obliviousness, other researchers [9] have developed orthogonal techniques to evade content-based IDS. These techniques encode attack inputs to conform to the normal profile used by the IDS (e.g., PAYL [33]). These encoding techniques can be easily combined with our attack method, as it allows the attacker full control over the contents of attack inputs and all outputs from the victim server.

### Related Work

In this section, we focus on mimicry attacks and other related work not previously discussed. Wagner and Soto [31] pioneered the concept of mimicry attacks, suggesting several strategies but ultimately choosing one that hijacks the control flow of the victim application and executes a system call sequence consistent with the IDS's application model. The attacker's objectives could still be achieved by altering the arguments to these system calls, as the IDS did not monitor system-call arguments. Subsequent works on mimicry attacks [29, 11, 20, 15] have relied on this strategy, combining control-flow hijack with modifications to system-call arguments.

Wagner and Soto formulated the problem of generating such an attack sequence as a finite-state automata intersection problem, generating a mimicry attack consisting of over 100 system calls to achieve the effect of an initial exploit with just 8 system calls. However, they did not implement a working mimicry attack. Tan et al. [29] addressed this, focusing on black-box IDS. Our work is the first to implement a working mimicry attack against real-world applications protected by gray-box IDS.

Gao et al. [11] introduced the term "gray-box anomaly detector" and developed a framework unifying previously known system-call anomaly detectors [16, 27, 8, 34], evaluating their resistance to mimicry attacks. For programs like wu-ftpd and Apache httpd, they showed that the minimum possible length of mimicry attacks ranges from 5 to 50 system calls, increasing with the precision of models.

Recent research has targeted two main challenges in developing mimicry attacks: the manual generation of long attack sequences and the difficulty of making system calls against gray-box IDS. Giiffin et al. [15] used model-checking techniques to generate mimicry attack sequences, incorporating a specification of OS behavior, the program behavior model used by the IDS, and a specification of an "unsafe" OS state desired by the attacker. Their technique can generate all possible mimicry attacks achieving the desired OS state, and can also generate system call arguments. Although their formulation can handle push-down models, their evaluation considered only finite-state models generated by the Stide technique [16], and they did not consider gray-box IDS.

A significant challenge in generating mimicry attacks against gray-box IDS is that system calls cannot be made directly by attack code, as the IDS can detect the presence of a return address on the stack outside the program text. Gao et al. [11] suggested that the attack code should jump to existing code in the victim application, which then makes the system call. However, this means that after the system call, control returns to the application rather than the attack code. To regain control, they proposed modifying a code pointer so that it points back to the attack code. They demonstrated the feasibility of this technique on a small example program, but manual development for realistic programs is challenging.

Kruegel et al. [20] automated the steps needed to regain control using symbolic code execution to compute relationships between memory and register contents at the point where the attack code jumps into the application code, and the code pointers used subsequently. Their analysis identifies if control can be regained and, if so, the memory locations that need to be modified and their contents. They demonstrated their technique on three small example programs and real applications like Apache, showing that about 90% of the time, control could be successfully returned to the attack code. However, their evaluation focused on demonstrating the ability of their symbolic execution technique to generate configurations that return control to the attack code, leaving several additional problems open for constructing working mimicry attacks against real-world applications.

### Conclusion

It is well-known that no intrusion detection system can precisely capture all deviations from an application's correct behavior. Our research shows that, with relatively little engineering effort, adversaries can execute powerful attacks while blending almost undetectably with the normal sequences of system calls. Our attack can evade all system-call-based intrusion detection systems we are familiar with. Powerful system-call monitors that examine almost all system-call arguments will typically prevent persistent interposition attacks from achieving arbitrary goals like gaining a root shell, but we have shown that typical end-goals such as stealing credit cards or hijacking and impersonating servers can be achieved.

Previous mimicry attacks required static analyses to discover system call sequences that can compromise an IDS and to regain control between these system calls. Our technique sidesteps these problems by "co-opting" the vulnerable application into invoking the attack code at convenient points during its execution. This makes persistent interposition attacks practical for today’s hackers to implement using skills and tools they already have, making them a more realistic threat compared to prior mimicry attacks.

Persistent interposition attacks highlight the limitations of system-call monitoring defenses. Any defense that could detect our attack would begin to emulate the monitored victim application, calling into question the feasibility of developing system-call monitors that can reliably detect common code-injection attacks.

Our results do not imply the absence of practical defenses against persistent interposition attacks. As discussed earlier, code injection defenses and memory error exploit defenses will defeat these attacks. However, our results emphasize the importance of deploying dedicated defenses against powerful attack vectors such as memory errors, rather than relying on the secondary line of defense provided by intrusion detection systems.

### References

[1] The PaX team. http://pax.grsecurity.net.
[2] Martin Abadi, Mihai Budiu, Ulfar Erlingsson, and Jay Ligatti. Control-flow integrity - principles, implementations, and applications. In ACM conference on Computer and Communications Security (CCS), 2005.
[3] S. Bhatkar, A. Chaturvedi, and R. Sekar. Dataflow anomaly detection. In IEEE Symposium on Security and Privacy, 2006.
[4] Sandeep Bhatkar, R. Sekar, and Daniel C. DuVarney. Efficient techniques for comprehensive protection from memory error exploits. In Proceedings of the 14th Usenix Security Symposium, pages 271–286, August 2005.
[5] Shuo Chen, Jun Xu, Emre C. Sezer, Prachi Gauriar, and Ravi Iyer. Non-control-data attacks are realistic threats. In USENIX Security Symposium, Baltimore, MD, August 2005.
[6] “Solar Eclipse”. openssl-too-open. http://www.phreedom.org/solar/exploits/apache-openssl/.
[7] H. Feng, J.T. Giiffin, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing sensitivity in static analysis for intrusion detection. In IEEE Symposium on Security and Privacy, 2004.
[8] H. Feng, O. Kolesnikov, P. Folga, W. Lee, and W. Gong. Anomaly detection using call stack information. In IEEE Symposium on Security and Privacy, May 2003.
[9] Prahlad Fogla, Monirul Sharif, Roberto Perdisci, Oleg Kolesnikov, and Wenke Lee. Polymorphic blending attacks. In USENIX Security Symposium, August 2006.
[10] Debin Gao, Michael K. Reiter, and Dawn Song. Gray-box extraction of execution graphs for anomaly detection. In ACM conference on Computer and Communications Security (CCS), pages 318–329, Washington, DC, October 2004.
[18] Calvin Ko, George Fink, and Karl Levitt. Automated detection of vulnerabilities in privileged programs by execution monitoring. In Annual Computer Security Applications Conference (ACSAC), December 1994.
[19] C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detection of anomalous system call arguments. In European Symposium on Research in Computer Security, Gjøvik, Norway, October 2003.
[20] Christopher Kruegel, Engin Kirda, Darren Mutz, William Robertson, and Giovanni Vigna. Automating mimicry attacks using static binary analysis. In USENIX Security Symposium, Baltimore, MD, August 2005.
[21] Christopher Kruegel and Giovanni Vigna. Anomaly detection of web-based attacks. In Proceedings of the 10th ACM Conference on Computer and Communications Security (CCS), 2003.
[22] Lap Chung Lam and T. Chiueh. Automatic extraction of accurate application-specific sandboxing policy. In Recent Advances in Intrusion Detection (RAID), Sophia Antipolis, French Riviera, France, September 2004.
[23] P. Loscocco and S. Smalley. Integrating flexible support for security policies into the Linux operating system. In Proc. of the FREENIX Track: 2001 USENIX Annual Technical Conference, 2001.
[24] George C. Necula, Scott McPeak, and Westley Weimer. CCured: type-safe retrofitting of legacy code. In Symposium on Principles of Programming Languages (POPL ’02), pages 128–139, Portland, OR, January 2002.
[25] Niels Provos. Improving host security with system call policies. In USENIX Security Symposium, Washington, DC, USA, August 2003.
[26] Olatunji Ruwase and Monica S. Lam. A practical dynamic buffer overflow detector. In Network and Distributed System Security Symposium (NDSS), February 2004.
[27] R. Sekar, M. Bendre, P. Bollineni, and D. Dhurjati. A fast automaton-based method for detecting anomalous program behaviors. In IEEE Symposium on Security and Privacy, 2001.
[11] Debin Gao, Michael K. Reiter, and Dawn Song. On gray-box program tracking for anomaly detection. In USENIX Security Symposium, pages 103–118, San Diego, CA, USA, August 2004.
[12] T. Garfinkel, B. Pfaff, and M. Rosenblum. Ostia: A delegating architecture for secure system call interposition. In USENIX Security Symposium, Washington, DC, USA, August 2003.
[28] R. Sekar and P. Uppuluri. Synthesizing fast intrusion prevention/detection systems from high-level specifications. In Usenix Security Symposium, August 1999.
[29] Kymie Tan, Kevin Killourhy, and Roy Maxion. Undermining an anomaly-based intrusion detection system using common exploits. In Recent Advances in Intrusion Detection (RAID), LNCS 2516, pages 54–73, Zurich, Switzerland, October 2002. Springer-Verlag.
[13] Jonathon T. Giiffin, David Dagon, Somesh Jha, Wenke Lee, and Barton P. Miller. Environment-sensitive intrusion detection. In Recent Advances in Intrusion Detection (RAID), September 2005.
[30] G. Tandon and P. Chan. Learning rules from system call arguments and sequences for anomaly detection. In ICDM Workshop on Data Mining for Computer Security (DMSEC), pages 20–29, 2003.
[14] Jonathon T. Giiffin, Somesh Jha, and Barton P. Miller. Efficient context-sensitive intrusion detection. In Network and Distributed System Security Symposium, San Diego, CA, February 2004.
[15] Jonathon T. Giiffin, Somesh Jha, and Barton P. Miller. Automated discovery of mimicry attacks. In Diego Zamboni and Christopher Krügel, editors, RAID, volume 4219 of Lecture Notes in Computer Science, pages 41–60. Springer, 2006.
[16] Steven A. Hofmeyr, Stephanie Forrest, and Anil Somayaji. Intrusion detection using sequences of system calls. Journal of Computer Security (JCS), 6(3):151–180, 1998.
[17] Robert W. M. Jones and Paul H. J. Kelly. Backwards-compatible bounds checking for arrays and pointers in C programs. In M. Kamkar and D. Byers, editors, Third International Workshop on Automated Debugging. Linkoping University Electronic Press, 1997.
[31] D. Wagner and P. Soto. Mimicry attacks on host-based intrusion detection systems. In ACM conference on Computer and Communications Security (CCS), 2002.
[32] David Wagner and Drew Dean. Intrusion detection via static analysis. In IEEE Symposium on Security and Privacy, Oakland, CA, May 2001.
[33] Ke Wang and Salvatore J. Stolfo. Anomalous payload-based network intrusion detection. In Proceeding of 7th International Symposium on Recent Advances in Intrusion Detection (RAID), 2004.
[34] A. Wespi, M. Dacier, and H. Debar. Intrusion detection using variable-length audit trail patterns. In Recent Advances in Intrusion Detection (RAID), Toulouse, France, October 2000.