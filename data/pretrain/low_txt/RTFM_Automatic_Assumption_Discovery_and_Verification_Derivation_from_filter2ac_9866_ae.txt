### 1. Introduction to the Problem and Proposed Solution

Certain code descriptions (CDs) in the library `libdbus` or other libraries are difficult to comprehend and translate, such as “if it wants to be able to provide clients with OCSP Certificate Status responses.” One potential approach to automate this process is to customize existing automatic programming techniques [28, 39] to construct a verification condition (VC) for a rare CD based on its smaller syntactic units, like “array-typed value.” Additionally, we observed that some rare CDs share semantic similarities with popular ones, which could allow us to adapt existing VCs to check these CDs. These directions will be explored in our follow-up research.

### 2. Related Work

In recent years, numerous studies have leveraged text analysis techniques to automatically discover various types of bugs, including access control misconfigurations, inappropriate permission requests, and logic flaws. For example, Zimmeck et al. [55] check the compliance between Android apps and privacy requirements. WHYPER [43] and AutoCog [45] investigate whether Android apps properly indicate their permission usage in their app descriptions. Tan et al. [47] extract implicit program rules from comments and use these rules to detect inconsistencies between comments and source code. Goffi et al. [27] and Blasi et al. [22] generate test oracles from documentation to dynamically find inconsistencies between documentation and code implementation. Zhong et al. [54] and Pandita et al. [42] extract API call sequence information from documentation to check for inconsistencies.

Unlike previous works, our research provides an end-to-end approach to detect security-critical API misuse in real-world applications.

### 3. Discovery of Integration Assumptions (IAs)

Previous works primarily used keyword-based [47] or template-matching [44] approaches to discover IAs. For instance, Tan et al. [47] use predefined keywords like “should” and “must” to extract IAs, but this method results in a high false-negative rate. Pandita et al. [44] and Chen et al. [23] define shallow parsing templates such as “(VB) (.)? (PRN)?” or regex templates like “Check the seller_id represents the supposed merchant” for IA extraction. In contrast, our research proposes a corpora-insensitive and efficient IA discovery method based on a bidirectional GRU model with attention.

### 4. Automatic API Misuse Detection

Another set of studies focuses on automatic API misuse detection through static or dynamic program analysis. For example, Mithun et al. [21], Kang et al. [30], and Li et al. [36] leverage manually crafted rules to statically find API error-handling blocks (EHBs). Hoan et al. [41] collect execution paths leading to API calls and derive potential preconditions for such invocations. Yun et al. [52] generate symbolic contexts with relaxed symbolic execution and explore common API context patterns. Maria et al. [31] combine static exception propagation analysis with automatic search-based test case generation to pinpoint crash-prone API misuses in client applications. For dynamic analysis, Wen et al. [50] discover API misuse patterns via mutation analysis. Unlike these methods, our approach does not rely heavily on the code set to infer IAs and uses machine learning to capture API misuses, thus reducing the risk of missing misuse cases due to low-quality code sets.

### 5. Conclusion

In this paper, we present a new technique for automatically detecting API misuses in applications by analyzing library documentation. Leveraging recent advancements in machine learning and natural language processing (NLP), our approach uses sentiment analysis to discover integration assumptions from documentation, tree mining to identify commonly-used CDs, and lexical and semantic analysis to resolve implicit references. When applied to the documentation of five libraries and 39 real-world applications, our prototype, Advance, successfully detected 193 API misuses, with 139 previously unreported, outperforming all existing approaches. This study demonstrates that new advancements in intelligent technologies can significantly improve security science, even for long-studied problems like API misuse detection.

### 6. Acknowledgments

The IIE authors are supported in part by the Beijing Natural Science Foundation (No. JQ18011), NSFC U1836211, National Top-notch Youth Talents Program of China, Youth Innovation Promotion Association CAS, Beijing Nova Program, National Frontier Science and Technology Innovation Project (No. YJKYYQ20170070), and the Beijing Academy of Artificial Intelligence (BAAI).

### 7. References

[1] StanfordParser. (2016). https://nlp.stanford.edu/software/dependencies_manual.pdf.
[2] AFL fuzzer. (2020). https://lcamtuf.coredump.cx/afl/.
[3] Atril for MATE. (2020). https://mate-desktop.org/.
[4] CodeQL. (2020). https://securitylab.github.com/tools/codeql.
[5] Confirmed bug. (2020). https://gitlab.gnome.org/GNOME/anjuta/-/issues/12.
[6] Confirmed bug. (2020). https://gitlab.kitware.com/vtk/vtk/issues/17818.
[7] Confirmed bug. (2020). https://bz.apache.org/bugzilla/show_bug.cgi?id=64264.
[8] Confirmed bug. (2020). https://github.com/hughsie/colord/issues/110.
[9] Confirmed bug. (2020). https://github.com/darktable-org/darktable/issues/6051.
[10] Confirmed bug. (2020). https://github.com/mate-desktop/atril/issues/485.
[11] Confirmed bug. (2020). https://gitlab.gnome.org/GNOME/at-spi2-core/-/issues/24.
[12] CVE-2015-8867. (2020). https://nvd.nist.gov/vuln/detail/CVE-2015-8867.
[13] GitHub. (2020). https://github.com/.
[14] GitLab. (2020). https://about.gitlab.com/.
[15] Google Translation. (2020). https://translate.google.cn.
[16] lxml. (2020). https://lxml.de/.
[17] man3. (2020). https://linux.die.net/man/3/.
[18] National Vulnerability Database. (2020). https://nvd.nist.gov/vuln/search.
[19] SourceForge. (2020). https://sourceforge.net/.
[20] Ubuntu. (2020). https://packages.ubuntu.com/en/xenial/libs/.

[21] Acharya, M., & Xie, T. (2009). Mining API error-handling specifications from source code. In International Conference on Fundamental Approaches to Software Engineering. Springer, 370–384.
[22] Blasi, A., Goffi, A., Kuznetsov, K., Gorla, A., Ernst, M. D., Pezzè, M., & Castellanos, S. D. (2018). Translating code comments to procedure specifications. In Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis. ACM, 242–253.
[23] Chen, Y., Xing, L., Qin, Y., Liao, X., Wang, X., Chen, K., & Zou, W. (2019). Devils in the guidance: predicting logic vulnerabilities in payment syndication services through automated documentation analysis. In 28th USENIX Security Symposium (USENIX Security 19). 747–764.
[24] Chung, J., Gulcehre, C., Cho, K., & Bengio, Y. (2014). Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. (12 2014).
[25] Edunov, S., Ott, M., Auli, M., & Grangier, D. (2018). Understanding Back-Translation at Scale. (08 2018).
[26] Gardner, M., Grus, J., Neumann, M., Tafjord, O., Dasigi, P., Liu, N. F., Peters, M., Schmitz, M., & Zettlemoyer, L. S. (2017). AllenNLP: A Deep Semantic Natural Language Processing Platform. arXiv:arXiv:1803.07640.
[27] Goffi, A., Gorla, A., Ernst, M. D., & Pezzè, M. (2016). Automatic generation of oracles for exceptional behaviors. In Proceedings of the 25th International Symposium on Software Testing and Analysis. 213–224.
[28] Gulwani, S., Polozov, O., Singh, R., et al. (2017). Program synthesis. Foundations and Trends® in Programming Languages 4, 1-2 (2017), 1–119.
[29] huggingface. (2020). neuralcoref. https://github.com/huggingface/neuralcoref.
[30] Kang, Y., Ray, B., & Jana, S. (2016). APEx: Automated Inference of Error Specifications for C APIs. In 31st IEEE/ACM International Conference on Automated Software Engineering (ASE). Singapore.
[31] Kechagia, M., Devroey, X., Panichella, A., Gousios, G., & van Deursen, A. (2019). Effective and efficient API misuse detection via exception propagation and search-based testing. In Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis. 192–203.
[32] Kim, Y. (2014). Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882 (2014).
[33] Klees, G., Ruef, A., Cooper, B., Wei, S., & Hicks, M. (2018). Evaluating fuzz testing. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. 2123–2138.
[34] Lai, S., Xu, L., Liu, K., & Zhao, J. (2015). Recurrent convolutional neural networks for text classification. In Twenty-ninth AAAI conference on artificial intelligence.
[35] Li, C., Gu, Z., Zhou, M., Wu, J., Zhang, J., & Gu, M. (2019). API Misuse Detection in C Programs: Practice on SSL APIs. International Journal of Software Engineering and Knowledge Engineering 29, 11&12 (2019), 1761–1779. https://doi.org/10.1142/S0218194019400205
[36] Li, C., Zhou, M., Gu, Z., Gu, M., & Zhang, H. (2019). Ares: inferring error specifications through static analysis. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 1174–1177.
[37] Li, Z., & Zhou, Y. (2005). PR-Miner: automatically extracting implicit programming rules and detecting violations in large software code. In Proceedings of the 10th European Software Engineering Conference held jointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering, 2005, Lisbon, Portugal, September 5-9, 2005, Michel Wermelinger and Harald C. Gall (Eds.). ACM, 306–315. https://doi.org/10.1145/1081706.1081755
[38] Lynten. (2018). stanfordcorenlp. https://github.com/Lynten/stanford-corenlp.
[39] Mahanipour, A., & Nezamabadi-Pour, H. (2019). GSP: an automatic programming technique with gravitational search algorithm. Applied Intelligence 49, 4 (2019), 1502–1516.
[40] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111–3119.
[41] Nguyen, H. A., Dyer, R., Nguyen, T. N., & Rajan, H. (2014). Mining preconditions of APIs in large-scale code corpus. In Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering. 166–177.
[42] Pandita, R., Taneja, K., Williams, L. A., & Tung, T. (2016). ICON: Inferring Temporal Constraints from Natural Language API Descriptions. 2016 IEEE International Conference on Software Maintenance and Evolution (ICSME) (2016), 378–388.
[43] Pandita, R., Xiao, X., Yang, W., Enck, W., & Xie, T. (2013). WHYPER: Towards Automating Risk Assessment of Mobile Applications. In 22nd USENIX Security Symposium (USENIX Security 13). USENIX Association, Washington, D.C., 527–542. https://www.usenix.org/conference/usenixsecurity13/technical-sessions/presentation/pandita
[44] Pandita, R., Xiao, X., Zhong, H., Xie, T., Oney, S., & Paradkar, A. (2012). Inferring method specifications from natural language API descriptions. In 2012 34th International Conference on Software Engineering (ICSE). IEEE, 815–825.
[45] Qu, Z., Rastogi, V., Zhang, X., Chen, Y., Zhu, T., & Chen, Z. (2014). Autocog: Measuring the description-to-permission fidelity in android applications. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. 1354–1365.
[46] Sha, F., & Pereira, F. (2003). Shallow Parsing with Conditional Random Fields. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. 213–220. https://www.aclweb.org/anthology/N03-1028
[47] Tan, L., Yuan, D., Krishna, G., & Zhou, Y. (2007). /* iComment: Bugs or bad comments?*. In ACM SIGOPS Operating Systems Review, Vol. 41. ACM, 145–158.
[48] Tan, S. H., Marinov, D., Tan, L., & Leavens, G. T. (2012). @ tcomment: Testing javadoc comments to detect comment-code inconsistencies. In 2012 IEEE Fifth International Conference on Software Testing, Verification and Validation. IEEE, 260–269.
[49] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention is All You Need. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, & R. Garnett (Eds.). Curran Associates, Inc., 5998–6008. http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf
[50] Wen, M., Liu, Y., Wu, R., Xie, X., Cheung, S.-C., & Su, Z. (2019). Exposing library API misuses via mutation analysis. In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 866–877.
[51] Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). Hierarchical attention networks for document classification. In Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies. 1480–1489.
[52] Yun, I., Min, C., Si, X., Jang, Y., Kim, T., & Naik, M. (2016). APISan: Sanitizing API Usages through Semantic Cross-Checking. In 25th USENIX Security Symposium, USENIX Security 16, Austin, TX, USA, August 10-12, 2016, Thorsten Holz & Stefan Savage (Eds.). USENIX Association, 363–378. https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/yun
[53] Zaki, M. J. (2005). Efficiently mining frequent trees in a forest: Algorithms and applications. IEEE transactions on knowledge and data engineering 17, 8 (2005), 1021–1035.
[54] Zhong, H., Zhang, L., Xie, T., & Mei, H. (2009). Inferring resource specifications from natural language API documentation. In 2009 IEEE/ACM International Conference on Automated Software Engineering. IEEE, 307–318.
[55] Zimmeck, S., Wang, Z., Zou, L., Iyengar, R., Liu, B., Schaub, F., Wilson, S., Sadeh, N., Bellovin, S. M., & Reidenberg, J. (2017). Automated Analysis of Privacy Requirements for Mobile Apps. Korea Society of Internet Information, Korea, Republic of. https://doi.org/10.14722/ndss.2017.23034
[56] Řehůřek, R. (2019). gensim. https://radimrehurek.com/gensim/. (2019).

### 8. Appendix

**Figure 7: Bidirectional GRU Model with Attention**

**Algorithm 1: Traverse the CD Tree**

```plaintext
Input: 𝐶𝐷_𝑡𝑟𝑒𝑒
Output: 𝑉𝐶

1: while 𝑔𝑒𝑡_𝑛𝑜𝑑𝑒𝑠(𝐶𝐷_𝑡𝑟𝑒𝑒) > 2 do
2:     𝑙𝑒𝑎𝑓 ← 𝑠𝑒𝑙𝑒𝑐𝑡_𝑙𝑒𝑎𝑓 (𝐶𝐷_𝑡𝑟𝑒𝑒)
3:     𝑠𝑖𝑏𝑙𝑖𝑛𝑔𝑠 ← 𝑔𝑒𝑡_𝑠𝑖𝑏𝑙𝑖𝑛𝑔𝑠(𝑙𝑒𝑎𝑓 )
4:     𝑝𝑎𝑟𝑒𝑛𝑡 ← 𝑔𝑒𝑡_𝑝𝑎𝑟𝑒𝑛𝑡(𝑙𝑒𝑎𝑓 )
5:     𝑛𝑒𝑤_𝑛𝑜𝑑𝑒 ← 𝑔𝑒𝑛_𝑛𝑜𝑑𝑒(𝑠𝑖𝑏𝑙𝑖𝑛𝑔𝑠, 𝑙𝑒𝑎𝑓 , 𝑝𝑎𝑟𝑒𝑛𝑡)
6:     𝑟𝑒𝑝𝑙𝑎𝑐𝑒(𝐶𝐷_𝑡𝑟𝑒𝑒, 𝑝𝑎𝑟𝑒𝑛𝑡, 𝑛𝑒𝑤_𝑛𝑜𝑑𝑒)
7: end while
8: 𝑉𝐶 ← 𝐶𝐷_𝑡𝑟𝑒𝑒.𝑟𝑜𝑜𝑡()
```

**Table 3: Dependent Tools and SLoC of Each Component in Advance**

| Components       | Dependent Tools                | SLoC  |
|------------------|--------------------------------|-------|
| IA Discovery     | Gensim, Stanford-NLP, Keras    | 3K    |
| IA Dereference   | Gensim, Stanford-NLP, NLTK    | 1K    |
| VC Generation    | Allennlp, CodeQL               | 1K    |

**Listing 3: An Example of False Positives**

```c
ptr = xmlGetProp(...);
list = g_list_append(list, ptr);
for (iter = g_list_first(list); iter != NULL; iter = g_list_next(iter))
    g_free(iter->data);
```

**Listing 4: Verification Code**

```cpp
import cpp, nullCheck
from FunctionCall fc
where fc.getTarget().hasName("xmlDocGetRootElement")
select fc.getLocation() and not nullcheck(fc)
```

**Table 4: List of Manually-Validated API Misuses Reported by Advance**

| Advance | APISAN | APEx | AFL |
|---------|--------|------|-----|
| 0       | 0      | 0    | 0   |
| 0       | 0      | 0    | 0   |
| 0       | 0      | 0    | 0   |
| 0       | 0      | 0    | 0   |
| 0       | 0      | 0    | 0   |
| 0       | 0      | 0    | 0   |
| 0       | 0      | 0    | 0   |
| 0       | 0      | 0    | 0   |

Note: The table includes 139 undisclosed (labeled with "*" in the "Advance" column) and 54 disclosed API misuses.