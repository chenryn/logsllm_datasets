### Aggregating Operations and Transaction Performance

As shown in Table 2, aggregating operations to create larger transactions increases the number of writes linearly. However, the number of unique pages modified by these operations remains largely unchanged. This is because most operations modify data on the same set of pages. Consequently, aggregating operations to form larger transactions should benefit page-tracking-based approaches, which heavily rely on Page-Tracking (PPT). In contrast, emulation-based approaches, which are independent of PPT but dependent on Write-Page-Tracking (WPP), will maintain their performance.

In this subsection, we evaluate the performance of larger transactions with OPT=5. Figure 14 illustrates the speedup of hypervisor-assisted approaches over their user-level counterparts for OPT=5. As expected, the results are similar to those for OPT=1 (Figure 12). Both PT and PTxen achieve a fivefold improvement with transaction aggregation, maintaining their relative performance. Emulxen shows a speedup of up to four times, while PTxen achieves a speedup of up to thirteen times over their user-level counterparts.

### Data Processing Overhead

At the end of the checkpoint cycle, the modified blocks of critical data areas must be either stored to disk or transferred to the backup machine over a network. Page tracking and emulation-based techniques process different amounts of data. In our experiments, we consider the case where OPT=1. Transaction aggregation, as noted earlier, would yield better performance (i.e., lower data processing overhead) for page-tracking-based approaches.

Figure 13 demonstrates that, in most cases, the user-level implementation of the page-tracking-based approach (PT) outperforms the emulation-based user-level approach (Emul). This contrasts with Figure 11, where Emul outperformed PT in many cases, highlighting the impact of decreased PPT on the performance of page-tracking-based approaches. Compared to Figure 11, the graphs in Figure 13 show a fivefold speedup for page-tracking-based approaches, while emulation-based approaches show no significant difference in performance.

Figures 15 and 16 illustrate the amount of data processed by each technique. Page-tracking-based approaches handle data in the order of hundreds of megabytes. In contrast, emulation-based approaches typically process less than 2MB of data (with the exception of tree-insert, where the value of 56MB is too large to scale).

Typical implementations do not have the main process handle data processing. Instead, writing to disk or transferring data to the backup is usually done by a separate thread or helper process. In multi-core machines, the helper process can run in parallel on an additional CPU core, allowing the main process to continue without stalling. The only additional overhead for the main application is copying the modified data to the helper process. The helper process can then save the modified data as-is or perform further processing, such as difference computation, data compression, or encryption for security. In this work, we focus on the overhead incurred by the main application, specifically the cost of memory copy.

For page-tracking-based approaches, the main application incurs the overhead of copying the entire modified pages to the helper process, as it does not track changes within the page. In contrast, emulation-based approaches keep track of modifications at word granularity, requiring the application to copy only the modified words.

Figure 17 shows the total time spent (including 10,000 operations and data copy to the helper process) by each approach for OPT=1. We observe that emulation-based approaches typically take less than 5ms (average < 1ms), whereas page-tracking-based approaches have a higher overhead, ranging from 10ms to 80ms. However, when considering the total time metric, the overall performance improvements due to hypervisor assistance are evident, as shown in Figure 18. PTxen improves performance over PT by approximately a factor of 8, while Emulxen improves over Emul by approximately a factor of 4. These improvements are slightly lower than those in Figure 12 due to the constant overhead of memory copy. Transaction aggregation (e.g., OPT=5) will further enhance the benefits of PTxen over PT, as page reuse within larger transactions reduces the amount of data copied.

### Conclusion

In this paper, we discussed application-assisted checkpointing in virtualized environments. We identified the root cause of the performance bottleneck in application checkpointing under virtualization and introduced the concept of hypervisor-assisted application checkpointing. Our approach implements key primitives for application checkpointing within the hypervisor and introduces direct and secure application-to-hypervisor interaction, allowing deployment without changes to the guest operating system. Our techniques can also be applied to non-virtualized environments by incorporating them into the OS instead of the hypervisor.

We designed and implemented a family of lightweight application checkpointing techniques. Our prototype for the Xen hypervisor added only a few hundred lines of code, totaling about 0.2% of the hypervisor code. Emulation-based techniques are useful for small transactions, while page-tracking approaches with hypervisor assistance show the best results. Compared to user-space implementations, our hypervisor-assisted application checkpointing shows impressive performance gains of 4x to 10x based on microbenchmark results and 4x to 13x based on workload evaluation.

### References

[1] E.N. Elnozahy, L. Alvisi, Y-M. Wang, and D.B. Johnson, "A survey of rollback-recovery protocols in message-passing systems", ACM Comput. Surv., vol. 34, no. 3, pp. 375-408, 2002.
[2] Yi-Min Wang, Yennun Huang, Kiem-Phong Vo, Pe-Yu Chung, C. Kintala, "Checkpointing and Its Applications," Twenty-Fifth International Symposium on Fault-Tolerant Computing (FTCS), 1995, Pasadena, CA.
[3] Plank, J.S. and Kai Li, “Libckpt: Transparent Checkpointing under Unix,” Conference Proceedings, Usenix Winter 1995 Technical Conference, New Orleans, LA, January, 1995.
[4] Jason Ansel, Kapil Arya, and Gene Cooperman, “DMTCP: Transparent Checkpointing for Cluster Computations and the Desktop,” 23rd IEEE International Parallel and Distributed Processing Symposium (IPDPS'09), Rome, Italy, May, 2009.
[5] Michael Litzkow, Todd Tannenbaum, Jim Basney, and Miron Livny, “Checkpoint and migration of UNIX processes in the Condor distributed processing system.” Technical Report CS-TR-199701346, University of Wisconsin, Madison, 1997.
[8] J. Janakiraman, J. R. Santos, D. Subhraveti, and Y. Turner, “Cruz: Application-Transparent Distributed Checkpoint-Restart on Standard Operating Systems.” In Proceedings of the International Conference on Dependable Systems and Networks (DSN’05), Yokohama, Japan, June 2005.
[9] K. M. Chandy and L. Lamport, “Distributed Snapshots: Determining Global States of Distributed Systems.” ACM Transactions on Computer Systems, 3(1):63–75, Feb. 1985.
[10] G. Deconinck, J. Vounckx, R. Lauwereins, J. A. Peperstraete, “A User-Triggered Checkpointing Library for Computation-Intensive Applications,” In Proceedings of 7th IASTED-ISMM International Conference on Parallel and Distributed Computing and Systems (IASTED, Anaheim-Calgary-Zurich) (ISCC97).
[11] L.M. Silva and J.G. Silva, “System-Level Versus User-Defined Checkpointing,” SRDS '98 Proceedings of the 17th IEEE Symposium on Reliable Distributed Systems.
[12] Junyoung Heo, Sangho Yi, Yookun Cho, Jiman Hong, Sung Y. Shin, “Space-efficient page-level incremental checkpointing,” Proceedings of the 2005 ACM symposium on Applied computing, March 13-17, 2005, Santa Fe, New Mexico.
[13] Thomas C. Bressoud, “Hypervisor-based Fault-tolerance,” Proceedings of the 15th ACM symposium on operating systems principles, Vol. 29, No. 5. (December 1995), pp. 1-11.
[14] Kernel-based Virtual Machine (KVM) for Linux, http://www.linux-kvm.org, Last accessed on April 12, 2011.
[15] VMware vSphere – VMware virtualization platform, http://www.vmware.com/products/vsphere/overview.html, Last accessed on April 12, 2011.
[16] Xen 4.1, “http://www.xen.org/files/Xen_4_1_Datasheet.pdf” Last accessed on April 12, 2011.
[17] C. Clark et al, “Live Migration of Virtual Machines,” Proceedings of the 2nd ACM/USENIX Symposium on Networked Systems Design and Implementation (NSDI) 2005, pp. 273-286.
[18] L. Wang, Z. Kalbarczyk, R.K. Iyer, A. Iyengar, "Checkpointing virtual machines against transient errors," Proceedings of the IEEE 16th International On-Line Testing Symposium (IOLTS), pp.97-102, July 2010.
[19] Brendan Cully et al., “Remus: high availability via asynchronous virtual machine replication,” In NSDI'08: Proceedings of the 5th USENIX Symposium on Networked Systems Design and Implementation (2008), pp. 161-174.
[20] Y. Tamura, “Kemari: Virtual Machine Synchronization for Fault Tolerance using DomT,” Xen Summit 2008, Boston, MA.
[21] A.W. Appel and K. Li, “Virtual memory primitives for user programs,” ASPLOS-IV Proceedings of the fourth international conference on Architectural support for programming languages and operating systems, 1991.
[22] S. T. Jones, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dusseau, “Antfarm: Tracking processes in a virtual machine environment,” In Proc. USENIX Annual Technical Conference, 2006.
[6] Hua Zhong and Jason Nieh, “CRAK: Linux Checkpoint / Restart As a Kernel Module.” Technical Report CUCS-014-01. Department of Computer Science. Columbia University, November 2002.
[23] S. T. Jones, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dusseau, “Geiger: Monitoring the buffer cache in a virtual machine environment,” In Proc. ASPLOS-XII, 2006.
[7] Oren Laadan and Jason Nieh, "Transparent Checkpoint-Restart of Multiple Processes on Commodity Operating Systems," Proceedings of the 2007 USENIX Annual Technical Conference, Santa Clara, CA, June 17-22, 2007, pp. 323-336.
[24] “Xen for upstream paravirt_ops kernel,” http://wiki.xensource.com/xenwiki/XenParavirtOps, Last accessed on April 12, 2011.
[25] Mark A. Weiss, “Data Structures and Algorithm Analysis,” Second Edition, Addison Wesley.

---

This revised version aims to improve clarity, coherence, and professionalism, ensuring that the content is well-structured and easy to follow.