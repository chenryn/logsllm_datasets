### Initial System Load and Runtime Checks

Initially, the system is moderately loaded, with all requests being processed using runtime checks. As the load increases at time \( t_1 \), the fraction of checked executions drops to zero. When the request rate returns to its original level at time \( t_2 \), the system resumes processing requests with runtime checks. The delay between \( t_2 \) and the point at which the rate of checked executions rebounds is due to the large number of pending requests in the system. Once this backlog is cleared, the fraction of checked executions returns to 1.0.

### Dynamic Adaptation of Software Variants

Figure 10 presents the overhead for different diversification methods, normalized to the execution time of the version without runtime checks. Although the absolute numbers are not critical, their relative values are important. Methods such as Assertion, OverAllocate, and NullWrite exhibit very low overhead. Since typical applications read memory more frequently than they write to it, NullRead, which employs more runtime checks, is more expensive.

SWIFT and SWIFTCFC have significantly higher overheads compared to other diversification methods, even exceeding those reported in the literature [4]. This is due to our implementation, which does not use any of the optimizations presented in [4].

### Performance Metrics and Workload

The overhead of various diversification methods is shown in Figure 10. The slowdown is measured for different applications, including MD5, LibPNG, Wordcount, and Zoologist. The fraction of executed checked versions is illustrated in Figure 11, showing how Aaron adapts the runtime checking by choosing cheaper variants more frequently as the system utilization increases.

### Future Work

In future work, we plan to extend Aaron in three directions:
1. **Dynamic Stack Rewriting**: Using dynamic stack rewriting, Aaron could switch between different variants during the processing of a single task, enabling it to operate on non-task-oriented applications.
2. **Hardware Replication**: We aim to extend Aaron into the hardware domain by dynamically replicating applications. Depending on the cluster environment's load, replication can be used to increase fault coverage, and we will downscale replication if throughput demands necessitate it.
3. **New Metrics for Decision Making**: We plan to explore new metrics to determine when runtime checks should be employed.

### Related Work

Many approaches to fault detection require significant additional resources, both in terms of hardware and software. For example, the replicated state machine approach using Byzantine fault-tolerant (BFT) protocols [19, 20] requires a minimum of \( 3F + 1 \) machines to tolerate \( F \) independent faults. Another approach is lockstep execution, as used in Orchestra [21], which applies automatic software diversity. Unlike BFT protocols and Orchestra, Aaron targets deployed systems with throughput-critical applications and switches on checking only if it does not affect throughput.

### Conclusion

For current server systems, the difference in power consumption between average and peak loads is small. Assuming an average load of 50%, using the remaining computing resources costs only about 14% in terms of power consumption. Aaron exploits these spare cycles to schedule automatically diversified software variants, maximizing fault coverage without affecting system performance in terms of throughput or responsiveness. Aaron enables the use of automatic software diversification methods, even if their overheads are high, and adapts failure coverage based on the current load situation.

### Acknowledgements

The authors thank Martin Nowack for valuable discussions and Figure 1. Parts of this research were funded in the context of the SRT-15 project by the European Commission under the Seventh Framework Program (FP7) with grant agreement number 257843.

### References

[1] B. Schroeder and G. A. Gibson, “A large-scale study of failures in high-performance computing systems,” in Proceedings of the International Conference on Dependable Systems and Networks (DSN), 2006.
[2] R. W. M. Jones and P. H. J. Kelly, “Backwards-compatible bounds checking for arrays and pointers in C programs,” in Proceedings of the 3rd International Workshop on Automatic Debugging (AADEBUG), 1997.
[3] C. Wang, H. seop Kim, Y. Wu, and V. Ying, “Compiler-managed software-based redundant multi-threading for transient fault detection,” in Proceedings of the International Symposium on Code Generation and Optimization (CGO), 2007.
[4] G. A. Reis, J. Chang, N. Vachharajani, R. Rangan, and D. I. August, “SWIFT: Software implemented fault tolerance,” in Proceedings of the International Symposium on Code generation and optimization (CGO), 2005.
[5] U. Schiffel, M. Süsskraut, and C. Fetzer, “An-encoding compiler: Building safety-critical systems with commodity hardware,” in Proceedings of the 28th International Conference on Computer Safety, Reliability, and Security (SAFECOMP), 2009.
[6] B. Randell, “System structure for software fault tolerance,” in Proceedings of the International Conference on Reliable Software, 1975.
[7] M. Castro, M. Costa, and T. L. Harris, “Securing software by enforcing data-flow integrity,” in Proceedings of the 7th Symposium on Operating Systems Design and Implementation (OSDI), 2006.
[8] G. Novark, E. D. Berger, and B. G. Zorn, “Exterminator: automatically correcting memory errors with high probability,” in Proceedings of the 2007 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2007.
[9] F. Qin, J. Tucek, J. Sundaresan, and Y. Zhou, “Rx: treating bugs as allergies – a safe method to survive software failures,” in Proceedings of the 20th ACM Symposium on Operating Systems Principles (SOSP), 2005.
[10] M. W. Stephenson, R. Rangan, E. Yashchin, and E. V. Hensbergen, “Statistically regulating program behavior via mainstream computing,” in Proceedings of the 8th Annual IEEE/ACM International Symposium on Code Generation and Optimization (CGO), 2010.
[11] M. Costa, M. Castro, L. Zhou, L. Zhang, and M. Peinado, “Bouncer: securing software by blocking bad input,” in Proceedings of twenty-first ACM SIGOPS symposium on Operating systems principles (SOSP), 2007.
[12] X. Liu, Z. Guo, X. Wang, F. Chen, X. Lian, J. Tang, M. Wu, F. M. Kaashoek, and Z. Zhang, “D3s: Debugging deployed distributed systems,” in Proceedings of the 5th USENIX Symposium on Networked Systems Design and Implementation (NSDI), 2008.
[13] C. Lattner and V. Adve, “LLVM: A compilation framework for lifelong program analysis & transformation,” in Proceedings of the International Symposium on Code Generation and Optimization (CGO), 2004.
[14] M. Rinard, C. Cadar, D. Dumitran, D. M. Roy, T. Leu, and W. S. Beebee, Jr., “Enhancing server availability and security through failure-oblivious computing,” in Proceedings of the 6th Symposium on Operating Systems Design & Implementation (OSDI), 2004.
[15] G. A. Reis, J. Chang, and D. I. August, “Automatic instruction-level software-only recovery,” IEEE Micro, vol. 27, pp. 36–47, Jan 2007.
[16] U. Hölzle and L. A. Barroso, The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines, 1st ed. Morgan and Claypool Publishers, 2009.
[17] M. Süsskraut, S. Weigert, T. Knauth, U. Schiffel, M. Meinhold, and C. Fetzer, “Prospect: A compiler framework for speculative parallelization,” in Proceedings of The 8th International Symposium on Code Generation and Optimization (CGO), 2010.
[18] P. Hunt, M. Konar, F. P. Junqueira, and B. Reed, “Zookeeper: wait-free coordination for internet-scale systems,” in Proceedings of the USENIX annual technical conference 2010 (USENIXATC), 2010.
[19] M. Abd-El-Malek, G. R. Ganger, G. R. Goodson, M. K. Reiter, and J. J. Wylie, “Fault-scalable byzantine fault-tolerant services,” in Proceedings of the 20th ACM Symposium on Operating Systems Principles (SOSP), 2005.
[20] A. Clement, E. Wong, L. Alvisi, M. Dahlin, and M. Marchetti, “Making byzantine fault tolerant systems tolerate byzantine faults,” in Proceedings of the 6th USENIX Symposium on Networked Systems Design and Implementation (NSDI), 2009.
[21] B. Salamat, T. Jackson, A. Gal, and M. Franz, “Orchestra: intrusion detection using parallel execution and monitoring of program variants in user-space,” in EuroSys ’09: Proceedings of the fourth ACM european conference on Computer systems. New York, NY, USA: ACM, 2009, pp. 33–46.
[22] X. Liu, “Wids checker: Combating bugs in distributed systems,” in Proceedings of the 4th USENIX Symposium on Networked Systems Design and Implementation (NSDI), 2007.
[23] D. Geels, G. Altekar, P. Maniatis, T. Roscoe, and I. Stoica, “Friday: Global comprehension for distributed replay,” in Proceedings of the 4th USENIX Symposium on Networked Systems Design and Implementation (NSDI), 2007.
[24] I. Cohen, M. Goldszmidt, T. Kelly, and J. Symons, “Correlating instrumentation data to system states: A building block for automated diagnosis and control,” in Proceedings of the 6th Symposium on Operating System Design and Implementation (OSDI), 2004.
[25] Z. Li, M. Zhang, Z. Zhu, Y. Chen, A. Greenberg, and Y.-M. Wang, “Webprophet: Automating performance prediction for web services,” in Proceedings of the 7th USENIX Symposium on Networked Systems Design and Implementation (NSDI), 2010.
[26] A. Depoutovitch and M. Stumm, “Software error early detection system based on run-time statistical analysis of function return values,” in 1st Workshop on Hot Topics in Autonomic Computing, 2006.
[27] S. K. Cha, I. Moraru, J. Jang, J. Truelove, D. Brumley, and D. G. Andersen, “Splitscreen: enabling efficient, distributed malware detection,” in Proceedings of the 7th USENIX Conference on Networked Systems Design and Implementation (NSDI), 2010.
[28] G. Candea, S. Kawamoto, Y. Fujiki, G. Friedman, and A. Fox, “Microreboot - a technique for cheap recovery,” in 6th Symposium on Operating System Design and Implementation (OSDI), 2004.
[29] F. Zhou, J. Condit, Z. R. Anderson, I. Bagrak, R. Enbody, and T. M. Chilimbi, “SafeDrive: Safe and recoverable extensions using language-based techniques,” in 7th Symposium on Operating Systems Design and Implementation (OSDI), 2006.
[30] Ú. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and G. C. Necula, “XFI: Software guards for system address spaces,” in 7th Symposium on Operating Systems Design and Implementation (OSDI), 2006.
[31] J. Dean and S. Ghemawat, “MapReduce: Simplified data processing on large clusters,” in 6th Symposium on Operating System Design and Implementation (OSDI), 2004.
[32] Y. Yu, M. Isard, D. Fetterly, M. Budiu, Ú. Erlingsson, P. K. Gunda, and J. Currey, “DryadLINQ: A system for general-purpose distributed data-parallel computing using a high-level language,” in 8th USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2008.
[33] M. Zaharia, A. Konwinski, A. D. Joseph, R. H. Katz, and I. Stoica, “Improving MapReduce performance in heterogeneous environments,” in 8th USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2008.
[34] K. Liang, X. Zhou, K. Zhang, and R. Sheng, “An adaptive performance management method for failure detection,” in Proceedings of the 9th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, 2008.
[35] E. B. Nightingale, D. Peek, P. M. Chen, and J. Flinn, “Parallelizing security checks on commodity hardware,” in Proceedings of the 13th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), 2008.
[36] M. Süsskraut, S. Weigert, U. Schiffel, T. Knauth, M. Nowack, D. B. de Brum, and C. Fetzer, “Speculation for parallelizing runtime checks,” in Proceedings of the 11th International Symposium on Stabilization, Safety, and Security of Distributed Systems (SSS), 2009.