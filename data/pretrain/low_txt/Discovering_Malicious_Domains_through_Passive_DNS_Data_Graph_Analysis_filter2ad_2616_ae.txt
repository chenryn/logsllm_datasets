# Thresholds and Evaluation Metrics
The following thresholds are set for the evaluation:
- **Threshold = 0.55**
- **Threshold = 0.65**
- **Threshold = 0.75**
- **Threshold = 0.85**

True Positive Rates (TPR) and False Positive Rates (FPR) for these thresholds are as follows:

- **TPR: 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96**
- **FPR: 0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05**

## Figures
### Figure 7: One-Week Dataset
- **(a)** False Positive Rate vs. True Positive Rate for all configurations.
- **(b)** Expansion vs. Seed Size.

### Figure 8: Two-Week Dataset
- **(a)** False Positive Rate vs. True Positive Rate for all configurations.
- **(b)** Expansion vs. Seed Size.

**Note:** The performance of our approach is significantly better compared to the alternative method. This does not contradict the results in [7], as their approach is designed for a different type of data. The inference intuition for host-domain graphs does not apply to domain resolution graphs. Therefore, while belief propagation works well for host-domain graphs, it performs poorly with passive DNS data.

## Evaluation Beyond VirusTotal
To further validate the feasibility and accuracy of our approach, we manually cross-checked our detection results against other third-party public services, including McAfee Site Advisor, multirbl.valli.org, MXToolBox, DBL-Update, and the German inps.de-DNSBL. Using all malicious ground truth from VirusTotal as the seed set for the one-week data (over 6000 malicious domains), we manually inspected a 10% sample. Our inspection revealed that 98% of domains with scores over 0.9 were reported as malicious or suspicious by at least one of the above public services, indicating high accuracy in our scheme.

## Discussion
Our current approach uses a simple technique to identify public IPs, which, although effective, is not exhaustive. More sophisticated algorithms could be developed to classify public/private IPs by considering advanced features such as domain distributions and traffic patterns, potentially improving the accuracy of malicious domain inferences.

One potential issue is that an attacker might "taint" a benign domain \( D \) by making a known malicious domain \( D' \) point to the IPs of \( D \), creating a fake association. However, this is not a serious concern, as attackers typically prefer stealthy and agile malicious domains. Additionally, such attacks can be partially mitigated by whitelisting popular benign domains. For less popular but benign domains hosted on public IPs, our approach ensures that even if a malicious domain is also hosted on the same IPs, no strong association will be formed between them.

## Conclusion and Future Work
In this paper, we propose a new technique to discover malicious domains by analyzing passive DNS data. Our approach leverages the dynamic nature of malicious domains to find strong associations among them, which are then used to infer additional malicious domains. We also propose heuristics to handle practical issues, such as web hosting, to improve both the effectiveness and efficiency of the technique. Experimental results show that our method achieves high true positive rates and low false positive rates, with good expansion.

Future work includes integrating passive DNS data with other network and application data to enhance association mechanisms. Investigating different inference methods and studying incremental malicious score updates as new data and seeds are added are also important directions.

## References
[1] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster. Building a dynamic reputation system for DNS. In 19th USENIX Security Symposium, Washington, DC, USA, August 11-13, 2010, Proceedings.
[2] M. Antonakakis, R. Perdisci, Y. Nadji, N. V. II, S. Abu-Nimeh, W. Lee, and D. Dagon. From throw-away traffic to bots: Detecting the rise of dga-based malware. In Proceedings of the 21st USENIX Security Symposium, Bellevue, WA, USA, August 8-10, 2012.
[3] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi. EXPOSURE: Finding malicious domains using passive DNS analysis. In Proceedings of the Network and Distributed System Security Symposium, San Diego, California, USA, February 6-9, 2011.
[4] M. Cova, C. Leita, O. Thonnard, A. D. Keromytis, and M. Dacier. An analysis of rogue AV campaigns. In Recent Advances in Intrusion Detection, 13th International Symposium, RAID 2010, Ottawa, Ontario, Canada, September 15-17, 2010. Proceedings.
[5] H. Crawford and J. Aycock. Kwyjibo: Automatic domain name generation. Softw., Pract. Exper., 38(14):1561–1567, 2008.
[6] M. Feily, A. Shahrestani, and S. Ramadass. A survey of botnet and botnet detection. In Emerging Security Information, Systems and Technologies, 2009. SECURWARE '09. Third International Conference on, June 2009.
[7] P. K. Manadhata, S. Yadav, P. Rao, and W. Horne. Detecting malicious domains via graph inference. In 19th European Symposium on Research in Computer Security, Wroclaw, Poland, September 7-11, 2014. Proceedings.
[8] B. Rahbarinia, R. Perdisci, and M. Antonakakis. Segugio: Efficient behavior-based tracking of new malware-control domains in large ISP networks. In 2015 45rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), Rio de Janeiro, Brazil, June 22-25, 2015.
[9] P. Royal. Quantifying maliciousness in Alexa top-ranked domains, December 2012.
[10] S. Schiavoni, F. Maggi, L. Cavallaro, and S. Zanero. Phoenix: DGA-based botnet tracking and intelligence. In Detection of Intrusions and Malware, and Vulnerability Assessment - 11th International Conference, DIMVA 2014, Egham, UK, July 10-11, 2014. Proceedings.
[11] R. Sherwood, S. Lee, and B. Bhattacharjee. Cooperative peer groups in NICE. Computer Networks, 50(4):523–544, 2006.
[12] E. Stinson and J. C. Mitchell. Towards systematic evaluation of the evadability of bot/botnet detection methods. In 2nd USENIX Workshop on Offensive Technologies, WOOT'08, San Jose, CA, USA, July 28, 2008, Proceedings.
[13] A. Tamersoy, K. A. Roundy, and D. H. Chau. Guilt by association: Large scale malware detection by mining file-relation graphs. In The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, New York, NY, USA, August 24-27, 2014.
[14] F. Weimer. Passive DNS replication, October 2007.
[15] J. Zhang, S. Saha, G. Gu, S. Lee, and M. Mellia. Systematic mining of associated server herds for malware campaign discovery. In 35th IEEE International Conference on Distributed Computing Systems, ICDCS 2015, Columbus, OH, USA, June 29-July 2, 2015.

### Figure 9: ROC Curves
- **(a)** True Positive Rate vs. False Positive Rate for the belief propagation approach.

This structured and organized format should make the content more readable and professional.