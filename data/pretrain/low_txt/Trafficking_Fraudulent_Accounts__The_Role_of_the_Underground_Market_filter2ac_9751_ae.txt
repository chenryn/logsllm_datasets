### Impact of the Underground Market on Twitter Spam

During active months, the underground market was responsible for registering 10-20% of all accounts that Twitter later flagged as spam. We estimate that the merchants generated a combined revenue between $127,000 and $459,000.

#### Figure 6: Fraction of All Suspended Accounts Over Time Originating from the Underground Market
```
0.6
|-------------------|
|                   |
|                   |
|                   |
0.4                 |
|                   |
|                   |
|                   |
0.2                 |
|                   |
|                   |
|                   |
0.0                 |
Apr 2012   Jul 2012  Oct 2012  Jan 2013  Apr 2013
Registration Date
```

### Impact on Twitter Spam

From our seed set of 121,027 accounts purchased from 27 merchants, we identified several million fraudulent accounts registered by the same merchants. Of these, 73% were sold and actively tweeting or forming relationships at some point, while the remaining 37% remained dormant and had not yet been purchased.

In collaboration with Twitter, we analyzed the total fraction of all suspended accounts that appear to originate from the merchants we tracked, as shown in Figure 6. At its peak, the underground marketplace was responsible for registering 60% of all accounts that would eventually be suspended for spamming. During more typical periods, the merchants we tracked contributed 10-20% of all spam accounts. The drop-off around April does not indicate a lack of recent activity; rather, it reflects that accounts are often stockpiled for months before being released to spammers, leading to their suspension. The most damaging merchants operate out of blackhat forums and web storefronts, while Fiverr and Freelancer sellers generate significantly fewer accounts. One exception is a Freelancer merchant, kamalkishover, but based on their overlapping patterns with nine other merchants, we believe they are reselling accounts.

### Estimating Revenue

We estimated the revenue generated by the underground market based on the total accounts sold and the prices charged during their sale. We distinguished between sold accounts and those that lay dormant, awaiting sale, based on whether an account had sent tweets or formed relationships. For sold accounts, we identified which merchant created the account and determined the minimum and maximum price the merchant would have charged based on our historical pricing data. In cases where multiple merchants could have generated the account (due to overlapping registration patterns), we took the minimum and maximum price of the set of matching merchants.

We estimate that the total revenue generated by the underground account market through the sale of Twitter credentials is between $127,000 and $459,000 over the course of a year. Many of the merchants we track simultaneously sell accounts for various web services, so this value likely represents only a fraction of their overall revenue. Nevertheless, our estimated income is far less than the revenue generated from actually sending spam or selling fake antivirus, where revenue is estimated in the tens of millions. As such, account merchants are stepping stones for larger criminal enterprises, which in turn disseminate scams, phishing, and malware throughout Twitter.

### Disrupting the Underground Market

With Twitter's cooperation, we disabled 95% of all fraudulent accounts registered by the 27 merchants we tracked, including those previously sold but not yet suspended for spamming. Throughout this process, we monitored the underground market to track fallout and recovery. While we did not observe a significant increase in pricing or delay in merchants delivering new accounts, we found that 90% of all purchased accounts immediately after our action were suspended upon arrival. Although we successfully depleted merchant stockpiles containing fraudulent accounts, we found that within two weeks, merchants were able to create fresh accounts and resume selling working credentials.

#### Suspending Identified Accounts

To disrupt the abusive activities of account merchants, we worked with Twitter’s Anti-spam, SpamOps, and Trust and Safety teams to manually validate the accuracy of our classifier and tune parameters to set acceptable bounds on false positives (legitimate users incorrectly identified as fraudulent accounts). Once tuned, we applied the classifier outlined in Section 5 to every account registered on Twitter going back to March 2012, filtering out accounts already suspended for abusive behavior.

From the set of accounts we identified, Twitter iteratively suspended accounts in batches of ten thousand and a hundred thousand before finally suspending all the remaining identified accounts. At each step, we monitored the rate of users requesting their accounts be unsuspended, using valid CAPTCHA solutions as a metric for false positives. Of the accounts we suspended, only 0.08% requested to be unsuspended. However, 93% of these requests were performed by fraudulent accounts abusing the unsuspension process, as determined by manual analysis by Twitter. Filtering these requests out, we estimate the final precision of our classifier to be 99.9942%. The tuned classifier has a recall of 95%, evaluated using the method presented in Section 5. Assuming our purchases are a random sample of the accounts controlled by the underground market, we estimate that 95% of all fraudulent accounts registered by the 27 merchants we tracked were disabled by our actions.

#### Marketplace Fallout and Recovery

Immediately after Twitter suspended the last of the underground market's accounts, we placed 16 new orders for accounts from the 10 merchants we suspected of controlling the largest stockpiles. Of the 14,067 accounts we purchased, 90% were suspended on arrival due to Twitter's previous intervention. When we requested working replacements, one merchant responded:

"All of the stock got suspended... Not just mine.. It happened with all of the sellers... Don't know what Twitter has done..."

Similarly, immediately after the suspension, buyaccs.com put up a notice on their website stating "Временно не продаем аккаунты Twitter.com," which roughly translates to "Temporarily not selling Twitter.com accounts."

While Twitter's initial intervention was successful, the market has begun to recover. Of the 6,879 accounts we purchased two weeks after Twitter's intervention, only 54% were suspended on arrival. Therefore, long-term disruption of the account marketplace requires both increasing the cost of account registration (as outlined in Section 4) and integrating abuse classification into the account registration process (similar to the classifier outlined in Section 5). We are now working with Twitter to integrate our findings and existing classifier into their abuse detection infrastructure.

### Summary

We have presented a longitudinal investigation of the underground market tied to fraudulent Twitter credentials, monitoring pricing, availability, and fraud perpetrated by 27 account merchants. These merchants specialize in circumventing automated registration barriers by leveraging thousands of compromised hosts, CAPTCHA solvers, and access to fraudulent Hotmail, Yahoo, and mail.ru credentials. We identified which registration barriers positively influenced the price of accounts and distilled our observations into a set of recommendations for how web services can improve existing barriers to bulk signups. Furthermore, we developed a classifier based on at-registration abuse patterns to successfully detect several million fraudulent accounts generated by the underground market. During active months, the 27 merchants we monitored appeared responsible for registering 10-20% of all accounts later flagged by Twitter as spam. For their efforts, these merchants generated an estimated revenue between $127,000 and $459,000. With Twitter's help, we successfully suspended 95% of all accounts registered by the 27 merchants we track, depleting the account stockpiles of numerous criminals. We are now working with Twitter to integrate our findings and existing classifier into their abuse detection infrastructure.

### Acknowledgments

This work was supported by the National Science Foundation under grants 1237076 and 1237265, by the Office of Naval Research under MURI grant N000140911081, and by a gift from Microsoft Research. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors.

### References

[1] Alexa. Alexa top 500 global sites. http://www.alexa.com/topsites, 2012.
[2] D.S. Anderson, C. Fleizach, S. Savage, and G.M. Voelker. SpamScatter: Characterizing internet scam hosting infrastructure. USENIX Security, 2007.
[3] F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida. Detecting Spammers on Twitter. In Proceedings of the Conference on Email and Anti-Spam (CEAS), 2010.
[4] J. Caballero, C. Grier, C. Kreibich, and V. Paxson. Measuring pay-per-install: The commoditization of malware distribution. In USENIX Security Symposium, 2011.
[5] CBL. Composite Blocking List. http://cbl.abuseat.org/, 2012.
[6] G. Danezis and P. Mittal. Sybilinfer: Detecting sybil nodes using social networks. In Proceedings of the Network and Distributed System Security Symposium (NDSS), 2009.
[7] J. Franklin, V. Paxson, A. Perrig, and S. Savage. An inquiry into the nature and causes of the wealth of Internet miscreants. In Proceedings of ACM Conference on Computer and Communications Security, pages 375–388, October 2007.
[8] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B.Y. Zhao. Detecting and characterizing social spam campaigns. In Proceedings of the Internet Measurement Conference (IMC), 2010.
[9] C. Grier, L. Ballard, J. Caballero, N. Chachra, C.J. Dietrich, K. Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pitsillidis, et al. Manufacturing compromise: The emergence of exploit-as-a-service. 2012.
[10] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @spam: the underground on 140 characters or less. In Proceedings of the ACM Conference on Computer and Communications Security (CCS), 2010.
[11] T. Holz, C. Gorecki, F. Freiling, and K. Rieck. Detection and mitigation of fast-flux service networks. In Proceedings of the 15th Annual Network and Distributed System Security Symposium (NDSS), 2008.
[12] C.Y. Hong, F. Yu, and Y. Xie. Populated IP addresses—classification and applications. 2012.
[13] Heather Kelley. 83 million Facebook accounts are fakes and dupes. http://www.cnn.com/2012/08/02/tech/social-media/facebook-fake-accounts/index.html, 2012.
[14] Brian Krebs. Spam volumes: Past & present, global & local. http://krebsonsecurity.com/2013/01/spam-volumes-past-present-global-local/, 2012.
[15] S. Lee and J. Kim. Warningbird: Detecting Suspicious URLs in Twitter Stream. In Symposium on Network and Distributed System Security (NDSS), 2012.
[16] K. Levchenko, A. Pitsillidis, N. Chachra, B. Enright, M. Felegyhazi, C. Grier, T. Halvorson, C. Kanich, C. Kreibich, H. Liu, D. McCoy, N. Weaver, V. Paxson, G.M. Voelker, and S. Savage. Click Trajectories: End-to-End Analysis of the Spam Value Chain. In Proceedings of the 32nd IEEE Symposium on Security and Privacy, 2011.
[17] D. McCoy, A. Pitsillidis, G. Jordan, N. Weaver, C. Kreibich, B. Krebs, G.M. Voelker, S. Savage, and K. Levchenko. Pharmaleaks: Understanding the business of online pharmaceutical affiliate programs. In Proceedings of the 21st USENIX conference on Security symposium. USENIX Association, 2012.
[18] A. Metwally and M. Paduano. Estimating the number of users behind IP addresses for combating abusive traffic. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2011.
[19] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy, G.M. Voelker, and S. Savage. Re: CAPTCHAs—understanding CAPTCHA-solving services in an economic context. In USENIX Security Symposium, volume 10, 2010.
[20] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G.M. Voelker. An analysis of underground forums. In Proceedings of the Internet Measurement Conference (IMC). ACM, 2011.
[21] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G.M. Voelker. Dirty jobs: The role of freelance labor in web service abuse. In Proceedings of the 20th USENIX Security Symposium, 2011.
[22] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich, G.M. Voelker, V. Paxson, N. Weaver, and S. Savage. Botnet Judo: Fighting spam with itself. 2010.
[23] P. Prasse, C. Sawade, N. Landwehr, and T. Scheffer. Learning to identify regular expressions that describe email campaigns. 2012.
[24] W.E. Ricker. Computation and interpretation of biological statistics of fish populations, volume 191. Department of the Environment, Fisheries and Marine Service Ottawa, 1975.
[25] B. Stone-Gross, R. Abman, R. Kemmerer, C. Kruegel, D. Steigerwald, and G. Vigna. The Underground Economy of Fake Antivirus Software. In Proceedings of the Workshop on Economics of Information Security (WEIS), 2011.
[26] G. Stringhini, C. Kruegel, and G. Vigna. Detecting Spammers on Social Networks. In Proceedings of the Annual Computer Security Applications Conference (ACSAC), 2010.
[27] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design and Evaluation of a Real-time URL Spam Filtering Service. In Proceedings of the 32nd IEEE Symposium on Security and Privacy, 2011.
[28] K. Thomas, C. Grier, and V. Paxson. Adapting social spam infrastructure for political censorship. In Proceedings of the 5th USENIX conference on Large-Scale Exploits and Emergent Threats. USENIX Association, 2012.
[29] K. Thomas, C. Grier, V. Paxson, and D. Song. Suspended Accounts in Retrospect: An Analysis of Twitter Spam. In Proceedings of the Internet Measurement Conference, November 2011.
[30] Twitter. The Twitter Rules. http://support.twitter.com/entries/18311-the-twitter-rules, 2010.
[31] G. Wang, C. Wilson, X. Zhao, Y. Zhu, M. Mohanlal, H. Zheng, and B.Y. Zhao. Serf and Turf: Crowdturﬁng for Fun and Profit. In Proceedings of the International World Wide Web Conference, 2011.
[32] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and I. Osipkov. Spamming botnets: Signatures and characteristics. Proceedings of ACM SIGCOMM, 2008.
[33] C. Yang, R. Harkreader, J. Zhang, S. Shin, and G. Gu. Analyzing Spammers’ Social Networks for Fun and Profit: a Case Study of Cyber Criminal Ecosystem on Twitter. In Proceedings of the 21st International Conference on World Wide Web, 2012.
[34] H. Yu, M. Kaminsky, P.B. Gibbons, and A. Flaxman. Sybilguard: Defending against sybil attacks via social networks. ACM SIGCOMM Computer Communication Review, 2006.
[35] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and E. Gillum. Botgraph: Large scale spamming botnet detection. 2009.

### Legal and Ethical Guidelines

To minimize the risk posed to Twitter or its users by our investigation of the account market, we follow a set of policies set down by our institutions and Twitter, reproduced here to serve as a note of caution to other researchers conducting similar research.

#### Twitter & Users
Some of the account merchants we deal with work in an on-demand fashion, where purchases we place directly result in abusive registrations on Twitter (e.g., harm) in violation of the site’s Terms of Service. Even purchases from existing stockpiles might be misconstrued as galvanizing further abuse of Twitter. As such, we directly contacted Twitter to receive permission to conduct our study. In the process, we determined that any interactions with the underground market should not result in harm to Twitter’s user base. In particular, accounts we purchased should never be used to tweet or form relationships while under our control. Furthermore, we take no special action to guarantee our accounts are not suspended (e.g., disabled) by Twitter; our goal is to observe the natural registration process, not to interact with or impede Twitter’s service in any way.

#### Account Merchants
We do not interact with merchants anymore than necessary to perform transactions. To this end, we only purchased from merchants that advertise their goods publicly and never contact merchants outside the websites or forums they provide to conduct a sale (or to request replacement accounts in the event of a bad batch). Our goal is not to study the merchants themselves or to collect personal information on them; only to analyze the algorithms they use to generate accounts.

#### Sensitive User Data
Personal data logged by Twitter is subject to a multitude of controls, while usernames and passwords sold by merchants also carry controls to prevent fraud, abuse, and unauthorized access. First, we never log into accounts; instead, we rely on Twitter to verify the authenticity of credentials we purchase. Furthermore, all personal data such as IP addresses or activities tied to an account are never accessed outside of Twitter’s infrastructure, requiring researchers involved in this study to work on-site at Twitter and to follow all relevant Twitter security practices. This also serves to remove any risk in the event an account is compromised rather than registered by an account merchant, as no personal data ever leaves Twitter. To our knowledge, we never obtained credentials for compromised accounts.