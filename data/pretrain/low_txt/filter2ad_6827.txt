# PPMLP 2020: Workshop on Privacy-Preserving Machine Learning in Practice

## Authors
- **Benyu Zhang**
  - SCI Lab, Ant Group
  - Email: [EMAIL]
- **Matei Zaharia**
  - Department of Computer Science, Stanford University
  - Email: [EMAIL]
- **Shouling Ji**
  - College of Computer Science and Technology, Zhejiang University
  - Email: [EMAIL]
- **Raluca Ada Popa**
  - Department of Electrical Engineering and Computer Sciences, UC Berkeley
  - Email: [EMAIL]
- **Guofei Gu**
  - Department of Computer Science and Engineering, Texas A&M University
  - Email: [EMAIL]

## Abstract
With the rapid advancement of technology, data is becoming increasingly ubiquitous. User privacy and data security have gained significant attention in recent years, especially with the implementation of the European Union's General Data Protection Regulation (GDPR) and other similar laws. From a customer's perspective, protecting user privacy while utilizing their data remains a challenging task. Conversely, data silos are becoming one of the most prominent issues in society. For businesses, bridging these isolated data islands to build better AI systems while meeting data privacy and regulatory compliance requirements poses significant challenges to the traditional machine learning paradigm. The PPMLP workshop aims to bring together researchers from both the computer and communication security (CCS) community and the machine learning community to address these challenges.

## Keywords
- Machine Learning
- Multi-Party Computation (MPC)
- Differential Privacy

## ACM Reference Format
Zhang, B., Popa, R.A., Zaharia, M., Gu, G., and Ji, S. 2020. PPMLP 2020: Workshop on Privacy-Preserving Machine Learning in Practice. In Proceedings of CCS 2020 (November 9-13, 2020, Virtual Event, USA), 2 pages. https://doi.org/10.1145/3372297.3416245

## 1. Introduction
Protecting data privacy from multiple data owners while using this data for joint model creation and analysis has become increasingly practical, given the enforcement of GDPR and other national laws. Academic researchers from various fields have proposed numerous solutions to address these challenges from different perspectives. Industry professionals have also implemented various improvements to internal AI systems to enhance privacy and security. However, more opportunities are needed to connect researchers from different backgrounds and domains to exchange practical problem formulations and research advancements. CCS, a top-tier conference, covers all real-world aspects of computer security and privacy. Organizing PPMLP in conjunction with CCS 2020 will provide a forum for both machine learning and security researchers and industrial practitioners to jointly review recent academic progress in PPML techniques and valuable lessons learned from real-world applications.

## 2. Topics of Interest
The workshop on Privacy-Preserving Machine Learning (PPML) includes, but is not limited to, the following techniques and applications:
- Secure multi-party computation techniques (e.g., secret sharing and garbled circuits)
- Homomorphic encryption techniques
- Centralized and decentralized protocols for learning on encrypted data
- Trusted execution environment (TEE) based approaches
- Differential privacy
- Collaborative learning / federated learning
- Solutions to database security in industries
- Privacy-preserving industrial-scale AI solutions

## 3. Workshop Chairs and Committee
We are honored to have the following workshop chairs to organize our event:
- Benyu Zhang, Ant Group
- Raluca Ada Popa, UC Berkeley
- Matei Zaharia, Stanford University
- Guofei Gu, Texas A&M University
- Shouling Ji, Zhejiang University

We are grateful to the following workshop committee members for carefully reviewing each submitted paper:
- Jun Zhou, Ant Group
- Pu Duan, Ant Group
- Ghazaleh Beigi, Google
- Wenting Zheng, UC Berkeley
- Rishabh Poddar, UC Berkeley
- Sameer Wagh, UC Berkeley
- Saba Eskandarian, Stanford University
- Pratiksha Thaker, Stanford University
- Xiangjun Fan, Bytedance
- Chaochao Chen, Ant Group
- Cen Chen, Ant Group
- Li Wang, Ant Group
- Feng Xue, Ant Group
- Cheng Hong, Alibaba Group
- Changchang Liu, IBM Research
- Anit Sahu, Bosch Center for AI
- Ting Wang, Penn State University
- Jian Du, Ant Group

## 4. Invited Keynote Speakers
We are honored to have the following keynote speakers who will cover a broad range of topics, including classic applications of cryptography theory on machine learning, secure computation platforms, engineering cryptographic protocols for machine learning, and industrial applications of privacy-preserving machine learning:
- **Yupeng Zhang, Texas A&M University**
  - Title: Zero Knowledge Proofs for Machine Learning
- **Raluca Ada Popa, UC Berkeley**
  - Title: MC2: A Secure Collaborative Computation Platform
- **Thomas Schneider, TU Darmstadt**
  - Title: Engineering Privacy-Preserving Machine Learning Protocols
- **Pu Duan, Ant Group**
  - Title: Introduction to Secure Collaborative Intelligence (SCI) Lab

## 5. Accepted Papers
PPMLP is a full-day workshop. We received a total of 34 high-quality papers. Each paper was reviewed by at least two reviewers, focusing on novelty, contribution, and practicality. Eight papers were accepted as full papers, and eight were accepted as short papers. 

### Accepted Full Papers
- Amos Treiber et al., CryptoSPN: Expanding PPML beyond Neural Networks
- Pratyush Mishra et al., Delphi: A Cryptographic Inference Service for Neural Networks
- Tom Farrand et al., Neither Private Nor Fair: The Impact of Data Imbalance on Utility and Fairness in Differential Privacy
- Andrew Law et al., Secure Collaborative Training and Inference for XGBoost
- Swanand Kadhe et al., FastSecAgg: Scalable Secure Aggregation for Privacy-Preserving Federated Learning
- Qian Lou et al., HERB: Fast Privacy-Preserving Inference using Block Circulant Weight Matrices
- Xiaoyun Xu et al., Information Leakage by Model Weights on Federated Learning
- Jinyin Chen et al., Adversarial Detection on Graph Structured Data

### Accepted Short Papers
- Fabian Boemer et al., MP2ML: A Mixed-Protocol Machine Learning Framework for Private Inference (Extended Abstract)
- Wenjie Lu et al., Faster Secure Multiparty Computation of Adaptive Gradient Descent
- Zuobin Ying et al., Privacy-Preserving in Defending against Membership Inference Attacks
- Sasi Kumar Murakonda et al., Quantifying the Privacy Risks of Learning High-Dimensional Graphical Models
- Neel Patel et al., Model Explanations with Differential Privacy
- Jianping Cai et al., SVM Learning for Default Prediction of Credit Card under Differential Privacy
- Veneta Haralampieva et al., A Systematic Comparison of Image Classification Encrypted Machine Learning Solutions
- Siam Umar Hussain et al., SYGC: Smart, Efficient, and Scalable Yao’s Garbled Circuit

## 6. Acknowledgments
We would like to thank the organizers of CCS 2020 and the ACM staff for their support and service in helping us organize PPMLP. We also extend our gratitude to the following reviewers who helped the committee carefully review and evaluate the papers:
- Jinyin Chen, Zhejiang University of Technology
- Siheng Chen, Mitsubishi Electric Research Laboratories
- Xiangjun Fan, Bytedance
- Weihao Gao, Bytedance
- Gerry Wan, Stanford University
- Jonathan Passerat-Palmbach, Imperial College London
- Jiankai Sun, Bytedance

---

**Workshop CCS '20, November 9–13, 2020, Virtual Event, USA**

**© 2020 Copyright is held by the owner/author(s).**

**ACM ISBN 978-1-4503-7089-9/20/11.**

**DOI: https://doi.org/10.1145/3372297.3416245**