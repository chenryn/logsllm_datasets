### Repeated Queries for Two Hostnames, One Accelerated by Each CDN

We conducted repeated queries for two hostnames, each accelerated by a different Content Delivery Network (CDN), directly to their respective authoritative nameservers. To ensure that the authoritative nameservers use the probes' location rather than ours, we included ECS (EDNS0-Client-Subnet) options with client subnet prefixes derived from 800 IP addresses of our RIPE Atlas probe sample in our queries.

For each DNS response received, we used RIPE Atlas SSL measurements to perform three certificate downloads from the corresponding Atlas probe using the first IP address in the DNS response. The median of the TCP handshake latencies was then used as our metric for the resulting user-to-edge-server proximity.

#### CDN-1 Analysis

For CDN-1, when using 24-bit prefixes of our 800 probe addresses, the authoritative nameserver returned 400 unique first IP addresses in their responses. However, with any shorter source prefixes (we studied prefix lengths between 16 and 24 bits), the total number of unique first IP addresses returned by the authoritative server drastically decreased, ranging from 5 to 14.

Figure 6 shows the cumulative distribution function (CDF) of the median TCP handshake latencies for the hostname accelerated by CDN-1, using the edge server obtained with an ECS prefix of a given length. The figure illustrates a significant degradation in CDN-1 mapping latency when reducing the source prefix length from 24 to 23 bits, while further shortening of the prefix had no visible effect. This suggests that CDN-1 does not use proximity-based server selection for prefixes shorter than /24.

#### CDN-2 Analysis

For CDN-2, when sending source prefix lengths between 16 and 20 bits, a single IP address was returned from the CDN-2 authoritative DNS server for all queries with a scope prefix length of zero. Using traceroute, we found that this IP address is located in Toronto, near our lab machine (located in Cleveland). Thus, it appears that CDN-2 ignores the ECS information when the source prefix length is 20 bits or less and uses the IP address of the resolver that sends the query as a proxy for the end-device location.

However, as soon as the prefix length reaches 21 bits or longer, CDN-2 returns 41-42 different IP addresses. Figure 7 shows the CDF of the median TCP handshake latencies for the hostname accelerated by CDN-2, excluding the results for source prefix lengths 16-19 because they are identical to length 20. We can see that using source prefix lengths of 21 bits and longer provide the same quality of mapping, but dropping to /20 leads to a dramatic penalty. It appears that CDN-2 leverages ECS prefixes in its edge server selection for prefixes of at least 21 bits, but not for shorter prefixes.

#### Implications for Resolvers

These results raise interesting questions about how resolvers should choose the prefix lengths when sending ECS queries to CDNs. They could blindly use the most specific prefixes recommended by the RFC (/24), but in the case of CDN-2, this would expose more client information than needed for proximity mapping. Sending 21 bits would suffice. However, sending fewer than 24 bits to CDN-1 would negate any benefits from ECS, and whatever client information is submitted in fewer bits would still be exposed unnecessarily.

The RFC suggests that resolvers utilize knowledge of their clients to use shorter source prefixes when all addresses covered by these prefixes are known to be in the same location. However, this recommendation assumes that the authoritative nameservers would use whatever number of client subnet bits they receive for server selection. The results from both CDNs show that this assumption is not always accurate. Both CDNs appear to stop using ECS once the source prefix length drops below a certain limit.

On balance, it would appear that using /24 for all ECS queries is the most practical approach. An alternative would be to track the source prefix lengths needed per CDN, or even per subdomain and per client address block, since a CDN can in principle use different prefix lengths for different subdomains and clients. This can get complicated very quickly.

### CNAME Flattening

The DNS standard does not allow CNAME records to co-exist with other record types at the same name. This poses a problem as CNAME records are a common method to onboard traffic to a CDN, and content providers often desire for their content to be reachable from the apex of their zones, e.g., example.com, which must have NS and SOA records. CNAME flattening has emerged to circumvent this obstacle. With CNAME flattening, when an authoritative nameserver receives a query for N1 that it would normally redirect to a CDN by returning a CNAME N2 from the CDN’s domain, the authoritative server instead resolves N2 itself by interacting with the CDN’s authoritative DNS on the backend, and then returns the final A/AAAA record(s) of the edge server(s) to the original querier. Thus, recursive resolvers querying the authoritative DNS server receive A/AAAA record(s) for N1, while N2 is invisible externally, outside the authoritative DNS servers of the website and the CDN involved.

In this section, we demonstrate how careless implementations of CNAME flattening may eliminate the ECS benefits even when ECS is supported by both the recursive resolver and the CDN.

We use an imaginary domain "customer.com" in this discussion, as our goal is to draw attention to this pitfall without singling out a specific website. The DNS zone is hosted with a major DNS provider, while its web acceleration is provided by a major CDN. The website can be accessed either via the apex of the zone, i.e., through URL http://customer.com (using CNAME flattening) or with www prepended, with URL http://www.customer.com.

We accessed customer.com from the Chrome browser using a major Public DNS service as our recursive resolver, as this Public DNS and the major CDN are known to support ECS with one another. We used Wireshark to collect a packet trace while loading the page. The order of actions is depicted in Figure 8 and is as follows:

1. (Steps 1-6) The client resolves customer.com to the IP address E1 of an edge server of the major CDN via CNAME flattening.
2. (Steps 7-8) The client performs HTTP interaction with E1, receiving an HTTP redirect to www.customer.com. This incurred 125 ms to complete the TCP handshake and 650 ms in total elapsed time from step 1.
3. (Steps 9-14) The client resolves www.customer.com, using the regular CNAME-based DNS redirection, to the IP address of a different edge server of the major CDN.
4. (Not shown in the figure) The HTTP download of the page from the second IP address, taking 45 ms for the TCP handshake.

From the results, we can infer that the mapping of customer.com to edge server E1 is poor, likely due to the absence of ECS in the DNS transaction between the DNS provider and the major CDN for the flattened CNAME. This forces the CDN to map the query based on the IP address of customer.com’s authoritative nameserver, which has no bearing on the client’s location. HTTP redirection is used to correct the mapping, incurring a 650 ms penalty due to the lack of ECS on part of the resolution path.

Authoritative DNS servers that implement CNAME flattening could mitigate this issue by using ECS and passing ECS source prefixes to the CDN when they resolve the flattened name. This would help if customer.com’s authoritative nameserver received queries directly from clients or from clients’ nearby ISP resolvers. However, with public DNS resolvers, the queries can still arrive from senders distant from the end-devices. Furthermore, even if the public DNS and the CDN mutually whitelist each other to support ECS, the problem remains unless the Public DNS also whitelists customer.com for ECS support. In summary, full elimination of the performance penalty due to CNAME flattening requires careful planning to enact pairwise coordination among multiple parties: customer.com’s authoritative DNS service provider, the CDN used to accelerate customer.com’s content delivery, and any public DNS resolution services.

### Limitations and Future Work

In this section, we describe topics that we did not study but would complement our work nicely. This includes extensions of our analysis as well as entirely new research questions.

Our study of source prefix lengths in Section 6.2 uses data from our scan that probes each forwarder only once. Thus, the number of times egress resolvers are engaged is variable and depends on how many open forwarders share a given resolver. Further, our authoritative nameserver in the scan always answers ECS queries with a deterministic scope (4 bits shorter than the source prefix length). It would be interesting to engage the same resolver repeatedly in a more systematic manner and explore if changing the scope in authoritative nameserver’s responses would affect the source prefix length of subsequent queries.

In Section 7, we study the impact ECS has on cache size for the portion of DNS responses that carry the ECS option only. To understand the impact on overall cache size, including DNS responses that do not carry the ECS option, future work should focus on the fraction of DNS responses that carry ECS options today and attempt to predict what that fraction will be as ECS support grows. From such a study, it would be possible to predict the overall cache blow-up factor for recursive resolvers at both present levels of ECS deployment by authoritative nameservers and future increases in deployment.

Another direction for future work is to conduct a comparative analysis of different whitelisted recursive resolvers as well as whitelisted vs. non-whitelisted resolvers in terms of their compliance with RFC recommendations and consequences of ECS on caching.

Our study of the ECS caching behavior of recursive resolvers in Section 6.3 includes only recursive resolvers that are discoverable through open forwarders in the Scan dataset and is not exhaustive of all recursive resolvers. Other techniques for probing recursive resolvers, including Ripe Atlas, would complement our study, increasing overall coverage.

In Section 8.1, we report a behavior of PowerDNS that has implications for authoritative nameserver handling of ECS. Similar nuanced behaviors may exist in other recursive resolver software. A lab-based analysis of ECS behavior in popular recursive resolver software could detect the PowerDNS behavior and many other similar behaviors, and would be beneficial to the developer community.

### Conclusion

This paper studies the behavior of recursive resolvers that have adopted the EDNS0-Client-Subnet (ECS) extension to the DNS protocol. ECS has been proposed to facilitate proximity-based server selection by content delivery networks (CDNs), especially in the face of increasing use of public DNS resolvers that can be far removed from the end-devices. Using diverse sources of data, we examine important aspects of ECS-related behavior and find a wide range of detrimental behaviors that negatively affect client privacy, ECS benefits in improving server selection, and the effectiveness of DNS caching. This shows that despite its apparent simplicity, ECS adoption requires careful engineering of a proper setup to get the most benefits from ECS and avoid harm.

### Acknowledgements

We thank the anonymous reviewers for extensive and useful comments. We are especially grateful to our shepherd, Tobias Fiebig, for his insightful comments and discussions during the final revision, which significantly improved the paper. The work of Michael Rabinovich was supported in part by NSF through grant CNS-1647145.

### References

[1] Bernhard Ager, Wolfgang Mühlbauer, Georgios Smaragdakis, and Steve Uhlig. 2010. Comparing DNS resolvers in the wild. In Proceedings of the Internet Measurement Conference. ACM, 15–21.

[2] Akamai 2019. Akamai Technologies, Inc. Retrieved 2019-09-07 from https://www.akamai.com/

[3] Rami Al-Dalky, Michael Rabinovich, and Mark Allman. 2018. Practical challenge-response for DNS. ACM SIGCOMM Computer Communication Review 48, 3 (2018), 20–28.

[4] Matt Calder, Xun Fan, Zi Hu, Ethan Katz-Bassett, John Heidemann, and Ramesh Govindan. 2013. Mapping the expansion of Google’s serving infrastructure. In Proceedings of the Internet Measurement Conference. ACM, 313–326.

[5] Matt Calder, Xun Fan, and Liang Zhu. 2019. A Cloud Provider’s View of EDNS Client-Subnet Adoption. In Network Traffic Measurement and Analysis Conference (TMA). IEEE, 129–136.

[6] Fangfei Chen, Ramesh K Sitaraman, and Marcelo Torres. 2015. End-User Mapping: Next Generation Request Routing for Content Delivery. ACM SIGCOMM Computer Communication Review 45, 4 (2015), 167–181.

[7] CloudFront 2019. Amazon CloudFront. Retrieved 2019-09-07 from https://aws.amazon.com/cloudfront/

[8] CNAME 2019. Introducing CNAME Flattening: RFC-Compliant CNAMEs at a Domain’s Root. https://blog.cloudflare.com/introducing-cname-flattening-rfc-compliant-cnames-at-a-domains-root/

[9] C. Contavalli, W. van der Gaast, D. Lawrence, and W. Kumari. 2016. Client Subnet in DNS Queries. RFC 7871. RFC Editor. https://tools.ietf.org/html/rfc7871

[10] D. Dagon, N. Provos, C.P. Lee, and W. Lee. 2008. Corrupted DNS Resolution Paths: The Rise of a Malicious Resolution Authority. In Network and Distributed System Security Symposium.

[11] J. Damas, M. Graff, and P. Vixie. 2013. Extension Mechanisms for DNS (EDNS(0)). RFC 6891. RFC Editor. https://tools.ietf.org/html/rfc6891

[12] Wouter B De Vries, Roland van Rijswijk-Deij, Pieter-Tjerk de Boer, and Aiko Pras. 2018. Passive observations of a large DNS service: 2.5 years in the life of Google. In Network Traffic Measurement and Analysis Conference (TMA). IEEE, 1–8.

[13] DITL 2018. A-Root DITL Data, submitted to DNS-OARC by Verisign. https://www.dns-oarc.net/oarc/data/ditl/2018.

[14] ECS 2019. EDNS Client Subnet FAQ. Retrieved 2019-09-07 from https://support.opendns.com/hc/en-us/articles/227987647-EDNS-Client-Subnet-FAQ

[15] EdgeScape 2019. Akamai EdgeScape. Retrieved 2019-09-07 from https://developer.akamai.com/edgescape

[16] R. Elz and R. Bush. 1997. Clarifications To the DNS Specification. RFC 2181. https://tools.ietf.org/html/rfc2181

[17] Fastly 2019. Fastly, Inc. Retrieved 2019-09-07 from https://www.fastly.com/

[18] T. Finch, E. Hunt, P. van Dijk, and A. Eden. 2018. Address-specific DNS aliases (ANAME). https://tools.ietf.org/html/draft-ietf-dnsop-aname-02. https://tools.ietf.org/html/draft-ietf-dnsop-aname-02

[19] Cheng Huang, David A Maltz, Jin Li, and Albert Greenberg. 2011. Public DNS system and global traffic management. In IEEE INFOCOM - The 30th Conference on Computer Communications. 2615–2623.

[20] Ben Jones, Nick Feamster, Vern Paxson, Nicholas Weaver, and Mark Allman. 2016. Detecting DNS root manipulation. In International Conference on Passive and Active Network Measurement. Springer, 276–288.

[21] Panagiotis Kintis, Yacin Nadji, David Dagon, Michael Farrell, and Manos Antonakakis. 2016. Understanding the Privacy Implications of ECS. In International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment. 343–353.

[22] D. Leonard and D. Loguinov. 2008. Turbo King: Framework for Large-Scale Internet Delay Measurements. In IEEE INFOCOM - The 27th Conference on Computer Communications. 31–35.

[23] J Ott, M Sanchez, J Rula, and F Bustamante. 2012. Content delivery and the natural evolution of DNS. In Proceedings of the Internet Measurement Conference. ACM, 523–536.

[24] PDNS 2019. PowerDNS Recursor. Retrieved 2019-09-07 from https://www.powerdns.com/recursor.html

[25] David Plonka and Arthur Berger. 2017. kIP: a Measured Approach to IPv6 Address Anonymization. arXiv preprint arXiv:1707.03900 (2017).

[26] RIPE Atlas 2019. Welcome to RIPE Atlas. Retrieved 2019-09-07 from https://atlas.ripe.net/

[27] Kyle Schomp, Tom Callahan, Michael Rabinovich, and Mark Allman. 2013. On Measuring the Client-Side DNS Infrastructure. In Proceedings of the Internet Measurement Conference. ACM, 77–90.

[28] Shadow 2019. Open Resolver Scanning Project. Retrieved 2019-09-07 from https://dnsscan.shadowserver.org/

[29] Philip Smith, Rob Evans, and Mike Hughes. 2006. RIPE routing working group recommendations on route aggregation. Document ripe-399, RIPE (2006).

[30] Florian Streibelt, Jan Böttger, Nikolaos Chatzis, Georgios Smaragdakis, and Anja Feldmann. 2013. Exploring EDNS-Client-Subnet Adopters in your Free Time. In Proceedings of the Internet Measurement Conference. ACM, 305–312.