### 7.2 PIN/Pattern Sequence Inference

The results presented in the previous section model the first attack scenario, where the attacker has a large corpus of labeled data and can use logistic regression to differentiate inputs. In this subsection, we consider the second attack scenario, where such a corpus is unavailable, and the attacker must infer the larger input by performing a sequence of smaller inferences. For example, the attacker might have a set of labeled data that refers to single touches or individual swipes rather than the exact PIN or pattern. The goal is to link these predictions together using a Hidden Markov Model (HMM) to infer the entire input.

#### Single Touch/Gesture Inference

The first step in this process involves demonstrating that the previously described features can also differentiate single touch or swipe inputs. To study this, we segmented the accelerometer data for PINs and patterns based on the recorded touch logs, allowing features to be extracted for each individual event. While the segmentation process using only accelerometer data is beyond the scope of this work, it is likely feasible, as described in [34].

We conducted experiments to infer both unigrams and bigrams. A unigram consists of a swipe across a contact point in a pattern or touching a single digit for a PIN. A bigram, on the other hand, consists of a swipe connecting two contact points in a pattern or two sequential digit presses in a PIN. There are 9 and 10 possible unigram values for patterns and PINs, respectively, and 72 and 100 possible bigram values for patterns and PINs, respectively. We used the collected accelerometer data, divided it into uni- and bigrams using the touch information, and performed a five-fold cross-validation for each user. The average results across all users are presented in Figure 13.

Clearly, both unigram and bigram prediction rates are well above random chance, with bigrams generally performing better. This bodes well for sequence prediction using bigrams. However, when we tested and trained on different users or introduced movement noise, the models performed poorly, often achieving only a small fraction above random chance or even worse. As we will discuss later, when using such models in an HMM, they were unable to infer the input, even after 1000 guess attempts.

#### Comparison to Taplogger

For unigram inference of PINs, we can compare our results to those of taplogger [34], which uses gyroscopic data to infer where on a touchscreen a tap event occurred. Our technique, which uses accelerometer data, performs comparably to taplogger, either nearly as well or slightly better, as shown in Figure 14 for four guesses (described as coverage in [34]).

#### Hidden Markov Model Inference

With models for individual touches or swipes, it is now possible to construct an HMM that selects the most likely (maximum a posteriori) set of touch or gesture inputs. For this experiment, we used a transition matrix trained from a set of 50 PINs and 50 patterns, and employed bigram models. Unigram prediction results were found to be very poor.

The results of the experiment are presented in Figure 15. On the x-axis is the number of guesses (or paths in the HMM attempted), and the y-axis is the prediction result. The most likely path is straightforward to obtain. To generate additional high-scoring paths from the HMM, we ordered the set of labels at each position by their max-marginal probabilities and employed non-max suppression to get a diverse set of guesses. The details of this technique can be found in [25].

At 20 guesses, the results for both PINs and patterns are very good. Patterns can be inferred with an accuracy of 26%, and PINs with an accuracy of 40%. These results are from a cross-validation for a single user on a single device. Similar experiments where we cross-trained on all users and tested on a single user showed significantly lower performance, and the actual PIN or pattern was rarely predicted. When applied to data collected while users were walking, the HMM performed very poorly, predicting with an accuracy far below 1%.

These results suggest that attackers' capabilities are mixed when limited labeled data is available. If the attacker has sufficient training on a single user in a controlled setting, they would likely perform well. However, adverse conditions such as movement noise or limited training greatly affect the models, potentially rendering them ineffective.

### 8. Sensors and Device Security

Given these results and previous sensor-based side-channel results [6, 7, 22, 24, 34], it is clear that any effective security mechanisms for touchscreen devices with movement sensors must deny untrusted applications access to the accelerometer when sensitive touchscreen input is being provided. At the same time, it may be undesirable to restrict access to the accelerometer (and other sensors) when sensitive input operations are not being performed. Many legitimate applications, such as pedometers, need continuous access to the accelerometer, and requiring users to manually shut them down before performing sensitive operations would reduce their appeal.

One approach might be to carefully vet applications that use sensors for malicious behavior before allowing them to be installed or made available in application markets. Unfortunately, this approach is logistically impractical at scale. An alternative approach, exemplified by Google in the Android App Market, is to label applications that access sensors using a permission model; however, this is insufficient because users may ignore such labels or not understand their implications.

Another approach may be to restrict the sampling rate of the sensors, as suggested in [24]. However, our experiments show that even with a relatively low sample rate of 20 Hz, prediction accuracy remains high and comparable to devices with sample rates of 50 Hz or more. Such a technique would likely require reducing the sample rate below the functional level required by legitimate applications.

We propose an alternative strategy: Applications installed by the user that require access to movement sensors should be able to use them at the highest sample rate allowed. However, the sensors should be disabled (or untrusted applications denied access to them) whenever a trusted input function, such as password entry, is being performed. Unfortunately, current handheld platforms do not support temporal access control over sensors, but context-based security rules proposed in [23] and [9] could be adopted. Currently, applications declare what access they need once, typically during installation, and then have essentially unrestricted, permanent access to everything they asked for at any time.

Although current mobile platforms do not support temporary revocation of sensor access, it could be implemented via a system call available to trusted input functions to obtain and revoke exclusive access to sensors. One approach would be for this system call to cause any untrusted application that requests access to a sensitive sensor to block (or fail) until the sensitive operation has concluded. Alternatively, untrusted applications could simply be suspended for the duration of the sensitive input.

### 9. Conclusion

In this paper, we demonstrate that the accelerometer sensor can function as a side channel against secure input, and our results indicate that a surprising amount of information can be inferred, even when movement noise is introduced. We show that there is consistency across users and devices, despite varied sample rates, and the construction of a sensor-reading-to-input dictionary is possible. However, in less controlled settings, such dictionaries may be ineffective. Further, we show that sequence predictions, in the form of an HMM, can be applied if insufficient labeled accelerometer readings are available, but such models are prone to false predictions caused by movement noise and cross-user training.

Given these new results and previous results using the accelerometer sensor [24] and gyroscopic sensor [6, 34], it is clear that the security model for on-board sensors on smartphones should be reconsidered. Both the new and previous results should be considered conservative estimates of the potential threat. Enhancements to features and larger data sources will inevitably lead to greater fidelity side channels, as seen in the study of keyboard acoustic side channels from supervised learning strategies [1] to unsupervised learning strategies [35]. It is clear that applications that have access to the accelerometer sensor should not be able to read from the sensor while the user is providing sensitive input. Current mobile platform permission schemes are insufficient to specify this; they provide applications with "all or nothing" access to every sensor they might ever need to use. The permission scheme and enforcement mechanism should restrict or allow access to sensors based on context: untrusted applications that require access to a sensor should be granted access only when sensitive input operations are not occurring.

### References

[1] Dmitri Asonov and Rakesh Agrawal. Keyboard accoustic emanations. In Proceedings of IEEE Symposium on Security and Privacy, 2004.

[2] Adam J. Aviv, Katherine Gibson, Evan Mossop, Matt Blaze, and Jonathan M. Smith. Smudge attacks on smartphone touch screens. In Proceedings of the 4th USENIX Workshop On Offensive Technologies, WOOT’10, 2010.

[3] Ling Bao and Stephen Intille. Activity recognition from user-annotated acceleration data. In Pervasive Computing, volume 3001 of Lecture Notes in Computer Science, pages 1–17. 2004.

[4] Alastair R. Beresford, Andrew Rice, and Nicholas Skehin. Mockdroid: Trading privacy for application functionality on smartphones. In 12th Workshop on Mobile Computing Systems and Applications, HotMobile’11, 2011.

[5] Joseph Bonneau, Sören Preibush, and Ross Anderson. A birthday present every eleven wallets? The security of customer-chosen banking pins. In Sixteenth International Conference on Financial Cryptography and Data Security, FINCRYPTO ’12, 2012.

[6] Liang Cai and Hao Chen. Touchlogger: Inferring keystrokes on touch screen from smartphone motion. In Proceedings of the 6th USENIX conference on Hot topics in security, HotSec’11, 2011.

[7] Liang Cai and Hao Chen. On the practicality of motion-based keystroke inference attack. In Proceedings of the 5th International Conference on Trust & Trustworthy Computing, Trust’12, 2012.

[8] Liang Cai, Sridhar Machiraju, and Hao Chen. Defending against sensor-sniffing attacks on mobile phones. In Proceedings of the 1st ACM workshop on Networking, systems, and applications for mobile handhelds, MobiHeld ’09, 2009.

[9] Mauro Conti, Vu Nguyen, and Bruno Crispo. Crepe: Context-related policy enforcement for android. In Mike Burmester, Gene Tsudik, Spyros Magliveras, and Ivana Ilic, editors, Information Security, volume 6531 of Lecture Notes in Computer Science, pages 331–345. Springer Berlin / Heidelberg, 2011.

[10] Google Android Development. http://developer.android.com/reference/android/hardware/SensorEvent.html.

[11] Splasho Development. Pattern lock pro. https://market.android.com/details?id=com.splasho.patternlockpro.

[12] Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. Liblinear: A library for large linear classification. J. Mach. Learn. Res., 9:1871–1874, June 2008.

[13] Google Inc. Google wallet. http://www.google.com/wallet/.

[14] THQ Inc. Star wars: Lightsaber duel. http://itunes.apple.com/us/app/star-wars-lightsaber-duel/id362158521?mt=8.

[15] Rupesh Jain. Pattern encrypt/decrypt upgrade. https://market.android.com/details?id=PatternEncryptDecryptUpgrade.free.

[16] M.J. Kearns and U.V. Vazirani. An introduction to computational learning theory. The MIT Press, 1994.

[17] D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques. The MIT Press, 2009.

[18] Jiayang Liu, Lin Zhong, Jehan Wickramasuriya, and Venu Vasudevan. uWave: Accelerometer-based personalized gesture recognition and its applications. Pervasive Mob. Comput., 5:657–675, December 2009.

[19] Jani Mäntyjärvi, Juha Kela, Panu Korpipää, and Sanna Kallio. Enabling fast and effortless customization in accelerometer-based gesture interaction. In Proceedings of the 3rd international conference on Mobile and ubiquitous multimedia, MUM ’04, 2004.

[20] Philip Marquardt, Arunabh Verma, Henry Carter, and Patrick Traynor. (sp)iPhone: Decoding vibrations from nearby keyboards using mobile phone accelerometers. In Proceedings of the 18th ACM conference on Computer and communications security, CCS ’11, 2011.

[21] Uwe Maurer, Anthony Rowe, Asim Smailagic, and Daniel P. Siewiorek. eWatch: A wearable sensor and notification platform. In Proceedings of the International Workshop on Wearable and Implantable Body Sensor Networks, 2006.

[22] Emiliano Miluzzo, Alexander Varshavsky, Suhrid Balakrishnan, and Romit Roy Choudhury. Tapprints: Your finger taps have fingerprints. In Proceedings of the 10th international conference on Mobile systems, applications, and services, MobiSys ’12, 2012.

[23] Machigar Ongtang, Stephen McLaughlin, William Enck, and Patrick McDaniel. Semantically rich application-centric security in android. In Computer Security Applications Conference, 2009. ACSAC ’09. Annual, ACSAC ’09, 2009.

[24] Emmanuel Owusu, Jun Han, Sauvik Das, Adrian Perrig, and Joy Zhang. Accessory: Keystroke inference using accelerometers on smartphones. In Proceedings of The Thirteenth Workshop on Mobile Computing Systems and Applications, HotMobile, 2012.

[25] Dennis Park and Deva Ramanan. N-best maximal decoders for part models. In IEEE International Conference on Computer Vision, ICCV’11, 2011.

[26] Rio Park. Memorize pattern. https://market.android.com/details?id=riopark.pattern.

[27] Kurt Partridge, Saurav Chatterjee, Vibha Sazawal, Gaetano Borriello, and Roy Want. TiltType: Accelerometer-supported text entry for very small devices. In Proceedings of the 15th annual ACM symposium on User interface software and technology, UIST ’02, 2002.

[28] C. Randell and H. Muller. Context awareness by analyzing accelerometer data. In Wearable Computers, The Fourth International Symposium on, pages 175–176, 2000.

[29] Nishkam Ravi, Nikhil D, Preetham Mysore, and Michael L. Littman. Activity recognition from accelerometer data. In Proceedings of the Seventeenth Conference on Innovative Applications of Artificial Intelligence (IAAI), pages 1541–1546. AAAI Press, 2005.

[30] Roman Schlegel, Kehuan Zhang, Xiaoyong Zhou, Mehool Intwala, Apu Kapadia, and XiaoFeng Wang. Soundcomber: A stealthy and context-aware sound trojan for smartphones. In Proceedings of the Network and Distributed System Security Symposium, NDSS, 2011.

[31] Dawn Xiaodong Song, David Wagner, and Xuqing Tian. Timing analysis of keystrokes and timing attacks on SSH. In Proceedings of the 10th conference on USENIX Security Symposium, SSYM’01, 2001.

[32] Bump Technologies. Bump app. bu.mp.

[33] Nan Xu, Fan Zhang, Yisha Luo, Weijia Jia, Dong Xuan, and Jin Teng. Stealthy video capturer: A new video-based spyware in 3G smartphones. In Proceedings of the second ACM conference on Wireless network security, WiSec ’09, 2009.

[34] Zhi Xu, Kun Bai, and Sencun Zhu. Taplogger: Inferring user inputs on smartphone touchscreens using on-board motion sensors. In Proceedings of the fifth ACM conference on Wireless network security, 2012.

[35] Li Zhuang, Feng Zhou, and J. D. Tygar. Keyboard acoustic emanations revisited. ACM Trans. Inf. Syst. Secur., 13, November 2009.