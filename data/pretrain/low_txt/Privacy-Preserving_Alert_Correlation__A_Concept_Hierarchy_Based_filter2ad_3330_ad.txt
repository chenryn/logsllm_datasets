# LLDOS 2.0.2 and DMZ/Inside Network Configurations

- **DMZ**
- **Inside**

## Detection Rates and False Alert Rates

| Configuration | Detection Rate (Original) | Detection Rate (Sanitized) | False Alert Rate (Original) | False Alert Rate (Sanitized) |
|---------------|---------------------------|----------------------------|-----------------------------|------------------------------|
| DMZ          | 93.18%                    | 94.74%                     | 92.31%                      | 100%                         |
| Inside       | 70.69%                    | 85.71%                     | 48.00%                      | 83.33%                       |
| Inside       | 93.18%                    | 94.74%                     | 66.67%                      | 62.50%                       |
| Inside       | 93.18%                    | 94.74%                     | 66.67%                      | 62.50%                       |

- **Ms (original)**
- **Ms (sanitized)**
- **Mc (original)**
- **Mc (sanitized)**

## Number of Alerts and Observable Attacks

- **Number of Alerts**: Total number of alerts
- **Observable Attacks**: Number of true attacks
- **False Alert Rate**: Calculated as \(1 - \frac{\text{Number of True Alerts}}{\text{Total Number of Alerts}}\)

## Experimental Verification of Correlation Methods

In the second set of experiments, our goal is to verify whether correlation methods can help differentiate between true and false alerts. We hypothesize that correlated alerts are more likely to be true alerts, and false alerts have a lower likelihood of being correlated. This hypothesis has been experimentally verified in [11] when original alerts are available. We aim to evaluate the results when alerts are sanitized.

Similar to [11], we compute the detection rate as:

\[ \text{Detection Rate} = \frac{\text{Number of Detected Attacks}}{\text{Total Number of Attacks}} \]

We calculated detection rates and false alert rates for the RealSecure network sensor, the correlation approach based on original datasets, and the correlation approach (our optimistic approach) based on sanitized datasets. The results are shown in Table 3. In Table 3, the numbers of alerts for correlation approaches are the numbers of correlated alerts.

### Observations

- Our optimistic approach significantly reduces false alert rates, albeit with a slight sacrifice in detection rates.
- Comparing the detection rates and false alert rates, the approach based on original datasets slightly outperforms our optimistic approach, as original datasets contain more precise information than sanitized ones.

## Evaluation of Aggregation in Alert Correlation Graphs

In the third set of experiments, our goal is to evaluate the effectiveness of aggregation in alert correlation graphs. Due to space constraints, we only show one case for the LL-DOS 1.0 inside dataset. We aggregated the alert correlation graph in Figure 3, setting the temporal constraint \(\delta = \infty\) and the probability threshold \(\theta = 0.1\). The result is shown in Figure 4.

### Findings

- Some false alerts are ruled out (e.g., Email Debug67705), which is highly desirable.
- However, some true alerts are also pruned (e.g., three Sadmind Ping alerts), which is undesirable.
- While it is possible to mitigate this undesirable case by setting a lower probability threshold, we cannot guarantee that only false alerts will be ruled out.
- Therefore, aggregation should be applied with caution. The alert correlation graphs created from the optimistic approach and the aggregated correlation graphs complement each other and should be used together to better understand security threats.

## Related Work

To our knowledge, [7] is the only paper that explicitly addresses privacy issues in alert correlation. This approach is complementary to ours. DShield allows audit log submitters to perform partial or complete obfuscation of destination IP addresses to sanitize sensitive information. Our approach can be considered an extension to the DShield approach, where the sanitization process is guided by the desired entropy, determined by the privacy policy, and leaves the maximum allowable information for further analysis.

Our work is also closely related to k-Anonymity approaches [15, 18], where an entity's information may be released only if there exist at least \(k-1\) other entities in the released data that are indistinguishable from this entity. These approaches use generalization hierarchies to help obfuscate attributes, where \(k\) is a pre-defined parameter to control the generalization process. Our approach differs in that we use entropy to control attribute sanitization and to help design satisfactory concept hierarchies. Additionally, we study methods to correlate sanitized alerts.

Other techniques that may be used to protect the privacy of alerts include data perturbation techniques [14, 6] used in statistical databases [1] and privacy-preserving data mining techniques [2].

## Conclusion and Future Work

In this paper, we proposed a concept hierarchy-based approach for privacy-preserving alert correlation. It operates in two phases: 

1. **Entropy-Guided Alert Sanitization**: Sensitive attributes are sanitized through concept hierarchies, where original attribute values are generalized to high-level concepts to introduce uncertainty into the datasets while partially maintaining attribute semantics. We use entropy and differential entropy to measure the uncertainty of sanitized attributes and guide the generalization of original attributes.
2. **Sanitized Alert Correlation**: Focuses on defining similarity functions between sanitized attributes and building attack scenarios from sanitized alerts.

### Future Research Directions

- One focus is to define new similarity functions for sanitized attributes, especially when the heuristics between original attributes are complex.
- We noticed that alert correlation graphs constructed from our optimistic approach may include false "prepare-for" relations, and we will investigate how to refine them in future work.

## References

[1] N. Adam and J. Wortmann. Security-control methods for statistical databases: A comparison study. ACM Computing Surveys, 21(4):515–556, 1989.

[2] R. Agrawal and R. Srikant. Privacy-preserving data mining. In Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, May 2000.

[3] T. Cover and J. Thomas. Elements of Information Theory. John Wiley & Sons, Inc., 1991.

[4] F. Cuppens and A. Miege. Alert correlation in a cooperative intrusion detection framework. In Proceedings of the 2002 IEEE Symposium on Security and Privacy, May 2002.

[5] H. Debar and A. Wespi. Aggregation and correlation of intrusion-detection alerts. In Recent Advances in Intrusion Detection, LNCS 2212, pages 85 – 103, 2001.

[6] C. Liew, U. Choi, and C. Liew. A data distortion by probability distribution. ACM Transactions on Database Systems, 10(3):395–411, September 1985.

[7] P. Lincoln, P. Porras, and V. Shmatikov. Privacy-preserving sharing and correlation of security alerts. In Proceedings of 13th USENIX Security Symposium, August 2004.

[8] MIT Lincoln Lab. 2000 DARPA intrusion detection scenario specific datasets. http://www.ll.mit.edu/IST/ideval/data/2000/2000_data_index.html, 2000.

[9] B. Morin and H. Debar. Correlation of intrusion symptoms: An application of chronicles. In Proceedings of the 6th International Conference on Recent Advances in Intrusion Detection (RAID’03), September 2003.

[10] B. Morin, L. Mé, H. Debar, and M. Ducassé. M2D2: A formal data model for IDS alert correlation. In Proceedings of the 5th International Symposium on Recent Advances in Intrusion Detection (RAID 2002), pages 115–137, 2002.

[11] P. Ning, Y. Cui, and D. S. Reeves. Constructing attack scenarios through correlation of intrusion alerts. In Proceedings of the 9th ACM Conference on Computer and Communications Security, pages 245–254, Washington, D.C., November 2002.

[12] P. Ning and D. Xu. Hypothesizing and reasoning about attacks missed by intrusion detection systems. ACM Transactions on Information and System Security, 7(4):591–627, November 2004.

[13] P. Porras, M. Fong, and A. Valdes. A mission-impact-based approach to INFOSEC alarm correlation. In Proceedings of the 5th International Symposium on Recent Advances in Intrusion Detection (RAID 2002), pages 95–114, 2002.

[14] S. Reiss. Practical data-swapping: The first steps. ACM Transactions on Database Systems, 9(1):20–37, March 1984.

[15] P. Samarati and L. Sweeney. Protecting privacy when disclosing information: k-anonymity and its enforcement through generalization and suppression. Technical Report SRI-CSL-98-04, Computer Science Laboratory, SRI International, 1998.

[16] C. Shannon. A mathematical theory of communication. The Bell System Technical Journal, 27:379–423, 623–656, July 1948.

[17] S. Staniford, J. Hoagland, and J. McAlerney. Practical automated detection of stealthy portscans. Journal of Computer Security, 10(1/2):105–136, 2002.

[18] L. Sweeney. k-anonymity: A model for protecting privacy. International Journal on Uncertainty, Fuzziness and Knowledge-based Systems, 10(5):557–570, October 2002.

[19] A. Valdes and K. Skinner. Probabilistic alert correlation. In Proceedings of the 4th International Symposium on Recent Advances in Intrusion Detection (RAID 2001), pages 54–68, 2001.

[20] V. Yegneswaran, P. Barford, and S. Jha. Global intrusion detection in the domino overlay system. In Proceedings of the 11th Annual Network and Distributed System Security Symposium (NDSS’04), February 2004.

---

**Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005)  
1063-9527/05 $20.00 © 2005 IEEE  
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25, 2021, at 12:08:53 UTC from IEEE Xplore. Restrictions apply.**