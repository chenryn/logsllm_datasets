### Error Characteristics and Detection Mechanisms

The magnitude and occurrence of errors in matrices A and B are randomly determined. We do not analyze the case where errors appear in matrix C, as our theory (see Table 1) indicates that such errors will always be detected by any of the detection methods, provided they make a non-negligible difference in the result.

The error detection mechanisms performed as expected. All significant errors introduced in matrix A were detected by both the left-sided and two-sided detection methods. Similarly, all significant errors introduced in matrix B were detected by the right-sided and two-sided detection methods. In practice, both the left- and right-sided methods were capable of detecting significant errors in either matrix A or B. As predicted, when we created a matrix A with columns summing to zero, the left-sided detection method had difficulty detecting errors in B. Conversely, when we created a matrix B with rows summing to zero, the right-sided detection method had trouble detecting errors in A.

### Performance Evaluation

Next, we evaluated the overhead introduced by our error detection and correction techniques. We added the error detection and correction mechanisms described in the previous sections to the implementation of matrix-matrix multiplication in ITXGEMM. As shown in [8, 9], this implementation (without error detection and correction) is highly competitive with other efforts (e.g., [16], which does not address fault-tolerance) in providing high-performance matrix-matrix multiplication for the Intel Pentium (R) III processor.

We report results for the following fault-tolerant matrix-matrix multiplication implementations:
- **L/R/2-sided detect**: ITXGEMM-based implementation with left/right/two-sided detection.
- **L/R/2-sided correct**: ITXGEMM-based implementation with left/right/two-sided detection and correction.

Specifically, the error detection and correction mechanisms were added to the MPP-MMP-MPM algorithm described in [8]. A significant error was introduced in matrix A, and it was always detected and, if desired, corrected.

Figure 2 shows the performance achieved by the different matrix-matrix multiplication implementations for rank-k updates (m = n, k = 128) and general square matrix-matrix multiplication (m = n = k). For this prototype implementation, the error detection methods reduce performance by 20-25% even if no error is introduced. When a single error is introduced and corrected, the performance of the right-sided detection and correction method is significantly worse. The performance of the left-sided method is not significantly affected, supporting the observations made in Section 4.2. Since the left-sided error detection and correction methods also detect and correct virtually all errors introduced in B, the two-sided method is also not significantly affected.

It should be noted that we expect to reduce overhead significantly by carefully amortizing the required additional computations. Furthermore, while we currently tie the blocking used for the error detection and correction mechanisms to the blocking used by ITXGEMM for moving data into the L2 cache, overhead can be reduced if a coarser blocking were allowed. This would, however, require additional memory for the roll-back mechanism and increase computational overhead if a correction becomes necessary.

### Status

We currently have a complete implementation of the above ideas for the operations:
- \( C \leftarrow \alpha AB + \beta C \)
- \( C \leftarrow \alpha A^T B + \beta C \)
- \( C \leftarrow \alpha A B^T + \beta C \)
- \( C \leftarrow \alpha A^T B^T + \beta C \)

Using similar techniques, we have also created fault-tolerant implementations for all level 3 BLAS operations using our Formal Linear Algebra Methods Environment [9, 10]. While we currently target only double-precision real arithmetic and have implementations for the Intel Pentium (R) III processor, the techniques can be easily extended to single-precision or complex arithmetic and to other architectures.

The ultimate goal is to create an environment for developing fault-tolerant linear algebra libraries, the Formal Linear Algebra Recovery Environment (FLARE), which may eventually include fault-tolerant implementations for the major operations included in LAPACK.

### Conclusion

In this paper, we have significantly extended the theory and practice of algorithmic fault-tolerant matrix-matrix multiplication. Specifically, we have expanded on existing results relevant to the detection of errors in the computation \( C = AB \). Based on these theoretical results, we have provided a practical, fault-tolerant, high-performance implementation of the matrix-matrix multiplication operation. It is evident that these results extend to all cases of matrix-matrix multiplication that are part of the BLAS. The experimental results demonstrate that our methods introduce, in practice, an acceptable level of overhead (about 20% for the error detection mechanism and an insignificant additional amount when a correction is required) relative to high-performance implementations that do not include algorithmic fault-tolerance.

### Additional Information

For additional information, visit:
[www.cs.utexas.edu/users/flame/FLARE/](http://www.cs.utexas.edu/users/flame/FLARE/).

### References

1. Remote Exploration and Experimentation Project Plan, July 2000. [http://ree.jpl.nasa.gov/](http://ree.jpl.nasa.gov/)
2. E. Anderson, Z. Bai, J. Demmel, J. E. Dongarra, J. DuCroz, A. Greenbaum, S. Hammarling, A. E. McKenney, S. Ostrouchov, and D. Sorensen. *LAPACK Users’ Guide*. SIAM, Philadelphia, 1992.
3. E. Barragy and R. van de Geijn. "BLAS performance for selected segments of a high p EBE finite element code." *International Journal on Numerical Methods in Engineering*, 38: 1327-1340, 1995.
4. E. Chen, L. Craymer, J. Deifik, A. J. Fogel, D. S. Katz, A. G. Silliman, Jr., R. R. Some, S. A. Upchurch, and K. Whisnant. "Demonstration of the Remote Exploration and Experimentation (REE) fault-tolerant parallel-processing supercomputer for spacecraft onboard scientific data processing." *Proceedings of the IEEE International Conference on Dependable Systems and Networks*, pages 367-372, 2000.
5. Jack J. Dongarra, Jeremy Du Croz, Sven Hammarling, and Iain Duff. "A set of level 3 basic linear algebra subprograms." *ACM Trans. Math. Soft.*, 16(1):1-17, March 1990.
6. Jack J. Dongarra, Iain S. Duff, Danny C. Sorensen, and Henk A. van der Vorst. *Solving Linear Systems on Vector and Shared Memory Computers*. SIAM, Philadelphia, PA, 1991.
7. Gene H. Golub and Charles F. Van Loan. *Matrix Computations*. The Johns Hopkins University Press, Baltimore, 2nd edition, 1989.
8. J. A. Gunnels, G. M. Henry, and R. A. van de Geijn. "A family of high-performance matrix multiplication algorithms." *Submitted to The 2001 International Conference on Computer Science (ICCS2001)*, May 2001.
9. John A. Gunnels, Greg M. Henry, and Robert A. van de Geijn. "Formal Linear Algebra Methods Environment (FLAME): Overview." *FLAME Working Note #1 CS-TR-00-28*, Department of Computer Sciences, The University of Texas at Austin, Nov. 2000.
10. John A. Gunnels and Robert A. van de Geijn. "Formal methods for high-performance linear algebra libraries." In Ronald E. Boisvert and Ping Tak Peter Tang, editors, *The Architecture of Scientific Software*. Kluwer Academic Press, 2001.
11. K. Huang and J.A. Abraham. "Algorithm-based fault tolerance for matrix operations." *IEEE Trans. on Computers*, 33(6):518-528, 1984.
12. B. Kågström, P. Ling, and C. Van Loan. "GEMM-based level 3 BLAS: High performance model implementations and performance evaluation benchmark." *TOMS*, 24(3):268-302, 1998.
13. Paula Prata and João Gabriel Silva. "Algorithm based fault tolerance versus result-checking for matrix computations." *Proceedings of the Twenty-Ninth Annual International Symposium on Fault-Tolerant Computing*, pages 4-11, 1999.
14. M. Turmon, R. Granat, and D. Katz. "Software-implemented fault detection for high-performance space applications." *Proceedings of the IEEE Int. Conf. on Dependable Systems and Networks*, pages 107-116, 2000.
15. H. Wasserman and M. Blum. "Software reliability via run-time result-checking." *Journal of the ACM*, 44(6):826-849, 1997.
16. R. Clint Whaley and Jack J. Dongarra. "Automatically tuned linear algebra software." *Proceedings of SC'98*, 1998.