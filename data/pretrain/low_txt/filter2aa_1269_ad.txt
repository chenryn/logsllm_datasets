### 7.2 Blinding Attack

Our attack is based on the assumption that CMOS/CCD sensors can be disturbed by malicious optical inputs, leading to the generation of unrecognizable images. These corrupted images will further influence the decision-making process of the ADAS unit and indirectly affect vehicle control. As a consequence, this can lead to the car deviating from its path, triggering an emergency brake, or potentially causing a crash.

**Figure 10: Forward-looking camera system block diagram [20].**

#### 7.2.1 Description

A common method to attack video equipment is through laser blinding. Photoelectric sensors are highly sensitive to light intensity. With a peak absorption coefficient generally ranging from \(10^3\) to \(10^5\), most of the laser energy at the sensor can be absorbed. The time required to damage a photoelectric sensor is one to several orders of magnitude less than the time needed to harm human eyes.

Under laser exposure, the surface temperature of the sensor rises rapidly due to thermal stress caused by a non-uniform temperature field. This can lead to avalanche breakdown in semiconductor materials, causing irreversible damage to the photoelectric devices. Camera exposure to laser radiation can occur when LiDARs are nearby. LEDs can also be used to generate bright light against cameras. In our experiment, we used three types of light sources: LED, visible laser, and infrared LED.

**Figure 11: Setup of camera blinding experiment. A is a calibration board, B is a camera, C1 and C2 are laser emitters.**

The experimental setup for the blinding attack is illustrated in Figure 11. A calibration board (A) is positioned 1 meter in front of the camera (B). Laser sources (C1 and C2) are either pointed at the camera or at the calibration board. C1 is positioned at a 15° angle to the axis of A–B, and C2 at a 45° angle. We tested with a 650 nm red laser, an 850 nm infrared LED spot, and an 800 mW LED spot, observed the camera image output, and measured the change in tonal distribution.

**Figure 12: Blinding camera with LED spot.**
(a) Toward board.
(b) Toward camera.
(c) Tonal distribution.

**Figure 13: Blinding camera with confronted laser.**
(a) Fixed beam.
(b) Wobbling beam.
(c) Damage caused by laser.
(d) Damage is permanent.

#### 7.2.2 Results

- **LED:** Aiming LED light at the calibration board results in increased tonal values in the center area, concealing information and making recognition impossible. Directly aiming the LED light at the camera induces significantly higher tonal values, causing complete blindness across the entire image. The camera system cannot acquire any visual information. The blinding time depends on the camera's refresh rate and the distance between the light source and the camera. The results are shown in Figure 12.

- **Laser:** Pointing a laser beam at the calibration board has almost no effect on the camera. However, directly pointing it at the camera leads to complete blindness for approximately 3 seconds, during which recognition is impossible. We also conducted an experiment with a wobbling laser beam to simulate handheld attacks or unintentional scenarios. As shown in Figure 13(b), this can also cause failure in camera image recognition, although the tonal values are not as high due to shorter exposure times at specific spots on the CMOS/CCD chip.

- **Permanent Damage:** When a laser beam is directly radiated at the camera within 0.5 meters and for a few seconds, irreversible damage can be caused to the CMOS/CCD chip. The black curve in Figure 13(c) provides evidence of this. Even after turning off the laser, the curve remains, as shown in Figure 13(d). Therefore, the damage is permanent and irreversible, and can only be fixed by replacing the CMOS/CCD component. Unintentional damage of this kind can be caused by nearby laser radars.

- **Infrared LED:** No effect on the camera was observed when the infrared LED spot was directed either at the camera or the board. This is likely due to the narrow frequency band of filters on the camera, indicating good hardware quality.

### 8. Discussion

In this section, we discuss the feasibility of our attacks on ultrasonic sensors, MMW Radars, and cameras from the perspectives of security research and real-world attacks. Based on our experience and limited expertise, we propose countermeasures against these attacks. Finally, we conclude with the limitations of our work and call for new findings in the future.

#### 8.1 Attack Feasibility

We evaluate the feasibility of our attacks by considering influential factors, knowledge threshold, hardware cost, detection by the system, and detection by the driver.

##### 8.1.1 Influential Factors

The success rate of the attack is affected by various factors, including distance, angle, weather, surroundings, equipment performance, and sensor design. We will focus on distance and angle.

- **Distance:** In ultrasonic attacks, jamming is typically kept within 1 meter due to atmospheric attenuation and the high jamming noise amplitude required. Spoofing can be done within several meters. The distance can be increased with equipment that generates higher sound pressure and narrower beam patterns. For radar and camera attacks, the maximum distance was not measured due to location limitations, which will be discussed later.

- **Angle:** In ultrasonic attacks, the best performance is achieved at a perpendicular angle. This is because sound is a longitudinal wave and projects most of its energy in the forward direction. However, up to a 75° angle to the sensor's perpendicular axis works when spoofing aims to create a ghost target. Angles were not tested for camera and radar attacks.

##### 8.1.2 Knowledge Threshold

To attack a sensor, a certain level of knowledge is required, including the system model, working principle, relevant physics, and skills to build or operate hardware equipment. Since attack methods on one type of sensor are not easily transferable to another, learning and researching must start anew, which can be time-consuming. Among the three sensors we studied, ultrasonic sensors are the easiest to approach, while radars are the most challenging.

##### 8.1.3 Hardware Cost

- **Ultrasonic Sensors:** An Arduino and transducer cost $23, and can be even cheaper if made in-house.
- **Laser Pointer:** A few dollars can cause permanent damage to a camera, regardless of whether it is on or off.
- **MMW Radar:** There are no off-the-shelf tools available. General equipment, like the ones we used, can cost more than a Tesla Model S.

##### 8.1.4 Detection by System

For all the attacks described in this paper, no alarm of "malicious attack" or "system failure" is given by the system. Under ultrasonic attacks, the system either displays the spoofed distance, no detection, or no display at all. Interestingly, in [18], it is noted that in the presence of ultrasonic noise, "the system responds by indicating a fault to the driver or a pseudo-obstacle at a distance that is less than potentially real obstacles." For jamming attacks, the distance is falsified to the maximum (indicating no detection), but no alarm is given. Under radar attacks, the detected object disappears, but no alarm of radar system error or any other type is given, and the Autopilot mode is not forced off.

##### 8.1.5 Detection by Driver

Detection of ultrasonic and radar attacks by the driver is unlikely due to the imperceptibility of ultrasound and MMW radio. Camera attacks using lasers are more likely to be discovered, unless the damage has already been done. There is a possibility that the driver may become suspicious of the equipment, so it is necessary to carefully hide the equipment or reduce its size.

##### 8.1.6 On Road Attack

We believe on-road attacks are possible. Ultrasonic jammers can be hidden in a fixed cover or held by hand. Radar equipment can be hidden at the roadside for fixed-spot attacks or in the trunk or a van for mobile attacks, leaving only the tiny antenna outside for concealment. Laser pointers or dazzlers can be placed similarly.

#### 8.2 Countermeasures

From the sensor side, jamming attacks can be easily recognized, especially for ultrasonic sensors and radars, as there are very few sources of ultrasonic and MMW radio noise in the working environment, particularly with high power. Many sensor applications have implemented noise rejection, but they are not designed with the security concern of malicious jamming and spoofing in mind.

On the systems side, we suggest using multiple sensors for redundancy checks, such as ultrasonic MIMO systems. We also recommend adding randomness into control parameters, incorporating logic checks, confidence priority, and attack detection systems into the sensor data fusion strategy.

#### 8.3 Limitations and Future Work

- **Ultrasonic Sensors:** We aim to increase the attack range by developing equipment with better performance and continuing the ultrasound cancellation system.
- **MMW Radars:** Due to test yard limitations, we were unable to test the attack performance at different distances and angles. We hope to conduct further tests in an open field and while the Tesla is moving.
- **Cameras:** We plan to research more on the feasibility of spoofing attacks.

Additionally, for most of the attacks, we could only observe the results from the vehicle display rather than from the sensors themselves, making it unclear where the problems originate, i.e., from the sensors or the ECUs. We hope to further analyze the automated driving system and monitor all states for a better understanding of system-level security.

### 9. Conclusions

This paper highlights that sensor security is a realistic issue for the safety of autonomous vehicles. We studied and examined three essential types of sensors used in Automated Driving Systems and deployed in Tesla vehicles with Autopilot: ultrasonic sensors, Millimeter Wave Radars, and cameras. Jamming and spoofing attacks were launched against these sensors both indoors and outdoors, causing malfunctions in the automotive system, which could potentially lead to crashes and compromise the safety of self-driving cars.

### 10. Acknowledgments

We thank Xin Bi and Keysight Open Laboratory & Solution Center in Beijing for their professional support and access to radar equipment. We also thank the Xmyth Team for participating in the ultrasonic research.

### 11. References

[1] Arduino. Arduino and Genuino Project. https://www.arduino.cc/. Accessed: 2016-07-05.
[2] L. Bergmann. The ultrasound and its application in science and technology. 1954.
[3] S. Checkoway, D. Mccoy, B. Kantor, D. Anderson, H. Shacham, S. Savage, K. Koscher, A. Czeskis, F. Roesner, and T. Kohno. Comprehensive Experimental Analyses of Automotive Attack Surfaces. System, pages 1–6, 2011.
[4] H. Chen and C. Chan. Acoustic cloaking in three dimensions using acoustic metamaterials. Applied Physics Letters, 91(18):183518, 2007.
[5] S. A. Cummer and D. Schurig. One path to acoustic cloaking. New Journal of Physics, 9(3):45, 2007.
[6] S. J. Elliott and P. A. Nelson. Active noise control. IEEE Signal Processing Magazine, 10(4):12–35, 1993.
[7] Google. Google Self-Driving Car Project. https://www.google.com/selfdrivingcar/. Accessed: 2016-07-06.
[8] S. Hall. Elon Musk says that the LIDAR Google uses in its self-driving car ‘doesn’t make sense in a car context’. http://9to5google.com/2015/10/16/. Accessed: 2016-07-06.
[9] J. Hasch, E. Topak, R. Schnabel, T. Zwick, R. Weigel, and C. Waldschmidt. Millimeter-wave technology for automotive radar sensors in the 77 GHz frequency band. IEEE Transactions on Microwave Theory and Techniques, 60(3):845–860, 2012.
[10] L. He. Development of submarine acoustic stealth technology. Ship Science and Technology, 28(s2):9–17, 2006.
[11] R. Katzwinkel, R. Auer, S. Brosig, M. Rohlfs, V. Schöning, F. Schroven, F. Schwitters, and U. Wuttke. Einparkassistenz. In Handbuch Fahrerassistenzsysteme, pages 471–477. Springer, 2012.
[12] K. Koscher, A. Czeskis, F. Roesner, S. Patel, T. Kohno, S. Checkoway, D. McCoy, B. Kantor, D. Anderson, H. Snach??m, and S. Savage. Experimental security analysis of a modern automobile. Proceedings - IEEE Symposium on Security and Privacy, pages 447–462, 2010.
[13] H. Kuttruff. Ultrasonics: Fundamentals and Applications. Springer Science & Business Media, 2012.
[14] J. Li and J. Pendry. Hiding under the carpet: a new strategy for cloaking. Physical Review Letters, 101(20):203901, 2008.
[15] C. Miller and C. Valasek. A Survey of Remote Automotive Attack Surfaces. Defcon 22, 2014.
[16] C. Miller and C. Valasek. Remote Exploitation of an Unaltered Passenger Vehicle. Blackhat USA, 2015:1–91, 2015.
[17] M. Noll and P. Rapps. Ultraschallsensorik. In Handbuch Fahrerassistenzsysteme, pages 110–122. Springer, 2012.
[18] M. Noll and P. Rapps. Ultrasonic sensors for a k44das. In Handbook of Driver Assistance Systems: Basic Information, Components and Systems for Active Safety and Comfort, pages 303–323. Springer, 2016.
[19] J. Petit, B. Stottelaar, M. Feiri, and F. Kargl. Remote Attacks on Automated Vehicles Sensors: Experiments on Camera and LiDAR. Blackhat.com, pages 1–13, 2015.
[20] Renesas. Front Detection. https://www.renesas.com/zh-cn/solutions/automotive/adas/front.html. Accessed: 2016-07-07.
[21] M. Seiter, H.-J. Mathony, and P. Knoll. Parking assist. In Handbook of Intelligent Vehicles, pages 829–864. Springer, 2012.
[22] M. Skolnik. An introduction and overview of radar. Radar Handbook, 3, 2008.
[23] Y. Son, H. Shin, D. Kim, Y. Park, J. Noh, K. Choi, J. Choi, and Y. Kim. Rocking drones with intentional sound noise on gyroscopic sensors. In 24th USENIX Security Symposium (USENIX Security 15), pages 881–896, 2015.
[24] R. Staszewski and H. Estl. Making cars safer through technology innovation. White Paper by Texas Instruments Incorporated, 2013.
[25] S. A. D. Team. Welcome. http://driving.stanford.edu/. Accessed: 2016-07-06.
[26] Tesla. A tragic loss. https://www.teslamotors.com/blog/tragic-loss, June 2016.
[27] Tesla Motors. Tesla Model S Software Release Notes v7.1, 2016.
[28] C. Valasek and C. Miller. Adventures in Automotive Networks and Control Units. Technical White Paper, page 99, 2013.
[29] J. Waanders. Piezoelectric ceramics-properties and applications. Philips Components. Marketing Communications, 1991.
[30] Wikipedia. Teardrop hull. https://en.wikipedia.org/wiki/Teardrop_hull. Accessed: 2016-07-06.
[31] H. Winner. Automotive radar. In Handbook of Driver Assistance Systems: Basic Information, Components and Systems for Active Safety and Comfort, pages 325–403. Springer, 2016.
[32] M. Wolf, A. Weimerskirch, and C. Paar. Security in Automotive Bus Systems. Proceedings of the Workshop on Embedded Security in Cars, pages 1–13, 2004.
[33] M. Wolf, A. Weimerskirch, and T. Wollinger. State of the art: Embedding security in vehicles. Eurasip Journal on Embedded Systems, 2007, 2007.