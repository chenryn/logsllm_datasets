### Feature Extraction and Dissimilarity Calculation
We extracted 20-dimensional features from multi-touch traces. Dynamic Time Warping (DTW) was employed to calculate the dissimilarity scores for these features. Our method achieved an average Equal Error Rate (EER) of 7.88% and a best-case EER of 2.98% for "user-defined" gestures. Since no restrictions were imposed on the users' gestures, the proposed features are subject to behavioral variability introduced by variations in finger separation and bending during multi-touch operations. This led to performance deterioration over time, with EERs increasing to nearly 20% for inter-session authentications [14]. Additionally, the proposed gestures require a large touch screen, limiting their applicability to most smartphones with medium or small-sized screens.

### Challenges in Behavioral Biometrics
For all investigated behavioral biometrics on smartphone platforms, variations in behavior or behavioral variability pose a significant challenge, undermining both accuracy and user experience in real applications. To address this issue, we developed a new approach to multi-touch authentication that combines physiological information about hand geometry with behavioral characteristics, thereby significantly reducing behavioral variability.

## Discussion and Future Work

### Authentication Time
Authentication time is a critical aspect of usability in authentication systems on smart devices such as smartphones. This time includes action time, verification time, and enrollment time for our TFST gesture-based authentication.

- **Action Time**: The time required for a user to perform a TFST gesture on the touch screen. For the most complex 4-finger TFST L swipe gesture, it takes approximately 0.75 seconds on average.
- **Verification Time**: The time required for the smart device to verify the legitimacy of a user using the multi-touch trace of their TFST gesture. A prototype system we developed on the Samsung Note 1 takes about 0.2 seconds to perform the verification, with a system overhead of 20M memory and 1% CPU.
- **Enrollment Time**: Consists of the time to provide training samples and the time for model training. As shown in Figure 7, for an EER of 3%, a user should provide 20 training samples of 4-finger TFST L swipes, which takes about 1 minute for an inexperienced user. Model training with KNN on the Note 1 takes about 2-3 seconds. To save enrollment time, we may allow new users to provide 5 training samples, resulting in an enrollment EER of 5.84% (Figure 7), and update the authentication model in subsequent authentication stages.

### Advanced Attacks
In Section VIII, we demonstrated that our method is resilient to four common types of attacks described in our threat model. For biometric authentication, replay attacks are another relevant concern, particularly effective against fingerprint and face recognition [37]. In a replay attack [38], an attacker replays a legitimate userâ€™s previously recorded authentication action to the authentication system.

For our method, a replay attack can be attempted at the touchscreen interface outside the smart device or inside the device by injecting recorded samples directly into the data flow of the authentication system. The latter approach requires access to the inner operating system, meaning local protection must be breached first. This is beyond the scope of our method, which focuses on local protection. For the former approach, success depends on replicating both hand geometry and multi-touch behavior. While not impossible, it is very difficult to achieve by the type of adversaries we aim to defend against, as outlined in Section II.

### Future Work
In this paper, we analyzed simple TFST gestures such as vertical, horizontal, and L swipes, and evaluated their basic capabilities for user authentication. There are more complex TFST gestures worth exploring, such as Z swipes and multi-touch signatures. The stability and discernibility of these gestures are good topics for future research.

Another important area for future work is expanding the dataset. Currently, we have established a reasonably large dataset consisting of more than two months of data from 161 subjects. However, all subjects are from within the campus. It would be beneficial to collect data from other population categories, such as workers and children, and from different ethnic groups. This data can be used to evaluate the generalizability of our results to a more diverse population and provide a more comprehensive basis to demonstrate the effectiveness of our approach.

## Conclusion
In this paper, we propose a simple, fast, reliable, and secure approach to multi-touch authentication using information from both hand geometry and behavioral characteristics. Users are authenticated by performing simple TFST gestures with one swipe on the touchscreen. TFST gestures require users to stretch their fingers and put them together, conforming to a fixed hand geometry and leading to a more stable behavioral pattern. Moreover, TFST gestures require much less touch area than traditional multi-touch operations, making them suitable for a wide range of multi-touch enabled devices, from small-screen smartphones to large-screen tablets or laptops.

To evaluate the reliability of our method, we established a large-scale multi-touch dataset from 161 subjects. The data collection process was carefully designed to capture behavioral variability over time. We conducted a comprehensive experimental analysis with respect to different TFST gestures, feature sets, classifiers, and sizes of training sets. Our approach achieves an EER of 5.84% with only 5 training samples, and the accuracy improves to an EER of 1.88% with sufficient training. The fusion of behavioral information with hand geometry features effectively resists behavioral variability over time, and our identity model demonstrates good applicability to future behavioral data.

Security analyses also show that our method is resilient against common smartphone authentication threats such as smudge attacks, shoulder surfing attacks, and statistical attacks. Finally, a usability study indicates user acceptance of our method.

## Acknowledgments
We would like to thank Prof. Ellen Bass for her valuable comments and careful proofreading. We also thank Prof. Xiaohong Guan, Prof. Qinghua Zheng, and Prof. Roy Maxion for their kind support of this work, and the anonymous reviewers for their helpful comments. We acknowledge the help from Mr. Tao Hua, Ms. Meilan Liu, and Hexiang Wang in the data collection process. This work is supported in part by NSFC grants 61175039, 61375040, and 61221063. Zhi-Li Zhang was supported in part by NSF grants CNS-1411636, DTRA grant HDTRA1-14-1-0040, and ARO MURI Award W911NF-12-1-0385.

## References
[1] S. Wiedenbeck, J. Waters, L. Sobrado, and J.-C. Birget, "Design and evaluation of a shoulder-surfing resistant graphical password scheme," in Proceedings of the Working Conference on Advanced Visual Interfaces, Venezia, Italy, 2006.
[2] A. J. Aviv, K. Gibson, E. Mossop, M. Blaze, and J. M. Smith, "Smudge attacks on smartphone touch screens," in Proceedings of the 4th USENIX Conference on Offensive Technologies, Washington, DC, 2010.
[3] iPhone fingerprint sensor hacked with a finger made of clay at MWC 2016, http://www.techworm.net/2016/02/iphone-fingerprint-sensor-hacked-finger-made-clay-mwc-2016.html
[4] J. Mantyjarvi, M. Lindholm, E. Vildjiounaite, S. M. Makela, and H. A. Ailisto, "Identifying users of portable devices from gait pattern with accelerometers," in Acoustics, Speech, and Signal Processing, 2005. Proceedings. (ICASSP). IEEE International Conference on, 2005, pp. ii/973-ii/976 Vol. 2.
[5] J. R. Kwapisz, G. M. Weiss, and S. A. Moore, "Cell phone-based biometric identification," in Biometrics: Theory Applications and Systems (BTAS), 2010 Fourth IEEE International Conference on, 2010, pp. 1-7.
...
[38] I. Sluganovic, M. Roeschlin, K. B. Rasmussen, and I. Martinovic, "Using Reflexive Eye Movements for Fast Challenge-Response Authentication," in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (CCS), 2016, pp. 1056-1067.