### 5.2 Anomaly Injection and Detection

We follow the methodology of [16] to inject anomalies into the Abilene dataset. While this method has limitations, such as assuming a single volume size is anomalous for all flows, we adopt it for relative comparison between PCA and Robust PCA, to measure the relative effects of poisoning, and for consistency with prior studies. We use week-long training sets, as this time scale is sufficient to capture weekday and weekend cyclic trends [28], and previous studies have used the same time scale [16]. Our method is not inherently limited to this time scale; it will work as long as the training data is poisoned throughout.

The data is binned in 5-minute windows, corresponding to the reporting interval of SNMP. This allows us to make a decision about the presence of an attack at the end of each 5-minute window, enabling detection within 5 minutes of its occurrence.

Starting with the flow traffic matrix \( X \) for the test week, we generate a positive example (an anomalous OD flow) by setting the flow \( f \)'s volume at time \( t \), \( X_{t,f} \), to a large value known to correspond to an anomalous flow. This value is defined [16] as 1.5 times a cutoff of \( 8 \times 10^7 \). After multiplying by the routing matrix \( A \), the link volume measurement at time \( t \) becomes anomalous. We repeat this process for each 5-minute window in the test week to generate 2016 anomaly samples for the single target flow \( f \).

To obtain false positive rates (FPRs), we generate negative examples (benign OD flows) using an Exponentially Weighted Moving Average (EWMA) model. This model captures the main trends of the data without much noise. We compare the actual data with the EWMA model, and if the difference is small (not in the flow's top one percentile) for a particular flow at a particular time \( X_{t,f} \), we label the element \( X_{t,f} \) as "benign." We do this across all flows; when we find time slots where all flows are labeled as benign, we run our detectors to see if they raise an alarm for those time slots.

We simulate a DoS attack along every flow at every time. We average false negative rates (FNRs) over all 144 possible anomalous flows and all 2016 anomaly times. When reporting the effect of an attack on traffic volumes, we first average over links within each flow, then over flows. We generally report average volumes relative to the pre-attack average volumes. Thus, a single poisoning experiment is based on one week of poisoning, with FNRs computed during the test week, which includes \( 144 \times 2016 \) samples from different flows and time slots. For the Add-More-If-Bigger scheme, the poisoning is deterministic, so the experiment was run once. For the Random poisoning scheme, we ran 20 independent repetitions of poisoning experiments because the poisoning is random.

To produce the ROC curves, we use the squared prediction errors (SPEs) produced by the detection methods, consisting of anomalous and normal examples from the test set. By varying the method's threshold from \(-\infty\) to \(\infty\), a curve of possible (FPR, TPR) pairs is produced from the set of SPEs. The Q-statistic and Laplace threshold each correspond to one point in ROC space. We adopt the Area Under Curve (AUC) statistic from Information Retrieval to directly compare ROC curves. The area under an ROC curve of detector \( A \) estimates the conditional probability:

\[ \text{AUC}(A) \approx \Pr (\text{SPE}_A(y_1) > \text{SPE}_A(y_2)) \]

given anomalous and normal random link volume vectors \( y_1 \) and \( y_2 \). The ideal detector has an AUC of 1, while a random predictor achieves an AUC of 0.5.

### 5.3 Single Period & Boiling Frog Poisoning

We evaluate the effectiveness of our attacker strategies using weeks 20 and 21 from the Abilene dataset to simulate Single-Training Period attacks. The PCA algorithm is trained on the week 20 traffic matrix poisoned by the attacker, and we then inject attacks during week 21 to see how often the attacker can evade detection. We select these particular weeks because PCA achieved the lowest FNRs during testing.

To test the Boiling Frog attack, we simulate traffic matrix data inspired by methods used in [16]. Our simulations present multiple weeks of stationary data to the adversary. While such data is unrealistic in practice, it is an easy case on which PCA should succeed. Anomaly detection under non-stationary conditions is difficult due to the learner's inability to distinguish between benign data drift and adversarial poisoning. Demonstrated flaws of PCA in the stationary case constitute strong results. We decided to validate the Boiling Frog attack on a synthesized multi-week dataset because the 6-month Abilene dataset of [33] proved to be too non-stationary for PCA to consistently operate well from one week to the next. It is unclear whether the non-stationarity observed in this data is prevalent in general or an artifact of the dataset.

We synthesize a multi-week set of OD flow traffic matrices with stationarity on the inter-week level. We use a three-step generative procedure to model each OD flow separately. First, the underlying daily cycle of the OD flow \( f \) time series is modeled by a sinusoidal approximation. Then, the times at which the flow is experiencing an anomaly are modeled by a Binomial arrival process with inter-arrival times distributed according to the geometric distribution. Finally, Gaussian white noise is added to the base sinusoidal model during times of benign OD flow traffic, and exponential traffic is added to the base model during times of anomalous traffic.

In step 1, we capture the underlying cyclic trends via Fourier basis functions. We use sinusoids of periods of 7, 5, and 3 days, and 24, 12, 6, 3, and 1.5 hours, as well as a constant function [16]. For each OD flow, we find the Fourier coefficients from the flow's projection onto this basis. We then remove the portion of the traffic modeled by this Fourier forecaster and model the remaining residual traffic via two processes: one is a noise process modeled by a zero-mean Gaussian to capture short-term benign traffic variance, and the second process models volume anomalies as being exponentially distributed.

In step 2, we select which of the two noise processes is used at each time interval. After computing the model's residuals (the difference between the observed and predicted traffic), we note the smallest negative residual value \(-m\). We assume that residuals in the interval \([-m, m]\) correspond to benign traffic and that residuals exceeding \( m \) correspond to traffic anomalies. We separate benign variation and anomalies in this way since these effects behave quite differently. (This is an approximation but works reasonably well for most OD flows.) Negative residual traffic reflects benign variance, and since we assume that benign residuals have a zero-mean distribution, such residuals should lie within the interval \([-m, m]\). Upon classifying residual traffic as benign or anomalous, we then model anomaly arrival times as a Bernoulli arrival process. Under this model, the inter-anomaly arrival times become geometrically distributed. Since we consider only spatial PCA methods, the placement of anomalies is of secondary importance.

For the final step, the parameters for the two residual traffic volume and the inter-anomaly arrival processes are inferred from the residual traffic using the Maximum Likelihood estimates of the Gaussian's variance and exponential and geometric rates, respectively. Positive goodness-of-fit results (Q-Q plots not shown) have been obtained for mouse, medium, and elephant flows.

In our simulations, we constrain all link volumes to respect the link capacities in the Abilene network: 10 Gbps for all but one link that operates at one-fourth of this rate. We cap chaff that would cause traffic to exceed the link capacities.

### 6. POISONING EFFECTIVENESS

#### 6.1 Single Training Period Poisoning

We evaluate the effectiveness of our three data poisoning schemes in Single-Training Period attacks. During the testing week, the attacker launches a DoS attack in each 5-minute time window. The results of these attacks are displayed in Fig. 3. Although our poisoning schemes focus on adding variance, the mean of the OD flow being poisoned also increases, increasing the means of all links over which the OD flow traverses. The x-axis in Fig. 3 indicates the relative increase in the mean rate. We average over all experiments (i.e., over all OD flows).

As expected, the increase in evasion success is smallest for the uninformed strategy, intermediate for the locally-informed scheme, and largest for the globally-informed poisoning scheme. A locally-informed attacker can use the Add-More-If-Bigger scheme to raise his evasion success to 28% from the baseline FNR of 3.67% via a 10% average increase in the mean link rates due to chaff. Although 28% may not be viewed as a high likelihood of evasion, the attacker success rate is nearly 8 times larger than the unpoisoned PCA model's rate. This number represents an average over attacks launched in each 5-minute window, so the attacker could simply retry multiple times. With our Globally-Informed scheme, a 10% average increase in the mean link rates raises the unpoisoned FNR by a factor of 10 to 38% and eventually to over 90%. The big difference between the performance of the locally-informed and globally-informed attacker is intuitive. The globally-informed attacker knows more (traffic on all links and future traffic levels) than the locally-informed one (who only knows the traffic status of a single ingress link). We consider the locally-informed adversary to have succeeded quite well with only a small view of the network. An adversary is unlikely to acquire, in practice, the capabilities used in the globally-informed poisoning attack. Moreover, adding 30% chaff, to obtain a 90% evasion success, is dangerous as the poisoning activity itself is likely to be detected. Therefore, Add-More-If-Bigger presents a nice trade-off, from the adversary's point of view, in terms of poisoning effectiveness, and attacker capabilities and risks. We therefore use Add-More-If-Bigger, the locally-informed strategy, for many of the remaining experiments.

We evaluate the PCA detection algorithm on both anomalous and normal data, as described in Section 5.2, producing the Receiver Operating Characteristic (ROC) curves displayed in Fig. 4. We produce a ROC curve by first training a PCA model on the unpoisoned data from week 20. We then evaluate the algorithm when trained on data poisoned by Add-More-If-Bigger.

To validate PCA-based detection on poisoned training data, we poison exactly one flow at a time as dictated by the threat model. Thus, for relative chaff volumes ranging from 5% to 50%, Add-More-If-Bigger chaff is added to each flow separately to construct 144 separate training sets and 144 corresponding ROC curves for the given level of poisoning. The poisoned curves in Fig. 4 display the averages of these ROC curves (i.e., the average TPR over the 144 flows for each FPR).

We see that the poisoning scheme can throw off the balance between false positives and false negatives of the PCA detector: The detection and false alarm rates drop together rapidly as the level of chaff is increased. At 10% relative chaff volume, performance degrades significantly from the ideal ROC curve (lines from (0, 0) to (0, 1) to (1, 1)), and at 20% the PCA's mean ROC curve is already close to that of blind randomized prediction (the y = x line with 0.5 AUC).

#### 6.2 Multi-Training Period Poisoning

We now evaluate the effectiveness of the Boiling Frog strategy, which contaminates the training data over multiple training periods. In Fig. 5, we plot the FNRs against the poisoning duration for the PCA detector. We examine four different poisoning schedules with growth rates \( g \) as 1.01, 1.02, 1.05, and 1.15, respectively. The goal of the schedule is to increase the attacked links' average traffic by a factor of \( g \) from week to week. The attack strength parameter \( \theta \) (see Sec. 3) is chosen to achieve this goal. We see that the FNR dramatically increases for all four schedules as the poison duration increases. With a 15% growth rate, the FNR is increased to more than 70% from 3.67% over 3 weeks of poisoning; even with a 5% growth rate, the FNR is increased to 50% over 3 weeks. Thus, Boiling Frog attacks are effective even when the amount of poisoned data increases rather slowly.

Recall that the two methods are retrained every week using the data collected from the previous week. However, the data from the previous week has been filtered by the detector, leading to a gradual degradation in performance.