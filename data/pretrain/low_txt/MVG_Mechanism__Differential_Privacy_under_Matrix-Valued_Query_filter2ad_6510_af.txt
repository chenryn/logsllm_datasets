### Novel Concept of Directional Noise for Reducing Query Answer Impact

We introduce the novel concept of directional noise, which can be employed to mitigate the impact of noise on the utility of query answers. Our experimental evaluation involves three matrix-valued query functions applied to three privacy-sensitive datasets. The results demonstrate that our approach consistently outperforms existing methods in terms of utility improvement across all experiments.

### Acknowledgements

The authors would like to express their gratitude to the reviewers for their valuable feedback, which significantly improved the quality of this paper. This research was supported in part by the National Science Foundation (NSF) under Grants CNS-1553437, CCF-1617286, and CNS-1702808; an Army Research Office YIP Award; and faculty research awards from Google, Cisco, Intel, and IBM.

### References

[1] Herve Abdi. 2007. Singular value decomposition (SVD) and generalized singular value decomposition. *Encyclopedia of Measurement and Statistics*. Thousand Oaks (CA): Sage (2007), 907–912.

[2] Gergely Acs, Claude Castelluccia, and Rui Chen. 2012. Differentially private histogram publishing through lossy compression. In *ICDM*. IEEE.

[3] P. I. Alatalo, H. M. Koivisto, J. P. Hietala, K. S. Puukka, R. Bloigu, and O. J. Niemela. 2008. Effect of moderate alcohol consumption on liver enzymes increases with increasing body mass index. *AJCN* 88, 4 (Oct 2008), 1097–1103.

[4] Davide Bacciu, Paolo Barsocchi, Stefano Chessa, Claudio Gallicchio, and Alessio Micheli. 2014. An experimental characterization of reservoir computing in ambient assisted living applications. *Neural Computing and Applications* 24, 6 (2014), 1451–1464.

[5] Robert M. Bell, Yehuda Koren, and Chris Volinsky. 2008. The bellkor 2008 solution to the netflix prize. *Statistics Research Department at AT&T Research* (2008).

[6] Christopher M. Bishop. 2006. Pattern recognition. *Machine Learning* 128 (2006).

[7] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. 2012. The Johnson-Lindenstrauss transform itself preserves differential privacy. In *FOCS*. IEEE.

[8] Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. 2005. Practical privacy: the SuLQ framework. In *PODS*. ACM.

[9] Avrim Blum, Katrina Ligett, and Aaron Roth. 2013. A learning theory approach to noninteractive database privacy. *JACM* 60, 2 (2013), 12.

[10] Avrim Blum and Aaron Roth. 2013. Fast private data release algorithms for sparse queries. Springer, 395–410.

[11] Thee Chanyaswad, Alex Dytso, H. Vincent Poor, and Prateek Mittal. 2018. A Differential Privacy Mechanism Design Under Matrix-Valued Query. *arXiv* preprint arXiv:1802.10077 (2018).

[12] Thee Chanyaswad, Changchang Liu, and Prateek Mittal. 2017. Coupling Random Orthonormal Projection with Gaussian Generative Model for Non-Interactive Private Data Release. *arXiv*:1709.00054 (2017).

[13] Kamalika Chaudhuri, Anand Sarwate, and Kaushik Sinha. 2012. Near-optimal differentially private principal components. In *NIPS*.

[14] Kamalika Chaudhuri and Staal A. Vinterbo. 2013. A stability-based validation procedure for differentially private machine learning. In *NIPS*.

[15] Graham Cormode, Cecilia Procopiuc, Divesh Srivastava, Entong Shen, and Ting Yu. 2012. Differentially private spatial decompositions. In *ICDE*. IEEE.

[16] A. Philip Dawid. 1981. Some matrix-variate distribution theory: notational considerations and a Bayesian application. *Biometrika* 68, 1 (1981), 265–274.

[17] Wei-Yen Day and Ninghui Li. 2015. Differentially private publishing of high-dimensional data using sensitivity control. In *CCS*. ACM.

[18] Diogo Ayres de Campos, Joao Bernardes, Antonio Garrido, Joaquim Marques de Sa, and Luis Pereira-Leite. 2000. SisPorto 2.0: a program for automated analysis of cardiotocograms. *Journal of Maternal-Fetal Medicine* 9, 5 (2000), 311–318.

[19] John C. Duchi, Michael I. Jordan, and Martin J. Wainwright. 2013. Local privacy and statistical minimax rates. In *FOCS*. IEEE.

[20] Pierre Dutilleul. 1999. The MLE algorithm for the matrix normal distribution. *Journal of statistical computation and simulation* 64, 2 (1999), 105–123.

[21] Cynthia Dwork. 2006. Differential privacy. Springer, 1–12.

[22] Cynthia Dwork. 2008. Differential privacy: A survey of results. In *TAMC*.

[23] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. 2006. Our data, ourselves: Privacy via distributed noise generation. In *EUROCRYPT*. Springer.

[24] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006. Calibrating noise to sensitivity in private data analysis. In *TCC*. Springer.

[25] Cynthia Dwork and Aaron Roth. 2014. The algorithmic foundations of differential privacy. *FnT-TCS* 9, 3-4 (2014), 211–407.

[26] Cynthia Dwork, Guy N. Rothblum, and Salil Vadhan. 2010. Boosting and differential privacy. In *FOCS*. IEEE.

[27] Cynthia Dwork, Kunal Talwar, Abhradeep Thakurta, and Li Zhang. 2014. Analyze gauss: optimal bounds for privacy-preserving principal component analysis. In *STOC*. ACM.

[28] Stephen E. Fienberg, Alessandro Rinaldo, and Xiaolin Yang. 2010. Differential privacy and the risk-utility tradeoff for multi-dimensional contingency tables. In *PSD*. Springer.

[29] Daniel Foreman-Mackey, David W Hogg, Dustin Lang, and Jonathan Goodman. 2013. emcee: the MCMC hammer. *Publications of the Astronomical Society of the Pacific* 125, 925 (2013), 306.

[30] Richard Forsyth and Roy Rada. 1986. Machine learning: applications in expert systems and information retrieval. Halsted Press.

[31] Matthew Fredrikson, Eric Lantz, Somesh Jha, Simon Lin, David Page, and Thomas Ristenpart. 2014. Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing. In *USENIX Security*.

[32] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2001. *The elements of statistical learning*. Vol. 1. Springer series in statistics New York.

[33] Walter R. Gilks, Sylvia Richardson, and David Spiegelhalter. 1995. *Markov chain Monte Carlo in practice*. CRC press.

[34] Chris Godsil and Gordon F. Royle. 2013. *Algebraic graph theory*. Vol. 207. Springer Science & Business Media.

[35] Gene H. Golub and Charles F. Van Loan. 1996. *Matrix computations*. Johns Hopkins University, Press, Baltimore, MD, USA (1996), 374–426.

[36] AK Gupta and T. Varga. 1992. Characterization of matrix variate normal distributions. *Journal of Multivariate Analysis* 41, 1 (1992), 80–88.

[37] Moritz Hardt, Katrina Ligett, and Frank McSherry. 2012. A simple and practical algorithm for differentially private data release. In *NIPS*.

[38] Moritz Hardt and Aaron Roth. 2012. Beating randomized response on incoherent matrices. In *Proceedings of the forty-fourth annual ACM symposium on Theory of computing*. ACM, 1255–1268.

[39] Moritz Hardt and Aaron Roth. 2013. Beyond worst-case analysis in private singular vector computation. In *STOC*. ACM.

[40] Moritz Hardt and Aaron Roth. 2013. Beyond worst-case analysis in private singular vector computation. In *Proceedings of the forty-fifth annual ACM symposium on Theory of computing*. ACM, 331–340.

[41] Moritz Hardt and Guy N. Rothblum. 2010. A multiplicative weights mechanism for privacy-preserving data analysis. In *FOCS*. IEEE.

[42] Moritz Hardt and Kunal Talwar. 2010. On the geometry of differential privacy. In *Proceedings of the forty-second ACM symposium on Theory of computing*. ACM, 705–714.

[43] Michael Hay, Ashwin Machanavajjhala, Gerome Miklau, Yan Chen, and Dan Zhang. 2016. Principled evaluation of differentially private algorithms using DPBench. In *SIGMOD/PODS*. ACM.

[44] Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu. 2010. Boosting the accuracy of differentially private histograms through consistency. *PVLDB* 3, 1-2 (2010), 1021–1032.

[45] Roger A. Horn and Charles R. Johnson. 1991. *Topics in matrix analysis*, 1991. Cambridge University Press 37 (1991), 39.

[46] Roger A. Horn and Charles R. Johnson. 2012. *Matrix analysis*. Cambridge university press.

[47] John F. Hughes, Andries Van Dam, James D. Foley, and Steven K. Feiner. 2014. *Computer graphics: principles and practice*. Pearson Education.

[48] Anis Iranmanesh, M. Arashi, and SMM Tabatabaey. 2010. On conditional applications of matrix variate normal distribution. *Iranian Journal of Mathematical Sciences and Informatics* 5, 2 (2010), 33–43.

[49] X. Jiang, Z. Ji, S. Wang, N. Mohammed, S. Cheng, and L. Ohno-Machado. 2013. Differential-private data publishing through component analysis. *Trans. on Data Privacy* 6, 1 (Apr 2013), 19–34.

[50] Noah Johnson, Joseph P. Near, and Dawn Song. 2017. Practical Differential Privacy for SQL Queries Using Elastic Sensitivity. *arXiv*:1706.09479 (2017).

[51] Ian T. Jolliffe. 1986. Principal Component Analysis and Factor Analysis. Springer, 115–128.

[52] Eric Jones, Travis Oliphant, Pearu Peterson, et al. 2001–. SciPy: Open source scientific tools for Python. http://www.scipy.org/

[53] Michael Kapralov and Kunal Talwar. 2013. On differentially private low rank approximation. In *SODA*. SIAM.

[54] Krishnaram Kenthapadi, Aleksandra Korolova, Ilya Mironov, and Nina Mishra. 2012. Privacy via the Johnson-Lindenstrauss transform. *arXiv*:1204.2606 (2012).

[55] S. Y. Kung. 2014. *Kernel Methods and Machine Learning*. Cambridge University Press.

[56] Beatrice Laurent and Pascal Massart. 2000. Adaptive estimation of a quadratic functional by model selection. *Annals of Statistics* (2000), 1302–1338.

[57] Chao Li, Michael Hay, Gerome Miklau, and Yue Wang. 2014. A data-and workload-aware algorithm for range queries under differential privacy. *PVLDB* 7, 5 (2014), 341–352.

[58] Chao Li, Michael Hay, Vibhor Rastogi, Gerome Miklau, and Andrew McGregor. 2010. Optimizing linear counting queries under differential privacy. In *PODS*. ACM.

[59] Chao Li and Gerome Miklau. 2012. An adaptive mechanism for accurate query answering under differential privacy. *PVLDB* 5, 6 (2012), 514–525.

[60] Yang D. Li, Zhenjie Zhang, Marianne Winslett, and Yin Yang. 2011. Compressive mechanism: Utilizing sparse representation in differential privacy. In *WPES*. ACM.

[61] M. Lichman. 2013. UCI Machine Learning Repository. http://archive.ics.uci.edu/

[62] Fang Liu. 2016. Generalized gaussian mechanism for differential privacy. *arXiv*:1602.06028 (2016).

[63] Fang Liu. 2016. Model-based differential private data synthesis. *arXiv*:1606.08052 (2016).

[64] Min Lyu, Dong Su, and Ninghui Li. 2016. Understanding the sparse vector technique for differential privacy. *arXiv*:1603.01699 (2016).

[65] James McDermott and Richard S. Forsyth. 2016. Diagnosing a disorder in a classification benchmark. *Pattern Recognition Letters* 73 (2016), 41–43.

[66] Frank McSherry and Ilya Mironov. 2009. Differentially private recommender systems: building privacy into the net. In *KDD*. ACM.

[67] Frank McSherry and Kunal Talwar. 2007. Mechanism design via differential privacy. In *FOCS*. IEEE.

[68] Jorma Kaarlo Merikoski, Humberto Sarria, and Pablo Tarazaga. 1994. Bounds for singular values using traces. *Linear Algebra Appl.* 210 (1994), 227–254.

[69] Carl D. Meyer. 2000. *Matrix analysis and applied linear algebra*. Vol. 2. Siam.

[70] Kevin P. Murphy. 2012. *Machine Learning: A Probabilistic Perspective*. The MIT Press.

[71] Arvind Narayanan and Vitaly Shmatikov. 2008. Robust de-anonymization of large sparse datasets. In *S&P*. IEEE.

[72] Netflix. 2009. Netflix Prize. http://www.netflixprize.com/. Accessed on: 08/10/2017.

[73] Truc T. Nguyen. 1997. A note on matrix variate normal distribution. *Journal of Multivariate Analysis* 60, 1 (1997), 148–153.

[74] Aleksandar Nikolov. 2015. An improved private mechanism for small databases. In *International Colloquium on Automata, Languages, and Programming*. Springer, 1010–1021.

[75] Aleksandar Nikolov, Kunal Talwar, and Li Zhang. 2013. The geometry of differential privacy: the sparse and approximate cases. In *STOC*. ACM.

[76] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. 2007. Smooth sensitivity and sampling in private data analysis. In *STOC*. ACM.

[77] Travis E Oliphant. 2006. *A guide to NumPy*. Vol. 1. Trelgol Publishing USA.

[78] Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, and Vincent Dubourg. 2011. Scikit-learn: Machine learning in Python. *JMLR* 12, Oct (2011), 2825–2830.

[79] Davide Proserpio, Sharon Goldberg, and Frank McSherry. 2014. Calibrating data to sensitivity in private data analysis: a platform for differentially-private analysis of weighted datasets. *PVLDB* 7, 8 (2014), 637–648.

[80] Wahbeh Qardaji, Weining Yang, and Ninghui Li. 2013. Differentially private grids for geospatial data. In *ICDE*. IEEE.

[81] Wahbeh Qardaji, Weining Yang, and Ninghui Li. 2013. Understanding hierarchical methods for differentially private histograms. *PVLDB* 6, 14 (2013), 1954–1965.

[82] C. Radhakrishna Rao. 1964. The use and interpretation of principal component analysis in applied research. *Sankhya: The Indian Journal of Statistics, Series A* (1964), 329–358.

[83] C. Costa Santos, João Bernardes, Paul MB Vitányi, and Luis Antunes. 2006. Clustering fetal heart rate tracings by compression. In *CBMS*. IEEE.

[84] Jonathan Sondow and Eric W. Weisstein. 2017. Harmonic Number. http://mathworld.wolfram.com/HarmonicNumber.html.

[85] William Carlisle Thacker. 1989. The role of the Hessian matrix in fitting models to measurements. *JGR: Oceans* 94, C5 (1989), 6177–6196.

[86] Jalaj Upadhyay. 2014. Circulant matrices and differential privacy. *Analysis* 16 (2014), 47.

[87] Jalaj Upadhyay. 2014. Randomness Efficient Fast-Johnson-Lindenstrauss Transform with Applications in Differential Privacy and Compressed Sensing. *arXiv*:1410.2470 (2014).

[88] Vladimir Vapnik. 2013. *The nature of statistical learning theory*. Springer Science & Business Media.

[89] J. von Neumann. 1937. Some matrix inequalities and metrization of metric space. *Tomsk Univ.Rev* 1 (1937), 286–296.

[90] DJ De Waal. 2006. Matrix-Valued Distributions. *Encyclopedia of Statistical Sciences* (2006).

[91] Steven R. White. 1992. Density matrix formulation for quantum renormalization groups. *PRL* 69, 19 (1992), 2863.

[92] Wikipedia. 2017. Matrix (mathematics). https://en.wikipedia.org/wiki/Matrix_(mathematics).

[93] Xiaokui Xiao, Gabriel Bender, Michael Hay, and Johannes Gehrke. 2011. iReduct: Differential privacy with reduced relative errors. In *Proceedings of the 2011 ACM SIGMOD International Conference on Management of data*. ACM, 229–240.

[94] Xiaokui Xiao, Guozhang Wang, and Johannes Gehrke. 2011. Differential privacy via wavelet transforms. *IEEE TKDE* 23, 8 (2011), 1200–1214.

[95] Yonghui Xiao, Li Xiong, Liyue Fan, and Slawomir Goryczka. 2012. DPCube: differentially private histogram release through multidimensional partitioning. *arXiv*:1202.5358 (2012).

[96] Chugui Xu, Ju Ren, Yaoxue Zhang, Zhan Qin, and Kui Ren. 2017. DPPro: Differentially Private High-Dimensional Data Release via Random Projection. *IEEE TIFS* (2017).

[97] Jia Xu, Zhenjie Zhang, Xiaokui Xiao, Yin Yang, Ge Yu, and Marianne Winslett. 2013. Differentially private histogram publication. *The VLDB Journal* 22, 6 (2013), 797–822.

[98] Ganzhao Yuan, Yin Yang, Zhenjie Zhang, and Zhifeng Hao. 2016. Convex optimization for linear query processing under approximate differential privacy. In *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*. ACM, 2005–2014.

[99] Ganzhao Yuan, Zhenjie Zhang, Marianne Winslett, Xiaokui Xiao, Yin Yang, and Zhifeng Hao. 2012. Low-rank mechanism: optimizing batch queries under differential privacy. *PVLDB* 5, 11 (2012), 1352–1363.

[100] Ganzhao Yuan, Zhenjie Zhang, Marianne Winslett, Xiaokui Xiao, Yin Yang, and Zhifeng Hao. 2015. Optimizing batch linear queries under exact and approximate differential privacy. *ACM Transactions on Database Systems (TODS)* 40, 2 (2015), 11.

[101] Xiaojian Zhang, Rui Chen, Jianliang Xu, Xiaofeng Meng, and Yingtao Xie. 2014. Towards accurate histogram publication under differential privacy. In *SDM*. SIAM.

[102] Shuheng Zhou, Katrina Ligett, and Larry Wasserman. 2009. Differential privacy with compression. In *ISIT*. IEEE.

### Full Proof of (ε, δ)-Differential Privacy

We present the full proof of the sufficient condition for the MVG (Matrix Variate Gaussian) mechanism to guarantee (ε, δ)-differential privacy as stated in Theorem 3.

**Proof:**

The MVG mechanism guarantees differential privacy if for every pair of neighboring datasets {X1, X2} and all possible measurable sets \( S \subseteq \mathbb{R}^{m \times n} \),

\[
\Pr[f(X_1) + Z \in S] \leq \exp(\epsilon) \Pr[f(X_2) + Z \in S].
\]

The proof follows by observing that (Lemma 4):

\[
Z = W \Sigma \Lambda^{1/2} \Psi N \Lambda^{1/2} \Psi^T W^T,
\]

where \( N \sim \mathcal{N}(0, I) \). Define the following events:

\[
R_1 = \{N : \|N\|_F \leq \zeta(\delta)^2\}, \quad R_2 = \{N : \|N\|_F > \zeta(\delta)^2\},
\]

where \( \zeta(\delta) \) is defined in Theorem 2. Next, observe that:

\[
\Pr[f(X_1) + Z \in S] = \Pr[({f(X_1) + Z \in S} \cap R_1) \cup ({f(X_1) + Z \in S} \cap R_2)].
\]

By the union bound, we have:

\[
\Pr[f(X_1) + Z \in S] \leq \Pr[{f(X_1) + Z \in S} \cap R_1] + \Pr[{f(X_1) + Z \in S} \cap R_2].
\]

By Theorem 2 and the definition of the set \( R_2 \), we have:

\[
\Pr[{f(X_1) + Z \in S} \cap R_2] \leq \Pr[R_2] = 1 - \Pr[R_1] \leq \delta.
\]

In the rest of the proof, we find sufficient conditions for the following inequality to hold:

\[
\Pr[f(X_1) + Z \in (S \cap R_1)] \leq \exp(\epsilon) \Pr[f(X_2) + Z \in S].
\]

Using the definition of \( \text{MVG}_{m,n}(0, \Sigma, \Psi) \) (Definition 2), this is satisfied if we have:

\[
\int_{S \cap R_1} \exp\left(-\frac{1}{2} \text{tr}[\Psi^{-1}(Y - f(X_1))^T \Sigma^{-1}(Y - f(X_1))]\right) dY \leq
\]

\[
\exp(\epsilon) \int_S \exp\left(-\frac{1}{2} \text{tr}[\Psi^{-1}(Y - f(X_2))^T \Sigma^{-1}(Y - f(X_2))]\right) dY.
\]

By inserting \( \exp\left(-\frac{1}{2} \text{tr}[\Psi^{-1}(Y - f(X_2))^T \Sigma^{-1}(Y - f(X_2))]\right) \) inside the integral on the left side, it is sufficient to show that:

\[
\exp\left(-\frac{1}{2} \text{tr}[\Psi^{-1}(Y - f(X_1))^T \Sigma^{-1}(Y - f(X_1))]\right) \leq
\]

\[
\exp(\epsilon) \exp\left(-\frac{1}{2} \text{tr}[\Psi^{-1}(Y - f(X_2))^T \Sigma^{-1}(Y - f(X_2))]\right),
\]

for all \( Y \in S \cap R_1 \). With some algebraic manipulations, the left-hand side of this condition can be expressed as:

\[
\exp\left(-\frac{1}{2} \text{tr}[\Psi^{-1} Y^T \Sigma^{-1} (f(X_2) - f(X_1))]\right).
\]

This completes the proof of the differential privacy guarantee.