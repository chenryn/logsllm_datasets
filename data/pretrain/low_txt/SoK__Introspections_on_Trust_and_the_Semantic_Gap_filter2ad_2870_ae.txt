### Most Papers on Introspection Focus on the First Problem

Most papers on introspection focus on the first problem, which has arguably been solved [40, 44, 80]. However, interesting attacks exploit the second issue, which remains an open problem, as does reliable introspection under more robust threat models. Unfortunately, the literature often fails to clearly distinguish between these problem variations, and only a close reading will reveal which one a given paper addresses. This confusion is further compounded when attempting to compare these papers in the context of attacks and defenses.

We believe that the pragmatic approach of starting with a weak attacker and iteratively strengthening the threat model is sound. The primary issue lies in the ambiguous nomenclature used in the field. We, therefore, propose a clearer nomenclature for the two sub-problems: the weak and strong semantic gap problems. The weak semantic gap is the largely resolved engineering challenge of generating VMI tools, while the strong semantic gap refers to the challenge of defending against an adversarial, untrusted guest OS. A solution to the strong semantic gap problem would not assume the guest OS is benign during a training phase or accept inferences from guest source code without runtime validation. To our knowledge, the strong semantic gap problem remains unsolved, and future work in this area depends on a clearer delineation of the level of trust placed in the guest OS. Solving the strong semantic gap problem would also prevent or detect DKSM attacks.

- **Weak Semantic Gap**: A solved engineering problem.
- **Strong Semantic Gap**: An open security problem.

### Toward an Untrusted OS

Any solution to the strong semantic gap problem may need to remove assumptions that the guest OS can be trusted to help train an introspection tool. As illustrated in Section III, most existing introspection tools rely on the assumption that the guest OS begins in a benign state and its source code or initial state can be trusted. Over time, several designs have reduced their reliance on the guest OS. It is unclear, however, whether continued iterative refinement will eliminate trust in the guest OS entirely.

Table IV illustrates the space of reasonable trust models in virtualization-based security. While much effort in VMI has focused on the weak semantic gap (first row), the community should now concentrate on new directions likely to bridge the strong semantic gap (second row) and adopt useful techniques from research into the other rows.

This section identifies promising approaches to the strong semantic gap, based on insights from the literature.

#### Paraverification

Many VMI systems aim to work with an unmodified OS or limit modifications to the module loader and hooks. This often leads to trusting the guest OS to simplify the problem. Specifically, most VMI tools assume the guest OS is not actively malicious and adheres to the behavior exhibited during the learning phase.

We observe that, rather than relaxing the threat model for VMI, it may be more useful to relax the requirement of an unmodified guest OS. By analogy, although initial hypervisors made significant efforts to virtualize unmodified legacy OSes on an ISA unsuitable for virtualization [26], most modern OSes now implement paravirtualization support [25]. Paravirtualization makes small modifications to the guest OS to eliminate the most onerous features to emulate. For instance, Xen allowed the guest OS to observe inaccessible physical pages, substantially reducing the overheads of virtualizing physical memory.

Thus, light modifications to a guest OS to aid in introspection could be a promising direction. The recent InkTag [52] system introduced the idea of paraverification, where the guest OS provides the hypervisor with evidence that it is servicing an application's request correctly. This evidence is easily checked by the hypervisor without trusting the guest OS. For example, a trusted application may request a memory mapping of a file, and, in addition to issuing an `mmap` system call, also reports the request to the hypervisor. When the OS modifies the application's page tables, it notifies the hypervisor, allowing the hypervisor to verify the changes.

While the goals of InkTag differ from VMI—ensuring a trusted application can safely use functionality from a malicious OS—forcing an untrusted OS to aid in its own introspection could be fruitful if the techniques are simple enough to adopt.

#### Hardware Support for Security

As observed in §IV-C, memory protection or other synchronous notification mechanisms appear necessary to move from detection to prevention. Unfortunately, the coarseness of mechanisms in commodity hardware introduces substantial overheads. Recent work on memory monitoring at cache line granularity is a valuable approach meriting further research.

Intel's Software Guard Extensions (SGX) [21, 50, 70] is an interesting direction. SGX allows an OS or hypervisor to manage virtual-to-physical mappings for an application, but the lower-level software cannot access memory contents. SGX provides memory isolation of a trusted application from an untrustworthy software stack. Similar memory isolation has been provided by several software-only systems, but at a substantial performance cost due to frequent traps to a trusted hypervisor. Fine-grained memory protection and monitoring hardware can reduce overheads and trust.

#### Reconstruction from Untrusted Sources

Current tools that automatically learn data structure signatures assume the OS will behave similarly during training and classification (§V-B). Among the assumptions made in current VMI tools, this is one that potentially has the best chance of being incrementally removed. One approach might be to train the VMI classifiers on the live OS and continue incremental training as the guest OS runs. Another approach would be to detect inconsistencies between the training and classification stages of VMI. For example, Lycosid detected inconsistencies between the `cr3` register and the purported process descriptor's `cr3` value [55].

VMI should detect inconsistent behavior over the life of an OS, not just between training and classification.

### Under-Explored Issues

Based on our survey of the literature on VMI, we identify a few issues that deserve more consideration in future work.

#### Scalability

Many VMI designs are expensive, especially those that run a sibling VM on a dedicated core for analysis. For example, one state-of-the-art system reports overheads ranging from 9.3 to 500× [44]. In a cloud environment, high VMI overheads are unacceptable, as they can double the bill for customers and halve revenue for providers. Future VMI research must focus on managing overheads and scalability with increasing numbers of VMs.

#### Privacy

VMI has the potential to create new side channels in cloud systems. For example, after reading application binaries, Patagonix [65] queries the NSRL database with the binary hash to determine the type of binary running on the system. This effectively leaks information about the programs run within a VM to an outside observer, undermining user privacy.

More generally, VMI can cause one guest to observe different cache timings based on the behavior of another guest. Consider a VMI tool that periodically scans the memory of multiple VMs on a cloud system. The memory scan or snapshot disrupts cache timings of the guest under observation. Based on its own cache timings, the VM can observe the frequency of its periodic scans. Because the length of a scan of another VM can vary based on what the VM is doing, changes in the time between scans of one VM can indicate what is happening in another VM on the same system.

Although it is unclear whether this side channel is exploitable in practice, VMI projects should be aware of potential side channels in a multi-VM system. Richter et al. [78] present initial work on privacy-preserving introspection, but more work is needed. An ideal system would not force the user to choose between integrity and privacy risks.

### Conclusion

Virtual machine introspection is a relatively mature research topic that has made substantial advances over the last twelve years since the semantic gap problem was posed. However, efforts in this space should be refocused on removing trust from the guest OS in service of the larger goal of reducing the system’s TCB. Future VMI solutions should balance innovative techniques and security properties with scalability and privacy concerns. We expect that the lessons from previous work will guide future efforts to adapt existing techniques or develop new techniques to bridge the strong semantic gap.

### Acknowledgements

We thank our shepherd, Virgil Gligor, and the anonymous reviewers for their insightful comments on earlier versions of this paper. This research was supported in part by NSF grants CNS-1149229, CNS-1161541, CNS-1228839, CNS-1318572, CNS-1223239, CCF-0937833, by the US ARMY award W911NF-13-1-0142, the Office of the Vice President for Research at Stony Brook University, and by gifts from Northrop Grumman Corporation, Parc/Xerox, Microsoft Research, and CA.