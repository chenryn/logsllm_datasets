### 2. Illustration of P2P Migration

To illustrate the potential migration of P2P traffic to other distribution mechanisms, we present inter-domain traffic data for a large direct download site in Figure 8. Typically, our ASN-based analysis cannot identify traffic contributed by individual co-located hosting customers. However, Figure 8 provides an exception.

Carpathia Hosting, which hosts several large customer direct download and video streaming sites, including MegaVideo and MegaUpload (ranked 72 on Alexa) [45, 44], is the focus of this analysis. We graph the weighted percentage of all inter-domain traffic originating or terminating in Carpathia’s ASNs (AS29748, AS46742, and AS35974) in Figure 8.

Private discussions with providers indicate that the significant and abrupt increase in Carpathia's inter-domain traffic percentages after January 2009 is due to the migration and consolidation of MegaUpload and associated sites onto Carpathia servers. As of July 2009, Carpathia represents a weighted average of more than 0.8% of all inter-domain traffic.

### 5. Internet Size Estimates

In this final analysis section, we use independent measurements of provider inter-domain traffic to validate our results and estimate the current volume of all inter-domain traffic, as well as the annualized rate of inter-domain traffic growth. We compare our findings with recent research and commercial estimates of global Internet traffic.

#### 5.1 Traffic Volume

To provide independent verification of our study measurements, we solicited inter-domain traffic statistics from twelve large, topologically, and geographically diverse providers and content sites. These datasets were disjoint from the 110 anonymous providers in our study. Each provider supplied peak inter-domain traffic volumes for July 2009, using a combination of in-house Flow tools or SNMP interface polling. We use these twelve known inter-domain traffic values as "ground-truth."

Figure 9 shows a plot of each provided traffic volume against the provider’s weighted average percentage of all inter-domain traffic (based on ASN) from our data. A linear fit of these measurements is also shown. The resulting line has a slope of 2.51, meaning that a 2.51% share of all inter-domain traffic represents approximately 1 Tbps of inter-domain traffic. This extrapolates to an overall size of the Internet at 1 / 2.51 = 39.8 Tbps as of July 2009.

While exhaustive validation is difficult due to the commercial secrecy surrounding provider traffic statistics, the plot in Figure 9 lends confidence to our findings. The linear fit has an R² value of 0.91, indicating that our data and statistical analysis are consistent with the independent "ground-truth" measurements supplied by the twelve providers.

We also calculate the absolute number of bytes for May 2008 for comparison with Cisco’s last published data [23]. This monthly calculated value matches Cisco’s Internet traffic estimate of 9 exabytes per month in 2008. Table 5 shows the result of our calculations combined with data from a private survey of providers and published reports from Cisco [23] and MINTS [14]. We also corroborate the data with a private survey of ISPs and content providers [46].

#### 5.2 Traffic Growth

To estimate the rate of inter-domain traffic growth, we compute an annual growth rate (AGR), which represents the estimated increase in inter-domain traffic volume over a year. This AGR is based on daily traffic samples collected over a one-year period at each router associated with a participant deployment. To calculate the AGR for a particular router, we employ a methodology similar to MINTS [14]. Specifically, we determine an exponential fit of the form y = A * 10^(Bx), where x is the day ([1, 365]) and y is the traffic sample in bps for day x for the router. An example curve fit over the daily sample points between May 2008 and May 2009 for an anonymous provider can be seen in Figure 10a. From the results of our linear least squares fit, we calculate the AGR as AGR = 10^(365*B). For example, an AGR of 0.5 represents a 50% decrease in traffic, 1.0 represents no change, 2.0 represents a 100% increase, 3.0 represents a 200% increase, and so on.

However, changes in the commercial probe infrastructure can complicate our growth estimation. For example, a provider may add, remove, or reconfigure routers associated with a particular probe deployment over time. Frequent changes in measurement infrastructure combined with misconfiguration and other anomalies can lead to noise within the dataset. Such noise may be present at three levels of granularity: (1) datapoint-level: datapoints for a single router may lack valid or non-zero data points; (2) router-level: fitting a growth curve to an inadequate set of traffic samples for a router may result in an inaccurate fit; (3) deployment-level: deployments may have misconfigured or anomalous routers or a small number of total routers, resulting in unstable routers having a large effect on the overall deployment.

To address these sources of noise, we apply a pass at each level of granularity to smooth out noise and exclude anomalous and misconfigured routers. For sample-level noise, we exclude sample sets that do not have at least 2/3 valid data points throughout the year. For router-level noise, we exclude AGR calculations that exhibit a high standard error when fitting a curve to noisy sample points. Lastly, we smooth out per-deployment noise by only considering routers with AGRs between the 1st and 3rd quartiles of the routers within that deployment.

We calculate the overall AGR for a deployment as the mean of the AGRs of the eligible routers within that deployment. The computed annual growth rates between May 2008 and 2009 for a number of provider deployments (Tier-1, Tier-2, and cable/DSL providers) in our data are shown in Figure 10b. In addition to per-deployment AGRs, we calculate AGRs by market segment by taking the mean of the per-deployment AGRs of the providers within that market segment. Table 6 breaks down the growth of each market segment and includes the number of deployments and eligible routers used to compute each AGR.

In Table 5, we compare our results of inter-domain traffic growth to similar measurement studies from Cisco and MINTS [23, 14], as well as the average growth rates reported in a survey of 25 ISPs. We note that both Cisco and MINTS report a slightly higher rate of 50%, but the difference may be due to the inclusion of internal/backbone traffic, while our study focused on inter-domain traffic.

### 6. Conclusion

In this paper, we provide one of the first large-scale longitudinal studies of Internet inter-domain traffic. Over a two-year period, we analyzed more than 200 Exabytes of commercial inter-domain traffic through the direct instrumentation of more than 3,000 peering routers across 110 geographically and topologically diverse Internet providers.

Our main contribution is the identification of a significant ongoing evolution of provider interconnection strategies and resultant inter-domain traffic demands, including the rapid transition to a more densely interconnected and less hierarchical inter-domain Internet topology. Specifically, we find that the majority of inter-domain traffic now flows directly between large content providers, data centers/CDNs, and consumer networks. As of July 2009, 150 ASNs (out of 30,000 ASNs in default-free BGP tables) originate more than 50% of all Internet inter-domain traffic by weighted average percentage. We also identify changes in Internet inter-domain application traffic patterns, including a significant rise in video traffic and a corresponding decline in P2P.

While analysts and the press have provided anecdotal discussion of these macro-level Internet trends (e.g., [3]), we believe this paper represents the first quantitative characterization. We observe that the emerging new provider inter-connection strategies have significant ongoing implications for backbone engineering, design of Internet-scale applications, and research. Given the significant obstacles intrinsic to commercial inter-domain traffic measurement, we hope to make our data available to other researchers on an ongoing basis, pending anonymization and privacy discussions with provider study participants.

Overall, we argue that the Internet industry is in the midst of an inflection point, out of which new network engineering designs, business models, and economies are emerging. Economic changes, including the decline of wholesale IP transit prices [2] and the dramatic growth in advertisement-supported services, have reversed decade-old business dynamics between transit providers, consumer networks, and content providers. For example, providers that used to charge content networks for transit now offer settlement-free interconnection or, in some cases, may even pay the content networks for access [5, 6].

As measured in this paper, provider inter-domain traffic demands provide a key measure of emergent network engineering and commercial strategies. As Google, Microsoft, Facebook, Baidu, and other large content owners and consumer networks compete for virtual real estate and Internet market share, we expect the trend towards Internet inter-domain traffic consolidation to continue and even accelerate.

### 7. Acknowledgments

The authors wish to thank Haakon Ringberg for contributions to an earlier incarnation of this research. We also thank Jennifer Rexford, Randy Bush, Vijay Gill, Bill Norton, Nasser El-Aawar, Shane Amante, Andrew Odlyzko, Kim Claffy, Darren Anstee, Emile Aben, Bradley Huffaker, and Mike Hollyman for their constructive comments. The authors also acknowledge the anonymous SIGCOMM 2010 referees for their feedback. Finally, we thank multiple unnamed reviewers at Internet providers and content networks for their generous insights. We also thank the 110 Internet provider participants for their extraordinary willingness to contribute data and make this research possible.

### 8. References

[1] C. Huitema, Routing in the Internet (2nd ed.). Upper Saddle River, NJ, USA: Prentice Hall PTR, 2000.
[2] O. Malik, “Wholesale Internet Bandwidth Prices Keep Falling.” GigaOM Blog, http://gigaom.com, October 2008.
[3] NetCompetition.org, “A First-Ever Research Study: Estimating Google’s U.S. Consumer Internet Usage and Cost.” Unpublished white paper, 2008.
[4] L. Dignan, “Comcast Feeling the Heat from Competition.” ZDNet, http://blogs.zdnet.com, October 2007.
[5] G. Goth, “New Internet Economics Might Not Make it to the Edge,” in IEEE Internet Computing, vol. 14,1, ACM, January 2010.
[6] Private communication with network operators., July 2009.
[7] A. Dhamdhere and C. Dovrolis, “Ten Years in the Evolution of the Internet Ecosystem,” in Proceedings of the 8th ACM SIGCOMM conference on Internet measurement, pp. 183–196, ACM New York, NY, USA, 2008.
[8] J. Wu, Z. M. Mao, J. Rexford, and J. Wang, “Finding a needle in a haystack: Pinpointing significant BGP routing changes in an IP network,” in Proc. Symposium on Networked Systems Design and Implementation, 2005.
[9] R. Oliveira, D. Pei, W. Willinger, B. Zhang, and L. Zhang, “The (in)Completeness of the Observed Internet AS-level Structure,” IEEE/ACM Transactions on Networking (ToN), 2010.
[10] M. Rajab, F. Monrose, A. Terzis, and N. Provos, “Peeking Through the Cloud: DNS-Based Estimation and Its Applications,” in Applied Cryptography and Network Security: 6th International Conference, ACNS 2008, New York, NY, USA, June 3-6, 2008, Proceedings, p. 21, 2008.
[11] “Global Internet Geography.” Telegeography Research, http://www.telegeography.com, September 2009.
[12] Akamai, “State of the Internet,” 2009.
[13] C. Fraleigh, S. Moon, B. Lyles, C. Cotton, M. Khan, D. Moll, R. Rockell, T. Seely, and C. Diot, “Packet-level Traffic Measurements from the Sprint IP Backbone,” in IEEE Network, November 2003.
[14] “Minnesota Internet Traffic Studies (MINTS).” MINTS, http://www.dtc.umn.edu/mints, July 2009.
[15] D. Antoniades, M. Polychronakis, N. Nikiforakis, E. Markatos, and Y. Mitsos, “Monitoring Three National Research Networks for Eight Weeks: Observations and Implications,” in IEEE Network Operations and Management Symposium Workshops, 2008. NOMS Workshops 2008, pp. 153–156, 2008.
[29] Wikipedia, “Tier 1 Network.” Wikipedia, http://en.wikipedia.org.
[30] R. Miller, “Google-YouTube: Bad News for Limelight?” Datacenter Knowledge Blog, http://www.datacenterknowledge.com, October 2006.
[31] CAIDA, “Internet Topology.” http://www.caida.org/research/topology.
[32] Q. Chen, H. Chang, S. J. Shenker, R. Govindan, and W. Willinger, “The Origin of Power Laws in Internet Topologies Revisited,” in Proc. of IEEE Infocom, 2007.
[33] M. Roughan, S. Sen, O. Spatscheck, and N. Duffield, “Class-of-Service Mapping for QoS: a Statistical Signature-Based Approach to IP Traffic Classification,” ACM Sigcomm Internet Measurement Workshop, 2004.
[16] G. Maier, A. Feldmann, V. Paxson, and M. Allman, “On Dominant Characteristics of Residential Broadband Internet Traffic,” in Proc. ACM IMC, 2009.
[34] Arbor Networks, “Arbor E100.” Product data sheet, www.arbornetworks.com.
[35] T. Magrino, “Xbox Live Going Dark June 16.” GameSpot, http://www.gamespot.com, June 2009.
[17] K. Cho, “Trends in Japanese Residential Traffic,” ISOC Panel on Internet Bandwidth: Dealing with Reality, 2009.
[18] G. Maier, A. Feldmann, V. Paxson, and M. Allman, “On Dominant Characteristics of Residential Broadband Internet Traffic,” in IMC ’09: Proceedings of the 9th ACM SIGCOMM conference on Internet Measurement Conference, (New York, NY, USA), ACM, 2009.
[19] B. Norton, “Internet Service Providers and Peering.” Equinix White Paper, 2001.
[20] B. Norton, “Video Internet: The Next Wave of Massive Disruption to the US Peering Ecosystem.” Equinix White Paper, September 2006.
[21] P. Faratin, D. Clark, P. Gilmore, S. Bauer, A. Berger, and W. Lehr, “Complexity of Internet Interconnections: Technology, Incentives, and Implications for Policy,” in The 35th Research Conference on Communication, Information and Internet Policy (TPRC), ACM, 2007.
[22] P. Gill, M. F. Arlitt, Z. Li, and A. Mahanti, “The Flattening Internet Topology: Natural Evolution, Unsightly Barnacles, or Contrived Collapse?,” in Proceedings of PAM, 2008.
[23] Cisco Systems, “Cisco Visual Networking Index – Forecast and Methodology.” A Cisco White Paper, 2008.
[24] “University of Oregon RouteViews Project.” http://www.routeviews.org.
[25] B. Choi and S. Bhattacharyya, “On the Accuracy and Overhead of Cisco Sampled NetFlow,” in Sigmetrics Workshop on Large Scale Network Inference (LSNI): Methods, Validation, and Applications, June 2005.
[26] Arbor Networks, “PeakFlow.” Product data sheet and whitepapers, www.arbornetworks.com/peakflowsp.
[27] P. Marshall, “Link Data: Global Network.” Yankee Group Report, http://www.yankeegroup.com, October 2009.
[28] J. Markoff, “Internet Traffic Begins to Bypass the U.S.,” New York Times, August 2008.
[36] C. Labovitz, “The Great Obama Traffic Flood.” Arbor Networks Blog, http://asert.arbornetworks.com/2009/01/the-great-obama-traffic-flood/, January 2009.
[37] C. Labovitz, “The Tiger Effect.” Arbor Networks Blog, http://asert.arbornetworks.com/2008/06/the-tiger-effect/, June 2008.
[38] J. Pigg, “P2P: Damn This Traffic Jam.” Yankee Group Report, http://www.yankeegroup.com, July 2008.
[39] J. Erman, A. Gerber, M. Hajiaghayi, D. Pei, and O. Spatscheck, “Network-aware Forward Caching,” in Proceedings of the 18th International Conference on World Wide Web, ACM New York, NY, USA, 2009.
[40] N. Anderson, “P2P Traffic Drops as Streaming Video Grows in Popularity.” Ars Technica, http://arstechnica.com, September 2008.
[41] J. Cheng, “Report: UK File Sharing Drops, Even Among Teens.” Ars Technica, http://arstechnica.com, June 2009.
[42] H. Xie, Y. Yang, A. Krishnamurthy, Y. Liu, and A. Silberschatz, “P4P: Provider Portal for Applications,” ACM SIGCOMM Computer Communication Review, vol. 38, no. 4, 2008.
[43] Wikipedia, “Direct Download.” http://en.wikipedia.org.
[44] C. Adamsick, “’Warez’ the Copyright Violation? Digital Copyright Infringement: Legal Loopholes and Decentralization,” TechTrends, vol. 52, no. 6, pp. 10–12, 2008.
[45] Alexa, “The Top 500 Sites on the Web.” http://www.alexa.com.
[46] D. McPherson and C. Labovitz, “2009 Survey of ISP Traffic Trends.” Private Survey of 25 Large ISPs and Content Providers, July 2009.