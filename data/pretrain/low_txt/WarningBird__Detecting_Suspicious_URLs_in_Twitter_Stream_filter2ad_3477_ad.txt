### 1.618, 0.484, 28.307

When the window size is set to 100,000, which includes approximately 10% of all tweets with URLs per hour, the processing time is only 6.9 minutes (see Figure 9). Next, we estimate the time required to classify a single URL. Our system currently uses 100 crawling threads to concurrently visit URL redirect chains; on average, each thread requires 2.42 seconds to visit a single URL redirect chain. For a window size of 100,000, the system needs 28.307 milliseconds to process a single URL (see Table 7). Consequently, our system can process about 127,000 URLs per hour. This means that our system can handle 10% of the tweet samples, as provided by the Gardenhose access role, in real time.

By increasing the number of crawling threads, we can process more than 10% of the tweet samples. For instance, if we use 1,000 crawling threads, we can process about 576,000 URLs per hour. However, even with this increase, the current implementation cannot process all tweets, as it would require processing a single URL in less than 3.6 milliseconds to handle 1,000,000 URLs per hour.

**Figure 9. Running time for each component to process a tweet window**

### 4.6 Real-time Detection and Sliding Window

The real-time version of WARNINGBIRD employs a sliding window technique to achieve good latency and detection coverage. A small window provides immediate results but may miss suspicious URLs that repeat after long intervals. Conversely, a large window offers better detection coverage but suffers from higher latency. The sliding window technique effectively combines the advantages of both small and large windows. Let \( w \) denote the window size and \( s \) denote the sliding size (\( s \leq w \)). Whenever a sliding window system receives \( s \) new items, it processes the previous \( w - s \) items and the \( s \) new items simultaneously. Therefore, the latency of this method depends on \( s \), and its detection coverage depends on \( w \). Currently, we have set \( w \) at 10,000 and \( s \) at 2,000. Every 12 minutes, the real-time version of WARNINGBIRD returns suspicious URLs that have appeared in the previous hour. Since our system can process 10,000 collected tweets in less than one minute (see Figure 9), we can detect suspicious URLs with only a one-minute lag. Between August 6 and August 18, 2011, the real-time WARNINGBIRD reported 4,336 unique suspicious URLs without system errors.

### 4.7 Comparison with Twitter

We compare the efficiency of WARNINGBIRD with Twitter's detection system. For the comparison, we sampled 14,905 accounts detected by the real-time WARNINGBIRD between September 1 and October 22, 2011. To evaluate their efficiencies, we measured the time difference between WARNINGBIRD's detection and Twitter's suspension of the accounts. We monitored the WARNINGBIRD to obtain newly detected suspicious accounts and then checked the status of each account every 15 seconds until it was suspended, within a day. Among the sampled accounts, 5,380 were suspended within a day: 37.3% were suspended within a minute, another 42.5% within 200 minutes, and the remaining 20.7% within a day (see Figure 10). The average time difference is 13.5 minutes, indicating that our detection system is more efficient than Twitter's. On October 28, 2011, we also checked the statuses of the sampled accounts to verify the accuracy of our system. Out of the 14,905 accounts, 9,250 were suspended. We randomly selected 500 accounts from the remaining 5,655 active accounts to manually check their suspiciousness. Among these 500 accounts, 320 were found to be suspicious.

**Figure 10. Time difference between WARNINGBIRD’s detection of suspicious accounts and Twitter’s suspension within a day**

### 5 Discussion

In this section, we discuss some limitations of our system and potential evasion techniques.

#### Dynamic Redirection
Currently, WARNINGBIRD uses a static crawler written in Python, which can only handle HTTP redirections. It is ineffective against pages with embedded dynamic redirections such as JavaScript or Flash. As a result, WARNINGBIRD designates pages with embedded dynamic redirection as entry point URLs, leading to inaccuracies in feature values like redirect chain lengths, positions of entry point URLs, and the number of different landing URLs. In the future, we plan to use customized Web browsers to fully retrieve redirect chains.

#### Multiple Redirections
Web pages can embed several external pages and different content, causing multiple redirections. Our system currently only considers HTTP redirection and does not account for page-level redirection. To address this, we need customized browsers to catch and handle multiple redirections.

#### Coverage and Scalability
Our system currently monitors only 1% of the samples from the Twitter public timeline due to the Spritzer access role. As shown in Section 4, if our accounts were to take on the Gardenhose access role, which allows processing 10% of the samples, our system could handle this number in real time. However, the current implementation cannot handle 100% of the Twitter public timeline. To address this, we must extend WARNINGBIRD to a distributed detection system, such as Monarch [24], to handle the entire Twitter public timeline.

#### Feature Evasion Methods
Attackers can fabricate features to evade our detection system. For example, they might use short redirect chains, change the position of their entry point URLs, and reuse initial and landing URLs. These modifications, paradoxically, would allow previous detection systems to detect their malicious URLs. Attackers may also reduce the frequency of their tweets to bypass our detection system, though this would also reduce the number of visitors to their malicious pages. Features derived from tweet information are relatively weak at protecting against forgery, as many researchers have pointed out [21, 24, 31]. Attackers could use a large number of source applications and Twitter accounts, use similar tweet texts, and carefully adjust the numbers of followers and friends of their accounts.

**Figure 11. Time difference between WARNINGBIRD’s detection of suspicious accounts and Twitter’s suspension within a day**

### 6 Related Work

#### 6.1 Twitter Spam Detection
Many Twitter spam detection schemes have been introduced. Most focus on collecting a large number of spam and non-spam accounts and extracting features to distinguish between them. Some schemes investigate collected data manually [2, 28], others use honey-profiles to lure spammers [16, 23], some monitor the Twitter public timeline for blacklisted URLs [11, 31], and some monitor Twitter’s official spam reporting account, @spam [21].

Preliminary work [2, 11, 16, 23, 28] relies on account features such as the numbers of followers and friends, account creation dates, URL ratios, and tweet text similarities, which can be efficiently collected but easily fabricated. Recent work [21, 31] relies on more robust features extracted from the Twitter graph. Yang et al. [31] focused on relations between spam nodes and their neighboring nodes, while Song et al. [21] considered the relations between spam senders and receivers. Extracting these robust features, however, is time and resource-consuming.

#### 6.2 Suspicious URL Detection
Many suspicious URL detection schemes have been proposed, classified into static or dynamic detection systems. Lightweight static detection systems focus on lexical features of URLs, such as length and number of dots [19], and consider underlying DNS and WHOIS information [17, 18]. More sophisticated static detection systems, like Prophiler [3], extract features from HTML content and JavaScript codes. However, static systems cannot detect URLs with dynamic content. Therefore, dynamic detection systems [4, 7, 24, 29, 30] use virtual machines and instrumented Web browsers for in-depth analysis. Nevertheless, these systems may still fail to detect sites with conditional behaviors.

#### 6.3 ARROW: Generating Signatures to Detect Drive-by Downloads
Zhang et al. developed ARROW [32], which generates signatures for drive-by download attacks by considering correlated URL redirect chains. It uses honeyclients to detect attacks and collect logs of HTTP redirection traces. From these logs, it identifies central servers and generates regular expression signatures using the central servers’ URLs. ARROW also groups domain names with the same IP addresses to avoid IP fast flux and domain flux [12, 22].

Although ARROW and WARNINGBIRD have similar methods for detecting central servers and entry point URLs, there are three key differences:
1. ARROW's HTTP traces are redirect chains between malicious landing pages and malware binaries, limiting its application to other web attacks.
2. ARROW focuses on generating signatures of central servers, while WARNINGBIRD measures the suspiciousness of entry point URLs.
3. ARROW relies on logs of HTTP traces, making it unsuitable for real-time detection, whereas WARNINGBIRD is a real-time system.

### 7 Conclusion

Previous suspicious URL detection systems are weak against conditional redirection servers that distinguish investigators from normal browsers. In this paper, we propose WARNINGBIRD, a new suspicious URL detection system for Twitter. Unlike previous systems, WARNINGBIRD is robust against conditional redirection because it does not rely on the features of malicious landing pages. Instead, it focuses on the correlations of multiple redirect chains that share redirection servers. We introduced new features based on these correlations, implemented a real-time classification system, and evaluated its accuracy and performance. The evaluation results showed that our system is highly accurate and can be deployed as a real-time system to classify large samples of tweets from the Twitter public timeline. In the future, we will extend our system to address dynamic and multiple redirections and implement a distributed version of WARNINGBIRD to process all tweets from the Twitter public timeline.

### References

[1] D. Antoniades, I. Polakis, G. Kontaxis, E. Athanasopoulos, S. Ioannidis, E. P. Markatos, and T. Karagiannis. we.b: The web of short URLs. In Int. World Wide Web Conf. (WWW), 2011.

[2] F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida. Detecting spammers on Twitter. In Collaboration, Electronic messaging, Anti-Abuse and Spam Conf. (CEAS), 2010.

[3] D. Canali, M. Cova, G. Vigna, and C. Kruegel. Prophiler: A fast filter for the large-scale detection of malicious web pages. In Int. World Wide Web Conf. (WWW), 2011.

[4] Capture-HPC. https://projects.honeynet.org/capture-hpc.

[5] Y.-W. Chen and C.-J. Lin. Combining SVMs with various feature selection strategies. In Feature Extraction, volume 207 of Studies in Fuzziness and Soft Computing, pages 315–324. 2006.

[6] Z. Chu, S. Gianvecchio, H. Wang, and S. Jajodia. Who is tweeting on Twitter: Human, bot, or cyborg? In Annual Computer Security Applications Conf. (ACSAC), 2010.

[7] M. Cova, C. Kruegel, and G. Vigna. Detection and analysis of drive-by-download attacks and malicious JavaScript code. In Int. World Wide Web Conf. (WWW), 2010.

[8] P. Eckersley. How unique is your web browser? In Privacy Enhancing Technologies (PET), 2010.

[9] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874, 2008.

[10] Google. Google safe browsing API. http://code.google.com/apis/safebrowsing.

[11] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @spam: The underground on 140 characters or less. In ACM Conf. Computer and Communications Security (CCS), 2010.

[12] T. Holz, C. Gorecki, K. Rieck, and F. C. Freiling. Measuring and detecting fast-flux service networks. In Network and Distributed System Security Symp. (NDSS), 2008.

[13] P. Jaccard. The distribution of flora in the alpine zone. The New Phytologist, 11(2):37–50, 1912.

[14] A. Kapravelos, M. Cova, C. Kruegel, and G. Vigna. Escape from monkey island: Evading high-interaction honeyclients. In SIG SIDAR Conf. Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA), 2011.

[15] H. Kwak, C. Lee, H. Park, and S. Moon. What is Twitter, a social network or a news media? In Int. World Wide Web Conf. (WWW), 2010.

[16] K. Lee, J. Caverlee, and S. Webb. Uncovering social spammers: Social honeypots + machine learning. In ACM SIGIR Conf., 2010.

[17] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker. Beyond blacklists: Learning to detect malicious web sites from suspicious URLs. In ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD), 2009.

[18] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker. Identifying suspicious URLs: An application of large-scale online learning. In Int. Conf. Machine Learning (ICML), 2009.

[19] D. K. McGrath and M. Gupta. Behind phishing: An examination of phisher modi operandi. In USENIX Workshop Large-Scale Exploits and Emergent Threats (LEET), 2008.

[20] M. A. Rajab, L. Ballard, N. Jagpal, P. Mavrommatis, D. Nojiri, N. Provos, and L. Schmidt. Trends in circumventing web-malware detection. Technical report, Google, 2011.

[21] J. Song, S. Lee, and J. Kim. Spam filtering in Twitter using sender-receiver relationship. In Int. Symp. Recent Advances in Intrusion Detection (RAID), 2011.

[22] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert, M. Szydlowski, R. Kemmerer, C. Kruegel, and G. Vigna. Your botnet is my botnet: Analysis of a botnet takeover. In ACM Conf. Computer and Communications Security (CCS), 2009.

[23] G. Stringhini, C. Kruegel, and G. Vigna. Detecting spammers on social networks. In Annual Computer Security Applications Conf. (ACSAC), 2010.

[24] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design and evaluation of a real-time URL spam filtering system. In IEEE Symp. Security and Privacy (Oakland), 2011.

[25] K. Thomas, C. Grier, V. Paxson, and D. Song. Suspended accounts in retrospect: An analysis of Twitter spam. In Internet Measurement Conf. (IMC), 2011.

[26] TweetAttacks. Twitter marketing software that breaks the limits. http://tweetattacks.com.

[27] Twitter Developers. Streaming API. https://dev.twitter.com/docs/streaming-api.

[28] A. Wang. Don’t follow me: Spam detecting in Twitter. In Int. Conf. Security and Cryptography (SECRYPT), 2010.

[29] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski, S. Chen, and S. King. Automated web patrol with Strider HoneyMonkeys: Finding web sites that exploit browser vulnerabilities. In Network and Distributed System Security Symp. (NDSS), 2006.

[30] C. Whittaker, B. Ryner, and M. Nazif. Large-scale automatic classification of phishing pages. In Network and Distributed System Security Symp. (NDSS), 2010.

[31] C. Yang, R. Harkreader, and G. Gu. Die free or live hard? Empirical evaluation and new design for fighting evolving Twitter spammers. In Int. Symp. Recent Advances in Intrusion Detection (RAID), 2011.

[32] J. Zhang, C. Seifert, J. W. Stokes, and W. Lee. ARROW: Generating signatures to detect drive-by downloads. In Int. World Wide Web Conf. (WWW), 2011.