### 4.1.1 Procedure

#### Interview Guide
We developed a structured question set to serve as the foundation for each interview, drawing inspiration from previous research [9] but with a specific focus on onion services. The semi-structured nature of our interviews allowed us to deviate from this set by asking follow-up questions as needed.

#### Consent and Demographic Information
We adhered to standard consent procedures for all participants. Each interview began with collecting demographic information (gender, age range, occupation, country of residence, and level of education). This was followed by questions about users' general online behavior. We concluded with questions about their use of Tor Browser and onion services, including when they started using these services, how they manage onion links, and their perceptions of the strengths and weaknesses of these services based on personal experience.

To gather data on users' mental models of Tor Browser and onion services, we designed a brief sketching exercise, similar to those used in other studies [25]. Participants were asked to draw sketches of how they believed Tor and onion services functioned, and we followed up on these drawings during the interviews.

#### Recruitment
To select eligible interview subjects, we created a short pre-interview survey [3] that asked users if they were over 18 years old, if they had used Tor Browser and onion services, and how they would rate their general privacy and security knowledge. Our goal was to target laypeople and maximize diversity in terms of culture, gender, geographic location, education, and age. The Tor Project advertised this survey through a blog post [37] and via Twitter. We also promoted the study on the Princeton Center for Information Technology (CITP) blog and recruited participants in person at an Internet freedom event.

Recruiting a representative sample of Tor users is challenging, and our methods likely resulted in a biased population for several reasons:
1. **Technical Audience**: The Tor Project's blog and Twitter accounts are more likely to be followed by technically savvy users, while non-technical users may not follow these channels.
2. **Privacy Concerns**: Tor users value their privacy highly, which may have influenced the honesty and candor of the responses we received.

#### Interviews
We conducted 13 in-person interviews and 4 remote interviews via Skype, Signal, WhatsApp, and Jitsi, depending on the participant's preference. Two participants declined to have their interviews recorded; the rest were recorded with the participant's permission. All participants completed the interview questions and the sketching exercise. Each interview concluded with a debriefing phase to address any remaining questions. Participants were compensated with a $20 gift card. The interviews took place between July 13, 2017, and October 20, 2017. The median interview duration was 34 minutes, ranging from 20 to 50 minutes.

#### Transcription and Analysis
We transcribed the interview recordings and employed qualitative data coding to analyze the transcripts [29]. For the two cases without recordings, we relied on field notes. We developed a codebook based on our research questions, using both deductive and inductive coding to identify and expand on themes of interest. We had ten parent codes, such as "Mental model of onion services," "Search habits," and "Reasons for using onion services," and 168 child codes, including "Definition- anonymous," "Word of mouth," and "Curiosity." After reaching consensus on the phenomena of interest, at least two team members (sometimes up to four) read and coded each transcript. Regular research meetings were held to discuss the coded transcripts and reach a final consensus on the themes.

### 4.1.2 Participants

We interviewed 17 subjects, as summarized in Table 1. To protect the identity of our participants, we only present aggregate demographic information. Our sample is biased towards educated and technical users, with almost 60% holding a postgraduate degree. However, it also reflects the diversity of Tor's user base, including human rights activists, legal professionals, writers, artists, and journalists. In the remainder of the paper, we refer to interview participants as 'P'.

### 4.2 Online Survey

Shortly after conducting our initial interviews, we designed, refined, and launched an online survey to complement our interview data.

#### Survey Design
We created the survey in Qualtrics because it could be displayed correctly by an unmodified Tor Browser. However, Qualtrics requires JavaScript, which is deactivated in Tor Browser's highest security setting. Several users commented on this issue in the recruitment blog post [37]. All respondents provided consent and confirmed they were at least 18 years old. The survey was available only in English but targeted an international audience due to cultural differences in security behavior [27], which aligns with The Tor Project's global mission.

The survey primarily focused on onion services but also included questions about general Tor usage. It consisted of 49 questions, mostly closed-ended. The first set of questions gathered basic demographic information (age, gender, privacy and security knowledge rating, and education level). Subsequent questions covered Tor usage frequency, detailed onion services usage, usability of onion links, management of onion domain links, and awareness of phishing and impersonation. The final set of questions explored users' general expectations of privacy and security when using onion services. Four attention checks were included to measure respondent engagement. Questions were not mandatory to ensure comfort. The survey took approximately 15 minutes to complete.

#### Survey Testing
We used cognitive pretesting to refine the survey questions [6]. Five pre-testers helped iteratively improve the survey, and after revisions, it was launched.

#### Recruitment
We advertised the survey in a blog post on The Tor Project's blog [37], on its corresponding Twitter account, the CITP blog at Princeton, and on three Reddit subforums. Unlike our interview participants, survey respondents were self-selected, likely biasing the sample towards engaged users. We did not offer incentives to allow for anonymous participation. Despite the lack of incentives, we collected sufficient responses. The survey ran from August 16 to September 11, 2017 (27 days).

#### Filtering and Analysis
Some survey responses were low-quality, possibly due to rushed answers or deliberate misinformation. We excluded participants who did not finish the survey or failed more than two out of four attention checks. We conducted a descriptive analysis of the survey data and computed correlation coefficients between every question pair, which did not yield significant results. Thus, we focus on the descriptive analysis. Percentages are reported out of the total sample, with 'No Response' denoting cases where participants chose not to answer. Two researchers performed a deductive coding pass on open-ended questions based on our interview codebook and held meetings to reach a final consensus on the themes. In the remainder of the paper, we denote survey participants as 'S'.

### 4.2.2 Participants

We collected 828 responses, of which 604 (73%) completed the survey, and 517 (62%) passed at least two attention checks. The rest of the paper focuses on these 517 responses. Table 2 shows the demographics of our survey respondents. As expected, respondents were young and educated: more than 71% were younger than 36, and 61% had at least a graduate or post-graduate degree. 44% considered themselves highly knowledgeable in matters of Internet privacy and security.

### 4.3 Domain Name Service (DNS) Queries

### 4.4 Limitations

We analyzed .onion domains leaked via the Domain Name System (DNS) to better understand onion service usage and look for specific evidence of usability issues.