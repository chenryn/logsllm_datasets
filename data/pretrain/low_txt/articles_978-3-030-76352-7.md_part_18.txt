### Search Query

- ("fault detection" OR "failure detection")
- ("ML" OR "Machine Learning")
- ("fault localization" OR "failure localization")
- ("inference" OR "logic" OR "reasoning")
- ("fault prediction" OR "failure prediction")
- ("supervised" OR "unsupervised" OR "semi-supervised" OR "reinforcement learning")
- ("fault prevention" OR "failure prevention")
- ("log" OR "logs" OR "log analysis")
- ("support vector machine" OR "SVM")
- ("metrics" OR "KPI" OR "key performance indicator")
- ("tree" OR "tree-based" OR "trees" OR "forest")
- ("remediation" OR "recovery")
- (("bayesian" OR "neural") AND "network")
- ("root cause analysis" OR "root cause analysis")
- (((("hidden" AND "markov") OR "gaussian mixture") AND "model"))
- ("tracing" OR "trace" OR "traces")
- (("data center" OR "datacenter") AND "management")

### Inclusion and Exclusion Criteria

**Inclusion Criteria:**
- The document references one or more AI methods. These mentions can be part of the implementation or as part of its discussion/analysis (e.g., in a survey).
- The document applies its concepts to some kind of IT system management.

**Exclusion Criteria:**
- The language of the document is not English.
- The document is not accessible online.
- The document does not belong to the following categories: scientific article (conference paper, journal article), book, white paper.
- The main topic of the document is one of the following: cybersecurity, industrial process control, cyber-physical systems, and optical sensor networks.
- For survey and review papers, they are considered relevant during the mapping study but excluded from the final result set, as these articles are useful for finding other connected works through references but do not constitute novel contributions to the field.

### Database Search

The database search is the first and most important step, aiming to provide the highest number of results and perform an initial screening of irrelevant papers. The search process is conducted in three steps: keywording, query construction, and result polling.

**Keywording:**
- We use the PICO technique to derive a set of keywords for AI and IT Operations. The keywords are listed in Table 1.
- For keywords with synonyms and abbreviations, we allow all equivalent expressions via OR disjunction.

**Query Construction:**
- Queries are constructed to return results where both AI and IT Operations are present.
- Logic conjunction of keywords across all combinations of the two keyword sets is applied to enforce precision in search results.
- General search queries related to the topic as a whole (e.g., "AIOps") are also performed.
- Some queries with common terms are grouped to reduce the number of queries.

**Databases:**
- IEEE Xplore
- ACM Digital Library
- arXiv

For each query, we restrict our analysis to the top 2000 results returned. Results from all searches are aggregated into one large set of papers, removing duplicates and annotating each item with corresponding search metadata (e.g., number of hits, index position in corresponding searches, etc.). This step yields 83,817 unique articles. For each item, we collect the title, authors, year, publication venue, contribution type, and citation count (from Google Scholar).

### Preliminary Filtering and Ranking-Based Selection

In the filtering step, we improve the quality of our selection of papers:
- Papers are automatically excluded based on publication venue if the venue is clearly irrelevant (e.g., meteorology).
- Papers published before 1990 are excluded as they precede the advent of large-scale IT services.
- Approximately 8,000 elements are excluded by this process.

**Ranking Procedure:**
- A ranking procedure is applied to prioritize the investigation of more relevant papers.
- The exclusion and inclusion rules are applied to the papers examined in ranking order.

**Stopping Criterion:**
- To determine when to stop the selection and discard the remaining items, we develop a new approach based on the observation of ranked items.
- The method assumes that a considerable ratio of relevant papers can be identified by ranking and selecting top results using different relevance criteria.
- We observe a long-tail distribution of relevant documents, where some relevant papers appear in the last positions even after sorting with relevance heuristics.
- Based on this assumption, we proceed as follows:
  - Screen all papers in the result set, ranked according to different relevance heuristics (e.g., number of hits in queries), and observe the ratio of relevant papers identified over time.
  - Examine the same papers in random order and measure the same ratio.
  - When the two ratios are comparable, we assert that we have reached the tail of the distribution of relevant papers and stop examining and selecting new papers.

Using this stopping criterion, we conclude this selection step when we have identified 430 relevant papers.

### Additional Search Techniques

To cover for the limitations of the "early stopping" criterion and to identify other relevant papers not present in the initial set, we apply additional search techniques:

**Reference Search:**
- For each of the 430 relevant papers, we search inside their cited references.
- We adopt backward snowball sampling, including in our relevant set all papers previously cited by a relevant paper whenever they fulfill the selection requirements.
- This method yields 631 relevant elements, for a total of 1,061.

**Conference Search:**
- We perform a manual search by inspecting papers published in relevant conferences.
- Relevant conferences are identified via correlation with other relevant papers and confirmed by experts in the field.
- We look at the latest 3 editions of each conference to compensate for the sampling of dated papers.
- This method yields 5 more papers.

**Iterative Search Improvement:**
- We analyze the available text content (text and abstract) of the relevant paper set to identify k-shingles (sets of k consecutive tokens) that appear often in relevant documents.
- We measure the document relevance probability given the set of shingles observed in the available text content.
- We use these shingles as keywords to construct new queries along with previously used AI keywords.
- This step identifies 20 new relevant papers and provides frequently cited concepts and keywords in AIOps, useful for taxonomy and classification.

### Data Extraction and Categorization

After obtaining the result set of 1,086 relevant papers, we classify the papers according to target components and data sources:

- **Target Components:** High-level pieces of software or hardware in an IT system (e.g., hard drive for hardware failure prediction). Components are grouped into five high-level categories: code, application, hardware, network, and data center.
- **Data Sources:** Input information of the algorithm (e.g., logs, metrics, execution traces). Data sources are categorized into source code, testing resources, system metrics, KPIs, network traffic, topology, incident reports, logs, and traces.
- **AI Method:** The actual algorithm employed, with similar methods aggregated into bigger classes to avoid excessive fragmentation (e.g., 'clustering' may contain both k-means and agglomerative hierarchical clustering approaches).

Table 3 presents a selection of papers from the result set with the corresponding target, source, and category annotation.

We then use the result set to infer a taxonomy based on tasks and target goals, depicted in Figure 2. The taxonomy divides AIOps contributions into failure management (FM) and resource provisioning. Within each macro-area, we further distinguish approaches based on the similarity of goals. In FM, the categories are failure prevention, online failure prediction, failure detection, root cause analysis (RCA), and remediation. In resource provisioning, the categories are resource consolidation, scheduling, power management, service composition, and workload estimation.

### Results

**Distribution of Papers:**
- The left side of Figure 3 visualizes the distribution of identified papers by macro-area and category.
- Excluding papers treating AIOps in general (8), the majority of items (670, 62.1%) are associated with FM, with most contributions concentrated in online failure prediction (26.4%), failure detection (33.7%), and RCA (26.7%).
- The remaining resource provisioning papers support resource consolidation, scheduling, and workload prediction.
- The right side of Figure 3 shows that the most common problems in FM are software defect prediction, system failure prediction, anomaly detection, fault localization, and root cause diagnosis.

**Temporal Trends:**
- Figure 4 depicts the number of publications in each category by year of publication.
- We observe a large, growing number of publications in AIOps.
- Failure detection has gained particular traction in recent years (71 publications for the 2018â€“2019 period), with a contribution size larger than the entire resource provisioning macro-area (69 publications in the same time frame).
- RCA (39) and online failure prediction (34) follow, while failure prevention and remediation have the smallest number of attested contributions (11 and 5, respectively).

### Conclusion

In this paper, we presented our contribution towards better structuring the AIOps field. Our systematic mapping study provides a comprehensive overview of the current state of research, identifying key areas of focus and temporal trends. This work serves as a foundation for future research and development in AIOps.