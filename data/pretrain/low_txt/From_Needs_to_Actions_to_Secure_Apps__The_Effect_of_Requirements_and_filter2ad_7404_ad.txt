### Table 2: Pearson R Results (R, P) Correlating App Security Measurements with Developer-based Factors

| Independent: | Expertise Support | Requirements | USENIX Association |
|--------------|------------------|--------------|--------------------|
| Dependent:   | Cryptographic API Misuse | Privacy Leak | SSL Security |
| -0.17, 0.016 | -0.09, 0.20      | -0.14, 0.049 | -0.06, 0.37        |
| -0.01, 0.85  | 0.01, 0.93       |              |                    |
| Developer Knowledge | -0.09, 0.17 | 0.02, 0.81 | -0.02, 0.76 |
| Assurance Technique Use | -0.13, 0.047 | 0.02, 0.81 | -0.08, 0.20 |

**Note:** Non-italic figures highlighted in yellow indicate a statistically significant result (p < 0.01).

---

### Section 5.2: Combinations of Assurance Techniques

Figure 6 indicates that over 60% of the respondents consider security to be very or extremely important to their users, and an even higher percentage place the same value on privacy.

The combinations of assurance techniques used, as discussed in Section 5.2, provide insights into how security improvements are being implemented. Although the analysis only covers a small fraction of the total population, it focuses on those using a subset of assurance techniques, offering a glimpse into which techniques are adopted first. 

One might expect teams driven by external experts to adopt the Threat Assessment/Penetration Test combination, as these activities can be performed by the experts themselves. However, more teams adopt tool-only techniques (e.g., Automated Static Analysis and Configuration Review) or code-review-based techniques (e.g., Automated Static Analysis and Code Review). This suggests that many teams lack access to security experts (Section 5.2).

This implies that the adoption of assurance techniques is primarily driven by developers rather than external security experts, indicating a trend towards developer-led security. This aligns with the reasons given for app security changes in Figure 11, where the most common reason for changes was developer initiative. It also resonates with the views of security experts, who emphasize the importance of developer initiative in improving software security [53].

### Section 6.2: Appropriate Use of Security Techniques

Using security assurance techniques incurs costs in both time and financial terms [45]. Therefore, it is economically inefficient to adopt them when they are not necessary. Table 1 shows that this is correctly reflected in the Android ecosystem: the use of assurance techniques increases in line with the importance of security for the app. We suggest that the correlation with the involvement of security professionals/champions and with developer knowledge of security may be both a cause (their involvement leads to increased assurance technique use) and an effect (expert developers and security professionals tend to work on products that need security).

Updating apps also has a considerable cost, and we would expect more security updates in cases where security is crucial for the app. Table 1 confirms this behavior, showing no correlation between the frequency of security updates and the security experience of the developer.

### Section 6.3: Impact on Real App Security

It was disappointing to find that the use of assurance techniques did not significantly lead to better security outcomes when analyzing the apps. Even though the analysis tools can only detect a limited range of code-level security issues, we expected more security-experienced developers and those using assurance techniques—especially Static Code Analysis—to generate fewer such issues.

We conclude that other factors must overshadow this effect. For example, most app binary code consists of libraries, and even up-to-date libraries can vary greatly in the number of issues they may have. We hypothesize that the scores generated by the tools depend more on the nature of the libraries needed to implement the app functionality than on the non-library code created by the developers. Current tools cannot verify this effect (Section 4.5).

More surprising is the finding that the involvement of professionals and champions seems to be associated with increased numbers of Cryptographic API issues. It is unlikely that they create these issues. Instead, our tools do not detect a failure to use cryptography in apps where it is required, whereas experts or champions will. We suggest that teams involving experts or champions will therefore tend to use cryptography more frequently, leading to more such issues.

### Section 6. Discussion

At first glance, the findings in Sections 5.6 and 5.7 present a discouraging view of app security. Over 80% of apps had reported defects from our analysis tools, and the majority of apps receive security updates less than once a year. Table 2 shows that security outcomes have little correlation with an app’s perceived need for security and privacy. Figure 12 indicates that GDPR's new compliance rules for apps have had minimal positive impact, suggesting that GDPR has not been a strong force for improving app security and privacy.

### Section 6.1: Adoption of Security Techniques by Developers

However, there are positive aspects. Figure 7 shows that the vast majority of respondents consider themselves to have at least some security knowledge, indicating awareness of security as a potential issue in software development. 

### Section 7: Summary and Conclusions

This paper describes the creation and deployment of a survey to Android app developers, asking about their approach to security and privacy in app development. In the second phase, we compared the responses with the outcomes of running security analysis tools on one of their apps. The research addresses the following questions:

**RQ1:** To what extent, and how, does a perceived need for security and privacy lead to security-enhancing activities and interactions in the development team?

From the 335 survey responses analyzed, we found a high level of reported security need for app development, but less use of practical security assurance techniques (Section 5.2). Where such techniques were used, this was in proportion to the perceived need, as was the involvement of professionals and security champions. The frequency of app security updates followed a similar pattern (Sections 5.4, 6.2).

Considering the "how" of RQ1: in the perception of respondents, app security improvements have been predominantly driven by developers themselves (Section 6.1); this is supported by the observation that the assurance techniques first adopted are those most easily available to developers. GDPR has also had an impact, though the resulting changes for GDPR have been mainly cosmetic (Section 5.3).

**RQ2:** To what extent do the need for security, the involvement of specialist roles, and the use of assurance techniques in a development team lead to fewer security defects?

The results of the app analysis showed little relationship with the reported security drivers and development process from the survey; we believe this reflects the inability of the current generation of binary analysis tools to analyze libraries effectively and separately from the main app code. We did, however, find the involvement of security specialists or champions to be associated with more Cryptographic API issues, probably since they correctly enforce much more Cryptography use (Sections 5.7, 6.3).

**RQ3:** What proportion of Android developers have access to security experts?

Section 5.2 concludes that between 14% and 22% of developers work with security experts.

**RQ4:** To what extent do Android developers actually use assurance techniques?

Only between 22% and 30% regularly use assurance techniques (Section 5.2).

Given the high need for security and the low use of assurance techniques and low availability of security professionals, we suggest an urgent need for ways to support app developers in adopting security assurance techniques in the absence of security professionals.

### Section 7.1: Future Work

As discussed in Section 6.3, we need binary analysis tools capable of:
1. Detecting library versions.
2. Performing static analysis on library components separately from the main code.

This is an active area of research; once such tools are available, a further survey using these will provide valuable results and an indication of changes over time in Android developer security practices.

More information is also needed to support developers in using these assurance techniques, starting with how developers currently use each one. Specific questions might address where developers go to get security advice, what tools they use to analyze their code, the methods they use for library analysis, how they approach penetration testing, what forms of code review they use, and how they tackle threat assessment. A further online survey can investigate these questions.

### Section 7.2: Notes and Credits

A privacy-preserving set of the survey data, along with the full questions and data description, is available online [52].

First, we thank Christian Stransky of LU Hannover for obtaining the Google Play data and APK files used as a basis for the survey; and Dominik Wermke of LU Hannover for initiating the use of Python and Jupyter notebooks for statistical analysis in this project.

We thank Dr. Tamara Lopez of the Open University, UK, for her helpful review of the survey questionnaire; Dr. Yasemin Acar, of LU Hannover for practical guidance on creating and validating questionnaires; and Professor Ian White, of UCL, UK, for valuable advice on the statistical analysis.

We also thank the eight anonymous reviewers of this and an earlier version of this paper, who have all contributed significantly; and particularly USENIX shepherd Professor Daniel Zappala of Brigham Young University.

This research was partially funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy - EXC 2092 CASA – 390781972.

### References

[1] Acar, Y., Backes, M., Fahl, S., et al. Comparing the Usability of Cryptographic APIs. 2017 IEEE Symposium on Security and Privacy (SP), IEEE (2017), 154–171.

[2] Acar, Y., Backes, M., Fahl, S., Kim, D., Mazurek, M.L., and Stransky, C. You Get Where You’re Looking For: The Impact of Information Sources on Code Security. IEEE Symposium on Security and Privacy, (2016), 289–305.

[3] Anscombe, F.J. The Transformation of Poisson, Binomial and Negative-Binomial Data. Biometrika 35, 3/4 (1948), 246.

[4] Arzt, S., Rasthofer, S., Fritz, C., et al. FlowDroid: Precise Context, Flow, Field, Object-sensitive and Lifecycle-aware Taint Analysis for Android Apps. Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, (2014).

[5] Assal, H. and Chiasson, S. Think Secure From the Beginning: A Survey With Software Developers. Conference on Human Factors in Computing Systems (CHI), (2019).

[6] Backes, M., Bugiel, S., and Derr, E. Reliable Third-Party Library Detection in Android and Its Security Applications. Proceedings of the ACM Conference on Computer and Communications Security, (2016), 356–367.

[7] Bai, J., Wang, W., Qin, Y., Zhang, S., Wang, J., and Pan, Y. BridgeTaint: A Bi-Directional Dynamic Taint Tracking Method for JavaScript Bridges in Android Hybrid Applications. IEEE Transactions on Information Forensics and Security 14, 3 (2019), 677–692.

[8] Becker, I., Parkin, S., and Sasse, M.A. Finding Security Champions in Blends of Organisational Culture. Proceedings 2nd European Workshop on Usable Security, (2017).

[9] Bell, L., Brunton-Spall, M., Smith, R., and Bird, J. Agile Application Security: Enabling Security in a Continuous Delivery Pipeline. O’Reilly, Sebastopol, CA, 2017.

[10] Caputo, D.D., Pfleeger, S.L., Sasse, M.A., Ammann, P., Offutt, J., and Deng, L. Barriers to Usable Security? Three Organizational Case Studies. IEEE Security and Privacy 14, 5 (2016), 22–32.

[11] CONSORT. Checklist of Information to Include When Reporting a Randomized Trial. 2010, 11–12. http://www.consort-statement.org/consort-2010.

[12] Coopamootoo, K.P.L. and Gross, T. A Codebook for Evidence-Based Research: The Nifty Nine Completeness Indicators. Newcastle, 2017.

[13] Date, S. The F-Test for Regression Analysis - Towards Data Science. https://towardsdatascience.com/fisher-test-for-regression-analysis-1e1687867259.

[14] Deborah J. Rumsey. Statistics Essentials For Dummies. Wiley, For Dummies, 2019.

[15] Derr, E., Bugiel, S., Fahl, S., Acar, Y., and Backes, M. Keep Me Updated: An Empirical Study of Third-Party Library Updatability on Android. Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security - CCS ’17, ACM Press (2017), 2187–2200.

[16] Egelman, S. and Peer, E. Scaling the Security Wall: Developing a Security Behavior Intentions Scale (SeBIS). Conference on Human Factors in Computing Systems (CHI2015), (2015).

[17] Eichberg, M. and Hermann, B. A Software Product Line for Static Analyses: The OPAL Framework. Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI) 2014-June, June (2014).

[18] Enck, W., Octeau, D., McDaniel, P., and Chaudhuri, S. A Study of Android Application Security. Proceedings of the 20th USENIX conference on Security, (2011).

[19] European Commission. General Data Protection Regulation (GDPR). 2019. https://ec.europa.eu/info/law/law-topic/data-protection_en.

[20] Fahl, S., Harbach, M., Muders, T., Smith, M., Baumgärtner, L., and Freisleben, B. Why Eve and Mallory Love Android: An Analysis of Android SSL. Proceedings of the 2012 ACM conference on Computer and communications security - CCS ’12, ACM Press (2012).

[21] Fowler, F.J. Survey Research Methods. Sage.

[22] Glanz, L., Amann, S., Eichberg, M., et al. CodeMatch: Obfuscation Won’t Conceal Your Repackaged App. Proceedings of ESEC/FSE’17, (2017), 638–648.

[23] Haney, J.M. and Lutters, W.G. The Work of Cybersecurity Advocates. Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA ’17, ACM Press (2017), 1663–1670.

[24] Kline, T. Classical Test Theory: Assumptions, Equations, Limitations, and Item Analyses.