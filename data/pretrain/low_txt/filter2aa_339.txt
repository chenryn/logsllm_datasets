# Secure Because Math: A Deep Dive into Machine Learning-Based Monitoring

### Speaker
**Alex Pinto**
- Chief Data Scientist, MLSec Project
- Machine Learning Researcher and Trainer
- Network Security and Incident Response Enthusiast
- Tortured by SIEMs as a Child
- Hacker Spirit Animal™: CAFFEINATED CAPYBARA

### Agenda
- **Security Singularity Approaches**
- **Some History**
- **Three-Letter Acronyms (TLAs)**
- **ML Marketing Patterns**
- **Anomaly Detection**
- **Classification**
- **Buyer’s Guide**
- **MLSec Project**

### Security Singularity Approaches
- "Machine learning, math, and algorithms... these terms are used interchangeively quite frequently."
- "Is behavioral baselining and anomaly detection part of this?"
- "What about Big Data Security Analytics?"

### Are We Even Trying?
- **Hyper-dimensional security analytics**
- **3rd generation Artificial Intelligence**
- **Secure because Math**
- **Lack of differentiation hurts buyers and investors.**
- **Are we even funding the right things?**

### Is This a Communication Issue?
- **Guess the Year!**
  - “(…)...behavior analysis system that enhances your network intelligence and security by auditing network flow data from existing infrastructure devices.”
  - "Mathematical models (…)...that determine baseline behavior across users and machines, detecting (...) anomalous and risky activities (...)."
  - ”(…)...maintains historical profiles of usage per user and raises an alarm when observed activity departs from established patterns of usage for an individual.”

### A Little History
- **Dorothy E. Denning**
  - Professor at the Department of Defense Analysis, Naval Postgraduate School
  - 1986 (SRI): First research leading to IDS
  - Intrusion Detection Expert System (IDES)
  - Already had statistical anomaly detection built-in
  - 1993: Colleagues release the Next Generation IDES

### Three-Letter Acronyms (TLAs) - KDD
- After the release of Bro (1998) and Snort (1999), DARPA thought we were covered for signature-based detection.
- DARPA released datasets for user anomaly detection in 1998 and 1999.
- The KDD-99 dataset was released, with over 6200 citations on Google Scholar.

### ML Marketing Patterns
- **The "Has-beens"**
  - Name is a bit harsh, but you hardly use ML anymore; let us try it.
- **The "Machine Learning o\_()_/o"**
  - Hey, that sounds cool; let’s put that in our brochure.
- **The "Sweet Spot"**
  - People who are actually trying to do something.
  - Anomaly Detection vs. Classification

### Anomaly Detection
- **Works well for well-defined "industrial-like" processes.**
- **Single, consistently measured variables.**
- **Historical usage in financial fraud prevention.**
- **Challenges:**
  - **Curse of Dimensionality**
    - Need "distances" to measure features/variables (e.g., Manhattan or Euclidean).
    - For high-dimensional data, the distribution of distances between all pairwise points becomes concentrated around an average distance.
    - The volume of the high-dimensional sphere becomes negligible compared to the high-dimensional cube, making everything seem too far away and at similar distances.
  - **Normality Poisoning**
    - Ground Truth (labels) >> Features >> Algorithms
    - No (or very little) Ground Truth in AD
    - Problem asymmetry: Solutions are biased towards the prevalent class
    - Hard to fine-tune, prone to many false negatives or positives
  - **Hanlon’s Razor**
    - Never attribute to malice that which is adequately explained by stupidity.

### User Behavior
- **Surprise, it kinda works! (as supervised)**
  - Specific implementations for specific solutions
  - Good examples from Square, AirBnB
  - Well-defined scope and labeling
  - Can it be general enough?
  - File exfiltration example (roles/info classification are mandatory?)
  - Can I "average out" user behaviors in different applications?

### Classification
- **Lots of available academic research around this**
- **Classification and clustering of malware samples**
- **More success in classifying artifacts you already know to be malware than in detecting new ones.**
- **State of the art? My guess is AV companies.**
  - They have an absurd amount of samples and have been researching and consolidating data for decades.

### Lots of Malware Activity
- **Can we do better than "AV Heuristics"?**
- **Lots of available public data**
- **Some papers suffer from potentially bad ground truth.**

### Threat Intelligence-Based Models
- **Private Beta of our Threat Intelligence-based models:**
  - Some use TI indicator feeds as blocklists.
  - More mature companies use the feeds to learn about threats (trained professionals only).
  - Our models extrapolate the knowledge of existing threat intelligence feeds as experienced analysts would.
  - Supervised model with seeded labeling from TI feeds.

### How Is It Going, Alex?
- **Very effective first triage for SOCs and Incident Responders**
  - Send us: log data from firewalls, DNS, web proxies
  - Receive: Report with a short list of potential compromised machines
  - Would you rather download all the feeds and integrate them yourself?
  - MLSecProject/Combine
  - MLSecProject/TIQ-test

### Why Should I Care?
- **Huge amounts of TI feeds available now (open/commercial)**
- **Non-malicious samples still challenging, but we have expanded to many collection techniques from different sources.**
  - High-ranked Alexa/Quantcast/OpenDNS random domains as seeds for trust search
  - Helped by customer logs in a semi-supervised fashion

### Ground Truth (Labels)
- **Vast majority of features are derived from structural/intrinsic data:**
  - GeoIP, ASN information, BGP Prefixes
  - pDNS information for IP addresses, hostnames
  - WHOIS information
  - A packer can’t change these things without cost.
  - Log data from the customer can, of course, but this does not make it worse than human specialists.

### Data Tampering
- **False positives/negatives are an intrinsic part of ML.**
- **“False positives are very good, and would have fooled our human analysts at first.”**
- **Their feedback helps us improve the models for everyone.**
- **Remember, it is about initial triage. A Tier-2/Tier-3 analyst must investigate and provide feedback to the model.**

### False Positives
- **Questions to Consider:**
  - What are you trying to achieve with adding Machine Learning to the solution?
  - What are the sources of Ground Truth for your models?
  - How can you protect the features/ground truth from adversaries?
  - How does the solution/process handle false positives?

### Buyer’s Guide
- **Don’t take my word for it! Try it out!**
- **Help us test and improve the models!**
- **Looking for participants and data sharing agreements.**
- **Limited capacity at the moment, so be patient. :)**
- **Visit [www.mlsecproject.org](http://www.mlsecproject.org), message @MLSecProject, or email me.**

### Thanks!
- **Q&A?**
- **Don’t forget the feedback!**

**Alex Pinto**
- @alexcpsec
- @MLSecProject
- "We are drowning in information and starved for knowledge." — John Naisbitt