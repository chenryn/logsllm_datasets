# Recent Developments in File Sharing Systems

Recently, file sharing systems such as BitTorrent and eMule have incorporated structured Distributed Hash Tables (DHTs) into their design [22]. For this component of the file sharing system, we propose replacing their DHTs with VerDi to leverage the benefits of our scheme.

## 7. Evaluation

In this section, we present an experimental evaluation of Verme and compare it to the Chord overlay, which served as the basis for our design.

### 7.1. Implementation Details

We implemented Verme by modifying the Chord implementation for p2psim [13], a discrete event simulator written in C++. The three variants of the VerDi DHT were developed based on an incomplete implementation of DHash included in p2psim. This partial implementation included the `get` operation and data stabilization routines to maintain certain replication levels for the data. We added the `put` operation and extended DHash to create the three variants of VerDi.

### 7.2. Performance Overhead

#### 7.2.1. Simulation Setup

Our experiments used a simulated network of 1,740 nodes, with inter-node latencies derived from DNS server measurements using the King method [14]. The average round trip time (RTT) was 198 ms. In both Verme and Chord overlays, each node had 10 successors, and stabilization functions ran every 30 seconds, while finger stabilization occurred every 60 seconds. Lookups were issued with random keys by each node at intervals exponentially distributed with a mean of 30 seconds, based on prior research [17, 23].

The Verme overlay was configured with 128 sections, resulting in an average of 13 nodes per section, with each node having 10 predecessors. The mean node lifetime was varied across 15 minutes, 30 minutes, 1 hour, 4 hours, and 8 hours. The same proportion of nodes of each type was used, and results with uneven distributions were omitted due to space constraints. These results indicated a slight load imbalance, which would only become significant under very high loads.

#### 7.2.2. Evaluation Results

**Figure 5. Comparison of Lookup Latencies**

**Figure 6. Latencies for Get and Put Operations**

Each experiment ran for 12 hours, and we computed average values. Each simulation was repeated 8 times, and we report the average results.

Verme lookups are recursive, whereas Chord lookups can be transitive, where a recursive route is taken by the lookup request, but the reply is given directly to the initiator. Figure 5 shows that Verme's lookup latencies are 35% higher than those of transitive Chord. However, the impact of this overhead is minimized when considering that a DHT operation includes both the lookup and the time to download or upload the data. Compared to recursive Chord, Verme's latency is similar, indicating that changes in the finger assignment and lookup strategy did not introduce significant overhead. Node dynamics did not affect the comparison, as all implementations were equally affected by the need to route around failures.

Additional experiments, reported in a separate document [11], show that both lookup failure rates and the bandwidth used for overlay maintenance and lookups do not differ significantly between Chord and Verme.

### 7.3. VerDi Overhead

Next, we evaluate the overhead of VerDi compared to Chord's DHT layer, DHash. For these experiments, the King dataset was less useful because it lacked reference values for bandwidth between nodes. Therefore, we modified the setup to use the GT-ITM model [26].

**Figure 6. Latencies for Get and Put Operations**

**Figure 7. Bandwidth for Get and Put Operations**

The results confirm a tradeoff between performance and security. Fast-VerDi has the lowest latency, close to DHash, as both perform a recursive lookup followed by a direct download from the responsible node. Secure-VerDi has the highest latency due to costly data transfers along the reverse lookup path. Compromise-VerDi performs between the other two, with up to 31% slower latency than DHash.

For put operations, Secure-VerDi has the highest latency because the data is sent through the forward lookup path. Fast-VerDi and Compromise-VerDi show a larger difference compared to DHash because the reply is only sent to the client after the responsible node makes a copy to the other responsible node of the opposite type.

**Figure 7. Bandwidth for Get and Put Operations**

Bandwidth usage for get operations is similar for DHash and Fast-VerDi, as most bandwidth is spent on data transfer from the responsible node to the client. Secure-VerDi is more costly due to piggybacking data on the reply, and Compromise-VerDi approximately doubles the bandwidth consumption. Put operations show similar results, with additional copies made before returning to the client. The results in Figure 7 do not include the bandwidth used for creating additional replicas, which occurs in the background.

### 7.4. Worm Propagation Speed

To analyze the benefits of using Verme in slowing down worm propagation, we developed a model based on existing work [21]. Nodes can be in one of four states: not infected, scanning, infecting, or inactive. A scanning node starts scanning other nodes at a rate of 100 scans/machine/second, with a 100 ms infection time and 1 second activation time. We considered a 100,000-node static overlay, with 50% of the machines vulnerable to the worm. The Verme overlay was configured with 4,096 sections, averaging 24 nodes per section.

**Figure 8. Simulated Propagation Speeds**

We compared the propagation speeds for different strategies: a P2P worm propagating exclusively in a Chord overlay, a P2P worm propagating exclusively in Verme, and a P2P worm using an impersonating node. For Fast-VerDi, the impersonating node issued 10 lookups per second, and for Compromise-VerDi, each node issued 1 lookup per second. Each strategy was simulated 10 times, and we report the average results.

Figure 8 shows the number of infected machines over time. Chord allows very fast propagation, infecting the entire system in 32 seconds. Verme confines the worm to a single section without impersonation. Secure-VerDi limits the infection to a logarithmic number of sections (352 nodes). Fast-VerDi and Compromise-VerDi slow down worm propagation, even with an impersonation attack, taking approximately 160 and 1600 seconds to infect half of the vulnerable population.

## 8. Conclusion

This paper introduces a novel overlay called Verme and a new DHT called VerDi, designed to contain or slow down the propagation of P2P worms. Our simulations show that the overhead of using Verme and VerDi is reasonable compared to Chord and DHash, and that Verme effectively contains or slows down worm propagation. This design represents a significant step towards containing worms that propagate using overlay networks and raises the difficulty level for writing such worms.

## 9. Acknowledgments

We thank the anonymous reviewers for their valuable feedback.

## References

[1] http://www.securityfocus.com/bid/4951.
[2] http://www.securityfocus.com/bid/6747.
[3] http://www.cert.org/incident_notes/IN-2004-01.html.
[4] Bitcomet torrent file handling remote buffer overflow vulnerability. http://www.securityfocus.com/bid/16311.
[5] G. Chen and R. S. Gray. Simulating non-scanning worms on peer-to-peer networks. In Proceedings of 1st International Conference on Scalable Information Systems (INFOSCALE 2006), May 2006.
[6] B. Cohen. Incentives build robustness in BitTorrent. In Proceedings of the First Workshop on the Economics of Peer-to-Peer Systems, 2003.
[7] M. Costa, J. Crowcroft, M. Castro, A. Rowstron, L. Zhou, L. Zhang, and P. Barham. Vigilante: End-to-end containment of internet worms. In Proceedings of the 20th ACM Symposium on Operating Systems Principles (SOSP 2005), Oct. 2005.
[8] F. Dabek, M. F. Kaashoek, D. Karger, R. Morris, and I. Stoica. Wide-area cooperative storage with CFS. In Proceedings of the 18th ACM Symposium on Operating System Principles, Oct. 2001.
[9] F. Dabek, J. Li, E. Sit, J. Robertson, M. F. Kaashoek, and R. Morris. Designing a DHT for low latency and high throughput. In Proceedings of the 1st USENIX Symposium on Networked Systems Design and Implementation (NSDI ’04), March 2004.
[10] J. Douceur. The Sybil attack. In Proceedings of the 1st International Workshop on Peer-to-Peer Systems (IPTPS’02), Mar. 2002.
[11] F. Freitas. Verme: Worm containment in overlay networks. Master Dissertation in Computer Engineering, Technical University of Lisbon, 2008.
[12] F. Freitas, R. Rodrigues, C. Ribeiro, P. Ferreira, and L. Rodrigues. Verme: Worm containment in peer-to-peer overlays. In 6th International Workshop on Peer-to-Peer Systems (IPTPS’07), 2007.
[13] T. Gil, F. Kaashoek, J. Li, R. Morris, and J. Stribling. p2psim: A simulator for peer-to-peer (P2P) protocols. http://pdos.csail.mit.edu/p2psim/.
[14] K. P. Gummadi, S. Saroiu, and S. D. Gribble. King: Estimating latency between arbitrary internet end hosts. In IMW ’02: Proceedings of the 2nd ACM SIGCOMM Workshop on Internet Measurement, 2002.
[15] F. Junqueira, R. Bhagwan, A. Hevia, K. Marzullo, and G. M. Voelker. Surviving internet catastrophes. In Proceedings of USENIX Annual Tech. Conference, 2005.
[16] C. Kreibich and J. Crowcroft. Honeycomb - Creating intrusion detection signatures using honeypots. In Proceedings of HotNets 2003, Nov. 2003.
[17] J. Li, J. Stribling, R. Morris, M. F. Kaashoek, and T. M. Gil. A performance vs. cost framework for evaluating DHT design tradeoffs under churn. In Proceedings of the INFOCOM’05, 2005.
[18] D. Moore, C. Shannon, and J. Brown. Code-red: A case study on the spread and victims of an internet worm. In IMW ’02: Proceedings of the 2nd ACM SIGCOMM Workshop on Internet Measurement, 2002.
[19] K. Ramachandran and B. Sikdar. Modeling malware propagation in Gnutella-type peer-to-peer networks. In Proceedings of the 20th IEEE International Parallel and Distributed Processing Symposium (IPDPS 2006), Apr. 2006.
[20] S. Singh, G. V. C. Estan, and S. Savage. Automated worm fingerprinting. In Proceedings of 6th Symposium on operating design and implementation 2004 (OSDI 2004), Dec. 2004.
[21] S. Staniford, V. Paxson, and N. Weaver. How to 0wn the internet in your spare time. In Proceedings of USENIX Security Symposium 2002, Aug. 2002.
[22] M. Steiner, E. W. Biersack, and T. Ennajjary. Actively monitoring peers in KAD. In 6th International Workshop on Peer-to-Peer Systems (IPTPS’07).
[23] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan. Chord: A scalable peer-to-peer lookup service for internet applications. In SIGCOMM ’01: Proceedings of the 2001 conference on Applications, technologies, architectures, and protocols for computer communications, Aug. 2001.
[24] K. Walsh and E. G. Sirer. Experience with an object reputation system for peer-to-peer filesharing. In 3rd Symposium on Networked Systems Design and Implementation (NSDI 06), May 2006.
[25] W. Yu, C. Boyer, S. Chellappan, and D. Xuan. Peer-to-peer system-based active worm attacks: Modeling and analysis. In IEEE International Conference on Communications (ICC), May 2005.
[26] E. W. Zegura, K. L. Calvert, and S. Bhattacharjee. How to model an internetwork. In INFOCOM, pages 594–602, 1996.
[27] L. Zhou, L. Zhang, F. McSherry, N. Immorlica, M. Costa, and S. Chien. A first look at peer-to-peer worms: Threats and defenses. In Proceedings of the 4th International Workshop on Peer-To-Peer Systems (IPTPS’05), Feb. 2005.
[28] C. C. Zou, W. Gong, D. Towsley, and L. Gao. The monitoring and early detection of internet worms. IEEE/ACM Trans. Netw., 13(5):961–974, 2005.