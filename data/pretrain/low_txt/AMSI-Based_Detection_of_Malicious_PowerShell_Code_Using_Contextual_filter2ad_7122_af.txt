以下是优化后的文本，使其更加清晰、连贯和专业：

---

### 参考文献

1. R. J. Schalkoff, *Artificial Neural Networks*. New York: McGraw-Hill, 1997, vol. 1.
2. B. Yegnanarayana, *Artificial Neural Networks*. New Delhi: PHI Learning Pvt. Ltd., 2009.
3. Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel, “Backpropagation applied to handwritten zip code recognition,” *Neural Computation*, vol. 1, no. 4, pp. 541–551, 1989.
4. Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” *Proceedings of the IEEE*, vol. 86, no. 11, pp. 2278–2324, 1998.
5. Y.-L. Boureau, F. Bach, Y. LeCun, and J. Ponce, “Learning mid-level features for recognition,” in *Computer Vision and Pattern Recognition (CVPR)*, 2010 IEEE Conference on, pp. 2559–2566, 2010.
6. D. M. Hawkins, “The problem of overfitting,” *Journal of Chemical Information and Computer Sciences*, vol. 44, no. 1, pp. 1–12, 2004.
7. G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov, “Improving neural networks by preventing co-adaptation of feature detectors,” arXiv preprint arXiv:1207.0580, 2012.
8. S. Lai, L. Xu, K. Liu, and J. Zhao, “Recurrent convolutional neural networks for text classification,” in *AAAI*, vol. 333, pp. 2267–2273, 2015.
9. T. Mikolov, M. Karafiát, L. Burget, J. Cernocký, and S. Khudanpur, “Recurrent neural network based language model,” in *Interspeech*, vol. 2, p. 3, 2010.
10. A. Graves, A.-r. Mohamed, and G. Hinton, “Speech recognition with deep recurrent neural networks,” in *Acoustics, Speech and Signal Processing (ICASSP)*, 2013 IEEE International Conference on, pp. 6645–6649, 2013.
11. A. Graves and N. Jaitly, “Towards end-to-end speech recognition with recurrent neural networks,” in *Proceedings of the 31st International Conference on Machine Learning (ICML-14)*, pp. 1764–1772, 2014.
12. H. Sak, A. Senior, and F. Beaufays, “Long short-term memory recurrent neural network architectures for large scale acoustic modeling,” in *Fifteenth Annual Conference of the International Speech Communication Association (INTERSPEECH)*, 2014.
13. A. Graves, “Generating sequences with recurrent neural networks,” arXiv preprint arXiv:1308.0850, 2013.
14. A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei, “Large-scale video classification with convolutional neural networks,” in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, pp. 1725–1732, 2014.
15. S. Hochreiter and J. Schmidhuber, “Long short-term memory,” *Neural Computation*, vol. 9, no. 8, pp. 1735–1780, 1997.
16. M. Schuster and K. K. Paliwal, “Bidirectional recurrent neural networks,” *IEEE Transactions on Signal Processing*, vol. 45, no. 11, pp. 2673–2681, 1997.
17. Y. Goldberg, “A primer on neural network models for natural language processing,” *Journal of Artificial Intelligence Research*, vol. 57, pp. 345–420, 2016.
18. D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning representations by back-propagating errors,” *Nature*, vol. 323, no. 6088, pp. 533–536, 1986.
19. S. T. Roweis and L. K. Saul, “Nonlinear dimensionality reduction by locally linear embedding,” *Science*, vol. 290, no. 5500, pp. 2323–2326, 2000.
20. T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efficient estimation of word representations in vector space,” in *ICLR Workshop*, 2013.
21. D. W. Hosmer Jr, S. Lemeshow, and R. X. Sturdivant, *Applied Logistic Regression*. Hoboken, NJ: John Wiley & Sons, 2013, vol. 398.
22. S. Kaufman, S. Rosset, C. Perlich, and O. Stitelman, “Leakage in data mining: Formulation, detection, and avoidance,” *ACM Transactions on Knowledge Discovery from Data (TKDD)*, vol. 6, no. 4, p. 15, 2012.
23. L. van der Maaten and G. Hinton, “Visualizing data using t-SNE,” *Journal of Machine Learning Research*, vol. 9, no. Nov, pp. 2579–2605, 2008.
24. S. Xingjian, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, and W.-c. Woo, “Convolutional LSTM network: A machine learning approach for precipitation nowcasting,” in *Advances in Neural Information Processing Systems (NIPS)*, pp. 802–810, 2015.
25. B. Athiwaratkun and J. W. Stokes, “Malware classification with LSTM and GRU language models and a character-level CNN,” in *Acoustics, Speech and Signal Processing (ICASSP)*, 2017 IEEE International Conference on, pp. 2482–2486, 2017.
26. J. Saxe and K. Berlin, “EXPOSE: A character-level convolutional neural network with embeddings for detecting malicious URLs, file paths and registry keys,” arXiv preprint arXiv:1702.08568, 2017.
27. W. Yang, W. Zuo, and B. Cui, “Detecting malicious URLs via a keyword-based convolutional gated-recurrent-unit neural network,” *IEEE Access*, 2019.
28. Microsoft, “Windows Defender ATP Machine Learning and AMSI,” https://www.mdsec.co.uk/2018/06/exploring-powershell-amsi-and-logging-evasion/, 2017.
29. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is all you need,” in *Advances in Neural Information Processing Systems (NIPS)*, 2017, pp. 6000–6010.
30. M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer, “Deep contextualized word representations,” arXiv preprint arXiv:1802.05365, 2018.
31. Y. Kim, “Convolutional neural networks for sentence classification,” arXiv preprint arXiv:1408.5882, 2014.
32. R. Collobert and J. Weston, “A unified architecture for natural language processing: Deep neural networks with multitask learning,” in *Proceedings of the 25th International Conference on Machine Learning (ICML)*, pp. 160–167, 2008.
33. F. Chollet et al., “Keras,” https://github.com/fchollet/keras, 2015.
34. L. Prechelt, “Early stopping—but when?” in *Neural Networks: Tricks of the Trade*, Springer, 1998, pp. 55–69.
35. D. Bohannon and L. Holmes, “REVOKE-OBFUSCATION: PowerShell obfuscation detection using science,” 2017.
36. G. Rusak, A. Al-Dujaili, and U.-M. O’Reilly, “AST-based deep learning for detecting malicious PowerShell,” in *Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (CCS)*, pp. 2276–2278, 2018.
37. N. Provos, D. McNamee, P. Mavrommatis, K. Wang, N. Modadugu et al., “The ghost in the browser: Analysis of web-based malware,” *HotBots*, vol. 7, pp. 4–4, 2007.
38. P. Likarish, E. Jung, and I. Jo, “Obfuscated malicious JavaScript detection using classification techniques,” in *2009 4th International Conference on Malicious and Unwanted Software (MALWARE)*, pp. 47–54, 2009.
39. I. A. AL-Taharwa, H.-M. Lee, A. B. Jeng, K.-P. Wu, C.-S. Ho, and S.-M. Chen, “JSOD: JavaScript Obfuscation Detector,” *Security and Communication Networks*, vol. 8, no. 6, pp. 1092–1107, 2015.
40. W. Xu, F. Zhang, and S. Zhu, “JSTILL: Mostly static detection of obfuscated malicious JavaScript code,” in *Proceedings of the Third ACM Conference on Data and Application Security and Privacy (CODASPY)*, pp. 117–128, 2013.
41. S. Kaplan, B. Livshits, B. Zorn, C. Siefert, and C. Curtsinger, “NOFUS: Automatically detecting ‘+ string.fromCharCode(32)+’ obfuscated ‘.toLowerCase()’ JavaScript code,” Technical Report MSR-TR 2011–57, Microsoft Research, 2011.
42. M. Cova, C. Kruegel, and G. Vigna, “Detection and analysis of drive-by-download attacks and malicious JavaScript code,” in *Proceedings of the 19th International Conference on World Wide Web (WWW)*, pp. 281–290, 2010.
43. W. Wei-Hong, L. Yin-Jun, C. Hui-Bing, and F. Zhao-Lin, “A static malicious JavaScript detection using SVM,” in *Proceedings of the 2nd International Conference on Computer Science and Electronics Engineering (ICCSEE)*, 2013.
44. I. Corona, D. Maiorca, D. Ariu, and G. Giacinto, “LUXOR: Detection of malicious PDF-embedded JavaScript code through discriminant analysis of API references,” in *Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop (AISec)*, pp. 47–57, 2014.
45. P. Laskov and N. Šrndić, “Static detection of malicious JavaScript-bearing PDF documents,” in *Proceedings of the 27th Annual Computer Security Applications Conference (ACSAC)*, pp. 373–382, 2011.
46. D. Wael, A. Shosha, and S. G. Sayed, “Malicious VBScript detection algorithm based on data-mining techniques,” in *2017 Intl Conf on Advanced Control Circuits Systems (ACCS) Systems & 2017 Intl Conf on New Paradigms in Electronics & Information Technology (PEIT)*, pp. 112–116, 2017.
47. A. Shah, “Malicious JavaScript detection using statistical language model,” 2016.
48. K. Schütt, M. Kloft, A. Bikadorov, and K. Rieck, “Early detection of malicious behavior in JavaScript code,” in *Proceedings of the 5th ACM Workshop on Security and Artificial Intelligence (SAI)*, pp. 15–24, 2012.
49. J. W. Stokes, R. Agrawal, and G. McDonald, “Neural classification of malicious scripts: A study with JavaScript and VBScript,” arXiv preprint arXiv:1805.05603, 2018.
50. Y. Wang, W.-d. Cai, and P.-c. Wei, “A deep learning approach for detecting malicious JavaScript code,” *Security and Communication Networks*, vol. 9, no. 11, pp. 1520–1534, 2016.
51. E. Raff, J. Sylvester, and C. Nicholas, “Learning the PE header, malware detection with minimal domain knowledge,” in *Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (AISec)*, pp. 121–132, 2017.

---

### 附录 - 实现细节

所有实验均在Azure托管的数据科学虚拟机上进行，该虚拟机配置为56 GB CPU内存（6个vCPU）和12 GB GPU内存（单核）。我们使用TensorFlow作为后端。使用Gensim构建嵌入层每次迭代耗时不到一个小时（我们进行了15次迭代，总执行时间为13小时37分钟）。CNN-RNN模型的训练时间少于7小时，Token-Char模型的训练时间为5小时，而CNN模型的训练时间为1小时。因此，在生产环境中，模型可以每天完全训练一次。我们的深度学习模型使用Keras实现。

对于深度学习模型，我们使用二元交叉熵作为损失函数，并采用Adam优化器，容差为10^-4。数据以512大小的迷你批次处理，最大迭代次数为30次，因为在大多数情况下，模型在30次迭代之前就已经收敛。实例权重与类别比例成正比。对于传统的机器学习训练，我们使用SGD优化器，对数损失和L2正则化。在100次迭代后或当损失变化小于10^-4时停止训练。架构超参数是手动选择的，基于平均TPR（跨折）的最佳经验结果，使用FPR低于10^-3的最大阈值。

#### A. 卷积神经网络 (CNN)

在嵌入层之上，我们使用了具有128个滤波器和3个内核大小的卷积层。接着是一个全局最大池化层，用于降低维度，然后是一个Dropout层和一个具有Sigmoid激活函数的全连接层。

```python
model = Sequential()
model.add(Embedding(32))
model.add(Conv1D(128, kernel_size=3, padding='valid', activation='relu', strides=1))
model.add(GlobalMaxPooling1D())
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))
```

#### B. 卷积-循环神经网络 (CNN-RNN)

我们在卷积层之上使用了一个LSTM层。卷积层有128个滤波器和3个内核大小。使用最大池化层，池大小和步长均为3，以降低维度，随后是一个双向LSTM层，输出大小为32，最后是一个具有Sigmoid激活函数的全连接层作为输出。

```python
model = Sequential()
model.add(Embedding(32))
model.add(Conv1D(128, kernel_size=3, padding='valid', activation='relu', strides=1))
model.add(MaxPooling1D(pool_size=3, strides=3))
model.add(Bidirectional(LSTM(32, dropout=0.5, recurrent_dropout=0.02)))
model.add(Dense(1, activation='sigmoid'))
```

#### C. Token-Char 模型

我们在两个卷积层的输出拼接之上使用了一个LSTM层——一个在token级别的输入之上，另一个在字符级别的输入之上。注意，在字符级别的情况下，我们在卷积层之上使用了一个全局最大池化层，结果是一个长度为64的张量。为了将其与token级别卷积层的最大池化输出拼接，我们选择了先复制这个张量，使其与后者具有相同的长度。在这两种情况下，卷积层都有64个滤波器和3个内核大小。对于token级别的输入，使用了池大小和步长均为3的最大池化层。拼接后，我们使用了一个输出大小为32的双向LSTM层和一个具有Sigmoid激活函数的全连接层作为输出。

```python
# TOKEN
token_input = Input(shape=(1000,), dtype='float')
token_embedding = GetEmbeddingLayer()(token_input)
token_conv = Conv1D(64, kernel_size=3, strides=1, padding='valid', activation='relu')(token_embedding)
token_pool = MaxPooling1D(pool_size=3, strides=3)(token_conv)
token_drop = Dropout(.5)(token_pool)

# CHAR
char_input = Input(shape=(1000,), dtype='float')
char_encoding = OneHotWithCaseBit(max_len)(char_input)
char_conv = Conv1D(64, kernel_size=3, strides=1, padding='valid', activation='relu')(char_encoding)
char_pool = GlobalMaxPooling1D()(char_conv)
char_drop = Dropout(.5)(char_pool)
char_repeated = RepeatVector(token_drop.get_shape()[1].value)(char_drop)

# Merge
merged = concatenate([token_drop, char_repeated])
lstm = Bidirectional(LSTM(32, dropout=0.3, recurrent_dropout=0.01))(merged)
output = Dense(1, activation="sigmoid")(lstm)
```

#### D. 词嵌入 (Tokens Embedding)

我们使用Gensim构建词嵌入。同时使用了Word2Vec和FastText，训练算法为CBOW。使用的参数如下：
- 最小词长度为2，最大为50。
- 忽略总频率低于10的所有词。
- 使用5个噪声词进行负采样。
- 进行15次迭代。
- 嵌入空间大小为32。
- 窗口大小为4（窗口是当前词和预测词之间的最大距离）。

参考链接：
- [Gensim](https://radimrehurek.com/gensim/)
- [Keras](https://keras.io/)