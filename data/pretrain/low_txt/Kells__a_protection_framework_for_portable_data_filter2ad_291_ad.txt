### Table 2: Kells Performance Characteristics – Average Throughput over Bulk Read and Write Operations

| Verification | Run (secs) | Read Throughput (MB/sec) | Overhead | Run (secs) | Write Throughput (MB/sec) | Overhead |
|--------------|------------|--------------------------|----------|------------|---------------------------|----------|
| No Verification | 36.1376 | 14.196 | N/A | 35.4375 | 5.6437 | N/A |
| 1 second | 36.5768 | 14.025 | 1.22% | 36.4218 | 5.4912 | 2.78% |
| 2 seconds | 36.6149 | 14.011 | 1.32% | 35.9895 | 5.5572 | 1.56% |
| 5 seconds | 36.3143 | 14.127 | 0.49% | 35.7969 | 5.5871 | 1.01% |
| 10 seconds | 36.2113 | 14.167 | 0.20% | 35.7353 | 5.5967 | 0.84% |

### Definitions

**GoodState(H, (t, treq, (l, n)), (tatt, sig))**:
- **Fresh(t, treq, tatt)**: Ensures the attestation is recent.
- **v = Verify((tatt, sig), AIK(H))**: Verifies the attestation signature using the AIK of the host.
- **Match(v, criteria)**: Ensures the verification result matches the specified criteria.

**Fresh (t, treq, tatt)**:
- **(tatt < treq ∧ treq − tatt < ∆t)**: The attestation time is within the allowed time window.
- **(treq < tatt ∧ ¬Reset(H) on [t, ρ])**: The attestation time is after the request time, and no reset has occurred in the interval.

### Experimental Setup

The experiments were conducted using an OMAP3530 processor, which features a 600 MHz ARM Cortex-A8 core, 128 MB of RAM, and 128 MB of NAND flash memory. An SD card interface provides additional storage, and the board supports a USB 2.0 On-the-Go interface for device-mode operation. The device runs an embedded Linux Angstrom distribution with a modified 2.6.28 kernel. The OMAP-3 processor's maximum power draw is approximately 750 mW, while a USB 2.0 interface can supply up to 500 mA at 5 V, or 2.5 W. The recently introduced USB 3.0 protocol can supply up to 900 mA at 5 V.

### Experiment 1: Read Operations

Our first set of experiments aimed to determine the overhead of read operations. Each test involved reading a single 517 MB file, the size of a large video, from the Kells device. We varied the security parameter ∆t (the periodicity of the host integrity re-validation) and created a baseline by performing the read test with an unmodified DevKit 8000 USB device and Linux kernel. All statistics are based on an average of 5 runs of each test.

As shown in Table 2, the read operation performance is largely unaffected by the validation process. This is because the host preemptively creates validation quotes and delivers them to the device just before a previous attestation becomes stale. Thus, the validation process is mostly hidden by normal read operations. However, performance degrades slightly as the validation process occurs more frequently. At the smallest security parameter supportable by the TPM hardware (∆t = 1 second), throughput is reduced by only 1.2%, and as little as 0.2% at 10 seconds. This overhead is primarily due to the overheads associated with receiving and validating the integrity proofs (which can be as large as 100 KB).

### Experiment 2: Write Operations

The second set of tests characterized write operations. We performed the same tests as in the read experiments, but with a 200 MB file. Write operations are generally slower on flash devices due to the underlying memory materials and structure. Similar to read operations, the write operations were largely unaffected by the presence of host validation, leading to a less than 3% overhead at ∆t = 1 second and just under 1% at 10 seconds.

Note that the throughputs observed in these experiments are substantially lower than those commonly provided by USB 2.0 devices. USB 2.0 advertises a maximal throughput of 480 Mbps, with recent flash drives advertising up to 30 MB/sec. All tests were performed on our proof-of-concept implementation, and the results are primarily meant to show that delays are acceptable. In a production version, a further optimized driver may greatly reduce the observed overheads. Given the limited throughput reduction observed in the test environment, we reasonably expect that the overheads would be negligible in production systems.

### Related Work

The need to access storage from portable devices and the associated security challenges have been well-documented. SoulPad [4] demonstrated that the increasing capacity of portable storage devices allows them to carry full computing stacks that require only a platform to execute on. DeviceSniffer [35] considered a portable USB device that allowed a kiosk to boot, where the software on the drive provides a root of trust for the system. Additional programs loaded on the host are dynamically verified by the device through comparison with an on-board measurement list. This architecture did not use trusted hardware and is thus susceptible to attacks at the BIOS and hardware levels. The iTurtle [17] proposed using a portable device to attest the state of a system through a USB interface, suggesting that load-time attestations of the platform were the best approach for verification. This work was exploratory and postulated questions rather than providing concrete solutions.

Other research has explored using mobile devices to ensure the security of the underlying platform, such as using a mobile phone as an authenticator [10]. Honeywell’s Project Guardian and the Scomp system provided a secure front-end processor for Multics [8]. SIDEARM was a hardware processor that ran on the LOCK kernel, establishing a separate security enforcement point from the rest of the system [31]. The Security Pipeline Interface [12] and other initiatives like the Dyad processor [40] and the IBM 4758 coprocessor [7] provided secure boot mechanisms. Secure boot was also considered by Arbaugh et al., whose AEGIS system allows for system startup in the face of integrity failure [6].

Numerous proposals have considered how to attest system state. SWATT [27] attests an embedded device by verifying its memory through pseudorandom traversal and checksum computation. Recent work has shown that SWATT may be susceptible to return-oriented rootkits [5], but this work itself is subject to assumptions about SWATT that may not be valid. Pioneer [26] enables software-based attestation through verifiable code execution, reliant on knowledge of the verified platform’s exact hardware configuration. A study of Pioneer showed that it requires a very long execution time to find malicious computation as CPU speeds increase [9]. Software genuinity [14] proposed relying on self-checksumming of code to determine whether it was running on a physical platform or inside a simulator, but Shankar et al. showed problems with this approach [29].

Augmenting storage systems to provide security has been a topic of sustained interest. Initially, this involved network-attached secure disks (NASD) [11], where metadata servers issue capabilities to disks augmented with processors. These capabilities form the basis for access control, requiring trust in servers external to the disk. Further research included self-securing storage [34], which, along with the NASD work, considered object-based storage rather than the block-based approach used in Kells. Pennington et al. [21] considered disk-based intrusion detection, requiring semantically-aware disks for deployment at the disk level.

### Conclusion

In this paper, we presented Kells, a portable storage device that validates host integrity before allowing read or write access to its contents. Access to trusted partitions is predicated on the host providing ongoing attestations of its good integrity state. Our prototype demonstrates that the operational overhead is minimal, with a reduction in throughput of 1.2% for reads and 2.8% for writes given a one-second periodic runtime attestation. Future work will include a detailed treatment of how policy may be enforced in an automated way between trusted and untrusted storage partitions, and further interactions with the OS to support and preserve properties such as data provenance and control of information flow.

### References

[1] IronKey. http://www.ironkey.com, 2009.
[2] K. Butler, S. McLaughlin, T. Moyer, J. Schiffman, P. McDaniel, and T. Jaeger. Firma: Disk-Based Foundations for Trusted Operating Systems. Technical Report NAS-TR-0114-2009, Penn State Univ., Apr. 2009.
[3] K. R. B. Butler, S. McLaughlin, and P. D. McDaniel. Rootkit-Resistant Disks. In ACM CCS, Oct. 2008.
[4] R. Cáceres, C. Carter, C. Narayanaswami, and M. Raghunath. Reincarnating PCs with portable SoulPads. In ACM MobiSys, 2005.
[5] C. Castelluccia, A. Francillon, D. Perito, and C. Soriente. On the difficulty of software-based attestation of embedded devices. In ACM CCS, Nov. 2008.
[6] A. Datta, J. Franklin, D. Garg, and D. Kaynar. A Logic of Secure Systems and its Application to Trusted Computing. In IEEE Symp. Sec. & Priv., May 2009.
[7] J. G. Dyer, M. Lindermann, R. Perez, et al. Building the IBM 4758 Secure Coprocessor. IEEE Computer, 39(10):57–66, Oct. 2001.
[8] L. J. Fraim. Scomp: A solution to the multilevel security problem. IEEE Computer, 16(7):26–34, July 1983.
[9] R. Gardner, S. Garera, and A. D. Rubin. On the difficulty of validating voting machine software with software. In USENIX EVT, Aug. 2007.
[10] S. Garriss, R. Cáceres, S. Berger, R. Sailer, L. van Doorn, and X. Zhang. Trustworthy and personalized computing on public kiosks. In ACM MobiSys, June 2008.
[11] G. A. Gibson, D. F. Nagle, K. Amiri, et al. A Cost-Effective, High-Bandwidth Storage Architecture. In ASPLOS, 1998.
[12] L. J. Hoffman and R. J. Davis. Security Pipeline Interface (SPI). In ACSAC, Dec. 1990.
[13] B. Kauer. OSLO: Improving the Security of Trusted Computing. In Proc. USENIX Security Symp., Aug. 2007.
[14] R. Kennell and L. H. Jamieson. Establishing the Genuineness of Remote Computer Systems. In Proc. USENIX Security Symp., Aug. 2003.
[15] Kingston Technology. DataTraveler 300: World’s first 256 GB Flash drive. http://www.kingston.com/ukroot/flash/dt300.asp, July 2009.
[16] C. Lomax. Security tightened as secretary blamed for patient data loss. Telegraph & Argus, 4 June 2009.
[17] J. M. McCune, A. Perrig, A. Seshadri, and L. van Doorn. Turtles all the way down: Research challenges in user-based attestation. In USENIX HotSec, Aug. 2007.
[18] Microsoft. BitLocker and BitLocker to Go. http://technet.microsoft.com/en-us/windows/dd408739.aspx, Jan. 2009.
[19] T. Moyer, K. Butler, J. Schiffman, et al. Scalable Web Content.
[20] B. Parno. Bootstrapping trust in a "trusted" platform. In USENIX Attestation. In ACSAC, 2009. HotSec, Aug. 2008.
[21] A. G. Pennington, J. D. Strunk, J. L. Griffin, et al. Storage-based Intrusion Detection: Watching storage activity for suspicious behavior. In Proc. USENIX Security, 2003.
[22] P. Porras, H. Saidi, and V. Yegneswaran. An Analysis of Conficker’s Logic and Rendezvous Points. Technical report, SRI Computer Science Lab, Mar. 2009.
[23] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn. Design and Implementation of a TCG-based Integrity Measurement Architecture. In Proc. USENIX Security, Aug. 2004.
[24] SanDisk. SanDisk Cruzer Enterprise. http://www.sandisk.com/business-solutions/enterprise, 2009.
[25] Seagate. Self-Encrypting Hard Disk Drives in the Data Center. Technology Paper TP583.1-0711US, Nov. 2007.
[26] A. Seshadri, M. Luk, E. Shi, et al. Pioneer: verifying code integrity and enforcing untampered code execution on legacy systems. In ACM SOSP, 2005.
[27] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla. SWATT: SoftWare-based ATTestation for Embedded Devices. In IEEE Symp. Sec. & Priv., May 2004.
[28] N. Shachtman. Under Worm Assault, Military Bans Disks, USB Drives. Wired, Nov. 2008.
[29] U. Shankar, M. Chew, and J. D. Tygar. Side Effects are Not Sufficient to Authenticate Software. In Proc. USENIX Security, 2004.
[30] M. Sivathanu, V. Prabhakarn, F. I. Popovici, et al. Semantically-Smart Disk Systems. In USENIX FAST, 2003.
[31] R. E. Smith. Cost profile of a highly assured, secure operating system. ACM Trans. Inf. Syst. Secur., 4(1):72–101, 2001.
[32] SRN Microsystems. Trojan.adware.win32.agent.bz. http://www.srnmicro.com/virusinfo/trj10368.htm, 2009.
[33] L. St. Clair, J. Schiffman, T. Jaeger, and P. McDaniel. Establishing and Sustaining System Integrity via Root of Trust Installation. In ACSAC, 2007.
[34] J. Strunk, G. Goodson, M. Scheinholtz, et al. Self-Securing Storage: Protecting Data in Compromised Systems. In USENIX OSDI, 2000.
[35] A. Surie, A. Perrig, M. Satyanarayanan, and D. J. Farber. Rapid trust establishment for pervasive personal computing. IEEE Pervasive Computing, 6(4):24–30, Oct.-Dec. 2007.
[36] TCG. TPM Main: Part 1 - Design Principles. Specification Version 1.2, Level 2 Revision 103. TCG, July 2007.
[37] TCG. TCG Storage Security Subsystem Class: Opal. Specification Version 1.0, Revision 1.0. Trusted Computing Group, Jan. 2009.
[38] T. Weigold, T. Kramp, R. Hermann, et al. The Zurich Trusted Information Channel – An Efficient Defence against Man-in-the-Middle and Malicious Software Attacks. In Proc. TRUST, Villach, Austria, Mar. 2008.
[39] R. Wojtczuk and J. Rutkowska. Attacking Intel Trusted Execution Technology. In Proc. BlackHat Technical Security Conf., Feb. 2009.
[40] B. Yee and J. D. Tygar. Secure Coprocessors in Electronic Commerce Applications. In Proc. USENIX Wrkshp. Electronic Commerce, 1995.