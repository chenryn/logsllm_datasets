### Campaign Network Information Breakdown

**Table 4: Breakdown of Coerced Unique Network Information by Category and Protocol for March 15th**

| Category | IP | Never Blacklisted | Total Count |
|----------|----|-------------------|-------------|
| In Campaign | 3  | 15                | 669         |
| IP        | 10 | 697               | 1           |
| IP        | 6  | 3381              | 3395        |

The additional network information generated by our games provides a more comprehensive view of Command and Control (C&C) communication, thereby making the relationships between malware samples clearer.

### Graph Representation of Malware Samples

Consider a graph \( K \) where the vertices represent malware samples for a given day in our long-term experiment. Edges between vertices indicate shared network information. For instance, if two malware samples connect to the same domain name \( d \), an edge is drawn between them in graph \( K \). As we uncover more information through gameplay, additional edges are added to \( K \). If these new edges form strongly related connections between malware samples, the number of components in graph \( K \) should decrease. 

**Figure 5** shows that for Gdnsw, there is always a reduction in the number of components in the game graph compared to the graph under Gnull. However, Gtcpw exhibited no change in the graph from Gnull.

### Domain Name Classification Using Notos

We used Notos [2] to evaluate the usefulness of the network information. Notos classifies domain names as suspicious, unknown, or whitelisted, along with providing a confidence score. Notos was trained using four weeks of passive DNS data from six ISP-based DNS recursive sensors across North America, using the top 2,000 Alexa 2LD domain names and the same blacklists as this study.

Out of the 161,000 unique domain names contacted during our long-term study, a simple random sample of 15,050 was run through Notos. Over 76% of these domain names were flagged as suspicious (see Table 5). The whitelisted domain names were primarily mail servers, dynamic DNS providers, and content distribution networks. Notos had high confidence in its classifications: 80% of suspicious domains and 98% of whitelisted domains had confidences above 95%.

**Table 5: Domain Name Classification Results and Mean Confidence Values from Notos**

| Classification | Count  | Percentage | Mean Confidence |
|----------------|--------|------------|-----------------|
| Suspicious     | 11,519 | 76.5%      | 0.97314         |
| Not Known      | 2      | < 0.01%    | -               |
| Whitelisted    | 3,529  | 23.4%      | 0.99565         |

### Discussion

#### Implications and Evasion Techniques

**6.1 Malware Alternative Plans**

Our results show that malware often relies on a single domain name or IP address to initiate and maintain a connection to its C&C server. Malware that does provide an alternative plan rarely uses its additional network information, as evidenced by the majority of domain names and IP addresses not appearing on public blacklists. This may explain why only 17% of samples responded to network games. More specific or dynamic games might be necessary to achieve gains in a larger proportion of samples. We are currently exploring these questions as potential future work.

In general, coerced domain names are more useful than coerced IP addresses. Domain names and abusing the DNS allow for more volatile malicious networks than an attacker could achieve with IP addresses alone. Furthermore, it is easier to vet the maliciousness of domain names, making them more attractive to security practitioners.

**6.2 Evasion Techniques**

Attackers are constantly attempting to evade newly created defenses. Common evasion techniques include timing attacks, peer-to-peer validation of network resource connectivity, communicating with different protocols, or evading dynamic analysis entirely with excessive timeouts before performing malicious behavior. We discuss these techniques and present methods to address them.

Since our games use RFC-compliant network responses, malware cannot determine if it is being gamed at the host level and must use the network in clever ways to determine its execution environment. Dynamic malware analysis systems generally execute malware for a fixed period, usually around five minutes per sample. Malware can remain dormant until this time passes to evade detection and analysis. Prior work has addressed this limitation by finding trigger-based behaviors and generating inputs to satisfy the triggers at runtime. This limitation applies to all dynamic analysis systems and is orthogonal to the problem of increasing the network information an executing sample attempts to connect to.

Overhead incurred during user-mode packet generation could enable a clever malware author to determine if they are being gamed. As a performance improvement, GZA will only route packets relevant to the game in question. For example, when Gdnsw is being played, iptables will only route UDP packets with a port of 53 destined for a VM. If DNS packets take abnormally long while other types of packets are unaffected, this could alert a malware sample that it is being analyzed. Routing all packets through its game would apply this overhead uniformly, removing the signal.

**Peer-to-Peer (P2P) Evasion**

A malware sample can verify the results of a DNS or TCP request by asking another infected machine to perform an identical request. If a sample \( m \) cannot resolve a domain name \( d \), but fellow infected hosts can resolve \( d \) successfully, \( m \) has reason to believe it is being run under our system. Communicating this information, however, requires the network, forcing \( m \) to succumb to gameplay one way or another. By focusing on the building blocks of network communication, we force all network activity to be gamed.

To perform a DNS query, a malware sample could query an HTTP-based DNS tool, bypassing the DNS protocol entirely. It could also directly connect to a C&C using a non-gamed protocol, such as UDP. These problems can be addressed by running aggregate games and adding additional protocols. Querying an HTTP-based DNS lookup tool still requires some network activity, so running DNS and TCP games simultaneously would prevent this lookup from succeeding. If an attacker uses another protocol, such as UDP, it is easy to write a new game targeting this new behavior. As malware adapts to the presence of network games, malware analysts can keep pace with malware authors without too much effort.

### Related Work

Deception through gameplay has been discussed [31, 11, 8, 37] or implemented by hand [10], but little empirical work has been done to demonstrate its usefulness. Prior work typically focuses on improving information gain generated by honeypots [37, 8] using game theory to model interactions between an attacker and a honeypot operator. Carroll et al. focused on gains generated by having a honeypot masquerade as a normal machine, or vice-versa, and showed in which cases a Nash equilibrium can be reached. Wagener et al. similarly tried to achieve equilibrium but also played games with live intruders. The honeypot was crafted to randomly fail process spawning system calls to coerce an attacker into attempting workarounds for failing tools, hopefully leading to previously unknown tools and exploits.

Gaming the botnet C&C network redundancy mechanism, what we refer to as alternative plans, was discussed and used to improve returns generated by a spamming botnet analysis engine [18]. Anticipation games [7], an extension of attack graphs based on game theory, were designed to anticipate malicious interaction with a network and determine the most effective patching strategy for a given network. We differ from previous gameplay work in that we focus on gathering network intelligence rather than host-level information and quantify the usefulness of this network information to security practitioners.

GZA is similar but complementary to other techniques that attempt to coerce malware into revealing useful information. All systems that rely on dynamic binary analysis face the problem of code coverage, which researchers have addressed by forcing the execution of all possible branches [22, 38]. Multipath exploration provides a complete view of possible execution paths of malware but can be evaded with conditional code obfuscation [34] or made impractical due to the exponential explosion in search space. Sharif et al. describe malware emulators [33] or malware obfuscated by a randomized bytecode instruction set that would evade multipath exploration. During dynamic analysis, multipath exploration would explore the paths of all possible bytecode programs rather than the execution paths of the malware itself. Since network games do not target binary execution paths, we are resistant to this evasion technique and provide a complementary analysis method.

Furthermore, malware increasingly uses external stimuli in the form of trigger-based behaviors to determine its execution environment [32, 28, 9], prompting the use of hardware virtualization [14]. More sophisticated techniques include waiting for a specific date to occur or a particular website to be visited. Research has shown how to detect changes in malware behavior and determine the underlying cause [3, 6]. We differ from prior work in malware analysis by introducing the concept of evasion-resistant network games. By performing execution path exploration from the network instead of the host, we make it difficult for malware to detect it is being gamed or evade our games.

### Conclusion

In this paper, we designed and built a framework, GZA, to explore malware execution paths using the concept of network games. By playing network games with malware, we described the prevalence of alternative plans in malware by examining a large malware corpus of 2,191 samples and performing a long-term study over three weeks of malware samples obtained from malware feeds. Our six network games coerced samples into revealing their alternative plans and the additional network features malware used to enact those plans. We show that while alternative plans have promise to improve malware reliability, they go relatively unused in malware seen in the wild. Only 17% of samples exhibit this behavior. This new network information, however, is very useful, with approximately 95% never appearing on public blacklists. This directly improves systems that rely on network information, such as blacklist generation, domain name and IP address reputation systems, and malware clustering on network features.

### Acknowledgments

The authors gratefully acknowledge Paul Royal for providing the malware samples used in both experiments and for his advice in implementing GZA. We also thank GZA/Genius for Liquid Swords and Legend of the Liquid Sword, which were on repeat during late-night programming and editing sessions. We also thank the anonymous reviewers for their helpful comments.

### References

[1] Alexa. Top sites. http://www.alexa.com/topsites, (Retrieved) March 2011.
[2] M. Antonakakis, R. Perdisci, D. Dagon, and W. Lee. Building a dynamic reputation system for DNS. In Proceedings of the 19th USENIX Security Symposium, 2010.
[3] D. Balzarotti, M. Cova, C. Karlberger, C. Kruegel, and E. Kirda. Efficient detection of split personalities in malware. In Proceedings of the Symposium on Network and Distributed System Security, 2010.
[4] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi. EXPOSURE: Finding malicious domains using passive DNS analysis. In Proceedings of the Symposium on Network and Distributed System Security, Jan 2011.
[5] P. Biondi. Scapy. http://www.secdev.org/projects/scapy/, (Retrieved) March 2011.
[6] D. Brumley, C. Hartwig, Z. Liang, J. Newsome, D. Song, and H. Yin. Automatically identifying trigger-based behavior in malware. Botnet Detection, pages 65–88, 2008.
[7] E. Bursztein and J. C. Mitchell. Using strategy objectives for network security analysis. Information Security and Cryptology, Jan 2011.
[8] T. Carroll and D. Grosu. A game theoretic investigation of deception in network security. Security and Communication Networks, Jan 2009.
[9] X. Chen, J. Andersen, Z. M. Mao, M. Bailey, and J. Nazario. Towards an understanding of anti-virtualization and anti-debugging behavior in modern malware. In Proceedings of the International Conference on Dependable Systems and Networks DSN, 2008.
[10] B. Cheswick. An evening with berferd in which a cracker is lured, endured, and studied. In Proceedings of the USENIX Security Symposium, Jan 1990.
[22] A. Moser, C. Kruegel, and E. Kirda. Exploring multiple execution paths for malware analysis. In Proceedings of the IEEE Symposium on Security and Privacy, volume 245, 2007.
[23] netfilter team. The netfilter.org “iptables” project. http://www.netfilter.org/projects/iptables/index.html, (Retrieved) March 2011.
[24] R. Perdisci, W. Lee, and N. Feamster. Behavioral clustering of HTTP-based malware and signature generation using malicious network traces. In Proceedings of the USENIX Symposium on Networked Systems Design and Implementation, 2010.
[25] H. S. Phillip Porras and V. Yegneswaran. An analysis of Conficker’s logic and rendezvous points. http://mtc.sri.com/Conficker/, 2009.
[26] S. Project. Snort DNS/IP/URL lists. http://labs.snort.org/iplists/, 2011.
[27] T. S. Project. Spamhaus drop list. http://www.spamhaus.org/drop/drop.lasso, 2011.
[28] T. Raﬀetseder, C. Krügel, and E. Kirda. Detecting system emulators. In Information Security Conference, pages 1–18, 2007.
[29] C. Report. CIDR report bogons. http://www.cidr-report.org, 2011.
[11] F. Cohen and D. Koike. Misleading attackers with deception. In Proceedings of the 2004 IEEE Workshop on Information Assurance, Jan 2004.
[30] J. Riden. How fast-flux service networks work. http://www.honeynet.org/node/132, 2008.
[31] N. Rowe, E. Custy, and B. T. Duong. Defending cyberspace with fake honeypots. Journal of Computers, Jan 2007.
[12] A. D. Correa. Malware patrol. http://malwarepatrol.com/, 2010.
[13] T. Cymru. Bogons. http://www.cymru.com/Documents/bogon-bn-nonagg.txt, 2010.
[14] A. Dinaburg, P. Royal, M. Sharif, and W. Lee. Ether: Malware analysis via hardware virtualization extensions. In Proceedings of the 15th ACM Conference on Computer and Communications Security, Jan 2008.
[15] DNS-BH. Malware prevention through DNS redirection (black hole DNS sinkhole). http://www.malwaredomains.com, 2010.
[16] dnsbl.abuse.ch. dnsbl.abuse.ch. http://dnsbl.abuse.ch, 2010.
[32] J. Rutkowska. Red pill... or how to detect VMM using (almost) one CPU instruction. http://invisiblethings.org/papers/redpill.html, 2004.
[33] M. Sharif, A. Lanzi, J. Griffin, and W. Lee. Rotalume: A tool for automatic reverse engineering of malware emulators.
[34] M. Sharif, A. Lanzi, J. Griffin, and W. Lee. Impeding malware analysis using conditional code obfuscation. In Proceedings of the Symposium on Network and Distributed System Security, Jan 2008.
[35] spyeyetracker.abuse.ch. Spyeye tracker. https://spyeyetracker.abuse.ch, 2010.
[17] dnswl. DNS whitelist - protect against false positives. http://www.dnswl.org, (Retrieved) March 2011.
[36] P.-N. Tan, M. Steinbach, and V. Kumar. Introduction to Data Mining. Addison Wesley, 2006.
[18] J. John, A. Moshchuk, S. Gribble, and A. Krishnamurthy. Studying spamming botnets using botlab. In Proceedings of the 6th USENIX Symposium on Networked Systems Design and Implementation, pages 291–306, 2009.
[19] M. D. List. Malware domain list. http://www.malwaredomainlist.com, 2010.
[20] L. Lu, V. Yegneswaran, P. Porras, and W. Lee. BLADE: an attack-agnostic approach for preventing drive-by malware infections. In Proceedings of the 17th ACM Conference on Computer and Communications Security (CCS 2010), Jan 2010.
[21] malc0de. Malc0de DNS blacklist. http://malc0de.com, 2010.
[37] G. Wagener, R. State, A. Dulaunoy, and T. Engel. Self-adaptive high interaction honeypots driven by game theory. In Proceedings of the 11th International Symposium on Stabilization, Safety, and Security of Distributed Systems, Jan 2009.
[38] J. Wilhelm and T. Chiueh. A forced sampled execution approach to kernel rootkit identification. In Proceedings of the Symposium on Recent Advances in Intrusion Detection, Jan 2007.
[39] J. Wolf. Technical details of srizbi’s domain generation algorithm. http://blog.fireeye.com/research/2008/11/technical-details-of-srizbis-domain-generation-algorithm.html, 2008.