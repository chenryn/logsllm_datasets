### Interval-of-Time Reward Variables

The interval-of-time reward variables calculated using our method are equivalent to those computed by typical discrete event simulators.

For time-averaged interval-of-time variables, we redefine the variable as:
\[ W[t, t+l] = \frac{Y[t, t+l]}{l} \]
(15)

This calculation is similar to the one given in Section II but uses the method for calculating interval-of-time variables. 

**Proof:**
Given Equation (14), Equation (15) is equivalent to the definition presented in Section II. From Equation (14), we know that \( Y[t, t+l] = \theta[t, t+l] \). Substituting \( \theta[t, t+l] \) for \( Y[t, t+l] \) in Equation (15) yields Equation (3).

### Method for Identifying Dependence Relationships

In this section, we detail a method to identify all dependence relationships in a model \( M \) using a Markov Decision Graph (MDG), \( GM \). We then describe how to identify rare faults in the model. Using the set of identified faults \( ER \) and the MDG, we show how to expand the set \( ER \) to include mitigation, repair, and propagation actions. We then demonstrate how to use \( ER \) with \( GM \) to form a set of decomposed submodels \( \Xi \), which we solve using Algorithm 2.

### Discussion

We applied our methods to a one-petabyte deduplicated storage system to assess the impact of deduplication on reliability. We modeled our system under three different RAID configurations: 8+1p, 8+2p, and 8+3p, corresponding to one, two, and three parity disks, respectively. The application of our framework allowed us to automatically generate detailed models of our storage system from models of individual components within the system. Models of deduplication relationships were then automatically generated from empirical data. We compared the efficiency of our hybrid, dependence-based, discrete event simulator to an unmodified discrete event simulator and achieved a significant speed-up, as shown in Table I.

In our previous work [4], we conducted a similar study of large-scale deduplicated storage systems, showing only a decrease in reliability due to the characteristics of the data stored in the studied system. We predicted that other systems might have different results given different deduplication relationships. In the system studied in this paper, we confirm the predictions made in [4], reaffirming the importance of a detailed understanding of the underlying relationships in a deduplicated storage system.

As shown in Figure 9, while the Archive and Database 1 file categories showed a decrease in reliability due to deduplication, the Code and Database 2 categories showed an increase in reliability due to a more even distribution of references. This means that no sets of files existed which contributed disproportionately to the impact from losses of deduplicated references. Similar results were observed for the impact of deduplication on corrupt data served due to Undetected Disk Errors (UDEs). Figure 10 shows the rates of corrupt data served per year for the Database 1 and Database 2 categories. For Database 1, deduplication improves reliability, whereas for Database 2, reliability degrades. Results were similar for other file categories in our modeled system.

RAID implemented as 8+2p and 8+3p proved highly fault-tolerant, with few data loss events occurring, affirming that multi-copy deduplication is unnecessary for protection against additional loss due to RAID failure in one-petabyte systems. However, such systems provide no additional protection against UDEs. For systems in which deduplication caused a decrease in reliability, keeping an additional copy for the most referenced 1% of files in each category was sufficient protection, though additional protection could be achieved (albeit with diminishing returns) by keeping additional copies for larger portions of a given category.

From these results and the results provided in [4], it is clearly important to take into account the actual deduplication characteristics of a given system when applying multi-copy deduplication strategies. With our framework, it is possible to model and develop per-category multi-copy deduplication schemes to achieve the desired level of reliability while maintaining a high level of storage efficiency. System designers need only submit to our framework the necessary component-level models, RAID level, and the size of the system, along with empirical data about the footprint of the deduplicated data they wish to store. Each category in the system can then be analyzed at varying levels of multi-copy coverage. Users can enter a desired level of reliability for their system, and using our framework, determine a level of multi-copy coverage which meets their goals while preserving more storage efficiency than the naive approach of assigning the same multi-copy scheme to the entire system.

### Conclusions

This paper presents a framework for the efficient solution of reliability models of large-scale storage systems utilizing deduplication. Our framework generates models from component-based templates, adds deduplication relationships derived from empirical data, and identifies dependence relationships in the generated model. These dependence relationships are used to improve the efficiency of model solution while leaving the reward measures unaffected. We demonstrate our method by solving a large-scale storage system and achieving significant speed-ups of roughly 20x when compared to unmodified discrete-event simulation. Our results show the importance of detailed models of deduplication based on file categories by showing some categories where deduplication improves reliability and some where it decreases reliability. We show that even for a similar type of category, the impact of deduplication may not be the same.

Our results emphasize the need to generate detailed models of deduplicated systems when making design decisions. Previous work which suggested broad application of multi-copy deduplication, while effective for improving reliability, does not take into account the diminishing returns realized when larger percentages of the deduplicated storage system store multiple copies of each referenced chunk. Detailed analysis has proven difficult in the past due to the complexities involved with solving large models containing rare events, but the framework we present in this paper significantly reduces the time needed to conduct such studies.

The limit of increased reliability for systems employing these methods is the undeduplicated portions of files. Given that most storage systems are overprovisioned or include unused hot spares to allow RAID repair, we propose that this underutilized space might be overbooked to keep additional copies of undeduplicated portions of important files, further improving reliability.

### References

[1] P. Lyman, H. R. Searingen, J. Pal, et al., "How much information?" [Online]. Available: http://www.sims.berkeley.edu/research/projects/how-much-info/

[2] J. F. Gantz, C. Chute, A. Manfrediz, S. Minton, D. Reinsel, W. Schlichting, and A. Toncheva, "The diverse and exploding digital universe: An updated forecast of worldwide information growth through 2011," White Paper, IDC, March 2008.

[3] J. F. Gantz and D. Reinsel, "Extracting value from chaos," White Paper, IDC, June 2011.

[4] E. W. Rozier, W. H. Sanders, P. Zhou, N. Mandagere, S. M. Uttamchandani, and M. L. Yakushev, "Modeling the fault tolerance consequences of deduplication," in Reliable Distributed Systems (SRDS), 2011 30th IEEE Symposium on, Oct. 2011, pp. 75–84.

[5] B. Zhu, K. Li, and H. Patterson, "Avoiding the disk bottleneck in the data domain deduplication file system," in USENIX FAST, 2008, pp. 1–14.

[6] C. Ungureanu, B. Atkin, A. Aranya, S. Gokhale, S. Rago, G. Calkowski, C. Dubnicki, and A. Bohra, "HydraFS: A high-throughput file system for the HYDRAstor content-addressable storage system," in FAST, 2010, pp. 225–238.

[7] D. Bhagwat, K. Pollack, D. D. E. Long, T. Schwarz, E. L. Miller, and J.-F. Pris, "Providing high reliability in a minimum redundancy archival storage system," in IEEE MASCOTS, 2006, pp. 413–421.

[8] L. L. You, K. T. Pollack, and D. D. E. Long, "Deep Store: An archival storage system architecture," in ICDE, IEEE, 2005, pp. 804–815.

[9] L. Freeman, "How safe is deduplication?" NetApp Tech. Rep., 2008. [Online]. Available: http://media.netapp.com/documents/tot0608.pdf

[10] B. Schroeder and G. A. Gibson, "Disk failures in the real world: What does an MTTF of 1,000,000 hours mean to you?" in FAST, 2007, p. 1.

[11] L. N. Bairavasundaram, G. R. Goodson, S. Pasupathy, and J. Schindler, "An analysis of latent sector errors in disk drives," SIGMETRICS 35, no. 1, pp. 289–300, 2007.

[12] B. Schroeder, S. Damouras, and P. Gill, "Understanding latent sector errors and how to protect against them," in FAST, 2010, pp. 71–84.

[13] A. Krioukov, L. N. Bairavasundaram, G. R. Goodson, K. Srinivasan, R. Thelen, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dussea, "Parity lost and parity regained," in FAST, USENIX, 2008, pp. 1–15.

[14] J. L. Hafner, V. Deenadhayalan, W. Belluomini, and K. Rao, "Undetected disk errors in RAID arrays," IBM J Research and Development 52, no. 4, pp. 413–425, 2008.

[15] E. W. D. Rozier, W. Belluomini, V. Deenadhayalan, J. Hafner, K. K. Rao, and P. Zhou, "Evaluating the impact of undetected disk errors in RAID systems," in DSN, 2009, pp. 83–92.

[16] W. D. Oball II, Measure-Adaptive State-Space Construction Methods. U Arizona, 1998.

[17] W. Sanders and J. Meyer, "A unified approach for specifying measures of performance, dependability, and performability," in DCCA 4. Springer, 1991, pp. 215–237.

[18] R. A. Howard, Dynamic Probabilistic Systems. Vol II: Semi-Markov and Decision Processes. New York: Wiley, 1971.

[19] J. F. Meyer, "On evaluating the performability of degradable computing systems," IEEE TC 29, pp. 720–731, 1980.

[20] W. H. Sanders and J. F. Meyer, "A unified approach to specifying measures of performance, dependability, and performability," Dependable Computing for Critical Applications, vol. 4, pp. 215–237, 1991.

[21] M. O. Rabin, "Fingerprinting by random polynomials," Tech. Rep., 1981.

[22] A. Z. Broder, "Identifying and filtering near-duplicate documents," in CPM. Springer, 2000, pp. 1–10.

[23] L. N. Bairavasundaram, G. R. Goodson, B. Schroeder, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dussea, "An analysis of data corruption in the storage stack," in FAST, USENIX, 2008, pp. 1–16.

[24] D. A. Patterson, G. A. Gibson, and R. H. Katz, "A case for Redundant Arrays of Inexpensive Disks (RAID)," EECS Department, UC Berkeley, Tech. Rep. UCB/CSD-87-391, 1987. [Online]. Available: http://www.eecs.berkeley.edu/Pubs/TechRpts/1987/5853.html

[25] G. Ciardo and K. S. Trivedi, "A decomposition approach for stochastic reward net models," Performance Eval. 18, no. 1, pp. 37–59, 1993.

[26] J. Bucklew and R. Radeke, "On the Monte Carlo simulation of digital communication systems in Gaussian noise," IEEE Trans. Comm. 51, no. 2, pp. 267–274, 2003.