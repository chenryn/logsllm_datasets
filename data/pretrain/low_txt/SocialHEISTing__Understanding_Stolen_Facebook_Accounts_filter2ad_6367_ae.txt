### 5.3 Limitations and Future Work

In this section, we highlight some of the limitations of our study and suggest potential future directions.

#### Research Hypotheses and Statistical Tests
Our study formulates several research hypotheses and employs statistical tests to validate them. However, it is important to note that our experiment focuses specifically on the threat of account credentials being leaked on paste sites, which may not be representative of all types of account compromises. We have discussed the threats to the validity of our work in Section 3.4.

#### Data Freshness
The data used in this study was collected in 2018, and while it may not be as current as possible, to the best of our knowledge, this is the first study to explore demographic risk factors in Facebook accounts. Although the specific campaigns conducted by attackers may have evolved since then, their underlying motives and the demographic risk factors identified are likely to remain relevant.

#### Realism of Test Accounts
Prior to the experiments, we populated the test accounts with publicly available data, but did not include any private messages. In contrast, real-world Facebook accounts often contain private messages, which could influence the perception of criminals when they visit these accounts. In future work, we plan to incorporate private messages to better approximate real user behavior.

#### Interaction with Attackers
During the course of the experiments, some honey accounts received private messages and timeline posts from criminals. As per our IRB protocol, we did not respond to any of these messages. This lack of interaction may have affected the perception of the criminals, as real users would typically respond to such activity. Additionally, this limited our visibility into the attackers' intentions, as we were unable to observe any follow-up actions. In future studies, it would be interesting to incorporate chatbots that can auto-respond to messages, thereby deepening the impression of "lived-in" accounts. However, this approach also raises ethical considerations that need to be carefully addressed.

#### Additional Demographic Attributes
In this study, we focused on two demographic attributes: age range and gender. Future research could investigate additional attributes, such as occupation, political leanings, and religious beliefs. These attributes may provide further insights into criminal activity in stolen accounts and help the research community address other issues, such as cyberbullying and targeted attacks. To better understand chain attacks, we also propose storing authentication tokens for other services within private messages in honey accounts, to observe how criminals might misuse them.

### 6. Conclusion

We presented the first large-scale honeypot system for monitoring compromised Facebook accounts. We created over 1,000 realistic Facebook accounts, incorporated demographic attributes, and observed attacker behavior over a six-month period. Our findings show that these demographic attributes significantly influenced the actions of attackers in the accounts. These insights will help the research community gain a deeper understanding of compromised online accounts, leading to the development of more effective security systems.

### Acknowledgments

We would like to thank the anonymous reviewers for their valuable comments. This work was supported by a Facebook Secure-the-Internet research gift. We also extend our gratitude to Mark Atherton for his assistance during the early stages of this project. This research was partially funded by the National Science Foundation (NSF) under Grant 1942610. Most of the work was completed while Jeremiah Onaolapo was at University College London (UCL) with the support of the Petroleum Technology Development Fund (PTDF) of Nigeria.

### References

[1] Accessing & downloading your information. https://www.facebook.com/help/1701730696756992. Accessed: 2020-09-18.
[2] The best free stock photos & videos shared by talented creators. https://www.pexels.com/. Accessed: 2020-09-18.
[3] Developer docs. https://developer.twitter.com/en/docs. Accessed: 2020-09-18.
[4] Find your inspiration. https://www.flickr.com/. Accessed: 2020-09-18.
[5] Googletrans: Free and unlimited Google translate API for Python. https://py-googletrans.readthedocs.io/en/latest. Accessed: 2020-09-18.
[6] Information (on Facebook test accounts). https://www.facebook.com/whitehat/info/. Accessed: 2020-09-18.
[7] The Internet’s source of freely-usable images. https://unsplash.com/. Accessed: 2020-09-18.
[8] IP geolocation API. https://ip-api.com. Accessed: 2020-09-18.
[9] nltk.stem package. https://www.nltk.org/api/nltk.stem.html. Accessed: 2020-09-18.
[10] nltk.tokenize package. https://www.nltk.org/api/nltk.tokenize.html. Accessed: 2020-09-18.
[11] Random user generator. https://randomuser.me/. Accessed: 2020-09-18.
[12] Stunning free images & royalty free stock. https://pixabay.com/. Accessed: 2020-09-18.
[13] D. Alvarez-Melis and M. Saveski. Topic modeling in Twitter: Aggregating tweets by conversations. In AAAI Conference on Weblogs and Social Media (ICWSM), 2016.
[14] T. Barron and N. Nikiforakis. Picky attackers: Quantifying the role of system properties on intruder behavior. In Annual Computer Security Applications Conference (ACSAC), 2017.
[15] H. Binsalleeh, T. Ormerod, A. Boukhtouta, P. Sinha, A. Youssef, M. Debbabi, and L. Wang. On the analysis of the Zeus botnet crimeware toolkit. In Privacy, Security and Trust (PST), 2010.
[16] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu. The socialbot network: When bots socialize for fame and money. In Annual Computer Security Applications Conference (ACSAC), 2011.
[17] A. M. Bossler and T. J. Holt. On-line activities, guardianship, and malware infection: An examination of routine activities theory. International Journal of Cyber Criminology, 3(1), 2009.
[18] E. Bursztein, B. Benko, D. Margolis, T. Pietraszek, A. Archer, A. Aquino, A. Pitsillidis, and S. Savage. Handcrafted fraud and extortion: Manual account hijacking in the wild. In ACM Internet Measurement Conference (IMC), 2014.
[19] P. Cao, Y. Wu, S. S. Banerjee, J. Azoff, A. Withers, Z. T. Kalbarczyk, and R. K. Iyer. CAUDIT: Continuous auditing of SSH servers to mitigate brute-force attacks. In USENIX Symposium on Networked Systems Design and Implementation (NSDI), 2019.
[20] J. DeBlasio, S. Savage, G. M. Voelker, and A. C. Snoeren. Tripwire: Inferring Internet site compromise. In ACM Internet Measurement Conference (IMC), 2017.
[21] R. Dhamija, J. D. Tygar, and M. Hearst. Why phishing works. In ACM Conference on Human Factors in Computing Systems (CHI), 2006.
[22] M. Duggan. Online harassment 2017. 2017.
[23] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna. COMPA: Detecting compromised accounts on social networks. In Symposium on Network and Distributed System Security (NDSS), 2013.
[24] S. Egelman and E. Peer. The myth of the average user: Improving privacy and security systems through individualization. In Proceedings of the 2015 New Security Paradigms Workshop, pages 16–28, 2015.
[25] R. A. Fisher. On the interpretation of χ² from contingency tables, and the calculation of p. Journal of the Royal Statistical Society, 85(1):87–94, 1922.
[26] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao. Detecting and characterizing social spam campaigns. In ACM Internet Measurement Conference (IMC), 2010.
[27] W. G. Halfond, J. Viegas, and A. Orso. A classification of SQL-injection attacks and countermeasures. In IEEE International Symposium on Secure Software Engineering, 2006.
[28] X. Han, N. Kheir, and D. Balzarotti. PhishEye: Live monitoring of sandboxed phishing kits. In ACM Conference on Computer and Communications Security (CCS), 2016.
[29] B. Henson, B. W. Reyns, and B. S. Fisher. Does gender matter in the virtual world? Examining the effect of gender on the link between online social network activity, security, and interpersonal victimization. Security Journal, 26(4):315–330, 2013.
[30] J. Huang, G. Stringhini, and P. Yong. Quit playing games with my heart: Understanding online dating scams. In Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA), 2015.
[31] J. Isacenkova, O. Thonnard, A. Costin, D. Balzarotti, and A. Francillon. Inside the scam jungle: A closer look at 419 scam email operations. In Security and Privacy Workshops (SPW), 2013.
[32] A. Kedrowitsch, D. D. Yao, G. Wang, and K. Cameron. A first look: Using Linux containers for deceptive honeypots. In Workshop on Automated Decision Making for Active Cyber Defense, 2017.
[33] A. Kolmogorov. Sulla determinazione empirica di una lgge di distribuzione. Inst. Ital. Attuari, Giorn., 4:83–91, 1933.
[34] M. Lazarov, J. Onaolapo, and G. Stringhini. Honey sheets: What happens to leaked Google spreadsheets? In USENIX Workshop on Cyber Security Experimentation and Test (CSET), 2016.
[35] K. Lee, J. Caverlee, and S. Webb. The social honeypot project: Protecting online communities from spammers. In World Wide Web Conference (WWW), 2010.
[36] A. Lenhart, M. Ybarra, K. Zickuhr, and M. Price-Feeney. Online harassment, digital abuse, and cyberstalking in America. Data and Society Research Institute, 2016.
[37] F. L. Lévesque, J. M. Fernandez, and D. Batchelder. Age and gender as independent risk factors for malware victimisation. Electronic Visualisation and the Arts (EVA 2017), pages 1–14, 2017.
[38] F. L. Lévesque, J. Nsiempba, J. M. Fernandez, S. Chiaison, and A. Somayaji. A clinical study of risk factors related to malware infections. In ACM Conference on Computer and Communications Security (CCS), 2013.
[39] J. Leyden. Rockyou hack reveals easy-to-crack passwords. https://www.theregister.co.uk/2010/01/21/lame_passwords_exposed_by_rockyou_hack/. Accessed: 2020-09-18.
[40] M. Näsi, A. Oksanen, T. Keipi, and P. Räsänen. Cybercrime victimization among young people: a multi-nation study. Journal of Scandinavian Studies in Criminology and Crime Prevention, 16(2):203–210, 2015.
[41] D. Oliveira, H. Rocha, H. Yang, D. Ellis, S. Dommaraju, M. Muradoglu, D. Weir, A. Soliman, T. Lin, and N. Ebner. Dissecting spear phishing emails for older vs. young adults: On the interplay of weapons of influence and life domains in predicting susceptibility to phishing. In ACM Conference on Human Factors in Computing Systems (CHI), 2017.
[42] J. Onaolapo, E. Mariconti, and G. Stringhini. What happens after you are pwnd: Understanding the use of leaked webmail credentials in the wild. In ACM Internet Measurement Conference (IMC), 2016.
[43] E. M. Redmiles. “Should I Worry?” A Cross-Cultural Examination of Account Security Incident Response. In IEEE Symposium on Security and Privacy, 2019.
[44] C. Rossow, C. J. Dietrich, C. Grier, C. Kreibich, V. Paxson, N. Pohlmann, H. Bos, and M. van Steen. Prudent practices for designing malware experiments: Status quo and outlook. In IEEE Symposium on Security and Privacy, 2012.
[45] S. Sheng, M. Holbrook, P. Kumaraguru, L. F. Cranor, and J. Downs. Who falls for phish? A demographic analysis of phishing susceptibility and effectiveness of interventions. In ACM Conference on Human Factors in Computing Systems (CHI), 2010.
[46] N. Smirnov. Table for estimating the goodness of fit of empirical distributions. The Annals of Mathematical Statistics, 19(2):279–281, 1948.
[47] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert, M. Szydlowski, R. Kemmerer, C. Kruegel, and G. Vigna. Your botnet is my botnet: Analysis of a botnet takeover. In ACM Conference on Computer and Communications Security (CCS), 2009.
[48] B. Stone-Gross, T. Holz, G. Stringhini, and G. Vigna. The underground economy of spam: A botmaster’s perspective of coordinating large-scale spam campaigns. In USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET), 2011.
[49] G. Stringhini and O. Thonnard. That ain’t you: Blocking spearphishing through behavioral modelling. In Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA), 2015.
[50] G. Suarez-Tangil, M. Edwards, C. Peersman, G. Stringhini, A. Rashid, and M. Whitty. Automatically dismantling online dating fraud. arXiv preprint arXiv:1905.12593, 2019.
[51] K. Thomas, D. Akhave, M. Bailey, D. Boneh, E. Burztein, S. Consolvo, N. Dell, Z. Durumeric, P. Kelley, D. Kumar, D. McCoy, S. Meiklejohn, T. Ristenpart, and G. Stringhini. SoK: Hate, harassment, and the changing landscape of online abuse. In IEEE Symposium on Security and Privacy, 2021.
[52] K. Thomas, C. Grier, D. Song, and V. Paxson. Suspended accounts in retrospect: An analysis of Twitter spam. In ACM Internet Measurement Conference (IMC), 2011.
[53] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Paxson. Trafficking fraudulent accounts: The role of the underground market in Twitter spam and abuse. In USENIX Security Symposium, 2013.
[54] S. G. A. van de Weijer and E. R. Leukfeldt. Big five personality traits of cybercrime victims. Cyberpsychology Behav. Soc. Netw., 20(7):407–412, 2017.
[55] D. Wang, Z. Zhang, P. Wang, J. Yan, and X. Huang. Targeted online password guessing: An underestimated threat. In ACM Conference on Computer and Communications Security (CCS), 2016.
[56] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng, and B. Y. Zhao. You are how you click: Clickstream analysis for Sybil detection. In USENIX Security Symposium, 2013.
[57] S. Webb, J. Caverlee, and C. Pu. Social honeypots: Making friends with a spammer near you. In Conference on Email and Anti-Spam (CEAS), 2008.
[58] M. T. Whitty. Anatomy of the online dating romance scam. Security Journal, 28(4):443–455, 2015.
[59] M. T. Whitty. Is there a scam for everyone? Psychologically profiling cyberscam victims. European Journal on Criminal Policy and Research, pages 1–11, 2020.
[60] M. T. Whitty and T. Buchanan. The online romance scam: A serious cybercrime. CyberPsychology, Behavior, and Social Networking, 15(3):181–183, 2012.
[61] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao, and Y. Dai. Uncovering social network Sybils in the wild. ACM Transactions on Knowledge Discovery from Data (TKDD), 8(1):2:1–2:29, 2014.