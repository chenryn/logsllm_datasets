### StringHound: Improving Deobfuscation and Revealing Critical Findings

**Introduction:**
StringHound significantly outperforms state-of-the-art deobfuscation tools. We also conducted a large-scale study on the usage of string obfuscation in both benign and malicious apps, uncovering highly relevant findings.

**Key Findings:**
- **Prevalence of String Obfuscation:** Our empirical evidence shows that string obfuscation is commonly used across malware, 100,000 apps from Google’s Play Store, and various ad libraries. This contradicts previous research suggesting that string obfuscation is rarely used in practice.
- **Revealed Issues:** By reversing string obfuscation, we uncovered numerous problematic string usages, including critical internet accesses, piggy-backed permissions, insecure cryptography algorithms, hard-coded passwords, and exposed YouTube API keys.
- **Malware and Spyware:** We found not only malware concealing hidden commands and communication endpoints but also spyware-like behavior in two apps within the Top 500 set.
- **Library Contributions:** Libraries account for a significant portion of obfuscated strings in benign apps, with many findings in ad libraries revealing serious privacy issues.

**Future Work:**
We have outlined several interesting areas for future work in Section 5. Additionally, we will investigate ways to enhance StringHound’s runtime performance by incorporating library detection [4, 22, 32, 34, 57] and extraction, as well as by parallelizing the execution of slices.

**Availability:**
StringHound and all datasets used in our evaluation are freely available at: [https://github.com/stg-tud/StringHound](https://github.com/stg-tud/StringHound).

**Acknowledgments:**
This work was supported by the Hessian LOEWE initiative within the Software-Factory 4.0 project, the DFG as part of CRC 1119 CROSSING, the German Federal Ministry of Education and Research (BMBF), and the Hessen State Ministry for Higher Education, Research, and the Arts (HMWK) through their joint support of the National Research Center for Applied Cybersecurity ATHENE.

### References
[1] Alfred V Aho, Ravi Sethi, and Jeffrey D Ullman. 1986. Compilers: Principles, Techniques, and Tools. Reading: Addison Wesley Publishing Company (1986).
[2] Androidrank. Accessed: 2019-05-15. [https://www.androidrank.org/](https://www.androidrank.org/).
[3] App Brain’s Ad Networks. Accessed: 2019-05-15. [https://www.appbrain.com/stats/libraries/ad-networks](https://www.appbrain.com/stats/libraries/ad-networks).
[4] Michael Backes, Sven Bugiel, and Erik Derr. 2016. Reliable third-party library detection in Android and its security applications. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (CCS’16). ACM, 356–367.
[5] Luciano Bello and Marco Pistoia. 2018. ARES: Triggering payload of evasive Android malware. In 2018 IEEE/ACM 5th International Conference on Mobile Software Engineering and Systems (MOBILESoft’18). IEEE, 2–12.
[6] David Binkley and Keith Brian Gallagher. 1996. Program slicing. Advances in Computers 43, 1-50 (1996), 1–2.
[7] Yi Chen, Wei You, Yeonjoon Lee, Kai Chen, XiaoFeng Wang, and Wei Zou. 2017. Mass discovery of Android traffic imprints through instantiated partial execution. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS’17). ACM, 815–828.
[8] Shield4J: A Java class, shrinker Android APK obfuscator, encrypter, and merger. Accessed: 2020-02-12. [https://dzone.com/articles/shield4j-java-class-and](https://dzone.com/articles/shield4j-java-class-and).
[9] Contagio Mobile Dump. Accessed: 2019-05-15. [http://contagiominidump.blogspot.com/](http://contagiominidump.blogspot.com/).
[10] Andrea Continella, Yanick Fratantonio, Martina Lindorfer, Alessandro Puccetti, Ali Zand, Christopher Kruegel, and Giovanni Vigna. 2017. Obfuscation-Resilient Privacy Leak Detection for Mobile Apps Through Differential Analysis. In Proceedings of the 2017 Network and Distributed Systems Symposium (NDSS’17).
[11] Oracle Naming Conventions. Accessed: 2019-04-26. [https://www.oracle.com/technetwork/java/codeconventions-135099.html](https://www.oracle.com/technetwork/java/codeconventions-135099.html).
[12] DashO. Accessed: 2019-05-15. [https://www.preemptive.com/](https://www.preemptive.com/).
[13] Soteris Demetriou, Whitney Merrill, Wei Yang, Aston Zhang, and Carl A Gunter. 2016. Free for All! Assessing User Data Exposure to Advertising Libraries on Android. In Proceedings of the 2016 Annual Network and Distributed System Security Symposium (NDSS’16).
[14] Dex Oracle. Accessed: 2019-05-15. [https://github.com/CalebFenton/dex-oracle](https://github.com/CalebFenton/dex-oracle).
[15] Dex2Jar Decrypt Strings. Accessed: 2019-05-15. [https://sourceforge.net/p/dex2jar/wiki/DecryptStrings/](https://sourceforge.net/p/dex2jar/wiki/DecryptStrings/).
[16] DexGuard. Accessed: 2017-10-23. [https://www.guardsquare.com/en/dexguard](https://www.guardsquare.com/en/dexguard).
[17] Shuaike Dong, Menghao Li, Wenrui Diao, Xiangyu Liu, Jian Liu, Zhou Li, Fenghao Xu, Kai Chen, Xiaofeng Wang, and Kehuan Zhang. 2018. Understanding Android Obfuscation Techniques: A Large-Scale Investigation in the Wild. Springer (2018), 172–192.
[18] Michael Eichberg and Ben Hermann. 2014. A Software Product Line for Static Analyses: The OPAL Framework. In Proceedings of the 3rd ACM SIGPLAN International Workshop on the State of the Art in Java Program Analysis (SOAP ’14). ACM, 1–6.
[19] Eric Enslen, Emily Hill, Lori Pollock, and K Vijay-Shanker. 2009. Mining source code to automatically split identifiers for software analysis. IEEE Computer Society (2009), 71–80.
[20] F-Droid. Accessed: 2019-05-15. [https://f-droid.org/](https://f-droid.org/).
[21] Yanick Fratantonio, Antonio Bianchi, William Robertson, Engin Kirda, Christopher Kruegel, and Giovanni Vigna. 2016. Triggerscope: Towards detecting logic bombs in Android applications. In 2016 IEEE Symposium on Security and Privacy (SP’16). IEEE, 377–396.
[22] Leonid Glanz, Sven Amann, Michael Eichberg, Michael Reif, Ben Hermann, Johannes Lerch, and Mira Mezini. 2017. CodeMatch: Obfuscation won’t conceal your repackaged app. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering. ACM, 638–648.
[23] Michael Grace, Yajin Zhou, Qiang Zhang, Shihong Zou, and Xuxian Jiang. 2012. RiskRanker: Scalable and accurate zero-day Android malware detection. In Proceedings of the 10th international conference on Mobile systems, applications, and services. ACM, 281–294.
[24] Johannes Hoffmann, Martin Ussath, Thorsten Holz, and Michael Spreitzenbarth. 2013. Slicing Droids: Program Slicing for Smali Code. In Proceedings of the 28th Annual ACM Symposium on Applied Computing (SAC ’13). ACM, New York, NY, USA, 1844–1851.
[25] Médéric Hurier, Kevin Allix, Tegawendé F Bissyandé, Jacques Klein, and Yves Le Traon. 2016. On the lack of consensus in anti-virus decisions: Metrics and insights on building ground truths of Android malware. In International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA’16). Springer, 142–162.
[26] Java bytecode analysis/deobfuscation tool. Accessed: 2019-05-15. [https://github.com/contra/JMD](https://github.com/contra/JMD).
[27] David Kahn. 1996. The Codebreakers: The comprehensive history of secret communication from ancient times to the internet. Simon and Schuster.
[28] Richard Killam, Paul Cook, and Natalia Stakhanova. 2016. Android malware classification through analysis of string literals. Text Analytics for Cybersecurity and Online Safety (TA-COS) (2016).
[29] Dongwoo Kim, Jin Kwak, and Jaecheol Ryou. 2015. DWroidDump: Executable Code Extraction from Android Applications for Malware Analysis. International Journal of Distributed Sensor Networks 11, 9 (2015), 379682. [https://doi.org/10.1155/2015/379682](https://doi.org/10.1155/2015/379682)
[30] Li Li, Tegawendé F. Bissyandé, Jacques Klein, and Yves Le Traon. 2015. An Investigation into the Use of Common Libraries in Android Apps. In Technique Report.
[31] Liuqing Li, He Feng, Wenjie Zhuang, Na Meng, and Barbara Ryder. 2017. Cclearner: A deep learning-based clone detection approach. In 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME’17). IEEE, 249–260.
[32] Menghao Li, Wei Wang, Pei Wang, Shuai Wang, Dinghao Wu, Jian Liu, Rui Xue, and Wei Huo. 2017. LibD: Scalable and precise third-party library detection in Android markets. In 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE’17). IEEE, 335–346.
[33] Robert Lyda and James Hamrock. 2007. Using entropy analysis to find encrypted and packed malware. IEEE Security & Privacy 5, 2 (2007), 40–45.
[34] Ziang Ma, Haoyu Wang, Yao Guo, and Xiangqun Chen. 2016. LibRadar: Fast and accurate detection of third-party libraries in Android apps. In Proceedings of the 38th International Conference on Software Engineering (ICSE’16). ACM, 653–656.
[35] Enrico Mariconti, Lucky Onwuzurike, Panagiotis Andriotis, Emiliano De Cristofaro, Gordon Ross, and Gianluca Stringhini. 2016. Mamadroid: Detecting Android malware by building Markov chains of behavioral models. arXiv preprint arXiv:1612.04433 (2016).
[36] Michael Meli, Matthew R McNiece, and Bradley Reaves. 2019. How Bad Can It Git? Characterizing Secret Leakage in Public GitHub Repositories. In NDSS.
[37] Luis Menezes and Roland Wismüller. 2017. Detecting information leaks in Android applications using a hybrid approach with program slicing, instrumentation, and tagging. In Security Technology (ICCST). IEEE, 1–6.
[38] O Mirzaei, JM de Fuentes, J Tapiador, and L Gonzalez-Manzano. 2018. AndrODet: An adaptive Android obfuscation detector. Future Generation Computer Systems (2018).
[39] Leann Myers and Maria J Sirois. 2004. Spearman correlation coefficients, differences between. Encyclopedia of statistical sciences 12 (2004), 81–106.
[40] Yuhong Nan, Zhemin Yang, Xiaofeng Wang, Yuan Zhang, Donglai Zhu, and Min Yang. 2018. Finding clues for your secrets: Semantics-driven, learning-based privacy discovery in mobile apps. In Proceedings of the 2018 Annual Network and Distributed System Security Symposium (NDSS’18).
[41] Allatori Java Obfuscator. Accessed: 2019-05-15. [http://www.allatori.com/](http://www.allatori.com/).
[42] Xiaorui Pan, Xueqiang Wang, Yue Duan, XiaoFeng Wang, and Heng Yin. 2017. Dark Hazard: Learning-based, large-scale discovery of hidden sensitive operations in Android apps. In Proceedings of the 2016 Annual Network and Distributed System Security Symposium (NDSS’17).
[43] Practical Cryptography. Accessed: 2019-05-15. [http://practicalcryptography.com/cryptanalysis/](http://practicalcryptography.com/cryptanalysis/).
[44] ProGuard provides minimal obfuscation. DexGuard applies multiple layers of encryption and obfuscation. 2017. [https://www.guardsquare.com/en/blog/dexguard-vs-proguard](https://www.guardsquare.com/en/blog/dexguard-vs-proguard), 2020-02-18.
[45] J. Ross Quinlan. 1986. Induction of decision trees. Machine learning 1, 1 (1986).
[46] Siegfried Rasthofer, Steven Arzt, Marc Miltenberger, and Eric Bodden. 2016. Harvesting Runtime Values in Android Applications That Feature Anti-Analysis Techniques. In NDSS.
[47] Abbas Razaghpanah, Rishab Nithyanand, Narseo Vallina-Rodriguez, Srikanth Sundaresan, Mark Allman, and Christian Kreibich Phillipa Gill. 2018. Apps, trackers, privacy, and regulators. In 25th Annual Network and Distributed System Security Symposium, NDSS, Vol. 2018.
[48] Sebastian Schrittwieser, Stefan Katzenbeisser, Johannes Kinder, Georg Merzdovnik, and Edgar Weippl. 2016. Protecting software through obfuscation: Can it keep pace with progress in code analysis? ACM Computing Surveys (CSUR) 49, 1 (2016), 4.
[49] Simplify. Accessed: 2019-05-15. [https://github.com/CalebFenton/simplify](https://github.com/CalebFenton/simplify).
[50] Sooel Son, Daehyeok Kim, and Vitaly Shmatikov. 2016. What Mobile Ads Know About Mobile Users. In Proceedings of the 2016 Network and Distributed Systems Symposium (NDSS’16).
[51] Ryan Stevens, Clint Gibler, Jon Crussell, Jeremy Erickson, and Hao Chen. 2012. Investigating user privacy in Android ad libraries. In Workshop on Mobile Security Technologies (MoST’12), Vol. 10.
[52] Stringer Java Obfuscator. Accessed: 2019-05-15. [https://jfxstore.com/](https://jfxstore.com/).
[53] Protecting users with TLS by default in Android P. Accessed: 2019-11-22. [https://android-developers.googleblog.com/2018/04/protecting-users-with-tls-by-default-in.html](https://android-developers.googleblog.com/2018/04/protecting-users-with-tls-by-default-in.html)
[54] Timothy Vidas and Nicolas Christin. 2014. Evading Android runtime analysis via sandbox detection. In Proceedings of the 9th ACM symposium on Information, computer, and communications security. ACM, 447–458.
[55] VirusTotal. Accessed: 2019-05-15. [https://www.virustotal.com/](https://www.virustotal.com/).
[56] Yan Wang and Atanas Rountev. 2017. Who changed you?: Obfuscator identification for Android. In Proceedings of the 4th International Conference on Mobile Software Engineering and Systems. 154–164.
[57] Yan Wang, Haowei Wu, Hailong Zhang, and Atanas Rountev. 2018. Orlis: Obfuscation-resilient library detection for Android. In 2018 IEEE/ACM 5th International Conference on Mobile Software Engineering and Systems (MOBILESoft’18). IEEE, 13–23.
[58] Dominik Wermke, Nicolas Huaman, Yasemin Acar, Bradley Reaves, Patrick Traynor, and Sascha Fahl. 2018. A large-scale investigation of obfuscation use in Google Play. In Proceedings of the 34th Annual Computer Security Applications Conference (ACSAC’18). ACM, 222–235.
[59] WhatsApp. Accessed: 2019-05-15. [https://play.google.com/store/apps/details?id=com.whatsapp](https://play.google.com/store/apps/details?id=com.whatsapp).
[60] Michelle Y Wong and David Lie. 2016. IntelliDroid: A Targeted Input Generator for the Dynamic Analysis of Android Malware. In Proceedings of the 2016 Annual Network and Distributed System Security Symposium (NDSS’16), Vol. 16. 21–24.
[61] Michelle Y Wong and David Lie. 2018. Tackling runtime-based obfuscation in Android with TIRO. In 27th USENIX Security Symposium (USENIX Security’18). 1247–1262.
[62] Zelix KlassMaster. Accessed: 2019-05-15. [http://www.zelix.com/](http://www.zelix.com/).
[63] Qingchuan Zhao, Chaoshun Zuo, Giancarlo Pellegrino, and Li Zhiqiang. 2019. Geo-locating Drivers: A Study of Sensitive Data Leakage in Ride-Hailing Services. In Proceedings of the 2019 Annual Network and Distributed System Security Symposium (NDSS’19).
[64] Yajin Zhou, Lei Wu, Zhi Wang, and Xuxian Jiang. 2015. Harvesting developer credentials in Android apps. In Proceedings of the 8th ACM Conference on Security & Privacy in Wireless and Mobile Networks. ACM, 23.
[65] Chaoshun Zuo, Zhiqiang Lin, and Yinqian Zhang. 2019. Why does your data leak? Uncovering the data leakage in cloud from mobile apps. In IEEE Symposium on Security and Privacy (SP’19).

### Appendix: Runtime Performance

**A.1 Runtime Performance:**
To evaluate the runtime performance of StringHound, we measured the average runtime per APK and per slice when running StringHound on the Top 500 and the two datasets from Section 4.2. The first measure indicates the time needed for APKs of different sizes, while the second can approximate the analysis time for a given APK. All performance measures indicate that StringHound is fast and ready for practical use.

**Figure 7: Average Runtime for Top 500 and the Two Malware Data Sets**

| Data Set         | Loading Analysis (s) | String Classifier (s) | Method Classifier (s) | Slicing (s) |
|------------------|----------------------|-----------------------|-----------------------|-------------|
| Top 500          | 0-50                 | 0-50                  | 0-50                  | 0-500       |
| Malware 2018     | 0-50                 | 0-50                  | 0-50                  | 0-500       |
| Contagio         | 0-50                 | 0-50                  | 0-50                  | 0-500       |

- **Observations:**
  - Processing the Top 500 dataset requires up to 20 times more time per APK than processing the Contagio dataset. This discrepancy is due to the large amount of library code in the Top 500 dataset, which is up to 14 times larger in code size than APKs from the Contagio dataset.
  - Across all three datasets, slicing consumes the most execution time. Improving the performance of slicing would speed up the entire analysis.
  - The mean, median, and 95%-quantile for each slice of all three datasets are below 250 ms. Thus, building and executing a single slice takes on average less than 250 ms.
  - Given that slicing consumes most of the execution time and a single slice takes less than 250 ms, the best way to improve performance is to parallelize the building and execution of single slices.