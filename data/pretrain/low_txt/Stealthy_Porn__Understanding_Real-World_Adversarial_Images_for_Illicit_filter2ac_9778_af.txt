### Ethical Considerations

As anticipated, evading advanced networks would be significantly more challenging than bypassing conventional ones. Before initiating this research, we consulted with the Institutional Review Board (IRB) and confirmed that our study did not require IRB approval. This is because all images reviewed were pre-existing, collected from the Internet, and only a secondary analysis of already published materials was involved, thus not constituting human subjects research. Additionally, to aid readers in better understanding our work, we have included a few Adversarial Promotional Porn Images (APPIs). We have applied masks to cover most exposed skin areas and the eyes of individuals in all explicit images to ensure that no explicit content is distributed and to protect the privacy of the actors.

### Related Work

#### Explicit Content Detection

Numerous studies have focused on detecting nudity or pornography in color images and videos. Traditional methods for explicit content detection include skin detection and text analysis. For instance, Platzer et al. [52] proposed an algorithm that accurately detects skin and its position using a collection of shapes and geometric rules. Chan et al. [30] developed a system based on skin-derived features and text analysis to detect pornographic websites. Lopes et al. [45] explored nudity detection in videos using a bag-of-visual-features representation for frames. In recent years, deep learning techniques have been increasingly used in explicit content detection. Wehrmann et al. [58] combined convolutional neural networks (CNNs) and Long Short-Term Memory (LSTM) recurrent networks for adult content detection in videos. Perez et al. [51] classified pornographic videos using CNNs along with static and motion information.

In contrast to these previous works, which primarily focus on detecting plain explicit content, our research introduces a unique technique to detect adversarial explicit content, even when multiple evasive techniques such as blurring and occlusion are applied.

#### Adversarial Image Detection

The field of adversarial example detection has seen rapid growth in recent years. Previous works on adversarial example detection can be categorized into three main approaches [28]. The first approach involves secondary classification-based detection, where a second classifier is built to detect adversarial examples. Grosse et al. [38] introduced a variant of adversarial re-training, adding a new class solely for adversarial examples. Gong et al. [36] constructed a binary classifier to distinguish natural images from adversarial examples. The second approach is principal component analysis (PCA) detection, which transforms high-dimensional data into a lower-dimensional space. Hendrycks et al. [41] observed that adversarial examples place higher weight on larger principal components compared to natural images. Li et al. [43] applied PCA to the values after inner convolutional layers of a neural network and used a cascade classifier to detect adversarial examples. The third approach involves comparing the distribution of natural images to that of adversarial examples. Feinman et al. [33], for example, investigated model confidence on adversarial samples by examining Bayesian uncertainty estimates and other features.

Our paper presents a novel technique to detect real-world adversarial explicit content generated by attackers for cybercrime purposes, setting it apart from previous work.

#### Image Processing for Security

Image processing techniques have been increasingly used in security and privacy research. Borgolte et al. [27] introduced Meerkat, a computer vision approach to website defacement detection, capable of identifying malicious content changes from website screenshots. Medvet et al. [47] proposed a system to detect potential phishing pages by leveraging features such as visible text, embedded images, and the overall appearance of the website. Anderson et al. [26] introduced image shingling, a technique similar to w-shingling, to cluster scam screenshots into campaigns. Nappa et al. [48] used perceptual hashing to group visually similar icons of malicious executables, assuming that similar icons indicate the same malware distribution campaign. Templeman et al. [56] developed a technique for owners of first-person cameras to "blacklist" sensitive spaces like bathrooms and bedrooms, using novel image analysis to classify where a photo was taken. Zannettou et al. [61] created a processing pipeline based on image processing techniques to detect and track memes across multiple web communities.

To the best of our knowledge, no prior work has applied image-based methods to detect promotional adversarial explicit content.

### Conclusion

In this paper, we present our study on adversarial promotional porn images (APPIs), which promote illicit businesses (e.g., porn apps or gambling sites) using adversarial techniques to evade explicit content detectors. To capture such stealthy images, our advanced explicit content detector, Maléna, employs a set of Deep Neural Network (DNN) based techniques to automatically identify promotional information and capture relatively less obfuscated regions in the images. Our study shows that Maléna achieves a low false detection rate (about 9%) with 85% coverage. Running on 4,042,698 images from 725,384 popular posts/microblogs across two social media platforms, Baidu Tieba and Sina Weibo, Maléna automatically detected 4,353 APPIs, highlighting the real-world obfuscation techniques used by cybercriminals to evade state-of-the-art explicit content detectors (e.g., Google Cloud Vision API and Yahoo Open NSFW model). These obfuscation techniques include adding high-frequency signals (e.g., texturing and noising) or filter effects (e.g., blurring) to images. Our research further demonstrates the effectiveness of such obfuscation techniques and the challenges they pose. Moving forward, our study reveals the ecosystem of illicit promotion, from distribution channels to APPI campaigns and the promoted illicit businesses, providing a comprehensive view of the issue and aiding in the development of effective solutions to mitigate such security risks.

### Acknowledgements

We are grateful to our shepherd Gianluca Stringhini and the anonymous reviewers for their insightful comments. We also thank Xiaoran Peng, David Crandall, and Dmitry Evtyushkin for their valuable feedback. This work is supported in part by NSF grants CNS-1527141, 1618493, 1801432, 1838083, 1801365, and ARO W911NF1610127.

### References

[1] “Baidu tieba,” https://tieba.baidu.com/.
[2] “Baidu tieba policy,” http://static.tieba.baidu.com/tb/eula.html.
[3] “Boofcv,” https://boofcv.org/index.php?title=Main Page.
[4] “China cybersecurity law,” http://www.cac.gov.cn/2016-11/07/c_1119867116.htm.
[5] “Clarifai,” https://clarifai.com/.
[6] “Downloads - incidental scene text,” http://rrc.cvc.uab.es/?ch=4&com=downloads.
[7] “Google cloud vision api,” https://cloud.google.com/vision/.
[8] “Safesearch - wikipedia,” https://en.wikipedia.org/wiki/SafeSearch.
[9] “Sina weibo,” https://www.weibo.com/.
[10] “Sina weibo service usage agreement,” https://www.weibo.com/signup/v5/protocol.
[11] “Twitter media policy,” https://help.twitter.com/en/rules-and-policies/media-policy.
[12] “phash: The open source perceptual hash library,” http://www.phash.org, 2008.
[13] “Zbar bar code reader,” http://zbar.sourceforge.net, 2011.
[14] “Zxing (zebra crossing) barcode scanning library for java, android,” https://github.com/zxing/zxing/, 2011.
[15] “Libmagic,” https://github.com/threatstack/libmagic, 2014.
[16] “Ms-celeb-1m: Challenge of recognizing one million celebrities in the real world,” https://www.microsoft.com/en-us/research/project/ms-celeb-1m-challenge-recognizing-one-million-celebrities-real-world/, 2016.
[17] “Tensorflow implementation of yahoo’s open nsfw model,” https://github.com/mdietrichstein/tensorflow-open_nsfw, 2017.
[18] “Baidu aipimagecensor github,” https://github.com/Baidu-AIP/php-sdk/blob/master/AipImageCensor.php, 2018.
[19] “维基百科,” https://zh.wikipedia.org, 2018.
[20] “Coco - common objects in context,” http://cocodataset.org/, 2018.
[21] “Implementation of our paper ‘pixellink: Detecting scene text via instance segmentation’ in aaai2018,” https://github.com/ZJULearning/pixel_link, 2018.
[22] “Opencv: Opencv modules,” https://docs.opencv.org/3.4/index.html, 2018.
[23] “Pillow,” https://pillow.readthedocs.io/en/latest/, 2018.
[24] “Scikit-image,” https://scikit-image.org, 2018.
[25] W. Abdulla, “Mask r-cnn for object detection and instance segmentation on keras and tensorflow,” https://github.com/matterport/Mask_RCNN, 2017.
[26] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker, “Spamscatter: Characterizing internet scam hosting infrastructure,” Ph.D. dissertation, University of California, San Diego, 2007.
[27] K. Borgolte, C. Kruegel, and G. Vigna, “Meerkat: Detecting website defacements through image-based object recognition.”
[28] N. Carlini and D. Wagner, “Adversarial examples are not easily detected: Bypassing ten detection methods,” in Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. ACM, 2017, pp. 3–14.
[29] ——, “Towards evaluating the robustness of neural networks,” in Security and Privacy (SP), 2017 IEEE Symposium on. IEEE, 2017, pp. 39–57.
[30] Y. Chan, R. Harvey, and D. Smith, “Building systems to block pornography.”
[31] D. Deng, H. Liu, X. Li, and D. Cai, “Pixellink: Detecting scene text via instance segmentation,” arXiv preprint arXiv:1801.01315, 2018.
[32] R. Di Pietro and L. V. Mancini, Intrusion detection systems. Springer Science & Business Media, 2008, vol. 38.
[33] R. Feinman, R. R. Curtin, S. Shintre, and A. B. Gardner, “Detecting adversarial samples from artifacts,” arXiv preprint arXiv:1703.00410, 2017.
[34] R. Girshick, “Fast r-cnn,” in Proceedings of the IEEE international conference on computer vision, 2015, pp. 1440–1448.
[35] R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hierarchies for accurate object detection and semantic segmentation,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2014, pp. 580–587.
[36] Z. Gong, W. Wang, and W.-S. Ku, “Adversarial and clean data are not twins,” arXiv preprint arXiv:1704.04960, 2017.
[37] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” stat, vol. 1050, p. 20, 2015.
[38] K. Grosse, P. Manoharan, N. Papernot, M. Backes, and P. McDaniel, “On the (statistical) detection of adversarial examples,” arXiv preprint arXiv:1702.06280, 2017.
[39] K. He, G. Gkioxari, P. Dollár, and R. Girshick, “Mask r-cnn,” in Computer Vision (ICCV), 2017 IEEE International Conference on. IEEE, 2017, pp. 2980–2988.
[40] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770–778.
[41] D. Hendrycks and K. Gimpel, “Early methods for detecting adversarial images,” arXiv preprint arXiv:1608.00530, 2016.
[42] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” in Advances in neural information processing systems, 2012, pp. 1097–1105.
[43] X. Li and F. Li, “Adversarial examples detection in deep networks with convolutional filter statistics.” in ICCV, 2017, pp. 5775–5783.
[44] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 3431–3440.
[45] A. P. B. Lopes, S. E. de Avila, A. N. Peixoto, R. S. Oliveira, M. d. M. Coelho, and A. d. A. Araújo, “Nude detection in video using bag-of-visual-features,” in Computer Graphics and Image Processing (SIBGRAPI), 2009 XXII Brazilian Symposium on. IEEE, 2009, pp. 224–231.
[46] D. G. Lowe, “Distinctive image features from scale-invariant keypoints,” International journal of computer vision, vol. 60, no. 2, pp. 91–110, 2004.
[47] E. Medvet, E. Kirda, and C. Kruegel, “Visual-similarity-based phishing detection,” in Proceedings of the 4th international conference on Security and privacy in communication networks. ACM, 2008, p. 22.
[48] A. Nappa, M. Z. Rafique, and J. Caballero, “Driving in the cloud: An analysis of drive-by download operations and abuse reporting,” in International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment. Springer, 2013, pp. 1–20.
[49] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and A. Swami, “The limitations of deep learning in adversarial settings,” in Security and Privacy (EuroS&P), 2016 IEEE European Symposium on. IEEE, 2016, pp. 372–387.
[50] N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, “Distillation as a defense to adversarial perturbations against deep neural networks,” in Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 2016, pp. 582–597.
[51] M. Perez, S. Avila, D. Moreira, D. Moraes, V. Testoni, E. Valle, S. Goldenstein, and A. Rocha, “Video pornography detection through deep learning techniques and motion information,” Neurocomputing, vol. 230, pp. 279–293, 2017.
[52] C. Platzer, M. Stütz, and M. Lindorfer, “Skin sheriff: A machine learning solution for detecting explicit images,” in Proceedings of the 2nd international workshop on Security and forensics in communication systems. ACM, 2014, pp. 45–56.
[53] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time object detection with region proposal networks,” in Advances in neural information processing systems, 2015, pp. 91–99.
[54] P. Samangouei, M. Kabkab, and R. Chellappa, “Defense-gan: Protecting classifiers against adversarial attacks using generative models,” arXiv preprint arXiv:1805.06605, 2018.
[55] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus, “Intriguing properties of neural networks,” arXiv preprint arXiv:1312.6199, 2013.
[56] R. Templeman, M. Korayem, D. J. Crandall, and A. Kapadia, “Placeavoider: Steering first-person cameras away from sensitive spaces.” 2014.
[57] J. R. Uijlings, K. E. Van De Sande, T. Gevers, and A. W. Smeulders, “Selective search for object recognition,” International journal of computer vision, vol. 104, no. 2, pp. 154–171, 2013.
[58] J. Wehrmann, G. S. Simões, R. C. Barros, and V. F. Cavalcante, “Adult content detection in videos with convolutional and recurrent neural networks,” Neurocomputing, vol. 272, pp. 432–438, 2018.
[59] G. L. Wittel and S. F. Wu, “On attacking statistical spam filters.” in CEAS, 2004.
[60] H. Xiao, B. Biggio, G. Brown, G. Fumera, C. Eckert, and F. Roli, “Is feature selection secure against training data poisoning?” in International Conference on Machine Learning, 2015, pp. 1689–1698.
[61] S. Zannettou, T. Caulfield, J. Blackburn, E. D. Cristofaro, M. Sirivianos, G. Stringhini, and G. Suarez-Tangil, “On the origins of memes by means of fringe web communities,” CoRR, vol. abs/1805.12512, 2018. [Online]. Available: http://arxiv.org/abs/1805.12512