### References

1. Anubis. <http://anubis.cs.ucsb.edu>
2. Norman Sandbox. <http://www.norman.com/>
3. Yara. <https://virustotal.github.io/yara/>
4. Abu Rajab, M., Zarfoss, J., Monrose, F., and Terzis, A. "A Multifaceted Approach to Understanding the Botnet Phenomenon." In Proceedings of the ACM SIGCOMM Internet Measurement Conference (IMC), New York, NY, USA, 2006, pp. 41-52.
5. Bailey, M., Oberheide, J., Andersen, J., Mao, Z. M., Jahanian, F., and Nazario, J. "Automated Classification and Analysis of Internet Malware." Recent Advances in Intrusion Detection, 2007, pp. 178-197.
6. Balzarotti, D., Cova, M., Karlberger, C., Kruegel, C., Kirda, E., and Vigna, G. "Efficient Detection of Split Personalities in Malware." NDSS, April 2010.
7. Bayer, U., Comparetti, P., Hlauschek, C., Kruegel, C., and Kirda, E. "Scalable, Behavior-Based Malware Clustering." Network and Distributed System Security Symposium (NDSS), 2009.
8. Bayer, U., Habibi, I., Balzarotti, D., Kirda, E., and Kruegel, C. "A View on Current Malware Behaviors." LEET, 2009.
9. Brumley, D., Hartwig, C., Liang, Z., Newsome, J., Song, D., and Yin, H. "Automatically Identifying Trigger-based Behavior in Malware." Springer US, Boston, MA, 2008, pp. 65-88.
10. Canali, D., Lanz, A., Balzarotti, D., Kruegel, C., Christodorescu, M., and Kirda, E. "A Quantitative Study of Accuracy in System Call-based Malware Detection." Proceedings of the 2012 International Symposium on Software Testing and Analysis (ISSTA), New York, NY, USA, 2012, p. 122.
11. Christodorescu, M., Jha, S., and Kruegel, C. "Mining Specifications of Malicious Behavior." Proceedings of the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering (ESEC-FSE), New York, NY, USA, 2007, p. 5.
12. Christodorescu, M., Jha, S., Seshia, S. A., Song, D., and Bryant, R. E. "Semantics-aware Malware Detection." Proceedings - IEEE Symposium on Security and Privacy, 2005, pp. 32-46.
13. Comparetti, P. M., Salvanescu, G., Kirda, E., Kolbitsch, C., Kruegel, C., and Zanero, S. "Identifying Dormant Functionality in Malware Programs." 2010 IEEE Symposium on Security and Privacy, 2010, pp. 61-76.
14. Cozzi, E., Graziano, M., Fratantonio, Y., and Balzarotti, D. "Understanding Linux Malware." IEEE Symposium on Security and Privacy (SP), 2018, pp. 161-175.
15. Crandall, J. R., Wassermann, G., de Oliveira, D. A., Su, Z., Wu, S. F., and Chong, F. T. "Temporal Search: Detecting Hidden Malware Timebombs with Virtual Machines." ACM SIGOPS Operating Systems Review, vol. 40, no. 5, 2006, pp. 25-36.
16. David, O. E., and Netanyahu, N. S. "DeepSign: Deep Learning for Automatic Malware Signature Generation and Classification." Proceedings of the International Joint Conference on Neural Networks, July 2015, vol. 2015-Septe, pp. 1-8.
17. Dinaburg, A., Royal, P., Shari, M., and Lee, W. "Ether: Malware Analysis via Hardware Virtualization Extensions." Proceedings of the ACM Conference on Computer and Communications Security, New York, NY, USA, 2008, pp. 51-62.
18. Fredrikson, M., Jha, S., Christodorescu, M., Sailer, R., and Yan, X. "Synthesizing Near-Optimal Malware Specifications from Suspicious Behaviors." 2010 IEEE Symposium on Security and Privacy, 2010, pp. 45-60.
19. Jordany, R., Holloway, R., Sharad, K., NEC Laboratories, Dash, S. K., Wang, Z., Papini, D., SELEX Elettronica, Nouretdinov, I., and Cavallaro, L. "Transcend: Detecting Concept Drift in Malware Classification Models." USENIX Security Symposium, 2017, pp. 625-642.
20. Kirat, D., and Vigna, G. "Malgene: Automatic Extraction of Malware Analysis Evasion Signature." Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, New York, NY, USA, 2015, pp. 769-780.
21. Kirat, D., and Vigna, G. "MalGene: Automatic Extraction of Malware Analysis Evasion Signature." Proceedings of the ACM Conference on Computer and Communications Security, New York, NY, USA, 2015, vol. 2015-Octob, pp. 769-780.
22. Kirat, D., Vigna, G., and Kruegel, C. "BareCloud: Bare-metal Analysis-based Evasive Malware Detection." 23rd USENIX Security Symposium (USENIX Security 14), 2014.
23. Kirda, E., Kruegel, C., Banks, G., Vigna, G., and Kemmerer, R. "Behavior-based Spyware Detection." Usenix Security Symposium, 2006, p. 694.
24. Kolbitsch, C., Comparetti, P. M., Kruegel, C., Kirda, E., Zhou, X., and Wang, X. "Effective and Efficient Malware Detection at the End Host." Presented as part of the 18th USENIX Security Symposium (USENIX Security 09), Montreal, Canada, 2009.
25. Kolbitsch, C., Kirda, E., and Kruegel, C. "The Power of Procrastination: Detection and Mitigation of Execution-Stalling Malicious Code." Proceedings of the ACM Conference on Computer and Communications Security, New York, NY, USA, 2011, pp. 285-296.
26. Konno, H., Shirakawa, H., and Yamazaki, H. "A Mean-Absolute Deviation-Skewness Portfolio Optimization Model." Annals of Operations Research, vol. 45, no. 1, 1993, pp. 205-220.
27. Kotzias, P., Bilge, L., Vervier, P.-A., and Caballero, J. "Mind Your Own Business: A Longitudinal Study of Threats and Vulnerabilities in Enterprises." Network and Distributed System Security Symposium (NDSS), 2019.
28. Kwon, B. J., Mondal, J., Jang, J., Bilge, L., and Dumitraş, T. "The Dropper Effect: Insights into Malware Distribution with Downloader Graph Analytics." Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, 2015, pp. 1118-1129.
29. Lanzi, A., Balzarotti, D., Kruegel, C., Christodorescu, M., and Kirda, E. "AccessMiner: Using System-Centric Models for Malware Protection." Proceedings of the 17th ACM Conference on Computer and Communications Security, New York, NY, USA, 2010, pp. 399-412.
30. Leys, C., Ley, C., Klein, O., Bernard, P., and Licata, L. "Detecting Outliers: Do Not Use Standard Deviation Around the Mean, Use Absolute Deviation Around the Median." Journal of Experimental Social Psychology, vol. 49, no. 4, 2013, pp. 764-766.
31. Lindorfer, M., Kolbitsch, C., and Milani Comparetti, P. "Detecting Environment-Sensitive Malware." Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), vol. 6961 LNCS, Springer, Berlin, Heidelberg, 2011, pp. 338-357.
32. Liu, L., Chen, S., Yan, G., and Zhang, Z. "BotTracer: Execution-based Bot-like Malware Detection." International Conference on Information Security, 2008, pp. 97-113.
33. Mann, H. B., and Whitney, D. R. "On a Test of Whether One of Two Random Variables is Stochastically Larger than the Other." The Annals of Mathematical Statistics, 1947, pp. 50-60.
34. Martignon, L., Stinson, E., Fredrikson, M., Jha, S., and Mitchell, J. C. "A Layered Architecture for Detecting Malicious Behaviors." International Workshop on Recent Advances in Intrusion Detection, 2008, pp. 78-97.
35. Miramirkhani, N., Appini, M. P., Nikiforakis, N., and Polychronakis, M. "Spotless Sandboxes: Evading Malware Analysis Systems Using Wear-and-Tear Artifacts." 2017 IEEE Symposium on Security and Privacy (SP), 2017, pp. 1009-1024.
36. Moser, A., Kruegel, C., and Kirda, E. "Exploring Multiple Execution Paths for Malware Analysis." 2007 IEEE Symposium on Security and Privacy (SP '07), May 2007, pp. 231-245.
37. Moser, A., Kruegel, C., and Kirda, E. "Limits of Static Analysis for Malware Detection." Twenty-Third Annual Computer Security Applications Conference (ACSAC 2007), December 2007, pp. 421-430.
38. Pendlebury, F., Pierazzi, F., Jordanye, R., Kinder, J., and Cavallaro, L. "TESSERACT: Eliminating Experimental Bias in Malware Classification Across Space and Time." 28th USENIX Security Symposium, 2019, pp. 729-746.
39. Praszmo, M. "Ramnit: In-Depth Analysis." <https://www.cert.pl/en/news/single/ramnit-in-depth-analysis/>
40. Rieck, K., Holz, T., Willems, C., Düssel, P., and Laskov, P. "Learning and Classification of Malware Behavior." International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, 2008, pp. 108-125.
41. Rieck, K., Trinius, P., Willems, C., and Holz, T. "Automatic Analysis of Malware Behavior Using Machine Learning." Journal of Computer Security, vol. 19, no. 4, June 2011, pp. 639-668.
42. Rossow, C., Dietrich, C., and Bos, H. "Large-Scale Analysis of Malware Downloaders." DIMVA, 2012, Springer, Berlin, Heidelberg, pp. 42-61.
43. Rossow, C., Dietrich, C. J., Grier, C., Kreibich, C., Paxson, V., Pohlmann, N., Bos, H., and Van Steen, M. "Prudent Practices for Designing Malware Experiments: Status Quo and Outlook." Proceedings - IEEE Symposium on Security and Privacy, May 2012, pp. 65-79.
44. Roth, F. "Generic Signature Format for SIEM Systems." <https://github.com/Neo23x0/sigma>
45. Schreuders, Z. C., Shaw, T., Shan-a-Khuda, M., Ravichandran, G., Keighley, J., and Ordean, M. "Security Scenario Generator (SecGen): A Framework for Generating Randomly Vulnerable Rich-Scenario VMs for Learning Computer Security and Hosting CTF Events." 2017 USENIX Workshop on Advances in Security Education (ASE 17), 2017.
46. Sebastian, M., Rivera, R., Kotzias, P., and Caballero, J. "AVClass: A Tool for Massive Malware Labeling." Research in Attacks, Intrusions, and Defenses, 2016.
47. Sharif, M. I., Lanzi, A., Giffin, J. T., and Lee, W. "Impeding Malware Analysis Using Conditional Code Obfuscation." NDSS, 2008.
48. Song, Y., Locasto, M. E., Stavrou, A., Keromytis, A. D., and Stolfo, S. J. "On the Infeasibility of Modeling Polymorphic Shellcode." Proceedings of the 14th ACM Conference on Computer and Communications Security, 2007, pp. 541-551.
49. SS64. "Quotes, Escape Characters, Delimiters - Windows CMD - SS64.com." <https://ss64.com/nt/syntax-esc.html>
50. TrendMicro. "Threat Encyclopedia - TrojanSpy.Win32.GLUPTEBA.A." <https://www.trendmicro.com/vinfo/us/threat-encyclopedia/malware/trojanspy.win32.glupteba.a>
51. Trinius, P., Willems, C., Holz, T., and Rieck, K. "A Malware Instruction Set for Behavior-Based Analysis." Sicherheit Schutz und Zuverlässigkeit SICHERHEIT, 2011.
52. Willems, C., Holz, T., and Freiling, F. "Toward Automated Dynamic Malware Analysis Using CWSandbox." IEEE Security & Privacy, vol. 5, no. 2, 2007, pp. 32-39.
53. Yadegari, B., and Debray, S. "Symbolic Execution of Obfuscated Code." Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, 2015, pp. 732-744.
54. Yin, H., Song, D., Egele, M., Kruegel, C., and Kirda, E. "Panorama: Capturing System-Wide Information Flow for Malware Detection and Analysis." Proceedings of the ACM Conference on Computer and Communications Security, New York, NY, USA, 2007, pp. 116-127.
55. Zhou, Y., and Jiang, X. "Dissecting Android Malware: Characterization and Evolution." 2012 IEEE Symposium on Security and Privacy, 2012, pp. 95-109.

### Appendix

#### A.1 Implications of Variability on Malware Clustering

Dynamic malware clustering [5, 7, 40, 41] aims to identify malware families (or variations within the same family) by grouping together samples with similar behaviors. These approaches commonly rely on only one execution trace per sample. Therefore, we investigate how the large variability among the traces of each sample could influence the results reported from clustering experiments.

This can be performed by clustering execution traces and then verifying whether the traces of the same sample are clustered together or scattered among multiple clusters. For this experiment, we implemented the clustering technique described by Bailey et al. [5], which also uses similar features to our dataset. As suggested in the paper, we applied their normalized compression distance to our samples and utilized the same hierarchical clustering algorithm and method to determine the number of clusters. We clustered execution traces from 2,424 malware samples. For each sample, we randomly selected 4 traces collected in the same week but on different machines; we repeated this step 10 times. We clustered the resulting 9,696 traces and obtained 88-105 clusters, of which we picked the median with 93 clusters.

To interpret these clusters as families of malware samples with similar behaviors, it is necessary that all executions of a sample fall within its family cluster. On average, we found that for 67% of malware samples, all 4 executions appeared indeed in the same cluster. However, one-third of the samples exhibited sufficient variability in behavior that their traces appeared in multiple clusters: 27% fell into 2 clusters, 5% in 3 clusters, and 1% in 4 different clusters. This calls into question the conclusion that the behavior clusters reflect malware families. Because some samples exhibit too much behavior variability to be clustered correctly into families, we must be cautious when drawing conclusions from clustering experiments. Importantly, this threat to validity comes to light when we cluster multiple traces per sample but remains hidden when using only a single trace per sample.

#### A.2 Impact on Anomaly Detection

One way of detecting malware regardless of their variability is to detect deviations from benign behavior. In this category, Lanzi et al. proposed AccessMiner [29], a system-level anomaly detector based on behavioral traces of benign programs. It is interesting to note that the authors already adopted a technique that accounted for behavioral variability over time and different machine profiles. Similarly to our data, their dataset was also collected from real users, but their goal was not to study changes in the application behavior but to obtain a complete picture of how benign files interact with the underlying operating system.

Since in the AccessMiner paper, the authors did not discuss how many executions of benign programs are needed to train the anomaly detector, we decided to leverage our data to find an answer to this question such that security companies that opt for anomaly detection rather than malware detection could benefit from our results.

Following the AccessMiner approach, we constructed the benign profile by using 90% of the benign executions in our dataset. The remaining 10% was used to measure the false-positive rate. As AccessMiner found file write events to be the most successful in identifying malware, we first built the graph using the file write actions in our dataset. We measured the success of an anomaly-based model that relies on only one execution per benign sample (Figure 9a), then the success when all of the executions available to us were included (Figure 9b). As seen from the figures, a single random benign execution is not sufficient to train an anomaly detector because it treats most of the executions as anomalies.

The detection rates we obtained from this experiment are lower than the ones reported in the original paper. Given that the nature of our data is very different from the benign dataset of AccessMiner, this is expected. Note that our data consists of unpopular benign applications, whose behavior might be more similar to malicious and unwanted programs. To obtain a better behavioral coverage for benign programs, not only popular benign files such as those used in AccessMiner should be considered, but also lower reputation, lower prevalence benign files.

(a) Using 1 random benign execution
(b) Using all benign execution

**Figure 9: Amount of samples for the ratio of machines with anomalous file writes.**

---

This version of the text is more structured, clear, and professional. It includes proper formatting and citation styles, making it easier to read and understand.