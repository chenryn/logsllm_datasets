### Code Refactoring and Security in Development

None of the participants wrote any customized validation or encoding routines. Therefore, ASIDE's code refactoring was effective in helping students write more secure code, even though they were not required to do so.

### Factors Affecting Warning Response

Several factors explain why certain warnings were not clicked or acted upon. Some warnings were generated when participants wrote debugging code, which was soon deleted. It is possible that students ignored security warnings on transient code. Additionally, a bug in the version of ASIDE used generated false warnings about the need for output encoding. Participants learned to recognize these false positives after one or more encounters and subsequently ignored them. However, the presence of false positives did not cause participants to disregard other ASIDE warnings. In cases where false positives were encountered, participants quickly recognized them and used ASIDE’s options to dismiss them.

### Interview Analysis

We transcribed all interviews into text using Inqscribe [15] and coded the transcripts with Atlas.ti [2] to identify general themes and interesting cases. All but one participant indicated that without ASIDE, they would not have been aware that some inputs needed validation before use. They unanimously agreed that they would not write their own validation routines if ASIDE did not provide them. One participant stated:

> "The warning design of ASIDE was good because, without it, I wouldn’t have realized I needed to inspect those input values."

No one found the ASIDE warnings annoying, and all expressed confidence that using ASIDE made their code more secure. For example:

> "I don't mind the warnings; they help me write secure code."

Overall, 8 out of 9 participants had a positive impression of ASIDE, with one being neutral. This study demonstrated that ASIDE was usable by our participants, who were able to utilize it quickly in their development, potentially improving the security of their code. We plan to expand this study to examine the use of ASIDE by professional developers to more deeply investigate its impact on programmer behavior in various contexts.

### Related Work

Research into tool support for software security primarily focuses on machine-related issues, such as advancements in vulnerability detection, accuracy, and coverage, with little attention to human factors. The two main techniques are static and dynamic program analyses. Static analysis typically uses taint tracking [27, 17, 21, 7], while dynamic analyses often use model checking [14, 9, 22] and symbolic execution [6, 10, 32]. Both approaches have their advantages and disadvantages, leading to research on combining them to achieve better performance [3, 23, 13].

Software developer education and training also aim to improve software security. Most efforts focus on developing educational materials and guidelines for best secure programming practices [5, 16, 1, 18, 35]. However, the mere existence of such information does not ensure its use by programmers [38]. Our work considers human factors and complements program analysis tools to help developers write more secure code.

Our work is motivated by studies on human errors [29] and programmer errors [20], which show that programmer errors contribute significantly to software flaws. Many such errors are due to skill-based, rule-based, and knowledge-based breakdowns. We believe that ASIDE’s contextualized reminders can address these issues by filling knowledge gaps and reminding programmers of secure programming practices within their current context.

Prior work on code annotation (e.g., [24]) used textual extensions of programming languages like C and Java, requiring developers to learn and use another language. In contrast, our approach leverages GUI support to make the process more intuitive, direct, and easy to use. Furthermore, soliciting security information from developers through annotations could open new ways to detect software vulnerabilities.

### Conclusions

The main contribution of our work is augmenting IDE tools to intelligently recognize software security issues and assist developers with possible mitigation actions. We evaluated this approach against mature open-source projects, and our results suggest that it is effective in detecting and preventing common types of web application vulnerabilities, such as lack of proper input validation and/or encoding, CSRF, and broken access control.

No single tool can detect all software vulnerabilities, and ASIDE is no exception. However, we believe ASIDE can be most effective in supplementing static analysis tools and increasing the productivity of current best software security practices. For input validation and encoding issues, which often constitute the largest percentage of issues in typical web applications, ASIDE can significantly reduce the number of issues generated by static analysis by helping programmers prevent them in the first place. Thus, ASIDE can improve software security, reduce the number of security fixes needed after static analysis, and save time for software security audits by 50%, based on our Roller case study.

Our user study results suggest that ASIDE is effective in helping novice developers and students write more secure code when using code refactoring. They pay attention to ASIDE warnings and follow its advice to perform input validation and/or encoding. Further studies, including those involving experienced developers, are needed to show whether ASIDE can improve developers’ understanding and practice of secure programming in more contexts. Preliminary evidence suggests that users can quickly recognize false positives in ASIDE and take easy action to dismiss them. More research on false positives and their impact on developers using ASIDE is needed.

Finally, our approach provides a tool platform to support the secure software development lifecycle in enforcing standards, collecting information for secure coding metrics, and capturing developer rationale for code review or in-depth program analysis. In an enterprise environment, ASIDE can serve as a medium to communicate a Software Security Group’s secure coding knowledge to developers. As we continue developing ASIDE, we plan to further investigate the use of these features and how they can contribute to secure applications.

### Acknowledgments

This work is supported in part by a grant from the National Science Foundation (0830624) and a research/educational license from HP Fortify Inc. We would like to thank Will Stranathan for his contributions to the formation of this idea and critiques and suggestions on the initial prototyping of ASIDE. We also want to thank all our participants for their time.

### References

[1] S. Ardi, D. Byers, P. H. Meland, I. A. Tondel, and N. Shahmehri. How can the developer benefit from security modeling? In The Second International Conference on Availability, Reliability and Security, 2007, pages 1017–1025, April 2007.

[2] Atlas.ti. Atlas.ti, 2011. www.atlasti.com.

[3] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic, E. Kirda, C. Kruegel, and G. Vigna. Saner: Composing static and dynamic analysis to validate sanitization in web applications. In Proceedings of the 2008 IEEE Symposium on Security and Privacy, pages 387–401. IEEE Computer Society, 2008.

[4] M. Bishop and B. J. Orvis. A clinic to teach good programming practices. In Proceedings from the Tenth Colloquium on Information Systems Security Education, pages 168–174, June 2006.

[5] CERT. CERT Secure Coding, 2011. www.cert.org/secure-coding.

[6] A. Chaudhuri and J. S. Foster. Symbolic security analysis of ruby-on-rails web applications. In Proceedings of the 17th ACM conference on Computer and communications security, CCS '10, pages 585–594. ACM, 2010.

[7] B. Chess and G. McGraw. Static analysis for security. IEEE Security and Privacy, 2:76–79, November 2004.

[8] B. Chess and J. West. Secure programming with static analysis. Addison-Wesley Professional, first edition, 2007.

[9] V. Felmetsger, L. Cavedon, C. Kruegel, and G. Vigna. Toward automated detection of logic vulnerabilities in web applications. In Proceedings of the 19th USENIX conference on Security, USENIX Security'10, pages 10–10. USENIX Association, 2010.

[10] X. Fu and K. Qian. Safeli: SQL injection scanner using symbolic execution. In Proceedings of the 2008 workshop on Testing, analysis, and verification of web services and applications, TAV-WEB '08, pages 34–39. ACM, 2008.

[21] V. B. Livshits and M. S. Lam. Finding security errors in Java programs with static analysis. In Proceedings of the 14th Usenix Security Symposium, pages 271–286, August 2005.

[22] M. Martin and M. S. Lam. Automatic generation of XSS and SQL injection attacks with goal-directed model checking. In Proceedings of the 17th conference on Security symposium, pages 31–43. USENIX Association, 2008.

[23] M. Martin, B. Livshits, and M. S. Lam. Finding application errors and security flaws using PQL: a program query language. In OOPSLA '05: Proceedings of the 20th annual ACM SIGPLAN conference on Object oriented programming systems languages and applications, pages 365–383, 2005.

[24] Microsoft. Microsoft SAL Annotations, 2011. http://msdn.microsoft.com/en-us/library/ms235402.aspx.

[25] Moodle. Moodle, 2011. http://moodle.org.

[26] Moodle. MSA-08-0013, 2011. http://moodle.org/mod/forum/discuss.php?d=101405.

[27] G. Naumovich and P. Centonze. Static analysis of role-based access control in J2EE applications. SIGSOFT Softw. Eng. Notes, 29:1–10, September 2004.

[11] B. C. G. McGraw and S. Migues. Building security in maturity model, 2011. www.bsimm2.com.

[12] M. Haﬁz, P. Adamczyk, and R. Johnson. Systematically eradicating data injection attacks using security-oriented program transformations. In Proceedings of the 1st International Symposium on Engineering Secure Software and Systems, ESSoS '09, pages 75–90. Springer-Verlag, 2009.

[28] OWASP. ESAPI Validator API, 2011. http://owasp-esapi-java.googlecode.com/svn/trunk_doc/latest/org/owasp/esapi/Validator.html.

[29] J. Reason. Human Error. Cambridge University Press, Cambridge, UK, 1990.

[30] A. Roller. Apache Roller, 2011. http://roller.apache.org.

[31] A. Roller. ROL-1766, 2011. https://issues.apache.org/jira/browse/ROL-1766.

[13] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D.-T. Lee, and S.-Y. Kuo. Securing web application code by static analysis and runtime protection. In Proceedings of the 13th international conference on World Wide Web, WWW '04, pages 40–52. ACM, 2004.

[14] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D. T. Lee, and S.-Y. Kuo. Verifying web applications using bounded model checking. In Proceedings of the 2004 International Conference on Dependable Systems and Networks, pages 199–, Washington, DC, USA, 2004. IEEE Computer Society.

[15] Inqscribe. Inqscribe, 2011. www.inqscribe.com.

[16] S. Institute. SANS Institute, 2011. www.sans.org.

[17] N. Jovanovic, C. Kruegel, and E. Kirda. Pixy: a static analysis tool for detecting web application vulnerabilities. In Security and Privacy, 2006 IEEE Symposium on, pages 6 pp. –263, May 2006.

[18] K. Karppinen, L. Yonkwa, and M. Lindvall. Why developers insert security vulnerabilities into their code. In Proceedings of the 2009 Second International Conferences on Advances in Computer-Human Interactions, ACHI '09, pages 289–294. IEEE Computer Society, 2009.

[19] D. E. Knuth. The errors of TeX. Softw. Pract. Exper., 19:607–685, July 1989.

[20] A. J. Ko and B. A. Myers. A framework and methodology for studying the causes of software errors in programming systems. J. Vis. Lang. Comput., 16:41–84, February 2005.

[32] P. Saxena, D. Akhawe, S. Hanna, F. Mao, S. McCamant, and D. Song. A symbolic execution framework for JavaScript. Technical Report UCB/EECS-2010-26, EECS Department, University of California, Berkeley, Mar 2010.

[33] H. Sharp, Y. Rogers, and J. Preece. Interaction Design: Beyond Human-Computer Interaction. Wiley, 2nd edition, 2007.

[34] F. Software. Fortify SCA, 2011. https://www.fortify.com/products/fortify360/source-code-analyzer.html.

[35] B. Taylor and S. Azadegan. Moving beyond security tracks: integrating security in CS0 and CS1. In Proceedings of the 39th SIGCSE technical symposium on Computer science education, SIGCSE '08, pages 320–324. ACM, 2008.

[36] VERACODE. State of Software Security Report Volume 1, 2, and 3, 2011. http://www.veracode.com/reports/index.html.

[37] J. Xie, B. Chu, and H. R. Lipford. IDEA: interactive support for secure software development. In Proceedings of the Third international conference on Engineering secure software and systems, ESSoS'11, pages 248–255. Springer-Verlag, 2011.

[38] J. Xie, H. R. Lipford, and B. Chu. Why do programmers make security errors? In Proceedings of 2011 IEEE Symposium on Visual Languages and Human Centric Computing, pages 161–164, 2011.