### 8. Conclusion

Proportional Rate Reduction (PRR) enhances fast recovery under practical network conditions. PRR operates effectively even when losses are significant, provides rapid recovery for short flows, and remains accurate even when acknowledgments are delayed, lost, or reordered. In live experiments, PRR reduced the latency of short Web transfers by 3-10% compared to standard Linux recovery. Additionally, PRR demonstrated smoother recovery for video traffic compared to the standard RFC 3517. Although these improvements may seem modest, it is important to note that even small delays, such as 100ms in page load times, have been shown to impact user satisfaction in multiple independent studies [25]. Based on its promising performance in live experiments, PRR has been accepted into the mainline Linux kernel as the default fast recovery algorithm and is proposed as an experimental RFC in the IETF [15].

Moving forward, we will re-evaluate the effectiveness of the Retransmission Timeout (RTO) mechanisms in practice. Our measurements indicate that timeouts (and subsequent exponential backoffs) in short flows account for over 60% of retransmissions. Most of these occur when flows are in the Open state and receive no duplicate acknowledgments. Our future research will explore whether and how timeouts can be improved, especially for short flows.

### 9. Acknowledgments

We would like to thank Ankur Jain, Bernhard Beck, Tayeb Karim, and John Reese for facilitating our experiments on live traffic. The following individuals provided valuable feedback to improve the paper: Larry Brakmo, Neal Cardwell, Jerry Chu, Ilpo Järvinen, Sivasankar Radhakrishnan, Neil Spring, Mukarram Bin Tariq, and our anonymous reviewers.

### 10. References

[1] State of the Internet, 2010. http://www.akamai.com/stateoftheinternet/

[2] Allman, M., Avrachenkov, K., Ayesta, U., Blanton, J., and Hurtig, P. Early retransmit for TCP and SCTP, May 2010. RFC 5827.

[3] Allman, M., Balakrishnan, H., and Floyd, S. Enhancing TCP’s loss recovery using limited transmit, January 2001. RFC 3042.

[4] Allman, M., Paxson, V., and Blanton, E. TCP congestion control, September 2009. RFC 5681.

[5] Balakrishnan, H., Padmanabhan, V. N., Seshan, S., Stemm, M., and Katz, R. H. TCP behavior of a busy internet server: Analysis and improvements. In Proc. of INFOCOMM (1998).

[6] Bennett, J. C., Partridge, C., and Shectman, N. Packet reordering is not pathological network behavior. IEEE/ACM Trans. on Networking (December 1999).

[7] Blanton, E., and Allman, M. Using TCP DSACKs and SCTP duplicate TSNs to detect spurious retransmissions, February 2004. RFC 3708.

[8] Blanton, E., Allman, M., Fall, K., and Wang, L. A conservative SACK-based loss recovery algorithm for TCP, 2003. RFC 3517.

[9] Floyd, S., Mahdavi, J., Mathis, M., and Podolsky, M. An extension to the SACK option for TCP, July 2000. RFC 2883.

[13] Ludwig, R., and Katz, R. H. The eifel algorithm: Making TCP robust against spurious retransmissions. (ACM) Computer Communication Review 30 (January 2000).

[14] Ludwig, R., and Meyer, M. The eifel detection algorithm for TCP, April 2003. RFC 3522.

[15] Mathis, M., Dukkipati, N., and Cheng, Y. Proportional rate reduction for TCP, March 2011. Work in progress, draft-mathis-tcpm-proportional-rate-reduction-00.txt.

[16] Mathis, M., and Mahdavi, J. Forward acknowledgment: refining TCP congestion control. SIGCOMM Comput. Commun. Rev. 26 (August 1996), 281–291.

[17] Mathis, M., and Mahdavi, J. TCP rate-halving with bounding parameters, December 1997. http://www.psc.edu/networking/papers/FACKnotes/current/

[18] Mathis, M., Mahdavi, J., Floyd, S., and Romanow, A. TCP selective acknowledgment options, October 1996. RFC 2018.

[19] Mathis, M., Semke, J., Mahdavi, J., and Lahey, K. The rate-halving algorithm for TCP congestion control, June 1999. draft-mathis-tcp-ratehalving-00.txt, http://www.psc.edu/networking/ftp/papers/draft-ratehalving.txt

[20] Petlund, A., Evensen, K., Griwodz, C., and Halvorsen, P. TCP enhancements for interactive thin-stream applications. In NOSSDAV (2008).

[21] Ramachandran, S. Web metrics: Size and number of resources. http://code.google.com/speed/articles/web-metrics.html

[22] Rewaskar, S., Kaur, J., and Smith, F. D. A performance study of loss detection/recovery in real-world TCP implementations. In Proc. of ICNP (2007).

[23] Sarolahti, P., and Kuznetsov, A. Congestion control in Linux TCP. In Proceedings of USENIX (2002), Springer, pp. 49–62.

[24] Scheffenegger, R. Improving SACK-based loss recovery for TCP, November 2010. Work in progress, draft-scheffenegger-tcpm-sack-loss-recovery-00.txt.

[25] Schurman, E., and Brutlag, J. The user and business impact of server delays, additional bytes, and HTTP chunking in web search. http://velocityconf.com/velocity2009/public/schedule/detail/8523

[26] Sun, P., Yu, M., Freedman, M. J., and Rexford, J. Identifying performance bottlenecks in CDNs through TCP-level monitoring. In SIGCOMM Workshop on Measurements Up the Stack (August 2011).

[10] Ha, S., Rhee, I., and Xu, L. CUBIC: a new TCP-friendly high-speed TCP variant. SIGOPS Oper. Syst. Rev. 42 (July 2008), 64–74.

[27] Touch, J. TCP control block interdependence, April 1997. RFC 2140.

[28] Yang, P., Luo, W., Xu, L., Deogun, J., and Lu, Y. TCP congestion avoidance algorithm identification. In Proc. of ICDCS (June 2011).

[29] Yang, Y., and Lam, S. General AIMD congestion control. Proc. International Conference on Network Protocols (November 2000).

### Summary Review Documentation for "Proportional Rate Reduction for TCP"

**Authors:** N. Dukkipati, M. Mathis, Y. Cheng, M. Ghobadi

**Reviewer #1**

**Strengths:**
- The A/B testing at scale gathers a wealth of data from production Web systems, providing insights into Web latency in practice.
- The TCP refinements lead to a modest reduction in loss for some cases and are useful, even if they are close to existing guidelines like Early Retransmit and Rate-Halving.

**Weaknesses:**
- There is a substantial penalty for any loss/retransmissions, and the TCP refinements only reduce it by 3-10%, which calls for a different approach to the problem.

**Comments to Authors:**
- More data should be presented, such as CDFs showing the variation in latency for different sizes, to better illustrate where connections with retransmissions break out in terms of latency.
- It would be beneficial to present data on the number of packets lost from these connections.
- Address the causes of outliers, particularly timeouts in the Open state, and why they are not being tackled first.
- Provide a comparison of latency before and after applying the techniques to show the improvement.
- Clarify the role of HTTP1.1 and persistent connections in the analysis.
- Define latency more clearly, including whether TCP connection setup is excluded and why.

**Reviewer #2**

**Strengths:**
- The proposed modifications to TCP are thoroughly evaluated with a large number of real flows terminating in Google servers, providing a detailed evaluation.

**Weaknesses:**
- The gains appear to be fairly small, and the authors do not convincingly demonstrate that this work is better than some alternate published work.
- The proportional rate reduction part is similar to GAIMD techniques designed as extensions to TCP about a decade ago.

**Comments to Authors:**
- The most impressive part is the evaluation using a large volume of real flows, which is likely to have a significant impact.
- However, the overall performance improvement is not more than 7-8%, and there is a large body of prior work in this domain.
- Consider comparing the proposal to older schemes like GAIMD and Binomial congestion control.
- Explain why not simply use RFC 3517 alone and what additional gains this work provides.
- The modification to early retransmit is similar to RFC 5827, and the work evaluates two of the three methods in RFC 5827.

**Reviewer #3**

**Strengths:**
- Clear writing, unique evaluation, important problem, useful solution, and authoritative description of Linux.

**Weaknesses:**
- Yet another TCP paper, and Figure 1 is not very effective.

**Comments to Authors:**
- Clarify what "The performance of connections experiencing losses is significantly slower than those with no losses" means in practice.
- Discuss whether Linux P2 is a significant problem and if quiet connections need to restart from slow start regardless of retransmission events.
- Highlight how this fix might improve perceived browser performance and whether users will see fewer spinning wheels.
- Appreciate the concise length of the paper.

**Reviewer #4**

**Strengths:**
- Problem identification and careful experimentation.

**Weaknesses:**
- Substantial gap between the severity of the problem and the modest improvement achieved by the suggested modifications.
- Unclear impact on large transfers and video streams.
- Lack of slicing losses by connection type and understanding the sources of losses.

**Comments to Authors:**
- The first parts of the paper are more interesting than the proposed modifications.
- Explore what an ideal retransmission mechanism could achieve.
- Investigate the causes of losses and whether they are due to congestion or buffer overflow.
- Determine if losses happen in large bursts and if end-to-end coding could help.
- Table 2 shows that nothing in the paper helps with timeouts in the Open state.
- Simplify sections 3.1 and 3.2, as they are not essential.
- Explain why ER does not help much with the latencies of connections on the tail.

**Reviewer #5**

**Strengths:**
- Real data on TCP performance in the wild against highly popular servers.
- Nice exposition of existing fast recovery mechanisms and their weaknesses.

**Weaknesses:**
- The problem does not seem very important, especially given the low gains achieved.
- Only ~6% of the connections suffer, and the proposed mechanism cuts down their latency by 10%.

**Comments to Authors:**
- Motivate the importance of the work, as it only affects 6% of responses and helps them by only 10%.
- The real value of the paper is the data on TCP retransmissions and the exposition of TCP recovery mechanisms.
- Consider sending the paper to CCR if it is not accepted.
- Include data from the India data center serving YouTube traffic.
- Clarify the experiments mentioned in section 6.5.
- Construct a fast recovery oracle to determine the maximum possible reduction in latency.

### Response from the Authors

**Summary of Changes Applied: "Improving TCP Loss Recovery"**

- **Major Changes:**
  - Included retransmission statistics and experiments with changes in an India data center serving YouTube traffic.
  - Focused the paper on PRR, unlike the original version, which had three loosely connected items: PRR, ER, and Google measurements.
  - Rewrote the introduction to provide a clear motivation: reducing TCP latency by improving fast recovery, which is key for loss recovery.
  - Illustrated the PRR algorithm and its properties through carefully chosen examples.

- **Other Changes and Comments on Reviews:**
  - **Concern: Substantial penalty (7-10X) for any losses/retransmissions, and the TCP refinements barely reduce it by 3-10%.**
    - Figure 1 compares response latency with the ideal to provide context on the latency disparity. Not all of this can be addressed by improving TCP's loss recovery, as latency also includes effects of slow user bandwidths and queueing delays. We included a CDF to show the variation in latencies between responses with/without retransmissions and the ideal latency of 1 RTT.
  - **Comparison with alternate published work such as GAIMD techniques and Binomial congestion control.**
    - GAIMD and Binomial are congestion control algorithms orthogonal to the current work. PRR is designed to work in conjunction with any congestion control algorithm, including GAIMD and Binomial.
  - **Additional gains relative to RFC 3517.**
    - RFC 3517 is overly aggressive in the presence of heavy losses, transmitting large bursts of retransmissions that incur further losses.
  - **Causes of losses and whether they happen in bursts.**
    - These are interesting questions but were not investigated in the current work.
  - **Timeouts in the Open state.**
    - This is an independent problem and not the focus of the current work on fast recovery.
  - **Only ~6% of the connections suffer retransmissions, and the proposed mechanisms cut down their latency by 10%.**
    - Even small changes are crucial in ultimately bringing the latency of a Web page as close to ideal as possible, where ideal is close to one round-trip time.