### Table 2: List of the Most Unactionable Advice Based on User Ratings

The first four columns indicate advice with a median rating of "not at all" confident and "very" time-consuming, disruptive, and/or difficult. The fifth column indicates expert-perceived efficacy, and the sixth column provides the expert-estimated median risk reduction for efficacious advice (negative for harmful advice).

| Confidence | Time-Consuming | Disruptive | Difficult | Efficacy | Risk Reduction |
|------------|-----------------|-------------|-----------|----------|----------------|
| 35%        | 30%             | 30%         | 50%       | 50%      | 35%            |
| 30%        | 40%             | 20%         | 50%       | 50%      | 30%            |
| 45%        | 10%             | 50%         | 50%       | 50%      | 45%            |

### Actionability of Security Advice

**Finance Advice:**
Advice related to finance was considered highly actionable. 94.1% of financial advice was perceived as at most "slightly" time-consuming or disruptive to implement, and more than 80% of this advice was perceived as at most "slightly" difficult to implement.

**Password Advice:**
Advice about passwords scored well on two of the four actionability submetrics. For more than 80% of password advice, people were at least "somewhat" confident they could implement it and perceived it as at most "slightly" difficult to implement.

**Least-Actionable Advice:**
The least-actionable advice pertains to data storage and network security. Data storage had the highest proportion of poor (lowest two ratings on the Likert scale) actionability ratings across all four metrics. More than half of the data storage imperatives received confidence responses of "slightly" or "not at all," and no advice about data storage was rated as "very" confident. Similarly, 58.8%, 41.2%, and 47.1% of the imperatives about data storage were rated at least "somewhat" time-consuming, disruptive, and difficult to implement, respectively. Network security advice performed nearly as poorly on three of the four actionability submetrics; participants were confident they could implement barely half the advice, and at least 40% of network security advice was perceived as "very" time-consuming or difficult to implement.

**Privacy Advice:**
Privacy advice was polarizing in terms of perceived actionability. Near-equal proportions of privacy advice were rated as at least "somewhat" time-consuming, disruptive, and difficult to implement.

### Comprehensibility by Topic

**Comprehension Scores:**
Documents related to finance achieved at least partial comprehension on average, with a mean Cloze score above 50%. Finance-related documents had particularly low variance in scores, with a standard deviation of 6.22%.

**Remaining Topics:**
The remaining topics had mean Cloze scores under 50%, indicating that the majority of test takers struggled to comprehend the average text on these topics. Password- and network-security-related documents had particularly low mean scores, with very wide score spreads. Passwords, being the most popular topic in the corpus, also had the highest standard deviation in Cloze scores, suggesting that the low scores may be partially due to the quantity of advice. On the other hand, network security is a particularly technical topic, so the low scores may relate to additional complexity or jargon.

**Reading Ease Perceptions:**
There was no significant difference in reading ease perceptions among different topics (p = 0.999, Kruskal-Wallis).

### Comprehensibility by Domain

**Most Comprehensible Sources:**
The most comprehensible sources are general news channels, subject-matter experts (SMEs), non-profits, and security and computer-repair companies. To understand whether some advice-givers provided more readable advice than others, we examined Cloze scores grouped by domain. Figure 9 summarizes these results. The Cloze scores of the domains were significantly different: p < 0.001, ANOVA (all pairwise tests remain significant after Holm-Bonferroni correction). Of the 30 domain groups considered, seven scored above 50% (mean across documents): SMEs, general news outlets, how-to websites, non-tech-focused and tech-focused non-profits, security companies, and computer-repair companies.

**Government Organizations:**
Among U.S. government organizations, ic3.gov, whitehouse.gov, ftc.gov, and dhs.gov had average scores mapping to partial comprehension or better. The remaining domains performed worse. We had only five non-U.S. government domains in our dataset, three of which (csir.co.za, staysmartonline.gov.au, and connectsmart.gov.nz) had mean scores of partial comprehension or above.

**Child-Focused Organizations:**
Encouragingly, documents from non-profit organizations (both technology-focused and not) aimed at children (e.g., childline.org.uk, netsmartz.org, safetynetkids.org.uk) were among the most readable. However, content collected from school websites was not particularly readable, with mean Cloze scores indicating low comprehension, suggesting that schools may be better off obtaining content from child-focused non-profits.

**Technical Non-Profits:**
Documents from non-profit organizations with a technical focus had wider variance. Documents from the Tor Project, GNU, and techsoup.org had mean Cloze scores of at least partial comprehension. However, documents from nine other technical non-profits, including Mozilla, Chromium, and Ubuntu, as well as organizations focused specifically on helping non-experts (e.g., libraryfreedomproject.org), had mean Cloze scores well below this threshold. Documents from the EFF and Tactical Tech-sponsored organizations also had mean Cloze scores mapping to low comprehension. This is important, as documents from these two organizations make up 21% of our corpus.

**Corporations:**
Security-focused companies and those offering computer-repair services scored very high on comprehensibility. We hypothesize that for these companies, providing readable materials may be a business requirement. On the other hand, non-security-focused companies, including some frequently criticized for privacy and security issues, scored poorly: mean Cloze scores for Google, Facebook, and Apple were 45.1%, 37.9%, and 41.7%, respectively.

**Low-Comprehension Platforms:**
Seven of the 30 advice-givers we examined provided particularly difficult-to-read advice (mean Cloze scores under 40%): SANS (sans.org), security forums (wilderssecurity.com), MOOCs (lynda.com, khanacademy.org), consumer rating sites (consumerreports.org, av-comparatives.org), Facebook, Technical Q&A websites (stackoverflow.com, stackexchange.com), and academic publications. While it is not necessarily problematic for more technical content such as academic security publications and security forums to be incomprehensible to the average person, low readability from organizations such as the Library Freedom Project, MOOCs, Facebook Help pages, and Technical Q&A websites may make it difficult for non-experts to stay secure.

### Discussion

This work makes three primary contributions:

1. **Taxonomy of Security Advice:**
   - We create a taxonomy of 374 pieces of security advice, providing a comprehensive point-in-time taxonomy of 374 end-user security behaviors, including 204 pieces of security advice not previously catalogued in the literature. The full set of behaviors can be explored here: [https://securityadvice.cs.umd.edu](https://securityadvice.cs.umd.edu). This taxonomy provides insight into the scope and quantity of advice received by users, a tool for researchers, and a mechanism for the broader security community to improve security advice.

2. **Axes of Security Advice Quality:**
   - Our approach to evaluating security advice identifies axes of quality (comprehensibility, actionability, and efficacy) and the measurement approaches designed to assess them. These can be applied to new advice to ensure higher-quality, more effective advice. Initial validation using our work shows that our metrics correlate with reported adoption, lending support for the importance of the advice quality factors we have operationalized. All four of our actionability sub-metrics correlate with reported behavior adoption by users. Additionally, priority ranking, one of our metrics of efficacy, strongly correlates with reported adoption for both general users and experts.

3. **Evaluation of Comprehensibility, Perceived Efficacy, and Perceived Actionability:**
   - By applying our metrics to the taxonomy, we provide a thorough and novel characterization of the quality of the security-advice ecosystem. While prior work focused on expert and user prioritization of a small set of security advice, we evaluate a much larger set and conduct a more comprehensive evaluation considering comprehensibility, perceived actionability, perceived efficacy, and their interactions. We find that security advice is generally perceived as fairly actionable and effective, but users do not consistently adopt even a fraction of this advice, partly due to mis-comprehension and a crisis of advice prioritization.

### Next Steps

Our results suggest two key directions for moving toward a healthier ecosystem of security advice:

1. **Measurement and Minimality:**
   - There is a need to narrow down a multitude of relatively actionable but half-heartedly followed security behaviors to a critical set that are most important for keeping users safe. Rigorous measurement is required to evaluate which behaviors are the most effective, for which users, in which threat scenarios. A strong commitment to minimality and practicality is needed to identify the smallest and most easily actionable set of behaviors to provide maximum user protection.

2. **Fixing Existing Advice:**
   - Some topics of advice, such as data storage and network security, performed consistently worse across our evaluations and are good candidates for revision and improvement. Future work may also examine the effectiveness of combining diverse sets of advice types and explore mechanisms for personalizing advice to users or helping users filter to advice that is most relevant to them.

### Acknowledgements

We are grateful to the reviewers and especially to our shepherd Mary Ellen Zurko for their feedback and guidance. This material is based upon work supported by a UMIACS contract under the partnership between the University of Maryland and DoD. Elissa M. Redmiles additionally wishes to acknowledge support from the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE 1322106 and a Facebook Fellowship.

### References

[1] Alessandro Acquisti, Idris Adjerid, Rebecca Balebako, Laura Brandimarte, Lorrie Faith Cranor, Saranga Komanduri, Pedro Giovanni Leon, Norman Sadeh, Florian Schaub, Manya Sleeper, et al. Nudges for privacy and security: Understanding and assisting users' choices online. ACM Computing Surveys (CSUR), 50(3):44, 2017.

[2] Elham Al Qahtani, Mohamed Shehab, and Abrar Aljohani. The effectiveness of fear appeals in increasing smartphone locking behavior among Saudi Arabians. In SOUPS 2018: Symposium on Usable Privacy and Security, 2018.

[3] A. Beautement, M. A. Sasse, and M. Wonham. The compliance budget: Managing security behavior in organizations. In NSPW 2009: New Security Paradigms Workshop, 2008.

[4] JM Blythe and CE Lefevre. Cyberhygiene insight report. 2017.

[5] Joseph Bonneau, Cormac Herley, Paul C Van Oorschot, and Frank Stajano. The quest to replace passwords: A framework for comparative evaluation of web authentication schemes. In 2012 IEEE Symposium on Security and Privacy, pages 553â€“567. IEEE, 2012.

[6] John R Bormuth. Comparable cloze and multiple-choice comprehension test scores. Journal of Reading, 1967.

[7] C. Bravo-Lillo, S. Komanduri, L. F. Cranor, R. W. Reeder, M. Sleeper, J. Downs, and S. Schechter. Your at-