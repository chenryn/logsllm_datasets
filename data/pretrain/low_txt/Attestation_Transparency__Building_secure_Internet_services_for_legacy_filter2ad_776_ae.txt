### Protecting Against Side-Channel Attacks

The operating system is in a prime position to launch side-channel attacks, as well as Iago attacks [11]. Intel SGX, while designed to provide secure enclaves, also has critical software components that may be more vulnerable to compromise than the hardware itself [14]. If an attacker gains control over the SGX on a system running a secure service, they can achieve access similar to directly compromising the service. However, even if SGX is compromised, future systems might offer enhanced secure enclave functionality that can be utilized for the secure service design proposed in this paper.

### 7.3 Adoption

Previous Trusted Computing approaches have seen limited practical use. Our scheme differs from most in that it requires hardware and software support only on the server side. A single entity can adopt our approach independently, without being constrained by their customers' hardware or software choices.

Some service providers may be hesitant to adopt our scheme. However, there are compelling reasons to consider it. The Information Technology and Innovation Foundation (ITIF) has predicted that the U.S. cloud computing industry could lose up to $35 billion by 2016 due to a loss of trust in the post-Snowden era [18]. Forrester Research has estimated that these losses could eventually reach up to $180 billion [35]. Our scheme provides a mechanism to partially address these trust concerns.

### 8. Related Work

Our work builds on several important advancements in the field.

#### Early Research on System Integrity Verification

An early line of research focused on verifying the integrity of a known system stack. This was crucial because malicious or unreliable system software could prevent the secure operation of even well-written applications. The AEGIS system [5] proposed a chain of integrity checks where each step in the boot process verifies the next before proceeding. This work has been extended to protect other critical software, such as BIOS code, which, if corrupted, presents insurmountable barriers for safe operations. Parno et al. provide an overview of the relevant techniques and research in this area [29].

#### Code as a First-Class Security Principal

Wobber et al. described how the Taos operating system treats code (represented, for example, as a cryptographic hash) as a first-class security principal that can be authenticated [39]. This enabled distributed programs to establish an authentication and authorization model as rich and reliable as that for a single program running in batch mode on a single machine.

However, it is not always desirable to attest directly to code principals, as software can change frequently and exist in many different configurations. Property-based attestation [12] aimed to solve this by using properties of software, rather than the software itself, as security principals.

#### Key Management and Remote Verification

As secure distributed computing relied on increasingly well-studied and accepted cryptographic mechanisms, researchers sought a key management mechanism that allowed remote verification of program identity and isolation properties of program elements running on widely dispersed machines. Trusted computing primitives, combining a discrete security chip [37] with processor features [20], provided the necessary underlying capabilities. Brannock et al. proposed a Secure Execution Environment [9] with properties similar to our secure enclave. The CloudProxy Tao [25] is a consolidated execution environment implemented recursively at each layer of software (VMM, OS, Linux process, container, plug-in) that programmers could generally use without extensive training using existing programming tools.

The relentless march towards cloud computing made these capabilities more critical, as cloud data centers are widely dispersed and employ powerful insiders who, absent these capabilities, can access or control keys and undetectably change code running security-critical services. These new primitives allowed the safe operation of well-written programs on computers that also ran untrustworthy applications written by adversaries.

#### Minimizing the TCB Footprint

Researchers recognized that large Trusted Computing Bases (TCBs) made security difficult to assure and maintain. To address this, Hawblitzel et al. proposed a system using Ironclad Apps [16] for secure remote computations by formally verifying the entire server stack. Flicker [26] emphasized the application of Trusted Computing primitives on small services within an application, isolating them from the rest of the application and the operating system. For example, Flicker enclaves were well-suited as a virtual Hardware Security Module or as an authentication enclave that used a long-term secret. The security model ensured that the OS, other applications, and other portions of the same application could not access private key material. However, it was shown that Intel Trusted Execution Technology, which Flicker is based on, is not secure [40].

#### Other Systems for Cloud and Trusted Computing

Various other systems were proposed to integrate cloud computing with trusted computing, such as Self-service Cloud Computing [10], Cryptography-as-a-Service [7], and MyCloud [24]. These systems focused on providing trust in the cloud hypervisor to a customer of the cloud service provider, rather than providing trust of Internet services to users of those services.

SGX [19] employed specialized hardware for this purpose and also encrypted enclave memory in DRAM, protecting against adversaries with system bus access. Several recent works have used SGX to protect cloud service components. Haven [6] employed SGX to run MS SQL Server entirely in a secure enclave, allowing clients to benefit from the Attestation Transparency Framework to verify the server they are connecting to. VC3 [33] implements secure MapReduce operations for the Hadoop distributed computation platform using SGX.

#### Attacks on PKI and Certificate Transparency

Attacks on Public Key Infrastructure (PKI) [1] threatened the trustworthiness of co-dependent services, prompting the development of Certificate Transparency [22] to highlight misissued certificates.

### 9. Conclusion

In this paper, we have demonstrated how to build secure services and enable clients to verify those services. This brings to clients the benefits of the cloud, including scalability, availability, elasticity, and maintainability, while guarding against principal attacks (e.g., from insiders) that make cloud usage worrisome.

We have presented a system that enables flexible policy options, allowing users to meaningfully choose security properties. Policies can be established by anyone, including software developers, auditors, independent organizations, and communities. The policies are enforced through a compulsory transparency mechanism that brings malicious intent to light, deterring bad actors since they can be easily identified for legal action or reputation damage.

We have extended the certificate transparency model to code, providing a technical mechanism for users to rely on the security principal that ultimately ensures security properties—code. Additionally, we provide flexible trust models that allow any user to meaningfully adduce behavior guarantees from actual implementations. We demonstrate that the resulting systems can be nearly as efficient and scalable as existing services and provide strong protection from mischievous providers, foreign governments, and sloppy cloud data center operations.

All proposed mechanisms include incremental deployment paths, making our techniques usable now for present-day clients, while future deployment will increase security guarantees. In conclusion, we have presented a flexible, practical mechanism to build secure Internet services.

### 10. Acknowledgements

We thank Jon McCune and our anonymous reviewers for their feedback. This work was supported by Intel through the ISTC for Secure Computing, AFOSR under MURI award FA9550-12-1-0040, and NSF under CCF-0424422.

### 11. References

[1] Comodo, DigiNotar Attacks Expose Crumbling Foundation of CA System. ThreatPost, 2011. URL: https://threatpost.com/090211/75609.

[2] D. Akhawe, F. Marier, F. Braun, and J. Weinberger. Subresource Integrity. W3C working draft, W3C, July 2015. URL: http://www.w3.org/TR/SRI/.

[3] D. Akhawe, P. Saxena, and D. Song. Privilege Separation in HTML5 Applications. In 21st USENIX Security Symposium, pages 429–444. USENIX, Aug. 2012.

[4] I. Anati, S. Gueron, S. Johnson, and V. Scarlata. Innovative Technology for CPU Based Attestation and Sealing. In Proceedings of the 2nd International Workshop on Hardware and Architectural Support for Security and Privacy, 2013.

[5] W. A. Arbaugh, D. J. Farber, and J. M. Smith. A secure and reliable bootstrap architecture. In IEEE Symposium on Security and Privacy, pages 65–71, 1997.

[6] A. Baumann, M. Peinado, and G. Hunt. Shielding Applications from an Untrusted Cloud with Haven. In 11th USENIX Symposium on Operating Systems Design and Implementation, pages 267–283. USENIX Association, Oct. 2014.

[7] S. Bleikertz, S. Bugiel, H. Ideler, S. Nürnberger, and A.-R. Sadeghi. Client-controlled cryptography-as-a-service in the cloud. In Proceedings of the 11th International Conference on Applied Cryptography and Network Security, pages 19–36, 2013.

[8] R. Boivie and P. Williams. SecureBlue++: CPU support for secure execution. Technical report, IBM Research Report, 2013.

[9] K. Brannock, P. Dewan, F. McKeen, and U. Savagaonkar. Providing a Safe Execution Environment. Intel Technology Journal, 13(2):36–51, 2009.

[10] S. Butt, H. A. Lagar-Cavilla, A. Srivastava, and V. Ganapathy. Self-service cloud computing. In Proceedings of the 2012 ACM Conference on Computer and Communications Security, pages 253–264, 2012.

[11] S. Checkoway and H. Shacham. Iago attacks: Why the system call API is a bad untrusted RPC interface. In Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS ’13, pages 253–264. ACM, 2013.

[12] L. Chen, R. Landfermann, H. Löhr, M. Rohe, A.-R. Sadeghi, and C. Stüble. A protocol for property-based attestation. In Proceedings of the 1st ACM Workshop on Scalable Trusted Computing, pages 7–16, 2006.

[13] D. Cooper, S. Santesson, S. Farrell, S. Boeyen, R. Housley, and W. Polk. Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile. RFC 5280 (Proposed Standard), May 2008. Updated by RFC 6818. URL: http://www.ietf.org/rfc/rfc5280.txt.

[14] V. Costan and S. Devadas. Intel SGX explained. Cryptology ePrint Archive, Report 2016/086, 2016. https://eprint.iacr.org/2016/086.

[15] E. Felten. A court order is an insider attack, 2013. URL: https://freedom-to-tinker.com/blog/felten/a-court-order-is-an-insider-attack/.

[16] C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan, B. Parno, D. Zhang, and B. Zill. Ironclad Apps: End-to-End Security via Automated Full-System Verification. In 11th USENIX Symposium on Operating Systems Design and Implementation, pages 165–181. USENIX Association, Oct. 2014.

[17] M. Hoekstra, R. Lal, P. Pappachan, C. Rozas, V. Phegade, and J. del Cuvillo. Using Innovative Instructions to Create Trustworthy Software Solutions. In Proceedings of the 2nd International Workshop on Hardware and Architectural Support for Security and Privacy, 2013.

[18] Information Technology and Innovation Foundation. How much will PRISM cost the U.S. cloud computing industry?, 2013. URL: http://www.itif.org/2013-cloud-computing-costs.pdf.

[19] Intel Corporation. Intel Software Guard Extensions Programming Reference, October 2014.

[20] Intel Corporation. Intel 64 and IA-32 Architectures, Software Developer’s Manual, volume 2C: Instruction Set Reference, chapter 5: Safer Mode Extensions Reference. 2015.

[21] Intel Corporation. Intel Software Guard Extensions Enclave Writer’s Guide, 2015.

[22] B. Laurie, A. Langley, and E. Kasper. Certificate Transparency. RFC 6962 (Experimental), June 2013. URL: http://www.ietf.org/rfc/rfc6962.txt.

[23] N. Lawson. Final post on JavaScript crypto, 2010. URL: http://rdist.root.org/2010/11/29/final-post-on-javascript-crypto/.

[24] M. Li, W. Zang, K. Bai, M. Yu, and P. Liu. MyCloud: Supporting user-configured privacy protection in cloud computing. In Proceedings of the 29th Annual Computer Security Applications Conference, pages 59–68, 2013.

[25] J. L. Manferdelli, T. Roeder, and F. B. Schneider. The CloudProxy Tao for Trusted Computing. Technical Report UCB/EECS-2013-135, EECS Department, University of California, Berkeley, Jul 2013. URL: https://github.com/jlmucb/cloudproxy.

[26] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter, and H. Isozaki. Flicker: An Execution Infrastructure for TCB Minimization. In Proceedings of the 3rd ACM SIGOPS/EuroSys European Conference on Computer Systems, pages 315–328. ACM, 2008.

[27] F. McKeen, I. Alexandrovich, A. Berenzon, C. Rozas, H. Shafi, V. Shanbhogue, and U. Savagaonkar. Innovative Instructions and Software Model for Isolated Execution. In Proceedings of the 2nd International Workshop on Hardware and Architectural Support for Security and Privacy, 2013.

[28] B. Parno, J. R. Lorch, J. R. Douceur, J. Mickens, and J. M. McCune. Memoir: Practical state continuity for protected modules. In 32nd IEEE Symposium on Security and Privacy, pages 379–394, 2011.

[29] B. Parno, J. M. McCune, and A. Perrig. Bootstrapping trust in commodity computers. In 31st IEEE Symposium on Security and Privacy, pages 414–429, 2010.

[30] T. Ptacek. JavaScript Cryptography Considered Harmful, 2011. URL: http://www.matasano.com/articles/javascript-cryptography/.

[31] Rust programming language. https://www.rust-lang.org/.

[32] P. Saint-Andre and J. Hodges. Representation and Verification of Domain-Based Application Service Identity within Internet Public Key Infrastructure Using X.509 (PKIX) Certificates in the Context of Transport Layer Security (TLS). RFC 6125 (Proposed Standard), Mar. 2011. URL: http://www.ietf.org/rfc/rfc6125.txt.

[33] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis, M. Peinado, G. Mainar-Ruiz, and M. Russinovich. VC3: Trustworthy Data Analytics in the Cloud Using SGX. In 36th IEEE Symposium on Security and Privacy, pages 38–54, May 2015.

[34] R. Sleevi and M. Watson. Web Cryptography API. W3C candidate recommendation, W3C, Dec. 2014. URL: http://www.w3.org/TR/WebCryptoAPI/.

[35] J. Staten. The cost of PRISM will be larger than ITIF projects. Forrester Research, 2013. URL: http://blogs.forrester.com/james_staten/13-08-14-the_cost_of_prism_will_be_larger_than_itif_projects.

[36] P. Stone. Pixel perfect timing attacks with HTML5. Presented at Black Hat USA 2013, 2013. URL: http://www.contextis.com/documents/2/Browser_Timing_Attacks.pdf.

[37] Trusted Computing Group. TPM Main Specification, 2011. URL: http://www.trustedcomputinggroup.org/resources/tpm_main_specification.

[38] J. Winter. Trusted Computing Building Blocks for Embedded Linux-based ARM TrustZone Platforms. In Proceedings of the 3rd ACM Workshop on Scalable Trusted Computing, pages 21–30. ACM, 2008.

[39] E. Wobber, M. Abadi, M. Burrows, and B. Lampson. Authentication in the Taos operating system. ACM Trans. Computer Systems, 12(1):3–32, 1994.

[40] R. Wojtczuk and J. Rutkowska. Attacking Intel Trusted Execution Technology. Presented at Black Hat DC 2009, 2009. URL: http://invisiblethingslab.com/resources/bh09dc/AttackingIntelTXT-slides.pdf.

[41] Zetetic LLC. SQLCipher. https://www.zetetic.net/sqlcipher/.