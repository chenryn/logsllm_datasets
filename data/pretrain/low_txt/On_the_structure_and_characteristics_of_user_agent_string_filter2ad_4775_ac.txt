### Overview of Microsoft Browsers' Compatibility View List

We first became aware of the compatibility view list while reviewing an alert generated by an internal traffic quality monitor designed to identify anomalies in the distribution of user agents. The compatibility view list, which is updated monthly, includes a wide variety of domains such as publishers, government websites, and financial companies. As of the time of writing, the current XML file for Edge4 contains approximately 1,600 domains.

For example, the current Internet Explorer list5 indicates that when visiting the financial site chase.com, the browser should use the Firefox 22 token, represented in the file as:
```
Mozilla/5.0 ($PLATFORM; Trident/7.0; rv:11.0) like Gecko/20100101 Firefox/22.0
```
This user agent (UA) string contains the Microsoft-specific token "Trident" but also includes an outdated version of Firefox.

### Anomalous User Agent Instances

The second anomalous instance concerns a significant shift within the UA space that occurred in 2015. In April of that year, the daily volume of the following Android UA suddenly increased from around 10 records per day to around 100 million records per day:
```
Mozilla/5.0 (Android; U; Android 2.1; en-us;) AppleWebKit/525.10 (KHTML,like Gecko)
```
Prior to April, the volume of this UA was minimal. By July 2015, this UA was among the top 100 worldwide. This event was discovered during a routine manual review of data quality. Figure 5 illustrates the daily volume of this Android UA anomaly during the summer of 2015.

This UA belongs to a device running Android version 2.1, which was most prevalent during 2010–2011. Therefore, the data showed a sudden large shift towards a browser version that was four years out of date. This event was visible from the perspectives of publishers, brands, and ad networks. No single publisher, ad campaign, or other entity appeared to be the target of this traffic. Since comScore also collects browser cookie information, we were able to track the evolution of several cookies as they transitioned from a current browser to the anomalous one and back again. This allowed for a partial diagnosis: the event appeared to be mostly related to the Facebook app running on Samsung devices. We conjecture that a software misconfiguration released in April 2015 by one of Samsung, Google, or Facebook was the underlying cause. A more precise diagnosis was not attempted since the event, despite its large scale and obvious inaccuracy, appeared benign.

### Related Work

The HTTP User-Agent string has been used in numerous prior studies to estimate browser version populations, operating system version prevalence, and device populations, particularly mobile handheld devices [13, 15, 19, 24]. These studies have noted that their population estimates align with industry estimates provided by companies such as netmarketshare.com. Third-party services like udger.com and deviceatlas.com provide UA string parsing libraries and device catalogs to help companies track various subpopulations of visitors to their websites. Maier et al. have used the combination of UA strings and client IP addresses to identify multiple devices behind NAT devices [19]. Our results can inform these string parsing libraries and device catalogs.

The UA string is commonly used by servers to deliver appropriately-sized content to mobile devices and other devices with constrained screen sizes. Many web application frameworks contain built-in capabilities for providing different content variants based on the UA string [1]. Some researchers have relied on this behavior by spoofing the UA request header to analyze differences in content delivered to mobile versus desktop devices [21, 26].

RFC7231 recommends that clients should not use UA strings with "needlessly fine-grained detail" to avoid host fingerprinting [22]. Prior studies have evaluated the potential for the UA string to be used to identify users [7, 11, 27]. Yen et al. found that 60–70% of users could be identified through the UA string [27], similar to findings by Eckersley [11]. Our results complement and enhance those of [27] in the following ways: (1) the long tail in observed UAs suggests users may be identified as shown in earlier work, but (2) our analysis of the time-varying nature of observed UAs suggests that anonymity sets evolve rapidly over hours and days due to user behavior, software updates, and browser behavior.

Other studies have evaluated UA strings to detect the presence of malware by using anomalies such as misspellings and inconsistent information in HTTP headers [14, 16, 23]. Kotov and Massacci studied the source code of several exploit kits and found that server-side malware used the UA string presented by clients to detect potentially vulnerable operating systems and devices [17]; the exploit code would mimic an "innocent" site if the UA indicated a non-vulnerable host.

### Summary and Conclusions

Analyzing User Agent strings transferred during web transactions offers valuable insights into understanding client systems on the Internet. In this paper, we describe our study of UAs based on a corpus of over 1 billion UA strings collected over two years by comScore. To conduct this study, we constructed a robust UA parsing and analysis infrastructure. Our analysis of the general characteristics of UA strings reveals that the most prevalent strings comprise about 26% of all UAs and are composed of the expected instances of popular platforms such as Google, Microsoft, and Apple. We also find that the rank-frequency distribution of strings follows a power law. Our analysis of UAs observed at multiple time scales indicates dynamic characteristics that can be explained by day-to-day user behavior and periodic updates to hardware and software platforms. Finally, we examine UA strings identified as anomalous or pertaining to unwanted or malicious activity, revealing unexpected anomalies.

In ongoing work, we continue to expand and drill down into our analyses. We expect this will reveal a variety of characteristics, especially in the long tail of the data, that will improve analysis, testing, and content negotiation capabilities.

### Acknowledgments

We thank the anonymous reviewers and our shepherd, Theophilus Benson, for their feedback. This material is based upon work supported by DHS grant BAA 11-01 and AFRL grant FA8750-12-2-0328. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the DHS or AFRL.

### References

[1] [n. d.]. Action Pack Variants (Ruby on Rails 4.1 Release Notes). http://edgeguides.rubyonrails.org/4_1_release_notes.html#action-pack-variants. ([n. d.]). Accessed August 2017.
[2] [n. d.]. Panopticlick. ([n. d.]). https://panopticlick.eff.org/
[3] [n. d.]. Udger. ([n. d.]). https://udger.com/resources/ua-list
[4] [n. d.]. Understanding the compatibility view list. https://msdn.microsoft.com/en-us/library/gg622935(v=vs.85).aspx. ([n. d.]). Accessed August 2017.
[5] [n. d.]. UserAgentString. ([n. d.]). http://www.useragentstring.com/pages/useragentstring.php
[6] [n. d.]. WhatIsMyBrowser.com. ([n. d.]). https://www.whatismybrowser.com/developers/tools/user-agent-parser/browse
[7] Károly Boda, Ádám Máté Földes, Gábor György Gulyás, and Sándor Imre. 2011. User tracking on the web via cross-browser fingerprinting. In Nordic Conference on Secure IT Systems. 31–46.
[8] Aaron Cahn, Scott Alfeld, Paul Barford, and S. Muthukrishnan. 2016. An Empirical Study of Web Cookies. In Proceedings of the 25th International Conference on World Wide Web (WWW ’16). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 891–901. https://doi.org/10.1145/2872427.2882991
[9] Shauvik Roy Choudhary, Husayn Versee, and Alessandro Orso. 2010. Webdiff: Automated identification of cross-browser issues in web applications. In IEEE International Conference on Software Maintenance (ICSM). 1–10.
[10] Media Ratings Council. [n. d.]. Invalid Traffic Detection and Filtration Guidelines Addendum. ([n. d.]). http://mediaratingcouncil.org/101515_IVT%20Addendum%20FINAL%20(Version%201.0).pdf
[11] Peter Eckersley. 2010. How unique is your web browser?. In International Symposium on Privacy Enhancing Technologies Symposium. 1–18.
[12] EF Foundation. [n. d.]. Panopticlick. ([n. d.]). https://panopticlick.eff.org/
[13] Aaron Gember, Ashok Anand, and Aditya Akella. 2011. A comparative study of handheld and non-handheld traffic in campus Wi-Fi networks. In International Conference on Passive and Active Network Measurement. 173–183.
[14] Martin Grill and Martin Rehák. 2014. Malware detection using HTTP user-agent discrepancy identification. In Information Forensics and Security (WIFS), 2014 IEEE International Workshop on. 221–226.
[15] Sunghwan Ihm and Vivek S Pai. 2011. Towards understanding modern web traffic. In Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement conference. 295–312.
[16] Nizar Kheir. 2013. Analyzing HTTP user agent anomalies for malware detection. In Data Privacy Management and Autonomous Spontaneous Security. 187–200.
[17] Vadim Kotov and Fabio Massacci. 2013. Anatomy of exploit kits. In International Symposium on Engineering Secure Software and Systems. 181–196.
[18] Balachander Krishnamurthy. 2001. Web protocols and practice: HTTP/1.1, Networking protocols, caching, and traffic measurement. Addison-Wesley Professional.
[19] Gregor Maier, Fabian Schneider, and Anja Feldmann. 2010. A first look at mobile hand-held device traffic. In International Conference on Passive and Active Network Measurement. 161–170.
[20] Ali Mesbah and Mukul R Prasad. 2011. Automated cross-browser compatibility testing. In Proceedings of the 33rd International Conference on Software Engineering. 561–570.
[21] Jitu Padhye and Henrik Frystyk Nielsen. 2012. A comparison of SPDY and HTTP performance. Technical Report MSR-TR-2012-102.
[22] J. Reschke and R. Fielding. 2014. RFC 7231: Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content. http://tools.ietf.org/html/rfc7231. (June 2014).
[23] Christian Rossow, Christian J Dietrich, Herbert Bos, Lorenzo Cavallaro, Maarten Van Steen, Felix C Freiling, and Norbert Pohlmann. 2011. Sandnet: Network traffic analysis of malicious software. In Proceedings of the First Workshop on Building Analysis Datasets and Gathering Experience Returns for Security. 78–88.
[24] Fabian Schneider, Bernhard Ager, Gregor Maier, Anja Feldmann, and Steve Uhlig. 2012. Pitfalls in HTTP traffic measurements and analysis. In International Conference on Passive and Active Network Measurement. 242–251.
[25] Kevin Springborn and Paul Barford. 2013. Impression Fraud in On-line Advertising via Pay-Per-View Networks. In USENIX Security. 211–226.
[26] Paul J Timmins, Sean McCormick, Emmanuel Agu, and Craig E Wills. 2006. Characteristics of mobile web content. In Hot Topics in Web Systems and Technologies, 2006. HOTWEB’06. 1st IEEE Workshop on. 1–10.
[27] Ting-Fang Yen, Yinglian Xie, Fang Yu, Roger Peng Yu, and Martin Abadi. 2012. Host Fingerprinting and Tracking on the Web: Privacy and Security Implications. In NDSS.