### 2.3 Scam and Spam Campaign Lifetimes

Our analysis revealed that 2,334 scams were advertised by an average of 137 spam emails each. To determine the lifetime of a spam campaign for a specific scam, we measured the time between the first and last spam email messages advertising that scam. Figure 11 illustrates the distribution of these spam campaign lifetimes. Compared to the lifespan of scam sites, most spam campaigns are relatively short. Over 50% of the campaigns lasted less than 12 hours, over 90% lasted less than 48 hours, and 99% lasted less than three days. In general, the lifecycle of a typical scam begins with a short spam campaign lasting approximately half a day, while the scam site remains active for at least a week.

The relative lifetimes of spam campaigns and scam hosts reflect the different operational requirements of these services. Spammers need only a brief window to distribute their spam globally; once the spam is sent, the spam relays are no longer needed for that particular scam. In contrast, scam hosts must remain responsive and available for extended periods to attract and interact with potential victims. Essentially, spam serves as a form of blanket advertising that requires no user interaction, whereas scam hosting is a service that fundamentally depends on user engagement to succeed.

### 2.4 Stability of Scam Hosting Infrastructure

A profitable scam requires stable infrastructure to serve potential customers at any time and for as long as the scam is active. To assess the stability of scam hosting infrastructure, we periodically probed each scam host over a week to measure its availability. During this process, we also used p0f to fingerprint the host operating systems and link connectivity.

We calculated scam availability as the ratio of successful web page downloads to the total number of download attempts within the overall lifetime of the scam. For example, if a scam lasted only three days, we computed availability only during those days. Our results showed that over 90% of scams had an availability of 99% or higher, with the remaining having availabilities of 98% or higher. According to p0f, more scams ran on Unix or server appliances (43%) than on Windows systems (30%), and all reported good link connectivity. These findings indicate that scam hosting is highly reliable within the lifetime of a scam.

### 2.5 Geographic and Network Locations of Scam Hosts

Next, we examined both the network and geographic locations of scam hosts. For comparison, we also analyzed the locations of the spam relays that sent the spam in our trace. This comparison highlights how the different requirements of these services influence their global and network distributions.

#### 2.5.1 Network Location

The network locations of spam relays and scam hosts show some consistency. Figure 12 displays the cumulative distribution of IP addresses for spam relays and scam hosts in our trace. The IP addresses of most spam relays and scam hosts fall into two ranges: 58.* to 91.* and 200.* to 222.*. However, within these ranges, the concentrations differ. Over 60% of spam relays fall into the first address range, distributed somewhat evenly except for a gap between 70.* and 80.*. Approximately half of the scam hosts also fall into the first address range, but most of these are concentrated in the 64.* to 72.* subrange, with relatively few in the second half of the range. Similarly, scams are more uniformly distributed within the second address range.

#### 2.5.2 Geographic Location

To understand how these variations in network address concentrations map to geographic locations, we used Digital Element’s NetAcuity tool to map the IP addresses of scam hosts to latitude and longitude coordinates. Table 4 shows the top ten countries containing scam hosts in our trace. Interestingly, nearly 60% of the scam hosts are located in the United States. Overall, 14% are located in Western Europe and 13% in Asia. For comparison, Table 5 shows the top ten countries containing spam relays. The geographic distributions for spam relays are quite different, with only 14% located in the United States, 28% in Western Europe, and 16% in Asia.

The strong bias toward locating scam hosts in the United States suggests that geographic location is more important to scammers than to spammers. This bias can be attributed to several factors, including the perceived enhanced credibility of U.S.-based hosts and the different operational requirements of the two services. As discussed earlier, spam relays can take advantage of hosts with much shorter lifetimes, making them suitable for compromised machines like botnets. Scam hosts, however, benefit more from the stability provided by hosts and networks within the United States.

### 2.6 Conclusion

This paper focuses on the infrastructure supporting internet scams, rather than spam itself or the infrastructure used to deliver it. We introduced the spamscatter technique for identifying scam infrastructure and used approximate image comparison to cluster servers according to individual scams, bypassing the extensive content and networking camouflage used by spammers.

From a week-long trace of a large real-time spam feed (approximately 150,000 per day), we identified and analyzed over 2,000 distinct scams hosted across more than 7,000 distinct servers. We found that, although large numbers of hosts are used to advertise internet scams via spam campaigns, individual scams are typically hosted on only one machine. Further, individual machines often host multiple scams and occasionally serve as spam relays, providing a convenient single point for network-based interdiction via IP blacklisting or network filtering.

The lifecycle of a typical scam starts with a short spam campaign lasting about half a day, while the scam site remains active for at least a week. The relative lifetimes of spam campaigns and scam hosts reflect the different requirements of these underground services. Spam is a form of blanket advertising that requires no user interaction, whereas scam hosting is a service that fundamentally depends on user engagement to be successful. Finally, mapping the geographic locations of scam hosts, we found a strong bias toward being located in the United States, suggesting that geographic location is more important to scammers than to spammers, likely due to the stability of hosts and networks within the U.S.

### Acknowledgments

We would like to thank several individuals who contributed to this project. We are particularly grateful to Weidong Cui and Christian Kreibich, who maintained the spam feed we used for our analyses, the anonymous party who gave us access to the spam feed itself, and Vern Paxson for discussions and feedback. Kirill Levchenko suggested image-based comparison of web pages as an equivalence test, and Colleen Shannon assisted us with Digital Element’s NetAcuity tool. We also thank the anonymous reviewers for their comments, the CCIED group for useful feedback on the project, and Chris X. Edwards for system support. Support for this work was provided in part by NSF under CyberTrust Grant No. CNS-0433668 and AFOSR MURI Contract F49620-02-1-0233.

### References

[1] ANTI-PHISHING WORKING GROUP. Report Phishing. http://www.antiphishing.org/.

[2] BARFORD, P., BESTAVROS, A., BYERS, J., AND CROVELLA, M. On the marginal utility of network topology measurements. In Proceedings of ACM SIGCOMM Internet Measurement Workshop (Oct. 2001).

[3] BÖHME, R., AND HOLZ, T. The effect of stock spam on financial markets. In Proceedings of the Fifth Workshop on the Economics of Information Security (WEIS 2006) (June 2006).

[4] BRODER, A. Z. On the resemblance and containment of documents. In Proceedings of the Compression and Complexity of Sequences (SEQUENCES’97) (June 1997), pp. 21–29.

[5] CASADO, M., GARFINKEL, T., CUI, W., PAXSON, V., AND SAVAGE, S. Opportunistic measurement: Extracting insight from spurious traffic. In Proceedings of the 4th ACM Workshop on Hot Topics in Networks (HotNets-IV) (College Park, MD, Nov. 2005).

[6] CASTLECOPS. Fried Phish: Phishing Incident Reporting and Termination (PIRT). http://www.castlecops.com/pirt.

[7] CHOU, N., LEDESMA, R., TERAGUCHI, Y., BONEH, D., AND MITCHELL, J. C. Client-side defense against Web-based identity theft. In Proceedings of the 11th Annual Network and Distributed System Security Symposium (NDSS ’04) (Feb. 2004).

[8] COOKE, E., BAILEY, M., MAO, Z. M., WATSON, D., JAHANIAN, F., AND MCPHERSON, D. Toward understanding distributed blackhole placement. In Workshop on Rapid Malcode (WORM’04) (Oct. 2004).

[9] COOKE, E., JAHANIAN, F., AND MCPHERSON, D. The zombie roundup: Understanding, detecting, and disrupting botnets. In Proceedings of the First Workshop on Steps to Reducing Unwanted Traffic on the Internet (SRUTI’05) (July 2005).

[10] DIGITAL ELEMENT. NetAcuity IP Intelligence. http://www.digital-element.net/ip_intelligence/ip_intelligence.html/.

[11] FETTERLY, D., MANASSE, M., AND NAJORK, M. On the evolution of clusters of near-duplicate Web pages. In Proceedings of the First Latin American Web Congress (Nov. 2003), pp. 37–45.

[12] GILLIS, T. Internet Security Trends for 2007. Ironport Whitepaper, 2007.

[13] IRONPORT INC. Spammers continue innovation. IronPort press release, June 28, 2006. http://www.ironport.com/company/ironport_pr_2006-06-28.html.

[14] KDE. Khtml layout engine. http://www.kde.org/.

[15] KEIZER, G. Spam volume jumps 35% in November, Dec. 2006. http://informationweek.com/news/showArticle.jhtml?articleID=196701527.

[16] MATHER, T. Perl module. http://search.cpan.org/~tjmather/Net::DNSBLLookup Net-DNSBLLookup-0.03/.

[17] MESSAGELABS. 2006: The year spam raised its game and threats got personal, Dec. 2006. http://www.messagelabs.com/publishedcontent/publish/about_us_dotcom_en/%news___events/press_releases/DA_174397.html.

[18] MONGA, V., AND EVANS, B. L. Robust perceptual image hashing using feature points. In Proceedings of the IEEE International Conference on Image Processing (ICIP’04) (Oct. 2004), pp. 677–680.

[19] MOORE, D., PAXSON, V., SAVAGE, S., SHANNON, C., STANIFORD, S., AND WEAVER, N. Inside the Slammer worm. IEEE Security and Privacy 1, 4 (July 2003), 33–39.

[20] MOORE, D., SHANNON, C., BROWN, D., VOELKER, G. M., AND SAVAGE, S. Inferring Internet denial-of-service activity. ACM Transactions on Computer Systems 24, 2 (May 2006), 115–139.

[21] MOORE, D., SHANNON, C., AND BROWN, J. Code-Red: a case study on the spread and victims of an Internet worm. In Proceedings of the ACM/USENIX Internet Measurement Workshop (IMW) (Marseille, France, Nov. 2002).

[22] NEWS.ADMIN.NET-ABUSE.SIGHTINGS. USENET newsgroup for discussion of spam. http://www.nanae.org/.

[23] PAUL BÄHER, THORSTEN HOLZ, MARKUS KÖTTER AND GEORG WICHERSKI. Know your enemy: Tracking botnets. In The Honeynet Project & Research Alliance (Mar. 2005).

[24] PHILADELPHIA INQUIRER. Special reports: Drugnet. http://www.philly.com/mld/inquirer/news/special_packages/pill/.

[25] PHISHTANK. Join the fight against phishing. http://www.phishtank.com/.

[26] RAJAB, M. A., ZARFOSS, J., MONROSE, F., AND TERZIS, A. A multifaceted approach to understanding the botnet phenomenon. In Proceedings of the ACM Internet Measurement Conference (Rio de Janeiro, Brazil, Oct. 2006).

[27] RAMACHANDRAN, A., AND FEAMSTER, N. Understanding the network-level behavior of spammers. In Proceedings of the ACM SIGCOMM Conference (Pisa, Italy, Sept. 2006).

[28] ROOVER, C. D., VLEESCHOUWER, C. D., LEFEBVRE, F., AND MACQ, B. Robust image hashing based on radial variance of pixels. In Proceedings of the IEEE International Conference on Image Processing (ICIP’05) (Sept. 2005), pp. 77–80.

[29] SHIVAKUMAR, N., AND GARCIA-MOLINA, H. Finding near-replicas of documents and servers on the Web. In Proceedings of the First International Workshop on the Web and Databases (WebDB’98) (Mar. 1998).

[30] VENKATESAN, R., KOON, S. M., JAKUBOWSKI, M. H., AND MOULIN, P. Robust image hashing. In Proceedings of the IEEE International Conference on Image Processing (ICIP’00) (Sept. 2000).

[31] WEBB, S., CAVERLEE, J., AND PU, C. Introducing the Webb spam corpus: Using email spam to identify Web spam automatically. In Proceedings of the 3rd Conference on Email and Anti-Spam (CEAS) (Mountain View, 2006).

[32] YEGNESWARAN, V., BARFORD, P., AND PLONKA, D. On the design and use of Internet sinks for network abuse monitoring. In Proceedings of Recent Advances on Intrusion Detection (Sept. 2004).