### 10.3 Top 10 Validation
We validate our findings for the Alexa Top 10 domains using SSL Labs [58]. Table 12 presents the settings for these top domains. Consistent with our overall results, we observe near-universal support for SCSV, but only a few domains deploy CT, HSTS, or HPKP. Notably, only google.com uses CAA, and no Top 10 domain deploys TLSA. We highlight the high and correct usage of SCTs as a TLS extension, primarily driven by Google domains. It is important to note that our investigation focuses solely on base domains, and does not follow redirects. As Kranch and Bonneau [42] point out, security extensions must function on the base domain, as any insecure redirect can be exploited by attackers. Under this principle, we do not attribute HSTS to domains that only use it on subdomains, such as google.com, where HSTS is supported for many subdomains (e.g., www.google.com) but not the base domain (see Section 6.2).

### 10.4 Correlating Effort, Risk, and Usage
In Table 13, we correlate deployment effort, risk to site availability, and the adoption of technologies that have emerged since the DigiNotar incident.

**Effort Classification:**
- **None:** No action required from the server administrator (e.g., SCSV, embedded SCTs).
- **Low:** Simple enabling of an extension with minimal configuration (e.g., HSTS, which can be enabled by copying a configuration string from a tutorial).
- **Medium:** Minor adjustments to instructions from manuals, such as replacing domain names or CA names (e.g., CAA).
- **High:** Requires careful thought and multiple steps (e.g., HPKP).

**Availability Risk Classification:**
- **None:** No risk.
- **Low:** Technologies with low risk potential or that are easy and quick to fix.
- **Medium:** Mechanisms that are more difficult to fix when deployed incorrectly and can affect a large user base at once.
- **High:** Technologies that can significantly harm availability for a large user base and are difficult and slow to remediate (e.g., wrongly preloaded HPKP pins [69] and hostile pinning, where an MITM attacker sends incorrect pins to restrict user access [25]).

Using this classification system, we observe that technologies with low effort and low risk to availability tend to have a higher market share.

### 10.5 Improving Deployment
Our data suggests that security extensions with low (or no) deployment effort and/or little risk to availability can quickly gain market traction. This supports several hypotheses, including administrators avoiding deployment due to perceived effort or risk, lack of concern about additional security, or unawareness of new mechanisms. In these cases, it is crucial to design new extensions with minimal administrative effort in mind. For example, enabling certain mechanisms by default, as done with SCSV in OpenSSL, could be extended to TLS-enabled web servers by sending an HSTS header by default. This approach complements efforts like Let’s Encrypt, which can automate the process to ensure a server always serves a valid certificate. Additionally, web server software could facilitate successful deployment by providing tools to generate the correct HPKP configuration directive for the currently used TLS key.

Our data also highlights the significant impact of major players in driving the adoption of security extensions. Browser vendors, for instance, can drive the ecosystem towards adopting extensions, as demonstrated by Google with Certificate Transparency (CT). This is most effective when their interests align with those of the userbase, which is a non-technical issue.

### 10.6 Multi-Site and Multi-Protocol Scans
For this study, we conducted a wide range of active and passive measurements, covering three continents and both IPv6 and IPv4. To our knowledge, this is the first work with such diverse coverage. We examined how much additional information can be gained from performing a varied array of scans compared to using more limited data sources.

For active scans, we found that the IPv4 results from Sydney and Munich were very consistent. While there were some expected differences between vantage points (e.g., DNS servers returning different A records), these differences were very limited in scope: only 15k out of 25M domains (.06%) served inconsistent HSTS or HPKP headers.

Similarly, when comparing our IPv6 and IPv4 scans, we found that, while there were fewer responses for IPv6, domains that responded on both IPv4 and IPv6 were typically configured consistently: only 754 out of 1.09M dual-stacked domains (.06% as well) served different HSTS/HPKP headers.

Our conclusion is that multiple scans are useful for result validation but are only necessary for studies seeking in-depth knowledge about the HTTPS ecosystem from different perspectives. Note that our analysis only compares HSTS and HPKP headers across domains—hosts may still serve different content, present different certificates, or exhibit different cryptographic algorithms, which were out of scope in this work. These properties, along with a detailed analysis of inconsistent domains [52], can be further analyzed based on our shared raw data.

Even for passive monitoring, the measurements from our three vantage points yielded similar results. Having multiple vantage points provides valuable validation. Comparing active and passive monitoring, we found that active scans provided more data points and allowed for more in-depth analysis and precise statements. Some of our measurements, such as HTTP headers, are impossible to obtain through passive monitoring of HTTPS. However, passive monitoring remains a valuable, complementary addition, as it allows tracking the uptake of new technologies by users and is more likely to lead to the discovery of anomalies, such as connections to servers imitating TLS handshakes to well-known sites (see Section 5.3).

### 10.7 Limitations and Future Work
Our work involves several key design decisions in evaluating domain-based security:
1. **Consistency Across Different IPs and Protocols:** We only consider domains that behave consistently across different target and source IP addresses and protocols. While very few domains fail this test, closer investigation of inconsistent domains may yield interesting insights.
2. **Base Domain Focus:** We focus on the base domain, not following redirects or prepending the "www" prefix, and only evaluate HTTP 200 domains. While it is critical for domains to protect their base domain, the behavior of redirects into subdomains is another complex and interesting area of study.
3. **Parked Domains:** A more systematic investigation of "parked" domains, which often use the same invalid certificate for millions of hosted domains, could further refine domain-based analysis by carefully limiting the influence of such clusters.

### 10.8 Reproducible Research & Data Release
We aim for repeatable, replicable, and reproducible research as defined by ACM [1, 64]. We publish all active scan data (traces and/or result data), as well as the source code for the utilities we used and created for this work. Due to ethical and legal reasons, we cannot provide detailed information about passively captured data. Hosting is provided by the TUM library for long-term availability at https://mediatum.ub.tum.de/1377982.

### 11 Summary
Several new security measures for the HTTPS ecosystem have been developed in the five years since the DigiNotar compromise. While these techniques protect against various attacks and could have prevented or mitigated the DigiNotar incident, we find that their deployment is generally disappointing. Our findings suggest a correlation between configuration effort, risk to site availability, and actual deployment status. Technologies that are easy to deploy and have little risk to availability, such as Certificate Transparency and SCSV, have the highest deployment. Those with high deployment effort or high risk of misconfiguration have low deployment. 

Certificate Transparency may be a special case in our study, as its deployment was heavily supported by a major corporation (Google) whose business is heavily web-based and which also develops a popular browser, allowing it to provide both client- and server-side support.

Our findings support the hypothesis that operators may consciously decide against deployment based on perceived effort and/or incurred risk. It also aligns with the possibility that many operators do not care enough about additional security to invest the effort or are simply unaware of available defenses for their sites. Empirical measurement has its limits here; a qualitative, interview-based follow-up study may be advisable to reveal deeper insights into why deployment is lacking. Thus, the mission to achieve HTTPS ecosystem security is certainly not yet accomplished.

### Acknowledgments
This work was partially funded by the Major Equipment and Early Career Researcher grant schemes of the Faculty of Engineering & Information Technology, The University of Sydney; by the German Federal Ministry of Education and Research under project X-Check, grant 16KIS0530, and project DecADe, grant 16KIS0538; by the National Science Foundation under grant numbers CNS-1528156 and ACI-1348077. Any opinions, findings, and conclusions are those of the authors and do not necessarily reflect the views of the funding agencies.