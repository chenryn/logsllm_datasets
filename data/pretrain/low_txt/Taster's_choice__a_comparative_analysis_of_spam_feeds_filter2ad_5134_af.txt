### 4.4.2 Last Appearance Time

Last appearance times are often used to estimate when spam campaigns end. Figure 11 illustrates the time between the last appearance of a domain in a feed and the domain’s campaign end time. Similar to Figure 10, we focus on a subset of the feeds where the last appearance of a domain is calculated from an aggregate of the same five feeds. Solid lines represent medians, while the boxes range from the 25th to the 75th percentile.

### Results and Analysis

The results in Figure 9, but with the Hu, Hyb, and blacklist feeds removed, show that these feeds contain domains reported by users, which affects the last appearance times of domains. By restricting the feeds used to determine campaign start times, we reduce the total set of domains but increase the likelihood that a domain appears in all traces. When we focus on just the MX honeypot and account traces, we observe that relative to each other, they continue to have consistent first appearance times. However, the relative first appearance times are now very short (roughly less than a day). These results indicate that timing estimates are highly relative and fundamentally depend on the feeds being considered.

### Challenges in Spam Data Analysis

While our analysis is not comprehensive, it has revealed significant variation among the ten feeds studied. Based on these findings, we recommend that researchers consider the following four challenges when using spam data:

1. **Limited Purity**: Even the best spam feeds include benign domains, and these should be anticipated in analyses. Researchers should identify the types of benign domains in their datasets and determine if their presence will bias results, especially when correlating spam feed data with other sources.

2. **Coverage Limitations**: MX and honey account spam sources are inherently biased towards loud, broad campaigns. For a broader view of what is advertised via spam, operational domain blacklists are the next best source if access to a large email provider is not possible.

3. **Temporal Uncertainty**: Studies of spam campaign timing should recognize how different feeds can introduce timing errors. Botnet-based feeds are among the best for timing information, but coverage is limited. Other feeds provide highly accurate "onset" information (e.g., blacklists and human-identified feeds) but may lack accurate ending timestamps. Combining the features of different feeds may be appropriate in this area.

4. **Lack of Proportionality**: It is tempting to measure the prevalence of one type of spam in a feed and extrapolate to the entire world. However, the significant differences in the makeup of the feeds we have studied suggest that such conclusions are risky. For example, spam filter results trained on botnet output may have little relevance to a large web mail provider. We advise making such claims based on knowledge of the source dataset. MX-based honeypots may be suitable for characterizing relative prevalence among distinct high-volume spam campaigns.

### Guidelines for Choosing Spam Feeds

While it is important to be aware of the limitations and challenges of spam feeds, the choice of feeds should be closely related to the questions being addressed. Here are some general guidelines:

- **Human-Identified Feeds**: Provided by large mail providers, these feeds offer the best coverage due to wide exposure and allow visibility into low-volume campaigns. They provide reasonable purity but require filtering due to the human factor. These feeds are less useful for studies relying on timing and last appearance information.

- **Blacklist Feeds**: If access to human-identified feeds is limited, high-quality blacklist feeds offer good coverage and first appearance information. They also provide the best purity, as they are commercially maintained with low false positives. Like human-identified feeds, they are less useful for studies relying on last appearance or duration information.

- **Diverse Feeds**: When working with multiple feeds, prioritize obtaining a diverse set. Additional feeds of the same type offer reduced added value, especially in the case of MX honeypot feeds.

- **Volume and Global Spam**: Accurately measuring volume and providing conclusions that apply to the entirety of the spam problem is challenging. Given the limited view into global spam output, all results are inherently tied to their respective input datasets.

### Conclusion

The spam research community benefits from having many different kinds of data sources available. While this diversity is advantageous, it also comes with the responsibility to validate and not blindly extrapolate from a single spam feed. Our paper provides a basic understanding of the limitations of existing feeds and a blueprint for further refining this understanding.

### Acknowledgments

We would like to thank the named and anonymous providers of our feeds, whose willingness to share data made this paper possible. We are also grateful to Brian Kantor and Cindy Moore for managing our systems and storage needs.

This work was supported by National Science Foundation grants NSF-0433668, NSF-0433702, NSF-0831138, by Office of Naval Research MURI grant N000140911081, and by generous research, operational, and in-kind support from the UCSD Center for Networked Systems (CNS).

### References

[1] Alexa. Alexa top 500 global sites. http://www.alexa.com/topsites, June 2011.
[2] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker. Spamscatter: Characterizing Internet Scam Hosting Infrastructure. In Proc. of 16th USENIX Security, 2007.
[3] I. Androutsopoulos, J. Koutsias, K. Chandrinos, G. Paliouras, and C. D. Spyropoulos. An Evaluation of Naive Bayesian Anti-Spam Filtering. In Proc. of 1st MLNIA, 2000.
[4] R. Beverly and K. Sollins. Exploiting Transport-Level Characteristics of Spam. In Proc. of 5th CEAS, 2008.
[5] X. Carreras and L. Márquez. Boosting Trees for Anti-Spam Email Filtering. In Proceedings of RANLP-2001, 2001.
[6] R. Clayton. How much did shutting down McColo help? In Proc. of 6th CEAS, 2009.
[7] H. Drucker, D. Wu, and V. N. Vapnik. Support vector machines for spam categorization. In Proc. of IEEE Transactions on Neural Networks, 1999.
[8] G. Gee and P. Kim. Doppleganger Domains. http://www.wired.com/images_blogs/threatlevel/2011/09/Doppelganger.Domains.pdf, 2011.
[9] P. H. C. Guerra, D. Guedes, W. M. Jr., C. Hoepers, M. H. P. C. Chaves, and K. Steding-Jessen. Spamming Chains: A New Way of Understanding Spammer Behavior. In Proc. of 6th CEAS, 2009.
[10] P. H. C. Guerra, D. Guedes, W. M. Jr., C. Hoepers, M. H. P. C. Chaves, and K. Steding-Jessen. Exploring the Spam Arms Race to Characterize Spam Evolution. In Proc. of 7th CEAS, 2010.
[11] J. P. John, A. Moshchuk, S. D. Gribble, and A. Krishnamurthy. Studying Spamming Botnets Using Botlab. In Proc. of 6th NSDI, 2009.
[12] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M. Voelker, V. Paxson, and S. Savage. Spamalytics: An Empirical Analysis of Spam Marketing Conversion. In Proc. of 15th ACM CCS, 2008.
[13] M. Konte, N. Feamster, and J. Jung. Dynamics of Online Scam Hosting Infrastructure. In PAM, 2009.
[26] B. Nelson, M. Barreno, F. J. Chi, A. D. Joseph, B. I. P. Rubinstein, U. Saini, C. Sutton, J. D. Tygar, and K. Xia. Exploiting Machine Learning to Subvert Your Spam Filter. In Proc. of 1st USENIX LEET, 2008.
[27] ODP – Open Directory Project. http://www.dmoz.org, September 2011.
[28] A. Pathak, Y. C. Hu, and Z. M. Mao. Peeking into Spammer Behavior from a Unique Vantage Point. In Proc. of 1st USENIX LEET, 2008.
[29] A. Pathak, F. Qian, Y. C. Hu, Z. M. Mao, and S. Ranjan. Botnet Spam Campaigns Can Be Long Lasting: Evidence, Implications, and Analysis. In Proc. of 9th ACM SIGMETRICS, 2009.
[30] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich, G. Voelkera, V. Paxson, N. Weaver, and S. Savage. Botnet Judo: Fighting Spam with Itself. In Proc. of 17th NDSS, 2010.
[14] C. Kreibich, C. Kanich, K. Levchenko, B. Enright, G. M. Voelker, V. Paxson, and S. Savage. On the Spam Campaign Trail. In Proc. 1st USENIX LEET, 2008.
[15] C. Kreibich, C. Kanich, K. Levchenko, B. Enright, G. M. Voelker, V. Paxson, and S. Savage. Spamcraft: An Inside Look at Spam Campaign Orchestration. In Proc. of 2nd USENIX LEET, 2009.
[16] M. Lee. Why My Email Went. http://www.symantec.com/connect/blogs/why-my-email-went, 2011.
[17] N. Leontiadis, T. Moore, and N. Christin. Measuring and Analyzing Search-Redirection Attacks in the Illicit Online Prescription Drug Trade. In Proc. of USENIX Security, 2011.
[18] K. Levchenko, A. Pitsillidis, N. Chachra, B. Enright, M. Félegyházi, C. Grier, T. Halvorson, C. Kanich, C. Kreibich, H. Liu, D. McCoy, N. Weaver, V. Paxson, G. M. Voelker, and S. Savage. Click Trajectories: End-to-End Analysis of the Spam Value Chain. In Proc. of IEEE Symposium on Security and Privacy, 2011.
[19] H. Liu, K. Levchenko, M. Félegyházi, C. Kreibich, G. Maier, G. M. Voelker, and S. Savage. On the Effects of Registrar-level Intervention. In Proc. of 4th USENIX LEET, 2011.
[20] M86 Security Labs. Top Spam Affiliate Programs. http://www.m86security.com/labs/traceitem.asp?article=1070, 2009.
[21] Marshal8e6 TRACELabs. Marshal8e6 Security Threats: Email and Web Threats. http://www.marshal.com/newsimages/trace/Marshal8e6_TRACE_Report_Jan2009.pdf, 2009.
[22] M. M. Masud, L. Khan, and B. Thuraisingham. Feature-Based Techniques for Auto-Detection of Novel Email Worms. In Proc. of 11th PACKDDD, 2007.
[23] D. McCoy, A. Pitsillidis, G. Jordan, N. Weaver, C. Kreibich, B. Krebs, G. M. Voelker, S. Savage, and K. Levchenko. PharmaLeaks: Understanding the Business of Online Pharmaceutical Affiliate Programs. In Proc. of the USENIX Security Symposium, 2012.
[24] D. K. McGrath and M. Gupta. Behind Phishing: An Examination of Phisher Modus Operandi. In Proc. of 1st USENIX LEET, 2008.
[25] T. Moore and R. Clayton. Examining the Impact of Website Take-down on Phishing. In Proceedings of the Anti-Phishing Working Group’s 2nd annual eCrime Researchers Summit. ACM, 2007.
[32] A. Ramachandran, N. Feamster, and S. Vempala. Filtering Spam with Behavioral Blacklisting. In Proc. of 14th ACM CCS, 2007.
[33] D. Samosseiko. The Partnerka — What is it, and why should you care? In Proc. of Virus Bulletin Conference, 2009.
[34] F. Sanchez, Z. Duan, and Y. Dong. Understanding Forgery Properties of Spam Delivery Paths. In Proc. of 7th CEAS, 2010.
[35] S. Sinha, M. Bailey, and F. Jahanian. Shades of Grey: On the Effectiveness of Reputation-Based Blacklists. In Proc. of 3rd MALWARE, 2008.
[36] O. Thonnard and M. Dacier. A Strategic Analysis of Spam Botnets Operations. In Proc. of 8th CEAS, 2011.
[37] Trustwave. Spam Statistics – Week ending Sep 2, 2012. https://www.trustwave.com/support/labs/spam_statistics.asp, September 2012.
[38] G. Warner. Random Pseudo-URLs Try to Confuse Anti-Spam Solutions. http://garwarner.blogspot.com/2010/09/random-pseudo-urls-try-to-confuse-anti.html, Sept. 2010.
[39] C. Wei, A. Sprague, G. Warner, and A. Skjellum. Identifying New Spam Domains by Hosting IPs: Improving Domain Blacklisting. In Proc. of 7th CEAS, 2010.
[40] A. G. West, A. J. Aviv, J. Chang, and I. Lee. Spam Mitigation Using Spatio-temporal Reputations From Blacklist History. In Proc. of 26th ACSAC, 2010.
[41] J. Whissell and C. Clarke. Clustering for Semi-Supervised Spam Filtering. In Proc. of 8th CEAS, 2011.
[42] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and I. Osipkov. Spamming Botnets: Signatures and Characteristics. In Proceedings of ACM SIGCOMM, 2008.
[43] L. Zhuang, J. Dunagan, D. R. Simon, H. J. Wang, I. Osipkov, G. Hulten, and J. Tygar. Characterizing Botnets from Email Spam Records. In Proc. of 1st USENIX LEET, 2008.
[44] J. Zittrain and L. Frieder. Spam Works: Evidence from Stock Touts and Corresponding Market Activity. Social Science Research Network, March 2007.