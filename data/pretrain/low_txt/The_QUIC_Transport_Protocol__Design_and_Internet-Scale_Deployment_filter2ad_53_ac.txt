### TCP-Terminating Proxies and QUIC

TCP-terminating proxies function by forwarding the TCP payload to an unrestricted front-end server, where the TLS session is terminated and further processed. In contrast, there is no equivalent for QUIC, as the transport session cannot be separated from the cryptographic session. Therefore, UDP-proxying simply forwards incoming client UDP packets to the unrestricted front-end servers, allowing users served at the Restricted Edge Locations (RELs) to use QUIC. Without UDP-proxying, RELs would only support TCP.

The performance improvement of QUIC in July 2016 can be attributed to the deployment of UDP-proxying at our RELs (labeled '3' in Figure 6). This resulted in an increase in the average overall improvement in Search Latency from about 4% to over 7%, demonstrating that QUIC's latency reductions more than compensated for the improvements from TCP termination at the RELs.

### QUIC Performance

#### 6.1 Experiment Setup

Our performance data is derived from QUIC experiments deployed on various clients using their frameworks for randomized experimental trials. Users are divided into two groups: the QUIC experimental group (QUICg) and the TLS/TCP control group (TCPg). Unless otherwise specified, QUIC performance is reported for users in QUICg, which includes those who could not establish a QUIC connection due to failed handshakes. Most users in this group, however, do use QUIC, with only 2% of HTTP transactions using TLS/TCP for servers that support QUIC.

Clients that do not use QUIC rely on HTTP/2 over a single TLS/TCP connection for search and HTTP/1.1 over two TLS/TCP connections for video playback. Both QUIC and TCP implementations use a paced form of the Cubic algorithm for congestion avoidance. Data is presented for both desktop and mobile users, with desktop users accessing services through Chrome and mobile users through dedicated apps with QUIC support. All results were gathered using QUIC version 35 and include over a billion samples. Search results were collected between December 12, 2016, and December 19, 2016, while video playback results were gathered between January 19, 2017, and January 26, 2017.

#### 6.2 Transport and Application Metrics

Before delving into application performance, we discuss transport-level handshake latency, a microbenchmark that QUIC aims to improve. Handshake latency is the time taken to establish a secure transport connection, including the TCP and TLS handshakes in TLS/TCP. We measured handshake latency at the server from the first TCP SYN or QUIC client hello packet to the completion of the handshake. For QUIC 0-RTT handshakes, latency is measured as 0 ms. Figure 7 illustrates the impact of QUIC’s 0-RTT and 1-RTT handshakes on handshake latency.

As RTT increases, the average handshake latency for TCP/TLS rises linearly, while QUIC remains nearly constant. This is due to the fixed (zero) latency cost of 0-RTT handshakes, which account for about 88% of all QUIC handshakes. The slight increase in QUIC handshake latency with RTT is due to the remaining connections that do not achieve a 0-RTT handshake.

While we do not present microbenchmarks for QUIC’s improved loss recovery, these improvements manifest as higher resilience to loss and lower latency for short connections. Microbenchmarks are useful for verifying transport changes, but application and user-relevant metrics are crucial for assessing the usefulness of these changes.

#### 6.3 Search Latency

Search Latency is the delay from when a user enters a search term to when all search result content, including images and embedded content, is generated and delivered to the client. On average, a search results in a total response load of 100 KB for desktop searches and 40 KB for mobile searches. Table 1 shows that users in QUICg experienced reduced mean Search Latency, with improvements increasing as base Search Latency increases. This is primarily due to reduced handshake latency, as shown in Figure 9, which demonstrates desktop latency reduction as a function of the client’s minimum RTT to the server.

Figure 8 shows the distribution of connection minimum RTTs for TCP connections to our servers, indicating that more than 20% of all connections have a minimum RTT larger than 150 ms, and 10% have a minimum RTT larger than 300 ms. The 0-RTT handshake contributes significantly to latency reduction, with about 88% of QUIC connections from desktop achieving a 0-RTT handshake, saving at least 2-RTT latency over TLS/TCP.

Table 1 also shows that Search Latency gains on mobile are lower than on desktop. This is due to differences in the mobile environment and usage, as well as factors such as IP address changes and different server configurations across data centers. These factors contribute to a reduction in successful 0-RTT handshakes.

Finally, the latency increase in QUICg at the 1st and 5th percentiles is attributed to additional small costs in QUIC, including OS process scheduler costs due to being in user-space. These costs are a higher proportion of the total latency at low overall latencies.

#### 6.4 Video Latency

Video Latency is the time from when a user hits "play" on a video to when the video starts playing. Video players typically buffer a few seconds of video before playing the first frame. Table 1 shows that users in QUICg experience decreased overall Video Latency for both desktop and mobile YouTube playbacks. Figure 9 indicates that Video Latency gains increase with client RTT, similar to Search Latency. An average of 85% of QUIC connections for video playback on desktop receive the benefit of a 0-RTT handshake, and the rest benefit from a 1-RTT handshake.

Mobile playbacks benefit less from QUIC, with the YouTube app achieving a 0-RTT handshake for only 65% of QUIC connections. Additionally, the app tries to hide handshake costs by establishing connections in the background, reducing the benefit of QUIC’s 0-RTT handshake for mobile video.

#### 6.5 Video Rebuffer Rate

Video Rebuffer Rate is the percentage of time a video pauses during playback to rebuffer data, normalized by video watch time. Table 2 shows that users in QUICg experience reduced Rebuffer Rate on average and substantial reductions at higher percentiles. Rebuffer Rate is influenced by loss-recovery latency and overall throughput, rather than handshake latency. Figure 9 compares QUICg and TCPg for various metrics versus minimum RTT, showing similar trends for both desktop and mobile.

Figure 10 shows the average TCP retransmission rate versus minimum RTT, indicating that network quality is highly correlated with the client’s minimum RTT. This suggests that QUIC’s improved loss recovery may also contribute to better performance at higher RTTs.