# Title: Poster: Towards Robust Open-World Detection of Deepfakes

## Authors
- Saniat Javid Sohrawardi, Rochester Institute of Technology
- Akash Chintha, Rochester Institute of Technology
- Bao Thai, Rochester Institute of Technology
- Sovantharith Seng, Rochester Institute of Technology
- Andrea Hickerson, University of South Carolina
- Raymond Ptucha, Rochester Institute of Technology
- Matthew Wright, Rochester Institute of Technology

## Abstract
The rise of deliberately inaccurate news has heightened concerns over the use of deepfake videos and images. These AI-generated or modified media have become increasingly realistic and easier to create, posing a significant threat to public trust. They can be used to disseminate false information from public figures or fabricate events that never occurred, misleading large audiences in dangerous ways. While some recent research has focused on detecting deepfakes, these methods often fail to generalize to real-world scenarios and are not readily accessible to the public. This project proposes a robust and efficient system for users to determine whether an online video is a deepfake. We approach this problem from a journalist's perspective, aiming to develop a tool that seamlessly integrates into their workflow. Our results demonstrate accurate detection across both matched and mismatched datasets.

## Keywords
Deepfake Detection, Deep Learning, Usable Security

## ACM Reference Format
Saniat Javid Sohrawardi, Akash Chintha, Bao Thai, Sovantharith Seng, Andrea Hickerson, Raymond Ptucha, and Matthew Wright. 2019. Poster: Towards Robust Open-World Detection of Deepfakes. In 2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19), November 11–15, 2019, London, United Kingdom. ACM, New York, NY, USA, 3 pages. https://doi.org/10.1145/3319535.3363269

## 1. Introduction
Deepfakes are artificially generated audio or visual renderings, most commonly in the form of videos. These videos, often created without the consent of the depicted individuals, can be used to defame public figures or influence public opinion. Historically, audio and video recordings were considered irrefutable evidence in legal settings. However, with the advent of generative adversarial networks (GANs) [7], even a standard desktop computer equipped with a graphics processing unit can produce high-quality deepfakes that can deceive both humans and machines.

In this work, we propose the development of a tool for detecting deepfakes, designed to be usable by journalists in real-world conditions. We explore multiple detection methods that can be integrated into such a tool and discuss findings from interviews with journalists regarding the tool's design.

### 1.1 Background
Image manipulation has been around for decades, but it was time-consuming and expensive. Recent advancements in deep convolutional neural networks (CNNs) have made it much more accessible to generate falsified visual content. The term "deepfakes" generally refers to videos generated using GANs, which place faces into frames learned from source videos or a collection of photos. The Face-swap method [11] is a fast but lower-quality technique used in social media apps like Snapchat. More convincing results are achieved with GAN-based methods, such as the FakeApp and Faceswap Github [15]. Face2Face [21] involves face re-enactment, where facial expressions are transferred from source to target frames. These techniques can be combined with faked sound data to create complete falsified content. Algorithms can also generate speech that mimics a target speaker based on text or utterances from another speaker [14].

### 1.2 Detecting Deepfakes
Over the past few years, researchers have studied various methods for detecting deepfakes. Early work focused on visual inconsistencies within frames, while other approaches examined biological signals [4, 13] or used CNNs for feature extraction [1, 8, 20]. Nguyen et al. [17] proposed using capsule networks with dynamic routing, achieving very good results. Some methods successfully localized manipulated areas, typically the face [5, 16, 18]. Agarwal et al. [2] suggested tracking facial landmarks to discern between real and fake video material. In audio detection, the ASVSpoof challenges have produced interesting results [10], though they are more focused on detecting attempts to bypass voice biometrics.

While recent methods achieve high accuracy, they do not provide a unified solution that is robust to different types of video manipulations, making them unreliable for detecting deepfakes in the wild.

## 2. Experimental Setting

### 2.1 Datasets
We used the FaceForensics++ dataset [18], which consists of 1,000 unmodified source videos and three sets of manipulated videos: Deepfake [15], Face2Face [21], and FaceSwap [12]. The training, validation, and test splits were generated using the mapping provided by Rössler et al. [18] in their GitHub repository, with 720, 140, and 140 videos, respectively. Facial extraction was performed using dlib [1] to extract faces with a bounding box three times the interocular distance.

For fake audio detection, we used the ASVSpoof2019 logical access dataset [22], consisting of speech data from 107 speakers. The dataset is partitioned into training, development, and evaluation datasets with 20, 10, and 48 speakers, respectively. We focused on logical access attack cases, as they are more relevant to deepfake generation.

### 2.2 Model Selection

#### 2.2.1 Video Model
We chose to work with the ClassNSeg model by Nguyen et al. [16], as their multi-task learning model demonstrated robustness to different types of deepfakes after fine-tuning with a small amount of data. Additionally, we constructed our own FacenetLSTM model, which targets temporal inconsistencies in videos. A common feature among all deepfake generation mechanisms is that each frame is treated as an individual image. Therefore, we believe a sequence-to-sequence model could exploit frame-to-frame inconsistencies and frame-level facial artifacts to better detect fakes. Our model is inspired by an RNN-based deepfake detection model [8], using a time-distributed FaceNet [19] pre-trained on VGGFace2 [3], followed by a unidirectional LSTM layer to capture temporal information.

#### 2.2.2 Audio Model
For fake audio detection, we explored two architectures. Our first model, ResNeXTSpoof, passes the input through multiple convolution blocks of different sizes. The output of the convolutions is summed and added to the original input, similar to skip connections in ResNet [9]. By using multiple filter sizes, we aim to detect artifacts at different frequency bands. The second model combines convolution layers and recurrent layers, inspired by Guerra and Delp [8]. Several convolutional layers downsample the input audio before passing the feature maps into a bidirectional LSTM. The hidden state of the LSTM is then used as a feature for a fully connected layer that performs binary classification.

## 3. Evaluation
For deepfake video detection, we trained the models on the three different datasets separately and tested them on their corresponding test sets to obtain matched accuracy results. We also trained the models on a combined dataset to evaluate their performance on mismatched data.

## References
[1] King, D. E. Dlib-ml: A machine learning toolkit. Journal of Machine Learning Research, 10(Jul):1755–1758, 2009.
[2] Agarwal, S., Farid, H. Protecting World Leaders from Deepfakes. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[3] Cao, Q., Shen, L., Xie, W., Parkhi, O. M., Zisserman, A. VGGFace2: A Dataset for Recognising Faces across Pose and Age. In International Conference on Automatic Face & Gesture Recognition (FG), 2018.
[4] Li, Y., Lyu, S. Exposing Deep Fakes Using Inconsistent Head Poses. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[5] Zhou, L., Wang, J., Tang, K. Two-Stream Neural Network for Spatiotemporal Localization of Deepfakes in Videos. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[6] Rössler, A., Cozzolino, D., Verdoliva, L. FaceForensics: A Large-Scale Video Dataset for Forgery Detection in Human Faces. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[7] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y. Generative Adversarial Networks. In Advances in Neural Information Processing Systems (NIPS), 2014.
[8] Guerra, P., Delp, E. J. Deep Learning for Generalized Face Manipulation Detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[9] He, K., Zhang, X., Ren, S., Sun, J. Deep Residual Learning for Image Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.
[10] Todisco, M., Larcher, A., Kinnunen, T., Sahidullah, M., Evans, N., Vestman, V., Lee, K.-A., Teixeira, H. ASVspoof 2019: Spoofing Countermeasures for Text-Independent Speaker Verification. In INTERSPEECH, 2019.
[11] Thies, J., Zollhöfer, M., Stamminger, M., Nießner, M., Theobalt, C. Face2Face: Real-time Face Capture and Reenactment of RGB Videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.
[12] Korshunov, P., Marcel, S. Face Forensics: A Database for Studying Face Manipulation in the Digital Age. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2018.
[13] Yang, Y., Li, H., Lyu, S. Exposing Deep Fakes Using Inconsistent Head Poses. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[14] Jia, Y., Zhang, Y., Weiss, R. J., Wang, Q. Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis. In Advances in Neural Information Processing Systems (NIPS), 2018.
[15] Nirkin, Y., Keller, A., Avidan, S. FSGAN: Subject Agnostic Face Swapping and Reenactment. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[16] Nguyen, H. H., Yamagishi, J., Echizen, I. Capsule-Forensics: Using Capsule Networks to Detect Forged Images and Videos. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[17] Nguyen, H. H., Yamagishi, J., Echizen, I. Multi-Task Learning for Joint Face Forgery Detection and Segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[18] Rössler, A., Cozzolino, D., Verdoliva, L. FaceForensics++: Learning to Detect Manipulated Facial Images. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[19] Schroff, F., Kalenichenko, D., Philbin, J. FaceNet: A Unified Embedding for Face Recognition and Clustering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.
[20] Zhou, L., Wang, J., Tang, K. Spatiotemporal Detection of Deepfakes in Videos. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019.
[21] Thies, J., Zollhöfer, M., Stamminger, M., Nießner, M., Theobalt, C. Face2Face: Real-time Face Capture and Reenactment of RGB Videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.
[22] Todisco, M., Larcher, A., Kinnunen, T., Sahidullah, M., Evans, N., Vestman, V., Lee, K.-A., Teixeira, H. ASVspoof 2019: Spoofing Countermeasures for Text-Independent Speaker Verification. In INTERSPEECH, 2019.