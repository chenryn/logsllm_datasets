### 4.2. Application Statistical Analysis
In this phase, we continued to use graphical tools for data exploration and linear analysis to investigate relationships within the data. To address Research Question 2 (RQ2), we defined additional scores to represent the outcome of "fewer security defects" in each analyzed application. The processing steps are illustrated in Figure 3.

We anticipated that the issue counts would follow a Poisson distribution. To facilitate linear analysis, we applied a log transformation to the issue counts. Specifically, we used the formula \(\log(x + k)\), where \(k\) is chosen to minimize skewness [3]. In practice, we tested different values of \(k\) and found no significant difference in the results; thus, we adhered to the conventional research practice of setting \(k = 1\). To ensure that the scores increase with better app security and privacy, we negated the log-transformed values.

We employed the same methodology as in Section 3.6 to explore relationships between these scores and the scores from Figure 2, which cover "the need for security, involvement of specialist roles, and use of assurance techniques in a development team" in RQ2.

### 4.3. Ethical Considerations
This study was approved by our institutions' Institutional Review Boards, including the use of publicly available contact details for survey invitations. Our research plan and survey procedures were designed to comply with strict data and privacy protection laws in the UK and Germany, as well as the General Data Protection Regulation (GDPR) in the EU. All participants were provided with a form detailing the study's purpose, the data collected and stored, and contact information for the principal investigators in case of any questions or concerns.

### 4.4. Survey Limitations
As with most studies of this nature, our work has several limitations. The response rate for our online developer survey was low, as expected from sending unsolicited emails to potential participants. However, our recruitment approach was consistent with relevant previous work [1, 2, 54]. The low response rate may introduce some self-selection bias, but since the invitations did not mention security, we have no reason to believe that the respondents differ meaningfully in terms of security or privacy behavior from those who did not respond.

All survey data, except for download count and last app update date, are self-reported. Although we aimed to keep questions as fact-oriented as possible, this remains an important limitation. Additionally, the survey reached app owners rather than all app developers, so the data on respondents' experiences may not be representative of all Android developers or software developers in general.

### 4.5. App Analysis Limitations
The static analyses we chose focus on specific categories of vulnerabilities, potentially overlooking other critical security issues. Many vulnerabilities, especially those related to privacy, are often embedded in the intended app functionality rather than in the detailed implementation, and we have no way to estimate these. However, we used detectors for a range of implementation issues that developers who prioritize security or privacy would be expected to address.

Static program analysis tools frequently report false positives, and the tools we used are no exception. For this survey, we assumed that the reported issue counts correlate with the number of true vulnerabilities, making them a useful proxy for aspects of app security in statistical analysis.

We were only able to analyze 'free' and 'freemium' apps, not those requiring payment for download from the Google Play Store, which may introduce a bias. In cases where respondents had multiple apps, the one we downloaded may not reflect the security practices and priorities described in the survey.

We considered ranking vulnerabilities based on severity but found that the analysis did not identify specific vulnerabilities; it reported counts of 'issues' detected, where an 'issue' is a potential vulnerability. Determining whether an issue represents a vulnerability would require detailed source code analysis, which was not feasible due to the widespread use of obfuscation tools.

### 5. Results
This section presents our results from both the survey and the app analysis.

#### 5.1. Sample Validity
Comparing the box plots for invitees and participants in Figure 4, we observe that the average user rating and number of downloads for apps produced by the 345 developers who completed the surveys are very similar to those of the 55,000 invited.

One survey question asked about the respondent's years of experience in software development. Figure 5 compares these results with answers from a similar question in the 2019 Stack Overflow developer survey [43], which included 21,000 out of 89,000 developers. As seen, the respondents are generally more experienced than the general population (median 12 years; Mann-Whitney \(p = 10^{-4}\)).

To test whether our app selection criterion (over 100 downloads and at least one update) was too lenient, we used the Mann-Whitney test to compare developers of apps with fewer than 1000 downloads against the rest. We did this for all scores (Sections 3.6 and 4.2) and numerically analyzable survey questions. Small p-values (<0.003) were found only for questions correlating with download counts: "How many apps have you developed," "How many Android apps have you developed," and "Is developing apps your primary job." We concluded that the populations were essentially the same.

For Phase 2 scores, we found low p-values only for the Cryptographic API Misuse and Privacy Leak scores (\(p \approx 0.016\)). These values are not statistically significant given the number of tests performed. Therefore, we concluded there was no justification for changing our app selection criteria.

Finally, to check the accuracy of respondents' replies, we compared the stated app update interval with objective evidence. We correlated the time since the last update with the participant-stated update interval using log scales: Pearson \(R = 0.38\), \(P = 10^{-9}\) (n=242). The tiny P value corroborates the assumption that the stated update frequencies reflect reality, while the moderate R value reflects the randomness of the release cycle.

#### 5.2. Findings on Self-Reported Developer Behavior
The following sections describe the survey results for individual questions without considering associations between answers.

**Importance of Security and Privacy:** Figure 6 shows respondents' ratings of the importance of security and privacy in their apps. For comparison, we also asked about the importance of other functional and non-functional requirements. We were surprised to find that many developers consider security and privacy important, with ratings comparable to multi-platform support and higher than for many features.

**Team Structure:** Only 42% of respondents worked in teams, with the remainder being solo developers. Only 17% of respondents received support from professional security experts. For RQ3, we calculated the 95% confidence interval for the proportion working with security experts in the Android app developer population as:
- Lower bound = 14%
- Upper bound = 22%

**Developer Security Knowledge:** Figure 7 shows how survey participants rated their security expertise. Very few considered themselves to have no knowledge, which aligns with the high level of development experience of the participants (Section 5.1).

**Use of Assurance Techniques:** Figure 8 shows the reported use of assurance techniques. Threat assessment for every build and penetration testing are rare, but the proportions using each technique are fairly consistent across the board.

**Combinations of Assurance Techniques:** We investigated the extent to which teams used combinations of assurance techniques. Figure 9 summarizes the number and frequency of techniques used. Less than half had used even one technique; about a quarter used one or more regularly; and very few used as many as four regularly.

**Security Updates:** Figure 10 shows the frequency of security updates, calculated as the product of the reported update frequency and the reported proportion of security updates. The 95% confidence interval for the proportion with less than one update per year is 59% - 70%.

#### 5.3. Recent Changes in Team or Development Security
Given the rapid evolution of software security, it is crucial to understand what might have caused changes in developers' perceptions or actions around security. Two survey questions addressed this: one listing possible reasons for security and privacy improvements and asking which had affected app security, and another asking about changes made due to the recent European GDPR legislation [19], which impacts developers worldwide.

Figure 11 shows the answers. Interestingly, developers perceive themselves as the main driver of security improvements, even more so than GDPR. Encouragingly, very few (3%) reported security improvements as a result of actual security issues, suggesting that such incidents are still rare. A few more (7%) reported 'horror stories'â€”something bad happening to a competitor.

Of the 45% of participants (n=133) who reported changes due to GDPR, Figure 12 summarizes the changes they made. Most changes were cosmetic, such as updating privacy policies or adding pop-up dialogs. Only 33 made substantive changes to improve user security or privacy, giving 95% confidence limits of 8% to 15% for the wider Android developer population [48].

#### 5.4. Linear Analysis of Developer Survey Scores
Table 1 shows the results of the analysis described in Section 3.6, correlating each of the two dependent scores representing "security-enhancing activities and interactions in the development team" against four independent "need and mechanisms for security and privacy" scores. Non-italic figures highlighted in yellow indicate statistically significant results (\(p < 0.01\)).

Figure 13 shows x-y plots of these significant results, with dots and vertical bars indicating the mean and its 95% confidence interval for the y-readings corresponding to each x-value. The plots also show a simple linear regression line and its confidence limits, validating the preconditions for the use of Pearson R [35]: particularly homoscedasticity and lack of outliers.

#### 5.5. Post-Hoc Justification for Score Calculation and Analysis
The first two plots in Figure 13 justify our choice of the calculation for the Requirements Score and Expertise Support Score, as the use of assurance techniques shows a strong linear relationship to both scores.

For each of the six pairs of values highlighted in Table 1, we compared Decision Tree models with the corresponding linear models (F-Test, with a cut-off alpha of 0.01). We found no significant differences between the six pairs of models, justifying the use of the simpler Pearson R (linear) model. See Appendix D for details.

#### 5.6. Findings on Application Security Indications
In the Phase 2 analysis, CogniCrypt reported no issues for 32% of apps, FlowDroid for 35%, and the Bad SSL/MalloDroid combination for 70%. Only 20% of apps analyzed showed no issues from any of the tools.

#### 5.7. Linear Analysis of App Analysis Scores
Table 2 shows the results of the analysis described in Section 4.2, correlating each of three dependent scores representing "fewer security defects" with the independent scores from the developer survey.