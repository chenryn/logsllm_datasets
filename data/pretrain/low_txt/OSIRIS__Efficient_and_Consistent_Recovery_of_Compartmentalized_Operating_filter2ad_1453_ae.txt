### System Maturity and Performance Considerations

Our system is currently a research prototype and not a fully mature solution. Consequently, the relative overheads may differ when applied to a more efficient baseline system. Additionally, compartmentalization, which is a prerequisite for OSIRIS, introduces the overhead of switching between compartments. As a result, systems like OSIRIS are unlikely to match the performance levels of monolithic systems such as Linux. However, compartmentalization offers significant reliability advantages that can compensate for the performance loss, even without recovery mechanisms.

To enhance performance and balance the trade-off between performance and reliability, one could, in principle, integrate our compartment-based design into high-performance monolithic operating system architectures. For example, this could be achieved using virtualization-based isolation, as demonstrated in VirtuOS [17].

### Related Work

#### Shielding Systems from Software Faults

The ability to shield systems from software faults has been the subject of numerous prior research efforts. Techniques such as software rejuvenation, checkpoint-restart, and component dependency tracking have been applied to recover from faults in device drivers, operating systems, server and multi-tier applications, and distributed systems. In this section, we discuss prior research in these areas and how it relates to our work.

##### A. Recovering by Reboot/Restart

Restartability is a method to recover from failures or proactively avoid them, particularly transient and aging-related bugs [42]. This can be implemented at both the operating system and application level. Phase-based reboot [29] aims to speed up the reboot process by reusing system state from previous reboots, bringing the system back to a known consistent state. However, this approach comes at the cost of losing prior execution state and contributing to downtime.

MINIX 3 [25], [8] employs fault isolation to enable the restarting of only crashed drivers, which is effective for stateless recovery. Our approach, on the other hand, supports fully stateful recovery for arbitrary OS components. Application-level recovery has also been made possible through design-level considerations that allow only the affected components to be restarted [43], [30]. In the domain of distributed systems, Neutron [44] uses a similar approach to revive sensor network systems by restarting components. In our work, hardware-assisted fault isolation organizes the operating system into individually restartable fault domains. Although restart-based systems are relatively efficient and simple to implement, they suffer from the loss of state, making them suitable only for stateless components.

##### B. Checkpoint-Restart/Rollback

Checkpointing enables the revival of a system without losing much of its execution context. Solutions have been implemented at the level of operating systems, individual applications, and distributed systems.

At the operating system level, CuriOS [18] takes a virtual memory isolated multi-server approach where server state is persisted in client-side memory, allowing affected servers to be restarted without losing clients’ context. While this circumvents the need for checkpointing, it is only suitable for systems where frequent access to the clients’ address space from server processes is inexpensive. Fine-grained fault tolerance [15] relies on power management code to record device states, including checkpointing device driver state. A crash causes the system to roll back to the last driver entry-point state and restore the corresponding device state. This solution, while beneficial, is limited to drivers and does not scale well to complex operating system core components.

Checkpoint-based solutions for application recovery range from hypervisor-assisted techniques to fast in-memory checkpointing [45], [46]. Vogt et al. [22] describe user-space memory checkpointing techniques that rely on compiler-based instrumentation for high-frequency checkpointing. OSIRIS uses similar compiler-based techniques but selectively disables the checkpointing instrumentation during out-of-window execution.

Fault tolerance in distributed systems often involves redundancy- and replication-based methods, as well as checkpoint/snapshot-based recovery and message logging. Participant nodes take local snapshots in a coordinated or uncoordinated fashion to achieve fault tolerance [20], [44], [47], [48]. Message logging and replay is another alternative for message passing-based distributed systems [49], [21]. The multi-server architecture and message passing-based communication in OSIRIS resemble a miniature distributed system. However, the high-frequency and near-instantaneous message transfers in an operating system setting make a request-oriented local checkpointing scheme more suitable for our design.

##### C. Dependency Tracking

Consistent recovery requires rolling back not just the failed component but also all its dependent components whose state may be invalidated due to the rollback. Nooks [24] performs runtime object tracking to clean up kernel data structures manipulated by kernel extensions, protecting the entire kernel from faulty extensions. Swift et al. [14] introduce a shadow driver mechanism that monitors driver-kernel interactions and services requests on behalf of a failed driver. Akeso [19] organizes the Linux kernel into a request-oriented hierarchy of recovery domains, tracking inter-recovery domain dependencies at runtime. When a fault occurs, Akeso initiates the recovery of dependent domains and the failed recovery domain.

In distributed systems, optimistic recovery [21] uses causal dependency tracking among participating processes, allowing dependent processes to be rolled back during recovery. However, runtime dependency tracking generally incurs nontrivial performance overhead. Inter-component/process dependencies may lead to a cascade of component rollbacks, requiring special care to avoid a domino effect. The SEEP channel in our design eliminates runtime dependency monitoring and associated complexities, thereby limiting performance degradation.

##### D. Other Techniques

In addition to traditional checkpoint/restart, prior research has explored various ways to recover from system crashes. For example, ASSURE [26] and REASSURE [27] reuse existing error handling logic in applications to turn crashes into erroneous function return values. Carburizer [50] uses shadow drivers to turn device failures into software errors, avoiding kernel crashes. OSIRIS relies on similar error virtualization strategies but gracefully propagates error conditions through the message passing interface in compartmentalized operating system architectures.

### Conclusion

We presented a recovery strategy for fatal persistent software faults in compartmentalized operating systems that maintains system state consistency. Our design trades off the total recovery surface of the system for performance and simplicity. By limiting recoverability to execution paths that do not affect the global state, we significantly reduce runtime complexity. This enabled us to limit the RCB size to only 12.5% of our OSIRIS prototype, demonstrating that reliability goals are practically achievable. We implemented our recoverability mechanisms using LLVM-based instrumentation, which can be reused for other compartmentalized systems. Our framework is customizable, allowing new classes of SEEPs and recovery actions to be defined for new target systems. Experimental results demonstrate that OSIRIS' design is practical and effective in consistently recovering from even persistent software faults.

Overall, OSIRIS demonstrates that balancing recoverability, runtime performance, and simplicity of the reliable computing base can be an effective strategy to enhance the dependability of compartmentalized operating systems. To foster further research and support open science, we are open-sourcing our OSIRIS prototype, available at http://github.com/vusec/osiris.

### Acknowledgements

We would like to thank the anonymous reviewers for their comments. This work was supported by the European Commission through project H2020 ICT-32-2014 “SHARCS” under Grant Agreement No. 644571 and by the Netherlands Organisation for Scientific Research through the NWO 639.023.309 VICI “Dowsing” project and the NWO “Re-Cover” project.

### References

[1] A. Ganapathi and D. A. Patterson, “Crash data collection: A windows case study.” in DSN, 2005, pp. 280–285.
[2] R. Matias, M. Prince, L. Borges, C. Sousa, and L. Henrique, “An empirical exploratory study on operating system reliability,” in SAC, 2014, pp. 1523–1528.
[3] T. J. Ostrand and E. J. Weyuker, “The distribution of faults in a large industrial software system,” in ISSTA, 2002, pp. 55–64.
[4] T. J. Ostrand, E. J. Weyuker, and R. M. Bell, “Where the bugs are,” in ISSTA, 2004, pp. 86–96.
[5] T.-H. Chen, M. Nagappan, E. Shihab, and A. E. Hassan, “An empirical study of dormant bugs,” in MSR, 2014, pp. 82–91.
[6] M. M. Swift, B. N. Bershad, and H. M. Levy, “Improving the reliability of commodity operating systems,” ACM Trans. Comput. Syst., vol. 23, no. 1, pp. 77–110, Feb. 2005.
[7] A. Chou, J. Yang, B. Chelf, S. Hallem, and D. Engler, “An empirical study of operating systems errors,” in SOSP, 2001, pp. 73–88.
[8] J. N. Herder, H. Bos, B. Gras, P. Homburg, and A. S. Tanenbaum, “Construction of a highly dependable operating system,” in EDCC, 2006, pp. 3–12.
[9] N. Palix, G. Thomas, S. Saha, C. Calvès, J. Lawall, and G. Muller, “Faults in linux: ten years later,” in ACM SIGARCH Computer Architecture News, vol. 39, no. 1, 2011, pp. 305–318.
[10] S. Chandra and P. M. Chen, “Whither generic recovery from application faults? a fault study using open-source software,” in DSN, 2000, pp. 97–106.
[11] J. Gray, “Why do computers stop and what can be done about it?” in The 5th Symposium on Reliability in Distributed Software and Database Systems, 1985.
[12] A. Depoutovitch and M. Stumm, “Otherworld: giving applications a chance to survive OS kernel crashes,” in Proceedings of the 5th European conference on Computer systems, 2010, pp. 181–194.
[13] S. Sundararaman, S. Subramanian, A. Rajimwale, A. C. Arpaci-Dusseau, R. H. Arpaci-Dusseau, and M. M. Swift, “Membrane: Operating system support for restartable file systems,” TOS, vol. 6, no. 3, p. 11, 2010.
[14] M. M. Swift, M. Annamalai, B. N. Bershad, and H. M. Levy, “Recovering device drivers,” ACM Transactions on Computer Systems (TOCS), vol. 24, no. 4, pp. 333–360, 2006.
[15] A. Kadav, M. J. Renzelmann, and M. M. Swift, “Fine-grained fault tolerance using device checkpoints,” in ACM SIGARCH Computer Architecture News, vol. 41, no. 1. ACM, 2013, pp. 473–484.
[16] F. Zhou, J. Condit, Z. Anderson, I. Bagrak, R. Ennals, M. Harren, G. Necula, and E. Brewer, “Safedrive: Safe and recoverable extensions using language-based techniques,” in OSDI, 2006, pp. 45–60.
[17] R. Nikolaev and G. Back, “VirtuOS: An operating system with kernel virtualization,” in SOSP, 2013, pp. 116–132.
[18] F. M. David, E. Chan, J. C. Carlyle, and R. H. Campbell, “CuriOS: Improving reliability through operating system structure.” in OSDI, 2008, pp. 59–72.
[19] A. Lenharth, V. S. Adve, and S. T. King, “Recovery domains: An organizing principle for recoverable operating systems,” in ACM SIGARCH Computer Architecture News, vol. 37, no. 1, 2009, pp. 49–60.
[20] D. J. Sorin, M. M. Martin, M. D. Hill, D. Wood et al., “SafetyNet: Improving the availability of shared memory multiprocessors with global checkpoint/recovery,” in ISCA, 2002, pp. 123–134.
[21] R. Strom and S. Yemini, “Optimistic recovery in distributed systems,” TOCS, vol. 3, no. 3, pp. 204–226, 1985.
[22] D. Vogt, C. Giuffrida, H. Bos, and A. S. Tanenbaum, “Lightweight memory checkpointing,” in DSN, 2015, pp. 474–484.
[23] G. C. Hunt and J. R. Larus, “Singularity: Rethinking the software stack,” SIGOPS OSR, vol. 41, no. 2, pp. 37–49, 2007.
[24] M. M. Swift, S. Martin, H. M. Levy, and S. J. Eggers, “Nooks: An architecture for reliable device drivers,” in ACM SIGOPS European workshop, 2002, pp. 102–107.
[25] J. N. Herder, H. Bos, B. Gras, P. Homburg, and A. S. Tanenbaum, “Failure resilience for device drivers,” in DSN, 2007, pp. 41–50.
[26] S. Sidiroglou, O. Laadan, C. Perez, N. Viennot, J. Nieh, and A. D. Keromytis, “ASSURE: Automatic software self-healing using rescue points,” ACM SIGARCH Computer Architecture News, vol. 37, no. 1, pp. 37–48, 2009.
[27] G. Portokalidis and A. D. Keromytis, “REASSURE: A self-contained mechanism for healing software using rescue points,” in IWSEC, 2011, pp. 16–32.
[28] G. Janakiraman, J. R. Santos, D. Subhraveti, and Y. Turner, “CRUZ: Application-transparent distributed checkpoint-restart on standard operating systems,” in DSN, 2005, pp. 260–269.
[29] K. Yamakita, H. Yamada, and K. Kono, “Phase-based reboot: Reusing operating system execution phases for cheap reboot-based recovery,” in DSN, 2011, pp. 169–180.
[30] G. Candea, J. Cutler, A. Fox, R. Doshi, P. Garg, and R. Gowda, “Reducing recovery time in a small recursively restartable system,” in DSN, 2002, pp. 605–614.
[31] C. Giuffrida, L. Cavallaro, and A. S. Tanenbaum, “We crashed, now what,” in HotDep, 2010, pp. 1–8.
[32] D. Vogt, A. Miraglia, G. Portokalidis, H. Bos, A. Tanenbaum, and C. Giuffrida, “Speculative memory checkpointing,” in Middleware, 2015, pp. 197–209.
[33] C. Lattner and V. Adve, “LLVM: A compilation framework for lifelong program analysis & transformation,” in CGO, 2004, pp. 75–86.
[34] M. Engel and B. Döbel, “The reliable computing base: A paradigm for software-based reliability,” in Workshop on SOBRES, 2012.
[35] “A UNIX benchmark suite, the original BYTE UNIX benchmark suite, updated and revised by many people over the years.” https://github.com/kdlucas/byte-unixbench, accessed: July 24th, 2015.
[36] “MINIX 3 source repository,” http://git.minix3.org/index.cgi?p=minix.git.
[37] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “EDFI: A dependable fault injection tool for dependability benchmarking experiments,” in PRDC, 2013, pp. 1–10.
[38] H. H. M. H. J. Liedtke and S. S. J. Wolter, “The performance of microkernel-based systems,” in SOSP, 1997.
[39] J. Liedtke, On micro-kernel construction. ACM, 1995, vol. 29, no. 5.
[40] J. Liedtke, “Improving IPC by kernel design,” in SIGOPS OSR, vol. 27, no. 5, 1994, pp. 175–188.
[41] J. Wu, H. Cui, and J. Yang, “Bypassing races in live applications with execution filters.” in OSDI, vol. 10, 2010, pp. 1–13.
[42] Y. Huang, C. Kintala, N. Kolettis, and N. D. Fulton, “Software rejuvenation: Analysis, module and applications,” in FTCS, 1995, pp. 381–390.
[43] G. Candea, S. Kawamoto, Y. Fujiki, G. Friedman, and A. Fox, “Microreboot—a technique for cheap recovery.” in OSDI, vol. 4, 2004, pp. 31–44.
[44] Y. Chen, O. Gnawali, M. Kazandjieva, P. Levis, and J. Regehr, “Surviving sensor network software faults,” in SOSP, 2009, pp. 235–246.
[45] M. Lee, A. Krishnakumar, P. Krishnan, N. Singh, and S. Yajnik, “Hypervisor-assisted application checkpointing in virtualized environments,” in DSN, 2011, pp. 371–382.
[46] F. Qin, J. Tucek, J. Sundaresan, and Y. Zhou, “Rx: Treating bugs as allergies—a safe method to survive software failures,” in SIGOPS OSR, vol. 39, no. 5, 2005, pp. 235–248.
[47] P. Sousa, A. N. Bessani, M. Correia, N. F. Neves, and P. Verissimo, “Highly available intrusion-tolerant services with proactive-reactive recovery,” TPDS, vol. 21, no. 4, pp. 452–465, 2010.
[48] A. Agbaria and R. Friedman, “Starfish: Fault-tolerant dynamic MPI programs on clusters of workstations,” Cluster Computing, vol. 6, no. 3, pp. 227–236, 2003.
[49] A. Borg, J. Baumbach, and S. Glazer, “A message system supporting fault tolerance,” ACM SIGOPS Operating Systems Review, vol. 17, no. 5, pp. 90–99, 1983.
[50] A. Kadav, M. J. Renzelmann, and M. M. Swift, “Tolerating hardware device failures in software,” in SOSP, 2009, pp. 59–72.