### Feature Attention Analysis

We analyzed the samples and identified the words that received the most attention. We then determined which features these words corresponded to. The results, summarized in Table 5, show that file operations were the most frequently attended to, followed by API calls, network activities, and DLL loads. Notably, file operations also performed the best as an individual feature, indicating that the feature receiving the highest attention was also the most effective on its own.

| **Feature** | **Number of times in top attention** |
|-------------|-------------------------------------|
| File        | 831                                 |
| API         | 305                                 |
| Network     | 107                                 |
| DLL Loads   | 95                                  |
| Mutex       | 72                                  |
| Registry    | 20                                  |

**Table 5:** This table shows the number of times each feature appeared among the top 10 most important words according to the attention score for 100 samples.

### Answer for RQ2
Natural Language Processing (NLP) techniques for document classification can be effectively applied to malware detection reports, yielding significantly better results than our Raw Model neural network.

### Answer for RQ4
Neurlux appears to be learning to use the best combinations of features. Specifically, it pays more attention to file operations and API calls, which are crucial for detecting malware.

## 6.5 Robustness

We observed that all approaches had lower accuracies when tested on datasets or sandbox reports they were not trained on. The differences in report formats likely account for the drop in accuracy. However, the lower accuracy on VendorDataset suggests that the learned features may not generalize well to all executables. This could be due to deficiencies in the training set, such as a lack of diverse samples, or the model's reliance on specific features that do not generalize well. Neurlux demonstrated the best robustness to different report formats, while other NLP-based deep learning models also showed decent robustness, suggesting that NLP techniques provide more generalizable features compared to our raw bytes approach.

### Answer for RQ3
Neurlux is the most robust of the models we tested, achieving the highest accuracy on another dataset and report format. In contrast, our raw bytes model performed poorly across different datasets and reports, indicating that the features learned using text classification approaches are more general.

## 6.6 Unseen Malware Family

In another experiment, we removed one malware family (Trojan.Viz.Gen.1) from the training data and evaluated Neurlux's classification accuracy on this family. Despite the absence of this family in the training data, Neurlux correctly classified all 346 samples as malware.

## 6.7 Performance

Our experiments were conducted on an Nvidia Titan RTX GPU and a Xeon Gold 6252 processor. The training process took 19.47 milliseconds per sample, and the detection process took 8.21 milliseconds per sample. Data cleaning and preprocessing ran at a rate of 6.16 milliseconds per sample.

## 7. Discussion and Future Work

One limitation of Neurlux is that it performs classification based on behavior seen in dynamic analyses, making it less effective as a preventative measure. However, it is still valuable for identifying malware to generate signatures or detect infections. Neurlux's ability to detect previously unseen malware families indicates its potential for use even on unanalyzed malware. Further exploration of the correlations between different malware families could enhance this capability.

Neurlux relies on accurate and broad training data. Future work will focus on improving its resilience to the quality of training data and exploring different execution environments to determine if one provides better results. Other directions for future work include investigating different models to improve performance, such as image recognition techniques, which have shown promising results. These models, known for their effectiveness in image recognition tasks, can also benefit from transfer learning.

### 7.1 Adversarial Learning

Recent studies have shown that adversarial learning can be used to evade machine learning-based malware classifiers. By generating adversarial samples, it is possible to perturb the feature vectors of original malware samples to change their classification from malicious to benign. The core of adversarial sample crafting involves computing the gradient of the classification function with respect to the feature vector to estimate the direction of maximum change. This technique, first introduced by Nguyen et al. [20], has been adapted to attack security systems that rely on machine learning models. Enhancing robustness against such attacks is an essential design characteristic, and our future work will focus on making Neurlux more resilient to adversarial attacks.

## 8. Related Work

Numerous studies have explored the use of machine learning and NLP models for malware classification, each bringing unique strengths and trade-offs. Initially, various machine learning models, such as Support Vector Machines (SVM), Decision Trees (DT), Random Forest, and K-Nearest Neighbor (KNN), were used. Recently, neural networks have become prevalent for malware detection and classification.

Saxe et al. [33] proposed a method to distinguish malware from benign software using a deep learning approach with four types of static features: entropy histogram, PE import, string 2D histogram, and PE metadata. Fan et al. [4] developed a sequence mining algorithm to discover consecutive malicious patterns using an All-Nearest-Neighbor classifier, focusing on static features and requiring domain knowledge for feature extraction.

Zheng et al. [43] created a behavior chain to aid in detection by monitoring API calls and constructing a behavior chain at runtime. They used Long Short-Term Memory (LSTM) to detect malicious behavior. Salehi et al. [31] recorded API call arguments and return values to create a selective and discriminative feature set for SVM classification. Other methods focused on API sequence calls for dynamic malware classification [23, 32, 35]. However, limiting to one type of feature restricts the vast feature space that can represent different malware behaviors.

MalInsight [7] profiles malware based on basic structure, low-level behavior, and high-level behavior, building a feature space on structural, OS interaction, and operational features. Han et al. selected features from Cuckoo sandbox reports and trained on them, but did not use neural networks or the entire report as Neurlux does.

Another approach, based on early-stage recognition [29], uses a recurrent neural network to predict malware using the first few seconds of file execution. Zhong et al. [44] suggested that a single deep learning model is insufficient and proposed a Multi-Level Deep Learning System, partitioning data using static and dynamic features, creating a convolutional model for each cluster, and combining them into a final model.

MalDy [11] uses a bag-of-words approach with an ensemble of models, but this method does not consider context and produces sparse feature vectors. In contrast, Neurlux, which uses word embeddings, produces dense, low-dimensional feature vectors, resulting in higher validation accuracy and better generalization to other datasets and report formats, as shown in Table 3.

## 9. Conclusions

This paper introduces Neurlux, a robust malware detection tool that identifies malicious files based on their run-time behavior without the need for feature engineering. Leveraging techniques from document classification, Neurlux outperforms similar approaches in malware classification. Our evaluation results show that Neurlux maintains high detection accuracy across different datasets and report formats, demonstrating its real-world applicability.

## Acknowledgments

This research was supported by a gift from Intel for the investigation of machine learning for malware analysis, the National Science Foundation grant #CNS-1704253, and DARPA under agreement number #FA8750-19-C-0003. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes. The views and conclusions are those of the authors and do not necessarily represent the official policies or endorsements of DARPA or the U.S. Government. We also thank Lastline for providing the data that made this research possible.

## References

[1] Cuckoo, automated malware analysis. https://cuckoosandbox.org/.

[2] H. S. Anderson and P. Roth. Ember: An open dataset for training static PE malware machine learning models. arXiv preprint arXiv:1804.04637, 2018.

[3] T. Brosch and M. Morgenstern. Runtime Packers: The Hidden Problem? Black Hat USA, 2006.

[4] Y. Fan, Y. Ye, and L. Chen. Malicious sequential pattern mining for automatic malware detection. Expert Systems with Applications, 52:16–25, 2016.

[5] T. Garfinkel, K. Adams, A. Warfield, and J. Franklin. Compatibility is not transparency: VMM detection myths and realities. In HotOS, 2007.

[6] K. Grosse, N. Papernot, P. Manoharan, M. Backes, and P. McDaniel. Adversarial examples for malware detection. In European Symposium on Research in Computer Security, pages 62–79. Springer, 2017.

[7] W. Han, J. Xue, Y. Wang, Z. Liu, and Z. Kong. Malinsight: A systematic profiling-based malware detection framework. Journal of Network and Computer Applications, 125:236–250, 2019.

[8] S. Hochreiter. The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107–116, 1998.

[9] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.

[10] Kanchan Sarkar. Recent trends in natural language processing using deep learning, 2017. https://medium.com/@kanchansarkar/recent-trends-in-natural-language-processing-using-deep-learning-a1469fbd2ef.

[11] E. B. Karbab and M. Debbabi. MalDy: Portable, data-driven malware detection using natural language processing and machine learning techniques on behavioral analysis reports. Digital Investigation, 28:S77–S87, 2019.

[12] A. Kharaz, S. Arshad, C. Mulliner, W. Robertson, and E. Kirda. UNVEIL: A large-scale, automated approach to detecting ransomware. In 25th USENIX Security Symposium (USENIX Security 16), pages 757–772, 2016.

[13] C. Kolbitsch, P. M. Comparetti, C. Kruegel, E. Kirda, X.-y. Zhou, and X. Wang. Effective and efficient malware detection at the end host. In USENIX security symposium, volume 4, pages 351–366, 2009.

[14] B. Kolosnjaji, A. Zarras, G. Webster, and C. Eckert. Deep learning for classification of malware system call sequences. In Australasian Joint Conference on Artificial Intelligence, pages 137–149. Springer, 2016.

[15] M. Lindorfer, C. Kolbitsch, and P. M. Comparetti. Detecting environment-sensitive malware. In International Workshop on Recent Advances in Intrusion Detection, pages 338–357. Springer, 2011.

[16] M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning transferable features with deep adaptation networks. arXiv preprint arXiv:1502.02791, 2015.

[17] L. v. d. Maaten and G. Hinton. Visualizing data using t-SNE. Journal of Machine Learning Research, 9(Nov):2579–2605, 2008.

[18] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111–3119, 2013.

[19] A. Moser, C. Kruegel, and E. Kirda. Limits of static analysis for malware detection. In Twenty-Third Annual Computer Security Applications Conference (ACSAC 2007), pages 421–430. IEEE, 2007.

[20] A. Nguyen, J. Yosinski, and J. Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 427–436, 2015.

[21] D. Oktavianto and I. Muhardianto. Cuckoo malware analysis. Packt Publishing Ltd, 2013.

[22] G. Paltoglou and M. Thelwall. More than bag-of-words: Sentence-based document representation for sentiment analysis. In Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013, pages 546–552, 2013.

[23] N. Peiravian and X. Zhu. Machine learning for Android malware detection using permission and API calls. In 2013 IEEE 25th International Conference on Tools with Artificial Intelligence, pages 300–305. IEEE, 2013.

[24] R. Perdisci, A. Lanzi, and W. Lee. MCBoost: Boosting scalability in malware collection and analysis using statistical classification of executables. In 2008 Annual Computer Security Applications Conference (ACSAC), pages 301–310. IEEE, 2008.

[25] E. Raff, J. Sylvester, and C. Nicholas. Learning the PE header, malware detection with minimal domain knowledge. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pages 121–132. ACM, 2017.

[26] E. Raff, J. Barker, J. Sylvester, R. Brandon, B. Catanzaro, and C. K. Nicholas. Malware detection by eating a whole EXE. In Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence, 2018.

[27] T. Raffetseder, C. Kruegel, and E. Kirda. Detecting system emulators. In International Conference on Information Security, pages 1–18. Springer, 2007.

[28] B. Rahbarinia, M. Balduzzi, and R. Perdisci. Exploring the long tail of (malicious) software downloads. In 2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pages 391–402. IEEE, 2017.

[29] M. Rhode, P. Burnap, and K. Jones. Early-stage malware prediction using recurrent neural networks. Computers & Security, 77:578–594, 2018.

[30] C. Rossow, C. J. Dietrich, C. Grier, C. Kreibich, V. Paxson, N. Pohlmann, H. Bos, and M. Van Steen. Prudent practices for designing malware experiments: Status quo and outlook. In 2012 IEEE Symposium on Security and Privacy, pages 65–79. IEEE, 2012.

[31] Z. Salehi, A. Sami, and M. Ghiasi. MAAR: Robust features to detect malicious activity based on API calls, their arguments, and return values. Engineering Applications of Artificial Intelligence, 59:93–102, 2017.

[32] A. Sami, B. Yadegari, H. Rahimi, N. Peiravian, S. Hashemi, and A. Hamze. Malware detection based on mining API calls. In Proceedings of the 2010 ACM Symposium on Applied Computing, pages 1020–1025. ACM, 2010.

[33] J. Saxe and K. Berlin. Deep neural network-based malware detection using two-dimensional binary program features. In Malicious and Unwanted Software (MALWARE), 2015 10th International Conference on, pages 11–20. IEEE, 2015.

[34] D. Sgandurra, L. Muñoz-González, R. Mohsen, and E. C. Lupu. Automated dynamic analysis of ransomware: Benefits, limitations, and use for detection. arXiv preprint arXiv:1609.03020, 2016.

[35] M. K. Shankarapani, S. Ramamoorthy, R. S. Movva, and S. Mukkamala. Malware detection using assembly and API call sequences. Journal in Computer Virology, 7(2):107–119, 2011.

[36] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.

[37] K. Simonyan, A. Vedaldi, and A. Zisserman. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034, 2013.

[38] D. Ucci, L. Aniello, and R. Baldoni. Survey on the usage of machine learning techniques for malware analysis. arXiv preprint arXiv:1710.08189, 2017.

[39] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pages 5998–6008, 2017.

[40] VirusTotal. AV comparative analyses. https://blog.virustotal.com/2012/08/av-comparative-analyses-marketing-and.html. (Accessed: 2019-3-31).

[41] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy. Hierarchical attention networks for document classification. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1480–1489, 2016.

[42] L. Zeltser. How malware generates mutex names to evade detection. https://isc.sans.edu/diary/How+Malware+Generates+Mutex+Names+to+Evade+Detection/19429/. (Accessed: 2019-5-31).