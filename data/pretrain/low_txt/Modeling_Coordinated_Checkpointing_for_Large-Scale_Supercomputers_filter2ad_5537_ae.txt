### Timeout Behavior and Performance Impact

Timeouts function similarly to a probabilistic checkpoint-abort mechanism. The probability of aborting a checkpoint is influenced by the coordination time (Mean Time to Quiescence, MTTQ, and the number of compute processors) and the timeout duration. Short timeouts result in a high probability of checkpoint abortion, which can negate the benefits of reducing processor wait times due to frequent checkpoint restarts. Figure 6 clearly illustrates this performance degradation with timeouts ranging from 20 to 100 seconds.

However, the system becomes less sensitive to timeouts if they are sufficiently long. This is because the overall coordination time increases slowly with the number of processors. For instance, the performance of an 8192-processor system with a 100-second timeout is only marginally better than with a 120-second timeout or no timeout at all.

### Effect of Correlated Failures

We consider two categories of correlated failures:

1. **Correlated Failures Due to Error Propagation:**
   - These failures are modeled using three parameters: error propagation rate (pe), correlated failure factor (r), and correlated failure window.
   - In real systems, a typical value for r is on the order of a few hundred. Our experiments use r values of 400, 800, and 1600 for various pe values, with a correlated failure window of 3 minutes.
   - As shown in Figure 7, the useful work fraction is not significantly affected by correlated failures due to error propagation, as it ranges between 0.51 and 0.56. This is because these failures are assumed to occur during recovery, and such failures have a minimal impact on the useful work fraction.

2. **Generic Correlated Failures:**
   - Generic correlated failures are modeled with two parameters: correlated failure factor (r) and correlated failure coefficient (α).
   - In our experiment, we use an r value of 400 and an α value of 0.0025, which doubles the entire system's failure rate.
   - Figure 8 shows that, unlike correlated failures due to error propagation, generic correlated failures cause significant performance degradation, hindering system scalability. For a system with 256K processors and an MTTF of 3 years per node, the useful work fraction is reduced by 0.24 (51%).

### Conclusions

This paper models a large-scale supercomputing system with coordinated checkpointing and rollback recovery. Unlike existing models, this study includes failures during checkpointing/recovery, coordination for checkpointing, and correlated failures. The impact of these factors on system performance (measured as the useful work fraction and total useful work) and scalability for systems with several hundred thousand processors is studied through simulation. Key conclusions include:

- For a given checkpoint interval, Mean Time to Repair (MTTR), and Mean Time to Failure (MTTF), there is an optimal number of processors that maximizes the total useful work. For example, with an MTTF of 1 year per node and an MTTR of 10 minutes, the optimal number is around 128K.
- The overall useful work fraction is relatively low due to the effect of failures in large-scale systems.
- Correlated failures must be considered, as they degrade performance and limit system scalability.

### Acknowledgments

This work was supported in part by NSF grants ACI-0121658 ITR/AP and ACI-CNS-0406351 (Next Generation Software). We thank Prof. W. Sanders for his suggestions on SAN modeling and Dr. B. Murphy for his advice and suggestions on the paper revision.

### References

[1] N.R. Adiga et al., “An Overview of the Blue Gene/L,” Proc. of IEEE Int’l Conference on Supercomputing, 2002.
[2] J. S. Plank, "An Overview of Checkpointing in Uniprocessor and Distributed Systems, Focusing on Implementation and Performance,” Technical Report of University of Tennessee, UT-CS, 1997.
[3] M. Chandy, L. Lamport. “Distributed Snapshots: Determinining Global States of Distributed Systems,” ACM Trans. on Computing Systems, 3(1), 1985.
[4] R. Koo, S. Toueg, “Checkpointing and Recovery Rollback for Distributed Systems,” IEEE Trans. on Software Engineering, Vol. SE-13, No. 1, 1987.
[5] F. Petrini, K. Davis, J. C. Sancho, “System Level Fault Tolerance in Large-Scale Parallel Machines,” Proc. of IEEE Int’l Parallel and Distributed Processing Symp. (IPDPS'04), 2004.
[6] D. Tang, R. K. Iyer, “Analysis and Modeling of Correlated Failures in Multicomputer Systems,” IEEE Trans. on Computers, Vol. 41, Num. 5, 1992.
[7] J. W. Young, “A First Order Approximation to the Optimum Checkpoint Interval,” Communications of the ACM, Vol. 17, Num. 9, 1974.
[8] J. Daly, “A Model for Predicting the Optimum Checkpoint Interval for Restart Dumps,” Proc. of Int’l Conference on Computational Science, 2003.
[9] G. P. Kavanaugh, W. H. Sanders, “Performance Analysis of Two Time-based Coordinated Checkpointing Protocols,” Proc. of IEEE Pacific Rim Int’l Symp. on Fault Tolerant Systems, 1997.
[10] J. S. Plank, M. G. Thomason, “The Average Availability of Parallel Checkpointing Systems and Its Importance in Selecting Runtime Parameters,” IEEE Proc. Int’l Symp. on Fault-Tolerant Computing, 1999.
[11] E. N. Elnozahy, J. S. Plank, W. K. Fuchs, “Checkpointing for Peta-Scale Systems: A Look into the Future of Practical Rollback-Recovery,” IEEE Trans. on Dependable and Secure Computing, Vol. 1, Num. 2, 2004.
[12] N. H. Vaidya, “On Checkpoint Latency,” Proc. of IEEE Pacific Rim Int’l Symp. on Fault-Tolerant Systems, 1995.
[13] L. G. Valiant, “A Bridging Model for Parallel Computation” Communications of the ACM, Vol. 33, 1990.
[14] E. Smirni, D. A. Reed, “Workload Characterization of Input/Output Intensive Parallel Applications,” Proc. of Int’l Conference on Computer Performance Evaluation: Modeling Techniques and Tools, 1997.
[15] E. Rosti, et al., “Models of Parallel Applications with Large Computation and I/O Requirements,” IEEE Trans. on Software Engineering, Vol.28, Num. 3, 2002.
[16] D. P. Siewiorek, R. S. Swarz, Reliable Computer Systems: Design and Evaluation, 2nd ed., Digital Press, 1992.
[17] G. Kulkarni, V. F. Nicola, K. S. Trivedi, “The Completion Time of a Job on Multimode Systems,” Advances in Applied Probability, Vol. 19, 1987.
[18] Y. Zhang, et al., "Performance Implications of Failures in Large-Scale Cluster Scheduling,” 10th Workshop on Job Scheduling Strategies for Parallel Processing, 2004.
[19] B. Tuthill, et al. “IRIX Checkpoint and Restart Operation Guide,” Document of Silicon Graphics, Inc., 1999.
[20] R. Iyer, D. Rossetti, "A Measurement-based Model for Workload Dependence of CPU Errors,” IEEE Trans. on Computers, Vol. C-35, 1986.
[21] T. Courtney et al., “The Möbius Modeling Environment,” Tools of the 2003 Illinois Int’l Multiconference on Measurement, Modelling, and Evaluation of Computer Communication Systems, Universität Dortmund Fachbereich Informatik research report no. 781, 2003.
[22] L. Spainhower, T. A. Gregg, “IBM S/390 Parallel Enterprise Server G5 Fault Tolerance: A Historical Perspective,” IBM Journal of Research and Development, Vol. 43, Num. 5/6, 1999.
[23] G. Bronevetsky et al., “Automated Application-level Checkpointing of MPI Programs,” Proc. of ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, 2003.
[24] S. Agarwal et al., “Adaptive Incremental Checkpointing for Massively Parallel Systems,” Proc. of IEEE Int’l Conference on Supercomputing, 2004.
[25] L. Wang et al., “Modeling Coordinated Checkpointing for Large-Scale Supercomputers,” Technical Report of University of Illinois, 2005.

Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05)  
0-7695-2282-3/05 $20.00 © 2005 IEEE