# Pseudo-Randomness and the Crystal Ball

**Author:** Cynthia Dwork  
**Affiliation:** Harvard University, Department of Computer Science, Cambridge, MA, USA

## Abstract
Over the past decade, algorithmic fairness has emerged as a critical frontier in the application of theoretical computer science to societal issues. The rapid transition from academic investigation to industry acknowledgment of these concerns has had both positive and negative implications, including the swift adoption of new technologies and the pressure for quick solutions.

Early literature on this topic distinguishes between group-based fairness, which compares prediction or classification statistics across (typically disjoint) demographic groups, and individual fairness, which requires that similar individuals be treated similarly [2]. Both approaches face significant challenges. Group fairness criteria, while appealing, can be meaningless [2, 8] or mutually incompatible [1, 7]. Individual fairness, on the other hand, requires a task-specific metric to measure the similarity between pairs of individuals, a metric that has only recently been addressed [6]; see also [4].

The focus on similarity metrics has highlighted foundational questions about randomness and uncertainty. Some of these questions are specific to the philosophy of fairness, such as the value of an ex ante guarantee of fairness provided by a roll of the dice. Others involve the choice of metric, exposing the role of context. For example, should the likelihood of a job candidate's success be evaluated in the context of the work culture of the specific company listing the position, or in an ideal, more inclusive company with a stronger culture of inclusivity?

A third set of questions revolves around the meaning of "probability" for non-repeatable events, such as the probability that a specific individual will succeed in a particular job. In cryptography, parties are algorithms that flip coins, and individuals interact with environments also endowed with randomness, providing well-defined probability spaces. However, when randomness is no longer controlled by algorithms, this model no longer applies.

**Outcome Indistinguishability** is a desirable property for prediction algorithms. Similar to pseudo-randomness, Outcome Indistinguishability is defined with respect to a computational class \( C \) of distinguishers. Specifically, a prediction algorithm mapping individuals to \([0, 1]\) is Outcome Indistinguishable with respect to \( C \) if outcomes drawn according to its predictions are indistinguishable, by any computation in \( C \), from outcomes drawn according to Nature [3]. In other words, the model of the real world provided by the algorithm cannot be falsified by members of \( C \).

With this notion in place, we obtain a natural hierarchy of Outcome Indistinguishability, with the levels differing in the degree of access that the distinguisher has to the prediction algorithm. The lower levels of this hierarchy are equivalent to multi-accuracy and multi-calibration, previously explored in an approach to fairness aiming to bridge the gap between individual and group notions [5]. We will discuss some highlights of what is known and what is new in this rapidly evolving area.

## Keywords
Algorithmic fairness, theory of algorithmic fairness, fairness, individual fairness, indistinguishability, outcome indistinguishability, machine learning, artificial intelligence, risk assessment, prediction algorithms, individual probability, forecasting, calibration, multi-calibration

## ACM Reference Format
Cynthia Dwork. 2021. Pseudo-Randomness and the Crystal Ball. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security (CCS '21), November 15–19, 2021, Virtual Event, Republic of Korea. ACM, New York, NY, USA, 2 pages. https://doi.org/10.1145/3460120.3482790

## Biography
Cynthia Dwork is the Gordon McKay Professor of Computer Science at the Harvard Paulson School of Engineering, and Affiliated Faculty at Harvard Law School and the Harvard Department of Statistics. She uses theoretical computer science to address societal problems with a solid mathematical foundation. Her early work in distributed computing established the pillars on which every fault-tolerant system has been built for decades. Her innovations have modernized cryptography to withstand the ungoverned interactions of the internet and the eventuality of quantum computing. Her invention of Differential Privacy has revolutionized privacy-preserving statistical data analysis. In 2012, she launched the theoretical investigation of algorithmic fairness. She is a recipient of numerous awards and is a member of the National Academy of Sciences (NAS), the National Academy of Engineering (NAE), the American Academy of Arts and Sciences, and the American Philosophical Society.

## References
[1] Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. *Big Data* 5, 2 (2017), 153–163.

[2] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In *Proceedings of the 3rd Innovations in Theoretical Computer Science Conference*. 214–226.

[3] Cynthia Dwork, Michael P. Kim, Omer Reingold, Guy N. Rothblum, and Gal Yona. 2021. Outcome indistinguishability. In *Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing*. 1095–1108.

[4] Stephen Gillen, Christopher Jung, Michael Kearns, and Aaron Roth. 2018. Online learning with an unknown fairness metric. arXiv preprint arXiv:1802.06936 (2018).

[5] Ursula Hébert-Johnson, Michael Kim, Omer Reingold, and Guy Rothblum. 2018. Multicalibration: Calibration for the (computationally-identifiable) masses. In *International Conference on Machine Learning*. PMLR, 1939–1948.

[6] Christina Ilvento. 2019. Metric learning for individual fairness. arXiv preprint arXiv:1906.00250 (2019).

[7] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2017. Inherent trade-offs in the fair determination of risk scores. In *8th Innovations in Theoretical Computer Science Conference (ITCS 2017)*. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.

[8] Roland Neil and Christopher Winship. 2019. Methodological challenges and opportunities in testing for racial discrimination in policing. *Annual Review of Criminology* 2 (2019), 73–98.