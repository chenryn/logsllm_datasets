### References
1. Y. Jia, Y. Lu, J. Shen, Q. A. Chen, H. Chen, Z. Zhong, and T. Wei, "Fooling Detection Alone is Not Enough: Adversarial Attack Against Multiple Object Tracking," in *International Conference on Learning Representations (ICLR)*, 2019.
2. J. Shen, J. Y. Won, Z. Chen, and Q. A. Chen, "Drift with Devil: Security of Multi-Sensor Fusion based Localization in High-Level Autonomous Driving under GPS Spoofing," in *USENIX Security Symposium*, 2020.
3. K. Tang, J. Shen, and Q. A. Chen, "Fooling Perception via Location: A Case of Region-of-Interest Attacks on Traffic Light Detection in Autonomous Driving," in *Workshop on Automotive and Autonomous Vehicle Security (AutoSec)*, 2021.
4. M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, "Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition," in *ACM SIGSAC Conference on Computer and Communications Security (ACM CCS)*, pp. 1528–1540, 2016.
5. S.-T. Chen, C. Cornelius, J. Martin, and D. H. P. Chau, "Shapeshifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector," in *Joint European Conference on Machine Learning and Knowledge Discovery in Databases*, pp. 52–68, Springer, 2018.
6. Z. Zhong, W. Xu, Y. Jia, and T. Wei, "Perception Deception: Physical Adversarial Attack Challenges and Tactics for DNN-Based Object Detection," in *Black Hat Europe*, 2018.
7. N. S. Council, *Reference Material for DDC Instructors*, 5th Edition, 2005.
8. UK ACPO Road Policing Enforcement Technology Committee, *ACPO Code of Practice for Operational Use of Enforcement Equipment*, 2002.
9. U. D. for Transport, *The Official Highway Code Book*, 2015.
10. H. Loeb, A. Belwadi, J. Maheshwari, and S. Shaikh, "Age and Gender Differences in Emergency Takeover from Automated to Manual Driving on Simulator," *Traffic Injury Prevention*, pp. 1–3, 2019.
11. "Watch Tesla Drivers Apparently Asleep at the Wheel, Renewing Autopilot Safety Questions." https://www.cnbc.com/2019/09/09/watch-tesla-drivers-apparently-asleep-at-the-wheel-renewing-safety-questions.html, 2019.
12. "Amazon Mechanical Turk." https://www.mturk.com/.
13. "Driver Take-Over Decision Survey with Automated Lane Centering System in our User Study." https://storage.googleapis.com/driving-decision-survey/driving_decision_survey.pdf, 2020.

### Required Deviations and Success Time

#### Required Deviations
The required deviations for highways and local roads are calculated based on the Toyota RAV4's width (including mirrors) and standard lane widths in the U.S. [62], as shown in Figure 16. We use the Toyota RAV4 because it is the reference vehicle used by the OpenPilot team when collecting the comma2k19 dataset [56]. For lane widths, we refer to the design guidelines [62] published by the U.S. Department of Transportation Federal Highway Administration. The required deviations to touch the lane line are calculated using \( \frac{L - C}{2} = 0.735 \) m (highway) and 0.285 m (local), where \( L \) is the lane width and \( C \) is the vehicle width.

#### Required Success Time
Since ALC systems assume a fully attentive human driver who is prepared to take over at any moment [1, 7], the required deviation must be achieved quickly enough that the human driver cannot react in time to steer back. Thus, our attack goal requires not only the specified deviation but also an attack success time shorter than the average driver reaction time to road hazards. We select the average driver reaction time based on different government-issued transportation policy guidelines [57, 96]. Specifically, the California Department of Motor Vehicles Commercial Driver Handbook Section 2.6.1 [57] describes:
- An average perception time of 1.75 seconds (time from seeing a hazard until recognizing it).
- An average reaction time of 0.75 to 1 second (time from recognizing the hazard to taking action).

Thus, the total time from seeing a hazard to taking action is 2.5 to 2.75 seconds. The UK "Highway Code Book" and "Code of Practice for Operational Use of Road Policing Enforcement Technology" use 3 seconds for driver reaction time [97, 98]. The National Safety Council also adopts a 3-second driver reaction time to calculate the minimum spacing between vehicles [96]. Among these, we select the smallest value, 2.5 seconds from the California Department of Motor Vehicles [57], as the required success time in this paper to avoid overestimating the attack effectiveness in our evaluation.

Note that the driver reaction time typically refers to the time to apply the brake, rather than steering. In our paper, we use the reaction time to apply the brake as the reaction time to take over the steering wheel when the ALC system is in control. This is because, in traditional driving, the driver actively steers the vehicle but passively applies the brake. However, when the ALC system controls the steering, the human driver is passively steering, i.e., their hands are not actively controlling the steering wheel. Therefore, the reaction time to take over the steering wheel during passive steering is analogous to the reaction time to apply the brake during passive braking.

In fact, the actual average driver reaction time when the ALC system is in control is likely much higher than the 2.5 seconds measured in traditional driving due to the reliance on such convenient driving automation technology. A recent study found that 40% of drivers fail to react in time to avoid a crash 6.2 seconds after the Autopilot fails to operate [99]. In the real world, it has been observed multiple times that Tesla drivers fall asleep with Autopilot controlling the vehicle at high speeds [100]. Thus, the required success time of 2.5 seconds used in this paper is a conservative estimate, and the reported attack effectiveness in our evaluations is likely a lower bound of the actual effectiveness in the real world.

### Evaluation Setup
We used Amazon Mechanical Turk [101] to conduct this study, collecting data from 100 participants. All participants have driving experience, confirmed by asking about their age when first licensed and their weekly driving mileage. A local-road driving trace was used, and for scenarios with attacks, we evaluated three stealthiness levels (λ = 10−2, 10−3, 10−4) as in §5.1. The survey is available at [102]. Among the 100 participants, 56% were male and 44% were female, with an average age of 32.3 years. 79% had experienced at least one ALC system, with Tesla Autopilot having the largest share (28%). Statistics of the ALC experiment and demographic information are shown in Figure 18.

### Results
Figure 17 shows the study results. As the attack success time approaches, more participants choose to take over driving in the attacked scenarios because the dirty patterns become increasingly larger and clearer. Among the three stealthiness levels, the driver decisions are consistent with our design: the lowest stealthiness level (λ = 10−4) has the highest take-over rate, while the highest level (λ = 10−2) has the lowest. Even at the lowest stealthiness level (λ = 10−4), fewer than 25% of participants decided to take over before the attack started to take effect. At this stealthiness level, the white dirty patterns are quite dense and prominent. These results suggest that most human drivers today do not treat dirty road patches as conditions where ALC systems cannot handle.

As introduced in §3.1, 2.5 seconds is commonly used as the average driver reaction time to road hazards. At 2.5 seconds or more before the attack succeeds, the human driver still has a chance to take over driving to prevent damage, provided they recognize the hazard. However, our results show that fewer than 20% of participants decide to take over at 2.5 and 3 seconds before the attack succeeds, even at the lowest stealthiness level. When the stealthiness levels are λ = 10−2 and λ = 10−3, the take-over rates at these two time points are similar to those for a benign road patch with only the base color. This suggests that, at the time when there is still a chance to prevent damage, our attack patches at λ = 10−2 and 10−3 appear as innocent as normal clean road patches to human drivers. In these cases, the take-over rates are less than 15%, which are from participants who would take over even for normal clean road patches. Note that the take-over rates in practice are likely to be lower since (1) this study is performed for a local road scenario, while the road patches in highway scenarios are much farther and less noticeable, and (2) the road patches in this study are digitally synthesized into the image frames, which may appear less natural and thus more easily alert participants.

### Stealthiness from Pedestrian View
In local road scenarios, the stealthiness from the pedestrian’s view is also an important consideration, as pedestrians may report anomalies if the attack patch looks too suspicious. Our user study includes the driver’s view at 1 second before the attack succeeds, which is 7 meters to the driver’s eyes, similar to the distance from a pedestrian on local roads. However, only 75% of participants did not think our attack patch at this distance looked suspicious enough to affect driving. This may be because the general public is unaware that dirty road patches can be a road hazard. We hope this paper will raise awareness of this issue.

### Details of OpenPilot ALC System
In this section, we describe the implementation details of the OpenPilot ALC system, which follows the typical modular ALC system design introduced in §1:

#### Lane Detection (LD)
The LD model used in OpenPilot employs recurrent DNN structures (e.g., RNN and GRU), detailed in our extended version [38] for three specific versions. In each frame, the recurrent model receives a front-camera input of 512 pixels wide by 256 pixels high and 512-dimensional recurrent features from the previous frame. The recurrent features are the output of a middle layer. The final output for ALC consists of information for three lines (left and right lines and driving path). Each line has coordinates of 192 points (1 m interval from the vehicle to driving direction), uncertainty scores for each coordinate, and a confidence score for its lane. Thus, there are (192 × 2 + 1) × 3 = 1,155 output values in total. The desired driving path is calculated by the weighted average of the driving path and the center line of the left and right lines, weighted by the uncertainty and confidence scores. See OpenPilot code [8] for more details.

This recurrent structure is stateful, allowing it to leverage previous detection results to enhance current frame detection, as lane line shapes typically do not change significantly across consecutive frames. OpenPilot LD models output the detected lane line points for the left line, right line, and predicted driving path. Each line is fitted to a 3-degree polynomial, and the desired driving path is then calculated as the weighted average of the three lines with their confidence levels. OpenPilot LD operates at 20 Hz (every 50 ms). In §7, we inject the attack traces at the end of this step by modifying the ALC source code to replace the real-time LD model outputs with a sequence of attacked ones obtained from the software-in-the-loop simulation at the same driving speed (simulation environment described in §6).

#### Lateral Control
OpenPilot uses Model Predictive Control (MPC) [24] to decide the desired steering angle, which is then sent to the vehicle actuation step. The input to the MPC is the desired driving path, the current speed, and the current steering angle. This step works at the same frequency as LD, i.e., the desired steering angle is decided every 50 ms. The MPC is stateful, reusing the solution of the previous frame as the initial solution for the current frame.

#### Vehicle Actuation
Based on the desired steering angle from MPC, OpenPilot vehicle actuation decides the steering angle change to actuate in the control step and sends actuation messages through the CAN (Controller Area Network) bus. This makes the absolute value of the actuated steering angle stateful, as the new actuated steering angle is built upon the previous one by applying the angle change actions. OpenPilot actuation works at 100 Hz control frequency. The actuated steering angle change is up to 0.25° per control step (every 10 ms). As described in §2.1, such limits are typically imposed in production ALC systems due to physical constraints of the mechanical control units and for driving stability and safety [22]. OpenPilot is integrated into a vehicle by overriding the stock cruise control system. It is engaged to control the steering and throttle when the driver turns on the cruise control mode and can work with stock safety features such as AEB and FCW [8].

### Figures
- **Figure 16**: Vehicle and lane widths used in this paper.
- **Figure 17**: Results of the attack stealthiness user study. Driving take-over rate is the percentage of participants who choose to take over driving at a particular time point before the attack succeeds.
- **Figure 18**: Statistics of the ALC system experience and demographic information in the attack stealthiness user study.