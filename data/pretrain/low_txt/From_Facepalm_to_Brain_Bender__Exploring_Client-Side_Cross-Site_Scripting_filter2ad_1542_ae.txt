### Introduction

We have identified evidence of security flaws that cannot be solely attributed to the developers of vulnerable web applications. These issues often arise from a combination of incompatible first- and third-party code or are entirely caused by third-party libraries. This paradigm is facilitated by the web's programming model, which allows third-party code to be included in a web page, granting it full access to the page's Document Object Model (DOM).

Additionally, we have observed patterns of errors caused by developers due to their misunderstanding of browser-provided APIs or the explicit decoding of user-provided data for convenience. Apart from the examples presented, we have also found instances where misguided attempts at securing applications have made it easy for attackers to bypass these measures. This suggests that even developers who are aware of the risks associated with using attacker-controllable data sometimes lack the knowledge to properly secure their applications.

### Related Work

#### Client-Side Cross-Site Scripting (XSS)

In 2005, Amit Klein introduced the concept of DOM-based XSS [11]. One of the first tools specifically designed to detect DOM-based XSS was DOMinator, which used taint-tracking to identify vulnerable flows [7]. We extended this concept by developing an automated method to detect and verify client-side XSS vulnerabilities, finding that approximately 10% of the top 10,000 web pages contain at least one such vulnerability [12]. Building on this taint-tracking engine, we created a taint-aware XSS filter to mitigate client-side XSS [27].

Previous work by Saxena et al. focused on so-called Client-Side Vulnerabilities, primarily targeting the exploitation of client-side XSS flaws. Using "taint-enhanced blackbox fuzzing," they discovered eleven previously unknown vulnerabilities on real-world web pages [22]. In contrast, Criscione presented a brute-force blackbox testing approach [5]. To find bugs in complex JavaScript code, Saxena et al. developed a symbolic execution framework for JavaScript, which helped them identify two previously unknown vulnerabilities [21].

#### JavaScript Analysis

Further attention has been given to general sources of JavaScript errors. Two research groups conducted empirical studies of JavaScript source code included in popular sites. Richards et al. investigated the general runtime behavior of JavaScript and concluded that the language is challenging for static analysis, confirming our decision to use a dynamic approach [20]. Ocariza et al. categorized the different kinds of errors they encountered with specific test cases for the top 100 websites [17]. Despite these sites being in a mature state, the same well-defined categories of errors were frequently discovered.

In 2011, Guarnieri et al. [8] presented ACTARUS, capable of conducting taint-aware static analysis of JavaScript on real-world websites, identifying over 500 vulnerabilities on eleven sites. Later, Meawad et al. developed Evalorizer, a tool aimed at assisting programmers in removing unnecessary eval constructs [14]. As our work has shown, websites often incorporate cross-domain JavaScript code. Nikiforakis et al. investigated the trust relationships between web pages of the Alexa Top 10,000 sites, demonstrating that sites often expose themselves to attacks by including third-party content [16].

#### Vulnerability Analysis

Other research has focused on more general vulnerability analysis. In 2008, Shin et al. analyzed how well code complexity metrics can predict vulnerabilities in the Mozilla JavaScript Engine [26]. They concluded that while complexity metrics can be useful in finding flaws with a low false positive rate, they carry a high false negative rate. Besides complexity, Shin et al. examined code churn and developer activity metrics to determine indicators of vulnerabilities and used them to prioritize inspection and testing efforts [25]. Similar results were obtained by Chowdhury et al., who used complexity, coupling, and cohesion metrics to discover vulnerabilities statically [3].

Scholte et al. presented an approach to find improper input validation using automatic data type inference for validation functions [23]. Their method found that 65% of server-side XSS flaws in their set were simple enough to be stopped without causing any hassle for developers, which aligns with the number of simple flows we discovered in our study. Wassermann and Su used static taint analysis to identify server-side XSS based on W3C recommendations [30]. Yamaguchi et al. conducted additional work to identify new vulnerabilities using machine learning and a set of known vulnerabilities [31], as well as based on Abstract Syntax Trees [32].

### Summary of Related Work

While previous research has focused on the detection of client-side XSS, JavaScript security analysis, and general vulnerability analysis, no prior work has investigated the underlying causes of client-side XSS flaws. Our work aims to fill this gap in the existing literature.

### Limitations and Future Work

The results of our analysis are influenced by the methodology used to find the vulnerabilities. Most importantly, our method only identifies vulnerabilities in code executed during a normal page visit. Therefore, flows dependent on specific conditions (such as URL parameters) may not be detected. Since there is no ground truth for all real-world client-side XSS vulnerabilities, we cannot ascertain whether such flaws are more complex than those in our study. Extending the detection methodology with static analysis to discover more vulnerabilities is a promising extension that could be incorporated into our current work.

An interesting extension of our work is the application of code coverage metrics by instrumenting cached JavaScript code [24]. However, this approach has its own limitations, as rewriting cannot be conducted on code dynamically generated at runtime using eval.

Additionally, with the gathered data, we can investigate the usage of filtering functions on the web, such as regular expressions. Analyzing these deployed filters might shed light on improper use, especially given anecdotal evidence of improperly used regular expression filtering.

### Conclusion

In this paper, we investigated the root causes of client-side XSS, focusing on the underlying issues related to this class of vulnerabilities. We thoroughly analyzed a set of 1,273 real-world vulnerabilities and classified them according to their complexity. Our work shows that a large number of flaws are relatively simple, likely rooted in insufficient security awareness among developers. Based on our classification approach, about two-thirds of all examined vulnerabilities fall into this category. In contrast, about 15% of the discovered flaws have a high combined complexity rating, indicating that developers may be overwhelmed by the complexity of the vulnerable code. In 59 cases, we even found interrupted code flows, significantly impeding flaw discovery. Our study also found that for randomly sampled flows, complexity metrics generally yield higher values, suggesting that non-exploitable code is often more complex than vulnerable code.

Our findings highlight that the aforementioned reasons are not the only factors causing client-side XSS. Third-party code is often responsible for flaws, either alone or in combination with first-party code. In 273 of our vulnerabilities, third-party code was solely responsible, while an additional 165 flaws were caused by a combination of third- and first-party code, partly due to the careless use of outdated and vulnerable libraries. Our work also uncovered patterns indicating that developers lack knowledge of the inner workings of browser-provided APIs, sometimes introducing vulnerabilities.

In summary, there is no single reason for the existence of client-side XSS. The issues are caused by a variety of factors, ranging from developers' unawareness of security implications when using attacker-controllable data to highly complex code constructs and issues introduced by third parties.

### Acknowledgements

We would like to thank the anonymous reviewers for their valuable feedback. This work was partially supported by the EU Project STREWS (FP7-318097).

### References

[1] D. Bates, A. Barth, and C. Jackson. Regular expressions considered harmful in client-side XSS filters. In WWW, 2010.
[2] BuiltWith. jQuery Usage Statistics. http://goo.gl/czK9XU (accessed 16/05/15), 2015.
[3] I. Chowdhury and M. Zulkernine. Can Complexity, Coupling, and Cohesion Metrics Be Used As Early Indicators of Vulnerabilities? In SAC, 2010.
[4] A. Cortesi and M. Hils. mitmproxy. https://goo.gl/VA9xw4 (accessed 16/05/15), 2014.
[5] C. Criscione. Drinking the Ocean - Finding XSS at Google Scale. Talk at the Google Test Automation Conference, (GTACâ€™13), http://goo.gl/8qqHA, 2013.
[6] M. E. Daggett. Enforcing Style. In Expert JavaScript. 2013.
[7] S. Di Paola. DominatorPro: Securing Next Generation of Web Applications. https://goo.gl/L6tJth (accessed 16/05/15), 2012.
[8] S. Guarnieri, M. Pistoia, O. Tripp, J. Dolby, S. Teilhet, and R. Berg. Saving the World Wide Web from Vulnerable JavaScript. In International Symposium on Software Testing and Analysis, 2011.
[9] I. Hickson and D. Hyatt. HTML 5 - A vocabulary and associated APIs for HTML and XHTML. W3c working draft, W3C, 2008.
[10] jQuery Bug Tracker. SELECTOR INTERPRETED AS HTML. http://goo.gl/JNggpp (accessed 16/05/15), 2012.
[11] A. Klein. DOM based cross site scripting or XSS of the third kind. Web Application Security Consortium, 2005.
[12] S. Lekies, B. Stock, and M. Johns. 25 Million Flows Later: Large-scale Detection of DOM-based XSS. In CCS, 2013.
[13] M. McDaniel and M. H. Heydari. Content based file type detection algorithms. In HICSS, 2003.
[14] F. Meawad, G. Richards, F. Morandat, and J. Vitek. Eval begone!: semi-automated removal of eval from javascript programs. ACM SIGPLAN Notices, 47, 2012.
[15] Mozilla Developer Network. Element.innerHTML - Web API Interfaces | MDN. https://goo.gl/udFqtb (accessed 16/05/15), 2015.
[16] N. Nikiforakis, L. Invernizzi, A. Kapravelos, S. Van Acker, W. Joosen, C. Kruegel, F. Piessens, and G. Vigna. You Are What You Include: Large-scale Evaluation of Remote JavaScript Inclusions. In CCS, 2012.
[17] F. Ocariza, K. Pattabiraman, and B. Zorn. JavaScript errors in the wild: An empirical study. In Software Reliability Engineering, 2011.
[18] E. Oftedal. Retire.js - identify JavaScript libraries with known vulnerabilities in your application. http://goo.gl/r4BQoG (accessed 16/05/15), 2013.
[19] G. Richards, C. Hammer, B. Burg, and J. Vitek. The eval that men do. In ECOOP. 2011.
[20] G. Richards, S. Lebresne, B. Burg, and J. Vitek. An Analysis of the Dynamic Behavior of JavaScript Programs. In PLDI, 2010.
[21] P. Saxena, D. Akhawe, S. Hanna, F. Mao, S. McCamant, and D. Song. A Symbolic Execution Framework for JavaScript. In IEEE S&P, 2010.
[22] P. Saxena, S. Hanna, P. Poosankam, and D. Song. Flax: Systematic discovery of client-side validation vulnerabilities in rich web applications. In NDSS, 2010.
[23] T. Scholte, W. Robertson, D. Balzarotti, and E. Kirda. Preventing input validation vulnerabilities in web applications through automated type analysis. In Computer Software and Applications Conference. IEEE, 2012.
[24] A. Seville. Blanket.js - seamless javascript code coverage. http://goo.gl/hzJFTn (accessed 16/05/15), 2014.
[25] Y. Shin, A. Meneely, L. Williams, and J. Osborne. Evaluating Complexity, Code Churn, and Developer Activity Metrics as Indicators of Software Vulnerabilities. Transactions on Software Engineering, 2011.
[26] Y. Shin and L. Williams. An Empirical Model to Predict Security Vulnerabilities Using Code Complexity Metrics. In International Symposium on Empirical Software Engineering and Measurement, 2008.
[27] B. Stock, S. Lekies, T. Mueller, P. Spiegel, and M. Johns. Precise client-side protection against DOM-based cross-site scripting. In USENIX Security, 2014.
[28] The jQuery Foundation. Working with JSONP. https://goo.gl/Wdqgo3 (accessed 16/05/15), 2015.
[29] W3Techs. Usage Statistics and Market Share of JQuery for Websites, February 2015. http://goo.gl/jyQEZR (accessed 16/05/15), 2015.
[30] G. Wassermann and Z. Su. Static detection of cross-site scripting vulnerabilities. In International Conference on Software Engineering, 2008.
[31] F. Yamaguchi, F. Lindner, and K. Rieck. Vulnerability Extrapolation: Assisted Discovery of Vulnerabilities Using Machine Learning. In USENIX WOOT, 2011.
[32] F. Yamaguchi, M. Lottmann, and K. Rieck. Generalized Vulnerability Extrapolation Using Abstract Syntax Trees. In ACSAC, 2012.