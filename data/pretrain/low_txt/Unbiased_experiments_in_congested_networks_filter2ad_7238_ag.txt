### Journal References

1. **Mittal, R., Lam, V. T., Dukkipati, N., Blem, E., Wassel, H., Ghobadi, M., Vahdat, A., Wang, Y., Wetherall, D., & Zats, D. (2015).** TIMELY: RTT-Based Congestion Control for the Datacenter. *Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication*. London, United Kingdom, 537–550. https://doi.org/10.1145/2785956.2787510

2. **Newey, W. K., & West, K. D. (1987).** A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix. *Econometrica*, 55(3), 703–708. https://doi.org/10.2307/1913610

3. **Garg, N. (2019).** COPA Congestion Control for Video Performance. (Nov. 2019). https://engineering.fb.com/2019/11/17/video-engineering/copa/

4. **Oman, S. D., & Seiden, E. (1988).** Switch-Back Designs. *Biometrika*, 75(1), 81–89. https://doi.org/10.1093/biomet/75.1.81

5. **Robins, J. (1986).** A New Approach to Causal Inference in Mortality Studies with a Sustained Exposure Period—Application to Control of the Healthy Worker Survivor Effect. *Mathematical Modelling*, 7(9-12), 1393–1512. https://doi.org/10.1016/0270-0255(86)90088-6

6. **Rubin, D. B. (2005).** Causal inference using potential outcomes: Design, modeling, decisions. *Journal of the American Statistical Association*, 100(469), 322–331.

7. **Saeed, A., Dukkipati, N., Valancius, V., Lam, V. T., Contavalli, C., & Vahdat, A. (2017).** Carousel: Scalable Traffic Shaping at End Hosts. *The Conference of the ACM Special Interest Group*. 404–417. https://doi.org/10.1145/3098822.3098852

8. **Saveski, M., Pouget-Abadie, J., Saint-Jacques, G., Duan, W., Ghosh, S., Xu, Y., & Airoldi, E. M. (2017).** Detecting Network Effects: Randomizing Over Randomized Experiments. *Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*. Halifax, NS, Canada, 1027–1035. https://doi.org/10.1145/3097983.3098192

9. **Sayre, R. (2008).** Change Max-Persistent-Connections-per-Server to 6. (March 2008). https://bugzilla.mozilla.org/show_bug.cgi?id=423377

10. **Schloss, N., & Maurer, B. (2017).** This Browser Tweak Saved 60% of Requests to Facebook. (Jan. 2017). https://engineering.fb.com/2017/01/26/web/this-browser-tweak-saved-60-of-requests-to-facebook/

11. **Scholz, D., Jaeger, B., Schwaighofer, L., Raumer, D., Geyer, F., & Carle, G. (2018).** Towards a Deeper Understanding of TCP BBR Congestion Control. *2018 IFIP Networking Conference (IFIP Networking) and Workshops*. Zurich, Switzerland, 1–9. https://doi.org/10.23919/IFIPNetworking.2018.8696830

12. **Johari, R., Li, H., Liskovich, I., & Weintraub, G. (2020).** Experimental design in two-sided platforms: An analysis of bias. *arXiv preprint arXiv:2002.05670*.

13. **Joras, M., & Chi, Y. (2020).** How Facebook Is Bringing QUIC to Billions. (Oct. 2020). https://engineering.fb.com/2020/10/21/networking-traffic/how-facebook-is-bringing-quic-to-billions/

14. **Kakhki, A. M., Jero, S., Choffnes, D., Nita-Rotaru, C., & Mislove, A. (2017).** Taking a Long Look at QUIC: An Approach for Rigorous Evaluation of Rapidly Evolving Transport Protocols. *Proceedings of the 2017 Internet Measurement Conference*. London, United Kingdom, 290–303. https://doi.org/10.1145/3131365.3131368

15. **Karrer, B., Shi, L., Bhole, M., Goldman, M., Palmer, T., Gelman, C., Konutgan, M., & Sun, F. (2020).** Network Experimentation at Scale. *arXiv:2012.08591 [cs, stat]*. https://arxiv.org/abs/2012.08591

16. **Kastelman, D., & Ramesh, R. (2018).** Unbiased Experiments in Congested Networks. *IMC '21, November 2–4, 2021, Virtual Event, USA*.

17. **Shah, A. (2019).** BBR Evaluation at a Large CDN. (Nov. 2019). https://blog.apnic.net/2019/11/01/bbr-evaluation-at-a-large-cdn/

18. **Souders, S. (2008).** Roundup on Parallel Connections. (March 2008). https://www.stevesouders.com/blog/2008/03/20/roundup-on-parallel-connections/

19. **Spang, B., Walsh, B., Huang, T.-Y., Rusnock, T., Lawrence, J., & McKeown, N. (2019).** Buffer Sizing and Video QoE Measurements at Netflix. *Proceedings of the 2019 Workshop on Buffer Sizing*. Palo Alto, CA, USA. https://doi.org/10.1145/3375235.3375241

20. **Splawa-Neyman, J., Dabrowska, D. M., & Speed, T. P. (1990).** On the application of probability theory to agricultural experiments. Essay on principles. Section 9. *Statistical Science*, 465–472.

21. **Tang, D., Agarwal, A., O'Brien, D., & Meyer, M. (2010).** Overlapping Experiment Infrastructure: More, Better, Faster Experimentation. *KDD'10*.

22. **Tchetgen Tchetgen, E. J., & VanderWeele, T. J. (2012).** On causal inference in the presence of interference. *Statistical Methods in Medical Research*, 21, 55–75.

23. **Tingley, M. (2018).** Streaming Video Experimentation at Netflix: Visualizing Practical and Statistical Significance. (Sept. 2018). https://netflixtechblog.com/streaming-video-experimentation-at-netflix-visualizing-practical-and-statistical-significance-7117420f4e9a

24. **Torvalds, L.** Tcp_input.c - Linux (v5.11-rc5). ([n. d.]). https://github.com/torvalds/linux/blob/2ab38c17aac10bf55ab3efde4c4db3893d8691d2/net/ipv4/tcp_input.c#L873

25. **Towsley, D. F. (2015).** TCP, Congestion Control. (Nov. 2015). http://gaia.cs.umass.edu/cs653/slides/tcp.pdf

26. **Turkovic, B., Kuipers, F. A., & Uhlig, S. (2019).** Fifty Shades of Congestion Control: A Performance and Interactions Evaluation. *arXiv:1903.03852 [cs]*. https://arxiv.org/abs/1903.03852

27. **Turkovic, B., Kuipers, F. A., & Uhlig, S. (2019).** Interactions between Congestion Control Algorithms. *2019 Network Traffic Measurement and Analysis Conference (TMA)*, 161–168. https://doi.org/10.23919/TMA.2019.8784674

28. **Ugander, J., Karrer, B., Backstrom, L., & Kleinberg, J. (2013).** Graph Cluster Randomization: Network Exposure to Multiple Universes. *Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '13)*. New York, NY, USA, 329–337. https://doi.org/10.1145/2487575.2487695

29. **Ware, R., Mukerjee, M. K., Seshan, S., & Sherry, J. (2019).** Beyond Jain’s Fairness Index: Setting the Bar For The Deployment of Congestion Control Algorithms. *Proceedings of the 18th ACM Workshop on Hot Topics in Networks*. Princeton, NJ, USA, 17–24. https://doi.org/10.1145/3365609.3365855

30. **Ware, R., Mukerjee, M. K., Seshan, S., & Sherry, J. (2019).** Modeling BBR’s Interactions with Loss-Based Congestion Control. *Proceedings of the Internet Measurement Conference*. Amsterdam, Netherlands, 137–143. https://doi.org/10.1145/3355369.3355604

31. **Wei, D. X., Cao, P., & Low, S. H. (2006).** TCP Pacing Revisited. (2006). http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.2658&rep=rep1&type=pdf

32. **Yan, F. Y., Ayers, H., Zhu, C., Fouladi, S., Hong, J., Zhang, K., Levis, P., & Winstein, K. (2020).** Learning in Situ: A Randomized Experiment in Video Streaming. *NSDI*. Santa Clara, CA, USA, 16. https://www.usenix.org/system/files/nsdi20-paper-yan.pdf

### Ethics
While our experiments involve live traffic running on a large video streaming service, our work is not human subjects research, and we have no way to identify the individual users of the platform. We only have access to performance-related data. Our experiments improved behavior during congestion but at the cost of reducing video quality. Netflix's customers have the option to opt out of experiments if they choose to.

### Appendix: Analysis of Experimental Data
In this appendix, we describe our general approach to analyzing data from large-scale experiments and how we apply this approach in the context of the experiments reported in Sections 4 and 5. For the duration of the appendix, we consider data for a fixed representative metric collected on a per-session basis (e.g., average throughput).

#### Units and Treatment Conditions
- **Units**: Video sessions.
- **Treatment Condition**: \( A_i \), where \( A_i = 1 \) denotes treatment and \( A_i = 0 \) denotes control.
- **Outcome**: \( Y_i \), the observed outcome on session \( i \).
- **Hour of Session**: \( h_i \in \{1, \ldots, 24\} \).

#### Hourly Aggregation
For each hour \( t = 1, \ldots, 24 \) and each treatment condition \( A = 0, 1 \), we compute:
\[ Z_t(A) = \frac{\sum_{i} Y_i \cdot \mathbb{I}_{h_i = t, A_i = A}}{\sum_{i} \mathbb{I}_{h_i = t, A_i = A}} \]
This is the average outcome for sessions in treatment condition \( A \) during hour \( t \).

#### Regression Model
We use a regression approach to estimate the treatment effect:
\[ Z_t(A) = c + \beta_0 A + \beta_t + \epsilon_i \]
for all \( t, A \).

- \( t = 1, \ldots, 24 \)
- \( A = 0, 1 \)
- \( \beta_0 \) is the coefficient on the treatment indicator.
- Each \( \beta_t \) is a fixed effect to control for hour-of-day heterogeneity.
- \( c \) is an intercept term.
- \( \epsilon_i \) is the error term.

We fit this model using least squares linear regression and estimate confidence intervals using Newey-West robust standard errors with a lag of two hours. This accounts for autocorrelation between successive hours and heteroskedasticity in the error terms \( \epsilon_i \).

#### Estimation
- \( \hat{\beta}_0 \) is the estimated coefficient on the treatment indicator and an estimator for the average treatment effect.
- We use hats to denote the corresponding estimates.

#### Assumptions and Considerations
- **Conservative Assumption**: We assume that sessions within a given hour and treatment condition are perfectly correlated, which is a very conservative assumption.
- **Current Practice**: This approach is current practice in the analysis of switch-back experiments in other industries.
- **Account-Level Standard Errors**: Using standard account-level standard errors would yield tighter confidence intervals, as shown in Figure 13.
- **Active Area of Investigation**: Correcting standard error estimates to properly account for dependencies between sessions remains an active area of investigation.

#### Application to Paired Link Experiment
In Section 4, sessions on link 1 were randomized 95% to treatment and 5% to control, and sessions on link 2 were randomized 5% to treatment and 95% to control. We carry out four separate analyses on this data:

1. **Treatment Sessions on Link 1**: We consider the 95% of all sessions in the treatment group on link 1 as our treatment sessions (\( A_i = 1 \)).
2. **Control Sessions on Link 2**: We consider the 95% of all sessions in the control group on link 2 as our control sessions (\( A_i = 0 \)).
3. **Spillover Estimation**: We use only the 5% control sessions on link 1 and the 95% control sessions on link 2.
4. **Naïve Estimates**: We use the difference in means estimator to compute two "naïve" estimates using only the sessions on link 1 or link 2.

#### Normalization
All reported values are normalized by dividing all estimates by the average across all control sessions on link 2 (where 95% of the traffic was control). This ensures that all reported values are a relative difference measured against the same global control condition.

#### Application to Switchback Experiments and Event Studies
In Section 5, we analyzed a switchback experiment and an event study emulated using the data from the paired link experiment. For the three days chosen to be treatment intervals, we define all treatment sessions on link 1 to have \( A_i = 1 \). For the two days chosen to be control intervals, we define all control sessions on link 2 to have \( A_i = 0 \). We then proceed with the analysis workflow and report \( \hat{\beta}_0 \) as our emulated estimate of the total treatment effect (TTE).