### Policy for Managing Nym Usability and Anonymity

#### Maintaining Usability
A key policy in managing the usability of a Nym \( N \) is to ensure that it remains functional either temporarily or permanently. This approach avoids reducing the usability of \( N \) or artificially delaying the appearance of the user's posts, as long as the possinymity set remains above a specified threshold. However, if the possinymity set of \( N \) falls below this threshold, all remaining users in the set become critical. In such a scenario, \( N \) becomes unusable for posting if any of these remaining members go offline. In a "dissident scenario," this event might signal the user to move to a new network location, such as obtaining a fresh IP address at a different Internet cafe.

#### Limiting Possinymity Loss Rate
An alternative or complementary goal is to reduce the rate at which \( N \)'s possinymity decreases. In realistic scenarios, clients often experience temporary delays or disconnections but return shortly thereafter. A more refined policy might temporarily halt all posting for Nym \( N \) by returning \( P_i = \emptyset \) when members of \( N \)'s current possinymity set go offline, with the hope that these missing members will soon return. If members remain offline for a sufficient number of rounds, the policy eliminates these persistently offline members from \( N \)'s permanent possinymity set by returning a smaller (but non-empty) \( P_i \). This policy can filter out brief offline periods of otherwise reliable users, but at the cost of delaying the user's posting to Nym \( N \) if some members go offline permanently. 

A loss rate limiting policy can be combined with a threshold-maintaining policy. A further refinement might be to increase the loss limiting policy's "tolerance"—the number of rounds a user may remain offline before being eliminated—as the Nym's possinymity set size approaches the user's specified lower bound. This policy trades temporary unavailability for greater overall Nym longevity.

#### Prioritizing Reliable Users
To maximize \( N \)'s possinymity and minimize the anonymity loss rate while limiting delays caused by unreliable users, we can consider some members of \( N \)'s current possinymity set as "more valuable" than others. For example, users who have remained online and participated reliably for a long period with only a few brief offline periods. A policy might apply an offline-time threshold to limit the loss rate but apply different thresholds to different members, giving longer, more generous thresholds to more "valued" users.

The Policy Oracle can build up reliability information about users from their first appearance, not just when a particular pseudonym of interest is created. Thus, a policy applied to a specific Nym \( N \) can benefit from user history data that the Policy Oracle has accumulated over time.

### Guaranteeing Minimum Indinymity

The possinymity metric considers intersection attacks across rounds with non-null messages. However, in realistic chat or blogging scenarios, a user's posts are interspersed with idle periods. A smarter adversary can use predictive techniques to glean probabilistic information from these idle periods. Therefore, we aim to guarantee users a minimum level of indinymity even under probabilistic attacks.

#### Forming and Enforcing Buddy-Sets
To ensure a Nym \( N \) has a minimum indinymity of value \( K \), the Policy Oracle must ensure that all of \( N \)'s buddy-sets—subsets of users with identical online behavior across rounds after user filtering—are of size at least \( K \). A simple approach is to divide \( N \)'s initial user roster \( M \) into \( \lceil |M|/K \rceil \) arbitrary buddy-sets, each containing at least \( K \) users. At step 5 of each round \( i \), for each buddy-set \( B \) containing any offline user \( u \notin O_i \), the Policy Oracle removes all members of \( u \)'s buddy set \( B \) from its filtered user set \( P_i \). This effectively forces members of each buddy set to come online or go offline in unison, keeping them permanently indistinguishable under probabilistic intersection attacks. However, this policy may yield poor availability, as it prevents \( N \)'s owner from posting whenever any member of the owner's buddy-set is offline.

#### Lazy Buddy-Set Formation
A more refined approach is to delay buddy-set decisions until users actually go offline. Initially, a Nym \( N \) starts with one large buddy-set containing its entire user roster \( M \). In the first round \( i \) where members of \( M \) go offline, the Policy Oracle might delay all posting for Nym \( N \) by returning \( P_i = \emptyset \), hoping the missing members will return online soon. Once the Policy Oracle "gives up" on one or more members, it splits \( N \)'s current buddy-sets into two, isolating all persistently offline members into one of the resulting buddy-sets. By delaying the decision, the Policy Oracle ensures that the buddy-set containing only online members has a chance to make progress until more users go offline for a sufficient duration to force another split.

After a split, each resulting buddy-set must be at least of size \( K \) to maintain the indinymity lower bound. If fewer than \( K \) total users are actually offline (\( |M - O_i| < K \)), the Policy Oracle must "sacrifice" a few online users, placing them in the offline users' buddy-set. This ensures that even if the attacker infers from the absence of posts that \( N \)'s owner is in the now-offline buddy-set, they cannot determine whether the owner is the user who caused the split or one of those sacrificed.

#### Choosing Whom to Sacrifice
When the Policy Oracle must "sacrifice" online users to pad an offline buddy set to size \( K \), an important issue is how to choose which online users to sacrifice. Two classes of sacrificial policies are random and least reliable users. Random choice clusters users regardless of reliability, which is simple but risks sacrificing reliable users. Alternatively, the Policy Oracle might first sacrifice users with the weakest historical record of reliability, such as recently arrived users or those with long offline periods. This heuristic aims to retain the most reliable users in the buddy set that remains online immediately after the split, though this buddy set may split further if more nodes go offline in the future.

We expect reliability-sensitive policies to maximize a Nym's effective lifetime, provided the Nym's true owner is one of the more reliable users and does not get sacrificed into an unreliable or permanently offline buddy set. A short-lived or unreliable user cannot expect their Nyms to be long-lived; a long-lived Nym must have a "base" of reliable, long-lived users to maintain anonymity under intersection attack, and the Nym's owner must be a member of this long-lived anonymity set.

### Varying Policies and Nym Independence

So far, we have assumed the Policy Oracle enforces a "global policy" on all Nyms, but this limits flexibility and unrealistically requires all users to agree on one policy. Instead, Buddies allows each Nym to have a separate policy, chosen by the Nym's owner. Intersection attacks are not an issue until a Nym \( N \) has been in use for more than one round. The Nym's owner specifies the policy parameters for \( N \) in its first post. The set of users online in this first message round forms \( N \)'s initial user roster \( M \), which is also the maximum anonymity set \( N \) can ever achieve under intersection attack. In subsequent rounds, the announced policy for \( N \) determines the Policy Oracle's behavior in filtering \( N \)'s user sets to mitigate intersection attacks.

Each Nym's policy is independent of other Nyms, including other Nyms owned by the same user. This independence and the correctness of Section 2's analysis depend on the assumption that the Anonymizer assigns Nyms to users uniformly at random and independently of all other Nyms. Otherwise, the choices the Policy Oracle makes on behalf of one Nym might leak information about other Nyms.

### Implementing Buddies in Practical Systems

Since Buddies' conceptual model is unrealistically simple, we now address key challenges of implementing Buddies in practical anonymity systems. We focus on our Buddies prototype built as an extension to Dissent [11, 13, 52], but also discuss its potential applicability to other existing anonymous communication systems.

#### Decentralizing the Anonymizer
In a practical design, we replace Buddies' Anonymizer with standard decentralized schemes for anonymous message transmission, such as mix-nets [6,8,15], DC-nets [9, 50], or verifiable shuffles [7, 25, 39]. Buddies assumes the Anonymizer is already resistant to basic, short-term network-level traffic analysis and timing attacks. We also assume the Anonymizer distributes trust across a group of servers, with at least one trustworthy server in this group, although the user need not know which server is trustworthy. This anytrust model is embodied in the relays used in mix-nets or Tor circuits [18], the "authorities" in verifiable shuffles [39], or Dissent's multi-provider cloud model [52].

While ad hoc mix-nets and onion routing schemes are vulnerable to many traffic analysis and active attacks, variants such as MIX cascades [5,7,41] and verifiable shuffles [25, 39] offer formally provable traffic analysis resistance. These systems typically work in synchronous rounds, where users submit onion-encrypted ciphertexts to a common set of mixes, who serially decrypt and permute the ciphertexts to reveal the anonymous plaintexts. To resist traffic analysis, users with no useful message to send in a round must submit encrypted "empty" messages as cover traffic.

DC-nets [9, 50] operate in synchronous rounds, deriving anonymity from parallel information coding techniques rather than serial mixing, achieving traffic analysis protection in fewer communication hops. Dissent [11, 13, 52] adapts DC-nets to a practical and scalable client-server model, achieving per-round latencies orders of magnitude lower than a verifiable shuffle or cascade mix, making it a natural foundation for our Buddies prototype.

#### Creating and Extending Nyms
Buddies can represent Nyms as public/private key pairs, so anyone can learn the public keys of all Nyms, but only the Nym's owner holds the corresponding private key. Dissent runs Neff's verifiable key-shuffle [39] once per communication epoch to generate a list of public keys forming a DC-nets transmission schedule for that epoch. Each client submits one public key to the shuffle, which the servers re-encrypt and randomly permute, producing a well-known list of slot keys. The client holding a slot's matching key can identify its own slot, but neither the servers nor other clients learn who owns any honest client's slot. Adapting this mechanism to create fresh Nyms in Buddies introduces two technical challenges: assigning Nyms to users independently at random and enabling Nyms to have unlimited lifetimes.

#### Creating Nyms via Lotteries
A simple way to create independent Nyms meeting the requirements in Section 3.3 is by "lottery." Each user submits a public key to the shuffle, and the servers re-encrypt and randomly permute these keys. The client holding a slot's matching key can identify its own slot, ensuring that Nyms are assigned independently at random. This mechanism also allows Nyms to have unlimited lifetimes, as the shuffle can be run periodically to refresh the list of public keys.