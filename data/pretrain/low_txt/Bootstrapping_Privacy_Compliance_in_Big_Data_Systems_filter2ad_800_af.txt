### Potential Weaknesses in Our System
Our system provides limited guarantees against adversarial developer behavior, such as incorrect annotations and intentional violations of naming conventions, which can mislead our bootstrap analysis. However, we anticipate that independent, redundant annotations combined with data flow analysis will significantly improve the accuracy and confidence of these labels over time.

### VIII. Related Work
Our focus is on privacy policies that impose restrictions on how various types of personal information are shared among programs. There are two primary areas of research closely related to our work: information flow analysis of programs and privacy policy enforcement over executions. Additionally, we discuss related work on usable policy languages.

#### a) Information Flow Analysis of Programs
Over the past three decades, there has been extensive research on restricting information flows in programs and developing language-based methods to support these restrictions. Examples include Jif, which extends Java with information flow types, and Flow Caml, which enhances ML (see [17] for a comprehensive survey). These languages enforce information flow properties like non-interference through static type checking. For instance, Jif principals have been used to model role-based [26] and purpose-based [28] restrictions on information flow.

Recognizing that non-interference is too stringent, the theory of relaxed non-interference through declassification [29], [30], [31] allows for more flexible policies. For example, it permits the disclosure of average age but not individual ages. Techniques for automated inference of declassification policies with minimal programmer annotations [32], [33] have also been developed.

While there are parallels between this work and ours, there are significant differences:
1. **Separation of Policy from Code**: Our policy language, LEGALEASE, enables explicit specification of policies separate from the code. In contrast, language-based approaches like Jif either express policies implicitly via typed interface specifications or explicitly via conditionals on program variables. This separation is crucial because it makes policy creation accessible to privacy champions and lawyers.
2. **Bootstrap Compliance Checking**: Our goal is to enable compliance checking on existing code without assuming that the code is annotated with information flow labels. GROK addresses the challenge of bootstrapping these labels with minimal human effort. Once the labels are in place, information flow analysis for our restricted programming model is simpler than for more complex languages like Jif.

We, along with Hayati and Abadi [28], assume that programs are correctly annotated with their purposes. Defining what it means for an agent (a program or human) to use information for a purpose is a separate challenge, addressed in other work [34].

#### b) Privacy Policy Enforcement Over Executions
This line of research checks system executions (i.e., traces of actions produced by programs or humans) for compliance with privacy policies that restrict the flow and use of personal information. It includes auditing, runtime monitoring, and logic programming methods for expressive fragments of first-order logic and first-order temporal logics [12], [35], [36], [37]. These methods have been applied to practical policies in healthcare, finance, and other sectors.

The key differences from our work are:
1. **Expressiveness**: Their languages for information flow restrictions are more expressive, capable of encoding role-based and purpose-based restrictions as well as a broader class of temporal restrictions.
2. **Enforcement Mechanisms**: Since their enforcement engines only have access to executions and not the code, they can only check for direct information flows and not non-interference-like properties. This contrasts with our approach, which involves code analysis. This is also a point of difference from enforcement using reference monitors for access control and privacy policy languages, such as XACML [38] and EPAL [39].

#### c) Usable Policy Languages
Several interfaces and tools have been tested for their usability in authoring policy statements. Direct comparison with our work is challenging because raw languages are rarely evaluated for ease of use without UI-based authoring tools. Nonetheless, we highlight three efforts with similar goals:

- **Expandable Grids Interface**: This interface was used to test the ability of people to author P3P policies (P3P is the W3C standard for creating XML-based machine-readable privacy policies). An empirical study found that Expandable Grids did not improve usability beyond users' abilities to express policies using natural language [40].
- **SPARCLE**: A web-based policy authoring tool that generates XML based on users' selections of user categories, actions, data categories, purposes, and conditions. SPARCLE has shown promising usability results [41].
- **Complementary Tools**: We view tools like SPARCLE as complementary to a language like LEGALEASE. Automated translation tools often introduce inaccuracies, so validation is necessary. With LEGALEASE, the translation can be verified by the authors themselves.

### IX. Conclusion
In this paper, we present a suite of techniques to transition to automated privacy compliance checking in big data systems. We designed the LEGALEASE language for specifying privacy policies as restrictions on information flows and the GROK data inventory to map low-level data types in code to high-level policy concepts. Our user study demonstrates that LEGALEASE is usable by non-technical privacy champions. We show that LEGALEASE can capture real-world privacy policies with purpose, role, and storage restrictions, including some limited temporal properties, as seen in Bing and Google's policies.

To build the GROK data flow graph, we leveraged previous work in program and data flow analysis. We demonstrate how to bootstrap labeling the graph with LEGALEASE policy datatypes at scale. The structure of the graph allows a small number of annotations to cover a large fraction of the graph. We share our experiences and learnings from operating the system for over a year in Bing.

### Acknowledgements
We thank the policy authors and privacy champions at Microsoft who participated in our user study. We also thank Leena Sheth, Carrie Culley, Boris Asipov, and Robert Chen for their contributions to the operational system. We appreciate the feedback from Michael Tschantz and the anonymous reviewers. This work was partially supported by the AFOSR MURI on "Science of Cybersecurity" and the National Science Foundation (NSF) grant CNS1064688 on "Semantics and Enforcement of Privacy Policies: Information Use and Purpose."

### References
[1] D. J. Solove and W. Hartzog, “The FTC and the New Common Law of Privacy,” Columbia Law Review (forthcoming 2014), vol. 114.
[2] (2012, Aug.) FTC approves final settlement with Facebook. Federal Trade Commission. [Online]. Available: http://www.ftc.gov/news-events/press-releases/2012/08/ftc-approves-final-settlement-facebook
[3] (2011, Mar.) FTC charges deceptive privacy practices in Google’s rollout of its Buzz social network. Federal Trade Commission. [Online]. Available: http://www.ftc.gov/opa/2011/03/google.shtm
[4] Data Protection Commissioner, Ireland, “Facebook Ireland, report of re-audit,” 2012. [Online]. Available: http://www.dataprotection.ie/documents/press/Facebook_Ireland_Audit_Review_Report_21_Sept_2012.pdf
[5] Information Commissioner’s Office, United Kingdom, “Google Inc.: Data protection audit report,” 2011. [Online]. Available: http://ico.org.uk/~/media/documents/disclosure_log/IRQ0405239b.ashx
[6] (2012, Apr.) Investigations of Google Street View. Electronic Privacy Information Center (EPIC). [Online]. Available: http://epic.org/privacy/streetview/
[7] A. Thusoo, J. S. Sarma, N. Jain, Z. Shao, P. Chakka, N. Zhang, S. Antony, H. Liu, and R. Murthy, “Hive - a petabyte scale data warehouse using Hadoop,” in ICDE ’10: Proceedings of the 26th International Conference on Data Engineering. IEEE, Mar. 2010, pp. 996–1005.
[8] S. Melnik, A. Gubarev, J. J. Long, G. Romer, S. Shivakumar, M. Tolton, and T. Vassilakis, “Dremel: Interactive analysis of web-scale datasets,” PVLDB, vol. 3, no. 1, pp. 330–339, 2010.
[9] R. Chaiken, B. Jenkins, P.-A. Larson, B. Ramsey, D. Shakib, S. Weaver, and J. Zhou, “Scope: easy and efficient parallel processing of massive data sets,” Proc. VLDB Endow., vol. 1, no. 2, pp. 1265–1276, Aug. 2008.
[10] Bing. [Online]. Available: http://www.bing.org/
[11] H. DeYoung, D. Garg, L. Jia, D. Kaynar, and A. Datta, “Experiences in the logical specification of the HIPAA and GLBA privacy laws,” in Proceedings of the 9th Annual ACM Workshop on Privacy in the Electronic Society. New York, NY, USA: ACM, 2010, pp. 73–82.
[12] A. Barth, A. Datta, J. Mitchell, and H. Nissenbaum, “Privacy and contextual integrity: framework and applications,” in Security and Privacy, 2006 IEEE Symposium on, 2006, pp. 15 pp.–198.
[13] J. A. Goguen and J. Meseguer, “Security policies and security models,” in IEEE Symposium on Security and Privacy, 1982, pp. 11–20.
[14] Facebook. (2012, Dec.) Data use policy. [Online]. Available: https://www.facebook.com/full_data_use_policy
[15] Google. (2013, Jun.) Privacy policy. [Online]. Available: http://www.google.com/policies/privacy/
[16] (2013, Oct.) Bing privacy statement. Microsoft. [Online]. Available: http://www.microsoft.com/privacystatement/en-gb/bing/default.aspx
[17] A. Sabelfeld and A. Myers, “Language-based information-flow security,” Selected Areas in Communications, IEEE Journal on, vol. 21, no. 1, pp. 5–19, 2003.
[18] M. C. Tschantz and S. Krishnamurthi, “Towards reasonability properties for access-control policy languages.” in SACMAT. ACM, 2006, pp. 160–169.
[19] R. Wille, “Restructuring lattice theory: An approach based on hierarchies of concepts,” in Ordered Sets, ser. NATO Advanced Study Institutes Series. Springer Netherlands, 1982, vol. 83, pp. 445–470.
[20] S. Sen, S. Guha, A. Datta, S. K. Rajamani, J. Tsai, and J. M. Wing, “Bootstrapping privacy compliance in a big data system,” Microsoft Research, Tech. Rep. MSR-TR-2014-36.
[21] C. Dwork, “Differential privacy,” in ICALP. Springer, 2006, pp. 1–12.
[22] C. Farkas and S. Jajodia, “The inference problem: A survey,” SIGKDD Explor. Newsl., vol. 4, no. 2, pp. 6–11, Dec. 2002.
[23] R. Madhavan, G. Ramalingam, and K. Vaswani, “Purity analysis: An abstract interpretation formulation,” in Static Analysis, ser. Lecture Notes in Computer Science, E. Yahav, Ed. Springer Berlin Heidelberg, 2011, vol. 6887, pp. 7–24.
[24] C. Gkantsidis, D. Vytiniotis, O. Hodson, D. Narayanan, F. Dinu, and A. Rowstron, “Rhea: Automatic filtering for unstructured cloud storage,” in Proceedings of the 10th USENIX Conference on Networked Systems Design and Implementation, ser. NSDI’13. Berkeley, CA, USA: USENIX Association, 2013, pp. 343–356.
[25] D. E. Denning and P. J. Denning, “Certification of programs for secure information flow,” Commun. ACM, vol. 20, no. 7, pp. 504–513, 1977.
[26] A. C. Myers and B. Liskov, “Protecting privacy using the decentralized label model,” ACM Trans. Softw. Eng. Methodol., vol. 9, no. 4, pp. 410–442, 2000.
[27] F. Pottier and V. Simonet, “Information flow inference for ML,” in POPL, 2002, pp. 319–330.
[28] K. Hayati and M. Abadi, “Language-based enforcement of privacy policies,” in In Proceedings of Privacy Enhancing Technologies Workshop (PET). Springer-Verlag, 2004.
[29] S. Chong and A. C. Myers, “Security policies for downgrading,” in Proceedings of the 11th ACM conference on Computer and communications security, ser. CCS ’04. New York, NY, USA: ACM, 2004, pp. 198–209.
[30] P. Li and S. Zdancewic, “Downgrading policies and relaxed noninterference.” in POPL. ACM, 2005, pp. 158–170.
[31] A. Sabelfeld and D. Sands, “Declassification: Dimensions and principles,” Journal of Computer Security, vol. 17, no. 5, pp. 517–548, 2009.
[32] M. C. Tschantz and J. M. Wing, “Extracting conditional confidentiality policies,” in Proceedings of the 2008 Sixth IEEE International Conference on Software Engineering and Formal Methods. Washington, DC, USA: IEEE Computer Society, 2008, pp. 107–116.
[33] J. A. Vaughan and S. Chong, “Inference of expressive declassification policies,” in Proceedings of the 2011 IEEE Symposium on Security and Privacy. Washington, DC, USA: IEEE Computer Society, 2011, pp. 180–195.
[34] M. C. Tschantz, A. Datta, and J. M. Wing, “Purpose restrictions on information use,” in Computer Security - ESORICS 2013, ser. Lecture Notes in Computer Science. Springer Berlin Heidelberg, 2013, vol. 8134, pp. 610–627.
[35] D. A. Basin, F. Klaedtke, S. Müller, and B. Pfitzmann, “Runtime monitoring of metric first-order temporal properties,” in FSTTCS, 2008, pp. 49–60.
[36] D. Garg, L. Jia, and A. Datta, “Policy auditing over incomplete logs: theory, implementation and applications,” in Proceedings of the 18th ACM conference on Computer and communications security, ser. CCS ’11. New York, NY, USA: ACM, 2011, pp. 151–162.
[37] D. A. Basin, F. Klaedtke, S. Marinovic, and E. Zalinescu, “Monitoring compliance policies over incomplete and disagreeing logs,” in RV, 2012, pp. 151–167.
[38] T. Moses et al., “Extensible access control markup language (XACML) version 2.0,” Oasis Standard, vol. 200502, 2005.
[39] P. Ashley, S. Hada, G. Karjoth, C. Powers, and M. Schunter, “Enterprise privacy authorization language (EPAL 1.2),” Submission to W3C, 2003.
[40] R. W. Reeder, L. Bauer, L. F. Cranor, M. K. Reiter, K. Bacon, K. How, and H. Strong, “Expandable grids for visualizing and authoring computer security policies,” in CHI, 2008, pp. 1473–1482.
[41] C. Brodie, C.-M. Karat, and J. Karat, “An empirical study of natural language parsing of privacy policy rules using the SPARCLE policy workbench,” in SOUPS, 2006, pp. 8–19.