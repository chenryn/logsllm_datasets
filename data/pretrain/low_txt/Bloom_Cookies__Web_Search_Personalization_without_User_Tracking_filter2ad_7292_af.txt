### Information Sharing and Privacy Techniques in Online Services

Online services frequently collect and utilize user information, particularly location data [26] and search queries [5]. To protect user privacy, several techniques have been proposed, including "transformation-based techniques" and "progressive retrieval techniques." Transformation-based techniques use cryptographic methods to obscure user data, while progressive retrieval techniques iteratively fetch candidate results from the server. However, both approaches incur significant overhead for the client and require server cooperation, making them impractical for web search. Generalization techniques [26], [49] replace specific identifiers with less precise but semantically consistent values, but these are not effective for search as demonstrated in §IV when comparing interest-based and URL-based profiles. Literature [18] confirms this, although there are differing opinions [49].

Bloom cookies, which employ noise addition techniques (described in [5]), can be implemented at the client side. Our baseline, HYBRID, is inspired by Plausibly Deniable Search (PDS) [31].

### Bloom Cookies in Web Search

We introduce Bloom cookies in the context of web search, an area with extensive research on personalization. As shown in [18], personalized search can be categorized based on whether it uses information from a single user or a group of users. Group-level personalization, such as collaborative filtering, requires server-side involvement. In this work, we focus on client-side solutions, specifically person-level techniques that mine user profiles at the granularity of user interests or URLs. Two main approaches for person-level re-ranking of search results are URL-based profiles and interest-based profiles. We implement and compare both.

To our knowledge, only one other work [8] leverages Bloom filters for privacy. The authors propose specialized techniques for setting bits in a Bloom filter to achieve deniability of stored items. However, these techniques are computationally expensive, generate deterministic noise, and still require a dictionary, making them unsuitable for our use case.

### Limitations

#### Small Dataset
We evaluated Bloom cookies using search logs from 1,300 users. A real online service typically has many more users, potentially several orders of magnitude greater. While the personalization quality for an individual user is not affected by the number of other users, a larger dataset could improve the privacy of Bloom cookies. This is because, with more users, a noisy profile is more likely to "collide" with another user's profile, making it difficult for the server to link a user's profile over time. Our experiments in §V-D confirm this. Additionally, a small user population represents a worst-case scenario, considering that a malicious server might reduce the user population size through geolocation, language filtering, etc.

#### User Feedback
The privacy guarantee provided by Bloom cookies is statistical rather than absolute. Our results show that Bloom cookies achieve unlinkability for a good fraction of users, but some users with distinct online activities and interests remain linkable across IP sessions. Future work includes developing feedback mechanisms to allow these users to add more noise or use other measures to enhance privacy, even if it comes at the cost of personalization.

#### Longer-Term Analysis
Our evaluation assumes two consecutive 2-week periods of user activity. With longer user histories, the evaluation can scale to more extended and varied time periods.

#### Applicability to Other Applications
We focus on web search and use standard personalization techniques and metrics. Commercial search engines may use more sophisticated, proprietary techniques. However, if personalization algorithms rearrange search results based on the presence of certain items in user profiles, our privacy-preserving approach can be applied straightforwardly. This is also true for services like advertising (ranking of ads), online shopping (ranking of products), and personalized news delivery (ranking of news). Different services could share data responsibly in a privacy-preserving manner, provided they are interested in similar user information, such as top-visited websites. However, a detailed privacy-personalization analysis of such a scenario is beyond the scope of this work.

#### Tracking Across Services
Tracking often occurs across multiple services, such as Google or Microsoft, which can track users via web search, email, or voice calls. This multi-service tracking scenario is out of scope for this paper, but our work sets the foundation for addressing it. IP-based tracking is unavoidable in client-server setups unless anonymization proxies are used. To address a multi-service scenario, it is necessary to understand the information each service needs for personalization and how it can be obfuscated. We chose web search due to its relatively mature personalization, which is not the case for most services.

### Conclusions

Bloom cookies encode user profiles in a compact and privacy-preserving manner without compromising personalization. Compared to profile generalization and noise addition techniques, Bloom cookies provide a better tradeoff between privacy, personalization, and network efficiency. Our analysis of web search logs shows that profile generalization significantly hurts personalization and fails to provide reasonable unlinkability. Noise injection addresses these issues but incurs high communication overhead and requires a trusted third party to provide a noise dictionary. Bloom cookies leverage Bloom filters to deliver similar or better personalization and unlinkability with lower communication costs and no dependency on a noise dictionary.

### Acknowledgements

This work was partly supported by the TerraSwarm Research Center, one of six centers supported by the STAR-net phase of the Focus Center Research Program (FCRP), a Semiconductor Research Corporation program sponsored by MARCO and DARPA. We thank Doug Burger for suggesting Bloom filters for service personalization, and Ryen White and Dan Liebling for their help in understanding web search personalization algorithms and processing search logs.

### References

[1] “Open Directory Project,” http://dmoz.org/.

[2] G. Aggarwal, E. Bursztein, C. Jackson, and D. Boneh, “An Analysis of Private Browsing Modes in Modern Browsers,” in USENIX Security Symposium, 2010, pp. 79–94.

[3] C. Ardagna, M. Cremonini, E. Damiani, S. De Capitani di Vimercati, and P. Samarati, “Location privacy protection through obfuscation-based techniques,” in Data and Applications Security XXI, ser. LNCS. Springer Berlin Heidelberg, 2007, vol. 4602, pp. 47–60.

[4] M. Balakrishnan, I. Mohomed, and V. Ramasubramanian, “Where’s that phone?: geolocating IP addresses on 3G networks,” in Proc. of IMC ’09, 2009, pp. 294–300.

[5] E. Balsa, C. Troncoso, and C. Diaz, “OB-PWS: Obfuscation-Based Private Web Search,” in Proceedings of the 2012 IEEE Symposium on Security and Privacy. IEEE Computer Society, 2012, pp. 491–505.

[6] P. N. Bennett, R. W. White, W. Chu, S. T. Dumais, P. Bailey, F. Borisyuk, and X. Cui, “Modeling the impact of short- and long-term behavior on search personalization,” in Proc. of SIGIR ’12, 2012, pp. 185–194.

[7] R. Bhagwan, S. Savage, and G. Voelker, “Understanding availability,” Springer Berlin Heidelberg, in Peer-to-Peer Systems II, ser. LNCS. 2003, vol. 2735, pp. 256–267.

[8] G. Bianchi, L. Bracciale, and P. Loreti, “‘Better Than Nothing’ Privacy with Bloom Filters: To What Extent?” in Privacy in Statistical Databases, ser. Lecture Notes in Computer Science. Springer Berlin Heidelberg, 2012, vol. 7556, pp. 348–363.

[9] B. H. Bloom, “Space/time trade-offs in hash coding with allowable errors,” Commun. ACM, vol. 13, no. 7, pp. 422–426, Jul. 1970.

[10] A. Broder and M. Mitzenmacher, “Network Applications of Bloom Filters: A Survey,” Internet Mathematics, vol. 1, no. 4, pp. 485–509, 2004.

[11] M. Casado and M. J. Freedman, “Peering Through the Shroud: The Effect of Edge Opacity on IP-based Client Identification,” in Proc. of NSDI ’07. USENIX Association, 2007, pp. 13–13.

[12] P. A. Chirita, W. Nejdl, R. Paiu, and C. Kohlschütter, “Using ODP metadata to personalize search,” in Proc. of SIGIR ’05, 2005, pp. 178–185.

[13] S. Claußand S. Schiffner, “Structuring Anonymity Metrics,” in Proc. of the 2nd ACM Workshop on Digital Identity Management, ser. DIM ’06, 2006, pp. 55–62.

[14] comScore, “The Myth of Static IP,” Sept 2008, http://www.comscore.com/Insights/Blog/The-Myth-of-Static-IP.

[15] S. Cronen-Townsend and W. B. Croft, “Quantifying query ambiguity,” Proc. of HLT’02, pp. 94–98, 2002.

[16] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: the second-generation onion router,” in Proc. of the 13th conference on USENIX Security Symposium - Volume 13, 2004, pp. 21–21.

[17] J. Domingo-Ferrer, A. Solanas, and J. Castellà-Roca, “h(k)-private information retrieval from privacy-uncooperative queryable databases,” Online Information Review, vol. 33, no. 4, pp. 720–744, 2009.

[18] Z. Dou, R. Song, and J.-R. Wen, “A large-scale evaluation and analysis of personalized search strategies,” in Proc. of WWW ’07, 2007, pp. 581–590.

[19] M. Franz, B. Meyer, and A. Pashalidis, “Attacking Unlinkability: The Importance of Context,” in Privacy Enhancing Technologies, ser. Lecture Notes in Computer Science, 2007, vol. 4776, pp. 1–16.

[20] M. Fredrikson and B. Livshits, “RePriv: Re-imagining Content Personalization and In-browser Privacy,” in IEEE Symposium on Security and Privacy, 2011, pp. 131–146.

[21] S. Gauch, J. Chaffee, and A. Pretschner, “Ontology-based personalized search and browsing,” Web Intelli. and Agent Sys., vol. 1, no. 3-4, pp. 219–234, Dec. 2003.

[22] D. Goldschlag, M. Reed, and P. Syverson, “Onion routing,” Commun. ACM, vol. 42, no. 2, pp. 39–41, Feb. 1999.

[23] S. Guha, B. Cheng, and P. Francis, “Privad: Practical Privacy in Online Advertising,” in Proc. of NSDI ’11, Boston, MA, 2011.

[24] D. Howe and H. Nissenbaum, “TrackMeNot: Resisting Surveillance in Web Search,” in In Lessons from the Identity Trail: Anonymity, Privacy, and Identity in a Networked Society, ser. Oxford: Oxford University Press, I. Kerr, C. Lucock, and V. Steeves, Eds., 2009, pp. 31–58.

[25] B. J. Jansen, A. Spink, and T. Saracevic, “Real life, real users, and real needs: a study and analysis of user queries on the web,” Information Processing and Management, vol. 36, no. 2, pp. 207 – 227, 2000.

[26] C. S. Jensen, H. Lu, and M. Yiu, “Location privacy techniques in client-server architectures,” in Privacy in Location-Based Applications, ser. Lecture Notes in Computer Science, C. Bettini, S. Jajodia, P. Samarati, and X. Wang, Eds., 2009, vol. 5599, pp. 31–58.

[27] A. Juels, “Targeted Advertising ... And Privacy Too,” in Proc. of the 2001 Conference on Topics in Cryptology: The Cryptographer’s Track at RSA (CT-RSA 2001), 2001, pp. 408–424.

[28] H. Kido, Y. Yanagisawa, and T. Satoh, “An anonymous communication technique using dummies for location-based services,” in Proc. of ICPS ’05, July 2005, pp. 88–97.

[29] R. Krovetz and W. B. Croft, “Lexical ambiguity and information retrieval,” ACM Trans. Inf. Syst., vol. 10, no. 2, pp. 115–141, Apr. 1992.

[30] Z. Ma, G. Pant, and O. R. L. Sheng, “Interest-based personalized search,” ACM Trans. Inf. Syst., vol. 25, no. 1, Feb. 2007.

[31] M. Murugesan and C. Clifton, “Providing Privacy through Plausibly Deniable Search,” in Proc. of the SIAM International Conference on Data Mining (SDM ’09), 2009, pp. 768–779.

[32] N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kruegel, F. Piessens, and G. Vigna, “Cookieless monster: Exploring the ecosystem of web-based device fingerprinting,” in IEEE Security and Privacy, 2013.

[33] M. S. Olivier, “Distributed proxies for browsing privacy: a simulation of flocks,” in Proc. of SAICSIT ’05, 2005, pp. 104–112.

[34] K. Purcell, J. Brenner, and L. Rainie, “Search Engine Use 2012,” March 2012, http://pewinternet.org/Reports/2012/Search-Engine-Use-2012.aspx.

[35] D. Rebollo-Monedero and J. Forné, “Optimized query forgery for private information retrieval,” IEEE Transactions on Information Theory, vol. 56, no. 9, pp. 4631–4642, 2010.

[36] B. Shapira, Y. Elovici, A. Meshiach, and T. Kuflik, “PRAW - A PRivAcy model for the Web,” J. Am. Soc. Inf. Sci. Technol., vol. 56, no. 2, pp. 159–172, Jan. 2005.

[37] X. Shen, B. Tan, and C. Zhai, “Implicit user modeling for personalized search,” in Proc. of CIKM ’05, 2005, pp. 824–831.

[38] C. Silverstein, H. Marais, M. Henzinger, and M. Moricz, “Analysis of a very large web search engine query log,” SIGIR Forum, vol. 33, no. 1, pp. 6–12, Sep. 1999.

[39] H. Song, S. Dharmapurikar, J. Turner, and J. Lockwood, “Fast hash table lookup using extended bloom filter: An aid to network processing,” in Proc. of SIGCOMM ’05. ACM, 2005, pp. 181–192.

[40] R. Song, Z. Luo, J.-R. Wen, Y. Yu, and H.-W. Hon, “Identifying Ambiguous Queries in Web Search,” in Proc. of WWW ’07. ACM, 2007, pp. 1169–1170.

[41] D. Sontag, K. Collins-Thompson, P. N. Bennett, R. W. White, S. Dumais, and B. Billerbeck, “Probabilistic models for personalizing web search,” in Proc. of WSDM ’12, 2012, pp. 433–442.

[42] M. Speretta and S. Gauch, “Personalized Search Based on User Search Histories,” in Proc. of the IEEE/WIC/ACM International Conference on Web Intelligence (WI’05), 2005, pp. 622–628.

[43] L. Sweeney, “K-anonymity: A Model for Protecting Privacy,” Int. J. Uncertain. Fuzziness Knowl.-Based Syst., vol. 10, no. 5, pp. 557–570, Oct. 2002.

[44] J. Teevan, S. T. Dumais, and E. Horvitz, “Personalizing search via automated analysis of interests and activities,” in Proc. of SIGIR ’05, 2005, pp. 449–456.

[45] J. Teevan, S. T. Dumais, and D. J. Liebling, “To personalize or not to personalize: modeling queries with variation in user intent,” in Proc. SIGIR ’08, 2008, pp. 163–170.

[46] G. Tóth, Z. Hornák, and F. Vajda, “Measuring anonymity revisited,” in Proc. of the 9th Nordic Workshop on Secure IT Systems, 2004, pp. 85–90.

[47] V. Toubiana, A. Narayanan, D. Boneh, H. Nissenbaum, and S. Barocas, “Adnostic: Privacy Preserving Targeted Advertising,” in Proc. of NDSS ’10, 2010.

[48] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt, and T. Wobber, “How dynamic are IP addresses?” vol. 37, no. 4, pp. 301–312, 2007.

[49] Y. Xu, K. Wang, B. Zhang, and Z. Chen, “Privacy-enhancing Personalized Web Search,” in Proc. of WWW ’07, 2007, pp. 591–600.

[50] S. Ye, S. F. Wu, R. Pandey, and H. Chen, “Noise Injection for Search Privacy Protection,” in Proc. of IEEE CSE ’09, 2009, pp. 1–8.

### Appendix

#### Linkability Model
As described in §III-B, the linkability model maps the Jaccard similarity of a pair of user profiles to the probability that these profiles belong to the same user. To calculate this mapping function, we take \( n \) test users and compute two profiles for each user, one for the time period \( T_1 \) and one for \( T_2 \) (both 2-week long). Next, we calculate the Jaccard similarity for the \( \frac{n(n-1)}{2} \) profile pairs. We divide the range of possible similarities (from 0 to 1) into 100 equal-sized buckets. For each bucket, we determine the fraction of profile pairs with similarities within that range that belong to the same user. From this, we calculate a conditional probability: the probability that a profile pair belongs to the same user given that the similarity lies within a certain range.

Figure 6 shows this mapping function with Bezier interpolation when using exact profiles (URLs). As expected, if the similarity exceeds a certain threshold, the probability that the profiles belong to the same user approaches 1.

We also calculate a mapping function for generalized profiles and for each noisy profile used in our evaluation. When adding noise to the profiles, we first add the noise to the test users' profiles and then repeat the process described above.