### Optimized Text

#### Asymptotic Behavior and Proof
As \( N \) approaches infinity, the value of \( R_t \) is given by:
\[
R_t = \mathbb{E} \left[ \left(1 - B \cdot a(s)\right)^{S-1} \right] \int_0^t a(s) \, ds
\]
where \( S \) is a random variable with distribution \( \nu \).

**Proof.** Refer to the appendix of [6].

In the limit, the number of uploads to remote nodes is denoted as \( R_\infty \). The value of \( R_\infty \) depends on:
1. The rate of queries over time.
2. The distribution of host online times.
3. The distribution of subnet sizes \( \nu \).

A small value of \( R_\infty \) indicates that the number of inter-subnet uploads is low, implying a significant benefit from using P2P with locality.

#### Lower Bound for \( R_t \)
Assume that the per-host query rate \( a(t) \) is non-increasing with \( t \) (see also Corollary 1). A lower bound for \( R_t \) is:
\[
R_t \geq \mathbb{E} \left[ (1 - \rho)^{S-1} \right] A(t), \quad \text{for } \rho \leq 1,
\]
where \( \rho \) can be interpreted as the number of polls in an interval equal to the average host online duration (see Corollary 1). This lower bound implies that \( R_\infty \) is greater than \( \mathbb{E} \left[ (1 - \rho)^{S-1} \right] \) (since \( A(\infty) = 1 \)). This lower bound is tight in our data set and provides a good estimate of \( R_\infty \).

#### Simulation Results and User Online Times
We revisit the simulation results presented in Figure 15, which were computed assuming users stay online for 1 minute. We aim to relate user online times to \( R_\infty \) and, consequently, to the reduction in inter-subnet traffic by preferentially uploading to nodes within the same subnet. Recall that the parameter \( \rho \) depends on the mean user online time \( b \), since \( \rho = b \cdot a^* \). Using Equation 3 and the observed distribution of subnet sizes (distribution \( \nu \) from which we draw values \( S \); see Figure 16), we evaluate \( R_\infty \). Note that \( R_\infty \) decreases with \( \rho \), the mean number of polls during a typical online interval. Figure 17 plots \( R_\infty \) as a function of \( \rho \), showing that \( R_\infty \) decreases rapidly as \( \rho \) increases.

The average polling frequency in the Windows Update system is \( a^* = \frac{1}{20} \) hours. For this polling frequency, we compute the required mean host online time to achieve specific numbers of remote uploads (small \( R_\infty \)); the results are given in Table 4. Host online times as low as a few minutes can reduce the number of remote uploads by more than an order of magnitude. Specifically, if hosts stay online for 1 minute, then \( \rho = \frac{1}{1200} \). Experimentally, we find that \( R_\infty \approx 0.015 \) for large enough subnets (see Figure 15(c)). This implies that with locality, the required upload traffic for large subnets decreases to 1.5% of the traffic without locality (e.g., random matching), representing an improvement of almost two orders of magnitude.

#### Impact on Subnet Uploads and Downloads
We have shown that locality reduces both remote downloads (Theorems 1 and Corollary 1) and remote uploads (Theorems 2 and Equation 3). However, how does locality affect the balance of per-subnet uploads and downloads? To answer this, we study the ratio of remote uploads to remote downloads, as shown in Figure 15(d). We observe that large subnets, with more than 5K users, upload to other subnets more than they download, indicating that large subnets contribute resources. Using the results from Theorem 1 and Theorem 2, we numerically compute the expected per-subnet upload-to-download ratio. The results in Figure 15(d) show good agreement between the analytical result (solid line) and the experimental findings.

Ideally, the ratio of uploads to downloads for all subnets should be close to 1. However, from Figure 15(d), we observe that, even though the upload traffic reduces, the ratio of uploads to downloads is greater than 1 for subnets larger than \( \frac{1}{\rho} \log \left( \frac{1}{R_\infty} \right) \approx 5040 \) (as observed experimentally). This implies that with locality, large subnets contribute more resources than they receive. Designing P2P matching algorithms with low inter-subnet traffic and balanced uploads to downloads for all subsets, even very large ones, remains an interesting challenge.

#### Nature of the Results
The results presented in Theorem 2 and Equation 3 are asymptotic and hold for large host populations. Our data set contains measurements for a large population (around 300M users), and thus, our empirical findings agree well with our analysis. (Note that the results in Theorem 1 and Corollary 1 apply to arbitrarily given subnet sizes \( N_j \)).

### Related Work
The problem of keeping a large number of machines updated with the latest software, fixes, and upgrades has been of great interest to many professionals, especially in large IT departments. Previous work focused primarily on designing middleware and configuring systems to enable remote software installations and upgrades [5, 10, 18, 21–23]. Although networking issues in updating many machines in parallel have not been explicitly addressed in these papers, Shaddock et al. [10] noted the problem of many machines simultaneously connecting to the software distribution center and proposed a ticket system to distribute the load.

From a commercial perspective, many products propose or use automatic updates [13, 15, 20, 25, 27], and we expect this trend to increase significantly in the future.

From a networking point of view, distributing software updates is a content distribution problem. Content distribution, studied for over a decade, has proposed various technologies such as multicasting, caching, CDNs [1], and peer-to-peer networks [4, 8] for update distribution. The current Windows Update system uses an extensive and geographically distributed content distribution network. However, software updates have distinct characteristics that differentiate them from traditional content distribution problems, and exploiting these characteristics may lead to more efficient distribution. For example, since downloading software updates is typically a background activity, user downloads can be scheduled to balance network load.

The design of an update distribution system that exploits similarities between users depends on understanding typical machine configurations and the software update process. Studies such as [12, 26] have provided insights into typical machine states and configuration issues, while [3] reports statistics on machine availability and load characteristics. These findings complement our work, although our analysis provides statistics at a coarser granularity and studies a much larger and diverse population.

Previous work has extensively studied popular Internet applications such as Web servers and video streaming services [3, 19, 24]. The problem of propagating updates to a large number of non-homogeneous users using broadcast channels has also been studied [14]. To the best of our knowledge, our study is the first large-scale study of a live patching system.

### Conclusions
In this paper, we characterize a large commercial update service to draw general guidelines for designing and architecting a fast and effective planet-scale patch dissemination system. Automatic software updating is a critical architectural issue in today's Internet, as rapid and effective update distribution to millions of machines is increasingly popular for keeping systems up-to-date with the latest features and bug fixes. Rapid distribution of security patches is vital for protecting against security attacks and malware.

Unlike traditional content distribution systems, patch distribution systems use near-push functionality, have publication times dependent on development cycles or malware appearances, use differential update mechanisms, exhibit distinct traffic patterns, and require minimum delivery times.

Based on empirical observations and analytical results, we identify interesting properties of today's update traffic and user behavior. We provide evidence that patches can be clustered into a small set of functional components, reducing the complexity of any patch delivery system. We estimate the percentage of always-online users and the characteristics of the user arrival pattern, and use these estimates to study the performance of an ideal patching solution. We consider two standard content distribution architectures, caching and peer-to-peer, and evaluate their applicability to patch dissemination. We demonstrate that P2P has great potential for providing fast and effective patch delivery, which is an interesting observation since current P2P systems work best when many users download few large files, rather than many small files as in patching systems.

Using extensive measurement data from multiple vantage points, we characterize the behavior of current patching systems and gain insights that may help design more efficient distribution mechanisms. We believe that the workloads used in this study represent typical behavior of live patching systems. Most of our findings capture general properties induced by user behavior, architectural characteristics of today's Internet, or properties of current software engineering systems and development cycles, and thus apply to the general problem of Internet-wide dissemination of software updates.

### Acknowledgments
We would like to thank the MS Software Distribution, Windows Update, and MSCOMS teams for their tremendous support and help during the data collection process and for providing invaluable information. In particular, we express our deepest gratitude to Ryan Auld, Jeff Davis, Josh Dunn, Taqi Jaffri, Deighton Maragh, Tom McGuire, Kurt Parent, Mark Roellich, Rob Satterwhite, Manoj Shende, and Mike Sligger.

### References
[1] Akamai home page. .
[2] BBC iMP. http://www.bbc.co.uk/imp/.
[3] W. Bolosky, J. Douceur, D. Ely, and M. Theimer. Feasibility of a serverless distributed file system deployed on an existing set of desktop PCs. In ACM SigMetrics, 2000.
[4] B. Cohen. BitTorrent. .
[5] J. Dunagan, R. Roussev, B. Daniels, A. Johnson, C. Verbowski, and Y.-M. Wang. Towards a self-managing software patching process using black-box persistent-state manifests. In IEEE Intl. Conf. on Autonomic Computing, 2004.
[6] C. Gkantsidis, T. Karagiannis, P. Rodriguez, and M. Vojnović. Planet scale software updates. Technical Report MSR-TR-2006-85, Microsoft Research, 2006.
[7] C. Gkantsidis, J. Miller, and P. Rodriguez. Anatomy of a P2P content distribution system with network coding. In 5th Int. Work. on P2P System (IPTPS), 2006.
[8] Gnutella. .
[9] S. Guha and P. Francis. Characterization and measurement of TCP traversal through NATs and firewalls. In ACM IMC, 2005.
[10] C. Hemmerich. Automatic request-based software distribution. In USENIX 14th System Administration Conf. (LISA), 2000.
[11] T. Karagiannis, P. Rodriguez, and K. Papagiannaki. Should internet service providers fear peer-assisted content distribution? In ACM/USENIX IMC, 2005.
[12] E. Kiciman and C. Verbowski. Analyzing persistent state interactions to improve state management. 2005.
[13] Mac OS X: Updating your software. http://docs.info.apple.com/article.html?artnum=106704, 2005.
[14] S. Mahajan, M. Donahoo, S. Navathe, M. Ammar, and S. Malik. Grouping techniques for update propagation in intermittently-connected databases. In IEEE Conf. on Data Engineering, 1998.
[15] Microsoft Update FAQ. http://update.microsoft.com/microsoftupdate/v6/default.aspx?ln=en-us.
[16] Using binary delta compression (BDC) technology to update Windows operating systems. Microsoft online White Paper.
[17] A. Muthitacharoen, B. Chen, and D. Mazieres. A low-bandwidth network file system. In SOSP, 2001.
[18] P. Osel and W. Günther. OpenDist - incremental software distribution. In USENIX 9th System Administration Conf. (LISA), 1995.
[19] V. Padmanabhan and L. Qiu. The content and access dynamics of a busy website: Findings and implications. In ACM SigComm, 2000.
[20] Red Hat Network. http://www.redhat.com/en_us/USA/rhn/, 2005.
[21] D. Ressman and J. Valdes. Use of CFEngine for automated, multiplatform software and patch distribution. In USENIX 14th System Administration Conf. (LISA), 2000.
[22] M. Shaddock, M. Mitchell, and H. Harrison. How to upgrade 1500 workstations on Saturday, and still have time to mow the yard on Sunday. In USENIX 9th System Administration Conf. (LISA), 1995.
[23] L. Sobr and P. Tuma. SOFAnet: Middleware for software distribution over the Internet. In IEEE Symp. on Applications and the Internet (SAINT’05), 2005.
[24] K. Sripanidkulchai, A. Ganjam, B. Maggs, and H. Zhang. The feasibility of supporting large-scale live streaming applications with dynamic application end-points. In ACM SigComm, 2004.
[25] Symantec Corp. http://www.symantec.com/.
[26] H. Wang, J. Platt, Y. Chen, R. Zhang, and Y.-M. Wang. Automatic misconfiguration troubleshooting with PeerPressure. In USENIX OSDI, 2004.
[27] ZDNet Updates.com. http://updates.zdnet.com.