### 13. Related Work

#### Author Identification and Cross-Site Identity Linking
The author identification problem aims to determine the original author of a document [51]. Narayanan et al. [51] used linguistic stylometry for large-scale identification of blog post authors, highlighting potential risks to anonymous bloggers and whistleblowers. A related challenge is cross-site identity linking attacks [15, 16, 34, 62, 86], where adversaries exploit linguistic [14] and location [30] patterns to link pseudonymous identities across different sites.

Backes et al. [16] introduced relative and absolute linkability measures to rank identities by their anonymity and estimate linkability risks. Andreou et al. [15] further explored the relationship between anonymity and the risks of linking Facebook and Twitter accounts. Venkatadri et al. [73] developed a framework to transfer trust between sites and identify trustworthy accounts. Jain et al. [34] observed shared attributes between Facebook and Twitter profiles to develop methods for linking Twitter accounts to their owners' Facebook accounts. Cloning attacks [39], where adversaries clone victims' accounts from one site to another, can complicate this linkage.

In our work, de-anonymization is not an attack but a desirable feature. This problem is more challenging because, unlike Twitter and Facebook, crowdsourcing and peer-opinion sites do not facilitate explicit inter-connections. Our research focuses on a many-to-one de-anonymization strategy, attributing multiple fake identities to a single real identity (i.e., the underlying fraud worker).

#### Sybil Community Detection
Pseudonymous fraudster discovery is equivalent to uncovering Sybil (or sockpuppet) communities. Sybil accounts disconnect physical from online identities, enabling malicious uses such as gaining control over systems [25], vandalism [63], or creating the illusion of widespread support for ideas, people, or products [66]. Early Sybil detection in online systems focused on social networks [23, 72, 84, 85], assuming that attackers can easily form social relationships between Sybil accounts but find it difficult to establish links with honest accounts. However, Yang et al. [81] showed that in Renren, Sybil accounts are well-connected with honest users and do not form tight-knit communities.

In peer-opinion systems lacking strong social links, social graphs can be replaced by co-activity graphs, such as our co-review graphs. Kumar et al. [40] demonstrated that Sybil accounts in discussion communities differ from honest accounts through social network structure, posting behavior, and linguistic traits. They leveraged the observation that pairs of accounts controlled by the same individual are more likely to interact on the same discussion to build a co-ownership predictor. Zheng et al. [87] predict Sybil links based on the similarity of reviews, including targeted products, times, and ratings. In Section 11.4, we show that our co-ownership predictor significantly outperforms Zheng et al. [87]'s predictor. We did not compare against Kumar et al. [40]'s predictor, which uses community feedback features unavailable in sites like Google Play. After detecting Sybil communities, Detego aims to de-anonymize them by identifying the crowdsourcing account of the human fraud worker who controls them.

#### Fraud Detection
There is extensive research on defending against online system fraud. State-of-the-art approaches use inference on the social graph [12, 37, 53, 58, 75] and classical machine learning based on several assumptions: (i) bursty activity [27, 43, 44, 83], (ii) review plagiarism [31, 36, 37, 47] and distinguishability of machine vs. human-generated reviews [82], (iii) extreme reviews and deviation [47, 58, 77, 79], (iv) lockstep behavior [18, 67, 71], and (v) ratio of singleton accounts [58, 61, 83]. Unlike previous work, which focuses on binary classification of reviews and accounts, we aim to identify prolific workers responsible for significant fraud. We implement a maximum likelihood estimation and deep learning-based guilt-by-association process to expand seed, fraudster-controlled account sets, and assign them to the crowdsourcing account of the fraudster who controls them.

#### Fraud Data Collection
De Cristofaro et al. [24] deployed Facebook honeypot pages to analyze like farms based on demographic, temporal, and social dimensions. Some farms appeared to be operated by bots, while others mimicked regular user behavior. Stringhini et al. [68] studied Twitter follower markets by purchasing followers and using this ground truth to detect "market" accounts. In this paper, we use fraudster responses to conduct live validation of our solutions and map accounts in the online peer-opinion system to the controlling crowdsourcing worker.

### 14. Conclusions
In this paper, we study the search rank fraud de-anonymization problem, which differs from the well-studied fraud or spammer detection problem. We model fraud de-anonymization as a maximum likelihood estimation problem and develop an unconstrained optimization algorithm. We introduce a graph-based deep learning approach to predict co-ownership of fraudulent account pairs and use it to build discriminative fraud de-anonymization and pseudonymous fraudster discovery algorithms. Additionally, we introduce the first protocol involving human fraud workers to evaluate the performance of fraud de-anonymization algorithms. Our solutions achieve high precision and recall on ground truth data, significantly outperforming state-of-the-art approaches and attributing thousands of new accounts to known crowdsourced fraudsters.

### Acknowledgments
We thank the anonymous reviewers for their insightful feedback. This research was supported by NSF grant CNS-1527153 and the Florida Center for Cybersecurity.

### References
[References remain unchanged]

This version of the text is more structured, clear, and professional, with improved flow and coherence.