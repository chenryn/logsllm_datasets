# Site Reliability Engineering: How Google Runs Production Systems

**Edited by Betsy Beyer, Chris Jones, Jennifer Petoff, and Niall Richard Murphy**

## Praise for Site Reliability Engineering

"Google's SREs have done our industry an enormous service by documenting the principles, practices, and patterns—both architectural and cultural—that enable their teams to combine continuous delivery with world-class reliability at a massive scale. You owe it to yourself and your organization to read this book and try out these ideas."  
—Jez Humble, coauthor of *Continuous Delivery* and *Lean Enterprise*

"I remember when Google first began speaking at systems administration conferences. It was like hearing from a Gila monster expert at a reptile show—entertaining, but ultimately, the audience would return to their geckos. Now, we live in a different universe where Google's operational practices are more relevant to those working on a smaller scale. The best practices of SRE, refined over the years, are now of keen interest to the rest of us. For those facing challenges around scale, reliability, and operations, this book is timely."  
—David N. Blank-Edelman, Director, USENIX Board of Directors, and founding co-organizer of SREcon

"I have been eagerly awaiting this book since I left Google. It is the gospel I preach to my peers at work."  
—Björn Rabenstein, Team Lead of Production Engineering at SoundCloud, Prometheus developer, and former Google SRE

"A thorough discussion of Site Reliability Engineering from the company that invented the concept. This book not only covers the technical details but also the thought process, goals, principles, and lessons learned over time. If you want to understand what SRE truly means, start here."  
—Russ Allbery, SRE and Security Engineer

"With this book, Google employees share the processes they have taken, including the missteps, that have allowed Google services to expand to both massive scale and great reliability. I highly recommend this book to anyone who wants to create a set of integrated services that they hope will scale. The book provides an insider’s guide to building maintainable services."  
—Rik Farrow, USENIX

"Writing large-scale services like Gmail is hard. Running them with high reliability is even harder, especially when you change them every day. This comprehensive 'recipe book' shows how Google does it, and you’ll find it much cheaper to learn from our mistakes than to make them yourself."  
—Urs Hölzle, SVP Technical Infrastructure, Google

## About the Book

### Site Reliability Engineering: How Google Runs Production Systems
**Edited by Betsy Beyer, Chris Jones, Jennifer Petoff, and Niall Richard Murphy**

**Copyright © 2016 Google, Inc. All rights reserved.**  
Printed in the United States of America.  
Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.  
O’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are also available for most titles. For more information, contact our corporate/institutional sales department at [corporate@oreilly.com](mailto:corporate@oreilly.com).

**Editor:** Brian Anderson  
**Production Editor:** Kristen Brown  
**Copyeditor:** Kim Cofer  
**Proofreader:** Rachel Monaghan  
**Indexer:** Judy McConville  
**Interior Designer:** David Futato  
**Cover Designer:** Karen Montgomery  
**Illustrator:** Rebecca Demarest

**First Edition: April 2016**  
**Revision History for the First Edition:**
- **2016-03-21:** First Release

For release details, see [the O’Reilly website](https://www.oreilly.com/).

The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. *Site Reliability Engineering*, the cover image, and related trade dress are trademarks of O’Reilly Media, Inc.

While the publisher and the authors have used good faith efforts to ensure that the information and instructions contained in this work are accurate, the publisher and the authors disclaim all responsibility for errors or omissions, including without limitation responsibility for damages resulting from the use of or reliance on this work. Use of the information and instructions contained in this work is at your own risk. If any code samples or other technology this work contains or describes is subject to open source licenses or the intellectual property rights of others, it is your responsibility to ensure that your use thereof complies with such licenses and/or rights.

**ISBN: 978-1-491-92912-4**

## Table of Contents

- **Foreword**  
- **Preface**
- **Part I: Introduction**
  - Chapter 1: Introduction
  - Chapter 2: The Production Environment at Google, from the Viewpoint of an SRE
- **Part II: Principles**
  - Chapter 3: Embracing Risk
  - Chapter 4: Service Level Objectives
  - Chapter 5: Eliminating Toil
  - Chapter 6: Monitoring Distributed Systems
  - Chapter 7: The Evolution of Automation at Google
  - Chapter 8: Release Engineering
  - Chapter 9: Simplicity
- **Part III: Practices**
  - Chapter 10: Practical Alerting from Time-Series Data
  - Chapter 11: Being On-Call
  - Chapter 12: Effective Troubleshooting
  - Chapter 13: Emergency Response
  - Chapter 14: Managing Incidents
  - Chapter 15: Postmortem Culture: Learning from Failure
  - Chapter 16: Tracking Outages
  - Chapter 17: Testing for Reliability
  - Chapter 18: Software Engineering in SRE
  - Chapter 19: Load Balancing at the Frontend
  - Chapter 20: Load Balancing in the Datacenter
  - Chapter 21: Handling Overload
  - Chapter 22: Addressing Cascading Failures
  - Chapter 23: Managing Critical State: Distributed Consensus for Reliability
  - Chapter 24: Distributed Periodic Scheduling with Cron
  - Chapter 25: Data Processing Pipelines
  - Chapter 26: Data Integrity: What You Read Is What You Wrote
  - Chapter 27: Reliable Product Launches at Scale
- **Part IV: Management**
  - Chapter 28: Accelerating SREs to On-Call and Beyond
  - Chapter 29: Dealing with Interrupts
  - Chapter 30: Embedding an SRE to Recover from Operational Overload
  - Chapter 31: Communication and Collaboration in SRE
  - Chapter 32: The Evolving SRE Engagement Model
- **Part V: Conclusions**
  - Chapter 33: Lessons Learned from Other Industries
  - Chapter 34: Conclusion
- **Appendices**
  - A: Availability Table
  - B: A Collection of Best Practices for Production Services
  - C: Example Incident State Document
  - D: Example Postmortem
  - E: Launch Coordination Checklist
  - F: Example Production Meeting Minutes
- **Bibliography**
- **Index**

## Foreword

Google’s story is one of scaling up, marking a shift towards IT-centric business. Google was one of the first companies to define business-IT alignment in practice, and went on to inform the concept of DevOps for a wider IT community. This book has been written by a broad cross-section of the very people who made that transition a reality.

Google grew at a time when the traditional role of the system administrator was being transformed. It questioned system administration, as if to say: we can’t afford to hold tradition as an authority, we have to think anew, and we don’t have time to wait for everyone else to catch up. Initially, Google was fiercely secretive, and what happened inside and outside of Google was very different. Over time, information and methods have flowed in both directions. This book shows a willingness to let SRE thinking come out of the shadows.

Here, we see not only how Google built its legendary infrastructure but also how it studied, learned, and changed its mind about the tools and technologies along the way. We, too, can face up to daunting challenges with an open spirit. The tribal nature of IT culture often entrenches practitioners in dogmatic positions that hold the industry back. If Google overcame this inertia, so can we.

This book is a collection of essays by one company, with a single common vision. The fact that the contributions are aligned around a single company’s goal is what makes it special. There are common themes, and common characters (software systems) that reappear in several chapters. We see choices from different perspectives, and know that they correlate to resolve competing interests. The articles are not rigorous, academic pieces; they are personal accounts, written with pride, in a variety of personal styles, and from the perspective of individual skill sets. They are written bravely, and with an intellectual honesty that is refreshing and uncommon in industry literature. Some claim “never do this, always do that,” others are more philosophical and tentative, reflecting the variety of personalities within an IT culture, and how that too plays a role in the story. We, in turn, read them with the humility of observers who were not part of the journey, and do not have all the information about the myriad conflicting challenges. Our many questions are the real legacy of the volume: Why didn’t they do X? What if they’d done Y? How will we look back on this in years to come? It is by comparing our own ideas to the reasoning here that we can measure our own thoughts and experiences.

The most impressive thing about this book is its very existence. Today, we hear a brazen culture of “just show me the code.” A culture of “ask no questions” has grown up around open source, where community rather than expertise is championed. Google is a company that dared to think about the problems from first principles, and to employ top talent with a high proportion of PhDs. Tools were only components in processes, working alongside chains of software, people, and data. Nothing here tells us how to solve problems universally, but that is the point. Stories like these are far more valuable than the code or designs they resulted in. Implementations are ephemeral, but the documented reasoning is priceless. Rarely do we have access to this kind of insight.

This, then, is the story of how one company did it. The fact that it is many overlapping stories shows us that scaling is far more than just a photographic enlargement of a textbook computer architecture. It is about scaling a business process, rather than just the machinery. This lesson alone is worth its weight in electronic paper.

We do not engage much in self-critical review in the IT world; as such, there is much reinvention and repetition. For many years, there was only the USENIX LISA conference community discussing IT infrastructure, plus a few conferences about operating systems. It is very different today, yet this book still feels like a rare offering: a detailed documentation of Google’s step through a watershed epoch. The tale is not for copying—though perhaps for emulating—but it can inspire the next step for all of us. There is a unique intellectual honesty in these pages, expressing both leadership and humility. These are stories of hopes, fears, successes, and failures. I salute the courage of the authors and editors in allowing such candor, so that we, who are not party to the hands-on experiences, can also benefit from the lessons learned inside the cocoon.

— Mark Burgess, author of *In Search of Certainty*  
Oslo, March 2016

## Preface

Software engineering has this in common with having children: the labor before the birth is painful and difficult, but the labor after the birth is where you actually spend most of your effort. Yet, software engineering as a discipline spends much more time talking about the first period as opposed to the second, despite estimates that 40–90% of the total costs of a system are incurred after birth. The popular industry model that conceives of deployed, operational software as being “stabilized” in production, and therefore needing much less attention from software engineers, is wrong. Through this lens, then, we see that if software engineering tends to focus on designing and building software systems, there must be another discipline that focuses on the whole lifecycle of software objects, from inception, through deployment and operation, refinement, and eventual peaceful decommissioning. This discipline uses—and needs to use—a wide range of skills, but has separate concerns from other kinds of engineers. Today, our answer is the discipline Google calls Site Reliability Engineering (SRE).

So, what exactly is Site Reliability Engineering (SRE)? We admit that it’s not a particularly clear name for what we do—pretty much every site reliability engineer at Google gets asked what exactly that is, and what they actually do, on a regular basis.

Unpacking the term a little, first and foremost, SREs are engineers. We apply the principles of computer science and engineering to the design and development of computing systems: generally, large distributed ones. Sometimes, our task is writing the software for those systems alongside our product development counterparts; sometimes, our task is building all the additional pieces those systems need, like backups or load balancing, ideally so they can be reused across systems; and sometimes, our task is figuring out how to apply existing solutions to new problems.

Next, we focus on system reliability. Ben Treynor Sloss, Google’s VP for 24/7 Operations, originator of the term SRE, claims that reliability is the most fundamental feature of any product: a system isn’t very useful if nobody can use it! Because reliability is so critical, SREs are focused on finding ways to improve the design and operation of systems to make them more scalable, more reliable, and more efficient. However, we expend effort in this direction only up to a point: when systems are “reliable enough,” we instead invest our efforts in adding features or building new products.

Finally, SREs are focused on operating services built atop our distributed computing systems, whether those services are planet-scale storage, email for hundreds of millions of users, or where Google began, web search. The “site” in our name originally referred to SRE’s role in keeping the google.com website running, though we now run many more services, many of which aren’t themselves websites—from internal infrastructure such as Bigtable to products for external developers such as the Google Cloud Platform.

Although we have represented SRE as a broad discipline, it is no surprise that it arose in the fast-moving world of web services, and perhaps in origin owes something to the peculiarities of our infrastructure. It is equally no surprise that of all the post-deployment characteristics of software that we could choose to devote special attention to, reliability is the one we regard as primary. The domain of web services, both because the process of improving and changing server-side software is comparatively contained, and because managing change itself is so tightly coupled with failures of all kinds, is a natural platform from which our approach might emerge.

Despite arising at Google, and in the web community more generally, we think that this discipline has lessons applicable to other communities and other organizations. This book is an attempt to explain how we do things: both so that other organizations might make use of what we’ve learned, and so that we can better define the role and what the term means. To that end, we have organized the book so that general principles and more specific practices are separated where possible, and where it’s appropriate to discuss a particular topic with Google-specific information, we trust that the reader will indulge us in this and will not be afraid to draw useful conclusions about their own environment.

We have also provided some orienting material—a description of Google’s production environment and a mapping between some of our internal software and publicly available software—which should help to contextualize what we are saying and make it more directly usable.

Ultimately, more reliability-oriented software and systems engineering is inherently good. However, we acknowledge that smaller organizations may be wondering how they can best use the experience represented here: much like security, the earlier you care about reliability, the better. This implies that even though a small organization has many pressing concerns and the software choices you make may differ from those Google made, it’s still worth putting lightweight reliability support in place early on, because it’s less costly to expand a structure later on than it is to introduce one that is not present. Part IV contains a number of best practices for training, communication, and meetings that we’ve found to work well for us, many of which should be immediately usable by your organization.

But for sizes between a startup and a multinational, there probably already is someone in your organization who is doing SRE work, without it necessarily being called that name, or recognized as such. Another way to get started on the path to improving reliability for your organization is to formally recognize that work, or to find these people and foster what they do—reward it. They are people who stand on the cusp between one way of looking at the world and another one: like Newton, who is sometimes called not the world’s first physicist, but the world’s last alchemist.

And taking the historical view, who, then, looking back, might be the first SRE?

We like to think that Margaret Hamilton, working on the Apollo program on loan from MIT, had all of the significant traits of the first SRE. In her own words, “part of the culture was to learn from everyone and everything, including from that which one would least expect.”

A case in point was when her young daughter Lauren came to work with her one day, while some of the team were running mission scenarios on the hybrid simulation computer. As young children do, Lauren went exploring, and she caused a “mission” to crash by selecting the DSKY keys in an unexpected way, alerting the team as to what would happen if the prelaunch program, P01, were inadvertently selected by a real astronaut during a real mission, during real midcourse. (Launching P01 inadvertently on a real mission would be a major problem, because it wipes out navigation data, and the computer was not equipped to pilot the craft with no navigation data.)

With an SRE’s instincts, Margaret submitted a program change request to add special error checking code in the onboard flight software in case an astronaut should, by accident, happen to select P01 during flight. But this move was considered unnecessary by the “higher-ups” at NASA: of course, that could never happen! So instead of adding error checking code, Margaret updated the mission specifications documentation to say the equivalent of “Do not select P01 during flight.” (Apparently the update was amusing to many on the project, who had been told many times that astronauts would not make any mistakes—after all, they were trained to be perfect.)

Well, Margaret’s suggested safeguard was only considered unnecessary until the very next mission, on Apollo 8, just days after the specifications update. During midcourse on the fourth day of flight with the astronauts Jim Lovell, William Anders, and Frank Borman on board, Jim Lovell selected P01 by mistake—as it happens, on Christmas Day—creating much havoc for all involved. This was a critical problem, because in the absence of a workaround, no navigation data meant the astronauts were never coming home. Thankfully, the documentation update had explicitly called this possibility out, and was invaluable in figuring out how to upload usable data and recover the mission, with not much time to spare.

As Margaret says, “a thorough understanding of how to operate the systems was not enough to prevent human errors,” and the change request to add error detection and recovery software to the prelaunch program P001 was approved shortly afterwards.

Although the Apollo 8 incident occurred decades ago, there is much in the preceding paragraphs directly relevant to engineers’ lives today, and much that will continue to be directly relevant in the future. Accordingly, for the systems you look after, for the groups you work in, or for the organizations you’re building, please bear the SRE Way in mind: thoroughness and dedication, belief in the value of preparation and documentation, and an awareness of what could go wrong, coupled with a strong desire to prevent it. Welcome to our emerging profession!

— Betsy Beyer, Chris Jones, Jennifer Petoff, and Niall Richard Murphy