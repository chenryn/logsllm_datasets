### Remote Hacker Control via Trojaned Applications

When a trojaned application is running, a remote hacker can gain control over the target machine. In this scenario, we utilize tools and payloads from the Metasploit Framework [31] to generate the trojaned application. The Metasploit Framework is a widely-adopted system for developing and executing exploit code for penetration testing. One of its command-line tools, `msfpayload`, generates various types of shellcode.

We use `msfpayload` to create a Meterpreter payload, which is dynamically extensible and uses in-memory DLL injection stagers. The Meterpreter communicates with the remote server via a reverse TCP connection, enabling the remote adversary to perform various hacking operations on the victim's system, such as keylogging, file uploading, taking screenshots, and collecting password hashes. In this case, the benign host application is WinSCP. We use `msfencode` to encode the payload with `shikata_ga_nai` (a polymorphic XOR additive feedback encoder) three times before embedding it into the WinSCP binary.

### Performance Evaluation

From the results, we observe that all five measurements (ACC, TPR, etc.) increase when using the WSVM model. For instance, Figure 6 shows that the ACC and TPR based on the call graph model are 74.79% and 68.16%, respectively. These values increase to 85.81% and 72.08% when using a traditional non-weighted SVM. Our Weighted SVM approach demonstrates even better classification effectiveness, with ACC and TPR increasing to 93.2% and 86.5%. These comparisons highlight the superior performance of our proposed CFG-guided Weighted SVM approach.

### Case Study II — vim_codeinject

This case also falls under the offline infection category but employs a different infection technique and payload. We use the hacking tool Codeinject [32] to inject a password dialog into a portable executable, with Vim serving as the host application. When the user starts Vim, a password dialog appears, asking for a pre-set password. If the user does not know the password, Vim exits silently.

Figure 6 shows that `vim_codeinject` increases all five measurements for each classification model. For example, the ACCs for CGraph, SVM, and WSVM are 35.5%, 72.5%, and 85.2%, respectively. Another measurement, NPVs for CGraph, SVM, and WSVM, are 51.8%, 64.6%, and 78.2%, respectively.

### Case Study III — putty_reverse_https_online

This case involves online injection. If there is an unpatched vulnerability in the target system, an adversary can craft shellcode and perform a remote exploitation to run the shellcode. To maintain persistence, the adversaries can inject a backdoor payload into the memory space of a long-running process. They first allocate a memory slot for the backdoor payload and then remotely create a thread to run the code in parallel with the benign code. In this case, the adversaries use the Metasploit Framework to take over the target system and then inject the Meterpreter payload into the memory of a running Putty. Finally, they connect to the Meterpreter payload within the Putty process via a reverse HTTPS connection.

Figure 7 shows that the ACC, PPV, TPR, TNR, and NPV for WSVM are the highest, consistent with our observations in Case Studies I and II. For example, the corresponding ACCs for the three methods are 69.22%, 78.25%, and 86.86%, and their respective TPRs are 41.2%, 56.1%, and 73.8%.

### Discussion

#### A. Source-level Trojaned Applications

LEAPS currently targets camouflaged attacks against binary applications, assuming the relative offsets of the benign code will not change. However, if the adversary has obtained the source code of the benign application, they could add malicious payload source code, recompile the program, and deliver the trojaned application to the victim. For closed-source software, only internal developers can conduct such attacks. For open-source software, public inspection makes such attacks more difficult. Assuming there are malicious vendors or negligent maintainers, LEAPS cannot currently assign correct weights in the mixed dataset because the CFG itself has been modified.

To address this limitation, we need to generalize our CFG comparison algorithm. For trojaned applications, if the adversaries do not change the functionality of the original benign software, the general structure of the benign subgraph in the CFG will remain unchanged. Instead of exact matching, we could search for isomorphic subgraphs in both benign and mixed CFGs by identifying and aligning pivotal nodes. This is a future direction to improve LEAPS.

#### B. Future Work in Learning

LEAPS uses a Weighted SVM model to distinguish malicious events from benign ones. As shown in the experimental results, LEAPS achieves good performance in detecting camouflaged attacks, outperforming approaches based on system-level call graphs and pure SVM. However, LEAPS only considers the order of adjacent events. In real scenarios, there may be causal relationships between multiple events dispersed in time. Therefore, we plan to explore more machine learning techniques, such as conditional random fields and hidden Markov models, to reveal these hidden relationships.

### Related Work

Host-based anomaly detection and malware classification systems have been well-researched in recent years. The general procedure involves extracting execution abstractions from a subject program, building a model, and using this model to make decisions on future data.

Some systems assume that source code or binary is available for analysis, allowing them to derive precise models of program execution. Wagner et al. [1] define a model of expected application behavior through static analysis of source code and check system call traces at runtime. Giffin et al. [2], [3] introduce the Dyck model based on static binary analysis to facilitate efficient runtime monitoring. DOME [4] identifies system call locations within executables and verifies at runtime that each observed system call is invoked from its legitimate call site. SMIT [33] clusters malware using function-call graphs. Kruegel et al. [34] propose extracting CFGs from worm executables to identify structural similarities among polymorphic worms. In real-world scenarios, source code or executables may not always be available, and obfuscated executables and complex binary disassembly make static analysis challenging. LEAPS, in contrast, does not require static analysis or instrumentation; it models program execution by analyzing system event logs and inferring CFGs to guide statistical learning.

Other researchers propose black-box or gray-box approaches to infer execution models without static analysis. Sekar et al. [6] generate deterministic FSAs by monitoring normal program executions at runtime. Gao et al. [7] build execution graphs based on system call sequences. Feng et al. [8] extract return addresses from the call stack to build abstract execution path models. LEAPS shares the methodology of dynamically deriving program execution models but is among the first to leverage inferred execution models to refine statistical learning models by pruning noisy training datasets.

Statistical learning techniques are widely adopted in anomaly detection research due to their robustness in handling incomplete training data. Hofmeyr et al. [11] characterize normal behaviors in terms of system call sequences. Wespi et al. [12] use Teiresias to build tables of variable-length patterns of audit events. Lee et al. [9], [10] use data mining techniques to find patterns of system features. Bailey et al. [23] categorize malware behavior in terms of system state changes. Lanzi et al. [35] demonstrate that system call sequence-based detectors may not be effective and build models based on access activities.

Recent research introduces more sophisticated machine learning models like HMM and SVM. Warrender et al. [13] compare four anomaly detection models and conclude that HMM achieves the best accuracy but with high computational costs. Gao et al. [36] introduce HMM to measure behavioral distance. Heller et al. [16] use one-class SVM to detect anomalous registry behavior. Kolter et al. [37] use n-grams of byte codes as features. Rieck et al. [15] extract malware behavior in a sandbox environment and use SVM for classification. Bayer et al. [38] use locality-sensitive hashing for unsupervised clustering. Khan et al. [17] enhance SVM training time using hierarchical clustering. Eskin [39] proposes learning a distribution probability over training data to detect anomalies. LEAPS adopts SVM but leverages inferred CFGs to prune noisy datasets, boosting the accuracy of the learned model for detecting camouflaged attacks.

### Conclusion

Camouflaged attacks implant malicious payloads into benign applications and execute concurrently under the cover of benign processes, causing traditional statistical learning-based detection systems to generate misleading decision boundaries due to noisy training data. LEAPS, a new attack detection system, classifies benign and malicious system events using a supervised statistical learning model. Unlike existing approaches, LEAPS leverages CFGs inferred from system event logs to automatically refine noisy training data, leading to a more accurate classification model for camouflaged attack detection. Extensive evaluations on real-world attacks with offline and online camouflaging strategies demonstrate that LEAPS effectively improves classification accuracy compared to traditional learning and system-level call graph-based models.

### Acknowledgment

This work was inspired by technical discussions with Dr. Sukarno Mertoguno, who proposed the "Learn-2-Reason" paradigm [19]. We also thank Brendan Saltaformaggio and the anonymous reviewers for their constructive comments. This research was supported in part by ONR under Award N000141410468, NSF under Award 1409668, and Cisco Systems under an unrestricted gift. Any opinions, findings, and conclusions in this paper are those of the authors and do not necessarily reflect the views of our sponsors.

### References

[1] D. Wagner and D. Dean, “Intrusion detection via static analysis,” in Proceedings of the 2001 IEEE Symposium on Security and Privacy, ser. SP ’01. Washington, DC, USA: IEEE Computer Society, 2001, pp. 156–.

[2] J. T. Giffin, S. Jha, and B. P. Miller, “Efficient context-sensitive intrusion detection.” in NDSS, 2004.

[3] J. T. Giffin, S. Jha, and B. P. Miller, “Detecting manipulated remote call streams,” in Proceedings of the 11th USENIX Security Symposium. Berkeley, CA, USA: USENIX Association, 2002, pp. 61–79.

[4] J. C. Rabek, R. I. Khazan, S. M. Lewandowski, and R. K. Cunningham, “Detection of injected, dynamically generated, and obfuscated malicious code,” in Proceedings of the 2003 ACM Workshop on Rapid Malcode, ser. WORM ’03. New York, NY, USA: ACM, 2003, pp. 76–82.

[5] H. Feng, J. Giffin, Y. Huang, S. Jha, W. Lee, and B. Miller, “Formalizing sensitivity in static analysis for intrusion detection,” in Security and Privacy, 2004. Proceedings. 2004 IEEE Symposium on, May 2004, pp. 194–208.

[6] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni, “A fast automaton-based method for detecting anomalous program behaviors,” in Proceedings of the 2001 IEEE Symposium on Security and Privacy, ser. SP ’01. Washington, DC, USA: IEEE Computer Society, 2001, pp. 144–.

[7] D. Gao, M. K. Reiter, and D. Song, “Gray-box extraction of execution graphs for anomaly detection,” in Proceedings of the 11th ACM Conference on Computer and Communications Security, ser. CCS ’04. New York, NY, USA: ACM, 2004, pp. 318–329.

[8] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong, “Anomaly detection using call stack information,” in Proceedings of the 2003 IEEE Symposium on Security and Privacy, ser. SP ’03. Washington, DC, USA: IEEE Computer Society, 2003, pp. 62–.

[9] W. Lee, S. J. Stolfo, and P. K. Chan, “Learning patterns from Unix process execution traces for intrusion detection,” in In AAAI Workshop on AI Approaches to Fraud Detection and Risk Management. AAAI Press, 1997, pp. 50–56.

[10] W. Lee and S. J. Stolfo, “Data mining approaches for intrusion detection,” in Proceedings of the 7th Conference on USENIX Security Symposium - Volume 7, ser. SSYM’98. Berkeley, CA, USA: USENIX Association, 1998, pp. 6–6.

[11] S. A. Hofmeyr, S. Forrest, and A. Somayaji, “Intrusion detection using sequences of system calls,” J. Comput. Secur., vol. 6, no. 3, pp. 151–180, Aug. 1998.

[12] A. Wespi, M. Dacier, and H. Debar, “Intrusion detection using variable-length audit trail patterns,” in Proceedings of the Third International Workshop on Recent Advances in Intrusion Detection, ser. RAID ’00. London, UK, UK: Springer-Verlag, 2000, pp. 110–129.

[13] C. Warrender, S. Forrest, and B. Pearlmutter, “Detecting intrusions using system calls: alternative data models,” in Security and Privacy, 1999. Proceedings of the 1999 IEEE Symposium on, 1999, pp. 133–145.

[14] D. Gao, M. K. Reiter, and D. Song, “Behavioral distance measurement using hidden Markov models,” in Proceedings of the 9th International Conference on Recent Advances in Intrusion Detection, ser. RAID’06. Berlin, Heidelberg: Springer-Verlag, 2006, pp. 19–40.

[15] K. Rieck, T. Holz, C. Willems, P. Düssel, and P. Laskov, “Learning and classification of malware behavior,” in Proceedings of the 5th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, ser. DIMVA ’08. Berlin, Heidelberg: Springer-Verlag, 2008, pp. 108–125.

[16] K. A. Heller, K. M. Svore, A. D. Keromytis, and S. J. Stolfo, “One-class support vector machines for detecting anomalous Windows registry accesses,” in In Proc. of the workshop on Data Mining for Computer Security, 2003.

[17] L. Khan, M. Awad, and B. Thuraisingham, “A new intrusion detection system using support vector machines and hierarchical clustering,” The VLDB Journal, vol. 16, no. 4, pp. 507–521, Oct. 2007.

[18] S.-J. Horng, M.-Y. Su, Y.-H. Chen, T.-W. Kao, R.-J. Chen, J.-L. Lai, and C. D. Perkasa, “A novel intrusion detection system based on hierarchical clustering and support vector machines,” Expert systems with Applications, vol. 38, no. 1, pp. 306–313, 2011.

[19] J. S. Mertoguno, “Human decision making model for autonomic cyber systems,” International Journal on Artificial Intelligence Tools Vol. 23, No. 6 (2014).

[20] C. H. Kim, J. Rhee, H. Zhang, N. Arora, G. Jiang, X. Zhang, and D. Xu, “Introperf: Transparent context-sensitive multi-layer performance inference using system stack traces,” in The 2014 ACM International Conference on Measurement and Modeling of Computer Systems, ser. SIGMETRICS ’14. New York, NY, USA: ACM, 2014, pp. 235–247.

[21] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical Learning, ser. Springer Series in Statistics. Springer New York Inc., 2001.

[22] T. Bao, J. Burket, M. Woo, R. Turner, and D. Brumley, “Byteweight: Learning to recognize functions in binary code,” pp. 845–860, 2014.

[23] M. Bailey, J. Oberheide, J. Andersen, Z. M. Mao, F. Jahanian, and J. Nazario, “Automated classification and analysis of internet malware,” in Proceedings of the 10th International Conference on Recent Advances in Intrusion Detection, ser. RAID’07. Berlin, Heidelberg: Springer-Verlag, 2007, pp. 178–197.

[24] C. Kolbitsch, P. M. Comparetti, C. Kruegel, E. Kirda, X. Zhou, and X. Wang, “Effective and efficient malware detection at the end host,” in Proceedings of the 18th Conference on USENIX Security Symposium, ser. SSYM’09. Berkeley, CA, USA: USENIX Association, 2009, pp. 351–366.

[25] C. M. Bishop, Pattern Recognition and Machine Learning (Information Science and Statistics). Secaucus, NJ, USA: Springer-Verlag New York, Inc., 2006.

[26] C. Chang and C. Lin, “LIBSVM: A library for support vector machines,” ACM TIST, vol. 2, no. 3, p. 27, 2011.

[27] S. hyuk Cha, “A genetic algorithm for constructing compact binary decision trees,” Journal of Pattern Recognition Research, 2009.

[28] B. Schölkopf, R. Herbrich, and A. J. Smola, “A generalized representer theorem,” in COLT, 2001, pp. 416–426.

[29] I. Buch and R. Park, “Improve debugging and performance tuning with ETW,” MSDN Magazine, [Online], Available from: http://msdn.microsoft.com/en-us/magazine/cc163437.aspx, 2007.

[30] S. V. Stehman, “Selecting and interpreting measures of thematic classification accuracy,” Remote sensing of Environment, vol. 62, no. 1, pp. 77–89, 1997.

[31] “Metasploit,” http://www.metasploit.com/.

[32] “Portable Executable (P.E.) Code Injection: Injecting an Entire C Compiled Application,” http://www.codeproject.com/Articles/24417/Portable-Executable-P-E-Code-Injection-Injecting-a.

[33] X. Hu, T.-c. Chiueh, and K. G. Shin, “Large-scale malware indexing using function-call graphs,” in Proceedings of the 16th ACM Conference on Computer and Communications Security, ser. CCS ’09. New York, NY, USA: ACM, 2009, pp. 611–620.

[34] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna, “Polymorphic worm detection using structural information of executables,” in Proceedings of the 8th International Conference on Recent Advances in Intrusion Detection, ser. RAID’05. Berlin, Heidelberg: Springer-Verlag, 2006, pp. 207–226.

[35] A. Lanzi, D. Balzarotti, C. Kruegel, M. Christodorescu, and E. Kirda, “Accessminer: Using system-centric models for malware protection,” in Proceedings of the 17th ACM Conference on Computer and Communications Security, ser. CCS ’10. New York, NY, USA: ACM, 2010, pp. 399–412.

[36] D. Gao, M. K. Reiter, and D. Song, “Behavioral distance for intrusion detection,” in Proceedings of the 8th International Conference on Recent Advances in Intrusion Detection, ser. RAID’05. Berlin, Heidelberg: Springer-Verlag, 2006, pp. 63–81.

[37] J. Z. Kolter and M. A. Maloof, “Learning to detect and classify malicious executables in the wild,” J. Mach. Learn. Res., vol. 7, pp. 2721–2744, Dec. 2006.

[38] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda, “Scalable, behavior-based malware clustering.” in NDSS, vol. 9. Citeseer, 2009, pp. 8–11.

[39] E. Eskin, “Anomaly detection over noisy data using learned probability distributions,” in Proceedings of the Seventeenth International Conference on Machine Learning, ser. ICML ’00. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 2000, pp. 255–262.