### The Number of Distinct (Landing Domain, Keyword) Pairs

The two peaks (marked A and B in the figure) observed around Christmas and the Super Bowl are not coincidental. Our analysis indicates that significant, predictable events can help adversaries increase their poisoning success rate, given sufficient preparation time and the high interest of a large number of search users in these events. Simultaneously, less predictable but widely covered breaking news, such as the recent earthquake and tsunami in Japan (marked C in Figure 5), also serve as easy targets for search poisoning. 

While the targeted keywords (upper curve) fluctuated to leverage different events, the number of detected landing domains (lower curve) remained relatively stable, suggesting that search poisoning operators have a solid presence in search engine indexes and are ready to launch new attacks whenever the opportunity arises.

### Micro Measurement Statistics

To gain deeper insights into the search poisoning problem, we conducted a long-term (7-month, 212-day) measurement study. In the first month, we manually analyzed the data, and for the subsequent six months, we used SURF to analyze the collected browsing data. During this period, SURF analyzed over 12 million search results from Google and Bing, querying the top 40 "trendy" keywords [2]. Specifically, once a keyword appeared in the top 40 list on a given day, SURF queried the search engines for that keyword for the following seven days. Overall, SURF automatically queried the search engines with 8,480 keywords. This extensive data collection enabled us to study in-the-wild search poisoning instances from two perspectives: a "micro measurement" study based on a 7-day window focusing on frequently changing keyword popularity, and a "macro measurement" study examining poisoning trends over the entire 7-month period.

### Micro Measurements

Due to the frequent changes in trendy search keywords [2], we initially expected that some time (e.g., a few days) would be required for attackers to poison the search terms and make their landing pages appear in the top search results. Surprisingly, our measurements suggest otherwise: adversaries are extremely responsive and have developed effective methods to promote rogue landing pages under targeted trendy search keywords in a short time.

Among the 3,869 keywords for which we detected related poisoned search results, 38% had a poisoning lag (i.e., the time it takes for the first poisoned result to be detected) of one day or less. This percentage decreases as the lag increases, with only 7% of the keywords having a poisoning lag of 7 days, as shown in Figure 4. These results indicate that adversaries are capable of keeping up with search users' interests, and the majority of their poisoning attempts succeed within the first three days.

We also found that the average lifespan of a rogue landing page involved in search poisoning is only 1.7 days. This suggests that adversaries favor a fast-switching strategy to reduce the exposure window, thereby decreasing the likelihood of detection and preserving compromised landing sites for future attacks. However, the appearance of these rogue landing pages in search results lasts for more than three days on average until the page ranking is demoted due to new information retrieved by search crawlers. Throughout the 7-day observation window, the relative volume of detected rogue landing pages for a given poisoned keyword continues to increase, indicating that search poisoning operators have a strong foothold in search engine indexes and are prepared to launch new attacks whenever the opportunity arises.

### Redirection and Landing Page Characteristics

On average, users who fall victim to search poisoning are redirected at least twice, including one cross-domain redirection, before reaching the malicious terminal page. Approximately 29% of these redirections were due to HTTP 30x responses. Unsurprisingly, the remaining 70% were primarily due to client-side scripts, likely an attempt to evade security crawlers that do not support script execution. About 78% of the landing page URLs explicitly contained the targeted search keywords to boost the page's relevance perceived by search crawlers. Approximately 98% of the intermediate URLs included ID-like parameters to track unique visitors, identify search poisoning affiliates, or prevent repeated visits. In 94% of the cases, the terminal page URLs used domain names registered for less than a year, often chosen to deceive victims and promote specific scams.

Among the detected search poisoning cases, the most frequently used top-level domains (TLDs) for landing pages were .com, .org, .net, and .info, with a TLD distribution similar to regular websites. On the other hand, domains related to terminal pages were mostly registered under TLDs such as .cc, .com, .in, and .net, some of which are known to be malware-friendly.

### Variety of Malicious Content

To understand the variety of malicious content promoted through search poisoning, we surveyed 350 randomly chosen terminal pages, evenly distributed across our 7-month measurement period. The results are shown in Figure 6. We manually categorized the terminal pages based on data saved at the time when the page was visited by SURF, including screenshots of each rendered page. As expected, fake antivirus (AV) software was the most prevalent type of malicious content during the entire 7-month period. However, their prevalence started to decline as other types of malicious terminal pages increased. Drive-by malware downloads and other browser exploitation techniques did not commonly leverage search poisoning. Instead, various types of social engineering-based malicious pages, such as rogue search engine pages, were dominant. These pages present users with seemingly relevant links but aim to profit from user clicks.

Scam pages (e.g., watch replicas, etc.) represented another significant fraction of the surveyed terminal pages. Generally, scam pages use free or unrealistically cheap goods to attract users and steal private information (e.g., credit card numbers, passwords). We also encountered several malicious terminal pages related to click fraud and rogue pharmacies. The terminal pages categorized as "void" typically contained clues of certain types of maliciousness (e.g., based on their domain name patterns) but were inaccessible when visited due to unsuccessful DNS resolution or webpage errors. SURF's ability to detect even these "void" malicious terminal pages supports our initial goal of building a detection system that is agnostic to the specific content of malicious pages promoted through search poisoning.

### Related Work

In this section, we discuss two lines of work related to our detection system:

#### Blackhat SEO Countermeasures

Blackhat SEO, which involves abusing search engine optimization techniques to achieve undeserved rankings, has been studied for years, especially in the information retrieval community. Most proposed detection methods work at the search engine level and focus on identifying deceptive information introduced by adversaries into the search index to influence website rankings. Detection features explored by these methods mainly focus on intra-page characteristics [18,22,25] and inter-page linkages [24]. However, for adversaries with full control over their injected search landing pages, such features are not difficult to evade. In fact, traditional methods of countering blackhat SEO have failed to stop its rising trend [11]. SURF addresses search poisoning, a new class of blackhat SEO, by building on lessons learned from previous work and approaching detection from a new angle using a set of features that are more robust to evasion (see Section 3.2.1).

deSEO [15] is a recent work done in parallel with SURF. It detects URLs from the search index that contain signatures derived from known search poisoning landing pages and exhibit patterns not previously seen by the search engine on the same domain. Since there is no need to crawl each URL, this approach scales better than SURF when dealing with a large volume of search results. However, deSEO is limited by the coverage of URL signatures and may only find a subset of what SURF detects. For example, about 12% of the landing page URLs detected by SURF in Section 5.2 do not contain trendy search keywords and thus may be missed by deSEO. Moreover, SURF does not rely on any internal search engine information and can be deployed at the client side, enabling individual browsers to detect poisoned search results and malicious webpages before the content is presented to the user.

#### Malicious Webpage Detection

When implemented as an automated detection agent, SURF can be viewed as a dynamic crawler used to scan search results for poisoned ones. From this perspective, SURF is similar to many proposed systems that crawl the Internet for various kinds of malicious webpages [17,23]. Such systems employ multiple browsing agents running in a controlled environment to visit suspicious URLs in batches and detect signs of specific types of malicious activities. SURF can be easily integrated into these systems and can enable the detection of search poisoning cases along with the related compromised landing pages and malicious terminal pages. However, relying solely on malicious page detectors for finding poisoned search results may achieve limited success due to the variety of terminal pages, many of which use social engineering attacks that are difficult to detect.

Applying machine learning techniques to data collected during a crawling session is also a common approach to detecting malicious webpages. A recent work [21] is able to detect URLs that lead to spam pages. Our work differs because SURF is not limited to detecting spam pages and can instead detect generic search poisoning cases.

### Conclusion

Search poisoning is an abuse of SEO techniques where miscreants target any search term that can maximize the number of incoming search users to their malicious websites. Through an empirical study, we observed that a key characteristic of search poisoning is the ubiquitous use of cross-site redirections. We designed and implemented SURF, a novel detection system that runs as a browser component and can detect malicious search user redirections resulting from clicking on poisoned search results. SURF extracts a number of detection features from search-then-visit browsing sessions. These features are robust, and the resulting classifier is hard to evade because they capture the key properties of search poisoning (derived from our empirical study and analysis). Our evaluation showed that SURF can achieve a detection rate of 99.1% at a false positive rate of 0.9% on a dataset containing real-world search poisoning instances. Using SURF, we also performed a long-term measurement study on search poisoning on the Internet over a period of seven months. Our study revealed new trends and interesting patterns related to a wide variety of poisoning cases, underscoring the prevalence and severity of the search poisoning problem.

### Acknowledgment

The authors would like to thank the anonymous reviewers for their helpful comments on earlier versions of the paper. This material is based upon work supported in part by the National Science Foundation under grant no. 0831300, the Department of Homeland Security under contract no. FA8750-08-2-0141, and the Office of Naval Research under grants no. N000140710907 and no. N000140911042. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation, the Department of Homeland Security, or the Office of Naval Research.

### References

[1] Google search engine optimization. http://www.google.com/webmasters/.

[2] Google Trends. http://www.google.com/trends.

[3] URLVoid: Scan a website with multiple scanning engines. http://www.urlvoid.com/.

[4] WOT: Web of Trust. http://www.mywot.com/wiki/API.

[5] C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, 1993.

[6] Google drives 70 percent of traffic to most websites. http://searchengineoptimism.com/Google_refers_70_percent.html, July 2006.

[7] Malware poisoning results for innocent searches. http://www.eweek.com/c/a/Security/Malware-Poisoning-Results-for-Innocent-Searches, November 2007.

[8] Barracuda Labs 2010 mid-year security report. Technical report, Barracuda Networks Inc., 2010.

[9] Search engine optimization 'poisoning' way up this year. http://www.networkworld.com/news/2010/110910-seo-poisoning-increases.html, November 2010.

[10] The dirty little secrets of search. http://www.nytimes.com/2011/02/13/business/13search.html, February 2011.

[11] Google: Search engine spam on the rise. http://www.pcworld.com/article/217370/google_search, January 2011.

[12] Z. Gyöngyi and H. Garcia-Molina. Web spam taxonomy. Technical report, Stanford University, 2005.

[13] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten. The WEKA data mining software: an update. SIGKDD Explor. Newsl., 11(1):10–18, 2009.

[14] F. Howard and O. Komili. Poisoned search results: How hackers have automated search engine poisoning attacks to distribute malware. Technical report, SophosLab, 2010.

[15] J. John, F. Yu, Y. Xie, M. Abadi, and A. Krishnamurthy. deSEO: Combating search-result poisoning. In Proceedings of the 20th USENIX Security, 2011.

[16] L. Lu, V. Yegneswaran, P. Porras, and W. Lee. Blade: An attack-agnostic approach for preventing drive-by malware infections. In Proceedings of the 17th ACM CCS, 2010.

[17] E. Moshchuk, T. Bragin, S. D. Gribble, and H. M. Levy. A crawler-based study of spyware on the web. In Proceedings of the NDSS, 2006.

[18] A. Ntoulas and M. Manasse. Detecting spam web pages through content analysis. In Proceedings of the 15th WWW, 2006.

[19] L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: Bringing order to the web. Technical Report 1999-66, Stanford InfoLab, 1999.

[20] M. A. Rajab, L. Ballard, P. Mavrommatis, N. Provos, and X. Zhao. The nocebo effect on the web: An analysis of fake antivirus distribution. In Proceedings of the 3rd USENIX LEET, 2010.

[21] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design and evaluation of a real-time URL spam filtering service. In Proceedings of the IEEE S&P, 2011.

[22] T. Urvoy, E. Chauveau, P. Filoche, and T. Lavergne. Tracking web spam with HTML style similarities. ACM Trans. Web, 2:3:1–3:28, March 2008.

[23] Y.-M. Wang, D. Beck, X. Jiang, and R. Roussev. Automated web patrol with Strider honeymonkeys: Finding websites that exploit browser vulnerabilities. In Proceedings of the NDSS, 2006.

[24] B. Wu and B. D. Davison. Identifying link farm spam pages. In Proceedings of the 14th WWW, 2005.

[25] B. Wu and B. D. Davison. Detecting semantic cloaking on the web. In Proceedings of the 15th WWW, 2006.