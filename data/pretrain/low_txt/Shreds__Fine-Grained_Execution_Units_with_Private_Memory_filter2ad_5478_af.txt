### End-to-End Time and Memory Footprint Analysis

#### End-to-End Time (in milliseconds)
| Application | With Shred | Without Shred | Time Increase |
|-------------|------------|---------------|---------------|
| `shred`     | 154        | 163           | 5.80%         |
| `curl`      | 23,770     | 25,650        | 7.90%         |
| `minizip`   | 158.1      | 163.3         | 3.20%         |
| `openssl`   | 2,502      | 2,546         | 1.75%         |
| `lighttpd`  | 501        | 525           | 4.70%         |
| **Average** | **4,707.02** | **4,967.24** | **5.95%**     |

#### Memory Footprint (Max RSS in KB)
| Application | With Shred | Without Shred | Size Increase |
|-------------|------------|---------------|---------------|
| `shred`     | 4,520      | 5,104         | 12.90%        |
| `curl`      | 3,004      | 3,064         | 1.90%         |
| `minizip`   | 3,908      | 4,644         | 18.80%        |
| `openssl`   | 3,892      | 3,908         | 0.40%         |
| `lighttpd`  | 3,364      | 3,440         | 2.30%         |
| **Average** | **3,737.6** | **3,966.0**   | **6.11%**     |

### Related Work

#### Isolated Environments
Isolated environments, such as those provided by virtual machines or containers, are neither suitable nor practical for preventing memory abuses. These systems do not consider the case where protected execution can be exploited. Our design, on the other hand, enforces security checks on in-shred executions.

#### Memory Encryption and Protection
Several memory protection mechanisms have been proposed:
- **Overshadow [27]**: Uses virtualization to render encrypted views of application memory to untrusted OS.
- **Mondrian [28]**: Provides hardware-level memory protection with permission control at word-granularity.
- **Another scheme [29]**: Offers memory encryption and integrity verification for secure processors.

While these schemes provide strong protection, they require hardware modifications and have not been widely adopted. This work was partly motivated by the lack of a practical and software-based memory protection mechanism. Recent research has focused on protecting cryptographic keys in memory, but these solutions are limited in scope and cannot protect other types of sensitive data or code.

#### Dynamic Information Flow Tracking
Dynamic information flow tracking has been used to detect and defend against various attacks, including privacy leaks and control flow manipulations. Systems like HiStar [39] and Flume [40] enabled system-wide tracking. However, this approach is challenging for average programmers. Our work takes a more practical approach, providing easy-to-use primitives to help developers efficiently protect their sensitive data and code.

#### Granular Sandbox and Compartmentalization
Recent works have proposed fine-grained and flexible application sandbox [15], [41] and compartmentalization [42] frameworks. These aim to mitigate memory-related exploitations by reducing the capabilities and privileges for untrusted or vulnerable code. In contrast, our work adopts a reversed model of trust: code in an application is by default untrusted, and only explicitly created and statically verified shreds are given extra privileges during runtime to access the associated s-pools.

Despite the differences in goals, shreds are related to this line of work for two reasons:
1. We faced the same technical challenge of efficiently isolating in-process memory and overcame it via a new and effective approach.
2. Shreds can employ compartmentalization to achieve more systematic mediation of untrusted code, as discussed in § III-D.

### Conclusion
We propose shreds, a set of OS-backed programming primitives that address developers' needs for fine-grained, convenient, and efficient protection of sensitive memory content against in-process adversaries. A shred is a flexibly defined segment of a thread execution, associated with a protected memory pool accessible only to code running in the shred. Unlike previous works, shreds offer in-process private memory without relying on separate page tables, nested paging, or modified hardware. They also provide essential data flow and control flow guarantees for running sensitive code. We have built the compiler toolchain and the OS module to enable threads on Linux. Our evaluation using five non-trivial open-source software, including OpenSSH and Lighttpd, shows that shreds are easy to use and incur low runtime overhead.

### Acknowledgment
We thank the anonymous reviewers for their insightful comments. We also thank our shepherds, Robert Watson and Brent Kang, for their guidance on the final paper revisions. We appreciate the feedback from our colleagues at the National Security Institute at Stony Brook, particularly Mingwei Zhang. This project was supported by the National Science Foundation (Grant#: CNS-1421824 and CNS-1514142) and the Office of Naval Research (Grant#: N00014-15-1-2378).

Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the National Science Foundation or the Office of Naval Research.

### References
[1] Z. Durumeric, J. Kasten, D. Adrian, J. A. Halderman, M. Bailey, F. Li, N. Weaver, J. Amann, J. Beekman, M. Payer et al., “The matter of heartbleed,” in Proceedings of the 2014 Conference on Internet Measurement Conference. ACM, 2014, pp. 475–488.
[2] Z. Deng, B. Saltaformaggio, X. Zhang, and D. Xu, “iris: Vetting private API abuse in iOS applications,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, ser. CCS ’15. New York, NY, USA: ACM, 2015, pp. 44–56. [Online]. Available: http://doi.acm.org/10.1145/2810103.2813675
[3] A. Bittau, P. Marchenko, M. Handley, and B. Karp, “Wedge: Splitting applications into reduced-privilege compartments.” in NSDI, vol. 8, 2008, pp. 309–322.
[4] “Memory domains,” http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0211k/Babjdffh.html.
[5] J. Corbet, “Memory protection keys,” https://lwn.net/Articles/643797/, May 2015.
[6] D. Hansen, “[rfc] x86: Memory protection keys,” https://lwn.net/Articles/643617/, May 2015.
[7] C. Lattner and V. Adve, “LLVM: A compilation framework for lifelong program analysis & transformation,” in Code Generation and Optimization, 2004. CGO 2004. International Symposium on. IEEE, 2004, pp. 75–86.
[8] D. Kilpatrick, “Privman: A library for partitioning applications.” in USENIX Annual Technical Conference, FREENIX Track, 2003, pp. 273–284.
[9] N. Provos, M. Friedl, and P. Honeyman, “Preventing privilege escalation.” in USENIX Security, vol. 3, 2003.
[10] D. Brumley and D. Song, “Privtrans: Automatically partitioning programs for privilege separation,” in USENIX Security Symposium, 2004, pp. 57–72.
[11] Y. Liu, T. Zhou, K. Chen, H. Chen, and Y. Xia, “Thwarting memory disclosure with efficient hypervisor-enforced intra-domain isolation,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, ser. CCS ’15, 2015.
[12] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. Shafi, V. Shanbhogue, and U. R. Savagaonkar, “Innovative instructions and software model for isolated execution,” in Proceedings of the 2nd International Workshop on Hardware and Architectural Support for Security and Privacy. ACM, 2013, pp. 1–1.
[13] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham, “Efficient software-based fault isolation,” in ACM SIGOPS Operating Systems Review, vol. 27, no. 5. ACM, 1994, pp. 203–216.
[14] “Domain access control register,” http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0434b/CIHBCBFE.html.
[15] R. N. Watson, J. Anderson, B. Laurie, and K. Kennaway, “Capsicum: Practical capabilities for UNIX.” in USENIX Security Symposium, 2010, pp. 29–46.
[16] “Clang: A C language family frontend for LLVM,” http://clang.llvm.org/.
[17] M. Castro, M. Costa, J.-P. Martin, M. Peinado, P. Akritidis, A. Donnelly, P. Barham, and R. Black, “Fast byte-granularity software fault isolation,” in Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles. ACM, 2009, pp. 45–58.
[18] U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and G. C. Necula, “XFI: Software guards for system address spaces,” in Proceedings of the 7th symposium on Operating systems design and implementation. USENIX Association, 2006, pp. 75–88.
[19] B. Ford and R. Cox, “Vx32: Lightweight user-level sandboxing on the x86.” in USENIX Annual Technical Conference. Boston, MA, 2008, pp. 293–306.
[20] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar, “Native Client: A sandbox for portable, untrusted x86 native code,” in Security and Privacy, 2009 30th IEEE Symposium on. IEEE, 2009, pp. 79–93.
[21] “ARM 32-bit sandbox,” https://developer.chrome.com/native-client/reference/sandbox-internals/arm-32-bit-sandbox. Available: https://developer.chrome.com/native-client/reference/sandbox-internals/arm-32-bit-sandbox.
[22] Y. Zhou, X. Wang, Y. Chen, and Z. Wang, “Armlock: Hardware-based fault isolation for ARM,” in Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2014, pp. 558–569.
[23] R. Strackx and F. Piessens, “Fides: Selectively hardening software application components against kernel-level or process-level malware,” in Proceedings of the 2012 ACM conference on Computer and communications security. ACM, 2012, pp. 2–13.
[24] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter, and H. Isozaki, “Flicker: An execution infrastructure for TCB minimization,” in ACM SIGOPS Operating Systems Review, vol. 42, no. 4. ACM, 2008, pp. 315–328.
[25] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor, and A. Perrig, “Trustvisor: Efficient TCB reduction and attestation,” in Security and Privacy (SP), 2010 IEEE Symposium on. IEEE, 2010, pp. 143–158.
[26] A. M. Azab, P. Ning, and X. Zhang, “SICE: A hardware-level strongly isolated computing environment for x86 multi-core platforms,” in Proceedings of the 18th ACM conference on Computer and communications security. ACM, 2011, pp. 375–388.
[27] X. Chen, T. Garfinkel, E. C. Lewis, P. Subrahmanyam, C. A. Waldspurger, D. Boneh, J. Dwoskin, and D. R. Ports, “Overshadow: A virtualization-based approach to retrofitting protection in commodity operating systems,” in ACM SIGOPS Operating Systems Review, vol. 42, no. 2. ACM, 2008, pp. 2–13.
[28] E. Witchel, J. Cates, and K. Asanović, “Mondrian memory protection,” in Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS X. New York, NY, USA: ACM, 2002, pp. 304–316. [Online]. Available: http://doi.acm.org/10.1145/605397.605429
[29] G. E. Suh, D. Clarke, B. Gassend, M. v. Dijk, and S. Devadas, “Efficient memory integrity verification and encryption for secure processors,” in Proceedings of the 36th annual IEEE/ACM International Symposium on Microarchitecture. IEEE Computer Society, 2003, p. 339.
[30] K. Harrison and S. Xu, “Protecting cryptographic keys from memory disclosure attacks,” in Dependable Systems and Networks, 2007. DSN’07. 37th Annual IEEE/IFIP International Conference on. IEEE, 2007, pp. 137–143.
[31] Akamai Technologies, “Secure storage of private (RSA) keys,” https://lwn.net/Articles/594923/.
[32] MSDN, “SecureString class,” https://msdn.microsoft.com/en-us/library/system.security.securestring.aspx.
[33] T. Müller, F. C. Freiling, and A. Dewald, “TRESOR runs encryption securely outside RAM.” in USENIX Security Symposium, 2011, pp. 17–17.
[34] L. Guan, J. Lin, B. Luo, and J. Jing, “COPKER: Computing with private keys without RAM,” in 21st ISOC Network and Distributed System Security Symposium (NDSS), 2014.
[35] G. Vasiliadis, E. Athanasopoulos, M. Polychronakis, and S. Ioannidis, “PixelVault: Using GPUs for securing cryptographic operations,” in Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2014, pp. 1131–1142.
[36] L. Guan, J. Lin, B. Luo, J. Jing, and J. Wang, “Protecting private keys against memory disclosure attacks using hardware transactional memory,” in Security and Privacy (SP), 2015 IEEE Symposium on, May 2015, pp. 3–19.
[37] D. Y. Zhu, J. Jung, D. Song, T. Kohno, and D. Wetherall, “TaintEraser: Protecting sensitive data leaks using application-level taint tracking,” ACM SIGOPS Operating Systems Review, vol. 45, no. 1, pp. 142–154, 2011.
[38] G. E. Suh, J. W. Lee, D. Zhang, and S. Devadas, “Secure program execution via dynamic information flow tracking,” in ACM SIGPLAN Notices, vol. 39, no. 11. ACM, 2004, pp. 85–96.
[39] N. Zeldovich, S. Boyd-Wickizer, E. Kohler, and D. Mazières, “Making information flow explicit in HiStar,” in Proceedings of the 7th symposium on Operating systems design and implementation. USENIX Association, 2006, pp. 263–278.
[40] M. Krohn, A. Yip, M. Brodsky, N. Cliffer, M. F. Kaashoek, E. Kohler, and R. Morris, “Information flow control for standard OS abstractions,” in ACM SIGOPS Operating Systems Review, vol. 41, no. 6. ACM, 2007, pp. 321–334.
[41] A. Belay, A. Bittau, A. Mashtizadeh, D. Terei, D. Mazières, and C. Kozyrakis, “DUNE: Safe user-level access to privileged CPU features,” in Presented as part of the 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12), 2012, pp. 335–348.
[42] R. N. Watson, J. Woodruff, P. G. Neumann, S. W. Moore, J. Anderson, D. Chisnall, N. Dave, B. Davis, K. Gudka, B. Laurie et al., “CHERI: A hybrid capability-system architecture for scalable software compartmentalization,” in Security and Privacy (SP), 2015 IEEE Symposium on. IEEE, 2015, pp. 20–37.