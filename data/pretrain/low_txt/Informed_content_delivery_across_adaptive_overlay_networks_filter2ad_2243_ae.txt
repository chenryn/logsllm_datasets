### Tweaking X-Axis Values in Our Plots
Figure 7 illustrates the results of our experiments for this scenario. In each experiment, uninformed collaboration performs poorly and degrades significantly as containment increases. This result is intuitive and can be analyzed using methods similar to those used in the well-known Coupon Collector's problem [14]. Essentially, the rate of useless symbols transmitted increases with the number of symbols shared between peers. The degree of sharing increases both as the initial containment increases and as the transfer progresses.

### Overhead in Collaborating with Multiple Peers in Parallel
Figure 9 shows the overhead when collaborating with multiple peers in parallel. Speculative collaboration is more efficient than uninformed collaboration, but the overhead still increases slowly with containment. In contrast, the overhead of reconciled collaboration is virtually indistinguishable from plain encoded transfers from a server and does not increase with containment. The extra overhead of reconciled collaboration is solely from the cost of reconciliation (e.g., transmitting a Bloom filter or approximate reconciliation tree), which is less than 1% when sending 8 bits for every symbol (1400 bytes).

### Peer-Augmented Downloads
The next scenario involves a download from a server with complete content, supplemented by a perpendicular transfer from a peer, as shown in Figure 6(b). Unlike the previous scenario, this one demonstrates the utility of additional bandwidth in parallel with an ongoing download from a server. The distribution of symbols between peers at the beginning of the scenario is determined by the slack and containment.

The results, shown in Figure 8, are similar regardless of the slack. The overhead of uninformed collaboration is lower than in the scenarios of Figure 7, primarily because a larger fraction of the content is sent directly via fresh symbols from the server. Using our methods, speculative collaboration performs similarly to uninformed collaboration in this scenario, as the recoding methods used are not highly optimized—some improvements are possible with additional effort. In all cases, reconciled collaboration has only slightly higher overhead than receiving symbols directly from the server, but the transfer time is substantially reduced when the additional connection is employed.

For this scenario, it is natural to consider the speedup obtained by augmenting the download with an additional connection. Defining the speedup as the ratio between the transfer time using a single sender with full content (and incurring no decoding overhead) and the transfer time we achieve, we have:
\[ \text{speedup} = \frac{\text{number of senders}}{1 + \text{overhead}} \]
Since all connections are assumed to have equal bandwidth and are fully utilized, a reconciled transfer with 0.025 overhead achieves a speedup of 1.95, while an uninformed transfer with 0.20 overhead achieves a more modest speedup of 1.67 over a vanilla download.

### Collaborating with Multiple Peers in Parallel
Finally, we consider a peer collaborating concurrently with four peers, all with partial content, as illustrated in Figure 6(c). This scenario demonstrates that, given appropriate reconciliation algorithms, one can leverage bandwidth from peers with partial content with only a slight increase in overhead.

When encoding symbols are allocated across multiple peers, slack and containment no longer uniquely determine the initial distribution of symbols. We employ the following allocation method: the receiver initially has exactly 0.5" symbols. One of these symbols is known to a sending peer with probability \( c \). The remaining symbols are known to a sending peer with probability \( p \) such that \( \left( \frac{0.5}{t} \right) (1 - c) / \left( 1 - \frac{0.5}{t} \right) \). Any symbols not known to any sending peers are discarded and replaced, resulting in each peer having an expected 0.5" symbols at the beginning of the experiment.

The results of this scenario are shown in Figure 9. As expected, uninformed collaboration performs extremely poorly. For low values of containment, speculative collaboration performs the same as uninformed collaboration but dramatically improves as containment increases. In contrast to previous experiments, reconciled collaboration has much higher overhead due to correlation across multiple peers. For example, sending peers D and E may identify shared symbol \( x \) as being in \( S_D - S_A \) and \( S_E - S_A \), respectively, and then both send \( x \) to receiving peer A. When a symbol is received multiple times, it directly contributes to the overhead. For similar reasons, the performance of speculative collaboration is also degraded, as the recoding algorithm is optimized only for transfers between pairs of peers.

Given the relatively poor performance of reconciled collaboration when there is sharing between sending peers, we now consider the effects of periodically updating the summaries, in contrast to the previous experiments, which performed fine-grained reconciliation only once at the beginning of the scenario. We repeat the experiments for this scenario with the containment constrained to zero (the worst case for reconciled collaboration) and modulate the frequency of reconciliation. Figure 10(a) shows the results of this experiment. In this graph, the update frequency \( f \) means that an update is performed after receiving \( \frac{N}{f} \) symbols, i.e., a frequency of 20 implies that updates are triggered after every 5% of the download progresses. The bottom curve reflects the extra bandwidth of traffic to the receiving peer. The top curve adds the bandwidth consumed by updates, thus accounting for the total amount of extra communication in both directions. For example, as \( f \) increases, the bandwidth spent on reconciliation updates becomes significant and ultimately would dominate the bandwidth of the actual transfer. When optimizing total bandwidth consumption, we find that a reasonable reconciliation frequency is roughly 10-20, depending on the slack of the scenario, meaning that there is an update after every 0.05" - 0.10" symbols that are transferred.

Figure 10(b) shows the results of using these updates in the scenarios of Figure 9, i.e., speculative collaboration updates the min-wise summary and reconciled collaboration updates the Bloom filters. An update frequency of 10 is used, and both speculative and reconciled collaboration show dramatic improvement.

### Conclusions
Overlay networks offer a powerful alternative to traditional mechanisms for content delivery, especially in terms of flexibility, scalability, and deployability. To derive the full benefits of this approach, some care is needed to provide methods for representing and transmitting the content in a manner that is as flexible and scalable as the underlying capabilities of the delivery model. We argue that straightforward approaches may appear effective at first but ultimately suffer from similar scaling and coordination problems that have undermined other multipoint service models for content delivery.

In contrast, a digital fountain approach to encoding the content affords a great deal of flexibility to end-systems performing large transfers. The main drawback of this approach is that the large space of possible symbols in the system means that coordination across end-systems is also needed, in this case, to filter useful content from redundant content. Our main contributions furnish efficient, concise representations that sketch the relevant state at an end-system in a handful of packets and then provide appropriate algorithmic tools to perform well under any circumstances. With these methods in hand, informed and effective collaboration between end-systems can be achieved, with all the benefits of using an encoded content representation.

### Acknowledgements
We would like to thank Ari Trachtenberg and the anonymous SIGCOMM '02 reviewers for the helpful feedback they provided on earlier versions of this paper.

### References
[1] Altavista. www.altavista.com.
[2] ANDERSEN, D., BALAKRISHNAN, H., KAASHOEK, F., AND MORRIS, R. Resilient overlay networks. In Proc. of ACM Symposium on Operating Systems Principles (Banff, Canada, October 2001).
[3] BLOOM, B. Space/time trade-offs in hash coding with allowable errors. Communications of the ACM 13 (July 1970), 422–426.
[4] BOHMAN, T., COOPER, C., AND FRIEZE, A. Min-wise independent linear permutations. Electronic Journal of Combinatorics 7, R26 (2000).
[5] BRODER, A. On the resemblance and containment of documents. In Compression and Complexity of Sequences (SEQUENCES) (Positano, Italy, June 1997).
[6] BRODER, A. Z., CHARIKAR, M., FRIEZE, A. M., AND MITZENMACHER, M. Min-wise independent permutations. Journal of Computer and System Sciences 60, 3 (2000), 630–659.
[7] BYERS, J. W., LUBY, M., AND MITZENMACHER, M. Accessing multiple mirror sites in parallel: Using Tornado codes to speed up downloads. In Proc. of IEEE INFOCOM (March 1999), pp. 275–83.
[8] BYERS, J. W., LUBY, M., MITZENMACHER, M., AND REGE, A. A digital fountain approach to reliable distribution of bulk data. In Proc. of ACM SIGCOMM (Vancouver, September 1998), pp. 56–67. To appear in IEEE Journal on Selected Areas in Communications.
[9] CHAWATHE, Y. Scattercast: An Architecture for Internet Broadcast Distribution as an Infrastructure Service. PhD thesis, University of California, Berkeley, December 2000.
[10] CHU, Y.-H., RAO, S., AND ZHANG, H. A case for end system multicast. In ACM SIGMETRICS (Santa Clara, CA, June 2000).
[11] CONSIDINE, J. Generating good degree distributions for sparse parity check codes using oracles. Tech. Rep. BUCS-TR 2001-019, Boston University, October 2001.
[12] FAN, L., CAO, P., ALMEIDA, J., AND BRODER, A. Summary cache: A scalable wide-area cache sharing protocol. IEEE/ACM Trans. on Networking 8(3) (2000), 281–293. A preliminary version appeared in Proc. of SIGCOMM '98.
[13] JANNOTTI, J., GIFFORD, D., JOHNSON, K., KAASHOEK, M., AND O'TOOLE, J. Overcast: Reliable multicasting with an overlay network. In Proc. of USENIX Symp. on Operating Systems Design and Implementation (San Diego, CA, October 2000).
[14] KLAMKIN, M., AND NEWMAN, D. Extensions of the birthday surprise. Journal of Combinatorial Theory 3 (1967), 279–282.
[15] LABOVITZ, C., MALAN, G., AND JAHANIAN, F. Internet routing instability. In Proc. of ACM SIGCOMM (September 1997).
[16] LUBY, M. Information Additive Code Generator and Decoder for Communication Systems. U.S. Patent No. 6,307,487, October 23, 2001.
[17] LUBY, M., MITZENMACHER, M., SHOKROLLAHI, A., AND SPIELMAN, D. Efficient erasure correcting codes. IEEE Transactions on Information Theory 47(2) (2001), 569–584.
[18] MACWILLIAMS, F. J., AND SLOANE, N. The Theory of Error-Correcting Codes. North Holland, Amsterdam, 1977.
[19] MAHANTI, A., EAGER, D. L., VERNON, M. K., AND SUNDARAM-STUKEL, D. Scalable on-demand media streaming with packet loss recovery. In Proc. of ACM SIGCOMM (August 2001), pp. 97–108.
[20] MERKLE, R. A digital signature based on a conventional encryption function. In Advances in Cryptology (CRYPTO) (Santa Barbara, CA, August 1987).
[21] MINSKY, Y., AND TRACHTENBERG, A. Practical set reconciliation. Tech. Rep. BU ECE 2002-01, Boston University, 2002.
[22] MINSKY, Y., TRACHTENBERG, A., AND ZIPPEL, R. Set reconciliation with nearly optimal communication complexity. In Proc. of IEEE Int’l Symp. on Information Theory (Washington, DC, June 2001).
[23] MITZENMACHER, M. Compressed bloom filters. In Proc. of the 20th Annual ACM Symposium on Principles of Distributed Computing (2001), pp. 144–150. To appear in IEEE/ACM Trans. on Networking.
[24] RABIN, M. Efficient dispersal of information for security, load balancing and fault tolerance. Journal of the ACM 38 (1989), 335–348.
[25] RATNASAMY, S., FRANCIS, P., HANDLEY, M., KARP, R., AND SHENKER, S. A scalable content-addressable network. In Proc. of ACM SIGCOMM (San Diego, CA, August 2001).
[26] RODRIGUEZ, P., AND BIERSACK, E. W. Dynamic parallel-access to replicated content in the Internet. IEEE/ACM Transactions on Networking 10(4) (August 2002). A preliminary version appeared in Proc. of IEEE INFOCOM '00.
[27] ROWSTRON, A., AND DRUSCHEL, P. Storage management and caching in past, a large-scale, persistent peer-to-peer storage utility. In Proc. of ACM Symposium on Operating Systems Principles (Banff, Canada, October 2001).
[28] SAVAGE, S., COLLINS, A., HOFFMAN, E., SNELL, J., AND ANDERSON, T. The end-to-end effects of Internet path selection. In Proc. of ACM SIGCOMM (August 1999).
[29] STOICA, I., MORRIS, R., KARGER, D., KAASHOEK, F., AND BALAKRISHNAN, H. Chord: A scalable peer-to-peer lookup service for internet applications. In Proc. of ACM SIGCOMM (San Diego, CA, August 2001).
[30] Swarmcast. http://www.opencola.org/projects/swarmcast.
[31] VITTER, J. S. Random sampling with a reservoir. ACM Trans. on Math. Software 11 (1985), 37–57.
[32] ZHUANG, S., ZHAO, B., JOSEPH, A., KATZ, R., AND KUBIATOWICZ, J. Bayeux: An architecture for scalable and fault-tolerant wide area data dissemination. In Proc. of NOSSDAV '01 (Port Jefferson, NY, June 2001).