# Efficiency and Performance Analysis of HoVer3

## 4.2. Short Write IO Costs
The term "short write" refers to a host write that updates any portion of a data element (e.g., a bit update). In the design of our HoVer code, each data element is associated with exactly \( t \) parity elements. Consequently, the cost of a short write update is precisely \( 2(t + 1) \) I/O seeks, achieved through a standard read-modify-write algorithm for the \( t \) parity values. This is optimal for most codes, with the exception of (near) symmetric codes, such as WEAVER codes [10, 11], which have an equal number of parity and data elements. The bound matches that of vertical MDS codes (e.g., X-code [22]) and is superior to horizontal MDS codes (e.g., Blaum-Roth [4]), where some data elements are associated with more than \( t = 2 \) parity elements.

## 4.3. Reconstruction Costs
HoVer codes demonstrate a significant advantage in reconstruction costs compared to most other codes. Consider the HoVer2\(^{1,1}\) code (a similar argument applies to HoVert\(^{t-1,1}\) codes for \( t = 3, 4 \) when fewer than \( t \) strips are lost, and a variation applies to HoVer3\(^{1,1}\) as well). We will discuss two scenarios: (a) reconstruction when one strip is lost, and (b) reconstruction when two strips are lost. The former is referred to as a Degraded array, and the latter as a Critical array. In the following discussion, we ignore cases where the h-parity strip is lost, as these are straightforward.

### Degraded Array
When one data/parity strip is lost, \( r \) data elements are lost. A host read to one of these strips requires the reconstruction of the lost data. RAID4 (or RAID5) with \( n \) data strips necessitates reading \( n \) chunks of data from \( n \) strips (the \( n-1 \) remaining data strips and the parity strip). An XOR computation with \( n \) inputs is then required to reconstruct the lost data. This same argument applies to any horizontal code, such as EVENODD or RDP. It can be verified that each of the vertical codes (X-code, BCP, or ZZS) requires reading from \( n-2 \) strips (on an array of size \( n \)) and an XOR computation with \( n-2 \) inputs.

This method using the h-parity can also be applied to HoVer codes, as they contain a RAID4 subcode. However, HoVer codes also utilize v-parity elements for reconstruction, requiring reads from only \( r \) strips. Since \( r \leq n-2 \) (for the HoVer2\(^{1,1}\) code), HoVer codes offer a net performance advantage over other known codes.

Furthermore, even for complete reconstruction of all the data and parity on the lost strip, only a subportion of the entire (remaining) stripe needs to be accessed, and every XOR computation has only \( r \) inputs. In contrast, most other codes require accessing the entire stripe, and most reconstruction formulas have order \( n \) inputs (or more).

By Theorem 2, we can vary the size of \( r \) below the bound of Theorem 3. A smaller \( r \) linearly improves reconstruction costs, albeit with a trade-off in efficiency.

### Critical Array
Suppose two data/parity strips are down in a HoVer2\(^{1,1}\) array. The proof of Theorem 3 shows that the recovery algorithm involves following reconstruction chains. For most failure scenarios in the 1-shift code and all scenarios in the 2-shift code, there are at least two such chains. Most scenarios have many (split) chains, and in some instances, these chains are only one element long. As the gap between the lost strips increases (modulo \( n \)), the number of chains of length one increases smoothly. For all vertical MDS codes and most horizontal codes, reconstruction follows such chains, but in these cases, the chains are generally quite long, and there are at most two such chains. Longer chains imply more work to reconstruct the elements near the end of the chains. The maximum length of the chains is proportional to the number of rows. Therefore, HoVer codes, which support constructions with variable \( r \), have more efficient and parameterizable reconstruction chains.

Additionally, if two lost strips are separated by \( r + s \) consecutive strips, each strip can be recovered independently using only the v-parity row. This is because no diagonal intersects both strips, so all recovery chains have length one.

## 4.4. Extended Fault Tolerance
The ability to vary the parameter \( r \) provides an additional advantage. If \( r \) is small compared to \( n \), the array can recover from certain instances of more than \( t \) failures. For the HoVer2\(^{1,1}\) case, if the gap between two lost strips is large enough, each can be recovered as an independent instance of a single failure (a property also shared by WEAVER codes [10, 11]). More precisely, the HoVer2\(^{1,1}\) code can recover from any number of failures so long as in any set of \( r + s \) consecutive strips (with wrap-around), there are no more than two lost strips. None of the MDS codes have this property (in a single code instance); this is a direct consequence of the MDS property. Similar extended fault tolerance is available for other HoVer code constructions, provided \( r \) is sufficiently small relative to \( n \).

## 4.5. Parameter Flexibility
Most codes that tolerate \( t \geq 2 \) failures have strict restrictions on the relationship between the parameters \( r \) and \( n \). For example, BCP [1] requires \( r = n/2 - 1 \) with \( n \) even. Other codes have primality restrictions on some parameters. The X-code [22] requires \( n \) to be prime and \( r = n - 2 \). Horizontal codes such as EVENODD [2], Blaum-Roth [4], and RDP [6] require \( r = p - 1 \) for some prime \( p \) and \( n \leq p \) (or \( n \leq p - 1 \) for RDP). In these cases, the number of rows must increase to increase the array size, which implies performance penalties. More rows mean more fragmentation of the parity formulas, more formulas, and thus more computation costs. Additionally, decreasing the number of rows can improve reconstruction costs and add additional fault tolerance.

HoVer codes are unique in that the number of rows is bounded above by a function of the array size. All array sizes are supported uniformly (unlike BCP codes, X-code, or ZZS [23]). The implementer may choose an \( r \) value that works for the entire range of array sizes supported by the system. This allows the array to support changes in size without significant rearrangement of data or parity elements. Furthermore, when one disk is down, the HoVer code's resource requirements for reconstruction are uniform across all array sizes with a constant \( r \) (a property not held by most 2-fault tolerant erasure codes). Fixing \( r \) and increasing \( n \) (or fixing \( n \) and decreasing \( r \)) significantly impacts storage efficiency. In summary, HoVer codes provide a range of constructions, allowing the implementer flexibility in balancing the efficiency penalty with performance advantages.

## 5. Open Problems
There are several open problems in the context of HoVer codes. We list a few of the more important ones here, ordered by the amount of effort we have put into them and their tractability (easier, more specific problems first):

- Determine (and prove) the precise conjecture for the HoVer3\(^{2,1}\) code when \( pr(n) = 3 \).
- Prove the lower bounds in Conjecture 2 for HoVer3\(^{2,1}\) codes.
- Find a construction for a HoVer3\(^{1,2}\) code (one parity row and two h-parity strips).
- Find a reasonable general construction for HoVert\(^{t-1,1}\) codes for any \( t \).

## 6. Summary
In this paper, we presented HoVer codes, a new family of XOR-based erasure codes for disk arrays. They combine the concepts of h-parity (parity stored on separate disks from the data) and v-parity (parity stored on the same disk with unrelated data) as a hybrid data/parity layout. We provided a complete characterization of one construction (and a simple variant) that tolerates 2 lost disks. Additionally, we provided a construction of a 3-fault tolerant code and discussed additional constructions for 3 and 4-fault tolerance. These latter constructions were supported by a mixture of theory, conjecture, and experiment, covering all practical array sizes. We argued that the parameter flexibility of HoVer codes gives implementers and designers the ability to adjust the performance/efficiency trade-off to achieve the best balance of these metrics in a specific environment or system.

## 7. Acknowledgements
The author thanks KK Rao, Tapas Kanungo, and Veera Deenadhayalan for their contributions to this work. We also want to thank the Blue Gene/L support team at IBM’s Almaden Research Center for the opportunity to run many of the larger experiments on their system and for their assistance. Testing array sizes in the 300–600 range (as we did for HoVer3\(^{1,1}\) codes) required considerable computing power.

## References
[1] S. Baylor, P. Corbett, and C. Park. Efficient method for providing fault tolerance against double device failures in multiple device systems, January 1999. U. S. Patent 5,862,158.
[2] M. Blaum, J. Brady, J. Bruck, and J. Menon. EVENODD: an efficient scheme for tolerating double disk failures in RAID architectures. IEEE Transactions on Computers, 44:192–202, 1995.
[3] M. Blaum, J. Brady, J. Bruck, J. Menon, and A. Vardy. The EVENODD code and its generalization. In J. Jin, T. Cortest, and R. Buyya, editors, High Performance Mass Storage and Parallel I/O: Technologies and Applications, chapter 14, pages 187–208. IEEE and Wiley Press, New York, 2001.
[4] M. Blaum and R. M. Roth. On lowest density MDS codes. IEEE Transactions on Information Theory, 45:46–59, 1999.
[5] J. Bloomer, M. Kalfane, M. Karpinski, R. Karp, M. Luby, and D. Zuckerman. An XOR-based erasure-resilient coding scheme. Technical Report TR-95-048, International Computer Science Institute, August 1995.
[6] P. Corbett, B. English, A. Goel, T. Grcanac, S. Kleiman, J. Leong, and S. Sankar. Row-diagonal parity for double disk failure. In Proceedings of the Third USENIX Conference on File and Storage Technologies, pages 1–14, 2004.
[7] R. G. Gallager. Low-Density Parity-Check Codes. MIT Press, Cambridge, MA, 1963.
[8] G. A. Gibson, L. Hellerstein, R. M. Karp, R. H. Katz, and D. A. Patterson. Failure correction techniques for large disk arrays. In Proceedings of International Conference on Architectural Support for Programming Languages and Operating Systems, pages 123–132, Boston, MA, 1989.
[9] J. L. Hafner. HoVer erasure codes for disk arrays. Technical Report RJ 20352, IBM Research, San Jose, CA, 2005.
[10] J. L. Hafner. WEAVER codes: Highly fault-tolerant erasure codes for storage systems. Technical Report RJ 10353, IBM Research, San Jose, CA, 2005.
[11] J. L. Hafner. WEAVER codes: Highly fault-tolerant erasure codes for storage systems. In Proceedings of the Fourth USENIX Conference on File and Storage Technologies, pages 211–224, San Francisco, CA USA, December 2005.
[12] J. L. Hafner, V. Deenadhayalan, KK Rao, and J. A. Tomlin. Matrix methods for lost data reconstruction in erasure codes. In Proceedings of the Fourth USENIX Conference on File and Storage Technologies, pages 183–196, San Francisco, CA USA, December 2005.
[13] T.-D. Han, S.-D. Kim, S.-B. Yang, K.-W. Lee, and S. Chang. Method for storing parity and rebuilding data contents of failed disks in an external storage subsystem and apparatus thereof, December 2000. U. S. Patent 6,158,017.
[14] C. Huang and L. Xu. Star: An efficient coding scheme for correcting triple storage node failures. In Proceedings of the Fourth USENIX Conference on File and Storage Technologies, pages 197–210, December 2005.
[15] M. G. Luby, M. Mitzenmacher, A. Shokrollahi, and D. A. Spielman. Efficient erasure correcting codes. IEEE Transactions on Information Theory, 47:569–584, 2001.
[16] S. Nanda. Method and system for disk fault tolerance in a disk array, April 2004. U. S. Patent Application US 2004/0078642 A1.
[17] J. S. Plank, R. L. Collins, A. L. Buchsbaum, and M. G. Thomason. Small parity-check erasure codes – exploration and observations. In Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05), 2005.
[18] J. S. Plank and M. G. Thomason. A practical analysis of low-density parity-check erasure codes for wide-area storage applications. In Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04), 2004.
[19] I. S. Reed and G. Solomon. Polynomial codes over certain finite fields. Journal of the Society for Industrial and Applied Mathematics, 8:300–304, 1960.
[20] A. Wilner. Multiple drive failure tolerant RAID system, December 2001. U. S. Patent 6,327,672 B1.
[21] L. Xu, V. Bohossian, J. Bruck, and D. G. Wagner. Low-density MDS codes and factors of complete graphs. IEEE Transactions on Information Theory, IT-45:1817–1826, 1999.
[22] L. Xu and J. Bruck. X-code: MDS array codes with optimal encoding. IEEE Transactions on Information Theory, IT-45:272–276, 1999.
[23] G. V. Zaitsev, V. A. Zinovev, and N. V. Semakov. Minimum-check-density codes for correcting bytes of errors. Problems in Information Transmission, 19:29–37, 1983.

---

**Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06)**  
**0-7695-2607-1/06 $20.00 © 2006 IEEE**