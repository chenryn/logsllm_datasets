### 6.2 Robustness Against Evasion Techniques

Defacers can adapt their strategies to keep defacements hidden from DMOS. One common method is to embed illicit content within images, which can be further obfuscated by introducing distortions and noise [48]. However, such evasion techniques do not make the illicit content appear in search results, thereby limiting their impact. Adversaries may also use other evasion tricks, such as targeting specific search engines. For example, defacers might use JavaScript to hide illicit content from all search engines except Google, as the latter can index JavaScript frameworks [2]. 

DMOS, however, is not limited to acquiring web pages solely through crawlers. It can integrate with other web page acquisition channels, such as firewalls, making such evasion techniques less effective.

### 7. Related Work

In this section, we review existing efforts in website defacement detection from three perspectives: defacement detection, black hat SEO investigation, and natural language processing.

#### 7.1 Defacement Detection

Davanzo et al. [25] treat web defacement detection as an anomaly detection problem for web pages. However, their evaluation is based on only 620 hand-picked web pages, which limits its general applicability. Delta [20] designs a framework to detect whether a website change is malicious or benign using clustering. Meerkat [21] takes a visual approach by rendering web pages using headless browsers and applying computer vision techniques to identify malicious content changes. These methods are more suited for detecting politically-motivated defacements, where the visual appearance of websites is deliberately altered, and may not perform as well for stealthy promotional defacements.

The work most closely related to DMOS is [39], which uses the hashing trick to create a hierarchical representation of web documents (e.g., HTML, JavaScript, CSS) and feeds this input to neural networks for general web document classification. However, this approach does not utilize the information carried by HTML tags, making it difficult to distinguish between stealthy defacements and legitimate noise. Additionally, [39] uses web content reported to VirusTotal [5] to train the network. As discussed in Section 4.3, most vendors on VirusTotal fail to detect promotional defacements, which affects the performance of the trained model.

#### 7.2 Black Hat SEO Investigation

Black hat SEO has become a popular channel for advertising illicit goods and services. Wang et al. [44] show that at least 0.48% of Google autocomplete results are polluted. Nektarios et al. [34] construct a list of 218 drug-related keywords for Google search and automatically gather 40,000 malicious search results to quantify the prevalence of search-redirection attacks, especially for unlicensed pharmacies. In a follow-up study, Nektarios et al. [33] conduct a four-year longitudinal investigation to reveal the evolution of attack strategies and technologies. Advanced techniques, such as using jargon, have proven effective in evading detection [42]. Liao et al. [35] develop a semantics-based approach to help search engines detect compromised sites by identifying semantic gaps between malicious keywords and infected sponsored Top-Level Domains (sTLD). In contrast, DMOS supports the detection of promotional defacements across any domain without limiting to specific sTLDs.

#### 7.3 Natural Language Processing

Beyond defacement detection, researchers have made significant progress in natural-language-processing-based text classification, such as BERT [24] and FastText [31]. Our scheme differs from typical document classification tasks, like sentiment analysis, in that we aim to detect active adversaries who try to evade detection by obscuring the semantics of their text. Inspired by the Hierarchical Attention Network [46], we have developed new techniques to encode HTML tag information into the neural network and examine content at hierarchical spatial scales. This allows us to capture local context, resulting in higher accuracy compared to the direct application of state-of-the-art NLP models.

### 8. Conclusion

In this paper, we propose DMOS, a scalable cloud-based detector for promotional website defacements. Using DMOS, we examined 38,526,989 web pages over 7,298 websites, finding that 11% of these sites had been defaced at least once. Our study highlights the pervasiveness of conspiring acts between seekers and promoters of illicit goods and services on the internet. By effectively detecting website defacements early, DMOS significantly raises the bar to mitigate the negative impact of promotional defacements, allowing site owners to quickly remove illicit content and contain damage. The findings from our measurement study also reveal new phenomena in the internet underground ecosystem.

### Acknowledgements and Ethical Considerations

We thank our shepherd Prof. Bimal Viswanath and the anonymous reviewers for their valuable comments, which helped improve the paper. We also thank our colleagues Shangcheng Shi, Zuoye Gong, and Zhiyi Cheng for their assistance. This research is supported in part by the CUHK Project Impact Enhancement Fund (Project#3133292) and the CUHK MobiTeC R&D Fund. For all Chinese websites in our experiments, crawling and detection were authorized by their owners with legal agreements. The crawled pages are kept privately and cannot be shared with the public. We informed the owners of all 824 defaced websites detected in our online experiment and provided them with a complete list of defaced page URLs. All site owners subsequently confirmed our findings, removed the illicit content, and deployed further security measures. For the defacements identified in our English dataset collection process, most affected websites had already removed the illicit content during our experiment. We notified four websites where defacements remained.

### References

[1] Four-corner system, 1995.
[2] Can google properly crawl and index javascript frameworks? A JavaScript SEO experiment. Online, 2017. https://www.onely.com/blog/javascript-seo-experiment/.
[3] Central office notice: Government websites domain policy. Online, 2018. http://www.gov.cn/zhengce/content/2018-09/06/content_5319675.htm.
[4] ssdeep project. Online, 2018. https://ssdeep-project.github.io/ssdeep/index.html.
[5] VirusTotal. Online, 2018. https://www.virustotal.com.
[6] Aho–Corasick algorithm. Online, 2019. https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm.
[7] Baidu URL Security Center. Online, 2019. https://bsb.baidu.com.
[8] China Webmaster. Online, 2019. http://top.chinaz.com/.
[9] Chinese Wiki Corpus. Online, 2019. https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2.
[10] Language model. Online, 2019. https://en.wikipedia.org/wiki/Language_model.
[11] Selenium. Online, 2019. https://www.seleniumhq.org/.
[12] Tencent URL Security Center. Online, 2019. https://urlsec.qq.com.
[13] TensorFlow. Online, 2019. https://www.tensorflow.org/.
[14] TF-IDF. Online, 2019. https://en.wikipedia.org/wiki/Tf%E2%80%93idf.
[15] Exploring Google hacking techniques. Online, 2020. https://securitytrails.com/blog/google-hacking-techniques.
[16] Kafka: A distributed streaming platform. Online, 2020. https://kafka.apache.org/intro.
[17] Sample defacement dataset of English webpages. Online, 2020. http://mobitec.ie.cuhk.edu.hk/DMoS/.
[18] Some example tools for defacement and black hat SEO. Online, 2020. http://www.zylou.cn/hmseo.
[19] Transformers: State-of-the-art natural language processing for PyTorch and TensorFlow 2.0. Online, 2020. https://github.com/huggingface/transformers.
[20] Borgolte, K., Kruegel, C., and Vigna, G. Delta: Automatic identification of unknown web-based infection campaigns. In Proceedings of the 2013 ACM SIGSAC Conference on Computer & Communications Security.
[21] Borgolte, K., Kruegel, C., and Vigna, G. Meerkat: Detecting website defacements through image-based object recognition. In 24th USENIX Security Symposium.
[22] Chen, T., and Guestrin, C. XGBoost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2016), pp. 785–794.
[23] Chung, Y.-J., Toyoda, M., and Kitsuregawa, M. A study of link farm distribution and evolution using a time series of web snapshots. In Proceedings of the 5th International Workshop on Adversarial Information Retrieval on the Web (2009), pp. 9–16.
[24] Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1, pp. 4171–4186.
[25] Davanzo, G., E. M., and Bartoli, A. Anomaly detection techniques for a web defacement monitoring service. In Expert Systems with Applications (2011).
[26] Gesenhues, A. Study: Organic search drives 51% of traffic, social only 5%. Search Engine Land (2014).
[27] Google. Policies for content posted by users on search. Online, 2018. https://support.google.com/websearch/answer/7408270?hl=en.
[28] IMF. The countries with the largest shadow economies. Online, 2017. https://tinyurl.com/x0b0r79y.
[29] John, J. P., Yu, F., Xie, Y., Krishnamurthy, A., and Abadi, M. Deseo: Combating search-result poisoning. In USENIX Security Symposium (2011), pp. 20–35.
[30] Joslin, M., Li, N., Hao, S., Xue, M., and Zhu, H. Measuring and analyzing search engine poisoning of linguistic collisions. In Proceedings-IEEE Symposium on Security and Privacy (2019), IEEE.
[31] Joulin, A., Grave, E., Bojanowski, P., and Mikolov, T. Bag of tricks for efficient text classification. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers (2017), pp. 427–431.
[32] Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., and Soricut, R. ALBERT: A lite BERT for self-supervised learning of language representations. In International Conference on Learning Representations (2019).
[33] Leontiadis, N., Moore, T., and Christin, N. A nearly four-year longitudinal study of search-engine poisoning. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pp. 930–941.
[34] Leontiadis, N., Moore, T., and Christin, N. Measuring and analyzing search-redirection attacks in the illicit online prescription drug trade. In USENIX Security Symposium (2011), vol. 11.
[35] Liao, X., Yuan, K., Wang, X., Pei, Z., Yang, H., Chen, J., Duan, H., Du, K., Alowaisheq, E., Alrwais, S., et al. Seeking nonsense, looking for trouble: Efficient promotional-infection detection through semantic inconsistency search. In 2016 IEEE Symposium on Security and Privacy (SP), pp. 707–723.
[36] Maggi, F., Balduzzi, M., Flores, R., Gu, L., and Ciancaglini, V. Investigating web defacement campaigns at large. In Proceedings of the 2018 on Asia Conference on Computer and Communications Security.
[37] Mikolov, T., Chen, K., Corrado, G., and Dean, J. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013).
[38] Pennington, J., Socher, R., and Manning, C. GloVe: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (2014), pp. 1532–1543.
[39] Saxe, J., Harang, R., Wild, C., and Sanders, H. A deep learning approach to fast, format-agnostic detection of malicious web content. In 2018 IEEE Security and Privacy Workshops (SPW), pp. 8–14.
[40] SEOMoz. Google algorithm change history. Online, 2018. https://moz.com/google-algorithm-change.
[41] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. Attention is all you need. In Advances in Neural Information Processing Systems (2017), pp. 5998–6008.
[42] Wang, D. Y., Der, M., Karami, M., Saul, L., McCoy, D., Savage, S., and Voelker, G. M. Search+ seizure: The effectiveness of interventions on SEO campaigns. In Proceedings of the 2014 Conference on Internet Measurement Conference, pp. 359–372.
[43] Wang, D. Y., Savage, S., and Voelker, G. M. Cloak and dagger: dynamics of web search cloaking. In Proceedings of the 18th ACM Conference on Computer and Communications Security (2011), pp. 477–490.
[44] Wang, P., Mi, X., Liao, X., Wang, X., Yuan, K., Qian, F., and Beyah, R. Game of missuggestions: Semantic analysis of search-autocomplete manipulations. In 25th Annual Network & Distributed System Security Symposium (NDSS) (2018).
[45] Yang, H., Ma, X., Du, K., Li, Z., Duan, H., Su, X., Liu, G., Geng, Z., and Wu, J. How to learn Klingon without a dictionary: Detection and measurement of black keywords used by the underground economy. In 2017 IEEE Symposium on Security and Privacy (SP), pp. 751–769.
[46] Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., and Hovy, E. Hierarchical attention networks for document classification. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1480–1489.
[47] Yuan, K., Lu, H., Liao, X., and Wang, X. Reading thieves' cant: automatically identifying and understanding dark jargons from cybercrime marketplaces. In 27th USENIX Security Symposium (2018), pp. 1027–1041.
[48] Yuan, K., Tangy, D., Liao, X., Wang, X., Feng, X., Chen, Y., Sun, M., Lu, M., and Zhang, K. Stealthy porn: Understanding real-world adversarial images for illicit online promotion. In Proceedings-IEEE Symposium on Security and Privacy (2019).
[49] Yujian, L., and Bo, L. A normalized Levenshtein distance metric. IEEE Transactions on Pattern Analysis and Machine Intelligence 29, 6 (2007), 1091–1095.

### A. Collecting Alarming Keywords

Compared to illicit keywords, developing alarming keywords is relatively straightforward. While defacers often obfuscate keywords, many obfuscated jargons share the same stem (i.e., commonly-used sequence). For example, there are many illicit phrases derived from "mark six," such as "buy mark six in Hong Kong" or "Hong Kong mark six." However, the stem "mark six" is seldom changed. Thus, the number of stems is limited, making them suitable as alarming keywords. Specifically, we build the alarming keywords as follows:

1. **Build a Dictionary of Stop Words**: We create a dictionary of stop words (e.g., "the," "Hong Kong") that are used in the legitimate dataset as well.
2. **Remove Stop Words**: For each phrase, we remove the stop words. For example, "buy mark six in Hong Kong" becomes "buy mark six."
3. **Extract n-gram Sequences**: We extract all n-gram sequences where \( n \) is larger than a threshold \( \theta_n \) (set to 2). For example, "buy mark six" is split into "buy mark," "mark six," and "buy mark six."
4. **Compute Frequency Differences**: For each sequence, we compute its frequency in the defaced and legitimate datasets, \( f_d \) and \( f_l \), respectively.
5. **Include Alarming Keywords**: Finally, we compute the frequency difference \( f_d - f_l \) for all substrings, starting from the shortest one. If the difference is more than a threshold \( \theta_{\text{alarm}} \), we include this sequence as an alarming keyword.

Note that we will extract at least one sequence from every illicit phrase to ensure the completeness of alarming keywords.