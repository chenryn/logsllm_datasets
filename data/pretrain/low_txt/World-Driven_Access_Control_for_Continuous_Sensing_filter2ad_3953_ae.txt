### Tracking Objects and Policy Communication

Today, objects can be tracked using various identifiers such as RFID, Bluetooth IDs, and MAC addresses. However, this document does not address the broader implications of such tracking, considering it out of scope.

World-driven access control can utilize diverse mechanisms to communicate policies. We have implemented and evaluated several methods for explicitly communicating these policies, and we encourage further research into other approaches. Our design is flexible enough to accommodate implicitly communicated policies, which may rely on advanced computer vision (e.g., recognizing sensitive locations as in PlaceAvoider [39]) or inferred from natural human behavior (e.g., closing a door or whispering). Other relevant works include Legion:AR [21], which uses a panel of humans to recognize activities, and studies on predicting the cost of interruption from sensor data [17]. To enhance policy detection accuracy, systems can incorporate additional policy-specific sensors, such as low-power cameras, which are dedicated to sensing policies rather than user-facing interactions [23].

### Additional Related Work

We have discussed prior works that consider bystander privacy, allowing individuals to opt out using visual [36] or digital markers [7, 16]. TagMeNot [8] proposes QR codes for opting out of photo tagging. These designs depend on compliant recording devices or vendors. Other systems aim to prevent recording by uncooperative devices, for example, by flashing directed light at cameras [32]. Recent studies have examined bystander reactions to augmented reality devices and surveyed design axes for privacy-mediation approaches [11]. Additionally, the privacy of device users has been a concern, with Starner identifying it as a primary challenge for wearable computing [38]. Although wearable devices can improve security (e.g., through location-based or device-based access control as in Grey [5]), they can also reveal sensitive information. This motivates the need for privacy-preserving location-based access control [4]. In our work, we assume that the device and system are trustworthy.

Other researchers have restricted applications' access to perceptual data. Darkly [19] integrates privacy protection into OpenCV, and the "recognizer" abstraction [18] helps limit applications' access to objects in a sensor feed. We build on these ideas. PlaceAvoider [39] identifies images captured in sensitive locations and withholds them from applications. PiBox [22] restricts applications from secretly leaking private data but provides weak guarantees when users explicitly share it. Our approach helps users avoid accidentally sharing sensitive content with untrusted applications.

### Conclusion

Continuous sensing applications on platforms like smartphones, Google Glass, and XBox Kinect present significant access control challenges that current techniques do not fully address. We introduced world-driven access control, where real-world objects specify per-application privacy policies. This approach aims to manage permissions at the granularity of objects rather than entire sensor streams, without explicit user involvement. A trusted platform detects these policies in the environment and automatically adjusts each application's "view" accordingly.

We built an end-to-end prototype of world-driven access control, addressing key challenges. We introduced passports to ensure policy authenticity and allow dynamic system extension. We mitigated detection inaccuracies by combining multiple policy communication techniques and introducing memory into policies. Finally, we explored the trade-offs between policy accuracy and performance, and between broadcast policies and privacy.

Our prototype enforces many policies, each expressed with modest developer effort, with reasonable accuracy even using today's technologies and off-the-shelf algorithms. Our experiences suggest that world-driven access control can reduce the user's permission management burden while preserving functionality and protecting privacy. Beyond exploring a new design point for access control in continuous sensing, this work represents a step toward integrating physical objects into a virtual world; we believe our explorations lay the groundwork for future research in this area.

### Acknowledgements

We thank Greg Akselrod, Ray Cheng, Lydia Chilton, Jon Howell, Jaeyeon Jung, Benjamin Livshits, Eyal Ofek, Matthai Philipose, Stuart Schechter, Will Scott, Alex Takakuwa, and Margus Veanes for valuable discussions and feedback on earlier drafts. We also thank Weidong Cui for his help with evaluation traces. This work was done while the first and fourth authors were visiting Microsoft Research. This work is supported in part by a National Science Foundation Graduate Research Fellowship under Grant DGE-0718124 and a Microsoft Research PhD Fellowship.

### References

[1] ZXing.Net. http://zxingnet.codeplex.com/.

[2] Abrash, M. Latency – the sine qua non of AR and VR, 2012. http://bit.ly/UbrBL0.

[3] Ada Initiative. Another way to attract women to conferences: photography policies, 2013. http://bit.ly/1bc3x3O.

[4] Ardagna, C. A., Cremonini, M., di Vimercati, S. D. C., and Samarati, P. Privacy-enhanced Location-based Access Control. In Handbook of Database Security. 2008, pp. 531–552.

[5] Bauer, L., Garriss, S., McCune, J. M., Reiter, M. K., Rouse, J., and Rutenbar, P. Device-enabled authorization in the Grey system. In International Conference on Information Security (2005).

[6] Borisov, N., and Brewer, E. A. Active certificates: A framework for delegation. In Network and Distributed System Security Symposium (NDSS) (2002).

[7] Brassil, J. Technical Challenges in Location-Aware Video Surveillance Privacy. In Protecting Privacy in Video Surveillance, A. Senior, Ed. 2009, pp. 91–113.

[8] Cammozzo, A. TagMeNot. http://tagmenot.info/.

[9] Clark, J., and van Oorschot, P. C. SoK: SSL and HTTPS: Revisiting past challenges and evaluating certificate trust model enhancements. IEEE Symposium on Security & Privacy (2013).

[10] CNXSoft. Qualcomm fast computer vision SDK, 2011. http://bit.ly/rUY7Pa.

[11] Denning, T., Dehlawi, Z., and Kohno, T. In situ with bystanders of augmented reality glasses: Perspectives on recording and privacy-mediating technologies. In ACM CHI (2014).

[12] Felt, A. P., Ha, E., Egelman, S., Haney, A., Chin, E., and Wagner, D. Android permissions: User attention, comprehension, and behavior. In Symposium on Usable Privacy and Security (SOUPS) (2012).

[13] Geambasu, R., Levy, A. A., Kohno, T., Krishnamurthy, A., and Levy, H. M. Comet: An active distributed key-value store. In USENIX OSDI (2010).

[14] Google. Google Glass. http://glass.google.com/.

[15] Gray, R. The places where Google Glass is banned, Dec. 2013. http://www.telegraph.co.uk/technology/google/10494231/The-places-where-Google-Glass-is-banned.html.

[16] Halderman, J. A., Waters, B., and Felten, E. W. Privacy Management for Portable Recording Devices. In Workshop on Privacy in Electronic Society (2004).

[17] Hudson, S., Fogarty, J., Atkeson, C., Avrahami, D., Forlizzi, J., Kiesler, S., Lee, J., and Yang, J. Predicting human interruptibility with sensors: a wizard of oz feasibility study. In ACM CHI (2003).

[18] Jana, S., Molnar, D., Moshchuk, A., Dunn, A., Livshits, B., Wang, H. J., and Ofek, E. Enabling Fine-Grained Permissions for Augmented Reality Applications with Recognizers. In USENIX Security Symposium (2013).

[19] Jana, S., Narayanan, A., and Shmatikov, V. A Scanner Darkly: Protecting User Privacy from Perceptual Applications. In IEEE Symposium on Security and Privacy (2013).

[20] Kotadia, M. Jamming device aims at camera phones, 2003. http://cnet.co/HEvS8b.

[21] Lasecki, W., Song, Y. C., Kautz, H., and Bigham, J. Real-time crowd labeling for deployable activity recognition. In Computer Supported Cooperative Work (CSCW) (2013).

[22] Lee, S., Wong, E., Goel, D., Dahlin, M., and Shmatikov, V. PiBox: A platform for privacy preserving apps. In USENIX Symposium on Networked Systems Design and Implementation (NSDI) (2013).

[23] LiKamWa, R., Priyantha, B., Philipose, M., Zhong, L., and Bahl, P. Energy characterization & optimization of image sensing toward continuous mobile vision. In MobiSys (2013).

[24] Lioy, A., and Ramunno, G. Trusted computing. In Handbook of Information and Communication Security, Stavroulakis and Stamp, Eds. 2010, pp. 697–717.

[25] Marlinspike, M. Convergence. http://convergence.io/.

[26] Meta. Spaceglasses. http://spaceglasses.com.

[27] Microsoft. App. Domains. http://msdn.microsoft.com/en-us/library/2bh4z9hs(v=vs.110).aspx.

[28] Microsoft. Creating your own code access permissions, 2013. http://bit.ly/HFzDKD.

[29] O’Brien, K. Swiss Court Orders Modifications to Google Street View, 2012. http://nyti.ms/L3cdNZ.

[30] Panzarino, M. Inside the revolutionary 3D vision chip at the heart of Google’s Project Tango phone, Feb. 2014. http://tcrn.ch/1fkCuWK.

[31] Paruchuri, J. K., Cheung, S.-C. S., and Hail, M. W. Video data hiding for managing privacy information in surveillance systems. EURASIP Journal on Info. Security (Jan. 2009), 7:1–7:18.

[32] Patel, S. N., Summet, J. W., and Truong, K. N. BlindSpot: Creating Capture-Resistant Spaces. In Protecting Privacy in Video Surveillance, A. Senior, Ed. 2009.

[33] Priyantha, N. B., Miu, A. K. L., Balakrishnan, H., and Teller, S. J. The cricket compass for context-aware mobile applications. In Mobile Computing and Networking (2001).

[34] Quest Visual. WordLens: See the world in your language. http://questvisual.com/.

[35] Roesner, F., Kohno, T., Moshchuk, A., Parno, B., Wang, H. J., and Cowan, C. User-driven access control: Rethinking permission granting in modern operating systems. In IEEE Symposium on Security and Privacy (2011).

[36] Schiff, J., Meingast, M., Mulligan, D. K., Sastry, S., and Goldberg, K. Y. Respectful Cameras: Detecting Visual Markers in Real-Time to Address Privacy Concerns. In International Conference on Intelligent Robots and Systems (2007).

[37] Shotton, J., Fitzgibbon, A., Cook, M., Sharp, T., Finocchio, M., Moore, R., Kipman, A., and Blake, A. Real-time human pose recognition in parts from a single depth image. In Computer Vision & Pattern Recognition (2011).

[38] Starner, T. The Challenges of Wearable Computing: Part 2. IEEE Micro 21, 4 (2001), 54—67.

[39] Templeman, R., Korayem, M., Crandall, D., and Kapadia, A. PlaceAvoider: Steering first-person cameras away from sensitive spaces. In Network and Distributed System Security Symposium (NDSS) (2014).

[40] Tennenhouse, D. L., Smith, J. M., Sincoskie, W. D., Wetherall, D. J., and Minden, G. J. A Survey of Active Network Research. IEEE Communications 35 (1997), 80–86.

[41] The 5 Point Cafe. Google Glasses Banned, Mar. 2013. http://the5pointcafe.com/google-glasses-banned/.

[42] Tom Simonite. Bringing cell-phone location-sensing indoors. http://bit.ly/TVyMEx.

[43] Wendlandt, D., Andersen, D. G., and Perrig, A. Perspectives: Improving SSH-style host authentication with multi-path probing. In USENIX Security Symposium (2008).

[44] Zimmermann, P. R. The Official PGP User’s Guide. MIT Press, Cambridge, MA, USA, 1995.

### Real-World Policies

We summarize a sample set of real-world locations with sensor privacy policies (Figure 10) that would benefit from world-driven access control. These scenarios motivate the incentive of establishments to install world-driven policies.

- **Mercury**: Ask before taking a photo.
- **5Point Cafe**: No photos, no Google Glass.
- **Goodwill**: No photos within 15 feet of dressing rooms.
- **Local Gym**: No cell phones in locker rooms.
- **AdaCamp SF**: Provide notice before taking a photo.
- **Open Source Bridge**: Ask before taking a photo.
- **Sirens**: No photos during sessions.
- **WisCon**: Ask before taking a photo.
- **Street View**: Blur sensitive areas, no photos over fences.

These policies can be captured by our framework, enabling establishments to enforce their specific privacy requirements effectively.