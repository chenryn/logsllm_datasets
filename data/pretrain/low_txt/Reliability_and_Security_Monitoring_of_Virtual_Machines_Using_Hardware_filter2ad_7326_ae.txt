### Ninja Sleep State and Detection Evasion

To determine the duration of Ninja's sleep state and the timing of the next check, we measured the interval and checking time. This information allowed us to launch transient attacks that could evade detection. However, this strategy was ineffective against H-Ninja, as it does not generate a `/proc` file in the target VM. Table III presents the results of this method, with each interval sampled 30 times.

### Combined Rootkit and Privilege Escalation Attacks

In a more sophisticated attack, we combined a privilege escalation exploit with a rootkit capable of hiding processes. After escalating the terminal, we immediately deployed the rootkit to prevent Ninja from detecting the presence of the terminal, thereby bypassing both versions of Ninja.

### Spamming Attacks

We increased the execution time of the function that iterates over the process list by launching a large number of valid processes along with one privilege-escalated process. The goal was to extend the scanning time, allowing the escalated process to complete before the scan reached it. It is important to note that a blocking H-Ninja is protected against this type of attack. An illustration of this method is provided at the bottom of Fig. 6.

### Active Monitoring with HT-Ninja

To demonstrate the benefits of HyperTap's active monitoring mechanism, we compared the detectability of three versions of Ninja (O-Ninja, H-Ninja, and HT-Ninja) against real exploits, using the attack strategies described above. Both O-Ninja and H-Ninja are vulnerable to DKOM rootkits, such as SucKIT, because they rely solely on OS invariants.

Our experiments showed that O-Ninja, with a 0-second checking interval, was quickly defeated by a privilege escalation exploit (CVE-2013-1763) combined with spamming and a rootkit. The attack was executed as follows: (i) creating multiple idle processes; (ii) running the exploit code to grant root privileges to the current process; and (iii) installing the rootkit with root privileges to remove the escalated process from the process list. We repeated the attack 300 times, and it took approximately 4 ms on an Intel(R) Core(TM)2 Duo CPU E8400 3GHz CPU. Without extra processes, O-Ninja detected about 10% of the attacks. With 100 idle processes, the detection probability dropped to single-digit percentages (2-3%). With 200 or more idle processes, O-Ninja failed to detect any attacks, except for a few outliers (â‰ˆ 1%).

For H-Ninja, we used the same combination of privilege escalation and rootkit. The attack was also successful, as H-Ninja did not detect the presence of the rootkit. 

Since HT-Ninja uses active monitoring, it was able to detect all attacks in all tested scenarios.

### Limitations of HT-Ninja

A key limitation of HT-Ninja, as well as O-Ninja and H-Ninja, is their inability to detect privilege escalation attacks within the context of "white-listed" processes. These processes, many of which are setuid programs, are ignored by Ninja. An attack that compromises and executes malicious code within the context of a white-listed process would not be detected.

### Performance Evaluation

We conducted experiments to measure the performance overhead of individual HyperTap auditors and the combined overhead of running multiple auditors. We used the UnixBench performance benchmark, enabling each auditor individually and then all three auditors simultaneously. The target VM was a SUSE 11 Linux VM with 2 vCPUs and 1 GiB of RAM. The host computer ran SUSE 11 Linux and the KVM hypervisor, equipped with an 8-core Intel i5 3.07 GHz processor and 8 GiB of RAM. The results are illustrated in Fig. 7. The baseline is the execution time when running the workloads in the VM without HyperTap integrated, and the reported numbers are the average of five runs of the workloads.

In most cases, the performance overhead of running all three auditors simultaneously was only slightly higher than that of running the slowest auditor, HT-Ninja, individually. This overhead was substantially lower than the sum of the individual overheads of all auditors, demonstrating the benefits of HyperTap's unified logging mechanism.

For Disk I/O and CPU-intensive workloads, all three auditors together produced less than 5% and 2% performance losses, respectively. The Disk I/O-intensive workloads incurred more overhead than CPU-intensive workloads due to the generation of more VM Exit events, which triggered monitoring code.

For context switching and system call micro-benchmarks, all three auditors together induced about 10% (or less) and 19% performance losses, respectively. These micro-benchmarks were designed to measure the performance of specific operations without useful processing and do not necessarily represent the performance overhead of general applications. The relatively high overhead was caused by the HyperTap routines enabled for logging these benchmarked operations. Since only HT-Ninja needs to log system calls, it was the primary source of the overhead in the system call micro-benchmark case.

### Conclusions

This paper presents principles for unifying RnS (Reliability and Security) monitoring. We identify the boundary dividing the logging and auditing phases in monitoring processes, allowing us to develop dependable logging mechanisms. We demonstrate the need for an isolated root of trust and active monitoring to support a wide variety of RnS monitors. We applied these principles in developing HyperTap, a framework that provides unified logging based on hardware invariants to safeguard VM environments. The feasibility of the framework was demonstrated through the implementation and evaluation of three monitors: Guest OS Hang Detection, Hidden RootKit Detection, and Privilege Escalation Detection. In all cases, the use of architectural invariants was central to the high quality and performance observed in the experiments. We presented additional analysis to enable the development of other reliability and security monitors on top of the HyperTap framework.

### Acknowledgments

This material is based upon work supported in part by the National Science Foundation under Grant No. CNS 10-18503 CISE, by the Army Research Office under Award No. W911NF-13-1-0086, by the National Security Agency (NSA) under Award No. H98230-14-C-0141, by the Air Force Research Laboratory and the Air Force Office of Scientific Research under agreement No. FA8750-11-2-0084, by an IBM faculty award, and by Infosys Corporation. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the National Science Foundation or other organizations.

### References

[References listed here]

---

This version of the text is more structured and professional, with improved clarity and coherence.