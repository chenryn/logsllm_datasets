### Survey Questions and Data Analysis

The survey questions are an adaptation of the NASA Task Load Index (TLX) designed to assess participants' perceived effort during the tasks. This data helps us understand the subjective effort perceived by participants and relate it to their physiological responses and objective success in understanding the programs. Table III summarizes the data collected from these surveys.

- **Objective Evaluation (OE):** Captures the average correctness of the understanding of the programs, where 0 indicates complete failure in understanding the code, and 1 indicates complete success.
- **Mental Effort (ME), Time Pressure (TP), and Discomfort (DI):** Collected using a NASA-TLX inquiry (second survey). All values range from 0 to 1, and both the average and standard deviation values are included.

The results from pupillography are consistent with the NASA-TLX results, suggesting that pupillography can provide real-time measurements of programmers' effort and cognitive load during software development activities. The subjective effort measured by NASA-TLX, as well as the biofeedback pupillography results, show that mental effort does not correlate well with complexity metrics. For example, the cyclomatic complexity of program C1 is higher than C2, but both the pupillography and NASA-TLX indicate that participants perceive C2 as almost as complex as C3. This finding aligns with the known limitations of using complexity metrics as predictors of programmers' effort in many scenarios.

### Utilization Perspectives and Future Work

Our study demonstrates that pupillography is a promising biofeedback mechanism, providing accurate indications of programmers' mental effort and cognitive load. The experiments also included eye-tracking data (among other sensors), which allowed us to identify the exact lines of code participants were looking at during the experiment. The next step is to analyze the pupillography data at a low level of code granularity, combining variations in pupil size with the specific lines of code identified by eye tracking. It is worth noting that the eye-tracking device is the same one used to measure pupil size, maintaining the non-intrusive nature of the method.

Future applications of pupillography, combined with eye tracking, will be key in measuring programmers' cognitive stress and mental effort in real time while they produce or read code for software inspections. Metadata about the programmers' cognitive state while dealing with a given code unit can be recorded and linked to the related program code lines, enabling new visionary features such as:

- **Online Advice:** Ranging from simple warnings about code areas that may need a second look to more sophisticated support scenarios that consider biofeedback metadata in conjunction with code complexity and the programmer's history of previous bugs (we call this "alter-pair programming").
- **Improved Models:** Enhanced bug density estimation and software risk analysis models using code complexity metrics augmented with biofeedback metadata that shows how complexity is actually perceived by each programmer.
- **New Testing Approaches:** Biofeedback-driven testing methods that use meta-information about the programmers' cognitive and emotional states, combined with traditional complexity metrics, to guide testing efforts to code units representing higher bug risk.
- **Programmer-Friendly IDEs:** Integrated development environments that automatically warn or enforce resting moments when signs of fatigue and mental strain indicate that both code quality and the programmer's mental well-being are at risk.
- **Optimized Training Needs:** Creation of individual programmer profiles to help define training plans based on biofeedback metadata associated with each programmer.

It is clear that pupillography should be complemented with other types of low-intrusive sensors, such as heart rate variability (HRV). A deeper understanding of error mechanisms at the neuroscience level is also crucial to reduce noise and increase accuracy. The current results on the use of pupillography to measure programmers' mental effort and cognitive load suggest promising future applications in software development and testing. The availability of low-cost eye-tracking devices, particularly those used in the video game industry, opens new possibilities for the rapid adoption of pupillography in software engineering.

### Conclusions

This practical experiment report presents new evidence showing that pupillography is an effective approach to measure programmers' mental effort and cognitive load in code comprehension tasks, such as in code inspection scenarios, as well as during general code development activities. The non-intrusive nature of pupillography and its ease of integration into current software development environments suggest that it could be adopted as a biofeedback mechanism in the near future.

The results from the observational study involving 30 experienced programmers show that the mental effort and cognitive load measured using pupillography are consistent with the subjective perception of complexity and load recorded by the programmers using the NASA-TLX task load index. As expected, the analysis based on complexity metrics deviates from both the pupillography and NASA-TLX results.

The paper concludes with a discussion of future perspectives for the utilization of pupillography in the broader context of Biofeedback Augmented Software Engineering (BASE).

### Acknowledgment

The authors would like to thank the volunteers who participated in the experiments. This work was partially funded by the BASE project, POCI - 01-0145 - FEDER- 031581.

### References

[1] S. Shah, M. Morisio, M. Torchiano, “The Impact of Process Maturity on Defect Density,” ACM-IEEE International Symposium on Empirical Software Engineering and Measurement, 2012.

[2] N. Honda, S. Yamada, “Empirical Analysis for High Quality SW Development,” American Journal Op. Research, 2012.

[3] Steve McConnell, “Code Complete: A Practical Handbook of Software Construction,” Microsoft Press, 2004.

[4] J. Durães and H. Madeira, “Emulation of SW Faults: A Field Data Study and a Practical Approach,” IEEE Transactions on SW Engineering, vol. 32, no. 11, pp. 849-867, November 2006.

[5] J. Christmansson and R. Chillarege, "Generation of an Error Set that Emulates SW Faults," Proc. of the 26th International Fault Tolerant Computing Symposium, FTCS-26, Sendai, Japan, 1996.

[6] A. Fuqun Huang, B. Bin Liu, and C. Bing Huang, “A Taxonomy System to Identify Human Error Causes for Software Defects,” 18th ISSAT International Conference on Reliability and Quality in Design, 2012.

[7] Fuqun Huang, “Human Error Analysis in Software Engineering,” chapter of the book “Theory and Application on Cognitive Factors and Risk Management,” F. Felice and A. Petrillo Editors, IntechOpen, 2017.

[8] James Reason, “Human Error,” Cambridge University Press, 1990.

[9] V. Anu, et al., “Using A Cognitive Psychology Perspective on Errors to Improve Requirements Quality: An Empirical Investigation,” IEEE 27th International Symposium on Software Reliability Engineering, 2016.

[10] N. Peitek, J. Siegmund, et al., “A Look into Programmers' Heads,” IEEE Transactions on Software Engineering, August, 2018.

[11] B. Floyd, T. Santander, and W. Weimer, “Decoding the Representation of Code in the Brain: An fMRI Study of Code Review and Expertise,” ICSE 2017, pp 175–186, Piscataway, NJ, USA, 2017.

[12] T. Nakagawa, Y. Kamei, et al., “Quantifying Programmers’ Mental Workload During Program Comprehension Based on Cerebral Blood Flow Measurement: A Controlled Experiment,” Proc. of ICSE 2014.

[13] J. Castelhano, I. C. Duarte, C. Ferreira, J. Durães, H. Madeira, and M. Castelo-Branco, “The Role of the Insula in Intuitive Expert Bug Detection in Computer Code: An fMRI Study,” Brain Imaging and Behavior, 2018.

[14] R. Couceiro, G. Duarte, J. Durães, J. Castelhano, C. Duarte, C. Teixeira, Miguel C. Branco, P. Carvalho, H. Madeira, “Biofeedback augmented software engineering: monitoring of programmers' mental effort,” International Conference on Software Engineering, New Ideas and Emerging Results, ICSE 2019 (accepted).

[15] S. C. Müller and T. Fritz, “Using (Bio)Metrics to Predict Code Quality Online,” Department of Informatics, University of Zurich, Switzerland, Proc. of 38th IEEE ICSE, 2016.

[16] S. Sirois and J. Brisson, "Pupillometry," Wiley Interdisciplinary Reviews: Cognitive Science, vol. 5, pp. 679-692, 2014.

[17] J. Beatty and B. Lucero-Wagoner, "The pupillary system," Handbook of psychophysiology, vol. 2, 2000.

[18] E. H. Hess and J. M. Polt, "Pupil size in relation to mental activity during simple problem-solving," Science, vol. 143, pp. 1190-1192, 1964.

[19] D. Kahneman and J. Beatty, "Pupil diameter and load on memory," Science, vol. 154, pp. 1583-1585, 1966.

[20] M. L. H. Võ, et al., "The coupling of emotion and cognition in the eye: Introducing the pupil old/new effect," Psychophysiology, vol. 45, pp. 130-140, 2008.

[21] J. Beatty, "Task-evoked pupillary responses, processing load, and the structure of processing resources," Psychological bulletin, vol. 91, 1982.

[22] H. Lüdtke, B. Wilhelm, M. Adler, F. Schaeffel, and H. Wilhelm, "Mathematical procedures in data recording and processing of pupillary fatigue waves," Vision research, vol. 38, pp. 2889-2896, 1998.

[23] M. Nakayama and Y. Shimizu, "Frequency analysis of task evoked pupillary response and eye-movement," in Proceedings of the 2004 symposium on Eye tracking research & applications, pp. 71-76, 2004.

[24] A. Murata and H. Iwase, "Evaluation of mental workload by fluctuation analysis of pupil area," in Engineering in Medicine and Biology Society, 1998. Proceedings of the 20th Annual International Conference of the IEEE, pp. 3094-3097, 1998.

[25] V. Peysakhovich, M. Causse, S. Scannella, and F. Dehais, "Frequency analysis of a task-evoked pupillary response: Luminance-independent measure of mental effort," International Journal of Psychophysiology, vol. 97, pp. 30-37, 2015.

[26] O. Salem, L. Yaning, and A. Mehaoua, "A lightweight anomaly detection framework for medical wireless sensor networks," in Wireless Comm. and Networking Conference (WCNC), 2013 IEEE pp. 4358-4363, 2013.

[27] D. Kondrashov and M. Ghil, "Spatio-temporal filling of missing points in geophysical data sets," Nonlinear Processes in Geophysics, vol. 13, pp. 151-159, 2006.

[28] R. Sassi, V. D. Corino, and L. T. Mainardi, "Analysis of surface atrial signals: time series with missing data?," Annals of biomedical engineering, vol. 37, pp. 2082-2092, 2009.

[29] F. Onorati, M. Mauri, V. Russo, and L. Mainardi, "Reconstruction of pupil dilation signal during eye blinking events," in Proceeding of the 7th International Workshop on Biosignal Interpretation, pp. 117-120, 2012.

[30] A. Eleuteri, A. C. Fisher, D. Groves, and C. J. Dewhurst, "An efficient time-varying filter for detrending and bandwidth limiting the heart rate variability tachogram without resampling: MATLAB open-source code and implementation," Computational and mathematical methods in medicine, vol. 2012, 2012.

[31] M. Malik, "Heart rate variability: Standards of measurement, physiological interpretation, and clinical use," European Heart Journal, vol. 17, pp. 354–381, 1996.

[32] J.P. Burg, "Maximum Entropy Spectral Analysis," Proceedings of the 37th Meeting of the Society of Exploration Geophysicists, 1967.

[33] F. M. Villalobos-Castaldi, J. Ruiz-Pinales, N. C. K. Valverde, and M. Flores, "Time-frequency analysis of spontaneous pupillary oscillation signals using the Hilbert-Huang transform," Biomedical Signal Processing and Control, vol. 30, pp. 106-116, 2016.