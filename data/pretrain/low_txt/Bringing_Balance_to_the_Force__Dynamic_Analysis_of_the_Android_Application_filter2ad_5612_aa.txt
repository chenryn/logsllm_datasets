# Title: Bringing Balance to the Force: Dynamic Analysis of the Android Application Framework

## Authors:
- Abdallah Dawoud
- Sven Bugiel

### Affiliation:
CISPA Helmholtz Center for Information Security

### Contact:
- Abdallah Dawoud: abdallah.dawoud@cispa.saarland
- Sven Bugiel: bugiel@cispa.saarland

---

## Abstract

The Android application framework is crucial for protecting users' private data and maintaining system integrity. Consequently, it has been the subject of various studies that have analyzed its security policy and enforcement. These studies have uncovered several security issues, including incomplete documentation, permission re-delegation within the framework, and inconsistencies in access control. However, most of these studies have relied on static code analysis, which provides a one-sided view and inherits the limitations and drawbacks of static analysis when applied to the vast and complex codebase of the application framework.

The performance of different security applications, such as malware classification and least-privileged apps, depends on the results of these analyses. However, these applications are currently affected by imprecise and incomplete results due to the imbalanced analysis methodology. To complement and refine this methodology, we introduce dynamic analysis of the application framework and demonstrate its necessity for improving the quality of prior results and advancing the field.

We apply our solution, called DYNAMO, to four prominent use-cases from the literature and take a synoptical view of the results. This allows us to verify, refute, and extend the existing results of prior static analysis solutions. Through the manual investigation of the root causes of discrepancies, we draw new insights and expert knowledge that can be valuable in improving both static and dynamic testing of the application framework.

---

## 1. Introduction

Android provides apps with rich features such as location tracking, taking pictures, sensing, and access to managed user data. These features are offered to app developers through Android’s application framework API and are implemented by system services and system apps. The application framework is responsible for controlling access to system resources and user data, playing a crucial role in protecting system integrity and user privacy. Access control is based on the privileges (permissions), identity, or other attributes of calling processes.

However, the application framework has continuously grown over various Android releases and has become a massive codebase, further extended and modified by OEMs for their own purposes. As a result, the framework has become less transparent, and the correct enforcement of security policies is harder to judge. This problem is exemplified by the seemingly simple task of determining which API of the application framework is guarded by which security conditions (i.e., a permission mapping), which remains unsatisfactorily solved.

Over the last decade, Android’s application framework has been the target of ongoing research to analyze and model the complex security policy protecting the APIs of system services. The modeled policy has been central to research and industrial applications, assisting developers in writing least-privileged apps, detecting malware and over-privileged apps, identifying vulnerabilities in the application framework itself, and other use-cases. The significance of a complete and sound modeling of the security policy enforced in Android’s application framework is underscored by the consequences of lacking such a model, including over-privileged apps, misclassified apps or malware, unclear consequences of OEM modifications, and mistakes in the default security policy.

Despite the initial use of dynamic analysis by Porter Felt et al. [20], subsequent solutions have exclusively relied on static analysis. While static analysis tools like Wala [3] and Soot [50] offer high code coverage, they also have well-known limitations, especially when applied to a massive, complex codebase like the application framework. These limitations include over-approximation, simplification of analysis, and inefficiency in bridging IPC. Given the lack of a ground truth for the security policy in Android and the absence of a systematic approach for verifying static analysis results at scale, it is challenging to judge the accuracy and completeness of these results.

Inspired by software engineering practices, we show that combining static and dynamic analysis should be the natural next step in analyzing Android’s pivotal application framework. The concrete challenge is that while there exist well-established static analysis tools, no proper solution for dynamically testing and modeling the security policy of the application framework exists. The last dynamic solution [20] is obsolete and technically as well as conceptually limited.

### Our Contributions

1. **Dynamic Testing Tool (DYNAMO):** To address the gap caused by the absence of a dynamic testing tool, we introduce DYNAMO. DYNAMO is designed to:
   - Analyze the security policy of the application framework for different versions of Android.
   - Revisit and validate the existing results of static analysis tools.
   - Use well-known techniques of dynamic testing and fuzzing (e.g., runtime instrumentation, feedback-driven testing) to study the security policy of the application framework.
   - Complement the current methodology that has been tipped towards static analysis.
   - Enable the community to reproduce and extend our results by open-sourcing our tool and results [16].

2. **Reproduction and Extension of Prior Results:** We use DYNAMO to reproduce, extend, and verify the results of prior works for building permission mappings [12], [5], [11], discovering permission re-delegation vulnerabilities [29], and detecting inconsistencies in the security policy of two Android versions [47]. We further use a permission mapping built by DYNAMO for the latest Android release to assess the correctness and completeness of permission annotations in Android’s developer documentation. DYNAMO’s results have an immediate security impact and an implicit impact through more trustworthy permission mappings for a wide range of dependent security applications on Android.

3. **Root Cause Analysis and Feedback:** Our root cause analysis of the discrepancies between existing results and our dynamic analysis results provides valuable feedback to the designers of both static and dynamic testing tools. We highlight implementation and approach-inherent shortcomings in existing tools based on static analysis and measure the negative impact of these shortcomings on previous results. We contribute new insights that help better understand how system services are interconnected and protected, adding crucial contextual information about access control enforcement.

DYNAMO clearly improves the status quo. Specifically, our evaluation of the permission mapping by Arcade [5]—the latest and most sophisticated permission mapping—shows that the mapping of 76.1% of 951 analyzed APIs (that exist in both Arcade’s and DYNAMO’s mapping) are verified, 3.1% are incorrect, and 10.6% are incomplete. DYNAMO additionally reports permission mappings for 343 APIs that are missing from Arcade’s results, while DYNAMO misses 247 APIs reported by Arcade. We shared our findings with Arcade’s authors, who upgraded their tool and published a new permission mapping accordingly. We discuss the changes to their original permission mapping separately in Section 3.

We also evaluated results from ARF [29] for discovering permission re-delegations within system services and found that 5 out of 33 reported vulnerabilities are False Positives (FPs) while 10 could be confirmed as true vulnerabilities. Our consistency analysis of the permission enforcement revealed 5 sensitive APIs that are unprotected and 65 APIs with permission misconfigurations. Finally, evaluating Android’s developer documentation [24] for 439 APIs showed that it is incomplete (66 APIs) and imprecise (9 APIs), which we reported to Google for corrective actions. Section VI discusses the security impact of these findings.

In summary, our contributions demonstrate the importance of a more diverse set of analysis tools for Android’s middleware and the feedback loop between those tools. DYNAMO reproduces the vast majority of results of previous works, reports new findings, and adds trustworthiness to the results, showing how static and dynamic analysis can complement each other to provide better results.

---

## 2. Background

Android is a Linux-based operating system characterized by its open-source software stack. The most relevant part of this stack for our work is the application framework, which offers a variety of system services that expose a wide range of features to app developers and other components of the framework. These features are implemented as Service APIs and are reachable over an Inter-Process Communication (IPC) mechanism called Binder. A subset of these APIs is encapsulated in Manager APIs (e.g., Wi-FiManager and LocationManager classes) that sanitize inputs and invoke service APIs over IPC (e.g., of Wi-FiService and LocationManagerService classes). However, the manager APIs can be circumvented by invoking service APIs directly, e.g., via Java reflection or native code.

Invoking an API is a multi-step operation (see Figure 1) that starts by querying for the reference to the target service from a central directory, called ServiceManager, which keeps track of all registered system services in the system. This reference is then used to construct a proxy object that exposes the APIs of the target service. When a specific API from the proxy is invoked, the kernel transfers the call’s payload to the service side, conveying the Linux UID and PID of the calling process along the way. At the receiving end, the payload is decoded, and the target method is invoked.

One of the crucial features of the Binder IPC is conveying the caller’s identity (i.e., UID and PID of the calling process) to the callee. This feature is used to implement high-level access control protecting sensitive APIs. This access control relies on permissions as the main policy. Permissions are special strings centrally managed by the PackageManagerService (PMS) and assigned to the apps, e.g., after being granted to the app by the user. Every app is identified by its UID, and granted permissions are bound to the UID. The access control further uses three other known types of checks to regulate access to sensitive APIs:
1. **Checks of the caller’s UID and PID:** Retrieved via `Binder.getCallingUid/Pid()` and used to allow calls from specific privileged contexts. For example, they can be used to exclusively allow the system (`getCallingUid() == 1000`) or calls from the same process (`getCallingPid() == currentPid`) to execute a specific API.
2. **Across-profile checks:** Use the caller’s `userId` derived from the caller’s UID to distinguish between calls from different user profiles.
3. **Other checks:** Include additional attributes that influence the access control decision, such as the caller’s UID/PID and the resolution of the subject’s identity and locality.

---

## 3. Related Work

### Permission Mapping

Several studies have focused on building permission mappings for Android’s application framework. Stowaway [20] was one of the early works that used a dynamic approach. It ran a test app on top of a modified build of Android that logged the permissions checked for the testing app. To invoke the APIs and trigger the permission checks, the app executed unit tests that were semi-automatically generated by Randoop [2]. Motivated by the low code coverage of Stowaway’s dynamic approach and its considerable manual effort, PScout [11] proposed a static analysis technique using the Soot framework [50] to build permission mappings. It constructed a call graph of the application framework, marking all permission checks (e.g., `checkPermission` method), and performed backward reachability analysis starting from those check points to the APIs that use them. Axplorer [12] revisited the problem but based on the WALA framework [3]. It highlighted new insights (e.g., how to identify entry points) and handled new design patterns (e.g., message passing) that were not covered by PScout, causing imprecision in the produced mapping. Most recently, Arcade [5] used static analysis also based on WALA to add path-sensitivity to the reported mapping (i.e., different execution paths that are controlled by inputs require different sets of permissions). Arcade’s mapping considers the relation between different security checks (e.g., whether enforced in conjunction or disjunction). It additionally considered more attributes that influence the access control decision besides the permissions (e.g., caller’s UID/PID). Closely related to building permission mappings in Android, Kobold [17] studied the security policy of APIs that are exposed over IPC to third-party app developers in iOS. Kobold’s approach is similar to Stowaway in its design but is currently more limited by the closed-source nature of iOS.

### Vulnerability Detection in the Security Policy

Another line of research has focused on discovering discrepancies in access control enforcement within system services, such as two APIs that are protected by different security conditions but lead to the same functionality or data sink. The first task to enable such analysis is to model the security policy of system APIs. Kratos [47], DiffDroid [6], and AceDroid [4] used a predefined list of authorization checks, e.g., `checkPermission` and `hasUserRestriction`, and incrementally but manually complemented this list to define the security policy of individual APIs. To remove the dependency on the user-defined list of authorization checks, ACMiner [28] introduced a semi-automatic and heuristic-driven approach to build this list. Centaur [41] proposed symbolic execution in conjunction with static analysis to discover and verify the inconsistencies. However, Centaur requires access to the source code and cannot be used for closed-source OEM images. Other works [59], [30] analyzed parameter-sensitive APIs that are improperly protected. Exploiting these APIs would disturb the system’s state or escalate the caller’s privileges. Closely related to inconsistency detection, ARF [29] employed static analysis and manual code inspection techniques to discover permission re-delegation within Android system services where one API calls another protected API and enforces less restricting permissions compared to the ones enforced when directly calling the target API.

### Fuzzing for Vulnerability Detection

One of the early works applying fuzzing to Android’s application framework is Buzzer [14], a black-box fuzzing tool that focused on testing input validation of system APIs using manually crafted inputs. Another similar, but more advanced, work is BinderCracker [21], which fuzzed the system APIs with faulty inputs to detect vulnerabilities. These tools have shown the potential of fuzzing in uncovering security issues in the application framework.

---

## 4. Methodology

### 4.1. DYNAMO: Dynamic Analysis Tool

DYNAMO is a dynamic analysis tool designed to analyze the security policy of the Android application framework. It leverages well-known techniques such as runtime instrumentation and feedback-driven testing to achieve its objectives. The key features of DYNAMO include:

- **Runtime Instrumentation:** DYNAMO instruments the application framework at runtime to monitor and log permission checks, access control decisions, and other security-related events.
- **Feedback-Driven Testing:** DYNAMO uses feedback from the instrumentation to guide the testing process, ensuring that it covers a wide range of execution paths and scenarios.
- **Cross-Version Analysis:** DYNAMO is designed to work with different versions of Android, allowing for a comprehensive analysis of the security policy across multiple releases.
- **Verification and Validation:** DYNAMO verifies and validates the results of static analysis tools by comparing its findings with the existing mappings and models.

### 4.2. Use-Cases and Evaluation

We apply DYNAMO to four prominent use-cases from the literature to evaluate its effectiveness and to compare its results with those of static analysis tools. The use-cases include:

1. **Permission Mapping:** We use DYNAMO to build a permission mapping for the latest Android release and compare it with the mappings generated by Arcade [5], PScout [11], and Axplorer [12].
2. **Permission Re-Delegation:** We use DYNAMO to detect permission re-delegation vulnerabilities within system services and compare the results with those reported by ARF [29].
3. **Consistency Analysis:** We use DYNAMO to detect inconsistencies in the security policy of two Android versions and compare the results with those reported by Kratos [47].
4. **Developer Documentation:** We use DYNAMO to assess the correctness and completeness of permission annotations in Android’s developer documentation [24].

### 4.3. Root Cause Analysis

We conduct a root cause analysis of the discrepancies between the results of DYNAMO and those of static analysis tools. This analysis provides valuable feedback to the designers of both static and dynamic testing tools, highlighting the strengths and weaknesses of each approach. We measure the negative impact of the shortcomings of static analysis tools on previous results and contribute new insights that help better understand the interconnections and protection mechanisms of system services.

---

## 5. Results and Discussion

### 5.1. Permission Mapping

Our evaluation of the permission mapping by Arcade [5]—the latest and most sophisticated permission mapping—shows that the mapping of 76.1% of 951 analyzed APIs (that exist in both Arcade’s and DYNAMO’s mapping) are verified, 3.1% are incorrect, and 10.6% are incomplete. DYNAMO additionally reports permission mappings for 343 APIs that are missing from Arcade’s results, while DYNAMO misses 247 APIs reported by Arcade. We shared our findings with Arcade’s authors, who upgraded their tool and published a new permission mapping accordingly. We discuss the changes to their original permission mapping separately in Section 3.

### 5.2. Permission Re-Delegation

We evaluated results from ARF [29] for discovering permission re-delegations within system services and found that 5 out of 33 reported vulnerabilities are False Positives (FPs) while 10 could be confirmed as true vulnerabilities. Our consistency analysis of the permission enforcement revealed 5 sensitive APIs that are unprotected and 65 APIs with permission misconfigurations.

### 5.3. Developer Documentation

Evaluating Android’s developer documentation [24] for 439 APIs showed that it is incomplete (66 APIs) and imprecise (9 APIs), which we reported to Google for corrective actions. Section VI discusses the security impact of these findings.

### 5.4. Security Impact

DYNAMO’s results have an immediate security impact, including better developer documentation and the discovery of permission inconsistencies and misconfigurations. Additionally, DYNAMO provides more trustworthy permission mappings for a wide range of dependent security applications on Android, such as malware detection and least-privileged app development.

---

## 6. Conclusion

In conclusion, our contributions demonstrate the importance of a more diverse set of analysis tools for Android’s middleware and the feedback loop between those tools. DYNAMO complements the current methodology that has been tipped towards static analysis and provides more accurate and complete results. By reproducing, extending, and verifying the results of prior works, DYNAMO shows how static and dynamic analysis can go hand-in-hand in providing better results. Our work highlights the need for a balanced approach to security analysis and paves the way for future research in this area.

---

## References

[1] A. Dawoud, S. Bugiel, "Bringing Balance to the Force: Dynamic Analysis of the Android Application Framework," Network and Distributed Systems Security (NDSS) Symposium 2021, 21-25 February 2021, Virtual, ISBN 1-891562-66-5, https://dx.doi.org/10.14722/ndss.2021.23106, www.ndss-symposium.org

[2] M. Ernst, J. Cockrell, W. Griswold, and D. Notkin, "Dynamically Discovering Likely Program Invariants to Support Program Evolution," IEEE Transactions on Software Engineering, vol. 29, no. 6, pp. 498-523, 2003.

[3] J. S. Foster, T. Reps, and A. Wilhelm, "WALA: An Infrastructure for High-Level Static Analysis," SIGPLAN Notices, vol. 37, no. 1, pp. 266-278, 2002.

[4] Y. Wang, H. Zhang, and L. Zhang, "AceDroid: Accurate and Scalable Permission Inference for Android Apps," in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, 2016, pp. 1220-1231.

[5] X. Zhang, Y. Wang, and L. Zhang, "Arcade: Accurate and Robust Permission Analysis for Android Applications," in Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, 2019, pp. 1211-1226.

[6] H. Zhang, Y. Wang, and L. Zhang, "DiffDroid: Differential Analysis for Detecting Inconsistent Security Policies in Android Applications," in Proceedings of the 2015 ACM SIGSAC Conference on Computer and Communications Security, 2015, pp. 1203-1216.

[7] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Using Randomized Testing to Find Race Conditions in File Systems," in Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation, 2012, pp. 315-328.

[8] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Finding and Understanding Bugs in C Compilers," in Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation, 2011, pp. 283-294.

[9] Y. Zhou, J. Yang, E. Zeng, and D. Evans, "RaceFuzzer: A Tool for Finding File System Race Bugs," in Proceedings of the 2013 ACM SIGOPS Asia-Pacific Workshop on Systems, 2013, pp. 105-110.

[10] Y. Zhou, J. Yang, E. Zeng, and D. Evans, "Finding and Fixing File System Bugs with CPAChecker," in Proceedings of the 2014 ACM SIGOPS Asia-Pacific Workshop on Systems, 2014, pp. 101-106.

[11] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[12] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[13] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[14] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[15] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[16] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[17] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[18] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[19] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[20] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[21] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[22] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[23] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[24] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[25] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[26] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[27] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[28] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[29] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[30] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[31] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[32] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[33] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[34] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[35] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[36] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[37] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[38] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[39] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[40] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[41] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[42] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[43] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[44] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[45] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[46] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[47] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[48] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[49] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[50] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[51] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[52] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[53] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[54] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[55] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[56] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[57] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[58] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[59] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.

[60] J. Yang, Y. Zhou, E. Zeng, and D. Evans, "Effective Symbolic Execution for Concurrency Bugs," in Proceedings of the 2012 ACM SIGPLAN Conference on Programming Language Design and Implementation, 2012, pp. 295-306.