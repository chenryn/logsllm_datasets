### Establishing Thresholds and Defining Control Policies

When the distances between observed behaviors and expected patterns are less than a predefined epsilon radius, the behavior is considered normal. Administrators may also choose to label distances slightly greater than the epsilon as normal, given their near-normality. A threshold distance can be set to distinguish between normal and abnormal behavior. Enforcing normal behavior necessitates stopping any detected abnormal behavior.

The threshold value is adjustable by the administrator. During periods of heightened security threats, the threshold can be lowered to enforce stricter behavioral controls. Conversely, during times of reduced threat, the threshold can be raised, creating a less restrictive but potentially less secure environment for program behavior.

### 5.7. Policy

In addition to behavioral information, tagging is essential for effective control. Once the distance is calculated, the tag information becomes highly useful. If the distance for a profile exceeds the anomaly threshold, the associated behavior may need to be stopped. For instance:
- If the tag is a process ID, the process can be terminated or killed by sending it a signal.
- If the tag is a socket's file descriptor, the `shutdown(2)` function can be called to close the socket.
- If the tag is a source IP address, incoming packets from that IP can be ignored in various ways.

Each profile contains tagging information that identifies the specific behavior of the program. The actions taken in response to anomalous behavior are determined by multiple factors. For critical programs or servers, the responses will likely be stringent. These responses are controlled by the administrator. Our behavioral measurement techniques help determine where and when to take action.

### Detecting and Stopping Attacks

Our approach can identify and stop attacks that share two key characteristics:
1. The attack must affect the program's execution.
2. The attacked program must generate enough behavior to fill more than a single profile.

If an attack can fully express itself within a single profile, our approach will detect the abnormality and its cause but will not prevent it. For example, if an attack is simply ignored by the program, its behavior is unlikely to change. If an attack does not require altering the program's execution, behavioral analysis may not detect it. Other security techniques, such as Access Control Lists (ACLs), are more effective for addressing this class of security issues.

### 6. Experimental Results: Victim

For experimental purposes, we demonstrated the capabilities of behavioral measurement and control by connecting a highly vulnerable version of the Linux kernel to the Internet. We then published the machine's URL to attract the attention of potential attackers. As an additional incentive, we announced that we would ship the computer to the first person who succeeded in rooting the operating system.

To prepare the victim machine, we:
- Installed a full "Everything" version of RedHat 6.2.
- Added the Watcher kernel plugin to the 2.2.18 kernel.
- Set up a test web site on the victim machine.
- Enabled nearly every service listed in `inetd.conf`.
- Scheduled cron jobs to restart services and build log summary files.

Unlike other security systems that rely on specific or general knowledge about attacks, our approach focuses on calibrating the system for normal behavior. We defined normal behavior as serving web pages and performing standard system administration tasks. Any behavior deviating from this baseline was considered abnormal and was stopped.

### Summary

While existing paradigms in computer security are still valuable, there has been a gap in the field. Our technology and approach fill this gap by providing procedural-based intrusion detection and response. This allows Watcher to detect and halt completely novel attacks that have not yet been seen on the Internet, protecting the first person to encounter a new attack or exploit.

In essence, we have learned to solve the right problem. Removing all software vulnerabilities is an unsolvable issue, and imposing restrictive barriers makes software difficult to use. Monitoring and controlling program execution at runtime through behavioral control is the missing piece in the security puzzle. The complete security solution consists of three components: data control (encryption), access control, and behavioral control.

### References

[1] J. Alves-Foss, D. Frincke, and J. Munson. Measuring Security: A Methodological Approach, International Workshop on Enterprise Security, Stanford, CA, June 1996.

[2] D. Anderson, T. Frivold, and A. Valdez: Next-generation intrusion detection expert system (NIDES). Technical Report, Computer Science Laboratory, SRI International, Menlo Park, CA, SRI-CSL-95-07, May 1995.

[3] M. Bishop: A Taxonomy of UNIX and Network Security Vulnerabilities, Technical Report 95-10, Department of Computer Science, University of California at Davis, May 1995.

[4] D. Denning: An intrusion-detection model. IEEE Transactions on Software Engineering, Vol.13, No:2, pp.222-232, February 1987.

[5] S. G. Elbaum and J. C. Munson, "Intrusion Detection through Dynamic Software Measurement," Proceedings of the USENIX Workshop on Intrusion Detection and Network Monitoring, Santa Clara, CA, April 1999.

[6] A. K. Ghosh, C. Michael, and M. Schatz: A real-time intrusion detection system based on learning program behavior, Proceedings of the Third International Workshop, RAID 2000, Springer-Verlag, Toulouse, France, pp. 93-109, October 2000.

[7] A. K. Ghosh, A. Schwartzbard, and M. Schatz: Learning program behavior profiles for intrusion detection. Proceedings of the USENIX Workshop on Intrusion Detection and Network Monitoring, Santa Clara, CA, April 1999.

[8] L. R. Halme and R. K. Bauer: AINT misbehaving - a taxonomy of anti-intrusion techniques. Proc. of the 18th National Information Systems Security Conference, pp. 163-172, October 1995.

[9] J. Hochberg, K. Jackson, C. Stallings, J. F. McClary, D. DuBois, and J. Ford: NADIR: An automated system for detecting network intrusion and misuse. Computers & Security, Vol.12, No:3, pp.235-248, May 1993.

[10] H. S. Javitz and A. Valdes: The SRI IDES statistical anomaly detector. Proc. of the IEEE Symposium on Research in Security and Privacy, pp.316-326, May 1991.

[11] A. P. Kosoresow and S. A. Hofmeyr, "Intrusion Detection via System Call Traces," IEEE Software, September/October 1997, pp. 35-42.

[12] S. Kumar and E. H. Spafford: A pattern matching model for misuse intrusion detection. Proc. of the 17th National Computer Security Conference, pp. 11-21, October 1994.

[13] S. Kumar and E. H. Spafford: A Software Architecture to Support Misuse Intrusion Detection, Proc. 18th National Information Systems Security Conference, pp.194-204, 1995.

[14] The Linux Kernel, http://sourceforge.net/projects/kip/

[15] J. C. Munson, “A Software Blackbox Recorder.” Proceedings of the 1996 IEEE Aerospace Applications Instrumentation Project, IEEE Computer Society Press, Los Alamitos, CA, November, pp. 309-320, 1996.

[16] A. P. Porras and G. P. Neumann: EMERALD: Event Monitoring Enabling Responses to Anomalous Live Disturbances. National Information Systems Security Conference, 1997.

[17] M. Sobirey, Richter, and H. Konig. The intrusion detection system AID. Architecture, and experiences in automated audit analysis. Proc. of the International Conference on Communications and Multimedia Security, pp. 278-290, September 1996.

[18] C. Warrender, S. Forrest, and B. Pearlmutter: Detecting intrusions using system calls: alternative data models, IEEE Symposium on Security and Privacy, IEEE Computer Society Press, pp. 133-145, 1999.