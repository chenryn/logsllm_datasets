### Optimized Text

When the number of users is increased to 500,000, the results from LDPMiner show a significant improvement in accuracy. Not only does it miss only one heavy hitter, but the frequency estimates for each heavy hitter are also very close to their true values. In contrast, Figure 4c shows a representative result from sampling RAPPOR, which, while improved, is clearly inferior to LDPMiner. This highlights the benefits of the proposed two-phase approach.

The skewness of the data affects the frequency difference between heavy hitters and other items; higher skewness makes it easier to identify the correct heavy hitters. LDPMiner's effectiveness is also influenced by this skewness. Figure 5a illustrates a representative result from LDPMiner using a synthetic dataset generated from a Laplace distribution with 500,000 users. Compared to Figure 4c, the skewness of heavy hitters further enhances the estimation accuracy of LDPMiner: no actual heavy hitters are missed, and the frequency estimation error for each heavy hitter is reduced. In contrast, Figure 5b shows the result from sampling RAPPOR over the same dataset, which does not demonstrate a clear improvement. The reason is that LDPMiner's first phase can accurately capture the top heavy hitters due to the skewness, allowing the second phase to allocate more privacy budget to these heavy hitters. Sampling RAPPOR, however, spreads the privacy budget evenly over all items, failing to leverage the skewness.

**Figure 4: Experimental results over synthetic datasets generated from a normal distribution**
- (a) LDPMiner-RAPPOR
- (b) LDPMiner-RAPPOR
- (c) Sampling RAPPOR

**Figure 5:**
- (a) and (b) show experimental results over synthetic datasets following the Laplace distribution.
- (c) shows the measured Relative Error of two synthetic datasets (normal and Laplace) with different privacy budget allocation strategies.

In the experiments, we evenly split the privacy budget between the two phases of LDPMiner. One might wonder about the impact of different budget splits. Intuitively, if too little budget is allocated to the first phase, the candidate set of heavy hitters will be larger, leading to a thinner spread of the second phase's budget. Conversely, if the second phase receives too little budget, the frequency estimates of the candidates will be very noisy. Figure 5c shows the Relative Error of LDPMiner's results on both normal and Laplace-distributed synthetic datasets with 500,000 users. The x-axis represents the percentage of the budget allocated to the first phase. It is evident that the relative error is minimized when the budget is split roughly evenly. Similar observations were made with other settings and using the NDCG metric. Therefore, for the rest of the experiments, we allocate an equal amount of budget to each phase of LDPMiner.

### 5.3 Experiments with Real Datasets

#### 5.3.1 The Impact of ε

In this experiment, we fix \( k = 10 \) and report the utility measures of different LDP mechanisms as ε varies. Figure 6 shows the relative errors for both datasets along with changes in ε. As expected, for all four algorithms, a larger ε results in lower relative errors. Additionally, LDPMiner-RAPPOR and LDPMiner-SH consistently achieve much lower relative errors than sampling RAPPOR and sampling SH. For most values of ε, the relative errors of single-phase approaches are almost twice those of LDPMiner.

Another observation is that LDPMiner-RAPPOR outperforms LDPMiner-SH, demonstrating the utility gain from tolerating slightly more communication cost (k bits vs. 1 bit per user response) when using RAPPOR in the second phase. We also observe that sampling RAPPOR is superior to sampling SH, although this comes at a high communication cost. Similar observations are made when measuring the utility of estimated heavy hitters using NDCG, as shown in Figure 7.

**Figure 6: Varying ε: Relative Error for Real Datasets**
- (a) AOL: RE
- (b) Kosarak: RE

**Figure 7: Varying ε: Normalized Discounted Cumulative Gain for Real Datasets**
- (a) AOL: NDCG
- (b) Kosarak: NDCG

#### 5.3.2 The Impact of k

In this experiment, we fix \( \varepsilon = 3 \) and vary the size of reported heavy hitters, \( k \), to study its impact on the utility of each algorithm. The results are shown in Figures 8 and 9. As expected, for all approaches, their utility measures decrease as \( k \) increases. We also observe that the advantage of LDPMiner over single-phase approaches is more significant when \( k \) is small. However, when \( k \) increases (e.g., \( k > 30 \) for the AOL dataset), the relative error of LDPMiner becomes higher than that of single-phase approaches. This is because the proposed two-phase framework improves utility by reducing the item set size from \( l \) to \( O(k) \). When \( k \) increases, the size of the candidate set approaches \( l \), and the utility gain from the trimmed candidate set is offset by the utility loss from budget splitting. Nevertheless, for the AOL dataset, even when \( k > 30 \), LDPMiner still achieves better NDCG despite having higher relative errors. This is even more pronounced for the Kosarak dataset. Recall that relative error reflects the quality of frequency estimation, while NDCG reflects the quality of the ranked list of heavy hitters. This suggests that, as \( k \) increases, although the frequency estimation of LDPMiner deteriorates, it still preserves the relative orders among heavy hitters better.

**Figure 8: Varying k: Relative Error for Real Datasets**
- (a) AOL: RE
- (b) Kosarak: RE

**Figure 9: Varying k: Normalized Discounted Cumulative Gain for Real Datasets**
- (a) AOL: NDCG
- (b) Kosarak: NDCG

### 6. Related Work

As discussed in Section 2, several works have studied the problem of frequency estimation under local differential privacy [3, 9, 19, 22]. After Warner's initial study [28] on randomized response, many works have explored various perturbation mechanisms to achieve optimal utility. In [22], the local privacy model was first formalized. A recent work by Duchi et al. [9] provides an upper bound under the LDP setting using information-theoretic techniques to derive a minimax-error bound for convex statistical estimation. Hsu et al. [19] focus on estimating heavy hitters using random projection and concentration of measure. Bassily et al. [3] propose an efficient protocol for succinct histogram estimation with information-theoretical optimal error. To address practical issues in private distribution estimation, RAPPOR [12, 13] generalizes Warner's randomizer from binary to k-ary alphabets. In [11], private estimation of frequent elements from stream data is studied in a setting called "pan-privacy," a variant of the LDP model.

Several works focus on publishing histograms and count queries under the centralized differential privacy model. Hay et al. [17] generate differentially private histograms through hierarchical partitioning of data. Wavelet transform is used to handle multi-dimensional datasets in [30]. Li et al. [23] propose a query matrix framework that generalizes the above two works but incurs high computational complexity. Xu et al. [31] propose a two-phase kd-tree-based spatial decomposition mechanism for publishing histograms. Li et al. [24] address the problem of releasing histograms for dynamic datasets using the sparse vector technique. He et al. [18] propose a flexible policy where users can specify sensitive information for releasing cumulative histograms. There is also a rich literature on frequent itemset mining, with several works relevant to our study. Bhaskar et al. [4] propose a two-phase approach using a truncated frequency threshold to shrink the candidate list of frequent itemsets, confirming the effectiveness of a two-phase approach in a centralized model. Inspired by [4], Li et al. propose improving utility by constructing a basis set privately. Chen et al. [7] study the publication of set-valued datasets under differential privacy, presenting a tree-structured partition mechanism in a top-down fashion.

However, all the above mechanisms require global knowledge of the dataset, making them unsuitable for local differential privacy. While not all techniques developed for centralized models are suitable for local models, the underlying ideas may still be helpful in designing mechanisms for LDP.

### 7. Conclusions and Future Work

In this paper, we study heavy hitter estimation under local differential privacy for set-valued data. We first review existing LDP techniques and analyze their direct extensions to handle set-valued data. Our theoretical and experimental analysis shows that such extensions either suffer from high communication overhead or low result utility. To address this, we propose LDPMiner, a two-phase framework: in the first phase, a candidate set of heavy hitters is identified by the data collector, and in the second phase, participants refine the frequency reports of items in the candidate set. Both theoretical analysis and extensive experiments confirm the utility, efficiency, and practicality of LDPMiner. A natural extension of LDPMiner is to study frequent itemset mining under local differential privacy. The challenge is that direct adoption of existing frequent itemset mining algorithms would require iterative information exchange between users and data collectors, resulting in significant noise accumulation due to the limited budget for each iteration.

### 8. Acknowledgments

Xiaokui Xiao was supported by grant ARC19/14 from MOE, Singapore.

### 9. References

[1] AOL search log. http://www.gregsadetsky.com/aol-data/.
[2] SPMF: An open-source data mining library. http://www.philippe-fournier-viger.com/spmf.
[3] R. Bassily and A. D. Smith. Local, private, efficient protocols for succinct histograms. In STOC, pages 127–135, 2015.
[4] R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta. Discovering frequent patterns in sensitive data. In SIGKDD, pages 503–512, 2010.
[5] A. Blum, K. Ligett, and A. Roth. A learning theory approach to noninteractive database privacy. JACM, 60(2):12, 2013.
[6] C. Burges et al. Learning to rank using gradient descent. In ICML, pages 89–96, 2005.
[7] R. Chen et al. Publishing set-valued data via differential privacy. PVLDB, 4(11):1087–1098, 2011.
[8] J. C. Duchi, M. I. Jordan, and M. J. Wainwright. Privacy aware learning. J. ACM, 61(6):38:1–38:57.
[9] J. C. Duchi, M. I. Jordan, and M. J. Wainwright. Local privacy and statistical minimax rates. In FOCS, pages 429–438, 2013.
[10] C. Dwork. Differential privacy: A survey of results. In Theory and applications of models of computation, pages 1–19, 2008.
[11] C. Dwork, M. Naor, T. Pitassi, G. N. Rothblum, and S. Yekhanin. Pan-private streaming algorithms. In ICS, pages 66–80, 2010.
[12] Ú. Erlingsson et al. RAPPOR: Randomized aggregatable privacy-preserving ordinal response. In CCS, pages 1054–1067, 2014.
[13] G. Fanti et al. Building a RAPPOR with the unknown: Privacy-preserving learning of associations and data dictionaries. PoPETS, issue 3, 2016.
[14] A. Gupta, M. Hardt, A. Roth, and J. Ullman. Privately releasing conjunctions and the statistical query barrier. SICOMP, 42(4):1494–1520, 2013.
[15] S. Hansell. AOL removes search data on vast group of web users. New York Times, 8:C4, 2006.
[16] M. Hardt and K. Talwar. On the geometry of differential privacy. In STOC, pages 705–714, 2010.
[17] M. Hay et al. Boosting the accuracy of differentially private histograms through consistency. PVLDB, 3(1-2):1021–1032, 2010.
[18] X. He, A. Machanavajjhala, and B. Ding. Blowfish privacy: Tuning privacy-utility trade-offs using policies. In SIGMOD, pages 1447–1458, 2014.
[19] J. Hsu, S. Khanna, and A. Roth. Distributed private heavy hitters. In Automata, Languages, and Programming, pages 461–472, 2012.
[20] W. B. Johnson and J. Lindenstrauss. Extensions of Lipschitz mappings into a Hilbert space. Contemporary mathematics, 26(189-206):1, 1984.
[21] D. Karger et al. Consistent hashing and random trees: Distributed caching protocols for relieving hot spots on the World Wide Web. In STOC, pages 654–663, 1997.
[22] S. P. Kasiviswanathan et al. What can we learn privately? SICOMP, 40(3):793–826, 2011.
[23] C. Li et al. Optimizing linear counting queries under differential privacy. In PODS, pages 123–134, 2010.
[24] H. Li et al. Differentially private histogram publication for dynamic datasets: An adaptive sampling approach. In CIKM, pages 1001–1010, 2015.
[25] N. Li, W. Qardaji, D. Su, and J. Cao. Privbasis: Frequent itemset mining with differential privacy. PVLDB, 5(11):1340–1351, 2012.
[26] F. D. McSherry. Privacy integrated queries: An extensible platform for privacy-preserving data analysis. In SIGMOD, pages 19–30, 2009.
[27] T. T. Nguyễnet al. Collecting and analyzing data from smart device users with local differential privacy. arXiv preprint arXiv:1606.05053, 2016.
[28] S. L. Warner. Randomized response: A survey technique for eliminating evasive answer bias. Journal of the ASA, 60(309):63–69, 1965.
[29] X. Xiao, Y. Tao, and M. Chen. Optimal random perturbation at multiple privacy levels. PVLDB, 2(1):814–825, 2009.
[30] X. Xiao, G. Wang, and J. Gehrke. Differential privacy via wavelet transforms. TKDE, 23(8):1200–1214, 2011.
[31] J. Xu et al. Differentially private histogram publication. VLDBJ, 22(6):797–822, 2013.
[32] Y. Zhou, D. Wilkinson, R. Schreiber, and R. Pan. Large-scale parallel collaborative filtering for the Netflix prize. In Algorithmic Aspects in Information and Management, pages 337–348, 2008.