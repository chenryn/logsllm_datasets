# Performance Impact of False Positive Symptoms

## 1. Introduction
The performance impact of false positive symptoms, when combined with parity and ECC, results in an overall rate of approximately 1%. The two mechanisms together provide significant soft error protection. Parity and ECC are primarily effective in detecting and recovering from soft errors in SRAM structures (e.g., register files, alias tables, and fetch queues), while the ReStore architecture is more effective at detecting soft errors in latches. When ReStore is used in conjunction with precisely placed parity/ECC, the mean time between failures (MTBF) improves by 7x compared to a conventional, unprotected pipeline.

## 2. Performance Impact Evaluation
In this section, we evaluate the performance impact due to false positive symptoms. We expect that symptoms originating from watchdog timer saturation and exception events will be infrequent enough to have a negligible impact on performance. Therefore, our focus is on the performance cost due to checkpoint rollbacks resulting from high-confidence branch mispredictions.

### 2.1 Experimental Setup
We conducted this evaluation using a timing model configured to resemble our processor model. To support a rollback distance of at least one checkpoint interval, two checkpoints are maintained at all times. When a rollback is required, the older checkpoint is used to restore the architectural state. The average rollback distance is thus one and a half times the checkpoint interval. During re-execution of a checkpoint interval, a branch outcome event log is used to provide perfect prediction of control flow, eliminating control misspeculations during re-execution.

### 2.2 Results
The results of this experiment are presented in Figure 7. The x-axis represents the checkpointing intervals, while the y-axis shows the relative performance compared to a baseline processor without checkpointing. The "imm" bars indicate the performance impact when rollback occurs immediately upon discovery of a symptom. This approach has the disadvantage of possibly incurring multiple rollbacks to a single checkpoint if multiple symptoms arise within the same checkpoint interval. As an alternative, we also simulated the performance impact when checkpoint rollback is delayed until the entire interval is executed. The data from this experiment is represented by the "delayed" bars.

Overall, the performance hit is minor for shorter checkpointing intervals. A checkpointing interval of 100 instructions yields a performance hit of approximately 6%. The delayed configuration slightly underperforms the "imm" configuration at smaller intervals but begins to gain an advantage at 500 instruction intervals. Using more accurate branch and confidence [2] predictors would mitigate some of this performance loss and also obtain better error coverage.

## 3. Scaling Trends
In this section, we examine silent data corruption FIT rates as a function of design size for various architectures. FIT stands for Failures in Time, measured in billions of hours, and is a measure of the reliability of a given design.

### 3.1 Methodology
To generate the results shown in Figure 8, we assumed a raw FIT of 0.001 per bit [11], which is a widely accepted estimate for per-bit FIT rate in SRAMs. The different processor configurations are:
- Baseline: Processor without any error detection.
- ReStore: Processor with ReStore architecture.
- LHF: Processor with carefully placed parity/ECC (i.e., the "low-hanging fruit" pipeline described in Section 5.2).
- LHF+ReStore: Processor with both techniques.

The FIT extrapolations are made assuming that the soft error masking rate of the larger designs remains constant as design size is scaled. A reliability goal of 1000 MTBF, or mean time (years) between failures, is reflected by the horizontal line at 115 FIT. Any design whose FIT rises above this line fails to meet this goal. Our model consists of approximately 46,000 bits of "interesting" state—state within the pipeline that is particularly problematic to protect. This is approximately represented by the first data point in Figure 8. The interesting observation is that the LHF+ReStore configuration yields an MTBF comparable to a design 1/7th the size.

## 4. Related Work
Gu et al. [8, 9] and Smolens et al. [25] explored failure modes from fault injections into general-purpose registers and noted a high percentage of failures from exceptions. We investigate error propagation from microarchitectural state to architectural state and eventually to exceptions. Furthermore, we evaluate the use of exceptions and other symptoms to aid soft error detection.

Patel et al. [22] explored the error coverage provided by the rePLay framework, which performs checkpoint rollbacks on highly biased branch mispredictions. Like Gu et al., they performed fault injections into general-purpose registers. Here, we perform a microarchitectural evaluation in a more general framework.

Previous work has explored using parity, ECC, and TMR to provide spatial redundancy in processor cores [6, 10]. Franklin [4] noted different modes of failure throughout the pipeline and proposed mechanisms to guard against them. We propose an alternative, more cost-effective approach to soft error detection and recovery.

Other work has introduced other forms of redundancy to mitigate the effects of soft errors [20, 24, 29]. Each relies on "full-time" redundancy, where the cost of redundant execution is paid for on each instruction. Rather than utilizing redundancy to detect and recover from soft errors, Weaver et al. [30] reduce the exposure of instructions to soft errors by squashing instructions upon encountering long latency events like cache misses. Here, we introduce the ReStore architecture to provide efficient "on-demand" time redundancy.

## 5. Conclusion
In this work, we propose the ReStore architecture, which leverages existing performance-enhancing hardware for the purpose of soft error detection and recovery. Selected high-level events from microarchitectural structures (soft error symptoms) are used to diagnose the likely presence of failure-causing soft errors, initiating checkpoint recoveries for detection. Thus, the ReStore architecture employs on-demand time redundancy, minimizing hardware cost and performance impact. Such an approach sacrifices some amount of error coverage but is suitable for environments where reliable operation is desired but not at all costs.

The baseline processor had an intrinsic error masking rate of approximately 93%, indicating that only 7 out of every 100 introduced faults propagate to persistent data corruption. With a 100 instruction checkpoint interval, an example ReStore implementation detects and recovers from half of all failures. Covering the most vulnerable portions of the baseline processor core with parity/ECC and overlaying ReStore extends the mean time between failures by 7x, while incurring minimal hardware and performance cost.

## 6. Acknowledgments
We thank the other members of the Advanced Computing Systems group as well as the FACT group at Intel, Zbigniew Kalbarczyk, Claudio Basile, and the anonymous referees for providing feedback during various stages of this work. This work was supported by the C2S2 Marco center, NSF grant EIA-0224453, and equipment donation from AMD.

## 7. References
[1] H. Akkary, R. Rajwar, and S. T. Srinivasan. Checkpoint processing and recovery: Towards scalable large instruction window processors. In MICRO-36, Dec. 2003.
[2] H. Akkary, S. T. Srinivasan, R. Koltur, Y. Patil, and W. Refaai. Perceptron-based branch confidence estimation. In HPCA-10, pages 265–274, Feb. 2004.
[3] B. A. Gieseke et al. A 600MHz superscalar RISC microprocessor with out-of-order execution. In 1997 IEEE International Solid-State Circuits Conference Digest of Technical Papers, pages 176–178, Feb. 1997.
[4] M. Franklin. Incorporating fault tolerance in superscalar processors. In Proceedings of High Performance Computing, pages 301–306, Dec. 1996.
[5] G. Hinton et al. The Microarchitecture of the Pentium 4 Processor. Intel Technology Journal, Jan. 2001.
[6] J. Gaisler. A portable and fault-tolerant microprocessor based on the SPARC V8 architecture. In DSN-2002, Sept. 2002.
[7] D. Grunwald, A. Klauser, S. Manne, and A. Pleszkun. Confidence estimation for speculation control. In ISCA-25, pages 122–131, June 1998.
[8] W. Gu, K. Kalbarczyk, and R. K. Iyer. Error sensitivity of the Linux kernel executing on PowerPC G4 and Pentium 4 processors. In DSN-2004, June 2004.
[9] W. Gu, K. Kalbarczyk, R. K. Iyer, and Z. Yang. Characterization of Linux kernel behavior under errors. In DSN-2003, June 2003.
[10] H. Ando et al. A 1.3 GHz fifth generation SPARC64 microprocessor. In Design Automation Conference, June 2003.
[11] P. Hazucha and C. Svensson. Impact of CMOS Technology Scaling on the Atmospheric Neutron Soft Error Rate. IEEE Transactions on Nuclear Science, 47(6):2586–2594, Dec. 2000.
[12] E. Jacobsen, E. Rotenberg, and J. E. Smith. Assigning confidence to conditional branch predictions. In MICRO-29, pages 142–152, 1996.
[13] D. A. Jimenez. Fast path-based neural branch prediction. In MICRO-36, Dec. 2003.
[14] T. Karnik, P. Hazucha, and J. Patel. Characterization of soft errors caused by single event upsets in CMOS processes. IEEE Transactions on Dependable and Secure Computing, 1(2):128–143, Apr. 2004.
[15] A. Klaiber. The technology behind Crusoe processors. Technical report, Transmeta Corporation, Jan. 2000.
[16] S. S. Lumetta and S. J. Patel. Characterization of essential dynamic instructions. In SIGMETRICS 2003, June 2003.
[17] A. Mahmood and E. J. McCluskey. Concurrent error detection using watchdog processors - a survey. IEEE Transactions on Computers, 37(2):160–174, Feb. 1988.
[18] S. McFarling. Combining branch predictors. Technical Report TN-36, Digital Western Research Laboratory, June 1993.
[19] D. Meyer. AMD-K7 Technology Presentation. Advanced Micro Devices, Inc., Sunnyvale, CA, Oct. 1998. Microprocessor Forum presentation.
[20] S. S. Mukherjee, M. Kontz, and S. K. Reinhardt. Detailed design and evaluation of redundant multithreading alternatives. In ISCA-29, pages 99–110, May 2002.
[21] S. S. Mukherjee, C. Weaver, J. Emer, S. K. Reinhardt, and T. Austin. A systematic methodology to compute the architectural vulnerability factors for a high-performance microprocessor. In MICRO-36, pages 29–40, Dec. 2003.
[22] S. J. Patel, Z. Kalbarczyk, R. K. Iyer, W. Magda, and N. Nakka. A processor-level framework for high-performance and high-dependability. In Workshop on Evaluating and Architecting Systems for Dependability, 2001.
[23] S. K. Reinhardt and S. S. Mukherjee. Transient fault detection via simultaneous multithreading. In ISCA-27, June 2000.
[24] E. Rotenberg. AR-SMT: A microarchitectural approach to fault tolerance in microprocessors. In FTCS, June 1999.
[25] J. C. Smolens, B. T. Gold, J. Kim, B. Falsafi, J. C. Hoe, and A. G. Nowatzyk. Fingerprinting: Bounding soft-error detection latency and bandwidth. In ASPLOS-11, Oct. 2004.
[26] L. Spainhower and T. A. Gregg. IBM S/390 parallel enterprise server G5 fault tolerance: A historical perspective. IBM Journal of Research and Development, 43(5/6):863–873, 1999.
[27] J. G. Steffan and T. C. Mowry. The potential for using thread-level data speculation to facilitate automatic parallelization. In HPCA-4, Feb. 1998.
[28] N. J. Wang, J. Quek, T. M. Rafacz, and S. J. Patel. Characterizing the effects of transient faults on a high-performance processor pipeline. In DSN-2004, June 2004.
[29] C. Weaver and T. Austin. A fault-tolerant approach to microprocessor design. In ISCA-29, May 2002.
[30] C. Weaver, J. Emer, S. S. Mukherjee, and S. K. Reinhardt. Techniques to reduce the soft error rate of a high-performance microprocessor. In ISCA-31, June 2004.

---

This optimized text provides a clearer and more professional structure, making it easier to follow and understand.