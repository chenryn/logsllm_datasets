### Memory Constraints in Mica and Telos Motes

The memory capacity of Mica and Telos motes is extremely limited. Specifically, the data memory (RAM) is restricted to 4KB in Mica motes and 10KB in Telos motes. Similarly, the program memory (Flash) is limited to 128KB in Mica motes and 48KB in Telos motes.

### Comparison of Memory Requirements: CADeT vs. Liblog

Figure 6 illustrates the program and data memory requirements for CADeT as a percentage of the corresponding requirements for Liblog. 

- **Program Memory**: CADeT requires slightly more program memory, with an increase of 0.3% to 1% compared to Liblog. This marginal increase is due to the more complex implementation of CADeT.
  
- **Data Memory**: CADeT uses 3% to 13% more data memory than Liblog. This additional usage is attributed to CADeT's need to store tables such as AAMap and PCMap in memory. The extra memory requirement translates to approximately 300 bytes, which is considered moderate.

### Figure 6: Memory Usage Comparison

(a) Program memory
(b) Data memory

**Fig. 6.** Memory usage of CADeT as a percentage of memory usage of Liblog

### Related Work

We discuss runtime debugging techniques proposed for both traditional distributed systems and Wireless Sensor Networks (WSNs). These techniques can be categorized into offline and online methods, based on whether the debugging is performed postmortem or in real-time.

#### Online Monitoring and Predicate Detection

- **Online Monitoring and Predicate Detection**: Techniques such as those described in [10] and [51] use external or internal monitoring agents to observe the execution of the distributed system, often by intercepting messages. Similar solutions have been proposed for WSNs [52], [53]. While these methods provide valuable insights in small-scale test deployments, they are not cost-effective for large WSNs due to the need for additional, sometimes more powerful, hardware. Coordinating and maintaining the correctness of monitors in large networks is also challenging.

- **Remote Debugging Tools**: Tools like Marionette [19], Clairvoyant [20], and Hermes [21] allow developers to inspect and modify the state of individual nodes. HSEND [54] is an invariant-based application-level runtime error detection tool for WSNs, where invariants are checked near the source of the error, reducing the need for periodic data collection at the base station. Hermes [21] extends this by allowing runtime modification of invariants and deployment of patches to fix violations. These approaches complement our diagnostic tracing but are limited to diagnosing faults that violate invariants, requiring prior knowledge of potential failures.

#### Offline, Trace-Based Debugging

- **Trace-Based Debugging**: Many offline, trace-based debugging approaches have been proposed for traditional distributed systems [13], [14], [15], [55], [30], [16], [18]. These methods use model-based, statistical, or execution replay techniques for diagnosis. However, they are not applicable to WSNs due to their resource constraints. In many of these techniques, messages are traced by recording their contents and timestamps generated by Lamport clocks [32], which helps recreate the causal ordering of messages.

- **Optimal Tracing Techniques**: Netzer et al. [35] observed that only racing messages need to be recorded, and they presented a mostly optimal tracing technique using vector clocks [34] to identify and record these messages. However, vector clocks are too resource-intensive for WSNs, and logical clocks assume a reliable messaging layer like TCP, which is not always present in WSNs. Additionally, logical clocks have high variability, reducing opportunities for compression.

#### Other Debugging Approaches

- **Sympathy and PAD**: Sympathy [23] periodically collects WSN information from the base station to detect and localize node and link failures. PAD [24] uses Bayesian analysis to reduce network monitoring traffic. Both require frequent data collection, even during correct operation, and provide coarse-grained diagnostics specific to node/link failures but not complex faults like data races.

- **NodeMD and LIS**: NodeMD [26] records system calls and context switches to detect stack overflows, livelocks, and deadlocks. LIS [27] proposes a log instrumentation specification language and runtime for efficient function call and control-flow trace collection. TinyTracer [9] records concurrent events and interprocedural control-flow paths succinctly. TinyLTS [22] provides an efficient printf logging mechanism. None of these approaches handle node interactions, and while message sends and receives can be recorded locally, the ordering of messages cannot be captured.

- **Declarative TracePoints and Macrodebugging**: Declarative TracePoints [25] offer a uniform SQL-based query language interface for debugging and can simulate other trace-based approaches. Macrodebugging [8] records traces of all variable values at the network level but cannot diagnose faults at individual nodes. Unlike [7], CADeT does not require multiple fault reproductions or specific event instrumentation. However, our approach is complementary to the machine learning techniques in [7], as CADeT traces can be used in conjunction with these methods.

### Conclusions

In this paper, we proposed a message tracing scheme that effectively records the distributed control flow for diagnosing complex faults in WSNs while adhering to the resource constraints of these networks. We demonstrated its effectiveness and highlighted its efficiency and consistency advantages over existing state-of-the-art methods.

### Acknowledgements

This research was partially supported by the National Science Foundation (NSF) under grant 0834529. The opinions, findings, conclusions, or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the NSF.

### References

[1] G. Werner-Allen, K. Lorincz, J. Johnson, J. Lees, and M. Welsh, “Fidelity and Yield in a Volcano Monitoring Sensor Network,” in USENIX OSDI, 2006.

[2] G. Barrenetxea, F. Ingelrest, G. Schaefer, and M. Vetterli, “The Hitchhiker’s Guide to Successful Wireless Sensor Network Deployments,” in ACM SenSys, 2008.

[3] S. Kim, S. Pakzad, D. Culler, J. Demmel, G. Fenves, S. Glaser, and M. Turon, “Health Monitoring of Civil Infrastructures using Wireless Sensor Networks,” in ACM/IEEE IPSN, 2007.

[4] L. Krishnamurthy, R. Adler, P. Buonadonna, J. Chhabra, M. Flanigan, N. Kushalnagar, L. Nachman, and M. Yarvis, “Design and Deployment of Industrial Sensor Networks: Experiences from a Semiconductor Plant and the North Sea,” in ACM SenSys, 2005.

[5] J. Beutel, K. Römer, M. Ringwald, and M. Woehrle, “Deployment Techniques for Wireless Sensor Networks,” in Springer Sensor Networks: Where Theory Meets Practice, G. Ferrari, Ed., 2009.

[6] R. Szewczyk, A. Mainwaring, J. Polastre, J. Anderson, and D. Culler, “An Analysis of a Large Scale Habitat Monitoring Application,” in ACM SenSys, 2004.

[7] M. Khan, T. Abdelzaher, and K. Gupta, “Towards Diagnostic Simulation in Sensor Networks,” in IEEE DCOSS, 2008.

[8] T. Sookoor, T. Hnat, P. Hooimeijer, W. Weimer, and K. Whitehouse, “Macrodebugging: Global Views of Distributed Program Execution,” in ACM SenSys, 2009.

[9] V. Sundaram, P. Eugster, and X. Zhang, “Efficient Diagnostic Tracing for Wireless Sensor Networks,” in ACM SenSys, 2010.

[10] K. Sen, A. Vardhan, G. Agha, and G. Rosu, “Efficient Decentralized Monitoring of Safety in Distributed Systems,” in IEEE ICSE, 2004.

[11] X. Liu, Z. Guo, X. Wang, F. Chen, X. Lian, J. Tang, M. Wu, M. F. Kaashoek, and Z. Zhang, “D3S: Debugging Deployed Distributed Systems,” in USENIX NSDI, 2009.

[12] H. Garcia-Molina, F. Germano, and W. H. Kohler, “Debugging a Distributed Computing System,” IEEE Transactions on Software Engineering, vol. SE-10, no. 2, 1984.

[13] A. V. Mirgorodskiy and B. P. Miller, “Diagnosing Distributed Systems with Self-propelled Instrumentation,” in Springer Middleware, 2008.

[14] N. Maruyama and S. Matsuoka, “Model-Based Fault Localization in Large-Scale Computing Systems,” in IEEE IPDPS, 2008.

[15] P. C. Bates, “Debugging Heterogeneous Distributed Systems Using Event-Based Models of Behavior,” ACM Trans. Comput. Syst., vol. 13, no. 1, 1995.

[16] R. Curtis and L. D. Wittie, “BUGNET: A Debugging System for Parallel Programming Environments,” in IEEE ICDCS, 1982.

[17] T. J. LeBlanc, J. Crummey, and M. M., “Debugging Parallel Programs with Instant Replay,” IEEE Transactions on Computer, vol. 36, no. 4, 1987.

[18] D. Geels, G. Altekar, P. Maniatis, and T. Roscoe, “Friday: Global Comprehension for Distributed Replay,” in USENIX NSDI, 2007.

[19] K. Whitehouse, G. Tolle, J. Taneja, C. Sharp, S. Kim, J. Jeong, J. Hui, P. Dutta, and D. Culler, “Marionette: Using RPC for Interactive Development and Debugging of Wireless Embedded Networks,” in ACM/IEEE IPSN, 2006.

[20] J. Yang, M. L. Soffa, L. Selavo, and K. Whitehouse, “Clairvoyant: A Comprehensive Source-Level Debugger for Wireless Sensor Networks,” in ACM SenSys, 2007.

[21] N. Kothari, K. Nagaraja, V. Raghunathan, F. Sultan, and S. Chakradhar, “Hermes: A Software Architecture for Visibility and Control in Wireless Sensor Network Deployments,” in ACM/IEEE IPSN, 2008.

[22] R. Sauter, O. Saukh, O. Frietsch, and P. J. Marrón, “TinyLTS: Efficient Network-Wide Logging and Tracing System for TinyOS,” in IEEE INFOCOM, 2011.

[23] N. Ramanathan, K. Chang, R. Kapur, L. Girod, E. Kohler, and D. Estrin, “Sympathy for the Sensor Network Debugger,” in ACM SenSys, 2005.

[24] K. Liu, M. Li, Y. Liu, M. Li, Z. Guo, and F. Hong, “PAD: Passive Diagnosis for Wireless Sensor Networks,” in ACM SenSys, 2008.

[25] Q. Cao, T. Abdelzaher, J. Stankovic, K. Whitehouse, and L. Luo, “Declarative Tracepoints: A Programmable and Application Independent Debugging System for Wireless Sensor Networks.” in ACM SenSys, 2008.

[26] V. Krunic, E. Trumpler, and R. Han, “NodeMD: Diagnosing Node-Level Faults in Remote Wireless Sensor Systems,” in ACM MobiSys, 2007.

[27] R. Shea, M. Srivastava, and Y. Cho, “Scoped Identifiers for Efficient Bit Aligned Logging,” in IEEE DATE, 2010.

[28] M. M. H. Khan, H. Le, H. Ahmadi, T. Abdelzaher, and J. Han, “Dustminer: Troubleshooting Interactive Complexity Bugs in Sensor Networks,” in ACM SenSys, 2008.

[29] D. Geels, G. Altekar, S. Shenker, and I. Stoica, “Replay Debugging for Distributed Applications,” in USENIX ATC, 2006.

[30] Z. Chen, Q. Gao, W. Zhang, and F. Qin, “FlowChecker: Detecting Bugs in MPI Libraries via Message Flow Checking,” in ACM SC, 2010.

[31] R. Shea, “Defect Exposure in Wireless Embedded Systems,” Ph.D. dissertation, UCLA, 2010.

[32] L. Lamport, “Time, Clocks, and the Ordering of Events in a Distributed System,” Commun. ACM, vol. 21, no. 7, 1978.

[33] M. Ronsse, K. De Bosschere, M. Christiaens, J. C. de Kergommeaux, and D. Kranzlmüller, “Record/Replay for Nondeterministic Program Executions,” Commun. ACM, vol. 46, no. 9, 2003.

[34] F. Mattern, “Virtual Time and Global States of Distributed Systems,” in IEEE Parallel and Distributed Algorithms, 1989.

[35] R. H. B. Netzer and B. P. Miller, “Optimal Tracing and Replay for Debugging Message-Passing Parallel Programs,” in ACM/IEEE SC, 1992.

[36] F. J. Torres-Rojas and M. Ahamad, “Plausible Clocks: Constant Size Logical Clocks for Distributed Systems,” Springer Distributed Computing, vol. 12, no. 4, 1999.

[37] R. Prakash and M. Singhal, “Dependency Sequences and Hierarchical Clocks: Efficient Alternatives to Vector Clocks for Mobile Computing Systems,” Kluwer Wirel. Netw., vol. 3, no. 5, 1997.

[38] C. Fidge, “Fundamentals of Distributed System Observation,” IEEE Software, vol. 13, no. 6, 1996.

[39] T. Ball and J. R. Larus, “Efficient Path Profiling,” in IEEE Micro, 1996.

[40] I. F. Akyildiz, W. Su, Y. Sankarasubramaniam, and E. Cayirci, “A Survey on Sensor Networks,” IEEE Communications Magazine, vol. 40, no. 8, 2002.

[41] J. Yick, B. Mukherjee, and D. Ghosal, “Wireless Sensor Network Survey,” Elsevier Computer Networks, vol. 52, no. 12, 2008.

[42] W. B. Heinzelman, A. P. Chandrakasan, and H. Balakrishnan, “An Application-Specific Protocol Architecture for Wireless Microsensor Networks,” IEEE Transactions on Wireless Communications, vol. 1, no. 4, 2002.

[43] T. He, S. Krishnamurthy, L. Luo, T. Yan, L. Gu, R. Stoleru, G. Zhou, Q. Cao, P. Vicaire, J. A. Stankovic, T. F. Abdelzaher, J. Hui, and B. Krogh, “VigilNet: An Integrated Sensor Network System for Energy-Efficient Surveillance,” ACM Trans. Sen. Netw., vol. 2, no. 1, 2006.

[44] A. Arora, P. Dutta, S. Bapat, V. Kulathumani, H. Zhang, V. Naik, V. Mittal, H. Cao, M. Demirbas, M. Gouda, Y.-R. Choi, T. Herman, S. S. Kulkarni, U. Arumugam, M. Nesterenko, A. Vora, and M. Miyashita, “A Line in the Sand: A Wireless Sensor Network for Target Detection, Classification, and Tracking,” Elsevier Computer Networks, vol. 46, no. 5, 2004.

[45] P. Dutta, J. Hui, J. Jeong, S. Kim, C. Sharp, J. Taneja, G. Tolle, K. Whitehouse, and D. Culler, “Trio: Enabling Sustainable and Scalable Outdoor Wireless Sensor Network Deployments,” in ACM/IEEE IPSN, 2006.

[46] C. Intanagonwiwat, R. Govindan, D. Estrin, J. Heidemann, and F. Silva, “Directed Diffusion for Wireless Sensor Networking,” IEEE/ACM Trans. Netw., vol. 11, no. 1, 2003.

[47] V. Sundaram, S. Bagchi, Y.-H. Lu, and Z. Li, “SeNDORComm: An Energy-Efficient Priority-Driven Communication Layer for Reliable Wireless Sensor Networks,” in IEEE SRDS, 2008.

[48] V. Sundaram, “TinyTracer Implementation. http://sss.cs.purdue.edu/projects/TinyTracer/index.html,” 2011.

[49] Y. Sazeides and J. E. Smith, “The predictability of data values,” in IEEE Micro, 1997.

[50] V. Sundaram, P. Eugster, and X. Zhang, “Prius: Generic Hybrid Trace Compression for Wireless Sensor Networks,” in ACM SenSys, 2012.

[51] G. Khanna, P. Varadharajan, and S. Bagchi, “Self Checking Network Protocols: A Monitor Based Approach,” in IEEE SRDS, 2004.

[52] B. Chen, G. Peterson, G. Mainland, and M. Welsh, “LiveNet: Using Passive Monitoring to Reconstruct Sensor Network Dynamics,” in IEEE DCOSS, 2008.

[53] M. M. H. Khan, L. Luo, C. Huang, and T. F. Abdelzaher, “SNTS: Sensor Network Troubleshooting Suite,” in IEEE DCOSS, 2007.

[54] D. Herbert, V. Sundaram, Y. H. Lu, S. Bagchi, and Z. Li, “Adaptive Correctness Monitoring for Wireless Sensor Networks Using Hierarchical Distributed Run-Time Invariant Checking,” ACM Trans. Auton. Adapt. Syst., vol. 2, no. 3, 2007.

[55] R. Fonseca, G. Porter, R. H. Katz, S. Shenker, and I. Stoica, “X-trace: A Pervasive Network Tracing Framework,” in USENIX NSDI, 2007.