### 7.1.2 Extended Attack Range Experiments

To further evaluate the system's performance in long-range scenarios, we conducted additional experiments by extending the attack range to 200 cm and 300 cm. The device placement for recording the attack audio is illustrated in Figure 10.

### 7.1.3 Evaluation Metrics

We used two primary metrics to assess the system's performance:

1. **Recognition Accuracy (RA):** Audio attack detection can be treated as a binary classification problem. Recognition accuracy is defined as the percentage of audio samples that are correctly classified.
2. **Equal Error Rate (EER):** EER is a widely used metric for evaluating replay attack detection systems [32]. It is the point at which the false acceptance rate (FAR) and the false rejection rate (FRR) are approximately equal.

### 7.1.4 Baseline Models

We compared our results with four state-of-the-art baseline models for replay attack detection:

1. **Gong et al. [23]:** A multi-channel replay attack network that includes a learnable filter-and-sum beamformer, a frequency convolution layer, and multiple stacked LSTM layers for classification.
2. **CQT-LCNN [54]:** A single-channel model that uses the log power magnitude spectrum extracted via the constant Q transform (CQT) [66] as features and a light convolutional network (LCNN) [63] as the classifier. This model achieved an EER of 1.23% in the ASVspoof2019 Physical Access (PA) [60] scenario, which can be improved to 0.54% (ranking 2nd place) with score-level fusion using other front-end features.
3. **LFCC-LCNN [62]:** A single-channel-based model that adopts linear frequency cepstral coefficients (LFCC) as the front end and LCNN as the back-end classifier. This model serves as the official baseline for the ASVspoof2021 challenge [6].
4. **RawNet2 [59]:** A single-channel model that aims to eliminate the need for hand-crafted features by training an end-to-end CNN-GRU network with a sinc-convolution layer [56] to extract useful cues directly from raw audio waveforms. SVM-based fusion of RawNet2 and high-spectral-resolution LFCC [58] can achieve an EER as low as 1.12%, ranking 2nd best in the ASVspoof2019 Logical Access (LA) scenario.

### 7.2 Overall System Performance for Replay Attack

We first evaluated the overall performance of the proposed system on replay attacks using the public ReMASC dataset. For a fair comparison, we used the same default data separation scheme suggested in the original paper [22] for all baseline methods and developed a separate model for each recording device, as done by Gong et al. [23].

For the Type II network, we used a width multiplier of \(\alpha = 1\) for devices 1 and 2, and \(\alpha = 1.5\) for devices 3 and 4. Each model was trained with a batch size of 32 for 100 epochs, using the same learning rate scheduling strategy. The initial learning rate was set to \(1 \times 10^{-3}\) for our Type II models and \(1 \times 10^{-5}\) for other models. We implemented all baseline methods and compared the experimental results with the proposed models in Table 4. By default, we used the signals collected from the first channel for the training of single-channel-based models. For the beamforming-based network proposed by Gong et al. [23], we reported its best results from the original paper (RA is not shown since it has not been reported).

From the results, we observed that RawNet2 achieved the overall best performance among all single-channel-based methods, even outperforming the multi-channel beamforming-based network proposed by Gong et al. [23] for recording device 1 with 2 channels. However, in general, multi-channel-based methods still outperformed single-channel-based methods, with the performance gain becoming more pronounced as the number of available channels increased. The proposed Type I network consistently achieved better EERs, with reductions of 20% to 55% compared to the existing beamforming-based network. The Type II network also reduced the EER by up to 31% compared to the beamforming-based network. These results confirm that utilizing magnitude and phase information from all available channels can lead to better performance in audio attack detection.

### Inference Time

Inference time is critical for real-time detection. To investigate the inference time of our models, we ran experiments on an Nvidia 2080Ti GPU with a batch size of 16 and repeated the trials 100 times to measure the average inference time. The results showed that the proposed Type I model took 36.5 ms, while the Type II model took only 23.3 ms. Compared to the latency of commercial speaker recognition models [52] (~40 ms) and speech recognition models [61] (~600 ms), the latency of the proposed detection model is sufficient for timely detection of various types of audio attacks in real-time applications.

### Model Size

For desktop or cloud applications with sufficient storage and computational resources, performance is often prioritized over model size. However, for mobile and embedded applications, the model size must be small enough to match resource constraints (e.g., memory, computational resources, and power consumption). The model size of our Type I network is approximately 479 MB, suitable for most desktop or cloud applications. For the Type II network, the model size is 18 MB with \(\alpha = 1\) and 40 MB with \(\alpha = 1.5\). This demonstrates that the proposed Type II network is extremely lightweight while retaining sufficient representation power to achieve high attack detection accuracy.

### 7.3 Environment-Independent Detection

In addition to evaluating the overall performance of the model by training on a mixture of data samples from all environments, we also assessed the model in environment-independent conditions. Specifically, we set one of the four environments as the target domain for testing, while the remaining three environments served as the source domain for training. We set \(\lambda = 0.33\) and used the optimization techniques mentioned in Section 4.4 to train the models. To validate the effectiveness of the domain adaptation (DA) training procedure, we compared the performance of our Type I model with DA to the performance of the model without DA in Table 5. The results of the multi-channel beamforming-based network [23] are also shown for comparison. Additionally, we compared the results of our models with single-channel-based methods using the data recorded from Device 2 in Table 6.

From the results, we observed that models trained on data from source environments generally had low generalizability to new environments. Specifically, Env-D (the in-vehicle environment) was the most challenging environment for the model to generalize. This is due to the unique acoustic features of the in-vehicle setting, such as loud road and engine noises and strong reverberations caused by the narrow cabin. As shown in Table 6, except for RawNet2, which achieved an EER of 26.4% in Env-B, all single-channel-based methods performed poorly in the environment-independent scenario (EER > 30%). Despite this, leveraging the domain adaptation process, the proposed network was able to reduce the EER by up to 42.2%, achieving an average EER of 21.8%, which is much lower than the beamforming-based network (33.8%) and the proposed network (30.3%) without applying domain adaptation.

### 7.4 Robustness Against Other Advanced Attacks

In this section, we expanded the evaluation of the system's robustness to include other advanced audio attacks using the self-collected dataset described in Section 7.1.2. We randomly split the collected audio attack samples into training and test sets, with 60% of the samples used for training and 40% reserved for testing, similar to the train/test split ratio used in the ReMASC dataset. The separated datasets were then merged with the audio samples from the ReMASC dataset, resulting in a total of 9596, 10260, and 9931 samples for training and 5816, 7295, and 6951 samples for testing, for devices 1, 2, and 3, respectively.

Table 7 compares the results of the proposed model with the baseline models. When considering all six types of audio attacks, the performance of most models degraded compared to those trained exclusively for detecting replay attacks, due to the highly varying behaviors of the advanced audio attacks. The proposed Type I network, however, achieved the best performance among the baseline models, with an overall average EER of 12.9% across all three devices. Despite its compact model size, the proposed Type II network also achieved relatively high recognition accuracy and low EER, surpassing existing single- and multi-channel-based models in most cases.