### Relationships Among AST Subtrees

TreeFuzz [41] is another model-based fuzzer. Its model is constructed based on the frequencies of co-occurring nodes and edges in given AST examples. However, its method for generating tests is not directly applicable to state-of-the-art language models, which are typically designed to handle word sequences rather than node and edge relationships in ASTs.

Recently, Aschermann et al. [2] and Blazytko et al. [6] introduced NAUTILUS and GRIMOIRE, respectively. Both fuzzers are designed to test programs that accept highly structured inputs by leveraging code coverage. NAUTILUS generates new JavaScript (JS) tests based on a provided grammar and checks if they achieve new code coverage, enabling further mutation. In contrast, GRIMOIRE does not require user-provided components such as grammar specifications or language models; instead, it synthesizes inputs that trigger new code coverage. According to the authors, GRIMOIRE struggles with generating inputs that have complex structures, as it lacks semantic information.

### Previous Studies on Mutational Fuzzing

Previous studies on mutational fuzzing [7, 18, 24, 32, 44, 54, 57, 58] have focused on altering given seeds to exploit functionalities already tested by those seeds.

LangFuzz [24] is a mutational fuzzing tool that substitutes non-terminal nodes in a given AST with code fragments. It iteratively replaces non-terminal nodes during the insertion process. However, LangFuzz does not consider the context when selecting promising candidates that could cause a target JS engine to crash. In contrast, Montage can learn implicit relationships between fragments that may be inherent in the given examples.

Liu et al. [32] proposed a mutation-based approach for fuzzing a target program. They trained a sequence-to-sequence model on a large corpus of C code to capture the inherent patterns at the character level. The trained model was then used to mutate the seed. Their approach has the limitation of generating many malformed tests, such as unbalanced parentheses.

### Language Models for Code

Hindle et al. [22] measured the naturalness of software by computing cross-entropy values over lexical code tokens in large Java and C applications. They also demonstrated that even count-based n-gram language models can be applied to code completion. To improve the accuracy of code completion suggestions, SLAMC [40] incorporated semantic information, including type, scope, and role for each lexical token. SLANG [43] allows a model to learn API call sequences from Android applications, using this model to enhance the precision of code completion. GraLan learns the relationships between API calls from the graph of API call sequences, and ASTLan uses GraLan to fill holes in the AST to complete the code [39].

Maddison et al. [33] studied generative models of natural source code based on Probabilistic Context-Free Grammars (PCFGs) and source code-specific structures. Bielik et al. [5] suggested a new generative probabilistic model of code called a probabilistic higher-order grammar, which generalizes PCFGs and parameterizes production rules based on context.

The objective of using a language model in these works is to provide better suggestions for code completion. However, Montage focuses on generating JS tests that should be accepted by a target JS engine.

### Conclusion

We present Montage, the first fuzzing tool that leverages a Neural Network Language Model (NNLM) to generate JS tests. We propose a novel algorithm for modeling the hierarchical structures of a JS test case and the relationships among these structures into a sequence of fragments. This encoding of an AST into a fragment sequence enables Montage to learn the relationships among the fragments using an LSTM model. Montage has discovered 37 real-world bugs in the latest JS engines, demonstrating its effectiveness in finding JS engine bugs.

### Acknowledgements

We thank the anonymous reviewers for their valuable feedback and Yale Song for his contributions to the development of some of the ideas in this paper. We are also grateful to Jihoon Kim for sharing his findings, which inspired our project. Finally, we thank Sunnyeo Park for collecting the JS seeds used for evaluation. This work was partially supported by (1) the Institute for Information & Communications Technology Promotion (IITP) grant funded by the Korea government (MSIT), No. 2018-0-00254, and (2) LIG Nex1.

### References

[1] Ebru Arisoy, Tara N. Sainath, Brian Kingsbury, and Bhuvana Ramabhadran. Deep neural network language models. In Proceedings of the NAACL-HLT 2012 Workshop, pages 20–28, 2012.

[2] Cornelius Aschermann, Patrick Jauernig, Tommaso Frassetto, Ahmad-Reza Sadeghi, Thorsten Holz, and Daniel Teuchert. NAUTILUS: Fishing for deep bugs with grammars. In Proceedings of the Network and Distributed System Security Symposium, 2019.

[5] Pavol Bielik, Veselin Raychev, and Martin Vechev. PHOG: Probabilistic model for code. In Proceedings of the International Conference on Machine Learning, pages 2933–2942, 2016.

[6] Tim Blazytko, Cornelius Aschermann, Moritz Schlögel, Ali Abbasi, Sergej Schumilo, Simon Wörner, and Thorsten Holz. GRIMOIRE: Synthesizing structure while fuzzing. In Proceedings of the USENIX Security Symposium, pages 1985–2002, 2019.

[7] Sang Kil Cha, Maverick Woo, and David Brumley. Program-adaptive mutational fuzzing. In Proceedings of the IEEE Symposium on Security and Privacy, pages 725–741, 2015.

[8] Stanley F. Chen and Joshua Goodman. An empirical study of smoothing techniques for language modeling. In Proceedings of the 34th Annual Meeting on Association for Computational Linguistics, pages 310–318, 1996.

[9] Yang Chen, Alex Groce, Chaoqiang Zhang, Weng-Keen Wong, Xiaoli Fern, Eric Eide, and John Regehr. Taming compiler fuzzers. In Proceedings of the ACM Conference on Programming Language Design and Implementation, pages 197–208, 2013.

[10] Microsoft Corporation. Microsoft ChakraCore. https://github.com/Microsoft/ChakraCore.

[11] Chris Cummins and Alastair Murray. Compiler fuzzing through deep learning. In Proceedings of the ACM International Symposium on Software Testing and Analysis, pages 95–105, 2018.

[12] Kyle Dewey, Jared Roesch, and Ben Hardekopf. Language fuzzing using constraint logic programming. In Proceedings of the International Conference on Automated Software Engineering, pages 725–730, 2014.

[13] Technical Committee 39 ECMA International. Test262. https://github.com/tc39/test262.

[14] Felix A. Gers, Jürgen Schmidhuber, and Fred Cummins. Learning to forget: Continual prediction with LSTM. Neural Computation, 12:2451–2471, 1999.

[3] Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and Christian Janvin. A neural probabilistic language model. The Journal of Machine Learning Research, 3(1):1137–1155, 2003.

[15] Patrice Godefroid, Adam Kiezun, and Michael Y. Levin. Grammar-based whitebox fuzzing. In Proceedings of the ACM Conference on Programming Language Design and Implementation, pages 206–215, 2008.

[4] Yoshua Bengio, Patrice Simard, and Paolo Frasconi. Learning long-term dependencies with gradient descent is difficult. Transactions on Neural Networks, 5(2):157–166, 1994.

[16] Patrice Godefroid, Hila Peleg, and Rishabh Singh. Learn&Fuzz: Machine learning for input fuzzing. In Proceedings of the International Conference on Automated Software Engineering, pages 50–59, 2017.

[17] Joshua T. Goodman. A bit of progress in language modeling. Computer Speech & Language, 15(4):403–434, 2001.

[18] Tao Guo, Puhan Zhang, Xin Wang, and Qiang Wei. GramFuzz: Fuzzing testing of web browsers based on grammar analysis and structural mutation. In Proceedings of the International Conference on Informatics Applications, pages 212–215, 2013.

[19] HyungSeok Han and Sang Kil Cha. IMF: Inferred model-based fuzzer. In Proceedings of the ACM Conference on Computer and Communications Security, pages 2345–2358, 2017.

[20] HyungSeok Han, DongHyeon Oh, and Sang Kil Cha. CodeAlchemist: Semantics-aware code generation to find vulnerabilities in JavaScript engines. In Proceedings of the Network and Distributed System Security Symposium, 2019.

[21] Ariya Hidayat. ECMAScript parsing infrastructure for multipurpose analysis. https://www.esprima.org.

[22] Abram Hindle, Earl T. Barr, Zhendong Su, Mark Gabel, and Premkumar Devanbu. On the naturalness of software. In Proceedings of the International Conference on Software Engineering, pages 837–847, 2012.

[23] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735–1780, 1997.

[24] Christian Holler, Kim Herzig, and Andreas Zeller. Fuzzing with code fragments. In Proceedings of the USENIX Security Symposium, pages 445–458, 2012.

[25] BuzzFeed Inc. Markovify. https://github.com/jsvine/markovify.

[26] Theori Inc. pwn.js. https://github.com/theori-io/pwnjs, 2017.

[27] ECMA International. ECMAScript language specification. https://www.ecma-international.org/ecma-262/.

[28] Dave Jones. Trinity. https://github.com/kernelslacker/trinity.

[29] Rafal Józefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling. CoRR, abs/1602.02410, 2016.

[31] George Klees, Andrew Ruef, Benji Cooper, Shiyi Wei, and Michael Hicks. Evaluating fuzz testing. In Proceedings of the ACM Conference on Computer and Communications Security, pages 2123–2138, 2018.

[32] Xiao Liu, Xiaoting Li, Rupesh Prajapati, and Dinghao Wu. DeepFuzz: Automatic generation of syntax valid C programs for fuzz testing. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 1044–1051, 2019.

[33] Chris J. Maddison and Daniel Tarlow. Structured generative models of natural source code. In Proceedings of the International Conference on Machine Learning, pages 649–657, 2016.

[34] Tomáš Mikolov, Martin Karaﬁát, Lukáš Burget, Jan Černocký, and Sanjeev Khudanpur. Recurrent neural network based language model. In Proceedings of the 11th Annual Conference of the International Speech Communication Association, pages 1045–1048, 2010.

[35] Matt Molinyawe, Abdul-Aziz Hariri, and Jasiel Spelman. $hell on Earth: From browser to system compromise. In Proceedings of the Black Hat USA, 2016.

[36] David Molnar, Xue Cong Li, and David A. Wagner. Dynamic test generation to find integer bugs in x86 binary Linux programs. In Proceedings of the USENIX Security Symposium, pages 67–82, 2009.

[37] Mozilla. Hoisting. https://developer.mozilla.org/en-US/docs/Glossary/Hoisting.

[38] MozillaSecurity. funfuzz. https://github.com/MozillaSecurity/funfuzz.

[39] Anh Tuan Nguyen and Tien N. Nguyen. Graph-based statistical language model for code. In Proceedings of the International Conference on Software Engineering, pages 858–868, 2015.

[40] Tung Thanh Nguyen, Anh Tuan Nguyen, Hoan Anh Nguyen, and Tien N. Nguyen. A statistical semantic language model for source code. In Proceedings of the International Symposium on Foundations of Software Engineering, pages 532–542, 2013.

[41] Jibesh Patra and Michael Pradel. Learning to fuzz: Application-independent fuzz testing with probabilistic, generative models of input data. Technical Report TUD-CS-2016-14664, TU Darmstadt, 2016.

[30] Yoon Kim, Yacine Jernite, David Sontag, and Alexander M. Rush. Character-aware neural language models. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 2741–2749, 2016.

[42] Van-Thuan Pham, Marcel Böhme, and Abhik Roychoudhury. Model-based whitebox fuzzing for program binaries. In Proceedings of the International Conference on Automated Software Engineering, pages 543–553, 2016.

[43] Veselin Raychev, Martin Vechev, and Eran Yahav. Code completion with statistical language models. In Proceedings of the ACM Conference on Programming Language Design and Implementation, pages 419–428, 2014.

[44] Alexandre Rebert, Sang Kil Cha, Thanassis Avgerinos, Jonathan Foote, David Warren, Gustavo Grieco, and David Brumley. Optimizing seed selection for fuzzing. In Proceedings of the USENIX Security Symposium, pages 861–875, 2014.

[45] Jesse Ruderman. Releasing jsfunfuzz and domfuzz. http://www.squarefree.com/2015/07/28/releasing-jsfunfuzz-and-domfuzz/, 2007.

[46] Joeri De Ruiter and Erik Poll. Protocol state fuzzing of TLS implementations. In Proceedings of the USENIX Security Symposium, pages 193–206, 2015.

[47] Juraj Somorovsky. Systematic fuzzing and testing of TLS libraries. In Proceedings of the ACM Conference on Computer and Communications Security, pages 1492–1504, 2016.

[48] Aditya K. Sood and Sherali Zeadally. Drive-by download attacks: A comparative study. IT Professional, 18(5):18–25, 2016.

[49] Alexander Sotirov. Heap feng shui in JavaScript. In Proceedings of the Black Hat USA, 2007.

[50] Michael Sutton, Adam Greene, and Pedram Amini. Fuzzing: Brute Force Vulnerability Discovery. Addison-Wesley Professional, 2007.

[52] PyTorch Core Team. Pytorch. https://pytorch.org/.

[53] Zhaopeng Tu, Zhendong Su, and Premkumar Devanbu. On the localness of software. In Proceedings of the International Symposium on Foundations of Software Engineering, pages 269–280, 2014.

[54] Spandan Veggalam, Sanjay Rawat, Istvan Haller, and Herbert Bos. IFuzzer: An evolutionary interpreter fuzzer using genetic programming. In Proceedings of the European Symposium on Research in Computer Security, pages 581–601, 2016.

[55] Dmitry Vyukov. syzkaller. https://github.com/google/syzkaller.

[56] Junjie Wang, Bihuan Chen, Lei Wei, and Yang Liu. Skyfire: Data-driven seed generation for fuzzing. In Proceedings of the IEEE Symposium on Security and Privacy, pages 579–594, 2017.

[57] Maverick Woo, Sang Kil Cha, Samantha Gottlieb, and David Brumley. Scheduling black-box mutational fuzzing. In Proceedings of the ACM Conference on Computer and Communications Security, pages 511–522, 2013.

[58] Michal Zalewski. American Fuzzy Lop. http://lcamtuf.coredump.cx/afl/.

[51] Yusuke Suzuki. Escodegen. https://www.npmjs.com/package/escodegen.

[59] ZERODIUM. Zerodium payouts. https://zerodium.com/program.html.