### Literature Review and Comparison

#### Previous Studies
- **Benenson et al. [7]**: Investigated the effectiveness of spear phishing attacks, focusing on the content rather than the scaffolding to deceive. Their study aimed to differentiate between genuine and fraudulent emails.
- **Dhamija et al. [20]**: Explored why phishing works, emphasizing that users can manage known risks but struggle with unfamiliar ones. This suggests that professional social networks like LinkedIn are often perceived as legitimate, making users more susceptible to phishing.
- **Halevi et al. [30]**: Conducted a pilot study on the relationship between personality traits and cybersecurity behavior, finding that certain traits can influence susceptibility to phishing.

#### Our Study
- **Reasoning**: We examined the strategies participants used to differentiate between legitimate and fraudulent emails and the impact of various demographic factors on their performance.
- **Spear Phishing**: We focused on targeted phishing attacks, including the use of recipients' names and basic information about the sender to increase the success rate of the attack.
- **Facade**: We analyzed the effect of mimicking professional email structures and the role of background knowledge, experience, occupation, and platform (mobile vs. PC) on participants' performance.

**Significant Effects**:
- **Reasoning**: Participants who paid attention to specific clues performed better in detecting phishing attempts.
- **Spear Phishing**: Including personalized information in the emails increased the success rate of the attacks by 10%.
- **Facade**: Professional email structures and the use of familiar scaffolding significantly affected participants' ability to detect phishing.

### Methodology and Results

- **Task**: Participants were asked to label four representative offers (with different parameters) as legitimate or fraudulent. Only 26% of participants correctly identified all four offers.
- **Techniques**: We used Recursive Transition Networks (RTNs) to generate fraudulent emails, which were indistinguishable from human-written emails.
- **Correlation Analysis**: There was a significant correlation between the clues participants noticed and their performance in detecting phishing attacks.

### Conclusion

- **Key Findings**: The study demonstrated that even well-known attacks, such as company representative fraud, can still deceive a significant number of people. Personalized information and professional email structures increased the success rate of phishing attacks.
- **Training Programs**: To reduce susceptibility, training programs should focus on younger adults and mobile users, and adapt materials to address spear phishing attacks. Customizing these approaches based on users' behavior and habitual patterns can further enhance their effectiveness.

### Acknowledgments

This research was supported by NSF grants DUE 1356705, DGE 1433817, and CNS 1319212, and US ARO grant W911NF-16-1-0422. Special thanks to Arjun Mukherjee for his valuable suggestions on Natural Language Generation techniques.

### References

[1] Ayman El Aassal, Shahryar Baki, Avisha Das, and Rakesh M. Verma. 2020. An In-Depth Benchmarking and Evaluation of Phishing Detection Research for Security Needs. IEEE Access 8 (2020), 22170–22192.

[2] Tahani Albalawi, Kambiz Ghazinour, and Austin Melton. 2019. That’s how I feel: A Study of User’s Security Mental Model. In Proc. of the Int’l Conf. on Security and Management (SAM). The Steering Committee of The World Congress in Computer Science, Computer, Springer, Las Vegas, USA, 115–122.

[3] Zafer Alqarni, Abdullah Algarni, and Yue Xu. 2016. Toward Predicting Susceptibility to Phishing Victimization on Facebook. In 2016 IEEE International Conference on Services Computing (SCC). IEEE, San Francisco, CA, USA, 419–426.

[4] Leila Bahri, Barbara Carminati, and Elena Ferrari. 2016. Coip–continuous, operable, impartial, and privacy-aware identity validity estimation for osn profiles. ACM Trans. Web 10, 4, Article 23 (Dec. 2016), 41 pages. https://doi.org/10.1145/3014338

[5] Shahryar Baki, Rakesh Verma, Arjun Mukherjee, and Omprakash Gnawali. 2017. Scaling and Effectiveness of Email Masquerade Attacks: Exploiting Natural Language Generation. In Proceedings of the 2017 ACM on Asia CCS. ACM, New York, NY, USA, 469–482.

[6] Shahryar Baki, Rakesh M. Verma, Arjun Mukherjee, and Omprakash Gnawali. 2020. Less is More: Exploiting Social Trust to Increase the Effectiveness of a Deception Attack. arXiv:cs.CR/2006.13499

[7] Zinaida Benenson, Freya Gassmann, and Robert Landwirth. 2017. Unpacking Spear Phishing Susceptibility. In Financial Cryptography and Data Security, Michael Brenner, Kurt Rohloff, Joseph Bonneau, Andrew Miller, Peter Y.A. Ryan, Vanessa Teague, Andrea Bracciali, Massimiliano Sala, Federico Pintore, and Markus Jakobsson (Eds.). Springer International Publishing, Cham, 610–627.

[8] Zinaida Benenson, Anna Girard, Nadina Hintz, and Andreas Luder. 2014. Susceptibility to URL-based Internet attacks: Facebook vs. email. In 2014 IEEE Int’l Conf. on Pervasive Computing & Communication Workshops (PERCOM WORKSHOPS). IEEE, Budapest, Hungary, 604–609. https://doi.org/10.1109/PerComW.2014.6815275

[9] Leyla Bilge, Thorsten Strufe, Davide Balzarotti, and Engin Kirda. 2009. All Your Contacts Are Belong to Us: Automated Identity Theft Attacks on Social Networks. In Proceedings of the 18th International Conference on World Wide Web (WWW ’09). ACM, New York, NY, USA, 551–560. https://doi.org/10.1145/1526709.1526784

[10] Andrew C Bulhak. 1996. On the simulation of postmodernism and mental debility using recursive transition networks. Technical Report. Monash University.

[11] Andrew C Bulhak. 2000. The Dada engine. dev.null.org/dadaengine/

[12] Better Business Bureau. 2019. Scam Alert: Employment Scams Target College Students. https://www.bbb.org/article/news-releases/20710-scam-alert-employment-scams-target-college-students

[13] Marcus Butavicius, Kathryn Parsons, Malcolm Pattinson, and Agata McCormac. 2016. Breaching the Human Firewall: Social engineering in Phishing and Spear-Phishing Emails. arXiv:cs.CY/1606.00887

[14] Casey Inez Canfield, Baruch Fischhoff, and Alex Davis. 2019. Better beware: comparing metacognition for phishing and legitimate emails. Metacognition and Learning 14, 3 (2019), 343–362. https://doi.org/10.1007/s11409-019-09197-5

[15] Jin-Hee Cho, Hasan Cam, and Alessandro Oltramari. 2016. Effect of personality traits on trust and risk to phishing vulnerability: Modeling and analysis. In 2016 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA). IEEE, San Diego, CA, USA, 7–13.

[16] Morshed U Chowdhury, Jemal H Abawajy, Andrei V Kelarev, and T Hochin. 2017. Multilayer hybrid strategy for phishing email zero-day filtering. Concurrency and Computation: Practice and Experience 29, 23 (2017), e3929.

[17] A. Das, S. Baki, A. El Aassal, R. Verma, and A. Dunbar. 2020. SoK: A Comprehensive Reexamination of Phishing Research From the Security Perspective. IEEE Communications Surveys Tutorials 22, 1 (2020), 671–708.

[18] Avisha Das and Rakesh Verma. 2019. Automated email Generation for Targeted Attacks using Natural Language. arXiv:1908.06893

[19] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv:cs.CL/1810.04805

[20] Rachna Dhamija, J. D. Tygar, and Marti Hearst. 2006. Why Phishing Works. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ’06). ACM, New York, NY, USA, 581–590. https://doi.org/10.1145/1124772.1124861

[21] Julie S. Downs, Mandy B. Holbrook, and Lorrie Faith Cranor. 2006. Decision Strategies and Susceptibility to Phishing. In Proceedings of the Second Symposium on Usable Privacy and Security (SOUPS ’06). ACM, New York, NY, USA, 79–90.

[22] Yvonne D Eaves. 2001. A synthesis technique for grounded theory data analysis. Journal of advanced nursing 35, 5 (2001), 654–663.

[23] G. Egozi and R. Verma. 2018. Phishing Email Detection Using Robust NLP Techniques. In 2018 IEEE International Conference on Data Mining Workshops (ICDMW). IEEE, Singapore, 7–12.

[24] Ayman El Aassal and Rakesh Verma. 2019. Spears Against Shields: Are Defenders Winning the Phishing War?. In Proc. 5th ACM International Workshop on Security and Privacy Analytics (IWSPA). ACM, Richardson, Texas, USA, 15–24.

[25] Yong Fang, Cheng Zhang, Cheng Huang, Liang Liu, and Yue Yang. 2019. Phishing email detection using improved RCNN model with multilevel vectors and attention mechanism. IEEE Access 7 (2019), 56329–56340.

[26] Shane Frederick. 2005. Cognitive reflection and decision making. Journal of Economic perspectives 19, 4 (2005), 25–42.

[27] Jack Jen Gieseking. 2013. Where we go from here: the mental sketch mapping method and its analytic components. Qualitative Inquiry 19, 9 (2013), 712–724.

[28] Robert Greszki, Marco Meyer, and Harald Schoen. 2014. The impact of speeding on data quality in nonprobability and freshly recruited probability-based online panels. John Wiley & Sons, Ltd, Chichester, UK, Chapter 11, 238–262. https://doi.org/10.1002/9781118763520.ch11

[29] Anti-Phishing Working Group. 2019. Phishing activity trends reports. https://apwg.org/trendsreports/

[30] Tzipora Halevi, James Lewis, and Nasir Memon. 2013. A pilot study of cyber security and privacy related behavior and personality traits. In Proc. of 22nd WWW Conf. (WWW ’13 Companion). ACM, New York, NY, USA, 737–744.

[31] Tzipora Halevi, Nasir Memon, and Oded Nov. 2015. Spear-phishing in the wild: A real-world study of personality, phishing self-efficacy and vulnerability to spear-phishing attacks. Phishing Self-Efficacy and Vulnerability to Spear-Phishing Attacks (January 2, 2015) (2015).

[32] Bing-Zhe He, Chien-Ming Chen, Yi-Ping Su, and Hung-Min Sun. 2014. A defence scheme against identity theft attack based on multiple social networks. Expert Systems with Applications 41, 5 (2014), 2345–2352.

[33] Amir Herzberg. 2009. Combining authentication, reputation and classification to make phishing unprofitable. In Emerging Challenges for Security, Privacy and Trust, Dimitris Gritzalis and Javier Lopez (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 13–24.

[34] Markus Huber, Martin Mulazzani, Edgar Weippl, Gerhard Kitzler, and Sigrun Goluch. 2011. Friend-in-the-middle attacks: Exploiting social networking sites for spam. IEEE Internet Computing 15, 3 (2011), 28–34.

[35] Danesh Irani, Marco Balduzzi, Davide Balzarotti, Engin Kirda, and Calton Pu. 2011. Reverse social engineering attacks in online social networks. In Detection of Intrusions and Malware, and Vulnerability Assessment, Thorsten Holz and Herbert Bos (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 55–74.

[36] Lei Jin, Hassan Takabi, and James B.D. Joshi. 2011. Towards active detection of identity clone attacks on online social networks. In Proceedings of the First ACM CODASPY. ACM, New York, NY, USA, 27–38.

[37] Oliver P John and Sanjay Srivastava. 1999. The Big Five trait taxonomy: History, measurement, and theoretical perspectives. Handbook of personality: Theory and research 2, 1999 (1999), 102–138.

[38] A Karakasiliotis, SM Furnell, and M Papadaki. 2006. Assessing end-user awareness of social engineering and phishing. In Australian Information Warfare and Security Conference. School of Computer and Information Science, Edith Cowan University, Perth, Western Australia, Perth, Western Australia.

[39] Eleftherios Karavaras, Emmanouil Magkos, and Aggeliki Tsohou. 2016. Low use awareness against social malware: an empirical study and design of a security awareness application. In 13th European Mediterranean and Middle Eastern Conference on Information Systems, Vol. 13. Cracow, Poland, 1–10.

[40] Paul J Lavrakas. 2008. Encyclopedia of survey research methods. Sage Publications, Los Angeles, London, New Delhi, Singapore, Washington DC.

[41] Tian Lin, Daniel E. Capecci, Donovan M. Ellis, Harold A. Rocha, Sandeep Dommaraju, Daniela S. Oliveira, and Natalie C. Ebner. 2019. Susceptibility to spear-phishing emails: Effects of internet user demographics and email content. ACM Trans. Comput.-Hum. Interact. 26, 5, Article 32 (July 2019), 28 pages.

[42] Shah Mahmood and Yvo Desmedt. 2012. Your facebook deactivated friend or a cloaked spy. In Pervasive Computing and Communications Workshops (PER-COM Workshops), 2012 IEEE International Conference on. IEEE, IEEE, Lugano, Switzerland, 367–373.

[43] KC Meijdam, W Pieters, and J van den Berg. 2015. Phishing as a service: Designing an ethical way of mimicking targeted phishing attacks to train employees. TU Delft, TU Delft.

[44] María M Moreno-Fernández, Fernando Blanco, Pablo Garaizar, and Helena Matute. 2017. Fishing for phishers. Improving Internet users’ sensitivity to visual deception cues to prevent electronic fraud. Computers in Human Behavior 69 (2017), 421–436.

[45] Ajaya Neupane, Md. Lutfor Rahman, Nitesh Saxena, and Leanne Hirshfield. 2015. A multi-modal neuro-physiological study of phishing detection and malware warnings. In Proc. of the 22nd CCS. ACM, New York, NY, USA, 479–491.

[46] Information Security Office. 2019. FBI Alert: Employment Scam Targeting Students. https://informationsecurity.princeton.edu/news/fbi-alert-employment-scam-targeting-students

[47] Information Security Office. 2019. PHISH BOWL/PHISHING SCAMS. https://www.it.ucla.edu/security/alerts/phishing-scams

[48] PhishLabs. 2017. Q2 2017 Phishing Trends & Intelligence Report. https://info.phishlabs.com/q2_2017_phishing_trends_and_-intelligence_report

[49] PhishLabs. 2018. 2018 Phishing Trends & Intelligence Report. https://info.phishlabs.com/2018_phishing_trends_and_-intelligence_report-0

[50] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI Blog 1, 8 (2019).

[51] L. Schipper. 1969. Human information processing and decision-making. In 1969 IEEE Symposium on Adaptive Processes (8th) Decision and Control. IEEE, University Park, PA, USA, USA, 25–25. https://doi.org/10.1109/SAP.1969.269909

[52] Steve Sheng, Mandy Holbrook, Ponnurangam Kumaraguru, Lorrie Faith Cranor, and Julie Downs. 2010. Who falls for phish?: A demographic analysis of phishing susceptibility and effectiveness of interventions. In Proceedings of the CHI’10. ACM, New York, NY, USA, 373–382.

[53] Cong Tang, Keith Ross, Nitesh Saxena, and Ruichuan Chen. 2011. What’s in a name: A study of names, gender inference, and gender behavior in Facebook. In Database Systems for Adanced Applications, Jianliang Xu, Ge Yu, Shuigeng Zhou, and Rainer Unland (Eds.). Springer, Berlin, Heidelberg, 344–356.

[54] Radicati Team. 2019. Email Statistics Report, 2019-2023. https://www.radicati.com/?p=15792

[55] Rakesh M. Verma and David J. Marchette. 2019. Cybersecurity analytics. CRC Press LLC, Boca Raton, FL. https://books.google.com/books?id=zez3xwEACAAJ

[56] Arun Vishwanath. 2015. Diffusion of deception in social media: Social contagion effects and its antecedents. Information Systems Frontiers 17, 6 (2015), 1353–1367.

[57] Arun Vishwanath. 2015. Habitual Facebook use and its impact on getting deceived on social media. J. of Computer-Mediated Communication 20, 1 (2015), 83–98.

[58] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized autoregressive pretraining for language understanding. arXiv:cs.CL/1906.08237

[59] Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben Y Zhao, and Yafei Dai. 2014. Uncovering social network sybils in the wild. ACM TKDD) 8, 1 (2014), 2.