### Utility of Automatically Generated Answers

We assessed the utility of automatically generated answers under four different conditions: Retrieval, SemVec, PriBot, and Random. For each condition, we evaluated the top-3 responses to each question, resulting in an assessment of 360 answers for 120 questions per approach.

### Study Design

We employed a between-subjects design by creating four surveys, each corresponding to one of the evaluation conditions. Each survey presented a series of 17 QA pairs (each on a separate page). Out of these, 15 were randomly selected from a pool of 360 QA pairs, ensuring that no participant received two QA pairs with the same question. The remaining two questions served as attention checkers, placed at random positions. We enforced a minimum duration of 15 seconds for respondents to evaluate each QA pair, with no maximum time limit. Additionally, we included an open-ended Cloze reading comprehension test to filter out responses from participants with poor reading skills.

### Participant Recruitment

Following IRB approval, we recruited 700 Amazon MTurk workers with a previous success rate of over 95% to complete our survey. This ensured that each QA pair was evaluated by at least 7 different individuals. Each respondent was compensated with $2, and with an average completion time of 14 minutes, the average pay was around $8.6 per hour (US Federal minimum wage is $7.25). Our participant pool exhibited high intragroup diversity but little difference across groups. The average age of participants was 34 years (std=10.5), with 62% being male and 38% female. More than 82% of participants were from North America, more than 87% had some level of college education, and more than 88% reported being employed.

### QA Pair Evaluation

To evaluate the relevance of a QA pair, we displayed the question and candidate answer as shown in Fig. 11. Respondents rated the relevance of the candidate response on a 5-point Likert scale (1=Definitely Yes to 5=Definitely No). A response was considered relevant (irrelevant) if the respondent chose either "Definitely Yes" or "Partially Yes" ("Definitely No" or "Partially No"). We consolidated the evaluations of multiple users per answer using a methodology similar to that in [10], where an answer was deemed relevant if at least 50% of users labeled it as such. Generally, there was strong agreement among respondents, with highly mixed responses (45–55% of workers tagging the answer as relevant) occurring in less than 16% of cases.

### User Study Results

We computed the top-k score for relevance, which measures the proportion of questions with at least one user-relevant answer in the top k returned answers. Table 4 shows this score for the four QA approaches with k ∈ {1, 2, 3}. PriBot clearly outperformed the three baseline approaches. At least one of the top-3 answers was relevant for 89% of the questions, with the first answer being relevant in 70% of the cases. For k = 1, the scores were 46% and 48% for the Retrieval and SemVec models, respectively (p-value ≤ 0.05 according to pairwise Fisher's exact test, corrected with the Holm-Bonferroni method for multiple comparisons). There were some discrepancies between the predictive models' accuracy and the users' perceived quality, consistent with observations in recommender systems research [44]. For example, the top-k score metric for accuracy differed by 2%, -3%, and 6% with respect to the perceived relevance in the PriBot model. The smaller differences between the SemVec and Retrieval models in this study compared to Section 8.3 suggest that some users accepted answers that matched the question's topic, even if the details were irrelevant.

### Discussion

#### Limitations

Polisis may be limited by the privacy taxonomy used. Although the OPP-115 taxonomy covers a wide range of privacy practices [11], certain types of applications may not be fully captured. One mitigation is to use Polisis as an initial step to filter relevant data at a high level before applying additional, application-specific text processing. Another mitigation is to leverage Polisis' modularity by adding new categories/attributes and training them on relevant annotated datasets. Like any automated approach, Polisis can exhibit instances of misclassification, which should be accounted for in any application built on it. Using confidence scores, similar to Eq. (3), can convey the (un)certainty of a reported result. Lastly, Polisis is not guaranteed to be robust against adversarially constructed privacy policies. An adversary could include misleading statements in the policy, carefully crafted to confuse Polisis' classifiers.

#### Deployment

We provide three prototype web applications for end-users:
1. An application that visualizes different aspects of privacy policies, powered by Polisis annotations (available as a web application and a browser extension for Chrome and Firefox).
2. A chatbot implementation of PriBot for answering questions about privacy policies in a conversational interface.
3. An application for extracting privacy labels from several policies given their links.
These applications are available at https://pribot.org.

#### Legal Aspects

Polisis is not intended to replace legally binding privacy policies but offers a complementary interface for privacy stakeholders to easily inquire about the contents of a privacy policy. Following the trend of automation in legal advice [56], insurance claim resolution [57], and privacy policy presentation [58, 16], third parties such as automated legal services firms or regulators can deploy Polisis as a solution for their users. These parties should include a disclaimer specifying that the analysis is based on automatic methods and does not represent the actual service provider [59]. Companies and service providers can internally deploy an application similar to PriBot as an assistance tool for customer support agents handling privacy-related inquiries. This human-in-the-loop approach allows for a favorable trade-off between the utility of Polisis and its legal implications.

#### Privacy-Specificity of the Approach

Our approach is uniquely tailored to the privacy domain, both in terms of data and model hierarchy. However, we envision that similar applications with comparable needs could benefit from extensions of our approach, both at the classification and QA levels.

### Related Work

#### Privacy Policy Analysis

There have been numerous attempts to create easy-to-navigate and alternative presentations of privacy policies. Kelley et al. [32] studied the use of nutrition labels as a paradigm for displaying privacy notices, while others have proposed icons representing privacy policies [31, 62]. Standards like P3P [13] have been proposed to push service providers to encode privacy policies in a machine-readable format, but they have not been widely adopted. Polisis has the potential to automate the generation of many of these notices without relying on the respective parties to do it themselves.

Recently, researchers have explored the potential of automated analysis of privacy policies. Liu et al. [58] used deep learning to model the vagueness of words in privacy policies, and Zimmeck et al. [63] showed significant inconsistencies between app practices and their privacy policies via automated analysis. These studies, enabled by the release of the OPP-115 dataset [11], have largely focused on labeling policies with a few practices. Our work is the first to provide a generic system for the automated analysis of privacy policies, allowing for much more fine-grained annotation (up to 10 high-level and 122 fine-grained classes).

#### Evaluating the Compliance Industry

Regulators and researchers continuously scrutinize the practices of the privacy compliance industry [21, 38, 39]. Miyazaki and Krishnamurthy [21] found no evidence that participating in a seal program indicates adherence to privacy practice standards. The FTC has also found discrepancies between companies' reported behaviors in their privacy policies and the privacy seals they have been granted [39]. Polisis can be used by these researchers and regulators to automatically and continuously perform such checks at scale, providing initial evidence that can be processed by skilled experts, thus reducing analysis time and cost.

#### Automated Question Answering

Our QA system, PriBot, focuses on non-factoid questions, which are typically complex and open-ended. Deep learning has yielded superior results to traditional retrieval techniques in this domain [51, 52, 66]. Our main contribution is building a QA system without a dataset that includes questions and answers, achieving results on par with the state of the art in other domains. We envision that our approach could be applied to other problems facing similar issues.

### Conclusion

We proposed Polisis, the first generic framework for detailed automatic analysis of privacy policies. It can assist users, researchers, and regulators in processing and understanding the content of privacy policies at scale. To build Polisis, we developed a new hierarchy of neural networks that extracts both high-level privacy practices and fine-grained information from privacy policies. Using this extracted information, Polisis enables several applications. In this paper, we demonstrated two applications: structured and free-form querying. In the first, we use Polisis' output to extract short notices from privacy policies in the form of privacy icons and to audit TRUSTe's policy analysis approach. In the second, we build PriBot, which answers users' free-form questions in real-time with high accuracy. Our evaluation of both applications reveals that Polisis matches the accuracy of expert analysis of privacy policies. Besides these applications, Polisis opens opportunities for further innovative privacy policy presentation mechanisms, including summarizing policies into simpler language and enabling comparative shopping applications that advise consumers on the privacy aspects of multiple applications.

### Acknowledgements

This research was partially funded by the Wisconsin Alumni Research Foundation and the US National Science Foundation under grant agreements CNS-1330596 and CNS-1646130.

### References

[1] F. H. Cate, “The limits of notice and choice,” IEEE Security & Privacy, vol. 8, no. 2, pp. 59–62, March 2010.
[2] Federal Trade Commission, “Protecting Consumer Privacy in an Era of Rapid Change,” March 2012.
[3] J. Gluck, F. Schaub, A. Friedman, H. Habib, N. Sadeh, L. F. Cranor, and Y. Agarwal, “How short is too short? Implications of length and framing on the effectiveness of privacy notices,” in Twelfth Symposium on Usable Privacy and Security (SOUPS 2016). Denver, CO: USENIX Association, 2016, pp. 321–340.
[4] A. M. McDonald and L. F. Cranor, “The cost of reading privacy policies,” ISJLP, vol. 4, p. 543, 2008.
[5] President’s Council of Advisors on Science and Technology, “Big data and privacy: A technological perspective. Report to the President, Executive Office of the President,” May 2014.
[6] F. Schaub, R. Balebako, and L. F. Cranor, “Designing effective privacy notices and controls,” IEEE Internet Computing, vol. 21, no. 3, pp. 70–77, 2017.
[7] Federal Trade Commission, “Internet of Things, Privacy & Security in a Connected World,” Jan. 2015.
[8] F. Schaub, R. Balebako, A. L. Durity, and L. F. Cranor, “A design space for effective privacy notices,” in Eleventh Symposium On Usable Privacy and Security (SOUPS 2015). Ottawa: USENIX Association, 2015, pp. 1–17.
[9] A. Rao, F. Schaub, N. Sadeh, A. Acquisti, and R. Kang, “Expecting the unexpected: Understanding mismatched privacy expectations online,” in Twelfth Symposium on Usable Privacy and Security (SOUPS 2016). Denver, CO: USENIX Association, 2016, pp. 77–96.
[10] S. Wilson, F. Schaub, R. Ramanath, N. Sadeh, F. Liu, N. A. Smith, and F. Liu, “Crowdsourcing annotations for websites’ privacy policies: Can it really work?” in Proceedings of the 25th International Conference on World Wide Web, ser. WWW ’16. Republic and Canton of Geneva, Switzerland: International World Wide Web Conferences Steering Committee, 2016, pp. 133–143.
[11] S. Wilson, F. Schaub, A. A. Dara, F. Liu, S. Cherivirala, P. G. Leon, M. S. Andersen, S. Zimmeck, K. M. Sathyendra, N. C. Russell, T. B. Norton, E. H. Hovy, J. R. Reidenberg, and N. M. Sadeh, “The creation and analysis of a website privacy policy corpus,” in Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers, 2016.
[12] U.S. Department of Commerce, “Privacy Shield Program Overview,” https://www.privacyshield.gov/Program-Overview, 2017, accessed: 10-01-2017.
[13] L. Cranor, Web Privacy with P3P. O’Reilly Media, Inc., 2002.
[14] P. G. Kelley, J. Bresee, L. F. Cranor, and R. W. Reeder, “A ‘nutrition label’ for privacy,” in Proceedings of the 5th Symposium on Usable Privacy and Security, ser. SOUPS ’09. New York, NY, USA: ACM, 2009, pp. 4:1–4:12.
[15] Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation), Official Journal of the European Union, vol. L119, pp. 1–88, May 2016.
[16] S. Zimmeck and S. M. Bellovin, “Privee: An architecture for automatically analyzing web privacy policies.” in USENIX Security, vol. 14, 2014.
[17] K. M. Sathyendra, S. Wilson, F. Schaub, S. Zimmeck, and N. Sadeh, “Identifying the provision of choices in privacy policy text,” in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 2017, pp. 2764–2769.
[18] Disconnect, “Privacy Icons,” https://web.archive.org/web/20170709022651/disconnect.me/icons, accessed: 07-01-2017.
[19] B. Edelman, “Adverse selection in online ‘trust’ certifications,” in Proceedings of the 11th International Conference on Electronic Commerce, ser. ICEC ’09. New York, NY, USA: ACM, 2009, pp. 205–212.
[20] T. Foremski, “TRUSTe responds to Facebook privacy problems...” http://www.zdnet.com/article/truste-responds-to-facebook-privacy-problems/, 2017, accessed: 2017-10-01.
[21] A. D. Miyazaki and S. Krishnamurthy, “Internet seals of approval: Effects on online privacy policies and consumer perceptions,” Journal of Consumer Affairs, vol. 36, no. 1, pp. 28–49, 2002.
[22] G. Glavaš, F. Nanni, and S. P. Ponzetto, “Unsupervised text segmentation using semantic relatedness graphs,” in *SEM 2016: The Fifth Joint Conference on Lexical and Computational Semantics: proceedings of the conference; August 11-12 2016, Berlin, Germany. Stroudsburg, Pa.: Association for Computational Linguistics, 2016, pp. 125–130.
[23] Y. Kim, “Convolutional neural networks for sentence classification,” in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, 2014, pp. 1746–1751.
[24] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, “Distributed representations of words and phrases and their compositionality,” in Advances in Neural Information Processing Systems, 2013, pp. 3111–3119.
[25] J. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors for word representation,” in Empirical Methods in Natural Language Processing (EMNLP), 2014, pp. 1532–1543.
[26] D. Tang, F. Wei, N. Yang, M. Zhou, T. Liu, and B. Qin, “Learning sentiment-specific word embedding for Twitter sentiment classification.” in ACL (1), 2014, pp. 1555–1565.
[27] N. Viennot, E. Garcia, and J. Nieh, “A measurement study of Google Play,” in ACM SIGMETRICS Performance Evaluation Review, vol. 42, no. 1. ACM, 2014, pp. 221–233.
[28] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching word vectors with subword information,” arXiv preprint arXiv:1607.04606, 2016.
[29] S. Bird and E. Loper, “NLTK: The Natural Language Toolkit,” in Proceedings of the ACL 2004 on Interactive poster and demonstration sessions. Association for Computational Linguistics, 2004, p. 31.
[30] D. Britz, “Understanding convolutional neural networks for NLP,” http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/, 2015, accessed: 01-01-2017.
[31] L. F. Cranor, P. Guduru, and M. Arjula, “User interfaces for privacy agents,” ACM Transactions on Computer-Human Interaction (TOCHI), vol. 13, no. 2, pp. 135–178, 2006.
[32] P. G. Kelley, J. Bresee, L. F. Cranor, and R. W. Reeder, “A nutrition label for privacy,” in Proceedings of the 5th Symposium on Usable Privacy and Security, ser. SOUPS ’09. New York, NY, USA: ACM, 2009, pp. 4:1–4:12.