### References

1. **Deep Learning**.  
   *SIGSAC Conference on Computer and Communications Security (CCS)*, pages 1310–1321. ACM, 2015.

2. **USENIX Association**  
   *29th USENIX Security Symposium*, pages 1305.  

3. **Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov**.  
   *Membership Inference Attacks Against Machine Learning Models*.  
   *Proceedings of the 2017 IEEE Symposium on Security and Privacy (S&P)*, pages 3–18. IEEE, 2017.  
   Referenced in: 2, 3, 13.

4. **Congzheng Song, Thomas Ristenpart, and Vitaly Shmatikov**.  
   *Machine Learning Models that Remember Too Much*.  
   *Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS)*, pages 587–601. ACM, 2017.  
   Referenced in: 13.

5. **Congzheng Song and Vitaly Shmatikov**.  
   *The Natural Auditor: How To Tell If Someone Used Your Words To Train Their Model*.  
   *CoRR abs/1811.00513*, 2018.  
   Referenced in: 13.

6. **Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus**.  
   *Intriguing Properties of Neural Networks*.  
   *CoRR abs/1312.6199*, 2013.  
   Referenced in: 13.

7. **Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel**.  
   *Ensemble Adversarial Training: Attacks and Defenses*.  
   *Proceedings of the 2017 International Conference on Learning Representations (ICLR)*, 2017.  
   Referenced in: 13.

8. **Florian Tramér, Fan Zhang, Ari Juels, Michael K. Reiter, and Thomas Ristenpart**.  
   *Stealing Machine Learning Models via Prediction APIs*.  
   *Proceedings of the 2016 USENIX Security Symposium (USENIX Security)*, pages 601–618. USENIX, 2016.  
   Referenced in: 13.

9. **Yevgeniy Vorobeychik and Bo Li**.  
   *Optimal Randomized Classification in Adversarial Settings*.  
   *Proceedings of the 2014 International Conference on Autonomous Agents and Multi-agent Systems (AAMAS)*, pages 485–492, 2014.  
   Referenced in: 13.

10. **Binghui Wang and Neil Zhenqiang Gong**.  
    *Stealing Hyperparameters in Machine Learning*.  
    *Proceedings of the 2018 IEEE Symposium on Security and Privacy (S&P)*. IEEE, 2018.  
    Referenced in: 3, 13.

11. **Bolun Wang, Yuanshun Yao, Bimal Viswanath, Haitao Zheng, and Ben Y. Zhao**.  
    *With Great Training Comes Great Vulnerability: Practical Attacks against Transfer Learning*.  
    *Proceedings of the 2018 USENIX Security Symposium (USENIX Security)*, pages 1281–1297. USENIX, 2018.  
    Referenced in: 13.

12. **Weilin Xu, David Evans, and Yanjun Qi**.  
    *Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks*.  
    *Proceedings of the 2018 Network and Distributed System Security Symposium (NDSS)*. Internet Society, 2018.  
    Referenced in: 13.

13. **Mohammad Yaghini, Bogdan Kulynych, and Carmela Troncoso**.  
    *Disparate Vulnerability: on the Unfairness of Privacy Attacks Against Machine Learning*.  
    *CoRR abs/1906.00389*, 2019.  
    Referenced in: 13.

14. **Dingdong Yang, Seunghoon Hong, Yunseok Jang, Tianchen Zhao, and Honglak Lee**.  
    *Diversity-Sensitive Conditional Generative Adversarial Networks*.  
    *Proceedings of the 2019 International Conference on Learning Representations (ICLR)*, 2019.  
    Referenced in: 8.

15. **Yuanshun Yao, Bimal Viswanath, Jenna Cryan, Haitao Zheng, and Ben Y. Zhao**.  
    *Automated Crowdturfing Attacks and Defenses in Online Review Systems*.  
    *Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS)*, pages 1143–1158. ACM, 2017.  
    Referenced in: 13.

16. **Samuel Yeom, Irene Giacomelli, Matt Fredrikson, and Somesh Jha**.  
    *Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting*.  
    *Proceedings of the 2018 IEEE Computer Security Foundations Symposium (CSF)*. IEEE, 2018.  
    Referenced in: 13.

17. **Xiao Zhang and David Evans**.  
    *Cost-Sensitive Robustness against Adversarial Examples*.  
    *Proceedings of the 2019 International Conference on Learning Representations (ICLR)*, 2019.  
    Referenced in: 13.

18. **Yang Zhang, Mathias Humbert, Tahleen Rahman, Cheng-Te Li, Jun Pang, and Michael Backes**.  
    *Tagvisor: A Privacy Advisor for Sharing Hashtags*.  
    *Proceedings of the 2018 Web Conference (WWW)*, pages 287–296. ACM, 2018.  
    Referenced in: 13.

19. **Yang Zhang, Mathias Humbert, Bartlomiej Surma, Praveen Manoharan, Jilles Vreeken, and Michael Backes**.  
    *Towards Plausible Graph Anonymization*.  
    *Proceedings of the 2020 Network and Distributed System Security Symposium (NDSS)*. Internet Society, 2020.  
    Referenced in: 13.

### Appendices

#### A. Target Models Architecture

**MNIST Model:**
- Sample → conv2d(5, 10)
- max(2)
- conv2d(5, 20)
- max(2)
- FullyConnected(50)
- FullyConnected(10)
- Softmax → (cid:96)

**CIFAR-10 Model:**
- Sample → conv2d(5, 6)
- max(2)
- conv2d(5, 16)
- max(2)
- FullyConnected(120)
- FullyConnected(84)
- FullyConnected(10)
- Softmax → (cid:96)

**Insta-NY Model:**
- Sample → FullyConnected(32)
- FullyConnected(16)
- FullyConnected(9)
- Softmax → (cid:96)

**Notes:**
- `max(2)` denotes a max-pooling layer with a 2×2 kernel.
- `FullyConnected(x)` denotes a fully connected layer with x hidden units.
- `Conv2d(k’,s’)` denotes a 2-dimensional convolution layer with kernel size k’×k’ and s’ filters.
- `Softmax` denotes the Softmax function.
- We use ReLU as the activation function for all layers in the MNIST, CIFAR-10, and Location models.

#### B. Encoder Architecture

**Encoder Architecture:**
- δ → FullyConnected(128)
- FullyConnected(64) → µ

**Notes:**
- µ denotes the latent vector which serves as the input for our decoder.
- We use LeakyReLU as the encoder’s activation function and apply dropout on both layers for regularization.

#### C. Single-sample Label Inference Attack’s Decoder Architecture

**ALI’s Decoder Architecture:**
- µ → FullyConnected(n)
- Softmax → (cid:96)

**Notes:**
- n is equal to the size of (cid:96), i.e., n = |(cid:96)|.

#### D. Single-sample Reconstruction Attack

**D.1 AE’s Encoder Architecture**

**AE’s Encoder Architecture for MNIST and CIFAR-10:**
- Sample → conv2d(k1, s1)
- max(2)
- conv2d(k2, s2)
- max(2)
- FullyConnected(f1)
- FullyConnected(f2) → µAE

**AE’s Encoder Architecture for Insta-NY:**
- Sample → FullyConnected(64)
- FullyConnected(32)
- FullyConnected(16)
- FullyConnected(16) → µAE

**Notes:**
- µAE is the latent vector output of the encoder.
- ki, si, and fi represent the kernel size, number of filters, and number of units in the ith layer.
- The concrete values of these hyperparameters depend on the target dataset and are presented in Table 2.
- We adopt ReLU as the activation function for all layers for the MNIST and CIFAR-10 encoders.
- For the Insta-NY decoder, we use ELU as the activation function for all layers except for the last one.
- We apply dropout after the first fully connected layer for MNIST and CIFAR-10.
- For Insta-NY, we apply dropout and batch normalization for the first three fully connected layers.

**D.2 AE’s Decoder Architecture**

**Autoencoder’s Decoder Architecture for MNIST and CIFAR-10:**
- µAE → FullyConnected(f'1)
- FullyConnected(f'2)
- ConvTranspose2d(k'1, s'1)
- ConvTranspose2d(k'2, s'2)
- ConvTranspose2d(k'3, s'3) → Sample

**Autoencoder’s Decoder Architecture for Insta-NY:**
- µAE → FullyConnected(16)
- FullyConnected(32)
- FullyConnected(64)
- FullyConnected(168) → Sample

**Notes:**
- `ConvTranspose2d(k’,s’)` denotes a 2-dimensional transposed convolution layer with kernel size k'×k' and s' filters.
- f'i specifies the number of units in the ith fully connected layer.
- The concrete values of these hyperparameters are presented in Table 2.
- For MNIST and CIFAR-10 decoders, we use ReLU as the activation function for all layers except for the last one where we adopt tanh.
- For the Insta-NY decoder, we adopt ELU for all layers except for the last one.
- We also apply dropout after the last fully connected layer for regularization for MNIST and CIFAR-10, and dropout and batch normalization on the first three fully connected layers for Insta-NY.

#### E. Multi-sample Reconstruction Attack’s Decoder Architecture

**CBM-GAN’s Generator Architecture for MNIST:**
- µ,z → FullyConnected(2048)
- FullyConnected(2048)
- FullyConnected(2048)
- FullyConnected(784) → Sample

**CBM-GAN’s Discriminator Architecture for MNIST:**
- µ,z → FullyConnected(1024)
- FullyConnected(512)
- FullyConnected(256)
- FullyConnected(1)
- Sigmoid → {1,0}

**CBM-GAN’s Generator Architecture for CIFAR-10:**
- µ,z → conv2d(2, 512)
- conv2d(4, 256)
- conv2d(4, 128)
- conv2d(4, 64)
- conv2d(4, 3) → Sample

**CBM-GAN’s Discriminator Architecture for CIFAR-10:**
- µ,z → conv2d(2, 64)
- conv2d(4, 128)
- conv2d(4, 256)
- conv2d(4, 512)
- conv2d(4, 1)
- Sigmoid → {1,0}

**CBM-GAN’s Generator Architecture for Insta-NY:**
- µ,z → FullyConnected(512)
- FullyConnected(512)
- FullyConnected(256)
- FullyConnected(168) → Sample

**CBM-GAN’s Discriminator Architecture for Insta-NY:**
- µ,z → FullyConnected(512)
- FullyConnected(256)
- FullyConnected(128)
- FullyConnected(1)
- Sigmoid → {1,0}

**Notes:**
- For both generators and discriminators, Sigmoid is the Sigmoid function.
- Batch normalization is applied on the output of each layer except the last layer.
- LeakyReLU is used as the activation function for all layers except the last one, which uses tanh.

---

This optimized version provides a clear, structured, and professional presentation of the references and appendices.