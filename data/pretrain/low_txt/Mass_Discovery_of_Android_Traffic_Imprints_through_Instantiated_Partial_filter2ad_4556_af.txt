### More Specifically, We Now Focus on the Combination of Invariable Tokens

More specifically, we now focus on the combination of invariable tokens (e.g., key-value pairs) within the same flow and remove duplicated tokens across different applications. The imprint generated in this way may not capture all packets or even entire applications. For example, a repackaged application might not have any flow-based imprint because its traffic invariants either belong to the original application it clones or to the advertising library injected into its code. However, it can still be fingerprinted by the combination of these invariants.

Generating imprints over multiple flows is challenging due to the difficulty in linking these flows together. For instance, a TCP connection for retrieving data from a server and another connection for downloading ads may need to be correlated. Prior research has used observed temporal relations to correlate two flows [28], but this approach may not work for repackaged apps if their identifiable flows are produced at different times. Addressing this problem remains an area for future research.

### 7. Related Work

#### Imprint Generation

Given the increasing demand for managing network behaviors of mobile applications, techniques for app traffic fingerprinting have been extensively investigated in recent years, both by industry (e.g., Palo Alto Networks) and academia [6, 7, 12, 14, 24, 26, 28-30, 37, 42]. All existing techniques rely on direct analysis of app traffic for imprint generation, primarily using supervised learning to build a classification model from a training set of network traces [30]. Most approaches assume that the app network traces are already available, sometimes provided by ISPs and mobile carriers [28]. In other cases, automatic UI exploration techniques (e.g., monkeyrunner [1]) are used or enhanced to generate app traffic. For example, NetworkProfiler [14] improves monkeyrunner by leveraging recorded user events and other heuristics to discover new UI paths of the app under test. However, the comprehensiveness of the traces produced in this manner, compared to the app's real-world traffic, is still uncertain, even after substantial testing (at least 5 minutes).

In general, obtaining realistic, comprehensive network traces for an app is difficult, let alone generating such traces at scale for millions of apps. Tiger is designed to address this challenge by using code analysis to guide traffic triggering and imprint generation. The only prior approach that does not rely on a training set or seed signatures was proposed in a study on in-app advertisements [39]. This approach uses app names (i.e., package names) and AD-IDs collected from an app’s metadata to fingerprint its traffic. The effectiveness of package names has also been mentioned in other work [24]. As demonstrated in our experiments, the invariants recovered by Tiger from an app's code vastly outperform these tokens in terms of coverage of the app's traffic. Our findings show that efficient code analysis is a promising approach for large-scale app imprint generation.

#### Program Slicing

Program slicing is a technique for simplifying a program by focusing only on a subset of its code relevant to specific points of interest (sinks) [38]. It has been widely used in debugging/testing [22, 41], program behavior analysis [23, 27], and bug detection [25]. Due to the complexity of modern applications, scalability is always a concern for real-world use [34]. Pruning is often used to address this issue. For example, "thin slicing" [36] has been proposed to identify statements that produce incorrect values [44]. Slicing has also been applied to analyze Android apps. For instance, SAAF [20] uses slicing to backtrack the parameters of a given method, and Harvester [32] combines slicing with dynamic execution to extract runtime values of plain-text telephone numbers in SMS trojans and command and control messages in malware.

However, slicing has never been tuned towards the analysis of traffic invariants, using instantiation of unrelated variables to prune the slice tree. Our research shows that this new technique achieves a 12.42× speedup over conventional slicing and execution and has the potential to be applied to other domains.

### 8. Conclusions

In this paper, we present Tiger, a novel technique that makes massive-scale, comprehensive app imprint generation possible. At the core of Tiger is a unique instantiated partial execution technique that slices the code related to an app’s network sinks in a way that unessential variables are quickly identified and instantiated, and related paths are pruned. This results in a very compact set of statements that need to be run to recover the content of invariable tokens, enabling at least one order of magnitude faster processing than more conventional slicing and execution approaches. 

Tiger achieves an average processing time of 18 seconds per app and covers over 98% of identifiable app traffic. Running Tiger over 200,000 real-world apps, a scale never achieved before in traffic signature generation, we gained an in-depth understanding of the identifiable traffic produced by modern apps. We found that unexpected information from apps’ communication, including fake device information, hardcoded time, credentials, and session IDs, could all be used to uniquely fingerprint individual apps. Additionally, we discovered the presence of complex triggering conditions, requiring human intervention, Intent triggers, and remote instructions, which highlights the limitations of automatic UI exploration and the importance of code-analysis-based solutions.

Finally, we discuss potential directions for future work, particularly enhancing our techniques to generate more complex cross-flow imprints and further improving the coverage of identifiable packets.

### Acknowledgments

We would like to thank the anonymous reviewers for their constructive comments. We also thank VirusTotal for their help in validating suspicious apps in our study. IIE authors were supported in part by NSFC U1536106 and 61728209, National Key Research and Development Program of China (Grant No.2016QY04W0805, No.2016YFB0801603), Youth Innovation Promotion Association CAS, and the strategic priority research program of CAS (XDA06010701). IU authors were supported by NSF CNS-1223477, 1223495, 1527141, 1618493, ARO W911NF1610127, and Samsung GIFT fund.

### References

[1] 2017. monkeyRunner. https://developer.android.com/studio/test/monkeyrunner/index.html. (2017).
[2] 2017. Trail: The Reflection API. https://docs.oracle.com/javase/tutorial/reflect/.
[6] AddictiveTips. 2017. Easily Monitor All Incoming & Outgoing Network Connections On Android. https://www.addictivetips.com/android/monitor-all-incoming-outgoing-network-connections-on-android/. (2017).
[7] Hasan Faik Alan and Jasleen Kaur. [n.d.]. Can Android Applications Be Identified Using Only TCP/IP Headers of Their Launch Time Traffic. In Proceedings of the 9th ACM Conference on Security and Privacy in Wireless and Mobile Networks (WiSec’ 16), r (Ed.).
[8] Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bodden, Alexandre Bartel, Jacques Klein, Yves Le Traon, Damien Octeau, and Patrick McDaniel. 2014. FlowDroid: Precise Context, Flow, Field, Object-Sensitive, and Lifecycle-Aware Taint Analysis for Android Apps. In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2014. 29.
[9] Kai Chen, Peng Liu, and Yingjun Zhang. 2014. Achieving Accuracy and Scalability Simultaneously in Detecting Application Clones on Android Markets. In Proceedings of the 36th International Conference on Software Engineering. ACM, 175–186.
[10] Kai Chen, Peng Wang, Yeonjoon Lee, XiaoFeng Wang, Nan Zhang, Heqing Huang, Wei Zou, and Peng Liu. 2015. Finding Unknown Malice in 10 Seconds: Mass Vetting for New Threats at the Google-Play Scale. In USENIX Security Symposium. 659–674.
[11] Kai Chen, Xueqiang Wang, Yi Chen, Peng Wang, Yeonjoon Lee, XiaoFeng Wang, Bin Ma, Aohui Wang, Yingjun Zhang, and Wei Zou. 2016. Following Devil’s Footprints: Cross-Platform Analysis of Potentially Harmful Libraries on Android and iOS. In Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 357–376.
[12] Mauro Conti, Luigi V. Mancini, Riccardo Spolaor, and Nino Vincenzo Verde. 2015. Can’t You Hear Me Knocking: Identification of User Actions on Android Apps via Traffic Analysis. In Proceedings of the 5th ACM Conference on Data and Application Security and Privacy (CODASPY’ 15). 297–304.
[3] 2017. UI/Application Exerciser Monkey. http://developer.android.com/tools/help/monkey.html. (2017).
[4] 2017. VirusTotal. https://www.virustotal.com. (2017).
[5] 2017. VirusTotal File Statistics During Last 7 Days. https://www.virustotal.com/en/statistics/. (2017).
[13] Andrea Continella, Yanick Fratantonio, Martina Lindorfer, Alessandro Puccecci, Ali Zand, Christopher Kruegel, and Giovanni Vigna. 2017. Obfuscation-Resilient Privacy Leak Detection for Mobile Apps Through Differential Analysis. In Proceedings of the ISOC Network and Distributed System Security Symposium (NDSS). 1–16.
[14] Shuaifu Dai, Alok Tongaonkar, Xiaoyin Wang, Antonio Nucci, and Dawn Song. 2013. NetworkProfiler: Towards Automatic Fingerprinting of Android Apps. In Proceedings of the 32nd IEEE International Conference on Computer Communications (INFOCOM’ 13). 809–817.
[15] Marianne De Michiel, Armelle Bonenfant, Hugues Cassé, and Pascal Sainrat. 2008. Static Loop Bound Analysis of C Programs Based on Flow Analysis and Abstract Interpretation. In Proceedings of the 14th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications. IEEE, 161–166.
[16] Gartner. 2017. Managed Security Service Provider (MSSP). http://www.gartner.com/it-glossary/mssp-managed-security-service-provider/. (2017).
[17] Arnab Ghosh, Prashant Kumar Gajar, and Shashikant Rai. 2013. Bring Your Own Device (BYOD): Security Risks and Mitigating Strategies. Journal of Global Research in Computer Science 4, 4 (2013), 62–70.
[18] Google. 2017. The Google Android Security Team’s Classifications for Potentially Harmful Applications. https://static.googleusercontent.com/media/source.android.com/en//security/reports/Google-Android-Security-PHA-classifications.pdf. (2017).
[19] Michael I Gordon, Deokhwan Kim, Jeff Perkins, Limei Gilham, Nguyen Nguyen, and Martin Rinard. 2015. Information-Flow Analysis of Android Applications in DroidSafe. In Proc. of the Network and Distributed System Security Symposium (NDSS). The Internet Society.
[20] Johannes Hoffmann, Martin Ussath, Thorsten Holz, and Michael Spreitzenbarth. [n.d.]. Slicing Droids: Program Slicing for Smali Code. In Proceedings of the 28th Annual ACM Symposium on Applied Computing (SAC’ 13). 1844–1851.
[21] Anurag Kumar Jain and Devendra Shanbhag. 2012. Addressing Security and Privacy Risks in Mobile Applications. IT Professional 14, 5 (2012), 28–33.
[22] Mariam Kamkar, Peter Fritzson, and Nahid Shahmehri. 1993. Interprocedural Dynamic Slicing Applied to Interprocedural Data Flow Testing. In Proceedings of the Conference on Software Maintenance (ICSM’ 93). 386–395.
[23] Bogdan Korel and Juergen Rilling. 1998. Program Slicing in Understanding of Large Programs. In Proceedings of the 6th International Workshop on Program Comprehension (IWPC’ 89). 145–152.
[24] Anh Le, Janus Varmarken, Simon Langhoff, Anastasia Shuba, Minas Gjoka, and Athina Markopoulou. 2015. AntMonitor: A System for Monitoring from Mobile Devices. In Proceedings of the 2015 ACM SIGCOMM Workshop on Crowdsourcing and Crowdsharing of Big (Internet) Data. 15–20.
[25] Bin Liang, Pan Bian, Yan Zhang, Wenchang Shi, Wei You, and Yan Cai. 2016. AntMiner: Mining More Bugs by Reducing Noise Interference. In Proceedings of the 38th International Conference on Software Engineering (ICSE 2016). 333–344.
[26] Envato Pty Ltd. 2017. Analyzing Android Network Traffic. http://code.tutsplus.com/tutorials/analyzing-android-network-traffic--mobile-10663. (2017).
[27] Andrea De Lucia, Anna Rita Fasolino, and Malcolm Munro. 1996. Understanding Function Behaviors through Program Slicing. In Proceedings of the 4th International Workshop on Program Comprehension (WPC’ 96). 9–10.
[28] Stanislav Miskovic, Gene Moo Lee, Yong Liao, and Mario Baldi. 2015. AppPrint: Automatic Fingerprinting of Mobile Applications in Network Traffic. In Proceedings of the 16th International Conference on Passive and Active Measurement (PAM’ 15). 57–69.
[29] Sophon Mongkolluksamee, Vasaka Visoottiviseth, and Kensuke Fukuda. 2015. Enhancing the Performance of Mobile Traffic Identification with Communication Patterns. In Proceedings of the 39th IEEE Annual Computer Software and Applications Conference (COMPSAC’ 2015). 336–345.
[30] Fairuz Amalina Narudin, Ali Feizollah, Nor Badrul Anuar, and Abdullah Gani. 2016. Evaluation of Machine Learning Classifiers for Mobile Malware Detection. Soft Comput. 20, 1 (2016), 343–357.
[31] Palo Alto Networks. 2017. WildFire Analysis Categories. https://www.paloaltonetworks.com/documentation/autofocus/autofocus/autofocus-admin-guide/assess-autofocus-artifacts/wildfire-analysis-categories.html. (2017).
[32] Siegfried Rasthofer, Steven Arzt, Marc Miltenberger, and Eric Bodden. 2016. Harvesting Runtime Values in Android Applications That Feature Anti-Analysis Techniques. In Proceedings of the Network and Distributed System Security Symposium (NDSS’ 16).
[33] RFC. 2000. HTTP Over TLS. https://tools.ietf.org/html/rfc2818. (2000).
[34] Juergen Rilling and Tuomas Klemola. 2003. Identifying Comprehension Bottlenecks Using Program Slicing and Cognitive Complexity Metrics. In Proceedings of the 11th IEEE International Workshop on Program Comprehension. IEEE, 115–124.
[35] Smali. 2013. An Assembler/Disassembler for Android’s Dex Format. http://code.google.com/p/smali/. (2013).
[36] Manu Sridharan, Stephen J. Fink, and Rastislav Bodík. 2007. Thin Slicing. In Proceedings of the ACM SIGPLAN 2007 Conference on Programming Language Design and Implementation (PLDI’ 07). 112–122.
[37] Jianhua Sun, Lingjun She, Hao Chen, Wenyong Zhong, Cheng Chang, Zhiwen Chen, Wentao Li, and Shuna Yao. 2015. Automatically Identifying Apps in Mobile Traffic. Concurrency and Computation: Practice and Experience (2015).
[38] Frank Tip. 1995. A Survey of Program Slicing Techniques. Journal of Program Language 3, 3 (1995).
[39] Alok Tongaonkar, Shuaifu Dai, Antonio Nucci, and Dawn Song. 2013. Understanding Mobile App Usage Patterns Using In-App Advertisements. In Proceedings of the 14th International Conference on Passive and Active Measurement (PAM’ 13). 63–72.
[40] Aliaksei Tsitovich, Natasha Sharygina, Christoph M Wintersteiger, and Daniel Kroening. 2011. Loop Summarization and Termination Analysis. In International Conference on Tools and Algorithms for the Construction and Analysis of Systems. Springer, 81–95.
[41] Mark Weiser. 1982. Programmers Use Slices When Debugging. Commun. ACM 25, 7 (1982), 446–452.
[42] Qiang Xu, Thomas Andrews, Yong Liao, Stanislav Miskovic, Zhuoqing Morley Mao, Mario Baldi, and Antonio Nucci. 2014. FLOWR: A Self-Learning System for Classifying Mobile Application Traffic. In Proceedings of the International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS’14). 569–570.
[43] Mu Zhang and Heng Yin. 2014. Efficient, Context-Aware Privacy Leakage Confinement for Android Applications Without Firmware Modding. In Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security (CCS’ 14). ACM, 259–270.
[44] Xiangyu Zhang, Neelam Gupta, and Rajiv Gupta. 2006. Pruning Dynamic Slices with Confidence. In Proceedings of the ACM SIGPLAN 2006 Conference on Programming Language Design and Implementation (PLDI’ 06). 169–180.