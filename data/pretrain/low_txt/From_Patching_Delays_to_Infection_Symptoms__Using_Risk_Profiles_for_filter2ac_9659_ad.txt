### Feature Sets and Training Details

- **Raw Features**: Trained using raw features on 10 days of observational data post-disclosure. Principal Component Analysis (PCA) was not used for dimensionality reduction to maintain the interpretability of the features.
- **Day x**: Classifiers trained using [Community] features on x days of observational data post-disclosure, for both symptoms and risk. Only Common Vulnerabilities and Exposures (CVEs) with known detection dates beyond day x were used for testing these classifiers.
- **Back x**: Classifiers trained using [Community] features on 10 days of observational data starting from x days before disclosure, for both symptoms and risk.
- **Intrinsic Features**: Trained using [Intrinsic] and [CVSS] families of features.
- **Community+Intrinsic**: Classifier trained using [Intrinsic] and [Community] features on 10 days of observational data post-disclosure.
- **Direct+Raw+Intrinsic**: Classifier trained using [Intrinsic], [Direct], and [Raw] features on 10 days of observational data post-disclosure.

### Performance Comparison

The main performance comparison is provided in Figure 8a. We observe a significant improvement in detection performance when combining community features with CVE intrinsic features. Both community and direct features, derived from raw features, outperform the use of raw features directly. Specifically, the community detection-based method performs the best among the three. The extracted features perform better because they preserve temporal information embedded in the time series data, which is often underutilized in decision tree classifiers.

Combining community features with intrinsic features achieves excellent detection performance, nearly matching the performance of all concatenated features. This suggests that community features, when combined with intrinsic features, can effectively replace the use of raw and direct features. The overall attainable performance is very promising, with an Area Under the Curve (AUC) of 96%, and true and false positive rates of 90% and 10%, respectively. These results are re-plotted in terms of precision and recall in Figure 8b.

### Intrinsic Features and Community Features

Intrinsic features alone are not strong predictors, as measured by AUC (69%). This is because intrinsic features are a priori characterizations of a vulnerability, while community features are a posteriori signs of exploitation, making them more powerful for detection. The combination of these two sets of features provides orthogonal attributes, resulting in much higher performance when combined.

### Limitations and Practical Considerations

While the performance is promising, it still falls short of typical intrusion detection systems (IDS) or spam filters. This is due to several reasons:
- Noisy labeling: Some exploited vulnerabilities may remain unreported.
- Weak signatures: In large populations, specific signatures for detection become weak or non-existent.
- False positives: In our setting, a false positive is less costly, as it merely suggests prioritizing patch development for potentially unexploited CVEs.

### Multiple CVE Exploits

If multiple CVEs are simultaneously exploited, our detection can still work as long as the hosts have non-identical patching behavior. If the host population exhibits the same patching behavior, the algorithm may detect all CVEs, leading to another type of false positive. However, the consequence is limited, as all detected CVEs will be suggested as high priority.

### Robustness and Noise

The accuracies presented are robust despite multiple sources of noise, such as one-to-multiple mapping from symptoms to vulnerabilities and hosts appearing in blacklists for reasons other than exploitation. The ground truth for testing our technique is independent of these noise sources, indicating that our method is robust to these imperfections.

### Observational Period Impact

We examined the impact of the observational period length on community detection. As shown in Figure 8c, longer observation periods post-disclosure improve predictive power, capturing more symptoms of infection. Starting observations before disclosure also captures useful information, suggesting some exploits begin before official disclosure. The "Day 4" version, with only 4 days of observation, performs the worst due to the short window.

### Case Studies and Discussion

#### Case Studies

- **CVE-2013-0640**: Affects Adobe Acrobat Reader, disclosed on 02/13/2013. Our system detected this vulnerability on the disclosure day using data from the preceding 10 days, confirming zero-day exploits.
- **CVE-2013-5330**: Affects Adobe Flash Player, disclosed on 11/12/2013. Our system detected this vulnerability on the disclosure day using data from the preceding 10 days, suggesting exploitation months before the earliest reported date.

#### Robustness Against Strategic Attacks

Our detection method is robust against strategic attacks that manipulate data to evade detection. Simulations show that even with a powerful adversary controlling up to 45% of ISPs, our method degrades gracefully.

#### Practical Use

Software vendors, antivirus companies, and security firms can use this methodology in real-time. They typically have access to similar data. The detection process is triggered by CVE disclosures, and daily processing of malicious activity and user patching data follows. The community structure can be updated online, maintaining computational efficiency.

### Conclusion

Our system enhances security by allowing early detection of active exploits, enabling better prioritization of patch development and deployment. It also helps in identifying at-risk host populations and encouraging prompt actions. While our technique relies on observing spam activity, it can be complemented with alternative bot detection methods for a more robust system.