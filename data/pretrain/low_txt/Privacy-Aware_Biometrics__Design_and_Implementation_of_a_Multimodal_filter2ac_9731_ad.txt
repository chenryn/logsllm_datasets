### Frequency Distributions and ROC Curves

Figures 5(A) to 5(C) illustrate the frequency distributions for various match-threshold values in a single-trait biometric system and our proposed method. Figure 5(D) presents the Receiver Operating Characteristic (ROC) curves. The single-iris system achieved an Equal Error Rate (EER) of 0.9%, while the fingerprint system and the proposed scheme achieved an EER of 0%. As expected, the multimodal system we proposed not only enhanced the protection of biometric inputs but also matched the performance of the single-trait fingerprint system, which is the best performer in our practical implementation.

### Potential for Improvement

Using commercial iris-code segmentation libraries could yield better absolute rates. Additionally, employing larger datasets would provide more realistic estimates of the EER. However, the primary goal of our implementation was to verify the practical feasibility of the method, which it successfully accomplished.

### Conclusions

In this paper, we introduced a method that combines standard cryptographic techniques with biometrics to create an effective and easily deployable identity verification system. This system is privacy-aware, as the information in the identifier is insufficient to recover the biometric traits, thereby preventing any abuse of biometric data. 

The proposed method meets the following requirements:
1. **Privacy-Awareness**: The system ensures that biometric traits cannot be recovered from the identifier.
2. **Multimodality**: The method requires at least two biometric traits.
3. **Modularity**: The system is composed of two basic modules that can be combined to build more complex systems.
4. **Algorithm Independence**: The method is independent of the specific feature extraction algorithms used.
5. **Offline Verification**: The system allows for offline secure document verification without storing biometric traits or sensitive data in a central database.
6. **Feasibility**: The implementation demonstrates the practical feasibility of the scheme and provides a benchmark for real-world performance.

To ensure the validity of the identifier produced during the enrollment phase, it can be signed using the private key of the issuer. At the verification stage, the signature on the ID can be verified using the issuer’s public key. The resulting error rate is acceptable and comparable to the best error rates of the single-trait biometric systems on which it is based. This work paves the way for large-scale applicability of privacy-aware biometric systems.

### Acknowledgments

We acknowledge helpful discussions with Sabrina De Capitani di Vimercati. This research was funded by the European Community’s Seventh Framework Programme (FP7/2007-2013) under grant agreement number 216483.

### References

[1] X. Boyen. Reusable cryptographic fuzzy extractors. In Proc. of the 11th ACM Conference on Computer and Communication Security (CCS 2004), volume 3027, pages 82–91. ACM, 2004.

[2] X. Boyen, Y. Dodis, J. Katz, R. Ostrovsky, and A. Smith. Secure remote authentication using biometric data. In R. Cramer, editor, Advances in Cryptology (EUROCRYPT 2005), volume 3494 of Lecture Notes in Computer Science. Springer-Verlag, 2005.

[3] J. Bringer, H. Chabanne, G. Cohen, B. Kindari, and G. Zémor. An application of the Goldwasser-Micali cryptosystem to biometric authentication. In Proc. of the 12th Australasian Conference on Information Security and Privacy (ACISP’07), volume 4586 of Lecture Notes in Computer Science, pages 96–106. Springer-Verlag, 2007.

[4] J. Bringer, H. Chabanne, G. Cohen, B. Kindarji, and G. Zémor. Optimal iris fuzzy sketches. The Computing Research Repository, abs/0705.3740, 2007.

[5] Chinese Academy of Sciences. Database of 756 greyscale eye images; Version 1.0, 2003.

[6] J. G. Daugman. High confidence visual recognition of persons by a test of statistical independence. IEEE Transactions on Pattern Analysis and Machine Intelligence, 15:1148–1161, 1993.

[7] Y. Dodis, R. Ostrovsky, L. Reyzin, and A. Smith. Fuzzy extractors: How to generate strong keys from biometrics and other noisy data. Technical Report 2006/235, Cryptology Eprint Archive, 2006.

[8] Y. Dodis, L. Reyzin, and A. Smith. Fuzzy extractors: How to generate strong keys from biometrics and other noisy data. In C. Cachin and J. Camenisch, editors, Advances in Cryptology (EUROCRYPT 2004), volume 3027 of Lecture Notes in Computer Science. Springer-Verlag, 2004.

[9] Y. Dodis, L. Reyzin, and A. Smith. Fuzzy extractors. In P. Tuyls and J. Goseling, editors, Security with Noisy Data, chapter 5, pages 93–111. Springer-Verlag, 2007.

[10] Y. Dodis and A. Smith. Correcting errors without leaking partial information. In Proceedings of the thirty-seventh annual ACM symposium on Theory of computing, pages 654–663, 2005.

[11] W. J. Gross, F. R. Kschischang, R. Koetter, and P. G. Gulak. Towards a VLSI architecture for interpolation-based soft-decision Reed-Solomon decoders. The Journal of VLSI Signal Processing, 39(1-2):93–111, 2005.

[12] V. Guruswami and M. Sudan. Improved decoding of Reed-Solomon and algebraic-geometry codes. IEEE Trans. Inf. Theory, 45(6):1757–1767, 1999.

[13] F. Hao, R. Anderson, and J. Daugman. Combining cryptography with biometrics effectively. Technical Report UCAM-CL-TR-640, University of Cambridge, Computer Laboratory, United Kingdom, July 2005.

[14] A. K. Jain, A. Ross, and S. Pankanti. Biometrics: A tool for information security. IEEE transactions on information forensics and security, 1(2):125–143, June 2006.

[15] A. Juels and M. Sudan. A fuzzy vault scheme. In A. Lapidoth and E. Teletar, editors, Proceedings of the IEEE International Symposium on Information Theory, 2002, page 408. IEEE Press, 2002.

[16] A. Juels and M. Wattenberg. A fuzzy commitment scheme. In Proceedings of the 6th ACM conference on Computer and communications security (CCS ’99), pages 28–36, New York, NY, USA, 1999. ACM Press.

[17] P. Karn. Reed-solomon encoding and decoding code, 2002.

[18] R. Koetter and A. Vardy. Algebraic soft-decision decoding of Reed-Solomon codes. IEEE Trans. Inf. Theory, 49(11):2809–2825, 2003.

[19] A. W.-K. Kong, K. H. Cheung, D. Zhang, M. S. Kamel, and J. You. An analysis of biohashing and its variants. Pattern Recognition, 39(7):1359–1368, 2006.

[20] A. Lumini and L. Nanni. An improved biohashing for human authentication. Pattern Recognition, 40(3):1057–1065, 2007.

[21] D. Maio, D. Maltoni, R. Cappelli, J. L. Wayman, and A. K. Jain. FVC2000: Fingerprint verification competition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24(3):402–412, 2002.

[22] L. Masek and P. Kovesi. MATLAB source code for a biometric identification system based on iris patterns. The School of Computer Science and Software Engineering, The University of Western Australia, 2003.

[23] A. Ross, K. Nandakumar, and A. K. Jain. Handbook of Multibiometrics (International Series on Biometrics). Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.

[24] B. Schneier. Biometrics: uses and abuses. Commun. ACM, 42(8):136, Aug. 1999.

[25] D. Schonberg and D. Kirovski. Eyecerts. IEEE Transactions on Information Forensics and Security, 1:144–153, June 2006.

[26] Y. Sutcu, Q. Li, and N. Memon. Protecting biometric templates with sketch: Theory and practice. IEEE Transaction on Information Forensics and Security, 2(3), 2007.

[27] U. Uludag, S. Pankanti, S. Prabhakar, and A. Jain. Biometric cryptosystems: Issues and challenges. In Proceedings of the IEEE, Special Issue on Enabling Security Technologies for Digital Rights Management, volume 92, pages 948–960, June 2004.

[28] C. I. Watson, M. D. Garris, E. Tabassi, C. L. Wilson, R. M. McCabe, S. Janet, and K. Ko. User’s Guide to NIST Biometric Image Software (NBIS) (formerly NISTIR 6813), 2007.

### Appendices

#### A. Discussion on the ECC Code Employed

The selection of the error-correcting code (ECC) requires further discussion. Given the large inter-subject variability of iris templates, where typically \( e_1 > 0.25 \), the fraction of errors the code must withstand is higher than in typical ECC applications. Common ECC codes, like BCH, can correct a fraction of errors strictly less than \( n/4 \), making them unsuitable. Other binary codes might approach the Singleton bound but at the cost of a small rate \( k/n \).

As several authors have pointed out [9], the Plotkin bound from coding theory implies that a binary code can correct more than \( n/4 \) errors only at the expense of reducing the number of codewords to about \( \log n \). We pursued this route by deriving a binary code from a Reed-Solomon code, which is Maximum Distance Separable (MDS) and reaches the Singleton bound. The concatenation of the shortened Reed-Solomon code \([9600, 1920, 7681]_{2^{14}}\) and the \([14, 1, 1]_2\) mapping leads, on average, to a \([14 \times 9600, 1920, 7681]_2\) binary code. The correction rate is effectively increased as we can decide which part of the codeword is affected by errors and which is not, unlike in digital transmissions.

If we generalize the construction to BCH codes, the software we used for computing the iris code had \( e_1 = 0.4 \). By injecting errors into a restricted part of a longer codeword, we can use this family of codes. For example, a \([32767, 2279, 7679]_2\) code can correct up to \( t = 3839 \) errors. Performing \( c \oplus I_1 \) on the upper 9600 bits at enrollment and \( s \oplus I'_1 \) on the same substring at verification does not introduce further errors on the remaining \( 32767 - 9600 \) bits. This results in a larger local correction ratio of approximately \( 3839/9600 \approx 40\% \), as desired.

A second issue is that the decoding procedure in the described scheme is successful when the number of differing bits between the two iris codes is smaller than the error-correcting capacity of the code. For Reed-Solomon codes, the classical Berlekamp-Welch decoder can correct up to \( t = \left\lfloor \frac{n-k}{2} \right\rfloor \) errors. However, in [12], the authors showed that it is feasible to list all codewords at a Hamming distance \( t' > t \) (list decoding problem), with \( t' \leq \left\lfloor n - \sqrt{n(k - 1)} - 1 \right\rfloor \). Further, in [18], the authors managed to exploit the statistical characteristics of the channel to solve the list decoding problem with even larger \( t' \). While a larger number of errors corrected by an ECC decoder means more reliable transmission and storage of information, here it implies that user biometrics might be uncovered simply by using a more capable decoder. The solution is either to use a code for which list decoding algorithms are not available or to tune the Reed-Solomon code for a larger capacity decoder. The latter solution brings a wider computational burden, although recent works show progress in reducing computational time [11].