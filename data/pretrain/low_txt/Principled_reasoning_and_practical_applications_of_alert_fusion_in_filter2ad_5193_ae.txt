### 6.4 A Robust Consideration for Cost Evaluation

In the previous section, we demonstrated that the LRT (Likelihood Ratio Test) technique is robust to parameter estimation errors up to a certain degree. Here, we propose an additional robust method for evaluating the expected (or total) cost, which addresses the concern of large deviations in estimation errors and uncertainties in practical parameters.

For a robust evaluation with uncertain parameters, we consider a scenario where the estimated base rate, false positive rate, and false negative rate deviate from their actual values to a certain extent. Instead of calculating the expected (or total) cost with a static set of parameters, we use a range bounded by the largest possible deviation to account for estimation errors. Among all possible final cost values, we select the highest value, representing the worst-case scenario with the most extreme estimation errors. This approach ensures that the final cost is an upper bound on all possible cases within the estimated parameter range. Consequently, the real cost evaluation will always be better than this robust result, given the largest possible estimation error bound.

### 6.5 Runtime Performance

The runtime performance of our LRT fusion rule is efficient. For example, in the first experiment using four IDSs, it took only 0.187 seconds to complete LRT fusion processing on all 311,029 records, which translates to approximately 0.6 microseconds per record (on a machine with 512 MB memory, a 2.4 GHz Pentium IV processor, and Windows 2K OS). Although this performance is slightly poorer than that of the AND and OR rules (about 0.2 microseconds per record), it is nearly as good as the VOT (Voting) fusion rule, which takes about 0.5 microseconds per record.

We can further improve the computational efficiency by pre-calculating the log probabilities and thresholds offline, storing them, and using them directly during the fusion decision process. Additionally, considering that fusion is primarily performed when there are alerts generated by IDSs (or even offline), the LRT rule is computationally efficient enough for practical usage.

### 6.6 Multi-class Extension

The LRT technique discussed so far is designed for two-class (anomaly or normal) alert fusion. It can also be extended to multi-class scenarios. The extension is similar to the method used for extending two-class SVM (Support Vector Machine) to multi-class cases, where a tree structure is employed to perform LRT along specific tree paths. For instance, the first LRT decides whether the class is 1 or not, the second LRT decides whether it is class 2 or not, and so on. The running time, measured in the number of LRT runs, is at most \(O(m)\) and at least \(O(\log(m))\), where \(m\) is the number of classes to classify.

### 7. Conclusion and Future Work

In this paper, we proposed a decision-theoretic alert fusion technique for an IDS (Intrusion Detection System) ensemble and reported our empirical experience with this technique in practice. We provided a formal interpretation of the LRT ensemble based on ROC (Receiver Operating Characteristic) curve analysis and discussed the reasoning behind its superiority over other approaches. Our empirical results, derived from experiments using several machine learning-based IDSs and real IDSs on multiple datasets, show that this approach outperforms existing fusion techniques in achieving low overall cost. Furthermore, this technique is adaptive to different base rates and risk scenarios (or cost models).

It is important to note that the LRT fusion rule is not only optimal in the sense that it minimizes the expected cost but is also optimal in a Neyman-Pearson [38] way. This means that the LRT rule maximizes the probability of detection for a given upper bound on the false alarm rate. The intuition for this notion of optimality is reflected in the ROC analysis in Section 5, where the ensemble's ROC was shown to have superior performance compared to individual detectors. Due to space constraints, we omit a detailed analysis of this property in this paper.

For future work, we plan to study robust and realistic approaches to incorporate probabilistic techniques and inference models. We also aim to explore how to obtain better independent (diverse) detectors, which is a critical and interesting problem in IDS research.

The LRT ensemble rule is not limited to intrusion detection applications. However, we have not encountered a formal treatment of the rule as presented in this paper in other applications such as machine learning. We are currently exploring its use in more general classification systems and voting algorithms and plan to extend this work to other applications.

### 8. Acknowledgments

This work is supported in part by NSF grant CCR-0133629, the Army Research Office contract W911NF0510139, and by TRUST, which receives funding from NSF grant CCF-0424422. The contents of this work are solely the responsibility of the authors and do not necessarily represent the official views of NSF and the U.S. Army.

### 9. References

[1] KDD Cup 1999 Data. http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html, 2005.
[2] Nahla Ben Amor, Salem Benferhat, and Zied Elouedi. Naive Bayes vs Decision Trees in Intrusion Detection Systems. In SAC '04: Proceedings of the 2004 ACM Symposium on Applied Computing, pages 420–424, New York, NY, USA, 2004. ACM Press.
[3] Anish Arora, Dennis Hall, C. Ariel Pinto, Dwayne Ramsey, and Rahul Telang. Measuring the Risk-Based Value of IT Security Solutions. IT Professional, 6(6):35–42, Nov.-Dec. 2004.
[4] S. Axelsson. The Base-Rate Fallacy and Its Implications for the Difficulty of Intrusion Detection. In Proceedings of ACM CCS'1999, November 1999.
[5] Marco Barreno, Alvaro A. Cardenas, and J. D. Tygar. Optimal ROC Curve for a Combination of Classifiers. In Proceedings of Neural Information Processing Systems (NIPS) 20, 2008.
[6] Tim Bass. Intrusion Detection Systems and Multisensor Data Fusion. Commun. ACM, 43(4):99–105, 2000.
[7] J. De Bonet, C. Isbell, and P. Viola. MIMIC: Finding Optima by Estimating Probability Densities. Advances in Neural Information Processing Systems, 9, 1997.
[8] L. Breiman. Bagging Predictors. Machine Learning, 24(2):123–140, 1996.
[9] Alvaro Cardenas, John Baras, and Karl Seamon. A Framework for the Evaluation of Intrusion Detection Systems. In Proceedings of the 2006 IEEE Symposium on Security and Privacy, Oakland, California, May 2006.
[10] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A Library for Support Vector Machines, 2001. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm.
[11] F. Cuppens and A. Miege. Alert Correlation in a Cooperative Intrusion Detection Framework. In Proceedings of IEEE Symposium on Security and Privacy 2002, 2002.
[12] Herve Debar and Andreas Wespi. Aggregation and Correlation of Intrusion-Detection Alerts. In Proceedings of the 4th International Symposium on Recent Advances in Intrusion Detection (RAID’01), 2001.
[13] Luca Didaci, Giorgio Giacinto, and Fabio Roli. Ensemble Learning for Intrusion Detection in Computer Networks. http://citeseer.ist.psu.edu/533620.html.
[14] Thomas G. Dietterich. Ensemble Methods in Machine Learning. Lecture Notes in Computer Science, 1857:1–15, 2000.
[15] W. Fan, W. Lee, S. Stolfo, and M. Miller. A Multiple Model Cost-Sensitive Approach for Intrusion Detection. In Proceedings of The Eleventh European Conference on Machine Learning (ECML’00), 2000.
[16] W. Fan, S. Stolfo, and J. Zhang. AdaCost: Cost-Sensitive Boosting. In Proceedings of International Conference on Machine Learning (ICML’99), 1999.
[17] Y. Freund and R. E. Schapire. Experiments with a New Boosting Algorithm. In Thirteenth International Conference on Machine Learning (ICML), pages 148–156, 1996.
[18] G. Giacinto and F. Roli. Intrusion Detection in Computer Networks by Multiple Classifier Systems. In Proceedings of 16th International Conference on Pattern Recognition (ICPR 2002), 2002.
[19] Guofei Gu, Prahlad Fogla, David Dagon, Wenke Lee, and Boris Skoric. Towards an Information-Theoretic Framework for Analyzing Intrusion Detection Systems. In Proceedings of the 11th European Symposium on Research in Computer Security (ESORICS’06), September 2006.
[20] Guofei Gu, Prahlad Fogla, David Dagon, Wenke Lee, and Boris Skoric. Measuring Intrusion Detection Capability: An Information-Theoretic Approach. In Proceedings of the 2006 ACM Symposium on Information, Computer, and Communication Security (ASIACCS’06), March 2006.
[21] Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning. Springer-Verlag New York, Inc., 2003.
[22] Imad Y. Hoballah and Pramod K. Varshney. Distributed Bayesian Signal Detection. IEEE Transactions on Information Theory, 35(5):995–1000, 1989.
[23] Wenjie Hu, Yihua Liao, and V. Rao Vemuri. Robust Support Vector Machines for Anomaly Detection in Computer Security. In Proc. 2003 International Conference on Machine Learning and Applications (ICMLA’03), 2003.
[24] Finn V. Jensen. Bayesian Networks and Decision Graphs. Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2001.
[25] Michael I. Jordan, editor. Learning in Graphical Models. MIT Press, Cambridge, MA, USA, 1999.
[26] C. Kruegel and G. Vigna. Anomaly Detection of Web-Based Attacks. In Proceedings of the 10th ACM Conference on Computer and Communication Security (CCS ’03), pages 251–261, Washington, DC, October 2003. ACM Press.
[27] C. Kruegel, G. Vigna, and W. Robertson. A Multi-Model Approach to the Detection of Web-Based Attacks. Computer Networks, 48(5):717–738, August 2005.
[28] Christopher Kruegel, Darren Mutz, William Robertson, and Fredrik Valeur. Bayesian Event Classification for Intrusion Detection. In Proceedings of the Annual Computer Security Applications Conference (ACSAC 2003), Las Vegas, NV, December 2003.
[29] Ludmila I. Kuncheva. Combining Pattern Classifiers: Methods and Algorithms. Wiley, 2004.
[30] W. Lee, W. Fan, M. Miller, S. Stolfo, and E. Zadok. Cost-Sensitive Modeling for Intrusion Detection and Response. Journal of Computer Security, 10(1,2), 2002.
[31] Wenke Lee and Salvatore J. Stolfo. A Framework for Constructing Features and Models for Intrusion Detection Systems. ACM Transactions on Information and System Security (TISSEC), 3(4):p.227–261, 2000.
[32] Yihua Liao and V. Rao Vemuri. Using Text Categorization Techniques for Intrusion Detection. In 11th USENIX Security Symposium, August 5–9, 2002., pages 51–59, 2002.
[33] R. P. Lippmann, D. J. Fried, I. Graf, J. W. Haines, K. P. Kendall, D. McClung, D. Weber, S. E. Webster, D. Wyschogrod, R. K. Cunningham, and M. A. Zissman. Evaluating Intrusion Detection Systems: The 1998 DARPA Off-Line Intrusion Detection Evaluation. In Proceedings of the 2000 DARPA Information Survivability Conference and Exposition (DISCEX’00), 2000.
[34] M. Mahoney. Network Traffic Anomaly Detection Based on Packet Bytes. In Proceedings of 18th ACM Symp. on Applied Computing, pages 346–350, November 2003.
[35] M. Mahoney and P. Chan. An Analysis of the 1999 DARPA/Lincoln Laboratory Evaluation Data for Network Anomaly Detection. In Proceedings of the 6th International Symposium on Recent Advances in Intrusion Detection (RAID’03), 2003.
[36] John McHugh. Testing Intrusion Detection Systems: A Critique of the 1998 and 1999 DARPA Off-Line Intrusion Detection System Evaluation as Performed by Lincoln Laboratory. ACM Transactions on Information and System Security, 3(4), November 2000.
[37] Tom Mitchell. Machine Learning. McGraw-Hill, 1997.
[38] J. Neyman and E. S. Pearson. On the Problem of the Most Efficient Tests of Statistical Hypotheses. Philosophical Transactions of the Royal Society of London, Series A, Containing Papers of a Mathematical or Physical Character, 231:289–337, 1933.
[39] Peng Ning, Yun Cui, and Douglas S. Reeves. Constructing Attack Scenarios Through Correlation of Intrusion Alerts. In Proceedings of the 9th ACM Conference on Computer & Communications Security (CCS’02), 2002.
[40] Roberto Perdisci, Guofei Gu, and Wenke Lee. Using an Ensemble of One-Class SVM Classifiers to Harden Payload-Based Anomaly Detection Systems. In Proceedings of the IEEE International Conference on Data Mining (ICDM’06), December 2006.
[41] Phillip A. Porras, Martin W. Fong, and Alfonso Valdes. A Mission-Impact-Based Approach to Infosec Alarm Correlation. In Proceedings of the 5th International Symposium on Recent Advances in Intrusion Detection (RAID’02), 2002.
[42] Rain Forest Puppy. Libwhisker Official Release v2.1, 2004. Available at http://www.wiretrip.net/rfp/lw.asp.
[43] Martin Roesch. Snort: Lightweight Intrusion Detection for Networks. In LISA, pages 229–238, 1999.
[44] M. Shankar, N. Rao, and S. Batsell. Fusing Intrusion Data for Detection and Containment. In Proceedings of MILCOM2003, 2003.
[45] Sal Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis, and Phil Chan. Cost-Based Modeling for Fraud and Intrusion Detection: Results from the JAM Project. In Proceedings of the 2000 DARPA Information Survivability Conference and Exposition (DISCEX ’00), 2000.
[46] Eric Totel, Frederic Majorczyk, and Ludovic Me. COTS Diversity Intrusion Detection and Application to Web Servers. In Proceedings of RAID’2005, September 2005.
[47] F. Valeur, G. Vigna, C. Kruegel, and R. Kemmerer. A Comprehensive Approach to Intrusion Detection Alert Correlation. IEEE Transactions on Dependable and Secure Computing, 1(3):146–169, July-September 2004.
[48] V.N. Vapnik. The Nature of Statistical Learning Theory. Springer, 1995.
[49] P. Varshney. Distributed Detection and Data Fusion. Springer-Verlag, New York, NY, 1996.
[50] Ke Wang and Salvatore J. Stolfo. Anomalous Payload-Based Network Intrusion Detection. In Proceedings of RAID’2004, September 2004.
[51] D. H. Wolpert. Stacked Generalization. Neural Networks, 5:241–259, 1992.
[52] L. Xu, A. Krzyzak, and CY Suen. Methods of Combining Multiple Classifiers and Their Applications to Handwriting Recognition. IEEE Trans. Systems Man Cybernet, 22(3):418–435, 1992.