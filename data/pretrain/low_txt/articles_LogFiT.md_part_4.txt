### LogFiT: A Novel Log Anomaly Detection Model

#### Evaluation of LogFiT and LogBERT on the BGL Dataset
The evaluation data was modified to replace the top 10 most frequent verbs with their WordNet lemmas. The column labeled "pred token anomaly" represents the LogFiT predictions (based on specificity) for the 5,000 normal samples. The column labeled "pred centroid anomaly" represents the model’s predictions (based on centroid distance) for the 1,000 anomaly samples.

Figure 6 illustrates the performance of the two anomaly detection methods, showing that centroid distance is not effective in distinguishing between normal and anomalous log paragraphs. In this case, all samples were categorized as normal by the centroid distance criteria.

To investigate why centroid distance is ineffective, the semantic vectors of the training and evaluation sets were plotted after reducing the vector dimensions to 2 using the UMAP algorithm [36]. As shown in Figure 7, the semantic vectors of the training set do not form clean clusters. Therefore, there are no distinct clusters that can effectively threshold the semantic vectors computed during inference. It can be concluded that centroid distance minimization does not improve the performance of LogFiT and can be omitted from the model.

In the figures, the color of the points represents different sample types: training samples (blue), normal predictions (pink), and anomaly predictions (yellow). The clusters for the anomaly samples from the evaluation set (yellow points) appear very close to the training/normal clusters (blue points). In contrast, the clusters for the normal samples from the evaluation set (pink points) are more spread out from the training/normal clusters (blue points). This indicates that centroid distance cannot be used to separate normal from anomalous log paragraphs.

#### Variations in Input Data
In practical applications, the content of log sentences may change over time due to programmers changing words or introducing misspellings. The LogFiT model supports log sentence variability with a large vocabulary of sub-word tokens (around 50K). In contrast, DeepLog and LogBERT would fail if they encounter variations in log sentences, which is attributed to their inability to handle out-of-vocabulary tokens.

Table V shows the results of feeding the modified BGL evaluation set to the unmodified LogFiT models. The results indicate that the LogFiT model is robust to changes in log sentences, as the reduction in F1 score is around 2% (from 91.22 to 89.38). However, the drop in F1 performance for LogBERT is significant, from 88.63 to 44.22.

#### Conclusion
This paper introduces LogFiT, a novel log anomaly detection model that leverages the general linguistic knowledge embedded within a pre-trained BERT-based language model (LM) and fine-tunes it to recognize specific linguistic patterns of system logs. LogFiT is trained in a self-supervised manner using only normal system logs to predict masked tokens in log sequences. This approach enables LogFiT to recognize the linguistic structure of normal system logs and flag anomalies when it fails to reconstruct an input log sequence.

Critically, LogFiT can handle variability in the content of system logs due to its use of a BERT-based LM. The performance of LogFiT on the HDFS, BGL, and Thunderbird datasets has been evaluated, and it has been found that LogFiT’s F1 score outperformed that of the baseline models. Moreover, LogFiT’s specificity exceeded that of the baselines on the HDFS and BGL datasets and was comparable to LogBERT on the Thunderbird dataset. Additionally, LogFiT demonstrated superior performance over LogBERT in experiments that tested for variations in the content of input log paragraphs, attributed to its ability to handle out-of-vocabulary tokens.

LogFiT integrates with the popular HuggingFace ecosystem, making it easy to adapt in future work. Overall, LogFiT presents a flexible and future-proof approach to detecting abnormal behavior in computer systems through language model adaptation and fine-tuning.

#### Future Work
While the LogFiT model is intended to be used as a threshold-based anomaly detector trained in a self-supervised manner, it can easily be converted to a classifier. If, after deployment, operators are able to collect and label anomaly log samples, the model can be converted to a classifier by replacing its language modeling head with a classification head. Additionally, the LogFiT LM can be pre-trained on diverse log datasets, allowing it to be used as a foundation for downstream NLP and log anomaly detection tasks.

#### References
[1] RiskIQ, "The evil internet minute 2019," 2019. [Online]. Available: https://www.riskiq.com/resources/infographic/evil-internet-minute-2019.
[2] Australia Department of Home Affairs, "Australia’s cybersecurity strategy 2020," 2020. [Online]. Available: https://www.homeaffairs.gov.au/cyber-security-subsite/files/cyber-security-strategy-2020.pdf.
[3] International Business Machines, "Cost of a data breach report 2022," 2022. [Online]. Available: https://www.ibm.com/security/data-breach.
[4] M. Du, F. Li, G. Zheng, and V. Srikumar, "DeepLog: Anomaly detection and diagnosis from system logs through deep learning," in Proceedings of the ACM Conference on Computer and Communications Security, New York, NY, USA: ACM, 2017, pp. 1285–1298, ISBN: 9781450349468. DOI: 10.1145/3133956.3134015.
[5] H. Guo, S. Yuan, and X. Wu, "LogBERT: Log Anomaly Detection via BERT," Proceedings of the International Joint Conference on Neural Networks, vol. 2021-July, Mar. 2021. DOI: 10.1109/IJCNN52387.2021.9534113. arXiv: 2103.04475. [Online]. Available: https://arxiv.org/abs/2103.04475v1.
[6] S. Nedelkoski, J. Bogatinovski, A. Acker, J. Cardoso, and O. Kao, "Self-attentive classification-based anomaly detection in unstructured logs," in Proceedings - IEEE International Conference on Data Mining, ICDM, vol. 2020-Novem, Institute of Electrical and Electronics Engineers Inc., Nov. 2020, pp. 1196–1201, ISBN: 9781728183169. DOI: 10.1109/ICDM50108.2020.00148. arXiv: 2008.09340.
[7] V. H. Le and H. Zhang, "Log-based Anomaly Detection with Deep Learning: How Far Are We?" Association for Computing Machinery, 2022, vol. 1, ISBN: 9781450392211. DOI: 10.1145/3510003.3510155. arXiv: 2202.04301. [Online]. Available: http://arxiv.org/abs/2202.04301.
[8] L. McInnes, J. Healy, and J. Melville, "UMAP: Uniform manifold approximation and projection for dimension reduction," arXiv preprint arXiv:1802.03426, 2018.
[9] D. Hendrycks, X. Liu, E. Wallace, A. Dziedzic, R. Krishnan, and D. Song, "Pretrained Transformers Improve Out-of-Distribution Robustness," Association for Computational Linguistics (ACL), Apr. 2020, pp. 2744–2751. DOI: 10.18653/v1/2020.acl-main.244. arXiv: 2004.06100. [Online]. Available: https://arxiv.org/abs/2004.06100v2.
[10] H. Ott, J. Bogatinovski, A. Acker, S. Nedelkoski, and O. Kao, "Robust and transferable anomaly detection in log data using pre-trained language models," in 2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence), IEEE, 2021, pp. 19–24.
[11] V.-H. Le and H. Zhang, "Log-based anomaly detection without log parsing," in 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), IEEE, 2021, pp. 492–504.
[12] T. Wittkopp, A. Acker, S. Nedelkoski, et al., "A2Log: Attentive Augmented Log Anomaly Detection," HICSS 2022 : Hawaii International Conference on System Sciences, Sep. 2021. arXiv: 2109.09537. [Online]. Available: http://arxiv.org/abs/2109.09537.
[13] G. Pang, C. Shen, L. Cao, and A. Van Den Hengel, "Deep learning for anomaly detection: A review," ACM Comput. Surv., vol. 54, no. 2, Mar. 2021, ISSN: 0360-0300. DOI: 10.1145/3439950. [Online]. Available: https://doi.org/10.1145/3439950.
[14] S. He, P. He, Z. Chen, T. Yang, Y. Su, and M. R. Lyu, "A survey on automated log analysis for reliability engineering," ACM computing surveys (CSUR), vol. 54, no. 6, pp. 1–37, 2021.
[15] R. Chalapathy and S. Chawla, "Deep Learning for Anomaly Detection: A Survey," 2019. arXiv: 1901.03407. [Online]. Available: http://arxiv.org/abs/1901.03407.
[16] N. Zhao, H. Wang, Z. Li, et al., "An empirical investigation of practical log anomaly detection for online service systems," in ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, vol. 21, 2021, pp. 1404–1415, ISBN: 9781450385626. DOI: 10.1145/3468264.3473933. [Online]. Available: https://doi.org/10.1145/3468264.3473933.
[17] X. Zhang, Y. Xu, Q. Lin, et al., "Robust log-based anomaly detection on unstable log data," in ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, vol. 19, 2019, pp. 807–817, ISBN: 9781450355728. DOI: 10.1145/3338906.3338931. [Online]. Available: https://doi.org/10.1145/3338906.3338931.
[18] R. B. Yadav, P. S. Kumar, and S. V. Dhavale, "A Survey on Log Anomaly Detection using Deep Learning," in ICRITO 2020 - IEEE 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions), Institute of Electrical and Electronics Engineers Inc., Jun. 2020, pp. 1215–1220, ISBN: 9781728170169. DOI: 10.1109/ICRITO48877.2020.9197818.
[19] Z. Chen, J. Liu, W. Gu, Y. Su, and M. R. Lyu, "Experience Report: Deep Learning-based System Log Analysis for Anomaly Detection," Jul. 2021. arXiv: 2107.05908. [Online]. Available: http://arxiv.org/abs/2107.05908.
[20] P. He, J. Zhu, Z. Zheng, and M. R. Lyu, "Drain: An Online Log Parsing Approach with Fixed Depth Tree," in Proceedings - 2017 IEEE 24th International Conference on Web Services, ICWS 2017, 2017, pp. 33–40, ISBN: 9781538607527. DOI: 10.1109/ICWS.2017.13.
[21] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "BERT: Pre-training of deep bidirectional transformers for language understanding," in NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference, vol. 1, Association for Computational Linguistics (ACL), Oct. 2019, pp. 4171–4186, ISBN: 9781950737130. arXiv: 1810.04805. [Online]. Available: https://arxiv.org/abs/1810.04805v2.
[22] G. Jawahar, B. Sagot, and D. Seddah, "What does BERT learn about the structure of language?" in ACL 2019 - 57th Annu. Meet. Assoc. Comput. Linguist. Proc. Conf., Association for Computational Linguistics (ACL), 2020, pp. 3651–3657, ISBN: 9781950737482. DOI: 10.18653/v1/p19-1356. [Online]. Available: https://aclanthology.org/P19-1356.
[23] Y. Lin, Y. C. Tan, and R. Frank, "Open Sesame: Getting inside BERT’s Linguistic Knowledge," 2019, pp. 241–253. DOI: 10.18653/v1/w19-4825. arXiv: 1906.01698. [Online]. Available: https://github.com/.
[24] Y. Goldberg, "Assessing BERT’s Syntactic Abilities," 2019. arXiv: 1901.05287. [Online]. Available: http://arxiv.org/abs/1901.05287.
[25] D. Yenicelik, F. Schmidt, and Y. Kilcher, "How does BERT capture semantics? A closer look at polysemous words," Association for Computational Linguistics (ACL), Nov. 2020, pp. 156–162. DOI: 10.18653/v1/2020.blackboxnlp-1.15. [Online]. Available: https://aclanthology.org/2020.blackboxnlp-1.15.
[26] R. Bommasani, D. A. Hudson, E. Adeli, et al., "On the Opportunities and Risks of Foundation Models," Aug. 2021. arXiv: 2108.07258. [Online]. Available: http://arxiv.org/abs/2108.07258.
[27] I. Beltagy, M. E. Peters, and A. Cohan, "Longformer: The Long-Document Transformer," 2020. arXiv: 2004.05150. [Online]. Available: http://arxiv.org/abs/2004.05150.
[28] Y. Liu, M. Ott, N. Goyal, et al., "RoBERTa: A Robustly Optimized BERT Pretraining Approach," 2019. arXiv: 1907.11692. [Online]. Available: http://arxiv.org/abs/1907.11692.
[29] C. Almodovar, F. Sabrina, S. Karimi, and S. Azad, "Can language models help in system security? Investigating log anomaly detection using BERT," in Proceedings of the 20th Annual Workshop of the Australasian Language Technology Association, Adelaide, Australia: Australasian Language Technology Association, Dec. 2022, pp. 139–147. [Online]. Available: https://aclanthology.org/2022.alta-1.19.
[30] L. N. Smith and N. Topin, "Super-convergence: Very fast training of neural networks using large learning rates," 2019, p. 36, ISBN: 9781510626775. DOI: 10.1117/12.2520589. arXiv: 1708.07120.
[31] J. Howard and S. Ruder, "Universal language model fine-tuning for text classification," in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Melbourne, Australia: Association for Computational Linguistics, Jul. 2018, pp. 328–339. DOI: 10.18653/v1/P18-1031. [Online]. Available: https://aclanthology.org/P18-1031.
[32] S. Gururangan, A. Marasovic, S. Swayamdipta, et al., "Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks," 2020, pp. 8342–8360. DOI: 10.18653/v1/2020.acl-main.740. arXiv: 2004.10964.
[33] A. Kumar, A. Raghunathan, R. Jones, T. Ma, and P. Liang, "Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution," Feb. 2022. arXiv: 2202.10054. [Online]. Available: http://arxiv.org/abs/2202.10054.
[34] W. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, "Detecting large-scale system problems by mining console logs," in ICML 2010 - Proceedings, 27th International Conference on Machine Learning, 2010, pp. 37–44, ISBN: 9781605589077.
[35] A. Oliner and J. Stearley, "What supercomputers say: A study of five system logs," in Proceedings of the International Conference on Dependable Systems and Networks, 2007, pp. 575–584, ISBN: 0769528554. DOI: 10.1109/DSN.2007.103.
[36] L. McInnes, J. Healy, and J. Melville, "UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction," arXiv preprint arXiv:1802.03426, 2018.