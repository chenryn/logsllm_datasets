# Fragment Reassembly in Digital Forensics

## Introduction
In digital forensics, the reassembly of scattered file fragments is a critical task. This paper presents a framework for reassembling fragmented documents using context-based statistical models. The problem is formulated as a graph problem, and a tree-pruning heuristic is proposed to compute near-optimal solutions.

## Reassembly Accuracy
### Figure 4: Average Reassembly of Fragments in a Single Pass
- **Logs and Operating System Files**: These files are reassembled more accurately due to their structured nature and predictable data patterns.
- **Source Code**: Standard keywords in source code facilitate the matching of fragments.
- **Binary Code and Binary Documents**: These files have less predictable patterns and often contain "file holes" (regions filled with zeros), making reassembly more challenging. When fragments are split along these holes, multiple candidates for adjacent fragments can arise, leading to uniformly distributed probabilities.
- **Raw Text and Encrypted/Compressed Data**: Unformatted plain text and chat transcripts are difficult to reassemble due to unpredictable words and large portions of empty spaces.

To address the challenges in binary files, the value of β is increased to look further down the path and choose the most likely fragment among competing ones. Compressed regions, such as inline images, further complicate the reassembly process.

## Compression Ratio
### Figure 5: Compression Ratio of Various Document Types
- **Log Files**: 57.7% - 68.0%
- **Executables**: 30.0% - 33.4%
- **Binary Files**: 23.4% - 28.4%
- **Unformatted Text**: 26.4% - 31.0%

The more structured a document, the better the accuracy of reassembly. This is evident when comparing the compression ratios in Figure 5 to the reassembly accuracy in Figure 4.

## Iterations Required for Reassembly
### Table 3: Iterations Required to Reconstruct the Entire Document
- **Log Files**: 4 iterations
- **Source Code**: 6 iterations
- **Executables**: 9 iterations
- **Binary Files**: 10 iterations
- **Unformatted Text**: 10 iterations

Even for unformatted and binary files, about 10 iterations are sufficient to converge to the correct reordering. This is a relatively small effort compared to manual analysis, especially for datasets with over a hundred fragments per file.

## Context Model Order
### Figure 6: Influence of Context Orders in Reassembly
- **Smaller Contexts (3 to 5)**: Generally perform well for various document types.
- **Larger Contexts**: Increasing the context size has little to no effect in most cases.

When candidate probabilities are properly distributed, increasing α and β yields better results. However, when probabilities are uniformly distributed, tweaking α and β has no influence on the results.

## Conclusion
Digital evidence is easily scattered, and forensic analysts often face the challenge of reassembling file fragments from randomly scattered data blocks. This paper introduces a general framework for reassembling scattered evidence using context-based statistical models. The problem is formulated as a graph problem, and a tree-pruning heuristic is proposed to compute near-optimal solutions. Our approach, implemented using PPM (Prediction by Partial Matching), shows promising results. Further investigation is needed to develop effective preprocessing heuristics for various document types. Incorporating meta-information, such as language syntax or instruction sets, will enhance the accuracy of reassembly. Future work includes reassembling image formats and collating fragments from mixed document types using text classification methods.

## References
- [1] J. G. Cleary and W. J. Teahan. Unbounded length context for PPM. The Computer Journal, 1997.
- [2] T. H. Cormen and e. a. Leiserson C. E. Introduction to algorithms. MIT Press, 2001.
- [3] G. S. I. Encase. http://www.encase.com/.
- [4] Freenet. http://freenetproject.org/.
- [5] Gnutella. http://gnutella.wego.com/.
- [6] I. Hamer and P. Chow. DES cracking on the Transmogrifier 2A. Cryptographic Hardware and Embedded Systems, LNCS 1717, Springer-Verlag, pages 13–24, 1999.
- [7] T. S. Kit. http://www.sleuthkit.org/.
- [8] D. E. Knuth and R. W. Moore. An analysis of alpha-beta pruning. Artificial Intelligence, pages 293–326, 1975.
- [9] J. Kubiatowicz and D. e. a. Bindel. OceanStore: An architecture for global-scale persistent storage. Proceedings of the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems, 2000.
- [10] H. C. G. Leitao and J. Stolfi. A multi-scale method for the re-assembly of fragmented objects. Proc. British Machine Vision Conference - BMVC 2000, 2:705–714, 2000.
- [11] A. Moffat. Implementing the PPM data compression scheme. IEEE Transactions on Communications, 1990.
- [12] M. o-o t. http://www.m-o-o-t.org/.
- [13] J. J. Rissanen. A universal data compression system. IEEE Transactions on Information Theory, 29(5):656–664, 1983.
- [14] J. J. Rissanen and G. G. Langdon. Arithmetic coding. IBM J. Res. Dev., 23(2):149–162, 1979.
- [15] J. J. Rissanen and G. G. Langdon. Universal modelling and coding. IEEE Transactions on Information Theory, 1981.
- [16] A. Rowstron and P. Druschel. Pastry: Scalable, distributed object location and routing for large-scale peer-to-peer systems. IFIP/ACM International Conference on Distributed Systems Platforms, pages 329–350, 2001.
- [17] I. Stoica and R. e. a. Morris. Chord: A scalable peer-to-peer lookup service for internet applications. ACM SIGCOMM 2001, pages 149–160, 2001.
- [18] T. C. T. (TCT). http://www.porcupine.org/forensics/tct.html.

Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25, 2021 at 07:46:44 UTC from IEEE Xplore. Restrictions apply.