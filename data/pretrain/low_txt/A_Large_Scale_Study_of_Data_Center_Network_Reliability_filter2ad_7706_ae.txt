### Size and Comparison to Previous Studies
Our study's size is comparable to that of Turner et al. [74] and three times larger than that of Wu et al. [75].

### Analysis of Backbone Network Failures
We analyze two types of backbone network failures:
- **Link Failures:** These occur when an individual bundle of optical fiber fails.
- **Edge Failures:** These happen when multiple link failures cause an entire edge to fail.

An edge connects to the backbone and the Internet using at least three links. If all of an edge’s links fail, the edge itself fails. Our dataset does not include root causes for these failures. We measure the mean time between failures (MTBF) and the mean time to recovery (MTTR) for both edges and links. Our analysis covers:
- Edge reliability (Section 6.1)
- Link reliability by fiber vendor (Section 6.2)
- Edge reliability by geographic location (Section 6.3)

### 6.1 Edge Reliability
- **Typical Edge Failure Rate:** On the order of months
- **Typical Edge Recovery Rate:** On the order of hours

**Figure 15:** MTBF as a function of the percentage of edges connecting Facebook data centers with that MTBF or lower.

Edges exhibit high variance in MTBF due to their diverse fiber vendor makeup and geographic locations (explored in Sections 6.2 and 6.3). The standard deviation of edge MTBF is 1320 hours, with the least reliable edge failing on average once every 253 hours and the most reliable edge failing on average once every 8025 hours.

We model \( \text{MTBF}_{\text{edge}}(p) \) as an exponential function of the percentage of edges, \( 0 \leq p \leq 1 \), with that MTBF or lower. We built these models using the least squares method. At Facebook, we use these models in capacity planning to calculate conditional risk, which is the likelihood of an edge or link being unavailable given a set of failures. We plan edge and link capacity to tolerate the 99.99th percentile of conditional risk. We find that \( \text{MTBF}_{\text{edge}}(p) = 462.88e^{2.3408p} \) (the dotted line in Figure 15) with \( R^2 = 0.94 \).

**Figure 16:** MTTR as a function of the percentage of edges connecting Facebook data centers with that MTTR or lower.

Edge recovery occurs much faster than the time between outages because edges contain multiple links (at least three) and fiber vendors work to repair link failures rapidly. 50% of edges recover within 10 hours of a failure; 90% within 71 hours.

### 6.2 Link Reliability by Fiber Vendor
- **Typical Vendor Link Failure Rate:** On the order of months
- **Higher MTBF in High Competition Markets**
- **Vendor MTBF and MTTR Span Multiple Orders of Magnitude**

We next analyze the MTBF and MTTR for fiber vendors based on when the links they operate fail or recover. For brevity, we refer to "the MTBF/MTTR of the links operated by a fiber vendor" as "fiber vendor MTBF/MTTR."

**Figure 17:** MTBF as a function of the percentage of fiber vendors with that MTBF or lower.

For most vendors, link failure happens only occasionally due to regular maintenance and monitoring. 50% of vendors have at least one link failure every 2326 hours, or once every 3.2 months. And 90% of vendors have at least one link failure every 5709 hours.

Fiber vendor MTBF varies by orders of magnitude. The standard deviation of fiber vendor MTBF is 2207 hours, with the least reliable vendor’s links failing on average once every 2 hours and the most reliable vendor’s links failing on average once every 11,721 hours. Anecdotally, we observe that fiber markets with high competition lead to more incentive for fiber vendors to increase reliability. For example, the most reliable vendor operates in a big city in the USA.

**Figure 18:** MTTR as a function of the percentage of fiber vendors with that MTTR or lower.

Most vendors repair links promptly. 50% of vendors repair links within 13 hours of a failure; 90% within 60 hours.

Fiber vendors exhibit high variance in MTTR because some fiber vendors operate in areas where they can more easily repair links (an observation we analyze in Section 6.3). The standard deviation of fiber vendor MTTR is 56 hours, with the slowest vendor taking on average 744 hours to repair their links and the most reliable vendor taking on average 1 hour to repair their links.

We model \( \text{MTTR}_{\text{vendor}}(p) \) as an exponential function of the percentage of vendors, \( 0 \leq p \leq 1 \), with that MTTR or lower. We find that \( \text{MTTR}_{\text{vendor}}(p) = 1.1345e^{4.7709p} \) (the dotted line in Figure 18) with \( R^2 = 0.98 \).

### 6.3 Edge Reliability by Geographic Location
- **Edge Failure Rate Similar Across Most Continents**
- **Edges Recover Within 1 Day on Average on All Continents**

We analyze the reliability of edges by their geographic location using the continent they reside on. Table 4 shows the distribution of edges in Facebook’s network among continents. Most edges reside in North America, followed closely by Europe. The continents with the fewest edges are Africa and Australia.

**Table 4:** Distribution and reliability of edges in Facebook’s network among continents.

| Continent         | Distribution | MTBF (hours) | MTTR (hours) |
|-------------------|--------------|--------------|--------------|
| North America     | 37%          | 1848         | 37           |
| Europe            | 33%          | 2029         | 33           |
| Asia              | 14%          | 2352         | 14           |
| South America     | 10%          | 1579         | 10           |
| Africa            | 4%           | 5400         | 4            |
| Australia         | 2%           | 1642         | 2            |

**MTBF:** We show the average MTBF for the edges in each continent in Table 4. Edges in Africa are outliers, with an average MTBF of 5400 hours, or 7.4 months. Edge reliability in Africa is important because edges in Africa are few and connect Europe and Asia. Edges in North America, South America, Europe, Asia, and Australia have average MTBFs ranging from 1579 hours (2.2 months, for South America) to 2352 hours (3.2 months, for Asia).

**MTTR:** We show the average MTTR for the edges in each continent in Table 4. Across continents, edges recover within 1 day on average. Edges in Africa, despite their long uptime, take the longest time on average to recover at 22 hours due to their submarine links. Edges in Australia take the shortest time on average to recover at 2 hours due to their locations in big cities. We observe a 7-hour standard deviation in edge MTTR among continents.

### 6.4 Inter Data Center Reliability Implications
- **Extending Automated Remediation to the Edge:** While Facebook can use software automation to improve the reliability of networks within our data centers, providing similar automation to the backbone networks that connect our data centers is a key challenge. Given that we often do not have full control of the devices along the links that connect the edges, coming up with a standard protocol and an automated procedure to enable this type of interaction or designing generic remediation systems is an important focus.
- **Coordinated Understanding of Shared Backbone Resources:** We reported on the reliability characteristics of the backbone links that Facebook operates on, yet in many cases, Facebook is only one of the many entities that share backbone link connectivity. Despite the shared fate of these links, relatively little openly accessible data is available on their reliability characteristics. While we have characterized the links that Facebook operates on, we hope that our work inspires other practitioners throughout the community to contribute to the body of knowledge available on this less understood aspect of web service operation.

### 7 Related Work
To our knowledge, this paper provides the first comprehensive study of network incidents from the perspective of large-scale web services. Prior large-scale data center failure studies [8, 16, 35, 60] report that network incidents are among the major causes of web service outages; however, none of these studies systematically analyze network incidents at a large scale, focusing on the availability of an entire web service, across both inter and intra data center networks, in a long-term, longitudinal study.

There are several prior studies that examined the failure characteristics of network links and devices in different types of networks, including both data center networks [30, 62, 63, 77] and optical backbones [29, 51, 63]. Specifically, Potharaju and Jain [63] and Turner et al. [74] also studied data center network infrastructure by characterizing device/link failures in both intra and inter data center networks. Their studies also characterized the failure impact, including connectivity losses, high latency, packet drops, and so on. These studies significantly boost the understanding of network failure characteristics and provide insights for network engineers and operators to improve the fault tolerance of existing networks and to design more robust networks.

While our work is closely related to these prior studies, it is fundamentally different and complementary in the following three aspects:
1. **Different Goal:** Unlike prior studies that focus on understanding fine-grained per-device, per-link failures and their impact on system-level services above the network stack, our work focuses on how network incidents affect the availability of the Internet service. Our goal is to reveal and quantify the incidents that cannot be tolerated despite industry best practices and shed light on how large-scale systems operate reliably in the face of these incidents.
2. **Comparative Study:** Prior studies only cover data center and backbone networks with traditional Clos-based architectures, whereas our work presents a comparative study of the reliability characteristics of data center network infrastructure with both a traditional Clos-based design and a contemporary fabric-based design with smaller, merchant-silicon-based switches. As introduced in Section 3, we achieve this due to the heterogeneity of the data center network infrastructure of Facebook, where networks with different designs coexist and cooperate.
3. **Long-Term Longitudinal Analysis:** We present a long-term (seven years for intra data center networks and eighteen months for inter data center networks) longitudinal analysis to reveal the evolution of network reliability characteristics, while prior studies typically provide only aggregated results, often over a much shorter period or with orders of magnitude fewer switches [74].

Govindan et al. [33] studied over 100 failure events at Google WAN and data center networks, offering insights on why maintaining high levels of availability for content providers is challenging. Their study, similar to [8, 16, 35, 60], focuses on network management and the design principles for building robust networks. Many of the high-level design principles mentioned in [33], such as using multiple layers of fallback (defense in depth), continuous prevention, and recovering fast, are applicable for large-scale software systems to protect against network incidents.

### 8 Conclusions
At Facebook, we strive to maintain a reliable network infrastructure both within (intra) and between (inter) data centers. In this study, we have characterized the network incidents we observe and their behavior on the software systems that run on them. We have also analyzed the backbone links that connect data centers and modeled their reliability characteristics. Our analysis revealed several key observations about the networks within and between data centers.

As software systems grow in complexity, interconnectedness, and geographic distribution, unwanted behavior from network infrastructure has the potential to become a key limiting factor in the ability to reliably operate distributed software systems at a large scale. To ameliorate the negative effects of network errors on service reliability, we have highlighted several promising implications for future network research.

We look forward to future research that sheds light on some of these important directions. It is our hope that the research community can build upon this study to better characterize, understand, and improve the reliability of data center networks and systems.

### Acknowledgements
We would like to thank Boliu Xu, Alexander Nikolaidas, James Zeng, Jimmy Williams, Omar Baldonado, and Hans Ragas for their feedback and suggestions while writing this paper.

### References
[1] Al-Fares, M., Loukissas, A., and Vahdat, A. A Scalable, Commodity Data Center Network Architecture. In Proceedings of the 2008 ACM SIGCOMM Conference (SIGCOMM'08) (Seattle, WA, USA, 2008).

[2] Alizadeh, M., Greenberg, A., Maltz, D. A., Padhye, J., Patel, P., Prabhakar, B., Sengupta, S., and Sridharan, M. Data Center TCP (DCTCP). In Proceedings of the 2010 ACM SIGCOMM Conference (SIGCOMM'10) (New Delhi, India, 2010).

[3] Andreyev, A. Introducing data center fabric, the next-generation Facebook data center network. https://code.facebook.com/posts/360346274145943/introducing-data-center-fabric-the-next-generation-facebook-data-center-network/, Nov. 2014.

[6] Bagga, J., and Yao, Z. Open networking advances with Wedge and FBOSS. https://code.facebook.com/posts/145488969140934/open-networking-advances-with-wedge-and-fboss/, Nov. 2015.

[7] Bailis, P., and Kingsbury, K. The Network is Reliable: An informal survey of real-world communications failures. Communications of the ACM (CACM) 57, 9 (Sept. 2014), 48–55.

[8] Barroso, L. A., Clidaras, J., and Hölzle, U. The Datacenter as a Computer: An Introduction to the Design of Warehouse-scale Machines, 2nd ed. Morgan and Claypool Publishers, 2013.

[9] Basiri, A., Behnam, N., de Rooij, R., Hochstein, L., Kosewski, L., Reynolds, J., and Rosenthal, C. Chaos Engineering. IEEE Software 33, 3 (May 2016), 35–41.

[10] Beaver, D., Kumar, S., Li, H. C., Sobel, J., and Vajgel, P. Finding a Needle in