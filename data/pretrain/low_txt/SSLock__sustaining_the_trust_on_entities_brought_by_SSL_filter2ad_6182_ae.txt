### Balancing Privacy and Protection

When it comes to online security, users often face a trade-off: they can prioritize privacy at the expense of protection or sacrifice some level of protection to maintain their privacy. This section explores various methods and initiatives aimed at enhancing both privacy and protection, along with their limitations.

#### Website’s Initiative: Opt-in Secure Cookie

To enhance protection, an opt-in website can configure a secure cookie with a far future expiration date in every valid HTTPS response. For example:

```http
Set-Cookie: ForceHTTPS; Expires=Wed, 01-Jan-2020 00:00:00 GMT; Secure
```

Upon receiving this cookie, a browser that supports ForceHTTPS will enable the protection until the cookie expires or is cleared. However, this protection is frequently neutralized if users employ privacy modes (such as Incognito Mode in Google Chrome), which are designed to purge cookies and browsing histories after each session. Users can also manually clear their cookies and browsing histories, leading to the same result. Consequently, even if a service provider takes the initiative to set up this protection, it can be easily neutralized on the client side. Additionally, the cookie must be present in all HTTPS requests or responses. After our paper was submitted, we found that ForceHTTPS has evolved into Strict Transport Security (STS), which still faces the same limitations.

#### User’s Initiative: Domain-Specific Profiles

Users can create domain-specific profiles that identify HTTPS URLs using regular expressions. The tool is designed to deny access to pages that are no longer served over valid HTTPS. However, it is inherently difficult for public users to define rules that cover all HTTPS pages of numerous websites, especially since these sites frequently change. For simple websites, advanced users might be able to create a few rules. But for more complex websites, users are likely to either give up or copy profiles distributed by other contributors, who may not be reliable. Currently, there is no mechanism to verify the authenticity and reliability of these rules with the website owners.

### Force-HTTPS in Google Chrome

Google Chrome was the first browser to allow only valid HTTPS connections. As shown in Figure 5, a user must add the special parameter `--force-https` to enable this protection, which accepts only valid HTTPS connections.

Upon recognizing the severity of SSL operational flaws, the browser vendor attempted to provide mitigation. However, this approach can be overly restrictive. For instance, the browser returns errors when visiting a website with an invalid certificate or opening `http://google.com` in a new tab. While these errors are expected, they can negatively impact the user experience, as users may need to copy and paste blocked URLs into an unprotected browser. Without proper segmentation between the security demands of different websites, it is doubtful whether such a sacrificial protection method will gain widespread adoption.

### Extended Validation (EV) Certificates

EV certificates provide users with extra confidence that a website is "secure" by displaying a green address bar. These certificates are typically more expensive than standard digital certificates, despite being technically similar. The main difference lies in the extensive validation process conducted by Certificate Authorities (CAs) to verify the legal identity and presence of the website owner. According to an independent usability study [14], 77% of participants would hesitate to shop if the green bar, which had been previously shown, was missing. Although 36% of participants would continue shopping, it is regrettable that these trained participants were informed about the potential absence of the green bar rather than recognizing it themselves.

Firstly, the effectiveness of EV as a visual security indicator depends on users, who should be ruled out in security-critical operations [1]. Some researchers have tried to exploit the visual indicator through picture-in-picture attacks [15]. Secondly, EV suffers from initialization attacks if a user forgets or is unaware of the green bar's existence. Lastly, EV is not an automated mechanism that can prevent users from bypassing security warnings and compromising SSL protection.

### Locked Single-Origin Policies (SOP)

Locked SOP [16] refines the traditional SOP with two proposals: weak-locked and strong-locked SOP. In legacy SOP, two objects can communicate only if they are served from the same origin (protocol, host, and port). Weak-locked SOP further segments the origin by treating content served with valid certificates as different from content served with invalid ones. Strong-locked SOP further segments the origin by determining if a public key is declared trusted through a periodically retrieved policy file `/pk.txt`. Thus, locked SOP is designed to mitigate attacks where both legitimate and malicious content are downloaded to a browser.

However, locked SOP cannot mitigate man-in-the-middle attacks where all content is downloaded from a malicious source. For example, if a user bypasses certificate warnings, as in attack 2, locked SOP cannot prevent SSL protection from being compromised. Additionally, locked SOP protection will not be triggered in attack 3, as no certificate is supplied to the victim’s browser. Furthermore, SOP implementation is known to have issues [17].

### DNS Security Extensions (DNSSEC)

DNSSEC extends the current DNS by digitally signing DNS responses to ensure authenticity and integrity [18]. Proposed for over a decade, its deployment has been hindered by backward compatibility problems and the complexity of deploying it on a large scale. Recently, the Kaminsky DNS attacks [19] have prompted a re-evaluation of DNSSEC deployment.

DNSSEC authenticates the mapping from a domain to an IP address, raising the bar for pharmers. However, even if a legitimate IP is resolved, one is not guaranteed to connect to a legitimate host. For instance, adversaries in a man-in-the-middle setting, like in attacks 2 and 3, can still mount attacks without altering DNS responses. Therefore, it is questionable whether the deployment effort for DNSSEC is justified.

### Conclusion

SSL has been protecting trillions of transactions worldwide, but it remains fragile due to serious operational flaws. Supported by numerous usability studies, these flaws must be addressed promptly. We urge application vendors to consider implementing SSLock due to its generic, lightweight, opt-in, zero-initialization, privacy-preserving, and user-friendly nature. The proposal is further justified by its high compatibility rate. SSLock sustains SSL protection by ruling out users from security-critical operations and is the only single approach capable of protecting users from severe dynamic pharming, deceptive captive portal, and SSLStrip attacks. Unless SSLock is deployed, it is likely that more attacks exploiting the operational flaw will occur if we continue to rely on users as the primary defense against legitimacy judgment.

### Acknowledgements

We thank Scottie K.S. Tse, T.Y. Wong, and Victor K. Wei for their helpful suggestions and feedback. We also thank anonymous reviewers for their valuable comments.

### References

[1] Lorrie Faith Cranor. A framework for reasoning about the human in the loop, in Proceedings of Usability, Psychology, and Security 2008 (UPSEC ’08), April 2008, San Francisco, CA, USA.

[2] Stephen Bell. Invalid banking cert spooks only one user in 300. ComputerWorld New Zealand, http://computerworld.co.nz/news.nsf/NL/FCC8B6B48B24CDF2CC2570020018FF73, May 2005.

[3] Moxie Marlinspike, New Techniques for Defeating SSL/TLS. https://www.blackhat.com/presentations/bh-dc-09/Marlinspike/BlackHat-DC-09-Marlinspike-Defeating-SSL.pdf.

[4] Johnathan Nightingale. MitM Me (SSL Error Bypass). https://addons.mozilla.org/en-US/firefox/addon/6843.

[5] Jerry Qian. Remember Certificate Exception. https://addons.mozilla.org/en-US/firefox/addon/10246.

[6] Andrew Lucking. Remember Mismatched Domains. https://addons.mozilla.org/en-US/firefox/addon/2131.

[7] Joshua Sunshine, Serge Egelman, Hazim Almuhimedi, Neha Atri, Lorrie Faith Cranor, Crying Wolf: An Empirical Study of SSL Warning Effectiveness, in Usenix Security Symposium, August 10-14, 2009, Montréal, Canada.

[8] Stuart E. Schechter, Rachna Dhamija, Andy Ozment, Ian Fischer, The Emperor's New Security Indicators, in Proceedings of the 2007 IEEE Symposium on Security and Privacy, p.51-65, May 20-23, 2007.

[9] Rachna Dhamija, J. D. Tygar, Marti Hearst, Why phishing works, in Proceedings of the SIGCHI conference on Human Factors in computing systems, April 22-27, 2006, Montréal, Canada.

[10] Yue Zhang, Serge Egelman, Lorrie Faith Cranor, and Jason Hong. Phinding phish: Evaluating anti-phishing tools, in Proceedings of the 14th Annual Network and Distributed System Security Symposium (NDSS 2007), February 2007.

[11] Collin Jackson and Adam Barth, ForceHTTPS: Protecting High-Security Web Sites from Network Attacks, in Proceedings of the 17th International World Wide Web Conference (WWW2008), April 21-25, 2008, Beijing, China.

[12] Jeff Hodges, Collin Jackson, Adam Barth. Strict Transport Security. http://bit.ly/438ir0, 18 December 2009.

[13] Google Chrome, Release Notes 2.0.156.1 (Chromium Developer Documentation). http://dev.chromium.org/getting-involved/dev-channel/release-notes/releasenotes201561.

[14] Tec-Ed Inc., Extended Validation and VeriSign Brand. http://www.verisign.com/static/040655.pdf.

[15] Collin Jackson, Daniel R. Simon, Desney S. Tan, and Adam Barth. An Evaluation of Extended Validation and Picture-in-Picture Phishing Attacks, in Proceedings of Usable Security (USEC '07), February 2007.

[16] C. Karlof, J. Tygar, D. Wagner, U. Shankar. Dynamic pharming attacks and locked same-origin policies for web browsers, in Proceedings of the 14th ACM conference on computer and communications security (CCS), 2007, New York, USA.

[17] S. Chen, D. Ross, and Y.-M. Wang. An analysis of browser domain-isolation bugs and a light-weight transparent defense mechanism, in Proceedings of the 14th ACM conference on Computer and communications security (CCS), 2007, New York, USA.

[18] DNSSEC – The DNS Security Extensions. http://www.dnssec.net/.

[19] Dan Kaminsky, Black Ops 2008: It’s The End Of The Cache As We Know It. http://www.blackhat.com/presentations/bh-jp-08/bh-jp-08-Kaminsky/BlackHat-Japan-08-Kaminsky-DNS08-BlackOps.pdf.

[20] Mozilla Foundation, Secure Connection Failed. http://support.mozilla.com/kb/Secure+connection+failed.

[21] Bugzilla@Mozilla – Bug 430790, Users can be tricked into thinking sites are encrypted with new visual cues added by bug 417844. https://bugzilla.mozilla.org/show_bug.cgi?id=430790, 25 April 2008.

[22] GoDaddy.com, Inc., SSL Certificate Services. http://www.godaddy.com/gdshop/compare/gdcompare_ssl.asp?isc=sslqgo002b.

[23] GeoTrust Inc., RapidSSL Competitive Replacement. https://products.geotrust.com/orders/rapidssl.do.

[24] S. Chen, Z. Mao, Y.M. Wang, M. Zhang, Pretty-Bad-Proxy. An Overlooked Adversary in Browsers’ HTTPS Deployments, in Proceedings of the 2009 IEEE Symposium on Security and Privacy, May 17-20, 2009.

[25] Alexander Sotirov, Marc Stevens, Jacob Appelbaum, Arjen Lenstra, David Molnar, Dag Arne Osvik, Benne de Weger, MD5 considered harmful today -- Creating a rogue CA certificate. http://www.phreedom.org/research/rogue-ca/.

[26] Bugzilla@Mozilla - Bug 470897, Investigate incident with CA that allegedly issued bogus cert for www.mozilla.com. https://bugzilla.mozilla.org/show_bug.cgi?id=470897, 23 December 2008.