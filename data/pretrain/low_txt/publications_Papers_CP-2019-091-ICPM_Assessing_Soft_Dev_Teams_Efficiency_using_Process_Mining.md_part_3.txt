# Teams and Process Mining Analysis

## Table of Contents
1. Unique Categories, Commands, and Edited Files Statistics
2. Behavior Differences Comparison
3. Assignment Duration
4. External Validity
5. Conclusions and Future Work
6. Acknowledgment
7. References

---

## 1. Unique Categories, Commands, and Edited Files Statistics
**Figure 3.** Unique Categories, Commands, and Edited Files Statistics

---

## 2. Behavior Differences Comparison
**Table III.** Behavior Differences Comparison

| Team | Reference Log | Control-Flow Differences (%) |
|------|---------------|------------------------------|
| T-41 | 87.60%        |
| T-26 | 85.11%        |
| T-24 | 85.04%        |

---

## 3. Assignment Duration
**Table IV.** Assignment Duration

| Team | Proficiency | Process Duration   |
|------|-------------|--------------------|
| T-43 | 0           | 23h:49m            |
| T-41 | 0.73        | 18d:3h             |
| T-02 | 0.75        | 11d:22h            |
| T-26 | 0.75        | 12d:16m            |
| T-23 | 0.72        | 12d:13m            |
| T-21 | 0.02        | 8d:12h             |
| T-24 | 0.64        | 47m:14s            |
| T-01 | 0           | 10d:7h             |
| REFERENCE | -         | 23m:05s            |

The mined processes reflect these times, but indeed, that was idle time. Nevertheless, other reasons may exist for these delays, and therefore, their model is in fact accurate because it plots what really happened.

---

## 4. External Validity
Since we wanted to block some factors such as the degree of previous experience (background) in the proposed process and repeat the data collection process in a between-groups design to avoid the learning effects of paired designs, the only feasible solution was to use students as subjects, as referred to in subsection III-B1. We cannot claim that these students are adequate surrogates for professional software developers.

---

## 5. Conclusions and Future Work

### A. Conclusions

1. **RQ1:**
   - Software development Integrated Development Environments (IDEs) provide users with a vast number of commands and menus to execute from, as seen in Section II-C. Trying to model these is indeed a challenge, and most times, a spaghetti-like process is the result of a successful process discovery.
   - Some users have stopped the collection mechanism, making it impossible to understand what they were doing during that period. We also found that a few teams made a pause in the task, causing it to express more execution time than what was actually needed.
   - Despite these challenges, we were able to model teams' behavior with moderate-to-strong fitness and precision values and achieve readable models. However, these values should be validated with more experiments and different data. No relevant performance or bottleneck patterns were identified in the processes, which may be related to the type of task requested, which did not impose restrictions on working times or the reduced schedule imposed on the task.

2. **RQ2:**
   - We were able to discover and reconstruct process models representing the efficiency of software development teams, where, in some cases, members were working individually, each with their own IDE setup configurations.
   - We confirmed that process mining may play a fundamental role in assessing the efficiency of software development teams and in potentially contributing to keeping them focused on their tasks by checking and enforcing compliance to prescribed processes.

3. **RQ3:**
   - By assessing the way a task is executed and the proficiency achieved, as we did to answer RQ3, we looked for any relation between these on the software development realm.
   - In general, teams with less complexity in their models were among the most proficient in the task. This means that they not only understood what was requested but also had the maturity to deliver what was expected by following a simple process. They were not only effective but also efficient by being focused on the task.
   - On the contrary, teams with insufficient proficiency produced long and complex models or, in very short time, created very fuzzy models with too many generic events. These teams posed more risk from a development project perspective due to their erratic behavior and uncertainty around the expected deliveries. Some of these teams did not perform well, and quality was impacted, and some did not even deliver what was expected. In a real-world scenario, these teams would have been identified as the most expensive due to their low productivity.

### B. Future Work
The current work can be expanded in breadth and depth. In this paper, we mainly explored the control-flow perspective, but other perspectives, such as organizational and performance, are worth exploring. Devising team dynamics based on the identification of the artifacts impacted/touched by the developers can be one of the following paths to research further. This study also opens the opportunity for new research related to forensic analysis on software development processes, exploring a combined perspective of the quality of the artifacts produced and the underlying processes.

While unveiling the details of past process instances is important to understand what went wrong or unplanned, we should be able to react as soon as possible, that is, while the process is being executed, to enable just-in-time corrective actions. The IDE-based process mining architecture presented in this paper forms the base of our SPOTS (Software Process On-the-run Tracking System). This tool will provide near real-time software development process insights at the individual or team level, such as in the Personal Software Process [34] or Team Software Process approaches [35], but in an automated fashion. According to [15], this kind of operational support is the most advanced form of process mining action.

We also plan to investigate how development process smells [36] may be used to assess software process drift management. Machine learning techniques are plausible candidates to automatically classify mined models (as good or bad process smells).

---

## 6. Acknowledgment
The authors would like to thank all ISCTE-IUL students involved in this research, as well as Prof. Vitor Basto Fernandes, who was in charge of the Software Engineering course where the experiment took place.

---

## 7. References
[1] P. Mohagheghi and M. Jorgensen, “What Contributed to the Success of IT Projects? Success Factors, Challenges, and Lessons Learned from an Empirical Study of Software Projects in the Norwegian Public Sector,” in 2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C). IEEE, May 2017, pp. 371–373. [Online]. Available: http://ieeexplore.ieee.org/document/7965362/

[2] T. Chow and D.-B. Cao, “A Survey Study of Critical Success Factors in Agile Software Projects,” Journal of Systems and Software, vol. 81, no. 6, pp. 961–971, June 2008. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0164121207003164

[3] M. Tanner and U. Von Willingh, “Factors Leading to the Success and Failure of Agile Projects Implemented in Traditionally Waterfall Environments,” in Management, Knowledge and Learning. Cape Town: University of Cape Town, South Africa, 2014, pp. 693–700. [Online]. Available: http://www.toknowpress.net/ISBN/978-961-6914-09-3/papers/ML14-618.pdf

[4] A. Aldahmash, A. M. Gravell, and Y. Howard, “A Review on the Critical Success Factors of Agile Software Development,” in European Conference on Software Process Improvement. Springer, Cham, 2017, pp. 504–512. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-319-65915-7_41

[5] M. Borges Ribeiro, V. Diniz Duarte, E. Gomes Salgado, and C. Vieira Castro, “Prioritization of Critical Success Factors in the Process of Software Development,” IEEE Latin America Transactions, vol. 15, no. 1, pp. 137–144, January 2017. [Online]. Available: http://ieeexplore.ieee.org/document/7827917/

[6] K. E. Emam and A. G. Koru, “A Replicated Survey of IT Project Failures,” IEEE Software, vol. 25, no. 5, pp. 84–90, September 2008. [Online]. Available: http://ieeexplore.ieee.org/document/4602680/

[7] P. A. McQuaid, “Software Disasters—Understanding the Past, to Improve the Future,” Journal of Software: Evolution and Process, vol. 24, no. 5, pp. 459–470, 2012. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.552

[8] IEEE Computer Society, SWEBOK V3.0. IEEE Computer Society, 2014, no. V3.0. [Online]. Available: http://www4.ncsu.edu/~tjmenzie/cs510/pdf/SWEBOKv3.pdf

[9] M. Niazi, S. Mahmood, M. Alshayeb, M. R. Riaz, K. Faisal, N. Cerpa, S. U. Khan, and I. Richardson, “Challenges of Project Management in Global Software Development: A Client-Vendor Analysis,” Information and Software Technology, vol. 80, no. C, pp. 1–19, December 2016. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0950584916301227

[10] A. M. Lemos, C. C. Sabino, R. M. F. Lima, and A. L. Oliveira, “Conformance Checking of Software Development Processes Through Process Mining,” SEKE, 2011. [Online]. Available: https://dl.acm.org/doi/abs/10.1145/2024401.2024462

[11] J. Caldeira and F. Brito e Abreu, “Software Development Process Mining: Discovery, Conformance Checking, and Enhancement,” in Proceedings - 2016 10th International Conference on the Quality of Information and Communications Technology, QUATIC 2016. IEEE, September 2017, pp. 254–259. [Online]. Available: http://ieeexplore.ieee.org/document/7814558/

[12] W. Poncin, A. Serebrenik, and M. V. D. Brand, “Process Mining Software Repositories,” 2011 15th European Conference on Software Maintenance and Reengineering, pp. 5–14, 2011. [Online]. Available: https://ieeexplore.ieee.org/document/5784606

[13] W. Van Der Aalst, A. Adriansyah, A. K. A. De Medeiros, F. Arcieri, T. Baier, T. Blickle, J. C. Bose, P. Van Den Brand, R. Brandtjen, J. Buijs, A. Burattin, J. Carmona, M. Castellanos, J. Claes, J. Cook, N. Costantini, F. Curbera, E. Damiani, M. De Leoni, P. Delias, B. F. Van Dongen, M. Dumas, S. Dustdar, D. Fahland, D. R. Ferreira, W. Gaaloul, F. Van Geffen, S. Goel, C. Günther, A. Guzzo, P. Harmon, A. Ter Hofstede, J. Hoogland, J. E. Ingvaldsen, K. Kato, R. Kuhn, A. Kumar, M. La Rosa, F. Maggi, D. Malerba, R. S. Mans, A. Manuel, M. McCreesh, P. Mello, J. Mendling, M. Montali, H. R. Motahari-Nezhad, M. Zur Muehlen, J. Munoz-Gama, L. Pontieri, J. Ribeiro, A. Rozinat, H. Seguel Pérez, R. Seguel Pérez, M. Sepúlveda, J. Sinur, P. Soffer, M. Song, A. Sperduti, G. Stilo, K. Swenson, M. Talamo, W. Tan, C. Turner, J. Vanthienen, G. Varvaressos, E. Verbeek, M. Verdonk, R. Vigo, J. Wang, B. Weber, M. Weidlich, T. Weijters, L. Wen, M. Westergaard, and M. Wynn, “Process Mining Manifesto,” Lecture Notes in Business Information Processing, vol. 99 LNBIP, pp. 169–194, 2012. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-642-28125-1_10

[14] M. L. Van Eck, X. Lu, S. J. J. Leemans, and W. M. P. Van Der Aalst, “PM²: A Process Mining Project Methodology,” in International Conference on Advanced Information Systems Engineering CAiSE 2015: Advanced Information Systems Engineering. Springer, Cham, 2015, pp. 297–313. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-319-19155-9_19

[15] W. van der Aalst, Process Mining: Data Science in Action. Berlin, Heidelberg: Springer Berlin Heidelberg, 2016. [Online]. Available: https://link.springer.com/book/10.1007/978-3-662-49851-4

[16] A. Fuggetta, E. D. Nitto, and P. Milano, “Software Process,” Proceedings of the On Future of Software Engineering, pp. 1–12, 2014. [Online]. Available: https://dl.acm.org/doi/abs/10.1145/2593882.2593910

[17] A. Meidan, J. A. García-García, I. Ramos, and M. J. Escalona, “Measuring Software Process,” ACM Computing Surveys, vol. 51, no. 3, pp. 1–32, June 2018. [Online]. Available: http://dl.acm.org/citation.cfm?doid=3212709.3186888

[18] A. R. C. Maita, L. C. Martins, C. R. López Paz, L. Rafferty, P. C. K. Hung, S. M. Peres, and M. Fantinato, “A Systematic Mapping Study of Process Mining,” Enterprise Information Systems, vol. 12, no. 5, pp. 505–549, May 2018. [Online]. Available: https://www.tandfonline.com/doi/full/10.1080/17517575.2017.1402371

[19] V. A. Rubin, I. Lomazova, and W. M. P. van der Aalst, “Agile Development with Software Process Mining,” Proceedings of the 2014 International Conference on Software and System Process - ICSSP 2014, pp. 70–74, 2014. [Online]. Available: https://dl.acm.org/doi/abs/10.1145/2593882.2593910

[20] V. A. Rubin, A. A. Mitsyuk, I. A. Lomazova, and W. M. P. van der Aalst, “Process Mining Can Be Applied to Software Too!” Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement - ESEM’14, pp. 1–8, 2014. [Online]. Available: https://dl.acm.org/doi/abs/10.1145/2652524.2652536

[21] C. Ioannou, A. Burattin, and B. Weber, “Mining Developers’ Workflows from IDE Usage,” Lecture Notes in Business Information Processing, vol. 316, pp. 167–179, 2018. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-319-98668-9_11

[22] L. Bao, Z. Xing, X. Xia, D. Lo, and A. E. Hassan, “Inference of Development Activities from Interaction with Uninstrumented Applications,” Empirical Software Engineering, vol. 23, no. 3, pp. 1313–1351, June 2018. [Online]. Available: https://link.springer.com/article/10.1007/s10664-017-9547-8

[23] K. Damevski, D. C. Shepherd, J. Schneider, and L. Pollock, “Mining Sequences of Developer Interactions in Visual Studio for Usage Smells,” IEEE Transactions on Software Engineering, vol. 43, no. 4, pp. 359–371, April 2017. [Online]. Available: https://ieeexplore.ieee.org/document/7854041

[24] M. Leemans, W. M. P. van der Aalst, and M. G. J. van den Brand, “The Statechart Workbench: Enabling Scalable Software Event Log Analysis Using Process Mining,” in 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, March 2018, pp. 502–506. [Online]. Available: https://ieeexplore.ieee.org/document/8330248

[25] K. Beck, M. Fowler, J. Brant, W. Opdyke, and D. Roberts, “Bad Smells in Code,” in Refactoring: Improving the Design of Existing Code. Addison-Wesley, 1999. [Online]. Available: https://martinfowler.com/books/refactoring.html

[26] C. Günther and E. Verbeek, “XES Standard Definition,” Fluxicon Process Laboratories, 2014. [Online]. Available: https://fluxicon.com/blog/2014/01/xes-standard-definition/

[27] I. Vanderfeesten, J. Cardoso, J. Mendling, H. A. Reijers, and W. Van Der Aalst, “Quality Metrics for Business Process Models,” Technische Universiteit Eindhoven, Tech. Rep., 2007. [Online]. Available: http://wwwis.win.tue.nl/wvdaalst/publications/p364.pdf

[28] A. Rozinat, A. de Medeiros, C. Günther, A. Weijters, and W. van der Aalst, “Towards an Evaluation Framework for Process Mining Algorithms,” Beta, Research School for Operations Management and Logistics, pp. 1–20, 2007. [Online]. Available: http://www.processmining.org

[29] A. Rozinat, M. Veloso, and W. M. P. van der Aalst, “Evaluating the Quality of Discovered Process Models,” Information Systems Journal, vol. 16, no. Section 2, pp. 1–8, 2008. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2575.2008.00282.x

[30] A. Bolt, M. de Leoni, and W. M. van der Aalst, “Process Variant Comparison: Using Event Logs to Detect Differences in Behavior and Business Rules,” Information Systems, vol. 74, pp. 53–66, May 2018. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0306437916305257

[31] M. Leemans, W. M. P. van der Aalst, and M. G. J. van den Brand, “Recursion Aware Modeling and Discovery for Hierarchical Software Event Log Analysis,” in 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), 2018, pp. 185–196. [Online]. Available: https://ieeexplore.ieee.org/document/8330248

[32] J. Cardoso, J. Mendling, G. Neumann, and H. A. Reijers, “A Discourse on Complexity of Process Models,” in International Conference on Business Process Management. Springer, 2006, pp. 117–128. [Online]. Available: https://link.springer.com/chapter/10.1007/11837862_9

[33] F. Jurado and P. Rodriguez, “Sentiment Analysis in Monitoring Software Development Processes: An Exploratory Case Study on GitHub’s Project Issues,” Journal of Systems and Software, vol. 104, pp. 82–89, 2015. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0164121215000485

[34] W. S. Humphrey, “Personal Software Process (PSP),” in Encyclopedia of Software Engineering, 2nd ed., J. J. Marciniak, Ed. New York, NY, USA: John Wiley & Sons, 2002, p. 1584. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/0471028959.sof210

[35] W. S. Humphrey, “Team Software Process (TSP),” Encyclopedia of Software Engineering, 2002. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/0471028959.sof211

[36] B. Weber, M. Reichert, J. Mendling, and H. A. Reijers, “Refactoring Large Process Model Repositories,” Computers in Industry, vol. 62, no. 5, pp. 467–486, 2011. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0166361510001029