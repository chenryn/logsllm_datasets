### Protection of Details from Disclosure

Giuffrida et al. [17] present a comprehensive, compiler-based software diversification approach that supports live re-randomization. The overheads associated with this method depend on the frequency of re-randomization. Snow et al. [40] report that JIT-ROP attacks can be executed in as little as 2.3 seconds. However, re-randomizing every two seconds adds an overhead of approximately 20%.

### Basic Block Randomization

The basic block randomization portion of our implementation is based on the STIR system [45]. STIR analyzes and rewrites binaries ahead of time to make them self-randomizing (or self-stirring). At load-time, a small randomization stub permutes the basic block and function layout within the binary. To account for disassembly errors, the original code is loaded as non-executable data, allowing the stirred binaries to compensate for these errors.

### Control-Flow Integrity (CFI)

In its most precise form, Control-Flow Integrity (CFI) [1] restricts indirect branches to flow only to a precise set of statically identified targets for each branch. Despite its potential, CFI has not seen widespread adoption in the industry. The primary reasons for this are:
1. The difficulty in reconstructing an accurate control-flow graph (CFG) for a binary without access to source code or debug symbols, which are often unavailable for commercial off-the-shelf (COTS) binaries.
2. Higher overheads compared to solutions based on code randomization.

Several low-overhead solutions have been proposed to impose less strict integrity checks on program executions. These include ROPecker [7], ROPGuard [16], and kBouncer [33]. Both ROPecker and kBouncer use the x86 last branch record (LBR) register set to perform their checks. For example, kBouncer performs CFI validation on the LBR during any Windows API invocation and ensures that all returns are call-preceded. ROPecker creates an offline gadget database, which is then compared at runtime with LBR entries to detect attacks. ROPGuard also performs CFI validation on Windows API calls, requiring that return addresses are call-preceded and verifying that the memory word before each return address is the start address of the API function.

### Coarse-Grained CFI Solutions

CFI for COTS binaries [50] is another proposed coarse-grained CFI solution. This technique can be applied to binaries without access to source code or debug information. It involves a static disassembly step where all potential branch (and return) targets are identified, and all indirect branches are instrumented with code that jumps to a CFI validation routine. The validation routine ensures that target and return addresses are either call-preceded or belong to the set of statically identified targets.

Similarly, Compact Control Flow Integrity and Randomization (CCFIR) [49] applies coarse-grained CFI to binaries without source code or debug information (but with relocation information). In this technique, permissible targets for indirect branches are collected into a separate Springboard section, and indirect branches are only allowed to flow into the Springboard. CCFIR also incorporates some elements of code randomization—target entries are placed at random locations within the Springboard. Although this confers an additional degree of security against traditional ROP attacks, disclosure attacks can read the full contents of the Springboard, nullifying its advantages against such attacks.

Davi et al. [11] tested these coarse-grained CFI solutions and found that they fail to adequately secure binaries against ROP attacks.

### Compiler-Based CFI Solutions

Forward CFI [43] and SafeDispatch [25] are two recent compiler-based CFI solutions. Forward CFI protects binaries by inserting validation checks for all forward-edge control flows. This solution is designed to secure forward control flows but does not protect against attacks that rely purely on return-terminated gadgets.

SafeDispatch protects C++ binaries from virtual table hijacking by recompiling binaries with a modified C++ compiler that instruments all virtual method call sites with runtime checks. These checks ensure that all method calls jump to valid implementations during execution. However, SafeDispatch only protects virtual method calls, leaving binaries vulnerable to ROP attacks that rely on modified return addresses on the stack.

### Conclusions

Control-Flow Integrity (CFI) and artificial software diversity are well-established, complementary strategies for protecting software against code-reuse attacks, including ROP attacks. Recent advances in offensive security have demonstrated how to bypass both: the security relaxations introduced by coarse-grained CFI to achieve acceptable performance are exploitable by skillful control-flow hijacking, and implementation disclosure vulnerabilities can be leveraged to derandomize even fine-grained artificial diversity defenses.

O-CFI combines and extends both CFI and fine-grained diversity to address the dual threat of code-reuse and implementation disclosure attacks. To do so, we reformulate CFI as a bounds-checking problem and repurpose fine-grained binary code randomization to diversify and conceal the exploitable edges of the protected program’s control-flow graph. As a result, O-CFI can protect software even against attackers who have complete read-access to the randomized program code.

Our prototype implementation demonstrates that O-CFI can be effectively applied to protect legacy binaries without source code, with experimental evaluation showing performance overheads of just 4.7% on legacy processors. Performance is expected to be even higher (approximately 4.17% overhead) on future-generation processors, as our bounds-checking implementation centers around Intel MPX instructions, which will be hardware-accelerated on forthcoming Intel-based processors.

### Acknowledgments

We thank Julian Lettner for benchmarking assistance, and Lucas Davi, Andrei Homescu, Christopher Liebchen, Matt Miller, and the anonymous reviewers for their insightful comments and suggestions.

This material is based upon work partially supported by the National Science Foundation (NSF) CAREER award #1054629, Office of Naval Research (ONR) award N00014-14-1-0030, Air Force Office of Scientific Research (AFOSR) award FA9550-14-1-0173, an Industry-University Collaborative Research Center grant from Raytheon Company, Defense Advanced Research Projects Agency (DARPA) contracts D11PC20024 and N660001-1-2-4014, and by gifts from Mozilla Corporation and Oracle Corporation. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the above supporters, their contracting agents, or any other agency of the U.S. Government.

### References

[1] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti, “Control-flow integrity principles, implementations, and applications,” ACM Trans. Information and System Security (TISSEC), vol. 13, no. 1, 2009.

[2] M. Backes and S. N¨urnberger, “Oxymoron: Making fine-grained memory randomization practical by allowing code sharing,” in Proc. 23rd Usenix Security Sym., 2014, pp. 433–447.

[3] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. N¨urnberger, and J. Pewny, “You can run but you can’t read: Preventing disclosure exploits in executable code,” in Proc. 21st ACM Conf. Computer and Communications Security (CCS), 2014, pp. 1342–1353.

[4] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazi`eres, and D. Boneh, “Hacking blind,” in Proc. 35th IEEE Sym. Security & Privacy (S&P), 2014, pp. 227–242.

[5] T. K. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang, “Jump-oriented programming: A new class of code-reuse attack,” in Proc. 6th ACM Sym. Information, Computer and Communications Security (ASIACCS), 2011, pp. 30–40.

[6] N. Carlini and D. Wagner, “ROP is still dangerous: Breaking modern defenses,” in Proc. 23rd Usenix Security Sym., 2014, pp. 385–399.

[7] Y. Cheng, Z. Zhou, M. Yu, X. Ding, and R. H. Deng, “ROPecker: A generic and practical approach for defending against ROP attacks,” in Proc. 21st Annual Network & Distributed System Security Sym. (NDSS), 2014.

[8] F. Cohen, “Operating system protection through program evolution,” Computers and Security, vol. 12, no. 6, pp. 565–584, 1993.

[9] Corelan Team, “Mona,” 2014, https://github.com/corelan/mona.

[10] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and F. Monrose, “Isomeron: Code randomization resilient to (just-in-time) return-oriented programming,” in Proc. 22nd Network and Distributed Systems Security Sym. (NDSS), 2015.

[11] L. Davi, A.-R. Sadeghi, D. Lehmann, and F. Monrose, “Stitching the gadgets: On the ineffectiveness of coarse-grained control-flow integrity protection,” in Proc. 23rd Usenix Security Sym., 2014, pp. 401–416.

[12] J. DeMott, “Bypassing EMET 4.1,” Bromium Labs, 2014, http://labs.bromium.com/2014/02/24/bypassing-emet-4-1.

[13] C. Evans, “Exploiting 64-bit Linux like a boss,” 2013, http://scarybeastsecurity.blogspot.com/2013/02/exploiting-64-bit-linux-like-boss.html.

[14] A. Fog, “Lists of instruction latencies, throughputs and micro-operation breakdowns for Intel, AMD and VIA CPUs,” 2014, http://www.agner.org/optimize/instruction tables.pdf.

[15] S. Forrest, A. Somayaji, and D. H. Ackley, “Building diverse computer systems,” in Proc. Workshop Hot Topics in Operating Systems, 1997, pp. 67–72.

[16] I. Fratri´c, “Runtime prevention of return-oriented programming attacks,” University of Zagreb, 2012, http://www.ieee.hr/download/repository/Ivan Fratric.pdf.

[17] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “Enhanced operating system security through efficient and fine-grained address space randomization,” in Proc. 21st USENIX Security Sym., 2012, pp. 475–490.

[18] E. G¨oktas¸, E. Athanasopoulos, H. Bos, and G. Portokalidis, “Out of control: Overcoming control-flow integrity,” in Proc. 35th IEEE Sym. Security & Privacy (S&P), 2014, pp. 575–589.

[19] E. G¨oktas¸, E. Athanasopoulos, M. Polychronakis, H. Bos, and G. Portokalidis, “Size does matter: Why using gadget-chain length to prevent code-reuse attacks is hard,” in Proc. 23rd Usenix Security Sym., 2014, pp. 417–432.

[20] A. Homescu, M. Stewart, P. Larsen, S. Brunthaler, and M. Franz, “Microgadgets: Size does matter in Turing-complete return-oriented programming,” in Proc. 6th USENIX Workshop Offensive Technologies (WOOT), 2012, pp. 64–76.

[21] A. Homescu, S. Brunthaler, P. Larsen, and M. Franz, “Librando: Transparent code randomization for just-in-time compilers,” in Proc. 20th ACM Conf. Computer and Communications Security (CCS), 2013, pp. 993–1004.

[22] A. Homescu, S. Neisius, P. Larsen, S. Brunthaler, and M. Franz, “Profile-guided automated software diversity,” in Proc. 11th IEEE/ACM Int. Sym. Code Generation and Optimization (CGO), 2013, pp. 1–11.

[23] R. N. Horspool and N. Marovac, “An approach to the problem of detranslation of computer programs,” The Computer J., vol. 23, no. 3, pp. 223–229, 1980.

[24] Intel, “Introduction to intel memory protection extensions,” https://software.intel.com/en-us/articles/introduction-to-intel-memory-protection-extensions, 2013.

[25] D. Jang, Z. Tatlock, and S. Lerner, “SafeDispatch: Securing C++ virtual calls from memory corruption attacks,” in Proc. 21st Annual Network & Distributed System Security Sym. (NDSS), 2014.

[26] N. Joly, “Advanced exploitation of Internet Explorer 10 / Windows 8 overflow (Pwn2Own 2013),” VUPEN Vulnerability Research Team (VRT), 2013, http://www.vupen.com/blog/20130522.Advanced Exploitation of IE10 Windows8 Pwn2Own 2013.php.

[27] P. Larsen, A. Homescu, S. Brunthaler, and M. Franz, “SoK: Automated software diversity,” in Proc. 35th IEEE Sym. Security & Privacy (S&P), 2014, pp. 276–291.

[28] A. Majumdar and C. Thomborson, “Securing mobile agents control flow using opaque predicates,” in Proc. 9th Int. Conf. Knowledge-based Intelligent Information and Engineering Systems, vol. 3, 2005, pp. 1065–1071.

[29] S. McCamant and G. Morrisett, “Evaluating SFI for a CISC architecture,” in Proc. 15th USENIX Security Sym., 2006.

[30] Microsoft, “Enhanced mitigation experience toolkit,” https://www.microsoft.com/emet, 2014.

[31] V. Mohan and K. W. Hamlen, “Frankenstein: Stitching malware from benign binaries,” in Proc. 6th USENIX Workshop Offensive Technologies (WOOT), 2012, pp. 77–84.

[32] B. Niu and G. Tan, “RockJIT: Securing just-in-time compilation using modular control-flow integrity,” in Proc. 21st ACM Conf. Computer and Communications Security (CCS), 2014, pp. 1317–1328.

[33] V. Pappas, M. Polychronakis, and A. D. Keromytis, “Transparent ROP exploit mitigation using indirect branch tracing,” in Proc. 22nd USENIX Security Sym., 2013, pp. 447–462.

[34] E. J. Schwartz, T. Avgerinos, and D. Brumley, “Q: Exploit hardening made easy,” in Proc. 20th USENIX Security Sym., 2011.

[35] J. Seibert, H. Okhravi, and E. S¨oderstr¨om, “Information leaks without memory disclosures: Remote side channel attacks on diversified code,” in Proc. 21st ACM Conf. Computer and Communications Security (CCS), 2014, pp. 54–65.

[36] F. J. Serna, “The info leak era on software exploitation,” Black Hat USA, 2012.

[37] ——, “CVE-2012-0769, the case of the perfect info leak,” Google Security Team, 2012, http://zhodiac.hispahack.com/my-stuff/security/Flash ASLR bypass.pdf.

[38] H. Shacham, “The geometry of innocent flesh on the bone: Return-into-libc without function calls (on the x86),” in Proc. 14th ACM Conf. Computer and Communications Security (CCS), 2007, pp. 552–561.

[39] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh, “On the effectiveness of address-space randomization,” in Proc. 11th ACM Conf. Computer and Communications Security (CCS), 2004, pp. 298–307.

[40] K. Z. Snow, F. Monrose, L. V. Davi, A. Dmitrienko, C. Liebchen, and A.-R. Sadeghi, “Just-in-time code reuse: On the effectiveness of fine-grained address space layout randomization,” in Proc. 34th IEEE Sym. Security & Privacy (S&P), 2013, pp. 574–588.

[41] A. Sotirov, “Heap feng shui in JavaScript,” Black Hat Europe, 2007, https://www.blackhat.com/presentations/bh-europe-07/Sotirov/Presentation/bh-eu-07-sotirov-apr19.pdf.

[42] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lachmund, and T. Walter, “Breaking the memory secrecy assumption,” in Proc. 2nd European Workshop System Security (EUROSEC), 2009, pp. 1–8.

[43] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway, ´U. Erlingsson, L. Lozano, and G. Pike, “Enforcing forward-edge control-flow integrity in GCC & LLVM,” in Proc. 23rd USENIX Security Sym., 2014.

[44] C. Wang, J. Hill, J. Knight, and J. Davidson, “Software tamper resistance: Obstructing static analysis of programs,” University of Virginia Charlottesville, Tech. Rep., 2000.

[45] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin, “Binary stirring: Self-randomizing instruction addresses of legacy x86 binary code,” in Proc. 19th ACM Conf. Computer and Communications Security (CCS), 2012, pp. 157–168.

[46] ——, “Securing untrusted code via compiler-agnostic binary rewriting,” in Proc. 28th Annual Computer Security Applications Conf. (ACSAC), 2012, pp. 299–308.

[47] R. Wartell, Y. Zhou, K. W. Hamlen, and M. Kantarcioglu, “Shingled graph disassembly: Finding the undecidable path,” in Proc. 18th Pacific-Asia Conf. Knowledge Discovery and Data Mining (PAKDD), 2014, pp. 273–285.

[48] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar, “Native Client: A sandbox for portable, untrusted x86 native code,” in Proc. 30th IEEE Sym. Security & Privacy (S&P), 2009, pp. 79–93.

[49] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant, D. Song, and W. Zou, “Practical control flow integrity and randomization for binary executables,” in Proc. 34th IEEE Sym. Security & Privacy (S&P), 2013, pp. 559–573.

[50] M. Zhang and R. Sekar, “Control flow integrity for COTS binaries,” in Proc. 22nd USENIX Security Sym., 2013, pp. 337–352.