### Data Sensitivity and Adversarial Value

A data point that is valuable to an adversary may be more difficult to obtain, especially if it is highly sensitive. Therefore, sensitive data points should inherently possess greater value for adversaries. A market could adopt a cost model, such as the one provided by the Financial Times (FT) calculator, to assign values as weights to these data points. Google, which functions as a data broker, likely has more accurate values and a broader set of data points. By normalizing the set of exposed data points, they can present a data exposure score for each app.

Let \( D \) be the set of data points in the cost model and \( X \) the set of corresponding weights, where \( |D| = |X| = n \). We include a null data point in \( D \) with a corresponding zero value in \( X \). Let \( \alpha \) represent the app under analysis. The new ranked value of \( \alpha \) would be:

\[ z_{\alpha} = \frac{x_{\alpha} - \min(X)}{\max(X) - \min(X)} \]

where \( x_{\alpha} \) is the sum of all weights of the data points found to be exposed by app \( \alpha \). Here, \( \min(X) \) corresponds to an app having only the least expensive data point in \( D \), and \( \max(X) \) corresponds to an app exposing all data points in \( D \). The value \( z_{\alpha} \) will range from 0 to 1, with higher values indicating greater data exposure. This score can be displayed on the app's download page in application markets alongside other relevant information. For better presentation, markets could use a scale from 0 to 10, stars, or a color spectrum, with red representing the highest data exposure.

### Application of the Ranking Technique

To illustrate the effectiveness of this approach, we applied Pluto and performed the proposed ranking technique on apps collected from the MEDICAL and HEALTH & FITNESS categories on Google Play. In the absence of co-installation patterns for all target apps, we did not consider the effect of having multiple data-exposing apps on the same device. Our findings indicate that most apps have a low risk score. Specifically, 97% of both MEDICAL and HEALTH & FITNESS apps had scores below 5.0. These apps either expose a very small amount of highly sensitive data, data of low sensitivity, or both.

For example, the hearing test app `net.epsilonzero.hearingtest` exposed two attributes—phone number and age—and scored 0.02. This ranking technique ensures that only a few apps stand out, typically those with a large number of exposed data points, including highly sensitive ones. The highest-scoring medical app, `com.excelatlife.depression`, with a score of 8.14, exposes 16 data points, including "depression," "headache," and "pregnancy," which have some of the highest values in the FT calculator. Table VIII lists the two most risky apps per category. Pluto, in conjunction with our ranking approach, helps users and analysts focus on high-risk cases.

### Prevalence of Targeted Data Exposure

Our ranking results also highlight the prevalence of targeted data exposure. As shown in Table VIII, the highest-ranked apps were installed on hundreds of thousands of devices. Consequently, highly sensitive data of a large number of users are exposed to opportunistic third-party libraries. In future work, we plan to explore practical approaches to mitigate data exposure by apps to third-party libraries.

### App Bundles and Data Collection

The collection of app bundle information by app developers, advertising companies, and marketing companies is concerning. Currently, apps can use Google Play Services (gIP or gIA) without special permissions, providing an opportunity for abuse by both app developers and advertisers. Our research demonstrates that this abuse is occurring and that such information can be reliably leveraged to infer users' attributes. Unfortunately, companies fail to notify consumers about the collection of app bundles, the entities collecting the information, how it is used, and steps to mitigate or prevent its collection. The Android API's lack of required permissions for gIP or gIA removes the user's ability to choose and consent to this type of information gathering. To prevent abuse, app providers should notify users in the privacy policy and within the application that app bundles are collected, and provide the option to deny the collection of this information for advertising or marketing purposes. The Android API could require special permissions for gIP or gIA, but the all-or-nothing permissions scheme might not add significant value beyond notice to the user.

### Limitations of Our Approach

Our estimation of data exposure to libraries is limited by the specific attack channels we consider. Our prototype employs specific examples for each channel and performs data exposure assessment based on those. However, there are additional potential channels, such as the CAMERA permission or RECORD_AUDIO, which could be used opportunistically to capture user information. These can be used to extend Pluto for a more comprehensive assessment. Our current prototype and results serve as a baseline for comparison.

### Related Work

Several efforts aim to characterize the current mobile ad targeting process. MAdScope [35] and Ullah et al. [47] found that ad libraries have not yet fully exploited their targeting potential. Our work builds on these observations to assess the data exposure risk associated with embedding a library in an app.

Many studies propose alternative mobile advertising architectures. AdDroid [36] enforces privilege separation by hard-coding advertising functions as a system service into the Android platform. AdSplit [40] achieves privilege separation by running ad libraries and host apps in separate processes. Leontiadis et al. [29] suggest a client-side library compiled with the host app to monitor real-time communication between the host app and ad libraries. MobiAd [19] proposes local profiling instead of keeping user profiles at data brokers to protect users' privacy. While these solutions aim to separate ad libraries from host apps, none are deployed in practice due to disruptions to the business model. We take a different approach by modeling the capabilities of ad libraries to proactively assess apps' data exposure risk.

There are numerous studies aimed at detecting and preventing privacy-infringing behaviors in mobile ads, categorized into static scanning, dynamic monitoring, and hybrid techniques. While these techniques can detect and prevent some attack strategies, they may still fail to protect against all allowed behaviors. Our focus is on assessing data exposure given the allowed behaviors, which is crucial for evaluating the privacy risk of an asset.

### Conclusion

In this work, we studied the feasibility and security implications of fully exploring advertising libraries' capabilities in Android apps. We manually investigated the prevalence of targeted data exposure and revealed a trend in ad networks becoming more aggressive towards reachable user information. We designed, implemented, and evaluated Pluto, a modular framework for privacy risk assessment of apps integrating ad libraries. Pluto can be used for automatic detection of targeted data exposure in Android apps. We hope that our work will inspire related efforts to systematically assess data exposure to ad libraries and that Pluto will serve as a baseline for evaluating future frameworks.

### Acknowledgments

This work was supported in part by HHS 90TR0003-01, NSF CNS 13-30491, NSF CNS 12-23967, and NSF CNS 15-13939. The views expressed are those of the authors only. We are grateful to Hari Sundaram for his comments on advertising, Andrew Rice for sharing the Device Analyzer dataset, and NDSS shepherd Venkat Venkatakrishnan for his valuable assistance in improving the final version of this paper.

### References

[1] Fda.gov. http://goo.gl/guSsMM. Accessed: 2015-01-05.
[2] Pluto code base and experimental results. https://goo.gl/dxXI4O, Observed in May 2015.
[3] R. Agrawal, R. Srikant, et al. Fast algorithms for mining association rules. In VLDB, 1994.
[4] D. Amalfitano, A. R. Fasolino, P. Tramontana, S. De Carmine, and A. M. Memon. Using GUI ripping for automated testing of Android applications. In ACM ASE, 2012.
[5] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein, Y. Le Traon, D. Octeau, and P. McDaniel. FlowDroid: Precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for Android apps. In PLDI, 2014.
[6] S. Banerjee and T. Pedersen. An adapted Lesk algorithm for word sense disambiguation using WordNet. In CICLing, 2002.
[7] P. Barford, I. Canadi, D. Krushevskaja, Q. Ma, and S. Muthukrishnan. AdScapes: Harvesting and analyzing online display ads. In WWW, 2014.
[8] R. Bhoraskar, S. Han, J. Jeon, T. Azim, S. Chen, J. Jung, S. Nath, R. Wang, and D. Wetherall. Brahmastra: Driving apps to test the security of third-party components. In USENIX Security, 2014.
[9] M. D. Buhrmester, T. Kwang, and S. D. Gosling. Amazon’s Mechanical Turk: A new source of inexpensive, yet high-quality data? Perspectives on Psychological Science, 2011.
[10] J. Carroll and T. Briscoe. High precision extraction of grammatical relations. In COLING, 2002.
[11] developer.android.com. UI/Application Exerciser Monkey. http://goo.gl/cH9wPR, Observed in May 2015.
[12] S. Dredge. Twitter scanning users’ other apps to help deliver ‘tailored content’. The Guardian, November.
[13] C. Duhigg. How companies learn your secrets. The New York Times, 16, 2012.
[14] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth. TaintDroid: An information-flow tracking system for real-time privacy monitoring on smartphones. In OSDI, 2010.
[15] M. Fernández-Delgado, E. Cernadas, S. Barro, and D. Amorim. Do we need hundreds of classifiers to solve real-world classification problems? J. Mach. Learn. Res., Jan. 2014.
[16] M. A. Finlayson. Java libraries for accessing the Princeton WordNet: Comparison and evaluation. In GWC, 2014.
[17] C. Gibler, J. Crussell, J. Erickson, and H. Chen. AndroidLeaks: Automatically detecting potential privacy leaks in Android applications on a large scale. In TRUST, 2012.
[18] M. C. Grace, W. Zhou, X. Jiang, and A.-R. Sadeghi. Unsafe exposure analysis of mobile in-app advertisements. In WiSec, 2012.
[19] H. Haddadi, P. Hui, and I. Brown. MobiAd: Private and scalable mobile advertising. In MobiArch, 2010.
[20] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In SIGMOD, 2000.
[21] S. Hao, B. Liu, S. Nath, W. G. Halfond, and R. Govindan. PUMA: Programmable UI-automation for large-scale dynamic analysis of mobile apps. In Mobisys, 2014.
[22] G. Hirst and D. St-Onge. Lexical chains as representations of context for the detection and correction of malapropisms. WordNet: An electronic lexical database, 1998.
[23] J. Huang, Z. Li, X. Xiao, Z. Wu, K. Lu, X. Zhang, and G. Jiang. SUPOR: Precise and scalable sensitive user input detection for Android apps. In USENIX Security, 2015.
[24] J. J. Jiang and D. W. Conrath. Semantic similarity based on corpus statistics and lexical taxonomy. arXiv.org, 1997.
[25] Y. Jing, G. Ahn, Z. Zhao, and H. Hu. Towards automated risk assessment and mitigation of mobile application. Dependable and Secure Computing, IEEE Transactions on, 2014.
[26] Y. Jing, G.-J. Ahn, Z. Zhao, and H. Hu. RiskMon: Continuous and automated risk assessment of mobile applications. In CODASPY, 2014.
[27] S. Kaplan and B. J. Garrick. On the quantitative definition of risk. Risk Analysis, 1981.
[28] C. Leacock and M. Chodorow. Combining local context and WordNet similarity for word sense identification. WordNet: An electronic lexical database, 1998.
[29] I. Leontiadis, C. Efstratiou, M. Picone, and C. Mascolo. Don’t kill my ads!: Balancing privacy in an ad-supported mobile application market. In HotMobile, 2012.
[30] D. Lin. An information-theoretic definition of similarity. In ICML, 1998.
[31] C. Mann and A. Starostin. A framework for static detection of privacy leaks in Android applications. In SAC, 2012.
[32] G. A. Miller. WordNet: A lexical database for English. CACM, 38(11), 1995.
[33] V. Moonsamy, M. Alazab, and L. Batten. Towards an understanding of the impact of advertising on data leaks. IJSN, 7(3), 2012.
[34] Y. Nan, M. Yang, Z. Yang, S. Zhou, G. Gu, and X. Wang. UIPicker: User-input privacy identification in mobile applications. In USENIX Security, 2015.
[35] S. Nath. MAdScope: Characterizing mobile in-app targeted ads. In Mobisys, 2015.
[36] P. Pearce, A. P. Felt, G. Nunez, and D. Wagner. Addroid: Privilege separation for applications and advertisers in Android. In ASIACCS, 2012.
[37] R. Rada, H. Mili, E. Bicknell, and M. Blettner. Development and application of a metric on semantic nets. IEEE SMC, 1989.
[38] P. Resnik. Using information content to evaluate semantic similarity in a taxonomy. arXiv.org, 1995.
[39] P. Sawers. businessinsider.com. http://goo.gl/8g34xB, Observed in May 2015.
[40] S. Shekhar, M. Dietz, and D. S. Wallach. AdSplit: Separating smartphone advertising from applications. In USENIX Security, 2012.
[41] D. Smith. businessinsider.com. http://goo.gl/LNn0pi, Observed in May 2015.
[42] E. Steel, C. Locke, E. Cadman, and B. Freese. How much is your personal data worth? Financial Times, June 2013.
[43] R. Stevens, C. Gibler, J. Crussell, J. Erickson, and H. Chen. Investigating user privacy in Android ad libraries. In MoST, 2012.
[44] L. Sweeney. K-anonymity: A model for protecting privacy. Int. J. Uncertain. Fuzziness Knowl.-Based Syst., 2002.
[45] J. Turow. The daily you: How the new advertising industry is defining your identity and your worth. Yale University Press, 2012.
[46] Twitter. What is app graph in Twitter? https://goo.gl/scmc69, Observed in May 2015.
[47] I. Ullah, R. Boreli, M. A. Kaafar, and S. S. Kanhere. Characterising user targeting for in-app mobile ads. In INFOCOM WKSHPS, 2014.
[48] L. Vigneri, J. Chandrashekar, I. Pefkianakis, and O. Heen. Taming the Android appstore: Lightweight characterization of Android applications. arXiv.org, 2015.
[49] D. T. Wagner, A. C. Rice, and A. R. Beresford. Device Analyzer: Understanding smartphone usage. In MobiQuitous, 2013.
[50] C. E. Wills and C. Tatar. Understanding what they do with what they know. In WPES, 2012.
[51] Z. Wu and M. Palmer. Verbs semantics and lexical selection. In ACL, 1994.
[52] Z. Yang, M. Yang, Y. Zhang, G. Gu, P. Ning, and X. S. Wang. AppIntent: Analyzing sensitive data transmission in Android for privacy leakage detection. In CCS, 2013.
[53] Y. Zhou, X. Zhang, X. Jiang, and V. W. Freeh. Taming information-stealing smartphone applications (on Android). In TRUST, 2011.