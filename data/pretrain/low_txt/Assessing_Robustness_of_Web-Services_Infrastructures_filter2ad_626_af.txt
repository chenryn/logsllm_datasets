### Results

As illustrated in Figure 4, 65% of the studies either lack evaluation or have only a small academic evaluation. Out of the total 144 studies, 13% are evaluated in either a small industrial project or a large open-source system. From an evaluation perspective, these results are considered to be of medium strength. The remaining 21% of the studies are evaluated in larger industrial contexts or in large academic projects, which typically work on commercial systems. Additionally, 86% of the studies with strong evaluations focus on verification and validation. These numbers suggest that there are very few comprehensive results in software robustness, particularly in areas other than verification and validation.

### Discussion

This systematic review provides an overview of the field of software robustness. Based on our findings, we can conclude that research contributions in some areas of software robustness are limited. A significant gap identified is the lack of studies on the elicitation and specification of robustness requirements. Verification and validation, primarily through testing, is the most extensively studied area, followed by design and architectural solutions to enhance robustness. Common practices for robustness testing include fault injection, automated robustness testing tools, and random interface testing. None of the studies focused on other verification and validation activities beyond testing.

Almost all the studies focus on robustness issues caused by invalid inputs, while other aspects of robustness, as defined by IEEE, are largely ignored. More complex aspects of robustness, such as timeouts, interrupts, unexpected events, and stressful execution environments, are rarely addressed in these studies.

Robustness focuses on states and events that should not occur in a system, rather than how the system should function under normal conditions. Creating a complete specification of all possible events and states is often cumbersome or even impossible in many systems. Consequently, most academic and industrial projects neglect the elicitation and specification of robustness requirements. This neglect often results in developers and testers being unaware of potential robustness risks, thereby reducing the overall robustness of the system. While it may be uneconomical or impractical for companies to create a comprehensive requirement specification that considers all robustness risks, they should still be aware of these risks and consider specifying the most critical ones with the highest potential negative impact.

Most of the identified design and architecture studies focus on interface wrappers that encapsulate external component interfaces from the rest of the system. This method is commonly used when working with Commercial Off-The-Shelf (COTS) or third-party applications and services. Wrappers filter the input and output data from external modules. Another popular design method for achieving robustness is graceful degradation. Since developers cannot always predict or intercept robustness issues, it is sometimes necessary to degrade the system's functionality in a controlled manner.

The majority of published studies on robustness focus on the verification and validation of systems in the presence of faulty input values. Most methods and tools introduced in this context generate random test cases based on a simple model of the system. Although this method can uncover robustness risks, the high level of randomness and lack of structure and traceability in most of these studies prevent us from guaranteeing complete robustness. To ensure robustness, a more structured approach that considers every possible state of the system is required. Randomly testing parts of the system can provide some assurance but does not eliminate all potential robustness risks.

Automated robustness testing methods should be viewed as complementary to other types of testing and cannot replace unit testing, system testing, overall functionality testing, or testing of other quality attributes. The popularity of automated testing methods stems from their high degree of automation and low development and testing effort. While this may be sufficient for smaller systems, more complex and safety-critical systems, or those with high safety and availability requirements, require a more systematic approach to ensure or improve robustness.

From the statistics provided in this paper, we can draw several interesting conclusions. Besides the general system focus, there are studies that specifically address web applications, COTS, and operating systems. Given the importance of robustness for embedded systems, more studies focusing on this specific domain would be valuable for practitioners.

Regarding the quality of the studies, many introduce new ideas and solutions for software robustness but fail to evaluate their contributions properly in larger contexts. According to our findings in [147], many of the results are not usable for industrial projects and remain purely academic. One reason for this is the lack of industrial validation, with studies often remaining in a lab or academic setting without being evaluated in an industrial context. Additionally, academic results tend to be context-specific and difficult to generalize, making them less applicable to many industrial situations. The strongest results with robust evaluations found in this review focus on testing large systems, such as operating systems, using randomly generated test cases based on the system's structure. We recommend the use of statistical and evidence-based methods, as described in [11, 91], for the design and evaluation of future studies. This will provide more scientific, repeatable, and useful results for the industry.

### Conclusion

This paper presents a review of the current state of knowledge in the field of software robustness based on a systematic literature review. We analyzed 9,193 primary studies from three well-known, scientific digital libraries: ISI Web of Knowledge, IEEE Xplore, and Engineering Village (Compendex & Inspec). An additional 350 most relevant results were browsed from the ACM Digital Library to ensure the completeness of our search.

A total of 601 papers were selected based on initial title exclusion. After further title, abstract, and full-text exclusions, 144 studies were chosen. Each study was classified based on its focus on development phase, system type, and the quality of research and evaluation.

The results indicate that while there are many studies on robustness testing of COTS and operating systems, very few studies address the elicitation and specification of robustness requirements. Fault injection and automated testing tools based on fault injection are the main areas of contribution in robustness testing. The second largest area of contributions focuses on improving robustness at the design and architecture level, primarily through the use of wrappers and encapsulation of existing software components. Another finding is that most studies focus on a narrow definition of robustness, considering only the aspect of invalid inputs and neglecting more complex aspects like timeouts, interrupts, and robustness problems related to the execution environment.

The quality of the studies varied, with 65% having weak or no evaluation, and only 21% being strongly evaluated in large academic or industrial contexts. There is a clear need for stronger research in areas where there is a gap in knowledge or where existing solutions are not sufficiently evaluated to be useful in industrial settings.

In conclusion, more research is needed on eliciting and specifying robustness requirements. Stronger evaluations, especially in industrial contexts, are strongly recommended for future studies. Additionally, more types of issues that can lead to robustness problems, such as robustness in the presence of unexpected timing or stressful environmental conditions, need to be addressed.

### References

[1] IEEE Standard Glossary of Software Engineering Terminology, IEEE Std 610.12-1990, 1990.
[2] Abie, H., Savola, R. M., Dattani, I., "Robust, secure, self-adaptive and resilient messaging middleware for business critical systems," 2009 Computation World: Future Computing, Service Computation, Cognitive, Adaptive, Content, Patterns (ComputationWorld 2009), pp. 153–160, November 2009.
[3] Acharya, M., Sharma, T., Xu, J., Tao, X., "Effective generation of interface robustness properties for static analysis," Proceedings of the 21st IEEE International Conference on Automated Software Engineering, p. 4, September 2006.
[4] Acharya, M., Tao, X., Jun, X., "Mining interface specifications for generating checkable robustness properties," 2006 17th IEEE International Symposium on Software Reliability Engineering, p. 10, November 2006.
[5] Afzal, W., Torkar, R., Feldt, R., "A systematic review of search-based testing for non-functional system properties," Information and Software Technology, vol. 51, no. 6, pp. 957–976, 2009.
[6] Ait-Ameur, Y., Bel, G., Boniol, F., Pairault, S., Wiels, V., "Robustness analysis of avionics embedded systems," 2003 ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES’03), pp. 123–132, June 2003.
[7] Al-Khanjari, Z. A., Woodward, M. R., Kutti, N. S., Ramadhan, H., Shibab, K., "Masking errors through software robustness," International Conference on Internet Computing - IC’03, pp. 809–817, June 2003.
[8] Albinet, A., Arlat, J., Fabre, J.-C., "Characterization of the impact of faulty drivers on the robustness of the Linux kernel," Dependable Systems and Networks, 2004 International Conference on, pp. 867–876, June 2004.
[9] Allen, J., "Towards robust agent-based dialogue systems," 2005 IEEE Workshop on Automatic Speech Recognition and Understanding, p. 4, November-December 2005.
[10] Ambriola, V., Gervasi, V., "Representing structural requirements in software architecture," Proceedings of IFIP TC2 WG2.4 Working Conference on Systems Implementation 2000: Languages, Methods and Tools, pp. 114–127, February 1998.
[11] Arcuri, A., Briand, L., "A practical guide for using statistical tests to assess randomized algorithms in software engineering," Proceeding of the 33rd international conference on Software engineering, pp. 1–10, 2011.
[12] Arunchandar, V., Memon, A. M., "ASPIRE: Automated Systematic Protocol Implementation Robustness Evaluation," Proceedings of the 2004 Australian Software Engineering Conference, pp. 241–250, April 2004.
[13] Avizienis, A., Laprie, J., Randell, B., "Fundamental Concepts of Dependability," Tech. Rep. 1145, University of Newcastle, 2001.
[14] Bak, S., Chivukula, D., Adekunle, O., Sun, M., Caccamo, M., Sha, L., "The system-level simplex architecture for improved real-time embedded system safety," Real-Time and Embedded Technology and Applications Symposium, 2009. RTAS 2009. 15th IEEE, pp. 99–107, April 2009.
[15] Barbosa, R., Silva, N., Duraes, J., Madeira, H., "Verification and Validation of (Real Time) COTS Products using Fault Injection Techniques," The 6th International IEEE Conference on Commercial-off-the-Shelf (COTS)-Based Software Systems, ICCBSS ’07, pp. 233–242, 2007.
[16] Baudry, B., Le Traon, Y., Jezequel, J. M., "Robustness and diagnosability of OO systems designed by contracts," Proceedings of the 7th International Software Metrics Symposium, METRICS 2001, pp. 272–284, April 2001.
[17] Belcastro, C., Chang, B.-C., "Uncertainty modeling for robustness analysis of failure detection and accommodation systems," Proceedings of the 2002 American Control Conference, vol. 6, pp. 4776–4782, 2002.
[18] Belli, F., Hollmann, A., Wong, W. E., "Towards scalable robustness testing," Secure Software Integration and Reliability Improvement (SSIRI), 2010 4th International Conference on, pp. 208–216, 2010.
[19] Bennani, M., Menasce, D., "Assessing the robustness of self-managing computer systems under highly variable workloads," Proceedings of the International Conference on Autonomic Computing, pp. 62–69, May 2004.
[20] Berztiss, A. T., "Safety-critical software: a research agenda," International Journal of Software Engineering and Knowledge Engineering, vol. 4, pp. 165–181, 1994.
[21] Biolchini, J., Mian, P., Natali, A., Travassos, G., "Systematic review in software engineering," System Engineering and Computer Science Department COPPE/UFRJ, Technical Report ES 679 (05), 2005.
[22] Boehm, B., "Characteristics of software quality," North-Holland, 1978.
[23] Boehm, B., Brown, J., Lipow, M., "Quantitative evaluation of software quality," Proceedings of the 2nd international conference on Software engineering, pp. 592–605, 1976.
[24] Brito, P., de Lemos, R., Rubira, C. M. F., "Verification of exception control flows and handlers based on architectural scenarios," High Assurance Systems Engineering Symposium, 2008. HASE 2008. 11th IEEE, pp. 177–186, 2008.
[25] Brito, P. H. S., de Lemos, R., Martins, E., Moraes, R., Rubira, C. M. F., "Architectural-based validation of fault-tolerant software," The 4th Latin-American Symposium on Dependable Computing, 2009. LADC ’09, pp. 103–110, 2009.
[26] Byung-Hoon, S., Hudak, J., Siewiorek, D., Segall, Z., "Development of a benchmark to measure system robustness: experiences and lessons learned," Proceedings of the 3rd International Symposium on Software Reliability Engineering (Cat. No.92TH0486-1), pp. 237–245, October 1992.
[27] Calas, G., Boklund, A., Mankefors-Christiernin, S., "A First Draft of RATF: A Method Combining Robustness Analysis and Technology Forecasting," Information Technology: New Generations, 2006. ITNG 2006. 3rd International Conference on, pp. 72–77, 2006.
[28] Calori, L. C., Stalhane, T., Ziemer, S., "Robustness analysis using FMEA and BBN - Case study for a web-based application," WEBIST 2007: Proceedings of the 3rd International Conference on Web Information Systems and Technologies, Vol IT - INTERNET TECHNOLOGY, 2007.
[29] Chan, H. A., "Accelerated stress testing for both hardware and software," Proceedings of the Annual Reliability and Maintainability Symposium, pp. 346–351, January 2004.
[30] Chattopadhyay, J., "Methodology to test the robustness of a fault tolerant system to meet real-time requirements," Journal of Aerospace Quality and Reliability, vol. 2, pp. 81–88, 2006.
[31] Cheng-Ying, M., Yan-Sheng, L., "Improving the robustness and reliability of object-oriented programs," *Journal of Software Engineering and Applications*, vol. 1, no. 1, pp. 1–10, 2005.