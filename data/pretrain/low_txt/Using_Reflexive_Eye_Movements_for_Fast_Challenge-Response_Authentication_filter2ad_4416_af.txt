### Advanced Attacks and Their Requirements

Advanced attacks, such as those involving the manipulation of both gaze tracking and visual channels, require a higher level of sophistication compared to simple replay attacks. In a replay attack, the adversary only needs to capture and replay a biometric sample. However, in more advanced scenarios, the adversary must not only control the gaze tracking channel but also observe and analyze the visual channel, significantly increasing the complexity of the attack.

### Conclusion on Threat Vectors

While we acknowledge that an adversary with multiple authentication attempts can attempt various targeted attacks, these attacks demand a much higher level of sophistication and dedication than what is required for a simple replay attack. Therefore, we argue that successfully preventing replay attacks, which are the most common and applicable threat vector against biometric systems, is a crucial step towards their widespread deployment.

### Authentication Speed: A Comparative Analysis

In today’s world, password-based authentication is the most common form of user verification. Passwords are relatively fast to type and easy to implement. Given their prevalence and simplicity, we use passwords as an informal benchmark to assess the future potential of gaze-based authentication based on reflexive eye behavior.

Over the past few years, numerous studies have evaluated password entry times and error rates for different password generation strategies. From a usability standpoint, a recent study by Shay et al. [39] provides a realistic estimate of password usage. The authors conducted an online experiment with 8,143 participants, who were asked to create, remember, and recall different passwords. Depending on the required password complexity, the median input times ranged from 11.6 to 16.2 seconds, with input error rates between 4% and 7%. Additionally, more than 20% of participants had difficulty recalling their passwords, and over 35% found it hard to remember them.

Considering these findings, our results, which show a median authentication time of 5 seconds and an equal error rate (EER) of 6.3%, are highly comparable to password input times and error rates. On average, a successful authentication attempt with our proposed system does not take longer than typing a password, with the added benefit that users do not need to learn or recall any information or procedure.

### Conclusion

Building upon the core idea of using reflexive human behavior for authentication, this paper presents an interactive visual stimulus designed to elicit standardized reflexive eye movements. We demonstrate how this stimulus can be used to construct a fast challenge-response biometric system. Our user experiments show that the stimulus indeed elicits primarily reflexive saccades, which are automatic responses that impose low cognitive load on the user. As a result, our authentication system achieves fast authentication times (median of 5 seconds) and low error rates (6.3% EER).

Most importantly, our proposed authentication method shows resilience against replay attacks, a property that is difficult to achieve with most biometric systems. Evaluation results indicate that the system can detect the replay of recorded eye traces with a very high probability of 99.94%, effectively preventing one of the most common attacks on biometric systems.

Given the recent proliferation of reliable and affordable eye-tracking devices, we believe that achieving fast and reliable gaze-based authentication is of broad interest. Our work represents an important step in this direction. Finally, this paper opens several interesting questions for future research, such as whether reflexive human behavior can be exploited in other biometric modalities and how the reflexive behavior of the human visual system can support other authentication methods.

### Acknowledgements

Ivo Sluganovic is supported by the UK EPSRC doctoral studentship, Scatcherd European Scholarship, and the Frankopan Fund. The authors wish to thank Armasuisse for providing support with gaze-tracking equipment.

### References

[1] W. W. Abbott and A. A. Faisal. Ultra-low-cost 3D gaze estimation: an intuitive high information throughput complement to direct brain-machine interfaces. Journal of Neural Engineering, 9(4), 2012.
[2] R. Abrams, D. E. Meyer, and S. Kornblum. Speed and accuracy of saccadic eye movements: characteristics of impulse variability in the oculomotor system. Journal of experimental psychology. Human perception and performance, 15(3), 1989.
[3] T. Bahill, M. R. Clark, and L. Stark. The main sequence, a tool for studying human eye movements. Mathematical Biosciences, 24(3-4):191–204, 1975.
[4] T. Bahill and T. Laritz. Why Can’t Batters Keep Their Eyes on the Ball? American Scientist, (May - June), 1984.
[5] A. Boehm, D. Chen, M. Frank, L. Huang, C. Kuo, T. Lolic, I. Martinovic, and D. Song. SAFE: Secure authentication with face and eyes. In Privacy and Security in Mobile Systems (PRISMS), 2013 International Conference on, June 2013.
[6] A. Bulling, F. Alt, and A. Schmidt. Increasing the security of gaze-based cued-recall graphical passwords using saliency masks. In CHI, 2012.
[7] V. Cantoni, C. Galdi, M. Nappi, M. Porta, and D. Riccio. GANT: Gaze analysis technique for human identification. Pattern Recognition, 48(4), 2015.
[8] M. S. Castelhano and J. M. Henderson. Stable individual differences across images in human saccadic eye movements. Canadian Journal of Experimental Psychology/Revue canadienne de psychologie expérimentale, 62(1):1–14, 2008.
[9] J. E. S. Choi, P. a. Vaswani, and R. Shadmehr. Vigor of movements and the cost of time in decision making. The Journal of neuroscience: the official journal of the Society for Neuroscience, 34(4), 2014.
[10] C. Cortes and V. Vapnik. Support-vector networks. Machine Learning, 20:273–297, 1995.
[11] A. De Luca, M. Denzel, and H. Hussmann. Look into my eyes!: Gaze-based interaction on multiple displays in an automotive environment. In Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics, 2011.
[12] F. Di Russo, S. Pitzalis, and D. Spinelli. Fixation stability and saccadic latency in elite shooters. Vision Research, 43(17), 2003.
[13] S. Eberz, K. B. Rasmussen, V. Lenders, and I. Martinovic. Preventing Lunchtime Attacks: Fighting Insider Threats With Eye Movement Biometrics. In Proceedings of the 2015 Networked and Distributed System Security Symposium., 2015.
[14] C. Galdi, M. Nappi, D. Riccio, V. Cantoni, and M. Porta. A new gaze analysis based soft-biometric. Lecture Notes in Computer Science, 7914 LNCS, 2013.
[15] L. R. Gottlob, M. T. Fillmore, and B. D. Abroms. Age-group differences in saccadic interference. The journals of gerontology. Series B, Psychological sciences and social sciences, 62(2):85–89, 2007.
[16] C. Holland and O. Komogortsev. Complex eye movement pattern biometrics: Analyzing fixations and saccades. In Biometrics (ICB), 2013 International Conference on, June 2013.
[17] C. Holland and O. V. Komogortsev. Biometric identification via eye movement scanpaths in reading. 2011 International Joint Conference on Biometrics, IJCB 2011, 2011.
[18] K. Holmqvist, M. Nyström, R. Andersson, R. Dewhurst, J. Halszka, and J. van de Weijer. Eye Tracking: A Comprehensive Guide to Methods and Measures. Oxford University Press, 2011.
[19] P. Kasprowski. Human Identification Using Eye Movements. Institute of Computer Science, 2004.
[20] P. Kasprowski. The Second Eye Movements Verification and Identification Competition. In IEEE & IAPR International Joint Conference on Biometrics, 2014.
[21] P. Kasprowski, O. V. Komogortsev, and A. Karpov. First eye movement verification and identification competition at BTAS 2012. 2012 IEEE 5th International Conference on Biometrics: Theory, Applications and Systems, BTAS 2012, (BTAS), 2012.
[22] P. Kasprowski and J. Ober. Eye Movements in Biometrics. Biometrics, 3087 / 200, 2003.
[23] Katharine Byrne. MSI & Tobii join forces to create eye-tracking gaming laptop, 2015.
[24] A. Klin, W. Jones, R. Schultz, F. Volkmar, and D. Cohen. Visual fixation patterns during viewing of naturalistic social situations as predictors of social competence in individuals with autism. Archives of general psychiatry, 59:809–816, 2002.
[25] T. Kocejko and J. Wtorek. Information Technologies in Biomedicine: Third International Conference, ITIB 2012, Gliwice, Poland, June 11-13, 2012. Proceedings, chapter Gaze Pattern Lock for Elders and Disabled, pages 589–602. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012.
[26] O. V. Kolesnikova, L. V. Tereshchenko, A. V. Latanov, and V. V. Shulgovskii. Neuroscience and Behavioral Physiology, 40(8):869–876, 2010.
[27] O. V. Komogortsev, U. K. S. Jayarathna, C. R. Aragon, and M. Mechehoul. Biometric Identification via an Oculomotor Plant Mathematical Model. Eye Tracking Research & Applications (ETRA) Symposium, 2010.
[28] O. V. Komogortsev, A. Karpov, and C. D. Holland. Attack of Mechanical Replicas: Liveness Detection With Eye Movements. IEEE TIFS, 10(4), 2015.
[29] M. Kumar, T. Garfinkel, D. Boneh, and T. Winograd. Reducing shoulder-surfing by using gaze-based password entry. In Proceedings of the 3rd Symposium on Usable Privacy and Security, SOUPS ’07, New York, NY, USA, 2007. ACM.
[30] M. F. Land. Oculomotor behaviour in vertebrates and invertebrates. The Oxford handbook of eye movements, 1, 2011.
[31] I. E. Lazarev and A. V. Kirenskaia. Effect of eye dominance on saccade characteristics and slow EEG potentials. Fiziologiia cheloveka, 34(2):23–33, 2008.
[32] E. Miluzzo, T. Wang, A. T. Campbell, and A. C. M. S. I. G. o. D. Communication. EyePhone: Activating Mobile Phones with Your Eyes. Workshop on Networking, Systems, and Applications on Mobile Handhelds (MobiHeld), 2010.
[33] M. Nystrom and K. Holmqvist. An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data. Behavior Research Methods, 42(1), 2010.
[34] T. Poitschke, F. Laquai, S. Stamboliev, and G. Rigoll. Can you guess my password? In Proceedings of the 5th Symposium on Usable Privacy and Security, SOUPS ’09, New York, NY, USA, 2009. ACM.
[35] I. Rigas, G. Economou, and S. Fotopoulos. Biometric identification based on the eye movements and graph matching techniques. Pattern Recognition Letters, 33(6), 2012.
[36] I. Rigas and O. V. Komogortsev. Biometric Recognition via Probabilistic Spatial Projection of Eye Movement Trajectories in Dynamic Visual Environments. IEEE TIFS, 9(10), 2014.
[37] U. Saeed. Eye movements during scene understanding for biometric identification. Pattern Recognition Letters, 59, 2015.
[38] SensoMotoric Instruments GmbH. SMI RED500 Technical Specification. Technical report, SensoMotoric Instruments GmbH, Teltow, Germany, 2011.
[39] R. Shay, L. F. Cranor, S. Komanduri, A. L. Durity, P. S. Huh, M. L. Mazurek, S. M. Segreti, B. Ur, L. Bauer, and N. Christin. Can long passwords be secure and usable? Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI ’14, 2014.
[40] P. Sumner. Determinants of saccade latency. In Oxford handbook of eye movements, volume 22, pages 411–424. 2011.
[41] R. Walker, D. G. Walker, M. Husain, and C. Kennard. Control of voluntary and reflexive saccades. Experimental Brain Research, 130(4):540–544, Feb. 2000.
[42] J. Weaver, K. Mock, and B. Hoanca. Gaze-based password authentication through automatic clustering of gaze points. Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics, 2011.
[43] Y. Zhang, Z. Chi, and D. Feng. An Analysis of Eye Movement Based Authentication Systems. International Conference on Mechanical Engineering and Technology (ICMET-London 2011), 2011.
[44] M. Zhang, Y; Laurikkala, J; Juhola. Biometric verification of a subject with eye movements, with special reference to temporal variability in saccades between a subject’s measurements. Int. J. Biometrics, 6(1), 2014.