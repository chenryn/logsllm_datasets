### Naive Approach

**Figure 5: Recording Overhead in Hypertable with Varying Number of Clients**

**2. Log Size:**
ADDA has low logging rates. Figure 6 illustrates the log size for a Memcached workload, while varying the total input size read from persistent storage. The naive approach records internal inputs (inputs exchanged between recorded nodes), resulting in an order of magnitude larger logs. For both systems, the log size increases linearly with the input size, but the slope is steeper for the naive approach. Since Memcached is designed such that server instances do not communicate with each other, the log size for the naive approach would increase even more if they did. ADDA, on the other hand, does not record this communication.

**Figure 6: Log Size for Recording a Memcached Workload with Varying Input Size from Persistent Storage**
- **Log Size vs. Input Size for Memcached:**
  - **ADDA**: 10× smaller logs compared to the naive approach.
  - **Naive Approach**: Significantly larger logs due to the recording of internal inputs.

**Hypertable exhibits a similar behavior (Figure 7).** We expect these results to improve further with a simple optimization: our current DPS prototype allocates a static 15KB entry (or a multiple of this size, if needed) for recording the metadata associated with an I/O system call. However, a single 15KB entry is typically too large: for Hypertable, log entries are dominated by zeros, which can be compressed to 100× smaller. By adding support for variable entry sizes, we anticipate substantial improvements in ADDA’s logging rates.

**Figure 7: Log Size for Recording a Hypertable Workload with Varying Input Size from Persistent Storage**
- **Log Size vs. Input Size for Hypertable:**
  - **ADDA**: Smaller logs due to efficient compression and selective recording.
  - **Naive Approach**: Larger logs due to the inclusion of internal inputs.

**3. Performance for Multi-Processors:**
To validate our assumption about applying CREW selectively to control plane components (i.e., the Hypertable master and lock server), we enabled CREW in the experiment shown in Figure 5. This allowed the control plane components to take advantage of both CPUs of their machines. ADDA had the same overhead compared to the baseline, confirming that using CREW for the control plane components in Hypertable does not slow down execution, even under heavy load. This is supported by the low rate of CREW faults (at most 150 faults/sec) for each of these components.

To validate that CREW imposes high overhead for data plane components, we recorded the Hypertable data plane components (the range servers) using CREW and observed overheads exceeding 400%.

These experiments confirm our design choice to enable CREW for control plane components, which imposes low overhead, while having CREW enabled all the time for data plane components is impractical for production use. However, this assumption may not hold for all datacenter applications, and further evaluation is ongoing.

### Replay

Replay is serial, so the replay overhead is expected to be proportional to the number of recorded nodes. For a Memcached workload with 3 nodes (one server and two clients), the replay was 2.46× slower than the original run. Similarly, for a Hypertable workload with a lock server, a master server, 2 range servers, and 3 clients, the replay was 2.7× slower. In both experiments, all inputs were recorded due to a bug that prevented the use of REPLAYNET. Typically, for these applications, replay overhead using REPLAYNET is similar to the naive approach. The replay was not n× slower (where n is the total number of nodes) because replay can fast-forward the execution of some instructions, eliminating "dead cycles" such as sleep or blocking I/O operations. In real setups, such dead cycles may also arise from multiple applications sharing the same node.

### Related Work

**Classic Single-Node Replay Systems:**
Systems like Instant Replay [19], VMware [6], and SMP-ReVirt [7] can be adapted for large-scale distributed operation but are unsuitable for datacenters due to high logging rates and the need for additional storage infrastructure. Systems like WiDS [4] and Friday [2] provide distributed replay but have high overhead for data-intensive applications.

**Relaxed-Deterministic Replay Systems:**
Systems such as PRES [8] and ReSpec [9], and hardware/and/or compiler-assisted systems like Capo [11] and CoreDet [26], support efficient recording of multi-core programs but still incur high record rates for network and disk-intensive distributed systems.

**R2 [12]:**
Provides an API and annotation mechanism for developers to select application code for recording and replay. R2 can record just control plane inputs, incurring low recording overheads. However, the annotations require significant developer effort. ADDA, in contrast, makes this selection automatically based on the data-rate heuristic.

**MPIWiz [27]:**
A hybrid deterministic replay system that exploits traffic patterns of MPI applications to reduce recording overhead. MPIWiz addresses MPI applications, while ADDA targets datacenter applications. MPIWiz does not handle non-determinism caused by data races and assumes shared memory non-determinism is due only to the order of MPI calls. ADDA captures all sources of non-determinism, including data races.

**Replay-Debugging Systems:**
Systems like SherLog [28] and ESD [10] can efficiently replay single-node applications while recording minimal information. These systems use inference to recompute missing runtime information but are not designed for distributed systems, especially datacenter applications. Even for single-node replay, these systems must reason about an exponential number of program paths, limiting their ability to replay at the scale of the datacenter.

### Discussion

For systems that do not meet our assumptions, the runtime overhead may be too high for production use. However, ADDA remains useful during development. Our evaluation shows runtime overhead ranging from 10% to 65%. We are not aware of any other record-replay system with lower overhead for data-intensive datacenter applications. Several simple engineering optimizations could further reduce the overhead to under 10% for a significant subset of datacenter applications and workloads.

Not all applications may meet our main assumptions about the control/data plane separation and the persistence of external inputs. For instance, the running time of a parallel scientific application may be dominated by the control plane code. Additionally, a datacenter application may not store external inputs (such as data acquired by a telescope) to append-only storage due to the sheer size of the inputs. For these applications, ADDA’s overhead may be unacceptably high. However, several applications, including Hadoop [15], Cassandra [17], CloudStore [14], and applications that process click streams (where initial inputs are logged for audit purposes), do meet ADDA’s assumptions. External inputs to MapReduce jobs are typically stored in HDFS, which is append-only storage, representing an important subset of datacenter applications.

**Reduced-Scale Replay:**
Useful in cases where the original machines are not available for replay (e.g., due to hardware failures or the cluster being loaded with another job).

**Divergence Detection:**
If ADDA fails to record an un-synthesizable source of non-determinism (e.g., a data race in the data-plane), the replay might diverge from the recording. ADDA detects divergences by checking that the delivery point of asynchronous events is the same during record and replay. ADDA supports recording of multiple multi-processor nodes but does not yet support multi-processor replay, which is planned for future work.

### Conclusion

We presented ADDA, a replay-debugging system for data-intensive datacenter applications. To reduce recording overhead, ADDA leverages the separation of the control and data planes and the persistence of external inputs in append-only storage. ADDA has low runtime overhead and logging rates, and deterministically replays real-world failures in popular datacenter applications. ADDA records the control plane with high accuracy and does not record intermediate data that can be synthesized during replay. Additionally, ADDA can perform reduced-scale replay and run sophisticated analyses during replay.

### References

[1] K. M. Chandy and L. Lamport, “Distributed snapshots: determining global states of distributed systems,” ACM Transactions on Computer Systems, vol. 3, no. 1, 1985.
[2] D. Geels, G. Altekar, P. Maniatis, T. Roscoe, and I. Stoica, “Friday: Global comprehension for distributed replay,” in Symp. on Networked Systems Design and Implementation, 2007.
[3] G. Altekar and I. Stoica, “Focus replay debugging effort on the control plane,” in Workshop on Hot Topics in Dependable Systems, 2010.
[4] X. Liu, W. Lin, A. Pan, and Z. Zhang, “Wids checker: Combating bugs in distributed systems,” in Symp. on Networked Systems Design and Implementation, 2007.
[5] S. Bhansali, W.-K. Chen, S. de Jong, A. Edwards, R. Murray, M. Drinić, D. Mihočka, and J. Chau, “Framework for instruction-level tracing and analysis of program executions,” in Intl. Conf. on Virtual Execution Environments, 2006.
[6] “VMware vSphere Architecture and Fault Tolerance: http://www.vmware.com/resources/techresources/10058.”
[7] G. W. Dunlap, D. G. Lucchetti, M. A. Fetterman, and P. M. Chen, “Execution replay of multiprocessor virtual machines,” in Intl. Conf. on Virtual Execution Environments, 2008.
[8] S. Park, W. Xiong, Z. Yin, R. Kaushik, K. H. Lee, S. Lu, and Y. Zhou, “PRES: Probabilistic replay with execution sketching on multiprocessors,” in Symp. on Operating Systems Principles, 2009.
[9] D. Lee, B. Wester, K. Veeraraghavan, S. Narayanasamy, P. M. Chen, and J. Flinn, “Online multiprocessor replay via speculation and external determinism,” in Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, 2010.
[10] C. Zamfir and G. Candea, “Execution synthesis: A technique for automated debugging,” in ACM SIGOPS/EuroSys European Conf. on Computer Systems, 2010.
[11] P. Montesinos, M. Hicks, S. T. King, and J. Torrellas, “Capo: a software-hardware interface for practical deterministic multiprocessor replay,” in Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, 2009.
[12] Z. Guo, X. Wang, J. Tang, X. Liu, Z. Xu, M. Wu, M. F. Kaashoek, and Z. Zhang, “R2: An application-level kernel for record and replay,” in Symp. on Operating Systems Design and Implementation, 2008.
[13] C. Zamfir, G. Altekar, G. Candea, and I. Stoica, “Debug determinism: the sweet spot for replay-based debugging,” in Workshop on Hot Topics in Operating Systems, 2011.
[14] “Cloudstore,” http://kosmosfs.sourceforge.net.
[15] “Hadoop,” http://hadoop.apache.org/.
[16] “Memcached,” http://www.memcached.org/.
[17] “Cassandra,” http://cassandra.apache.org.
[18] “Hypertable,” http://www.hypertable.org.
[19] T. J. LeBlanc and J. M. Mellor-Crummey, “Debugging parallel programs with instant replay,” IEEE Trans. Computers, vol. 36, no. 4, pp. 471–482, 1987.
[20] “LibVEX,” http://valgrind.org/.
[21] “Hypertable,” http://www.hypertable.org.
[22] F. Chang, J. Dean, S. Ghemawat, W. Hsieh, D. Wallach, M. Burrows, T. Chandra, A. Fikes, and R. Gruber, “Bigtable: A distributed storage system for structured data,” USENIX Annual Technical Conf., 2006.
[23] “Hypertable issue 63,” http://code.google.com/p/hypertable/issues/.
[24] R. Nikolaev and G. Back, “Perfctr-xen: a framework for performance counter virtualization,” in Intl. Conf. on Virtual Execution Environments, 2011.
[25] D. Beaver, S. Kumar, H. C. Li, J. Sobel, and P. Vajgel, “Finding a needle in haystack: Facebook’s photo storage,” in Symp. on Operating Systems Design and Implementation, 2010.
[26] T. Bergan, O. Anderson, J. Devietti, L. Ceze, and D. Grossman, “CoreDet: A compiler and runtime system for deterministic multithreaded execution,” in Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, 2010.
[27] Xue, “MPIWiz: Subgroup reproducible replay of MPI applications,” in Symp. on Principles and Practice of Parallel Programming, 2009.
[28] D. Yuan, H. Mai, W. Xiong, L. Tan, Y. Zhou, and S. Pasupathy, “SherLog: error diagnosis by connecting clues from run-time logs,” in Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, 2010.