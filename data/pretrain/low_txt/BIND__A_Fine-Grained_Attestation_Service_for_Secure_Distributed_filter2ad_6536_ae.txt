### Verification of ASPATH Integrity and BIND

By verifying the integrity of the previous hop process, we can ensure that the entire chain of routers has performed only legal transformations on the ASPATH. Using BIND, we can achieve at least the same security properties as S-BGP [21, 22] and SPV [20], assuming full deployment.

First, BIND provides protection against the modification and truncation of the ASPATH. With the attestation service, we can guarantee that a router has performed only the legal operation of appending the ASN of the next-hop router to the ASPATH. Additionally, BIND is secure against ASPATH lengthening attacks, which SPV cannot prevent. Another key property achieved by S-BGP and SPV is the delegation property: a malicious router M cannot propagate an ASPATH without the permission of the last hop router on the ASPATH. In our approach, this property is partly ensured through protocol semantics. The ASPATH generation process explicitly appends the next-hop router to the ASPATH, delegating the right to forward the ASPATH. Since the delegation code is part of the attested process, the correctness of the delegation can be verified under the transitive trust properties of BIND.

However, the attestation service does not prevent data misuse attacks by a malicious intermediary. For BGP, a typical data misuse attack is the data replay attack, where a malicious intermediary replays a route that has already been withdrawn. Under our model, it is up to the protocol semantics to address such attacks. For example, to defend against replay attacks, the ASPATH generation process can attach a timeout field to each ASPATH before sending them to the attestation service for MACing. The logic for checking the timestamp should also be embedded in the attested process code. It is important to note that the BIND approach is not well-suited for incremental deployment.

### Related Work

In this section, we review related work on verifying correct code execution, Virtual Machine Monitors (VMMs), and the TPM and SEM technology extensively used in this paper. Other related work, including securing BGP and distributed computation applications, has been discussed in Section 5.

**Verifying Code Execution:**
Wasserman and Blum [42] review theoretical work that enables the verification of program results. While theoretically interesting, their methodology is limited to specific functions and thus has limited practical use.
Vigna [41] proposes using cryptographic traces to securely execute mobile code on untrusted hosts. This approach requires the untrusted host to store cryptographic traces of the execution, allowing a trusted host to request and verify the trace by re-executing the code and comparing the results. However, this method is expensive, as the verifier must re-execute the entire code, and the size of the trace grows linearly with the code size.
Malkhi et al. [26] developed Fairplay, a secure two-party computation system. There has been extensive theoretical work on secure multi-party computation, primarily focused on ensuring the secrecy of input data rather than the integrity of the computed outcome.

**Secure Boot Mechanisms:**
To verify the integrity of the booting process, secure boot mechanisms [8, 9] can be used. Starting from an initial trusted state, each layer verifies the digital signature of the next layer before executing it, ensuring that the software stack has not been altered. This mechanism is similar to our transitive integrity verification mechanism, where we verify the integrity of the previous hop process or data before using it.

**Software-Based Attestation (SWATT):**
Seshadri et al. [37] use timing properties to perform SWATT for embedded devices. The embedded device computes a checksum of its memory whenever it receives a challenge. A malicious attack that modifies the memory contents would take longer to compute the correct checksum, making the attack detectable.

**Virtual Machine Monitors (VMMs):**
Garfinkel et al. [16] developed Terra, a virtual machine-based platform for trusted computing. They partition a tamper-resistant hardware platform into multiple, isolated VMs. The VMM and trusted hardware can attest to the software running on each VM to a remote verifier. Their approach assumes the VMM cannot be compromised at runtime and partially addresses the efficiency and usability of attestation. They propose splitting attestable entities into smaller blocks and computing a hash over each block to improve coarse-grained attestation.

**Trustworthy Computing Platform:**
The Trusted Platform Module (TPM) [40] is a coprocessor designed as the hardware root of trust for a trusted platform. It provides several functional components, including fast cryptographic engines, protected storage, and key generation. Researchers have explored how to use a TPM for load-time attestations of the software system [27, 36].

The Secure Execution Mode (SEM) architecture, part of AMD's drive toward trustworthy computing, is designed to counter software attacks. Built on the x86 architecture, SEM introduces a new mode, the Trusted Execution Mode (TX = 1), where the Secure Kernel runs. This mode offers several hardware protection mechanisms, including memory, I/O, DMA, and system/control register protection. SEM also supports secure initialization through the SKINIT instruction, which works with the TPM to securely record the measurements of the loaded software.

Apart from AMD's SEM technology, Intel's Vanderpool [6] and LaGrande [19] processors provide similar TCG/TPM and isolation features required by BIND. AMD's new generation of processor virtualization technology, Presidio [24], also supports BIND.

### Conclusion and Future Work

As code attestation technology gains more attention in the research community, we aim to address the following questions:
1. What are the desired properties we ultimately want to achieve through attestation?
2. If we could build a perfect attestation service with all desired properties and make it available on every platform, how could it aid in designing secure distributed systems in general?
3. How close are we to a perfect attestation service, and how far can we push our limits using currently available TCG and microprocessor technology?

We propose BIND, a fine-grained attestation service that ties the proof of what code has executed to the data it has produced. By attesting to the critical code immediately before it executes, we narrow the gap between the time of use and the time of attestation. BIND is useful for establishing a trusted environment for distributed systems and simplifies the design of secure distributed systems.

For future work, we plan to investigate the feasibility of a hardware-based design for BIND. The current version of BIND runs in the Secure Kernel and assumes the Secure Kernel is trustworthy, which is a hybrid hardware and software solution. However, it would be desirable to place trust solely on hardware and eliminate any reliance on software components.

### Acknowledgments

We gratefully acknowledge the support, feedback, and fruitful discussions with Dawn Song, Yih-Chun Hu, and James Hendricks. We especially thank Virgil D. Gligor for his suggestions on improving the paper and the anonymous reviewers for their insightful comments.

### References

[1] The folding@home project. Stanford University, http://www.stanford.edu/group/pandegroup/cosm/.
[2] The great internet mersenne prime search. http://www.mersenne.org/prime.htm.
[3] The search for extraterrestrial intelligence project. University of California Berkeley, http://setiathome.berkeley.edu/.
[4] Exploiting format string vulnerabilities. TESO Security Group, http://www.team-teso.net/articles/verbformatstring, Sept. 2001.
[5] AMD platform for trustworthy computing. WinHEC 2003, http://www.microsoft.com/whdc/winhec/papers03.mspx, Sept. 2003.
[6] Intel Vanderpool Technology for IA-32 processors (VT-x) preliminary specification. ftp://download.intel.com/technology/computing/vptech/C97063.pdf, Jan. 2005.
[7] W. Aiello, J. Ioannidis, and P. McDaniel. Origin authentication in interdomain routing. In Proceedings of ACM Conference on Computer and Communications Security (CCS 2003), pages 165–178, Oct. 2003.
[8] W. A. Arbaugh, D. J. Farber, and J. M. Smith. A reliable bootstrap architecture. In Proceedings of IEEE Symposium on Security and Privacy, pages 65–71, May 1997.
[9] W. A. Arbaugh, A. D. Keromytis, D. J. Farber, and J. M. Smith. Automated recovery in a secure bootstrap process. In Proceedings of Symposium on Network and Distributed Systems Security (NDSS), pages 155–167, Mar. 1998.
[10] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R. Neugebar, I. Pratt, and A. Warfield. Xen and the art of virtualization. In Proceedings of the ACM Symposium on Operating Systems Principles (SOSP), Oct. 2003.
[11] M. Bellare, R. Canetti, and H. Krawczyk. Keying hash functions for message authentication. In Advances in Cryptology - Crypto '96, pages 1–15, 1996.
[12] M. Castro and B. Liskov. Practical byzantine fault tolerance. In Proceedings of Symposium on Operating Systems Design and Implementation (OSDI), Feb. 1999.
[13] C. Cowan, P. Wagle, C. Pu, S. Beattie, and J. Walpole. Buffer overflows: Attacks and defenses for the vulnerability of the decade. In Proceedings of DARPA Information Survivability Conference and Exposition (DISCEX 2000), pages 119–129, Jan. 2000.
[14] W. Diffie and M. E. Hellman. New directions in cryptography. IEEE Trans. Inform. Theory, IT-22:644–654, Nov. 1976.
[15] J. S. Foster, M. Fahndrich, and A. Aiken. A theory of type qualifiers. In Proceedings of ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI'99), May 1999.
[16] T. Garfinkel, B. Pfaff, J. Chow, M. Rosenblum, and D. Boneh. Terra: A virtual machine-based platform for trusted computing. In Proceedings of Symposium on Operating System Principles (SOSP), Oct. 2003.
[17] P. Golle and I. Mironov. Uncheatable distributed computations. In Proceedings of the RSA Conference (CT-RSA 2001), 2001.
[18] G. Goodell, W. Aiello, T. Griffin, J. Ioannidis, P. McDaniel, and A. Rubin. Working around BGP: An incremental approach to improving security and accuracy in interdomain routing. In Proceedings of Symposium on Network and Distributed Systems Security (NDSS), Feb. 2003.
[19] D. Grawrock. LaGrande SCMS-18. Architecture. http://www.intel.com/technology/security/downloads/scms18-LT_arch.pdf, Sept. 2003.
[20] Y.-C. Hu, A. Perrig, and M. Sirbu. SPV: Secure path vector routing for securing BGP. In Proceedings of ACM SIGCOMM, Sept. 2004.
[21] S. Kent, C. Lynn, J. Mikkelson, and K. Seo. Secure border gateway protocol (S-BGP) — real world performance and deployment issues. In Proceedings of Symposium on Network and Distributed Systems Security (NDSS), pages 103–116, Feb. 2000.
[22] S. Kent, C. Lynn, and K. Seo. Secure border gateway protocol (S-BGP). IEEE Journal on Selected Areas in Communications, 18(4):582–592, Apr. 2000.
[23] L. Lamport, R. Shostak, and M. Pease. The Byzantine generals problem. ACM Transactions on Programming Languages and Systems (TOPLAS), 4(3):382–401, July 1982.
[24] M. LaPedus. Amd tips 'Pacifica' and 'Presidio' processors for '06. http://www.eetimes.com/semi/news/showArticle.jhtml?articleID=52601317, Nov. 2004.
[25] R. Mahajan, D. Wetherall, and T. Anderson. Understanding BGP misconfiguration. In Proceedings of ACM SIGCOMM, Aug. 2002.
[26] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay - a secure two-party computation system. In Proceedings of USENIX Security Symposium, pages 287–302, Aug. 2004.
[27] H. Maruyama, S. Munetoh, S. Yoshihama, and T. Ebringer. Trusted platform on demand. IPSJ SIGNotes Computer SE-Curity Abstract No. 024 - 032.
[28] S. A. Misel. Wow, AS7007! NANOG mail archives, http://www.merit.edu/mail.archives/nanog/1997-04/msg00340.html, 1997.
[29] F. Monrose, P. Wyckoff, and A. Rubin. Distributed execution with remote audit. In Proceedings of ISOC Network and Distributed System Security Symposium (NDSS '99), Feb. 1999.
[30] Next-Generation Secure Computing Base (NGSCB). http://www.microsoft.com/resources/ngscb/default.mspx, 2003.
[31] O. Nordström and C. Dovrolis. Beware of BGP attacks. ACM Computer Communications Review, 34(2):1–8, Apr. 2004.
[32] N. L. Petroni, T. Fraser, J. Molina, and W. A. Arbaugh. Copilot – a coprocessor-based kernel runtime integrity monitor. In Proceedings of USENIX Security Symposium, pages 179–194, Aug. 2004.
[33] Y. Rekhter and T. Li. A border gateway protocol 4 (BGP-4). RFC 1771, Mar. 1995.
[34] Routing protocol security requirements (rpsec). IETF working group, http://www.ietf.org/html.charters/rpsec-charter.html, 2004.
[35] R. Sailer, T. Jaeger, X. Zhang, and L. van Doorn. Attestation-based policy enforcement for remote access. In Proceedings of ACM Conference on Computer and Communications Security (CCS), Oct. 2004.
[36] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn. Design and implementation of a TCG-based integrity measurement architecture. In Proceedings of USENIX Security Symposium, pages 223–238, Aug. 2004.
[37] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla. SWAtt: SoftWare-based Attestation for embedded devices. In Proceedings of IEEE Symposium on Security and Privacy, May 2004.
[38] J. W. Stewart. BGP4: inter-domain routing in the Internet. Addison-Wesley, 1999.
[39] D. Szajda, B. Lawson, and J. Owen. Hardening functions for large-scale distributed computations. In Proceedings of IEEE Symposium on Security and Privacy, pages 216–224, May 2003.
[40] Trusted Computing Group (TCG). https://www.trustedcomputinggroup.org/, 2003.
[41] G. Vigna. Cryptographic traces for mobile agents. In Mobile Agents and Security, volume 1419 of LNCS State-of-the-Art Survey, pages 137–153. Springer-Verlag, June 1998.
[42] H. Wasserman and M. Blum. Software reliability via runtime result-checking. Journal of the ACM, 44(6):826–849, Nov. 1997.
[43] R. White. Securing BGP through secure origin BGP. Internet Protocol Journal, 6(3):15–22, Sept. 2003.
[44] R. White, D. McPherson, and S. Sangli. Practical BGP. Addison-Wesley, 2004.