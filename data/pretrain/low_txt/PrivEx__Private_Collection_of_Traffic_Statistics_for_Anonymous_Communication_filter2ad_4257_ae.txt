### Related Work

#### Differential Privacy in Two-Party and Multiparty Settings
Goyal et al. [13] explicitly evaluate the accuracy-privacy tradeoffs for computing Boolean functions. Mironov et al. [25] investigate calculating the distance between two vectors, while McGregor et al. [23] focus on Hamming distance. These works explore the limits of differential privacy (DP) in a two-party setting. In contrast, our work considers a different problem—summing integral inputs—and evaluates the tradeoff between accuracy and privacy in a multiparty setting.

The most closely related work is by Beimel et al. [4], which deals with binary inputs, whereas our inputs are integral. Although binary inputs can be adapted to integers, there are three key differences:
1. Their protocol requires more communication rounds.
2. Our protocol allows for malicious parties, making PrivEx a more practical solution.
3. In their setting, each data collector (DC) keeps its database private and only releases binary outputs, whereas in our setting, all DCs release their private data with added noise to preserve DP.

Kasiviswanathan et al. [18] analyze network graphs to understand how the removal and addition of nodes affect the privacy of the graph's structure. While they also consider DP in a network setting, they focus on safely revealing information about the nodes themselves, whereas we are interested in the information that can be revealed by studying the traffic flowing through the network, i.e., the users' information.

A general key difference is that PrivEx provides a clear framework for reasoning about the privacy and utility of the system, which previous works leave to the system designer. We provide an explicit statement and relationship between privacy and utility, making the system easier to analyze and potentially easier to deploy.

#### Secure Multiparty Computation
Secure multiparty computations (SMC) have been used in scenarios where the parties performing the operations are not trustworthy. This means they should not learn the inputs of the calculations, should provide proofs that the calculations were performed correctly, and should not learn anything beyond the output of the calculation.

A closely related work is SEPIA [6] by Burkhart et al., which focuses on collecting aggregate information from networks without revealing individual inputs. Both PrivEx and SEPIA aim to collect network statistics and use similar secret sharing schemes, but there are several differences:
1. SEPIA briefly mentions DP as a possible defense, while PrivEx provides a thorough treatment of using DP to protect aggregated statistics.
2. SEPIA requires honest DCs to sanitize their inputs, whereas PrivEx adds DP noise.
3. PrivEx is secure as long as there is one honest DC and one honest trusted key server (TKS), in contrast to SEPIA, which requires at least half of the aggregators to be honest. This is particularly useful in anonymity networks like Tor, where the stakes for information leakage are high.
4. SEPIA is designed for large-scale ISP infrastructure, while PrivEx has low overhead and is suitable for volunteer-resourced networks like Tor.

The secret sharing scheme in PrivEx is adapted from the scheme presented by Barthe et al. [3], which extends previous works by Kursawe et al. [20], Jawurek et al. [15], and Shi et al. [31]. The novelty of PrivEx is the introduction of addition using additive secret shares for coercion resistance and perfect forward secrecy, which these previous works do not address.

#### Anonymity Network Data Collection
McCoy et al. [22] provided insights into Tor client behavior, but their method of safeguarding the privacy of collected data was considered insufficient by the community [33]. Similarly, Diaz and Sassaman [7] analyzed mix input traffic in anonymous email networks using actual traffic data, which had the potential to deanonymize clients. PrivEx addresses these issues by providing a way to collect statistical data about clients of anonymous networks in a privacy-preserving and compulsion-resistant manner.

Anonymity networks must be cautious about data collection to avoid exposing the entire network. Tor currently collects network-wide bandwidth data, independent of client data, and client-specific network usage data from guard and bridge nodes but not exit nodes. This is safer because guards/bridges already know the connected clients, so an adversary compromising these nodes would not gain additional information.

A key difference between PrivEx and the current Tor data collection environment is that the latter stores true client statistics (e.g., aggregated per-country) in a centralized database. PrivEx ensures that no entity learns any real client data except the nodes that originally collected it.

### Future Work

In the near future, we aim to integrate PrivEx with the Tor codebase. Once this is done, we hope to achieve acceptance from the Tor community and deploy PrivEx on the live Tor network to collect statistics about website visits at exit nodes. PrivEx is incrementally deployable; even if only a fraction of Tor exit nodes become data collectors (DCs), we can still collect data and extrapolate to network-wide statistics, albeit with some error. Only exit nodes need to change to support PrivEx, except for the optional enhancement in §4.2.1, which also requires the cooperation of entry nodes.

As an additional application, PrivEx can be applied to the current guard/bridge data collection process to provide the same benefits as those shown for exit nodes, addressing potential risks associated with ingress data collection.

An open question is whether PrivEx-like systems can be extended to collect data across subsets of the network. This could allow for troubleshooting specific localized issues in a privacy-preserving manner, but it may also give adversaries the ability to partition the data and learn sensitive information.

A limitation of PrivEx, since it is not needed for the scenarios we study, is that only a single query can be made of the database. We plan to investigate how to support multiple related queries, such as network load or circuit latency, while maintaining PrivEx’s privacy and utility features.

### Conclusion

We have presented PrivEx, a decentralized system for privately collecting client statistics in anonymity networks. We detailed two variants of PrivEx, one based on secret sharing and the other on distributed decryption. Both schemes are efficient and resilient to coercion attacks and malicious actors. We introduce noise, as defined in the DP setting, into our aggregation process to prevent information leakage when the statistics are published.

Using Tor as a case study, we show how it can incorporate PrivEx, and other anonymity networks can similarly deploy it. In this case study, we collect statistics about client destination visits at the DC nodes, demonstrating that this can be done efficiently with low computational and communication overhead.

With PrivEx, our aim is to convince administrators and users of anonymity networks that client data collection is possible while maintaining anonymity and privacy. The benefits include valuable information about usage trends, guiding performance and maintenance efforts, and providing more accurate usage statistics and client models for research.

### Acknowledgements

We would like to thank NSERC, ORF, and The Tor Project for funding this research and our CrySP lab colleagues for their invaluable feedback.

### References

[1] M. Alsabah, K. Bauer, T. Elahi, and I. Goldberg. The Path Less Travelled: Overcoming Tor’s Bottlenecks with Traffic Splitting. In Proceedings of the 13th Privacy Enhancing Technologies Symposium (PETS), pages 143–163. Springer, July 2013.

[2] Anonymizer Inc. Anonymizer. https://www.anonymizer.com/index.html, 2013. Retrieved May 2014.

[3] G. Barthe, G. Danezis, B. Grégoire, C. Kunz, and S. Zanella-Béguelin. Verified computational differential privacy with applications to smart metering. In 26th IEEE Computer Security Foundations Symposium (CSF), pages 287–301, 2013.

[4] A. Beimel, K. Nissim, and E. Omri. Distributed private data analysis: Simultaneously solving how and what. In Advances in Cryptology–CRYPTO 2008, pages 451–468. Springer, 2008.

[5] J. Benaloh. Dense probabilistic encryption. In Proceedings of the Workshop on Selected Areas in Cryptography, pages 120–128, 1994.

[6] M. Burkhart, M. Strasser, D. Many, and X. Dimitropoulos. SEPIA: Privacy-preserving aggregation of multi-domain network events and statistics. In 19th USENIX Security Symposium, August 2010.

[7] C. Diaz, L. Sassaman, and E. Dewitte. Comparison between two practical mix designs. In ESORICS 2004, pages 141–159. Springer, 2004.

[8] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-generation onion router. In Proceedings of the 13th USENIX Security Symposium, August 2004.

[9] C. Dwork. Differential privacy. In Automata, languages and programming, pages 1–12. Springer, 2006.

[10] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves: Privacy via distributed noise generation. In Advances in Cryptology-EUROCRYPT 2006, pages 486–503. Springer, 2006.

[11] C. Dwork, G. N. Rothblum, and S. Vadhan. Boosting and differential privacy. In 51st IEEE Symposium on Foundations of Computer Science (FOCS), pages 51–60. IEEE, 2010.

[12] T. Elahi, G. Danezis, and I. Goldberg. PrivEx: Private Collection of Traffic Statistics for Anonymous Communication Networks. Technical Report 2014-08, CACR, 2014. http://cacr.uwaterloo.ca/techreports/2014/cacr2014-08.pdf.

[13] V. Goyal, I. Mironov, O. Pandey, and A. Sahai. Accuracy-privacy tradeoffs for two-party differentially private protocols. In Advances in Cryptology–CRYPTO 2013, pages 298–315. Springer, 2013.

[14] M. Hardt and A. Roth. Beating randomized response on incoherent matrices. In 44th Symposium on Theory of Computing (STOC), pages 1255–1268. ACM, 2012.

[15] M. Jawurek and F. Kerschbaum. Fault-tolerant privacy-preserving statistics. In 12th Privacy Enhancing Technologies Symposium (PETS), pages 221–238. Springer, 2012.

[16] JonDo Inc. JonDonym. http://anonymous-proxy-servers.net/, 2013. Retrieved May 2014.

[17] jrandom (Pseudonym). Invisible internet project (i2p) project overview. https://geti2p.net/_static/pdf/i2p_philosophy.pdf, August 2003. Retrieved May 2014.

[18] S. P. Kasiviswanathan, K. Nissim, S. Raskhodnikova, and A. Smith. Analyzing graphs with node differential privacy. In Theory of Cryptography, pages 457–476. Springer, 2013.

[19] S. Köpsell and U. Hillig. How to Achieve Blocking Resistance for Existing Systems Enabling Anonymous Web Surfing. In Workshop on Privacy in the Electronic Society (WPES), Washington, DC, USA, October 2004.

[20] K. Kursawe, G. Danezis, and M. Kohlweiss. Privacy-friendly aggregation for the smart-grid. In 11th Privacy Enhancing Technologies Symposium (PETS), pages 175–191. Springer, 2011.

[21] K. Loesing. Measuring the Tor Network. https://research.torproject.org/techreports/directory-requests-2009-06-25.pdf, 2009. Retrieved August 2014.

[22] D. McCoy, K. Bauer, D. Grunwald, T. Kohno, and D. Sicker. Shining light in dark places: Understanding the Tor network. In 8th Privacy Enhancing Technologies Symposium (PETS), pages 63–76. Springer, 2008.

[23] A. McGregor, I. Mironov, T. Pitassi, O. Reingold, K. Talwar, and S. Vadhan. The limits of two-party differential privacy. In 51st IEEE Symposium on Foundations of Computer Science (FOCS), pages 81–90. IEEE, 2010.

[24] I. Mironov. On significance of the least significant bits for differential privacy. In 2012 ACM Conference on Computer and Communications Security (CCS), pages 650–661. ACM, 2012.

[25] I. Mironov, O. Pandey, O. Reingold, and S. Vadhan. Computational differential privacy. In Advances in Cryptology-CRYPTO 2009, pages 126–142. Springer, 2009.

[26] S. J. Murdoch and G. Danezis. Low-cost traffic analysis of Tor. In 2005 IEEE Symposium on Security and Privacy. IEEE, May 2005.

[27] L. Øverlier and P. Syverson. Locating hidden servers. In 2006 IEEE Symposium on Security and Privacy. IEEE, May 2006.

[28] J. M. Pollard. Monte carlo methods for index computation (mod p). Mathematics of computation, 32(143):918–924, 1978.

[29] K. Poulsen. Edward Snowden’s Email Provider Shuts Down Amid Secret Court Battle. http://www.wired.com/2013/08/lavabit-snowden/, 2013. Retrieved May 2014.

[30] D. Shanks. Class number, a theory of factorization, and genera. In Proc. Symp. Pure Math, volume 20, pages 415–440, 1971.

[31] E. Shi, T.-H. H. Chan, E. G. Rieffel, R. Chow, and D. Song. Privacy-preserving aggregation of time-series data. In Network and Distributed System Security Symposium (NDSS), 2011.

[32] R. Singel. Encrypted E-Mail Company Hushmail Spills to Feds. http://www.wired.com/threatlevel/2007/11/encrypted-e-mai/, 2007. Retrieved May 2014.

[33] C. Soghoian. Enforced Community Standards for Research on Users of the Tor Anonymity Network. In 2nd Workshop on Ethics in Computer Security Research (WECSR), pages 146–153, 2011.

[34] The Tor Project. Tor Metrics Portal: Network, Advertised bandwidth distribution. https://metrics.torproject.org/network.html, 2014. Retrieved May 2014.

[35] The Tor Project. Tor Metrics Portal: Users. https://metrics.torproject.org/users.html, 2014. Retrieved May 2014.

[36] P. Winter. Towards a Tor Censorship Analysis Tool. https://blog.torproject.org/category/tags/measurement, 2013. Retrieved August 2014.