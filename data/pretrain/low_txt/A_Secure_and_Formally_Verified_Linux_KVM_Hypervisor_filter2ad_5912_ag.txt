### References

1. R. Russell, Z. Yanmin, I. Molnar, and D. Sommerseth, “Improve hackbench,” Linux Kernel Mailing List (LKML), Jan. 2008. [Online]. Available: http://people.redhat.com/mingo/cfs-scheduler/tools/hackbench.c. [Accessed: Dec 16, 2020].
2. R. Jones, “Netperf.” [Online]. Available: https://github.com/HewlettPackard/netperf. [Accessed: Dec 16, 2020].
3. Apache, “ab tool.” [Online]. Available: http://httpd.apache.org/docs/2.4/programs/ab.html. [Accessed: Dec 16, 2020].
4. B. F. Cooper, A. Silberstein, E. Tam, R. Ramakrishnan, and R. Sears, “Benchmarking Cloud Serving Systems with YCSB,” in Proceedings of the 1st ACM Symposium on Cloud Computing (SoCC 2010), Indianapolis, IN, Jun. 2010, pp. 143–154.
5. “Using Vhost - KVM.” [Online]. Available: https://www.linux-kvm.org/page/UsingVhost. [Accessed: Dec 16, 2020].
6. J. T. Lim, C. Dall, S.-W. Li, J. Nieh, and M. Zyngier, “NEVE: Nested Virtualization Extensions for ARM,” in Proceedings of the 26th ACM Symposium on Operating Systems Principles (SOSP 2017), Shanghai, China, Oct. 2017, pp. 201–217.
7. C. Dall, S.-W. Li, J. T. Lim, and J. Nieh, “ARM Virtualization: Performance and Architectural Implications,” ACM SIGOPS Operating Systems Review, vol. 52, no. 1, pp. 45–56, Jul. 2018.
8. J. T. Lim and J. Nieh, “Optimizing Nested Virtualization Performance Using Direct Virtual Hardware,” in Proceedings of the 25th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2020), Lausanne, Switzerland, Mar. 2020, pp. 557–574.
9. G. Klein, J. Andronick, K. Elphinstone, T. Murray, T. Sewell, R. Kolanski, and G. Heiser, “Comprehensive Formal Verification of an OS Microkernel,” ACM Transactions on Computer Systems, vol. 32, no. 1, pp. 2:1–70, Feb. 2014.
10. R. Gu, Z. Shao, H. Chen, J. Kim, J. Koenig, X. Wu, V. Sjöberg, and D. Costanzo, “Building Certified Concurrent OS Kernels,” Communications of the ACM, vol. 62, no. 10, pp. 89–99, Sep. 2019.
11. “seL4 Supported Platforms.” [Online]. Available: https://docs.sel4.systems/Hardware. [Accessed: Dec 16, 2020].
12. J. Oberhauser, R. L. de Lima Chehab, D. Behrens, M. Fu, A. Paolillo, L. Oberhauser, K. Bhat, Y. Wen, H. Chen, J. Kim, and V. Vafeiadis, “VSync: Push-Button Verification and Optimization for Synchronization Primitives on Weak Memory Models,” in Proceedings of the 26th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2021), Detroit, MI, Apr. 2021.
13. G. Klein, J. Andronick, M. Fernandez, I. Kuz, T. Murray, and G. Heiser, “Formally Verified Software in the Real World,” Communications of the ACM, vol. 61, no. 10, pp. 68–77, Sep. 2018.
14. “seL4 Reference Manual Version 11.0.0,” Data61, Nov. 2019.
15. “Frequently Asked Questions on seL4.” [Online]. Available: https://docs.sel4.systems/projects/sel4/frequently-asked-questions.html. [Accessed: Dec 16, 2020].
16. E. Cohen, M. Dahlweid, M. Hillebrand, D. Leinenbach, M. Moskal, T. Santen, W. Schulte, and S. Tobies, “VCC: A Practical System for Verifying Concurrent C,” in Proceedings of the 22nd International Conference on Theorem Proving in Higher Order Logics (TPHOLs 2009), Munich, Germany, Aug. 2009, pp. 23–42.
17. D. Leinenbach and T. Santen, “Verifying the Microsoft Hyper-V hypervisor with VCC,” in Proceedings of the 16th International Symposium on Formal Methods (FM 2009), Eindhoven, The Netherlands, Nov. 2009, pp. 806–809.
18. A. Vasudevan, S. Chaki, L. Jia, J. McCune, J. Newsome, and A. Datta, “Design, Implementation and Verification of an eXtensible and Modular Hypervisor Framework,” in Proceedings of the 2013 IEEE Symposium on Security and Privacy (SP 2013), San Francisco, CA, May 2013, pp. 430–444.
19. A. Vasudevan, S. Chaki, P. Maniatis, L. Jia, and A. Datta, “überSpark: Enforcing Verifiable Object Abstractions for Automated Compositional Security Analysis of a Hypervisor,” in Proceedings of the 25th USENIX Security Symposium (USENIX Security 2016), Austin, TX, Aug. 2016, pp. 87–104.
20. C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan, B. Parno, D. Zhang, and B. Zill, “Ironclad Apps: End-to-End Security via Automated Full-System Verification,” in Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 2014), Broomfield, CO, Oct. 2014, pp. 165–181.
21. L. Nelson, J. Bornholt, R. Gu, A. Baumann, E. Torlak, and X. Wang, “Scaling Symbolic Evaluation for Automated Verification of Systems Code with Serval,” in Proceedings of the 27th ACM Symposium on Operating Systems Principles (SOSP 2019), Huntsville, Ontario, Canada, Oct. 2019, pp. 225–242.
22. D. Jang, Z. Tatlock, and S. Lerner, “Establishing Browser Security Guarantees through Formal Shim Verification,” in Proceedings of the 21st USENIX Security Symposium (USENIX Security 2012), Bellevue, WA, Aug. 2012, pp. 113–128.
23. C. Baumann, M. Näslund, C. Gehrmann, O. Schwarz, and H. Thorsen, “A High Assurance Virtualization Platform for ARMv8,” in Proceedings of the 2016 European Conference on Networks and Communications (EuCNC 2016), Athens, Greece, Jun. 2016, pp. 210–214.
24. C. Baumann, O. Schwarz, and M. Dam, “On the verification of system-level information flow properties for virtualized execution platforms,” Journal of Cryptographic Engineering, vol. 9, no. 3, pp. 243–261, May 2019.
25. T. Murray, R. Sison, E. Pierzchalski, and C. Rizkallah, “Compositional Verification and Refinement of Concurrent Value-Dependent Noninterference,” in Proceedings of the 29th IEEE Computer Security Foundations Symposium (CSF 2016), Lisbon, Portugal, Jun. 2016, pp. 417–431.
26. T. Murray, R. Sison, and K. Engelhardt, “COVERN: A Logic for Compositional Verification of Information Flow Control,” in Proceedings of the 2018 IEEE European Conference on Security and Privacy (EuroS&P 2018), London, United Kingdom, Apr. 2018, pp. 16–30.
27. G. Ernst and T. Murray, “SecCSL: Security Concurrent Separation Logic,” in Proceedings of the 31st International Conference (CAV 2019), New York, NY, Jul. 2019, pp. 208–230.
28. D. Schoepe, T. Murray, and A. Sabelfeld, “VERONICA: Expressive and Precise Concurrent Information Flow Security,” in Proceedings of the 33rd IEEE Computer Security Foundations Symposium (CSF 2020), Boston, MA, Jun. 2020, pp. 79–94.
29. T. Garfinkel, B. Pfaff, J. Chow, M. Rosenblum, and D. Boneh, “Terra: A Virtual Machine-based Platform for Trusted Computing,” in Proceedings of the 19th ACM Symposium on Operating Systems Principles (SOSP 2003), Bolton Landing, NY, Oct. 2003, pp. 193–206.
30. R. Strackx and F. Piessens, “Fides: Selectively Hardening Software Application Components Against Kernel-level or Process-level Malware,” in Proceedings of the 2012 ACM Conference on Computer and Communications Security (CCS 2012), Raleigh, NC, Oct. 2012, pp. 2–13.
31. R. Ta-Min, L. Litty, and D. Lie, “Splitting Interfaces: Making Trust Between Applications and Operating Systems Configurable,” in Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation (OSDI 2006), Seattle, WA, Nov. 2006, pp. 279–292.
32. Y. Liu, T. Zhou, K. Chen, H. Chen, and Y. Xia, “Thwarting Memory Disclosure with Efficient Hypervisor-enforced Intra-domain Isolation,” in Proceedings of the 2015 ACM Conference on Computer and Communications Security (CCS 2015), Denver, CO, Oct. 2015, pp. 1607–1619.

### Appendix A: KCore’s Top-Level Interface and Hypercalls

#### A. Hypercalls
KCore provides a set of hypercalls and exception handlers as part of its top-level interface `TrapHandler`. Below are the details of the hypercalls:

- **register_vm**: Used by KServ to request KCore to create a new VM. KCore allocates a unique VM identifier, which it returns to KServ. It also allocates the per-VM metadata `VMInfo` and a stage 2 page table root for the VM.
- **register_vcpu**: Used by KServ to request KCore to initialize a new VCPU for a specified VM. KCore allocates the `VCPUContext` data structure for the VCPU.
- **set_boot_info**: Used by KServ to pass VM boot image information, such as the image size, to KCore.
- **remap_boot_image_page**: Used by KServ to pass one page of the VM boot image to KCore. KCore remaps all pages of a VM image to a contiguous range of memory in its address space so it can later authenticate the image.
- **verify_vm_image**: Used by KServ to request KCore to authenticate a VM boot image. KCore authenticates each binary of the boot image and refuses to boot the VM if authentication fails. Before authenticating a VM image, KCore unmaps all its pages from KServ’s stage 2 page table to ensure that the verified image cannot be later altered by KServ. If authentication succeeds, KCore maps the boot image to the VM’s stage 2 page table.
- **clear_vm**: Used by KServ to request KCore to reclaim pages from a terminated VM. KCore will scrub all pages of the terminated VM and set their ownership to KServ.
- **encrypt_vcpu**: Used by KServ to request KCore to export encrypted VM CPU data for VM migration and snapshots.
- **decrypt_vcpu**: Used by KServ to request KCore to import encrypted VM CPU data for VM migration and snapshots. KCore copies the data to a private buffer before decrypting it.
- **encrypt_vm_mem**: Used by KServ to request KCore to export encrypted VM memory data for VM migration and snapshots.
- **decrypt_vm_mem**: Used by KServ to request KCore to import encrypted VM memory data for VM migration and snapshots. KCore copies the data to a private buffer before decrypting it.
- **set_timer**: Used by KServ to request KCore to update a privileged EL2 timer register with a timer counter offset for timer virtualization, as SeKVM offloads timer virtualization to KServ.
- **smmu_alloc_unit**: Used by KServ to request KCore to allocate an SMMU translation unit for a given device. KCore sets the owner of the SMMU translation unit to the owner of the device.
- **smmu_free_unit**: Used by KServ to request KCore to deallocate an SMMU translation unit previously used by a device. If a device was owned by a VM, KCore ensures that deallocation can succeed when the VM is powered off.
- **smmu_map**: Used by KServ to request KCore to map a 4KB page pfn to a device’s SMMU page table, from a device virtual address (iova) to the hPA of the pfn. KServ rejects the request if the owner of the pfn is different from the device. KServ is allowed to map a page to the SMMU page table of a VM-owned device before the VM boots.
- **smmu_unmap**: Used by KServ to request KCore to unmap an iova in a device’s SMMU page table. KServ is only allowed to do so after the VM that owns the device is powered off.
- **smmu_iova_to_phys**: Used by KServ to request KCore to walk a device’s SMMU page table. Given an iova, KCore returns the corresponding physical address.
- **run_vcpu**: Used by KServ to request KCore to run a VM’s VCPU on the current CPU. KServ passes the VM and VCPU identifiers to KCore. KCore context switches to the VCPU and resolves prior VM exceptions before returning to the VM.
- **grant**: Used by a VM to grant KServ access to its data in a memory region. KCore sets the share field in the `S2Page` structure for each page in the memory region.
- **revoke**: Used by a VM to revoke KServ’s access to a previously shared memory region. KCore clears the share field in the `S2Page` structure for each of the pages in the memory region and unmaps the pages from KServ.
- **psci_power**: Used by a VM to request KCore to configure VM power states via Arm’s PSCI power management interface. The request is passed to KServ for power management emulation.

#### B. Exception Handlers
KCore also provides several exception handlers:

- **host_page_fault**: Handles stage 2 page faults for KServ. KCore builds the mapping for the faulted address in KServ’s stage 2 page table if the access is allowed. An identity mapping is used for hPAs in KServ’s stage 2 page table, allowing KServ to implicitly manage all free physical memory.
- **vm_page_fault**: Handles stage 2 page faults for a VM, which occur when a VM accesses unmapped memory or its MMIO devices. KCore context switches to KServ for further exception processing, to allocate memory for the VM and emulate VM MMIO accesses. KCore copies the I/O data from KServ to the VM’s GPRs on MMIO reads, and vice versa on MMIO writes.
- **handle_irq**: Handles physical interrupts that result in VM exits. KCore context switches to KServ for the interrupt handling.
- **handle_wfx**: Handles VM exits due to WFI/WFE instructions. KCore context switches to KServ to handle the exception.
- **handle_sysreg**: Handles VM exits due to accessing privileged system registers, handled directly by KCore.

#### C. Memory Operations
- **mem_load/store**: Used to specify regular memory accesses. A memory access from a currently running principal will walk its stage 2 page table to translate from a gPA to hPA. If the physical page is not found or the access permission is violated, a page fault occurs. If KServ caused the fault, the program counter (PC) is set to the `host_page_fault` primitive. If a VM caused the fault, the PC is set to the `vm_page_fault` primitive.
- **dev_load/store**: Used to specify memory accesses by devices. A memory access from a currently running principal’s device will walk its SMMU page table to translate from an iova to hPA.

### Appendix B: Example Proofs

We present a more detailed but still simplified proof of the primitives involved in handling a VM’s stage 2 page fault, expanding on the examples in Sections III-A and V-B with Coq definitions. We describe the refinement proofs for primitives across four layers which handle the page fault after KServ has proposed a pfn to allocate and called `run_vcpu` in `TrapHandler`.

- **Layer 1: NPTWalk**. This layer specifies a set of basic primitives, verified in lower layers and passed through to higher layers, and an abstract state upon which they act. The abstract state consists of a log of shared object events, the local CPU identifier `cid`, the currently running VM `vmid` on CPU `cid`, and a map from `vmid` to each VM’s local state. We define the events and log:
  ```coq
  Inductive Event :=
  | ACQ_NPT (vmid: Z)
  | P_LD (vmid ofs: Z)
  | ACQ_S2PG
  | GET_OWNER (pfn: Z)
  | SET_MEM (pfn val: Z).
  | REL_NPT (vmid: Z)
  | P_ST (vmid ofs val: Z)
  | REL_S2PG
  | SET_OWNER (pfn owner: Z)
  (* Log is a list of events and their CPU identifiers *)
  Definition Log := list (Event * Z).
  ```
  We then define a VM’s local state and NPTWalk’s abstract state:
  ```coq
  (* VM local state *)
  Record LocalState := {
    data_oracle: ZMap.t Z; (* data oracle for the VM *)
  }
  ```

- **Primitives provided by NPTWalk**:
  ```c
  extern void acq_lock_npt(uint vmid);
  extern void rel_lock_npt(uint vmid);
  extern uint pt_load(uint vmid, uint ofs);
  extern void pt_store(uint vmid, uint ofs, uint value);
  extern void acq_lock_s2pg();
  extern void rel_lock_s2pg();
  extern uint get_s2pg_owner(uint pfn);
  ```