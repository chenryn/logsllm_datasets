### Adversarial Attacks on Video Classification Systems

#### Introduction
The generation of adversarial samples for attacking video classification systems presents several unique challenges. These include the need to generate perturbations in real-time, ensure that these perturbations are stealthy, and handle the indeterminism of video clip boundaries in real-time applications. This paper addresses these challenges by extending recent advances in generative models.

#### Related Work

**Video Recognition Systems**
Wei et al. [54] introduced an attack on video recognition systems by adding perturbations to only the first few consecutive frames of a video clip. However, their approach is not effective in practical real-time video classification systems where the boundaries of video clips are not known. Hosseini et al. [15] also explored attacks on video recognition, but they assumed that the starting frame used by the API is known to the attacker, which is not deterministic in real-time applications.

**Generative Adversarial Networks (GANs)**
Goodfellow et al. [10] and Radford et al. [38] have employed GANs to generate natural images. Mopuri et al. [32] extended a GAN architecture to train a generator for modeling universal perturbations for images. Their objective was to explore the distribution of universal adversarial perturbations in the image space. Our work significantly extends this generative framework, focusing on the generation of effective perturbations for videos rather than images.

**Other Learning Systems**
Adversarial attacks have been studied in various other learning systems, including face recognition [28, 39, 40], voice recognition [5], and malware classification [12]. However, these studies do not account for the unique input characteristics present in real-time video activity recognition systems.

#### Methodology

We identify three key challenges in generating adversarial samples for video classification systems:
1. **Real-time Perturbation Generation**: The perturbations must be generated in real-time to be effective.
2. **Stealthiness**: The perturbations should be subtle enough to avoid detection.
3. **Indeterminism of Video Clip Boundaries**: The boundaries of video clips in real-time applications are not fixed and can vary, making it difficult to target specific frames.

To address these challenges, we extend recent advances in generative models. We propose a novel approach that leverages GANs to generate potent adversarial perturbations specifically tailored for video content.

#### Experiments

We conducted extensive experiments on two different datasets:
1. A dataset capturing coarse-grained actions (e.g., applying makeup).
2. A dataset capturing fine-grained actions (e.g., hand gestures).

Our results demonstrate that our approaches achieve around 80% attack success rates in both cases, highlighting the effectiveness of our method.

#### Future Work

We discuss potential defenses against such adversarial attacks and propose directions for future research to enhance the robustness of video classification systems.

### Conclusions

In this paper, we investigated the problem of generating adversarial samples for attacking video classification systems. We identified and addressed three key challenges: real-time perturbation generation, stealthiness, and the indeterminism of video clip boundaries. By extending recent advances in generative models, we developed a method to generate highly effective adversarial samples. Our experiments on two different datasets demonstrated the potency of our approach, achieving high attack success rates. We also outlined potential defenses and future research directions.

### Acknowledgments

We would like to thank the anonymous reviewers for their valuable feedback on this paper. This work was partially supported by the U.S. Army Research Laboratory Cyber Security Collaborative Research Alliance under Cooperative Agreement Number W911NF-13-2-0045. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation hereon.

### References

[1] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard et al., “TensorFlow: A system for large-scale machine learning,” in OSDI, vol. 16, 2016, pp. 265–283.

[2] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Šrndić, P. Laskov, G. Giacinto, and F. Roli, “Evasion attacks against machine learning at test time,” in Joint European conference on machine learning and knowledge discovery in databases. Springer, 2013, pp. 387–402.

[3] B. Biggio, G. Fumera, and F. Roli, “Pattern recognition systems under attack: Design issues and research challenges,” International Journal of Pattern Recognition and Artificial Intelligence, vol. 28, no. 07, p. 1460002, 2014.

[4] D. S. Biggs, “3D deconvolution microscopy,” Current Protocols in Cytometry, pp. 12–19, 2010.

[5] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields, D. Wagner, and W. Zhou, “Hidden voice commands,” in USENIX Security Symposium, 2016, pp. 513–530.

[6] J. Carreira and A. Zisserman, “Quo vadis, action recognition? A new model and the Kinetics dataset,” in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2017, pp. 4724–4733.

[7] J. Dataset, “Humans performing pre-defined hand actions,” https://20bn.com/datasets/jester, 2016, [Online; accessed 30-April-2018].

[8] S. R. Fanello, I. Gori, G. Metta, and F. Odone, “One-shot learning for real-time action recognition,” in Iberian Conference on Pattern Recognition and Image Analysis. Springer, 2013, pp. 31–40.

[9] H. Foroughi, B. S. Aski, and H. Pourreza, “Intelligent video surveillance for monitoring fall detection of elderly in home environments,” in Computer and Information Technology, 2008. ICCIT 2008. 11th International Conference on. IEEE, 2008, pp. 219–224.

[10] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in Advances in neural information processing systems, 2014, pp. 2672–2680.

[11] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples (2014),” arXiv preprint arXiv:1412.6572.

[12] K. Grosse, N. Papernot, P. Manoharan, M. Backes, and P. McDaniel, “Adversarial perturbations against deep neural networks for malware classification,” arXiv preprint arXiv:1606.04435, 2016.

[13] J. Gu, Z. Wang, J. Kuen, L. Ma, A. Shahroudy, B. Shuai, T. Liu, X. Wang, G. Wang, J. Cai et al., “Recent advances in convolutional neural networks,” Pattern Recognition, 2017.

[14] S. Herath, M. Harandi, and F. Porikli, “Going deeper into action recognition: A survey,” Image and vision computing, vol. 60, pp. 4–21, 2017.

[15] H. Hosseini, B. Xiao, A. Clark, and R. Poovendran, “Attacking automatic video analysis algorithms: A case study of Google Cloud Video Intelligence API,” in Proceedings of the 2017 on Multimedia Privacy and Security. ACM, 2017, pp. 21–32.

[16] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. Tygar, “Adversarial machine learning,” in Proceedings of the 4th ACM workshop on Security and artificial intelligence. ACM, 2011, pp. 43–58.

[17] X. Huang, Y. Li, O. Poursaeed, J. Hopcroft, and S. Belongie, “Stacked generative adversarial networks,” in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 2, 2017, p. 4.

[18] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep network training by reducing internal covariate shift,” arXiv preprint arXiv:1502.03167, 2015.

[19] B. L. Kalman and S. C. Kwasny, “Why tanh: choosing a sigmoidal function,” in Neural Networks, 1992. IJCNN., International Joint Conference on, vol. 4. IEEE, 1992, pp. 578–581.

[20] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei, “Large-scale video classification with convolutional neural networks,” in Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2014, pp. 1725–1732.

[21] H. Kataoka, Y. Satoh, Y. Aoki, S. Oikawa, and Y. Matsui, “Temporal and fine-grained pedestrian action recognition on driving recorder database,” Sensors, vol. 18, no. 2, p. 627, 2018.

[22] H. Kataoka, T. Suzuki, S. Oikawa, Y. Matsui, and Y. Satoh, “Drive video analysis for the detection of traffic near-miss incidents,” arXiv preprint arXiv:1804.02555, 2018.

[23] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv preprint arXiv:1412.6980, 2014.

[24] A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial machine learning at scale,” arXiv preprint arXiv:1611.01236, 2016.

[25] K. Lab, “Man-in-the-middle attack on video surveillance systems,” https://securelist.com/does-cctv-put-the-public-at-risk-of-cyberattack/70008/, Defcon, 2014, [Online; accessed 30-April-2018].

[26] R. Longadge and S. Dongre, “Class imbalance problem in data mining review,” arXiv preprint arXiv:1305.1707, 2013.

[27] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards deep learning models resistant to adversarial attacks,” arXiv preprint arXiv:1706.06083, 2017.

[28] M. McCoyd and D. Wagner, “Spoofing 2D face detection: Machines see people who aren’t there,” arXiv preprint arXiv:1608.02128, 2016.

[29] S.-M. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and P. Frossard, “Universal adversarial perturbations,” in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017, pp. 86–94.

[30] S. M. Moosavi Dezfooli, A. Fawzi, and P. Frossard, “DeepFool: A simple and accurate method to fool deep neural networks,” in Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), no. EPFL-CONF-218057, 2016.

[31] K. R. Mopuri, U. Garg, and R. V. Babu, “Fast feature fool: A data independent approach to universal adversarial perturbations,” arXiv preprint arXiv:1707.05572, 2017.

[32] K. R. Mopuri, U. Ojha, U. Garg, and R. V. Babu, “NAG: Network for adversary generation,” arXiv preprint arXiv:1712.03390, 2017.

[33] V. Nair and G. E. Hinton, “Rectified linear units improve restricted Boltzmann machines,” in Proceedings of the 27th international conference on machine learning (ICML-10), 2010, pp. 807–814.

[34] R. Planinc, A. Chaaraoui, M. Kampel, and F. Flrez-Revuelta, “Computer vision for active and assisted living,” pp. 57–79, 01 2016.

[35] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation learning with deep convolutional generative adversarial networks,” arXiv preprint arXiv:1511.06434, 2015.

[36] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, “Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition,” in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2016, pp. 1528–1540.

[37] ——, “Adversarial generative nets: Neural network attacks on state-of-the-art face recognition,” arXiv preprint arXiv:1801.00349, 2017.

[38] K. Soomro, A. R. Zamir, and M. Shah, “UCF101: A dataset of 101 human actions classes from videos in the wild,” arXiv preprint arXiv:1212.0402, 2012.

[39] W. Sultani, C. Chen, and M. Shah, “Real-world anomaly detection in surveillance videos,” arXiv preprint arXiv:1801.04264, 2018.

[40] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus, “Intriguing properties of neural networks,” arXiv preprint arXiv:1312.6199, 2013.

[41] C. TensorFlow, “C3D Implementation,” https://github.com/hx173149/C3D-tensorflow.git, 2016, [Online; accessed 30-April-2018].

[42] F. Tramèr, A. Kurakin, N. Papernot, D. Boneh, and P. McDaniel, “Ensemble adversarial training: Attacks and defenses,” arXiv preprint arXiv:1705.07204, 2017.

[43] D. Tran, L. Bourdev, R. Fergus, L. Torresani, and M. Paluri, “Learning spatiotemporal features with 3D convolutional networks,” in Computer Vision (ICCV), 2015 IEEE International Conference on. IEEE, 2015, pp. 4489–4497.

[44] V. Tripathi, A. Mittal, D. Gangodkar, and V. Kanth, “Real-time security framework for detecting abnormal events at ATM installations,” Journal of Real-Time Image Processing, pp. 1–11, 2016.

[45] G. Varol, I. Laptev, and C. Schmid, “Long-term temporal convolutions for action recognition,” IEEE transactions on pattern analysis and machine intelligence, 2017.

[46] U. C. Vision, “Case Study: Elementary School in Taiwan,” https://news.umbocv.com/case-study-taiwan-elementary-school-13fa14cdb167.

[47] ——, “Umbo Customer Case Study NCHU,” https://news.umbocv.com/umbo-customer-case-study-nchu-687356292f43.

[48] ——, “Umbo’s Smart City Featured on CBS Sacramento,” https://news.umbocv.com/umbos-smart-city-featured-on-cbs-sacramento-26f839415c51.

[49] ——, “Case Studies,” https://news.umbocv.com/case-studies/home, 2016, [Online; accessed 30-April-2018].

[50] C. Vondrick, H. Pirsiavash, and A. Torralba, “Generating videos with scene dynamics,” in Advances In Neural Information Processing Systems, 2016, pp. 613–621.

[51] X. Wei, J. Zhu, and H. Su, “Sparse adversarial perturbations for videos,” arXiv preprint arXiv:1803.02536, 2018.

[52] W. Xu, D. Evans, and Y. Qi, “Feature squeezing: Detecting adversarial examples in deep neural networks,” arXiv preprint arXiv:1704.01155, 2017.

[53] ——, “Feature squeezing mitigates and detects Carlini/Wagner adversarial examples,” arXiv preprint arXiv:1705.10686, 2017.

[54] M. D. Zeiler, “AdaDelta: An adaptive learning rate method,” arXiv preprint arXiv:1212.5701, 2012.

[55] Z. Net, “Surveillance with infected Amazon cameras sold on,” https://www.zdnet.com/article/amazon-surveillance-cameras-infected-with-malware/, ZDNet, 2016, [Online; accessed 30-April-2018].

[56] N. Papernot, N. Carlini, I. Goodfellow, R. Feinman, F. Faghri, A. Matyasko, K. Hambardzumyan, Y.-L. Juang, A. Kurakin, R. Sheatsley et al., “cleverhans v2.0.0: An adversarial machine learning library,” arXiv preprint arXiv:1610.00768, 2016.

[57] N. Papernot, P. McDaniel, and I. Goodfellow, “Transferability in machine learning: From phenomena to black-box attacks using adversarial samples,” arXiv preprint arXiv:1605.07277, 2016.