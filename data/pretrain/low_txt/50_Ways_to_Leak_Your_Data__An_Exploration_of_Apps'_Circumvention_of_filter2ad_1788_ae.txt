### Malicious and Intentional Practices in Mobile Applications

The Shutterfly app, which extracts geolocation information from EXIF metadata, may not be doing so to gather location data about the user or for any specific purpose. However, when an app contains both code to access data through the permission system and code that implements evasion techniques, it is difficult to justify such actions as benign. This is especially true for apps that legitimately access the data and then store it for others to access. Such covert channels can be exploited by any app that knows the protocol, not just those sharing the same SDK. For instance, Baidu's practice of writing users' IMEI to publicly accessible storage allows any app to access this information without permission, not just other Baidu-containing apps.

### 6.1 Privacy Expectations

In the United States, privacy practices are governed by the "notice and consent" framework. Companies provide notice to consumers about their privacy practices (often through a privacy policy), and consumers consent to these practices by using the company's services. The Android permissions system is another example of this framework, as it provides transparency into the sensitive resources to which apps request access (notice) and requires explicit user consent before an app can access, collect, and share sensitive data (consent). The fact that apps can and do circumvent this framework highlights its shortcomings. In practical terms, these behaviors may directly lead to privacy violations because they likely defy consumers' expectations.

Nissenbaum’s "Privacy as Contextual Integrity" framework defines privacy violations as data flows that defy contextual information norms. In this framework, data flows are modeled by senders, recipients, data subjects, data types, and transmission principles in specific contexts (e.g., providing app functionality, advertising, etc.). By circumventing the permissions system, apps can exfiltrate data to their own servers or third parties in ways that defy users' expectations and societal norms, particularly if it occurs after the user has denied the app's explicit permission request. Thus, the behaviors documented in this paper constitute clear privacy violations. From a legal and policy perspective, these practices are likely to be considered deceptive or otherwise unlawful.

### 6.2 Legal and Policy Issues

The practices highlighted in this paper also raise several legal and policy issues. In the United States, they may violate the Federal Trade Commission's (FTC) prohibitions against deceptive practices and state laws governing unfair business practices. In the European Union, they may constitute violations of the General Data Protection Regulation (GDPR).

The FTC, responsible for protecting consumer interests, has brought several cases under Section 5 of the FTC Act in this context. These cases have stated that circumvention of Android permissions and collection of information without user consent or in a misleading manner is an unfair and deceptive act. One case suggested that apps requesting permissions beyond what users expect or need to operate the service were found to be "unreasonable" under the FTC Act. Another case involved the FTC pursuing a complaint against HTC for allowing developers to collect information without obtaining users' permission via the Android permission system and failing to protect users from potential third-party exploitation of a related security flaw.

Additionally, state-level Unfair and Deceptive Acts and Practices (UDAP) statutes may apply, reflecting and complementing federal law. With growing regulatory and public attention to data privacy and security, data collection that undermines users' expectations and informed consent may also violate various general privacy regulations, such as the Children’s Online Privacy Protection Act (COPPA), the California Consumer Privacy Act (CCPA), and potentially data breach notification laws, depending on the type of personal information collected.

In Europe, these practices may violate GDPR. A recent landmark ruling by the French data regulator, CNIL, levied a 50 million Euro fine for a breach of GDPR's transparency requirements, emphasizing the importance of informed consent regarding data collection for personalized ads. This ruling underscores that permission requests serve a key function in informing users of data collection practices and as a mechanism for providing informed consent.

Our analysis reveals novel permission circumvention methods used by otherwise legitimate Android apps. These circumventions enable the collection of information either without asking for consent or after the user has explicitly refused to provide consent, likely undermining users' expectations and potentially violating key privacy and data protection requirements at the state, federal, and global levels. By uncovering these practices and making our data public, we aim to provide regulators with sufficient data and tools to bring enforcement actions, help the industry identify and fix problems before releasing apps, and allow consumers to make informed decisions about the apps they use.

### 7 Limitations and Future Work

During our research, certain design decisions may impact the comprehensiveness and generalizability of our findings. Our study focuses on a subset of permissions labeled by Google as dangerous: those controlling access to user identifiers and geolocation information. While these are the most concerning and privacy-intrusive permissions, there may be other permissions, such as the BLUETOOTH permission, that, while not labeled as dangerous, can still give access to sensitive user data.

Our methods rely on observations of network transmissions that suggest the existence of covert and side channels, rather than searching for them directly through static analysis. Many apps and third-party libraries use obfuscation techniques to disguise their transmissions, which may result in some transmissions not being flagged as containing permission-protected information. Additionally, there may be channels that are exploited but did not transmit the accessed personal data during our testing. Furthermore, apps could expose channels but never abuse them during our tests, even though this would still be an unexpected breach of Android's security model.

Many popular apps also use certificate pinning, which results in them rejecting the custom certificate used by our man-in-the-middle proxy. While certificate pinning is a reasonable security measure, it may also be used to thwart attempts to analyze and study the network traffic of a user's mobile phone.

Our dynamic analysis uses the Android Exerciser Monkey as a UI fuzzer to generate random UI events to interact with the apps. While our prior work found that the Monkey explored similar code branches as a human for 60% of the apps tested, it likely fails to explore some code branches that may exploit covert and side channels. For example, the Monkey fails to interact with apps that require specific inputs, such as login screens. Future work should compare our approaches to more sophisticated tools for automated exploration, such as Moran et al.’s Crashscope, which generates inputs to an app designed to trigger crash events.

These limitations only result in the possibility that there are side and covert channels we have not yet discovered (i.e., false negatives). It does not impact the validity of the channels we did uncover (i.e., no false positives), and improvements in our methodology can only result in the discovery of more such channels.

### Moving Forward

There must be a collective effort from all stakeholders to prevent apps from circumventing the permissions system. Google has announced that they are addressing many of the issues we reported, but these fixes will only be available to users who can upgrade to Android Q, positioning privacy as a luxury good. Instead, they should treat privacy vulnerabilities with the same seriousness as security vulnerabilities and issue hotfixes to all supported Android versions.

Regulators and platform providers need better tools to monitor app behavior and hold app developers accountable by ensuring apps comply with applicable laws, protecting users' privacy, and respecting their data collection choices. Society should support more mechanisms, both technical and otherwise, that empower users' informed decision-making with greater transparency into what apps are doing on their devices. To this end, we have made the list of all apps that exploit or contain code to exploit the side and covert channels we discovered available online.

### Acknowledgments

This work was supported by the U.S. National Security Agency’s Science of Security program, the Department of Homeland Security, the National Science Foundation, the Rose Foundation, the European Union’s Horizon 2020 Innovation Action program, the Data Transparency Lab, and the Center for Long-Term Cybersecurity at U.C. Berkeley. We thank John Aycock, Irwin Reyes, Greg Hagen, René Mayrhofer, Giles Hogben, and Refjohürs Lykkewe for their contributions.

### References

[1] IDA: About. Ida pro.
https://www.hex-rays.com/products/ida/.

[2] J. P. Achara, M. Cunche, V. Roca, and A. Francillon.
WiﬁLeaks: Underestimated privacy implications of the
access wiﬁ state Android permission. Technical Report
EURECOM+4302, Eurecom, 05 2014.

[3] A. Al-Haiqi, M. Ismail, and R. Nordin. A new
sensors-based covert channel on android. The Scientiﬁc
World Journal, 2014, 2014.

[4] D. Amalﬁtano, A. R. Fasolino, P. Tramontana, B. D. Ta,
and A. M. Memon. MobiGUITAR: Automated
model-based testing of mobile apps. IEEE Software,
32(5):53–59, 2015.

[5] Android Documentation. App Manifest Overview.
https://developer.android.com/guide/topics/
manifest/manifest-intro, 2019. Accessed:
February 12, 2019.

[6] Android Studio. UI/Application Exerciser Monkey.
https://developer.android.com/studio/test/
monkey.html, 2017. Accessed: October 12, 2017.

[7] Apktool. Apktool: A tool for reverse engineering
android apk ﬁles.
https://ibotpeaches.github.io/Apktool/.

[18] S. Cabuk, C. E. Brodley, and C. Shields. IP covert
channel detection. ACM Transactions on Information
and System Security (TISSEC), 12(4):22, 2009.

[8] AppCensus Inc. Apps using Side and Covert Channels.
https://blog.appcensus.mobi/2019/06/01/
apps-using-side-and-covert-channels/, 2019.

[9] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel,
J. Klein, Y. Le Traon, D. Octeau, and P. McDaniel.
FlowDroid: Precise Context, Flow, Field,
Object-sensitive and Lifecycle-aware Taint Analysis for
Android Apps. In Proc. of PLDI, pages 259–269, 2014.

[10] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie. Pscout:
analyzing the android permission speciﬁcation. In
Proceedings of the 2012 ACM conference on Computer
and communications security, pages 217–228. ACM,
2012.

[11] V. Avdiienko, K. Kuznetsov, A. Gorla, A. Zeller,
S. Arzt, S. Rasthofer, and E. Bodden. Mining apps for
abnormal usage of sensitive data. In Proceedings of the
37th International Conference on Software Engineering-
Volume 1, pages 426–436. IEEE Press, 2015.

[12] G. S. Babil, O. Mehani, R. Boreli, and M. A. Kaafar. On
the effectiveness of dynamic taint analysis for protecting
against private information leaks on android-based
devices. In 2013 International Conference on Security
and Cryptography (SECRYPT), pages 1–8, July 2013.

[13] Baidu. Baidu Geocoding API. https://geocoder.
readthedocs.io/providers/Baidu.html, 2019.
Accessed: February 12, 2019.

[14] Baidu. Baidu Maps SDK. http://lbsyun.baidu.
com/index.php?title=androidsdk, 2019.
Accessed: February 12, 2019.

[15] Bauer, A. and Hebeisen, C. Igexin advertising network
put user privacy at risk. https:
//blog.lookout.com/igexin-malicious-sdk,
2019. Accessed: February 12, 2019.

[16] R. Bhoraskar, S. Han, J. Jeon, T. Azim, S. Chen,
J. Jung, S. Nath, R. Wang, and D. Wetherall.
Brahmastra: Driving Apps to Test the Security of
Third-Party Components. In 23rd USENIX Security
Symposium (USENIX Security 14), pages 1021–1036,
San Diego, CA, 2014. USENIX Association.

[19] Y. Cao, Y. Fratantonio, A. Bianchi, M. Egele, C. Kruegel,
G. Vigna, and Y. Chen. EdgeMiner: Automatically
Detecting Implicit Control Flow Transitions through
the Android Framework. In Proc. of NDSS, 2015.

[20] B. Chess and G. McGraw. Static analysis for security.
IEEE Security & Privacy, 2(6):76–79, 2004.

[21] M. Christodorescu and S. Jha. Static analysis of
executables to detect malicious patterns. Technical
report, Wisconsin Univ-Madison Dept of Computer
Sciences, 2006.

[22] M. Christodorescu, S. Jha, S. A Seshia, D. Song, and
R. E. Bryant. Semantics-aware malware detection. In
Security and Privacy, 2005 IEEE Symposium on, pages
32–46. IEEE, 2005.

[23] A. Continella, Y. Fratantonio, M. Lindorfer, A. Puccetti,
A. Zand, C. Kruegel, and G. Vigna.
Obfuscation-resilient privacy leak detection for mobile
apps through differential analysis. In Proceedings of
the ISOC Network and Distributed System Security
Symposium (NDSS), pages 1–16, 2017.

[24] Commission Nationale de l’Informatique et des
Libertés (CNIL). Data Protection Around the World.
https://www.cnil.fr/en/
data-protection-around-the-world, 2018.
Accessed: September 23, 2018.

[25] Commission Nationale de l’Informatique et des
Libertés (CNIL). The CNIL’s restricted committee
imposes a financial penalty of 50 Million euros against