### System Configuration

Consider a system utilizing an r-degree PhantomCache, an m-way set associative cache, and physical addresses with t-bit tags and i-bit index bits.

#### Logic Overhead

The primary source of logic overhead in the Last Level Cache (LLC) is the mapping logic. The mapping function consists of a hash with 2 × t × i 2-input AND gates and (t + 2 × i) 2-input XOR gates (Figure 5). Consequently, all r mapping units contain a total of r × (t + 2 × t × i + 2 × i) 2-input gates, comprising r × t × i AND gates and r × (t × i + t + 2i) XOR gates.

For our default LLC configuration with t = 44, i = 14, m = 16, and r = 8, the total logic overhead amounts to 10,432 2-input gates, specifically 4,928 AND gates and 5,504 XOR gates. In terms of gate equivalents (GE), an AND gate typically has the same size as 1.5 NAND gates, and an XOR gate has the same size as 2 NAND gates. Thus, the logic overhead of the mapping function is approximately 18,400 GEs.

The logic overhead of PhantomCache is less than twice that of a 128-bit AES encryption, which is around 10,000 GEs [4]. This overhead is considered manageable in modern CPUs.

#### Storage Overhead

PhantomCache requires additional storage for salts, cache set indices, and Linear Feedback Shift Register (LFSR) state values. The r salts occupy r × (t + i) bits, the r cache set indices occupy r × i bits, and the t state values occupy t × i bits. Using our default LLC with t = 44, i = 14, and r = 8, the extra storage overhead is 1,192 bits (149 bytes). Additionally, each cache line stores an extra (cid:100)log2 r(cid:101)-bit random number for indexing salts. When r = 8, this takes up 3 bits, introducing approximately 0.50% storage overhead per cache line.

### Energy Overhead

Energy overhead is a significant concern for PhantomCache as it multiplies the number of requests in every access. The energy consumption of a cache primarily consists of static power and dynamic power. Static power refers to the leakage power of the cache, while dynamic power is consumed during cache access [7]. PhantomCache only affects the dynamic power of the LLC by increasing cache activity during access. Regarding dynamic power, PhantomCache behaves similarly to a normal set-associative cache but with r times higher associativity. We evaluate a 16MB, 8-bank, 16-way LLC with 8 candidate sets and compare it to a baseline LLC with no candidate sets.

#### Power Consumption

We use Xilinx Vivado 2018.2 [14] to estimate the static energy overhead of PhantomCache. For this, we choose the device xc7k325tffg676 from the Xilinx Kintex-7 family. The static energy overhead arises from the mapping circuit introduced by PhantomCache for addressing r candidate sets. The static power consumption of this mapping circuit is 0.22 W (r = 8), which is marginal compared to the 7.69 W consumed by the entire baseline 8-bank LLC. Note that the analysis using Xilinx Vivado emulates an FPGA, while PhantomCache is implemented on an ASIC, meaning the estimation is an overestimation.

We then use CACTI 6.0 [31] to estimate the dynamic energy overhead of PhantomCache. To evaluate the dynamic power consumption, we use CACTI to assess the energy consumption of read and write operations in a 128-way set-associative LLC. The dynamic power depends on two factors: the power consumption of a single read or write access and the count of read or write accesses generated by a benchmark. Generally, more accesses consume more power for any LLC, including both the baseline and PhantomCache. Since PhantomCache performs each read access by searching all r candidate sets, benchmarks with more read accesses will result in higher power consumption for PhantomCache compared to the baseline. Based on performance measurements, we use ten mixed workloads, each containing 1 billion instructions from 8 randomly selected benchmarks. These workloads generate 51,686,150 read accesses and 34,842,011 write accesses over the baseline LLC. For PhantomCache, the number of read accesses is 51,844,724, and the number of write accesses is 34,701,023, introducing 0.31% more read accesses and 0.40% fewer write accesses. On average, a mixed workload consumes 1.21 W on the baseline LLC and 6.97 W on PhantomCache.

Table IV summarizes the power consumption of PhantomCache compared to the baseline. PhantomCache consumes 67.27% more power than the baseline LLC. This result is counterintuitive, as it suggests PhantomCache should have consumed multiple times the energy. Two reasons account for this: First, the extra requests produced by PhantomCache only access the tag array in the cache, not the data array. Second, the static power of PhantomCache remains nearly the same as the traditional cache, mitigating the impact of increased dynamic power.

### Conclusion

We have studied the concept of localized randomization to defend against conflict-based cache timing attacks. It provides the same strong defense as global randomization countermeasures and avoids inefficient mechanisms in previous global randomization designs, such as random replacement and dynamic remapping. We implement localized randomization through PhantomCache. Security analysis shows that an attacker cannot successfully launch a conflict-based cache timing attack within 100 years when the degree of PhantomCache is set to 8. Finally, we implement PhantomCache using ChampSim, and the evaluation demonstrates that PhantomCache introduces only a 0.50% performance degradation and affordable hardware overhead.

### Acknowledgment

This work is supported in part by The Natural Science Foundation of Zhejiang Province under Grant No. LY19F020050, National Natural Science Foundation under Grant No. 61772236, Zhejiang Key R&D Plan under Grant No. 2019C03133, Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Research Institute of Cyberspace Governance in Zhejiang University, and Leading Innovative and Entrepreneur Team Introduction Program of Zhejiang. We sincerely thank NDSS 2020 Chairs and Reviewers for their review efforts and helpful feedback. We also extend our gratitude to Bowen Huang and Seetal Potluri for insightful discussions on PhantomCache performance. Finally, Kai Bu wholeheartedly appreciates all the students from the Computer Architecture classes for their support and encouragement.

### References

[1] "The champsim simulator. https://github.com/champsim/champsim."
[2] "Intel digital random number generator (drng) software implementation guide. https://software.intel.com/en-us/articles/intel-digital-random-number-generator-drng-software-implementation-guide."
[3] "Spec cpu2017 home page: www.spec.org/cpu2017."
[4] S. Banik, A. Bogdanov, and F. Regazzoni, “Exploring energy efficiency of lightweight block ciphers,” in International Conference on Selected Areas in Cryptography. Springer, 2015, pp. 178–194.
[5] D. J. Bernstein, “Cache-timing attacks on aes,” 2005.
[6] D. J. Bernstein, T. Lange, and P. Schwabe, “The security impact of a new cryptographic library,” in Latincrypt, 2012, pp. 159–176.
[7] S. Chakraborty, D. Deb, D. Buragohain, and H. K. Kapoor, “Cache capacity and its effects on power consumption for tiled chip multiprocessors,” in 2014 International Conference on Electronics and Communication Systems (ICECS).
IEEE, 2014, pp. 1–6.
[8] A. Chen, W. B. Moore, H. Xiao, A. Haeberlen, L. T. X. Phan, M. Sherr, and W. Zhou, “Detecting covert timing channels with time-deterministic replay.” in OSDI, 2014, pp. 541–554.
[9] J. Chen and G. Venkataramani, “Cc-hunter: Uncovering covert timing channels on shared processor hardware,” in MICRO, 2014, pp. 216–228.
[10] J. Daemen and V. Rijmen, “Aes proposal: Rijndael,” 1999.
[11] P. Damaschke, “Threshold group testing,” in General theory of information transfer and combinatorics, 2006, pp. 707–718.
[12] P. Deepthi and P. Sathidevi, “Design, implementation and analysis of hardware efficient stream ciphers using lfsr based hash functions,” Computers & Security, vol. 28, no. 3-4, pp. 229–241, 2009.
[13] H. Fang, S. S. Dayapule, F. Yao, M. Doroslovački, and G. Venkataramani, “Prefetch-guard: Leveraging hardware prefetches to defend against cache timing channels,” in HOST, 2018, pp. 187–190.
[14] T. Feist, “Vivado design suite,” White Paper, vol. 5, p. 30, 2012.
[15] D. Gruss, J. Lettner, F. Schuster, O. Ohrimenko, I. Haller, and M. Costa, “Strong and efficient cache side-channel protection using hardware transactional memory,” in USENIX Security Symposium, 2017, pp. 217–233.
[16] D. Gruss, R. Spreitzer, and S. Mangard, “Cache template attacks: Automating attacks on inclusive last-level caches.” in USENIX Security Symposium, 2015, pp. 897–912.
[17] G. Hamerly, E. Perelman, J. Lau, and B. Calder, “Simpoint 3.0: Faster and more flexible program phase analysis,” Journal of Instruction Level Parallelism, vol. 7, no. 4, pp. 1–28, 2005.
[18] Z. He and R. B. Lee, “How secure is your cache against side-channel attacks?” in Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture. ACM, 2017, pp. 341–353.
[19] G. Irazoqui, T. Eisenbarth, and B. Sunar, “Cross processor cache attacks,” in Proceedings of the 11th ACM on Asia conference on computer and communications security. ACM, 2016, pp. 353–364.
[20] H. Krawczyk, “Lfsr-based hashing and authentication,” in CRYPTO, 1994, pp. 129–139.
[21] D. Levinthal, “Performance analysis guide for Intel Core (tm) i7 processor and Intel Xeon (tm) 5500 processors,” Intel Performance Analysis Guide, 2009.
[22] M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and S. Mangard, “Armageddon: Cache attacks on mobile devices.” in USENIX Security Symposium, 2016, pp. 549–564.
[23] F. Liu, Q. Ge, Y. Yarom, F. McKeen, C. Rozas, G. Heiser, and R. B. Lee, “Catalyst: Defeating last-level cache side channel attacks in cloud computing,” in HPCA, 2016, pp. 406–418.
[24] F. Liu and R. B. Lee, “Random fill cache architecture,” in MICRO, 2014, pp. 203–215.
[25] F. Liu, H. Wu, K. Mai, and R. B. Lee, “Newcache: Secure cache architecture thwarting cache side-channel attacks,” IEEE Micro, vol. 36, no. 5, pp. 8–16, 2016.
[26] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-level cache side-channel attacks are practical,” in S&P, 2015, pp. 605–622.
[27] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood, “Pin: building customized program analysis tools with dynamic instrumentation,” in ACM SIGPLAN Notices, vol. 40, no. 6, 2005, pp. 190–200.
[28] R. Martin, J. Demme, and S. Sethumadhavan, “Timewarp: rethinking timekeeping and performance monitoring mechanisms to mitigate side-channel attacks,” ACM SIGARCH Computer Architecture News, vol. 40, no. 3, pp. 118–129, 2012.
[29] C. Maurice, N. Le Scouarnec, C. Neumann, O. Heen, and A. Francillon, “Reverse engineering Intel last-level cache complex addressing using performance counters,” in International Workshop on Recent Advances in Intrusion Detection. Springer, 2015, pp. 48–65.
[30] C. Maurice, M. Weber, M. Schwarz, L. Giner, D. Gruss, C. A. Boano, S. Mangard, and K. Römer, “Hello from the other side: SSH over robust cache covert channels in the cloud,” NDSS, 2017.
[31] N. Muralimanohar, R. Balasubramonian, and N. P. Jouppi, “CACTI 6.0: A tool to model large caches,” HP laboratories, vol. 27, p. 28, 2009.
[32] K. Olukotun, T. Mudge, and R. Brown, “Performance optimization of pipelined primary cache,” in ISCA, 1992, pp. 181–190.
[33] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D. Keromytis, “The spy in the sandbox: Practical cache attacks in JavaScript and their implications,” in CCS, 2015, pp. 1406–1418.
[34] M. K. Qureshi, “CEASER: Mitigating conflict-based cache attacks via encrypted-address and remapping,” in MICRO, 2018.
[35] ——, “New attacks and defense for encrypted-address cache,” in ISCA, 2019, pp. 360–371.
[36] A. Seznec, “A case for two-way skewed-associative caches,” 1993, pp. 169–178.
[37] A. Sodani, R. Gramunt, J. Corbal, H.-S. Kim, K. Vinod, S. Chinthamani, S. Hutsell, R. Agarwal, and Y.-C. Liu, “Knights Landing: Second-generation Intel Xeon Phi product,” IEEE MICRO, vol. 36, no. 2, pp. 34–46, 2016.
[38] V. Varadarajan, T. Ristenpart, and M. M. Swift, “Scheduler-based defenses against cross-VM side-channels.” in USENIX Security Symposium, 2014, pp. 687–702.
[39] B. C. Vattikonda, S. Das, and H. Shacham, “Eliminating fine-grained timers in Xen,” in CCSW, 2011, pp. 41–46.
[40] P. Vila, B. Köpf, and J. F. Morales, “Theory and practice of finding eviction sets,” in S&P, 2019.
[41] Y. Wang, A. Ferraiuolo, D. Zhang, A. C. Myers, and G. E. Suh, “SECDCP: Secure dynamic cache partitioning for efficient timing channel protection,” in DAC, 2016.
[42] Z. Wang and R. B. Lee, “New cache designs for thwarting software cache-based side channel attacks,” in ISCA, 2007, pp. 494–505.
[43] ——, “A novel cache architecture with enhanced performance and security,” in MICRO, 2008, pp. 83–93.
[44] M. Weiß, B. Heinz, and F. Stumpf, “A cache timing attack on AES in virtualization environments,” in FC, 2012, pp. 314–328.
[45] M. Werner, T. Unterluggauer, L. Giner, M. Schwarz, D. Gruss, and S. Mangard, “Scattercache: Thwarting cache attacks via cache set randomization,” in USENIX Security, 2019.
[46] M. Yan, B. Gopireddy, T. Shull, and J. Torrellas, “Secure hierarchy-aware cache replacement policy (SHARP): Defending against cache-based side channel attacks,” in ISCA, 2017, pp. 347–360.
[47] M. Yan, Y. Shalabi, and J. Torrellas, “ReplayConfusion: Detecting cache-based covert channel attacks using record and replay,” in MICRO, 2016.
[48] Y. Yarom and K. Falkner, “Flush+Reload: A high resolution, low noise, L3 cache side-channel attack.” in USENIX Security, vol. 1, 2014, pp. 22–25.