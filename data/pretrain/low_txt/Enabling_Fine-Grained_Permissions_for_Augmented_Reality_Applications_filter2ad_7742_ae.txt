### Sensor Privacy

Sensor privacy encompasses several key components: access control on sensors, usage control of sensor data once an application gains access, and access visualization. We will discuss related work for each of these areas.

#### Access Control
Access control can be implemented through user permissions. For example, iOS prompts the user for permission the first time a sensor is accessed (e.g., a map application accessing GPS). Android and the latest Windows OSes use manifests at installation time to inform the user about sensor usage. The installation proceeds only if the user grants all requested permissions. However, these existing systems are either disruptive or ask for permissions out of context. They also do not follow the principle of least privilege, often granting permanent access unnecessarily. Felt et al. [11] have shown that most users ignore manifests, and those who do read them often do not understand them.

To address these issues, Access Control Gadgets (ACGs) [27] were introduced as trusted UI elements for sensors, which applications can embed. User actions on an ACG (e.g., a camera trusted UI) grant the embedding application permission to access the represented sensor. In this paper, we argue that even the ACG style of permission granting is too coarse-grained for augmented reality (AR) systems because most AR applications require specific objects rather than entire RGB streams (Section 5.1).

Another form of access control involves reducing the sensitivity of private data available to applications. MockDroid [3] and AppFence [14] allow the use of fake sensor data. Krumm [19] surveys methods for reducing sensitive information in location readings. Differential privacy [9] adds noise to data to provide strong guarantees against an adversary's ability to learn about specific individuals. Similarly, we proposed modifying sensor inputs to recognizers to reduce false positives that could result in privacy leaks. Darkly [18] transforms output from computer vision algorithms (such as contours, moments, or recognized objects) to blur the identity of the output. Darkly can be applied to the output of our recognizers.

#### Usage Control
Once an application obtains access to sensors, information flow control approaches can be used to monitor and control the application's usage of sensitive data, as in TaintDroid [10] and AppFence [14]. In access visualization, sensor-access widgets [15] can be displayed within an application to show sensor data being collected. Darkly [18] also provides a visualization of its transformations. Our privacy goggles apply similar ideas to the AR environment, allowing users to visualize an application's view of their world.

#### Abstractions for Privacy
Our approach of taking raw sensor data and providing higher-level abstractions through recognizers is similar to CondOS [4]'s Contextual Data Units. However, CondOS does not specify a set of concrete Contextual Data Units suitable for a wide variety of real-world applications, nor does it address privacy concerns arising from applications having access to these units. Koi [13] provides a location matching abstraction to replace raw GPS coordinates in applications. While Koi is limited to location data and may require significant integration effort, our recognizers cover many types of sensor data and are specifically chosen to match application needs.

### Future Work

#### Further Recognizer Visualization
The recognizers we evaluated had straightforward visualizations, such as the Kinect skeleton. However, some recognizers, like voice commands, do not have obvious visualizations. Other recognizers might extract features from raw video or audio for use by various object recognition algorithms but do not have easily understood semantics, such as a fast Fourier transform of audio. Key challenges include designing visualizations for privacy goggles that clearly communicate the impact of allowing application access to the recognizer. For example, with voice commands, we might show a video with sound where detected words are highlighted with subtitles. Another challenge is characterizing the privacy impact of algorithmic transformations on raw data, especially in the case of computer vision features that have not been considered from a privacy perspective.

#### Third-Party Recognizers
All recognizers in this paper are assumed to be trusted. To enable new experiences, we aim to support third-party recognizers. This raises challenges, including permissions for recognizers and sandboxing untrusted GPU code without sacrificing performance. We have developed recognizers in a domain-specific language that enables precise analysis [8]. Addressing these challenges is intriguing future work, similar to research on third-party driver isolation in operating systems. For example, we might require third-party recognizers to go through a vetting program and have their code signed, similar to drivers in Windows or applications on mobile platforms.

#### Sensing Applications
Beyond traditional AR applications, other applications employ rich sensing but do not necessarily render on human senses. For example, robots use the Kinect sensor for navigation, and video conferencing can use the "person texture" recognizer we describe. One colleague suggested that video conferencing could benefit from a depth-limited camera [28]. These applications may also benefit from recognizers.

#### Bystander Privacy
Our focus is on protecting a user’s privacy against untrusted applications. Mobile AR systems like Google Glass have raised significant discussions about bystander privacy—the ability of people around the user to opt out of recording and object recognition. Our architecture allows explicitly identifying all applications that might have access to bystander information but does not determine when and how to stop sending recognizer events to applications. Making the system aware of these issues is important future work.

### Conclusions
We introduced a new abstraction, the recognizer, for operating systems to support augmented reality applications. Recognizers allow applications to raise the level of abstraction from raw sensor data, such as audio and video streams, to specific recognized objects. This enables applications to act with the least privilege needed. Our analysis of existing applications shows that all would benefit from least privilege enabled by an OS with support for recognizers. We then introduced a "privacy goggles" visualization for recognizers to communicate the impact of allowing access to users. Our surveys establish a clear privacy ordering on core recognizers, show that users expect AR apps to have limited capabilities, and demonstrate that privacy goggles are effective at communicating the capabilities of apps that access recognizers. We built a prototype on top of the Kinect for Windows SDK. Our implementation has negligible overhead for single applications, enables secure OS-level offloading of heavyweight recognizer computation, and improves performance for concurrent applications. In short, the recognizer abstraction improves privacy and performance for AR applications, laying the groundwork for future OS support of rich sensing and AR application rendering.

### Acknowledgements
We thank Janice Tsai, our Privacy Manager, for reviewing our survey. We also thank Doug Burger, Loris D'Antoni, Yoshi Kohno, Franziska Roesner, Stuart Schechter, Margus Veanes, and John Vilk for helpful discussions and review of drafts. Stuart Schechter suggested the idea of a depth-limited camera for teleconferencing scenarios. This work was carried out while the first and fourth authors were interning at Microsoft Research.

### References
[1] R. T. Azuma. A survey of augmented reality. Presence: Teleoperators and Virtual Environments, 6(4):355–385, August 1997.
[2] R. T. Azuma, Y. Baillot, R. Behringer, S. Feiner, S. Julier, and B. MacIntyre. Recent advances in augmented reality. Computer Graphics and Applications, 21(6):34–47, 2001.
[3] A. R. Beresford, A. Rice, N. Skehin, and R. Sohan. MockDroid: Trading privacy for application functionality on smartphones. In Workshop on Mobile Computing Systems and Applications (HotMobile), 2011.
[4] D. Chu, A. Kansal, J. Liu, and F. Zhao. Mobile apps: It’s time to move up to condOS. May 2011.
[5] M. Corporation. Kinect for Xbox 360 privacy considerations, 2012. http://www.microsoft.com/privacy/technologies/kinect.aspx.
[6] M. Corporation. Kinect for Windows SDK, 2013. http://www.microsoft.com/en-us/kinectforwindows/.
[7] L. D’Antoni, A. Dunn, S. Jana, T. Kohno, B. Livshits, D. Molnar, A. Moshchuk, E. Ofek, F. Roesner, S. Saponas, M. Veanes, and H. J. Wang. Operating system support for augmented reality applications. In Hot Topics in Operating Systems (HotOS), 2013.
[8] L. D’Antoni, M. Veanes, B. Livshits, and D. Molnar. FAST: A transducer-based language for tree manipulation, 2012. MSR Technical Report 2012-123. http://research.microsoft.com/apps/pubs/default.aspx?id=179252.
[9] C. Dwork. The differential privacy frontier. In 6th Theory of Cryptography Conference (TCC), 2009.
[10] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth. TaintDroid: An information-flow tracking system for realtime privacy monitoring on smartphones. In Conference on Operating System Design and Implementation, 2010.
[11] A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and D. Wagner. Android permissions: User attention, comprehension, and behavior. In Symposium on Usable Privacy and Security (SOUPS), 2012.
[12] W. Garage. OpenCV, 2013. http://opencv.org/.
[13] S. Guha, M. Jain, and V. N. Padmanabhan. Koi: A location-privacy platform for smartphone apps. In NSDI, 2012.
[14] P. Hornyack, S. Han, J. Jung, S. Schechter, and D. Wetherall. These aren’t the droids you’re looking for: retrofitting Android to protect data from imperious applications. In Conference on Computer and Communications Security, 2011.
[15] J. Howell and S. Schechter. What You See is What They Get: Protecting users from unwanted use of microphones, cameras, and other sensors. In Web 2.0 Security and Privacy, IEEE, 2010.
[16] J. Howell and S. Schecter. What you see is what they get: Protecting users from unwanted use of microphones, cameras, and other sensors. In Web 2.0 Security and Privacy Workshop, 2010.
[17] E. Hutchings. Augmented reality shop lets you look and see how new furniture would look at home. http://www.psfk.com/2012/05/augmented-reality-furniture-app.html, 2012.
[18] S. Jana, A. Narayanan, and V. Shmatikov. DARKLY: Privacy for perceptual applications. In IEEE Symposium on Security and Privacy, 2013.
[19] J. Krumm. A survey of computational location privacy. Personal Ubiquitous Computing, 13(6):391–399, Aug 2009.
[20] Layar. Layar catalogue, 2013. http://www.layar.com/layers.
[21] Microsoft Research Face SDK Beta. http://research.microsoft.com/en-us/projects/facesdk/.
[22] Microsoft Speech Platform. http://msdn.microsoft.com/en-us/library/hh361572(v=office.14).aspx.
[23] R. A. Newcombe, S. Izadi, O. Hilliges, D. Molyneaux, D. Kim, A. J. Davison, P. Kohli, J. Shotton, S. Hodges, and A. Fitzgibbon. KinectFusion: Real-time dense surface mapping and tracking. In 10th IEEE International Symposium on Mixed and Augmented Reality, 2011.
[24] M. Poh, D. MacDuﬀ, and R. Picard. Advancements in non-contact, multiparameter physiological measurements using a webcam. IEEE Trans Biomed Engineering, 58(1):7–11, 2011.
[25] Project Glass. https://plus.google.com/+projectglass/posts.
[26] Qualcomm. Augmented Reality SDK, 2011. http://www.qualcomm.com/products_services/augmented_reality.html.
[27] F. Roesner, T. Kohno, A. Moshchuk, B. Parno, H. J. Wang, and C. Cowan. User-driven access control: Rethinking permission granting in modern operating systems. In IEEE Symposium on Security and Privacy, 2011.
[28] S. Schecter. Depth-limited camera for Skype - personal communication, 2012.
[29] J. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore, A. Kipman, and A. Blake. Real-time human pose recognition in parts from a single depth image. In Computer Vision and Pattern Recognition, June 2011.
[30] uSample. Instant.ly survey creator, 2013. http://instant.ly.
[31] P. Viola and M. Jones. Robust Real-time Object Detection. In International Journal of Computer Vision, 2001.