### Acknowledgments

The authors express their gratitude to all reviewers and proofreaders for their valuable feedback on the manuscript. Special thanks are extended to Gijs Vanspauwen for his significant contributions to the compiler.

### Financial Support

This research was supported by the following institutions and programs:
- The Prevention against Crime Programme of the European Union
- IBBT (Interdisciplinary Institute for Broadband Technology)
- IWT (Institute for the Promotion of Innovation through Science and Technology in Flanders)
- The Research Fund KU Leuven
- The EU-funded FP7 project NESSoS (Network of Excellence in Security Software)

### References

1. Abadi, M., and Plotkin, G. D. "On protection by layout randomization." In *Computer Security Foundations Symposium (CSF)* (2010), pp. 337–351.
2. Agten, P., Strackx, R., Jacobs, B., and Piessens, F. "Secure compilation to modern processors." In *Computer Security Foundations Symposium* (2012), pp. 171–185.
3. Appel, A. W. *Compiling with Continuations*. Cambridge University Press, New York, NY, USA, 2007.
4. Azab, A., Ning, P., and Zhang, X. "SICE: a hardware-level strongly isolated computing environment for x86 multi-core platforms." In *Proceedings of the 18th ACM Conference on Computer and Communications Security* (2011), ACM, pp. 375–388.
5. Chen, X., Garfinkel, T., Lewis, E. C., Subrahmanyam, P., Waldspurger, C. A., Boneh, D., Dwoskin, J., and Ports, D. R. K. "Overshadow: A virtualization-based approach to retrofitting protection in commodity operating systems." In *ASPLOS* (2008).
6. Cohen, E., Dahlweid, M., Hillebrand, M., Leinenbach, D., Moskal, M., Santen, T., Schulte, W., and Tobies, S. "VCC: A practical system for verifying concurrent C." In *Proceedings of the 22nd International Conference on Theorem Proving in Higher Order Logics (TPHOLs)* (Berlin, Heidelberg, 2009), Springer-Verlag, pp. 23–42.
7. Datta, A., Franklin, J., Garg, D., and Kaynar, D. "A logic of secure systems and its application to trusted computing." In *30th IEEE Symposium on Security and Privacy* (2009), IEEE, pp. 221–236.
8. Dolev, D., and Yao, A. C. "On the security of public key protocols." *IEEE Transactions on Information Theory* 29, 2 (1983), 198–208.
9. El Defrawy, K., Aurélien Francillon, D., and Tsudik, G. "SMART: Secure and minimal architecture for (establishing a dynamic) root of trust." In *Proceedings of the Network & Distributed System Security Symposium (NDSS)*, San Diego, CA (2012).
10. England, P., Lampson, B., Manferdelli, J., and Willman, B. "A trusted open platform." *Computer* 36, 7 (July 2003), 55–62.
11. Erlingsson, Ú. "Low-level software security: Attacks and defenses." *Foundations of Security Analysis and Design IV* (2007), 92–134.
12. Erlingsson, U., Younan, Y., and Piessens, F. "Low-level software security by example." In *Handbook of Information and Communication Security*. Springer, 2010.
13. Garfinkel, T., Pfaff, B., Chow, J., Rosenblum, M., and Boneh, D. "Terra: A virtual machine-based platform for trusted computing." *ACM SIGOPS Operating Systems Review* 37, 5 (2003), 193–206.
14. Kauer, B. "Oslo: Improving the security of trusted computing." In *SS’07: Proceedings of 16th USENIX Security Symposium* (Berkeley, CA, USA, 2007), USENIX Association, pp. 1–9.
15. King, S., Chen, P., Wang, Y., Verbowski, C., Wang, H., and Lorch, J. "SubVirt: Implementing malware with virtual machines." *IEEE Symposium on Security and Privacy (Oakland)* (2006).
16. Klein, G., Elphinstone, K., Heiser, G., Andronick, J., Cock, D., Derrin, P., Elkaduwe, D., Engelhardt, K., Kolanski, R., Norrish, M., et al. "seL4: Formal verification of an OS kernel." In *Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles* (2009), ACM, pp. 207–220.
17. Longley, D., and Rigby, S. "An automatic search for security flaws in key management schemes." *Computers & Security* 11, 1 (1992), 75–89.
18. Martignoni, L., Paleari, R., and Bruschi, D. "Conqueror: Tamper-proof code execution on legacy systems." In *Proceedings of the 7th Conference on Detection of Intrusions and Malware and Vulnerability Assessment (DIMVA)* (Bonn, Germany, July 2010), Lecture Notes in Computer Science, Springer, pp. 21–40.
19. Martignoni, L., Poosankam, P., Zaharia, M., Han, J., McCamant, S., Song, D., Paxson, V., Perrig, A., Shenker, S., and Stoica, I. "Cloud terminal: Secure access to sensitive applications from untrusted systems."
20. McCune, J. M., Li, Y., Qu, N., Zhou, Z., Datta, A., Gligor, V., and Perrig, A. "TrustVisor: Efficient TCB reduction and attestation." In *Proceedings of the IEEE Symposium on Security and Privacy* (May 2010).
21. McCune, J. M., Parno, B., Perrig, A., Reiter, M. K., and Isozaki, H. "Flicker: An execution infrastructure for TCB minimization." In *Proceedings of the ACM European Conference in Computer Systems (EuroSys)* (Apr. 2008), ACM, pp. 315–328.
22. McCune, J. M., Perrig, A., and Reiter, M. K. "Safe passage for passwords and other sensitive data." In *Proceedings of the Symposium on Network and Distributed Systems Security (NDSS)* (Feb. 2009).
23. One, A. "Smashing the stack for fun and profit." *Phrack Magazine* 7, 49 (1996).
24. Parno, B., Lorch, J. R., Douceur, J. R., Mickens, J., and McCune, J. M. "Memoir: Practical state continuity for protected modules." In *Proceedings of the IEEE Symposium on Security and Privacy* (May 2011).
25. Parno, B., McCune, J. M., and Perrig, A. "Bootstrapping trust in commodity computers." In *Proceedings of the IEEE Symposium on Security and Privacy* (2010).
26. Reynolds, J. "Definitional interpreters for higher-order programming languages." In *Proceedings of the 25th ACM National Conference* (1972), pp. 717–740.
27. Rutkowska, J. "Subverting VistaTM Kernel For Fun And Profit." *Black Hat Briefings* (2006).
28. Sahita, R., Warrier, U., and D. P. "Protecting Critical Applications on Mobile Platforms." *Intel Technology Journal* 13 (2009), 16–35.
29. Saltzer, J., and Schroeder, M. "The protection of information in computer systems." *Proceedings of the IEEE* 63, 9 (1975), 1278–1308.
30. Seshadri, A., Luk, M., Qu, N., and Perrig, A. "SecVisor: A tiny hypervisor to provide lifetime kernel code integrity for commodity OSes." In *Proceedings of the Twenty-First ACM SIGOPS Symposium on Operating Systems Principles* (2007), ACM, pp. 335–350.
31. Seshadri, A., Luk, M., Shi, E., Perrig, A., van Doorn, L., and Khosla, P. "Pioneer: Verifying integrity and guaranteeing execution of code on legacy platforms." In *Proceedings of the ACM Symposium on Operating Systems Principles (SOSP)* (Oct. 2005), ACM, pp. 1–15.
32. Shacham, H. "The geometry of innocent flesh on the bone: return-into-libc without function calls (on the x86)." In *Proceedings of the 14th ACM Conference on Computer and Communications Security* (New York, NY, USA, 2007), CCS ’07, ACM, pp. 552–561.
33. Singaravelu, L., Pu, C., Härting, H., and Helmuth, C. "Reducing TCB complexity for security-sensitive applications: three case studies." In *EuroSys ’06: Proceedings of the 1st ACM SIGOPS/EuroSys European Conference on Computer Systems 2006* (New York, NY, USA, 2006), ACM, pp. 161–174.
34. Strackx, R., Piessens, F., and Preneel, B. "Efficient Isolation of Trusted Subsystems in Embedded Systems." *Security and Privacy in Communication Networks* (2010), 344–361.
35. Strackx, R., Younan, Y., Philippaerts, P., Piessens, F., Lachmund, S., and Walter, T. "Breaking the memory secrecy assumption." In *Proceedings of the Second European Workshop on System Security* (2009), ACM, pp. 1–8.
36. Ta-Min, R., Litty, L., and Lie, D. "Splitting interfaces: Making trust between applications and operating systems configurable." In *Proceedings of the 7th Symposium on Operating Systems Design and Implementation* (2006), USENIX Association, pp. 279–292.
37. Thekkath, D. L. C., Mitchell, M., Lincoln, P., Boneh, D., Mitchell, J., and Horowitz, M. "Architectural support for copy and tamper resistant software." *SIGOPS Oper. Syst. Rev.* 34 (November 2000), 168–177.
38. Williams, P., and Boivie, R. "CPU support for secure executables." *Trust and Trustworthy Computing* (2011), 172–187.
39. Younan, Y., Joosen, W., and Piessens, F. "Code injection in C and C++: A survey of vulnerabilities and countermeasures." Tech. rep., Department of Computer Science, KULeuven, 2004.
40. Zhou, Z., Gligor, V., Newsome, J., and McCune, J. "Building verifiable trusted path on commodity x86 computers." In *IEEE Symposium on Security and Privacy* (2012).

### Appendix

#### A. The Vault

The Vault is a Secure Processing Module (SPM) designed to store sensitive information on behalf of other SPMs. It provides two primary services:

1. **Persistent Secret Data Storage**: An SPM can request the Vault to store persistent secret data. The Vault appends the identity of the requesting SPM (its layout and cryptographic hash of the public section), encrypts and signs the data, and stores it using the (untrusted) services of the legacy operating system.

2. **Data Retrieval**: Only an SPM that previously stored secret data can retrieve it. After mutual authentication, the Vault retrieves the encrypted data from the legacy operating system, verifies its integrity, decrypts it, and sends it over a secure channel to the requesting SPM.

The Vault is treated specially by Fides: it is created when Fides is booted, and it receives its own secret data directly from the secure storage space on the Trusted Platform Module (TPM).

**State Continuity**: The Vault also ensures state continuity [24]. It protects against two types of attacks:

1. **Rollback Attack**: An attacker might pass a stale version of an SPM’s stored data from disk to the Vault. This could result in security vulnerabilities, such as the reuse of cryptographic keys.

2. **Crash Resilience**: A compromised legacy kernel may allow an attacker to cause the system to crash, preventing the persistent storage of fresh data based on subtle timing differences. This essentially enables an attacker to prevent the system from making progress.

Our prototype implementation does not yet include state continuity guarantees, but the techniques proposed by Parno et al. [24] are applicable to Fides. Each SPM could request persistent storage of service requests before they are handled. The Vault maintains a request history for each module, acting as an intermediate module that stores state information of other modules. This reduces the number of modules requiring state-continuity storage on the TPM chip, limiting wear on Non-Volatile Random Access Memory (NVRAM).

#### B. Remote Attestation

Fides' access control model and local communication mechanism can be leveraged to attest the correct execution of modules with two key characteristics:

1. **Meaningful Attestation**: The remote party (verifier) receives meaningful attestation. Only a small Trusted Computing Base (TCB) consisting of the Fides architecture, an attestation module, the Vault, and the attested module(s) are included in the measurement.

2. **Transparency**: The attestation is transparent, allowing the correct execution of any module to be verified without modification, enhancing module reusability.

Attestation in Fides is based on a two-layered approach where each layer attests its correct execution. Due to page constraints, only a sketch of the mechanism is presented. It relies on μTPMs presented by McCune et al. [20].

**Layer 1**: The TPM chip ensures the correct loading of Fides and boots trust on the next layer. PCR registers 17, 18, and 19 are extended with a measurement of Fides, the security report of an attestation module, and the Attestation Identity Key (AIK_SPM) respectively.

**Layer 2**: Attestation modules provide an attestation service and implement PCR extend and quote functionality similar to a hardware TPM chip. This prevents hardware PCR registers from being cluttered. Multiple identical attestation modules can be loaded, allowing virtually unlimited SPMs to be attested simultaneously.

Figure 8 illustrates how the correct execution of an Attested SPM can be proven:

1. The verifier provides two nonces, n1 and n2, and an attestation module is created.
2. The attestation module extends its measurement with the Vault and requests its AIK_SPM key.
3. The attested module is measured and contacted.
4. The attestation module extends its measurement with the received result and signs it together with n2. A similar request is sent to the lower level with n1, but is only granted when the request is made from a module compliant with the measured security report in PCR 18.
5. Both quotes are sent to the verifier.

If the attested SPM calls other SPMs, the verifier can rely on the authenticated communication mechanism to ensure that no untrusted SPMs are used in the computation of the result. Alternatively, attestation-aware SPMs could notify the attestation module which SPMs are used.