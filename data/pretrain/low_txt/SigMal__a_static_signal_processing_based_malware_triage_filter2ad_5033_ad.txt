### 5.5.2 Evaluation with Sliding Window Experiments

The mean values of the daily results and their standard errors are presented in Figure 10. At a threshold \( t = 0.33 \), more than 50% of the recent daily samples can be accurately classified as either malicious or benign, with a precision of 99.5% (standard error: 0.000835). This high precision significantly reduces the resource requirements of a triage system by approximately 50%, as it avoids the need for further, more computationally expensive, analysis.

Figure 11 illustrates the detection results of all methods when applied to the sliding window dataset. The training set consists of samples from November 2012, and the testing set includes samples from December 1, 2012. The results show that other methods, such as PE-heuristics-based and CFG-based approaches, have lower precision. Although these methods achieve higher recall, they do not produce high-precision results. Additionally, the CFG-based method is computationally expensive, making it unsuitable for large-scale malware triage.

### 5.5.3 Evaluation with Current AV Labels

The detection results were initially validated using VirusTotal results obtained at the time of submission to Anubis. However, some malware may not have been detected by most antivirus vendors at that time, and there is a possibility that some malware might never be detected by all antivirus vendors. Therefore, an accurate analysis of false positives is challenging. We focused on how many malware samples SigMal could detect before any antivirus vendor identified them as malicious. Using an old dataset from 2011, we retrieved both the original and the latest antivirus labels from VirusTotal. We then performed a simulated daily sliding-window experiment and re-evaluated our results with the updated labels. Our findings indicate that SigMal could detect, on average, 70 malware samples per day before any antivirus vendor flagged them as malicious.

### 5.6 Limitations

Our approach, which relies on instance-based learning, has a primary limitation: it can only detect malware similar to previously observed samples. It cannot identify zero-day malware that is structurally different from known malware. This is a common issue with similarity-based detection methods. For example, the malware visualization method proposed in [20] also faces this challenge, although our method differs in the way signals are extracted using heuristics based on the PE structure.

### 6.2 Static Malware Similarity

Various approaches to static-feature-based malware analysis and triage systems have been proposed. Many of these methods use N-gram-based feature extraction [3, 9, 10, 13, 23, 29]. Jacob et al. [9] studied the statistical similarity of packed binaries and proposed a packer-agnostic bigram-based similarity measure. However, N-gram-based approaches are less scalable due to the computational cost of feature matching over a high-dimensional feature space. Jang et al. [10] introduced feature hashing to reduce the dimensionality of the feature space, but their evaluation was limited to clustering an unpacked malware dataset without including benign samples.

Other packer-agnostic methods include those based on features extracted from the PE file structure [24, 26, 30, 31, 35]. While these methods are time-efficient, achieving high accuracy remains a challenge. Some static-feature-based detection methods require unpacked code [5, 8, 10, 15]. For example, Hu et al. [8] used function call graphs for efficient nearest-neighbor search in a large graph database of malware. Kruegel et al. [15] proposed extracting control-flow graphs from network streams to detect worms. We used the CFG-based method from [15] for comparison in our evaluation.

### 7. Conclusions

In this paper, we introduced SigMal, a fast signal processing-based malware similarity detection framework. SigMal can operate on both packed and unpacked samples, avoiding the resource-intensive unpacking process. By using heuristics based on PE structure information, we improved the signal processing-based features. Our results show that SigMal outperforms existing static malware detection methods in terms of precision. Large-scale experiments on 1.2 million recent samples, both packed and unpacked, observed over three months, demonstrated that our method can classify 50% of incoming samples with over 99% precision.

### 8. Acknowledgments

This work was supported by the Office of Naval Research (ONR) under grant N00014-11-10111, the Army Research Office (ARO) under grant W911NF0910553, and the National Science Foundation (NSF) under grants CNS-0845559 and CNS-0905537.

### 9. References

[1] Anubis. http://anubis.iseclab.org.
[2] VirusTotal. http://www.virustotal.com.
[3] T. Abou-Assaleh, N. Cercone, V. Keselj, and R. Sweidan. N-gram-based detection of new malicious code. In Proc. of COMPSAC’04. IEEE, 2004.
[4] U. Bayer, P. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda. Scalable, behavior-based malware clustering. In Proc. of NDSS’09. Citeseer, 2009.
[5] E. Carrera and G. Erdélyi. Digital genome mapping–advanced binary malware analysis. In Virus Bulletin Conference, 2004.
[6] J. G. Daugman. Complete discrete 2-d gabor transforms by neural networks for image analysis and compression. IEEE Transactions on ASSP, 1988.
[7] M. Douze, H. Jégou, H. Sandhawalia, L. Amsaleg, and C. Schmid. Evaluation of gist descriptors for web-scale image search. In ACM International Conference on Image and Video Retrieval. ACM, 2009.
[8] X. Hu, T. Chiueh, and K. Shin. Large-scale malware indexing using function-call graphs. In Proc. of CCS’09. ACM, 2009.
[9] G. Jacob, P. M. Comparetti, M. Neugschwandtner, C. Kruegel, and G. Vigna. A static, packer-agnostic filter to detect similar malware samples. In Proc. of DIMVA’13. Springer, 2013.
[10] J. Jang, D. Brumley, and S. Venkataraman. Bitshred: feature hashing malware for scalable triage and semantic analysis. In Proc. of CCS’11. ACM, 2011.
[11] M. Karim, A. Walenstein, A. Lakhotia, and L. Parida. Malware phylogeny generation using permutations of code. Journal in Computer Virology, 1(1), 2005.
[12] A. Karnik, S. Goswami, and R. Guha. Detecting obfuscated viruses using cosine similarity analysis. In Proc. of AMS’07, pages 165–170. IEEE, 2007.
[13] J. Kolter and M. Maloof. Learning to detect and classify malicious executables in the wild. The Journal of Machine Learning Research, 7:2721–2744, 2006.
[14] J. Kornblum. Identifying almost identical files using context triggered piecewise hashing. Digital investigation, 3:91–97, 2006.
[15] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna. Polymorphic worm detection using structural information of executables. In Proc. of RAID’06. Springer, 2006.
[16] M. Labs. McAfee threats report: Second quarter 2013. Technical report, McAfee, 2013.
[17] P. Li, L. Liu, D. Gao, and M. K. Reiter. On challenges in evaluating malware clustering. In Proc. of RAID’10. Springer, 2010.
[18] B. S. Manjunath and W. Ma. Texture features for browsing and retrieval of image data. IEEE Trans. on Pattern Analysis and Machine Intelligence (PAMI), 18(8), Aug 1996.
[19] R. Moskovitch, D. Stopel, C. Feher, N. Nissim, N. Japkowicz, and Y. Elovici. Unknown malcode detection and the imbalance problem. J. Computer Virology, 5(4):295–308, 2009.
[20] L. Nataraj, S. Karthikeyan, G. Jacob, and B. S. Manjunath. Malware images: visualization and automatic classification. In Proc. of VizSec’11, VizSec ’11. ACM, 2011.
[21] A. Oliva and A. Torralba. Modeling the shape of a scene: a holistic representation of the spatial envelope. Intl. Journal of Computer Vision, 42(3):145–175, 2001.
[22] S. M. Omohundro. Five balltree construction algorithms. Technical report, International Computer Science Institute Berkeley, 1989.
[23] R. Perdisci and A. Lanzi. McBoost: Boosting scalability in malware collection and analysis using statistical classification of executables. Computer Security Applications, pages 301–310, Dec. 2008.
[24] R. Perdisci, A. Lanzi, and W. Lee. Classification of packed executables for accurate computer virus detection. Pattern Recognition Letters, 29(14), 2008.
[25] R. Perdisci, W. Lee, and N. Feamster. Behavioral clustering of HTTP-based malware and signature generation using malicious network traces. In Proc. of NSDI, 2010.
[26] K. Raman. Selecting features to classify malware. In InfoSec Southwest, 2012.
[27] C. Rossow, C. J. Dietrich, C. Grier, C. Kreibich, V. Paxson, N. Pohlmann, H. Bos, and M. van Steen. Prudent practices for designing malware experiments: Status quo and outlook. In Proc of SP’12, pages 65–79. IEEE, 2012.
[28] P. Salembier and T. Sikora. Introduction to MPEG-7: Multimedia Content Description Interface. John Wiley & Sons, Inc., New York, NY, USA, 2002.
[29] I. Santos, Y. Penya, J. Devesa, and P. Bringas. N-grams-based file signatures for malware detection. In Proc. of ICEIS’09, 2009.
[30] M. Schultz, E. Eskin, F. Zadok, and S. Stolfo. Data mining methods for detection of new malicious executables. In Proc of SP’01. IEEE, 2001.
[31] M. Shafiq, S. Tabish, F. Mirza, and M. Farooq. PE-miner: Mining structural information to detect malicious executables in real-time. In Proc. of RAID’09. Springer, 2009.
[32] S. M. Tabish, M. Z. Shafiq, and M. Farooq. Malware detection using statistical analysis of byte-level file content. In ACM SIGKDD Workshop CyberSecurity and Intelligence Informatics, 2009.
[33] A. Torralba, K. Murphy, W. Freeman, and M. Rubin. Context-based vision systems for place and object recognition. In Proceedings of ICCV, 2003.
[34] A. Walenstein, M. Venable, M. Hayes, C. Thompson, and A. Lakhotia. Exploiting similarity between variants to defeat malware. In Proc. BlackHat DC Conf., 2007.
[35] G. Wicherski. pehash: A novel approach to fast malware clustering. In USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET), 2009.