# Title: Structural Data De-anonymization: Quantification, Practice, and Implications

## Authors
- Shouling Ji
- Weiqing Li
- Mudhakar Srivatsa
- Raheem A. Beyah

## Affiliations
- **Georgia Institute of Technology**
  - Shouling Ji
  - Weiqing Li
  - Raheem A. Beyah
  - School of Electrical and Computer Engineering
- **IBM T. J. Watson Research Center**
  - Mudhakar Srivatsa

## Abstract
In this paper, we study the quantification, practice, and implications of structural data de-anonymization (DA), such as social data and mobility traces. First, we address several open problems in structural data DA by quantifying perfect and (1 − ϵ)-perfect structural data DA, where ϵ is the error tolerated by a DA scheme. To our knowledge, this is the first work to quantify structural data DA under a general data model, bridging the gap between DA practice and theory. Second, we conduct the first large-scale study on the de-anonymizability of 26 real-world structural datasets, including social networks, collaboration networks, communication networks, autonomous systems, and peer-to-peer networks. We also quantitatively show the conditions for perfect and (1 − ϵ)-perfect DA for these 26 datasets. Third, following our quantification, we design a practical and novel single-phase cold-start optimization-based DA (ODA) algorithm. Experimental analysis of ODA shows that approximately 77.7%−83.3% of users in Gowalla (0.2M users and 1M edges) and 86.9%−95.5% of users in Google+ (4.7M users and 90.8M edges) are de-anonymizable in different scenarios, demonstrating the implementability and power of optimization-based DA in practice. Finally, we discuss the implications of our DA quantification and ODA, providing general suggestions for future secure data publishing.

## Categories and Subject Descriptors
- **C.2.0 [General]:** Security and protection
- **H.4 [Information Systems Applications]:** Miscellaneous
- **G.3 [Probability and Statistics]:** Stochastic processes

## General Terms
- Security
- Privacy
- Theory
- Management

## Permission
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

## CCS'14
- **Date:** November 3–7, 2014
- **Location:** Scottsdale, Arizona, USA
- **Copyright:** 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
- **DOI:** http://dx.doi.org/10.1145/2660267.2660278.

## Keywords
- De-anonymization
- Structural data
- Quantification
- Evaluation
- Social networks
- Mobility traces

## 1. Introduction
Today, a significant amount of data generated by computer networks and services has a graph structure, referred to as structural data. For example, social networks (SNs), network topologies, and mobility traces (e.g., WiFi contacts, instant message contacts) can be modeled as graphs. Even spatiotemporal data (mobility traces) with the classical (latitude, longitude, timestamp) format can be converted to structural data using sophisticated techniques. Given the commercial value and societal impact of these structural data, security and privacy issues during data release, sharing, and transfer have become increasingly important.

Currently, the most common technique to protect structural data privacy is to remove personally identifiable information (PII) before releasing the data. However, this method is vulnerable to many de-anonymization (DA) attacks. More sophisticated anonymization schemes, such as k-anonymity and its variants, have been designed to protect structural data privacy to some extent. However, they are susceptible to emerging structure-based DA attacks due to their limitations and the rich auxiliary information available to adversaries.

Structure-based DA attacks use auxiliary data (graphs) to break the privacy of anonymized structural data based solely on structural information. The availability of auxiliary data from various domains makes these attacks powerful and practical. For instance, Flickr can be used to de-anonymize Twitter, and Facebook can be used to de-anonymize WiFi mobility traces.

Although there are successful structure-based DA techniques, there is no rigorous theoretical analysis under a general model that explains why these attacks work. In this paper, we study the quantification, practice, and implications of structural data DA. Our contributions include:
- The first work to quantify structural data DA under a general data model, answering fundamental questions about the inherent reasons for the success of existing DA practices, the conditions for perfect and (1 − ϵ)-perfect DA, and the portion of users that can be de-anonymized.
- The first large-scale study on the de-anonymizability of 26 real-world structural datasets, showing that all considered datasets are perfectly or partially de-anonymizable.
- A novel optimization-based DA (ODA) attack, which is a single-phase cold-start algorithm without any priori knowledge requirements. Experimental results on real datasets (Gowalla and Google+) demonstrate the effectiveness and power of ODA.
- Discussion of the implications of our DA quantification and ODA, along with general suggestions for future secure data publishing.

## 2. Related Work
### 2.1 State-of-the-Art Advances
Recent research has focused on the security and privacy issues related to structural data. Korolova et al. [10] presented an attack on link privacy in SNs, while Zheleva and Getoor [11] discussed another attack using link-based and group-based classification. Pang et al. [12] developed an automated procedure to identify users in 802.11 traces. Backstrom [13] proposed an algorithm to predict users’ locations using SN information. Various strategies have been developed to protect privacy in SN systems, such as pseudonym abstraction [14], decentralized protocols for anonymous communications [15], guaranteed data lifetime [16], compromised accounts detection [17], and privacy-preserving SN applications [18]. Location-based services, especially those in smartphone-based SN applications, have created significant commercial benefits but also pose serious privacy threats [3][19][20].

### 2.2 Structural Data Anonymization and DA
#### 2.2.1 Anonymization Schemes
To protect the privacy of structural data, the most common method is removing PII. However, this naive solution is vulnerable to many DA attacks. Researchers have proposed more sophisticated anonymization solutions, such as k-anonymity and its variants [6][7][8]. These solutions provide some protection against semantics-based DA attacks but fail against emerging structure-based DA attacks. Adversaries can obtain rich auxiliary information through multiple channels, making these attacks practical and effective.