### Table 3: Baseline Comparison on Preparation Time

| Firmware Image | Binaries (Total/Unique) | Basic Blocks | Multi-MH | Multi-k-MH | discovRE | Genius | Centroid | Preparation Time (Minutes) |
|----------------|-------------------------|--------------|-----------|-------------|----------|--------|----------|------------------------------|
| DD-WRT r21676 (MIPS) | 143 (142) | 329,220 | 2,927,857 | 9,419 | 83,766 | 616 | 5,475 | 4.9 |
| ReadyNAS v6.1.6 (ARM) | 1,510 (1,463) | 2,927,857 | 9,419 | 83,766 | 616 | 5,475 | 89.7 |

### Evaluation of Parameters

**A. Distance Metrics and Structural Features**

To evaluate the contribution of the proposed structural features, we conducted bipartite graph matching experiments with and without these features. As shown in Fig. 6a, the matching with structural features outperformed the matching without them. Additionally, we evaluated two distance metrics used in the LSH: cosine distance and Euclidean distance. The results indicate that the cosine distance performs better than the Euclidean distance.

**B. Codebook Sizes**

We created codebooks of different sizes to study their impact on search accuracy. We evaluated the accuracy in terms of the recall rate at two representative false positive rates. Fig. 6b illustrates the results for codebooks with 16, 32, 64, and 128 centroids. The results show that the codebook size does not significantly influence the accuracy of Genius. This insight allows us to reduce codebook preparation time by using a smaller codebook (n = 16).

**C. Training Data Sizes**

Another important parameter is the size of the training set used to generate the codebook. We selected training data samples of different sizes to generate the codebook for search. Fig. 6c shows the search results. The more samples used for training, the better Genius performed, but the increase in accuracy becomes saturated when the training data is sufficiently large (up to 100,000 functions). This is consistent with observations from image retrieval methods.

**D. Feature Encoding Methods**

We discussed two feature encoding methods in Section 4.2: bag-of-features and VLAD encoding. We compared their impacts on search accuracy while fixing other parameters. Fig. 6d illustrates the ROC curves using both encoding methods. The results show that VLAD performs better than bag-of-features encoding. This observation suggests that considering first-order statistics is beneficial for the bug search problem. Given that the computational cost is similar between VLAD and bag-of-features, we recommend using VLAD feature encoding in practice.

### Scalability of Genius

We evaluated the scalability of Genius on Dataset III, which consists of 8,126 firmware images containing 420,336,846 functions, in terms of the preparation and search phases. We investigated the time consumption for each stage to demonstrate that Genius can handle firmware images at a large scale.

**Preparation Time**

We encoded 1 million functions randomly selected from Dataset III and collected the preparation time for each. The preparation time included control flow graph extraction and graph encoding. Fig. 10a demonstrates the Cumulative Distribution Function (CDF) of time consumption for the 1 million query functions. Nearly 90% of the functions were encoded in less than 0.1 seconds, and less than 10% needed more than 4 seconds. This is because these functions have more than 1,000 basic blocks, which take longer to encode. The preparation time across different sizes of ACGFs is illustrated in Fig. 10b.

**Search Time**

We further evaluated the search time for Genius in the large-scale codebase. We partitioned Dataset III into six codebases of different scales, ranging from \( s = 10^3 \) to \( s = 10^8 \), where \( s \) is the total number of functions in the codebase. Genius was tested against 1 to 10,000 sequentially submitted queries. Fig. 10c shows the log-log plot of the time consumption for Genius during the online search phase. The search time grows sublinearly with the increase in codebase size, and the average search time observed was less than 1 second for a firmware codebase of about 100 million functions.

### Case Studies

We evaluated the efficacy of Genius in real-world bug search scenarios. Case studies were conducted on Genius for the two use scenarios discussed in Section 2. These case studies demonstrated how Genius works in the real world to facilitate the vulnerability identification process.

**Scenario I: Vulnerability Search on Dataset III**

We conducted a vulnerability search on Dataset III of 8,126 images using vulnerability queries extracted from Dataset IV. We performed a comprehensive search for two vulnerabilities (CVE-2015-1791 and CVE-2014-3508), which took less than 3 seconds. We manually verified the top 50 candidates for each vulnerability and found 38 potentially vulnerable firmware devices across 5 vendors, confirming that 23 were actually vulnerable. We contacted the product vendors for further confirmation.

- **CVE-2015-1791**: This vulnerability allows remote attackers to cause a denial of service (double free and application crash) on the device. In the top 50 candidates, we found 14 firmware images potentially affected, and confirmed 10 were actually vulnerable. These images were from D-LINK and Belkin.
- **CVE-2014-3508**: This vulnerability allows context-dependent attackers to obtain sensitive information from process stack memory. We found 24 firmware images potentially affected, and confirmed 13 were actually vulnerable. These images were from CenturyLink, D-Link, and Actiontec.

**Scenario II: Commercial Firmware Images**

We chose the two latest commercial firmware images from D-Link DIR-810 model as our evaluation targets. We built the LSH indexes for these two firmware images and searched for all 185 vulnerabilities from Dataset IV. It took less than 0.1 seconds on average to finish searching for all 154 vulnerabilities. We conducted manual verification at the top 100 candidates for each vulnerability and found 103 potential vulnerabilities in total for the two images, 16 of which were confirmed (see Table 4). We contacted the product vendor for further confirmation.

### Discussion

While we have demonstrated the efficacy of Genius for accurate, scalable bug search in IoT devices, there are several technical limitations. Our method utilizes static analysis to extract syntactical features and cannot handle obfuscated code used to avoid similarity detection (e.g., malware). The accuracy of Genius heavily relies on the quality of CFG extraction, and although IDA Pro provides reasonable accuracy, more advanced techniques could further improve it. Additionally, function inlining may change CFG structures, affecting the accuracy of Genius. Since our main focus is to improve the scalability of existing in-depth bug search, we will leave the evaluation of Genius for this case as future work.

### Related Work

We have discussed closely related work throughout the paper. Here, we briefly survey additional related work, focusing on approaches using code similarity to search for known bugs. There are many other approaches aimed at finding unknown bugs, such as fuzzing or symbolic execution, which are orthogonal to our approach and thus not discussed here.

- **Source-Level Bug Search**: Many works focus on finding code clones at the source code level, such as generating code property graphs, token-based approaches, and numerical vector-based methods. These approaches require source code and cannot find bugs in firmware images unless the source code is available.
- **Binary-Level Bug Search**: Since we do not always have access to firmware source code, bug search techniques that work on binary code are very important. Current approaches often support only a single architecture, which is a limitation since bugs from one architecture can appear in another. Genius addresses this by supporting multiple architectures.