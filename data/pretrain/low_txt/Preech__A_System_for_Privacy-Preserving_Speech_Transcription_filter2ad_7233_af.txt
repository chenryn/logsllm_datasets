### 4. Challenges in Distinguishing Dummy Segments

The difficulty in distinguishing the dummy segments from the real ones is expected due to three primary reasons:
1. **Segment Length**: The segments are very short, making it challenging to discern meaningful patterns.
2. **Dummy Segment Generation**: The dummy segments are generated using a state-of-the-art language model, which enhances their similarity to real segments.
3. **Transcription Errors**: Most transcription errors occur at the beginning and end of segments due to context breaks, further complicating the re-ordering process.

Additionally, if the user partitions the speech data (S) among multiple Cloud Service Providers (CSPs), consecutive segments are less likely to be processed by the same CSP. This setup increases Prεεch's protection against re-ordering attacks.

### 7.4 Flexibility of the Control Knobs

#### 7.4.1 Utility-Privacy Trade-off

In this section, we empirically evaluate the control knobs that provide a utility-privacy trade-off.

#### 7.4.2 Usability-Privacy Trade-off

Usability in our system can be measured along three dimensions: latency, monetary cost, and implementation overhead. However, it is important to note that Prεεch is not designed for real-time speech transcription, so latency is not a primary concern. Nevertheless, we include it in the following discussion for completeness.

**Latency Evaluations**:
- All operations in Prεεch are performed on speech segments, leading to a linear relationship between the number of segments and latency.
- We evaluated the end-to-end system latency per segment (with an average length of ~6 seconds) for the Original Speech Provider (OSP), the CSP, and Prεεch. The latency values were 2.17 seconds, 1.70 seconds, and 14.90 seconds, respectively.
- The overhead in Prεεch is primarily attributed to the many-to-one voice conversion (VC), which takes approximately 11 seconds per segment on average.
- When one-to-one VC is applied instead, the end-to-end per segment latency reduces to 3.90 seconds (or 11.47 seconds) at the expense of some privacy loss, as discussed in Section 7.4.1.

**Vocabulary Size**:
- Increasing the vocabulary size (V) enhances the scope of the differential privacy (DP) guarantee. For example, adding external words provides protection against statistical analysis like text classification (Section 7.3).
- However, a larger V results in more dummy segments and, consequently, higher monetary costs. For instance, extending V by ~1000 out-of-domain words for the Carpenter dataset incurred a total cost of $25 at d = 15.

**Distance Parameter (d)**:
- A larger value of d increases the scope of privacy but also requires more noise. For example, increasing d from 2 to 15 for the VCTK p266 dataset increased the cost by approximately $5 (Table 3).

#### 7.4.3 Utility-Usability Trade-off

The following control knobs provide a means to customize the utility-usability trade-off:

**Number of CSPs**:
- Using multiple CSPs reduces the number of dummy segments and, thus, the monetary cost. However, it may come at the expense of utility, as the transcription accuracy varies among different CSPs. For example, AWS has a higher Word Error Rate (WER) than Google (Table 1). Therefore, using multiple CSPs may result in lower mean utility.

**One-to-One VC**:
- One-to-one VC techniques have a lower WER than many-to-one VC techniques (Table 2). However, they require access to representative samples of the source speaker's voice for parallel training, limiting scalability for previously unseen speakers (Section 4.6).

### 8 Related Work

In this section, we summarize the related work in the field of privacy-preserving speech processing.

**Privacy by Design**:
- One class of approaches redesigns the speech recognition pipeline to be private by design. For example, Srivastava et al. propose an encoder-decoder architecture for speech recognition [42]. Other approaches use secure multi-party computation (SMC) to represent the basic operations of a traditional Automatic Speech Recognition (ASR) system using cryptographic primitives [32]. VoiceGuard is a system that performs ASR in the trusted execution environment of a processor [8]. However, these approaches often require significant changes to existing systems.

**Speech Sanitization**:
- Recent approaches sanitize the speech before sending it to the CSP. For instance, one approach randomly perturbs the Mel-frequency cepstral coefficients (MFCC), pitch, tempo, and timing features of the speech [45]. Others use vocal tract length normalization (VTLN) to sanitize the speaker's voice [33, 34]. A recent approach modifies the emotional features of an audio signal using a Generative Adversarial Network (GAN) [4]. Additionally, adversarial attacks against speaker identification systems can provide some privacy properties by applying minimal perturbations to mislead the network [9, 22].

These approaches differ from ours in two key ways:
1. **Textual Content**: They do not consider the textual content of the speech signal. The only exception is the approach by Qian et al. [34], which addresses the problem of private publication of speech datasets. This approach requires a text transcript with the audio file, which is not the case for the speech transcription task. Prεεch adds indistinguishable noise to the speech file, a property not provided by the other techniques.
2. **Voice Privacy**: The above approaches only consider voice privacy against a limited set of features, such as speaker identification or emotion recognition. Prεεch applies many-to-one VC to provide perfect voice privacy.

### 9 Conclusion

In this paper, we proposed Prεεch, an end-to-end system for speech transcription that:
1. Protects users' privacy along both acoustic and textual dimensions.
2. Offers improved performance relative to offline ASR.
3. Provides customizable utility, usability, and privacy trade-offs.

### Acknowledgment

This work was supported in part by the NSF under grants 1661036, 1838733, 1942014, and 1931364. We also acknowledge Google for providing Google Cloud Platform credits and NVIDIA Corporation for donating the Quadro P6000 GPU used in this research. We thank the anonymous reviewers for their valuable comments and Micah Sherr for shepherding this paper.

### References

[1] An all-neural on-device speech recognizer. https://ai.googleblog.com/2019/03/an-all-neural-on-device-speech.html.

[2] Prεεch demo. https://bit.ly/2Vytbx7.

[3] S. Ahmed, A. R. Chowdhury, K. Fawaz, and P. Ramanathan. Preech: A system for privacy-preserving speech transcription. arXiv preprint arXiv:1909.04198, 2019.

[4] R. Aloufi, H. Haddadi, and D. Boyle. Emotionless: Privacy-preserving speech analysis for voice assistants. arXiv preprint arXiv:1908.03632, 2019.

[5] D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen, et al. Deep speech 2: End-to-end speech recognition in English and Mandarin. In International Conference on Machine Learning, pages 173–182, 2016.

[6] J. Bater, X. He, W. Ehrich, A. Machanavajjhala, and J. Rogers. Shrinkwrap: Differentially-private query processing in private data federations. arXiv preprint arXiv:1810.01816, 2018.

[7] P. Boersma. Accurate short-term analysis of the fundamental frequency and the harmonics-to-noise ratio. Institute of Phonetic Sciences - University of Amsterdam, 17:97–110, 1993.

[8] F. Brasser, T. Frassetto, K. Riedhammer, A.-R. Sadeghi, T. Schneider, and C. Weinert. Voiceguard: Secure and private speech processing. In Interspeech, pages 1303–1307, 2018.

[9] W. Cai, A. Doshi, and R. Valle. Attacking speaker recognition with deep generative models. arXiv preprint arXiv:1801.02384, 2018.

[10] K. Chatzikokolakis, M. E. Andrés, N. E. Bordenabe, and C. Palamidessi. Broadening the scope of differential privacy using metrics. In E. De Cristofaro and M. Wright, editors, Privacy Enhancing Technologies, pages 82–102, Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.

[11] R. Chen, N. Mohammed, B. C. Fung, B. C. Desai, and L. Xiong. Publishing set-valued data via differential privacy. Proceedings of the VLDB Endowment, 4(11):1087–1098, 2011.

[12] M. Davino. Assessing privacy risk in outsourcing. Assessing Privacy Risk in Outsourcing/AHIMA, American Health Information Management Association, 2004.

[13] C. Dwork, A. Roth, et al. The algorithmic foundations of differential privacy. Foundations and Trends® in Theoretical Computer Science, 9(3–4):211–407, 2014.

[14] O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu, T. Shaked, S. Soderland, D. S. Weld, and A. Yates. Unsupervised named-entity extraction from the web: An experimental study. Artificial Intelligence, 165(1):91–134, 2005.

[15] A. Friedman and A. Schuster. Data mining with differential privacy. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 493–502. ACM, 2010.

[16] J. S. Garofolo, L. F. Lamel, W. M. Fisher, J. G. Fiscus, and D. S. Pallett. DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus CD-ROM. NIST Speech Disc 1-1.1. NASA STI/Recon Technical Report n, 93, 1993.

[17] A. Graves, A.-r. Mohamed, and G. Hinton. Speech recognition with deep recurrent neural networks. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pages 6645–6649. IEEE, 2013.

[18] A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta, A. Coates, et al. Deep speech: Scaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567, 2014.

[19] T. Hofmann. Probabilistic latent semantic analysis. arXiv preprint arXiv:1301.6705, 2013.

[20] Y. Jia, Y. Zhang, R. Weiss, Q. Wang, J. Shen, F. Ren, Z. Chen, P. Nguyen, R. Pang, I. Lopez Moreno, and Y. Wu. Transfer learning from speaker verification to multispeaker text-to-speech synthesis. In Advances in Neural Information Processing Systems 31, pages 4480–4490. Curran Associates, Inc., 2018.

[21] K. Kobayashi and T. Toda. Sprocket: Open-source voice conversion software. In Odyssey, pages 203–210, 2018.

[22] F. Kreuk, Y. Adi, M. Cisse, and J. Keshet. Fooling end-to-end speaker verification with adversarial examples. ICASSP 2018, Apr 2018.

[23] J. Lindberg and M. Blomberg. Vulnerability in speaker verification—a study of technical impostor techniques. In Sixth European Conference on Speech Communication and Technology, 1999.

[24] J. Lorenzo-Trueba, J. Yamagishi, T. Toda, D. Saito, F. Villavicencio, T. Kinnunen, and Z. Ling. The voice conversion challenge 2018: Promoting development of parallel and nonparallel methods. arXiv preprint arXiv:1804.04262, 2018.

[25] S. E. McGregor, P. Charters, T. Holliday, and F. Roesner. Investigating the computer security practices and needs of journalists. In 24th USENIX Security Symposium (USENIX Security 15), pages 399–414, 2015.

[26] H. Muckenhirn, M. M. Doss, and S. Marcell. Towards directly modeling raw speech signal for speaker verification using CNNs. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4884–4888. IEEE, 2018.

[27] K. S. R. Murty, B. Yegnanarayana, and M. A. Joseph. Characterization of glottal activity from speech signals. IEEE Signal Processing Letters, 16(6):469–472, 2009.

[28] G. J. Mysore. Can we automatically transform speech recorded on common consumer devices in real-world environments into professional production quality speech?—A dataset, insights, and challenges. IEEE Signal Processing Letters, 22(8):1006–1010, 2014.

[29] A. Nautsch, C. Jasserand, E. Kindt, M. Todisco, I. Trancoso, and N. Evans. The GDPR & speech data: Reflections of legal and technology communities, first steps towards a common understanding. arXiv preprint arXiv:1907.03458, 2019.

[30] S. Nutanong, C. Yu, R. Sarwar, P. Xu, and D. Chow. A scalable framework for stylometric analysis query processing. In ICDM 2016, pages 1125–1130. IEEE, 2016.

[31] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur. Librispeech: An ASR corpus based on public domain audio books. In ICASSP 2015, pages 5206–5210. IEEE, 2015.

[36] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised multitask learners. OpenAI Blog, 1(8):9, 2019.

[37] D. Ramage, D. Hall, R. Nallapati, and C. D. Manning. Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora. In EMNLP 2009, pages 248–256, Stroudsburg, PA, USA, 2009. Association for Computational Linguistics.

[38] A. Rousseau, P. Deléglise, and Y. Esteve. TED-LIUM: An automatic speech recognition dedicated corpus. In LREC, pages 125–129, 2012.

[39] S. Safavi, M. Russell, and P. Jančovič. Automatic speaker, age-group, and gender identification from children’s speech. Computer Speech & Language, 50:141–156, 2018.

[40] B. Schuller and A. Batliner. Computational paralinguistics: Emotion, affect, and personality in speech and language processing. John Wiley & Sons, 2013.

[41] B. Schuller, S. Steidl, A. Batliner, F. Burkhardt, L. Devillers, C. Müller, and S. Narayanan. Paralinguistics in speech and language—state-of-the-art and the challenge. Computer Speech & Language, 27(1):4–39, 2013.

[42] B. M. L. Srivastava, A. Bellet, M. Tommasi, and E. Vincent. Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion? In INTERSPEECH 2019, Graz, Austria, Sept. 2019.

[43] M. Steyvers and T. Griffiths. Probabilistic topic models. Handbook of Latent Semantic Analysis, 427(7):424–440, 2007.

[32] M. A. Pathak, B. Raj, S. D. Rane, and P. Smaragdis. Privacy-preserving speech processing: Cryptographic and string-matching frameworks show promise. IEEE Signal Processing Magazine, 30(2):62–74, 2013.

[44] L. Sun, K. Li, H. Wang, S. Kang, and H. Meng. Phonetic posteriorgrams for many-to-one voice conversion without parallel data training. In ICME 2016, pages 1–6. IEEE, 2016.

[33] J. Qian, H. Du, J. Hou, L. Chen, T. Jung, X.-Y. Li, Y. Wang, and Y. Deng. Voicemask: Anonymize and sanitize voice input on mobile devices. arXiv preprint arXiv:1711.11460, 2017.

[34] J. Qian, F. Han, J. Hou, C. Zhang, Y. Wang, and X.-Y. Li. Towards privacy-preserving speech data publishing. In IEEE INFOCOM 2018-IEEE Conference on Computer Communications, pages 1079–1087. IEEE, 2018.

[35] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. Improving language understanding by generative pre-training. URL: https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language-understanding-paper.pdf, 2018.

[45] T. Vaidya and M. Sherr. You talk too much: Limiting privacy exposure via voice input. In International Workshop on Privacy Engineering (IWPE), 2019.

[46] C. Veaux, J. Yamagishi, K. MacDonald, et al. CSTR VCTK Corpus: English multi-speaker corpus for CSTR voice cloning toolkit. University of Edinburgh. The Centre for Speech Technology Research (CSTR), 2017.

[47] Z. Wu, N. Evans, T. Kinnunen, J. Yamagishi, F. Alegre, and H. Li. Spoofing and countermeasures for speaker verification. Speech Communication, 66(C):130–153, Feb. 2015.