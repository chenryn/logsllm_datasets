### Observations and Comparisons

In the Geolife dataset, SGLT exhibits the lowest Average Relative Error (AvRE) among the evaluated methods. However, AdaTrace outperforms SGLT in terms of Kendall-tau, a measure of rank correlation. This highlights the importance of using multiple evaluation metrics to comprehensively assess trajectory utility.

### Visual Density Distributions

Figure 6 illustrates the visual density distributions of synthetic databases generated by various methods, with Brinkhoff serving as the real data reference. AdaTrace, while showing high AvRE, demonstrates that this is primarily due to frequent patterns (FPs) in the synthetic data having lower support compared to the real data. Even though these FPs are correctly identified as frequent, their reduced frequency in the synthetic data leads to significant support errors, explaining the competitive F1 scores despite the high AvRE.

### Spatio-Temporal Travel Metrics

AdaTrace excels in trip error, significantly outperforming its competitors. While length errors for AdaTrace are comparable to other methods, diameter errors are notably smaller. This is surprising given the clear relationship between these two metrics. Further analysis reveals that DPT and ngram tend to generate trajectories with low displacement, often including loops and U-turns. In contrast, AdaTrace's synthesis algorithm prevents such unrealistic features by guiding the random walk of each trajectory towards its final destination, resulting in more goal-driven and realistic trajectories.

### Frequent Travel Patterns

There is a correlation between FP AvRE and F1 similarity metrics, but some discrepancies exist. For instance, FP AvRE indicates a 30-40% error in FP support when using certain methods. These findings suggest that while there is a general alignment between the two metrics, they can also provide complementary insights into the quality of the synthetic data.

### Efficiency Comparison

Table 3 summarizes the execution times for generating 50,000 trajectories on a high-end laptop with an Intel i7 CPU. AdaTrace is highly efficient, completing the task in just over 2 minutes. ngram and DPT are also relatively efficient, finishing in several minutes, but not as fast as AdaTrace. SGLT, on the other hand, is significantly slower, taking several days to generate the same number of trajectories. This inefficiency makes SGLT less suitable for use on commodity hardware or mobile devices, especially for large datasets.

### Impact of Attack Resilience on Utility

#### Bayesian Inference

Our defense ensures that the difference between priors and posteriors is ≤ ϑ. As ϑ increases, the defense becomes more relaxed. Figure 7a shows the percentage improvement in Query AvRE and FP AvRE as ϑ is gradually increased. The results indicate that both spatial densities and frequent patterns benefit from a more relaxed privacy setting. This is particularly evident for queries and FPs involving the sensitive zone Z, which become more random and less preserved under stricter privacy settings.

#### Partial Sniffing

This defense involves two parameters: φ, which bounds the intersection between a sniffed actual trajectory and its synthetic counterpart, and ϱ, which limits the likelihood of the synthetic trajectory visiting a sensitive zone. We set ϱ = 0 (the strictest setting) and vary φ to observe its impact on utility. Surprisingly, aggregate utility remains constant despite changes in φ, suggesting that the impact of φ on overall utility is negligible. This is because our utility metrics consider the entire dataset rather than individual trajectory comparisons.

#### Outlier Leakage

The parameters β and κ control the blending of synthetic outliers into crowds of actual trajectories. β dictates the uniformity of the crowd, while κ specifies the required crowd size. Stricter privacy requirements (lower β, higher κ) lead to more outliers failing the defense, particularly when κ ≥ 25. This is attributed to the curse of dimensionality, as forming similar crowds in high-dimensional trajectory data is challenging. Despite this, the perturbation or regeneration of outliers has little to no impact on aggregate trajectory utility, as shown in Figure 7d.

### Summary of Findings

Under reasonable privacy parameters, Defenses 2 and 3 (Partial Sniffing and Outlier Leakage) have minimal impact on aggregate trajectory utility. Small perturbations to individual trajectories can be counterbalanced by re-injecting lost utility into the remaining trajectories. Defense 1 (Bayesian Inference), however, directly affects aggregate information, and stricter privacy settings or larger sensitive zones negatively impact utility.

### Conclusion

We introduced AdaTrace, a utility-aware location trace synthesizer that provides differential privacy and attack resilience. AdaTrace outperforms existing methods like ngram, DPT, and SGLT in terms of utility and efficiency. Our experiments on real and simulated datasets show that AdaTrace offers up to a 3-fold improvement in trace utility and is computationally more efficient, being 1.5x faster than DPT, 8x faster than ngram, and 1000x faster than SGLT. Future work will focus on extending AdaTrace to handle incremental updates for growing and streaming location trace datasets.

### Acknowledgment

This research was partially supported by NSF grants SaTC 1564097 and an RCN BD Fellowship, provided by the Research Coordination Network (RCN) on Big Data and Smart Cities, and an IBM Faculty Award. The opinions, findings, and conclusions expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies and companies mentioned above.

### References

[1] 2017. NYC Taxi & Limousine Commission – Trip Record Data. http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml. Accessed: 2018-05-03.
[2] 2018. Analyzing 1.1 Billion NYC Taxi and Uber Trips with a Vengeance. http://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/. Accessed: 2018-05-03.
[3] 2018. Uber Movement: Let’s find smarter ways forward. movement.uber.com. Accessed: 2018-05-03.
[4] Gergely Acs and Claude Castelluccia. 2014. A case study: Privacy preserving release of spatio-temporal density in Paris. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1679–1688.
[5] Miguel E Andrés, Nicolás E Bordenabe, Konstantinos Chatzikokolakis, and Catuscia Palamidessi. 2013. Geo-indistinguishability: Differential privacy for location-based systems. In Proceedings of the 2013 ACM SIGSAC Conference on Computer and Communications Security. ACM, 901–914.
[6] Bhuvan Bamba, Ling Liu, Peter Pesti, and Ting Wang. 2008. Supporting anonymous location queries in mobile environments with PrivacyGrid. In Proceedings of the 17th international conference on World Wide Web. ACM, 237–246.
[7] Vincent Bindschaedler and Reza Shokri. 2016. Synthesizing plausible privacy-preserving location traces. In 2016 IEEE Symposium on Security and Privacy (S&P). IEEE, 546–563.
[8] Nicolás E Bordenabe, Konstantinos Chatzikokolakis, and Catuscia Palamidessi. 2014. Optimal geo-indistinguishable mechanisms for location privacy. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 251–262.
[9] Thomas Brinkhoff. 2002. A framework for generating network-based moving objects. GeoInformatica 6, 2 (2002), 153–180.
[10] Konstantinos Chatzikokolakis, Catuscia Palamidessi, and Marco Stronati. 2014. A predictive differentially-private mechanism for mobility traces. In International Symposium on Privacy Enhancing Technologies. Springer, 21–41.
[11] Rui Chen, Gergely Acs, and Claude Castelluccia. 2012. Differentially private sequential data publication via variable-length n-grams. In Proceedings of the 2012 ACM Conference on Computer and Communications Security. ACM, 638–649.
[12] Rui Chen, Benjamin CM Fung, S Yu Philip, and Bipin C Desai. 2014. Correlated network data publication via differential privacy. The VLDB Journal 23, 4 (2014), 653–676.
[13] Chris Clifton and Tamir Tassa. 2013. On syntactic anonymity and differential privacy. Transactions on Data Privacy 6, 2 (2013), 161–183.
[14] Graham Cormode. 2011. Personal privacy vs population privacy: learning to attack anonymization. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1253–1261.
[15] Graham Cormode, Cecilia Procopiuc, Divesh Srivastava, Entong Shen, and Ting Yu. 2012. Differentially private spatial decompositions. In 2012 IEEE 28th International Conference on Data Engineering (ICDE). IEEE, 20–31.
[16] Wei-Yen Day and Ninghui Li. 2015. Differentially private publishing of high-dimensional data using sensitivity control. In Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security (AsiaCCS). ACM, 451–462.
[17] Yves-Alexandre De Montjoye, César A Hidalgo, Michel Verleysen, and Vincent D Blondel. 2013. Unique in the crowd: The privacy bounds of human mobility. Scientific Reports 3 (2013), 1376.
[18] Cynthia Dwork. 2006. Differential Privacy. In International Colloquium on Automata, Languages, and Programming. Springer, 1–12.
[19] Cynthia Dwork. 2008. Differential privacy: A survey of results. In International Conference on Theory and Applications of Models of Computation. Springer, 1–19.
[20] Cynthia Dwork, Aaron Roth, et al. 2014. The algorithmic foundations of differential privacy. Foundations and Trends® in Theoretical Computer Science 9, 3–4 (2014), 211–407.
[21] Matthew Fredrikson, Eric Lantz, Somesh Jha, Simon Lin, David Page, and Thomas Ristenpart. 2014. Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing. In USENIX Security Symposium. 17–32.
[22] Marco Gaboardi, Hyun-Woo Lim, Ryan M Rogers, and Salil P Vadhan. 2016. Differentially Private Chi-Squared Hypothesis Testing: Goodness of Fit and Independence Testing. In ICML. 2111–2120.
[23] Bugra Gedik and Ling Liu. 2005. Location privacy in mobile systems: A personalized anonymization model. In 25th IEEE International Conference on Distributed Computing Systems (ICDCS 2005). IEEE, 620–629.
[24] Arthur Gervais, Reza Shokri, Adish Singla, Srdjan Capkun, and Vincent Lenders. 2014. Quantifying web-search privacy. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 966–977.
[25] Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu. 2010. Boosting the accuracy of differentially private histograms through consistency. Proceedings of the VLDB Endowment 3, 1-2 (2010), 1021–1032.
[26] Xi He, Graham Cormode, Ashwin Machanavajjhala, Cecilia M Procopiuc, and Divesh Srivastava. 2015. DPT: Differentially private trajectory synthesis using hierarchical reference systems. Proceedings of the VLDB Endowment 8, 11 (2015), 1154–1165.
[27] Ari Juels and Ronald L Rivest. 2013. Honeywords: Making password-cracking detectable. In Proceedings of the 2013 ACM SIGSAC Conference on Computer and Communications Security. ACM, 145–160.
[28] Shiva P Kasiviswanathan and Adam Smith. 2014. On the 'semantics' of differential privacy: A Bayesian formulation. Journal of Privacy and Confidentiality 6, 1 (2014), 1.