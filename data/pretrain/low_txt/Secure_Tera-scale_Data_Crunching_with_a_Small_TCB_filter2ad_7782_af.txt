### Environmental Constraints

**Figure 13** illustrates the progress of the application. It takes approximately 13 hours to process 1 terabyte of data, with a relatively steady processing rate of 23 MB/s. The zoomed-in view shows slight variability in the processing speed.

- **0.9TB**
- **11h**
- **8h**
- **12h**
- **1.0TB**
- **0.8TB**
- **0.6TB**
- **0.4TB**
- **0.2TB**
- **2h**
- **4h**
- **6h**
- **0h**
- **14h**

**Figure 13: Progress in hours to process 1TB of data.** The zoomed-in view highlights a negligible variability in processing speed with a straight dashed line.

- **10h**
- **12h**

It is important to note that this experiment uses a dataset that is one to two orders of magnitude larger than previous work on secure data analytics [13], [17]. This is also unprecedented on the XMHF-TrustVisor software stack [10], [25], [15], which was designed for small applications, and on a bare-metal hypervisor.

### Nucleobase Search

This application [26, 3.2] searches for a nucleobase sequence among the billion-scale reads (i.e., fragments obtained from DNA sequencing machines) present in the FASTQ format of the human genome [40]. The application is relevant for investigating protein-coding mRNA sequences or for assembling sequences to reconstruct a contiguous interval of the genome [27].

**Figure 14** shows the outcome of our experiment on a human genome of approximately 0.3 TB. The experiment produces about 1.15 million page faults handled directly by the hypervisor, and about 2.24 thousand are forwarded to the SMM for grabbing data from disk. The nucleobase search is slower than the first application because it involves processing all the data.

- **(cid:3)(cid:2)(cid:6)(cid:3)(cid:17)(cid:13)**
- **(cid:3)(cid:2)(cid:5)(cid:3)(cid:17)(cid:13)**
- **(cid:3)(cid:2)(cid:4)(cid:3)(cid:17)(cid:13)**
- **(cid:15)(cid:18)(cid:27)(cid:28)(cid:14)(cid:17)(cid:1)(cid:19)(cid:18)(cid:27)(cid:22)(cid:21)(cid:3)(cid:16)(cid:29)(cid:20)(cid:24)(cid:22)(cid:25)(cid:19)(cid:18)(cid:27)(cid:22)(cid:3)(cid:27)(cid:22)(cid:18)(cid:26)(cid:20)(cid:23)**
- **(cid:3)(cid:23)**
- **(cid:4)(cid:23)**
- **(cid:5)(cid:23)**
- **(cid:6)(cid:23)**
- **(cid:7)(cid:23)**
- **(cid:8)(cid:23)**
- **(cid:9)(cid:23)**
- **(cid:10)(cid:23)**
- **(cid:11)(cid:23)**
- **(cid:12)(cid:23)**

**Figure 14: Progress in hours to process a 0.3 TB large human genome.**

### Database Engine

The final application is the full SQLite (v.3.8.7.2) [28], a real-world database engine with a non-trivial code base of 92.6K lines of code, executed on LASTGT without modifying its source code. We compiled it with a virtual file system module that uses LASTGT’s library to access the state, and with an abstraction layer that uses LASTGT’s functionality for memory management and I/O.

The benchmark measures the time to query key-value stores of different sizes to get the value associated with a specific key.

- **(cid:4)(cid:2)**
- **(cid:3)(cid:7)**
- **(cid:3)(cid:2)**
- **(cid:3)(cid:7)**
- **(cid:3)(cid:2)**
- **(cid:19)(cid:16)(cid:14)(cid:18)(cid:17)(cid:15)(cid:19)**
- **(cid:3)**
- **(cid:12)(cid:10)**
- **(cid:4)**
- **(cid:12)(cid:10)**
- **(cid:6)**
- **(cid:12)(cid:10)**
- **(cid:9)**
- **(cid:12)(cid:10)**
- **(cid:3)(cid:8)**
- **(cid:12)(cid:10)**
- **(cid:5)(cid:4)**
- **(cid:12)(cid:10)**
- **(cid:8)(cid:6)**
- **(cid:12)(cid:10)**
- **(cid:3)(cid:4)(cid:9)**
- **(cid:12)(cid:10)**
- **(cid:4)(cid:7)(cid:8)**
- **(cid:12)(cid:10)**
- **(cid:7)(cid:3)(cid:4)**
- **(cid:12)(cid:10)**
- **(cid:3)**
- **(cid:11)(cid:10)**
- **(cid:4)**
- **(cid:11)(cid:10)**
- **(cid:1)(cid:1)(cid:1) (cid:2)(cid:1)(cid:4)(cid:7)**
- **(cid:13)(cid:10)**

**Figure 15: Time (y) to query a SQLite-based key-value store of different sizes (x).** The state is built using 128MB chunks and 256KB block sizes.

The results in **Figure 15** show that the query time grows slowly up to x = 128MB due to the larger data loaded in untrusted memory and the larger hash tree to be validated in the trusted execution environment. At x = 128MB, 256MB, 512MB, the query time stabilizes. This is due to the data access pattern of SQLite, which only involves the first chunk. At x = 1GB, 2GB, however, SQLite also accesses the 7th chunk before going back to the first one. This forces LASTGT to load and validate the metadata of several chunks and to maintain their data in untrusted memory in case it is accessed. This happens similarly with larger databases. For instance, at x = 0.25TB, SQLite requires accessing one more chunk (the 420th) in addition to those listed before. Hence, the overhead scales linearly with the number of accessed chunks.

### A Glimpse of Chunk & Block Size Optimization

To demonstrate the benefits of optimizing LASTGT for specific application requirements, we repeated the previous SQLite-based experiments by protecting the database using a smaller chunk size (1MB) and block size (4KB). The results in **Figure 16** show about an order of magnitude better performance. This is chiefly due to the smaller chunks read from disk and smaller data blocks transferred in secure memory whenever the engine performs a random memory access. The performance with a terabyte-scale state is in the order of a few seconds. This is due to a large master-chunk that contains metadata for many (about 280K) small chunks, in contrast with the few (about 2K) large chunks in the previous experiment.

- **3.6**
- **3.4**
- **3.2**
- **0.4**
- **0.2**
- **0.0**
- **seconds**
- **128 MB**
- **256 MB**
- **512 MB**
- **1 GB**
- **2 GB**
- **...**
- **0.25 TB**

**Figure 16: Time (y) to query a SQLite-based key-value store of different sizes (x).** The state is built using 1MB chunks and 4KB block sizes.

### Discussion

The performance of LASTGT is influenced by various factors and can be optimized by leveraging better-performing trusted components. First, the chunk and block sizes fixed for all experiments can be tuned for specific applications. This optimization problem is left for future work. However, intuitively, smaller chunk and block sizes reduce unnecessary data validation and data loading. Second, when a memory map is created, LASTGT optimizes for lazy loading in isolated memory, but XMHF-TrustVisor still requires the data to be present in untrusted main memory. This means writing data in memory bypasses critical optimizations such as lazy loading from disk. In this case, we believe that the SGX implementation can be beneficial to take advantage of the highly optimized kernel software stack, in addition to avoiding expensive virtualization operations such as VMEXITs and maintaining nested page tables.

### Conclusions

We have described the design, implementation, and evaluation of LASTGT, showing that it is possible to build a secure system using a generic trusted component and supporting generic large-scale data applications. Our experiments with applications such as databases and genome analytics show that generic large-scale applications can run on systems with a small TCB. Overhead is significant, but we also show that the overhead in XMHF-TrustVisor is mostly due to expensive data I/O and context switches, which we expect can be heavily reduced on Intel SGX.

### Acknowledgments

This work was partially supported by the EC through project H2020-643964 (SUPERCLOUD), by national funds of Fundação para a Ciência e a Tecnologia (FCT) through project UID/CEC/00408/2013 (LaSIGE). We thank Vinicius Cogo for interesting discussions and support with the cluster, and André Nogueira for fruitful discussions on kernel-level development.

### References

[1] W. R. Claycomb and A. Nicoll, “Insider Threats to Cloud Computing: Directions for New Research Challenges,” in Proc. of the 36th Computer Software and Applications Conf. (COMPSAC), 2012.

[2] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, “Hey, you, get off of my cloud: exploring information leakage in third-party compute clouds,” in Proc. of the 16th Conf. on Computer and Communications Security (CCS), 2009.

[3] S. Checkoway and H. Shacham, “Iago attacks,” in Proc. of the 18th Conf. on Architectural Support for Programming Languages and Operating Systems (ASPLOS), vol. 41, no. 1, 2013.

[4] Trusted Computing Group, “TPM Specs v2.0 rev. 00.99,” 2013.

[5] A. F. Simpao, L. M. Ahumada, J. A. Gálvez, and M. A. Rehman, “A Review of Analytics and Clinical Informatics in Health Care,” Journal of Medical Systems, vol. 38, no. 4, 2014.

[6] K. Srinivas, B. Rani, and A. Govrdhan, “Applications of Data Mining Techniques in Healthcare and Prediction of Heart Attacks,” Int. Journal on Computer Science and Engineering (IJCSE), vol. 02, no. 2, 2010.

[7] D. H. Chau, C. Nachenberg, J. Wilhelm, A. Wright, and C. Faloutsos, “Polonium: Tera-Scale Graph Mining and Inference for Malware Detection,” in Proc. of the SIAM Conf. on Data Mining (SDM), 2011.

[8] K. Ren, C. Wang, and Q. Wang, “Security Challenges for the Public Cloud,” IEEE Internet Computing, vol. 16, no. 1, 2012.

[9] P. Muir and Et-al., “The real cost of sequencing: scaling computation to keep pace with data generation,” Genome Biology, vol. 17.1, 2016.

[10] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor, and A. Perrig, “TrustVisor: Efficient TCB Reduction and Attestation.” in Proc. of the IEEE Symp. on Security and Privacy (S&P), 2010.

[11] B. Vavala, N. Neves, and P. Steenkiste, “Secure Identification of Actively Executed Code on a Generic Trusted Component,” in Proc. of the IEEE Conf. on Dependable Systems and Networks (DSN), 2016.

[12] S. Bajaj and R. Sion, “TrustedDB: A Trusted Hardware-Based Database with Privacy and Data Confidentiality,” IEEE Transactions on Knowledge and Data Engineering, vol. 26, no. 3, 2014.

[13] F. Schuster and M. Costa, “VC3: Trustworthy data analytics in the cloud,” in Proc. of the Symp. on Security and Privacy (S&P), 2015.

[14] A. Baumann, M. Peinado, and G. Hunt, “Shielding applications from an untrusted cloud with Haven,” in Proc. of the 11th USENIX Conf. on Operating Systems Design and Implementation (OSDI), 2014.

[15] Y. Li, J. McCune, J. Newsome, A. Perrig, B. Baker, and W. Drewry, “MiniBox: a two-way sandbox for x86 native code,” in Proc. of the USENIX Annual Technical Conf. (ATC), 2014.

[16] A. S. Tanenbaum, “Lessons learned from 30 years of MINIX,” Communications of the ACM (CACM), vol. 59, no. 3, 2016.

[17] T. T. A. Dinh, P. Saxena, E.-C. Chang, B. C. Ooi, and C. Zhang, “M2R: enabling stronger privacy in MapReduce computation,” in Proc. of the 24th USENIX Security Symp. (SEC), 2015.

[18] S. Arnautov, B. Trach, F. Gregor, T. Knauth, A. Martin, C. Priebe, J. Lind, D. Muthukumaran, M. L. Stillwell, D. Goltzsche, D. Eyers, P. Pietzuch, and C. Fetzer, “SCONE: Secure Linux Containers with Intel SGX,” in Proc. of the 12th USENIX Conf. on Operating Systems Design and Implementation (OSDI), 2016.

[19] S. Shinde, D. L. Tien, S. Tople, and P. Saxena, “PANOPLY: Low-TCB Linux Applications with SGX Enclaves,” in Proc. of the Annual Network and Distributed System Security Symp. (NDSS), 2017.

[20] T. Hunt, Z. Zhu, Y. Xu, S. Peter, and E. Witchel, “Ryoan: A Distributed Sandbox for Untrusted Computation on Secret Data,” in Proc. of the 12th USENIX Conf. on Operating Systems Design and Implementation (OSDI), 2016.

[21] W. Wei, J. Du, T. Yu, and X. Gu, “SecureMR: A Service Integrity Assurance Framework for MapReduce,” in Proc. of the Computer Security Applications Conf. (ACSAC), 2009.

[22] H. Ulusoy, M. Kantarcioglu, and E. Pattuk, “TrustMR: Computation Integrity Assurance System for MapReduce,” in Proc. of the IEEE Conf. on Big Data (Big Data), 2015.

[23] M. Correia, P. Costa, M. Pasin, A. Bessani, F. Ramos, and P. Verissimo, “On the Feasibility of Byzantine Fault-Tolerant MapReduce in Clouds-of-Clouds,” in Proc. of the 31st IEEE Int. Symp. on Reliable Distributed Systems (SRDS), 2012.

[24] B. Vavala, N. Neves, and P. Steenkiste, “Securing Passive Replication Through Verification,” in Proc. of the 34st IEEE Symp. on Reliable Distributed Systems (SRDS), 2015.

[25] A. Vasudevan, S. Chaki, L. Jia, J. McCune, J. Newsome, and A. Datta, “Design, Implementation and Verification of an Extensible and Modular Hypervisor Framework,” in Proc. of the IEEE Symp. on Security and Privacy (S&P), 2013.

[26] B. Haubold and T. Wiehe, Biological Sequences and the Exact String Matching Problem. Birkhäuser Verlag, Basel (Switzerland), 2006.

[27] J. C. Venter and Et-al., “The Sequence of the Human Genome,” Science, vol. 291, no. 5507, 2001.

[28] SQLite. WWW.SQLITE.ORG

[29] Intel. Intel Software Guard Extensions. HTTPS://SOFTWARE.INTEL.COM/SITES/DEFAULT/FILES/MANAGED/48/88/329298-002.PDF

[30] A. Baumann, M. Peinado, G. Hunt, K. Zmudzinski, C. V. Rozas, M. Hoekstra. “Secure execution of unmodified applications on an untrusted host”. Poster/Work-in-Progress. SOSP, 2013. HTTP://RESEARCH.MICROSOFT.COM/PUBS/204758/SOSP13-ABSTRACT.PDF

[31] Intel Software Guard Extensions: EPID Provisioning and Attestation Services. HTTPS://SOFTWARE.INTEL.COM/SITES/DEFAULT/FILES/MANAGED/AC/40/2016%20WW10%20SGX%20PROVISIONING%20AND%20ATTESATATION%20FINAL.PDF

[32] David A. Wheeler. SLOCCount. HTTP://WWW.DWHEELER.COM/SLOCCOUNT/SLOCCOUNT.HTML

[33] Cloud Security Alliance. The Treacherous 12 – Cloud Computing Top Threats in 2016. HTTPS://DOWNLOADS.CLOUDSECURITYALLIANCE.ORG/ASSETS/RESEARCH/TOP-THREATS/TREACHEROUS-12-CLOUD-COMPUTING-TOP-THREATS.PDF

[34] Common Vulnerabilities and Exposures. CVE-2016-3841. HTTPS://CVE.MITRE.ORG/CGI-BIN/CVENAME.CGI?NAME=CVE-2016-3841

[35] Kernel Statistics. HTTP://LINUXCOUNTER.NET/STATISTICS/KERNEL

[36] AMD. Secure Memory Encryption. HTTP://DEVELOPER.AMD.COM/WORDPRESS/MEDIA/2013/12/AMD-MEMORY-ENCRYPTION-WHITEPAPER-V7-PUBLIC.PDF

[37] AMD. Secure Encrypted Virtualization. HTTP://SUPPORT.AMD.COM/TECHDOCS/55766-SEV-KM%20API-SPEC.PDF#SEARCH=SECURE%2520ENCRYPTED%2520VIRTUALIZATION

[38] Amazon. Amazon Linux AMI Security Advisory: ALAS-2016-653. HTTPS://ALAS.AWS.AMAZON.COM/ALAS-2016-653.HTML

[39] Rackspace. QEMU “VENOM” Vulnerability (CVE-2015-3456). HTTPS://COMMUNITY.RACKSPACE.COM/GENERAL/F/53/T/5187

[40] DNAnexus Sequence Read Archive. Homo Sapiens SRR622458-NA12891. HTTP://SRA.DNANEXUS.COM/RUNS/SRR622458

[41] C. Tsai, D. Porter. “Graphene/Graphene-SGX Library OS - a library OS for Linux multi-process applications, with Intel SGX support”. HTTPS://GITHUB.COM/OSCARLAB/GRAPHENE