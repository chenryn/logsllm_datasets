# Fifth ACM Workshop on Artificial Intelligence and Security (AISec 2012)

## Authors
- Alvaro A. Cárdenas, Fujitsu Laboratories of America, 1240 E Arques Ave, M/S 345, Sunnyvale, CA, 94085, USA; cardenas@fla.fujitsu.com
- Blaine Nelson, Wilhelm Schickard Institute for Computer Science, University of Tübingen, Sand 1, 72076 Tübingen, Germany; blaine.nelson@wsii.uni-tuebingen.de
- Benjamin I. P. Rubinstein, Microsoft Research, Silicon Valley, 1288 Pear Ave., Mountain View, CA 94043, USA; ben.rubinstein@microsoft.com

## Abstract
The Workshop on Artificial Intelligence and Security (AISec) focuses on the application of AI and Machine Learning (ML) to address unique security and privacy challenges. The workshop serves as a premier venue for this interdisciplinary field, attracting submissions from a diverse set of researchers. Its primary goal is to provide a forum for researchers in Security, Privacy, AI, and ML to discuss the role of AI and ML in security and privacy applications, and to highlight the unique needs of these problems to the AI and ML communities.

## Categories and Subject Descriptors
- **C.2.0 [Computer-Communication Networks]:** General—security and protection (e.g., firewalls)
- **D.4.6 [Operating Systems]:** Security and Protection
- **I.2.6 [Artificial Intelligence]:** Learning
- **I.2.7 [Artificial Intelligence]:** Natural Language Processing
- **I.2.8 [Artificial Intelligence]:** Problem Solving, Control Methods, and Search
- **K.4.1 [Computers and Society]:** Public Policy Issues—privacy
- **K.6.5 [Management of Computing and Information Systems]:** Security and Protection

## General Terms
- Algorithms
- Security
- Theory

## Keywords
- Artificial Intelligence
- Computer Security
- Machine Learning
- Computer Privacy

## 1. Background and Motivation
The use of AI, ML, and Data Mining for security and privacy continues to grow and diversify. For example, there has been a significant increase in the use of Big Data analytics for security. These technologies play a crucial role in extracting knowledge, situational awareness, and security intelligence from Big Data, and in the establishment of Security Information and Event Management (SIEM) systems. Companies like Click Security, Splunk, IPTrust, and IBM's QRadar are key players in this field, which is expected to continue growing. Additionally, cloud computing offers advantages such as large-scale ML and data-driven abuse detection, further enhancing security.

For the past four years, AISec has served as the primary meeting place for researchers in security, privacy, AI, and ML. It provides a venue to develop fundamental theory and practical applications supporting the use of ML for security and privacy. The community, focused on topics like learning in game-theoretic adversarial environments, privacy-preserving learning, and new learning algorithms in security, benefits from the continued co-location with CCS. In 2011, AISec had excellent attendance, placing it in the middle of the CCS 2011 workshops by size.

## 2. Goals and Objectives
The AISec workshop aims to complement mainstream venues in security and AI. While much research in security and privacy involves ML or data analysis, the discussion of appropriate AI application is often limited. New learning algorithms for previously identified problems are rare in mainstream venues, which focus on new security issues. Adaptive defenses are not always evaluated against active adversaries but rather against fixed datasets. Privacy-preserving learning, a rich topic in theory, learning, and databases, has had less exposure in security. Conversely, security/privacy papers suitable for ML venues do not always reach a security audience.

## 3. Topics of Interest
We solicited paper submissions on the following (but not limited to) research topics:
- Adversarial Learning
- Robust Statistics
- Online Learning
- Computer Forensics
- Spam Detection
- Botnet Detection
- Intrusion Detection
- Malware Identification
- Big Data Analytics for Security
- Adaptive Side-Channel Attacks
- Privacy-Preserving Data Mining
- Design and Analysis of CAPTCHAs
- Phishing Detection and Prevention
- AI Approaches to Trust and Reputation
- Vulnerability Testing through Intelligent Probing (e.g., Fuzzing)
- Content-Driven Security Policy Management and Access Control
- Techniques and Methods for Generating Training and Test Sets
- Anomalous Behavior Detection (e.g., for Fraud Prevention, Authentication)

## 4. Program Committee
We are grateful to the members of our program committee:
- Christos Dimitrakakis, EPFL, Switzerland
- Mario Frank, University of California, Berkeley, USA
- Giorgio Giacinto, University of Cagliari, Italy
- Rachel Greenstadt, Drexel University, USA
- Guofei Gu, Texas A&M University, USA
- Ling Huang, Intel Labs, USA
- Anthony Joseph, University of California, Berkeley, USA
- Murat Kantarciouglu, University of Texas at Dallas, USA
- Latifur Khan, University of Texas at Dallas, USA
- Pavel Laskov, University of Tübingen, Germany
- Justin Ma, University of California, Berkeley, USA
- Aikaterini Mitrokotsa, EPFL, Switzerland
- Konrad Rieck, University of Göttingen, Germany
- Fabio Roli, University of Cagliari, Italy
- Elaine Shi, University of California, Berkeley, USA
- Robin Sommer, ICSI and LBNL, USA
- Jessica Staddon, Google, USA
- Natalia Stakhanova, University of South Alabama, USA
- J. Doug Tygar, University of California, Berkeley, USA
- Shobha Venkataraman, AT&T Research, USA

Copyright is held by the author/owner(s).  
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.  
ACM 978-1-4503-1651-4/12/10.