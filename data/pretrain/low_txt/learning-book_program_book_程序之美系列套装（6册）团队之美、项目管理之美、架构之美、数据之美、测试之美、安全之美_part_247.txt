### 为什么决定不采用它们的设计理念

#### G公司的BigTable
BigTable（Chang等，2006）是为支持G公司多种Web应用而设计的分布式存储系统。该系统通过水平切分“大表”（bigtable）为多个小表（tablet），并将其分散到不同的服务器上，以实现可扩展性。BigTable还具备灵活的模式和有序存储等特性，这些与我们采用的方法有相似之处。然而，我们的设计在某些关键方面与BigTable有所不同。

**首要区别在于数据复制方式**。BigTable构建在G公司的文件系统GFS之上（Ghemawat等，2003）。GFS通过同步更新三个数据备份到三台不同的服务器上来处理数据备份。这种方法在一个数据中心内可以很好地工作，因为服务器间的延迟很短。但在跨多个分散的数据中心时，同步更新的成本非常高。例如，Alice可能需要等待很长时间才能看到状态更新，特别是当她的朋友通过带宽较低的网络访问数据中心时。为了支持跨数据中心的数据复制，我们提出了时间轴一致性模型，并引入了与主备份、负载均衡和故障恢复相关的机制。

另一个主要区别在于**系统架构**。BigTable和GFS之间存在数据库服务器和文件系统的分离，而PNUTS则不采用这种分离。GFS最初是为了需要扫描大文件的应用（如MapReduce）设计和优化的。BigTable通过保留每个记录的版本历史并与GFS关联，将文件以SSTables格式压缩来减少存储空间。这意味着对于读取和更新操作，数据需要解码和编码。此外，GFS面向扫描的特点有助于BigTable处理面向列的扫描应用（如“返回所有用户的所有地理位置信息”）。相反，我们的主要应用场景是读取和更新小范围记录内的单个版本。因此，我们的策略是将数据作为完整的记录，以B树形式组织保存在磁盘上，从而优化快速定位和就地更新。

此外，PNUTS支持一个应用中的多个表，而不是一个大表，并且同时支持散列表和有序表。MegaStore是在BigTable之后推出的系统，添加了事务、索引和更丰富的API，但仍遵循BigTable的基本架构原则。

#### Amazon的Dynamo
Dynamo（DeCandia等，2007）是Amazon开发的大规模数据存储系统，与我们的高可用性和大规模数据存储目标最为接近。Dynamo通过允许应用程序向任何副本写入数据来提供写操作的可用性，并通过Gossip协议（稍后会详细介绍）延迟传播这些更新操作。

为了解决网速慢和易失效问题，Dynamo和PNUTS都采用了延迟传播更新策略。然而，PNUTS的复制策略与Dynamo有很大不同。在Gossip协议中，更新操作会随机传播到选定的副本，再由这些副本继续传播给其他随机选择的副本。这种随机性提供了概率性的保证，确保大多数副本能够相对快速地更新。但在我们的应用场景中，这种随机性通常是次优的。例如，Alice在美国西海岸的数据中心执行状态更新操作，若采用Gossip方式，该操作可能随机传播到新加坡的副本，然后再到德克萨斯州的副本，最后传到东京的副本。这种跨越太平洋三次的更新操作浪费了大量的带宽。相比之下，一种更确定性的方法只需一次传播即可节省宝贵的跨太平洋主干带宽。此外，Gossip要求传播数据的副本预先知道其他数据中心的哪些服务器上有副本，这使得负载均衡和数据恢复变得更加复杂。

另一个关键区别在于**一致性协议**。Gossip协议本质上是一种最终一致性模型：所有数据副本最终会保持一致，但在更新传播期间，副本可能会出现不一致的情况。特别是在多步更新的情况下，副本可能会进入无效状态。例如，Alice将她的状态从“Sleeping”改为“Busy”，再将地理位置信息从“Home”改为“Work”。由于更新顺序的不同，有些副本可能会首先接收到改为“Work”的更新，导致临时显示（“Sleeping, Work”）状态。这种情况下，如果Alice的老板看到这种状态，可能会对Alice产生误解。对于依赖于在一条记录上按合理顺序执行多次更新的应用程序，我们需要比最终一致性更严格的一致性保证。虽然时间线一致性模型允许副本过期，但即使是过期的副本也应该是与某个合理的更新顺序一致的版本。

PNUTS和Dynamo还有许多其他区别。Dynamo仅支持散列表，而不支持有序表；而PNUTS两者都支持。相比Dynamo，PNUTS支持更灵活的数据到服务器的映射机制，从而提高负载均衡和数据恢复能力（尤其是对于可能出现不可预测热点的有序表）。除了Dynamo，Amazon还提供了其他存储系统，如用于存储数据块的S3和用于在结构化、包含索引的数据上执行复杂查询的SimpleDB。尽管SimpleDB提供了更丰富的API，但它需要应用程序实现某种数据分区策略，每个分区都有固定的大小限制。因此，一个分区内的数据增长受到限制。

#### 微软的Azure SDS
作为Azure服务的一部分，微软构建了大规模的SQL Server服务器，称为SQL数据服务（SLDataService或SDS）。SDS的一个优点是通过扩展数据索引并使用SQL Server作为查询处理引擎，提高了查询能力。然而，SDS通过严格的分区来实现其查询表达能力，这使得重分区变得困难。因此，虽然可以在一个数据分区内执行复杂的查询请求，但如果某个数据分区的数据量增长或访问频繁，系统无法简单或自动地通过划分分区来解决“热点”效应。我们的策略是通过表抽象层，使数据分区和重新分区对上层应用透明。尽管PNUTS的查询表达能力不如SDS（PNUTS不支持跨分区的复杂查询），但我们仍在探索增强PNUTS查询功能的策略（如前面描述的视图方法）。

PNUTS和SDS的另一个区别在于地理复制。PNUTS将地理复制作为内置的主要特性，而至少对于SDS的第一个版本，其工作负荷期望全部在一个数据中心内运行，只有在主副本全部崩溃时才会使用远程备份。我们希望Alice在新加坡、柏林和里约热内卢（巴西）的好友都能拥有本地的Alice更新的首要备份。

#### 其他相关系统
类似我们的系统，一些需要扩展性和灵活性的其他公司也构建了许多系统。Facebook构建了Cassandra系统（Lakshman等，2008），这是一个P2P（Peer-to-Peer，对等网络）的数据存储系统，其数据模型类似于BigTable，架构类似于Dynamo，系统只提供最终一致性。

Sharded数据库（如Flickr [Pattishall] 和Facebook [Sobel 2008] 使用的MySQL分区策略）通过将数据分区到多个服务器上来提供可扩展性。然而，Sharding系统并没有提供我们所期望的扩展灵活性或全球数据复制特性。与SimpleDB类似，Sharded数据库的数据需要预分区，并且只有一个副本可以作为主副本执行写操作。而在PNUTS中，不同数据中心的所有副本都可以执行写操作（虽然是对不同的记录）。

#### 雅虎的其他系统
PNUTS是雅虎构建的众多云系统之一。在数据管理方面，还包括云计算的其他两个方面，但研究的问题与PNUTS不同。Hadoop是MapReduce框架（Dean和Ghemawat，2007）的开源实现，它提供了在大数据文件上的大规模并行分析处理。Hadoop的文件系统HDFS对扫描操作进行了优化，因为MapReduce主要用于处理面向扫描的操作。相比之下，PNUTS主要用于处理单条记录的读写操作。另一个系统MOBStor是为存储和服务大数据对象（如图片和视频）而设计的，旨在为静态对象提供低延迟检索和低成本存储。由于许多应用需要结合记录存储、数据分析和对象检索，我们正在探索无缝集成这三个系统（Cooper等，2009）。

### 结论
启动PNUTS项目时，我们希望该系统能够无缝扩展到跨多个州的成千上万的服务器。构建这样的系统不仅需要巧妙的工程技术，还需要我们在数据库的许多现有领域进行深入探索。虽然放弃ACID特性是一个相对简单的决策，但我们很快发现需要提出其他方案来替代它，因此我们提出了时间线一致性模型。尽管该模型在设计上相对简单，但处理复杂的极端情况、提出有效的实现机制以及构建应用用例模型都需要反复深入的思考。

值得一提的是，刚开始时，我们的客户和我们自己都不太关心系统只支持简单查询语言的不足。但随着开发者开始在PNUTS上构建实际应用，我们意识到系统无法处理的小部分复杂查询将影响其被广泛采用。如果我们不提出解决这些问题的机制，开发者就需要采用复杂的变通方案，在应用内部实现代价高昂的操作（如嵌套连接）或者频繁地将数据导出到其他索引来支持他们的应用工作负载。

云数据管理是一个新兴领域，这在许多其他可选系统的设计和部署中也得到了体现。我们希望PNUTS的思想有助于我们更接近构建易于管理、广泛应用、多租户的云数据库系统的目标，为应用提供弹性、高效、全球可用且极其健壮的数据后台。

### 致谢
PNUTS是雅虎许多员工共同努力的结果。工程方面的负责人是P. P. S. Narayan和Chuck Neerdaels。该项目的其他研究员包括Adam Silberstein和Rodrigo Fonseca。Brad McMillen和Pat Quaid帮助构建PNUTS架构并将其应用于雅虎的云计算服务。该系统的其他设计和开发人员包括Phil Bohannon、Ramana Yerneni、Daniel Weaver、Michael Bigby、Nicholas Puz、Hans-Arno Jacobsen、Bryan Call和Andrew Feng。

### 参考文献
[1] Azure Services Platform. http://www.microsoft.com/azure/
[2] Hadoop. http://hadoop.apache.org.
[3] Agrawal, P., A. Silberstein, B. F. Cooper, U. Srivastava, and R. Ramakrishnan. "Asynchronous View Maintenance for VLSD Databases." In SIGMOD, 2009.
[4] Chang, F. et al. "Bigtable: A distributed storage system for structured data." In OSDI, 2006.
[5] Cooper, B. F., E. Baldeschwieler, R. Fonseca, J. J. Kistler, P. P. S. Narayan, Chuck Neerdaels, Toby Negrin, Raghu Ramakrishnan, Adam Silberstein, Utkarsh Srivastava, and Raymie Stata. "Building a cloud for Yahoo!" IEEE Data Engineering Bulletin, 32(1): 36-43, 2009.
[6] Cooper, B. F., R. Ramakrishnan, U. Srivastava, A. Silberstein, P. Bohannon, H.-A. Jacobsen, N. Puz, D. Weaver, and R. Yerneni. "PNUTS: Yahoo!'s hosted data serving platform." In VLDB, 2008.
[7] Dean, J. and S. Ghemawat. "MapReduce: Simplified data processing on large clusters." In OSDI, 2004.
[8] DeCandia, G. et al. "Dynamo: Amazon's highly available key-value store." In SOSP, 2007.
[9] Furman, J. J., J. S. Karlsson, J.-M. Leon, A. Lloyd, S. Newman, and P. Zeyliger. "Megastore: A Scalable Data System for User Facing Applications." In SIGMOD, 2008.
[10] Ghemawat, S., H. Gobioff, and S.-T. Leung. "The Google File System." In SOSP, 2003.
[11] Lakshman, A., P. Malik, and K. Ranganathan. "Cassandra: A Structured Storage System on a P2P Network." In SIGMOD, 2008.