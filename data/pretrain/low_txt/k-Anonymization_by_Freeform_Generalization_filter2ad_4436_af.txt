# k-Concealment and Other Anonymization Techniques

## 8.4 Effect of Dimensionality

Next, we investigate the impact of dimensionality on the performance of various anonymization techniques. We selected the first 10,000 tuples from the CENSUS dataset and examined the performance of our algorithms as a function of the number of selected attributes \( d \), with \( d \) ranging from 2 to 8, and \( k \) set to 30 and 50. The results are presented in Figure 9.

### Key Observations
- **Generalized Certainty Penalty (GCP):** Our three algorithms (k-concealment, Greedy, and SortGreedy) achieve better GCP than the competing NH and k−c methods. They also exhibit better resistance to the curse of dimensionality; the GCP does not deteriorate as severely as that of the other two methods as \( d \) increases.
- **Difference Quotient:** To highlight the effect of increasing dimensionality, we measured the difference quotient (i.e., the slope) of the GCP as a function of \( d \), calculated as \(\frac{GCP(d) - GCP(2)}{d - 2}\). The middle column in Figure 9 presents these results. Notably, k−c has the worst behavior with respect to growing dimensionality, followed by NH. Our three algorithms, especially SortGreedy and Hungarian, show much better robustness to dimensionality.
- **Runtime Performance:** The third column in Figure 9 shows the runtime results on a logarithmic scale. The runtime of our three methods falls between those of NH and k−c, but all algorithms scale well with increasing dimensionality.

## 8.5 Effect of Data Size

Finally, we examine the scalability of the compared algorithms as the dataset size grows. We used datasets of exponentially increasing size, ranging from 1,000 to 64,000 tuples, from the CENSUS dataset, with full dimensionality \( d = 8 \). The GCP and runtime results are presented in Figure 10 for \( k \) values set at 15 and 50, using logarithmic scales for both size and time axes.

### Key Observations
- **GCP Results:** Our methods consistently outperform NH and k−c, with SortGreedy approaching the performance of the Hungarian method. It is interesting to note that k−c achieves better GCP than NH for small \( k \), consistent with the results in Figure 8.
- **Runtime Results:** Our two greedy methods, Greedy and SortGreedy, are similarly scalable as k−c, as expected theoretically. While NH has the same quadratic complexity, its default version runs only on partitions of the dataset rather than the complete dataset. As seen in Section 8.1, our algorithms benefit from data partitioning and parallelism, providing an efficiency advantage.

## 9. Conclusions

This paper provides new insights into the k-anonymity privacy model, which remains a prerequisite for more advanced models and a useful tool in its own right. We treat k-anonymization as a network flow problem, aiming to minimize information loss due to value generalization. Previous works either imposed superfluous constraints or employed value suppression, compromising data utility. We devise solutions for the most general form of the problem, achieving significantly lower information loss. The problem is formulated as building a k-regular bipartite graph that defines an anonymization of high utility. We model an optimal solution using Mixed Integer Programming and develop a greedy algorithm with \( O(kn^2) \) time complexity, an enhanced \( O(kn^2 \log n) \) version, and an \( O(kn^3) \) solution based on the Hungarian algorithm. Our techniques provide the same privacy guarantee as previous research on k-anonymity and are secure against adversaries reverse-engineering the algorithm. Our experimental study shows that our algorithms achieve near-optimal utility and reliably outperform previous work, with their advantage increasing as data dimensionality grows. Additionally, our methods are more time-efficient in a parallel processing environment when the dataset is divided into partitions.

## Acknowledgments

We thank Wai Kit Wong and Arnon Mazza for sharing the codes for NH and k-concealment, respectively, and Aristides Gionis and Jonathan Eckstein for valuable discussions on this topic.

## References

[1] http://www.ipums.org.
[2] C. C. Aggarwal. On k-anonymity and the curse of dimensionality. In VLDB, 2005.
[3] R. K. Ahuja, T. L. Magnanti, and J. B. Orlin. Network Flows: Theory, Algorithms, and Applications. Prentice Hall, 1993.
[4] R. E. Bixby, M. Fenelon, Z. Gu, E. Rothberg, and R. Wunderling. Mixed-integer programming: A progress report. In M. Grötschel, editor, The Sharpest Cut, chapter 18, pages 309–325. 2004.
[5] J. Brickell and V. Shmatikov. The cost of privacy: destruction of data-mining utility in anonymized data publishing. In KDD, 2008.
[6] J. Cao and P. Karras. Publishing microdata with a robust privacy guarantee. PVLDB, 5(11):1388–1399, 2012.
[7] J. Cao, P. Karras, P. Kalnis, and K.-L. Tan. SABRE: a Sensitive Attribute Bucketization and REdistribution framework for t-closeness. The VLDB Journal, 20(1):59–81, 2011.
[8] R. Chaytor and K. Wang. Small domain randomization: Same privacy, more utility. PVLDB, 3(1):608–618, 2010.
[9] K. Choromanski, T. Jebara, and K. Tang. Adaptive anonymity via b-matching. In NIPS, pages 3192–3200, 2013.
[10] C. Clifton and T. Tassa. On syntactic anonymity and differential privacy. In PrivDB, 2013.
[11] G. Cormode, N. Li, T. Li, and D. Srivastava. Minimizing minimality and maximizing utility: Analyzing method-based attacks on anonymized data. PVLDB, 3(1):1045–1056, 2010.
[12] C. Dwork. Differential privacy. In ICALP (2), 2006.
[13] J. Edmonds and R. M. Karp. Theoretical improvements in algorithmic efficiency for network flow problems. J. of the ACM, 19(2):248–264, 1972.
[14] G. Ghinita, P. Karras, P. Kalnis, and N. Mamoulis. Fast data anonymization with low information loss. In VLDB, 2007.
[15] G. Ghinita, P. Karras, P. Kalnis, and N. Mamoulis. A framework for efficient data anonymization under privacy and accuracy constraints. ACM TODS, 34(2):1–47, 2009.
[16] A. Gionis, A. Mazza, and T. Tassa. k-anonymization revisited. In ICDE, 2008.
[17] A. Korolova. Privacy violations using microtargeted ads: A case study. In ICDM Workshops, 2010.
[18] H. W. Kuhn. The Hungarian method for the assignment problem. Naval Research Logistics Quarterly, 2(1–2):83–97, 1955.
[19] K. LeFevre, D. J. DeWitt, and R. Ramakrishnan. Workload-aware anonymization techniques for large-scale datasets. ACM TODS, 33(3):17:1–17:47, 2008.
[20] N. Li, T. Li, and S. Venkatasubramanian. Closeness: A new privacy measure for data publishing. IEEE TKDE, 22(7):943–956, 2010.
[21] N. Li, W. H. Qardaji, and D. Su. On sampling, anonymization, and differential privacy or, k-anonymization meets differential privacy. In ASIACCS, 2012.
[22] T. Li and N. Li. On the tradeoff between privacy and utility in data publishing. In KDD, 2009.
[23] A. Machanavajjhala, D. Kifer, J. Gehrke, and M. Venkitasubramaniam. l-diversity: Privacy beyond k-anonymity. ACM TKDD, 1(1):3, 2007.
[24] P. Samarati. Protecting respondents’ identities in microdata release. IEEE TKDE, 13(6):1010–1027, 2001.
[25] T. Tassa, A. Mazza, and A. Gionis. k-concealment: An alternative model of k-type anonymity. Transactions on Data Privacy, 5(1):189–222, 2012.
[26] N. Tomizawa. On some techniques useful for solution of transportation network problems. Networks, 1:173–194, 1971.
[27] R. Wacks. Privacy. A very short introduction, volume 221 of Very short introductions. Oxford University Press, 2010.
[28] W. K. Wong, N. Mamoulis, and D. W. L. Cheung. Non-homogeneous generalization in privacy preserving data publishing. In SIGMOD, 2010.
[29] M. Xue, P. Karras, C. Raïssi, J. Vaidya, and K.-L. Tan. Anonymizing set-valued data by nonreciprocal recoding. In KDD, 2012.