# Title: Detecting Malicious Web Pages Based on Structural Similarity of Redirection Chains

## Authors:
Toshiki Shibahara, Takeshi Yagi, Mitsuaki Akiyama, Yuta Takata, and Takeshi Yada  
NTT Secure Platform Laboratory  
3-9-11 Midori-cho, Musashino-shi, Tokyo, 180-8585 Japan  
{shibahara.toshiki, yagi.takeshi, akiyama.mitsuaki, takata.yuta, yada.takeshi}@lab.ntt.co.jp

## Abstract
Detecting malicious web pages used in drive-by download attacks and building blacklists and signatures from them are essential for protecting users. Gathering and evaluating the content of web pages can help detect malicious web pages. Supervised machine learning methods have been proposed for this purpose, but they require manual inspections to prepare training data, which is impractical for frequent retraining. In this paper, we propose a method that evaluates the maliciousness of web pages based on the structural similarity of redirection chains, using only the discrimination results from high-interaction honeyclients. Our experiments with two years of data show that our method achieves about 20% higher accuracy compared to previous methods.

## Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]: Security and Protection

## General Terms
Security

## Keywords
drive-by download, graph mining, retraining of classifiers

## 1. Introduction
Drive-by download attacks pose a significant threat, where users accessing compromised web pages are redirected to attackers' web pages. Blocking access to malicious web pages using blacklists is an effective countermeasure. However, attackers frequently change the domains of malicious web pages, necessitating the analysis of a large number of web pages to update blacklists.

Supervised machine learning methods have been applied to analyze web pages, but they require manual inspections to verify the maliciousness of the content. This makes it difficult to maintain accuracy as the content on malicious web pages changes. 

In this paper, we propose a method that automatically prepares training data using high-interaction honeyclients. The proposed method evaluates the maliciousness of web pages based on the structural similarity of redirection chains. This allows for continuous and accurate detection of malicious web pages, as the classifier can be retrained frequently without manual inspections.

The main contributions of this paper are:
- A method for detecting malicious web pages continuously and accurately without manual inspections.
- Enhanced detection rates of attacks by detecting malicious web pages from a large number of web pages.

## 2. Proposed Method
### 2.1 Structural Similarity of Redirection Chains
Redirections on web pages form tree structures with URLs as nodes and redirections as edges. The similarity of redirections is calculated based on the degree of correspondence between their subtrees. We focus on the paths of redirections from the first accessed URL to the last accessed URLs, as these are crucial for detecting drive-by download attacks.

To extract subtrees, we first gather sequences of labels in redirection paths. Then, we extract subsequences and remove duplicates. These subsequences are used as subtrees. The similarity function \( S \) for redirection chains \( R_i \) and \( R_j \) is defined as:

\[
S(R_i, R_j) = \frac{|R_i \cap R_j|}{|R_i \cup R_j|}
\]

where \( |R| \) is the number of subtrees, \( R_i \cap R_j \) is the intersection of \( R_i \) and \( R_j \), and \( R_i \cup R_j \) is the union of \( R_i \) and \( R_j \).

### 2.2 Feature Vectors
Training data is split into clusters of similar redirection chains. If the maximum similarity between a redirection chain \( R \) and any cluster \( C \) exceeds a threshold \( s_t \), \( R \) is added to \( C \). The template of each cluster is the maximum common subtree of its redirection chains. The feature vector of a redirection chain \( r \) is an \( n \)-dimensional vector, where \( n \) is the number of clusters. Each component of the feature vector is the similarity between \( r \) and the templates of the clusters. We use SVM with the RBF kernel for classification.

## 3. Experiment
We prepared the training data using information from high-interaction honeyclients. We implemented the proposed method and Prophiler, comparing their detection performance and investigating the necessity of retraining. The time periods and the number of data points are shown in Table 1.

| Category       | Training Data | Test Data   |
|----------------|---------------|-------------|
| Label          | Malicious     | Benign      |
| Time Period    | Jul. 2012 – Dec. 2012 | Jan. 2013 – Dec. 2014 |
| Number         | 693           | 1,540       |
|                | 1,033         | 2,578       |

Accuracy, recall, and precision were measured every three months. The proposed method generally outperformed Prophiler, but retraining the classifier is essential for maintaining high accuracy.

## 4. Discussion
The proposed method can maintain high accuracy if the classifier is retrained at regular intervals using automatically prepared training data. Misclassifications occur when benign pages have similar redirection patterns to malicious ones. Future work will include developing methods to use the content of web pages to improve classification.

## 5. Related Work
### 5.1 Evaluation of Maliciousness
Methods such as ZOZZLE, Revolver, and Prophiler extract features from various perspectives and apply machine learning to evaluate maliciousness. SpiderWeb focuses on the length of redirections but is costly for large-scale evaluation. 

### 5.2 Classification of Structural Data
Graph mining research proposes methods to classify structural data using tree kernels, which measure the degree of correspondence between subtrees. These methods are computationally expensive for large datasets.

## 6. Conclusion
We proposed a method that classifies web pages based on the structural similarity of redirection chains. The method can maintain high accuracy through regular retraining using automatically prepared training data, enabling continuous and accurate detection of malicious web pages.

## 7. References
[1] M. Akiyama et al. Design and implementation of high interaction client honeypot for drive-by-download attacks. IEICE Transactions on Communications, 93(5):1131–1139, 2010.  
[2] D. Canali, et al. Prophiler: a fast filter for the large-scale detection of malicious web pages. In Proceedings of the 20th International Conference on World Wide Web, pages 197–206, 2011.  
[3] C. Curtsinger et al. Zozzle: Fast and precise in-browser JavaScript malware detection. In USENIX Security Symposium, pages 33–48, 2011.  
[4] T. Gärtner. A survey of kernels for structured data. ACM SIGKDD Explorations Newsletter, 5(1):49–58, 2003.  
[5] C. Grier et al. Manufacturing compromise: the emergence of exploit-as-a-service. In Proceedings of the 2012 ACM conference on Computer and communications security, pages 821–832, 2012.  
[6] A. Kapravelos et al. Revolver: An automated approach to the detection of evasive web-based malware. In USENIX Security Symposium, pages 637–652, 2013.  
[7] G. Stringhini et al. Shady Paths: Leveraging surfing crowds to detect malicious web pages. In Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security, pages 133–144, 2013.