### Enriching Ground Truth and Ensuring Accuracy

In our final experiment, we evaluate the prediction accuracy of RiskTeller on a per-enterprise basis. As previously mentioned, our dataset includes data from 18 different enterprises. Prior to initiating the classification experiments for each enterprise, we analyzed the ground truth details. Figure 6 illustrates that the ground truths can be highly imbalanced (e.g., 13,000 risky and 1,600 clean profiles) or very small in size (e.g., 23 risky and 60 clean profiles). 

As expected, the basic random forest classifier performs poorly in these scenarios, achieving an average True Positive Rate (TPR) of 45% with a False Positive Rate (FPR) of 5%. The semi-supervised learning (SSL) classifier yields better results, with an average TPR of 61% and an FPR of 5%. However, these results are still not as good as those obtained when combining data from multiple enterprises.

**Figure 6: Ground Truth Size per Enterprise**

### Discussion

When applying machine learning (ML) in the security domain, one common concern is evasion, i.e., the possibility that malicious actors will modify their behavior to avoid detection by the ML system. In the case of RiskTeller, this issue does not apply because it uses features observed during benign usage to predict the risk of future infections. Since the features are collected before any attacks occur, evasion is not a relevant concern.

Another typical issue in ML and security is concept drift, where the statistical properties of the variables that the ML models rely on change over time, rendering the models less effective. For example, a malware detection system may lose effectiveness as new malware families emerge. Unlike systems that characterize attacks, RiskTeller models the likely victims of cyber-attacks. Our results, as shown in Figure 3, indicate that RiskTeller's predictions remain stable over 6-month labeling periods, suggesting that the characteristics of typical cyber-attack victims change slowly over time. To address longer-term concept drift, our model can be re-trained periodically.

Since we do not have data on the direct causes of attacks, we cannot use our system to infer causality. However, the correlations we observe can help us understand the factors that increase the risk of attack. Section 4.2 provides a clear picture of machines at risk of becoming infected: those with few or no security updates and unusual usage patterns, such as irregular temporal activity and the installation of uncommon binaries. It is intuitive to see why such machines are at higher risk.

Our results show that RiskTeller can predict infections with varying precision depending on the dataset. The prediction quality is higher than typical values in the insurance context, where prediction is a challenging problem due to human factors and external events that are not observable in a model. For example, in bankruptcy prediction, the ROC curves in the works by [7] and [28] show that even less precise predictions can still be useful for quantifying risk and pricing insurance. We consider RiskTeller valuable for identifying at-risk machines and guiding proactive hardening efforts in enterprises. Machine risk levels can be used independently or aggregated by organizations (e.g., departments) and job roles, driving efforts to harden systems or educate users, ensuring that more effort is spent where it is most needed. It is important to note that false positives in our system would result in unnecessary hardening, which, while not ideal, is less severe than false positives in malware detection, where legitimate software might be incorrectly flagged as malicious, potentially making applications or machines unusable.

### Related Work

In the field of computer security, a significant amount of research has focused on detecting ongoing attacks or distinguishing malware from legitimate software. By comparison, the body of work on predicting future attacks and infections is smaller. In 1998, Korzyk [14] attempted to predict the growth in the number of vulnerability advisories using time series analysis. Other works, such as those by Jones et al. [13] and Axelrod and Iliev [1], use game theory to predict the behavior of attackers and defenders. These approaches are more suitable for high-stakes interactions between a few rational players and do not provide much insight into the broader context of Internet security, where billions of machines are susceptible to attack.

The IARPA CAUSE project [12] is a recent effort to use large amounts of Internet data and machine learning to find fingerprints (e.g., system probing) that predict future attacks. Unlike this project, our work focuses on the behavior of potential victims rather than attackers.

More closely related to our approach, six works analyze user and system data to estimate the risk of cyber incidents:
- Lalonde Levesque et al. [16] analyze a small set of 50 users' demographics and web browsing features to evaluate risk factors.
- Canali et al. [4] associate users with their risk through information about their web browsing logs.
- Soska and Christin [30] collect features about websites to predict which ones will become malicious.
- Yen et al. [38] analyze user demographics and behavioral features in a single large corporation to compute risk factors.
- Liu et al. [19] predict cybersecurity incidents within organizations by analyzing externally measurable features.
- Veeramachanent et al. [37] analyze historical incident records of enterprises to predict cyber incidents using deep learning methods.

These approaches provide informative predictions, but none achieve perfect accuracy. For example, Soska and Christin obtain 66% true positives (TPs) with 17% false positives (FPs), Canali et al. achieve 74% TPs with 8% FPs, and Liu et al. have 90% TPs with 10% FPs. Veeramachanent et al. achieve 86.8% FPs with 4.4% TPs after being boosted with feedback from security analysts. While these studies predict different types of incidents, they provide context showing that predicting incidents is a difficult problem. RiskTeller's TP/FP rates are generally better than those observed in similar studies. Additionally, the studies by Liu et al. and Veeramachanent et al. are less granular and predict attacks only at the organizational level, whereas our approach provides more granular information, enabling administrators to highlight the most at-risk components of their infrastructure.

Semi-supervised learning has been used in the security context by Han and Shen [9] to classify email-based spear-phishing campaigns. In this domain, ground truth datasets are created by human analysts, requiring extensive effort. Han and Shen propose using semi-supervised learning to reduce the labeling overhead. In our work, we use semi-supervised learning to verify the completeness of our ground truth and enrich it when it is limited or imbalanced.

### Conclusion

In an era where cyber incidents are increasingly unavoidable, cyber defenders are shifting their focus from reactive to proactive security. Enterprises and individuals are also purchasing more cyber insurance packages to mitigate losses when incidents occur. A crucial task in both proactive security and cyber insurance is to estimate and predict risk in advance. If effective risk prediction methods exist, malware defense solutions can incorporate this information to harden the systems of at-risk machines, making it harder for attackers to compromise them. Cyber insurance schemes can also benefit from risk estimates to price their offers more efficiently.

In this work, we addressed this gap in the cyber ecosystem by proposing RiskTeller, a system that can predict at-risk machines in enterprises with high accuracy. To date, no previous work has achieved a 96% TPR with only a 5% FPR for such predictions at a machine-level granularity.

Despite RiskTeller's capabilities, there is still much to explore in the area of prediction for cybersecurity. Currently, RiskTeller predicts that a machine is at risk from malware without providing specific hints about malware categories. In future work, we plan to extend our system to predict the risk of different machine profiles for threat types such as banking trojans, advanced threats, data breaches, and ransomware. This will require community efforts in automated threat categorization on large-scale data. Another line of research we wish to explore is risk prediction for individual users, whose usage behavior is less regular compared to enterprise users. We plan to explore new techniques and evaluate other datasets to better capture these users' behavior and improve prediction accuracy.

### References

[1] Robert Axelrod and Rumen Iliev. 2014. Timing of cyber conflict. Proceedings of the National Academy of Sciences 111, 4 (2014), 1298–1303.

[2] Oleg Bogomolniy. 2017. Cyber Insurance Conundrum: Using CIS Critical Security Controls for Underwriting Cyber Risk. https://www.sans.org/reading-room/whitepapers/legal/cyber-insurance-conundrum-cis-critical-security-controls-underwriting-cyber-risk-37572. (2017).

[3] Leo Breiman. 2001. Random Forests. Machine Learning 45, 1 (2001), 5–32.

[4] Davide Canali, Leyla Bilge, and Davide Balzarotti. 2014. On the effectiveness of risk prediction based on users browsing behavior. In Proceedings of the 9th ACM symposium on Information, computer and communications security. ACM, 171–182.

[5] Duen Horng Chau, Carey Nachenberg, Jeffrey Wilhelm, Adam Wright, and Christos Faloutsos. 2011. Polonium: Tera-Scale Graph Mining and Inference for Malware Detection. In SIAM International Conference on Data Mining (SDM) 2011, Vol. 25. 131–142.

[6] Lucian Constantin. 2011. MSE false positive detection forces Google to update Chrome. The Inquirer, http://www.theinquirer.net/inquirer/news/2113892/mse-false-positive-detection-forces-google-update-chrome. (October 2011).

[7] J David Cummins, Martin F Grace, and Richard D Phillips. 1999. Regulatory solvency prediction in property-liability insurance: Risk-based capital, audit ratios, and cash flow simulation. Journal of Risk and Insurance (1999), 417–458.

[8] Experian. 2015. Data Breach Industry Forecast. https://www.experian.com/assets/data-breach/white-papers/2015-industry-forecast-experian.pdf. (2015).

[9] Yufei Han and Yun Shen. 2016. Accurate Spear Phishing Campaign Attribution and Early Detection. In Proceedings of the 31st ACM Symposium on Applied Computing.

[10] G. R. Hileman, S. M. Mehmud, and M. A. Rosenberg. 2016. Risk Scoring in Health Insurance. https://www.soa.org/Files/Research/research-2016-risk-scoring-health-insurance.pdf. (2016).

[11] Tin Kam Ho. 1995. Random Decision Forest. In Proceedings of the 3rd International Conference on Document Analysis and Recognition. 278–282.

[12] IARPA. 2015. Cyber-attack Automated Unconventional Sensor Environment (CAUSE). https://www.iarpa.gov/index.php/research-programs/cause. (2015).

[13] Malachi Jones, Georgios Kotsalis, and Jeff S Shamma. 2013. Cyber-attack forecast modeling and complexity reduction using a game-theoretic framework. In Control of Cyber-Physical Systems. Springer, 65–84.

[14] Alexander D. Korzyk, Sr. 1998. A forecasting model for internet security attacks. In National Information System Security Conference.

[15] Aorato Labs. 2014. The Untold Story of the Target Attack Step by Step. https://aroundcyber.files.wordpress.com/2014/09/aorato-target-report.pdf. (September 2014).

[16] Fanny Lalonde Levesque, Jude Nsiempba, José M Fernandez, Sonia Chiasson, and Anil Somayaji. 2013. A clinical study of risk factors related to malware infections. In Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security. ACM, 97–108.

[17] John Leyden. 2010. Horror AVG update ballsup bricks Windows 7. The Register, http://www.theregister.co.uk/2010/12/02/avgautoimmuneupdate/. (December 2010).

[18] Andy Liaw and Matthew Wiener. 2002. Classification and regression by randomForest. R news 2, 3 (2002), 18–22.

[19] Yang Liu, Armin Sarabi, Jing Zhang, Parinaz Naghizadeh, Manish Karir, Michael Bailey, and Mingyan Liu. 2015. Cloudy with a chance of breach: Forecasting cyber security incidents. In 24th USENIX Security Symposium (USENIX Security 15). 1009–1024.

[20] Declan McCullough. 2010. Buggy McAfee update whacks Windows XP PCs. CNET, http://www.cnet.com/news/buggy-mcafee-update-whacks-windows-xp-pcs/. (April 2010).

[21] Yuxin Meng, Wenjuan Li, and Lam-For Kwok. 2014. Enhancing email classification using data reduction and disagreement-based semi-supervised learning. In Proceedings of IEEE International Conference on Communications 2014. 622–627.

[22] Antonio Nappa, Richard Johnson, Leyla Bilge, Juan Caballero, and Tudor Dumitraş. 2015. The attack of the clones: a study of the impact of shared code on vulnerability patching. In Security and Privacy (SP), 2015 IEEE Symposium on. IEEE, 692–708.

[23] Kartik Nayak, Daniel Marino, Petros Efstathopoulos, and Tudor Dumitraş. 2014. Some vulnerabilities are different than others. In Research in Attacks, Intrusions and Defenses. Springer International Publishing, 426–446.

[24] M. Ovelgonne, T. Dumitras, A. Prakash, V.S. Subrahmanian, and B. Wang. 2016. Understanding the Relationship between Human Behavior and Susceptibility to CyberAttacks: A Data-Driven Approach. In ACM Transactions on Intelligent Systems and Technology.

[25] Clifton Phua, Vincent C. S. Lee, Kate Smith-Miles, and Ross W. Gayler. 2010. A Comprehensive Survey of Data Mining-based Fraud Detection Research. Computing Research Repository abs/1009.6119 (2010).

[26] Emil Protalinski. 2008. AVG incorrectly flags user32.dll in Windows XP SP2/SP3. Ars Technica, http://arstechnica.com/information-technology/2008/11/avg-incorrectly-flags-user32-dll-in-windows-xp-sp2sp3/. (November 2008).

[27] PWC. 2016. Insurance 2020 and beyond: Reaping the dividends of cyber resilience. http://www.pwc.com/gx/en/insurance/publications/assets/reaping-dividends-cyber-resilience.pdf. (2016).

[28] Alexander S Reisz and Claudia Perlich. 2007. A market-based framework for bankruptcy prediction. Journal of Financial Stability 3, 2 (2007), 85–131.

[29] Igor Santos, Javier Nieves, and Pablo G. Bringas. 2011. Semi-supervised Learning for Unknown Malware Detection. In Proceedings of International Symposium on Distributed Computing and Artificial Intelligence 2011. 415–422.

[30] Kyle Soska and Nicolas Christin. 2014. Automatically detecting vulnerable websites before they turn malicious. In 23rd USENIX Security Symposium (USENIX Security 14). 625–640.

[31] Amarnag Subramanya and Jeff Bilmes. 2011. Semi-supervised learning with measure propagation. Journal of Machine Learning Research 12 (2011), 3311–3370.

[32] Symantec. 2016. Internet Security Threat Report Vol. 21. https://www.symantec.com/security-center/threat-report. (April 2016).

[33] Christopher T. Symons and Justin M. Beaver. 2012. Nonparametric Semi-supervised Learning for Network Intrusion Detection: Combining Performance Improvements with Realistic In-situ Training. In Proceedings of the 5th ACM Workshop on Security and Artificial Intelligence (AISec). ACM, New York, NY, USA, 49–58.

[34] Acar Tamersoy, Kevin Roundy, and Duen Horng Chau. 2014. Guilt by association: large scale malware detection by mining file-relation graphs. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge Discovery and Data Mining. ACM, 1524–1533.

[35] Aaron Tan. 2007. Flawed Symantec update cripples Chinese PCs. CNET, http://www.cnet.com/news/flawed-symantec-update-cripples-chinese-pcs/. (May 2007).

[36] Olivier Thonnard, Leyla Bilge, Anand Kashyap, and Martin Lee. 2015. Are you at risk? Profiling organizations and individuals subject to targeted attacks. In Financial Cryptography and Data Security. Springer Berlin Heidelberg, 13–31.

[37] Kalyan Veeramachanent, Ignacio Arnaldo, Alfredo Cuesta-Infante, Korrapati Vamsi, Costa Bassias, and Li Ke. 2016. AI2: Training a big data machine to defend. In Proceedings of the 2nd IEEE International Conference on Big Data Security.

[38] Ting-Fang Yen, Victor Heorhiadi, Alina Oprea, Michael K Reiter, and Ari Juels. 2014. An epidemiological study of malware encounters in a large enterprise. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 1117–1130.