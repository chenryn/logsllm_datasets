### Simplified Message Delivery and Information Flow Control

The process of message delivery is significantly simplified in the abstract firewall, as it inherently knows the sender of a message. This allows the firewall to permit messages from senders \( S \) and \( G \), while blocking those from \( B \). Consequently, no information can flow directly from \( B \) to \( C \) in this ideal structure.

### Correct Output Probability and Distinguisher Definition

Assume that \( C \) outputs the bit \( b \) correctly with a probability of at least \( 1 - 2^{-ns(k)} \) for some \( ns \notin \text{SMALL} \). The only possible cut in this scenario is \( \hat{C} := \{S, G\} \). We define a distinguisher for the abstract structure as follows:

Given the view of \( S \) and \( G \) in a run and the random tape of \( C \), the distinguisher simulates the behavior of \( C \) by using \( C \)'s input information, which must come from \( S \) or \( G \) (since no information can flow directly from \( B \) to \( C \)), and the content of \( C \)'s random tape. More precisely, the machine \( D \) proceeds through the joint view of \( S \) and \( G \). For each output directed to \( C \), it calls the state transition function \( \phi_C \) of \( C \) with the current position on the random tape. If \( \phi_C \) outputs a bit \( b \) at port \( p^*_C \), the distinguisher outputs this bit as its own guess. Otherwise, it updates the position on the random tape of the simulated machine \( C \) to the first unused position and continues processing the view.

It is clear that the distinguisher accurately simulates the behavior of \( C \), as every input to \( C \) must have come from \( S \) or \( G \).

### Preservation Theorem and Concrete Implementation

Using the preservation theorem (Theorem 5.1), this property carries over to the concrete implementation, which uses cryptographic primitives and accounts for error probabilities, without any additional work.

**Remark:** The construction of \( D \) is straightforward because direct information flow from \( B \) to \( C \) is completely prohibited, not just up to a negligible error probability. If we had performed this proof for the real system, we would have had to account for certain runs where direct flow occurred, such as when \( B \) successfully forged a signature of \( S \) or \( G \). These runs cannot be properly simulated by the distinguisher, as it lacks the incoming information of \( C \) in these cases. One approach to handle this is to collect these runs in so-called error sets and show that their aggregated probability is still negligible, or that the underlying cryptography could be broken. Although this technique is common in simulatability proofs (e.g., see [21]), we avoid it when proving non-interference for specific applications. Thus, our preservation theorem is very useful.

### Related Literature

The concept of non-interference for transitive policies was initiated by the deterministic definition of Goguen and Meseguer [5] and has been extended by many articles, including definitions for possibilistic and non-deterministic systems [27, 15, 9, 29, 19, 16, 31, 4, 13].

Although probabilistic non-interference was introduced in 1992 by Gray [7], probabilistic information flow was overlooked for some time. However, the development of cryptography has renewed interest in understanding information flow in cryptographic contexts. Laud [11] defined real computational secrecy for a sequential language but only covered encryption, excluding other important concepts like authentication and pseudo-random number generators. Moreover, the definition is non-reactive, not accounting for continuous interaction between the user, the adversary, and the system, which limits its applicability to cryptographic systems.

Volpano [28] investigated conditions for safe use of one-way functions in programming languages but did not address non-interference, focusing instead on the secrecy of a specific secret. Abadi and Blanchet [1] introduced type systems for asymmetric communication primitives, particularly public-key encryption, but these were relative to a Dolev-Yao abstraction [3], which idealizes the primitives, eliminating the need for a computational non-interference definition. For a discussion on why the Dolev-Yao abstraction is not justified by current cryptography, see [20].

Recently, we introduced the notion of computational probabilistic non-interference [2], which is based on a fully reactive setting, includes error probabilities and computational restrictions, and allows for analyzing information flow for general cryptographic primitives. However, this definition, like previous ones, was designed specifically for transitive information flow policies.

For intransitive policies, no prior work exists for a probabilistic definition of flow, to the best of our knowledge. For deterministic systems, Goguen and Meseguer proposed a definition of intransitive information flow based on an "unless" construct [6], which extends their original definition for transitive flow policies. However, this construct did not meet intuitive requirements for intransitive flow, accepting many intuitively insecure systems as secure. The first satisfactory formal definition of intransitive flow was proposed by Rushby [24], followed by Pinsky [22] and recently by Roscoe and Goldsmith [23]. Rushby's approach is the most popular for deterministic systems, as case studies have shown its feasibility for real applications [25]. Mantel [14] presented a new approach for intransitive flow suitable for non-deterministic systems, but these definitions are not suited for capturing probabilistic behaviors, especially in cryptographic applications. Our definitions address this by capturing intransitive non-interference for systems involving arbitrary cryptographic primitives.

Finally, we briefly address downgrading of information, a common application of intransitive flow. Many definitions are overly restrictive, preventing useful systems from being built. This led to the approach of downgrading certain information so that it may subsequently leak from the system [18, 32]. The amount of leaked information can sometimes be rigorously defined using information-theoretic techniques [17, 10]. As prior approaches of downgrading are specific to non-probabilistic systems, our definition is the first to capture downgrading for probabilistic information flow.

### Conclusion

Despite recent interest in linking information flow and probabilism, no probabilistic formalism existed to capture intransitive flow policies, creating a gap between information flow and cryptographic applications. In this article, we bridge this gap by proposing definitions for intransitive flow for probabilistic systems, including blocking non-interference, recognition non-interference, and the weaker recognition non-interference for trusted recipients. We also define downgrading, ensuring that our definitions can be fulfilled by cryptographic primitives by capturing error probabilities, computational restrictions, and fully reactive systems.

In situations involving multiple third parties in intransitive flow, we consider how cuts in the flow graph block the flow or join their knowledge to detect information flow. This highlights a major difference between probabilistic and non-probabilistic approaches, showing why the notion of probabilistic information flow is more fine-grained.

We have shown that intransitive non-interference properties proved for abstract specifications carry over to concrete implementations without further work, provided the implementations are correct according to modern cryptographic simulatability definitions.

### Acknowledgments

We thank Heiko Mantel and Michael Waidner for helpful discussions.

### References

[1] M. Abadi and B. Blanchet. Secrecy types for asymmetric communication. In Proc. 4th International Conference on Foundations of Software Science and Computation Structures (FOSSACS), volume 2030 of Lecture Notes in Computer Science, pages 25–41. Springer, 2001.

[2] M. Backes and B. Pfitzmann. Computational probabilistic non-interference. In Proc. 7th European Symposium on Research in Computer Security (ESORICS), volume 2502 of Lecture Notes in Computer Science, pages 1–23. Springer, 2002.

[3] D. Dolev and A. C. Yao. On the security of public key protocols. IEEE Transactions on Information Theory, 29(2):198–208, 1983.

[4] R. Focardi and F. Martinelli. A uniform approach to the definition of security properties. In Proc. 8th Symposium on Formal Methods Europe (FME 1999), volume 1708 of Lecture Notes in Computer Science, pages 794–813. Springer, 1999.

[5] J. A. Goguen and J. Meseguer. Security policies and security models. In Proc. 3rd IEEE Symposium on Security & Privacy, pages 11–20, 1982.

[6] J. A. Goguen and J. Meseguer. Unwinding and inference control. In Proc. 5th IEEE Symposium on Security & Privacy, pages 75–86, 1984.

[7] J. W. Gray III. Toward a mathematical foundation for information flow security. Journal of Computer Security, 1(3):255–295, 1992.

[8] C. A. R. Hoare. Communicating Sequential Processes. International Series in Computer Science, Prentice Hall, Hemel Hempstead, 1985.

[9] D. M. Johnson and F. Javier Thayer. Security and the composition of machines. In Proc. 1st IEEE Computer Security Foundations Workshop (CSFW), pages 72–89, 1988.

[10] M. H. Kang, I. S. Moskowitz, and D. C. Lee. A network version of the pump. In Proc. 16th IEEE Symposium on Security & Privacy, pages 144–154, 1995.

[11] P. Laud. Semantics and program analysis of computationally secure information flow. In Proc. 10th European Symposium on Programming (ESOP), pages 77–91, 2001.

[12] N. Lynch. Distributed Algorithms. Morgan Kaufmann Publishers, San Francisco, 1996.

[13] H. Mantel. Unwinding possibilistic security properties. In Proc. 6th European Symposium on Research in Computer Security (ESORICS), volume 1895 of Lecture Notes in Computer Science, pages 238–254. Springer, 2000.

[14] H. Mantel. Information flow control and applications – bridging a gap. In Proc. 10th Symposium on Formal Methods Europe (FME 2001), volume 2021 of Lecture Notes in Computer Science, pages 153–172. Springer, 2001.

[15] D. McCullough. Specifications for multi-level security and a hook-up property. In Proc. 8th IEEE Symposium on Security & Privacy, pages 161–166, 1987.

[16] J. McLean. Security models. Chapter in Encyclopedia of Software Engineering, 1994.

[17] J. K. Millen. Covert channel capacity. In Proc. 8th IEEE Symposium on Security & Privacy, pages 60–66, 1987.

[18] A. Myers and B. Liskov. Protecting privacy using the decentralized label model. ACM Transactions on Software Engineering and Methodology, pages 410–442, 2000.

[19] C. O’Halloran. A calculus of information flow. In Proc. 1st European Symposium on Research in Computer Security (ESORICS), pages 147–159, 1990.

[20] B. Pfitzmann and M. Waidner. Composition and integrity preservation of secure reactive systems. In Proc. 7th ACM Conference on Computer and Communications Security, pages 245–254, 2000.

[21] B. Pfitzmann and M. Waidner. A model for asynchronous reactive systems and its application to secure message transmission. In Proc. 22nd IEEE Symposium on Security & Privacy, pages 184–200, 2001.

[22] S. Pinsky. Absorbing covers and intransitive non-interference. In Proc. 16th IEEE Symposium on Security & Privacy, pages 102–113, 1995.

[23] A. Roscoe and M. Goldsmith. What is intransitive non-interference? In Proc. 12th IEEE Computer Security Foundations Workshop (CSFW), pages 226–238, 1999.

[24] J. Rushby. Noninterference, transitivity, and channel-control security. Technical report, Computer Science Laboratory, SRI International, 1992.

[25] G. Schellhorn, W. Reif, A. Schairer, P. Karger, V. Autexier, and D. Toll. Verification of a formal security model for multiapplicative smart cards. In Proc. 6th European Symposium on Research in Computer Security (ESORICS), volume 1895 of Lecture Notes in Computer Science, pages 17–36. Springer, 2000.

[26] A. Shamir. How to share a secret. Communications of the ACM, 22(11):612–613, Nov. 1979.

[27] D. Sutherland. A model of information. In Proc. 9th National Computer Security Conference, pages 175–183, 1986.

[28] D. Volpano. Secure introduction of one-way functions. In Proc. 13th IEEE Computer Security Foundations Workshop (CSFW), pages 246–254, 2000.

[29] J. T. Wittbold and D. M. Johnson. Information flow in nondeterministic systems. In Proc. 11th IEEE Symposium on Security & Privacy, pages 144–161, 1990.

[30] A. C. Yao. Protocols for secure computations. In Proc. 23rd IEEE Symposium on Foundations of Computer Science (FOCS), pages 160–164, 1982.

[31] A. Zakinthinos and E. S. Lee. A general theory of security properties. In Proc. 18th IEEE Symposium on Security & Privacy, pages 94–102, 1997.

[32] S. Zdancewic and A. C. Myers. Robust declassification. In Proc. 14th IEEE Computer Security Foundations Workshop (CSFW), pages 15–23, 2001.