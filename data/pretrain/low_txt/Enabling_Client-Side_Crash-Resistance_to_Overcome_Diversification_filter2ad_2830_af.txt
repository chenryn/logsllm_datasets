### Crash-Resistant Code Paths and Their Exploitation

Crash-resistant code paths can be manipulated by an attacker without the need for control-flow hijacking [54].

### Design Choices, Countermeasures, and Defenses

Several strategies can be employed to mitigate crash-resistance. Individual instances of crash-resistance are often fixable. For example, in Internet Explorer, no legitimate use cases for crash-resistance were identified. After collaborating with Microsoft, it was determined that this issue is security-relevant and affects versions 7 through 11 of Internet Explorer and the Microsoft Edge Browser (see CVE-2015-6161). The issue was resolved for Microsoft Edge during the December 2015 Patch Tuesday, and hardening settings for Internet Explorer were made available [32]. Historically, some vulnerabilities have allowed attackers to survive crashes, enabling them to bypass ASLR or increase the likelihood of successful exploits [25, 52]. Therefore, Microsoft's Security Development Lifecycle (SDL) recommends avoiding global exception handlers that can catch all violations [29]. It is important to note that while individual buffer overflow vulnerabilities can be fixed, the broader class of buffer overflows remains challenging to eliminate entirely. Similarly, constructing a memory oracle on any modern system that allows applications to handle faults is feasible.

#### 1. Crash Policies
A general countermeasure is to limit the number of faults an attacker can cause. This forces the attacker to reduce probing attempts and hit the correct location early. However, this approach is probabilistic, as there is still a small chance that the first probe could succeed. Additionally, a strict crash policy may interfere with legitimate use cases where exceptions are expected. For instance, Firefox uses exceptions for fast array accesses to avoid bounds checking. An out-of-bounds read is caught by the exception handler and returns a default value (undefined). Removing exception support would decrease performance, as additional bound checks for every array access would be required.

#### 2. Accurate Exception Information Checking
The most effective countermeasure against crash-resistance is to accurately check the exception information of triggered faults. In Internet Explorer, the exceptions used for crash-resistance can be exploited as side-channels. Exception handlers should only catch faults that are expected in guarded code. Therefore, the exception type and the address of the instruction causing the fault should be carefully inspected to ensure that only intended faults are caught. Additionally, it is crucial to prevent guarded code from throwing other exceptions. While it may be difficult to handle all faults accurately, unintended faults should always be forwarded unhandled, allowing the operating system to safely terminate the program and prevent crash-resistance. Firefox’s fault handler performs rigorous checks on the data provided by the OS, including the address of the faulty instruction, the error code, and the exception type. To exploit this, we had to modify metadata in the process to trick the checks before triggering a fault.

Exception handling differs between Windows and Linux. Linux can differentiate between faults due to unmapped memory and those due to incorrect permissions. Firefox's asm.js functionality utilizes this distinction to prevent crash-resistance. In Firefox 39, a check was added to the asm.js exception handling to handle only permission errors, not unmapped memory. This fix, though not flagged as a security issue, unintentionally eliminated a security vulnerability. However, crash-resistance within asm.js persists in the Windows version of Firefox.

#### 3. Using Guard Pages to Prevent Probing
In our tests with Firefox on Windows, we found that accesses to guard pages around the stack were not crash-resistant. Guard pages typically prevent stack overflows. Accessing a guard page resulted in a different error code than accessing a heap guard region, which the asm.js handler did not manage. By placing guard pages around critical structures, scanning attempts can be detected, and the program can be terminated immediately upon detecting an illegal access. The difference in exception codes helps distinguish intended faults from those caused by an attacker. However, in Internet Explorer, any fault is handled, allowing complete crash-resistant memory scanning, even when probing an unmapped page.

#### 4. Defenses Against Crash-Resistance
Softbound [34] and CETS [35] are memory corruption defenses and memory safety solutions for C programs. Softbound provides spatial safety, while CETS prevents temporal bugs. These defenses eliminate memory corruptions, making our current approach to crash-resistance infeasible in C programs. However, most parts of Firefox and Internet Explorer are written in C++, which these tools do not support.

### Conclusion

In this paper, we demonstrated that even client applications like web browsers can be resistant to crashes. We showed that an adversary can safely query the address space, which is normally not legitimate and should lead to program termination. Our approach does not rely on control-flow hijacking, code injection, or code-reuse attacks. We introduced the concept of crash-resistance and developed memory oracles, enabling adversaries to use fault-tolerant functionality as a side channel to obtain information about the memory layout. We also introduced Crash-Resistant Oriented Programming (CROP), which leverages crash-resistance to execute function chains in a fault-tolerant manner. As a result, recently proposed information hiding and randomization defenses are weakened, and control-flow hijacking and code-reuse attacks can be re-enabled.

### Acknowledgment

This work was partially supported by ERC Starting Grant No. 640110 (BASTION).

### References

[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-Flow Integrity. In ACM Conference on Computer and Communications Security (CCS), 2005.
[2] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. Nurnberger, and J. Pewny. You can run but you can’t read: Preventing disclosure exploits in executable code. In ACM Conference on Computer and Communications Security (CCS), 2014.
[3] M. Backes and S. Nurnberger. Oxymoron: Making fine-grained memory randomization practical by allowing code sharing. In USENIX Security Symposium, 2014.
[4] S. Bhatkar, D. C. DuVarney, and R. Sekar. Address Obfuscation: An Efficient Approach to Combat a Broad Range of Memory Error Exploits. In USENIX Security Symposium, 2003.
[5] S. Bhatkar, D. C. DuVarney, and R. Sekar. Efficient techniques for comprehensive protection from memory error exploits. In USENIX Security Symposium, 2005.
[6] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazieres, and D. Boneh. Hacking blind. In IEEE Symposium on Security and Privacy, 2014.
[7] T. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang. Jump-oriented Programming: A New Class of Code-reuse Attack. In ASIACCS, 2011.
[8] E. Bosman and H. Bos. Framing signals-a return to portable shellcode. In IEEE Symposium on Security and Privacy, 2014.
[9] N. Carlini, A. Barresi, M. Payer, D. Wagner, and T. R. Gross. Control-flow bending: On the effectiveness of control-flow integrity. In USENIX Security Symposium, 2015.
[10] N. Carlini and D. Wagner. ROP is still dangerous: Breaking modern defenses. In USENIX Security Symposium, 2014.
[11] D. Chappell. Understanding ActiveX and OLE: a guide for developers and managers. Microsoft Press, 1996.
[12] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham, and M. Winandy. Return-oriented programming without returns. In ACM Conference on Computer and Communications Security (CCS), 2010.
[13] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R. Sadeghi, S. Brunthaler, and M. Franz. Readactor: Practical code randomization resilient to memory disclosure. In IEEE Symposium on Security and Privacy, 2015.
[14] S. Crane, S. Volckaert, F. Schuster, C. Liebchen, P. Larsen, L. Davi, A.-R. Sadeghi, T. Holz, B. D. Sutter, and M. Franz. It’s a TRAP: Table Randomization and Protection against Function Reuse Attacks. In ACM Conference on Computer and Communications Security (CCS), 2015.
[15] T. H. Dang, P. Maniatis, and D. Wagner. The performance cost of shadow stacks and stack canaries. In ACM Symposium on Information, Computer and Communications Security (ASIACCS), 2015.
[16] L. Davi, D. Lehmann, A.-R. Sadeghi, and F. Monrose. Stitching the gadgets: On the ineffectiveness of coarse-grained control-flow integrity protection. In USENIX Security Symposium, 2014.
[17] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and F. Monrose. Isomeron: Code randomization resilient to (just-in-time) return-oriented programming. In Symposium on Network and Distributed System Security (NDSS), 2015.
[18] U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and G. C. Necula. XFI: Software Guards for System Address Spaces. In Symposium on Operating Systems Design and Implementation (OSDI), 2006.
[19] I. Evans, S. Fingeret, J. Gonzalez, U. Otgonbaatar, T. Tang, H. Shrobe, S. Sidiroglou-Douskos, M. Rinard, and H. Okhravi. Missing the point (er): On the effectiveness of code pointer integrity. In IEEE Symposium on Security and Privacy, 2015.
[20] I. Fratric. Runtime Prevention of Return-Oriented Programming Attacks. http://ropguard.googlecode.com/svn-history/r2/trunk/doc/ropguard.pdf.
[21] E. Goktas, E. Athanasopoulos, H. Bos, and G. Portokalidis. Out of control: Overcoming control-flow integrity. In IEEE Symposium on Security and Privacy, 2014.
[22] E. Goktas, E. Athanasopoulos, M. Polychronakis, H. Bos, and G. Portokalidis. Size does matter: Why using gadget-chain length to prevent code-reuse attacks is hard. In USENIX Security Symposium, 2014.
[23] J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. Davidson. ILR: Where’d My Gadgets Go? In IEEE Symposium on Security and Privacy, 2012.
[24] C. Kil, J. Jim, C. Bookholt, J. Xu, and P. Ning. Address space layout permutation (ASLP): Towards fine-grained randomization of commodity software. In Annual Computer Security Applications Conference (ACSAC), 2006.
[25] K. Kortchinsky. Escaping VMware Workstation through COM1. https://www.exploit-db.com/docs/37276.pdf, 2015.
[26] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song. Code-pointer integrity. In Symposium on Operating Systems Design and Implementation (OSDI), 2014.
[27] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, and D. Song. Poster: Getting the point(er): On the feasibility of attacks on code-pointer integrity. In IEEE Symposium on Security and Privacy, 2015.
[28] miasm2 Authors. Miasm2: Reverse Engineering Framework in Python. https://github.com/cea-sec/miasm, 2015.
[29] Microsoft. The Microsoft SDL and the CWE/SANS Top 25. http://download.microsoft.com/download/C/A/9/CA988ED6-C490-44E9-A8C2-DE098A22080F/Microsoft%20SDL%20and%20the%20CWE-SANS%20Top%2025.doc, 2009.
[30] Microsoft. Bringing asm.js to the Chakra JavaScript engine in Windows 10. http://blogs.msdn.com/b/ie/archive/2015/02/18/bringing-asm-js-to-the-chakra-javascript-engine-in-windows-10.aspx, 2014.
[31] Microsoft. EMET 5.2 is available. http://blogs.technet.com/b/srd/archive/2015/03/16/emet-5-2-is-available.aspx, 2014.
[32] Microsoft. Microsoft Security Bulletin Summary for December 2015. https://technet.microsoft.com/en-us/library/security/ms15-dec.aspx, 2015.
[33] Mozilla. asm.js working draft. http://asmjs.org/spec/latest/.
[34] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic. SoftBound: Highly compatible and complete spatial memory safety for C. In ACM Sigplan Notices, 2009.
[35] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic. CETS: Compiler enforced temporal safety for C. In ACM Sigplan Notices, 2010.
[36] V. Pappas. kBouncer: Efficient and Transparent ROP Mitigation. http://www.cs.columbia.edu/~vpappas/papers/kbouncer.pdf.
[37] V. Pappas, M. Polychronakis, and A. D. Keromytis. Smashing the gadgets: Hindering return-oriented programming using in-place code randomization. In IEEE Symposium on Security and Privacy, 2012.
[38] PaX Team. Address Space Layout Randomization. https://pax.grsecurity.net/docs/aslr.txt, 2001.
[39] PaX Team. Pageexec. https://pax.grsecurity.net/docs/pageexec.txt, 2001.
[40] A. Permamedov. Why it’s not crashing? The Code Project, 2010.
[41] M. Pietrek. A crash course on the depths of Win32 structured exception handling. Microsoft Systems Journal-US Edition, 12(1):41–66, 1997.
[42] M. Pietrek. New vectored exception handling in Windows XP. MSDN Magazine, 16(9):131–142, 2001.
[43] M. Polychronakis, K. G. Anagnostakis, and E. P. Markatos. Comprehensive shellcode detection using runtime heuristics. In Annual Computer Security Applications Conference (ACSAC), 2010.
[44] M. Prandini and M. Ramilli. Return-Oriented Programming. In IEEE Symposium on Security and Privacy, 2012.
[45] M. Russinovich, D. A. Solomon, and A. Ionescu. Windows Internals, Part 1. Microsoft Press, 6th edition, 2012.
[46] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R. Sadeghi, and T. Holz. Counterfeit object-oriented programming: On the difficulty of preventing code reuse attacks in C++ applications. In IEEE Symposium on Security and Privacy, 2015.
[47] F. Schuster, T. Tendyck, J. Pewny, A. Maass, M. Steegmanns, M. Contag, and T. Holz. Evaluating the effectiveness of current anti-ROP defenses. In Symposium on Recent Advances in Intrusion Detection (RAID), 2014.
[48] J. Seibert, H. Okkhravi, and E. Soderstrom. Information leaks without memory disclosures: Remote side channel attacks on diversified code. In ACM Conference on Computer and Communications Security (CCS), 2014.
[49] H. Shacham. The Geometry of Innocent Flesh on the Bone: Return-into-libc Without Function Calls (on the x86). In ACM Conference on Computer and Communications Security (CCS), 2007.
[50] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh. On the effectiveness of address-space randomization. In ACM Conference on Computer and Communications Security (CCS), 2004.
[51] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and A.-R. Sadeghi. Just-in-time code reuse: On the effectiveness of fine-grained address space layout randomization. In IEEE Symposium on Security and Privacy, 2013.
[52] A. Sotirov. Reverse Engineering and the ANI Vulnerability. http://www.phreedom.org/presentations/reverse-engineering-ani/reverse-engineering-ani.pdf, 2007.
[53] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lachmund, and T. Walter. Breaking the memory secrecy assumption. In Proceedings of the Second European Workshop on System Security, 2009.
[54] S. Vogl, R. Gawlik, B. Garmany, T. Kittel, J. Pfoh, C. Eckert, and T. Holz. Dynamic hooks: Hiding control flow changes within non-control data. In USENIX Security Symposium, 2014.
[55] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham. Efficient software-based fault isolation. In ACM SIGOPS Operating Systems Review, 1994.
[56] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary stirring: Self-randomizing instruction addresses of legacy x86 binary code. In ACM Conference on Computer and Communications Security (CCS), 2012.
[57] T. Yan. The Art of Leaks: The Return of Heap Feng Shui. In CanSecWest, 2014.
[58] Y. Yu. Write Once, Pwn Anywhere. In Black Hat USA, 2014.
[59] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant, D. Song, and W. Zou. Practical control flow integrity and randomization for binary executables. In IEEE Symposium on Security and Privacy, 2013.
[60] M. Zhang and R. Sekar. Control flow integrity for COTS binaries. In USENIX Security Symposium, 2013.