### Table III: Median Time to First Compromise (in Days) and Probability of Compromise for Three Different Client Behaviors and Nine Different Actual Adversary Distributions

| Adversary | 2a | 4 | 5 |
|-----------|-----|-----|-----|
| **Median Time to First Compromise (TTFC)** | min./med./max. | min./med./max. | min./med./max. |
| .01 > 7 > 7 | .38 | .57 | 6 |
| .01 > 7 > 7 | 5 | .01 | .68 |
| .01 > 7 > 7 | .47 | .47 | 7 |
| .01 > 7 > 7 | 6 | 5 | .07 |
| .01 > 7 > 7 | 7 | .71 | .48 |
| .01 > 7 > 7 | .49 | 7 | 5 |
| .01 > 7 > 7 | .0 | .82 | 6 |
| .01 > 7 > 7 | .25 | .61 | 7 |
| .01 > 7 > 7 | .38 | .58 | - |

**Data are from 10,000 simulations of a client in AS 6128 running for 7 days.**

### Table IV: Statistics (Minimum, Median, and Maximum) on the Median Times to First Compromise (in Days), Compromise Probability, and Fraction of Paths Compromised Over 10,000 Trials for Each of 401 Client Locations Running for One Day Each Against a Selected Set of Adversaries

| Adversary | Med. TTFC | Med. Prob. | Med. Frac. |
|-----------|------------|-------------|-------------|
| 2a | .01 > 1 > 1 | .01 > 1 > 1 | .0 |
| 4 | .01 > 1 > 1 | .01 > 1 > 1 | .01 |
| 5 | .01 > 1 > 1 | .01 > 1 > 1 | .01 |
| 2a | .21 | .27 | .09 |
| 4 | .59 | .45 | .11 |
| 5 | .49 | .66 | .0 |
| 2a | .66 | .69 | .1 |
| 4 | .79 | - | .16 |
| 5 | - | - | .0 |

**The clients choose paths against The Man; the actual adversary is shown in the first column.**

### Comparison with Figure 2

Comparing Table III with Figure 2, we observe that when the client in AS 6128 chooses paths against The Man, the use of TAPS enhances her security compared to vanilla Tor, especially against adversaries related to The Man, even if the client is not entirely accurate about the adversary's nature. This holds true for all adversary types considered in this section, except Type 5. Type 5 represents an adversary that independently compromises each relay and virtual link, and does not base its compromise on organizations or families. When the adversary is of Type 5, Tables III and IV show that it can effectively counter the client across many locations and behaviors.

### IX. Obtaining and Propagating Trust

To implement The Man policy, we consider the amount of data that must be stored and communicated. First, the client must determine the cluster of itself and its destinations. With 46,368 ASes in the network map used for TAPS analysis, 200 client clusters, and 200 destination clusters, 182 KiB is sufficient for each client to determine the needed clusters. Second, to choose guards and exits, the client needs to determine the AS and IXP organizations on any virtual link between their cluster representative and a guard, or between a destination-cluster representative and an exit. There are only 359 IXPs, so an AS or IXP organization can be specified in two bytes. For data gathered in December 2013, all guards are within 603 ASes, all exits are within 962 ASes, and the average number of AS and IXP organizations on a virtual link is 4.05. Thus, a list of the entities on all relevant virtual links for a given client would be 1.68 MiB. Routing changes could be propagated daily or weekly with much smaller updates once the full data is obtained.

### X. Related Work

Early proposals to use trust for Tor routing came from Øverlier and Syverson [30], who suggested choosing guards "based on trust in the node administrator." However, they did not develop this idea further. A mathematical notion of trust in Tor was introduced by Johnson and Syverson [20]. They formalized trust as the probability of compromise of a relay and provided an analysis of end-to-end correlation attacks with two different levels of trust. This model was later used by Johnson et al. [21] to produce a "downhill" Tor path-selection algorithm that can handle arbitrary trust levels at the relays and is designed to prevent traffic-correlation attacks. Jaggard et al. [16] expanded this probabilistic notion of trust by describing how to identify compromise factors that apply to links and nodes, such as AS organizations, legal jurisdictions, and router software. They focused on expressing rich trust models, while this paper focuses on using these models in a path-selection algorithm that improves security.

Another approach to trust in anonymous communication is to leverage social network relations. Danezis et al. [11] described this for interactive but low-volume anonymous communication. Focusing on low-volume applications allowed them to use padding, which is generally too expensive and ineffective for popular applications that use Tor. Mittal et al. [26] described a social-network onion-routing architecture designed for web browsing and other interactive communications, adding resistance to active adversaries. This design uses potentially longer paths than Tor’s three hops, which may significantly impact performance.

The threat of AS adversaries to Tor was first recognized by Feamster and Dingledine [14]. Their analysis showed that entry and exit paths through the network are likely to be simultaneously observed by a single AS 10% to 30% of the time, depending on the locations of the client and destination. They suggested that clients choose entry and exit nodes to avoid traversing the same AS upon entry and exit. Edman and Syverson [12] updated this work and showed that, despite the growth of the network from about 30 to about 1300 relays, the risk of deanonymization by a single AS is not reduced. They also showed how to efficiently implement AS-aware path selection by providing clients with routing data to infer AS-level routing paths. Murdoch and Zieliński [28] introduced IXPs as potential adversaries, showing that an IXP can correlate traffic even at low sampling rates. Link adversaries at both ASes and IXPs were extended by Johnson et al. [22] to consider adversaries controlling multiple ASes or IXPs, such as companies owning many IXPs. Akhoondi et al. [6] presented an alternate method for clients to efficiently infer the ASes between hosts for choosing Tor paths that avoid allowing the same AS to observe entry and exit traffic. Juen [23] presented another method, adding the inference of IXPs on those paths. All preceding suggestions for AS-aware Tor path selection neglect key details, such as circuit reuse and handling destinations with no path avoiding an AS on both sides. Additionally, Juen et al. [24] showed that methods of AS inference for detecting Tor paths vulnerable to AS-level compromise suffer from significant false-positives and false-negatives when compared to direct traceroute measurements.

Nithyanand et al. [29] presented Astoria, the first reasonably complete network-aware Tor path-selection algorithm. As described in Section II, like other previous work on network-aware path selection, Astoria is secure only when each connection is analyzed independently. DeNASA [8], by Barton and Wright, is another recent and fully-specified network-aware Tor path-selection algorithm. DeNASA considers individual ASes as adversaries and protects against the eight most likely ASes to deanonymize a connection. DeNASA does not consider the specific destination when constructing a circuit, allowing it to use pre-built circuits for speed but making it unable to protect connections to destinations with paths dissimilar from the pre-selected set used for exit selection. DeNASA is still vulnerable to leakage about a client’s AS across repeated connections, assuming its guard and exit-selection algorithms are jointly used.

Sun et al. [34] showed that traffic correlation attacks on Tor are effective even when the attacker observes paths in different directions on the entry and exit sides. They also demonstrated the application of BGP hijacking and interception attacks to redirect Tor traffic to malicious ASes for deanonymizing users. Tan et al. [35] extended this analysis, showing that 90% of Tor’s bandwidth is vulnerable to BGP hijacking, and proposed a set of monitors to detect routing attacks and notify Tor clients to avoid affected relays.

### XI. Conclusion

In this paper, we demonstrate how previous network-aware Tor path-selection algorithms are vulnerable to attacks across multiple Tor connections. We present TAPS, a path-selection algorithm for Tor that is not vulnerable to such attacks and enables clients to avoid traffic-correlation attacks by using trust in network elements. We present two global-adversary models, analyze the security and performance of TAPS against these adversaries, and consider both trust errors and trust propagation.

### Acknowledgments

We thank Ryan Wails for contributing to the results in Section II. The work at NRL was supported by ONR. Joan Feigenbaum’s research was supported in part by NSF grants CNS-1407454 and CNS-1409599, DHS contract FA8750-16-2-0034, and William and Flora Hewlett Foundation grant 2016-3834.

### References

[1] Shadow Git Repository. https://github.com/shadow/shadow.
[2] Shadow Homepage. http://shadow.github.io/.
[3] Shadow Tor plug-in Git Repository. https://github.com/shadow/shadow-plugin-tor.
[4] Tor Metrics Portal. http://metrics.torproject.org/.
[5] TorPerf. https://gitweb.torproject.org/torperf.git/.
[6] M. Akhoondi, C. Yu, and H. V. Madhyastha, “LASTor: A low-latency AS-aware Tor client,” in IEEE Symposium on Security & Privacy, 2012.
[7] B. Augustin, B. Krishnamurthy, and W. Willinger, “IXPs: Mapped?” in Internet Measurement Conference, 2009.
[8] A. Barton and M. Wright, “DeNASA: Destination-naive AS-awareness in anonymous communications,” Proceedings on Privacy Enhancing Technologies, 2016.
[9] X. Cai, J. Heidemann, B. Krishnamurthy, and W. Willinger, “An organization-level view of the Internet and its implications (extended),” USC/ISI, Tech. Rep. ISI-TR-2009-679, 2012.
[10] The CAIDA UCSD Internet Topology Data Kit - December 2013. http://www.caida.org/data/internet-topology-data-kit.
[11] G. Danezis, C. Diaz, C. Troncoso, and B. Laurie, “Drac: An architecture for anonymous low-volume communications,” in Privacy Enhancing Technologies Symposium, 2010.
[12] M. Edman and P. Syverson, “AS-awareness in Tor path selection,” in ACM Conference on Computer and Communications Security, 2009.
[13] N. S. Evans, R. Dingledine, and C. Grothoff, “A practical congestion attack on Tor using long paths,” in USENIX Security Symposium, 2009.
[14] N. Feamster and R. Dingledine, “Location diversity in anonymity networks,” in Workshop on Privacy in the Electronic Society, 2004.
[15] J. Geddes, R. Jansen, and N. Hopper, “How low can you go: Balancing performance with anonymity in Tor,” in Privacy Enhancing Technologies Symposium, 2013.
[16] A. D. Jaggard, A. Johnson, S. Cortes, P. Syverson, and J. Feigenbaum, “20,000 in league under the sea: Anonymous communication, trust, MLATs, and undersea cables,” Proceedings on Privacy Enhancing Technologies, 2015.
[17] R. Jansen, J. Geddes, C. Wacek, M. Sherr, and P. Syverson, “Never been KIST: Tor’s congestion management blossoms with kernel-informed socket transport,” in USENIX Security Symposium, 2014.
[18] R. Jansen and N. Hopper, “Shadow: Running Tor in a box for accurate and efficient experimentation,” in Network & Distributed System Security Symposium, 2012.
[19] A. Johnson, R. Jansen, A. D. Jaggard, and P. Syverson, “Avoiding the man on the wire: Improving Tor’s security with trust-aware path selection.” [Online]. Available: http://arxiv.org/abs/1511.05453
[20] A. Johnson and P. Syverson, “More anonymous onion routing through trust,” in IEEE Computer Security Foundations Symposium, 2009.
[21] A. Johnson, P. Syverson, R. Dingledine, and N. Mathewson, “Trust-based anonymous communication: Adversary models and routing algorithms,” in ACM Conference on Computer and Communications Security, 2011.
[22] A. Johnson, C. Wacek, R. Jansen, M. Sherr, and P. Syverson, “Users get routed: Traffic correlation on Tor by realistic adversaries,” in ACM Conference on Computer and Communications Security, 2013.
[23] J. Juen, “Protecting anonymity in the presence of autonomous system and internet exchange level adversaries,” Master’s thesis, University of Illinois at Urbana-Champaign, 2012.
[24] J. Juen, A. Johnson, A. Das, N. Borisov, and M. Caesar, “Defending Tor from network adversaries: A case study of network path prediction,” Proceedings on Privacy Enhancing Technologies, 2015.
[25] P. Mittal, A. Khurshid, J. Juen, M. Caesar, and N. Borisov, “Stealthy traffic analysis of low-latency anonymous communication using throughput fingerprinting,” in ACM Conference on Computer and Communications Security, 2011.
[26] P. Mittal, M. Wright, and N. Borisov, “Pisces: Anonymous communication using social networks,” in Network & Distributed System Security Symposium, 2013.
[27] S. J. Murdoch and G. Danezis, “Low-cost traffic analysis of Tor,” in IEEE Symposium on Security & Privacy, 2005.
[28] S. J. Murdoch and P. Zieliński, “Sampled traffic analysis by Internet-exchange-level adversaries,” in Privacy Enhancing Technologies Symposium, 2007.
[29] R. Nithyanand, O. Starov, P. Gill, A. Zair, and M. Schapira, “Measuring and mitigating AS-level adversaries against Tor,” in Network & Distributed System Security Symposium, 2016.
[30] L. Øverlier and P. Syverson, “Locating hidden servers,” in IEEE Symposium on Security & Privacy, 2006.
[31] H.-S. Park and C.-H. Jun, “A simple and fast algorithm for K-medoids clustering,” Expert Systems with Applications, vol. 36, no. 2, 2009.
[32] J. Qiu and L. Gao, “AS path inference by exploiting known AS paths,” in IEEE GLOBECOM, 2005.
[33] University of Oregon route views project. http://www.routeviews.org/.
[34] Y. Sun, A. Edmundson, L. Vanbever, O. Li, J. Rexford, M. Chiang, and P. Mittal, “RAPTOR: Routing attacks on privacy in Tor,” in USENIX Security Symposium, 2015.
[35] H. Tan, M. Sherr, and W. Zhou, “Data-plane Defenses against Routing Attacks on Tor,” Proceedings on Privacy Enhancing Technologies, 2016.
[36] Tor directory protocol. https://gitweb.torproject.org/torspec.git/blob/HEAD:/dir-spec.txt.
[37] T. Wang and I. Goldberg, “Improved website fingerprinting on Tor,” in Workshop on Privacy in the Electronic Society, 2013.