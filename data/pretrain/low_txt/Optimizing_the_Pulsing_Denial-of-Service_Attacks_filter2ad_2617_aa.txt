# Optimizing the Pulsing Denial-of-Service Attacks

**Authors:** Xiapu Luo and Rocky K. C. Chang  
**Journal:** IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 13, NO. 1, FEBRUARY 2005

## Abstract
This paper introduces a network architecture and accompanying algorithms designed to counter distributed denial-of-service (DDoS) attacks on Internet servers. The core mechanism involves a server under stress installing a router throttle at selected upstream routers. This throttle, which can be a leaky-bucket rate, regulates the packet rates destined for the server, thereby proactively mitigating potential attacks. We propose a level- max-min fairness concept for allocating server capacity among participating routers. A control-theoretic model is presented to evaluate algorithm convergence under various system parameters. Additionally, we provide simulation results using a realistic global network topology and models of user and attacker behavior. Our findings show that the throttle mechanism effectively prioritizes good user traffic over attacker traffic, especially when using level- max-min fairness. Throttling also ensures that the server remains operational by regulating the experienced load below its design limit. Implementation results on a Pentium III/866 MHz machine demonstrate that router throttling has low deployment overhead in terms of time and memory.

**Index Terms:** Congestion control, distributed denial of service, network security, router throttling.

**Manuscript received:** December 27, 2002; revised March 22, 2003; approved by IEEE/ACM TRANSACTIONS ON NETWORKING Editor V. Paxson. The work was supported by the National Science Foundation, CERIAS, and RGC Earmarked Grant.

**Affiliations:**
- D. K. Y. Yau: Department of Computer Science, Purdue University, West Lafayette, IN 47907 USA
- J. C. S. Lui: Department of Computer Science and Engineering, Chinese University of Hong Kong, Shatin, NT, Hong Kong
- F. Liang: Department of Telecommunications, Zhejiang University of Technology, Zhejiang, P. R. China
- Y. Yam: Department of Automation and Computer-aided Engineering, Chinese University of Hong Kong, Shatin, NT, Hong Kong

**Digital Object Identifier:** 10.1109/TNET.2004.842221

## I. Introduction

Distributed denial-of-service (DDoS) attacks involve a group of malicious or compromised hosts (zombies) coordinating to send a large volume of traffic to a victim server. In such attacks, the server resources are often more stressed than the connecting network due to high-capacity pipes and the full force of aggregated attack traffic. This can incapacitate the server under extreme overload conditions.

We view DDoS attacks as a resource management problem and aim to protect a server from excessive service request arrivals over a global network. Our approach is proactive: before aggressive packets can overwhelm the server, we ask upstream routers to regulate contributing packet rates to more moderate levels. The basic mechanism involves a server under stress installing a router throttle at an upstream router, limiting the rate at which packets are forwarded. Excess traffic can be dropped or rerouted, though we focus on the dropping solution in this paper.

A key element is to install appropriate throttling rates at distributed routing points, ensuring the network uses the server's full service capacity without exceeding it. These throttles are dynamically negotiated between the server and the network. When the server load increases and crosses the designed load limit, it installs and activates a rate throttle at a subset of its upstream routers. If the throttle fails to reduce the load, the throttle rate is reduced. Conversely, if the load falls below a low-water mark, the throttle rate is increased. The goal is to keep the server load within acceptable limits whenever a throttle is in effect.

Our implementation on the CROSS/Linux software router running on a Pentium III/864 MHz machine shows that throttling adds little computational overhead and requires minimal state information per throttle. Although the total state information needed is linear in the number of installed throttles, the approach is feasible as an on-demand and selective protection mechanism, given that DDoS attacks are relatively rare.

## A. Our Contributions

- **Fundamental Understanding:** We contribute to the understanding of router throttling as a DDoS defense mechanism, advancing a control-theoretic model to analyze system behavior under various parameters.
- **Adaptive Algorithm:** We present an adaptive throttle algorithm that effectively protects the server from resource overload and enhances the ability of good user traffic to reach the server.
- **Max-Min Fairness:** We show how max-min fairness can be achieved across many flows and introduce the notion of level- max-min fairness for DDoS attacks.
- **Application Performance:** We study the impact of throttling on real application performance, specifically on an HTTP web server, through simulations.
- **Implementation Results:** We provide system implementation results to quantify the deployment overhead of router throttling.

## B. Paper Organization

- **Section II:** Discusses practical challenges in deploying router throttling in the Internet.
- **Section III:** Introduces our system model.
- **Section IV:** Formally specifies baseline and fair algorithms for computing throttle rates.
- **Section V:** Presents a control-theoretic mathematical model for system performance analysis.
- **Section VI:** Provides diverse ns2 simulation results using a realistic network topology.
- **Section VII:** Details the implementation and experimental evaluation of router throttling on the CROSS/Linux software-programmable router.
- **Section VIII:** Compares our solution with related work.
- **Section IX:** Concludes the paper.

## II. Deployment Issues

Our work explores fundamental issues in mitigating DDoS attacks through dynamic resource control, focusing on providing good users with productive access to server resources despite excessive demands from attackers. While our results are promising, several deployment issues need resolution:

- **Trust Model:** Routers in the defense network trust each other but not necessarily the network users. Establishing trust relationships across multiple administrative domains is challenging.
- **Assumption of Aggressiveness:** Our approach assumes attackers are significantly more aggressive than regular users. If this assumption is false, good user traffic may be penalized similarly to attacker traffic.
- **Unpredictability of Attackers:** Modeling attacker behavior is inherently difficult. We have developed an analytical model to study the behavior of our control strategy, but adaptively learning the best control parameters requires further research.
- **Multicast Communication:** We assume protected servers will send throttle requests to deployment routers via multicast, though full IP multicast support is not necessary.
- **Supporting Routers:** Our study assumes router throttling is supported in specified deployment routers. If this is not true, identifying alternative supporting routers adds overhead.
- **Priority Transmission:** Techniques should be investigated to ensure reliable and timely delivery of throttle messages.

## III. System Model

We model a network as a connected graph \( G = (V, E) \), where \( V \) is the set of nodes and \( E \) is the set of edges. All leaf nodes are hosts and can be traffic sources, while internal nodes are routers. Hosts are not trusted and may spoof traffic, disobey congestion signals, or initiate bogus network requests. Routers are trusted and do not generate traffic but forward it from connected hosts or peer routers. The set of hosts \( H \) is partitioned into ordinary "good" users \( H_g \) and attackers \( H_a \). Network links are assumed to be bi-directional with infinite bandwidth.

In our control architecture, routers do not exchange control information beyond passing throttle requests. The target server makes all control decisions and instructs deployment routers to implement them. An attacker sends packets to the server at a rate chosen from a range, while a good user sends packets at a different rate. We target attacks where the attacker rate is significantly higher than the good user rate.

When the server is under attack, it initiates the throttle defense mechanism. The throttle does not need to be deployed at every router but at specific deployment points parameterized by a positive integer \( k \). The deployment points are given by \( R(k) \), which contains all routers either \( k \) hops away or directly connected to a host.

An important research problem is achieving fair rate allocation of the server capacity among the routers in \( R(k) \). To this end, we define level- max-min fairness:

**Definition 1 (Level- Max-Min Fairness):** A resource control algorithm achieves level- max-min fairness among the routers in \( R(k) \) if the allowed forwarding rate of traffic for each router is the routerâ€™s max-min fair share of some rate \( r \) satisfying \( \sum_{r \in R(k)} r = C \), where \( C \) is the server's full service capacity.