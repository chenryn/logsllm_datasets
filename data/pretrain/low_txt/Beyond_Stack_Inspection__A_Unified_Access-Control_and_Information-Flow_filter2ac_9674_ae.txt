### Taint Analysis and Information Flow Control

To perform taint analysis, one must identify the sources and sinks of potentially tainted data. This involves recognizing methods that generate tainted values and those that use possibly tainted values. Livshits and Lam's analysis algorithm [28] requires a flow-insensitive points-to heap analysis and assumes the presence of programmer-defined descriptors for sources and sinks. Additionally, it necessitates descriptors for library methods that handle objects through which taintedness may propagate. However, this approach does not account for indirect flows. In contrast, the algorithm presented in this paper considers indirect flows and does not require any programmer-defined descriptors. Pistoia et al. [33] use program slicing to detect tainted variables in privilege-asserting code. The work described in this paper subsumes their approach, as discussed in Section 4.1.

Stoughton [38] compares access control and information flow in a simple imperative language with semaphores, but does not provide formal results or static analysis for information flow. Myers' Jif tool [29] employs type-based static analysis [41, 13] to track information flow in Java, but the information-flow policy is expressed by a static labeling assumed to be given. Banerjee and Naumann [6] enhance such a type system with an effect analysis for stack-based access control (SBAC), allowing a procedure's labeling to depend on the permissions authorized at runtime. They prove noninterference, which has even been machine-checked [30]. However, their information lattice is separate from permissions. They also adapt their system to history-based access control (HBAC), where dynamic permissions can be exploited as a storage channel [5]. Barthe and Rezk [8] prove noninterference for a security type system for Java bytecode. Barthe et al. [7] show that typable source code compiles to typable bytecode. Zhao and Boyland [45] combine type-based and dynamic checks to improve the security of stack inspection by tracking data flows, but they do not consider implicit flows. In contrast to static checking of noninterference, Le Guernic et al. [22] propose dynamic, automaton-based monitoring of information flow for a single execution of a sequential program. The mechanism combines dynamic and static analyses, accepting or rejecting a single execution without necessarily doing the same for all other executions. The automaton ensures the confidentiality of secret data and accounts for both direct and implicit flows. The static analysis overapproximates implicit indirect flows and generates corresponding branch-not-taken inputs to the automaton, similar to the write oracle in our semantics. However, their work does not derive an information-flow policy from an access-control policy.

Several works focus on stack inspection as an access-control policy enforcement, aiming to define alternative implementations and study optimization techniques. Wallach et al. [44, 43] present Security Architecture Formerly Known as Stack Inspection (SAFKASI), which uses the calculus of Security-Passing Style (SPS) to enforce a form of access control equivalent to stack inspection. Pottier et al. [34] extend and formalize the SPS calculus via type theory using a λ-calculus called λsec. Jensen et al. [25] focus on proving that code is secure with respect to a global security policy, using operational semantics and a two-level temporal logic to detect redundant authorization tests. Bartoletti et al. [9] aim to optimize the performance of runtime authorization tests by eliminating redundant tests and relocating others as needed. Rather than analyzing existing code, Erlingsson and Schneider [40] describe a system that inlines reference monitors into the code to enforce specific security policies, reducing or eliminating redundant authorization tests. Koved et al. [27] use static analysis to identify permission requirements. Besson et al. [10] present a static analysis technique for verifying the security of libraries in SBAC systems.

### Discussion

In this paper, we introduce IBAC, a new access-control model that verifies, for any security-sensitive operation, that all the code responsible for that operation is sufficiently authorized. IBAC automatically infers the information-flow policy labels for a program from an existing access-control policy and transforms existing access-control tests into information-flow tests. The motivation for IBAC comes from a common process in production-level code: code initially written to run without SBAC enforcement is later required to run with SBAC enabled. System administrators must determine the necessary permissions, and developers must insert grant calls to prevent unnecessary permission requirements from percolating up the stack and affecting client code. However, an inherent flaw in SBAC is that code influencing a security-sensitive operation may no longer be on the stack of execution for that operation. Therefore, an SBAC test call may fail to verify the permission assignments of all the code associated with a security-sensitive action, and a grant call may allow untrusted code to influence, through tainted variables, the execution of trusted library code. Furthermore, we compare IBAC to HBAC and demonstrate that IBAC permits the execution of safe programs that HBAC would otherwise reject.

SBAC is also vulnerable to confidentiality attacks in systems that enforce capability-based security. For example, consider the Java program in Figure 4. As observed in Section 4.1, IBAC accepts that program. Suppose, however, that the FileOutputStream object created in F.main inadvertently escapes the security context in which it was created. It could be passed as a parameter to a method m4 of an object h of type H, or stored in the heap by F.main and subsequently accessed by h, where H is a class with no FilePermission "passwords.txt", "write". Now, h.m4 could call write on that FileOutputStream object, and its permissions are not checked since no object of type H was on the stack when the FileOutputStream object was created—a confidentiality violation. This paper discusses the integrity aspects of IBAC. In the future, we plan to extend this work to include confidentiality and explore how to integrate IBAC with a mechanism for declassification.

So far, we have implemented a subsystem of IBAC that enforces the rejection of integrity violations caused by tainted variables in privilege-asserting code. We plan to develop a full implementation of IBAC and validate its usefulness on production-level code that has adopted SBAC as its form of access control.

### References

[1] M. Abadi and C. Fournet. Access Control Based on Execution History. In Proceedings of the 11th Network and Distributed System Security Symposium (NDSS 2003), San Diego, CA, USA, Feb. 2003.

[2] T. Amtoft, S. Bandhakavi, and A. Banerjee. A Logic for Information Flow in Object-Oriented Programs. In Proceedings of the 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL 2006), pages 91–102, Charleston, SC, USA, Jan. 2006. Extended version as KSU CIS-TR-2005-1.

[3] L. O. Andersen. Program Analysis and Specialization for the C Programming Language. PhD thesis, University of Copenhagen, Copenhagen, Denmark, May 1994.

[4] K. Ashcraft and D. Engler. Using Programmer-Written Compiler Extensions to Catch Security Holes. In Proceedings of the 2002 IEEE Symposium on Security and Privacy, pages 143–159, Oakland, CA, USA, May 2002. IEEE Computer Society.

[5] A. Banerjee and D. A. Naumann. History-based Access Control and Secure Information Flow. In G. Barthe, L. Burdy, M. Huisman, J.-L. Lanet, and T. Muntean, editors, Construction and Analysis of Safe, Secure, and Interoperable Smart Devices, International Workshop (CASSIS 2004), Revised Selected Papers, volume 3362 of Lecture Notes in Computer Science, 2005.

[6] A. Banerjee and D. A. Naumann. Stack-based Access Control for Secure Information Flow. Journal of Functional Programming, 15(2):131–177, Mar. 2005. Special Issue on Language-Based Security.

[7] G. Barthe, D. A. Naumann, and T. Rezk. Deriving an Information Flow Checker and Certifying Compiler for Java. In 27th IEEE Symposium on Security and Privacy, pages 230–242, Oakland, CA, USA, May 2006.

[8] G. Barthe and T. Rezk. Non-interference for a JVM-like Language. In M. Fähndrich, editor, Proceedings of 2005 ACM SIGPLAN International Workshop on Types in Languages Design and Implementation (TLDI 2005), pages 103–112, Long Beach, CA, USA, Jan. 2005. ACM Press.

[9] M. Bartoletti, P. Degano, and G. L. Ferrari. Static Analysis for Stack Inspection. In Proceedings of International Workshop on Concurrency and Coordination, Electronic Notes in Theoretical Computer Science, volume 54, Amsterdam, The Netherlands, 2001. Elsevier.

[10] F. Besson, T. Blanc, C. Fournet, and A. D. Gordon. From Stack Inspection to Access Control: A Security Analysis for Libraries. In Proceedings of the 17th IEEE Computer Security Foundations Workshop (CSFW-17 2004), pages 61–75, Pacific Grove, CA, USA, June 2004. IEEE Computer Society.

[11] M. Bishop and M. Dilger. Checking for Race Conditions in File Accesses. Computing Systems, 9(2):131–152, Spring 1996.

[12] D. E. Denning. A Lattice Model of Secure Information Flow. Communications of the ACM, 19(5):236–243, May 1976.

[13] D. E. Denning and P. J. Denning. Certification of Programs for Secure Information Flow. Communications of the ACM, 20(7):504–513, July 1977.

[14] Eclipse Project, http://www.eclipse.org.

[15] Equinox Security Java Project, http://www.eclipse.org/equinox/incubator/security/java2security.html.

[16] J. S. Fenton. Memoryless Subsystems. The Computer Journal, 17(2):143–147, 1974.

[17] J. S. Foster, T. Terauchi, and A. Aiken. Flow-Sensitive Type Qualifiers. In Proceedings of the 2002 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2002), pages 1–12, Berlin, Germany, June 2002.

[18] C. Fournet and A. D. Gordon. Stack Inspection: Theory and Variants. In Proceedings of the 29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL 2002), pages 307–318, Portland, OR, USA, Jan. 2002. ACM Press.

[19] J. A. Goguen and J. Meseguer. Security Policies and Security Models. In Proceedings of the 1982 IEEE Symposium on Security and Privacy, pages 11–20, Oakland, CA, USA, May 1982. IEEE Computer Society Press.

[20] L. Gong, M. Mueller, H. Prafullchandra, and R. Schemers. Going Beyond the Sandbox: An Overview of the New Security Architecture in the Java Development Kit 1.2. In USENIX Symposium on Internet Technologies and Systems, Monterey, CA, USA, Dec. 1997.

[21] D. Grove and C. Chambers. A Framework for Call Graph Construction Algorithms. ACM Trans. Program. Lang. Syst., 23(6):685–746, November 2001.

[22] G. L. Guernic, A. Banerjee, T. Jensen, and D. A. Schmidt. Automata-based Confidentiality Monitoring. In Proceedings of 11th Annual Asian Computing Science Conference (ASIAN 2006), Tokyo, Japan, Dec. 2006.

[23] C. Hammer, J. Krinke, and G. Snelting. Information Flow Control for Java Based on Path Conditions in Dependence Graphs. In Proceedings of IEEE International Symposium on Secure Software Engineering, Arlington, VA, USA, Mar. 2006.

[24] N. Hardy. The Confused Deputy. ACM SIGOPS Operating Systems Review, 22(4):36–38, Oct. 1988.

[25] T. P. Jensen, D. L. Métayer, and T. Thorn. Verification of Control Flow Based Security Properties. In Proceedings of the 1999 IEEE Symposium on Security and Privacy, pages 89–103, Oakland, CA, USA, May 1999.

[26] G. A. Kildall. A Unified Approach to Global Program Optimization. In Proceedings of the 1st Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pages 194–206, Boston, MA, USA, 1973. ACM Press.

[27] L. Koved, M. Pistoia, and A. Kershenbaum. Access Rights Analysis for Java. In Proceedings of the 17th ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, pages 359–372, Seattle, WA, USA, November 2002. ACM Press.

[28] V. B. Livshits and M. S. Lam. Finding Security Vulnerabilities in Java Applications with Static Analysis. In Proceedings of the 14th USENIX Security Symposium, Baltimore, MD, USA, July 2005.

[29] A. C. Myers. JFlow: Practical Mostly-static Information Flow Control. In Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL 1999), pages 228–241, San Antonio, TX, USA, Jan. 1999.

[30] D. A. Naumann. Verifying a Secure Information Flow Analyzer. In J. Hurd and T. Melham, editors, 18th International Conference on Theorem Proving in Higher Order Logics (TPHOLs 2005), volume 3603 of Lecture Notes in Computer Science, pages 211–226, Oxford, UK, Aug. 2005. Springer.

[31] J. Newsome and D. X. Song. Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software. In Proceedings of the 12th Network and Distributed System Security Symposium (NDSS 2005), San Diego, CA, USA, Feb. 2005. IEEE Computer Society.

[32] N. Paul and D. Evans. .NET Security: Lessons Learned and Missed from Java. In Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC 2004), pages 272–281, Washington, DC, USA, December 2004. IEEE Computer Society.

[33] M. Pistoia, R. J. Flynn, L. Koved, and V. C. Sreedhar. Interprocedural Analysis for Privileged Code Placement and Tainted Variable Detection. In Proceedings of the 19th European Conference on Object-Oriented Programming, pages 362–386, Glasgow, Scotland, UK, July 2005. Springer-Verlag.

[34] F. Pottier, C. Skalka, and S. F. Smith. A Systematic Approach to Static Access Control. In Proceedings of the 10th European Symposium on Programming Languages and Systems, pages 30–45. Springer-Verlag, 2001.

[35] J. H. Saltzer and M. D. Schroeder. The Protection of Information in Computer Systems. In Proceedings of the IEEE, volume 63, pages 1278–1308, Sept. 1975.

[36] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting Format String Vulnerabilities with Type Qualifiers. In Proceedings of the 10th USENIX Security Symposium, Washington, DC, USA, Aug. 2001.

[37] G. Snelting, T. Robschink, and J. Krinke. Efficient Path Conditions in Dependence Graphs for Software Safety Analysis. ACM Transactions on Software Engineering and Methodology (TOSEM), 15(4):410–457, October 2006.

[38] A. Stoughton. Access Flows: A Protection Model which Integrates Access Control and Information Flow. In Proceedings of the 1981 IEEE Symposium on Security and Privacy, pages 9–18, Oakland, CA, USA, May 1981.

[39] IBM Security Workbench Development Environment for Java (SWORD4J), http://www.alphaworks.ibm.com/tech/sword4j.

[40] Úlfar Erlingsson and F. B. Schneider. IRM Enforcement of Java Stack Inspection. In Proceedings of the 2000 IEEE Symposium on Security and Privacy, pages 246–255, Oakland, CA, USA, May 2000. IEEE Computer Society.

[41] D. Volpano, C. Irvine, and G. Smith. A Sound Type System for Secure Flow Analysis. Journal of Computer Security, 4(2-3):167–187, Jan. 1996.

[42] L. Wall, T. Christiansen, and J. Orwant. Programming Perl. O’Reilly & Associates, Inc., Sebastopol, CA, USA, third edition, July 2000.

[43] D. S. Wallach, A. W. Appel, and E. W. Felten. SAFKASI: A Security Mechanism for Language-based Systems. ACM Transactions on Software Engineering and Methodology (TOSEM), 9(4):341–378, 2000.

[44] D. S. Wallach and E. W. Felten. Understanding Java Stack Inspection. In Proceedings of the 1998 IEEE Symposium on Security and Privacy, pages 52–63, Oakland, CA, USA, May 1998.

[45] T. Zhao and J. T. Boyland. Type Annotations to Improve Stack-Based Access Control. In 18th IEEE Computer Security Foundations Workshop (CSFW-18 2005), pages 197–210, Aix-en-Provence, France, June 2005. IEEE Computer Society.