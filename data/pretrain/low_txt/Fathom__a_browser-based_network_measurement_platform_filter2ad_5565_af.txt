### Portability

While Fathom currently operates exclusively in Firefox, our vision includes expanding support to other browsers and environments. The Android version of Firefox shares the same architecture as its desktop counterpart, necessitating only minor adjustments for Fathom compatibility. For Chrome, implementation would require a combination of content scripts to hook the API into the window, an extension core to mediate between the web page and the operating system, and a native binary to handle all remaining functionality, including command invocation on the host. Fathom’s callback-driven API aligns well with Chrome’s architecture. Internet Explorer and Safari present more challenges: the former requires the development of a browser helper object, while the latter’s limited extension JavaScript API necessitates the use of a plugin component.

### Incentives for Adoption

Fathom offers significant incentives for end-users, researchers, and website operators. For end-users, Fathom’s built-in troubleshooting capabilities provide an immediate reason to install the platform, as it helps debug connectivity issues that users would otherwise need to solve manually. Our experience with Netalyzr shows that there is a genuine demand for such debugging tools among a subset of users who frequently return to the Netalyzr site to run diagnostics and provide feedback. Since Fathom can support troubleshooting both in the presence of fundamental connectivity problems (which preclude the use of web-based services like Netalyzr) and when visiting a webpage is feasible, we believe this incentive is at least as strong for Fathom as it is for Netalyzr.

For researchers, Fathom’s appeal lies in its ability to eliminate the need for manual installation of experiment-specific code. Once the user has installed Fathom, any Fathom-driven experiment can be conducted with the ease of visiting a web page, thereby lowering the barrier to entry for both users and experimenters. Similarly, for site operators, once users have installed Fathom, both parties benefit from a deeper understanding of performance impediments.

### Support for Long-Running Measurements

Experimenters often need to execute long-running measurement tasks, such as studying the evolution of network topology or the dynamics of network performance. Fathom’s browser-based nature raises questions about how long users typically keep a particular page open. Data collected by the Mozilla TestPilot project, which recorded the browsing behavior of 2,000 Firefox users, provides some insight: 20% of browser windows remain open for at least an hour, and 7% for more than a day. With gentle reminders to users about ongoing experiments, Fathom should be able to facilitate reasonable levels of longer-term data collection.

Fathom’s current implementation supports the execution of long-running tasks if the measurement script is invoked within a FathomScript (as described in §5.4). This mechanism allows for independence from user interaction with the web page, thus immunizing the experiment from potential scheduling degradations imposed by the browser when a tab does not have focus. However, it still requires the end-user to keep the measurement tab open. This is because Fathom manages resource consumption by deallocating all requested resources when the corresponding browser tab or window is closed. Additionally, Fathom does not save any measurement state in the event of browser or system shutdown.

We anticipate introducing a special API for experimenters to launch background experiments, thereby decoupling the longevity of a measurement task from a browser tab. This approach will provide independence from accidental tab closures but requires careful consideration of resource management for long-running tasks. Specifically, we must address (i) what experiment state and resources must be preserved across browser or system reboots, and (ii) the security implications of running a background task with access to host and web resources.

### Related Work

We categorize related work into three main areas: browser-based approaches to profile page performance, server-based measurement platforms, and efforts that piggyback measurements with applications already running on end systems.

#### Browser-Based Page Performance Profiling

Several browser-based approaches help developers benchmark and debug web page performance. Tools like the Firebug extension and the dynaTrace application break down page load times, but these measurements are only accessible from the browser, not the web page itself. This limits the ability of web page developers to remotely execute tests from real users’ browsers. The Boomerang JavaScript library overcomes this limitation by giving web pages a vantage point directly from the end-system. Janc et al. combined JavaScript and Flash to measure throughput and jitter in HTTP downloads, but neither effort provides a generic API. The forthcoming NavigationTiming API standardizes latency measurements by providing timestamps for fixed events during a page’s loading cycle, but it only applies to the page itself, not embedded components. Fathom, in contrast, adds the ability to contrast passive timing collection with active measurements. Rivet, another recent effort, leverages reflection and dynamic characteristics of JavaScript to implement a remote debugger for web applications. As a regular JavaScript library, Rivet does not fundamentally add functionality to JavaScript in web pages, and unlike Fathom, it cannot enable additional passive or active measurement tasks.

#### Measurement Platforms

Researchers often use PlanetLab and Google’s M-Lab as measurement platforms. Both are based on well-connected servers rather than end systems, as is the case with Fathom. Scriptroute added the capability for any Internet user to run measurements using scripts in a sandboxed, resource-limited environment in PlanetLab. While we share Scriptroute’s goal of building a community platform for network measurements, our focus on taking measurements directly from end systems introduces new challenges, particularly in terms of portability across operating systems and minimizing performance overhead.

#### Piggybacking Measurements with Applications

Dasu is a Vuze plugin that analyzes BitTorrent traffic to characterize ISP performance. Because Dasu piggybacks on BitTorrent, it has a large user base. However, BitTorrent’s frequent use for sharing pirated content can make its use problematic from a policy perspective. We instead opt for deploying measurements on the web browser, which is even more ubiquitous than BitTorrent. The Measurement Manager Protocol (MGRP) is an in-kernel service that runs on end systems to reduce overhead for active measurement tools. MGRP allows measurement tools to send probe trains where application packets piggyback on measurement probes. Neither MGRP nor Dasu provide a programmable measurement platform.

### Conclusion

In this paper, we describe Fathom, a browser extension that uses web browser APIs to build a measurement platform. Fathom provides a programmable interface for writing and launching measurements from the convenience of the web browser. We have implemented a Fathom prototype for the Firefox web browser. Our evaluation shows that it can achieve timestamp accuracies of 1 ms and generally has runtime overheads of <3.2% for popular websites. We also demonstrate its utility in three case studies: providing a JavaScript version of the Netalyzr network characterization tool, debugging web access failures, and enabling websites to diagnose performance problems of their clients.

### Acknowledgements

We thank the anonymous reviewers and our shepherd, KC Claffy, for their comments and feedback on the paper. This work was supported in part by the National Science Foundation under grants CNS-0831535 and CNS-1111672. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. We also thank Comcast and Google for their support.

### References

[1] S. Agarwal, P. Mohan, N. Liogkas, and V. Padmanabhan. WebProfiler: Cooperative Diagnosis of Web Failures. In Proc. COMSNETS, 2010.
[2] G. Aggrawal, E. Bursztein, C. Jackson, and D. Boneh. An Analysis of Private Browsing Modes in Modern Browsers. In Proc. USENIX Security, 2010.
[3] A. Barth, A. Felt, P. Saxena, and A. Boodman. Protecting Browsers from Extension Vulnerabilities. In Proc. NDSS, 2010.
[4] S. Bauer, D. Clark, and W. Lehr. Understanding Broadband Speed Measurements. MITAS Project White Paper, 2010.
[5] Z. S. Bischof, J. S. Otto, M. A. Sánchez, J. P. Rula, D. R. Choffnes, and F. E. Bustamante. Crowdsourcing ISP Characterization to the Network Edge. In Proc. ACM SIGCOMM Workshop on Measurements Up the Stack, 2011.
[6] Bugzilla. https://bugzilla.mozilla.org/show_bug.cgi?id=687306.
[7] M. Butkiewicz, H. V. Madhyastha, and V. Sekar. Understanding Website Complexity: Measurements, Metrics, and Implications. In Proc. IMC, 2011.
[8] K. Chen, D. R. Choffnes, R. Potharaju, Y. Chen, F. E. Bustamante, D. Pei, and Y. Zhao. Where the Sidewalk Ends: Extending the Internet AS Graph Using Traceroutes from P2P Users. In Proc. CoNEXT, 2009.
[9] B. Chun, D. Culler, T. Roscoe, A. Bavier, L. Peterson, M. Wawrzoniak, and M. Bowman. PlanetLab: An Overlay Testbed for Broad-Coverage Services. ACM SIGCOMM Computer Communication Review, 33(3), July 2003.
[10] H. Cui and E. Biersack. Trouble Shooting Interactive Web Sessions in a Home Environment. In Proc. ACM SIGCOMM Workshop on Home Networks, 2011.
[11] L. DiCioccio, R. Teixeira, M. May, and C. Kreibich. Probe and Pray: Using UPnP for Home Network Measurements. In Passive and Active Measurement Conference (PAM), Vienna, Austria, March 2012.
[12] M. Dischinger, M. Marcon, S. Guha, K. P. Gummadi, R. Mahajan, and S. Saroiu. Glasnost: Enabling End Users to Detect Traffic Differentiation. In Proc. USENIX NSDI, 2010.
[13] J. R. Douceur, J. Elson, J. Howell, and J. R. Lorch. Leveraging Legacy Code to Deploy Desktop Applications on the Web. In Proc. USENIX OSDI, 2008.
[14] dynaTrace Software. Diagnose and Prevent AJAX Performance Issues. http://ajax.dynatrace.com/.
[15] P. Eckersley. How Unique Is Your Web Browser? In Proc. Privacy Enhancing Technologies Symposium (PETS), 2010.
[16] A. P. Felt, S. Egelman, M. Finifter, D. Akhawe, and D. Wagner. How to Ask for Permission. In Proc. USENIX Workshop on Hot Topics in Security, 2012.
[17] FireEye. Zero-Day Season Is Not Over Yet. http://blog.fireeye.com/research/2012/08/zero-day-season-is-not-over-yet.html.
[18] A. Giammarchi. An Introduction to js-ctypes. http://webreflection.blogspot.com/2011/09/introduction-to-js-ctypes.html.
[19] Google. Google Maps Help Forum. http://www.google.com/support/forum/p/maps/thread?tid=24f446d4cc24d07a.
[20] Internet2. Network Diagnostic Tool (NDT). http://www.internet2.edu/performance/ndt/.
[21] Iperf. http://iperf.sourceforge.net/.
[22] A. Janc. Nettest. http://code.google.com/p/nettest/.
[23] A. Janc, C. Wills, and M. Claypool. Network Performance Evaluation in a Web Browser. In Proc. IASTED PDCS, 2009.
[24] S. Kambala. Speed Metrics in Google Analytics. http://googlecode.blogspot.com/2011/12/speed-metrics-in-google-analytics.html.
[25] P. Kanuparthy and C. Dovrolis. ShaperProbe: End-to-End Detection of ISP Traffic Shaping Using Active Methods. In Proc. IMC, 2011.
[26] A. Kingsley-Hughes. Flashback Malware Worth Up To $10,000 A Day To Criminals. http://www.forbes.com/sites/adriankingsleyhughes/2012/05/01/flashback-malware-worth-up-to-10000-a-day-to-criminals/, May 2012.
[27] C. Kreibich, N. Weaver, G. Maier, B. Nechaev, and V. Paxson. Experiences from Netalyzr with Engaging Users in End-System Measurement. In Proc. ACM SIGCOMM Workshop on Measurements Up the Stack, 2011.
[28] C. Kreibich, N. Weaver, B. Nechaev, and V. Paxson. Netalyzr: Illuminating the Edge Network. In Proc. IMC, 2010.
[29] V. Lam, S. Antonatos, P. Akritidis, and K. Anagnostakis. Puppetnets: Misusing Web Browsers as a Distributed Attack Infrastructure. In Proc. ACM CCS, 2006.
[30] A. Lieuallen, A. Boodman, and J. Sundström. Greasemonkey. http://www.greasespot.net/.
[31] M. Mathis, J. Heffner, P. O’Neil, and P. Siemsen. Pathdiag: Automated TCP Diagnosis. In Proc. PAM, 2008.
[32] Measurement Lab. http://www.measurementlab.net/.
[33] D. Meketa. Policy File Changes in Flash Player 9 and Flash Player 10. http://www.adobe.com/devnet/flashplayer/articles/fplayer9_security.html.
[34] J. Mickens. Rivet: Browser-Agnostic Remote Debugging for Web Applications. In Proc. USENIX ATC, pages 30–38, 2012.
[35] Mitre.org. CVE-2012-4681. http://cve.mitre.org/cgi-bin/cvename.cgi?name=2012-4681.
[36] Mozilla. Firebug. http://getfirebug.com/.
[37] Mozilla. Perfmeasurement.jsm. https://developer.mozilla.org/en/JavaScript_code_modules/PerfMeasurement.jsm.
[38] Mozilla. Signed Scripts in Mozilla. http://www.mozilla.org/projects/security/components/signed-scripts.html.
[39] Mozilla Developer Network. ChromeWorker. https://developer.mozilla.org/en/DOM/ChromeWorker.
[40] Mozilla Developer Network. js-ctypes. https://developer.mozilla.org/en/js-ctypes.
[41] Mozilla TestPilot. Tab Switch Study. https://testpilot.mozillalabs.com/testcases/tab-switch-study.
[42] V. N. Padmanabhan, S. Ramabhadran, S. Agarwal, and J. Padhye. A Study of End-to-End Web Access Failures. In Proc. CoNEXT, 2006.
[43] P. Papageorge, J. McCann, and M. Hicks. Passive Aggressive Measurement with MGRP. In Proc. ACM SIGCOMM, 2009.
[44] V. Paxson. End-to-End Routing Behavior in the Internet. Proc. ACM SIGCOMM, 1996.
[45] M. Perry. Torbutton Design Documentation. https://www.torproject.org/torbutton/en/design/.
[46] C. Reis, S. Gribble, T. Kohno, and N. Weaver. Detecting In-Flight Page Changes with Web Tripwires. In Proc. USENIX NSDI, pages 31–44, 2008.
[47] Y. Shavitt and E. Shir. DIMES: Let the Internet Measure Itself. ACM SIGCOMM Computer Communication Review, 35(5), 2005.
[48] J. Sommers and P. Barford. An Active Measurement System for Shared Environments. In Proc. IMC, 2007.
[49] N. Spring, D. Wetherall, and T. Anderson. Scriptroute: A Public Internet Measurement Facility. In Proc. USENIX Symposium on Internet Technologies and Systems, 2003.
[50] J. Ullrich. JavaScript DDoS Tool Analysis. http://isc.sans.org/diary/Javascript+DDoS+Tool+Analysis/12442.
[51] UPnP Forum. Internet Gateway Device (IGD) V 2.0. http://upnp.org/specs/gw/igd2.
[52] W3C. Navigation Timing, Editor’s Draft November 14th, 2011. https://dvcs.w3.org/hg/webperf/raw-file/tip/specs/NavigationTiming/Overview.html.
[53] Wikimedia Foundation, Inc. Netscape Plugin Application Programming Interface. http://en.wikipedia.org/wiki/NPAPI.
[54] Yahoo! Exceptional Performance Team. This, Is Boomerang. http://yahoo.github.com/boomerang/doc/.
[55] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, N. Fullagar, and G. Inc. Native Client: A Sandbox for Portable, Untrusted x86 Native Code. In Proc. IEEE S&P, 2009.