# Meme and Social Contagion Analysis

## 5.4 Rate of Spread
To understand the speed at which social contagions spread, we compare the delay between each compromised user's first spam tweet \( t_i \) and the onset of the contagion \( t_0 \), estimated as the first tweet in the cluster. We repeat this process for every meme participant and fraudulent account. The results are presented in Figure 10.

Our findings indicate that compromise is the slowest process, with only 30% of victims posting within the first day compared to 44% of meme participants. Spam campaigns using fake accounts are the most condensed, with 65% of accounts posting within a day of the campaign's onset. The long tail for fraudulent accounts is due to new accounts joining campaigns over time, with multiple campaigns being merged due to overlapping participants. These findings suggest that, unlike Internet worms [24], social contagions are slow-moving because they require victims to interact with harmful content.

**Figure 10: Delay between the onset \( t_0 \) of a cluster and each user’s participation at \( t_i \).**

```
F
D
C
100%
75%
50%
25%
0%
0.01
1.00
Duration (in days)
100.00
compromise
fraudulent
meme
```

## 5.5 Campaign Duration
Despite the quick reaction time of compromised users to unwarranted content in their feeds (discussed in Section 4.2), contagions can still spread and last for multiple days. The median duration of a compromise cluster, measured from the first tweet \( t_0 \) to the last tweet \( t_n \), is 9 days (see Figure 11). For comparison, memes last a median of 5 days, while spam campaigns conducted via fraudulent accounts last only 1 day. The extended duration of compromise campaigns indicates that even batch jobs for detecting these contagions can significantly reduce the number of victims. If Twitter detected and remedied social contagions within 24 hours, it would result in 70% fewer compromises.

**Figure 11: Duration of clusters measured from the first clustered tweet \( t_0 \) to the last tweet \( t_n \).**

## 6. Monetizing Hijacked Accounts
The ultimate goal of account hijacking is profit. We explore the three dominant monetization strategies that criminals use once they gain access to compromised credentials. Table 3 summarizes each strategy and its impact on Twitter. These monetization schemes are similar to previous Twitter spam campaigns that rely on fraudulent accounts [28], though the challenge of reaching an audience is greatly simplified by account hijacking.

### 6.1 Weight Loss
Easy weight loss nutraceuticals were the most prolific ploys used by criminals to monetize compromised accounts. Our dataset contains 221 campaigns, involving approximately 4.7 million unique victims (34% of all compromised accounts). Despite the short lifetime of individual campaigns (an average of 6 days), weight loss schemes persisted for 229 days—nearly the entire data collection period. Criminals relied on stolen credentials to author spam tweets; 98% of the advertisements for weight loss were composed via Twitter-owned and operated clients requiring a username and password. The largest single contagion in this set used 1.1 million compromised accounts to advertise, "It's been 2 weeks and I lost 20 lbs thanks to garcinia, try it for free...," linking to nearly 70,000 distinct URLs over a 23-day period.

Such scams generate profit through visitors voluntarily providing their credit card details and subsequently purchasing products like garcinia, green coffee, acai berry, raspberry ketone, or other nutraceuticals (often advertised with a misappropriation of the "Dr. Oz" brand). Merchants fulfilling these orders have recently come under scrutiny by the FTC for deceptive practices [31], while gray-market advertisers on Facebook have also had their ads pulled for violating advertisement rules [11]. The reliance of criminals on compromised accounts to reach a wide audience can be seen as an evolution in the ongoing battle against weight loss scams.

### 6.2 Gain Followers & Retweets
Fake follower schemes, where victims unwittingly (or willingly) provide their credentials to criminals in return for gaining more followers or retweets, are the second largest source of compromises on Twitter. We identified 779 such schemes, netting roughly 3.7 million users (27% of all compromised accounts). Victims often advertise phrases like "easy way to get free followers..." and "ücretsiz takipçi kazan" (Earn free followers), with the most popular advertisements appearing in English (47%), Turkish (22%), and Indonesian (19%). Unlike weight loss schemes, 88% of spam tweets were authored via a long tail of 4,343 OAuth applications, and the remaining 12% via the web. These applications include Retweetlr, BestFollowers App, and a slew of throwaway OAuth credentials generated by criminals to withstand Twitter disabling their app.

Fake follower schemes both spread and generate profit by having victims install their application. Criminals use compromised accounts to advertise services like http://followrush.org/, where miscreants can buy 20,000 followers for $40 and 5,000 retweets and 5,000 favorites for $40—all sourced from compromised accounts. Alternative monetization strategies rely on tiered pricing between free and premium memberships. One example in our dataset is PlusFollower, where free members must follow all premium users and send a promotional tweet as frequently as every 4 hours, in return receiving an unspecified number of followers. Premium members pay a fee (starting at £10) to gain followers, avoiding the requirement to follow other users or advertise the service.

Fake follower rings on Twitter have persisted since 2010, with criminals advertising both "real accounts" and fraudulent accounts as the source of follows [16, 25, 30]. While some victims may participate willingly, they should still be considered compromised. Users lose control of their accounts and have no oversight over subsequent spam advertisements, retweets, favorites, and follows. Even if victims wish to leave the service, they must go through the same mechanism to restore account control as compromised victims. Finally, the monetization of these participants is clearly criminal and in violation of Twitter’s Terms of Service.

### 6.3 Lead Generation
The final monetization strategy we highlight is lead generation, where criminals entice victims into filling out surveys for a nominal payment or trick them into paying a "one-time fee" before they can be paid for their work. We found only one contagion relying on this approach, but it alone consisted of nearly 1 million victims and lasted 31 days. Criminals used hijacked credentials to tweet an automated template loosely matching, "Sweeeet!! I earned $157.18 this week filling out a couple of surveys," with all posts originating from the web where a username and password is required.

Surprisingly, all of the URLs used to monetize clicks led to Facebook applications that are no longer operational, suggesting the contagion may have existed on both Twitter and Facebook. While investigating the broken Facebook applications, we found an embedded iFrame linking back to at least one live site, getcashforsurveys.com, which advertises a quick cash program through completing surveys with an upfront enrollment fee of $74.

## 7. Summary
Our work highlights the threat of large-scale compromise in social networks, identifying 13 million hijacked victims on Twitter. Our measurements capture the underlying social component of compromise and how it operates at scale. This includes the human cost of 21% of victims losing access to their account and 57% becoming more isolated from friends, the ability of miscreants to generate social cascades that propagate as virulently as media sensations, and the finding that user vulnerability to compromise appears independent of user savviness.

Our results indicate that compromise is dominated by social contagions—phishing and malware campaigns that prey on user trust—rather than weak passwords or lax site security. The underlying social process that drives compromise mirrors that of information diffusion for benign memes and viral content. Consequently, a user with 20 compromised neighbors is 10 times more likely to become compromised compared to a user with one compromised neighbor.

To combat the threat of widespread hijacking, we observe that, in addition to better account-hijacking detection signals, existing victims can serve as early detectors for attacks. We find that a median user deletes an errant spam tweet posted by a hijacker within one hour of its appearance. If Twitter detected social contagions within 24 hours of their outbreak via correlated deletion events (similar to the detection scheme outlined in this paper), they could protect 70% of future potential victims. In particular, we emphasize that the centralized control afforded to online social networks provides an opportunity to inoculate victims and arrest the spread of contagions in a way that has never been possible for Internet worms.

## 8. Acknowledgments
We would like to thank James Fowler for his helpful comments on our research and its development. This work was supported in part by the National Science Foundation under grant 1237265, by the Office of Naval Research under MURI grant N000140911081, and by a gift from Google. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors.

## 9. References
[1] Eytan Bakshy, Brian Karrer, and Lada A Adamic. Social influence and the diffusion of user-created content. In Proceedings of the 10th ACM conference on Electronic commerce, 2009.
[2] Eytan Bakshy, Itamar Rosenn, Cameron Marlow, and Lada Adamic. The role of social networks in information diffusion. In Proceedings of the 21st international conference on World Wide Web, 2012.
[3] Andrei Z Broder. On the resemblance and containment of documents. In Compression and Complexity of Sequences 1997. Proceedings, 1997.
[4] Chris Brook. Github resets users’ passwords following brute force attack. http://threatpost.com/github-resets-users-passwords-following-brute-force-attack/102983, 2013.
[5] M. Cha, H. Haddadi, F. Benevenuto, and K.P. Gummadi. Measuring User Influence in Twitter: The Million Follower Fallacy. In Proceedings of the 4th International Conference on Weblogs and Social Media, 2010.
[6] Nicholas A Christakis and James H Fowler. The spread of obesity in a large social network over 32 years. New England Journal of Medicine, 2007.
[7] Dan Cosley, Daniel P Huttenlocher, Jon M Kleinberg, Xiangyang Lan, and Siddharth Suri. Sequential influence models in social networks. In Proceedings of the International Conference of Weblogs and Social Media, 2010.
[8] Anupam Das, Joseph Bonneau, Matthew Caesar, Nikita Borisov, and XiaoFeng Wang. The tangled web of password reuse. In Symposium on Network and Distributed System Security (NDSS), 2014.
[9] Munmun De Choudhury, Yu-Ru Lin, Hari Sundaram, K Selcuk Candan, Lexing Xie, and Aisling Kelliher. How does the data sampling strategy impact the discovery of information diffusion in social media? In Proceedings of the International Conference of Weblogs and Social Media, 2010.
[10] Manuel Egele, Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna. COMPA: Detecting Compromised Accounts on Social Networks. In Proceedings of the Network and Distributed System Security Symposium (NDSS), 2013.
[11] Facebook. Guidelines for advertised products & services. https://www.facebook.com/help/399392800124391/, 2014.
[12] Hongyu Gao, Yan Chen, Kathy Lee, Diana Palsetia, and Alok Choudhary. Towards online spam filtering in social networks. In Symposium on Network and Distributed System Security (NDSS), 2012.
[13] Hongyu Gao, Jun Hu, Christo Wilson, Zhichun Li, Yan Chen, and Ben Y Zhao. Detecting and characterizing social spam campaigns. In Proceedings of the 10th ACM SIGCOMM conference on Internet measurement. ACM, 2010.
[14] Sharad Goel, Duncan J Watts, and Daniel G Goldstein. The structure of online diffusion networks. In Proceedings of the 13th ACM Conference on Electronic Commerce, 2012.
[15] C. Grier, L. Ballard, J. Caballero, N. Chachra, C.J. Dietrich, K. Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pitsillidis, et al. Manufacturing compromise: The emergence of exploit-as-a-service. In Proceedings of the ACM Conference on Computer and Communications Security (CCS), 2012.
[16] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @spam: The Underground on 140 Characters or Less. In Proceedings of the ACM Conference on Computer and Communications Security (CCS), 2010.
[17] Brian Krebs. Adobe breach impacted at least 38 million users. http://krebsonsecurity.com/2013/10/adobe-breach-impacted-at-least-38-million-users/, 2013.
[18] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. Graphs over time: densification laws, shrinking diameters and possible explanations. In Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, 2005.
[19] Miller McPherson, Lynn Smith-Lovin, and James M Cook. Birds of a feather: Homophily in social networks. Annual review of sociology, 2001.
[20] Fred Morstatter, Jurgen Pfeffer, Huan Liu, and Kathleen M Carley. Is the Sample Good Enough? Comparing Data from Twitter’s Streaming API with Twitter’s Firehose. In Proceedings of the International Conference of Weblogs and Social Media, 2013.
[21] Mark EJ Newman. Spread of epidemic disease on networks. Physical review E, 2002.
[22] Nicole Perlroth. Lax Security at LinkedIn Is Laid Bare. http://nyti.ms/1fRQIl4, 2012.
[23] Daniel M Romero, Brendan Meeder, and Jon Kleinberg. Differences in the mechanics of information diffusion across topics: Idioms, political hashtags, and complex contagion on Twitter. In Proceedings of the 20th international conference on World wide web, 2011.
[24] Stuart Staniford, Vern Paxson, and Nicholas Weaver. How to 0wn the Internet in Your Spare Time. In USENIX Security Symposium, 2002.
[25] Gianluca Stringhini, Gang Wang, Manuel Egele, Christopher Kruegel, Giovanni Vigna, Haitao Zheng, and Ben Y Zhao. Follow the Green: Growth and Dynamics in Twitter Follower Markets. In Proceedings of the 2013 conference on Internet measurement conference, 2013.
[26] Fred Tanneau. Twitter hacked! 250,000 user accounts breached. http://www.cnbc.com/id/100343530, 2013.
[27] Ke Tao, Fabian Abel, Claudia Hauff, Geert-Jan Houben, and Ujwal Gadiraju. Groundhog day: Near-duplicate detection on Twitter. In Proceedings of the 22nd international conference on World Wide Web, 2013.
[28] K. Thomas, C. Grier, V. Paxson, and D. Song. Suspended Accounts In Retrospect: An Analysis of Twitter Spam. In Proceedings of the Internet Measurement Conference, November 2011.
[29] Kurt Thomas and David M. Nicol. The Koobface botnet and the rise of social malware. In Proceedings of The 5th International Conference on Malicious and Unwanted Software (Malware 2010), 2010.
[30] C. Yang, R. Harkreader, J. Zhang, S. Shin, and G. Gu. Analyzing Spammers’ Social Networks for Fun and Profit: a Case Study of Cyber Criminal Ecosystem on Twitter. In Proceedings of the 21st International Conference on World Wide Web, 2012.
[31] Alison Young. FTC takes action against deceptive weight-loss products. http://www.usatoday.com/story/news/nation/2014/01/07/ftc-charges-deceptive-weight-loss-products/4354669/, 2014.