### Optimized Text

#### Performance Evaluation

**Request Handling and Configuration:**
- The CBASE parallelizer treats requests as independent.
- CBASE-FS operates with 16 threads, while unreplicated NFS runs with 16 daemon processes.
- In all file system instances, NFS servers write asynchronously to the disk.

**Overhead Analysis:**
- Figure 6(a) illustrates the response time versus throughput for CBASE-FS, BASE-FS, and unreplicated NFS.
- CBASE-FS and BASE-FS exhibit similar performance, with their throughput saturating around 2.5 MB/sec.

**Throughput with Multiple Disks:**
- Figure 7 compares the throughput of BASE-FS, CBASE-FS, and unreplicated NFS with one and two disks.
- With a single disk, CBASE-FS and BASE-FS show similar performance, but with two disks, CBASE-FS outperforms BASE-FS by 72% due to concurrent writing.
- Unreplicated NFS outperforms both CBASE-FS and BASE-FS by a factor of 1.5 with one disk and 2.5 with two disks, consistent with previous results.

**Iozone Micro-Benchmark:**
- Iozone [2] provides microbenchmarks to test commercial file systems.
- We run the write and random mix microbenchmarks to compare CBASE-FS and BASE-FS.
- Each file server accesses data on a remote disk via NFS, allowing for hardware parallelism.
- **Write Microbenchmark:**
  - Measures the performance of writing 256 KB of data to a new file.
  - BASE-FS saturates at about 160 KB/sec, while CBASE-FS saturates at 320 KB/sec, showing a 100% improvement.
  - CBASE-FS is limited by the remote disk bandwidth, achieving only a 2x improvement.
  - Unreplicated NFS achieves a maximum throughput of 500 KB/sec when running on the remote disk machine.
- **Random Mix Microbenchmark:**
  - Measures the performance of writing and reading 256 KB files with random access.
  - BASE-FS's throughput saturates at about 1 MB/sec, while CBASE-FS saturates at 2 MB/sec.
  - File caching improves the throughput of both systems, with CBASE-FS showing a 100% better performance than BASE-FS.

**Macro-Benchmarks:**
- We evaluate CBASE-FS and BASE-FS using the Andrew [11] and Postmark [3] benchmarks.
- **Andrew-100 Benchmark:**
  - Sequentially runs 100 copies of the Andrew benchmark, which is largely client-CPU-limited.
  - CBASE-FS and BASE-FS have nearly identical performance, with BASE-FS outperforming CBASE-FS by 4%.
- **Postmark Benchmark:**
  - Measures the performance of Internet applications like email, net news, and e-commerce.
  - Initially creates a pool of files and performs transactions (create, delete, read, append).
  - We run the benchmark with 100 files for 500 transactions.
  - In the read-mostly experiment, the read bias is set to 9, and in the write-mostly experiment, the read bias is set to 1.
  - CBASE-FS and BASE-FS replicas write to the remote disk to evaluate the benefits of concurrent execution.
  - Figure 8 shows that CBASE-FS and BASE-FS have nearly identical performance with one client.
  - With multiple clients, CBASE-FS is 20-25% faster than BASE-FS, limited by the single available hardware disk.

#### Related Work

- Extensive research exists on replication techniques for highly-available systems that tolerate failures.
- This study is the first to improve the throughput of a Byzantine fault-tolerant system by using application semantics to execute requests concurrently.
- Schneider [20] introduced the idea of reordering commutative requests in state machine replication, improving average response time but not throughput.
- Our approach generalizes this to identify and concurrently execute independent requests, thereby improving throughput.
- Byzantine fault-tolerant state machine replication has been well-studied [6, 10, 17], with recent work demonstrating practical implementations [8, 9].
- Optimizations like request batching, reduced communication, and symmetric encryption improve throughput but do not overcome the limits of sequential execution.
- Some systems support tentative execution for read requests, but our strategy applies to all types of requests and exploits both application-level and hardware-level parallelism.
- Farsite [5] and Oceanstore [18] use PBFT [8] for Byzantine fault tolerance, providing scalability through partitioning, but sequential execution within partitions limits throughput.

#### Conclusion

- This paper proposes a simple change to BFT state machine replication architectures to improve throughput by separating agreement from execution and introducing an application-specific parallelizer.
- CBASE, our system prototype, demonstrates significant performance improvements over existing systems, provided there is sufficient parallelism and hardware resources.
- Although focused on BFT state machine replication, the partial order property can be exploited in traditional state machine replication systems to improve throughput.

#### References

- [1] http://www.cert.org
- [2] http://www.iozone.org
- [3] http://www.netapp.com/tech-library/postmark.html
- [4] Nfs: Network file system protocol specification. Request for Comments 1094, Network Working Group, ISI, Mar. 1987.
- [5] A. Adya, W. Bolosky, M. Castro, R. Chaiken, G. Cermak, J. Douceur, J. Howell, J. Lorch, M. Theimer, and R. Wattenhofer. Farsite: Federated, available, and reliable storage for an incompletely trusted environment. In 5th Symp on Operating Systems Design and Impl., 2002.
- [6] R. Canetti and T. Rabin. Optimal Asynchronous Byzantine Agreement. Technical Report 92-15, Dept. of Computer Science, Hebrew University, 1992.
- [7] M. Castro. Practical Byzantine Fault Tolerance. PhD thesis, MIT, Jan. 2001.
- [8] M. Castro and B. Liskov. Practical byzantine fault tolerance. In 3rd Symp. on Operating Systems Design and Impl., Feb. 1999.
- [9] M. Castro and B. Liskov. Proactive recovery in a Byzantine-fault-tolerant system. In 4th Symp. on Operating Systems Design and Impl., pages 273–288, 2000.
- [10] J. Garay and Y. Moses. Fully Polynomial Byzantine Agreement for n(cid:0)3t Processors in t  1 Rounds. SIAM Journal of Compouting, 27(1), 1998.
- [11] J. Howard, M. Kazar, S. Menees, D. Nichols, M. Satyanarayanan, R. Sidebotham, and M. West. Scale and Performance in a Distributed File System. ACM Trans. on Computer Systems, 6(1):51–81, Feb. 1988.
- [12] R. Kotla. High throughput byzantine fault tolerant architecture. Master’s thesis, The Univ. of Texas, Austin, Dec. 2003.
- [13] R. Kotla and M. Dahlin. High throughput byzantine fault tolerance. Technical Report UTCS-TR-03-58, The Univ. of Texas, Austin, 2003.
- [14] L. Lamport. Part-time parliament. ACM Trans. on Computer Systems, 16(2), May 1998.
- [15] B. Liskov, S. Ghemawat, R. Gruber, P. Johnson, L. Shrira, and M. Williams. Replication in the Harp File System. In 13th ACM Symp. on Operating Systems Principles, Oct. 1991.
- [16] D. Mazires. A toolkit for user-level file systems. In USENIX Annual Technical Conference, pages 261–274, June 2001.
- [17] M. Reiter. The Rampart toolkit for building high-integrity services. In Dagstuhl Seminar on Dist. Sys., pages 99–110, 1994.
- [18] S. Rhea, P. Eaton, D. Geels, H. Weatherspoon, B. Zhao, and J. Kubiatowicz. Pond: the oceanstore prototype. In 2nd Usenix Conf on File and Storage Technologies, March 2003.
- [19] R. Rodrigues, M. Castro, and B. Liskov. BASE: Using abstraction to improve fault tolerance. In 18th ACM Symp. on Operating Systems Principles, Oct. 2001.
- [20] F. Schneider. Implementing Fault-tolerant Services Using the State Machine Approach: A tutorial. Computing Surveys, 22(3):299–319, Sept. 1990.
- [21] U. Voges and L. Gmeiner. Software diversity in reacter protection systems: An experiment. In IFAC Workshop SAFECOMP79, May 1979.
- [22] M. Welsh, D. Culler, and E. Brewer. SEDA: An architecture for well-conditioned, scalable internet services. In 18th ACM Symp. on Operating Systems Principles, pages 230–243, 2001.
- [23] J. Yin, J. Martin, A. Venkataramani, L. Alvisi, and M. Dahlin. Separating agreement from execution for byzantine fault-tolerant services. In 19th ACM Symp. on Operating Systems Principles, Oct. 2003.