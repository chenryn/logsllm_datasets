以下是优化后的文本，使其更加清晰、连贯和专业：

---

**参考文献**

[15] I. Chalkidis, M. Fergadiotis, P. Malakasiotis, 和 I. Androutsopoulos, “大规模多标签文本分类在欧盟立法中的应用,” 在 ACL, 2019.

[16] Z. Dai, Z. Yang, Y. Yang, J. G. Carbonell, Q. V. Le, 和 R. Salakhutdinov, “Transformer-XL: 超越固定长度上下文的注意力语言模型,” 在 ACL, 2019.

[17] J. Devlin, M.-W. Chang, K. Lee, 和 K. Toutanova, “BERT: 深度双向变换器的预训练以实现语言理解,” 在 NAACL-HLT, 2018.

[18] A. Dosovitskiy 和 T. Brox, “使用卷积网络反转视觉表示,” CVPR, 第 4829–4837 页, 2016.

[19] V. Duddu, D. Samanta, D. V. Rao, 和 V. E. Balas, “通过时间侧信道窃取神经网络,” ArXiv, 卷号 abs/1812.11720, 2018.

[20] C. Dwork 和 A. Roth, “差分隐私的算法基础,” 理论计算机科学的基础与趋势, 卷 9, 第 211–407 页, 2014.

[21] M. Fredrikson, S. Jha, 和 T. Ristenpart, “利用置信信息的模型反演攻击及其基本对策,” 在 CCS, 2015.

[22] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, 和 T. Ristenpart, “药理遗传学中的隐私: 个性化华法林剂量的端到端案例研究,” 卷 2014, 第 17–32 页, 2014.

[23] K. Ganju, Q. Wang, W. Yang, C. A. Gunter, 和 N. Borisov, “使用置换不变表示对全连接神经网络进行属性推断攻击,” 在 CCS, 2018.

[24] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. E. Lauter, M. Naehrig, 和 J. R. Wernsing, “Cryptonets: 应用于加密数据的高吞吐量和准确性的神经网络,” 在 ICML, 2016.

[25] I. Goodfellow, Y. Bengio, 和 A. Courville, 深度学习. MIT Press, 2016, http://www.deeplearningbook.org.

[26] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. C. Courville, 和 Y. Bengio, “生成对抗网络,” 在 NIPS, 2014.

[27] I. J. Goodfellow, J. Shlens, 和 C. Szegedy, “解释和利用对抗性示例,” ArXiv, 卷号 abs/1412.6572, 2014.

[28] W. Guo, J. Shao, R. Lu, Y. Liu, 和 A. A. Ghorbani, “云环境中的隐私保护在线医疗预诊断方案,” IEEE Access, 卷 6, 第 48946–48957 页, 2018.

[29] M. Hardt, E. Price, 和 N. Srebro, “监督学习中的机会平等,” 在 NIPS, 2016.

[30] M. Humbert, E. Ayday, J.-P. Hubaux, 和 A. Telenti, “解决缺乏家族的担忧: 量化亲属基因组隐私,” 在 CCS, 2013.

[31] ——, “量化基因组隐私中的相互依赖风险,” ACM Trans. Priv. Secur., 卷 20, 第 3:1–3:31 页, 2017.

[32] S. Ioffe 和 C. Szegedy, “批量归一化: 通过减少内部协变量偏移来加速深度网络训练,” ArXiv, 卷号 abs/1502.03167, 2015.

[33] N. Japkowicz 和 S. Stephen, “类别不平衡问题: 系统性研究,” Intell. Data Anal., 卷 6, 第 429–449 页, 2002.

[34] Y. Ji, X. Zhang, S. Ji, X. Luo, 和 T. Wang, “针对深度学习系统的模型重用攻击,” 在 CCS, 2018.

[35] J. Jia 和 N. Z. Gong, “AttriGuard: 通过对抗机器学习防御属性推理攻击,” ArXiv, 卷号 abs/1805.04810, 2018.

[36] A. Jochems, T. Deist, I. E. Naqa, M. L. Kessler, C. Mayo, J. Reeves, S. Jolly, M. Matuszak, R. T. Haken, J. van Soest, C. J. G. Oberije, C. Faivre-Finn, G. J. Price, D. K. M. D. Ruysscher, P. Lambin, 和 A. Dekker, “通过跨三个国家的分布式学习开发和验证 NSCLC 患者的生存预测模型,” 在国际放射肿瘤学、生物学、物理学杂志, 2017.

[37] A. Jochems, T. Deist, J. van Soest, M. J. Eble, P. Bulens, P. A. Coucke, W. J. F. Dries, P. Lambin, 和 A. Dekker, “分布式学习: 基于多个医院的数据开发预测模型而不让数据离开医院——一个现实生活中的概念验证.” 放射治疗与肿瘤学: 欧洲治疗放射学会和肿瘤学杂志, 卷 121 3, 第 459–467 页, 2016.

[38] D. Jurafsky, “语音和语言处理,” 2006.

[39] D. P. Kingma 和 J. Ba, “Adam: 一种随机优化方法,” ArXiv, 卷号 abs/1412.6980, 2014.

[40] R. Kiros, Y. Zhu, R. Salakhutdinov, R. S. Zemel, R. Urtasun, A. Torralba, 和 S. Fidler, “跳过思想向量,” 在 NIPS, 2015.

[41] G. Lample 和 A. Conneau, “跨语言语言模型预训练,” ArXiv, 卷号 abs/1901.07291, 2019.

[42] Q. V. Le 和 T. Mikolov, “句子和文档的分布式表示,” ArXiv, 卷号 abs/1405.4053, 2014.

[43] B. Lee, T. Lee, B. Na, 和 S. Yoon, “基于深度循环神经网络的 DNA 级别剪接位点预测,” ArXiv, 卷号 abs/1512.05135, 2015.

[44] Y. Liu, M. Ott, N. Goyal, J. Du, M. S. Joshi, D. Chen, O. Levy, M. Lewis, L. S. Zettlemoyer, 和 V. Stoyanov, “RoBERTa: 一种鲁棒优化的 BERT 预训练方法,” ArXiv, 卷号 abs/1907.11692, 2019.

[45] F. MASTEROPPGAVE 和 Ø. Johansen, “使用人工神经网络进行基因剪接位点预测,” 2008.

[46] H. B. McMahan, E. Moore, D. Ramage, S. Hampson, 和 B. A. y Arcas, “从分散数据中高效学习深度网络,” 在 AISTATS, 2016.

[47] L. Melis, C. Song, E. D. Cristofaro, 和 V. Shmatikov, “利用协作学习中的无意特征泄漏,” 在 Security & Privacy, 2019.

[48] E. M. E. Mhamdi, R. Guerraoui, 和 S. Rouault, “拜占庭式分布式学习中的隐藏漏洞,” 在 ICML, 2018.

授权许可仅限于: 清华大学。下载时间为 2021 年 3 月 19 日 10:19:28 UTC 从 IEEE Xplore。适用限制。

[49] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, 和 J. Dean, “词和短语的分布式表示及其组合性,” 在 NIPS, 2013.

[50] M. Nasr, R. Shokri, 和 A. Houmansadr, “使用对抗正则化的成员隐私机器学习,” 在 CCS, 2018.

[51] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, 和 A. Lerer, “PyTorch 中的自动微分,” 2017.

[52] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, 和 L. S. Zettlemoyer, “深度上下文化的词表示,” ArXiv, 卷号 abs/1802.05365, 2018.

[53] P. Pollastro 和 S. Rampone, “HS3D: 人类剪接位点数据集,” 2002.

[54] A. Radford, “通过生成预训练改进语言理解,” 2018.

[55] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, 和 I. Sutskever, “语言模型是无监督的多任务学习者,” 2019.

[56] H. E. Robbins, “一种随机逼近方法,” 2007.

[57] S. Salamatian, A. Zhang, F. du Pin Calmon, S. Bhamidipati, N. Fawaz, B. Kveton, P. Oliveira, 和 N. Taft, “管理您的私有和公共数据: 减少针对您隐私的推理攻击,” IEEE 信号处理选题期刊, 卷 9, 第 1240–1255 页, 2015.

[58] A. Salem, A. Bhattacharyya, M. Backes, M. Fritz, 和 Y. Zhang, “更新泄露: 在线学习中的数据集推理和重建攻击,” ArXiv, 卷号 abs/1904.01067, 2019.

[59] A. Salem, Y. Zhang, M. Humbert, P. Berrang, M. Fritz, 和 M. Backes, “ML-Leaks: 与模型和数据无关的成员推理攻击及防御,” ArXiv, 卷号 abs/1806.01246, 2018.

[60] G. Salton 和 C. Buckley, “自动文本检索中的术语加权方法,” 信息处理与管理, 卷 24, 第 513–523 页, 1988.

[61] G. Shen, K. Dwivedi, K. Majima, T. Horikawa, 和 Y. Kamitani, “从人脑活动中端到端重建图像,” 在 Front. Comput. Neurosci., 2019.

[62] R. Shetty, B. Schiele, 和 M. Fritz, “通过对抗训练神经机器翻译实现作者属性匿名,” 在 USENIX 安全研讨会, 2017.

[63] R. Shokri, M. Stronati, C. Song, 和 V. Shmatikov, “针对机器学习模型的成员推理攻击,” 安全与隐私, 第 3–18 页, 2017.

[64] R. Shokri, G. Theodorakopoulos, J.-Y. L. Boudec, 和 J.-P. Hubaux, “量化位置隐私,” 安全与隐私, 第 247–262 页, 2011.

[65] S. S. Shringarpure 和 C. D. Bustamante, “从基因组数据共享信标中产生的隐私风险.” 美国人类遗传学杂志, 卷 97 5, 第 631–46 页, 2015.

[66] L. Song, R. Shokri, 和 P. Mittal, “保护机器学习模型免受对抗示例攻击的隐私风险,” ArXiv, 卷号 abs/1905.10291, 2019.

[67] Y. Sun, S. Wang, Y. Li, S. Feng, H. Tian, H. Wu, 和 H. Wang, “ERNIE 2.0: 一种持续预训练的语言理解框架,” ArXiv, 卷号 abs/1907.12412, 2019.

[68] I. Sutskever, O. Vinyals, 和 Q. V. Le, “使用神经网络进行序列到序列学习,” 在 NIPS, 2014.

[69] D. Tang, Y. Zhao, 和 T. Liu, “使用门控循环神经网络进行情感分类的文档建模,” 在 EMNLP, 2015.

[70] F. Tramèr, F. Zhang, A. Juels, M. K. Reiter, 和 T. Ristenpart, “通过预测 API 窃取机器学习模型,” ArXiv, 卷号 abs/1609.02943, 2016.

[71] V. N. Vapnik, “统计学习理论的本质,” 在工程和信息科学统计学, 1995.

[72] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, 和 I. Polosukhin, “注意力就是你所需要的,” 第 5998–6008 页, 2017.

[73] B. Wang 和 N. Z. Gong, “窃取机器学习中的超参数,” 安全与隐私, 第 36–52 页, 2018.

[74] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf, M. Funtowicz, 和 J. Brew, “HuggingFace 的 Transformers: 最先进的自然语言处理,” ArXiv, 卷号 abs/1910.03771, 2019.

[75] Y. Wu 和 M. S. 等, “Google 的神经机器翻译系统: 缩小人类与机器翻译之间的差距,” ArXiv, 卷号 abs/1609.08144, 2016.

[76] Z. Yang, Z. Dai, Y. Yang, J. G. Carbonell, R. Salakhutdinov, 和 Q. V. Le, “XLNet: 通用自回归预训练以实现语言理解,” ArXiv, 卷号 abs/1906.08237, 2019.

[77] Z. Yang, J. Zhang, E.-C. Chang, 和 Z. Liang, “在对抗环境下通过背景知识对齐进行神经网络反演,” 在 CCS, 2019.

[78] S. Yeom, I. Giacomelli, M. Fredrikson, 和 S. Jha, “机器学习中的隐私风险: 分析与过拟合的联系,” CSF, 第 268–282 页, 2017.

[79] L. Yu, W. Zhang, J. Wang, 和 Y. Yu, “SeqGAN: 带有策略梯度的序列生成对抗网络,” ArXiv, 卷号 abs/1609.05473, 2016.

[80] Y. Zhang, M. Humbert, T. A. Rahman, C.-T. Li, J. Pang, 和 M. Backes, “Tagvisor: 一个分享标签的隐私顾问,” WWW, 2018.

[81] Y. Zhang, X. Liu, J. N. MacLeod, 和 J. Liu, “从 RNA-seq 对齐中辨别新的剪接位点: 一种深度学习方法,” 在 BMC 基因组学, 2018.

[82] L. Zhu, Z. Liu, 和 S. Han, “从梯度中泄露深度信息,” 在 NeurIPS, 2019.

---

### 附录

#### A. 实用模型的实现

图 8. (a) 基因组和 (b) 医疗基准系统的效用。

1. **基因组**: 我们基于一个名为 HS3D（智人剪接位点数据集）的公开基因组数据集实现了八个基因组分类系统，用于剪接位点预测。简而言之，剪接位点预测是一个二分类任务，旨在确定目标核苷酸序列是否包含某些功能单元。为了构建基准系统，我们首先从 HS3D 数据集中准备了一个数据集，该数据集包括 28800 个负样本（2880 个正样本）用于训练，以及 1000 个样本（1000 个正样本）用于测试。所有基因组序列的长度均为 20。每个系统由一个预训练的语言模型用于特征提取和一个具有 200 个隐藏单元和 sigmoid 激活函数的三层 MLP 组成。图 8(a) 报告了我们的基准系统在结合不同语言模型时的效用（准确性），其中相对于随机猜测的非平凡优势表明了它们的有效性。

2. **医疗**: 我们基于 CMS 公共医疗记录实现了八个预诊断系统。这些系统旨在根据患者的疾病描述将其引导至适当的部门。预处理的数据集包含来自 10 个医疗部门（如骨科手术、麻醉学、皮肤病学等）的 120,000 条疾病描述。我们将预诊断任务建模为 10 类分类，并将系统实现为预训练语言模型与具有 200 个隐藏单元和 sigmoid 激活函数的三层 MLP 的组合。图 8(b) 中的分类准确性高度展示了我们基准系统的效用。

#### B. 基因组攻击模型的实现细节

在实践中，我们发现如果只使用嵌入和相应的核苷酸类型对来训练针对第 i 个核苷酸的攻击模型是无效的。我们推测这可能是由于训练样本本身包含的信息不足。考虑序列 ACGT AACT 的例子，攻击者的目标是第四位核苷酸。如果我们只提供学习模型其嵌入和类型 T，那么攻击模型实际上无法知道学习目标是推断尾部的 T 还是其他位置的 T。为了解决这个问题，我们提出通过添加关于目标位置的辅助信息来增强训练对 (z, wi)，形式为位置嵌入 pi 表示目标位置 i。基本上，我们将生成样本的嵌入 z 与位置 i 的位置嵌入 pi 连接起来。正式地，我们使用 [72] 中定义的正弦位置嵌入，定义为 pi,2k = sin (i/10000^(2k/dpos)), pi,2k+1 = cos (i/10000^((2k+1)/dpos))，其中 pi,2k 表示 pi 的第 2k 个坐标，dpos 是其维度。在我们的实现中，我们将 dpos 设置为 z 的维度。相应地，我们实现了一个单一的攻击模型来推断任何指定位置的核苷酸类型。不同于 Citizen 案例，这种修改不会增加参数数量，因为类的数量仍然是 4。攻击模型实现为一个三层 MLP，输入 z ⊕ pi 维度为 2d，具有 200 个隐藏单元和 sigmoid 激活函数，并带有中间批量归一化层 [32] 以加快收敛速度。对于训练，我们生成大小为 128 的小批量，由元组 (z, pi, wi) 组成，其中位置嵌入 i 从可能的位置区间（即 1, ..., 20）中随机采样。对于推理，攻击者输入受害者的嵌入和目标位置，模型输出预测的核苷酸类型。

#### C. 防御措施的省略细节

**拉普拉斯机制**：对于第二种防御，我们采用差分隐私方法进行缓解。具体来说，我们应用 [20] 中介绍的拉普拉斯机制来保护原始嵌入不被泄露。简单地说，拉普拉斯机制通过对嵌入进行逐坐标扰动，扰动值从拉普拉斯分布中采样，其参数由语言模型的 L1 敏感度决定。形式上，我们提出的基于 DP 的防御为 ˆz = Dlap,f,ε(z) .= z + (Y1, ..., Yd)，其中 Yi 是从 Lap(Δf / ε) 中独立同分布抽取的随机样本，Laplace 分布的位置为 0，尺度为 Δf / ε。这里 Δf 表示语言模型的 L1 敏感度，定义为 Δf = max_x,x' ∈ N|V|, x - x' = 1 ||f(x) - f(x')||_1，其中 x 和 x' 是仅在一个位置不同的句子。直观上，拉普拉斯机制使得对手更难从嵌入中区分出由一个单词改变引起的变化，从而直接防御模式重建攻击和关键词推理攻击。理论上可以证明，受保护的语言模型 Dlap,f,ε ◦ f 是 (ε, 0)-差分隐私的。在实践中，我们通过生成 10,000 对 (x, x') 通过单词替换、查询语言模型并根据定义计算 Δf 来估计每个语言模型的 L1 敏感度。数值结果见表 IV。然而，仍然存在许多理论挑战，例如如何限定估计 L1 敏感度的误差，这将是未来值得追求的一个有意义的方向。

**表 IV. 每种语言模型的估计 L1 敏感度及查询一个训练批次的时间成本**

| 名称 | 估计 Δf | 查询时间 (秒) |
| --- | --- | --- |
| BERT | 81.82 | 0.577 |
| Transformer-XL | 17.09 | 0.577 |
| XLNet | 601.5 | 0.577 |
| GPT | 73.19 | 0.577 |
| GPT-2 | 110.2 | 0.577 |
| RoBERTa | 4.15 | 0.577 |
| XLM | 219.4 | 0.577 |
| ERNIE 2.0 | 28.20 | 0.577 |

---