### Cache Replacement Policies and Their Impact on Measurements

In our experiments, we observed that Sandy Bridge CPUs consistently utilized the Least Recently Used (LRU) policy. However, Ivy Bridge processors exhibited a more dynamic behavior, with some cache sets operating in LRU mode and others in Bounded Inclusion Policy (BIP) mode. This suggests a "set dueling" mechanism, where the two policies are compared in real-time to determine which one generates fewer cache misses. Haswell and Broadwell CPUs frequently switched between these policies, but we did not observe any instances where both policies were simultaneously active in different cache sets.

We hypothesize that Haswell and newer CPUs employ a more sophisticated method to choose the optimal cache replacement policy, rather than simple set dueling. The choice of policy significantly impacted our measurements, as the BIP policy complicates the priming and probing steps. Priming becomes more challenging because sequentially accessing all entries in the eviction set does not bring the cache into a known state—some entries used by the victim process may still be in the cache set. Consequently, the probing step may incorrectly indicate that the victim has accessed the cache set during a specific time period. These combined effects act as a low-pass filter on the memorygram, reducing our temporal resolution by up to a factor of 16. To avoid triggering the switch to BIP, we designed our attack code to minimize cache misses in benign cases. We achieved this by using a zig-zag access pattern (as suggested by Osvik et al. [19]) and actively pruning our measurement data set to remove overly active cache sets.

### Noise Effects

#### Sources
Side-channel attacks must contend with three general categories of noise: electronic, switching, and quantization (or measurement). Electronic noise, or thermal noise, is inherent in any physical system but is less prevalent in our setup due to its relatively low resolution. Switching noise arises from the fact that measurements capture not only the victim's secret information but also other activities on the device, either correlated or uncorrelated with the measurement. In our case, this noise is caused by spurious cache events due to background process activity, as well as the cache activity of the attack code and the underlying JavaScript runtime. Quantization noise refers to inaccuracies introduced by the measurement apparatus. For us, this can be caused by the limited resolution of the JavaScript performance counter or by low-level events such as context switches that occur while the measurement code is running. It should be noted that, except for timer granularity, all sources of noise in our system are additive, meaning they will only cause a measurement to take longer.

#### Effects
There are two main elements of our attack that can be affected by noise: the cache profiling process, where eviction sets are created, and the online step, where individual cache sets are probed. Noise during the profiling process, particularly during steps (1.b) and (1.e) of Algorithm 1, can cause the algorithm to erroneously include or exclude a memory address from an eviction set. Noise during the online step can lead to incorrect detection of activity on a cache set when there is none, or to associating cache activity with a victim process when it was actually caused by another source. Interestingly, one significant source of switching noise is the measurement process itself, as creating a memorygram involves millions of measurements over a short period, which has a considerable impact on the cache.

#### Mitigations
To quantify the prevalence of measurement noise in our system, we measured the proportion of cache misses in an area with no cache activity. We found that approximately 0.3% of cache hits were mis-detected as cache misses due to timing jitter, primarily caused by context switches during the measurement process. Such events are easy to detect because the returned time exceeds the OS multitasking quantum (10ms on our system). However, to keep our measurement loop simple, we did not apply this logic in our actual attack. To address the limited resolution of the timer on some targets, we could use the workarounds suggested in the previous section or find an alternative form of time-taking that does not rely on JavaScript’s built-in timer API. Timing jitter was generally not influenced by CPU-intensive background activities, but memory-intensive activities, such as file transfers or video encoding, caused a large amount of switching noise and significantly degraded the effectiveness of our attack. To mitigate the switching noise caused by our measurement code, we spread out our data structures so that they occupied only the first 64 bytes of every 4KB block of memory, ensuring that at most 1/64 of the cache was affected by the construction of the memorygram.

Another source of noise was Intel’s Turbo Boost feature, which dynamically varied our CPU clock speed between 2.5 GHz and 3.2 GHz. This changed the cache hit timings on our CPU, making it difficult to detect cache misses. To mitigate this effect, we periodically estimated the cache hit time (by measuring the access time of a cache set immediately after priming it) and measured cache misses against this baseline.

### Additional Attack Vectors

The general mechanism we presented in this paper can be used for various purposes beyond the attack we described. Below, we survey a few interesting directions.

#### KASLR Derandomization
Kernel control-flow hijacking attacks often rely on pre-existing code deployed by the OS. By forcing the OS kernel to jump to this code (e.g., by exploiting a memory corruption vulnerability that overwrites control data), attackers can take over the entire system [12]. A common countermeasure is Kernel Address Space Layout Randomization (KASLR), which shifts kernel code by a random offset, making it harder for an attacker to hard-code a jump to kernel code in their exploits. Hund et al. showed that probing the Last-Level Cache (LLC) can help defeat this randomization countermeasure [10].

We demonstrated that LLC probing can also be carried out in JavaScript, implying that the attack by Hund et al. can be executed by an untrusted webpage. Such attacks are particularly suited to our attacker model, especially drive-by exploits that attempt to profile and then infect users with tailored malware. The derandomization method we present can be used to bootstrap a drive-by exploit, dividing the attack into two phases. In the first phase, an unprivileged JavaScript function profiles the system and discovers the address of a kernel data structure. Next, the JavaScript code connects to the web server again and downloads a tailored exploit for the running kernel.

Note that cache sets are not directly mappable to virtual addresses, especially in JavaScript, where pointers are not available. An additional building block used by Hund et al., which is not available to us, is the call to `sysenter` with an unused syscall number. This call resulted in a very quick and reliable trip into the kernel, allowing efficient measurements [10].

#### Secret State Recovery
Cache-based key recovery has been widely discussed in the scientific community. In the context of browser-based cache attacks, the adversary may be interested in discovering the user’s TLS session key, any VPN or IPSec keys used by the system, or the secret key used by the system’s disk encryption software. There are additional secret state elements that are even more relevant in network attacks. One such secret is the sequence number in an open TCP session. Discovering this value enables traffic injection and session hijacking attacks.

### Countermeasures

The attacks described in this paper are possible due to a combination of design and implementation decisions at the micro-architectural level and the JavaScript runtime. Mitigation steps can be applied at each of these junctions, but each will have drawbacks for the benign uses of the system.

At the micro-architectural level, changes to the way physical memory addresses are mapped to cache lines will severely confound our attack, which relies heavily on the fact that 6 out of the lower 12 bits of an address are used directly to select a cache set. Similarly, moving to an exclusive cache micro-architecture instead of an inclusive one will make it impossible for our code to trivially evict entries from the L1 cache, resulting in less accurate measurements. These design decisions were chosen to make the CPU more efficient, and changing them would exact a performance cost on many applications. Additionally, modifying a CPU’s micro-architecture is non-trivial and impossible as an upgrade to already deployed hardware.

At the JavaScript level, reducing the resolution of the high-resolution timer would make our attack more difficult to launch. However, the high-resolution timer was created to address a real need of JavaScript developers for applications ranging from music and games to augmented reality. A possible stopgap measure would be to restrict access to this timer to applications that gain the user’s consent (e.g., by displaying a confirmation window) or the approval of a third party (e.g., downloaded from a trusted “app store”).

An interesting approach could be the use of heuristic profiling to detect and prevent this specific kind of attack. Just as the abundance of arithmetic and bitwise instructions used by Wang et al. [28] indicated the presence of cryptographic primitives, the various steps of our attack access memory in a very particular pattern. Since modern JavaScript runtimes already scrutinize the runtime performance of code as part of their profile-guided optimization mechanisms, it could be possible for the JavaScript runtime to detect profiling-like behavior and modify its response accordingly (e.g., by jittering the high-resolution timer or dynamically moving arrays around in memory).

### Conclusion

We demonstrated how a micro-architectural, side-channel cache attack, already recognized as an extremely potent attack method, can be effectively launched from an untrusted webpage. Instead of traditional cryptanalytic applications, we showed how user behavior can be successfully tracked using our methods. The potential reach of side-channel attacks has been extended, meaning that additional classes of systems must be designed with side-channel countermeasures in mind.

### Acknowledgments

We are grateful to Yinqian Zhang, our shepherd, and the anonymous reviewers for their valuable comments. We also thank Kiril Tsemekhman and Jason Shaw for providing interesting directions regarding this research. This work was supported by the Office of Naval Research (ONR) through Contract N00014-12-1-0166. Any opinions, findings, conclusions, or recommendations expressed herein are those of the authors and do not necessarily reflect those of the US Government or ONR.

### References

[1] O. Aciiçmez. Yet Another MicroArchitectural Attack: Exploiting I-Cache. In Proc. of ACM CSAW, pages 11–18, 2007.
[2] G. I. Apecechea, M. S. Inci, T. Eisenbarth, and B. Sunar. Wait a Minute! A fast, Cross-VM Attack on AES. In Proc. of RAID, pages 299–319, 2014.
[3] D. J. Bernstein. Cache-timing attacks on AES. http://cr.yp.to/papers.html#cachetiming, April 2005. [Online; accessed August-2015].
[4] D. Brumley and D. Boneh. Remote Timing Attacks are Practical. In Proc. of USENIX Sec., pages 1–14, 2005.
[5] Ecma International. Standard ECMA-262: ECMAScript Language Specification. http://www.ecma-international.org/ecma-262/5.1/index.html, June 2011. [Online; accessed August-2015].
[6] T. Eisenbarth, T. Kasper, A. Moradi, C. Paar, M. Salmasizadeh, and M. T. M. Shalmani. On the Power of Power Analysis in the Real World: A Complete Break of the KEELOQ Code Hopping Scheme. In Proc. of CRYPTO, pages 203–220, 2008.
[7] D. Herman and K. Russell. Typed Array Specification. https://www.khronos.org/registry/typedarray/specs/latest/, July 2013. [Online; accessed August-2015].
[8] G. Ho, D. Boneh, L. Ballard, and N. Provos. Tick Tock: Building Browser Red Pills from Timing Side Channels. In Proc. of WOOT, 2014.
[9] W. Hu. Lattice Scheduling and Covert Channels. In Proc. of IEEE S&P, pages 52–61, 1992.
[10] R. Hund, C. Willems, and T. Holz. Practical Timing Side Channel Attacks Against Kernel Space ASLR. In Proc. of IEEE S&P, pages 191–205, 2013.
[11] S. Jana and V. Shmatikov. Memento: Learning Secrets from Process Footprints. In Proc. of IEEE S&P, pages 143–157, 2012.
[12] V. P. Kemerlis, M. Polychronakis, and A. D. Keromytis. ret2dir: Rethinking Kernel Isolation. In Proc. of USENIX Sec, pages 957–972, 2014.
[13] P. C. Kocher. Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems. In Proc. of CRYPTO, pages 104–113, 1996.
[14] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee. Last-Level Cache Side-Channel Attacks are Practical. In Proc. of IEEE S&P, pages 605–622, 2015.
[15] S. Mangard, E. Oswald, and T. Popp. Power Analysis Attacks: Revealing the Secrets of Smart Cards. Springer, 2007.
[16] J. Mann. High Resolution Time. http://www.w3.org/TR/hr-time/, December 2012. [Online; accessed August-2015].
[17] C. Maurice, C. Neumann, O. Heen, and A. Francillon. C5: Cross-Cores Cache Covert Channel. In Proc. of DIMVA, pages 46–64, 2015.
[18] Y. Oren, M. Kirschbaum, T. Popp, and A. Wool. Algebraic side-channel analysis in the presence of errors. In Proc. of CHES, pages 428–442, 2010.
[19] D. A. Osvik, A. Shamir, and E. Tromer. Cache Attacks and Countermeasures: The Case of AES. In Proc. of CT-RSA, pages 1–20, 2006.
[20] D. Oswald and C. Paar. Breaking Mifare DESFire MF3ICD40: Power Analysis and Templates in the Real World. In Proc. of CHES, pages 207–222, 2011.
[21] C. Percival. Cache Missing for Fun and Profit. In Proc. of BSDCan, 2005.
[22] N. Provos, P. Mavrommatis, M. A. Rajab, and F. Monrose. All Your iFRAMEs Point to Us. In Proc. of USENIX Sec., pages 1–15, 2008.
[23] M. K. Qureshi, A. Jaleel, Y. N. Patt, S. C. S. Jr., and J. Emer. Adaptive Insertion Policies for High Performance Caching. In Proc. of ISCA, pages 381–391, 2007.
[24] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage. Hey, You, Get Off of My Cloud: Exploring Information Leakage in Third-Party Compute Clouds. In Proc. of CCS, pages 199–212, 2009.
[25] K. A. Shutemov. pagemap: do not leak physical addresses to non-privileged userspace. https://lwn.net/Articles/642074/, March 2015. [Online; accessed August-2015].
[26] StatCounter. GlobalStats. http://gs.statcounter.com, January 2015. [Online; accessed August-2015].
[27] W3C. Javascript APIs Current Status. http://www.w3.org/standards/techs/js. [Online; accessed August-2015].
[28] Z. Wang, X. Jiang, W. Cui, X. Wang, and M. Grace. ReFormat: Automatic Reverse Engineering of Encrypted Messages. In Proc. of ESORICS, pages 200–215, 2009.
[29] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart. Cross-VM Side Channels and Their Use to Extract Private Keys. In Proc. of CCS, pages 305–316, 2012.
[30] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart. Cross-Tenant Side-Channel Attacks in PaaS Clouds. In Proc. of ACM CCS, pages 990–1003, 2014.