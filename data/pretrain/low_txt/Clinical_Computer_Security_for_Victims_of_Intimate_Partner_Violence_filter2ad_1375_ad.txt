### Obtaining Client Consent and Data Collection

We obtained the client’s verbal consent to participate in the study. Additionally, we requested permission to audio record the consultations for data collection purposes. Out of 46 consultations, we received permission to record 36. For participants who did not consent to audio recording, we took detailed handwritten notes.

### Consultation Procedure

After obtaining the client’s consent, we followed the consultation procedure outlined in Section 4. This included:
- Administering the Technology Abuse Questionnaire (TAQ)
- Constructing a technograph
- Scanning the client’s devices with ISDi
- Performing manual privacy configuration checks

We also suggested that it might be beneficial for the client to have their case manager or another Intimate Partner Violence (IPV) professional present during the consultation to assist with safety planning and documenting relevant findings. In total, 16 out of 44 clients had a professional present during their consultation. After completing all procedures and discussing the findings with the client (and the professional, if present), we thanked the client for their time. For clients requiring follow-up, we discussed the nature of the follow-up and confirmed the relevant professional to contact once the follow-up was complete.

### Data Collection and Analysis

We collected detailed handwritten notes and audio recordings (when permitted) to document each consultation. This included:
- Client answers to TAQ questions
- Discussion of their digital footprint
- Details of manual privacy checks
- Results from ISDi device scans
- Advice or recommendations discussed with the client
- Any follow-up actions

All audio recordings were professionally transcribed and collated with the relevant handwritten notes, completed technographs, and ISDi data. We manually reviewed this data multiple times to carefully summarize each consultation and produce the descriptive and aggregate statistics presented in Section 7. The data was stored securely, with access limited to the subset of the research team responsible for analysis.

### Safety Protocols

Given the sensitive nature of IPV research, our procedures were designed to protect clients’ privacy and safety. For example, we did not ask participants to sign a consent form to avoid collecting identifying information. All communication with clients was conducted through the referring professional, including scheduling and any post-consultation follow-ups.

Although we provided participants with various printed handouts to help them understand their digital safety and privacy, we explained the potential risks of taking such materials home, especially if they still lived with their abuser. Changing privacy settings or uninstalling surveillance apps could lead to dangerous escalation of abuse. Therefore, we encouraged participants to have a trusted IPV professional present during the consultation. When this was not possible, we ensured that another experienced case worker was available to help develop safety plans and discuss new protection strategies.

We also prioritized the safety and well-being of our research team. Our training included ways to balance the need to inform participants about our affiliation while avoiding the disclosure of detailed identifying information. For example, we introduced ourselves by first name only due to the risk of spyware on devices recording conversations. Additionally, working with IPV survivors can be mentally and emotionally challenging. We regularly met as a team after consultations to debrief and encouraged team members to discuss their feelings and experiences. An experienced IPV case worker was always available to support researchers and help them process any upsetting experiences.

### Results of the Field Study

The primary goal of our study was to evaluate the utility of our consultation protocol for IPV victims. Our tools and instruments uncovered significant, potentially dangerous security issues that we discussed with clients and professionals. While our preliminary data suggests that our consultation protocol provides benefits, the small sample size from a single city means that our results should not be interpreted as statistically representative of problems faced by IPV survivors. We discuss the limitations of our results in Section 8.

To maintain client anonymity, we cannot report on the full details of our consultations. Instead, we provide aggregate results and discuss specific situations in a way that aligns with widely reported IPV technology abuse scenarios, as per prior work [8, 14, 19, 20, 27, 35, 43] and our experiences.

#### Participants and Devices

We conducted 46 consultations with 44 IPV survivors (43 female, 1 male) who were all clients at the Family Justice Centers (FJCs). Two clients received second consultations to scan additional devices. All participants were adults, and one still lived with their abuser.

As shown in Figure 3 (left table), clients brought a total of 105 devices to the consultations. Of these, 82 were Android or iOS devices, and we scanned 75 with ISDi. Two unscanned devices were iPhone Xs, which initially caused an error in ISDi due to changes in Apple's device ID format (subsequently fixed). In two cases, ISDi could not scan very old iPhones, possibly due to an error in the libimobiledevice tool. One iPhone was not scanned because the client left early, and two other phones were not scanned either because the client was locked out of the device or stated they were not concerned about scanning it. All devices that were not scanned with ISDi were checked manually, except for two where clients were locked out of the device (a phone and a laptop).

We performed manual checks on 97 out of 105 devices brought in by clients. Some devices, such as Internet-of-Things (IoT) devices, gaming systems, a Blackberry phone, and a flip phone, did not have a protocol for manual privacy checks. We performed a best-effort inspection in these cases, except for the flip phone, where the client had no privacy concerns.

#### Participants' Chief Concerns

Clients expressed a range of chief concerns, as shown in Figure 3 (middle table). The descriptions, such as "abuser hacked accounts," reflect the terminology used by clients. A relatively large number of clients (20) described experiences suggesting abusers had access to their online accounts (often described as "hacking") or reported evidence indicative of such access (e.g., abuser knows information only stored in an account). The second most prevalent chief concern (18 clients) was general concerns about their abuser tracking them or installing spyware, but without specific reasons for suspecting it. Other clients were concerned about their location being tracked, their phone acting suspiciously, and more. A few clients wanted to learn more about tech privacy and had no specific concerns about tech abuse directed towards them.

Chief concerns were often connected to the security issues we detected, discussed below. For example, concerns involving illicit access to accounts were often best explained by poor password practices, family sharing, or confirmation of account access by abuser devices. In one case, the chief concern was entirely unrelated to the discovered security issue, confirming the importance of both identifying the chief concerns and using instruments and procedures that may surface unexpected problems.

#### Security Vulnerabilities Discovered

For 23 out of 44 clients (52%), our consultations identified important security risks, vulnerabilities, or plausible vectors for tech abuse. It is important to note that, in most cases, we do not have definitive proof that the vulnerabilities discovered are the root causes of clients' problems. For example, if a client’s password is the name of a child they share with the abuser, or if their phone is part of a shared family plan, these provide plausible theories for, but not hard evidence of, how compromises may be occurring.

**Results from ISDi:**
ISDi flagged a total of 79 apps as problematic across all device scans. The majority (61) were dual-use apps, with "find my phone" and child monitoring apps being the most prevalent categories. For all but one of these dual-use apps, discussions with clients confirmed that they recognized the apps and were aware of their presence. For one dual-use app, the client said they did not install or recognize the app, which was a controller for remote home surveillance systems with WiFi, camera, and motion detection capabilities. We treated this case as a true positive result. The other 18 apps detected by ISDi were false positives (i.e., clearly not relevant to IPV) that the consultant easily dismissed. The number of false positives in any individual consultation was low, with the maximum number of flagged apps on a client’s device being five. This meant that consultants were not overwhelmed by large numbers of apps flagged by ISDi.

The relatively low rate of actual spyware detection may be because many abusers are able to surveil clients via compromised accounts, and thus may not need to install spyware. Additionally, almost all clients no longer lived with the abuser, had changed or reset their devices since leaving (which would remove spyware in most cases), and for many devices, the abuser no longer had physical access needed to (re-)install spyware. Finally, ISDi detected that one client’s Android tablet was rooted. Subsequent discussion revealed that the abuser bought this tablet for the client, had physical access to it during the relationship, and had insisted the client log into her accounts with it. As a result of our conversation, the client decided to stop using the tablet.

**Results from TAQ and Technograph:**
For many clients, we discovered security vulnerabilities through combined use of the TAQ, technograph, and/or manual privacy checks. In some cases, the TAQ and technograph were the primary (or only) way to uncover a potential problem. For example, four clients reported that they were still part of a shared family plan or that their abuser pays for their phone plan, vulnerabilities that could give the abuser access to the client’s device location and call and text history. Another common problem that the TAQ and technograph revealed for 14 clients was the use of passwords that the client said were known, or could be guessed, by their abuser. In several of these cases, a compromised password provided a plausible explanation for how the abuser may be gaining access to the client’s accounts.

**Results from Manual Checks:**
Combining TAQ and technograph information with subsequent manual privacy checks often yielded evidence of malicious account access. For example, during manual checks of iCloud account settings for four clients, we discovered that their iCloud accounts listed "trusted" devices that the client either did not know or recognized as belonging to the abuser. Similarly, manual checks of client email and social media accounts showed unknown or abuser device logins for another eight clients.

iCloud and email account access, whether by password compromise or via unauthorized "trusted" device access, also yielded plausible explanations for a range of other problems. For example, three clients reported that they kept written records of passwords for all their accounts in files that were then synced with their compromised iCloud, potentially resulting in the abuser obtaining all these passwords. Similarly, several clients emailed copies of their new passwords to themselves via potentially compromised email accounts. Another prevalent avenue for compromise happened when clients used a compromised account as the backup account for other services (e.g., social media), with clients unaware of how this might result in abuser access to these services.

For two clients, manual checks of laptops revealed browser extensions that the clients did not install or know about. In one case, the extension was "off store" (not available via the official Chrome Web Store), may have been sideloaded (installed via developer mode), and had permission to read and write all browser data. We regarded this as possible spyware. For the other case, the extension is available via the Chrome Store and is used to monitor access to web content. This extension provided a plausible explanation for the client’s chief concern, which was that her abuser knew about her online activities, and we regarded it as probable spyware.

**No Problems Detected:**
For 21 out of 44 clients, our instruments did not surface any evidence of potential tech issues. For 19 of these, the lack of discovered problems was reassuring, and many left the consultation visibly relieved and more at ease. However, in two cases, the consultation’s inability to address their chief concerns left the client unsatisfied. In these cases, we performed follow-up research, including reaching out to other tech experts for second opinions about their concerns (in an anonymized fashion), but unfortunately, we still have no plausible explanation for what they were experiencing.

**Hand-off and Follow-up:**
For the 23 clients with discovered problems and two clients with unresolved issues, we conducted follow-up consultations to address their concerns and provide further support.