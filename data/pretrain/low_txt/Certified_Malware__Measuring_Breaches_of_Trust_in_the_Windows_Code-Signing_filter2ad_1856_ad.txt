### 2.2 VBA32
- **Detection**: 1
- **Zillya**: 1
- **Qihoo-360**: 2
- **Kaspersky**: 2
- **ZoneAlarm**: 1

### 2.3 Malformed Signatures and Detection Rates
Malformed signatures reduced the VirusTotal detection rate by 20.7%. This reduction is likely due to the fact that antivirus (AV) software considers digital signatures when filtering and prioritizing files for scanning, thereby reducing the overhead on the user's system. However, incorrect implementation of Authenticode signature checks in many AVs allows malware authors to evade detection using a simple and inexpensive method.

We have reported this issue to the relevant antivirus companies. One company confirmed that their product fails to check signatures properly and plans to address the issue. Another company acknowledged the problem but did not provide further details.

### 4.4 Properly Signed Malware
In our dataset, 189 malware samples carry correct digital signatures, generated using 111 unique certificates. To generate these signatures, adversaries must have controlled the private keys of these certificates. We will analyze the weaknesses in the code-signing Public Key Infrastructure (PKI) that contributed to this abuse in Section 4.5. First, we investigate how these certificates are used in the wild and for how long users are exposed to these threats.

At the time of writing, 27 of these certificates had been revoked. While all the abusive certificates in our dataset had expired, executable files signed with one of the 84 non-revoked certificates may still be valid if they carry a trusted timestamp obtained during the certificate's validity period. For example, the digital signatures from 109 malware samples in our dataset remain valid. We notified the Certificate Authorities (CAs) of the compromised certificates and requested revocation, except for two CAs (GlobalSign and GoDaddy) due to issues with their abuse report systems.

### Malware Families
We determined the malware family from the AV labels using AVClass [32]. We identified a total of 116 unique families in the 189 properly signed malware samples. The most prevalent family is delf (7 samples), followed by fareit (4 samples). Figure 4 illustrates the number of unique certificates used per malware family. 103 families utilize a single certificate, and 13 use more than two certificates. Among the families with multiple certificates, we observe droppers (autoit, banload, agentb, dynamer, delf), bots (Zeus), and fake AVs (smartfortress and onescan). Similar types of malware appear in the list of families with a single certificate, including those used in targeted attacks. For example, Krbanker was reported to be involved in targeted attacks against customers of South Korean banks. Shylock is also known as a banking trojan that targeted customers of UK banks. The large fraction (88.8%) of malware families relying on a single certificate suggests that, in most cases, abusive certificates are controlled by the malware authors rather than third parties.

### Certificates
On average, an abusive certificate signs samples from 1.5 malware families. Most certificates (79.3%) were issued to publishers in five countries: China, Korea, USA, Brazil, and the UK. This observation reflects the reputation of these publishers, making them attractive targets for abuse, particularly for targeted attacks against users or organizations in these countries.

In the 189 properly signed malware samples, most (111, 66.8%) were timestamped through TSA; Verisign was the preferred TSA for most samples (38, 34.2%). This suggests that malware authors value the extended validity provided by trusted timestamps and are not concerned about submitting hashes of their malware samples to the timestamping authorities.

### Certificate Lifecycle
To determine how long users are exposed to these threats, we examined the lifecycle of these abusive certificates. For each certificate, we investigated the expiration date specified in the certificate, the revocation date specified in the CRL (if available), and the dates when benign and malicious binaries were signed with these certificates. If a binary has a trusted timestamp, we used that timestamp as the signing date. This corresponds to 66.8% of the binaries in our dataset. For the other samples, we inspected their first appearance in WINE and the first submission to VT, using the earliest timestamp as the signing date.

Figure 5 illustrates the timelines reconstructed in this manner. For example, the compromised certificate used by Stuxnet had previously been utilized to sign several legitimate binaries. These binaries were signed both before and after the malware's signing date. After the abuse was discovered, the certificate was revoked as of the date when the malware was signed, invalidating all benign binaries signed after that date. We note that the revocation date indicates when the certificate should cease to be valid, not when it was added to a CRL. In other words, revocation dates do not allow us to determine for how long users were exposed to the abuse.

While the Stuxnet incident raised awareness about digitally signed malware, we observed that this problem was prevalent in the wild before Stuxnet. We found a certificate from Skyline Software Systems compromised to sign malware in 2003, before Stuxnet appeared. Additionally, in Figure 3, we have 195 signed malware samples that appeared before 2010, when Stuxnet was discovered. We also observed two interesting behaviors: 5 certificates were used to sign malware that was not timestamped and was seen in the wild after the certificate expired. There is no motivation for malware writers to release their code after the expiration date, suggesting these samples correspond to stealthy attacks that evaded detection. We also found 7 certificates with ineffective revocations, where the revocation dates were set after the timestamping dates of the malware samples, allowing the malware to remain valid after revocation.

### Survival Analysis
To determine for how long the compromised certificates remain a threat, we performed survival analysis [17]. This statistical technique allows us to estimate the probability that an abused certificate will "survive" (i.e., not be revoked) after a given number of days. We considered the signing date (estimated as described above) of the oldest malware sample signed with the same certificate as the "birth" of the abuse. We estimated "death events"—the dates when certificates are added to CRLs—as follows. For a revoked certificate, we collected the scan date and the state of the certificate in VirusTotal for all the binaries signed with the certificate. We sorted the scan dates and took the last date when the state was "valid" right before the first scan date where the state is "revoked." We then calculated the time difference in days between birth and death events for the abused certificate. This represents a conservative estimation of the threat exposure, as the birth is an upper bound for the compromise date and the death is a lower bound for the revocation date. We also accounted for the fact that we cannot observe the death of some abusive certificates—the ones that are not yet revoked. In these cases, we do not know how big the revocation delay is, but we know that the certificates were not yet revoked on May 18, 2017; in survival analysis terminology, these data points are censored. We computed the Kaplan-Meier estimator [17] of the survival function, as it can account for censored data in the estimation.

We present the estimation in Figure 6. The probability that a certificate is not yet revoked decreases to 96% after the first day, owing to some certificates for which all the VT reports indicated a "revoked" status. The probability continues to decrease slowly for 5.6 years, then it stops decreasing after reaching 80%. This suggests that the threat of abused certificates is very resilient: only 20% of the certificates used to sign malware are likely to be revoked during our observation period, which spans 15 years. If the malware samples signed with the remaining certificates also carry a trusted timestamp, they remain valid today.

### 4.5 Measuring the Abuse Factors
To gain insight into the attackers' methods, we utilized the algorithm from Section 3.4 to identify the PKI weakness exploited in abusing the 111 certificates.

#### Publisher-Side Key Mismanagement
We considered a certificate as falling into this category if it was used for signing both benign and malicious programs. Of the 111 clusters (i.e., certificates), at least 75 certificates were used for signing both. We examined the validity of the samples in this case. Surprisingly, as of this writing, most (50, 66.7%) are still valid while only some certificates (10, 13.3%) were explicitly revoked. Although all certificates were already expired, the executable files signed with the certificates are still valid beyond the expiration date due to trusted timestamping. Therefore, users will see a message saying the publisher is verified and legitimate when they run the malware.

To categorize the certificates, we manually and deeply investigated:

- **Compromised Certificate**: Out of 75 certificates, we believe that most (72) were compromised and used for signing malware. Using this method, we found the Stuxnet malware, which is known to have been signed with a compromised certificate [10]. In our dataset, it was signed with the Realtek Semiconductor Corp. certificate issued by Verisign. Our systems also detected that an Australian department's private key was stolen and used to sign malware, labeled as autoit.
- **Infected Developer Machines**: We also identified developer machines that were infected and used to sign malicious code with a legitimate certificate. This resulted in signed malicious code shipped with a legitimate package. We found three certificates used to sign W32/Induc.A, which infects only Delphi developer machines. We investigated the prevalence of Induc in the wild using the WINE dataset. About 1,554 binaries were detected as a variant of Induc, and 93,016 machines were infected. Among these machines, 180 were Delphi compiler machines. This suggests that infecting developer machines is an effective method for amplifying the impact of signed malware and ultimately infecting 517× more machines. As depicted in Table 4, 70% of them are issued by the Symantec group (Thawte and Verisign).

#### CA-Side Verification Failure
This weakness is caused by CAs' failure in verifying the publisher's identity. CAs may issue certificates to an adversary who impersonates someone else or uses shell company information.

We believe that 27 certificates were issued to malicious publishers due to verification failures. To distinguish between identity theft and shell companies, we manually investigated each certificate by searching for the publisher names on the Internet or in openCorporates to see if the publishers are legitimate. 22 certificates out of 27 were issued through identity theft, and 5 were done through shell company information. For example, a certificate issued to a delivery service company in Korea was used to sign malware. Another certificate was issued to an Oregon resident. We believe that the company is not related to software development and has never released any software. Moreover, we doubt that a malware writer would reveal their identity. Therefore, we consider these cases of identity theft.

We investigated the process for issuing code signing certificates to understand the weakness that allowed these certificates to be issued. The policy might have changed from the time these certificates were issued; however, we assumed that the policy will not downgrade. Around the end of 2016, the Certificate Authority Security Council (CASC) announced minimum requirements for code signing certificates. The new requirements include:

- **Stronger Protection of Private Keys**: Now, private keys should only be stored on secure cryptographic hardware, such as a USB token or Hardware Security Module (HSM).
- **Careful Identity Verification**: The new requirement asks CAs to strictly verify the identity of the publisher, including checking the legal identity and cross-checking with the known bad publisher list.
- **Better Response to Abuse**: CAs now have to quickly respond to revocation requests, revoking the certificate within two days or notifying the reporter that the investigation has started.
- **TSA Requirement**: Every code signing provider must operate an RFC-3161 compliant TSA.

These guidelines suggest that CASC is aware of the abuse happening in the wild. Increased protection of private keys would help prevent certificates from being compromised, and strict identification checks will make it harder to acquire a certificate by impersonation. Moreover, Microsoft announced that CAs must follow these guidelines starting February 1, 2017.

We investigated the policies of the top ten code signing CAs listed in Table 2. We found that only Certum follows the guidelines. The survey results suggest that code signing is still vulnerable to certification thefts and fraudulent applications.

### Revocation
We investigated the revocation practice in the field. By category, 15.3%, 40.9%, and 80.0% of the certificates were revoked for compromised, identity theft, and shell company, respectively. Interestingly, the revocation rate was significantly lower for compromised certificates compared to the other abuse types.

### Verification and Further Investigation
We decided to contact the owners of the compromised certificates we found to inform them that their certificates were used for signing malware and to better understand the code signing ecosystem. We manually searched for their websites and sent emails to 23 publishers asking them to check if the certificate was owned by them. We were unable to send more emails due to unrecognizable publisher names, closures, etc.

As of this writing, we received eight replies. All of them stated that they issued and used the certificates to sign their benign programs. Three of them were already aware that their certificates were abused by adversaries and revoked by their CAs because the CAs notified them that the certificates were compromised. One publisher told us that their private key may have been compromised.