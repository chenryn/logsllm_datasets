### Section 3.1: Example of Information Leakage

After a user grants the greeting card app access to their address book, it becomes extremely challenging to prevent the app from leaking this information.

### Mitigation Techniques

#### Control Flow Integrity (CFI)
Jekyll apps heavily rely on control flow hijacking vulnerabilities. Advanced exploit prevention techniques, such as Control Flow Integrity (CFI), can effectively mitigate these threats. CFI ensures that runtime control-flow transfers adhere to rules derived from static analysis of the program and constraints inferred from the execution context. 

- **MoCFI [14] and PSiOS [47]**: These frameworks bring CFI to iOS, but they require jailbroken devices. Despite their high performance overhead and low adoption rates, CFI is generally considered effective against conventional Return-Oriented Programming (ROP) attacks, which partly inspired the design of Jekyll apps.
- **Effectiveness**: If properly implemented and deployed on iOS, CFI can significantly increase the complexity of designing Jekyll apps, forcing attackers to trade code flexibility for success. Skilled attackers might still use systematic non-control data attacks [12] or function-level gadgets to bypass CFI, but these techniques would likely reduce the stealthiness of Jekyll apps due to increased distinguishability.

#### Type-Safe Programming Languages
Type-safe programming languages like Java are immune to low-level memory errors such as buffer overflows. Enforcing the use of type-safe languages for third-party app development can prevent control flow hijacking and information leakage vulnerabilities.

### Summary and Recommendations

We advocate for official support for runtime security monitoring mechanisms on iOS. The design of Jekyll apps aims to highlight the need for such mechanisms, which can protect iOS against advanced attacks and ensure that the app review process and regulations are maximally effective.

### Conclusion

In this paper, we introduced a novel attack scheme that malicious iOS developers can use to evade the mandatory app review process. The key idea is to dynamically introduce new execution paths that do not exist in the app code as reviewed by Apple. Specifically, attackers can plant artificial vulnerabilities in a benign app and embed malicious logic by decomposing it into disconnected code gadgets hidden throughout the app's code space. This seemingly benign app can pass the app review because it neither violates any Apple-imposed rules nor contains functional malice. However, once a victim downloads and runs the app, attackers can remotely exploit the planted vulnerabilities and assemble the gadgets to perform various malicious tasks.

We demonstrated the versatility of our attack through a broad range of malicious operations and discussed newly discovered private APIs in iOS that can be abused to send emails, SMS, and post tweets without user consent.

Our proof-of-concept malicious app was successfully published on the App Store and tested on a controlled group of users. Even within the iOS sandbox, the app could stealthily post tweets, take photos, gather device identity information, send emails and SMS, attack other apps, and even exploit kernel vulnerabilities.

### Acknowledgements

We thank our shepherd Benjamin Livshits and the anonymous reviewers for their valuable comments. This work was supported in part by the National Science Foundation under grants no. CNS-1017265 and no. CNS-0831300, the Office of Naval Research under grant no. N000140911042, and the United States Air Force under Contract no. FA8650-10-C-7025. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation, the Office of Naval Research, or the United States Air Force.

### References

[1] JailbreakMe. http://www.jailbreakme.com/.
[2] News:yc, the open source news client for iOS. https://github.com/Xuzz/newsyc.
[3] Unstructured supplementary service data. http://en.wikipedia.org/wiki/Unstructured_Supplementary_Service_Data.
[4] Apple’s worldwide developers conference keynote address, June 2010. http://www.apple.com/apple-events/wwdc-2010/.
[5] Apple’s app store review guidelines, 2013. https://developer.apple.com/appstore/resources/approval/guidelines.html.
[6] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-flow integrity principles, implementations, and applications. In Proceedings of the ACM Conference on Computer and Communications Security (CCS), Alexandria, VA, USA, 2005.
[7] A. Bednarz. Cut the drama: Private APIs, the app store & you. 2009. http://goo.gl/4eVr4.
[8] D. Blazakis. The apple sandbox. In Blackhat DC, Jan 2011.
[9] E. Buchanan, R. Roemer, H. Shacham, and S. Savage. When good instructions go bad: generalizing return-oriented programming to RISC. In Proceedings of the 15th ACM conference on Computer and communications security (CCS), Alexandria, VA, USA, 2008.
[10] Bulba and Kil3r. Bypassing stackguard and stackshield. Phrack Magazine, 56(5), 2000.
[11] S. Checkoway, L. Davi, A. Dmitrienko, A. R. Sadeghi, H. Shacham, and M. Winandy. Return-oriented programming without returns. In Proceedings of the 17th ACM conference on Computer and Communications Security (CCS), Chicago, IL, USA, Oct 4-8, 2010.
[12] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer. Non-control-data attacks are realistic threats. In Proceedings of the 14th conference on USENIX Security Symposium, pages 12–12, 2005.
[13] S. Dai, T. Wei, C. Zhang, T. Wang, Y. Ding, Z. Liang, and W. Zou. A framework to eliminate backdoors from response-computable authentication. In Proceedings of the 2012 IEEE Symposium on Security and Privacy, 2012.
[14] L. Davi, R. Dmitrienko, M. Egele, T. Fischer, T. Holz, R. Hund, S. Nrnberger, and A. reza Sadeghi. MoCFI: A framework to mitigate control-flow attacks on smartphones. In In Proceedings of the Network and Distributed System Security Symposium (NDSS), 2012.
[15] L. Davi, A. Dmitrienkoy, A.-R. Sadeghi, and M. Winandy. Return-oriented programming without returns on ARM. Technical Report HGI-TR-2010-002, System Security Lab, Ruhr University Bochum, Germany, 2010.
[36] K. Lu, D. Zou, W. Wen, and D. Gao. Packed, printable, and polymorphic return-oriented programming. In Proceedings of the 14th International Symposium on Recent Advances in Intrusion Detection (RAID), Menlo Park, California, USA, September 2011.
[37] C. Miller. Inside iOS code signing. In Symposium on Security for Asia Network (SyScan), Taipei, Nov 2011.
[38] C. Miller, D. Blazakis, D. DaiZovi, S. Esser, V. Iozzo, and R.-P. Weinmann. iOS Hacker’s Handbook. Wiley, 1st edition, May 2012.
[39] V. Pappas, M. Polychronakis, and A. D. Keromytis. Smashing the gadgets: Hindering return-oriented programming using in-place code randomization. In Proceedings of the 33rd IEEE Symposium on Security and Privacy, pages 601–615, San Francisco, CA, USA, May 2012.
[40] M. PRATI. ROP gadgets hiding techniques in Open Source Projects. PhD thesis, University of Bologna, 2012.
[41] P. Roberts. Accountability, not code quality, makes iOS safer than Android. April 2012. http://goo.gl/ZaXhj.
[42] F. Roesner, T. Kohno, A. Moshchuk, B. Parno, H. J. Wang, and C. Cowan. User-driven access control: Rethinking permission granting in modern operating systems. In Proceedings of the 2012 IEEE Symposium on Security and Privacy, Washington, DC, USA, 2012.
[43] E. J. Schwartz, T. Avgerinos, and D. Brumley. Q: Exploit hardening made easy. In Proceedings of USENIX Security, San Francisco, CA, USA, 2011.
[44] H. Shacham. The geometry of innocent flesh on the bone: return-into-libc without function calls (on the x86). In Proceedings of the 14th ACM conference on Computer and Communications Security (CCS), Alexandria, VA, USA, Oct. 29-Nov. 2, 2007.
[45] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh. On the effectiveness of address-space randomization. In Proceedings of the 11th ACM conference on Computer and communications security, pages 298–307, Washington DC, USA, 2004.
[46] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary stirring: self-randomizing instruction addresses of legacy x86 binary code. In Proceedings of the 2012 ACM conference on Computer and communications security (CCS), Raleigh, NC, USA, Oct, 2012.
[47] T. Werthmann, R. Hund, L. Davi, A.-R. Sadeghi, and T. Holz. PSiOS: Bring your own privacy & security to iOS devices. In 8th ACM Symposium on Information, Computer and Communications Security (ASIACCS 2013), May 2013.
[48] Wikipedia. iOS jailbreaking. http://en.wikipedia.org/wiki/IOS_jailbreaking.
[49] H. Xu and X. Chen. Find your own iOS kernel bug. In Power of Community (POC), Seoul, Korea, 2012.
[50] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar. Native Client: A sandbox for portable, untrusted x86 native code. In Proceedings of the 2009 30th IEEE Symposium on Security and Privacy, 2009.
[51] D. A. D. Zovi. iOS 4 security evaluation. In Blackhat USA, Las Vegas, NV, Aug 2011.
[16] S. designer. Bugtraq, Aug, 1997. return-to-libc attack.
[17] M. Egele, C. Kruegel, E. Kirda, and G. Vigna. PIOS: Detecting privacy leaks in iOS applications. In 18th Annual Network and Distributed System Security Symposium (NDSS), February 2011.
[18] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth. TaintDroid: An information-flow tracking system for real-time privacy monitoring on smartphones. In Proceedings of the 9th USENIX conference on Operating systems design and implementation, OSDI’10, 2010.
[19] J. Engler, S. Law, J. Dubik, and D. Vo. iOS application security assessment and automation: Introducing SIRA. In Black Hat USA, LAS VEGAS, 2012.
[20] K. Ermakov. Send SMS. Your flashlight can. http://blog.ptsecurity.com/2012/10/your-flashlight-can-send-sms-one-more.html, Oct 2012.
[21] S. Esser. Antid0te 2.0 - ASLR in iOS. In Hack In The Box (HITB). Amsterdam, May 2011.
[22] S. Esser. iOS kernel exploitation. In Black Hat USA, LAS VEGAS, 2011.
[23] D. ETHERINGTON. iPhone app contains secret Game Boy Advance emulator, get it before it’s gone. March 2013. http://goo.gl/OGyc0.
[24] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wagner. A survey of mobile malware in the wild. In Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices (SPSM), pages 3–14, 2011.
[25] J. Han, S. M. Kywe, Q. Yan, F. Bao, R. H. Deng, D. Gao, Y. Li, and J. Zhou. Launching generic attacks on iOS with approved third-party applications. In 11th International Conference on Applied Cryptography and Network Security (ACNS 2013). Banff, Alberta, Canada, June 2013.
[26] J. Han, Q. Yan, D. Gao, J. Zhou, and R. H. Deng. Comparing Mobile Privacy Protection through Cross-Platform Applications. In Proceedings of the Network and Distributed System Security Symposium (NDSS), San Diego, CA, February 2013.
[27] J. D. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. Davidson. ILR: Where’d my gadgets go? In Proceedings of the 33rd IEEE Symposium on Security and Privacy, pages 571–585, San Francisco, CA, USA, May 2012.
[28] J. Howell and S. Schechter. What you see is what they get: Protecting users from unwanted use of microphones, cameras, and other sensors. In The Web 2.0 Security & Privacy Workshop (W2SP), 2010.
[29] R. Hund, T. Holz, and F. C. Freiling. Return-oriented rootkits: Bypassing kernel code integrity protection mechanisms. In Proceedings of the 18th USENIX Security Symposium, Montreal, Canada, Aug, 2009.
[30] iOS Market Statistics, 2012. http://goo.gl/LSK7I/.
[31] iOS Security, May 2012. http://images.apple.com/ipad/business/docs/iOS_Security_May12.pdf.
[32] H. Kipp. ARM GCC inline assembler cookbook. http://www.ethernut.de/en/documents/arm-inline-asm.html. 2007.
[33] T. Kornau. Return oriented programming for the ARM architecture. Master’s thesis, Ruhr-University Bochum, Germany, 2009.
[34] C. Kruegel, E. Kirda, and A. Moser. Limits of Static Analysis for Malware Detection. In Proceedings of the 23rd Annual Computer Security Applications Conference (ACSAC), Miami Beach, Florida, USA, Dec, 2007.
[35] D. Larochelle and D. Evans. Statically detecting likely buffer overflow vulnerabilities. In Proceedings of the 10th conference on USENIX Security Symposium, Berkeley, CA, USA, 2001.