### 3. Comparison of Net Prowler and Snort Performance

When comparing the performance of Net Prowler to that of Snort (as shown in Table 2), it is evident that Net Prowler generates fewer alerts overall. However, it is important to note that the traffic generated by Mucus-1 is synthetic. Consequently, the alerts generated by Net Prowler in this experiment are false positives.

One might be tempted to conclude from the low number of alerts that Net Prowler is more effective at correctly identifying synthetic attacks, suggesting that it is more robust against IDS stimulation attacks. An alternative explanation, however, is that Net Prowler may have a less comprehensive or significantly different set of signatures, and thus, it simply does not detect the synthetic attacks represented by the missed signatures.

Since the authors were unable to obtain the Net Prowler signature set, it was not possible to determine which of these conflicting conjectures is correct for each instance of synthetic attack traffic. To address this, one method would be to expose Net Prowler to actual attacks that are being simulated using Mucus-1. The alerts produced by Net Prowler in response to these real attacks would then indicate which attacks it has signatures for. The following section details this experiment.

### 5.4 Real Attack Traffic

As mentioned in the previous section, real attacks can help determine whether an IDS has signatures for specific attacks, even without precise knowledge of the system's signatures or implementation. This approach allows one to evaluate whether an IDS exhibits robustness against IDS stimulation attacks or if it simply does not model the attacks being synthetically reproduced. Additionally, the ultimate goal of automated attack traffic generation for network IDS evaluation is to produce traffic that is indistinguishable from actual attacks. Comparing the responses of an IDS to synthetic and real versions of an attack is a way to measure the fidelity of synthetically generated attacks.

In this experiment, a sampling of exploits and information-gathering attacks was gathered from various internet sources and run against both Snort and Net Prowler. Each attack had a corresponding Snort rule, enabling the generation of synthetic traffic for comparison. It should be noted that, in some cases, the vulnerable services were not installed on the victim host, and therefore, the exploits were not successful. However, for the purposes of this experiment, an attempted exploit is considered a critical event from the perspective of a network IDS. Table 4 summarizes the results of this experiment.

The results show strong agreement for the Snort IDS: In all cases, Snort generates alerts for both synthetic and real versions of the attacks. This indicates that, from Snort's perspective, the synthetically generated traffic is essentially indistinguishable from the true attacks. Table 4 also shows that the majority of attacks selected go undetected by Net Prowler. While in the previous experiment, not detecting synthetically generated traffic seemed to show Net Prowler's robustness to IDS stimulation, not detecting the real attacks in this experiment provides evidence for the alternative explanation: Net Prowler's signature set is smaller than, or largely disjoint from, that of Snort. Agreement between the synthetic and true attack event streams is achieved in all but one instance, the HTTP phf attack, where the real attack causes Net Prowler to generate an alert while the synthetic attack fails to do so. This suggests that for this particular attack, Net Prowler has a more robust detection capability than Snort.

### 6 Conclusions and Future Work

This paper presents a tool for cross-testing signature-based intrusion detection systems and introduces a new methodology for generating test cases. A tool called Mucus-1 was developed, and an empirical evaluation of this proof-of-concept prototype was conducted, yielding interesting results.

These experiments highlight the detrimental impact of the lack of information flow from commercial IDS vendors on the research community. Some vendors refuse to disclose precise information about their signatures, while others do not disclose details about their algorithms. From an IDS evaluator's perspective, this opaqueness makes it impossible to establish the cause of errors or misdetections. Dropped packets, poor signatures, and logical errors are indistinguishable unless system internals are known.

Future work in the area of black-box evaluation of network IDS will be extended in several ways:

1. **Support for Additional Signature Languages**: Adding support in Mucus-1 for signature languages other than Snort would dramatically increase the scope of this work. Some languages, like STATL, allow for stateful, multi-step, time-dependent attack scenarios, which would require more complex representations in Mucus-1.

2. **Measuring Signature Quality**: To improve the testing capabilities of Mucus beyond qualitative measures of IDS performance, a measure of signature quality must be developed. Without knowing how closely signatures match the event streams of attacks, it is not possible to draw quantitative conclusions about the performance of an IDS.

3. **Signature Overlap and First-Match Behavior**: Section 5.2 examined the problem of signature overlap combined with the first-match behavior in Snort. An automated tool to compute the intersection of constraints specified by any two rules in the Snort ruleset would be advantageous.

### Acknowledgments

This research builds on the work of several individuals. We thank Sniph, the author of snot, for building the first extensive tool for IDS stimulation. The code of the first Mucus-1 prototype re-used portions of his code. We also thank Steve Eckmann, who developed the Snort-to-STATL translator. The Mucus-1 Snort rule parser was built by extending his original work.

This research was supported by the State of California, the Army Research Office under agreement DAAD19-01-1-0484, and the Defense Advanced Research Projects Agency (DARPA) and Rome Laboratory, Air Force Materiel Command, USAF, under agreement number F30602-97-1-0207. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation thereon.

### References

[References listed as in the original text]