### Friendship Relations and Network Analysis

Table 3 (sixth column) presents the total number of friendship relationships between users who liked our pages, broken down by each provider. In Figure 3(a), we visualize the social graph formed by these friendships, excluding users who did not have any friendship connections with other likers. Based on this social structure, we make the following observations:

1. **BoostLikes**: The dense network of connections among BoostLikes users suggests an interconnected group of either real or fake users designed to mimic complex social ties.
2. **SocialFormula**: The presence of pairs (and occasionally triplets) of connected users may indicate a strategy to construct networks that are less likely to be entirely compromised if one user is identified as fake.
3. **AuthenticLikes and MammothSocials**: The friendship relations between users from these two providers suggest that they might be managed by the same operator.

We also examined indirect links through mutual friends. Table 3 reports the total number of 2-hop relationships (i.e., friends of friends) for each provider. Figure 3(b) illustrates the connections between users who have either direct relationships or mutual friends, highlighting the strong intra-provider connections. These tight connections, along with the large number of friends, imply that we are only observing a small portion of these networks. For instance, like farms often sell packages of up to 50,000 likes. For SocialFormula, AuthenticLikes, and MammothSocials, we observed many isolated pairs and triplets of users, suggesting that farm operators create separate fake accounts to avoid detection.

### Page Like Analysis

Next, we analyzed the other pages liked by profiles that interacted with our honeypot pages. Figures 4(a) and 4(b) show the distribution of page likes for users from Facebook ads and like farm campaigns. To establish a baseline, we collected page like counts from a random sample of 2,000 Facebook users, drawn from an unbiased sample of the Facebook user population.

Our findings include:
- A wide variance in the number of pages liked, ranging from 1 to 10,000.
- Median page like counts of 600 to 1,000 for Facebook campaign users and 1,200 to 1,800 for like farm campaign users, except for the BL-USA campaign (median: 63).
- A median page like count of 34 for the baseline Facebook user sample, consistent with previous research indicating an average of around 40 page likes per user.

The high number of page likes from our honeypot pages suggests that the majority of these likes are likely fake. These users may be reused for multiple "jobs" and like "normal" pages to appear more authentic.

To further validate this, we calculated the Jaccard similarity between the sets of liked pages for different campaigns. Specifically, let \( S_k \) denote the set of pages liked by user \( k \). The Jaccard similarity between the sets of likes for two campaigns \( A \) and \( B \) is defined as \( \frac{|A \cap B|}{|A \cup B|} \). We plotted these similarities in Figure 5(a) and the similarity between the sets of likers in Figure 5(b).

Key observations:
- FB-IND, FB-EGY, and FB-ALL have relatively high Jaccard similarities, suggesting shared fake profiles.
- SF-USA and SF-ALL, and AL-USA and MS-USA, also exhibit high similarities, indicating that the same fake profiles are used across multiple campaigns and possibly by the same operator.

### Concluding Remarks

This study provides a comparative analysis of Facebook page promotion methods, focusing on the activities of like farms. We identified two main operational strategies:
1. **Bot-Operated Farms**: Providers like SocialFormula and AuthenticLikes use bots, characterized by large bursts of likes and a limited number of friends per profile.
2. **Stealthy Farms**: Providers like BoostLikes aim to mimic regular user behavior, relying on a large and well-connected network structure to distribute likes while maintaining a low count of likes per user.

One month after the campaigns, we checked the status of the likers' accounts. Only one account associated with BoostLikes was terminated, compared to 9, 20, and 44 for other like farms. Eleven accounts from the regular Facebook campaigns were also terminated. This suggests that most fake accounts are disposable and easy to detect, but some, like those from BoostLikes, are more challenging due to their resemblance to real user behavior.

Our findings do not necessarily imply that advertising on Facebook is ineffective, but they do highlight the need for better detection of fake likes. Future work should include larger and more diverse honeypot measurements, longer observation periods, and further investigation into the origin of fake likes.

### Acknowledgments

We thank the reviewers and our shepherd for their feedback and useful comments. We are also grateful to Gianluca Stringhini for reviewing a draft of the paper.

### References

[1] Facebook Ads Optimization. <http://weigend.com/files/teaching/stanford/2009/homeworks/ad_optimization_final.pdf>
[2] Selenium WebDriver: Browser Automation. <http://docs.seleniumhq.org/projects/webdriver/>
[3] C. Arthur. How low-paid workers at ‘click farms’ create appearance of online popularity. <http://www.theguardian.com/technology/2013/aug/02/click-farms-appearance-online-popularity>, August 2013.
[4] A. Beutel, W. Xu, V. Guruswami, C. Palow, and C. Faloutsos. CopyCatch: Stopping Group Attacks by Spotting Lockstep Behavior in Social Networks. In WWW, 2013.
[5] Q. Cao, M. Sirivianos, X. Yang, and T. Pregueiro. Aiding the Detection of Fake Accounts in Large Scale Social Online Services. In NSDI, 2012.
[6] B. Carter. The Like Economy: How Businesses Make Money with Facebook. Que Publishing, 2013.
[7] R. Cellan-Jones. Who ‘likes’ my Virtual Bagels? <http://www.bbc.co.uk/news/technology-18819338>, July 2012.
[8] A. Chaabane, G. Acs, and M.-A. Kaafar. You Are What You Like! Information Leakage Through Users’ Interests. In NDSS, 2012.
[9] T. Chen, A. Chaabane, P. U. Tournoux, M.-A. Kaafar, and R. Boreli. How Much is too Much? Leveraging Ads Audience Estimation to Evaluate Public Profile Uniqueness. In PETS, 2013.
[10] G. Danezis and P. Mittal. SybilInfer: Detecting Sybil Nodes using Social Networks. In NDSS, 2009.
[11] V. Dave, S. Guha, and Y. Zhang. Measuring and Fingerprinting Click-Spam in Ad Networks. In SIGCOMM, 2012.
[12] eMarketer. Mobile Growth Pushes Facebook to Become No. 2 US Digital Ad Seller. <http://preview.tinyurl.com/mq6vu3u>, December 2013.
[13] Facebook. Can I buy likes for my Facebook Page? <http://www.facebook.com/help/281084665319172>
[14] J. Filan. Facebook Ads: What Are You Really Paying For? <http://www.searchenginejournal.com/facebook-ads-what-are-you-really-paying-for/46194/>, July 2012.
[15] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao. Detecting and Characterizing Social Spam Campaigns. In IMC, 2010.
[16] J. Lafferty. How Many Pages Does The Average Facebook User Like? <http://allfacebook.com/how-many-pages-does-the-average-facebook-user-like_b115098>, 2013.
[17] K. Lee, J. Caverlee, and S. Webb. Uncovering social spammers: Social honeypots + machine learning. In SIGIR, 2010.
[18] M. Mendoza. How Facebook Likes Get Bought And Sold. <http://www.huffingtonpost.com/2014/01/05/buy-facebook-likes_n_4544800.html>, 2014.
[19] R. Metzger. Facebook: I Want My Friends Back. <http://dangerousminds.net/comments/facebook_i_want_my_friends_back>, October 2012.
[20] D. Muller. Facebook Fraud. <https://www.youtube.com/watch?v=oVfHeWTKjag>, February 2014.
[21] A. Nazir, S. Raza, C.-N. Chuah, and B. Schipper. Ghostbusting Facebook: Detecting and Characterizing Phantom Profiles in Online Social Gaming Applications. In WOSN, 2010.
[22] J. Schneider. Likes or lies? How perfectly honest businesses can be overrun by Facebook spammers. <http://thenextweb.com/facebook/2014/01/23/likes-lies-perfectly-honest-businesses-can-overrun-facebook-spammers/>, January 2014.
[23] G. Stringhini, C. Kruegel, and G. Vigna. Detecting Spammers on Social Networks. In ACSAC, 2010.
[24] G. Stringhini, G. Wang, M. Egeley, C. Kruegel, G. Vigna, H. Zheng, and B. Y. Zhao. Follow the Green: Growth and Dynamics in Twitter Follower Markets. In ACM IMC, 2013.
[25] K. Thomas, C. Grier, V. Paxson, and D. Song. Suspended Accounts in Retrospect: An Analysis of Twitter Spam. In IMC, 2011.
[26] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Paxson. Trafficking Fraudulent Accounts: The Role of the Underground Market in Twitter Spam and Abuse. In USENIX Security Symposium, 2013.
[27] C. Yang, R. Harkreader, J. Zhang, S. Shin, and G. Gu. Analyzing Spammers’ Social Networks for Fun and Profit. In WWW, 2012.
[28] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao, and Y. Dai. Uncovering Social Network Sybils in the Wild. In IMC, 2011.
[29] H. Yu, P. B. Gibbons, M. Kaminsky, and F. Xiao. SybilLimit: A Near-Optimal Social Network Defense against Sybil Attacks. In IEEE Security & Privacy, 2008.
[30] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman. SybilGuard: Defending Against Sybil Attacks via Social Networks. In SIGCOMM, 2006.