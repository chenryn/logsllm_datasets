### 1. Introduction and Context

The following text discusses the coverage and overlap of interdomain interconnections observed through traceroutes to M-Lab, Speedtest.net, and Alexa targets. It also examines the statistical challenges in inferring internet congestion using end-to-end throughput measurements.

### 2. Differences in Interconnection Traversals

**Figure 4:**
- **(a) Overlap at AS-level**
- **(b) Overlap at router-level**

**Description:**
This figure illustrates the differences in the number of interconnections traversed on paths to M-Lab and Speedtest.net servers compared to those on paths toward Alexa targets. "Mlab-Alexa" denotes the number of interconnections in traceroutes to M-Lab servers but not in traceroutes to Alexa targets. "Alexa-Mlab" denotes the number of interconnections in traceroutes to Alexa targets but not in traceroutes to M-Lab servers. The remaining two bars compare the overlap between interconnections on paths to Speedtest.net servers and Alexa targets. For each vantage point (VP), a significant number of interconnections on paths to popular web content were not covered using M-Lab or Speedtest.net servers.

### 3. Methodological Considerations

To examine the coverage of an ISP's AS-level interconnections, outbound traceroutes are sufficient. Future work will use Reverse Traceroute [23] and Sibyl [16] systems to infer inbound paths to our Ark VPs. A caveat of our methodology is that it measures popular web content and does not include CDN locations from which popular videos may be served. An examination of paths toward the sources of popular video content is left for future work.

### 4. Coverage of Interdomain Interconnections

**Figure 2:**
- Compares the set of (AS-level and router-level) interconnections of the 16 VPs observed in traceroutes toward M-Lab and Speedtest.net targets with the set of interconnections discovered by bdrmap.
- In January 2017, M-Lab and Speedtest.net servers provided coverage of a small fraction of interdomain interconnections observable from the VP.
- M-Lab servers covered between 0.4% (for AT&T) and 9% (for Frontier) of AS-level interconnections, while Speedtest.net servers covered between 2.3% (for AT&T) and 28% (for Sonic) of AS-level interconnections.

**Figure 3:**
- Similar to Figure 2 but reflects only interconnections inferred as peers by CAIDA’s AS-rank algorithm [12].
- Settlement-free (or paid) peers are more important than customers or providers from the perspective of interdomain congestion and performance.
- Both M-Lab and Speedtest.net provided better coverage of peer interconnections than they did of all interconnections.
- Speedtest.net servers provided better coverage of both AS and router-level peer interconnections than M-Lab.

### 5. Overlap with Popular Web Content

**Figure 4:**
- Shows the overlap between the set of interdomain interconnections covered using M-Lab and Speedtest.net servers and those traversed on paths to popular web content (Alexa targets).
- For 13 of 16 VPs, we observed AS-level interconnections on paths to M-Lab servers that were not on paths to any Alexa targets.
- For each VP, we observed AS-level interconnections on paths toward Alexa targets that were not covered using M-Lab or Speedtest.net servers.
- Between 79% and 90% of AS-level interconnections on paths from Ark VPs to Alexa targets were not covered using M-Lab servers.

### 6. Changes Over Time

- Conducted measurements and analysis in October 2015 and February 2017.
- The number of M-Lab servers remained the same (261), while Speedtest expanded from 3591 to 5209 servers.
- The coverage of all AS-level interconnections using both M-Lab and Speedtest servers decreased by a small amount (< 5%) for all ISPs.
- The coverage of peer AS interconnections with Speedtest increased for Comcast and Cox but decreased for other networks.
- For M-Lab, the coverage of Comcast’s peers increased, while the coverage of all other networks decreased.

### 7. Statistical Challenges

**End-to-end throughput-based measurement to detect congestion involves:**
- Two steps: the measurement itself and aggregating measurements to infer congestion on the path.
- Two assumptions: (1) Internet traffic has diurnal patterns, and (2) a client is typically limited by the access link capacity.

**Limitations of crowdsourcing:**
- Samples cannot be controlled.
- Time of day bias.
- Service plan variance.
- Home network interference.

**Thresholds to detect congestion:**
- Identifying what constitutes congestion is not straightforward.
- Even examples used in the report to contrast with congested links show diurnal patterns.
- Distinguishing between a link that becomes congested at peak hours and an uncongested link that sees higher utilization during peak hours is challenging.

### 8. Lessons Learned

- Congestion at ISP interconnections has been a recent focus in research, economic, and regulatory arenas.
- Using public measurement data and our own experiments, we investigated challenges in inferring interconnection congestion using end-to-end throughput measurements.
- Methodological and statistical challenges need to be addressed to improve the accuracy of congestion inference.