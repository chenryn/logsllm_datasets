### Data and Observations

The following data points represent various packet lengths and their corresponding values, which are likely related to delay or processing times in network devices. The values are presented in both numerical and scientific notation for clarity.

- 1,000,000 (1e+06)
- 100,000 (1e+05)
- 10,000
- 1,000
- 100
- 10
- 1
- 0

#### Cisco Packet Lengths
- **Packet Length > 1500 bytes:**
  - Delay/Processing Time: 1,000,000 (1e+06), 100,000 (1e+05), 10,000, 1,000, 100, 10, 1, 0
- **Packet Length ≤ 1500 bytes:**
  - Delay/Processing Time: 1,000,000 (1e+06), 100,000 (1e+05), 10,000, 1,000, 100, 10, 1, 0

#### Foundry Packet Lengths
- **Packet Length > 1500 bytes:**
  - Delay/Processing Time: 540,000, 2.252, 5.484, 18.835, 281.096
- **Packet Length ≤ 1500 bytes:**
  - Delay/Processing Time: 103,073, 4.364, 3.338, 31.233, 1537.800

### Analysis of Residual Delay

Figure 9 presents a histogram of the residual delay \(\xi\), which is the delay minus the lower bound of delay as shown in Table 2 for packet sizes below and above 1500 bytes. This summary histogram suggests, but does not prove, the stationarity of \(\xi\) with respect to packet size. While stationarity is often assumed, our preliminary results indicate that it only approximately holds.

A common assumption in network research is that an idle router processes packets with the minimum possible delay [31]. Our experimental setup ensures no cross-traffic and that routers process probes one at a time. Table 3 provides statistics (average, 95%, 99%, and maximum) for the residual delay \(\xi\), which is the ICMP generation time in excess of the linear lower bound \(ax + b\) (where Table 2 shows the slope \(a\) and intercept \(b\)).

Key findings:
- Cisco and Foundry gigE interfaces process TimeExceeded messages with no more than 6 µs of extra delay (over the size-dependent lower bound) in 95% of cases.
- For 1% of packets, the extra delay is between 20 and 300 µs on the Cisco and 30–1500 µs on the Foundry.
- Despite the piecewise linearity of the lower bound, the statistics of \(\xi\) are similar for packets under and over 1500 bytes.

### Discussion, Conclusions, and Future Work

We demonstrated that a linear model of ICMP delay is an approximation that breaks down for packet sizes over 1500 bytes. Many measurement techniques rely on this assumption, which is a pressing issue as providers like Abilene, Geant, and Switch already support 9000-byte transparent paths. The global Internet transition toward these larger packet sizes is imminent.

With a 1500-byte ICMP delay rate discontinuity at all three routers, and with packet forwarding (as opposed to ICMP message generation delay) showing a similar break in linearity at 1500 bytes for at least one router, we can conclude that there is disparate treatment of packets under versus over 1500 bytes. Designers of bandwidth estimation and other measurement tools must be aware of this reality.

#### Key Observations
- Delays above the minimum are not necessarily due to queuing. For example, Juniper delays some closely spaced traceroute packets by 9–10 ms (Fig. 4).
- Buffer carving [32] can lead to "non-physical" size-delay dependence, which can appear faster than the link rate or decrease with packet size. Such buffering can also make loss rates size-independent [33].
- The negative slope for the Foundry data in Fig. 8 could be caused by the router zeroing out the rest of a 1500-byte buffer after a smaller packet arrives, though this is speculative.

Surprisingly, we found that the ICMP rate can differ by two orders of magnitude from the link rate, depending on the router and ICMP type. This ambiguity suggests that capacity estimates by ICMP-based tools may need to heavily use router and interface fingerprinting.

We found that Juniper’s TimeExceeded processing is based on 64-byte cells (Fig. 3a). We plan to investigate whether the 48-byte cell granularity of the Cisco documented in [32] is present in our data.

Our analysis shows that ICMP delay can depend on packet size and header fields in various non-intuitive ways, including:
- Different growth rates under and over 1500 bytes (piecewise linearity, Fig. 7, 8)
- Jumps or drops (discontinuity, Fig. 3)
- Stepwise growth, e.g., each 64 bytes (Fig. 3)
- Negative (decreasing) slope with respect to packet size (Fig. 4, 8, Table 2)
- Internal tasks can postpone packet scheduling by fixed delays (clustering in distinct "bands") on an absolutely empty device (Fig. 8, 9)
- Warming up caches can cause significant (20-30 µs) extra latency for widely spaced probes (Fig. 6, 5, 7, 8)

Table 4 summarizes our main results and lists three cases of linearity of message generation delay with respect to packet size (fully linear, linear with a break, stepwise linear with jumps) observed for the three router types studied. In contrast with prevalent assumptions used by some rate estimation tools, none of our studied routers has a TimeExceeded generation rate equal to the line rate of the inbound link for packets under 1500 bytes. One router has an ICMP rate that is 20 times slower than its line rate (the ratio of generation rate to line rate is 0.05, Table 4). Other routers use optimizations that create an illusion of a faster ICMP rate at the expense of increasing minimal ICMP delay. These properties can facilitate remote device/link fingerprinting.

Our results indicate surprisingly different attitudes of router vendors (from restrictive to receptive to acceptive) with regard to ICMP Time Exceeded messages. Our work in progress suggests that many of these attitudes apply to other ICMP messages too.

#### Future Work
Areas for further investigation include confirming details on the phenomena mentioned above, as well as forwarding delays, payload-dependent delays, cross-traffic effects, rate estimates based on optimization techniques, and independence tests.

### Acknowledgements
Dan Andersen, Brendan White, Grant Duvall, Margaret Murray, and Kevin Walsh created the lab used in this study. Ken Keys helped with the Coral software. Yoshi Kohno provided the linear programming code. Thanks to the PAM reviewers for their comments, all of which we incorporated in the text. Thanks also to Allen Porter, Dave Berlin, Niheer Patel, Xin Cai, Andrey Shapiro, and Tin Tran for their useful feedback on this report.

### References
[References listed as provided, with proper formatting and citations.]

This revised version aims to provide a clearer, more coherent, and professional presentation of the data, analysis, and conclusions.