### Data Collection and Privacy Measures

Our data collection methodology adheres to strict privacy and ethical standards. We aggregate the data in a way that never tracks or analyzes individual user behavior. We do not share raw data outside of Google, and we set a short retention period for collected data, after which only aggregated data is stored. Our system is designed to be compatible with all clients, ensuring no degradation in user experience due to crashes. Additionally, our system does not interfere with ad injectors or tamper with the client's DOM; it only provides a passive measure of ad injection in the wild.

### Identifying Distribution Vectors

To identify the distribution vectors of ad injectors, we conducted a comprehensive analysis. This involved dynamically analyzing over 1 million browser extensions and 25 million binaries. We also employed a secondary technique to detect network-based injectors.

#### Browser Extensions

We used WebEval, Google’s internal system for reviewing Chrome extensions, and Hulk, an independent system for detecting malicious Chrome extensions, to analyze ad injection via browser extensions. We obtained extensions from three sources: web crawling, extensions installed or side-loaded by binaries provided by Safe Browsing, and all extensions in the Chrome Web Store. WebEval evaluated over 1 million extensions created between March 2011 and October 2014, while Hulk focused on 91,660 extensions crawled from the Web Store.

**WebEval Analysis Pipeline:**
- **Static Analysis:** WebEval scans the extension's HTML, JavaScript, and manifest permissions. It identifies sensitive permissions such as intercepting web requests, unrestricted access to cookies, and the ability to prevent uninstallation. It also checks for code obfuscation, the use of `eval()`, and embedded URLs.
- **Dynamic Analysis:** WebEval launches a virtualized Windows environment and installs the extension in an instrumented Chrome browser. The testing environment captures all Chrome API calls, DOM method calls, and network requests. It actively man-in-the-middles HTTPS connections to inspect packet contents.

#### Binaries

Safe Browsing dynamically evaluated over 25 million unique binaries from February to October 2014. Of these, 34,407 were categorized as ad injectors.

#### Network

We used client-side measurements to detect network-based ad injectors. These actors intercept page content in transit to inject scripts or directly inject ad-based DOM elements. We compared the fraction of tampered DOMs served over HTTP versus HTTPS to detect potential tampering. This approach assumes that a network attacker does not have a valid certificate to man-in-the-middle HTTPS connections.

### Pinpointing Advertisers and Intermediaries

The ad injection ecosystem relies on advertisers paying for traffic from injectors, involving a complex network of intermediaries. To unravel this, we automatically visited creatives (e.g., ad text, images, and objects) served by ad injectors and enumerated all parties involved.

**Acquiring Creatives:**
- We dynamically executed Chrome in a virtualized environment with an ad injector installed and visited a suite of pages that trigger ad insertion. This approach simplifies the process by avoiding the need to reverse engineer the ad request protocol for each injector.

**Identifying Trigger Pages:**
- We manually scanned the Alexa Top 100 in Chrome, cycling through 14 different ad injection extensions. This set of extensions provides non-overlapping coverage of the top injection libraries observed in the wild.

### Design Decisions and Related Approaches

When designing our client-side detection, we opted for whitelisting rather than blacklisting page elements. This approach requires no knowledge of active threats and is more robust to changes in ad injection techniques over time. Our strategy is similar to "web tripwires" used to detect in-flight page changes, but we expand on this idea to identify specific injected elements.

Our system is also similar to Content Security Policies (CSP), supported by modern browsers, which rely on server-specified whitelists to prevent or report cross-origin requests. However, we chose a JavaScript payload for finer-grain reporting and broader browser compatibility. At the time of writing, CSP was only supported in Chrome, Firefox, and Safari, with enforcement in Internet Explorer still in development.

### Ethics and Privacy

Our data collection technique is analogous to Content Security Policies, which modern browsers use to report client-side telemetry of page integrity to website operators. Google’s internal privacy review board vetted and approved our architecture and the data it collects. Restrictions include never analyzing data in non-aggregated form and setting a short lifetime on the collected data.

By following these guidelines, we ensure that our system is both effective and respectful of user privacy.