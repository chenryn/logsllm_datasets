### DenseNet Performance Metrics

- **Fully Connected Layers:**
  - **Training Accuracy (Train Acc.):** 100.0%
  - **Testing Accuracy (Test Acc.):** 
    - 39.8%
    - 95.2%
    - 64.3%
    - 48.6%
    - 77.5%

- **Distinguishing Between D, DΔ, and ¯D:**
  - **Distinguish D from DΔ:**
    - 62.1%
    - 63.3%
    - 58.4%
    - 64.4%
  - **Distinguish D from ¯D:**
    - 75.4%
    - 74.6%
    - 68.4%
    - 73.8%
  - **Distinguish DΔ from ¯D:**
    - 71.3%
    - 71.5%
    - 67.2%
    - 71.2%

- **Gradient Norms for Member and Non-Member Instances:**
  - **Member Instances:**
    - 0.7
    - 0.6
    - 0.5
    - 0.4
    - 0.3
    - 0.2
    - 0.1
    - 0
  - **Non-Member Instances:**
    - 0
    - 20
    - 40
    - 60
    - 80
  - **Training Epochs:**
    - 0
    - 20
    - 40
    - 60
    - 80

### Figure 3: Gradient Norms During Learning Epochs
- **Description:** Gradient norms of the last layer during learning epochs for member and non-member instances (for Purchase100).
- **Observation:** The underlying distribution is unknown to the attacker, but they can classify tested records into two clusters as described in Section II-D.

### Implementation and Comparison
- **Attack Implementation:**
  - We implemented our attack and compared its performance with Shadow models by Shokri et al. [6].
  - **Datasets Used:**
    - Texas100
    - Purchase100
    - CIFAR100
  - **Training Details:**
    - For Texas100 and Purchase100, we trained a single Shadow model using training sizes according to Table II.
    - For CIFAR100, the Shadow model uses a training dataset that overlaps with the target model’s dataset due to limited instances (50,000 out of 60,000 available records).

- **Clustering:**
  - After training, we used the Spectral clustering algorithm [14] to divide input samples into two clusters.
  - **Label Assignment:**
    - Member label to the cluster with smaller average gradient norm.
    - Non-member label to the other cluster.

### Table VII: Attack Accuracy Comparison
- **Comparison:**
  - Our unsupervised attack offers higher accuracy compared to shadow training [6] on various datasets and architectures.
  - **Intuition:**
    - Encoded values of our unsupervised algorithm present different distributions for member and non-member samples, as shown in Figure 5.

### C. Stand-Alone Setting: Attacking Fine-Tuned Models
- **Scenario:**
  - Investigate privacy leakage in fine-tuned target models.
  - **Model Training:**
    - Initial training with dataset D.
    - Fine-tuning with dataset DΔ.
  - **Attacker Access:**
    - Access to both trained models (before and after fine-tuning).
  - **Goal:**
    - Distinguish between members of D, DΔ, and non-members (¯D).
  - **Experiment Details:**
    - 60% of the train dataset as D and the rest for DΔ.
    - **Results:**
      - Attacker can distinguish between members and non-members with high accuracy.
      - Can also distinguish between members of D and DΔ with reasonably high accuracies.

### D. Federated Learning Settings: Passive Inference Attacks
- **Dataset Sizes:**
  - Table XI shows the dataset sizes used in federated attack experiments.
  - **Local Attacker:**
    - Each participant uses 30,000 instances to train, with overlapping datasets due to limited instances.
  - **Passive Global Attacker:**
    - Access to target model parameters over multiple training epochs.
    - **Observation:**
      - Limited GPU resources allow observation during only five (non-consecutive) training epochs.
      - **Accuracy:**
        - Using later epochs increases attack accuracy.
        - Earlier epochs contain generic features, while later epochs contain more membership information.

### Table X: Federated Learning Attack Accuracy
- **Participants:**
  - 4 participants.
  - **Attackers:**
    - Global attacker (central parameter aggregator).
    - Local attacker (a participant).
  - **Attack Types:**
    - Passive
    - Active
  - **Results:**
    - Higher accuracy with active attacks, especially when isolating participants or using gradient ascent.

### Figures 4 and 5: Distribution of Gradient Norms and Encoded Values
- **Figure 4:**
  - Shows the distribution of gradient norms for member and non-member instances of different pre-trained models.
- **Figure 5:**
  - Shows the distribution of encoded values for member and non-member instances, highlighting the distinguishability of our unsupervised algorithm.

### Figure 6: ROC Curve for Different Uncertainty Classes
- **ROC Curve:**
  - For three different classes of data with large, medium, and small prediction uncertainty values (pre-trained CIFAR100-Alexnet model in the stand-alone scenario).