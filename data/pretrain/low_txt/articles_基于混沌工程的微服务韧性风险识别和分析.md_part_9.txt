以下是优化后的参考文献列表，使其更加清晰、连贯和专业：

1. [10.1109/RNDM.2017.8093034]
2. Haselböck, S., Weinreich, R., & Buchgeher, G. (2017). Decision guidance models for microservices: Service discovery and fault tolerance. In *Proceedings of the 5th European Conference on the Engineering of Computer-based Systems* (pp. 1-10). New York: ACM. [doi: 10.1145/3123779.3123804]
3. Heorhiadi, V., Rajagopalan, S., Jamjoom, H., et al. (2016). Gremlin: Systematic resilience testing of microservices. In *Proceedings of the 2016 IEEE 36th International Conference on Distributed Computing Systems (ICDCS)* (pp. 57-66). Piscataway: IEEE. [doi: 10.1109/ICDCS.2016.11]
4. Düllmann, T. F., & van Hoorn, A. (2017). Model-driven generation of microservice architectures for benchmarking performance and resilience engineering approaches. In *Proceedings of the 8th ACM/SPEC International Conference on Performance Engineering Companion* (pp. 171-172). New York: ACM. [doi: 10.1145/3053600.3053627]
5. Giedrimas, V., Omanovic, S., & Alic, D. (2018). The aspect of resilience in microservices-based software design. In *Proceedings of the Federation of International Conferences on Software Technologies: Applications and Foundations* (pp. 589-595). Cham: Springer-Verlag. [doi: 10.1007/978-3-030-04771-9_44]
6. Van Hoorn, A., Aleti, A., Düllmann, T. F., et al. (2018). ORCAS: Efficient resilience benchmarking of microservice architectures. In *Proceedings of the 2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)* (pp. 146-147). Piscataway: IEEE. [doi: 10.1109/ISSREW.2018.00-10]
7. Jagiełło, M., Rusek, M., & Karwowski, W. (2019). Performance and resilience to failures of a cloud-based application: Monolithic and microservices-based architectures compared. In *Proceedings of the IFIP International Conference on Computer Information Systems and Industrial Management* (pp. 445-456). Cham: Springer-Verlag. [doi: 10.1007/978-3-030-28957-7_37]
8. Williams, R. C., Pandelios, G. J., & Behrens, S. G. (1999). Software risk evaluation (SRE) method description: Version 2.0. Pittsburgh: Software Engineering Institute, Carnegie Mellon University.
9. Lee, W. S., Grosh, D. L., Tillman, F. A., et al. (1985). Fault tree analysis, methods, and applications—A review. *IEEE Transactions on Reliability*, 34(3), 194-203. [doi: 10.1109/TR.1985.5222114]
10. Alexander, I. (2003). Misuse cases: Use cases with hostile intent. *IEEE Software*, 20(1), 58-66. [doi: 10.1109/MS.2003.1159030]
11. Shostack, A. (2014). *Threat Modeling: Designing for Security*. John Wiley & Sons.
12. Stamatis, D. H. (2003). *Failure Mode and Effect Analysis: FMEA from Theory to Execution* (2nd ed.). Milwaukee: ASQ Quality Press.
13. Lindvall, M., Diep, M., Klein, M., et al. (2017). Safety-focused security requirements elicitation for medical device software. In *Proceedings of the 2017 IEEE 25th International Requirements Engineering Conference (RE)* (pp. 134-143). Piscataway: IEEE. [doi: 10.1109/RE.2017.21]
14. Friedberg, I., McLaughlin, K., Smith, P., et al. (2017). STPA-SafeSec: Safety and security analysis for cyber-physical systems. *Journal of Information Security and Applications*, 34(2), 183-196. [doi: 10.1016/j.jisa.2016.05.008]
15. Basiri, A., Behnam, N., de Rooij, R., et al. (2016). Chaos engineering. *IEEE Software*, 33(3), 35-41. [doi: 10.1109/MS.2016.60]
16. Tucker, H., Hochstein, L., Jones, N., et al. (2018). The business case for chaos engineering. *IEEE Cloud Computing*, 5(3), 45-54. [doi: 10.1109/MCC.2018.032591616]
17. Blohowiak, A., Basiri, A., Hochstein, L., et al. (2016). A platform for automating chaos experiments. In *Proceedings of the 2016 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)* (pp. 5-8). Piscataway: IEEE. [doi: 10.1109/ISSREW.2016.52]
18. Basiri, A., Hochstein, L., Jones, N., et al. (2019). Automating chaos experiments in production. In *Proceedings of the 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)* (pp. 31-40). Piscataway: IEEE. [doi: 10.1109/ICSE-SEIP.2019.00012]
19. Zhang, L., Morin, B., Haller, P., et al. (2019). A chaos engineering system for live analysis and falsification of exception-handling in the JVM. *IEEE Transactions on Software Engineering*, PrePrints: 1-1. [doi: 10.1109/TSE.2019.2954871]
20. Simonsson, J., Zhang, L., Morin, B., et al. (2019). Observability and chaos engineering on system calls for containerized applications in Docker. arXiv preprint arXiv:1907.13039.
21. Salinas, E. (2018). Tammy Bütow on chaos engineering. *IEEE Software*, 35(5), 125-128. [doi: 10.1109/MS.2018.3571246]
22. ThoughtWorks. (2018). Technology radar vol. 18. Retrieved from https://thoughtworks.com/radar
23. ThoughtWorks. (2019). Technology radar vol. 20. Retrieved from https://thoughtworks.com/radar
24. Sharma, B., Jayachandran, P., Verma, A., et al. (2013). CloudPD: Problem determination and diagnosis in shared dynamic clouds. In *Proceedings of the IEEE/IFIP International Conference on Dependable Systems & Networks* (pp. 1-12). Piscataway: IEEE. [doi: 10.1109/DSN.2013.6575298]
25. Bodik, P., Goldszmidt, M., Fox, A., et al. (2010). Fingerprinting the datacenter: Automated classification of performance crises. In *Proceedings of the 5th European Conference on Computer Systems* (pp. 111-124). New York: ACM. [doi: 10.1145/1755913.1755926]
26. Cherkasova, L., Kivanc, O., Mi, N. F., et al. (2009). Automated anomaly detection and performance modeling of enterprise applications. *ACM Transactions on Computer Systems*, 27(3), 1-32. [doi: 10.1145/1629087.1629089]
27. Duan, S., Babu, S., & Munagala, K. (2009). FA: A system for automating failure diagnosis. In *Proceedings of the 2009 IEEE 25th International Conference on Data Engineering* (pp. 1012-1023). Piscataway: IEEE. [doi: 10.1109/ICDE.2009.115]
28. Kandula, S., Mahajan, R., Verkaik, P., et al. (2009). Detailed diagnosis in enterprise networks. In *Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication* (pp. 243-254). New York: ACM. [doi: 10.1145/1592568.1592597]
29. Nguyen, H., Shen, Z., Tan, Y., et al. (2013). FChain: Toward black-box online fault localization for cloud systems. In *Proceedings of the 2013 IEEE 33rd International Conference on Distributed Computing Systems* (pp. 21-30). Piscataway: IEEE. [doi: 10.1109/ICDCS.2013.26]
30. Kandula, S., Chandra, R., & Katabi, D. (2008). What’s going on? Learning communication rules in edge networks. *ACM SIGCOMM Computer Communication Review*, 38(4), 87-98. [doi: 10.1145/1402958.1402970]
31. Nguyen, H., Tan, Y., & Gu, X. (2011). PAL: Propagation-aware anomaly localization for cloud-hosted distributed applications. In *Proceedings of the Managing Large-scale Systems via the Analysis of System Logs and the Application of Machine Learning Techniques (SLAML 2011)* (pp. 1-8). New York: ACM. [doi: 10.1145/2038633.2038634]
32. Fonseca, R., Porter, G., Katz, R. H., et al. (2007). X-Trace: A pervasive network tracing framework. In *Proceedings of the 4th USENIX Symposium on Networked Systems Design & Implementation (NSDI 2007)* (pp. 271-284). USENIX.
33. Chen, M. Y., Kiciman, E., Fratkin, E., et al. (2002). Pinpoint: Problem determination in large, dynamic Internet services. In *Proceedings of the International Conference on Dependable Systems and Networks* (pp. 595-604). Piscataway: IEEE. [doi: 10.1109/DSN.2002.1029005]
34. Zhao, X., Zhang, Y., Lion, D., et al. (2014). LProf: A non-intrusive request flow profiler for distributed systems. In *Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 2014)* (pp. 629-644). USENIX.
35. Chow, M., Meisner, D., Flinn, J., et al. (2014). The Mystery Machine: End-to-end performance analysis of large-scale Internet services. In *Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 2014)* (pp. 217-231). USENIX.
36. Wang, P., et al. (2018). CloudRanger: Root cause identification for cloud-native systems. In *Proceedings of the 2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)* (pp. 492-502). Piscataway: IEEE. [doi: 10.1109/CCGRID.2018.00076]
37. Lin, J. J., Chen, P., & Zheng, Z. (2018). Microscope: Pinpoint performance issues with causal graphs in micro-service environments. In *Proceedings of the International Conference on Service-Oriented Computing* (pp. 3-20). Cham: Springer-Verlag. [doi: 10.1007/978-3-030-03596-9_1]
38. Chen, P., Qi, Y., & Hou, D. (2019). CauseInfer: Automated end-to-end performance diagnosis with hierarchical causality graph in cloud environment. *IEEE Transactions on Service Computing*, 12(2), 214-230. [doi: 10.1109/TSC.2016.2607739]
39. Standard Performance Evaluation Corporation. (2000). SPEC Benchmark. Retrieved from https://www.spec.org/benchmarks.html
40. Transaction Processing Performance Council. (2010). TPC Benchmark™C—Standard Specification Revision 5.11. Retrieved from http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-c_v5.11.0.pdf
41. Transaction Processing Performance Council. (2003). TPC Benchmark™W—Standard Specification Revision 2.0r. Retrieved from http://tpc.org/tpc_documents_current_versions/pdf/tpcw_v2.0.0.pdf
42. European Telecommunications Standards Institute. (2016). ETSI GS NFV-TST 001: Network Functions Virtualisation (NFV); Pre-deployment Testing; Report on Validation of NFV Environments and Services. Retrieved from https://www.etsi.org/deliver/etsi_gs/NFV-TST/001_099/001/01.01.01_60/gs_NFV-TST001v010101p.pdf
43. Al-Masri, E., & Mahmoud, Q. H. (2007). QoS-based discovery and ranking of Web services. In *Proceedings of the 2007 16th International Conference on Computer Communications and Networks* (pp. 529-534). Piscataway: IEEE. [doi: 10.1109/ICCCN.2007.4317873]
44. Zhang, Y., Zheng, Z., & Lyu, M. R. (2010). WSExpress: A QoS-aware search engine for Web services. In *Proceedings of the 2010 IEEE International Conference on Web Services* (pp. 91-98). Piscataway: IEEE. [doi: 10.1109/ICWS.2010.20]
45. Kalepu, S., Krishnaswamy, S., & Loke, S. W. (2003). Verity: A QoS metric for selecting Web services and providers. In *Proceedings of the 4th International Conference on Web Information Systems Engineering Workshops* (pp. 131-139). Piscataway: IEEE. [doi: 10.1109/WISEW.2003.1286795]
46. Spirtes, P., Clark, G., & Richard, S. (1996). *Causation, Prediction, and Search* (2nd ed.). Cambridge: MIT Press. [doi: 10.1007/978-1-4612-2748-9]
47. Pearl, J. (2009). *Causality: Models, Reasoning, and Inference* (2nd ed.). New York: Cambridge University Press.
48. Anderson, T. W., & Amemiya, Y. (1988). The asymptotic normal distribution of estimators in factor analysis under general conditions. *The Annals of Statistics*, 16(2), 759-771. [doi: 10.1214/aos/1176350834]
49. Luo, C., Lou, J. G., Lin, Q., et al. (2014). Correlating events with time series for incident diagnosis. In *Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining* (pp. 1583-1592). New York: ACM. [doi: 10.1145/2623330.2623374]
50. Aderaldo, C. M., Mendonça, N. C., Pahl, C., et al. (2017). Benchmark requirements for microservices architecture research. In *Proceedings of the 1st International Workshop on Establishing the Community-wide Infrastructure for Architecture-based Software Engineering* (pp. 8-13). Piscataway: IEEE. [doi: 10.1109/ECASE.2017.4]
51. European Telecommunications Standards Institute. (2015). ETSI GS NFV-REL 001: Network Functions Virtualisation (NFV): Resiliency Requirements. Retrieved from https://www.etsi.org/deliver/etsi_gs/NFV-REL/001_099/001/01.01.01_60/gs_NFV-REL001v010101p.pdf
52. Thalheim, J., Rodrigues, A., Akkus, I. E., et al. (2017). Sieve: Actionable insights from monitored metrics in distributed systems. In *Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference* (pp. 14-27). New York: ACM. [doi: 10.1145/3135974.3135977]

**作者简介：**

殷康璘（1992-），男，博士，中国计算机学会学生会员。主要研究领域为软件工程与智能运维。

杜庆峰（1968-），男，博士，教授，博士生导师。主要研究领域为软件工程与质量控制、机器学习与智能运维。