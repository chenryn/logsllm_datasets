### Scalability and Side-Channel Information Flows

Current methods for verifying hardware security do not scale well beyond simple examples. Timing and other side-channel information flows are often not adequately modeled, and the computational scalability required to verify real-world complex Systems-on-Chip (SoCs) remains a significant challenge. For instance, verifying a single AES core can take approximately 30 minutes [6].

### Model Checking-Based Approaches

Model checking-based approaches involve verifying a given property against the modeled state space and possible state transitions using provided invariants and predefined conditions. These methods face scalability issues as the computation time scales exponentially with the size of the model and state space. This problem can be mitigated by using abstraction to simplify the model or by constraining the state space to a bounded number of states through assumptions and conditions. However, these techniques can introduce false positives, may miss vulnerabilities, and require expert knowledge. Industry-leading tools, such as the one used in this work, typically rely on model checking algorithms, including Boolean satisfiability problem solvers and property specification schemes like assertion-based verification, to ensure the required properties of a given hardware design.

### Side-Channel Leakage Modeling and Detection

Side-channel leakage modeling and detection remain an open problem. Recent work [76] uses the Murϕ model checker to verify different hardware cache architectures for side-channel leakage against various adversary models. A formal verification methodology for SGX and Sanctum enclaves under limited adversaries was introduced in [67]. However, these approaches are not directly applicable to hardware implementation and rely exclusively on formal verification, which is inherently limited by the underlying algorithms in terms of scalability and state space explosion. Additionally, they demand specific expertise to use effectively.

### Information Flow Analysis

Information flow analysis, such as Static Program Verification (SPV), works by assigning a security label (or taint) to data inputs and monitoring the propagation of this taint. This allows designers to verify whether the system adheres to the required security policies. Recently, information flow tracking (IFT) has been shown to be effective in identifying security vulnerabilities, including timing side channels and information-leaking hardware Trojans.

IFT techniques are proposed at different levels of abstraction: gate-level, Register-Transfer Level (RTL), and language-level. Gate-Level Information Flow Tracking (GLIFT) [2, 58, 70] performs IFT analysis directly at the gate level by generating GLIFT analysis logic derived from the original logic and operating in parallel. Although gate-level IFT logic is easy to generate automatically, it does not scale well. Furthermore, when IFT uses strict non-interference, it conservatively taints any information flow as a vulnerability [34], which scales well for more complex hardware but generates too many false positives.

At the language level, Caisson [42] and Sapper [41] are security-aware HDLs that use a typing system where the designer assigns security "labels" to each variable (wire or register) based on the required security policies. However, both require redesigning the RTL using a new hardware description language, which is impractical. SecVerilog [22, 75] overcomes this by extending the Verilog language with a dynamic security type system. Designers assign a security label to each variable in the RTL to enable compile-time checks of hardware information flow. However, this involves complex analysis during simulation to reason about the run-time behavior of the hardware state and dependencies across data types for precise flow tracking.

### Hardware/Firmware Co-Verification

Hardware/firmware co-verification to capture and verify interactions between hardware and firmware remains an open challenge and is not available in widely used industry-standard tools. A co-verification methodology [28] addresses the semantic gap between hardware and firmware by modeling both using instruction-level abstraction to leverage software verification techniques. However, this requires semi-automatic, cumbersome, and lossy modeling of the hardware that interacts with firmware.

While research is underway [71] to analyze a limited amount of low-level firmware running on top of a simulated RTL design, these approaches are still under development and not scalable. Current verification approaches focus on register-state information-flow analysis, e.g., to monitor whether sensitive locations are accessible from unprivileged signal sources. Further research is needed to explicitly model non-register states and timing alongside the existing capabilities of these tools.

### Recent Attacks

We present and cautiously classify the underlying hardware vulnerabilities of recent cross-layer exploits (see Table 2 in Appendix B), using the categories introduced in Section 3.1. We do not have access to proprietary processor implementations, so our classification is based on published technical descriptions. Yarom et al. demonstrated that software-visible side channels can exist even below cache-line granularity in CacheBleed [74], undermining a core assumption of prior defenses, such as scatter-gather [9]. MemJam [45] exploits false read-after-write dependencies in the CPU to maliciously slow down victim accesses to memory blocks within a cache line. We categorize the underlying vulnerabilities of CacheBleed and MemJam as potentially hard to detect in RTL due to the many cross-module connections involved and the timing-flow leakage. The timing flow leakage is caused by the software triggering clock cycle differences in accesses that map to the same bank below cache line granularity, thus breaking constant-time implementations.

The TLBleed [23] attack shows how current TLB implementations can be exploited to break state-of-the-art cache side-channel protections. As described in Section 4, TLBs are typically highly interconnected with complex processor modules, such as the cache controller and memory management unit, making vulnerabilities therein very hard to detect through automated verification or manual inspection.

BranchScope [20] extracts information through the directional branch predictor, bypassing software mitigations that prevent leakage via the BTB. We classify it as a cache-state gap in branch prediction units, which is significantly challenging to detect using existing RTL security verification tools, which cannot capture and verify cache states. Meltdown [43] exploits speculative execution on modern processors to completely bypass all memory access restrictions. Van Bulck et al. [72] also demonstrated how to apply this to Intel SGX. Similarly, Spectre [37] exploits out-of-order execution across different user-space processes as arbitrary instruction executions would continue during speculation. We recognize that these vulnerabilities are hard to detect due to scalability challenges in existing tools, as the out-of-order scheduling module is connected to many subsystems in the CPU. Additionally, manually inspecting these interconnected complex RTL modules is very challenging and cumbersome.

CLKScrew [69] abuses low-level power-management functionality exposed to software to induce faults and glitches dynamically at runtime in the processor. We categorize CLKScrew as having vulnerable hardware-firmware interactions and timing-flow leakage, as it directly exposes clock-tuning functionality to attacker-controlled software.

### Conclusion

Software security bugs and their impact have been known for many decades, with a spectrum of established techniques to detect and mitigate them. However, the threat of hardware security bugs has only recently become significant as cross-layer exploits have shown that they can completely undermine software security protections. While some hardware bugs can be patched with microcode updates, many cannot, often leaving millions of affected chips in the wild. In this paper, we presented the first testbed of RTL bugs and systematically analyzed the effectiveness of state-of-the-art formal verification techniques, manual inspection, and simulation methods in detecting these bugs. We organized an international hardware security competition and an in-house study. Our results showed that 54 teams were only able to detect 61% of the total number of bugs, while with industry-leading formal verification techniques, we were only able to detect 48% of the bugs. We showcase that the grave security impact of many of these undetected bugs is further exacerbated by being software-exploitable.

Our investigation revealed the limitations of state-of-the-art verification/detection techniques in detecting certain classes of hardware security bugs that exhibit particular properties. These approaches remain limited in detecting vulnerabilities that require capturing and verifying complex cross-module inter-dependencies, timing flows, cache states, and hardware-firmware interactions. While these effects are common in SoC designs, they are difficult to model, capture, and verify using current approaches. Our investigative work highlights the necessity of treating the detection of hardware bugs as significantly as that of software bugs. Through our work, we highlight the pressing call for further research to advance the state of the art in hardware security verification. Particularly, our results indicate the need for increased scalability, efficacy, and automation of these tools, making them easily applicable to large-scale commercial SoC designs—without which software protections are futile.

### Acknowledgments

We thank our anonymous reviewers and shepherd, Stephen Checkoway, for their valuable feedback. The work was supported by the Intel Collaborative Research Institute for Collaborative Autonomous & Resilient Systems (ICRI-CARS), the German Research Foundation (DFG) by CRC 1119 CROSSING P3, and the Office of Naval Research (ONR Award #N00014-18-1-2058). We would also like to acknowledge the co-organizers of Hack@DAC: Dan Holcomb (UMass-Amherst), Siddharth Garg (NYU), and Sourav Sudhir (TAMU), and the sponsors of Hack@DAC: the National Science Foundation (NSF CNS-1749175), NYU CCS, Mentor - a Siemens Business and CROSSING, as well as the participants of Hack@DAC.

### References

[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-flow integrity. ACM conference on Computer and communications security, pages 340–353, 2005.
[2] A. Ardeshiricham, W. Hu, J. Marxen, and R. Kastner. Register Transfer Level Information Flow Tracking for Provably Secure Hardware Design. Design, Automation & Test in Europe, pages 1695–1700, 2017.
[3] ARM. Security technology building a secure system using trust-zone technology (white paper). http://infocenter.arm.com/help/topic/com.arm.doc.prd29-genc-009492c/PRD29-GENC-009492C_trustzone_security_whitepaper.pdf, 2009.
[5] Averant. Solidify. http://www.averant.com/storage/documents/Solidify.pdf, 2018.
[6] M.-M. Bidmeshki, X. Guo, R. G. Dutta, Y. Jin, and Y. Makris. Data Secrecy Protection Through Information Flow Tracking in Proof-Carrying Hardware IP—Part II: Framework Automation. IEEE Transactions on Information Forensics and Security, 12(10):2430–2443, 2017.
[7] M.-M. Bidmeshki and Y. Makris. VeriCoq: A Verilog-to-Coq Converter for Proof-Carrying Hardware Automation. IEEE International Symposium on Circuits and Systems, pages 29–32, 2015.
[8] F. Brasser, D. Gens, P. Jauernig, A.-R. Sadeghi, and E. Stapf. SANCTUARY: ARMing TrustZone with User-space Enclaves. Network and Distributed System Security Symposium (NDSS), 2019.
[9] E. Brickell, G. Graunke, M. Neve, and J.-P. Seifert. Software mitigations to hedge AES against cache-based software side channel vulnerabilities. IACR Cryptology ePrint Archive, 2006:52, 2006.
[10] Cadence. Incisive Enterprise Simulator. https://www.cadence.com/content/cadence-www/global/en_US/home/tools/system-design-and-verification/simulation-and-testbench-verification/incisive-enterprise-simulator.html, 2014.
[11] Cadence. JasperGold Formal Verification Platform. https://www.cadence.com/content/cadence-www/global/en_US/home/tools/system-design-and-verification/formal-and-static-verification/jasper-gold-verification-platform.html, 2014.
[12] Cadence. JasperGold Security Path Verification App. https://www.cadence.com/content/cadence-www/global/en_US/home/tools/system-design-and-verification/formal-and-static-verification/jasper-gold-verification-platform/security-path-verification-app.html, 2018. Last accessed on 09/09/18.
[13] M. Castro, M. Costa, and T. Harris. Securing software by enforcing data-flow integrity. USENIX Symposium on Operating Systems Design and Implementation, pages 147–160, 2006.
[14] D. P. Christopher Celio, Krste Asanovic. The Berkeley Out-of-Order Machine. https://riscv.org/wp-content/uploads/2016/01/Wed1345-RISCV-Workshop-3-BOOM.pdf, 2016.
[15] Cisco. Cisco: Strengthening Cisco Products. https://www.cisco.com/c/en/us/about/security-center/security-programs/secure-development-lifecycle.html, 2017.
[16] E. M. Clarke, W. Klieber, M. Nováček, and P. Zuliani. Model checking and the state explosion problem. Tools for Practical Software Verification, 2012.
[17] K. Conger. Apple announces long-awaited bug bounty program. https://techcrunch.com/2016/08/04/apple-announces-long-awaited-bug-bounty-program/, 2016.
[18] V. Costan, I. A. Lebedev, and S. Devadas. Sanctum: Minimal Hardware Extensions for Strong Software Isolation. USENIX Security Symposium, pages 857–874, 2016.
[19] O. Demir, W. Xiong, F. Zaghloul, and J. Szefer. Survey of approaches for security verification of hardware/software systems. https://eprint.iacr.org/2016/846.pdf, 2016.
[4] R. Armstrong, R. Punnoose, M. Wong, and J. Mayo. Survey of Existing Tools for Formal Verification. Sandia National Laboratories. https://prod.sandia.gov/techlib-noauth/access-control.cgi/2014/1420533.pdf, 2014.
[20] D. Evtyushkin, R. Riley, N. C. Abu-Ghazaleh, D. Ponomarev, et al. BranchScope: A New Side-Channel Attack on Directional Branch Predictor. ACM Conference on Architectural Support for Programming Languages and Operating Systems, pages 693–707, 2018.
[21] F. Farahmandi, Y. Huang, and P. Mishra. Formal Approaches to Hardware Trust Verification. The Hardware Trojan War, 2018.
[22] A. Ferraiuolo, R. Xu, D. Zhang, A. C. Myers, and G. E. Suh. Verification of a Practical Hardware Security Architecture Through Static Information Flow Analysis. ACM Conference on Architectural Support for Programming Languages and Operating Systems, pages 555–568, 2017.
[23] B. Gras, K. Razavi, H. Bos, and C. Giuffrida. Translation Leak-aside Buffer: Defeating Cache Side-channel Protections with TLB Attacks. USENIX Security Symposium, 2018.
[24] D. Gruss, C. Maurice, A. Fogh, M. Lipp, and S. Mangard. Prefetch Side-Channel Attacks: Bypassing SMAP and Kernel ASLR. Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pages 368–379, 2016.
[25] M. Hicks, C. Sturton, S. T. King, and J. M. Smith. SPECS: A Lightweight Runtime Mechanism for Protecting Software from Security-Critical Processor Bugs. In Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS. ACM, 2015.
[26] M. Howard and S. Lipner. The Security Development Lifecycle. Microsoft Press Redmond, 2006.
[27] H. Hu, S. Shinde, A. Sendroiu, Z. L. Chua, P. Saxena, and Z. Liang. Data-oriented programming: On the expressiveness of non-control data attacks. IEEE Symposium on Security and Privacy, 2016.
[28] B.-Y. Huang, S. Ray, A. Gupta, J. M. Fung, and S. Malik. Formal Security Verification of Concurrent Firmware in SoCs Using Instruction-level Abstraction for Hardware. ACM Annual Design Automation Conference, pages 91:1–91:6, 2018.
[29] R. Hund, C. Willems, and T. Holz. Practical timing side channel attacks against kernel space ASLR. Symposium on Security and Privacy, 2013.
[30] F. Inc. Common Vulnerability Scoring System v3.0. https://www.first.org/cvss/cvss-v30-specification-v1.8.pdf, 2018.
[31] Intel. Intel Software Guard Extensions (Intel SGX). https://software.intel.com/en-us/sgx, 2016. Last accessed on 09/05/18.
[32] Intel. Intel Bug Bounty Program. https://www.intel.com/content/www/us/en/security-center/bug-bounty-program.html, 2018.
[33] S. Islam, A. Moghimi, I. Bruhns, M. Krebbel, B. Gulmezoglu, T. Eisenbarth, and B. Sunar. SPOILER: Speculative Load Hazards Boost Rowhammer and Cache Attacks. https://arxiv.org/abs/1903.00446, 2019.
[38] C. Lattner and V. S. Adve. LLVM: A compilation framework for lifelong program analysis & transformation. International Symposium on Code Generation and Optimization, 2004.
[39] D. Lee. Keystone enclave: An open-source secure enclave for RISC-V. https://keystone-enclave.org/, 2018.
[40] Lenovo. Lenovo: Taking Action on Product Security. https://www.lenovo.com/us/en/product-security/about-lenovo-product-security, 2017.
[41] X. Li, V. Kashyap, J. K. Oberg, M. Tiwari, V. R. Rajarathinam, R. Kastner, T. Sherwood, B. Hardekopf, and F. T. Chong. Sapper: A Language for Hardware-level Security Policy Enforcement. International Conference on Architectural Support for Programming Languages and Operating Systems, pages 97–112, 2014.
[42] X. Li, M. Tiwari, J. K. Oberg, V. Kashyap, F. T. Chong, T. Sherwood, and B. Hardekopf. Caisson: A Hardware Description Language for Secure Information Flow. ACM SIGPLAN Conference on Programming Language Design and Implementation, 46(6):109–120, 2011.
[43] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg. Meltdown. https://arxiv.org/abs/1801.01207, 2018.
[44] Mentor. Questa Verification Solution. https://www.mentor.com/products/fv/questa-verification-platform, 2018.
[45] A. Moghimi, T. Eisenbarth, and B. Sunar. MemJam: A false dependency attack against constant-time crypto implementations in SGX. Cryptographers’ Track at the RSA Conference, pages 21–44, 2018.