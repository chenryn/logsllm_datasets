### 6.3.4 Cross-site Tracing Attacks

Analysis of webgoat and several other applications revealed a previously unknown vulnerability in core J2EE libraries, which are used by thousands of Java applications. This vulnerability is related to the `TRACE` method specified in the HTTP protocol. The `TRACE` method is used to echo the contents of an HTTP request back to the client for debugging purposes. However, if the contents of user-provided headers are sent back verbatim, it can enable cross-site scripting (XSS) attacks.

This variant of cross-site scripting, caused by a vulnerability in the HTTP protocol specification, was previously discovered, although its presence in J2EE had not been publicly announced. This type of attack is known as cross-site tracing and is responsible for CERT vulnerabilities 244729, 711843, and 728563. Since this behavior is specified by the HTTP protocol, there is no straightforward way to fix the issue at the source level. General recommendations for mitigating cross-site tracing include disabling the `TRACE` functionality on the server or disabling client-side scripting [18].

### 6.4 Analysis Features and False Positives

The version of our analysis that employs both context sensitivity and improved object naming, as described in Section 4, achieves very precise results, as measured by the number of false positives. In this section, we examine the contribution of each feature of our static analysis approach to the precision of our results. We also explain the causes of the remaining 12 false positives reported by the most precise analysis version.

To analyze the importance of each analysis feature, we examined the number of false positives and the number of tainted objects reported by each variation of the analysis. Tainted objects provide a useful metric for analysis precision: as the analysis becomes more precise, the number of objects deemed to be tainted decreases.

Figure 10(a) summarizes the results for the four different analysis versions. The first part of the table shows the number of tainted objects reported by the analysis. The second part of the table shows the number of reported security violations. The third part of the table summarizes the number of false positives. Finally, the last column provides the number of real errors detected for each benchmark. Figure 10(b) provides a graphical representation of the number of tainted objects for different analysis variations.

**Key Observations:**
- Context sensitivity combined with improved object naming achieves a very low number of false positives. For all applications except snipsnap, the number of false positives was zero. For snipsnap, the number of false positives was reduced by more than 50 times compared to the context-insensitive analysis version with no naming improvements.
- Excluding the small program jboard, the most precise version on average reported five times fewer tainted objects than the least precise. For roller, our largest benchmark, the number of tainted objects dropped more than 15-fold.
- All 12 false positives reported by the most precise version were located in snipsnap and were caused by insufficient precision of the default allocation site-based object-naming scheme. The default naming caused an allocation site in snipsnap to be conservatively considered tainted because a tainted object could propagate to that allocation site. The allocation site in question is located within `StringWriter.toString()`, a JDK function similar to `String.toLowerCase()` that returns a tainted `String` only if the underlying `StringWriter` is constructed from a tainted string. Our analysis conservatively concluded that the return result of this method may be tainted, causing a vulnerability to be reported, where none can occur at runtime. All the false positives in snipsnap can be eliminated by creating a new object name at every call to `StringWriter.toString()`, which is achieved with a one-line change to the pointer analysis specification.

### 7 Related Work

In this section, we first discuss penetration testing and runtime monitoring, two of the most commonly used approaches for finding vulnerabilities besides manual code reviews. We also review the relevant literature on static analysis for improving software security.

#### 7.1 Penetration Testing

Current practical solutions for detecting web application security problems generally fall into the realm of penetration testing [3, 5, 15, 36, 44]. Penetration testing involves attempting to exploit vulnerabilities in a web application or crashing it by using a set of appropriate malicious input values. Penetration reports usually include a list of identified vulnerabilities [25]. However, this approach is incomplete. A penetration test can usually reveal only a small sample of all possible security risks in a system without identifying the parts of the system that have not been adequately tested. Generally, there are no standards that define which tests to run and which inputs to try. In most cases, this approach is not effective, and considerable program knowledge is needed to find application-level security errors successfully.

#### 7.2 Runtime Monitoring

A variety of both free and commercial runtime monitoring tools for evaluating web application security are available. Proxies intercept HTTP and HTTPS data between the server and the client, so that data, including cookies and form fields, can be examined and modified, and resubmitted to the application [9, 42]. Commercial application-level firewalls available from NetContinuum, Imperva, Watchfire, and other companies take this concept further by creating a model of valid interactions between the user and the application and warning about violations of this model. Some application-level firewalls are based on signatures that guard against known types of attacks. The white-listing approach specifies what the valid inputs are; however, maintaining the rules for white-listing is challenging. In contrast, our technique can prevent security errors before they have a chance to manifest themselves.

#### 7.3 Static Analysis Approaches

A good overview of static analysis approaches applied to security problems is provided in [8]. Simple lexical approaches employed by scanning tools such as ITS4 and RATS use a set of predefined patterns to identify potentially dangerous areas of a program [56]. While a significant improvement over Unix `grep`, these tools have no knowledge of how data propagates throughout the program and cannot be used to automatically and fully solve taint-style problems.

A few projects use path-sensitive analysis to find errors in C and C++ programs [6, 20, 33]. While capable of addressing taint-style problems, these tools rely on an unsound approach to pointers and may therefore miss some errors. The WebSSARI project uses combined unsound static and dynamic analysis in the context of analyzing PHP programs [23]. WebSSARI has successfully been applied to find many SQL injection and cross-site scripting vulnerabilities in PHP code.

An analysis approach that uses type qualifiers has been proven successful in finding security errors in C for the problems of detecting format string violations and user/kernel bugs [26, 45]. Context sensitivity significantly reduces the rate of false positives encountered with this technique; however, it is unclear how scalable the context-sensitive approach is.

Much of the work in information-flow analysis uses a type-checking approach, as exemplified by JFlow [38]. The compiler reads a program containing labeled types and, in checking the types, ensures that the program cannot contain improper information flow at runtime. The security type system in such a language enforces information-flow policies. The annotation effort, however, may be prohibitively expensive in practice. In addition to explicit information flows, our approach addresses, JFlow also deals with implicit information flows.

Static analysis has been applied to analyzing SQL statements constructed in Java programs that may lead to SQL injection vulnerabilities [17, 53]. That work analyzes strings that represent SQL statements to check for potential type violations and tautologies. This approach assumes that a flow graph representing how string values can propagate through the program has been constructed a priori from points-to analysis results. However, since accurate pointer information is necessary to construct an accurate flow graph, it is unclear whether this technique can achieve the scalability and precision needed to detect errors in large systems.

### 8 Conclusions

In this paper, we showed how a general class of security errors in Java applications can be formulated as instances of the general tainted object propagation problem, which involves finding all sink objects derivable from source objects via a set of given derivation rules. We developed a precise and scalable analysis for this problem based on a precise context-sensitive pointer alias analysis and introduced extensions to the handling of strings and containers to further improve the precision. Our approach finds all vulnerabilities matching the specification within the statically analyzed code. Note, however, that errors may be missed if the user-provided specification is incomplete.

We formulated a variety of widespread vulnerabilities, including SQL injections, cross-site scripting, HTTP splitting attacks, and other types of vulnerabilities, as tainted object propagation problems. Our experimental results showed that our analysis is an effective practical tool for finding security vulnerabilities. We were able to find a total of 29 security errors, and all but one of our nine large real-life benchmark applications were vulnerable. Two vulnerabilities were located in commonly used libraries, thus subjecting applications using the libraries to potential vulnerabilities. Most of the security errors we reported were confirmed as exploitable vulnerabilities by their maintainers, resulting in more than a dozen code fixes. The analysis reported false positives for only one application. We determined that the false warnings reported can be eliminated with improved object naming.

### 9 Acknowledgements

We are grateful to Michael Martin for his help with PQL and dynamic validation of some of the vulnerabilities we found and to John Whaley for his support with the bddbddb tool and the joeq framework. We thank our paper shepherd R. Sekar, whose insightful comments helped improve this paper considerably. We thank the benchmark application maintainers for responding to our bug reports. We thank Amit Klein for providing detailed clarifications about web application vulnerabilities and Ramesh Chandra, Chris Unkel, and Ted Kremenek, and the anonymous paper reviewers for providing additional helpful comments. Finally, this material is based upon work supported by the National Science Foundation under Grant No. 0326227.

### References

[1] C. Anley. Advanced SQL injection in SQL Server applications. http://www.nextgenss.com/papers/advanced sql injection.pdf, 2002.
[2] C. Anley. (more) advanced SQL injection. http://www.nextgenss.com/papers/more advanced sql injection.pdf, 2002.
[3] B. Arkin, S. Stender, and G. McGraw. Software penetration testing. IEEE Security and Privacy, 3(1):84–87, 2005.
[4] K. Beaver. Achieving Sarbanes-Oxley compliance for web applications through security testing. http://www.spidynamics.com/support/whitepapers/WI SOXwhitepaper.pdf, 2003.
[5] B. Buege, R. Layman, and A. Taylor. Hacking Exposed: J2EE and Java: Developing Secure Applications with Java Technology. McGraw-Hill/Osborne, 2002.
[6] W. R. Bush, J. D. Pincus, and D. J. Sielaff. A static analyzer for finding dynamic programming errors. Software - Practice and Experience (SPE), 30:775–802, 2000.
[7] CGI Security. The cross-site scripting FAQ. http://www.cgisecurity.net/articles/xss-faq.shtml.
[8] B. Chess and G. McGraw. Static analysis for security. IEEE Security and Privacy, 2(6):76–79, 2004.
[9] Chinotec Technologies. Paros—a tool for web application security assessment. http://www.parosproxy.org, 2004.
[10] Computer Security Institute. Computer crime and security survey. http://www.gocsi.com/press/20020407.jhtml?requestid=195148, 2002.
[11] S. Cook. A web developer's guide to cross-site scripting. http://www.giac.org/practical/GSEC/Steve Cook GSEC.pdf, 2003.
[12] C. Cowan, C. Pu, D. Maier, J. Walpole, P. Bakke, S. Beattie, A. Grier, P. Wagle, Q. Zhang, and H. Hinton. StackGuard: Automatic adaptive detection and prevention of buffer-overflow attacks. In Proceedings of the 7th USENIX Security Conference, pages 63–78, January 1998.
[13] J. D'Anjou, S. Fairbrother, D. Kehn, J. Kellerman, and P. McCarthy. Java Developer’s Guide to Eclipse. Addison-Wesley Professional, 2004.
[14] S. Friedl. SQL injection attacks by example. http://www.unixwiz.net/techtips/sql-injection.html, 2004.
[15] D. Geer and J. Harthorne. Penetration testing: A duet. http://www.acsac.org/2002/papers/geer.pdf, 2002.
[16] Gentoo Linux Security Advisory. SnipSnap: HTTP response splitting. http://www.gentoo.org/security/en/glsa/glsa-200409-23.xml, 2004.
[17] C. Gould, Z. Su, and P. Devanbu. Static checking of dynamically generated queries in database applications. In Proceedings of the 26th International Conference on Software Engineering, pages 645–654, 2004.
[18] J. Grossman. Cross-site tracing (XST): The new techniques and emerging threats to bypass current web security measures using TRACE and XSS. http://www.cgisecurity.com/whitehat-mirror/WhitePaper screen.pdf, 2003.
[19] J. Grossman. WASC activities and U.S. web application security trends. http://www.whitehatsec.com/presentations/WASC WASF 1.02.pdf, 2004.
[20] S. Hallem, B. Chelf, Y. Xie, and D. Engler. A system and language for building system-specific, static analyses. In Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design and Implementation, pages 69–82, 2002.
[21] M. Howard and D. LeBlanc. Writing Secure Code. Microsoft Press, 2001.
[22] D. Hu. Preventing cross-site scripting vulnerability. http://www.giac.org/practical/GSEC/Deyu Hu GSEC.pdf, 2004.
[23] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D.-T. Lee, and S.-Y. Kuo. Securing web application code by static analysis and runtime protection. In Proceedings of the 13th conference on World Wide Web, pages 40–52, 2004.
[24] G. Hulme. New software may improve application security. http://www.informationweek.com/story/IWK20010209S0003, 2001.
[25] Imperva, Inc. SuperVeda penetration test. http://www.imperva.com/download.asp?id=3.
[26] R. Johnson and D. Wagner. Finding user/kernel pointer bugs with type inference. In Proceedings of the 2004 Usenix Security Conference, pages 119–134, 2004.
[27] A. Klein. Hacking web applications using cookie poisoning. http://www.cgisecurity.com/lib/CookiePoisoningByline.pdf, 2002.
[28] A. Klein. Divide and conquer: HTTP response poisoning attacks, web cache, and related topics. http://www.packetstormsecurity.org/papers/general/whitepaper httpresponse.pdf, 2004.
[29] S. Kost. An introduction to SQL injection attacks for Oracle developers. http://www.net-security.org/dl/articles/IntegrigyIntrotoSQLInjectionAttacks.pdf, 2004.
[30] M. Krax. Mozilla foundation security advisory 2005-38. http://www.mozilla.org/security/announce/mfsa2005-38.html, 2005.
[31] D. Litchfield. Oracle multiple PL/SQL injection vulnerabilities. http://www.securityfocus.com/archive/1/385333/2004-12-20/2004-12-26/0, 2003.
[32] D. Litchfield. SQL Server Security. McGraw-Hill Osborne Media, 2003.
[33] V. B. Livshits and M. S. Lam. Tracking pointers with path and context sensitivity for bug detection in C programs. In Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering, pages 317–326, Sept. 2003.
[34] V. B. Livshits and M. S. Lam. Detecting security vulnerabilities in Java applications with static analysis. Technical report. Stanford University. http://suif.stanford.edu/~livshits/papers/tr/webappsec tr.pdf, 2005.
[35] M. Martin, V. B. Livshits, and M. S. Lam. Finding application errors using PQL: a program query language (to be published). In Proceedings of the ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA), Oct. 2005.
[36] J. Melbourne and D. Jorm. Penetration testing for web applications. http://www.securityfocus.com/infocus/1704, 2003.
[37] J. S. Miller, S. Ragsdale, and J. Miller. The Common Language Infrastructure Annotated Standard. Addison-Wesley Professional, 2003.
[38] A. C. Myers. JFlow: practical mostly-static information flow control. In Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 228–241, Jan. 1999.
[39] NetContinuum, Inc. The 21 primary classes of web application threats. https://www.netcontinuum.com/securityCentral/TopThreatTypes/index.cfm, 2004.
[40] Open Web Application Security Project. A guide to building secure web applications. http://voxel.dl.sourceforge.net/sourceforge/owasp/OWASPGuideV1.1.pdf, 2004.
[41] Open Web Application Security Project. The ten most critical web application security vulnerabilities. http://umn.dl.sourceforge.net/sourceforge/owasp/OWASPTopTen2004.pdf, 2004.
[42] Open Web Application Security Project. WebScarab. http://www.owasp.org/software/webscarab.html, 2004.
[43] S. Sagiv, T. Reps, and R. Wilhelm. Parametric shape analysis via 3-valued logic. In Proceedings of the 26th ACM Symposium on Principles of Programming Languages, pages 105–118, Jan. 1999.
[44] J. Scambray and M. Shema. Web Applications (Hacking Exposed). Addison-Wesley Professional, 2002.
[45] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting format string vulnerabilities with type qualifiers. In Proceedings of the 2001 Usenix Security Conference, pages 201–220, Aug. 2001.
[46] K. Spett. Cross-site scripting: Are your web applications vulnerable? http://www.spidynamics.com/support/whitepapers/SPIcross-sitescripting.pdf, 2002.
[47] K. Spett. SQL injection: Are your web applications vulnerable? http://downloads.securityfocus.com/library/SQLInjectionWhitePaper.pdf, 2002.
[48] B. Steensgaard. Points-to analysis in almost linear time. In Proceedings of the 23rd ACM Symposium on Principles of Programming Languages, pages 32–41, Jan. 1996.
[49] M. Surf and A. Shulman. How safe is it out there? http://www.imperva.com/download.asp?id=23, 2004.
[50] J. D. Ullman. Principles of Database and Knowledge-Base Systems. Computer Science Press, Rockville, Md., volume II edition, 1989.
[51] D. Wagner, J. Foster, E. Brewer, and A. Aiken. A first step towards automated detection of buffer overrun vulnerabilities. In Proceedings of Network and Distributed Systems Security Symposium, pages 3–17, Feb. 2000.
[52] L. Wall, T. Christiansen, and R. Schwartz. Programming Perl. O’Reilly and Associates, Sebastopol, CA, 1996.
[53] G. Wassermann and Z. Su. An analysis framework for security in web applications. In Proceedings of the Specification and Verification of Component-Based Systems Workshop, Oct. 2004.
[54] WebCohort, Inc. Only 10% of web applications are secured against common hacking techniques. http://www.imperva.com/company/news/2004-feb-02.html, 2004.
[55] J. Whaley and M. S. Lam. Cloning-based context-sensitive pointer alias analysis using binary decision diagrams. In Proceedings of the ACM SIGPLAN 2004 conference on Programming Language Design and Implementation, pages 131–144, June 2004.
[56] J. Wilander and M. Kamkar. A comparison of publicly available tools for static intrusion prevention. In Proceedings of 7th Nordic Workshop on Secure IT Systems, Nov. 2002.

---

This revised text is more structured, clear, and professional, making it easier to read and understand.