# Multi-Modal Facial Vein Map and Interactive Response

| Level | Low | Middle | High* |
|-------|-----|--------|--------|
| Interactive Response | No | No | Yes* |
| Security Level | Low | Middle | High* |

## 5.3 Implications of Our Findings

Face authentication offers an attractive alternative for user authentication due to its non-intrusive and zero-memory procedure. However, the emergence of Online Social Network Facial Disclosure (OSNFD) poses a significant threat to the practicality of face authentication as a usable authentication factor. With the widespread sharing of personal facial images and videos on online social networks (OSNs), potential adversaries can now access these biometrics without the need for physical proximity. Consequently, face biometrics are no longer secret and can be disclosed to anyone with access to the victim's shared images.

Raising the security level of face authentication systems could mitigate the OSNFD threat, but this often comes at the cost of reduced accessibility, leading to inconvenience for legitimate users. Liveness detection is another major countermeasure against spoofing attacks on face authentication systems. Unfortunately, existing liveness detection techniques available on consumer-level computing devices can be easily circumvented with one or two images. More reliable liveness detection, such as multi-modal mechanisms, typically involves additional authentication factors (e.g., voice or fingerprint). This introduces new challenges, as these additional factors can also be spoofed. Moreover, collecting multiple biometric data from users raises serious privacy concerns, which may lead to the rejection of liveness detection mechanisms.

As OSNFD continues to erode the confidentiality of face biometrics, one of the fundamental requirements for a usable authentication factor, and given that current liveness detection techniques are either too weak or too difficult to deploy on consumer-level devices, our findings suggest that face authentication may not be a suitable authentication factor unless the discovered issues are resolved.

## 5.4 Limitations

Ecological validity is a challenge in any user study. Like most prior research [12, 35, 3], our study recruited university students who are more active in using consumer-level computing devices and sharing images on OSNs. Therefore, the evaluation of OSNFD may vary with other populations.

In the user study design, collecting facial images with precisely controlled head poses remains a challenge [27]. The accuracy of head poses in our dataset may be affected by participants' difficulty in accurately directing their heads, unconscious movements, and resource limitations. In another experiment examining the false rejection rates of face authentication systems, we chose four locations to mimic different login environments. Since it was impossible for all participants to test simultaneously at the same physical positions, the background of captured images varied.

Another challenge in our study was accurately estimating parameters such as head pose, illumination, and makeup in our collected OSN dataset. Due to the limited accuracy of automatic labeling tools [1, 30], we manually labeled the OSN images with the help of automatic tools, following the validation methodology used in prior studies [21, 17, 41]. For each OSN image, we estimated the head pose using typical algorithms like POSIT and LGBP [27], and manually validated the estimation by comparing the OSN image with the participant's controlled head pose images. We manually labeled lighting conditions based on shadow and histogram analysis, similar to [21, 17]. Facial expressions were labeled by comparing the OSN image with those captured in our user study. We used Picasa to mark the face region and calculate the resolution. Parameters related to blur, makeup, and edits were labeled similarly to [21, 17, 41].

Further improvements to our risk estimation tool are possible. To our knowledge, our work is the first attempt to semi-automatically detect vulnerable images that can be used to attack face authentication. Our current tool can serve as a baseline for future improvements by refining key parameters and statistical models. Incorporating high-accuracy automatic labeling for hard-to-label attributes like illumination and facial makeup would be valuable once ongoing research [27, 9, 7] resolves these challenges.

## 6. Related Work

### Face Recognition
In face recognition, holistic approaches and local landmark-based approaches are the two major types of popular algorithms [1, 43]. Holistic approaches, such as PCA-based and LDA-based algorithms, use the entire face region as input. Local landmark-based approaches extract features like eyes, nose, and mouth, and feed their locations and local statistics into a classifier.

### Face Authentication
Face authentication is a critical application of face recognition, validating a claimed identity by comparing a facial image with an enrolled image and determining whether to accept or reject the claim [26]. Trewin et al. [36] showed that face authentication is faster and less disruptive to user memory recall tasks than voice, gesture, and password entry. It also provides stronger defense against repudiation compared to token-based and password-based authentication [28]. Besides face authentication, face identification, which compares a facial image with multiple registered users, can cause privacy leakage in OSNs due to identifiable personal images [3, 12]. Our study focuses on the impact of shared personal images that can be used to attack face authentication systems.

### Spoofing Attacks and Liveness Detection
It is well-known that face authentication is susceptible to spoofing attacks, where an attacker can pass authentication by displaying images or videos of a legitimate user [5]. However, it was generally believed to be sufficiently secure for common access protection, as an adversary typically needs physical proximity to collect face biometrics. Our findings indicate that this belief is no longer valid due to OSNFD, as face biometrics can now be disclosed on a large scale and acquired remotely.

Liveness detection is the primary countermeasure against spoofing attacks. Popular approaches include interaction-based, multi-modal, and motion-based methods [29, 19, 4]. Interaction-based approaches require real-time responses like eye blinks or head rotations but can be bypassed with one or two images [31]. Multi-modal approaches combine face biometrics with other biometrics like voice or facial thermograms, requiring additional hardware and specific environments [29]. Motion-based approaches detect involuntary motions of a 3D face, requiring high-quality images under ideal lighting conditions [19]. Our estimation tool addresses this problem by increasing users' awareness before they publish personal images, reducing the number of exploitable images available to adversaries.

## 7. Conclusion

In this paper, we investigated the threat of OSN-based facial disclosure (OSNFD) against real-world face authentication systems. Our results show that these systems are vulnerable to OSNFD-based attacks. We analyzed the characteristics of these attacks from three perspectives: security settings, target platforms, and user behavior. Key attributes of OSNFD were extracted to develop a risk estimation tool to help users understand the risks associated with their shared personal images. Our work is a first step in systematically understanding OSNFD, and quantitative evidence indicates that face authentication may not be a suitable authentication factor due to the significant compromise of face biometric confidentiality by OSNFD.

## 8. Acknowledgments

The authors would like to thank Swee Won Lo (School of Information Systems, Singapore Management University) for her help and discussion on the user study and data collection. We also thank Jianhui Huang (School of Information Systems, Singapore Management University) for his assistance and discussions on the risk estimation model.

## 9. References

[1] A. F. Abate, M. Nappi, D. Riccio, and G. Sabatino. 2D and 3D face recognition: A survey. Pattern Recognition Letters, 28(14):1885–1906, 2007.
[2] M. Abdel-Mottaleb and M. H. Mahoor. Assessment of blurring and facial expression effects on facial image recognition. In Advances in Biometrics, pages 12–18, 2005.
[3] A. Acquisti, R. Gross, and F. Stutzman. Faces of Facebook: Privacy in the age of augmented reality. BlackHat USA, 2011.
[4] A. Anjos and S. Marcel. Counter-measures to photo attacks in face recognition: A public database and a baseline. In Biometrics (IJCB), 2011 International Joint Conference on, pages 1–7, 2011.
[5] B. Biggio, Z. Akhtar, G. Fumera, G. Marcialis, and F. Roli. Security evaluation of biometric authentication systems under real spoofing attacks. IET Biometrics, 1:11–24, 2012.
[6] I. Chingovska, A. Anjos, and S. Marcel. On the effectiveness of local binary patterns in face anti-spoofing. In BIOSIG - Proceedings of the International Conference of the Biometrics Special Interest Group, pages 1–7, 2012.
[7] A. Dantcheva, C. Chen, and A. Ross. Can facial cosmetics affect the matching accuracy of face recognition systems? In BTAS - IEEE Fifth International Conference on Biometrics: Theory, Applications and Systems, pages 391–398, 2012.
[8] Facelock.mobi. http://www.facelock.mobi/facelock-for-apps.
[9] A. S. Georghiades, P. N. Belhumeur, and D. J. Kriegman. From few to many: Illumination cone models for face recognition under variable lighting and pose. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(6):643–660, 2001.
[10] Google. http://www.android.com/about/ice-cream-sandwich/.
[11] Google. https://play.google.com/store/apps?hl=en.
[12] R. Gross and A. Acquisti. Information revelation and privacy in online social networks. In Proceedings of the 2005 ACM Workshop on Privacy in the Electronic Society, pages 71–80, 2007.
[13] R. Gross, I. Matthews, J. Cohn, T. Kanade, and S. Baker. Multi-PIE. Image and Vision Computing, 28(5):807–813, 2010.
[14] A. J. Harris and D. C. Yen. Biometric authentication: Assuring access to information. Information Management & Computer Security, 10(1):12–19, 2002.
[15] D. W. Hosmer Jr, S. Lemeshow, and R. X. Sturdivant. Applied logistic regression. Wiley. com, 2013.
[16] F. Hua, P. Johnson, N. Sazonova, P. Lopez-Meyer, and S. Schuckers. Impact of out-of-focus blur on face recognition performance based on modular transfer function. In ICB - 5th IAPR International Conference on Biometrics, pages 85–90, 2012.
[17] G. B. Huang, M. Mattar, T. Berg, E. Learned-Miller, et al. Labeled faces in the wild: A database for studying face recognition in unconstrained environments. In Workshop on Faces in 'Real-Life' Images: Detection, Alignment, and Recognition, 2008.
[18] A. K. Jain, A. Ross, and S. Pankanti. Biometrics: A tool for information security. Trans. Info. For. Sec., 1(2):125–143, 2006.
[19] K. Kollreider, H. Fronthaler, and J. Bigun. Non-intrusive liveness detection by face images. Image and Vision Computing, 27(3):233–244, 2009.
[20] S. G. Kong, J. Heo, B. R. Abidi, J. Paik, and M. A. Abidi. Recent advances in visual and infrared face recognition ˛ala review. Computer Vision and Image Understanding, 97(1):103–135, 2005.
[21] N. Kumar, A. C. Berg, P. N. Belhumeur, and S. K. Nayar. Attribute and simile classifiers for face verification. In CVPR - IEEE 12th International Conference on Computer Vision, pages 365–372, 2009.
[22] Idiap Lab. https://www.idiap.ch/dataset/replayattack.
[23] K.-C. Lee, J. Ho, and D. J. Kriegman. Acquiring linear subspaces for face recognition under variable lighting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(5):684–698, 2005.
[24] Lenovo. http://en.wikipedia.org/wiki/VeriFace.
[25] Luxand. http://www.luxand.com/.
[26] H. Moon and P. J. Phillips. The FERET verification testing protocol for face recognition algorithms. In FG - Third IEEE International Conference on Automatic Face and Gesture Recognition, pages 48–53, 1998.
[27] E. Murphy-Chutorian and M. M. Trivedi. Head pose estimation in computer vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31(4):607–626, 2009.
[28] L. O'Gorman. Comparing passwords, tokens, and biometrics for user authentication. Proceedings of the IEEE, 91(12):2021–2040, 2003.
[29] G. Pan, L. Sun, Z. Wu, and S. Lao. Eyeblink-based anti-spoofing in face recognition from a generic web camera. In ICCV - IEEE 11th International Conference on Computer Vision, pages 1–8, 2007.
[30] P. J. Phillips, P. J. Flynn, T. Scruggs, K. W. Bowyer, J. Chang, K. Hoffman, J. Marques, J. Min, and W. Worek. Overview of the face recognition grand challenge. In CVPR - IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 1, pages 947–954, 2005.
[31] J. Rice. http://www.androidpolice.com/2012/08/03/android-jelly-beans-face-unlock-liveness-check-circumvented-with-simple-photo-editing/.
[32] C. J. V. Rijsbergen. Information Retrieval. Butterworth-Heinemann, 1979.
[33] SAS. http://www.sas.com/.
[34] T. Sim, S. Baker, and M. Bsat. The CMU pose, illumination, and expression database. IEEE Transactions on Pattern Analysis and Machine Intelligence, 25(12):1615–1618, 2003.
[35] F. Stutzman, R. Gross, and A. Acquisti. Silent listeners: The evolution of privacy and disclosure on Facebook. Journal of Privacy and Confidentiality, 4(2):2, 2013.
[36] S. Trewin, C. Swart, L. Koved, J. Martino, K. Singh, and S. Ben-David. Biometric authentication on a mobile device: A study of user effort, error, and task disruption. In ACSAC - 28th Annual Computer Security Applications Conference, pages 159–168, 2012.
[37] VagueWare.com. http://www.vagueware.com/top-globally-popular-face-recognition-software/.
[38] Visidon. http://www.visidon.fi/en/Home.
[39] SensibleVision. http://www.sensiblevision.com/en-us/home.aspx.
[40] K. Wagner. http://mashable.com/2013/09/16/facebook-photo-uploads/.
[41] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli. Image quality assessment: From error visibility to structural similarity. IEEE Transactions on Image Processing, 13(4):600–612, 2004.
[42] J. D. Woodward. Biometrics: Privacy's foe or privacy's friend? Proceedings of the IEEE, 85(9):1480–1492, 1997.
[43] W. Zhao, R. Chellappa, P. J. Phillips, and A. Rosenfeld. Face recognition: A literature survey. ACM Computing Surveys (CSUR), 35(4):399–458, 2003.