### Network Convergence and BGP Behavior

As shown in Figure 19, an average of nearly 190 updates per router, per destination, are required to reach convergence. More importantly, the behavior of Graceful Restart (GR) under link failure is critical. In our experiments, the recovering connection with the primary link advertises many new routes, which get filtered out before reaching the main network but still prolong resynchronization. During this time, GR prevents convergence from beginning, even though an underlying network link has failed. The GR data shows a convergence delay increased by more than 100 seconds compared to the raw case. Moreover, our experiments were conducted on a relatively small network. These delays are strongly dependent on the size of the underlying network routing tables, which are significantly larger in the core of the Internet and continue to grow.

### TCPR for Failover

TCPR offers the best results for failover: it masks the failure, allowing the control plane to recover as soon as the failure is detected and the recoverable application is restarted, with no overhead. For forwarding failover, TCPR behaves identically to unprotected BGP and avoids the additional delays introduced by GR.

### Related Work

Pei et al. [13] have studied the disruption caused during BGP convergence, explaining how topology and configuration affect the result, and evaluated several proposed strategies to make convergence faster and less disruptive. Other work focuses on ensuring that routers can rapidly fail over to temporary routes until convergence is complete [15]. Both approaches are valuable when convergence is unavoidable, such as when the topology genuinely changes. However, since they do not eliminate the disruption, it is preferable to mask the failure and recover transparently when possible.

Prior work on transparent TCP masking and recovery has often involved replicating the entire TCP stack and everything above it, including the application. Examples include HydraNet-FT [16], CoRAL [17], [18], HotSwap [19], ST-TCP [20], [21], AR-TCP [22], TRODS [23], and others [24], [25], which use primary-backup replication.

FATPETS [26] is a network stack written in Erlang, designed specifically for failover and migration. It can operate in an "active" mode, which consists of primary-backup replication of the entire state, including buffers, or a "passive" mode, which protects input with delayed acknowledgments similar to TCPR.

To avoid changing the network stack, new software can be interposed on its interfaces with the application and the network, recording and possibly modifying incoming and outgoing events. Failover-TCP [27] and FT-TCP [28], [29], [8] use such techniques. Similar to our TCPR approach, acknowledgments are delayed until the data is safely handled, and sequence numbers in packets to and from a restarted network stack are rewritten.

Failover between active replicas is straightforward and fast. However, to avoid running out of replicas, new ones must be brought up to speed. The replay-driven approach assumes that the application is deterministic and warms up new replicas by replaying all of a connection's input, at either the packet or socket level. This can be effective for HTTP requests but becomes impractical for connections receiving a lot of input, such as a BGP session.

Another approach is to use a proxy server between a server and its clients [30]. The client sets up a connection to the proxy server, and the proxy handles failing over from a primary server to a backup server as necessary. However, without a method for replicating the proxy [31], it introduces a new single point of failure.

Virtualization offers a lower-level approach to transparent migration. For example, Remus [32] replicates an entire virtual machine, including the application, the network stack, and the operating system. Virtual machine migration can also be used to protect particular applications [33], [34]. However, the failure or reconfiguration of the application within the virtual machine image still causes its TCP connections to break, providing only limited benefit for heavyweight replication demands.

Backdoors [35] takes a unique approach by replicating state after the application has already failed, assuming that the network interfaces survive the failure and modifying them to support remote DMA.

Finally, when it is possible to modify all of the application's peers, a good option is to introduce a session library or modified socket library [36], [37], [38], [39], [40]. Such an implementation can automatically set up a new connection to a new server if the current one fails, or even maintain redundant connections.

### Conclusions

Application-driven TCP recovery is a novel approach that enables a fault-tolerant application to protect connections in cases where replay-driven recovery was impossible. Our prototype, TCPR, confirms the simplicity of application-driven recovery. Rather than replicating the TCP state and everything above it, TCPR itself is not replicated because the application assumes responsibility. TCPR is middleware, outside the network stack, enabling any application to use it with an unmodified, unwrapped network stack and whatever interface it provides. By controlling the acknowledgment of data, along with occasional input from the application layer, TCPR needs only a small, constant amount of state per connection, enabling low overhead in normal operation and sub-millisecond recovery.

BGP is an important application for TCP recovery because broken connections trigger disproportionate amounts of disruption for core Internet forwarding. Furthermore, BGP challenges some crucial assumptions made by prior work, including determinism, whether the application can be a TCP client, and limitations on the length of its input.

All of these approaches suffer from being replay-driven. Often, they maintain multiple active replicas by duplicating input to each of them and using only the primary replica's output. Our evaluation of BGP uses a novel measurement framework to demonstrate that unmasked failover can result in tens or hundreds of seconds of outages, even when it is not necessary to reconverge at all. Graceful Restart, although beneficial in some cases, can arbitrarily delay convergence when forwarding and control failures are correlated.

Ironically, a high-availability router might benefit from a design that increases the correlation between such failures. Forwarding elements in large routers usually have general-purpose CPUs and memory, in addition to specialized forwarding hardware. The general-purpose hardware exists to handle slow-path forwarding decisions and configuration tasks but is usually over-provisioned. Offloading control element responsibilities onto parts of forwarding hardware can dramatically increase the replication possibilities, from one or two dedicated control nodes to every component in the router. With more replicas come more frequent faults, but also additional fault-tolerance and greater parallelism for distributing workloads. Restructuring a router to exploit these resources would be unwise with Graceful Restart, as any forwarding element failure would be correlated with the failure of some control element functionality. However, failover using TCPR is lightweight and, more importantly, invisible to peers, allowing the system designer to fully exploit the available resources. In fact, our work on TCPR originated in a project that prototyped just such an architecture [41].

The ability to easily migrate connections between replicas can also be useful when running multiple versions or configurations of an application. For example, a router could be made tolerant to implementation bugs by exploiting software diversity [42]. Using TCPR to protect the output of a master version or voting module can enable such an approach to tolerate hardware failure as well.

TCPR can offer benefits to applications other than BGP. For example, TCPR enables a lightweight approach to migration that can also tolerate unexpected failures, making it beneficial for load balancing long-running connections for streaming media within a CDN point-of-presence. We are also exploring applications of TCPR to a cloud-based smart power grid controller, where the middlebox helps make connections to data collectors fault-tolerant and enables elastic rebalancing of connections within the cloud, without complicating the implementation of deployed hardware.

High-availability, fault-tolerant applications already do a lot of work to maintain their own state. Application-driven TCP recovery can be seen as a way to give such an application access to its own state, which would otherwise be encapsulated in a network stack, without interfering with the implementation hidden behind that encapsulation.

### Acknowledgments

We thank Robert Broberg and the entire Ludd project at Cisco Systems, whose work on reliable routers inspired, supported, and tested TCPR, providing the uncommon opportunity to work on a real core Internet router architecture. We also thank Tudor Marian, who invested significant effort evaluating an early prototype of TCPR. Our work was supported, in part, by grants from the NSF, Cisco, DARPA, AFRL, and DOE (ARPAe).

### Availability

TCPR is free software under the BSD license. Source code and documentation are available from:
http://github.com/rahpaere/tcpr/

### References

[1] C. Labovitz, A. Ahuja, A. Bose, and F. Jahanian, “Delayed Internet routing convergence,” in Proc. ACM SIGCOMM, 2000, pp. 175–187.
[2] D. Pei, B. Zhang, D. Massey, and L. Zhang, “An analysis of convergence delay in path vector routing protocols,” Computer Networks: The International Journal of Computer and Telecommunications Networking, vol. 50, no. 3, Feb. 2006.
[3] X. Zhao, D. Pei, D. Massey, and L. Zhang, “A study on the routing convergence of Latin American networks,” in LANC 2003, La Paz, Bolivia, Oct. 2003.
[4] A. Sahoo, K. Kant, and P. Mohapatra, “Characterization of BGP recovery time under large-scale failures,” in IEEE International Conference on Communications (ICC’06), Jun. 2006, pp. 949–954.
[5] A. Avižienis, J.-C. Laprie, B. Randell, and C. Landwehr, “Basic concepts and taxonomy of dependable and secure computing,” IEEE Trans. on Dependable and Secure Computing, vol. 1, no. 1, 2004.
[6] S. Sangli, E. Chen, R. Fernando, J. Scudder, and Y. Rekhter, “Graceful restart mechanism for BGP,” RFC 4724, Jan. 2007.
[7] Information Sciences Institute, “Transmission Control Protocol,” RFC 793, Sep. 1981.
[8] D. Zagorodnov, K. Marzullo, L. Alvisi, and T. Bressoud, “Practical and low-overhead masking of failures of TCP-based servers,” Transactions on Computer Systems, vol. 27, no. 2, 2009.
[9] R. Braden, “Requirements for Internet hosts—communication layers,” RFC 1122, Oct. 1989.
[10] J. H. Saltzer, D. P. Reed, and D. D. Clark, “End-to-end arguments in system design,” in ICDCS. IEEE Computer Society, 1981, pp. 509–512.
[11] V. Jacobson, R. Braden, and D.Borman, “TCP extensions for high performance,” RFC 1323, May 1992.
[12] M. Mathis, J. Mahdavi, S. Floyd, and A. Romanow, “TCP selective acknowledgment options,” RFC 2018, Oct. 1996.
[13] D. Pei, X. Zhao, D. Massey, and L. Zhang, “A study of BGP path vector route looping behavior,” in Proceedings of the 24th International Conference on Distributed Computing Systems, 2004, pp. 720–729.
[14] P. Jakama, “Revised default values for the BGP ‘Minimum Route Advertisement Interval’,” Internet-Draft draft-jakama-mrai-02, Nov. 2008.
[15] O. Bonaventure, C. Filsfils, and P. François, “Achieving sub-50 milliseconds recovery upon BGP peering link failures,” IEEE/ACM Transactions on Networking, vol. 15, no. 5, Oct. 2007.
[16] G. Shenoy, S. K. Satapati, and R. Bettati, “HydraNet-FT: Network support for dependable services,” in Proc. of the International Conference on Distributed Computing Systems (ICDCS’00), 2000, pp. 699–706.
[17] N. Aghdaie and Y. Tamir, “Client-transparent fault-tolerant web service,” in Proceedings of the 20th IEEE International Performance, Computing, and Communications Conference (IPCCC 2001), Phoenix, AZ, Apr. 2001.
[18] ——, “CoRAL: A transparent fault-tolerant web service,” Journal of Systems and Software, vol. 82, Jan. 2009.
[19] N. Burton-Krahn, “HotSwap – transparent server failover for Linux,” in Proc. of USENIX LISA 02: Sixteenth Systems Administration Conference, 2002.
[20] M. Marwah, S. Mishra, and C. Fetzer, “TCP server fault tolerance using connection migration to a backup server,” in Proc. of the International Conference on Dependable Systems and Networks (DSN’03). San Francisco, CA: IEEE Computer Society, Jun. 2003.
[21] ——, “A system demonstration of ST-TCP,” in Proc. of the 2005 IEEE International Conference on Dependable Systems and Networks (DSN 2005). Yokohama, Japan: IEEE Computer Society, Jun. 2005.
[22] Z. Shao, H. Jin, and J. Wu, “AR-TCP: Actively replicated TCP connections for cluster of workstations,” in Workshop on Frontier of Computer Science and Technology (FCST ’06), Fukushima, Japan, Nov. 2006, pp. 3–10.
[23] W. Lloyd and M. J. Freedman, “Coercing clients into facilitating failover for object delivery,” in DSN, 2011, pp. 157–168.
[24] M.-Y. Luo and C.-S. Yang, “Constructing zero-loss web services,” in Proceedings of IEEE INFOCOM, Anchorage, AK, 2001, pp. 1781–1790.
[25] R. Zhang, T. Abdelzaher, and J. Stankovic, “Efficient TCP connection failover in server clusters,” in Proceedings of IEEE INFOCOM, Hong Kong, 2004, pp. 1219–1228.
[26] J. Paris, A. Valderruten, and V. Gulias, “Developing a functional TCP/IP stack oriented towards TCP connection replication,” in Proceedings of the 3rd International IFIP/ACM Latin American conference on Networking (LANC’05), Cali, Colombia, Oct. 2005.
[27] R. Koch, S. Hortikar, L. Moser, and P. Melliar-Smith, “Transparent TCP connection failover,” in Proc. of the International Conference on Dependable Systems and Networks (DSN’03). IEEE Computer Society, 2003, pp. 383–392.
[28] L. Alvisi, T. C. Bressoud, A. El-Khashab, K. Marzullo, and D. Zagorodnov, “Wrapping server-side TCP to mask connection failures,” in Proc. of Infocom 2001, Anchorage, Alaska, Apr. 2001, pp. 329–338.
[29] D. Zagorodnov, K. Marzullo, L. Alvisi, and T. Bressoud, “Engineering fault-tolerant TCP/IP servers using FT-TCP,” in Proc. of the International Conference on Dependable Systems and Networks (DSN’03). Los Alamitos, CA, USA: IEEE Computer Society, 2003.
[30] M. Marwah, S. Mishra, and C. Fetzer, “Fault-tolerant and scalable TCP splice and web server architecture,” in Proc. of the 25th Symposium on Reliability in Distributed Software (SRDS’06). IEEE Computer Society, 2006, pp. 301–310.
[31] ——, “Enhanced server fault-tolerance for improved user experience,” in Proc. of the International Conference on Dependable Systems and Networks (DSN’08). IEEE Computer Society, 2008, pp. 167–176.
[32] B. Cully, G. Lefebvre, D. Meyer, M. Feeley, N. Hutchinson, and A. Warfield, “Remus: High availability via asynchronous virtual machine replication,” in Proceedings of the USENIX Symposium on Networked Systems and Implementation, San Francisco, CA, Apr. 2008.
[33] E. Keller, J. Rexford, and J. van der Merwe, “Seamless BGP migration with router grafting,” in Proceedings of the 7th USENIX Symposium on Networked Systems Design and Implementation (NSDI’10), San Jose, CA, Apr. 2010.
[34] C. Clark, K. Fraser, S. Hand, J. G. Hansen, E. Jul, C. Limpach, I. Pratt, and A. Warfield, “Live migration of virtual machines,” in Proceedings of the USENIX Symposium on Networked Systems and Implementation, Boston, MA, May 2005.
[35] F. Sultan, A. Bohra, S. Smaldone, Y. Pan, P. Gallard, I. Neamtiu, and L. Iftode, “Recovering Internet service sessions from operating system failures,” IEEE Internet Computing, vol. 9, no. 2, pp. 17–27, 2005.
[36] Y. Huang and C. M. R. Kintala, “Software Implemented Fault Tolerance: Technologies and experience,” in Proceedings of 23rd International Symposium on Fault Tolerant Computing (FTCS-23), Jun. 1993, pp. 2–9.
[37] M. Orgiyan and C. Fetzer, “Tapping TCP streams,” in Proc. of the International Symposium on Network Computing and Applications (NCA’01). IEEE Computer Society, 2001, pp. 278–289.
[38] A. C. Snoeren, D. G. Andersen, and H. Balakrishnan, “Fine-grained failover using connection migration,” in Proceedings of the 3rd USENIX Symposium on Internet Technologies and Systems, San Francisco, CA, 2001, pp. 221–232.
[39] F. Sultan, K. Srinivasan, D. Iyer, and L. Iftode, “Migratory TCP: Connection migration for service continuity over the Internet,” in Proc. of the 22nd International Conference on Distributed Computing Systems (ICDCS ’02), Jul. 2002.
[40] V. C. Zandy and B. P. Miller, “Reliable network connections,” in Proceedings of ACM MobiCom, Atlanta, GA, 2002, pp. 95–106.
[41] A. Agapi, K. Birman, R. M. Broberg, C. Cotton, T. Kielmann, M. Millnert, R. Payne, R. Surton, and R. van Renesse, “Routers for the cloud,” Internet Computing, vol. 15, no. 5, Sep. 2011.
[42] E. Keller, M. Yu, M. Caesar, and J. Rexford, “Virtually eliminating router bugs,” in CoNEXT, 2009.