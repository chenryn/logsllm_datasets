### 6.4 Evasion

SpamTracker must be resilient against attacks that mislead the clustering engine, causing spam to be misclassified as legitimate email and vice versa. To enhance classification robustness, SpamTracker can form clusters based on email sending patterns from a smaller number of trusted email recipients (e.g., a few hundred trusted domains), each of which communicates with the SpamTracker system over a secure channel. Although SpamTracker's clustering benefits from more inputs about email senders, it can still serve as a classifier for a much larger set of domains that it does not necessarily trust to provide data for forming the clusters.

If spamming bots in a botnet select target domains from the same distribution, SpamTracker’s clustering algorithm will group these spammers into the same cluster. However, SpamTracker is limited by the time window used for clustering (e.g., 6 hours, as in Section 5), and a spammer might exploit this weakness to evade detection. We are improving SpamTracker to automatically adjust the window in response to the fraction of received email in the last window that was classified as spam. The intuition is that the fraction of spam does not change much over short timeframes, and a decrease in the fraction of flagged email indicates that the window is too small to cluster similar IPs together. Spamming bots might also try to emulate the distribution of target domains (or other behavioral features) of normal senders, but doing so may inherently reduce their effectiveness (e.g., they may have to reduce their sending rate or the expansiveness of their target list).

### 6.5 Sensor Placement

A set of domains that observes more even sending behavior across domains may be better at distinguishing spammers from legitimate senders. As noted in Section 2.1.2, 90% of the spam we observe is received by only 84 of the 115 domains from which we observe email, and only about 15% of the senders in our traces target more than one of the domains from which we can observe sending patterns at the email hosting provider. Based on our experiments using only clusters where the average vectors are less "skewed" towards a single domain (Figure X), we expect that a more even distribution of sensors would further improve the SpamTracker classifier. Many commercial spam filtering companies (e.g., IronPort [16], Secure Computing [31]) may already have this data. Another option for sensors would be ubiquitous webmail domains such as hotmail.com, gmail.com, etc.

### 7. Related Work

In this section, we discuss several areas of related work: (1) previous characterization studies, which offer statistics that help build the case for behavioral blacklisting; (2) existing systems for spam filtering, many of which use distributed monitoring but incorporate different algorithms for classification; and (3) previous approaches for classifying email into legitimate email and spam.

#### Blacklisting and Identity

SpamTracker relates to previous blacklisting proposals. Conventional blacklists consist of lists of IP addresses of likely spammers and are intended to help spam filters [15, 23, 35] make better decisions about whether to block a piece of email based on the sender. Some blacklists are policy-based (e.g., they list all IP addresses that belong to a certain class, such as dial-up addresses [34]). Other IP-based blacklists are "reactive": they attempt to keep track of whether an IP address is a spammer, bot, phisher, etc., and keep this list up-to-date as hosts are renumbered, botnets move, and so forth [24, 36, 37, 39]. These blacklists essentially maintain lists of IP addresses and must be vigilantly maintained to stay current. Sender Policy Framework (SPF) attempts to prevent IP addresses from sending mail on behalf of a domain for which they are not authorized [42], and DomainKeys associate a responsible identity with each mail [3]. Although both frameworks make it more difficult for an arbitrary IP address to send mail, they do not allow a recipient to classify an email sender with an unknown reputation.

#### Collaborative Filtering and Whitelisting

SpamTracker resembles many existing systems that take inputs from many distributed sources to build information about known spam (or spammers). Some of the most widely deployed collaborative filtering systems characterize known spam based on the contents of a piece of spam that was reported or submitted by another user or mail server [10, 12, 20, 27, 28, 40]. These systems allow mail servers to compare the contents of an arriving piece of email to the contents of an email that has been confirmed as spam; they do not incorporate any information about network-level behavior.

Other systems collect information from distributed sets of users either to help filter spam or decrease the probability that legitimate mail is mistakenly filtered. IronPort [17] and Secure Computing [32] sell spam filtering appliances to domains, which then pass information about both legitimate mail and spam back to a central processing engine that in turn improves the filters. The widespread deployment of these products and systems makes them ideal candidates for the deployment of an algorithm like SpamTracker.

#### Characterization Studies

Our recent characterization study of the network-level behavior of spammers observes spamming behavior from the perspective of a single spam "trap" domain [30]. In this study, we observed that any particular IP address sends only a small volume of spam to the particular domain being observed over the course of 18 months. Duan et al. recently performed a similar study that observes similar characteristics [13]. Our characterization of spammers in Section 2 builds on these previous studies by observing email sending patterns across domains and time.

#### Content-Independent Blocking

Like SpamTracker, Clayton’s "spamHINTS" project also aims to characterize and classify spam with analysis of network traffic patterns, rather than email contents [38]. Earlier work on "extrusion detection" involves instrumenting a mail server with a log processing program to detect senders of spam both at the local ISP [8] and in remote ISPs [9]. Although Clayton’s proposed methods are similar in spirit to our work (in that the methods rely on examining traffic patterns to distinguish legitimate email senders from spammers), the methods generally involve heuristics related to SMTP sessions from a single sender (e.g., variations in HELO messages, attempts to contact incoming mail servers to send outgoing mail). In contrast, SpamTracker relies on a wider deployment of traffic monitors (i.e., it relies on observing email sending patterns from many domains) and is then able to create more protocol-agnostic "fingerprints" for email senders that are likely spammers. Trinity counts email volumes to identify emails that are likely sent from bots [6]; it could also be used to track email sending patterns for input to SpamTracker.

#### Clustering for Spam Classification

Previous studies have attempted to cluster spammers based on the content of emails, such as the URLs contained in the bodies of the emails [4, 22]. Li et al. focus on clustering spam senders to predict whether a known spammer will send spam in the future [22], and Anderson et al. cluster spam according to URLs to better understand the relationship between the senders' spam messages that advertise phishing and scam sites and the web servers that host the scams themselves [4]. These systems cluster emails based on content, while SpamTracker clusters email senders based on their sending behavior. Unlike the methods of Li et al., SpamTracker’s clustering techniques can also classify previously unseen IP addresses.

#### Throttling Outgoing Spam

SpamTracker complements previous proposals that suggest throttling senders using schemes such as stamps, proof-of-work, etc. One prominent postage scheme is called "bankable postage," whereby senders obtain stamps or tokens from some authority and then attach these tokens to emails [2, 41]. Other techniques for throttling spam require the sender to issue some "proof of work," either in CPU [5] or memory [14], although these schemes have also been criticized because, in certain circumstances, they can prevent legitimate users from sending normal volumes of email [21].

### 8. Conclusion

This paper presents SpamTracker, a system that classifies email senders using a technique we call behavioral blacklisting. Rather than classifying email senders according to their IP addresses, behavioral blacklisting classifies senders based on their sending patterns. Behavioral blacklisting is based on the premise that many spammers exhibit similar, stable sending patterns that can act as "fingerprints" for spamming behavior.

SpamTracker clusters email senders based on the set of domains they target. It uses these sending patterns of confirmed spammers to build "blacklist clusters," each of which has an average vector that represents a spamming fingerprint for that cluster. SpamTracker tracks the sending patterns of other senders and computes the similarity of their sending patterns to those of a known spam cluster as the basis for a "spam score." Our evaluation using email logs from an email provider that hosts over 115 independent domains shows that SpamTracker can complement existing blacklists: it can distinguish spam from legitimate mail and also detects many spammers before they are listed in any blacklist. SpamTracker’s design makes it easy to replicate and distribute, and deploying it requires only small modifications to the configurations of existing mail servers. Our ongoing work involves gathering data from a wider set of domains, improving the behavioral classification algorithms (e.g., by using other features of email senders), and deploying the system to allow us to evaluate it in practice.

### Acknowledgments

This work was supported by an NSF CAREER award CNS-0633974, by NSF Cybertrust awards CNS-0721581 and CNS-0716278, by NSF grant CCF-0721503, and in part by the Georgia Tech Algorithms and Randomness Center (ARC) Think-Tank (http://www.arc.gatech.edu/). We thank Merrick Furst, Suresh Ramasubramanian, Craig Sprosts, and Muhammad Mukarram bin Tariq for their comments and assistance.

### References

[1] Spamhaus delisting policy, 2007. http://www.spamhaus.org/sbl/policy.html.
[2] M. Abadi, A. Birrell, M. Burrow, F. Dabek, and T. Wobber. Bankable Postage for Network Services. In Proc. Asian Computing Science Conference, Dec. 2003.
[3] E. Allman, J. Callas, M. Delany, M. Libbey, J. Fenton, and M. Thomas. DomainKeys Identified Mail (DKIM) Signatures, May 2007. http://www.ietf.org/rfc/rfc4871.txt.
[4] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker. Spamscatter: Characterizing Internet Scam Hosting Infrastructure. In Proc. 16th USENIX Security Symposium, Boston, MA, Aug. 2007.
[5] A. Back. Hashcash. http://www.cypherspace.org/adam/hashcash/.
[6] A. Brodsky and D. Brodsky. A Distributed Content Independent Method for Spam Detection. In First USENIX Workshop on Hot Topics in Understanding Botnets (HotBots), Cambridge, MA, Apr. 2007.
[7] D. Cheng, R. Kannan, S. Vempala, and G. Wang. A divide-and-merge methodology for clustering. ACM Transactions on Database Systems, 31(4):1499–1525, 2006.
[8] R. Clayton. Stopping Spam by Extrusion Detection. In First Conference on Email and Anti-Spam (CEAS), Mountain View, CA, July 2004.
[9] R. Clayton. Stopping Outgoing Spam by Examining Incoming Server Logs. In Second Conference on Email and Anti-Spam (CEAS), Stanford, CA, July 2005.
[10] Cloudmark Authority Anti-Spam. http://www.cloudmark.com/serviceproviders/authority/spam/, 2007.
[11] Commtouch Inc. 2006 Spam Trends Report: Year of the Zombies. http://www.commtouch.com/documents/Commtouch 2006 Spam Trends Year of the Zombies.pdf.
[12] E. Damiani, S. de Vimercati, and P. Samarati. P2P-Based Collaborative Spam Detection and Filtering. In 4th IEEE Conference on P2P, 2004.
[13] Z. Duan, K. Gopalan, and X. Yuan. Behavioral Characteristics of Spammers and Their Network Reachability Properties. In Proc. IEEE ICC, Glasgow, Scotland, June 2007.
[14] C. Dwork and M. Naor. Pricing via Processing or Combatting Junk Mail. In CRYPTO, Santa Barbara, CA, Aug. 1992.
[15] P. Graham. Better Bayesian Filtering. http://www.paulgraham.com/better.html.
[16] IronPort. http://www.ironport.com/, 2007.
[17] IronPort Carrier Grade Email Security Appliance. http://www.ironport.com/products/ironport x1000.html, 2007.
[18] R. Kannan, S. Vempala, and A. Vetta. On clusterings: good, bad and spectral. J. of the ACM, 51(3):497–515, 2004.
[19] Kelly Jackson Higgins, Dark Reading. Botnets Battle Over Turf. http://www.darkreading.com/document.asp?doc id=122116, Apr. 2007.
[20] J. Kong et al. Scalable and Reliable Collaborative Spam Filters: Harnessing the Global Social Email Networks. In 3rd Annual Workshop on the Weblogging Ecosystem, 2006.
[21] B. Laurie and R. Clayton. Proof-of-Work Proves Not to Work. In Third Annual Workshop on Economics and Information Security (WEIS), Minneapolis, MN, May 2004.
[22] F. Li and M.-H. Hseih. An Empirical Study of Clustering Behavior of Spammers and Group-based Anti-Spam Strategies. In 3rd Conference on Email and Anti-Spam (CEAS), Mountain View, CA, July 2006.
[23] MailAvenger, 2007. http://www.mailavenger.org/.
[24] Mail Abuse Prevention System (MAPS). http://www.mail-abuse.com/.
[25] Messaging Anti-Abuse Working Group. MAAWG Issues First Global Email Spam Report. http://www.prnewswire.com/cgi-bin/stories.pl?ACCT=104&STORY=/www/story/03-08-2006/0004316196, Mar. 2006.
[26] PandaLabs Blog. Zunker Spamming Bot Front-end Analysis. http://blogs.pandasoftware.com/blogs/pandalabs/archive/2007/05/08/Zunker.aspx, May 2007.
[27] V. Prakash. Vipul’s Razor. http://razor.sourceforge.net/, 2007.
[32] Secure Computing IronMail. http://www.securecomputing.com/index.cfm?skey=1612, 2007.
[33] A. Sinclair and M. Jerrum. Approximate counting, uniform generation and rapidly mixing Markov chains. Information and Computation, 82:93–133, 1989.
[34] Spam and Open-Relay Blocking System (SORBS). http://www.sorbs.net/.
[35] SpamAssassin, 2007. http://www.spamassassin.org/.
[36] SpamCop. http://www.spamcop.net/.
[37] Spamhaus, 2007. http://www.spamhaus.org/.
[38] SpamHINTS. http://www.spamhints.org/, 2007.
[39] Realtime URI Blacklist. http://www.uribl.com/.
[40] P. Vixie. Distributed Checksum Clearinghouse. http://www.rhyolite.com/anti-spam/dcc/, 2007.
[41] M. Walfish, J. Zamfirescu, H. Balakrishnan, and D. Karger. Distributed Quota Enforcement for Spam Control. In Proc. 3rd Symposium on Networked Systems Design and Implementation (NSDI), San Jose, CA, May 2006.
[42] M. Wong and W. Schlitt. Sender Policy Framework (SPF) for Authorizing Use of Domains in E-Mail, Apr. 2006. RFC 4408.
[28] Pyzor. http://pyzor.sourceforge.net/, 2007.
[29] A. Ramachandran, D. Dagon, and N. Feamster. Can DNSBLs Keep Up with Bots? In 3rd Conference on Email and Anti-Spam (CEAS), Mountain View, CA, July 2006.
[30] A. Ramachandran and N. Feamster. Understanding the Network-Level Behavior of Spammers. In Proc. ACM SIGCOMM, Pisa, Italy, Aug. 2006.
[31] Secure Computing. http://www.securecomputing.com/, 2007.