# Face/Off: Preventing Privacy Leakage From Photos in Social Networks

## Authors
- Panagiotis Ilia, FORTH, Greece, [PI:EMAIL]
- Iasonas Polakis, Columbia University, USA, [PI:EMAIL]
- Elias Athanasopoulos, FORTH, Greece, [PI:EMAIL]
- Federico Maggi, Politecnico di Milano, Italy, [PI:EMAIL]
- Sotiris Ioannidis, FORTH, Greece, [PI:EMAIL]

## Abstract
The widespread availability of internet connectivity and the advanced capabilities of modern devices have led to an unprecedented scale of photo sharing online. This trend is further amplified by the popularity of social networks, which offer immediate content sharing. However, existing access control mechanisms are too coarse-grained to handle conflicts of interest among users associated with a photo, leading to common instances of embarrassing or inappropriate photos being widely accessible.

In this paper, we propose a new approach to access control for photos that effectively prevents unwanted individuals from recognizing users in a photo. Our core concept is to change the granularity of access control from the photo level to the level of personally identifiable information (PII), specifically focusing on faces. When a user attempts to view a photo, the system determines which faces they do not have permission to see and blurs those faces. Our system leverages the existing face recognition functionality of social networks and can interoperate with current photo-level access control mechanisms.

We implement a proof-of-concept application for Facebook and demonstrate that the performance overhead of our approach is minimal. A user study shows that our approach effectively prevents users from identifying their contacts in 87.35% of restricted photos. Additionally, the study highlights misconceptions about the privacy offered by existing mechanisms and indicates that users are positive towards adopting an intuitive, straightforward access control mechanism that allows them to manage the visibility of their faces in published photos.

*Panagiotis Ilia is also affiliated with the University of Crete.

**Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org.**

CCS'15, October 12â€“16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813603.

### Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]: Security and Protection

### General Terms
Security, Privacy, Human Factors

### Keywords
Access Control, Online Social Networks, Shared Photos, Photo Tagging

## 1. Introduction
Online social networks (OSNs) have significantly transformed the online behavior and activities of users. Unfortunately, these services have also introduced numerous privacy issues, drawing attention from both the research community and data protection agencies. As OSNs become integral to daily life, users may face severe consequences when their personal and professional lives intersect through these platforms. Incidents of users being fired due to sensitive photos, which they believed were private, have been widely reported.

The scale of these privacy issues is alarming. Facebook, for example, has over 1.49 billion monthly active users, with an average of 968 million daily users. It is the most time-consuming online activity and the primary platform for photo sharing, with over 350 million photos uploaded daily. Many companies check job applicants' online presence during the hiring process, and studies show that recruiters often reject candidates based on online information, including photos.

In some cases, users may not be concerned about privacy or may be unaware of the implications of their actions. They may not fully understand complex access control mechanisms and disclose private information without hesitation. Facebook has attempted to address this by altering the privacy selector for status updates and building a system to warn users about potentially embarrassing photos. However, these measures cannot prevent other users with malicious intent or poor judgment from sharing such content.

The core problem is that existing mechanisms for defining access to photos in OSNs cannot effectively handle conflicts of interest. The photo uploader is considered the owner and has full rights, while the people in the photo have no rights. Additional policies, such as restricting visibility for tagged users, can complicate matters. The uploader does not need to request permission from the people in the photo before publishing it and may ignore requests to remove it. Even if tagged users restrict visibility, the photo will still be publicly available if the uploader does not restrict access.

Previous work has proposed frameworks for integrating access control policies, but these solutions are too coarse-grained to accommodate the privacy settings of all associated users. In this paper, we propose an approach that changes the granularity of access control to the level of users' faces. This enables an OSN to enforce each user's privacy settings within an image, ensuring that no one's settings are overridden. Our approach uses face recognition to identify users in a photo and automatically restricts the visibility of each user's face based on their privacy settings. The result is a "processed" photo that can be selectively rendered according to who is viewing it.

We conduct a case study on over 4 million photos from 128 participants and their social circles, exploring the characteristics of their social graphs and tagging behavior. We quantify the privacy risks users face due to existing access control mechanisms. To evaluate the feasibility of our approach, we measure the overhead of our proof-of-concept implementation. On average, our system requires only 0.05 seconds per photo on a commodity machine.

To evaluate the effectiveness of our approach in preserving user privacy, we conduct an experiment with 34 participants. Each participant is shown a set of photos with one user's face hidden and asked to identify the user. In 87.35% of cases, participants fail to identify their contacts, demonstrating the effectiveness of our approach. We also interview 52 participants to understand their perceptions of existing access control mechanisms and their opinions on our approach. Most users are positive towards a simpler, more privacy-preserving approach, with 77% expressing positive opinions and 19.2% remaining neutral.

### Main Contributions
- **Design**: An innovative fine-grained access control mechanism for photo-sharing services that enforces the visibility of each user's face based on their respective access control lists, effectively handling all conflicts of interest between users' privacy settings.
- **Implementation**: A proof-of-concept application demonstrating the feasibility and applicability of our approach within the infrastructure of a real-world OSN. Our experiments show that the performance overhead is small compared to existing photo processing, making our approach suitable for large-scale adoption.
- **User Study Insights**: Insights into user tagging behavior and the risks they face due to conflicting privacy settings on shared photos. We assess user tagging behavior and quantify the risk in certain photo-sharing scenarios.
- **Effectiveness Demonstration**: A second user study demonstrates the effectiveness of our approach in hiding users' identities from their contacts. We highlight the counter-intuitive nature of existing access control mechanisms and the eagerness of users to adopt a mechanism that allows them to manage the visibility of their faces.

## 2. Photo-Based Privacy Leakage
### 2.2 Privacy Leakage Scenarios
Earlier work has reported that users are concerned about their privacy and tend to avoid publishing photos or any other private information publicly. According to a survey by Besmer et al., explicit requests for photo deletion or untagging are complicated and can lead to social tension. Users may abstain from such actions to maintain social relationships, even at the cost of their privacy. The wide visibility of photos can also expose users to inference attacks or be used by attackers to bypass account protection mechanisms.