# Title: Plinius: Secure and Persistent Machine Learning Model Training

## Authors:
- Peterson Yuhala
- Pascal Felber
- Valerio Schiavoni
- Alain Tchana

### Abstract
With the growing popularity of cloud-based machine learning (ML) techniques, there is an increasing need for privacy and integrity guarantees for ML data. Additionally, the significant scalability challenges faced by DRAM, combined with the high access times of secondary storage, represent a major performance bottleneck for ML systems. While solutions exist to address the security aspect, performance remains a concern. Persistent memory (PM) offers resilience to power loss, provides fast and fine-granular access to memory, and has latency and bandwidth close to that of DRAM. We present PLINIUS, an ML framework that uses Intel SGX enclaves for secure training of ML models and PM for fault tolerance. PLINIUS employs a novel mirroring mechanism to create and maintain encrypted mirror copies of ML models on PM and encrypted training data in byte-addressable PM, enabling near-instantaneous data recovery after a system failure. Compared to disk-based checkpointing systems, PLINIUS is 3.2× and 3.7× faster, respectively, for saving and restoring models on real PM hardware, achieving robust and secure ML model training in SGX enclaves.

### Introduction
Privacy-preserving machine learning is a challenging computational paradigm. Data and computations must be protected from various threats, including powerful attackers, compromised hypervisors and operating systems, and even malicious cloud or human operators. Preserving the confidentiality of the models (i.e., weights and biases) being trained, as well as the input datasets, is crucial, as these are often the most valuable business assets. Application domains include health, finance, and Industry 4.0. Given the significant computing resources required during the training phase, moving model training to public clouds appears pragmatic. However, this approach raises concerns about exposing confidential datasets and models to untrusted clouds.

Trusted execution environments (TEEs) are becoming the go-to solution for addressing confidentiality requirements. Several cloud providers now offer TEE-enabled computing instances (e.g., IBM, Azure). Intel Software Guard Extensions (SGX) is a TEE that offers applications secure memory regions called enclaves to shield code and data from unwanted accesses. SGX is widely available across various cloud providers but imposes security restrictions on enclave code, requiring application-level changes and limited memory capacity, which necessitates minimizing the trusted computing base (TCB).

While offloading ML training jobs to SGX-enabled clouds may solve the confidentiality issue, such jobs are typically deployed in batch, with lower priorities than latency-sensitive services. To avoid resource waste due to workload variations, ML applications are often co-located with latency-sensitive applications, leading to interruptions when the latter require more resources. Another practice that can interrupt ML jobs is the use of cheap yet unreliable virtual machine instances, such as EC2 spot instances, which are automatically terminated when a better offer is made by another user. To avoid restarting model training from scratch, frequent checkpointing on persistent storage is recommended. However, frequent checkpointing on secondary storage leads to significant I/O overheads, and relying on volatile memory (i.e., DRAM) would prevent resuming the job in case of task eviction.

Emerging memory technologies like persistent memory (PM) have the potential to address the scalability challenges faced by DRAM and the high latency of secondary storage. PM is persistent on power failure, byte-addressable, and can be accessed via processor load and store instructions. Recent work shows how market-available PM solutions, such as Intel Optane DC PM, result in significant performance gains for various applications. Cloud services like MS Azure already provide PM offerings, and we expect this technology to gain even more momentum. However, using PM in privacy-preserving ML jobs opens additional security risks, as confidential model parameters could be persisted in plain text on PM or exposed at runtime to malicious privileged users or compromised operating systems. We argue that there is a need to develop tools and mechanisms to enable these applications to leverage PM in secure computation environments.

In this work, we build the first framework, PLINIUS, that integrates secure ML with Intel SGX and fault tolerance on PM. State-of-the-art PM libraries (e.g., Intel Persistent Memory Development Kit, Romulus) and ML frameworks (e.g., TensorFlow, Darknet) require considerable porting efforts to be fully functional within SGX enclaves. Tools exist to run unmodified applications inside SGX enclaves, but they come with larger TCB sizes and reduced performance. In ML scenarios with large confidential models and datasets, enclave memory becomes a major bottleneck.

PLINIUS is a secure ML framework that leverages PM for fast checkpoint/restore of machine learning models. It uses Intel SGX to ensure the confidentiality and integrity of ML models and data during training and PM for fault tolerance. PLINIUS employs a mirroring mechanism to create an encrypted mirror copy of an enclave model directly in PM, synchronized with the enclave model across training iterations. Training data is maintained in byte-addressable PM. Upon a system crash or power failure, the encrypted ML model replica in PM is securely decrypted in the enclave and used as the next starting point for the training iteration, avoiding costly serialization operations of disk-based solutions. To validate our approach, we build and contribute SGX-DARKNET, a complete port of the Darknet ML framework to SGX, and SGX-ROMULUS, an SGX-compatible PM library on top of an efficient PM library. Our results show that SGX-ROMULUS is best suited for the PLINIUS framework. Using PLINIUS, we build and train convolutional neural network (CNN) models with real-world datasets (e.g., MNIST) and demonstrate that PLINIUS reduces overhead by ∼3.5× for model saving and ∼2.5× for model restores with real SGX hardware and emulated PM.

### Contributions
- **SGX-ROMULUS**: We implement and release as open-source SGX-ROMULUS, built on top of Romulus, for Intel SGX. SGX-ROMULUS manipulates PM directly from within SGX enclaves, without costly enclave transitions.
- **SGX-DARKNET**: We design, build, and release as open-source SGX-DARKNET, an extension of Darknet for Intel SGX. SGX-DARKNET can perform secure training and inference on ML models directly inside SGX enclaves.
- **PLINIUS Framework**: We present PLINIUS, an open-source framework that leverages SGX-ROMULUS and SGX-DARKNET to provide an end-to-end fault tolerance mechanism for training models in privacy-preserving ML settings.
- **Comprehensive Evaluation**: We provide a comprehensive evaluation of PLINIUS using real PM hardware and real AWS Spot traces, demonstrating its superior performance compared to traditional checkpointing on secondary storage (i.e., disk or SSD).

### Roadmap
- **Section II**: Background on Intel SGX, PM, and relevant ML concepts.
- **Section III**: Threat model.
- **Section IV**: Architectures of SGX-ROMULUS, SGX-DARKNET, and PLINIUS.
- **Section V**: Implementation details.
- **Section VI**: Experimental evaluation.
- **Section VII**: Related work.
- **Section VIII**: Conclusion and future work.

### Background
This section provides background on Intel SGX, PM, and some machine-learning concepts specific to PLINIUS.

#### Intel Software Guard Extensions (SGX)
Intel SGX is a set of extensions to Intel's architecture that allows applications to create CPU-protected memory areas (enclaves), shielding confidential code and data from disclosure and modifications. SGX reserves a secure memory region called the Enclave Page Cache (EPC) for enclave code and data. The processor ensures that software outside the enclave (e.g., the OS kernel or hypervisor) cannot access EPC memory. The enclave can access both EPC and non-EPC memory.

Data in the EPC is in plaintext only in on-chip caches and is encrypted and integrity-protected in the Memory Encryption Engine (MME) once it is evicted from the cache to memory. Current Intel processors support a maximum of 128 MB of EPC memory, of which 93.5 MB is usable by SGX enclaves. This limits the total size of code and data allowed within the EPC. To support applications with larger memory needs, the Linux kernel provides a paging mechanism for swapping pages between the EPC and untrusted memory.

Enclaves cannot issue system calls and standard OS abstractions (e.g., file systems, network), which are ubiquitous in real-world applications. All system services thus require costly enclave transitions, up to 13,100 CPU cycles. The Intel SGX application design requires splitting applications into a trusted (the enclave) and untrusted part. To achieve communication across the enclave boundary, the Intel SGX SDK provides specialized function call mechanisms, i.e., `ecalls` and `ocalls`, for entering and exiting an enclave, respectively.

To mitigate security risks, the Trusted Computing Base (TCB) should be as small as possible. Systems exist to run unmodified applications inside enclaves, either by porting entire library OSes into the enclave or via a modified libc library, specialized for containerized services. These solutions are efficient with small application binaries but quickly show limitations for memory-constrained applications such as ML.

#### Persistent Memory (PM) and PM Libraries
Persistent memory is a novel memory technology that is non-volatile, byte-addressable, and has latency and bandwidth similar to that of DRAM. PM resides on the memory bus and can be accessed directly using CPU load and store instructions. Intel Optane DC PM has been commercially available since April 2019 and scales better than DRAM, providing much larger capacity (up to 512 GB per PM module). Intel Optane DC PM modules can operate in two modes: memory mode, where they are simply used to extend the system's DRAM, and app direct mode, where they are accessed directly by applications.

### Threat Model
[Detailed threat model to be provided here]

### Architectures
[Detailed architectures of SGX-ROMULUS, SGX-DARKNET, and PLINIUS to be provided here]

### Implementation Details
[Detailed implementation details to be provided here]

### Experimental Evaluation
[Detailed experimental evaluation to be provided here]

### Related Work
[Discussion of related work to be provided here]

### Conclusion and Future Work
[Conclusion and future work to be provided here]