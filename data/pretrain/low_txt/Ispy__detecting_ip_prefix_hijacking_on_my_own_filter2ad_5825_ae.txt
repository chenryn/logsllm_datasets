### Positive Ratios from Internet Experiments and Analysis of Sensitivity

In this section, we analyze the sensitivity and trade-offs between two key ratios by varying threshold values.

### 6. INTERNET EXPERIMENTS

#### 6.1 PlanetLab Experiment

ISPY has been continuously running on over 100 PlanetLab sites since November 2007. Given that hijacking is a rare event in the Internet, this deployment was used to evaluate the false positive detection ratio of ISPY. Specifically, we evaluated ISPY's performance on 108 PlanetLab hosts (each with distinct prefixes) located in 88 ASes, starting from December 1, 2007, for a period of 25 days. Our goal was to validate the design hypothesis that non-hijacking events do not cause large numbers of cuts.

**Detection Accuracy:**

Over the 25-day period, ISPY reported hijacking alarms for 0.17% of all probing rounds across the 108 hosts, using a detection threshold of 10 cuts. The alarm rate would be 0.44% and 0.05% with detection thresholds of 5 and 20 cuts, respectively.

We believe that all these alarms were false positives, as they did not correspond to actual hijacking events. This conclusion is based on two pieces of evidence:
1. The cuts never lasted for more than one round, whereas hijacking typically lasts longer.
2. No MOAS (Multiple Origin AS) announcements were found in RouteViews for these hosts' prefixes during the 25-day period.

**False Positive Ratios:**

Figure 5 shows the false positive ratios for the 108 PlanetLab hosts when the detection threshold is set to 10. 70% of the hosts had false positive ratios below 0.2%, and 95% had false positive ratios below 0.5%. Only three hosts had false positive ratios higher than 0.5%.

To understand the causes of high false positive ratios, we closely examined the three hosts that triggered the most false alarms. Figure 6 illustrates the number of unreachable transit ASes and the number of cuts witnessed by ISPY at `stella.planetlab.ntua.gr`, which triggered the most alarms (22 out of 1363 probing rounds). The total probing time was 500 hours, excluding the time when the host was down.

Analysis of the probing rounds that triggered alarms revealed a common abnormal pattern. During these rounds, traceroute probes encountered more `*` hops in the middle of paths, and some probes aborted at random ASes. Additionally, complementary ping and TCP ping probes also failed, leading to the generation of cuts for a few inter-AS links. Another observation was that the RTTs (Round-Trip Times) returned by successful probes were higher than normal. These anomalies never lasted for more than one probing round, suggesting that the issues were likely due to short-lived machine overload or congestion near the probing machines.

**Choice of Detection Threshold:**

The detection threshold used by ISPY affects both the false positive and false negative ratios. To study the trade-off between these ratios, we plotted the false positive ratios from the deployment study and the false negative ratios from Section 3.4 in Figure 7, varying the detection threshold. The figure shows that a threshold of 10 cuts strikes a good balance, yielding a false positive ratio of 0.17% and a false negative ratio of 0.45%. A threshold of 10 provides a better false negative ratio than 20 and a much better false positive ratio than 5, with almost no degradation in the false negative ratio. This is because, as observed in Section 3.4, if the number of cuts created by a hijack is less than 10, it is very likely to be less than 5.

#### 6.2 Hijacking Experiment

While our analysis in Section 3 provided strong indications of ISPY’s accuracy in detecting real hijacking events, we sought to validate its performance in real-world scenarios. In addition to validating detection accuracy, these experiments allowed us to study the detection latency of a deployed system in reporting real hijacks.

Historical cases of prefix hijacking have occurred in the Internet, but our deployment of ISPY at over 100 PlanetLab sites has not yet witnessed any such events. To overcome this challenge, we set up a controlled hijacking testbed to launch 15 hijacking attacks on our own prefix and deployed ISPY to observe its live action during these events.

**Experiment Setup:**

Our prefix hijacking testbed consisted of three hosts located in Seattle, London, and Tokyo, each running a software BGP router to maintain BGP peering sessions with their respective upstream provider ISPs: Verio (AS 2914), Clara.net (AS 8426), and JPNIC (AS 2497). This setup, shown in Figure 8, allowed us to inject an anycast prefix (198.180.153.0/24) from any of the three hosts into the Internet, emulating different hijacking scenarios.

For each hijacking event, we designated one site as the victim and another as the attacker. Initially, only the victim injected the target prefix. Two hours later, the attacker also injected the prefix, initiating the hijacking event. After another two hours, the attacker withdrew the prefix. We conducted a total of 15 hijackings during two one-week periods in January and June 2008. The times of the hijacking events and the corresponding attackers and victims are listed in Table 8. During these periods, ISPY was continuously running on the hosts at the victim sites, with the detection threshold set to 10 cuts.

**Details of Detecting One Hijack:**

We first discuss one hijacking event in detail, introducing the entries shown in Table 8. Event 1 started on January 22 at 14:00 GMT, initiated by the London site. Upon convergence, 35.6% of the transit ASes became unreachable from the Seattle site, resulting in cuts in the vPath in the range of [376; 409]. Figures 9(a)-(b) show the number of unreachable ASes and the number of cuts computed at the boundary of probing rounds before and after the hijack injection moment. The probing rounds had shorter durations before the hijack due to the need to retry alternative IPs for unreachable ASes. Before the hijack, the numbers of unreachable ASes and cuts were insignificant. At the hijack injection moment, the current probing round had been running for 2.1 minutes. As the probing progressed, ISPY updated the observed cuts, and at 2.1 minutes after the hijack, the detected number of cuts reached the detection threshold, triggering the alarm. Thus, the detection latency was 2.1 minutes, well before the round finished 19 minutes later.

**Overall Detection Performance:**

Table 8 details all 15 hijacking events, all of which were definitively detected by ISPY. Upon convergence, the pollution ranged from 31.0% to 52.3%, and the number of cuts was always above 200, confirming our observation that hijacking typically creates a large number of cuts in vPath. The first probing round in which the alarm was triggered is called the "first alarming round" in Table 8. For events other than 9, the alarm was triggered by the probing round in progress when the hijacking occurred, and thus their start time relative to the hijacking event is negative. For event 9, the initial round did not collect enough cuts to trigger the alarm, but the accumulated cuts in the subsequent round quickly triggered the alarm.

In summary, Table 8 shows that despite variations in the start time of the first alarming round (from 10.9 minutes before to 0.2 minutes after the hijack injection), the detection latency remained consistently low, ranging from 1.4 to 3.1 minutes. This consistent low latency is attributed to the continuous computation of cuts and the rapid response of ISPY to significant changes in the network.

**Table 8: Statistics of the 15 Hijacking Events and ISPY’s Detection Performance**

| Event # | Start Time (GMT) | Attacker | Victim | Pollution (%) | Cuts | First Alarming Round (min) | Detection Latency (min) |
|---------|------------------|----------|--------|---------------|------|---------------------------|-------------------------|
| 1       | Jan 22 14:00     | London   | Seattle| 35.6          | 376-409 | -2.1                      | 2.1                     |
| 2       | ...              | ...      | ...    | ...           | ...  | ...                       | ...                     |
| 3       | ...              | ...      | ...    | ...           | ...  | ...                       | ...                     |
| 4       | ...              | ...      | ...    | ...           | ...  | ...                       | ...                     |
| 5       | ...              | ...      | ...    | ...           | ...  | ...                       | ...                     |
| 6       | ...              | ...      | ...    | ...           | ...  | ...                       | ...                     |
| 7       | ...              | ...      | ...    | ...           | ...  | ...                       | ...                     |

(Note: The table continues with similar entries for events 8-15.)