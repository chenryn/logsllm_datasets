### Introduction

During the analysis of email headers, particularly the "Received:" fields, investigators can easily identify discrepancies. These fields often contain domain names and IP addresses, which can be further analyzed using various Unix tools to gather forensic information.

### Example Analysis

The following is an example of a "Received:" field from an email message we received:

```
Received: from walking14.legessermon.com ([64.192.31.14])
     by e18si15752160qbe.2007.05.30.10.46.13; 
     Wed, 30 May 2007 10:46:24 -0700 (PDT)
```

This field contains two domain names (walking14.legessermon.com, mx.google.com) and one IP address (64.192.31.14). UnMask collects detailed forensic information for each of these entities by launching the appropriate Unix tools. The information was collected within one day of receiving the message.

### Detailed Report

Figure 6 shows a snapshot of the report section related to the domain name `walking14.legessermon.com` found in the "Received:" field. This section includes:
- Location and contact information of the organization responsible for the domain.
- MX and DNS records for the domain.
- The route to the domain name.
- The IP address associated with the domain.

For the domain `walking14.legessermon.com`, the IP address returned by the `dig` tool was 64.192.31.2, which differs from the IP address listed in the "Received:" field (64.192.31.14). However, no strong conclusions can be drawn from this discrepancy, as both IP addresses may be on the same subnet.

UnMask also collected similar information for the IP address 64.192.31.14 and the domain `mx.google.com`. We do not discuss these results further due to space limitations. It is worth noting that the location and contact information obtained from probing IP addresses tend to be more reliable and long-lived compared to those obtained from domain names.

### Extending UnMask Capabilities

While our current reports present the information gathered from the email and additional data from Unix tools, we can further enhance the system by incorporating logical analysis and data mining. Since PostgreSQL is a relational database, we can apply predicate logic to the relations in our database.

Currently, we generate reports by collating the gathered information and presenting it in a meaningful format. However, we could do more by applying formal logic and data mining. For instance, we could identify companies that enable phishing activities by not enforcing policies and standard procedures. We could gather vital statistics on phishing scams associated with these companies and use predicate logic to cluster emails that are part of larger criminal activities.

A concrete example would be to structure a query that counts the number of unique URLs found in all emails in the UnMask database. We could then count the number of URLs registered at each Registrar (e.g., Go Daddy, eNom, Network Solutions, Tucows) to determine if any Registrar is associated with a higher level of phishing activity. This information could be used to persuade ICANN to investigate potential concerns.

As the system is used, the techniques for interpreting data will evolve. The logic used can be integrated back into the reports, automating not only the task of data collection but also the deductions about the data.

### Conclusion

This paper describes the design and development of the UnMask system, which supports law enforcement in investigating phishing email crimes. The system allows investigators to upload a suspect email via a secure user interface and receive a detailed report. A novel aspect of UnMask is its use of a database to store and organize information, and to launch automated searches to collect additional data from the internet. To the best of our knowledge, UnMask is the first comprehensive system that can automatically analyze emails and generate forensic reports for investigation and prosecution.

Version 1 of UnMask is a working system, completed except for code hardening. We plan to have law enforcement use the system experimentally and provide feedback to add additional features and search tools. Future enhancements include checking for blacklisted sites, inspecting websites with automated crawlers, and incorporating a logic analysis module to filter and assess the retrieved data.

### Acknowledgements

This work was supported in part by the National Institute of Justice under grants 2005-MU-MU-K007 and 2006-DN-BX-K007. We thank NW3C (Bob Hopper and Nick Newman) and FDLE (Mike Phillips and his group in the Computer Crime Center) for their invaluable feedback, help, and support.

### References

[1] Anti-Phishing Working Group. http://www.antiphishing.org/  
[2] Phishing and Federal Law Enforcement. Referenced 5/29/07, http://www.abanet.org/adminlaw/annual2004/Phishing/PhishingABAAug2004Rusch.ppt.  
[3] President’s Information Technology Advisory Committee (PITAC) (2005). Cybersecurity: A Crisis of Prioritization, Report to the President. Posted 2/28/2005, http://www.nitrd.gov/pitac/reports/20050301_cybersecurity/cybersecurity.pdf.  
[4] Law Enforcement Battles with Botnets. Referenced 5/29/07, http://government.zdnet.com/?p=2373.  
[5] Daubert v. Merrell Dow Pharmaceuticals, Inc. 509 U.S. 579 (1993).  
[6] The Anti-Phishing group at Indiana University. http://www.indiana.edu/~phishing/.  
[7] Bob Breeden, Mike Cantey, Brett Cureton, Clifford Stokes, Peter Henry, Judie Mulholland, Wayne Sprague, and Jim Watson. The Phlorida Autopsy Report. Digital Forensic Practice, Journal of, 1(3):203-222, 2006.  
[8] Y. Teraguchi N. Chou, R. Ledesma and J.C. Mitchell. Client-side defense against web-based identity theft. In 11th Annual Network and Distributed System Security Symposium (NDSS '04), San Diego, CA, USA, February 2004.  
[19] Joshua Goodman, Gordon V. Cormack, and David Heckerman, Spam and the ongoing battle for the inbox. Commun. ACM, 50(2), February, 2007.  
[20] Aleksander Kolcz, Abdur Chowdhury, and Joshua Alspector. The Impact of Feature Selection on Signature-Driven Spam Detection. In CEAS 2004 - First Conference on Email and Anti-Spam, Mountain View, CA, USA, July 2004.  
[21] William W. Cohen. Learning rules that classify email. In Proceedings of 1996 AAAI Spring Symposium on Machine Learning in Information Access (MLIA '96), 1996.  
[22] Isidore Rigoutsos and Tien Huynh. Chung-Kwei: a Pattern-discovery-based System for the Automatic Identification of Unsolicited Email Messages (SPAM). In CEAS 2004 - First Conference on Email and Anti-Spam, Mountain View, CA, USA, July 2004.  
[23] Paul Graham. A Plan for Spam. http://www.paulgraham.com/spam.html, 2002.  
[24] Sam Spade. http://www.pcworld.com/downloads/file/fid,4709-page,1/description.html  
[25] DomainTools. http://www.domaintools.com.  
[26] Phisherman, SPARTA, Inc. http://www.isso.sparta.com/documents/phisherman.pdf.  
[27] Sudhir Aggarwal, Daniel Beech, Rajarshi Das, Breno de Medeiros, Eric Thompson. X-Online: An Online Interface for Digital Decryption Tools. Proceedings of the 2nd Int. Workshop on Systematic Approaches to Digital Forensics Engineering (SADFE 2007), April 2007.  
[28] PostgrelSQL, http://www.postgresql.org.  
[29] P. Rensnick, “Internet Message Format”, RFC 2822. April 2001.  
[30] Comprehensive Perl Archive Network. http://www.cpan.org/.  
[31] SQL Injection. http://en.wikipedia.org/wiki/SQL_Injection.  
[32] IPGEO Tools. http://www.ipgeo.com.  
[9] SpoofStick. http://www.spoofstick.com.  
[10] TrustBar. http://www.cs.biu.ac.il/~herzbea/Papers/ecommerce/spoofing.htm.  
[11] Min Wu, Robert C. Miller, and Simson L. Garfinkel. Do security toolbars actually prevent phishing attacks? In CHI '06: Proceedings of the SIGCHI conference on Human Factors in computing systems, pages 601-610, New York, NY, USA, 2006. ACM Press.  
[12] Rachna Dhamija and J. D. Tygar. The battle against phishing: Dynamic security skins. In SOUPS '05: Proceedings of the 2005 symposium on Usable privacy and security, pages 77-88, New York, NY, USA, 2005. ACM Press.  
[13] PassMark. http://www.passmarksecurity.com.  
[14] Min Wu, Robert C. Miller, and Greg Little. Web wallet: preventing phishing attacks by revealing user intentions. In SOUPS '06: Proceedings of the second symposium on Usable privacy and security, pages 102-113, New York, NY, USA, 2006. ACM Press.  
[15] Wenyin Liu, Xiaotie Deng, Guanglin Huang, and A.Y. Fu. An antiphishing strategy based on visual similarity assessment. Internet Computing, IEEE, 10(2):58-65, March-April 2006.  
[16] Madhusudhanan Chandrasekaran, Ramkumar Chinchani, and Shambhu Upadhyaya. PHONEY: Mimicking User Response to Detect Phishing Attacks. In 2006 International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM'06), pages 668-672, 2006.  
[17] Yi-Min Wang, Doug Beck, Xuxian Jiang, Roussi Roussev, Chad Verbowski, Shuo Chen, and Samuel T. King. Automated web patrol with Strider HoneyMonkeys: Finding web sites that exploit browser vulnerabilities. In Proceedings of the Network and Distributed System Security Symposium, NDSS 2006, San Diego, CA, USA, 2006. The Internet Society.  
[18] Aaron E. Kornblum. Searching For John Doe: Finding Spammers and Phishers. In CEAS 2005 - Second Conference on Email and Anti-Spam, July 2005.