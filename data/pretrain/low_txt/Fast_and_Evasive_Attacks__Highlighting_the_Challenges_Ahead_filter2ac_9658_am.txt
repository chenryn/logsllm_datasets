### Scalability of the Automated Approach

This automated approach can be easily scaled to accommodate large collections of program models.

### Acknowledgments

We extend our gratitude to the anonymous reviewers and the members of the WiSA project at the University of Wisconsin for their valuable feedback, which significantly enhanced the quality of this paper. This work was partially supported by grants from the Office of Naval Research (N00014-01-1-0708), the National Science Foundation (CCR-0133629), and the Department of Energy (DE-FG02-93ER25176). Jonathon T. Giffin received partial support through a Cisco Systems Distinguished Graduate Fellowship. Somesh Jha was partially supported by an NSF Career grant (CNS-0448476). The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes, notwithstanding any copyright notices affixed hereon. The views and conclusions expressed in this document are those of the authors and should not be interpreted as representing the official policies or endorsements, either expressed or implied, of the aforementioned government agencies or the U.S. Government.

### References

1. **T. Ball and S. K. Rajamani.** "Bebop: A Symbolic Model Checker for Boolean Programs." In *7th International SPIN Workshop on Model Checking of Software*, Stanford, California, Aug./Sep. 2000.

2. **F. Besson, T. Jensen, D. L. Métayer, and T. Thorn.** "Model Checking Security Properties of Control-Flow Graphs." *Journal of Computer Security*, 9:217–250, 2001.

3. **H. Chen and D. Wagner.** "MOPS: An Infrastructure for Examining Security Properties of Software." In *9th ACM Conference on Computer and Communications Security (CCS)*, Washington, DC, Nov. 2002.

4. **E. M. Clarke, O. Grumberg, and D. A. Peled.** *Model Checking*. The MIT Press, 2000.

5. **J. Esparza, D. Hansel, P. Rossmanith, and S. Schwoon.** "Efficient Algorithms for Model Checking Pushdown Systems." In *Computer Aided Verification (CAV)*, Chicago, Illinois, July 2000.

6. **H. H. Feng, J. T. Giffin, Y. Huang, S. Jha, W. Lee, and B. P. Miller.** "Formalizing Sensitivity in Static Analysis for Intrusion Detection." In *IEEE Symposium on Security and Privacy*, Oakland, California, May 2004.

7. **S. Forrest.** "Data Sets—Synthetic FTP." [http://www.cs.unm.edu/~immsec/data/FTP/UNM/normal/synth/](http://www.cs.unm.edu/~immsec/data/FTP/UNM/normal/synth/), 1998.

8. **S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff.** "A Sense of Self for UNIX Processes." In *IEEE Symposium on Security and Privacy*, Oakland, California, May 1996.

9. **D. Gao, M. K. Reiter, and D. Song.** "On Gray-Box Program Tracking for Anomaly Detection." In *USENIX Security Symposium*, San Diego, California, Aug. 2004.

10. **J. T. Giffin, D. Dagon, S. Jha, W. Lee, and B. P. Miller.** "Environment-Sensitive Intrusion Detection." In *8th International Symposium on Recent Advances in Intrusion Detection (RAID)*, Seattle, Washington, Sept. 2005.

11. **J. T. Giffin, S. Jha, and B. P. Miller.** "Detecting Manipulated Remote Call Streams." In *11th USENIX Security Symposium*, San Francisco, California, Aug. 2002.

12. **R. Gopalakrishna, E. H. Spafford, and J. Vitek.** "Efficient Intrusion Detection Using Automaton Inlining." In *IEEE Symposium on Security and Privacy*, Oakland, California, May 2005.

13. **J. D. Guttman, A. L. Herzog, J. D. Ramsdell, and C. W. Skorupka.** "Verifying Information Flow Goals in Security-Enhanced Linux." *Journal of Computer Security*, 13:115–134, 2005.

14. **L.-c. Lam and T.-c. Chiueh.** "Automatic Extraction of Accurate Application-Specific Sandboxing Policy." In *Recent Advances in Intrusion Detection (RAID)*, Sophia Antipolis, French Riviera, France, Sept. 2004.

15. **C. R. Ramakrishnan and R. Sekar.** "Model-Based Vulnerability Analysis of Computer Systems." In *2nd International Workshop on Verification, Model Checking and Abstract Interpretation*, Pisa, Italy, Sept. 1998.

16. **F. B. Schneider.** "Enforceable Security Policies." *ACM Transactions on Information and System Security*, 3(1):30–50, Feb. 2000.

17. **S. Schwoon.** "Model-Checking Pushdown Systems." Ph.D. dissertation, Technische Universität München, June 2002.

18. **S. Schwoon.** "Moped—a Model-Checker for Pushdown Systems." [http://www.fmi.uni-stuttgart.de/szs/tools/moped/](http://www.fmi.uni-stuttgart.de/szs/tools/moped/), 2006.

19. **R. Sekar, M. Bendre, P. Bollineni, and D. Dhurjati.** "A Fast Automaton-Based Method for Detecting Anomalous Program Behaviors." In *IEEE Symposium on Security and Privacy*, Oakland, California, May 2001.

20. **K. Tan, K. S. Killourhy, and R. A. Maxion.** "Undermining an Anomaly-Based Intrusion Detection System Using Common Exploits." In *Recent Advances in Intrusion Detection (RAID)*, Zürich, Switzerland, Oct. 2002.

21. **K. Tan and R. A. Maxion.** "Why 6? Defining the Operational Limits of STIDE, an Anomaly-Based Intrusion Detector." In *IEEE Symposium on Security and Privacy*, Oakland, California, May 2002.

22. **K. Tan, J. McHugh, and K. Killourhy.** "Hiding Intrusions: From the Abnormal to the Normal and Beyond." In *5th International Workshop on Information Hiding*, Noordwijkerhout, Netherlands, Oct. 2002.

23. **D. Wagner and D. Dean.** "Intrusion Detection via Static Analysis." In *IEEE Symposium on Security and Privacy*, Oakland, California, May 2001.

24. **D. Wagner and P. Soto.** "Mimicry Attacks on Host-Based Intrusion Detection Systems." In *9th ACM Conference on Computer and Communications Security*, Washington, DC, Nov. 2002.

25. **B. J. Walker, R. A. Kemmerer, and G. J. Popek.** "Specification and Verification of the UCLA Unix Security Kernel." *Communications of the ACM*, 23(2), Feb. 1980.

---

### Allergy Attack Against Automatic Signature Generation

**Simon P. Chung and Aloysius K. Mok**

*University of Texas at Austin, Austin TX 78712, USA*

*Department of Computer Sciences, {phchung, mok}@cs.utexas.edu*

#### Abstract

Recent research has focused on systems that automatically generate signatures to filter out zero-day worm instances at perimeter defense. While these systems often struggle with polymorphic worms, we investigate a different and potentially more serious issue: attacks that manipulate the signature generation system to cause denial of service (DoS) against the protected system. We term this new attack the "allergy attack." Although this type of attack has been discussed in the context of "detraining" in machine learning, its practical impact on real intrusion detection/prevention systems has not been demonstrated. This paper presents the practical impact of "allergy attacks."

#### Keywords

Automatic Signature Generation, Adaptive Response, Intrusion Prevention

#### 1. Introduction

With the rapid proliferation of worms, automatic worm containment is increasingly seen as a solution. Automatic signature generation (ASG) systems, which generate signatures to filter worm instances at perimeter defense, are a key focus. Similar to [3,8,10], our work highlights a common weakness in many ASG systems: the "allergy attack." While worm polymorphism renders ASG systems ineffective [3,8], the allergy attack allows attackers to turn ASG systems into agents for inflicting harm by manipulating them to filter normal traffic. This vulnerability, which transforms ASG systems from imperfect but harmless defenses into active threats, is as damaging as the well-addressed issues of worm polymorphism. The scope of the threat from allergy attacks is broader, affecting systems that use various types of signatures, not just contiguous byte sequences.

The problem of allergy attacks is similar to the "causative, indiscriminate availability" attack mentioned in [1]. However, [1] focuses on theoretical attacks on machine-learning-based security mechanisms, while our study specifically addresses the practicality of inducing high false positives in ASG systems. To demonstrate the practicality of allergy attacks, we have experimented with one publicly available ASG system and analyzed the algorithms of eight others. Our work complements [1] by providing experimental validation of allergy attacks. Additionally, ASG systems often need to identify features before applying machine-learning techniques, making feature extraction a critical avenue for attack.

Our literature survey shows that the threat from allergy attacks has received limited attention. Resilience against allergy attacks is not a design objective in published ASG systems, yet it is essential for their practical use. Our contributions are:

1. By defining and demonstrating the allergy attack, we aim to highlight the threat.
2. By providing insights into the root causes, we hope to aid in designing future ASG systems that are resilient to allergy attacks.

#### 2. Defining Allergy Attack

An allergy attack is a DoS attack achieved by inducing ASG systems to generate signatures that match normal traffic, leading to the blocking of target normal traffic when applied to perimeter defense. We focus on attacks against valid service requests, where successful attacks block all instances of the target requests, making the corresponding service unavailable.

Since existing ASG systems observe network traffic, attackers manipulate them by presenting crafted packets with the following properties:

1. The packets are classified as suspicious and used for signature generation.
2. The packets result in the desired signatures being generated.

Although checking new signatures against a corpus of normal traffic might seem like a solution, it is impractical due to memory and time constraints. Many ASG systems employ methods to eliminate false positives using observed normal traffic, but they remain vulnerable to allergy attacks because these methods are designed for naturally occurring false positives, not intentionally produced ones.

#### 3. Related Work

##### 3.1 String-Matching ASG Systems

Many ASG systems use simple byte sequences as signatures. These systems first identify worm packets using heuristic approaches and then extract invariant byte sequences as signatures.

##### 3.2 Other ASG Systems

To address polymorphic worms, some systems use other properties of suspicious packets as signatures, such as byte-frequency distribution, control-flow graph properties, or protocol frame values.

##### 3.3 Allergy-Type Attack in the Literature

While the allergy attack has not been demonstrated in practice, it has been briefly mentioned in several works [4,11,14]. Singh et al. [11] suggested comparing signatures with existing traffic corpora, which is infeasible. Kim et al. [4] proposed vetting candidate signatures among distributed monitors, which can be defeated if all sites are attacked simultaneously. Yegneswaran et al. [14] suggested human sanity checks, which defeat the purpose of automated signature generation.

#### 4. Attacking Autograph: A Demonstration

We demonstrate the allergy attack against Autograph, a real ASG system. We chose Autograph because it is accessible and typical of ASG systems vulnerable to allergy attacks. Our attack involves two steps:

1. Induce Autograph to classify controlled machines (drones) as scanners.
2. Use drones to connect to protected network machines, populating Autograph's suspicious pool with crafted packets that result in the desired signatures.

Due to Autograph's simple heuristics, the first step can be achieved by requesting connections with many random IP addresses or sending TCP connection requests with unusual flag combinations.

#### 5. Type II Allergy Attack

We describe a more sophisticated type II allergy attack, which can defeat simple defenses. This attack allows finer control over what services are targeted, making it more challenging to mitigate.

#### 6. Root Causes and Mitigation

We present our initial theory on the root causes of vulnerability to allergy attacks and factors that facilitate exploitation. Understanding these factors will help in designing resilient ASG systems and devising remedies for existing ones.

#### 7. Conclusion

By defining and demonstrating the allergy attack, we aim to draw attention to this significant threat. Our insights into the root causes and factors facilitating exploitation will aid in the design of future ASG systems that are resilient to allergy attacks.