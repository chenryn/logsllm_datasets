### Section VII: Vote Score Distribution and Evasion Attacks

The vote score distribution of these attacks is largely disjoint from that observed in typical benign or malicious instances. By employing an ensemble classifier diversity-based approach, the majority of these attacks can be distinguished from benign observations. Consequently, these attacks should be regarded as weak mimicry attempts.

When all attributes of the classifier are known, 33% of the attacks are effective. However, if either the details of the classifier or the training set are withheld, the attack success rate drops to 10% or lower. In addition to evaluating against the Contagio dataset, the mimicry attack data was tested against a classifier trained with the University dataset. This results in an alternate FC attack scenario because the training set is unknown to the attacker. Figure 8 illustrates the score distribution from applying the malware from the FTC attack scenario to the University classifier.

The results are very similar between the two classifiers. In both cases, only 7 out of 100 evasion attempts are classified as benign. A careful comparison of Figures 6 and 8 reveals that the University classifier provides a tighter cluster of scores near the center of the disagreement region. The results from the Contagio classifier are similar to those of the University classifier because the Mimicus evasion attempts use Contagio data for both baseline benign and attack data.

When mutual agreement is utilized, the majority of Mimicus attacks are labeled as uncertain, indicating known classifier failure and possible evasion. In the best mimicry attack scenario, where all attributes of PDFrate are known, only 33% of the mimicry attempts are successfully classified as benign. If some details of the classifier, such as the exact training set, are not known by the attacker, the mimicry success rate is below 10%.

### C. Reverse Mimicry

We also applied mutual agreement analysis to the Reverse Mimicry attack proposed by Maiorca et al. [26], [27]. The exact procedures required to replicate these attacks are not publicly documented. However, Maiorca et al. provided us with the documents used in their studies. Their most recent attacks involved 500 documents in each evasion scenario. To remain consistent with the Mimicus attack evaluation, we took a 100-sample random subset of each scenario for our evaluation.

Table VIII presents the results of applying mutual agreement analysis to the Reverse Mimicry attacks against both the Contagio and University classifiers. The score distributions for these attacks against the University classifier are shown in Figures 9, 10, and 11. Despite mutual agreement analysis, 67% of the Reverse Mimicry attacks are successful evasions (considered benign) against the Contagio classifier.

The University classifier performs much better than the Contagio classifier. The only evasions against the University classifier are achieved by the PDFembed attack. This attack is so successful because a complete malicious PDF is embedded in an otherwise benign document. The embedded document resides in a compressed data stream, which means that the structural features cannot be observed by PDFrate’s feature extractor. This contrasts with the other scenarios, EXEembed and JSinject, where despite efforts at minimization, some indicators of malfeasance remain exposed.

The PDFembed scenario is effective against the detector at pdfrate.com because it does not perform recursive decoding and analysis, as would be necessary in an operational system. This failure is similar to malware analysis systems that assume an input of an unpacked executable and fail when presented with a packed executable or a Trojan document. When PDFrate is deployed in operational detection systems, it is usually done within a framework that provides both decoding of PDF streams and extraction of PDFs from other containers such as emails or zip files [3]. In all the PDFembed attacks, the embedded document was identical. The Contagio and University classifiers both easily detect this document with high confidence once it is extracted, returning scores of 97.6% and 100%, respectively.

For the isolated PDFrate implementation, the PDFembed scenario represents a strong evasion scenario, where classifier introspection provides little benefit because the feature extractor is so well evaded. Even though the Contagio-based classifier is a poor fit for the malware used in the EXEembed and JSinject, many of these samples still fall in the uncertain outcome vote range. When the stronger University classifier is used, mutual agreement analysis flags these evasion scenarios that would otherwise be successful.

### D. Drebin

To apply mutual agreement analysis to the Drebin Android malware detector, we constructed an ensemble classifier. We employed a Random Forest classifier, which required adapting the features to ensure computational efficiency and to ensure results comparable to the original linear SVM. Instead of using all string values as features, we used a subset of 891 features that comprise the most durable features. We used all of the features for constrained categories such as API calls and permissions. For arbitrarily named attributes, such as components and intents, we utilized the most prolific values, selecting those which occur over 100 times in the training set. Lastly, we ignored specific values for highly volatile items such as URLs and network addresses, which compose over half the features used by Drebin. We summed the occurrences of each category of features and used these counts as features.

As an optimization, we de-duplicated any equivalent feature vectors during classifier training (not during evaluation). This de-duplication, using our narrow feature set, resulted in a reduction from 123,453 to 63,379 unique benign and 5,560 to 2,185 unique malicious samples. Barring these transformations of data, we used the published Drebin datasets including dataset partitions in our evaluation.

We tuned our Random Forest-based classifier to provide classification performance comparable to the linear SVM classifier of Drebin. The primary item we tuned was the ratio of benign to malicious samples used in training each tree. This was necessary because there is an extreme imbalance in the benign to malicious ratio of the various training sets. We tuned the ratio for individual tree training to 2.5 benign to 1 malicious in order to match the desired false positive rate of 1% chosen by Arp et al. We set the other tunable parameters for Random Forest to standard values: each Random Forest contained 1,000 trees, and the number of variables tried at each split was set to the square root of the number of features. Our Random Forest classifier provided an average false positive rate of 1.06% and a malware detection rate of 92.3% on the published dataset partitions using a traditional threshold without an uncertain region. The Random Forest-based classifier performance is very similar, albeit slightly inferior, to that provided by Drebin’s linear SVM. Figure 12 shows the score distribution for benign samples using one of the published dataset partitions. Figure 13 shows the same for the malicious samples.

An important aspect of the original Drebin study is the division of malware by family and the evaluation of the classifier on previously unknown malware families. This was achieved by withholding the family to be evaluated from the training set and then applying the resultant classifier to the malware samples in that family. It is noted by Arp et al. [4] that Drebin provides relatively poor classification of previously unknown malware families. We applied our Random Forest-based classifier and uncertain score region to this same problem. Figure 15 compares the detection rates of the linear SVM classifier and our Random Forest-based classifier using mutual agreement analysis.

As expected, the vast majority of unknown malware families have the score distribution of a weak evasion attack, indicating that the classifier considers these observations neither similar to the benign nor malicious samples seen in the training set. As an example, the scores of malware family A are shown in Figure 14. On average, 75.2% of every family is labeled as uncertain and an additional 8.2% are labeled as malicious using our Random Forest-based classifier, while 50.6% of every family is labeled as malicious by the Drebin linear SVM. Families Q and R represent strong evasion. Arp et al. note that Family R cannot be reliably detected with the feature set used by Drebin. While the features used by Drebin are sufficient for the detection of Family Q when included in the training set, it is too different from other families in Drebin’s feature space to be flagged as an evasion. On the other hand, Family P is so similar to other malware families in Drebin’s feature space that it is not necessary to have samples of this family in the training set. Removing these three families, an average of 89.7% of the samples in the remaining 17 families are identified as malicious or uncertain by the Random Forest classifier, while 53.2% are detected by the linear SVM classifier. It is advantageous to label these previously unknown samples as uncertain so that the operator can take action to improve the classifier. While the linear SVM classifier provides the average classification accuracy of a coin toss in these scenarios, the mutual agreement-conscious ensemble is able to flag the majority of the novel attacks as possible evasions.

Mutual agreement analysis is effective at identifying possible evasions in the PDFrate and Drebin malware detection systems caused by both novel attacks and targeted mimicries.

### VI. Mutual Agreement Threshold Tuning

For most of our evaluations, we used a 50% mutual agreement threshold, which splits the classifier voting score region into four equal-sized quadrants. It is possible to choose an arbitrary mutual agreement threshold. Table IX contains Drebin predictions for three mutual agreement threshold levels. The distribution of scores for the benign samples using one of the published dataset partitions is shown in Figure 12. Figure 13 shows the same for the malicious samples. As expected, the score distributions are shaped similarly to that of PDFrate, but since the classifier accuracy is lower, the samples are distributed farther from the respective ends of the score continuum. Table IX shows the classifier outcomes for typical mutual agreement thresholds.

An important facet of the original Drebin study is the division of malware by family and the evaluation of the classifier on previously unknown malware families. This was achieved by withholding the family to be evaluated from the training set and then applying the resultant classifier to the malware samples in that family. It is noted by Arp et al. [4] that Drebin provides relatively poor classification of previously unknown malware families. We applied our Random Forest-based classifier and uncertain score region to this same problem. Figure 15 compares the detection rates of the linear SVM classifier and our Random Forest-based classifier using mutual agreement analysis.

### VII. GD-KDE and Ensemble SVMs

Mutual agreement analysis should apply to all ensemble classifiers that provide sufficient diversity in individual classifiers. To validate this, we studied the feasibility of countering evasion against SVMs by applying mutual agreement analysis to SVMs using an ensemble approach.

The Mimicus attack framework implements a Gradient Descent and Kernel Density Estimation (GD-KDE) attack against their PDFrate replica utilizing an SVM classifier. This attack operates by exploiting the known decision boundary of a differentiable classifier [8].

We reproduced the GD-KDE evasion attacks of Mimicus and confirmed that they are indeed extremely effective. Using the e1071 package of R [2], which relies on libSVM [10], we calculated the average probability of 8.9% malicious (or 91.1% benign) for both GD-KDE scenarios, placing these attacks squarely within the evasion region. Šrndić and Laskov use the following mutual agreement thresholds to illustrate the uncertain score ranges:

| Mutual Agreement Threshold | Uncertain Score Range |
|---------------------------|-----------------------|
| 0%                        | (45, 55)               |
| 10%                       | (40, 60)               |
| 20%                       | (35, 65)               |
| 30%                       | (30, 70)               |
| 40%                       | (25, 75)               |
| 50%                       | (20, 80)               |
| 60%                       | (15, 85)               |
| 70%                       | (10, 90)               |
| 80%                       | (5, 95)                |
| 90%                       | (0, 100)               |

The exact mutual agreement threshold chosen strikes a balance between improvement in classification failure detection and the number of classifier predictions thrown out as uncertain. Operators who wish to have a lower amount of uncertain outcomes may choose a lower threshold. Taking the PDFrate performance in Table X as an example, if 30% is selected as a threshold, the uncertain region comprises ensemble classifier voting scores between 35% and 65% instead of 25% and 75% with a 50% threshold. For the operational dataset, the uncertain rate for benign samples drops from 0.456% to 0.256%. However, the number of successful evasion attempts rises from 7% to 12%. The optimal setting for this threshold depends on the preferences of the operator. The sensitivity of uncertain detection is adjusted by tuning the mutual agreement threshold, setting the boundaries for the uncertain range.