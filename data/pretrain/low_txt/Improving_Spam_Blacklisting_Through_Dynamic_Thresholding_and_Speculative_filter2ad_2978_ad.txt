### 4.4 Performance

Figure 9 illustrates the growth of blacklists for three different techniques: existing static threshold-based models, dynamic thresholding, and speculative aggregation. Our findings indicate that the blacklist size grows most rapidly for ratio-based techniques and least for the speculative-aggregation technique, which consolidates multiple sources into BGP prefixes.

To assess how blacklist size impacts system performance, we created tables with varying blacklist sizes in a PostgreSQL database, which is the same database used in our system. We then created an index on the IP addresses and prefixes using the GiST index in PostgreSQL. Table 4 presents the lookup time and index size for different blacklist sizes. The results show that the lookup time for an entry does not increase significantly, and the index size remains manageable even after a month of operation.

### 4.5 Impact of the Oracle on Accuracy

To validate the accuracy of SpamAssassin, we manually classified several email boxes and fed them to SpamAssassin. As reported in our previous study [23], SpamAssassin had a false positive rate of less than 1% and a false negative rate of around 5%. These errors in the oracle can affect the accuracy of our measurements. For instance, a false negative from SpamAssassin (i.e., spam classified as ham) may be incorrectly identified as a false positive by the blacklist if the blacklist correctly identifies the email as spam.

Given the inaccuracy of SpamAssassin, the false positive rate for the blacklist can be expressed as \( \text{FP}_{\text{blacklist}} \pm \text{FN}_{\text{SpamAssassin}} \), and the false negative rate for the blacklist can be expressed as \( \text{FN}_{\text{blacklist}} \pm \text{FP}_{\text{SpamAssassin}} \). With the values of 20% or greater for the false negatives of blacklists and 1% for the false positives, the blacklist's false positive rate becomes \( 1\% \pm 5\% \), and the false negative rate becomes \( > 20\% \pm 1\% \). Clearly, the small false positive rate of the blacklists can be overshadowed by the noise from the oracle.

To address this issue, we manually classified the false negatives of SpamAssassin. Instead of examining all false negatives (which could include legitimate emails), we only classified sources that hit spamtraps, ensuring that no legitimate users were affected.

### 5 Related Work

Recent research has explored various algorithms for generating blacklists. Ramachandran et al. [20] proposed a method to blacklist source IP addresses based on their email sending patterns. However, their experiment was limited to emails received on spamtraps, not on live networks, thus evaluating only the false negatives of spamtrap-received emails, not the false positives of their approach. In contrast, our study generates blacklists based on spamtrap emails and applies them to live network emails, allowing us to evaluate both false positives and false negatives on the live network.

Xie et al. [29] demonstrated that many IP addresses are dynamically assigned, and emails from these addresses are often spam. They recommended adding dynamic IP ranges to blacklists to reduce false negatives. Zhang et al. [31] argued that common blacklists may contain unused entries and proposed a method to reduce blacklist size and computational overhead. However, their approach only improves the blacklist "hit-rate" and not the overall false positive or false negative rates.

Ramachandran and Feamster [19] collected spam by monitoring emails sent to an unused domain and found that spamming sources are clustered within IP address space, with some being short-lived. Our speculative aggregation technique automatically identifies bad IP neighborhoods by considering both spamtrap hits and sources that have not yet hit the spamtraps.

Several studies have questioned the effectiveness of blacklists. Ramachandran et al. [18] analyzed the speed at which Bobax-infected hosts appeared in the SpamHaus blacklists, finding that many hosts were not listed, highlighting delays in blacklisting. Our speculative aggregation technique addresses this delay problem.

Email servers can be overwhelmed by spam, leading to increased interest in lightweight measures to reduce server load. Venkataraman et al. [26] proposed coarse IP-based blacklists to reject emails and reduce server load. They monitored emails on a mail server and used SpamAssassin scores to identify spam and ham. While their approach relies on an existing spam detector, our method uses deployed spamtraps and production network emails to generate blacklists, making them useful for improving spam detectors rather than just reducing server load.

Xie et al. [30] used a spam detector to classify emails and proposed an automated way to generate spam signatures, focusing on message content. Similarly, Beverly et al. [8] used TCP information to develop TCP-level spam features. Kanich et al. [12] empirically evaluated spam success rates and monetization, while Rajab et al. [17] analyzed botnet behavior without developing an automated blacklisting method.

The work of Hao et al. [11] is most similar to ours. They used a spam detector to separate emails into ham and spam and identified network-level features to differentiate between the two. They then used machine-learning models to build a spam classifier. While their work results in a lightweight spam filter, it does not explore how existing blacklists fail and can be improved. Our approach focuses on a few key features, such as remote BGP prefix clustering, and explores the properties and trade-offs of each.

### 6 Discussions

In this paper, we conducted a detailed investigation of blacklist generation techniques using 2.5 million emails from a large academic network and 14 million emails from a spamtrap deployment in 11 domains. We analyzed ham and spam sources based on our own spamtrap deployment, explaining the limitations of existing spam blacklist approaches. We proposed two improvements to the standard threshold-based blacklist approach: one reduces false positives by comparing live network traffic to spamtrap hits, and the other safely aggregates bad sources into bad neighborhoods. Combined, these techniques improved the false negative rate by 4-5x for false positive rates below 0.5% and 2x for false positive rates above 0.5%.

#### 6.1 Ethical Considerations for Spam Blacklist Evaluation

Internet research raises ethical issues, particularly regarding beneficence, which involves maximizing benefits while minimizing harm. Spam impacts user productivity, consumes resources, and serves as an infection vector for malicious software. Our work aims to reduce this burden. The primary risk to subjects is the loss of privacy. To minimize this, we did not publish any personally identifiable information and restricted data collection to email source and destination servers. We hand-classified the contents of four subjects' inboxes with their explicit permission and classified emails sent to our spamtrap, where no legitimate users reside. No emails were modified during the study.

#### 6.2 Limitations

While effective, our work has several limitations and opportunities for future research. First, the speculative aggregation technique is preemptive, which may be unacceptable for blocking traffic from hosts preemptively. Second, like other reputation-based systems, our blacklist generation system is vulnerable to attacks that manipulate source reputations. The dynamic threshold technique provides some protection but is still vulnerable to attackers increasing the reputation of sources by sending many emails to legitimate users. A system that counts the number of unique users to which a source sends mail may be more resilient. Third, blacklist providers often disclaim responsibility for blocking emails, but our proposed deployment model requires either publishing raw spamtrap data to subscribers or local network traffic statistics to blacklist providers, each with its own limitations. Finally, in our current implementation, we only extracted the first "Received" header in email messages, limiting our ability to blacklist sources beyond the first one. Future work will address these limitations.

### 7 Acknowledgements

We thank the anonymous reviewers for their comments and extend special thanks to Thorsten Holz, our shepherd, for his efforts in significantly improving this paper. This work was supported in part by the Department of Homeland Security (DHS) under contract numbers NBCHC080037, NBCHC060090, and FA8750-08-2-0147, the National Science Foundation (NSF) under contract numbers CNS 091639, CNS 08311174, CNS 0627445, and CNS 0751116, and the Department of the Navy under contract N000.14-09-1-1042.

### References

[1] Not just another bogus list. http://njabl.org.
[2] Pyzor. http://pyzor.sourceforge.net/.
[3] Sorbs DNSBL. http://www.sorbs.net.
[4] SpamCop.net - Beware of cheap imitations. http://www.spamcop.net/.
[5] The SpamHaus Project. http://www.spamhaus.org.
[6] Vipul’s razor. http://razor.sourceforge.net/.
[7] What is the SpamCop Blocking List (SCBL)? http://spamcop.net/fom-serve/cache/297.html.
[8] R. Beverly and K. Sollins. Exploiting transport-level characteristics of spam. In Proceedings of the Fifth Conference on Email and Anti-Spam (CEAS), Aug. 2008.
[9] D. Dittrich, M. D. Bailey, and S. Dietrich. Towards community standards for ethical behavior in computer security research. Technical Report 2009-01, Stevens Institute of Technology, Hoboken, NJ, USA, April 2009.
[10] H. Drucker, V. Vapnik, and D. Wu. Support vector machines for spam categorization. IEEE Transactions on Neural Networks, 10(5):1048–1054, 1999.
[11] S. Hao, N. A. Syed, N. Feamster, A. Gray, and S. Krasser. Detecting Spammers with SNARE: Spatio-temporal Network-level Automatic Reputation Engine. In Usenix Security ’09, Montreal, Canada, August 2009.
[12] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M. Voelker, V. Paxson, and S. Savage. Spamalytics: an empirical analysis of spam marketing conversion. In CCS ’08: Proceedings of the 15th ACM conference on Computer and communications security, pages 3–14, New York, NY, USA, 2008. ACM.
[13] J. Mason. Filtering Spam with SpamAssassin. SAGE-IE meeting presentation, 2002.
[14] McAfee and I. International. The carbon footprint of email. http://newsroom.mcafee.com/images/spam report. 10039/carbonfootprint2009.pdf, April 2009.
[15] T. Micro. Most abused infection vector. http://blog.trendmicro.com/most-abused-infection-vector/, December 2008.
[16] B. Nelson, M. Barreno, F. J. Chi, A. D. Joseph, B. I. P. Rubinstein, U. Saini, C. Sutton, J. D. Tygar, and K. Xia. Exploiting machine learning to subvert your spam filter. In First USENIX Workshop on Large-Scale Exploits and Emergent Threats, April 2008.
[17] M. A. Rajab, J. Zarfoss, F. Monrose, and A. Terzis. A multi-faceted approach to understanding the botnet phenomenon. In IMC ’06: Proceedings of the 6th ACM SIGCOMM on Internet measurement, pages 41–52, New York, NY, USA, 2006. ACM Press.
[18] A. Ramachandran, D. Dagon, and N. Feamster. Can DNS-Based Blacklists Keep Up with Bots? In Proceedings of the Third Conference on Email and Anti-Spam (CEAS 2006), July 2006.
[19] A. Ramachandran and N. Feamster. Understanding the network-level behavior of spammers. In SIGCOMM ’06: Conference on Applications, technologies, architectures, and protocols for computer communications, pages 291–302, New York, NY, USA, 2006. ACM Press.
[20] A. Ramachandran, N. Feamster, and S. Vempala. Filtering spam with behavioral blacklisting. In CCS ’07: Proceedings of the 14th ACM conference on Computer and communications security, pages 342–351, New York, NY, USA, 2007. ACM.
[21] N. Research and KnowledgeStorm. Nucleus research: Spam costing US businesses $712 per employee each year. http://nucleusresearch.com/news/press-releases/nucleus-research-spam-costing-us-businesses-712-per-employee-each-year/, April 2007.
[22] M. Sahami, S. Dumais, D. Heckerman, and E. Horvitz. A Bayesian approach to filtering junk e-mail. In AAAI-98 Workshop on Learning for Text Categorization, pages 55–62, 1998.
[23] S. Sinha, M. Bailey, and F. Jahanian. Shades Of Grey: On the effectiveness of reputation-based blacklists. In International Conference on Malicious and Unwanted Software (Malware 2008), October 2008.
[24] B. Stone. Spam back to 94% of all e-mail, March 2009. http://bits.blogs.nytimes.com/2009/03/31/spam-back-to-94-of-all-e-mail/.
[25] Unspam Technologies. Project Honey Pot. http://projecthoneypot.org, 2008.
[26] S. Venkataraman, S. Sen, O. Spatscheck, P. Haffner, and D. Song. Exploiting network structure for proactive spam mitigation. In Proceedings of 16th USENIX Security Symposium, pages 1–18, Berkeley, CA, USA, 2007. USENIX Association.
[27] G. L. Wittel and S. F. Wu. On attacking statistical spam filters. In Proceedings of the First Conference on Email and Anti-Spam (CEAS), 2004. Available: http://www.ceas.cc/papers-2004/170.pdf.
[28] R. Wojtczuk. libnids, June 2004.
[29] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt, and T. Wobber. How dynamic are IP addresses? In SIGCOMM ’07: Conference on Applications, technologies, architectures, and protocols for computer communications, pages 301–312, New York, USA, 2007.
[30] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and I. Osipkov. Spamming botnets: signatures and characteristics. SIGCOMM Comput. Commun. Rev., 38(4):171–182, 2008.
[31] J. Zhang, P. Porras, and J. Ullrich. Highly predictive blacklisting. In 17th USENIX Security Symposium (USENIX Security ’08), July-August 2008.