### Applicability to Real-World Browsing Environments at Scale

K-fingerprinting demonstrates high accuracy even when an attacker trains on a small fraction of the total data. Unreliable data within this small fraction can be filtered and removed before launching the attack, leading to better results. This indicates that long-term website fingerprinting attacks on targeted clients pose a realistic threat.

### References

1. **Alexa - The Web Information Company**  
   [Accessed August 2015]  
   URL: <http://alexa.com>

2. **Leo Breiman - Random Forests**  
   [Accessed July 2015]  
   URL: <https://www.stat.berkeley.edu/~breiman/RandomForests/>

3. **The Nielsen Company**  
   [Accessed July 2015]  
   URL: <http://www.nielsen.com/us/en/insights/news/2010/led-by-facebook-twitter-global-time-spent-on-social-media-sites-up-82-year-over-year.html>

4. **Tor Proposal 254**  
   [Accessed November 2015]  
   URL: <https://gitweb.torproject.org/torspec.git/tree/proposals/254-padding-negotiation.txt>

5. **George Dean Bissias, Marc Liberatore, David Jensen, and Brian Neil Levine**  
   "Privacy Vulnerabilities in Encrypted HTTP Streams"  
   In Proceedings of the 5th International Conference on Privacy Enhancing Technologies, pages 1–11, 2006.

6. **Leo Breiman**  
   "Random Forests"  
   Mach. Learn., 45(1):5–32, 2001.

7. **Xiang Cai, Xin Cheng Zhang, Brijesh Joshi, and Rob Johnson**  
   "Touching from a Distance: Website Fingerprinting Attacks and Defenses"  
   In ACM Conference on Computer and Communications Security, pages 605–616, 2012.

8. **Xiang Cai, Rishab Nithyanand, and Rob Johnson**  
   "CS-BuFLO: A Congestion Sensitive Website Fingerprinting Defense"  
   In Proceedings of the 13th Workshop on Privacy in the Electronic Society, pages 121–130, 2014.

9. **Shuo Chen, Rui Wang, XiaoFeng Wang, and Kehuan Zhang**  
   "Side-Channel Leaks in Web Applications: A Reality Today, a Challenge Tomorrow"  
   In Proceedings of the 2010 IEEE Symposium on Security and Privacy, pages 191–206, 2010.

10. **Heyning Cheng, Heyning Cheng, and Ron Avnur**  
    "Traffic Analysis of SSL Encrypted Web Browsing", 1998.

11. **Roger Dingledine, Nick Mathewson, and Paul F. Syverson**  
    "Tor: The Second-Generation Onion Router"  
    In Proceedings of the 13th USENIX Security Symposium, pages 303–320, 2004.

12. **Kevin P. Dyer, Scott E. Coull, Thomas Ristenpart, and Thomas Shrimpton**  
    "Peek-a-Boo, I Still See You: Why Efficient Traffic Analysis Countermeasures Fail"  
    In Proceedings of the 2012 IEEE Symposium on Security and Privacy, pages 332–346, 2012.

13. **Jerome H. Friedman**  
    "Greedy Function Approximation: A Gradient Boosting Machine"  
    Annals of Statistics, 29:1189–1232, 2000.

14. **Pall Oskar Gislason, Jon Atli Benediktsson, and Johannes R. Sveinsson**  
    "Random Forests for Land Cover Classification"  
    Pattern Recogn. Lett., 27(4):294–300, March 2006.

15. **Xiaodan Gu, Ming Yang, and Junzhou Luo**  
    "A Novel Website Fingerprinting Attack against Multi-Tab Browsing Behavior"  
    In 19th IEEE International Conference on Computer Supported Cooperative Work in Design, CSCWD, pages 234–239, 2015.

16. **Dominik Herrmann, Rolf Wendolsky, and Hannes Federrath**  
    "Website Fingerprinting: Attacking Popular Privacy Enhancing Technologies with the Multinomial Naive-Bayes Classifier"  
    In Proceedings of the 2009 ACM Workshop on Cloud Computing Security, pages 31–42, 2009.

17. **Marc Juárez, Sadia Afroz, Gunes Acar, Claudia Díaz, and Rachel Greenstadt**  
    "A Critical Evaluation of Website Fingerprinting Attacks"  
    In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 263–274, 2014.

18. **Marc Juárez, Mohsen Imani, Mike Perry, Claudia Díaz, and Matthew Wright**  
    "WTF-PAD: Toward an Efficient Website Fingerprinting Defense for Tor"  
    CoRR, abs/1512.00524, 2015.  
    URL: <http://arxiv.org/abs/1512.00524>

19. **Albert Kwon, Mashael AlSabah, David Lazar, Marc Dacier, and Srinivas Devadas**  
    "Circuit Fingerprinting Attacks: Passive Deanonymization of Tor Hidden Services"  
    In 24th USENIX Security Symposium, pages 287–302, 2015.

20. **A. Liaw and M. Wiener**  
    "Classification and Regression by randomForest"  
    R News: The Newsletter of the R Project, 2(3):18–22, 2002.

21. **Marc Liberatore and Brian Neil Levine**  
    "Inferring the Source of Encrypted HTTP Connections"  
    In Proceedings of the 13th ACM Conference on Computer and Communications Security, pages 255–263, 2006.

22. **Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou**  
    "Isolation-Based Anomaly Detection"  
    ACM Trans. Knowl. Discov. Data, 6(1):3:1–3:39, March 2012.

23. **Liming Lu, Ee-Chien Chang, and Mun Choon Chan**  
    "Website Fingerprinting and Identification Using Ordered Feature Sequences"  
    In Proceedings of the 15th European Conference on Research in Computer Security, pages 199–214, 2010.

24. **Xiapu Luo, Peng Zhou, Edmond W. W. Chan, Wenke Lee, Rocky K. C. Chang, and Roberto Perdisci**  
    "HTTPOS: Sealing Information Leaks with Browser-Side Obfuscation of Encrypted Flows"  
    In Proc. Network and Distributed Systems Symposium (NDSS), 2011.

25. **Rishab Nithyanand, Xiang Cai, and Rob Johnson**  
    "Glove: A Bespoke Website Fingerprinting Defense"  
    In Proceedings of the 13th Workshop on Privacy in the Electronic Society, pages 131–134, 2014.

26. **A. Stolerman, M. V. Ryan, P. Brennan, P. Juola, J. I. Noecker Jr, and R. Greenstadt**  
    "A Dataset for Active Linguistic Authentication"  
    In IFIP WG 11.9 International Conference on Digital Forensics, 2013.

27. **Andriy Panchenko, Lukas Niessen, Andreas Zinnen, and Thomas Engel**  
    "Website Fingerprinting in Onion Routing Based Anonymization Networks"  
    In Proceedings of the 10th Annual ACM Workshop on Privacy in the Electronic Society, WPES, pages 103–114, 2011.

28. **Andriy Panchenko, Fabian Lanze, Andreas Zinnen, Martin Henze, Jan Pennekamp, Klaus Wehrle, and Thomas Engel**  
    "Website Fingerprinting at Internet Scale"  
    In Network and Distributed System Security Symposium, 2016.

29. **Mike Perry**  
    "A Critique of Website Traffic Fingerprinting Attacks"  
    [Accessed June 2015]  
    URL: <https://blog.torproject.org/blog/critique-website-traffic-fingerprinting-attacks>

30. **Mike Perry**  
    "Experimental Defense Website Traffic Fingerprinting"  
    [Accessed June 2015]  
    URL: <https://blog.torproject.org/blog/experimental-defense-website-traffic-fingerprinting>

31. **Vitaly Shmatikov and Ming-Hsiu Wang**  
    "Timing Analysis in Low-Latency Mix Networks: Attacks and Defenses"  
    In ESORICS, 2006.

32. **Qixiang Sun, Daniel R. Simon, Yi-Min Wang, Wilf Russell, Venkata N. Padmanabhan, and Lili Qiu**  
    "Statistical Identification of Encrypted Web Browsing Traffic"  
    In Proceedings of the 2002 IEEE Symposium on Security and Privacy, pages 19–, 2002.

33. **Vladimir Svetnik, Andy Liaw, Christopher Tong, J. Christopher Culberson, Robert P. Sheridan, and Bradley P. Feuston**  
    "Random Forest: A Classification and Regression Tool for Compound Classification and QSAR Modeling"  
    Journal of Chemical Information and Computer Sciences, 43(6):1947–1958, 2003.

### Appendix

#### A. Total Feature Importance

Figure 12: Feature importance score for all 150 features in order. The table gives the description for the 20 least important features.

#### B. Closed World Error Rates

Figure 13 shows the confusion matrix in our closed-world setting, indicating 49 misclassifications out of 550. Some persistent misclassification patterns of web pages appear, for example, web page 54 is correctly classified four times but misclassified as web page 0 six times. The misclassification rate in Figure 13 is 0.09, which is the average error rate across all web pages.

Figure 13 also shows that the classification error is not uniform across all web pages. Some pages are misclassified many times and confused with many others, while others are never misclassified. An attacker can leverage this information to estimate the misclassification rate of each web page instead of using the global average misclassification rate.

As in Section 10, an attacker can use their training set of web pages to estimate the misclassification rate of each web page by splitting the training set into a smaller training set and validation set. Since both sets are from the original training set, the attacker has access to the true labels. The attacker then computes the misclassification rate of each web page, which they can use as an estimation for the misclassification rate when training on the entire training set and testing on new traffic instances.

Figures 14 and 15 show the global misclassification rate for a varying number of monitored pages. Monitored pages are first ordered in terms of the misclassification rate they have, ordered from smallest to largest. From Figure 14, using the Wang et al. dataset, we see that if the attacker considers only the top 50% of web pages in terms of per-page misclassification rate, the true global misclassification rate and the global misclassification rate estimated by the attacker drop by over 70%. Similarly, from Figure 15, using DSNorm, if the attacker considers only the top 50% of web pages in terms of per-page misclassification rate, the true global misclassification rate and the global misclassification rate estimated by the attacker drop by over 80%. This allows an attacker to train on monitored pages and then cull the pages that have too high an error rate, allowing for more confidence in the classification of the rest of the monitored pages.

The gap between the attacker’s estimate and the misclassification rate of the test set is largely due to the size of the dataset. Figure 14 has a smaller error of estimate than Figure 15 because the Wang et al. dataset has 60 instances per monitored page, compared to DSNorm, which has 20 instances per monitored page. In practice, an attacker cannot expect perfect alignment; they are generated from two different sets of data, the training and training + test set. Nevertheless, the attacker can expect this difference to decrease with the collection of more training instances.

#### C. Attack on Larger World Size of DSNorm

We run k-fingerprinting on DSNorm with the same number of monitored sites but increase the number of unmonitored sites to 17,000. We evaluate when we have both time and size features available.

Figure 16 shows the results of k-fingerprinting while varying the number of fingerprints (k) used for classification, from between 1 and 10, for various experiments trained with different numbers of unmonitored pages. We see that the attack results are comparable to the attack on 7,000 unmonitored pages, meaning there is no degradation in attack accuracy when we increase the world size by 10,000 web pages. Training on approximately 30% of the 7,000 unmonitored web pages, k-fingerprinting gives a True Positive Rate (TPR) of over 0.90 and a False Positive Rate (FPR) of 0.01 for k=1. Training on approximately 30% of the 17,000 unmonitored web pages, k-fingerprinting gives a TPR of 0.90 and an FPR of 0.006 for k=1.

The fraction of unmonitored pages that were incorrectly classified as a monitored page decreased as we increased our world size. In other words, out of 12,000 unmonitored pages, only 72 were classified as a monitored page, with this figure dropping to 24 if we use k=10 for classification. This provides a strong indication that k-fingerprinting can scale to a real-world attack in which a client is free to browse the entire internet, with no decrease in attack accuracy.

Figure 17 shows the out-of-bag score as we change the number of monitored pages we train. We found that training on any more than a third of the data gives roughly the same accuracy.