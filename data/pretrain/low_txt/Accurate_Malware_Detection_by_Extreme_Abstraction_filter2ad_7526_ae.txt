### Introduction

To the best of our knowledge, there is no prior work on the intentional abstraction of the operating system for malware analysis. In [3], the authors use an abstraction of program behavior, but it is derived from a concrete operating system. Similarly, in [25], the authors describe their method as "abstracting the API calls," but in practice, they use the sequence of API calls as an abstraction of behavior observed on a concrete system. The term "abstraction" is used in this sense in [11] as well. In [24], malware detection is performed using abstract interpretation, an analysis technique that employs successive sound approximations of the semantics of computer programs. This approach is distinct from our loose and unsound approximations. Additionally, the work in [24] uses a synthetic programming language and does not reference the operating system.

### 4.3 Malware Classification

Malware classification using machine learning methods is an active research area. The research can be broadly categorized into two types: works based on features extracted from static binary files, and models that employ sample execution within a sandbox or another isolation environment.

#### Static Analysis

In [27], the authors extract various features from the PE header and content to feed into a machine learning model. Conversely, in [26], the authors feed the raw bytes of the file into the machine learning model. In contrast, we emulate the sample's execution in an abstract environment and gather information about its behavior. This allows our system to overcome packed and obfuscated executables, which may pose a challenge to models based on static file features. The architecture in [10] includes a decompressor, which unpacks PE files compressed by tools like UPX. However, this limits the system's ability to correctly classify malware or benign samples compressed with proprietary packers and obfuscators, for which no standard unpacker is available. Our system, on the other hand, emulates the sample execution through the unpacking code, reaching the actual behavior of the original executable (whether benign or malicious), and thus extracts enough information for accurate classification by the machine learning model.

#### Dynamic Analysis

Several works have suggested feeding logs of API calls collected by a sandbox executing the sample into a machine learning model. For example, [6] uses 3-grams of API calls produced by a proprietary sandbox. In [22], the authors use Echo State Networks (ESNs) and Recurrent Neural Networks (RNNs) fed from a stream of high-level events gathered from samples analyzed in a proprietary anti-malware engine. Similar approaches are used for classifying malware into families. For instance, in [7] and [15], the authors gather sample logs of API calls using the Cuckoo sandbox and then train a deep learning model to classify each sample into its malware family.

In contrast, we use features extracted from the logs of an extremely abstract OS. Unlike the above works, which use an API call log of a single execution of each sample, our system uses multiple paths extracted from an extremely abstract analysis and aggregates information from these paths to form a single feature vector fed into the machine learning model. This allows our system to accurately detect malware samples that hide their malicious behavior in some execution paths but not in others. Furthermore, we use a funnel-based approach that saves runtime and provides more accurate classification.

### 5 Future Work

While our results are promising, every fraction of a percentage point is crucial when dealing with tens or hundreds of thousands of samples per day. Future work will include completing training for layers 3 and beyond of the funnel to measure the effectiveness of layers based on an increasing number of paths and/or longer timeouts. We also plan to augment the training set with packed versions of every sample and measure whether this improves our detection rate. Additionally, we intend to explore feature clustering of API functions based on their natural language descriptions. Finally, we have started exploring the use of deep learning for classifying sequences of events recorded during the execution of a sample and have found bidirectional LSTM to be very promising when applied to sequences of informative, suspicious, and malicious features. We plan to explore how to leverage this in a multiple path scenario.

### 6 Conclusion

We have presented a novel approach to malware detection based on extreme abstraction of the operating system, which proves to be highly effective in distinguishing between benign and malicious samples. We use lightweight symbols, akin to taint, to drive symbolic execution and time models as a lighter alternative to exploring multiple paths. By exploring multiple paths in a system that only approximates real behavior, we discover behavior that would often be difficult to elicit using the real system. By aggregating features from multiple paths into a single feature vector that considers differences between the paths, we achieve a higher True Positive Rate (TPR) compared to a single path analysis. Using a funnel-like configuration of classifiers, we achieve an even higher TPR while reducing the average runtime from four minutes (one minute per path) to just over one minute.

We have described TAMALES, a malware detection system based on these ideas, in detail, and presented machine learning results on a 330K sample set (230K training, 100K test) showing a False Positive Rate (FPR) of 0.10% and a TPR of 99.11%. We have also provided experimental evidence showing that we are learning more than just packed/unpacked or obfuscated/unobfuscated code, and that extreme abstraction can be useful for family classification as well.

### Acknowledgments

We thank the following individuals who contributed to or supported the project in various ways: Oshri Adler, Sandy Bird, Lior Keshet, Amit Klein, Moshe Levinger, Shmulik Regev, Tamer Salman, and Maksim Shudrak. The authors acknowledge the IBM Research Cognitive Computing Cluster service for providing resources that have contributed to the research results reported in this paper.

### References

[1] Sebastian Banescu, Christian S. Collberg, Vijay Ganesh, Zack Newsham, and Alexander Pretschner. 2016. Code obfuscation against symbolic execution attacks. In Proceedings of the 32nd Annual Conference on Computer Security Applications, ACSAC 2016, Los Angeles, CA, USA, December 5-9, 2016. ACM, New York, NY, USA, 189–200.

[2] Clark W. Barrett, Roberto Sebastiani, Sanjit A. Seshia, and Cesare Tinelli. 2009. Satisfiability Modulo Theories. In Handbook of Satisfiability. IOS Press, Amsterdam, 825–885.

[3] Philippe Beaucamps, Isabelle Gnaedig, and Jean-Yves Marion. 2010. Behavior Abstraction in Malware Analysis. In Runtime Verification, Howard Barringer, Ylies Falcone, Bernd Finkbeiner, Klaus Havelund, Insup Lee, Gordon Pace, Grigore Roşu, Oleg Sokolsky, and Nikolai Tillmann (Eds.). Springer, Berlin Heidelberg New York, 168–182.

[4] Leo Breiman. 2001. Random Forests. Machine Learning 45, 1 (2001), 5–32.

[5] L Breiman, JH Friedman, RA Olshen, and CJ Stone. 1984. Classification and Regression Trees. Wadsworth & Brooks, Monterey, CA.

[6] George E Dahl, Jack W Stokes, Li Deng, and Dong Yu. 2013. Large-scale malware classification using random projections and neural networks. In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 3422–3426.

[7] Omid E David and Nathan S Netanyahu. 2015. DeepSign: Deep learning for automatic malware signature generation and classification. In Neural Networks (IJCNN), 2015 International Joint Conference on. IEEE, 1–8.

[8] Martin Davis and Hilary Putnam. 1960. A Computing Procedure for Quantification Theory. J. ACM 7, 3 (1960), 201–215.

[9] Serge Gaspers and Toby Walsh (Eds.). 2017. Theory and Applications of Satisfiability Testing - SAT 2017 - 20th International Conference, Melbourne, VIC, Australia, August 28 - September 1, 2017, Proceedings. Lecture Notes in Computer Science, Vol. 10491. Springer.

[10] William Hardy, Lingwei Chen, Shifu Hou, Yanfang Ye, and Xin Li. 2016. DL4MD: A deep learning framework for intelligent malware detection. In Proceedings of the International Conference on Data Mining (DMIN). The Steering Committee of The World Congress in Computer Science, Computer Engineering and Applied Computing (WorldComp), 61.

[11] Grégoire Jacob, Hervé Debar, and Eric Filiol. 2009. Malware Behavioral Detection by Attribute-Automata Using Abstraction from Platform and Language. In Recent Advances in Intrusion Detection, 12th International Symposium, RAID 2009, Saint-Malo, France, September 23-25, 2009. Proceedings (Lecture Notes in Computer Science), Vol. 5758. Springer, Berlin Heidelberg New York, 81–100.

[12] John T Kent. 1983. Information gain and a general measure of correlation. Biometrika 70, 1 (1983), 163–173.

[13] James C. King. 1976. Symbolic Execution and Program Testing. Commun. ACM 19, 7 (July 1976), 385–394.

[14] Clemens Kolbitsch, Benjamin Livshits, Benjamin G. Zorn, and Christian Seifert. 2012. Rozzle: De-cloaking Internet Malware. In IEEE Symposium on Security and Privacy, SP 2012, 21-23 May 2012, San Francisco, California, USA. IEEE Computer Society, Washington, DC, USA, 443–457.

[15] Bojan Kolosnjaji, Apostolis Zarras, George Webster, and Claudia Eckert. 2016. Deep learning for classification of malware system call sequences. In Australasian Joint Conference on Artificial Intelligence. Springer, 137–149.

[16] Christopher Kruegel. 2014. Full system emulation: Achieving successful automated dynamic analysis of evasive malware. (August 2014).

[17] John Leitch. [n. d.]. Process hollowing. www.autosectools.com/process-hollowing.pdf. ([n. d.]).

[18] Tamas K. Lengyel, Steve Maresca, Bryan D. Payne, George D. Webster, Sebastian Vogl, and Aggelos Kiayias. 2014. Scalability, Fidelity and Stealth in the DRAKVUF Dynamic Malware Analysis System. In Proceedings of the 30th Annual Computer Security Applications Conference (ACSAC ’14). ACM, New York, NY, USA, 386–395.

[19] Andreas Moser, Christopher Kruegel, and Engin Kirda. 2007. Limits of Static Analysis for Malware Detection. In 23rd Annual Computer Security Applications Conference (ACSAC 2007), December 10-14, 2007, Miami Beach, Florida, USA. IEEE Computer Society, Washington, DC, USA, 421–430.

[20] Andreas Moser, Christopher Krügel, and Engin Kirda. 2007. Exploring Multiple Execution Paths for Malware Analysis. In 2007 IEEE Symposium on Security and Privacy (S&P 2007), 20-23 May 2007, Oakland, California, USA. IEEE Computer Society, Washington, DC, USA, 231–245.

[21] Robert Moskovitch, Clint Feher, Nir Tzachar, Eugene Berger, Marina Gitelman, Shlomi Dolev, and Yuval Elovici. 2008. Unknown Malcode Detection Using OP-CODE Representation. In Intelligence and Security Informatics, First European Conference, EuroISI 2008, Esbjerg, Denmark, December 3-5, 2008. Proceedings (Lecture Notes in Computer Science), Vol. 5376. Springer, Berlin Heidelberg New York, 204–215.

[22] Razvan Pascanu, Jack W Stokes, Hermineh Sanossian, Mady Marinescu, and Anil Thomas. 2015. Malware classification with recurrent networks. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE, 1916–1920.

[23] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12 (2011), 2825–2830.

[24] Mila Dalla Preda. 2007. Code Obfuscation and Malware Detection by Abstract Interpretation. Ph.D. Dissertation. Università degli Studi di Verona, Dipartimento di Informatica.

[25] Yong Qiao, Yuexiang Yang, Lin Ji, and Jie He. 2013. Analyzing Malware by Abstracting the Frequent Itemsets in API Call Sequences. In 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2013 / 11th IEEE International Symposium on Parallel and Distributed Processing with Applications, ISPA-13 / 12th IEEE International Conference on Ubiquitous Computing and Communications, IUCC-2013, Melbourne, Australia, July 16-18, 2013. IEEE Computer Society, Washington, DC, USA, 265–270.

[26] Edward Ra, Jon Barker, Jared Sylvester, Robert Brandon, Bryan Catanzaro, and Charles Nicholas. 2017. Malware Detection by Eating a Whole EXE. arXiv preprint arXiv:1710.09435 (2017).

[27] Joshua Saxe and Konstantin Berlin. 2015. Deep neural network based malware detection using two dimensional binary program features. In Malicious and Unwanted Software (MALWARE), 2015 10th International Conference on. IEEE, 11–20.

[28] Edward J. Schwartz, Thanassis Avgerinos, and David Brumley. 2010. All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution (but Might Have Been Afraid to Ask). In Proceedings of the 2010 IEEE Symposium on Security and Privacy (SP ’10). IEEE Computer Society, Washington, DC, USA, 317–331.

[29] Marcos Sebastián, Richard Rivera, Platon Kotzias, and Juan Caballero. 2016. AV-Class: A Tool for Massive Malware Labeling. In Research in Attacks, Intrusions, and Defenses - 19th International Symposium, RAID 2016, Paris, France, September 19-21, 2016, Proceedings (Lecture Notes in Computer Science), Vol. 9854. Springer, Berlin Heidelberg New York, 230–253.

[30] Michael Sikorski and Andrew Honig. 2012. Practical Malware Analysis: The Hands-On Guide to Dissecting Malicious Software (1st ed.). No Starch Press, San Francisco, CA, USA.

[31] Themida [n. d.]. www.oreans.com/themida.php. ([n. d.]).

[32] UPX [n. d.]. upx.github.io. ([n. d.]).

[33] VirusSign [n. d.]. www.virussign.com. ([n. d.]).

[34] VirusTotal [n. d.]. www.virustotal.com. ([n. d.]).

[35] VMProtect [n. d.]. vmpsoft.com. ([n. d.]).

[36] Kilian Q. Weinberger, Anirban Dasgupta, John Langford, Alexander J. Smola, and Josh Attenberg. 2009. Feature hashing for large scale multitask learning. In Proceedings of the 26th Annual International Conference on Machine Learning, ICML 2009, Montreal, Quebec, Canada, June 14-18, 2009. ACM, New York, NY, USA, 1113–1120.

[37] Jeffrey Wilhelm and Tzi-cker Chiueh. 2007. A Forced Sampled Execution Approach to Kernel Rootkit Identification. In Recent Advances in Intrusion Detection, 10th International Symposium, RAID 2007, Gold Goast, Australia, September 5-7, 2007, Proceedings (Lecture Notes in Computer Science), Vol. 4637. Springer, Berlin Heidelberg New York, 219–235.

[38] Babak Yadegari and Saumya Debray. 2015. Symbolic Execution of Obfuscated Code. In Proceedings of the 22Nd ACM SIGSAC Conference on Computer and Communications Security (CCS ’15). ACM, New York, NY, USA, 732–744.