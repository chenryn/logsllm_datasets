### Figure 2: Results of Automatically Analyzing the PIN Integrity Check with Respect to Multiple Runs of an Adaptive Attacker

We conclude that the distribution of the PINs is \(\gamma\)-close to the uniform distribution \(u\), i.e., \(p_Y \approx u\).

Consider again the PIN integrity check program \(P\) from Section 5.1, generalized to 4 PINs, where:
- \(I_P = \{0, \ldots, 9\}^4\)
- \(F_P = \{0, 1\}\)
- \(P(s_1 s_2 s_3 s_4) = \bigwedge_{i=1}^4 (s_i \oplus m_i < 10)\)

Theorem 3 provides the following formula to bound \(H(D_{p_Y} | P_{p_Y})\):
\[ H(D_{p_Y} | P_{p_Y}) \leq \gamma \cdot H(D_u) - \frac{1}{\gamma} \cdot H(P_u) + \log_2 \left( \gamma \gamma + \frac{1}{\gamma}! \right) \]

Setting \(m = FFFF\), we obtain the following upper bound:
\[ H(D_{p_Y} | P_{p_Y}) \leq \gamma \cdot \log_2 10^4 + \log_2 \left( \gamma \gamma + \frac{1}{\gamma}! \right) \]
\[ \approx 13.1654 \]

A lower bound of \(H(D_{p_Y} | P_{p_Y}) \geq 13.0664\) follows along the same lines.

The small difference between the upper and lower bounds indicates that the uniform analysis is (almost) precise for PINs generated according to the Interbank algorithm. We compare this result with the analysis of PINs generated using decimalization tables presented in Section 5.2, where for 4-digit PINs, the remaining uncertainty was 12.9631 bits. The difference in remaining uncertainties highlights the security gain from using a better (i.e., less skewed) PIN generation algorithm.

### 6. Related Work

Denning was the first to quantify information flow in terms of the reduction in uncertainty about a program variable [14]. Millen [28] and Gray [16] used information theory to derive bounds on the transmission of information between processes in multi-user systems. Lowe [24] showed that the channel capacity of a program can be over-approximated by the number of possible behaviors, which corresponds to the maximal leakage with respect to any input distribution.

Clark, Hunt, and Malacaria [10] connected equivalence relations to quantitative information flow and proposed the first type system for statically deriving quantitative bounds on the information that a program leaks [11]. Their analysis assumes bounds on the entropy of the input variables and delivers corresponding bounds for the leakage. For loops with high guards, the analysis always reports complete leakage of the guard.

Malacaria [25] characterized the leakage of loops in terms of the loop’s output and the number of iterations. Mu and Clark [30] proposed a precise, automatic QIF based on a distribution transformer semantics, which can handle non-uniform input distributions. Their approach relies on an explicit representation of the probability distribution transformed by the program, which can be challenging for programs with large state spaces. This issue is mitigated by an interval-based abstraction [29], which splits a totally ordered domain into intervals, each assumed to be uniformly distributed. In our approach, the probability distribution is represented in terms of preimages of a generating program, offering a symbolic treatment of large state spaces.

Köpf and Basin [20] computed partitions on the secret input that represent what an attacker can learn in an adaptive attack. Backes, Köpf, and Rybalchenko [2] determined the partitions corresponding to the information (with respect to a non-adaptive attacker) that a program leaks by computing weakest preconditions. Both approaches rely on counting the number and sizes of preimages to quantify the remaining uncertainty about the input with respect to uniform distributions. When used in conjunction with these approaches, the ideas presented in this paper can weaken the requirement of a uniform distribution.

Köpf and Rybalchenko [22] proposed approximation and randomization techniques to approximate the remaining uncertainty about a program’s inputs for programs with unbounded loops. Their approach approximates the sizes of blocks without complete enumeration and delivers bounds with respect to uniformly distributed inputs. As shown, the reduction presented in this paper can extend these techniques to programs with non-uniform input distributions.

McCamant and Ernst proposed a dynamic taint analysis for quantifying information flow [27]. Their method does not assume a particular input distribution and provides over-approximations of the leaked information along a particular path but does not yield guarantees for all program paths, which is crucial for security analysis. Newsome, McCamant, and Song [31] used feasible outputs along single program paths as bounds for channel capacity and applied heuristics to approximate upper bounds on the number of reachable states of a program.

Chatzikokolakis, Chothia, and Guha [7] used sampling to build a statistical system model and computed the channel capacity, i.e., the maximum leakage with respect to all possible input distributions. DiPierro, Hankin, and Wiklicky [33] considered probabilistic processes with given input distributions and used the distance of the produced output distributions to quantify information flow.

Clarkson, Myers, and Schneider [12] used non-uniform input distributions to model adversaries' beliefs, updating them according to the program semantics, but did not discuss automation or abstraction techniques.

Smith [36] proposed min-entropy as an alternative measure of information flow. Min-entropy gives bounds on the probability of guessing a secret in one attempt, while Shannon-entropy gives bounds on the average number of guesses required to determine a secret. Investigating a reduction from non-uniform to uniform QIF for min-entropy remains future work.

### 7. Conclusions and Future Work

We have addressed the problem of quantifying information flow in programs with respect to non-uniform input distributions. Our contributions include:

1. **Reduction to Uniform Case**: We showed how the problem of non-uniform QIF can be reduced to the uniform case by representing the non-uniform input distribution as a program that receives uniform input and sequentially composing it with the target program. We proved a connection between the information-theoretic characteristics of the target program and its composition with the distribution generator, enabling a precise non-uniform analysis using existing QIF techniques for the uniform case.
   
2. **Robustness to Small Variations**: We demonstrated that the result of a QIF is robust with respect to small variations in the input distribution. This allows us to estimate the information-theoretic characteristics of a program by considering an approximate input distribution, which is useful when the input distribution can only be approximated or when an approximation simplifies the analysis.

3. **Case Study**: We performed a case study illustrating both techniques and demonstrating their practical usefulness.

### Acknowledgments

Boris Köpf's research was partially conducted at MPI-SWS and is supported by FP7-ICT Project NESSoS (256980), FP7-PEOPLE-COFUND Project AMAROUT (229599), and Comunidad de Madrid Program PROMETIDOS-CM (S2009TIC-1465).

### 8. References

[1] American National Standards Institute. Banking - Personal Identification Number Management and Security - Part 1: PIN protection principles and techniques for online PIN verification in ATM & POS systems. ANSI X9.8-1, 2003.

[2] M. Backes, B. Köpf, and A. Rybalchenko. Automatic Discovery and Quantification of Information Leaks. In Proc. 30th IEEE Symposium on Security and Privacy (S& P ’09), pages 141–153. IEEE, 2009.

[3] T. Batu, S. Dasgupta, R. Kumar, and R. Rubinfeld. The complexity of approximating entropy. In Proc. 34th Symposium on the Theory of Computing (STOC ’02), pages 678–687. ACM, 2002.

[4] O. Berkman and O. M. Ostrovsky. The unbearable lightness of pin cracking. In Financial Cryptography (FC ’07), volume 4886 of LNCS, pages 224–238. Springer, 2008.

[5] M. Bond and P. Zieliński. Decimalisation table attacks for PIN cracking. Technical Report UCAM-CL-TR-560, University of Cambridge, Computer Laboratory, Feb. 2003.

[6] C. Cachin. Entropy Measures and Unconditional Security in Cryptography. PhD thesis, ETH Zürich, 1997.

[7] K. Chatzikokolakis, T. Chothia, and A. Guha. Statistical Measurement of Information Leakage. In Proc. 16th Intl. Conf. on Tools and Algorithms for the Construction and Analysis of Systems (TACAS ’10), LNCS 6015, pages 390–404. Springer, 2010.

[8] K. Chatzikokolakis, C. Palamidessi, and P. Panangaden. Anonymity protocols as noisy channels. Inf. Comput., 206(2-4):378–401, 2008.

[9] D. Clark, S. Hunt, and P. Malacaria. Quantitative Analysis of the Leakage of Confidential Data. Electr. Notes Theor. Comput. Sci., 59(3), 2001.

[10] D. Clark, S. Hunt, and P. Malacaria. Quantitative Information Flow, Relations and Polymorphic Types. J. Log. Comput., 18(2):181–199, 2005.

[11] D. Clark, S. Hunt, and P. Malacaria. A static analysis for quantifying information flow in a simple imperative language. Journal of Computer Security, 15(3):321–371, 2007.

[12] M. R. Clarkson, A. C. Myers, and F. B. Schneider. Belief in Information Flow. In Proc. IEEE Computer Security Foundations Workshop (CSFW ’05), pages 31–45. IEEE, 2005.

[13] J. Clulow. The Design and Analysis of Cryptographic Application Programming Interfaces for Security Devices. Master’s thesis, University of Natal, SA, 2003.

[14] D. E. Denning. Cryptography and Data Security. Addison-Wesley, 1982.

[15] C. Gomez, A. Sabharwal, and B. Selman. Chapter 20: Model Counting. In Handbook of Satisfiability: Volume 185 Frontiers in Artificial Intelligence and Applications. IOS Press, 2009.

[16] J. W. Gray. Toward a Mathematical Foundation for Information Flow Security. Journal of Computer Security, 1(3-4):255–294, 1992.

[17] J. Heusser and P. Malacaria. Quantifying information leaks in software. In Proc. Annual Computer Security Applications Conference (ACSAC ’10). ACM, 2010.

[18] IBM Corporation. Interbank PIN generation algorithm. https://publib.boulder.ibm.com/infocenter/zos/v1r9/topic/com.ibm.zos.r9.csfb400/inbkal.htm.

[19] B. Köpf and D. Basin. Automatically Deriving Information-theoretic Bounds for Adaptive Side-channel Attacks. Journal of Computer Security (to appear).

[20] B. Köpf and D. Basin. An Information-Theoretic Model for Adaptive Side-Channel Attacks. In Proc. ACM Conference on Computer and Communications Security (CCS ’07), pages 286–296. ACM, 2007.

[21] B. Köpf and M. Dürmuth. A Provably Secure and Efficient Countermeasure against Timing Attacks. In Proc. 22rd IEEE Computer Security Foundations Symposium (CSF ’09), pages 324–335. IEEE, 2009.

[22] B. Köpf and A. Rybalchenko. Approximation and Randomization for Quantitative Information-Flow Analysis. In Proc. 23rd IEEE Computer Security Foundations Symposium (CSF ’10), pages 3–14. IEEE, 2010.

[23] B. Köpf and G. Smith. Vulnerability Bounds and Leakage Resilience of Blinded Cryptography under Timing Attacks. In Proc. 23rd IEEE Computer Security Foundations Symposium (CSF ’10), pages 44–56. IEEE, 2010.

[24] G. Lowe. Quantifying Information Flow. In Proc. IEEE Computer Security Foundations Workshop (CSFW ’02), pages 18–31. IEEE, 2002.

[25] P. Malacaria. Risk assessment of security threats for looping constructs. Journal of Computer Security, 18(2):191–228, 2010.

[26] J. L. Massey. Guessing and Entropy. In Proc. IEEE International Symposium on Information Theory (ISIT ’94), page 204. IEEE, 1994.

[27] S. McCamant and M. D. Ernst. Quantitative information flow as network flow capacity. In Proc. Conf. on Programming Language Design and Implementation (PLDI ’08), pages 193–205. ACM, 2008.

[28] J. K. Millen. Covert Channel Capacity. In Proc. IEEE Symposium on Security and Privacy (S&P ’87), pages 60–66. IEEE, 1987.

[29] C. Mu and D. Clark. An Interval-based Abstraction for Quantifying Information Flow. ENTCS, 253(3):119–141, 2009.

[30] C. Mu and D. Clark. Quantitative Analysis of Secure Information Flow via Probabilistic Semantics. In Proc. 4th International Conference on Availability, Reliability and Security (ARES ’09), pages 49–57. IEEE, 2009.

[31] J. Newsome, S. McCamant, and D. Song. Measuring Channel Capacity to Distinguish Undue Influence. In Proc. 4th ACM Workshop on Programming Languages and Analysis for Security (PLAS ’09). ACM, 2009.

[32] S. Park, F. Pfenning, and S. Thrun. A Probabilistic Language based upon Sampling Functions. In Proc. ACM Symposium on Principles of Programming Languages (POPL ’05), 2005.

[33] A. D. Pierro, C. Hankin, and H. Wiklicky. Approximate Non-Interference. In Proc. IEEE Computer Security Foundations Workshop (CSFW ’02), pages 3–17. IEEE, 2002.

[34] C. E. Shannon. A Mathematical Theory of Communication. Bell System Technical Journal, 27:379–423 and 623–656, July and October 1948.

[35] C. E. Shannon. Communication theory of secrecy systems. Bell System Technical Journal, 28:656–715, 1949.

[36] G. Smith. On the foundations of quantitative information flow. In Proc. Intl. Conference of Foundations of Software Science and Computation Structures (FoSSaCS ’09), LNCS 5504, pages 288–302. Springer, 2009.

[37] G. Steel. Formal analysis of PIN block attacks. Theoretical Computer Science, 367(1-2):257–270, Nov. 2006.