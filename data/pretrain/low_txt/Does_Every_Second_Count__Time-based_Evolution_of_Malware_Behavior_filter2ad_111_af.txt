### Analyzing Adversarial Software

Malware authors often employ various techniques to evade analysis environments (see Section II-C). This evasion is a concern not only for our sandbox but also for other sandboxes, impacting real-world malware analysis pipelines. In Section V-A, we detail how we attempted to conservatively filter out samples that did not run correctly in our environment. However, it is possible that some malware detected our environment and continued to execute without exhibiting its full malicious behavior.

Our primary contribution is to measure the extent to which malicious code can be analyzed within a given execution time. The generalizability of our results to other sandboxes is crucial. Therefore, both our sandbox and our machine learning classifier are designed to closely mimic the current state of research. Our solution, based on an emulator, is inherently more precise than most VM-based sandboxes, though the specific set of collected events may vary. Additionally, the distribution of malware samples under observation can differ. The dataset we collected for our experiments is the largest ever used for such a fine-grained analysis, and due to our sampling strategy, we are confident that it closely resembles what might have been observed by other commercial sandboxes during the same period.

### Impact on Prior Work

In Section II-A, we highlighted the wide variation in malware analysis execution times in academic studies, ranging from less than 30 seconds to one hour. None of these studies provided a clear rationale for their chosen thresholds, with each paper motivated by different goals that could justify longer or shorter analysis times.

Our results indicate that, in most cases, executing a malware sample for two minutes is sufficient to observe the majority of its behavior. This window also led to the best accuracy for our machine learning classifier. We now examine how these findings could impact studies that executed samples for very short (less than two minutes) or unusually long (more than five minutes) periods. Short execution times may compromise experimental results, while long times likely represent sub-optimal use of computational resources, potentially leading to smaller datasets and reduced statistical significance.

However, the exact time threshold depends on the overhead introduced by the analysis system (in our case, between 1.4x and 3.7x). Moreover, previous experiments, often conducted a decade ago on much slower server infrastructures, make direct comparisons challenging.

For papers with short execution times, the motivations were typically to showcase a prototype or to identify the most suitable classifier based on system or API calls. For the former, the short execution time was not critical, but the results should be interpreted with caution. For the latter, the 30-second timeout raises questions about the validity of the findings.

Papers with long execution times (over five minutes) often aimed at classifying or detecting malware. Our results suggest that such long times were unnecessary. A notable exception is the collection of network packets, where longer execution times can be useful, as shown by Russow et al. [82], who found that only 23.6% of endpoints were discovered in the first five minutes.

### Recommendations

Our primary goal is to provide insights to guide future dynamic malware analysis experiments. We recommend running samples for two minutes (adjusted for system overhead) if the goal is classification or building a behavioral report. This is particularly relevant for industrial analysis environments, which primarily classify unknown programs into malicious or benign categories. We also suggest implementing countermeasures for basic timing attacks, as many malware authors use these to hide malicious behaviors.

Academic researchers should justify their chosen execution thresholds, using our results as a guide. Long execution times (five minutes or more) are often unjustified and can increase overall analysis costs. It is better to analyze more samples for a shorter time rather than reducing the dataset size to accommodate longer executions.

### Key Takeaways

1. **Execution Time Distribution**: Both benign and malicious samples tend to run either for a short amount of time (less than two minutes) or for a long time (over ten minutes). Analysis of older samples would likely show even shorter execution times.
2. **Code Coverage**: While new system calls can be collected regularly, code coverage plateaus quickly, typically within the first minute or two.
3. **Stalling Code**: Common anti-analysis techniques, such as invoking sleep functions, affected only 2-3% of our samples. Countermeasures are easy to implement and can effectively analyze these samples.
4. **Code Exposure**: A single sandbox execution typically exposes between 10% and 40% of a binary's code, varying by family.
5. **Machine Learning Classifier**: The quality and volume of data for classification are mostly concentrated in the first two minutes of execution.

Based on our experiment, we confirm that a two-minute threshold is generally sufficient for analyzing freshly collected malware samples. Security companies should adopt a self-tuning analysis infrastructure, regularly updating parameters based on recent data.

### Acknowledgment

This research was supported by the European Research Council (ERC) under the Horizon 2020 research and innovation program (grant agreement No 771844 – BitCrumbs).

### References

[1] Anubis sandbox. [Online]. Available: https://anubis.iseclab.org
[2] Cuckoo sandbox. [Online]. Available: https://github.com/cuckoosandbox/cuckoo
[3] Hybrid-analysis sandbox. [Online]. Available: https://www.hybrid-analysis.com
[4] Panda – syscalls2 plugin. [Online]. Available: https://github.com/panda-re/panda/tree/master/panda/plugins/syscalls2
[5] Panda plugin win7proc. [Online]. Available: https://github.com/panda-re/panda/tree/panda1/qemu/panda plugins/win7proc
[6] Rekall forensics. [Online]. Available: http://www.rekall-forensic.com
[7] Smda. [Online]. Available: https://github.com/danielplohmann/smda
[8] Virus total. [Online]. Available: https://www.virustotal.com/
[9] Vmray sandbox. [Online]. Available: https://www.vmray.com/
[10] M. Abdelsalam, R. Krishnan, Y. Huang, and R. Sandhu, “Malware detection in cloud infrastructures using convolutional neural networks,” in 2018 IEEE 11th International Conference on Cloud Computing (CLOUD).
IEEE, 2018, pp. 162–169.
[11] S. Ahmed, Y. Xiao, K. Z. Snow, G. Tan, F. Monrose, and D. D. Yao, “Methodologies for quantifying (re-)randomization security and timing under JIT-ROP,” in Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, 2020.
[12] B. Anderson and D. McGrew, “Machine learning for encrypted malware traffic classification: accounting for noisy labels and non-stationarity,” in Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2017.
[13] B. Anderson, D. Quist, J. Neil, C. Storlie, and T. Lane, “Graph-based malware detection using dynamic analysis,” Journal in computer Virology, vol. 7, no. 4, pp. 247–258, 2011.
[14] D. Andriesse, A. Slowinska, and H. Bos, “Compiler-agnostic function detection in binaries,” in 2017 IEEE European Symposium on Security and Privacy (Euro S&P), April 2017.
[15] K. Aoki, T. Yagi, M. Iwamura, and M. Itoh, “Controlling malware HTTP communications in dynamic analysis system using search engine,” in 2011 Third International Workshop on Cyberspace Safety and Security (CSS).
IEEE, 2011, pp. 1–6.
[16] S. Attaluri, S. McGhee, and M. Stamp, “Profile hidden Markov models in computer virology, and metamorphic virus detection,” Journal, vol. 5, pp. 151–169, 2009.
[17] D. Balzarotti, M. Cova, C. Karlberger, C. Kruegel, E. Kirda, and G. Vigna, “Efficient detection of split personalities in malware,” in In Proceedings of the Symposium on Network and Distributed System Security (NDSS), 2010.
[18] T. Barabosch and E. Gerhards-Padilla, “Host-based code injection attacks: A popular technique used by malware,” in 2014 9th International Conference on Malicious and Unwanted Software: The Americas (MALWARE).
IEEE, 2014.
[19] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda, “Scalable, behavior-based malware clustering.” in NDSS, 2009.
[20] U. Bayer, E. Kirda, and C. Kruegel, “Improving the efficiency of dynamic malware analysis,” in Proceedings of the 2010 ACM Symposium on Applied Computing, 2010.
[21] M. Brengel and C. Rossow, “Memscrimper: Time-and space-efficient storage of malware sandbox memory dumps,” in DIMVA. Springer, 2018, pp. 24–45.
[22] D. Brumley, C. Hartwig, Z. Liang, J. Newsome, D. Song, and H. Yin, Automatically Identifying Trigger-based Behavior in Malware. Boston, MA: Springer US, 2008, pp. 65–88.
[23] P. Burnap, R. French, F. Turner, and K. Jones, “Malware classification using self organising feature maps and machine activity data,” computers & security, vol. 73, pp. 399–410, 2018.
[24] H. Cai, N. Meng, B. Ryder, and D. D. Yao, “Droidcat: Unified dynamic detection of Android malware,” Department of Computer Science, Virginia Polytechnic Institute & State University, Tech. Rep., 2016.
[25] R. Canzanese, M. Kam, and S. Mancoridis, “Multi-channel change-point malware detection,” in 2013 IEEE 7th International Conference on Software Security and Reliability.
IEEE, 2013, pp. 70–79.
[26] Y. Cao, J. Liu, Q. Miao, and W. Li, “Osiris: A malware behavior capturing system implemented at virtual machine monitor layer,” in 2012 Eighth International Conference on Computational Intelligence and Security, 2012.
J. Chung, C¸. G¨ulc¸ehre, K. Cho, and Y. Bengio, “Empirical evaluation of gated recurrent neural networks on sequence modeling,” CoRR, vol. abs/1412.3555, 2014.
[27]
[28] P. M. Comparetti, G. Salvaneschi, E. Kirda, C. Kolbitsch, C. Kruegel, and S. Zanero, “Identifying dormant functionality in malware programs,” in 2010 IEEE Symposium on Security and Privacy.
IEEE.
[29] E. Cozzi, M. Graziano, Y. Fratantonio, and D. Balzarotti, “Understanding Linux malware,” in 2018 IEEE S&P.
IEEE, 2018, pp. 161–175.
[30] J. R. Crandall, G. Wassermann, D. A. S. de Oliveira, Z. Su, S. F. Wu, and F. T. Chong, “Temporal search: Detecting hidden malware time-bombs with virtual machines,” in Proceedings of the 12th International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS XII. ACM, 2006, p. 2536.
[31] B. Dolan-Gavitt, J. Hodosh, P. Hulin, T. Leek, and R. Whelan, “Repeatable reverse engineering with panda,” in Proceedings of the 5th Program Protection and Reverse Engineering Workshop, 2015.
[32] B. Dolan-Gavitt, T. Leek, J. Hodosh, and W. Lee, “Tappan zee (north) bridge: Mining memory accesses for introspection,” in Proceedings of the 2013 ACM SIGSAC CCS, ser. CCS ’13. ACM, 2013.
[33] B. Efron, T. Hastie, L. Johnstone, and R. Tibshirani, “Least angle regression,” Annals of Statistics, vol. 32, pp. 407–499, 2004.
[34] M. Egele, T. Scholte, E. Kirda, and C. Kruegel, “A survey on automated dynamic malware-analysis techniques and tools,” ACM