# Title: XACML Policy Performance Evaluation Using a Flexible Load Testing Framework

## Authors:
- Bernard Butler
- Brendan Jennings
- Dmitri Botvich

### Affiliations:
FAME, Ireland  
Telecommunications Software & Systems Group  
Waterford Institute of Technology  
{bbutler, bjennings, dbotvich}@tssg.org

## Abstract
The performance and scalability of access control systems are becoming increasingly important as organizations deploy more complex communication and content management systems. Fine-grained access control is becoming more prevalent, leading to more frequent decisions and larger policy sets. This paper outlines a flexible performance testing framework that accepts XACML Policy Decision Point (PDP) implementations in the server component and submits representative access control requests from the client component in a realistic temporal order. The framework includes instrumentation and analysis modules to support performance experiments. We describe an initial realization of the framework and report on initial experiments comparing the performance of the SunXACML and Enterprise XACML PDPs.

## Categories and Subject Descriptors
D.2.8 [Software Engineering]: Metrics—Performance measures; D.4.6 [Operating Systems]: Security and protection—Access controls, Information flow controls

## General Terms
Security, Performance, Measurement

## Keywords
Access control policies, performance evaluation, measurement testbed

## 1. Introduction
Policy Decision Point (PDP) performance is a critical requirement for access control systems. In large organizations, access decisions often depend on the context of the request, necessitating fine-grained access control to implement security policies with complex boundaries between permitted and denied behavior. As the number of access requests increases, so does the number of policy evaluations, and each evaluation takes longer as policy sets grow larger.

For example, in enterprises, instant messaging communications, especially in group-chat scenarios, generate a large number of policy evaluations. The access control system must decide which participant pairs can communicate, which is essential in organizations where regulatory reasons require maintaining Chinese Walls [1].

Many enterprise-level access control systems use XACML (eXtensible Access Control Markup Language) [7] to encode access controls. Therefore, researchers focus on XACML policies and requests and their use in Policy Enforcement Points (PEPs) and XACML-based PDPs.

While it is relatively easy to scale out the stateless PEP function, scaling the stateful PDP function is more challenging. Typical performance measures for a PDP include latency and throughput, so any testbed needs to compute both. Some researchers advocate "black box" approaches such as caching frequently encountered request-result pairs. Alternatively, given one or more policy sets, request profiles, or PDP source code, "white-box" approaches are possible. XACML policies can be improved through categorization, reordering, and clustering [4], numericalization, and simplification to tree structures [3]. XACML policies can also be replaced with an equivalent Description Logic formulation [2].

Generally, the evidence presented by researchers is based on comparisons with the Sun XACML reference implementation [8], often using unpublished policies and requests. This makes it difficult to compare different approaches or determine trade-offs. We propose a performance testbed for access control implementations to facilitate research into the performance and scalability problems facing XACML-based access control. Our goal is to provide a flexible, easily configurable framework, enabling researchers to perform quantitative experiments under representative, controlled, and repeatable conditions.

## 2. Related Work
Generating a large and representative set of policy requests for performance evaluation is related to generating a test set that covers as many policy conditions as possible. Ensuring full coverage means all policy conditions are checked, providing a path to each terminal node in the decision tree inferred from the policy set [5]. [5] also describes how Margrave can be used to determine redundant rules in a complex policy set. [6] describes how policy mutation testing can be used to determine how well a given test set of XACML requests discovers faults (deliberately injected as mutations) in policy sets.

Data clustering has been applied to characterize policies and improve PDP performance [4].

## 3. Framework Overview
The architecture of our XACML load testing framework is presented in Figure 1. The XTS (server) comprises a PDP, a simplified "universal" PEP, and a specific PDP adapter. Each PDP implementation needs an adapter to wrap calls from the universal PEP. The adapter also brackets each PDP call with timing calls to compute the elapsed time at the PDP.

Several modes of request generation are possible in the XTC (client):
- Reusing existing requests by weighted resampling
- Generating new requests, motivated by Section 2

The XTC submits the generated XACML requests to the XTS PEP based on request scenarios chosen by testbed users. XTA persists the XTS results (both responses and timings) and analyzes them offline by fitting empirical (frequency) distribution functions (edf) and clustering requests by locating peaks in the response duration edf.

## 4. Initial Experiments and Results
In the testbed, we compared the performance of the Sun XACML and Enterprise XACML [9] PDP implementations, using the same policies and identical resampled requests, as shown in Figure 2. Both PDPs made the same access decisions for all requests. We believe each cluster of processing durations (equivalently, edf peak) corresponds to a set of requests that share similar processing requirements, such as policy search paths for a given PDP. Qualitatively, the Enterprise XACML PDP shows better performance (tEX < tSX) than the Sun XACML PDP. The Enterprise XACML PDP exhibits remarkably consistent performance at about 1.4 milliseconds per request, with just a few upper outliers.

The experiments are valid for that combination of policies and requests since we employ a randomized block design and control for other known factors.

## 5. Conclusions and Future Work
The testing framework provides necessary infrastructure for building access control policy evaluation models. Such models are needed to understand how to improve the performance and/or scalability of XACML-based access control systems. Future work will include better request generation and timing analysis techniques to broaden the scope of hypotheses that can be tested. We will also extend to more PDP implementations and multiple PDP instances. Additionally, we will seek a predictive model underlying the observed timings.

## 6. Acknowledgments
The authors acknowledge the contribution of Keith Griffin and Ger Lawlor, Cisco Systems Inc., who helped clarify the requirements for modeling the performance of XACML PDPs. The work was funded by Science Foundation Ireland via the "FAME" Strategic Research Cluster, grant no. 08/SRC/I1403.

## 7. References
[1] D. F. C. Brewer and M. J. Nash. The Chinese Wall Security Policy. In IEEE Symposium on Security and Privacy, pages 206–214, 1989.

[2] V. Kolovski, J. Hendler, and B. Parsia. Analyzing web access control policies. In WWW '07: Proceedings of the 16th international conference on World Wide Web, pages 677–686, New York, NY, USA, 2007. ACM.

[3] A. X. Liu, F. Chen, J. Hwang, and T. Xie. Xengine: a fast and scalable XACML policy evaluation engine. In SIGMETRICS '08: Proceedings of the 2008 ACM SIGMETRICS international conference on Measurement and modeling of computer systems, pages 265–276, New York, NY, USA, 2008. ACM.

[4] S. Marouf, M. Shehab, A. Squicciarini, and S. Sundareswaran. Statistics & Clustering Based Framework for Efficient XACML Policy Evaluation. In POLICY '09: Proceedings of the 2009 IEEE International Symposium on Policies for Distributed Systems and Networks, pages 118–125, Washington, DC, USA, 2009. IEEE Computer Society.

[5] E. Martin. Automated test generation for access control policies. In OOPSLA '06: Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and applications, pages 752–753, New York, NY, USA, 2006. ACM.

[6] E. Martin, T. Xie, and T. Yu. Defining and measuring policy coverage in testing access control policies. In Proc. 8th International Conference on Information and Communications Security, pages 139–158, 2006.

[7] T. Moses. eXtensible Access Control Markup Language TC v2.0 (XACML). http://docs.oasis-open.org/xacml/2.0/access-control-xacml-2.0-core-spec-os.pdf, February 2005.

[8] S. Proctor. Sun’s XACML Implementation - Programmer’s Guide for Version 1.2. http://sunxacml.sourceforge.net/guide.html, July 2004. Last accessed 2009-11-25.

[9] Z. Wang. Enterprise Java XACML. http://code.google.com/p/enterprise-java-xacml/wiki/DevelopmentPlan, February 2010. Last accessed 2010-04-19.

![Figure 1: XACML Load Testing System Architecture](figure1.png)

![Figure 2: Comparison of the performance profiles of two XACML PDPs on the same policy and request sets](figure2.png)