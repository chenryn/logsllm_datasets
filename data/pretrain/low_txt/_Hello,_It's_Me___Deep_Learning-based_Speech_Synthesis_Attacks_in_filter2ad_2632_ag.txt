### Recognition

#### Speaker Recognition
- **Azure Cognitive Services**: [Speaker Recognition](https://azure.microsoft.com/en-us/services/cognitive-services/speaker-recognition/)

#### Text-to-Speech (TTS) and Voice Cloning Tools
- **Mozilla TTS (2021)**: [GitHub Repository](https://github.com/mozilla/TTS)
- **Resemble.AI (2021)**: [Website](https://www.resemble.ai/)
- **TensorFlowTTS (2021)**: [GitHub Repository](https://github.com/TensorSpeech/TensorFlowTTS)
- **Voxforge (2021)**: [Website](http://www.voxforge.org/)
- **VoicePrint (WeChat Documentation, 2021)**: [Documentation](https://help.wechat.com/cgi-bin/micromsg-bin/oshelpcenter?opcode=2&plat=ios&lang=en&id=150819uqYnUR150819YzINVb)

### References

1. **Muhammad Ejaz Ahmed, Il-Youp Kwak, Jun Ho Huh, Iljoo Kim, Taekkyung Oh, and Hyoungshick Kim (2020)**: *VOID: A Fast and Light Voice Liveness Detection System*. In *Proc. of USENIX*.
2. **Ehab A AlBadawy, Siwei Lyu, and Hany Farid (2019)**: *Detecting AI-Synthesized Speech Using Bispectral Analysis*. In *CVPR Workshops*.
3. **Federico Alegre, Artur Janicki, and Nicholas Evans (2014)**: *Re-assessing the Threat of Replay Spoofing Attacks Against Automatic Speaker Verification*. In *Proc. of BIOSIG*.
4. **Gopala K Anumanchipalli, Josh Chartier, and Edward F Chang (2019)**: *Speech Synthesis from Neural Decoding of Spoken Sentences*. *Nature* (2019).
5. **Gopala Krishna Anumanchipalli, Kishore Prahallad, and Alan W Black (2011)**: *Festvox: Tools for Creation and Analyses of Large Speech Corpora*. In *Workshop on Very Large Scale Phonetics Research*.
6. **Sercan O Arik, Jitong Chen, Kainan Peng, Wei Ping, and Yanqi Zhou (2018)**: *Neural Voice Cloning with a Few Samples*. In *Proc. of NeurIPS (2018)*.
7. **Pascal Belin, Patricia E G Bestelmeyer, Marianne Latinus, and Rebecca Watson (2011)**: *Understanding Voice Perception*. *British Journal of Psychology* 102, 4 (Nov. 2011), 711–725.
8. **Frédéric Bimbot, Jean-François Bonastre, Corinne Fredouille, et al. (n.d.)**: *A Tutorial on Text-Independent Speaker Verification*. *EURASIP Journal on Advances in Signal Processing* 2004.
9. **Maximilian Bisani and Hermann Ney (2008)**: *Joint-Sequence Models for Grapheme-to-Phoneme Conversion*. *Speech Communication* 50, 5 (2008), 434–451. [DOI](https://doi.org/10.1016/j.specom.2008.01.002)
10. **Guangke Chen, Sen Chen, Lingling Fan, Xiaoning Du, Zhe Zhao, Fu Song, and Yang Liu (2019)**: *Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems*. *arXiv preprint arXiv:1911.01840* (2019).
11. **Si Chen, Kui Ren, Sixu Piao, Cong Wang, Qian Wang, Jian Weng, Lu Su, and Aziz Mohaisen (2017)**: *You Can Hear but You Cannot Steal: Defending Against Voice Impersonation Attacks on Smartphones*. In *Proc. of ICDS*.
12. **Jemine Corentin (2019)**: *Master Thesis: Real-Time Voice Cloning*. [Link](https://matheo.uliege.be/handle/2268.2/6801)
13. **Phillip L De Leon, Vijendra Raj Apsingekar, Michael Pucher, and Junichi Yamagishi (2010)**: *Revisiting the Security of Speaker Verification Systems Against Imposture Using Synthetic Speech*. In *Proc. of ICASSP*.
14. **Mattia A Di Gangi, Matteo Negri, and Marco Turchi (2019)**: *Adapting Transformer to End-to-End Spoken Language Translation*. In *Proc. of INTERSPEECH*.
15. **Grant Fairbanks (1960)**: *Voice and Articulation Drillbook*. *Addison-Wesley Educational Publishers*.
16. **Sadaoki Furui (1981)**: *Cepstral Analysis Technique for Automatic Speaker Verification*. In *Proc. of ICASSP*.
17. **Haichang Gao, Honggang Liu, Dan Yao, Xiyang Liu, and Uwe Aickelin (2010)**: *An Audio CAPTCHA to Distinguish Humans from Computers*. In *2010 Third International Symposium on Electronic Commerce and Security*. *IEEE*, 265–269.
18. **Yang Gao, Jiachen Lian, Bhiksha Raj, and Rita Singh (2021)**: *Detection and Evaluation of Human and Machine Generated Speech in Spoofing Attacks on Automatic Speaker Verification Systems*. In *Proc. of IEEE SLT Workshop*.
19. **Rosa González Hautamäki, Md Sahidullah, Ville Hautamäki, and Tomi Kinnunen (2017)**: *Acoustical and Perceptual Study of Voice Disguise by Age Modification in Speaker Verification*. *Speech Communication* (2017).
20. **Georg Heigold, Ignacio Moreno, Samy Bengio, and Noam Shazeer (2016)**: *End-to-End Text-Dependent Speaker Verification*. In *Proc. of ICASSP*. *IEEE*.
21. **Wei-Ning Hsu, Yu Zhang, Ron J Weiss, Heiga Zen, Yonghui Wu, Yuxuan Wang, Yuan Cao, Ye Jia, Zhifeng Chen, Jonathan Shen, et al. (2019)**: *Hierarchical Generative Modeling for Controllable Speech Synthesis*. In *Proc. of ICLR*.
22. **Qiong Hu, Erik Marchi, David Winarsky, Yannis Stylianou, Devang Naik, and Sachin Kajarekar (2019)**: *Neural Text-to-Speech Adaptation from Low Quality Public Recordings*. In *Speech Synthesis Workshop, Vol. 10*.
23. **Chien-yu Huang, Yist Y Lin, Hung-yi Lee, and Lin-shan Lee (2021)**: *Defending Your Voice: Adversarial Attack on Voice Conversion*. In *Proc. of IEEE SLT Workshop*.
24. **Artur Janicki, Federico Alegre, and Nicholas Evans (2016)**: *An Assessment of Automatic Speaker Verification Vulnerabilities to Replay Spoofing Attacks*. *Security and Communication Networks* (2016).
25. **Corentin Jemine (2020)**: *Real-Time Voice Cloning*. [GitHub Repository](https://github.com/CorentinJ/Real-Time-Voice-Cloning)
26. **Ye Jia, Yu Zhang, Ron Weiss, Quan Wang, Jonathan Shen, Fei Ren, Patrick Nguyen, Ruoming Pang, Ignacio Lopez Moreno, Yonghui Wu, et al. (2018)**: *Transfer Learning from Speaker Verification to Multispeaker Text-to-Speech Synthesis*. In *Proc. of NeurIPS*.
27. **Hirokazu Kameoka, Takuhiro Kaneko, Kou Tanaka, and Nobukatsu Hojo (2018)**: *StarGAN-VC: Non-Parallel Many-to-Many Voice Conversion Using Star Generative Adversarial Networks*. In *Proc. of IEEE SLT Workshop*.
28. **Elie Khoury, Laurent El Shafey, and Sébastien Marcel (2014)**: *SPEAR: An Open Source Toolbox for Speaker Recognition Based on Bob*. In *Proc. of ICASSP*.
29. **Tomi Kinnunen, Md Sahidullah, Héctor Delgado, Massimiliano Todisco, Nicholas Evans, Junichi Yamagishi, and Kong Aik Lee (2017)**: *The ASVspoof 2017 Challenge: Assessing the Limits of Replay Spoofing Attack Detection*.
30. **Tomi Kinnunen, Zhi-Zheng Wu, Kong Aik Lee, Filip Sedlak, Eng Siong Chng, and Haizhou Li (2012)**: *Vulnerability of Speaker Verification Systems Against Voice Conversion Spoofing Attacks: The Case of Telephone Speech*. In *Proc. of ICASSP*.
31. **John Kominek and Alan W Black (2003)**: *CMU ARCTIC Databases for Speech Synthesis*. *Carnegie Mellon University, Language Technologies Institute Tech Report CMU-LTI-03-177*.
32. **Michael W. Kraus, Brittany Torrez, Jun Won Park, and Fariba Ghayebi (2019)**: *Evidence for the Reproduction of Social Class in Brief Speech*. *Proceedings of the National Academy of Sciences* 114, 46 (Nov. 2019), 22998–23003.
33. **Felix Kreuk, Yossi Adi, Moustapha Cisse, and Joseph Keshet (2018)**: *Fooling End-to-End Speaker Verification with Adversarial Examples*. In *Proc. of ICASSP*.
34. **Gautam Krishna, Co Tran, Yan Han, Mason Carnahan, and Ahmed H Tewfik (2020)**: *Speech Synthesis Using EEG*. In *Proc. of ICASSP*.
35. **I Han Kuo, Joel Marcus Rabindran, Elizabeth Broadbent, Yong In Lee, Ngaire Kerse, Rebecca MQ Stafford, and Bruce A MacDonald (2009)**: *Age and Gender Factors in User Acceptance of Healthcare Robots*. In *Proc. of RO-MAN*. *IEEE*.
36. **Yee Wah Lau, Michael Wagner, and Dat Tran (2004)**: *Vulnerability of Speaker Verification to Voice Mimicking*. In *Proc. of ISIMP*.
37. **Galina Lavrentyeva, Sergey Novoselov, Egor Malykh, Alexander Kozlov, Oleg Kudashev, and Vadim Shchemelinin (2017)**: *Audio Replay Attack Detection with Deep Learning Frameworks*. In *Proc. of INTERSPEECH*.
38. **Zhuohang Li, Cong Shi, Yi Xie, Jian Liu, Bo Yuan, and Yingying Chen (2020)**: *Practical Adversarial Attacks Against Speaker Recognition Systems*. In *Proc. of HotMobile*.
39. **A Lieto, D Moro, F Devoti, C Parera, Vincenzo Lipari, Paolo Bestagini, and Stefano Tubaro (2019)**: *“Hello? Who Am I Talking to?” A Shallow CNN Approach for Human vs. Bot Speech Classification*. In *Proc. of ICASSP*.
40. **Sabrina López, Pablo Riera, María Florencia Assaneo, Manuel Eguía, Mariano Sigman, and Marcos A Trevisan (2013)**: *Vocal Caricatures Reveal Signatures of Speaker Identity*. *Scientific Reports* (2013).
41. **Takashi Masuko, Takafumi Hitotsumatsu, Keiichi Tokuda, and Takao Kobayashi (1999)**: *On the Security of HMM-Based Speaker Verification Systems Against Imposture Using Synthetic Speech*. In *Proc. of 6th European Conference on Speech Communication and Technology*.
42. **Dibya Mukhopadhyay, Maliheh Shirvanian, and Nitesh Saxena (2015)**: *All Your Voices Are Belong to Us: Stealing Voices to Fool Humans and Machines*. In *Proc. of ESORICS*.
43. **John Mullennix and Steven Stern (2010)**: *Computer Synthesized Speech Technologies: Tools for Aiding Impairment*. *IGI Global*.
44. **Arsha Nagrani, Joon Son Chung, Weidi Xie, and Andrew Zisserman (2020)**: *VoxCeleb: Large-Scale Speaker Verification in the Wild*. *Computer Speech & Language* (2020).
45. **Ajaya Neupane, Nitesh Saxena, Leanne M Hirshfield, and Sarah E Bratt (2019)**: *The Crux of Voice (In) Security: A Brain Study of Speaker Legitimacy Detection*. In *Proc. of NDSS*.
46. **Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur (2015)**: *LibriSpeech: An ASR Corpus Based on Public Domain Audio Books*. In *Proc. of ICASSP*.
47. **Pavol Partila, Jaromir Tovarek, Gokhan Hakki Ilk, Jan Rozhon, and Miroslav Voznak (2020)**: *Deep Learning Serves Voice Cloning: How Vulnerable Are Automatic Speaker Verification Systems to Spoofing Trials?*. *IEEE Communications Magazine* (2020).
48. **Cyril R. Pernet and Pascal Belin (2012)**: *The Role of Pitch and Timbre in Voice Gender Categorization*. *Frontiers in Psychology* 3 (Feb 2012).
49. **Wei Ping, Kainan Peng, Andrew Gibiansky, Sercan O Arik, Ajay Kannan, Sharan Narang, Jonathan Raiman, and John Miller (2018)**: *DeepVoice 3: Scaling Text-to-Speech with Convolutional Sequence Learning*. In *Proc. of ICLR*.
50. **Kaizhi Qian (2021)**: *AutoVC GitHub Implementation*. [GitHub Repository](https://github.com/auspicious3000/autovc)
51. **Kaizhi Qian, Yang Zhang, Shiyu Chang, Mark Hasegawa-Johnson, and David Cox (2020)**: *Unsupervised Speech Decomposition via Triple Information Bottleneck*. In *Proc. of ICML*.
52. **Kaizhi Qian, Yang Zhang, Shiyu Chang, Xuesong Yang, and Mark Hasegawa-Johnson (2019)**: *AutoVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss*. In *Proc. of ICML*.
53. **Yao Qin, Nicholas Carlini, Garrison Cottrell, Ian Goodfellow, and Colin Raffel (2019)**: *Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition*. In *Proc. of ICMR*.
54. **Yurii Rebryk and Stanislav Beliaev (2020)**: *ConVoice: Real-Time Zero-Shot Voice Style Transfer with Convolutional Network*. *arXiv preprint arXiv:2005.07815* (2020).
55. **Douglas A Reynolds, Thomas F Quatieri, and Robert B Dunn (2000)**: *Speaker Verification Using Adapted Gaussian Mixture Models*. *Digital Signal Processing* 10 (2000).
56. **Aaron E Rosenberg (1976)**: *Automatic Speaker Verification: A Review*. *IEEE* (1976).
57. **J. Saldana (2009)**: *The Coding Manual for Qualitative Researchers*. *Sage Publications Limited* (2009).
58. **Aaron Sell, Gregory A. Bryant, Leda Cosmides, John Tooby, Daniel Sznycer, et al. (2010)**: *Adaptations in Humans for Assessing Physical Strength from the Voice*. *Proceedings of the Royal Society B* 277 (June 2010), 3509–3518.
59. **Joan Serrà, Santiago Pascual, and Carlos Segura (2019)**: *Blow: A Single-Scale Hyperconditioned Flow for Non-Parallel Raw-Audio Voice Conversion*. In *Proc. of NeurIPS*.
60. **Neeraj Kumar Sharma, Shobhana Ganesh, Sriram Ganapathy, and Lori L Holt (2019)**: *Talker Change Detection: A Comparison of Human and Machine Performance*. *The Journal of the Acoustical Society of America* (2019).
61. **Jonathan Shen, Ruoming Pang, Ron J Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, RJ Skerry-Ryan, et al. (2018)**: *Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions*. In *Proc. of ICASSP*.
62. **Maliheh Shirvanian, Manar Mohammed, Nitesh Saxena, and S Abhishek Anand (2020)**: *VoiceFox: Leveraging Inbuilt Transcription to Enhance the Security of Machine-Human Speaker Verification against Voice Synthesis Attacks*. In *Annual Computer Security Applications Conference*. 870–883.
63. **Maliheh Shirvanian and Nitesh Saxena (2014)**: *Wiretapping via Mimicry: Short Voice Imitation Man-in-the-Middle Attacks on Crypto Phones*. In *Proc. of CCS*.
64. **Maliheh Shirvanian, Summer Vo, and Nitesh Saxena (2019)**: *Quantifying the Breakability of Voice Assistants*. In *Proc. of PerCom*.
65. **Dan Simmons (2017)**: *BBC Fools HSBC Voice Recognition System*. [Link](https://www.bbc.com/news/technology-39965545)
66. **David Snyder, Pegah Ghahremani, Daniel Povey, Daniel Garcia-Romero, Yishay Carmiel, and Sanjeev Khudanpur (2016)**: *Deep Neural Network-Based Speaker Embeddings for End-to-End Speaker Verification*. In *Proc. of IEEE SLT Workshop*.
67. **Catherine Stupp (2019)**: *Fraudsters Used AI to Mimic CEO’s Voice in Unusual Cybercrime Case*. *Wall Street Journal* (August 2019).
68. **Yaniv Taigman, Lior Wolf, Adam Polyak, and Eliya Nachmani (2018)**: *VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop*. In *Proc. of ICLR*.
69. **Rie Tamagawa, Catherine I Watson, I Han Kuo, Bruce A MacDonald, and Elizabeth Broadbent (2011)**: *The Effects of Synthesized Voice Accents on User Perceptions of Robots*. *International Journal of Social Robotics* 3 (2011).
70. **Ehsan Variani, Xin Lei, Erik McDermott, Ignacio Lopez Moreno, and Javier Gonzalez-Dominguez (2014)**: *Deep Neural Networks for Small Footprint Text-Dependent Speaker Verification*. In *Proc. of ICASSP*. *IEEE*.
71. **Ville Vestman, Tomi Kinnunen, Rosa González Hautamäki, and Md Sahidullah (2020)**: *Voice Mimicry Attacks Assisted by Automatic Speaker Verification*. *Computer Speech & Language* (2020).
72. **James Vincent (2018)**: *Google’s AI Sounds Like a Human on the Phone – Should We Be Worried*. *The Verge* (May 2018).
73. **Robbie Vogt and Sridha Sridharan (2008)**: *Explicit Modelling of Session Variability for Speaker Verification*. *Computer Speech & Language* (2008).
74. **Li Wan, Quan Wang, Alan Papir, and Ignacio Lopez Moreno (2018)**: *Generalized End-to-End Loss for Speaker Verification*. In *Proc. of ICASSP*.
75. **Qian Wang, Xiu Lin, Man Zhou, Yanjiao Chen, Cong Wang, Qi Li, and Xiangyang Luo (2019)**: *VoicePop: A Pop Noise Based Anti-Spoofing System for Voice Authentication on Smartphones*. In *Proc. of INFOCOM*.
76. **Run Wang, Felix Juefei-Xu, Yihao Huang, Qing Guo, Xiaofei Xie, Lei Ma, and Yang Liu (2020)**: *DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake Voices*. *arXiv preprint arXiv:2005.13770* (2020).
77. **Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, et al. (2017)**: *Tacotron: Towards End-to-End Speech Synthesis*. In *Proc. of INTERSPEECH* (2017).
78. **Robert Weide (1998)**: *The Carnegie Mellon Pronouncing Dictionary*. [Link](http://www.speech.cs.cmu.edu/cgi-bin/cmudict)
79. **Steven H. Weinberger (2013)**: *Speech Accent Archive*. *George Mason University*.
80. **Da-Yi Wu, Yen-Hao Chen, and Hung-Yi Lee (2020)**: *VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net Architecture*. *arXiv preprint arXiv:2006.04154* (2020).
81. **Zhizheng Wu, Tomi Kinnunen, Nicholas Evans, Junichi Yamagishi, Cemal Hanilçi, Md Sahidullah, and Aleksandr Sizov (2015)**: *ASVspoof 2015: The First Automatic Speaker Verification Spoofing and Countermeasures Challenge*. In *Proc. of ISCA*.
82. **Junichi Yamagishi, Christophe Veaux, and Kirsten MacDonald (n.d.)**: *CSTR VCTK Corpus: English Multi-Speaker Corpus for CSTR Voice Cloning Toolkit*. [DOI](https://doi.org/10.7488/ds/2645)
83. **Chen Yan, Yan Long, Xiaoyu Ji, and Wenyuan Xu (2019)**: *The Catcher in the Field: A Fieldprint Based Spoofing Detection for Text-Independent Speaker Verification*. In *Proc. of CCS*.
84. **R. Zaske and S. R. Schweinberger (2011)**: *You Are Only as Old as You Sound: Auditory Aftereffects in Vocal Age Perception*. *Hearing Research* 282, 1-2 (Dec. 2011), 283–288.
85. **Linghan Zhang, Sheng Tan, and Jie Yang (2017)**: *Hearing Your Voice is Not Enough: An Articulatory Gesture Based Liveness Detection for Voice Authentication*. In *Proc. of CCS*.

### Appendix

#### Methodology for §4.1

Here, we describe the methodology used to recreate [57] in §4.1.

**Systems Used:**
- **Festvox [20]**: A text-dependent voice conversion system that uses Gaussian Mixture Models (GMMs) [70] to model vocal characteristics. Training requires 4-8 minutes of speech from both the source and target speakers and takes approximately 5-10 minutes.
- **Bob Spear [43]**: An open-source speaker recognition system using classical statistical techniques (Universal Background Model Gaussian Mixture Models (UBM-GMM) and Inter-Session Variability (ISV)) for speaker recognition [88].
- **Resemblyzer, Azure**: See §3.

**Datasets Used:**
- **CMU ARCTIC [46]**: Contains 1150 spoken phrases from male and female English speakers.
- **Voxforge [14]**: An open-source dataset of transcribed speech. The subset used contains 6561 spoken phrases, each approximately 5 seconds long, from 30 English speakers.

**Attack Implementation:**
- We recreated the exact setup of the voice conversion attack from [57]. Festvox was used to convert speech from two CMU ARCTIC speakers (one male, one female) to imitate 10 speakers from the Voxforge dataset.
- The synthesized attack samples were tested against both of Bob Spear’s speaker recognition algorithms (UBM-GMM and ISV), along with Resemblyzer and Azure.
- Attack performance was measured using the attack success rate (AS), which denotes the percentage of synthesized samples identified as the target.