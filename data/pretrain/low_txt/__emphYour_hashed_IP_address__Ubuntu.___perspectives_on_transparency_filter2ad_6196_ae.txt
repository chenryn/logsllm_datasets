### 5. Transparency Mechanisms and Subject Access Requests

The current approaches to subject access requests (SARs) vary widely, and there appears to be limited support for improvements. The primary objective of most companies is legal compliance rather than fostering user understanding. While most participants acknowledge the value of transparency mechanisms, a significant mismatch exists between user expectations and the industry's understanding of personal data. For a long time, the industry has not considered users' data as personal, and many companies are still unaware of the actual data flows.

### 6. Discussion and Recommendations

Our survey revealed that the number of users requesting access to their data is relatively low. One factor contributing to this is the lack of awareness among consumers about the new opportunities provided by online tools and regulations. Additionally, some companies make it difficult for users to understand who collects their data, even for those who are aware of their rights.

When users do request access, they prefer receiving inferred information (e.g., interest segments) over technical data. In our user study, participants strongly expressed their desire for "less technical" data (P-43) and an "easy-to-read visualization" (P-324). However, not all companies can provide such information, as it depends on the nature of their business. To address this, companies should offer both high-level, easily understandable information and the underlying raw data, allowing users to analyze the data according to their needs.

The problems with privacy policies have been well-documented, yet it seems that the responsibility for developing better tools falls on researchers, as companies focus more on legal compliance than on user understanding. As one participant (I-5) stated: “I wrote something like a hundred privacy policies, and I think all of them lack transparency. I can defend myself in front of an authority, but I think a normal user, like a person who would read a policy, will not fully understand what is happening.”

Over 60% of the companies surveyed expressed a need for more regulatory guidance on designing SAR processes. Our research suggests that consumers would appreciate simplified and unified methods for obtaining transparency. We recommend providing a visual overview, such as a workflow diagram, that describes the data collection, its sources, and with whom it is shared. Further research is needed to evaluate these designs, which could serve as blueprints for companies when designing or improving their SAR processes or general transparency guidelines. An industry-wide standard would enable users to compare services based on their privacy impact.

Companies that aim to be transparent should start by educating users about how their personal data is used before collecting and presenting it. This education should begin at a high level, with the option to download raw data. Previous research has emphasized the need for information literacy [6].

Public mistrust in the data sharing industry has driven the implementation of stricter regulations. To counter misconceptions, companies must improve public understanding of their practices. It could be helpful to provide information on what is not done with collected data (e.g., a company might not collect users' location, but users may still wonder why it is not shown). As we found that users struggle to identify the companies that collect their data, adding "Provided by X" information in every ad banner would be beneficial.

### 7. Limitations

In our analysis of transparency tools, we examined data from 22 ad companies, a subset of all advertisement-related companies. Our study focused on larger companies in terms of web presence, and we did not analyze smaller companies. However, we identified different transparency approaches, and interviews with smaller companies suggest that we did not miss methodologically distinct approaches. The analyzed profiles do not include all the data a company might collect (e.g., not all interest segments or demographic information), so our classification may have some inaccuracies. Nonetheless, omitting the four uncertain cases would not fundamentally change our overall results and findings.

Our user study was based on participants from the US only. We decided not to recruit EU residents because providing the online questionnaire in multiple languages would have been necessary to avoid bias. We expect that US residents have similar needs regarding transparency in online advertisements. Our survey was based on a small subset of companies willing to participate in our study and telephone interviews. Therefore, the views presented may not be fully representative of the entire industry. Despite this, we identified a diverse set of opinions and hope that future work can broaden the empirical basis of our results.

### 8. Related Work

In the following section, we discuss work closely related to ours and compare prior research to our approach. Personal data is often conceptualized as an economic asset for companies [2]. Business models are built on the collection and aggregation of personal data [1, 20], and malicious attempts to collect such data have also been studied [53].

**Subject Access Requests (SARs):** The GDPR introduced the SAR process, giving users the right to access their data collected by online services. Urban et al. [52] measured the SAR process in detail, showing that it varies significantly in terms of obstacles, timing, and success between different actors in the online advertising economy. Boniface et al. [7] analyzed the tension between authentication and security during SARs and discussed measures used to identify users and the threats (e.g., denial of access) posed by overly strict measures. Recent studies have shown how SARs can be misused to gain access to personal data stored about other individuals [10, 15]. These studies involved spoofing identities and filing SARs, revealing that some companies carelessly share data without verifying the user's identity. Degeling et al. [14] analyzed the adoption and effect of the GDPR on privacy policies and cookie notices.

**User Transparency Tools:** Leon et al. [33] evaluated the usability of several tools to limit Online Behavioral Advertising (OBA). Their laboratory study showed that all tools had serious usability flaws, leading to misuse and misunderstanding. Andreou et al. [4] analyzed Facebook's ad transparency tools and found that the messages explaining why users see specific ads were often incomplete and misleading. Parra-Arnau et al. [40] presented a web browser extension that gives users fine-grained control over the ads they see and helps them understand how their browsing data is used. Melicher et al. [38] investigated users' perspectives on the benefits and risks of online tracking through 35 user interviews. They found that while users want more control over tracking, they are unwilling to put effort into actually taking control. Schaub et al. [44] evaluated the effectiveness of three different tools used to block online tracking (e.g., Ghostery) and found that these tools often fail to inform users about tracking, and some users even believe that the tools themselves track them. Bashir et al. [5] analyzed "ad preference managers," which allow users to see and edit the segments companies have inferred about them. In their user study, they found that only 27% of participants believed the shown interests were relevant. Utz et al. [55] analyzed user interactions with cookie banners and found that current implementations often do not allow for meaningful consent, and very few users interact with the banners.

### 9. Conclusion

The ad industry is striving to provide more transparency about its practices and the data it collects. We studied the implementation of new transparency and data access possibilities in the online advertising industry. By analyzing different transparency approaches of ad-tech companies, we identified three types of data that companies provide to users upon request: (1) tracking data, (2) segment data, and (3) raw technical data. Our research shows that not all companies disclose the necessary information, and many do so in a way that is not user-friendly. Participants in our user study struggled to understand and interpret the personal data they received, especially when confronted with low-level technical data. Most users rated the provided data as helpful (>50%), with "segment data" being the most popular category. Furthermore, a large proportion of users (65%) do not trust that companies provide all collected data upon request. When it comes to identifying the companies behind standard ad banners, only 24% of users correctly identified the ad network, while 46% named the advertised product's company as the ad provider.

We surveyed data protection officers in various companies active in the advertisement ecosystem to better understand their perspectives. Participants reported that technical hurdles rooted in the complexity of the ecosystem make it challenging to disclose exact information. Most companies in the interviews and almost half in the survey (42%) stated that they receive fewer SARs than expected, and 63% of participating companies expressed a need for more guidance when designing SAR processes. We also found that companies still primarily focus on compliance rather than transparency for users. Regulatory authorities and industry associations must develop clear guidelines and consistent consumer-facing portals to improve the situation.

### Acknowledgments

This work was partially supported by the Ministry of Culture and Science of the State of North Rhine-Westphalia (MKW grants 005-1703-0021 “MEwM” and Research Training Group NERD.nrw). We would like to thank the anonymous reviewers for their valuable feedback, Christine Utz at Ruhr University Bochum for her efforts in proofreading this work, and Yana Koval at Ruhr University Bochum for transcribing the interviews. We also thank all participants in our user and company studies, and especially the interview partners for their valuable insights. Any findings, conclusions, opinions, or recommendations stated in this work are those of the authors and do not necessarily reflect the views of the participants in the conducted interviews/user studies or the sponsors.

### References

[1] Gunes Acar, Christian Eubank, Steven Englehardt, Marc Juarez, Arvind Narayanan, and Claudia Diaz. 2014. The Web Never Forgets: Persistent tracking mechanisms in the wild. In Proceedings of the 21st ACM Conference on Computer and Communications Security (CCS’14). ACM Press, New York, New York, USA, 674–689.

[2] Alessandro Acquisti, Curtis R. Taylor, and Liad Wagman. 2015. The Economics of Privacy. Journal of Economic Literature 52 (2015), 64.

[3] Amazon. 2018. Amazon’s Mechanical Turk. https://www.mturk.com/ Accessed: 2019-02-05.

[4] Athanasios Andreou, Giridhari Venkatadri, Oana Goga, Krishna P. Gummadi, Patrick Loiseau, and Alan Mislove. 2018. Investigating ad transparency mechanisms in social media: A case study of Facebook’s explanations. In Proceedings of the 2018 Symposium on Network and Distributed System Security (NDSS’18). Internet Society, San Diego, CA, 15.

[5] Muhammad Ahmad Bashir, Umar Farooq, Maryam Shahid, Muhammad Fareed Zaffar, and Christo Wilson. 2019. Quantity vs. Quality: Evaluating User Interest Profiles Using Ad Preference Managers. In Proceedings of the 2019 Symposium on Network and Distributed System Security (NDSS’19). Internet Society, San Diego, CA, 15.

[6] Bettina Berendt. 2012. Data Mining for Information Literacy. In Data Mining: Foundations and Intelligent Paradigms, Dawn E. Holmes and Lakhmi C. Jain (Eds.). Springer-Verlag, Cham, 265–297.

[7] Coline Boniface, Imane Fouad, Nataliia Bielova, Cédric Lauradoux, and Cristiana Santos. 2019. Security Analysis of Subject Access Request Procedures: How to authenticate data subjects safely when they request their data. In Annual Privacy Forum (APF’19). Springer-Verlag, Berlin, Heidelberg, 20.

[8] Virginia Braun and Victoria Clarke. 2012. Thematic analysis. In APA handbook of research methods in psychology, Vol 2: Research designs: Quantitative, qualitative, neuropsychological, and biological. American Psychological Association, Washington, DC, US, 57–71. https://doi.org/10.1037/13620-004

[9] Randolph E Bucklin and Catarina Sismeiro. 2003. A model of web site browsing behavior estimated on clickstream data. Journal of marketing research 40, 3 (2003), 249–267.

[10] Matteo Cagnazzo, Thorsten Holz, and Norbert Pohlmann. 2019. GDPiRated– Stealing Personal Information On- and Off-line. In Proceedings of the 2019 European Symposium on Research in Computer Security (ESORICS’19). Springer-Verlag, Cham, 21.

[11] S. Chiasson, Y. Abdelaziz, and F. Chanchary. 2018. Privacy Concerns Amidst OBA and the Need for Alternative Models. IEEE Internet Computing 22, 2 (2018), 52–61.

[12] CNN Business. 2019. Amazon reportedly employs thousands of people to listen to your Alexa conversations. https://edition.cnn.com/2019/04/11/tech/amazon-alexa-listening/index.html Accessed: 2019-02-05.

[13] CONSENT project. 2017. CONSENT Report Summary. https://cordis.europa.eu/result/rcn/140471_en.html Accessed: 2019-02-05.

[14] Martin Degeling, Christine Utz, Christoper Lentzsch, Henry Hosseini, Florian Schaub, and Thorsten Holz. 2019. We Value Your Privacy... Now Take Some Cookies: Measuring the GDPR’s Impact on Web Privacy. In Proceedings of the 2019 Symposium on Network and Distributed System Security (NDSS’19). Internet Society, San Diego, California, USA, 20.

[15] Mariano Di Martino, Pieter Robyns, Winnie Weyts, Peter Quax, Wim Lamotte, and Ken Andries. 2019. Personal Information Leakage by Abusing the GDPR "Right of Access". In Proceedings of the 15th Symposium on Usable Privacy and Security (SOUPS’19). ACM Press, New York, NY, 16.

[16] Digital Advertising Alliance. 2018. DAA Self-Regulatory Principles. https://digitaladvertisingalliance.org/principles Accessed: 2019-02-05.

[17] Digital Advertising Alliance. 2018. Your Ad Choices. https://optout.aboutads.info/?c=2&lang=EN Accessed: 2019-02-05.

[18] Claire Dolin, Ben Weinshel, Shawn Shan, Chang Min Hahn, Euirim Choi, Michelle L. Mazurek, and Blase Ur. 2018. Unpacking Perceptions of Data-Driven Inferences Underlying Online Targeting and Personalization. In Proceedings of the 2018 Conference on Human Factors in Computing Systems (CHI’18). ACM Press, New York, NY, USA, 1–12.

[19] eMarketer. 2017. Ad Blocking in the US: eMarketer’s Updated Estimates and Forecast for 2014–2018. https://www.emarketer.com/Report/Ad-Blocking-US-eMarketers-Updated-Estimates-Forecast-20142018/2002044 Accessed: 2019-02-05.

[20] Steven Englehardt and Arvind Narayanan. 2016. Online tracking: A 1-million-site measurement and analysis. In Proceedings of the 2016 ACM Conference on Computer and Communications Security (CCS’16). ACM Press, New York, NY, USA, 1388–1401.

[21] IAB Europe. 2018. IAB Europe Transparency & Consent Framework Policies. http://www.iabeurope.eu/tcfdocuments/documents/legal/currenttcfpolicyFINAL.pdf Accessed: 2019-02-05.

[22] European Interactive Digital Advertising Alliance. 2018. Your Online Choices. http://www.youronlinechoices.com Accessed: 2019-02-05.

[23] Benjamin Fabian, Tatiana Ermakova, and Tino Lentz. 2017. Large-scale Readability Analysis of Privacy Policies. In Proceedings of the 2017 Conference on Web Intelligence (WI’17). ACM Press, New York, NY, USA, 18–25.

[24] Uwe Flick. 2014. The SAGE handbook of qualitative data analysis. Sage Publications Ltd., Thousand Oaks, CA, USA.

[25] Samuel Grogan and Aleecia M. McDonald. 2016. Access Denied! Contrasting Data Access in the United States and Ireland. Proceedings on Privacy Enhancing Technologies 3, 23 (07 2016), 191–211.

[26] Mireille Hildebrandt. 2012. The Dawn of a Critical Transparency Right for the Profiling Era. Digital Enlightenment Yearbook 1 (2012), 41–56. http://www.medra.org/servlet/aliasResolver?alias=iospressISBN&isbn=978-1-61499-056-7&spage=41

[27] Inc. 2019. Google Is Absolutely Listening to Your Conversations, and It Confirms Why People Don’t Trust Big Tech. https://www.inc.com/jason-aten/google-is-absolutely-listening-to-your-conversations-it-just-confirms-why-people-dont-trust-big-tech.html Accessed: 2019-02-05.

[28] Interactive Advertising Bureau. 2017. Internet Advertising Revenue Report. https://www.iab.com/wp-content/uploads/2018/05/IAB-2017-Full-Year-Internet-Advertising-Revenue-Report.REV2_.pdf Accessed: 2019-08-27.

[29] Interactive Advertising Bureau Europe. 2017. European Digital Advertising market has doubled in size in 5 years. https://www.iabeurope.eu/research-thought-leadership/resources/iab-europe-report-adex-benchmark-2017-report/ Accessed: 2019-08-27.

[30] Musa J Jafar and Amjad Abdullat. 2009. Exploratory analysis of the readability of information privacy statement of the primary social networks. Journal of Business & Economics Research 7, 12 (2009), 123–142.

[31] Carlos Jensen and Colin Potts. 2004. Privacy Policies As Decision-making Tools: An Evaluation of Online Privacy Notices. In Proceedings of the 2004 Conference on Human Factors in Computing Systems (CHI’04). ACM Press, New York, NY, USA, 471–478.