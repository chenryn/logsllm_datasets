### References

1. Review, 31(1):321, June 2003.
2. N. Brownlee, K. Claffy, and E. Nemeth. DNS Measurements at a Root Server. In *Proc. IEEE Conference on Global Communications (Globecom)*, San Antonio, TX, Nov. 2001.
3. S. Castro, D. Wessels, M. Fomenkov, and K. Claffy. A Day at the Root of the Internet. *ACM SIGCOMM Computer Communication Review*, 38(5):41–46, Oct. 2008.
4. P. Danzig, K. Obraczka, and A. Kumar. An Analysis of Wide-Area Name Server Traffic: A Study of the Internet Domain Name System. *ACM SIGCOMM Computer Communication Review*, 22(4):292, Oct. 1992.
5. M. Felegyhazi, C. Kreibich, and V. Paxson. On the Potential of Proactive Domain Blacklisting. In *Proc. 3rd USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET)*, San Jose, CA, Apr. 2010.
6. T. Holz, C. Gorecki, K. Rieck, and F. C. Freiling. Measuring and Detecting Fast-Flux Service Networks. In *Proc. 16th Annual Network and Distributed System Security Symposium (NDSS)*, San Diego, CA, Feb. 2008.
7. J. Jung, E. Sit, H. Balakrishnan, and R. Morris. DNS Performance and the Effectiveness of Caching. In *Proc. ACM SIGCOMM Internet Measurement Workshop*, San Francisco, CA, Nov. 2001.
8. M. Konte, N. Feamster, and J. Jung. Dynamics of Online Scam Hosting Infrastructure. In *Proc. Passive and Active Measurement (PAM)*, Seoul, South Korea, Apr. 2009.
9. C. Kreibich, C. Kanich, K. Levchenko, B. Enright, G. M. Voelker, V. Paxson, and S. Savage. Spamcraft: An Inside Look At Spam Campaign Orchestration. In *Proc. 2nd USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET)*, Boston, MA, Apr. 2009.
10. PlanetLab. <http://www.planet-lab.org/>.
11. Spamhaus. <http://www.spamhaus.org/>.
12. Domain Name Industry Brief. <http://www.verisigninc.com/DNIB>, 2011.
13. J. M. Spring, L. B. Metcalf, and E. Stoner. Correlating Domain Registrations and DNS First Activity in General and for Malware. In *Proc. Securing and Trusting Internet Names (SATIN)*, Teddington, United Kingdom, Apr. 2011.
14. J. Zupan. *Clustering of Large Data Sets*. John Wiley and Sons, Ltd., 1982.

### Summary Review Documentation for "Monitoring the Initial DNS Behavior of Malicious Domains"

**Authors:** S. Hao, N. Feamster, R. Pandrangi

#### Reviewer #1
**Strengths:**
- Unique dataset coupled with thorough analysis.
- The conclusions about tainted address blocks are interesting.

**Weaknesses:**
- The paper does not develop or evaluate a new technique for predicting whether a new domain is spam or not, though this is likely out of scope for a short paper.

**Comments to Authors:**
- This is a well-written paper based on a relatively unique data set. There are no real surprises, but the data is analyzed and presented well.
- It is not clear how useful the observations about spam domains are. For instance, knowing that most spam domains are not immediately used (Figure 1) and that the distribution for MX/A/NS records of spam versus legitimate domains is different (Figure 2) is interesting but does not lead to a test for whether a single new domain is legitimate or not.
- Perhaps there is a method or a way to associate a legitimate-use probability with a domain based on its initial behavior, but such a technique was not developed or evaluated in this paper.
- In this short paper, we investigated the potential for using DNS lookup patterns for detection, as the main focus was to measure different features and leave the detection system for future work. We added a paragraph in the conclusion section to discuss future work on detecting malicious versus legitimate domains.
- In the absence of such a method, the paper does a competent job of presenting the data cleanly and drawing initial conclusions.

#### Reviewer #2
**Strengths:**
- The topic of the paper is still relevant, and I like the combination of datasets and features the authors study.

**Weaknesses:**
- The piece is quite rushed and in parts unpleasant to read.
- The authors miss relevant related work, and each of the three features they use has been touched in previous work.

**Comments to Authors:**
- The first finding is not novel. Check the LEET 2009 Spamcraft paper for a plot documenting delays from registration time to time of use.
  - **Response:** We have added this paper to the references, although our findings and conclusions differ from those in the Spamcraft paper. The previous work sees similar delays between registration and first lookup for a single campaign, but we focus on the time delay between registration and attack for .com and .net domains to investigate the possibility of early detection before the attack occurs.
- Your second finding isn’t particularly novel either. The proactive domain blacklisting paper from LEET 2010 is clearly related, as its authors tried to predict malicious domain use from the patterns of registration and the infrastructure touched by a domain’s hosting. I’m surprised you don’t cite it. You should also cite Spamhaus’ DBL, as it too is a predictive spam blacklist.
  - **Response:** We have added the paper “On the Potential of Proactive Domain Blacklisting” from LEET 2010 to the references. We have already referred to Spamhaus in Section 3, so there is no need to refer to it again.
- The third finding is interesting but has also been covered in previous work; see Spring et al.’s paper at the SATIN workshop.
  - **Response:** We have added the paper “Correlating Domain Registrations and DNS First Activity in General and for Malware” (Securing and Trusting Internet Names 2011) to the references. This paper reports some findings similar to ours. They examined the delay between the registration of a malware domain and the first successfully resolved response in DNS traffic.
- Given that all three features are promising, I would suggest you actually try to build a predictor for malicious domains so you can report on its accuracy—it would be interesting (particularly its real-time aspects), and I am pretty sure it would work quite well.
  - **Response:** We will consider this for future work.

**Specific Comments:**
- **Sec. 2.1:** “When a DNS domain is registered, several basic entries are inserted to refer to the services for the domain.” Please make the writing more active—registered by whom, inserted where?
  - **Response:** We changed this sentence to “When an entity registers a DNS domain, domain name registries insert several basic entries into the zone files to refer to the services for the domain.”
- **Sec. 3:** Again, passive voice: “the source IP addresses were aggregated into /24 subnets and the TLD name servers recorded the number of queries for each domain.” Is this something you did, or do Verisign’s systems provide that?
  - **Response:** We changed this to “Verisign’s systems aggregated the source IP addresses into /24 subnets for logging, and the TLD name servers recorded querying subnets each day.”
- **How do the query record entries scale?** It seems that the number of /24s must be huge for popular domains...
  - **Response:** Since we recorded the querying /24s (not the individual queries), the data for each domain has an upper limit (at most the number of all /24s). Our work focuses on newly registered domains, so fewer domains would get huge queries in a short time.
- **Did you build your own PlanetLab experiment or did you use CoDNS?**
  - **Response:** We designed and built our own experimental platform. We must collect different types of records, including A, NS, and MX records, so we have built and deployed our own system to perform the tasks of resolving the domain names.
- **Why would spammers care about their domains’ MX records?**
  - **Response:** When considering email spam, attackers do not want messages to bounce back if someone replies. The MX-type could be set up anyway. If spammers do not care about the MX records, that could be a pattern itself, as legitimate domains do care to configure correct MX records.
- **I can’t make out in Sec. 4.2 whether the NS record alone would suffice in detecting malice-related patterns. Per the above papers and my reading of Table 2(b), I am virtually certain they do. If so, you do not need to conduct A-record lookups as the NSs are in the zone file, which obviously simplifies the process.**
  - **Response:** We probed for NS-type and A-type records for two reasons:
    1. To ensure comprehensive data collection.
    2. To validate the consistency of the NS records with the A records.

#### Reviewer #3
**Strengths:**
- Interesting measurements and conclusions.
- The proposal to use these conclusions to detect malicious domains early seems promising.

**Weaknesses:**
- I do not think that the conclusions are new.
- The proposal (of how to use these conclusions) is not clear.

**Comments to Authors:**
- My main concern is that, despite being useful and interesting, the conclusions are not new. For instance, it is known that machines that participate in malicious activities tend to be clustered (“Observed structure of addresses in IP traffic”, IEEE/ACM Trans. on Networking, Dec. 2006).
  - **Response:** We did not make any changes to the paper, as the paper “Observed structure of addresses in IP traffic” is not directly related to our work. Our work focuses on DNS analysis, and the traffic monitoring did not occur near the root DNS resolvers.
- Section 5 is confusing to the non-expert. The paper is supposed to be looking at the characteristics of malicious domains *before* they are involved in malicious activity. But then, what does “early lookup behavior” refer to? Are malicious domains looked up before they are involved in malicious activity, i.e., before they appear in spam messages? This is what I thought at first, but then the following comment confused me: In Section 5.1, it says that the reason why malicious domains are looked up by the same resolvers is that a user clicking on one spam URL is likely to click on another and/or malicious domains may be participating in the same spamming campaigns. This comment implies that we are talking about lookups resulting from spam, i.e., a point in time after the malicious domains have started demonstrating malicious behavior. Hence, it is not clear how this lookup-clustering characteristic could be used to detect malicious domains *early*.
  - **Response:** We have added more explanation in Section 5: “Queries to a malicious domain may signal the onset of an attack, and the abnormal pattern in the global DNS traffic could help to detect the attack campaign in its infancy.”
- Section 4 is clearer in this respect, i.e., it says that malicious domains tend to be served by infrastructure that uses specific address blocks and few “tainted” ASes, which are rarely used by legitimate domains—implying that an early detection system could investigate domains that are served by these few tainted ASes. This makes sense. However, the numbers in Table 3 (on which this conclusion is based) are confusing: Apparently, the AS mostly used by malicious domains is the Chinanet Backbone AS. My understanding is that this AS hosts a large fraction of the Chinese Internet infrastructure. Hence, if we consider this AS “tainted,” a large fraction of legitimate Chinese domains will have to be investigated as suspect of malicious behavior. This does not sound right.
  - **Response:** We didn’t try to build a detection system and evaluate its performance in this paper. Regarding the “Chinanet backbone” case, if an AS has a large mixture of good and bad domains, that AS should be handled as a special case, as blocking the entire AS is not feasible. In such cases, using other auxiliary patterns to distinguish malicious from legitimate domains (e.g., lookup patterns) may be necessary. Even if a detection method simply suspected all domains involved in “Chinanet backbone,” based on our findings in Table 2(a), it saves effort to investigate 10% of legitimate domains compared to all domains.

#### Reviewer #4
**Strengths:**
- The problem is important, and the paper presents some interesting new insights about the DNS dynamics of malware sites.
- Unique datasets from the TLD servers.

**Weaknesses:**
- Not sure how unbiased the data set is.

**Comments to Authors:**
- I think the problem is important, and the authors do a good job in the paper showing evidence that often there is not much lag between a domain getting registered and beginning to send spam. I like the paper overall.
- The authors mention the use of Yahoo mail servers for collecting timestamps. It might be good to elaborate on what exact data they had for this purpose.
  - **Response:** We added the following clarification: “Yahoo! Inc. provides the received time of the email messages and the URLs contained in the messages.”
- Finding 4.1 is not intuitive. I think you may want to say the contrapositive, that 45% of malicious domains appeared within a day, if you want this finding to be reflective of the early detectability. The sentences following this finding also need to be rephrased properly; right now they are confusing.
  - **Response:** We stated that “55% of the malicious domains appeared in spam campaigns more than one day after they were registered,” because the intention is to check what the buffer time people have to detect a bad domain before it is used in malicious activity.
- I would use benign as an opposite of malicious. Legitimate is not accurate since all domains are legitimate since they have been registered with the registrar (and not hijacked, which is yet another study).
  - **Response:** We do not agree with this suggestion and have not made the change in the paper. It is much clearer to use “legitimate,” as this corresponds with standard parlance in the literature (cf. “legitimate” email vs. spam).
- Isn’t the non-uniform distribution of IP addresses across the NS, MX, and A records an artifact of the data you have? Presumably, if you have only a partial dataset, you would potentially see only some attack IPs.
  - **Response:** We arguably have the most representative dataset possible; it is one of the most expansive datasets that it is possible to obtain: .com (and .net) is a good representative of TLD, and the data have big coverage already. It is true that the particular IP blocks will be different for domains under different TLDs, but they will have similar patterns as we see in .com (and .net). We added some statistics in Section 3, e.g., “.com and .net account for over 45% of registered domain names on the Internet.”
- I think 2(a) is not in line with the finding 4.3 and it is not clearly explained. I see very little difference between the benign and malicious domains. MX/A records, I can see some difference, but not so much in 2(a).
  - **Response:** The MX and A records of malicious domains are still relatively concentrated in one or two particular ASes (about 30% of the records reside in these ASes). Although some ASes appear in both sets, we are not suggesting that this feature alone would be sufficient to detect bad domains. In some cases, ASes predominantly appear in one list or the other, and this information will be useful for establishing a prior.
- I am not sure if the query data collected using recursive queries at the TLD server is unbiased between malicious and benign domains.
  - **Response:** This comment does not make sense. We have already emphasized in Section 3: “Verisign deploys multiple TLD name servers to resolve second-level domain names, and we collected the logs of querying /24s from all servers for analysis.”

#### Reviewer #5
**Strengths:**
- Interesting insights from a great data set (top-level domain DNS request volume).

**Weaknesses:**
- Interesting observation, but can this be turned into some practical policies to blacklist malicious domains?
- Data set only available to the owner of top-level domain managers.
- Observation only based on .com and .net. Is this representative?

**Comments to Authors:**
- The main weakness is that it is not clear how to turn your findings into some practical policies to blacklist domains. You clearly show differences between legitimate and malicious domains, but can you use this information in practice? Would it be easy for domains to avoid the new blacklisting rules identified? I understand this is a short paper, and I am hoping that you will cover this in future work.
  - **Response:** We will consider this for future work.
- Your work is based on .com and .net data. How representative is this? Could you comment on some statistics to say X% of spams or blacklisted domains are .com or .net? Is it 90% or 2%?
  - **Response:** Based on analysis of our spam trap data, we see that around 40% of unique second-level domains reside under .com and .net. These figures are derived from all second-level domains in the spamtrap email.
- Your analysis of /24 reminded me of a work that you did not reference: S. Venkataram, A. Blum, D. Song, S. Sen, and O. Spatscheck, “Tracking dynamic sources of malicious activity at Internet-scale,” in Proc. NIPS, 2009.
  - **Response:** This paper might be a useful clustering method if we were designing a detection scheme, but since our work is not mainly to develop a new clustering algorithm, we do not think this paper is particularly related to our work.
- Regarding Figure 1, do you have finer-grain data to show what happens during the first couple of hours for the other 45% of the domains?
  - **Response:** Because the active resource-record probing and the lookup data are aggregated on a daily basis, analyzing the data on a more fine-grained basis is not possible.
- Could you add a candle chart on Figure 4 to show the distribution of legitimate traffic to see how practical a policy based on this metric would work? e.g., do a lot of legitimate domains exhibit the same pattern as the malicious domains? You just show the differences between the means.
  - **Response:** We included standard error in the figure for both malicious and legitimate domains. Because the value for legitimate domains is comparatively small, these values might be difficult to see in the figure.

### Response from the Authors

The review comments fall into three categories:

1. **Some related work is not included, and the differences from our paper are not described carefully.**
   - To correct this concern, we added most of the related papers pointed out by the reviewers, including “On the Potential of Proactive Domain Blacklisting” from LEET 2010 and “Correlating Domain Registrations and DNS First Activity in General and for Malware” from the SATIN 2011 workshop.
   - There are three major differences in our work from earlier studies: we focus on newly registered second-level domains, the DNS records are actively probed instead of passively monitored, and we observe the lookup pattern at the TLD name servers (with a global view from all /24 networks across the Internet).
   - We did not include several of the papers that reviewers mentioned, as they do not appear to be related to our paper.

2. **It is unclear whether the DNS patterns could be eventually developed into a detection system.**
   - Since the intention of our work is to reveal DNS characteristics that could shed light on identifying different patterns for malicious and legitimate domains, the paper does not actually design a detection system based on the features (which is our next step).
   - We changed the text to make the claim clear, e.g., adding a paragraph in the conclusion section to state detection algorithms as future work.

3. **Some details of the data and the findings need more clarification.**
   - To present the Verisign data more clearly, we checked the representativeness of the .com and .net domains and added more details to the paper about the collection process.
   - We also added extra explanation explaining how we correlate second-level domains appearing in spamtrap URLs with those that appear in a Yahoo! email trace.