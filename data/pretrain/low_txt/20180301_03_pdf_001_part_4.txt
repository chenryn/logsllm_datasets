### 5.2.0.1 Hierarchical Heavy Hitters
A generalization of the heavy hitter problem is finding Hierarchical Heavy Hitters (HHH) [7], which assumes that the items are leaves in a hierarchy of depth \( h \). The goal is to identify all nodes in the hierarchy that are heavy hitters, after discounting the contribution of any descendant heavy hitter nodes. Using our Count-Min (CM) sketch, the solution provided in [7] for the turnstile model can be improved from \( O(h \log \frac{1}{\epsilon}) \) space and time per update to \( O(h \log \frac{1}{\epsilon}) \) space and \( O(h \log \frac{1}{\epsilon}) \) time per update.

### 6 Comparison of Sketch Techniques
We provide a common framework to summarize known sketch constructions and compare their time and space requirements for fundamental queries: point, range, and inner products.

#### Summary of Known Sketch Constructions
- **Tug-of-War Sketches** [2]: These sketches use 4-wise independent random hash functions \( g \) mapping items to \(\{+1, -1\}\). The \( j \)-th entry of the sketch, a vector of length \( O(\frac{1}{\epsilon^2} \log \frac{1}{\epsilon}) \), is defined as \( \sum_i g_j(i) \). This structure was applied to computing inner products with additive error \( \epsilon \|a\|_2 \|b\|_2 \) [1, 20]. In [20], the authors used these sketches to compute large wavelet coefficients, showing how the structure allows point queries to be computed up to an additive error of \( \epsilon \|a\|_2 \). For range sums, range-summable random variables are used, but this incurs an additional \( O(\log n) \) factor in time and space, with worse error guarantees for larger ranges: \( \epsilon (r - l + 1) \|a\|_1 \).
- **Pairwise Independence for Point Queries** [5]: Pairwise independence suffices for tug-of-war sketches. The authors used a second set of hash functions \( h_j \) to spread the effect of high-frequency items in their Count Sketch, achieving the same space bounds but improving the time bound to \( O(\log \frac{1}{\epsilon}) \) for updating the sketch.
- **Random Subset Sums** [21]: These use 2-universal hash functions \( h \) mapping items to \(\{0, 1\}\), and the \( j \)-th entry of the sketch is maintained as \( \sum_{i=1}^n a_i h_j(i) \).

The asymptotic space and time bounds for different techniques in terms of their dependence on \( \epsilon \) are summarized in Figure 2.

#### Common Framework for Sketch Constructions
All sketching techniques, including the one proposed in this paper, can be described in a common way:
1. They can be viewed as linear projections of the vector \( a \) with appropriately chosen random vectors.
2. The computation of these linear projections is similar across all methods.

Define a sketch as a two-dimensional array of dimension \( w \) by \( d \). Let \( h_1, \ldots, h_d \) be pairwise independent hash functions mapping from \(\{1, \ldots, n\}\) to \(\{1, \ldots, w\}\), and let \( g_1, \ldots, g_d \) be another set of hash functions whose range and randomness vary by construction. The \((j, k)\)-th entry of the sketch is defined as:

\[
\sum_{i: h_k(i) = j} a_i g_k(i)
\]

The content of the sketch for each technique is specified by the parameters \( w \), \( d \), and \( g \). The update time for each sketch is \( O(d) \) computations of \( g \) and \( h \), and the space requirement is dominated by \( O(wd) \) counters, provided the hash functions can be stored efficiently.

- **Tug-of-War Sketches**: \( w = 1 \), \( d = O(\frac{1}{\epsilon^2} \log \frac{1}{\epsilon}) \), \( g(i) \) is \(\{+1, -1\}\) with 4-wise independence.
- **Count Sketches**: \( w = O(\frac{1}{\epsilon^2}) \), \( d = O(\log \frac{1}{\epsilon}) \), \( g(i) \) is \(\{+1, -1\}\) with 2-wise independence.
- **Random Subset Sums**: \( w = 2 \), \( d = 24 \log \frac{1}{\epsilon} \), \( g(i) = 1 \).
- **Count-Min Sketches**: \( w = e \), \( d = \ln \frac{1}{\epsilon} \), \( g(i) = 1 \).

#### Other Sketch Constructions
- **L1 Difference Sketch** [14]: Extends the tug-of-war construction to compute L1 differences, demonstrating efficient range sums of 4-wise random variables.
- **Stable Distributions** [23]: Pioneered by Indyk, using stable distributions for sketch computations to compute Lp norms of vectors presented as a sequence of updates.
- **Uniscan Algorithm** [13] and **Parallel Multistage Filters** [11]: These structures do not approximate values but return binary answers about whether an item has exceeded a certain threshold. They require only positive updates and use fully independent hash functions, which is prohibitive in principle.

### 7 Conclusions
We have introduced the Count-Min (CM) sketch and shown how to estimate fundamental queries such as point, range, or inner product queries, as well as solve more sophisticated problems like quantiles and heavy hitters. Our CM sketch improves the space and/or time bounds of previously known solutions, typically from \( O(\frac{1}{\epsilon^2}) \) to \( O(\frac{1}{\epsilon}) \), which is significant in real applications. The CM sketch is simple and likely to find many applications, including hardware solutions for these problems.

We have recently applied these ideas to change detection in data streams [9] and believe they can improve the time and space bounds for constructing approximate wavelet and histogram representations of data streams [19]. The CM sketch can also be naturally extended to solve problems on streams that describe multidimensional arrays rather than unidimensional arrays.

However, the CM sketch is not effective for computing the norms of data stream inputs, which have applications in computing correlations between data streams and tracking the number of distinct elements. Designing extremely simple, practical sketches for such applications remains an open problem.

### References
[1] N. Alon, P. Gibbons, Y. Matias, and M. Szegedy. Tracking join and self-join sizes in limited storage. In Proceedings of the Eighteenth ACM Symposium on Principles of Database Systems (PODS’99), pages 10–20, 1999.

[2] N. Alon, Y. Matias, and M. Szegedy. The space complexity of approximating the frequency moments. In Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, pages 20–29, 1996. Journal version in Journal of Computer and System Sciences, 58:137–147, 1999.

[3] B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom. Models and issues in data stream systems. In Proceedings of Symposium on Principles of Database Systems (PODS), pages 1–16, 2002.

[4] Z. Bar-Yossef, T. S. Jayram, R. Kumar, D. Sivakumar, and L. Trevisian. Counting distinct elements in a data stream. In Proceedings of RANDOM 2002, pages 1–10, 2002.

[5] M. Charikar, K. Chen, and M. Farach-Colton. Finding frequent items in data streams. In Proceedings of the International Colloquium on Automata, Languages, and Programming (ICALP), pages 693–703, 2002.

[6] G. Cormode, M. Datar, P. Indyk, and S. Muthukrishnan. Comparing data streams using Hamming norms. In Proceedings of the 28th International Conference on Very Large Data Bases, pages 335–345, 2002. Journal version in IEEE Transactions on Knowledge and Data Engineering 15(3):529–541, 2003.

[7] G. Cormode, F. Korn, S. Muthukrishnan, and D. Srivastava. Finding hierarchical heavy hitters in data streams. In International Conference on Very Large Databases, pages 464–475, 2003.

[8] G. Cormode and S. Muthukrishnan. What’s hot and what’s not: Tracking most frequent items dynamically. In Proceedings of ACM Principles of Database Systems, pages 296–306, 2003.

[9] G. Cormode and S. Muthukrishnan. What’s new: Finding significant differences in network data streams. In Proceedings of IEEE Infocom, 2004.

[10] A. Dobra, M. Garofalakis, J. E. Gehrke, and R. Rastogi. Processing complex aggregate queries over data streams. In Proceedings of the 2002 ACM Sigmod International Conference on Management of Data, pages 61–72, 2002.

[11] C. Estan and G. Varghese. New directions in traffic measurement and accounting. In Proceedings of ACM SIGCOMM, volume 32, 4 of Computer Communication Review, pages 323–338, 2002.

[12] C. Estan and G. Varghese. Data streaming in computer networks. In Proceedings of Workshop on Management and Processing of Data Streams, http://www.research.att.com/conf/mpds2003/schedule/estanV.ps, 2003.

[13] M. Fang, N. Shivakumar, H. Garcia-Molina, R. Motwani, and J. D. Ullman. Computing iceberg queries efficiently. In Proceedings of the Twenty-fourth International Conference on Very Large Databases, pages 299–310, 1998.

[14] J. Feigenbaum, S. Kannan, M. Strauss, and M. Viswanathan. An approximate L1-difference algorithm for massive data streams. In Proceedings of the 40th Annual Symposium on Foundations of Computer Science, pages 501–511, 1999.

[15] P. Flajolet and G. N. Martin. Probabilistic counting. In 24th Annual Symposium on Foundations of Computer Science, pages 76–82, 1983. Journal version in Journal of Computer and System Sciences, 31:182–209, 1985.

[16] M. Garofalakis, J. Gehrke, and R. Rastogi. Querying and mining data streams: You only get one look. In Proceedings of the ACM SIGMOD International Conference on Management of Data, 2002.

[17] P. Gibbons and Y. Matias. Synopsis structures for massive data sets. DIMACS Series in Discrete Mathematics and Theoretical Computer Science, A, 1999.

[18] P. Gibbons and S. Tirthapura. Estimating simple functions on the union of data streams. In Proceedings of the 13th ACM Symposium on Parallel Algorithms and Architectures, pages 281–290, 2001.

[19] A. Gilbert, S. Guha, P. Indyk, Y. Kotidis, S. Muthukrishnan, and M. Strauss. Fast, small-space algorithms for approximate histogram maintenance. In Proceedings of the 34th ACM Symposium on Theory of Computing, pages 389–398, 2002.

[20] A. Gilbert, Y. Kotidis, S. Muthukrishnan, and M. Strauss. Surfing wavelets on streams: One-pass summaries for approximate aggregate queries. In Proceedings of the 27th International Conference on Very Large Data Bases, pages 79–88, 2001. Journal version in IEEE Transactions on Knowledge and Data Engineering, 15(3):541–554, 2003.

[21] A. C. Gilbert, Y. Kotidis, S. Muthukrishnan, and M. Strauss. How to summarize the universe: Dynamic maintenance of quantiles. In Proceedings of the 28th International Conference on Very Large Data Bases, pages 454–465, 2002.

[22] M. Greenwald and S. Khanna. Space-efficient online computation of quantile summaries. SIGMOD Record (ACM Special Interest Group on Management of Data), 30(2):58–66, 2001.

[23] P. Indyk. Stable distributions, pseudorandom generators, embeddings, and data stream computation. In Proceedings of the 40th Symposium on Foundations of Computer Science, pages 189–197, 2000.

[24] W. B. Johnson and J. Lindenstrauss. Extensions of Lipshitz mappings into Hilbert space. Contemporary Mathematics, 26:189–206, 1984.

[25] G. S. Manku, S. Rajagopalan, and B. G. Lindsay. Approximate medians and other quantiles in one pass and with limited memory. In Proceedings of the ACM SIGMOD International Conference on Management of Data, pages 426–435, 1998.

[26] G. S. Manku and R. Motwani. Approximate frequency counts over data streams. In Proceedings of the 28th International Conference on Very Large Data Bases, pages 346–357, 2002.

[27] R. Motwani and P. Raghavan. Randomized Algorithms. Cambridge University Press, 1995.

[28] S. Muthukrishnan. Data streams: Algorithms and applications. In ACM-SIAM Symposium on Discrete Algorithms, http://athos.rutgers.edu/muthu/stream-1-1.ps, 2003.

[29] N. Thaper, P. Indyk, S. Guha, and N. Koudas. Dynamic multidimensional histograms. In Proceedings of the ACM SIGMOD International Conference on Management of Data, pages 359–366, 2002.

[30] D. Woodruff. Optimal space lower bounds for all frequency moments. In ACM-SIAM Symposium on Discrete Algorithms, 2004.