### Security and Performance Analysis of Refactored Programs

#### Security Improvement
The results in Table V indicate that the refactored `su` cannot execute any of the four modeled attacks for at least 12% of its execution time. Additionally, since ROSA (the analysis tool) is unable to deliver a verdict on attacks 1 and 2 for privilege sets 6 and 7 within our 5-hour limit, we assume that the refactored `su` is invulnerable to all the attacks for an additional 87% of its execution time. This assumption is based on the observation that ROSA's analysis often takes longer when the attacks are impossible, as it must search the entire state space. Therefore, we believe that the refactored `su` is invulnerable for nearly 99% of its execution.

#### Vulnerability Analysis
Table III shows that `su` is vulnerable with all privilege sets except the empty one. The last privilege to remain active is `CAP_SETUID`. Similar to `passwd`, the PrivAnalyzer results help identify which privileges increase the risk of privilege escalation, guiding developers on where to focus their refactoring efforts.

### Security Refactoring Lessons

Our refactoring work provides two key insights into writing privileged applications on Linux:

1. **Change Credentials Early:**
   We observed that many privileged operations in programs simply require a process running as one user to create or manipulate resources owned by another user. However, Linux privileges such as `CAP_DAC_OVERRIDE` allow a process to manipulate files owned by any user. A better approach is to use `CAP_SETUID` and `CAP_SETGID` to provide the process with two sets of credentials: one in the real UID and GID, and another in the saved UID and GID. This allows the process to switch between the effective UID/GID and the saved UID/GID without needing elevated privileges, often allowing the removal of other privileges like `CAP_CHOWN`, `CAP_DAC_READ_SEARCH`, and `CAP_DAC_OVERRIDE`.

2. **Create Special Users for Special Files:**
   On Ubuntu, root owns many system configuration files, providing access to nearly all sensitive system files. For example, a password-changing program shouldn't be able to read and write device files, but it can on Ubuntu. By having different special users own different files, privileged programs can configure themselves to only access the files they need. For instance, changing `/etc/shadow` to be owned by a special `etc` user restricts access appropriately.

### Performance Evaluation

We evaluated the performance of ROSA, the bounded model checker in PrivAnalyzer, using the programs listed in Table II. Our experiments were conducted on a Dell Precision 3620 workstation with a 3.6 GHz Intel i7-7770 processor, 16 GB of RAM, and a 1 TB TOSHIBA DT01ACA1 hard disk running Ubuntu 16.04. We used the `time` system call to report the sum of user and system time in seconds that ROSA takes to reach a verdict. Each test was run 10 times to compute the average search time and standard deviation.

Figures 5, 6, 7, 8, and 9 show that, in most experiments, ROSA needs less than 2 seconds to reach a verdict. However, in one case (where `su` has dropped all of its privileges), ROSA takes almost 40 seconds to determine that `su` cannot read or write `/dev/mem`. This delay is likely due to the large search space, as numerous system calls such as `open()`, `setresuid()`, `chown()`, and `chmod()` are relevant. For failed attacks, ROSA must determine that all combinations of these system calls do not lead to a compromise. In contrast, fewer system calls are relevant to attacks 3 and 4, which involve killing other processes or binding to privileged ports, resulting in a smaller state space for ROSA to search.

Figures 10 and 11 show ROSA's performance when analyzing the refactored `passwd` and `su` programs. Generally, ROSA takes longer to reach a verdict for the refactored programs. For example, ROSA takes almost 12 hours to determine that the refactored `passwd` cannot write to `/dev/mem` when executing with privilege set 3 (as shown in Table V). There are cases where the operating system kills ROSA due to high memory consumption after 3 days of execution, and we do not get a response. This behavior is likely due to the large state space to explore. Attacks 1 and 2 involve a larger number of system calls and UID/GID values, requiring ROSA to try every combination to determine if the attack can succeed.

### Related Work

**Zanin et al. [9]** propose an automatic tool for evaluating security policy configurations for SELinux. SELinux is a system that allows administrators to specify a set of rules enforced by the Linux kernel for access control decisions. Zanin et al. formalize the semantics of the configuration constructs and develop a tool that decides whether access to a specific object by a given subject under the configured policy is possible. Their tool, similar to PrivAnalyzer, can reach verdicts about the possibility of attacks allowed under a specific set of configuration rules. However, unlike our work, they do not quantify the vulnerability window of the system under a specific configuration.

**Chen et al. [10]** developed VulSAN, a tool that quantifies the quality of protection offered by mandatory access control systems. Given an attack objective and the attacker’s initial resources, VulSAN identifies minimal sets of programs that, if compromised, can lead to the attack succeeding. VulSAN maps the security policies and the state of the system to Prolog facts and generates a graph for each attack scenario. Each path in the graph represents a sequence of different program executions. While both systems evaluate important security metrics, VulSAN relies on a MAC scheme and cannot model dynamic changes of access rights. PrivAnalyzer evaluates the vulnerability of a program in a discretionary access control system, accounting for dynamic changes in the access control policy.

### Future Work

Several directions for future work include:

1. **Enhancing PrivAnalyzer to Model Additional Operating System Privilege Models:**
   We plan to extend PrivAnalyzer to model additional operating system privilege models, such as Solaris privileges [28] and Capsicum [5], to compare their efficacy with Linux privileges.

2. **Modeling Additional Attacks and Defenses:**
   We will model additional attacks and defenses. For example, our current evaluation assumes that attacks can corrupt application control-flow and data-flow. With enhancements to PrivAnalyzer, we can model attacks weakened by defenses such as control-flow integrity [29] and code-pointer integrity [30] and determine what types of attacks a weakened attacker can perform.

### Conclusions

This paper presents PrivAnalyzer, an automated tool that measures the risk posed by privileged programs. PrivAnalyzer adds two new components to the AutoPriv compiler: the ChronoPriv vulnerability analyzer and the ROSA bounded model checker. Using PrivAnalyzer, we measured the efficacy of using Linux privileges and showed that enabling, disabling, and removing privileges from otherwise unmodified applications does not significantly improve their security posture. We then refactored two privileged Linux programs to better leverage Linux privileges and used PrivAnalyzer to measure the security improvement. From this exercise, we learned two key approaches for using Linux privileges more effectively.

### Acknowledgements

We thank the anonymous reviewers for their insightful feedback. This work was funded by NSF award CNS-1463870.

### References

[1] M. E. Russinovich and D. A. Solomon, Microsoft Windows Internals, Fourth Edition: Microsoft Windows Server(TM) 2003, Windows XP, and Windows 2000 (Pro-Developer). Redmond, WA, USA: Microsoft Press, 2004.

[2] D. P. Bovet and M. Cesati, Understanding the LINUX Kernel, 2nd ed. Sebastopol, CA: O’Reilly, 2002.

[3] M. K. McKusick, G. V. Neville-Neil, and R. N. M. Watson, The Design and Implementation of the FreeBSD Operating System, 2nd ed. Addison-Wesley Professional, 2014.

[4] J. L. Berger, J. Picciotto, J. P. L. Woodward, and P. T. Cummings, “Compartmented mode workstation: Prototype highlights,” IEEE Trans. Softw. Eng., vol. 16, no. 6, pp. 608–618, Jun. 1990.

[5] R. N. M. Watson, J. Anderson, B. Laurie, and K. Kennaway, “Capsicum: Practical capabilities for UNIX,” in Proceedings of the 19th USENIX Conference on Security, ser. USENIX Security’10. Berkeley, CA, USA: USENIX Association, 2010, pp. 3–3.

[6] S. E. Hallyn and A. G. Morgan, “Linux capabilities: Making them work,” in Proceedings of The Linux Symposium, Ottawa, Canada, July 2008.

[7] linuxcontainers.org, “Linux Containers,” https://linuxcontainers.org/, [Online; accessed 28-March-2019].

[8] D. Documentation, “Docker,” https://docs.docker.com/engine/security/security/, [Online; accessed 28-March-2019].

[9] G. Zanin and L. V. Mancini, “Towards a formal model for security policies specification and validation in the selinux system,” in Proceedings of the Ninth ACM Symposium on Access Control Models and Technologies, ser. SACMAT ’04. New York, NY, USA: ACM, 2004, pp. 136–145. [Online]. Available: http://doi.acm.org/10.1145/990036.990059

[10] H. Chen, N. Li, and Z. Mao, “Analyzing protection quality of security-enhanced operating systems,” in Proceedings of the 10th Annual Information Security Symposium, ser. CERIAS ’09. West Lafayette, IN: CERIAS - Purdue University, 2009, pp. 8:1–8:1. [Online]. Available: http://dl.acm.org/citation.cfm?id=2788357.2788369

[11] X. Hu, J. Zhou, S. Gravani, and J. Criswell, “Transforming code to drop dead privileges,” in 2018 IEEE Cybersecurity Development (SecDev), vol. 00, Sept 2018, pp. 45–52. [Online]. Available: doi.ieeecomputersociety.org/10.1109/SecDev.2018.00014

[12] M. Clavel, F. Durán, S. Eker, P. Lincoln, N. Martí-Oliet, J. Meseguer, and C. Talcott, All About Maude - a High-performance Logical Framework: How to Specify, Program and Verify Systems in Rewriting Logic. Berlin, Heidelberg: Springer-Verlag, 2007.

[13] Argus Systems Group, Inc., “Security features programmer’s guide,” Savoy, IL, September 2001.

[14] Solar Designer, “return-to-libc attack,” August 1997, https://insecure.org/sploits/linux.libc.return.lpr.sploit.html [Online; accessed 11-March-2019].

[15] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer, “Non-control-data Attacks Are Realistic Threats,” in Proceedings of the 14th USENIX Security Symposium (SEC), Baltimore, MD, 2005, pp. 12–12. [Online]. Available: http://dl.acm.org/citation.cfm?id=1251398.1251410

[16] N. Provos, “Improving host security with system call policies,” in 12th USENIX Security Symposium, August 2003.

[17] A. One, “Smashing the Stack for Fun and Profit,” Phrack, vol. 7, November 1996, http://www.phrack.org/issues/49/14.html [Online; accessed 11-March-2019].

[18] H. Shacham, “The Geometry of Innocent Flesh on the Bone: Return-into-libc without Function Calls (on the x86),” in Proceedings of the 14th ACM SIGSAC Conference on Computer and Communications Security (CCS), Alexandria, VA, October 2007, pp. 552–561.

[19] C. Lattner and V. Adve, “LLVM: A compilation framework for lifelong program analysis & transformation,” in Proceedings of the International Symposium on Code Generation and Optimization: Feedback-directed and Runtime Optimization, ser. CGO’04. Palo Alto, CA: IEEE Computer Society, 2004, pp. 75–86. [Online]. Available: http://dl.acm.org/citation.cfm?id=977395.977673

[20] C. Lattner et al., “LLVM Language Reference Manual,” January 2016. [Online]. Available: http://releases.llvm.org/3.7.1/docs/LangRef.html

[21] “Linux programmer’s manual: mem(4),” November 1992.

[22] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham, and M. Winandy, “Return-oriented Programming Without Returns,” in Proceedings of the 17th ACM SIGSAC Conference on Computer and Communications Security (CCS), Chicago, IL, October 2010.

[23] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and A.-R. Sadeghi, “Just-In-Time Code Reuse: On the Effectiveness of Fine-Grained Address Space Layout Randomization,” in Proceedings the 34th IEEE Symposium on Security and Privacy (S&P), San Francisco, CA, May 2013, pp. 574–588. [Online]. Available: http://dx.doi.org/10.1109/SP.2013.45

[24] D. A. Wheeler, “SLOCCount Version 2.26,” 2004.

[25] “Apachebench: A complete benchmarking and regression testing suite. http://freshmeat.net/projects/apachebench/,” July 2003.

[26] S. Smalley, “Configuring the SELinux policy,” NSA, Tech. Report, February 2005.

[27] H. Vijayakumar, J. Schiffman, and T. Jaeger, “Integrity walls: Finding attack surfaces from mandatory access control policies,” in 7th ACM Symposium on Information, Computer, and Communications Security (ASIACCS), May 2012.

[28] J. Mauro and R. McDougall, Solaris Internals: Core Kernel Architecture. Prentice Hall PTR, 2000.

[29] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-flow integrity principles, implementations, and applications,” ACM Transactions on Information Systems Security, vol. 13, pp. 4:1–4:40, November 2009. [Online]. Available: http://doi.acm.org/10.1145/1609956.1609960

[30] V. Kuznetsov, L. Szekeres, M. Payer, G. Candea, R. Sekar, and D. Song, “Code-pointer integrity,” in Proceedings of the 11th USENIX Conference on Operating Systems Design and Implementation, ser. OSDI’14. Berkeley, CA, USA: USENIX Association, 2014, pp. 147–163. [Online]. Available: http://dl.acm.org/citation.cfm?id=2685048.2685061