### Mobile Web Browsers with Native Anti-Phishing Blacklists

We focused on mobile web browsers that include native anti-phishing blacklists, as listed in Table I. Although we identified a few other web browsers with blacklist protection, such as CM Browser, we did not test them due to their low market share [4].

### Filter Types

We selected a set of request filtering techniques based on high-level cloaking strategies found in a recent study of .htaccess files from phishing kits [8]. Given the impracticality of exhaustively measuring every possible combination of request filters with a large sample size, we chose a manageable set of filtering strategies that we believed would effectively limit traffic to broad yet representative groups of potential victims while remaining simple for criminals to implement. These strategies were inspired by techniques observed in the wild [7]. Table III summarizes our filter selections.

We cannot disclose the exact conditions required for each filter, but we can provide a high-level overview. Filter A served as our control group; we expected every site in this group to be blacklisted at least as quickly as other sites. Filter B was designed to study how well mobile-only devices are blacklisted, coinciding with the recent increase in mobile users and phishing victims [28], [2]. Filters C and D focused on desktop browsers protected by Google Safe Browsing (GSB), which cover the majority of desktop users today. We also included geolocation, which, while less frequent in the wild, is highly effective due to its low detectability and relevance to spearphishing. Filter E, the most elaborate, emulates typical real-world phishing kits by blocking anti-phishing entities using hundreds of IP addresses, hostnames, referrers, and user agents. Finally, Filter F only displays phishing content if the client browser can execute JavaScript, which may defeat simple script-based web crawlers. This filter is common in modern search engine cloaking [7] and is further motivated by an ongoing study of JavaScript use in real-world phishing sites.

### Tested Entities

In addition to the blacklist operators, major clearinghouses, and PayPal’s internal anti-phishing system, we aimed to test as many other types of anti-phishing entities discussed in Section II-C as possible. We started with a recently-published list of entities commonly targeted for evasion by phishers [8]. We prioritized the more common and impactful entities in today’s ecosystem. Some entities were excluded because they do not accept direct external phishing reports, and we had to consider the domain registration costs associated with conducting each experiment. Table II summarizes our entity selections.

### Reporting

When reporting our phishing sites to each entity, we submitted the site URLs either via email or the entity’s web interface (if available and preferred by the entity). We used publicly-available submission channels and had no special agreements with the entities. For web submissions, we used a browser to submit each phishing site’s exact URL to the entity. Email reports were more involved, as the industry prefers to receive attachments with entire phishing emails rather than just a URL. We used PayPal-branded HTML email templates to create lookalike phishing messages, each containing a random customer name and email address within one of many body templates. We sent emails from unique accounts across five security-branded domains under our control. This approach is realistic, though larger victim organizations often contract enterprise security firms with private communication channels for streamlined reporting.

### Preliminary Tests

Our preliminary testing took place in mid-2017 and followed the full experimental approach from Section III-A on a small scale. One of our key goals was to minimize confounding effects on our experimental results. To achieve this, we secured a large set of IP addresses, ensuring that no anti-phishing entity would see two of our sites hosted on the same IP address. We provisioned 40 web servers powered by Digital Ocean, each with a unique IP address in one of the host’s data centers in Los Angeles, New York, Toronto, Frankfurt, Amsterdam, or Singapore. Our batch size was thus 40 phishing sites per preliminary test, for a total of 400 sites across the 10 entities being tested. Within each batch, six sites used filter types A and F, while seven used filter types B through E.

We also mimicked actual phishing attacks by following the classification of phishing URL types submitted to the Anti-phishing Working Group’s eCrime Exchange in early 2017. We registered only .com domains, as they account for the majority of real-world phishing attacks. We chose GoDaddy as our registrar, which is among the most-abused registrars by real phishers [1]. To prevent crawlers from landing on our phishing sites by chance, paths were non-empty across all of our URLs. Using deceptive URLs allowed us to gain insight into how various URL types are treated by entities, though it may skew blacklisting speed. Table IV shows the distribution of URL types and filters per batch of sites.

### Responsible Disclosure

Our analysis of the preliminary tests yielded several security recommendations (discussed in Section VI). We immediately disclosed our findings to the directly impacted entities (i.e., browser vendors, the brand itself, and major blacklist operators) which we also intended to re-test. Our first disclosure meeting was with PayPal in August 2017. Following PayPal’s legal approval, we disclosed to Google, Microsoft, Apple, Mozilla, and the APWG in February 2018. Each meeting included a detailed review of the entity’s performance, positive findings, specific actionable findings, and high-level comparisons to other entities. Our disclosures were generally well-received and resulted in close follow-up collaboration with Google, Mozilla, and the APWG, leading to the implementation of effective blacklisting within mobile GSB browsers and general mitigations against certain types of cloaking. We clearly stated that we would repeat our experiments in 4-6 months and thereafter publish our findings.

We did not immediately disclose to the blacklists powering Opera, as we had not originally expected to have the resources to re-test a fifth entity. Additionally, given lesser short-term urgency with respect to the remaining entities and the absence of close relationships with them, we felt it would be more impactful to disclose the preliminary findings alongside the full test findings. After completing the full tests, we reached out to all remaining entities via email; all but PhishTank and Opera responded and acknowledged receipt of a textual report containing our findings. US CERT and ESET followed up for clarifications once thereafter.

### Full-scale Tests

We believed that key ecosystem changes resulting from our disclosures would still be captured by our original experimental design. Thus, we did not alter our retesting approach beyond increasing the scale to enable statistically significant observations. Instead of using the URL distribution from the preliminary experiments, we used non-deceptive paths and hostnames (i.e., with randomly-chosen English words) to remove URL classification as a possible confounding factor in our cloaking evaluation.

We registered the required domains in May 2018 and initiated sequential deployment of our full-scale tests in early July. We re-tested all entities to which we disclosed and added PhishTank for its promising performance in the preliminary test. Each of the resulting five experiment batches consisted of 396 phishing sites, evenly split into six groups for each cloaking technique. Our reporting method did not change, though we throttled emailing such that the reports were spread over a one-hour period. Reporting through Google and Microsoft’s web interfaces spanned a slightly longer period of up to two hours due to the unavoidable manual work involved in solving required CAPTCHA challenges.

### Sample Size Selection

For our full tests, we chose a sample size of 384 phishing sites for each entity. Our goal was to obtain a power of 0.95 at the significance level of 0.05 in a one-way independent ANOVA test, which, for each entity, could identify the presence of a statistically significant difference in mean blacklisting speed between the six cloaking filters. Based on Cohen’s recommendation [50] and our preliminary test results, we assumed a medium effect size (f) of 0.25. We added 12 sites (2 per filter) to each experiment to serve as backups. All sites ultimately delivered 100% uptime during deployment, resulting in an effective sample size of 396 per experiment.

### PhishFarm Testbed Framework

To execute our experimental design at scale, we designed PhishFarm: a comprehensive framework for deploying phishing sites, reporting them to anti-abuse entities, and measuring blacklist response. The framework operates as a web service and satisfies three important requirements: automation, scalability, and reliability. We eliminated as many manual actions as technically feasible to ensure that the difference between launching hundreds and thousands of sites was only a matter of minutes. Actual site deployment can happen instantly and on-demand. Apart from upfront bulk domain registration and reporting phishing through a web form, all framework components feature end-to-end automation.

The framework consists of five interconnected components: bulk domain registration and DNS setup, stateless cloud web servers to display the phishing sites, an API and database that manages configuration, a client that issues commands through the API, and a monitoring system that regularly checks in which browsers each phishing site is blacklisted. In total, we wrote over 11,000 lines of PHP, Java, and Python code for these backend components. We extensively tested each component, particularly the hosting and monitoring infrastructure, to verify correct operation.

#### Domain and DNS Configuration

A core component of any phishing site is its URL, which consists of a hostname and path [49]. Our framework includes a script to automatically generate hostnames and paths per the experimental design. We manually register the required domain names in bulk and point them to our cloud hosting provider’s nameservers. We then automatically create DNS records such that the domains for each experiment are evenly spread across the IP addresses under our control. We set up wildcard CNAME records [51] to programmatically configure the subdomain of each phishing site on the server side. Registration of the 400 preliminary domains took about 15 minutes, while registration of the 1,980 domains for the full tests took 30 minutes; apart from the domain registration itself, no manual intervention is needed.

#### Research Client

We implemented a cross-platform client application to control the server-side components of the framework and execute our research. This client enables bulk configuration of phishing sites and cloaking techniques, bulk deployment of experiments, automated email reporting, semi-automated web reporting, monitoring of status, and data analysis.

#### Server-Side Components

The server-side components in our framework display the actual phishing sites based on dynamic configuration. They are also responsible for logging request data for later analysis and monitoring blacklist status.

1. **Central Database and API**: At the heart of our framework is a central API that serves as an interface to a database with our phishing site and system state. For each site, the database maintains attributes such as date activated, reported, and disabled; blacklisting status; site and email HTML templates; server-side and JavaScript request filtering code; and access logs. We interact with this API via the client whenever we define new sites or deploy sites as part of an experiment. All traffic to and from the API is encrypted.

2. **Hosting Infrastructure**: Our hosting infrastructure consists of Ubuntu cloud servers running custom intermediate software on top of Apache. The intermediate software captures all requests, enabling dynamic cloaking configuration and enhanced traffic logging. Each server obtains all of its configuration from the API, allowing the number of servers to be flexibly chosen based on testing requirements (40 in our case). When an HTTP request is received by any server, the server checks the request URL against the list of live phishing sites from the API, processes any cloaking rules, responds with the intended content, and logs the request. System state is cached locally on each server to minimize API queries.

   We served all our phishing sites over HTTP rather than HTTPS, as this was typical among real-world phishing sites at the time we designed the preliminary tests [1]. While our framework supports HTTPS, we did not wish to alter the experimental design between tests. Both approaches generate potential artifacts that might benefit the anti-phishing ecosystem: unencrypted sites allow network-level packet sniffing, while encrypted sites leave an evidence trail at the time a certificate is issued. We mitigated the former risk to a large extent through the design of our monitoring system.

   Our framework supports arbitrary, brand-agnostic web page content to be displayed for each phishing site. For our experiments, we hosted all resources (e.g., images and CSS) locally on each server to avoid confounding detection through external web requests to these files. In the wild, we have observed that sophisticated phishing kits follow a similar strategy to reduce detectability, though today’s typical kits merely embed resources from the legitimate website.

3. **Monitoring Infrastructure**: The purpose of the monitoring system is to identify, at a fine granularity, how much time elapses before a reported phishing site is blacklisted (if at all). To obtain a clear picture of the early hours of blacklist response, we configured the monitoring system to access each live phishing URL at least once every 10 minutes in each target desktop browser (the shortest interval feasible given our resources). We check the blacklist status of each URL by analyzing a screenshot of the respective browser window, similar to the approach taken by Sheng et al. [6]. We chose this approach for its universal applicability and lack of dependencies on browser automation libraries, which commonly force-disable phishing protection. For our purposes, it sufficed to check if the dominant color in each image [52] was similar to red (used in the warning messages of the browsers we considered). Although this image-based approach proved reliable and can be fully automated, it does not scale well because each browser requires exclusive use of a single system’s screen.

   To satisfy the scalability requirement, our monitoring system follows a distributed architecture with multiple autonomous nodes that communicate with the API. Each node is a virtual machine (VM) that runs on a smaller set of host systems. Software on each VM points a browser to the desired URL via command line and sends virtual keystrokes, as needed, to close stale tabs and allow for quick page navigation.