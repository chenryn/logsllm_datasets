The first client requested a deadline of 200 milliseconds for each run and specified that this deadline should be met with a probability of 0.2. The second client, on the other hand, requested different deadlines for each run. For each of these deadline values, we computed the probability of timing failures in a run of fifty requests by measuring the number of responses that failed to arrive by the deadline specified by the second client.

To study the behavior of the dynamic selection algorithm under different probabilities of timely responses, we repeated these experiments for three distinct probability values: 1) 0.9, 2) 0.5, and 3) 0. A probability value of 0 was chosen to represent the worst-case scenario, where the dynamic selection algorithm would experience the highest timing failure rates, providing insight into its worst-case performance.

Figure 4 illustrates the expected number of replicas selected by the dynamic selection algorithm to service the second client for each of its QoS specifications. Two key observations can be made from this figure: First, as the deadline increases, the algorithm tends to select fewer replicas, on average, to service the client. Second, the algorithm selects a lower redundancy level when the client requests a lower probability of timely responses. For instance, when the client specifies that at least 90% of its responses should be timely, the algorithm may choose a redundancy value as high as 6. Conversely, when the client is willing to tolerate any number of timing failures, the algorithm may select only a redundancy level of 2, which is the minimum number of replicas required by Algorithm 1.

These observations can be attributed to the fact that our algorithm never selects more replicas than necessary to meet the client’s QoS requirements. As the client’s QoS specifications become less stringent, the probability that a chosen replica will meet the client’s specification increases, allowing the algorithm to satisfy the requirements with fewer replicas.

Figure 5 demonstrates the success of the selected set of replicas, as shown in Figure 4, in meeting the QoS specifications of the second client. When the client specifies that the probability of timely responses must be at least 0.9, the maximum observed probability of timing failures is only 0.08, which is below the 0.1 timing failure probability that the client is willing to tolerate. Similarly, for cases where the client is willing to accept a failure probability up to 0.5 and 1, the maximum observed timing failure probabilities are 0.32 and 0.36, respectively, for the deadline values used. These results indicate that, in each case, the set of replicas selected by Algorithm 1 successfully met the client’s QoS requirements by maintaining the timing failure probability well below the acceptable failure probability.

The above results show that, despite some computational overhead, the dynamic selection scheme effectively utilizes available replicas to meet the QoS specifications, thereby reducing the occurrence of timing failures even when multiple clients access a service simultaneously. We believe such a replica selection scheme would be valuable in environments where time-critical clients access compute-bound service providers with variable response times.

### 7. Related Work

We now briefly discuss some related efforts that address the problem of detecting and preventing timing failures for clients in distributed systems.

- **DREAM Project [11]**: This project provides an integrated object-based framework for tolerating crash faults, value faults, and timing faults in real-time, distributed systems using a primary/backup replication scheme. While DREAM aims to prevent timing failures due to replica crashes, it does not handle timing failures caused by the load induced when multiple clients concurrently access a service.
- **Wolfe [22]**: This research addresses the problem of meeting time constraints when a CORBA service is accessed by multiple clients. Their approach uses a global scheduling service that assigns a global CORBA priority to a request based on the client's timing requirements. This priority determines the order in which a server processes the request. However, their work does not address replica crashes.
- **Verissimo and Casimiro [21]**: They proposed a general architectural construct called the Timely Computing Base (TCB) that can verify timeliness and detect timing failures, essential for building dependable and timely services. Our implemented timing fault handler realizes some of these properties for a replicated service.

### 8. Concluding Remarks

We have presented a new approach for tolerating timing faults in replicated services. This approach uses an algorithm that dynamically selects replicas at request time based on their ability to meet a client’s time constraints, considering delays and replica crashes. A key contribution of this paper is the definition of a probabilistic model that predicts, at runtime, the probability that a replica’s response will arrive by a given time, based on performance updates received from the replica. This prediction, made by a scheduler part of the timing fault handler, is used to select a set of replicas that can meet the client’s timing constraint with at least the requested probability.

We have implemented the selection algorithm in AQuA, an infrastructure for building dependable distributed applications, and obtained experimental results that demonstrate its efficacy. Our model and selection algorithm can be easily extended to any environment that provides replicated services and supports a mechanism for tracking and recording the recent performance history of its replicas.

### Future Work

- **Multiple Service Interfaces**: Extend the work to support servers that export multiple service interfaces by modifying the information repository to classify performance data based on the method interfaces.
- **Request Semantics**: In systems where the middleware has knowledge about an application’s request semantics, extend the selection algorithm to distinguish between requests made to the same server based on the arguments passed by the clients.
- **Active Probes**: Use active probes when a replica’s performance information is outdated.

### Acknowledgments

We thank the anonymous reviewers for their valuable feedback, Mouna Seri and the AQuA team for their contributions, and Jenny Applequist for improving the readability of the paper.

### References

[References remain unchanged]

---

This revised version aims to improve clarity, coherence, and professionalism while retaining the original content and structure.