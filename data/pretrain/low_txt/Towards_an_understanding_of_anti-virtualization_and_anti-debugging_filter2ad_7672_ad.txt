### Effectiveness of Imitated Fingerprints

Our simple tools have demonstrated the ability to create similar effects on 656 (25%) of the 2,624 malware samples tested. A detailed comparison of the effectiveness of Virtual Machines (VMs), debuggers, and our imitated fingerprints in deterring malicious behavior is presented in Table 3. Despite creating only a few imitated fingerprints, particularly those related to debuggers, our tools effectively deterred one-fourth of the malicious behavior that a real debugger can prevent, and even more than what VMs can deter. These results highlight the significant potential of our approach.

#### Case Study: Storm Worm Variant

In the case of the Storm Worm variant discussed in ยง4.1, our imitated fingerprints achieved the same effect as VM execution, successfully preventing file extractions and executions. However, a registry key was still modified, indicating that our imitation of debugger fingerprints is not yet complete. This may be due to the fact that we only superficially altered the result of the `IsDebuggerPresent()` API, while a program can directly read the corresponding bit in its process PEB (Process Environment Block). Deeper-level imitation of such fingerprints could help deter more sophisticated malware.

### Experimental Setup

Most of our experiments were conducted under Windows XP SP2, which prevented us from logging network activities due to software incompatibility. To further evaluate the effectiveness of our approach in preventing network behavior, we set up a smaller experiment running the 656 malware samples under an unpatched version of Windows XP. Our imitated fingerprints deterred 4,029 (70.5%) of the 5,717 network connection attempts made during plain execution, compared to 5,674 (99.2%) that a debugger could deter. This is noteworthy given that we implemented only a few debugger fingerprints.

### Comparison of Malicious Behavior

We found that 610 malware samples exhibited reduced malicious behavior with our imitated fingerprints. The performance overhead introduced by the VMware driver and OllyDbg window insertion is negligible, as these components are not accessed by legitimate applications and do not consume significant computational resources. The Detours package [15] handles the VMware hook and debugger checking API interception, with an overhead of around 15 microseconds per function call. We only intercept a few functions that are rarely executed in normal programs but are commonly used by malware, such as exception handlers, which are only triggered during significant software faults.

### Improving Imitated Fingerprints

During our evaluation, we tracked all potential reconnaissance actions to gain insights for improving our system. Among the 656 samples that showed reduced malicious behavior with our imitated fingerprints, `IsDebuggerPresent()` was checked 1,040 times, the SoftICE driver was checked 458 times, and the VM hook was checked 29 times. Additionally, there were 5,162 search attempts for the window name "creating rules for malware.exe," 654 attempts for "Hidden Process Requests Network Access," and numerous others for FileMon, APIMonitor, and Regmon, indicating evasive actions against antivirus software like AVP and Kaspersky, and monitoring programs. By applying malware multi-path execution techniques [24], we can reveal the condition checks that clearly separate benign and malicious behavior, likely related to the discrepancies that malware cares about. Enriching our imitated fingerprints based on these inputs will further enhance their effectiveness.

### Discussion

The use of Intel-based VMs is a current topic of extensive research and industry activity. As hardware and operating system support for VMs improve, some existing VM fingerprints may disappear, such as instruction fingerprints. Conversely, as VMs become more prevalent in production systems, the value of detecting whether a particular application is running inside a VM diminishes. For example, the most sophisticated worm to date, the Storm Worm, does not seem to care about the virtual machine environment. However, there is always a significant gap between monitoring systems and production systems. Debuggers, for instance, are often detected and avoided by a large portion of malware. Designing monitoring systems to be identical to production systems is challenging, and discrepancies will always exist and can be exploited.

By imitating fingerprints that are unique to monitoring systems, we have shown that it is possible to deter many sophisticated malware. However, the extent to which we should imitate such discrepancies remains a question. For example, hooking the `IsDebuggerPresent()` API to return a fake result is effective, but malware can further check the process PEB directly. We argue that false negatives are more disastrous than false positives for malware detection. Therefore, malware should exit if any of the tests return true. Raising the bar slightly higher can help win this arms race.

Another challenge is dealing with attackers' attempts to detect our imitated fingerprints. For example, hooking the `IsDebuggerPresent()` API without changing the corresponding flag in the PEB creates an inconsistency that indicates intentional fingerprinting. This may lead attackers to develop more intelligent and stealthy malware, such as testing the actual behavior of a driver rather than simply detecting a driver name. As the escalation worsens, attackers will face more overhead in detecting sophisticated fingerprints, and the existence of such inconsistencies already suggests that the target host is likely monitored and guarded.

### Conclusion

Our work provides the first detailed taxonomy of evasion techniques actively used by modern malware to avoid monitoring systems based on virtualization and debugger characteristics. These techniques span different layers of the computer system and vary in difficulty to perform, obfuscate, and imitate. Through large-scale experiments on 6,900 recent malware samples, we identified the behavioral differences among plain-machine execution, virtual machine execution, and debugger-attached execution. Our results show that a significant percentage of malware samples actively evade monitoring systems by exhibiting less malicious behavior. Despite various powerful evasion techniques, none can detect a remote networked monitoring system. To address this, we developed a novel technique to detect a remote networked virtual machine based on its clock skew behavior. We also proposed a new approach to mislead attackers and deter them from infecting target hosts by making production systems on plain machines appear as monitoring systems. Our lightweight imitated fingerprints have already shown the ability to deter a significant portion of malware samples and a large portion of malicious behavior. We believe our work represents important progress in combating emerging threats of evasive malware through a novel deterrence technique.

### References

[1] Collaborative malware collection and sensing. http://alliance.mwcollect.org.
[2] Detect if your program is running inside a VM. http://www.codeproject.com/system/vrndetect.asp.
[3] The Honeynet Project. http://project.honeynet.org.
[4] Honeypotting with VMware - basics. http://www.seifried.org/security/ids/20020107-honeypotvmware-basics.html.
[5] Red Pill. http://invisiblethings.org/papers/redpill.html.
[6] Scoopydoo. http://www.trapkit.de/research/vm/scoopydoo/scoopy_doo.htm.
[7] C. Associates. Win32.Agobot. http://www3.ca.com/securityadvisor/virusinfo/virus.aspx?id=37776, July 2004.
[8] M. Bailey, J. Oberheide, J. Andersen, Z. M. Mao, F. Jahanian, and J. Nazario. Automated Classification and Analysis of Internet Malware. In 10th International Symposium on Recent Advances in Intrusion Detection (RAID 2007), September 2007.
[9] J. Corey. Advanced honeypot identification. Phrack magazine, January 2004. http://www.phrack.org/fakes/p63/p63-0x09.txt.
[10] J. Franklin, M. Luk, J. M. McCune, A. Seshadri, A. Perrig, and L. van Doom. Remote detection of virtual machine monitors with fuzzy benchmarking. ACM SIGOPS Operating System Review, April 2008.
[11] D. Gao, M. Reiter, and D. Song. Behavioral Distance for Intrusion Detection. In 8th International Symposium on Recent Advance in Intrusion Detection (RAID 2005), September 2005.
[12] D. Gao, M. Reiter, and D. Song. Behavioral Distance Measurement Using Hidden Markov Models. In 9th International Symposium on Recent Advance in Intrusion Detection (RAID 2005), September 2006.
[13] T. Garfinkel, K. Adams, A. Warfield, and J. Franklin. Compatibility is Not Transparency: VMM Detection Myths and Realities. In Proceedings of the 11th Workshop on Hot Topics in Operating Systems (HotOS-XI), May 2007.
[14] T. Holz and F. Raynal. Detecting honeypots and other suspicious environments. In Systems, Man and Cybernetics (SMC) Information Assurance Workshop, 2005. Proceedings from the Sixth Annual IEEE, June 2005.
[15] G. Hunt and D. Brubacher. Detours: Binary Interception of Win32 Functions. In Proceedings of the 3rd USENIX Windows NT Symposium, pp. 135-143. Seattle, WA, July 1999.
[16] V. Jacobson, R. Braden, E. Lagache, and M. K. Claffy. TCP extensions for high performance. RFC 1323, May 1992.
[17] X. Jiang and D. Xu. Collapsar: A VM-Based Architecture for Network Attack Detention Center. In Proceedings of the 13th USENIX Security Symposium, August 2004.
[18] K. Kato. VMware backdoor I/O port. http://chichat.at.infoseek.co.jp/vmware/backdoor.html.
[19] R. Kennell and L. H. Jamieson. Establishing the Genuineness of Remote Computer Systems. In 12th USENIX Security Symposium, August 2003.
[20] S. T. King and P. M. Chen. Backtracking Intrusions. In Proceedings of the 2003 Symposium on Operating Systems Principles, October 2003.
[21] T. Kohno, A. Broido, and K. C. Claffy. Remote physical device fingerprinting. In SP '05: Proceedings of the 2005 IEEE Symposium on Security and Privacy, pages 211-225, Washington, DC, USA, 2005. IEEE Computer Society.
[22] C. Krรผgel, W. K. Robertson, F. Valeur, and G. Vigna. Static disassembly of obfuscated binaries. In USENIX Security Symposium, pages 255-270, 2004.
[23] T. Liston and E. Skoudis. On the cutting edge: Thwarting virtual machine detection. http://handlers.sans.org/tliston/ThwartingVMDetection_Liston_Skoudis.pdf.
[24] A. Moser, C. Kruegel, and E. Kirda. Exploring multiple execution paths for malware analysis. In Proceedings of the 2007 IEEE Symposium on Security and Privacy, pages 231-245, Washington, DC, USA, 2007. IEEE Computer Society.
[25] J. Oberheide, E. Cooke, and F. Jahanian. Rethinking Antivirus: Executable Analysis in the Network Cloud. In Proceedings of the 2nd USENIX Workshop on Hot Topics in Security (HOTSEC '07), August 2007.
[26] G. H. Project. Tracking Botnets, 2005. http://www.honeynet.org/papers/bots.
[27] T. Raffetseder, C. Kruegel, and E. Kirda. Detecting System Emulators. In Proceedings of 10th Information Security Conference (ISC), Lecture Notes in Computer Science, Springer Verlag, 2007.
[28] J. S. Robin and C. E. Irvine. Analysis of Intel Pentium's ability to support a secure virtual machine monitor. In USENIX Security Symposium, August 2000.
[29] A. Vasudevan and R. Yerraballi. Stealth breakpoints. In ACSAC '05: Proceedings of the 21st Annual Computer Security Applications Conference, pages 381-392, Washington, DC, USA, 2005. IEEE Computer Society.
[30] C. C. Zou and R. Cunningham. Honeypot-aware advanced botnet construction and maintenance. In DSN '06: Proceedings of the International Conference on Dependable Systems and Networks, pages 199-208, Washington, DC, USA, 2006. IEEE Computer Society.