# OASIS Instructions and Performance Comparison

## OASIS Operations
1. **Initialization (init)**
2. **Creation (create)**
3. **Launch (launch)**
4. **Unbind with Asymmetric Key (unbind with asym)**
5. **Unbind with Symmetric Key (unbind with sym)**
6. **Bind (bind)**

## Performance Overheads
| Operation | Time (sec) |
|-----------|------------|
| 7.2 K     | 3.58 · 10<sup>−3</sup> |
| 2.16 · 10<sup>+3</sup> | 4.3 B |
| 137 K     | 6.84 · 10<sup>−2</sup> |
| 68.1 M    | 3.40 · 10<sup>+1</sup> |
| 17.9 M    | 8.95 · 10<sup>+0</sup> |
| 3.12 M    | 1.56 · 10<sup>+0</sup> |

## Memory Isolation
Replace the CAR mode-based memory isolation to support applications of much larger size.

## Related Work

### SMART
Similar to our work, Defrawy et al. propose SMART, an architecture for establishing a dynamic root of trust in remote devices [13]. SMART focuses on remote embedded devices, particularly low-end microcontroller units (MCUs), while OASIS is applicable to high-end processors. SMART uses secret key material to establish a root of trust, assuming the existence of secure non-volatile memory to store the secret. In contrast, OASIS is based on SRAM memory–based PUFs [16, 17].

### XOM
Previous work has explored hardware extensions designed for an adversary model where software and physical attacks are possible. Lie et al. present XOM, a hardware implementation of eXecute-only-memory [26]. Similar to our adversary model, XOM assumes a completely untrusted OS. Unlike OASIS, XOM assumes a secure manufacturing process, allows secure XOM applications to access the platform secret, and requires secure non-volatile memory.

### SP
Lee et al. present SP, a processor architecture for isolated execution [24, 12]. Similar to OASIS, SP does not require a secure manufacturing process; however, SP includes no immutable device secret, which makes it challenging to prove the authenticity of the executing platform to a third party.

### Memory Cloaking
Memory cloaking provides secrecy and integrity of application data while allowing the OS to carry out most of its memory management tasks by limiting the OS’s data access to ciphertext. More recently, Williams et al. (Secure Executables [49]) and Chhabra et al. (SecureMe [8]) propose an isolated execution environment using hardware-based memory cloaking. Secure Executables use CPU-protected memory regions to store the register set (e.g., while a Secure Executable is suspended during a system call). This solution avoids cryptographic operations but may be vulnerable to direct memory attacks (e.g., by a DMA-enabled hardware component). The root of trust in Secure Executables is based on a public/private keypair installed in the CPU during manufacturing. In our design, both the manufacturer and the device owner (or system integrator) contribute to initializing a root of trust, reducing the possibility of large-scale data breaches and facilitating repurposing the device for new owners.

### AEGIS
Suh et al. propose AEGIS, a secure processing architecture that uses Physical Unclonable Functions (PUFs) for creating and protecting secrets [42]. AEGIS consigns security-sensitive OS functionality (e.g., context switching and virtual memory management) to a security kernel. However, this approach faces the same problem as the trusted OS model: the resulting TCB can be quite large.

### ISE
Our ISE is inspired by the recommendations of McCune et al. [34] but, in contrast to previous approaches that use a TPM as the root of trust, we use a PUF-derived key integrated within the processor. This integration increases performance and diminishes the possibility of attacks on the buses connecting the platform to the TPM.

### Hypervisor
Another alternative is to use a special-purpose hypervisor instead of additional hardware instructions. The hypervisor provides a less expensive alternative to hardware instruction set extensions and is significantly smaller than a full OS. However, the hypervisor must be trusted to enforce memory isolation and DMA protection for executing code, and thus must be included in the TCB.

### Secure Co-Processor
An alternative to extending functionality to the CPU is to use a secure co-processor [40]. A dedicated TPM is the approach endorsed by the TCG. This approach decouples system security from the production of traditional processors but reduces physical security due to the exposed bus and incurs a performance hit due to communication over the bus.

### SoC Integration
Alternatively, a co-processor could be included as an IP on a SoC, providing speed, tighter control, and enhanced security. The motivation for extending the processor ISA rather than a SoC TPM implementation is cost savings.

## Conclusion
Currently, TPM-based solutions have not reached widespread application in security-sensitive contexts, perhaps because TCG solutions lack protection against more resourceful adversaries, lack sufficient properties for end-to-end application protection, lack architectural safeguards against supply-chain compromises, or suffer from poor performance. OASIS offers a stronger degree of protection through highly efficient isolated execution with no hardware dependencies outside the CPU.

We have explored the extent to which minimal modifications to commodity CPUs can support isolated code execution. The ISA extensions explored in this research enable compute service providers and application developers to provide high-security assurance at low cost in terms of platform and software complexity.

## Acknowledgments
We are thankful to Olatunji Ruwase, Chen Chen, Yanlin Li, and Siddhartha Chhabra for their insightful discussions and valuable suggestions, and to the anonymous reviewers for their detailed comments and feedback.

## References
[1] ARM Security Technology - Building a Secure System using TrustZone Technology, 2009. Available at http://infocenter.arm.com/.
[2] The CDW 2011 Cloud Computing Tracking Poll, 2011. Available at www.cdw.com.
[3] Intel Trusted Execution Technology (Intel TXT) - Software Development Guide, 2013. Document Number: 315168-009. Available at www.intel.com.
[4] B¨osch, C., Guajardo, J., Sadeghi, A.-R., Shokrollahi, J., and Tuyls, P. Efficient Helper Data Key Extractor on FPGAs. In Cryptographic Hardware and Embedded Systems (CHES) (2008).
[5] Boyen, X., Dodis, Y., Katz, J., Ostrovsky, R., and Smith, A. Secure Remote Authentication Using Biometric Data. In Advances in Cryptology (EUROCRYPT) (2005).
[6] Brian Krebs. Coordinated ATM Heist Nets Thieves $13M, 2011. Available at http://krebsonsecurity.com.
[7] Chen, L. Recommendation for Key Derivation Using Pseudorandom Functions (Revised). NIST Special Publication 800-108, 2009.
[8] Chhabra, S., Rogers, B., Solihin, Y., and Prvulovic, M. SecureME: A Hardware-Software Approach to Full System Security. In ACM International conference on Supercomputing (ICS) (2011).
[9] Dodis, Y., Katz, J., Reyzin, L., and Smith, A. Robust Fuzzy Extractors and Authenticated Key Agreement from Close Secrets. In Advances in Cryptology (CRYPTO) (2006).
[10] Dodis, Y., Reyzin, M., and Smith, A. Fuzzy Extractors: How to Generate Strong Keys from Biometrics and Other Noisy Data. In Advances in Cryptology (EUROCRYPT) (2004).
[11] Dolev, D., Dwork, C., and Naor, M. Non-Malleable Cryptography. In SIAM Journal on Computing (2000).
[12] Dwoskin, J. S., and Lee, R. B. Hardware-rooted trust for secure key management and transient trust. In ACM conference on Computer and communications security (CCS) (2007).
[13] El Defrawy, K., Francillon, A., Perito, D., and Tsudik, G. SMART: Secure and Minimal Architecture for (Establishing a Dynamic) Root of Trust. In Network and Distributed System Security Symposium (NDSS) (2012).
[14] Gassend, B., Clarke, D., van Dijk, M., and Devadas, S. Controlled Physical Random Functions. In Proceedings of Annual Computer Security Applications Conference (ACSAC) (2002).
[15] Gassend, B., Clarke, D., van Dijk, M., and Devadas, S. Silicon Physical Random Functions. In ACM conference on Computer and Communications Security (CCS) (2002).
[16] Guajardo, J., Kumar, S. S., Schrijen, G.-J., and Tuyls, P. FPGA Intrinsic PUFs and Their Use for IP Protection. In Cryptographic Hardware and Embedded Systems (CHES) (2007).
[17] Holcomb, D. E., Burleson, W. P., and Fu, K. Power-Up SRAM State as an Identifying Fingerprint and Source of True Random Numbers. IEEE Trans. Computers (2009).
[18] IEEE. IEEE Standard Specifications for Public-Key Cryptography — IEEE Std 1363T M -2000, 2000. Available at www.ieee.org.
[19] Ittai Anati, Shay Gueron, S. P. J. Innovative Technology for CPU Attestation and Sealing. In Workshop on Hardware Architecture for Security and Privacy (2013).
[20] Jason Kincaid. Google Confirms That It Fired Engineer For Breaking Internal Privacy Policies, 2010. Available at http://techcrunch.com.
[21] Juels, A., and Wattenberg, M. A Fuzzy Commitment Scheme. In ACM conference on Computer and Communications Security (CCS) (1999).
[22] Krawczyk, H. Cryptographic Extraction and Key Derivation: The HKDF Scheme. In Advances in Cryptology (2010), CRYPTO.
[23] Kursawe, K., Sadeghi, A.-R., Schellekens, D., Skoric, B., and Tuyls, P. Reconfigurable Physical Unclonable Functions – Enabling Technology for Tamper-Resistant Storage. In IEEE International Workshop on Hardware-Oriented Security and Trust (HOST) (2009).
[24] Lee, R., Kwan, P., McGregor, J., Dwoskin, J., and Wang, Z. Architecture for Protecting Critical Secrets in Microprocessors. In Proceedings of the International Symposium on Computer Architecture (ISCA) (2005).
[25] Li, J., Krohn, M., Mazi`eres, D., and Shasha, D. Secure Untrusted Data Depository (SUNDR). In USENIX Symposium on Operating Systems Design & Implementation (OSDI) (2004).
[26] Lie, D., Thekkath, C., Mitchell, M., Lincoln, P., Boneh, D., Mitchell, J., and Horowitz, M. Architectural Support for Copy and Tamper Resistant Software. ACM SIGPLAN Notices (2000).
[27] Linnartz, J.-P., and Tuyls, P. New Shielding Functions to Enhance Privacy and Prevent Misuse of Biometric Templates.
[28] Lu, Y., Lo, L.-T., Watson, G., and Minnich, R. CAR: Using Cache as RAM in LinuxBIOS, 2012. Available at http://rere.qmqm.pl/ mirq.
[29] Lucian Constantin. One year after DigiNotar breach, Fox-IT details extent of compromise, 2012. Available at www.wired.com.
[30] Maes, R., Tuyls, P., and Verbauwhede, I. Low-Overhead Implementation of a Soft Decision Helper Data Algorithm for SRAM PUFs. In Cryptographic Hardware and Embedded Systems (CHES) (2009).
[31] Magnusson, P., Christensson, M., Eskilson, J., Forsgren, D., Hallberg, G., Hogberg, J., Larsson, F., Moestedt, A., and Werner, B. Simics: A full system simulation platform. Computer (2002).
[32] McCune, J. M., Li, Y., Qu, N., Zhou, Z., Datta, A., Gligor, V. D., and Perrig, A. TrustVisor: Efficient TCB Reduction and Attestation. In IEEE Symposium on Security and Privacy (S&P) (2010).
[33] McCune, J. M., Parno, B., Perrig, A., Reiter, M. K., and Isozaki, H. Flicker: An Execution Infrastructure for TCB Minimization. In ACM European Conference in Computer Systems (EuroSys) (2008).
[34] McCune, J. M., Parno, B., Perrig, A., Reiter, M. K., and Seshadri, A. How Low Can You Go? Recommendations for Hardware-Supported Minimal TCB Code Execution. In ACM Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS) (2008).
[35] Pappu, R. S., Recht, B., Taylor, J., and Gershenfeld, N. Physical One-way Functions. Science (2002). Available at web.media.mit.edu.
[36] Parno, B., Lorch, J. R., Douceur, J. R., Mickens, J. W., and McCune, J. M. Memoir: Practical state continuity for protected modules. In IEEE Symposium on Security and Privacy (S&P) (2011).
[37] Schmitz, J., Loew, J., Elwell, J., Ponomarev, D., and Abu-Ghazaleh, N. B. TPM-SIM: A Framework for Performance Evaluation of Trusted Platform Modules. In ACM Design Automation Conference (DAC) (2011).
[38] Shoup, V. A Proposal for an ISO Standard for Public Key Encryption. Version 2.1, 2001. Available at www.shoup.net.
[39] Shoup, V. OAEP Reconsidered. In Advances in Cryptology (CRYPTO) (2001). Available at www.shoup.net.
[40] Smith, S. W., and Weingart, S. "Building a High-Performance, Programmable Secure Coprocessor". Computer Networks (1999).
[41] Song, D., Shi, E., Fischer, I., and Shankar, U. Cloud data protection for the masses. IEEE Computer (2012).
[42] Suh, G. E., O’Donnell, C. W., and Devadas, S. AEGIS: A Single-Chip Secure Processor. Information Security Technical Report (2005).
[43] Symantec. Symantec-Sponsored Ponemon Report Finds Negligent Employees Top Cause of Data Breaches in the U.S. While Malicious Attacks Most Costly, 2012. Available at www.symantec.com.
[44] Taylor, G., and Cox, G. Behind Intel’s New Random-Number Generator. IEEE Spectrum (2011). Available at http://spectrum.ieee.org.
[45] Tuyls, P., Schrijen, G.-J., Skoric, B., van Geloven, J., Verhaegh, N., and Wolters, R. Read-Proof Hardware from Protective Coatings. In Cryptographic Hardware and Embedded Systems (CHES) (2006).
[46] Vasudevan, A., McCune, J., Newsome, J., Perrig, A., and van Doorn, L. CARMA: A Hardware Tamper-Resistant Isolated Execution Environment on Commodity x86 Platforms. In ACM Symposium on Information, Computer and Communications Security (ASIACCS) (2012).
[47] Virtutech. Simics x86-440BX Target Guide, 2010.
[48] Wang, Y., kei Yu, W., Wu, S., Malysa, G., Suh, G. E., and Kan, E. C. Flash Memory for Ubiquitous Hardware Security Functions: True Random Number Generation and Device Fingerprints. In IEEE Symposium on Security and Privacy (S&P) (2012).
[49] Williams, P., and Boivie, R. CPU Support for Secure Executables. In Trust and Trustworthy Computing (2011).