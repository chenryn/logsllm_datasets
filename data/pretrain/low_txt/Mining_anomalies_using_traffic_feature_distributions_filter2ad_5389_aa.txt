# Mining Anomalies Using Traffic Feature Distributions

**Authors:**
- Anukool Lakhina, Boston University
- Mark Crovella, Boston University
- Christophe Diot, Intel Research, Cambridge, UK

## Abstract
The increasing feasibility of large-scale flow capture has made it possible to develop traffic analysis methods capable of detecting and identifying a wide and diverse set of anomalies. However, the challenge of effectively analyzing this massive data source for anomaly diagnosis remains unmet. We argue that the distributions of packet features (such as IP addresses and ports) observed in flow traces can reveal both the presence and structure of a wide range of anomalies. By using entropy as a summarization tool, we demonstrate significant advances on two fronts: (1) highly sensitive detection of a wide range of anomalies, complementing volume-based methods, and (2) automatic classification of anomalies via unsupervised learning. Our analysis shows that anomalies naturally fall into distinct and meaningful clusters, which can be used to automatically classify anomalies and uncover new types. We validate our claims using data from two backbone networks (Abilene and Géant) and conclude that feature distributions show promise as a key element of a general network anomaly diagnosis framework.

**Categories and Subject Descriptors:**
C.2.3 [Computer-Communication Networks]: Network Operations

**General Terms:**
Measurement, Performance, Security

**Keywords:**
Anomaly Detection, Anomaly Classification, Network-Wide Traffic Analysis

**Acknowledgments:**
This work was supported in part by NSF grants ANI-9986397 and CCR-0325701, and by Intel.

**Permissions:**
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
SIGCOMM’05, August 22–26, 2005, Philadelphia, Pennsylvania, USA.
Copyright 2005 ACM 1-59593-009-4/05/0008 ...$5.00.

## 1. Introduction
Network operators frequently encounter a wide range of unusual events, some of which may be malicious. Detecting and classifying these anomalies is crucial for choosing the appropriate response. The primary challenge in automating this process is the vast diversity of potential anomalies, ranging from network abuse (e.g., DDoS attacks, scans, worms) to equipment failures (e.g., outages) to unusual customer behavior (e.g., sudden changes in demand, flash crowds, high volume flows), and even to previously unknown events. A general anomaly diagnosis system should be able to detect a range of anomalies with diverse structures, distinguish between different types of anomalies, and group similar anomalies. This is an ambitious goal.

At the same time, operators are increasingly able to collect network-wide views of traffic in the form of sampled flow data. This data source contains valuable information about normal and abnormal traffic behavior, but anomalies are often buried within a large volume of data. An important challenge is to determine how best to extract meaningful insights about the presence and nature of traffic anomalies from this data.

Another complication is that network anomalies are a moving target. It is difficult to define the set of network anomalies precisely and permanently, especially in the case of malicious anomalies. New anomalies will continue to emerge over time, so an effective anomaly detection system should not be restricted to a predefined set of anomalies.

In this paper, we aim to take significant steps toward a system that meets these criteria. We seek methods that can detect a diverse and general set of network anomalies with high detection rates and low false alarm rates. Furthermore, rather than classifying anomalies into pre-defined classes, we aim to mine the anomalies from the data by discovering and interpreting the patterns present in network-wide traffic.

Our work is based on the observation that despite their diversity, most traffic anomalies share a common characteristic: they induce a change in the distributional aspects of packet header fields (i.e., source and destination addresses and ports, referred to as traffic features). For example, a DDoS attack, regardless of its volume, will cause the distribution of traffic by destination addresses to be concentrated on the victim address. Similarly, a scan for a vulnerable port will have a dispersed distribution for destination addresses and a skewed distribution for destination ports. Even anomalies such as worms might be detectable as a change in the distributional aspect of traffic features if observed at a high aggregation level, i.e., network-wide. Our thesis is that examining distributions of traffic features provides considerable diagnostic power in both the detection and classification of a large set of anomalies.

Treating anomalies as events that disturb the distribution of traffic features differs from previous methods, which have largely focused on traffic volume as the primary metric. In comparison, feature-based analysis has two key benefits. First, it enables the detection of anomalies that are difficult to isolate in traffic volume. Some anomalies, such as scans or small DDoS attacks, may have a minor effect on the traffic volume of a backbone link and are better detected by systematically mining for distributional changes instead of volume changes. Second, unusual distributions reveal valuable information about the structure of anomalies, which is not present in traffic volume measures. The distributional structure of an anomaly can aid in the automatic classification of anomalies into meaningful categories. This is a significant advance over heuristic rule-based categorizations, as it can accommodate new, unknown anomalies and expose their unusual features.

The key question then is how to effectively extract the properties of feature distributions in a manner suitable for anomaly detection and classification. In this paper, we find that entropy is a particularly effective metric for this purpose. Entropy captures the distributional changes in traffic features in a single value, and observing the time series of entropy on multiple features exposes unusual traffic behavior.

We analyze network-wide flow traffic measurements (as the set of Origin-Destination flows) from two IP backbone networks: Abilene and Géant. We find that examining traffic feature distributions as captured by entropy is an effective way to detect a wide range of important anomalies. We show that entropy captures anomalies distinct from those captured in traffic volume (such as bytes or packets per unit time). Almost all the anomalies detected are important to network operators, indicating that our methods exhibit a low false alarm probability. Further, we show that our methods are very sensitive, capable of detecting anomalies that only comprise on the order of 1% of an average traffic flow. In the technical report version of this paper [24], we also demonstrate that our methods are particularly effective at detecting network-wide anomalies that span multiple flows, even when these anomalies are severely dwarfed in individual flows (e.g., constituting much less than 1% of a flow's traffic).

We find that anomalies detected in Abilene and Géant naturally fall into distinct clusters, even when using simple clustering methods. Moreover, the clusters delineate anomalies according to their internal structure and are semantically meaningful. The power of this approach is demonstrated by (1) the discovery of new anomalies in Abilene that we had not anticipated and (2) the successful detection and classification of external anomalies (previously identified attacks and worms) injected into the Abilene and Géant traffic.

We believe our methods are practical, as they rely only on sampled flow data, which is currently collected by many ISPs using router-embedded software such as NetFlow [5, 15]. However, our objective in this paper is not to deliver a fully automatic anomaly diagnosis system. Instead, we aim to demonstrate the utility of new primitives and techniques that a future system could exploit to diagnose anomalies.

This paper is organized as follows. We survey related work in Section 2. In Section 3, we elaborate on the utility of traffic feature distributions for diagnosing anomalies and introduce the sample entropy metric to summarize distributions. In Section 4, we describe our anomaly diagnosis framework, which includes an extension of the subspace method [23] to accommodate multiple data types and an unsupervised classification technique using simple clustering algorithms. In Section 5, we introduce our experimental data. In Section 6, we show that entropy detects a new set of anomalies not previously detected by volume metrics, and we manually inject previously identified anomalies into our traffic to demonstrate the sensitivity of our methods. In Section 7, we show how to use entropy to identify anomalies by automatically clustering them into distinct types. Finally, we conclude in Section 8.

## 2. Related Work
Anomaly detection has been widely studied, dating back at least as far as Denning’s statistical model for anomaly detection [6], and has received considerable attention recently. Most of the recent research and commercial literature (e.g., [2–4, 22, 23, 29, 30]) has treated anomalies as deviations in overall traffic volume (number of bytes or packets). Volume-based detection schemes have been successful in isolating large traffic changes (such as bandwidth flooding attacks), but a large class of anomalies do not cause detectable disruptions in traffic volume. In contrast, we demonstrate the utility of a more sophisticated treatment of anomalies as events that alter the distribution of traffic features.

Furthermore, anomaly classification remains an important, unmet challenge. Much of the work in anomaly detection and identification has been restricted to point-solutions for specific types of anomalies, e.g., port scans [14], worms [17, 32], DDoS attacks [11], and flash crowds [12]. A general anomaly diagnosis method remains elusive, although two notable instances of anomaly classification are [34] and [18]. The authors of [34] seek to classify anomalies by exploiting correlation patterns between different SNMP MIB variables. The authors of [18] propose rule-based heuristics to distinguish specific types of anomalies in sampled flow traffic volume, but no evaluation on real data is provided. Our work suggests that one reason for the limited success of both these attempts at anomaly classification is that they rely on volume-based metrics, which do not provide sufficient information to distinguish the structure of anomalies. In contrast, we show that by examining feature distributions, one can often classify anomalies into distinct categories in a systematic manner.

A third distinguishing feature of our method is that it can detect anomalies in network-wide traffic. Much of the work in anomaly detection has focused on single-link traffic data. A network-wide view of traffic enables the detection of anomalies that may be dwarfed in individual link traffic. Two studies that detect anomalies in network-wide data are [23], which analyzes link traffic byte-counts, and [22], which examines traffic volume in Origin-Destination flows. Both studies use the subspace method to detect changes in traffic volume. We also employ the subspace method to compare volume-based detections to anomalies detected via entropy of feature distributions. We note, however, that our work goes beyond [22, 23] by mining for anomalies using traffic feature distributions instead of traffic volume. In doing so, we extend the subspace method to detect both multi-flow anomalies and anomalies that span multiple traffic features. Finally, we tackle the anomaly classification problem, which was not studied by the authors of [22] and [23].

We are not aware of any work that provides a systematic methodology to leverage traffic feature distributions for anomaly diagnosis. The authors of [20] and [19] use address correlation properties in packet headers to detect anomalies. The authors of [21] also found that IP address distributions change during worm outbreaks. Entropy has been proposed for anomaly detection in other contexts, for example, for problems in intrusion detection by [26], and to detect DDoS attacks [9]. We use entropy as a summarization tool for feature distributions, with a broader objective: detecting and classifying general anomalies, not just individual types of anomalies. Other work proposes sketch-based methods to detect traffic volume changes and hierarchical heavy-hitters [36]. These methods also move beyond treating anomalies as simple volume-based deviations but operate on single-link traffic only. There has also been considerable work on using traffic features to automatically find clusters in single-link traffic (not network-wide traffic, which is our focus); a notable example is [8]. Finally, concurrent with our work, the authors of [35] also use entropy to summarize traffic feature distributions, with the goal of classifying and profiling traffic on a single backbone link.

Similar problems (pertaining to anomaly detection and classification) arise in the intrusion detection literature, where they remain open research problems [28]. Intrusion detection methods are well-suited for the network edge, where it is feasible to collect and analyze detailed packet payload data. Many data mining methods proposed to detect intrusions rely on detailed data to mine for anomalies. Such methods do not appear likely to scale to network-wide backbone traffic, where payload data is rare, and only sampled packet header measurements are currently practical to collect. In contrast to the work in edge-based anomaly detection with packet payload data, our objective is to diagnose network-wide anomalies using sampled packet header data.

## 3. Feature Distributions
Our thesis is that the analysis of traffic feature distributions is a powerful tool for the detection and classification of network anomalies. The intuition behind this thesis is that many important kinds of traffic anomalies cause changes in the distribution of addresses or ports observed in traffic.

For example, Table 1 lists a set of anomalies commonly encountered in backbone network traffic. Each of these anomalies affects the distribution of certain traffic features. In some cases, feature distributions become more dispersed, as when source addresses are spoofed in DDoS attacks, or when ports are scanned for vulnerabilities. In other cases, feature distributions become concentrated on a small set of values, as when a single source sends a large number of packets to a single destination in an unusually high volume flow.

A traffic feature is a field in the header of a packet. In this paper, we focus on four fields: source address (sometimes called source IP and denoted srcIP), destination address (or destination IP, denoted dstIP), source port (srcPort), and destination port (dstPort). Clearly, these are not the only fields that may be examined to detect or classify an anomaly; our methods are general enough to encompass other fields as well. However, all our results in this paper are based on the analysis of these four fields.

Figure 1 illustrates an example of how feature distributions change as a result of a traffic anomaly—in this case, a port scan occurring in traffic from the Abilene backbone network (described in Section 5). Two traffic features are illustrated: destination ports in the upper half of the figure, and destination addresses in the lower half of the figure. Each plot shows a distribution of features found in a 5-minute period. Distributions are plotted as histograms over the set of features present, in decreasing rank order. On the left in each case is the distribution during a typical 5-minute period, and on the right is the distribution during a period including the port scan event.

In the upper half of the figure, both plots have the same range in the y-axis. Thus, although the most common destination port occurs about the same number of times (roughly 30) in both cases, the total number of ports seen is much larger during the anomaly. This results in a distribution that is much more dispersed during the anomaly than during normal conditions. The reverse effect occurs with respect to destination addresses. In the lower half of the figure, both plots have the same range in the x-axis. Here, there is roughly the same number of distinct addresses in both cases, but during the anomaly, the distribution becomes more concentrated on a smaller set of addresses.