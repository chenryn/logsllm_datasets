### Negative Caching Times and TTL of the Root DNSKEY RRset

Negative caching times are typically much shorter than the Time to Live (TTL) of the root DNSKEY Resource Record Set (RRset), which is currently set to 48 hours. Clients relying on resolvers with incorrectly configured trust anchors may receive responses with the SERVFAIL error code, as the resolver fails to perform DNSSEC validation. The ICANN KSK rollover design team anticipated that the number of resolvers unable to update their trust anchor would be low [2]. This confidence was based on the widespread implementation of the RFC 5011 mechanism, which we will describe in the next section. In Section 4.2, we measure the actual impact of the rollover on resolvers and clients.

### Response Size Changes

Due to the Key Signing Key (KSK) and Zone Signing Key (ZSK) split, the size of most responses remains the same during the KSK rollover. Only the size of a DNSKEY response changes. Figure 3 illustrates the sizes of various DNSKEY responses throughout the rollover process, ranging from 864 to 1,425 octets. These sizes include the question and standard EDNS0 data. Some root servers have deployed DNS cookies, adding another 28 octets to the sizes shown. These response sizes can exceed the Maximum Transmission Unit (MTU) of some networks, causing fragmentation of UDP packets. Firewalls and other middle-boxes sometimes block fragmented packets [11, 12], which can hinder resolvers from receiving the DNSKEY record set and validating signatures. Pre-rollover measurements by ICANN and the community indicated that up to 6% of resolvers could be affected by this problem. These resolvers serve less than 1% of users, and most do not perform DNSSEC validation [2].

Root servers may also receive an increased number of ICMP packets signaling that the packet size exceeds the network’s MTU. Clients relying on these resolvers could experience increased response times or receive a DNS SERVFAIL response. We study the impact of increased response sizes during the revocation in Section 4.3, when the highest packet size occurred during the rollover process.

### Updating Trust Anchors

DNSSEC allows validators to automatically update their trust anchors through an in-band mechanism in the DNS, known as RFC 5011 [13]. The process works as follows: at the start of a rollover, the new key (KSK-2017, introduced at Phase I) is added to the DNSKEY RRset, but the RRset is only signed with the then-current trust anchor (KSK-2010). This signals to resolvers that support RFC 5011 to start the process of accepting the newly introduced key as a trust anchor. Acceptance is not immediate; instead, a hold-down timer starts, lasting 30 days. Only if the resolver consistently sees the new key throughout the hold-down period will it accept the new key. This prevents malicious actors who have gained access to a trust anchor from instantly injecting a new trust anchor. Once the new trust anchor comes into effect, the old one may be revoked. In RFC 5011, this is achieved by publishing a DNSKEY RRset in which the old key is marked with a revocation flag (at Phase V). After a 30-day hold-down, the trust anchor is removed by resolvers. Most resolver software (e.g., BIND, Unbound, and Knot) supports RFC 5011. Among popular implementations, only PowerDNS lacks support. The widespread support of RFC 5011 gave the Rollover Design Team confidence that most resolvers would pick up the new key on time [2].

This KSK rollover was the first real test of RFC 5011. Since its publication in 2007, new technologies have been introduced, such as the widespread use of virtual machines and containers, configuration management tools like Puppet and Ansible, and DNS resolvers running on inexpensive, hard-to-update home and small office routers. While RFC 5011 specifies an in-band approach, an out-of-band approach is discussed in RFC 7958 [14]. In this approach, resolvers and other applications can retrieve keys and/or hashes directly from the IANA website as an XML document. Applications can validate the correctness of this information using various methods, such as trusting protections provided by TLS or a digital (PGP) signature file, published separately. The Unbound resolver software uses this mechanism when updates via RFC 5011 fail [15].

With both mechanisms, it is not possible for third parties to determine which resolvers have configured KSK-2017. To address this, new resolver software supports protocols that try to provide this insight. We use these protocols to measure the deployment of KSK-2017 in Sections 4.1.1 and 4.3.1 and discuss their use in Section 6.

### Datasets and Methodology

We use a broad set of passive and active measurements at different vantage points in the DNS hierarchy to cover the most critical phases of the rollover. We discuss these datasets and how we use them to analyze the rollover below. We also make the processed datasets and accompanying scripts for each figure available [16].

#### Passive Measurements

The DNS root system has 13 root server identities, each operated by a different entity [17]. At various stages of the rollover, we use passive datasets from select root servers or aggregate data for all root servers from a public repository. Specifically, we use the following datasets:

- **Root Queries**: The Domain Name System Operations Analysis and Research Center (DNS-OARC) collects DNS traces from various name servers, including the root system. This includes their well-known annual Day-in-the-Life (DITL) datasets [18]. Given the significance of the KSK rollover, DNS-OARC coordinated a DITL data collection from root operators spanning an 82-hour window around the dates of the actual rollover. We utilized this data, available to researchers and DNS-OARC members, to provide a holistic view of root query traffic during the rollover.

- **Longitudinal Data**: Our analysis extends to well before and after the rollover. To support this, we use query datasets collected at three root servers, A, B, and J. This non-public longitudinal data, spanning 2017–2019, was made available by Verisign (A/J Root) and the University of Southern California’s Information Sciences Institute (B Root). These datasets are used throughout the analysis in Section 4 whenever detailed information about specific resolvers exhibiting anomalous behavior is required. Note that other root servers might show different query patterns [19].

- **RSSAC Measurements**: The ICANN Root Server System Advisory Committee (RSSAC) [20] advises ICANN on operational matters related to the DNS root system. RSSAC defined a set of metrics that all root server operators are expected to publish daily [21]. The resulting data is published as YAML files, accessible through a public GitHub repository [22], with data going back to 2013. We use the RSSAC002 data on traffic sizes to the root as a proxy for DNSKEY queries in Section 4.3.2 and to estimate the impact of the increased DNSKEY RRset size in Section 4.3.3. The data is available for all root servers except G Root.

- **Trust Anchor Signals**: RFC 8145 [3] describes a protocol allowing DNSSEC validators to signal the keys in their trust anchor set. RFC 8145 signals are 16-bit "key tags," encoded as hexadecimal values in DNS queries. KSK-2010 has key tag 19036 (4a5c in hexadecimal), and KSK-2017 has key tag 20326 (4f66 in hexadecimal). A validator that implements RFC 8145 periodically sends a query whose first label starts with the string "_ta-" followed by a hyphen-separated list of hexadecimal key tag values. It then appends the name of the zone to which the keys belong. Table 1 shows root zone trust anchor signal strings and their meanings.

In this paper, we use two RFC 8145 datasets: (i) all trust anchor signals received by A, B, and J Root from up to 100,000 distinct IP addresses daily, and (ii) trust anchor signals provided to ICANN by most root server operators from up to 200,000 distinct IP addresses daily; ICANN provided us with a subset of this data covering February 1st to March 29th, 2018.

#### Active Measurements

- **Resolver State**: By using only data collected at the root, we miss the perspective of the client. To add this perspective, we rely on public measurements [23] that make use of the RIPE Atlas measurement network [24]. An Atlas probe is a device from which we can actively send DNS queries through its recursive resolvers, pre-configured by the probe owner or learned through DHCP. This allows us to observe the transition from KSK-2010 to KSK-2017 (event IV) and the revocation of KSK-2010 (event V) from the perspective of resolvers and measure whether they continue to validate DNSSEC signatures successfully. The public measurements we leverage consist of two queries sent every hour: the first asks for the A record of a domain with a valid signature, and the second for a domain with a bogus signature. The response codes of both measurements can be combined (see Table 2) to establish if a resolver (i) does not validate DNSSEC signatures (state insecure), (ii) validates signatures correctly (state secure), or (iii) fails to validate (state bogus). Secure resolvers changing state to insecure or bogus at any stage of the rollover may indicate that the resolver is experiencing problems.

- **Additional Measurement**: In addition to the public measurements, we schedule our own measurement, querying each resolver for the DNSKEY RRset of the root, to measure the uptake of KSK-2017 during the rollover.

Using 10,004 RIPE Atlas probes (all probes available at the time of our measurement) and their recursive resolvers gives 18,277 vantage points (VPs), located in 3,647 autonomous systems (ASs). To find how many resolvers these VPs cover, we send hourly queries for a domain under our control, using the probe ID and a random string as a sub-label to avoid caching. Our authoritative name server responds with the IP address of the resolver that served the query. Using this method, we observe 35,719 upstream IPs located in 3,141 ASs over the period in which we conducted the measurement.

- **Root Sentinel**: As discussed, RFC 8145 allows resolvers to signal which trust anchors they use to upstream authoritative name servers. However, there was no way for resolver users and other third parties to actively ask resolvers which trust anchors they use. This led to the introduction of RFC 8509, the so-called "Root Sentinel" [25]. Given that the specification was only finalized in December 2018, it could not reliably be used to monitor the root KSK rollover (although we do observe early implementations). We include Root Sentinel measurements to study the adoption of this new form of telemetry and to observe the revocation of KSK-2010 in 2019 from the perspective of resolvers.

The Root Sentinel is an active measurement mechanism. A client can send two special queries to resolvers to ask what trust anchors they currently have to validate DNSSEC responses. The first query type allows a client to ask if a DNSKEY with a certain key tag is a trust anchor, and the second type allows a client to ask the inverse (whether a specific DNSKEY is not a trust anchor). The resolver returns a valid response to the first type if the specified key is a trust anchor, and a SERVFAIL error if it is not. For the second query type, the opposite behavior applies. Table 3 shows what the queries look like. Note that while RFC 8145 uses hexadecimally encoded key tags, RFC 8509 uses decimal key tags. Thus, to query for the presence of KSK-2010 and KSK-2017, ... -is-ta-19036 and ... -is-ta-20326 are used.

Our goal is to examine (i) how many resolvers support Root Sentinel queries, and for those that do, (ii) if they correctly have the new key (KSK-2017) and remove the old key (KSK-2010) when it is revoked (event V). To do so, we set up a domain under our control. The name server for this domain is configured to return a DNSSEC-signed A record for Root Sentinel queries. We then use RIPE Atlas to issue four Root Sentinel queries (i.e., each of the two Root Sentinel queries for the old and new key) under our test domain. For this measurement, we extended our coverage of the global resolver population by including additional measurements using the Luminati proxy network [26]. This gives us more visibility in residential networks. Luminati is a paid HTTP/S proxy service enabling clients to route traffic via the Hola Unblocker Network. Luminati currently provides over 187 million potential exit nodes.