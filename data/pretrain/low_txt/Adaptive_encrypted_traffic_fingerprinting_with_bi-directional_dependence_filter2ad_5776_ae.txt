### 4.3.6 Adaptive Fingerprinting

In this section, we present the experimental results of the adaptive learning approach (ADABIND) discussed in §3.2.2. Figure 9 illustrates the impact of concept drift on the model and the dynamic update (re-training) process in WFIN. The x-axis represents time (in days), and the y-axis represents accuracy (%).

We selected 20 websites from the HTTPS dataset, using a training window of 16 traces per website to train the ADABIND model (R = 16, starting from day 1 to day 16). A sliding window of 4 traces (starting from day 17) per website was then used to validate the model by testing its accuracy.

It is important to note that the training and testing data were collected at different times under varying experimental conditions. As the 4-day validation window slides, if the accuracy drops below a certain threshold (85% in this experiment), the model is considered obsolete, and re-training is initiated. This re-training occurs at specific points (e.g., day 33, 94, 119, and 148 as shown in the figure). This dynamic re-training mechanism improves the accuracy, maintaining it above the assigned threshold. The average accuracy of this approach is 92.6%.

Figure 9 also demonstrates the drop in accuracy when no updates are applied. In this scenario, the model is trained once at the beginning, and the 4-day sliding window is used to validate the test traces. The resulting average accuracy for this static learning method is 76%, highlighting the need for re-training to adapt to potential data drifts over time.

Additionally, Figure 9 shows the same experiment where we apply the BINDFUP fixed update approach, re-training the model every 24 days instead of using the dynamic update in BINDDUP. The 4-day validation window remains the same. The figure indicates that the model becomes more accurate and stable with the fixed update approach. However, this results in additional training overhead due to unnecessary updates. The average accuracy for this approach is 93.3%, which is marginally better than the average accuracy of BINDDUP (92.6%). The number of updates in this experiment for BINDFUP is 8, which is twice the number of updates in the dynamic update approach (BINDDUP). As discussed in §4.3.4, frequent re-training can lead to significant execution time, increasing the overall cost.

To evaluate the effect of the training window (R), Figure 10 presents the BINDDUP dynamic update experiments with R values in the range {4, 8, 12, 16, 20}. If R is small, the number of training instances may be insufficient to build a robust model, leading to frequent updates. Conversely, large values of R increase training overhead and may cause the model to miss some data drifts. Table 13 summarizes the average accuracies and the number of updates/re-trains for the experiments shown in Figure 10. The results indicate that the average accuracy improves up to a certain point as R increases, and then declines. The best results were obtained when R = 16, with a moderate number of updates (i.e., 4 re-trains).

For the previous experiments using SVM, similar conclusions were observed for other datasets, though they were not included due to space limitations. Generally, the adaptive learning algorithm can be applied to any classification approach.

### 5. Discussion

In this paper, we introduced BIND, a new feature extraction and classification method for analyzing encrypted network traffic, with two case studies: WFIN and AFIN. We discuss the challenges and limitations resulting from the assumptions in our evaluation, as well as future work.

A study in WFIN [23] describes the effects of various assumptions on the evaluation results. Major assumptions include single-tabbed browsing or the absence of other background noise, a small time gap (or freshness) in data collection between the training and test sets, page load parsing, and replicability. Recent studies [18,38] have attempted to address these issues by evaluating classifiers under more relaxed conditions. A significant time gap (or staleness) in data collection between the training and testing sets can significantly impact classifier accuracy. This limitation applies to the BIND approach as well, since similar base features, such as packet statistics (length, sequence, and timing), are affected over time. This challenge can be addressed by periodically training a new model with fresh training data, as introduced in this paper using ADABIND, which models fingerprinting in an adaptive manner.

The ADABIND method updates the model with new training batches, requiring a significant number of training instances. Furthermore, the re-training process assumes the availability of testing instance labels, which may not always be valid. To address these challenges, future work will focus on identifying the optimal point in the incoming data stream to incrementally re-train the model (keeping old useful data) in an unsupervised manner (without labels). One direction for future research is to apply Change Point Detection (CPD) [19,20] to decide when to update the model in an unsupervised fashion and re-train incrementally.

The proposed methods in this paper assume sequential user access to end-nodes and ignore background noise, as mentioned in §2.1 regarding WFIN [23]. These methods can be augmented with techniques that relax such assumptions. Additionally, these assumptions are applicable to AFIN as well. In a smartphone, multiple apps may run background services, such as auto-sync, that periodically access the Internet. Moreover, app services can change over time with newer versions released by developers. Each updated version of an app may have a different network signature or fingerprint, affecting classifier performance. Exploring different activities of an app would generate different network signatures compared to a signature obtained by merely launching it. Dynamic analysis techniques [4,32] can be used to automatically explore an app for a better understanding of its network behaviors. These aspects are left for future work.

### 6. Conclusion

We introduced, implemented, and evaluated BIND, a new data analysis method for encrypted network traffic for end-node identification. The method leverages dependencies in packet sequences to extract characteristic features suitable for classification. We studied two cases where our method is applicable: website fingerprinting and app fingerprinting. We empirically evaluated both cases in closed-world and open-world settings using various real-world datasets over HTTPS and Tor. The empirical results demonstrate the effectiveness of BIND in various scenarios, including the realistic open-world setting. Our evaluations also include cases where defense mechanisms are applied to website and app fingerprinting. We showed how the proposed approach achieves higher performance compared to existing techniques. Additionally, we introduced the ADABIND approach, which addresses temporal changes in data patterns over time while performing traffic fingerprinting.

### 7. Acknowledgment

This material is based upon work supported by NSF under Award No. 1054629, AFOSR under Award No. FA9550-12-1-0077 and Award No. FA9550-14-1-0173, and NSA under Award No. H98230-15-1-0271.

### References

[1] ALEXA. The top visited sites on the web. http://www.alexa.com/.
[2] ALSABAH, M., BAUER, K., AND GOLDBERG, I. Enhancing tor’s performance using real-time traffic classification. In Proceedings of the 2012 ACM conference on Computer and communications security (2012), ACM, pp. 73–84.
[3] ATENIESE, G., HITAJ, B., MANCINI, L. V., VERDE, N. V., AND VILLANI, A. No place to hide that bytes won’t reveal: Sniffing location-based encrypted traffic to track a user’s position. In Network and System Security. Springer, 2015, pp. 46–59.
[4] BHORASKAR, R., HAN, S., JEON, J., AZIM, T., CHEN, S., JUNG, J., NATH, S., WANG, R., AND WETHERALL, D. Brahmastra: Driving apps to test the security of third-party components. In 23rd USENIX Security Symposium (USENIX Security 14) (2014), pp. 1021–1036.
[5] BREIMAN, L. Random forests. Machine learning 45, 1 (2001), 5–32.
[6] CAI, X., NITHYANAND, R., WANG, T., JOHNSON, R., AND GOLDBERG, I. A systematic approach to developing and evaluating website fingerprinting defenses. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security (2014), ACM, pp. 227–238.
[7] CAI, X., ZHANG, X. C., JOSHI, B., AND JOHNSON, R. Touching from a distance: Website fingerprinting attacks and defenses. In Proceedings of the 2012 ACM conference on Computer and communications security (2012), ACM, pp. 605–616.
[8] CHANG, C.-C., AND LIN, C.-J. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology 2 (2011), 27:1–27:27. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm.
[9] CONTI, M., MANCINI, L. V., SPOLAOR, R., AND VERDE, N. V. Can’t you hear me knocking: Identification of user actions on android apps via traffic analysis. In Proceedings of the 5th ACM Conference on Data and Application Security and Privacy (2015), ACM, pp. 297–304.
[10] CONTI, M., MANCINI, L. V., SPOLAOR, R., AND VERDE, N. V. Analyzing android encrypted network traffic to identify user actions. Information Forensics and Security, IEEE Transactions on 11, 1 (2016), 114–125.
[11] CORTES, C., AND VAPNIK, V. Support-vector networks. Machine Learning 20, 3 (1995), 273–297.
[12] DAI, S., TONGAONKAR, A., WANG, X., NUCCI, A., AND SONG, D. NetworkProfiler: Towards automatic fingerprinting of android apps. In INFOCOM, 2013 Proceedings IEEE (2013), IEEE, pp. 809–817.
[13] DAVI, L., DMITRIENKO, A., SADEGHI, A.-R., AND WINANDY, M. Privilege escalation attacks on android. In Information Security. Springer, 2010, pp. 346–360.
[14] DINGLEDINE, R., MATHEWSON, N., AND SYVERSON, P. Tor: The second-generation onion router. Tech. rep., DTIC Document, 2004.
[15] DOUGHERTY, J., KOHAVI, R., SAHAMI, M., ET AL. Supervised and unsupervised discretization of continuous features. In Machine learning: proceedings of the twelfth international conference (1995), vol. 12, pp. 194–202.
[16] DUDOROV, D., STUPPLES, D., AND NEWBY, M. Probability analysis of cyber attack paths against business and commercial enterprise systems. In Proc. IEEE European Intelligence and Security Informatics Conf. (EISIC) (2013), pp. 38–44.
[17] DYER, K. P., COULL, S. E., RISTENPART, T., AND SHRIMPTON, T. Peek-a-boo, I still see you: Why efficient traffic analysis countermeasures fail. In Security and Privacy (SP), 2012 IEEE Symposium on (2012), IEEE, pp. 332–346.
[18] GU, X., YANG, M., AND LUO, J. A novel website fingerprinting attack against multi-tab browsing behavior. In Computer Supported Cooperative Work in Design (CSCWD), 2015 IEEE 19th International Conference on (2015), IEEE, pp. 234–239.
[19] HAQUE, A., KHAN, L., AND BARON, M. SAND: Semi-supervised adaptive novel class detection and classification over data stream. In Proc. 30th Conf. Artificial Intelligence (AAAI) (2016), pp. 1652–1658.
[20] HAQUE, A., KHAN, L., BARON, M., THURAISINGHAM, B., AND AGGARWAL, C. Efficient handling of concept drift and concept evolution over stream data. In 2016 IEEE 32nd International Conference on Data Engineering (ICDE) (May 2016), pp. 481–492.
[21] HERRMANN, D., WENDOLSKY, R., AND FEDERRATH, H. Website fingerprinting: attacking popular privacy enhancing technologies with the multinomial naïve-bayes classifier. In Proceedings of the 2009 ACM workshop on Cloud computing security (2009), ACM, pp. 31–42.
[22] HITE, K. C., CICIORA, W. S., ALISON, T., BEAUREGARD, R. G., ET AL. System and method for delivering targeted advertisements to consumers, June 30 1998. US Patent 5,774,170.
[23] JUAREZ, M., AFROZ, S., ACAR, G., DIAZ, C., AND GREENSTADT, R. A critical evaluation of website fingerprinting attacks. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security (2014), ACM, pp. 263–274.
[24] KIHL, M., ÖDLING, P., LAGERSTEDT, C., AND AURELIUS, A. Traffic analysis and characterization of internet user behavior. In Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT), 2010 International Congress on (2010), IEEE, pp. 224–231.
[26] MISKOVIC, S., LEE, G. M., LIAO, Y., AND BALDI, M. AppPrint: Automatic fingerprinting of mobile applications in network traffic. In Passive and Active Measurement (2015), Springer, pp. 57–69.
[27] PANCHENKO, A., LANZE, F., ZINNEN, A., HENZE, M., PENNEKAMP, J., WEHRLE, K., AND ENGEL, T. Website fingerprinting at internet scale. In Proceedings of the 23rd Internet Society (ISOC) Network and Distributed System Security Symposium (NDSS 2016) (2016). To appear.
[28] PANCHENKO, A., NIESSEN, L., ZINNEN, A., AND ENGEL, T. Website fingerprinting in onion routing based anonymization networks. In Proceedings of the 10th annual ACM workshop on Privacy in the electronic society (2011), ACM, pp. 103–114.
[29] PEDREGOSA, F., VAROQUAUX, G., GRAMFORT, A., MICHEL, V., THIRION, B., GRISEL, O., BLONDEL, M., PRETTENHOFER, P., WEISS, R., DUBOURG, V., ET AL. Scikit-learn: Machine learning in python. The Journal of Machine Learning Research 12 (2011), 2825–2830.
[30] PLONKA, D. FlowScan: A network traffic flow reporting and visualization tool. In LISA (2000), pp. 305–317.
[31] RAYMOND, J.-F. Traffic analysis: Protocols, attacks, design issues, and open problems. In Designing Privacy Enhancing Technologies (2001), Springer, pp. 10–29.
[32] SOUNTHIRARAJ, D., SAHS, J., GREENWOOD, G., LIN, Z., AND KHAN, L. SMV-Hunter: Large scale, automated detection of SSL/TLS man-in-the-middle vulnerabilities in android apps. In Proceedings of the 19th Network and Distributed System Security Symposium (2014).
[33] STÖBER, T., FRANK, M., SCHMITT, J., AND MARTINOVIC, I. Who do you sync you are?: Smartphone fingerprinting via application behavior. In Proceedings of the sixth ACM conference on Security and privacy in wireless and mobile networks (2013), ACM, pp. 7–12.
[34] TAYLOR, V., SPOLAOR, R., CONTI, M., AND MARTINOVIC, I. AppScanner: Automatic fingerprinting of smartphone apps from encrypted network traffic. In 1st IEEE European Symposium on Security and Privacy (Euro S&P 2016) (Mar 2016). To appear.
[35] VIDAS, T., VOTIPKA, D., AND CHRISTIN, N. All your droid are belong to us: A survey of current android attacks. In WOOT (2011), pp. 81–90.
[36] WANG, T., CAI, X., NITHYANAND, R., JOHNSON, R., AND GOLDBERG, I. Effective attacks and provable defenses for website fingerprinting. In Proc. 23th USENIX Security Symposium (USENIX) (2014).
[37] WANG, T., AND GOLDBERG, I. Improved website fingerprinting on Tor. In Proceedings of the 12th ACM workshop on Workshop on privacy in the electronic society (2013), ACM, pp. 201–212.
[38] WANG, T., AND GOLDBERG, I. On realistically attacking Tor with website fingerprinting. Tech. rep., Technical Report 2015-08, CACR., 2015.
[39] WEI, T., ZHANG, Y., XUE, H., ZHENG, M., REN, C., AND SONG, D. Sidewinder targeted attack against Android in the golden age of ad libraries. Black Hat USA 2014 (2014).
[25] LIBERATORE, M., AND LEVINE, B. N. Inferring the source of encrypted HTTP connections. In Proceedings of the 13th ACM conference on Computer and communications security (2006), ACM, pp. 255–263.
[40] WRIGHT, C. V., COULL, S. E., AND MONROSE, F. Traffic morphing: An efficient defense against statistical traffic analysis. In In Proceedings of the 16th Network and Distributed Security Symposium (2009), IEEE, pp. 237–250.