### Title: Revisiting TCP Congestion Control Throughput Models and Fairness Properties at Scale

### Authors:
- Adithya Abraham Philip
- Ranysha Ware
- Rukshani Athapathu
- Justine Sherry
- Vyas Sekar

### Affiliation:
Carnegie Mellon University, United States of America

### Abstract
Our understanding of congestion control algorithm (CCA) throughput and fairness is largely based on models and measurements that assume congestion occurs in the last mile. These studies typically evaluate CCAs in "small scale" edge settings, involving tens of flows and bandwidths up to a few hundred Mbps. However, recent measurements indicate that congestion can also occur in the core of the Internet, where thousands of flows share high-bandwidth links. This raises the question: do our current understandings of CCA throughput and fairness hold at the scale found in the core of the Internet, with thousands of flows and Gbps bandwidths?

Our preliminary experimental study reveals that some expectations derived from edge settings do not hold at scale. For example, using loss rate as a parameter in the Mathis model to estimate TCP NewReno throughput works well in edge settings but fails to provide accurate estimates in high-bandwidth, high-flow-count scenarios. Additionally, BBR, which achieves good fairness in edge settings when competing solely with other BBR flows, can become highly unfair to other BBR flows in the core of the Internet. In this paper, we discuss these findings and their implications for future CCA analysis and evaluation.

### CCS Concepts
- Networks → Protocol testing and verification; Transport protocols; Network measurement

### Keywords
- Congestion control, computer networks, fairness, throughput, TCP, BBR, Reno, Cubic

### ACM Reference Format:
Adithya Abraham Philip, Ranysha Ware, Rukshani Athapathu, Justine Sherry, Vyas Sekar. 2021. Revisiting TCP Congestion Control Throughput Models & Fairness Properties At Scale. In ACM Internet Measurement Conference (IMC ’21), November 2–4, 2021, Virtual Event, USA. ACM, New York, NY, USA, 8 pages. https://doi.org/10.1145/3487552.3487834

This work is licensed under a Creative Commons Attribution International 4.0 License.
IMC ’21, November 2–4, 2021, Virtual Event, USA 
© 2021 Copyright held by the owner/author(s). 
ACM ISBN 978-1-4503-9129-0/21/11.
https://doi.org/10.1145/3487552.3487834

### 1. Introduction
Congestion control algorithms (CCAs) are a fundamental component of the modern Internet, and the networking community has been analyzing and designing CCAs for over three decades [12, 18, 26, 37, 39, 48]. In the wide-area setting, throughput and fairness are critical CCA properties, as they determine the effectiveness of data transfer across the Internet and the coexistence of multiple TCP flows. Many past efforts have used systematic models and experimental studies to understand these properties. For instance, the models by Mathis et al. [37] and Padhye et al. [41] predict the throughput of a NewReno flow as a function of packet loss and round-trip time (RTT), while the BBR model by Ware et al. [48] predicts the throughput of BBR when competing with other CCAs. Application developers can use such results to choose the best CCA for their network conditions or to debug performance issues.

One implicit assumption in many of these results is that in the wide-area setting, congestion almost always occurs close to the edge or last mile of the network. Consequently, many findings have been derived in contexts that emulate congestion occurring at the edge (e.g., residential link settings). Specifically, they consider a few or tens of flows competing for a shared bottleneck link with a capacity of a few tens or hundreds of Mbps [26, 37, 45, 52].

However, many measurements suggest that this assumption may not always hold. Indeed, both new [21] and old [11] measurements show that congestion does occur at inter-domain links, characterized by higher flow counts and larger network pipes [4, 13]. Past work on router buffer sizing has shown that CCA properties can change in such settings [13].

This raises a natural question: do the known findings and models about TCP throughput [37] and fairness [20, 26, 28, 39] derived from edge-link settings hold at the scale found in the core of the Internet? To address this, we revisit aspects of TCP throughput and fairness at high bandwidths of 10Gbps and with thousands of concurrent flows. Specifically, we ask:

- **Throughput Model**: Does the commonly accepted Mathis analytical model [37] for TCP throughput prediction, which states that throughput depends only on RTT and loss, accurately predict TCP NewReno’s throughput at scale?
- **Intra-CCA Fairness**: Do NewReno, Cubic, and BBR, which have shown to be fair at lower flow counts when all flows have the same CCA and RTT [20, 26, 28, 39], continue to be fair at scale?
- **Inter-CCA Fairness**: Does the inter-CCA unfairness observed in home link settings, where Cubic takes up to 80% of link bandwidth when competing with NewReno [26], or BBR starves competing NewReno and Cubic flows [28, 47, 48, 52], continue to hold at scale?

We use a simple but effective measurement setup to answer these questions, re-evaluating past beliefs on a 10 Gbps bottleneck link with thousands of competing flows, representative of the core of the Internet [4, 13]. We find that some edge-derived expectations do not hold at scale:

- The Mathis model [37] for NewReno throughput relies on a parameter \( p \) commonly interpreted as the network loss rate [44, 46]. While using loss rate for \( p \) works well in edge settings, we find that using packet loss rate for \( p \) at scale results in more than 45% error in estimating throughput. Instead, operators should use direct measurements of the congestion window halving rate for throughput estimates at this scale.
- BBR surprisingly becomes unfair at scale even when competing with solely other BBR flows at the same RTT, with a Jain’s Fairness Index (JFI) as low as 0.4. This contrasts with the fairness observed in edge settings or at low flow counts, where the JFI is typically 0.99 [28, 47, 52].

On the other hand, our findings validate prior claims about CCAs derived from analyses evaluating the edge:

- A single BBR flow takes up 40% of link capacity even when competing with thousands of NewReno or Cubic flows at scale. Prior work had only measured this phenomenon at up to 16 competing flows [42, 47, 48], and our measurements illustrate that this phenomenon persists even at scale. This confirms the prediction from the model by Ware et al. [48].
- The intra-CCA fairness of NewReno and Cubic and the inter-CCA unfairness of Cubic competing with NewReno continue to hold at scale. The extreme inter-CCA unfairness when multiple BBR flows compete with multiple Cubic or NewReno flows also persists at scale.

Our preliminary results have key implications for CCA design and analysis and suggest the need for future analysis. First, applying the Mathis model over the Internet precisely will require end-host TCP instrumentation to obtain the congestion window values, as one cannot rely on just measured packet loss. Second, BBR’s unexpectedly high unfairness when competing with just other BBR flows at scale highlights the importance of explicitly including evaluations with thousands of flows and Gbps bandwidths as part of future CCA design and evaluation roadmaps.

### 2. Related Work & Motivation

#### 2.1. CCA Background
Today, there are many CCAs on the Internet, including NewReno [25], Cubic [44], Vegas [17], Copa [14], and BBRv1 [18] (hereafter referred to as 'BBR') as well as BBRv2 [2] (which remains a work in progress). Developers and network administrators evaluate CCAs for important properties, including:

- **Throughput**: The rate at which a connection transfers data [26, 37, 41].
- **Fairness**: How equitably multiple connections share throughput when competing over a bottleneck link [20, 39, 44].

#### 2.2. Throughput Models
Analytical models help us understand how well a CCA performs in a given network setting by predicting the throughput of a connection as a function of key network properties (e.g., loss, delay). For example, the NewReno models by Mathis et al. [37] and Padhye et al. [41] predict the throughput of a NewReno flow given the network RTT and loss rate. Researchers have derived similar models for Cubic [26] and BBR [48]. In this paper, we revisit the simpler model for NewReno throughput by Mathis et al. [37] and investigate the fairness implications of the BBR model by Ware et al. [48].

#### 2.3. Fairness
Fairness determines the deployability of a CCA. For example, if Cubic flows completely starve NewReno flows when competing for bandwidth over a shared link, Netflix streams (which use NewReno) would see degraded performance every time they share a bottleneck link with large downloads using Cubic. Fairness is typically evaluated in two settings:

- **Intra-CCA Fairness**: All competing flows have the same CCA.
- **Inter-CCA Fairness**: Competing flows have different CCAs.

Past research has found that in the wide-area context, NewReno, Cubic, and BBR all exhibit high intra-CCA fairness when all flows have the same RTT, with most flows getting the same throughput [18, 20, 26, 28]. There is also work on intra-CCA fairness when flows have different RTTs [26, 32, 35, 39]. In this paper, as a simpler starting point, we specifically evaluate the same-RTT setting.

In the inter-CCA setting, prior work shows that Cubic flows compete unfairly with NewReno, with Cubic obtaining up to 80% of total bandwidth [26]. Past research also finds that BBR competes unfairly with both Cubic and NewReno, with a single BBR flow taking up 40% of link capacity irrespective of the number of competing Cubic and NewReno flows [47, 48]. Multiple BBR flows competing with an equal number of Cubic flows also result in the BBR flows obtaining 90% to 95% of link bandwidth with large buffers [45] and up to 99% with small buffers [28]. We re-evaluate all of these findings in the context of high-bandwidth, high-flow-count scenarios.