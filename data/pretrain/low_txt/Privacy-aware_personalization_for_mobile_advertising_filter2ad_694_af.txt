### Protecting User Anonymity and Location Privacy

To protect the anonymity of users and the privacy of their locations, a user's location in a query is replaced with a broader region that contains at least \( k \) users [38]. This approach has been extended to contexts beyond location [36]. Following the principles of \( \ell \)-diversity [32], a region is considered broad enough if its area is sufficiently large and the ratio of sensitive area to total area is low (e.g., [9]). Most solutions, such as [35], follow a hybrid approach where the server returns a superset of the results, which can lead to high communication costs. Notable exceptions approximate the results, allowing for a trade-off between efficiency and accuracy [10, 28, 47].

Our work shares the same goals as Location-Based Services (LBS): privacy, utility, and efficiency. However, while LBS focus on nearest neighbor queries and measure utility as proximity, our work focuses on targeted advertisements, measuring utility as revenue or ad relevance. Previous techniques are not directly applicable to this problem.

### Privacy-Preserving Distributed Count Protocols

Previous work on distributed counting protocols [1, 12, 37, 40] provides strong privacy guarantees. Early work by Dwork et al. [12] required a number of messages quadratic in the number of users, which is prohibitively expensive in our setting. Follow-up work by Rastogi et al. [37], Shi et al. [40], and Ács et al. [1] reduced the number of messages to be linear in the number of users. In Section 5.5, we empirically demonstrated that even under modest assumptions about user dynamics, these existing protocols need to repeat various phases an impractically high number of times, which is problematic in our setting with a large number of transient mobile users.

Chen et al. [8] extended our Count protocol to guarantee accuracy and prevent malicious users from arbitrarily altering the result. This is achieved by using the Goldwasser-Micali bit encryption scheme [17] and adding noise at the proxy.

### Conclusion

We have addressed the problem of personalizing ad delivery to smartphones without violating user privacy. We showed that the problem of selecting the most relevant ads under constraints on privacy and efficiency is NP-hard and proposed a solution with a tight approximation guarantee. We also proposed the first differentially-private distributed protocol to compute various statistics required for our framework, even in the presence of a dynamic and malicious set of participants. Our experiments on real click logs demonstrated that reasonable levels of privacy, efficiency, and ad relevance can be achieved simultaneously.

### References

[1] Gergely Ács and Claude Castelluccia. "I have a dream!: differentially private smart metering." In Proceedings of the 13th International Conference on Information Hiding (IH), 2011.
[2] Gagan Aggarwal, Mayank Bawa, Prasanna Ganesan, Hector Garcia-Molina, Krishnaram Kenthapadi, Rajeev Motwani, Utkarsh Srivastava, Dilys Thomas, and Ying Xu. "Two can keep a secret: A distributed architecture for secure database services." In CIDR, 2005.
[3] Bhuvan Bamba, Ling Liu, Peter Pesti, and Ting Wang. "Supporting anonymous location queries in mobile environments with PrivacyGrid." In WWW, 2008.
[4] Thorben Burghardt, Klemens Böhm, Achim Guttmann, and Chris Clifton. "Anonymous search histories featuring personalized advertisement - balancing privacy with economic interests." Transactions on Data Privacy, 4(1):31–50, 2011.
[5] Georg Buscher, Susan T. Dumais, and Edward Cutrell. "The good, the bad, and the random: an eye-tracking study of ad quality in web search." In SIGIR, 2010.
[6] A. Chen. "Gcreep: Google engineer stalked teens, spied on chats." http://gawker.com/5637234, September 2010.
[7] Bee-Chung Chen, Daniel Kifer, Kristen LeFevre, and Ashwin Machanavajjhala. "Privacy-preserving data publishing." Foundations and Trends in Databases, 2(1-2):1–167, 2009.
[8] Ruichuan Chen, Alexey Reznichenko, Paul Francis, and Johannes Gehrke. "Towards statistical queries over distributed private user data." In NSDI, 2012.
[9] Reynold Cheng, Yu Zhang, Elisa Bertino, and Sunil Prabhakar. "Preserving user location privacy in mobile data management infrastructures." In Privacy Enhancing Technologies, 2006.
[10] Chi-Yin Chow, Mohamed F. Mokbel, Joe Naps, and Suman Nath. "Approximate evaluation of range nearest neighbor queries with quality guarantee." In SSTD, 2009.
[11] Direct Marketing News. "Mobile marketing to 'explode' in 2012." http://www.dmnews.com/mobile-marketing-to-explode-in-2012/article/222991/, January 2012.
[12] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. "Our data, ourselves: Privacy via distributed noise generation." In EUROCRYPT, volume 4004, 2006.
[13] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. "Calibrating noise to sensitivity in private data analysis." In TCC, 2006.
[14] Uriel Feige. "A threshold of ln n for approximating set cover." Journal of the ACM, 45:314–318, 1998.
[15] Matthew Fredrikson and Benjamin Livshits. "REPRIV: Re-imagining content personalization and in-browser privacy." In IEEE Symposium on Security and Privacy (Oakland), 2011.
[16] William Gasarch. "A survey on private information retrieval." Bulletin of the EATCS, 82:72–107, 2004.
[17] Shafi Goldwasser and Silvio Micali. "Probabilistic encryption." J. Comput. Syst. Sci., 28(2):270–299, 1984.
[18] Michaela Götz. "On User Privacy in Personalized Mobile Services." PhD thesis, Cornell University, 2012.
[19] Michaela Götz, Ashwin Machanavajjhala, Guozhang Wang, Xiaokui Xiao, and Johannes Gehrke. "Publishing search logs - a comparative study of privacy guarantees." TKDE, 99(PrePrints), 2011.
[20] Marco Gruteser and Dirk Grunwald. "Anonymous usage of location-based services through spatial and temporal cloaking." In MobiSys, 2003.
[21] Saikat Guha, Bin Cheng, and Paul Francis. "Challenges in Measuring Online Advertising Systems." In IMC, 2010.
[22] Saikat Guha, Alexey Reznichenko, Kevin Tang, Hamed Haddadi, and Paul Francis. "Serving Ads from localhost for Performance, Privacy, and Profit." In HotNets, 2009.
[23] Moritz Hardt and Guy Rothblum. "A multiplicative weights mechanism for interactive privacy-preserving data analysis." In FOCS, 2010.
[24] Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu. "Boosting the accuracy of differentially private histograms through consistency." PVLDB, 3(1):1021–1032, 2010.
[25] Dorit Hochbaum and Anu Pathria. "Analysis of the Greedy Approach in Problems of Maximum k-Coverage." Naval Research Logistics, 45(6):615–627, 1998.
[26] Christian S. Jensen, Hua Lu, and Man Lung Yiu. "Location Privacy Techniques in Client-Server Architectures," pages 31–58. Springer-Verlag, 2009.
[27] Ari Juels. "Targeted advertising ... and privacy too." In CT-RSA, 2001.
[28] Ali Khoshgozaran and Cyrus Shahabi. "Blind evaluation of nearest neighbor queries using space transformation to preserve location privacy." In SSTD, 2007.
[29] Aleksandra Korolova. "Privacy violations using microtargeted ads: A case study." In PADM, 2010.
[30] Andreas Krause and Eric Horvitz. "A utility-theoretic approach to privacy and personalization." In AAAI, 2008.
[31] Ashwin Machanavajjhala, Daniel Kifer, John M. Abowd, Johannes Gehrke, and Lars Vilhuber. "Privacy: Theory meets practice on the map." In ICDE, 2008.
[32] Ashwin Machanavajjhala, Daniel Kifer, Johannes Gehrke, and Muthuramakrishnan Venkitasubramaniam. "\(\ell\)-diversity: Privacy beyond k-anonymity." TKDD, 1(1), 2007.
[33] Frank McSherry and Ratul Mahajan. "Differentially-private network trace analysis." In SIGCOMM, 2010.
[34] Emiliano Miluzzo, Cory T. Cornelius, Ashwin Ramaswamy, Tanzeem Choudhury, Zhigang Liu, and Andrew T. Campbell. "Darwin phones: The evolution of sensing and inference on mobile phones." In MobiSys, 2010.
[35] Mohamed F. Mokbel, Chi-Yin Chow, and Walid G. Aref. "The new Casper: A privacy-aware location-based database server." In ICDE, 2007.
[36] Linda Pareschi, Daniele Riboni, Alessandra Agostini, and Claudio Bettini. "Composition and generalization of context data for privacy preservation." In PerComm, 2008.
[37] Vibhor Rastogi and Suman Nath. "Differentially private aggregation of distributed time-series with transformation and encryption." In SIGMOD, 2010.
[38] Pierangela Samarati and Latanya Sweeney. "Protecting privacy when disclosing information: k-anonymity and its enforcement through generalization and suppression." Technical report, CMU, SRI, 1998.
[39] Xuehua Shen, Bin Tan, and ChengXiang Zhai. "Implicit user modeling for personalized search." In CIKM, 2005.
[40] Elaine Shi, T-H. Hubert Chan, Eleanor Rieffel, Richard Chow, and Dawn Song. "Privacy-preserving aggregation of time-series data." In NDSS, 2011.
[41] Eran Toch, Justin Cranshaw, Paul Hankes Drielsma, Janice Y. Tsai, Patrick Gage Kelley, James Springfield, Lorrie Cranor, Jason Hong, and Norman Sadeh. "Empirical models of privacy in location sharing." In Ubicomp, 2010.
[42] Vincent Toubiana, Helen Nissenbaum, Arvind Narayanan, Solon Barocas, and Dan Boneh. "Adnostic: Privacy preserving targeted advertising." In NDSS, 2010.
[43] Xiaokui Xiao, Guozhang Wang, and Johannes Gehrke. "Differential privacy via wavelet transforms." In ICDE, 2010.
[44] Yabo Xu, Ke Wang, Benyu Zhang, and Zheng Chen. "Privacy-enhancing personalized web search." In WWW, 2007.
[45] Mingqiang Xue, Panos Kalnis, and Hung Keng Pung. "Location diversity: Enhanced privacy protection in location-based services." In LoCA, 2009.
[46] Jun Yan, Ning Liu, Gang Wang, Wen Zhang, Yun Jiang, and Zheng Chen. "How much can behavioral targeting help online advertising?" In WWW, 2009.
[47] Man Lung Yiu, Christian S. Jensen, Xuegang Huang, and Hua Lu. "SpaceTwist: Managing the trade-offs among location privacy, query performance, and query accuracy in mobile services." In ICDE, 2008.

### Appendix

#### A. Proofs

**A.1 Proof of Corollary 4.3**

**Proof.** Consider two neighboring click logs \( L \) and \( L' \), where \( L' \) is obtained from \( L \) by adding or deleting the data of a single user. Consider the hierarchy \( H \) consisting of \( \text{height}(H) \) levels, where level \( i \) contains \( 2^i \) nodes. We denote by \( c_{l,j} \) (resp. \( c'_{l,j} \)) the count of the \( j \)-th node at level \( l \) in \( L \) (resp. \( L' \)). We denote by \( c_{l,j,a,1} \) (resp. \( c'_{l,j,a,1} \)) the count of clicks on \( a \) in the \( j \)-th node at level \( l \) and by \( c_{l,j,a,0} \) (resp. \( c'_{l,j,a,0} \)) the count of views of \( a \) in the \( j \)-th node at level \( l \) that did not result in clicks in \( L \) (resp. \( L' \)).

Within a level of the hierarchy, the \( L_2 \)-sensitivity of each count is at most \( m \). Overall, the square of the \( L_2 \)-sensitivity is at most:

\[
\sum_{l=0}^{\text{height}(H)-1} \sum_{j=1}^{2^l} (c_{l,j} - c'_{l,j})^2 + \sum_{l=0}^{\text{height}(H)-1} \sum_{j=1}^{2^l} \sum_a (c_{l,j,a,1} - c'_{l,j,a,1})^2 + (c_{l,j,a,0} - c'_{l,j,a,0})^2
\]

\[
\leq 3 \cdot m^2 \cdot \text{height}(H)
\]

Thus, the \( L_2 \)-sensitivity is bounded by \( \sqrt{3 \cdot \text{height}(H) \cdot m} \). From Theorem 4.1, it follows that choosing \( \sigma^2 \geq \frac{3 \cdot \text{height}(H) \cdot m^2 \cdot 2 \log(4/\delta)}{\epsilon^2} \) guarantees \( (\epsilon, \delta) \)-probabilistic differential privacy.

**A.2 Utility Analysis of Algorithm 2**

We define the utility of an estimate \( \hat{CTR}(a|v) \) by comparing it to the true click-through-rate:

\[
\text{true CTR}(a|v) = \frac{\text{clicks\_true}_{a,v}}{\text{clicks\_true}_{a,v} + \text{no\_clicks\_true}_{a,v}}
\]

We say the estimate is \( (\alpha, \beta) \)-accurate if with probability at least \( \beta \):

\[
\hat{CTR}(a|v) \geq \frac{\text{clicks\_true}_{a,v} - \alpha}{\text{clicks\_true}_{a,v} + \text{no\_clicks\_true}_{a,v} + 2\alpha}
\]

\[
\hat{CTR}(a|v) \leq \frac{\text{clicks\_true}_{a,v} + \alpha}{\text{clicks\_true}_{a,v} + \text{no\_clicks\_true}_{a,v} - 2\alpha}
\]

Consider our protocol Estimates (and its parameters \( N \), \( t \), \( \sigma \) as in Corollary 4.3) and suppose all users respond truthfully. Then the computed estimates are \( (\alpha, \beta) \)-accurate for:

\[
\beta \leq 1 - \frac{3}{2\pi\alpha} \sigma \sqrt{\frac{N}{(1-t)N - 1}} \exp\left(-\frac{\alpha^2 ((1-t)N - 1)}{2N \sigma^2}\right)
\]

The proof follows from a Gaussian tail bound that we can use to bound the probabilities of:

\[
|\text{clicks\_true}_{a,v} - \text{clicks}_{a,v}| > \alpha \quad \text{and} \quad |\text{no\_clicks\_true}_{a,v} - \text{no\_clicks}_{a,v}| > \alpha
\]

However, it may happen that the algorithm does not output an estimate \( \hat{CTR}(a|v) \) for some \( a, v \) if the noisy count of context \( v \) or some ancestor in the context hierarchy is less than the min_support.