# ROC Plots and Model Performance Analysis

**Figure 2.** ROC plots for three users: Faculty Member, Ph.D. Student, and Master’s Student.

- **False Positive Rate (FPR):** 0, 0.2, 0.4, 0.6, 0.8, 1
- **Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005)**
- **1063-9527/05 $20.00 © 2005 IEEE**
- **Authorized licensed use limited to: Tsinghua University. Downloaded on March 25, 2021, at 12:13:33 UTC from IEEE Xplore. Restrictions apply.**

## Table 5. Model Performance Using Default (dp) and Optimal (op) Parameter Settings

| User           | psw  | plw  | pv   | pC  | pW  | f p  | f a  | tp   |
|----------------|------|------|------|-----|-----|------|------|------|
| Fac. (dp)      | 40   | 800  | 0    | 10  | 2.0 | 0.11 | 9    | 1.0  |
| Fac. (op)      | 40   | 800  | 0    | 20  | 2.5 | 0.04 | 25   | 0.96 |
| Ph.D. (dp)     | 5    | 100  | 0    | 10  | 2.0 | 0.16 | 6    | 0.91 |
| Ph.D. (op)     | 5    | 75   | 1    | 20  | 2.0 | 0.04 | 25   | 0.90 |
| M.S. (dp)      | 30   | 600  | 0    | 10  | 2.0 | 0.13 | 8    | 0.55 |
| M.S. (op)      | 30   | 300  | 0    | 10  | 2.5 | 0.1  | 10   | 1.0  |

- **f p:** False Positive Rate
- **f a:** False Alarm Rate
- **tp:** True Positive Rate

## Feasibility Analysis of the Model

To date, our focus has been on using offline experiments to evaluate the feasibility of the model in distinguishing legitimate users from simulated attacker behavior (attack model AU D). Specifically, we have tested how different parameter settings affect the trade-off between false positives and true positives. For our approach to be feasible, it must detect a significant number of attacks while generating no more false positives than a regular user could handle.

### ROC Curve Analysis

**Figure 2** shows the ROC curves for each user based on 96 sets of parameters, with one point per parameter set. These parameter sets are selected combinations of the values listed in Table 4. 

- **Faculty and Ph.D. Students:** Most points are located in the upper left corner, indicating a false positive rate less than 20% and a true positive rate greater than 80%.
- **Master’s Student:** Points are spread more evenly across the range of false positives, suggesting that the disposition of this user's emails is not significantly determined by the sender.

This discrepancy can be explained by the fact that the master’s student receives many automated messages for systems administrative purposes, which originate from a small number of non-human email senders.

### False Alarm Rate Analysis

To further understand how these false positive rates translate into alarms, we analyzed the false alarm rate (f a), which represents the average number of days between false alarms. Given that the size of short-term data is set to the average number of new messages received each day, f a is equal to 1/f p.

**Table 5** shows the false positive rate, average daily false alarm rate, and true positive rate for default and optimal parameter settings. Optimal settings produce the best performance in terms of low false positives and high true positives. From the table, we see that false alarm rates are relatively low, meaning a user would only be bothered once a week at most, and for better-behaved users, roughly once a month on average. Despite these settings, over half (and generally, almost all) attacks would be detected.

## Discussion

Although we are encouraged by our results, several limitations must be considered:

1. **Small User Population:** Our results are based on a very small user population. While we do not believe any simple model of user behavior can apply to all users, our results suggest that our modeling strategy has a good chance of working for some high-volume email users.

2. **Assumptions:** Several assumptions were made when analyzing true and false positives, which may not be entirely realistic. Users receive a highly variable number of messages daily, and typical email archive attackers do not read new messages every day. While such complications need to be addressed in an online implementation, we do not believe they would significantly change our basic results.

3. **Email Client Behavior:** In practice, we would not want to exclude email client behavior from normal access behavior, as it can be difficult to distinguish between intended user behavior and program-generated incidental IMAP commands. However, such additions should not significantly impact false positive rates and may improve true positive rates if attackers use different email clients.

4. **Detection Limitations:** Our detector can only detect an attack once per day, and we are uncertain about the effect of interleaved attacker and normal behavior on our model’s accuracy. Future work should address the gap between realistic attacker behaviors and the attack model AU D.

Despite these limitations, we believe it is possible to build a practical email archive intrusion detection system by leveraging inherent features of the domain, selecting good features, and using simple and efficient modeling methods. Given the vulnerabilities and sensitivity of email archives, we hope this work encourages the development of email archive intrusion detection systems.

## Acknowledgements

The authors thank the members of the CCSL for their participation, encouragement, and feedback. This work was supported by the Canadian government through an NSERC Discovery Grant and MITACS.

## References

[1] D. Anderson, T. Frivold, and A. Valdes. Next-Generation Intrusion Detection Expert System (NIDES): A Summary. Technical Report SRI-CSL-95-07, Computer Science Laboratory, SRI International, May 1995.

[2] Apache Software Foundation. SpamAssassin, 2005. http://spamassassin.apache.org.

[3] F. Bergadano, D. Gunetti, and C. Picardi. User Authentication through Keystroke Dynamics. ACM Trans. Inf. Syst. Secur., 5(4):367-397, 2002.

[4] C. Chung, M. Gertz, and K. Levitt. DEMIDS: Misuse Detection System Database System. In IICIS, 1999.

[5] C. Cowan, C. Pu, D. Maier, J. Walpole, P. Bakke, S. Beattie, A. Grier, P. Wagle, Q. Zhang, and H. Hinton. StackGuard: Automatic Adaptive Detection and Prevention of Buffer-Overflow Attacks. In Proc. 7th USENIX Security Conference, Jan 1998.

[6] M. Crispin. Request for Comment (RFC) 3501: Internet Message Access Protocol—Version 4rev1, March 2003.

[7] M. Delany. Internet draft: Domain-based email authentication using public-keys advertised in the DNS (DomainKeys), March 2005. http://www.ietf.org/internet-drafts/draft-delany-domainkeys-base-02.txt.

[8] W. DuMouchel. Computer Intrusion Detection Based on Bayes Factors for Comparing Command Transition Probabilities. Technical report, National Institute of Statistical Sciences (NISS), 1999.

[9] L. Heberlein, G. Dias, K. Levitt, B. Mukherjee, J. Wood, and D. Wolber. A Network Security Monitor. In Proceedings of the IEEE Symposium on Security and Privacy, 1990.

[10] S. Hofmeyr. An Immunological Model of Distributed Detection and its Application to Computer Security. PhD thesis, University of New Mexico, 1999.

[11] G. Kim and E. Spafford. The Design and Implementation of Tripwire: A File System Integrity Checker. In ACM Conference on Computer and Communication Security, 1994.

[12] J. Klensin. Request for Comment (RFC) 2821: Simple Mail Transfer Protocol, April 2001.

[13] T. Lane. Machine Learning Techniques for the Computer Security Domain of Anomaly Detection. PhD thesis, Purdue University, 2000.

[14] Y. Li. Email archive intrusion detection systems. Master’s thesis, Carleton University, 2005.

[15] R. Maxion and T. Townsend. Masquerade Detection Using Truncated Command Lines. In DSN ’02: Proceedings of the 2002 International Conference on Dependable Systems and Networks, 2002.

[16] J. Myers and M. Rose. Request for Comment (RFC) 1939: Post Office Protocol—Version 3, May 1996.

[17] M. Oka, Y. Oyama, H. Abe, and K. Kato. Anomaly Detection Using Layered Networks Based on Eigen Co-occurrence Matrix. In RAID 2004 Proceedings, volume 3224 of LNCS, pages 223-237. Springer-Verlag, 2004.

[18] B. Ramsdell. Request for Comment (RFC) 2633: S/MIME Version 3 Message Specification, June 1999.

[19] M. Roesch. Snort—Lightweight Intrusion Detection for Networks. In Proceedings of LISA ’99: 13th Systems Administration Conference, Seattle, WA, November 7-12, 1999.

[20] M. Schonlau, W. DuMouchel, W. Ju, A. Karr, M. Theus, and Y. Vardi. Computer intrusion: Detecting masquerades. Statistical Science, 16(1):1-17, 2001.

[21] A. Somayaji. Operating System Stability and Security through Process Homeostasis. PhD thesis, University of New Mexico, 2002.

[22] A. Somayaji and S. Forrest. Automated Response Using System-Call Delays. In Proceedings of the 9th USENIX Security Symposium, Denver, CO, August 14-17, 2000.

[23] The Spamhaus Project. http://www.spamhaus.org, 2005.

[24] University of Washington. IMAP information center. http://www.washington.edu/imap/, 2005.

[25] K. Wang and S. J. Stolfo. Anomalous Payload-based Network Intrusion Detection. In RAID 2004 Proceedings, volume 3224 of LNCS, pages 203-222. Springer-Verlag, 2004.

[26] M. Wong and W. Schlitt. Internet draft: Sender policy framework (SPF) for authorizing use of domains in e-mail, version 1, June 6, 2005. http://www.ietf.org/internet-drafts/draft-schlitt-spf-classic-02.txt.

[27] P. Zimmerman. The official PGP user’s guide. MIT Press, Cambridge, MA, 1995.

**Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005)**
**1063-9527/05 $20.00 © 2005 IEEE**
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 25, 2021, at 12:13:33 UTC from IEEE Xplore. Restrictions apply.**