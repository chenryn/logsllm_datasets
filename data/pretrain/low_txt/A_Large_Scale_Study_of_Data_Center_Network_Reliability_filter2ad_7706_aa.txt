# A Large-Scale Study of Data Center Network Reliability

**Authors:**
- Justin Meza, Facebook, Inc.
- Tianyin Xu, Facebook, Inc.
- Kaushik Veeraraghavan, Facebook, Inc.
- Onur Mutlu, ETH Zürich and Carnegie Mellon University

**Abstract:**
The ability to tolerate, remediate, and recover from network incidents (e.g., caused by device failures and fiber cuts) is critical for building and operating highly available web services. Achieving fault tolerance and failure preparedness requires system architects, software developers, and site operators to have a deep understanding of network reliability at scale, along with its implications for data center systems. Unfortunately, little has been reported on the reliability characteristics of large-scale data center network infrastructure, let alone its impact on the availability of services powered by software running on that network infrastructure (service-level availability).

This paper addresses this gap by presenting a large-scale, longitudinal study of data center network reliability based on operational data collected from the production network infrastructure at Facebook, one of the largest web service providers in the world. The study covers the reliability characteristics of both intra and inter data center networks. For intra data center networks, we analyze seven years of operational data comprising thousands of network incidents across two different data center network designs: a classic cluster-based architecture and a state-of-the-art fabric-based topology. For inter data center networks, we examine eighteen months of recent repair tickets to understand the reliability of WAN backbones.

In contrast to prior work, we study the effects of network reliability on web services and how these reliability characteristics evolve over time. We discuss the implications of network reliability on the design, implementation, and operation of large-scale data center systems and how it affects highly available web services. We hope our study forms the foundation for understanding the reliability of large-scale network infrastructure and inspires new reliability solutions to network incidents.

**Keywords:**
data centers, network, reliability

**Permissions:**
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

**IMC '18, October 31–November 2, 2018, Boston, MA, USA**
© 2018 Association for Computing Machinery.
ACM ISBN TBA...$TBA
https://doi.org/TBA

**ACM Reference Format:**
Justin Meza, Tianyin Xu, Kaushik Veeraraghavan, and Onur Mutlu. 2018. A Large Scale Study of Data Center Network Reliability. In Proceedings of IMC '18. ACM, New York, NY, USA, 17 pages. https://doi.org/TBA

## 1. Introduction
Data center network infrastructure, consisting of both intra and inter data center networks, is a cornerstone of large-scale, geo-distributed web services. Over the past two decades, data center network infrastructure has evolved rapidly, driven by the scalability challenges derived from ever-increasing traffic demand and the consequent need for larger and more geographically distributed data centers. New technologies for data center networks [1–3, 24, 34, 36, 37, 42, 48, 54, 57, 70] and WAN backbones [38, 40, 44, 59] have been designed, deployed, and operated in the field. At a high level, both data center and backbone networks are moving from traditional Clos-based network designs [19] running on large vendor hardware toward designs featuring more centralized automation, monitoring, and control.

Despite the significance of network infrastructure in data center operations, three aspects of data center network infrastructure are not well understood in the literature:
1. Little has been reported on the overall reliability characteristics of data center network infrastructure, from the networks within data centers to the networks that interconnect different data centers.
2. No previous study has examined the reliability trends associated with the transition away from cluster-based Clos network designs toward modern fabric-based topologies with automated failover [70].
3. There is relatively little discussion regarding the impact of network design decisions from the perspective of the software services that run on top of the networks (i.e., the network's effect on service-level availability).

In the past, lack of understanding has hindered researchers and practitioners in combating network incidents [7]. Today, network incidents have become a major root cause of data center system outages, as shown in recent studies [8, 27, 35, 60] and news reports [20, 23, 31, 32, 72]. For example, Gunawi et al. [35] studied 597 unplanned web and cloud service outages from headline news and public postmortem reports over a 7-year span from 2009 to 2015. Their study shows that network incidents contributed to 15% of these outages, constituting the second largest root cause category.

Therefore, understanding network reliability and its implications on service-level availability is critically important to the design, implementation, and operation of large-scale data center systems.

A number of prior studies have examined the reliability of data center networks and network devices [29, 30, 33, 62, 63]. However, most of these studies focus on the failure characteristics of network devices and links without connecting their impact to service-level events. Service-level events often manifest as failures and anomalies in the production systems running on data center network infrastructure and transmitting data on the network. In fact, not all device- and link-level failures are created equal—many failures are masked by built-in hardware redundancy, path diversity, and other fault-tolerance logic. Compared with network device failures, network incidents (i.e., misbehavior of the network as a whole that impairs the availability or quality of large-scale web services) are among the least understood types of failures in the literature.

This paper fills the gap by presenting a large-scale, longitudinal study on the reliability of data center network infrastructure. The study is based on seven years of intra data center operational data and eighteen months of inter data center operational data collected from the production systems of Facebook, one of the largest web service providers in the world. Facebook serves 2.4 billion monthly users and operates twelve geographically distributed data centers with multiple generations of data center network design; these data centers are interconnected via our Wide Area Network (WAN) backbone designed for serving different use cases (we will provide more detail on these use cases in §3).

We study the reliability characteristics of both data center and backbone networks from the perspective of service-level incidents in large-scale systems and how these reliability characteristics evolve over time. Specifically, we discuss in depth how data center network reliability influences the design, implementation, and operation of large-scale software systems that run highly available web services.

This paper makes the following major observations:
- Among the failures that cannot be remediated by software, we observe that most failures involve maintenance, faulty hardware, and misconfiguration as devices and routing configurations become more complex and challenging to maintain (§5.1).
- Network devices with higher bisection bandwidth have a higher likelihood of affecting service-level software, and network devices built from commodity chips have much lower incident rates compared to devices from third-party vendors due to the ease of integration with automated failover and remediation software (§5.2).
- Rack switches contribute to around 28% of the service-level incidents that occurred in the past year (2017). Despite rack switches having the largest mean time to incident (over ten million hours) compared to other types of network devices, the sheer size of the rack switch population leads to a noticeable reliability effect on the software systems running in data centers (§5.4).
- Core network devices that connect data centers and the backbone contribute to around 34% of service-level incidents compared to other network devices. This is because network devices with higher bisection bandwidth tend to affect a larger number of connected downstream devices and are thus correlated with widespread impact when these types of devices fail (§5.4).
- As opposed to cluster-based Clos networks, fabric networks contributed to around 50% of the number of intra data center network incidents in the past year (2017). We find that data center fabric networks are more reliable due to their simpler, commodity-chip-based switches and automated remediation software that dynamically adapts to and tolerates device failures (§5.5).
- While high reliability is essential for widely deployed devices, such as RSWs, incident rates can be greatly decreased through the use of software-managed failover and automated remediation (§5.6).
- We model the reliability of a diverse set of edge networks and links that provide backbone connectivity and find that time to failure and time to repair closely follow exponential functions. We provide models for these phenomena so that future studies can compare against them and use them to understand the nature of backbone failures (§6.1–§6.3).
- Backbone links that connect data centers typically fail on the order of weeks to months and typically recover on the order of hours. However, some backbone links exhibit very high mean time to repair, on the order of days. In these cases, path diversity in the backbone topology ensures that large-scale networks can tolerate failures with long repair times (§6.1, §6.1).
- Backbone link vendors exhibit a wide degree of variance in failure rates of their backbone links. This problem makes the task of planning and maintaining network connectivity and capacity a key challenge for large-scale web service companies (§6.2).

## 2. Motivation
The reliability of data center network infrastructure is critically important for building and operating highly available and scalable web applications [7, 16]. Despite an abundance of device- and link-level monitoring, the effects of network infrastructure reliability on the production systems that run on them are not well understood. The fundamental problem lies in the difficulty of correlating device- and link-level faults with system-level impact. First, with the redundancy built into most network infrastructure (including device, path, and protocol redundancy), many faults do not manifest as issues in the production systems that run on them. Second, large-scale network infrastructure is typically equipped with automated mitigation and failover mechanisms that take actions to resolve faults when they occur. At Facebook, the vast majority of device- and link-level faults are automatically mitigated and resolved, with neither human intervention nor noticeable service-level impact (§4.1).

As a result, we argue that it is impossible to fully characterize the impact of network incidents in the wild without examining how they affect services (their service-level effects). The systems community coined a term for this type of behavior that can only be studied at a full-system scale: emergent behavior. Emergent behavior describes the unexpected ways that complex systems (mis)behave that are not easily predictable from the behavior of their components [55]. We adopt this term to describe the types of system-level effects that we examine in large-scale data center networks. As software systems grow in complexity, interconnectedness, and geographic distribution, unwanted emergent behavior from network infrastructure has the potential to become a key limiting factor in the ability to reliably operate software systems at a large scale.

To understand the behavior of network failures, we must be able to answer questions such as: How long do network failures affect software when they occur? What are the root causes of the network failures that affect software? How do network failures manifest themselves in production systems? Unfortunately, past efforts to understand network incidents in large-scale network infrastructure are limited to informal surveys and a small number of public postmortem reports [7, 35], which could be biased toward certain types of failures and not comprehensive. As noted in [7], due to scant evidence and even less data, it is hard to discuss the reliability of distributed systems in the face of network incidents: “much of what we believe about the failure modes is founded on guesswork and rumor.”

Even for large web and cloud service providers, understanding the reliability of network infrastructure is challenging, given the complex, dynamic, and heterogeneous nature of large-scale networks. With complex and constantly evolving network designs built from a wide variety of vendor devices, it is hard to reason about the end-to-end reliability of network infrastructure under different failure modes, let alone how it affects the software that runs on it. As far as we know, from what limited information has been publicly discussed, this is a common challenge across the industry.

Facebook has attempted to address this challenge by seeking to understand the reliability of its data center network infrastructure. At Facebook, service-level events that affect reliability (known as SEVs) are rigorously documented and reviewed to uncover their root causes, duration, service-level impact, as well as recommended mitigation and recovery procedures (cf. §4.2) [52]. These postmortem reports form an invaluable source of information for analyzing and understanding network reliability from the perspective of large-scale web services.

Our goal is to shed light on the network reliability incidents that affect the design of reliable large-scale systems both within and between data centers and their system-level effects. Our study focuses on the perspective of the software systems that power large-scale web services. We hope that this work helps researchers and practitioners anticipate and prepare for network incidents and inspire new reliability solutions.

## 3. Facebook’s Network Architecture
Figure 1 shows Facebook’s network architecture [3, 24, 41, 67]. Facebook’s network consists of interconnected data center regions. Each region contains buildings called data centers. Facebook operates both data center and backbone networks. We call the network within data centers the intra data center network and the backbone network between data centers the inter data center network.

The diversity of Facebook’s network provides an opportunity to compare the reliability across network designs. Though diverse, Facebook’s network is by no means unique. Published network architectures from Google and Microsoft use similar design principles and building blocks [30, 33, 40, 62, 63, 70]. We suspect our findings and implications apply to other large-scale data center networks.