### Introduction

This section discusses methods for preventing errors from being introduced into the architected state through means other than incorrect execution. Although these techniques logically perform similar comparisons, they differ in granularity and mechanism.

### Lock-Step Approach

The lock-step approach ensures that both processors perform the same operations each cycle and compares the updates made by each processor to the architected state every cycle. If any deviation is detected, an error is reported. This method requires very high bandwidth between the two processors and will detect any propagating fault as an error to be corrected. The derating rate resulting from this error detection technique corresponds precisely to the no-propagate rates reported in Figure 5.

### Bandwidth Reduction Techniques

To reduce the required bandwidth between the two processors, other techniques summarize the changes to the register file (which are most of the changes to the architected state) in the form of a signature. These signatures are compared periodically, along with a trace of branch outcomes and store addresses and data [22]. These techniques reduce the required bandwidth at the cost of introducing a small possibility of false negatives, but the rate of false negatives can be controlled by the size of the signature.

#### Incremental Periodic Technique

The first periodic technique, called incremental periodic, constructs the signature by incrementally folding into the signature the information relating to writes to the register file as they retire from the processor. Since it includes the values produced by every instruction, the derating rate of the incremental periodic technique is identical to that of the lock-step approach.

#### Snapshot Periodic Technique

In contrast, the snapshot periodic technique constructs its signature from a periodic snapshot of the architected state. Because the snapshot is only taken periodically, faulty values have the opportunity to be masked (overwritten) before the snapshot is created. As a result, the software derating available includes both the passing no-propagate and a fraction of the passing propagate, as shown in the black bars in Figure 7. The fraction depends on how frequently the comparisons are performed. Therefore, the snapshot periodic technique is guaranteed to achieve a derating rate that equals or exceeds that of the other two techniques, supporting our assertion that error detection rates can differ due to propagating errors that are later masked.

### Experimental Data

The data shown in Figure 7 was collected using the same fault injection methodology described in Section 3, augmented with the error detection mechanisms discussed above. The first bar in each graph (LS) denotes the error derating of the lock-step and incremental periodic techniques. For the snapshot periodic technique, the error derating rate depends on the frequency of the checking, so we plot this function of frequency. In our implementation, we identify a subset of instructions (control, store, and system call instructions), which we refer to as check-fence instructions. We only generate snapshots after these instructions, as doing so increases the number of masked errors without significantly increasing the complexity of checking. We measure the derating rates that occur when checking at every check-fence instruction and at intervals of 10, 100, and 1000 check-fence instructions. We show data for five of the twelve SPEC CINT2000 benchmarks run at full optimization (-O3), whose results we believe to be representative for the whole suite. Additionally, we include the average results for these programs without optimization (-O0), which result in the same basic trends with slightly higher levels of masking.

### Performance Considerations

As previously noted, the black bars in Figure 7 demonstrate that the snapshot periodic error derating increases as the interval between checks increases. While increased derating is beneficial, it is important that it does not come at a huge increase in the latency to detect errors. For example, if an error occurs once every 10^5 instructions, performing error detection once every 5,000 instructions will result in roughly a 2.5% loss in performance, plus the overhead for recovery, as the faulting instruction will, on average, occur in the middle of the error detection interval. With a check-fence instruction occurring roughly every 4 instructions in our experiment, the intervals in Figure 7 correspond to checking for errors every 4, 40, 400, and 4,000 instructions.

A significant factor leading to increased derating with larger intervals is the greater temporal opportunity for a register containing an incorrect, and usually dead, value to be overwritten. Clearly, comparing the entire architected state is sufficient but not necessary for correctness; any values that are dead (i.e., known not to be referenced again) need not be checked, as they cannot affect further computation. To explore what further fraction of unnecessary error recoveries could be eliminated, we modified the LLVM compiler to record static register liveness information [16] associated with each check-fence instruction. In a second set of experiments shown in Figure 7, we demonstrate that by comparing only statically live register values between processors, almost 90% of the instruction-level error derating can be achieved, even with very small error detection intervals.

### Conclusion

In this work, we demonstrated the mechanisms that result in instruction-level error derating, i.e., how incorrect architectural state or incorrect instruction execution can lead to correct program behavior. We classified these mechanisms into six categories: value comparison, sub-word operations, logical operations, overflow/precision, lucky loads, and dynamically dead values. Unlike previous work on software derating that exploits the structure of the computation or the numerical properties of specific applications, these are general-purpose instruction properties found in all the programs we studied. Even if we conservatively restrict the opportunity for instruction-level derating by considering a fault as an error if it propagates to the memory system or affects control flow, we find that 36% of architecturally visible faults are derated and masked.

Understanding the mechanisms of software derating provides system builders with opportunities to exploit them. We considered two instruction-level derating-motivated opportunities in the context of systems that use error detection mechanisms to improve performance or reduce power consumption. First, we demonstrated that comparing architected state via periodic snapshots permits faults to be masked that would otherwise lead to error recovery actions if the result of every instruction were incorporated. Second, we demonstrated that the rate of derating can be further increased by excluding the contents of known dead registers from the comparison.

Looking forward, we believe there are other applications enabled by an understanding of the mechanism of instruction-level derating. In particular, we are interested in investigating the degree to which instruction-level derating can be increased by the optimizations performed by a compiler and how it handles code generation.

### Acknowledgment

This research was supported in part by NSF CCF-0702501 and NSF CAREER award CCF-0347260. The authors would also like to thank Lee Baugh, Brian Greskamp, Edward Lee, Naveen Neelakantam, and Pierre Salverda for their many useful comments.

### References

[1] The LLVM Compiler Infrastructure. Home page: http://llvm.cs.uiuc.edu/.

[2] T. Austin, E. Larson, and D. Ernst. Simplescalar: An infrastructure for computer system modeling. IEEE Computer, 35(2):59-67, Feb. 2002.

[3] T. M. Austin. DIVA: A reliable substrate for deep submicron microarchitecture design. In Proc. of the Int'l Symp. on Microarchitecture, pages 196-207, 1999.

[4] J. Blome, S. Mahlke, D. Bradley, and K. Flautner. A microarchitectural analysis of soft error propagation in a production-level embedded microprocessor. In Proc. of the Workshop on Architectural Reliability, 2005.

[5] S. Borkar et al. Parameter variations and impact on circuits and microarchitecture. In Proc. of the Annual Conf. on Design Automation, pages 338-342, 2003.

[6] J. A. Butts and G. S. Sohi. Characterizing and predicting value degree of use. In Proc. of the Int'l Symp. on Microarchitecture, pages 15-26, Nov. 2002.

[7] H. Cha, E. M. Rudnick, J. H. Patel, R. K. Iyer, and G. S. Choi. A gate-level simulation environment for alpha-particle-induced transient faults. IEEE Trans. on Computers, 45(11):1248-1256, Nov. 1996.

[8] J. J. Cook and C. Zilles. Characterizing instruction-level error derating. In Proc. of the IEEE Workshop on Silicon Errors in Logic System Effects, Mar 2008.

[9] D. Ernst, N. S. Kim, S. Das, S. Pant, R. Rao, T. Pham, C. Zeisler, D. Blaauw, T. Austin, K. Flautner, and T. Mudge. Razor: A low-power pipeline based on circuit-level timing speculation. In Proc. of the Int'l Symp. on Microarchitecture, pages 7-18, 2003.

[10] M. Favalli and C. Metra. Optimization of error detecting codes for the detection of crosstalk originated errors. In Proc. of the Conf. on Design, Automation and Test in Europe, 2001.

[11] M. Gomaa, C. Scarbrough, T. N. Vijaykumar, and I. Pomeranz. Transient-fault recovery for chip multiprocessors. In Proc. of the Int'l Symp. on Computer Architecture, pages 98-109, 2003.

[12] B. Greskamp and J. Torrellas. Paceline: Improving single-thread performance in nanoscale CMPs through core overclocking. In Proc. of the Int'l Conf. on Parallel Architecture and Compilation Techniques, pages 213-224, 2007.

[13] W. Gu, Z. Kalbarczyk, R. Iyer, and Z. Yang. Characterization of Linux kernel behavior under errors. In Proc. of the Int'l Conf. on Dependable Systems and Networks, June 2003.

[14] G. A. Kanawati, N. A. Kanawati, and J. A. Abraham. FERRARI: A flexible software-based fault and error injection system. IEEE Trans. on Computers, 44(2):248-260, Feb. 1995.

[15] X. Li and D. Yeung. Application-level correctness and its impact on fault tolerance. In Proc. of the Int'l Symp. on High-Performance Computer Architecture, 2007.

[16] M. M. Martin, A. Roth, and C. N. Fischer. Exploiting dead value information. In Proc. of the Int'l Symp. on Microarchitecture, pages 125-135, 1997.

[17] F. Mesa-Martinez and J. Renau. Effective optimistic-checker tandem core design through architectural pruning. In Proc. of the Int'l Symp. on Microarchitecture, 2007.

[18] S. Mitra, N. Seifert, M. Zhang, Q. Shi, and K. S. Kim. Robust system design with built-in soft-error resilience. IEEE Computer, 38(2):43-52, Feb. 2005.

[19] S. S. Mukherjee, C. Weaver, J. Emer, S. K. Reinhardt, and T. Austin. A systematic methodology to compute the architectural vulnerability factors for a high-performance microprocessor. In Proc. of the Int'l Symp. on Microarchitecture, pages 29-40, 2003.

[20] G. P. Saggese, A. Vetteth, Z. Kalbarczyk, and R. Iyer. Microprocessor sensitivity to failures: control vs. execution and combinational vs. sequential logic. In Proc. of the Int'l Conf. on Dependable Systems and Networks, pages 760-769, June 2005.

[21] P. Shivakumar, M. Kistler, S. W. Keckler, D. Burger, and L. Alvisi. Modeling the effect of technology trends on the soft error rate of combinational logic. In Proc. of the Int'l Conf. on Dependable Systems and Networks, pages 389-398, June 2002.

[22] J. C. Smolens, B. T. Gold, J. Kim, B. Falsafi, J. C. Hoe, and A. G. Nowatzyk. Fingerprinting: bounding soft-error detection latency and bandwidth. In Proc. of the Int'l Conf. on Architectural Support for Programming Languages and Operating Systems, pages 224-234, 2004.

[23] J. Srinivasan, S. V. Adve, P. Bose, and J. A. Rivers. The case for lifetime reliability-aware microprocessors. In Proc. of the Int'l Symp. on Computer Architecture, 2004.

[24] K. Sundaramoorthy, Z. Purser, and E. Rotenberg. Slipstream processors: Improving both performance and fault tolerance. In Proc. of the Int'l Conf. on Architectural Support for Programming Languages and Operating Systems, pages 257-268, Nov. 2000.

[25] D. D. Thaker, D. Franklin, V. Akella, and F. T. Chong. Reliability requirements of control, address, and data operations in error-tolerant applications. In Proc. of the Workshop on Architectural Reliability, 2005.

[26] N. Wang, M. Fertig, and S. Patel. Y-branches: When you come to a fork in the road, take it. In Proc. of the Int'l Conf. on Parallel Architectures and Compilation Techniques, page 56, 2003.

[27] N. J. Wang, A. Mahesri, and S. J. Patel. Examining ACE analysis reliability estimates using fault-injection. In Proc. of the Int'l Symp. on Computer Architecture, pages 460-469, 2007.

[28] N. J. Wang, J. Quek, T. M. Rafacz, and S. J. Patel. Characterizing the effects of transient faults on a high-performance processor pipeline. In Proc. of the Int'l Conf. on Dependable Systems and Networks, pages 61-70, June 2004.