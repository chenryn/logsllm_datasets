### Optimized Text

#### Lockstep Detection and Supplementation
The lockstep detection process consists of two main parts: (1) initial detection on the primary FP tree, and (2) supplementation to identify partially missing locksteps (see Section IV-E). Near-biclique detection is integrated into the lockstep detection phase, adding an overhead of at most 10 seconds. As illustrated in Figure 9(c), the first part is relatively fast, with a maximum runtime of 12 seconds. The majority of the computational cost in lockstep detection stems from the supplementation effort, which exhibits three phases of linear growth. Specifically, the number of nodes with multiple versions in the FP tree increases significantly around batches 94-96, leading to the third growth pattern in the total runtime.

While Beewolf currently performs these supplementary searches sequentially, they can be executed in parallel since the sub-processes are independent. To evaluate this potential optimization, we estimated the lockstep detection time under optimal parallelism. Assuming sufficient computing resources for parallel execution, the overall cost would be determined by the longest running supplementation. Adding this to the runtime of lockstep detection on the main FP tree, the total cost with optimal parallelism is at most 19 seconds, as shown in Figure 9(c), with a single pattern of slow linear growth. The supplementation phase is crucial for detecting malicious locksteps, contributing to 95% of MDL detections and 91% of PDL detections at the final batch. These locksteps encompass 48.7% of the MDs and 80.6% of the PDs.

Overall, the results indicate that the cost of Beewolf's first two analysis steps is amortized over time. We perform star detection only on new data batches and incrementally maintain the galaxy graph. Although the FP tree construction algorithm is not incremental and requires traversing the entire graph, we optimize this step by pruning the FP tree at level 7, as MDLs below this level are uncommon. Similarly, lockstep detection involves traversing the whole FP tree and constructing version lists for its nodes, but this can be optimized through parallel supplementation. The resulting runtime of Beewolf increases linearly with the graph size. Our findings suggest that maintaining one year of download events is feasible in terms of resource and performance requirements, even with daily lockstep detection.

#### Related Work
**Graph-based Attack Detection:**
Zhao et al. [43] introduced BotGraph, which detects email accounts involved in spamming by leveraging shared IP addresses to form user-user graphs. Other works have developed reputation score systems using belief propagation, based on the locality intuition. For example, Chau et al. [11] constructed a bipartite graph representing hosts and files, while Tamersoy et al. [37] designed a graph with files as nodes, placing edges between nodes sharing a common host. Oprea et al. [34] built a host vs. domain graph incrementally, detecting malicious domains within the same campaign. In Beewolf, we maintain a graph based on the "accessed by" relationship between downloaders and domains, with lockstep behavior detection returning clusters of downloaders and domains considering temporal bounds.

**Malware Distribution:**
Cova et al. [13] analyzed rogue anti-virus campaigns by investigating malicious domains and introduced an attack attribution method using feature-based clustering. Vadrevu et al. [40] developed AMICO, a system for detecting malware delivery in live network traffic using supervised techniques. Invernizzi et al. [19] studied malware delivery through networks and proposed Nazca, a system for detecting malicious download events from web traffic. Zhang et al. [42] used unsupervised techniques to identify groups of related servers likely involved in the same malware campaign. Unlike these works, Beewolf focuses on the client side of malware distribution networks and employs unsupervised techniques based on graph patterns rather than features. Additionally, we attribute campaigns by leveraging the code signing behavior of downloaders, rather than relying on properties of malicious domains.

**Spam Campaigns:**
Campaigns have been observed in other attack domains, such as email spam [21], [27], and social media spam [16], [17]. Prior work has utilized machine learning techniques to characterize social media spam campaigns. While some prior techniques use domain-specific features, the lockstep detection algorithm in Beewolf has broad applicability.

**Lockstep Detection:**
CopyCatch [4] identifies locksteps by analyzing the connectivity between users and pages through the "likes" relationship. We discuss the limitations of this algorithm and provide a comparison with Beewolf in Section VI-B. Most work in this area focuses on detecting suspicious nodes [20] or edges [10] through outlier detection. SynchroTrap [9] proposes a malicious account detection system in social networks, clustering users based on Jaccard similarity. Our work differs in that Beewolf focuses on detecting malicious campaigns corresponding to near-bipartite cores, captures campaigns over large time intervals, and uses frequent patterns to detect suspicious behavior. Our algorithm is also unsupervised.

#### Conclusions
We introduce Beewolf, a system for systematically detecting silent delivery campaigns. Beewolf identifies lockstep behavior, capturing sets of downloaders controlled remotely and the domains they access. Using Beewolf, we identified and analyzed 1.4 million campaigns conducted in 2013, revealing novel findings about malware distribution, such as overlaps between malware and PUP delivery ecosystems and tight business relationships among PPI providers. We also identified properties of malware distribution locksteps, including their size, life cycle, and frequent domain changes, enabling several optimizations for detecting malware delivery campaigns in a streaming fashion. We evaluated Beewolf's performance in streaming mode and demonstrated its scalability to large volumes of data.

#### Acknowledgments
We thank Jonathan Katz, the anonymous reviewers, and our shepherd, Alina Oprea, for their feedback. We also thank VirusTotal for access to their service and Symantec for making data available through the WINE platform. This research was partially supported by the National Science Foundation (award CNS-1564143), the Department of Defense, and a grant from Amazon Web Services.

#### References
[1] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster. Building a dynamic reputation system for DNS. In USENIX Security Symposium, 2010.
[2] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster. Building a dynamic reputation system for DNS. In Proceedings of the 19th USENIX Conference on Security, 2010.
[3] M. Antonakakis, R. Perdisci, W. Lee, N. V. II, and D. Dagon. Detecting malware domains at the upper DNS hierarchy. In 20th USENIX Security Symposium, 2011.
[4] A. Beutel, W. Xu, V. Guruswami, C. Palow, and C. Faloutsos. Copycatch: stopping group attacks by spotting lockstep behavior in social networks. In WWW, 2013.
[5] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi. Exposure: Finding malicious domains using passive DNS analysis. In NDSS, 2011.
[6] L. Bilge, S. Sen, D. Balzarotti, E. Kirda, and C. Kruegel. Exposure: A passive DNS analysis service to detect and report malicious domains. ACM Trans. Inf. Syst. Secur., 2014.
[7] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008.
[8] J. Caballero, C. Grier, C. Kreibich, and V. Paxson. Measuring pay-per-install: The commoditization of malware distribution. In USENIX Security Symposium, 2011.
[9] Q. Cao, X. Yang, J. Yu, and C. Palow. Uncovering large groups of active malicious accounts in online social networks. In CCS, 2014.
[10] D. Chakrabarti. Autopart: Parameter-free graph partitioning and outlier detection. In Knowledge Discovery in Databases: PKDD, 2004.
[11] D. H. Chau, C. Nachenberg, J. Wilhelm, A. Wright, and C. Faloutsos. Polonium: Tera-scale graph mining for malware detection. In SIGKDD, 2010.
[12] A. Clauset, M. E. Newman, and C. Moore. Finding community structure in very large networks. Physical Review E, 70(6):066111, 2004.
[13] M. Cova, C. Leita, O. Thonnard, A. D. Keromytis, and M. Dacier. An analysis of rogue AV campaigns. In RAID, 2010.
[14] T. D¨ubendorfer and S. Frei. Web browser security update effectiveness. In CRITIS Workshop, September 2009.
[15] L. C. Freeman. A set of measures of centrality based on betweenness. Sociometry, 1977.
[16] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao. Detecting and characterizing social spam campaigns. In SIGCOMM, 2010.
[17] C. Grier, K. Thomas, V. Paxson, and C. M. Zhang. @spam: the underground on 140 characters or less. In CCS, 2010.
[18] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In ACM Sigmod Record, volume 29, pages 1–12. ACM, 2000.
[19] L. Invernizzi, S.-J. Lee, S. Miskovic, M. Mellia, R. Torres, C. Kruegel, S. Saha, and G. Vigna. Nazca: Detecting malware distribution in large-scale networks. In NDSS, 2014.
[20] M. Jiang, P. Cui, A. Beutel, C. Faloutsos, and S. Yang. Catching synchronized behaviors in large networks: A graph mining approach. TKDD, 2015.
[21] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M. Voelker, V. Paxson, and S. Savage. Spamalytics: An empirical analysis of spam marketing conversion. In CCS, 2008.
[22] P. Kotzias, L. Bilge, and J. Caballero. Measuring PUP prevalence and PUP distribution through Pay-Per-Install services. In USENIX Security Symposium, 2016.
[23] P. Kotzias, S. Matic, R. Rivera, and J. Caballero. Certified PUP: Abuse in Authenticode code signing. In CCS, 2015.
[24] B. Krebs. "Signed malware is expensive: Oops for HP." http://krebsonsecurity.com/2014/10/signed-malware-is-expensive-oops-for-hp/, October 2014.
[25] M. K¨uhrer, C. Rossow, and T. Holz. Paint it black: Evaluating the effectiveness of malware blacklists. In RAID, 2014.
[26] B. J. Kwon, J. Mondal, J. Jang, L. Bilge, and T. Dumitras. The dropper effect: Insights into malware distribution with downloader graph analytics. In CCS, 2015.
[27] K. Levchenko, A. Pitsillidis, N. Chachra, B. Enright, M. F´elegyh´azi, C. Grier, T. Halvorson, C. Kanich, C. Kreibich, H. Liu, D. McCoy, N. Weaver, V. Paxson, G. M. Voelker, and S. Savage. Click trajectories: End-to-end analysis of the spam value chain. In S&P, 2011.
[28] Z. Li, S. A. Alrwais, Y. Xie, F. Yu, and X. Wang. Finding the linchpins of the dark web: A study on topologically dedicated hosts on malicious web infrastructures. In S&P, 2013.
[29] P. K. Manadhata, S. Yadav, P. Rao, and W. Horne. Detecting malicious domains via graph inference. In ESORICS, 2014.
[30] J. Mondal and A. Deshpande. EAGR: Supporting continuous ego-centric aggregate queries over large dynamic graphs. In SIGMOD, 2014.
[31] J. Mondal and A. Deshpande. Stream querying and reasoning on social data. In Encyclopedia of Social Network Analysis and Mining, 2014.
[32] A. Nappa, R. Johnson, L. Bilge, J. Caballero, and T. Dumitras. The attack of the clones: A study of the impact of shared code on vulnerability patching. In S&P, 2015.
[33] T. Nelms, R. Perdisci, M. Antonakakis, and M. Ahamad. WebWitness: Investigating, categorizing, and mitigating malware download paths. In USENIX Security Symposium, 2015.
[34] A. Oprea, Z. Li, T.-F. Yen, S. H. Chin, and S. Alrwais. Detection of early-stage enterprise infection by mining large-scale log data. In DSN, 2015.
[35] R. Peeters. The maximum edge biclique problem is NP-complete. Discrete Applied Mathematics, 131(3):651–654, 2003.
[36] B. Rahbarinia, R. Perdisci, and M. Antonakakis. Segugio: Efficient behavior-based tracking of malware-control domains in large ISP networks. In DSN, 2015.
[37] A. Tamersoy, K. Roundy, and D. H. Chau. Guilt by association: Large-scale malware detection by mining file-relation graphs. In SIGKDD, 2014.
[38] K. Thomas, J. A. E. Crespo, R. Rasti, J.-M. Picod, C. Phillips, M.-A. Decoste, C. Sharp, F. Tirelo, A. Toﬁgh, M.-A. Courteau, L. Ballard, R. Shield, N. Jagpal, M. A. Rajab, P. Mavrommatis, N. Provos, E. Bursztein, and D. McCoy. Investigating commercial pay-per-install and the distribution of unwanted software. In USENIX Security Symposium, 2016.
[39] K. Thomas, D. Huang, D. Wang, E. Bursztein, C. Grier, T. J. Holt, C. Kruegel, D. McCoy, S. Savage, and G. Vigna. Framing dependencies introduced by underground commoditization. In WEIS, 2015.
[40] P. Vadrevu, B. Rahbarinia, R. Perdisci, K. Li, and M. Antonakakis. Measuring and detecting malware downloads in live network traffic. In ESORICS, 2013.
[41] Z. Xu, A. Nappa, R. Baykov, G. Yang, J. Caballero, and G. Gu. AUTOPROBE: Towards automatic active malicious server probing using dynamic binary analysis. In CCS, 2014.
[42] J. Zhang, S. Saha, G. Gu, S. Lee, and M. Mellia. Systematic mining of associated server herds for malware campaign discovery. In ICDCS, 2015.
[43] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and E. Gillum. BotGraph: Large scale spamming botnet detection. In NSDI, 2009.