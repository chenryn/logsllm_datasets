Each botnet family possesses unique characteristics, leading to variations in their flow features. For instance, the packet per flow (ppf) of Trickbot is 8.66, while that of HTBot is 28.34. This suggests that the impact of different actions on each botnet family should vary, implying that each family's dominant actions will differ.

To test this hypothesis, we recorded and analyzed the action list taken by the agent during testing, counting the frequency of each action. Table 6 presents the results for the BotCatcher-SARSA instance, where the action numbers correspond to those described in Section 3. The table reveals significant differences in the distributions and dominant actions across families, which often correlate with the specific characteristics and primary functions of each family's flows.

For example, the median duration of Rbot family flows is 9.02 seconds, whereas for the Menti family, it is 2.91 seconds. From Table 6, we observe that the action `change_timestamp` has a much smaller impact on Rbot samples (0.02) compared to Menti samples (0.51). This indicates that flows with shorter durations may be more affected by the `change_timestamp` action than those with longer durations. Thus, the influence of actions on different families is closely related to the statistical or image characteristics of each family.

Our proposed framework aims to craft adversarial botnet flow examples that can mislead detectors by exploring the feature set the detector relies on and adding targeted perturbations. Additionally, the current actions have a substantial impact on botnet flows, and we can reduce these perturbations through an iterative method. We believe our framework can advance research on adversarial botnet flow examples and positively impact the botnet detection field.

**Acknowledgments:**
This work was supported by the Youth Innovation Promotion Association CAS (No.2019163), the National Natural Science Foundation of China (No.61902396), the Strategic Priority Research Program of Chinese Academy of Sciences (No. XDC02040100), the Key Laboratory of Network Assessment Technology at Chinese Academy of Sciences, and the Beijing Key Laboratory of Network Security and Protection Technology.

**Conclusion:**
In this paper, we propose a general reinforcement learning (RL)-based framework to generate adversarial botnet flow examples, enabling black-box adversarial attacks against machine learning (ML)-based botnet flow detectors. To ensure that the original malicious functions of the botnet flow remain unaffected, we designed an action space with 14 functionality-preserving actions. These actions can alter important transport layer characteristics without affecting the application layer information containing malicious functions. We selected 14 botnet families to create a new botnet dataset for evaluating our method. Our experiments demonstrate that ML-based botnet detectors are indeed vulnerable to adversarial attacks, and our system can achieve considerable evasion rates for various botnet detection models with fewer queries.

Despite our notable performance, there are areas for improvement. First, we can explore additional actions. Second, we can further refine our iterative perturbation reduction method.

**References:**
[1] 2008. https://en.wikipedia.org/wiki/Conficker
[2] 2008. https://en.wikipedia.org/wiki/Gh0st_RAT
[3] 2011. SplitCap. https://www.netresec.com/?page=SplitCap.
[4] Abdullah Al-Dujaili, Alex Huang, Erik Hemberg, and Una-May O’Reilly. 2018. Adversarial deep learning for robust detection of binary encoded malware. In 2018 IEEE Security and Privacy Workshops (SPW). IEEE, 76–82.
[5] Manos Antonakakis, Tim April, Michael Bailey, Matt Bernhard, Elie Bursztein, Jaime Cochran, Zakir Durumeric, J. Alex Halderman, Luca Invernizzi, Michalis Kallitsis, Deepak Kumar, Chaz Lever, Zane Ma, Joshua Mason, Damian Menscher, Chad Seaman, Nick Sullivan, Kurt Thomas, and Yi Zhou. 2017. Understanding the Mirai Botnet. In 26th USENIX Security Symposium (USENIX Security 17). USENIX Association, Vancouver, BC, 1093–1110. https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/antonakakis
[6] Giovanni Apruzzese and Michele Colajanni. 2018. Evading botnet detectors based on flows and random forest with adversarial samples. In 2018 IEEE 17th International Symposium on Network Computing and Applications (NCA). IEEE, 1–8.
[7] Shumeet Baluja and Ian Fischer. 2018. Learning to Attack: Adversarial Transformation Networks.. In AAAI, Vol. 1. 3.
[8] Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. 2007. Greedy layer-wise training of deep networks. In Advances in neural information processing systems.
[9] Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Šrndić, Pavel Laskov, Giorgio Giacinto, and Fabio Roli. 2013. Evasion attacks against machine learning at test time. In Joint European conference on machine learning and knowledge discovery in databases. Springer, 387–402.
[10] Leyla Bilge, Davide Balzarotti, William Robertson, Engin Kirda, and Christopher Kruegel. 2012. Disclosure: detecting botnet command and control servers through large-scale netflow analysis. In Proceedings of the 28th Annual Computer Security Applications Conference. 129–138.
[11] Wieland Brendel, Jonas Rauber, and Matthias Bethge. 2017. Decision-based adversarial attacks: Reliable attacks against black-box machine learning models. arXiv preprint arXiv:1712.04248 (2017).
[12] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. 2016. OpenAI Gym. arXiv preprint arXiv:1606.01540 (2016).
[13] Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness of neural networks. In 2017 IEEE Symposium on Security and Privacy (SP). IEEE, 39–57.
[14] Hung Dang, Yue Huang, and Ee-Chien Chang. 2017. Evading classifiers by morphing in the dark. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. 119–133.
[15] Sukhpreet Singh Dhaliwal, Abdullah-Al Nahid, and Robert Abbas. 2018. Effective intrusion detection system using XGBoost. Information 9, 7 (2018), 149.
[16] Jérôme François, Shaonan Wang, Thomas Engel, et al. 2011. BotTrack: tracking botnets using NetFlow and PageRank. In International Conference on Research in Networking. Springer, 1–14.
[17] Sebastian Garcia, Martin Grill, Jan Stiborek, and Alejandro Zunino. 2014. An empirical comparison of botnet detection methods. Computers & Security 45 (2014), 100–123.
[18] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).
[19] Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and Patrick McDaniel. 2017. Adversarial examples for malware detection. In European Symposium on Research in Computer Security. Springer, 62–79.
[20] Guofei Gu, Roberto Perdisci, Junjie Zhang, and Wenke Lee. 2008. BotMiner: Clustering analysis of network traffic for protocol-and structure-independent botnet detection. (2008).
[21] Weiwei Hu and Ying Tan. 2017. Generating adversarial malware examples for black-box attacks based on GAN. arXiv preprint arXiv:1702.05983 (2017).
[22] Bojan Kolosnjaji, Ambra Demontis, Battista Biggio, Davide Maiorca, Giorgio Giacinto, Claudia Eckert, and Fabio Roli. 2018. Adversarial malware binaries: Evading deep learning for malware detection in executables. In 2018 26th European Signal Processing Conference (EUSIPCO). IEEE, 533–537.
[23] Satoshi Kondo and Naoshi Sato. 2007. Botnet traffic detection techniques by C&C session classification using SVM. In International Workshop on Security. Springer, 91–104.
[24] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial machine learning at scale. arXiv preprint arXiv:1611.01236 (2016).
[25] Zilong Lin, Yong Shi, and Zhi Xue. 2019. IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection. arXiv:1809.02077 [cs.CR].
[26] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. 2015. Human-level control through deep reinforcement learning. Nature 518, 7540 (2015), 529–533.
[27] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. 2017. Universal adversarial perturbations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1765–1773.
[28] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016. DeepFool: A simple and accurate method to fool deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2574–2582.
[29] Carlos Novo and Ricardo Morla. 2020. Flow-Based Detection and Proxy-Based Evasion of Encrypted Malware C2 Traffic. In Proceedings of the 13th ACM Workshop on Artificial Intelligence and Security (Virtual Event, USA) (AISec'20). Association for Computing Machinery, New York, NY, USA, 83–91. https://doi.org/10.1145/3411508.3421379
[30] Nick Pantic and Mohammad I. Husain. 2015. Covert Botnet Command and Control Using Twitter (ACSAC 2015). Association for Computing Machinery, New York, NY, USA, 10 pages. https://doi.org/10.1145/2818000.2818047
[31] Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. 2017. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. 506–519.
[32] Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram Swami. 2016. The limitations of deep learning in adversarial settings. In 2016 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 372–387.
[33] Matthias Plappert. 2016. keras-rl. https://github.com/keras-rl/keras-rl.
[34] Shahbaz Rezaei and Xin Liu. 2019. Deep learning for encrypted traffic classification: An overview. IEEE Communications Magazine 57, 5 (2019), 76–81.
[35] M. Rigaki and S. Garcia. 2018. Bringing a GAN to a Knife-Fight: Adapting Malware Communication to Avoid Detection. In 2018 IEEE Security and Privacy Workshops (SPW). 70–75. https://doi.org/10.1109/SPW.2018.00019
[36] Markus Ring, Daniel Schlör, Dieter Landes, and Andreas Hotho. 2018. Flow-based Network Traffic Generation using Generative Adversarial Networks. Computers & Security 82 (12 2018). https://doi.org/10.1016/j.cose.2018.12.012
[37] Sherif Saad, Issa Traore, Ali Ghorbani, Bassam Sayed, David Zhao, Wei Lu, John Felix, and Payman Hakimian. 2011. Detecting P2P botnets through network behavior analysis and machine learning. In 2011 Ninth Annual International Conference on Privacy, Security and Trust. IEEE, 174–180.
[38] Elizabeth Stinson and John C Mitchell. 2008. Towards Systematic Evaluation of the Evadability of Bot/Botnet Detection Methods. WOOT 8 (2008), 1–9.
[39] Richard S Sutton and Andrew G Barto. 2018. Reinforcement Learning: An Introduction. MIT Press.
[40] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 (2013).
[41] Pablo Torres, Carlos Catania, Sebastian Garcia, and Carlos Garcia Garino. 2016. An analysis of recurrent neural networks for botnet detection behavior. In 2016 IEEE Biennial Congress of Argentina (ARGENCON). IEEE, 1–6.
[42] Wei Wang, Ming Zhu, Xuewen Zeng, Xiaozhou Ye, and Yiqiang Sheng. 2017. Malware traffic classification using convolutional neural network for representation learning. In 2017 International Conference on Information Networking (ICOIN). IEEE, 712–717.
[43] Di Wu, Binxing Fang, Xiang Cui, and Qixu Liu. 2018. BotCatcher: Botnet detection system based on deep learning. Infocomm-journal 39, 8 (2018), 18–28.
[44] Xiapu Luo, E. W. W. Chan, and R. K. C. Chang. 2008. TCP covert timing channels: Design and detection. In 2008 IEEE International Conference on Dependable Systems and Networks With FTCS and DCC (DSN). 420–429. https://doi.org/10.1109/DSN.2008.4630112