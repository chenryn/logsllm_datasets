### 图14：包含短响应流（具有不同到达率的泊松到达）和两个长流的基准流量

该图展示了在不同流到达率下，三种协议（D3、RCPdc 和 TCP）的性能。图 (a) 显示了不同流到达率下的流完成时间百分位数（1st-5th-50th-95th-99th），而图 (b) 显示了长流吞吐量。

#### 流到达率对流完成时间的影响

- **低负载**：在非常低的负载下，三种协议的流完成时间相当（TCP 的中位流完成时间比 D3 高 50%）。
- **高负载**：随着流到达率的增加，长流的存在和由此产生的排队会导致 TCP 丢包。即使在 200 流/秒时，超过 1% 的流会因丢包而错过截止时间。由于重传超时值 (RTO=300ms)，TCP 的 99th 百分位流完成时间超过 300ms。将 RTO 减少到较低值（如 10ms）可以提高 TCP 的性能，使其能够支持大约 1100 流/秒（见表 1）。但即便如此，TCP 支持的流数量仍不到 D3 的一半。

#### D3 与 RCPdc 的比较

- **流完成时间**：在整个范围内，D3 和 RCPdc 的流完成时间相似。例如，在 2000 流/秒时，99th 百分位完成时间几乎相同，尽管 D3 可以满足 99% 的流截止时间，而 RCPdc 只能满足 96.5% 的流截止时间。
- **截止时间意识**：虽然截止时间意识并不能进一步减少流完成时间（RCPdc 已经最小化了它们），但它确保了更多流能够满足其截止时间。

### 长流吞吐量

图 14(b) 显示了实验期间每个长流的平均吞吐量。结果表明，D3 并没有损害长流的性能，而是通过更智能地分配资源给有截止时间要求的流来实现其优势。

### 6.1.3 流抑制

除了不公平共享的好处外，截止时间意识还可以指导“流抑制”以应对严重拥塞。如第 1 节所述，在极端压力下，最好放弃一些负载，确保大量流能够满足其截止时间，而不是让所有流运行到完成，即使大多数会错过截止时间。D3 设计特别适合这种流抑制。因为端主机知道满足其截止时间所需的速率以及网络可以提供的速率，它们可以独立决定是否继续流传输。

我们实现了一个简单的流抑制机制，其中端主机在以下情况下提前终止流（发送 FIN）：
- 所需速率超过其上行链路容量
- 截止时间已经过期

图 15 显示了基准流量实验中使用流抑制的应用吞吐量。流抑制在极端负载下导致性能平滑下降。从应用角度来看，较少的终端用户会收到空响应。超过 2500 流/秒时，D3 无法应对网络负载，因为流到达率超过了流离开率。因此，应用吞吐量急剧下降，网络遭受拥塞崩溃。然而，通过流抑制，端主机不会追求不可达的截止时间，从而为其他可以满足截止时间的流保留带宽。

### 6.2 D3 作为拥塞控制协议

我们还评估了 D3 作为独立拥塞控制协议的性能，不考虑任何截止时间信息。前面部分的结果已经显示，D3（和 RCPdc）在短流延迟和流突发容忍方面优于 TCP。这里我们关注 D3 性能的其他方面。

#### 吞吐量和排队

首先，我们评估 D3 在长流中的行为以确定实现的网络吞吐量。为此，我们启动不同数量的流（2-20）到一个端主机，并以 1ms 间隔记录流吞吐量。图 16(a) 显示，随着长流数量的增加，总吞吐量保持不变，中位和平均网络吞吐量为 0.95Gbps（容量的 95%）。总体而言，D3 与 TCP 在长流方面的性能相当。

图 16(b) 显示了瓶颈链路上的瞬时队列长度。对于所有场景，平均队列大小为 4-6KB，中位数为 1.5KB，而 99th 百分位为 16.5-48KB。相比之下，TCP 倾向于使长流填满交换机缓冲区，导致更大的队列。这会影响共享同一瓶颈的短（截止时间）流。即使与 DCTCP 相比，D3 也能在队列短五倍的情况下实现相同的吞吐量。

#### 多跳多瓶颈设置

我们还评估了 D3 在多跳网络中的性能。由于篇幅限制，结果在 [26] 中讨论。总的来说，我们的实验表明，D3 在多跳和多瓶颈场景中表现良好。

### 讨论

虽然我们已经评估了 D3 设计和性能的许多方面，但仍有一些问题未详细讨论。我们在这里简要评论最重要的几点。

#### 部署性

D3 采取了一种激进的方法，使数据中心网络与应用程序需求对齐。它要求几乎所有参与者（应用程序、端主机和网络元素）进行更改。虽然在所有情况下这些更改可能被认为是易于实现的，但选择修改主要组件是非常有意的。与数据中心运营商和应用程序设计者的讨论表明，他们非常愿意采用新的设计，以摆脱现有改造协议的人为限制。特别是当额外的好处显著时，如 D3 的情况。Facebook 使用基于 UDP 的传输协议就是一个很好的例子，说明设计师愿意走额外的路来克服当前的限制 [22]。

D3 部署的最大障碍可能是对网络元素的必要更改。从技术角度来看，我们努力将 D3 路由器维护的状态和处理减少到最低限度。这使得我们的用户空间软件实现能够轻松达到线速，并预示着硬件实现的良好前景。例如，像 RCP [11] 一样，D3 可以在 NetFPGA 板上实现。

正如第 4 节所述，与现有协议（如 TCP 或其他非 D3 流量）共存不是 D3 的目标。然而，我们承认，整个数据中心转向仅 D3 流量的标志日可能不现实，逐步部署是可取的。在这方面，我们认为 D3 的性能不应受到低速率 TCP 或 UDP 流量（如控制流量）的影响，因为路由器的速率分配确实考虑到了通过 C 估计观察到的利用率。但是，D3 在存在现有协议的情况下的性能以及 D3 启用和传统交换机混合的逐步部署的详细检查超出了本工作的范围。

#### 软截止时间与硬截止时间

在整个论文中，D3 假设截止时间是硬性的，一旦错过，流就变得无用。这个决定是有意强调一个极端的设计点：具备截止时间意识对网络提供了显著的价值。另一方面，可以想象一些应用和流操作在软截止时间下。例如，这些流可以在错过截止时间后优雅地降级其性能，而不必被抑制。D3 模型可以通过多种方式适应软截止时间。例如，由于主机控制请求的速率，具有软要求的流可以在错过截止时间时延长截止时间，或者回退到公平份额模式；或者，可以在路由器中实现两阶段分配过程，根据网络拥塞按重要性顺序满足需求（例如，并非所有截止时间都具有同等价值）。然而，即使存在软截止时间，第 6 节的评估也强调了具备截止时间意识协议的好处。另一个扩展用例涉及具有变化截止时间的持久流。只要将截止时间的变化传达给协议，D3 就可以进行修改以处理这种情况。这样的修改以及在各种工作负载或端主机故障下的长期稳定性需要进一步研究。

### 结论

D3 是一种利用应用程序截止时间信息来实现网络带宽明智分配的控制协议。它明确解决了数据中心环境中的挑战——小 RTT 和具有广泛截止时间的突发、多样化流量混合。我们的评估表明，D3 是实用的，并且相对于现有解决方案（甚至是优化版本）提供了显著的好处。我们认为，这是一个很好的例子，说明了经过调整以满足应用程序需求并利用底层网络固有特性的数据中心可以超越当前的技术水平。新兴趋势表明，运营商愿意采用解决他们问题的新设计，这对 D3 的采用是一个好兆头。

### 致谢

我们感谢 Greg O’Shea、Austin Donnelly 和 Paolo Costa 的宝贵帮助。我们还要感谢 David Oran 在护送过程中的帮助和评论。

### 参考文献

[1] H. Abu-Libdeh, P. Costa, A. Rowstron, G. O’Shea, and A. Donnelly. Symbiotic routing in future data centers. In ACM SIGCOMM, 2010.
[2] M. Al-Fares, A. Loukissas, and A. Vahdat. A Scalable, Commodity Data Center Network Architecture. In Proc. of ACM SIGCOMM, 2008.
[3] M. Alizadeh, B. Atikoglu, A. Kabbani, A. Laksmikantha, R. Pan, B. Prabhakar, and M. Seaman. Data center transport mechanisms: congestion control theory and IEEE standardization. In Proc. of Allerton Conference on Communications, Control and Computing, Sept. 2008.
[4] M. Alizadeh, A. G. Greenberg, D. A. Maltz, J. Padhye, P. Patel, B. Prabhakar, S. Sengupta, and M. Sridharan. Data center TCP (DCTCP). In ACM SIGCOMM, 2010.
[5] C. Aras, J. Kurose, D. Reeves, and H. Schulzrinne. Real-time communication in packet-switched networks. Proc.of the IEEE, 82(1), 1994.
[6] D. Beaver, S. Kumar, H. C. Li, J. Sobel, and P. Vajgel. Finding a Needle in Haystack: Facebook’s Photo Storage. In Proc. of OSDI, 2010.
[7] B. B. Chen and P.-B. Primet. Scheduling deadline-constrained bulk data transfers to minimize network congestion. In CCGRID, May 2007.
[8] Y. Chen, R. Griffith, J. Liu, R. H. Katz, and A. D. Joseph. Understanding TCP incast throughput collapse in datacenter networks. In WREN, 2009.
[9] J. Dean and S. Ghemawat. MapReduce: Simplified Data Processing on Large Clusters. In USENIX OSDI, 2004.
[10] G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman, A. Pilchin, S. Sivasubramanian, P. Vosshall, and W. Vogels. Dynamo: amazon’s highly available key-value store. ACM SIGOPS, 41(6), 2007.
[11] N. Dukkipati. Rate Control Protocol (RCP): Congestion control to make flows complete quickly. PhD thesis, Stanford University, 2007.
[12] D. Ferrari, A. Banerjea, and H. Zhang. Network support for multimedia: A discussion of the tenet approach. In Proc. of Computer Networks and ISDN Systems, 1994.
[13] A. Greenberg, J. R. Hamilton, N. Jain, S. Kandula, C. Kim, P. Lahiri, D. A. Maltz, P. Patel, and S. Sengupta. VL2: a scalable and flexible data center network. In Proc. of ACM SIGCOMM, 2009.
[14] Y. Gu, C. V. Hollot, and H. Zhang. Congestion Control for Small Buffer High Speed Networks. In Proc. of IEEE INFOCOM, 2007.
[15] C. Guo, H. Wu, K. Tan, L. Shi, Y. Zhang, and S. Lu. Dcell: a scalable and fault-tolerant network structure for data centers. In Proc. of ACM SIGCOMM, 2008.
[16] T. Hoff. 10 eBay Secrets for Planet Wide Scaling, Nov. 2009. http://highscalability.com/blog/2009/11/17/10-ebay-secrets-for-planet-wide-scaling.html.
[17] T. Hoff. Latency is Everywhere and it Costs You Sales - How to Crush it, July 2009. http://highscalability.com/blog/2009/7/25/latency-is-everywhere-and-it-costs-you-sales-how-to-crush-it.html.
[18] M. Isard, M. Budiu, Y. Yu, A. Birrell, and D. Fetterly. Dryad: Distributed Data-Parallel Programs from Sequential Building Blocks. In Proc. of EuroSys, Mar. 2007.
[19] D. Katabi, M. Handley, and C. Rohrs. Congestion Control for High Bandwidth-Delay Product Networks. In Proc. of ACM SIGCOMM, Aug. 2002.
[20] R. Kohavi, R. Longbotham, D. Sommerfield, and R. M. Henne. Controlled experiments on the web: survey and practical guide. Data Mining and Knowledge Discovery, 18(1), 2009.
[21] C. L. Liu and J. W. Layland. Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment. Journal of the ACM, 20(1), 1973.
[22] P. Saab. Scaling memcached at Facebook, Dec. 2008. http://www.facebook.com/note.php?note_id=39391378919.
[23] V. Vasudevan, A. Phanishayee, H. Shah, E. Krevat, D. G. Andersen, G. R. Ganger, G. A. Gibson, and B. Mueller. Safe and effective fine-grained TCP retransmissions for datacenter communication. In ACM SIGCOMM, 2009.
[24] W. Vogels. Performance and Scalability, Apr. 2009. http://www.allthingsdistributed.com/2006/04/performance_and_scalability.html.
[25] M. Welsh, D. Culler, and E. Brewer. Seda: an architecture for well-conditioned, scalable internet services. In Proc. of ACM SOSP, 2001.
[26] C. Wilson, H. Ballani, T. Karagiannis, and A. Rowstron. Better never than late: Meeting deadlines in datacenter networks. Technical Report MSR-TR-2011-66, Microsoft Research, May 2011.