We have also manually examined the generated models to evaluate the potential damage a sophisticated attacker could inflict using mimicry techniques. We are confident that all three of the finger models offer very limited room for such attacks, as the finger source code primarily opens a network connection and accesses world-readable files on the system. However, the results for the other applications are mixed. The digraph model appears unlikely to withstand a mimicry attack, and we generally believe it should not be relied upon for defense against malicious code specifically designed to deceive our system. On the other hand, the abstract stack model performs reasonably well; we believe it would successfully mitigate the harmful effects of any compromise in qpopper or procmail. For sendmail, the generated abstract stack model is too complex for us to make a definitive determination.

Developing a metric or methodology to quantify the resistance of intrusion detection systems to unforeseen attacks, such as the mimicry attacks mentioned above, remains an important open problem.

**Detected Attacks:**
We have tested our system on several known attacks from the past decade. Each of the four applications discussed has a known security vulnerability, and we confirmed that our system could detect the known attacks on these applications. 

Perhaps the most common type of attack we detect is buffer overruns, which account for approximately half of all recent attacks [5, 35]. Most existing exploit scripts gain full root privileges and take distinctive actions (such as launching a shell under the attacker’s control) immediately after exploiting the overrun vulnerability, making detection straightforward for our tool. While many other systems can also detect these blatant attacks, albeit with high false alarm rates, a unique feature of our tool is its ability to detect more subtle, 'stealthy' attacks as well.

Our approach can also detect Trojan horses in trusted software. One popular method among today’s attackers is the rootkit toolkit, which replaces some system utilities with versions containing backdoors. We verified that our implementation could detect when these backdoors were exercised, causing behavior to deviate from the original source code. 

The most interesting feature of our approach is its ability to detect exotic attacks, even those unknown to the designers. For example, one subtle attack exploited the ability to pass environment variables to telnetd, causing the dynamic linker to link with a shared library provided by the adversary. Our system would have detected this attack, and any future dynamic-linking attacks, because our model is generated statically with the correct library. More recently, format string attacks have provided another unexpected way to introduce malicious code into vulnerable applications. Since our detection mechanism makes no assumptions about how malicious code may be introduced, we expect our system to be effective against format string attacks and other future methods of taking control of vulnerable applications. These examples highlight the importance of detecting unforeseen attacks.

Despite these successes, we strongly recommend that our tool should not be used as the sole defense against any of these attacks but should complement other techniques. Prevention is often a more effective barrier, and intrusion detection systems are best viewed as a backup layer in case the primary defense is breached.

**Future Work:**
This work opens up many avenues for future research. The main limitation of our approach is the high runtime overhead for some automata. However, we expect that more advanced static analysis could yield more precise models and better performance. Additionally, the prototype was written in Java; recoding the system in C or assembly language and integrating it directly into the operating system kernel could significantly reduce performance overhead. This work also raises the intriguing possibility of reusing the generated specifications to automatically verify properties of security-critical programs with a model checker. We note that our callgraph model, being a finite automaton, appears nearly ideal for a model checker. Although our stack model will be more challenging to model check, there has been theoretical work in this area [5, 13, 32, 36, 41].

**Conclusions:**
We have successfully applied static program analysis to intrusion detection. Our system scales to handle real-world programs and is fully automated, requiring only that the programmer or system administrator run our tools on the program at hand. Unlike other automatic approaches to intrusion detection, which are based on statistical inference and often lead to many false alarms, our approach is provably sound—when the alarm goes off, something has definitely gone wrong. We can immediately detect if a program behaves in a manner impossible according to its source, thus catching intrusions that other systems miss.

Our approach combines strategic static analysis with dynamic monitoring, yielding better results than either method alone and presenting a promising new approach to the intrusion detection problem.

**Acknowledgements:**
We thank Alex Aiken, Nikita Borisov, Eric Brewer, Jeff Foster, David Gay, Steve Gribble, Alan Hu, Adrian Perrig, and Dawn Song for their valuable discussions and contributions to this work.

**References:**
[References listed as in the original text]