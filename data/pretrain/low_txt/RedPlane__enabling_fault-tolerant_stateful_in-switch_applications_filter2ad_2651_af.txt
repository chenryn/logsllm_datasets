### Enabling Fault-Tolerant Stateful In-Switch Applications

#### Introduction
Recent advancements in programmable switches have demonstrated their potential for handling datacenter functions. However, a critical missing piece in current designs is fault tolerance. This paper introduces RedPlane, a system that provides a fault-tolerant state store abstraction for in-switch applications. RedPlane ensures linearizability-based correctness for replicated switch data plane states and implements a practical replication protocol. Our evaluation on a real testbed shows that RedPlane can support fault tolerance with minimal performance and resource overheads, enabling quick recovery from switch failures.

#### Related Work
1. **State Management in Switches**:
   - Some recent work focuses on allowing switches to handle state larger than their on-device memory, but it does not address fault tolerance or multi-writer consistency.
   - Other research runs coordination protocols between switches to build reliable storage. Our goal is different: we aim to replicate state for in-switch applications rather than providing a networked storage service. We do, however, use similar mechanisms such as network sequencing.

2. **Switch-Based Reliability Protocols**:
   - Recent studies have explored running coordination protocols between switches to build reliable storage systems. For example, P4xos [29] and NetChain [37] focus on building reliable storage services. Our approach, while conceptually different, leverages some of these mechanisms to achieve fault tolerance in in-switch applications.

#### Conclusions
Many recent efforts have highlighted the benefits of running datacenter functions on programmable switches. However, fault tolerance remains a significant challenge. To address this, we present RedPlane, which provides a fault-tolerant state store abstraction for in-switch applications. We define a linearizability-based correctness model for replicated switch data plane states and develop a practical replication protocol. Our evaluation with various stateful applications on a real testbed demonstrates that RedPlane can support fault tolerance with minimal performance and resource overheads, enabling rapid recovery from switch failures.

#### Ethics
This work does not raise any ethical issues.

#### Experimental Results
1. **End-to-End Throughput During Failover and Recovery**:
   - **Figure 14**: This figure illustrates the end-to-end throughput changes during failover and recovery with and without RedPlane. In a network without RedPlane, when a switch fails, packets are rerouted and dropped, breaking TCP connections. In contrast, RedPlane maintains high throughput even when a switch fails, with only short disruptions (0.9 and 1.0 seconds). The recovery time is influenced by the core switch's failure detection/rerouting time and RedPlane's lease period (set to 1 second here). Further optimizations could reduce this time.

2. **RedPlane Switch ASIC Resource Usage**:
   - **Packet Buffer Usage**: We evaluate the overhead of our request buffering mechanism. RedPlane buffers a replication request until it receives a corresponding reply from the state store, consuming some switch packet buffer. Since there is no precise way to measure buffer usage in real-time, we use queue depth information provided by the switch ASIC to estimate the upper bound of buffer occupancy. Specifically, we assume a write-centric application where every incoming packet issues a request (the most demanding scenario). We generate packets from a traffic generation server while varying the traffic rate and request loss rate. Figure 15 shows the results. When there is no request loss, the buffer occupancy is less than 1.5 KB even at a 100 Gbps traffic rate. As the request loss rate increases, so does the buffer usage.

#### Acknowledgments
We would like to thank the anonymous SIGCOMM reviewers and our shepherd, Mythili Vutukuru, for their insightful comments and constructive feedback. This work was supported in part by the CONIX Research Center, one of six centers in JUMP, a Semiconductor Research Corporation (SRC) program sponsored by DARPA, and by NSF award 1700521. Daehyeok Kim was also supported by the Microsoft Research PhD Fellowship.

#### References
[1] 2009. 2009-M57-Patents packet trace. http://downloads.digitalcorpora.org/corpora/scenarios/2009-m57-patents/net/
[2] 2010. Data Set for IMC 2010 Data Center Measurement. http://pages.cs.wisc.edu/~tbenson/IMC10_Data.html
[3] 2011. RDMA Aware Networks Programming User Manual. https://www.mellanox.com/related-docs/prod_software/RDMA_Aware_Programming_user_manual.pdf
[4] 2012. A signaling storm is gathering - Is your packet core ready? https://www.nokia.com/blog/a-signaling-storm-is-gathering-is-your-packet-core-ready/
[5] 2017. vEPC Acceleration Using Agilio SmartNICs. https://www.netronome.com/
[6] 2018. Advanced Network Telemetry. https://www.barefootnetworks.com/use-cases/ad-telemetry/
[7] 2018. Barefoot Networks Unveils Tofino 2, the Next Generation of the World’s First Fully P4-Programmable Network Switch ASICs. https://www.barefootnetworks.com/press-releases/barefoot-networks-unveils-tofino-2-the-next-generation-of-the-worlds-first-fully-p4-programmable-network-switch-asics/
[8] 2018. Cavium Xpliant Ethernet Switches. https://www.cavium.com/xpliant-ethernet-switch-product-family.html
[9] 2018. Offloading VNFs to programmable switches using P4. https://wiki.onosproject.org/download/attachments/12420314/p4-vnf-offloading-ons2018.pdf
[10] 2019. Cisco Visual Networking Index. https://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/white-paper-c11-738429.html
[11] 2019. P416 Language Specification. https://p4.org/p4-spec/docs/P4-16-v1.2.0
[12] 2020. Barefoot P4 Studio. https://www.barefootnetworks.com/products/brief-p4-studio/
[13] 2020. Cisco Silicon One Q200 and Q200L Processors Data Sheet. https://www.cisco.com/c/en/us/solutions/collateral/silicon-one/datasheet-c78-744312.html
[14] 2020. Intel Tofino. https://www.intel.com/content/www/us/en/products/network-io/programmable-ethernet-switch/tofino-series/tofino.html
[15] 2020. iperf(1) - Linux man page. https://linux.die.net/man/1/iperf
[16] 2020. Redis. https://redis.io/
[17] 2020. The Evolved Packet Core. https://www.3gpp.org/technologies/keywords-acronyms/100-the-evolved-packet-core
[18] 2020. The TLA+ Home Page. https://lamport.azurewebsites.net/tla/tla.html
[19] 2020. Trident4 / BCM56880 Series. https://www.broadcom.com/products/ethernet-connectivity/switching/strataxgs/bcm56880-series
[20] 2021. RedPlane Public Repository. https://github.com/daehyeok-kim/redplane-public
[21] 3GPP. 2012. 3GPP TS 23.007: Restoration procedures.
[22] Alexey Andreyev. 2014. Facebook data center network. https://engineering.fb.com/production-engineering/introducing-data-center-fabric-the-next-generation-facebook-data-center-network/
[23] Arista Networks. 2020. Arista 7170 Series. https://www.arista.com/en/products/7170-series
[24] Barefoot Networks. 2017. Tofino Switch Architecture Specification (accessible under NDA).
[25] Burton H. Bloom. 1970. Space/Time Trade-offs in Hash Coding with Allowable Errors. Commun. ACM 13, 7 (July 1970), 422–426.
[26] Pat Bosshart, Glen Gibb, Hun-Seok Kim, George Varghese, Nick McKeown, Martin Izzard, Fernando Mujica, and Mark Horowitz. 2013. Forwarding Metamorphosis: Fast Programmable Match-action Processing in Hardware for SDN. In ACM SIGCOMM (2013).
[27] David Clark. 1988. The design philosophy of the DARPA Internet protocols. In Symposium proceedings on Communications architectures and protocols (1988), 106–114.
[28] Graham Cormode and Marios Hadjieleftheriou. 2008. Finding Frequent Items in Data Streams. Proceedings of the VLDB Endowment 1, 2 (2008).
[29] H. T. Dang, P. Bressana, H. Wang, K. S. Lee, N. Zilberman, H. Weatherspoon, M. Canini, F. Pedone, and R. Soulé. 2020. P4xos: Consensus as a Network Service. IEEE/ACM Transactions on Networking (2020).
[30] Daniel E. Eisenbud, Cheng Yi, Carlo Contavalli, Cody Smith, Roman Kononov, Eric Mann-Hielscher, Ardas Cilingiroglu, Bin Cheyney, Wentao Shang, and Jinnah Dylan Hosein. 2015. Maglev: A Fast and Reliable Software Network Load Balancer. In USENIX NSDI (2015).
[31] Aaron Gember-Jacobson, Raajay Viswanathan, Chaithan Prakash, Robert Grandl, Junaid Khalid, Sourav Das, and Aditya Akella. 2014. OpenNF: Enabling Innovation in Network Function Control. In ACM SIGCOMM (2014).
[32] Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. 2003. The Google File System. In ACM SOSP (2003).
[33] Cary Gray and David Cheriton. 1989. Leases: An efficient fault-tolerant mechanism for distributed file cache consistency. ACM SIGOPS Operating Systems Review 23, 5 (1989).
[34] Albert Greenberg, James R Hamilton, Navendu Jain, Srikanth Kandula, Changhoon Kim, Parantap Lahiri, David A Maltz, Parveen Patel, and Sudipta Sengupta. 2009. VL2: a scalable and flexible data center network. In ACM SIGCOMM (2009).
[35] Arpit Gupta, Rob Harrison, Marco Canini, Nick Feamster, Jennifer Rexford, and Walter Willinger. 2018. Sonata: Query-driven Streaming Network Telemetry. In ACM SIGCOMM (2018).
[36] Maurice P Herlihy and Jeannette M Wing. 1990. Linearizability: A correctness condition for concurrent objects. ACM Transactions on Programming Languages and Systems (TOPLAS) 12, 3 (1990).
[37] Xin Jin, Xiaozhou Li, Haoyu Zhang, Nate Foster, Jeongkeun Lee, Robert Soulé, Changhoon Kim, and Ion Stoica. 2018. NetChain: Scale-Free Sub-RTT Coordination. In USENIX NSDI (2018).
[38] Xin Jin, Xiaozhou Li, Haoyu Zhang, Robert Soulé, Jeongkeun Lee, Nate Foster, Changhoon Kim, and Ion Stoica. 2017. NetCache: Balancing Key-Value Stores with Fast In-Network Caching. In ACM SOSP (2017).
[39] Naga Katta, Mukesh Hira, Changhoon Kim, Anirudh Sivaraman, and Jennifer Rexford. 2016. HULA: Scalable Load Balancing Using Programmable Data Planes. In ACM SOSR (2016).
[40] Naga Katta, Haoyu Zhang, Michael Freedman, and Jennifer Rexford. 2015. Ravana: Controller fault-tolerance in software-defined networking. In ACM SOSR (2015).
[41] Eric Keller, Jennifer Rexford, and Jacobus E van der Merwe. 2010. Seamless BGP Migration with Router Grafting.. In NSDI (2010).
[42] Daehyeok Kim, Zaoxing Liu, Yibo Zhu, Changhoon Kim, Jeongkeun Lee, Vyas Sekar, and Srinivasan Seshan. 2020. TEA: Enabling State-Intensive Network Functions on Programmable Switches. In ACM SIGCOMM (2020).
[43] Petr Lapukhov, Ariff Premji, and Jon Mitchell. 2016. Use of BGP for routing in large-scale data centers. Internet Requests for Comments RFC Editor RFC 7938 (2016).
[44] Collin Lee, Seo Jin Park, Ankita Kejriwal, Satoshi Matsushita, and John K. Ousterhout. 2015. Implementing linearizability at large scale and low latency. In ACM SOSP (2015).
[45] Jialin Li, Ellis Michael, and Dan RK Ports. 2017. Eris: Coordination-free consistent transactions using in-network concurrency control. In ACM SOSP (2017).
[46] Jialin Li, Ellis Michael, Naveen Kr. Sharma, Adriana Szekeres, and Dan R. K. Ports. 2016. Just Say No to Paxos Overhead: Replacing Consensus with Network Ordering. In USENIX OSDI (2016).
[47] Jialin Li, Jacob Nelson, Ellis Michael, Xin Jin, and Dan RK Ports. 2020. Pegasus: Tolerating Skewed Workloads in Distributed Storage with In-Network Coherence Directories. In USENIX OSDI (2020).
[48] Hyeontaek Lim, Dongsu Han, David G Andersen, and Michael Kaminsky. 2014. MICA: A holistic approach to fast in-memory key-value storage. In USENIX NSDI (2014).
[49] Barbara Liskov and James Cowling. 2012. Viewstamped Replication Revisited. Technical Report MIT-CSAIL-TR-2012-021. MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA.
[50] Hongqiang Harry Liu, Yibo Zhu, Jitu Padhye, Jiaxin Cao, Sri Tallapragada, Nuno P Lopes, Andrey Rybalchenko, Guohan Lu, and Lihua Yuan. 2017. Crystalnet: Faithfully emulating large production networks. In ACM SOSP (2017).
[51] Vincent Liu, Daniel Halperin, Arvind Krishnamurthy, and Thomas Anderson. 2013. F10: A fault-tolerant engineered network. In USENIX NSDI (2013).
[52] Zaoxing Liu, Zhihao Bai, Zhenming Liu, Xiaozhou Li, Changhoon Kim, Vladimir Braverman, Xin Jin, and Ion Stoica. 2019. DistCache: Provable Load Balancing for Large-Scale Storage Systems with Distributed Caching. In USENIX FAST (2019).
[53] Zaoxing Liu, Antonis Manousis, Gregory Vorsanger, Vyas Sekar, and Vladimir Braverman. 2016. One Sketch to Rule Them All: Rethinking Network Flow Monitoring with UnivMon. In ACM SIGCOMM (2016).
[54] Justin Meza, Tianyin Xu, Kaushik Veeraraghavan, and Onur Mutlu. 2018. A large scale study of data center network reliability. In ACM IMC.
[55] Rui Miao, Hongyi Zeng, Changhoon Kim, Jeongkeun Lee, and Minlan Yu. 2017. SilkRoad: Making Stateful Layer-4 Load Balancing Fast and Cheap Using Switching ASICs. In ACM SIGCOMM (2017).

#### Authors
- Daehyeok Kim
- Jacob Nelson
- Dan R. K. Ports
- Vyas Sekar
- Srinivasan Seshan