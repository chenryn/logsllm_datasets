### IV. Evaluation

The deep learning methods were implemented in Python using Keras [18]. The experiments on the collected dataset were conducted on a regular personal computer equipped with an NVIDIA GTX 1060 GPU. For all models, we used a batch size of 512, a learning rate of 0.001, and trained for 400 epochs.

#### A. Anomaly Injections and Measurement of Accuracy for SAD

In practice, anomalies may not be confined to a single event. We consider a trace to be anomalous if at least one event deviates from normal behavior, making our approach applicable even when the anomaly is spread across multiple events.

**Baselines:**
We compared our approach with two baseline models:
1. **Single-Modality Deep Learning Architecture:** Composed of a simple feed-forward neural network with the architecture: input, dense(50), dense(20), output.
2. **Multimodal Deep Learning Architecture:** Composed of two inputs, each followed by dense(50) layers, concatenated, and then passed through dense(20) layers, with separate outputs for each modality.

**Anomaly Injection:**
For structural anomaly detection (SAD), we injected anomalies as follows: given a trace \( T = \{e_0, e_1, ..., e_{T_l}\} \) with \( N_z \) non-zero elements, we selected a label not in the top-k predictions and injected it at the position of the normal observed label. We then ran the prediction with the model and determined the decision (anomaly/normal) by comparing the non-corrupted sample with the prediction. If the output was true and the label in the corrupted event position was not in the top-k predictions, the injected anomaly was successfully detected.

**Results and Discussion:**
Figure 5 shows that the best results in terms of accuracy for the task of structural anomaly detection are achieved using the multimodal LSTM predictions. The bar plot illustrates the accuracy of all models for different values of \( k \). The single-modality LSTM achieves comparable accuracy, while the other two single- and multimodal dense architectures have lower accuracies. The dense models cannot account for temporal information, whereas the multimodal LSTM benefits from additional response time information. For \( k = 3 \) and \( k = 5 \), the results are comparable, but for \( k = 1 \), the multimodal approach outperforms the single-modality by a large margin of 16%.

Figure 6 evaluates the accuracy when the anomaly is injected into traces of different sizes, ignoring the position of injection. Both proposed architectures achieve high accuracies for \( k \in \{3, 5\} \). The multimodal slightly outperforms the single-modality approach in 9 out of 15 trace lengths for both \( k \). Significantly better results are achieved for \( k = 1 \) for almost all trace lengths, demonstrating stability without performance reduction as the trace length increases.

#### B. Anomaly Injections and Measurement of Accuracy for RTAD

For response time anomaly detection (RTAD), we injected anomalies by selecting the event response time \( rt_i \) at a position \( i \) of the trace and increasing it by a random value \( r \in (2 \times rt_i, 5 \times rt_i) \). Once the anomaly is injected, we computed the mean squared error between the input and the predicted output. If the error was not within the 95% confidence interval computed from the Gaussian fitted on the training set, the anomaly was detected successfully. The accuracy was computed as the ratio of the number of successfully detected anomalies to the number of injected anomalies.

**Results and Discussion:**
Figures 8 and 9 compare the two multimodal approaches for different positions of the injected anomaly and different trace lengths. The multimodal approach consistently achieves higher accuracy for response time anomaly detection. Figure 8 shows a slight decrease in accuracy as the trace length increases. In Figure 9, the accuracy drops at position 7, possibly due to a small signal-to-noise ratio and the presence of outliers. Our approach did not apply any preprocessing or outlier removal techniques, assuming the recorded data represented normal behavior. Preprocessing techniques for response time may improve accuracy in critical positions.

### V. Conclusion and Future Work

This paper addressed the challenge of anomaly detection in large-scale cloud infrastructures using tracing data containing detailed information about inter-service calls. We used sequential deep networks for structural anomaly detection and presented approaches to recognize dependent or concurrently invoked services. We further extended the approach with a multimodal architecture for detecting both structural and response time anomalies by simultaneously considering the trace structure and service latency.

Our evaluation with real-world production cloud data showed that our multimodal LSTM approach achieved over 90% accuracy in multiple experiments, outperforming the single-modality and baseline dense neural networks, although the single-modality LSTM yielded comparable results in structural anomaly detection.

Our approach paves the way for developing new techniques that simultaneously consider application logs, resource metrics, or other observability data to create a joint representation of states, enabling anomaly detection in large-scale complex microservice systems. These achievements are fundamental for the development of zero-touch AIOps solutions for automated anomaly detection, root-cause analysis, and remediation.

### References
[1] F. Schmidt, A. Gulenko, M. Wallschlager, A. Acker, V. Hennig, F. Liu, and O. Kao, “Iftm - unsupervised anomaly detection for virtualized network function services,” in 2018 IEEE International Conference on Web Services (ICWS), July 2018, pp. 187–194.
[2] A. Gulenko, F. Schmidt, A. Acker, M. Wallschlager, O. Kao, and F. Liu, “Detecting anomalous behavior of black-box services modeled with distance-based online clustering,” in 2018 IEEE 11th International Conference on Cloud Computing (CLOUD), Jul 2018, pp. 912–915.
[3] M. Du, F. Li, G. Zheng, and V. Srikumar, “Deeplog: Anomaly detection and diagnosis from system logs through deep learning,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2017, pp. 1285–1298.
[4] F. Schmidt, F. Suri-Payer, A. Gulenko, M. Wallschlager, A. Acker, and O. Kao, “Unsupervised anomaly event detection for cloud monitoring using online ARIMA,” in 2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion), Dec 2018, pp. 71–76.
[5] D. Battre, N. Frejnik, S. Goel, O. Kao, and D. Warneke, “Evaluation of network topology inference in opaque compute clouds through end-to-end measurements,” in 2011 IEEE 4th International Conference on Cloud Computing, July 2011, pp. 17–24.
[6] B. H. Sigelman, L. A. Barroso, M. Burrows, P. Stephenson, M. Plakal, D. Beaver, S. Jaspan, and C. Shanbhag, “Dapper, a large-scale distributed systems tracing infrastructure,” Google, Inc., Tech. Rep., 2010. [Online]. Available: https://research.google.com/archive/papers/dapper-2010-1.pdf
[7] Q. Fu, J.-G. Lou, Y. Wang, and J. Li, “Execution anomaly detection in distributed systems through unstructured log analysis,” in 2009 IEEE International Conference on Data Mining (ICDM), 2009, pp. 149–158.
[8] N. Srivastava and R. R. Salakhutdinov, “Multimodal learning with deep Boltzmann machines,” in Advances in Neural Information Processing Systems, 2012, pp. 2222–2230.
[9] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural Computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[10] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning with neural networks,” in Advances in Neural Information Processing Systems, 2014, pp. 3104–3112.
[11] A. Graves, A.-r. Mohamed, and G. Hinton, “Speech recognition with deep recurrent neural networks,” in 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2013, pp. 6645–6649.
[12] P. Malhotra, L. Vig, G. Shroff, and P. Agarwal, “Long short term memory networks for anomaly detection in time series,” in ESANN, 2015.
[13] A. Taylor, S. Leblanc, and N. Japkowicz, “Anomaly detection in automotive control network data with long short-term memory networks,” in 2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA), 2016, pp. 130–139.
[14] A. Brown, A. Tuor, B. Hutchinson, and N. Nichols, “Recurrent neural network attention mechanisms for interpretable system log anomaly detection,” in Proceedings of the First Workshop on Machine Learning for Computing Systems, ser. MLCS’18. New York, NY, USA: ACM, 2018, pp. 1:1–1:8.
[15] J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A. Y. Ng, “Multimodal deep learning,” in Proceedings of the 28th International Conference on Machine Learning (ICML-11), 2011, pp. 689–696.
[16] OpenZipkin, “openzipkin/zipkin,” 2018. [Online]. Available: https://github.com/openzipkin/zipkin
[17] N. M. Nasrabadi, “Pattern recognition and machine learning,” Journal of Electronic Imaging, vol. 16, no. 4, p. 049901, 2007.
[18] F. Chollet et al., “Keras,” https://keras.io, 2018.
[19] A. Shrivastwa, S. Sarat, K. Jackson, C. Bunch, E. Sigler, and T. Campbell, OpenStack: Building a Cloud Environment. Packt Publishing, 2016.
[20] R. Ricci, E. Eide, and C. Team, “Introducing CloudLab: Scientific infrastructure for advancing cloud architectures and applications,” The Magazine of USENIX & SAGE, vol. 39, no. 6, pp. 36–38, 2014.