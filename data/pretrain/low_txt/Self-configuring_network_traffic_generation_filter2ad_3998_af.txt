### 6.3 Implications

Precisely controlled traffic streams are valuable for Internet RFC conformance testing and for subjecting network systems to extreme conditions along specific dimensions. However, our experiments demonstrate that a workload based on the measured characteristics of real Internet traffic generates a fundamentally different and more variable load on routers. Our results suggest ranges of behaviors that can be expected for given average loads. These ranges could be used to tune constant bit rate streams to explore an appropriate operational space. Additionally, the subsystem load variability imposed by Harpoon should provide system designers with insights into the stresses that these systems might experience under real operating conditions, informing the allocation of resources in future system designs.

### 7. Conclusions and Future Work

Harpoon is a new tool for generating representative IP traffic based on eight distributional characteristics of TCP and UDP flows. Parameters for these distributions can be automatically extracted from NetFlow data collected from a live router. These characteristics enable Harpoon to generate statistically representative traffic workloads that are independent of any specific application. To our knowledge, no other workload generation tool has this capability. We implemented Harpoon as a client-server application suitable for testbed environments. We parameterized Harpoon using data collected from a NetFlow trace and a set of packet traces, and verified in controlled laboratory tests that Harpoon generates traffic qualitatively similar to the input data.

We demonstrated Harpoon's utility beyond simple background traffic generation through a series of throughput tests conducted on a Cisco 6509 router. We compared and contrasted the workload generated by Harpoon with the constant bit rate workloads recommended for standard tests. We found that while Harpoon generated similar overall throughput, the stresses placed on router subsystems during these tests were significantly different. These results suggest that, in addition to generating background traffic, Harpoon could be a valuable tool for providing network hardware designers and network operators with insights into how systems might behave under realistic traffic conditions.

Future work will focus on extending our parameterization tools and model to accommodate sampled flow records and the absence of TCP flags. We also plan to enhance the UDP traffic model to support a broader range of UDP traffic characteristics. Finally, Harpoon currently assumes all sources are well-behaved, which is not always the case in the Internet. We intend to develop traffic anomaly models that can be incorporated into the Harpoon framework.

### 8. Acknowledgments

We would like to thank Dave Plonka at the University of Wisconsin for his helpful discussions regarding NetFlow, and Spirent Communications for the use of the AX/4000 system. We also thank the anonymous reviewers and our shepherd, Anja Feldmann, for their constructive criticism.

This research was supported by the National Science Foundation under Grant No. 0335234 and by support from Cisco Systems. The opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or Cisco Systems.

### 9. References

[1] Catalyst 6500 Series Switches. http://www.cisco.com/univercd/cc/td/doc/product/lan/cat6000/index.htm. Accessed August 2004.
[2] Cisco’s IOS NetFlow Feature. http://www.cisco.com/warp/public/732/netflow. Accessed August 2004.
[3] CoralReef: Passive Network Traffic Monitoring and Statistics Collection. http://www.caida.org/tools/measurement/coralreef. Accessed August 2004.
[4] Endace Measurement Systems. http://www.endace.com/. Accessed August 2004.
[5] The eXpat XML Parser. http://expat.sourceforge.net. Accessed August 2004.
[6] The iPerf TCP/UDP Bandwidth Measurement Tool. http://dast.nlanr.net/Projects/Iperf. Accessed August 2004.
[7] NetFlow Services Solutions Guide (NetFlow White Paper). http://www.cisco.com/univercd/cc/td/doc/cisintwk/-intsolns/netflsol/nfwhite.htm. Accessed August 2004.
[8] Spirent Communications Inc. Adtech AX/4000 Broadband Test System. http://www.spirentcom.com/analysis/product-line.cfm?pl=1&WS=173&wt=2. Accessed August 2004.
[9] SSFnet Network Simulator. http://www.ssfnet.org. Accessed August 2004.
[10] The University of New Hampshire Interoperability Laboratory. http://www.iol.unh.edu. Accessed August 2004.
[11] The Wisconsin Advanced Internet Laboratory. http://wail.cs.wisc.edu. Accessed August 2004.
[12] UCB/LBNL/VINT Network Simulator - ns (Version 2). http://www.isi.edu/nsnam/ns. Accessed August 2004.
[13] Web Polygraph. http://www.web-polygraph.org. Accessed August 2004.
[14] Workshop on Models, Methods, and Tools for Reproducible Network Research. http://www.acm.org/sigs/sigcomm/sigcomm2003/workshop/mometools, 2003.
[15] XML-RPC Home Page. http://www.xmlrpc.org. Accessed August 2004.
[16] P. Abry and D. Veitch. Wavelet Analysis of Long-Range Dependent Traffic. IEEE Transactions on Information Theory, 44(1):2–15, 1998.
[17] C. Barakat, P. Thiran, G. Iannaccone, C. Diot, and P. Owezarski. Modeling Internet Backbone Traffic at the Flow Level. IEEE Transactions on Signal Processing (Special Issue on Networking), August 2003.
[18] P. Barford and M. Crovella. Generating Representative Workloads for Network and Server Performance Evaluation. In Proceedings of ACM SIGMETRICS ’98, pages 151–160, Madison, WI, June 1998.
[19] P. Barford and M. Crovella. A Performance Evaluation of Hyper Text Transfer Protocols. In Proceedings of ACM SIGMETRICS ’99, Atlanta, GA, May 1999.
[20] S. Bradner. Benchmarking Terminology for Network Interconnect Devices. IETF RFC 1242, July 1991.
[21] S. Bradner and J. McQuaid. Benchmarking Methodology for Network Interconnect Devices. IETF RFC 2544, March 1999.
[22] T. Bu and D. Towsley. Fixed Point Approximation for TCP Behavior in an AQM Network. In Proceedings of ACM SIGMETRICS ’01, San Diego, CA, June 2001.
[23] Y.-C. Cheng, U. Hölzle, N. Cardwell, S. Savage, and G. M. Voelker. Monkey See, Monkey Do: A Tool for TCP Tracing and Replaying. In Proceedings of the USENIX 2004 Conference, June 2004.
[24] K. Claffy, G. Polyzos, and H.-W. Braun. Internet Traffic Flow Profiling. Technical Report TR-CS93-328, University of California San Diego, November 1989.
[25] W. Cleveland, D. Lin, and D. Sun. IP Packet Generation: Statistical Models for TCP Start Times Based on Connection Rate Superposition. In Proceedings of ACM SIGMETRICS ’00, Santa Clara, CA, June 2000.
[26] M. Crovella and A. Bestavros. Self-Similarity in World Wide Web Traffic: Evidence and Possible Causes. IEEE/ACM Transactions on Networking, 5(6):835–846, December 1997.
[27] N. Duffield, C. Lund, and M. Thorup. Estimating Flow Distributions from Sampled Flow Statistics. In Proceedings of ACM SIGCOMM ’03, Karlsruhe, Germany, August 2003.
[28] A. Feldmann, A. Gilbert, P. Huang, and W. Willinger. Dynamics of IP Traffic: A Study of the Role of Variability and the Impact of Control. In Proceedings of ACM SIGCOMM ’99, Boston, MA, August 1999.
[29] A. Feldmann, A. Gilbert, and W. Willinger. Data Networks as Cascades: Investigating the Multifractal Nature of Internet WAN Traffic. In Proceedings of ACM SIGCOMM ’98, August 1998.
[30] S. Floyd and E. Kohler. Internet Research Needs Better Models. In Hotnets-I, Princeton, NJ, October 2002.
[31] S. Floyd and V. Paxson. Difficulties in Simulating the Internet. IEEE/ACM Transactions on Networking, 9(4), August 2001.
[32] M. Fomenkov, K. Keys, D. Moore, and K. Claffy. Longitudinal Study of Internet Traffic from 1998-2001: A View from 20 High Performance Sites. Technical report, Cooperative Association for Internet Data Analysis (CAIDA), 2002.
[33] N. L. for Applied Network Research. http://moat.nlanr.net/Datacube. Accessed August 2004.
[34] C. Fraleigh, S. Moon, B. Lyles, C. Cotton, M. Khan, D. Moll, R. Rockell, T. Seely, and C. Diot. Packet-Level Traffic Measurements from the Sprint IP Backbone. IEEE Network, 2003.
[35] S. Fredj, T. Bonald, A. Proutiere, G. Regnie, and J. Roberts. Statistical Bandwidth Sharing: A Study of Congestion at Flow Level. In Proceedings of ACM SIGCOMM ’01, San Diego, CA, August 2001.
[36] M. Fullmer and S. Romig. The OSU Flow-Tools Package and Cisco NetFlow Logs. In Proceedings of the USENIX Fourteenth System Administration Conference LISA XIV, New Orleans, LA, December 2000.
[37] S. Jin and A. Bestavros. GISMO: Generator of Streaming Media Objects and Workloads. Performance Evaluation Review, 29(3), 2001.
[38] W. Leland, M. Taqqu, W. Willinger, and D. Wilson. On the Self-Similar Nature of Ethernet Traffic (Extended Version). IEEE/ACM Transactions on Networking, pages 2:1–15, 1994.
[39] R. Mandeville. Benchmarking Terminology for LAN Switching Devices. IETF RFC 2285, February 1998.
[40] R. Mandeville and J. Perser. Benchmarking Methodology for LAN Switching Devices. IETF RFC 2889, August 2000.
[41] D. Newman, G. Chagnot, and J. Perser. Internet Core Router Test. http://www.lightreading.com/document.asp?site=testing&doc_id=4009, March 2001. Accessed August 2004.
[42] K. Park and W. Willinger. Self-Similar Network Traffic and Performance Evaluation. Wiley Interscience, 2000.
[43] V. Paxson. Measurements and Analysis of End-to-End Internet Dynamics. PhD thesis, University of California Berkeley, 1997.
[44] V. Paxson and S. Floyd. Wide-Area Traffic: The Failure of Poisson Modeling. IEEE/ACM Transactions on Networking, 3(3):226–244, June 1995.
[45] D. Plonka. Flowscan: A Network Traffic Flow Reporting and Visualization Tool. In Proceedings of the USENIX Fourteenth System Administration Conference LISA XIV, New Orleans, LA, December 2000.
[46] A. Turner. tcpreplay. http://tcpreplay.sourceforge.net/. Accessed August 2004.
[47] S. Uhlig. Simulating Interdomain Traffic at the Flow Level. Technical Report Infonet-TR-2001-11, University of Namur, Institut d’ Informatique, 2001.
[48] A. Vahdat, K. Yocum, K. Walsh, P. Mahadevan, D. Kostic, J. Chase, and D. Becker. Scalability and Accuracy in a Large-Scale Network Emulator. In Proceedings of 5th Symposium on Operating Systems Design and Implementation (OSDI), Boston, MA, December 2002.
[49] B. White, J. Lepreau, L. Stoller, R. Ricci, S. Guruprasad, M. Newbold, M. Hibler, C. Barb, and A. Joglekar. An Integrated Experimental Environment for Distributed Systems and Networks. In Proceedings of 5th Symposium on Operating Systems Design and Implementation (OSDI), Boston, MA, December 2002.
[50] W. Willinger, M. Taqqu, R. Sherman, and D. Wilson. Self-Similarity Through High-Variability: Statistical Analysis of Ethernet LAN Traffic at the Source Level. IEEE/ACM Transactions on Networking, 5(1):71–86, February 1997.
[51] M. Yajnik, S. Moon, J. Kurose, and D. Towsley. Measurement and Modeling of Temporal Dependence in Packet Loss. In Proceedings of IEEE INFOCOM ’99, New York, NY, March 1999.