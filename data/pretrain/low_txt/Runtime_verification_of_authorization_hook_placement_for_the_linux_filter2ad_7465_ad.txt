### Number of Different Authorization Cases and Sensitivity Class Lists

The data contains a variety of authorization cases. Sensitivity class lists, which are textual, are particularly useful for regression testing [9].

### Partitioning Controlled Operations for the `read` System Call

Figure 6 illustrates the partitioning of controlled operations for the `read` system call, which is used as an example in Section 3.2.

### Authorization Graph for `fcntl` Calls

Figure 5 shows the authorization graph for `fcntl` calls, specifically for `F_SETLEASE` (controlled operations in `lease_modify` and `fput`) and `F_SETOWN` (controlled operations in `do_fcntl` and `put`). When the command is `F_SETOWN`, both `FCNTL` and `SET_OWNER` are authorized, but only `FCNTL` is authorized for `F_SETLEASE`.

### Specification of Controlled Operations in the `read` System Call Context

The specification `(D,1)` on the second line indicates that all controlled operations of this type within a `read` system call will be extracted. If the authorizations associated with these controlled operations differ, the member access is sensitive to its location.

### System Call Input Sensitive Rule

The system call input sensitive rule collects all log entries for read-only access in each `open` system call. The authorizations for the `open` system call depend on the access type for which the file is opened, making it system call input sensitive. Additionally, a negative filter is applied to eliminate all entries within the scope of the `path_walk` function, allowing us to separate the authorizations for file lookup from those for opening the file. This filtering capability provides flexibility in choosing the analysis scope.

### Graphical Log Analysis

The analysis tool can generate graphs for visual inspection of filtered data. An authorization graph consists of two sets of nodes: (1) controlled operations and (2) authorizations made. Edges are drawn from each controlled operation to the satisfied authorizations. There are two types of edges:
- **Always edges**: The associated authorization is always satisfied when the controlled operation is run.
- **Sometimes edges**: The associated authorization is satisfied at least once when the controlled operation is run.

An always edge (or the lack of an edge) indicates that the authorization is not sensitive to lower-level attributes. A sometimes edge indicates sensitivity. The absence of an expected edge suggests a missing authorization.

### Example Authorization Graph

Figure 5 shows an example authorization graph using the dotty graph visualization tool [10]. The graph displays controlled operations and authorizations for two types of `fcntl` calls:
1. `fcntl(fd, F_SETOWN, pid_owner)`
2. `fcntl(fd, F_SETLEASE, F_UNLCK)`

Controlled operation nodes include location (function name, file name, line number) and operation details.

### Rules for Finding the `f_owner` Anomaly

Figure 7 presents rules for finding the `f_owner` anomaly. The rules collect authorizations and controlled operations for the `f_owner` field in `fcntl` calls.

### Sensitivity Class List

The sensitivity class list shows two classes sensitive at the datatype level: one for tasks and superblocks with no authorizations, and one for files with read authorization. It also includes two object-sensitive classes: one for the inode with read authorization and one for its directory with no authorizations. We expect to annotate the current task, file’s directory, and file’s superblock as read authorized, resulting in consistent authorizations for all controlled operations.

### Experience with File System and Task Authorizations

Most of our experience is with the file system, though we have also examined task authorizations. Most objects have either one or no authorizations, keeping the sensitivity class lists relatively simple. The `unlink` system call is an exception, with multiple authorizations for the directory inode (exec, write, unlink dir) and the inode being removed (unlink file).

### Sample Analysis: Anomaly in `fcntl` System Call

We found an anomaly in the `fcntl` system call. The sensitivity class list for `fcntl` shows that its authorizations are system call input sensitive. The values of the `cmd` and `arg` parameters can change the required authorizations. Using authorization graphs, we can visually inspect authorizations under different inputs, making it easier to identify coarse-grained problems.

### Results of the Analysis

We applied the December 10, 2001 LSM patch to the Linux 2.4.16 source and compiled the kernel using a modified version of GCC-3.0. To create an execution log, we ran three instances of LMBench, the SAINT vulnerability tool, a kernel compile, regular usage, and some test programs. Our static analysis tool identified potential errors, and benchmarks need to be developed to cover more kernel code paths.

### Detailed Analysis on File System and Task Authorizations

We have instrumented the kernel to collect controlled operations on major kernel data structures: files, inodes, superblocks, tasks, sockets, and skbuffs. We have conducted a detailed analysis on file system authorizations and an initial analysis on task authorizations. Despite the well-understood nature of the file system, we found some anomalies.

### Examples of Anomalies

- **Member Sensitive (multiple system calls)**: No authorization hook in `setgroups16`, but the task’s group set can be reset. This was missed because 16-bit task operations usually convert their values to 32-bit and call the current versions with authorizations.
- **Member Sensitive (single system call)**: The `f_owner.pid` field in `struct file` is authorized by `file_ops->set_fowner` for `F_SETOWN`, but not for `F_SETLEASE` or TUN device operations.
- **System Call Sensitive (missing authorization)**: Read authorization is performed at the beginning of every `read` system call but not during page-faults on memory-mapped files.

### Conclusion

We presented tools for verifying the correctness of the Linux Security Modules (LSM) framework. By analyzing structure member operations on major kernel data structures, we identified misplaced hooks. Working with the LSM community, we fixed several anomalies. Runtime analysis is useful for identifying inconsistencies likely to be errors, and further benchmark development remains a challenge.

### References

[1] K. Ashcraft and D. Engler. Using programmer-written compiler extensions to catch security holes. In Proceedings of the IEEE Symposium on Security and Privacy 2002, May 2002.
[2] M. Bishop and M. Dilger. Checking for race conditions in file accesses. Computing Systems, 9(2):131–152, 1996.
[3] H. Chen and D. Wagner. MOPS: An infrastructure for examining security properties of software. In Proceedings of the 9th Conference on Computer and Communications Security, November 2002.
[4] A. Edwards, T. Jaeger, and X. Zhang. Runtime verification of authorization hook placement for the Linux Security Modules framework. Technical Report RC22254, IBM Research, December 2001.
[5] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking system rules using system-specific, programmer-written compiler extensions. In Proceedings of the Fourth Symposium on Operation System Design and Implementation (OSDI), October 2000.
[6] J. Foster, M. Fahndrich, and A. Aiken. A theory of type qualifiers. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI ’99), pages 192–203, May 1999.
[7] P. Gutmann. The design and verification of a cryptographic security architecture, August 2000. Submitted thesis. Available at www.cs.auckland.ac.nz/ pgut001/pubs/thesis.html.
[8] ITSEC. Common Criteria for Information Security Technology Evaluation. ITSEC, 1998. Available at www.commoncriteria.org.
[9] T. Jaeger, X. Zhang, and A. Edwards. Maintaining the correct of the Linux Security Modules framework. In Proceedings of the 2002 Ottawa Linux Symposium, pages 223-241, June 2002.
[10] E. Koutsoﬁos and S. North. Drawing graphs with Dot. Available at http://www.research.att.com/sw/tools/graphviz/.
[11] L. Koved, M. Pistoia, and A. Kerschenbaum. Access rights analysis for Java. In Proceedings of 17th Annual ACM Conference on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA), November 2002.
[12] D. Larochelle and D. Evans. Statically detecting likely buffer overflow vulnerabilities. In Proceedings of the Tenth USENIX Security Symposium, pages 177–190, August 2001.
[13] NCSC. Trusted Computer Security Evaluation Criteria. National Computer Security Center, 1985. DoD 5200.28-STD, also known as the Orange Book.
[14] G. C. Necula, S. McPeak, and W. Weimer. CCured: Type-safe retrofitting of legacy code. In Proceedings of the 29th ACM Symposium on Principles of Programming Languages (POPL02), January 2002.
[15] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting format string vulnerabilities with type qualifiers. In Proceedings of the Tenth USENIX Security Symposium, pages 201–216, August 2001.
[16] J. Viega, J. Bloch, Y. Kohno, and G. McGraw. ITS4: A static vulnerability scanner for C and C++ code. In Proceedings of 2000 Annual Security Applications Conference, December 2000.
[17] D. Wagner, J. S. Foster, E. A. Brewer, and A. Aiken. A first step towards automated detection of buffer overrun vulnerabilities. In Proceedings of Network and Distributed System Security Symposium (NDSS 2000), February 2000.
[18] X. Zhang, A. Edwards, and T. Jaeger. Using CQUAL for static analysis of authorization hook placement. In Proceedings of the 11th USENIX Security Symposium, August 2002.