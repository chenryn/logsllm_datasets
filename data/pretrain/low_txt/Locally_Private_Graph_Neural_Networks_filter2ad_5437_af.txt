### Experimental Results

The following results are presented for the performance of the Drop method and the Forward Correction method. The accuracy scores (mean ± standard deviation) are as follows:

- **Forward Correction:**
  - 28.4 ± 2.5
  - 56.8 ± 2.8

- **Drop:**
  - 18.6 ± 2.5
  - 37.1 ± 2.5
  - 75.1 ± 1.0
  - 38.7 ± 1.4
  - 68.8 ± 0.7
  - 81.0 ± 0.2
  - 68.9 ± 1.3
  - 73.8 ± 1.1
  - 88.9 ± 0.2
  - 44.9 ± 5.3
  - 58.5 ± 3.6
  - 79.2 ± 1.3

- **Drop:**
  - 42.9 ± 1.5
  - 69.3 ± 1.2
  - 78.4 ± 0.7
  - 69.8 ± 0.7
  - 74.9 ± 0.3
  - 81.0 ± 0.2
  - 75.1 ± 0.6
  - 84.9 ± 0.2
  - 90.7 ± 0.1
  - 70.0 ± 3.0
  - 82.1 ± 1.0
  - 85.7 ± 0.7

The results indicate that the Drop method performs better or at least equally compared to the Forward Correction method. This suggests that Drop can effectively utilize the information within the graph structure to recover the actual node labels, and more importantly, it can achieve high accuracy without using any clean labels for model validation, such as for early stopping or hyper-parameter optimization.

### Related Work

#### Graph Neural Networks (GNNs)
In recent years, there has been a significant increase in the application of GNNs for representation learning over graphs. Various GNN models have been proposed, including:
- **Graph Convolutional Networks (GCNs)** [26]
- **Graph Attention Networks (GATs)** [47]
- **GraphSAGE** [18]
- **Graph Isomorphism Networks (GINs)** [59]
- **Jumping Knowledge Networks (JK-Nets)** [60]
- **Gated Graph Neural Networks (GG-NNs)** [32]

For a comprehensive overview of GNNs, their performance, and applications, readers are referred to available surveys [19, 57].

#### Local Differential Privacy (LDP)
Local differential privacy has become increasingly popular for privacy-preserving data collection and analytics, as it does not require a trusted aggregator. Several LDP mechanisms have been developed for estimating aggregate statistics, such as:
- **Frequency Estimation** [7, 16, 52]
- **Mean Estimation** [11, 12, 50]
- **Heavy Hitters** [54]
- **Frequent Itemset Mining** [40]

Additionally, LDP has been applied to various learning problems, including:
- **Probability Distribution Estimation** [3, 12, 22]
- **Heavy Hitter Discovery** [6, 8, 54]
- **Frequent New Term Discovery** [49]
- **Marginal Release** [10]
- **Clustering** [37]
- **Hypothesis Testing** [17]

LDP frequency oracles, which are fundamental primitives in LDP, have been extensively studied [4, 6, 7, 16, 52, 62]. Techniques such as Hadamard transform [4, 6] and hashing [52] are commonly used. These oracles are also applied in tasks like frequent itemset mining [40, 53] and histogram estimation [22, 51, 55].

#### Privacy Attacks on GNNs
Several recent works have attempted to characterize potential privacy attacks associated with GNNs and quantify the privacy leakage of publicly released GNN models or node embeddings trained on private graph data. For example:
- **Link Stealing Attacks**: He et al. [1] proposed a series of link stealing attacks on GNNs, showing that an adversary can accurately infer links between nodes.
- **Privacy Leakage Quantification**: Duddu et al. [13] conducted a comprehensive study on quantifying the privacy leakage of graph embedding algorithms, introducing three major classes of privacy attacks: membership inference, graph reconstruction, and attribute inference.
- **Model Extraction Attacks**: Wu et al. [56] proposed a model extraction attack against GNNs by generating legitimate-looking queries and reconstructing the model using the query responses.

These works highlight the many privacy risks associated with GNNs and demonstrate the vulnerability of these models to various privacy attacks.

#### Privacy-Preserving GNN Models
While there is growing interest in both the theory and applications of GNNs, relatively few attempts have been made to provide privacy-preserving graph representation learning algorithms. Some notable works include:
- **Differentially Private Graph Embedding**: Xu et al. [58] and Zhang and Ni [66] proposed differentially private methods for graph embedding, targeting classic graph embedding algorithms rather than GNNs.
- **Adversarial Training Frameworks**: Li et al. [29] and Liao et al. [33] used adversarial training to address privacy concerns, but they assumed complete access to private data, which differs from our problem setting.
- **Federated and Split Learning Approaches**: Mei et al. [35] and Zhou et al. [68] proposed GNNs based on federated and split learning, but these approaches rely on a trusted third party for model aggregation and do not provide formal privacy guarantees.
- **Distributed and Secure Frameworks**: Jiang et al. [21] proposed a distributed and secure framework for learning object representations in video data, but their approach assumes each party owns a series of graphs, which is a different problem setting than node data privacy.

### Conclusion
In this paper, we presented a locally private GNN to address node data privacy, where graph nodes have sensitive data that are kept private, but a central server can leverage them to train a GNN for learning rich node representations. We proposed the multi-bit mechanism, a multidimensional \(\epsilon\)-LDP algorithm, to privately collect node features and estimate the first-layer graph convolution of the GNN using noisy features. To further decrease the estimation error, we introduced KProp, a simple graph convolution layer that aggregates features from higher-order neighbors, which is prepended to the backbone GNN. Finally, to learn the model with perturbed labels, we proposed a learning algorithm called Drop that utilizes KProp for label denoising. Experimental results over real-world graph datasets on node classification demonstrated that the proposed framework could maintain an appropriate privacy-utility trade-off.

### Future Directions
The concept of privacy-preserving graph representation learning is a novel field with many potential future directions, such as:
- **Link Privacy and Graph-Level Privacy**: Extending the current setting to preserve the graph structure.
- **Effective Neighborhood Expansion Mechanisms**: Exploring other neighborhood expansion mechanisms that are more effective than KProp.
- **Rigorous Algorithms for Differentially Private Labels**: Developing more rigorous algorithms for learning with differentially private labels, which is currently unexplored for GNNs.
- **Combining LPGNN with Deep Graph Learning**: Combining the proposed LPGNN with deep graph learning algorithms to address privacy-preserving classification over non-relational datasets with low communication cost.

### Acknowledgments
This work was supported by the Swiss National Science Foundation (SNSF) through the Dusk2Dawn project (Sinergia program) under grant number 173696. Additional support was provided by the European Commission under the European Horizon 2020 Programme, grant number 951911, AI4Media project. We would like to thank Emiliano De Cristofaro, Hamed Haddadi, Nikolaos Karalias, and Mohammad Malekzadeh for their helpful comments on earlier drafts of this paper.

### References
[1] He, J., et al. (2021). Stealing Links from Graph Neural Networks. In 30th USENIX Security Symposium (USENIX Security 21). USENIX Association, Vancouver, B.C. https://www.usenix.org/conference/usenixsecurity21/presentation/he

[2] Abu-El-Haija, S., et al. (2019). MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing. In Proceedings of Machine Learning Research, Vol. 97. PMLR, Long Beach, California, USA, 21–29.

[3] Acharya, J., Sun, Z., and Zhang, H. (2018). Communication efficient, sample optimal, linear time locally private discrete distribution estimation. arXiv preprint arXiv:1802.04705.

[4] Acharya, J., Sun, Z., and Zhang, H. (2019). Hadamard Response: Estimating Distributions Privately, Efficiently, and with Little Communication. In The 22nd International Conference on Artificial Intelligence and Statistics. PMLR, 1120–1129.

[5] Balle, B., and Wang, Y.-X. (2018). Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising. In International Conference on Machine Learning. PMLR, 394–403.

[6] Bassily, R., Nissim, K., Stemmer, U., and Thakurta, A. (2017). Practical locally private heavy hitters. arXiv preprint arXiv:1707.04982.

[7] Bassily, R., and Smith, A. (2015). Local, private, efficient protocols for succinct histograms. In Proceedings of the forty-seventh annual ACM symposium on Theory of computing. 127–135.

[8] Bun, M., Nelson, J., and Stemmer, U. (2019). Heavy Hitters and the Structure of Local Privacy. ACM Transactions on Algorithms (TALG) 15, 4, 1–40.

[9] Chen, Z., Li, X., and Bruna, J. (2017). Supervised Community Detection with Line Graph Neural Networks. arXiv preprint arXiv:1705.08415.

[10] Cormode, G., Kulkarni, T., and Srivastava, D. (2018). Marginal Release Under Local Differential Privacy. In Proceedings of the 2018 International Conference on Management of Data. 131–146.

[11] Ding, B., Kulkarni, J., and Yekhanin, S. (2017). Collecting Telemetry Data Privately. In Advances in Neural Information Processing Systems. 3571–3580.

[12] Duchi, J. C., Jordan, M. I., and Wainwright, M. J. (2018). Minimax Optimal Procedures for Locally Private Estimation. J. Amer. Statist. Assoc. 113, 521, 182–201.

[13] Duddu, V., Boutet, A., and Shejwalkar, V. (2020). Quantifying Privacy Leakage in Graph Embedding. In Mobiquitous 2020-17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services. 1–11.

[14] Duvenaud, D. K., et al. (2015). Convolutional Networks on Graphs for Learning Molecular Fingerprints. In Advances in neural information processing systems. 2224–2232.

[15] Dwork, C., and Roth, A. (2014). The Algorithmic Foundations of Differential Privacy. Foundations and Trends ® in Theoretical Computer Science 9, 3–4, 211–407.

[16] Erlingsson, Ú., Pihur, V., and Korolova, A. (2014). RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response. In Proceedings of the 2014 ACM SIGSAC conference on computer and communications security. 1054–1067.

[17] Gaboardi, M., and Rogers, R. (2018). Local Private Hypothesis Testing: Chi-Square Tests. In International Conference on Machine Learning. PMLR, 1626–1635.

[18] Hamilton, W., Ying, Z., and Leskovec, J. (2017). Inductive Representation Learning on Large Graphs. In Advances in neural information processing systems. 1024–1034.

[19] Hamilton, W. L., Ying, R., and Leskovec, J. (2017). Representation Learning on Graphs: Methods and Applications. arXiv preprint arXiv:1709.05584.

[20] Jha, M., and Raskhodnikova, S. (2013). Testing and Reconstruction of Lipschitz Functions with Applications to Data Privacy. SIAM J. Comput. 42, 2, 700–731.

[21] Jiang, M., Jung, T., Karl, R., and Zhao, T. (2020). Federated Dynamic GNN with Secure Aggregation. arXiv preprint arXiv:2009.07351.

[22] Kairouz, P., Bonawitz, K., and Ramage, D. (2016). Discrete Distribution Estimation Under Local Privacy. In International Conference on Machine Learning. PMLR, 2436–2444.

[23] Kairouz, P., et al. (2019). Advances and Open Problems in Federated Learning. arXiv preprint arXiv:1912.04977.

[24] Kasiviswanathan, S. P., Lee, H. K., Nissim, K., Raskhodnikova, S., and Smith, A. (2011). What Can We Learn Privately? SIAM J. Comput. 40, 3, 793–826.

[25] Kingma, D. P., and Ba, J. (2014). Adam: A Method for Stochastic Optimization. arXiv preprint arXiv:1412.6980.

[26] Kipf, T. N., and Welling, M. (2017). Semi-Supervised Classification with Graph Convolutional Networks. In International Conference on Learning Representations (ICLR).

[27] Klambauer, G., Unterthiner, T., Mayr, A., and Hochreiter, S. (2017). Self-Normalizing Neural Networks. In Advances in neural information processing systems. 971–980.

[28] Klicpera, J., Weiß enberger, S., and Günnemann, S. (2019). Diffusion Improves Graph Learning. In Advances in Neural Information Processing Systems. 13354–13366.

[29] Li, K., Luo, G., Ye, Y., Li, W., Ji, S., and Cai, Z. (2020). Adversarial Privacy Preserving Graph Embedding Against Inference Attack. arXiv preprint arXiv:2008.13072.

[30] Li, Q., Han, Z., and Wu, X.-M. (2018). Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. arXiv preprint arXiv:1801.07606.

[31] Li, Y., Chen, L., et al. (2021). Unified Robust Training for Graph Neural Networks Against Label Noise. arXiv preprint arXiv:2103.03414.

[32] Li, Y., Tarlow, D., Brockschmidt, M., and Zemel, R. (2015). Gated Graph Sequence Neural Networks. arXiv preprint arXiv:1511.05493.

[33] Liao, P., Zhao, H., Xu, K., Jaakkola, T., Gordon, G., Jegelka, S., and Salakhutdinov, R. (2020). Graph Adversarial Networks: Protecting Information Against Adversarial Attacks. arXiv preprint arXiv:2009.13504.

[34] McPherson, M., Smith-Lovin, L., and Cook, J. M. (2001). Birds of a Feather: Homophily in Social Networks. Annual review of sociology 27, 1, 415–444.

[35] Mei, G., Guo, Z., Liu, S., and Pan, L. (2019). SGNN: A Graph Neural Network Based Federated Learning Approach by Hiding Structure. In 2019 IEEE International Conference on Big Data (Big Data). IEEE Computer Society, Los Alamitos, CA, USA, 2560–2568.

[36] Morris, C., Ritzert, M., Fey, M., Hamilton, W. L., Lenssen, J. E., Rattan, G., and Grohe, M. (2019). Weisfeiler and Leman Go Neural: Higher-Order Graph Neural Networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 4602–4609.

[37] Nissim, K., and Stemmer, U. (2018). Clustering Algorithms for the Centralized and Local Models. In Algorithmic Learning Theory. PMLR, 619–653.

[38] NT, H., Jin, C. J., and Murata, T. (2019). Learning Graph Neural Networks with Noisy Labels. arXiv preprint arXiv:1905.01591.

[39] Patrini, G., Rozza, A., Menon, A. K., Nock, R., and Qu, L. (2017). Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1944–1952.

[40] Qin, Z., Yang, Y., Yu, T., Khalil, I., Xiao, X., and Ren, K. (2016). Heavy Hitter Estimation Over Set-Valued Data with Local Differential Privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. 192–203.

[41] Rhee, S., Seo, S., and Kim, S. (2017). Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classification. arXiv preprint arXiv:1711.05859.

[42] Rozemberczki, B., Allen, C., and Sarkar, R. (2019). Multi-Scale Attributed Node Embedding. arXiv preprint arXiv:1909.13021.

[43] Rozemberczki, B., and Sarkar, R. (2020). Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models. In Proceedings of the 29th ACM International Conference on Information and Knowledge Management (CIKM ’20). ACM.

[44] Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., and Monfardini, G. (2008). The Graph Neural Network Model. IEEE Transactions on Neural Networks 20, 1, 61–80.

[45] Song, H., Kim, M., Park, D., and Lee, J.-G. (2020). Learning from Noisy Labels with Deep Neural Networks: A Survey. arXiv preprint arXiv:2007.08199.

[46] Thakurta, A. G., Vyrros, A. H., Vaishampayan, U. S., Kapoor, G., Freudiger, J., Sridhar, V. R., and Davidson, D. (2017). Learning New Words. US Patent 9,594,741.

[47] Veličković, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., and Bengio, Y. (2017). Graph Attention Networks. arXiv preprint arXiv:1710.10903.

[48] Wang, H., and Leskovec, J. (2020). Unifying Graph Convolutional Neural Networks and Label Propagation. arXiv preprint arXiv:2002.06755.

[49] Wang, N., Xiao, X., Yang, Y., Hoang, T. D., Shin, H., Shin, J., and Yu, G. (2018). PrivTrie: Effective Frequent Term Discovery Under Local Differential Privacy. In 2018 IEEE 34th International Conference on Data Engineering (ICDE). IEEE, 821–832.

[50] Wang, N., Xiao, X., Yang, Y., Zhao, J., Hui, S. C., Shin, H., Shin, J., and Yu, G. (2019). Collecting and Analyzing Multidimensional Data with Local Differential Privacy. In 2019 IEEE 35th International Conference on Data Engineering (ICDE). IEEE, 638–649.

[51] Wang, S., Huang, L., Wang, P., Nie, Y., Xu, H., Yang, W., Li, X.-Y., and Qiao, C. (2016). Mutual Information Optimally Local Private Discrete Distribution Estimation. arXiv preprint arXiv:1607.08025.

[52] Wang, T., Blocki, J., Li, N., and Jha, S. (2017). Locally Differentially Private Protocols for Frequency Estimation. In 26th {USENIX} Security Symposium ({USENIX} Security 17). 729–745.

[53] Wang, T., Li, N., and Jha, S. (2018). Locally Differentially Private Frequent Itemset Mining. In 2018 IEEE Symposium on Security and Privacy (SP). IEEE, 127–143.

[54] Wang, T., Li, N., and Jha, S. (2019). Locally Differentially Private Heavy Hitter Identification. IEEE Transactions on Dependable and Secure Computing.

[55] Wang, Y., Wu, X., and Hu, D. (2016). Using Randomized Response for Differential Privacy Preserving Data Collection. In EDBT/ICDT Workshops, Vol. 1558. 0090–6778.

[56] Wu, B., Yang, X., Pan, S., and Yuan, X. (2020). Model Extraction Attacks on Graph Neural Networks: Taxonomy and Realization. arXiv preprint arXiv:2010.12751.

[57] Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., and Philip, S. Y. (2020). A Comprehensive Survey on Graph Neural Networks. IEEE Transactions on Neural Networks and Learning Systems.

[58] Xu, D., Yuan, S., Wu, X., and Phan, H. (2018). DPNE: Differentially Private Network Embedding. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 235–246.

[59] Xu, K., Hu, W., Leskovec, J., and Jegelka, S. (2018). How Powerful Are Graph Neural Networks? arXiv preprint arXiv:1810.00826.

[60] Xu, K., Li, C., Tian, Y., Sonobe, T., Kawarabayashi, K.-i., and Jegelka, S. (2018). Representation Learning on Graphs with Jumping Knowledge Networks. In Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 80), Dy, J., and Krause, A. (Eds.). PMLR, Stockholmsmässan, Stockholm Sweden, 5453–5462.

[61] Yang, Z., Cohen, W. W., and Salakhutdinov, R. (2016). Revisiting Semi-Supervised Learning with Graph Embeddings. arXiv preprint arXiv:1603.08861.

[62] Ye, M., and Barg, A. (2018). Optimal Schemes for Discrete Distribution Estimation Under Locally Differential Privacy. IEEE Transactions on Information Theory 64, 8, 5662–5676.

[63] Yi, K., and Wu, J. (2019). Probabilistic End-to-End Noise Correction for Learning with Noisy Labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 7017–7025.

[64] Zhang, H., Cisse, M., Dauphin, Y. N., and Lopez-Paz, D. (2017). mixup: Beyond Empirical Risk Minimization. arXiv preprint arXiv:1710.09412.

[65] Zhang, M., and Chen, Y. (2018). Link Prediction Based on Graph Neural Networks. In Advances in Neural Information Processing Systems. 5165–5175.

[66] Zhang, S., and Ni, W. (2019). Graph Embedding Matrix Sharing with Differentially Private Perturbed Gradient Descent. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI).