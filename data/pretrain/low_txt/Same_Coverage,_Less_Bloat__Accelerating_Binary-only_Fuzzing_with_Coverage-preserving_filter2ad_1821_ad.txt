### Benchmark Selection
Our benchmark selection (Table 6) follows the current standard in fuzzing literature, consisting of eight binaries from popular open-source applications. These applications vary by input file format (e.g., images, audio, video) and characteristics. Additionally, since Coverage-Guided Tracing (CGT) is commonly used to accelerate binary-only fuzzing, we include a set of four closed-source binary benchmarks distributed as free software. All benchmarks are chosen from versions known to contain well-documented bugs, ensuring a clear and self-evident comparison in our bug-finding evaluation.

For each tracing approach, we exclude benchmarks that are unsupported or fail:
- **QEMU**: sam2p and sfconvert (due to repeated deadlocks).
- **Dyninst**: lzturbo, pngout, rar, and unrar (due to its inability to support closed-source, stripped binaries [38]).
- **RetroWrite**: jasper, nasm, sam2p, lzturbo, pngout, rar, and unrar (due to crashes on startup and/or being position-dependent/stripped).
- **AFL-Clang**: lzturbo, pngout, rar, and unrar (due to it only supporting open-source targets).

### Infrastructure
All evaluations are conducted on Microsoft Azure cloud infrastructure. Each fuzzing trial is executed on an isolated Ubuntu 16.04 x86-64 virtual machine. Following the standard set by Klees et al. [32], we run 16 trials of 24 hours each for every benchmark and coverage-tracing approach listed in Table 5, resulting in over 2.4 years of total compute time across our entire evaluation. Benchmarks are instrumented on an Ubuntu 16.04 x86-64 desktop with a 6-core 3.50GHz Intel Core i7-7800x CPU and 64GB of memory. The same system is used for all data post-processing.

### Q1: Coverage Evaluation
To understand the trade-offs of adapting CGT to finer-grained coverage metrics, we first evaluate HeXcite’s code and loop coverage against the block-coverage-only Coverage-guided Tracer UnTracer, as well as conventional always-on coverage-tracing approaches like QEMU, Dyninst, RetroWrite, and AFL-Clang. Below, we detail our experimental setup and results.

#### 5.2.1 Code Coverage
We compare the code coverage of all tracing approaches in Table 5. We use AFL++’s Link Time Optimization (LTO) instrumentation [18] to build collision-free edge-tracking versions of each binary. The same technique is applied to our four closed-source benchmarks (Table 6) using the industry-standard binary-to-LLVM lifting tool McSema [14]. We measure each trial’s code coverage by replaying its test cases on the LTO binary using AFL’s `afl-showmap` utility and compute the average across all 16 trials. Table 7 reports the average across all benchmark–tracer pairs, along with Mann-Whitney U significance scores at the \( p = 0.05 \) significance level. Figure 7 shows the relative edge coverage over 24 hours for several benchmarks.

**Versus UnTracer:**
As shown in Table 7, HeXcite surpasses UnTracer in total coverage across all benchmarks by 1–18%, with a mean improvement of 6.2%. Statistically higher coverage is observed on 10 out of 12 benchmarks. The impact of coverage granularity on CGT is significant; besides seeing the worst coverage on unrtf (Figure 7c) and sfconvert, UnTracer is outperformed by AFL-Clang on all 8 open-source benchmarks. This demonstrates that sheer speed is not enough to overcome a sacrifice in code coverage, whereas HeXcite’s coverage-preserving CGT achieves the highest overall code coverage in our evaluation.

**Versus Binary-Only Always-On Tracing:**
HeXcite achieves a mean 23.1%, 18.1%, and 6.3% higher code coverage over binary-only always-on tracers QEMU, Dyninst, and RetroWrite, respectively. Statistically significant improvements are observed on all but one binary per comparison (yara for QEMU, and sfconvert for Dyninst and RetroWrite). For sfconvert, all tracers' runs are dominated by timeout-inducing inputs, causing roughly equal execution speeds and code coverage. While timeout-laden binaries are less likely to benefit from CGT, HeXcite’s balance of fine-grained coverage and speed ranks it as the highest-coverage binary-only tracer.

**Versus Source-Level Always-On Tracing:**
Across all eight open-source benchmarks, HeXcite averages 1.1% higher coverage than AFL’s source-level tracing, AFL-Clang. Despite statistically worse coverage on sfconvert (due to heavy timeouts), HeXcite’s coverage is statistically better or identical to AFL-Clang’s on 7 out of 8 benchmarks, confirming that coverage-preserving CGT brings coverage tracing at least as effective as source-level tracing to binary-only fuzzing use cases.

#### 5.2.2 Loop Coverage
To determine if coverage-preserving CGT is more effective at covering code loops, we develop a custom LLVM instrumentation pass to report the maximum consecutive iterations per loop per trial. Despite successfully lifting our closed-source benchmarks to add edge-tracking instrumentation (§ 5.2.1), none of our binary-to-LLVM lifters (McSema, rev.ng, RetDec, reopt, llvm-mctoll, or Ghidra-to-LLVM) succeeded in recovering the necessary loop metadata. Thus, our loop analysis is restricted to the eight open-source benchmarks.

We compare HeXcite to UnTracer and AFL-Clang, as they support all eight open-source benchmarks. We compute each loop’s mean from the maximum consecutive iterations for all trials per benchmark–tracer pair, capping iterations at 128 to match AFL. Table 8 shows HeXcite’s mean loop coverage relative to UnTracer and AFL-Clang, with statistically significant improvements highlighted.

**Results:**
- **HeXcite vs. UnTracer:** HeXcite shows a 130% increase in loop coverage.
- **HeXcite vs. AFL-Clang:** HeXcite shows a 36% increase in loop coverage.

Figure 8 illustrates HeXcite’s mean loop coverage relative to UnTracer, with green and pink shading indicating higher relative loop coverage for HeXcite and UnTracer, respectively, and grey indicating no change.

### Throughput Analysis
Figure 9 shows HeXcite’s mean throughput relative to conventional coverage tracers. We normalize throughput to the worst-performing tracer per benchmark, providing a clear comparison of performance.