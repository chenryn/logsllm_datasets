### Detection Time

We evaluated the feasibility of CHIRON as a practical tool for detecting semantic bugs by measuring the execution time of its major components (see Table VI). In this experiment, we considered only the restricted event model (EM1). Each reported execution time is an average of 10 independent runs.

Once the E-FSM is extracted, it can be used to detect semantic bugs against any number of properties. For property checking, we measured the total time required to model check all properties (6 for TLS, 11 for Telnet, and 7 for DHCP) until either a consistent counterexample (CEX) or no CEX is found. For comparison, we report the average time required to model check per property (see Table VI). The CEX replay time is measured only if CHIRON found a consistent CEX to replay. We report the time to replay per consistent CEX. The experiment time signifies the total time required to complete the entire analysis of each implementation.

Among the three Telnet server implementations, CHIRON requires the longest time (6 seconds) to extract the E-FSM from Telnet C27, which has a relatively larger E-FSM size (see Table V). A similar trend is observed for the two DHCP client implementations. Note that CHIRON requires more time for both DHCP implementations compared to the Telnet implementations. This is because, for a DHCP client, CHIRON processes a symbolic packet of up to 552 bytes for each receive event, whereas for a Telnet server, it processes 1 byte at a time. Similarly, CHIRON requires about 100 seconds to extract the E-FSM from TLS OP, which is expected due to its large E-FSM size (see Table V).

The time spent on model checking each property is influenced by the E-FSM size, the length of the property, and the number of propositions. This trend is evident among the implementations we tested (see Table VI), with TLS OP taking the longest time (2 seconds) to model check a single property compared to the other implementations. Replaying a CEX takes a small fraction of the time compared to the extraction of the respective E-FSM because CHIRON’s CEX replayer drives the actual execution of the protocol along only one execution path. Finally, CHIRON completes the full analysis for each implementation within a few seconds (with a maximum of 2 minutes for TLS OP).

### Related Work

We outline the prior work closely related to CHIRON.

#### Software Model Checking

CHIRON aims to automatically check whether a protocol implementation violates a given temporal property and thus detect the underlying semantic bug. Software model checking [33]–[39] generalizes this for any program and safety properties. A software model checking approach can either focus on finding violations or proving properties. Based on the underlying technique, software model checking approaches can be broadly categorized into two classes: execution-based approaches [33]–[35] and abstraction-based approaches [36], [37]. CHIRON follows the abstraction-based approach by abstracting the protocol implementation with an E-FSM. Typically, execution-based approaches cannot explore the entire state space due to the state-space explosion problem, whereas abstraction-based approaches suffer from spurious CEXs.

Another class of software model checking approaches, known as counterexample-guided abstraction refinement (CEGAR) [38]–[40], combines the advantages of both approaches by automatically generating abstractions of the program under analysis and refining the program (or the model) when a spurious CEX is encountered. Although CHIRON does not exactly follow the CEGAR approach, adding invariants based on spurious CEXs during model checking can be viewed as model refinement.

#### Protocol Analysis

Prior work checks the correctness of protocols by analyzing either manually formalized specifications [41], [42] or implementations in domain-specific languages [43]–[45]. However, these approaches cannot find bugs in actual implementations. Holzmann et al. [46] require heavily annotated source code and user-provided rules to extract the abstract event-driven program model from the source. The model is then verified using a non-deterministic test driver to simulate the necessary behavior of the external system. In contrast, CHIRON uses symbolic execution to automatically extract the E-FSM of the protocol with minimal user input and does not require a test driver.

Several explicit-state model checkers (CMC [7], [8], NICE [9]) are used to verify protocol implementations against user-provided state invariants, not temporal properties. While directly model checking the code can help detect low-level programming errors, it can quickly lead to the state-space explosion problem. In contrast, CHIRON focuses on temporal properties expressed in pLTL and checks them against the extracted E-FSM using a symbolic model checker.

Several tools [31], [32], [47] have been developed by extending dynamic symbolic execution [27], [48] to analyze network protocol implementations; however, they cannot detect semantic bugs due to violations of temporal properties. SymbexNet [31] can be tailored to test temporal behavior limited to discernible effects (e.g., exchanged messages), but CHIRON can check properties even with silent internal effects. PIC [32] identifies non-interoperable implementations by finding discrepancies between what the sender can send and what the receiver can receive. In contrast, CHIRON detects semantic bugs in implementations with respect to user-provided temporal properties, often derived from RFCs.

Fuzzing has been another predominant approach to finding bugs in protocol implementations [30], [49], [50], including secure protocols like TLS [5], [6]. Fuzzing relies on black-box testing and finds bugs causing discernible external effects (e.g., crashes, incorrect message exchanges). In contrast, CHIRON's capabilities are fundamentally different and complementary. While some fuzzing tools can be tailored to check temporal behavior with discernible effects, they cannot find semantic bugs causing silent incorrect behavior nor identify buggy execution paths. SmackTLS [5] finds additional bugs in OpenSSL that CHIRON cannot detect as they are not directly realizable through the TLS client’s E-FSM. To detect those bugs, SmackTLS relies on two manually derived components: a state machine of TLS for generating test cases and a verified reference implementation of TLS to decide if the outcome of a test case is correct. In contrast, CHIRON requires neither a state machine nor a reference implementation; it relies on the desired temporal properties derived from RFCs and the developer-provided meta-information of the protocol implementation.

#### Inferring Protocol Specification

Prior work aims to infer the protocol specification (FSM) based on network traces [51]–[54], using program analysis [6], [24], [55], [56], or through model checking [36], [57]. These extracted FSMs represent either discernible external interactions of the protocol (e.g., sequences of exchanged messages) or low-level program state machines (not E-FSMs). In contrast, CHIRON extracts the E-FSM from the implementation by primarily capturing precise internal interactions of the protocol.

### Conclusion

We presented CHIRON, an automated tool to help developers detect semantic bugs in event-driven network protocol implementations by checking if the implementation violates given temporal properties. CHIRON first automatically extracts the E-FSM from the implementation using our FSM extraction technique based on symbolic execution and then uses a symbolic model checker to detect whether the E-FSM violates the properties. We demonstrated CHIRON’s efficacy by applying it to six mature implementations of three protocols. CHIRON detected 11 semantic bugs violating properties derived from the documentation and RFCs of the protocols. Our results demonstrate that CHIRON can be useful for developers to discover semantic bugs.

### Acknowledgment

We would like to thank the anonymous reviewers for their helpful comments. This work was supported in part by the grant CNS-1421815 from the SaTC program of the National Science Foundation. Its contents are solely the responsibility of the authors and do not represent the official view of the National Science Foundation.

### References

[1] T. Dierks and C. Allen, “The tls protocol version 1.0,” Internet Requests for Comments, RFC 2246, 1999.
[2] L. Tan, C. Liu, Z. Li, X. Wang, Y. Zhou, and C. Zhai, “Bug characteristics in open source software,” Empirical Softw. Engg., vol. 19, no. 6, 2014.
[3] “OpenSSL toolkit,” http://www.openssl.org/.
[4] “Contiki bug report,” http://github.com/contiki-os/contiki/commit/d862e.
[5] B. Beurdouche, K. Bhargavan, A. Delignat-Lavaud, C. Fournet, M. Kohlweiss, A. Pironti, P. Strub, and J. Zinzindohoue, “A messy state of the union: Taming the composite state machines of TLS,” in S&P. IEEE, 2015.
[6] J. de Ruiter and E. Poll, “Protocol state fuzzing of tls implementations,” in USENIX Security, 2015.
[7] M. Musuvathi and D. Engler, “Model checking large network protocol implementations,” in NSDI, 2004.
[8] M. Musuvathi, D. Park, A. Chou, D. Engler, and D. Dill, “CMC: Pragmatic approach to model checking real code,” in OSDI, 2002.
[9] M. Canini, D. Venzano, P. Perešíni, D. Kostić, and J. Rexford, “A nice way to test openflow applications,” in NSDI, 2012.
[10] J. C. King, “Symbolic execution and program testing,” Communications of the ACM, vol. 19, no. 7, pp. 385–394, 1976.
[11] B. Alpern and F. Schneider, “Recognizing safety and liveness,” Distributed Computing, vol. 2, no. 3, pp. 117–126, 1987.
[12] J. Postel and J. Reynolds, “Telnet protocol specification,” RFC 854, 1983.
[13] R. Droms, “Dynamic host configuration protocol,” RFC 2131, 1997.
[14] A. Dunkels, “Full tcp/ip for 8-bit architectures,” in MobiSys, 2003.
[15] “Fnet embedded tcp/ip stack,” http://fnet.sourceforge.net/.
[16] S. Chong, J. Guttman, A. Datta, A. Myers, B. Pierce, P. Schaumont, T. Sherwood, and N. Zeldovich, “Report on the NSF Workshop on Formal Methods for Security,” eprint arXiv:1608.00678, 2016.
[17] C. Labovitz, A. Ahuja, A. Bose, and F. Jahanian, “Delayed internet routing convergence,” in SIGCOMM, 2000.
[18] R. Jhala and R. Majumdar, “Software model checking,” ACM Computing Surveys (CSUR), vol. 41, no. 4, p. 21, 2009.
[19] G. Nelson and D. Oppen, “Fast decision procedures based on congruence closure,” J. ACM, vol. 27, no. 2, 1980.
[20] Z. Manna and A. Pnueli, The Temporal Logic of Reactive and Concurrent Systems. Springer-Verlag, 1992.
[21] K. L. McMillan, Symbolic model checking. Springer, 1993.
[22] N. Kothari, R. Mahajan, T. Millstein, R. Govindan, and M. Musuvathi, “Finding protocol manipulation attacks,” in SIGCOMM, 2011.
[23] I. Yun, C. Min, X. Si, Y. Jang, T. Kim, and M. Naik, “Apisan: Sanitizing api usages through semantic cross-checking,” in USENIX Security, 2016.
[24] N. Kothari, T. Millstein, and R. Govindan, “Deriving state machines from tinyos programs using symbolic execution,” in IPSN. IEEE, 2008.
[25] A. Bauer and M. Leucker, “The theory and practice of SALT,” in NASA Formal Methods, ser. LNCS, 2011.
[26] “Contiki OS,” http://www.contiki-os.org.
[27] C. Cadar, D. Dunbar, and D. R. Engler, “Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs.” in OSDI, 2008, pp. 209–224.
[28] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore, M. Roveri, R. Sebastiani, and A. Tacchella, “NuSMV Version 2: An OpenSource Tool for Symbolic Model Checking,” in CAV, 2002.
[29] C. Hawblitzel, J. Howell, M. Kapritsos, J. Lorch, B. Parno, M. Roberts, S. Setty, and B. Zill, “Ironfleet: Proving practical distributed systems correct,” in SOSP, 2015.
[30] G. Banks, M. Cova, V. Felmetsger, K. Almeroth, R. Kemmerer, and G. Vigna, “Snooze: Toward a stateful network protocol fuzzer,” in Information Security. Springer, 2006.
[31] J. Song, C. Cadar, and P. Pietzuch, “Symbexnet: Testing network protocol implementations with symbolic execution and rule-based specifications,” TSE, vol. 40, no. 7, 2014.
[32] L. Pedrosa, A. Fogel, N. Kothari, R. Govindan, R. Mahajan, and T. Millstein, “Analyzing protocol implementations for interoperability,” in NSDI, 2015.
[33] T. Andrews, S. Qadeer, S. K. Rajamani, J. Rehof, and Y. Xie, “Zing: A model checker for concurrent software,” in CAV, 2004.
[34] P. Godefroid, “Model checking for programming languages using verisoft,” in POPL. ACM, 1997.
[35] G. Holzmann, “The model checker SPIN,” TSE, vol. 23, no. 5, 1997.
[36] J. Corbett, M. Dwyer, J. Hatcliff, S. Laubach, C. Păsăreanu, R. Bby, and H. Zheng, “Bandera: Extracting finite-state models from java source code,” in ICSE, 2000.
[37] M. Das, S. Lerner, and M. Seigle, “Esp: Path-sensitive program verification in polynomial time,” in PLDI, 2002.
[38] T. Ball and S. Rajamani, “The slam project: Debugging system software via static analysis,” SIGPLAN Not., vol. 37, no. 1, 2002.
[39] D. Beyer, T. Henzinger, R. Jhala, and R. Majumdar, “The software model checker blast: Applications to software engineering,” Int. J. Softw. Tools Technol. Transf., vol. 9, no. 5, 2007.
[40] E. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith, “Counterexample-guided abstraction refinement,” in CAV, 2000, pp. 154–169.
[41] K. Bhargavan, D. Obradovic, and C. Gunter, “Formal verification of standards for distance vector routing protocols,” JACM, vol. 49, no. 4, pp. 538–576, 2002.
[42] S. Bishop, M. Fairbairn, M. Norrish, P. Sewell, M. Smith, and K. Wansbrough, “Rigorous specification and conformance testing techniques for network protocols, as applied to tcp, udp, and sockets,” in SIGCOMM, 2005.
[43] E. M. Clarke, S. Jha, and W. Marrero, “Verifying security protocols with brutus,” TOSEM, vol. 9, no. 4, 2000.
[44] S. Chaki and A. Datta, “Aspier: An automated framework for verifying security protocol implementations,” in IEEE CSF, 2009, pp. 172–185.
[45] K. Bhargavan, C. Fournet, A. Gordon, and S. Tse, “Verified interoperable implementations of security protocols,” TOPLAS, vol. 31, no. 1, 2008.
[46] G. Holzmann and M. Smith, “A practical method for verifying event-driven software,” in ICSE. ACM, 1999.
[47] R. Sasnauskas, O. Landsiedel, M. H. Alizai, C. Weise, S. Kowalewski, and K. Wehrle, “Kleenet: Discovering insidious interaction bugs in wireless sensor networks before deployment,” in IPSN. ACM, 2010.
[48] P. Godefroid, N. Klarlund, and K. Sen, “DART: Directed automated random testing,” in PLDI. ACM, 2005.
[49] H. J. Abdelnur, R. State, and O. Festor, “Kif: A stateful sip fuzzer,” in IPTComm. ACM, 2007.
[50] S. Jero, H. Lee, and C. Nita-Rotaru, “Leveraging state information for automated attack discovery in transport protocol implementations,” in DSN, 2015.
[51] P. M. Comparetti, G. Wondracek, C. Kruegel, and E. Kirda, “Prospex: Protocol specification extraction,” in S&P. IEEE, 2009.
[52] Y. Wang, Z. Zhang, D. D. Yao, B. Qu, and L. Guo, “Inferring protocol state machine from network traces: A probabilistic approach,” in ACNS. Springer, 2011.
[53] J. Caballero, P. Poosankam, C. Kreibich, and D. Song, “Dispatcher: Enabling active botnet infiltration using automatic protocol reverse-engineering,” in ACM CCS, 2009.
[54] C. Cho, D. Babić, E. Shin, and D. Song, “Inference and analysis of formal models of botnet command and control protocols,” in CCS, 2010.
[55] C. Y. Cho, D. Babic, P. Poosankam, K. Z. Chen, E. X. Wu, and D. Song, “Mace: Model-inference-assisted concolic exploration for protocol and vulnerability discovery.” in USENIX Security, 2011.
[56] J. Caballero, H. Yin, Z. Liang, and D. Song, “Polyglot: Automatic extraction of protocol message format using dynamic binary analysis,” in ACM CCS, 2007.
[57] D. Lie, A. Chou, D. Engler, and D. L. Dill, “A simple method for extracting models from protocol code,” in ISCA. IEEE, 2001.

### Appendix A: Symbolic Execution

Symbolic execution is a program analysis technique that executes the code using symbolic values instead of concrete values (e.g., α instead of 2) for program inputs. After executing each program statement, the executor updates the symbolic store, maintaining information about program variables (e.g., x = 5α). Special attention is given to handling branches (i.e., if-else, loops). At each branch, the executor consults a constraint solver (e.g., an SMT solver) to determine the feasibility of the branch condition given the information in the symbolic store, so that the executor can continue exploring only feasible branches. When both branches are feasible, the executor explores both, creating two different execution paths. Upon termination of the execution, the executor constructs a tree of all possible execution paths of the program. Each execution path is represented by a unique path constraint, which is the conjunction of branch choices that need to be made to follow the path. If necessary, each path constraint can be solved using a constraint solver to obtain concrete inputs for that path.