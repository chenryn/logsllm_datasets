# Distributed Secure Systems: Then and Now

**Authors:**
- Brian Randell
- John M. Rushby

**Conference:**
23rd Annual Computer Security Applications Conference

**Biographies:**

**Brian Randell:**
Brian Randell graduated in Mathematics from Imperial College, London, in 1957. He began his career at the English Electric Company, where he led a team that developed several compilers, including the Whetstone KDF9 Algol compiler. From 1964 to 1969, he worked at IBM, primarily at the IBM T.J. Watson Research Center, focusing on operating systems, ultra-high-speed computer design, and computing system design methodology. In 1969, he became a Professor of Computing Science at Newcastle University, where he initiated research into software fault tolerance and introduced the "recovery block" concept in 1971. His subsequent work included the Newcastle Connection and the prototype Distributed Secure System.

Randell has been the Principal Investigator for numerous research projects funded by the Science Research Council (now the Engineering and Physical Sciences Research Council), the Ministry of Defence, and the European Strategic Programme of Research in Information Technology (ESPRIT). Currently, he is involved with the European Information Society Technologies (IST) Programme. He has directed projects such as CaberNet (the IST Network of Excellence on Distributed Computing Systems Architectures), MAFTIA (Malicious- and Accidental-Fault Tolerance for Internet Applications), and DSoS (Dependable Systems of Systems).

He has published nearly 200 technical papers and reports and co-authored or edited seven books. Randell is now an Emeritus Professor of Computing Science and Senior Research Investigator at Newcastle University. He has served on the Conseil Scientifique of the CNRS, France (2001-2005), and as Chairman of the IEEE John von Neumann Medal Committee (2003-2005). He is also a Member of the ACM A.M. Turing Award Committee (2005-2009). He has received a D.Sc. from the University of London and honorary doctorates from the University of Rennes and the Institut National Polytechnique of Toulouse, France. Additionally, he was awarded the IEEE Emanuel R. Piore Award in 2002.

**John M. Rushby:**
John M. Rushby received his B.Sc. and Ph.D. in computing science from the University of Newcastle upon Tyne in 1971 and 1977, respectively. He joined the Computer Science Laboratory at SRI International in 1983 and served as its director from 1986 to 1990. Currently, he manages the laboratory's research program in formal methods and dependable systems, which includes the development of the PVS verification system, the SAL suite of model checkers, and the Yices SMT solver.

Prior to joining SRI, Rushby held academic positions at the Universities of Manchester and Newcastle upon Tyne in England. His research interests focus on the use of formal methods for the design and assurance of secure and dependable systems. He has been an associate editor for Communications of the ACM, IEEE Transactions on Software Engineering, and Formal Aspects of Computing. Rushby authored a chapter on formal methods for the FAA Certification Handbook and is a member of a National Research Council study that recently delivered the report “Software for Dependable Systems: Sufficient Evidence?”

---

**Abstract:**

In the early 1980s, sophisticated distributed systems emerged, allowing a collection of systems to operate as a coherent whole through remote procedure calls, hierarchical naming, and middleware. One such system, developed at Newcastle University, enabled pre-existing applications and Unix systems to be used as components of a large, multi-processor Unix system. The Distributed Secure System (DSS) proposed in our 1983 paper leveraged the design freedom of distributed computing to separate security concerns of policy enforcement from those of resource sharing. The DSS used various mechanisms, including dedicated components, cryptography, and separation kernels, to manage resource sharing more simply than before.

In this retrospective, we provide the full original text of our DSS paper, prefaced by an introductory discussion of the DSS in its historical context. We follow with an account of the subsequent implementation and deployment of an industrial prototype of DSS and a description of its modern interpretation in the form of the MILS architecture. We conclude by outlining current opportunities and challenges presented by this approach to security.

---

**Introduction and Background:**

The concept of a Distributed Secure System (DSS) was largely an accidental outcome of a long-running series of research projects at Newcastle University on reliability and fault tolerance. These projects were inspired by discussions at the 1968 NATO Software Engineering Conference, which highlighted the major problems in large software projects and spurred research aimed at producing bug-free software. At Newcastle, the focus was on achieving reliable service from complex software systems despite the presence of bugs.

Initially, the work focused on sequential programs, but by 1975, it had expanded to include error recovery among sets of cooperating processes. By the late 1970s, the research had shifted to distributed computing systems. The goal was to gradually extend the range of systems and types of faults for which well-structured error recovery could be provided, rather than adding reliability to immense complexity.

The reliability research was mainly funded by the Science Research Council (SRC), with additional funding from the Royal Signals and Radar Establishment (RSRE) of the UK Ministry of Defence. RSRE later offered funding to work on security, specifically to undertake a detailed and critical study of various security projects in the United States aimed at providing formal proofs of highly secure systems.

This allowed John Rushby to rejoin Newcastle University, where he realized that the Secure User Executive, developed by Derek Barnes, had a simpler structure than most secure operating systems being developed in the USA. This led to the formulation of the ideas of a "separation kernel" and "proof of separability," which later influenced the conception of DSS.

The reliability project intended to base its work on existing distributed systems. However, in 1982, a novel scheme was developed to construct a powerful distributed system from a set of Unix systems, leveraging the hierarchical naming structure in Unix. This scheme, known as the "Newcastle Connection," involved inserting a transparent layer of middleware at the Unix system call level, allowing neither the Unix system nor any application programs to be altered. The resulting distributed systems were termed "UNIX United."

An important characteristic of the Newcastle Connection, designed by Lindsay Marshall, was that it handled all system calls, not just those related to files, making UNIX United a true distributed computing system, not just a distributed file system.

The recursive approach to system building in UNIX United led to the realization that other transparent layers of software, including one for hardware fault tolerance based on Triple Modular Redundancy (TMR), could be added. When John Rushby expressed a desire to join the system-building efforts, the idea of applying the recursive approach to deconstruct a system emerged. This led to the understanding that it would be possible to implement an apparently conventional Unix system that enforced a multi-level security policy by allocating different security domains to different physical machines and enforcing security constraints on inter-machine communication.

---

**A Distributed Secure System:**

A secure system is one that can be trusted to keep secrets, and the key word here is "trusted." Individuals, governments, and institutions such as banks, hospitals, and commercial enterprises will only entrust their secrets to a computer system if they can be absolutely certain of confidentiality. The problems of maintaining security are compounded because the sharing of secrets is generally desired but must be tightly controlled. In the simplest case, an individual can choose others with whom to share private information, a type of controlled sharing called discretionary security.

However, when individuals are part of an organization, the organization may impose a mandatory security policy to safeguard its interests. The most widely used scheme of this type is the multilevel security (MLS) policy, which enforces a hierarchy of access levels.