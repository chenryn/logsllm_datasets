### Optimized Text

#### Unknown or Untargeted Locations
The techniques presented in this paper detect network monitors through a faster, stealthy, and lightweight sampling method that does not require a pre-established set of publishing locations. 

Zeiton et al. demonstrated the feasibility of estimating the liveliness of /24 address prefixes by selectively probing IP addresses based on common network administration practices (e.g., selecting commonly used router interface addresses such as a.b.c.1 and a.b.c.129). Their technique achieved over 90% accuracy in detecting live prefixes but is limited to /24 prefixes. In contrast, our methodology provides an upper-bound on the number of probes and is applicable to prefixes of any size.

#### Fast Worms and Novel Scanning Techniques
Over the past few years, several proposals have highlighted the threat posed by fast worms employing novel scanning techniques. These techniques enhance worm propagation through various forms of collaboration among worm instances. For example, Staniford et al. [33] outlined collaborative scanning strategies, including permutation scanning, where the worm maps the IP space into a large permutation and diversifies the starting points of scanners to reduce redundant scanning. While this strategy allows for faster worm spread, the scanning activity remains visible to network monitors because the worm still scans the entire IP space. Flash and topological worms can reach saturation in just a few seconds [32], but they rely on a priori knowledge of the vulnerable population through an existing large hit-list.

Chen et al. [5] proposed an alternative strategy to disseminate information about the vulnerable population distribution and divert worm scans toward populated address groups. However, their approach has limitations from an evasion perspective. Initially, the worm scans the IP space uniformly at random to find enough vulnerable hosts to estimate the vulnerable population distribution, which is easily detected by distributed network monitors. Additionally, the vulnerable population distribution is only estimated at the /8 prefix level, limiting the worm's ability to evade monitors in heavily populated prefixes. Furthermore, each infected host must contact a centralized "worm-server," creating a single point of failure and an unnecessary bottleneck.

Our coordination mechanism exploits re-infections to disseminate updated knowledge about the vulnerable population across worm instances. This idea was independently suggested by Ma et al. [16] for designing self-stopping worms, where re-infection is used to share an estimate of the infected population, which is then used to decide when to stop scanning. Although such worms can hide the infected population past worm saturation, they can still be detected and contained during the spreading phase. In contrast, our examples conceal worm activity during the spreading phase and are inherently self-stopping.

#### Persistent Port Scanning and Fingerprinting
Several measurement studies based on packet traces collected from network monitors have speculated that persistent port scanning activities are being used to fingerprint vulnerable hosts (e.g., Pang et al. [20], Pouget et al. [24]). In this paper, we demonstrate how such reconnaissance can be performed in a dynamic, fast, and evasive manner.

### Summary
The use of passive network monitors has been crucial in many malware detection and containment studies. However, with the increased use of passive monitoring techniques, it is prudent to expect that attacks will evolve to minimize the practical benefits gained from such techniques. In this paper, we highlight the challenges posed by evasive techniques that severely limit the view of the infection as recorded by collections of distributed network monitors. Our techniques use lightweight sampling to detect passive network monitors and clusters of live network prefixes. We demonstrate the effectiveness of these evasive techniques through trace-based analysis and actual probing experiments conducted in the wild. Our experimental results verify that with a reasonably small number of probes, it is possible to accurately detect the locations of passive network monitors and identify live address clusters containing the majority of the vulnerable population. We also outline the design of evasive malware capable of evading extensive collections of network monitors while saturating the vulnerable population in a matter of seconds. We hope our results will stimulate the research community to develop monitoring infrastructures capable of countering these impending threats.

### Acknowledgments
This work is supported in part by the National Science Foundation grant SCI-0334108. We thank DShield for providing access to their IDS logs. We also extend our gratitude to the reviewers for their insightful comments and feedback.

### References
1. Michael Bailey, Evan Cooke, Farnam Jahanian, Jose Nazario, and David Watson. Internet motion sensor: A distributed blackhole monitoring system. In Proceedings of the ISOC Network and Distributed System Security Symposium (NDSS), 2005.
2. Paul Barford, Rob Nowak, Rebecca Willet, and Vinod Yagneswaran. Toward a Model for Source Address of Internet Background Radiation. In Proceedings of the Passive and Active Measurement Conference (PAM 2006), March 2006.
3. John Bethencourt, Jason Franklin, and Mary Vernon. Mapping Internet Sensors with Probe Response Attacks. In Proceedings of the 14th USENIX Security Symposium, pages 193–212, August 2005.
4. Zesheng Chen, Lixin Gao, and Kevin Kwiat. Modeling the Spread of Active Worms. In Proceedings of IEEE INFOCOMM, volume 3, pages 1890–1900, 2003.
5. Zesheng Chen and Chuanyi Ji. A Self-Learning Worm Using Importance Scanning. In Proceedings of ACM Workshop On Rapid Malcode (WORM), November 2005.
6. The Distributed Intrusion Detection System (DShield). See www.dshield.org/.
7. Xinwen Fu, Bryan Graham, Dan Cheng, Riccardo Bettati, and Wei Zhao. Camouflaging Virtual Honeypots. In Texas A&M University technical report #2005-7-3, 2005.
8. Thorsten Holz and Frederic Raynal. Defeating Honeypots. Online article, see http://www.securityfocus.com/infocus/1826#ref3.
9. Internet Assigned Numbers Authority (IANA). See http://www.iana.org/.
10. Internet Systems Consortium (ISC). See http://www.isc.org.
11. Vinod Yegneswaran Jonathon T. Griffin Paul Barford Somesh Jha. An architecture for generating semantic-aware signatures. In Proceedings of the 14th USENIX Security Symposium, August 2005.
12. Hyang-Ah Kim and Brad Karp. Autograph: Toward automated, distributed worm signature detection. In Proceedings of 13th USENIX Security Symposium, 2004.
13. Eddie Kohler, Jinyang Li, Vern Paxson, and Scott Shenker. Observed Structure of Addresses in IP Traffic. In Proceedings of ACM SIGCOMM Internet Measurement Workshop, November 2002.
14. Christian Kreibich and Jon Crowcroft. Honeycomb—creating intrusion detection signatures using honeypots. In Proceedings of 2nd Workshop on Hot Topics in Networks (Hotnets-II), 2003.
15. Tom Liston, LaBrea Tarpit Project. See http://labrea.sourceforge.net/.
16. Justin Ma, Geoffrey Voelker, and Stefan Savage. Self-stopping worms. In Proceedings of ACM Workshop On Rapid Malcode (WORM), pages 12–21, November 2005.
17. David Moore. Network Telescopes: Observing Small or Distant Security Events. In 11th USENIX Security Symposium, Invited Talk, August 2002.
18. David Moore, Vern Paxson, Stefan Savage, Colleen Shannon, Stuart Staniford, and Nicholas Weaver. Inside the Slammer Worm. IEEE Magazine of Security and Privacy Magazine, pages 33–39, July 2003.
19. David Moore, Colleen Shannon, Geoffrey M. Voelker, and Stefan Savage. Internet Quarantine: Requirements for Containing Self-Propagating Code. In Proceedings of IEEE INFOCOM, 2003.
20. Ruoming Pang, Vinod Yegneswaran, Paul Barford, Vern Paxson, and Larry Peterson. Characteristics of Internet Background Radiation. In Proceedings of ACM IMC, October 2004.
21. Larry Peterson, Tom Anderson, and David Culler. A blueprint for introducing disruptive technology into the internet. In First ACM Workshop on Hot Topics in Networks (HotNets-I), October 2002.
22. Phillip Porras, Linda Briesemeister, Keith Skinner, Karl Levitt, Jeff Rowe, and Yu-Cheng Allen Ting. A hybrid quarantine defense. In Proceedings of the Second ACM Workshop on Rapid Malcode (WORM), November 2004.
23. Fabien Pouget, Marc Dacier, and Van Hau Pham. Lurre.com: On the Advantages of Deploying a Large Scale Distributed Honeypot Platform. In Proceeding of the E-Crime and Computer Conference ECCE, March 2005.
24. Fabien Pouget, Marc Dacier, Van Hau Pham, and Herve Deber. Honeynets: Foundations for the development of early warning systems. In NATO Advanced Research Workshop, 2004.
25. Neil Provos. A virtual honeypot framework. In Proceedings of the 13th USENIX Security Symposium, August 2004.
26. Moheeb Abu Rajab, Fabian Monrose, and Andreas Terzis. Fast and Evasive Attacks: Highlighting the challenges ahead. In JHU Computer Science Technical Report HiNRG-RMT-112205, November 2005.
27. Moheeb Abu Rajab, Fabian Monrose, and Andreas Terzis. On the Effectiveness of Distributed Worm Monitoring. In Proceedings of the 14th USENIX Security Symposium, pages 225–237, August 2005.
28. Moheeb Abu Rajab, Fabian Monrose, and Andreas Terzis. Worm Evolution Tracking via Timing Analysis. In Proceedings of ACM Workshop on Rapid Malware (WORM), pages 52–59, November 2005.
29. David Meyer, University of Oregon RouteViews Project. See http://www.routeviews.org/.
30. Colleen Shannon and David Moore. The Spread of the Witty Worm. IEEE Security and Privacy Magazine, 2(4):46–50, July 2004.
31. Yoichi Shinoda, Ko Ikai, and Motomu Itoh. Vulnerabilities of Passive Internet Threat Monitors. In Proceedings of the 14th USENIX Security Symposium, pages 209–224, August 2005.
32. Stuart Staniford, David Moore, Vern Paxson, and Nick Weaver. The Top Speed of Flash Worms. In Proceedings of the ACM Workshop on Rapid Malcode (WORM), pages 33–42, October 2004.
33. Stuart Staniford, Vern Paxson, and Nicholas Weaver. How to 0wn the internet in your spare time. In Proceedings of the 11th USENIX Security Symposium, August 2002.
34. George Varghese, Sumeet Singh, Cristian Estan, and Stefan Savage. Automated worm fingerprinting. In Proceedings of 6th Symposium on Operating System Design and Implementation (OSDI), 2004.
35. Michael Vrable, Justin Ma, Jay Chen, David Moore, Erik Vandekieft, Alex C. Snoeren, Geoffrey M. Voelker, and Stefan Savage. Scalability, Fidelity and Containment in the Potemkin Virtual Honeyfarm. Proceedings of ACM SIGOPS Operating System Review, 39(5):148–162, 2005.
36. Vinod Yegneswaran, Paul Barford, and Somesh Jha. Global intrusion detection in the domino overlay system. In Proceedings of the ISOC Network and Distributed Systems Security Symposium (NDSS), 2004.
37. Vinod Yegneswaran, Paul Barford, and David Plonka. On the Design and Use of Internet Sinks for Network Abuse Monitoring. In Proceedings of the Symposium on Recent Advances in Intrusion Detection (RAID), Sept. 2004.
38. Amgad Zeitoun and Sugih Jamin. Rapid Exploration of Internet Live Address Space Using Optimal Discovery Path. In Proceedings of Globecomm, 2003.

### Anagram: A Content Anomaly Detector Resistant to Mimicry Attack
**Ke Wang, Janak J. Parekh, and Salvatore J. Stolfo**
**Computer Science Department, Columbia University**
**500 West 120th Street, New York, NY, 10027**
**{kewang, janak, sal}@cs.columbia.edu**

#### Abstract
In this paper, we present Anagram, a content anomaly detector that models a mixture of high-order n-grams (n > 1) designed to detect anomalous and suspicious network packet payloads. By using higher-order n-grams, Anagram can detect significant anomalous byte sequences and generate robust signatures of validated malicious packet content. The Anagram content models are implemented using highly efficient Bloom filters, reducing space requirements and enabling privacy-preserving cross-site correlation. The sensor models the distinct content flow of a network or host using a semi-supervised training regimen. Previously known exploits, extracted from the signatures of an IDS, are likewise modeled in a Bloom filter and are used during training as well as detection time. We demonstrate that Anagram can identify anomalous traffic with high accuracy and low false positive rates. Anagram’s high-order n-gram analysis technique is also resilient against simple mimicry attacks that blend exploits with “normal” appearing byte padding, such as the blended polymorphic attack recently demonstrated in [1]. We discuss randomized n-gram models, which further raise the bar and make it more difficult for attackers to build precise packet structures to evade Anagram even if they know the distribution of the local site content flow. Finally, Anagram’s speed and high detection rate make it valuable not only as a standalone sensor but also as a network anomaly flow classifier in an instrumented fault-tolerant host-based environment; this enables significant cost amortization and the possibility of a “symbiotic” feedback loop that can improve accuracy and reduce false positive rates over time.

#### Introduction
Current generations of Network Intrusion Detection Systems (NIDS) are often ill-suited for stealthy worms and targeted attacks. Misuse and anomaly detectors that analyze packet headers and traffic flow statistics may be too slow to reliably detect worms designed to evade detection by shaping their behavior to look like legitimate traffic patterns [2]. Furthermore, signature scanners are vulnerable to zero-day exploits [3] and polymorphic worms/stealthy attacks with obfuscated exploit code [4]. Consequently, there has been an increasing focus on payload analysis to detect the early onset of a worm or targeted attack. Ideally, one would hope to detect the very first packets of an attack, rather than accumulating sufficient statistics about connection flows to detect a zero-day attack.

Several researchers (e.g., [5-8]) have focused on payload-based anomaly detection. Approaches that have been studied include specification-based anomaly detection [7] and techniques that aim to detect “code-like” byte sequences in network payloads [6, 9]. In our work, we have focused on automated statistical learning approaches to efficiently train content models on a site’s “normal” traffic flow without requiring significant semantic analysis. Ideally, we seek to design a sensor that automatically learns the characteristics of “normal” attack-free data for any application, service, network, or host. Consequently, a model learned for “normal” attack-free data may be used to identify “abnormal” or suspicious traffic that would be subjected to further analysis to validate whether the data embodies a new attack.

In our previous work, we proposed PAYL (short for “PAYLoad anomaly detection”), which modeled the “normal” attack-free traffic of a network site as 1-gram, byte-value frequency distributions [10], and demonstrated an ability to effectively detect worm behavior via ingress/egress and cross-site correlation [11]. The sensor was designed to be language-independent, requiring no syntactic analysis of the byte stream. Furthermore, PAYL was designed to be efficient and scalable for high-speed networks and applicable to any network service. Various experiments demonstrated that PAYL achieved a high detection rate and with low false positives for “typical” worms and exploits available at the time.

However, most researchers correctly suspected that PAYL’s simplicity would be easily blinded by mimicry attacks. Kolesnikov, Dagon, and Lee [1] demonstrated a new blended, polymorphic worm designed to evade detection by PAYL and other frequency distribution-based anomaly detectors. This demonstration represents a new class of “smart worms” that launch their attack by first sniffing traffic and shaping the datagram to the statistics specific to a given site to appear normal. The same principles may be applied to the propagation strategy as well as in, for example, parasitic worms. Since PAYL only models 1-gram distributions, it can be easily evaded with proper padding to avoid detection of anomalous byte sequences. As a countermeasure, we conjecture that higher-order n-gram modeling may likely detect these anomalous byte sequences. Unfortunately, computing a full frequency distribution for higher order n-grams is computationally and memory-wise infeasible and would require a prohibitively long training period even for modest gram sizes.

In this paper, we present a new sensor, Anagram, which introduces the use of Bloom filters and a binary-based detection model. Anagram does not compute frequency distributions of normal content flows; instead, it trains its model by storing all of the distinct n-grams observed during training in a Bloom filter without counting the occurrences of these n-grams. Anagram also stores n-grams extracted from known malicious packets in a second bad content Bloom filter, acquired by extracting n-grams from openly available worm detection rules, such as the latest Snort rulesets [12]. At detection time, packets are scored by the sensor on the basis of the number of unobserved n-grams the packet contains. The score is weighted by the number of malicious n-grams it contains as well. In this paper, we demonstrate that this semi-supervised strategy attains remarkably high detection and low false positive rates, in some cases 100% detection with less than 0.006% false positive rate (per packet).

The use of Bloom filters makes Anagram memory and computationally efficient and allows for the modeling of a mixture of different sizes of n-grams extracted from packet payloads, i.e., an Anagram model need not contain samples of a fixed-size gram. This strategy is demonstrated to exceed PAYL in both detection and false positive rates. Furthermore, Anagram’s modeling technique is easier to train and allows for the estimation of when the sensor has been trained enough for deployment. The Bloom filter model representation also provides the added benefit of preserving the privacy of shared content models and alerts for cross-site correlation.