### Zero-Day Vulnerabilities and the Honeymoon Period

**Zero-Day Vulnerabilities with No Honeymoon Period**

Less-than-zero-day vulnerabilities occur when a new version of a product is released with known, previously disclosed vulnerabilities. For instance, on the day Windows 7 was officially released, it was found to be vulnerable to several prominent viruses that were originally designed for Windows XP [35]. Our research indicates that less-than-zero-day vulnerabilities account for approximately 21% of all legacy vulnerabilities, with closed-source code being the most affected (34%) (see Table 4). In these cases, the median time to first exploitation is reduced by about one-third, and the median honeymoon ratio drops from 1.54 to 1.0. This suggests that failing to patch vulnerabilities significantly shortens the honeymoon period. While it is challenging to pinpoint exactly when an attacker will test an existing exploit against a newly released product, the tests conducted by Sophoslabs [35] provide a good indication of how quickly vendors can expect attackers to act.

### Related Work

As noted in the introduction, the scale of modern software systems and their deployment has made software design and engineering a focal point for scientists and engineers.

**Brooks' "The Mythical Man-Month"**

Frederick P. Brooks' "The Mythical Man-Month" [5] is a seminal reference for both the problems addressed by the software engineering discipline and its collected data (albeit from the 1960s) supporting its observations. Brooks focuses on software defects ("bugs") rather than security vulnerabilities, but his analyses of management issues in software engineering, particularly scheduling factors, remain relevant. For example, his discussion of "Regenerative Schedule Disaster" (Fig. 2.8) supports our observations about the time required to become familiar with a software system. Figure 11.2, "Bug occurrence as a function of release age," shows a decrease in bugs found, followed by a slow rise, illustrating the effects of increased familiarity with the system. Like many software engineering scholars, Brooks emphasizes the positive aspects of reusable software components without discussing potential risks from malicious actors.

**Software Reliability Models**

Software reliability analysis is crucial for commercial firms that must deliver reliable software promptly. Several models [21, 12, 27, 22] have been developed, focusing on bug rates and their implications for software maturity and releasability. However, these models, testing methods, and data collections do not address malicious actors.

**Vulnerability Life-Cycle Studies**

Arbaugh et al. [2] initiated the study of the specialized software vulnerability life-cycle, focusing on the intervals between the discovery of a vulnerability and the update to remove it. These works focused on the rate of exploitation, whereas this paper focuses on the rate of vulnerability discovery.

**Behavioral Hypotheses and Code Reuse**

Jonsson et al. [17] provided observations on a user population of students, with a quantitative evaluation of behavioral hypotheses. The most relevant finding for us is the ability to find bugs rapidly once the time investment in learning the software system is made.

Alhamzi et al. [1] studied Windows 98 and Windows NT 4.0 and proposed a three-phase S-shaped model (AIM) to describe the rate of cumulative vulnerabilities over time. Ozment's analysis [24] showed that the AIM model's predictive accuracy assumed a static code-base and was never tested against software spanning multiple versions. Our analysis supports an S-shaped curve model but finds that the three phases in the AIM model do not accurately describe our data. We are concerned with the first vulnerability found per version and the cumulative number of days between vulnerabilities, especially those closest to the product's release date.

**Recent Studies on Open Source Software**

Recent studies on large open source software systems [6, 25] analyzed vulnerability density across several versions and provided data and observations that support our hypothesis. First, since the software systems under study are open source (e.g., Linux and OpenBSD) and readily available, they can be learned by an attacker with sufficient time. Second, an analysis of persistent bugs across versions showed that such bugs often resulted from "cut and paste" software engineering, a crude yet effective form of reuse. Most existing vulnerability life-cycle and VDM research using the NVD dataset focused on a small number of operating systems or server applications, typically looking at only one version of each. Ozment and Schecter [25] found that 62% of the vulnerabilities in OpenBSD v.2.3-3.7 came from legacy code, concluding that the original version of the source code may constitute the bulk of the later version’s code base.

**Microsoft's Security Development Lifecycle (SDL)**

Microsoft's Security Development Lifecycle (SDL) claims to have reduced the number of vulnerabilities found in Windows Vista's first year compared to Windows XP, which did not use SDL (66 vs. 119, a 45% improvement). However, while Vista was in its first year, XP had been out for six years. This also supports our hypothesis, as XP had only 28 vulnerabilities in its first year, a 58% difference [23].

**Code Reuse and Security Challenges**

Code reuse continues to be considered an important part of secure and efficient software development in both open and closed products [13, 10, 4]. However, Coverity's analysis [3] of lessons learned from using their static code analysis tool provides possible explanations for the role of legacy code in the honeymoon effect. Developers often record current bugs without fixing them, prioritizing new bugs instead. This suggests that an attacker familiar with the legacy code carried over into a newly released version would have an advantage in finding new vulnerabilities, potentially shortening the honeymoon period.

**Risk of Exploitation in Open Source Products**

A recently published paper [28] used a Cox proportional model to analyze the risk of first exploitation attempts and concluded that the exploitation process is accelerated for open source products. However, the focus was on measuring the rate of exploitation attempts, not the rate of vulnerability discovery, making it less relevant to our paper.

### Discussion and Conclusions

The software lifecycle has been extensively examined to understand the dynamics of software production processes, particularly the arrival rate of faults and failures. These rates decrease over time as updates gradually repair errors until an acceptable error rate is achieved.

The software vulnerability lifecycle has received less attention, with most studies focusing on the period after an exploit has been discovered. To understand the properties of vulnerability discovery, we could either study a single software system in depth or examine a large set of software systems to find general properties. We chose the latter approach because it allowed us to incorporate both open and closed source systems, analyze different classes of software, and discover general vulnerability properties independent of the type of software.

We broke down each analysis by year and version-to-version to mitigate inconsistencies due to changes in tools, utilities, methodologies, and goals used by both attackers and defenders over the last decade. We also analyzed the role of legacy code in vulnerability discovery and found that software reuse may be a significant source of new vulnerabilities. The standard practice of reusing code offers unexpected security challenges, as mature software provides ample opportunity for attackers to turn vulnerabilities into exploits.

There are multiple potential causal mechanisms for the honeymoon effect, including:
1. A second vulnerability being similar to the first, making it easier to find.
2. Methodologies or tools developed for the first vulnerability lowering the effort required to find subsequent ones.
3. A discovered vulnerability signaling weakness to other attackers, causing them to focus more on that area.

The first two causes require familiarity with the system, while the third is an example of extrinsic properties affecting the length of the honeymoon period. Future work will examine these possible causes.

The period between when the error rate is low enough for release and when attacker familiarity becomes high enough for an initial zero-day vulnerability is called the honeymoon. This paper demonstrates that the dynamics of the honeymoon effect apply to the majority of popular software systems for which we had data.

The dynamics of the honeymoon effect suggest a trade-off between decreasing error rates and increasing attacker familiarity. This has important implications for the arms race between defenders and attackers. A new release can enjoy a substantial honeymoon period without discovered vulnerabilities once it is stable, independent of security practices. The honeymoon period appears to be a strong predictor of the approximate upper bound of the vulnerability arrival rate. Attacker familiarity is a key element of the software process dynamics, indicating a need for alternative approaches to security, such as automated diversity, redundant execution, and software design diversity, to extend the honeymoon period of newly released software or even give old software a second honeymoon.

### Acknowledgments

Professors Blaze and Smith's work was supported by the Office of Naval Research under N00014-07-1-907, Foundational and Systems Support for Quantitative Trust Management; Professor Smith received additional support from the Office of Naval Research under the Networks Opposing Botnets effort N00014-09-1-0770, and from the National Science Foundation under CCD-0810947, Blue Chip: Security Defenses for Misbehaving Hardware. Professor Blaze received additional support from the National Science Foundation under CNS-0905434 TC: Medium: Collaborative: Security Services in Open Telecommunications.

### References

[1] O.H. Alhamzi and Y.K. Malaiya. Modeling the vulnerability discovery process. In Proceedings of the 16th IEEE International Symposium on Software Reliability Engineering (ISSRE’05), Washington, DC, USA, 2005.

[2] William A. Arbaugh, William L. Fithen, and John McHugh. Windows of vulnerability: A case study analysis. Computer, 33(12):52–59, 2000.

[3] Al Bessey, Ken Block, Ben Chelf, Andy Chou, Bryan Fulton, Seth Hallem, Charles Henri-Gros, Asya Kamsky, Scott McPeak, and Dawson Engler. A few billion lines of code later: Using static analysis to find bugs in the real world. Communications of the ACM, 53(2):66–75, 2010.

[4] BlackDuck. Koders.com. http://corp.koders.com/about/, April 2010.

[5] Frederick P. Brooks. The Mythical Man-Month: Essays on Software Engineering, 20th Anniversary Edition. Addison-Wesley Professional, August 1995.

[6] A. Chou, J. Yang, B. Chelf, S. Hallem, and D. Engler. An empirical study of operating systems errors. In Proceedings, 18th ACM Symposium on Operating Systems Principles, pages 73–82, October 2001.

[7] Sandy Clark, Matt Blaze, and Jonathan Smith. Blood in the water: Are there honeymoon effects outside software? In In Proceedings of the 18th Cambridge International Security Protocols Workshop - pending publication. Springer, 2010.

[8] Benjamin Cox, David Evans, Adrian Filipi, Jonathan Rowanhill, Wei Hu, Jack Davidson, John Knight, Anh Nguyen-tuong, and Jason Hiser. N-variant systems: A secretless framework for security through diversity. In In Proceedings of the 15th USENIX Security Symposium, pages 105–120, 2006.

[9] CVE. Common vulnerabilities and exposures, 2008.

[10] Dr Dobbs Journal. Open Source Study Reveals High Level of Code Reuse. http://www.drdobbs.com/open-source/216401796, March 2009.

[11] Stefan Frei. Security Econometrics - The Dynamics of (In)Security. ETH Zurich, dissertation 18197, ETH Zurich, 2009. ISBN 1-4392-5409-5, ISBN-13: 9781439254097.

[12] A.L. Goel and K. Okumoto. A time dependent error detection model for software reliability and other performance measures. IEEE Transactions on Reliability, R-28:206–211, August 1979.

[13] Michael Howard and Steve Lipner. The Security Development Lifecycle. Microsoft Press, May 2006.

[14] IBM Internet Security Systems - X-Force. X-Force Advisory. http://www.iss.net.

[15] iDefense. Vulnerability Contributor Program. http://labs.idefense.com/vcp.

[16] Pankaj Jalote, Brendan Murphy, and Vibhu Saujanya Sharma. Post-release reliability growth in software products. ACM Trans. Softw. Eng. Methodol., 17(4):1–20, 2008.

[17] Erland Jonsson and Tomas Olovsson. A quantitative model of the security intrusion process based on attacker behavior. IEEE Trans. Softw. Eng., 23(4):235–245, 1997.

[18] M.C. McIlroy. Mass-produced software components. Report to Scientific Affairs Division, NATO, October 1968.

[19] Microsoft. Internet Explorer Architecture. http://msdn.microsoft.com/en-us/library/aa741312(VS.85).aspx, 2010.

[20] Microsoft Corporation. Security Development Lifecycle. http://www.microsoft.com/security/sdl/benefits/measurable.aspx, September 2008.

[21] John D. Musa. A theory of software reliability and its application. IEEE Transactions on Security Engineering, SE-1:312–327, September 1975.

[22] John D. Musa, Anthony Iannino, and Kasuhira Okumoto. Software Reliability: Measurement, Prediction, Application. McGraw-Hill, 1987.

[23] NIST. National Vulnerability Database, 2008.

[24] Andy Ozment. Improving vulnerability discovery models. In QoP ’07: Proceedings of the 2007 ACM workshop on Quality of protection, pages 6–11, New York, NY, USA, 2007. ACM.

[25] Andy Ozment and Stuart E. Schechter. Milk or wine: Does software security improve with age? In USENIX-SS’06: Proceedings of the 15th conference on USENIX Security Symposium, Berkeley, CA, USA, 2006. USENIX Association.

[26] R.E. Prather. Theory of program testing - an overview. Bell System Technical Journal, 72(10):3073–3105, December 1983.

[27] C.V. Ramamoorthy and F.B. Bastani. Software reliability - status and perspectives. IEEE Transactions on Software Engineering, SE-8(4):354–371, July 1982.

[28] Sam Ransbotham. An Empirical Analysis of Exploitation Attempts Based on Vulnerabilities in Open Source Software. In Workshop on the Economics of Information Security (WEIS), June 2010.

[29] Secunia. http://www.secunia.com. Vulnerability Intelligence Provider.

[30] Security Focus. Vulnerabilities Database, 2008.

[31] SecurityTracker. http://www.SecurityTracker.com. SecurityTracker.

[32] TippingPoint. Zero Day Initiative (ZDI). http://www.zerodayinitiative.com/.

[33] US-CERT. Vulnerability Statistics. http://www.cert.org/stats/vulnerability_remediation.html.

[34] Vupen. Vupen Security. http://www.vupen.com.

[35] Chester Wisniewski. Windows 7 vulnerable to 8 out of 10 viruses, 2009. http://www.sophos.com/blogs/chetw/g/2009/11/03/windows-7-vulnerable-8-10-viruses/.