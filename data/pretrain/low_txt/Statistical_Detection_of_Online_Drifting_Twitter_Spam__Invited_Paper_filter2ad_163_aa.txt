# Statistical Detection of Online Drifting Twitter Spam: Invited Paper

## Authors
- Shigang Liu
- Jun Zhang
- Yang Xiang

### Affiliations
**Deakin University**
- School of Information Technology
- 221 Burwood Hwy, Burwood, Vic 3125, Australia
- Email: [PI:EMAIL]

## Abstract
Spam is a critical problem in online social networks, and this paper focuses on the detection of Twitter spam. Recent research has applied machine learning techniques to detect Twitter spam using statistical features of tweets. However, these methods suffer from the issue of Twitter spam drift, where the statistical properties of spam tweets change over time. To address this, one effective solution is to train a new Twitter spam classifier daily. This approach, however, faces the challenge of limited and imbalanced training data due to the time-consuming nature of labeling spam samples.

This paper proposes a novel method to tackle this challenge by employing two new techniques: fuzzy-based redistribution and asymmetric sampling. The fuzzy-based information decomposition technique redistributes the spam class and generates more spam samples, while the asymmetric sampling technique rebalances the sizes of spam and non-spam samples in the training data. Finally, an ensemble technique is used to combine classifiers trained on different datasets. Experiments on a real-world 10-day ground-truth dataset show that the proposed method significantly improves the detection performance for drifting Twitter spam.

**Keywords**: Twitter spam detection, social network security, security data analytics

## 1. Introduction
Spam detection is a continuous battle between spammers and security companies. Spammers attempt to mask themselves as legitimate users, while security companies strive to stop them. Twitter, founded in 2006, is one of the fastest-growing social networks, with over 400 million new tweets generated daily by more than 200 million users. Unfortunately, spammers use Twitter to post unsolicited messages containing malicious links and hijack trending topics, contributing to the exponential growth of online spamming activities. Studies indicate that more than 3% of messages are likely to be spam [1].

To combat this, Twitter and security companies have implemented various measures, such as the "report as spam" feature and the BotMaker detection system, which includes blacklist filtering. However, blacklists often fail to protect users from new spam due to the time lag in updating them. Over 90% of victims may visit a new spam link before it is blocked [2]. To address these limitations, researchers have proposed machine learning-based methods that treat spam detection as a binary classification problem, using statistical features like account age, number of followers, and tweet length [6].

Despite these efforts, we observe a significant problem: "Twitter spam drift," where the statistical properties of spam tweets vary over time, degrading the performance of existing machine learning models. For example, Figures 1 and 2 illustrate the changes in the number of characters and account ages of spam tweets over 10 days. To address this, an effective solution is to train a new spam classifier daily. However, this approach faces the challenge of small and imbalanced training data, as labeling spam samples is time-consuming.

In this work, we propose a new detection method that addresses the problem of Twitter spam drift. Our contributions include:
- A new detection method that learns from a small, imbalanced training dataset using fuzzy-based redistribution and asymmetric sampling.
- A fuzzy-based redistribution technique that generates more spam samples consistent with the spam class distribution.
- An asymmetric sampling technique that rebalances the sizes of spam and non-spam samples in the training data.
- An ensemble technique to combine classifiers trained on different datasets.

Experiments on a real-world 10-day ground-truth dataset demonstrate that our method significantly improves the detection performance for drifting Twitter spam. The rest of the paper is organized as follows: Section 2 reviews related work, Section 3 describes our new spam detection method, Section 4 reports the experiments and results, and Section 5 concludes the work.

## 2. Related Work
Recent research has applied various machine learning techniques to Twitter spam detection [1, 11, 12]. Early studies focused on understanding the nature of Twitter spam. For instance, a 2009 study found that 3.75% of tweets were spam [13], while Grier et al. (2010) reported that 8% of unique URLs in tweets were spam [5]. Thomas et al. (2011) found that 80 million out of 1.8 billion tweets were spam [14]. Najada and Zhu analyzed spam detection with 20% spam samples, and Chao et al. (2011) found that about 1% of URLs in 600 million tweets were spam [11].

Blacklist-based methods, such as Trend Micro's Web Reputation Technology, are commonly used but suffer from time lags in updating [15]. Heuristic rule-based methods, like Yardi et al.'s #robotpickupline hashtag and Kwak et al.'s hashtag removal, have also been explored [16, 17]. However, these basic features can be easily fabricated by spammers.

To overcome these limitations, researchers have proposed robust features based on social graphs. Song et al. (2010) improved classifier performance to nearly 99% True Positive and less than 1% False Positive by merging sophisticated features with basic ones [22]. Yang et al. (2011) introduced robust features like Local Clustering Coefficient, Betweenness Centrality, and Bidirectional Links Ratio, achieving outstanding performance [23].

More recent studies have applied machine learning techniques using a range of features, including tweet-based, author-based, and social graph attributes. Hamzah and Xingquan (2011) used URL-based features, while Chao et al. (2011) collected spam-relevant features like URL, redirect chain length, and relative number of different initial URLs [25]. Wang et al. (2011) introduced a Bayesian model, and Benevenuto et al. (2010) used Support Vector Machines [12]. Stringhini et al. (2010) trained a Random Forest classifier for multiple social networks, and Lee et al. (2011) deployed honeypots to derive spammers' profiles [18, 19].

Our previous work observed that Twitter spams drift over time, affecting the performance of existing machine learning methods. Training a new classifier daily is an effective solution, but it faces the challenge of small, imbalanced training data. This motivates our current work.

## 3. Proposed Method
This section presents our new detection method, which employs fuzzy-based redistribution, asymmetric sampling, and an ensemble technique.

### 3.1 New Detection Framework
We treat the detection of drifted spam tweets as a specific learning problem with a small, imbalanced training dataset. Figure 3 illustrates our new framework. First, we apply a fuzzy-based redistribution technique to extend the original training dataset by creating synthetic spam samples. Next, we perform asymmetric sampling on the two training datasets to balance the size of spam and non-spam samples. Ensemble training is then used to construct a set of classifiers from each training dataset, and the classifiers are combined to detect spam in the testing tweets.

### 3.2 Fuzzy-Based Redistribution
To alleviate the imbalance between spam and non-spam classes, we develop a new fuzzy-based redistribution algorithm. This technique uses information decomposition to generate reliable synthetic spam samples. Given a set of labeled spam and non-spam tweets, S+ and Sâˆ’, we partition the feature vector into small intervals, calculate weights, and generate synthetic values. The algorithm is detailed in Algorithm 1.

### 3.3 Asymmetric Sampling
Asymmetric sampling is used to rebalance the sizes of spam and non-spam samples. We apply over-sampling to spam training tweets and under-sampling to non-spam training tweets. The process is described in Algorithm 2.

### 3.4 Ensemble Training
Ensemble training combines the classifiers trained on the balanced datasets. This technique helps to improve the overall detection performance by leveraging the strengths of multiple classifiers.

## 4. Experiments and Results
We conducted experiments on a real-world 10-day ground-truth dataset to evaluate our method. The results show that our method significantly improves the detection performance for drifting Twitter spam. Detailed experimental setups and results are presented in this section.

## 5. Conclusion
In this paper, we proposed a new method to address the problem of Twitter spam drift. Our method uses fuzzy-based redistribution and asymmetric sampling to handle the challenges of small and imbalanced training data. Experiments on a real-world dataset demonstrate the effectiveness of our approach. Future work will focus on further improving the detection performance and adapting to new types of spam.

## References
[1] Reference 1
[2] Reference 2
[3] Reference 3
[4] Reference 4
[5] Reference 5
[6] Reference 6
[7] Reference 7
[8] Reference 8
[9] Reference 9
[10] Reference 10
[11] Reference 11
[12] Reference 12
[13] Reference 13
[14] Reference 14
[15] Reference 15
[16] Reference 16
[17] Reference 17
[18] Reference 18
[19] Reference 19
[20] Reference 20
[21] Reference 21
[22] Reference 22
[23] Reference 23
[24] Reference 24
[25] Reference 25
[26] Reference 26