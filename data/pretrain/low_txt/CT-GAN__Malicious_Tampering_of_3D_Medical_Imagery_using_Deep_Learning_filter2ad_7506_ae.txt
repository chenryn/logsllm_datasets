### Introduction to Image Tampering in Medical Imaging

The manipulation of medical images, particularly through the use of malware, can occur due to several constraints. For instance, a radiologist may perform a diagnosis immediately after an image is taken, or the malware could be embedded in the viewing application and operate in real-time. Additionally, many Picture Archiving and Communication Systems (PACS) do not have direct internet connections, necessitating the use of malware that can autonomously tamper with images.

For cancer injection, simpler automated methods, such as pasting a pre-saved cropped image of cancer into a scan, could be used. However, to validate the use of Generative Adversarial Networks (GANs), we evaluated this splice attack as a baseline comparison.

### Experimental Setup

To create our set of "pre-saved cancers," we carefully extracted ten 32x32x32 cubes of real cancerous nodules from [54]. We then removed irrelevant background tissue by generating transparency (alpha) channels using Equation (1).

The evaluation dataset consisted of 20 scans: 10 faked (FM) and 10 true (TM). To create a FM scan, we selected a random healthy scan and used steps 1 and 2 from Figure 8 to determine a candidate injection location. We then pasted one of the pre-saved cancers into the scan at that location using the transparency channel. For the TM scans, we randomly selected 10 sick patients, each with exactly one nodule.

### Baseline Attack Evaluation

We asked Radiologist R2 to analyze the 20 scans and determine which were authentic (TM) and which were tampered (FM). This task took approximately two hours to complete.

In summary, R2 correctly identified all the tampered scans but mislabeled three authentic scans as fake. These results indicate that the baseline cancer injection attack cannot effectively deceive a radiologist, unlike CT-GAN, which succeeds nearly every time. The failure of the baseline attack is attributed to the obvious artifacts created by automatically pasting cancer, such as cut bronchi, inconsistent noise patterns, and unaligned borders. CT-GAN avoids these artifacts by using in-painting, which considers the original content and surrounding anatomy.

### Countermeasures

The tampering of DICOM medical files is a well-known concern. Here, we provide an overview of solutions for preventing and detecting such attacks.

#### Prevention

To mitigate this threat, administrators should secure both data-in-motion (DiM) and data-at-rest (DaR). For DiM, encryption between hosts in the PACS network should be enabled using proper SSL certificates. For DaR, servers and anti-virus software on modality and radiologist workstations should be kept up to date, and exposure to the internet should be limited.

#### Detection

The best method for detecting this attack is to have the scanner sign each scan with a digital signature. The DICOM standard already supports storing signatures within the file's data structure. Another method is digital watermarking (DW), which embeds a hidden signal into an image to indicate integrity loss upon tampering. Machine learning techniques can also be used to detect tampered images, especially in supervised settings where models are trained on examples of tampered images.

### Conclusion

This paper introduces the possibility of an attacker modifying 3D medical imagery using deep learning. We discussed the motivations, attack vectors, and presented a manipulation framework (CT-GAN) that can be executed by malware. Our case study demonstrated how an attacker can inject or remove lung cancer from full-resolution 3D CT scans. We found that CT-GAN can fool both radiologists and state-of-the-art AI. This highlights the need to be wary of closed-world assumptions and the importance of robust countermeasures to prevent and detect such attacks.

### References

[1] P. I, W. LR, et al. Health care spending in the United States and other high-income countries. JAMA, 319(10):1024–1039, 2018.
[2] J. R. Haaga. CT and MRI of the Whole Body. No. v. 1 in CT and MRI of the Whole Body. Mosby/Elsevier, 2008. ISBN 9780323053754.
[3] H. I. News. The biggest healthcare data breaches of 2018 (so far). https://www.healthcareitnews.com/projects/biggest-healthcare-data-breaches-2018-so-far, 2019.
[4] T. George. Feeling the pulse of cybersecurity in healthcare, securityweek.com. https://www.securityweek.com/feeling-pulse-cyber-security-healthcare, 2018.
[5] I. Institute. Cybersecurity in the healthcare industry. https://resources.infosecinstitute.com/cybersecurity-in-the-healthcare-industry, 2016.
[6] L. Coventry and D. Branley. Cybersecurity in healthcare: A narrative review of trends, threats and ways forward. Maturitas, 113:48 – 52, 2018. ISSN 0378-5122.
[7] M. S. Jalali and J. P. Kaiser. Cybersecurity in hospitals: A systematic, organizational perspective. Journal of medical Internet research, 20(5), 2018.
[8] C. Beek. McAfee researchers find poor security exposes medical data to cybercriminals, McAfee blogs. https://securingtomorrow.mcafee.com/other-blogs/mcafee-labs/mcafee-researchers-find-poor-security-exposes-medical-data-to-cybercriminals/, 2018.
[9] H. Huang. PACS-Based Multimedia Imaging Informatics: Basic Principles and Applications. Wiley, 2019. ISBN 9781118795736.
[10] Verizon. Protected health information data breach report. White paper, 2018.
[11] F. Bray, J. Ferlay, et al. Global cancer statistics 2018: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries. CA: A Cancer Journal for Clinicians, 68(6):394–424, 2018.
[12] X. Wu, K. Xu, et al. A survey of image synthesis and editing with generative adversarial networks. Tsinghua Science and Technology, 22(6):660–674, 2017.
[13] I. Goodfellow, J. Pouget-Abadie, et al. Generative adversarial nets. In Advances in Neural Information Processing Systems, pp. 2672–2680, 2014.
[14] W. Hu and Y. Tan. Generating adversarial malware examples for black-box attacks based on GAN. arXiv preprint arXiv:1702.05983, 2017.
[15] M. Rigaki and S. Garcia. Bringing a GAN to a knife-fight: Adapting malware communication to avoid detection. In 2018 IEEE Security and Privacy Workshops (SPW), pp. 70–75. IEEE, 2018.
[16] R. Chesney and D. K. Citron. Deep fakes: A looming challenge for privacy, democracy, and national security. U of Texas Law, Public Law Research Paper No. 692; U of Maryland Legal Studies Research Paper No. 2018-21, 2018.
[17] P. Isola, J.-Y. Zhu, et al. Image-to-image translation with conditional adversarial networks. arXiv preprint, 2017.
[18] T. Seals. RSA Conference 2019: Ultrasound hacked in https://threatpost.com/