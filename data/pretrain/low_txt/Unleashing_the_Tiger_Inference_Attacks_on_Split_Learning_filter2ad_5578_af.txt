### References

1. **Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. 2020. How To Backdoor Federated Learning.** In *Proceedings of the Twenty-Third International Conference on Artificial Intelligence and Statistics (AISTATS)*, Silvia Chiappa and Roberto Calandra (Eds.), Vol. 108. PMLR, Online, 2938–2948. [Link](http://proceedings.mlr.press/v108/bagdasaryan20a.html)

2. **Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo. 2019. Analyzing Federated Learning through an Adversarial Lens.** In *Proceedings of Machine Learning Research*, Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.), Vol. 97. PMLR, Long Beach, California, USA, 634–643. [Link](http://proceedings.mlr.press/v97/bhagoji19a.html)

3. **K. A. Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloé M Kiddon, Jakub Konečný, Stefano Mazzocchi, Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel Ramage, and Jason Roselander. 2019. Towards Federated Learning at Scale: System Design.** In *SysML 2019*. [Link](https://arxiv.org/abs/1902.01046)

4. **Brendan McMahan, Ramesh Raskar, Otkrist Gupta, Praneeth Vepakomma, Hassan Takabi, Jakub Konečný. 2019. CVPR Tutorial On Distributed Private Machine Learning for Computer Vision: Federated Learning, Split Learning and Beyond.** [Link](https://nopeekcvpr.github.io) (2019).

5. **Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.** arXiv:cs.CL/2005.14165 (2020). [Link](https://arxiv.org/abs/2005.14165)

6. **Adrian Bulat and Georgios Tzimiropoulos. 2017. How Far Are We from Solving the 2D & 3D Face Alignment Problem? (and a Dataset of 230,000 3D Facial Landmarks).** In *International Conference on Computer Vision*.

7. **Iker Ceballos, Vivek Sharma, Eduardo Mugica, Abhishek Singh, Alberto Roman, Praneeth Vepakomma, and Ramesh Raskar. 2020. SplitNN-driven Vertical Partitioning.** arXiv:cs.LG/2008.04137 (2020). [Link](https://arxiv.org/abs/2008.04137)

8. **Adam Coates, Andrew Ng, and Honglak Lee. 2011. An Analysis of Single-Layer Networks in Unsupervised Feature Learning.** In *Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS)*, Geoffrey Gordon, David Dunson, and Miroslav Dudík (Eds.), Vol. 15. PMLR, Fort Lauderdale, FL, USA, 215–223. [Link](http://proceedings.mlr.press/v15/coates11a.html)

9. **Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Gong. 2020. Local Model Poisoning Attacks to Byzantine-Robust Federated Learning.** In *29th USENIX Security Symposium (USENIX Security 20)*. USENIX Association, 1605–1622. [Link](https://www.usenix.org/conference/usenixsecurity20/presentation/fang)

10. **Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. 2015. Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures.** In *Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (CCS '15)*. Association for Computing Machinery, New York, NY, USA, 1322–1333. [Link](https://doi.org/10.1145/2810103.2813677)

11. **David Froelicher, Juan R. Troncoso-Pastoriza, Apostolos Pyrgelis, Sinem Sav, Joao Sa Sousa, Jean-Philippe Bossuat, and Jean-Pierre Hubaux. 2020. Scalable Privacy-Preserving Distributed Learning.** arXiv:cs.CR/2005.09532 (2020). [Link](https://arxiv.org/abs/2005.09532)

12. **Clement Fung, Chris J. M. Yoon, and Ivan Beschastnikh. 2020. The Limitations of Federated Learning in Sybil Settings.** In *23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)*. USENIX Association, San Sebastian, 301–316. [Link](https://www.usenix.org/conference/raid2020/presentation/fung)

13. **Karan Ganju, Qi Wang, Wei Yang, Carl A. Gunter, and Nikita Borisov. 2018. Property Inference Attacks on Fully Connected Neural Networks Using Permutation Invariant Representations.** In *Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (CCS '18)*. Association for Computing Machinery, New York, NY, USA, 619–633. [Link](https://doi.org/10.1145/3243734.3243834)

14. **Y. Gao, M. Kim, S. Abuadbba, Y. Kim, C. Thapa, K. Kim, S. A. Camtep, H. Kim, and S. Nepal. 2020. End-to-End Evaluation of Federated Learning and Split Learning for Internet of Things.** In *2020 International Symposium on Reliable Distributed Systems (SRDS)*. 91–100. [Link](https://doi.org/10.1109/SRDS51746.2020.00017)

15. **Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial Nets.** In *Advances in Neural Information Processing Systems (NeurIPS)*, Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger (Eds.), Vol. 27. Curran Associates, Inc., 2672–2680.

16. **Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C. Courville. 2017. Improved Training of Wasserstein GANs.** In *Advances in Neural Information Processing Systems (NeurIPS)*, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc., 5767–5777.

17. **Otkrist Gupta and Ramesh Raskar. 2018. Distributed Learning of Deep Neural Network over Multiple Agents.** *Journal of Network and Computer Applications* 116 (2018), 1–8. [Link](https://doi.org/10.1016/j.jnca.2018.05.003)

18. **David Gutman, Noel C. F. Codella, M. Emre Celebi, Brian Helba, Michael A. Marchetti, Nabin K. Mishra, and Allan Halpern. 2016. Skin Lesion Analysis toward Melanoma Detection: A Challenge at the International Symposium on Biomedical Imaging (ISBI) 2016, hosted by the International Skin Imaging Collaboration (ISIC).** arXiv:1605.01397 (2016). [Link](http://arxiv.org/abs/1605.01397)

19. **M. Hao, H. Li, X. Luo, G. Xu, H. Yang, and S. Liu. 2020. Efficient and Privacy-Enhanced Federated Learning for Industrial Artificial Intelligence.** *IEEE Transactions on Industrial Informatics* 16, 10 (2020), 6532–6542. [Link](https://doi.org/10.1109/TII.2019.2945367)

20. **K. He, X. Zhang, S. Ren, and J. Sun. 2016. Deep Residual Learning for Image Recognition.** In *2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*. 770–778. [Link](https://doi.org/10.1109/CVPR.2016.90)

21. **Zecheng He, Tianwei Zhang, and Ruby B. Lee. 2019. Model Inversion Attacks against Collaborative Inference.** In *Proceedings of the 35th Annual Computer Security Applications Conference (ACSAC '19)*. Association for Computing Machinery, New York, NY, USA, 148–162. [Link](https://doi.org/10.1145/3359789.3359824)

22. **Briland Hitaj, Giuseppe Ateniese, and Fernando Perez-Cruz. 2017. Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning.** In *Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS '17)*. Association for Computing Machinery, New York, NY, USA, 603–618. [Link](https://doi.org/10.1145/3133956.3134012)

23. **J. Jeon and J. Kim. 2020. Privacy-Sensitive Parallel Split Learning.** In *2020 International Conference on Information Networking (ICOIN)*. 7–9. [Link](https://doi.org/10.1109/ICOIN48656.2020.9016486)

24. **J. Kang, Z. Xiong, D. Niyato, S. Xie, and J. Zhang. 2019. Incentive Mechanism for Reliable Federated Learning: A Joint Optimization Approach to Combining Reputation and Contract Theory.** *IEEE Internet of Things Journal* 6, 6 (2019), 10700–10714. [Link](https://doi.org/10.1109/JIOT.2019.2940820)

25. **J. Kim, Sungho Shin, Yeonguk Yu, Junseok Lee, and Kyoobin Lee. 2020. Multiple Classification with Split Learning.** arXiv:2008.09874 (2020). [Link](https://arxiv.org/abs/2008.09874)

26. **Yusuke Koda, Jihong Park, Mehdi Bennis, Koji Yamamoto, Takayuki Nishio, and Masahiro Morikura. 2019. One Pixel Image and RF Signal Based Split Learning for MmWave Received Power Prediction.** In *CoNEXT '19 Companion*. Association for Computing Machinery, New York, NY, USA, 54–56. [Link](https://doi.org/10.1145/3360468.3368176)

27. **Jakub Konečný, H. Brendan McMahan, Daniel Ramage, and Peter Richtárik. 2016. Federated Optimization: Distributed Machine Learning for On-Device Intelligence.** arXiv:cs.LG/1610.02527 (2016). [Link](https://arxiv.org/abs/1610.02527)

28. **Jakub Konečný, H. Brendan McMahan, Felix X. Yu, Peter Richtárik, Ananda Theertha Suresh, and Dave Bacon. 2017. Federated Learning: Strategies for Improving Communication Efficiency.** arXiv:cs.LG/1610.05492 (2017). [Link](https://arxiv.org/abs/1610.05492)

29. **Brenden M. Lake, Ruslan Salakhutdinov, and Joshua B. Tenenbaum. 2015. Human-level concept learning through probabilistic program induction.** *Science* 350, 6266 (2015), 1332–1338. [Link](https://doi.org/10.1126/science.aab3050)

30. **M. Langer, Z. He, W. Rahayu, and Y. Xue. 2020. Distributed Training of Deep Learning Models: A Taxonomic Perspective.** *IEEE Transactions on Parallel and Distributed Systems* 31, 12 (2020), 2802–2818. [Link](https://doi.org/10.1109/TPDS.2020.3003307)

31. **Wei Yang Bryan Lim, Jer Shyuan Ng, Zehui Xiong, Dusit Niyato, Cyril Leung, Chunyan Miao, and Qiang Yang. 2020. Incentive Mechanism Design for Resource Sharing in Collaborative Edge Learning.** arXiv:cs.NI/2006.00511 (2020). [Link](https://arxiv.org/abs/2006.00511)

32. **Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. 2015. Deep Learning Face Attributes in the Wild.** In *Proceedings of the International Conference on Computer Vision (ICCV)*.

33. **Kamalesh Palanisamy, Vivek Khimani, Moin Hussain Moti, and D. Chatzopoulos. 2020. SplitEasy: A Practical Approach for Training ML models on Mobile Devices in a Split Second.** arXiv:2011.04232 (2020). [Link](https://arxiv.org/abs/2011.04232)

34. **Maarten G. Poirot, Praneeth Vepakomma, Ken Chang, Jayashree Kalpathy-Cramer, Rajiv Gupta, and Ramesh Raskar. 2019. Split Learning for Collaborative Deep Learning in Healthcare.** arXiv:cs.LG/1912.12115 (2019). [Link](https://arxiv.org/abs/1912.12115)

35. **Alec Radford, Luke Metz, and Soumith Chintala. 2016. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.** In *4th International Conference on Learning Representations (ICLR 2016)*, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings, Yoshua Bengio and Yann LeCun (Eds.). [Link](http://arxiv.org/abs/1511.06434)

36. **Daniele Romanini, Adam James Hall, Pavlos Papadopoulos, Tom Titcombe, Abbas Ismail, Tudor Cebere, Robert Sandmann, Robin Roehm, and Michael A. Hoeh. 2021. PyVertical: A Vertical Federated Learning Framework for Multi-headed SplitNN.** In *ICLR 2021 Workshop on Distributed and Private Machine Learning*.

37. **F. Sattler, S. Wiedemann, K. R. Müller, and W. Samek. 2020. Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data.** *IEEE Transactions on Neural Networks and Learning Systems* 31, 9 (2020), 3400–3413. [Link](https://doi.org/10.1109/TNNLS.2019.2944481)

38. **Vivek Sharma, Praneeth Vepakomma, Tristan Swedish, Ken Chang, Jayashree Kalpathy-Cramer, and Ramesh Raskar. 2019. ExpertMatcher: Automating ML Model Selection for Clients using Hidden Representations.** arXiv:cs.CV/1910.03731 (2019). [Link](https://arxiv.org/abs/1910.03731)

39. **Reza Shokri and Vitaly Shmatikov. 2015. Privacy-Preserving Deep Learning.** In *Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (CCS '15)*. Association for Computing Machinery, New York, NY, USA, 1310–1321. [Link](https://doi.org/10.1145/2810103.2813687)

40. **R. Shokri, M. Stronati, C. Song, and V. Shmatikov. 2017. Membership Inference Attacks Against Machine Learning Models.** In *2017 IEEE Symposium on Security and Privacy (SP)*. 3–18. [Link](https://doi.org/10.1109/SP.2017.41)

41. **Abhishek Singh, Praneeth Vepakomma, Otkrist Gupta, and Ramesh Raskar. 2019. Detailed Comparison of Communication Efficiency of Split Learning and Federated Learning.** arXiv:cs.LG/1909.09145 (2019). [Link](https://arxiv.org/abs/1909.09145)

42. **Gabor Szekely, Maria Rizzo, and Nail Bakirov. 2008. Measuring and Testing Dependence by Correlation of Distances.** *The Annals of Statistics* 35 (04 2008). [Link](https://doi.org/10.1214/009053607000000505)

43. **Chandra Thapa, M. A. P. Chamikara, and Seyit Camtepe. 2020. SplitFed: When Federated Learning Meets Split Learning.** arXiv:cs.LG/2004.12088 (2020). [Link](https://arxiv.org/abs/2004.12088)

44. **Chandra Thapa, M. A. P. Chamikara, and Seyit A. Camtepe. 2020. Advancements of Federated Learning towards Privacy Preservation: From Federated Learning to Split Learning.** arXiv:cs.LG/2011.14818 (2020). [Link](https://arxiv.org/abs/2011.14818)

45. **Philipp Tschandl, Cliff Rosendahl, and Harald Kittler. 2018. The HAM10000 Dataset, a Large Collection of Multi-Source Dermoscopic Images of Common Pigmented Skin Lesions.** *Scientific Data* 5, 1 (2018), 180161. [Link](https://doi.org/10.1038/sdata.2018.161)

46. **Valeria Turina, Zongshun Zhang, Flavio Esposito, and Ibrahim Matta. 2020. Combining Split and Federated Architectures for Efficiency and Privacy in Deep Learning.** In *Proceedings of the 16th International Conference on Emerging Networking EXperiments and Technologies (CoNEXT '20)*. Association for Computing Machinery, New York, NY, USA, 562–563. [Link](https://doi.org/10.1145/3386367.3431678)

47. **Praneeth Vepakomma, Otkrist Gupta, Abhimanyu Dubey, and Ramesh Raskar. 2019. Reducing Leakage in Distributed Deep Learning for Sensitive Health Data.** (05 2019). [Link](https://arxiv.org/abs/1905.00933)

48. **Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, and Ramesh Raskar. 2018. Split Learning for Health: Distributed Deep Learning without Sharing Raw Patient Data.** arXiv:cs.LG/1812.00564 (2018). [Link](https://arxiv.org/abs/1812.00564)

49. **Praneeth Vepakomma, Tristan Swedish, Ramesh Raskar, Otkrist Gupta, and Abhimanyu Dubey. 2018. No Peek: A Survey of Private Distributed Deep Learning.** arXiv:cs.LG/1812.03288 (2018). [Link](https://arxiv.org/abs/1812.03288)

50. **C. Wang, X. Wei, and P. Zhou. 2020. Optimize Scheduling of Federated Learning on Battery-powered Mobile Devices.** In *2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)*. 212–221. [Link](https://doi.org/10.1109/IPDPS47924.2020.00031)

51. **Jiayu Wu, Qixiang Zhang, and Guoxi Xu. 2020. Tiny ImageNet Challenge.** [Link](http://cs231n.stanford.edu/reports/2017/pdfs/930.pdf) (2020).

52. **Han Xiao, Kashif Rasul, and Roland Vollgraf. 2017. Fashion-MNIST: A Novel Image Dataset for Benchmarking Machine Learning Algorithms.** arXiv:cs.LG/1708.07747 (2017). [Link](https://arxiv.org/abs/1708.07747)

53. **Song Yang Zhang, Zhifei, and Hairong Qi. 2017. Age Progression/Regression by Conditional Adversarial Autoencoder.** In *IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*. IEEE.

54. **Y. Zhang, R. Jia, H. Pei, W. Wang, B. Li, and D. Song. 2020. The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural Networks.** In *2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*. 250–258. [Link](https://doi.org/10.1109/CVPR42600.2020.00033)

55. **Ligeng Zhu, Zhijian Liu, and Song Han. 2019. Deep Leakage from Gradients.** In *Advances in Neural Information Processing Systems (NeurIPS)*, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett (Eds.), Vol. 32. Curran Associates, Inc. [Link](https://proceedings.neurips.cc/paper/2019/file/60a6c4002cc7b29142def8871531281a-Paper.pdf)

### Appendices

#### A. Additional Results

In this section, we include and discuss additional results.

##### A.1 On the Effect of the Public Dataset

Extending the results presented in Section 3.4.1, we test the FSHA on other datasets.

**Natural Images:**
- **TinyImageNet**: A subset of ImageNet containing only 200 classes of natural images.
- **STL-10**: Defined over the natural domain, consisting of 10 different classes (six animals and four vehicles). Note that, given the size of TinyImageNet, the 10 classes of STL-10 can be considered a subset of the 200 classes of TinyImageNet. However, there is no intersection between the images of the two sets.

We test the ability of FSHA to reconstruct instances of TinyImageNet (\(X_{priv}\)) by using STL-10 as \(X_{pub}\). This attack is particularly challenging due to the strong discrepancy between the public and private distributions. There are around 190 unknown semantic classes of data (i.e., 95% of the private distribution) that the attacker has never observed. Nevertheless, as shown in Figure A.1, besides altered colors and missing details, the attack converges towards suitable reconstructions of the private instances of the TinyImageNet set, threatening clients’ privacy even in this difficult setup. This result suggests that the FSHA can generalize over the adopted public set and provide a representative feature space that captures unknown clients’ private instances.

**Medical Images:**
- **HAM10000**: An extensive collection of multi-source dermatoscopic images of common pigmented skin lesions, containing 10015 images collected from different populations and acquired by different modalities.
- **ISIC-2016**: Similar to HAM10000, it collects dermatoscopic lesion images.

We report additional examples using dermoscopic lesion image datasets such as HAM10000 and ISIC-2016. As shown in Figure A.2, the FSHA can also reconstruct instances from the HAM10000 dataset using the ISIC-2016 dataset as \(X_{pub}\), further demonstrating its effectiveness in capturing and reconstructing private data.

**Figures:**
- **Figure A.1**: Random examples of inference of private training instances on the TinyImageNet dataset. The first row (gray frame) reports the original data, the second row (red frame) depicts the attacker’s reconstruction using \(X_{pub} = \text{TinyImageNet (test)}\), and the third row (blue frame) depicts the attacker’s reconstruction using \(X_{pub} = \text{STL-10}\). We run the attacks for \(2 \times 10^3\).
- **Figure A.2**: Random examples of inference of private training instances on the HAM10000 dataset. The first row (gray frame) reports the original data, the second row (red frame) depicts the attacker’s reconstruction using \(X_{pub} = \text{HAM10000 (test)}\), and the third row (blue frame) depicts the attacker’s reconstruction using \(X_{pub} = \text{ISIC-2016}\). We run the attacks for \(2 \times 10^3\).