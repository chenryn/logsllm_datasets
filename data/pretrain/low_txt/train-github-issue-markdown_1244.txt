## Bug Report

### Issue Description
When using PyTorch 1.3 C++ distribution in Visual Studio 2017 and following the tutorial for loading a TorchScript model from C++ (as described [here](https://pytorch.org/tutorials/advanced/cpp_export.html)), the code runs successfully as long as the model and tensor data remain on the CPU. However, attempting to move the model to the GPU (CUDA) using `.to(at::kCUDA)` results in a crash. The crash occurs immediately in the debug version of the libraries, and later in the release version during the `.forward` method.

### Steps to Reproduce
1. Follow the code examples provided in the [tutorial](https://pytorch.org/tutorials/advanced/cpp_export.html).
2. Download the latest Windows 10 debug version of the PyTorch libraries from the official website.
3. Create a new Visual Studio 2017 project and include the code snippets from the tutorial.
4. Use the include files and libraries from the downloaded debug version.
5. Run the code within Visual Studio 2017.

### Stack Trace
```cpp
torch.dll!at::native::DispatchStub::operator()(c10::DeviceType device_type, at::TensorIterator & , bool & ) Line 74	C++
torch.dll!at::native::copy_impl(at::Tensor & self, const at::Tensor & src, bool non_blocking) Line 148	C++
torch.dll!at::native::copy_(at::Tensor & self, const at::Tensor & src, bool non_blocking) Line 157	C++
torch.dll!at::TypeDefault::copy_(at::Tensor & self, const at::Tensor & src, bool non_blocking) Line 1246	C++
torch.dll!c10::detail::WrapRuntimeKernelFunctor_ >::operator()(at::Tensor & , const at::Tensor & , bool ) Line 24	C++
torch.dll!c10::detail::wrap_kernel_functor_unboxed_ >,at::Tensor & __ptr64 __cdecl(at::Tensor & __ptr64,at::Tensor const & __ptr64,bool)>::call(c10::OperatorKernel * functor, at::Tensor & , const at::Tensor & , bool ) Line 261	C++
torch.dll!c10::KernelFunction::callUnboxedOnly(at::Tensor & , const at::Tensor & , bool ) Line 95	C++
torch.dll!c10::impl::OperatorEntry::callUnboxedOnly::__l2::(const c10::DispatchTable & dispatchTable) Line 68	C++
torch.dll!c10::LeftRight::read(const c10::DispatchTable &) >(c10::impl::OperatorEntry::callUnboxedOnly::__l2::at::Tensor & (const c10::DispatchTable &) && readFunc) Line 74	C++
torch.dll!c10::impl::OperatorEntry::callUnboxedOnly(c10::TensorTypeId dispatchKey, at::Tensor & , const at::Tensor & , bool ) Line 70	C++
torch.dll!c10::Dispatcher::callUnboxedOnly(const c10::OperatorHandle & op, c10::TensorTypeId dispatchKey, at::Tensor & , const at::Tensor & , bool ) Line 177	C++
torch.dll!at::Tensor::copy_(const at::Tensor & src, bool non_blocking) Line 746	C++
torch.dll!torch::autograd::VariableType::copy_(at::Tensor & self, const at::Tensor & src, bool non_blocking) Line 151	C++
torch.dll!c10::detail::WrapRuntimeKernelFunctor_ >::operator()(at::Tensor & , const at::Tensor & , bool ) Line 24	C++
torch.dll!c10::detail::wrap_kernel_functor_unboxed_ >,at::Tensor & __ptr64 __cdecl(at::Tensor & __ptr64,at::Tensor const & __ptr64,bool)>::call(c10::OperatorKernel * functor, at::Tensor & , const at::Tensor & , bool ) Line 261	C++
torch.dll!c10::KernelFunction::callUnboxedOnly(at::Tensor & , const at::Tensor & , bool ) Line 95	C++
torch.dll!c10::impl::OperatorEntry::callUnboxedOnly::__l2::(const c10::DispatchTable & dispatchTable) Line 68	C++
torch.dll!c10::LeftRight::read(const c10::DispatchTable &) >(c10::impl::OperatorEntry::callUnboxedOnly::__l2::at::Tensor & (const c10::DispatchTable &) && readFunc) Line 74	C++
torch.dll!c10::impl::OperatorEntry::callUnboxedOnly(c10::TensorTypeId dispatchKey, at::Tensor & , const at::Tensor & , bool ) Line 70	C++
torch.dll!c10::Dispatcher::callUnboxedOnly(const c10::OperatorHandle & op, c10::TensorTypeId dispatchKey, at::Tensor & , const at::Tensor & , bool ) Line 177	C++
torch.dll!at::Tensor::copy_(const at::Tensor & src, bool non_blocking) Line 746	C++
torch.dll!at::native::to_impl(const at::Tensor & self, const c10::TensorOptions & options, bool non_blocking) Line 25	C++
torch.dll!at::native::to(const at::Tensor & self, c10::Device device, c10::ScalarType dtype, bool non_blocking, bool copy) Line 63	C++
torch.dll!at::TypeDefault::to(const at::Tensor & self, c10::Device device, c10::ScalarType dtype, bool non_blocking, bool copy) Line 4830	C++
torch.dll!torch::autograd::VariableType::`anonymous namespace'::to(const at::Tensor & self, c10::Device device, c10::ScalarType dtype, bool non_blocking, bool copy) Line 11390	C++
torch.dll!at::ATenOpTable::callUnboxed(const at::Tensor & , c10::Device , c10::ScalarType , bool , bool ) Line 94	C++
torch.dll!at::Tensor::to(c10::Device device, c10::ScalarType dtype, bool non_blocking, bool copy) Line 3387	C++
torch.dll!torch::jit::script::module_state_to(const torch::jit::script::Slot & s, const c10::optional & device, const c10::optional & dtype, bool non_blocking) Line 123	C++
torch.dll!torch::jit::script::Module::to_impl(const c10::optional & device, const c10::optional & dtype, bool non_blocking) Line 140	C++
torch.dll!torch::jit::script::Module::to_impl(const c10::optional & device, const c10::optional & dtype, bool non_blocking) Line 136	C++
torch.dll!torch::jit::script::Module::to_impl(const c10::optional & device, const c10::optional & dtype, bool non_blocking) Line 136	C++
torch.dll!torch::jit::script::Module::to(c10::Device device, bool non_blocking) Line 79	C++
```

### Expected Behavior
The code should not crash when moving the model to the GPU.

### Environment
- **PyTorch Version:** 1.3
- **Windows Version:** 10.0.18362 Build 18362
- **Installation Method:** Used the provided Windows libraries
- **CUDA/cuDNN Version:** 10.1/7
- **GPU Model:** 1060ti
- **Visual Studio Version:** 15.9.8

If you need any additional information or have further questions, please let me know.