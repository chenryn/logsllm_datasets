### 8.2 Control Flow Integrity

**Control-Flow Integrity (CFI)** was introduced by Abadi et al. [1]. The core concept is to use static analysis to compute a control-flow graph and enforce it at runtime. Enforcement is based on matching constants (called IDs) between the source and target of each indirect control flow (ICF) transfer. However, due to the challenges in performing accurate points-to analysis and the so-called destination equivalence problem, their implementation resorts to coarse-grained enforcement, allowing any indirect call to target any function whose address is taken. Li et al. [22] implement a compiler-based CFI that follows a similar policy for coarse-grained CFI. While they can support finer-grained CFI, this requires runtime profiling to compute possible targets of indirect calls, which can lead to false positives.

**Control-Flow Locking (CFL)** [6] significantly improves the performance of Abadi et al.'s approach while tightening the policy, especially for return instructions. However, this tighter policy poses challenges in the presence of indirect tail calls. Another key difference is that CFL operates on assembly code generated by the compiler, whereas our work targets binaries.

**MoCFI** [13] presents a design and implementation of CFI for mobile platforms, which present unique challenges such as an instruction set without explicit returns and a closed platform (iOS). A notable feature of their approach is the aggressive pruning of possible targets for each ICF transfer, which can provide better protection but may also lead to false positives, especially with large jump tables. In contrast, our approach emphasizes handling large binaries, including shared libraries, which are not addressed by MoCFI. This requirement dictates the use of coarser-grained CFI in our technique.

**CCFIR** [48], like our work, targets binaries. Their key insight is that most Windows binaries support Address Space Layout Randomization (ASLR), which requires relocation information to be included in the binary. They leverage this information for accurate disassembly and static rewriting. Since relocation information effectively identifies all code pointers, they can avoid runtime address translation, leading to better performance. However, this technique cannot be used on most UNIX systems, as UNIX binaries rarely contain the necessary relocations.

**CFI has been used as the basis for untrusted code sandboxing**. PittSFIeld [27] implements Software Fault Isolation (SFI) on top of instruction bundling, a weaker CFI model. XFI [15] presents techniques based on CFI and SFI to confine untrusted code in shared-memory environments. Zeng et al. [47] improve the performance of SFI using CFI and static analysis. Native Client [46] aims to run native binaries securely in a browser context and relies on instruction bundling. Many other works [22, 3, 4, 42, 21, 36, 34, 20] that enforce CFI rely on compiler-provided information and even hardware support. In contrast, bin-CFI operates on commercial off-the-shelf (COTS) binaries without requiring support from the compiler, operating system, or hardware.

### 9 Conclusions

In this paper, we developed a notion of control-flow integrity that can be effectively enforced on binaries. We developed analysis techniques to compute possible ICF targets and instrumentation techniques to limit ICF transfers to these targets. The resulting implementation defeats most common control-flow hijack attacks and greatly reduces the number of possible gadgets for Return-Oriented Programming (ROP) attacks. We presented a robust implementation that scales to large binaries and complex, low-level libraries, including hand-coded assembly. Our technique is modular, supporting independent transformation of shared libraries, and provides very good performance.

Our results realize one of the central benefits of CFI: it can be applied to protect low-level code that is available only in the form of binaries. Although the lack of high-level information can degrade the precision of static analysis, our results demonstrate that the reduction is small. Overall, there is only a modest reduction in the strength of protection compared to previous techniques that required source code, relocation information, or relied on compiler-based implementations.

### 10 Acknowledgements

We are very grateful to the developers of Katana, especially James Oakley for his quick and very helpful responses to our questions. We also thank Edward Schwartz for his technical support.

### References

[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-Flow Integrity. In the 12th ACM Conference on Computer and Communications Security (CCS), 2005.

[2] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-Flow Integrity Principles, Implementations, and Applications. ACM Transactions on Information and System Security (TISSEC), (1), Nov. 2009.

[3] P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and M. Castro. Preventing Memory Error Exploits with WIT. In the 29th IEEE Symposium on Security and Privacy (Oakland), 2008.

[4] J. Ansel, P. Marchenko, U. Erlingsson, E. Taylor, B. Chen, D. L. Schuff, D. Sehr, C. L. Biffle, and B. Yee. Language-Independent Sandboxing of Just-In-Time Compilation and Self-Modifying Code. In the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2011.

[5] S. Bhatkar, D. C. DuVarney, and R. Sekar. Address Obfuscation: An Efficient Approach to Combat a Broad Range of Memory Error Exploits. In the 12th USENIX Security Symposium, 2003.

[6] T. Bletsch, X. Jiang, and V. Freeh. Mitigating Code-Reuse Attacks with Control-Flow Locking. In the 27th Annual Computer Security Applications Conference (ACSAC), 2011.

[7] T. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang. Jump-Oriented Programming: A New Class of Code-Reuse Attack. In the 6th ACM Symposium on Information, Computer and Communications Security (ASIACCS), 2011.

[8] D. L. Bruening. Efficient, Transparent, and Comprehensive Runtime Code Manipulation. PhD thesis, MIT, 2004.

[9] E. Buchanan, R. Roemer, H. Shacham, and S. Savage. When Good Instructions Go Bad: Generalizing Return-Oriented Programming to RISC. In the 15th ACM Conference on Computer and Communications Security (CCS), 2008.

[10] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham, and M. Winandy. Return-Oriented Programming Without Returns. In the 17th ACM Conference on Computer and Communications Security (CCS), 2010.

[11] P. Chen, H. Xiao, X. Shen, X. Yin, B. Mao, and L. Xie. DROP: Detecting Return-Oriented Programming Malicious Code. In the 5th International Conference on Information Systems Security (ICISS), 2009.

[12] C. Cowan, C. Pu, D. Maier, H. Hintony, J. Walpole, P. Bakke, S. Beattie, A. Grier, P. Wagle, and Q. Zhang. StackGuard: Automatic Adaptive Detection and Prevention of Buffer-Overflow Attacks. In the 7th USENIX Security Symposium, 1998.

[13] L. Davi, R. Dmitrienko, M. Egele, T. Fischer, T. Holz, R. Hund, S. Nurnberger, and A. Reza Sadeghi. MoCFI: A Framework to Mitigate Control-Flow Attacks on Smartphones. In the 19th Network and Distributed System Security Symposium (NDSS), 2012.

[14] L. Davi, Ahmad-Reza Sadeghi, and M. Winandy. ROPdefender: A Detection Tool to Defend Against Return-Oriented Programming Attacks. In the 6th ACM Symposium on Information, Computer and Communications Security (ASIACCS), 2011.

[15] U. Erlingsson, S. Valley, M. Abadi, M. Vrable, M. Budiu, and G. C. Necula. XFI: Software Guards for System Address Spaces. In the 7th USENIX Symposium on Operating Systems Design and Implementation (OSDI), 2006.

[16] C. Evans. Exploiting 64-bit Linux Like a Boss. http://scarybeastsecurity.blogspot.com/2013/02/exploiting-64-bit-linux-like-boss.html.

[17] M. Frantzen and M. Shuey. StackGhost: Hardware Facilitated Stack Protection. In the 10th USENIX Security Symposium, 2001.

[18] J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. Davidson. ILR: Whereâ€™d My Gadgets Go? In the 33rd IEEE Symposium on Security and Privacy (Oakland), 2012.

[19] R. Hund, T. Holz, and F. C. Freiling. Return-Oriented Rootkits: Bypassing Kernel Code Integrity Protection Mechanisms. In the 18th USENIX Security Symposium, 2009.

[20] M. Kayaalp, M. Ozsoy, N. Abu-Ghazaleh, and D. Ponomarev. Branch Regulation: Low-Overhead Protection from Code Reuse Attacks. In the 39th Annual International Symposium on Computer Architecture (ISCA), 2012.

[21] V. Kiriansky, D. Bruening, and S. P. Amarasinghe. Secure Execution via Program Shepherding. In the 11th USENIX Security Symposium, 2002.

[22] J. Li, Z. Wang, T. Bletsch, D. Srinivasan, M. Grace, and X. Jiang. Comprehensive and Efficient Protection of Kernel Control Data. IEEE Transactions on Information Forensics and Security, (4), Dec. 2011.

[23] J. Li, Z. Wang, X. Jiang, M. Grace, and S. Bahram. Defeating Return-Oriented Rootkits with "Return-Less" Kernels. In the 5th European Conference on Computer Systems (EuroSys), 2010.

[24] The PaX Team. Address Space Layout Randomization. http://pax.grsecurity.net/docs/aslr.txt, 2001.

[25] Tool Interface Standard. Executable and Linking Format (ELF) Specification. http://www.uclibc.org/docs/elf.pdf, 1995.

[26] UNIX International Programming Languages SIG. DWARF Debugging Information Format. http://www.dwarfstd.org/doc/dwarf-2.0.0.pdf, 1993.

[27] S. McCamant and G. Morrisett. Evaluating SFI for a CISC Architecture. In the 15th USENIX Security Symposium, 2006.

[28] Nergal. The Advanced Return-Into-Lib(c) Exploits: PaX Case Study. Phrack Magazine, 2001.

[29] J. Oakley and S. Bratus. Exploiting the Hard-Working DWARF: Trojan and Exploit Techniques with No Native Executable Code. Technical Report, Computer Science Department, Dartmouth College, 2011.

[30] J. Oakley and S. Bratus. Exploiting the Hard-Working DWARF: Trojan and Exploit Techniques with No Native Executable Code. In the 5th USENIX Conference on Offensive Technologies (WOOT), 2011.

[31] K. Onarlioglu, L. Bilge, A. Lanzi, D. Balzarotti, and E. Kirda. G-Free: Defeating Return-Oriented Programming Through Gadget-Less Binaries. In the 26th Annual Computer Security Applications Conference (ACSAC), 2010.

[32] V. Pappas. kBouncer: Efficient and Transparent ROP Mitigation. Technical Report, Columbia University, 2012.

[33] V. Pappas, M. Polychronakis, and A. D. Keromytis. Smashing the Gadgets: Hindering Return-Oriented Programming Using In-Place Code Randomization. In the 33rd IEEE Symposium on Security and Privacy (Oakland), 2012.

[34] A. Prakash, H. Yin, and Z. Liang. Enforcing System-Wide Control Flow Integrity for Exploit Detection and Diagnosis. In the 8th ACM SIGSAC Symposium on Information, Computer and Communications Security (ASIACCS), 2013.

[42] Z. Wang and X. Jiang. HyperSafe: A Lightweight Approach to Provide Lifetime Hypervisor Control-Flow Integrity. In the 31st IEEE Symposium on Security and Privacy (Oakland), 2010.

[43] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary Stirring: Self-Randomizing Instruction Addresses of Legacy x86 Binary Code. In the 19th ACM Conference on Computer and Communications Security (CCS), 2012.

[44] Wikipedia. Open Addressing Hashing. http://en.wikipedia.org/wiki/Open_addressing, 2012.

[45] J. Wilander, N. Nikiforakis, Y. Younan, M. Kamkar, and W. Joosen. RIPE: Runtime Intrusion Prevention Evaluator. In the 27th Annual Computer Security Applications Conference (ACSAC), 2011.

[46] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar. Native Client: A Sandbox for Portable, Untrusted x86 Native Code. In the 30th IEEE Symposium on Security and Privacy (Oakland), 2009.

[47] B. Zeng, G. Tan, and G. Morrisett. Combining Control-Flow Integrity and Static Analysis for Efficient and Validated Data Sandboxing. In the 18th ACM Conference on Computer and Communications Security (CCS), 2011.

[48] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant, D. Song, and W. Zou. Practical Control Flow Integrity & Randomization for Binary Executables. In the 34th IEEE Symposium on Security and Privacy, 2013.

[49] D. D. Zovi. Practical Return-Oriented Programming. Technical Report, SOURCE, 2010.

[35] J. Salwan. ROPGadget. http://shell-storm.org/project/ROPgadget.

[36] D. Sehr, R. Muth, C. Biffle, V. Khimenko, E. Pasko, K. Schimpf, B. Yee, and B. Chen. Adapting Software Fault Isolation to Contemporary CPU Architectures. In the 19th USENIX Security Symposium, 2010.

[37] F. J. Serna. CVE-2012-0769, the Case of the Perfect Info Leak, 2012.

[38] H. Shacham. The Geometry of Innocent Flesh on the Bone: Return-Into-LIBC Without Function Calls (on the x86). In the 14th ACM Conference on Computer and Communications Security (CCS), 2007.

[39] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and A.-R. Sadeghi. Just-In-Time Code Reuse: On the Effectiveness of Fine-Grained Address Space Layout Randomization. In the 34th IEEE Symposium on Security and Privacy, 2013.

[40] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lachmund, and T. Walter. Breaking the Memory Secrecy Assumption. In the 2nd European Workshop on System Security (EUROSEC), 2009.

[41] M. Tran, M. Etheridge, T. Bletsch, X. Jiang, V. Freeh, and P. Ning. On the Expressiveness of Return-Into-LIBC Attacks. In the 14th International Conference on Recent Advances in Intrusion Detection (RAID), 2011.