# 基于PU-Learning的恶意URL检测
> 作者：Ya-Lin Zhang, Longfei Li, Jun Zhou, Xiaolong Li, Yujiang Liu, Yuanchao Zhang, Zhi-Hua Zhou  
>  单位：南京大学软件新技术国家重点实验室，中国；蚂蚁金融服务集团，中国  
>  来源：CCS’17

## 摘要
本文介绍了一种基于PU-Learning（正例和未标记学习）的潜在恶意URL检测系统。传统的方法将此问题视为有监督学习问题，但在实际中，我们通常只能获得少量已知攻击URL及大量未标记样本，这使得有监督学习难以实施。为此，我们将该问题定义为PU-Learning问题，并结合了两种策略（两阶段策略和代价敏感策略）。实验结果表明，所开发的系统能够有效识别潜在的恶意URL攻击。该系统不仅可作为现有系统的补充部署，还能帮助网络安全工程师发现新的攻击模式，从而快速更新现有的防御系统。

## 1 引言
随着互联网的快速发展，恶意URL攻击日益增多，严重威胁网络安全。传统的检测方法依赖黑名单或规则列表，但这些方法难以应对新出现的威胁。为了提高检测能力，研究人员尝试使用机器学习方法。尽管有监督学习在标注数据充足时表现出色，但在实际应用中，往往只能获取到少量标注数据。因此，我们将问题抽象为PU-Learning问题，以充分利用有限的恶意URL信息和大量的未标记URL。通过结合两阶段策略和代价敏感策略，我们构建了一个高效的恶意URL检测系统。实验验证了该系统在实际场景中的有效性，显著减轻了网络安全工程师的工作负担。

## 2 系统架构
本节介绍了所开发系统的整体架构。如图1所示，系统主要由三个模块组成：
- **特征提取**：将原始URL转换成特征向量；
- **模型训练**：利用提取的特征向量训练PU-Learning模型；
- **预测**：对输入的URL进行分类，输出可能的恶意URL集合。

### 2.1 特征提取
首先，将原始URL转换为特征向量表示，便于后续处理。URL通常包括协议、认证、路径、查询和片段等部分，其中片段部分最易受到攻击。我们的系统重点关注片段部分，从Key-Value对中提取特征。具体而言，对于每个URL，我们保留前N个最常见的恶意Key，并将其余Key-Value对合并为一个。然后，从每个过滤后的值中提取8种统计特征，包括字符、字母、数字和标点符号的数量及其种类。最终，每个URL被描述为一个(N+1)×8维的特征向量。

### 2.2 模型训练
由于缺乏足够的负例标注数据，传统有监督学习算法不适用于本场景。因此，我们采用PU-Learning框架。PU-Learning是半监督学习的一种特殊情况，专门解决只有正例和未标注样本的问题。我们采用了两种策略：
- **两阶段策略**：第一阶段从未标记实例中选择可靠的负例，第二阶段利用正例和选出的负例训练监督模型。
- **代价敏感策略**：假设未标注样本中仅有少量正例，将所有未标注样本设为负例，并最小化目标函数。通过设置不同的误分类惩罚因子，使模型更关注恶意URL的正确分类。

### 2.3 预测
在预测阶段，新输入的URL首先经过特征提取，生成特征向量。然后，该向量被送入两个子模型（分别对应上述两种策略），每个模型输出一个恶意概率得分。最终得分取这两个得分的平均值，得分越高，URL越可能是恶意的。在工程实践中，我们会根据候选恶意URL集筛选出K个高分URL供网络安全工程师进一步验证。

## 3 实验验证
### 3.1 数据集与准备工作
数据来自蚂蚁金服的实际业务场景，包含大量未标记URL和少量已知恶意URL。我们每天从请求中抽取一亿个URL，其中恶意URL数量从几万到数十万不等。模型使用连续七天的数据进行训练，并用于预测每日新出现的未标记URL。

### 3.2 实验结果
我们邀请网络安全工程师检查候选恶意URL集的结果。实验证明，该系统的精度达到90%，能有效识别潜在恶意URL。此外，还发现了新的攻击模式，帮助改进现有系统。该系统可以与现有系统协同工作，提高整体网络安全水平。

## 4 总结
本文提出了一种基于PU-Learning的潜在恶意URL检测系统，仅需少量恶意URL和大量未标记URL即可运行。系统通过特征提取、两阶段策略和代价敏感策略，实现了高效准确的恶意URL检测。实验结果表明，该系统在实际应用中表现良好，有助于提升网络安全防护能力。

## 参考文献
[1] Olivier Chapelle, Bernhard Scholkopf, and Alexander Zien. 2009. Semi-Supervised Learning. IEEE Transactions on Neural Networks 20, 3 (2009), 542–542.  
[2] Marthinus C du Plessis, Gang Niu, and Masashi Sugiyama. 2014. Analysis of Learning from Positive and Unlabeled Data. In Advances in Neural Information Processing Systems 27. 703–711.  
[3] Charles Elkan and Keith Noto. 2008. Learning Classifiers from Only Positive and Unlabeled Data. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 213–220.  
[4] Bing Liu, Yang Dai, Xiaoli Li, Wee Sun Lee, and Philip S Yu. 2003. Building Text Classifiers Using Positive and Unlabeled Examples. In Proceeding of the 3rd IEEE International Conference on Data Mining. 179–186.  
[5] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation Forest. In Proceeding ot the 8th IEEE International Conference on Data Mining. 413–422.  
[6] Justin Ma, Lawrence K Saul, Stefan Savage, and Geoffrey M Voelker. 2009. Beyond Blacklists: Learning to Detect Malicious Web Sites from Suspicious URLs. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1245–1254.  
[7] Zhi-Hua Zhou and Ming Li. 2010. Semi-Supervised Learning by Disagreement. Knowledge and Information Systems 24, 3 (2010), 415–439.