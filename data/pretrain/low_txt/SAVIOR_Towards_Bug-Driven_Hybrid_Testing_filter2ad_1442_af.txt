### Differing from the Above Works: Code-Coverage Improvement
Differing from the above works that focus on code-coverage improvement, SAVIOR introduces a new philosophy in hybrid testing. It prioritizes concolic execution on seeds with higher potential and guides the verification of encountered vulnerabilities, leading to faster and more comprehensive bug coverage.

### Guided Software Testing
This line of research [25, 32, 43, 52] aims to guide testing towards specific code locations. Katch [52] prioritizes seeds that approach patches, thereby guiding the symbolic executor. Combined with three other guiding schemes, Katch can efficiently cover the target code. Similarly, AFLGO [25] calculates the distance from each code region to the targets (e.g., vulnerable code regions or patches). In fuzz testing, AFLGO favors seeds that exercise code regions with smaller distances. Christakis et al. [32] propose pruning paths in dynamic symbolic execution by discarding paths that have already been verified. However, these existing works generally prioritize seeds that quickly approach the targets, often resulting in shallow contexts. In contrast, SAVIOR values all seeds with high potential, creating various contexts to exercise the target code. This approach enables SAVIOR to outperform existing guided testing techniques in bug finding. Some other works use static analysis to label potential vulnerabilities, such as using data flow analysis to pinpoint data leaks [23], slicing to mark use-after-free paths [38], and taint analysis to identify possible races [50]. These analyses are complementary to SAVIOR. Additionally, SAVIOR relies on fuzz testing to stably approach the to-be-verified paths, while other approaches use heuristic-based methods to guide symbolic execution towards marked labels.

### Conclusion
In this work, we introduce SAVIOR, a novel hybrid testing approach. Unlike mainstream hybrid testing tools that follow a coverage-driven design, SAVIOR is driven by the goal of identifying bugs. We propose two novel techniques in SAVIOR: bug-driven prioritization and bug-guided verification. On one hand, SAVIOR prioritizes concolic execution to run seeds with higher potential for leading to vulnerabilities. On the other hand, SAVIOR examines all vulnerable candidates along the running program path in concolic execution. By modeling unsafe conditions in SMT constraints, it either finds proofs of valid vulnerabilities or proves that the corresponding vulnerabilities do not exist. SAVIOR significantly outperforms existing coverage-driven tools. On average, it detects vulnerabilities 43.4% faster than DRILLER and 44.3% faster than QSYM, resulting in the discovery of 88 and 76 more security violations in 24 hours, respectively.

### Acknowledgments
We would like to thank our shepherd Mathias Payer and the anonymous reviewers for their valuable feedback. This project was supported by the Office of Naval Research (Grant#: N00014-17-1-2891, N00014-18-1-2043, and N00014-17-1-2787). Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding agency.

### References
[1] “AFLGo source code,” https://github.com/aflgo/aflgo.
[2] “American fuzzy lop,” http://lcamtuf.coredump.cx/afl.
[3] “Angora source code,” https://github.com/AngoraFuzzer/Angora.
[4] “angr/tracer: Utilities for generating dynamic traces,” https://github.com/angr/tracer.
[5] “Apollo: an open autonomous driving platform,” https://github.com/ApolloAuto/apollo.
[6] “Driller reading file patch,” https://github.com/shellphish/driller/issues/48.
[7] “Driller stuck heuristic,” https://github.com/shellphish/driller#the-stuck-heuristic.
[8] “Index of /gnu/binutils,” https://ftp.gnu.org/gnu/binutils/.
[9] “Jasper source code,” https://github.com/mdadams/jasper/archive/master.zip.
[10] “Klee intrinsiccleaner,” https://github.com/klee/klee/blob/master/lib/Module/IntrinsicCleaner.cpp.
[11] “libjpeg source code,” https://www.ijg.org/files/jpegsrc.v9c.tar.gz.
[12] “Libtiff source code,” https://download.osgeo.org/libtiff/.
[13] “libxml2 source code,” http://xmlsoft.org/libxml2/libxml2-git-snapshot.tar.gz.
[14] “The myth of bug free software,” https://www.betabreakers.com/the-myth-of-bug-free-software/.
[15] “Objdump overflow patch,” https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;a=commitdiff;h=f2023ce7.
[16] “OSS-Fuzz - continuous fuzzing for open source software,” https://github.com/google/oss-fuzz.
[17] “Qsym source code,” https://github.com/sslab-gatech/qsym.
[18] “Run angora on LAVA dataset,” https://github.com/AngoraFuzzer/Angora/blob/master/docs/lava.md.
[19] “T-Fuzz source code,” https://github.com/HexHive/T-Fuzz.
[20] “Tcpdump source code,” http://www.tcpdump.org/release/.
[21] “Undefined behavior sanitizer - clang 9 documentation,” http://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html#ubsan-checks.
[22] A. Afifi, D. Chan, J. J. Comuzzi, J. M. Hart, and A. Pizzarello, “Method and apparatus for analyzing computer code using weakest precondition,” US Patent 6,029,002, Feb. 22, 2000.
[23] S. Arzt, S. Rasthofer, R. Hahn, and E. Bodden, “Using targeted symbolic execution for reducing false-positives in dataflow analysis,” in Proceedings of the 4th ACM SIGPLAN International Workshop on State Of the Art in Program Analysis, SOAP@PLDI 2015, Portland, OR, USA, June 15-17, 2015, pp. 1–6.
[24] T. Avgerinos, S. K. Cha, B. L. T. Hao, and D. Brumley, “AEG: automatic exploit generation,” in Proceedings of the Network and Distributed System Security Symposium, NDSS 2011, San Diego, California, USA, February 6-9, 2011, pp. 1–15.
[25] M. Böhme, V.-T. Pham, M.-D. Nguyen, and A. Roychoudhury, “Directed greybox fuzzing,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2017, pp. 2329–2344.
[26] J. Burnim and K. Sen, “Heuristics for scalable dynamic test generation,” in 23rd IEEE/ACM International Conference on Automated Software Engineering, L’Aquila, Italy, September 15-19, 2008, pp. 443–446.
[27] C. Cadar, D. Dunbar, and D. Engler, “Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs,” in Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation. USENIX Association, 2008, pp. 209–224.
[28] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley, “Unleashing mayhem on binary code,” in IEEE Symposium on Security and Privacy, SP 2012, San Francisco, California, USA, May 21-23, 2012, pp. 380–394.
[29] P. Chen and H. Chen, “Angora: Efficient fuzzing by principled search,” in 2018 IEEE Symposium on Security and Privacy (SP). IEEE, 2018, pp. 711–725.
[30] Y. Chen, D. Mu, J. Xu, Z. Sun, W. Shen, X. Xing, L. Lu, and B. Mao, “Ptrix: Efficient hardware-assisted fuzzing for COTS binary,” in Proceedings of the 2019 ACM on Asia Conference on Computer and Communications Security.
[31] V. Chipounov, V. Kuznetsov, and G. Candea, “S2E: A platform for in-vivo multi-path analysis of software systems,” in ACM SIGARCH Computer Architecture News, vol. 39, no. 1. ACM, 2011, pp. 265–278.
[32] M. Christakis, P. Müller, and V. Wüstholz, “Guiding dynamic symbolic execution toward unverified program executions,” in Proceedings of the 38th International Conference on Software Engineering. ACM, 2016, pp. 144–155.
[33] L. M. de Moura and N. Bjørner, “Satisfiability modulo theories: introduction and applications,” Commun. ACM, vol. 54, no. 9, pp. 69–77, 2011.
[34] L. M. de Moura, B. Dutertre, and N. Shankar, “A tutorial on satisfiability modulo theories,” in Lecture Notes in Computer Science, vol. 4590, 2007, pp. 20–36.
[35] W. Dietz, P. Li, J. Regehr, and V. Adve, “Understanding integer overflow in C/C++,” in Proceedings of the 34th International Conference on Software Engineering, ICSE’12, 2012, pp. 760–770.
[36] B. Dolan-Gavitt, P. Hulin, E. Kirda, T. Leek, A. Mambretti, W. Robertson, F. Ulrich, and R. Whelan, “LAVA: Large-scale automated vulnerability addition,” in Proceedings of the 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 2016, pp. 110–121.
[37] H. Fan, F. Zhu, C. Liu, L. Zhang, L. Zhuang, D. Li, W. Zhu, J. Hu, H. Li, and Q. Kong, “Baidu Apollo EM motion planner,” arXiv preprint arXiv:1807.08048, 2018.
[38] J. Feist, L. Mounier, S. Bardin, R. David, and M. Potet, “Finding the needle in the heap: combining static analysis and dynamic symbolic execution to trigger use-after-free,” in Proceedings of the 6th Workshop on Software Security, Protection, and Reverse Engineering, SSPREW@ACSAC 2016, Los Angeles, California, USA, December 5-6, 2016, pp. 2:1–2:12.
[39] S. Gan, C. Zhang, X. Qin, X. Tu, K. Li, Z. Pei, and Z. Chen, “CollAFL: Path sensitive fuzzing,” in 2018 IEEE Symposium on Security and Privacy (SP), vol. 00, pp. 660–677.
[40] V. Ganesh and D. L. Dill, “A decision procedure for bit-vectors and arrays,” in Lecture Notes in Computer Science, vol. 4590, 2007, pp. 519–531.
[41] P. Godefroid, N. Klarlund, and K. Sen, “DART: directed automated random testing,” in Proceedings of the ACM SIGPLAN 2005 Conference on Programming Language Design and Implementation, Chicago, IL, USA, June 12-15, 2005, pp. 213–223.
[42] P. Godefroid, M. Y. Levin, D. A. Molnar et al., “Automated whitebox fuzz testing.” in NDSS, vol. 8, 2008, pp. 151–166.
[43] S. Guo, M. Kusano, C. Wang, Z. Yang, and A. Gupta, “Assertion guided symbolic execution of multithreaded programs,” in Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, Bergamo, Italy, August 30 - September 4, 2015, pp. 854–865.
[44] D. Harel, D. Kozen, and J. Tiuryn, “Dynamic logic,” in Handbook of philosophical logic. Springer, 2001, pp. 99–217.
[45] C. Hathhorn, C. Ellison, and G. Rosu, “Defining the undefinedness of C,” in Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation, Portland, OR, USA, June 15-17, 2015, pp. 336–345.
[46] W. E. Howden, “Symbolic testing and the DISSECT symbolic evaluation system,” IEEE Trans. Software Eng., vol. 3, no. 4, pp. 266–278, 1977.
[47] K. Jayaraman, D. Harvison, V. Ganesh, and A. Kiezun, “jFuzz: A concolic whitebox fuzzer for Java,” in First NASA Formal Methods Symposium - NFM 2009, Moffett Field, California, USA, April 6-8, 2009, pp. 121–125.
[48] J. C. King, “Symbolic execution and program testing,” Commun. ACM, vol. 19, no. 7, pp. 385–394, 1976.
[49] G. Klees, A. Ruef, B. Cooper, S. Wei, and M. Hicks, “Evaluating fuzz testing,” arXiv preprint arXiv:1808.09700, 2018.
[50] P. Li, G. Li, and G. Gopalakrishnan, “Practical symbolic race checking of GPU programs,” in International Conference for High Performance Computing, Networking, Storage and Analysis, SC 2014, New Orleans, LA, USA, November 16-21, 2014, pp. 179–190.
[51] R. Majumdar and K. Sen, “Hybrid concolic testing,” in Software Engineering, 2007. ICSE 2007. 29th International Conference on. IEEE, 2007, pp. 416–426.
[52] P. D. Marinescu and C. Cadar, “KATCH: high-coverage testing of software patches,” in Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE’13, Saint Petersburg, Russian Federation, August 18-26, 2013, pp. 235–245.
[53] P. E. McKnight and J. Najab, “Mann-Whitney U test,” The Corsini encyclopedia of psychology, pp. 1–1, 2010.
[54] D. Mu, A. Cuevas, L. Yang, H. Hu, X. Xing, B. Mao, and G. Wang, “Understanding the reproducibility of crowd-reported security vulnerabilities,” in Proceedings of the 27th USENIX Conference on Security Symposium. USENIX Association, 2018, pp. 919–936.
[55] B. S. Pak, “Hybrid fuzz testing: Discovering software bugs via fuzzing and symbolic execution,” School of Computer Science Carnegie Mellon University, 2012.
[56] H. Peng, Y. Shoshitaishvili, and M. Payer, “T-Fuzz: fuzzing by program transformation,” in 2018 IEEE Symposium on Security and Privacy (SP). IEEE, 2018, pp. 697–710.
[57] S. Rawat, V. Jain, A. Kumar, L. Cojocar, C. Giuffrida, and H. Bos, “VUZZER: Application-aware evolutionary fuzzing,” in Proceedings of the Network and Distributed System Security Symposium (NDSS), 2017.
[58] A. Rebert, S. K. Cha, T. Avgerinos, J. Foote, D. Warren, G. Grieco, and D. Brumley, “Optimizing seed selection for fuzzing,” in Proceedings of the 23rd USENIX Conference on Security Symposium. USENIX Association, 2014, pp. 861–875.
[59] K. Sen, “Concolic testing,” in Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering. ACM, 2007, pp. 571–572.
[60] K. Sen and G. Agha, “CUTE and jCUTE: Concolic unit testing and explicit path model-checking tools,” in Computer Aided Verification, 18th International Conference, Seattle, WA, USA, August 17-20, 2006, Proceedings, 2006, pp. 419–423.
[61] K. Sen, D. Marinov, and G. Agha, “CUTE: a concolic unit testing engine for C,” in Proceedings of the 10th European Software Engineering Conference held jointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering, Lisbon, Portugal, September 5-9, 2005, pp. 263–272.
[62] K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov, “AddressSanitizer: A fast address sanity checker.” in USENIX Annual Technical Conference. USENIX Association, 2012, pp. 309–318.
[63] D. She, K. Pei, D. Epstein, J. Yang, B. Ray, and S. Jana, “NEUZZ: Efficient fuzzing with neural program smoothing,” in NEUZZ: Efficient Fuzzing with Neural Program Smoothing. IEEE, 2018.
[64] R. M. Smullyan and R. Smullyan, Gödel’s incompleteness theorems. Oxford University Press on Demand, 1992.
[65] V. C. Sreedhar, G. R. Gao, and Y.-f. Lee, “Incremental computation of dominator trees,” in ACM SIGPLAN Notices, vol. 30, no. 3. ACM, 1995, pp. 1–12.
[66] N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang, J. Corbetta, Y. Shoshitaishvili, C. Kruegel, and G. Vigna, “Driller: Augmenting fuzzing through selective symbolic execution.” in Proceedings of the Network and Distributed System Security Symposium (NDSS), 2016.
[67] Y. Sui and J. Xue, “SVF: interprocedural static value-flow analysis in LLVM,” in Proceedings of the 25th International Conference on Compiler Construction. ACM, 2016, pp. 265–266.
[68] A. Takanen, J. D. DeMott, and C. Miller, Fuzzing for software security testing and quality assurance. Artech House, 2008.
[69] X. Wang, H. Chen, A. Cheung, Z. Jia, N. Zeldovich, and M. F. Kaashoek, “Undefined behavior: what happened to my code?” in Asia-Pacific Workshop on Systems, APSys ’12, Seoul, Republic of Korea, July 23-24, 2012, p. 9.
[70] X. Wang, N. Zeldovich, M. F. Kaashoek, and A. Solar-Lezama, “Taint-directed fuzzing for software vulnerability detection,” in Proceedings of the 2013 ACM SIGSAC Conference on Computer & Communications Security. ACM, 2013, pp. 833–844.