### VIII. DISCUSSION AND FUTURE WORK

In this section, we summarize and discuss the main findings from our work, outline the strengths and limitations of our study, and suggest directions for future research. Table X provides a summary of our overall results.

#### Summary and Insights
Our study revealed that participants exhibited increased activation in the dorsolateral prefrontal cortex (DLPFC), frontopolar cortex (FPC), and orbitofrontal gyrus (OFG) when deciding on the legitimacy of speakers' voices. These regions are associated with decision-making, working memory, memory recall, and trust. Additionally, there was activation in the superior temporal gyrus (STG), which is involved in processing auditory signals. These results indicate that participants were engaging in higher-order cognitive processes while making real vs. fake voice decisions. However, behavioral results showed that participants performed poorly in identifying original, morphed, and different speakers' voices. This poor performance may be attributed to the fact that participants were unaware that the voices could be morphed, reflecting a real-world attack scenario. Another factor could be the high quality of voice morphing technology, which effectively captures the features of the original speaker.

We also compared neural activities when participants listened to original and morphed voices but did not find statistically significant differences in brain activations, as reported in previous studies [34]. Although the lack of statistical significance does not rule out the possibility of differences, our findings suggest that such differences, if present, may not be consistent. Task performance results indicated that participants were nearly as likely to mistake morphed voices for real ones, suggesting that humans may inherently struggle to distinguish between real and morphed voices. Consequently, they may need to rely on external mechanisms, such as automated detection tools, to assist in this differentiation. However, even current voice biometric solutions have been shown to be vulnerable to voice impersonation attacks [30].

To address this, we developed and tested an automated mechanism to identify original and morphed voices using neural data. The model achieved only slightly better than random guessing, indicating that both explicit user responses and implicit brain activity suggest that morphed voices are indistinguishable from original ones. This finding highlights the susceptibility of users to voice imitation attacks, especially with advanced voice modeling techniques like those offered by Lyrebird and Google WaveNet [29, 41].

On a positive note, the inability to differentiate between original and morphed voices at both neural and behavioral levels suggests that current morphing technology may be suitable for individuals who have lost their voices.

#### Future Work
Future studies should investigate the impact of explicit training on users' ability to detect fabricated voices. Such training could potentially improve users' performance in identifying morphed voices, providing an interesting avenue for further research.

#### Study Strengths and Limitations
Our study, like any other involving human subjects, had certain limitations. It was conducted in a lab setting, which may have affected participants' performance due to the absence of real-world security concerns. Despite efforts to emulate a realistic environment and use lightweight fNIRS probe caps, the headset might have influenced some participants' performance. In real-world scenarios, users are not explicitly told to identify real and fake voices, unlike in our study. This, however, can be seen as a strength, as it shows that participants were unable to detect these attacks even when explicitly asked, suggesting that real-world performance may be even worse.

The sample size and diversity were well-aligned with prior studies [33, 34], but the majority of participants were young, which may not represent the success rate of voice spoofing attacks against older people or those with hearing impairments. The number of trials (forty-eight voice samples, each presented for 16 seconds) may have been more challenging than what users would face in real life. Additionally, the fNIRS device used primarily captures brain activities close to the cortex, potentially missing deeper neural activities. The distinctive and familiar voices of Oprah and Freeman used in the study may have confounded neural activity in the frontal cortex. Future studies should explore more realistic task setups.

Despite these limitations, our work provides a solid foundation for understanding vocal security from a neuro-physiological perspective, offering valuable insights for future research.

### IX. CONCLUDING REMARKS

In this paper, we explored voice security through the lens of neuroscience and neuroimaging, conducting an fNIRS study on human-centered speaker legitimacy detection. We found differences in neural activities when users listened to real vs. different speakers' voices but no significant differences when comparing real vs. morphed voices. This key insight helps explain users' susceptibility to morphing attacks, as supported by our task performance results and prior studies.

### ACKNOWLEDGMENTS

We would like to thank Micah Sherr (our shepherd) and NDSS’19 anonymous reviewers for their constructive comments and guidance. We are also grateful to Rajesh Kana, Abhishek Anand, Maliheh Shirvanian, and Kiavash Satvat for critiquing previous drafts of the paper. This work has been funded in part by a Department of Justice (DOJ) GRF-STEM fellowship.

### REFERENCES

[1] H. Abdi, “Holm's sequential Bonferroni procedure.”

[2] E. Amaro and G. J. Barker, “Study design in fMRI: basic principles,” Brain and Cognition, vol. 60, no. 3, pp. 220–232, 2006.

[3] S. R. Arnott, C. A. Heywood, R. W. Kentridge, and M. A. Goodale, “Voice recognition and the posterior cingulate: an fMRI study of prosopagnosia,” Journal of Neuropsychology, vol. 2, no. 1, pp. 269–286, 2008.

[4] X. Bai, L. Xing, N. Zhang, X. Wang, X. Liao, T. Li, and S. M. Hu, “Staying secure and unprepared: Understanding and mitigating the security risks of Apple Zeroconf,” in 2016 IEEE Symposium on Security and Privacy (SP), May 2016, pp. 655–674.

[5] J. V. Baldo and N. F. Dronkers, “The role of inferior parietal and inferior frontal cortex in working memory.” Neuropsychology, vol. 20, no. 5, p. 529, 2006.

[6] P. Belin, R. J. Zatorre, P. Lafaille, P. Ahad, and B. Pike, “Voice-selective areas in human auditory cortex,” Nature, vol. 403, no. 6767, pp. 309–312, 2000.

[7] A. Bethmann, H. Scheich, and A. Brechmann, “The temporal lobes differentiate between the voices of famous and unknown people: an event-related fMRI study on speaker recognition,” PLoS One, vol. 7, no. 10, p. e47626, 2012.

[8] Bonnie Brinton Anderson, C. Brock Kirwan, Jeffrey L. Jenkins, David Eargle, Seth Howard, and Anthony Vance, “How polymorphic warnings reduce habituation in the brain: Insights from an fMRI study,” in ACM Conference on Human Factors in Computing Systems, CHI, 2015.

[9] K. Brodmann, Vergleichende Lokalisationslehre der Grosshirnrinde in ihren Prinzipien dargestellt auf Grund des Zellenbaues. Barth, 1909.

[10] S. C. Bunce, M. Izzetoglu, K. Izzetoglu, B. Onaral, and K. Pourrezaei, “Functional near-infrared spectroscopy,” IEEE Engineering in Medicine and Biology Magazine, vol. 25, no. 4, pp. 54–62, 2006.

[11] B. Chance, Z. Zhuang, C. UnAh, C. Alter, and L. Lipton, “Cognition-activated low-frequency modulation of light absorption in human brain.” Proceedings of the National Academy of Sciences, vol. 90, no. 8, pp. 3770–3774, 1993.

[12] J. Cohen, “Statistical power analysis for the behavioral sciences (revised ed.),” 1977.

[13] C. E. Curtis and M. D'Esposito, “Persistent activity in the prefrontal cortex during working memory,” Trends in Cognitive Sciences, vol. 7, no. 9, pp. 415–423, 2003.

[14] D. T. Delpy, M. Cope, P. van der Zee, S. Arridge, S. Wray, and J. Wyatt, “Estimation of optical pathlength through tissue from direct time of flight measurement,” Physics in Medicine and Biology, vol. 33, no. 12, p. 1433, 1988.

[15] A. Dimoka, “What does the brain tell us about trust and distrust? Evidence from a functional neuroimaging study,” MIS Quarterly, pp. 373–396, 2010.

[16] J. R. Dubno, D. D. Dirks, and D. E. Morgan, “Effects of age and mild hearing loss on speech recognition in noise,” The Journal of the Acoustical Society of America, vol. 76, no. 1, pp. 87–96, 1984.

[17] “Bellesouth: Facebook scammers use voice-imitation to prey on users' relatives.” http://bellesouthblogs.com/facebookscam/, 2012, accessed: 5-12-2018.

[18] “Festival,” http://www.cstr.ed.ac.uk/projects/festival/, 2017, accessed: 5-12-2018.

[19] “Festvox,” http://festvox.org/, 2014, accessed: 05-11-2018.

[20] E. Formisano, F. De Martino, M. Bonte, and R. Goebel, “‘Who’ is saying ‘what’? Brain-based decoding of human voice and speech,” Science, vol. 322, no. 5903, pp. 970–973, 2008.

[21] “Grandparents scam,” http://www.michigan.gov/ag/0,4534,7-164-18156-205169–,00.html, 2017, accessed: 5-12-2018.

[22] M. A. Hall, “Correlation-based feature selection for machine learning,” Ph.D. dissertation, The University of Waikato, 1999.

[23] “Hemodynamic response,” https://en.wikipedia.org, 2017, accessed: 5-12-2018.

[24] L. M. Hirshfield, R. Gulotta, S. Hirshfield, S. Hincks, M. Russell, R. Ward, T. Williams, and R. Jacob, “This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy,” in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 2011, pp. 373–382.

[25] M. Huang, H. Bridge, M. J. Kemp, and A. J. Parker, “Human cortical activity evoked by the assignment of authenticity when viewing works of art,” Frontiers in Human Neuroscience, vol. 5, 2011.

[26] K. Izzetoglu, S. Bunce, B. Onaral, K. Pourrezaei, and B. Chance, “Functional optical brain imaging using near-infrared during cognitive tasks,” International Journal of Human-Computer Interaction, vol. 17, no. 2, pp. 211–227, 2004.

[27] J. León-Carrión and U. León-Domínguez, “Functional near-infrared spectroscopy (fNIRS): principles and neuroscientific applications,” Neuroimaging Methods. Rijeka, Croatia: InTech (2012): 47-74, 2012.

[28] K. Lewison and F. Corella, “Backing rich credentials with a blockchain PKI,” 2016.

[29] “Lyrebird,” https://lyrebird.ai/, 2017, accessed: 5-12-2018.

[30] D. Mukhopadhyay, M. Shirvanian, and N. Saxena, “All your voices are belong to us: Stealing voices to fool humans and machines,” in European Symposium on Research in Computer Security. Springer, 2015, pp. 599–621.

[31] K. Murphy and H. Garavan, “An empirical investigation into the number of subjects required for an event-related fMRI study,” Neuroimage, vol. 22, no. 2, pp. 879–885, 2004.

[32] A. Neupane, M. L. Rahman, N. Saxena, and L. Hirshfield, “A multi-modal neuro-physiological study of phishing detection and malware warnings,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, 2015, pp. 479–491.

[33] A. Neupane, N. Saxena, and L. Hirshfield, “Neural underpinnings of website legitimacy and familiarity detection: An fNIRS study,” in Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2017, pp. 1571–1580.

[34] A. Neupane, N. Saxena, K. Kuruvilla, M. Georgescu, and R. Kana, “Neural signatures of user-centered security: An fMRI study of phishing, and malware warnings,” in Proceedings of the Network and Distributed System Security Symposium (NDSS), 2014, pp. 1–16.

[35] M. Plichta, M. Herrmann, C. Baehne, A.-C. Ehlis, M. Richter, P. Pauli, and A. Fallgatter, “Event-related functional near-infrared spectroscopy (fNIRS): are the measurements reliable?” Neuroimage, vol. 31, no. 1, pp. 116–124, 2006.

[36] I. Released, “IBM SPSS Statistics for Windows. 20.” Armonk, NY: IBM Corp, 2013.

[37] B. R. Rosen, R. L. Buckner, and A. M. Dale, “Event-related functional MRI: past, present, and future,” Proceedings of the National Academy of Sciences, vol. 95, no. 3, pp. 773–780, 1998.

[38] M. Shirvanian and N. Saxena, “Wiretapping via mimicry: short voice imitation man-in-the-middle attacks on crypto phones,” in Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2014, pp. 868–879.

[39] D. Tsuzuki and I. Dan, “Spatial registration for functional near-infrared spectroscopy: from channel position on the scalp to cortical location in individual and group analyses,” Neuroimage, vol. 85, pp. 92–103, 2014.

[40] A. Villringer and B. Chance, “Non-invasive optical spectroscopy and imaging of human brain function,” Trends in Neurosciences, vol. 20, no. 10, pp. 435–442, 1997.

[41] “Google Wavenet,” https://cloud.google.com/text-to-speech/docs/wavenet, 2017, accessed: 8-3-2018.

[42] H. Ye and S. Young, “High quality voice morphing,” in Acoustics, Speech, and Signal Processing, 2004. Proceedings. (ICASSP’04). IEEE International Conference on, vol. 1. IEEE, 2004, pp. I–9.

[43] R. J. Zatorre, A. C. Evans et al., “Lateralization of phonetic and pitch discrimination in speech processing,” Science, vol. 256, no. 5058, p. 846, 1992.