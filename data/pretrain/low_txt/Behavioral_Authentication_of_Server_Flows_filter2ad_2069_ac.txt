### Network Placement of Host and Aggregate Classifiers

**Components:**
- Classifier
- IDS (Intrusion Detection System)
- Server A
- Server B
- Firewall
- User Workstations

**Figure 3.** Network placement of the host and aggregate classifiers. Host classifiers monitor specific server flows for deviations from expected behavior, while aggregate classifiers monitor user traffic to determine if flow behavior matches generalized behavior of other flows of the same type.

### Functionality of Classifiers

**Aggregate Model:**
The aggregate model aims to answer the question: "What other flows does this flow resemble?" This model is designed to identify patterns in user traffic and compare them to generalized behavior of similar flows.

**Host Model:**
In contrast, host models are based on the previously observed behavior of flows for a specific host. Given an unseen flow, the host models try to answer the question: "Does this flow resemble previous server flows from this host?"

### Intrusion/Misuse Detection Systems and Firewalls

Intrusion/misuse detection systems and firewalls aim to identify potentially harmful actions before they can cause damage. An IDS may passively monitor traffic and alert in the presence of attack conditions, while firewalls actively drop network packets that violate network policies. Our classification method complements these a priori mechanisms by identifying activities indicative of intrusion or misuse after an event has occurred. By working in concert with these systems, we can attempt to determine at any moment whether there is an impending attack or evidence of a successful attack.

### Integration into Existing Networks

**Figure 3** illustrates how our classification methods can be integrated into a network with an existing IDS. The organization uses servers to provide network services (internally, externally, or both) to a community of users. Our host-flow classification system directly monitors the output of these servers to determine if currently observed flows continue to behave as expected. If an attacker takes control of a service, they would need to interact with the server in a way that exactly matches the previous behavior. For example, a trojaned web server that behaves like a Telnet server when communicating with a select group of host addresses would not match the expected host model and thus be detected.

### Monitoring External Traffic

The network also carries additional user traffic to external servers. This traffic is monitored using the aggregate model. We classify the flow generally and compare it to the port label. For instance, observing traffic that resembles Telnet on a non-standard server port may indicate an installed backdoor. Similarly, traffic labeled as web traffic (with a server port of 80) that behaves more like Telnet traffic may suggest the presence of a proxy used to evade firewall rules. A peer-to-peer client operating at a user-defined port may violate network policy. In each of these cases, the aggregate classifier can indicate if a given flow behaves in a manner consistent with its port label. It may not be necessary to monitor every flow; the system could be configured to randomly select a flow and attempt to classify it. If this flow generally matches a flow that is unusual or undesirable for a port range, it can be identified and investigated.

### Implementation and Performance

Our method can operate on its own physical system or be part of the IDS or firewall. This decision will depend on the number of flows the system is expected to monitor. Following the construction of the models, the system makes simple and rapid classifications.

### Subverting Classification

Given the presence of a monitoring system, we examined ways in which an attacker could manipulate a session to affect the classification of a server flow. One such example, though innocuous, is the Water Cooler Effect, where the user suspends interaction, causing variation in packet arrival times and potentially large fluctuations in the mean inter-arrival time. An attacker could do the same, but it is unclear whether they could cause a particular classification to be chosen. More likely, they would alter the observations to cause an indeterminate class to be chosen. If a host classifier is being used, the deviation from expected behavior would trigger an alarm.

Another method might involve the use of extraneous TCP flags in packets sent to the server. For example, using the URG flag in HTTP packets. The distribution of TCP flags in the corresponding server flow may or may not be affected, depending on the server's implementation. As with timing effects, we are investigating the sensitivity of classifiers to this manipulation in future work.

### Related Work

Previous research in flow identification has employed various techniques and feature sets. Dunigan and Ostrouchov used Principal Component Analysis (PCA) on two features (packet inter-arrival time and length) to create signatures for different flow types [10]. Their reported classification accuracies are comparable to our method, but their method requires offline analysis. In contrast, our method performs classification in real-time.

Tan and Collie used a modified neural network built on a single feature (total number of bytes transmitted) [35]. They confined their analysis to the classification of Telnet and FTP protocols, and their reported classification accuracies were generally lower than our method for these protocols.

Daniels [9] reports using a decision tree built with a single feature (the first one hundred bytes of a packet) to classify flows. However, the classification accuracy was found to be inadequate for practical use.

Several commercial products attempt to identify flow types [23–25, 34], primarily for bandwidth allocation. For example, a network administrator might create a policy stating that web traffic must not exceed a certain percentage of total bandwidth and use one of these products to selectively drop traffic when that policy is violated. Many details of the classification methods used by these products are proprietary and not publicly available, making direct comparison difficult. It is unclear whether these products can correctly classify flows in the presence of malicious activity. Packeteer [25] reports that their product uses information from all seven layers of the protocol stack to create an application signature, but such a system may or may not be appropriate in environments with payload encryption or privacy concerns.

We have also identified a component of the Snort IDS [29] that classifies server flows. However, this system relies on port numbers and the detection of the TCP three-way handshake, which may not be reliable in the presence of a proxy or compromised service.

With respect to our feature set, the NATE (Network Analysis of Anomalous Traffic Events) [36] system is also based on TCP flags. NATE uses principal component analysis to detect certain types of attacks. Our method differs in two respects: First, NATE models differences between normal and attack traffic, not between protocols. Second, NATE uses clustering to identify anomalies, which must be done offline, limiting its usefulness in real-time environments. In contrast, once a decision tree has been created, our system can monitor packets in real-time.

### Conclusions

We have presented a novel approach for defining a set of features to model the operational behavior of server flow traffic. Using the C5.0 decision tree algorithm, we demonstrated that our features can differentiate the behavior of server protocols with an accuracy of 82% to 100%. We empirically illustrate that aggregate models can classify an unseen server flow as belonging to a family of previously seen flows, and host models can determine whether flows from a given server match the behavior of previously seen flows from that server. These classifiers can augment traditional intrusion detection systems to detect artifacts of successful attacks. Our techniques are independent of packet labels and are thus immune to techniques that modify port numbers to conceal activity.

The decision tree classifiers can be sensitive to fluctuations in the inter-arrival time of packets, as exemplified by the Water Cooler Effect. We plan to investigate how this sensitivity can be mitigated to increase classification accuracy for certain protocols.

### Future Work

We intend to further examine and augment our feature set to model additional types of server flows. Our technique will be expanded to other transport protocols, particularly those used by peer-to-peer file sharing systems. Other feature sets are in development to model UDP traffic, ICMP traffic, and selected routing protocols.

### Acknowledgments

This research is supported by AFRL grant number F30602-02-2-0217.

### References

[1] 1999 DARPA Intrusion Detection Evaluation Data Set. URL: http://www.ll.mit.edu/IST/ideval/data/1999/1999_data_index.html.

[2] RFC 1700: Assigned Port Numbers. URL: ftp://ftp.internic.net/rfc/rfc1700.txt.

[3] RFC 793 - Transmission Control Protocol. URL: ftp://ftp.internic.net/rfc/rfc0793.txt.

[4] Testing Intrusion Detection Systems: A Critique of the 1998 and 1999 DARPA Intrusion Detection System Evaluations as Performed by Lincoln Laboratory. ACM Transactions on Information and System Security (TISSEC), 3(4):262–294, 2000. ISSN 1094-9224.

[5] S. Barbara and S. Jajodia. Applications of Data Mining in Computer Security. Kluwer Academic Publishers, 2002.

[6] K. Bennett and C. Campbell. Support Vector Machines: Hype or Hallelujah? SIGKDD Explorations, 2:1–13, 2000.

[7] J. Boxmeyer. ONCTec - List of Possible Trojan/Backdoor Port Activity. ONCTek, LLC. URL: http://www.onctek.com/trojanports.html.

[8] Cornell University Student Assembly Committee on Information and Technologies and ResNet. Cornell Internet Usage Statistics. URL: http://www.cit.cornell.edu/computer/students/bandwidth/charts.html.

[9] Thomas E. Daniels. Personal communication, September 2003.

[10] Tom Dunigan and George Ostrouchov. Flow Characterization for Intrusion Detection. Technical Report, Oak Ridge National Laboratory, November 2000.

[11] Y. Freund. Boosting a Weak Learning Algorithm by Majority. Information and Computation, 121(2):256–285, 1995.

[12] Saul Hansell. E-mail’s Backdoor Open to Spammers. New York Times, May 20, 2003.

[13] iNetPrivacy Software Inc. Anti-Firewall. URL: http://www.antifirewall.com/intro.htm.

[14] Internet Technical Resources. Traffic Statistics. URL: http://www.cs.columbia.edu/~hgs/internet/traffic.html.

[15] G. H. Kim and G. Spafford. The Design and Implementation of Tripwire: A File System Integrity Checker. In ACM Conference on Computer and Communications Security, pages 18–29, 1994. URL: citeseer.nj.nec.com/article/kim94design.html.

[16] T. Lane and C. E. Brodley. Temporal Sequence Learning and Data Reduction for Anomaly Detection. In Proceedings of the Fifth ACM Conference on Computer and Communications Security, pages 150–158. Association for Computing Machinery, Nov 1998.

[17] T. Lane and C. E. Brodley. Temporal Sequence Learning and Data Reduction for Anomaly Detection. ACM Transactions on Computer Security, 2(3):295–331, 1999.

[18] W. Lee and S. Stolfo. A Framework for Constructing Features and Models for Intrusion Detection Systems. ACM Transactions on Information and System Security, 3(4):227–261, November 2000.

[19] M. Mahoney and P. K. Chan. PHAD: Packet Header Anomaly Detection for Identifying Hostile Network Traffic. Technical Report CS-2001-4, Florida Tech, 2001.

[20] Evangelos P. Markatos. Tracing a Large-Scale Peer-to-Peer System: An Hour in the Life of Gnutella. Technical Report 298, 2001. URL: citeseer.nj.nec.com/markatos01tracing.html.

[21] T. Miller. Detecting Loadable Kernel Modules (LKM). URL: http://www.incident-response.org/LKM.htm.

[22] N. Murilo and K. Steding-Jessen. chkrootkit: A Tool that Locally Checks for Signs of a Rootkit. URL: http://www.chkrootkit.org/.

[23] NetScreen Technologies, Inc. NetScreen-5000 Series. URL: http://www.netscreen.com/products/datasheets/ds_ns_5000.jsp.

[24] Captus Networks. Captus IPS 4000 Series. URL: http://www.captusnetworks.com/.

[25] Packeteer, Inc. Packeteer PacketShaper. URL: http://www.packeteer.com/resources/prod-sol/PSDS.pdf.

[26] P. A. Porras and P. G. Neumann. EMERALD: Event Monitoring Enabling Responses to Anomalous Live Disturbances. In Proc. 20th NIST-NCSC National Information Systems Security Conference, pages 353–365, 1997. URL: http://citeseer.nj.nec.com/porras97emerald.html.

[27] J. R. Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA, 1993.

[28] Ross Quinlan. Data Mining Tools See5 and C5.0. URL: http://www.rulequest.com/see5-info.html.

[29] M. Roesch and C. Green. Snort - The Open Source Network Intrusion Detection System. URL: http://www.snort.org/.

[30] Robert E. Schapire. A Brief Introduction to Boosting. In IJCAI, pages 1401–1406, 1999. URL: citeseer.nj.nec.com/schapire99brief.html.

[31] Sharman Networks Ltd. Kazaa Media. URL: http://www.kazaa.com/us/.

[32] E. Skoudis. Counter Hack: A Step-by-Step Guide to Computer Attacks and Effective Defenses. Prentice Hall, 2002.

[33] J. St. Sauver. Percentage of Total Internet2 Traffic Consisting of Kazaa/Morpheus/FastTrack - University of Oregon. In Collaborative Computing in Higher Education: Peer-to-Peer and Beyond Workshop. URL: http://darkwing.uoregon.edu/~joe/kazaa.html.

[34] Stampede Technologies, Inc. TurboGold Enterprise Edition. URL: http://www.stampede.com/productsclienttoserverfeaturesTraffic.html.

[35] K. M. C. Tan and B. S. Collie. Detection and Classification of TCP/IP Network Services. In Proceedings of the Thirteenth Annual Computer Security Applications Conference, pages 99–107, San Diego, California, December 1997.

[36] Carol Taylor and Jim Alves-Foss. NATE: Network Analysis of Anomalous Traffic Events, a Low-Cost Approach. In Proceedings of the 2001 Workshop on New Security Paradigms, pages 89–96. ACM Press, 2001. ISBN 1-58113-457-6.

---

**Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003)**  
1063-9527/03 $17.00 © 2003 IEEE  
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25, 2021, at 07:48:39 UTC from IEEE Xplore. Restrictions apply.