### 4. Proposed Methods for Robust Detection of Audio Attacks

We demonstrate that the proposed methods can learn general features capable of distinguishing machine-induced audio from genuine speech, thereby achieving robust detection of various types of audio attacks.

### 7.5 Ablation Study

#### Impact of Involved Channels
To investigate the impact of the number of involved channels on the detection performance, we trained a group of models on genuine and replayed audio data recorded using device 2. We varied the number of input audio channels and measured the resulting recognition accuracy and Equal Error Rate (EER). As shown in Figure 11, the recognition accuracy increases as more channels are involved. Specifically, the EER decreased from 17.1% to 11.0% when using four channels. These results validate the effectiveness and benefits of using multiple channel audio for audio attack detection.

#### Impact of Phase Information
To examine the impact of phase information on the system, we modified the structure of the proposed Type I network to use only magnitude spectrograms and evaluated its performance. The results showed recognition accuracies of 96.3%, 87.9%, and 73.1%, with corresponding EERs of 8.6%, 11.4%, and 29.2% for devices 1, 2, and 3, respectively. Compared to the model that uses both magnitude and phase spectrograms, the average EER increased by 38.8%. This result confirms that phase spectrograms provide complementary information, enhancing the performance of audio attack detection.

### 7.6 Model Interpretability Analysis

We further investigated the interpretability of our approach by visualizing the saliency map and learned representations of the model.

#### Visualization of Saliency Map
We used the gradient-weighted class activation map (Grad-CAM) to visualize the decision-making process of the deep learning model. Grad-CAM highlights important regions in the input feature map, allowing us to see where the model focuses its attention. Figure 12 shows two examples of Grad-CAM generated from our model. The three columns from left to right represent the magnitude spectrogram of the input, the generated CAM image, and the CAM overlaid on the spectrogram. The model primarily focuses on the low-frequency region, with some attention also paid to high-frequency noises. These findings align with previous studies on discriminative frequency regions for replay attack detection [9, 12, 76], demonstrating the effectiveness of our learning-based approach.

#### Visualization of Learned Representations
To explore the learned representations, we randomly selected 20 audio samples from genuine speech and each type of audio attack recorded using device 1. We computed the output of the first layer in the classifier of our Type I model as embeddings. We then applied Principal Component Analysis (PCA) to reduce the dimensionality of each embedding to 100 and used t-distributed Stochastic Neighbor Embedding (t-SNE) to visualize the embeddings on a 2D plane. The visualization result is shown in Figure 13. The figure indicates that genuine and attack audio samples are well-clustered, verifying the model's ability to extract discriminative features. Additionally, although the model was not explicitly trained to distinguish different types of attacks, we observed some patterns between them. Notably, synthesis attacks produced audio samples closest to genuine speech in the learned manifold, indicating that the deep learning-powered speech synthesizer used in our attack implementation can generate highly realistic speech samples.

### 8. Discussion

#### Integration with Intelligent Audio Systems
The developed audio attack detection models can be integrated into commercial intelligent audio systems with minimal or no hardware modifications. These systems include standalone intelligent audio systems (e.g., smart speakers) and mobile intelligent audio systems like smartphones, which often have multiple microphones for stereo recording and noise/reverberation cancellation. Given the similarity in microphone array dimensions between smartphones and the 2-channel device (Google AIY voice kit) used in our experiments, we expect our model to be easily adaptable to smartphone use. The model can be inserted at the beginning of the inference pipeline to check the legitimacy of the audio input before it reaches the speech or speaker recognition model. Depending on the application scenario and system capabilities, the detection process can be executed via cloud-based services or directly on the device. The proposed Type I model is suitable for cloud servers with sufficient computational power to achieve maximum detection accuracy. For resource-constrained devices, we provide a fast and lightweight Type II network, which is approximately 12× lighter and 1.5× faster than the Type I network, with slightly compromised performance.

#### Potential Evasion
The effectiveness of the proposed model relies on collecting samples from existing audio attack methods for attack profiling. A sophisticated attacker with access to this profile may design adaptive attacks to bypass the system. However, such attacks face several challenges. First, the attacker cannot directly regulate the received signal in its digital form, as the model only accepts signals received through the physical channel (i.e., picked up by the microphone array). Propagation in physical environments leaves traceable patterns in the audio signal. Although injecting signals via other modalities like lasers may reduce over-the-air propagation distortion, such attacks can be defended against by cross-checking signals from all microphone channels. An attacker may also attempt to evade detection by manipulating the sound field with multiple playback devices, but precise control of the signal received by each microphone is difficult due to the low directionality and diffraction of sound. Moreover, these attacks still involve the same recording and playback process, causing distortions in the magnitude and phase domain. Defeating the detection model alone is insufficient, as the attacker must also bypass the actual audio processing model (e.g., speech or speaker recognition model), which remains challenging in practice.

### 9. Conclusion

In this paper, we propose a comprehensive solution for detecting machine-induced audio attacks by leveraging the readily available microphone array on modern intelligent audio systems. We utilize magnitude and phase information derived from multi-channel audio and train a deep learning model to capture the fundamental differences between human speech and adversarial audio launched from playback devices. To improve generalizability to new acoustic environments, we use unsupervised domain adaptation to help the model learn domain-invariant features. We also develop a more compact model suitable for resource-constrained mobile and IoT devices. Extensive experiments on a public multi-channel replay attack dataset and a self-collected advanced audio attack dataset show that the proposed method can achieve an EER as low as 6.6% for detecting a variety of audio attacks and maintain high recognition accuracy even in challenging, environment-independent scenarios.

### Acknowledgments

We would like to thank the anonymous reviewers for their insightful feedback. This work is supported in part by National Science Foundation grants CNS2114161, CNS2114220, CCF1909963, and CCF2028876, and Air Force Research Lab grant FA87501820058.

### References

[1] Google Text-to-Speech. (2020). https://cloud.google.com/text-to-speech/docs

[2] Hidden Voice Commands. (2021). https://www.hiddenvoicecommands.com/demo

[3] The LJ Speech Dataset. (2021). https://keithito.com/LJ-Speech-Dataset/

[4] Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems. (2021). https://sites.google.com/view/practicalhiddenvoice/home

[5] Ultrasonic Dynamic Speaker Vifa. (2021). http://www.avisoft.com/playback/vifa/

[6] ASVspoof 2021: Automatic Speaker Verification Spoofing and Countermeasures Challenge Evaluation Plan. (2021). https://www.asvspoof.org/asvspoof2021/asvspoof2021_evaluation_plan.pdf

[7] Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor, Kevin R. B. Butler, and Joseph Wilson. 2019. Practical Hidden Voice Attacks against Speech and Speaker Recognition Systems. arXiv:cs.CR/1904.05734

[8] Anup Agarwal, Mohit Jain, Pratyush Kumar, and Shwetak Patel. 2018. Opportunistic sensing with MIC arrays on smart speakers for distal interaction and exercise tracking. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6403–6407.

[9] Muhammad Ejaz Ahmed, Il-Youp Kwak, Jun Ho Huh, Iljoo Kim, Taekkyung Oh, and Hyoungshick Kim. 2020. Void: A fast and light voice liveness detection system. In 29th USENIX Security Symposium (USENIX Security 20). USENIX Association, 2685–2702. https://www.usenix.org/conference/usenixsecurity20/presentation/ahmed-muhammad

[10] Jacob Benesty, Jingdong Chen, and Yiteng Huang. 2008. Microphone array signal processing. Vol. 1. Springer Science & Business Media.

[11] Logan Blue, Hadi Abdullah, Luis Vargas, and Patrick Traynor. 2018. 2ma: Verifying voice commands via two microphone authentication. In Proceedings of the 2018 on Asia Conference on Computer and Communications Security (ACM ASIA CCS). 89–100.

[12] Logan Blue, Luis Vargas, and Patrick Traynor. 2018. Hello, is it me you’re looking for? Differentiating between human and electronic speakers for voice interface security. In Proceedings of the 11th ACM Conference on Security & Privacy in Wireless and Mobile Networks. 123–133.

[13] Nicholas Carlini, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang, Micah Sherr, Clay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden voice commands. In 25th {USENIX} Security Symposium ({USENIX} Security 16). 513–530.

[14] Nicholas Carlini and David Wagner. 2018. Audio adversarial examples: Targeted attacks on speech-to-text. In 2018 IEEE Security and Privacy Workshops (SPW). IEEE, 1–7.

[15] Si Chen, Kui Ren, Sixu Piao, Cong Wang, Qian Wang, Jian Weng, Lu Su, and Aziz Mohaisen. 2017. You can hear but you cannot steal: Defending against voice impersonation attacks on smartphones. In 2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS). IEEE, 183–195.

[16] Jian Cheng, Jiaxiang Wu, Cong Leng, Yuhang Wang, and Qinghao Hu. 2017. Quantized CNN: A unified approach to accelerate and compress convolutional networks. IEEE transactions on neural networks and learning systems 29, 10 (2017), 4730–4743.

[17] Phillip L De Leon, Michael Pucher, Junichi Yamagishi, Inma Hernaez, and Ibon Saratxaga. 2012. Evaluation of speaker verification security and detection of HMM-based synthetic speech. IEEE Transactions on Audio, Speech, and Language Processing 20, 8 (2012), 2280–2290.

[18] Chunhua Deng, Siyu Liao, Yi Xie, Keshab K Parhi, Xuehai Qian, and Bo Yuan. 2018. PermDNN: Efficient compressed DNN architecture with permuted diagonal matrices. In 2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). IEEE, 189–202.

[19] Huan Feng, Kassem Fawaz, and Kang G Shin. 2017. Continuous authentication for voice assistants. In Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking. 343–355.

[20] Yaroslav Ganin and Victor Lempitsky. 2015. Unsupervised domain adaptation by backpropagation. In International conference on machine learning. PMLR, 1180–1189.

[21] Yang Gao, Yincheng Jin, Jagmohan Chauhan, Seokmin Choi, Jiyang Li, and Zhanpeng Jin. 2021. Voice In Ear: Spoofing-Resistant and Passphrase-Independent Body Sound Authentication. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 1 (2021), 1–25.

[22] Yuan Gong, Jian Yang, Jacob Huber, Mitchell MacKnight, and Christian Poellabauer. 2019. ReMASC: Realistic replay attack corpus for voice controlled systems. arXiv preprint arXiv:1904.03365 (2019).

[23] Yuan Gong, Jian Yang, and Christian Poellabauer. 2020. Detecting Replay Attacks Using Multi-Channel Audio: A Neural Network-Based Method. IEEE Signal Processing Letters 27 (2020), 920–924.

[24] Cemal Hanilçi. 2017. Features and classifiers for replay spoofing attack detection. In 2017 10Th international conference on electrical and electronics engineering (ELECO). IEEE, 1187–1191.

[25] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, and Andrew Y. Ng. 2014. Deep Speech: Scaling up end-to-end speech recognition. arXiv:cs.CL/1412.5567

[26] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770–778.

[27] Yitao He, Junyu Bian, Xinyu Tong, Zihui Qian, Wei Zhu, Xiaohua Tian, and Xinbing Wang. 2019. Canceling inaudible voice commands against voice control systems. In The 25th Annual International Conference on Mobile Computing and Networking. 1–15.

[28] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 (2017).

[29] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. 2017. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition. 4700–4708.

[30] Shehzeen Hussain, Paarth Neekhara, Shlomo Dubnov, Julian McAuley, and Farinaz Koushanfar. 2021. WaveGuard: Understanding and Mitigating Audio Adversarial Examples. arXiv preprint arXiv:2103.03344 (2021).

[31] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).

[32] Tomi Kinnunen, Md Sahidullah, Héctor Delgado, Massimiliano Todisco, Nicholas Evans, Junichi Yamagishi, and Kong Aik Lee. 2017. The ASVspoof 2017 challenge: Assessing the limits of replay spoofing attack detection. (2017).

[33] Phillip L De Leon, Bryan Stewart, and Junichi Yamagishi. 2012. Synthetic speech discrimination using pitch pattern statistics derived from image analysis. In Thirteenth Annual Conference of the International Speech Communication Association.

[34] En Li, Liekang Zeng, Zhi Zhou, and Xu Chen. 2019. Edge AI: On-demand accelerating deep neural network inference via edge computing. IEEE Transactions on Wireless Communications 19, 1 (2019), 447–457.

[35] Zhuohang Li, Cong Shi, Yi Xie, Jian Liu, Bo Yuan, and Yingying Chen. 2020. Practical adversarial attacks against speaker recognition systems. In Proceedings of the 21st International Workshop on Mobile Computing Systems and Applications. 9–14.

[36] Zhuohang Li, Yi Wu, Jian Liu, Yingying Chen, and Bo Yuan. 2020. AdvPulse: Universal, Synchronization-free, and Targeted Audio Adversarial Attacks via Subsecond Perturbations. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security. 1121–1134.

[37] Meng Liu, Longbiao Wang, Jianwu Dang, Seiichi Nakagawa, Haotian Guan, and Xiangang Li. 2019. Replay attack detection using magnitude and phase information with attention-based adaptive filters. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6201–6205.

[38] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. 2018. Rethinking the value of network pruning. arXiv preprint arXiv:1810.05270 (2018).

[39] Dibya Mukhopadhyay, Maliheh Shirvanian, and Nitesh Saxena. 2015. All your voices are belong to us: Stealing voices to fool humans and machines. In European Symposium on Research in Computer Security. Springer, 599–621.

[40] Alan V Oppenheim, John R Buck, and Ronald W Schafer. 2001. Discrete-time signal processing. Vol. 2. Upper Saddle River, NJ: Prentice Hall.

[41] Nirupam Roy, Sheng Shen, Haitham Hassanieh, and Romit Roy Choudhury. 2018. Inaudible voice commands: The long-range attack and defense. In 15th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 18). 547–560.

[42] Md Sahidullah, Tomi Kinnunen, and Cemal Hanilçi. 2015. A comparison of features for synthetic speech detection. (2015).

[43] Jon Sanchez, Ibon Saratxaga, Inma Hernaez, Eva Navas, Daniel Erro, and Tuomo Raitio. 2015. Toward a universal synthetic speech spoofing detection using phase information. IEEE Transactions on Information Forensics and Security 10, 4 (2015), 810–820.

[44] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks.