Certainly! Here is the optimized version of your text, with improved clarity, coherence, and professionalism:

---

### Timeout Values in Dynamic Environments

Fixed timeout values are often ineffective in highly dynamic environments, such as call processing. More sophisticated and adaptive schemes that can adjust the timeout dynamically based on current system activity are required. Our technique enables rapid detection of client hangs, facilitating quick recovery.

### Confidence Intervals and Observations

Confidence intervals are calculated assuming a binomial distribution. For outcome categories with a small number of observations, the tables provide the raw number of observed cases.

### Error Injection Campaigns

The number of runs per error injection campaign varies (i.e., it is not always 800) because we exclude experiments where the application fails to start due to an error.

### Table 7: Cumulative Results from Directed Injection to Control Flow Instructions

| Category | Without PECOS | With PECOS |
|----------|----------------|-------------|
| **Without Audit** | 579 (40.5-59.5)% | 53% (48.5-59.5)% |
| **With Audit** | 8% (1-4)% | 83% (79-87)% |

**Note:** NIA (Not In Application)

### Detailed Breakdown

| Category | Without PECOS | With PECOS |
|----------|----------------|-------------|
| **Without Audit** | 579 (40.5-59.5)% | 53% (48.5-59.5)% |
| **With Audit** | 8% (1-4)% | 83% (79-87)% |
| **Total Errors** | 777 | 738 |
| **Client+Database (Error Mix)** | 35% (0.25*28 + 0.75*37) | 57% (12+45) 37% |
| **Without PECOS** | 33% (26+7) 87% (85+2) 73% | 58% (7+49+2) 87% 42% 80% |
| **Total Errors** | 787 | 800 |

### Improving Coverage

To enhance overall coverage, it is essential to implement mechanisms for detecting errors in the data flow of the client.

### Conclusions

This paper presents the design, implementation, and evaluation of a framework for providing data and control flow error detection and recovery in a wireless call-processing environment. The data audit subsystem is responsible for detecting and correcting errors in the database, while a preemptive control flow checking technique, PECOS, protects the call-processing clients from control flow errors. The effectiveness of these techniques was evaluated through detailed error injection experiments.

The results show that the data audit subsystem successfully detected about 85% of the errors injected into the database. Despite this, more than 13% of the database corruptions propagated and affected the clients. PECOS significantly reduced the incidence of process crashes and hangs for control flow injections to the call-processing clients. Even with PECOS present, about 8% of the client errors resulted in incorrect data being written to the database. A combined study of PECOS and data audits shows a coverage of 80%, indicating that data flow errors are a key reason for error escapes. Future work should include the development of adaptive techniques for detecting errors in the data flow of applications.

### Acknowledgments

This work was supported in part by NSF grants (CCR-9902026 and CCR-0086096ITR), in part by a grant from Motorola Inc. as part of the Motorola Center for Communications, and in part by JPL under grant NASAJPL-961345. We thank P. Jones, J. Xu, W. Gu, and S. Narayanaswamy for developing the error injectors used in the experiments.

### References

1. Z. Alkhalifa, et al., “Design and Evaluation of System-Level Checks for On-line Control Flow Error Detection,” IEEE Transactions on Parallel and Distributed Systems, Vol. 10, No. 6, pp. 627-641, June 1999.
2. S. Bagchi, “Hierarchical Error Detection in a SIFT Environment,” Ph.D. Thesis, Univ. of Illinois, 2000.
3. F. V. Brasiliero, et al., “Implementing Fail-Safe Nodes for Distributed Systems,” IEEE Transactions on Computers, Vol. 45, No. 11, pp. 1226-1238, 1996.
4. D. Costa, T. Rilho, H. Madeira, “Joint Evaluation of Performance and Robustness of a COTS DBMS through Fault-Injection,” in Proc. Int. Conference on Dependable Systems and Networks, 2000, pp. 251-260.
5. M. Ernst, et al., “Dynamically Discovering Likely Program Invariants to Support Program Evolution,” Proc. 21st International Conference on Software Engineering, pp. 213-224, 1999.
6. G. Haugk, et al., “The 5ESS Switching System: Maintenance Capabilities,” AT&T Technical Journal, Vol. 64, No. 6, 1985, pp. 1385-1416.
7. G. Kanawati, N. Kanawati, J. Abraham, “FERRARI: A Flexible Software-Based Fault and Error Injection System,” IEEE Trans. on Computers, Vol. 44, No. 2, pp. 248-260, February 1995.
8. H. Levendel, Private communication, May 1999.
9. Y. Liu, “Database Error Detection and Recovery in a Wireless Network Controller,” M.S. Thesis, Univ. of Illinois, 2000.
10. H. Madeira, J. G. Silva, “On-Line Signature Learning and Checking,” Proc. 2nd IFIP Working Conf. on Dependable Computing for Critical Applications, pp. 170-177, 1991.
11. A. Mahmood, E.J. McCluskey, “Concurrent Error Detection Using Watchdog Processors—A Survey,” IEEE Trans. on Computers, Vol. 37, No. 2, pp. 160-174, 1988.
12. T. Michel, R. Leveugle, G. Saucier, “A New Approach to Control Flow Checking without Program Modification,” Proc. 21st Symposium on Fault-Tolerant Computing, pp. 334-341, 1991.
13. G. Miremadi, et al., “Two Software Techniques for On-Line Error Detection,” Proc. 22nd Int. Symp. on Fault-Tolerant Computing, pp. 328-335, 1992.
14. G. Miremadi, et al., “Use of Time and Address Signatures for Control Flow Checking,” Proc. 11th IFIP Working Conf. on Dependable Computing for Critical Applications, pp. 113-124, 1995.
15. J. Ohlsson, M. Rimen, U. Gunneflo, “A Study of the Effects of Transient Fault Injection into a 32-bit RISC with Built-in Watchdog,” Proc. 22nd Int. Symposium on Fault-Tolerant Computing, pp. 316-325, 1991.
16. M. Saharatnam, O. Torhjomsen, S. Hvasshovd, “Evaluating the Effectiveness of Fault Tolerance in Replicated Database Management Systems,” Proc. 29th Int. Symposium on Fault-Tolerant Computing, pp. 306-313, 1999.
17. M.A. Schuette, J.P. Shen, “Processor Control Flow Monitoring Using Signatured Instruction Streams,” IEEE Transactions on Computers, Vol. C-36, No. 3, pp. 264-276, 1987.
18. D.T. Stott, B. Floering, Z. Kalharczyk, R.K. Iyer, “Dependability Assessment in Distributed Systems with Lightweight Fault Injectors in NITAPE,” Proc. 4th Int. Computer Performance and Dependability Symposium, pp. 91-100, 2000.
19. D. J. Taylor, D. E. Morgan, J. P. Black, “Redundancy in Data Structures: Improving Software Fault Tolerance,” IEEE Transactions on Software Engineering, Vol. 6, No. 6, pp. 585-594, 1980.
20. D. J. Taylor, J. P. Black, “Guidelines for Storage Structure Error Correction,” Proc. 15th Int. Symposium on Fault-Tolerant Computing, pp. 20-22, 1985.
21. S. Upadhyaya, B. Ramamurthy, “Concurrent Process Monitoring with No Reference Signatures,” IEEE Transactions on Computers, Vol. 43, No. 4, pp. 475-480, 1994.
22. S.S. Yau, F-Ch. Chen, “An Approach to Concurrent Control Flow Checking,” IEEE Trans. on Software Engineering, Vol. SE-6, No. 2, pp. 126-137, 1980.
23. K. Wilken, J.P. Shen, “Continuous Signature Monitoring: Low-Cost Concurrent Detection of Processor Errors,” IEEE Transactions on Computer-Aided Design, pp. 629-641, 1990.
24. Sybase Adaptive Server System Administration Guide, Chapter 25, <http://manuals.sybase.com:80/onlinebooks/group-as/asg1200e/asesag>
25. TimesTen 4.0 Datasheet, <http://www.timesten.com/products/ttdatasheet.html>
26. Oracle8 Server Utilities, Release 8.0, Chapter 10, <http://pundit.bus.utexas.edu/oradocs/server803/A54652~0>

---

This version is more structured, clear, and professional, making it easier to read and understand.