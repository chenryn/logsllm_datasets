### DREAM++ and Semantic Naming

Yakdan et al. [5] introduced DREAM++, a tool that employs a set of heuristics derived from feedback from reverse engineers (REs) to generate semantically meaningful names for decompiled variables, significantly enhancing code readability. An improvement to this approach could involve expanding beyond DREAM++’s preconfigured set of readability transformations by observing and learning from developer input through renaming and annotations. This semantic learning problem presents a significant challenge for the implementation of G5, as it likely requires the analysis to consider subtle nuances of the program context.

### Exploratory Visual Analysis (EVA) in RE Tool Design

RE tool designers should consider the literature on exploratory visual analysis (EVA). In addition to the guidelines drawn directly from our results, we believe RE tool designers can draw inspiration from EVA. EVA addresses situations where analysts visually search large datasets to summarize their main characteristics. Based on a review of the EVA literature, Battle and Heer [91] define a process similar to the one observed in REs, starting with a high-level overview, generating hypotheses, and iteratively refining these hypotheses through a mix of scanning and detailed analysis. Furthermore, Shneiderman [92] divides EVA into three phases: "Overview first, zoom and filter, then details-on-demand." While techniques from this field may not be directly applicable due to differences in the underlying data, these similarities suggest that insights from EVA could guide the development of RE tools, including methods for data exploration [93–96], interaction [97–100], and predicting future analysis questions [101–104].

### Conclusion

Our goal is to model REs' processes carefully to support better design of RE tools. To achieve this, we conducted a semi-structured observational interview study involving 16 professional REs. We found that RE involves three distinct phases: overview, sub-component scanning, and focused experimentation. Reverse engineers use a variety of manual and automated approaches in each phase, often combining methods to accomplish specific tasks (e.g., static analysis alongside a debugger). In the first two phases (overview and sub-component scanning), REs typically use static techniques (e.g., examining control-flow graphs), but switch to dynamic techniques (e.g., debugging or dynamic analysis) in the last phase (focused experimentation). Based on our findings, we proposed five design guidelines for RE tools. We believe our model will help in the design and development of RE tools that more closely match the RE process.

### Acknowledgments

We thank Kelsey Fulton and the anonymous reviewers for their valuable feedback; BinaryNinja, the two bug-bounty platform companies, and the many CTF teams that supported our recruitment efforts; and Jordan Wiens for providing valuable insights into the world of reverse engineering. This research was supported in part by a UMIACS contract under the partnership between the University of Maryland and DoD, and by a Google Research Award.

### References

[1] D. Votipka, R. Stevens, E. M. Redmiles, J. Hu, and M. L. Mazurek, “Hackers vs. testers: A comparison of software vulnerability discovery processes,” in IEEE S&P ’18, May 2018, pp. 374–391.
[2] M. Ceccato, P. Tonella, C. Basile, B. Coppens, B. De Sutter, P. Falcarin, and M. Torchiano, “How professional hackers understand protected code while performing attack tasks,” in ICPC ’17. Piscataway, NJ, USA: IEEE Press, 2017, pp. 154–164. [Online]. Available: https://doi.org/10.1109/ICPC.2017.2
[3] E. Eilam, *Reversing: secrets of reverse engineering*. John Wiley & Sons, 2011.
[4] D. Fraze, “Computer and Humans Exploring Software Security (CHESS),” DARPA, 2017, [Online]. Available: https://www.darpa.mil/program/computers-and-humans-exploring-software-security (Accessed 05-31-2019).
[5] K. Yakdan, S. Dechand, E. Gerhards-Padilla, and M. Smith, “Helping johnny to analyze malware: A usability-optimized decompiler and malware analysis user study,” in IEEE S&P ’16, May 2016, pp. 158–177.
[6] Y. Shoshitaishvili, M. Weissbacher, L. Dresel, C. Salls, R. Wang, C. Kruegel, and G. Vigna, “Rise of the hacrs: Augmenting autonomous cyber reasoning systems with human assistance,” in CCS ’17. ACM, 2017.
[7] N. Rutar, C. B. Almazan, and J. S. Foster, “A comparison of bug finding tools for java,” in ISSRE ’04. IEEE Computer Society, 2004, pp. 245–256.
[8] D. Baca, B. Carlsson, K. Petersen, and L. Lundberg, “Improving software security with static automated code analysis in an industry setting.” *Software: Practice and Experience*, vol. 43, no. 3, pp. 259–279, 2013.
[9] A. Doupé, M. Cova, and G. Vigna, “Why johnny can’t pentest: An analysis of black-box web vulnerability scanners,” in DIMVA ’10. Springer-Verlag, 2010, pp. 111–131.
[10] A. Austin and L. Williams, “One technique is not enough: A comparison of vulnerability discovery techniques,” in ESEM ’11. IEEE Computer Society, 2011, pp. 97–106.
[11] N. Antunes and M. Vieira, “Comparing the effectiveness of penetration testing and static code analysis on the detection of SQL injection vulnerabilities in web services,” in PRDC ’09. IEEE Computer Society, 2009, pp. 301–306.
[12] L. Suto, “Analyzing the effectiveness and coverage of web application security scanners,” BeyondTrust, Inc, Tech. Rep., 2007. [Online]. Available: https://www.beyondtrust.com/resources/white-paper/analyzing-the-effectiveness-and-coverage-of-web-application-security-scanners/
[13] ——, “Analyzing the accuracy and time costs of web application security scanners,” BeyondTrust, Inc, Tech. Rep., 2010. [Online]. Available: https://www.beyondtrust.com/wp-content/uploads/Analyzing-the-Accuracy-and-Time-Costs-of-Web-Application-Security-Scanners.pdf
[14] G. McGraw and J. Steven, “Software [in]security: Comparing apples, oranges, and aardvarks (or, all static analysis tools are not created equal),” Cigital, 2011, (Accessed 02-26-2017). [Online]. Available: http://www.informit.com/articles/article.aspx?p=1680863
[15] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth, “Taintdroid: An information-flow tracking system for realtime privacy monitoring on smartphones,” in OSDI ’10. Berkeley, CA, USA: USENIX Association, 2010, pp. 393–407. [Online]. Available: http://dl.acm.org/citation.cfm?id=1924943.1924971
[16] C. Cadar, D. Dunbar, D. R. Engler et al., “Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs.” in OSDI ’08, vol. 8, 2008, pp. 209–224.
[17] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley, “Unleashing mayhem on binary code,” in IEEE S&P ’12. IEEE Computer Society, 2012, pp. 380–394.
[18] N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang, J. Corbetta, Y. Shoshitaishvili, C. Kruegel, and G. Vigna, “Driller: Augmenting fuzzing through selective symbolic execution,” in NDSS ’16, no. 2016. Internet Society, 2016, pp. 1–16.
[19] Hex-Rays, “IDA: About,” 2019, (Accessed 05-30-2019). [Online]. Available: https://www.hex-rays.com/products/ida/
[20] Vector35, “Binary.ninja: A reverse engineering platform,” 2019, (Accessed 05-30-2019). [Online]. Available: https://binary.ninja/
[21] Synopsys, “Coverity Scan - Static Analysis,” 2019, (Accessed 05-30-2019). [Online]. Available: https://scan.coverity.com/
[22] ForAllSecure, “ForAllSecure,” 2019, (Accessed 05-30-2019). [Online]. Available: https://forallsecure.com/
[23] Hex-Rays, “Plug-in Contest 2018: Hall of Fame,” 2019, (Accessed 05-30-2019). [Online]. Available: https://www.hex-rays.com/contests/2018/index.shtml
[24] Vector35, “Vector35/community-plugins,” 2019, (Accessed 05-30-2019). [Online]. Available: https://github.com/Vector35/community-plugins/tree/master/plugins
[25] B. Shneiderman and C. Plaisant, *Designing the User Interface: Strategies for Effective Human-Computer Interaction*, 4th ed. Pearson, 2016.
[26] S. Letovsky, “Cognitive processes in program comprehension,” in ESP ’86. Norwood, NJ, USA: Ablex Publishing Corp., 1986, pp. 58–79. [Online]. Available: http://dl.acm.org/citation.cfm?id=21842.28886
[27] T. D. LaToza, D. Garlan, J. D. Herbsleb, and B. A. Myers, “Program comprehension as fact finding,” in ESEC/FSE ’07. New York, NY, USA: ACM, 2007, pp. 361–370. [Online]. Available: http://doi.acm.org/10.1145/1287624.1287675
[28] V. Arunachalam and W. Sasso, “Cognitive processes in program comprehension: An empirical analysis in the context of software reengineering,” *Journal on System Software*, vol. 34, no. 3, pp. 177–189, Sep. 1996. [Online]. Available: http://dx.doi.org/10.1016/0164-1212(95)00074-7
[29] T. Roehm, R. Tiarks, R. Koschke, and W. Maalej, “How do professional developers comprehend software?” in ICSE ’12. Piscataway, NJ, USA: IEEE Press, 2012, pp. 255–265. [Online]. Available: http://dl.acm.org/citation.cfm?id=2337223.2337254
[30] L. Gugerty and G. Olson, “Debugging by skilled and novice programmers,” in CHI ’86. New York, NY, USA: ACM, 1986, pp. 171–174. [Online]. Available: http://doi.acm.org/10.1145/22627.22367
[31] R. Brooks, “Towards a theory of the comprehension of computer programs,” *International Journal of Man-Machine Studies*, vol. 18, no. 6, pp. 543 – 554, 1983. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0020737383800315
[32] A. Von Mayrhauser and A. Vans, “Industrial experience with an integrated code comprehension model,” *Software Engineering Journal*, vol. 10, no. 5, pp. 171–182, 1995.
[33] F. Detienne, “Chapter 3.1 - expert programming knowledge: A schema-based approach,” in *Psychology of Programming*. London: Academic Press, 1990, pp. 205 – 222. [Online]. Available: http://www.sciencedirect.com/science/article/pii/B9780123507723500185
[34] A. J. Ko, B. A. Myers, M. J. Coblenz, and H. H. Aung, “An exploratory study of how developers seek, relate, and collect relevant information during software maintenance tasks,” *IEEE Transactions on Software Engineering*, vol. 32, no. 12, pp. 971–987, Dec. 2006. [Online]. Available: http://dx.doi.org/10.1109/TSE.2006.116
[35] N. Pennington, “Stimulus structures and mental representations in expert comprehension of computer programs,” *Cognitive Psychology*, vol. 19, no. 3, pp. 295 – 341, 1987. [Online]. Available: http://www.sciencedirect.com/science/article/pii/0010028587900077
[36] D. C. Littman, J. Pinto, S. Letovsky, and E. Soloway, “Mental models and software maintenance,” in ESP ’86. Norwood, NJ, USA: Ablex Publishing Corp., 1986, pp. 80–98. [Online]. Available: http://dl.acm.org/citation.cfm?id=21842.28887
[37] E. J. Chikofsky and J. H. Cross, “Reverse engineering and design recovery: a taxonomy,” *IEEE Software*, vol. 7, no. 1, pp. 13–17, Jan 1990.
[38] P. O’Kane, S. Sezer, and K. McLaughlin, “Obfuscation: The hidden malware,” *IEEE Security and Privacy*, vol. 9, no. 5, pp. 41–47, Sep. 2011.
[39] M. Ligh, S. Adair, B. Hartstein, and M. Richard, *Malware analyst’s cookbook and DVD: tools and techniques for fighting malicious code*. John Wiley & Sons, 2010.
[40] A. Harper, S. Harris, J. Ness, C. Eagle, G. Lenkey, and T. Williams, *Gray hat hacking: the ethical hacker’s handbook*, 3rd ed. McGraw-Hill Education, 2018.
[41] G. A. Klein, “Recognition-primed decisions,” *Advances in man-machine systems research*, vol. 5, pp. 47–92, 1989.
[42] G. A. Klein, R. Calderwood, and A. Clinton-Cirocco, “Rapid decision making on the fire ground,” in HFES ’86, vol. 30, no. 6. Sage Publications Sage CA: Los Angeles, CA, 1986, pp. 576–580.
[43] J. A. Cannon-Bowers and E. E. Salas, *Making decisions under stress: Implications for individual and team training*. American psychological association, 1998.
[44] G. A. Klein, R. Calderwood, and D. Macgregor, “Critical decision method for eliciting knowledge,” ICSMCCCS ’89, vol. 19, no. 3, pp. 462–472, 1989.
[45] G. A. Klein, *Sources of power: How people make decisions*. MIT press, 2017.
[46] A. Bryant, “Understanding how reverse engineers make sense of programs from assembly language representations,” Ph.D. dissertation, US Air Force Institute of Technology, 01 2012.
[47] K. G. Ross, G. A. Klein, P. Thunholm, J. F. Schmitt, and H. C. Baxter, “The recognition-primed decision model,” Army Combined Arms Center Military Review, Tech. Rep., 2004.
[48] C. E. Zsambok and G. Klein, *Naturalistic decision making*. Psychology Press, 2014.
[49] G. A. Klein and C. P. Brezovic, “Design engineers and the design process: Decision strategies and human factors literature,” *Human Factors in Ergonomics and Society*, vol. 30, no. 8, pp. 771–775, 1986.
[50] G. Klein, D. Klinger, and T. Miller, “Using decision requirements to guide the design process,” in ICSMCCCS ’97, vol. 1, Oct 1997, pp. 238–244 vol.1.
[51] J. Rasmussen, “Skills, rules, and knowledge; signals, signs, and symbols, and other distinctions in human performance models,” ICSMC-CCS ’83, vol. SMC-13, no. 3, pp. 257–266, May 1983.
[52] T. Yamaguchi, H. Nitta, J. Miyamichi, and T. Takagi, “Distributed sensory intelligence architecture for human centered ITS,” in IECON ’00, vol. 1, Oct 2000, pp. 509–514 vol.1.
[53] H. Ohno, “Analysis and modeling of human driving behaviors using adaptive cruise control,” in IECON ’00, vol. 4, Oct 2000, pp. 2803–2808 vol.4.
[54] M. A. J. Arne Worm, “Information-centered human-machine systems analysis for tactical command and control systems modeling and development,” in ICSMCCCS ’00, vol. 3, Oct 2000, pp. 2240–2246 vol.3.
[55] S. Akbari and M. B. Menhaj, “A new framework of a decision support system for air to air combat tasks,” in ICSMCCCS ’00, vol. 3, Oct 2000, pp. 2019–2022 vol.3.
[65] J. Annett, “Hierarchical task analysis,” *Handbook of cognitive task design*, vol. 2, pp. 17–35, 2003.
[66] A. Strauss and J. Corbin, *Basics of qualitative research: Techniques*