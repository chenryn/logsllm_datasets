### ISA Dependency and Instruction Format

Table I summarizes the Alpha instruction format. Experiments involving unused bits consistently produced strictly correct results. The validation of faults affecting branch instructions was achieved by examining the simulation's statistical information. For instance, when a fault was introduced into the displacement bits of an instruction and the branch was not taken, the simulation statistics remained unchanged, and the outcome was categorized as strictly correct. Faults in the Ra field may not result in errors if the branch outcome remains the same. When faults altered the displacement field of memory instructions, the application frequently crashed. Similarly, altering the Ra value of a memory instruction often led to crashes, as the base address was read from another register. As expected, when faults were injected into the opcode or function fields, and the resulting opcode or function was not implemented, the benchmarks always terminated due to illegal instructions.

### Decoding Stage Faults

A similar analysis was applied to faults inserted during the decoding stage. Errors affecting the selection of the base for load/store instructions typically caused segmentation faults. An interesting observation is that faults in the decoding stage of the PI algorithm resulted in crashes at nearly half the probability compared to other applications, likely because PI performs minimal data accesses from memory. Errors in the decoding stage generally led to Silent Data Corruptions (SDCs). Correct results could only be produced by faults that altered a squashed instruction or due to inherent, algorithmic application resiliency.

### Execution Stage Faults

Faults introduced in the execution stage, particularly those altering memory access instructions, often led to crashes. At this stage, the virtual address for memory transfers is calculated, and faults that alter the resulting address typically cause segmentation violations. The variation in crash rates among different applications correlated with the percentage of memory operations in the instruction mix. For example, in Knapsack, which heavily uses arrays and pointers, 42% of faults in the execution stage resulted in crashes. In contrast, PI evaluation, with minimal data accesses, suffered almost no crashes. Correct and strictly correct results in the execution stage were often due to faults that were masked during the remaining execution or affected less significant bits of data computations. Faults altering the result of data loads/stores rarely caused crashes, except when they affected the store/load of an address, such as the return address. Overall, data store/load operations exhibited high resiliency, resulting in correct outcomes in 78% of cases. Faults altering the Program Counter (PC) address were almost always fatal, with correct results only occurring when the corrupted PC address was close to the correct one, effectively causing a small forward or backward jump.

### Timing of Fault Injection

The timing of fault injection also influenced the application's behavior. Figure 6 shows the results from three fault injection campaigns, with the horizontal axis representing the normalized timing of fault injection and the vertical axis showing the fraction of experiments resulting in each class of outcomes. "Acceptable" represents the union of correct and strictly correct results. For Monte Carlo PI estimation, the timing of fault injection appeared uncorrelated with application behavior, as the application iteratively produces random numbers, and all iterations similarly affect the final result. Conversely, in Knapsack, later fault injections were more likely to produce acceptable results, as faulty data that did not converge towards the solution was discarded in subsequent iterations. In Jacobi, early faults tended to result in strict correctness, while later faults increased the likelihood of correct results at the expense of strict correctness, given the diagonally dominant input matrix.

### Performance Evaluation of GemFI

To evaluate the overhead of GemFI, we compared the execution time for simulated runs of the benchmarks on both GemFI and the unmodified Gem5 simulator. We measured and compared the simulation time for the part of the application where fault injection was active. Despite activating the fault injection functionality, no actual faults were injected in these experiments to ensure a fair comparison. It is important to note that all GemFI functionality, except the fault injection itself, was activated. The experimental results, shown in Figure 7, indicate an overhead ranging from -0.1% to 3.3%, primarily dependent on the number of instructions simulated with fault injection enabled. This overhead is minimal, and GemFI performed slightly better than Gem5 for PI estimation, though not statistically significant.

### Checkpointing and Speedup

As discussed in Section III-D, GemFI significantly reduces the time for executing simulation campaigns. Figure 8 summarizes the simulation time with and without using the checkpointing capability to fast-forward the simulation to the point where fault injection is activated. Using the checkpointing methodology, the speedup ranged from 3x to 244x (64.5x on average), depending on the ratio of execution time spent on pre- and post-checkpoint code. The third set of bars in Figure 8 shows the execution time of the simulation campaigns on a network of 27 workstations, using the meta-simulation infrastructure discussed in Section III-E. Each workstation, equipped with quad-core Intel Xeon E5520 CPUs at 2.27 GHz and 8 GB RAM, executed four simulations simultaneously, providing an additional speedup of approximately 108x compared to a simple system with checkpoint-based fast forwarding.

### Related Work

Several research groups have evaluated the impact of faults using various approaches, including software fault injection, simulation fault injection, and physical-level fault injection. RIFFLE [9] and MESSALINE [10] inject faults at the pin level, while FIAT [11] and FERRARI [11] implement software-level fault injection. Simulation-based fault injection, such as MEFISTO [12] and VERIFY [13], can model complex systems with high accuracy but face challenges in ensuring realistic models and managing simulation time. Czeck and Siewiorek [15] used bit-flip faults in their simulation model, while Gaisler [16] enhanced the register file fault tolerance by adding ECC bits. In [17], fault injection was performed on simulated processors, enhancing system tolerance with additional hardware support.

GemFI, based on the widely used reconfigurable Gem5 simulator, supports arbitrary fault models and allows users to describe faults in an input file. To our knowledge, GemFI is the first infrastructure that can target specific application areas with minimal changes to the original source code.

### Conclusion

In this paper, we introduced GemFI, a new simulator enabling fault injection of transient, intermittent, and permanent faults. GemFI simulates unreliable environments in full system, cycle-accurate mode, and is easily extensible to support future fault models. Features like checkpointing allow the execution of large-scale fault injection campaigns. Our validation and performance evaluation showed that GemFI produced expected outcomes according to the characteristics of each application, with minimal overhead over Gem5. Future work will extend GemFI to inject faults outside the processor, such as on the processor/memory interconnect and external I/O devices, and enhance it with realistic fault models associating supply voltage (Vdd) with error rates in different system components.

### Acknowledgment

This work was partially supported by the EC within the 7th Framework Program under the FET-Open grant agreement SCoRPiO, grant number 323872.

### References

[1] N. Binkert, B. Beckmann, G. Black, S. K. Reinhardt, A. Saidi, A. Basu, J. Hestness, D. R. Hower, T. Krishna, S. Sardashti, R. Sen, K. Sewell, M. Shoaib, N. Vaish, M. D. Hill, and D. A. Wood, “The Gem5 Simulator,” ACM SIGARCH Computer Architecture News, 2011.
[2] C. R. Yount and D. P. Siewiorek, “A methodology for the rapid injection of transient hardware errors,” IEEE Trans. on Computers, 1996.
[3] J. Ansel, K. Arya, and G. Cooperman, “DMTCP: Transparent Checkpointing for Cluster Computations and the Desktop Proc,” in Proc. of the IEEE International Symposium on Parallel & Distributed Processing (IPDPS), 2009.
[4] A. Skodras, C. Christopoulos, and T. Ebrahimi, “The JPEG 2000 image compression standard,” Proc. of the IEEE International Symposium on Signal Processing (ICSP), 2001.
[5] L. Fan, S. Ma, and F. Wu, “Overview of AVS video standard,” in Proc. of the IEEE International Conference on Multimedia and Expo (ICME), 2004.
[6] C. Bienia and K. Li, “PARSEC 2.0: A New Benchmark Suite for Chip-Multiprocessors,” in Proc. of the Annual Workshop on Modeling, Benchmarking and Simulation (MoBS), 2009.
[7] R. Leveugle, A. Calvez, P. Maistri, and P. Vanhauwaert, “Statistical fault injection: quantified error and confidence,” in Proc. of the Conference & Exhibition on Design, Automation & Test in Europe (DATE), 2009.
[8] S. T. Welstead, Fractal and wavelet image compression techniques. SPIE Optical Engineering Press, 1999.
[9] H. Madeira, M. Rela, F. Moreira, and J. G. Silva, “RIFLE: A general purpose pin-level fault injector,” in Proc. of the European Dependable Computing Conference (EDCC), 1994.
[10] J. Arlat, M. Aguera, L. Amat, Y. Crouzet, J.-C. Fabre, J.-C. Laprie, E. Martins, and D. Powell, “Fault Injection for Dependability Validation: A Methodology and Some Applications,” IEEE Trans. on Software Engineering, 1990.
[11] J. H. Barton, E. W. Czeck, Z. Z. Segall, and D. P. Siewiorek, “Fault Injection Experiments Using FIAT,” IEEE Trans. on Computers, 1990.
[12] E. Jenn, J. Arlat, M. Rimn, J. Ohlsson, and J. Karlsson, “Fault Injection into VHDL Models: The MEFISTO Tool,” in Proc. of the Symposium on Fault-Tolerant Computing (FTCS), 1994.
[13] V. Sieh, O. Tschche, and F. Balbach, “VERIFY: Evaluation of Reliability Using VHDL-Models with Embedded Fault Descriptions,” in Proc. of the Symposium on Fault-Tolerant Computing (FTCS), 1997.
[14] M. Rimén, J. Ohlsson, J. Karlsson, E. Jenn, and J. Arlat, “Design guidelines of a VHDL-based simulation tool for the validation of fault tolerance,” ESPRIT Basic Research Project (PDCS-2), Tech. Rep., 1993.
[15] E. W. Czeck and D. P. Siewiorek, “Effects of transient gate-level faults on program behavior,” in Proc. of the International Symposium on Fault-Tolerant Computing (FTCS), 1990.
[16] J. Gaisler, “A Portable and Fault-Tolerant Microprocessor Based on the SPARC V8 Architecture.” in Proc. of the International Conference on Dependable Systems and Networks (DSN), 2002.
[17] N. J. Wang, J. Quek, T. M. Rafacz, and S. J. Patel, “Characterizing the Effects of Transient Faults on a High-Performance Processor Pipeline,” in Proc. of the International Conference on Dependable Systems and Networks (DSN), 2004.