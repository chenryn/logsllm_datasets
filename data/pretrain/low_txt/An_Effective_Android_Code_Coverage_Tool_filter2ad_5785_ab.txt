### 2. ACVTool Architecture

ACVTool is designed to measure and analyze the degree to which the code of a closed-source Android app is executed during testing, and to collect crash reports generated in the process. The tool instruments an app and measures code coverage at the instruction, method, and class levels. We designed ACVTool to be self-contained, making it easy to integrate with various testing solutions. Additionally, the tool is useful for manual analysis to investigate which parts of a third-party application's code have been executed.

Figure 1 illustrates the main phases of the ACVTool workflow: offline, online, and report generation. These phases are indicated in the upper, lower, and right-most parts of the scheme, respectively. The offline phase involves preprocessing the app before installation and instrumenting it. During the online phase, ACVTool installs the instrumented app and enables data collection during testing. In the report generation phase, ACVTool produces detailed information about code coverage. Below, we describe the workflow of ACVTool in more detail.

#### 2.1 Offline Phase

Instrumenting a third-party app without access to the source code is a challenging task. This requires injecting specific instrumentation bytecode instructions (probes) into the original bytecode. ACVTool is built on Apktool [15], which uses the baksmali disassembler [12] to decompile the app into smali code, a human-readable representation of Android bytecode. We then insert probes that log the execution of the original smali instructions. Afterward, ACVTool rebuilds and signs the new version of the app using apksigner. This allows ACVTool to instrument almost all applications that Apktool can repackage. Moreover, updates to DEX files that introduce new types of bytecode instructions can be handled with minimal effort.

**Smali Code Modification:**
Modifying smali code is not straightforward due to the stack-based architecture of Android. We use a direct instrumentation approach, as previously introduced by Huang et al. [8] and Liu et al. [9], combined with a register management technique. Our approach is more efficient. We optimize the mechanism of registering probe executions by maintaining a binary array. When a probe is executed, it writes a value into the corresponding cell of the binary array. This method ensures minimal runtime overhead. We are currently working on an experiment to precisely evaluate the runtime overhead.

### 3. Evaluation

We extensively tested ACVTool on real-life third-party applications. For brevity, we only report basic evaluation statistics, summarized in Table 1.

**Instrumentation Success Rate:**
For evaluation, we collected all application projects from the popular open-source F-Droid market, which is frequently used for evaluating automated testing tools (e.g., in [10]). Among all projects on F-Droid, we successfully built and launched 448 apps on a device. We also randomly selected 500 apps from the AndroZoo [1] snapshot of the Google Play market, targeting apps released after Android API 22. This sample is representative of real-life third-party apps that may use anti-debugging techniques. Of the 500 selected apps, 398 were launch-able on a device (the rest crashed immediately or gave installation errors). Thus, we tested ACVTool on 846 apps, with an average APK size of 6.8MB.

As shown in Table 1, ACVTool successfully instrumented 97.6% of these apps. Among the failures, 13 apps could not be repackaged by Apktool, and the others produced exceptions during the instrumentation process. We then installed and launched all successfully instrumented apps, finding that 6 apps crashed immediately due to various errors. Therefore, the total instrumentation success rate of ACVTool on our dataset is 96.9%.

**Overhead:**
Table 1 shows that ACVTool introduces a relatively small instrumentation-time overhead (36.2 seconds per app, on average), which is acceptable for the offline part of testing and analysis. We estimated the potential runtime overhead introduced by the added instrumentation code by running the original and repackaged app versions with the same Monkey scripts and comparing the execution timings. For 50 randomly selected apps from our dataset, we found no significant difference in execution time (median time difference less than 0.08 sec, mean difference less than 0.12 sec, standard deviation 0.84 sec), and no unexpected crashes. This experiment suggests that there is no drastic runtime overhead introduced by our instrumentation.

### 4. Demo Details

We plan an interactive demonstration of the entire coverage measurement cycle on real applications. In the demo, we will walk the audience through the ACVTool design and show how the smali code looks before and after injecting the probes.

### 5. Conclusion

We presented a novel tool for black-box code coverage measurement of Android applications. We significantly improved the smali instrumentation technique, achieving an instrumentation success rate of 96.9%, compared to 36% in Huang et al. [8] and 65% in Zhauniarovich et al. [17]. Our implementation is open-source and available to the community.

### Acknowledgements

This research was partially supported by the Luxembourg National Research Fund through grants AFR-PhD-11289380-DroidMod and C15/IS/10404933/COMMA.

### References

[1] K. Allix, T. Bissyandé, J. Klein, and Y. Le Traon. 2016. AndroZoo: Collecting Millions of Android Apps for the Research Community. In Proc. of MSR. ACM, 468–471.
[2] H. Cai and B. Ryder. 2017. DroidFax: A toolkit for systematic characterization of Android applications. In Proc. of ICSME. IEEE, 643–647.
[3] P. Carter, C. Mulliner, M. Lindorfer, W. Robertson, and E. Kirda. 2016. CuriousDroid: Automated user interface interaction for Android application analysis sandboxes. In Proc. of FC. Springer, 231–249.
[4] S. R. Choudhary, A. Gorla, and A. Orso. 2015. Automated test input generation for Android: Are we there yet?. In Proc. of ASE. IEEE/ACM, 429–440.
[5] S. Dashevskyi, O. Gadyatskaya, A. Pilgun, and Y. Zhauniarovich. 2018. POSTER: The Influence of Code Coverage Metrics on Automated Testing Efficiency in Android. In Proc. of CCS.
[6] ELLA. 2016. A Tool for Binary Instrumentation of Android Apps, https://github.com/saswatanand/ella.
[7] Google. 2018. https://source.android.com/devices/tech/dalvik/dalvik-bytecode.
[8] C. Huang, C. Chiu, C. Lin, and H. Tzeng. 2015. Code Coverage Measurement for Android Dynamic Analysis Tools. In Proc. of Mobile Services (MS). IEEE, 209–216.
[9] J. Liu, T. Wu, X. Deng, J. Yan, and J. Zhang. 2017. InsDal: A safe and extensible instrumentation tool on Dalvik byte-code for Android applications. In Proc. of SANER. IEEE, 502–506.
[10] K. Mao, M. Harman, and Y. Jia. 2016. Sapienz: Multi-objective automated testing for Android applications. In Proc. of ISSTA. ACM, 94–105.
[11] K. Moran, M. Linares-Vásquez, C. Bernal-Cárdenas, C. Vendome, and D. Poshyvanyk. 2016. Automatically discovering, reporting and reproducing Android application crashes. In Proc. of ICST.
[12] smali/backsmali. 2018. https://github.com/JesusFreke/smali.
[13] W. Song, X. Qian, and J. Huang. 2017. EHBDroid: Beyond GUI testing for Android applications. In Proc. of ASE. IEEE/ACM, 27–37.
[14] F. Wei, Y. Li, S. Roy, X. Ou, and W. Zhou. 2017. Deep ground truth analysis of current Android malware. In Proc. of DIMVA.
[15] R. Wiśniewski and C. Tumbleson. 2017. Apktool - A tool for reverse engineering 3rd party, closed, binary Android apps. https://ibotpeaches.github.io/Apktool/
[16] Z. Yang, M. Yang, Y. Zhang, G. Gu, P. Ning, and X. S. Wang. 2013. Appintent: Analyzing sensitive data transmission in Android for privacy leakage detection. In Proc. of CCS.
[17] Y. Zhauniarovich, A. Philippov, O. Gadyatskaya, B. Crispo, and F. Massacci. 2015. Towards black box testing of Android apps. In Proc. of SAW at ARES. IEEE, 501–510.

### Figure 2: The ACVTool Code Coverage Report

### Table 1: ACVTool Performance Evaluation

| Parameter                       | Total # Selected Apps | Average APK Size | Instrumented Apps | Healthy Instrumented Apps | Avg. Instrumentation Time (Total per App) |
|---------------------------------|-----------------------|------------------|-------------------|---------------------------|--------------------------------------------|
| F-Droid Benchmark               | 448                   | 3.1MB            | 444 (99.1%)       | 440 (98.2%)               | 24.7 sec                                   |
| Google Play Benchmark           | 398                   | 11.1MB           | 382 (95.9%)       | 380 (95.4%)               | 49.6 sec                                   |
| Total                           | 846                   | 6.8MB            | 97.6%             | 96.9%                     | 36.2 sec                                   |