### Training Process and Simulation Parameters

The training process is influenced by our simulation parameters, specifically the maximum bid price of 0.0955. The chosen maximum bid price, along with the variations in spot market prices, will determine the total number of interruptions of the spot instance, and consequently, the total training time (including interruption times). The spot traces and simulation scripts used in this study are available in the PLINIUS repository.

### Loss Curves and Crash Resilience

Figure 10(c) illustrates the loss curve when there is no crash resilience, meaning the model's state is not saved. With the given simulation parameters, there are two interruptions during the training process. As a result, the training must be resumed from the beginning, leading to an increase in the total number of iterations and the overall training time compared to a crash-resilient system. This highlights the importance of fault tolerance in machine learning scenarios.

### CPU and Memory Overhead

Our mirroring mechanism uses 140 bytes of Persistent Memory (PM) for encryption metadata per layer. The Message Authentication Code (MAC) is 16 bytes, and the Initialization Vector (IV) is 12 bytes, resulting in 28 bytes per encrypted parameter buffer. Each layer contains 5 parameter matrices, so 28 × 5 = 140 bytes per layer. For a model with \( N \) layers, we account for \( N \times 140 \) extra bytes on PM for encryption metadata, which is relatively small compared to the size of actual models (typically a few megabytes). The training algorithm is a single-threaded, compute-intensive application that utilizes 98-100% of the CPU during execution.

### Secure Inference

PLINIUS can also be used for secure inference. We trained a Convolutional Neural Network (CNN) model with 12 Leaky ReLU (LReLU) convolutional layers on the MNIST training dataset. The trained model was then used to classify 10,000 grayscale images of handwritten digits ranging from 0 to 9. The model, available in the PLINIUS repository, achieved an accuracy of 98.52% with the specified hyper-parameters.

### GPU and TPU Support

Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs) are increasingly used in machine learning applications. However, these hardware accelerators do not integrate Trusted Execution Environment (TEE) capabilities. Recent works such as HIX [23], Graviton [37], and Slalom [33] propose techniques to securely offload expensive ML computations to GPUs. Using Darknet’s CUDA extensions, PLINIUS can leverage these techniques to improve training performance. The trained model weights can be securely copied between the secure CPU and the GPU (or TPU), and our mirroring mechanism can be applied with minimal changes. We are currently exploring further improvements to PLINIUS in this direction.

### Related Work

#### TEE-based Schemes

Several solutions leverage trusted hardware, such as Intel SGX, for secure machine learning. For example, Slalom [33] is a framework for secure Deep Neural Network (DNN) inference in TEEs. It outsources costly neural network operations to a faster, but untrusted GPU during inference. Occlumency [26] uses Intel SGX to preserve the confidentiality and integrity of user data during deep learning inference in untrusted cloud infrastructure. Privado [15] implements secure inference-as-a-service by eliminating input-dependent access patterns from ML code, reducing data leakage risks in the enclave. Chiron [19] leverages Intel SGX for secure ML-as-a-service, preventing the disclosure of both data and code.

These systems use TEEs for model inference but lack support for failure recovery. PLINIUS provides a full framework that supports both in-enclave model training and inference with efficient fault tolerance guarantees on PM.

SecureTF [25] integrates TensorFlow for model training and inference in secure SCONE containers. This requires the entire TensorFlow library (over 2.5 million lines of code [5]) to run inside SGX enclaves, increasing the Trusted Computing Base (TCB). In contrast, the trusted portion of PLINIUS comprises only 15,900 lines of code, significantly reducing the TCB and enhancing security.

#### Homomorphic Encryption (HE)-based Schemes

Without trusted hardware enclaves, many privacy-preserving ML methods use HE-based techniques to compute directly over encrypted data. CryptoNets [14] implements inference over encrypted data for pre-trained neural networks. Other solutions [18] enable training and inference on neural network models using HE.

While these methods ensure the privacy of sensitive training and classification data, they have significant performance overhead (up to 1,000 times slower than TEE-based schemes [20]). PLINIUS offers an orthogonal approach, combining Intel SGX enclaves to ensure the confidentiality and integrity of models and datasets during training and inference at a much lower cost.

#### Fault Tolerance in ML

A common technique for fault tolerance in ML frameworks is checkpointing, where the model's state is saved to secondary storage during training and restored from it during recovery. Several frameworks, such as TensorFlow [6], Caffe [24], and Darknet [3], rely on secondary storage for persistent storage of training data. Distributing training across multiple compute nodes improves scalability and fault tolerance.

However, these techniques have high performance overhead due to the slow access times of secondary storage. After a crash, entire datasets and models must be reloaded into main memory from secondary storage. PLINIUS's novel mirroring mechanism leverages PM for fault tolerance: upon a crash, the model and associated training data are immediately available in memory. This design eliminates the need for expensive serialization and deserialization of models to and from secondary storage, providing a more efficient approach for handling large amounts of training data.

### Conclusion

PLINIUS is the first secure ML framework to leverage Intel SGX for secure model training and PM for fault tolerance. Our novel mirroring mechanism creates encrypted mirror copies of enclave ML models in PM, which are synchronized across training iterations. By leveraging PM to store byte-addressable training data, PLINIUS completely avoids expensive disk I/O operations in the event of a system failure. Evaluations show that PLINIUS substantially reduces the TCB compared to systems with unmodified libraries, and the mirroring mechanism outperforms disk-based checkpointing systems while ensuring robustness upon system failures. Using real-world datasets for image recognition, we demonstrate that PLINIUS offers a practical solution for securely training ML models in TEEs integrated with PM hardware at a reasonable cost.

### Future Work

We plan to extend this work in several directions. First, we aim to explore GPUs and TPUs by offloading expensive enclave operations without compromising confidentiality. The extent to which this can be done while preserving the confidentiality of model parameters and training or inference data will be a key area of future research. Second, we intend to explore distributed training using PLINIUS to overcome the limitations of the SGX Enclave Page Cache (EPC). Lastly, we plan to better exploit system parallelism to improve the performance of PLINIUS, which may involve redesigning SGX-DARKNET to efficiently support parallel training with threads spawned in the untrusted runtime.

### Acknowledgment

This work was funded by the Swiss National Science Foundation (FNS) under project PersiST (no. 178822).

### References

[1] “Optimize Your Cloud and Enable Azure Customers to Innovate at Scale with Intel® Optane™ Persistent Memory,” https://www.intel.la/content/www/xl/es/now/microsoft-azure-optane-innovation-editorial.html, accessed: Mar 9, 2021.
[2] “The MNIST Database of Handwritten Digits,” http://yann.lecun.com/exdb/mnist/, accessed: May 7, 2020.
[3] “Darknet: Open Source Neural Networks in C,” https://pjreddie.com/darknet/, 2013-2016, accessed: May 7, 2020.
[4] “Intel SGX Evolves for Data Center,” https://itpeernetwork.intel.com/intel-sgx-data-center/, 2019, accessed: Dec 11, 2020.
[5] “The TensorFlow Open Source Project on Open Hub,” https://www.openhub.net/p/tensorflow, 2020, accessed: Dec 11, 2020.
[6] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard et al., “TensorFlow: A system for large-scale machine learning,” in USENIX OSDI 2016.
[7] M. Al-Rubaie and J. M. Chang, “Privacy-preserving machine learning: Threats and solutions,” IEEE Security Privacy, 2019.
[8] S. Arnautov, B. Trach, F. Gregor, T. Knauth, A. Martin, C. Priebe, J. Lind, D. Muthukumaran, D. O’Keeffe, M. L. Stillwell, D. Goltzsche, D. Eyers, R. Kapitza, P. Pietzuch, and C. Fetzer, “SCONE: Secure linux containers with intel SGX,” in USENIX OSDI 16.
[9] J. V. Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens, M. Silberstein, T. F. Wenisch, Y. Yarom, and R. Strackx, “Foreshadow: Extracting the keys to the intel SGX kingdom with transient out-of-order execution,” in USENIX Security 2018.
[10] I. Corporation, “Intel® Software Guard Extensions Developer Reference for Linux* OS,” https://download.01.org/intel-sgx/sgx-linux/2.8/docs/Intel_SGX_Developer_Reference_Linux_2.8_Open_Source.pdf, 2019.
[11] A. Correia, P. Felber, and P. Ramalhete, “Romulus: Efficient algorithms for persistent transactional memory,” in SPAA’18.
[12] V. Costan and S. Devadas, “Intel SGX explained,” 2016.
[13] M. J. Dworkin, “Recommendation for block cipher modes of operation: Galois/counter mode (gcm) and gmac,” Tech. Rep., 2007.
[14] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter, M. Naehrig, and J. Wernsing, “Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy,” in ICML’16.
[15] K. Grover, S. Tople, S. Shinde, R. Bhagwan, and R. Ramjee, “Privado: Practical and Secure DNN Inference with Enclaves,” arXiv preprint arXiv:1810.00602, 2018.
[16] D. Gruss, J. Lettner, F. Schuster, O. Ohrimenko, I. Haller, and M. Costa, “Strong and efficient cache side-channel protection using hardware transactional memory,” in USENIX Security 2017.
[17] L. Hanzlik, Y. Zhang, K. Grosse, A. Salem, M. Augustin, M. Backes, and M. Fritz, “Mlcapsule: Guarded offline deployment of machine learning as a service,” arXiv preprint arXiv:1808.00590, 2018.
[18] E. Hesamifard, H. Takabi, M. Ghasemi, and C. Jones, “Privacy-preserving machine learning in cloud,” in Proceedings of the 2017 on Cloud Computing Security Workshop, 2017.
[19] T. Hunt, C. Song, R. Shokri, V. Shmatikov, and E. Witchel, “Chiron: Privacy-preserving machine learning as a service,” arXiv preprint arXiv:1803.05961, 2018.
[20] N. Hynes, R. Cheng, and D. Song, “Efficient deep learning on multi-source private data,” arXiv preprint arXiv:1807.06689, 2018.
[21] C. Iorgulescu, R. Azimi, Y. Kwon, S. Elnikety, M. Syamala, V. R. Narasayya, H. Herodotou, P. Tomita, A. Chen, J. Zhang, and J. Wang, “Perfiso: Performance isolation for commercial latency-sensitive services,” in USENIX ATC 2018.
[22] J. Izraelevitz, J. Yang, L. Zhang, J. Kim, X. Liu, A. Memaripour, Y. J. Soh, Z. Wang, Y. Xu, S. R. Dulloor et al., “Basic performance measurements of the intel optane dc persistent memory module,” arXiv preprint arXiv:1903.05714, 2019.
[23] I. Jang, A. Tang, T. Kim, S. Sethumadhavan, and J. Huh, “Heterogeneous isolated execution for commodity gpus,” in Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS ’19. New York, NY, USA: Association for Computing Machinery, 2019, p. 455–468. [Online]. Available: https://doi.org/10.1145/3297858.3304021
[24] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell, “Caffe: Convolutional architecture for fast feature embedding,” in ACM Multimedia 2014.
[25] R. Kunkel, D. L. Quoc, F. Gregor, S. Arnautov, P. Bhatotia, and C. Fetzer, “SecureTF: A Secure TensorFlow Framework,” in Middleware’20.
[26] T. Lee, Z. Lin, S. Pushp, C. Li, Y. Liu, Y. Lee, F. Xu, C. Xu, L. Zhang, and J. Song, “Occlumency: Privacy-preserving remote deep-learning inference using SGX,” in MobiCom’19.
[27] L. Lersch, X. Hao, I. Oukid, T. Wang, and T. Willhalm, “Evaluating persistent memory range indexes,” VLDB Endowment 2019.
[28] E. Liberty, Z. Karnin, B. Xiang, L. Rouesnel, B. Coskun, R. Nallapati, J. Delgado, A. Sadoughi, Y. Astashonok, P. Das et al., “Elastic Machine Learning Algorithms in Amazon SageMaker,” SIGMOD’20.
[29] P. Mohassel and Y. Zhang, “SecureML: A system for scalable privacy-preserving machine learning,” in IEEE S&P 2017.
[30] O. Oleksenko, B. Trach, R. Krahn, M. Silberstein, and C. Fetzer, “Varys: Protecting SGX enclaves from practical side-channel attacks,” in USENIX ATC 2018.
[31] M. Schwarz, S. Weiser, D. Gruss, C. Maurice, and S. Mangard, “Malware guard extension: Using SGX to conceal cache attacks,” in International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, 2017.
[32] Y. Shen, H. Tian, Y. Chen, K. Chen, R. Wang, Y. Xu, Y. Xia, and S. Yan, “Occlum: Secure and Efficient Multitasking Inside a Single Enclave of Intel SGX,” ser. ASPLOS’20.
[33] F. Tramer and D. Boneh, “Slalom: Fast, verifiable and private execution of neural networks in trusted hardware,” in ICLR’19.
[34] F. Tramèr, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Stealing machine learning models via prediction apis,” in USENIX Security 2016.
[35] C. Tsai, D. E. Porter, and M. Vij, “Graphene-sgx: A practical library OS for unmodified applications on SGX,” in USENIX ATC 2017.
[36] H. Volos, A. J. Tack, and M. M. Swift, “Mnemosyne: Lightweight persistent memory,” in ASPLOS’11.
[37] S. Volos, K. Vaswani, and R. Bruno, “Graviton: Trusted execution environments on gpus,” in 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). Carlsbad, CA: USENIX Association, Oct. 2018, pp. 681–696. [Online]. Available: https://www.usenix.org/conference/osdi18/presentation/volos
[38] C. Wang, Q. Liang, and B. Urgaonkar, “An empirical analysis of amazon EC2 Spot Instance features affecting cost-effective resource procurement,” TOMPECS’18.
[39] N. Weichbrodt, P. Aublin, and R. Kapitza, “sgx-perf: A performance analysis tool for intel SGX enclaves,” in Middleware’18.
[40] J. Yang, J. Kim, M. Hoseinzadeh, J. Izraelevitz, and S. Swanson, “An empirical guide to the behavior and use of scalable persistent memory,” in USENIX FAST 2020.
[41] P. Zuo and Y. Hua, “Secpm: a secure and persistent memory system for non-volatile memory,” in HotStorage’18.