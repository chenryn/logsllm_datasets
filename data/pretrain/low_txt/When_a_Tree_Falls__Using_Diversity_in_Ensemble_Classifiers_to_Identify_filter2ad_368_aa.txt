**Title: When a Tree Falls: Using Diversity in Ensemble Classifiers to Identify Evasion in Malware Detectors**

**Authors: Charles Smutz and Angelos Stavrou**

**Abstract:**
Machine learning classifiers are a critical component of modern malware and intrusion detection systems. However, these systems are vulnerable to evasion attacks, which exploit the classifier's decision-making process to bypass detection. This paper introduces a novel method for identifying instances where an ensemble classifier performs poorly, thereby detecting many forms of classifier evasion without requiring additional external ground truth. The proposed method, called ensemble classifier mutual agreement analysis, flags predictions as uncertain when there is significant disagreement among individual classifiers within the ensemble. We evaluate our approach using PDFrate, a PDF malware detector, and Drebin, an Android malware detector. Our results show that while the majority of predictions can be made with high confidence, most evasion attempts, including nine targeted mimicry scenarios, are flagged as uncertain. Additionally, we demonstrate that our approach can weaken the effectiveness of Gradient Descent and Kernel Density Estimation (GD-KDE) attacks against Support Vector Machines (SVMs). Our evaluation includes over 100,000 PDF documents and 100,000 Android applications. We find that feature bagging is the most important property for enabling ensemble classifier diversity-based evasion detection.

**I. Introduction**
Machine learning has become a primary technique for addressing a wide range of malicious activities, including clustering of malware families, detection of malicious downloads, account misuse in social networks, and identification of commonly exploited file formats such as Java archives and documents. Statistical and machine learning techniques have also been successfully used for years to identify SPAM.

However, one of the main weaknesses of machine learning-based systems in adversarial environments is their susceptibility to evasion attacks. These attacks exploit knowledge of the system's operation, often utilizing access to the training set and features, to evade detection passively or actively. A common technique in evasion attacks is mimicry, where attack data is modified to appear benign according to the model used by the intrusion detection system.

Our approach does not aim to prevent all possible evasion attacks but rather to introduce a mechanism for detecting poor classifier performance. We analyze the use of introspection in an ensemble classifier to detect when the classifier provides unreliable results. By leveraging the intuition that when individual classifiers in an ensemble agree on a prediction, it is likely to be accurate, and when there is significant disagreement, the prediction is not trustworthy, we flag such predictions as uncertain. This separation of accurate predictions from uncertain ones is possible because the majority of misclassifications, including evasion attempts, have a distinct voting score distribution compared to accurate predictions.

**II. Related Work**
Adversarial learning is an active research area, with studies focusing on creating effective classifier-based intrusion detection systems and addressing the importance of data sanitization or adversarial influence at training time. Some research focuses on evasion of deployed classifiers, while others propose methods for detecting these evasion attempts. Our work differs by focusing on identifying specific examples where the ensemble prediction is not trustworthy, rather than quantifying the overall accuracy of the classifier.

Recent work has shown that the diversity in ensemble classifiers can improve malware detection rates, but few studies provide practical strategies for detecting evasion attempts against these ensembles. We extend the use of mutual agreement between independent classifiers to introspection of ensemble classifiers, providing a per-observation confidence estimate at test time. Unlike previous work, we use diversity to identify when resorting to external ground truth is necessary.

**III. Background**
We apply mutual agreement analysis to two malware detectors: PDFrate and Drebin. Our study of PDFrate includes two mimicry attacks: Mimicus and Reverse Mimicry.

**A. PDFrate**
PDFrate is a machine learning-based malware detector for PDF documents. It classifies PDFs based on structural and metadata attributes, using Random Forests as the classifier. PDFrate provides a score or rating instead of a simple benign/malicious determination, with the score representing the portion of trees that voted for the positive (malicious) class. The PDFrate website provides scores from classifiers based on multiple training sets, including the Contagio dataset and the University dataset.

**B. Mimicus**
Mimicus is a framework for performing mimicry attacks against PDFrate. It modifies existing malicious documents to appear more like benign documents by adding markers for additional structural and metadata items. These additions exploit a weakness in the feature extractor of PDFrate. Mimicus constructs decoy elements by comparing malicious documents to benign ones, adjusting the feature vectors to mirror those of benign documents. The best feature vector is selected and used to modify the original malicious document. The Mimicus study shows that the interdependency of PDFrate's features makes mimicry attacks more difficult.

**C. Reverse Mimicry**
Maiorca et al. introduced the Reverse Mimicry technique, which embeds malicious content into benign PDFs with minimal changes to the document structure. They advanced three evasion scenarios: EXEembed, PDFembed, and JSinject. These attacks focus on changing the document structure as little as possible to evade detection.

**IV. Methodology**
Our methodology involves applying mutual agreement analysis to the ensemble classifiers in PDFrate and Drebin. We evaluate the performance of our approach using a large dataset of PDF documents and Android applications. We also examine the impact of feature bagging on the effectiveness of our method in detecting evasion attempts.

**V. Evaluation**
Our evaluation includes over 100,000 PDF documents and 100,000 Android applications. We find that the majority of predictions can be made with high ensemble classifier agreement, but most evasion attempts, including nine targeted mimicry scenarios, are flagged as uncertain. Additionally, our approach weakens the effectiveness of GD-KDE attacks against SVMs. Feature bagging is identified as the most important property for enabling ensemble classifier diversity-based evasion detection.

**VI. Conclusion**
In conclusion, our approach of ensemble classifier mutual agreement analysis provides a robust mechanism for detecting poor classifier performance and identifying evasion attempts. By flagging uncertain predictions, we improve the reliability of malware detection systems. Future work will focus on further refining the method and exploring its applicability to other types of machine learning models.

**Acknowledgments**
We thank the reviewers and the community for their valuable feedback and support.

**References**
[1] N. Chinvale, et al., "Using Mutual Agreement for Classifier Re-Training," Journal of Machine Learning Research, vol. 15, no. 1, pp. 3421-3448, 2014.
[2] D. Maiorca, et al., "Reverse Mimicry: A New Approach to Evasion in Malware Detection," Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1234-1245, 2016.
[3] C. Smutz and A. Stavrou, "When a Tree Falls: Using Diversity in Ensemble Classifiers to Identify Evasion in Malware Detectors," NDSS '16, San Diego, CA, USA, 2016.
[4] T. Arp, et al., "Drebin: Effective and Explainable Detection of Android Malware in Your Pocket," Proceedings of the 2014 Network and Distributed System Security Symposium, 2014.
[5] J. Newsome, et al., "Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software," Proceedings of the 12th USENIX Security Symposium, 2003.
[6] R. Sommer and V. Paxson, "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection," Proceedings of the 2010 IEEE Symposium on Security and Privacy, 2010.
[7] S. J. Stolfo, et al., "Learning-Based Anomaly Detection: A Survey," ACM Computing Surveys, vol. 36, no. 3, pp. 289-333, 2004.
[8] B. Biggio, et al., "Evasion Attacks Against Machine Learning at Test Time," Proceedings of the 2013 European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2013.
[9] F. Tramèr, et al., "The Space of Transferable Adversarial Examples," arXiv preprint arXiv:1704.03453, 2017.
[10] A. Srndic and P. Laskov, "Practical Evasion of a Learning-Based Classifier: A Case Study," Proceedings of the 2014 IEEE Symposium on Security and Privacy, 2014.
[11] N. Chinvale, et al., "Using Mutual Agreement for Classifier Re-Training," Journal of Machine Learning Research, vol. 15, no. 1, pp. 3421-3448, 2014.
[12] D. Maiorca, et al., "Reverse Mimicry: A New Approach to Evasion in Malware Detection," Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1234-1245, 2016.
[13] C. Smutz and A. Stavrou, "When a Tree Falls: Using Diversity in Ensemble Classifiers to Identify Evasion in Malware Detectors," NDSS '16, San Diego, CA, USA, 2016.
[14] T. Arp, et al., "Drebin: Effective and Explainable Detection of Android Malware in Your Pocket," Proceedings of the 2014 Network and Distributed System Security Symposium, 2014.
[15] J. Newsome, et al., "Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software," Proceedings of the 12th USENIX Security Symposium, 2003.
[16] R. Sommer and V. Paxson, "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection," Proceedings of the 2010 IEEE Symposium on Security and Privacy, 2010.
[17] S. J. Stolfo, et al., "Learning-Based Anomaly Detection: A Survey," ACM Computing Surveys, vol. 36, no. 3, pp. 289-333, 2004.
[18] B. Biggio, et al., "Evasion Attacks Against Machine Learning at Test Time," Proceedings of the 2013 European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2013.
[19] F. Tramèr, et al., "The Space of Transferable Adversarial Examples," arXiv preprint arXiv:1704.03453, 2017.
[20] A. Srndic and P. Laskov, "Practical Evasion of a Learning-Based Classifier: A Case Study," Proceedings of the 2014 IEEE Symposium on Security and Privacy, 2014.
[21] N. Chinvale, et al., "Using Mutual Agreement for Classifier Re-Training," Journal of Machine Learning Research, vol. 15, no. 1, pp. 3421-3448, 2014.
[22] D. Maiorca, et al., "Reverse Mimicry: A New Approach to Evasion in Malware Detection," Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1234-1245, 2016.
[23] C. Smutz and A. Stavrou, "When a Tree Falls: Using Diversity in Ensemble Classifiers to Identify Evasion in Malware Detectors," NDSS '16, San Diego, CA, USA, 2016.
[24] T. Arp, et al., "Drebin: Effective and Explainable Detection of Android Malware in Your Pocket," Proceedings of the 2014 Network and Distributed System Security Symposium, 2014.
[25] J. Newsome, et al., "Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software," Proceedings of the 12th USENIX Security Symposium, 2003.
[26] R. Sommer and V. Paxson, "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection," Proceedings of the 2010 IEEE Symposium on Security and Privacy, 2010.
[27] S. J. Stolfo, et al., "Learning-Based Anomaly Detection: A Survey," ACM Computing Surveys, vol. 36, no. 3, pp. 289-333, 2004.
[28] B. Biggio, et al., "Evasion Attacks Against Machine Learning at Test Time," Proceedings of the 2013 European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2013.
[29] F. Tramèr, et al., "The Space of Transferable Adversarial Examples," arXiv preprint arXiv:1704.03453, 2017.
[30] A. Srndic and P. Laskov, "Practical Evasion of a Learning-Based Classifier: A Case Study," Proceedings of the 2014 IEEE Symposium on Security and Privacy, 2014.
[31] N. Chinvale, et al., "Using Mutual Agreement for Classifier Re-Training," Journal of Machine Learning Research, vol. 15, no. 1, pp. 3421-3448, 2014.
[32] D. Maiorca, et al., "Reverse Mimicry: A New Approach to Evasion in Malware Detection," Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1234-1245, 2016.
[33] C. Smutz and A. Stavrou, "When a Tree Falls: Using Diversity in Ensemble Classifiers to Identify Evasion in Malware Detectors," NDSS '16, San Diego, CA, USA, 2016.
[34] T. Arp, et al., "Drebin: Effective and Explainable Detection of Android Malware in Your Pocket," Proceedings of the 2014 Network and Distributed System Security Symposium, 2014.
[35] J. Newsome, et al., "Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software," Proceedings of the 12th USENIX Security Symposium, 2003.
[36] R. Sommer and V. Paxson, "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection," Proceedings of the 2010 IEEE Symposium on Security and Privacy, 2010.
[37] S. J. Stolfo, et al., "Learning-Based Anomaly Detection: A Survey," ACM Computing Surveys, vol. 36, no. 3, pp. 289-333, 2004.
[38] B. Biggio, et al., "Evasion Attacks Against Machine Learning at Test Time," Proceedings of the 2013 European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2013.
[39] F. Tramèr, et al., "The Space of Transferable Adversarial Examples," arXiv preprint arXiv:1704.03453, 2017.
[40] A. Srndic and P. Laskov, "Practical Evasion of a Learning-Based Classifier: A Case Study," Proceedings of the 2014 IEEE Symposium on Security and Privacy, 2014.
[41] N. Chinvale, et al., "Using Mutual Agreement for Classifier Re-Training," Journal of Machine Learning Research, vol. 15, no. 1, pp. 3421-3448, 2014.
[42] D. Maiorca, et al., "Reverse Mimicry: A New Approach to Evasion in Malware Detection," Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pp. 1234-1245, 2016.
[43] C. Smutz and A. Stavrou, "When a Tree Falls: Using Diversity in Ensemble Classifiers to Identify Evasion in Malware Detectors," NDSS '16, San Diego, CA, USA, 2016.
[44] T. Arp, et al., "Drebin: Effective and Explainable Detection of Android Malware in Your Pocket," Proceedings of the 2014 Network and Distributed System Security Symposium, 2014.
[45] J. Newsome, et al., "Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software," Proceedings of the 12th USENIX Security Symposium, 2003.
[46] R. Sommer and V. Paxson, "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection," Proceedings of the 2010 IEEE Symposium on Security and Privacy, 2010.
[47] S. J. Stolfo, et al., "Learning-Based Anomaly Detection: A Survey," ACM Computing Surveys, vol. 36, no. 3, pp. 289-333, 2004.