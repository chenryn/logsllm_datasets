# Discussion

## 6.1 Improvements

### Combining More Features
NEIGHBORWATCHER currently relies solely on spamming structure information to infer spam. However, incorporating additional spamming behaviors could enhance the system's accuracy. For example, some spammers use both HTML tags and BBcode tags to ensure their spam links are embedded, as they are uncertain about the supported methods of the target platforms. Additionally, spammers often post spam links on websites in different languages, such as posting Russian spam on Chinese, Korean, and English websites, which is highly unlikely for normal postings. By integrating these features, we can improve the overall inference accuracy.

### Improving Algorithms
In Equation (3), we assume that postings on different platforms have equal weight. However, this assumption may not hold true. For instance, if postings on a platform share similar posting times, email addresses, or IP addresses with the input posting, it is likely that they were posted by the same spammer simultaneously. Therefore, we can assign different weights to different platforms based on these factors to refine our algorithm.

### Updating Spam Platforms
Our system identifies new spam platforms by recursively searching inferred spam in search engines. As long as spammers continue to use these spam infrastructures, we can discover new platforms. However, the current system cannot infer spam posted on only one platform in our dataset, preventing us from identifying other platforms where the same spam is posted. To address this, we can build a relationship graph among returned websites from the search results, excluding the searched link. If these websites show close relationships (e.g., dense connections), the searched link is likely to be spam, and the corresponding search result websites are potential spam platforms. Although normal links may appear on various websites, it is highly unlikely that normal users will consistently post similar content on certain websites. Our ongoing work will focus on designing and testing new algorithms to efficiently update our spam platform dataset.

## 6.2 Possible Evasions

### Evasion by Exploring New Platforms
Spammers may attempt to evade detection by spamming on platforms not included in our database or by finding entirely new platforms. In this case, our neighborhood-based inference algorithm would fail to detect their new structures. However, as long as spammers also post spam on both new and old platforms, we can still identify their new platforms by continuously updating our database. Otherwise, spammers would need to keep finding new platforms and abandon existing ones, which is less likely due to the associated costs.

### Evasion by Changing Spamming Behaviors
If spammers know that we use spam links to build relationship graphs, they might post different links on different platforms. This would prevent us from building their spamming structure. However, spammers would need to find more platforms to post their varied links, increasing their costs and time. Alternatively, they might post the same spam multiple times on certain platforms to boost search rankings, which increases the likelihood of detection by content-based systems.

### Evasion by Using Polymorphic URLs
Our algorithm groups identical URLs to infer possible spam messages. Spammers might evade this by using polymorphic URLs (i.e., different URLs on different platforms). However, it is generally not feasible to create fully polymorphic URLs for a given spam URL. If spammers use URL shortening services, we can use the resolved final URLs in our system. Additionally, we can use the domain of a spam URL instead of the full URL, which is more stable if spammers aim to promote specific domains.

## 7. Related Work

### Comment Spam
Several studies have been conducted to detect comment spam. Kolari et al. [31] proposed a machine-learning-based method to detect blog spam by extracting features from the posting content, such as bag-of-words, bag-of-anchors, and bag-of-URLs. Mishne et al. [24] used a language model approach to detect comment spam by generating models for blog posts, comments, and linked pages, and then classifying spam based on language model divergences.

Recently, Niu et al. [32] studied comment spam in both legitimate and honeypot forums, proposing a context-based detection method that looks for redirection and cloaking. Shin et al. [33] developed a lightweight SVM classifier to detect forum spam, using 16 different features extracted from spammer origins, comment activities, URLs, and textual contents. Tan et al. [23] analyzed spamming activities on a commercial blog site, developing a real-time system to detect spam postings based on 13 non-textual features. Kantchelian et al. [28] defined spam as uninformative content and proposed a machine-learning-based method to detect spam based on the content complexity of comments in social media.

Most of these studies focus on specific blogs or honeypot blogs. In contrast, our study examines a large number of frequently used spam platforms, providing an in-depth analysis that cannot be observed from a few blogs. Our system complements content-, context-, and behavior-based detection features by exploiting the spamming infrastructure, which is more stable in the spamming process.

### Graph-Based Algorithms
Graph-based algorithms have been applied in spam detection. PageRank [29] and TrustRank [35] are widely used by search engines to determine search ranks. Zhao et al. [22] proposed a spam detection system by exploring link dependencies and content similarities among web pages. The system clusters hosts based on content features, assigns labels using majority voting, and propagates these labels to neighbor hosts, retraining the classifier with predicted labels as new features.

Our paper uses a different graph-based algorithm to characterize the spamming structure, combining it with the real posting structure to infer spam. Our work is motivated by two studies: Ramachandran et al. [20] proposed an email spam filtering system that builds clusters of sending patterns from a small seed of spammers. Zhang et al. [26] built a system to predict blacklists based on attackers' history. Our work shares a similar intuition but applies it to a different application with different inference algorithms. We also present a measurement study of spam platforms, which has not been shown in prior work.

## 8. Conclusion

Despite years of research, the arms race between spammers and researchers has rendered many existing detection systems ineffective. Spammers continually develop new techniques to evade content- or context-based detection systems.

In this paper, we present a deep study on comment spam from a new perspective: the spamming infrastructure, which is the core and stable part of the spamming process. By measuring 35,931 spam platforms, we conclude that spammers prefer to reuse their platforms unless blocked. Based on this finding, we design a graph-structure-based inference system to infer comment spam by checking if the same spam appears on neighboring (clique) platforms. Our evaluation results show that we can infer a large number of new comment spam and spam platforms, and continue to find them daily.

## 9. Acknowledgments

This material is based upon work supported in part by the National Science Foundation under Grant CNS-1218929. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.

## References

[1] Alexa rank. http://www.alexa.com/.
[2] Botnets and dorks: a new recipe for hacking. http://www.darkreading.com/vulnerabilitymanagement/167901026/security/vulnerabilities/231500104/botnetsandgoogledorksanewrecipeforhacking.html.
[3] cfinder. http://www.cfinder.org/.
[4] The (evil) genius of comment spammers. http://www.wired.com/wired/archive/12.03/google.html?pg=7.
[5] Globalspyware. http://globalspyware.com/.
[6] Google bombs. http://www.searchenginepeople.com/blog/incredible-google-bombs.html.
[7] Google cache. http://www.googleguide.com/cached_pages.html.
[8] Google pagerank API in PHP. http://www.fusionswift.com/2011/10/google-pagerank-api-in-php-october-2011/.
[9] Google rolls out content spam detection. http://www.nationalpositions.com/blog/seonewsgooglerollsoutcontentspamdetection/.
[10] Google safe browsing. http://code.google.com/apis/safebrowsing.
[11] Google search and search engine spam. http://googleblog.blogspot.com/2011/01/google-search-and-search-engine-spam.html.
[12] Hamming distance. http://en.wikipedia.org/wiki/Hamming_distance.
[13] rel="nofollow". http://support.google.com/webmasters/bin/answer.py?hl=en&answer=96569.
[14] Safe browsing - protecting web users for five years and counting. http://googlepublicpolicy.blogspot.com/2012/06/safe-browsingprotecting-web-users-for.html.
[15] Spambust. http://spambusted.com/.
[16] Stop forum spam. http://www.stopforumspam.com/.
[17] What does your Google pagerank mean? http://www.redfusionmedia.com/google_pagerank.htm.
[18] Ramachandran, A., Dasgupta, A., & Feamster, N. (2011). Spam or ham?: Characterizing and detecting fraudulent not spam reports in web mail systems. In Proceedings of the 8th Annual Collaboration, Electronic messaging, Anti-Abuse and Spam Conference (CEAS 11).
[19] Ramachandran, A., & Vempala, S. (2007). Filtering spam with behavioral blacklisting. In Proceedings of the 14th ACM conference on computer and communications security.
[20] Brin, S., & Page, L. (1998). The anatomy of a large-scale hypertextual Web search engine. In Proceedings of the seventh international conference on World Wide Web.
[21] Castillo, C., Donato, D., & Gionis, A. (2007). Know your neighbors: Web spam detection using the web topology. In ACM Special Interest Group on Information Retrieval (SIGIR) Conference.
[22] Tan, X. Z., Guo, L., & Zhao, Y. (2012). Spam behavior analysis and detection in user generated content on social network. In Proceedings of the 32nd International Conference on Distributed Computing Systems (ICDCS 2012), Macao, China.
[23] Mishne, G., & Lempel, R. (2005). Blocking Blog Spam with Language Model Disagreement. In First International Workshop on Adversarial Information Retrieval on the Web, at 14th international conference on World Wide Web (WWW).
[24] Gyongyi, Z., & Garcia-Molina, H. (2004). Web Spam Taxonomy. In Technical report, Stanford Digital Library Technologies Project.
[25] Zhang, J., & Ullrich, J. (2008). Highly Predictive Blacklisting. In Proceedings of the USENIX Security Symposium, San Jose, CA.
[26] Zhang, J., Yan, C., & Gu, G. (2012). PoisonAmplifier: A Guided Approach of Discovering Compromised Websites through Reversing Search Poisoning Attacks. In Proceedings of the 15th International Symposium on Research in Attacks, Intrusions and Defenses (RAID’12).
[27] Kantchelian, A., Ma, J., Huang, L., Afroz, S., Joseph, A., & Tygar, J. D. (2012). Robust detection of comment spam using entropy rate. In Proceedings of the 5th ACM workshop on Security and artificial intelligence (AISec’12).
[28] Page, L., Brin, S., & Winograd, T. (1998). The PageRank citation ranking: Bringing order to the Web. In Technical report, Stanford University Database Group. http://citeseer.nj.nec.com/368196.html.
[29] Leontiadis, I., & Christin, N. (2011). Measuring and analyzing search-redirection attacks in the illicit online prescription drug trade. In Proceedings of the 20th USENIX Security.
[30] Kolari, P., Finin, T., & Joshi, A. (2006). SVMs for the blogosphere: Blog identification and splog detection. In Proceedings of AAAI Spring Symposium on Computational Approaches to Analysing Weblogs.