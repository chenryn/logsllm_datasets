### 6.1 Reconfigurable Hardware Security

The work most closely related to ours is that of Huffmire et al. [19]. To provide memory protection on an FPGA, they propose the use of a reconfigurable reference monitor that enforces legal sharing of memory among cores. The memory access policy is expressed in a specialized language, and a compiler translates this policy directly into a circuit that enforces it. This circuit is then loaded onto the FPGA along with the cores. While their approach addresses the specifics of constructing an efficient memory access monitor in reconfigurable hardware, it does not address the problem of protecting the monitor from routing interference or ensuring that all memory accesses go through the monitor. Our paper complements their work by providing the fundamental primitives needed to implement memory protection on a reconfigurable device.

There appears to be limited research on managing FPGA resources securely. Chien and Byun [8] have one of the closest works, where they address safety and protection concerns in enhancing a CMOS processor with reconfigurable logic. Their design achieves process isolation by providing a reconfigurable virtual machine to each process, and their architecture uses hardwired TLBs to check all memory accesses. Our work can be used in conjunction with theirs, employing soft-processor cores on commercial off-the-shelf FPGAs rather than a custom silicon platform. We believe one of the strengths of our work is that it may provide a viable implementation path for those requiring a custom secure architecture, such as execute-only memory [31] or virtual secure co-processing [29].

Gogniat et al. [12] propose a method of embedded system design that implements security primitives, such as AES encryption, on an FPGA. This is one component of a secure embedded system containing memory, I/O, CPU, and other ASIC components. Their Security Primitive Controller (SPC), which is separate from the FPGA, can dynamically modify these primitives at runtime in response to the detection of abnormal activity (attacks). In this work, the reconfigurable nature of the FPGA is used to adapt a crypto core to situational concerns, although the focus is on using an FPGA to efficiently thwart system-level attacks rather than chip-level concerns. Indeed, FPGAs are a natural platform for performing many cryptographic functions due to the large number of bit-level operations required in modern block ciphers. However, while there is extensive work on exploiting FPGAs to speed up cryptographic or intrusion detection primitives, systems researchers are just beginning to realize the security implications of building systems around reconfigurable hardware.

Most of the work related to FPGA security has focused on preventing the theft of intellectual property and securely uploading bitstreams in the field. Because such attacks directly impact their bottom line, the industry has developed several techniques to combat the theft of FPGA IP, such as encryption [6] [23] [24], fingerprinting [27], and watermarking [28]. Establishing a root of trust on a fielded device is challenging because it requires a decryption key to be incorporated into the finished product. Some FPGAs can be remotely updated in the field, and the industry has devised secure hardware update channels that use authentication mechanisms to prevent a subverted bitstream from being uploaded [15] [16]. These techniques were developed to prevent an attacker from uploading a malicious design that causes unintended functionality. A malicious design could even physically destroy the FPGA by causing a short-circuit [14]. However, these authentication techniques only ensure that a bitstream is authentic; an "authentic" bitstream could still contain a subverted core designed by a third party.

### 6.2 Covert Channels, Direct Channels, and Trap Doors

The work in Section 4.1 builds upon existing research on covert channels. Exploitation of a covert channel results in the unintended flow of information between cores. Covert channels operate via internal shared resources, such as power consumption, processor activity, disk usage, or error conditions [47] [41]. Classical covert channel analysis involves identifying all shared resources on the chip, determining if the shared resource is exploitable, and assessing the bandwidth of the covert channel. Storage channels can be mitigated by partitioning resources, while timing channels can be mitigated with sequential access, a fact we exploit in the construction of our bus architecture. Remedial actions include decreasing the bandwidth (e.g., introducing artificial noise in resource usage [44]) or closing the channel. Unfortunately, an adversary can extract a signal from the noise given sufficient resources [37].

Our technique primarily focuses on restricting opportunities for direct channels and trap doors [49]. Our memory protection scheme is an example of this. Without memory protection, a core can leak secret data by writing it directly to memory. Another example of a direct channel is a tap connecting two cores. An unintentional tap can be established through luck, such as when the place-and-route tool's optimization strategy interlaces the wires of two cores.

### 7 Conclusion

Designing reconfigurable systems is a complex process involving multiple software tool chains with different trust levels. Since developing an optimized tool chain from scratch to meet assurance needs is not cost-effective, only the most sensitive cores should be designed using a trusted tool chain. Most cores can be designed with highly optimized but untrusted commodity tools to meet performance needs, resulting in multiple cores on a chip with varying trust levels. Our methodology will not make less trusted portions more dependable or correct, but it will isolate trusted portions from the effects of their subversion or failure. To address this, developers need to build monitored or fail-safe systems on top of FPGAs to prevent the theft of critical secrets.

We have presented two low-level protection mechanisms, moats and drawbridges, and analyzed their trade-offs. Larger moats consume more area but offer better performance due to longer segments. Our interconnect tracing primitive complements the moat primitive by allowing smaller moats to be used without sacrificing performance. We have also described how these basic primitives are useful in implementing a higher-level memory protection primitive, which can prevent unintended sharing of information in embedded systems.

### Acknowledgments

The authors would like to thank Virgil Gligor for his insightful comments on this paper. We also wish to thank the anonymous reviewers for their helpful feedback. This research was funded in part by the National Science Foundation Grant CNS-0524771, NSF Career Grant CCF-0448654, and the SMART Defense Scholarship for Service.

### References

[1] Z. Baker and V. Prasanna. Efficient architectures for intrusion detection. In Twelfth Annual International Conference on Field-Programmable Logic and its Applications (FPL '04), August 2004.
[2] Z. Baker and V. Prasanna. Computationally-efficient engine for flexible intrusion detection. October 2005.
[3] V. Betz, J. S. Rose, and A. Marqardt. Architecture and CAD for deep-submicron FPGAs. Kluwer Academic, Boston, MA, 1999.
[4] K. Bondalapati and V. Prasanna. Reconfigurable computing systems. In Proceedings of the IEEE, volume 90(7), pages 1201–17, 2002.
[5] U. Bondhugula, A. Devulapalli, J. Fernando, P. Wyckoff, and P. Sadayappan. Parallel FPGA-based all-pairs shortest-paths in a directed graph. In Proceedings of the 20th IEEE International Parallel and Distributed Processing Symposium (IPDPS'06), April 2006.
[6] L. Bossuet, G. Gogniat, and W. Burleson. Dynamically configurable security for SRAM FPGA bitstreams. In Proceedings of the 18th International Parallel and Distributed Processing Symposium (IPDPS '04), Santa Fe, NM, April 2004.
[7] D. Buell and K. Pocek. Custom computing machines: an introduction. In Journal of Supercomputing, volume 9(3), pages 219–29, 1995.
[8] A. Chien and J. Byun. Safe and protected execution for the morph/AMRM reconfigurable processor. In Seventh Annual IEEE Symposium on Field-Programmable Custom Computing Machines, Napa, CA, April 1999.
[9] K. Compton and S. Hauck. Reconfigurable computing: a survey of systems and software. In ACM Computing Surveys, volume 34(2), pages 171–210, USA, 2002. ACM.
[10] A. DeHon. Comparing computing machines. In SPIE-Int. Soc. Opt. Eng. Proceedings of SPIE - the International Society for Optical Engineering, volume 3526, pages 124–33, 1998.
[11] A. DeHon and J. Wawrzynek. Reconfigurable computing: what, why, and implications for design automation. In Proceedings of the Design Automation Conference, pages 610–15, West Point, NY, 1999.
[12] G. Gogniat, T. Wolf, and W. Burleson. Reconfigurable security support for embedded systems. In Proceedings of the 39th Hawaii International Conference on System Sciences, 2006.
[13] S. Guccione, D. Levi, and P. Sundararajan. Jbits: Java-based interface for reconfigurable computing. In Proceedings of the Second Annual Conference on Military and Aerospace Applications of Programmable Logic Devices and Technologies (MAPLD), Laurel, MD, USA, September 1999.
[14] I. Hadzic, S. Udani, and J. Smith. FPGA viruses. In Proceedings of the Ninth International Workshop on Field-Programmable Logic and Applications (FPL '99), Glasgow, UK, August 1999.
[15] S. Harper and P. Athanas. A security policy based upon hardware encryption. In Proceedings of the 37th Hawaii International Conference on System Sciences, 2004.
[16] S. Harper, R. Fong, and P. Athanas. A versatile framework for FPGA field updates: An application of partial self-reconfiguration. In Proceedings of the 14th IEEE International Workshop on Rapid System Prototyping, June 2003.
[17] T. Hill. Acceldsp synthesis tool floating-point to fixed-point conversion of MATLAB algorithms targeting FPGAs, April 2006.
[18] W.-M. Hu. Reducing timing channels with fuzzy time. In IEEE Computer Society Symposium on Research in Security and Privacy, Oakland, CA, May 1991.
[19] T. Huffmire, S. Prasad, T. Sherwood, and R. Kastner. Policy-driven memory protection for reconfigurable systems. In Proceedings of the European Symposium on Research in Computer Security (ESORICS), Hamburg, Germany, September 2006.
[20] B. Hutchings, R. Franklin, and D. Carver. Assisting network intrusion detection with reconfigurable hardware. In Proceedings of the 10th Annual IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM'02), 2002.
[21] A. Jain, D. Koppel, K. Kaligian, and Y.-F. Wang. Using stationary-dynamic camera assemblies for wide-area video surveillance and selective attention. In IEEE Conference on Computer Vision and Pattern Recognition, 2006.
[22] R. Kastner, A. Kaplan, and M. Sarrafzadeh. Synthesis Techniques and Optimizations for Reconfigurable Systems. Kluwer Academic, Boston, MA, 2004.
[23] T. Kean. Secure configuration of field programmable gate arrays. In Proceedings of the 11th International Conference on Field Programmable Logic and Applications (FPL '01), Belfast, UK, August 2001.
[24] T. Kean. Cryptographic rights management of FPGA intellectual property cores. In Tenth ACM International Symposium on Field-Programmable Gate Arrays (FPGA '02), Monterey, CA, February 2002.
[25] R. Kemmerer. Shared resource matrix methodology: An approach to identifying storage and timing channels. In ACM Transactions on Computer Systems, 1983.
[26] P. Kocher, R. Lee, G. McGraw, A. Raghunathan, and S. Ravi. Security as a new dimension in embedded system design. In Proceedings of the 41st Design Automation Conference (DAC '04), San Diego, CA, June 2004.
[27] J. Lach, W. Mangione-Smith, and M. Potkonjak. FPGA fingerprinting techniques for protecting intellectual property. In Proceedings of the 1999 IEEE Custom Integrated Circuits Conference, San Diego, CA, May 1999.
[28] J. Lach, W. Mangione-Smith, and M. Potkonjak. Robust FPGA intellectual property protection through multiple small watermarks. In Proceedings of the 36th ACM/IEEE Conference on Design Automation (DAC '99), New Orleans, LA, June 1999.
[29] R. Lee, P. Kwan, J. McGregor, J. Dwoskin, and Z. Wang. Architecture for protecting critical secrets in microprocessors. In Proceedings of the 32nd International Symposium on Computer Architecture (ISCA), June 2005.
[30] J. Lewis and B. Martin. Cryptol: High assurance, retargetable crypto development and validation. In Military Communications Conference (MILCOM), October 2003.
[31] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. Mitchell, and M. Horowitz. Architectural support for copy and tamper resistant software. In Proceedings of the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IX), Cambridge, MA, November 2000.
[32] B. Lisanke. Logic synthesis and optimization benchmarks. Technical report, Microelectronics Center of North Carolina, Research Triangle Park, NC, USA, January 1991.
[33] P. Lysaght and D. Levi. Of gates and wires. In Proceedings of the 18th International Parallel and Distributed Processing Symposium, 2004.
[34] P. Lysaght and J. Stockwood. A simulation tool for dynamically reconfigurable field programmable gate arrays. IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 4(3), September 1996.
[35] W. Mangione-Smith, B. Hutchings, D. Andrews, A. DeHon, C. Ebeling, R. Hartenstein, O. Mencer, J. Morris, K. Palem, V. Prasanna, and H. Spaanenburg. Seeking solutions in configurable computing. In Computer, volume 30(12), pages 38–43, 1997.
[36] D. McGrath. Gartner Dataquest analyst gives ASIC, FPGA markets clean bill of health. EE Times, June 13, 2005.
[37] J. Millen. Covert channel capacity. In Proceedings of the 1987 IEEE Symposium on Security and Privacy, 1987.
[38] E. Nakashima. Used cellphones hold trove of secrets that can be hard to erase. Washington Post, October 21, 2006.
[39] H. Ngo, R. Gottumukkal, and V. Asari. A flexible and efficient hardware architecture for real-time face recognition based on eigenface. In Proceedings of the IEEE Computer Society Annual Symposium on VLSI, 2005.
[40] W. Niu, J. Long, D. Han, and Y.-F. Wang. Human activity detection and recognition for video surveillance. In Proceedings of the IEEE Multimedia and Expo Conference, Taipei, Taiwan, 2004.
[41] C. Percival. Cache missing for fun and profit. In BSDCan 2005, Ottawa, Ontario, Canada, 2005.
[42] B. Salefski and L. Caglar. Reconfigurable computing in wireless. In Proceedings of the Design Automation Conference (DAC), 2001.
[43] J. Saltzer and M. Schroeder. The protection of information in computer systems. Communications of the ACM, 17(7), July 1974.
[44] H. Saputra, N. Vijaykrishnan, M. Kandemir, M. Irwin, R. Brooks, S. Kim, and W. Zhang. Masking the energy behavior of DES encryption. In IEEE Design Automation and Test in Europe (DATE '03), 2003.
[45] P. Schaumont, I. Verbauwhede, K. Keutzer, and M. Sarrafzadeh. A quick safari through the reconfiguration jungle. In Proceedings of the Design Automation Conference, pages 172–7, 2001.
[46] A. Senior, S. Pankanti, A. Hampapur, L. Brown, Y.-L. Tian, and A. Ekin. Blinkering surveillance: Enabling video privacy through computer vision. Technical Report RC22886, IBM, 2003.
[47] F. Standaert, L. Oldenzeel, D. Samyde, and J. Quisquater. Power analysis of FPGAs: How practical is the attack? In Field-Programmable Logic and Applications, 2778(2003):701–711, Sept. 2003.
[48] The MathWorks Inc. MATLAB User’s Guide, 2006.
[49] K. Thompson. Reflections on trusting trust. Communications of the ACM, 27(8), 1984.
[50] J. Vuillemin, P. Bertin, D. Roncin, M. Shand, H. Touati, and P. Boucard. Programmable active memories: Reconfigurable systems come of age. In IEEE Transactions on Very Large Scale Integration (VLSI) Systems, volume 4(1), pages 56–69, 1996.
[51] S. Weingart and S. Smith. Building a high-performance, programmable secure coprocessor. Computer Networks (Special Issue on Computer Network Security), 31:831–860, April 1999.
[52] S. Wilton. Architectures and Algorithms for Field-Programmable Gate Arrays with Embedded Memory. PhD thesis, University of Toronto, 1997.
[53] Xilinx Inc. Getting Started with the Embedded Development Kit (EDK), 2006.