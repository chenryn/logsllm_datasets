### System to Issue Warnings for Phishing Attacks
The system should issue a warning if, for example, the user is about to fall victim to a phishing attack.

### Hardware Keyloggers
Resistance to physical attacks is not an explicit goal of Bumpy; however, the issue warrants discussion. Bumpy’s resilience to hardware keyloggers depends on the model used for associating new input devices with the user’s computer. If a simple plug-and-play architecture is allowed, a hardware keylogger inserted between the input device and the user’s computer can appear as a new input device to the computer and as a new computer to the input device. One alternative is to require manufacturer certification before the user’s computer will associate with the input device. However, this may be impractical, as users may perceive all certification errors as indicative of a broken device. The core research challenge here is the problem of key establishment between devices with no prior context [3, 20, 33].

### Conclusion and Future Work
We have described Bumpy, a system that protects users’ sensitive input from keyloggers and screen scrapers by excluding the legacy OS and software stack from the TCB (Trusted Computing Base) for input. Bumpy allows users to specify which input is considered sensitive, thus extending protection beyond just passwords. It also enables web servers to define how input deemed sensitive by their users is handled and allows users’ systems to generate attestations that input protections are in place. With a separate local device, Bumpy can provide the user with a positive indicator that her input is protected. We have implemented Bumpy and demonstrated that it is efficient and compatible with existing legacy software.

We intend to continue developing a usable solution for protecting more substantial input, such as composing a sensitive letter. Additionally, we plan to evaluate the current Bumpy architecture through a formal user study.

### Acknowledgments
The authors would like to thank Karthik S. Lakshmanan and Anthony Rowe for their advice on embedded Linux systems and USB. Bryan Parno and Ahren Studer provided valuable feedback and suggestions for the design, implementation, and writing. We are grateful for the observations from the CyLab Student Seminar audience on October 17, 2008, and the Security Group Lunch audience at UNC on November 12, 2008. Unrestrained comments from our anonymous reviewers were also helpful.

### References
[1] Advanced Micro Devices. AMD64 Architecture Programmer’s Manual: Volume 2: System Programming. AMD Publication no. 24593 rev. 3.14, September 2007.
[2] D. Balfanz and E. W. Felten. Hand-held computers can be better smart cards. In Proceedings of the USENIX Security Symposium, August 1999.
[3] D. Balfanz, D. Smetters, P. Stewart, and H. C. Wong. Talking to strangers: Authentication in ad-hoc wireless networks. In Proceedings of the Symposium on Network and Distributed Systems Security (NDSS), February 2002.
[4] BeagleBoard.org. BeagleBoard Revision B6 System Reference Manual Revision 0.1. BeagleBoard.org, November 2008.
[5] K. Borders and A. Prakash. Securing network input via a trusted input proxy. In Proceedings of the USENIX Workshop on Hot Topics in Security (HotSec), August 2007.
[6] E. Brickell, J. Camenisch, and L. Chen. Direct anonymous attestation. In Proceedings of the ACM Conference on Computer and Communications Security (CCS), October 2004.
[7] S. Chiasson, P. C. van Oorschot, and R. Biddle. A usability study and critique of two password managers. In Proceedings of the USENIX Security Symposium, August 2006.
[8] P. England, B. Lampson, J. Manferdelli, M. Peinado, and B. Willman. A trusted open platform. IEEE Computer, 36(7):55–62, July 2003.
[9] N. Feske and C. Helmuth. A nitpicker’s guide to a minimal-complexity secure GUI. In Proceedings of the Annual Computer Security Applications Conference (ACSAC), 2005.
[10] E. Gabber, P. Gibbons, Y. Matias, and A. Mayer. How to make personalized web browsing simple, secure, and anonymous. In Proceedings of Financial Cryptography, 1997.
[11] E. Gabber, P. B. Gibbons, D. M. Kristol, Y. Matias, and A. Mayer. On secure and pseudonymous client-relationships with multiple servers. ACM Trans. Inf. Syst. Secur., 2(4):390–415, 1999.
[12] IBM Zurich Research Lab. Security on a stick. Press release, October 2008.
[13] Intel Corporation. Trusted Execution Technology – Preliminary Architecture Specification and Enabling Considerations. Document number 31516803, November 2006.
[14] M. Jakobsson and S. Myers. Phishing and Countermeasures: Understanding the Increasing Problem of Electronic Identity Theft. Wiley, December 2006.
[15] J. Jonsson and B. Kaliski. PKCS #1: RSA Cryptography Specifications Version 2.1. RFC 3447, February 2003.
[16] B. Kauer. OSLO: Improving the security of Trusted Computing. In Proceedings of the USENIX Security Symposium, August 2007.
[17] K. Kursawe, D. Schellekens, and B. Preneel. Analyzing trusted platform communication. In Proceedings of the Cryptographic Advances in Secure Hardware Workshop (CRASH), September 2005.
[18] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and H. Isozaki. Flicker: An execution infrastructure for TCB minimization. In Proceedings of the ACM European Conference in Computer Systems (EuroSys), April 2008.
[19] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and A. Seshadri. Minimal TCB code execution (extended abstract). In Proceedings of the IEEE Symposium on Security and Privacy, May 2007.
[20] J. M. McCune, A. Perrig, and M. K. Reiter. Seeing-is-believing: Using camera phones for human-verifiable authentication. In Proceedings of the IEEE Symposium on Security and Privacy, May 2005.
[21] J. M. McCune, A. Perrig, and M. K. Reiter. Bump in the ether: A framework for securing sensitive user input. In Proceedings of the USENIX Annual Technical Conference, June 2006.
[22] B. Parno. Bootstrapping trust in a “trusted” platform. In Proceedings of the USENIX Workshop on Hot Topics in Security (HotSec), July 2008.
[23] M. Peinado, Y. Chen, P. England, and J. Manferdelli. NGSCB: A trusted open system. In Proceedings of the Australasian Conference on Information Security and Privacy (ACISP), July 2004.
[24] Proliﬁc Technology Inc. PL-25A1 Hi-Speed USB Host to Host Bridge Controller. PL-25A1 Product Brochure, October 2006.
[25] B. Ross, C. Jackson, N. Miyake, D. Boneh, and J. C. Mitchell. Stronger password authentication using browser extensions. In Proceedings of the USENIX Security Symposium, August 2005.
[26] A.-R. Sadeghi, M. Selhorst, C. St¨uble, C. Wachsmann, and M. Winandy. TCG inside? - A note on TPM specification compliance. In Proceedings of the ACM Workshop on Scalable Trusted Computing (STC), November 2006.
[27] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn. Design and implementation of a TCG-based integrity measurement architecture. In Proceedings of the USENIX Security Symposium, August 2004.
[28] J. H. Saltzer and M. D. Schroeder. The protection of information in computer systems. Proceedings of the IEEE, 63(9):1278–1308, September 1975.
[29] R. Sharp, A. Madhavapeddy, R. Want, and T. Pering. Enhancing web browsing security on public terminals using mobile composition. In Proceedings of the Conference on Mobile Systems, Applications, and Services (MobiSys), June 2008.
[30] R. Sharp, A. Madhavapeddy, R. Want, T. Pering, and J. Light. Fighting crimeware: An architecture for split-trust web applications. Technical Report IRC-TR-06-053, Intel Research Center, April 2006.
[31] R. Sharp, J. Scott, and A. Beresford. Secure mobile computing via public terminals. In Proceedings of the International Conference on Pervasive Computing, May 2006.
[32] D. X. Song, D. Wagner, and X. Tian. Timing analysis of keystrokes and timing attacks on SSH. In Proceedings of the USENIX Security Symposium, August 2001.
[33] F. Stajano and R. Anderson. The resurrecting duckling: Security issues for ad-hoc wireless networks. In Proceedings of the Security Protocols Workshop, 1999.
[34] Trusted Computing Group. Trusted Platform Module Main Specification, Part 1: Design Principles, Part 2: TPM Structures, Part 3: Commands. Version 1.2, Revision 103, July 2007.
[35] D. Wendlandt, D. G. Andersen, and A. Perrig. Perspectives: Improving SSH-style host authentication with multi-path probing. In Proceedings of the USENIX Annual Technical Conference, June 2008.
[36] D. A. Wheeler. Linux Kernel 2.6: It’s worth more! Available at: http://www.dwheeler.com/essays/linux-kernel-cost.html, October 2004.

### TCG-Style Attestation and Sealed Storage
The v1.2 Trusted Platform Module (TPM) chip contains an array of 24 or more Platform Configuration Registers (PCRs), each capable of storing a 160-bit hash. These PCRs can be extended with a measurement (cryptographic hash) of data, such as a program binary. Given a measurement \( m \leftarrow \text{SHA1}(\text{data}) \), the extend process works as follows:
\[ \text{PCR}_{\text{new}} \leftarrow \text{SHA1}(\text{PCR}_{\text{old}} || m) \]

TPMs include two kinds of PCRs: static and dynamic. Static PCRs reset to \( 0^{160} \) when the TPM itself resets (generally during a full platform reset or power-cycle, although physical TPM-reset attacks have been demonstrated [16, 17, 26]), and can only have their value updated via an Extend operation. These PCRs can be used to keep a record of measurements for all software loaded since the last reboot, as in IBM’s Integrity Measurement Architecture [27].

Dynamic PCRs are present in v1.2 TPMs and are relevant when the platform supports Dynamic Root of Trust, e.g., Intel TXT [13] or AMD SVM [1]. Dynamic PCRs reset to \( 1^{160} \) during a full platform reset and can additionally be reset to \( 0^{160} \) via a Late Launch, thereby establishing a Dynamic Root of Trust. In addition to resetting the dynamic PCRs, Late Launch resets the CPU to a known trusted state without rebooting the rest of the system. This includes configuring the system’s memory controller to prevent access to the launching code from DMA-capable devices. One of the newly reset dynamic PCRs is then automatically extended with a measurement of the software that will get control following the Late Launch [1]. This enables software to bootstrap without including the BIOS or any system peripherals in the TCB. The Open Secure Loader (OSLO) performs a Late Launch on AMD systems to remove the BIOS from the TCB of a Linux system [16]. Trusted Boot6 from Intel performs similarly for Intel hardware, though it adds the ability to enforce a Launch Control Policy. The Flicker system uses Late Launch to briefly interrupt the execution of a legacy OS and execute a special-purpose code module in isolation from all other software and devices on the platform, before returning control to the legacy OS [18].

Once measurements have accumulated in the PCRs, they can be attested to a remote party to demonstrate what software has been loaded on the platform. They can also be used to seal data to a particular platform configuration. We discuss each of these in turn.

#### Attestation
The attestation process involves a challenge-response protocol, where the challenger sends a cryptographic nonce (for replay protection) and a list of PCR indexes, and requests a TPM Quote over the listed PCRs. A Quote is a digital signature computed over an aggregate of the listed PCRs using an Attestation Identity Key (AIK). An AIK is an asymmetric signing keypair generated on the TPM. We discuss the certification of AIKs shortly. The messages exchanged between a challenger \( C \) and an untrusted system \( U \) to perform an attestation are:
\[ C \rightarrow U : \text{nonce}, \text{PCRindexes} \]
\[ U \rightarrow C: \text{PCRvals}, \{\text{PCRvals}, \text{nonce}\}_{\text{AIK}^{-1}} \]

Once the challenger receives the attestation response, it must (1) verify its nonce is part of the reply, (2) check the signature with the public AIK obtained via an authentic channel, (3) verify that the list of PCR values received corresponds to those in the digital signature, and (4) verify that the PCR values themselves represent an acceptable set of loaded software. Note that since the sensitive operations for a TPM Quote take place entirely within the TPM chip, the TPM Quote operation can safely be invoked from untrusted software. The only attack available to malicious software is denial-of-service. In the context of the Flicker system, this removes the code that causes the TPM Quote to be generated from the system’s TCB.

#### Certifying Platform Identity
The Attestation Identity Keypair (AIK) used to perform the TPM Quote effectively represents the identity of the attesting host. We discuss options for certifying this keypair (i.e., obtaining an authentic copy of the public AIK for a particular physical host).

Multiple credentials are provided by TPM and host manufacturers that are intended to convince a remote party that they are communicating with a valid TPM installed in a host in conformance with the relevant specifications [34]. These are the TPM’s Endorsement Key (EK) Credential, Platform Credential, and Conformance Credential. One option is to use these credentials directly as the host’s identity, but the user’s privacy may be violated. Motivated by privacy concerns, the Trusted Computing Group (TCG) has specified Privacy Certificate Authorities (Privacy CAs). Privacy CAs are responsible for certifying that an AIK generated by a TPM comes from a TPM and host with valid Endorsement Key, Platform, and Conformance Credentials.

To the best of our knowledge, there are no commercial Privacy CAs in operation today. Thus, we must either provide all of the credentials corresponding to the untrusted host to the challenger (compromising privacy), or the challenger must blindly accept the AIK without performing any verification (compromising host identity, and adopting the trust-on-first-use model). Trust-on-first-use models have been deployed successfully, e.g., for the Secure Shell (SSH) protocol. Thus, we believe the choice of which host identity mechanism to use is application-dependent. For communication with a bank or established online merchant, where an honest user almost always provides her true identity, it is not clear that there is any loss of privacy by providing the full set of TPM and host credentials.

Direct Anonymous Attestation (DAA) has also been proposed as an alternative to Privacy CAs for protecting platform identity [6]. To the best of our knowledge, no systems are available today that include TPMs supporting DAA.

#### Sealed Storage
TPM-protected sealed storage is a mechanism by which an asymmetric encryption keypair can be bound to certain PCR values. Data encrypted under this keypair then becomes unavailable unless the PCR values match those specified when the data was sealed. This is a relatively slow process since the asymmetric cryptographic operations are performed by the low-cost CPU inside the TPM. An alternative is to use the TPM’s Non-Volatile RAM (NV-RAM) facility. NV-RAM can be configured with similar properties to sealed storage, in that a region of NV-RAM can be made inaccessible unless the PCR values match those specified when the region was defined. NV-RAM has a limited number of write cycles during the TPM’s lifetime, but the use of a symmetric master key that is only read from NV-RAM in the common case can greatly extend its life. Flicker can use TPM sealed storage or NV-RAM to protect long-term state that is manipulated during Flicker sessions.