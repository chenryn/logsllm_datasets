### Copilot and Security Quality of Generated Code

Copilot, a code generation tool, is trained on open-source code available on GitHub. We hypothesize that the variable security quality of the generated code stems from the nature of the community-provided code. Specifically, if certain bugs are more prevalent in open-source repositories, Copilot is more likely to reproduce these bugs. However, this should not be taken as a definitive statement on the overall security quality of open-source repositories on GitHub. To date, there are no comprehensive studies evaluating the entire GitHub dataset or the subset used for training Copilot, making this an open question for future research.

Another critical aspect to consider is the temporal dimension of security practices. What is considered 'best practice' at the time of writing may become 'bad practice' as the cybersecurity landscape evolves. Outdated practices can persist in the training set, leading to code generation based on obsolete approaches. For example, in the context of password hashing, MD5 was once considered secure, followed by a single round of SHA-256 with a salt. Today, best practices involve multiple rounds of a simple hashing function or the use of libraries like 'bcrypt' that age gracefully. Unmaintained and legacy code often uses insecure hashes, and Copilot may continue to suggest these.

### Threats to Validity

1. **CodeQL Limitations:**
   - While we aimed to evaluate as many scenarios as possible using GitHub’s CodeQL, some Common Weakness Enumerations (CWEs) could not be easily processed. CodeQL builds graphs of program content and structure, excelling in identifying self-evident vulnerabilities, such as SQL injection. However, it has limitations in parsing important information, particularly concerning memory buffer sizes and deriving memory boundaries. Additionally, some CWEs require contextual information beyond the codebase, making them difficult to evaluate. For instance, CWE-434 (Unrestricted Upload of File with Dangerous Type) is challenging to assess without additional context. Furthermore, while we made efforts to ensure the accuracy of test cases and results, there may be edge cases where CodeQL marked something as vulnerable when it was not.
   - For languages and scenarios not supported by CodeQL (e.g., Verilog), CWEs had to be manually marked. We strived for objective outputs by strictly adhering to the definitions of the relevant CWEs. However, the human element introduces the possibility of debatable results.

2. **Statistical Validity:**
   - The number of samples in each scenario may not be sufficient for drawing statistically significant conclusions. The manual nature of using the GitHub Copilot interface limited the number of samples we could collect. Additionally, the lack of a formal definition for the 'mean prob' score returned by Copilot further hampers our ability to make statistical claims. Despite these limitations, we believe our empirical findings are noteworthy.

3. **Reproducible Code Generation:**
   - As a generative model, Copilot's outputs are not directly reproducible. For the same prompt, Copilot can generate different answers at different times. Given that Copilot is a black-box, closed-source system, general users cannot examine the underlying model. The manual effort required to query Copilot, combined with rate-limiting, makes efficient data collection challenging. To address this, we archived all options for every provided prompt to ensure reproducibility.

4. **Scenario Creation:**
   - Our experiments cover a range of scenarios and potential weaknesses in three different programming languages. While these scenarios provide insights into Copilot's behavior, they are artificial and do not fully reflect the complexity of real-world code, which includes more context and variability. Subtle variations in prompts can affect Copilot's code generation, and broader contexts with higher-quality code can yield more secure suggestions. Future work should explore how Copilot responds to combinations of prompts and scenarios to identify biases. Additionally, the vast array of languages supported by Copilot requires methods to quantify the limits of such models, especially for low-level or esoteric languages like x86 assembly, ladder logic, and g-code.

### Disclosures

The findings of this paper do not lead to exploitable vulnerabilities in the GitHub Copilot product. We simply examined the tool as intended, generating code samples and evaluating their properties. Therefore, coordinated vulnerability disclosure was not necessary.

### Conclusions and Future Work

Next-generation 'auto-complete' tools like GitHub Copilot will undoubtedly increase the productivity of software developers. However, while Copilot can rapidly generate large amounts of code, developers should remain vigilant when using it. Ideally, Copilot should be paired with appropriate security-aware tooling during both training and generation to minimize the risk of introducing security vulnerabilities. Our study provides new insights into its behavior in response to security-relevant scenarios, but future work should investigate other aspects, including adversarial approaches for security-enhanced training.

### References

[1] “GitHub Copilot · Your AI pair programmer.” [Online]. Available: https://copilot.github.com/

[2] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and W. Zaremba, “Evaluating Large Language Models Trained on Code,” arXiv:2107.03374 [cs], Jul. 2021, arXiv: 2107.03374. [Online]. Available: http://arxiv.org/abs/2107.03374

[3] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le, and C. Sutton, “Program Synthesis with Large Language Models,” arXiv:2108.07732 [cs], Aug. 2021, arXiv: 2108.07732. [Online]. Available: http://arxiv.org/abs/2108.07732

[4] The MITRE Corporation (MITRE), “2021 CWE Top 25 Most Dangerous Software Weaknesses,” 2021. [Online]. Available: https://cwe.mitre.org/top25/archive/2021/2021 cwe top25.html

[5] G. Inc., “CodeQL documentation,” 2021. [Online]. Available: https://codeql.github.com/docs/

[6] The MITRE Corporation (MITRE), “CWE-1194: CWE VIEW: Hardware Design,” Jul. 2021. [Online]. Available: https://cwe.mitre.org/data/deﬁnitions/1194.html

[7] D. Zhang and J. J. Tsai, “Machine Learning and Software Engineering,” Software Quality Journal, vol. 11, no. 2, pp. 87–119, Jun. 2003. [Online]. Available: https://doi.org/10.1023/A:1023760326768

[8] N. Jiang, T. Lutellier, and L. Tan, “CURE: Code-Aware Neural Machine Translation for Automatic Program Repair,” in 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), May 2021, pp. 1161–1173, iSSN: 1558-1225.

[9] R. Mihalcea, H. Liu, and H. Lieberman, “NLP (Natural Language Processing) for NLP (Natural Language Programming),” in Computational Linguistics and Intelligent Text Processing, A. Gelbukh, Ed. Springer Berlin Heidelberg, 2006, pp. 319–330.

[10] R. Drechsler, I. G. Harris, and R. Wille, “Generating formal system models from natural language descriptions,” in IEEE Int. High Level Design Validation and Test Workshop (HLDVT), 2012, pp. 164–165.

[11] C. B. Harris and I. G. Harris, “GLAsT: Learning formal grammars to translate natural language specifications into hardware assertions,” in Design, Automation Test in Europe Conf. Exhibition (DATE), 2016, pp. 966–971.

[12] K. M. T. H. Rahit, R. H. Nabil, and M. H. Huq, “Machine Translation from Natural Language to Code Using Long-Short Term Memory,” in Future Technologies Conf. (FTC). Springer International Publishing, Oct. 2019, pp. 56–63, iSSN: 2194-5365.

[13] M. Sundermeyer, R. Schl¨uter, and H. Ney, “LSTM neural networks for language modeling,” in Conf. Int. Speech Communication Assoc., 2012.

[14] P. Liu, X. Qiu, and X. Huang, “Recurrent Neural Network for Text Classification with Multi-Task Learning,” CoRR, vol. abs/1605.05101, 2016, eprint: 1605.05101. [Online]. Available: http://arxiv.org/abs/1605.05101

[15] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \. Kaiser, and I. Polosukhin, “Attention is All you Need,” in Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds. Curran Associates, Inc., 2017, pp. 5998–6008.

[16] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,” CoRR, vol. abs/1810.04805, 2018, eprint: 1810.04805. [Online]. Available: http://arxiv.org/abs/1810.04805

[17] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, “Language Models are Unsupervised Multitask Learners,” p. 24, 2019. [Online]. Available: https://cdn.openai.com/better-language-models/language models are unsupervised multitask learners.pdf

[18] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, “Language Models are Few-Shot Learners,” arXiv:2005.14165 [cs], Jul. 2020, arXiv: 2005.14165. [Online]. Available: http://arxiv.org/abs/2005.14165

[19] S. Reddy, D. Chen, and C. D. Manning, “CoQA: A Conversational Question Answering Challenge,” Transactions of the Association for Computational Linguistics, vol. 7, pp. 249–266, 2019.

[20] H. Pearce, B. Tan, and R. Karri, “DAVE: Deriving Automatically Verilog from English,” in Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD. Virtual Event Iceland: ACM, Nov. 2020, pp. 27–32. [Online]. Available: https://dl.acm.org/doi/10.1145/3380446.3430634

[21] OWASP, “Source Code Analysis Tools.” [Online]. Available: https://owasp.org/www-community/Source Code Analysis Tools

[22] V. Bandara, T. Rathnayake, N. Weerasekara, C. Elvitigala, K. Thilakarathna, P. Wijesekera, and C. Keppitiyagama, “Fix that Fix Commit: A real-world remediation analysis of JavaScript projects,” in 2020 IEEE 20th International Working Conference on Source Code Analysis and Manipulation (SCAM), Sep. 2020, pp. 198–202.

[23] The MITRE Corporation (MITRE), “CWE - CWE-Compatible Products and Services,” Dec. 2020. [Online]. Available: https://cwe.mitre.org/compatible/compatible.html

[24] J. Li, B. Zhao, and C. Zhang, “Fuzzing: a survey,” Cybersecurity, vol. 1, no. 1, p. 6, Dec. 2018. [Online]. Available: https://cybersecurity.springeropen.com/articles/10.1186/s42400-018-0002-y

[25] G. Dessouky, D. Gens, P. Haney, G. Persyn, A. Kanuparthi, H. Khattri, J. M. Fung, A.-R. Sadeghi, and J. Rajendran, “HardFails: Insights into Software-Exploitable Hardware Bugs,” in 28th USENIX Security Symposium, 2019, pp. 213–230. [Online]. Available: https://www.usenix.org/conference/usenixsecurity19/presentation/dessouky

[26] M. Fischer, F. Langer, J. Mono, C. Nasenberg, and N. Albartus, “Hardware Penetration Testing Knocks Your SoCs Off,” IEEE Design Test, vol. 38, no. 1, pp. 14–21, Feb. 2021, conference Name: IEEE Design Test.

[27] G. Nichols, “RTL Linting Sign Off - Ascent Lint.” [Online]. Available: https://www.realintent.com/rtl-linting-ascent-lint/

[28] “Verilator User’s Guide — Verilator 4.202 documentation.” [Online]. Available: https://verilator.org/guide/latest/#

[29] D. Zhang, Y. Wang, G. E. Suh, and A. C. Myers, “A Hardware Design Language for Timing-Sensitive Information-Flow Security,” in Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems. Istanbul Turkey: ACM, Mar. 2015, pp. 503–516. [Online]. Available: https://dl.acm.org/doi/10.1145/2694344.2694372

[30] S. Deng, D. Gümüşoğlu, W. Xiong, S. Sari, Y. S. Gener, C. Lu, O. Demir, and J. Szefer, “SecChisel Framework for Security Verification of Secure Processor Architectures,” in Proceedings of the 8th International Workshop on Hardware and Architectural Support for Security and Privacy. Phoenix AZ USA: ACM, Jun. 2019, pp. 1–8. [Online]. Available: https://dl.acm.org/doi/10.1145/3337167.3337174

### Appendix

#### Rationale for Excluding Certain CWEs from Analysis

In this study, we did not design "CWE scenarios" (Copilot prompts) for several CWEs from the MITRE Top-25. Generally, we omitted CWEs where CodeQL could not be configured to detect the weakness, where considerable context outside the source code file was required, or where the security issue was more architectural than code-level.

- **CWE-352: Cross-Site Request Forgery (CSRF):** This compound-type CWE covers scenarios where a web application does not verify that a request was intentionally made by the user. Determining the presence of this weakness is complex, requiring both front-end and back-end code analysis. Tools like CodeQL cannot check for this CWE. Fortunately, preventing CWE-352 in Python web applications, such as Flask, is straightforward by enabling the appropriate built-in extension.

- **CWE-287: Improper Authentication:** This class-type CWE covers a wide range of scenarios where an actor claims an identity without sufficient proof. Given its broad scope, it is challenging to create concrete scenarios for evaluation, especially since it is a parent of CWE-306 and CWE-522. Thus, we did not analyze this CWE.

- **CWE-862: Missing Authorization:** This class-type CWE describes scenarios where no authorization check is performed for accessing critical resources or performing sensitive actions. It is related to CWE-285, which was also excluded. Errors related to this CWE are typically architectural rather than coding issues.

- **CWE-276: Incorrect Default Permissions:** This base-type CWE covers situations where default permissions for files are poorly set during installation, allowing any user to modify these files. It is a system or architectural-level issue rather than a code-level issue.

- **CWE-611: Improper Restriction of XML External Entity Reference:** This base-type CWE applies to parsing XML files containing external entity references. Determining vulnerability requires significant context and code, so we excluded it from analysis.

- **CWE-918: Server-Side Request Forgery (SSRF):** This base-type CWE refers to scenarios where web applications receive URL requests from upstream components without ensuring the requests are sent to expected destinations. Similar to CWE-352, it is difficult to check and requires examining multiple interacting components and languages.

- **CWE-77: Improper Neutralization of Special Elements used in a Command (Command Injection):** This class-type CWE covers scenarios where commands are built from user-controlled or upstream components without neutralizing special elements. As it is a parent class of both CWE-78 (OS command injection) and CWE-89 (SQL Injection), both of which we analyzed, we did not analyze this CWE.

### Source and Dataset Access

The dataset containing the 89 CWE-based scenarios, as well as the source code of the experimental framework, is available for download at the following URL: https://doi.org/10.5281/zenodo.5225650.

### Disclaimer

Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation nor the Office of Naval Research.