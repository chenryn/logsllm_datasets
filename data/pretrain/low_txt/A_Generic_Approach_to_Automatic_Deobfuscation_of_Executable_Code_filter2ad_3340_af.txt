# Code Coverage and Deobfuscation Techniques

## Introduction
Code coverage can be a significant issue when relying on dynamic analysis, as it only observes one execution path through the program. To address this, we employ multi-path exploration techniques based on concolic execution to identify inputs that exercise alternative execution paths, thereby increasing code coverage [21], [18]. The constraints used to identify these alternative inputs are derived from an execution trace, which can be either the original (obfuscated) trace or the simplified trace in our system.

### Experimental Observations
Our experiments indicate that obfuscation often results in larger and more complex traces, leading to more complex constraints. These complex constraints require more time and memory to solve. We found that the constraint solver (in our case, STP [32]) frequently fails to find solutions for constraints obtained from the original traces due to time or memory limitations. However, it successfully solves those derived from the simplified traces. Therefore, deobfuscation is also beneficial for exploring alternative behaviors in obfuscated executables.

## Control Flow Graphs
Partial control flow graphs for the Win32/Kryptik.OHY Trojan before and after deobfuscation are shown in Figure 10. Basic blocks that perform code unpacking, i.e., write to memory locations that are subsequently executed as code, are highlighted in red.

## Threat Model and Adversary Strategies
Our threat model assumes that the adversary is aware of our semantics-based approach to deobfuscation. We recognize three primary strategies an adversary might use to reduce the effectiveness of our analysis:

1. **Entwining Obfuscation with I/O Operations**: The adversary can deeply entwine the obfuscation code with the original input-to-output computation, making it difficult to simplify away.
2. **Introducing Additional I/O Operations**: The adversary can introduce new input/output operations along with obfuscation code that operates on the new input-to-output flow.
3. **Hiding Computation**: The adversary can hide some of the computation performed by the program, such as performing the computation on a remote host where it cannot be observed.

### Analysis of Adversary Strategies
- **Entwining Obfuscation**: This approach is challenging because even simple transformations can affect the observable behavior of the program, such as changing use/definition relationships, introducing arithmetic overflow/underflow, or perturbing condition code settings. Such entanglement would require sophisticated program analyses beyond current obfuscation tools.
- **Introducing New I/O Operations**: This changes the program's semantics, making it impossible for a deobfuscation tool to automatically disregard semantically significant operations. Our approach can be extended interactively by allowing the user to specify certain input and output operations to be disregarded.
- **Hiding Computation**: Performing computation elsewhere, such as on a remote host, is a fundamental limitation for any automatic deobfuscation tool. This strategy is a challenge for all known approaches to automatic deobfuscation.

## Related Work
The work closest to ours is that of Coogan et al. [6], who use equational reasoning about assembly-level instruction semantics to simplify obfuscation code from execution traces. While their goals are similar, our approach offers more control over the deobfuscation process and allows us to recover higher-level representations, such as control flow graphs, with high precision. Additionally, we handle multiple levels of emulation and other kinds of programs, such as ROPs.

Sharif et al. [5] describe an outside-in approach that first reverse engineers the VM emulator and then recovers the logic embedded in the byte code program. This approach is effective when the emulator structure meets the analyzer's assumptions but may not work well otherwise. For example, it does not fully deobfuscate code obfuscated using Themida, which virtualizes the unpacker routine for emulator instructions.

## Conclusions
This paper presents a generic approach to deobfuscating executable code. Instead of making strong assumptions about the obfuscation, we focus on the semantics of the program in terms of the input-to-output transformation it implements. Our approach has been evaluated on emulation-based obfuscation and return-oriented programs, demonstrating its effectiveness in stripping out obfuscation and extracting the logic of the original code.

## Acknowledgments
We thank Patrick Chan for his implementation of the control flow graph similarity algorithm used in our evaluation.

## References
[1] Oreans Technologies, “Code virtualizer: Total obfuscation against reverse engineering,” www.oreans.com/codevirtualizer.php.
[2] StrongBit Technology, “EXECryptor – bulletproof software protection,” www.strongbit.com/execryptor.asp.
[3] VMProtect Software, “VMProtect – New-generation software protection,” www.vmprotect.ru/.
[4] Oreans Technologies, “Themida: Advanced windows software protection system,” www.oreans.com/themida.php.
[5] M. Sharif, A. Lanzi, J. Giffin, and W. Lee, “Automatic reverse engineering of malware emulators,” in Proc. 2009 IEEE Symposium on Security and Privacy, May 2009.
[6] K. Coogan, G. Lu, and S. Debray, “Deobfuscating virtualization-obfuscated software: A semantics-based approach,” in Proc. ACM Conference on Computer and Communications Security (CCS), Oct. 2011, pp. 275–284.
[7] R. Roemer, E. Buchanan, H. Shacham, and S. Savage, “Return-oriented programming: Systems, languages, and applications,” ACM Transactions on Information and System Security, vol. 15, no. 1, pp. 2:1–2:??, Mar. 2012.
[8] H. Shacham, “The geometry of innocent flesh on the bone: return-into-libc without function calls (on the x86),” in proc. ACM Conference on Computer and Communications Security, 2007, pp. 552–561.
[9] K. Lu, D. Zou, W. Wen, and D. Gao, “deRop: removing return-oriented programming from malware,” in Proc. 27th. Annual Computer Security Applications Conference (ACSAC), Dec. 2011, pp. 363–372.
[10] T. Bletsch, X. Jiang, V. Freeh, and Z. Liang, “Jump-oriented programming: A new class of code-reuse attack,” in Proc. 6th ACM Symposium on Information, Computer and Communications Security, ser. ASIACCS ’11, 2011, pp. 30–40.
[11] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham, and M. Winandy, “Return-oriented programming without returns,” in Proc. ACM Conference on Computer and Communications Security, 2010, pp. 559–572.
[12] C. Kruegel, W. Robertson, F. Valeur, and G. Vigna, “Static disassembly of obfuscated binaries,” in Proc. 13th USENIX Security Symposium, Aug. 2004.
[13] M. G. Kang, P. Poosankam, and H. Yin, “Renovo: A hidden code extractor for packed executables,” in Proc. Fifth ACM Workshop on Recurring Malcode (WORM 2007), Nov. 2007.
[14] J. Stoy, Denotational Semantics of Programming Languages: The Scott-Strachey Approach to Programming Language Theory. MIT, 1977.
[15] P. Ferrie, “Prophet loss,” Virus Bulletin, Sep. 2008, www.virusbtn.com/virusbulletin/archive/2008/09/vb200809-prophet-loss.
[16] A. Dinaburg, P. Royal, M. I. Sharif, and W. Lee, “Ether: malware analysis via hardware virtualization extensions,” in Proc. ACM Conference on Computer and Communications Security (CCS), Oct. 2008, pp. 51–62.
[17] B. Yadegari and S. Debray, “Bit-level taint analysis,” in Source Code Analysis and Manipulation (SCAM), 2014 IEEE 14th International Working Conference on. IEEE, 2014, pp. 255–264.
[18] D. Brumley, C. Hartwig, Z. Liang, J. Newsome, D. Song, and H. Yin, “Automatically identifying trigger-based behavior in malware,” in Botnet Detection. Springer, 2008, pp. 65–88.
[19] V. Chipounov, V. Kuznetsov, and G. Candea, S2E: A platform for in-vivo multi-path analysis of software systems. ACM, 2011, vol. 39, no. 1.
[20] K. Sen, D. Marinov, and G. Agha, CUTE: a concolic unit testing engine for C. ACM, 2005, vol. 30, no. 5.
[21] A. Moser, C. Kruegel, and E. Kirda, “Exploring multiple execution paths for malware analysis,” in Security and Privacy, 2007. SP’07. IEEE Symposium on. IEEE, 2007, pp. 231–245.
[22] E. J. Schwartz, T. Avgerinos, and D. Brumley, “All you ever wanted to know about dynamic taint analysis and forward symbolic execution (but might have been afraid to ask),” in IEEE Symposium on Security and Privacy, 2010, pp. 317–331.
[23] C. Collberg, C. Thomborson, and D. Low, “Manufacturing cheap, resilient, and stealthy opaque constructs,” in Proc. 25th. ACM Symp. Principles of Programming Languages (POPL 1998), Jan. 1998, pp. 184–196.
[24] A. V. Aho, M. S. Lam, R. Sethi, and J. D. Ullman, Compilers – Principles, Techniques, and Tools. Reading, Mass.: Addison-Wesley, 2007.
[25] D. Angluin, “On the complexity of minimum inference of regular sets,” Information and Control, vol. 39, no. 3, pp. 337–350, 1978.
[26] E. M. Gold, “Complexity of automaton identification from given data,” Information and Control, vol. 37, pp. 302–320, 1978.
[27] L. Pitt and M. K. Warmuth, “The minimum consistent DFA problem cannot be approximated within any polynomial,” J. ACM, vol. 40, no. 1, pp. 95–142, 1993.
[28] X. Hu, T.-C. Chiueh, and K. G. Shin, “Large-scale malware indexing using function-call graphs,” in Proc. ACM Conference on Computer and Communications Security, Nov. 2009, pp. 611–620.
[29] W. worm, 2003-20.cfm.
[30] W32.Netsky.AE, www.cert.org/historical/advisories/CA-writeup.jsp?docid=2004-102522-4640-99&tabid=2.
[31] pakt, “ROPC – Turing complete ROP compiler,” http://gdtr.wordpress.com/2013/12/13/ropc-turing-complete-rop-compiler-part-1/.
[32] V. T. Ganesh and Hansen, “STP,” https://github.com/stp/stp.
[33] S. K. Udupa, S. K. Debray, and M. Madou, “Deobfuscation: Reverse engineering obfuscated code,” in Proc. 12th IEEE Working Conference on Reverse Engineering, Nov. 2005, pp. 45–54.
[34] C. Wang, J. Davidson, J. Hill, and J. Knight, “Protection of software-based survivability mechanisms,” in Proc. International Conference of Dependable Systems and Networks, Jul. 2001.
[35] N. D. Jones, C. K. Gomard, and P. Sestoft, Partial Evaluation and Automatic Program Generation. Prentice Hall, 1993.
[36] L. Davi, A.-R. Sadeghi, and M. Winandy, “ROPdefender: a detection tool to defend against return-oriented programming attacks,” in Proc. 6th ACM Symposium on Information, Computer and Communications Security (ASIACCS), Mar. 2011, pp. 40–51.
[37] K. Onarlioglu, L. Bilge, A. Lanzi, D. Balzarotti, and E. Kirda, “G-free: defeating return-oriented programming through gadget-less binaries,” in Proc. 26th. Annual Computer Security Applications Conference (ACSAC), Dec. 2010, pp. 49–58.
[38] Y. Cheng, Z. Zhou, M. Yu, X. Ding, and R. H. Deng, “ROPecker: A generic and practical approach for defending against ROP attack,” in Proc. 21th Annual Network and Distributed System Security Symposium (NDSS), Feb. 2014.