### 优化后的文本

#### 表7: 给定T'的S条件分布
| T′ | cwdn | cndw | cndn | cwdw |
|---|------|------|------|------|
| S | 0.86 | 0.14 | 0.5  | 0.5  |
| d | 0.14 | 0.86 | 0.5  | 0.5  |

#### 表8: 给定T'的S条件分布
| T′ | cwdn | cndw | cndn | cwdw |
|---|------|------|------|------|
| S | 0.5  | 0.5  | 0.5  | 0.5  |
| d | 0.5  | 0.5  | 0.5  | 0.5  |

表7显示了给定T'的S条件分布。由于St1,A的评估值接近其最大值（本例中为1），因此由抑制t1引起的隐私增强显著。我们省略了效用退化的计算，因为t1并未改变T，这意味着Ut1,A = 0。

尽管St1,A = 0.717表明有相当程度的隐私增强，但仍然存在从t1(A)推断S的可能性，这是由于S和T之间的相关性。为了应对这个问题，我们采用置换t2随机重排照片标签，使得对手无法确定朋友c是否最初被标记在婚礼照片或自然照片中。

假设t2的输入是t1(A)的输出（即T'），则t2(t1(A))的输出如表6所示。如果一个朋友在一个照片中被标记，在置换后，他/她有0.5的概率被标记在另一张照片中，有0.5的概率保持不变。置换t2引起的隐私增强如下：
- St1(A) = 0.283 根据公式(11)
- St2(t1(A)) = H(S) - H(S | t2(t1(A))) = 1 - H(S | T') = 0
- St2,t1(A) = 0.283 - 0 = 0.283

表8显示了所需的P(S | T')。由于我们的隐私增强度量是可加的，t = t2○t1对A的总隐私增强计算如下：
- St,A = St1,A + St2,t1(A) = 0.717 + 0.283 = 1

结果，t完全隐藏了S，因为它达到了最大的隐私增强，即St,A = I(S; A) = 1。在设计第二个变换时，我们小心地不改变标签总数，因此Ut,A = 0，表明t不会引起效用退化。

### 6.2 变换分析
我们调查了四种半结构化数据的净化变换：抑制、泛化、置换和噪声添加。在什么情况下一种类别的变换会优于另一种？以下我们将使用我们的分析框架来突出每种类别的特性。变换可以从以下三个方面进行比较：(a) 保持效用的能力，(b) 保护隐私的有效性，以及(c) 效率。我们将重点讨论(a)和(b)，因为(c)不在本文的研究范围内。

这四种类别变换的共同点是一个约简函数r，它将配置文件a分解为两部分：一部分未经进一步净化直接发布（r(a)），另一部分a \ r(a)将通过片段变换tf进行净化。为了公平比较，我们假设这四个选择都基于相同的约简r，并且a \ r(a)捕获了相关性的核心（§5）。

**核心抑制——最少信息泄露**：由于a \ r(a)是相关性的核心，完全去除它通过抑制可以完全消除与敏感信息S的相关性。在其他三种变换中，抑制t包含的敏感信息最少。因此，核心抑制总是增强隐私的最佳选择，但也是保留效用最差的选择。

**置换和聚合效用**：假设我们将一个配置文件分为两部分：(a) 值和 (b) 捕获值之间关联的结构。在我们的代数结构中，常量符号是值，带有一个或多个输入参数的函数符号贡献于配置文件的结构。例如，在表3中，1/2/2013和hello是两个值，而函数符号entry将它们连接起来，表示1/2/2013是带有消息hello的墙条目的时间戳。

抑制可能同时移除结构和值。泛化只改变值而不改变结构。噪声添加既改变值也改变结构。相比之下，置换是唯一仅操作配置文件结构而不改变值的变换。由此得出的一个推论是，如果配置文件的效用仅依赖于值，则置换可能是最佳选择。这通常发生在效用U是值的某种聚合形式时，例如，计数条目总数。这种查询的结果在置换后保持不变。

### 7. 相关工作
隐私问题一直是安全专家关注的重点。特别是在数据集中保护个人身份方面，已经投入了大量努力。为了评估这些通常称为匿名化的努力，定义了一些衡量标准，以评估在发布数据集时个人身份受到多大程度的保护。k-匿名性[21]、l-多样性[18]、t-接近性[15]等是最知名的指标。Askari等人[6]最近的工作提出了一个信息理论框架，将所有这些匿名技术统一到一个系统中。

虽然上述匿名技术在隐私保护数据挖掘应用中得到了广泛研究，但在社交网络服务（SNSs）的背景下尚未得到应用。与数据挖掘应用不同，在SNSs中，用户的身份通常是已知的，不仅对其他用户，也对第三方扩展程序。事实上，已知的身份是社交网络文化的一部分。第三方开发者期望知道他们的用户身份。SNSs采用了基于权限的授权机制来保护用户信息。然而，多项研究表明SNSs中的隐私问题仍然存在。例如，Bilge等人[7]讨论了两种建立友谊关系并访问用户信息的对抗技术。类似地，Boshmaf等人[9]展示了他们的社交机器人可以冒充人类，并通过建立友谊关系来访问用户信息。

与多年前数据库中的推理问题相比，SNSs中的推理攻击是一个热门研究领域。Zheleva和Getoor[25]进行了实验，证明了社交网络数据集中推理攻击的可行性。此外，Xu等人[24]提出了一项与[25]类似的工作，利用社交友谊信息推断个人性别。

文献中完全忽略了第三方扩展程序在发起推理攻击中的作用。以前的实证研究[25, 24, 13]假设对手可以访问整个社交网络数据集。这个假设在通过第三方应用程序发起推理攻击的情况下并不现实。Ahmadinejad等人[4, 5]首次评估了第三方扩展程序对SNSs的推理攻击威胁。这些努力可以在SNSs中用户的授权机制期望与其实际发生的情况之间架起桥梁。尽管这些努力非常有助于警告用户谨慎与扩展程序共享信息，但仍需要特别设计的保护机制来控制第三方扩展程序的推理，这也是本文的重点。

处理社交网络隐私问题的另一个视角是不信任所有涉及方，包括SNS提供商。为此，[16, 17, 11]提出了加密技术，使SNS提供商只能访问用户数据的加密形式。授权用户将拥有解密数据所需的密钥。

### 8. 结论与未来工作
我们阐述了防止第三方应用程序在社交计算平台中进行推理攻击的视图保护需求，并提出了一种理论框架，用于评估半结构化数据的净化变换是否满足定量隐私和效用目标。我们还确定了变换安全组合的条件。我们将经典的净化变换建模为树术语代数上的操作，并展示了如何在我们的框架中评估它们的隐私增强和效用保留效果。因此，我们的工作提供了一种正式验证变换的隐私和效用属性的方法，以控制处理半结构化数据的应用程序的推理。

这项工作是我们开发可编程环境中的推理控制机制的更大研究计划的一部分。目前的工作包括开发与现有树操作和查询标准（例如XML）互操作的具体保护技术，以及避免在评估查询前物化视图的查询优化技术。未来的工作还包括加强隐私和效用目标。

### 致谢
本工作部分由加拿大自然科学与工程研究理事会发现资助（RGPIN-2014-06611）和加拿大研究主席项目（950-229712）支持。

### 参考文献
[1] Aggarwal, C. C., and Yu, P. S. Privacy-Preserving Data Mining: Models and Algorithms. Springer, 2008.
[2] Ahmadinejad, S. H. A View-Based Protection Model to Prevent Inference Attacks by Third-Party Extensions to Social Computing Platforms. PhD dissertation, University of Calgary, Jan. 2016. http://hdl.handle.net/11023/2755.
[3] Ahmadinejad, S. H., Anwar, M., and Fong, P. Inference attacks by third-party extensions to social network systems. In Proceedings of IEEE 9th International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops) (2011), pp. 282–287.
[4] Ahmadinejad, S. H., and Fong, P. W. On the feasibility of inference attacks by third-party extensions to social network systems. In Proceedings of the 8th ACM Symposium on Information, Computer and Communications Security (Hangzhou, China, 2013), ASIACCS’13, pp. 161–166.
[5] Ahmadinejad, S. H., and Fong, P. W. Unintended disclosure of information: Inference attacks by third-party extensions to social network systems. Computers & Security 44 (2014), 75–91.
[6] Askari, M., Safavi-Naini, R., and Barker, K. An information theoretic privacy and utility measure for data sanitization mechanisms. In Proceedings of the Second ACM Conference on Data and Application Security and Privacy (San Antonio, Texas, USA, 2012), CODASPY’12, pp. 283–294.
[7] Bilge, L., Strufe, T., Balzarotti, D., and Kirda, E. All your contacts are belong to us: automated identity theft attacks on social networks. In Proceedings of the 18th International Conference on World Wide Web (Madrid, Spain, 2009), WWW’09, pp. 551–560.
[8] Boag, S., Chamberlin, D., Fernández, M., Florescu, D., Robie, J., Siméon, J., and Stefanescu, M. XQuery 1.0: An XML query language. W3C Recommendation (2007).
[9] Boshmaf, Y., Muslukhov, I., Beznosov, K., and Ripeanu, M. The socialbot network: when bots socialize for fame and money. In Proceedings of the 27th Annual Computer Security Applications Conference (Orlando, FL USA, 2011), ACSAC’11, pp. 93–102.
[10] Cover, T. M., and Thomas, J. A. Elements of Information Theory. Wiley-Interscience, 2006.
[11] De Cristofaro, E., Soriente, C., Tsudik, G., and Williams, A. Hummingbird: privacy at the time of Twitter. In Proceedings of the 33rd IEEE Symposium on Security and Privacy (San Francisco, CA, USA, 2012), SP’12, pp. 285–299.
[12] Gries, D. The Science of Programming. Springer-Verlag, 1981.
[13] He, J., Chu, W. W., and Liu, Z. V. Inferring privacy information from social networks. In Proceedings of the 4th IEEE International Conference on Intelligence and Security Informatics (San Diego, CA, USA, 2006), ISI’06, Springer-Verlag, pp. 154–165.
[14] Kay, M. XML Path language (XPath) version 2.0. W3C Recommendation 23 (2007).
[15] Li, N., Li, T., and Venkatasubramanian, S. t-Closeness: privacy beyond k-anonymity and l-diversity. In Proceedings of the 23rd IEEE International Conference on Data Engineering (Istanbul, Turkey, 2007), ICDE’07, pp. 106–115.
[16] Lucas, M. M., and Borisov, N. FlyByNight: mitigating the privacy risks of social networking. In Proceedings of the 7th ACM Workshop on Privacy in the Electronic Society (Alexandria, VA, USA, 2008), WPES’08, pp. 1–8.
[17] Luo, W., Xie, Q., and Hengartner, U. FaceCloak: an architecture for user privacy on social networking sites. In Proceedings of the 12th IEEE International Conference on Computational Science and Engineering (Vancouver, Canada, 2009), vol. 3 of CSE’09, pp. 26–33.
[18] Machanavajjhala, A., Kifer, D., Gehrke, J., and Venkitasubramaniam, M. l-diversity: privacy beyond k-anonymity. ACM Transactions on Knowledge Discovery from Data 1, 1 (2007), 1–52.
[19] Pearl, J. Causality: Models, Reasoning, and Inference. Cambridge University Press, NY, USA, 2000.
[20] Robling Denning, D. E. Inference controls. In Cryptography and data security. Addison-Wesley Longman Pub. Co., 1982, ch. 6, pp. 331–390.
[21] Samarati, P. Protecting respondents identities in microdata release. IEEE Transactions on Knowledge and Data Engineering 13, 6 (2001), 1010–1027.
[22] Smith, G. Quantifying information flow using min-entropy. In Proceedings of the 8th International Conference on Quantitative Evaluation of Systems (2011), QEST’11, pp. 159–167.
[23] Thuraisingham, B. M. A perspective of the inference problem. In Database and applications security. 2005, ch. 12, pp. 217–228.
[24] Xu, W., Zhou, X., and Li, L. Inferring privacy information via social relations. In Proceedings of the 24th IEEE International Conference on Data Engineering Workshop (Cancun, Mexico, 2008), ICDEW’08, pp. 525–530.
[25] Zheleva, E., and Getoor, L. To join or not to join: the illusion of privacy in social networks with mixed public and private user profiles. In Proceedings of the 18th International Conference on World Wide Web (Madrid, Spain, 2009), WWW’09, pp. 531–540.