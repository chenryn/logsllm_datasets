### Case Study 3: Reading Sensitive Logs

Three popular Android vendors exposed sensitive system logs via Init services that write the resulting log files to external storage. These system logs provide a timestamped trace of messages, events, and stack traces. Android offers a shared logging mechanism where any app can write arbitrary log messages using standard framework APIs. However, processes do not always sanitize sensitive user data before writing it to the log. Therefore, the Android system does not allow third-party apps to access the global system log. Since Init services typically run as privileged users, they can access sensitive logs from all processes.

In each of the three cases, the vendors used an Init service to execute a shell script as the root user to execute the `logcat` command. Two of the three vendors also exposed the output of the `dumpsys` command, which calls routines in each framework service to dump its state, often containing sensitive information. Active monitoring and mining of these logs using regular expressions by an adversarial local process poses a serious risk to the user's security and privacy.

### Case Study 4: Screen Recording

One vendor had five firmware images that exposed the capability to initiate a screen recording, with the resulting recording file made available to other processes on external storage. A screen recording provides an actual screen capture, allowing an adversary to monitor the contents of the device screen and the actions taken by the user. The recordings can reveal sensitive data such as passwords, credit card numbers, notification and message content, and other private information. The screen recording was performed in a shell script using the standard `screenrecord` command, with a recording duration of 30 minutes.

### 6.5 Runtime Performance of DEFINIT

We conclude our evaluation by providing measurements of the runtime performance of DEFINIT. We implemented DEFINIT in 7K-SLOCs of Python, leveraging BinaryNinja [26] for ELF analysis and Kryptowire’s internal Android static analysis engine [27] for app analysis. Our analysis was conducted on an Ubuntu 20.04 server with an 8-core Intel(R) Xeon(R) E5-4620 2.20GHz CPU and 512 GiB of RAM.

DEFINIT took about 5 minutes on average to unpack a firmware image, with 90% of the images finishing unpacking in less than 20 minutes. Processing Init files, collecting traces, and building IDGs took about 30 minutes on average, with 90% completing in less than 50 minutes. Analyzing pre-installed apps took 7 minutes on average, with 90% of the apps finishing in less than 10 minutes. Each firmware image was analyzed independently, and no specific optimizations were performed to improve the performance of DEFINIT. Overall, 90% of the firmware images finished in less than 70 minutes end-to-end, which is reasonable in practice.

### 7 Discussion and Future Work

#### Analysis Limitations

The goal of this study is to explore the impact of Init routines added by vendors to Android and called from privileged apps with potentially lax app component access control. To achieve this, we developed DEFINIT. The primary aim of DEFINIT is not to automatically determine whether an identified exposed routine is exploitable, but to identify instances that have potential security implications, bringing them to the surface for further investigation and verification by an analyst. Automatically reasoning about exploitability is an extremely challenging task with no viable solution in practice [28, 29].

The analysis in §5 is conservative, as we tuned our analysis to avoid constructs known to result in false information flows during static analysis. These constructs are commonly handled in an unsound manner in practice to avoid overapproximations that may lead to too much noise in the findings. For instance, the ICFGs constructed by DEFINIT for ELF binaries and apps were under-approximated to avoid noise, limiting indirect/virtual call resolution to only indirect calls with one possible candidate callee based on the call receiver information available at an indirect call site. Other constructs not handled include reflection, flows through containers, inter-component communication, and flows that cross between managed and native code (e.g., flows through JNI calls). We also considered permission-protected components as unexported, regardless of the permission protection level [30].

For trace collection, more involved techniques or even firmware emulation [31, 32] could have been used, though this comes with numerous nontrivial challenges beyond the scope of this work [33–35]. From a practical perspective, we believe our analysis was adequate given the findings and goals of this study. More sophisticated analysis can be incorporated in the future to detect obfuscated or deeply-buried behaviors.

#### Manual Effort

The manual steps in this study included shortlisting sensitive commands and APIs, developing detection rules, and analyzing the annotated traces produced by DEFINIT that matched interesting rules. Enumerating and shortlisting the sensitive commands took one day for three persons.

Developing the detection rules used in DEFINIT took about four workdays for one person. We believe our selection provides reasonable coverage for the purpose of this study, though more commands and rules can be added as needed. This step is standard in behavioral binary analysis and is unlikely to be fully automated, as it requires expert knowledge. It may be possible to automate rule creation to some extent by using data mining techniques [36, 37] on a large labeled corpus of traces of Android-specific potentially sensitive behaviors or a generic model of what constitutes a sensitive behavior on Android. This can be an interesting direction for future work.

Analyzing and verifying the findings in Table 8 took about seven workdays for one person. Since the execution paths identified by DEFINIT cross multiple OS layers, end-to-end automated dynamic verification is extremely challenging, requiring at least a rooted target device and an advanced Android-aware, cross-layer dynamic symbolic execution engine. Overall, the manual effort involved was quite reasonable given the number of firmware and apps in our dataset and the number of cases we verified.

#### SELinux and Exploitation

We assumed that vendors have configured their firmware images properly for their customizations to work as intended. This includes configuring the necessary SELinux labels, rules, and transitions for their custom routines to function. This extends to the use of Vendor Init [38], where vendors are expected to place vendor Init .rc files and binaries in /vendor to run under a SELinux domain separate from the system Init domain. DEFINIT detects behaviors that can be exploited through individual pre-installed apps, and all constructs (property names, values, executables, commands, and APIs) along a vulnerable path are hardcoded. Therefore, SELinux transitions should not block these flows since the involved actors (pre-installed apps, Init routines, and their executables) are the ones expected by SELinux and intended to operate in this manner, unless there are considerable errors on the part of vendors due to a lack of testing. In the cases we dynamically verified, we did not encounter any SELinux restrictions preventing exploitation.

For scenarios where one sensitive behavior could be split between multiple apps (e.g., an attacker invokes one pre-installed app to record a video and then a different app to move files to external storage), it may be possible that SELinux prevents exploitation of these behaviors if the triggered routines have different SELinux contexts and the vendor did not add transitions that allow these behaviors to manifest. We leave detecting these multi-app behaviors and handling their SELinux constraints to future work.

#### Threats to Validity

In our implementation of DEFINIT, we did not check for dynamic access control constructs (e.g., dynamic permission checks, UID checks, confirmation dialogues) that may fall on the path from a pre-installed app to the call site setting a system property. We manually checked only the findings in Table 8 for these constructs during verification. Therefore, the results provided in Tables 7 and A.6 should be interpreted with this in mind. Reasoning about dynamic access control automatically is a challenging task that requires modeling relevant code constraints dominating a call site setting a system property, modeling runtime environment constraints, and solving these constraints using a symbolic solver, which we leave for future work.

While we tried to cover a representative sample of the Android market, our firmware dataset was not uniform across all vendors and Android versions. Some vendors in our dataset (e.g., Itel) also had significantly smaller firmware images and fewer Init routines compared to others. The unpacking process of some proprietary image formats in our dataset may have missed some files and partitions. Therefore, the differences between vendors in our results may not be statistically significant to substantiate differences in the overall security posture of the vendors and should be interpreted carefully in this regard.

#### Potential Countermeasures

There are various measures that AOSP, Google, and vendors can take to reduce the security impact of Init customizations. The first step is perhaps for Android Init to default child processes spawned from Init to an unprivileged user and SELinux domain (e.g., a nobody user). Defaulting to a low-privilege user and domain can confine the impact of exploiting exposed routines and binaries mistakenly leftover by vendors.

Second, given that Google has established a set of requirements as part of the Android Compatibility Definition Document (CDD) [39] that vendors must adhere to in order to brand their devices as Android-compatible, the CDD should enforce strict requirements on vendors to not add privileged custom Init routines that can be programmatically triggered from outside Init itself unless the functionality is key for normal system operation. This can be a mundane process and may not be straightforward to test by the CDD, but it is essential to confine the impact of exploiting potential flaws introduced by Init customizations.

Third, Android can block interaction between unprivileged apps and pre-installed apps that set system properties. In fact, Android can go a step further by blocking interaction between third-party apps and privileged apps by default unless the user explicitly grants a third-party app the permission to interact with a pre-installed app. This step, despite putting the burden on the user, could easily thwart most privilege-escalation attacks from third-party apps trying to parasitize on privileged apps without user consent. Adopting this approach would likely need to be phased in over time to not immediately break the current open communication model Android employs among apps co-located on an Android device. In addition, vendors should enforce proper access control at the boundaries of their privileged apps to minimize confused deputy attacks initiated by enterprising third-party apps trying to indirectly trigger sensitive functionality.

Finally, Android SELinux policies could default to preventing executables launched by Init routines from writing to external storage. This could easily block multiple of the flaws identified in our study that capitalize on leaking information to a publicly-readable path on external storage. A better separation of pre-installed apps, where the ones likely to be interacted with by third-party apps are not allowed to set Init properties or perform sensitive operations, may also help here. Some of the most severe cases (e.g., disabling SELinux) should also display a clear warning and ask the user if the action that was initiated programmatically can proceed. Specifically, enforcing user interaction for many of the extensive system logging routines can help safeguard the user. This is by no means a perfect solution, but if explained clearly, it will allow the user to have greater control over the security of their device.

### 8 Related Work

Numerous prior works have studied the security issues introduced by Android vendor customizations at different layers of the Android OS. At the application layer, Woodpecker [2] was among the very first studies to detect capability leakages on Android. It analyzed eight devices and found that 11 out of 13 privileged permissions can leak to unprivileged apps. SEFA [3] analyzed 10 firmware images and found that over 85% of their pre-installed apps were overprivileged. Hare-Hunter [4] discovered thousands of hanging attribute references (Hares) in 97 firmware images, allowing unprivileged apps to claim access to potentially sensitive functionalities by using attributes hardcoded in pre-installed apps.

More recently, Gamba et al. [40] conducted a comprehensive study of multiple devices and identified several instances of advertising and data collection without user consent. FirmScope [11] performed a large-scale static analysis study of pre-installed apps in more than 2000 firmware images from top Android vendors and identified numerous privilege escalation vulnerabilities due to improper access control in pre-installed apps. The authors of FirmScope identified a few apps that were able to set arbitrary system properties, which, while relevant to our study, did not assess the impact of setting these properties nor how they may be related to custom Init routines added by vendors. Nevertheless, privilege-escalation flaws in pre-installed apps in general can potentially enable more attack vectors for launching sensitive Init routines, e.g., by exploiting a command execution flaw in a privileged app to directly call an executable launched by a sensitive Init routine running with the system UID.

For security issues introduced to the Android framework layer (sometimes referred to as the Android middleware), Tian et al. [9] analyzed 2,000 firmware images and identified 3,500 AT Commands invokable over USB, multiple of which can perform sensitive functionalities, such as bypassing the screen lock and factory resetting the device. Most of these commands were hardcoded in custom ELF libraries added by vendors to the framework as part of the Radio Interface Layer (RIL), yet a few were also introduced by privileged pre-installed apps. ARF [10] analyzed the AOSP framework and identified cases of confused deputies due to inconsistent access checks in framework service components. FANS [41] fuzzed native framework services on six Android 9.0 devices and identified 30 vulnerabilities and thousands of crashes. These studies are complementary to our work. Studying Init capabilities leaked through vendor customizations to the Android framework itself (e.g., via new framework APIs introduced by vendors) is a possible interesting area for future work.

At the kernel level, ADDICTED [14] analyzed vendor device drivers and found multiple privilege escalation vulnerabilities that allow third-party apps to perform sensitive functionalities without permission by talking to open interfaces in custom device drivers. BootStomp [13] found eight vulnerabilities in the bootloaders used by a number of devices, allowing attackers to potentially compromise the entire chain of trust established at boot time or cause denial of service. BigMac [16] analyzed the SELinux policies on two devices and identified multiple policy inconsistencies that allow unprivileged actors to load kernel modules and communicate with root processes.

To the best of our knowledge, none of the prior studies have analyzed vendor customizations of the Android Init process that are visible at the application layer, and the security impact of these changes, which is what we focus on in this study.

### 9 Conclusion

Android Init routines can provide privileged operation interfaces to privileged system apps that can trigger them by setting system properties. The privileged capabilities of these Init routines can be exposed to unprivileged third-party apps through open interfaces in privileged apps triggering the routines. To understand the prevalence and security impact of exposed Init routines, we designed DEFINIT as a system to help detect Init routines exposed by privileged apps and their behaviors. We studied 259 firmware images covering Android 8 to 11 from the top 21 vendors worldwide and identified numerous vulnerabilities that allow unprivileged third-party apps to perform sensitive functionalities, including capturing network traffic, reading system logs, and disabling SELinux, among others. Our findings demonstrate the significance of these changes to Init and the need for rigorous Android regulations to reduce and confine the impact of potential security weaknesses introduced by vendors.

### Acknowledgments

We thank the anonymous reviewers and our shepherd, Antonio Bianchi, for their insightful comments on earlier versions of this work. We thank Jinghan Guo for assisting with firmware unpacking and verification. Part of this work was done while Yuede Ji was at George Washington University.

Opinions expressed in this article are those of the authors and do not necessarily reflect the official policy or position of their respective institutions.

### References

[1] “Mobile operating system market share worldwide,” https://gs.statcounter.com/os-market-share/mobile/worldwide/.

[2] M. C. Grace, Y. Zhou, Z. Wang, and X. Jiang, “Systematic detection of capability leaks in stock Android smartphones.” in NDSS, vol. 14, 2012.

[3] L. Wu, M. Grace, Y. Zhou, C. Wu, and X. Jiang, “The impact of vendor customizations on Android security,” in 2013 ACM SIGSAC Conference on Computer and Communications Security (CCS).

[4] Y. Aafer, N. Zhang, Z. Zhang, X. Zhang, K. Chen, X. Wang, X. Zhou, W. Du, and M. Grace, “Hare hunting in the wild Android: A study on the threat of hanging attribute references,” in 22nd ACM SIGSAC Conference on Computer and Communications Security (CCS).

[5] J. Gamba, M. Rashed, A. Razaghpanah, J. Tapiador, and N. Vallina-Rodriguez, “An analysis of pre-installed Android software,” in 2020 IEEE Symposium on Security and Privacy (S&P).

[6] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein, Y. Le Traon, D. Octeau, and P. McDaniel, “Flowdroid: Precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for Android apps,” ACM SIGPLAN Notices, vol. 49, no. 6, 2014.

[22] “disclosures/getsuperserial.md at master,” https://github.com/rednaga/disclosures/blob/master/GetSuperSerial.md.

[7] F. Wei, S. Roy, X. Ou et al., “Amandroid: A precise and general inter-component data flow analysis framework for security vetting of Android apps,” in 2014 ACM SIGSAC Conference on Computer and Communications Security (CCS).

[8] L. Zhang, Z. Yang, Y. He, Z. Zhang, Z. Qian, G. Hong, Y. Zhang, and M. Yang, “Invetter: Locating insecure input validations in Android services,” in 2018 ACM SIGSAC Conference on Computer and Communications Security.

[9] D. J. Tian, G. Hernandez, J. I. Choi, V. Frost, C. Raules, P. Traynor, H. Vijayakumar et al., “Attention spanned: Comprehensive vulnerability analysis of AT commands within the Android ecosystem,” in 27th USENIX Security Symposium, 2018.

[10] S. A. Gorski III and W. Enck, “ARF: Identifying re-delegation vulnerabilities in Android system services,” in 12th Conference on Security and Privacy in Wireless and Mobile Networks, 2019.

[11] M. Elsabagh, R. Johnson, A. Stavrou, C. Zuo, Q. Zhao, and Z. Lin, “FirmScope: Automatic uncovering of privilege-escalation vulnerabilities in pre-installed apps in Android firmware,” in 29th USENIX Security Symposium, 2020.

[12] Y. Fratantonio, C. Qian, S. P. Chung, and W. Lee, “Cloak and dagger: From two permissions to complete control of the UI feedback loop,” in 2017 IEEE Symposium on Security and Privacy (S&P).

[13] N. Redini, A. Machiry, D. Das, Y. Fratantonio, A. Bianchi, E. Gustafson, Y. Shoshitaishvili, C. Kruegel, and G. Vigna, “Bootstomp: On the security of bootloaders in mobile devices,” in 26th USENIX Security Symposium, 2017.

[14] X. Zhou, Y. Lee, N. Zhang, M. Naveed, and X. Wang, “The peril of fragmentation: Security hazards in Android device driver customizations,” in 2014 IEEE Symposium on Security and Privacy (S&P).

[15] H. Zhang, D. She, and Z. Qian, “Android ion hazard: The curse of customizable memory management system,” in 2016 ACM SIGSAC Conference on Computer and Communications Security (CCS).

[16] G. Hernandez, D. J. Tian, A. S. Yadav, B. J. Williams, and K. R. Butler, “BigMAC: Fine-grained policy analysis of Android firmware,” in 29th USENIX Security Symposium, 2020.

[17] “Android Init Language,” https://android.googlesource.com/platform/system/core/+/master/init/README.md.

[18] F. B. Cohen and D. F. Cohen, A short course on computer viruses. John Wiley & Sons, Inc., 1994.

[19] “bash(1) — Linux manual page,” https://man7.org/linux/man-pages/man1/bash.1.html.

[20] J. Six, Application Security for the Android Platform: Processes, Permissions, and Other Safeguards. O’Reilly Media, Inc., 2011.

[23] “CVE-2020-26964,” https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26964.

[24] Y. Shao, J. Ott, Y. J. Jia, Z. Qian, and Z. M. Mao, “The misuse of Android Unix domain sockets and security implications,” in 2016 ACM SIGSAC Conference on Computer and Communications Security (CCS).

[25] “Ransomware uses DDoS attacks to force victims to pay,” https://www.bleepingcomputer.com/news/security/another-ransomware-now-uses-ddos-attacks-to-force-victims-to-pay/.

[26] “Binary Ninja,” https://binary.ninja/.

[27] “Kryptowire,” https://kryptowire.com/.

[28] A. Younis, Y. K. Malaiya, and I. Ray, “Assessing vulnerability exploitability risk using software properties,” Software Quality Journal, vol. 24, no. 1, 2016.

[29] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino, A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel et al., “SOK: (State of) the art of war: Offensive techniques in binary analysis,” in 2016 IEEE Symposium on Security and Privacy (S&P).

[30] “Component permission protection level,” https://developer.android.com/guide/topics/manifest/permission-element#plevel.

[31] T. Eisenbarth, R. Koschke, and G. Vogel, “Static trace extraction,” in Ninth Working Conference on Reverse Engineering. IEEE, 2002.

[32] A. A. Clements, E. Gustafson, T. Scharnowski, P. Grosen, D. Fritz, C. Kruegel, G. Vigna, S. Bagchi, and M. Payer, “Halucinator: Firmware re-hosting through abstraction layer emulation,” in 29th USENIX Security Symposium, 2020.

[33] X. Meng and B. P. Miller, “Binary code is not easy,” in 25th International Symposium on Software Testing and Analysis, 2016.

[34] D. Landman, A. Serebrenik, and J. J. Vinju, “Challenges for static analysis of Java reflection—literature review and empirical study,” in 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE).

[35] C. Wright, W. A. Moeglein, S. Bagchi, M. Kulkarni, and A. A. Clements, “Challenges in firmware re-hosting, emulation, and analysis,” ACM Computing Surveys (CSUR), vol. 54, no. 1, 2021.

[36] C. Yang, Z. Xu, G. Gu, V. Yegneswaran, and P. Porras, “DroidMiner: Automated mining and characterization of fine-grained malicious behaviors in Android applications,” in European Symposium on Research in Computer Security. Springer, 2014, pp. 163–182.

[37] E. Raff, R. Zak, G. Lopez Munoz, W. Fleming, H. S. Anderson, B. Filar et al., “Automatic YARA rule generation using biclustering,” in 13th ACM Workshop on Artificial Intelligence and Security, 2020.

[21] “CVE-2018-6597,” https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-6597.

[38] “Vendor Init | Android Open Source Project,” https://source.android.com/security/selinux/vendor-init.

[39] “Android Compatibility Definition Document,” https://source.android.com/compatibility/cdd.

[40] J. Gamba, M. Rashed, A. Razaghpanah, J. Tapiador, and N. Vallina-Rodriguez, “An analysis of pre-installed Android software,” in 2020 IEEE Symposium on Security and Privacy.