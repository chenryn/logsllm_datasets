### Table 4: Availability across Router Classes
**Estimated availability for routers or links classified by AS tier and location.**  
- **Border Router Definition:** A border router is defined as one with at least one link to another Autonomous System (AS).

### Application of RON Data Set for Availability Statistics
To apply the availability statistics derived from the RON data set, we identified and classified the routers on paths between nodes in our testbed. We performed traceroute measurements approximately every 20 minutes between nodes in our Content Delivery Network (CDN) testbed from December 4, 2003, to December 11, 2003. For our analysis, we used the most frequently observed path between each pair of nodes; in almost all cases, this path was used more than 95% of the time.

Using the router availabilities estimated from the RON data set, we estimated the availability of routes in our testbed when using route control or overlay routing. When estimating the simultaneous failure probability of multiple paths, it is important to identify which routers are shared among the paths so that failures on those paths are accurately correlated.

### Challenges in Identifying Router Aliases
Because determining router aliases was difficult on some paths in our testbed, we conservatively assumed that the routers at the end of paths toward the same destination were identical if they belonged to the same sequence of ASes. For example, if we had two router-level paths destined for a common node that map to the ASes A A B B C C and D D D B C C, respectively, we assume the last three routers are the same (since B C C is common). Even if in reality these routers are different, failures at these routers are still likely to be correlated. The same heuristic was used to identify identical routers on paths originating from the same source node. We assume other failures are independent.

### Potential Biases in the Analysis
Several aspects of this approach may introduce biases in our analysis:
1. **Route Representation:** The routes on RON paths may not be representative of the routes in our testbed, though we tried to ensure similarity by using only paths between relatively well-connected RON nodes in the U.S. Additionally, the availabilities across router classes in the RON dataset did not vary substantially across different months, so we do not believe the difference in timeframes impacted our results.
2. **Frequent Failures:** There may be routers or links in the RON data set that fail frequently and bias the availability of a particular router type. However, since traceroutes are initiated only when a failure is detected, there is no way for us to accurately estimate the overall failure rates of all individual routers.
3. **Failure Attribution:** It is questionable whether we should assign failures to the last reachable router in a traceroute; it is possible that the next (unknown) or an even further router in the path is actually the one that failed. Nevertheless, our availabilities still estimate how often failures are observed at or just after a router of a given type.

### Comparison of Average Availability
**Figure 14** compares the average availability using overlays and route control on paths originating from six cities to all destinations in our testbed. For overlay routing, we only calculate the availability of the paths for the first and last overlay hop (since these will be the same no matter which intermediate hops are used), and assume that there is always an available path between other intermediate hops. An ideal overlay has a practically unlimited number of path choices and can avoid a large number of failures in the middle of the network.

As expected from our active measurements, the average availability along the paths in our testbed is relatively high, even for direct paths. 3-multihoming improves the average availability by 0.15-0.24% in all the cities (corresponding to about 13-21 more hours of availability each year). Here, the availability is primarily upper-bounded by the availability of the routers or links immediately before the destination that are shared by all three paths as they converge.

In most cases, 1-overlays have slightly higher availability (at most about 0.07%). Since a 1-overlay has arbitrary flexibility in choosing intermediate hops, only about 2.7 routers are common (on average) between all possible overlay paths, compared to about 4.2 in the 3-multihoming case. However, note that a 1-overlay path using a single provider is more vulnerable to access link failures. For example, the low availability of the 1-overlay in Chicago is due to:
1. The chosen ISP (based on RTT performance) is a tier 4 network, which has internal routers with relatively lower availability.
2. All paths exiting that provider have the first five hops in common, hence have a high chance of correlated failures.

Finally, we see that using a 3-overlay usually makes routes only slightly more available than when using a 1-overlay (between 0.01% to 0.08%, excluding Chicago). This is because at least one router is shared by all paths approaching a destination, so failures at that router impact all possible overlay paths.

### Summary
Despite the greater flexibility of overlays, route control with 3-multihoming is still able to achieve an estimated availability within 0.08-0.10% (or about 7 to 9 hours each year) of 3-overlay.

### Discussion
#### Key Observations
As expected, our results show that overlay routing provides improved latency, throughput, and reliability over route control with multihoming. We found that overlay routing's performance gains arise primarily from the ability to find routes that are physically shorter (i.e., shorter propagation delay). In addition, its reliability advantages stem from having a superset of the routes available to standard routing. The surprise in our results is that careful use of a few additional routes via multihoming at the end-network was enough to significantly reduce the advantage of overlays. Since their performance is similar, the question remains whether overlays or multihoming is the better choice. To answer this, we must look at other factors such as cost and deployment issues.

#### Cost of Operation
Unfortunately, it was difficult to consider the cost of implementing route control or overlays in our evaluation. In the case of multihoming, a stub network must pay for connectivity to a set of different ISPs. Different ISPs charge different amounts, and therefore the solution we consider "best" may not be the most cost-effective choice. In the case of overlays, we envision that there will be overlay service offerings, similar to Akamai’s SureRoute [1]. Users of overlays with multiple first-hop choices (k-overlay routing in our analysis) must add the cost of subscribing to the overlay service to the base cost of ISP multihoming. Using an overlay with a single provider (i.e., 1-overlays) would eliminate this additional cost, but our analysis shows that the performance gain is reduced significantly.

#### Deployment and Operational Overhead
Overlays and multihoming each have their unique set of deployment and performance challenges that our measurements do not highlight. Below, we consider the issues of ease of use and deployment, routing table expansion, and routing policy violations.

##### Ease of Use and Employment
- **Overlay Routing:** Requires a third-party to deploy a potentially large overlay network infrastructure. Building overlays of sufficient size and distribution to achieve significantly improved round-trip and throughput performance is challenging in terms of infrastructure and bandwidth cost, as well as management complexity.
- **Multihoming:** As a single end-point based solution, it is relatively easier to deploy and use from an end-network’s perspective.

##### Routing Table Expansion Due to Multihoming
An important overhead of multihoming that we did not consider in this study is the resulting increase in the number of routing table entries in backbone routers. ISPs will likely charge multihomed customers appropriately for any increased overhead in the network core, making multihoming less desirable. This problem occurs only when the stub network announces the same address range to each of its providers. Smaller networks could instead use techniques based on Network Address Translation (NAT) to avoid issues with routing announcements and still make intelligent use of multiple upstream ISPs [13, 4].

##### Violation of Policies by Overlay Paths
One of the concerns that overlay routing raises is its circumvention of routing policies instituted by intermediate ASes. For example, a commercial endpoint could route data across the relatively well-provisioned, academic Internet2 backbone by using an overlay hop at a nearby university. While each individual overlay hop would not violate any policies (i.e., the nearby university node is clearly allowed to transmit data across Internet2), the end-to-end policy may be violated. Our analysis quantifies the number of routing policy violations, but we did not consider their impact. Most Internet routing policies are related to commercial relationships between service providers. Therefore, it is reasonable to expect that the presence of an overlay node in an ISP network implies that the overlay provider and the ISP have some form of business agreement. This relationship should require that the overlay provider pay for additional expenses that the ISP incurs by providing transit to overlay traffic. Network providers would thus be compensated for most policy violations, limiting the negative impact of overlay routing.

##### Future Changes to BGP
We have discussed some important issues regarding overlays and route control in today’s environment, but have not considered changes to BGP that may further improve standard Internet routing performance relative to overlays. For example, we only consider the impact of performance or availability-based route selection at the edge of the network. It is possible that transit ASes could perform similar route control in the future, thereby exposing a superior set of AS paths to end networks. Another future direction is the development of new protocols for AS-level source-routing, such as NIRA [33], which allow stub networks greater control over their routes.

### Limitations of the Study
Our observations may be constrained by a few factors such as the size of our testbed, the coarse granularity of our performance samples, and our limited analysis of resilience. We discuss these issues in detail below.

#### Testbed Size
In Figure 15, we compare the average RTT performance from 3-multihoming against 3-overlays, as a function of the number of intermediate overlay nodes available. The graph shows the RTT difference between the best 3-overlay path (direct or indirect) and the best 3-multihoming path, averaged across all measurements as nodes are added one-by-one, randomly, to the overlay network. A different heuristic of adding nodes may yield different results. As the size of the overlay is increased, the performance of 3-overlays gets better relative to multihoming. Although the relative improvement is marginal, there is no discernible "knee" in the graph. Therefore, it is possible that considering additional overlay nodes may alter the observations in our study in favor of overlay routing.

#### Granularity of Performance Samples
Our performance samples are collected at fairly coarse timescales (6-minute intervals for round-trip time and 30 minutes for throughput). As a result, our results may not capture very fine-grained changes, if any, in the performance on the paths, and their effect on either overlay routing or multihoming route control. However, we believe that our results capture much of the observable performance differences between the two path selection techniques for two key reasons:
1. Our conclusions are based on data collected continuously over a week-long period, and across a fairly large set of paths.
2. Zhang et al. observed that the "steadiness" of both round-trip time and throughput performance is at least on the order of minutes [34]. Other more recent measurements of round-trip times on similar paths as those in our testbed have shown mean intervals of several minutes between changes of 30% or more [4]. As such, we do not expect that a higher sampling frequency would yield significantly different results.

#### Repair and Failure Detection
Our reliability analysis does not compare the relative ability of overlay routing and multihoming to avoid BGP convergence problems. For example, a peering link failure may affect routing between the peer ISPs until BGP re-converges. It is possible that some multihoming configurations cannot avoid such routing failures. We leave this comparison for future work.

### Summary
Past studies have demonstrated the use of overlay routing to make better use of the underlying connectivity of the Internet than the current BGP-based system. However, BGP-based routing can benefit from the added capability of two important factors at end-networks:
1. Additional access to end-to-end BGP routes via ISP multihoming.
2. Implementation of performance- and resilience-aware route control mechanisms to dynamically select among multiple BGP routes.

In this paper, we have compared the relative benefits of overlay routing and intelligent route control and investigated possible reasons for the differences via an extensive measurement-based analysis. Our findings are as follows:
- **Multihoming Route Control:** Can offer performance similar to overlay routing. Specifically, overlays employed in conjunction with multihoming to 3 ISPs offer only about 5-15% better RTTs and 1–10% better throughput than route control in conjunction with multihoming to three ISPs. In fact, when overlays are constrained to a single first-hop ISP, they provide inferior performance relative to route control.
- **RTT Performance:** The marginally better RTT performance of overlays comes primarily from their ability to select shorter end-to-end routes. The performance gap between overlays and route control can be further reduced if, for example, ISPs implement mutually cooperative peering policies such as late-exit.
- **Resilience:** While route control cannot offer the near-perfect resilience of overlays, it can eliminate almost all observed failures on end-to-end paths. The path diversity offered by multihoming can improve fault tolerance of end-to-end paths by two orders of magnitude relative to the direct BGP path.

The results in our paper show that it is not necessary to circumvent BGP routing to achieve good end-to-end resilience and performance. These goals can be effectively realized by means of multihoming coupled with intelligent route control.

### Acknowledgment
We would like to thank Olaf Maennel, Roberto De Prisco, Ramesh Sitaraman, and Ravi Sundaram for their support and assistance with our experiments and data collection. We would also like to thank Nick Feamster and David Andersen for providing the RON failure data. Discussions and feedback from the following people have helped improve this work greatly: David Andersen, Hari Balakrishnan, Claudson Bornstein, Nick Feamster, Erich Nahum, Venkat Padmanabhan, Jennifer Rexford, Sambit Sahu, and Hui Zhang. Finally, we thank our shepherd, Tom Anderson, and our anonymous reviewers for their valuable feedback and suggestions.

### References
[1] Akamai Technologies. Akarouting (SureRoute).
http://www.akamai.com, June 2001.
[2] Akamai Technologies. Edgescape.
http://www.akamai.com/en/html/services/
edgescape.html, 2004.
[3] A. Akella, B. Maggs, S. Seshan, A. Shaikh, and
R. Sitaraman. A Measurement-Based Analysis of
Multihoming. In Proc. of ACM SIGCOMM ’03, Karlsruhe,
Germany, August 2003.
[4] A. Akella, S. Seshan, and A. Shaikh. Multihoming
Performance Benefits: An Experimental Evaluation of
Practical Enterprise Strategies. In Proc. of the USENIX 2004
Annual Technical Conference, Boston, MA, June 2004.
[5] L. Amini, A. Shaikh, and H. Schulzrinne. Issues with
Inferring Internet Topological Attributes. In Proceedings of
SPIE ITCOM, August 2002.
[6] D. Andersen, H. Balakrishnan, M. Kaashoek, and R. Morris.
Resilient Overlay Networks. In Proc. of the 18th Symposium
on Operating System Principles, Banff, Canada, October
2001.
[7] N. Cardwell, S. Savage, and T. Anderson. Modeling TCP
Latency. In Proc. of IEEE INFOCOM 2000, Tel Aviv, Israel,
March 2000.
[8] F5 Networks. BIG-IP link controller. http://www.f5.
com/f5products/bigip/LinkController/.
[9] N. Feamster, D. Andersen, H. Balakrishnan, and M. F.
Kaashoek. Measuring the Effects of Internet Path Faults on
Reactive Routing. In Proc. of ACM SIGMETRICS 2003, June
2003.
[10] N. Feamster, J. Borkenhagen, and J. Rexford. Guidelines for
Interdomain Traffic Engineering. ACM SIGCOMM
Computer Communication Review, October 2003.
[11] L. Gao. On Inferring Autonomous System Relationships in
the Internet. IEEE/ACM Transactions on Networking, 9(6),
December 2001.
[12] L. Gao and F. Wang. The Extent of AS Path Inflation by
Routing Policies. In Proc. of IEEE GLOBECOM 2002, pages
2180–2184, 2002.
[13] F. Guo, J. Chen, W. Li, and T. Chiueh. Experiences in
Building a Multihoming Load Balancing System. In
Proceedings of IEEE INFOCOM, Hong Kong, March 2004.
to appear.
[14] Y. Hyun, A. Broido, and k claffy. Traceroute and BGP AS
Path Incongruities. Technical report, CAIDA, University of
California, San Diego, 2003. http://www.caida.org/
outreach/papers/2003/ASP/.
[15] IETF Traffic Engineering Working Group. http://www.
ietf.org/html.charters/tewg-charter.html,
2000.
[16] C. Labovitz, A. Ahuja, A. Bose, and F. Jahanian. Delayed
Internet routing convergence. IEEE/ACM Transactions on
Networking, 9(3):293–306, June 2001.
[17] Z. Mao, R. Govindan, G. Varghese, and R. Katz. Route Flap
Damping Exacerbates Internet Routing Convergence. In
Proc. of ACM SIGCOMM ’03, Karlsruhe, Germany, August
2003.
[18] Z. Mao, J. Rexford, J. Wang, and R. Katz. Towards an
Accurate AS-Level Traceroute Tool. In Proc. of ACM
SIGCOMM ’03, Karlsruhe, Germany, August 2003.
[19] Nortel Networks. Alteon link optimizer.
http://www.nortelnetworks.com/products/
01/alteon/optimizer/.
[20] W. B. Norton. Internet Service Providers and Peering. In
Proceedings of NANOG 19, Albuquerque, NM, June 2000.
[21] Radware. Peer Director. http:
//www.radware.com/content/products/pd/.
[22] Y. Rekhter and T. Li. A Border Gateway Protocol 4 (BGP-4).
Internet Request for Comments (RFC 1771), March 1995.
[23] M. Roughan, M. Thorup, and Y. Zhang. Traffic Engineering
with Estimated Traffic Matrices. In Internet Measurement
Conference, Miami, FL, November 2003.
[24] RouteScience Technologies, Inc. Routescience PathControl.
http://www.routescience.com/products.
[25] S. Savage, A. Collins, E. Hoffman, J. Snell, and T. Anderson.
The End-to-End Effects of Internet Path Selection. In
Proceedings of ACM SIGCOMM, Boston, MA, September
1999.
[26] S. Savage et al. Detour: A Case for Informed Internet
Routing and Transport. IEEE Micro, 19(1):50–59, 1999.
[27] A. Shaikh, J. Rexford, and K. G. Shin. Load-Sensitive
Routing of Long-Lived IP Flows. In Proc. of ACM
SIGCOMM ’99, Cambridge, MA, September 1999.
[28] N. Spring, R. Mahajan, and T. Anderson. Quantifying the
Causes of Internet Path Inflation. In Proc. of ACM
SIGCOMM ’03, August 2003.
[29] N. Spring, R. Mahajan, and D. Wetherall. Measuring ISP
Topologies with Rocketfuel. In Proc. of ACM SIGCOMM
’02, Pittsburgh, PA, August 2002.
[30] J. W. Stewart. BGP4: Inter-Domain Routing in the Internet.
Addison-Wesley, 1999.
[31] L. Subramanian, S. Agarwal, J. Rexford, and R. H. Katz.
Characterizing the Internet Hierarchy from Multiple Vantage
Points. In Proceedings of IEEE INFOCOM, June 2002.
[32] H. Tangmunarunkit, R. Govindan, and S. Shenker. Internet
Path Inflation Due to Policy Routing. In SPIE ITCOM,
August 2001.
[33] X. Yang. NIRA: A New Internet Routing Architecture. In
Proc. of the ACM SIGCOMM Workshop on Future
Directions in Network Architecture (FDNA), August 2003.
[34] Y. Zhang, N. Duffield, V. Paxson, and S. Shenker. On the
Constancy of Internet Path Properties. In Proc. of ACM
SIGCOMM Internet Measurement Workshop (IMW),
November 2001.