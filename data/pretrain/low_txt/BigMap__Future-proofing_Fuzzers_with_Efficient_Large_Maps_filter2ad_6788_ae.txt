### Optimized Text

A small memory footprint is crucial, as it ensures that the program and the utilized portion of its bitmap fit within faster cache levels. In this section, we evaluate the performance when a large bitmap (i.e., 2MB) is used. For this experiment, we ran 4, 8, and 12 concurrent instances in a master-secondary configuration. In this setup, a single master instance performs the deterministic fuzzing steps before proceeding to random fuzzing. The remaining instances are secondary and skip the deterministic step. The output corpus is periodically synchronized between these instances. This configuration is standard for all real-world parallel fuzzing sessions.

**Figure 9(a)** shows the resultant throughput. Each benchmark's throughput is normalized to the corresponding single-run version to better visualize the scaling effect. The black line represents the theoretical 1:1 scaling, where \( k \) instances achieve \( k \) times the throughput. The bold red line indicates the average execution rate across all benchmarks.

It is evident that both BigMap and AFL cannot maintain 1:1 scaling with large bitmaps. The reason is that with multiple instances and large bitmaps, the working set is more likely to exceed the last-level cache capacity, which is shared across all fuzzing instances. BigMap performs relatively well because it does not access the full map, resulting in a smaller effective memory footprint. In contrast, AFL scales poorly. The throughput of AFL decreases above four instances, indicating that the total number of executions actually went down as the number of instances increased.

**Figure 9(b)** provides the speedup attained by BigMap over AFL. This speedup is measured by taking the ratio of the total test cases generated by BigMap and AFL with an equal number of instances. As AFL scales poorly with the number of instances compared to BigMap (as shown in **Figure 9(a)**), it is expected that the speedup will show a super-linear behavior. On average, BigMap achieved a speedup of 4.9x, 9.2x, and 13.8x for 4, 8, and 12 concurrent runs, respectively.

**Figure 10** depicts a similar trend in the number of unique crashes found. AFL suffers due to the drop in execution throughput. For 4, 8, and 12 instances, BigMap found 20%, 36%, and 49% more unique crashes on average. If we compare the best configurations available on our hardware (e.g., 12 instances for BigMap and 4/8 instances for AFL), BigMap shows an average speedup of 9.2x and uncovers 37% more crashes.

### VI. RELATED WORK

Fuzzing as an evolutionary process was first introduced by Sidewinder in 2006 [24]. Since then, most successful fuzzers have followed this approach [6]–[8], [16], [17], [23], [25]–[28]. A critical component in this evolutionary process is the fitness function, which determines what inputs will be used as seeds for future fuzzing rounds. AFL and AFL-based fuzzers [8], [16], [23] use coarse edge hit counts as the fitness function. Any test vector that exercises a yet-unseen edge or a seen edge with a different hit count is considered an interesting input. On the other hand, libFuzzer-based fuzzers [6], [7], [25] leverage compiler support such as SanitizerCoverage [18] to utilize basic block coverage as the fitness function. Angora [17] combines function calling context with edge coverage to differentiate between interesting test cases covering the same sets of edges but having unique execution paths. PerfFuzz [29] considers both execution count and code coverage. Ankou [28] queries behavioral similarity between a new test case and the current seeds in the seed pool to determine if it should be considered interesting. All of these approaches use some form of code coverage as the fitness function. BigMap is orthogonal to these approaches and can be adopted to improve their fitness functions' accuracy by reducing collisions.

In addition to seed selection, fuzzers can leverage coverage information for scheduling seeds from the seed pool. AFL schedules "favored" entries more frequently, and these entries are determined based on edge coverage. AFLFast [16] selects seeds that cover the least frequently traveled paths. VUzzer [25] uses control-flow graphs to model the execution path and prioritizes inputs that visit deeper blocks. Cerebro [30] employs a multi-objective algorithm that takes code coverage, complexity, and execution time into account during scheduling. FairFuzz [31] prioritizes seeds based on rare branch coverage, as rare branches are more likely to hide hard-to-trigger bugs. NeuFuzz [32] trains a deep neural network model to differentiate between a vulnerable path and a clean path and prioritizes the vulnerable one. AFLGo [33] measures branch distance to select seeds that are closer to predetermined targets. Since these approaches use coverage feedback in their scheduling mechanism, hash collisions can obscure the seeds' priority.

The expressiveness of the coverage metric also influences the collision rate. Angora's context-sensitive coverage puts up to eight times more pressure on the bitmap [17]. Coverage metrics such as N-gram (hash of the last N branches), memory-access-aware branch coverage, and memory-write-aware branch coverage also exhibit higher map pressure than simple edge coverage [12]. Control-flow transformations such as laf-intel [11] or CmpCov [34] can increase map pressure, necessitating collision mitigation.

Fuzzers do not need to fixate on a particular coverage metric or scheduling algorithm. An ensemble of different fuzzing mechanisms has proven to be an effective strategy [12], [35]. Ensemble fuzzers run multiple fuzzing instances with different metrics and periodically cross-pollinate the inputs. However, unlike BigMap, they do not stack the coverage metrics together, which still subjects them to increased hash collisions. Comparing BigMap with ensemble fuzzing is not covered in this work and can be an interesting avenue for future research.

CollAFL [9] is the state-of-the-art technique for mitigating hash collisions in coverage bitmaps. It leverages static analysis to distribute edge IDs with a link-time compiler pass. Blocks with a single incoming edge are assigned IDs statically. For other blocks, injected instrumentation generates the IDs at runtime. It adapts to indirect edges by considering all blocks with no incoming edges as potential branching targets. One shortcoming of CollAFL is that it cannot be extended for coverage metrics other than block or edge coverage (e.g., N-gram, Angora). Additionally, it expands the bitmap to fit all the statically assigned IDs. Our experimental findings (presented in Table II) indicate that only a fraction of the static edges are visited during a fuzzing campaign, making the increase in map size a source of unnecessary runtime overhead. While both BigMap and CollAFL aim to solve the hash collision issue, they are orthogonal mitigation techniques. BigMap can be used independently of CollAFL to reduce hash collisions. It can also be used in combination with CollAFL to completely eliminate collisions while providing more efficient access to the map. Furthermore, BigMap supports any form of coverage metric as long as it is recorded in a coverage bitmap, making it applicable to a wide variety of fuzzers.

### VII. CONCLUSION

We investigated the common belief that enlarging bitmaps to mitigate hash collisions necessarily results in the deterioration of both throughput and quality in fuzzing campaigns. Our key observation is that the primary source of overhead stems from frequent map operations performed on the full bitmap, although only a fraction of the map is under active use. We proposed BigMap, a two-level bitmap that adds an extra level of indirection to limit the map operations on the map's active regions. Our evaluation results showed a 0.98x to 33.1x throughput gain over AFL as we increased the map size from 64kB to 8MB. BigMap also demonstrated better scalability with the number of concurrent fuzzing instances. Furthermore, BigMap's compatibility with most coverage metrics, along with its efficiency on large maps, enabled exploring aggressive compositions of coverage metrics and fuzzing algorithms, uncovering 33% more unique crashes. By making the use of large maps practical and open-sourcing BigMap, we hope to enable and spur further research into the design space of coverage metrics.

### ACKNOWLEDGEMENT

This work was supported in part by CRISP, one of the six centers of JUMP, a Semiconductor Research Corporation program sponsored by DARPA. This work was also supported in part by DARPA under contract numbers W911NF-18-C-0019 and FA8750-20-C-0507. The authors also wish to thank the anonymous reviewers for their time and valuable feedback.

### REFERENCES

[1] C. Cadar et al., “Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs.” in OSDI, 2008, pp. 209–224.
[2] A. Ahmed and P. Mishra, “QUEBS: Qualifying event-based search in concolic testing for validation of RTL models,” in ICCD, 2017, pp. 185–192.
[3] Y. Lyu, A. Ahmed, and P. Mishra, “Automated activation of multiple targets in RTL models using concolic testing,” in DATE, 2019, pp. 354–359.
[4] A. Ahmed, F. Farahmandi, and P. Mishra, “Directed test generation using concolic testing on RTL models,” in DATE, 2018, pp. 1538–1543.
[19] J. Naus, “Probabilities for a generalized birthday problem,” Journal of the American Statistical Association, pp. 810–815, 1974.
[20] “opt-llvm optimizer,” in https://llvm.org/docs/CommandGuide/opt.html, 2020.
[21] B. Nagy, “Crashwalk: Bucket and triage on-disk crashes,” in URL: https://github.com/bnagy/crashwalk, 2020.
[22] “Fuzzbench report,” in URL: https://www.fuzzbench.com/reports/2020-08-23/index.html, 2020.
[23] M. Heuse et al., “American fuzzy lop plus plus (afl++),” in URL: https://github.com/AFLplusplus/AFLplusplus, 2020.
[5] K. Serebryany, “Oss-fuzz: Google’s fuzzing service for open-source software,” in URL: https://github.com/google/oss-fuzz/, 2020.
[24] S. Embleton, S. Sparks, and R. Cunningham, “Sidewinder: An evolutionary guidance system for malicious input crafting,” Black Hat, August, 2006.
[6] ——, “Continuous fuzzing with libfuzzer and addresssanitizer,” in Cybersecurity Development, 2016, pp. 157–157.
[7] R. Swiecki, “Honggfuzz: A general-purpose, easy-to-use fuzzer with interesting analysis options,” URL: https://github.com/google/honggfuzz, 2020.
[25] S. Rawat et al., “Vuzzer: Application-aware evolutionary fuzzing.” in NDSS, 2017, pp. 1–14.
[26] I. Yun et al., “QSYM: A practical concolic execution engine tailored for hybrid fuzzing,” in USENIX, 2018, pp. 745–761.
[8] M. Zalewski, “American fuzzy lop, v2.52b,” in URL: https://lcamtuf.coredump.cx/afl/, 2020.
[27] D. She et al., “Neuzz: Efficient fuzzing with neural program smoothing,” in Security and Privacy, 2019, pp. 803–817.
[9] S. Gan et al., “CollAFL: Path sensitive fuzzing,” in Security and Privacy, 2018, pp. 679–696.
[28] V. J. Manès, S. Kim, and S. K. Cha, “Ankou: Guiding grey-box fuzzing towards combinatorial difference.”
[10] “Fuzzbench: Fuzzer benchmarking as a service,” in URL: https://github.com/google/fuzzbench, 2020.
[29] C. Lemieux et al., “Perffuzz: Automatically generating pathological inputs,” in SIGSOFT, 2018, pp. 254–265.
[11] “laf-intel: Circumventing fuzzing with compiler transformations,” in URL: https://clang.llvm.org/docs/SanitizerCoverage.html, 2020.
[30] Y. Li et al., “Cerebro: Context-aware adaptive fuzzing for effective vulnerability detection,” in ESEC/FSE, 2019, pp. 533–544.
[12] J. Wang et al., “Be sensitive and collaborative: Analyzing impact of coverage metrics in greybox fuzzing,” in RAID, 2019, pp. 1–15.
[31] C. Lemieux and K. Sen, “Fairfuzz: A targeted mutation strategy for increasing greybox fuzz testing coverage,” in ASE, 2018, pp. 475–485.
[13] M. Zalewski, “Technical whitepaper for afl-fuzz,” in URL: https://github.com/google/AFL/blob/master/docs/technical_details.txt, 2019.
[14] S. Nagy and M. Hicks, “Full-speed fuzzing: Reducing fuzzing overhead through coverage-guided tracing,” in Security and Privacy, 2019.
[15] “Ankou benchmark sources,” in URL: https://github.com/SoftSec-KAIST/Ankou-Benchmark, 2019.
[32] Y. Wang et al., “Neufuzz: Efficient fuzzing with deep neural network,” IEEE Access, pp. 36 340–36 352, 2019.
[33] M. Böehme et al., “Directed greybox fuzzing,” in CCS, 2017, pp. 2329–2344.
[34] M. Jurczyk, “Comparecoverage,” in URL: https://github.com/googleprojectzero/CompareCoverage, 2020.
[16] M. Böehme, V.-T. Pham, and A. Roychoudhury, “Coverage-based greybox fuzzing as Markov chain,” IEEE Transactions on Software Engineering, pp. 489–506, 2017.
[17] P. Chen and H. Chen, “Angora: Efficient fuzzing by principled search,” in Security and Privacy, 2018, pp. 711–725.
[35] C. Salls et al., “Exploring abstraction functions in fuzzing,” in CNS, 2020, pp. 1–9.
[18] “Clang sanitizer coverage,” in URL: https://clang.llvm.org/docs/SanitizerCoverage.html, 2020.