### 8. CONCLUSION

Our study revealed that only a small percentage of participants recognized a spoofed operating system credential-entry window as an attempt to steal their passwords. In our most effective attacks, over 20% of Windows users entered their usernames and passwords into a spoofed User Account Control (UAC) window, later admitting that these were genuine device-login credentials.

Providing a trusted path for secure credential entry is not sufficient to prevent such attacks. Operating systems must also prohibit the collection of device-login credentials through less secure paths (e.g., spoofable windows). Otherwise, users may become habituated to entering credentials when they stray from the trusted path.

### Acknowledgements

The authors would like to thank John Douceur (Microsoft Research), Serge Egelman (UC Berkeley), David Molnar (Microsoft Research), Rob Reeder (Microsoft), Adam Shostack (Microsoft), and the anonymous reviewers for their valuable feedback and suggestions on early versions of this paper. This research was partially funded by NSF grants CNS0831428, CNS1116934, and DGE090365.

### 7. A PATH FORWARD?

Developing strategies to address the trusted path problem is challenging because it is not feasible to use laboratory studies or short-term field studies to prove the resilience of these strategies against real-world attacks. Users become habituated to security rituals over time through repeated conditioning. To study how participants respond to attacks, researchers must observe individuals who are already conditioned. In other words, proving that a trusted path ritual can resist real-world attacks requires deploying the ritual to users who will rely on it.

Given the high costs associated with establishing the security of a trusted path ritual, it is essential to learn from current failures. Relying on subtle cues to confirm that a window belongs to the operating system does not appear to be effective.

The shortcomings of individual trusted path mechanisms suggest that the problem is unlikely to be adequately addressed by any single mechanism. Future work may focus on combining multiple mechanisms. For example, consider rituals where users must first enter a shared attention sequence and then expect to see a visual shared secret. These two mechanisms could complement each other: the expectation of a visual shared secret may make it more difficult for an attacker to trick the user into entering a password or performing a security-sensitive action without first providing the expected cue.

### 9. REFERENCES

[1] Adelsbach, A., Gajek, S., and Schwenk, J. Visual spoofing of SSL-protected websites and effective countermeasures. Information Security Practice and Experience (2005), 204–216.

[2] Bravo-Lillo, C., Cranor, L. F., Downs, J., and Komanduri, S. Bridging the gap in computer security warnings: A mental model approach. IEEE Security & Privacy Magazine 9, 2 (Mar. 2011), 18–26.

[3] Cova, M. Personal correspondence, May 5, 2012.

[4] Cova, M., Leita, C., Thonnard, O., Keromytis, A. D., and Dacier, M. An analysis of rogue AV campaigns. In Proceedings of the 13th International Symposium on Recent Advances in Intrusion Detection (RAID 2010) (Sept. 2010), pp. 442–463.

[5] Dhamija, R., and Tygar, J. D. The battle against phishing: Dynamic security skins. In Proceedings of the 2005 Symposium on Usable Privacy and Security (New York, NY, USA, 2005), SOUPS ’05, ACM, pp. 77–88.

[6] Dhamija, R., Tygar, J. D., and Hearst, M. Why phishing works. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (New York, NY, USA, 2006), CHI ’06, ACM, pp. 581–590.

[7] Downs, J. S., Holbrook, M. B., and Cranor, L. F. Decision strategies and susceptibility to phishing. In Proceedings of the Second Symposium on Usable Privacy and Security (New York, NY, USA, 2006), SOUPS ’06, ACM, pp. 79–90.

[8] Downs, J. S., Holbrook, M. B., Sheng, S., and Cranor, L. F. Are your participants gaming the system?: Screening Mechanical Turk workers. In Proceedings of the 28th International Conference on Human Factors in Computing Systems (New York, NY, USA, 2010), CHI ’10, ACM, pp. 2399–2402.

[9] Felten, E. W., Balfanz, D., Dean, D., and Wallach, D. S. Web spoofing: An Internet con game. In 20th National Information Systems Security Conference (Oct. 1996).

[10] Feske, N., and Helmuth, C. A nitpicker’s guide to a minimal-complexity secure GUI. In Proceedings of the 21st Annual Computer Security Applications Conference (Washington, DC, USA, 2005), IEEE Computer Society, pp. 85–94.

[11] Herzberg, A., and Gbara, A. Security and identification indicators for browsers against spoofing and phishing attacks. Cryptology ePrint Archive, Report 2004/155, 2004. http://eprint.iacr.org/.

[12] Initializing Winlogon, 2012. http://msdn.microsoft.com/en-us/library/windows/desktop/aa375994(v=vs.85).aspx.

[13] Jackson, C., Simon, D. R., Tan, D. S., and Barth, A. An evaluation of extended validation and picture-in-picture phishing attacks. In Proceedings of the 11th International Conference on Financial Cryptography and 1st International Conference on Usable Security (Berlin, Heidelberg, 2007), FC’07/USEC’07, Springer-Verlag, pp. 281–293.

[14] Kerr, K. Defend your apps and critical user info with defensive coding techniques. MSDN Magazine (Nov. 2004). http://msdn.microsoft.com/en-us/magazine/cc163883.aspx.

[15] Lefranc, S., and Naccache, D. Cut-&-paste attacks with Java. In Proceedings of the 5th International Conference on Information Security and Cryptology (Berlin, Heidelberg, 2003), ICISC’02, Springer-Verlag, pp. 1–15.

[16] Li, T.-Y., and Wu, Y. Trust on web browser: Attack vs. defense. In Applied Cryptography and Network Security, J. Zhou, M. Yung, and Y. Han, Eds., vol. 2846 of Lecture Notes in Computer Science. Springer Berlin / Heidelberg, 2003, pp. 241–253. 10.1007/978-3-540-45203-4_19.

[17] Libonati, A., McCune, J. M., and Reiter, M. K. Usability testing a malware-resistant input mechanism. In Proceedings of the 18th Annual Network & Distributed System Security Symposium (NDSS11) (Feb. 2011).

[18] Microsoft Corporation. What is User Account Control? http://windows.microsoft.com/en-US/windows-vista/What-is-User-Account-Control.

[19] Nodder, C. Users and trust: A Microsoft case study. In Security and Usability: Designing Secure Systems That People Can Use, L. F. Cranor and S. L. Garfinkel, Eds., first ed., Theory in practice. O’Reilly Media, Inc., Sebastopol, CA, USA, 2005, ch. 29, pp. 589–606.

[20] Parno, B., Kuo, C., and Perrig, A. Phoolproof phishing prevention. In Proceedings of the Financial Cryptography and Data Security 10th International Conference (2006), FC’06.

[21] Rajab, M. A., Ballard, L., Mavrommatis, P., Provos, N., and Zhao, X. The nocebo* effect on the web: An analysis of fake anti-virus distribution. In Proceedings of the 3rd USENIX Conference on Large-Scale Exploits and Emergent Threats: Botnets, Spyware, Worms, and More (Berkeley, CA, USA, 2010), LEET’10, USENIX Association, pp. 3–3.

[22] Ross, B., Jackson, C., Miyake, N., Boneh, D., and Mitchell, J. C. Stronger password authentication using browser extensions. In Proceedings of the 14th USENIX Security Symposium (Aug. 2005).

[23] Schechter, S. E., Dhamija, R., Ozment, A., and Fischer, I. The emperor’s new security indicators. In Proceedings of the 2007 IEEE Symposium on Security and Privacy (Washington, DC, USA, 2007), IEEE Computer Society, pp. 51–65.

[24] “Security-on-a-Stick” to protect consumers and banks from the most sophisticated hacker attacks, October 2008. http://www.zurich.ibm.com/news/08/ztic.html.

[25] Shapiro, J. S., Vanderburgh, J., Northup, E., and Chizmadia, D. Design of the EROS trusted window system. In Proceedings of the 13th Conference on USENIX Security Symposium (Berkeley, CA, USA, 2004), SSYM’04, USENIX Association, pp. 12–12.

[26] Stone-Gross, B., Abman, R., Kemmerer, R. A., Kruegel, C., Steigerwald, D. G., and Vigna, G. The underground economy of fake antivirus software. In Workshop on Economics of Information Security (WEIS) (June 2011).

[27] Symantec Corporation. Symantec report on rogue security software, Oct. 2009.

[28] Tygar, J. D., and Whitten, A. WWW electronic commerce and Java Trojan horses. In Proceedings of the Second USENIX Workshop on Electronic Commerce (Berkeley, CA, USA, 1996), vol. 2, USENIX Association, pp. 15–15.

[29] Ye, E., Yuan, Y., and Smith, S. Web spoofing revisited: SSL and beyond. Tech. Rep. TR2002-417, Dartmouth College, 2002.

[30] Ye, Z. E., Smith, S., and Anthony, D. Trusted paths for browsers. In Proceedings of the 11th USENIX Security Symposium (2002), pp. 263–279.

[31] Yee, K.-P. User interaction design for secure systems. In Proceedings of the 4th International Conference on Information and Communications Security (London, UK, 2002), ICICS ’02, Springer-Verlag, pp. 278–290.

### APPENDIX

#### A. PARTICIPANT SOLICITATION

Researchers at Carnegie Mellon University are conducting a set of brief surveys about online games. You will need to play three online games and then answer a short survey giving us your opinion about each game. The entire survey should take approximately 20 minutes. We will pay you $1.00 for your participation.

**Requisites to participate:**
1. You must be 18 years old or older.
2. You must be in the United States while taking the survey.
3. [Shown only to users of Windows clients] You must use Microsoft Windows Vista or Windows 7. We will not pay you if you use another operating system or an older version of Microsoft Windows (like Windows XP). If you use MS Internet Explorer, you must use Internet Explorer 8 or higher.
4. [Shown only to users of MacOS clients] You must use Apple MacOS to participate. We will not pay you if you use another operating system.
5. You cannot take this survey twice. Please click here to check if you have taken this survey before.

**To be paid, follow these steps:**

#### B. EXAMPLE GAME EVALUATION FORM

**Instructions to evaluate the game:**
1. While pressing CTRL/Command on your keyboard, click on the link below to open the game in a new tab of your browser.
2. Click on the button "Click to play online" on the left of your screen. Wait for the game to load.
3. When the game has loaded completely, play the game "Mars Buggy Online" for about 2 to 3 minutes.
4. Return to this survey to answer the questions below.

**Assigned game N: Mars Buggy Online**
http://www.gametop.com/online-free-games/mars-buggy-online/
(Press CTRL/Command while clicking this link)

**Attention:** The website whose URL appears above is external to this study. Our researchers do not control its content.

If you are unable to download or install the game, please check the box below and then click 'Next' at the bottom of the page. You will be assigned a new game to evaluate.

- [ ] I was not able to download or install the game, please assign me another game to evaluate.

Please briefly explain why you were not able to play the game: (required open text)

1. Go to: http://saucers.cups.cs.cmu.edu/yacot/mnt/wtk/survey.php?i=workerID
   - Please provide a one-sentence description of the game you played (between 10 and 50 words): (optional open text)
2. After completing the survey, you will receive a confirmation code on the last page. Enter the code in the box below, and we will approve your payment. Please do not enter the code more than once. If you are unsure about having entered the code correctly, please send us a message, and we will resolve the issue as soon as possible.

**Please answer the following questions about the game you played:**
- Have you ever played this game before?
  - [ ] Yes
  - [ ] No
- Do you think this game is appropriate for children between 4 and 8 years old?
  - [ ] Yes
  - [ ] No
- Do you think this game is appropriate for pre-teenagers between 9 and 12 years old?
  - [ ] Yes
  - [ ] No
- Do you think this game is appropriate for teenagers between 13 and 17 years old?
  - [ ] Yes
  - [ ] No
- Do you think this game is fun?
  - [ ] Yes
  - [ ] No