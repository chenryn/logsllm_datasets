# Table I: Experimental Results

| File Type | False Positives | Bound on False Positive Rate (99% confidence) |
|-----------|-----------------|----------------------------------------------|
| 42299     | 0               | err(1) < 0.0108%                            |
| 64089     | 0               | err(1) < 0.0072%                            |
| 38913     | 775             | 1.16% ≤ err(1) ≤ 2.82%                      |
| 58959     | 172             | 0% ≤ err(1) ≤ 0.96%                         |
| 8853      | 0               | err(1) < 0.0520%                            |
| 8853      | 12              | 0% ≤ err(1) ≤ 1.87%                         |

**Table I: Experimental Results.** We obtained strong bounds on the Type I error (False Positive Rate) for anomaly detectors processing several file types. Each bound holds with 99% confidence.

## Techniques for Anomaly Detection

Researchers have developed techniques that use pushdown automata (PDA) to model invalid program paths that can only occur if being exploited [23], [25], [50]. Precondition analysis has also been used to directly synthesize input constraints that can eliminate certain classes of errors [38], [15].

## Applications of Anomaly Detection Systems

In recent years, Anomaly Detection Systems (ADS) have increasingly been deployed to handle data from the web. Common applications include:
- Detecting malicious websites [44], [48]
- Automatically neutralizing malicious JavaScript code [18], [20], [28], [36]
- Filtering anomalies in more general data types, which are usually acquired from the web [37], [38]

## Rigorous ADS Testing

It is recognized in the anomaly detection literature that drawing test data (and training data) from a well-defined distribution over "normal" inputs is desirable. However, as Chandola et al. [16] point out, while statistical techniques for ADS are based on the assumption of an underlying input distribution, it is often difficult or impossible to define, let alone sample, from this distribution. Thus, samples for testing are typically collected with a best-effort approach, with the focus placed on detection techniques.

As recognized by Gao et al. [24]:
> It is not our goal here to determine how to acquire adequate training data for a program. Rather, we simply assume we have adequate training data in our study; if this is not true, our techniques might yield false detections, i.e., they may detect anomalies that are not, in fact, intrusions.

### Web Data Collection
While we are not aware of any work that samples directly from the PageRank distribution, several works on anomaly detection have employed crawl-based methods for collecting data [20], [37], [36], [48]. It has been recognized that simply drawing webpages from a known list (i.e., search engine indexes) gives a limited diversity of input samples [18]. Crawling helps ameliorate that issue.

Ntoulas et al. [44] further recognize that crawling biases samples towards "high quality," frequently visited webpages. This is a key motivation in our work, as a distribution weighted by such features more accurately represents the pages a typical user is expected to encounter. While motivated by similar intuition, Ntoulas et al. [44] do not formalize their input distribution and do not provide any guarantees (such as bounds on the false positive rate) about the performance of the anomaly detector.

### PageRank Distribution
The PageRank distribution has been well-studied in both theoretical and practical literature. Berkhin [13] provides a valuable survey. Other candidate representative distributions have been proposed for the web, but largely due to Google's success, PageRank has risen as a clear leader in site ranking algorithms. One of the earliest alternatives is the Hypertext Induced Topic Selection (HITS) algorithm introduced by Kleinberg [30]. This algorithm is considered a precursor to PageRank and was the first approach to weight links by "authority," something PageRank does implicitly through its random surfer model.

Part of the early motivation for PageRank was ease of computation [45]. Several results have focused on accelerated approaches [17], [33] since a full list of probabilities is required in actually using the distribution to rank webpages (i.e., a set returned from a web search). We are not aware of prior applications of sampling webpages by PageRank. Sampling has been considered in a more theoretical context for collecting a representative group of nodes from a general network [35].

## Conclusion

Anomaly detectors are a critical component of many security systems. Despite their central role, anomaly detectors are often designed and deployed with no precise understanding of their behavior. We present a novel technique and implemented system, Fortuna, for obtaining probabilistic bounds on the actual false positive rate that deployed anomaly detectors will incur. We demonstrate that Fortuna can provide tight bounds for three anomaly detectors designed to process input files from the Internet. Fortuna takes an important step towards placing anomaly detection on a firmer theoretical foundation and is designed to help practitioners better understand the behavior and consequences of the anomaly detectors they build and deploy.

## Acknowledgment

The authors would like to thank our anonymous reviewers for many helpful comments and suggestions. This research was supported by DARPA grant No. FA8650-11-C-7192. B. Juba was supported by ONR grant No. N000141210358. C. Musco was partially supported by NSF Graduate Research Fellowship grant No. 1122374.

## References

[1] “Alexa Internet,” http://www.alexa.com/.

[2] “Alexa Top Million Sites,” http://s3.amazonaws.com/alexa-static/top-1m.csv.zip.

[3] “Common Crawl,” http://commoncrawl.org/.

[4] “Common Crawl URL Index,” https://github.com/trivio/common_crawl_index.

[5] “Dillo,” http://www.dillo.org/.

[6] “Google Toolbar,” http://toolbar.google.com/.

[7] “Imagemagick,” http://www.imagemagick.org/.

[8] “Swftools,” http://www.swftools.org/.

[9] “Wepawet,” https://wepawet.cs.ucsb.edu/.

[10] “Netcraft Web Server Survey,” http://www.alexa.com/, June 2014.

[11] R. Andersen, F. Chung, and K. Lang, “Using PageRank vectors to locally partition graphs,” Internet Mathematics, vol. 4, no. 1, pp. 35–64, 2007.

[12] V. S. Arvind Narayanan, “Robust de-anonymization of large sparse datasets (how to break anonymity of the netflix prize dataset),” in IEEE Security and Privacy (Oakland), 2008, pp. 111–125.

[13] P. Berkhin, “A survey on PageRank computing,” Internet Mathematics, vol. 2, no. 1, pp. 73–120, 2005.

[14] M. Bianchini, M. Gori, and F. Scarselli, “Inside PageRank,” ACM Trans. Internet Techn., vol. 5, no. 1, pp. 92–128, 2005.

[15] D. Brumley, H. Wang, S. Jha, and D. Song, “Creating vulnerability signatures using weakest preconditions,” in Proceedings of the 20th IEEE Computer Security Foundations Symposium, ser. CSF ’07. Washington, DC, USA: IEEE Computer Society, 2007, pp. 311–325. [Online]. Available: http://dx.doi.org/10.1109/CSF.2007.17

[16] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A survey,” ACM Comput. Surv., vol. 41, no. 3, pp. 15:1–15:58, Jul. 2009. [Online]. Available: http://doi.acm.org/10.1145/1541880.1541882

[17] Y.-Y. Chen, Q. Gan, and T. Suel, “I/O-efficient techniques for computing PageRank,” in Proceedings of the Eleventh International Conference on Information and Knowledge Management, ser. CIKM ’02. ACM, 2002, pp. 549–557. [Online]. Available: http://doi.acm.org/10.1145/584792.584882

[18] M. Cova, C. Kruegel, and G. Vigna, “Detection and analysis of drive-by-download attacks and malicious JavaScript code,” in Proceedings of the 19th International Conference on World Wide Web, ser. WWW ’10. New York, NY, USA: ACM, 2010, pp. 281–290. [Online]. Available: http://doi.acm.org/10.1145/1772690.1772720

[19] A. Croll and S. Power, Complete Web Monitoring - Watching your visitors, performance, communities, and competitors. O’Reilly, 2009.

[20] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert, “Zozzle: Fast and precise in-browser JavaScript malware detection,” in Proceedings of the 20th USENIX Conference on Security, ser. SEC’11. Berkeley, CA, USA: USENIX Association, 2011, pp. 3–3. [Online]. Available: http://dl.acm.org/citation.cfm?id=2028067.2028070

[21] D. Denning, “An intrusion-detection model,” Software Engineering, IEEE Transactions on, vol. SE-13, no. 2, pp. 222–232, Feb 1987.

[22] A. Farahat, T. Lofaro, J. C. Miller, G. Rae, and L. A. Wart, “Authority rankings from HITS, PageRank, and SALSA: Existence, uniqueness, and effect of initialization,” SIAM J. Sci. Comput., vol. 27, no. 4, pp. 1181–1201, 2006.

[23] H. Feng, J. Griffin, Y. Huang, S. Jha, W. Lee, and B. Miller, “Formalizing sensitivity in static analysis for intrusion detection,” in Security and Privacy, 2004. Proceedings. 2004 IEEE Symposium on, May 2004, pp. 194–208.

[24] D. Gao, M. K. Reiter, and D. Song, “On gray-box program tracking for anomaly detection,” in Proceedings of the 13th conference on USENIX Security Symposium - Volume 13, ser. SSYM’04. USENIX Association, 2004. [Online]. Available: http://portal.acm.org/citation.cfm?id=1251375.1251383

[25] J. T. Griffin, S. Jha, and B. P. Miller, “Detecting manipulated remote call streams,” in Proceedings of the 11th USENIX Security Symposium. Berkeley, CA, USA: USENIX Association, 2002, pp. 61–79. [Online]. Available: http://dl.acm.org/citation.cfm?id=647253.720282

[26] T. H. Haveliwala and S. D. Kamvar, “The second eigenvalue of the Google matrix,” Stanford University, Tech. Rep. 582, 2003.

[27] W. Hoeffding, “Probability inequalities for sums of bounded random variables,” Journal of the American Statistical Association, vol. 58, no. 301, pp. 13–30, 1963.

[28] A. Kapravelos, Y. Shoshitaishvili, M. Cova, C. Kruegel, and G. Vigna, “Revolver: An automated approach to the detection of evasive web-based malware,” in Proceedings of the 22nd USENIX Conference on Security, ser. SEC’13. Berkeley, CA, USA: USENIX Association, 2013, pp. 637–652. [Online]. Available: http://dl.acm.org/citation.cfm?id=2534766.2534821

[29] M. J. Kearns and U. V. Vazirani, An Introduction to Computational Learning Theory. Cambridge, MA, USA: MIT Press, 1994.

[30] J. M. Kleinberg, “Authoritative sources in a hyperlinked environment,” J. ACM, vol. 46, no. 5, pp. 604–632, Sep. 1999. [Online]. Available: http://doi.acm.org/10.1145/324133.324140

[31] C. Kruegel and G. Vigna, “Anomaly detection of web-based attacks,” in Proceedings of the 10th ACM conference on Computer and communications security, ser. CCS ’03. ACM, 2003. [Online]. Available: http://doi.acm.org/10.1145/948109.948144

[32] A. N. Langville and C. D. Meyer, Google’s PageRank and Beyond: The Science of Search Engine Rankings. Princeton, NJ: Princeton University Press, 2006.

[33] C. P. Lee, “A fast two-stage algorithm for computing PageRank and its extensions,” Tech. Rep., 2003.

[34] M. Leonard, “Flawed process,” Indiana Herald-Times, August 10–12, 2008.

[35] J. Leskovec and C. Faloutsos, “Sampling from large graphs,” in Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD ’06. New York, NY, USA: ACM, 2006, pp. 631–636. [Online]. Available: http://doi.acm.org/10.1145/1150402.1150479

[36] Z. Li, S. Alrwais, X. Wang, and E. Alowaisheq, “Hunting the red fox online: Understanding and detection of mass redirect-script injections,” in Proceedings of 2014 IEEE Symposium on Security and Privacy. IEEE Computer Society, 2014.

[37] F. Long, V. Ganesh, M. Carbin, S. Sidiroglou, and M. Rinard, “Automatic input rectification,” in Proceedings of the 2012 International Conference on Software Engineering, ser. ICSE 2012. IEEE Press, 2012, pp. 80–90. [Online]. Available: http://dl.acm.org/citation.cfm?id=2337223.2337233

[38] F. Long, S. Sidiroglou-Douskos, D. Kim, and M. Rinard, “Sound input filter generation for integer overflow errors,” in Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, ser. POPL ’14. New York, NY, USA: ACM, 2014, pp. 439–452. [Online]. Available: http://doi.acm.org/10.1145/2535838.2535888

[39] M. W. Mahoney and L. Orecchia, “Implementing regularization implicitly via approximate eigenvector computation,” in Proceedings of the 28th International Conference on Machine Learning (ICML’11), 2011, pp. 121–128.

[40] M. R. Meiss, B. Gonçalves, J. J. Ramasco, A. Flammini, and F. Menczer, “Modeling traffic on the web graph,” in Proc. 7th Workshop on Algorithms and Models for the Web Graph (WAW), R. Kumar and D. Sivakumar, Eds. Berlin / Heidelberg: Springer, 2010, pp. 50–61.

[41] M. R. Meiss, F. Menczer, S. Fortunato, A. Flammini, and A. Vespignani, “Ranking web sites with real user traffic,” in Proc. WSDM’08, 2008, pp. 65–75.

[42] A. Narayanan and V. Shmatikov, “De-anonymizing social networks,” in IEEE Security and Privacy, 2009, pp. 173–187.

[43] ——, “Myths and fallacies of personally identifiable information,” Communications of the ACM, vol. 53, no. 6, pp. 24–26, 2010.

[44] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly, “Detecting spam web pages through content analysis,” in Proceedings of the 15th International Conference on World Wide Web, ser. WWW ’06. New York, NY, USA: ACM, 2006, pp. 83–92. [Online]. Available: http://doi.acm.org/10.1145/1135777.1135794

[45] L. Page, S. Brin, R. Motwani, and T. Winograd, “The PageRank citation ranking: Bringing order to the Web,” in Proceedings of the 7th International World Wide Web Conference, Brisbane, Australia, 1998, pp. 161–172. [Online]. Available: citeseer.nj.nec.com/page98pagerank.html

[46] R. Perdisci, D. Ariu, P. Fogla, G. Giacinto, and W. Lee, “McPAD: A multiple classifier system for accurate payload-based anomaly detection,” Computer Networks, vol. 53, no. 6, pp. 864 – 881, 2009, traffic Classification and Its Applications to Modern Networks. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S1389128608003927

[47] G. Stringhini, C. Kruegel, and G. Vigna, “Shady paths: Leveraging surfing crowds to detect malicious web pages,” in Proceedings of the 2013 ACM SIGSAC Conference on Computer & Communications Security, ser. CCS ’13. New York, NY, USA: ACM, 2013, pp. 133–144. [Online]. Available: http://doi.acm.org/10.1145/2508859.2516682

[48] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song, “Design and evaluation of a real-time URL spam filtering service,” in Proceedings of the 2011 IEEE Symposium on Security and Privacy, ser. SP ’11. Washington, DC, USA: IEEE Computer Society, 2011, pp. 447–462. [Online]. Available: http://dx.doi.org/10.1109/SP.2011.25

[49] F. Valeur, D. Mutz, and G. Vigna, “A learning-based approach to the detection of SQL attacks,” in DIMVA 2005, 2005.

[50] D. Wagner and D. Dean, “Intrusion detection via static analysis,” in Security and Privacy, 2001. S P 2001. Proceedings. 2001 IEEE Symposium on, 2001, pp. 156–168.

[51] K. Wang and S. J. Stolfo, “Anomalous payload-based network intrusion detection,” in RAID, 2004.