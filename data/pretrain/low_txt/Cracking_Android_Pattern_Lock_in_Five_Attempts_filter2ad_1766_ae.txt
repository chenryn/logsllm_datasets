### Experiment Overview

In this experiment, we investigate the feasibility of an attacker inferring a pattern either by watching a video or through direct observation. To address this, we recruited ten participants and asked each to watch 60 videos, in which patterns were drawn by other participants, and to guess the pattern. Each video segment, lasting approximately 3 seconds, was played only during the pattern drawing phase. To familiarize participants with the process, we initially showed them five sample videos, revealing the correct patterns at the end of each.

Each participant was given 10 minutes to watch a video and had five attempts to guess the pattern. They could adjust the playback speed and replay the video as many times as they wished.

### Results from Video Watching

Figure 24(a) illustrates the success rates of pattern guessing using only visual observation. Our participants correctly guessed nearly half of the simple patterns within five attempts. However, they found it challenging to infer complex patterns, especially those with many line segments, overlapping lines, and intersections. The success rate for guessing complex patterns was less than 10% in five attempts. This outcome is not surprising, as while it is feasible to guess simple patterns by watching the video, doing so for more complex structures is significantly more difficult.

### Direct Observation

We also conducted an experiment where participants directly observed the pattern being drawn from a distance of 2 meters. The rationale behind this evaluation is that human eyes can capture richer information compared to a digital video camera. The results are shown in Figure 24(b). Although the success rate improved compared to watching the video, the chances of guessing the correct pattern in five attempts remained low. Specifically, the success rates for simple, medium, and complex patterns were 48.3%, 38.3%, and 11.7%, respectively.

### Evaluation on Other Pattern Grids

**Result 7:**
A pattern grid with more dots provides stronger protection, but our attack can still crack most patterns. Some applications (e.g., CyanLock) and customized ROMs allow increasing the pattern grid size from 3×3 to 4×4, 5×5, and 6×6. While a 3×3 grid remains popular (as it is supported by the native Android OS), it is important to study whether larger grids enhance security.

In this experiment, we ranked all possible patterns for each grid setting in ascending order of complexity and divided them into three groups: simple, medium, and complex. Participants randomly selected 20 patterns from each group for evaluation. We report the success rate of our attack within five attempts.

Figure 25 shows the success rates of our attack for different grid sizes. Similar to the 3×3 grid, our approach achieved higher success rates for complex patterns over simple ones. On average, we cracked 90% of the complex patterns. A grid with more dots does provide stronger protection; for example, the success rate for complex patterns dropped from 95% on a 4×4 grid to 87% on a 6×6 grid. For simple patterns, the success rate dropped from 85% on a 4×4 grid to 75% on a 6×6 grid. This is because a fingertip trajectory can be mapped to a larger number of candidates on a grid with more dots. Overall, our attack can crack over 75% (up to 95%) of the patterns within five attempts. Despite the intention to allow users to use more complex patterns, this experiment suggests that complex patterns remain less secure under our attack.

### Discussion

#### Potential Countermeasures

The success of our attack depends on three factors:
1. **Knowledge of the pattern grid:** Attackers can obtain this information by analyzing a device with the same operating system and applications. Randomization techniques, such as randomized pictures, could mitigate this, but they often come at the cost of poorer usability.
2. **Quality of video footage:** High-quality footage is necessary for the algorithm to track the fingertip movement. Techniques like KALEIDO can prevent unauthorized videotaping by dynamically changing the screen's color and brightness. Non-technical solutions, such as covering the fingers when drawing a pattern, can also help, though this may be awkward on large-screen devices.
3. **Identifying the video segment:** For screen locks, identifying the segment is straightforward as pattern drawing is typically the first activity. Mixing pattern unlocking with other on-screen activities could be a countermeasure, but it might annoy users.

#### Implications

While many users prefer pattern locks, this work demonstrates their vulnerability to video-based attacks. Our attack can break most patterns in five attempts, highlighting the insecurity of the default Android setting, which allows five failed attempts before locking the device. Contrary to common belief, complex patterns do not provide stronger protection under our attack.

### Related Work

Our work combines computer vision and motion tracking to develop a new attack on graphical- and touch-based authentication methods. No prior work has targeted using video footage to crack Android pattern locks. Our approach is inspired by Shukla et al.'s work on video-based attacks on PIN-based passwords but differs in targeting graphical-based passwords and not requiring knowledge of the screen or grid size. Other related work includes attacks on PIN-based passwords via screen brightness changes and reflections, which require clear visibility of the screen content, unlike our method.

### Conclusions

This paper presents a novel video-based side-channel attack for Android pattern locks. Using a mobile phone camera, we filmed the target device from a distance of 2 meters. Our approach, which tracks the fingertip movement and uses geometric information to identify likely patterns, was evaluated with 120 unique patterns. The experimental results show that our attack can successfully crack over 90% of the patterns in five attempts. Complex patterns, contrary to popular belief, provide weaker protection under our attack, suggesting that Android pattern locks are vulnerable to video-based side-channel attacks.

### Acknowledgements

This work was partly supported by the National Natural Science Foundation of China (NSFC) through grant agreements 61672427, 61672428, and 61572402; and the UK Engineering and Physical Sciences Research Council (EPSRC) through grant agreements EP/M01567X/1 (SANDeRs) and EP/M015793/1 (DIVIDEND). The user patterns used to evaluate this work are openly available from the Lancaster University data archive at https://dx.doi.org/10.17635/lancaster/researchdata/113.

### References

[1] A. J. Aviv et al., “Smudge attacks on smartphone touch screens,” in 4th USENIX Conference on Offensive Technologies, 2010.
[2] M. Backes et al., “Tempest in a teapot: Compromising reflections revisited,” in IEEE S & P ’09.
[3] L. Ballard et al., “Forgery quality and its implications for behavioral biometric security,” IEEE SMC, 2007.
[4] D. a. Balzarotti, “Clearshot: Eavesdropping on keyboard input from video,” in IEEE S &P ’08.
[5] J. Beh et al., “Rule-based trajectory segmentation for modeling hand motion trajectory,” Pattern Recognition, 2014.
[6] R. Biddle et al., “Graphical passwords: Learning from the first twelve years,” ACM Computing Surveys (CSUR), 2012.
[7] D. V. Bruggen, “Studying the impact of security awareness efforts on user behavior,” Ph.D. dissertation, University of Notre Dame, 2014.
[8] L. F. Cranor et al., Eds., It’s a Hard Lock Life: A Field Study of Smartphone (Un)Locking Behavior and Risk Perception.
[9] A. De Angeli et al., “Is a picture really worth a thousand words? exploring the feasibility of graphical authentication systems,” Int. J. Hum.-Comput. Stud., 2005.
[10] A. De Luca et al., “Touch me once and I know it’s you!: implicit authentication based on touch screen patterns,” in CHI ’12.
[11] S. Egelman et al., “Are you ready to lock?” in CCS ’14.
[12] v. G. R. Grompone et al., “LSD: a fast line segment detector with a false detection control.” IEEE PAMI, 2010.
[13] T. Hastie and R. Tibshirani, “Discriminant adaptive nearest neighbor classification,” IEEE PAMI, 1996.
[14] Z. Kalal, “TLD: Tracking-learning-detection,” http://kahlan.eps.surrey.ac.uk/featurespace/tld/.
[15] Z. Kalal et al., “Tracking-learning-detection,” IEEE PAMI, 2012.
[16] M. G. Kuhn, “Compromising emanations: eavesdropping risks of computer displays,” Ph.D. dissertation, University of Cambridge, 2002.
[17] M. H. Kutner, C. J. Nachtsheim, and J. Neter, “Applied linear regression models (5th ed.),” Technometrics, vol. 26, no. 4, 2004.
[18] M. D. Løge, “Tell me who you are and I will tell you your unlock pattern,” Master’s thesis, Norwegian University of Science and Technology, 2015.
[19] M. Mannan and P. C. van Oorschot, “Using a personal device to strengthen password authentication from an untrusted computer,” in Financial Cryptography and Data Security. Springer, 2007, pp. 88–103.
[20] R. Raguram et al., “iSpy: automatic reconstruction of typed input from compromising reflections,” in CCS ’11.
[21] J. Rogers, “Please enter your four-digit PIN,” Financial Services Technology, 2007.
[22] A. Serwadda and V. V. Phoha, “When kids’ toys breach mobile phone security,” in CCS ’13.
[23] D. Shukla et al., “Beware, your hands reveal your secrets!” in CCS ’14.
[24] H. Siadati et al., “Fortifying android patterns using persuasive security framework,” in UBICOMM 2015.
[25] D. Stefan et al., “Robustness of keystroke-dynamics based biometrics against synthetic forgeries,” Computers & Security, 2012.
[26] B. Stenger et al., “Model-based hand tracking using a hierarchical Bayesian filter,” IEEE PAMI, 2006.
[27] C. Sun et al., “Dissecting pattern unlock: The effect of pattern strength meter on pattern selection,” Journal of Information Security and Applications, 2014.
[28] A. Torralba and A. Oliva, “Depth estimation from image structure,” IEEE PAMI, 2002.
[29] S. Uellenbeck et al., “Quantifying the security of graphical passwords: The case of Android unlock patterns,” in CCS ’13.
[30] E. von Zezschwitz et al., “Easy to draw, but hard to trace?: On the observability of grid-based (un)lock patterns,” in CHI ’15.
[31] Y. Xu et al., “Seeing double: Reconstructing obscured typed input from repeated compromising reflections,” in CCS ’13.
[32] M. H. Yang et al., “Extraction of 2D motion trajectories and its application to hand gesture recognition,” IEEE PAMI, 2002.
[33] Q. Yue et al., “Blind recognition of touched keys: Attack and countermeasures,” arXiv preprint arXiv:1403.4829, 2014.
[34] J. Zhang et al., “Privacy leakage in mobile sensing: Your unlock passwords can be leaked through wireless hotspot functionality,” Mobile Information Systems, 2016.
[35] L. Zhang et al., “Kaleido: You can watch it but cannot record it,” in MobiCom ’15.