# Infection Burstiness Analysis

## Figure 9: Infection Burstiness for Servers and Clients

- **Server Infections**
- **Client Infections**
- **Independent Infections**

| Time Interval (seconds) | Frequency |
|------------------------|-----------|
| 0                      | 10        |
| 1                      | 10        |
| 2                      | 10        |
| 3                      | 10        |
| 4                      | 10        |
| 5                      | 10        |

### Analysis of Infection Burstiness

An interesting aspect of the extracted infection time series is the burstiness across different time scales. To quantify this, we use the Allan deviation [2], which is defined by the following equation:

\[
\sigma^2_x(\tau) = \frac{1}{2} \left\langle (\Delta x)^2 \right\rangle
\]

The time series is discretized into intervals of length \(\tau\), and each interval yields a sample \(x_i\) representing the number of infections within it. The equation measures the difference between successive samples \(x_i\) for different interval lengths \(\tau\).

In Figure 9, the bold line at the bottom represents the minimum possible deviation, which occurs when all infections have independent arrival times. Intuitively, the Allan deviation should diverge significantly from this reference in time scales where the signal exhibits high burstiness.

- **Server Infections**: At low time scales, server infections are almost independent. This changes at time scales above one hour, suggesting that measuring infections over hourly intervals can provide a useful long-term average of expected infections. This observation can be used to build a predictor of near-future infection incidents using simple linear time series models like ARIMA.
- **Client Infections**: Client infections are consistently more bursty, especially for time scales above two minutes.

## Related Work

### IDS Evaluation

- **DARPA Dataset [35]**: Despite dating back to 1999, it remains one of the best options for IDS evaluation, though it has several well-known shortcomings [1, 3].
- **DARPA Cyber Panel Correlation Technology Validation [31]**: Created in 2002 but no longer available.
- **MACE [48]**: An environment for generating malicious packets for evaluating IDSs in testbeds.
- **Our Contribution**: We emphasize the need to use and label traces collected in real-world environments.

### Intrusion Measurements

- **DShield [17]**: Large traces of intrusion data, such as IDS alerts and firewall logs, have been analyzed in previous studies.
- **Yegneswaran et al. [52]**: Made observations on the distribution, types, and prevalence of intrusions, and projected global intrusion volumes.
- **Kati et al. [34]**: Analyzed a large trace of IDS alerts, reported characteristics of correlated attacks, and investigated collaboration in intrusion detection.
- **Our Contribution**: We provide further insights specifically on infections, which have not been studied as a separate class in the past.

### Alert Correlation and Aggregation

#### Statistical/Temporal Alert Correlation
- **Statistical Correlation Methods [41, 36]**: Estimate the association between different alerts by measuring co-occurrence and frequency.
- **Temporal-Based Correlation [42]**: Perform time series analysis on the alert stream to compute dependencies.
- **Our Contribution**: We use a statistical alert correlation test in our heuristic and show its utility for extrusion detection.

#### Scenario- and Rule-based Alert Correlation
- **Scenario-Based Approaches [38, 12]**: Hardcode attack steps into full scenarios or rules to identify, summarize, and annotate alert groups.
- **Rule-Based Approaches [39, 6, 5]**: Match specific alerts to the prerequisites and consequences of an active attack stage.
- **Our Contribution**: We highlight the limitations of these approaches and propose a simpler form of alert aggregation, called "alert bundling," for grouping spurts of almost identical alerts.

#### Alert Aggregation
- **Valdes et al. [51]**: Represent each alert as a vector of attributes and group them based on weighted similarity.
- **Dain et al. [10, 9]**: Propose a system for associating incoming alerts with groups in an online fashion.
- **Julisch [32]**: Uses clustering techniques to group alerts sharing the same root causes.
- **Zhu et al. [53]**: Propose a supervised learning approach based on neural networks.
- **Our Contribution**: We use a simple form of alert aggregation in our heuristic, which groups spurts of almost identical alerts for further statistical analysis.

## Discussion

### False Negatives
- **Objective**: Design the heuristic to produce a small number of false positives, as excessive false positives are a limiting factor for IDSs.
- **Trade-off**: Prefer to incur more false negatives to reduce false positives.
- **Evaluation**: Quantifying false negative rates in a production environment is challenging, but synthetic or testbed-based traces can be used for assessment.

### Academic Infrastructure
- **Data Source**: Our characterization results are based on data from an academic infrastructure and should be generalized carefully to other network types.
- **Expected Findings**: Similar qualitative findings about the impact of infections and the presence of heavy hitters are expected in different networks, but the volume of infections may be lower in tightly managed environments.

## Conclusions

We present a novel approach to identify active infections in a large population of hosts using IDS logs. By tailoring our heuristic based on the observation that alerts with high mutual information are likely to be correlated, we find infections for over 91,000 unique hosts. Our method reduces the false-positive rate of raw IDS alerts to only 15%. Our findings suggest that infections exhibit high spatial correlations and open wide attack vectors for inbound attacks. Additionally, client infections are significantly more bursty compared to server infections. These results are valuable for various fields, including network defenses, extrusion detection, IDS false positive reduction, and network forensics.

## Acknowledgements

We thank Prof. Bernhard Plattner and Dr. Vincent Lenders for their invaluable help and fruitful discussions. We also thank Matthias Eggli for his assistance in validating the infection incidents. Stephan Sheridan and Christian Hallqvist at ETH provided support in the collection and archiving of the data used in this paper. This work was supported by the Armasuisse Secmetrics [2-7841-09] project.

## References

[1] Testing intrusion detection systems: a critique of the 1998 and 1999 DARPA intrusion detection system evaluations as performed by Lincoln Laboratory. ACM Trans. Inf. Syst. Secur., 3:262–294, November 2000.

[2] D. W. Allan. Time and frequency (time domain) characterization, estimation and prediction of precision clocks and oscillators. IEEE Trans. UFFC, 34, November 1987.

[3] Carson Brown, Alex Cowperthwaite, Abdulrahman Hijazi, and Anil Somayaji. Analysis of the 1999 DARPA/Lincoln Laboratory IDS evaluation data with NetAdhict. In Proceedings of the Second IEEE international conference on Computational intelligence for security and defense applications, CISDA’09, pages 67–73, Piscataway, NJ, USA, 2009. IEEE Press.

[4] David Brumley, Cody Hartwig, Zhenkai Liang, James Newsome, Dawn Song, and Heng Yin. Automatically identifying trigger-based behavior in malware, 2008.

[5] Steven Cheung, Ulf Lindqvist, and Martin W. Fong. Modeling multistep cyber attacks for scenario recognition, 2003.

[6] Frédéric Cuppens and Alexandre Miège. Alert correlation in a cooperative intrusion detection framework. In Proceedings of the 2002 IEEE Symposium on Security and Privacy, pages 202–, Washington, DC, USA, 2002. IEEE Computer Society.

[7] Frédéric Cuppens and Rodolphe Ortalo. Lambda: A language to model a database for detection of attacks. In Proceedings of the Third International Workshop on Recent Advances in Intrusion Detection, RAID ’00, pages 197–216, London, UK, 2000. Springer-Verlag.

[8] D. Curry and H. Debar. Intrusion detection message exchange format: Extensible markup language document type definition, 2003.

[9] Oliver Dain and Robert K. Cunningham. Fusing a heterogeneous alert stream into scenarios. In In Proceedings of the 2001 ACM workshop on Data Mining for Security Applications, pages 1–13, 2001.

[10] Oliver M. Dain and Robert K. Cunningham. Building scenarios from a heterogeneous alert stream, 2002.

[11] Neil Daswani, The Google Click Quality, Security Teams, and Google Inc. The anatomy of clickbot.a. In In USENIX Hotbots’07, 2007.

[12] Hervé Debar and Andreas Wespi. Aggregation and correlation of intrusion-detection alerts. In Proceedings of the 4th International Symposium on Recent Advances in Intrusion Detection, RAID ’00, pages 85–103, London, UK, 2001. Springer-Verlag.

[13] Steven Eckmann, Giovanni Vigna, and Richard A. Kemmerer. STATL: An attack language for state-based intrusion detection, 2002.

[14] Advanced automated threat analysis system. www.threatexpert.com.

[15] Anonymous postmasters early warning system. www.apews.org.

[16] Common Vulnerabilities and Exposures dictionary of known information security vulnerabilities. cve.mitre.org.

[17] Cooperative Network Security Community - Internet Security. www.dshield.org.

[18] Damballa - Botnet and Advanced Malware Detection and Protection. www.damballa.com.

[19] Emerging Threats web page. http://www.emergingthreats.net.

[20] Network Security Archive. http://www.networksecurityarchive.org.

[21] Packet Storm Full Disclosure Information Security. packetstormsecurity.org.

[22] Projecthoneypot web page. www.projecthoneypot.org.

[23] Shadowserver Foundation web page. www.shadowserver.org.

[24] Symantec SecurityFocus technical community. www.securityfocus.com.

[25] The Nessus vulnerability scanner. www.tenable.com/products/nessus.

[26] The Open Vulnerability Assessment System. www.openvas.org.

[27] The Spamhaus Project. www.spamhaus.org.

[28] The Urlblacklist web page. www.urlblacklist.org.

[29] TrustedSource Internet Reputation System. www.trustedsource.org.

[30] Loic Etienne and Jean-Yves Le Boudec. Malicious traffic detection in local networks with Snort. Technical report, EPFL, 2009.

[31] Joshua Haines, Dorene Kewley Ryder, Laura Tinnel, and Stephen Taylor. Validation of sensor alert correlators. IEEE Security and Privacy, 1:46–56, January 2003.

[32] Klaus Julisch. Clustering intrusion detection alarms to support root cause analysis. ACM Transactions on Information and System Security, 6:443–471, 2003.

[33] Klaus Julisch and Marc Dacier. Mining intrusion detection alarms for actionable knowledge. In KDD ’02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 366–375, New York, NY, USA, 2002. ACM.

[34] Sachin Katti, Balachander Krishnamurthy, and Dina Katabi. Collaborating against common enemies. In Proceedings of the 5th ACM SIGCOMM conference on Internet Measurement, IMC ’05, pages 34–34, Berkeley, CA, USA, 2005. USENIX Association.

[35] Richard Lippmann, Joshua W. Haines, David J. Fried, Jonathan Korba, and Kumar Das. The 1999 DARPA off-line intrusion detection evaluation. Computer Networks, 34:579–595, October 2000.

[36] Federico Maggi and Stefano Zanero. On the use of different statistical tests for alert correlation: short paper. In Proceedings of the 10th international conference on Recent advances in intrusion detection,