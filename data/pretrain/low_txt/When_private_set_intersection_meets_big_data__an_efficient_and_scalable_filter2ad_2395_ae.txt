### Performance Evaluation of the Basic Protocol

#### Overview
The hash functions in the OT (Oblivious Transfer) extension protocol are instantiated based on security parameters. When hash values need to be truncated, the truncation follows the NIST [14] guidelines. For the public key operations required by the Naor-Pinkas OT protocol, we use NIST elliptic curve groups over \( \mathbb{F}_p \) [36]. Elliptic curve groups are chosen because they offer better performance at high security levels compared to integer groups.

The C prototype consists of two executables: one for the client and one for the server. Communication between the client and server is facilitated via TCP. The prototype can operate in two modes: pipelined and parallel. 

- **Pipelined Mode**: In this mode, computation is performed in a single thread on each side, with an additional thread handling data transmission in parallel when possible. This allows the server or client to start working immediately without waiting for the other party to complete its computation.
  
- **Parallel Mode**: This mode extends the pipelined mode by utilizing all available CPU cores and distributing tasks evenly across them. Our test results show that the parallel mode significantly improves performance on multicore systems. This is due to the fact that the computation in our protocol is dominated by independent hashing. Specifically, on each side, \( n \) independent set elements each need to be hashed \( k \) times to build the Bloom filter or the garbled Bloom filter, and \( m \) matrix rows need to be hashed in the OT extension protocol. Since the data to be hashed is independent, this scenario is ideal for SPMD (Single Program Multiple Data) execution. The program detects the number of available cores, determines the number of threads, allocates data evenly to each thread, and then launches the threads to execute tasks in parallel. The hash values are then consumed by the main threads running the protocol. This approach requires minimal changes to the program structure. For example, only one line (line 8) needs to be modified in Algorithm 1, where instead of hashing the element, the algorithm reads from an array of precomputed index numbers.

#### Performance Evaluation

In this section, we present the performance evaluation results of our prototype. All experiments were conducted on two Mac computers:
- **Server**: Mac Pro with 2 Intel E5645 6-core 2.4GHz CPUs, 32 GB RAM, running Mac OS X 10.8.
- **Client**: MacBook Pro laptop with an Intel 2720QM quad-core 2.2 GHz CPU, 16 GB RAM, running Mac OS X 10.7.
- **Network**: 1000M Ethernet connection.

The security settings for the experiments are summarized in Table 2. In all experiments, we set the Bloom filter/garbled Bloom filter parameter \( k = \lambda \) so that the false positive probability of a Bloom filter is at most \( 2^{-\lambda} \). We also set \( m \) to the optimal value \( kn \log_2 e \). For example, at 80-bit security, \( k = \lambda = 80 \), and when \( n = 2^{20} \), \( m = 120795960 \). We used randomly generated integer sets in the experiments.

We measured the total running time of the protocol, starting from the client sending the request and ending immediately after the client outputs the intersection. The measurement includes all operations such as building the Bloom filter, building the garbled Bloom filter, the full OT extension protocol (including the underlying Naor-Pinkas OT), data transmission, and the client-side query for obtaining the intersection. However, we do not include the time for initialization tasks, such as generating random sets, interpreting command line arguments, and setting up sockets.

**Pipelined Mode Performance**
- We varied the set size \( n \) from \( 2^{10} \) to \( 2^{20} \) and security parameters \( \lambda \) and \( k \) from 80 to 256. The results are shown in Figure 4a. The running time increases almost linearly with the set size at each security level. Each increase in the security parameter results in an approximate doubling of the running time.
- We also measured the time for each individual step of the protocol, fixing the set size at \( 2^{20} \) and varying only the security levels. The results are shown in Figure 4b. The protocol's running time is dominated by the OT execution, suggesting that a more efficient OT protocol could further reduce the total running time.

**Parallel Mode Performance**
- In the parallel mode, multiple threads are used for computation. The results are shown in Figure 4c. The total running time in the parallel mode is significantly less than in the pipelined mode. At 80-bit security, the intersection of a million-element set can be computed in 41 seconds. In the highest security setting, the same computation takes 339 seconds, which is less than 6 minutes. A comparison of the performance in the two modes is shown in Figure 4d. The client has 4 cores, and the server has 12 cores, resulting in the parallel mode being about 5 times faster than the pipelined mode. This demonstrates that our protocol can fully leverage the benefits of multicore architecture.

**Comparison with Plain Algorithms**
- Our protocol's performance can even outperform some inefficient plain algorithms in certain settings. For example, Figure 4d shows the time needed for a single-threaded C program to compute the intersection of two unencrypted random sets (\( n = 2^{20} \)) by pairwise comparing the elements. It takes 429 seconds in the best case (when \( C = S \)) and 844 seconds in the worst case (when \( C \cap S = \emptyset \)).

### Performance Comparison

We compared the performance of our basic protocol against two existing protocols: Huang’s (Java) and De Cristofaro’s (C). The results are summarized in Table 3. All times shown in the table are in seconds, with some values estimated. The performance of our protocol is competitive and, in many cases, superior to these existing solutions.

- **Figure 4: Performance of our basic protocol**
  - **(a)** Bandwidth consumption at 80-bit security.
  - **(b)** Breakdown of the running time at different security levels.
  - **(c)** Performance in the parallel mode.
  - **(d)** Comparison of running time in the two modes.

- **Table 3: Performance comparison**
  - Shows the running times for different set sizes and security levels, comparing our protocol with Huang’s and De Cristofaro’s implementations.

This comprehensive evaluation demonstrates the efficiency and scalability of our protocol, making it suitable for large-scale private data processing.