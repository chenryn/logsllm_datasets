### Load and Component Performance Analysis

**Load (Applications/Node)**
- 6
- 8
- 9
- 10

**Component Average Prediction Error (%)**
- sort: 2.875
- project: 7.872
- aggregate: 0.838
- count: 2.019
- compare: 4.904

**Figure 17. Absolute average rate prediction error.**

**Component Average Prediction Time (ms)**
- sort: 0.133
- project: 0.327
- aggregate: 0.509
- count: 0.836
- compare: 1.187

**Figure 18. Average total prediction time.**

### Application QoS Improvement

**Application QoS Improvement**
- Without Hot-Spot Elimination
- With Hot-Spot Elimination

**Load (Applications/Node)**
- 1
- 2
- 3
- 5
- 7
- 4
- 6
- 8
- 9
- 10

**Figure 19. Application QoS improvement.**

### Application Performance Variation and Migration Overhead

**Application Performance Variation**
- Data Tuple Sequence Number: 0 to 2000
- End-to-End Delay (s): 0 to 12

**Migration Overhead**
- Number of Applications: 0 to 350
- Average Prediction Error (%): 0 to 120

**Figure 20. Application performance improvement.**
**Figure 21. Application performance variation.**
**Figure 22. Migration overhead.**

The figure focuses on the first 2000 tuples out of the total.

**Migration Overhead Analysis**
In Figure 22, we present the migration overhead required to achieve hot-spot alleviation benefits. The number of migrations is shown as a function of the number of applications deployed in the system. We observe that the number of migrations grows linearly with the number of applications. On average, one migration is required for every three applications. This indicates that, on average, one out of every three applications experiences a hot-spot at some point during execution, underscoring the need for application-oriented hot-spot alleviation. This assumes that not many applications require more than one migration, meaning the system is not so overloaded that a single migration does not permanently resolve a hot-spot. The average time required to perform a migration is 1144 ms, which includes the complete distributed protocol execution described in Section 4.2. The short migration time, combined with the fact that our migration protocol allows application execution to continue while the migration is taking place offline, makes our hot-spot alleviation mechanism suitable for distributed stream processing applications with QoS demands. Prediction further facilitates a fast response to a hot-spot before significant QoS violations occur.

### Related Work

Distributed stream processing systems have been the focus of extensive recent research from various perspectives. Studies on the placement of components to optimize resource use and maximize application performance [1, 13] complement our work. Any technique for deploying new components can be used when all nodes hosting a particular component type are overloaded. Additionally, the migration techniques presented in [13] can be used as an alternative to our migration protocol, complementing the prediction mechanisms for QoS violations. Similarly, work on component composition [8, 14] or application adaptation [2, 6, 10] can assist in load balancing. Load balancing for distributed stream processing applications has also been studied [3, 18, 24, 25]. Our approach differs in that we focus on application QoS rather than system utilization. Furthermore, we propose a hot-spot prediction framework to drive proactive migration decisions. In our previous work [15], we presented a peer-to-peer load balancing architecture, focusing on reactive, node-oriented hot-spot detection without using prediction. Load shedding [4, 21, 23] has been explored as a means to alleviate application hot-spots in stream processing systems. Our goal is to alleviate application hot-spots via migration in a less intrusive manner. Similar to our work, [23] identifies the need for proactive QoS management and proposes operator selectivity estimation using sampling. However, their methods refer to centralized stream processing on a single node.

Workload prediction has been studied in various contexts. [17] discusses how some workloads are best represented by open models, while others by closed ones. Dinda [7] has shown the effectiveness of linear models in predicting host load, network bandwidth, and performance data. In grid computing, multi-resource prediction has been proposed [11], where processor utilization is cross-correlated with memory utilization. We also use cross-correlation but between different nodes rather than different resources. Performance prediction for multi-tier web servers [19, 26] is relevant to our work, provided all tiers are considered and not just one assumed to be the bottleneck. [19] proposes a model based on queuing theory to predict performance as a function of the transaction mix. For stream processing applications, however, rate fluctuations rather than the type of required processing affect performance. Therefore, certain assumptions regarding the distribution of arrival rates needed for queuing analysis may not hold. [26] proposes a model based on regression to predict the processing cost of web transactions and drive capacity planning decisions. We also employ linear regression but focus on online execution time prediction.

### Conclusions

We have described hot-spot prediction and alleviation mechanisms for distributed stream processing applications. Our algorithms for hot-spot prediction are based on statistical methods such as linear regression and correlation, utilizing lightweight, passive measurements. Statistics collection, hot-spot prediction, and alleviation are carried out at runtime by all nodes independently, building upon a fully decentralized architecture. The experimental evaluation of our techniques on the Synergy middleware over PlanetLab, using a real network monitoring application operating on traces of real TCP traffic, demonstrated high prediction accuracy and substantial performance benefits with moderate monitoring and migration overheads.

### References

[1] Y. Ahmad and U. Cetintemel. Network-aware query processing for stream-based applications. In VLDB, 2004.
[2] R. Arpaci-Dusseau. Run-time adaptation in river. ACM Transactions on Computer Systems, 21(1):36–86, Feb. 2003.
[3] M. Balazinska, H. Balakrishnan, and M. Stonebraker. Contract-based load management in federated distributed systems. In NSDI, 2004.
[4] P. Barlet-Ros et al. Load shedding in network monitoring applications. In USENIX Annual Technical Conference, 2007.
[5] A. Bavier et al. Operating systems support for planetary-scale network services. In NSDI, 2004.
[6] F. Chen, T. Repantis, and V. Kalogeraki. Coordinated media streaming and transcoding in peer-to-peer systems. In IPDPS, 2005.
[7] P. Dinda. Design, implementation, and performance of an extensible toolkit for resource prediction in distributed systems. IEEE TPDS, 17(2):160–173, February 2006.
[8] X. Gu, P. Yu, and K. Nahrstedt. Optimal component composition for scalable stream processing. In ICDCS, 2005.
[9] L. Kleinrock. Queueing Systems. Volume 1: Theory. John Wiley and Sons Inc., New York, NY, USA, 1975.
[10] V. Kumar, B. Cooper, Z. Cai, G. Eisenhauer, and K. Schwan. Resource-aware distributed stream management using dynamic overlays. In ICDCS, 2005.
[11] J. Liang, K. Nahrstedt, and Y. Zhou. Adaptive multi-resource prediction in distributed resource sharing environment. In CCGRID, 2004.
[12] D. Montgomery and G. Runger. Applied Statistics and Probability for Engineers. John Wiley & Sons Inc., NY, 2006.
[13] P. Pietzuch, J. Ledlie, J. Shneidman, M. Roussopoulos, M. Welsh, and M. Seltzer. Network-aware operator placement for stream-processing systems. In ICDE, 2006.
[14] T. Repantis, X. Gu, and V. Kalogeraki. Synergy: Sharing-aware component composition for distributed stream processing systems. In Middleware, 2006.
[15] T. Repantis and V. Kalogeraki. Alleviating hot-spots in peer-to-peer stream processing environments. In DBISP2P, 2007.
[16] A. Rowstron and P. Druschel. Pastry: Scalable, distributed object location and routing for large-scale peer-to-peer systems. In Middleware, 2001.
[17] B. Schroeder, A. Wierman, and M. Harchol-Balter. Open versus closed: A cautionary tale. In NSDI, 2006.
[18] M. Shah, J. Hellerstein, S. Chandrasekaran, and M. Franklin. Flux: An adaptive partitioning operator for continuous query systems. In ICDE, 2003.
[19] C. Stewart, T. Kelly, and A. Zhang. Exploiting nonstationarity for performance prediction. In EuroSys, 2007.
[20] Stream Query Repository. http://infolab.stanford.edu/stream/sqr/netmon.html, 2002.
[21] N. Tatbul, U. Cetintemel, S. Zdonik, M. Cherniack, and M. Stonebraker. Load shedding in a data stream manager. In VLDB, 2003.
[22] The Internet Traffic Archive. http://ita.ee.lbl.gov/html/contrib/lbl-tcp-3.html, 1994.
[23] Y. Wei, V. Prasad, S. Son, and J. Stankovic. Prediction-based QoS management for real-time data streams. In RTSS, 2006.
[24] Y. Xing, J. Hwang, U. Cetintemel, and S. Zdonik. Providing resiliency to load variations in distributed stream processing. In VLDB, 2006.
[25] Y. Xing, S. Zdonik, and J. Hwang. Dynamic load distribution in the Borealis stream processor. In ICDE, 2005.
[26] Q. Zhang, L. Cherkasova, and E. Smirni. A regression-based analytic model for dynamic resource provisioning of multi-tier applications. In ICAC, 2007.