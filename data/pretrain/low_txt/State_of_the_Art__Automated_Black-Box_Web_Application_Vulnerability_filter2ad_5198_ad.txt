# Server and Cryptographic Configuration Vulnerability Detection Results

Figure 13 illustrates the results of server and cryptographic configuration vulnerability detection, sorted by scanner rank. The benign region within a block caused false positives in two scanners: one reported a single false positive URL, while the other reported 13 different URLs.

## False Positive Analysis

Figure 14 presents the number of false positives reported by each scanner in ascending order for this category. For reference, there are approximately 90 confirmed vulnerabilities in our testbed. Notably, several scanners did not report any false positives, and some with low false-positive rates also had high vulnerability detection rates. The two scanners with the highest number of false positives, both with among the lowest vulnerability detection rates, incorrectly reported accessible code backup files that did not exist. The worst-performing scanner for false positives also reported issues such as file inclusion, SQL injection, IP disclosure, path disclosure, and forms accepting POST parameters from GET requests. Additionally, this scanner classified hidden form values as vulnerabilities, which contradicts established practices for CSRF prevention using hidden form authentication tokens. Other notable false positives included a CSRF vulnerability reported despite the presence of an authentication token, and auto-complete being reported for a password field where it was actually disabled.

Some scanners issued general warnings for potential vulnerabilities, such as GET form methods or forms without hidden authentication fields, without specifying the offending URLs. We counted these as detections in our data collection, but they could also be considered false positives due to their general nature.

## Experimental and Scanner Usage Observations

We have primarily focused on the detection performance of the scanners across different vulnerability classifications. In this section, we will discuss some individual characteristics of the scanners without making overall comparative rankings.

No single scanner excelled in every vulnerability classification. Often, scanners with leading detection rates in one category performed poorly in others. For example, the top scanner for XSS and SQL injection was among the bottom three for session management vulnerabilities, while the leader in session vulnerabilities lagged in XSS and SQL injection. This suggests that scanner vendors could benefit from cross-pollination of ideas.

Scanners with high detection rates effectively controlled false positives, while those with low detection rates often produced many false positives. Some scanners were reticent, reporting few total vulnerabilities, resulting in both low detection rates and low false-positive counts.

The distinction between remote and local scanners offers interesting choices for customers. Remote scanners are convenient as they require no installation, offer portable user interfaces and report storage, run with complete automation after initial configuration, and do not consume internal network and system resources. However, commercial enterprises may be concerned about privacy and information disclosure when conducting scans over public networks. Vendors like Cenzic and Rapid7 offer both remote and local options. Our experiments showed that the architecture (local vs. remote) did not significantly affect overall detection results.

Regarding user experience, most tools offer interactive and automated scanning modes. In automated mode, some tools still require user interaction to dismiss JavaScript alert boxes, causing workflow disruptions. This issue is likely to persist in larger, deployed applications.

While the reported vulnerability detection rates are generally less than 50%, this should not be seen as a criticism of the usefulness of automated black-box scanners. These tools can still be valuable components in security auditing programs, especially when considering factors like cost and time savings compared to manual review.

## Related Work

Significant regulatory and industry efforts have been devoted to vulnerability categorization. The Common Vulnerabilities and Exposures (CVE) database, sponsored by the US Department of Homeland Security, associates each vulnerability with a Common Weakness Enumeration (CWE) category. Industry groups like OWASP and WASC have published web-specific vulnerability classifications. WASC has also published a report on web-vulnerability statistics, which supports our results but includes higher self-reported detection rates due to the inclusion of manual white-box audits.

NIST and WASC have published evaluation criteria for web application scanners. We consulted these guidelines to ensure the comprehensiveness of our testbed, which checks all NIST recommendations and 37 of the 41 first-and-second-level testing capabilities listed by WASC.

Academic research on web application security tools has largely focused on source code analysis for detecting XSS and SQL injection via information flow and model checking. Notable works include studies by Wassermann, Lam, KieË™zun, Jovanovic, and Huang.

Kals et al. and McAllister et al. implemented automated black-box web vulnerability scanners, targeting SQLI and XSS vulnerabilities. Maggi et al. discussed techniques to reduce false positives in automated intrusion detection, applicable to black-box scanning. Open-source scanner projects like W3AF, Powerfuzzer, and Nikto were evaluated but not included in the study due to their limited testing scope.

Vulnerability demonstration sites like WebGoat, Hacme Bank, and AltoroMutual provide educational and sales-demonstration purposes. Suto conducted a comparison of seven black-box scanners using these sites. Fonseca et al. evaluated the XSS and SQLI detection performance of three commercial applications using automated software fault-injection methods.

## Conclusion

Our study examined the vulnerabilities targeted by current black-box scanners and their effectiveness. Cross-Site Scripting (XSS), SQL Injection, and Information Disclosure are the most prevalent classes of vulnerabilities. Black-box scanners generally expend testing effort in proportion to the prevalence of these vulnerabilities and are adept at detecting straightforward historical vulnerabilities. However, there is room for improvement in detecting advanced and second-order forms of XSS and SQLI, other forms of Cross-Channel Scripting, Cross-Site Request Forgery, and Malware Presence.

Research opportunities lie in improving the detection of advanced and second-order XSS and SQLI, increasing observability for second-order vulnerabilities, and better understanding of active content and scripting languages. Despite the need for improvement, the scanners we tested can still be valuable when used systematically as part of an overall security program.

## Acknowledgment

The authors thank Acunetix, Cenzic, IBM, McAfee, Qualys, and Rapid7 for their participation in this study.

## References

[References listed here as per the original document]

---

This revised version aims to provide a clear, coherent, and professional presentation of the text, ensuring that the information is well-organized and easy to follow.