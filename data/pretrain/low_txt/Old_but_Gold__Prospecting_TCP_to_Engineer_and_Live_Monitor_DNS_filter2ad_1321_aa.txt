**Title: Old but Gold: Prospecting TCP to Engineer and Live Monitor DNS Anycast**

**Authors:**
- Giovane C. M. Moura<sup>1,2</sup>
- John S. Heidemann<sup>3</sup>
- Wes Hardaker<sup>3</sup>
- Pithayuth Charnsethikul<sup>3</sup>
- Jeroen Bulten<sup>4</sup>
- Jo√£o M. Ceron<sup>1</sup>
- Cristian Hesselman<sup>1,5</sup>

**Affiliations:**
1. SIDN Labs, Arnhem, The Netherlands
2. TU Delft, Delft, The Netherlands
3. USC/ISI, Marina Del Rey, USA
4. SIDN, Arnhem, The Netherlands
5. University of Twente, Enschede, The Netherlands

**Abstract:**
DNS latency is a critical concern for many service operators. Content Delivery Networks (CDNs) aim to reduce service latency for end-users, but they rely on global DNS for reachability and load balancing. Currently, DNS latency is monitored through active probing from distributed platforms like RIPE Atlas or commercial services. While RIPE Atlas has broad coverage, its 10,000 sites only capture a fraction of the Internet. In this paper, we demonstrate that passive observation of TCP handshakes can measure live DNS latency continuously, providing comprehensive coverage of current clients. Estimating Round-Trip Time (RTT) from TCP is an old idea, but its application to DNS has not been thoroughly studied. We show that there is sufficient TCP DNS traffic today to provide good operational coverage, especially for IPv6, and excellent temporal coverage, enabling near-real-time evaluation of DNS latency from real clients. Additionally, DNS servers can optionally solicit TCP to broaden coverage. We validate that DNS latency estimates from TCP are consistent with UDP latency. Our approach uncovers previously unknown issues, such as DNS polarization, where a hypergiant sends global traffic to one anycast site instead of utilizing the global anycast deployment. Correcting polarization in Google DNS reduced latency from 100 ms to 10 ms, and in Microsoft Azure, it was reduced from 90 ms to 20 ms. We also identify other routing problems that add 100-200 ms latency. Real-time use of our approach for a European country-level domain helped detect and correct a BGP routing misconfiguration that detoured European traffic to Australia. We have integrated our approach into several open-source tools, including ENTRADA, Anteater, and a DNS anonymization tool.

**Introduction:**
Latency is a key performance indicator for DNS operators. DNS latency is often a bottleneck in web access, and CDNs are particularly sensitive to it due to frequent DNS-based load balancing and replica selection. Although DNS uses caching to reduce latency, low latency remains a selling point for many commercial DNS operators. DNS deployments often use IP anycast to reduce latency, allowing clients to select the lowest-latency authoritative server. However, monitoring DNS latency has been challenging. Active probing methods like RIPE Atlas and Verfploeter provide mixed coverage, with limitations in frequency and network reach.

The main contribution of this paper is to evaluate and demonstrate the operational effectiveness of passive latency observations in DNS using TCP. We show that passive observations of TCP handshakes can provide continuous updates of latency without additional traffic, complementing active probing methods. Observing latency from TCP in DNS is not new, but prior work has not validated its accuracy and coverage. We validate that latency measured from UDP and our estimates from TCP match, and we show that DNS servers can solicit TCP from selected clients to increase coverage.

Our second contribution is to demonstrate that TCP handshakes provide an effective estimate of DNS latency. Despite DNS primarily using UDP, there is enough DNS/TCP traffic to support good latency estimation. Passive analysis of TCP provides better coverage, especially for IPv6 networks, and can scale with actual traffic, increasing temporal coverage beyond current active approaches.

Finally, we show that TCP-based latency estimation is valuable for detecting and correcting latency problems in operational networks. We identify DNS polarization, where a hypergiant sends traffic to a single anycast location, and show how correcting this can significantly reduce latency. Our tools, including ENTRADA, Anteater, and a DNS anonymization tool, have been operational for more than two years at SIDN and were deployed by the B-Root root DNS server in March 2021. These tools have detected and corrected several issues, including a BGP routing misconfiguration that caused significant RTT increases.

**DNS/TCP for RTT?**
While UDP is the preferred transport layer for DNS, TCP support is required for large replies and when the server sets the TC (truncated) bit. Increasing numbers of clients are using TCP due to DNSSEC, response-rate limiting, and DNS privacy. The RTT between a TCP client and server can be measured passively during the TCP session establishment. We derive the RTT by computing the difference between times s2 and s1, measured at the server. For multiple observations per target region, we take the median to mitigate the impact of occasional retries.

For passive TCP observations to be effective for evaluating anycast networks, (a) enough clients must send DNS over TCP to serve as vantage points, and (b) the RTT for queries sent over TCP and UDP should be similar. We verify these requirements using data from three production authoritative servers: two from the .nl zone and B-root, one of the Root DNS servers. We compare the RTT of more than 8,000 vantage points with both TCP and UDP, confirming their similarity towards two large anycast networks: K and L-Root.

**Does TCP Provide Enough Coverage?**
To assess DNS/TCP coverage in production authoritative servers, we analyze traffic from the .nl zone and the DNS Root. For each zone, we measure the number of resolvers, ASes, TCP query fraction, and the percentage of resolvers using both UDP and TCP. Our goal is to estimate RTT latency for recursive servers accounting for the majority of client traffic. If every query were TCP, we could determine the latency of each query and achieve 100% coverage. However, most DNS queries are sent over UDP.

We analyze one week of traffic (October 15-22, 2019) for two .nl authoritative services, each configured to use IP anycast. The data shows that .nl handles about 10.9 billion queries from about 2 million resolvers spanning 42,000 ASes. We find that there is sufficient TCP DNS traffic to provide good operational coverage, especially for IPv6, and excellent temporal coverage, enabling near-real-time evaluation of DNS latency from real clients.