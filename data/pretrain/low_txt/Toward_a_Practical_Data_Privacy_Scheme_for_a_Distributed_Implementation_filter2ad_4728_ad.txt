### Security and Privacy in Distributed Computation

In the context of our discussion, the security measures employed by some existing methods are more stringent than necessary. These methods assume that the details of the function \( f \) remain hidden from the data owner. However, such methods, including those requiring interaction [8, 9, 36], involve a level of server-participant interaction that is impractical for volunteer distributed computations. Sander, Young, and Yung [31] developed a non-interactive protocol called Symmetrically-secure CryptoComputing (SYC), which provides a variant of secure circuit evaluation. This protocol hides the input \( x \) and reveals only a bound on the depth of the circuit \( f \). However, SYC is limited to log-depth circuits, making it unsuitable for our context.

Rivest, Adleman, and Dertouzos [29] formally introduced the concept of privacy homomorphisms, which theoretically allow computing with encrypted functions. They concluded that these homomorphisms have inherent limitations, as comparisons cannot be included in the set of operations without creating vulnerabilities to ciphertext-only attacks. They also raised the open question of whether highly secure privacy homomorphisms that use large sets of operations exist. Ahituv, Lapid, and Neumann [5] demonstrated that if a privacy homomorphism allows the addition operation, it becomes insecure under chosen plaintext attacks. Brickell and Yacobi [12] introduced R-additive privacy homomorphisms, which are secure under addition but impose constraints on the number of ciphertexts that can be added.

In general, finding secure privacy homomorphisms that preserve more than one operation is challenging. An exception is the homomorphism developed by Ferrer [15], which preserves addition and multiplication while resisting known plaintext attacks. Although elegant, these homomorphisms have too limited an operation set to be practical for volunteer distributed computations.

### Multiparty Function Computation

The problem of multiparty function computation involves players \( P_i \) (where \( 1 \leq i \leq n \)) with private inputs \( x_i \) who wish to evaluate a function \( f(x_1, \ldots, x_n) \) without revealing more information about the \( x_i \) than is implicitly contained in the output value. Yao [38] introduced this problem and developed a protocol for the two-player case. Goldreich, Micali, and Wigderson [20] extended this result to multiple parties, developing a protocol that leaks no input information provided a majority of the players are honest. Both results are based on the cryptographic approach, which assumes the intractability of certain functions. Results based on the information-theoretic approach, which does not assume limits on processor computation power, include the work of Ben-Or, Goldwasser, and Wigderson [10], who presented a protocol that achieves a tight bound on the size of the group of colluding players that can disrupt the computation. Chaum, Crépeau, and Damgard [14] showed that any "reasonable" multiparty protocol can be achieved if at least 2/3 of the players are honest. Goldreich [19] provides a survey of results in this area. As with the secure circuit evaluation work, these protocols have communication and computation complexities that preclude their use in the current context.

### Conclusions

Through a specific application, we have introduced a strategy for enhancing data privacy in some distributed volunteer computations. The strategy leverages the observation that the requirements for computing with obscured data can be less restrictive in certain volunteer computations due to the filtering nature of these computations. Specifically, because the goal is to identify important data rather than the output associated with this data, there can be considerable flexibility in task procedure definitions. This flexibility can be used to provide data privacy by allowing transformations to data and procedures that retain sufficient information for filtering while obscuring data details to make identification difficult or impossible.

We illustrated the potential of this strategy by describing a scheme for enhancing data privacy in the Smith-Waterman local sequence comparison algorithm. Our modifications provide reasonable, though not rigorously provable, data privacy while preserving sufficient information for distinguishing well-matching sequences. By presenting a practical, important, and non-trivial real-world application that requires privacy and is efficiently parallelizable, we have begun to populate a potential benchmark suite of applications for privacy study.

### Acknowledgments

We would like to thank biologists Rafael De Sa, Laura Runyen-Janecky, and Joe Gindhart from the University of Richmond for their patient and thorough treatment of our questions. We also thank the anonymous reviewers and Tadayoshi Kohno for many valuable comments that helped improve this paper.

### References

[1] M. Abadi and J. Feigenbaum. Secure circuit evaluation: A protocol based on hiding information from an oracle. Journal of Cryptology, 2(1):1–12, 1990.
[2] M. Abadi, J. Feigenbaum, and J. Kilian. On hiding information from an oracle. In Proceedings of the 19th ACM Symposium on the Theory of Computing, pages 195–203, 1987.
[3] M. Abadi, J. Feigenbaum, and J. Kilian. On hiding information from an oracle. Journal of Computer and System Sciences, 39(1):21–50, August 1989.
[4] M. Abdalla, M. Bellare, D. Catalano, E. Kiltz, T. Kohno, T. Lange, J. Malone-Lee, G. Neven, P. Paillier, and H. Shi. Searchable encryption revisited: Consistency properties, relation to anonymous IBE, and extensions. Cryptology ePrint Archive, Report 2005/254, 2005. http://eprint.iacr.org/.
[5] N. Ahituv, Y. Lapid, and S. Neumann. Processing encrypted data. Commun. ACM, 30(9):777–780, 1987.
[6] M. Ajtai and C. Dwork. A public-key cryptosystem with worst-case/average-case equivalence. In Proceedings of the 29th Annual ACM Symposium on Theory of Computing, pages 284–293, El Paso, Texas, May 1997.
[7] S. Altschul and W. Gish. Local alignment statistics. Methods Enzymol, 266:460–480, 1996.
[8] J. Bar-Ilan and D. Beaver. Non-cryptographic fault-tolerant computing in a constant number of rounds of interaction. In Proceedings of 8th ACM SIGACT-SIGOPS Symposium on Principles of Distributed Computing, pages 201–209, 1989.
[9] D. Beaver, S. Micali, and P. Rogaway. The round complexity of secure protocols. In Proceedings of the Twenty-second Annual ACM Symposium on Theory of Computing, pages 503–513. ACM Press, 1990.
[10] M. Ben-Or and A. Wigderson. Completeness theorems for non-cryptographic fault-tolerant distributed computation. In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, pages 1–10, 1988.
[11] M. Bishop. Computer Security: Art and Science. Addison-Wesley, 2003.
[12] E. Brickell and Y. Yacobi. On privacy homomorphisms (extended abstract). In D. Chaum and W. Price, editors, Advances in Cryptology—EUROCRYPT ‘87, volume 304 of Lecture Notes in Computer Science, pages 117–126, Berlin, 1987. Springer-Verlag.
[13] E. Chargaff. Structure and function of nucleic acids as cell constituents. Fed. Proc, 10:654–659, 1951.
[14] D. Chaum, C. Crépeau, and I. Damgard. Multiparty unconditionally secure protocols. In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, pages 11–19, 1988.
[15] J. Domingo-Ferrer. A new privacy homomorphism and applications. Information Processing Letters, 60(5):277–282, December 1996.
[16] C. Dwork, M. Naor, and O. Reingold. Immunizing encryption schemes from decryption errors. In C. Cachin and J. Camenisch, editors, Advances in Cryptology – EUROCRYPT 2004, volume 3027 of Lecture Notes in Computer Science, pages 342–360, Interlaken, Switzerland, May 2004. Springer-Verlag.
[17] J. Feigenbaum. Encrypted problem instances, or... Can you take advantage of someone without having to trust him? In Proceedings of Crypto’ 85, pages 477–488. Springer-Verlag, 1986.
[18] Genbank. http://www.ncbi.nlm.nih.gov/GenBank/GenBankOverview.html.
[19] O. Goldreich. Secure multi-party computation. Working Draft, 2000.
[20] O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game. In Proceedings of the Nineteenth Annual ACM Conference on Theory of Computing, pages 218–229, 1987.
[21] P. Golle and I. Mironov. Uncheatable distributed computations. In Proceedings of the RSA Conference 2001, Cryptographers’ Track, pages 425–441, San Francisco, CA, 2001. Springer.
[22] P. Golle and S. Stubblebine. Secure distributed computing in a commercial environment. In P. Syverson, editor, Proc. of Financial Crypto 2001, volume 2339 of Lecture Notes in Computer Science, pages 289–304. Springer-Verlag, 2001.
[23] S. Karlin and S. Altschul. Methods for assessing the statistical significance of molecular sequence features by using general scoring schemes. Proceedings of the National Academy of Sciences (USA), 87:2264–2268, March 1990.
[24] S. Karlin and S. Altschul. Applications and statistics for multiple high-scoring segments in molecular sequences. Proceedings of the National Academy of Sciences (USA), 90:5873–5877, June 1993.
[25] F. Monrose, P. Wyckoff, and A. Rubin. Distributed execution with remote audit. In Proceedings of the 1999 ISOC Network and Distributed System Security Symposium, pages 103–113, 1999.
[26] S. Needleman and C. Wunsch. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of Molecular Biology, 48:443–453, 1970.
[27] W. Pearson. Empirical statistical estimates for sequence similarity searches. Journal of Molecular Biology, 276:71–84, 1998.
[28] T. Phan, L. Huang, and C. Dulan. Challenge: Integrating mobile wireless devices into the computational grid. In Proceedings of the Eight International Conference on Mobile Computing and Networking (MobiCom 2002), pages 271–278, Atlanta, GA, September 2002.
[29] R. Rivest, L. Adleman, and M. Dertouzos. On data banks and privacy homomorphisms. In R. D. Millo, D. Dobkin, A. Jones, and R. Lipton, editors, Foundations of Secure Computation, pages 169–179. Academic Press, New York, 1978.
[30] R. D. Sa, L. Runyen-Janecky, and J. Gindhart, July 2005. Personal conversations.
[31] T. Sander, A. Young, and M. Yung. Non-interactive crypto-computing for NC1. In IEEE Symposium on Foundations of Computer Science, pages 554–567, 1999.
[32] L. Sarmenta. Sabotage-tolerance mechanisms for volunteer computing systems. Future Generation Computer Systems, 18(4):561–572, March 2002.
[33] T. Smith and M. Waterman. Identification of common molecular subsequences. Journal of Molecular Biology, 147:195–197, 1981.
[34] D. Szajda, B. Lawson, and J. Owen. Hardening functions for large-scale distributed computations. In Proceedings of the 2003 IEEE Symposium on Security and Privacy, pages 216–224, Berkeley, CA, May 2003.
[35] D. Szajda, B. Lawson, and J. Owen. Toward an optimal redundancy strategy for distributed computations. In Proceedings of the 2005 IEEE International Conference on Cluster Computing (Cluster 2005), Boston, MA, September 2005.
[36] S. Tate and K. Xu. On garbled circuits and constant round secure function evaluation. Technical Report TR 2003-02, University of North Texas, Computer Privacy and Security (CoPS) Lab, 2003.
[37] M. Waterman. Introduction to Computational Biology: Maps, Sequences, and Genomes. Chapman & Hall, 1995.
[38] A. Yao. How to generate and exchange secrets. In Proceedings of the 27th Annual Symposium on Foundations of Computer Science, pages 162–167, Toronto, Canada, October 1986.

### Appendix A: Sequence Comparison Algorithm Details

The details of the Smith-Waterman global sequence alignment algorithm follow. For simplicity of notation, we assume that length \( n \) sequences begin at index 1 and end at index \( n \). Recall that \( S \) denotes the similarity score of a sequence pair, \( s \) denotes the similarity function for symbols, and \( g \) denotes the gap penalty.

**Theorem** [37]. If \( U = u_1u_2 \ldots u_n \) and \( V = v_1v_2 \ldots v_m \), define
\[ S_{i,j} = S(u_1u_2 \ldots u_i, v_1v_2 \ldots v_j). \]
Also, set
\[ S_{0,0} = 0, \quad S_{0,j} = \sum_{k=1}^j g(v_k), \quad \text{and} \quad S_{i,0} = \sum_{k=1}^i g(u_k). \]
Then
\[ S_{i,j} = \max\{S_{i-1,j} + g(u_i), S_{i-1,j-1} + s(u_i, v_j), S_{i,j-1} + g(v_j)\}. \]

Proving the validity of the dynamic programming approach in this context is straightforward. One need only observe that an alignment ending with indices \( i \) and \( j \) must end with one of the choices below:
- \( \ldots u_i \)
- \( \ldots - \)
- \( \ldots u_i \)
- \( \ldots v_j \)
- \( \ldots - \)
- \( \ldots v_j \)

Thus, the best alignment ending with indices \( i \) and \( j \) must be the best alignment ending with indices \( i \) and \( j-1 \) plus the gap penalty, or the best alignment ending with indices \( i-1 \) and \( j-1 \) plus \( s(u_i, v_j) \), or the best alignment ending with indices \( i-1 \) and \( j \) plus the gap penalty.

For local sequence comparison, define for the \( (i, j) \) pair the function \( H \) by
\[ H_{i,j} = \max\{0; S(u_xu_{x+1} \ldots u_i, v_yv_{y+1} \ldots v_j) : 1 \leq x \leq i, 1 \leq y \leq j\}. \]
Then \( H \) can be computed using the following two results from [37].

**Theorem**. Assume that the gap function \( g \) is a function of gap length. Set \( H_{0,0} = 0 \), and set \( H_{i,0} = H_{0,j} = 0 \) for \( 1 \leq i \leq n \) and \( 1 \leq j \leq m \). Then
\[ H_{i,j} = \max\left\{0, \max_{1 \leq k \leq i}\{H_{i-k,j} - g(k)\}, H_{i-1,j-1} + s(u_i, v_j), \max_{1 \leq l \leq j}\{H_{i,j-l} - g(l)\}\right\}. \]

The proof is similar to that of the global alignment algorithm.

Finally, we have the following:

**Corollary**.
\[ H(U, V) = \max\{H_{k,l} : 1 \leq k \leq n, 1 \leq l \leq m\}. \]

### Appendix B: Entropy Calculation

Given that the adversary has determined the location of all instances of a single nucleotide, we can measure conditional entropy. Assume that our original sequence \( U \) has length \( N \), and that the adversary has been provided with \( F(U, \delta) \) for some fixed literal \( \delta \in \Sigma \). There are \( 4^N \) possible length \( N \) sequences over \( \Sigma \), and we may assume that these are enumerated such that each has a unique integer index in the range 1 to \( 4^N \) inclusive. That is, all possible length \( N \) sequences over \( \Sigma \) occur exactly once among the set \( S = \{S_1, S_2, \ldots, S_{4^N}\} \). Let \( X \) be the random variable that has a uniform distribution over \( S \). (Technically, \( X \) is the random variable that has a uniform distribution over the set of integers between 1 and \( 4^N \) inclusive.) The entropy \( H(X) \) of \( X \) is easily shown to be \( 2N \), which is expected since each nucleotide contains two bits of uncertainty.

Now let us consider the conditional entropy \( H(X|Y) \) of \( X \) given that the adversary has received offset sequence \( Y = F(U, \delta) \). Let \( C_\delta \) denote the number of occurrences of literal \( \delta \) in \( U \). Then
\[ H(X|Y) = \sum_{i=1}^{4^N} -P(X = S_i | Y = F(U, \delta)) \log(P(X = S_i | Y = F(U, \delta))). \]

Since the positions of literal \( \delta \) are revealed by \( F(U, \delta) \), and \( \delta \) is known to the adversary, there are \( 3^N - C_\delta \) sequences in \( S \) that could be the preimage of \( U \). Let \( k_1, k_2, \ldots, k_{3^N - C_\delta} \) be the indices (over the set \( S \) of these possible preimages). Thus,
\[ H(X|Y) = \sum_{i=1}^{3^N - C_\delta} -P(X = S_{k_i} | Y = F(U, \delta)) \log(P(X = S_{k_i} | Y = F(U, \delta))) = -(3^N - C_\delta) \log\left(\frac{1}{3^N - C_\delta}\right) = (N - C_\delta) \log 3. \]

This calculation shows the reduction in entropy when the adversary has partial information about the sequence.