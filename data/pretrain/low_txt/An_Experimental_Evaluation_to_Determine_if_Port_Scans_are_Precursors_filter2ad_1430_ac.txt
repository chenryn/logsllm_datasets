# Port Scans, Vulnerability Scans, and Attacks

## Summary of Collected Data
- **Total Records:**
  - Port Scans: 9,660
  - Vulnerability Scans: 8,432
  - Attacks: 2,583
  - Total: 22,710
- **Unique Records:**
  - Port Scans: 3,007
  - Vulnerability Scans: 779
  - Attacks: 1,657
  - Total: 6,203

### Figure 7. Distribution of Scans Leading to an Attack

## 6.3 Distribution of Port Scan Types
To better analyze the collected port scans, we characterized them based on common practices [27, 28] and the design of network port scanners like Nmap [29]. We propose a state machine model (Figure 8) to classify port scans into five categories (Figure 9).

### Figure 8. Representation of Port Scans
- **Scan Type:**
  - Full Open
  - Half Open
  - Full Reverse
  - Half Reverse
  - Incomplete
- **Connection Termination State:**
  - Full Open: State 4
  - Half Open: State 5
  - Full Reverse: State 6
  - Half Reverse: State 3
  - Incomplete: State 2

### Figure 9. Classification of Port Scans

We developed Perl scripts to parse the collected malicious activity. These scripts detected the five types of scans and also identified a special case where six packets were used, which was actually a half reverse scan performed three times. This issue was previously mentioned in Section 5.2 when analyzing vulnerability scans provided by Nessus.

### Figure 10. Distribution of Port Scans
- **Scan Type:**
  - Full Open: 10 (0.12%)
  - Half Open: 355 (4.38%)
  - Full Reverse: 6 (0.07%)
  - Half Reverse: 7,667 (94.66%)
  - Incomplete: 7 (0.07%)
- **Total:**
  - 8,100 (96.1% of 8,432 collected port scans)

## 7. Experimental Results
We identified ICMP scans, port scans, vulnerability scans, and attacks in the collected traffic. The next step was to analyze the correlation between these scans and attacks.

### 7.1 Scans Followed by Attacks
For each scan and combination of scans from a specific source IP address, we checked if an attack followed. The results are presented in Figure 11.

### Figure 11. Distribution of Scans Leading to an Attack
- **Type of Scan:**
  - Port: 694 (4.03%)
  - ICMP: 2,797 (0.04%)
  - Vulnerability: 1,399 (21.16%)
  - Port & ICMP: 11 (0%)
  - Port & Vulnerability: 59 (71.19%)
  - ICMP & Vulnerability: 184 (2.72%)
  - Port & ICMP & Vulnerability: 15 (46.67%)

### 7.2 Attacks Preceded by Scans
For each of the 760 attacks, we checked if any scan or combination of scans preceded the attack. The results are presented in Figure 12.

### Figure 12. Distribution of Scans Preceding an Attack
- **Type of Scan:**
  - Port: 28 (3.68%)
  - ICMP: 1 (0.13%)
  - Vulnerability: 296 (38.95%)
  - Port & ICMP: 0 (0%)
  - Port & Vulnerability: 42 (5.53%)
  - ICMP & Vulnerability: 5 (0.66%)
  - Port & ICMP & Vulnerability: 7 (0.92%)
  - None: 381 (50.13%)

## 8. Conclusions
To evaluate the security of a computing system, it is essential to identify system weaknesses and assess the threat. This paper focused on the correlation between scans and attacks to determine if a scan can be used as a signal that an attack might follow.

### Key Findings:
- Over 50% of the attacks were not preceded by a scan.
- Among the scans leading more frequently to an attack were vulnerability scans and combinations of port and vulnerability scans.
- Port scans combined with vulnerability scans might be a relevant indicator of a coming attack.
- Only port scans did not appear to be a good indicator of a future attack.

### Future Work:
This experiment provides a first step in answering whether port scans are a good indicator of a future attack. Future work could include a longer data collection period, target computers deployed in different locations, and varying sets of vulnerabilities.

## Acknowledgments
The authors thank The Institute for Systems Research and the Office for Information Technology for their support in implementing a test-bed for collecting attack data at the University of Maryland. Special thanks to Michael Wilson, Gerry Sneeringer, Melvin Fields, and Dylan Hazelwood for their contributions.

## References
[1] U.S. Department of Defense Standard, "Department of Defense Trusted Computer System Evaluation Criteria" ("Orange Book"), DOD 5200.28-STD, Dec. 1985.
[2] ISO/IEC International Standards (IS) 15408-1:1999, 15408-2:1999, and 15408-3:1999, "Common Criteria for Information Technology Security Evaluation."
[3] C. Landwehr, "Formal Models for Computer Security," Computer Surveys, vol.13, no.3, Sept. 1981.
[4] J. Lowry, "An initial foray into understanding adversary planning and courses of action," in Proc. DARPA Information Survivability Conference and Exposition II, DISCEX’01, p. 123-33, 2001.
[5] K. Goseva-Popstojanova et al., "Characterizing Intrusion Tolerant Systems Using A State Transition Model," in Proc. DARPA Information Survivability Conference and Exposition II, DISCEX’01, 2001.
[6] S. Jha and J. M. Wing, "Survivability Analysis of Networked Systems," in Proc. of the 23rd International Conference on Software Engineering (ICSE 2001), pp. 307-317, 2001.
[7] R. Ortalo, Y. Deswarte, and M. Kaaniche, "Experimenting with quantitative evaluation tools for monitoring operational security," IEEE Transactions on Software Engineering, vol.25, no.5, p. 633-50, Sept.-Oct. 1999.
[8] RFC 793: Transmission Control Protocol, http://www.faqs.org/rfcs/rfc793.html
[9] Snort, http://www.snort.org/
[10] Bro-IDS, http://bro-ids.org/
[11] L.T. Heberlein et al., "A network security monitor," in Proc. Symposium on Research in Security and Privacy, pp. 296-304, 1990.
[12] S. Staniford-Chen et al., "GrIDS: A Graph-Based Intrusion Detection System for Large Networks," in Proc. 19th National Information Systems Security Conference, 1996.
[13] Emerald, http://www.sdl.sri.com/projects/emerald/
[14] L. Ertoz et al., "Scan Detection – Revisited," AHPCRC Technical Report 2004-127.
[15] C. B. Lee et al., "Detection and Characterization of Port Scan Attacks," http://www.cs.ucsd.edu/users/clbailey/PortScans.pdf
[16] R. Pan et al., "Characteristics of Internet Background Radiation," in Proc. ACM SIGCOMM’04, 2004.
[17] L. Spitzner, "Honeypots: Tracking Hackers," Addison-Wesley, 2002.
[18] The Honeynet Project, "Know Your Enemy," Addison-Wesley, 2002.
[19] Sebek, http://www.honeynet.org/tools/sebek/
[20] Ethereal, http://www.ethereal.com/
[21] Swatch, http://swatch.sourceforge.net/
[22] Symantec, http://www.symantec.com/
[23] Nmap, http://www.insecure.org/nmap/
[24] Newt, http://www.tenablesecurity.com/newt.html
[25] Nessus, http://www.nessus.org/
[26] Nettime, http://sourceforge.net/projects/nettime
[27] S. McClure, J. Scambray, and G. Kurtz, "Hacking Exposed: Network Security Secrets & Solutions," McGraw-Hill, 1999.
[28] J. Chirillo, "Hack Attacks Revealed: A Complete Reference for UNIX, Windows, and Linux with Custom Security Toolkit," Wiley, Second Edition, 2002.
[29] M. Wolfgang, "Host Discovery with nmap," 2002, http://www.net-security.org/dl/articles/discovery.pdf

---

**Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05)  
0-7695-2282-3/05 $20.00 © 2005 IEEE  
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:49 UTC from IEEE Xplore. Restrictions apply.**