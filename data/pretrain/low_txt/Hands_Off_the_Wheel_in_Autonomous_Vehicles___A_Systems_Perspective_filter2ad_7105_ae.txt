### 4.69
### 31.19
### 902.34
### 0.0398
### 0.0442
### 0.293
### 8.502
### Waymo
### Delphi
### Nissan
### GMCruise

**APMi (Accidents per Mission for an Autonomous Vehicle)**
- **Airline APM**: 9.8 × 10⁻⁵
- **Surgical Robot (SR) APM**: 1.04 × 10⁻²

Our analysis indicates that autonomous vehicles (AVs) perform surprisingly well on a per-mission basis. When compared to airplanes, which employ sophisticated resilience models and techniques, AVs are only 4.22 times worse. Additionally, AVs outperform surgical robots by a factor of 2.5 (see Table VIII).

However, if all cars are replaced by AVs in the future, the number of trips made by AVs will be approximately 96 billion per year [44], compared to 9.6 million trips for airlines. This means that AVs will make 10,000 times more trips than airlines, leading to a higher annual number of accidents. Furthermore, the average mission length in terms of time and distance covered is significantly different for airplanes and AVs. Therefore, a comprehensive comparison across these systems should consider operational time per mission and account for competing failures during concurrent deployments.

### 2. Traditional Reliability Metrics

While we have provided an approximate comparison, a more traditional and accurate method for comparing the resilience of AVs with that of airplanes (which are also highly automated systems) is through operational hours to failure. However, this metric is not available for cars due to the lack of information about idle time or its distribution. We propose an alternative metric based on the number of miles driven to disengagement/accident, which can be consistently applied across transportation systems.

To directly obtain this measure, there needs to be a minor change in data collection by the Department of Motor Vehicles (DMV): manufacturers and the DMV should collect data on the miles between disengagements per vehicle to enable the computation of the metrics.

### VI. Threats to Validity

An empirical study like ours is subject to variability arising from heterogeneous data collection systems, such as the inclusion or exclusion of data points, or the disparate information content across data formats. This can hamper the ability to draw generalized conclusions. Such issues are common in system reliability assessment, and we assert the need for replication studies to verify our conclusions across other datasets. Below, we discuss potential threats to validity specific to our study.

- **Construct Validity**: Ensures that the variables associated with the study are measured correctly, i.e., that the measurements are constructed in accordance with the theoretical foundations of the area. We have discussed construct validity in Section V-C2.
  
- **Internal Validity**: Implies that there are no systematic errors and biases. We studied datasets from 12 different manufacturers and reported only generalized trends to eliminate any biases and micro-observations (observations with low statistical significance) that might be artifacts of poor logging or biased reporting by the manufacturers. For example:
  - **Data Underreporting**: Companies are legally required to report all disengagements and accidents related to technology failures and safe operation. The interpretation of "safe" operation and technology "failure" can vary, leading to underreporting. Regulatory oversight and enforcement are difficult, further contributing to underreporting.
  - **Not All Miles Are Equivalent**: One manufacturer may test their AVs in more challenging environments than others, such as at night or during bad weather. Not all manufacturers report environmental conditions during tests. Where available, we report the testing conditions and disengagements caused by environmental factors (see “Environment” in Fig. 6).
  - **Validity of Fault Tags and Failure Categories**: There is no consistent data format for disengagement/accident reports across manufacturers. Our natural language processing (NLP) framework for tagging and categorization may lead to systematic errors. Therefore, the dictionaries were manually verified by the authors to ensure correctness. Data points with uncertain tags and categories were explicitly labeled as "Unknown-T/C."

- **External Validity**: Concerns the extent to which a study can be generalized to other systems or datasets. To our knowledge, the California DMV dataset is the only publicly available dataset pertaining to AV failures. Until we work with manufacturers on proprietary data (which may not be disclosed publicly), we cannot comment on the general external validity of the techniques presented here.

### VII. Related Work

The majority of prior research into AV systems has focused on the functionality of vehicle guidance systems. Numerous demonstrations of end-to-end computing systems for autonomous vehicles have been conducted (e.g., [2]–[7], [45], [46]). The currently accepted practice for vehicular safety, based on the ISO 26262 safety standard [47], is to consider human drivers as ultimately responsible for safety. This forms the basis for most AV testing programs on public roads, which require a safety driver to monitor the vehicle and intervene in case of a system failure. Safety considerations for AVs include:
1. The AV's ability to alert the driver in case of failure.
2. The driver's ability to recognize the capabilities and limits of the AV.
3. The AV's ability to anticipate the behavior of other road users who may not always conform to the rules.
4. Other road users' ability to anticipate the behavior of the AV [48], [49].

Safety is also emphasized in several publications, including [51], [52]. Waymo has published a report on the safety precautions considered for their AVs [25]. [36] provides a model to estimate the number of miles AVs must be driven to demonstrate their reliability with statistical confidence. [30], [34] provide summary statistics (e.g., driver reaction times and AV speed in accident scenarios) from tabulated data in the DMV dataset. Our approach uses an STPA-based ontology and NLP techniques to parse a significant amount of unstructured data presented as natural text.

[19] uses fault injection to evaluate the fault tolerance of deep neural networks (DNNs), which are primarily used in the sensor fusion and environmental information processing step shown in Fig. 3. They analyze DNN results and propose techniques to safeguard DNNs from single-event upsets. In contrast, we present an analysis of the entire control system of the AV, of which DNNs are a small part.

Other related work has focused on the legal and regulatory barriers for AV deployment and implementation (e.g., [10], [11], [12]–[15]). Security and privacy measures to encompass system-level attacks and failures of AVs have also been studied [53], [54].

### VIII. Conclusions and Future Work

A steady march toward the use of AVs is clearly underway. The reliability and safety challenges of fully-autonomous vehicles (Level 4 & 5, currently under development) and today’s semi-AVs are significant and often underestimated. We draw the following conclusions to frame our future research and draw the attention of other reliability researchers:
- There is ongoing research on the verification and validation of the safety properties of individual system components (e.g., control, communication, and mechanical system components) using the STAMP framework [51]. However, our study shows the need for rigorous theoretical models (like STPA models) for evaluating AV technologies.
- The machine learning systems responsible for perception and control need further research and assessment under fault conditions via stochastic modeling and fault injection to augment data collection.
- In reality, there is a strong possibility that both AVs and semi-AVs will co-exist with non-AVs (with human drivers completely in charge) within several years. Therefore, the urgency of joint study driven by data and models needs to be emphasized.

### Acknowledgments

This material is based upon work supported by an IBM Faculty Award and the National Science Foundation (NSF) under Grant Nos. CNS 13-14891 and CNS 15-45069. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF. We thank K. Atchley, J. Applequist, W. S. B. M. Lim, and A. P. Athreya for their help in preparing the manuscript.

For their trained drivers, Waymo claimed there was one accident for every 2.3 million miles; however, we cannot substantiate this claim.

### References

[1] M. Gerla et al., “Internet of vehicles: From intelligent grid to autonomous cars and vehicular clouds,” in 2014 IEEE World Forum on Internet of Things (WF-IoT), Mar 2014, pp. 241–246.
[2] U. Ozguner, C. Stiller, and K. Redmill, “Systems for safety and autonomous behavior in cars: The DARPA grand challenge experience,” Proc. of the IEEE, vol. 95, no. 2, pp. 397–412, Feb 2007.
[3] “Special issue on the 2007 DARPA Urban Challenge, Part I,” J. Field Robot., vol. 25, no. 8, Aug 2008.
[4] C. Urmson et al., “Autonomous driving in urban environments: Boss and the urban challenge,” J. Field Robotics, vol. 25, no. 8, pp. 425–466, 2008.
[5] A. Chatham, “Google’s self-driving cars—the technology, capabilities, and challenges,” in 2013 Embedded Linux Conf., Feb, 2013, pp. 20–24.
[6] C. Urmson, “Realizing self-driving vehicles,” in 2012 IEEE Intelligent Vehicles Symposium (IV). Alcalá de Henares, Spain, 2012.
[7] B. Paden et al., “A survey of motion planning and control techniques for self-driving urban vehicles,” IEEE Trans. Intelligent Vehicles, vol. 1, no. 1, pp. 33–55, Mar 2016.
[8] W. Payre, J. Cestac, and P. Delhomme, “Intention to use a fully automated car: Attitudes and a priori acceptability,” Transportation Research Part F: Traffic Psychology and Behaviour, vol. 27, pp. 252–263, Nov 2014.
[9] S. Shladover, D. Su, and X.-Y. Lu, “Impacts of cooperative adaptive cruise control on freeway traffic flow,” Transportation Research Record: J. the Transportation Research Board, vol. 2324, pp. 63–70, Dec 2012.
[10] G. E. Marchant and R. A. Lindor, “The coming collision between autonomous vehicles and the liability system,” Santa Clara L. Rev., vol. 52, p. 1321, 2012.
[11] M. Parent et al., “Legal issues and certification of the fully automated vehicles: best practices and lessons learned,” CityMobil2 Rep., 2013.
[12] J. M. Anderson et al., “Autonomous vehicle technology: A guide for policymakers,” RAND Corp., Tech. Rep. RR-443-2-RC, 2016.
[13] D. J. Fagnant and K. Kockelman, “Preparing a nation for autonomous vehicles: opportunities, barriers and policy recommendations,” Transportation Research Part A: Policy and Practice, vol. 77, pp. 167–181, Jul 2015.
[14] L. Fraade-Blanar and N. Kalra, “Autonomous vehicles and federal safety standards: An exemption to the rule?” RAND Corp., Tech. Rep. PE-258-RC, 2017.
[15] D. G. Groves and N. Kalra, “Enemy of good,” RAND Corp., Tech. Rep. RR-2150-RC, 2017.
[16] California Department of Motor Vehicles, “Testing of autonomous vehicles,” https://www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/testing, Accessed: 2017-11-27.
[17] C. Chen et al., “Deepdriving: Learning affordance for direct perception in autonomous driving,” in Proc. IEEE International Conf. Computer Vision, 2015, pp. 2722–2730.
[18] S. Petti and T. Fraichard, “Safe motion planning in dynamic environments,” in 2005 IEEE/RSJ International Conf. Intelligent Robots and Systems, Aug 2005, pp. 2210–2215.
[19] G. Li et al., “Understanding Error Propagation in Deep Learning Neural Network (DNN) Accelerators and Applications,” in Proc. International Conf. for High Performance Computing, Networking, Storage and Analysis, 2017, pp. 8:1–8:12.
[20] NVIDIA, “Introducing Xavier, the NVIDIA AI Supercomputer for the Future of Autonomous Transportation,” https://blogs.nvidia.com/blog/2016/09/28/xavier, Accessed: 2017-11-27.
[21] SAE International, Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles, Sep 2016.
[22] F. Mujica, “Scalable electronics driving autonomous vehicle technologies,” Texas Instruments White Paper, 2014.
[23] N. Leveson, Engineering a safer world: Systems thinking applied to safety. MIT press, 2011.
[24] A. Abdulkhaleq et al., “A Systematic Approach Based on STPA for Developing a Dependable Architecture for Fully Automated Driving Vehicles,” Procedia Engineering, vol. 179, pp. 41–51, 2017.
[25] Waymo Safety Report, “On the Road to Fully Self-Driving,” https://assets.documentcloud.org/documents/4107762/Waymo-Safety-Report-2017.pdf, Accessed: 2017-11-27.
[26] N. H. Amer et al., “Modelling and control strategies in path tracking control for autonomous ground vehicles: a review of state of the art and challenges,” J. Intelligent & Robotic Systems, vol. 86, no. 2, pp. 225–254, 2017.
[27] A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous driving? The Kitti Vision Benchmark Suite,” in 2012 IEEE Conf. Computer Vision and Pattern Recognition (CVPR), pp. 3354–3361.
[28] California Department of Motor Vehicles, “Deployment of autonomous vehicles for public operation,” https://www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/auto, Accessed: 2017-11-27.
[29] F. M. Favaró et al., “Examining accident reports involving autonomous vehicles in California,” PLoS one, vol. 12, no. 9, p. e0184952, 2017.
[30] F. Favaró, S. Eurich, and N. Nader, “Autonomous vehicles’ disengagements: Trends, triggers, and regulatory limitations,” Accident Analysis & Prevention, vol. 110, pp. 136–148, 2018.
[31] R. Smith, “An Overview of the Tesseract OCR Engine,” in Ninth International Conf. Document Analysis and Recognition, vol. 2, Sep 2007, pp. 629–633.
[32] H. Alemzadeh, “Data-driven resiliency assessment of medical cyber-physical systems,” Ph.D. dissertation, University of Illinois at Urbana-Champaign, 2016.
[33] A. Avizienis et al., “Basic concepts and taxonomy of dependable and secure computing,” IEEE Trans. Dependable Secur. Comput., vol. 1, no. 1, pp. 11–33, Jan. 2004.
[34] V. V. Dixit, S. Chand, and D. J. Nair, “Autonomous vehicles: disengagements, accidents and reaction times,” PLoS one, vol. 11, no. 12, p. e0168054, 2016.
[35] D. B. Fambro, Determination of stopping sight distances (Report / National Cooperative Highway Research Program). National Academy Press, 1997.
[36] N. Kalra and S. M. Paddock, “Driving to safety: How many miles of driving would it take to demonstrate autonomous vehicle reliability?” Transportation Research Part A: Policy and Practice, vol. 94, pp. 182–193, 2016.
[37] National Highway Traffic Safety Administration (NHTSA), “2015 motor vehicle crashes: overview DOT HS 812 318,” Traffic Safety Facts Research Note, pp. 1–9, 2016.
[38] Federal Highway Administration (FHWA), “Traffic volume trends.” https://www.fhwa.dot.gov/policyinformation/travel_monitoring/tvt.cfm, Accessed: 2017-11-27.
[39] FAA, “System design and analysis,” Tech. Rep. AC 25.1309-1A, Jun 1988.
[40] H. Alemzadeh et al., “Adverse events in robotic surgery: a retrospective study of 14 years of FDA data,” PLoS One, vol. 11, no. 4, p. e0151470, 2016.
[41] National Transportation Safety Board, “Aviation statistics: Review of accident data,” https://www.ntsb.gov/investigations/data/Pages/aviation_stats.aspx, Accessed: 2017-11-27.
[42] H. Alemzadeh et al., “Analysis of safety-critical computer failures in medical devices,” IEEE Security & Privacy, vol. 11, no. 4, pp. 14–26, Jul 2013.
[43] U.S. Department of Transportation, Federal Highway Administration, Office of Highway Policy Information, National Household Travel Survey., “Our nation’s highways: 2008,” https://www.fhwa.dot.gov/policyinformation/pubs/pl08021/index.cfm, Accessed: 2017-11-27.
[44] P. Plötz, N. Jakobsson, and F. Sprei, “On the distribution of individual daily driving distances,” Transportation Research Part B: Methodological, vol. 101, pp. 213–227, 2017.
[45] G. Stanek et al., “Junior 3: A test platform for advanced driver assistance systems,” in Intelligent Vehicles Symposium (IV), 2010 IEEE, 2010, pp. 143–149.
[46] J. Levinson et al., “Towards fully autonomous driving: Systems and algorithms,” in 2011 IEEE Intelligent Vehicles Symposium (IV), Jun 2011, pp. 163–168.
[47] “Road vehicles — Functional safety,” International Organization for Standardization, Geneva, CH, Standard, Nov. 2011.
[48] S. M. Casner, E. L. Hutchins, and D. Norman, “The challenges of partially automated driving,” Comm. of the ACM, vol. 59, no. 5, pp. 70–77, Apr 2016.
[49] A. Reschka, “Safety concept for autonomous vehicles,” in Autonomous Driving: Technical, Legal and Social Aspects, M. Maurer et al., Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2016, pp. 473–496.
[50] P. Koopman and M. Wagner, “Autonomous vehicle safety: An interdisciplinary challenge,” IEEE Intelligent Transportation Systems Magazine, vol. 9, no. 1, pp. 90–96, Spring 2017.
[51] N. Leveson, “A new accident model for engineering safer systems,” Safety science, vol. 42, no. 4, pp. 237–270, 2004.
[52] C. Fan et al., “DryVR: Data-Driven Verification and Compositional Reasoning for Automotive systems,” in Computer Aided Verification. Springer International Publishing, 2017, pp. 441–461.
[53] SAE International, Cybersecurity Guidebook for Cyber-Physical Vehicle Systems, Jan 2016.
[54] J. Joy and M. Gerla, “Privacy risks in vehicle grids and autonomous cars,” in Proc. of the 2nd ACM International Workshop on Smart, Autonomous, and Connected Vehicular Systems and Services, 2017, pp. 19–23.

---

This version of the text is more organized, clear, and professional. It maintains the original content while improving readability and coherence.