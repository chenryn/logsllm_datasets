### Profile
**Figure 5. The Distribution of AM Profiles of DHCP Clients for Two Runs Separated by Five Months**

The distribution of Active Mapping (AM) profiles for DHCP clients, as shown in Figure 5, was measured over two runs separated by five months. The significant spike in the graph corresponds to Windows machines that do not run any public services.

Among the 1,618 machines with fixed IP addresses, only 35 showed any difference in their AM profiles between the two runs. Although we did not have complete OS information for all these IPs for each run, our manual comparison where possible indicated that these differences were almost entirely due to OS upgrades. Thus, it does not appear that there is a considerable amount of turnover in this group.

### 5.3 Mapping Time

The times measured for mapping are dependent on the policies found. Since many tests' results are determined by the presence or absence of a response from the host within a certain time, some policies generate more timeouts than others. Most timeouts are on the order of 5–10 seconds; we found this interval to be sufficient to account for delays at the hosts and in the network.

Mapping a single host requires approximately 37 seconds. This minimum time is due to the fact that each of the mapping tests is repeated three times, and a single test requires two rounds of communication.

Wall-clock time increases sublinearly through 64 hosts, due to increased parallelism. For more than 64 hosts, however, times are likely to scale linearly since the mapper implements rate-limiting to avoid packet-buffer overflows. We were able to alleviate this problem in part by using larger-than-normal packet capture buffers. Indeed, mapping 101 hosts took 532 seconds, or 5.3 seconds per host; for 64 hosts, the time was 5.7 seconds per host, and for 16 hosts, it took 10.1 seconds per host.

The inefficiency of our prototype implementation resulted in these timing measurements.

### 5.5.1 Synthetic Tests

To test the correctness of the modified NIDS (its ability to disambiguate traffic correctly), we generated HTTP attack traffic to 8 hosts, with evasion measures added using Fragroute [So02] to modify traffic to 2 hosts. Fragroute automatically transformed the request stream to include overlapping and inconsistent IP fragments and TCP segments. The inconsistency favored one of two policies (in our parlance, a “first” policy and a “BSD” policy); the data not expected to be accepted were chosen randomly. For the two machines receiving modified traffic, we used Active Mapping profiles which would allow the traffic to be properly interpreted.

We found that the unmodified NIDS believed the HTTP request to be:
```
GET /msadcTpo6EGKEY./../..%bTMmzyQaL/system32/fipGNdDg++dir+c:
```
rather than the actual request URL:
```
GET /msadc/../../../../../../winnt/system32/cmd.exe?/c+dir+c:
```
It is clear that the unmodified NIDS, which had no way to properly resolve the ambiguous overlaps, chose the wrong data to use in reassembly. The modified NIDS performed reassembly correctly.

To measure the impact of Active Mapping on the NIDS’ performance in the presence of a relatively high proportion of ambiguous traffic, we used two traces of 500 connections to the 8 hosts. In the first, where none of the connections were modified by Fragroute, times were essentially identical over three trials. In the second, where connections to two of the machines were modified by Fragroute, the Active Mapping-enabled NIDS was actually about 15% faster, since it was able to discard more data. In practice, we expect this effect to be small, as it is only relevant when there are overlapping IP fragments or TCP segments, which are uncommon.

### 5.5.2 Real-world Tests

To get a picture of the performance impact on a larger, more realistic dataset, we used two real-world traces. The first was of a wide variety of non-HTTP traffic (mostly just SYN/FIN/RST packets, with the data filtered out) gathered by a one-hour capture at a busy site (100.2 MB data, 1.2 M packets, 273 K connections). The second was of two hours of HTTP traffic (with full data) at another site (137 MB, 197 K packets, 6,379 connections). In both cases, the results were the same: with Active Mapping on, execution time was essentially identical. Memory usage was approximately 200K higher with AM (specific profiles were used for about 4,800 hosts; a default one for the rest), a small fraction of the 68MB used overall.

We are currently working on deploying an Active Mapping-enabled NIDS operationally to gather more data on the impact of using AM profiles on performance and precision.

### 5.6 Conclusions and Recommendations

The test results suggest that mapping can be performed quite frequently. A full class C subnet can be scanned in about 20 minutes, so daily scans during off-peak times are certainly feasible. Importantly, with a steady-state rate of about 5 seconds per host (using our unoptimized prototype), it is feasible to completely remap even large sites—say, thousands of hosts—on a weekly basis during off-peak hours. Certain tests whose results we expect not to change often (e.g., those related to network topology) can be performed less frequently.

The mapping-induced traffic of about 19 KB per host mapped is quite low, and its impact during off-peak hours is likely to be negligible. Remapping can also be triggered by any inconsistency between the stored policy and an observed one. For example, if a host sends an ICMP Needs Fragmentation message for a packet smaller than the stored PMTU, then the host should be remapped. External information, such as OS fingerprint results, can be used to detect changes in the status of a machine as well.

On-the-fly mapping—mapping when the first packet to a host is seen—is probably not possible, because many tests take several seconds. In any case, host policy changes are most likely to be triggered by infrequent operating system upgrades. More frequent changes to the policy database are those initiated by DHCP. As we have noted, we can store policies by MAC address and simply update a table when the NIDS sees a DHCP request (or is informed of a new lease by the DHCP server itself). For new hosts—say, a laptop attached for the first time to the network—mapping can be performed in under one minute (mapping a single host takes on the order of 30 seconds). This period of uncertainty is unlikely to be problematic, since it is rare that DHCP clients export public services.

Runtime performance in the NIDS was not negatively affected by the addition of Active Mapping-based disambiguation. In fact, since using Active Mapping results allows the NIDS to discard additional packets, performance in some cases was actually improved. The additional memory footprint was approximately 100 bytes per host. We expect with all mappings implemented, it would be on the order of a few hundred bytes.

The modified NIDS was also capable of correctly interpreting traffic in a way that the original one was not, detecting precise attacks that the original could only hint at through warnings about inconsistent retransmission. We stress that no amount of care in the design of the original could have changed its behavior in this respect: since hosts' behavior varies, any single policy employed by the NIDS will inevitably fail for hosts that employ a different one.

### 6 Related Work

#### 6.1 Normalization

As previously discussed, traffic normalization seeks to eliminate network traffic ambiguities by altering the traffic stream [HKP01]. The normalizer lies in the forwarding path of packets into a site. It reassembles IP fragments and TCP streams and statefully modifies or filters out nonconforming traffic before sending packets on to the internal network. Its efficacy in improving the precision of the NIDS relies on its output being interpreted in the same way by all the hosts on the network. It largely succeeds at achieving this goal; the paper also discusses some exceptions.

There are disadvantages to normalization, however. A normalizer performs the same sorts of tasks as a firewall but does more work: it deals with TCP streams rather than just individual packets. Two main concerns arising from this complexity are performance and robustness. Since the normalizer is in the forwarding path, it must be able to process every packet as it arrives, even in the presence of state-holding attacks on itself. Further, it must be extremely reliable; if it is not, the entire site may lose Internet connectivity. An additional concern is that the normalizer changes the semantics of the streams it rewrites. This can block useful traffic, cause unintended problems with newer protocols, or decrease efficiency.

It appears that Active Mapping can replace many of the normalizations (see the Appendix for a full list). Still, there are cases in which some amount of normalization can confer significant benefits: its ability to remove flags and options can be used to eliminate any uncertainty as to their use. Accordingly, it may sometimes work best to use informed partial normalization, that is, to perform a limited set of normalizations that eliminate ambiguities that Active Mapping cannot. If the host profiles indicate that certain kinds of noncompliant packets are never accepted by any host, or if administrators want an additional layer of safety, such packets may be filtered out at the firewall.

#### 6.2 Mapping Tools

Active Mapping’s tactic of sending specially crafted packets and interpreting responses to infer host properties has been employed in a variety of tools. The most common purpose for such tools is to determine the operating system of a host. Nmap [Fyo01] uses port scans combined with IP and TCP options in responses to guess a host’s operating system. Queso [Sa98] takes a similar tack, sending TCP packets with illegal flag combinations. By matching initial TTL values, advertised TCP windows, initial sequence numbers, nonconforming responses to packets sent to closed ports, and so forth, these tools can detect a large number of operating system versions.

Neither provides us with enough precise information on the long list of policy choices and parameters we need. Since doing OS detection takes approximately as long as Active Mapping, there seems little advantage to doing OS detection instead for this purpose; however, knowing the host OS can be very useful in eliminating false positives (i.e., could a particular attack actually succeed?). We note that, especially in light of the fact that operating systems may be user-modified, the actually observed behavior is the only relevant thing for correct interpretation: the OS version is at best a proxy for this information.

Nonetheless, there is a certain synergy between the two. If OS data is known, it can serve as a quick proxy for mapping characteristics when coupled to a database containing canonical mappings by OS type and version. Conversely, known mappings can give at least a rough estimation of the OS a host is running. This can be useful for alert filtering: if a particular attack only works on Linux and the mapping data suggest a Windows machine, then we can filter out irrelevant alerts without knowing more precisely the OS versions.

The Ntop NIDS has been supplemented with network information inferred from passive monitoring [DS00]; this information appears to be limited to guessing the hop count and figuring out which IP addresses correspond to routers. Tbit [PF01] tries to learn the TCP behavior of HTTP servers in regards to congestion control. It only sends legitimate TCP packets, relying on TCP options, advertised windows, and timing information to deduce the server’s TCP configuration (or bugs therein). We use its scheme for implementing our user-level TCP.

### 7 Summary

Ambiguity in the interpretation of network traffic is a critical difficulty for Network Intrusion Detection. This ambiguity takes many forms. Some types may be resolved by careful construction of the NIDS. Other types are fundamentally more difficult to resolve and require additional information about the network and the hosts being monitored. In this paper, we have presented Active Mapping, a method of eliminating network- and transport-layer ambiguities by informing the NIDS of relevant network and host TCP/IP stack policies. We stress that the ambiguities that Active Mapping seeks to address are readily exploitable; systems have been designed for doing just that [So02, Mc98].

Active Mapping runs separately from the NIDS (typically during off-peak hours) and works by sending specially crafted packets to each host and inferring policy from the responses it receives (or lack thereof). It does not require any real-time manipulation of the incoming traffic stream by the NIDS. In our tests with a NIDS modified to use Active Mapping-generated profiles, we found that there was essentially no cost in terms of speed or memory use to get the increased precision in analysis; we expect this will hold true for any NIDS. In addition, we have shown that Active Mapping itself is efficient in terms of time, network bandwidth consumed, and output size. Preliminary mapping results show considerable variation in policy among hosts’ TCP/IP stacks, underscoring the need for the precise simulation that Active Mapping enables. Future work in this area might include exploring using passive monitoring to determine when to remap a host, as well as an implementation of mapping of DHCP clients and implementation of more of the mappings described in the Appendix.

Finally, we note that the problem of ambiguous traffic is not confined to the network and transport layers. It also occurs at the application layer—for example, exactly how will a particular URL be interpreted?—and dealing with all possible ambiguities appears essentially intractable. Active Mapping profiles might be able to help lower false positives by allowing the NIDS to consider only platform-relevant attacks, but analysis of this potential benefit is beyond the scope of this paper. Thus, we do not claim to have “solved” the NIDS evasion problem. However, we believe that the general problem of ambiguity resolution is best addressed in a systematic, layered fashion, and Active Mapping represents a step toward eliminating ambiguity at the bottom layers.

### Acknowledgments

We would like to thank Mark Handley at ICIR and Partha Banerjee, Mark Dedlow, Jay Krous, and Craig Leres in the SNS group at LBNL who helped us with testing the Active Mapper and in gathering data about the hosts on the LBNL network. We would also like to thank Nikita Borisov, Mark Handley, Rob Johnson, Chris Karlof, and David Wagner for their insightful and focusing comments on this paper.

### References

[Be02] Steven M. Bellovin, “A Technique for Counting NATted Hosts.” Proceedings of the Second Internet Measurement Workshop, November 2002.

[B+99] S. Blake et al, “An Architecture for Differentiated Services,” RFC 2475, Dec. 1998.

[Dr97] R. Droms et al., “Dynamic Host Configuration Protocol,” RFC 2131, Mar. 1997.

[DS00] L. Deri and S. Suin, “Improving Network Security Using Ntop,” Proc. Third International Workshop on the Recent Advances in Intrusion Detection (RAID 2000), 2000.

[EF94] K. Egevang and P. Francis, “The IP Network Address Translator (NAT),” RFC 1631, 1994.

[Fyo01] Fyodor. nmap, 2001. http://www.insecure.org/nmap/.

[HKP01] Mark Handley, Christian Kreibich, and Vern Paxson, “Network Intrusion Detection: Evasion, Traffic Normalization,” Proc. 10th USENIX Security Symposium, 2001.

[Mc98] John McDonald. “Defeating Sniffers and Intrusion Detection Systems,” Phrack Magazine, 8(54), Dec 25th, 1998.

[MLJ94] S. McCanne, C. Leres, and V. Jacobson, libpcap, available at http://www.tcpdump.org, 1994.

[Pa98] Vern Paxson, “Bro: A System for Detecting Network Intruders in Real-Time,” Computer Networks, 31(23-24), pp. 2435–2463, 14 Dec. 1999.

[PF01] Jitendra Padhye and Sally Floyd, “Identifying the TCP Behavior of Web Servers,” Proc. ACM SIGCOMM, Aug. 2001.

[PN98] T. H. Ptacek and T. N. Newsham, “Insertion, Evasion and Denial of Service: Eluding Network Intrusion Detection”, Secure Networks, Inc., Jan. 1998. http://www.icir.org/vern/Ptacek-Newsham-Evasion-98.ps

[Po80] J. Postel, “User Datagram Protocol,” RFC 768, August 1980.

[Po81a] J. Postel, “Internet Protocol,” RFC 791, September 1981.

[Po81b] J. Postel, “Internet Control Message Protocol,” RFC 792, September 1981.

[Po81c] J. Postel, “Transmission Control Protocol,” RFC 793, September 1981.

[Sa98] Savage, “QueSO,” PI:EMAIL, http://www.backupcentral.com/cgi-1998.