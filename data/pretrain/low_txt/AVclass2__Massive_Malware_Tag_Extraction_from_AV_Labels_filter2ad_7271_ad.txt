### 5.1 Datasets
We evaluate AVclass2 using the 11 datasets listed in Table 3. For each dataset, the table provides information on the target architecture (Windows, Android, or both), whether the samples are labeled with a family name, the number of samples, the availability of binaries (or just their hashes), and the collection period. These datasets are derived from previous studies, except for the Superset, which is a combination of all other datasets. Some datasets overlap; for example, Drebin [1] is a superset of MalGenome [39]. We do not remove duplicates to facilitate mapping results to publicly available datasets.

We had VirusTotal (VT) reports for most samples and only collected a few missing ones. We used the available reports because VT's rate limits make it impractical to collect the latest reports for all samples.

### 5.2 Tagging Evaluation
Table 4 summarizes the tagging coverage of AVclass2, indicating the fraction of samples for which it can extract at least one tag. These results are obtained using the tagging rules, expansion rules, and taxonomy generated by the update module after identifying previously unknown relations. In Section 5.3, we analyze the improvement in tagging before and after applying the update module. The table first shows the fraction of all samples and those flagged by at least four antivirus (AV) engines for which at least one tag was obtained. We use a threshold of four AV detections to filter out potentially benign samples. This threshold has been used in prior works [19], and a recent study [40] suggests that values between two and 14 are effective for balancing precision and recall. For each category, the table then shows the fraction of tagged samples with at least four detections and a tag of that category. The UNK column corresponds to samples with at least one output unknown token not in the taxonomy.

The results show that AVclass2 can extract at least one tag for 89%–100% of the samples, depending on the dataset. This indicates that the majority of samples can be indexed. The files for which no tags can be extracted are primarily those with very few detections, which is more common in the Andropup dataset, as it is the most recent. When considering samples flagged by at least four AV engines, the fraction of tagged samples is at least 99%. As shown by the Superset, the most common tags are file properties (99% of samples), followed by malware classes (94%), known families (83%), and behaviors (75%). It is important to note that the FAM column considers only samples tagged with families that appear in the taxonomy. However, unknown tags often correspond to new families not yet added to the taxonomy and should be considered for final family tagging results. Section 5.5 compares the family tagging results of AVclass2 to prior tools like AVclass and Euphony.

### Most Popular Tags
Table 5 shows the top 10 tags in the Superset for each category, ranked by the number of samples assigned the tag. The most popular tag is FILE:OS:windows (61% of samples), followed by CLASS:grayware (46%), BEH:execdownload (27%), BEH:filemodify (21%), FILE:packed (20%), and CLASS:downloader (20%). Our taxonomy contains 32–95 tags in each of the non-family categories and 894 families. Of the tags in the taxonomy, 94%–100%, depending on the category, appear in the Superset. Thus, the distribution of tags per category includes a large number of tags with at most 1% coverage, each identifying up to tens of thousands of samples. This means that AVclass2 extracts a wide variety of tags that analysts can use to search for samples based on class, family, file properties, and behaviors.

The top FILE tags include the platform (Windows, Android), whether the sample is packed, if it is a bundle containing other executables, the programming language (AutoIt, MSIL for C#), if it is an installer or generated by a particular installer (NSIS), and the file size (small). Intermediate tags rank high because they accumulate the popularity of their children through the expansion of taxonomy relationships. For example, "packed" accumulates the influence of all packer tags in the taxonomy (e.g., asroot, upack, themida). Similarly, "installer" accumulates the influence of NSIS and other installer-generating software (e.g., wiseinstaller, installmate).

There are four CLASS tags appearing in more than 10% of the samples. They capture the prevalence of potentially unwanted programs, downloaders, monetization through advertisements, and viruses. CLASS:grayware:adware:multiplug refers to adware that installs browser plugins (e.g., extensions, toolbars) to modify the user’s web surfing. CLASS:grayware:tool includes tools that are not necessarily malicious but are often misused, such as those used for remote administration. Note that "trojan" is considered a generic term; otherwise, it would be assigned to 86% of the samples.

The top three behavior tags correspond to expansions from class tags: downloader → execdownload, virus → filemodify, worm → selfpropagate. The behavior associated with a class often has a higher tagging ratio than its class, indicating additional samples without the corresponding class tag. For example, execdownload has an additional 7% of samples without the downloader class tag, and filemodify has an additional 6% over virus. Other popular behaviors include autorun, which captures samples that modify the autorun.inf Windows file to automatically execute; those related to obfuscation, such as injecting code into a benign process and killing a process (typically of a security tool); opening a server, alerting the user, sending SMS messages; and launching denial-of-service attacks.

Top families have lower prevalence than top classes, file properties, and behaviors. The most prevalent family is vobfus (10%). Half of the top families correspond to grayware families (loadmoney, softpulse, installerex, domaiq, firseria), and the rest are malware. Top unknown tokens have much lower prevalence, at most 1%. They mostly correspond to families not yet in the taxonomy, for which no strong relation has yet been observed to another tag.

### 5.3 Update Module
To illustrate the usage of the update module, we use the Andropup dataset as an example. When we first obtained this dataset, we ran AVclass2's labeler and observed that 65% of the samples contained an unknown tag.