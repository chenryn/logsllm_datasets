### Observations and Analysis

We observed a Pearson correlation coefficient of ρ = −0.20 (p-value = 0.10). Although this result is not statistically significant, the negative correlation suggests that the more helpful a user found a warning message, the fewer times they fell for the corresponding attack.

### Discussion and Conclusions

Our study provides several key takeaways regarding the various Bumpy designs tested:

1. **NoTM Design:**
   - **Deployment and User Experience:** The NoTM design is attractive for both deployment (as it does not use a Trusted Monitor, or TM) and user login duration (see Figure 3(b)).
   - **Security Concerns:** Contrary to our expectations (see §3.2.2), there is significant evidence that the NoTM design is more susceptible to users leaking password characters compared to other designs (see rejected hypotheses (3)–(6)). This vulnerability persists even after training via warnings (see rejected hypotheses (7)–(8)), although warnings did significantly improve security against some attacks (see Figure 5).
   - **Recommendation:** If the NoTM design is deployed, a concerted training effort for users is warranted.

2. **Challenge Design:**
   - **Password Leakage:** The Challenge design offers generally low password leakage after training via warnings, as illustrated in Figure 5. Specifically, the sample means for Challenge were the lowest across designs for all Active attacks, with the exception of Feigned-Fail in Figure 5(a).
   - **Statistical Significance:** While the evidence supporting the greater security of the Challenge design was statistically significant only in some cases (see rejected hypotheses (5)–(6) and (7)), it appears to be a generally good choice for security.
   - **Trade-offs:** The requirement for users to examine the TM in the login process results in statistically significantly longer login times (see Figure 3(b)).

3. **Graphical Design:**
   - **Performance:** The Graphical design did not offer significant improvements over the Original design in terms of login success rate, duration, or password leakage in either Attack or Attack-and-Warn scenarios. While it did show significant improvement due to warnings in the Attack-and-Warn phase (see Figure 5), the attacks for which it did so often still captured as many password characters as the Original or Challenge designs.
   - **Passive Attacks:** The best argument for the Graphical design is its performance in Passive attacks, where it yielded the least leakage (in terms of sample means) (Figures 4, 5).
   - **Implementation Challenges:** Given the implementation challenges introduced by the Graphical design (see §3.2.1), stronger evidence of its benefits would be needed to advocate for its adoption.

### Broader Observations

1. **Secure Attention Sequences:** Users appear to readily adapt to using secure attention sequences (at least generic ones, rather than site-specific ones), as evidenced by the low password leakage against Passive attacks in our designs that employ them. Techniques leveraging secure attention sequences thus hold promise.

2. **Login Duration and Security Trade-off:** Our study suggests a tradeoff between login duration and security. However, we do not conclude that this tradeoff is fundamental. It remains an open problem to design a login system that offers both speed and security against the attacks considered here.

3. **Interactive Security Indicators:** The additional security offered by the Challenge design suggests that interactive security indicators yield better security than those that users are simply asked to observe. This direction deserves further attention.

4. **User Behavior Training:** Some users were unfazed by warnings in the Attack-and-Warn phase, suggesting that training requiring immediate repetition of tasks following mistakes may be necessary. Such training could potentially disrupt the user’s primary activity, so it might be more acceptable as a separate user activity. Automated reinforcement during teachable moments, such as when a user makes a mistake during normal operation, may also be desirable, but such designs must be carefully balanced against the risk of malicious use by attackers.

5. **User Preparedness for Subtle Attacks:** Many of our Active attacks were designed to mimic changes in behavior that might seem familiar to users, such as software updates or failures. Our study indicates that many users are unprepared to distinguish between benign discontinuities and subtle attacks without training.

### Limitations

- **Complexity and Usability:** Our study did not evaluate the usability of Bumpy designs for protecting multiple secret input fields on a single web form, input fields to multiple websites, or secrets of greater complexity or length than a typical password. More complex secrets may be problematic for usability since Bumpy prevents keystrokes from echoing to the user’s display.
- **Forgotten Passwords:** The study did not employ Bumpy protections on the "reset password" page.
- **Experimental Constraints:** The step required of users who detected malware (reloading the page) and our simulation of the TM are sources of unrealism in our experiment, albeit unavoidable given the constraints of the course setting.
- **Financial Incentives:** A financial incentive was necessary to motivate users to protect their passwords, but such incentives are not directly available in practice and could have unintended effects on user behavior.
- **Simulated Attacks:** As discussed in §4.4, our simulated attacks are not exhaustive. For example, we did not consider phishing attacks, though previous studies have shown promise in educating users to detect them through a training regimen similar to our Attack-and-Warn phase [28].
- **Sample Size:** The numerous conditions required for computing some of our measures reduced the number of sample points (users) for some of our measures to an uncomfortably small number. Larger studies focused on each attack may be desirable if further investigation confirms these as primary threats.

### Acknowledgements

We are particularly grateful to the students of COMP380 at UNC in the Fall 2009 semester and to the course instructor, Tessa Joseph Nicholas, for permitting us to conduct this experiment. We also thank Chris Wiesen of the Odum Institute at UNC for his guidance on the statistical evaluations in this paper. Additionally, we thank Kathleen McCune for her assistance on the study questionnaire and Darrell Bethea, Ting-Fang Yen, and the anonymous reviewers for their comments on previous versions of this paper. This work was supported in part by NSF grant CT-0756998 and by grant DAAD19-02-1-0389 from the Army Research Office.

### References

[1] D. Balfanz and E. W. Felten. Hand-held computers can be better smart cards. In USENIX Security, Aug. 1999.
[2] K. Borders and A. Prakash. Securing network input via a trusted input proxy. In USENIX HotSec, Aug. 2007.
[3] S. Chiasson, P. C. Van Oorschot, and R. Biddle. A usability study and critique of two password managers. In USENIX Security, Aug. 2006.
[4] D. E. Clarke, B. Gassend, T. Kotwal, M. Burnside, M. van Dijk, S. Devadas, and R. L. Rivest. The untrusted computer problem and camera-based authentication. In International Conf. Pervasive Computing, 2002.
[5] P. Coogan. Zeus, king of the underground crimeware toolkits. Symantec Blogs, Aug. 2009.
[6] L. F. Cranor. What do they “indicate”?: evaluating security and privacy indicators. Interactions, 13(3):45–47, 2006.
[7] L. Duﬂot, O. Levillain, B. Morin, and O. Grumelard. Getting into the SMRAM: SMM reloaded. Central Directorate for Information Systems Security, 2009.
[8] L. K. Edwards. Applied Analysis of Variance in Behavioral Science. CRC Press, 1993.
[9] S. Egelman, L. F. Cranor, and J. Hong. You’ve been warned: An empirical study of the effectiveness of web browser phishing warnings. In CHI, 2008.
[10] E. Gabber, P. B. Gibbons, D. M. Kristol, Y. Matias, and A. Mayer. On secure and pseudonymous client-relationships with multiple servers. ACM TISSEC, 2:390–415, Nov. 1999.
[11] S. Garriss, R. C´aceres, S. Berger, R. Sailer, L. van Doorn, and X. Zhang. Trustworthy and personalized computing on public kiosks. In MobiSys, June 2008.
[12] D. Grawrock. Dynamics of a Trusted Platform: A Building Block Approach. Intel Press, 2008.
[13] IBM Zurich Research Lab. Security on a stick. Press release, Oct. 2008.
[14] M. Kassner. Carberp: Quietly replacing Zeus as the financial malware of choice. TechRepublic IT Security Blogs, Oct. 2010.
[15] S. T. King, P. M. Chen, Y.-M. Wang, C. Verbowski, H. J. Wang, and J. R. Lorch. SubVirt: Implementing malware with virtual machines. In IEEE Symp. Security and Privacy, 2006.
[16] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and H. Isozaki. Flicker: An execution infrastructure for TCB minimization. In ACM EuroSys, Apr. 2008.
[17] J. M. McCune, A. Perrig, and M. K. Reiter. Safe passage for passwords and other sensitive data. In ISOC NDSS, Feb. 2009.
[18] B. A. Myers. Using handhelds and PCs together. CACM, 44(11), Nov. 2001.
[19] A. Oprea, D. Balfanz, G. Durfee, and D. K. Smetters. Securing a remote terminal application with a mobile trusted device. In ACSAC, 2004.
[20] Organisation for Economic Co-operation and Development (OECD). Malicious software (malware): A Technical Report DSTI/ICCP/REG(2007)5/FINAL, OECD, June 2008.
[21] D. Rees. Foundations of Statistics. Chapman and Hall/CRC, 1987.
[22] B. Ross, C. Jackson, N. Miyake, D. Boneh, and J. C. Mitchell. Stronger password authentication using browser extensions. In USENIX Security, Aug. 2005.
[23] S. J. Ross, J. L. Hill, M. Y. Chen, A. D. Joseph, D. E. Culler, and E. A. Brewer. A composable framework for secure multi-modal access to Internet services from post-PC devices. Mobile Network Applications, 7(5):389–406, 2002.
[24] J. Rutkowska. Subverting Vista kernel for fun and profit. Presented at Black Hat USA, 2006.
[25] S. E. Schechter, R. Dhamija, A. Ozment, and I. Fischer. The emperor’s new security indicators. In IEEE Symp. Security and Privacy, 2007.
[26] R. Sharp, A. Madhavapeddy, R. Want, and T. Pering. Enhancing web browsing security on public terminals using mobile composition. In MobiSys, June 2008.
[27] R. Sharp, J. Scott, and A. Beresford. Secure mobile computing via public terminals. In International Conf. Pervasive Computing, May 2006.
[28] S. Sheng, B. Magnien, P. Kumaraguru, A. Acquisti, L. F. Cranor, J. I. Hong, and E. Nunge. Anti-phishing phil: the design and evaluation of a game that teaches people not to fall for phish. In SOUPS, pages 88–99, 2007.
[29] J. Sobey, R. Biddle, P. C. Van Oorschot, and A. S. Patrick. Exploring user reactions to new browser cues for extended validation certificates. In ESORICS, 2008.
[30] M. Stiegler. An introduction to petname systems, Feb. 2005.
[31] J. Sunshine, S. Egelman, H. Almuhimedi, N. Atri, and L. Cranor. Crying wolf: An empirical study of SSL warning effectiveness. In USENIX Security, Aug. 2009.
[32] Trusted Computing Group. Trusted platform module main specification, Part 1: Design principles, Part 2: TPM structures, Part 3: Commands. Version 1.2, Revision 103, July 2007.
[33] T. Whalen and K. M. Inkpen. Gathering evidence: use of visual security cues in web browsers. In Graphics Interface, 2005.
[34] R. Wojtczuk and J. Rutkowska. Xen 0wning trilogy. Invisible Things Lab, 2008.
[35] R. Wojtczuk and J. Rutkowska. Attacking SMM memory via Intel CPU cache poisoning. Invisible Things Lab, 2009.
[36] M. Wu, R. C. Miller, and S. L. Garﬁnkel. Do security toolbars actually prevent phishing attacks? In CHI, 2006.

### Summary of Bumpy Internals

The original Bumpy6 design [17] is motivated by the prevalence of malware on users’ computers, and thus assumes the operating system (e.g., Windows, Linux) is untrustworthy. Additional assumptions include that the remote web server is uncompromised and that the SSL certificate provided by the web server is legitimate and can be extended to integrity-protect the site’s favicon. Bumpy enables users to submit sensitive data on web forms without revealing that data to local malware.

**Bumpy User Experience:**
A detailed description of the Bumpy user experience is provided in §3.1. Here, we summarize the technical underpinnings of the system, specifically the system architecture required to protect user input from a malicious operating system.

**System Architecture:**
To ensure that Bumpy always receives (plaintext) user input before the OS, the following components are required:
- **Encryption-capable Input Devices:** Encryption-capable user-input devices (or an encryption-capable interposer, e.g., a small USB device).
- **Isolated Execution Environment:** An isolated and attestable execution environment on the user’s computer (e.g., Flicker [16]).
- **Bumpy Software Module:** A Bumpy software module that executes in this isolated environment, comprising a Pre-Processor (PreP) and Post-Processor (PoPr).
- **Trusted Monitor (TM):** A trustworthy device with a display to serve as a TM.
- **Bumpy-aware Webserver Software:** Bumpy-aware software on the web server.

These items are part of the trusted computing base (TCB) for Bumpy. Other enhancements needed to the software on the client host to work with Bumpy include enhancements to the input-handling logic of the platform OS and an extension to the user’s web browser. These, however, are not part of the TCB for Bumpy.

**Input Processing:**
Figure 7 summarizes the flow of user input:
1. **Keystroke Encryption:** Keystrokes are encrypted by an encryption-capable keyboard (or an interposer), and the ciphertext is received by the OS (Steps 1–3).
2. **Decryption and Processing:** The OS invokes a protected execution environment (Step 4), where keystrokes are decrypted and processed by the Bumpy module.
3. **Pre-Processor (PreP):** The PreP decrypts incoming keystrokes and tracks whether the current input is sensitive. Sensitive input begins with the user typing the SAS @@ and ends when the user provides an input that would cause a blur in the web browser GUI (e.g., a tab).
4. **Normal Input Handling:** Normal input is released to the platform OS decrypted (Step 5), and the user’s experience remains unchanged.
5. **Sensitive Input Handling:** Sensitive input is queued within the PreP, and decoy input events (e.g., asterisks) are released to the platform OS (also Step 5). When the user finishes providing sensitive input, the PoPr is invoked to re-encrypt the user’s sensitive input for its intended destination (Step 6).
6. **Transmission and Attestation:** The ciphertext containing the user’s sensitive input is prepared for transmission, and a TPM-based attestation [32] is produced. This attestation is used to convince the destination web server that the user’s input was handled with the Bumpy system (Step 7). The ciphertext and attestation are sent to the remote web server (Step 8), which verifies the attestation, decrypts the user’s input, and processes it (e.g., a credit card number for an online purchase).

**Trusted Monitor (TM):**
Upon receiving the SAS, the PreP outputs an authenticated message for the TM that includes information about the currently active destination website. This information, including the domain name (Common Name in the site’s SSL certificate) and graphic logo (the site’s favicon), is maintained in the PreP and read directly from the destination web server’s SSL certificate. The user is responsible for verifying that this is the intended destination.