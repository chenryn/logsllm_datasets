### Experimental Results

We evaluated the performance of stateful and stateless recovery mechanisms across three different configurations: Alexa-top US sites, a large FTP download, and two separate BitTorrent downloads. In all three scenarios, stateful recovery closely matched the baseline performance. However, for stateless recovery over HTTP connections, we observed a significant drop in performance, corresponding to the connection reset time of 180 seconds. 

For the BitTorrent downloads, one of the torrents showed minimal impact under stateless recovery, while the other failed almost entirely, requiring a client restart. The failed torrent had only 10 available peers, and when the connections were reset, the client assumed these peers had gone offline. In contrast, the successful torrent had a large pool of available peers, allowing it to quickly reconnect to new ones.

These experiments highlight that while some applications can recover rapidly under stateless conditions, many existing applications are not designed to do so effectively.

### Related Work

We discuss three main lines of work relevant to FTMB, as outlined in Section 2:

#### No-Replay Schemes
In Section 6, we detailed and experimentally compared three recent systems—Remus, Pico, and Colo—that adopt this approach with FTMB.

#### Rollback Recovery in Distributed Systems
The literature on distributed systems includes a wide range of protocol proposals (see Elnozahy et al. [31] for a comprehensive survey). However, to our knowledge, there is no available system implementation that can be tested in our application context. The focus on distributed systems introduces several differences from our single-machine parallel program, such as:
- **Failure Model:** Partial vs. complete failure.
- **Nature of Nondeterminism:** Message arrival and sending order vs. thread races.
- **Frequency of Output:** High-rate outputs in our case.
- **Frequency of Nondeterminism:** Per-packet nondeterminism.
- **Performance Bottlenecks:** Logging and output commit decisions.

These differences led us to design new, simpler, and more lightweight solutions than those found in the literature.

#### Multicore Record-and-Replay Systems
These systems, used for debugging, do not implement output commit. We discussed them in Section 2 and evaluated one such system, Scribe, in Section 6.

### Additional Systems

- **Hypervisor-based Fault Tolerance [18]:** An early system in the 90s that implemented fault tolerance for arbitrary virtual machines. It did not address multicore systems and required synchronization for every nondeterministic operation.
- **SMP Revirt [29]:** Performs record-and-replay over Xen VMs. Unlike FTMB, SMP ReVirt uses page protection to track memory accesses. For applications with limited contention, the authors report a 1.2-8x slowdown, but for "racy" applications like ours, the results are similar to Scribe.
- **Eidetic Systems [24]:** Allow users to replay any event in the system's history, even years back. They achieve very low overheads for end-user desktops but do not scale well for racy and high-output systems.
- **R2 [36]:** Logs a cut in an application’s call graph and introduces detailed logging of information flowing across the cut using an R2 runtime to intercept syscalls and underlying libraries. The overhead of interception makes it unsuitable for our application with frequent nondeterminism.
- **ODR [16]:** A general record-and-replay system that provides output determinism by searching the space of possible executions during replay. This can result in replay times several orders of magnitude higher than the original execution, which is not acceptable for rapid recovery.

### Discussion

FTMB is a system for rollback recovery that uses ordered logging and parallel release to achieve low overhead for middlebox fault tolerance. We demonstrated that FTMB imposes only 30µs of latency for median packets through an industry-designed middlebox, with modest throughput overheads and the ability to perform replay recovery in 1-2 wide area RTTs.

#### Future Directions

- **User-Level Packet Processing Stacks:** Efforts in industry and research aim to enable fast packet processing in user space (e.g., netmap [52], DPDK [38]). These systems currently lack support for seamless virtual machine migration, which will be necessary as NFV stacks become more widely deployed.
- **New Virtualization Techniques and Fast Checkpointing:** Linux Containers [5] offer finer-grained virtualization, enabling cheaper snapshotting. Ongoing efforts in hardware and software support for faster snapshotting [1, 20] will improve migration and reliability systems [11, 23], thereby enhancing FTMB's tail latencies.
- **Varied Operating Systems and Hardware Components:** NFV offers the potential for a wider range of diversity in system software stacks and hardware. This diversity can extend the failure model assumed by FTMB and other systems, providing protection against bugs in drivers, NICs, and operating systems.
- **Diverse Middlebox Software:** Open-source implementations of many middleboxes (e.g., Snort [8], Bro [10], Vyatta [12], Squid [9]) and vendor re-architecting of hardware-based appliances as software-only implementations suggest that FTMB's techniques will have broad applicability in the future.

As the NFV ecosystem continues to evolve, FTMB's approach—ordered logging and parallel release—will be a practical, low-overhead solution for reliability.

### Acknowledgements

We thank the anonymous reviewers of the SIGCOMM program committee and our shepherd Jeff Chase for their thoughtful feedback. We also thank the middlebox vendors for helpful discussions about FTMB, reliability practices, and state-of-the-art network appliances. Jiawei Chen and Eddie Dong at Intel shared the Colo source code and helped us deploy it in our lab at Berkeley. Kay Ousterhout provided feedback on multiple iterations of this paper. This work was supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1106400 and by generous financial and technical support from Intel Research.

### References

[References listed here as in the original text]

---

This version of the text is more structured, coherent, and professional, making it easier to read and understand.