# Optimized Text

## Figure 16: Offline Preprocessing Time for 10,000 Triples
Figure 16 illustrates the time in milliseconds required for offline preprocessing of 10,000 triples, with and without MMO (Memory-Mapped Operations) and large domain hashing optimizations. The figure also shows the effect of reducing the number of consistency checks in the correlated OTs (μ = 3). The experiments were conducted on a single thread over a LAN supporting up to 10 Gbps.

### Offline Reduced Correlation Checks Benchmark
- **k = 32**: 
  - With MMO and large domain hashing: 531 ms
  - Without MMO and large domain hashing: 373 ms
- **k = 64**:
  - With MMO and large domain hashing: 1,684 ms
  - Without MMO and large domain hashing: 994 ms

## Figure 17: Preprocessing Time for 10,000 Multiplications
Figure 17 depicts the time in milliseconds for preprocessing 10,000 multiplications, running on 4 threads over a 10 Gbps network, with varying amounts of correlation checks. The results are presented with and without MMO and large domain hashing optimizations applied.

### Reducing the Number of Consistency Checks in Correlated OT
We further optimize the correlated OT protocol by reducing the number of consistency checks. The protocol from [41] performs one check between every pair of OT inputs, resulting in a total of \( k^2 \) checks. We apply an optimization from [43], which reduces the number of checks to \( \mu \cdot k \) for a small constant \( \mu \). This significantly reduces the computational costs of the protocol, with a minor sacrifice in security: based on the analysis in [43], using \( \mu = 3 \) should result in losing no more than 9 bits of statistical security. In Figure 17, we present a micro-benchmark comparing the use of \( \mu = 3 \) versus \( \mu = 10 \), which is the default without the optimization. The optimization reduces the triple generation time by up to 40%.

## Memory Usage
In addition to our performance benchmarks for the online and preprocessing phases, we also measured peak memory usage.

### Online Phase
- None of our benchmarks exceeded 6 GB in memory usage.
- This is well below the available RAM in our experimental setup (16 GB) and our maximum heap size JVM setting (15 GB).
- Memory does not present a bottleneck.
- Peak memory usage was consistently lower for SPDZ2k than SPDZ, with up to a 1.4 factor improvement across all benchmarks.

### Offline Phase
- For SPDZ2k and MASCOT, memory usage was below half a gigabyte.
- Overdrive's memory usage was higher (approximately 4 GB for \( k = 64 \)), but still well below the available RAM (16 GB) of our machines.

## Acknowledgments
This work has been supported by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme under grant agreement No 669255 (MPCPRO); the European Union’s Horizon 2020 research and innovation programme under grant agreement No 731583 (SODA); the European Union’s Horizon 2020 research and innovation programme under grant agreement No 74079 (ALGSTRONGCRYPTO); and the Danish Independent Research Council under Grant-ID DFF–6108-00169 (FoCC).

We would like to thank the authors of [28] and [29] for providing us with their machine learning models.

## References
[References listed as provided, with no changes needed.]

---

This optimized text aims to improve clarity, coherence, and professionalism while maintaining the original content and structure.