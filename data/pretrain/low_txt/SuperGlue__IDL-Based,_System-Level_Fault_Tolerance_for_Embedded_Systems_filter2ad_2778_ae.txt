### Performance Evaluation

Performance is a critical priority in our study. The web server under evaluation utilizes all system-level components, allowing us to assess the impact of the recovery infrastructure on best-effort tasks. Previous research [7] has demonstrated the real-time properties of interface-driven recovery. We evaluate a custom web server implemented in COMPOSITE, as well as versions enhanced with SuperGlue and C3, under both normal conditions and in the presence of injected faults. For comparison, we also test the Apache HTTP server (version 2.2.14) running on Linux 3.2.6 on a machine equipped with an Intel i7-2760QM processor at 2.4 GHz.

Performance is measured using the Apache HTTP server benchmarking tool, `ab` (version 2.3), which sends 50,000 requests to the server, with a maximum of 10 concurrent requests. Each test is repeated 20 times, and the average and standard deviation of the results are reported.

Figure 7 illustrates the throughput (HTTP requests per second) for all four variations over one minute. The Apache HTTP server achieves approximately 17,600 requests per second, while the COMPOSITE base web server handles about 16,200 requests per second. The COMPOSITE with SuperGlue configuration averages 14,281 requests per second, representing an 11.84% slowdown, and the COMPOSITE with C3 configuration averages 14,500 requests per second, a 10.5% slowdown.

### Fault Recovery Evaluation

We evaluated the fault recovery capabilities of COMPOSITE with SuperGlue and COMPOSITE with C3 by injecting faults into one system-level component every 10 seconds. Our observations indicate that recovery proceeds concurrently with ongoing web server operations, and after recovery, the web server returns to a similar throughput as before the fault. For example, when a fault occurs in the scheduler, the web server's throughput is only temporarily disturbed for less than 2 seconds, and it continues serving clients without dropping the network throughput to zero. These results suggest that SuperGlue can enhance system reliability with only a minor performance degradation.

### Web Server Throughput Comparison

Figure 7: Web Server Throughput. This figure shows the number of requests per second for Apache, COMPOSITE, COMPOSITE with C3 (without faults), COMPOSITE with SuperGlue (without faults), and COMPOSITE with SuperGlue (with one crash injected every 10 seconds into a different system-level component, indicated by red crosses).

### Related Work

#### Improving OS Reliability

Significant research has been conducted to improve operating system (OS) reliability. Two well-known approaches are Triple Modular Redundancy (TMR) and checkpoint-restore. TMR achieves reliability through redundancy but at the cost of tripling software, weight, and power (SWaP) requirements. Checkpoint-restore, as seen in EROS [31], Otherworld [32], and Tardigrade [33], involves taking snapshots of OS services and rolling back to a previous state upon a fault. This method incurs storage and time overheads, and checkpointing client (user-space) state adds extra consistency overhead. Additionally, restoring a checkpoint can result in the loss of computation and communication since the last saved checkpoint, leading to mismatches between the current physical system state and the state expected by the control system [7]. Process-level replication [34] can also improve system reliability by using redundant processes and comparing their outputs.

#### Dependability in OS

**Nooks [1]** enhances Linux reliability by moving device drivers into a lightweight protection domain with limited access to the kernel's memory space. A shadow driver, designed with the same interface as the original driver, monitors data transfers during normal execution. When a fault occurs, the shadow driver takes over, allowing the system to recover using previously saved state.

**Minix [35]** is a microkernel OS where a special isolated component, the reincarnation server, restarts faulty components by recreating a fresh copy. However, Minix does not track client state, making its recovery mechanisms suitable only for stateless servers like device drivers. System-level services such as memory management are still in the kernel space, posing challenges for building a reliable OS tolerant of system-level faults.

**CuriOS [36]** is another microkernel OS that uses a Server State Region (SSR) to store each server's client-related information, protected from both the server and client. SSRs are managed by a single separate component (SSRManager), and requests causing crashes are isolated by restricting writes from clients. When a fault occurs, a recovery routine in the restarted server enumerates all associated SSRs to recreate the internal state. However, SSRManager is a single point of failure, making it less desirable for a reliable OS.

In contrast, **COMPOSITE with C3 [7]**, as discussed in Section II, focuses on fault tolerance mechanisms for system-level services. **C’MON [28]** allows predictable detection of latent faults in system-level services in a component-based OS.

**SuperGlue** aims to build a reliable OS while reducing programming effort. It maps a high-level abstract system model to low-level interface-driven recovery mechanisms, enhancing the reliability of system-level services in a component-based OS with minimal performance degradation. Although further integration with formal specification techniques [37, 38] could provide greater system assurance, our focus is on a model that enables a concise definition of system behavior to evaluate SuperGlue's effectiveness.

#### Interface Synthesis

Automatic code generation with Interface Description Languages (IDLs) has been extensively studied for various purposes. **Flick [39]** is a highly flexible IDL compiler that supports various IDL types and generates code for different communication platforms. **Jinn [30]** is a dynamic analysis framework for Java Native Interface (JNI) that synthesizes runtime checks to detect language interface violations. Jinn enforces these rules by dynamically injecting checks into user code at JNI interfaces.

**SuperGlue IDL**, aimed at system reliability, allows a declarative high-level description of a component-based OS based on a resource-descriptor relation model and a descriptor state machine. This enables the SuperGlue compiler to generate fault recovery code for system-level services, enhancing the dependability of component-based embedded systems.

### Conclusion

Faults in system-level services often require system reboots, disrupting all applications. In real-time and embedded systems, this can violate temporal guarantees and system correctness. This paper introduces SuperGlue, an infrastructure built on the predictable recovery mechanisms of C3 to improve programmability. We present a model of component and interface semantics that enables the IDL-based, declarative specification of key properties used by the SuperGlue compiler to generate recovery code. The average SuperGlue IDL file replaces C header files and is 37 lines of code, a significant improvement over C3, which required manually written, error-prone recovery code. We demonstrate that SuperGlue causes a non-prohibitive slowdown of 11.84% in a throughput-oriented application (a web server). Even with injected faults, the slowdown is only 13.6%.

### References

[1] Michael M. Swift, Brian N. Bershad, and Henry M. Levy. Improving the reliability of commodity operating systems. In SOSP, 2003.
[2] Pedro Mej´ıa-Alvarez and Daniel Moss´e. A responsiveness approach for scheduling fault recovery in real-time systems. In RTAS, 1999.
[3] A. Burns, S. Punnekkat, L. Strigini, and D. R. Wright. Probabilistic scheduling guarantees for fault-tolerant real-time systems. In DCCA, 1999.
[4] S. Punnekkat and A. Burns. Analysis of checkpointing for schedulability of real-time systems. In RTCSA Workshop, 1997.
[5] Man-Lap Li, Pradeep Ramachandran, Swarup Kumar Sahoo, Vikram S. Adve, and Yuanyuan Zhou. Understanding the propagation of hard errors to software and implications for resilient system design. In ASPLOS, 2008.
[6] R. Barbosa, J. Karlsson, Qiu Yu, and Xiaozhen Mao. Toward dependability benchmarking of partitioning operating systems. In DSN, 2011.
[7] Jiguo Song, John Wittrock, and Gabriel Parmer. Predictable, efficient system-level fault tolerance in C3. In RTSS, 2013.
[8] Gabriel Parmer and Richard West. Mutable protection domains: Adapting system fault isolation for reliability and efficiency. In ACM Transactions on Software Engineering (TSE), July/August 2012.
[9] P. Chevochot, I. Puaut, and Projet Solidor. Experimental evaluation of the fail-silent behavior of a distributed real-time run-time support built from COTS components. 2000.
[10] S. Chandra and P. M. Chen. How fail-stop are faulty programs? In FTCS, 1998.
[11] Shekhar Borkar. Designing reliable systems from unreliable components: The challenges of transistor variability and degradation. IEEE Micro, 2005.
[12] Shubu Mukherjee. Architecture Design for Soft Errors. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2008.
[13] Qi Wang, Yuxin Ren, Matt Scaperoth, and Gabriel Parmer. Speck: A kernel for scalable predictability. In Proceedings of the 21st IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS), 2015.
[14] Gabriel Parmer. The case for thread migration: Predictable IPC in a customizable and reliable OS. In OSPERT, 2010.
[15] Bryan Ford and Jay Lepreau. Evolving Mach 3.0 to a migrating thread model. In Proceedings of the Winter 1994 USENIX Technical Conference and Exhibition, 1994.
[16] J. Liedtke. On micro-kernel construction. In Proceedings of the 15th ACM Symposium on Operating System Principles. ACM, December 1995.
[17] Yuxin Ren, Gabriel Parmer, Gedare Bloom, and Teo Georgiev. Cbufs: Efficient, system-wide memory management and sharing. In Proceedings of the 2016 International Symposium on Memory Management, 2016.
[18] Kevin Elphinstone and Gernot Heiser. From L3 to seL4 what have we learnt in 20 years of L4 microkernels? In SOSP, 2013.
[19] G. Candea, S. Kawamoto, Y. Fujiki, G. Friedman, and A. Fox. Microreboot–a technique for cheap recovery. In OSDI, 2004.
[20] Giacinto P. Saggese, Nicholas J. Wang, Zbigniew T. Kalbarczyk, Sanjay J. Patel, and Ravishankar K. Iyer. An experimental study of soft errors in microprocessors. IEEE Micro, 2005.
[21] M. Nicolaidis. Time redundancy based soft-error tolerance to rescue nanometer technologies. In VLSI Test Symposium, 1999.
[22] A. Wood A. Dixit, R. Heald. Trends from ten years of soft error experimentation. In SELSE, 2009.
[23] Jonathan Chang, George A. Reis, and David I. August. Automatic instruction-level software-only recovery methods. In DSN, 2006.
[24] Nicholas J. Wang, Justin Quek, Todd M. Rafacz, and Sanjay J. Patel. Characterizing the effects of transient faults on a high-performance processor pipeline. In DSN, 2004.
[25] M. Rebaudengo, M.S. Reorda, and M. Violante. An accurate analysis of the effects of soft errors in the instruction and data caches of a pipelined microprocessor. In DATE, 2003.
[26] George A. Reis, Jonathan Chang, Neil Vachharajani, Ram Rangan, and David I. August. Swift: Software implemented fault tolerance. In CGO, 2005.
[27] N.J. Wang and S.J. Patel. Restore: Symptom based soft error detection in microprocessors. In DSN, 2005.
[28] Jiguo Song and Gabriel Parmer. C’MON: a predictable monitoring infrastructure for system-level latent fault detection and recovery. In RTSS, 2013.
[29] Manuel F¨ahndrich, Mark Aiken, Chris Hawblitzel, Orion Hodson, Galen C. Hunt, James R. Larus, and Steven Levi. Language support for fast and reliable message-based communication in Singularity OS. In EuroSys, 2006.
[30] Byeongcheol Lee, Ben Wiedermann, Martin Hirzel, Robert Grimm, and Kathryn S. McKinley. Jinn: synthesizing dynamic bug detectors for foreign language interfaces. In PLDI, 2010.
[31] Jonathan S. Shapiro, Jonathan M. Smith, and David J. Farber. Eros: A fast capability system. In SOSP, 1999.
[32] Alex Depoutovitch and Michael Stumm. Otherworld: giving applications a chance to survive OS kernel crashes. In Proceedings of the 5th European conference on Computer systems, pages 181–194, New York, NY, USA, 2010. ACM.
[33] Jacob R. Lorch, Andrew Baumann, Lisa Glendenning, Dutch T. Meyer, and Andrew Warfield. Tardigrade: Leveraging lightweight virtual machines to easily and efficiently construct fault-tolerant services. In NSDI, 2015.
[34] A. Shye, J. Blomstedt, T. Moseley, V.J. Reddi, and D.A. Connors. Plr: A software approach to transient fault tolerance for multicore architectures. TDSC, 2009.
[35] Jorrit N. Herder, Herbert Bos, Ben Gras, Philip Homburg, and Andrew S. Tanenbaum. Reorganizing UNIX for reliability. In ACSAC, 2006.
[36] Francis M. David, Ellick M. Chan, Jeffrey C. Carlyle, and Roy H. Campbell. CuriOS: Improving reliability through operating system structure. In OSDI’08.
[37] M. Rodriguez, J. C. Fabre, and J. Arlat. Formal specification for building robust real-time microkernels. In RTSS, 2000.
[38] Jean Arlat, Jean-Charles Fabre, Manuel Rodr´ıguez, and Fr´ed´eric Salles. Dependability of COTS microkernel-based systems. IEEE Transactions on Computers, 2002.
[39] Eric Eide, Kevin Frei, Bryan Ford, Jay Lepreau, and Gary Lindstrom. Flick: a flexible, optimizing IDL compiler. In PLDI, 1997.