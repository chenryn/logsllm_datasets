### Additional Features and Security Guarantees

The Trusted Abstract Platform (TAP) incorporates additional features, such as non-volatile monotonic counters and demand paging, along with enhanced protections against sophisticated attackers, including timing attacks. TAP provides an extensible verification methodology that facilitates rigorous reasoning about the security properties of future enclave platforms. It also serves as a flexible model for analyzing enclave programs.

### 7.1 Implications for Enclave Platforms

The TAP offers several benefits to implementers of enclave platforms:

1. **Top-Down Specification**: The TAP can be used as a top-down specification for the operations that an enclave platform must support. Implementers can use refinement checks to ensure that the TAP's security guarantees are met in their implementations. A significant challenge is that security is not compositional: adding new operations to a secure platform can introduce vulnerabilities. For example, the insecurity of SGX to Adversary MCP [69, 83] is due to demand paging, which allows the OS to observe the state of the enclave’s page tables. This feature is not present in the current implementation of Sanctum. If the next version of Sanctum supports demand paging using oblivious RAM to maintain TAP's confidentiality guarantee, reasoning about these more complex platforms would be infeasible without a verification methodology and a TAP-like specification of the platform's primitives.

2. **Bottom-Up Analysis**: The TAP can also be used bottom-up to analyze the security properties of existing platforms, as demonstrated in this paper. Such analysis can highlight differences between various platforms, such as leakage through the cache and page tables in SGX. The refinement methodology described here can show that implementations of enclave platforms (e.g., the Sanctum implementation) are refinements of corresponding models (e.g., the Sanctum model). Since we have shown that the Sanctum model is a refinement of the TAP, this proof means that the security properties of the TAP also hold for the Sanctum implementation.

### 7.2 Implications for Enclave Software

While techniques for verifying the security properties of enclave programs [70, 71] have been developed, they often rely on detailed models of the underlying enclave platform. We argue that reasoning about these properties is better done using TAP’s clean abstraction, which is simpler than the instruction-level model of SGX and the API-level model of Sanctum. This simplification makes automated verification more scalable while maintaining soundness through refinement checks. It also promotes portability among different enclave platforms.

Most importantly, this paper provides a common language for research into the security properties of enclaves. While side-channel defenses have been proposed for SGX enclaves [55, 68, 69], the lack of formalization of the enclave’s execution, attacker’s operations, and observations, and the desired confidentiality property makes it infeasible to systematically compare two defenses.

### 7.3 Limitations

#### 7.3.1 Limitations of the TAP

The TAP does not model the full range of systems for which enclaves are relevant; instead, it focuses on enclave platforms that provide memory-based isolation. The TAP’s current adversary model assumes that platform memory (DRAM) is trusted, meaning memory can only be modified via software. Extending the adversary model to include, for example, memory probing or DMA attacks, would require augmenting the TAP’s memory operations (fetch, load, store) with encryption and integrity protection. The TAP also does not support demand paging, as a naive implementation is vulnerable to the pigeonhole attack [69, 83]. One approach to achieving confidentiality-preserving demand paging in the TAP would be to use an oblivious-RAM protocol.

The TAP model and proofs are currently limited to concurrent execution on a single-threaded, single-core processor. A fully general proof showing that the TAP ensures SRE on multicore systems would require parameterized verification of these properties for an unbounded number of cores, using, for example, the CMP method [18]. We would also need to show linearizability of operations in the Sanctum/SGX models [31]. In this context, linearizability means that each operation appears atomic and there exists an ordering of operations across all cores that is consistent with their sequential orders of completion in individual cores. Linearizability of an SGX model was shown by Leslie-Hurd et al. [39]. Extending the TAP to model the security of simultaneously multithreaded (SMT) processors would require modeling many more side channels (e.g., branch predictors, shared resources such as instruction queues and function units) and developing architectural mechanisms to prevent leakage through these side channels.

Finally, the TAP does not model the cryptography in the attestation operation. Instead, we model the hash function using uninterpreted functions and assume the properties of collision resistance and second pre-image resistance.

#### 7.3.2 Limitations of the Sanctum/SGX Models

Our SGX model does not include demand paging, memory encryption, or memory integrity protection and assumes the correctness of SGX measurement. Unlike the TAP, the Sanctum implementation’s measurement is not computed on a single snapshot of state but is updated incrementally during enclave creation. A proof that this incremental measurement is identical to the TAP’s measurement is ongoing. Like the TAP, our Sanctum model also uses uninterpreted functions to model the cryptography in the measurement operation.

### 8. Related Work

#### Secure Processors

Several commercial deployments of secure processors exist. ARM TrustZone [2] implements secure and normal modes of execution to create a single privileged enclave in an isolated address space. TPM+TXT [29] enables attestation of the platform’s state but includes all privileged software layers in the trusted computing base. Intel SGX [3, 20, 32, 47] implements unprivileged enclaves that protect the integrity of memory and enclave state against software adversaries and certain physical access attacks. Academic work seeking to improve the security of conventional processors is also abundant [25, 43, 44].

Several clean-slate academic projects aim to build trusted systems. The XOM [42] architecture introduced the concept of isolated software containers managed by untrusted host software, employing encryption and HMAC to protect DRAM. Aegis [76] showed how a security kernel could measure and sign enclaves, using counter-mode memory encryption and a Merkle tree to guarantee data freshness in DRAM. Bastion [16] encrypts and HMACs DRAM and employs a trusted (and authenticated as part of remote attestation) hypervisor, invoked at each TLB miss to check address translation against a policy. Fides [74] uses a small trusted hypervisor to provide security guarantees for protected modules, which offer similar programming abstractions and security guarantees as enclaves. Sancus [54] builds upon Fides, proposing hardware extensions that ensure the security of protected modules in resource-constrained embedded processors. Ascend [27] and Phantom [46] ensure the privacy and integrity of all CPU memory accesses through a hardware ORAM primitive.

#### Attacks on Secure Processors

Secure systems often expose complex threat models, leading to vulnerabilities in application layers. Side-channel attacks, such as those observing cache timing, can compromise cryptographic keys used by numerous cryptosystems [11, 14, 15, 37]. Other shared resource attacks, such as those observing a core’s branch history buffers [38], are viable at any privilege level, separated by arbitrary protection boundaries [34, 45, 56]. Similar attacks apply to trusted hardware, as shown in SGX with attacks observing shared caches [12, 49, 66] and shared page tables [69, 83].

#### Formal Models/Verification of Enclave Platforms

A formal cryptographic model of SGX’s anonymous attestation scheme is presented in [58]. Barbosa et al. [6] present a formal analysis of cryptographic protocols for secure outsourced computation using enclave platforms. In contrast, our work formalizes the security guarantees of enclave platforms themselves. Patrignani et al. [60, 61] develop abstract trace semantics for low-level code (excluding side-channels) on protected module architectures—Fides [74] and Sancus [54]—to build secure compilers for these platforms [59]. This complements our work, which focuses on formalizing the security guarantees of enclave platforms in the presence of precisely modeled adversaries (including side-channel observations).

While our work analyzes models of enclave platforms, verifying actual implementations remains a significant challenge. One aspect of this was studied by Leslie-Hurd et al. [39], who verified the linearizability of concurrent updates to shared SGX data structures.

#### Non-Interference and Hyperproperties

The security properties of secure measurement, integrity, and confidentiality are formulated as 2-safety observational determinism properties [48, 62], a restricted class of hyperproperties [19]. SRE closely relates to the notion of non-interference introduced by Goguen and Meseguer [28] and separability proposed by Rushby [63]. Our confidentiality definition is an adaptation of standard non-interference to the enclave execution model. Separability provides isolation from other programs on the system but is too strict for practical applications, as it forbids communication between programs and assumes the absence of covert channels. It also does not consider privileged software adversaries, assuming a safe underlying hardware-software system.

#### Security Type Systems

A large body of work has studied type systems that enforce information-flow security [17, 22, 65, 73, 80]. Recent examples for hardware design include [40, 41, 85]. SecVerilog [85] extends the Verilog hardware description language with dependent type annotations that define a security policy statically verified by the SecVerilog compiler. One could conceivably implement SGX or Sanctum processors using SecVerilog, thus guaranteeing the implementation does not have unsafe information flow. However, these techniques reason about the security policy at the level of individual signals in the hardware. A higher level of abstraction (like TAP) is needed for reasoning about enclave software. Software fault isolation prevents an untrusted software module from arbitrarily tampering with the system’s state, restricting all communication to occur via a narrow interface. RockSalt [50] uses Coq to reason about an x86 processor model and guarantee software fault isolation of an untrusted module.

#### Machine-Checked Proofs of Systems

We perform machine-checked proofs in this work, and similar efforts have verified other classes of systems. The seL4 project [36, 51] proves isolation and information flow enforcement in the seL4 microkernel using the Isabelle/HOL proof assistant [53]. The Ironclad project [30] built a fully verified software stack (including an OS, device drivers, and cryptographic libraries) from the ground up. The miTLS project [10] is building a verified reference implementation of TLS, which complements our work nicely—enclaves indubitably require TLS channels to communicate with other enclaves and clients. Vijayaraghavan et al. [79] used the Coq proof assistant [9] to verify the correctness of a multiprocessor directory-based cache coherence protocol. While our Boogie [7, 24] proofs do involve manual effort, we contend that they are more automated than their hypothetical counterparts in systems such as Isabelle and Coq.

### 9. Conclusion

This paper introduces a framework and methodology for reasoning about the security guarantees provided by enclave platforms. We introduced the Trusted Abstract Platform (TAP) and performed proofs demonstrating that TAP satisfies the three properties required for secure remote execution (SRE): secure measurement, integrity, and confidentiality. We then presented machine-checked proofs stating that models of Intel SGX and Sanctum are refinements of TAP under certain adversarial conditions. Therefore, these platforms also satisfy the properties required for SRE. Overall, this paper takes a step towards a unified, extensible framework for reasoning about enclave programs and platforms.

### Acknowledgments

Funding for this research was partially provided by the National Science Foundation under grants CNS-1413920 and CNS-1528108, by the Intel ADEPT Center, by Delta Electronics, and by TerraSwarm, one of six centers of STARnet, a Semiconductor Research Corporation program sponsored by MARCO and DARPA.

### References

[1] Lenovo ThinkPad System Management Mode Arbitrary Code Execution 0day Exploit. Available at https://github.com/Cr4sh/ThinkPwn.git.
[2] T. Alves and D. Felton. TrustZone: Integrated Hardware and Software Security. Information Quarterly, 3(4):18–24, 2004.
[3] I. Anati, S. Gueron, S. P. Johnson, and V. R. Scarlata. Innovative Technology for CPU Based Attestation and Sealing. In Proceedings of the 2nd International Workshop on Hardware and Architectural Support for Security and Privacy, HASP, volume 13, 2013.
[4] K. Asanovic, R. Avizienis, J. Bachrach, S. Beamer, D. Biancolin, C. Celio, H. Cook, D. Dabbelt, J. Hauser, A. Izraelevitz, et al. The Rocket Chip Generator. EECS Department, University of California, Berkeley, Tech. Rep. UCB/EECS-2016-17, 2016.
[5] K. Asanović and D. A. Patterson. Instruction Sets Should Be Free: The Case For RISC-V. EECS Department, University of California, Berkeley, Tech. Rep. UCB/EECS-2014-146, 2014.
[6] M. Barbosa, B. Portela, G. Scerri, and B. Warinschi. Foundations of Hardware-Based Attested Computation and Application to SGX. In IEEE European Symposium on Security and Privacy, EuroS&P 2016, Saarbrücken, Germany, March 21-24, 2016, pages 245–260, 2016.
[7] M. Barnett, B. E. Chang, R. DeLine, B. Jacobs, and K. R. M. Leino. Boogie: A Modular Reusable Verifier for Object-Oriented Programs. In FMCO ’05, LNCS 4111, pages 364–387, 2005.
[8] G. Barthe, P. R. D’Argenio, and T. Rezk. Secure information flow by self-composition. Mathematical Structures in Computer Science, 21(6):1207–1252, 2011.
[9] Y. Bertot and P. Castéran. Interactive Theorem Proving and Program Development: Coq’Art: The Calculus of Inductive Constructions. Springer Science & Business Media, 2013.
[10] K. Bhargavan, C. Fournet, and M. Kohlweiss. miTLS: Verifying Protocol Implementations against Real-World Attacks. IEEE Security & Privacy, 14(6):18–25, 2016.
[11] J. Bonneau and I. Mironov. Cache-Collision Timing Attacks Against AES, pages 201–215. Springer Berlin Heidelberg, Berlin, Heidelberg, 2006.
[12] F. Brasser, U. Müller, A. Dmitrienko, K. Kostiainen, S. Capkun, and A. Sadeghi. Software Grand Exposure: SGX Cache Attacks Are Practical. CoRR, abs/1702.07521, 2017.
[13] M. C. Browne, E. M. Clarke, and O. Grumberg. Characterizing Finite Kripke Structures in Propositional Temporal Logic. Theoretical Computer Science, 59:115–131, 1988.
[14] B. B. Brumley and N. Tuveri. Remote Timing Attacks Are Still Practical. In Proceedings of the 16th European Conference on Research in Computer Security, ESORICS’11, pages 355–371, Berlin, Heidelberg, 2011. Springer-Verlag.
[15] D. Brumley and D. Boneh. Remote Timing Attacks Are Practical. In Proceedings of the 12th Conference on USENIX Security Symposium - Volume 12, SSYM’03, pages 1–1, Berkeley, CA, USA, 2003. USENIX Association.
[16] D. Champagne and R. B. Lee. Scalable architectural support for trusted software. In High Performance Computer Architecture (HPCA), 2010 IEEE 16th International Symposium on, pages 1–12. IEEE, 2010.
[17] A. Chaudhuri. Language-based security on Android. In Proceedings of the 2009 Workshop on Programming Languages and Analysis for Security, PLAS 2009, Dublin, Ireland, 15-21 June, 2009, pages 1–7, 2009.
[18] C.-T. Chou, P. K. Mannava, and S. Park. A simple method for parameterized verification of cache coherence protocols. In A. J. Hu and A. K. Martin, editors, Proceedings of the 5th International Conference on Formal Methods in Computer-Aided Design, pages 382–398, Berlin, Heidelberg, 2004. Springer Berlin Heidelberg.
[19] M. R. Clarkson and F. B. Schneider. Hyperproperties. Journal of Computer Security, 18(6):1157–1210, Sept. 2010.
[20] V. Costan and S. Devadas. Intel SGX Explained. Cryptology ePrint Archive, Report 2016/086, 2016. http://eprint.iacr.org/2016/086.
[21] V. Costan, I. Lebedev, and S. Devadas. Sanctum: Minimal Hardware Extensions for Strong Software Isolation. In 25th USENIX Security Symposium (USENIX Security 16), pages 857–874, Austin, TX, 2016. USENIX Association.
[22] A. Datta, J. Franklin, D. Garg, and D. Kaynar. A Logic of Secure Systems and Its Application to Trusted Computing. In Proceedings of the 2009 30th IEEE Symposium on Security and Privacy, SP ’09, pages 221–236, Washington, DC, USA, 2009. IEEE Computer Society.
[23] L. de Moura and N. Bjørner. Z3: An Efficient SMT Solver. In TACAS ’08, pages 337–340, 2008.
[24] R. DeLine and K. R. M. Leino. BoogiePL: A typed procedural language for checking object-oriented programs. Technical Report MSR-TR-2005-70, Microsoft Research, 2005.
[25] L. Domnitser, A. Jaleel, J. Loew, N. Abu-Ghazaleh, and D. Ponomarev. Non-monopolizable caches: Low-complexity mitigation of cache side channel attacks. Transactions on Architecture and Code Optimization (TACO), 2012.