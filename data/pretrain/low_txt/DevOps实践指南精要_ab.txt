### 自动化测试与数据集

**问题：**
自动化测试使用了非常小的数据集，导致结果不够真实。

**现状：**
- 交叉培训开发人员进行自动化Schema变更。
- 每天执行这些变更，并移除了与DBA的交接环节。
- 在脱敏的客户数据上进行真实的压力测试。

**结果：**
- 生产环境事故下降91%。
- 平均恢复时间（MTTR）下降80%。
- 生产环境部署前置时间从14天减少到1天。

### Etsy—自服务开发者部署案例

**概述：**
Etsy的部署可以由任何希望执行部署的人进行，包括开发、运维和信息安全团队成员。该流程既安全又常规化，新员工在入职第一天就可以进行生产环境部署。

**流程：**
- 工程师进入一个聊天室，将自己加入部署队列中，并跟踪部署活动进展。
- 鼓励工程师相互帮助。
- 目标是实现简单且安全的生产环境部署，尽量减少步骤和仪式。

**解决方案：**
- 在提交代码之前，开发人员在一分钟内运行4500个单元测试。
- 所有外部调用（如数据库）都被模拟。
- 代码提交到主干后，超过7000个自动化测试在CI服务器上执行。
- 最长的测试可在11分钟内完成；如果顺序执行则需要半小时。
- 测试被拆分为不同的子集，在10台机器上并行执行。
- 进行系统级测试（冒烟测试），通过curl调用PHPUnit测试案例。
- 端到端GUI驱动的测试在QA或准生产环境中进行。
- 一键式部署QA、准生产和生产环境。
- 在IRC聊天室中的人员会知道部署了哪些代码，并提供diff链接。
- 不在聊天室中的人通过邮件等方式通知。

**效果：**
- 2009年，Etsy的部署过程充满压力和恐惧。
- 2011年，部署变得例行化，每天进行25到50次。
- 帮助工程师快速将代码推送到生产环境，更快地交付价值给客户。

### Dixons Retail—蓝绿部署POS系统

**背景：**
Dixons Retail是英国最大的零售商之一，拥有数千个分布在数百家零售商店的POS系统。尽管蓝绿部署通常用于在线Web服务，但它也可以显著降低POS系统升级的风险。

**传统方法：**
- 升级POS系统是一个大规模的瀑布项目。
- 客户端和服务端同时升级，导致长时间的不可用（通常整个周末）。
- 显著的网络带宽需求（推送新客户端软件到零售商店）。
- 如果未按计划进行，会给商店运营带来混乱。

**解决方案：**
- 蓝绿策略：建立两个服务端生产环境版本，支持新旧客户端版本。
- 在计划的POS升级前，通过缓慢的网络向零售商店发送客户端新版本安装包。
- 新软件保持非活跃状态，而旧版本正常运行。
- 当所有POS客户端就绪且升级测试成功后，新客户端软件部署到所有商店。
- 商店经理有权决定是否发布新版本，可以根据业务需要选择升级或等待。

**结果：**
- 发布更加平滑和快速。
- 商店经理满意度提高。
- 减少对商店运营的干扰。

### Facebook Chat—暗启动

**背景：**
2008年，Facebook有超过7000万日活跃用户。聊天功能是最资源密集型的操作之一，特别是保持每个在线用户的在线/空闲/离线状态。这个计算密集型任务花费了一年时间完成。

**解决方案：**
- Chat团队将代码签入版本控制库，每天部署生产环境。
- 初始阶段，聊天功能仅对Chat团队内部可见。
- 然后对所有内部员工可见，但对外部用户隐藏。
- 每个用户Session中的JavaScript都有一个测试工具，聊天UI元素隐藏。
- 浏览器可以发送隐藏的测试聊天信息到后台生产环境的聊天服务，模拟类生产环境的负载。
- 在发布给客户之前找到并修复性能问题。
- 正式发布只需两个步骤：修改Gatekeeper配置，让部分外部用户可见；加载新的JavaScript，呈现UI，并禁用测试。

**结果：**
- 正式发布顺利进行，一夜之间从0扩展到7000万用户。
- 逐步扩大规模，从内部用户到1%，再到5%等。

### Amazon—进化架构

**背景：**
Amazon始于1996年，最初是一个单体应用，运行在Web服务器上并与后台数据库通信。随着业务增长，Obidos（奥比都斯）管理所有业务逻辑，展示逻辑和功能，变得过于复杂和难以扩展。

**解决方案：**
- 采用SOA架构，隔离组件，使其能够快速独立扩展。
- 从2层单体架构转变为完全分布式、去中心化的服务平台。
- 严格的面向服务带来隔离。
- 禁止客户端直接访问数据库，以提高伸缩性和可靠性。
- 开发和运维流程受益于面向服务的方法。
- 每个服务由专门团队负责其功能架构、构建和运维。

**结果：**
- 生产率和稳定性显著提升。
- 2011年，每天执行大约15000次部署。
- 2015年，每天解决136000次部署。

### Blackboard Learn—绞杀者模式

**背景：**
Blackboard Learn是一家技术学习机构，2011年收入为6.5亿美元。自1997年起，代码主要基于J2EE，部分Perl代码嵌入其中。2010年，老系统的复杂性和增加的前置时间成为问题。

**解决方案：**
- 2012年开始，进行代码重构，使用绞杀者模式。
- 创建构件块，使开发者能够在分离的模块上工作，与单体代码基解耦，通过特定API访问。
- 开发者更自主，无需与其他开发组大量沟通和协调。
- 单体应用仓库代码开始减少，因为代码转移到构件块仓库。
- 每个工程师选择在构件块仓库工作，更加自主、自由和安全。

**结果：**
- 改进代码模块化。
- 工作更加独立和自由。
- 更快更好的反馈，更高的质量。

### LinkedIn—自助服务指标创建

**背景：**
LinkedIn在2011年开始创建自助服务指标。

### Netflix—自动扩展容量

**背景：**
Netflix开发了Scryer工具，作为Amazon Auto Scaling的补充，根据历史使用模式预测客户需求并分配必要的容量。

**问题：**
- 处理快速峰值。
- AWS实例启动过慢（10-45分钟）。
- 中断后迅速缩减的客户需求导致AAS移除大量计算资源。
- AAS在容量安排时未考虑流量使用模式。

**解决方案：**
- Scryer使用差异点分析排除异常点，然后使用FFT快速傅里叶变换、线性回归等技术保护合法流量。

**结果：**
- 显著提升客户访问体验。
- 改进服务可用性。
- 降低Amazon EC2成本。

### Google—发布和交接准备审查

**背景：**
Google的SRE（Site Reliability Engineering）团队成立于2004年，从最初的7人发展到2014年的1200人。即使新产品足够重要，开发团队仍需自行管理服务至少6个月，才能申请SRE支持。

**解决方案：**
- 发布新服务的安全检查清单。
- **Launch Readiness Review (LRR)**：面向用户和接受生产流量之前。
- **Hand-off Readiness Review (HRR)**：服务转交给运维团队，LRR之后数月。
- 每个阶段分配一个SRE帮助理解和满足需求。
- 让产品团队自行管理生产环境的服务，按照运维方式工作。
- 根据LRR和HRR指导，服务转交更容易和可预测。
- 上下游共情，SRE在早期帮助产品团队，成为重要的文化规范。

**结果：**
- 服务转交更顺畅和可预测。
- 提高上下游协作效率。

### 总结
通过上述案例，我们可以看到自动化测试、自服务部署、蓝绿部署、暗启动、进化架构、绞杀者模式、自助服务指标创建、自动扩展容量以及发布和交接准备审查等方法在不同公司中的成功应用。这些方法不仅提高了生产效率和稳定性，还增强了团队的协作和创新能力。