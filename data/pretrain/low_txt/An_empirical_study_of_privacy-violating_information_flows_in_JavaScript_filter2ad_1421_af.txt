# Search Engine and Event Tracking

## Events
- Copy, Mouseover
- Copy, Mouseover
- Copy, Mouseover
- Copy, Mouseover
- Copy, Mouseover
- Copy, Mouseover
- Copy, Mouseover

## Table 4: Websites Utilizing Real Behavior Sniffing via tynt.com

We identified that 7 websites perform covert keyboard and mouse tracking, which we could reliably replicate. These 7 websites are listed in Table 3. For each site, we provide its Alexa rank, URL, a brief description, and the events being tracked covertly.

### Covert Click Tracking
One may be surprised to see "clicking" as an event being tracked covertly. When a user clicks on a link, there is a clear visual cue that information is being sent over the network, as the target of the link will know that the user has clicked. However, when we list clicking as being tracked covertly, it means there is an additional event handler that tracks the click and sends information about the click to another server. Google, for example, records clicks through an event handler without any visual cue (we do not include Google in Table 3 because our analysis only covers the front pages of websites, and Google's tracking occurs on the search results page).

### Notable Example: Microsoft.com
The most notable example in Table 3 is the microsoft.com site, which covertly tracks clicking and mouse behavior over many links on the front page and sends the information to the web statistics site webtrends.com.

### Cases of Visible Tracking
Of the 10 sites sampled, 3 were cases of visible tracking despite our filtering heuristic. In one case, the server responded with very small images (less than 100 bytes) that were redrawn in response to mouse-over events. In another case, the server responded with small JSON commands that caused parts of the web page to be redrawn. In all these cases, there was a clear visual cue that information was being sent to the server.

### Use of Tracking Libraries
Of the 115 sites where filtered flows were reported, 7 used a behavior tracking software product developed by tynt.com to track what is copied off the sites. These 7 websites are listed in Table 4. The library monitors the copy event. When a visitor copies content from a web page to their clipboard, the library inserts the URL of the page into the copied content. Thus, the URL is contained within subsequent pastes from the clipboard, driving more traffic to the URL. Using our framework, we discovered that on each client website, the copied content is also transferred to tynt.com.

### Suspicious Website: huffingtonpost.com
While investigating several sites that installed event handlers, we found that huffingtonpost.com exhibits suspicious behavior. Every article on the site's front page has an on-mouse-over event handler. These handlers collect information about what articles the mouse passes over in a global data structure. Although this information is never sent over the network, we still consider this case suspicious because the infrastructure is present and actively collects information locally.

## Related Work

Information flow [7] and non-interference [11] have been used to formalize fine-grained isolation for nearly three decades. Several static techniques ensure that certain kinds of inputs do not flow into certain outputs, including type systems [31, 23], model checking [28], Hoare-logics [1], and dataflow analyses [18, 26]. The most expressive policies are captured by the dependent type system of [21], which allows the specification and (mostly) static enforcement of rich flow and access control policies, including the dynamic creation of principals and declassification of high-security information. Unfortunately, fully static techniques are not applicable in our setting, as parts of the code only become available at runtime and often rely on underlying program structure (e.g., a static type system).

Several authors have investigated the use of dynamic taint propagation and checking using specialized hardware [27, 29], virtual machines [4], binary rewriting [22], and source-level rewriting [5, 19]. In the late nineties, the JavaScript engine in Netscape 3.0 implemented a Data Tainting module [10], which tracked a single taint bit on different pieces of data. The module was abandoned in favor of signed scripts, which are rarely used in Web 2.0 applications, partly because it led to too many alerts. Our results show that, due to the prevalence of privacy-violating flows in popular Web 2.0 applications, the question of designing efficient, flexible, and usable flow control mechanisms should be revisited.

Recently, Vogt et al. [30] modified the browser’s JavaScript engine to track a taint bit that determines whether a piece of data is sensitive and report an XSS attack if this data is sent to a domain other than the page’s domain. Dhawan and Ganapathy [8] used similar techniques to analyze confidentiality properties of JavaScript browser extensions for Firefox. Our approach provides a different point in the design space. Our policies are more expressive, as our framework can handle both integrity and confidentiality policies, and more fine-grained, as our framework can carry multiple taints from different sources simultaneously, rather than just a single bit of taint. On the downside, our approach is implemented using a JavaScript rewriting strategy rather than modifying the JavaScript runtime, resulting in a larger performance overhead.

Dynamic rewriting approaches for client-side JavaScript information flow have also been investigated in a theoretical setting [5, 19]. Our work distinguishes itself from these more theoretical advances in terms of experimental evaluation: we have focused on implementing a rewriting-based approach that works on a large number of popular sites and evaluating the prevalence of privacy-violating flows on these websites.

One way to ensure safety on the client is to disallow unknown scripts from executing [16]. However, this will likely make it hard to use dynamic third-party content. Finally, Yu et al. [32] present a formal semantics of the interaction between JavaScript and browsers and build a proxy-based rewriting framework for dynamically enforcing automata-based security policies [17]. These policies are quite different from information flow in that they require sparser instrumentation and cannot enforce fine-grained isolation.

The possibility of history sniffing was first raised in the academic community a decade ago [9]. The original form of history sniffing used timing differences between retrieving a resource that is cached (because it has previously been retrieved) and one that is not. Many other forms of history sniffing are possible based on CSS link decoration, some of which (for example, setting the background property of a visited link to `url(...)`) work even when JavaScript is disabled. This, together with the genuine user-interface utility that visited link decoration provides, is the reason that history sniffing is so difficult to address comprehensively in browsers. The potential of history sniffing has been recently proven to be enormous [14]. However, since there has been no public disclosure regarding the use of history sniffing, and no publicly available tools for detecting it, we expect that many malicious sites will prefer the simple, robust approach of querying and exfiltrating link computed style. Accordingly, it is this data flow that we focus on; if there are sites that use other approaches, we will not have detected them. Our goal in this paper is to draw attention to the use of clandestine history sniffing at popular, high-traffic sites, which means that false negatives are acceptable. In future work, we hope to extend our tool to detect other forms of history sniffing as well.

## Conclusions and Future Work

In this paper, we proposed a rewriting-based information flow framework for JavaScript and evaluated the performance of an instantiation of the framework. Our evaluation showed that the performance of our rewriting-based information flow control is acceptable given our engineering and optimization efforts, but it still imposes a perceptible running-time overhead. We also presented an extensive empirical study of the prevalence of privacy-violation information flows, including cookie stealing, location hijacking, history sniffing, and behavior tracking. Our JavaScript information flow framework found many interesting privacy-violating information flows, including 46 cases of real history sniffing over the Alexa global top 50,000 websites, despite some incompleteness.

One direction for future work is a larger-scale study on privacy-violating information flows. Such a study could perform a deeper crawl of the web, going beyond the front pages of websites, and look at more kinds of privacy-violating information flows. Moreover, we would like to investigate the prevalence of security attacks led by privacy-violating information flows, such as phishing and request forgery.

Another direction for future work is to extend our current framework to become a bullet-proof client-side protection mechanism. The primary purpose of our tool so far has been to observe existing flows in the wild, a scenario for which we don’t need to worry about malicious code trying to circumvent our system. However, with additional work, our framework could possibly lead to a protection mechanism as well. For this purpose, we would have to soundly cover all possible forms of information flow, including implicit flow, flows induced by the DOM and browser built-in APIs. In addition, we would also need better performance to deliver a practical browsing experience. However, we believe that with careful and extensive engineering efforts, there is a possibility that our framework could lead to a practical protection mechanism.

## Acknowledgments

This material is based upon work supported by the National Science Foundation under Grant Nos. CCF-0644306, CCF-0644361, CNS-0720802, CNS-0831532, and CNS-0964702. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.

## References

[1] T. Amtoft and A. Banerjee. Information flow analysis in logical form. In R. Giacobazzi, editor, Proceedings of SAS 2004, volume 3148 of LNCS, pages 100–15. Springer-Verlag, Aug. 2004.
[2] L. D. Baron. Preventing attacks on a user’s history through CSS :visited selectors, Apr. 2010. Online: http://dbaron.org/mozilla/visited-privacy.
[3] Bugzilla@Mozilla. Bug 147777 – :visited support allows queries into global history, May 2002. Online: https://bugzilla.mozilla.org/show_bug.cgi?id=147777.
[4] J. Chow, B. Pfaff, T. Garfinkel, K. Christopher, and M. Rosenblum. Understanding data lifetime via whole system simulation. In M. Blaze, editor, Proceedings of USENIX Security 2004, pages 321–36. USENIX, Aug. 2004.
[5] A. Chudnov and D. A. Naumann. Information flow monitor inlining. In M. Backes and A. Myers, editors, Proceedings of CSF 2010. IEEE Computer Society, July 2010.
[6] A. Clover. Timing attacks on Web privacy. Online: http://www.securiteam.com/securityreviews/5GP020A6LG.html, Feb. 2002.
[7] D. E. Denning. A lattice model of secure information flow. Commun. ACM, 19(5):236–243, 1976.
[8] M. Dhawan and V. Ganapathy. Analyzing information flow in JavaScript-based browser extensions. In C. Payne and M. Franz, editors, Proceedings of ACSAC 2009, pages 382–91. IEEE Computer Society, Dec. 2009.
[9] E. W. Felten and M. A. Schneider. Timing attacks on Web privacy. In S. Jajodia, editor, Proceedings of CCS 2000, pages 25–32. ACM Press, Nov. 2000.
[10] D. Flanagan. JavaScript: The Definitive Guide. O’Reilly, fifth edition, Aug. 2006.
[11] J. A. Goguen and J. Meseguer. Security policies and security models. In Proceedings of IEEE Security and Privacy (“Oakland”) 1982, pages 11–20. IEEE Computer Society, Apr. 1982.
[12] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell. Protecting browser state from Web privacy attacks. In C. Goble and M. Dahlin, editors, Proceedings of WWW 2006, pages 737–44. ACM Press, May 2006.
[13] M. Jakobsson and S. Stamm. Invasive browser sniffing and countermeasures. In C. Goble and M. Dahlin, editors, Proceedings of WWW 2006, pages 523–32. ACM Press, May 2006.
[14] A. Janc and L. Olejnik. Feasibility and real-world implications of Web browser history detection. In C. Jackson, editor, Proceedings of W2SP 2010. IEEE Computer Society, May 2010.
[15] D. Jang, R. Jhala, S. Lerner, and H. Shacham. Rewriting-based dynamic information flow for JavaScript. Technical report, University of California, San Diego, Jan. 2010. Online: http://pho.ucsd.edu/rjhala/dif.pdf.
[16] T. Jim, N. Swamy, and M. Hicks. Defeating script injection attacks with browser-enforced embedded policies. In P. Patel-Schneider and P. Shenoy, editors, Proceedings of WWW 2007, pages 601–10. ACM Press, May 2007.
[17] H. Kikuchi, D. Yu, A. Chander, H. Inamura, and I. Serikov. JavaScript instrumentation in practice. In G. Ramalingam, editor, Proceedings of APLAS 2008, volume 5356 of LNCS, pages 326–41. Springer-Verlag, Dec. 2008.
[18] M. S. Lam, M. Martin, V. B. Livshits, and J. Whaley. Securing Web applications with static and dynamic information flow tracking. In R. Glück and O. de Moor, editors, Proceedings of PEPM 2008, pages 3–12. ACM Press, Jan. 2008.
[19] J. Magazinius, A. Russo, and A. Sabelfeld. On-the-fly inlining of dynamic security monitors. In K. Rannenberg and V. Varadharajan, editors, Proceedings of SEC 2010, Sept. 2010.
[20] L. A. Meyerovich and V. B. Livshits. Conscript: Specifying and enforcing fine-grained security policies for JavaScript in the browser. In Proceedings of IEEE Security and Privacy (“Oakland”) 2010, pages 481–496. IEEE Computer Society, 2010.
[21] A. C. Myers. Programming with explicit security policies. In M. Sagiv, editor, Proceedings of ESOP 2005, volume 3444 of LNCS, pages 1–4. Springer-Verlag, Apr. 2005.
[22] J. Newsome and D. X. Song. Dynamic taint analysis for automatic detection, analysis, and signature generation of exploits on commodity software. In D. Boneh and D. Simon, editors, Proceedings of NDSS 2005. ISOC, Feb. 2005.
[23] F. Pottier and V. Simonet. Information flow inference for ML. In J. C. Mitchell, editor, Proceedings of POPL 2002, pages 319–330. ACM Press, Jan. 2002.
[24] N. Provos, D. McNamee, P. Mavrommatis, K. Wang, and N. Modadugu. The ghost in the browser: Analysis of Web-based malware. In N. Provos, editor, Proceedings of HotBots 2007. USENIX, Apr. 2007.
[25] A. Russo, A. Sabelfeld, and A. Chudnov. Tracking information flow in dynamic tree structures. In M. Backes and P. Ning, editors, Proceedings of ESORICS 2009, volume 5789 of LNCS, pages 86–103. Springer-Verlag, Sept. 2009.
[26] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting format string vulnerabilities with type qualifiers. In D. Wallach, editor, Proceedings of USENIX Security 2001, pages 201–17. USENIX, Aug. 2001.
[27] G. E. Suh, J. W. Lee, D. Zhang, and S. Devadas. Secure program execution via dynamic information flow tracking. In K. McKinley, editor, Proceedings of ASPLOS 2004, pages 85–96. ACM Press, Oct. 2004.
[28] T. Terauchi and A. Aiken. Secure information flow as a safety problem. In C. Hankin, editor, Proceedings of SAS 2005, volume 3672 of LNCS, pages 352–67. Springer-Verlag, Sept. 2005.
[29] N. Vachharajani, M. J. Bridges, J. Chang, R. Rangan, G. Ottoni, J. A. Blome, G. A. Reis, M. Vachharajani, and D. I. August. RIFLE: An architectural framework for user-centric information-flow security. In A. González and J. P. Shen, editors, Proceedings of MICRO 2004, pages 243–54. IEEE Computer Society, Dec. 2004.
[30] P. Vogt, F. Nentwich, N. Jovanovic, E. Kirda, C. Krügel, and G. Vigna. Cross-site scripting prevention with dynamic data tainting and static analysis. In W. Arbaugh and C. Cowan, editors, Proceedings of NDSS 2007. ISOC, Feb. 2007.
[31] D. Volpano and G. Smith. Verifying secrets and relative secrecy. In T. Reps, editor, Proceedings of POPL 2000, pages 268–76. ACM Press, Jan. 2000.
[32] D. Yu, A. Chander, N. Islam, and I. Serikov. JavaScript instrumentation for browser security. In M. Felleisen, editor, Proceedings of POPL 2007, pages 237–49. ACM Press, Jan. 2007.