### C. How Can a Cyber-criminal Evade Nazca?

Cyber-criminals can employ several strategies to evade detection by Nazca. One method is the use of encrypted protocols. While HTTPS has its advantages and drawbacks, custom encryption protocols are also an option. However, these custom channels may be blocked by corporate firewalls, limiting the pool of potential victims.

A more sophisticated approach involves piggybacking on popular software channels, such as Skype. This method can bypass Nazca, but it still restricts the number of potential targets. Additionally, service providers have a vested interest in preventing misuse of their platforms, as malicious activities can harm their customers and ultimately damage their business.

Another evasion technique is to maintain small, independent malicious infrastructures. Although this would render our detection step ineffective, techniques like Dedicated Malware Hosts Detection could still identify these structures.

The most effective evasion strategy we foresee is the continuous creation and rapid rotation of new, independent malware infrastructures. Nazca requires multiple connections to a malware infrastructure before it can detect it (typically around five connections). If the cyber-criminal switches to a completely different infrastructure before Nazca can detect the previous one, they can avoid detection and its consequences, such as blocking connections to their domains. However, the new infrastructure must be entirely independent, with different domains, hosts, URL structures, and files. The clients contacted by the new infrastructure must also be new. Otherwise, after a few iterations, the infected clients would become noticeable in our graph, and Nazca would flag connections to previously unseen domains from these clients. This approach is challenging for cyber-criminals, increasing their operational costs while reducing the average lifespan and number of infections.

Another evasion technique is to bypass Nazca entirely by distributing malware disguised as multimedia files. We have observed simple cases where malware was distributed with a GIF image header, which Nazca detected due to mutations in the images. More advanced methods might use steganography to enhance stealth. If such attacks become more common, Nazca will need to drop its prefilter on images, potentially leading to a performance loss and an increase in false detections. Ultimately, steganalysis detectors may become necessary to combat this trend.

### D. What is the Minimum Scale of the Network on Which Nazca Can Operate?

Two key factors determine the minimum scale of the network for Nazca: the observation timespan and the number of clients in the traffic. Before becoming operational, Nazca must observe enough traffic to learn and tune various thresholds. The more data collected, the more precise Nazca becomes. In our training dataset with 8,813 clients, Nazca began performing detections after observing less than six hours of traffic. In smaller networks, this learning period will be longer, inversely proportional to the number of users.

In addition to the initial learning phase, Nazca must observe a few interactions with the malware distribution networks to achieve successful detections. Therefore, the number of users in the traffic must be sufficient to provide a comprehensive view of these distribution infrastructures. In our datasets, 7.17% of the clients came into contact with distribution infrastructures. As a reference point, we identified several distribution infrastructures using the traffic of 50 randomly chosen infected clients. Given the fraction of infected clients in our dataset, Nazca could operate with approximately 700 clients. With fewer clients, Nazca's performance gradually degrades.

Due to the sensitive nature of ISP traffic data, we were unable to obtain similar datasets from other ISPs. We are currently developing a self-contained version of Nazca that ISPs can deploy, allowing us to validate our system under diverse conditions.

### E. What is Nazca's Space/Time Performance?

In our experiments, we ran the Candidate Selection stage in real-time with traffic collection on a four-core server with 12 GB of memory. This stage is critical for performance, as it reduces the number of entities (URLs, domains, hosts) to be processed by the Detection stage by a factor of 20. Thanks to this reduction, in the Detection stage, we generated only 40/58 non-trivial graphs (i.e., graphs with more than 10 nodes) in our 2/7-day dataset. We build graphs incrementally every six hours, and a graph can take up to ten minutes to build from scratch, including all incremental updates. The cumulative build time for trivial graphs is under five minutes.

For each connection, Nazca stores the source and destination IP addresses, TCP port, HTTP User-Agent, and an MD5 hash of the payload and its MIME type. To manage database size, we perform optimizations such as deduplicating strings and keeping pointers to them. For example, the training dataset, containing up to 10 kilobytes of data per connection, requires 470 GB of storage. Nazca's database representation of this data takes 4.92 GB, accounting for 286 KB of data per client per day. Nazca does not need to keep more than a few days of data, as it can operate with a sliding time window of collected data. These space requirements can be further reduced using systems like Time Machine [4].

### F. How Can Nazca be Used?

Nazca outputs a set of web downloads, including the file and the URL it was downloaded from. This information can be used to augment blacklists and prevent additional clients from contacting infection or Command & Control (C&C) hosts. Network administrators can also identify all clients that may have been infected and initiate appropriate cleanup actions.

### G. Can Nazca Benefit from Third-party Blacklists?

Third-party blacklist records can be added to the candidates selected in the Candidate Selection Step, providing a richer set of candidates for generating malicious neighborhood graphs. This gives more insight into the malicious activities represented by these graphs.

### VIII. RELATED WORK

#### Malware Detection

To identify malicious web pages, researchers have adopted three main strategies: (i) visiting them with honeyclients, (ii) statically/dynamically analyzing their content, and (iii) studying the set of malware distribution paths leading to their exploitation backends.

Honeyclients, such as CAPTURE-HPC [15] and PHONEYC [16], visit web pages with vulnerable browsers in virtual machines, looking for signs of infection. This approach has very low false positives but does not scale well, as each page must be tested with a wide variety of browser configurations [17]. Additionally, this method is vulnerable to fingerprinting and evasions [1], leading to a high number of false negatives.

A more efficient solution is to perform content analysis, recognizing patterns known to be malicious [18], [19], or to conduct static [20] or dynamic [21] analysis of JavaScript code. These solutions are becoming less effective as cyber-criminals improve their code obfuscation and ability to fingerprint analysis platforms. Researchers now consider evolving evasions against their systems as a sign of maliciousness [22].

#### Malware Distribution Infrastructures

To overcome the limitations of previous solutions, researchers have focused on studying and detecting malicious paths as a whole, from the initial landing pages to the infection page. Previous works have examined the infrastructures and economies of malvertising [24], Search-Engine Optimization [25], and spam [26]. Infections targeting surfing crowds have been passively detected by analyzing redirection chains in network traffic [11] or actively through honeyclients [27], [10]. Other researchers have proposed reputation-based systems to detect malicious downloads, such as POLONIUM [28] and CAMP [29]. Nazca differs from these approaches by generating graphs containing all the heterogeneous entities involved in the malware distribution network, providing a more complete view of the attackers' systems and the lifecycle of infected hosts.

Once an entry point to these malicious network infrastructures is found, it can be used to explore the structure and interconnections of these networks, thereby detecting more malware sources. Researchers have done this by crawling in WEBCOP [30] and by exploiting search engine indexes to gain a more complete view in EVILSEED [8].

A recent in-depth study by Zhou [9] explores the malicious neighborhoods of an initial set of dedicated malware-spreading hosts through crawling. It uses graph mining to classify Hostname-IP clusters as topologically-dedicated hosts. Like Polonium and Nazca, it is based on the observation that there is a higher density of interconnections among malicious infrastructures than with the rest of the web. Unlike Zhou’s crawlers, Nazca passively inspects users’ activity, making countermeasures such as cloaking, domain takedowns, and parking (when run on live traffic) ineffective against it. Moreover, Nazca does not require an initial seed of malicious hosts to expand from. We speculate that a collaboration between Nazca and Zhou’s work would provide the best insight into malware distribution networks, with Nazca providing the malicious seed to bootstrap Zhou’s expansion process.

### IX. CONCLUSION

We analyzed how successful drive-by download exploits download and install malware programs. Specifically, we developed Nazca, a system that monitors network traffic and distinguishes between downloads of legitimate and malicious programs. To make this distinction, the system observes traffic from many clients in a large-scale network. We use various techniques to identify suspicious downloads, focusing on behaviors typically associated with malicious activity that attempts to avoid traditional defenses. We then aggregate suspicious connections into a malicious neighborhood graph, which provides context and allows us to focus on related malicious entities. This approach removes false positives and paints a better picture of ongoing malware distribution campaigns. We evaluated our system on nine days of ISP traffic, during which Nazca detected almost ten million file downloads.

### ACKNOWLEDGMENTS

This work was supported in part by the Office of Naval Research (ONR) under grant N000140911042, the National Science Foundation (NSF) under grants CNS-0905537 and CNS-0845559, and Secure Business Austria.

### REFERENCES

[1] A. Kapravelos, M. Cova, C. Kruegel, and G. Vigna, “Escape from monkey island: Evading high-interaction honeyclients,” in IEEE Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA), 2011, pp. 124–143.

[2] iMPERVA, “Assessing the effectiveness of antivirus solutions,” Tech. Rep.

[3] A. Gostev, “The darker side of online virus scanners,” http://www.securelist.com/en/weblog?weblogid=208187473.

[4] S. Kornexl, V. Paxson, H. Dreger, A. Feldmann, and R. Sommer, “Building a time machine for efficient recording and retrieval of high-volume network traffic,” in ACM Internet Measurement Conference (IMC), 2005.

[5] Microsoft, “Pre-installed malware in production lines spurs Microsoft’s 3322.org takedown,” http://www.infosecurity-magazine.com/view/28215/.

[6] J. Caballero, C. Grier, C. Kreibich, and V. Paxson, “Measuring pay-per-install: The commoditization of malware distribution.” in USENIX Security Symposium, 2011.

[7] I. S. S. Lab, “Anubis: Analyzing unknown binaries,” http://anubis.iseclab.org/.

[8] L. Invernizzi, P. M. Comparetti, S. Benvenuti, C. Kruegel, M. Cova, and G. Vigna, “Evilseed: A guided approach to finding malicious web pages,” in IEEE Symposium on Security and Privacy, 2012.

[9] Z. Li, S. Alrwais, Y. Xie, F. Yu, M. S. Valley, and X. Wang, “Finding the linchpins of the dark web: a study on topologically dedicated hosts on malicious web infrastructures,” in IEEE Symposium on Security and Privacy, 2013.

[10] S. Lee and J. Kim, “Warningbird: Detecting suspicious URLs in Twitter stream,” in IEEE Symposium on Network and Distributed System Security (NDSS), 2012.

[11] G. Stringhini, C. Kruegel, and G. Vigna, “Shady paths: Leveraging surfing crowds to detect malicious web pages,” in ACM Conference on Computer and Communications Security (CCS), 2013.

[12] C. Seifert and R. Steenson, “Capture-honeypot client (capture-hpc),” https://projects.honeynet.org/capture-hpc.

[22] A. Kapravelos, Y. Shoshitaishvili, M. Cova, C. Kruegel, and G. Vigna, “Revolver: An automated approach to the detection of evasive web-based malware,” in USENIX Security Symposium, 2013.

[23] C. Grier, L. Ballard, J. Caballero, N. Chachra, C. J. Dietrich, K. Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pitsillidis et al., “Manufacturing compromise: the emergence of exploit-as-a-service,” in Proceedings of the 2012 ACM conference on Computer and communications security. ACM, 2012, pp. 821–832.

[24] M. H. Moore, Know your enemy. Cambridge University Press, 2010.

[25] L. Lu, R. Perdisci, and W. Lee, “SURF: Detecting and measuring search poisoning,” in ACM conference on Computer and Communications Security (CCS), 2011, pp. 467–476.

[26] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker, “Spamscatter: Characterizing internet scam hosting infrastructure,” in USENIX Security Symposium, 2007.

[27] J. Zhang, C. Seifert, J. W. Stokes, and W. Lee, “ARROW: Generating signatures to detect drive-by downloads,” in International World Wide Web Conference (WWW), 2011.

[28] D. H. Chau, C. Nachenberg, J. Wilhelm, A. Wright, and C. Faloutsos, “Polonium: Tera-scale graph mining and inference for malware detection,” in SIAM International Conference on Data Mining (SDM), 2011.

[29] M. A. Rajab, L. Ballard, N. Lutz, P. Mavrommatis, and N. Provos, “CAMP: Content-agnostic malware protection,” in IEEE Network and Distributed Systems Security Symposium (NDSS), 2013.

[30] J. W. Stokes, R. Andersen, C. Seifert, and K. Chellapilla, “WebCop: Locating neighborhoods of malware on the web,” in USENIX Workshop on Large-Scale Exploits and Emergent Threats, 2010.

[13] S. Takashi Katsuki, “Malware targeting Windows 8 uses Google Docs,” http://www.symantec.com/connect/blogs/malware-targeting-windows-8-uses-google-docs.

[14] C. Squared, “Killing with a borrowed knife: Chaining core cloud service profile infrastructure for cyber attacks,” http://www.cybersquared.com/killing-with-a-borrowed-knife-chaining-core-cloud-service-profile-infrastructure-for-cyber-attacks/.

[15] C. Seifert and R. Steenson, “Capture-honeypot client (capture-hpc),” pp. Available at https://projects.honeynet.org/capture-hpc, 2006.

[16] J. Nazario, “Phoneyc: A virtual client honeypot,” in USENIX conference on Large-scale exploits and emergent threats: botnets, spyware, worms, and more, 2009.

[18] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker, “Beyond blacklists: Learning to detect malicious web sites from suspicious URLs,” in ACM SIGKDD International Conference on Knowledge discovery and Data Mining, 2009, pp. 1245–1254.

[19] J. P. John, F. Yu, Y. Xie, A. Krishnamurthy, and M. Abadi, “DESEO: Combating search-result poisoning.” in USENIX Security Symposium, 2011.

[20] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert, “Zozzle: Low-overhead mostly static JavaScript malware detection,” in USENIX Security Symposium, 2011.

[21] C. Kolbitsch, B. Livshits, B. Zorn, and C. Seifert, “Rozzle: De-cloaking internet malware,” in IEEE Symposium on Security and Privacy, 2012, pp. 443–457.