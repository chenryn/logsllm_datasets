# Performance Analysis of Dynamic Power Management (DPM) in RPC and Streaming Benchmarks

## 1. Introduction
This document provides a detailed performance analysis of the impact of Dynamic Power Management (DPM) on two case studies: Remote Procedure Call (RPC) and streaming benchmarks. The analysis is conducted using both Markovian and general models, and the results are compared to evaluate the effectiveness and transparency of DPM.

## 2. RPC Benchmark Analysis

### 2.1. Performance Metrics
The performance metrics of interest are defined as follows:
- **Throughput**: Number of processed result packets.
- **Waiting Time**: Time spent by clients waiting for server responses.
- **Energy Consumption**: Energy consumed by the server in different states (idle, busy, and awaking).

These metrics are expressed in the companion language of Æmilia:
```plaintext
MEASURE throughput IS
ENABLED(C.process_result_packet) -> TRANS_REWARD(1);

MEASURE waiting_time IS
ENABLED(C.monitor_waiting_client) -> STATE_REWARD(1);

MEASURE energy IS
ENABLED(S.monitor_idle_server) -> STATE_REWARD(2);
ENABLED(S.monitor_busy_server) -> STATE_REWARD(3);
ENABLED(S.monitor_awaking_server) -> STATE_REWARD(2);
```

### 2.2. Results
The results of the performance analysis for the Markovian model of the RPC benchmark are shown in Figure 3 (left). The throughput, average waiting time, and energy per request are plotted as functions of the DPM timeout. The energy per request is calculated as the ratio of energy consumption to throughput.

- **Without DPM (dot-dashed lines)**: No power management is applied.
- **With DPM (solid lines)**: Power management is applied with varying timeouts.

As expected, shorter timeouts lead to a more significant impact of DPM. The extreme cases are:
- **Timeout = 0 ms**: DPM issues a shutdown command as soon as the server goes idle, leading to maximum DPM impact.
- **Timeout = ∞ ms**: DPM never issues shutdown commands, resulting in no DPM effect.

It is noted that DPM is not counterproductive in terms of energy, but it does introduce performance penalties such as reduced throughput and increased waiting time.

## 3. Streaming Benchmark Analysis

### 3.1. Parameters
For the Markovian model of the streaming benchmark, the following parameters are assumed:
- Access point buffer size: 10
- Client buffer size: 10
- Average server service time: 67 ms
- Average packet propagation time: 4 ms
- Packet loss probability: 0.02
- Average NIC checking time: 5 ms
- Average NIC awaking time: 15 ms
- Average initial client delay: 684 ms
- Average client rendering time: 67 ms
- Average DPM shutdown period: 5 ms
- Average DPM awake period: 0 to 800 ms

### 3.2. Performance Metrics
The performance metrics for the streaming application are:
- **Energy per Frame**: Average energy consumed by the NIC to receive each frame.
- **Loss Rate**: Probability of losing a frame due to a buffer-full event.
- **Miss Rate**: Probability of violating a real-time constraint due to a buffer-empty event.
- **Quality of Service (QoS)**: Probability of delivering a video frame in time.

These metrics are plotted in Figure 4 as functions of the DPM awake period.

### 3.3. Results
- **Without DPM (dot-dashed lines)**: No power management is applied.
- **With DPM (solid lines)**: Power management is applied with varying awake periods.

As expected, DPM has a larger impact for longer awake periods. The longer the awake period, the longer the sleep time of the NIC, which reduces energy consumption but degrades service quality. The loss rate is non-monotonic, explained by the interplay between the access point and client-side buffers.

For awake periods between 0 and 100 ms, the energy per frame decreases rapidly, while the QoS remains high. For awake periods above 100 ms, the marginal energy savings become negligible, and the QoS degrades significantly. An awake period of 50 ms provides about 70% energy savings with a negligible impact on QoS.

## 4. General Model Validation

### 4.1. Model Description
The general model is obtained from the Markovian model by replacing exponentially distributed delays with generally distributed delays. This provides a more realistic description of the system with and without DPM.

### 4.2. Validation
The general model is validated by comparing its performance measures with those of the Markovian model. The results for the RPC benchmark are shown in Figure 5, demonstrating good agreement between the two models.

### 4.3. Application to RPC
The parameters for the general model of the RPC benchmark are similar to those of the Markovian model, with the exception that some parameters are now deterministic, and the packet propagation time is normally distributed.

The results for the general model (right-hand-side graphs of Figure 3) show a bimodal dependence on the DPM timeout. For timeouts shorter than the average idle period, energy consumption grows linearly with the timeout, while the waiting time and throughput remain constant. For longer timeouts, DPM has no effect on the measured parameters.

### 4.4. Application to Streaming
The parameters for the general model of the streaming application are based on real-world measurements. The results are reported in Figure 6, showing a similar energy per frame dependency on the awake period as in the Markovian model. However, there are significant differences in the behavior of other performance metrics, making the simulation results more informative.

## 5. Conclusion

The proposed methodology for assessing the impact of DPM on system functionality and performance is applied to two realistic case studies. The results show that DPM can be transparent to the user in terms of performance, provided the DPM parameters are appropriately set. The tradeoff between energy consumption and performance metrics is summarized in Figures 7 and 8, highlighting the differences between Markovian and general models.

## References
[1] L. Benini, A. Bogliolo, and G. De Micheli, “A Survey of Design Techniques for System-Level Dynamic Power Management”, in IEEE Trans. on VLSI Systems 8:299-316, 2000.
[2] M. Bernardo, “TwoTowers 3.0: Enhancing Usability”, in Proc. of the 11th IEEE/ACM Int. Symp. on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (MASCOTS 2003), IEEE-CS Press, pp. 188-193, Orlando (FL), 2003.
[3] M. Bernardo and M. Bravetti, “Performance Measure Sensitive Congruences for Markovian Process Algebras”, in Theoretical Computer Science 290:117-160, 2003.
[4] M. Bernardo, L. Donatiello, and P. Ciancarini, “Stochastic Process Algebra: From an Algebraic Formalism to an Architectural Description Language”, in Performance Evaluation of Complex Systems: Techniques and Tools, LNCS 2459:236-260, 2002.
[5] Cisco System, “Cisco Aironet 350 Series Access Points”, http://www.cisco.com/univercd/cc/td/doc/product/wireless/airo 350/accsspts/index.htm, 2003.
[6] Cisco System, “Cisco Aironet 350 Series Wireless LAN Adapters”, http://www.cisco.com/univercd/cc/td/doc/product/wireless/airo 350/350cards/index.htm, 2003.
[7] R. Focardi and R. Gorrieri, “A Classification of Security Properties”, in Journal of Computer Security 3:5-33, 1995.
[8] J.A. Goguen and J. Meseguer, “Security Policy and Security Models”, in Proc. of the Symp. on Security and Privacy (SSP 1982), IEEE-CS Press, pp. 11-20, 1982.
[9] R.K. Gupta, S. Irani, and S.K. Shukla, “Formal Methods for Dynamic Power Management”, tutorial at IEEE/ACM Int. Conf. on Computer Aided Design (ICCAD 2003), ACM Press, 2003.
[10] LAN/MAN Standards Committee of the IEEE Computer Society, “Part 11: Wireless LAN MAC and PHY Specifications: Higher-Speed Physical Layer Extension in the 2.4 GHz Band”, 1999.
[11] R. Milner, “Communication and Concurrency”, Prentice Hall, 1989.
[12] G. Norman, D. Parker, M. Kwiatkowska, S.K. Shukla, and R.K. Gupta, ”Formal Analysis and Validation of Continuous-Time Markov Chain Based System Level Power Management Strategies”, in Proc. of the IEEE High-Level Design Validation and Test Workshop, IEEE-CS Press, pp. 45-50, 2002.