### Professional Data Sequences and Concept Drift Detection

Prior works [6, 7] have utilized conformal prediction to detect deviations in data sequences from the independent and identically distributed (i.i.d.) assumption, which can be caused by concept drift. The drift is quantified using a martingale function. If the data does not follow the i.i.d. assumption, the conformal predictor outputs an invalid result. This occurs when p-values assigned to true hypotheses about data labels are too small or deviate from uniformity, leading to high values of the martingale. However, this approach does not account for p-values assigned to incorrect hypotheses, which can also lead to misclassification, such as classifying malicious samples as benign. We consider this information crucial, especially in the context of malware evolution, where malicious samples are often designed to be indistinguishable from benign ones, thus receiving high p-values for incorrect hypotheses. Additionally, the martingale approach relies on true labels to study data drift without making predictions, whereas our approach operates without access to true labels and analyzes the predictions made by a given model.

### Comparison with Conformal Prediction

Although the conformal evaluator (CE) is built on top of the conformal predictor (CP), it does not share the same weaknesses as other solutions based on CP [6, 7]. Fern and Dietterich [10] have shown that CP is not suitable for anomaly detection because it outputs a set of labels and needs modification to predict the quality of predictions. We highlight the differences between CP and CE, which make CE better suited for detecting concept drift.

**Conformal Predictor (CP)**: A machine learning classification algorithm that relies on a non-conformity measure (NCM) to compute p-values. For each classification task, CP uses these p-values to introduce credibility—the class with the highest p-value—and confidence, defined as one minus the second-highest p-value. The CP algorithm then outputs either a single class prediction with identified credibility and confidence, or, given a fixed confidence level \(1 - \epsilon\) (where \(\epsilon\) represents the significance level), a prediction set that includes classes above this threshold. This set is proven to cover the true class with a probability not lower than \(1 - \epsilon\).

**Conformal Evaluator (CE)**: Dissects CP metrics to extract p-values, which are used together with the output labels provided by the algorithm under evaluation to build CE metrics. CP ignores these labels as it tries to predict them, while CE uses this information to provide quality metrics for assessing the performance of the encapsulated algorithm. This change is critical for deriving thresholds (computed by Transcend) used to accept or reject a prediction.

The posterior use of labels is a key feature that enables CE to detect concept drift. In contrast, CP is designed as a predictive tool that only uses prior information. Since labels are important pieces of information, CE uses them to build its metrics and assessments (see §2.4 and §3). The labels used by CE are those of the training samples, not the testing samples, which are unavailable at the time of classification.

### Conclusions

We presented Transcend, a fully tunable tool for statistically assessing the performance of a classifier and filtering out unreliable classification decisions. At the heart of Transcend, CE’s statistical confidence provides evidence for better understanding model generalization and class separation. For instance, CE has been successfully adopted to selectively invoke computationally expensive learning-based algorithms when predictions choose classes with low confidence [4], trading off performance for accuracy. Our work details the CE metrics used in [4] and extends it to facilitate the identification of concept drift, thus bridging a fundamental research gap when dealing with evolving malicious software.

We present two case studies as representative use cases of Transcend. Our approach provides sound results for both binary and multi-class classification scenarios on different datasets and algorithms using proper training, calibration, and validation, and testing datasets. The diversity of case studies presents compelling evidence in favor of our framework being generalizable.

### Availability

We encourage the adoption of Transcend in machine learning-based security research and deployments. Further information is available at:
https://s2lab.isg.rhul.ac.uk/projects/ce

### Acknowledgments

This research has been partially supported by the UK EPSRC grants EP/K033344/1, EP/L022710/1, and EP/K006266/1. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research. We are equally thankful to the anonymous reviewers' comments and Roberto Perdisci, our shepherd, for their invaluable comments and suggestions to improve the paper. Additionally, we thank the Technology Integrated Health Management (TIHM) project awarded to the School of Mathematics and Information Security at Royal Holloway as part of an initiative by NHS England supported by Innovate UK. We also thank the authors of [2] for their public dataset used in our evaluation and Mansour Ahmadi for providing the algorithm used in [1].

### References

[1] AHMADI, M., ULYANOV, D., SEMENOV, S., TROFIMOV, M., AND GIACINTO, G. Novel feature extraction, selection, and fusion for effective malware family classification. In Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy (New York, NY, USA, 2016), CODASPY '16, ACM, pp. 183–194.

[2] ARP, D., SPREITZENBARTH, M., HUBNER, M., GASCON, H., AND RIECK, K. DREBIN: Effective and explainable detection of Android malware in your pocket. In 21st Annual Network and Distributed System Security Symposium, NDSS 2014, San Diego, California, USA, February 23-26, 2014 (2014).

[3] BREIMAN, L. Random Forests. Machine Learning 45, 1 (2001), 5–32.

[10] A. Fern and T. Dietterich. “Toward Explainable Uncertainty.” https://intelligence.org/files/csrbai/fern-slides-1.pdf

[4] DASH, S. K., SUAREZ-TANGIL, G., KHAN, S. J., TAM, K., AHMADI, M., KINDER, J., AND CAVALLARO, L. Droidscribe: Classifying Android malware based on runtime behavior. In 2016 IEEE Security and Privacy Workshops, SP Workshops 2016, San Jose, CA, USA, May 22-26, 2016 (2016), pp. 252–261.

[5] DEO, A., DASH, S. K., SUAREZ-TANGIL, G., VOVK, V., AND CAVALLARO, L. Prescience: Probabilistic guidance on the retraining conundrum for malware detection. In Proceedings of the 2016 ACM Workshop on Artificial Intelligence and Security (New York, NY, USA, 2016), AISec '16, ACM, pp. 71–82.

[6] FEDOROVA, V., GAMMERMAN, A. J., NOURETDINOV, I., AND VOVK, V. Plug-in martingales for testing exchangeability online. In Proceedings of the 29th International Conference on Machine Learning, ICML 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012 (2012).

[7] HO, S. A martingale framework for concept change detection in time-varying data streams. In Machine Learning, Proceedings of the Twenty-Second International Conference (ICML 2005), Bonn, Germany, August 7-11, 2005 (2005), pp. 321–327.

[8] HO, S., AND WECHSLER, H. Query by transduction. IEEE Trans. Pattern Anal. Mach. Intell. 30, 9 (2008), 1557–1571.

[9] HO, S., AND WECHSLER, H. A martingale framework for detecting changes in data streams by testing exchangeability. IEEE Trans. Pattern Anal. Mach. Intell. 32, 12 (2010), 2113–2127.

[10] HUBERT, M., AND VANDERVIEREN, E. An adjusted boxplot for skewed distributions. Computational Statistics and Data Analysis 52, 12 (2008), 5186 – 5201.

[11] KAGGLE INC. (BIG 2015). Microsoft Malware Classification Challenge. https://www.kaggle.com/c/malware-classification, 2015.

[12] KANTCHELIAN, A., AFROZ, S., HUANG, L., ISLAM, A. C., MILLER, B., TSCHANTZ, M. C., GREENSTADT, R., JOSEPH, A. D., AND TYGAR, J. D. Approaches to adversarial drift. In AISec'13, Proceedings of the 2013 ACM Workshop on Artificial Intelligence and Security, Co-located with CCS 2013, Berlin, Germany, November 4, 2013 (2013), pp. 99–110.

[13] LI, P., LIU, L., GAO, D., AND REITER, M. K. On challenges in evaluating malware clustering. In Recent Advances in Intrusion Detection, 13th International Symposium, RAID 2010, Ottawa, Ontario, Canada, September 15-17, 2010. Proceedings (2010), pp. 238–255.

[14] LINDORFER, M., NEUGSCHWANDTNER, M., AND PLATZER, C. MARVIN: Efficient and comprehensive mobile app classification through static and dynamic analysis. In 39th IEEE Annual Computer Software and Applications Conference, COMP-SAC 2015, Taichung, Taiwan, July 1-5, 2015. Volume 2 (2015), pp. 422–433.

[15] MAGGI, F., ROBERTSON, W. K., KRÜGEL, C., AND VIGNA, G. Protecting a moving target: Addressing web application concept drift. In Recent Advances in Intrusion Detection, 12th International Symposium, RAID 2009, Saint-Malo, France, September 23-25, 2009. Proceedings (2009), pp. 21–40.

[16] MARICONTI, E., ONWUZURIKE, L., ANDRIOTIS, P., DE CRISTOFARO, E., ROSS, G., AND STRINGHINI, G. Mamadroid: Detecting Android malware by building Markov chains of behavioral models. arXiv preprint arXiv:1612.04433 (2016).

[17] PLATT, J., ET AL. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. Advances in Large Margin Classifiers 10, 3 (1999), 61–74.

[18] RIDGEWAY, G. The state of boosting. Computing Science and Statistics (1999), 172–181.

[19] RIECK, K., HOLZ, T., WILLEMS, C., DÜSSEL, P., AND LASKOV, P. Learning and classification of malware behavior. In Detection of Intrusions and Malware, and Vulnerability Assessment, 5th International Conference, DIMVA 2008, Paris, France, July 10-11, 2008. Proceedings (2008), pp. 108–125.

[20] SHAFER, G., AND VOVK, V. A tutorial on conformal prediction. The Journal of Machine Learning Research 9 (2008), 371–421.

[21] TANG, Y. Extreme Gradient Boosting. https://github.com/dmlc/xgboost.

[22] TEGELER, F., FU, X., VIGNA, G., AND KRUEGEL, C. Botfinder: Finding bots in network traffic without deep packet inspection. In In Proc. Co-NEXT 12 (2012), pp. 349–360.

[23] THOMAS, K., GRIER, C., MA, J., PAXSON, V., AND SONG, D. Design and evaluation of a real-time URL spam filtering service. In 32nd IEEE Symposium on Security and Privacy, S&P 2011, 22-25 May 2011, Berkeley, California, USA (2011), pp. 447–462.

[24] V. VOVK, A. G., AND SHAFER, G. Algorithmic learning in a random world. Springer-Verlag New York, Inc., 2005.

[25] WECHSLER, H. Cyberspace security using adversarial learning and conformal prediction. Intelligent Information Management 7, 04 (2015), 195.

### Appendix A

**Figure 5: Multiclass Classification Case Study: Elements Kept During the Test of the New Class**
- The test elements belong to a new class, so every sample kept will be misclassified.
- The net separation between good and bad performance comes from the perfect classification of training samples used to derive the thresholds.

**Figure 6: Binary Classification Case Study [2]: Complete Comparison Between P-Value and Probability Metrics**
- Across all the threshold range, we can see that the p-value-based thresholding provides better performance than the probability-based one, discarding the samples that would have been incorrectly classified if kept.

**Figure 7: Multiclass Classification Case Study [1]: P-Value Distribution for Samples of Tracur Family Omitted from the Training Dataset**
- As expected, the values are all close to zero.

**Figure 8: Multiclass Classification Case Study [1]: Probability Distribution for Samples of Tracur Family Omitted from the Training Dataset**
- Probabilities are higher than zero and not equally distributed across all families, making the classification difficult.
- Some probabilities are skewed towards large values (i.e., greater than 0.5), further hindering a correct classification result.

**Figure 9: Multiclass Classification Case Study [1]: A New Family is Discovered by Relying on the P-Value Distribution for Known Malware Families**
- The figure shows the amount of conformity each sample has with its own family; for each sample, there is only one family with a high p-value.

**Figure 10: Multiclass Classification Case Study [1]: Probability Distribution for Samples of Families Included in the Training Dataset**
- High probabilities support the algorithm's classification choice.