### 9. Acknowledgements

This work is partially supported by the National Key Basic Research Program of China (Grant No. 2010CB328104), Macau FDCT (Grant No. 061-2011-A3), International S&T Cooperation Program of China (Grant No. 2013DFA10690), US NSF (Grants 1116644, CNS-1318948, and 1262275), and the National Science Foundation of China (Grant No. 61272054). The opinions, findings, conclusions, and recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding agencies.

### 10. References

[1] M. Backes, T. Chen, M. Duermuth, H. Lensch, and M. Welk. "Tempest in a teapot: Compromising reflections revisited." In *Proceedings of the 30th IEEE Symposium on Security and Privacy*, pages 315–327, 2009.

[2] M. Backes, M. Dürmuth, and D. Unruh. "Compromising reflections or how to read LCD monitors around the corner." In *Proceedings of the IEEE Symposium on Security and Privacy*, pages 158–169, 2008.

[3] D. Balzarotti, M. Cova, and G. Vigna. "Clearshot: Eavesdropping on keyboard input from video." In *Proceedings of the 2008 IEEE Symposium on Security and Privacy (SP '08)*, pages 170–183, 2008.

[4] H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. "Speeded-up robust features (SURF)." *Comput. Vis. Image Underst.*, 110(3):346–359, June 2008.

[5] H. Benko, A. D. Wilson, and P. Baudisch. "Precise selection techniques for multi-touch screens." In *Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '06)*, pages 1263–1272, 2006.

[6] R. Biddle, S. Chiasson, and P. van Oorschot. "Graphical passwords: Learning from the first twelve years." *ACM Computing Surveys*, 2012.

[7] G. R. Bradski and A. Kaehler. *Learning OpenCV*. O’Reilly Media, Inc., 1st edition, 2008.

[8] A. Bulling, F. Alt, and A. Schmidt. "Increasing the security of gaze-based cued-recall graphical passwords using saliency masks." In *Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems (CHI '12)*, 2012.

[9] J. Canny. "A computational approach to edge detection." *IEEE Trans. Pattern Anal. Mach. Intell.*, 8(6):679–698, 1986.

[10] N. Dalal and B. Triggs. "Histograms of oriented gradients for human detection." In *Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR '05)*, pages 886–893. IEEE Computer Society, 2005.

[11] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. "Object detection with discriminatively trained part-based models." *IEEE Trans. Pattern Anal. Mach. Intell.*, 32(9):1627–1645, 2010.

[12] C. Forlines, D. Wigdor, C. Shen, and R. Balakrishnan. "Direct-touch vs. mouse input for tabletop displays." In *Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '07)*, pages 647–656, 2007.

[13] H. Grabner, M. Grabner, and H. Bischof. "Real-time tracking via online boosting." In *Proceedings of the British Machine Vision Conference*, 2006.

[14] R. Hartley and A. Zisserman. *Multiple View Geometry in Computer Vision*. Cambridge University Press, 2nd edition, 2003.

[15] S. B. Hirsch. "Secure input system." *United States Patent No. 4,479,112*, 1982.

[16] S. B. Hirsch. "Secure keyboard input terminal." *United States Patent No. 4,333,090*, 1982.

[17] B. Hoanca and K. Mock. "Screen-oriented technique for reducing the incidence of shoulder surfing." In *Proceedings of the International Conference on Security and Management (SAM '05)*, 2005.

[18] P. Huber. *Robust Statistics*. John Wiley & Sons, 1981.

[19] Juniper Networks, Inc. "Juniper Networks Third Annual Mobile Threats Report." http://www.juniper.net/us/en/local/pdf/additional-resources/3rd-jnpr-mobile-threats-report-exec-summary.pdf, 2013.

[20] Y. Ke, R. Sukthankar, and M. Hebert. "Efficient visual event detection using volumetric features." In *Proceedings of the Tenth IEEE International Conference on Computer Vision (ICCV '05)*, pages 166–173, 2005.

[21] D. Kim, P. Dunphy, P. Briggs, J. Hook, J. W. Nicholson, J. Nicholson, and P. Olivier. "Multi-touch authentication on tabletops." In *Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems (CHI '10)*, 2010.

[22] I. Kim. "Keypad against brute force attacks on smartphones." *IET Information Security*, 2012.

[23] J. Koch. "CodeScrambler." http://cydia.saurik.com/package/org.thebigboss.codescrambler/, 2014.

[24] T. Lan, Y. Wang, and G. Mori. "Discriminative figure-centric models for joint action localization and recognition." In *International Conference on Computer Vision (ICCV)*, 2011.

[25] C. Lee. "System and method for secure data entry." *United States Patent Application Publication*, 2011.

[26] Logitech. "Logitech HD Pro Webcam C920." http://www.logitech.com/en-us/product/hd-pro-webcam-c920, 2013.

[27] D. G. Lowe. "Distinctive image features from scale-invariant keypoints." *Int. J. Comput. Vision*, 60(2):91–110, November 2004.

[28] F. Maggi, S. Gasparini, and G. Boracchi. "A fast eavesdropping attack against touchscreens." In *IAS*, pages 320–325. IEEE, 2011.

[29] J. Matas, C. Galambos, and J. Kittler. "Robust detection of lines using the progressive probabilistic Hough transform." *Comput. Vis. Image Underst.*, 78(1):119–137, 2000.

[30] K. E. McIntyre, J. F. Sheets, D. A. J. Gougeon, C. W. Watson, K. P. Morlang, and D. Faoro. "Method for secure PIN entry on touch screen display." *United States Patent No. 6,549,194*, 2003.

[31] M. Muja and D. G. Lowe. "Fast approximate nearest neighbors with automatic algorithm configuration." In *VISAPP International Conference on Computer Vision Theory and Applications*, pages 331–340, 2009.

[32] Plugable. "Plugable USB 2.0 Digital Microscope for Windows, Mac, Linux (2MP, 10x-50x optical zoom, 200x digital magnification)." http://www.amazon.com/Plugable-Digital-Microscope-Windows-Magnification/dp/B00AFH3IN4/ref=sr_1_1?ie=UTF8&qid=1382796731&sr=8-1&keywords=optical+zoom+webcam, 2013.

[33] R. Raguram, A. M. White, D. Goswami, F. Monrose, and J.-M. Frahm. "iSpy: Automatic reconstruction of typed input from compromising reflections." In *Proceedings of the 18th ACM Conference on Computer and Communications Security (CCS '11)*, pages 527–536, 2011.

[34] N. Sae-Bae, K. Ahmed, K. Isbister, and N. Memon. "Biometric-rich gestures: A novel approach to authentication on multi-touch devices." In *Proceedings of the 30th ACM SIGCHI Conference on Human Factors in Computing Systems (CHI '12)*, 2012.

[35] J. Shi and C. Tomasi. "Good features to track." Technical report, 1993.

[36] H.-S. Shin. "Device and method for inputting password using random keypad." *United States Patent No. 7,698,563*, 2010.

[37] X. Suo, Y. Zhu, and G. S. Owen. "Graphical passwords: A survey." In *Proceedings of the Annual Computer Security Applications Conference (ACSAC)*, 2005.

[38] R. Szeliski. *Computer Vision: Algorithms and Applications*. Springer-Verlag New York, Inc., 1st edition, 2010.

[39] Y. Tian, R. Sukthankar, and M. Shah. "Spatiotemporal deformable part models for action detection." In *Proceedings of the 2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR '13)*, pages 2642–2649, 2013.

[40] F. Wang, X. Cao, X. Ren, and P. Irani. "Detecting and leveraging finger orientation for interaction with direct-touch surfaces." In *Proceedings of the 22nd Annual ACM Symposium on User Interface Software and Technology (UIST '09)*, pages 23–32, 2009.

[41] F. Wang and X. Ren. "Empirical evaluation for finger input properties in multi-touch interaction." In *Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '09)*, pages 1063–1072, 2009.

[42] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba. "SUN database: Large-scale scene recognition from abbey to zoo." *IEEE*, pages 3485–3492, 2010.

[43] Y. Xu, J. Heinly, A. M. White, F. Monrose, and J.-M. Frahm. "Seeing double: Reconstructing obscured typed input from repeated compromising reflections." In *Proceedings of the 20th ACM Conference on Computer and Communications Security (CCS '13)*, 2013.

[44] Q. Yan, J. Han, Y. Li, J. Zhou, and R. H. Deng. "Designing leakage-resilient password entry on touchscreen mobile devices." In *Proceedings of the 8th ACM Symposium on Information, Computer and Communications Security (AsiaCCS '13)*, 2013.

[45] Y. Hu, L. Cao, F. Lv, S. Yan, Y. Gong, and T. S. Huang. "Action detection in complex scenes with spatial and temporal ambiguities." *ICCV*, 2009.

[46] J. Y. Bouguet. "Pyramidal implementation of the Lucas-Kanade feature tracker." Intel Corporation, Microprocessor Research Labs, 2000.

[47] Y. Zhang, P. Xia, J. Luo, Z. Ling, B. Liu, and X. Fu. "Fingerprint attack against touch-enabled devices." In *Proceedings of the Second ACM Workshop on Security and Privacy in Smartphones and Mobile Devices (SPSM '12)*, pages 57–68, 2012.

### Appendix

In this appendix, we discuss countermeasures to computer vision-based attacks introduced in this paper and related work. There are several other authentication approaches that are immune to these attacks to some extent, including biometric-rich gesture-based authentication [34, 44, 21] and graphical password schemes [6, 37, 8]. The concept of randomized keyboards has been proposed for both legacy keypads and touch-enabled devices [16, 15, 30, 17, 36, 25, 22]. We have designed and developed the context-aware Privacy Enhancing Keyboard (PEK) for Android for the first time. We have implemented PEK as a third-party app and can also change the internal system keyboard to implement PEK.

#### Design and Implementation of PEK

A software keyboard typically consists of three sub-keyboards:
1. **Primary Sub-Keyboard**: The QWERTY keyboard, which is the most common layout.
2. **Numerical Sub-Keyboard**: This may also contain some symbols.
3. **Symbol Sub-Keyboard**: Contains special symbols.

The layout for these three sub-keyboards is stored in an XML file, which records the positions of keys and their corresponding key codes. The system generates the keyboard by reading the keys from the XML file and placing them in the correct positions.

**PEK Randomization:**
- **Shuffled Keys**: When a keyboard is needed, PEK generates a random sequence of key labels for each of the three different keyboards. As each key is read from the XML, PEK randomly selects an integer between one and the size of the key sequence. This number is used to pick a specific key label from the randomized key sequence, which is then removed from the sequence. The selected key replaces the current key, effectively shuffling the key positions on a normal keyboard.
- **Brownian Motion**: Another version of PEK makes each key move within the keyboard region in a Brownian motion fashion. Each key's position is updated repeatedly according to the Brownian motion, causing the keys to be in constant motion. Even if the same key is pressed multiple times, its position will differ each time. This is an improvement over the shuffled keys version, where the keyboard does not change during a single session of password input.

**Figures:**
- **Figure 22**: PEK with Shuffled Keys
- **Figure 23**: PEK with Brownian Motion

**Figure 24: Input Time of Three Distinct Keyboards**

PEK is context-aware and only pops up the randomized keyboard when the input box is for sensitive information. The Android class `EditorInfo` can be used to detect the type of input box. In our case, the following types are used to identify the password input box:
- `TYPE_NUMBER_VARIATION_PASSWORD`
- `TYPE_TEXT_VARIATION_PASSWORD`
- `TYPE_TEXT_VARIATION_VISIBLE_PASSWORD`
- `TYPE_TEXT_VARIATION_WEB_PASSWORD`

Once the password input box is triggered by the user, a new randomized keyboard is constructed, ensuring that the user sees a different key layout each time they press the password input box.

#### Evaluation of PEK

To measure the usability of PEK, we recruited 20 students (5 female and 15 male) with an average age of 25 years. We implemented a test password input box and generated 30 random four-letter passwords. The students were required to input these 30 passwords using both the shuffled keyboard and the Brownian motion keyboard, and the test app recorded the user input time.

**Table 7: Usability Test**

| Keyboard Type | Median Input Time (Seconds) | Success Rate |
|---------------|-----------------------------|--------------|
| Normal        | 2.235                       | 98.50%       |
| Shuffled Keys | 5.859                       | 98.83%       |
| Brownian Motion | 8.24                        | 94.17%       |

**Figure 24: Box Plot of Input Time for Three Different Keyboards**

- **Normal Keyboard**: Median input time is around 2.2 seconds.
- **Shuffled Keyboard**: Median input time is around 5.9 seconds.
- **Brownian Motion Keyboard**: Median input time is around 8.2 seconds.

The success rate for all three keyboards is high, although it is slightly lower for the Brownian motion keyboard. Participants in our experiments found PEK acceptable when it only popped up the randomized keyboard for sensitive information input.