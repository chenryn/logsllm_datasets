### 7.3 Further Discussion

The For scheme (k=3) is integrated into the code following our robust-by-design method, as detailed in Section 6.2. We consider three variants of this scheme: P1, P2, and P3.

- **P1 (Basic)**: This is the simple version of For, as presented in Figure 8.
- **P2 (Obfuscated)**: This variant includes a mildly obfuscated version with an if statement that always evaluates to true within the loop (an opaque predicate).
- **P3 (Weak)**: This version naively relies on fake inputs, similar to the Split construction discussed in Section 7.3, which is known to be dangerous.

A protection is considered simplified if:
- The number of explored paths for full coverage is significantly lower than expected (for DSE tools).
- No protection code is marked by the analysis tool (Frama-C).
- Running KLEE on the produced code does not show any differences (compilers).

### Results & Observations

Table 5 confirms our expectations. Only Clang is able to simplify our robust-by-design protections (P1 and P2), while the weaker P3 is broken by slicing (GCC, Clang, Frama-C) but not by tainting, as discussed in Section 7.3. Notably, Clang -Ofast simplifies scheme P1 due to loop simplification, rather than slicing, by finding an affine relation between variables and loop counters. The slightly obfuscated version P2 is immune to this specific attack.

### Conclusion

Our robust-by-design method experimentally works as expected against taint and slice (RQ3). However, caution is needed to avoid pattern-like simplifications. In a real scenario, attackers must work with binary code, making static analysis more challenging. Additionally, virtualization, unpacking, or self-modification can be added to path-oriented protections to further thwart static analysis.

### 9. Application: Hardened Benchmark

We propose new benchmarks consisting of 4 programs from Banescu’s dataset and 6 real-world programs from Section 8.2 (excluding GRUB) to advance the state of the art in symbolic deobfuscation. Each program is set up for Path Exploration and Secret Finding, obfuscated with both a path-oriented protection (For k=5, taint- and slice-resistant) and a virtualization layer against human and static attacks. Table 6 shows the performance of KLEE, Triton, Binsec, and Angr (Secret Finding, 24-hour timeout). The hardened codes remain unsolved within the timeout for all tools.

**Table 6: Results on 10 hardened examples (secret finding)**

| Tool      | Unprotected (TO = 10 sec) | Virt ×1 (TO = 5 min) | Hardened – For (k=5) (TO = 24h) |
|-----------|---------------------------|----------------------|---------------------------------|
| KLEE      | 10/10                     | 10/10                | 0/10 ✓                          |
| Binsec    | 10/10                     | 10/10                | 0/10 ✓                          |
| Triton    | 10/10                     | 10/10                | 0/10 ✓                          |
| Angr      | 10/10                     | 10/10                | 0/10 ✓                          |

### 10. Discussion

#### 10.1 On the Methodology

We discuss potential biases in our experimental evaluation:

- **Metrics**: We include overhead metrics (runtime, code size) in addition to the commonly used "DSE slowdown" measure, providing a more comprehensive view of the pros and cons of obfuscation methods.
- **Obfuscation Techniques & Tools**: We use the strongest standard obfuscation methods known against DSE, as identified in previous studies. Tigress, a widely respected and freely available obfuscation tool, is used, and its protections are generally strong.
- **DSE Engines**: We use four symbolic execution engines (KLEE, Binsec, Triton, Angr) working on different program representations (C source, binary) with very similar results. KLEE, in particular, is highly respected and implements advanced path pruning and solving strategies.
- **Benchmarks**: Our benchmarks include synthetic benchmarks from Banescu et al. and 7 larger real-life programs, primarily hash functions. Both source and binary code are used to add variability.

#### 10.2 Generality of Path-Oriented Protections

Path-oriented protections should be effective against a broader class of attacks beyond DSE, including Bounded Model Checking, backward bounded DSE, and abstract interpretation. These methods suffer from path explosion, ineffective refinements, and significant precision loss. Advanced program analysis techniques for loops are still largely open, and even KLEE, which implements path merging, fails against our protections.

#### 10.3 Countermeasures and Mitigations

Slicing, tainting, and pattern attacks are thoroughly discussed in Sections 6.2 and 7. Anti-implicit flow techniques may identify dataflow hidden as control-flow but do not recover precise loop semantics. Obfuscation schemes can be scattered across multiple functions to prevent targeted intra-procedural attacks, and real-life attacks on binary code are extremely difficult. Static analysis is completely broken by packing or self-modification.

### 11. Related Work

We have discussed obfuscation, symbolic execution, and symbolic deobfuscation throughout the paper. Schrittwieser et al. provide an exhaustive survey on program analysis-based deobfuscation, and Schwartz et al. review DSE and tainting for security. Anand et al. describe the major weaknesses of DSE, and Cadar shows how compiler optimizations can alter the performance of symbolic analyzers. Various anti-DSE techniques, such as constraint-based protections and cryptographic hash functions, are also discussed. Systematic evaluations of anti-DSE techniques, such as those by Banescu et al., set the ground for our experimental evaluation.

### 12. Conclusion

Code obfuscation aims to protect proprietary software assets against reverse engineering and tampering. Recently, automated attacks based on symbolic execution (DSE) and semantic reasoning have shown great potential against traditional obfuscation methods. We explore a new class of anti-DSE techniques targeting path exploration, proposing a predictive framework and new lightweight, efficient, and resistant obfuscations. Experimental evaluation indicates that our method critically damages symbolic deobfuscation while incurring only a small overhead.

### References

[1] Tigress challenge. http://tigress.cs.arizona.edu/challenges.html.
[2] S. Anand, E. K. Burke, T. Y. Chen, J. Clark, M. B. Cohen, W. Grieskamp, M. Harman, M. J. Harrold, and P. McMinn. An orchestrated survey of methodologies for automated software test case generation. Journal of Systems and Software, 2013.
[3] Thanassis Avgerinos, Alexandre Rebert, Sang Kil Cha, and David Brumley. Enhancing symbolic execution with veritesting. Commun. ACM, 59(6), 2016.
[4] Gogul Balakrishnan and Thomas W. Reps. WYSINWYX: what you see is not what you execute. ACM Trans. Program. Lang. Syst., 32, 2010.
[5] Sebastian Banescu, Christian S. Collberg, Vijay Ganesh, Zack Newsham, and Alexander Pretschner. Code obfuscation against symbolic execution attacks. In Annual Conference on Computer Security Applications, ACSAC 2016, 2016.
[6] Sebastian Banescu, Christian S. Collberg, and Alexander Pretschner. Predicting the resilience of obfuscated code against symbolic execution attacks via machine learning. In USENIX Security Symposium, 2017.
[7] Boaz Barak, Oded Goldreich, Russell Impagliazzo, Steven Rudich, Amit Sahai, Salil P. Vadhan, and Ke Yang. On the (im)possibility of obfuscating programs. In Advances in Cryptology - CRYPTO, 2001.
[8] Sébastien Bardin, Robin David, and Jean-Yves Marion. Backward-bounded DSE: targeting infeasibility questions on obfuscated codes. In 2017 IEEE Symposium on Security and Privacy, SP, 2017.
[9] Clark Barrett and Cesare Tinelli. Satisfiability Modulo Theories. Springer International Publishing, 2018.
[10] Armin Biere. Bounded Model Checking. In Handbook of Satisfiability. 2009.
[11] Fabrizio Biondi, Sébastien Josse, Axel Legay, and Thomas Sirvent. Effectiveness of synthesis in concolic deobfuscation. Computers & Security, 70, 2017.
[12] Guillaume Bonfante, José M. Fernandez, Jean-Yves Marion, Benjamin Rouxel, Fabrice Sabatier, and Aurélien Thierry. Codisasm: Medium scale concatic disassembly of self-modifying binaries with overlapping instructions. In Conference on Computer and Communications Security, 2015.
[13] David Brumley, Cody Hartwig, Zhenkai Liang, James Newsome, Dawn Xiaodong Song, and Heng Yin. Automatically identifying trigger-based behavior in malware. In Wenke Lee, Cliff Wang, and David Dagon, editors, Botnet Detection: Countering the Largest Security Threat, volume 36 of Advances in Information Security, pages 65–88. Springer, 2008.
[14] Robert Brummayer and Armin Biere. Boolector: An efficient SMT solver for bit-vectors and arrays. In International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS, 2009.
[15] Roberto Bruni, Roberto Giacobazzi, and Roberta Gori. Code obfuscation against abstract model checking attacks. In Verification, Model Checking, and Abstract Interpretation - 19th International Conference, VMCAI, 2018.
[16] Cristian Cadar. Targeted program transformations for symbolic execution. In Meeting on Foundations of Software Engineering, ESEC/FSE, 2015.
[17] Cristian Cadar, Daniel Dunbar, and Dawson R. Engler. KLEE: unassisted and automatic generation of high-coverage tests for complex systems programs. In 8th USENIX Symposium on Operating Systems Design and Implementation, OSDI, 2008.
[18] Cristian Cadar and Koushik Sen. Symbolic execution for software testing: three decades later. Commun. ACM, 56(2), 2013.
[19] Mariano Ceccato, Paolo Tonella, Cataldo Basile, Paolo Falcarin, Marco Torchiano, Bart Coppens, and Bjorn De Sutter. Understanding the behaviour of hackers while performing attack tasks in a professional setting and in a public challenge. Empirical Software Engineering, 24(1):240–286, Feb 2019.
[20] Sang Kil Cha, Thanassis Avgerinos, Alexandre Rebert, and David Brumley. Unleashing mayhem on binary code. In Symposium on Security and Privacy, SP, 2012.
[21] Christian Collberg and Jasvir Nagra. Surreptitious Software: Obfuscation, Watermarking, and Tamperproofing for Software Protection. Addison-Wesley Professional, 1st edition, 2009.
[22] Christian Collberg, Clark Thomborson, and Douglas Low. A taxonomy of obfuscating transformations, 1997.
[23] Christian S. Collberg, Sam Martin, Jonathan Myers, and Jasvir Nagra. Distributed application tamper detection via continuous software updates. In Annual Computer Security Applications Conference, ACSAC, 2012.
[24] Kevin Coogan, Gen Lu, and Saumya K. Debray. Deobfuscation of virtualization-obfuscated software: a semantics-based approach. In Conference on Computer and Communications Security, 2013.