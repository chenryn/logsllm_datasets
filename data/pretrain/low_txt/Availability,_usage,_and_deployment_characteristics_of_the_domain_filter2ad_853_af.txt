### Large Number of New LDNS Servers and Their Impact

Over time, a significant number of "new" Local DNS (LDNS) servers have appeared, many of which use dynamic IP addresses, often behind DSL, cable, or dial-up links. This diversity likely contributes to the higher availability observed in Authoritative DNS (ADNS) servers. It suggests that unless precautions are taken, infrastructures deployed similarly to LDNS servers will face more heterogeneity compared to those deployed like ADNS servers.

### Application to Distributed Hash Tables (DHTs)

To illustrate the application of DNS measurements to the design of federated distributed systems, we model the effect of dedicated infrastructure with similar availability characteristics as DNS on a DHT. A DHT is a fundamental building block in several proposed Internet-scale infrastructures [18, 20, 28, 33, 35]. In DHT-based systems, availability governs the degree of churn, which impacts stability and performance [21, 29].

**Simulation Setup:**

- **Environment:** 1024 nodes simulated using p2psim [26].
- **Network Topology:** Pairwise latencies of 1024 DNS servers collected using the King method [14] by Li et al. [21].
- **DHT Algorithm:** Chord [34] with proximity neighbor selection.
- **Lookup Rate:** 1 per node, with exponentially distributed arrival intervals and a mean of 2 minutes.

**Time to Failure and Recovery:**

- **Client Nodes:** Modeled after clients in an operational peer-to-peer file-sharing network [13]:
  - Exponentially distributed time to failure with a mean of 2.4 minutes.
  - Exponentially distributed time to recovery with a mean of 2.4 minutes.

- **Server Nodes:** Modeled after LDNS servers measured in our study:
  - 37.8% use the empirical LDNS time to failure distribution (see LDNS with short failures data in Figure 10).
  - The rest of the servers were never seen to fail, so they are pessimistically modeled as failing with an exponentially distributed mean time to failure of two weeks.
  - All use the empirical LDNS time to recovery distribution.

**Figure 17: DHT Simulation Setup**
- Parameters used in our DHT simulations.

Using parameters derived from our DNS measurements, we demonstrate how dedicated infrastructure nodes can significantly reduce overhead bandwidth in a DHT. Overhead bandwidth includes lookup traffic and maintenance traffic. Lookup traffic scales proportionally to the lookup rate and the logarithm of the network size in Chord. Maintenance traffic depends on the maintenance interval, which is the inverse of how often a node checks its neighbors' status and repairs broken overlay links. Longer intervals incur less maintenance traffic. If nodes leave frequently, the maintenance interval must be shorter to prune stale routing data. Conversely, if some nodes are part of a dedicated infrastructure, the interval can be longer. Efficiency requires a maintenance interval inversely proportional to the lookup rate or longer, while reliability requires it to be proportional to the average lifetime or shorter. When the lookup rate and lifetime are inversely proportional, extending the lifetime will substantially decrease maintenance traffic.

**Figure 18: Simulation Results**
- Varying the fraction of dedicated infrastructure nodes (servers) and end-user nodes (clients) in the DHT.
- With a portion of nodes acting as dedicated infrastructure, we can achieve similar reliability while decreasing bandwidth (or maintain bandwidth and improve reliability). For example, if a quarter of the nodes are servers rather than clients, the network requires roughly half the bandwidth to achieve similar reliabilities.

Our simulation results show that having infrastructure with failure properties no better than those of LDNS servers allows DHT maintenance to be performed much less frequently while still achieving a high rate of successful lookups. Other observations from our measurement study may also have implications for DHTs. For instance, the number of requests generated by LDNS servers was highly skewed, suggesting that in a federated DHT, a few nodes might generate the majority of the lookups. Measures may need to be taken to balance the load required to route these lookups. Additionally, certain deployment styles within organizations may be amenable to more hierarchical overlay construction. We leave this for future work.

### Related Work

#### 6.1 DNS Characterization
- Danzig et al. [11] presented the first comprehensive study of DNS traffic in the wide area, finding a large number of misbehaving local DNS resolvers.
- Brownlee et al. [6, 7] discuss more recent measurements at root name servers, continuing to find a large number of illegitimate queries.
- Liston et al. [22] studied DNS traffic from the client perspective, analyzing diversity across sites.
- Jung et al. [17] examined DNS traces from two local DNS servers, analyzing the impact of caching and TTL settings on client performance.
- Our study focuses on the characteristics of the DNS infrastructure rather than specific traffic characteristics.
- Ramasubramanian and Sirer [28] examined the authoritative DNS hierarchy, including bottlenecks and security vulnerabilities.

#### 6.2 Availability
- Recent studies [30, 5, 31] analyzed the availability of participants in peer-to-peer file-sharing systems.
- Long et al. [23] studied the availability of hosts on the Internet, but our focus is on dedicated infrastructure, and our measurements are more recent.

#### 6.3 DHTs and Churn
- Li et al. [21] and Rhea et al. [29] examined the impact of churn on DHTs and devised mechanisms for managing extremely low mean time to failures.
- Our evaluation suggests that such mechanisms are unnecessary in an infrastructure-based system because the infrastructure allows for very low maintenance traffic exchange rates.

### Summary

In this paper, we presented measurements of a large number of local and authoritative DNS servers, analyzing their load, availability, and deployment characteristics. Our key findings include:
- A large fraction of end-users use a small number of local DNS servers.
- Many local DNS servers are highly available, with authoritative servers generally having higher availability.
- There is a slight positive correlation between usage and availability of DNS servers.
- Local DNS server deployment and usage are diverse, with many servers originating from dynamic IP address pools.
- Some servers exhibit diurnal availability patterns.
- Local DNS server deployments within organizations range from a few highly used servers to a large number of lightly loaded ones.

Our observations provide new insights into DNS infrastructure and are important for the study of future federated infrastructure services. For example, we simulated a DHT using DNS-like availability characteristics and showed how much infrastructure support improves reliability and decreases overhead.

### Acknowledgments
We would like to thank Hui Zhang for initial feedback and our anonymous reviewers for their valuable feedback and suggestions. We also thank Steve Hill, Eric Olson, and Arthur Berger at Akamai for helping us with our infrastructure, and Jeremy Stribling for assistance with p2psim. James Hendricks is supported in part by an NDSEG Fellowship, sponsored by the Department of Defense.

### References
[References listed as provided in the original text]