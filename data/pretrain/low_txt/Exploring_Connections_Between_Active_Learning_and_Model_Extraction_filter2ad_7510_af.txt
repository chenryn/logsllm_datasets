### Acknowledgements

This work was partially supported by the Air Force Grant FA9550-18-1-0166, the National Science Foundation (NSF) Grants CCF-FMitF-1836978, SaTC-Frontiers-1804648, CCF-1652140, CNS-1838733, CNS-1719336, CNS-1647152, and CNS-1629833, as well as the Army Research Office (ARO) grant W911NF-17-1-0405. Kamalika Chaudhuri and Songbai Yan also acknowledge support from NSF under grants 1719133 and 1804829.

### References

1. [arXiv:1811.02054], 2019.
2. Alabdulmohsin, I. M., Gao, X., & Zhang, X. (2014). Adding robustness to support vector machines against adversarial reverse engineering. In *Proceedings of the 23rd ACM International Conference on Information and Knowledge Management (CIKM 2014)*, Shanghai, China, November 3-7, 2014, pp. 231–240.
3. Alabdulmohsin, I. M., Gao, X., & Zhang, X. (2015). Efficient active learning of halfspaces via query synthesis. In *AAAI*, pp. 2483–2489.
4. Angluin, D. (1987). Learning regular sets from queries and counterexamples. *Information and Computation*, 75(2), 87–106.
5. Ateniese, G., Mancini, L. V., Spognardi, A., Villani, A., Vitali, D., & Felici, G. (2015). Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers. *International Journal of Security and Networks (IJSN)*, 10(3), 137–150.
6. Atlas, L. E., Cohn, D. A., & Ladner, R. E. (1990). Training connectionist networks with queries and selective sampling. In *Advances in Neural Information Processing Systems*, pp. 566–573.
7. Awasthi, P., Feldman, V., & Kanade, V. (2013). Learning using local membership queries. In *Conference on Learning Theory*, pp. 398–431.
8. Balcan, M.-F., Beygelzimer, A., & Langford, J. (2009). Agnostic active learning. *Journal of Computer and System Sciences*, 75(1), 78–89.
9. Balcan, M.-F., Broder, A. Z., & Zhang, T. (2007). Margin based active learning. In *Learning Theory, 20th Annual Conference on Learning Theory (COLT 2007)*, San Diego, CA, USA, June 13-15, 2007, Proceedings, pp. 35–50.
10. Balcan, M.-F., & Long, P. M. (2013). Active and passive learning of linear separators under log-concave distributions. In *COLT 2013 - The 26th Annual Conference on Learning Theory*, Princeton University, NJ, USA, June 12-14, 2013, pp. 288–316.
11. Beygelzimer, A., Hsu, D., Langford, J., & Zhang, T. (2010). Agnostic active learning without constraints. In *23rd International Conference on Neural Information Processing Systems (NIPS)*.
12. Bordes, A., Ertekin, S., Weston, J., & Bottou, L. (2005). Fast kernel classifiers with online and active learning. *Journal of Machine Learning Research (JMLR)*, September 2005.
13. Brendel, W., Rauber, J., & Bethge, M. (2017). Decision-based adversarial attacks: Reliable attacks against black-box machine learning models. *arXiv preprint arXiv:1712.04248*.
14. Brinker, K. (2003). Incorporating diversity in active learning with support vector machines. In *Proceedings of the 20th International Conference on Machine Learning (ICML-03)*, pp. 59–66.
15. Carlini, N., & Wagner, D. (2017). Towards evaluating the robustness of neural networks. In *Security and Privacy (SP), 2017 IEEE Symposium on*, pp. 39–57. IEEE.
16. Chen, L., Hassani, S. H., & Karbasi, A. (2017). Near-optimal active learning of halfspaces via query synthesis in the noisy setting. In *AAAI*, pp. 1798–1804.
17. Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization with active learning. *Machine Learning*, 15(2), 201–221.
18. Dagan, I., & Engelson, S. P. (1995). Committee-based sampling for training probabilistic classifiers. In *Proceedings of the Twelfth International Conference on Machine Learning*, pp. 150–157. Morgan Kaufmann Series in Machine Learning.
19. Dasgupta, S., Hsu, D., & Monteleoni, C. (2007). A general agnostic active learning algorithm. In *NIPS*.
20. Dasgupta, S. (2005). Coarse sample complexity bounds for active learning. In *Advances in Neural Information Processing Systems 18 (NIPS 2005)*, December 5-8, 2005, Vancouver, British Columbia, Canada, pp. 235–242.
21. Dasgupta, S. (2011). Two faces of active learning. *Theoretical Computer Science*, 412(19), 1767–1781.
22. Dasgupta, S., Hsu, D. J., & Monteleoni, C. (2008). A general agnostic active learning algorithm. In *Advances in Neural Information Processing Systems*, pp. 353–360.
23. Fredrikson, M., Lantz, E., Jha, S., Lin, S., Page, D., & Ristenpart, T. (2014). Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing. In *USENIX Security Symposium*, pp. 17–32.
24. Fujii, A., Tokunaga, T., Inui, K., & Tanaka, H. (1998). Selective sampling for example-based word sense disambiguation. *Computational Linguistics*, 24(4), 573–597.
25. Gulwani, S. (2012). Synthesis from examples: Interaction models and algorithms. In *Symbolic and Numeric Algorithms for Scientific Computing (SYNASC), 2012 14th International Symposium on*, pp. 8–14. IEEE.
26. Hanneke, S. (2007). A bound on the label complexity of agnostic active learning. In *ICML*.
27. Hanneke, S. (2014). Theory of disagreement-based active learning. *Foundations and Trends in Machine Learning*, 7(2-3), 131–309.
28. Hegedűs, T. (1995). Generalized teaching dimensions and the query complexity of learning. In *Proceedings of the Eighth Annual Conference on Computational Learning Theory*, pp. 108–117. ACM.
29. Huang, L., Joseph, A. D., Nelson, B., Rubinstein, B. I. P., & Tygar, J. D. (2011). Adversarial machine learning. In *Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence (AISec 2011)*, Chicago, IL, USA, October 21, 2011, pp. 43–58.
30. Kääriäinen, M. (2006). Active learning in the non-realizable case. In *Algorithmic Learning Theory, 17th International Conference (ALT 2006)*, Barcelona, Spain, October 7-10, 2006, Proceedings, pp. 63–77.
31. Karp, R. M., & Kleinberg, R. (2007). Noisy binary search and its applications. In *Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2007)*, New Orleans, Louisiana, USA, January 7-9, 2007, pp. 881–890.
32. King, R. D., Rowland, J., Oliver, S. G., Young, M., Aubrey, W., Byrne, E., Liakata, M., Markham, M., Pir, P., Soldatova, L. N., et al. (2009). The automation of science. *Science*, 324(5923), 85–89.
33. Klivans, A. R., & Kothari, P. (2014). Embedding hard learning problems into Gaussian space. In *Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2014)*, Barcelona, Spain, September 4-6, 2014, pp. 793–809.
34. Krishnamurthy, V. (2002). Algorithms for optimal scheduling and management of hidden Markov model sensors. *IEEE Transactions on Signal Processing*, 50(6), 1382–1397.
35. Kushilevitz, E., & Mansour, Y. (1993). Learning decision trees using the Fourier spectrum. *SIAM Journal on Computing*, 22(6), 1331–1348.
36. Lindenbaum, M., Markovitch, S., & Rusakov, D. (1999). Selective sampling for nearest neighbor classifiers. In *AAAI/IAAI*, pp. 366–371. Citeseer.
37. Liu, H., Motoda, H., & Yu, L. (2004). A selective sampling approach to active feature selection. *Artificial Intelligence*, 159(1-2), 49–74.
38. Lowd, D., & Meek, C. (2005). Adversarial learning. In *Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*, Chicago, Illinois, USA, August 21-24, 2005, pp. 641–647.
39. McCallum, A., & Nigam, K. (1998). Employing EM and pool-based active learning for text classification. In *Proceedings of the Fifteenth International Conference on Machine Learning*, Madison, Wisconsin, USA, July 24-27, 1998, pp. 350–358.
40. Minh, H. Q., Niyogi, P., & Yao, Y. (2006). Mercer’s theorem, feature maps, and smoothing. In *International Conference on Computational Learning Theory*, pp. 154–168. Springer.
41. Mitchell, T. M. (1982). Generalization as search. *Artificial Intelligence*, 18(2), 203–226.
42. Mitchell, T. M. (1978). Version spaces: An approach to concept learning. *Technical Report, Stanford University, Department of Computer Science*.
43. Naghshvar, M., Javidi, T., & Chaudhuri, K. (2012). Noisy Bayesian active learning. In *Communication, Control, and Computing (Allerton), 2012 50th Annual Allerton Conference on*, pp. 1626–1633. IEEE.
44. Nowak, R. (2009). Noisy generalized binary search. In *Advances in Neural Information Processing Systems*, pp. 1366–1374.
45. Nowak, R. D. (2011). The geometry of generalized binary search. *IEEE Transactions on Information Theory*, 57(12), 7893–7906.
46. Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z. B., & Swami, A. (2017). Practical black-box attacks against machine learning. In *Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security*, pp. 506–519. ACM.
47. Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z. B., & Swami, A. (2016). The limitations of deep learning in adversarial settings. In *Security and Privacy (EuroS&P), 2016 IEEE European Symposium on*, pp. 372–387. IEEE.
48. Papernot, N., McDaniel, P., Sinha, A., & Wellman, M. (2016). Towards the science of security and privacy in machine learning. *arXiv preprint arXiv:1611.03814*.
49. Sener, O., & Savarese, S. (2018). Active learning for convolutional neural networks: A core-set approach.
50. Settles, B. (2009). Active learning literature survey. *Technical Report, CS Tech. Rep. 1648, University of Wisconsin-Madison*.
51. Shi, Y., Sagduyu, Y., & Grushin, A. (2017). How to steal a machine learning classifier with deep learning. In *Technologies for Homeland Security (HST), 2017 IEEE International Symposium on*, pp. 1–5. IEEE.
52. Shokri, R., Stronati, M., Song, C., & Shmatikov, V. (2017). Membership inference attacks against machine learning models. In *Security and Privacy (SP), 2017 IEEE Symposium on*, pp. 3–18. IEEE.
53. Srndic, N., & Laskov, P. (2014). Practical evasion of a learning-based classifier: A case study. In *2014 IEEE Symposium on Security and Privacy (SP 2014)*, Berkeley, CA, USA, May 18-21, 2014, pp. 197–211.
54. Tong, S., & Koller, D. (2001). Support vector machine active learning with applications to text classification. *Journal of Machine Learning Research*, 2(Nov), 45–66.
55. Tramèr, F., Zhang, F., Juels, A., Reiter, M. K., & Ristenpart, T. (2016). Stealing machine learning models via prediction APIs. In *25th USENIX Security Symposium (USENIX Security 16)*, Austin, TX, USA, August 10-12, 2016, pp. 601–618.
56. Valiant, L. G. (1984). A theory of the learnable. *Communications of the ACM*, 27(11), 1134–1142.
57. Wang, B., & Gong, N. Z. (2018). Stealing hyperparameters in machine learning. *arXiv preprint arXiv:1802.05351*.
58. Wang, C., Cheung, A., & Bodik, R. (2017). Interactive query synthesis from input-output examples. In *Proceedings of the 2017 ACM International Conference on Management of Data*, pp. 1631–1634. ACM.
59. Wang, L., Hu, X., Yuan, B., & Lu, J. (2015). Active learning via query synthesis and nearest neighbor search. *Neurocomputing*, 147, 426–434.
60. Yan, S., Chaudhuri, K., & Javidi, T. (2016). Active learning from imperfect labelers. In *Advances in Neural Information Processing Systems*, pp. 2128–2136.
61. Yan, S., & Zhang, C. (2017). Revisiting perceptron: Efficient and label-optimal learning of halfspaces. In *Advances in Neural Information Processing Systems 30 (NIPS 2017)*, Long Beach, CA, USA, December 4-9, 2017, pp. 1056–1066.
62. Yu, H. (2005). SVM selective sampling for ranking with application to data retrieval. In *Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining*, pp. 354–363. ACM.
63. Zhang, C., & Chaudhuri, K. (2014). Beyond disagreement-based agnostic active learning. In *Advances in Neural Information Processing Systems*, pp. 442–450.