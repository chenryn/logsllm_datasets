### Lossless and Lossy Relations

A relation is considered lossless if its constant parameters do not contain wildcard patterns such as “?” and “*”. For example, the relation `X isWithinDir Y` is lossless if `X = Ys`, where `s` is a constant parameter that does not include any wildcard pattern. Conversely, the relation `hasSameDirAs` is lossy because it retains only the common directory name while discarding the rest of the argument information.

### Branching Factor Analysis

Figure 8 illustrates the average branching factor for our models under three conditions: without argument learning, with learning of unary relations, and with learning of both unary and binary relations that do not lose significant information. The results show that incorporating binary relations significantly improves the branching factor.

It is important to note that the average branching factor of our technique cannot be directly compared to other techniques unless they also use an FSA-based control model. Therefore, we do not make direct comparisons with the results reported by [14].

### Performance Overheads

#### Model Sizes

Figure 7 provides details on the programs used in our experiments, along with their model sizes in terms of the number of states, transitions, and relations. The models are relatively small compared to the size of the programs involved.

#### Time for Learning Models

We evaluated the performance of the learning algorithm using three programs: `httpd`, `ftpd`, and `sshd`. The training traces ranged from 100MB to 300MB, consisting of 1.5 to 4 million system calls. The learning algorithm took between 5 to 25 minutes to process these traces.

#### Overhead for Intrusion Detection

Our current implementation uses `ptrace` for system call interception, which introduces high runtime overheads, sometimes exceeding 100% for some programs. To improve performance, an in-kernel interceptor can be used. According to [9], the overhead for system call interception, including the costs of retrieving the program counter (PC), is around 6% for a kernel implementation. Additionally, intrusion detection requires verifying binary relations and making `realpath` calls for file names. We measured these overheads individually using our user-level implementation, as shown in Figure 9. The `find` command represents a worst-case scenario due to the large number of system calls involving file names, each incurring the overhead of a `realpath` call and the overhead of verifying relationships on file names. An in-kernel implementation of `realpath` would likely have lower overheads, but the overhead numbers for relationship verification are unlikely to change.

### Related Work

#### Static Analysis Techniques

Several static analysis techniques have been developed for building intrusion detection models. [30] and [19] use source-code analysis, while [14] employs binary analysis. These approaches can extract system call arguments that appear as immediate constants in the program. The binary analysis approach in [12] additionally associates the calling context of the extracted static data using data flow analysis and incorporates environment dependencies. However, these dependencies need to be specified manually. In contrast, our approach automatically learns these dependencies.

The primary benefit of static analysis techniques is the elimination of false alarms, as they capture a superset of all possible behaviors. However, this conservative nature limits attack detection, as only attacks causing deviations from the code's expected behavior are detected. This means that various attacks, such as input validation errors and race conditions, cannot be detected. Capturing accurate information about data values is also challenging due to the complexities of languages like C, which allow arbitrary type casts and pointer arithmetic.

#### Learning-Based Approaches

##### Intrusion Detection

Several techniques for learning control-flow behaviors for intrusion detection have been discussed. [18] describes methods for learning statistical information about system call arguments for anomaly detection, including properties of string arguments like length and character distribution. [27] proposes a host-based anomaly detection system that uses a rule-learning algorithm to model system call behaviors, capturing a fixed number of distinct values of frequently occurring arguments.

In our terminology, these approaches focus on unary relations, whereas our approach excels in learning more complex binary relations. Our method also utilizes control-flow context to improve the precision of dataflow relationships, which the above approaches do not.

##### Hypothesizing Program Properties

[1] presents a technique for automatically extracting likely program properties from execution traces, but it relies on human specification of regions within a trace. [22] has similar goals but is fully automated. The primary difference is that [22] focuses on invariant properties, while our algorithm focuses on temporal properties on traces. These problems require different techniques; for instance, algorithms for learning invariants can exploit transitivity, which is not applicable to trace properties.

##### Mobile Code Security

In [26], we described models similar to those in this paper, but with a focus on mobile code security. This paper improves upon [26] in several ways:
1. A formal treatment of dataflow properties.
2. Utilization of control flow contexts to improve the precision of dataflow relationships.
3. Development of an efficient algorithm for learning relationships and analyzing its complexity.
4. Parameterization of the model to incorporate dependence on the program's environment, including command-line arguments, environment variables, and open file descriptors.
5. Detailed evaluation of our technique for intrusion detection.

### Conclusion

In this paper, we presented an approach for enhancing the accuracy of host-based intrusion detection models by capturing dataflow information. This approach can be layered over existing techniques for learning control-flows. We provided a formal treatment of dataflow properties of traces and an efficient learning algorithm parameterized with respect to relations of interest. Through experimental evaluation, we demonstrated that our approach is effective in detecting sophisticated attacks that most previous techniques fail to detect. We also showed that the models are compact and produce low false alarm rates. An important benefit of our approach is that it enables formal reasoning about the security guarantees provided when these models are used for intrusion detection.

### Acknowledgments

We thank Diptikalyan Saha for his invaluable help with verification and Zhenkai Liang for his support with the system call interposition environment for model extraction. We also thank Shabbir Dahodwala, Daniel C. DuVarney, Yow-Jian Lin, and C.R. Ramakrishnan for several discussions on model extraction and verification. Finally, we thank the anonymous reviewers for their insightful comments and suggestions.

### References

[1] G. Ammons, R. Bodik, and J. Larus. Mining specifications. In ACM Symposium on Principles of Programming Languages (POPL), January 2002.

[2] M. Bishop and M. Dilger. Checking for race conditions in file accesses. Computing Systems, 9(2):131–152, 1996.

[3] CERT CC. CERT Advisory CA-2001-33 Multiple Vulnerabilities in WU-FTPD, 2001.

[4] H. Chen, D. Dean, and D. Wagner. Model checking one million lines of C code. In Network and Distributed System Security Symposium, San Diego, CA, February 2004.

[5] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. Iyer. Non-control-data attacks are realistic threats. In USENIX Security Symposium, Baltimore, MD, August 2005.

[6] H. Feng, J. Griffin, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing sensitivity in static analysis for intrusion detection. In IEEE Symposium on Security and Privacy, 2004.

[7] H. Feng, O. Kolesnikov, P. Folga, W. Lee, and W. Gong. Anomaly detection using call stack information. In IEEE Symposium on Security and Privacy, May 2003.

[8] Common vulnerability matrix v2.0. Published on World-Wide Web at URL http://www.tripwire.com/files/literature/poster/Tripwire exploit poster.pdf, 2002.

[9] D. Gao, M. K. Reiter, and D. Song. Gray-box extraction of execution graphs for anomaly detection. In ACM conference on Computer and Communications Security (CCS), pages 318–329, Washington, DC, October 2004.

[10] D. Gao, M. K. Reiter, and D. Song. On gray-box program tracking for anomaly detection. In USENIX Security Symposium, pages 103–118, San Diego, CA, USA, August 2004.

[11] A. Ghosh and A. Schwartzbard. A study in using neural networks for anomaly and misuse detection. In USENIX Security Symposium, Washington, DC, August 1999.

[12] J. T. Griffin, D. Dagon, S. Jha, W. Lee, and B. P. Miller. Environment-sensitive intrusion detection. In Recent Advances in Intrusion Detection (RAID), September 2005.

[13] J. T. Griffin, S. Jha, and B. P. Miller. Detecting manipulated remote call streams. In USENIX Security Symposium, San Francisco, CA, August 2002.

[14] J. T. Griffin, S. Jha, and B. P. Miller. Efficient context-sensitive intrusion detection. In Network and Distributed System Security Symposium, San Diego, CA, February 2004.

[15] S. A. Hofmeyr, S. Forrest, and A. Somayaji. Intrusion detection using sequences of system calls. Journal of Computer Security (JCS), 6(3):151–180, 1998.

[16] C. Ko, G. Fink, and K. Levitt. Automated detection of vulnerabilities in privileged programs by execution monitoring. In Annual Computer Security Applications Conference (ACSAC), December 1994.

[17] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna. Automating mimicry attacks using static binary analysis. In USENIX Security Symposium, Baltimore, MD, August 2005.

[18] C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detection of anomalous system call arguments. In European Symposium on Research in Computer Security, Gjøvik, Norway, October 2003.

[19] L. C. Lam and T. Chiueh. Automatic extraction of accurate application-specific sandboxing policy. In Recent Advances in Intrusion Detection (RAID), Sophia Antipolis, French Riviera, France, September 2004.

[20] K. Lhee and S. J. Chapin. Detection of file-based race conditions. International Journal of Information Security (IJIS), 4(1-2):105–119, 2005.

[21] C. C. Michael and A. Ghosh. Simple, state-based approaches to program-based anomaly detection. In ACM Transactions on Information and System Security (TISSEC), 2002.

[22] J. Perkins and M. Ernst. Efficient incremental algorithms for dynamic detection of likely invariants. In ACM International Symposium on Foundations of Software Engineering (FSE), Newport Beach, CA, USA, November 2004.

[23] N. Provos. Improving host security with system call policies. In USENIX Security Symposium, Washington, DC, USA, August 2003.

[24] W. Purczynski. GNU fileutils - recursive directory removal race condition, March 2002. Bugtraq-fileutils mailing list.

[25] R. Sekar, M. Bendre, P. Bollineni, and D. Dhurjati. A fast automaton-based approach for detecting anomalous program behaviors. In IEEE Symposium on Security and Privacy, 2001.

[26] R. Sekar, V. Venkatakrishnan, S. Basu, S. Bhatkar, and D. C. DuVarney. Model-carrying code: A practical approach for safe execution of untrusted applications. In ACM Symposium on Operating Systems Principles (SOSP), Bolton Landing, New York, October 2003.

[27] G. Tandon and P. Chan. Learning rules from system call arguments and sequences for anomaly detection. In ICDM Workshop on Data Mining for Computer Security (DMSEC), pages 20–29, 2003.

[28] E. Tsyrklevich and B. Yee. Dynamic detection and prevention of race conditions in file accesses. In USENIX Security Symposium, Washington, DC, USA, August 2003.

[29] P. Uppuluri, A. Ray, and U. Joshi. Preventing race condition attacks on file systems. In (ACM) Symposium on Applied Computing (SAC), 2005.

[30] D. Wagner and D. Dean. Intrusion detection via static analysis. In IEEE Symposium on Security and Privacy, Oakland, CA, May 2001.

[31] D. Wagner and P. Soto. Mimicry attacks on host-based intrusion detection systems. In ACM conference on Computer and Communications Security (CCS), 2002.

[32] C. Warrender, S. Forrest, and B. Pearlmutter. Detecting intrusions using system calls: Alternative data models. In IEEE Symposium on Security and Privacy, pages 133–145, 1999.

[33] A. Wespi, M. Dacier, and H. Debar. Intrusion detection using variable-length audit trail patterns. In Recent Advances in Intrusion Detection (RAID), Toulouse, France, October 2000.

[34] Wikipedia. http://en.wikipedia.org/wiki/Trie.

[35] XSB. The XSB logic programming system v2.3, 2001. Available from http://www.cs.sunysb.edu/~sbprolog.