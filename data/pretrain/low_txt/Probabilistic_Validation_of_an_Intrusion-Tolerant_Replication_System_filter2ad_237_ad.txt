### 4.2. Impact of Varying the Number of Hosts per Domain

In the second study, we varied the total number of hosts for each experiment in the study. Figures 4(a) and 4(b) illustrate the variations in unavailability and unreliability, respectively, as the number of hosts in 10 domains increases. Given that the probability of a successful intrusion into any host is constant across all experiments, an increase in the number of hosts within a domain raises the likelihood that at least one host will be compromised. This, in turn, results in the exclusion of the entire domain, leading to a slight increase in both unavailability and unreliability.

Notably, the variation in these metrics over the first 5 time units is minimal, and even over the first 10 time units, it remains significantly lower than the variations observed in the study described in Section 4.1.

Figure 4(c) highlights that increasing the number of hosts in a domain leads to a considerable waste of resources, as the domain is excluded as soon as a small number of hosts are corrupted. Figure 4(d) shows that the number of excluded domains increases with the number of hosts, which can be attributed to the fact that the corruption (and detection) of a single host leads to the exclusion of the entire domain. Consequently, with more hosts per domain, the likelihood of domain corruption is higher.

From these two studies, it is evident that it is preferable to minimize the number of hosts per domain. The second study indicates that increasing the number of hosts per domain does not provide significant improvement, even when the overall system cost increases. Therefore, unless constrained by physical limitations such as network design or firewall placement, it is advisable to form more domains with fewer hosts per domain.

### 4.3. Comparison of Domain-Exclusion and Host-Exclusion Management Algorithms

Another critical management issue is determining what to exclude when a host (or a replica on it) is found to be corrupt, assuming multiple hosts per domain. One approach is to exclude the entire domain containing the corrupt host, which is a preemptive measure against potential spread of the attack to other hosts in the domain. The alternative approach is to exclude only the detected host, thereby conserving resources. We conducted experiments to compare the effectiveness of these approaches under different rates of attack spread.

In these experiments, we assumed that the corruption of the host operating system and services increased the likelihood of corruption of the replicas and management entity running on the host by fivefold. The experimental setup was similar to previous experiments, with 10 domains, each containing 3 hosts, and 4 applications, each with 7 replicas. The within-domain attack spread rate ranged from 0 (low) to 10 (high). A spread rate of 5 or higher is considered high but may be reasonable given that major hardening is typically done at inter-domain boundaries rather than within domains.

Figure 5(a) shows that for low values of attack spread, excluding a single host provides better application availability in the short term (5 hours) compared to the domain exclusion scheme. However, the two schemes perform similarly for high values of attack spread. As shown in Figure 5(b), the domain-exclusion scheme outperforms the host-exclusion scheme in the long term (10 hours) for most values of the attack spread rate. The attack spread rate has a minimal impact on the performance of the domain-exclusion scheme.

Figure 5(c) indicates that under the domain-exclusion scheme, application reliability remains relatively stable regardless of the within-domain attack spread rate, whereas it is more sensitive to the spread rate under the host-exclusion scheme. For the parameter ranges studied, the domain-exclusion scheme provides better application reliability for spread rates of 4 or more (for the first 5 hours). Figure 5(d) shows that the domain-exclusion scheme outperforms the host-exclusion scheme for almost all spread rate values over a longer period of 10 hours.

These results suggest that, for the studied attack and detection rates, even with a low within-domain attack spread rate, a preemptive-action-based domain-exclusion scheme performs almost as well as the host-exclusion scheme in the short run and significantly better in the long run.

### 5. Conclusion

In this paper, we present a probabilistic validation of an intrusion-tolerant replication system. The results are significant for several reasons. First, they demonstrate the utility of probabilistic modeling for validating complex intrusion-tolerant architectures and show that stochastic activity networks (SANs) are an appropriate model representation for this purpose. Models abstract a system’s implementation and behavior, making it easier to analyze properties of a model than those of the real system. The SAN model created is modular and can be easily modified to represent other intrusion-tolerant systems.

Furthermore, the results provide valuable insights into the relative merits of various design choices for the ITUA replication management system. The results indicate that it is advisable to minimize the number of hosts per domain, as the intrusion tolerance offered by the system is highly sensitive to the number of security domains available for starting new replicas. We also studied another management scheme where only the corrupt host is excluded and observed that if an attack can spread quickly within a domain, it is better to exclude the entire domain when an intrusion is detected.

### Acknowledgments

We would like to thank the other members of the ITUA team for their helpful comments. We are grateful to Jenny Applequist for her editorial assistance.

### References

[1] M. Castro and B. Liskov. Practical Byzantine Fault Tolerance. In Proc. Third Symp. on Operating Systems Design and Implementation, pages 173–186, Feb. 1999.

[2] T. Courtney, J. Lyons, H. V. Ramasamy, W. H. Sanders, M. Seri, M. Atighetchi, P. Rubel, C. Jones, F. Webber, P. Pal, R. Watro, M. Cukier, and J. Gossett. Providing Intrusion Tolerance with ITUA. In Supplement of the 2002 Intl Conf. on Dependable Sys. and Networks (DSN-2002), pages C–5–1– C–5–3, June 2002.

[3] D. D. Deavours, G. Clark, T. Courtney, D. Daly, S. Derisavi, J. M. Doyle, W. H. Sanders, and P. G. Webster. The M¨obius Framework and Its Implementation. IEEE Trans. on Software Engineering, 28(10):956–969, Oct. 2002.

[4] F. Gong, K. Goseva-Popstojanova, F. Wang, R. Wang, K. Vaidyanathan, K. Trivedi, and B. Muthusamy. Characterizing Intrusion Tolerant Systems Using A State Transition Model. In Proc. DARPA Information Survivability Conf. and Expo. II (DISCEX’01), pages 211–221, 2001.

[5] S. Jha and J. M. Wing. Survivability Analysis of Networked Systems. In Proc. 23rd Intl Conf. on Software Engineering (ICSE2000), pages 307–317, 2001.

[6] E. Jonsson and T. Olovsson. A Quantitative Model of the Security Intrusion Process Based on Attacker Behavior. IEEE Trans. on Software Engineering, 23(4):235–245, Apr. 1997.

[7] C. Landwehr. Formal Models for Computer Security. Computer Surveys, 13(3):247–278, Sept. 1981.

[8] B. Littlewood, S. Brocklehurst, N. Fenton, P. Mellor, S. Page, D. Wright, J. Doboson, J. McDermid, and D. Gollmann. Towards Operational Measures of Computer Security. Journal of Computer Security, 2(2-3):211–229, 1993.

[9] J. Lowry. An Initial Foray into Understanding Adversary Planning and Courses of Action. In Proc. DARPA Information Survivability Conf. and Expo. II (DISCEX’01), pages 123–133, 2001.

[10] R. Ortalo, Y. Deswarte, and M. Kaˆaniche. Experimenting with Quantitative Evaluation Tools for Monitoring Operational Security. IEEE Trans. on Software Engineering, 25(5):633–650, 1999.

[11] H. V. Ramasamy, P. Pandey, J. Lyons, M. Cukier, and W. H. Sanders. Quantifying the Cost of Providing Intrusion Tolerance in Group Communication Systems. In Proc. 2002 Intl Conf. on Dependable Systems and Networks (DSN 2002), pages 229–238, June 2002.

[12] W. H. Sanders and J. F. Meyer. Stochastic Activity Networks: Formal Definitions and Concepts. In E. Briksma, H. Hermanns, and J. P. Katoen, editors, Lectures on Formal Methods and Performance Analysis, pages 315–343. Springer-Verlag, Berlin, 2001.

[13] S. Singh. Probabilistic Validation of an Intrusion-Tolerant Replication System. Master’s thesis, University of Illinois at Urbana-Champaign, 2002.

[14] US Department of Defense. Trusted Computer System Evaluation Criteria (Orange Book). http://www.radium.ncsc.mil/tpep/library/rainbow/5200.28-STD.html, Dec. 1985. DoD 5200.28-STD.

---

**Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03)  
0-7695-1959-8/03 $17.00 (c) 2003 IEEE  
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:53 UTC from IEEE Xplore. Restrictions apply.**