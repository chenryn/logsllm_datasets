### 4.1 Qualitative Investigation

We identified 25 participants who control at least 100 accounts on Google Play, have been active for at least one year, and have completed at least 100 App Store Optimization (ASO) tasks. Following recruitment, we read to these participants an introductory script included in the auxiliary document. Eighteen of them (all male, aged 19-29, located in Bangladesh (13), India (4), and New Zealand (1)) agreed to participate.

In the following, we refer to the interview participants as P1 through P18. We conducted a structured interview study with these participants, which included 46 questions and 72 additional questions for clarification, as detailed in the auxiliary document. The questions covered demographic information, workflow, devices used, and operational methods. The interviews were conducted over Skype between August and October 2018, lasting from 33 to 66 minutes (mean = 46.38 minutes, standard deviation = 12.34 minutes). Participants were compensated at a rate of $5 USD for every 15 minutes of their time. With the participants' permission, we audio-recorded the interviews, transcribed them, and anonymized the data.

We analyzed the anonymized data using the Grounded Theory method [33]. We used open coding to identify 169 unique codes, including both abstract and concrete labels. Two members of our team independently coded the data, achieving an inter-coder agreement of 84.61%. In cases where the codes did not match, a third team member was consulted to decide the final code. We then used axial coding to relate the generated codes, resulting in 22 categories grounded in the collected data. Some of these categories include: account blending, account creation, devices, early-bird fraud, extreme reviews, and strategy. We further refined these categories into the codes that form the subsection titles in §5.

### 4.2 Quantitative Investigation

We performed a quantitative investigation with user accounts collected from 39 ASO workers, different from the qualitative study participants but recruited using the same methods described in §4.1. In the following, we refer to the quantitative study participants as F1 through F39. Each of the selected workers claimed to control up to 500 Google Play accounts (mean = 211, standard deviation = 166), and each shared the IDs of at least 15 Google Play accounts they control, yielding a total of 1,164 account IDs for analysis.

We then crawled the 6,362 unique apps reviewed by these 1,164 worker-controlled accounts, which were available on Google Play. These apps had received 21,767 reviews from the worker-controlled accounts and a total of 218,167,727 reviews. We used the AppBrain API [3] to collect the category and release date of each app.

**Device Model Data Collection:**
We collected information provided by Google Play about the devices used to post fraudulent reviews. Google Play’s client-side functionality allows authenticated users to filter reviews according to the model of their registered devices. We used this functionality to query the reviews posted for an app, for all possible device models, and thus identify the device model used to post any individual review. We used the list of 21,597 Google-supported devices [10], which contains the parameters needed to identify the device models used to post the 21,767 reviews from the 1,164 ASO worker-controlled accounts, as perceived by Google’s systems. Additionally, we collected the device release date and price (in EUR) from GSM Arena [12] and Gadgets360 [8].

### 4.3 Ethical Considerations

Some ASO work is considered unethical according to several ethical frameworks, and many ASO workers belong to low-paid, vulnerable groups. Therefore, our study took utmost care to follow the best ethical practices for conducting sensitive research with vulnerable populations [29]. Our study included a clear declaration of the researchers’ identity, research objectives, and potential impact on the participants’ work without any deception. The entire study procedure was scrutinized and approved by the institutional review board of a major North American university (IRB-18-0077@FIU). We include our recruitment message and introductory script in Appendix A and discuss the recruitment process, possible reasons for participants' responses, and other relevant issues in the auxiliary document.

We used GDPR [70] recommended pseudonymization for data processing and statistics and followed other generally accepted good practices for privacy preservation. After data collection, we deleted all device-to-identity links and only generated statistics that allowed us to validate our assumptions. We avoided obtaining additional information about the devices used or the accounts involved. We contacted Google about our discovered device model identification issue through Google’s Vulnerability Reward Program (VRP) [11] (issue: 119676181). Google accepted our finding and invited us to join their hall of fame.

### 5. Findings

We organize, analyze, and report findings from the interview and quantitative studies. Figure 1 provides a map of the topics we investigated.

#### 5.1 Team, Location, and Organization

All 18 interview participants claimed to be part of organizations dedicated to posting fraud on Google Play. Our data shows that ASO workers assemble in various organizational structures. While some work in teams with well-defined roles and regular salaries, others work in more unstructured teams and share their earnings. We classify ASO teams into several categories based on their location, organization type, type of fraud, and profit-sharing structure. Figure 2 shows a Venn diagram of the 18 participants grouped according to four of these categories for readability.

**Team Size:**
The first column of Table 1 lists the team sizes claimed by each participant, including both physically co-located and online team members. Five participants claimed to work alone, while the other 13 claimed to have teams with at least 10 members. Notably, P4 claimed to be part of a large company with around 150 people in their team, organizing 15,000 organic ASO workers through virtual (WhatsApp, Facebook) groups.

**Physical Co-located vs. Online Teams:**
Seven participants (Figure 2) claimed to work with physically co-located teams, with five of them having brick-and-mortar offices. Figure 3 shows a photo taken by P10, with the premises and (anonymized) employees of his business. Seven others claimed to have strictly online teams, and the remaining four claimed to be part of hybrid organizations that are both physical and online.

**Organization Structure: Hierarchical vs. Flat:**
Fifteen participants claimed a hierarchical structure in their organizations (Figure 2). Eleven of them described specific roles, including job managers who interface with developers and manage work from the marketplace, team admins who organize, distribute tasks, and verify the work of review posters, and new account creators. For example, P3 said, “I am one of the admins in our team, and we have 10–12 admins. Under each admin, we have 15–20 members. All admins work as subcontractors, and some of our other team members work with the developers and manage work from the marketplace.” However, two participants claimed to work in teams with a flat organization. For instance, P15 said, “We all work together. There is no hierarchy.”

**Organic Fraud:**
Nine participants claimed to organize or be part of online teams of “organic” users, workers who use their personal accounts to post fake reviews (Table 1). P5 said, “I also have my own Facebook group where I have combined 60 real users to write reviews.” P7 did not specify the number of organic accounts they can access but stated, “We have 3,000 accounts. If we need more, we run CPI/CPA campaigns where people get an incentive to install apps.”

**Profit Sharing:**
One participant claimed to pay team members a monthly salary, while another claimed an even split among members. Three mentioned preferential cuts for the job manager (10–25%) and team lead (10–50%) and an equal split of the rest among the actual review posters. Two participants claimed a flat rate for the review posters ($0.40 per review). The rest of the participants did not respond to this question.

**Summary:**
Our study confirms observations made by existing work that fraud is perpetrated by experts who control either (1) many sockpuppet user accounts, e.g., [28, 37, 55, 59, 60, 63, 64, 77, 93, 95, 99], or (2) organic fraudsters, i.e., real account owners.