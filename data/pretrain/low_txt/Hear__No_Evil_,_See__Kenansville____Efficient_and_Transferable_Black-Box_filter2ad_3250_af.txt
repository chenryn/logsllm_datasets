### Optimized Text

#### Dependence on Low-Intensity Components in ASR and AVI Systems
Automated Speech Recognition (ASR) and Audio-Visual Identification (AVI) systems have inadvertently become reliant on low-intensity audio components for inference. This reliance explains why the removal of these seemingly insignificant parts of speech can confuse the model, leading to mistranscriptions or misidentifications. Additionally, this phenomenon may account for a portion of the errors observed in ASR and AVI systems when tested on regular datasets. Future research could leverage these findings to develop more robust models and reduce system errors.

#### Adversarial Attacks on ASR Systems
While our attack guarantees that a perturbed word will be mistranscribed, it remains untargeted, meaning the resulting transcription can be anything. However, an attacker has some control over the output. Our experiments have focused on determining the minimum perturbation required to fool the model. In some cases, the transcriptions of the adversarial audio and its benign counterpart were phonetically similar (Table II). Increasing the distortion can decrease the phonetic similarity of the transcriptions. During our experiments with Discrete Fourier Transform (DFT) and Singular Spectrum Analysis (SSA) perturbation methods, we observed that ASRs often mistook the input as noise. Manual listening tests by the authors confirmed that the audio samples remained intelligible. An attacker aiming to completely evade the ASR could apply additional distortion, forcing the ASR to either produce a phonetically dissimilar transcription or, ideally, no transcription at all.

#### Applications in Audio CAPTCHAs
Our attack also has implications for audio CAPTCHAs, which are commonly used by web services to verify human presence. These CAPTCHAs rely on the assumption that humans can transcribe audio better than machines, a premise that modern ASR systems challenge [46], [47], [48], [49], [50]. Our attack could potentially be used to distort audio CAPTCHAs, making them resistant to modern ASR systems.

#### Related Work
Machine Learning (ML) models, particularly deep learning models, have shown significant advancements in complex tasks such as image classification [51], [52], [53] and speech recognition [54], [26], [24]. However, previous work has demonstrated that ML models are inherently vulnerable to Adversarial Machine Learning (AML) attacks [55]. Early AML techniques focused on introducing visually imperceptible changes to images that cause the model to misclassify them. These attacks target either specific pixels [56], [57], [58], [59], [60], [61] or entire patches of pixels [62], [63], [64], [65]. In some cases, the attack generates entirely new images that the model classifies to an adversary's chosen target [66], [67].

However, the success of these attacks is based on two restrictive assumptions: first, that the underlying target model is a neural network, and second, that the model can be influenced by pixel-level changes [64], [66]. These assumptions limit the applicability of image-based attacks to ASR models. ASR systems have succeeded across various ML architectures, from Hidden Markov Models (HMMs) to Deep Neural Networks (DNNs). Moreover, since audio data is typically preprocessed for feature extraction before entering the statistical model, ASR models operate at a higher level than their image counterparts.

To overcome these limitations, previous works have proposed several new attacks that exploit specific behaviors of ASR models. These attacks can be categorized into three types:
1. **Inaudible to Humans but Detected by ASR**: The generated audio is inaudible to the human ear but detected by the speech recognition model [68].
2. **Noisy but Decipherable by ASR**: The audio sounds like noise to humans but is correctly deciphered by the ASR [69], [11], [10].
3. **Pristine but Misinterpreted**: The audio sounds normal to humans but is transcribed as a different, chosen phrase [3], [70], [71], [72], [7], [6], [2], [5], [73].

Although the third category seems most useful, these attacks often require white-box access to the model, limiting their success.

Attacks against image recognition models are well-studied, allowing for targeted attacks even in black-box settings. This has not yet been achieved for speech models [74], even for untargeted attacks in a query-efficient manner. Both targeted and untargeted attacks on speech models typically require knowledge of the model's internals and a large number of queries. In contrast, we propose a query-efficient black-box attack that can generate an audio sample that will be reliably mistranscribed by the model, regardless of its architecture or parameterization. Our attack can generate an attack audio sample in logarithmic time while maintaining the audio quality.

#### Conclusion
ASR and AVI systems are increasingly important in security decisions, necessitating rigorous evaluation of their robustness. In this paper, we demonstrate black-box attacks against multiple models, showing that these systems rely on audio features that are not critical to human comprehension. We show that such attacks can be efficiently conducted by perturbing certain phonemes (e.g., vowels), causing significant misclassification. Furthermore, we demonstrate that our attacks work across models and do not affect human intelligibility. While adversarial training may provide partial mitigation, more substantial defenses are ultimately required to protect against these attacks.

#### References
[1] D. Williamson, M. Draper, G. Calhoun, and T. Barry, “Commercial Speech Recognition Technology in the Military Domain: Results of Two Recent Research Efforts,” vol. 8, no. 1, pp. 9–16, 2005.
[2] M. Cisse, Y. Adi, N. Neverova, and J. Keshet, “Houdini: Fooling deep structured prediction models,” arXiv preprint arXiv:1707.05373, 2017.
[3] X. Yuan, Y. Chen, Y. Zhao, Y. Long, X. Liu, K. Chen, S. Zhang, H. Huang, X. Wang, and C. A. Gunter, “Commandersong: A systematic approach for practical adversarial voice recognition,” in Proceedings of the USENIX Security Symposium, 2018.
[4] N. Carlini and D. Wagner, “Audio Adversarial Examples: Targeted Attacks on Speech-to-Text,” ArXiv e-prints, p. arXiv:1801.01944, Jan. 2018.
[5] L. Schönherr, K. Kohls, S. Zeiler, T. Holz, and D. Kolossa, “Adversarial attacks against automatic speech recognition systems via psychoacoustic hiding,” arXiv preprint arXiv:1808.05665, 2018.
[6] F. Kreuk, Y. Adi, M. Cisse, and J. Keshet, “Fooling end-to-end speaker verification by adversarial examples,” arXiv preprint arXiv:1801.03339, 2018.
[7] M. Alzantot, B. Balaji, and M. Srivastava, “Did you hear that? Adversarial examples against automatic speech recognition,” arXiv preprint arXiv:1801.00554, 2018.
[8] R. Taori, A. Kamsetty, B. Chu, and N. Vemuri, “Targeted adversarial examples for black box audio systems,” arXiv preprint arXiv:1805.07820, 2018.
[9] H. Abdullah, K. Warren, V. Bindschaedler, N. Papernot, and P. Traynor, “SoK: The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems,” In Submission, 2020.
[10] H. Abdullah, W. Garcia, C. Peeters, P. Traynor, K. Butler, and J. Wilson, “Practical hidden voice attacks against speech and speaker recognition systems,” Proceedings of the 2019 Network and Distributed System Security Symposium (NDSS), 2019.
[11] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields, D. Wagner, and W. Zhou, “Hidden voice commands.” in USENIX Security Symposium, 2016, pp. 513–530.
[12] Z. Yang, B. Li, P.-Y. Chen, and D. Song, “Characterizing audio adversarial examples using temporal dependency,” arXiv preprint arXiv:1809.10875, 2018.
[13] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards deep learning models resistant to adversarial attacks,” arXiv preprint arXiv:1706.06083, 2017.
[14] S. A. Gelfand, Hearing: An Introduction to Psychological and Physiological Acoustics, 5th ed. Informa Healthcare, 2009.
[15] L. R. Rabiner and R. W. Schafer, Digital processing of speech signals. Prentice Hall, 1978.
[16] S. Venugopalan, H. Xu, J. Donahue, M. Rohrbach, R. Mooney, and K. Saenko, “Translating videos to natural language using deep recurrent neural networks,” arXiv preprint arXiv:1412.4729, 2014.
[17] T. N. Sainath, O. Vinyals, A. Senior, and H. Sak, “Convolutional, long short-term memory, fully connected deep neural networks,” in 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), April 2015, pp. 4580–4584.
[18] O. Abdel-Hamid, A.-r. Mohamed, H. Jiang, and G. Penn, “Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition,” pp. 4277–4280, May 2012.
[19] T. N. Sainath, A.-r. Mohamed, B. Kingsbury, and B. Ramabhadran, “Deep convolutional neural networks for LVCSR,” pp. 8614–8618, May 2013.
[20] A. Graves, A.-r. Mohamed, and G. Hinton, “Speech recognition with deep recurrent neural networks,” ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings, vol. 38, March 2013.
[21] H. Sak, A. Senior, and F. Beaufays, “Long short-term memory recurrent neural network architectures for large scale acoustic modeling,” Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, pp. 338–342, January 2014.
[22] H. Sak, O. Vinyals, G. Heigold, A. Senior, E. McDermott, R. Monga, and M. Mao, “Sequence discriminative distributed training of long short-term memory recurrent neural networks,” Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, pp. 1209–1213, January 2014.
[23] H. Sak, A. Senior, K. Rao, and F. Beaufays, “Fast and accurate recurrent neural network acoustic models for speech recognition,” CoRR, vol. abs/1507.06947, 2015. [Online]. Available: http://arxiv.org/abs/1507.06947
[24] A. Graves and N. Jaitly, “Towards end-to-end speech recognition with recurrent neural networks,” in International Conference on Machine Learning, 2014, pp. 1764–1772.
[25] P. Lamere, P. Kwok, W. Walker, E. Gouvêa, R. Singh, B. Raj, and P. Wolf, “Design of the CMU Sphinx-4 decoder,” in Eighth European Conference on Speech Communication and Technology, 2003.
[26] D. Amodei et al., “Deep Speech 2: End-to-end speech recognition in English and Mandarin,” in Proceedings of The 33rd International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, M. F. Balcan and K. Q. Weinberger, Eds., vol. 48. New York, New York, USA: PMLR, June 20–22, 2016, pp. 173–182. [Online]. Available: http://proceedings.mlr.press/v48/amodei16.html
[27] “1,000 Most Common US English Words,” Last accessed in 2019, available at https://www.ef.edu/english-resources/english-vocabulary/top-1000-words/.
[28] H. Köpcke, A. Thor, and E. Rahm, “Evaluation of entity resolution approaches on real-world match problems,” Proceedings of the VLDB Endowment, vol. 3, no. 1-2, pp. 484–493, 2010.
[29] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami, “Practical Black-box Attacks Against Machine Learning,” in Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, 2017, pp. 506–519.
[30] J. Lu, H. Sibai, E. Fabry, and D. Forsyth, “NO Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles,” ArXiv e-prints, 2017.
[31] J. S. Garofolo et al., “Getting started with the DARPA TIMIT CD-ROM: An acoustic-phonetic continuous speech database,” National Institute of Standards and Technology (NIST), Gaithersburg, MD, vol. 107, p. 16, 1988.
[32] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “LibriSpeech: An ASR corpus based on public domain audio books,” in Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE, 2015, pp. 5206–5210.
[33] “The CMU Audio Database (also known as AN4 database),” Last accessed in 2019, available at http://www.speech.cs.cmu.edu/databases/an4/.
[34] “Project SHTOOKA - A Multilingual Database of Audio Recordings of Words and Sentences,” Last accessed in 2019, available at http://shtooka.net/.
[35] J. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Bengio, “Attention-based models for speech recognition,” in Advances in Neural Information Processing Systems, 2015, pp. 577–585.
[36] L. R. Rabiner and B.-H. Juang, Fundamentals of Speech Recognition. PTR Prentice Hall Englewood Cliffs, 1993, vol. 14.
[37] D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio, “End-to-end attention-based large vocabulary speech recognition,” in Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on. IEEE, 2016, pp. 4945–4949.
[38] “Azure Speaker Identification API,” Last accessed in 2019, available at https://azure.microsoft.com/en-us/services/cognitive-services/speaker-recognition/.
[39] “Who’s Smartest: Alexa, Siri, and Google Now?” Last accessed in 2019, available at https://bit.ly/2ScTpX7.
[40] “WER Are We - An Attempt at Tracking States of the Art(s) and Recent Results on Speech Recognition,” https://github.com/syhw/wer-are-we, Last accessed in 2019.
[41] “Google’s Speech Recognition Technology Now Has a 4.9% Word Error Rate,” Last accessed in 2019, available at https://bit.ly/2rGRtUQ.
[42] A. Danielsson, “Comparing Android Runtime with Native: Fast Fourier Transform on Android,” 2017, Master’s thesis. [Online]. Available: https://bit.ly/2MQpUV1
[43] “Twilio - Communication APIs for SMS, Voice, Video, and Authentication,” Last accessed in 2019, available at https://www.twilio.com/.