### Vibration Response

| Metric | Value |
|--------|-------|
| FNR    | 4.42% |
|        | 2.48% |
|        | <5%   |
|        | 6%    |
|        | 1.74% |
|        | 10%   |
|        | 6.3%  |
|        | 2.503%|
|        | 5.8%  |

### Challenge-Response

| Metric | Value |
|--------|-------|
| FPR    | 5.8%  |

**Challenge-Response Protocol:**
- **Security:** This protocol is effective against impersonators as it is nearly impossible to mimic an individual's heartbeat. A similar approach, utilizing heartbeat-induced vibrations captured by smartphones, achieved an EER of 2.48% against zero-effort impersonators [40]. However, this method may not be robust against replay and synthesis attacks in V’s threat model, where static biometric features can be leaked through a compromised channel.
- **Tooth Click Sound:** The authors of [46] used unique sounds from tooth clicks recorded by commodity devices, achieving good consistency and security through comprehensive user studies. The FPR for replay attacks decreased to 5.6% with increasing replay distance.
- **BreathPrint:** Chen et al. [4] utilized the distinctiveness of users' breath patterns, evaluating three types of breathing gestures (sniff, normal, and deep breathing). The FNR and FPR were 6% and 2%, respectively.
- **Taprint:** Chen et al. [5] designed a system called Taprint, which uses finger-tapping-induced vibrations for user authentication, achieving an EER of 1.74%.
- **VibWrite:** Liu et al. [21] leveraged the fact that varying user gestures change the frequency response measured from a vibrating surface, designing a platform called VibWrite for authenticating users via password, lock pattern, and gesture input. Using password input, the FPR was 2% even under imitation attacks when the password was leaked.

**Limitations:**
- While [4] and [46] acknowledge and evaluate security against replay attacks, they are not suitable for V’s threat model, where clean raw responses can be directly injected. The efficacy of replay attacks on these biometrics is highly dependent on the quality of replaying.
- In terms of protocol, our work is most similar to [19, 33], where replay attacks of raw responses can be stopped by adopting a challenge-response protocol with changing visual stimuli that elicit unique passive reflexive eye movements for each challenge and each user. The system achieves an EER of 6.3% against impersonation and rejects almost all replay samples. However, the security against synthesis attacks is guaranteed by the high complexity of synthesizing eye movements. This modality may not be suitable for V’s use case due to the static nature of the features used for verification.

### V’s Approach

V takes advantage of the challenge-response protocol and the modality of hand-surface vibration responses to achieve robust authentication. By utilizing the physiological characteristics of the hand and the nonlinearity in hand-surface vibration responses, V generates numerous disposable CRPs (Challenge-Response Pairs) to defend against various attacks, including raw signal replay and strong synthesis attacks. V attains low error rates while successfully rejecting all synthesized samples.

### Conclusion

This paper verifies the feasibility of using nonlinear responses from the hand-surface system for user authentication, relying on the unique physiological characteristics of the human hand with a challenge-response protocol. By building the prototype of V and conducting extensive user experiments, we validate several properties of V regarding usability and security. 

- **EER:** V achieves an EER against impersonation as low as 5.8% in long-term tests, with a negligible loss of 5.7% in short-term test trials, indicating good temporal permanence.
- **Training and Authentication Time:** This result can be attained with reasonable training effort and negligible authentication time of a 200-ms challenge.
- **Scalability:** We verify the scalability of V’s disposable CRPs by examining the FNR and FPR of individual challenges and challenges of different complexities.
- **Defensive Capabilities:** V succeeds in defending against all replay and synthesis attacks, benefiting from distinct features in each nonlinear response to a unique challenge.

Our findings suggest that V’s non-static biometrics are robust even when strong attackers are present. To further improve scalability, more effort should be put into investigating its performance in ubiquitous settings and the design space of CRPs.

### Acknowledgments

This work was supported by the Wisconsin Alumni Research Foundation and NSF under grants CNS-1719336 and CNS-1845469. We also acknowledge the contribution of our anonymous participants.

### References

[1] Surajudeen Adewusi, Subhash Rakheja, Patrice Marcotte, and Jérôme Boutine. 2010. Vibration transmissibility characteristics of the human hand–arm system under different postures, hand forces, and excitation levels. Journal of Sound and Vibration 329, 14 (2010), 2953–2971.

[2] Corey Ashby, Amit Bhatia, Francesco Tenore, and Jacob Vogelstein. 2011. Low-cost electroencephalogram (EEG) based authentication. In Proceedings of IEEE/EMBS Conference on Neural Engineering (NER). 442–445.

[3] Silvio Barra, Maria De Marsico, Michele Nappi, Fabio Narducci, and Daniel Riccio. 2019. A hand-based biometric system in visible light for mobile environments. Information Sciences 479 (2019), 472–485.

[4] Jagmohan Chauhan, Yining Hu, Suranga Seneviratne, Archan Misra, Aruna Seneviratne, and Youngki Lee. 2017. BreathPrint: Breathing acoustics-based user authentication. In Proceedings of the ACM Annual International Conference on Mobile Systems, Applications, and Services (MobiSys). 278–291.

[5] Wenqiang Chen, Lin Chen, Yandao Huang, Xinyu Zhang, Lu Wang, Rukhsana Ruby, and Kaishun Wu. 2019. Taprint: Secure text input for commodity smart wearables. In Proceedings of the ACM Annual International Conference on Mobile Computing and Networking (MobiCom).

[6] Yimin Chen, Jingchao Sun, Rui Zhang, and Yanchao Zhang. 2015. Your song your way: Rhythm-based two-factor authentication for multi-touch mobile devices. In Proceedings of IEEE Conference on Computer Communications (INFOCOM). 2686–2694.

[7] Mohammad Omar Derawi, Claudia Nickel, Patrick Bours, and Christoph Busch. 2010. Unobtrusive user-authentication on mobile phones using biometric gait recognition. In Proceedings of the IEEE International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP). 306–311.

[8] Ren G. Dong, Aaron W. Schopper, Thomas McDowell, Daniel E. Welcome, John Wu, W. Paul Smutz, Christopher M. Warren, and Subhash Rakheja. 2004. Vibration energy absorption (VEA) in human fingers-hand-arm system. Medical engineering & physics 26, 6 (2004), 483–492.

[9] Ren G. Dong, John Wu, and Daniel E. Welcome. 2005. Recent advances in biodynamics of human hand-arm system. Industrial health 43, 3 (2005), 449–471.

[10] Jesse Engel, Cinjon Resnick, Adam Roberts, Sander Dieleman, Mohammad Norouzi, Douglas Eck, and Karen Simonyan. 2017. Neural audio synthesis of musical notes with WaveNet autoencoders. In Proceedings of the International Conference on Machine Learning (ICML). 1068–1077.

[11] Anil Jain, Lin Hong, and Sharath Pankanti. 2000. Biometric identification. ACM Communications 43, 2 (2000), 90–98.

[12] Nathan D. Kalka, Jinyu Zuo, Natalia A. Schmid, and Bojan Cukic. 2006. Image quality assessment for iris biometric. In Biometric technology for human identification III, Vol. 6202. 62020D.

[13] Mohamed Khamis, Florian Alt, Mariam Hassib, Emanuel von Zezschwitz, Regina Hasholzner, and Andreas Bulling. 2016. Gazetouchpass: Multimodal authentication using gaze and touch on mobile devices. In Proceedings of the ACM Conference Extended Abstracts on Human Factors in Computing Systems (CHI). 2156–2164.

[14] Muhammad Khurram Khan, Jiashu Zhang, and Xiaomin Wang. 2008. Chaotic hash-based fingerprint biometric remote user authentication scheme on mobile devices. Chaos, Solitons & Fractals 35, 3 (2008), 519–524.

[15] Tomi Kinnunen, Filip Sedlak, and Roman Bednarik. 2010. Towards task-independent person authentication using eye movement signals. In Proceedings of the ACM Symposium on Eye-Tracking Research & Applications (ETRA). 187–190.

[16] Wolfgang Klippel. 2006. Tutorial: Loudspeaker nonlinearities–causes, parameters, symptoms. Journal of the Audio Engineering Society 54, 10 (2006), 907–939.

[17] Gierad Laput, Robert Xiao, and Chris Harrison. 2016. Viband: High-fidelity bio-acoustic sensing using commodity smartwatch accelerometers. In Proceedings of the ACM Annual Symposium on User Interface Software and Technology (UIST). 321–333.

[18] Zhengxiong Li, Zhuolin Yang, Chen Song, Changzhi Li, Zhengyu Peng, and Wenyao Xu. 2018. E-Eye: Hidden electronics recognition through mmwave nonlinear effects. In Proceedings of the ACM Conference on Embedded Networked Sensor Systems (SenSys). 68–81.

[19] Feng Lin, Kun Woo Cho, Chen Song, Wenyao Xu, and Zhanpeng Jin. 2018. Brain password: A secure and truly cancelable brain biometrics for smart headwear. In Proceedings of the ACM Annual International Conference on Mobile Systems, Applications, and Services (MobiSys). 296–309.

[20] Feng Lin, Chen Song, Yan Zhuang, Wenyao Xu, Changzhi Li, and Kui Ren. 2017. Cardiac scan: A non-contact and continuous heart-based user authentication system. In Proceedings of the ACM Annual International Conference on Mobile Computing and Networking (MobiCom). 315–328.

[21] Jian Liu, Chen Wang, Yingying Chen, and Nitesh Saxena. 2017. VibWrite: Towards finger-input authentication on ubiquitous surfaces via physical vibration. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS). 73–87.

[22] Peipei Liu and Hoon Sohn. 2017. Development of nonlinear spectral correlation between ultrasonic modulation components. NDT & E International 91 (2017), 120–128.

[23] Rui Liu, Cory Cornelius, Reza Rawassizadeh, Ronald Peterson, and David Kotz. 2018. Vocal resonance: Using internal body voice for wearable authentication. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) 2, 1 (2018), 19.

[24] Jaime Lorenzo-Trueba, Fuming Fang, Xin Wang, Isao Echizen, Junichi Yamagishi, and Tomi Kinnunen. 2018. Can we steal your vocal identity from the Internet?: Initial investigation of cloning Obama’s voice using GAN, WaveNet, and low-quality found data. arXiv preprint arXiv:1803.00860 (2018).

[25] Shrirang Mare, Mary Baker, and Jeremy Gummeson. 2016. A study of authentication in daily life. In Proceedings of the USENIX Symposium on Usable Privacy and Security (SOUPS). 189–206.

[26] Parimarjan Negi, Prafull Sharma, Vivek Jain, and Bahman Bahmani. 2018. K-means++ vs. behavioral biometrics: One loop to rule them all. In Proceedings of the Network and Distributed System Security Symposium (NDSS).

[27] Saurabh Panjwani and Achintya Prakash. 2014. Crowdsourcing attacks on biometric systems. In Proceedings of the USENIX Symposium on Usable Privacy and Security (SOUPS). 257–269.

[28] Jaebum Park, Nemanja Pažin, Jason Friedman, Vladimir M. Zatsiorsky, and Mark L. Latash. 2014. Mechanical properties of the human hand digits: Age-related differences. Clinical Biomechanics 29, 2 (2014), 129–137.

[29] Alexandre Presas, David Valentin, Eduard Egusquiza, Carme Valero, Mònica Egusquiza, and Matias Bossio. 2017. Accurate determination of the frequency response function of submerged and confined structures by using PZT-patches. Sensors 17, 3 (2017), 660.

[30] Marc Rébillat, Romain Hennequin, Etienne Corteel, and Brian F. G. Katz. 2011. Identification of cascade of Hammerstein models for the description of nonlinearities in vibrating devices. Journal of Sound and Vibration 330, 5 (2011), 1018–1038.

[31] Douglas A. Reynolds, Thomas F. Quatieri, and Robert B. Dunn. 2000. Speaker verification using adapted Gaussian mixture models. Digital Signal Processing 10, 1–3 (2000), 19–41.

[32] Michael Sherman, Gradeigh Clark, Yulong Yang, Shridatt Sugrim, Arttu Modig, Janne Lindqvist, Antti Oulasvirta, and Teemu Roos. 2014. User-generated free-form gestures for authentication: Security and memorability. In Proceedings of the ACM Annual International Conference on Mobile Systems, Applications, and Services (MobiSys). 176–189.

[33] Ivo Sluganovic, Marc Roeschlin, Kasper B. Rasmussen, and Ivan Martinovic. 2016. Using reflexive eye movements for fast challenge-response authentication. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS). 1056–1067.

[34] Yunpeng Song, Zhongmin Cai, and Zhi-Li Zhang. 2017. Multi-touch authentication using hand geometry and behavioral information. In Proceedings of the IEEE Symposium on Security and Privacy (S&P). 357–372.

[35] G. Edward Suh and Srinivas Devadas. 2007. Physical unclonable functions for device authentication and secret key generation. In Proceedings of the ACM/IEEE Design Automation Conference (DAC). 9–14.

[36] A. Talarico, M. Malvezzi, and Domenico Prattichizzo. 2014. Modeling the human touch: A FEM model of the human hand fingertips for haptic application. In Proceedings of the COMSOL Conference.

[37] Aäron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew W. Senior, and Koray Kavukcuoglu. 2016. WaveNet: A generative model for raw audio. arXiv preprint arXiv:1609.03499 (2016).

[38] Shreyas Venugopalan, Felix Juefei-Xu, Benjamin Cowley, and Marios Savvides. 2015. Electromyograph and keystroke dynamics for spoof-resistant biometric authentication. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPR). 109–118.

[39] Alexander Voishvillo, Alexander Terekhov, Eugene Czerwinski, and Sergei Alexandrov. 2004. Graphing, interpretation, and comparison of results of loudspeaker nonlinear distortion measurements. Journal of the Audio Engineering Society 52, 4 (2004), 332–357.

[40] Lei Wang, Kang Huang, Ke Sun, Wei Wang, Chen Tian, Lei Xie, and Qing Gu. 2018. Unlock with your heart: Heartbeat-based authentication on commercial mobile phones. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) 2, 3 (2018), 140.

[41] Zhizheng Wu, Junichi Yamagishi, Tomi Kinnunen, Cemal Hanilçi, Mohammed Sahidullah, Aleksandr Sizov, Nicholas Evans, and Massimiliano Todisco. 2017. ASVspoof: The automatic speaker verification spoofing and countermeasures challenge. IEEE Journal of Selected Topics in Signal Processing 11, 4 (2017), 588–604.

[42] Vladimir Yu. Zaitsev, Lev A. Matveev, and Alex Matveyev. 2011. Elastic-wave modulation approach to crack detection: Comparison of conventional modulation and higher-order interactions. NDT & E International 44, 1 (2011), 21–31.

[43] Linghan Zhang, Sheng Tan, and Jie Yang. 2017. Hearing your voice is not enough: An articulatory gesture-based liveness detection for voice authentication. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS). 57–71.

[44] Linghan Zhang, Sheng Tan, Jie Yang, and Yingying Chen. 2016. VoiceLive: A phoneme localization-based liveness detection for voice authentication on smartphones. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS). 1080–1091.

[45] Zhaoyang Zhang, Honggang Wang, Athanasios V. Vasilakos, and Hua Fang. 2012. ECG-cryptography and authentication in body area networks. IEEE Transactions on Information Technology in Biomedicine 16, 6 (2012), 1070–1078.

[46] Yongpan Zou, Meng Zhao, Zimu Zhou, Jiawei Lin, Mo Li, and Kaishun Wu. 2018. BiLock: User authentication via dental occlusion biometrics. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) 2, 3 (2018), 152.