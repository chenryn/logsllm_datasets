### Analysis of the Algorithm and Its Impact on Anonymity

Our analysis of the proposed algorithm within our model demonstrates that it significantly enhances the anonymity of onion routing, particularly in scenarios where an adversary can compromise a substantial portion of the network. 

### Trust Information and Adversary Knowledge

An adversary who gains knowledge of the trust placed in specific routers may infer information about the resources a user (or her organization) has employed to protect her communications. For de-anonymization, as discussed in Section 4.1, trust information must first be acquired. Due to space constraints, we defer a detailed discussion of how an adversary might learn trust values to future work. Similarly, we do not explore the implications of an adversary learning this information in the context of the usage scenario and algorithm described, or in other cases.

For example, if Alice is a "road warrior" traveling on behalf of her employer and wishes to log in from her hotel to her workstation back at the office, starting her circuits at highly trusted nodes could reveal information about who she is trying to hide from. This scenario would require a complementary uphill-trust algorithm, although it is not simply a reverse of the downhill algorithm. Other nuances, such as the need for dynamic hops, also come into play.

### Trust in Mix Networks

In mix networks, trust can help avoid compromised routers, but the adversary and communication assumptions differ, leading to different strategies. Our general model encompasses both onion-routing and mix networks, as well as other types of anonymous communication. However, in this paper, we focus on onion-routing networks. We plan to investigate the impact of trust on other protocols for secure route selection.

### Future Work and Open Questions

We intend to explore several issues in future work:
- **User Classes and Nonuniform Adversaries:** How do multiple user classes, each trying to avoid distinct nonuniform adversaries, affect one another?
- **Robustness and Incentive Mechanisms:** How robust are our results when a fraction of users deviate from the optimal strategy, and what incentive mechanisms can encourage cooperation?
- **Path-Selection Algorithms:** Users with flat trust distributions will choose \( \ell = 1 \) plus two dynamic hops, which aligns with the current Tor path-selection algorithm [39].
- **Adversary Attacks:** Adversaries could employ various attack methods, such as congestion attacks [23, 36], DoS attacks [4], changing the network topology, and manipulating trust values.
- **Trust Among Links:** We aim to investigate the effect of different trust values among links to account for real-world Internet routing issues [21, 24].
- **Roving Adversary:** We would like to study a roving adversary that attempts to compromise different sets of nodes over time [38, 48].
- **Compromise Distribution:** The joint distribution of events where adversaries compromise nodes could be arbitrary, rather than assuming independence between nodes.
- **Attacker Budget and Costs:** Assigning costs to attempting compromise on a node and giving the attacker a budget.
- **Multiple Adversaries:** Users might face multiple adversaries, and each user could set a cost for losing privacy to each adversary. For instance, Alice might prefer to be exposed by Eve rather than Mallory.

### Conclusion

Although this is a simple example, we have shown that our new routing algorithm has significant security implications in plausible usage scenarios. Our model incorporates trust-based routing, a novel aspect of both anonymous and secure communication. We hope that other researchers will see the potential of our approach and take up these questions or be inspired to explore our model through their own inquiries.

### Acknowledgments

The authors would like to thank Nick Hopper for his guidance in improving this paper. We also extend our gratitude to George Danezis, Karsten Loesing, and the anonymous reviewers for their valuable comments on drafts of this paper. This work was supported by ONR, NSF, and DARPA.

### References

[1] K. Bauer, D. McCoy, D. Grunwald, T. Kohno, and D. Sicker. Low-resource routing attacks against Tor. In Proceedings of the Workshop on Privacy in the Electronic Society (WPES 2007), Washington, DC, USA, October 2007.

[2] R. Beauxis and C. Palamidessi. Probabilistic and nondeterministic aspects of anonymity. Theoretical Computer Science, 410(41):4006–4025, 2009.

[3] A. Beimel and S. Dolev. Buses for anonymous message delivery. Journal of Cryptology, 16(1):25–39, 2003.

[4] N. Borisov, G. Danezis, P. Mittal, and P. Tabriz. Denial of service or denial of security? How attacks on reliability can compromise anonymity. In Proceedings of the 14th ACM Conference on Computer and Communications Security (CCS), October 2007.

[5] J. Camenisch and A. Lysyanskaya. A formal treatment of onion routing. In V. Shoup, editor, Advances in Cryptology – CRYPTO 2005: 25th Annual International Cryptology Conference, pages 169–187. Springer-Verlag, LNCS 3621, August 2005.

[6] D. Chaum. Untraceable electronic mail, return addresses, and digital pseudonyms. Communications of the ACM, 4(2), 1981.

[7] D. Chaum. The dining cryptographers problem: Unconditional sender and recipient untraceability. Journal of Cryptology: The Journal of the International Association for Cryptologic Research, 1(1):65–75, 1988.

[8] T. M. Cover and J. A. Thomas. Elements of information theory. Wiley-Interscience, New York, NY, USA, 1991.

[9] G. Danezis. Mix-networks with restricted routes. In R. Dingledine, editor, Privacy Enhancing Technologies: Third International Workshop, PET 2003, pages 1–17. Springer-Verlag, LNCS 2760, 2003.

[10] G. Danezis and R. Clayton. Route fingerprinting in anonymous communications. In Sixth IEEE International Conference on Peer-to-Peer Computing, P2P 2006, pages 69–72. IEEE Computer Society Press, 2006.

[11] G. Danezis, C. Diaz, and P. Syverson. Anonymous communication. In B. Rosenberg, editor, Handbook of Financial Cryptography. CRC Press, 2010.

[12] G. Danezis, R. Dingledine, and N. Mathewson. Mixminion: Design of a Type III Anonymous Remailer Protocol. In Proceedings of the 2003 IEEE Symposium on Security and Privacy, pages 2–15, 2003.

[13] G. Danezis and A. Serjantov. Statistical disclosure or intersection attacks on anonymity systems. In Deploying low-latency anonymity: Design challenges and social factors. IEEE Security & Privacy, 5(5):83–87, September/October 2007.

[14] C. Díaz, S. Seys, J. Claessens, and B. Preneel. Towards measuring anonymity. In R. Dingledine and P. Syverson, editors, Privacy Enhancing Technologies, Second International Workshop, PET 2002, Revised Papers, pages 54–68. Springer-Verlag, LNCS 2482, 2003.

[15] R. Dingledine, M. J. Freedman, D. Hopwood, and D. Molnar. A reputation system to increase MIX-net reliability. In I. S. Moskowitz, editor, Information Hiding: 4th International Workshop, IH 2001, pages 126–141, Pittsburgh, PA, USA, April 2001. Springer-Verlag, LNCS 2137.

[16] R. Dingledine and N. Mathewson. Anonymity loves company: Usability and the network effect. In R. Anderson, editor, Fifth Workshop on the Economics of Information Security (WEIS 2006), June 2006.

[17] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-generation onion router. In Proceedings of the 13th USENIX Security Symposium, pages 303–319. USENIX Association, August 2004.

[18] R. Dingledine and P. Syverson. Reliable MIX cascade networks through reputation. In M. Blaze, editor, Financial Cryptography, 6th International Conference, FC 2002, pages 253–268. Springer-Verlag, LNCS 2357, 2003.

[19] S. Dolev and R. Ostrovsky. Xor-trees for efficient anonymous multicast and reception. ACM Transactions on Information and System Security, 3(2):63–84, 2000.

[20] M. Edman and P. Syverson. AS-awareness in Tor path selection. In S. Jha, A. D. Keromytis, and H. Chen, editors, CCS’09: Proceedings of the 16th ACM Conference on Computer and Communications Security, pages 380–389. ACM Press, 2009.

[21] M. Edman and B. Yener. On anonymity in an electronic society: A survey of anonymous communication systems. ACM Computing Surveys, 42(1), 2010.

[22] N. S. Evans, R. Dingledine, and C. Grothoff. A practical congestion attack on Tor using long paths. In Proceedings of the 18th USENIX Security Symposium, pages 33–50, Montreal, Canada, August 2009. USENIX Association.

[23] N. Feamster and R. Dingledine. Location diversity in anonymity networks. In Proceedings of the Workshop on Privacy in the Electronic Society (WPES 2004), pages 66–76, 2004.

[24] S. Goel, M. Robson, M. Polte, and E. G. Sirer. Herbivore: A scalable and efficient protocol for anonymous communication. Technical Report 2003-1890, Cornell University, Ithaca, NY, February 2003.

[25] D. M. Goldschlag, M. G. Reed, and P. F. Syverson. Hiding routing information. In Information Hiding: First International Workshop, Proceedings, pages 137–150. Springer-Verlag, LNCS 1174, 1996.

[26] P. Golle and A. Juels. Dining cryptographers revisited. In Proceedings of the 2006 IEEE Symposium on Security and Privacy. IEEE CS, May 2006.

[27] C. Gulcu and G. Tsudik. Mixing E-mail with Babel. In Proceedings of the Network and Distributed Security Symposium (NDSS 1996), pages 2–16, 1996.

[28] A. Hintz. Fingerprinting websites using traffic analysis. In R. Dingledine and P. Syverson, editors, Privacy Enhancing Technologies: Second International Workshop, PET 2002, pages 171–178, San Francisco, CA, USA, April 2002. Springer-Verlag, LNCS 2482.

[29] N. Hopper, E. Y. Vasserman, and E. Chan-Tin. How much anonymity does network latency leak? ACM Transactions on Information and System Security, 13(2):13–28, 2010. February.

[30] A. Johnson and P. Syverson. More anonymous onion routing through trust. In 22nd IEEE Computer Security Foundations Symposium, CSF 2009, pages 3–12, Port Jefferson, New York, July 2009. IEEE Computer Society.

[31] D. Kesdogan, D. Agrawal, and S. Penz. Limits of anonymity in open environments. In Proceedings of Information Hiding Workshop (IH 2002), 2002.

[32] M. Liberatore and B. N. Levine. Inferring the source of encrypted HTTP connections. In R. N. Wright, S. De Capitani di Vimercati, and V. Shmatikov, editors, CCS’06: Proceedings of the 13th ACM Conference on Computer and Communications Security, pages 255–263. ACM Press, 2006.

[33] N. Mathewson and R. Dingledine. Practical traffic analysis: Extending and resisting statistical disclosure. In D. Martin and A. Serjantov, editors, Privacy Enhancing Technologies, 4th International Workshop, PET 2004, Revised Selected Papers, pages 17–34. Springer Verlag, LNCS 3424, 2005.

[34] U. Möller, L. Cottrell, P. Palfrader, and L. Sassaman. Mixmaster Protocol — Version 2. Draft, 2003.

[35] S. J. Murdoch and G. Danezis. Low-cost traffic analysis of Tor. In Proceedings of the 2005 IEEE Symposium on Security and Privacy, pages 183–195, 2005.

[36] S. J. Murdoch and P. Zieliński. Sampled traffic analysis by internet-exchange-level adversaries. In N. Borisov and P. Golle, editors, Proceedings of the Seventh Workshop on Privacy Enhancing Technologies (PET 2007), Ottawa, Canada, June 2007. Springer.

[37] R. Ostrovsky and M. Yung. How to withstand mobile virus attacks. In Proceedings of the Tenth ACM Symposium on Principles of Distributed Computing (PODC ’91), pages 51–59. ACM Press, 1991.

[38] P. Rackoff and D. R. Simon. Cryptographic defense against traffic analysis. In Proceedings of ACM Symposium on Theory of Computing, pages 672–681, 1993.

[39] M. Reiter and A. Rubin. Crowds: Anonymity for web transactions. ACM Transactions on Information and System Security, 1(1):66–92, 1998.

[40] V. Sassone, S. Hamadou, and M. Yang. Trust in anonymity networks. In P. Gastin and F. Laroussinie, editors, CONCUR 2010 - Concurrency Theory: 21st International Conference, pages 48–70. Springer-Verlag, LNCS 6269, 2010.

[41] B. Schneier. Secret German IP addresses leaked. Schneier on Security, http://www.schneier.com/, November 2008.

[42] A. Serjantov and G. Danezis. Towards an information theoretic metric for anonymity. In R. Dingledine and P. Syverson, editors, Privacy Enhancing Technologies, Second International Workshop, PET 2002, Revised Papers, pages 41–53. Springer-Verlag, LNCS 2482, 2003.

[43] P. Syverson. Why I’m not an entropist. In Seventeenth International Workshop on Security Protocols. Springer-Verlag, LNCS, 2009. Forthcoming.

[44] P. Syverson. Sleeping dogs lie in a bed of onions but wake when mixed. In 4th Hot Topics in Privacy Enhancing Technologies (HotPETs 2011), July 2011.

[45] P. Syverson, A. Johnson, R. Dingledine, and N. Mathewson. Trust-based anonymous communication: Adversary models and routing algorithms. Technical report, University of Texas at Austin, 2011.

[46] P. Syverson, G. Tsudik, M. Reed, and C. Landwehr. Towards an analysis of onion routing security. In H. Federrath, editor, Designing Privacy Enhancing Technologies: International Workshop on Design Issues in Anonymity and Unobservability, Proceedings, pages 96–114. Springer-Verlag, LNCS 2009, July 2001.

[47] The Tor project home page. https://www.torproject.org/.

[48] Tor metrics portal. https://metrics.torproject.org/, April 2011.

[49] Y. Zhu, X. Fu, B. Graham, R. Bettati, and W. Zhao. On flow correlation attacks and countermeasures in mix networks. In Proceedings of Privacy Enhancing Technologies workshop (PET 2004), pages 207–225, 2004.