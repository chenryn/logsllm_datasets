### Program Invariant Verification and Security Skeleton Extraction

Our program \( P(m) \) adheres to the specified invariant. We successfully extracted the security skeleton from Flicker's approximately 250 lines of C code. To ensure that the skeleton maintains the exact invariant from our security proof, we verified the presence of instructions for evaluating the function \( f \), the extension of the End-Of-Life (EOL) marker into \( m.d pcr.k \), and that each instruction is executed only once across all code paths. In several instances, multiple C instructions were mapped to a single action, as these instructions refine the action. For example, extending the EOL involves two instructions: a `memset` to create the EOL sequence and a call to a wrapper for the extend instruction. The entire manual process of extracting the security skeleton and auditing the invariant took less than one hour for an individual with no prior experience with the Flicker security kernel. Although we did not formally verify the property, a promising direction for future work is to use these invariants to derive refined invariants for implementation verification, possibly using software model checking techniques.

### Related Work

LS2 draws on conceptual ideas from Protocol Composition Logic (PCL) [3], particularly the local reasoning style used to prove security properties without explicitly considering adversary actions. In PCL, global security properties are derived by combining properties of individual protocol steps with invariants proved by induction over the protocol programs executed by honest parties. LS2 extends this reasoning to a richer language that includes network communication, cryptography, shared memory, memory protection, machine resets, and dynamically loaded unknown code. The insights underlying the new proof rules are detailed in Section 2.2.

Technically, LS2 differs significantly from PCL. Instead of associating pre-conditions and post-conditions with all actions in a process, LS2 models time explicitly, associating monotonically increasing time points with events on a trace. This explicit time model allows us to express invariants about memory, such as ensuring a memory location contains the same value throughout an interval \([t1, t2]\). Explicit time also facilitates reasoning about the relative order of events. While explicit time may seem low-level and cumbersome, the proof system for LS2 uses it in a limited way, similar to temporal logics like Linear Temporal Logic (LTL) [31]. It is plausible to rework the proof system using LTL operators instead of explicit time. However, we believe a real-time model may be necessary for analyzing certain systems of interest (e.g., [32]–[34]).

LS2 shares features with other logics of programs [8], [10], [35]. Hoare logic and dynamic logic focus on sequential imperative programs and do not consider concurrency, network communication, or adversaries. LS2’s abstract locks are similar to regions in concurrent separation logic [8], which are used to reason about synchronized access to memory. However, LS2 uses locks to enforce data integrity, while regions prevent race conditions. Another key difference is that concurrent separation logic does not consider network communication and typically does not include an adversary model. Adversaries could be encoded as regular programs, but proving invariants would require induction over both the honest parties' and the attacker's steps.

Previous proposals for reasoning about dynamically loaded code use higher-order extensions of Hoare logic [24]–[28], but they are restricted to sequential programs and require known invariants at the point of the call. LS2 addresses this problem in the context of concurrent execution, where one thread can modify code loaded by another. As shown in Section 4.1, the (Jump) rule allows combining evidence of code execution with separate evidence of the code's identity to reason precisely about the effects of the jump. This reasoning is essential for applications like trusted computing and is not possible in prior work.

Several analyses of trusted computing have been conducted. Abadi and Wobber used an authorization logic to describe NGSCB, the predecessor to TCG [37], clarifying basic concepts rather than proving specific properties. Chen et al. developed a formal logic for remote attestation protocols [38]. Unlike LS2, these logics are not tied to the execution semantics of the protocols. Gurgens et al. used a model checker to analyze TCG protocols [39], and Millen et al. employed a model checker to understand trust relationships in remote attestation [40]. Our analysis with LS2 complements these approaches by proving security properties for an infinite number of simultaneous protocol invocations, using a more abstract model of TPM primitives. Lin [41] used a theorem prover and model finder to analyze TPM security against invalid API call sequences.

### Conclusion

In this paper, we introduced LS2 and applied it to a substantial case study of trusted computing attestation protocols. Designing LS2 was conceptually and technically challenging, especially in defining a realistic adversary model and formulating sound reasoning principles for dynamically loaded, untrusted code. The proof system supports high-level abstraction, which was particularly useful in the case studies, yielding many insights into the security of trusted computing systems.

Future work will extend this research to model and analyze security properties of web browsers, security hypervisors, and virtual machine monitors. We also plan to develop further principles for modeling and reasoning about security at the system interface level, supporting richer access control models and system composition and refinement.

### Acknowledgments

The authors thank Michael Hicks, Jonathan McCune, and the anonymous reviewers for their valuable comments and suggestions. This work was partially supported by the U.S. Army Research Office contract on Perpetually Available and Secure Information Systems (DAAD19-02-1-0389) to CMU’s CyLab, the NSF Science and Technology Center TRUST, and the NSF CyberTrust grant “Realizing Verifiable Security Properties on Untrusted Computing Platforms.” Jason Franklin is supported in part by an NSF Graduate Research Fellowship.

### References

[1] Trusted Computing Group (TCG), "https://www.trustedcomputinggroup.org/", 2008.
[2] A. Datta, A. Derek, J. C. Mitchell, and D. Pavlovic, "A derivation system and compositional logic for security protocols," Journal of Computer Security, vol. 13, no. 3, pp. 423–482, 2005.
[3] A. Datta, A. Derek, J. C. Mitchell, and A. Roy, "Protocol Composition Logic (PCL)," Electr. Notes Theor. Comput. Sci., vol. 172, pp. 311–358, 2007.
[4] N. Durgin, J. C. Mitchell, and D. Pavlovic, "A compositional logic for proving security properties of protocols," Journal of Computer Security, vol. 11, pp. 677–721, 2003.
[5] A. Roy, A. Datta, A. Derek, J. C. Mitchell, and J.-P. Seifert, "Secrecy analysis in protocol composition logic," Formal Logical Methods for System Security and Correctness, 2008.
[6] R. Milner, M. Tofte, and R. Harper, The Definition of Standard ML. Cambridge, MA, USA: MIT Press, 1990.
[7] J. Saltzer and M. Schroeder, "The protection of information in computer systems," Proceedings of the IEEE, vol. 63, no. 9, pp. 1278–1308, September 1975.
[8] S. Brookes, "A semantics for concurrent separation logic," in Proceedings of 15th International Conference on Concurrency Theory, 2004.
[9] Z. Manna and A. Pnueli, Temporal Verification of Reactive Systems: Safety. Springer-Verlag, 1995.
[10] C. A. R. Hoare, "An axiomatic basis for computer programming," Communications of the ACM, vol. 12, no. 10, pp. 576–580, 1969.
[11] P. W. O’Hearn, J. C. Reynolds, and H. Yang, "Local reasoning about programs that alter data structures," in Proceedings of the 15th International Workshop on Computer Science Logic. London, UK: Springer-Verlag, 2001, pp. 1–19.
[12] J. C. Reynolds, "Separation logic: A logic for shared mutable data structures," in Proceeding of the 17th Annual IEEE Symposium on Logic in Computer Science (LICS). IEEE Computer Society, 2002, pp. 55–74.
[27] H. Cai, Z. Shao, and A. Vaynberg, "Certified self-modifying code," in ACM SIGPLAN Conference on Programming Language Design and Implementation. New York, NY, USA: ACM, 2007, pp. 66–77.
[13] Trusted Computing Group, "TCG Specification Architecture Overview, Specification Revision 1.4," https://www.trustedcomputinggroup.org/groups/TCG 1 4 Architecture Overview.pdf, August 2007.
[14] TCG, "PC client specific TPM interface specification (TIS)," Version 1.2, Revision 1.00, Jul. 2005.
[15] Advanced Micro Devices, "AMD64 virtualization: Secure virtual machine architecture reference manual," AMD Publication no. 33047 rev. 3.01, May 2005.
[16] Intel Corporation, "Intel Trusted Execution Technology: Software Development Guide," Document Number: 315168-005, June 2008.
[17] A. Datta, J. Franklin, D. Garg, and D. Kaynar, "A logic of secure systems and its application to trusted computing," Carnegie Mellon University, Tech. Rep. CMU-CyLab-09-001, 2009.
[18] E. M. Chan, J. C. Carlyle, F. M. David, R. Farivar, and R. H. Campbell, "BootJacker: Compromising computers using forced restarts," in Proceedings of 15th ACM Conference on Computer and Communications Security, 2008.
[19] S. Garriss, R. C´aceres, S. Berger, R. Sailer, L. van Doorn, and X. Zhang, "Towards trustworthy kiosk computing," in Workshop on Mobile Computing Systems and Applications, Feb. 2006.
[20] H. DeYoung, D. Garg, and F. Pfenning, "An authorization logic with explicit time," in Proceedings of the 21st IEEE Computer Security Foundations Symposium (CSF-21), Jun. 2008.
[21] J. Reed, "Hybridizing a logical framework," in International Workshop on Hybrid Logic 2006 (HyLo 2006), ser. Electronic Notes in Computer Science, August 2006.
[22] T. Bra¨uner and V. de Paiva, "Towards constructive hybrid logic," in Electronic Proceedings of Methods for Modalities 3 (M4M3), 2003.
[23] AMD Corp., "Secure virtual machine architecture reference manual," May 2005. Available: http://www.amd.com/us-en/assets/content type/white papers and tech docs/33047.pdf
[24] N. Krishnaswami, "Separation logic for a higher-order typed language," in Workshop on Semantics, Program Analysis and Computing Environments for Memory Management, SPACE06, 2006.
[25] H. Thielecke, "Frame rules from answer types for code pointers," in 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages. New York, NY, USA: ACM, 2006, pp. 309–319.
[26] Z. Ni and Z. Shao, "Certified assembly programming with embedded code pointers," in 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages. New York, NY, USA: ACM, 2006, pp. 320–333.
[28] A. Nanevski, G. Morrisett, and L. Birkedal, "Hoare type theory, polymorphism and separation," Journal of Functional Programming, vol. 18, no. 5&6, pp. 865–911, 2008.
[29] B. Kauer, "OSLO: Improving the security of trusted computing," in Proceedings of the USENIX Security Symposium, Aug. 2007.
[30] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and H. Isozaki, "Flicker: An execution infrastructure for TCB minimization," in Proceedings of the ACM European Conference in Computer Systems (EuroSys), Apr. 2008.
[31] A. Pnueli, "The temporal logic of programs," in Proceedings of 19th Annual Symposium on Foundations on Computer Science, 1977.
[32] R. Kennell and L. H. Jamieson, "Establishing the genuinity of remote computer systems," in Proceedings of the 2003 USENIX Security Symposium, Aug. 2003.
[33] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla, "SWATT: Software-based attestation for embedded devices," in Proceedings of the IEEE Symposium on Security and Privacy, May 2004.
[34] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla, "Pioneer: Verifying code integrity and enforcing untampered code execution on legacy platforms," in Proceedings of ACM Symposium on Operating Systems Principles (SOSP), Oct. 2005.
[35] D. Harel, D. Kozen, and J. Tiuryn, Dynamic Logic, ser. Foundations of Computing. MIT Press, 2000.
[36] L. Lamport, "The temporal logic of actions," ACM Transactions on Programming Languages and Systems, vol. 16, no. 3, May 1994.
[37] M. Abadi and T. Wobber, "A logical account of NGSCB," in Proceedings of Formal Techniques for Networked and Distributed Systems, 2004.
[38] S. Chen, Y. Wen, and H. Zhao, "Formal analysis of secure bootstrap in trusted computing," in Proceedings of 4th International Conference on Autonomic and Trusted Computing, 2007.
[39] S. Gurgens, C. Rudolph, D. Scheuermann, M. Atts, and R. Plaga, "Security evaluation of scenarios based on the TCG’s TPM specification," in Proceedings of 12th European Symposium On Research In Computer Security, 2007.
[40] J. Millen, J. Guttman, J. Ramsdell, J. Sheehy, and B. Sniffen, "Analysis of a measured launch," The MITRE Corporation, Tech. Rep., 2007.
[41] A. H. Lin, "Automated analysis of security APIs," Master’s thesis, Massachusetts Institute of Technology, 2005.