### δ. Randomized Procedure for (ε, δ)-DD-Privacy

There exists a randomized procedure to generate \( r = (r_1, \ldots, r_n) \) that is \((\varepsilon, \delta)\)-differential privacy (DD-private) with respect to the sum. Specifically, for all \( x \in (\mathbb{Z}_p)^n \), and for all \( 0 < \varepsilon \) and \( 0 < \delta < 1 \), the procedure ensures that the generated values maintain the required privacy guarantees.

### Hierarchical Aggregation

In a hierarchical structure, each entity at level \( j > 1 \) is given the sum of the secrets of the entities at the level below. For \( j = 1 \), each entity above the leaf nodes is given the negative of the sum of the secrets of the participants below it, as in the basic construction.

### Product Computation

The basic construction can be easily modified to support the oblivious computation of a product instead of a sum. This is achieved by encrypting \( \chi \) as \( c \leftarrow \chi \cdot H(t)^{\text{sk}_i} \). Since the plaintext is no longer in the exponent, this scheme for products does not suffer from the small plaintext restriction.

### Open Research Challenges

This paper introduces a new problem: how an untrusted data aggregator can compute aggregate statistics over ciphertexts from multiple sources while preserving each individual's privacy in a strong sense. We formally defined privacy notions and demonstrated a construction allowing the aggregator to compute the sum statistic for time series data.

Several intriguing and challenging problems remain open. We hope to inspire future research efforts in this new direction, particularly in addressing the following challenges:

#### Large Plaintext Space Support

One limitation of our cryptographic construction is that it supports only polynomial-sized plaintext spaces for computing sums. However, when our construction is modified to support the product statistic, it can readily support large plaintext spaces. A key challenge is to design a scheme that supports large plaintext spaces for computing sums. Promising directions include exploring other algebraic primitives such as bilinear groups, Paillier groups, and lattices.

#### Richer Statistics

An important goal is to support richer statistics. In general, the aggregator may wish to evaluate an arbitrary polynomial-time function \( f \) on the participants' inputs. While recent advances in fully homomorphic encryption schemes [8, 18] are encouraging, they do not directly apply in our setting because their homomorphic operations are performed over ciphertexts encrypted under the same key. It is both interesting and challenging to consider expressive homomorphic encryption schemes over ciphertexts encrypted under multiple user keys.

#### Dynamic Joins and Leaves

In our current scheme, whenever a participant dynamically joins or leaves the system, we need to perform the trusted setup phase again. This makes our scheme more suitable for scenarios where the set of participants is relatively static over time. An important open problem is to provide better support for dynamic joins and leaves, a capability that is valuable in systems with high churn.

#### Node Failures

Participants may fail to upload their encrypted values in a certain time period, or malicious participants may launch Denial-of-Service attacks. When this happens, our scheme requires that the aggregator cannot decrypt any partial information about the remaining participants. This requirement is inherent in our security definition. Allowing the aggregator to decrypt partial information about a subset of users would enable a malicious aggregator to use inputs from only a subset of the participants. We acknowledge that this mode of failure may not be desirable in some practical settings. Therefore, one open problem is how to support graceful degradation in the face of failures. This question is challenging to answer, as it remains unclear what security notion one might employ to deal with node failures. The security definition must somehow reconcile two conflicting goals: the requirement of graceful degradation in the presence of failures and the requirement that the aggregator should not learn anything from a subset of the inputs.

### Acknowledgments

We gratefully thank the anonymous reviewers for their insightful comments and feedback.

Dawn Song is partially supported by the National Science Foundation under Grants No. 0716230, 0448452, and CCF-0424422, and by the Office of Naval Research under MURI Grant No. N000140911081. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or the Office of Naval Research.

### References

[1] D. J. Bernstein and T. L. (editors). eBACS: ECRYPT benchmarking of cryptographic systems. http://bench.cr.yp.to, accessed 7 March 2011.
[2] D. Boneh, E.-J. Goh, and K. Nissim. Evaluating 2-DNF formulas on ciphertexts. In TCC, 2005.
[3] C. Castelluccia, A. C.-F. Chan, E. Mykletun, and G. Tsudik. Efficient and provably secure aggregation of encrypted data in wireless sensor networks. ACM Trans. Sen. Netw., 5(3):1–36, 2009.
[4] A. Cavoukian, J. Polonetsky, and C. Wolf. Smart-Privacy for the smart grid: embedding privacy into the design of electricity conservation. Identity in the Information Society, 3(2):275–294, August 2010.
[5] C. Dwork. Differential privacy. Invited talk at ICALP, 2006.
[6] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves: Privacy via distributed noise generation. In EUROCRYPT, 2006.
[7] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private data analysis. In TCC, 2006.
[8] C. Gentry. Fully homomorphic encryption using ideal lattices. In STOC, pages 169–178, 2009.
[9] A. Ghosh, T. Roughgarden, and M. Sundararajan. Universally utility-maximizing privacy mechanisms. In STOC '09: Proceedings of the 41st annual ACM symposium on Theory of computing, 2009.
[10] O. Goldreich. Secure multi-party computation. http://www.wisdom.weizmann.ac.il/˜oded/PS/prot.ps.
[11] E. Magkos, M. Maragoudakis, V. Chrissikopoulos, and S. Gritzalis. Accurate and large-scale privacy-preserving data mining using the election paradigm. Data & Knowledge Engineering, 2009.
[12] J. Menezes, P. C. V. Oorschot, and S. A. Vanstone. Handbook of applied cryptography. CRC Press, 1997.
[13] I. Mironov, O. Pandey, O. Reingold, and S. Vadhan. Computational differential privacy. In CRYPTO, 2009.
[14] A. D. Molina, M. Salajegheh, and K. Fu. HIC-CUPS: health information collaborative collection using privacy and security. In SPIMACS'09, pages 21–30, 2009.
[15] E. L. Quinn. Privacy and the new energy infrastructure. SSRN, Feb 2009.
[16] V. Rastogi and S. Nath. Differentially private aggregation of distributed time-series with transformation and encryption. In SIGMOD 2010, pages 735–746, 2010.
[17] E. G. Rieffel, J. Biehl, W. van Melle, and A. J. Lee. Secured histories: computing group statistics on encrypted data while preserving individual privacy. In submission, 2010.
[18] M. van Dijk, C. Gentry, S. Halevi, and V. Vaikuntanathan. Fully homomorphic encryption over the integers. In EUROCRYPT, 2010.
[19] Z. Yang, S. Zhong, and R. N. Wright. Privacy-preserving classification of customer data without loss of accuracy. In SIAM SDM, 2005.

### A. Proof of Aggregator Oblivious Security

First, we prove that the following intermediate game is difficult to win, given that the Decisional Difﬁe-Hellman (DDH) assumption holds. Let \( G \) be a group of prime order \( p \).

**Setup:**
- The challenger picks random generators \( g, h \in G \).
- The challenger also picks random \( \alpha_0, \alpha_1, \ldots, \alpha_n \in \mathbb{Z}_p \) such that \( \sum_{i=0}^n \alpha_i = 0 \).
- The challenger gives the adversary \( g, h, g^{\alpha_0}, g^{\alpha_1}, \ldots, g^{\alpha_n} \).

**Queries:**
- The adversary can make "compromise" queries adaptively and ask for the value of \( \alpha_i \).