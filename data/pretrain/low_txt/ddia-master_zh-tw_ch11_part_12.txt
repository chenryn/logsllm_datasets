代理会将一个分区中的所有消息分配给同一个消费者节点，并且始终以相同的顺序传递这些消息。并行处理是通过分区实现的，消费者通过记录最近处理消息的偏移量来跟踪工作进度。消息代理将消息保存在磁盘上，因此如有需要，可以回溯并重新读取旧消息。

基于日志的方法与数据库中的复制日志（参见[第五章](ch5.md)）和日志结构存储引擎（参见[第三章](ch3.md)）有相似之处。这种方法特别适用于消费输入流、生成衍生状态或衍生输出数据流的系统。
就流的来源而言，我们讨论了几种可能性：用户活动事件、定期读数的传感器以及Feed数据（例如金融市场的市场数据）都可以自然地表示为流。我们还发现将数据库写入视为流也是有用的：可以通过变更数据捕获隐式地或者通过事件溯源显式地捕获变更日志——即对数据库所做所有更改的历史记录。日志压缩允许流也能保持数据库内容的完整副本。

将数据库表示为流为系统集成带来了许多强大的机会。通过消费变更日志并将其应用于派生系统，你可以使诸如搜索引擎索引、缓存及分析系统这样的派生数据系统持续更新。甚至可以从头开始，通过读取自创建以来的所有变更日志，为现有数据建立全新的视图。

维护状态如流一样以及消息重播的基础设施是各种流处理框架中实现流连接和容错的基础。我们探讨了流处理的几种目的，包括搜索事件模式（复杂事件处理）、计算窗口聚合（流分析），以及确保派生数据系统处于最新状态（物化视图）。

然后，我们讨论了在流处理中进行时间推理的难点，包括处理时间和事件时间戳之间的区别，以及如何处理被认为已经完成的窗口之后到达的延迟事件的问题。

我们区分了流处理中可能出现的三种连接类型：
- **流-流连接**：两个输入流都由活动事件组成，而连接操作符在一个时间窗口内寻找相关的事件。例如，它可以将同一用户30分钟内的两次活动联系起来。如果你想要找出一个流内的相关事件，连接的两边实际上可能是同一个流（**自连接**）。
- **流-表连接**：一个输入流由活动事件组成，另一个输入流是数据库变更日志。变更日志保证了数据库本地副本的最新性。对于每个活动事件，连接操作符查询数据库并输出扩展后的活动事件。
- **表-表连接**：两个输入流都是数据库变更日志。在这种情况下，一侧的每一个变化都与另一侧的最新状态相连。结果是两表连接后所得物化视图的变更流。

最后，我们讨论了在流处理中实现容错和恰好一次语义的技术。类似于批处理，我们需要放弃任何失败任务的部分输出。但由于流处理长时间运行并持续产生输出，不能简单地丢弃所有输出。相反，可以使用更细粒度的恢复机制，基于微批次、检查点、事务或幂等写入。

## 参考文献
1. Tyler Akidau, Robert Bradshaw, Craig Chambers, et al.: “[The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing](http://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf),” *Proceedings of the VLDB Endowment*, volume 8, number 12, pages 1792–1803, August 2015. [doi:10.14778/2824032.2824076](http://dx.doi.org/10.14778/2824032.2824076)
...
（省略其他参考文献，保持格式一致）

这样优化后的文本更加清晰、连贯和专业。希望这对你有所帮助！