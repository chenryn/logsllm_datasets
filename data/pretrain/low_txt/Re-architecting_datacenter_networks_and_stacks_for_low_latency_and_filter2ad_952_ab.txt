### Delay Variations and NDP Implementation

A production version of NDP (Network Data Processing) cannot overburden server CPUs, as these resources are critical for application workloads. The optimal solution is to implement NDP on a smartNIC, either using a System-on-Chip (SoC) based solution, such as the Broadcom Stingray PS225, or an FPGA-based one, like the Intel N3000.

### Deployment Prospects

To evaluate the impact of NDP two years after its publication, we will estimate its potential for deployment in this section and discuss its research impact in the next.

As systems researchers, our goal is to create practical and widely adopted systems. Our experience with Multipath TCP (MPTCP) demonstrates that the effort to standardize MPTCP at the IETF and maintain a stable Linux kernel implementation was worthwhile, as MPTCP is now widely used.

However, our attempts to deploy solutions in data centers have not been as successful. When NDP was presented at Sigcomm 2017, implemented and demonstrated by Mark Handley using the Unity game engine, it generated significant interest. We approached the major cloud providers to gauge their interest in deploying NDP in their data centers. Unfortunately, the responses were lukewarm, citing the lack of switch support as a major barrier. Instead, they suggested finding a solution that does not require switch support. Homa, published at Sigcomm 2018, achieves this but with some performance trade-offs in certain scenarios. It remains to be seen if Homa will be adopted in practice.

This was not the first time we faced challenges in deploying our solutions in data centers. The feedback convinced us that overcoming these hurdles would be an uphill battle. Like many of our peers, we shifted our focus to areas where our research could have a more immediate impact.

Surprisingly, three switch vendors approached us, expressing interest in implementing NDP in their switches. We began collaborating with them, and one vendor has already developed a working prototype that we are currently testing. Additionally, a smartNIC implementation of the NDP endhost stack is in progress, giving us hope that a near-production deployment of NDP may soon be possible.

Whether NDP will be adopted by the major cloud providers or smaller, latency-sensitive enterprise data centers remains uncertain. However, there is a good chance that NDP will find practical use in the near future.

### Research Impact

The problem of efficiently utilizing data center networks has been a focal point of research for a decade, with thousands of papers published on the topic. The seminal Hedera paper, which opened this field, has over 1,300 citations, as does DCTCP.

NDP appears to be part of a group of papers that effectively conclude this area of research, along with Homa (Sigcomm 2018) and ExpressPass (Sigcomm 2017). The number of papers addressing this problem has steadily decreased (13 papers in 2017, 5 in 2018, and none at NSDI 2019).

NDP currently has 67 citations on Google Scholar, ranking fourth out of 36 papers in Sigcomm 2017, behind QUIC and Pensieve (each with 200 citations) and SilkRoad (Facebook’s load balancer, with 70 citations). The NDP paper has been downloaded 7,300 times from the ACM digital library, second only to Google’s QUIC paper (9,000 downloads) in the Sigcomm 2017 batch (the average number of downloads is 2,400).

The high number of downloads indicates significant interest in NDP, though this interest has not translated into citations at the same rate as for QUIC. This may be due to the decreasing amount of research in this area.

The true measure of impact, however, is whether NDP will be deployed and used in practice. While it is too early to determine this, there are promising signs.

### Acknowledgments

We conclude this brief retrospective of the NDP work by noting that, in our experience, networking research can have a practical impact, but it requires long-term projects and large teams to achieve success.

While this editorial was written by a subset of the NDP authors, we acknowledge that NDP was a collaborative project. The design and simulations were conducted by Mark Handley (UCL) and Costin Raiciu (UPB), the main software implementation was done by Alexandru Agache (UPB), the P4 implementation by Andrei Voinescu (UPB), and the NetFPGA-based switch implementation by Gianni Antichi, Marcin Wojchik, and Andrew Moore (University of Cambridge).

Our reference to Multipath TCP is also a collective one. Mark Handley (UCL) and Costin Raiciu (UPB) contributed to the protocol design, initial implementation, and the first phase of standardization. Olivier Bonaventure's team at Université Catholique de Louvain was instrumental in developing the mature Linux kernel implementation, which is now widely used. Many others have contributed to MPTCP, including Alan Ford (Pexip) leading the lengthy standardization work, Phil Eardley and Yoshifumi Yoshida leading the MPTCP working group, and Marcelo Bagnulo (UC3M) working on the security aspects, to name just a few.

### References

[References remain unchanged]

ACM SIGCOMM Computer Communication Review
Volume 49 Issue 5, October 2019
113-114