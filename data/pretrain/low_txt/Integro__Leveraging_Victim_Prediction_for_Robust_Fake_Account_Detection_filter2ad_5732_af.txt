### Assigned High Weights and Lower AUC in User Ranking

When high weights are assigned to certain features, it can lead to a lower Area Under the Curve (AUC) in user ranking. This is because the model may overemphasize these features, potentially leading to suboptimal performance.

### Maintenance and Regular Retraining

While an attacker does not control real accounts or their activities, they can still trick users into befriending fake accounts. To achieve a high-quality ranking, the victim classifier should be regularly retrained to capture new and changing user behavior, particularly in terms of susceptibility to social infiltration. This is a common practice in supervised machine learning when applied to computer security problems [8].

### Detection of Automated Fake Accounts

The ranking scheme is designed to detect automated fake accounts that befriend many victims for subsequent attacks. Íntegro has been deployed at Tuenti alongside a feature-based detection system and a user-based abuse reporting system.

### Conclusion

Online Social Networks (OSNs) today face the challenge of detecting fake accounts in a highly adversarial environment. As such accounts become more sophisticated in cloaking their operations with patterns resembling real user behavior, the problem becomes increasingly challenging. In this paper, we presented Íntegro, a scalable defense system that helps OSN operators detect fake accounts using a meaningful user ranking scheme.

Our evaluation results show that SybilRank, the state-of-the-art in fake account detection, is ineffective when fakes infiltrate the target OSN by befriending a large number of real users. Íntegro, however, has proven more resilient to this effect by leveraging the knowledge of benign victim accounts that befriend fakes. We have implemented Íntegro on top of standard data processing platforms, Mahout and Giraph, which are scalable and easy to deploy in modern data centers. Tuenti, the largest OSN in Spain with more than 15 million active users, has deployed our system in production, achieving at least ten times more precision in detecting fakes.

### Acknowledgment

We would like to thank our shepherd, Gianluca Stringhini, and our colleagues for their help and feedback on an earlier version of this paper. The first author is grateful to the University of British Columbia for a generous doctoral fellowship.

### References

[1] J. R. Douceur, “The sybil attack,” in 1st International Workshop on Peer-to-Peer Systems. Springer-Verlag, 2002, pp. 251–260.
[2] Facebook, “Quarterly earning reports,” Jan 2014. [Online]. Available: http://goo.gl/YujtO
[3] CBC, “Facebook shares drop on news of fake accounts,” Aug 2012. [Online]. Available: http://goo.gl/6s5FKL
[4] K. Thomas and et al., “Suspended accounts in retrospect: an analysis of Twitter spam,” in Proc. IMC’11. ACM, 2011, pp. 243–258.
[5] G. Yan and et al., “Malware propagation in online social networks: nature, dynamics, and defense implications,” in Proc. ASIACCS’11. ACM, 2011, pp. 196–206.
[6] J. Ratkiewicz and et al., “Truthy: mapping the spread of astroturf in microblog streams,” in Proc. WWW’11. ACM, 2011, pp. 249–252.
[7] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu, “The socialbot network: when bots socialize for fame and money,” in Proc. ACSAC’11. ACM, 2011, pp. 93–102.
[8] T. Stein, E. Chen, and K. Mangla, “Facebook immune system,” in Proceedings of the 4th Workshop on Social Network Systems. ACM, 2011, pp. 8–14.
[9] L. Alvisi, A. Clement, A. Epasto, U. Sapienza, S. Lattanzi, and A. Panconesi, “SoK: The evolution of sybil defense via social networks,” In Proceedings of the IEEE Symposium on Security and Privacy, 2013.
[10] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda, “All your contacts are belong to us: automated identity theft attacks on social networks,” in Proc. WWW’09. ACM, 2009, pp. 551–560.
[11] C. Wagner, S. Mitter, C. Körner, and M. Strohmaier, “When social bots attack: Modeling susceptibility of users in online social networks,” in WWW Workshop on Making Sense of Microposts, vol. 12, 2012.
[12] M. N. Ko, G. P. Cheek, M. Shehab, and R. Sandhu, “Social-networks connect services,” Computer, vol. 43, no. 8, pp. 37–43, 2010.
[13] Q. Cao, M. Sirivianos, X. Yang, and T. Pregueiro, “Aiding the detection of fake accounts in large scale social online services,” in Proc. NSDI’12. USENIX Association, 2012, pp. 15–15.
[14] S. Yardi, N. Feamster, and A. Bruckman, “Photo-based authentication using social networks,” in Proceedings of the first workshop on Online social networks. ACM, 2008, pp. 55–60.
[15] S. D. Kamvar and et al., “The EigenTrust algorithm for reputation management in P2P networks,” in Proceedings of 12th international conference on World Wide Web. ACM, 2003, pp. 640–651.
[16] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman, “Sybilguard: defending against sybil attacks via social networks,” ACM SIGCOMM Computer Communication Review, vol. 36, no. 4, pp. 267–278, 2006.
[17] H. Yu and et al., “Sybillimit: A near-optimal social network defense against sybil attacks,” in Proc. S&P’08. IEEE, 2008, pp. 3–17.
[18] G. Danezis and P. Mittal, “Sybilinfer: Detecting sybil nodes using social networks.” in Proceedings of the 9th Annual Network & Distributed System Security Symposium. ACM, 2009.
[19] B. Viswanath, A. Post, K. P. Gummadi, and A. Mislove, “An analysis of social network-based sybil defenses,” in Proceedings of ACM SIGCOMM Computer Communication Review. ACM, 2010, pp. 363–374.
[20] N. Tran, J. Li, L. Subramanian, and S. S. Chow, “Optimal sybil-resilient node admission control,” in INFOCOM, 2011 Proceedings IEEE. IEEE, 2011, pp. 3218–3226.
[21] J. Dean and S. Ghemawat, “Mapreduce: simplified data processing on large clusters,” Comm. of ACM, vol. 51, no. 1, pp. 107–113, 2008.
[22] G. Malewicz and et al., “Pregel: a system for large-scale graph processing,” in Proceedings of the 2010 ACM SIGMOD International Conference on Management of data. ACM, 2010, pp. 135–146.
[23] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu, “Design and analysis of a social botnet,” Computer Networks, vol. 57, no. 2, pp. 556–578, 2013.
[24] T. Hwang, I. Pearce, and M. Nanis, “Socialbots: Voices from the fronts,” interactions, vol. 19, no. 2, pp. 38–45, 2012.
[25] M. Egele and et al., “COMPA: Detecting compromised accounts on social networks.” in Proc. NDSS’13, 2013.
[26] M. Motoyama and et al., “Dirty jobs: The role of freelance labor in web service abuse,” in Proceedings of the 20th USENIX Security Symposium. USENIX Association, 2011, pp. 14–14.
[27] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao, and Y. Dai, “Uncovering social network sybils in the wild,” in Proceedings of 2011 ACM Internet Measurement Csonference. ACM, 2011, pp. 259–268.
[28] G. Stringhini, C. Kruegel, and G. Vigna, “Detecting spammers on social networks,” in Proceedings of the 26th Annual Computer Security Applications Conference. ACM, 2010, pp. 1–9.
[29] G. Wang and et al., “You are how you click: Clickstream analysis for sybil detection,” in Proceedings of the 22nd USENIX Security Symposium. USENIX Association, 2013, pp. 1–8.
[30] G. Karypis and V. Kumar, “Multilevel k-way partitioning scheme for irregular graphs,” Journal of Parallel and Distributed computing, vol. 48, no. 1, pp. 96–129, 1998.
[31] J. Tygar, “Adversarial machine learning.” IEEE Internet Computing, vol. 15, no. 5, 2011.
[32] D. Lowd and C. Meek, “Adversarial learning,” in Proceedings of the 11th ACM SIGKDD. ACM, 2005, pp. 641–647.
[33] Y. Boshmaf and et al., “Key challenges in defending against malicious socialbots,” in Proc. LEET’12, vol. 12, 2012.
[34] H. Yu, “Sybil defenses via social networks: a tutorial and survey,” ACM SIGACT News, vol. 42, no. 3, pp. 80–101, 2011.
[35] B. Viswanath and et al., “Exploring the design space of social network-based sybil defenses,” in In Proceedings of the 4th International Conference on Communication Systems and Networks. IEEE, 2012, pp. 1–8.
[36] Y. Boshmaf and et al., “Graph-based sybil detection in social and information systems,” in Proc. ASONAM’13. IEEE, 2013.
[37] J. Leskovec, K. Lang, A. Dasgupta, and M. Mahoney, “Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters,” Internet Mathematics, vol. 6, no. 1, pp. 29–123, 2009.
[38] S. Fortunato, “Community detection in graphs,” Physics Reports, vol. 486, no. 3, pp. 75–174, 2010.
[39] A. Mislove and et al., “You are who you know: inferring user profiles in online social networks,” in Proc. WSDM’10. ACM, 2010, pp. 251–260.
[40] G. Wang, M. Mohanlal, C. Wilson, X. Wang, M. Metzger, H. Zheng, and B. Y. Zhao, “Social turing tests: Crowdsourcing sybil detection,” in Proc. NDSS’13. ACM, 2013.
[41] S. Ghosh and et al., “Understanding and combating link farming in the twitter social network,” in Proceedings of 21st international conference on World Wide Web. ACM, 2012, pp. 61–70.
[42] A. Elyashar, M. Fire, D. Kagan, and Y. Elovici, “Homing socialbots: intrusion on a specific organization’s employee using socialbots,” in Proc. ASONAM’13. ACM, 2013, pp. 1358–1365.
[43] G. Stringhini and et al., “Follow the green: growth and dynamics in twitter follower markets,” in Proc. IMC’13. ACM, 2013, pp. 163–176.
[44] C. Yang and et al., “Analyzing spammers’ social networks for fun and profit: a case study of cyber criminal ecosystem on twitter,” in Proc. of WWW’12. ACM, 2012, pp. 71–80.
[45] D. A. Spielman and S.-H. Teng, “Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems,” in Proc. TC’04. ACM, 2004, pp. 81–90.
[46] L. Breiman, “Random forests,” Machine learning, vol. 45, no. 1, pp. 5–32, 2001.
[47] T. Hastie, R. Tibshirani, and J. Friedman, The elements of statistical learning: Data mining, inference, and prediction, second edition. Springer, 2009.
[48] Z. Gyöngyi, H. Garcia-Molina, and J. Pedersen, “Combating web spam with trustrank,” in Proceedings of VLDB, 2004, pp. 576–587.
[49] G. H. Golub and H. A. Van der Vorst, “Eigenvalue computation in the 20th century,” Journal of Computational and Applied Mathematics, vol. 123, no. 1, pp. 35–65, 2000.
[50] E. Behrends, Introduction to Markov chains with special emphasis on rapid mixing. Vieweg, 2000, vol. 228.
[51] M. Dellamico and Y. Roudier, “A measurement of mixing time in social networks,” in Proceedings of the 5th International Workshop on Security and Trust Management, Saint Malo, France, 2009.
[52] A. Mohaisen, A. Yun, and Y. Kim, “Measuring the mixing time of social graphs,” in Proceedings of the 10th annual conference on Internet measurement. ACM, 2010, pp. 383–389.
[53] J. Leskovec, K. J. Lang, A. Dasgupta, and M. W. Mahoney, “Statistical properties of community structure in large social and information networks,” in Proc. WWW’08. ACM, 2008, pp. 695–704.
[54] V. Blondel, J. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast unfolding of communities in large networks,” Journal of Statistical Mechanics: Theory and Experiment, vol. 2008, no. 10, 2008.
[55] M. E. Newman, “Modularity and community structure in networks,” Proceedings of the National Academy of Sciences, vol. 103, no. 23, pp. 8577–8582, 2006.
[56] Y. Boshmaf, D. Logothetis, G. Siganos, J. Lería, J. Lorenzo, M. Ripeanu, and K. Beznosov, “Íntegro: Leveraging victim prediction for robust fake account detection in OSNs,” LERSSE technical report, 2014.
[57] A. Sinclair, “Improved bounds for mixing rates of Markov chains and multicommodity flow,” in Proceedings of Latin American Symposium on Theoretical Informatics. Springer-Verlag, 1992, pp. 474–487.
[58] D. N. Tran, B. Min, J. Li, and L. Subramanian, “Sybil-resilient online content voting.” in NSDI, vol. 9, 2009, pp. 15–28.
[59] J. Leskovec and C. Faloutsos, “Sampling from large graphs,” in Proceedings of the ACM SIGKDD Conference. ACM, 2006, pp. 631–636.
[60] D. J. Watts and S. H. Strogatz, “Collective dynamics of small-world networks,” nature, vol. 393, no. 6684, pp. 440–442, 1998.
[61] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. T. Riedl, “Evaluating collaborative filtering recommender systems,” ACM Transactions on Information Systems (TOIS), vol. 22, no. 1, pp. 5–53, 2004.
[62] A. Mohaisen, H. Tran, N. Hopper, and Y. Kim, “On the mixing time of directed social graphs and security implications,” in Proceedings of the ASIACCS Conference. ACM, 2012, pp. 36–37.
[63] Y. Xie and et al., “Innocent by association: early recognition of legitimate users,” in Proc. CCS’12. ACM, 2012, pp. 353–364.