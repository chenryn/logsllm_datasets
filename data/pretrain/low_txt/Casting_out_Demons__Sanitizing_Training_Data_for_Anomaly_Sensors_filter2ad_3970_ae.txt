### 5.2 Polymorphic Attacks

Polymorphic attacks are of increasing concern. To test the effectiveness of our system against such attacks, we used a popular polymorphic engine, CLET [6], to generate samples of polymorphic shellcode.

In these experiments, we assumed that an attacker would attempt a training attack using a polymorphic vector, implying that the exploit would include polymorphic shellcode. We generated 2100 samples of shellcode using CLET. For the dataset `www1`, we derived 100 micro-models with a three-hour granularity. Each micro-model was poisoned with 20 samples of shellcode, and the remaining 100 shellcode samples were used to poison the dataset from which the sanitized model was built.

We then rebuilt the sanitized model using our system. In the voting strategy, all micro-models identified the 100 shellcode samples as anomalous, with an average of 82% of the grams from the 100 samples being flagged as abnormal by the micro-models. After computing the sanitized model, we tested it against a 100-hour testing dataset. As expected, the performance results were identical to those obtained when the sanitized model was constructed without any shellcode samples. These experiments indicate that most common polymorphic attacks can be effectively handled by our local sanitization architecture.

### 6. Related Work

Our approach for sanitizing training datasets shares elements with ensemble methods, which are reviewed in [7]. It is important to note that, while most of these methods traditionally fall into the category of supervised learning algorithms, our work uses unlabeled training data due to the nature of real network traffic.

In particular, we construct a set of classifiers and classify new data points using a (weighted) vote. We generate AD models from slices of the training data, thus manipulating the training examples presented to the learning method. Another similar machine learning approach is Bagging predictors [2], which uses a learning algorithm with a training set consisting of a sample of \( m \) training examples drawn randomly from the initial dataset. The cross-validated committees method [19] proposes constructing a training model by leaving out disjoint subsets of the training data. ADABoost [11] generates multiple hypotheses and maintains a set of weights over the training examples. Each iteration invokes the learning algorithm to minimize the weighted error and returns a hypothesis, which is used in a final weighted vote.

One of the most similar works to ours is MetaCost [8], an algorithm that implements cost-sensitive classification. Instead of modifying an error minimization classification procedure, it views the classifier as a black box, the same as we do, and wraps the procedure around it to reduce loss. MetaCost estimates class probabilities and relabels the training examples such that the expected cost of predicting new labels is minimized. Finally, it builds a new model based on the relabeled data. Our algorithm also labels the training examples and ignores the abnormal ones in the training process.

We have previously explored the feasibility of cleaning traffic [5]. That work contained a limited analysis and did not address the problem of long-lasting attacks in the training data. In contrast, this paper performs an extended analysis on larger and more realistic datasets to confirm the hypothesis that cleaning is possible. We also present alternatives that can be used when the local architecture fails due to long-lasting training attacks.

JAM [24] focuses on developing and evaluating a range of learning strategies for fraud detection. This work presents methods for "meta-learning" by computing sets of "base classifiers" over various partitions or samplings of the training data. The combining algorithms proposed are called "class-combiner" or "stacking" and are built based on work presented in [3] and [31]. The exchange of abnormal models was used in [24] for commercial fraud detection. Their results show that fraud detection systems can be substantially improved by combining multiple models of fraudulent transactions shared among banks. We apply a similar idea in the case of network traffic content-based anomaly detection to cross-sanitize the normal model.

The perceived utility of anomaly detection is based on the assumption that malicious inputs rarely occur during the normal operation of the system. Because a system can evolve over time, it is also likely that new non-malicious inputs will be seen [10]. Perhaps more troubling, Fogla and Lee [9] have shown how to evade anomaly classifiers by constructing polymorphic exploits that blend with normal traffic (a sophisticated form of mimicry attack [27]). Song et al. [23] have further improved on this technique and shown that content-based approaches may not work against all polymorphic threats, as many approaches often fixate on specific byte patterns [17].

### 7. Conclusions

Due to recent advances in polymorphic attacks, we believe that the research community should make a concerted effort to revive the use of content-based anomaly detection as a first-class defensive technique. To that end, we introduce a novel sanitization technique that significantly improves the detection performance of out-of-the-box anomaly detection (AD) sensors. We are the first to introduce the notion of micro-models: models of "normal" trained on small slices of the training dataset. Using simple weighted voting schemes, we significantly improve the quality of unlabeled training data by making it as "attack-free" and "regular" as possible. Our approach is straightforward and general, and we believe it can be applied to a wide range of unmodified AD sensors (because it interacts with the training data rather than the AD algorithm) without incurring significant additional computational cost other than in the initial training phase.

Experimental results indicate that our system can serve both as a stand-alone sensor and as an efficient and accurate online packet classifier using a shadow sensor. Furthermore, the alerts generated by the "sanitized" AD model represent a small fraction of the total traffic. The model detects approximately five times more attack packets than the unsanitized AD model. Additionally, the AD system can detect more threats both online and after an actual attack, as the AD training data are attack-free. In cases where local sanitization is evaded, we extend our methodology to support sharing models of abnormal traffic among collaborating sites. A site can cross-sanitize its local training data based on remote models. Our results show that if the collaborating sites were targeted by the same attack and they were able to capture it in their abnormal models, the detection rate can be improved up to 100%.

Obtaining anomaly sensors from the research community is a difficult process; most sensors are heavily protected IP or are under active development. We are, however, currently investigating two additional sensors: one based on libanomaly and one based on the pH system [22]. We plan to investigate how to clean training data for these algorithms to help show that our approach extends to other AD sensors.

### Acknowledgements

We would like to thank Yingbo Song for helpful feedback and Wei-Jen Li and Vanessa Frias-Martinez for interesting discussions. This material is based on research sponsored by the Air Force Research Laboratory under agreement number FA8750-06-2-0221, the Army Research Office under grant No. DA W911NF-04-1-0442, and by the National Science Foundation under NSF grants CNS-06-27473 and CNS-04-26623. We authorize the U.S. Government to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation thereon. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.

### References

[1] K. G. Anagnostakis, S. Sidiroglou, P. Akritidis, K. Xinidis, E. Markatos, and A. D. Keromytis. Detecting Targeted Attacks Using Shadow Honeypots. In Proceedings of the 14th USENIX Security Symposium, August 2005.
[2] L. Breiman. Bagging Predictors. Machine Learning, 24(2):123–140, 1996.
[3] P. K. Chan and S. J. Stolfo. Experiments in Multistrategy Learning by Meta-Learning. In Proceedings of the second international conference on information and knowledge management, pages 314–323, Washington, DC, 1993.
[4] J. R. Crandall, Z. Su, S. F. Wu, and F. T. Chong. On Deriving Unknown Vulnerabilities from Zero-Day Polymorphic and Metamorphic Worm Exploits. In ACM Conference on Computer and Communications Security, Alexandria, VA, 2005.
[5] G. F. Cretu, A. Stavrou, S. J. Stolfo, and A. D. Keromytis. Improving the Forensic Utility of Data Sanitization: Anomaly Detection Systems. In Workshop on Hot Topics in System Dependability (HotDep), 2007.
[6] T. Detristan, T. Ulenspiegel, Y. Malcom, and M. S. von Underduk. Polymorphic Shellcode Engine Using Spectrum Analysis. Phrack, 11(61-9), 2003.
[7] T. G. Dietterich. Ensemble Methods in Machine Learning. Lecture Notes in Computer Science, 1857:1–15, 2000.
[8] P. Domingos. Metacost: A general method for making classifiers cost-sensitive. In Knowledge Discovery and Data Mining, pages 155–164, 1999.
[9] P. Fogla and W. Lee. Evading Network Anomaly Detection Systems: Formal Reasoning and Practical Techniques. In Proceedings of the 13th ACM Conference on Computer and Communications Security (CCS), pages 59–68, 2006.
[10] S. Forrest, A. Somayaji, and D. Ackley. Building Diverse Computer Systems. In Proceedings of the 6th Workshop on Hot Topics in Operating Systems, pages 67–72, 1997.
[11] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. In European Conference on Computational Learning Theory, pages 23–37, 1995.
[29] K. Wang, J. J. Parekh, and S. J. Stolfo. Anagram: A Content Anomaly Detector Resistant to Mimicry Attack. In Proceedings of the Symposium on Recent Advances in Intrusion Detection (RAID), September 2006.
[30] K. Wang and S. J. Stolfo. Anomalous Payload-based Network Intrusion Detection. In Proceedings of the Symposium on Recent Advances in Intrusion Detection (RAID), September 2004.
[31] D. Wolpert. Stacked Generalization. In Neural Networks, volume 5, pages 241–259, 1992.
[12] S. S. Janak Parekh, Ke Wang. Privacy-preserving payload-based correlation for accurate malicious traffic detection. In SIGCOMM Workshop on Large Scale Attack Defense, 2006.
[13] C. Kruegel, T. Toth, and E. Kirda. Service Specific Anomaly Detection for Network Intrusion Detection. In Symposium on Applied Computing (SAC), Madrid, Spain, 2002.
[14] R. P. Lippmann and J. Haines. Analysis and Results of the 1999 DARPA Off-Line Intrusion Detection Evaluation. In Proceedings of the Recent Advances in Intrusion Detection (RAID 2000), pages 162–182, 2000.
[15] J. McHugh. Testing Intrusion Detection Systems: A Critique of the 1998 and 1999 DARPA Intrusion Detection System Evaluations as Performed by Lincoln Laboratory. ACM TISSEC, 3(4):262–291, 2000.
[16] D. Moore and C. Shannon. The Spread of the Code Red Worm (CRv2). http://www.caida.org/analysis/security/code-red/coderedv2 analysis.xml.
[17] J. Newsome, B. Karp, and D. Song. Polygraph: Automatically Generating Signatures for Polymorphic Worms. In IEEE Security and Privacy, Oakland, CA, 2005.
[18] J. J. Parekh. Privacy-Preserving Distributed Event Corroboration. PhD thesis, Columbia University, 2007.
[19] B. Parmanto, M. P. W., and H. R. Doyle. Improving Committee Diagnosis with Resampling Techniques. Advances in Neural Information Processing Systems, 8:882–888, 1996.
[20] H. Patil and C. N. Fischer. Efficient Turn-time Monitoring Using Shadow Processing. In Proceedings of the 2nd International Workshop on Automated and Algorithmic Debugging, 1995.
[21] S. Sidiroglou, M. E. Locasto, S. W. Boyd, and A. D. Keromytis. Building a Reactive Immune System for Software Services. In Proceedings of the USENIX Technical Conference, June 2005.
[22] A. Somayaji and S. Forrest. Automated Response Using System-Call Delays. In Proceedings of the 9th USENIX Security Symposium, August 2000.
[23] Y. Song, M. E. Locasto, A. Stavrou, A. D. Keromytis, and S. J. Stolfo. On the Infeasibility of Modeling Polymorphic Shellcode. In ACM Computer and Communications Security Conference (CCS), 2007.
[24] S. Stolfo, W. Fan, W. Lee, A. Prodromidis, and P. Chan. Cost-based Modeling for Fraud and Intrusion Detection: Results from the JAM Project. In Proceedings of the DARPA Information Survivability Conference and Exposition (DISCEX), 2000.
[25] K. M. Tan and R. A. Maxion. Why 6? Defining the Operational Limits of stide, an Anomaly-Based Intrusion Detector. In Proceedings of the IEEE Symposium on Security and Privacy, pages 188–201, May 2002.
[26] C. Taylor and C. Gates. Challenging the Anomaly Detection Paradigm: A Provocative Discussion. In Proceedings of the 15th New Security Paradigms Workshop (NSPW), pages 21–29, September 2006.
[27] D. Wagner and P. Soto. Mimicry Attacks on Host-Based Intrusion Detection Systems. In ACM CCS, 2002.
[28] K. Wang, G. Cretu, and S. J. Stolfo. Anomalous Payload-based Worm Detection and Signature Generation. In Proceedings of the Symposium on Recent Advances in Intrusion Detection (RAID), September 2005.