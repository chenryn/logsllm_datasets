### Results and Performance

The results presented are a valid, yet rough estimation of how the de-anonymization attack would perform against random users on the Internet. Specifically, out of 9,969 participants, we found at least one group hit for 3,717 users. Among these, we were able to correctly de-anonymize 1,207 individuals. This corresponds to 12.1% of the overall participants and 37.3% of the users who had at least one Xing-specific link in their browsing history, suggesting they are likely members of Xing. Although this percentage is lower than what we achieved in our controlled experiment, it still demonstrates the real-world feasibility of the attack.

### Run-Time and Throughput Rate

The runtime of the attack significantly influences its success rate in practice. Since we perform an active attack that probes the victim’s browsing history, the victim needs to interact with the attacker for a certain amount of time. Techniques to prolong the interaction range from benign methods, such as showing a video or music clip, to more aggressive tactics like using JavaScript to "hijack" the user's browser and prevent them from leaving the site. From the attacker's perspective, it is desirable to minimize the attack's duration.

We measured the typical time required to perform a history stealing attack in practice. The results, shown in Figure 1, indicate the number of tested pages over time for different browsers. For example, Safari 4 on Mac, Chrome, Firefox 3.5 on various platforms, and Internet Explorer 8.

### Server-side Mitigation

As a server-side mitigation, web applications could use dynamic hyperlinks that are difficult for attackers to predict. For instance, existing systems could be hardened by automatically adding HTTP GET parameters containing random tokens to all hyperlinks. Depending on the web server, it might be possible to retrofit existing web applications using URL rewriting to add such tokens. Even a simple, alphanumerical string of length 2 would increase the attacker’s search space by a factor of 3,844 (62^2), effectively preventing the attack.

Additionally, web applications should prefer HTTP POST over HTTP GET for sending parameters, as only GET parameters are stored in the browsing history. A server-side mitigation solution that randomizes web-application links is presented in existing work [22].

However, server-side mitigation can affect the usability of web applications. For example, it may become more difficult to bookmark parts of the application, and links to certain groups may be harder to remember. Furthermore, server-side mitigation is only effective if all (or at least many) social networks implement it. If a user is a member of several social networks and only some implement the mitigation strategy, the user remains vulnerable based on the information collected from the non-mitigated network. Thus, a social network might not have an incentive to deploy a countermeasure unless all other social networks also participate.

### Client-side Mitigation

On the client-side, mitigating history stealing without sacrificing functionality is challenging. The goal is to prevent browsers from leaking sensitive and private information via style information. One solution is to restrict client-side scripts from accessing the CSS properties of hyperlinks. However, this could break existing websites that legitimately do so.

Jackson et al. [8] offer a clever solution by extending the same-origin concept of web browsers to visited links. Unfortunately, none of the published countermeasures to history sniffing have seen widespread adoption, whether on the server or client-side.

Current web browsers provide limited options for protection against attacks based on history stealing. Turning off JavaScript or using browser add-ons like NoScript [23] may only provide limited help. Another mitigation option could be to throttle the rate at which style properties can be accessed and limit the total number of checks performed on a single page, but we did not explore this option in depth.

### Degradation of Group Data in Xing

Figure 8 shows the degradation of group data in Xing, indicating the effort an attacker must invest for a de-anonymization attack. An attacker can develop iterative approaches to keep the collected information up-to-date, such as using social networking features that list only new members in groups and newly created groups.

To measure the fluctuation in groups, we conducted experiments for Xing. Instead of repeatedly crawling the entire network, we downloaded the group directory and member size for each group every four hours over 18 days. Figure 8 shows the CDF for changes in group size over four different periods. Our measurements confirm that the quality of the collected group and member data degrades over time, but the data remains relatively stable, significantly reducing the necessary crawling effort for an attacker.

While we acknowledge that the number of users joining or leaving a group might lead to the same overall group size, we believe our experiment provides a reasonable indication of the amount of change affecting Xing’s group configurations.

### Possible Mitigation Techniques

The approach presented in this work allows a malicious user to launch de-anonymization attacks against a large number of victims with relatively little effort. While history stealing alone is often insufficient to identify individual users, combining it with the misuse of group membership information stored in social networks creates a critical weakness. In this section, we list mitigation techniques aimed at thwarting our attack.

Users can permanently or temporarily disable their browsing history or use “private browsing modes” supported by several current browsers (e.g., Firefox, Safari). However, these methods require user effort and reduce the usability of web browsers and web applications.

### Responsible Disclosure

We notified the affected social networks about our attack and discussed possible mitigation strategies with them. Since client-side mitigation was out of scope for them, we focused on server-side mitigation as discussed above.

Within four days of our notification, Xing added a random number to all relevant links on the platform (i.e., links containing group information) [24]. The random number considers the current date and a user-specific number, changing every 24 hours. As a result, the de-anonymization attack presented in this paper is no longer effective against Xing. At the time of writing, Facebook and LinkedIn are still investigating the best way to mitigate this attack.

### Related Work

De-anonymization of privacy-sensitive data is not a new concept. Initial research focused on anonymizing and de-anonymizing network-level data. For example, Pang et al. [25] presented techniques for anonymizing network packet traces for sharing between researchers. In response, Coulls et al. [26] introduced approaches to de-anonymize network traces and recover sensitive data on network topologies.

Due to the popularity of social networks and the large amounts of sensitive data they store, de-anonymization research has extended to this area. Several publications have shown that seemingly non-sensitive data from publicly available sources can be used to recover private information about individuals. For example, Grifﬁth and Jakobsson [10] use public records to infer individuals’ mothers’ maiden names, and Heatherly et al. [27], as well as Zheleva and Getoor [6], show how public data provided by social networks can be used to infer private information.

Several publications have analyzed and measured privacy-related features of social networks. Mislove et al. [28] present a measurement study on social networks, while Bonneau and Preibusch [29] evaluate the privacy settings and policies of a large number of social networks. Recent papers focus on scenarios for malicious activity directed against social networks. For example, Jagatic et al. [15] evaluate the success rates of phishing attacks, and Brown et al. [30] discuss context-aware spam. Bilge et al. [31] show the feasibility of automated identity theft attacks in social networks.

Our attack is passive, requiring a user to visit a website that then performs the attack. Ur and Ganapathy [32] explored active attacks, such as injecting images into popular MySpace profiles, and showed that such attacks can significantly increase the success rate. Future studies might investigate such attacks, but ethical and legal considerations need to be taken into account.

Attacks on browsing privacy leverage a technique known since 2000, which uses CSS to steal browsing history. This technique has been discussed in several browser bug reports [12]–[14] and has been shown to be practical for targeted phishing attacks by Jakobsson and Stamm [9]. Despite its malicious potential, browser history stealing has not led to any changes in browser software.

Other techniques aim to expose private browsing information. Felten and Schneider [33] show an attack on web browsing history by analyzing caching operations, while Bortz and Boneh [34] use timing attacks to recover private information from web applications.

Narayanan and Shmatikov [11] have shown that statistical methods can be applied to de-anonymize micro-data by cross-correlating multiple datasets. They extend their approach to social networks [5], proving that it is possible to de-anonymize members by mapping known, auxiliary information on the (social) network topology. Diaz et al. [35] present a de-anonymization approach using information gained from observing communication patterns between social network members. Backstrom et al. [3] showed how to de-anonymize a single social network.

In contrast to existing work, our attack uses only information from a single social networking site and combines it with the browsing history of a user to identify individuals. This enables us to learn the actual identity of the visitor of a website. Furthermore, our attack is highly practical and works effectively in the real world, potentially affecting the privacy of millions of registered social network users.

### Conclusion

In this paper, we introduce a novel, practical de-anonymization attack that leverages group information in social networking sites. Using empirical, real-world experiments, we demonstrate that the group membership of a user in a social network may reveal enough information to identify her when visiting web pages from third parties.

The implications of our attack are significant. It requires low effort and has the potential to affect millions of registered social networking users who have group memberships. Our theoretical analysis and empirical measurements demonstrate the feasibility of the attack on Xing, Facebook, and LinkedIn. Our investigations suggest that many more social networks supporting group memberships can potentially be misused for similar attacks.

### Acknowledgments

This work has been supported by the Austrian Research Promotion Agency under grant 820854, the Austrian Science Foundation under grant P18764-N04, and by the European Commission through project FP7-ICT-216026-WOMBAT. We also thank our shepherd Vitaly Shmatikov and the anonymous reviewers for their valuable insights and comments.

### References

[1] Alexa, “Top 500 Global Sites,” http://www.alexa.com/topsites, 2009.
[2] “Facebook,” http://www.facebook.com, 2009.
[3] L. Backstrom, C. Dwork, and J. Kleinberg, “Wherefore Art Thou R3579X?: Anonymized Social Networks, Hidden Patterns, and Structural Steganography,” in 16th Conference on World Wide Web (WWW’07), 2007.
[4] M. Chew, D. Balfanz, and B. Laurie, “(Under)mining Privacy in Social Networks,” in Proceedings of Web 2.0 Security and Privacy Workshop (W2SP), 2008.
[5] A. Narayanan and V. Shmatikov, “De-anonymizing social networks,” in IEEE Symposium on Security and Privacy, 2009.
[6] E. Zheleva and L. Getoor, “To Join or Not To Join: The Illusion of Privacy in Social Networks with Mixed Public and Private User Profiles,” in 18th International Conference on World Wide Web (WWW), 2009.
[7] EFF, “Panopticlick: How Unique – and Trackable – is Your Browser?” http://panopticlick.eff.org/, 2010.
[8] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell, “Protecting Browser State From Web Privacy Attacks,” in 15th International Conference on World Wide Web (WWW), 2006.
[9] M. Jakobsson and S. Stamm, “Invasive Browser Sniffing and Countermeasures,” in 15th International World Wide Web Conference, 2006.
[10] V. Griffith and M. Jakobsson, “Messin’ with Texas, Deriving Mother’s Maiden Names using Public Records,” in Third Conference on Applied Cryptography and Network Security (ACNS), June 2005.
[11] A. Narayanan and V. Shmatikov, “Robust De-anonymization of Large Sparse Datasets,” in IEEE Symposium on Security and Privacy, 2008.
[12] J. Ruderman, “CSS on a:visited can load an image and/or reveal if visitor been to a site,” https://bugzilla.mozilla.org/show_bug.cgi?id=57351, 2000.
[13] D. Baron, “:visited support allows queries into global history,” https://bugzilla.mozilla.org/show_bug.cgi?id=147777, 2002.
[14] Z. Braniecki, “CSS allows to check history via :visited,” https://bugzilla.mozilla.org/show_bug.cgi?id=224954, 2003.
[15] T. N. Jagatic, N. A. Johnson, M. Jakobsson, and F. Menczer, “Social phishing,” Commun. ACM, vol. 50, no. 10, pp. 94–100, 2007.
[16] R. Dingledine, N. Mathewson, and P. F. Syverson, “Tor: The Second-Generation Onion Router,” in USENIX Security Symposium, 2004.
[17] U.S. Census Bureau, “Frequently Occurring Names and Surnames,” http://www.census.gov/genealogy/www, 2009.
[18] M. Jakobsson, P. Finn, and N. Johnson, “Why and How to Perform Fraud Experiments,” Security & Privacy, IEEE, vol. 6, no. 2, pp. 66–68, March-April 2008.
[19] M. Jakobsson and J. Ratkiewicz, “Designing ethical phishing experiments: a study of (ROT13) rOnl query features,” in 15th International Conference on World Wide Web (WWW), 2006.
[20] “LinkedIn,” http://www.linkedin.com, 2009.
[21] Computational Crawling LP, “80legs,” http://www.80legs.com, 2009.
[22] M. Jakobsson and S. Stamm, “Web Camouflage: Protecting Your Clients from Browser-Sniffing Attacks,” IEEE Security and Privacy, vol. 5, no. 6, 2007.
[23] G. Maone, “NoScript,” https://addons.mozilla.org/de/firefox/addon/722, 2009.
[24] J. Mainusch, “De-De-Anonymizing in Four Days,” http://blog.xing.com/2010/02/de-de-anonymizing-in-four-days/, 2010.
[25] R. Pang, M. Allman, V. Paxson, and J. Lee, “The Devil and Packet Trace Anonymization,” SIGCOMM Comput. Commun. Rev., vol. 36, no. 1, 2006.
[26] S. Coulls, C. Wright, F. Monrose, M. Collins, and M. Reiter, “Playing Devil’s Advocate: Inferring Sensitive Information from Anonymized Traces,” in Symposium on Network and Distributed Systems Security (NDSS), 2007.
[27] R. Heatherly, M. Kantarcioglu, and B. Thuraisingham, “Preventing Private Information Inference Attacks on Social Networks,” University of Texas at Dallas, Tech. Rep. UTDCS-03-09, 2009.
[28] A. Mislove, M. Marcon, K. P. Gummadi, P. Druschel, and B. Bhattacharjee, “Measurement and Analysis of Online Social Networks,” in 7th ACM SIGCOMM Internet Measurement Conference (IMC), 2007.
[29] J. Bonneau and S. Preibusch, “The Privacy Jungle: On the Market for Privacy in Social Networks,” in Eighth Workshop on the Economics of Information Security (WEIS), 2009.
[30] G. Brown, T. Howe, M. Ihbe, A. Prakash, and K. Borders, “Social networks and context-aware spam,” in ACM 2008 Conference on Computer Supported Cooperative Work (CSCW), 2008.
[31] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda, “All Your Contacts Are Belong to Us: Automated Identity Theft Attacks on Social Networks,” in 18th International Conference on World Wide Web (WWW), 2009.
[32] B. E. Ur and V. Ganapathy, “Evaluating Attack Amplification in Online Social Networks,” in Web 2.0 Security and Privacy, 2009.
[33] E. W. Felten and M. A. Schneider, “Timing Attacks on Web Privacy,” in 7th ACM Conference on Computer and Communications Security (CCS), 2000.
[34] A. Bortz and D. Boneh, “Exposing Private Information by Timing Web Applications,” in 16th International Conference on World Wide Web (WWW), 2007.
[35] C. Diaz, C. Troncoso, and A. Serjantov, “On the Impact of Social Network Profiling on Anonymity,” in 8th International Symposium on Privacy Enhancing Technologies (PETS), 2008.