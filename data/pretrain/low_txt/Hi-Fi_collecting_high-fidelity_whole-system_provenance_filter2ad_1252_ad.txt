### 6.1.2 Backdoor Techniques

A common backdoor technique involves opening a port that listens for incoming connections and provides the attacker with a remote shell. This approach is frequently used by various types of malware, including the Plupii and Millen worms. Our experiment demonstrates that the provenance record captures both the shell's network communication and the attacker's activities:

- **[744] exec B:/bin/bash -i**
- **[744] socksend B:173**
- **[744] sockrecv unknown**
- **[744] socksend B:173**
- **[751] exec B:/bin/cat /etc/shadow**
- **[751] read B:/etc/shadow**
- **[751] socksend B:173**
- **[744] socksend B:173**
- **[744] sockrecv unknown**
- **[744] socksend B:173**
- **[744] link (new) to B:/testfile**
- **[744] write B:/testfile**

In this scenario, the attacker uses the remote shell to view the `/etc/shadow` file and create a new file in the root directory. Since the attacker's system is unlikely to be running a trusted instance of Hi-Fi, we see "unknown" socket entries, indicating data received from an unprovenanced host. Remote shells can also be implemented as "reverse shells," which connect from the infected host back to the attacker. Our tests on a reverse shell, such as the one in the Jac.8759 virus, show results identical to a normal shell.

### 6.1.3 Exfiltration

Another common payload activity is data exfiltration, where the malware reads sensitive information from a file, such as password hashes or credit card numbers, and sends this information to the attacker. Our simulation for this behavior reads the `/etc/shadow` file and forwards it using two methods:

1. **HTTP Upload**: The file is uploaded to a web server.
2. **Direct Socket Communication**: The file is sent directly to a remote port.

Both methods result in the following log entries:

- **[85f] read B:/etc/shadow**
- **[85f] socksend B:1ae**

Emailing the information to the attacker, as done by the Adore worm, would create a similar record.

### 6.1.4 Spread

Our experiment models three different mechanisms used by malware to spread to newly infected hosts:

1. **Initial Exploit Payload Delivery**:
   - When the entire payload can be sent using the initial exploit, no separate dropper is needed. The provenance log is as follows:
     - **[807] read A:/home/evil/payload**
     - **[807] socksend A:153**
     - **[684] sockrecv A:153**
     - **[684] write B:/tmp/payload**
   - The payload is then executed, and subsequent log entries reflect the malicious behavior.

2. **Payload Fetch from Remote Web Server**:
   - Used by the Plupii and Sorso worms, the payload is fetched from a remote web server. Assuming the web server is unprovenanced, the log contains "unknown" entries:
     - **[7ff] read A:/home/evil/dropper**
     - **[7ff] socksend A:15b**
     - **[685] sockrecv A:15b**
     - **[685] write B:/tmp/dropper**
     - **[6ef] socksend B:149**
     - **[6ef] sockrecv unknown**
     - **[6ef] write B:/tmp/payload**
   - If the web server were a provenanced host, the log would contain host and socket IDs in the `sockrecv` entry corresponding to a `socksend` on the server.

3. **Relay Dropper**:
   - To illustrate the spread of malware across several hosts, we tested a "relay" dropper that uses a randomly-chosen port to transfer the payload from each infected host to the next. The combined log of our three hosts shows this process:
     - **[83f] read A:/home/evil/dropper**
     - **[83f] socksend A:159**
     - **[691] sockrecv A:159**
     - **[691] write B:/tmp/dropper**
     - **[6f5] exec B:/tmp/dropper**
     - **[844] read A:/home/evil/payload**
     - **[844] socksend A:15b**
     - **[6fc] sockrecv A:15b**
     - **[6fc] write B:/tmp/payload**
     - **[74e] read B:/tmp/dropper**
     - **[74e] socksend B:169**
     - **[682] sockrecv B:169**
     - **[682] write C:/tmp/dropper**
     - **[6e6] exec C:/tmp/dropper**
     - **[750] read B:/tmp/payload**
     - **[750] socksend B:16b**
     - **[6ed] sockrecv B:16b**
     - **[6ed] write C:/tmp/payload**
   - Here, the attacker transfers both the dropper and the payload to the first victim using two different sockets. This victim then sends the dropper and the payload to the next host in the same manner.

### 6.1.5 Full Simulation

For a comprehensive test, we use our tool to simulate the Linux Adore worm according to Symantec's description. Our provenance record captures the entire life cycle of the worm, including:

- **Downloading and Extracting the Payload Tarball**
- **Execution of start.sh, which Activates the Payload**
- **Replacement of the ps Binary with a Trojaned Version, and Copying the Original ps to /usr/bin/adore**
- **Installation of a Cron Job which Kills the Worm**
- **Replacement of klogd with a Backdoor Shell**
- **Emailing of the /etc/shadow File, Process List, and Network Information to the Attacker**
- **Infection of the Next Victim**

We also successfully capture a sample backdoor session, in which the attacker views a user’s command-line history and downloads an updated payload.

### 6.2 Performance

In addition to demonstrating that Hi-Fi records malicious activity, we also aim to show that it does so without significantly degrading system performance. We benchmark a system running a stock Arch Linux kernel (version 3.2.13), then benchmark the same system with Hi-Fi compiled in. Our test system has two 2.30-GHz quad-core AMD Opteron processors, 16GB of RAM, and two 73GB hard disks in a RAID 0 array.

#### System-Call Level Overhead

We first evaluate performance overhead at the system-call level using microbenchmarks. LMbench, a commonly used tool for Linux microbenchmarks, provided inconsistent results. Instead, we created a small program to exercise major file and process operations. We then used the `strace` utility to measure the time spent in various system calls over a large number of executions of this program. The results are summarized in Table 2. For the system calls measured, the overhead is at most 6.2%, with most calls within 1% of the baseline.

| System Call | Baseline (μs) | With Hi-Fi (μs) | Overhead (%) |
|-------------|---------------|-----------------|--------------|
| open        | 13.8          | 13.8            | 0.0%         |
| close       | 10.6          | 10.7            | 1.0%         |
| read        | 13.7          | 14.6            | 6.2%         |
| write       | 21.4          | 21.3            | -0.2%        |
| creat       | 24.1          | 24.4            | 1.1%         |
| rename      | 19.8          | 20.0            | 0.9%         |
| unlink      | 36.4          | 36.7            | 0.7%         |
| clone       | 74.6          | 74.0            | -0.7%        |
| execve      | 150.3         | 155.1           | 3.2%         |

#### Macrobenchmarks

To demonstrate the overall impact on system performance, we run two macrobenchmarks customarily used in provenance system evaluation:

1. **Linux Kernel Build**:
   - Evaluates a typical combination of process execution and file manipulation.
   - Unmodified kernel: 107 seconds
   - With Hi-Fi: 110 seconds
   - Overhead: 2.8%

2. **PostMark**:
   - Specifically stresses filesystem and disk transactions.
   - Achieves 2,083 transactions per second in both cases.
   - No significant performance degradation observed.

### 7. Conclusion

We have presented Hi-Fi, a system that applies the reference monitor concept to collect a high-fidelity provenance record suitable for security applications. This record can be used to observe the behavior of malware, not only within a single host but also across multiple provenanced hosts. Furthermore, we demonstrate that our implementation imposes less than 3% overhead on representative workloads and a similarly small overhead in system-call microbenchmarks.

We believe that Hi-Fi will provide a solid platform for future provenance research. For example, while we do not explore options for working with provenance data after it is collected, the modular design of Hi-Fi will make it simple to evaluate many different approaches to processing, storage, and querying. We have shown that complete system-level and socket provenance can provide deep insight into the design, performance, and security of systems and networks, and we believe that many other significant discoveries are yet to be made in this area.

### Acknowledgements

This work is supported by the National Science Foundation under awards HECURA-0937944 and CNS-1118046.

### References

1. J. P. Anderson. Computer security technology planning study. Technical Report ESD-TR-73-51, AFSC, Hanscom AFB, Bedford, MA, Oct. 1972. AD-758 206, ESD/AFSC.
2. U. Braun, S. Garfinkel, D. Holland, K. Muniswamy-Reddy, and M. Seltzer. Issues in automatic provenance collection. In Proceedings of the 2006 International Provenance and Annotation Workshop, pages 171–183, 2006.
3. A. Edwards, T. Jaeger, and X. Zhang. Runtime verification of authorization hook placement for the Linux Security Modules framework. In V. Atluri, editor, ACM Conference on Computer and Communications Security, pages 225–234. ACM, 2002.
4. Filesystem in userspace. http://fuse.sourceforge.net.
5. V. Ganapathy, T. Jaeger, and S. Jha. Automatic placement of authorization hooks in the Linux Security Modules framework. In V. Atluri, C. Meadows, and A. Juels, editors, ACM Conference on Computer and Communications Security, pages 330–339. ACM, 2005.
6. D. Garg, L. Jia, and A. Datta. Policy auditing over incomplete logs: theory, implementation and applications. In Proceedings of the 18th ACM conference on Computer and Communications Security, CCS ’11, pages 151–162, New York, NY, USA, 2011. ACM.
7. A. Goel, K. Farhadi, K. Po, and W.-c. Feng. Reconstructing system state for intrusion analysis. SIGOPS Oper. Syst. Rev., 42(3):21–28, Apr. 2008.
8. A. Goel, W.-C. Feng, D. Maier, and J. Walpole. Forensix: a robust, high-performance reconstruction system. In Distributed Computing Systems Workshops, 2005. 25th IEEE International Conference on, pages 155–162, June 2005.
9. R. Ikeda and J. Widom. Panda: A system for provenance and data. IEEE Data Engineering Bulletin, September 2010.
10. S. N. Jones, C. R. Strong, D. D. Long, and E. L. Miller. Tracking emigrant data via transient provenance. In Third Workshop on the Theory and Practice of Provenance. USENIX, June 2011.
11. J. Katcher. Postmark: a new file system benchmark. Network Appliance Tech Report TR3022, Oct. 1997.
12. L. Lamport. Time, clocks, and the ordering of events in a distributed system. Communications of the ACM, 21(7):558–565, July 1978.
13. Metasploit Project. http://www.metasploit.com.
14. L. Moreau, B. Clifford, J. Freire, J. Futrelle, Y. Gil, P. T. Groth, N. Kwasnikowska, S. Miles, P. Missier, J. Myers, B. Plale, Y. Simmhan, E. G. Stephan, and J. V. den Bussche. The Open Provenance Model core specification (v1.1). Future Generation Comp. Syst., 27(6):743–756, 2011.
15. K. Muniswamy-Reddy, J. Barillari, U. Braun, D. Holland, D. Maclean, M. Seltzer, and S. Holland. Layering in provenance-aware storage systems. In Proceedings of the 2009 USENIX Annual Technical Conference, San Diego, CA, 2009.
16. K. Muniswamy-Reddy and D. Holland. Causality-based versioning. ACM Transactions on Storage (TOS), 5(4):13, 2009.
17. Phoronix Test Suite. http://phoronix-test-suite.com.
18. C. F. Reilly and J. F. Naughton. Transparently gathering provenance with provenance aware Condor. In First workshop on theory and practice of provenance, TAPP’09, pages 13:1–13:10, Berkeley, CA, USA, 2009. USENIX Association.
19. C. Sar and P. Cao. Lineage file system. Online at http://crypto.stanford.edu/cao/lineage.html, 2005.
20. R. Sion. Strong worm. In Proceedings of the 2008 The 28th International Conference on Distributed Computing Systems, 2008.
21. R. P. Spillane, R. Sears, C. Yalamanchili, S. Gaikwad, M. Chinni, and E. Zadok. Story Book: An efficient extensible provenance framework. In J. Cheney, editor, Workshop on the Theory and Practice of Provenance. USENIX, 2009.
22. S. Sundararaman, G. Sivathanu, and E. Zadok. Selective versioning in a secure disk system. In Proceedings of the 17th conference on Security symposium, 2008.
23. Symantec Security Response. http://www.symantec.com/security_response.
24. L. Tan, X. Zhang, X. Ma, W. Xiong, and Y. Zhou. AutoISES: Automatically inferring security specification and detecting violations. In P. C. van Oorschot, editor, USENIX Security Symposium, pages 379–394. USENIX Association, July 2008.
25. J. Widom. Trio: A system for integrated management of data, accuracy, and lineage. In CIDR, pages 262–276, 2005.
26. C. Wright, C. Cowan, S. Smalley, J. Morris, and G. Kroah-Hartman. Linux Security Modules: General security support for the Linux kernel. In USENIX, editor, Proceedings of the 11th USENIX Security Symposium 2002, August 5–9, 2002, San Francisco, CA, pages 17–31. USENIX, 2002.
27. T. Zanussi, K. Yaghmour, R. Wisniewski, R. Moore, and M. Dagenais. relayfs: An efficient unified approach for transmitting data from kernel to user space. In Proceedings of the 2003 Linux Symposium, Ottawa, ON, Canada, pages 494–506, July 2003.
28. X. Zhang, A. Edwards, and T. Jaeger. Using CQUAL for static analysis of authorization hook placement. In D. Boneh, editor, USENIX Security Symposium, pages 33–48. USENIX, 2002.