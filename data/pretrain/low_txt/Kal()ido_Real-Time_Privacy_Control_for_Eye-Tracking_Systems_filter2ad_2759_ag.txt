Certainly! Below is a more polished and coherent version of the provided text, with improved formatting and clarity:

---

### References

1. **What Do Different Evaluation Metrics Tell Us About Saliency Models?**  
   *IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)*, 41(3):740–757, 2018.

2. **Eye-Tracking Product Recommenders’ Usage**  
   *S. Castagnos, N. Jones, and P. Pu*  
   In *ACM RecSys*, 2010.

3. **Experimental Methods: Between-Subject and Within-Subject Design**  
   *G. Charness, U. Gneezy, and M. A. Kuhn*  
   *Journal of Economic Behavior & Organization*, 81(1):1–8, 2012.

4. **A Predictive Differentially-Private Mechanism for Mobility Traces**  
   *K. Chatzikokolakis, C. Palamidessi, and M. Stronati*  
   In *PETS*, 2014.

5. **Scanpath Modeling and Classification with Hidden Markov Models**  
   *A. Coutrot, J. H. Hsiao, and A. B. Chan*  
   *Behavior Research Methods*, 50(1):362–379, 2018.

6. **It Depends on How You Look at It: Scanpath Comparison in Multiple Dimensions with MultiMatch, a Vector-Based Approach**  
   *R. Dewhurst, M. Nyström, H. Jarodzka, T. Foulsham, R. Johansson, and K. Holmqvist*  
   *Behavior Research Methods*, 44(4):1079–1100, 2012.

7. **The Algorithmic Foundations of Differential Privacy**  
   *C. Dwork and A. Roth*  
   *Foundations and Trends in Theoretical Computer Science*, 9(3-4):211–407, 2014.

8. **When Your Fitness Tracker Betrays You: Quantifying the Predictability of Biometric Features Across Contexts**  
   *S. Eberz, G. Lovisotto, A. Patane, M. Kwiatkowska, V. Lenders, and I. Martinovic*  
   In *IEEE S&P*, 2018.

9. **28 Blinks Later: Tackling Practical Challenges of Eye Movement Biometrics**  
   *S. Eberz, G. Lovisotto, K. B. Rasmussen, V. Lenders, and I. Martinovic*  
   In *ACM CCS*, 2019.

10. **Scanpath Trend Analysis on Web Pages: Clustering Eye Tracking Scanpaths**  
    *S. Eraslan, Y. Yesilada, and S. Harper*  
    *ACM Transactions on the Web (TWEB)*, 10(4):1–35, 2016.

11. **GazeRecorder – Webcam Eye Tracking**  
    *GazeRecorder*  
    2020. [https://gazerecorder.com](https://gazerecorder.com)

12. **Evaluation of the Tobii EyeX Eye Tracking Controller and MATLAB Toolkit for Research**  
    *A. Gibaldi, M. Vanegas, P. J. Bex, and G. Maiello*  
    *Behavior Research Methods*, 49(3):923–946, 2017.

13. **The Perceptual and Attentive Impact of Delay and Jitter in Multimedia Delivery**  
    *S. R. Gulliver and G. Ghinea*  
    *IEEE Transactions on Broadcasting*, 53(2):449–458, 2007.

14. **A New Method for Categorizing Scanpaths from Eye Tracking Data**  
    *M. J. Haass, L. E. Matzen, K. M. Butler, and M. Armenta*  
    In *ACM ETRA*, 2016.

15. **Adversarial Attacks on Classifiers for Eye-Based User Modelling**  
    *I. Hagestedt, M. Backes, and A. Bulling*  
    In *ACM ETRA*, 2020.

16. **The Area-of-Interest Problem in Eyetracking Research: A Noise-Robust Solution for Face and Sparse Stimuli**  
    *R. S. Hessels, C. Kemner, C. van den Boomen, and I. T. C. Hooge*  
    *Behavior Research Methods*, 48(4):1694–1712, 2016.

17. **Noise-Robust Fixation Detection in Eye Movement Data: Identification by Two-Means Clustering (I2MC)**  
    *R. S. Hessels, D. C. Niehorster, C. Kemner, and I. T. C. Hooge*  
    *Behavior Research Methods*, 49(5):1802–1823, 2017.

18. **Usability Evaluation of Eye Tracking on an Unmodified Common Tablet**  
    *C. Holland, A. Garza, E. Kurtova, J. Cruz, and O. Komogortsev*  
    In *ACM CHI EA*, 2013.

19. **Biometric Identification via Eye Movement Scanpaths in Reading**  
    *C. Holland and O. V. Komogortsev*  
    In *IEEE IJCB*, 2011.

20. **Adjustment of Fixation Duration in Visual Search**  
    *I. T. C. Hooge and C. J. Erkelens*  
    *Vision Research*, 38(9):1295–IN4, 1998.

21. **Differential Privacy: An Economic Method for Choosing Epsilon**  
    *J. Hsu, M. Gaboardi, A. Haeberlen, S. Khanna, A. Narayan, B. C. Pierce, and A. Roth*  
    In *IEEE CSF*, 2014.

22. **Technology Probes: Inspiring Design for and with Families**  
    *H. Hutchinson and et al.*  
    In *ACM CHI*, 2003.

23. **EyeDroid: An Open Source Mobile Gaze Tracker on Android for Eyewear Computers**  
    *S. Jalaliniya, D. Mardanbegi, I. Sintos, and D. G. Garcia*  
    In *ACM UbiComp*, 2015.

24. **A Scanner Darkly: Protecting User Privacy from Perceptual Applications**  
    *S. Jana, A. Narayanan, and V. Shmatikov*  
    In *IEEE S&P*, 2013.

25. **SALICON: Saliency in Context**  
    *M. Jiang, S. Huang, J. Duan, and Q. Zhao*  
    In *IEEE CVPR*, 2015.

26. **A Benchmark of Four Methods for Generating 360° Saliency Maps from Eye Tracking Data**  
    *B. John, P. Raiturkar, O. Le Meur, and E. Jain*  
    *International Journal of Semantic Computing (IJSC)*, 13(03):329–341, 2019.

27. **Distinctive Features of Microsaccades in Alzheimer’s Disease and in Mild Cognitive Impairment**  
    *Z. Kapoula, Q. Yang, J. Otero-Millan, S. Xiao, S. L. Macknik, A. Lang, M. Verny, and S. Martinez-Conde*  
    *Age*, 36(2):535–543, 2014.

28. **Differentially Private Event Sequences over Infinite Streams**  
    *G. Kellaris, S. Papadopoulos, X. Xiao, and D. Papadias*  
    In *VLDB*, 2014.

29. **Preserving Differential Privacy and Utility of Non-Stationary Data Streams**  
    *M. Khavkin and M. Last*  
    In *IEEE ICDMW*, 2018.

30. **A Nonparametric Method for Detecting Fixations and Saccades Using Cluster Analysis: Removing the Need for Arbitrary Thresholds**  
    *S. D. König and E. A. Buffalo*  
    *Journal of Neuroscience Methods*, 227:121–131, 2014.

31. **Eye Tracking for Everyone**  
    *K. Krafka, A. Khosla, P. Kellnhofer, H. Kannan, S. Bhandarkar, W. Matusik, and A. Torralba*  
    In *IEEE CVPR*, 2016.

32. **Gaze-Enhanced Scrolling Techniques**  
    *M. Kumar, T. Winograd, and A. Paepcke*  
    In *ACM CHI EA*, 2007.

33. **Gaze Datum Format**  
    *Pupil Labs*  
    2020. [https://docs.pupil-labs.com/developer/core/overview/#gaze-datum-format](https://docs.pupil-labs.com/developer/core/overview/#gaze-datum-format)

34. **Human-Computer Interaction – INTERACT 2019**  
    *D. Lamas, F. Loizides, L. Nacke, H. Petrie, M. Winckler, and P. Zaphiris*  
    Springer, 2019.

35. **In What Ways Do Eye Movements Contribute to Everyday Activities?**  
    *M. F. Land and M. Hayhoe*  
    *Vision Research*, 41(25-26):3559–3565, 2001.

36. **How Much is Enough? Choosing ε for Differential Privacy**  
    *J. Lee and C. Clifton*  
    In *ISC*, 2011.

37. **Gazture: Design and Implementation of a Gaze-Based Gesture Control System on Tablets**  
    *Y. Li, Z. Cao, and J. Wang*  
    *ACM IMWUT*, 1(3):1–17, 2017.

38. **Microsoft COCO: Common Objects in Context**  
    *T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick*  
    In *ECCV*, 2014.

39. **Differential Privacy for Eye-Tracking Data**  
    *A. Liu, L. Xia, A. Duchowski, R. Bailey, K. Holmqvist, and E. Jain*  
    In *ACM ETRA*, 2019.

40. **Edge Assisted Real-Time Object Detection for Mobile Augmented Reality**  
    *L. Liu, H. Li, and M. Gruteser*  
    In *ACM MobiCom*, 2019.

41. **Differentially Private k-Means Clustering with Guaranteed Convergence**  
    *Z. Lu and H. Shen*  
    arXiv:2002.01043, 2020.

42. **Eye Tracking and Eye-Based Human–Computer Interaction**  
    *P. Majaranta and A. Bulling*  
    In *Advances in Physiological Computing*, pages 39–65. Springer, 2014.

43. **Mise-Unseen: Using Eye Tracking to Hide Virtual Reality Scene Changes in Plain Sight**  
    *S. Marwecki, A. D. Wilson, E. Ofek, M. Gonzalez Franco, and C. Holz*  
    In *ACM UIST*, 2019.

44. **Visual Attention**  
    *S. A. McMains and S. Kastner*  
    *Encyclopedia of Neuroscience*, 1:4296–4302, 2009.

45. **Understanding Scene SDK**  
    *Microsoft*  
    2020. [https://docs.microsoft.com/en-us/windows/mixed-reality/develop/platform-capabilities-and-apis/scene-understanding-sdk/](https://docs.microsoft.com/en-us/windows/mixed-reality/develop/platform-capabilities-and-apis/scene-understanding-sdk/)

46. **Eye See Through You! Eye Tracking Unmasks Concealed Face Recognition Despite Countermeasures**  
    *A. E. Millen and P. J. B. Hancock*  
    *Cognitive Research: Principles and Implications*, 4(1):23, 2019.

47. **EyePhone: Activating Mobile Phones with Your Eyes**  
    *E. Miluzzo, T. Wang, and A. T. Campbell*  
    In *ACM MobiHeld*, 2010.

48. **Eye Gaze Tracking Techniques for Interactive Applications**  
    *C. H. Morimoto and M. R. M. Mimica*  
    *Computer Vision and Image Understanding*, 98(1):4–24, 2005.

49. **The Effect of Optical Devices and Repeated Trials on the Velocity of Saccadic Eye Movements**  
    *C. Müller, W. Stoll, and F. Schmäl*  
    *Acta Oto-Laryngologica*, 123(4):471–476, 2003.

50. **Smooth Sensitivity and Sampling in Private Data Analysis**  
    *K. Nissim, S. Raskhodnikova, and A. Smith*  
    In *ACM SOTC*, 2007.

51. **Is Geo-Indistinguishability What You Are Looking For?**  
    *S. Oya, C. Troncoso, and F. Pérez-González*  
    In *ACM WPES*, 2017.

52. **WebGazer: Scalable Webcam Eye Tracking Using User Interactions**  
    *A. Papoutsaki, P. Sangkloy, J. Laskey, N. Daskalova, J. Huang, and J. Hays*  
    In *IJCAI*, 2016.

53. **Towards Foveated Rendering for Gaze-Tracked Virtual Reality**  
    *A. Patney, M. Salvi, J. Kim, A. Kaplanyan, C. Wyman, N. Benty, D. Luebke, and A. Lefohn*  
    *ACM Transactions on Graphics (TOG)*, 35(6):179, 2016.

54. **Visual Attention to Repeated Print Advertising: A Test of Scanpath Theory**  
    *R. Pieters, E. Rosbergen, and M. Wedel*  
    *Journal of Marketing Research*, 36(4):424–438, 1999.

55. **MarkIt: Privacy Markers for Protecting Visual Secrets**  
    *N. Raval, A. Srivastava, K. Lebeck, L. Cox, and A. Machanavajjhala*  
    In *ACM UbiComp*, 2014.

56. **Eye Movements When Looking at Unusual/Weird Scenes: Are There Cultural Differences?**  
    *K. Rayner, M. S. Castelhano, and J. Yang*  
    *Journal of Experimental Psychology: Learning, Memory, and Cognition*, 35(1):254, 2009.

57. **YOLOv3: An Incremental Improvement**  
    *J. Redmon and A. Farhadi*  
    arXiv:1804.02767, 2018.

58. **Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks**  
    *S. Ren, K. He, R. Girshick, and J. Sun*  
    In *NIPS*, 2015.

59. **World-Driven Access Control for Continuous Sensing**  
    *F. Roesner, D. Molnar, A. Moshchuk, T. Kohno, and H. J. Wang*  
    In *ACM CCS*, 2014.

60. **Identifying Fixations and Saccades in Eye-Tracking Protocols**  
    *D. D. Salvucci and J. H. Goldberg*  
    In *ACM ETRA*, 2000.

61. **Attentional Disengagement Predicts Stress Recovery in Depression: An Eye-Tracking Study**  
    *A. Sanchez, C. Vazquez, C. Marker, J. LeMoult, and J. Joormann*  
    *Journal of Abnormal Psychology*, 122(2):303, 2013.

62. **Peer Acceptance and Rejection through the Eyes of Youth: Pupillary, Eyetracking, and Ecological Data from the Chatroom Interact Task**  
    *J. S. Silk, L. R. Stroud, G. J. Siegle, R. E. Dahl, K. H. Lee, and E. E. Nelson*  
    *Social Cognitive and Affective Neuroscience*, 7(1):93–105, 2012.

63. **Visual Disengagement: Genetic Architecture and Relation to Autistic Traits in the General Population**  
    *M. Siqueiros Sanchez, E. Pettersson, D. P. Kennedy, S. Bölte, P. Lichtenstein, B. M. D’Onofrio, and T. Falck-Ytter*  
    *Journal of Autism and Developmental Disorders*, 2019.

64. **Face Processing and Familiarity: Evidence from Eye-Movement Data**  
    *P. C. Stacey, S. Walker, and J. D. M. Underwood*  
    *British Journal of Psychology*, 96(4):407–422, 2005.

65. **Privacy-Aware Eye Tracking Using Differential Privacy**  
    *J. Steil, I. Hagestedt, M. X. Huang, and A. Bulling*  
    In *ACM ETRA*, 2019.

66. **Eye-Tracking for Avatar Eye-Gaze and Interactional Analysis in Immersive Collaborative Virtual Environments**  
    *W. Steptoe, R. Wolff, A. Murgia, E. Guimaraes, J. Rae, P. Sharkey, D. Roberts, and A. Steed*  
    In *ACM CSCW*, 2008.

67. **Basics of Qualitative Research Techniques**  
    *A. Strauss and J. Corbin*  
    Sage, 1998.

68. **The Diagnostic Value of Saccades in Movement Disorder Patients: A Practical Guide and Review**  
    *P. Termsarasab, T. Thammongkolchai, J. C. Rucker, and S. J. Frucht*  
    *Journal of Clinical Movement Disorders*, 2(1):14, 2015.

69. **Scripting API of Tobii Unity SDK**  
    *Tobii*  
    2020. [https://developer.tobii.com/pc-gaming/unity-sdk/scripting-api/](https://developer.tobii.com/pc-gaming/unity-sdk/scripting-api/)

70. **A Mixed Reality Head-Mounted Text Translation System Using Eye Gaze Input**  
    *T. Toyama, D. Sonntag, A. Dengel, T. Matsuda, M. Iwamura, and K. Kise*  
    In *ACM IUI*, 2014.

71. **Selective Search for Object Recognition**  
    *J. R. R. Uijlings, K. E. A. Van De Sande, T. Gevers, and A. W. M. Smeulders*  
    *International Journal of Computer Vision (IJCV)*, 104(2):154–171, 2013.

72. **Scripting Reference of XR.Eyes**  
    *Unity*  
    2020. [https://docs.unity3d.com/ScriptReference/XR.Eyes.html](https://docs.unity3d.com/ScriptReference/XR.Eyes.html)

73. **Survival Shooter Tutorial**  
    *Unity*  
    2020. [https://learn.unity.com/project/survival-shooter-tutorial/?tab=overview](https://learn.unity.com/project/survival-shooter-tutorial/?tab=overview)

74. **Unity Scripting API: Keyframe**  
    *Unity*  
    2020. [https://docs.unity3d.com/ScriptReference/Keyframe.html](https://docs.unity3d.com/ScriptReference/Keyframe.html)

75. **Hands-Free Vision-Based Interface for Computer Accessibility**  
    *J. Varona, C. Manresa-Yee, and F. J. Perales*  
    *Journal of Network and Computer Applications*, 31(4):357–374, 2008.

76. **Pelee: A Real-Time Object Detection System on Mobile Devices**  
    *R. J. Wang, X. Li, and C. X. Ling*  
    In *NIPS*, 2018.

77. **An Extensive Dataset of Eye Movements During Viewing of Complex Images**  
    *N. Wilming, S. Onat, J. P. Ossandón, A. Açık, T. C. Kietzmann, K. Kaspar, R. R. Gameiro, A. Vormberg, and P. König*  
    *Scientific Data*, 4(1):1–11, 2017.

78. **Personalized Online Document, Image and Video Recommendation via Commodity Eye-Tracking**  
    *S. Xu, H. Jiang, and F. C. M. Lau*  
    In *ACM RecSys*, 2008.

79. **Detecting Eye Contact Using Wearable Eye-Tracking Glasses**  
    *Z. Ye, Y. Li, A. Fathi, Y. Han, A. Rozga, G. D. Abowd, and J. M. Rehg*  
    In *ACM Ubicomp*, 2012.

80. **Fast Pixel-Based Video Scene Change Detection**  
    *X. Yi and N. Ling*  
    In *IEEE ISCAS*, 2005.

### Appendix

#### A.1 Proof of Theorem 2

**Theorem 2 (Composition over multiple windows theorem).**  
Let \( M : S^g \rightarrow C^g \) be a mechanism that takes as input a gaze stream prefix \( S^g_k = (h_{g_1, t_1}, \ldots, h_{g_k, t_k}) \), and outputs a transcript \( O = (o_1, \ldots, o_k) \in C \). Additionally, let \( M \) be decomposed into \( k \) mechanisms \( M_1, \ldots, M_k \) such that \( M_i(g_i) = o_i \), and each \( M_i \) generates independent randomness while achieving \((\epsilon_i, r)\)-geo-indistinguishability. Then for two stream prefixes \( S^g \) and \( S^{g'} \) such that:
- For all \( i \in [k] \), \( t_i = t'_i \)
- For each \( g_i, g'_i \) such that \( i \in [k] \) and \( g_i \neq g'_i \) it holds that \( d(g_i, g'_i) \leq r \), i.e., \((g_i, g'_i)\) are \( r \)-Euclidean neighboring,

the following inequality holds:
\[ \mathbb{E} \left[ \exp \left( \frac{\epsilon}{r} \cdot d(O, O') \right) \right] \leq \exp(\epsilon) \]

where \( O \) and \( O' \) are the transcripts generated by \( M \) on inputs \( S^g \) and \( S^{g'} \), respectively.

---

This version is more organized, with clear references and a well-structured appendix.