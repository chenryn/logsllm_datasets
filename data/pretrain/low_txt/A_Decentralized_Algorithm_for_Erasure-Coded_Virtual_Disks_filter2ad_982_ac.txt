# Optimized Text

## Return Values and Logical Time Ordering
- `return decode(blocks)`
- `return ⊥`

### Variable `ord-ts` and Logical Time
The variable `ord-ts` represents the logical time at which the most recent write operation was initiated, establishing its position in the sequence of operations. The condition `max-ts(log)  max-ts(log) and ts≥ ord-ts)` ensures that if the status is true, `ord-ts` is updated to `ts`, and the new value is stored. A reply `[Order-R, status]` is then sent to the coordinator.

### Status and Logical Time Update
- `status ←(ts > max-ts(log) and ts ≥ ord-ts)`
- Initialize `lts← LowTS; b ← ⊥`
- If the status is true:
  - `ord-ts ←ts; store(ord-ts)`
  - If `j = i` or `j = ALL`:
    - When receiving `[Order&Read, j, max, ts]` from the coordinator, the system responds with `[Order&Read-R, status, lts, b]`.

### Write Operation
- When receiving `[Write, [b1, ..., bn], ts]` from the coordinator:
  - `status ←(ts > max-ts(log) and ts ≥ ord-ts)`
  - If the status is true, the log is updated to include `[ts, bi]` and stored.
  - A reply `[Write-R, status]` is sent to the coordinator.

### Recovery Method
The recovery method ensures that a completed read operation appears to occur after any partial write operation and that future read operations will return values consistent with this history. It finds the most recent version with at least `m` blocks, ending when it locates the timestamp of the most recent complete write.

## Reading and Writing a Single Block
### Algorithm 3: Block Methods and Handlers for Process `pi`

#### Procedure: `read-block(j)`
- `replies←quorum([Read, { j}])`
- If all statuses are true, `pj` has replied, and the `val-ts` in all replies is the same, return the block in `pj`'s reply.
- Otherwise, call `s← recover()`.
- If `s ≠ ⊥`, return `s[j]`.
- Otherwise, return `⊥`.

#### Procedure: `write-block(j, b)`
- `ts←newTS()`
- If `fast-write-block(j, b, ts) = OK`, return `OK`.
- Otherwise, return `slow-write-block(j, b, ts)`.

#### Procedure: `fast-write-block(j, b, ts)`
- `replies←quorum([Order&Read, j, HighTS, ts])`
- If the status contains false or `pj` did not reply, return `⊥`.
- Set `bj` to the block in `pj`'s reply and `tsj` to the timestamp in `pj`'s reply.
- `replies←quorum([Modify, j, bj, b, tsj, ts])`
- If all statuses are true, return `OK`.
- Otherwise, return `⊥`.

#### Procedure: `slow-write-block(j, b, ts)`
- `data←read-prev-stripe(ts)`
- If `data = ⊥`, return `⊥`.
- Update `data[j]` to `b`.
- Return `store-stripe(data, ts)`.

#### Message Handler: `[Modify, j, bj, b, tsj, ts]`
- `status ←(tsj = max-ts(log) and ts ≥ ord-ts)`
- If the status is true:
  - If `i = j`, set `bi ←b`.
  - If `i > m`, set `bi ←modify j,i(bj, b, max-block(log))`.
  - Otherwise, set `bi ←⊥`.
- Update the log to include `[ts, bi]` and store it.
- Reply `[Modify-R, status]` to the coordinator.

## Discussion
### Read-Block and Write-Block Methods
- The `read-block` method reads a specific block number `j`, similar to the `read-stripe` method but typically only `pj` performs the read.
- The `write-block` method updates both the data block and parity blocks, ensuring consistency. In the common case without partial writes, it reads from and writes to `pj` and the parity processes (using `fast-write-block`). Otherwise, it performs a recovery, replacing the `jth` block with the new value upon write-back.

### Garbage Collection
- The algorithm relies on each process maintaining a persistent log of updates, which is impractical. For correctness, each process needs to remember the most recent timestamp-data pair from a complete write.
- After successfully updating a full quorum with a timestamp `ts`, the coordinator can send a garbage-collection message to all processes to remove data with timestamps older than `ts`. This message can be sent asynchronously after the coordinator returns `OK`.

## Performance Comparison
### Table 1: Performance Comparison
- Our algorithm improves on previous work by providing efficient reading in the absence of failures or concurrent accesses and supporting erasure coding.
- There are straightforward ways to reduce network bandwidth for block-level writes, such as communicating only with `pj` and the parity processes, and sending a single coded block value to each parity process.

## Related Work
- Our erasure-coding algorithm is based on different assumptions compared to traditional erasure-coding algorithms in disk arrays.
- The algorithm in [15] provides decentralized erasure-coded storage using a quorum system and log-based store, handling Byzantine and crash failures but not process recovery. Our algorithm handles crash failures and incorporates process recovery.
- The goal of [2] is to allow clients to directly execute erasure-coding algorithms on storage devices, but it can result in data loss under certain failure conditions. Our algorithm can tolerate the simultaneous crash of all processes and makes progress when an `m-quorum` of processes are available.
- Several algorithms implement atomic read-write registers in asynchronous distributed systems, but none support erasure coding.

## References
- [1] M. K. Aguilera and S. Frolund. Strict linearizability and the power of aborting. Technical Report HPL-2003-241, HP Labs, November 2003.
- [2] K. Amiri, G. A. Gibson, and R. Golding. Highly concurrent shared storage. In International Conference on Distributed Computing Systems (ICDCS), 2000.
- [3] S. Asami. Reducing the cost of system administration of a disk storage system built from commodity components. PhD thesis, University of California, Berkeley, May 2000. Tech. Report. no. UCB-CSD-00-1100.
- [4] H. Attiya, A. Bar-Noy, and D. Dolev. Sharing memory robustly in message-passing systems. Journal of the ACM, 42(1):124–142, 1995.
- [5] J. Elson, L. Girod, and D. Estrin. Fine-grained network time synchronization using reference broadcasts. In Proceedings of the 5th symposium on operatings systems design and implementation (OSDI), pages 147–163. USENIX, 2002.
- [6] S. Frolund, A. Merchant, Y. Saito, S. Spence, and A. Veitch. FAB: enterprise storage systems on a shoestring. In Proceedings of the Ninth Workshop on Hot Topics in Operating Systems (HOTOS IX). USENIX, 2003. to appear.
- [7] S. Frolund, A. Merchant, Y. Saito, S. Spence, and A. Veitch. A decentralized algorithm for erasure-coded virtual disks. Technical Report HPL-2004-46, HP Labs, April 2004.
- [8] M. Herlihy and J. Wing. Linearizability: a correctness condition for concurrent objects. ACM Transactions on Programming Languages and Systems, 12(3):463–492, July 1990.
- [9] iSCSI draft 20 specification. http://www.diskdrive.com-/reading-room/standards.html, 2003.
- [10] N. A. Lynch and A. A. Shvartsman. Robust emulation of shared memory using dynamic quorum-acknowledged broadcasts. In Proceedings of the IEEE Symposium on Fault-Tolerant Computing Systems (FTCS), pages 272–281, 1997.
- [11] N. A. Lynch and A. A. Shvartsman. RAMBO: A reconfigurable atomic memory service for dynamic networks. In 16th Int. Conf. on Dist. Computing (DISC), October 2002.
- [12] D. A. Patterson, G. Gibson, and R. H. Katz. A case for redundant arrays of inexpensive disks (RAID). In H. Boral and P.-A. Larson, editors, Proceedings of 1988 SIGMOD International Conference on Management of Data, pages 109–16, Chicago, IL, 1–3 June 1988.
- [13] J. S. Plank. A tutorial on Reed-Solomon coding for fault-tolerance in RAID-like systems. Software—Practice and Experience, 27(9), 1997.
- [14] S. Reah, P. Eaton, D. Geels, H. Weatherspoon, B. Zhao, and J. Kubiatowics. Pond: the OceanStore prototype. In Conference and File and Storage Technologies (FAST). USENIX, mar 2003.
- [15] J. J. Wylie, G. R. Goodson, G. R. Ganger, and M. K. Reiter. Efficient Byzantine-tolerant erasure-coded storage. In Proceedings of the International Conference on Dependable Systems and Networks (DSN), 2004.