### 5.2.1 Dictionary Attacks
We evaluated dictionary attacks using the Openwall and dic-0294 dictionaries, which are ad-hoc dictionaries for password guessing that have been assessed in related work [7,19,30]. We compared these dictionaries to using the passwords in the Xato dataset as a dictionary, sorted by decreasing frequency of occurrence. The results are presented in Figure 9.

Figure 9 shows that large sets of leaked passwords outperform ad-hoc crafted dictionaries in cracking passwords. PCFGs (Probabilistic Context-Free Grammars) are efficient at generalizing guesses when dictionaries are exhausted.

### 5.2.2 N-Grams
In Figure 10, we compare attack models based on n-grams. Compared to results from smaller training sets [7], the sheer size of our training dataset allows us to find a large majority of the passwords even with higher-order models (n = 3 and n = 4). Attack models based on 2-grams and 1-grams (i.e., simply considering character frequencies) are unlikely to be effective for practical guessing attacks.

### 5.2.3 PCFGs
Figure 11 analyzes the performance of PCFG-based attacks. Our implementation of the model allows us to perform "leave-one-out" cross-validation. This method evaluates the benefits an attacker might gain with a very well-tuned training set, such as the full Rockyou database. As described in Section 4.2.2, we also train the alphabetic patterns of PCFGs from an external dictionary, choosing Openwall because it performs best in Figure 9.

A better training set (Rockyou rather than Xato) significantly improves performance, increasing the percentage of found passwords by around 13%. Two factors contribute to this: first, the Rockyou training set is larger than Xato; second, it is more representative of passwords for the Rockyou website (e.g., the "rockyou" string is very common in the former and relatively rare in the latter). This confirms that the size of modern training sets makes ad-hoc dictionaries obsolete, aligning with previous findings [19].

### 5.2.4 Backoff
Figure 12 presents the results of evaluating different variants of the backoff model. We again use the Rockyou dataset as a training set, employing the "leave-one-out" method. The figure highlights that the backoff strategy performs nearly optimally for each probability, especially for passwords that appear multiple times in the training dataset. When a password can ultimately be guessed by PCFGs, they do so with less effort than the backoff attack. However, roughly a third of the passwords are never guessed by PCFGs and thus do not appear in the graph.

### 5.3 Impact of Training Set Size
In Figure 13, we examine the effect of training set size on our results, focusing on the backoff model, which achieves a good guessing probability for any number of attempts. We vary the training set size between 0.1% and 100% of the full dataset.

Interestingly, a larger training set has little impact on guessing either the easiest or the hardest passwords. The most common passwords are likely to be in smaller subsets of the original training set, while the hardest ones are unique and provide little information even from large datasets. Increasing the training set size, however, is useful for "average" passwords, where either the given password or a similar one can be found in a larger dataset.

### 5.4 Evaluating Mandatory Requirements
We now evaluate mandatory requirements often imposed on passwords, such as minimum length and the inclusion of uppercase, numeric, and symbolic characters. From our datasets, we only consider passwords that meet these requirements and assess the number of attempts an attacker would need to guess them. We assume the attacker is aware of the restrictions and will not guess non-compliant passwords.

These results should be seen as optimistic evaluations of the strength improvements gained by imposing such restrictions. Users who choose weaker passwords might see these restrictions as hurdles to bypass with minimal effort, such as appending "1" to satisfy the requirement of including digits.

### 6. Conclusions
Passwords are a ubiquitous method for access control, and evaluating their security against state-of-the-art attacks is crucial. To our knowledge, this is the first study providing a reliable estimation, backed by proofs of correctness and convergence, for the success rate of expensive attacks using advanced guessing techniques. By assessing password strength in terms of the number of guesses needed, we gain insights into the actual cost an attacker must pay to guess a password, thereby better understanding the usability vs. security trade-off.

Our study shows that the number of attempts needed to guess a password is correlated across different attacks. However, we recommend checking user passwords against multiple attack models and outputting the result yielding the lowest strength value as a conservative strategy.

Our method is generic and lightweight, with the possibility of increasing accuracy by investing more computational resources. It is applicable to any generative probabilistic model and is future-proof, as new developments in password guessing are likely to continue using such models.

### 7. References
[1] J. Bonneau. The science of guessing: analyzing an anonymized corpus of 70 million passwords. In S&P. IEEE, 2012.
[2] G. Bontempi and S. Ben Taieb. Statistical foundations of machine learning. 2009.
[3] M. Burnett. Today I am releasing ten million passwords. https://xato.net/passwords/ten-million-passwords/, February 2015.
[4] W. Burr, D. Dodson, R. Perlner, W. Polk, and S. Gupta. NIST special publication 800-63-1 electronic authentication guideline, 2006.
[5] C. Castelluccia, M. Dürmuth, and D. Perito. Adaptive password-strength meters from Markov models. In NDSS. Internet Society, 2012.
[6] X. de Carné de Carnavalet and M. Mannan. From very weak to very strong: Analyzing password-strength meters. In NDSS. Internet Society, 2014.
[7] M. Dell’Amico, P. Michiardi, and Y. Roudier. Password strength: An empirical analysis. In INFOCOM. IEEE, 2010.
[8] M. Duermuth, F. Angelstorf, C. Castelluccia, D. Perito, and A. Chaabane. OMEN: Faster password guessing using an ordered Markov enumerator. In ESSoS. IEEE, 2015.
[9] S. Egelman, A. Sotirakopoulos, I. Muslukhov, K. Beznosov, and C. Herley. Does my password go up to eleven?: the impact of password meters on password selection. In SIGCHI. ACM, 2013.
[10] D. Florêncio, C. Herley, and P. C. Van Oorschot. An administrator’s guide to internet password research. In LISA. USENIX, 2014.
[11] D. Florêncio, C. Herley, and P. C. Van Oorschot. Password portfolios and the finite-effort user: Sustainably managing large numbers of accounts. In USENIX Security, 2014.
[12] C. Herley and P. Van Oorschot. A research agenda acknowledging the persistence of passwords. In S&P. IEEE, 2012.
[13] D. G. Horvitz and D. J. Thompson. A generalization of sampling without replacement from a finite universe. J. Am. Stat. Assoc., 47(260):663–685, 1952.
[14] S. Katz. Estimation of probabilities from sparse data for the language model component of a speech recognizer. IEEE TASSP, 35(3):400–401, 1987.
[15] P. G. Kelley, S. Komanduri, M. L. Mazurek, R. Shay, T. Vidas, L. Bauer, N. Christin, L. F. Cranor, and J. Lopez. Guess again (and again and again): Measuring password strength by simulating password-cracking algorithms. In S&P. IEEE, 2012.
[16] D. V. Klein. Foiling the cracker: A survey of, and improvements to, password security. In USENIX Security, 1990.
[17] S. Komanduri, R. Shay, L. F. Cranor, C. Herley, and S. Schechter. Telepathwords: Preventing weak passwords by reading users’ minds. In USENIX Security, 2014.
[18] Z. Li, W. Han, and W. Xu. A large-scale empirical analysis of Chinese web passwords. In USENIX Security, 2014.
[19] J. Ma, W. Yang, M. Luo, and N. Li. A study of probabilistic password models. In S&P. IEEE, 2014.
[20] R. Morris and K. Thompson. Password security: A case history. CACM, 22(11):594–597, 1979.
[21] A. Narayanan and V. Shmatikov. Fast dictionary attacks on passwords using time-space tradeoff. In CCS. ACM, 2005.
[22] P. Oechslin. Making a faster cryptanalytic time-memory tradeoff. In CRYPTO. Springer, 2003.
[23] C. Percival and S. Josefsson. The scrypt password-based key derivation function. 2012.
[24] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. Numerical Recipes: The Art of Scientific Computing. Cambridge University Press, 3rd edition, 2007.
[25] Solar Designer and S. Marechal. Password security: past, present, future. Password^12 workshop, December 2012.
[26] E. H. Spafford. Observing reusable password choices. In USENIX Security, 1992.
[27] B. Ur, P. G. Kelley, S. Komanduri, J. Lee, M. Maass, M. L. Mazurek, T. Passaro, R. Shay, T. Vidas, L. Bauer, et al. How does your password measure up? the effect of strength meters on password creation. In USENIX Security, 2012.
[28] R. Veras, C. Collins, and J. Thorpe. On the semantic patterns of passwords and their security impact. In NDSS. Internet Society, 2014.
[29] M. Weir, S. Aggarwal, M. Collins, and H. Stern. Testing metrics for password creation policies by attacking large sets of revealed passwords. In CCS. ACM, 2010.
[30] M. Weir, S. Aggarwal, B. De Medeiros, and B. Glodek. Password cracking using probabilistic context-free grammars. In S&P. IEEE, 2009.