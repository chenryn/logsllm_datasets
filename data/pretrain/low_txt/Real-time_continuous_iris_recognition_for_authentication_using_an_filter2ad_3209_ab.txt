### Sampling Rates for Iris Images

The iris image is sampled at a resolution of 20x60, which means that 20 samples are taken in the radial dimension and 60 samples are taken around the contour (in the angular dimension). To determine these parameters, we tested the iris recognition software using a database of user iris images [17]. This database contains data from 64 users, with three samples per user for both eyes, stored as 768x576x24 color PNG files. We used only the red channel information from the color images [18]. The database also helped confirm that the low resolution of the eye tracker was not a significant impediment.

### IRB-Approved User Study

The user study, approved by the Institutional Review Board (IRB), involved 37 participants. The eye tracker was connected to a 13-inch laptop computer. Participants were asked to remove their glasses to eliminate glare. The experimenter used a secondary monitor to view live video from the camera to ensure the eye tracker was focused on the participant's eyes. Participants were instructed to perform a Google Images search, and once they began, the recording of iris images started. The program recorded two runs, each consisting of 25 valid sample images of the participants' eyes (excluding samples where the eye was fully closed or the iris could not be located). Some valid samples included an iris image with up to 80% occlusion (e.g., during a blink). Each run took between 60 and 90 seconds.

### Experiments, Results, and Discussion

#### Iris Recognition in the User Study

Participants' irises were sampled at a resolution of 20x60 (radial and angular sampling rates), with the iris diameters in the eye tracker images being approximately 100 pixels. For each run, the software identified the 5 samples with the smallest total Hamming distance (minimum sum of distances from each sample to all other 24 samples). These 5 samples form the core of the run and serve as reference images for the iris.

In the best-of-batch authentication approach, we selected the 5 closest samples from a user's batch of samples for comparison to the core. This method enhances robustness against errors in individual samples. For this scenario, the equal error rate (EER) is 11% at a threshold of 0.235. Figure 2 illustrates the true positive versus false positive rate.

**Figure 2: True Positive vs. False Positive Rate**

If we require iris occlusion to be below 30%, only 14 out of the 37 users in the study meet this criterion. For these users, the best performance achieved an EER of 9%.

We also employed a k-nearest neighbors (KNN) machine learning algorithm to compare a core iris sample against the core samples for all users. A test core should match only the core of the same eye from different samples. For k=3 and using only the right eyes, the accuracy of the classification was 100%. Using the Manhattan distance metric, the KNN correctly classified 96.4% of the cores for k=3.

**Table 1: Accuracy of KNN for Core-Level Classification for Open Eyes**

| Metric | knn1 | knn3 | knn5 | knn7 | knn9 |
|--------|------|------|------|------|------|
| Left Eye | 85.7% | 82.1% | 85.7% | 78.6% | 67.9% |
| Right Eye | 96.4% | 100.0% | 92.9% | 92.9% | 82.1% |
| Manhattan | 92.9% | 96.4% | 92.9% | 92.9% | 92.9% |

### Conclusion

Results from the user study indicate that a commercial eye tracker can be effectively used for user authentication via iris recognition. Eye trackers have a resolution 2-5 times lower than dedicated iris recognition systems, and users can move freely while using the eye tracker, which poses challenges in capturing high-quality iris images. In a live user study, we achieved an EER of 11% for discriminating among users. For 14 out of the 37 users, the iris occlusion was small enough to achieve an EER of 9%. While this error rate is consistent with other continuous authentication schemes [11], it is too high to be used as the sole authentication method but could be useful when combined with more accurate techniques.

Eye trackers can also be used for user identification. Under optimal conditions, selecting only samples of open eyes and comparing core-to-core may allow for classification accuracy close to 100%. Future work will need to consider the effects of lighting conditions, user fatigue, and other long-term factors.

Ultimately, as eye trackers become more widely available as user interface devices, they might offer the additional benefit of real-time, continuous user authentication, potentially replacing traditional passwords or serving as part of multifactor authentication systems. Although the authentication capabilities of eye trackers alone may not lead to their widespread deployment, if they are already available for other applications, their potential for real-time continuous authentication should not be overlooked.

### Acknowledgements

We wish to thank the UAA University Honors College and College of Arts & Sciences for funding part of this research.

### References

[1] Daugman, J. (n.d.). How Iris Recognition Works. Retrieved April 14, 2010, from http://www.cl.cam.ac.uk/~jgd1000/irisrecog.pdf

[2] Thalheim, L., Krissler, J. and Zielger, P.-M. (2002). Body check: biometric access protection devices and their programs put to the test, translated by Robert Smith, c’t

[3] Biel, L.; Pettersson, O.; Philipson, L.; Wide, P.; (2001). ECG analysis: a new approach in human identification. Instrumentation and Measurement, IEEE Transactions on, vol.50, no.3, pp.808-812, Jun 2001.

[4] Hoanca, B., & Mock, K. J. (2006). Secure graphical password system for high traffic public areas. Eye Tracking Research and Applications (p. 35). San Diego: ACM.

[5] Spillane, R. (1975). Keyboard apparatus for personal identification. IBM Technical Disclosure Bulletin, 17, 3346.

[6] Denning, D., Neumann, P., & Parker, D.B. (1987). Social aspects of computer security. In Proceedings of the 10th National Computer Security Conference.

[7] Jorgensen, Z. & Yu, T. (2011). On Mouse Dynamics as a Behavioral Biometric for Authentication. Proceedings of the Sixth ACM Symposium on Information, Computer, and Communications Security.

[8] Slivovsky, L. & Tan, H. (2000). A real-time static posture classification system. Proceedings of the Ninth International Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, American Society of Mechanical Engineers Dynamic Systems and Control Division, Vol. 69-2, S. S. Nair (Ed.), (p. 1049-1056), Orlando, FL.

[9] Bledsoe, W. (1964). The model method in facial recognition. Technical report PRI 15, Panoramic Research, Inc., Palo Alto, CA.

[10] Dantcheva, A. & Dugelay, J. L. (2011). Frontal-to-side face re-identification based on hair, skin, and clothes patches. 2011 8th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS). Klagenfurt, Germany.

[11] Killourhy, K. & Maxion, R. (2009). Comparing Anomaly-Detection Algorithms for Keystroke Dynamics. In International Conference on Dependable Systems & Networks (DSN-09), (p. 125-134), Estoril, Lisbon, Portugal, July 2009. IEEE Computer Society Press, Los Alamitos, CA.

[12] Xiao, Q. (2005). Security issues in biometric authentication, Information Assurance Workshop, IAW 2005 (p. 8-13).

[13] Duchowski, A. (2002). A Breadth-First Survey of Eye-Tracking Applications. Behavior Research Methods Instruments and Computers, 34, 4, (p. 455-470).

[14] TM3 - EyeTech Digital Systems. (n.d.). Retrieved from EyeTech Digital Systems-Eye Tracking Technology Solutions: http://www.eyetechds.com/research/tm3-qc

[15] Masek, L. (2003). Iris Recognition. Retrieved from http://www.csse.uwa.edu.au/~pk/studentprojects/libor/

[16] He, X. & Shi, P. (2005). An Efficient Iris Segmentation Method for Recognition. Third International Conference on Advances in Pattern Recognition. Bath, UK.

[17] Dobeš, M., & Machala, L. (n.d.). Retrieved 4/30/2012 from Iris Database: http://phoenix.inf.upol.cz/iris/

[18] Dobeš M., Machala L., Tichavský P., Pospíšil J. (2004). Human Eye Iris Recognition Using the Mutual Information. Optik Journal for Light and Electron Optics, 115(9), p.399-405, Elsevier, ISSN 0030-4026.