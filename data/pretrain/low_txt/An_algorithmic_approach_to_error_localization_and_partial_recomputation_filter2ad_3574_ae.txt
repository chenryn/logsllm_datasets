### Input Vector and Application Checkpoint
The input vector of the matrix-vector product serves as the application checkpoint. Each technique is applied to an instance of the Parallel Conjugate Gradient (CG) algorithm (N=10) on linear problems, defined by the matrices described in Section IV-B. The solvers are run until a fixed accuracy of 1e-6 is achieved.

### Performance Overheads
Figure 4 illustrates the performance overheads of each technique across varying fault rates, ranging from 1e-8 to 1e-4. The y-axis represents the performance overhead, calculated for each matrix using the following formula:
\[
\text{Performance Overhead} = \left( \frac{\text{Time}_{\text{tech}}}{\text{Time}_{\text{NONE}}} - 1 \right) \times 100\%
\]
where \(\text{Time}_{\text{tech}}\) is the execution time of a given technique, and \(\text{Time}_{\text{NONE}}\) is the execution time of the solver without any fault tolerance techniques applied. Each dot in Figure 4 represents the average performance of a particular technique applied to a specific problem. The overhead is calculated relative to runs with no fault tolerance and zero faults, as discussed in Section IV. Each line in the figure represents the mean overhead across all problems at each fault rate.

### Observations from Results
The first observation is that detection and rollback techniques have a high cost (>200%) as the fault rate increases. For low fault rates (e.g., between 1e-8 and 1e-7), both the PR (Partial Recomputation) and DR (Detection and Rollback) based techniques have a similar mean overhead around 50%. However, after a fault rate of 1e-7, the overheads of DR-based approaches increase to over 100% on average. This is expected due to the higher cost of recovery for these traditional approaches. In contrast, PR-based techniques show a much slower increase in mean overheads. Specifically, PR-based techniques may have 2x-3x less overhead. For example, the PR-based approach that locates faults within segments located at 0.4 the total height of the binary search tree shows only a 30% average overhead from fault rates ranging from 1e-8 to 1e-4, compared to up to 3x with DR (perfect detection).

If the fault rates increase past a certain point, nearly every entry of the output will be erroneous for the matrices chosen. For such fault rates, the benefits of PR-based approaches diminish compared to DR-based approaches. However, for most real-world problems, the range of fault rates before this "saturating point" is hit encompasses even the worst-case expected operating points for future High-Performance Computing (HPC) systems. For example, with the sparse matrices considered in this evaluation, high fault rate scenarios (1e-6 – 1e-4) correspond to only 0.0001% to 0.01% of the output being corrupted. As systems and problems scale to even larger sizes (e.g., millions and billions of nodes), increasingly smaller fractions of the output will be corrupted for any reasonable fault rate, thus increasing the value of PR-based approaches.

### Matrix Properties and Overheads
Figure 4 also shows that the overheads at any given fault rate can vary significantly based on the properties of the matrix. For example, for problems bcsstk16 and nd3k, the overheads are significantly larger for techniques using practical detection schemes (PR-based and DR (t=1)). This is because the average magnitude of entries within these problems is very large, making it difficult to detect faults with a fixed threshold (bcsstk16 and nd3k contain average magnitudes of 1e6 and 1e-4, respectively). Therefore, the detection and fault localization process is less accurate and incurs greater overheads from false negatives and false positives. Other problems, such as nasa2910, which has a condition number of 1e64, are simply poorly conditioned and incur high overheads across all techniques. In general, the overheads for the different matrices are near their representative means (±30%).

### Success Rates
Each solver instance is run under faults until it either hits the accuracy target or reaches the limit on the maximum number of iterations (10 times the number of rows). If the solver does not meet the accuracy target by the maximum number of iterations, it is considered a failure. Figure 5 shows the success rate for each technique over the same set of matrices and fault rates as in Figure 4. The solvers are run until convergence and for a maximum number of iterations (10 times the dimension of the problem). As the fault rate increases, DR is less likely to make forward progress and is increasingly unable to meet the accuracy target by the maximum number of iterations. All techniques, except DR using a realistic threshold, complete nearly 80% of the tested matrices. For solver instances using DR(t = 1), the success rate drops quickly from 1e-8 to 1e-4 due to the high overhead of rollbacks and extra iterations incurred due to missed faults. Solver instances using DR with perfect detection show good success rates until a fault rate of 1e-4, where the high overhead of rollback-based recoveries prevents the solver from meeting the accuracy target by the iteration limit.

### Scalability of Techniques
Figure 6 illustrates the results of experiments evaluating the scalability of the techniques. Dots correspond to individual experiments, and lines represent the mean overheads. The overhead for each matrix is calculated using the following formula:
\[
\text{Overhead} = \left( \frac{\text{Time}_{\text{tech}} \text{ with N nodes and 1e-6 faults}}{\text{Time}_{\text{NONE}} \text{ with N nodes and zero faults}} - 1 \right) \times 100\%
\]

As the number of nodes in the system increases, the benefits of a partial computation-based approach versus traditional detection also increase. To evaluate the scalability of the techniques, we fix the fault rate (1e-6) and run the same experiments with different numbers of nodes ({1, 2, 10, 20, 100}). A description of the parallel solver implemented with MPI is included in Section IV-C.

We observe in Figure 6 that the benefit of PR-based approaches increases as the number of nodes scales up. At N=10, the average overhead of DR-based approaches over PR is 50%. As the number of nodes used in the solver increases to 100, the overheads of DR over PR become even more pronounced, increasing to over 300%–350%. These results indicate that more realistic detection schemes using dynamic thresholds, partial recomputation-based approaches are significantly more efficient (CG converges 70% more often and performance overheads are 2x-3x smaller). For a fixed moderate fault rate, partial recomputation-based approaches with complete error localization reduce the overhead by up to 32% on average when scaled up to 10 nodes and 320% when scaled up to 100 nodes. Similarly, with the relaxed error localization routine, the overhead is reduced by up to 77% at 10 nodes and up to 390% at 100 nodes.

### Conclusions
Our results demonstrate the value of research into partial recomputation in the context of a wider range of algorithms. Since this approach is significantly more efficient than whole-application recomputation and also significantly simpler than algorithmic correction techniques, we expect this line of work to be extremely productive in ensuring cheap and effective resilience on future massively parallel systems.

### Acknowledgments
This work was supported in part by NSF, ARO, GSRC, and the Department of Energy Early Career award program. It was also partially performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344. We thank Tzanio Kolev and anonymous reviewers for their helpful feedback.

### References
[1] Mpich-v. http://mpich-v.lri.fr.
[2] International Technology Roadmap for Semiconductors. White Paper, ITRS, 2010.
[3] J. Anfinson and F. T. Luk. A linear algebraic model of algorithm-based fault tolerance. IEEE Trans. Comput., 37:1599–1604, December 1988.
[4] Greg Bronevetsky, Ignacio Laguna, Saurabh Bagchi, Bronis R. de Supinski, Dong H. Ahn, and Martin Schulz. AutomaDeD: Automata-Based Debugging for Dissimilar Parallel Tasks. In 2010 IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pages 231–240, Chicago, IL, 2010.
[5] Greg Bronevetsky, Daniel Marques, Keshav Pingali, and Paul Stodghill. Automated application-level checkpointing of MPI programs. SIGPLAN Not., 38(10):84–94, June 2003.
[6] Zizhong Chen. Algorithm-based recovery for iterative methods without checkpointing. In Proceedings of the 20th international symposium on High performance distributed computing, HPDC ’11, pages 73–84, New York, NY, USA, 2011. ACM.
[7] Timothy A. Davis. University of Florida Sparse Matrix Collection. NA Digest, 92, 1994.
[8] Berman et. al. Exascale computing study: Technology challenges in achieving exascale systems Peter Kogge, editor & study lead. Technical report, DARPA IPTO, SEP 2008.
[9] J. N. Glosli et. al. Extending stability beyond CPU millennium: a micron-scale atomistic simulation of Kelvin-Helmholtz instability. In Proceedings of the 2007 ACM/IEEE conference on Supercomputing, SC ’07, pages 58:1–58:11, New York, NY, USA, 2007. ACM.
[10] Jack Dongarra Andrew et. al. A sparse matrix library in C++ for high performance architectures, 1994.
[11] Keun Soo Yim et. al. Hauberk: Lightweight silent data corruption error detector for GPGPU. In Proceedings of the 2011 IEEE International Parallel & Distributed Processing Symposium, IPDPS ’11, 2011.
[12] Man-lap Li et. al. SWAT: An error resilient system, 2008.
[13] Nahmsuk Oh et. al. Control-flow checking by software signatures. IEEE Transactions on Reliability, 51:111–122, 2002.
[23] Adam Moody, Greg Bronevetsky, Kathryn Mohror, and Bronis R. de Supinski. Design, modeling, and evaluation of a scalable multi-level checkpointing system. In ACM/IEEE Conference on Supercomputing, 2010.
[24] Sung-Boem Park, Anne Bracy, Hong Wang, and Subhasish Mitra. Blog: post-silicon bug localization in processors using bug localization graphs. In Proceedings of the 47th Design Automation Conference, DAC ’10, pages 368–373, New York, NY, USA, 2010. ACM.
[25] Valeria Simoncini, Daniel, and B. Szyld. Theory of inexact Krylov subspace methods and applications to scientific computing. Technical report, 2002.
[26] J. Sloan, D. Kesler, R. Kumar, and A. Rahimi. A numerical optimization-based methodology for application robustification: Transforming applications for error tolerance. In Dependable Systems and Networks (DSN), 2010, June 2010.
[27] J. Sloan, R. Kumar, and G. Bronevetsky. Algorithmic approaches to low overhead fault detection for sparse linear algebra. In Dependable Systems and Networks (DSN), 2012, 2012-july 1 2012.
[28] Gregory F. Sullivan, Dwight S. Wilson, and Gerald M. Masson. Certification of computational results. IEEE Transactions on Computers, 44:833–847, 1995.
[29] Diana Szentivanyi, Simin Nadjm-Tehrani, and John M. Noble. Optimal choice of checkpointing interval for high availability. In Proceedings of the 11th Pacific Rim International Symposium on Dependable Computing, PRDC ’05, pages 159–166, Washington, DC, USA, 2005. IEEE Computer Society.
[30] Chao Wang, Frank Mueller, Christian Engelmann, and Stephen L. Scott. A job pause service under LAM/MPI+BLCR for transparent fault tolerance. In International Parallel and Distributed Processing Symposium, pages 26–30, 2007.
[31] Hadley Wickham. ggplot2: Elegant graphics for data analysis. Springer New York, 2009.
[14] Nithin Nakka et. al. An architectural framework for providing reliability and security support. In DSN, pages 585–594. IEEE Computer Society, 2004.
[15] Ronald F. Boisvert et. al. Matrix Market: A web resource for test matrix collections. In The Quality of Numerical Software: Assessment and Enhancement, pages 125–137. Chapman and Hall, 1997.
[16] Sarah Michalak et. al. Predicting the Number of Fatal Soft Errors in Los Alamos National Laboratory’s ASC Q Supercomputer. IEEE Transactions on Device and Materials Reliability, 5(3), 2005.
[17] Michael A. Heroux and Mark Hoemmen. Fault-tolerant iterative methods via selective reliability. Technical report, Sandia National Laboratories Technical Report, 2011.
[18] Kuang-Hua Huang and J.A. Abraham. Algorithm-based fault tolerance for matrix operations. Computers, IEEE Transactions on, C-33(6):518–528, 1984.
[19] P. Hargrove, J. Duell, and E. Roman. The design and implementation of Berkeley Lab’s Linux checkpoint/restart. Technical report, Berkeley Lab Technical Report, 2002.
[20] C. Kong. Study of voltage and process variation’s impact on the path delays of arithmetic units. In UIUC Master’s Thesis, 2008.
[21] Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems, 2009.
[22] A.V. Mirgorodskiy, N. Maruyama, and B.P. Miller. Problem diagnosis in large-scale computing environments. In SC 2006 Conference, Proceedings of the ACM/IEEE, 2006.