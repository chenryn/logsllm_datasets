# Pingmesh Pipeline and Extensions

## Silent Packet Drop Detection
As discussed in Section 5, Pingmesh has been utilized for silent packet drop detection. Since latency data is already available, the primary task is to develop and implement the detection algorithm within the DSA pipeline, without modifying other Pingmesh components.

## Network Metrics for Services
Two key metrics provided by Pingmesh are used by service developers to enhance their services. The Pingmesh Agent exposes two performance counters for each server: the 99th percentile latency and the packet drop rate. These metrics help service developers better understand data center network latency at the server level. The per-server packet drop rate is also used by several services as a criterion for server selection.

For the above extensions, only inter-data center (inter-DC) Pingmesh and Quality of Service (QoS) monitoring were designed intentionally. The other three features emerged organically due to Pingmesh's loosely coupled design, allowing for smooth integration without architectural changes.

## Visualization for Pattern Discovery
We have invested significantly in the analysis and visualization of Pingmesh data. Our findings indicate that the data itself is highly informative, and visualization enhances our ability to understand and detect various latency patterns. Figure 8 illustrates several typical visualized latency patterns. In these visualizations, small green, yellow, or red blocks represent the 99th percentile network latency between source-destination pod pairs. Green indicates latency less than 4ms, yellow indicates latency between 4-5ms, and red indicates latency greater than 5ms. A white block signifies no available latency data.

- **Figure 8(a)**: An almost all-green pattern, indicating that the network is functioning well. This pattern is one of the most widely used features of Pingmesh, providing an easy way to assess the global health of the network.
- **Figure 8(b)**: A white-cross pattern, where the width corresponds to a Podset (containing around 20 pods). This pattern indicates a Podset-down scenario, typically caused by power loss to the entire Podset.
- **Figure 8(c)**: A red-cross pattern, again corresponding to a Podset. The red-cross indicates high network latency to and from the Podset, suggesting a network issue within the Podset. Possible causes include packet drops by Leaf switches or broadcast storms if the Podset is a Layer 2 domain.
- **Figure 8(d)**: A pattern with red color and green squares along the diagonal. Each small green square represents a Podset, indicating normal latencies within Podsets but out-of-SLA cross-Podset latencies. This suggests a network issue at the Spine switch layer.

The success of the visualization has exceeded expectations. Regularly checking the visualization portal has become a habit for many, including network developers, engineers, and customers. Initially, the network team used the visualization to prove network health to customers. Now, customers use it to identify ongoing network issues, which is a positive change in usage patterns.

## Pingmesh Limitations
During the operation of Pingmesh, we identified two main limitations:

1. **Fault Localization**: While Pingmesh can detect which tier a faulty network device is located in, it cannot pinpoint the exact location. In our network, there are tens to hundreds of switches at the Spine layer. Knowing the Spine layer is experiencing issues is helpful but not sufficient. We need methods to quickly locate and isolate faulty devices. This limitation was known from the start, and we address it by combining Pingmesh with TCP traceroute, as described in Section 5.2.

2. **Latency Measurement**: Pingmesh currently measures single-packet Round-Trip Time (RTT), which is effective for detecting network reachability and packet-level latency issues. However, it does not cover scenarios requiring multiple round trips. For example, a recent live-site incident caused by TCP parameter tuning was not detected by Pingmesh because it only measures single-packet RTT.

## Related Work
Our experience running one of the largest data center networks globally has taught us that various components, including applications, OS kernels, NICs, switching ASICs, firmware, and fibers, can cause communication failures. [4] provides a summary of such failures.

- **[21]** and **[6]** studied traffic and flow characteristics in different types of data centers using network traces. Pingmesh focuses on network latency and complements these works.
- **[18]** and Pingmesh both aim to detect packet drops using active probing packets. However, [18] uses RSVP-TE-based source routing to pinpoint the routing path, while Pingmesh can be used for both intra-DC and inter-DC networks.
- **Cisco IPSLA [8]** uses active packets for network performance monitoring, configured to run on Cisco switches. Pingmesh differs by using servers for data collection, making it device-independent and focusing on both measurement and data analysis.
- **NetSight [19]** tracks packet history by introducing postcard filters at switches. Pingmesh is server-based and can detect silent packet drops, which is not straightforward with NetSight.
- **ATPG [25]** determines a minimal set of probing packets to cover all network links and forwarding rules. Pingmesh does not minimize the number of probings and is designed to run continuously, making it more suitable for real-time monitoring.

## Conclusion
We have presented the design and implementation of Pingmesh for data center network latency measurement and analysis. Pingmesh is always-on, providing network latency data for all servers. It has been running in Microsoft data centers for over four years, helping to determine if service issues are network-related, define and track network SLAs, and serve as an essential tool for network troubleshooting.

Due to its loosely coupled design, Pingmesh is easily extensible, with many new features added without changing its architecture. By analyzing Pingmesh latency data and learning from latency patterns through visualization and data mining, we continuously improve network quality, such as automatically fixing packet black-holes and detecting switch silent random packet drops.

## Acknowledgements
We thank Lijiang Fang, Albert Greenberg, Wilson Lee, Randy Kern, Kelvin Yiu, Dongmei Zhang, Yongguang Zhang, Feng Zhao, and members of the Wireless and Networking Group of Microsoft Research Asia for their support. We also thank Sujata Banerjee and the anonymous SIGCOMM reviewers for their valuable feedback and comments.

## References
[1] M. Al-Fares, A. Loukissas, and A. Vahdat. A Scalable, Commodity Data Center Network Architecture. In Proc. SIGCOMM, 2008.
[2] Alexey Andreyev. Introducing data center fabric, the next-generation Facebook data center network. https://code.facebook.com/posts/360346274145943/, Nov 2014.
[3] Hadoop. http://hadoop.apache.org/.
[4] Peter Bailis and Kyle Kingsbury. The Network is Reliable: An Informal Survey of Real-World Communications Failures. ACM Queue, 2014.
[5] Luiz Barroso, Jeffrey Dean, and Urs Hölzle. Web Search for a Planet: The Google Cluster Architecture. IEEE Micro, March-April 2003.
[6] Theophilus Benson, Aditya Akella, and David A. Maltz. Network Traffic Characteristics of Data Centers in the Wild. In Internet Measurement Conference, November 2010.
[7] et.al Brad Calder. Windows Azure Storage: A Highly Available Cloud Storage Service with Strong Consistency. In SOSP, 2011.
[8] Cisco. IP SLAs Configuration Guide, Cisco IOS Release 12.4T. http://www.cisco.com/c/en/us/td/docs/ios-xml/ios/ipsla/configuration/12-4t/sla-12-4t-book.pdf.
[9] Citrix. What is Load Balancing? http://www.citrix.com/glossary/load-balancing.html.
[10] Jeffrey Dean and Luiz André Barroso. The Tail at Scale. CACM, February 2013.
[11] Jeffrey Dean and Sanjay Ghemawat. MapReduce: Simplified Data Processing on Large Clusters. In OSDI, 2004.
[12] Albert Greenberg et al. VL2: A Scalable and Flexible Data Center Network. In SIGCOMM, August 2009.
[13] Chi-Yao Hong et al. Achieving High Utilization with Software-Driven WAN. In SIGCOMM, 2013.
[14] Parveen Patel et al. Ananta: Cloud Scale Load Balancing. In ACM SIGCOMMM. ACM, 2013.
[15] R. Chaiken et al. SCOPE: Easy and Efficient Parallel Processing of Massive Data Sets. In VLDB’08, 2008.
[16] Sushant Jain et al. B4: Experience with a Globally-Deployed Software Defined WAN. In SIGCOMM, 2013.
[17] Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. The Google File System. In ACM SOSP. ACM, 2003.
[18] Nicolas Guilbaud and Ross Cartlidge. Google Backbone Monitoring, Localizing Packet Loss in a Large Complex Network, February 2013. Nanog57.
[19] Nikhil Handigol, Brandon Heller, Vimalkumar Jeyakumar, David Mazières, and Nick McKeown. I Know What Your Packet Did Last Hop: Using Packet Histories to Troubleshoot Networks. In NSDI, 2014.
[20] Michael Isard. Autopilot: Automatic Data Center Management. ACM SIGOPS Operating Systems Review, 2007.
[21] Srikanth Kandula, Sudipta Sengupta, Albert Greenberg, Parveen Patel, and Ronnie Chaiken. The nature of data center traffic: Measurements & analysis. In Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement Conference, IMC ’09, 2009.
[22] Rishi Kapoor, Alex C. Snoeren, Geoffrey M. Voelker, and George Porter. Bullet Trains: A Study of NIC Burst Behavior at Microsecond Timescales. In ACM CoNEXT, 2013.
[23] Cade Metz. Return of the Borg: How Twitter Rebuilt Google’s Secret Weapon. http://www.wired.com/2013/03/google-borg-twitter-mesos/all/, March 2013.
[24] Wenfei Wu, Guohui Wang, Aditya Akella, and Anees Shaikh. Virtual Network Diagnosis as a Service. In SoCC, 2013.
[25] Hongyi Zeng, Peyman Kazemian, George Varghese, and Nick McKeown. Automatic Test Packet Generation. In CoNEXT, 2012.