### Message Processing and HIPAA Compliance

The system processes messages based on eight attributes, including the sender, intended recipient, subject, type of information, and purpose. The prototype tool features a user-friendly front-end and provides an interface for understanding the types of disclosures and uses of personal health information that are permitted and forbidden by the HIPAA Privacy Rule. However, the approach has certain limitations in demonstrating compliance with the HIPAA Privacy Rule:

1. **Temporal Conditions**: The pLogic system uses specialized predicates to capture past events but cannot represent future obligations, which are necessary for formalizing many clauses in HIPAA. In contrast, our policy logic and the reduce algorithm handle both temporal and real-time conditions.
2. **Assumed Correctness**: pLogic assumes that all asserted beliefs, purposes, and types of information associated with messages are correct. Our reduce algorithm, however, mines logs to determine the truth values of atoms, ensuring that facts are only assumed if there is supporting evidence in the logs.
3. **Comprehensive Formalization**: Our prototype implementation was evaluated with a full formalization of the HIPAA Privacy Rule, whereas Lam et al. only formalized sections §§164.502, 164.506, and 164.510.

### Policy Specification and Analysis

Several variants of Linear Temporal Logic (LTL) have been used to specify properties of programs, business processes, and security and privacy policies [6, 15, 8, 18, 23]. The logic we use, as well as the formalization of HIPAA in our experiments, is adapted from our prior work on the logic PrivacyLFP [15], which draws inspiration from the earlier logic LPU [6]. PrivacyLFP is more expressive than LPU, allowing first-order quantification over infinite domains.

Additionally, several access-control models have been extended to include usage control and future obligations [20, 10, 28, 21, 26, 16, 27]. Some models, such as Irwin et al. [21], define obligations as tuples containing the subject, actions, objects, and time frames. Others leave the specifications for obligations more abstract [20, 10, 28]. These specific models and policies can be encoded in our logic using quantifiers.

There has also been significant research on analyzing the properties of policies represented in formal models. For example, Ni et al. [26] study the interaction between obligations and authorization, while Irwin et al. [21] analyze accountability problems with obligations, and Dougherty et al. [16] model the interaction between obligations and programs. These methods are complementary to our objective of policy enforcement.

Privacy languages like EPAL [4] and privacyAPI [25] do not include obligations or temporal modalities as primitives and are less expressive than our framework.

### Conclusion and Future Work

We have designed, implemented, and evaluated a provably correct iterative algorithm, reduce, for policy audit, which works even with incomplete audit logs. Our policy logic is expressive enough to represent real privacy legislation like HIPAA, yet tractable due to a carefully designed static analysis. Empirical evaluation shows that reduce is efficient enough for practical use.

In future work, we plan to investigate two additional applications:

1. **Runtime Monitoring of Policies**: Reduce can be applied to the part of the policy relevant to an action, using a hypothetical log that includes the future action. If the resulting formula is unsatisfiable, the action is a violation; if it is satisfiable, the action is permitted. If reduce outputs a non-trivial residual formula, it can guide agents about the legitimacy of their actions. This tool will be useful for organizations to educate employees about appropriate disclosures and uses of personal information as described in complex policies like the HIPAA Privacy Rule.
2. **Accounting of Actions Involving Personal Information**: Proposals for informing patients about disclosures and uses of their personal health information are currently being debated in the U.S. [14]. Reduce can be run on the entire policy with a subset of the logs pertaining to a specific agent to discover all related disclosures and evidence supporting whether the disclosures were violations, permitted, or conditionally permitted.

We also plan to integrate our audit algorithm into a policy-aware health information exchange system being developed as part of the SHARPS project (http://sharps.org). Ensuring that disclosures of protected health information comply with privacy regulations is critical in this setting. This project will provide a platform to deploy and evaluate the effectiveness of our algorithm using real hospital logs. Another direction of ongoing and future work is to develop semantic foundations and enforcement techniques for concepts in privacy policies related to purposes and beliefs, which are challenging to formalize and enforce using computational methods.

### Acknowledgments

This work was partially supported by the U.S. Army Research Office contract “Perpetually Available and Secure Information Systems” (DAAD19-02-1-0389) to Carnegie Mellon CyLab, the NSF Science and Technology Center TRUST, the NSF CyberTrust grant “Privacy, Compliance and Information Risk in Complex Organizational Processes,” the AFOSR MURI “Collaborative Policies and Assured Information Sharing,” and HHS Grant no. HHS 90TR0003/01.

### References

[1] R. Alur and T. A. Henzinger. A really temporal logic. Journal of the ACM, 41(1):181–203, 1994.
[2] K. R. Apt and E. Marchiori. Reasoning about Prolog programs: From modes through types to assertions. Formal Aspects of Computing, 6(6):743–765, 1994.
[3] F. Baader, A. Bauer, and M. Lippmann. Runtime verification using a temporal description logic. In Proceedings of the 7th International Conference on Frontiers of Combining Systems (FroCos), pages 149–164, 2009.
[4] M. Backes, B. Pfitzmann, and M. Schunter. A toolkit for managing enterprise privacy policies. In Proceedings of the 8th European Symposium on Research in Computer Security (ESORICS), LNCS 2808, pages 101–119, 2003.
[5] H. Barringer, A. Goldberg, K. Havelund, and K. Sen. Rule-based runtime verification. In Proceedings of the 5th International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI), pages 44–57, 2004.
[6] A. Barth, A. Datta, J. C. Mitchell, and H. Nissenbaum. Privacy and contextual integrity: Framework and applications. In Proceedings of the 27th IEEE Symposium on Security and Privacy (Oakland), pages 184–198, 2006.
[7] A. Barth, J. C. Mitchell, A. Datta, and S. Sundaram. Privacy and utility in business processes. In Proceedings of the 20th IEEE Computer Security Foundations Symposium (CSF), pages 279–294, 2007.
[8] D. Basin, F. Klaedtke, and S. Müller. Monitoring security policies with metric first-order temporal logic. In Proceeding of the 15th ACM Symposium on Access Control Models and Technologies (SACMAT), pages 23–34, 2010.
[9] D. A. Basin, F. Klaedtke, and S. Müller. Policy monitoring in first-order temporal logic. In Proceedings of the 22nd International Conference on Computer Aided Verification (CAV), pages 1–18, 2010.
[10] C. Bettini, S. Jajodia, X. S. Wang, and D. Wijesekera. Provisions and obligations in policy rule management. Journal of Network and Systems Management, 11:351–372, 2003.
[11] G. Bruns and P. Godefroid. Generalized model checking: Reasoning about partial state spaces. In Proceedings of the 11th International Conference on Concurrency Theory (CONCUR), pages 168–182, 2000.
[12] J. G. Cederquist, R. Corin, M. A. C. Dekker, S. Etalle, J. I. den Hartog, and G. Lenzini. Audit-based compliance control. International Journal of Information Security, 6(2):133–151, 2007.
[13] Deloitte & Touche and the Ponemon Institute. Enterprise@Risk: 2007 Privacy and Data Protection Survey. White Paper, December 2007.
[14] Department of Health and Human Services, Office of the Secretary. HIPAA Privacy Rule accounting of disclosures under the health information technology for economic and clinical health act. 45 CFR 164, 2011. Available at http://www.gpo.gov/fdsys/pkg/FR-2011-05-31/pdf/2011-13297.pdf.
[15] H. DeYoung, D. Garg, L. Jia, D. Kaynar, and A. Datta. Experiences in the logical specification of the HIPAA and GLBA privacy laws. In Proceedings of the 9th Annual ACM Workshop on Privacy in the Electronic Society (WPES), 2010. Full version: Carnegie Mellon University Technical Report CMU-CyLab-10-007.
[16] D. J. Dougherty, K. Fisler, and S. Krishnamurthi. Obligations and their interaction with programs. In Proceedings of the 12th European Symposium on Research in Computer Security (ESORICS), pages 375–389, 2007.
[17] D. Garg, L. Jia, and A. Datta. A logical method for policy enforcement over evolving audit logs. Technical Report CMU-CyLab-11-002, Carnegie Mellon University, 2011.
[18] C. Giblin, A. Y. Liu, S. Müller, B. Pfitzmann, and X. Zhou. Regulations expressed as logical models (REALM). In Proceeding of the 18th Annual Conference on Legal Knowledge and Information Systems (JURIX), pages 37–48, 2005.
[19] P. Godefroid and M. Huth. Model checking vs. generalized model checking: Semantic minimizations for temporal logics. In Proceedings of the 20th Annual IEEE Symposium on Logic in Computer Science (LICS), pages 158–167, 2005.
[20] M. Hilty, D. A. Basin, and A. Pretschner. On obligations. In Proceedings of the 10th European Symposium on Research in Computer Security (ESORICS), pages 98–117, 2005.
[21] K. Irwin, T. Yu, and W. H. Winsborough. On the modeling and analysis of obligations. In Proceedings of the 13th ACM Conference on Computer and Communications Security (CCS), pages 134–143, 2006.
[22] P. E. Lam, J. C. Mitchell, and S. Sundaram. A formalization of HIPAA for a medical messaging system. In Proceedings of the 6th International Conference on Trust, Privacy and Security in Digital Business (TrustBus), pages 73–85, 2009.
[23] Y. Liu, S. Müller, and K. Xu. A static compliance-checking framework for business process models. IBM Systems Journal, 46:335–361, 2007.
[24] Z. Manna and A. Pnueli. Temporal Verification of Reactive Systems: Safety. Springer-Verlag, 1995.
[25] M. J. May, C. A. Gunter, and I. Lee. Privacy APIs: Access control techniques to analyze and verify legal privacy policies. In Proceedings of the 19th IEEE Workshop on Computer Security Foundations (CSFW), pages 85–97, 2006.
[26] Q. Ni, E. Bertino, and J. Lobo. An obligation model bridging access control policies and privacy policies. In Proceedings of the 13th ACM Symposium on Access Control Models and Technologies (SACMAT), pages 133–142, 2008.
[27] OASIS XACML Committee. Extensible access control markup language (XACML) v2.0, 2004. Available at http://www.oasis-open.org/specs/#xacmlv2.0.
[28] J. Park and R. Sandhu. Towards usage control models: beyond traditional access control. In Proceedings of the 7th ACM Symposium on Access Control Models and Technologies (SACMAT), pages 57–64, 2002.
[29] G. Roşu and K. Havelund. Rewriting-based techniques for runtime verification. Automated Software Engineering, 12:151–197, 2005.
[30] M. Roger and J. Goubault-Larrecq. Log auditing through model-checking. In Proceedings of the 14th IEEE Workshop on Computer Security Foundations (CSF), pages 220–236, 2001.
[31] O. Sokolsky, U. Sammapun, I. Lee, and J. Kim. Run-time checking of dynamic properties. Electronic Notes in Theoretical Computer Science, 144:91–108, 2006.
[32] P. Thati and G. Roşu. Monitoring algorithms for metric temporal logic specifications. Electronic Notes in Theoretical Computer Science, 113:145–162, 2005.
[33] US Congress. Gramm-Leach-Bliley Act, Financial Privacy Rule. 15 USC §6801–§6809, November 1999. Available at http://www.law.cornell.edu/uscode/usc_sup_01_15_10_94_20_I.html.
[34] US Congress. Health Insurance Portability and Accountability Act of 1996, Privacy Rule. 45 CFR 164, 2002. Available at http://www.access.gpo.gov/nara/cfr/waisidx_07/45cfr164_07.html.