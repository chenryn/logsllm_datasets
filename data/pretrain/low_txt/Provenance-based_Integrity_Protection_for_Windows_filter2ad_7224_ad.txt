### Code Attacks and Multi-Step Exploits to Circumvent Sandboxes

**Code attacks** refer to scenarios where an attacker has the ability to execute code but with limited privileges, such as within a restrictive sandbox. For example, in the Adobe Reader exploit [11], it is assumed that the attacker has already compromised the sandboxed worker process. Although the attacker cannot run code outside the sandbox, they can exploit vulnerabilities in the broker process. Specifically, the attack exploited the worker-broker Inter-Process Communication (IPC) interface. The broker process only enforced policies by resolving the first-level NTFS junction. A compromised worker could use a chain of junctions to bypass the sandbox policy and write arbitrary files to the file system with the broker's permissions. Since the broker ran with user privileges, the attacker could escape the sandbox and modify any user files. In Spif, both the broker and worker processes are run as untrusted processes. As a result, the attack could only create or modify low-integrity files, meaning that any subsequent uses of these files were also confined by the low-integrity sandbox.

Spif prevented the Stuxnet [10] attack by stopping the lnk vulnerability from being triggered. Since the lnk file is of low integrity, Spif prevented Windows Explorer from loading it, thus preventing the loading of any untrusted DLLs. We also tested the Microsoft Windows OLE Package Manager Code Execution vulnerability, known as Sandworm [46]. This vulnerability was exploited in the wild in October 2014. When users view a malicious PowerPoint file, the OLE package manager can be exploited to modify a registry key in HKLM, which subsequently triggers a payload to run with system-administrator privileges. Spif ran PowerPoint as a low-integrity process when it opened the untrusted file. The exploit was stopped because the low-integrity process did not have the necessary permissions to modify the system registry.

The most common technique used to exploit the remaining applications was a Structured Exception Handler (SEH) buffer overflow. The upload preference file `uploadpref.dat` of Calavera UpLoader and `Setting.ini` of Total Video Player were modified so that when the applications ran, the shellcode specified in the files would be executed. Similarly, SEH buffer overflows can be triggered via data input, such as using a multimedia playlist (.m3u) for Light Alloy or a word document (.wps) for Kingsoft Office Writer. Other common techniques include integer overflows (used in `CCProxy.ini` for CCProxy) and stack overflows (triggered when MuPDF parsed a crafted xps file or when WinAmp parsed a directory name with an invalid length). Without Spif, these applications ran with user privileges, allowing attackers to abuse these privileges, for example, to make the malware persist across reboots.

Although preference files are specific to applications, there is no permission control to prevent other applications from modifying them. Spif ensures that preference files of high-integrity applications cannot be modified by any low-integrity subject. This protects benign processes from being exploited, and thus, attackers cannot abuse user privileges. On the other hand, Spif does not prevent low-integrity instances of the applications from consuming low-integrity preference or data files. While attackers could exploit low-integrity processes, they only had the privileges of the low-integrity user. Furthermore, all actions taken by the attackers were tracked and confined by the low-integrity sandbox.

### Related Work

The first step in most malware attacks is an exploit, typically targeting a memory corruption vulnerability to gain arbitrary execution capability. Widespread deployment of Address Space Layout Randomization (ASLR) and Data Execution Prevention (DEP) has raised the bar, but attackers often find ways to bypass these defenses. Comprehensive memory corruption defenses [48, 33] can stop these exploits, but they introduce some incompatibilities in large and complex software. Lightweight bounds-checking [15] avoids this problem by trading off some protection for increased compatibility and performance.

Instead of focusing on the exploit mechanism, most malware defenses target the payload execution phase. The payload may be an exploit payload or installed malware. These defenses can be categorized into several types discussed below.

#### 6.1 Sandboxing and Isolation

Various sandboxing techniques [13, 35, 45, 24, 49] have been discussed earlier in the paper. A central challenge is policy development: identifying a policy that effectively blocks attacks without unduly degrading functionality. Some techniques, such as model-carrying code [40], have been devised to ease application-specific policy development, but they require a level of trust in the software. If one suspects that the software could be truly malicious, a secure policy will likely preclude all access, causing the application to fail.

Full isolation is a more realistic alternative for potentially malicious software. By default, Android apps are fully isolated from each other, preventing one malicious app from compromising another. This approach is so popular that vendors have back-ported the idea to recent desktop operating systems (Windows 8 and Mac OS X). Unfortunately, full isolation means that no data can be shared. As a result, an untrusted application cannot be used to view or process user files created by another application. This difficulty can be solved using the concept of one-way isolation [22], which allows untrusted applications to read user files but not overwrite them. The idea of shadowing files was proposed in that work to permit untrusted applications to run safely without experiencing security failures.

In practice, full isolation proves to be too restrictive, so mobile operating systems like Android permit apps to communicate with each other or with system applications using well-defined interfaces. Unfortunately, once such interactions occur, security can no longer be guaranteed. If a benign process receives and processes a request or data from an untrusted process, it is entirely up to the benign process to protect itself from damage due to this interaction. It is in this context that information-flow-based techniques like Spif help: by tracking the provenance of input, Spif can either prevent a benign process from consuming the input or downgrade itself into a low-integrity process before consuming it.

#### 6.2 Information Flow Techniques

These techniques label every object and subject with an integrity (and/or confidentiality) label and globally track their propagation. The earliest works in this area date back to the 1970s and rely on centralized Information Flow Control (IFC), where the labels are global to the system. In contrast, some recent efforts have focused on decentralized IFC (DIFC) [50, 9, 19], which allows any principal to create new labels. This flexibility comes with the responsibility to make nontrivial changes to application and/or OS code. Since backward compatibility with existing code is a high priority for Spif, we have not pursued a DIFC model.

Several recent works [42, 25, 21, 44] have focused on making IFC work on contemporary operating systems, specifically Linux. Of these, PPI [42] specifically targeted the same problem as us, namely, integrity protection for desktop systems against malware and exploits. Unlike Spif, PPI relies on kernel modifications (implemented using LSM hooks) for label propagation and policy enforcement. While such an approach provides more flexibility and supports a wider range of policies, its downside is that it is difficult to port to other operating systems. In contrast, PIP [44] avoids OS changes and is hence most closely related to Spif. Like Spif, PIP repurposes multi-user protection for information-flow tracking. However, its design, targeted at Unix, necessarily differs from Spif, which targets Windows. Spif can take advantage of mechanisms specific to Windows, such as Access Control Lists (ACLs) and Windows Integrity Mechanism (WIM), to remove the need for helper processes or a separate display server. Moreover, Spif’s design provides a greater degree of portability across different OS versions and a higher level of application compatibility, having been applied to a much larger range of complex, feature-rich applications. Spif’s integration with the security zone in Windows also provides better end-to-end protection.

#### 6.3 Provenance

Data provenance has become an important consideration in many domains, including scientific computing, law, and healthcare. In these domains, provenance captures not only the origin of data ("where") but also how it was generated [6]. Securing data provenance [16] is an important concern in many domains. Some recent efforts have incorporated secure provenance tracking into operating systems, e.g., Linux [1].

Other works in security have focused on (security) applications of provenance. Reference [47] associates every network packet with a keystroke event. These keystroke events serve as provenance labels for a packet, enabling the detection of malware-generated network packets that lack these provenance labels. Reference [32] uses provenance-tracking to correlate malicious network traffic to the application that generated it. Spif combines the ideas of provenance and information flow tracking to protect system integrity against unknown malware.

### Conclusion

In this paper, we presented Spif, a comprehensive system for integrity protection on Windows based on system-wide provenance tracking. Unlike existing malware defenses, which are reactive, Spif is proactive and works against unknown and stealthy malware. We described the design of Spif, detailed its security features, and outlined features designed to preserve application usability. Our experimental results show that Spif imposes low performance overheads, almost negligible on many benchmarks. It works on many versions of Windows and is compatible with a wide range of feature-rich software, including all popular browsers and Office software, media players, and more. We evaluated it against several malware samples from the Exploit Database [34] and showed that it can stop a variety of highly stealthy malware.

We do not claim that our prototype is free of vulnerabilities or that it can stand up to targeted attacks. However, we believe that any such weaknesses are the result of limited resources expended on its implementation and are not fundamental to its design. Hardening it to withstand targeted, real-world malware attacks will require substantial additional engineering work. Nevertheless, we believe that Spif represents a promising new direction for principled malware defense. An open-source implementation of our system is available from http://seclab.cs.stonybrook.edu/download.

### References

[1] Bates, A., Tian, D. J., Butler, K. R., and Moyer, T. Trustworthy Whole-System Provenance for the Linux Kernel. In USENIX Security (2015).

[2] Biba, K. J. Integrity Considerations for Secure Computer Systems. In Technical Report ESD-TR-76-372, USAF Electronic Systems Division, Hanscom Air Force Base, Bedford, Massachusetts (1977).

[3] Brian Gorenc, J. S. Thinking outside the sandbox - Violating trust boundaries in uncommon ways. In BlackHat (2014).

[4] Brumley, D., and Song, D. Privtrans: Automatically Partitioning Programs for Privilege Separation. In USENIX Security (2004).

[5] BufferZone Security Ltd. BufferZone, http://bufferzonesecurity.com/.

[6] Buneman, P., Khanna, S., and Tan, W. C. Why and Where: A Characterization of Data Provenance. In ICDT (2001).

[7] Constantin, L. Researchers hack Internet Explorer 11 and Chrome at Mobile Pwn2Own. http://www.pcworld.com/article/2063560/researchers-hack-internet-explorer-11-and-chrome-at-mobile-pwn2own.html/.

[8] Dell. Dell Data Protection | Protected Workspace. http://www.dell.com/learn/us/en/04/videos~en/documents~data-protection-workspace.aspx.

[9] Efstathopoulos, P., Krohn, M., VanDeBogart, S., Frey, C., Ziegler, D., Kohler, E., Mazières, D., Kaashoek, F., and Morris, R. Labels and Event Processes in the Asbestos Operating System. In SOSP (2005).

[10] Falliere, N., Murchu, L., and Chien, E. W32. Stuxnet Dossier. White paper, Symantec Corp., Security Response (2011).

[11] Fisher, D. Sandbox Escape Bug in Adobe Reader Disclosed. http://threatpost.com/sandbox-escape-bug-in-adobe-reader-disclosed/109637.

[12] Fraser, T. LOMAC: Low Water-Mark Integrity Protection for COTS Environments. In S&P (2000).

[13] Goldberg, I., Wagner, D., Thomas, R., and Brewer, E. A. A Secure Environment for Untrusted Helper Applications (Confining the Wily Hacker). In USENIX Security (1996).

[14] Google Security Research. Windows Acrobat Reader 11 Sandbox Escape in MoveFileEx IPC Hook. https://code.google.com/p/google-security-research/issues/detail?id=103.

[15] Hasabnis, N., Misra, A., and Sekar, R. Lightweight Bounds Checking. In CGO (2012).

[16] Hasan, R., Sion, R., and Winslett, M. Introducing Secure Provenance: Problems and Challenges. In StorageSS (2007).

[17] jduck. CVE-2010-3338 Windows Escalate Task Scheduler XML Privilege Escalation | Rapid7. http://www.rapid7.com/db/modules/exploit/windows/local/ms10_092_schelevator.

[18] Katcher, J. Postmark: A New File System Benchmark. Technical Report TR3022, Network Appliance, 1997.

[24] Loscocco, P., and Smalley, S. Meeting Critical Security Objectives with Security-Enhanced Linux. In Ottawa Linux Symposium (2001).

[25] Mao, Z., Li, N., Chen, H., and Jiang, X. Combining Discretionary Policy with Mandatory Information Flow in Operating Systems. In TISSEC (2011).

[26] Microsoft. URL Security Zones (Windows) - MSDN - Microsoft. https://msdn.microsoft.com/en-us/library/ie/ms537021%28v=vs.85%29.aspx.

[27] Microsoft. What is Protected View? - Office Support. https://support.office.com/en-au/article/What-is-Protected-View-d6f09ac7-e6b9-4495-8e43-2bbcdbcb6653.

[28] Microsoft. What is the Windows Integrity Mechanism? https://msdn.microsoft.com/en-us/library/bb625957.aspx.

[29] Microsoft. Working with the AppInit DLLs registry value. http://support.microsoft.com/kb/197571.

[30] Microsoft Research. Detours. http://research.microsoft.com/en-us/projects/detours/.

[31] Mozilla. Buildbot/Talos/Tests. https://wiki.mozilla.org/Buildbot/Talos/Tests.

[32] Nadji, Y., Giffin, J., and Traynor, P. Automated Remote Repair for Mobile Malware. In ACSAC (2011).

[33] Nagarakatte, S., Zhao, J., Martin, M. M., and Zdancewic, S. SoftBound: Highly Compatible and Complete Spatial Memory Safety for C. In PLDI (2009).

[34] Offensive Security. Exploits Database, http://www.exploit-db.com/.

[35] Provos, N. Improving Host Security with System Call Policies. In USENIX Security (2003).

[36] Provos, N., Markus, F., and Peter, H. Preventing Privilege Escalation. In USENIX Security (2003).

[37] Rahul Kashyap, R. W. Application Sandboxes: A Pen-Tester’s Perspective. http://labs.bromium.com/2013/07/23/application-sandboxes-a-pen-testers-perspective/.

[38] Reis, C., and Gribble, S. D. Isolating Web Programs in Modern Browser Architectures. In EuroSys (2009).

[39] Sandboxie Holdings, LLC. Sandboxie, http://www.sandboxie.com/.

[40] Sekar, R., Venkatakrishnan, V., Basu, S., Bhatkar, S., and DuVarney, D. C. Model-Carrying Code: A Practical Approach for Safe Execution of Untrusted Applications. In SOSP (2003).

[41] Sun, W., Sekar, R., Liang, Z., and Venkatakrishnan, V. N. Expanding Malware Defense by Securing Software Installations. In DIMVA (2008).

[42] Sun, W., Sekar, R., Poothia, G., and Karandikar, T. Practical Proactive Integrity Preservation: A Basis for Malware Defense. In S&P (2008).

[43] Sze, W. K., Mital, B., and Sekar, R. Towards More Usable Information Flow Policies for Contemporary Operating Systems. In SACMAT (2014).

[44] Sze, W. K., and Sekar, R. A Portable User-Level Approach for System-wide Integrity Protection. In ACSAC (2013).

[45] Ubuntu. AppArmor. https://wiki.ubuntu.com/AppArmor/.

[46] Ward, S. iSIGHT discovers zero-day vulnerability CVE-2014-4114 used in Russian cyber-espionage campaign. http://www.isightpartners.com/2014/10/cve-2014-4114/.

[19] Krohn, M., Yip, A., Brodsky, M., Cliffer, N., Kaashoek, M. F., Kohler, E., and Morris, R. Information Flow Control for Standard OS Abstractions. In SOSP (2007).

[20] Li, H. CVE-2015-0016: Escaping the Internet Explorer Sandbox. http://blog.trendmicro.com/trendlabs-security-intelligence/cve-2015-0016-escaping-the-internet-explorer-sandbox.

[21] Li, N., Mao, Z., and Chen, H. Usable Mandatory Integrity Protection for Operating Systems. In S&P (2007).

[22] Liang, Z., Sun, W., Venkatakrishnan, V. N., and Sekar, R. Alcatraz: An Isolated Environment for Experimenting with Untrusted Software. In TISSEC (2009).

[23] Liang, Z., Venkatakrishnan, V., and Sekar, R. Isolated Program Execution: An Application Transparent Approach for Executing Untrusted Programs. In ACSAC (2003).

[47] Xu, K., Xiong, H., Wu, C., Stefan, D., and Yao, D. Data-Provenance Verification for Secure Hosts. In TDSC (2012).

[48] Xu, W., DuVarney, D. C., and Sekar, R. An Efficient and Backwards-Compatible Transformation to Ensure Memory Safety of C Programs. In FSE (2004).

[49] Yee, B., Sehr, D., Dardyk, G., Chen, J. B., Muth, R., Orm, T., Okasaka, S., Narula, N., Fullagar, N., and Inc, G. Native Client: A Sandbox for Portable, Untrusted x86 Native Code. In S&P (2009).

[50] Zeldovich, N., Boyd-Wickizer, S., Kohler, E., and Mazières, D. Making Information Flow Explicit in HiStar. In OSDI (2006).