# An Empirical Evaluation of Relay Selection in Tor

**Authors:**
- Chris Wacek, Georgetown University
- Henry Tan, Georgetown University
- Kevin S. Bauer, University of Waterloo
- Micah Sherr, Georgetown University

## Abstract
Tor is the most widely used low-latency anonymity network today, but it faces several performance issues that hinder its broader adoption. One significant factor contributing to Tor's slow performance is the method by which clients select relays. Recent proposals aim to modify Tor’s relay selection algorithm to improve bandwidth, latency, and anonymity. This paper evaluates the trade-offs between anonymity and performance for these proposed relay selection techniques using highly accurate topological models. These models capture the actual Tor network's autonomous system (AS) boundaries, points-of-presence, inter-relay latencies, and relay performance characteristics.

Using realistic network models, we conduct a whole-network evaluation with varying traffic workloads to understand the potential performance benefits of a comprehensive set of relay selection proposals from the Tor literature. We also quantify the anonymity properties of each approach using our network model in combination with simulations fueled by data from the live Tor network.

## 1. Introduction
The Tor [11] anonymity network is used by hundreds of thousands of daily users to enhance the privacy of their communications [25]. Recently, significant efforts have been made to improve Tor’s performance, which, as noted by the network's operators [12], suffers from high congestion and latency. These efforts have focused on improving Tor’s circuit processing [3, 46], transport mechanisms [28, 39], relay recruitment [22, 31], and relay selection [2, 42, 43, 49].

Tor exhibits high latencies partly due to the way clients select relays for their anonymous circuits. For example, a large fraction of Tor’s volunteer-operated relays are located in the United States or Germany [30, 47], often requiring a typical client’s traffic to make at least one transoceanic trip.

Existing work has proposed methods to create lower latency anonymous circuits by carefully selecting relays to reduce link latencies [41, 42] or the geographic distance covered by anonymous paths [2]. Other work suggests that Tor clients should be able to tune relay selection to achieve greater performance (by favoring high-bandwidth routers) or greater anonymity (by selecting more uniformly at random) [43]. Additional work aims to decrease latency by avoiding circuits with high congestion levels [49].

### The Need for Realistic Tor Network Modeling
Despite the growing body of research on path selection techniques for Tor, none of the existing proposals have been evaluated under conditions that accurately reflect those of a live anonymity network. For instance, studies [43, 46] have shown that performance gains achieved in modeling and simulation do not translate to real-world conditions [21, 32]. While a particular algorithm may show advantageous effects when adopted by a small number of clients and/or relays, it may have unexpected negative consequences when adopted en masse.

There is thus a need to move beyond considering only local effects ("if I adopt this algorithm, will it improve my performance and anonymity?") and consider the potential impacts on the entire network ("what are the effects if a large number of clients/relays adopts this strategy?"). In short, we need new methods and tools that (1) more realistically model the Tor network and (2) enable more comprehensive performance and anonymity analyses.

### Whole-Network Tor Experimentation
Through whole-network experimentation using a state-of-the-art Tor emulation framework with highly realistic network models, this paper aims to better understand the potential performance benefits and anonymity risks of path selection algorithms.

The primary contribution of this paper is a framework for measuring performance and anonymity under realistic conditions (Section 3). Our experimental methodology uses the recently proposed ExperimenTor [4] emulator, running native Tor binaries on a synthetic network topology. To maximize realism, we construct topologies that capture Tor’s bandwidth distribution, configuration distribution, geographic diversity (both of relays and the most common clients and destinations), AS and point-of-presence paths, and pairwise latencies. The ability to execute unmodified Tor code and operate on (emulated) networks that share many characteristics with the live Tor network allows us to more accurately predict how a proposed relay selection strategy will behave on the live network. Importantly, our framework allows us to measure multidimensional aspects of both performance (i.e., throughput, latency, time-to-first-byte) and anonymity (i.e., frequency of relay selection, AS path diversity).

Using this framework, we evaluate a set of recently proposed relay selection techniques that we have integrated into Tor (Sections 4 through 6). Our findings indicate that several previously proposed methods are unlikely to produce desirable performance if widely adopted. We also evaluate hybrid relay selection techniques that combine aspects of existing approaches. Our results show that a hybrid strategy in which selection is biased in favor of bandwidth and away from congested circuits provides the best performance.

### Contributions
In summary, this work offers the following contributions to the field of anonymous communications:
- **Methodology for Modeling the Tor Network:** We introduce a methodology for modeling the Tor network and present our resulting Tor network model that includes the real Tor network’s AS boundaries, link latencies, bandwidths, and relay configurations. We instantiate this model within a state-of-the-art Tor network emulation platform to realize highly realistic Tor network experimentation.
- **Comprehensive Performance Analysis:** We implement a comprehensive set of relay selection algorithms from the Tor literature in the Tor source code and conduct an exhaustive performance analysis to identify which path selection algorithm offers the best performance under dynamic traffic loads.
- **Anonymity Implications:** We simulate each router selection algorithm and use real data from the live Tor network to evaluate the anonymity implications of each respective approach.
- **Best Performing Hybrid Strategy:** We find that a combination of Tor’s bandwidth-weighted relay selection and techniques that avoid congested circuits results in the greatest improvement in throughput and latency relative to Tor’s current design. Augmenting Tor with virtual-coordinate-based selection also suggests promising performance improvements. Furthermore, we find that neither approach significantly impacts anonymity.

## 2. Background
### Relay Selection in Tor
Tor is the third-generation onion routing network and provides anonymous communication to TCP-based applications [11]. Tor clients select a source-routed circuit of precisely three Tor routers (sometimes called relays) by querying any one of several authoritative directories. After constructing a circuit, clients forward traffic through their circuits using a layered encryption scheme based on onion routing [17]. Upon receipt of a fixed-size unit of transmission (a cell), each router along a circuit adds or removes a layer of encryption, depending on the cell’s direction.

While early onion routing systems initially specified that clients should select routers uniformly at random [45], it became necessary to balance Tor’s traffic load over the available router bandwidth as the anonymity network’s popularity increased. Tor performs load balancing by weighting router selection in proportion to each router’s perceived bandwidth capacity. Tor currently utilizes a set of trusted Bandwidth Authorities responsible for actively probing the Tor routers and estimating each router’s capacity [36]. Additional constraints are placed on router selection, including the use of entry guards [35] for the first hop to defend against the predecessor attack [50] and exit policies that specify the destination addresses and ports allowed by an exit router’s operator. Recent work has also suggested selection algorithms that incorporate users’ trust over various parts of the network [23].

Despite Tor’s popularity with several hundred thousand daily users [19], one of the primary roadblocks to wide-scale Tor adoption continues to be its poor performance. Prior work [12] has examined several factors contributing to Tor’s performance problems, including undesirable inter-circuit interference due to TCP’s congestion control [39], suboptimal flow control at the application layer [3], and imperfect load balancing, which causes lower bandwidth routers to handle too much traffic.

Snader and Borisov offer refinements to Tor’s router selection policy that allow senders to tune the performance of their anonymous paths by defining the degree to which relay selection is biased in favor of bandwidth [43]. However, follow-up work by Murdoch and Watson found that Tor’s default router selection algorithm offers a good trade-off between performance and anonymity [32].

Other work has noted that Tor’s use of three often geographically distributed routers introduces another source of high latency due to cell propagation over circuitous routes. Latency-informed router selection [42] using virtual coordinate systems [8, 41] and minimal geographical distances between Tor routers [2] have been proposed as methods to optimize Tor circuits for low latency. However, no whole-network evaluation of either proposal has been performed, making it unclear how each path selection algorithm affects performance when deployed at scale.

In this work, we seek to provide a unifying framework for reasoning about the many different methods for router selection that have been proposed in the literature and an understanding of what techniques are effective.

### Tor Evaluation and Modeling
A large volume of existing work attempts to approximate the live network’s behavior, often as a means to evaluate a refinement to the network’s protocols or configuration. At a high level, efforts at modeling Tor can roughly be organized into three categories: analytic, simulation, and emulation.

Analytic methods [5, 32] allow researchers to evaluate refinements to Tor’s protocols. However, accurately and analytically modeling complex network effects (e.g., congestion, jitter, etc.) remains an open problem. Indeed, existing analytic approaches often ignore network effects entirely.

There are also several available Tor simulators [22, 32–34]. As with the analytic methods, existing simulators fail to fully capture Tor’s complexities. (To highlight this complexity, we note that recent versions of Tor have more than 200 configuration options.) In general, it is difficult to assess how well simulated behavior predicts the behavior of Tor in an actual deployment.

More recently, Moore et al. [31] and AlSabah et al. [3] use the ExperimenTor emulator [4] to examine alternative rate limiting and congestion/flow control policies for Tor. However, their topologies do not model the live Tor network’s latency, geography, or AS distributions. Similarly, Jansen and Hopper [21] introduce the Shadow framework for executing (slightly modified) Tor code on a synthetic network. They sample the live network’s bandwidth distribution but configure geographic locations and latencies only according to a sample of several PlanetLab nodes.

Jansen et al. [20] extend their model to construct a network graph that clusters hosts into geographical regions, assigns upstream and downstream bandwidths and loss rates to hosts using measurements from Ookla Net Index, and utilizes link latency and jitter data obtained from iPlane [27]. An algorithm for obtaining a “best fit” approximation of the real Tor network’s relay bandwidth distribution is used to downsample and produce experimental Tor networks with 50 and 100 relays. One important limitation of this work, however, is that it does not attempt to model the Tor network at the AS-level; as such, it cannot be used to conduct an anonymity and security analysis of an AS-level adversary.

To the best of our knowledge, ours is the first work that attempts to model the distributions of latencies, bandwidths, relay types, AS assignments, and geographies found on the live Tor network. We apply our models both under simulation (for scalability) and emulation (for realism).

## 3. Modeling the Tor Network
One of the difficulties inherent in testing new protocols and technologies on the Tor network is the network’s size: Tor has over 2500 relays and nearly 1000 bridges distributed globally. Certain types of research either cannot or should not be tested on the live Tor network because they either require large-scale modifications to core protocols (and hence are impractical to implement globally) or because they could unwittingly compromise the anonymity of people who depend upon the network for their safety [44].

Technologies that make changes to the core Tor network therefore require an experimental platform that can emulate or simulate the characteristics of the live Tor network. There are several critical characteristics that should be considered when evaluating the performance and anonymity of an experimental technology: the latency between Tor relays, the bandwidth of individual Tor relays, and the distribution of clients, relays, and destinations, both across geographies and autonomous systems (ASes). In what follows, we describe how we construct (Section 3.1) and verify (Section 3.2) scaled-down models of Tor that faithfully represent the live network’s distributions of latencies, bandwidths, geographies, and AS memberships.

### 3.1 Topology Construction
Our goal is to create a reduced map of the Internet that includes the network locations of Tor relays, clients, and destinations, and supplies latency measurements between hosts.

Several methods have been proposed for estimating the latencies between arbitrary Internet end-hosts, notably IDMaps [15], the King method [18], and iPlane [26, 27]. We evaluated the feasibility of these existing options and concluded that they were insufficient for our purposes. IDMaps estimates latencies between arbitrary hosts by performing triangulation from strategically placed Tracer nodes; however, no such service is currently in place on the Internet. The King method relies on recursive DNS queries, which the majority of DNS servers currently disable. iPlane has helpfully built and maintained a map of the Internet based on autonomous system data. Using iPlane data, we were able to construct AS-level network topologies, but this unfortunately did not provide sufficiently accurate latencies: we found that in many cases, real-world latencies between ASes are often small, while those across ASes can be relatively large—the iPlane data did not capture this characteristic, resulting in unrealistically small latencies within ASes. We additionally examined the iPlane “point of presence” data to construct our own AS graphs but were unable to build a suitably connected graph using their data.

**Accurately modeling the Tor network.** We desire a “scale” model of the actual Tor network that accurately reflects the network’s bandwidths and latencies, as well as the locations of its clients, destinations, and relays. Since no such model of the Tor network exists, we constructed a compact network graph suitable for our emulation experiments (see Section 6) using data from multiple available datasets. We constructed our model of the Tor network at the granularity of a point-of-presence (PoP), where a PoP is roughly intended to represent an access point on the Internet. We built our model of the Tor network as follows:

1. **Latency normalization.** To construct our model, we utilize traceroute data from CAIDA [7]. CAIDA collects and makes available traceroute measurements to most of the Internet’s /24 prefixes from geographically and topologically diverse vantage points. We normalize the traceroutes by removing all negative latency hops; these occur when the traceroute data indicate that the latency required for reaching a node b in a path sequence a → b → c is greater than that required to reach node c in the same path. We normalize such occurrences by setting the time required to reach b to be the same as the time required to reach c.