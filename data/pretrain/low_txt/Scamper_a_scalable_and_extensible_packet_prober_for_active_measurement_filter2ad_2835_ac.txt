### Beyond 1000 PPS: Measurement Etiquette and Considerations

To adhere to measurement etiquette, the experiment did not exceed 1000 packets per second (PPS), as most probes in this setup solicit responses from intermediate routers. The machine was otherwise idle during the tests.

### CPU Consumption

All tests consumed nearly the same total amount of CPU time, ranging between 25.3 and 26.9 seconds, regardless of the PPS rate. This consistency can be attributed to the use of efficient data structures with O(log n) scaling and the sharing of sockets among tasks, which reduces the number of sockets that need to be monitored. The total CPU time was highest for tests with the lowest PPS rates because the scamper process accounted for more wall clock and system CPU time. Figure 2 illustrates the maximum CPU usage observed for scamper when configured with different PPS rates. CPU requirements increase linearly with probing speed. The experiment was well within the capabilities of our Pentium 3 800 MHz system, requiring a peak of 8.1% of the CPU at 1000 PPS.

### Memory Consumption

To meet a specified PPS rate, scamper adds new tasks as necessary, each requiring additional memory to maintain state. Figure 2 also shows the maximum resident set size (RSS) reported by the operating system for each test. At 100 PPS, scamper required 1.9 MB of memory at peak, and this requirement increased linearly to 6.2 MB at 1000 PPS. The memory and CPU requirements for running scamper are modest.

### Effect on Data Collected

Summary statistics for the data collected were almost identical across different PPS rates:
- 5.2% of destinations were reachable.
- 10.0% received an ICMP destination unreachable code.
- 5.9% halted due to apparent forwarding loops.
- 78.9% halted after three consecutive unresponsive hops.

The number of packets sent for all data sets ranged between 232k and 234k, and the number of IP-level links ranged between 29.2k and 29.3k. Figure 3 plots the time required to complete each traceroute for selected PPS values; the lines for other PPS rates fall between the plotted values. For this workload, the distribution of time required to complete tasks was almost identical for all PPS rates. However, 10% of tasks took up to five seconds longer to complete in some experiments, likely due to the time traceroute waits before timing out and sending another probe. There is no correlation between the probing rate and these variations; network conditions at the time of the sample are believed to be the cause.

### Using Scamper

As described in Section 3, scamper can be run as a daemon and controlled using a Unix domain socket or a TCP socket bound to the loopback interface. For example, a researcher who wishes to dynamically collect data about router-level connectivity towards a set of destinations would need to:
- Collect the interface graph using MDA traceroute.
- Determine the utility of probing each interface with TCP, ICMP, and UDP probes to identify which probe types can elicit responses with incrementing IP-ID values.
- Collapse the graph using an alias resolution technique such as RadarGun.

The driver program the researcher would write to support this collection follows from the data requirements. The driver is responsible for:
- Remembering the list of targets to probe with MDA traceroute.
- Maintaining the list of interfaces to probe with ping.
- Tracking the utility of each ping method for soliciting an incrementing IP-ID to avoid repeated measurements.

While there are targets to probe, the driver communicates the measurement tasks to scamper. As each measurement completes, scamper sends the results back to the driver via the control socket. The data arrives in binary form, so the driver can use a socketpair to write the binary data to one end and read the decoded measurements from the other using the provided API. The driver can also record the binary data to disk for archiving. When the list of targets is empty and all results are back from scamper, the final step is to provide scamper with a RadarGun probing specification containing the interfaces to probe and the appropriate probe method (ICMP, UDP, or TCP). After data collection, the final step is to process the collected data to infer which interfaces are aliases and produce the router-level graph.

### Experiences

#### Identifying IPv6 Network Problems in the Dual-Stack World

The first use of scamper was in a 2004 study comparing the forward paths of IPv4 and IPv6 addresses believed to belong to the same host [17]. The goal was to find IPv6 paths that performed poorly compared to their IPv4 counterparts and to provide operators with suggestions for improving IPv6 routing. The work used scamper's one-shot measurement functionality, where a list of IPv4 and IPv6 addresses was provided to scamper, which probed them in parallel until the list was completed. Key findings included:
- Only a small proportion of targets had much larger delays with IPv6 than with IPv4.
- The impact of IPv6 tunnels, inferred by changes in Path-MTU, depends heavily on the upstream connectivity of the vantage point.

With the IANA pool of remaining IPv4 addresses rapidly depleting, it is crucial to identify and address the worst indirect IPv6 routes. Future work will focus on automating data collection and procedures to communicate problems to operators.

#### CAIDA’s Macroscopic Internet Topology Project

Scamper is used in CAIDA’s macroscopic Internet topology discovery project to collect forward-IP path data continuously since September 2007. As of August 2010, there are 48 vantage points distributed globally, divided into three teams. Each team collectively probes a randomly generated address in all /24 prefixes routed on the Internet. Work is coordinated using the Marinda tuple-space system [9]. An external measurement process monitors scamper’s progress; when a unit of work is complete, a new set of random IP addresses is written to a file and passed to scamper via its control socket. Scamper is configured to probe at 100 PPS; a team of 12 vantage points requires approximately two and a half days to probe all routed /24 prefixes. The collected data is available to researchers as the IPv4 Routed /24 Topology dataset [27]. Significant work remains to translate the data into a router-level graph of the Internet using alias resolution and to develop techniques to correctly filter AS-level links.

#### IPv6 AS-Core Poster

One of CAIDA’s widely recognized visualizations is the IPv4 AS core poster, showing the geographic connectivity and importance of ASes. In 2008, CAIDA had few vantage points with IPv6 connectivity, so volunteers were solicited on the NANOG mailing list. Each volunteer downloaded the scamper source code, compiled it, and ran scamper using a supplied address list. Contributors from 53 different cities, running various operating systems, supplied data, demonstrating scamper’s portability and ease of use. The data was used to support a geographic comparison of the IPv4 and IPv6 AS-level graphs [28].

#### Traceroute Probe Method Comparison

In 2008, we compared the utility of five different methods and found that ICMP-Paris traceroute reaches the most destinations and infers the most AS links when destinations are chosen randomly [29]. To collect the required data, we wrote a driver that connected to a running scamper process and issued a series of traceroute commands for each destination. The next method to use was chosen randomly by the driver, and it waited at least five seconds between traceroutes to any single destination. Using scamper’s support for external drivers allowed us to focus on data collection and analysis rather than implementing complex probing loops and algorithms.

#### Quantifying the Pitfalls of Traceroute

In 2009, researchers at Harbin Institute of Technology and UCLA examined the limitations of using traceroute data and corresponding longest BGP prefix matches to infer AS connectivity [30]. This required collecting traceroutes from a vantage point where a BGP feed was also available. CAIDA’s Ark topology project has three such vantage points; a fourth was created at UCLA by using scamper to collect traceroute data from their campus network, where they could also procure a BGP feed.

### Related Work

Spring et al. developed scriptroute to allow portable implementations of measurement techniques on a public general-purpose measurement facility [6]. Both scriptroute and scamper include a portability layer, allowing researchers to focus on the logic of their techniques and providing implementations of common measurement methods. Scriptroute offers a distributed set of machines for running experiments, while scamper focuses on building a parallelized packet-prober suitable for both measurement infrastructure and standalone contexts.

fping [31], hping [32], and nmap [33] offer portable and parallelized implementations of ping, traceroute, and network security tests, respectively, enabling rapid network testing. Scamper is designed with Internet researchers in mind, providing an extensible file format to record detailed measurements and offering flexibility in the control of the measurement process, making it suitable for Internet measurement infrastructure.

### Conclusion

Internet researchers face many challenges, including overcoming technical limitations of operating systems, recording results and data for sound analysis, parallelizing their implementation to scale to the size of the Internet, and finding enough vantage points to ensure representative results. Scamper provides a flexible and reusable packet-probing architecture, allowing researchers to focus on scientific experiments rather than building accurate and scalable instrumentation. Scamper’s architecture has proven useful in community-oriented network measurement infrastructure, as it is currently used in CAIDA’s Archipelago system [9]. The source code for scamper is freely available at http://www.wand.net.nz/scamper/.

### Acknowledgements

We thank WIDE and CAIDA for funding and supporting the initial development of scamper. This work is currently supported by the New Zealand Foundation for Research Science and Technology (FRST) contract UOWX0705.

### References

[1] David Mills. Internet delay experiments. RFC 889, December 1983.

[2] V. Paxson, J. Mahdavi, A. Adams, and M. Mathis. An architecture for large-scale Internet measurement. IEEE Communications Magazine, 36(8):48–54, 1998.

[3] Sunil Kalidindi and Matthew J. Zekauskas. Surveyor: An infrastructure for Internet performance measurements. In INET'99, San Jose, CA, June 1999.

[4] Tony McGregor and Hans-Werner Braun. Balancing cost and utility in active monitoring: The AMP example. In INET 2000, Yokohama, Japan, July 2000.

[5] Bradley Huﬀaker, Daniel Plummer, David Moore, and k claﬀy. Topology discovery by active probing. In SAINT 2002, pages 90–96, Nara City, Japan, January 2002.

[6] Neil Spring, David Wetherall, and Tom Anderson. Scriptroute: A public Internet measurement facility. In USITS ’03, pages 225–238, Seattle, WA, March 2003.

[7] Yavul Shavitt and Eran Shir. DIMES: let the Internet measure itself. Computer Communication Review, 35(5):71–74, 2005.

[8] Harsha Madhyastha, Tomas Isdal, Michael Piatek, Colin Dixon, Thomas Anderson, Arvind Krishnamurthy, and Arun Venkataramani. iPlane: An information plane for distributed services. In OSDI '06, pages 367–380, Seattle, WA, November 2006.

[9] Young Hyun. Archipelago measurement infrastructure. http://www.caida.org/projects/ark/.

[10] kc claﬀy, Mark Crovella, Timur Friedman, Colleen Shannon, and Neil Spring. Community-oriented network measurement infrastructure (CONMI) workshop report. ACM/SIGCOMM Computer Communication Review, 36(2):41–48, April 2006.

[11] Van Jacobson. traceroute. ftp://ftp.ee.lbl.gov/traceroute.tar.gz.

[12] Brice Augustin, Xavier Cuvellier, Benjamin Orgogozo, Fabien Viger, Timur Friedman, Matthieu Latapy, Clémence Magnien, and Renata Teixeira. Avoiding traceroute anomalies with Paris traceroute. In IMC '06, pages 153–158, Rio de Janeiro, Brazil, October 2006.

[13] Mark Allman and Vern Paxson. A reactive measurement framework. In PAM 2008, pages 92–101, Cleveland, OH, April 2008.

[14] Young Hyun. rb-wartslib: ruby warts library. http://rb-wartslib.rubyforge.org/.

[15] Stefan Savage. Sting: a TCP-based network measurement tool. In USITS '99, pages 71–79, Boulder, CO, October 1999.

[16] A. Medina, M. Allman, and S. Floyd. Measuring the evolution of transport protocols in the Internet. Computer Communication Review, 35(2):37–52, April 2005.

[17] Kenjiro Cho, Matthew Luckie, and Bradley Huﬀaker. Identifying IPv6 network problems in the dual-stack world. In ACM SIGCOMM workshop on Network Troubleshooting, pages 283–288, Portland, OR, August 2004.

[18] Matthew Luckie, Kenjiro Cho, and Bill Owens. Inferring and debugging path MTU discovery failures.