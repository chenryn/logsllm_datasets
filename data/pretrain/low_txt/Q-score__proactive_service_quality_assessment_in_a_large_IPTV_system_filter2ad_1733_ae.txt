### Summary and Review Documentation for "Q-score: Proactive Service Quality Assessment in a Large IPTV System"

#### Authors:
- H. Song
- Z. Ge
- A. Mahimkar
- J. Wang
- J. Yates
- Y. Zhang
- A. Basso
- M. Chen

**Note:** The authors of this paper opted out of this year’s reviewing experiment. As a result, the final version of this paper is not accompanied by the reviews that the paper received during the reviewing process.

---

## 1. Introduction

In this paper, we introduce Q-score, a novel framework for proactive assessment of user-perceived service quality in a large operational IPTV network. By associating coarse-grained network Key Performance Indicators (KPIs) with imperfect user feedback, Q-score generates a single score that represents the user-perceived Quality of Experience (QoE). 

### 2. Methodology

#### 2.1 Data Collection and Preprocessing
- **Network Events (bi):** Network events are captured through KPIs.
- **User Feedback (ci):** User feedback is collected through customer reports.
- **Time Gap (δ):** The default time gap between a network event (si + δ) and user feedback (ui) is set to 0 hours, i.e., ui = si + δ.
- **Skipping Interval (Δ):** An additional skipping interval Δ is added to the equation, making it ui = si + δ + Δ.

#### 2.2 Q-score Generation
- **Regression Analysis:** The regression model is used to predict user feedback based on network events.
- **False Positive Rate (FPR) and False Negative Rate (FNR):** The FPR-FNR trade-off is analyzed as Δ increases.

### 3. Experimental Results

#### 3.1 Impact of Skipping Interval (Δ)
- **Figure 9:** Shows the FPR-FNR trade-off for different skipping intervals ranging from 0 to 36 hours.
- **Observations:** As Δ increases, the FPR-FNR trade-off worsens. A feasible lead time of 9 hours is identified, which maintains an FPR of 0.1% while increasing FNR from 30% to 40%.

#### 3.2 Spatial Distribution of User Feedback
- **Figure 10:** Illustrates the normalized amount of user feedback over different spatial locations (COs) and times.
- **Observations:** High user feedback is localized to specific COs and changes over time, indicating temporal and local issues rather than permanent or global ones.

#### 3.3 Leveraging Q-score for Workforce Dimensioning
- **Figure 11:** Compares the trend of per-CO Q-scores and user feedback for COs with high, moderate, and low levels of customer feedback.
- **Observations:**
  - For COs with high feedback, the Pearson correlation coefficient (R) is 0.8797.
  - For COs with moderate feedback, R is 0.7478.
  - For COs with low feedback, R is 0.5011.
- **Conclusion:** Q-scores, when aggregated, closely follow the trend of user feedback, allowing for proactive workforce allocation.

### 4. Related Work

#### 4.1 Quality of Experience (QoE) Assessment
- **Controlled Performance Assessment:** Traditional methods include controlled lab environments, code analysis, protocol analysis, and testbed tests.
- **Video Quality Assessment:** Subjective evaluation (MOS) and objective metrics (PSNR, ITU standards) are discussed. Our method uses customer trouble tickets as a proxy for user feedback.

#### 4.2 Reactive Performance Diagnosis
- **Techniques:** Bayesian networks, graph analysis, and statistical correlations are widely used.
- **Systems:** NICE, Giza, Mercury, and others focus on detecting and troubleshooting chronic network conditions.
- **Comparison:** Our work is more proactive, using network performance indicators to construct QoE scores, offering rapid notification and a lead time before customer reports.

### 5. Conclusion

Q-score is a novel framework for proactive assessment of user-perceived service quality in a large operational IPTV network. It accurately predicts 60% of service problems with only a 0.1% false positive rate. Q-score can be applied to various scenarios, including identifying relevant KPIs, alerting bad QoE early, and pre-allocating customer care workforce to affected areas. Future work includes applying Q-score to other network services like VoIP and mobile networks.

### 6. References

[1] Methods for subjective determination of transmission quality. ITU-T Rec. P.800, 1998.
[2] One-way transmission time. ITU-T Rec. G.114, 2003.
[3] Objective perceptual multimedia video quality measurement in the presence of a full reference. ITU-T Rec. J.247, 2008.
[4] Perceptual audiovisual quality measurement techniques for multimedia services over digital cable television networks in the presence of a reduced bandwidth reference. ITU-T Rec. J.246, 2008.
[5] R. Abreu, A. G. 0002, P. Zoeteweij, and A. J. C. van Gemund. Automatic software fault localization using generic program invariants. In SAC, 2008.
[6] R. Abreu, P. Zoeteweij, and A. J. C. van Gemund. Spectrum-based multiple fault localization. In ASE, 2009.
[7] P. Bahl, R. Chandra, A. Greenberg, S. Kandula, D. A. Maltz, and M. Zhang. Towards highly reliable enterprise network services via inference of multi-level dependencies. In Sigcomm, 2007.
[8] L. Breslau, D. Estrin, K. Fall, S. Floyd, J. Heidemann, A. Helmy, P. Huang, S. McCanne, K. Varadhan, Y. Xu, and H. Yu. Advances in network simulation. IEEE Computer, 33(5), 2000.
[9] S. Chatterjee and A. S. Hadi. Influential observations, high leverage points, and outliers in linear regression. Statistical Science, Vol. 1:379–416, 1986.
[10] I. Cohen, J. S. Chase, M. Goldszmidt, T. Kelly, and J. Symons. Correlating instrumentation data to system states: A building block for automated diagnosis and control. In OSDI, 2004.
[11] A. E. Hoerl and R. W. Kennard. Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, Vol. 12, No. 1:55–67, 1970.
[12] G. Holzmann. Design and Validation of Computer Protocols. Prentice-Hall, 1991.
[13] Y. Jin, N. G. Duffield, A. Gerber, P. Haffner, S. Sen, and Z.-L. Zhang. Nevermind, the problem is already fixed: proactively detecting and troubleshooting customer DSL problems. In CoNEXT, page 7, 2010.
[14] S. Kandula, D. Katabi, and J.-P. Vasseur. Shrink: A tool for failure diagnosis in IP networks. In MineNet, 2005.
[15] S. Kandula, R. Mahajan, P. Verkaik, S. Agarwal, J. Padhye, and P. Bahl. Detailed diagnosis in enterprise networks. In ACM SIGCOMM, 2009.
[16] R. R. Kompella, J. Yates, A. Greenberg, and A. C. Snoeren. IP fault localization via risk modeling. In NSDI, 2005.
[17] T.-L. Lin, S. Kanumuri, Y. Zhi, D. Poole, P. Cosman, and A. R. Reibman. A versatile model for packet loss visibility and its application in packet prioritization. IEEE Transactions on Image Processing, to appear, 2010.
[18] A. Mahimkar, Z. Ge, A. Shaikh, J. Wang, J. Yates, Y. Zhang, and Q. Zhao. Towards automated performance diagnosis in a large IPTV network. In ACM SIGCOMM, 2009.
[19] A. Mahimkar, H. H. Song, Z. Ge, A. Shaikh, J. Wang, J. Yates, Y. Zhang, and J. Emmons. Detecting the performance impact of upgrades in large operational networks. In ACM SIGCOMM, 2010.
[20] A. Mahimkar, J. Yates, Y. Zhang, A. Shaikh, J. Wang, Z. Ge, and C. T. Ee. Troubleshooting chronic conditions in large IP networks. In ACM CoNEXT, 2008.
[21] J. S. Moore and M. Kaufmann. Some key research problems in automated theorem proving for hardware and software verification. In RACSAM, 2004.
[22] Perceptual evaluation of video quality. 2011. http://www.pevq.org.
[23] M. Pinson and S. Wolf. Comparing subjective video quality testing methodologies. In SPIE Video Communications and Image Processing Conference, pages 8–11, 2003.
[24] T. Qiu, J. Feng, Z. Ge, J. Wang, J. Xu, and J. Yates. Listen to me if you can: Tracking user experience of mobile network on social media. In IMC, 2010.
[25] K. Shen, C. Stewart, C. Li, and X. Li. Reference-driven performance anomaly identification. In SIGMETRICS, 2009.
[26] M. Steinder and A. Sethi. Increasing robustness of fault localization through analysis of lost, spurious, and positive symptoms. In Infocom, 2002.
[27] S. Tao, J. Apostolopoulos, and R. Guérin. Real-time monitoring of video quality in IP networks. In Proceedings of the international workshop on Network and operating systems support for digital audio and video, NOSSDAV ’05, pages 129–134, New York, NY, USA, 2005. ACM.
[28] S. Tao, J. Apostolopoulos, and R. Guérin. Real-time monitoring of video quality in IP networks. IEEE/ACM Trans. Netw., 16:1052–1065, October 2008.
[29] M. Tariq, A. Zeitoun, V. Valancius, N. Feamster, and M. Ammar. Answering what-if deployment and configuration questions with WISE. In SIGCOMM, 2008.

---