# Fraud De-Anonymization for Fun and Profit

**Authors:**
- Nestor Hernandez
- Mizanur Rahman
- Ruben Recabarren
- Bogdan Carbunar

**Affiliations:**
- Florida International University (FIU), Miami, USA

**Contact:**
- PI:EMAIL (for all authors)

## Abstract
The persistence of search rank fraud in online peer-opinion systems, facilitated by crowdsourcing sites and specialized fraud workers, highlights the inefficiency of current fraud detection and filtering methods. We introduce a fraud de-anonymization approach to disincentivize such fraudulent activities by attributing user accounts flagged by fraud detection algorithms to the human workers who control them. We model this problem as a maximum likelihood estimation and propose UODA, an unconstrained optimization solution. Additionally, we develop a graph-based deep learning approach to predict ownership of account pairs by the same fraudster, which is used to build discriminative fraud de-anonymization (DDA) and pseudonymous fraudster discovery (PFD) algorithms.

To address the lack of ground truth fraud data and its negative impacts on online systems, we propose the first cheating-resistant fraud de-anonymization validation protocol, transforming human fraud workers into performance evaluation oracles. In a user study with 16 human fraud workers, UODA achieved a precision of 91%. Using ground truth data from 23 other fraud workers, our co-ownership predictor outperformed a state-of-the-art competitor, enabling DDA and PFD to discover tens of new fraud workers and attribute thousands of suspicious user accounts to existing and newly discovered fraudsters.

## CCS Concepts
- **Security and Privacy:** Social network security and privacy; Social aspects of security and privacy.
- **Information Systems:** Incentive schemes.

## Keywords
- Fraud De-Anonymization
- Search Rank Fraud
- Crowdturfing
- Fake Review
- Opinion Spam
- Sybil Attack
- App Store Optimization

## 1. Introduction
Popular online service providers rely on user feedback to rank products and content. Unfortunately, many review-based platforms (e.g., Google Play, TripAdvisor, Amazon, Twitter) are targets of undisclosed and deceptive marketing practices where product developers engage in fake endorsements to boost their products or demote competitors. Black hat crowdsourcing, or crowdturfing, offers an economically viable opportunity for developers to hire specialized workers who spam for profit.

This type of propaganda undermines the trustworthiness and quality of online services, and users can suffer from bait-and-switch schemes. Major online peer-opinion services aim to detect and remove fake reviews resulting from hidden endorsements, which are unlawful according to FTC regulations. Significant academic work has focused on binary classification of reviews as fake or honest and reviewers as fraudulent (Sybil) or genuine. However, these solutions are ineffective in preventing fraud and their accuracy is difficult to evaluate due to the challenge of collecting ground truth fraud data.

Services like Yelp acknowledge this validation problem by not removing but making suspected fake reviews harder to access, and moving reviews between fake and honest classes based on subsequent iterations of their detection algorithms. Academic work has built gold standard fraud datasets using rule-based heuristics, but these assumptions are also difficult to validate, especially as they are straightforward to bypass by experienced fraudsters.

### Addressing Inefficacy
In this paper, we propose to discourage fraud instead of merely discovering it. We seek to bridge the anonymity gap between existing fraud detection techniques that uncover pseudonymous user accounts and the real identities of crowdsourcing site accounts that control them. Specifically, we leverage the observation that crowdsourcing site accounts contain uniquely identifying payment information (e.g., bank, PayPal accounts) to de-anonymize fraud by attributing accounts uncovered by fraud detection algorithms to their human owners in crowdsourcing sites.

### Addressing Validation
We introduce the first cheating-resistant fraud de-anonymization validation protocol to obtain ground truth confirmation on the performance of developed solutions. The protocol asks human fraud workers to reveal a seed set of user accounts they control and subsequently confirm and prove control of predicted accounts. Multiple verifications of participant attention and honesty, including e-mail and token-based verifications, are introduced.

### Results
We conducted the fraud de-anonymization validation protocol through a user study with 16 human fraud workers, who revealed control of 230 Google Play accounts. Participants confirmed control of 91% of the user accounts newly discovered by UODA. On 942 ground truth attributed user accounts collected from 23 other fraud workers, both DDA and UODA achieved precision and recall exceeding 90%, attributing thousands of new accounts to these fraudsters.

Our co-ownership predictor outperformed the F1-measure of the state-of-the-art Elsiedetâ€™s Sybil social link builder by more than 12 percentage points. The PFD algorithm identified thousands of previously unknown fraudulent accounts, grouped into communities according to common ownership by fraudsters. Analysis of 1.1 billion pairs of reviews from these communities provided orthogonal evidence of fraud, including communities with more than 80% of accounts involved in review text plagiarism.

### Contributions
- **Fraud De-Anonymization:** Model fraud de-anonymization as a maximum likelihood estimation problem and develop UODA, an unconstrained optimization fraud de-anonymization algorithm.
- **Co-Ownership Predictor:** Introduce a graph-based deep learning approach to predict ownership of account pairs by the same fraudster, and leverage it to build DDA and PFD.
- **Human Fraud De-Anonymization Oracles:** Develop the first protocol to provide human-fraud-worker-based performance evaluation of fraud de-anonymization algorithms and evaluate proposed solutions using data collected through this protocol.

## 2. Concepts and Background
### 2.1 Basic Terminology
- **User:** A person or entity who posts reviews about a subject on an online peer-opinion system.
- **Subject:** A developer-created object or product that receives user-created reviews.
- **Developer:** A person or entity that hosts subjects on the peer-opinion system and often hires workers to manipulate reviews.
- **Fraud Worker:** A person or entity that performs review manipulation on behalf of a developer, often using Sybil accounts.

### 2.2 System and Adversary Model
We consider online peer-opinion systems (e.g., Google Play, Yelp, Amazon) that host accounts for developers, users, and products. Developers use their accounts to upload product information, while users post reviews. The survival of products is contingent on their review-influenced search rank. Higher-ranked products generate more revenue, either through direct payments or ads. For example, a one-star boost in rating can increase restaurant revenue by 5-9%.

## 3. Problem Definition
The insight that multiple fraud workers usually target a single subject suggests that a binary classification of fraud (e.g., fake vs. honest reviews, fraudulent vs. genuine accounts) is insufficient. Instead, we study the fraud de-anonymization problem, which involves attributing fraudulent accounts and fake reviews to the crowdsourcing accounts of the fraud workers who control and post them.

Formally, let \( U \) be the set of all user accounts, and \( S \) be the set of all subjects hosted in the online peer-opinion system. A user account is considered fraudulent if it was opened by a fraudster to perform fraudulent activities, i.e., to target subjects from \( S \).

## Conclusion
Our work introduces a novel approach to de-anonymize and disincentivize search rank fraud in online peer-opinion systems. By attributing fraudulent accounts to their human controllers, we aim to create a more transparent and trustworthy online environment. Future work will focus on refining and scaling these methods to further combat fraud.