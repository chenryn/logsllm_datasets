### Input on the Clone and Malware Detection

Input on the clone that damages the state can be discarded later. Malware can create a schedule and attempt to predict future usage by recording and examining old input. If the input is old, it is likely to have been entered before the clone operation and thus by the real user.

To identify real human input, it remains an open question how difficult it would be for an attacker. However, the attacking program has the additional burden of needing to be very sure that its identification is correct. If the probability (p) that the input is actually real when the malware thinks it is, is much less than 1, then the probability of remaining undetected decreases exponentially over time. The program could still have good odds if it packages large amounts of data into a single burst. This attack can be easily prevented by employing a rate-limiting anomaly detection system such as Web Tap [2] in parallel with Siren. For instance, if the probability of correctness for the malware is 0.95, or it is correct 95% of the time about the user being present, it would still have over a 50% chance of being detected after sending 14 times. To be successful, Siren only needs to fool the attacker some of the time.

### Siren’s Security Analysis

There are several methods an attacker could use to avoid or prolong detection by Siren. If the input generation algorithm is weak, Siren can exploit its shortcomings to learn characteristics of real input or even identify it immediately. For example, if input is only injected into cloned virtual machines, malware can look at older data to see a user's real input and predict when they will be active next. If the generation algorithm does not act sufficiently human, malware may use this to its advantage. For instance, if the algorithm never uploads files, a file upload will let the malware know it is safe to send data over the network.

As mentioned earlier, one precondition for Siren to eventually detect malware is that the malware must continually send network messages over time. A potential vulnerability in the Siren system is an attack that requires user interaction to deliver the payload immediately and then exits. An example of such a threat is an email worm. If the worm only opens when the user clicks on an email, sends emails to everyone in the address book, and then terminates quickly, Siren would have a hard time detecting it. One way to mitigate this vulnerability is to deploy additional deception methods, such as adding bogus addresses to the email client’s address book.

Another precondition for Siren to detect malicious software is that the attacker cannot determine usage through an out-of-band channel. A hacker could call a user on the phone and instruct them to enter a particular sequence of input triggering some malware. The hacker could also communicate with the user via instant messaging to ensure the user is active on their computer. Although these and other social engineering techniques could help an attacker figure out when a user is present, and Siren has no way to stop them, they are not trivial to execute and usually require associating a phone number and name with an IP or email address.

Finally, malicious software could hide data in a covert channel, such as modifying TCP flags in outbound traffic. However, these channels are often low bandwidth and require the attacker to passively listen on the path of a connection.

### Conclusion

Traditional behavioral analysis techniques can detect many novel threats but are vulnerable to mimicry attacks. In this paper, we presented Siren, a detection system that looks at human input to identify malicious network traffic. Siren also injects bogus human input to confuse and disrupt attackers who try to mimic legitimate programs by waiting for user input to send network messages.

We discussed possible methods for creating realistic human input and addressed potential shortcomings such as inadvertent state modification. For our evaluation, we manually entered a predetermined sequence of input on a clean machine and on virtual machines with ten different types of spyware installed. Siren was able to detect all ten spyware programs, while a competing anomaly detection system that does not inject input was only able to detect three of the ten. We also discussed methods of attacking Siren itself, such as out-of-band information gathering and identifying real activity by waiting for state-changing operations.

### Acknowledgements

We acknowledge support from Intel Corporation and the National Science Foundation. We also thank the reviewers for their helpful comments.

### References

[1] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R. Neugebauer, I. Pratt, and A. Warfield. Xen and the Art of Virtualization. In Proc. 19th ACM Symp. on Operating Systems Principles, pp. 164-177, 2003.

[2] K. Borders and A. Prakash. Web Tap: Detecting Covert Web Traffic. In Proc. 11th ACM Conf. on Computer and Communications Security, pp. 110-120, 2004.

[3] W. Cheswick. An Evening with Berferd in Which a Hacker is Lured, Endured, and Studied. In Proc. of the Winter Usenix 92 Conference, 1992.

[4] M. Chew and J.D. Tygar: Image Recognition CAPTCHAs. In Proc. 7th Information Security Conference, 2004.

[5] C. Clark, K. Fraser, S. Hand, J. G. Hansen, E. Jul, C. Limpach, I. Pratt, and A. Warfield. Live Migration of Virtual Machines. Proc. 2nd ACM/USENIX Symp. on Networked Systems Design and Implementation, 2005.

[6] J. Clark and D. Pradhan. Fault Injection: A Method for Validating Computer-System Dependability. Computer, 28(6):47-56, June 1995.

[7] A. Coates, H. Baird, and R. Fateman. Pessimistic Print: A Reverse Turing Test. In Proc. Sixth Intl. Conf. on Document Analysis and Recognition, pp. 1154, 2001.

[8] F. Cohen, D. Lambert, C. Preston, N. Berry, C. Stewart, and E. Thomas. A Framework for Deception. http://www.all.net/journal/deception/Framework/Framework.html, July 2001.

[9] W. Cui, R. Katz, and W. Tan. BINDER: An Extrusion-Based Break-In Detector for Personal Computers. In Proc. USENIX Annual Technical Conference, 2005.

[10] H. Feng, O. Kolesnikov, P. Fogla, W. Lee, and W. Gong. Anomaly Detection Using Call Stack Information. In Proc. IEEE Symp. on Security and Privacy, 2003.

[11] T. Garfinkel and M. Rosenblum. A Virtual Machine Introspection Based Architecture for Intrusion Detection. In Proc. ISOC Symp. on Network and Distributed System Security, 2003.

[12] T. Garfinkel and M. Rosenblum. When Virtual is Harder than Real: Security Challenges in Virtual Machine-based Computing Environments. In Proc. 10th Workshop on Hot Topics in Operating Systems (HotOS-X), May 2005.

[13] S. A. Hofmeyr, S. Forrest, and A. Somayaji. Intrusion Detection Using Sequences of System Calls. Journal of Computer Security, 6(3):151–180, 1998.

[14] HoneyPots. http://www.honeypots.org, 2005.

[15] A. Joshi, S. King, G. Dunlap, and P. Chen. Detecting Past and Present Intrusions through Vulnerability-Specific Predicates. In Proc. Symp. on Operating Systems Principles, 2005.

[16] G. H. Kim and E. H. Spafford. The Design and Implementation of Tripwire: a File System Integrity Checker. In Proc. ACM Conf. on Computer and Communications Security, 1994.

[17] S. King and P. Chen. Subvirt: Implementing malware with virtual machines. In IEEE Symp. on Security and Privacy, Oakland, California, May 2006.

[18] O. Kolesnikov, D. Dagon, and W. Lee. Advanced Polymorphic Worms: Evading IDS by Blending in with Normal Traffic. Georgia Tech Technical Report, GIT-CC-04-15, 2004-2005.

[19] C. Kruegel and E. Kirda. Automating Mimicry Attacks Using Static Binary Analysis. In Proc. 14th USENIX Security Symposium, pp. 161–176, 2005.

[20] Y. Liao and V. R. Vemuri. Using Text Categorization Techniques for Intrusion Detection. In Proc. 11th USENIX Security Symposium, pp. 51-59, 2002.

[21] MessageLabs. MessageLabs Survey Finds Spyware No. 1 Web Security Issue for Australian Businesses. http://www.computerworld.com.au/index.php/id;478111644, 2005.

[22] K. Mitnick and W. Simon. The Art of Deception: Controlling the Human Element of Security. Wiley (2002).

[23] M. Naor. Verification of a Human in the Loop, or Identification via the Turing Test. Unpublished manuscript, http://www.wisdom.weizmann.ac.il/~naor/PAPERS/human_abs.html, 1996.

[24] B. Schneier. Attack Trends: 2004 and 2005, Queue, June 2005. http://www.schneier.com/blog/archives/2005/06/attack_trends_2.html.

[25] L. Spitzner. The Other Honeypot, July 2003. http://www.securityfocus.com/infocus/1713.

[26] K. Tan, K.S. Killourhy, and R.A. Maxion. Undermining an Anomaly-Based Intrusion Detection System Using Common Exploits. In Proc. Fifth Intl. Symp. on Recent Advances in Intrusion Detection (RAID), pp. 54-73. Lectures Notes in Computer Science #2516, Springer-Verlag, Oct. 2002.

[27] Sun Tzu. The Art of War (translated by James Clavell). Dell Publishing, New York, 1983.

[28] D. Wagner and P. Soto. Mimicry Attacks on Host-Based Intrusion Detection Systems. In Proc. 9th ACM Conf. on Computer and Communications Security, pp. 255-264, 2002.

[29] Y. Zhang and V. Paxson. Detecting Stepping Stones. In Proc. 9th USENIX Security Symposium, pp. 171-184, August 2000.