### Related Work
Most previous studies on sound Angle of Arrival (AoA) estimation have relied on microphone arrays [46, 48, 50]. The works by [18, 30, 32] are the most closely related to our research, as they attempted to estimate sound AoA using artificially designed robotic ears. Our problem is more challenging because these authors had complete control over the design and understanding of the robot's Head-Related Transfer Function (HRTF). In contrast, we must estimate the sound source AoA using features extracted from an HRTF that is not as accurate, which introduces unique challenges.

### Limitations and Open Problems

#### 3D HRTF
Our UNIQ prototype currently estimates 2D HRTFs for users. This may be acceptable, given that human ears generally have lower resolution in distinguishing elevation angles, making 2D HRTFs sufficient for many applications. However, if 3D HRTFs are required, extending UNIQ is feasible. The user would need to move the phone in a spherical pattern around their head, and the motion tracking equations would need to be extended to 3D. If this increases the tracking error, the phone camera could be utilized to integrate motion, acoustics, and computer vision, potentially improving accuracy. We leave this extension to future work.

#### Integrating Room Multipath
As discussed earlier, UNIQ removes environmental reverberations through a pre-processing step in the time domain, which helps minimize the effect of room multipath on the estimated HRTF. However, for realistic 3D audio, especially in indoor environments, it is necessary to embed room reverberations into the HRTF. In other words, a truly immersive experience can only be achieved by filtering the earphone sound with both the room impulse response (RIR) and the HRTF. Estimating RIR at home is an interesting but separate research question, outside the scope of this paper.

#### User Experience and Externalization
An estimated HRTF is considered accurate when the user cannot correctly identify whether the sound they hear comes from their earphones or an ambient loudspeaker. When a user mistakes an earphone-played sound for one coming from the environment, the goal of "externalization" is achieved. Testing for externalization requires high-quality earphone hardware and RIR integration. Additionally, optimization methods based on human feedback may be needed, as externalization is a complex function of human perception [14]. While our estimated HRTFs are mathematically close to true HRTFs, further work is needed to achieve full externalization.

### Conclusion
The gap between global and personalized HRTFs remains an open problem. This paper introduces ideas from motion tracking and sensor fusion to partially bridge this gap. We demonstrate that simple arm gestures from users can provide valuable motion information, which in turn helps in modeling the user’s unique HRTF parameters. As a side benefit, we find that earphones can better estimate the AoA of ambient sounds. The results are promising and could underpin a range of immersive applications that are becoming increasingly relevant in the post-COVID future.

### Acknowledgments
We sincerely thank our shepherd Prof. Fadel Adib and the anonymous reviewers for their insightful comments and suggestions. We are also grateful to the National Science Foundation (NSF; award numbers: 1918531, 1910933, 1909568, and 1719337), the National Institutes of Health (NIH; award number: 1R34DA050262-01), Google, and Samsung for partially funding this research.

### References
[1] 2015. The Sound Professionals. Retrieved Jan 26, 2021, from https://www.soundprofessionals.com/cgi-bin/gold/item/SP-TFB-2
[2] 2015. Wave Interactions and Interference. Retrieved Jan 24, 2021, from https://www.ck12.org/section/wave-interactions-and-interference-%3a%3aof%3a%3a-waves-%3a%3aof%3a%3a-ck-12-physical-science-for-middle-school/
[3] 2017. Beyond Surround Sound: Audio Advances in VR. Retrieved Jan 24, 2021, from https://www.oculus.com/blog/beyond-surround-sound-audio-advances-in-vr/
[4] 2017. Near-field 3D Audio Explained. Retrieved Jun 11, 2021, from https://developer.oculus.com/blog/near-field-3d-audio-explained/
[5] 2018. Simulating Dynamic Soundscapes at Facebook Reality Labs. Retrieved Jan 26, 2021, from https://www.oculus.com/blog/simulating-dynamic-soundscapes-at-facebook-reality-labs/
[6] 2019. Audio in mixed reality. Retrieved Jan 24, 2021, from https://docs.microsoft.com/en-us/windows/mixed-reality/design/spatial-sound
[7] 2019. Mach1 will provide spatial audio for Bose’s AR platform. Retrieved Jan 24, 2021, from https://venturebeat.com/2019/12/18/mach1-will-provide-spatial-audio-for-boses-ar-platform/
[8] 2020. Apple brings surround sound and Dolby Atmos to AirPods Pro. Retrieved Jan 24, 2021, from https://thenextweb.com/plugged/2020/06/22/apple-brings-surround-sound-and-dolby-atmos-to-airpods-pro/
[9] 2020. Diffraction. Retrieved Jan 24, 2021, from https://en.wikipedia.org/wiki/Diffraction
[10] 2020. Inside Facebook Reality Labs Research: The Future of Audio. Retrieved Jan 24, 2021, from https://about.fb.com/news/2020/09/facebook-reality-labs-research-future-of-audio/
[11] 2020. Xiaomi United States. Retrieved Jan 26, 2021, from https://www.mi.com/us/
[12] 2021. DIY HRTF measurement using an iPhone. Retrieved Jun 11, 2021, from https://www.earfish.eu/sites/default/files/2018-01/DIY_earfish_iPhone_0.pdf
[13] 2021. Equal-loudness contour. Retrieved Jan 24, 2021, from https://en.wikipedia.org/wiki/Equal-loudness_contour
[14] Ishwarya Ananthabhotla, Vamsi Krishna Ithapu, and W Owen Brimijoin. 2021. A framework for designing head-related transfer function distance metrics that capture localization perception. JASA Express Letters 1, 4 (2021), 044401.
[15] Jeffrey R Blum, Mathieu Bouchard, and Jeremy R Cooperstock. 2011. What’s around me? Spatialized audio augmented reality for blind users with a smartphone. In International Conference on Mobile and Ubiquitous Systems: Computing, Networking, and Services. Springer, 49–62.
[16] C Phillip Brown and Richard O Duda. 1997. An efficient HRTF model for 3-D sound. In Proceedings of 1997 Workshop on Applications of Signal Processing to Audio and Acoustics. IEEE, 4–pp.
[17] Thibaut Carpentier, Hélène Bahu, Markus Noisternig, and Olivier Warusfel. 2014. Measurement of a head-related transfer function database with high spatial resolution. In 7th Forum Acusticum (EAA).
[18] Jorge Dávila-Chacón, Jindong Liu, and Stefan Wermter. 2018. Enhanced robot speech recognition using biomimetic binaural sound source localization. IEEE transactions on neural networks and learning systems 30, 1 (2018), 138–150.
[19] Hossein Falaki, Ratul Mahajan, Srikanth Kandula, Dimitrios Lymberopoulos, Ramesh Govindan, and Deborah Estrin. 2010. Diversity in smartphone usage. In Proceedings of the 8th international conference on Mobile systems, applications, and services. 179–194.
[20] Yang Gao, Wei Wang, Vir V Phoha, Wei Sun, and Zhanpeng Jin. 2019. EarEcho: Using Ear Canal Echo for Wearable Authentication. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 3, 3 (2019), 1–24.
[21] William G Gardner. 2005. Spatial audio reproduction: Towards individualized binaural sound. In Frontiers of Engineering:: Reports on Leading-Edge Engineering from the 2004 NAE Symposium on Frontiers of Engineering, Vol. 34. 113.
[22] William G Gardner and Keith D Martin. 1995. HRTF measurements of a KEMAR. The Journal of the Acoustical Society of America 97, 6 (1995), 3907–3908.
[23] Reza Ghaffarivardavagh, Sayed Saad Afzal, Osvy Rodriguez, and Fadel Adib. 2020. Ultra-wideband underwater backscatter via piezoelectric metamaterials. In Proceedings of the Annual conference of the ACM Special Interest Group on Data Communication on the applications, technologies, architectures, and protocols for computer communication. 722–734.
[24] Yasaman Ghasempour, Chia-Yi Yeh, Rabi Shrestha, Yasith Amarasinghe, Daniel Mittleman, and Edward W Knightly. 2020. LeakyTrack: non-coherent single-antenna nodal and environmental mobility tracking with a leaky-wave antenna. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems. 56–68.
[25] Michael M Goodwin and Jean-Marc Jot. 2007. Binaural 3-D audio rendering based on spatial audio scene coding. In Audio Engineering Society Convention 123. Audio Engineering Society.
[26] Michael M Goodwin, Jean-Marc Jot, and Mark Dolson. 2013. Spatial audio analysis and synthesis for binaural reproduction and format conversion. US Patent 8,374,365.
[27] Corentin Guezenoc and Renaud Seguier. 2020. HRTF individualization: A survey. arXiv preprint arXiv:2003.06183 (2020).
[28] Nail A Gumerov, Ramani Duraiswami, and Dmitry N Zotkin. 2007. Fast multipole accelerated boundary elements for numerical computation of the head related transfer function. In 2007 IEEE International Conference on Acoustics, Speech and Signal Processing-ICASSP’07, Vol. 1. IEEE, I–165.
[29] Hongmei Hu, Lin Zhou, Hao Ma, and Zhenyang Wu. 2008. HRTF personalization based on artificial neural network in individual virtual auditory space. Applied Acoustics 69, 2 (2008), 163–172.
[30] Sungmok Hwang, Youngjin Park, and Younsik Park. 2007. Sound direction estimation using artificial ear. In 2007 International Conference on Control, Automation and Systems. IEEE, 1906–1910.
[31] C Jackman, M Zampino, D Cadge, R Dravida, V Katiyar, and J Lewis. 2009. Estimating acoustic performance of a cell phone speaker using Abaqus. In SIMULIA Customer Conference. 14–21.
[32] Cheol-Taek Kim, Tae-Yong Choi, ByongSuk Choi, and Ju-Jang Lee. 2008. Robust estimation of sound direction for robot interface. In 2008 IEEE International Conference on Robotics and Automation. IEEE, 3475–3480.
[33] Lin Li and Qinghua Huang. 2013. HRTF personalization modeling based on RBF neural network. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 3707–3710.
[34] Zhihong Luo, Qiping Zhang, Yunfei Ma, Manish Singh, and Fadel Adib. 2019. 3D backscatter localization for fine-grained robotics. In 16th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 19). 765–782.
[35] Wenguang Mao, Wei Sun, Mei Wang, and Lili Qiu. 2020. DeepRange: Acoustic Ranging via Deep Learning. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, 4 (2020), 1–23.
[36] Alok Meshram, Ravish Mehra, Hongsheng Yang, Enrique Dunn, Jan-Michael Franm, and Dinesh Manocha. 2014. P-HRTF: Efficient personalized HRTF computation for high-fidelity spatial sound. In 2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEE, 53–61.
[37] Yan Michalevsky, Aaron Schulman, Gunaa Arumugam Veerapandian, Dan Boneh, and Gabi Nakibly. 2015. Powerspy: Location tracking using mobile device power analysis. In 24th {USENIX} Security Symposium ({USENIX} Security 15). 785–800.
[38] Philip M Morse and Pearl J Rubenstein. 1938. The diffraction of waves by ribbons and by slits. Physical Review 54, 11 (1938), 895.
[39] Rajalakshmi Nandakumar, Krishna Kant Chintalapudi, Venkat Padmanabhan, and Ramarathnam Venkatesan. 2013. Dhwani: secure peer-to-peer acoustic NFC. ACM SIGCOMM Computer Communication Review 43, 4 (2013), 63–74.
[40] Takanori Nishino, Sumie Mase, Shoji Kajita, Kazuya Takeda, and Fumitada Itakura. 1996. Interpolating HRTF for auditory virtual reality. Ph.D. Dissertation. Acoustical Society of America.
[41] Chunyi Peng, Guobin Shen, Yongguang Zhang, Yanlin Li, and Kun Tan. 2007. Beepbeep: a high accuracy acoustic ranging system using cots mobile devices. In Proceedings of the 5th international conference on Embedded networked sensor systems. 1–14.
[42] Ming-Zher Poh, Kyunghee Kim, Andrew D Goessling, Nicholas C Swenson, and Rosalind W Picard. 2009. Heartphones: Sensor earphones and mobile application for non-obtrusive health monitoring. In 2009 International Symposium on Wearable Computers. IEEE, 153–154.
[43] Swadhin Pradhan, Ghufran Baig, Wenguang Mao, Lili Qiu, Guohai Chen, and Bo Yang. 2018. Smartphone-based acoustic indoor space mapping. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2, 2 (2018), 1–26.
[44] Jay Prakash, Zhijian Yang, Yu-Lin Wei, and Romit Roy Choudhury. 2019. STEAR: Robust Step Counting from Earables. In Proceedings of the 1st International Workshop on Earable Computing. 36–41.
[45] Niklas Röber, Sven Andres, and Maic Masuch. 2006. HRTF simulations through acoustic raytracing. Universitäts-und Landesbibliothek Sachsen-Anhalt.
[46] Sheng Shen, Daguan Chen, Yu-Lin Wei, Zhijian Yang, and Romit Roy Choudhury. 2020. Voice localization using nearby wall reflections. In Proceedings of the 26th Annual International Conference on Mobile Computing and Networking. 1–14.
[47] Tzu-Chun Tai, Kate Ching-Ju Lin, and Yu-Chee Tseng. 2019. Toward reliable localization by unequal AoA tracking. In Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. 444–456.
[48] Jelmer Tiete, Federico Domínguez, Bruno Da Silva, Laurent Segers, Kris Steenhaut, and Abdellah Touhafi. 2014. SoundCompass: a distributed MEMS microphone array-based sensor for sound source localization. Sensors 14, 2 (2014), 1918–1949.
[49] Edgar A Torres-Gallegos, Felipe Orduna-Bustamante, and Fernando Arámbula-Cosío. 2015. Personalization of head-related transfer functions (HRTF) based on automatic photo-anthropometry and inference from a database. Applied Acoustics 97 (2015), 84–95.
[50] J-M Valin, François Michaud, Jean Rouat, and Dominic Létourneau. 2003. Robust sound source localization using a microphone array on a mobile robot. In Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003)(Cat. No. 03CH37453), Vol. 2. IEEE, 1228–1233.
[51] Lars Falck Villemoes and Dirk Jeroen Breebaart. 2012. Method and apparatus for generating a binaural audio signal. US Patent 8,265,284.
[52] Jeff Wilson, Bruce N Walker, Jeffrey Lindsay, Craig Cambias, and Frank Dellaert. 2007. Swan: System for wearable audio navigation. In 2007 11th IEEE international symposium on wearable computers. IEEE, 91–98.
[53] Jens Windau and Laurent Itti. 2016. Walking compass with head-mounted IMU sensor. In 2016 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 5542–5547.
[54] Zhijian Yang, Yu-Lin Wei, Sheng Shen, and Romit Roy Choudhury. 2020. Ear-AR: indoor acoustic augmented reality on earphones. In Proceedings of the 26th Annual International Conference on Mobile Computing and Networking. 1–14.
[55] Guangzheng Yu, Ruixing Wu, Yu Liu, and Bosun Xie. 2018. Near-field head-related transfer-function measurement and database of human subjects. The Journal of the Acoustical Society of America 143, 3 (2018), EL194–EL198.
[56] Yanzi Zhu, Yibo Zhu, Ben Y Zhao, and Haitao Zheng. 2015. Reusing 60GHz radios for mobile radar imaging. In Proceedings of the 21st Annual International Conference on Mobile Computing and Networking. 103–116.
[57] Harald Ziegelwanger, Wolfgang Kreuzer, and Piotr Majdak. 2016. A priori mesh grading for the numerical calculation of the head-related transfer functions. Applied Acoustics 114 (2016), 99–110.
[58] DYN Zotkin, Jane Hwang, R Duraiswaini, and Larry S Davis. 2003. HRTF personalization using anthropometric measurements. In 2003 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (IEEE Cat. No. 03TH8684). IEEE, 157–160.
[59] Dmitry N Zotkin, Ramani Duraiswami, and Larry S Davis. 2004. Rendering localized spatial audio in a virtual auditory space. IEEE Transactions on multimedia 6, 4 (2004), 553–564.