### Greedy Heuristic for Near-Optimal Key Sequence

**Algorithm: GREEDY-HEURISTIC(KG)**

1. **Initialization:**
   - Set `flag` to 0.
   - For each vertex `vi` in the set of neighbors `NEIGHBOR(S)`:
     - Compute `vertex_cost` as `NEW-VERTEX-COST(vi)`.
2. **Matrix and Path Initialization:**
   - Update the adjacency matrix `M` using `UPDATED-ADJ-MATRIX(KG, p(S))`.
   - Compute the All-Pairs Shortest Paths (APSP) `A` from the updated matrix `M`.
   - Set `min_cost` to `A[v0, vs]`, where `v0` is the start vertex and `vs` is the target vertex.
3. **Main Loop:**
   - For each round from 1 to the number of vertices `|V|`:
     - If `flag` is 1, break the loop.
     - Otherwise, set `new_vertex` to `vi`.
     - Set `flag` to 1.
4. **Update and Recompute:**
   - Add `new_vertex` to the set `S`.
   - If `flag` is 1, update the adjacency matrix `M0` using `UPDATED-ADJ-MATRIX(KG, p(S ∪ {vi}))`.
   - For each vertex `vj` in `S`, set `M0[vj, vi]` and `M0[vi, vj]` to 0.
   - Recompute the APSP `A0` from the updated matrix `M0`.
   - If `(vertex_cost + A0[v0, vs])` is less than `min_cost`, update `min_cost` to `vertex_cost + A0[v0, vs]`.
5. **Return:**
   - Return the `min_cost`.

### Algorithm Benchmarking

We conducted empirical evaluations to compare the performance of the `BRUTE-FORCE` algorithm with the `GREEDY-HEURISTIC` algorithm. The experiments were run on a Pentium 4/3GHz/1GB RAM machine running RedHat Linux 9.1. Due to the prohibitively expensive running time of the `BRUTE-FORCE` algorithm, we limited the input size to only 15 nodes.

Our test dataset consisted of 1000 simulation runs, with each run generating a random instance of a key challenge graph. We compared the quality of the solutions computed by both algorithms (see Figure 4) and their running times (see Figure 5).

**Comparison of Attack Costs:**
- In Figure 4, two distinct bands are observed: a lower band representing the optimal attack costs returned by `BRUTE-FORCE` and a higher band representing the attack costs returned by `GREEDY-HEURISTIC`.
- The gap between the two bands is due to the inapproximability results discussed in Section 4.
- `GREEDY-HEURISTIC` performed well when the final attack sequence was very small (3-4 nodes), which is the best-case scenario for the heuristic algorithm.
- However, for longer attack sequences (10-15 nodes), the heuristic produced a larger gap from the optimal solution. This is attributed to the increased likelihood of errors in the decision-making process, which compound over a longer sequence.

**Comparison of Running Times:**
- For the 1000 runs, we used a cross-section of varying graph sizes (3-20 nodes).
- The running time of the `BRUTE-FORCE` algorithm becomes very large even for small values of 13 to 15 nodes, which is expected given its O(n!) complexity.
- In contrast, `GREEDY-HEURISTIC` has polynomial running times for the same input. Even for graphs with a large number of nodes (200-300 nodes), the running time was observed to be only a few minutes (15-20 minutes).

### Related Work

Theoretical models allow for inexpensive security analysis without the need for real experiments or implementation. Fault trees, privilege graphs, and attack graphs are the most relevant modeling methodologies in our context. We compare and contrast these techniques to provide perspective on our work.

- **Fault Trees:** These are the first generation of formal models primarily used for system failure analysis. While suitable for modeling disjunctions and conjunctions of faults, they lack the expressive power to capture attacks.
- **Privilege Graphs:** Introduced by Dacier et al. as an extension to the Typed Access Model (TAM), these directed graphs represent sets of privileges on objects and arcs represent privilege escalation. Determining meaningful probabilities for these models is challenging, and they do not capture the dynamic nature of edge traversal.
- **Attack Graphs:** Proposed by Philips and Swiler, these graphs represent the state of a network and steps in an attack. Although model-checking can generate such graphs, it suffers from state explosion, making it unsuitable for networks of reasonable size.

While privilege graphs and attack graphs share some similarities with our approach, they differ in the details captured and the nature of threat analysis. Our model generates polynomial-sized models and can account for attacks that succeed without privilege escalation or vulnerabilities, which is particularly relevant for insider threats.

### Conclusion and Future Work

Insider threat is a long-standing security problem, but until now, there have been limited tools and techniques to counter it. In this paper, we propose a usable and generic threat assessment model and demonstrate its applications in typical insider threat scenarios. Our model complements existing models and offers a more generic methodology that may have broader appeal.

Future work involves developing automated tools around the modeling methodology and algorithms presented in this paper to empower security analysts with techniques to measure threats that were previously unmeasurable.

### References

[1] 2004 E-Crime Watch Survey: Summary Of Findings. CERT/United States Secret Service/CSO, 2004. http://www.cert.org/archive/pdf/2004eCrimeWatchSummary.pdf.

[2] Insider Threat Study: Banking And Finance Sector. CERT/United States Secret Service, August 2004. http://www.secretservice.gov/ntac/its_report_040820.pdf.

[3] S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. Proof Verification And The Hardness Of Approximation Problems. J. ACM, 45(3):501-555, 1998.

[4] S. Arora and S. Safra. Probabilistic Checking Of Proofs: A New Characterization Of NP. J. ACM, 45(1):70-122, 1998.

[5] R. Chinchani, D. Ha, A. Iyer, H. Q. Ngo, and S. Upadhyaya. On the hardness of approximating the Min-Hack problem. 2005. Technical Report 2005-05. Computer Science and Engineering, SUNY at Buffalo.

[6] M. Dacier. Towards Quantitative Evaluation of Computer Security. PhD thesis, Institut National Polytechnique de Toulouse, December 1994.

[7] M. Dacier and Y. Deswarte. Privilege graph: an extension to the typed access matrix model. In ESORICS, pages 319-334, 1994.

[8] I. Dinur and S. Safra. On the Hardness of Approximating Label Cover. Electronic Colloquium on Computational Complexity (ECCC), 6(015), 1999.

[9] U. Feige, S. Goldwasser, L. Lovász, S. Safra, and M. Szegedy. Interactive Proofs And The Hardness Of Approximating Cliques. J. ACM, 43(2):268-292, 1996.

[10] M. R. Garey and D. S. Johnson. Computers and Intractability. W. H. Freeman and Co., San Francisco, Calif., 1979. A Guide To The Theory Of NP-Completeness, A Series of Books in the Mathematical Sciences.

[11] J. Gorski and A. Wardzinski. Formalizing Fault Trees. Achievement and Assurance of Safety, pages 311-327, 1995.

[12] J. Håstad. Some Recent Strong Inapproximability Results. In Algorithm theory—SWAT’98 (Stockholm), volume 1432 of Lecture Notes in Comput. Sci., pages 205-209. Springer, Berlin, 1998.

[13] J. Håstad. Some Optimal Inapproximability Results. In STOC ’97 (El Paso, TX), pages 1-10 (electronic). ACM, New York, 1999.

[14] D. S. Hochbaum, editor. Approximation Algorithms for NP Hard Problems. PWS Publishing Company, Boston, MA, 1997.

[15] S. Khanna, R. Motwani, M. Sudan, and U. Vazirani. On Syntactic Versus Computational Views Of Approximability. SIAM J. Comput., 28(1):164-191 (electronic), 1999.

[16] C. Meadows. A Representation of Protocol Attacks for Risk Assessment. In R. N. Wright and P. G. Neumann, editors, DIMACS Series in Discrete Mathematics and Theoretical Computer Science: Network Threats, volume 38, December 1998.

[17] R. Ortalo, Y. Dewarte, and M. Kaaniche. Experimenting With Quantitative Evaluation Tools For Monitoring Operation Security. IEEE Transactions on Software Engineering, 25(5):633-650, September/October 1999.

[18] C. H. Papadimitriou and M. Yannakakis. Optimization, Approximation, And Complexity Classes. J. Comput. System Sci., 43(3):425-440, 1991.

[19] C. Phillips and L. P. Swiler. A Graph-Based System For Network-Vulnerability Analysis. In Proceedings of 1998 New Security Paradigms Workshop, pages 71-79, Charlottesville, Virginia, 1998.

[20] O. Sheyner, J. Haines, S. Jha, R. Lippmann, and J. M. Wing. Automated Generation and Analysis of Attack Graphs. In Proceedings of the IEEE Symposium on Security and Privacy, Oakland, CA., May 2002.

[21] L. P. Swiler, C. Phillips, D. Ellis, and S. Chakerian. Computer-Attack Graph Generation Tool. In DARPA Information Survivability Conference and Exposition (DISCEX 11’01), volume 2, June 2001.