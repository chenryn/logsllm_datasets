与安卓 2.0 和 2.1 中包含的 Facebook 客户端不同，2.2 版本的部分功能仍可使用，并且能够登录到 Facebook 服务器。该应用是谷歌当时设计指南的一个优秀示例，建议在应用主页上设置一个 3x2 的图标方阵导航页。

这是谷歌首次尝试将导航元素从菜单按钮移至屏幕上，以便用户更易发现。尽管这一设计具有实用性，但它在打开和使用应用之间增加了额外步骤。不久之后，谷歌意识到，在用户启动应用时直接展示内容而非导航页更为合适。以 Facebook 为例，直接显示信息订阅流会是一个更好的选择。随后，应用设计逐渐将导航降至次要位置——首先是作为顶部标签之一，最终演变为“导航抽屉”，即一个可以滑出的面板，包含了应用程序的所有功能选项。

另一个预装在 Froyo 上的应用是 Google Goggles，这是一款视觉搜索工具，能够识别图片中的主体。它在艺术品、地标及条形码识别方面表现出色，但除此之外的功能较为有限。最初的两个设置屏幕和相机界面是目前唯一仍然可用的部分。由于客户端版本过旧，实际上已无法完成搜索任务。除了带有返回搜索结果页面的相机界面外，应用内并无太多其他内容。

*Twitter 应用，一款充满动画效果的谷歌与 Twitter 合作成果。 [Ron Amadeo 提供]*

Froyo 还推出了首个安卓版 Twitter 应用，实际上是谷歌与 Twitter 共同开发的产物。当时，Twitter 应用是安卓平台上的一个重要缺失项。开发者们更倾向于为 iPhone 开发应用，加上苹果在市场上的先发优势及其严格的设计要求，App Store 中可供选择的应用数量远超安卓市场。因此，谷歌需要推出自己的 Twitter 应用来弥补这一空白，于是与 Twitter 合作组建团队完成了第一版应用的开发。

这款应用体现了谷歌的新设计语言，拥有中间导航页以及大量动画效果。事实上，Twitter 应用比 Cooliris 相册使用的动画还要多——几乎每个元素都在不断移动。所有页面顶部和底部都有云朵滚动，而底部的小鸟标志则不停地扇动翅膀并左右摆头。

Twitter 应用还具备早期 Action Bar 的一些特性，后者是在安卓 3.0 中引入的一条顶部对齐的连续控制栏。所有屏幕顶部都有一条蓝色横栏，上面有 Twitter 标志以及搜索、刷新和发布推文等按钮。与后来的 Action Bar 相比，主要区别在于右上角缺少了一个“返回”按钮；相反，它使用了第二个完整的栏位来显示当前位置。如上图所示，可以看到带有“Tweets”标签的位置指示栏（当然还有不断滚动的云朵）。第二个栏中的 Twitter 标志也充当了一个导航元素，有时用于显示当前部分的下拉区域，有时则展示顶级快捷方式集合。

2.3 版本中的推文流看起来与今天没有太大区别，只是操作按钮（如回复、转推等）被隐藏在一个右对齐的箭头按钮中。点击后会弹出一个聊天气泡菜单，类似于导航弹窗。仿 Action Bar 在撰写推文页面中起到了重要作用，其中包括 Twitter 标志、剩余字符计数器以及添加照片、拍摄新照片和提及联系人等功能按钮。

此外，Twitter 应用还提供了两种主屏小部件：较大的一个占据 8 个网格单元格，提供了一个发推栏、更新按钮、一条推文以及左右箭头来查看更多推文；较小的那个则只显示一条推文和回复按钮。点击大号小部件的发推栏可以直接打开“新推文”窗口，使得“更新”按钮变得多余。

*Google Talk 和新的 USB 对话框。 [Ron Amadeo 提供]*

另一方面，Google Talk（以及未截图的短信应用）从暗色主题转变为浅色主题，使其外观更加接近现代应用。USB 存储界面现在会在设备连接电脑时从简单的对话框切换到全屏模式，其中包含一个异形的安卓机器人/USB闪存盘混合体，取代了之前的纯文本设计。

尽管安卓 2.2 在用户交互方面没有引入太多新特性，但后续版本将迎来重大的 UI 调整。然而，在进行这些 UI 工作之前，谷歌希望先改进安卓的核心组件。
### **语音操作——口袋里的超级计算机**

2010 年 8 月，作为语音搜索应用的一项新功能，“[语音命令](http://arstechnica.com/gadgets/2010/08/google-beefs-up-voice-search-mobile-sync/)”正式登陆安卓市场。通过语音命令，用户可以用声音向手机发出指令，安卓系统会尝试理解并执行这些任务。例如，说出“导航至[地址]”这样的命令，就可以启动谷歌地图并开始逐向导航至指定目的地。你还可以通过语音发送短信或电子邮件、拨打电话、访问网站、获取方向或在地图上查找地点。

语音命令代表了谷歌新应用设计理念的巅峰之作。它是当时最先进的语音控制软件之一，其秘密在于所有计算过程都在云端完成，而不是在设备本地进行。一般来说，语音识别是一项 CPU 密集型任务，许多语音识别程序甚至允许用户选择“速度与准确性”之间的权衡——更多的 CPU 处理意味着更高的准确性。

谷歌的创新之处在于将语音识别所需的运算量转移到了云端服务器上，而不是依赖于手机上有限的处理能力。当用户发出语音命令时，音频数据会被打包并通过互联网发送到谷歌的数据中心，在那里由超级计算机分析和解释语音信号，然后将结果传回手机。虽然整个过程涉及较长的数据传输路径，但借助高速互联网的支持，这项任务通常可以在一两秒内完成。

许多人用“云计算”这个词来描述“所有东西都被存储在服务器上”的概念，但这才是真正的云计算。谷歌利用云端庞大的计算资源来进行复杂的语音处理工作，从而显著提高了识别精度。更重要的是，由于所有使用语音操作的用户都在持续不断地训练这个系统，因此无需每个用户单独对其进行校准。借助互联网的力量，安卓将一部超级计算机放进了你的口袋里，同时通过将语音识别任务从小型手持设备转移到大型数据中心，大大提升了准确性。

早在 2007 年 4 月，谷歌就推出了免费电话信息服务 1-800-GOOG-411，用户可以通过拨打此号码查询电话号码。这一服务完全基于语音识别技术和文本转语音引擎运行。经过三年多时间的学习和完善，才最终实现了语音命令功能。

语音识别是谷歌长期战略的一个典范——公司并不害怕在可能不会立即带来商业回报的项目上投入多年精力。如今，谷歌旗下众多产品和服务都采用了这项技术，包括谷歌搜索应用、安卓系统的语音输入功能以及 Google.com 网站本身。此外，它还是 Google Glass 和 [Android Wear](http://arstechnica.com/gadgets/2014/03/in-depth-with-android-wear-googles-quantum-leap-of-a-smartwatch-os/) 设备的主要输入方式之一。

不仅如此，谷歌还将语音识别技术应用于其他领域，例如自动生成 YouTube 视频字幕，帮助听障人士观看视频内容。生成的字幕还被编入索引，使用户能够搜索特定语句出现的具体位置。可以说，语音已经成为许多未来产品的关键要素之一，而谷歌凭借其前瞻性的布局成为了少数几家拥有自主语音识别服务的企业之一。相比之下，大多数其他语音识别产品（如苹果的 Siri 和三星设备）都需要依赖 Nuance 的技术支持，并为此支付授权费用。

在成功建立起强大的计算机听觉系统之后，谷歌又将同样的策略应用于计算机视觉领域，这便是像 Google Goggles、Google 图像搜索和 [Project Tango](http://arstechnica.com/gadgets/2014/02/googles-project-tango-is-a-smartphone-with-kinect-style-computer-vision/) 等项目的初衷所在。就像 GOOG-411 项目一样，这些研究目前仍处于起步阶段。当[谷歌的机器人部门](http://arstechnica.com/gadgets/2013/12/google-robots-former-android-chief-will-lead-google-robotics-division/)开发出真正意义上的机器人时，它们将需要具备视觉和听觉能力，而谷歌在这方面的积累无疑为其奠定了坚实的基础。
---
![](/data/attachment/album/201612/06/172630v978lo4o997cailj.jpg)

[Ron Amadeo](http://arstechnica.com/author/ronamadeo) 是 Ars Technica 的评论编辑，专注于安卓系统和谷歌产品。他总是热衷于探索新技术，并喜欢拆解事物以了解其工作原理。 [@RonAmadeo](https://twitter.com/RonAmadeo)

本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创翻译，[Linux中国](http://linux.cn/) 荣誉推出。

译者：[alim0x](https://github.com/alim0x) 校对：[wxy](https://github.com/wxy)