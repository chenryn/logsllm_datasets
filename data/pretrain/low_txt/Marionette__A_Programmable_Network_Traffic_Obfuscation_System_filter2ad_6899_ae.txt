### 7.6 Performance

In our experiments, the performance of Marionette was primarily influenced by two key factors: (1) the structure of the model specification and (2) the client-server latency in our testbed. To illustrate this, consider our FTP format in Section 7.2, which requires nine back-and-forth messages in the FTP command channel before we can initiate a PASV FTP connection. This format necessitates a total of thirteen round trips (nine for our messages and four to establish the two TCP connections) before we can send the first downstream ciphertext. In our testbed, with a 75ms client-server latency, this means that at least 975ms elapse before any data is transmitted. Consequently, a significant amount of time is spent waiting for network I/O.

Figure 11 summarizes the percentage of time that our client and server were blocked due to network I/O for each of the Marionette formats in our case studies. In the most extreme case, the Marionette server for the HTTP specification in Section 7.4 spends 98.8% of its time idle, waiting for network events. These results indicate that certain Marionette formats, such as the high-fidelity HTTP mimicry in Section 7.4, are particularly susceptible to performance degradation due to network effects. Balancing efficiency and realism is a critical design consideration for Marionette formats.

### 8 Conclusion

Marionette is the first programmable obfuscation system that allows users to control traffic features ranging from the format of individual application-layer messages to statistical features of connections and dependencies among multiple connections. This flexibility enables users to tailor their strategy to their specific network environment and usage requirements. Importantly, Marionette achieves this without compromising performance beyond what is necessary to maintain the constraints of the model, providing an acceptable trade-off between control over traffic features and network throughput.

Our evaluation demonstrates the power of Marionette through various case studies motivated by censorship techniques found in practice and the research literature. We now place these experimental results in context by comparing them to the state-of-the-art in application identification techniques and highlighting the open questions about the limitations of the Marionette system.

#### DPI
The most widely used method for application identification available to censors is Deep Packet Inspection (DPI), which can search for content matching specified keywords or regular expressions. DPI technology is now available in a variety of networking products capable of handling traffic volumes up to 30Gbps [11] and has been used in real-world censorship events in China [41] and Iran [7]. Marionette uses a novel template grammar system and a flexible plugin system to control the format of messages and how data is embedded. This allows the system to produce messages that match a range of DPI signatures, as demonstrated in Sections 7.1 and 7.2.

#### Proxies and Application Firewalls
Many large enterprise networks implement advanced proxy and application-layer firewall devices capable of deep analysis of protocols like FTP, HTTP, and SMTP [39]. These devices can cache data, apply protocol-specific content controls, and examine entire protocol sessions for signs of attacks. They often rewrite headers, multiplex connections, change protocol versions, and alter content (e.g., HTTP chunking). Although not commonly used by nation-states, these devices can handle large traffic volumes (e.g., 400TB/day [6]) and could potentially block many current obfuscation and mimicry systems. Marionette avoids these issues by using template grammars and a resilient record layer to combine several independent data-carrying fields into a message that is robust to reordering, changes to protocol headers, and connection multiplexing. The protocol compliance and proxy traversal capabilities of Marionette were demonstrated in Sections 7.2 and 7.3, respectively.

#### Recent Research
Recent work by Houmansadr et al. [20] and Geddes et al. [17] has presented several passive and active tests that censors could use to identify mimicry systems. Passive tests include examining dependent communication channels, while active tests involve dropping packets or preemptively closing connections to elicit expected actions. Additionally, the networking community has been developing methods to tackle traffic identification for over a decade [9], including specific methods for encrypted traffic [44].

To date, there is no evidence that these advanced methods have been applied in practice, likely due to two challenges. First, many proposed traffic analysis techniques require non-trivial amounts of state and machine learning algorithms that do not scale to multi-gigabit traffic volumes. Second, identifying rare events in large volumes of traffic (the base-rate fallacy) can generate overwhelming false positives. Sommer and Paxson [32] and Perry [29] provide detailed analyses of these issues.

Despite the current state of practice, technological developments or carefully controlled network environments may enable censors to apply these techniques. As shown in Section 7.4, Marionette can control multiple statistical features across simultaneous connections and respond to active probing and fingerprinting, as explored in Section 7.5.

#### Future Work
While our case studies cover a range of potential adversaries, several open questions and potential limitations remain. For example, the long-term state modeling capabilities of probabilistic I/O automata and the ability of template grammars to produce complex message content need further exploration. Additionally, the development of model specifications, which impact both unobservability and efficiency, requires more research.

### References
[1] Lantern. https://getlantern.org/.
[2] Metasploit. http://www.metasploit.com/.
[3] Nessus. http://www.tenable.com/.
[4] Nmap. https://nmap.org/.
[5] uProxy. https://uproxy.org/.
[6] Apache Traffic Server. http://trafficserver.apache.org/.
[7] Simurgh Aryan, Homa Aryan, and J. Alex Halderman. Internet Censorship in Iran: A First Look. In Presented as part of the 3rd USENIX Workshop on Free and Open Communications on the Internet, Berkeley, CA, 2013. USENIX.
[8] Chad Brubaker, Amir Houmansadr, and Vitaly Shmatikov. CloudTransport: Using Cloud Storage for Censorship-Resistant Networking. In Proceedings of the 14th Privacy Enhancing Technologies Symposium (PETS 2014), July 2014.
[9] A. Callado, C. Kamienski, G. Szabo, B. Gero, J. Kelner, S. Fernandes, and D. Sadok. A Survey on Internet Traffic Identification. IEEE Communications Surveys & Tutorials, 11(3):37–52, 2009.
[10] Jin Cao, William S. Cleveland, Yuan Gao, Kevin Jeffay, F. Donelson Smith, and Michele Weigle. Stochastic Models for Generating Synthetic HTTP Source Traffic. In Proceedings of IEEE INFOCOM, 2004.
[11] Cisco SCE 8000 Service Control Engine. http://www.cisco.com/c/en/us/products/collateral/service-exchange/sce-8000-series-service-control-engine/data_sheet_c78-492987.html, June 2015.
[12] Weidong Cui, Vern Paxson, Nicholas Weaver, and Randy H. Katz. Protocol-Independent Adaptive Replay of Application Dialog. In Proceedings of the 13th Annual Network and Distributed System Security Symposium (NDSS), February 2006.
[13] Holly Dagres. Iran Induces Internet 'Coma' Ahead of Elections. http://www.al-monitor.com/pulse/originals/2013/05/iran-internet-censorship-vpn.html, May 2013.
[14] Roger Dingledine, Nick Mathewson, and Paul Syverson. Tor: The Second-Generation Onion Router. In Proceedings of the 13th USENIX Security Symposium, 2004.
[15] Kevin P. Dyer, Scott E. Coull, Thomas Ristenpart, and Thomas Shrimpton. Protocol Misidentification Made Easy with Format-Transforming Encryption. In Proceedings of the 20th ACM Conference on Computer and Communications Security, November 2013.
[35] Matthias Vallentin, Robin Sommer, Jason Lee, Craig Leres, Vern Paxson, and Brian Tierney. The NIDS Cluster: Scalable, Stateful Network Intrusion Detection on Commodity Hardware. In Recent Advances in Intrusion Detection, pages 107–126. Springer, 2007.
[36] Qiyan Wang, Xun Gong, Giang Nguyen, Amir Houmansadr, and Nikita Borisov. CensorSpoofer: Asymmetric Communication using IP Spoofing for Censorship-Resistant Web Browsing. In The 19th ACM Conference on Computer and Communications Security, 2012.
[37] Michele C. Weigle, Prashanth Adurthi, Félix Hernández-Campos, Kevin Jeffay, and F. Donelson Smith. TMix: A Tool for Generating Realistic TCP Application Workloads in ns-2. SIGCOMM Comput. Commun. Rev., 36(3):65–76, July 2006.
[38] Zachary Weinberg, Jeffrey Wang, Vinod Yegneswaran, Linda Briesemeister, Steven Cheung, Frank Wang, and Dan Boneh. Stegotorus: A Camouflage Proxy for the Tor Anonymity System. In ACM Conference on Computer and Communications Security, 2012.
[39] D. Wessels and k. claffy. ICP and the Squid Web Cache. IEEE Journal on Selected Areas in Communications, 16(3):345–57, Mar 1998.
[40] Brandon Wiley. Dust: A Blocking-Resistant Internet Transport Protocol. Technical report, School of Information, University of Texas at Austin, 2011.
[41] Philipp Winter and Stefan Lindskog. How the Great Firewall of China is Blocking Tor. In Free and Open Communications on the Internet, 2012.
[42] Philipp Winter, Tobias Pulls, and Juergen Fuss. Scramblesuit: A Polymorphic Network Protocol to Circumvent Censorship. In Proceedings of the 12th ACM workshop on Workshop on privacy in the electronic society, pages 213–224. ACM, 2013.
[43] Charles V. Wright, Christopher Connelly, Timothy Braje, Jesse C. Rabek, Lee M. Rossey, and Robert K. Cunningham. Generating Client Workloads and High-Fidelity Network Traffic for Controllable, Repeatable Experiments in Computer Security. In Somesh Jha, Robin Sommer, and Christian Kreibich, editors, Recent Advances in Intrusion Detection, volume 6307 of Lecture Notes in Computer Science, pages 218–237. Springer Berlin Heidelberg, 2010.
[44] Charles V. Wright, Fabian Monrose, and Gerald M. Masson. On Inferring Application Protocol Behaviors in Encrypted Network Traffic. Journal on Machine Learning Research, 7, December 2006.
[45] Sue-Hwey Wu, Scott A. Smolka, and Eugene W. Stark. Composition and Behaviors of Probabilistic I/O Automata. Theoretical Computer Science, 176(1):1–38, 1997.
[46] T. Ylonen and C. Lonvick. The Secure Shell (SSH) Transport Layer Protocol. RFC 4253 (Proposed Standard), January 2006.
[47] Wenxuan Zhou, Amir Houmansadr, Matthew Caesar, and Nikita Borisov. Sweet: Serving the Web by Exploiting Email Tunnels. HotPETS. Springer, 2013.
[16] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach, and T. Berners-Lee. Hypertext Transfer Protocol – HTTP/1.1. RFC 2616 (Draft Standard), June 1999.
[17] John Geddes, Max Schuchard, and Nicholas Hopper. Cover Your ACKs: Pitfalls of Covert Channel Censorship Circumvention. In Proceedings of the 20th ACM Conference on Computer and Communications Security, pages 361–372. ACM, 2013.
[18] Andrew Griffin. WhatsApp and iMessage Could Be Banned Under New Surveillance Plans. The Independent, January 2015.
[19] Seung-Sun Hong and S. Felix Wu. On Interactive Internet Traffic Replay. In Proceedings of the 8th International Conference on Recent Advances in Intrusion Detection, RAID’05, pages 247–264, Berlin, Heidelberg, 2006. Springer-Verlag.
[20] Amir Houmansadr, Chad Brubaker, and Vitaly Shmatikov. The Parrot Is Dead: Observing Unobservable Network Communications. In The 34th IEEE Symposium on Security and Privacy, 2013.
[21] Amir Houmansadr, Thomas Riedl, Nikita Borisov, and Andrew Singer. I Want My Voice to Be Heard: IP over Voice-over-IP for Unobservable Censorship Circumvention. In Proceedings of the Network and Distributed System Security Symposium - NDSS’13. Internet Society, February 2013.
[22] Christopher M. Inacio and Brian Trammell. YAF: Yet Another Flowmeter. In Proceedings of the 24th International Conference on Large Installation System Administration, LISA’10, 2010.
[23] Sheharbano Khattak, Mobin Javed, Philip D. Anderson, and Vern Paxson. Towards Illuminating a Censorship Monitor’s Model to Facilitate Evasion. In Presented as part of the 3rd USENIX Workshop on Free and Open Communications on the Internet, Berkeley, CA, 2013. USENIX.
[24] Shuai Li, Mike Schliep, and Nick Hopper. Facet: Streaming Over Videoconferencing for Censorship Circumvention. In Proceedings of the 12th Workshop on Privacy in the Electronic Society (WPES), November 2014.
[25] Jeroen Massar, Ian Mason, Linda Briesemeister, and Vinod Yegneswaran. Jumpbox–A Seamless Browser Proxy for Tor Pluggable Transports. Security and Privacy in Communication Networks. Springer, page 116, 2014.
[26] Hooman Mohajeri Moghaddam, Baiyu Li, Mohammad Derakhshani, and Ian Goldberg. SkypeMorph: Protocol Obfuscation for Tor Bridges. In Proceedings of the 2012 ACM Conference on Computer and Communications Security, 2012.
[27] Katia Moskvitch. Ethiopia Clamps Down on Skype and Other Internet Use on Tor. BBC News, June 2012.
[28] Vern Paxson. Bro: A System for Detecting Network Intruders in Real-Time. In Proceedings of the 7th Conference on USENIX Security Symposium - Volume 7, SSYM’98, 1998.
[29] Mike Perry. A Critique of Website Traffic Fingerprinting Attacks. https://blog.torproject.org/, November 2013.
[30] J. Postel and J. Reynolds. File Transfer Protocol. RFC 959 (Standard), October 1985. Updated by RFCs 2228, 2640, 2773, 3659.
[31] Sam Small, Joshua Mason, Fabian Monrose, Niels Provos, and Adam Stubblefield. To Catch a Predator: A Natural Language Approach for Eliciting Malicious Payloads. In Proceedings of the 17th Conference on Security Symposium, 2008.
[32] R. Sommer and V. Paxson. Outside the Closed World: On Using Machine Learning for Network Intrusion Detection. In Security and Privacy (SP), 2010 IEEE Symposium on, 2010.
[33] Tcpreplay. http://tcpreplay.synfin.net/.
[34] Tor Project. Obfsproxy. https://www.torproject.org/projects/obfsproxy.html.en, 2015.