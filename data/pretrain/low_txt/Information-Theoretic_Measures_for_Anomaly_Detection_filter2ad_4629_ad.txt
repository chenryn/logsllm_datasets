### Averaging and Data Presentation

To simplify the presentation, we have plotted only the 4-day averages. The figure clearly illustrates that intrusion datasets exhibit significantly higher misclassification rates, distinctly separated from those of normal datasets. For normal data, models derived from more finely partitioned datasets demonstrate superior performance. Additionally, models incorporating temporal and statistical features also show enhanced performance on normal test data.

### Relationship Between Conditional Entropy and Misclassification Rate

It is worth noting that, in contrast to the results from experiments on sendmail data, the relationship between conditional entropy and misclassification rate is less clear here. This is because the added features can only approximate sequential dependencies. We are currently experimenting with the "placeholder" method (detailed in Section 2.4) to construct features that directly represent these dependencies.

### Discussion

In this section, we will discuss the advantages and limitations of our work.

#### Advantages

As demonstrated in our case studies, information-theoretic measures can be used to characterize regularity in audit data, thereby guiding the model building and evaluation process. In our experiments, we exhaustively computed models using different sequence lengths to illustrate the relationship between regularity and detection performance. Once this relationship is understood, in practice, we can simply compute the regularity of a given dataset and determine the appropriate model to build. Computing regularity is generally more efficient than computing a model, making our approach superior to the current ad-hoc and expensive trial-and-error methods, which lack guidelines for model building and performance explanation.

#### False Alarm Rate

False alarm rate is a critical performance metric for intrusion detection, particularly for anomaly detection. Given the probabilistic nature of anomaly detection, alarms should be post-processed to filter out sporadic false alarms due to inherent data uncertainty. For example, in sendmail data, we use the misclassification rate on the entire trace rather than individual misclassifications for anomaly detection. Similarly, for network connection data, we can use the misclassification rate over a time segment. We believe that anomalies within a single connection, such as a "buffer overflow" attack, can be best detected using models based on lower-level data, such as system call data of the target program. Regardless of the post-processing method, the model must maintain high accuracy (e.g., low misclassification rate for normal data). Therefore, regularity in audit data indirectly influences the false alarm rate.

#### Regularity and Detection Performance

We have not attempted to explain or reason why certain regularities exist in specific datasets. Our aim is to make our approach independent of assumptions about the underlying computing environment, as we strive to develop general theories and tools for anomaly detection. In practice, our approach can be complemented by expert domain knowledge to validate the computed regularity.

We have shown that there is a relationship between regularity and detection performance when the model is a classifier. Other probabilistic algorithms, such as clustering, Bayesian modeling, and Hidden Markov Models, can also be used for anomaly detection. Can similar information-theoretic measures be applied to these algorithms? More fundamentally, can we select the best algorithm based on the regularity of the data? These questions will be addressed in our future work.

#### Experiments with Regularity Measures

Our experiments with regularity measures on sequential dependencies, specifically conditional entropy, have been conducted on fixed sequence length or time window models. Debar et al. demonstrated that although a variable-length pattern matching model for sendmail data is more challenging to build, it can be more effective [5]. Similarly, using a variable time window based on network traffic load may improve detection performance. From a conditional entropy plot, we can estimate the performance of various sequence lengths (or time windows), build multiple models with different sequence lengths, and select an appropriate model to use at runtime based on the relative conditional entropy between the sequences in runtime and training. A better approach would be to build an adaptive model that dynamically adjusts to different lengths based on runtime information. We plan to extend our approach to facilitate the construction of such models.

### Related Work

Anomaly detection is a significant research area in intrusion detection. Early systems typically based normal profiles on statistical measures of system features, such as CPU usage and the number of shell commands [1, 11, 27]. Recent studies have applied learning-based approaches to build anomaly detection models using system call data of privileged programs [6, 7, 15, 29]. Lane et al. [12] proposed a learning algorithm for analyzing user shell command history to detect anomalies, addressing the "concept drift" problem. EMERALD [25] uses statistical anomaly detection modules to monitor network traffic and a "resolver" to correlate alarms from misuse and anomaly detectors across an enterprise. While these systems have achieved some success, they were developed for specific environments, and the fundamental question of how to build and evaluate anomaly detection models in general remains inadequately addressed.

Researchers have begun to develop principles and theories for intrusion detection. Axelsson [2] pointed out similarities between the established field of detection and estimation theory and the IDS domain. For example, the subject of an anomaly detection model corresponds to the "signal source" in detection and estimation theory, auditing mechanisms correspond to "signal transmission," and audit data corresponds to "observation space." Results from detection and estimation theory, applicable to a wide range of problems, may be useful in the IDS domain. One key finding by Axelsson is that both anomaly and intrusion data are needed to ensure detection performance. In previous work [17], we showed that using labeled training datasets with normal and intrusion connections, highly effective classifiers for intrusion detection can be built. However, obtaining intrusion data is difficult in practice. Therefore, this work focuses on building anomaly detection models when only normal data is available for training. Another key finding by Axelsson is that a detection model should be optimized for some utility function, not necessarily statistical accuracy, but possibly some definition of cost. We are studying how to build cost-sensitive IDS, i.e., an IDS that provides the best-valued protection [14].

The most related work is by Maxion et al. [22], where the relationship between data regularity and anomaly detection performance was studied. The study focused on sequence data, defining regularity as conditional entropy. The key result from experiments on synthetic data is that when an anomaly detection model is tested on datasets with varying regularity values, the detection performance also varies. This suggests that the current practice of deploying a particular anomaly detection system across different environments may be flawed and should be reconsidered. Our study confirmed this finding, showing that the expected detection performance can be attained only when the relative conditional entropy between the training and testing datasets is small. Our study is more extensive, using real system and network audit data in case studies and defining more information-theoretic measures to guide the construction of anomaly detection models.

### Conclusion and Future Work

In this paper, we proposed using information-theoretic measures for anomaly detection. Entropy can measure the regularity of an audit dataset of unordered records, while conditional entropy can measure the regularity of sequential dependencies in ordered records. Relative (conditional) entropy can measure the similarity between the regularity measures of two datasets. Information gain of a feature describes its power in classifying data items, and information cost measures the computational cost of processing audit data by an anomaly detection model. These measures can guide the model building process and explain the model's performance.

In the case studies on sendmail system call data, we showed that conditional entropy can determine the appropriate sequence length for accuracy or the trade-off between accuracy and cost, a problem posed but not solved by the community. We demonstrated that when relative conditional entropy is low, the detection performance on the testing dataset is comparable to that on the training dataset. In the case study on network data, we showed that entropy can direct the partitioning of a dataset and build better models. We also provided evidence that conditional entropy can guide the construction of temporal and statistical features.

Although our work is preliminary, we are encouraged by the results thus far. We aim to show that, despite the need for expert domain knowledge, theoretical understandings and tools are not only necessary but also possible. While our results may seem obvious, developing a formal framework to state and validate them is crucial for the rapid and rigorous progress of the intrusion detection field.

For future work, we plan to conduct more comprehensive experiments and evaluations. We will also study how to extend our information-theoretic measures to accommodate algorithms other than classification for building anomaly detection models, determine the best algorithm based on data regularity, and build models with variable sequence length or time window.

### Acknowledgments

This research is supported in part by grants from DARPA (F30602-00-1-0603). Roy Maxion of Carnegie Mellon University has provided insightful and valuable suggestions.

### References

[1] D. Anderson, T. Frivold, and A. Valdes. Next-generation intrusion detection expert system (NIDES): A summary. Technical Report SRI-CSL-95-07, Computer Science Laboratory, SRI International, Menlo Park, California, May 1995.

[2] S. Axelsson. A preliminary attempt to apply detection and estimation theory to intrusion detection. Technical report, Department of Computer Engineering, Chalmers University of Technology, Goteborg, Sweden, 2000.

[3] W. W. Cohen. Fast effective rule induction. In Machine Learning: the 12th International Conference, Lake Tahoe, CA, 1995. Morgan Kaufmann.

[4] T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley, 1991.

[5] H. Debar, M. Dacier, M. Nassehi, and A. Wespi. Fixed vs. variable-length patterns for detecting suspicious processes. In Proceedings of the 1998 ESORICS (LNCS 1485), 1998.

[6] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff. A sense of self for Unix processes. In Proceedings of the 1996 IEEE Symposium on Security and Privacy, pages 120-128, Los Alamitos, CA, 1996. IEEE Computer Society Press.

[7] A. K. Ghosh and A. Schwartzbard. A study in using neural networks for anomaly and misuse detection. In Proceedings of the 8th USENIX Security Symposium, August 1999.

[8] K. Ilgun, R. A. Kemmerer, and P. A. Porras. State transition analysis: A rule-based intrusion detection approach. IEEE Transactions on Software Engineering, 21(3):181-199, March 1995.

[9] V. Jacobson, C. Leres, and S. McCanne. tcpdump. Available via anonymous ftp to ftp.ee.lbl.gov, June 1989.

[10] S. Kumar and E. H. Spafford. A software architecture to support misuse intrusion detection. In Proceedings of the 18th National Information Security Conference, pages 194-204, 1995.

[11] L. A. N. Laboratory. Wisdom and sense guidebook. Los Alamos National Laboratory.

[12] T. Lane and C. E. Brodley. Temporal sequence learning and data reduction for anomaly detection. In Proceedings of the 5th ACM Conference on Computer & Communication Security, 1998.

[13] W. Lee. A Data Mining Framework for Constructing Features and Models for Intrusion Detection Systems. PhD thesis, Columbia University, June 1999.

[14] W. Lee, W. Fan, M. Miller, S. Stolfo, and E. Zadok. Toward cost-sensitive modeling for intrusion detection and response. In 1st ACM Workshop on Intrusion Detection Systems, 2000.

[15] W. Lee and S. J. Stolfo. Data mining approaches for intrusion detection. In Proceedings of the 7th USENIX Security Symposium, San Antonio, TX, January 1998.

[16] W. Lee, S. J. Stolfo, and P. K. Chan. Learning patterns from Unix process execution traces for intrusion detection. In AAAI Workshop: AI Approaches to Fraud Detection and Risk Management, pages 50-56. AAAI Press, July 1997.

[17] W. Lee, S. J. Stolfo, and K. W. Mok. A data mining framework for building intrusion detection models. In Proceedings of the 1999 IEEE Symposium on Security and Privacy, May 1999.

[18] R. Lippmann, D. Fried, I. Graf, J. Haines, K. Kendall, D. McClung, D. Weber, S. Webster, D. Wyschogrod, R. Cunningham, and M. Zissman. Evaluating intrusion detection systems: The 1998 DARPA off-line intrusion detection evaluation. In Proceedings of the 2000 DARPA Information Survivability Conference and Exposition, January 2000.

[19] R. Lippmann, J. Maines, D. Fried, J. Haines, J. Korba, and K. Das. Analysis and results of the 1999 DARPA off-line intrusion detection evaluation. In Proceedings of the 3rd International Workshop on Recent Advances in Intrusion Detection (RAID 2000). October 2000.

[20] T. Lunt. Detecting intruders in computer systems. In Proceedings of the 1993 Conference on Auditing and Computer Technology, 1993.

[21] T. Lunt, A. Tamaru, E. Gilham, R. Jagannathan, P. Neumann, H. Javitz, A. Valdes, and T. Garvey. A real-time intrusion detection expert system (IDES) - final technical report. Technical report, Computer Science Laboratory, SRI International, Menlo Park, California, February 1992.

[22] R. A. Maxion and K. M. C. Tan. Benchmarking anomaly-based detection systems. In Proceedings of the 1st International Conference on Dependable Systems & Networks, 2000.

[23] T. Mitchell. Machine Learning. McGraw-Hill, 1997.

[24] V. Paxson. Bro: A system for detecting network intruders in real-time. In Proceedings of the 7th USENIX Security Symposium, San Antonio, TX, 1998.

[25] P. A. Porras and P. G. Neumann. EMERALD: Event monitoring enabling responses to anomalous live disturbances. In National Information Systems Security Conference, Baltimore, MD, October 1997.

[26] C. E. Shannon and W. Weaver. The Mathematical Theory of Communication. University of Illinois Press, 1949.

[27] S. E. Smaha. Haystack: An intrusion detection system. In Proceedings of the IEEE Fourth Aerospace Computer Security Applications Conference, 1988.

[28] SunSoft. Solaris SHIELD Basic Security Module Guide. SunSoft, Mountain View, CA, 1995.

[29] C. Warrender, S. Forrest, and B. Pearlmutter. Detecting intrusions using system calls: Alternative data models. In Proceedings of the 1999 IEEE Symposium on Security and Privacy, May 1999.

[30] A. Wespi, M. Dacier, and H. Debar. Intrusion detection using variable-length audit trail patterns. In Proceedings of the 3rd International Workshop on Recent Advances in Intrusion Detection (RAID 2000), October 2000.