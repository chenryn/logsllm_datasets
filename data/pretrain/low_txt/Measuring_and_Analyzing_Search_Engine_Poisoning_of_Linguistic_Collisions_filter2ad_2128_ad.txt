### Search Engine Auto-Correction and Poisoning Analysis

**Introduction:**
This section analyzes the impact of auto-correction on search queries and the prevalence of malicious URLs in search results. The metrics "% Non-Auto-Corrected" and "% Poisoning" are used to quantify these effects. 

- **% Non-Auto-Corrected**: The percentage of queries for which the search engine does not offer auto-correction, either automatically or as a suggestion.
- **% Poisoning**: The percentage of non-auto-corrected queries that contain malicious URLs on the first page of search results.

The raw numbers of searches are provided in parentheses.

#### (a) English Experiment (on Google)
#### (b) Chinese Experiment (on Baidu)

**Figure 7: Comparison of Search Poisoning Rates Among Different Misspelling Types per Keyword Category**

- **Y-axis**: Percentage of searches containing malicious URLs on the first page of search results.
- **X-axis**: Categories and types of misspellings.
- **Categories**: Described in Section V-A. Note that the "Defense Contractors" category is only present in the English experiment.
- **Misspelling Types**:
  - **Original**: Correctly spelled terms.
  - **Showing-results-for**: Suggested corrected terms.
  - **Including-results-for**: Partially corrected terms.
  - **Did-you-mean**: Alternative suggested terms.
  - **Linguistic-collision (Non-auto-corrected)**: Terms not auto-corrected, as described in Section III.

**Auxiliary Information Collection:**

In addition to the search results from Google and Baidu, we collected data from VirusTotal, Google Adwords, Google Translate, and Baidu Index to enhance our analysis.

- **VirusTotal**: Identified URLs with suspicious activity. We scanned 2.06M URLs, of which 1.18% (24.4k) were flagged by at least one scanner. Manual spot-checks using a virtual machine identified 5,256 malicious URLs under 2,743 domains.
- **Google Adwords Keyword Planner**: Checked device breakdown estimates for 117,791 uncorrected misspellings and 12,943 original keywords.
- **Google Detect Language API**: Collected 105,978 predictions for uncorrected misspellings to understand language distribution across categories.

**Results of RNN Model:**

- **Model Configuration**: 150 hidden layers, sequence length of 5 characters, vocabulary size of 37 characters (lower-case alphanumerics and a null character).
- **Training**: Used 4 servers with 24 GB RAM and 16 CPU cores each. Trained on a wordlist with 675,903 unique words.
- **Validation**: Used ground truth data from the Alexa top 1,000 misspellings.
- **Performance**: The RNN outperformed dictionary checking and other algorithms. For the Alexa 1,001–10,000, the RNN achieved a non-auto-corrected rate of 38.04% with 23,236 uncorrected misspellings, providing a 2.84x improvement over random sampling.

**Table II: Data Collection Statistics Based on Alexa Top List**

- **Alexa Rank Range**: 1–100, 101–1,000, 1,001–10,000.
- **Metrics**: % Non-Auto-Corrected, # Misspell Candidates, Poisoning Rate.
- **Note**: Results for the Alexa 1,001–10,000 are based on RNN predictions.

**Section VI: Measurement and Discoveries**

**A. Landscape and Comparison of Misspelling Search Results:**

- **Pervasiveness of Linguistic-Collision Misspellings**: 15.16% of English and 7.69% of Chinese misspellings are not auto-corrected.
- **Blacklist Statistics**: 1,511 URLs from first-page results of non-auto-corrected searches were found to be malicious.
- **Per-Category Results**: Table I provides detailed statistics, showing that linguistic-collision misspellings have a higher poisoning rate (1.19%) compared to other types of misspellings.

**B. Characteristics of Linguistic-Collision Search Results:**

- **Comparison of Misspelling Generation**: 
  - **English**: Wrong vowel substitution method produced a higher non-auto-corrected rate (22.85%) compared to edit-distance 1 (15.16%).
  - **Chinese**: Same pronunciation and fuzzy pinyin methods had higher non-auto-corrected rates (18.21% and 17.63%) compared to edit distance 1 (7.69%).
- **Language Distribution**: Google Translate API detected 74 languages in uncorrected misspellings, with many being valid words in other languages.

**Conclusion:**

Linguistic-collision misspellings are a significant vector for search poisoning, particularly in categories like "Drugs," "Gambling," and "Adult Terms." The RNN model effectively identifies high-risk misspellings, improving the detection of malicious URLs. Future work should focus on enhancing search engine protections against these vulnerabilities.