### Challenges to Existing Computer Vision Methods

Two significant challenges arise for existing computer vision methods, which typically assume consistent appearance and visually distinctive foregrounds [52]. However, our user study indicates that people had little difficulty solving these CAPTCHAs. This suggests that current CAPTCHA designs are still effective against today's attacks.

### Future Directions for MIOR CAPTCHAs

Looking ahead, greater robustness in MIOR CAPTCHAs could be achieved if automated attacks were required to perform classification, categorization of classes with high intra-class variance, or identification of higher-level semantics to understand the presented challenge. For example, a user might be shown two objects (a person and a truck) at the same scale and asked to identify which one is larger. To succeed, an automated attack would need to determine the objects (without prior knowledge) and then understand the relationship. Humans can perform this task due to the inherent priors learned from daily life, but it remains a challenging problem in computer vision. This combination offers a balanced approach and aligns with the ideas proposed by Naor [34] and von Ahn et al. [1], suggesting that using hard (and useful) underlying AI problems in CAPTCHAs creates a win-win situation: either the CAPTCHA remains unbroken and distinguishes between humans and computers, or it is broken, and a valuable problem is solved.

### Acknowledgments

The authors thank Pierre Georgel, Joseph Tighe, and Avi Rubin for their insightful discussions and valuable feedback on an earlier draft of this manuscript. We are also especially grateful to Fletcher Fairey (of the Office of University Counsel at Chapel Hill), Cindy Cohn, and Marcia Hofmann (of the Electronic Frontier Foundation) for their guidance and assistance in making our findings available to NuCaptcha in a timely manner. Sonia Chiasson holds a Canada Research Chair in Human-Oriented Computer Security, and Paul Van Oorschot holds a Canada Research Chair in Authentication and Computer Security. Both acknowledge the Natural Sciences and Engineering Research Council of Canada (NSERC) for funding the Chairs and Discovery Grants, as well as funding from NSERC ISSNet. This work is also supported by the National Science Foundation (NSF) under award number 1148895.

### Notes

1. In cases where the foreground characters have varying appearances, we use multiple modes.
2. Readers can view videos of the Emerging Images concept [31] at http://graphics.stanford.edu/~niloy/research/emergence/emergence_image_siga_09.html.
3. See the Security Features discussed at http://www.nucaptcha.com/features/security-features, 2012.
4. One participant opted to view only six challenges in each of the Extended and Emerging variants. We count the remaining four as skips.

### References

[1] L. V. Ahn, M. Blum, N. J. Hopper, and J. Langford. CAPTCHA: Using hard AI problems for security. In Eurocrypt, pages 294–311, 2003.
[2] A. Basso and F. Bergadano. Anti-bot strategies based on human interactive proofs. In P. Stavroulakis and M. Stamp, editors, Handbook of Information and Communication Security, pages 273–291. Springer, 2010.
[3] E. Bursztein. How we broke the NuCaptcha video scheme and what we proposed to fix it. See http://elie.im/blog/security/how-we-broke-the-nucaptcha-video-scheme-and-what-we-propose-to-fix-it/, Accessed March, 2012.
[4] E. Bursztein and S. Bethard. DeCAPTCHA: Breaking 75% of eBay audio CAPTCHAs. In Proceedings of the 3rd USENIX Workshop on Offensive Technologies, 2009.
[5] E. Bursztein, S. Bethard, C. Fabry, J. C. Mitchell, and D. Jurafsky. How good are humans at solving CAPTCHAs? A large-scale evaluation. In IEEE Symposium on Security and Privacy, pages 399–413, 2010.
[6] E. Bursztein, R. Beauxis, H. Paskov, D. Perito, C. Fabry, and J. C. Mitchell. The failure of noise-based non-continuous audio CAPTCHAs. In IEEE Symposium on Security and Privacy, pages 19–31, 2011.
[7] E. Bursztein, M. Martin, and J. Mitchell. Text-based CAPTCHA strengths and weaknesses. In Proceedings of the 18th ACM conference on Computer and Communications Security, pages 125–138, 2011.
[8] K. Chellapilla, K. Larson, P. Y. Simard, and M. Czerwinski. Designing human-friendly human interaction proofs (HIPs). In ACM Conference on Human Factors in Computing Systems, pages 711–720, 2005.
[9] K. Chellapilla, K. Larson, P. Y. Simard, and M. Czerwinski. Building segmentation-based human-friendly human interaction proofs (HIPs). In Human Interactive Proofs, Second International Workshop, pages 1–26, 2005.
[10] J. Cui, W. Zhang, Y. Peng, Y. Liang, B. Xiao, J. Mei, D. Zhang, and X. Wang. A 3-layer Dynamic CAPTCHA Implementation. In Workshop on Education Technology and Computer Science, volume 1, pages 23–26, March 2010.
[11] J.-S. Cui, J.-T. Mei, X. Wang, D. Zhang, and W.-Z. Zhang. A CAPTCHA Implementation Based on 3D Animation. In International Conference on Multimedia Information Networking and Security, volume 2, pages 179–182, November 2009.
[12] J.-S. Cui, J.-T. Mei, W.-Z. Zhang, X. Wang, and D. Zhang. A CAPTCHA Implementation Based on Moving Objects Recognition Problem. In International Conference on E-Business and E-Government, pages 1277–1280, May 2010.
[13] J. J. DiCarlo and D. D. Cox. Untangling invariant object recognition. Trends in Cognitive Sciences, 11:333–341, 2007.
[14] J. Driver and G. Baylis. Edge-assignment and figure-ground segmentation in short-term visual matching. Cognitive Psychology, 31:248–306, 1996.
[15] M. Egele, L. Bilge, E. Kirda, and C. Kruegel. CAPTCHA smuggling: Hijacking web browsing sessions to create CAPTCHA farms. In Proceedings of the ACM Symposium on Applied Computing, pages 1865–1870, 2010.
[16] J. Elson, J. R. Douceur, J. Howell, and J. Saul. Asirra: A CAPTCHA that exploits interest-aligned manual image categorization. In Proceedings of the ACM Conference on Computer and Communications Security, pages 366–374, 2007.
[17] M. Fischler and R. Bolles. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. Comm. of the ACM, 24(6):381–395, 1981.
[18] N. Friedman and S. Russell. Image segmentation in video sequences: A probabilistic approach. University of California, Berkeley, 94720, 1776.
[19] P. Golle. Machine learning attacks against the Asirra CAPTCHA. In Proceedings of the ACM Conference on Computer and Communications Security, pages 535–542, 2008.
[20] K. Grill-Spector and N. Kanwisher. Visual recognition: As soon as you know it is there, you know what it is. Psychological Science, 16(2):152–160, 2005.
[21] C. Harris and M. Stephens. A combined corner and edge detection. In Proceedings of The Fourth Alvey Vision Conference, volume 15, pages 147–151, 1988.
[22] J. M. G. Hidalgo and G. Alvarez. CAPTCHAs: An Artificial Intelligence Application to Web Security. Advances in Computers, 83:109–181, 2011.
[23] A. Jain, M. Murty, and P. Flynn. Data clustering: A review. ACM computing Surveys, 31(3):264–323, 1999.
[24] K. A. Kluever and R. Zanibbi. Balancing usability and security in a video CAPTCHA. In Proceedings of the 5th Symposium on Usable Privacy and Security, pages 1–14, 2009.
[25] J. Lazar, J. H. Feng, and H. Hochheiser. Research Methods in Human-Computer Interaction. John Wiley and Sons, 2010.
[26] W.-H. Liao and C.-C. Chang. Embedding information within dynamic visual patterns. In Multimedia and Expo, IEEE International Conference on, volume 2, pages 895–898, June 2004.
[27] R. Lowry. Concepts and Applications of Inferential Statistics. Vassar College, http://faculty.vassar.edu/lowry/webtext.html, 1998.
[28] B. Lucas and T. Kanade. An iterative image registration technique with an application to stereo vision. In International Joint Conference on Artificial Intelligence (IJCAI), pages 674–679, 1981.
[29] D. Marr. Vision: A computational investigation into the human representation and processing of visual information. W. H. Freeman, San Francisco, 1982.
[30] D. Marr and T. Poggio. A computational theory of human stereo vision. Proceedings of the Royal Society of London. Series B, Biological Sciences, 204(1156):301–328, 1979.
[31] N. J. Mitra, H.-K. Chu, T.-Y. Lee, L. Wolf, H. Yeshurun, and D. Cohen-Or. Emerging images. ACM Transactions on Graphics, 28(5), 2009.
[32] G. Mori and J. Malik. Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA. In Computer Vision and Pattern Recognition, volume 1, pages 134–141, June 2003.
[33] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy, G. M. Voelker, and S. Savage. Re: CAPTCHAs—Understanding CAPTCHA-solving services in an economic context. In USENIX Security Symposium, pages 435–462, 2010.
[34] M. Naor. Verification of a human in the loop or identification via the Turing test, 1996.
[35] NuCaptcha. Whitepaper: NuCaptcha & Traditional CAPTCHA, 2011. http://nucaptcha.com.
[36] A. Oliva and A. Torralba. The role of context in object recognition. Trends in Cognitive Sciences, 11(12):520–527, 2007.
[37] S. Ray and R. Turi. Determination of number of clusters in k-means clustering and application in colour image segmentation. In Proceedings of the International conference on advances in pattern recognition and digital techniques, pages 137–143, 1999.
[38] M. Shirali-Shahreza and S. Shirali-Shahreza. Motion CAPTCHA. In Conference on Human System Interactions, pages 1042–1044, May 2008.
[39] P. Simard, D. Steinkraus, and J. Platt. Best practices for convolutional neural networks applied to visual document analysis. In Proceedings of the Seventh International Conference on Document Analysis and Recognition, volume 2, pages 958–962, 2003.
[40] Y. Soupionis and D. Gritzalis. Audio CAPTCHA: Existing solutions assessment and a new implementation for VoIP telephony. Computers & Security, 29(5):603–618, 2010.
[41] S. Thorpe, D. Fize, and C. Marlot. Speed of processing in the human visual system. Nature, 381(6582):520–522, 1996.
[42] S. Ullman. Computational studies in the interpretation of structure and motion: Summary and extension. In Human and Machine Vision. Academic Press, 1983.
[43] S. Ullman. High-Level Vision: Object Recognition and Visual Cognition. The MIT Press, 1st edition, July 2000.
[44] A. Vedaldi and B. Fulkerson. VLFeat: An open and portable library of computer vision algorithms. In Proceedings of the international conference on Multimedia, pages 1469–1472, 2010.
[45] P. A. Viola and M. J. Jones. Rapid object detection using a boosted cascade of simple features. In Computer Vision and Pattern Recognition, 2001.
[46] L. von Ahn, M. Blum, and J. Langford. Telling humans and computers apart automatically. Commun. ACM, 47:56–60, February 2004.
[47] J. Yan and A. S. E. Ahmad. Breaking visual CAPTCHAs with naive pattern recognition algorithms. In ACSAC, pages 279–291, 2007.
[48] J. Yan and A. S. E. Ahmad. A low-cost attack on a Microsoft CAPTCHA. In ACM Conference on Computer and Communications Security, pages 543–554, 2008.
[49] J. Yan and A. S. E. Ahmad. Usability of CAPTCHAs or usability issues in CAPTCHA design. In SOUPS, pages 44–52, 2008.
[50] J. Yan and A. El Ahmad. CAPTCHA robustness: A security engineering perspective. Computer, 44(2):54–60, February 2011.
[51] J. Yan and M. Pollefeys. Articulated motion segmentation using RANSAC with priors. Dynamical Vision, pages 75–85, 2007.
[52] A. Yilmaz, O. Javed, and M. Shah. Object tracking: A survey. ACM Comput. Surv., 38, December 2006.
[53] B. B. Zhu, J. Yan, Q. Li, C. Yang, J. Liu, N. Xu, M. Yi, and K. Cai. Attacks and design of image recognition CAPTCHAs. In ACM Conference on Computer and Communications Security, pages 187–200, 2010.

### Parameters for Video Generation

Similar to NuCaptcha’s videos, our sequences feature letters moving across a background scene with constant horizontal velocity and harmonic vertical movement (i.e., \( y(t) = A \cdot \sin(\omega t + \psi) \), where \( y \) is the vertical position of the letter, \( t \) is the frame ID, and \( A, \omega, \psi \) are adjustable parameters). The horizontal distance between two letters is a function of their average width. If their widths are \( \text{width}_1 \) and \( \text{width}_2 \), the distance between their centers is set to be \( \alpha \cdot (\text{width}_1 + \text{width}_2) \), where \( \alpha \) is an adjustable parameter indicating the overlap. Our letters also rotate and loop around. The angle \( \theta \) to which a letter rotates is decided by a sine function \( \theta = \theta_0 \cdot \sin(\omega_\theta t + \psi_\theta) \), where \( \theta_0, \omega_\theta, \psi_\theta \) are adjustable parameters. For the standard case, we set the parameters the same as in NuCaptcha’s videos. These parameters are adjusted based on the type of defenses explored in Section 5.2.

### User Study Comments

Table 2 highlights some of the free-form responses written on the questionnaire used in our study.

| **Variant** | **Comments** |
|-------------|--------------|
| **Standard** | - User friendly<br>- It was too easy<br>- Much easier than traditional CAPTCHAs |
| **Extended** | - My mother would not be able to solve these<br>- Giant Pain in the Butt! Sheer mass of text was overwhelming and I got lost many times<br>- Too long! I would prefer a shorter text<br>- It was very time-consuming, and is very prone to mistakes<br>- Letters too bunched – several loops needed to decipher<br>- Takes longer because I had to wait for the letter to move a bit so I can see more of it<br>- Still had a dizzying effect. Not pleasant<br>- Some characters were only partially revealed, ‘Y’ looked like a ‘V’<br>- Tree background is unreadable, any non-solid background creates too much interference<br>- With some backgrounds, I almost didn’t realize there were red letters<br>- It was almost faded and very time-consuming. I think I made more mistakes in this mechanism<br>- Not that complicated<br>- I’d feel dizzy after staring at it for more than 1 minute<br>- It was hideous! Like an early 2000s website. But it did do the job. It made my eyes feel ‘fuzzy’ after a while<br>- It was good, better than the challenges with lines through letters |

### Table 2: Sample Participant Comments for Each Variant

This table provides a summary of the user feedback for each variant of the CAPTCHA, highlighting both positive and negative aspects.