# NeurIPS 2020 论文解读：基于跨模态检索的二进制代码-源代码匹配

## 译文声明
本文为翻译文章，具体内容和含义以原文为准。

## 导语
在NeurIPS 2020中，腾讯安全科恩实验室的研究论文《CodeCMR: Cross-Modal Retrieval for Function-Level Binary-Source Code Matching》成功入选。该论文首次提出了一种基于AI的端到端二进制代码与源代码匹配算法，相比传统方法，其准确率显著提升。这项研究为逆向分析领域提供了新的思路，并大大提高了工业部署效率。最新研究成果将应用于腾讯安全科恩实验室开发的代码检索工具BinaryAI。

## 关于NeurIPS会议
NeurIPS（神经信息处理系统会议）是人工智能领域最具影响力的顶级学术会议之一，备受学者关注。NeurIPS 2020于2020年12月7日至12日在线上举行。据统计，此次会议共收到9454篇投稿，创历史最高纪录，最终接收了1900篇论文，接收率为历史最低的20.1%。

## 背景
### 论文链接
[CodeCMR: Cross-Modal Retrieval for Function-Level Binary-Source Code Matching](neurips_2020_cameraready.pdf)

在AAAI 2020中，腾讯安全科恩实验室利用图神经网络解决了二进制程序函数相似性分析问题，引起了广泛关注。在此基础上，本次研究进一步扩展到二进制代码与源代码的交叉领域，继续探索AI在安全领域的应用。

二进制代码-源代码匹配是信息安全领域的重要研究方向。逆向分析研究人员希望在给定二进制代码的情况下找到对应的源代码，从而提高分析效率和准确性。然而，由于源代码和二进制代码之间的差异，这一领域的研究相对较少。传统方法如B2SFinder和BinPro通过提取字符串和立即数等特征进行匹配，但这些方法在函数级别的匹配准确率较低，且设计合适的特征需要大量专家经验。

图1展示了函数的源代码和二进制代码示例。从图中可以看出，除了字符串和立即数特征外，代码中的语义特征也非常重要。因此，本文旨在设计一种端到端模型，能够自动提取代码间的语义特征，从而提高匹配准确率。

![图1 – 二进制代码与对应的源代码](图1)

## 模型
本研究将二进制代码-源代码匹配任务视为一个跨模态检索问题，类似于图文互搜。为此，我们设计了CodeCMR框架（见图2），这是一种常见的跨模态检索结构。在计算最终向量之前，两个模态之间没有信息传递，因此可以预先计算向量，节省线上计算时间和存储空间。

![图2 – CodeCMR整体框架](图2)

## 整体结构
模型的输入包括源代码特征和二进制代码特征两部分。源代码特征包括字符级源代码、从中提取的字符串和立即数；二进制代码特征包括控制流图、二进制代码的字符串和立即数。首先，使用不同模型分别计算三个输入（语义特征、字符串特征、立即数特征）的向量，然后通过拼接和BatchNorm得到代码向量，最后使用triplet loss作为损失函数。

在这个基础框架上，有许多改进的创新点，例如使用预训练模型进行语义融合、使用对抗损失对齐向量等，将在后文详细讨论。

![图3 – 源代码与二进制代码的语义模型](图3)

## 语义模型
对于字符级源代码，我们使用DPCNN模型；对于二进制控制流图，我们使用端到端的GNN模型。在函数级别，字符级源代码的输入通常超过4096个字符，DPCNN的效果远优于TextCNN和LSTM。对于控制流图，我们采用端到端训练的方式，而不是使用BERT预训练的node embedding，取得了更好的效果。

尽管本文使用了DPCNN和GNN，但ASTNN等树模型也同样值得尝试。由于输入是函数级别的代码，缺少#define、#include等重要信息，需要设计合适的编译工具将源代码转化为抽象语法树（AST）。相比之下，直接将文本作为输入的优点是无需额外的专家经验，具有更强的健壮性。

## 立即数、字符串模型
对于源代码和二进制代码的立即数和字符串，我们也设计了相应的匹配模型。

对于立即数，我们设计了一种Integer-LSTM，其输入包括integer token和integer number。integer number作用于LSTM的输入门和输出门，从而控制信息流动。

对于字符串，我们使用层次模型，先用LSTM模型得到每个字符串的向量，再通过sum pooling方法得到字符串集合的向量。

## Norm Weighted Sampling
在得到源代码和二进制代码的向量后，我们设计了一种采样方法。在度量学习领域，损失函数和采样方法是两个重要的模块。为了克服hard样本在训练早期收敛到局部极小值的问题，提出了semi-hard采样方法。然而，这种方法可能会在某个时间段停止训练。为此，本文提出了一种改进的norm weighted sampling方法，通过增加一个超参数s来调整概率分布，从而适应不同的任务和数据集。

## 实验
### 数据集与评测指标
本文使用gcc-x64-O0和clang-arm-O3两种编译器组合方式，制作了包含30000/10000/10000个样本的训练/验证/测试集，并使用recall@1和recall@10作为评测指标。数据集已公开发布。

### 实验结果
如表1所示，本文提出的方法相比传统方法有显著提升，这符合我们的预期，表明代码间的隐含语义特征十分重要。在语义模型中，DPCNN+HBMP取得了最佳效果，说明在二进制侧进行端到端训练优于预训练的node embedding。与随机采样和distance weighted采样方法相比，norm weighted采样效果更好。图4显示了训练和验证的损失函数曲线，当s=5时，norm weighted sampling的train loss更高但valid loss更低，表明采样到了更合适的样本对。

![表1 – 实验结果](表1)
![图4 – 训练与验证的损失函数曲线](图4)

## 讨论与总结
### 讨论
基于CodeCMR框架，有许多值得尝试的创新方向：
1. **代码编码器**：ASTNN、Tree-LSTM、Transformer等模型可能同样有效。
2. **其他损失函数和采样方法**：如AM-softmax、Circle loss等。
3. **对抗训练及其他跨模态检索方法**。
4. **预训练算法**：在获得最终向量前，两个模态没有信息融合，因此可以在两个模态分别单独预训练或使用跨语言模型的方法进行融合训练。

### 总结
本文针对二进制代码-源代码匹配任务提出了CodeCMR框架，成功利用了源代码与二进制代码间的语义特征。与传统方法相比，取得了显著突破。

## 参考文献
1. Yuan Z, Feng M, Li F, et al. B2SFinder: Detecting Open-Source Software Reuse in COTS Software[C]//2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2019: 1038-1049.
2. Miyani D, Huang Z, Lie D. Binpro: A tool for binary source code provenance[J]. arXiv preprint arXiv:1711.00830, 2017.
3. Wang H, Sahoo D, Liu C, et al. Learning cross-modal embeddings with adversarial networks for cooking recipes and food images[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019: 11572-11581.
4. Wang B, Yang Y, Xu X, et al. Adversarial cross-modal retrieval[C]//Proceedings of the 25th ACM international conference on Multimedia. 2017: 154-162.
5. Schroff F, Kalenichenko D, Philbin J. Facenet: A unified embedding for face recognition and clustering[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 815-823.
6. Johnson R, Zhang T. Deep pyramid convolutional neural networks for text categorization[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. 2017: 562-570.
7. Yu Z, Cao R, Tang Q, et al. Order Matters: Semantic-Aware Neural Networks for Binary Code Similarity Detection[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(01): 1145-1152.
8. Wu C Y, Manmatha R, Smola A J, et al. Sampling matters in deep embedding learning[C]//Proceedings of the IEEE International Conference on Computer Vision. 2017: 2840-2848.

## 阅读原文
[neurips_2020_cameraready.pdf](neurips_2020_cameraready.pdf)