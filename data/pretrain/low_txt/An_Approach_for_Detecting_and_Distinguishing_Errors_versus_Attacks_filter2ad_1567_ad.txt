### 9.1 to 10.0 Time [day] and Observed Data

- **Time [day]**: 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10
- **Percentage (%)**:
  - 110
  - 100
  - 90
  - 80
  - 70
  - 60
  - 50
  - 40
  - 30
  - 20
  - 10
  - 0

**Observed Data:**
- **Faulty**
- **Correct**

### Figure 10: Dynamic Deletion Attack
- **(a) Attack on the temperature readings.**
- **(b) Attack on the humidity readings.**

### Table 6: BCO Matrix for Malicious Sensor 7 (Dynamic Deletion Attack)
- **i ↓, j →**:
  - (29,56): 0.001
  - (20,71): 0.999
  - (13,78): 0.001
  - (0,95): 0.001
  - (12,94): 0.001
  - (0,0): 0.001

### Injection Experiment for Dynamic Creation Attacks
- In the considered example, malicious nodes inject high temperature values and low humidity values into the system to force a change in the overall, observed state of the environment, whereas the correct environmental temperature and humidity remain approximately constant (see Fig. 11).
- **Table 7: BCO Matrix for Malicious Sensor 2 (Dynamic Creation Attack)**
  - **i ↓, j →**:
    - (17,86): 1
    - (31,56): 0
    - (18,78): 0
    - (12,95): 0
    - (25,69): 0.3546, 0.6454

### Figure 11: Dynamic Creation Attack
- **(a) Attack on the temperature readings.**
- **(b) Attack on the humidity readings.**

### 4.3 Alarm Generation
- **Figure 12: Raw Alarms Generated for a Faulty and a Non-Faulty Node**
  - The generated alarms clearly indicate the absence and presence of an anomaly, but the raw alarm data are quite noisy (e.g., 1.5% false alarm rate for the non-faulty sensor), requiring appropriate filtering to smoothen them.

### 5. Related Work
- **Markov Models in Anomaly Detection:**
  - Markov models have been widely used in anomaly detection systems [5, 6, 11–14].
  - In [11], a Markov chain is estimated using a training suite and then used to classify normal versus anomalous behavior.
  - In [13], a Markov model is used to detect attacks against web-servers and web-based applications.
  - Nong Ye et al. [14] analyze the robustness of a Markov chain-based approach to anomaly detection and conclude that Markov chains perform well only under low noise levels in the data.
  - Hidden Markov Models (HMMs) provide a more powerful mathematical tool than standard Markov models and have also been explored in the domain of anomaly detection [5, 6].

### 6. Conclusions
- This paper proposes an on-the-fly statistical technique to detect and distinguish faulty data from malicious data in a distributed sensor network.
- The technique can learn the correct system behavior dynamically with no separate training phase by exploiting the natural redundancy present in sensor networks.
- It can classify faults versus attacks based on structural relations between two types of Hidden Markov Models learned.
- The proposed mathematical framework can be generalized for different types of distributed computing environments.
- Future work includes applying the methodology to monitor intrusions and failures in a large cluster of machines dedicated to running an e-commerce application.

### Acknowledgments
- This work is supported in part by MURI grant N00014-01-1-0576, the Gigascale Systems Research Center (GSRC/MARCO), and the Motorola Corporation as part of Motorola Center.

### References
- [1] R. Szewczyk, J. Polastre, A. Mainwaring, and D. Culler. Lessons from a sensor network expedition. In Proc. of European Workshop on Wireless Sensor Networks, 2004.
- [2] A. D. Wood and J. A. Stankovic. Denial of service in sensor networks. IEEE Computer, 35(10):54–62, Oct. 2002.
- [3] C. Karlof and D. Wagner. Secure routing in wireless sensor networks: Attacks and countermeasures. In First IEEE International Workshop on Sensor Network Protocols and Applications, pages 113–127, May 2003.
- [4] B. Przydatek, D. Song, and A. Perrig. Sia: Secure information aggregation in sensor networks. In Proc. of SenSys, 2003.
- [5] C. Warrender, S. Forrest, and B. A. Pearlmutter. Detecting intrusions using system calls: Alternative data models. In IEEE Symposium on Security and Privacy, pages 133–145, 1999.
- [6] S.-J. Cho and S.-J. Han. Two sophisticated techniques to improve HMM-based intrusion detection systems. LNCS, 2820:207–219, 2003.
- [7] A. Mainwaring, J. Polastre, R. Szewczyk, D. Culler, and J. Anderson. Wireless Sensor Networks for Habitat Monitoring. In Proceedings of the 1st ACM International Workshop on Wireless Sensor Networks and Applications, pages 88–97, 2002.
- [8] L. R. Rabiner. A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition. IEEE Proceedings, 77(2):257–286, 1989.
- [9] M. Basseville and I. Nikiforov. Detection of abrupt changes: theory and application. Information and system science series. Prentice Hall, Englewood Cliffs, NJ, 1993.
- [10] J. Stiller and G. Radons. Online estimation of hidden Markov models. IEEE Signal Processing Letters, 6(8):213–215, 1999.
- [11] S. Jha, K. Tan, and R. A. Maxion. Markov Chains, Classifiers, and Intrusion Detection. In Proceedings of the 14th IEEE Workshop on Computer Security Foundations, page 206, 2001.
- [12] M. Nassehi. Anomaly Detection for Markov Models. Technical Report RZ 3011 (93057), IBM Research Division, Zurich Research Laboratory, 1998.
- [13] C. Kruegel and G. Vigna. Anomaly Detection of Web-based Attacks. In Proceedings of the 10th ACM Conference on Computer and Communications Security, pages 251–261, 2003.
- [14] N. Ye, Y. Zhang, and C. M. Boror. Robustness of the Markov Chain Model for Cyber-Attack Detection. IEEE Transactions on Reliability, 53(1), March 2004.

**Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06)**
- 0-7695-2607-1/06 $20.00 © 2006 IEEE
- Authorized licensed use limited to: Tsinghua University. Downloaded on March 19, 2021, at 12:29:25 UTC from IEEE Xplore. Restrictions apply.