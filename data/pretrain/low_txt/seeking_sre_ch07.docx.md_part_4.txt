### 初始阶段：Spotify 的队列管理工具

在 Spotify 的早期，我们构建并使用了一套工具来管理新生的队列。这些工具假设服务器一旦安装并投入使用，就会持续运行直到退役。此外，还假设预配新服务器是一个不常见的事件，每月仅需执行几次。因此，安装服务器的工具运行时间较长（几分钟），并且需要频繁的手动干预是可以接受的。从开始到结束，一批服务器的安装可能需要一个小时到一个完整的工作日。

### 2011 年的变化

然而，到了 2011 年，我们发现新服务器的安装频率远远超过预期。虽然重新利用服务器是一个已知的过程，但经常出现的问题迫使运维团队手动介入修复。对于一家拥有少量服务器的小型公司来说，这种情况并不罕见或不可接受。但在当时，Spotify 已经拥有两个数据中心，并且正在启用第三个数据中心。随着服务器数量的激增，这种手动干预变得越来越难以维持。

### 打破旧习惯

业内的运维模式正在发生变化，尽管一些人预见到了这一点，但具体的影响和对服务可用性的影响尚不清楚。对我们而言，这种转变非常明确：我们需要调整硬件以适应我们的意图，而不是调整意图以适应硬件。这一转变对许多人来说很难接受，因为我们在日常工作中已经习惯了现有的方式。事实上，这种心态的改变花了几年时间才完全实现，部分原因是创建新的工具以支持这种变化需要时间。

### 组织变革

2011 年底，另一个重要的转变开始了：功能开发人员开始以不同的方式组织自己。午餐时，我们听到开发人员讨论自主自组织团队以及他们所属的“章节”。虽然我们仍然可以与他们讨论服务和用户，但对话现在更多地关注产品和利益相关者。整个开发部门正在缓慢过渡到一个可扩展的敏捷组织，而运维部门则在一旁观察这一变化。

从运维团队的角度来看，这种组织变革最令人不安的是它对我们角色的影响。命名从“开发团队”变为“团队”，加上对自主性和自我组织性的重视，挑战了我们习惯的中心地位。小队又被分组成所谓的“部落”，这些部落也有明确的自主和自我组织意图。运维团队现在面对的是多个结构略有不同的部落，几乎没有保持同质化的迹象。

### 关键收获

这一时期的主要学习点包括：
- 将思维模式从以服务器为中心转变为以服务为中心，并使工具反映这一点。
- 敏捷矩阵组织模型的引入迫使我们重新思考运维的定位。

### 无法扩展的系统：2012 年

- 近 25 名运维工程师
- 近 70 名后端工程师
- 三个数据中心，几千台服务器
- 近 50 个后端服务

#### 前奏

在本节中，我们将讨论运维团队与组织一同扩展的挑战：

**迭代胜过失败**
有效的扩展仍然很困难，放弃责任是不够的。我们需要重新审视 Spotify 的运维含义。

**默认需要运维经验**
执行大部分运维工作的中央运维团队无法扩展规模。我们需要通过将运维责任转移到更接近开发人员的位置，使运维成为普遍技能。

2012 年，Spotify 用户群继续增长，带来了新的可扩展性和稳定性问题。运维小组由不到十名 SRE 组成（事实上，在这两年才开始使用 SRE 称呼），在斯德哥尔摩和纽约两地按需招聘。每个 SRE 负责数十项后端服务的维护，包括新版本的部署、容量规划、系统设计评审、配置管理或代码评审，以及维护操作手册等。

我们的后端现在在三个数据中心运行，第四个数据中心即将投入运行。我们必须负责配置机架交换机、订购硬件、远程手动布线、服务器引入、主机配置、打包服务、配置管理和部署，从物理空间到应用程序环境。由于责任范围扩大，我们组建了另一个团队来开发工具自动化，并与运维部门密切合作。该团队开发的早期产品之一是用于硬件清单和容量调配的配置管理数据库（CMDB）。

由于配置定制且不均匀，可预测性很难。运维所有者与服务的开发人员需要密切合作，努力提高质量，遵循生产就绪实践，并运行一个现已正式的部署清单，以确保即使在初始阶段的服务设计也符合运维标准。我们经常提出的关切包括：
- 服务是否在我们的构建系统上打包和构建？
- 该服务是否生成日志？
- 是否有图形、监视和警报？
- 已定义备份和还原测试？
- 是否有安全审查？
- 谁拥有这项服务？它的依赖项是什么？
- 是否有任何潜在的可扩展性问题？是否有任何单点故障？

#### 手工运维碰壁

尽管我们不断手动或通过配置管理进行部署，但持续交付机制并未形成。我们仍然以良好的速度不断发布更新，但这是以手工完成的工作为代价的。服务发现包括静态 DNS 记录以及手动编辑和维护的区域文件。DNS 更改通常由运维审核和部署。我们在 DNS 部署期间往往通过脚本自动在 IRC 上喊话“DNS 部署开始了！”

运维所有者和开发所有者定期浏览容量规划电子表格，以确保服务有足够的容量来维持当前使用量的增加。收集访问模式和资源利用率，并根据当前增长预测容量需求。对于几十个服务的所有者来说，这意味着要进行大量的容量规划。

2012 年下半年，我们达到了 100 万并发用户。这意味着有一百万人直接收听连接到我们三个数据中心之一的音乐。这是一个相当伟大的成就，归功于一些早期决策，如 Spotify 后端架构被设计为可扩展，早期的客户端/协议/后端优化，以及良好的实现。此外，由于没有复杂的逻辑，大多数故障都可以轻松定位和隔离。每个后端服务都做了一件事，并且做得很好。我们保持简单。

随着流媒体音乐用户数量呈指数级增长，运维团队无法做到这一点。我们发现集中式 SRE 运维团队是一个无法扩展的系统。

### 关键收获

我们从这一时期的主要学习点包括：
- 使运维从一开始就真正成为默认；如果你构建它，你就要运行和维护它。
- 将运维责任转移到更接近目标的人：开发人员。
- 随着服务生态系统的扩展，需要不断审视运维工作是如何扩展的。昨天有效的方法今天可能不再适用。

### 引入小组内嵌运维：2013-2015

- 近 50 名运维工程师
- 近 150 名后端工程师
- 三个数据中心
- 60 个后端服务
- 一个用于登台环境的云服务商

#### 前奏

在本节中，我们将讨论新的运维方法如何减少瓶颈并允许技术组织更快地增长：

**迭代胜过失败**
采用“小组内嵌运维”的新模式，使我们得以集中精力尽量减少手工作业。

**核心工程价值**
小组拥有自己的运维人员，这在不知不觉中帮助我们维护了自主和信任的价值观。工程师有可能造成广泛的损害，但同时他们手上也有避免这种破坏的工具和流程。

此时，工程组织已经变得太大，无法作为单个团队运行。于是基础架构和运维（IO）部落成立，专注于为我们的后端开发人员提供基础架构，并解决大规模运维带来的问题。这个部落的一部分叫做服务可用性（SA），主要由我们以前在生产运维中工作的工程师组成。到 2013 年，SA 由四个小队组成，分别是：安全、监控和另外两个工作小组（他们负责提供管理服务器所需的任何其他基础设施工具）。我们聘用新开发人员和启动新开发团队的速度太高，以至于这四个 SA 团队无法跟上。由于我们可以购买和安装新服务器、查看和合并 Puppet 更改、添加 DNS 等任务，这些都需要大量的时间和人力。