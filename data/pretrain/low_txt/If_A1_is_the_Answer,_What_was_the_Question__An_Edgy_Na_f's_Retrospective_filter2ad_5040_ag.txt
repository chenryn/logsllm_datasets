### Open Technical Issues vs. Resolved Ones

Upon my unofficial involvement in the UNCLASSIFIED process, while my clearance was being finalized, I joined a writing group with principal members: Roger Schell, Dan Edwards, Mario Tinto, Jim Anderson, Pete Tasker, Grace Nibaldi, and myself.

### 3.1.1. First Draft: Powder Blue

Upon my arrival at the Center, we still lacked a unified document. The previous week’s workshop on capability-based systems had not sufficiently clarified how their evaluation criteria could be structured. I received the welcome news that Sheila Brand would join the Center in May to lead the Standards organization. Additionally, I learned of a controversy raised by the MITRE Corporation regarding the structure of evaluation criteria.

The Nibaldi proposal consisted of a strictly-ordered set of seven requirement-subsuming evaluation classes, ranging from no protection to attributes beyond the state of the art. While Nibaldi's work refined the Lee panel’s results, nearly 2.5 years had passed since its publication, and critics noted that the Lee panel had not prescribed a strict hierarchy of fully subsuming levels.

A MITRE report by Anne-Marie Claybrook proposed that products be evaluated against criteria drawn by the product developer from sets of policy, mechanism, and assurance requirements perceived as desirable for an application. This approach, described as a "Chinese-Menu" method, had many strong adherents. They argued that not all requirements for, say, Nibaldi Level 4 need apply to a multilevel transaction-only system operating in an environment without remote user capabilities. This proposal aligns with contemporary trends, such as the German IT Security Criteria, the UK’s ITSEC, and the Common Criteria, which allow for "protection profiles." Many argued for the flexibility and tailoring benefits of this approach.

However, others, notably Roger Schell, strongly advocated for preserving Nibaldi’s structure of a small number of well-ordered levels. Schell, drawing from his extensive experience in the DoD procurement process, argued that procurement officers needed a strictly ordered set of product characterizations keyed to the security requirements of the application. A procured system operating in a remote-user environment with CONFIDENTIAL through TOP SECRET data would minimally need to meet a specified (or higher) degree of "certifiability." This could be achieved through a frequently-updated published Evaluated Products List.

Schell’s argument was persuasive, and we agreed to argue requirement-by-requirement among ourselves to fit together seven ordered levels of trusted systems criteria, plus one level for products failing to meet any level. To maintain focus, Schell suggested selecting existing products or developments to characterize each level, emphasizing the value of worked engineering examples for each evaluation class.

We also agreed to limit the possibility of introducing new intermediate evaluation classes over time, particularly to avoid watering down the minimum requirements for each division. Dan Edwards solved this by assigning evaluation classes a digraph rating, patterned on bond ratings, where the divisions were ordered alphabetically.

The identified classes and worked examples from our Final Draft [8] are as follows:

- **Class D: Common Practice** - Reserved for systems that have been evaluated and failed to meet the requirements of a higher class.
- **Class C1: Discretionary Security Protection** - Systems with individual user authentication, nominal discretionary access control, and self-protection. Candidate: UNIX.
- **Class C2: Controlled Access Protection** - Systems with discretionary access control, individual accountability, and security-event auditing. Candidates: RACF, ACF2, and Secure add-on packages for IBM’s MVS/370.
- **Class B1: Labeled Security Protection** - Systems providing mandatory security access control and suitable for DoD need-to-know protection. Candidate: GCOS.
- **Class B2: Structured Protection** - Systems extending mandatory security to all objects visible outside the TCB, with information flow control and confinement channels. Candidate: Multics incorporating the Access Isolation Mechanism (AIM).
- **Class B3: Security Domains** - Systems supporting a defined security model with the principle of least privilege. Candidate: Project Guardian Multics.
- **Class A1: Verified Design** - Systems with a formal model, formally specified top-level user interface, and verified to satisfy the model. Candidates: KVM, KSOS, Honeywell SCOMP, and SACDIN.
- **Class A2: Verified Implementation** - Systems using a formal machine-checkable methodology to ensure the actual implementation conforms to the verified top-level specifications. No candidate specified.

### 3.1.2. Community Response

We announced that the first draft would be presented at the Computer Security Initiative Seminar, and the response was overwhelming. We naively assumed we were close to getting it right and requested written comments from participants, setting a tight review and publication schedule. The draft invited a first round of comments with a deadline of July 1, 1982, promising a second draft by August 1, 1982, and final publication in October 1982.

We received a massive response, filling file-drawers with industry and government comments. Sheila Brand, newly arrived at the Center, was inundated with correspondence and requests for visits to discuss the draft. Complaints centered on the imprecise language and organization, but most feedback was supportive and constructively stated. Reviewers suggested reorganizing the document to place the criteria first, allowing each evaluation class’s requirements to be self-contained. This added to the bulk of the TCSEC but removed internal cross-referencing. Additional requests included a glossary of terms, guidelines on testing, covert channels, and configuring MAC features, and the issue of giving extra credit for features or assurances beyond those required for a specific access class.