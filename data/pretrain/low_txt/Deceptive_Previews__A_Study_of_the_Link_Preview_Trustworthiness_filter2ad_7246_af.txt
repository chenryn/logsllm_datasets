### Observations on Phishing URL Detection Across Browsers and Platforms

#### Mobile Browsers
We observed that popular messaging apps such as Facebook Messenger, Instagram, and WhatsApp (both on Android and iOS) do not display any warnings when loading our phishing URLs. Additionally, we found that external browser apps may not consistently show Safe Browsing warnings. This behavior was reproduced in the following browsers:
- **Chrome Browser 76.0.3809.123** for iOS 12.4.1
- **Chrome for Android** (Android 9, Pixel Build/PQ3A.190801.002 and Pixel 2 Build/PQ3A.190801.002)
- **Safari 12.1.2** (Mobile)
- **Brave Browser for Android** (1.3.2 based on Chromium 76.0.3809.132)
- **Firefox Focus for Android** (8.0.16)

Only one mobile browser, **Firefox for Android (68.1)**, correctly displayed the warning. All tested apps and operating systems were used with their default configurations.

#### Desktop Browsers
Desktop browsers were more consistent in displaying the warning. The following desktop browsers were tested:
- **Chrome Browser 77.0.3865.75** for Ubuntu 18.04
- **Brave Software Browser 0.68.132** (based on Chromium 76.0.3809.132 for Ubuntu 18.04)
- **Firefox 69.0** for Ubuntu 18.04

Independent non-academic research has also confirmed a discrepancy between Google Safe Browsing on mobile and desktop platforms (see [26], [19]).

#### Implications
The reasons for this discrepancy are not fully understood and require further research. These results indicate that browsers may fail to detect malicious URLs, suggesting that browser-side countermeasures should not be considered a foolproof last line of defense. Therefore, we recommend developers implement upstream URL validation during the generation of link previews. Among the 20 platforms we verified, only two implemented such a mechanism.

### Proper URL Validation
An HTTP agent can access web resources by following chains of redirections. Historically, redirections were implemented via HTTP response codes and the refresh HTML meta tag. Today, redirections are also implemented using JavaScript code. When validating URLs, it is crucial to validate all URLs in a redirection chain. Unfortunately, the only two platforms implementing URL validation (Twitter and LinkedIn) did not validate URLs during redirections, allowing attackers to bypass these countermeasures. Table VI summarizes the results of our experiments with these two social networks.

### Ethical Considerations
Our experiments raise valid ethical concerns regarding the sharing of malicious content on social media platforms. To avoid harming users, we limited the visibility of the shared malicious links from the platform accounts we controlled. For platforms that did not support limiting post visibility (e.g., Medium and Plurk), we did not share the phishing link and instead used the innocuous EICAR test file, commonly used to test antivirus software.

Another concern is the risk of blacklisting our network and domain name, which could affect the work of research and administration staff. To mitigate this, we registered a first-level domain name and moved our servers to Amazon Web Services (AWS) EC2.

### Related Work
In this section, we review works related to our study, focusing on the analysis of malicious URLs in social networks and phishing.

#### Analysis of Clicks on Social Platforms
Users rely on various signals displayed by social platforms when deciding whether to click on link previews. Redmiles et al. [27] showed that users consider who shares the content and the online community it originates from. Our work aims to shed light on the dynamics behind user clicks on social networks, focusing on the content of link previews, the trustworthiness of preview creation, and the extent to which an attacker can control the fields displayed to victims.

Facebook addressed the issue of maliciously crafted link previews in 2017 by forbidding users from modifying link previews [28]. Barak Tawily [33] independently showed that Facebook link previews can be modified via metatags. Our study expands on Tawily's work, demonstrating that motivated attackers can still control the content of a preview by crafting ad-hoc HTML tags of the shared pages. This problem is not unique to Facebook but is a systematic issue affecting most of the social platforms we evaluated.

#### Phishing in Social Networks
Phishing attacks typically involve an attacker, a victim, and a malicious resource used as bait. Attackers often impersonate existing institutions or services, increasing their chances of success through visually similar domains, graphics, and logos. With the rise of social media, attackers can directly reach targeted victims or engage in broader campaigns. Han et al. [16] noted that Facebook is among the top-five organizations targeted by phishers, who use off-the-shelf phishing kits on compromised web servers. Phishing attacks often employ multiple redirections to evade detection and blacklists.

Previous work [29], [31] studied redirection chains for detecting malicious pages, including in the context of social networks like Twitter. Detection of phishing pages can also be done by inspecting the content and structure of a webpage [24] or the URL structure [7].

Unlike these works, our study does not present new detection techniques for phishing pages. However, it shows that attackers can create link previews that are visually similar to benign ones, masking the malicious intent of the landing page.

#### Detection of Malicious Content
As social networks gained popularity, attackers started using them to spread malicious URLs beyond phishing, such as drive-by downloads. Several works have focused on detecting these URLs. Lee et al. [29] proposed a technique based on chains of redirections, while Thomas et al. [34] presented a method for evaluating URLs shared on social networks and other web services. Other studies have focused on inspecting the content of both desktop and mobile browsers [6], [1].

Our paper does not present a detection technique but studies how social platforms behave when preparing previews of malicious URLs. Bell et al. [4] measured the reactivity of Twitter's malicious URL detection system, finding that many malicious URLs remain undetected for at least 20 days. Their work is complementary to ours, as it explores the reactivity of countermeasures, while we focus on the ways social platforms generate previews in an adversarial setting.

#### Cloaking Attacks
Cloaking attacks involve altering the web page content when visited by a crawler or bot to conceal the malicious purpose. Wang et al. [39] and Invernizzi et al. [18] have proposed techniques to detect cloaking. While these techniques can help, they may not be sufficient to prevent the creation of deceptive previews. Our study shows that complying with our recommendations is challenging in practice, and attackers can exploit implementation pitfalls to craft malicious previews and distribute unwanted content over social platforms.

### Conclusion
In this paper, we presented a comprehensive analysis of link previews on social media platforms. We explored the variability in how their content is specified and rendered, highlighting how this can lead to uninformed security decisions. We demonstrated that it is possible to misuse the preview-rendering service, as it relies entirely on the content of meta tags without further inspection. In four social media platforms, we crafted benign-looking link previews leading to potentially malicious webpages. Crafting such previews for the remaining 16 platforms requires only the ability to register a new domain.

We also examined active and passive countermeasures employed by social media platforms against the spread of known malicious URLs and software, finding that only two out of 20 platforms perform active checks on shared URLs. Even in these cases, cross-checks can be bypassed through client- and server-side redirections. We reported inconsistencies with safe browsing services on mobile phones, supporting our recommendation for upstream checks performed directly by social media platforms. We concluded with a discussion on the impact of misleading previews on user behavior, evaluating the resulting security risks, and suggesting seven recommendations for possible improvements.

### Acknowledgments
We would like to thank the anonymous reviewers, Katharina Krombholz, and Sebastian Becking for their valuable feedback. We also thank Nick Nikiforakis for shepherding this paper. This work was partially supported by the German Federal Ministry of Education and Research (BMBF) through funding for the CISPA-Stanford Center for Cybersecurity (FKZ: 13N1S0762).

### References
[1] C. Amrutkar, Y. S. Kim, and P. Traynor, “Detecting mobile malicious webpages in real time,” IEEE Transactions on Mobile Computing, vol. 16, no. 8, pp. 2184–2197, 2016.
[2] M. Armstrong, “Referral traffic - Google or Facebook?” Statista, 2017. [Online]. Available: https://www.statista.com/chart/9555/referral-traffic---google-or-facebook/
[3] Ars Technica, “Armed with iOS 0days, hackers indiscriminately infected iPhones for two years,” 2019. [Online]. Available: https://arstechnica.com/information-technology/2019/08/armed-with-ios-0days-hackers-indiscriminately-infected-iphones-for-two-years/
[4] S. Bell, K. Paterson, and L. Cavallaro, “Catch me (on time) if you can: Understanding the effectiveness of Twitter URL blacklists,” arXiv preprint arXiv:1912.02520, 2019.
[5] D. Canali and D. Balzarotti, “Behind the scenes of online attacks: An analysis of exploitation behaviors on the web,” 2013.
[6] D. Canali, M. Cova, G. Vigna, and C. Kruegel, “Prophiler: A fast filter for the large-scale detection of malicious web pages,” in Proceedings of the 20th International Conference on World Wide Web. ACM, 2011, pp. 197–206.
[7] N. Chou, R. Ledesma, Y. Teraguchi, and J. C. Mitchell, “Client-side defense against web-based identity theft,” in Proceedings of the Network and Distributed System Security Symposium, NDSS 2004, San Diego, California, USA, 2004. [Online]. Available: http://www.isoc.org/isoc/conferences/ndss/04/proceedings/Papers/Chou.pdf
[8] J. S. Downs, M. Holbrook, and L. F. Cranor, “Behavioral response to phishing risk,” in Proceedings of the Anti-Phishing Working Groups 2nd Annual eCrime Researchers Summit. ACM, 2007, pp. 37–44.
[9] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna, “Towards detecting compromised accounts on social networks,” IEEE Transactions on Dependable and Secure Computing, vol. 14, no. 4, pp. 447–460, 2015.
[10] Facebook Inc., “I got a message from Facebook saying a file I tried to share has a virus.” [Online]. Available: https://www.facebook.com/help/223268604538225
[11] ——, “The Open Graph Protocol.” [Online]. Available: https://ogp.me/
[12] ——, “What is Facebook doing to protect me from spam?” [Online]. Available: https://www.facebook.com/help/637109102992723
[13] S. Garera, N. Provos, M. Chew, and A. D. Rubin, “A framework for detection and measurement of phishing attacks,” in Proceedings of the 2007 ACM Workshop on Recurring Malcode. ACM, 2007, pp. 1–8.
[14] Google Inc., “Google Safe Browsing.” [Online]. Available: https://safebrowsing.google.com/
[15] S. Gupta, A. Khattar, A. Gogia, P. Kumaraguru, and T. Chakraborty, “Collective classification of spam campaigners on Twitter: A hierarchical meta-path based approach,” in Proceedings of the 2018 World Wide Web Conference. International World Wide Web Conferences Steering Committee, 2018, pp. 529–538.
[16] X. Han, N. Kheir, and D. Balzarotti, “Phisheye: Live monitoring of sandboxed phishing kits,” in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. ACM, 2016, pp. 1402–1413.
[17] J. Hong, “The current state of phishing attacks,” 2012.
[18] L. Invernizzi, K. Thomas, A. Kapravelos, O. Comanescu, J. Picod, and E. Bursztein, “Cloak of visibility: Detecting when machines browse a different web,” in 2016 IEEE Symposium on Security and Privacy (SP), 2016.
[19] K. Johnson, “Google Safe Browsing can differ between desktop and mobile. Why?” 2019. [Online]. Available: https://www.wandera.com/mobile-security/google-safe-browsing/
[20] A. Le, A. Markopoulou, and M. Faloutsos, “PhishDef: URL names say it all,” in 2011 Proceedings IEEE INFOCOM. IEEE, 2011, pp. 191–195.
[21] C. Ludl, S. McAllister, E. Kirda, and C. Kruegel, “On the effectiveness of techniques to detect phishing sites,” in International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment. Springer, 2007, pp. 20–39.
[22] A. Oest, Y. Safaei, A. Doupé, G.-J. Ahn, B. Wardman, and K. Tyers, “PhishFarm: A scalable framework for measuring the effectiveness of evasion techniques against browser phishing blacklists,” in PhishFarm: A Scalable Framework for Measuring the Effectiveness of Evasion Techniques against Browser Phishing Blacklists. IEEE, 2019, p. 0.
[23] OpenDNS, “PhishTank.” [Online]. Available: https://www.phishtank.com/
[24] Y. Pan and X. Ding, “Anomaly based web phishing page detection,” in 2006 22nd Annual Computer Security Applications Conference (ACSAC’06), 2006.
[25] G. Pellegrino, O. Catakoglu, D. Balzarotti, and C. Rossow, “Uses and Abuses of Server-Side Requests,” in Proceedings of the 19th International Symposium on Research in Attacks, Intrusions and Defenses, September 2016.
[26] L. L. Porta, “Google’s security efforts are falling short on mobile,” 2019. [Online]. Available: https://www.brianmadden.com/opinion/Google-Safe-Browsing-differs-between-desktop-and-mobile
[27] E. M. Redmiles, N. Chachra, and B. Waismeyer, “Examining the demand for spam: Who clicks?” in Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, ser. CHI ’18, 2018. [Online]. Available: http://doi.acm.org/10.1145/3173574.3173786
[28] M. Robertson, “Modifying link previews,” 2017. [Online]. Available: https://developers.facebook.com/blog/post/2017/06/27/API-Change-Log-Modifying-Link-Previews
[29] Sangho Lee and Jong Kim, “Warningbird: Detecting suspicious URLs in Twitter stream,” in NDSS, 2012.
[30] S. Sheng, B. Wardman, G. Warner, L. F. Cranor, J. Hong, and C. Zhang, “An empirical analysis of phishing blacklists,” in Sixth Conference on Email and Anti-Spam (CEAS). California, USA, 2009.
[31] G. Stringhini, C. Kruegel, and G. Vigna, “Shady paths: Leveraging surfing crowds to detect malicious web pages,” in Proceedings of the 2013 ACM SIGSAC Conference on Computer & Communications Security, ser. CCS ’13, 2013. [Online]. Available: http://doi.acm.org/10.1145/2508859.2516682
[32] G. Stringhini, C. Kruegel, and G. Vigna, “Detecting spammers on social networks,” in Proceedings of the 26th Annual Computer Security Applications Conference, ser. ACSAC ’10, 2010. [Online]. Available: http://doi.acm.org/10.1145/1920261.1920263
[33] B. Tawily, “Can you trust Facebook links?” 2017. [Online]. Available: https://quitten.github.io/Facebook/
[34] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song, “Design and evaluation of a real-time URL spam filtering service,” in Proceedings of the 2011 IEEE Symposium on Security and Privacy, ser. SP ’11, 2011. [Online]. Available: https://doi.org/10.1109/SP.2011.25
[35] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Paxson, “Trafficking fraudulent accounts: The role of the underground market in Twitter spam and abuse,” in Presented as part of the 22nd USENIX Security Symposium (USENIX Security 13), 2013, pp. 195–210.
[36] Twitter Inc., “About unsafe links.” [Online]. Available: https://help.twitter.com/en/safety-and-security/phishing-spam-and-malware-links
[37] ——, “Optimize with cards.” [Online]. Available: https://developer.twitter.com/en/docs/tweets/optimize-with-cards/overview/abouts-cards
[38] A. Vishwanath, T. Herath, R. Chen, J. Wang, and H. R. Rao, “Why do people get phished? Testing individual differences in phishing vulnerability within an integrated, information processing model,” Decision Support Systems, vol. 51, no. 3, pp. 576–586, 2011.
[39] D. Y. Wang, S. Savage, and G. M. Voelker, “Cloak and dagger: Dynamics of web search cloaking,” in Proceedings of the 18th ACM Conference on Computer and Communications Security, ser. CCS ’11, 2011. [Online]. Available: http://doi.acm.org/10.1145/2046707.2046763
[40] B. Wu and B. D. Davison, “Detecting semantic cloaking on the web,” in Proceedings of the 15th International Conference on World Wide Web, ser. WWW 06, 2006. [Online]. Available: https://doi.org/10.1145/1135777.1135901