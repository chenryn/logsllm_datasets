### Impact of Short-Term Half-Life on Optimal Threshold

Small variations in the short-term half-life can significantly affect the optimal threshold. This implies that minor random perturbations can cause one of the two threshold values to be deemed optimal. As we conduct experiments by varying the block size and saturation, these random perturbations can cause the optimal short-term half-life or threshold to oscillate between the two local minima, resulting in a jagged appearance of the optimal threshold surface.

### Low Sensitivity

Notice also that even on the Hst = 15 curve, the cost value is nearly flat near the minimum point. This further suggests that random perturbations can cause the optimum point to fluctuate, adding to the difficulty in finding a stable optimal threshold.

### Analysis of the Optimal Short-Term Half-Life Surface

Turning our attention back to the optimal short-term half-life surface shown in Figure 4(a), we observe three distinct regions based on the foreign-symbol saturation (λa) value:

- **Low Foreign-Symbol Saturation**: In this region, the normal and anomalous blocks are so similar that even with optimal tuning, detector performance is poor (see Figure 2). The cost as a function of the short-term half-life is essentially flat, except for noise due to random variations in the synthetic data. This results in the optimal short-term half-life being determined by these random variations rather than by the effects of the data or detector, leading to jagged peaks and valleys.

- **Medium Foreign-Symbol Saturation**: In this region, the optimal short-term half-life increases as the block size increases. This is due to the trade-off between the accuracy provided by a larger short-term half-life (and thus a larger effective sample size) and the block-boundary problem (discussed in Section 6.1), which is exacerbated by larger short-term half-life values. As the block size increases, the transition problem becomes less significant, making a larger short-term half-life more effective.

- **High Foreign-Symbol Saturation**: In this region, the foreign-symbol saturation is so high that anomalies can be easily detected even with a small sample. Since there is no significant benefit to using a large sample (i.e., a large short-term half-life), a smaller short-term half-life is preferred to minimize errors due to block transitions.

### Comparison with Real-World Data

To validate the significance of the synthetic-data experiments, we compared the results of an experiment using real-world data to those using synthetic data. The real-world data was the sendmail system-call trace data collected by researchers at the University of New Mexico [5]. The trace data consists of a "normal" trace file and an "intruder" trace file. We first created three 100,000-symbol data sets, drawn from the first 300,000 symbols of the normal trace file (which contained 1,571,583 symbols); these data sets, each the same size as those used in the synthetic data sets, were used to train the detector. We then constructed the test data by splicing together alternating blocks of symbols from the normal trace (starting at symbol 300,001, to avoid using the same data for training and testing) and the intruder trace. We used the block-size parameter B to vary block sizes in the same way as in the synthetic data experiments, providing a trace based on real-world data that is directly comparable to our synthetic-data experiments.

Figure 6(a) shows the detector error cost for the real-world data as a function of the block size and the detector short-term half-life, assuming the threshold is optimally tuned. Figure 6(b) shows the corresponding graph for synthetic data with foreign symbol injections at a saturation of λa = 0.5. With a few small differences, the basic shape of the two graphs is very similar. The most obvious differences are:

- In the real-world data experiment, the error cost decreases almost immediately as the block size increases, whereas in the synthetic-data experiment, the error cost remains constant until the block size is moderately large.
- The optimal cost for the synthetic-data experiment is lower than that for the real-world data experiment.

While injection type (foreign, rare, or uncommon) and saturation do affect the details of the cost surface shape, the same basic features are generally preserved. Typically, lower saturation values result in a cost surface that slopes down more gradually from the small-blocksize/high-short-term-half-life corner and has a larger lip on the low-short-term-half-life edge of the curve. Additionally, other parameters not studied in detail in this paper (e.g., alphabet size and symbol-type distribution standard deviation σ) would also be expected to have an effect. Given that changing the data characteristics can result in a variety of similar cost curves, we believe that our sendmail trace results are well within the scope of our expectations.

### Conclusion

In this paper, we presented an evaluation approach for an anomaly-based detector using a parameterized family of synthetic data sets. We varied the injection type and saturation level, as well as the block size (via injection length and time between injections). We validated our observed performance characteristics on the synthetic data by comparing it with a real-world data set, noting that we obtained similar performance curves.

We observed a relationship between the block size and the optimal short-term half-life. As the block size decreased, we needed to decrease the short-term half-life to maintain optimal performance. This suggests that in environments where attacks are expected to be short or frequent, a small short-term half-life should be used. Since the short-term half-life essentially sets a short-term window, we could expect similar results for other detectors with a window-size parameter. An exception to this rule is when an intruder manifests as an obvious and easy-to-detect anomaly (e.g., has a high saturation value) or is on the margin of the detector’s discriminatory capability, in which case larger short-term half-life values should be used.

We evaluated RIDES over a wide range of data environments. The lessons learned have been consistent across all environments, strongly suggesting that the results are extensible to other data sets. For example, since we have observed that RIDES is blind to a low saturation of anomalies, we believe it is highly unlikely that RIDES would be able to detect a single foreign symbol in any other environment.

We also showed that there are challenges remaining in the area of intrusion-detector performance modeling. Interactions among the detector parameters can lead to multiple local optima, making it difficult to find a satisfactory tuning in some cases. More work is needed to identify additional criteria for tuning decisions.

### Acknowledgements

The authors are grateful for helpful comments from F. Arshad, K. Killourhy, P. Loring, and R. Roberts. The authors are also thankful to several anonymous referees whose thoughtful remarks inspired improvements in the paper. This work was supported by National Science Foundation grant number CNS-0430474.

### References

1. Anderson, Debra; Lunt, Teresa F.; Javitz, Harold; Tamaru, Ann and Valdes, Alfonso. “Detecting Unusual Program Behavior Using the Statistical Component of the Next-Generation Intrusion Detection Expert System (NIDES),” Technical Report SRI-CSL-95-06, Computer Science Laboratory, SRI International, May 1995.
2. Anderson, Debra; Lunt, Teresa F.; Javitz, Harold; Tamaru, Ann and Valdes, Alfonso. “Safeguard Final Report: Detecting Unusual Program Behavior Using the NIDES Statistical Component,” Technical Report, Computer Science Laboratory, SRI International, Menlo Park, California, 02 December 1993.
3. Arbel, Gil. Anomaly Detection Falls Short. TechWorld, 13 March 2006.
4. Denning, Dorothy E. An Intrusion-Detection Model, IEEE Transactions on Software Engineering, Vol. SE-13, No. 2, pp. 222-232, February 1987.
5. Forrest, Stephanie. “Computer Immune Systems.” Data sets for sequence-based intrusion detection: http://www.cs.unm.edu/∼immsec/systemcalls.htm. Computer Science Department, University of New Mexico, Albuquerque, New Mexico. 2006.
6. Forrest, Stephanie; Hofmeyr, Steven A.; Somayaji, Anil and Longstaﬀ, Thomas A. “A Sense of Self for Unix Processes,” In IEEE Symposium on Security and Privacy, pp. 120-128, 06-08 May 1996, Oakland, California. IEEE Computer Society Press, Los Alamitos, California.
7. Ghosh, Anup K.; Schwartzbart, Aaron and Schatz, Michael. “Learning Program Behavior Profiles for Intrusion Detection,” In 1st USENIX Workshop on Intrusion Detection and Network Monitoring, pp. 51-62, Santa Clara, CA, 09-12 April 1999.
8. Ghosh, Anup K.; Wanken, James and Charron, Frank. “Detecting Anomalous and Unknown Intrusions Against Programs,” In 14th Annual Computer Security Applications Conference, pp. 259-267, Phoenix, AZ, 07-11 December 1998. Los Alamitos, CA, IEEE Computer Society Press, 1998.
9. Javitz, Harold S. and Valdes, Alfonso. The NIDES Statistical Component: Description and Justification. Annual Report A010, 07 March 1994, SRI International, Menlo Park, California.
10. Javitz, Harold S. and Valdes, Alfonso. “The SRI IDES Statistical Anomaly Detector,” In IEEE Symposium on Research in Security and Privacy, pp. 316-326, Oakland, California, 20-22 May 1991. IEEE Computer Security Press, Los Alamitos, California.
11. Jha, Somesh; Tan, Kymie M. C. and Maxion, Roy A. “Markov Chains, Classifiers, and Intrusion Detection,” In 14th IEEE Computer Security Foundations Workshop, pp. 206-219, Cape Breton, Nova Scotia, Canada, 11-13 June 2001.
12. Swets, John A. and Pickett, Ronald M. Evaluation of Diagnostic Systems: Methods from Signal Detection Theory. Academic Press, New York, 1982.
13. Tan, Kymie M. C. and Maxion, Roy A. “Determining the Operational Limits of an Anomaly-Based Intrusion Detector.” IEEE Journal on Selected Areas in Communications, Special Issue on Design and Analysis Techniques for Security Assurance, Vol. 21, No. 1, pp. 96-110, January 2003.
14. Tan, Kymie M. C. and Maxion, Roy A. “The Effects of Algorithmic Diversity on Anomaly Detector Performance,” In International Conference on Dependable Systems & Networks (DSN-05), pages 216-225, Yokohama, Japan, 28 June - 01 July 2005. IEEE Computer Society Press, Los Alamitos, California, 2005.
15. Valdes, Alfonso and Anderson, Debra. Statistical Methods for Computer Usage Anomaly Detection Using NIDES (Next-Generation Intrusion Detection Expert System), Third International Workshop on Rough Sets and Soft Computing (RSSC-94), 10-12 November 1994, San Jose, California. Published by the Society for Computer Simulation, San Diego, 1995, pp. 104-111.
16. Warrender, Christina; Forrest, Stephanie and Pearlmutter, Barak. “Detecting Intrusions Using System Calls: Alternative Data Models,” In IEEE Symposium on Security and Privacy, pp. 133-145, Oakland, California, 09-12 May 1999. IEEE Computer Security Press, Los Alamitos, California.
17. Zissman, Marc. “1998/99 DARPA Intrusion Detection Evaluation data sets,” MIT Lincoln Laboratory, http://www.ll.mit.edu/IST/ideval/data/data index.html.