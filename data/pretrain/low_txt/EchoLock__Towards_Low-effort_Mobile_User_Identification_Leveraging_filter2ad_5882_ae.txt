### Impact of Device Models

We examined the performance variations of EchoLock across different mobile devices. Participants were provided with devices equipped with our prototype and given a brief explanation of its functionality. We found that a single demonstration, lasting less than 10 seconds, was sufficient for participants to understand how to use EchoLock, indicating its ease of use.

In Figure 10, we plot True Positive (TP) and False Positive (FP) rates as a Receiver Operating Characteristic (ROC) curve for each device. Our analysis reveals that performance correlates with the size of the device. Users more easily adapt to a consistent posture on smaller devices compared to larger ones. On average, we achieved a TP rate of 94% at a fixed FP rate of 5%. Notably, the Nexus 5, our top-performing device, consistently exceeded a TP rate of 97%.

For larger devices, such as tablets, the size difference between the hand and the device diminishes the impact of the holding posture, suggesting that our measurements are most reliable when conducted on a small, well-defined space. These results serve as a benchmark for other experiments.

### N-Chirp Sequence Length

We investigated the effect of chirp sequence length on identification accuracy to improve performance. While increasing the sequence length enhances accuracy, we observed diminishing returns after approximately five iterations. Stability around 90% can be maintained with as few as three chirps in optimal test cases (e.g., smaller devices, quiet settings), as shown in Figure 14.

### Impact of Environmental Noises

We studied the performance of EchoLock in public environments using a subset of our mobile devices. Smartphones showed greater resilience under these conditions compared to tablets, likely due to the lack of secondary microphones on tablets, which limits noise-cancellation capabilities. As indicated in Figure 13(a), significant noise produces measurable degradation, with TP rates declining by 2-6% at a fixed 5% FP rate. The higher end of this degradation is often caused by loud vocalizations, such as shouting or laughter, which can overwrite biometric measurements due to the use of Mel Frequency Cepstral Coefficients (MFCCs). This suggests that EchoLock may face challenges in noisy environments, such as during conversations.

### Indirect Physical Contact

We also explored the influence of indirect physical contact on EchoLock's performance. To simulate these conditions, we used a smartphone case on the Galaxy Note 5 and provided wool gloves (approximately 2mm thick) for users to wear during separate sets of experiments. Figure 13(b) shows that these conditions did not result in statistically significant deterioration. In some cases, users even showed slightly improved accuracy (1-2%), particularly when wearing gloves. This improvement may be attributed to the material of the gloves conforming well to the hand's curvature and reducing grip variability.

### Execution Time and Sample Requirements

As mentioned in Section 5.2, a single chirp iteration requires only 25ms, or 50ms when accounting for buffering between iterations. This indicates that our current performance can be achieved within execution times competitive with techniques like fingerprinting. It also suggests that an individual's hand biometrics are recognizable, allowing our machine learning framework to identify users with moderate success using relatively few samples.

### Discussion

#### Jamming Attacks

We considered the potential for acoustic disruptions via jamming strategies. We tested the system's ability to function when an attacking device played a continuous signal within the operational frequency range of EchoLock. During ten identification attempts per user, with the attacking signal sweeping from 18kHz to 22kHz at a distance of 0.2m, we found that detecting these jamming signals is feasible using a threshold scheme. However, negating the interference remains challenging. Jamming attempts from distances greater than 1m were less effective, similar to the public environment conditions described in Section 8.5. Methods to avoid threshold detection require careful synchronization and matching the length of the chirp sequence, which the attacker cannot predict. We are working on improving resistance to these attacks as part of our future work.

#### Potential Hardware Constraints

During our selection of candidate devices, we identified certain hardware configurations unsuitable for implementing EchoLock (e.g., speakers on the front face and microphones on the back). Our implementation requires hardware components to be oriented as far apart as possible to allow for uninterrupted sound propagation. This constraint may be relaxed by leveraging additional sensor measurements, but this would add more hardware requirements to our minimalist design.

### Conclusion

We have proposed EchoLock, a low-effort, lightweight identification protocol deployable on commodity mobile devices. Our system verifies users based on how they hold their devices using a novel technique that leverages acoustic sensing of structure-borne sound to measure biometric characteristics. This technique enables seamless identification checks and personalized user services on smartphones, tablets, and similar devices. A prototype of EchoLock has been implemented on Android and evaluated in 160 trials, obtaining 80,000 hand geometry samples from multiple participants. Our technique is quick to conduct, easy to use, and demonstrates accuracy over 94%. For future work, we intend to integrate EchoLock with existing authentication techniques, assess the possibility of elevating current security rates, and develop a more robust implementation to realize secure, low-effort identification.

### Acknowledgment

This work was partially supported by the National Science Foundation Grants CNS1566455, CNS1826647, CNS1954959, CCF1909963, CCF2000480, CNS1801630, CNS1820624, and ARO Grant W911NF-18-1-0221.

### References

[1] 2019. Internet of Things (IoT) connected devices installed base worldwide from 2015 to 2025 (in billions). https://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/.

[2] 2019. Material Sound Velocities. https://www.olympus-ims.com/en/ndt-tutorials/thickness-gage/appendices-velocities/.

[3] Abbas Acar, Hidayet Aksu, A. Selcuk Uluagac, and Kemal Akkaya. 2018. WACA: Wearable-Assisted Continuous Authentication. In IEEE Symposium on Security and Privacy Workshops.

[4] Amazon. 2018. Fire TV Stick. https://developer.amazon.com/docs/fire-tv/device-specifications-fire-tv-stick.html.

[5] Apple. 2018. Apple iOS. support.apple.com.

[6] Kaoru Ashihara. 2007. Hearing thresholds for pure tones above 16 kHz. The Journal of the Acoustical Society of America 122, 3 (2007).

[7] Silvio Barra, Maria De Marsico, Michele Nappi, Fabio Narducci, and Daniel Riccio. 2019. A hand-based biometric system in visible light for mobile environments. Information Sciences 479 (2019), 472–485.

[8] Todd Bishop. 2019. Amazon’s Blink unveils new security camera with “exclusive” chip and two-year battery life. https://www.geekwire.com/2019/amazons-blink-unveils-new-security-camera-proprietary-chip-enables-two-year-battery-life/.

[9] Cam Bunton. 2016. Samsung Galaxy Note 7 iris scanner. https://www.pocket-lint.com/phones/news/samsung/138335-samsung-galaxy-note-7-iris-scanner-what-is-it-and-how-does-it-work.

[10] J. Guerra Casanova, C. Sánchez Ávila, A. de Santos Sierra, G. Bailador del Pozo, and V. Jara Vera. 2010. A Real-Time In-Air Signature Biometric Technique Using a Mobile Device Embedding an Accelerometer. In Networked Digital Technologies, Filip Zavoral, Jakub Yaghob, Pit Pichappan, and Eyas El-Qawasmeh (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 497–503.

[11] Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST) 2, 3 (2011), 27.

[12] Ivan Cherapau, Ildar Muslukhov, Nalin Asanka, and Konstantin Beznosov. 2015. On the Impact of Touch ID on iPhone Passcodes. In Symposium on Usable Privacy and Security (SOUPS). 257–276.

[13] Hsin-Yi Chiang and Sonia Chiasson. 2013. Improving user authentication on mobile devices: a touchscreen graphical password. In Proceedings of the 15th International Conference on Human-computer interaction with mobile devices and services. MobileHCI.

[14] Sonia Chiasson, Paul C van Oorschot, and Robert Biddle. 2007. Graphical password authentication using cued click points. In Computer Security–ESORICS 2007. Springer, 359–374.

[15] Eric Chiu. 2017. Google’s CEO Wants $30 Smartphones For Developing Countries. https://www.ibtimes.com/googles-ceo-wants-30-smartphones-developing-countries-2471321/.

[16] Mohammed E. Fathy, Vishal M. Patel, and Rama Chellappa. 2015. Face-based Active Authentication on mobile devices. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing. IEEE.

[17] Jeremy Ford. 2011. $80 Android Phone Sells Like Hotcakes in Kenya, the World Next? https://singularityhub.com/2011/08/16/80-android-phone-sells-like-hotcakes-in-kenya-the-world-next/.

[18] Google. 2019. Android Developer Resources. https://developer.android.com/reference/android/media/AudioRecord.html.

[19] Marian Harbach, Emanuel von Zezchwitz, Andreas Fichtner, Alexander De Luca, and Matthew Smith. 2014. It’s a Hard Lock Life: A Field Study of Smartphone (Un)Locking Behavior and Risk Perception. In Proceedings of the Tenth Symposium on Usable Privacy and Security (SOUP). SOUP, 213–224.

[20] R.C. Johnson, Walter J. Scheirer, and Terrance E. Boult. 2013. Secure voice-based authentication for mobile devices: vaulted voice verification. In Proceedings of Biometric and Surveillance Technology for Human and Activity Identification. SPIE.

[21] Sven Kratz and Md Tanvir Islam Aumi. 2014. AirAuth: a biometric authentication system using in-air hand gestures. In CHI’14 Extended Abstracts on Human Factors in Computing Systems. ACM, 499–502.

[22] Jian Liu, Hongbo Liu, Yingying Chen, Yan Wang, and Chen Wang. 2019. Wireless Sensing for Human Activity: A Survey. IEEE Communications Surveys & Tutorials (2019).

[23] Jian Liu, Chen Wang, Yingying Chen, and Nitesh Saxena. 2017. VibWrite: Towards finger-input authentication on ubiquitous surfaces via physical vibration. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 73–87.

[24] Beth Logan et al. 2000. Mel Frequency Cepstral Coefficients for Music Modeling. In ISMIR, Vol. 270. 1–11.

[25] Andrew Martinik. 2018. How to customize Active Edge on the Google Pixel 3. https://www.androidcentral.com/how-customize-active-edge-pixel-3.

[26] Surbhi Mathur, Ankit Vjay, Jidnya Shah, Shreyasi Das, and Adil Malla. 2016. Methodology for partial fingerprint enrollment and authentication on mobile devices. In Proceedings of the International Conference on Biometrics. IEEE.

[27] Meinard Müller, Frank Kurth, and Michael Clausen. 2005. Audio Matching via Chroma-Based Statistical Features. In ISMIR, Vol. 2005. 6th.

[28] Yanzhi Ren, Yingying Chen, Mooi Choo Chuah, and Jie Yang. 2014. User Verification Leveraging Gait Recognition For Smartphone Enabled Mobile Healthcare Systems. IEEE Transactions on Mobile Computing (2014).

[29] Yanzhi Ren, Chen Wang, Yingying Chen, Mooi Choo Chuah, and Jie Yang. 2015. Critical segment based real-time e-signature for securing mobile transactions. In 2015 IEEE Conference on Communications and Network Security (CNS). IEEE, 7–15.

[30] Jan Rychlewski. 1984. On Hooke’s law. Journal of Applied Mathematics and Mechanics 48, 3 (1984), 303–314.

[31] Napa Sae-Bae, Kowsar Ahmed, Katherine Isbister, and Nasir Memon. 2012. Biometric-rich Gestures: A Novel Approach to Authentication on Multi-touch Devices. In Proceedings of ACM SIGCHI.

[32] Muhammad Shahzad, Alex X Liu, and Arjmand Samuel. 2013. Secure unlocking of mobile touch screen devices by simple gestures: You can see it but you can not do it. In ACM MobiCom. 39–50.

[33] Ke Sun, Ting Zhao, Wei Wang, and Lei Xie. 2018. VSkin: Sensing Touch Gestures on Surfaces of Mobile Devices Using Acoustic Signals. In Proceedings of the 24th Annual International Conference on Mobile Computing and Networking. 591–605.

[34] Xiaoyuan Suo, Ying Zhu, and G Scott Owen. 2005. Graphical passwords: A survey. In Proceedings of the 21st Annual Computer Security Applications Conference. IEEE. https://www.tsys. 2016 U.S. Consumer Payment Study.

[35] TSYS. 2016. https://www.tsys.com/Assets/TSYS/downloads/rs_2016-us-consumer-payment-study.pdf.

[36] Yu-Chih Tung and Kang G. Shin. 2015. EchoTag: Accurate Infrastructure-Free Indoor Location Tagging with Smartphones. In Proceedings of the 21st Annual International Conference on Mobile Computing and Networking. 525–536.

[37] Yu-Chih Tung and Kang G. Shin. 2016. Expansion of Human-Phone Interface By Sensing Structure-Borne Sound Propagation. In Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services. 277–289.

[38] Sebastian Uellenbeck, Markus Dürmuth, Christopher Wolf, and Thorsten Holz. 2013. Quantifying the security of graphical passwords: the case of android unlock patterns. In Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security. 161–172.

[39] Dirk Van Bruggen, Shu Liu, Mitch Kajzer, Aaron Striegel, Charles R. Crowell, and D’Arcy John. 2013. Modifying Smartphone User Locking Behavior. In Proceedings of the Ninth Symposium on Usable Privacy and Security (SOUP). SOUP, 213–224.

[40] Chen Wang, Yan Wang, Yingying Chen, Hongbo Liu, and Jian Liu. 2020. User authentication on mobile devices: Approaches, threats and trends. Computer Networks 170 (2020), 107–118. https://doi.org/10.1016/j.comnet.2020.107118

[41] WeChat. 2017. Voiceprint. https://thenextweb.com/apps/2015/03/25/wechat-on-ios-now-lets-you-log-in-using-just-your-voice/.

[42] Nan Zheng, Kun Bai, Hai Huang, and Haining Wang. 2014. You Are How You Touch: User Verification on Smartphones via Tapping Behaviors. In ICNP, Vol. 14. 221–232.

[43] Yu Zhong and Yunbin Deng. 2014. Sensor orientation invariant mobile gait biometrics. In Proceedings of the IEEE International Joint Conferene on Biometrics. IEEE.

[44] Bing Zhou, Jay Lohokare, Ruipeng Gao, and Fan Ye. 2018. EchoPrint: Two-factor Authentication using Acoustics and Vision on Smartphones. In Proceedings of the 24th Annual International Conference on Mobile Computing and Networking. 321–336.

[45] Man Zhou, Qian Wang, Jingxiao Yang, Qi Li, Feng Xiao, Zhibo Wang, and Xianfeng Chen. 2018. PatternListener: Cracking Android Pattern Lock Using Acoustic Signals. In ACM Conference on Computer and Communications Security.