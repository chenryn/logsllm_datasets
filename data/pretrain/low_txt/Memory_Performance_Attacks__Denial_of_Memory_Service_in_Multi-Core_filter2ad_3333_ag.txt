### Memory System Performance and Fairness

The memory system we propose enhances the performance of both memory-intensive and non-memory-intensive applications, which are often unfairly delayed by a Memory Performance Hog (MPH).

### Related Work

Several studies have explored the potential for exploiting software vulnerabilities to deny memory allocation to other applications. For instance, [37] describes an attack where one process continuously allocates virtual memory, causing other processes on the same machine to run out of memory space due to the exhaustion of disk swap space. The "memory performance attack" discussed in this paper is fundamentally different from such "memory allocation attacks" because:

1. It exploits vulnerabilities in the hardware system.
2. It cannot be mitigated by software solutions; instead, the hardware algorithms must be modified.
3. It can be caused unintentionally by well-written, non-malicious but memory-intensive applications.

#### Hardware Security in Computer Architecture

There are only a few research papers that address hardware security issues in computer architecture. Woo and Lee [38] describe similar shared-resource attacks developed concurrently with our work, but they do not demonstrate the effectiveness of these attacks in real multi-core systems. In their study, a malicious thread attempts to displace data from shared caches or saturate on-chip or off-chip bandwidth. In contrast, our attack exploits the unfairness in DRAM memory scheduling algorithms, making their attacks and ours complementary.

Grunwald and Ghiasi [12] investigate microarchitectural denial of service (DoS) attacks in Simultaneous Multithreading (SMT) processors. They show that SMT processors have several vulnerabilities that can be exploited by malicious threads, including attacks that affect caching behavior and use self-modifying code to flush the trace cache. The authors propose counter-measures to ensure fair pipeline utilization. Hasan et al. [13] study heat stroke attacks in a simulator, where repeated access to a shared resource creates a hot spot, slowing down the SMT pipeline. Their solution selectively slows down malicious threads. These works present sophisticated ways of hacking existing systems, while our paper highlights a more prevalent and easily exploitable problem: simple, unintentional memory performance hogs that can significantly impact future multi-core systems.

#### Memory Scheduling Algorithms

The FR-FCFS (First-Ready, First-Come, First-Served) scheduling algorithm, implemented in many current single-core and multi-core systems, was studied in [30, 29, 15, 23]. Its best implementation, as presented in Section 2, is due to Rixner et al. [30]. This algorithm, originally designed for single-threaded applications, shows good throughput performance in such scenarios. However, it can negatively impact fairness in chip-multiprocessor systems, as shown in [23]. The performance impact of different memory scheduling techniques in SMT processors and multiprocessors has been considered in [42, 22].

#### Fairness in Shared Resource Management

Fairness in managing access to shared resources has been studied in various contexts. Network fair queuing, for example, ensures guaranteed service to simultaneous flows over a shared network link [24, 40, 3]. Techniques from network fair queuing have been applied to CPU scheduling [6]. The best-known algorithm for network fair scheduling that also addresses the idleness problem was proposed in [2]. Nesbit et al. [23] propose a fair memory scheduler based on network queuing fairness, but directly applying these techniques to DRAM memory scheduling is problematic and can suffer from the idleness problem. Fairness in disk scheduling has been studied in [4, 26], but the physical association of data on the disk (cylinders, tracks, sectors, etc.) makes these techniques inapplicable to DRAM scheduling.

#### Shared Caches in Multi-Core Systems

Shared hardware caches in multi-core systems have been extensively studied, e.g., in [35, 19, 14, 28, 9]. Suh et al. [35] and Kim et al. [19] develop hardware techniques to provide thread-fairness in shared caches. Fedorova et al. [9] and Suh et al. [35] propose modifications to the operating system scheduler to allow each thread its fair share of the cache. While these solutions do not directly apply to DRAM memory controllers, the solution we examine in this paper interacts with both the operating system scheduler and the fairness mechanisms used in shared caches, which we intend to explore in future work.

### Conclusion

The advent of multi-core architectures has generated significant excitement, but it also poses important security risks. We have shown that due to unfairness in the memory system of multi-core architectures, some applications can act as memory performance hogs, degrading the memory-related performance of other applications running on different processors. To mitigate these risks, we propose a memory request scheduling algorithm based on a novel definition of DRAM fairness. As the number of processors integrated on a single chip increases, and multi-chip architectures become more common, the danger of memory performance hogs will likely worsen, necessitating more sophisticated solutions. We hope this paper raises awareness of the security issues involved in the rapid shift towards larger multi-core architectures.

### Acknowledgments

We thank Burton Smith for his inspiring discussions and Hyesoon Kim, Chris Brumme, Mark Oskin, Rich Draves, Trishul Chilimbi, Dan Simon, John Dunagan, Yi-Min Wang, and the anonymous reviewers for their valuable comments and suggestions.

### References

[1] Advanced Micro Devices. AMD Opteron. http://www.amd.com/us-en/Processors/ProductInformation/.

[2] J. H. Anderson, A. Block, and A. Srinivasan. Quick-release fair scheduling. In RTSS, 2003.

[3] J. C. Bennett and H. Zhang. Hierarchical packet fair queuing algorithms. In SIGCOMM, 1996.

[4] J. Bruno et al. Disk scheduling with quality of service guarantees. In Proceedings of IEEE Conference on Multimedia Computing and Systems, 1999.

[5] A. Chander, J. C. Mitchell, and I. Shin. Mobile code security by Java bytecode instrumentation. In DARPA Information Survivability Conference & Exposition, 2001.

[6] A. Chandra, M. Adler, P. Goyal, and P. Shenoy. Surplus fair scheduling: A proportional-share CPU scheduling algorithm for symmetric multiprocessors. In OSDI-4, 2000.

[7] R. S. Cox, J. G. Hansen, S. D. Gribble, and H. M. Levy. A safety-oriented platform for web applications. In IEEE Symposium on Security and Privacy, 2006.

[8] V. Cuppu, B. Jacob, B. Davis, and T. Mudge. A performance comparison of contemporary DRAM architectures. In ISCA-26, 1999.

[9] A. Fedorova, M. Seltzer, and M. D. Smith. Cache-fair thread scheduling for multi-core processors. Technical Report TR-17-06, Harvard University, Oct. 2006.

[10] T. Garfinkel, B. Pfaff, J. Chow, M. Rosenblum, and D. Boneh. Terra: A virtual machine-based platform for trusted computing. In SOSP, 2003.

[11] S. Gochman et al. The Intel Pentium M processor: Microarchitecture and performance. Intel Technology Journal, 7(2), May 2003.

[12] D. Grunwald and S. Ghiasi. Microarchitectural denial of service: Insuring microarchitectural fairness. In MICRO-35, 2002.

[13] J. Hasan et al. Heat stroke: Power-density-based denial of service in SMT. In HPCA-11, 2005.

[14] L. R. Hsu, S. K. Reinhardt, R. Iyer, and S. Makineni. Communist, utilitarian, and capitalist cache policies on CMPs: Caches as a shared resource. In PACT-15, 2006.

[15] I. Hur and C. Lin. Adaptive history-based memory schedulers. In MICRO-37, 2004.

[16] Intel Corporation. Terascale computing. http://www.intel.com/pressroom/archive/releases/20060926corp_b.htm.

[17] Intel Corporation. Pentium D. http://www.intel.com/products/processor_number/chart/pentium_d.htm.

[18] Intel Corporation. Tera-Scale Research Chips. http://www.intel.com/research/platform/terascale/index.htm.

[19] S. Kim, D. Chandra, and Y. Solihin. Fair cache sharing and partitioning in a chip multiprocessor architecture. PACT-13, 2004.

[20] C. K. Luk et al. Pin: Building customized program analysis tools with dynamic instrumentation. In PLDI, 2005.

[21] J. D. McCalpin. STREAM: Sustainable memory bandwidth in high-performance computers. http://www.cs.virginia.edu/stream/.

[22] C. Natarajan, B. Christenson, and F. Briggs. A study of performance impact of memory controller features in multi-processor server environment. In WMPI, 2004.

[23] K. J. Nesbit, N. Aggarwal, J. Laudon, and J. E. Smith. Fair queuing memory systems. In MICRO-39, 2006.

[24] A. K. Parekh. A Generalized Processor Sharing Approach to Flow Control in Integrated Service Networks. PhD thesis, MIT, 1992.

[25] D. Peterson, M. Bishop, and R. Pandey. A flexible containment mechanism for executing untrusted code. In 11th USENIX Security Symposium, 2002.

[26] T. Pradhan and J. Haritsa. Efficient fair disk schedulers. In 3rd Conference on Advanced Computing, 1995.

[27] V. Prevelakis and D. Spinellis. Sandboxing applications. In USENIX 2001 Technical Conf.: FreeNIX Track, 2001.

[28] N. Rafique et al. Architectural support for operating system-driven CMP cache management. In PACT-15, 2006.

[29] S. Rixner. Memory controller optimizations for web servers. In MICRO-37, 2004.

[30] S. Rixner, W. J. Dally, U. J. Kapasi, P. Mattson, and J. D. Owens. Memory access scheduling. In ISCA-27, 2000.

[31] A. Rogers, M. C. Carlisle, J. Reppy, and L. Hendren. Supporting dynamic data structures on distributed memory machines. ACM Transactions on Programming Languages and Systems, 17(2):233â€“263, Mar. 1995.

[32] T. Sherwood et al. Automatically characterizing large-scale program behavior. In ASPLOS-X, 2002.

[33] E. Sprangle and O. Mutlu. Method and apparatus to control memory accesses. U.S. Patent 6,799,257, 2004.

[34] Standard Performance Evaluation Corporation. SPEC CPU2000. http://www.spec.org/cpu2000/.

[35] G. E. Suh, S. Devadas, and L. Rudolph. A new memory monitoring scheme for memory-aware scheduling and partitioning. HPCA-8, 2002.

[36] D. Wang et al. DRAMsim: A memory system simulator. Computer Architecture News, 33(4):100â€“107, 2005.

[37] Y.-M. Wang et al. Checkpointing and its applications. In FTCS-25, 1995.

[38] D. H. Woo and H.-H. S. Lee. Analyzing performance vulnerability due to resource denial of service attack on chip multiprocessors. In Workshop on Chip Multiprocessor Memory Systems and Interconnects, Feb. 2007.

[39] W. Wulf and S. McKee. Hitting the memory wall: Implications of the obvious. ACM Computer Architecture News, 23(1), 1995.

[40] H. Zhang. Service disciplines for guaranteed performance service in packet-switching networks. In Proceedings of the IEEE, 1995.

[41] Z. Zhang, Z. Zhu, and X. Zhang. A permutation-based page interleaving scheme to reduce row-buffer conflicts and exploit data locality. In MICRO-33, 2000.

[42] Z. Zhu and Z. Zhang. A performance comparison of DRAM memory system optimizations for SMT processors. In HPCA-11, 2005.

---

This revised version aims to make the text more coherent, professional, and easier to follow.