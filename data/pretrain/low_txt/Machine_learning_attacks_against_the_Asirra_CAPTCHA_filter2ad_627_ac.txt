### Asirra Challenge and Attacks

**Asirra Challenge Overview:**
The Asirra challenge consists of 12 images, each depicting either a cat or a dog. To solve the challenge, one must correctly identify all the cat images.

**Generic Attack:**
A classifier with a success probability \( p \) (where \( 0 < p < 1 \)) for correctly classifying a single Asirra image can solve a 12-image Asirra challenge with a probability of \( p^{12} \). Our best classifier has an accuracy of 82.74%, which translates to a 10.3% chance of solving an Asirra challenge completely automatically. This success probability is independent of the distribution used to generate the Asirra challenges.

**Leveraging Prior Information:**
The success probability can be improved if the attacker has knowledge of the prior probability distribution of Asirra challenges over the space \(\{Cat, Dog\}^{12}\).

Let \( C = \{I_1, \ldots, I_{12}\} \) denote a 12-image Asirra challenge, and let \( A = \{a_1, \ldots, a_{12}\} \), where \( a_i \in \{Cat, Dog\} \), represent the assignment of the images \( I_1, \ldots, I_{12} \) to the "cat" and "dog" classes. According to Bayes' rule:

\[ \Pr[A|C] = \frac{\Pr[A] \Pr[C|A]}{\Pr[C]} \]

The attacker's goal is to compute \( \max_A \Pr[A|C] \), or equivalently \( \max_A (\Pr[A] \Pr[C|A]) \). The first term, \( \Pr[A] \), is the prior probability distribution assumed to be known by the attacker. The second term, \( \Pr[C|A] \), can be estimated by the attacker using a classifier that produces real-valued outputs.

**Example:**
The exact rules for creating Asirra challenges are not precisely specified in [7]. However, it seems that the 12 images are drawn uniformly at random, either from the full Asirra database of more than 3,000,000 images or from a subset of images of pets located near the user. If this assumption is correct, each image in an Asirra challenge is drawn independently at random from the "cat" class with probability \( q \) and from the "dog" class with probability \( 1 - q \). An attacker can learn the value of \( q \) by observing Asirra challenges. Our measurements suggest \( q \approx 0.5 \), as we found approximately the same number of cats and dogs in our sample of the Asirra database.

Using this information, we can compute the most likely assignment \( A \) for a given challenge: \( \max_A (\Pr[A] \Pr[C|A]) \). In this example, \( \Pr[A] = q^w (1 - q)^{12-w} \), where \( w \) is the number of cats in \( A \). Using the combined color and texture classifier from section 2.3 to estimate \( \Pr[C|A] \), we solve an Asirra challenge with a probability of 10.4%. This probability is only slightly higher than that of the generic attack (10.3%). The reason is that, with the classifier of section 2.3, the generic attack already produces assignments that nearly follow a binomial distribution of cats and dogs.

**Hypothetical Example:**
Consider a hypothetical variant of Asirra where every challenge contains exactly 6 images of cats and 6 images of dogs. Here, \( \Pr[A] = 0 \) if the number of cats and dogs in \( A \) are not equal, and \( \Pr[A] = \frac{1}{\binom{12}{6}} \) otherwise. Using the Bayesian formula and the classifier from section 2.3, we can solve these variant Asirra challenges automatically with a probability of 23.8%. While this variant may be attractive from a usability perspective (users may solve Asirra challenges faster if they know they must find exactly 6 cats), our analysis shows that it is insecure and should be avoided.

### Enhancements to Asirra

**Partial Credit Algorithm (PCA):**
Two enhancements to Asirra are proposed in [7]. The first is a partial credit algorithm designed to improve the usability of Asirra for human users. The second is a token bucket scheme designed to harden Asirra against automated attacks.

- **Partial Credit Algorithm (PCA):** A user who correctly classifies 11 out of 12 images in an Asirra challenge is considered to have "nearly" solved the challenge. The user is placed in an intermediate state and presented with a second challenge. If the user solves or nearly solves the second challenge (i.e., identifies 11 or 12 images correctly), the user passes. Otherwise, the user fails and returns to the default (non-intermediate) state.

- **Token Bucket Scheme:** The token bucket scheme punishes users who fail many Asirra challenges. These users must solve two Asirra challenges in close succession to be considered successful. The scheme is parameterized by a parameter TB-refill, which specifies how many chances the user is given to correctly solve a second CAPTCHA after solving the first one. A value TB-refill = 1 means that a user who has failed "too many" Asirra challenges must then solve two successive CAPTCHAs correctly to be considered successful.

**Impact on Classifier Success:**
- **Partial Credit Algorithm (PCA):** Table 6 shows the impact of the partial credit algorithm on the success of the classifier from section 2.3. With PCA, the success rate of our automatic classifier is 38.0% after 3 challenges, which is unacceptably high. We recommend that the partial credit algorithm should not be deployed with Asirra.
  
- **Token Bucket Scheme:** Table 7 shows the impact of the token bucket scheme on the success of the classifier from section 2.3. Our results suggest that PCA leads to weak security, even in combination with the token bucket scheme. On the other hand, Asirra appears reasonably secure with the parameter TB-refill = 1, since our attack in that case is only 1.1% successful (although this parameter also significantly decreases the human success rate, negatively impacting usability).

### Defenses

**Best Defenses:**
The best defenses against machine learning attacks on Asirra include IP monitoring schemes, which prevent an adversary from requesting and attempting to solve too many Asirra challenges. The token bucket scheme proposed in [7] is a clever instantiation of an IP monitoring scheme. The strictest version of the token bucket scheme reduces the probability of solving an Asirra challenge automatically to 1.1%, but also reduces the usability of Asirra for humans. The token bucket scheme could be further strengthened by requiring users to correctly solve more than two Asirra challenges in a row, but this would also negatively affect human usability.

**Other Approaches:**
- **Increasing Image Count:** Another approach to improving the security of Asirra is to increase the number of images used in challenges.
- **Image Distortion:** Distorting, warping, or degrading the quality of the images is unlikely to significantly lower the accuracy of SVM classifiers based on color and texture features, as these features are largely unaffected by global image distortions.
- **Grayscale Images:** Using grayscale images instead of color images may decrease the accuracy of the color classifiers from section 2.1 but would likely have little effect on the texture classifiers from section 2.2. These techniques do not appear promising, as they are unlikely to dent the effectiveness of automatic classifiers without also significantly reducing the usability advantage that is Asirraâ€™s greatest strength.

### Related Work

**Text-Based CAPTCHAs:**
Several attacks have been reported against text-based CAPTCHAs. Mori and Malik [14] proposed object recognition algorithms that succeeded in recognizing words in the EZ-Gimpy CAPTCHA with a probability of 92% and in the Gimpy CAPTCHA with a probability of 33%. More recently, attacks have been reported in the popular press against the CAPTCHAs used by Yahoo! [15] and Google [16], although few details are available. Very recent work [17] provides a detailed description of character segmentation attacks against Microsoft and Yahoo! CAPTCHAs.

**User-Friendly, Clickable CAPTCHAs:**
Beyond Asirra, there have been other proposals for user-friendly, clickable CAPTCHAs. For example, Lopresti [12] proposes asking users to select the right orientation of a page through a click. BotBarrier [2] asks users to click on a specified location in an image. The security of these proposals relies on new and relatively untested assumptions. It is not clear whether these assumptions will withstand the test of time.

Another approach to clickable CAPTCHAs was recently proposed by Chow et al. [4]. The approach combines several textual CAPTCHAs into a grid of clickable CAPTCHAs (e.g., a 3-by-4 grid). The solution to the grid is the determination (e.g., by clicking) of the grid elements that satisfy some given requirement. One advantage of this approach is that it relies on existing security assumptions about text-based CAPTCHAs that have been in use for a long time and have been the object of intense scrutiny.

### Conclusion

We describe a classifier that is 82.7% accurate in distinguishing between the images of cats and dogs used in Asirra. This classifier allows us to solve a 12-image Asirra challenge with a probability of 10.3%. The weakness we have exposed in the current implementation of Asirra cautions against deploying Asirra without additional safeguards. With appropriate safeguards, notably the token bucket scheme described in [7], we believe that Asirra continues to offer an appealing balance between security and usability. We hope that this work will contribute to the secure deployment of Asirra.

### Acknowledgements

I would like to thank David Goldberg, Maurice Chu, Richard Chow, Glenn Durfee, and Kurt Partridge for valuable feedback on this project. Glenn and Richard also helped manually classify training images, for which I am very grateful. I would like to thank Jeremy Elson, John Douceur, and Jon Howell for generously answering my questions about ASIRRA and offering additional labeled images. Finally, I would like to thank the anonymous reviewers whose comments helped improve this paper.

### References

[1] MSR Asirra: A Human Interactive Proof. On the Web at http://research.microsoft.com/asirra/
[2] BotBarrier.com. On the web at http://www.botbarrier.com/
[3] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a library for support vector machines, 2001. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm
[4] R. Chow, P. Golle, M. Jakobsson, X. Wang, and L. Wang. Making CAPTCHAs Clickable. In Proc. of HotMobile 2008.
[5] C. Cortes and V. Vapnik. Support-vector network. Machine Learning 20, 273â€“297, 1995.
[6] J. Douceur and J. Elson. Private communication.
[7] J. Elson, J. Douceur, J. Howell, and J. Saul. Asirra: a CAPTCHA that exploits interest-aligned manual image categorization. In Proc. of ACM CCS 2007, pp. 366â€“374.
[10] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning (Data Mining, Inference, and Prediction). Springer Series in Statistics, 2001.
[11] P. Kruizinga, N. Petkov, and S.E. Grigorescu. Comparison of texture features based on Gabor filters. In Proc. of the 10th International Conference on Image Analysis and Processing (1999), pp. 142â€“147.
[12] D. Lopresti. Leveraging the CAPTCHA problem. In Proc. of the Second International Workshop on Human Interactive Proofs, pp. 97â€“110. Springer Verlag, 2005.
[13] I. Mironov and L. Zhang. Applications of SAT Solvers to Cryptanalysis of Hash Functions. In Theory and Applications of Satisfiability Testing â€“ SAT 2006, pp. 102â€“115, 2006.
[14] G. Mori and J. Malik. Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA. In Proc. of the 2003 Conference on Computer Vision and Pattern Recognition, pp. 134â€“144. IEEE Computer Society, 2003.
[15] SlashDot. Yahoo CAPTCHA Hacked (posted Jan 29, 2008). On the Web at http://it.slashdot.org/it/08/01/30/0037254.shtml
[16] Websense Blog (posted Feb 22, 2008). Googleâ€™s CAPTCHA busted in recent spammer tactics. On the web at http://securitylabs.websense.com/content/Blogs/2919.aspx
[17] J. Yan and A. El Ahmad. A Low-cost Attack on a Microsoft CAPTCHA. To appear in Proc. of ACM CCS 2008.