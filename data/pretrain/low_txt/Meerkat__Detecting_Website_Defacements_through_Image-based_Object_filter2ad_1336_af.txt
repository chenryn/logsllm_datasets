### Similarity Based on Root Mean Squared Deviation

If the root mean squared deviation (RMSD) between the histograms of two images is below a manually determined threshold, the images are considered similar. However, a defacement detection system based on this technique is not suitable in an adversarial context. An attacker can easily evade such a system by slightly altering the colors or adding dynamic content, thereby increasing the RMSD above the threshold while maintaining visual similarity to the human eye. Furthermore, as with Nappa et al. [66], this method requires pairwise comparison of the histogram of the screenshot to be classified with all previously seen defacements, leading to a detection time that increases with each observed defacement. The best-case scenario is O(log n), and the worst-case scenario is O(n), where n is the number of observed defacements.

### Advantages of MEERKAT

MEERKAT overcomes these limitations by learning high-level features from the general look and feel of defacements, enabling it to detect previously unseen defacements. Additionally, its classification time remains constant regardless of the number of already-seen defacements.

## Conclusions

In this paper, we introduced MEERKAT, a monitoring system designed to detect website defacements. MEERKAT leverages recent advances in machine learning, such as stacked autoencoders and deep neural networks, combined with computer vision techniques. Unlike previous approaches, MEERKAT does not rely on additional information from the website's operator or manually engineered features. Instead, it automatically learns high-level features from the data. By focusing on specific regions of the website screenshot rather than the entire image, MEERKAT is robust to the normal evolution of websites and can be scaled effectively. To further enhance robustness against defacement variants, MEERKAT employs techniques like dropout and fine-tuning.

We demonstrated the effectiveness of MEERKAT using the largest website defacement dataset to date, which includes 10,053,772 defacements observed between January 1998 and May 2014, and 2,554,905 legitimate websites. MEERKAT achieved a true positive rate between 97.422% and 98.816%, a false positive rate between 0.547% and 1.528%, and a Bayesian detection rate between 98.583% and 99.845%, significantly outperforming existing state-of-the-art methods.

## Acknowledgments

We would like to express our gratitude to the reviewers for their valuable feedback, comments, and suggestions, which have greatly improved the quality of this paper.

This work was supported by the Office of Naval Research (ONR) under grant N00014-12-1-0165, the Army Research Office (ARO) under grant W911NF-09-1-0553, the Department of Homeland Security (DHS) under grant 2009-ST-061-CI0001, the National Science Foundation (NSF) under grant CNS-1408632, Lastline Inc., and SBA Research.

## References

[1] G. Davanzo, E. Medvet, and A. Bartoli, “A Comparative Study of Anomaly Detection Techniques in Web Site Defacement Detection,” in Proceedings of the IFIP 20th World Computer Congress, Springer, 2008.

[2] Anonymous, Reference blinded for double-blind review process, Nov. 2014. [Online]. Available: http://anonymized.

[3] Wall Street Journal (WSJ), Malaysia Airlines Website Hacked by Group Calling Itself ‘Cyber Caliphate’, Jan. 26, 2015. [Online]. Available: http://goo.gl/RhO2tO.

[4] British Broadcasting Company (BBC), Keighley Cougars website hacked to read 'I love you Isis', Nov. 2014. [Online]. Available: http://goo.gl/bzxJ8M.

[5] R. Preatoni, M. Almeida, K. Fernandez, and other unknown authors, Zone-H.org - Unrestricted Information, since January 1998. [Online]. Available: http://zone-h.org/.

[6] E. Kovacs, Softpedia Interview: Alberto Redi, Head of Zone-H, Jun. 8, 2013. [Online]. Available: http://goo.gl/cwPBrW.

[7] Malaysian Computer Emergency Response Team, MyCERT Incident Statistics, Jan. 2014. [Online]. Available: http://goo.gl/0LTRPj.

[8] CyberSecurity Malaysia, “MyCERT 2nd Quarter 2013 Summary Report,” eSecurity Bulletin, vol. 34, Aug. 2013.

[9] S. Mansfield-Devine, “Hacktivism: assessing the damage,” Network Security, vol. 2011, no. 8, 2011.

[10] M. Gorge, “Cyberterrorism: hype or reality?,” Computer Fraud & Security, vol. 2007, no. 2, 2007.

[11] H. Kircher, “The Practice of War: Production, Reproduction and Communication of Armed Violence,” Berghahn Books, Mar. 2011, ch. 12. Martyrs, Victims, Friends and Foes: Internet Representations by Palestinian Islamists.

[12] G. Weimann, “Terror on the Internet: The New Arena, the New Challenges,” US Institute of Peace Press, 2006, ch. 6. Fighting Back: Responses to Terrorism on the Internet, and Their Cost.

[13] Wall Street Journal (WSJ), Google Access Is Disrupted in Vietnam, Feb. 23, 2015. [Online]. Available: http://goo.gl/JlVtfW.

[14] L. Makani, 100+ Zambian websites hacked & defaced: Spar, Post-dotnet, SEC, Home Affairs, Ministry of Finance, Apr. 2014. [Online]. Available: http://goo.gl/NvQsJM.

[15] British Broadcasting Company (BBC), Angry Birds website hacked after NSA-GCHQ leaks, Jan. 2014. [Online]. Available: http://goo.gl/kHDIAj.

[16] A. Mittal, NIC of Suriname, Antigua & Barbuda and Saint Lucia Hacked by Pakistani Hackers, Oct. 2013. [Online]. Available: http://goo.gl/ynGG0y.

[17] J. Leyden, Islamist hackers attack Danish sites, Feb. 2006. [Online]. Available: http://goo.gl/jcE7iv.

[18] ——, Hacktivists attack UN.org, Aug. 2007. [Online]. Available: http://goo.gl/SfvkUc.

[19] G. Maone, United Nations vs. SQL Injections, Aug. 2007. [Online]. Available: http://goo.gl/v8oXih.

[20] S. Reid, Hip-Hop Sites Hacked By Apparent Hate Group; SOHH, AllHipHop Temporarily Suspend Access, Jun. 2008. [Online]. Available: http://goo.gl/VtW4i6.

[21] B. Acohido, State Department webpages defaced, Oct. 23, 2013. [Online]. Available: http://goo.gl/698XRW.

[22] J. Leyden, Foxconn website defaced after iPhone assembly plant suicides, May 2010. [Online]. Available: http://goo.gl/6BtZbX.

[23] ——, Anti-Israel hackers deface central bank site, Apr. 2008. [Online]. Available: http://goo.gl/7Ve2xT.

[24] British Broadcasting Company (BBC), Nottinghamshire Police website hacked by AnonGhost, Nov. 2014. [Online]. Available: http://goo.gl/Gbldxt.

[25] ——, Shropshire Fire Service website hacked by AnonGhost, Nov. 2014. [Online]. Available: http://goo.gl/3dq4Cq.

[26] D. Dagon, M. Antonakakis, P. Vixie, T. Jinmei, and W. Lee, “Increased DNS Forgery Resistance Through 0x20-Bit Encoding: SecURItY viA LeET QueRieS,” in Proceedings of the 15th ACM Conference on Computer and Communications Security (CCS), ACM, 2008.

[27] G. Vigna and C. Kruegel, “Host-based Intrusion Detection,” Handbook of Information Security. John Wiley and Sons, 2005.

[28] A. Bartoli, G. Davanzo, and E. Medvet, “The Reaction Time to Web Site Defacements,” Internet Computing, IEEE, vol. 13, no. 4, 2009.

[29] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker, “Spamscatter: Characterizing Internet Scam Hosting Infrastructure,” in Proceedings of 16th USENIX Security Symposium on USENIX Security Symposium, ser. SS’07, USENIX Association, 2007.

[30] K. Borgolte, C. Kruegel, and G. Vigna, “Delta: Automatic Identification of Unknown Web-based Infection Campaigns,” in Proceedings of the 20th ACM SIGSAC Conference on Computer and Communications Security (CCS), ACM, 2013.

[31] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. LeCun, “OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks,” in Proceedings of the 2nd International Conference on Learning Representations (ICLR), CBLS, Apr. 2014.

[32] Q. Le, M. Ranzato, R. Monga, M. Devin, K. Chen, G. Corrado, J. Dean, and A. Ng, “Building High-level Features Using Large Scale Unsupervised Learning,” in Proceedings of the 29th International Conference on Machine Learning (ICML), IMLS, Jun. 2012.

[33] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet Classification with Deep Convolutional Neural Networks,” in Advances in Neural Information Processing Systems 25 (NIPS), vol. 1, 2012.

[34] R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hierarchies for accurate object detection and semantic segmentation,” arXiv preprint arXiv:1311.2524, 2013.

[35] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” Proceedings of the IEEE, vol. 86, no. 11, 1998.

[36] R. Raina, A. Madhavan, and A. Y. Ng, “Large-scale deep unsupervised learning using graphics processors,” in Proceedings of the 26th International Conference on Machine Learning (ICML), 2009.

[37] Q. V. Le, J. Ngiam, Z. Chen, D. J. hao Chia, P. W. Koh, A. Y. Ng, and D. Chia, “Tiled convolutional neural networks,” in Advances in Neural Information Processing Systems 23 (NIPS), 2010.

[38] H. Lee, R. Grosse, R. Ranganath, and A. Y. Ng, “Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations,” in Proceedings of the 26th Annual International Conference on Machine Learning (ICML), ACM, 2009.

[39] P. Sermanet, S. Chintala, and Y. LeCun, “Convolutional neural networks applied to house numbers digit classification,” in Proceedings of the 21st International Conference on Pattern Recognition (ICPR), IEEE, 2012.

[40] A. Hyvärinen, J. Hurri, and P. O. Hoyer, Natural Image Statistics: A Probabilistic Approach to Early Computational Vision. Springer, 2009, vol. 39.

[41] K. Gregor and Y. LeCun, “Emergence of complex-like cells in a temporal product network with local receptive fields,” arXiv preprint arXiv:1006.0448, 2010.

[42] K. Jarrett, K. Kavukcuoglu, M. Ranzato, and Y. LeCun, “What is the best multi-stage architecture for object recognition?,” in Proceedings of the 12th IEEE International Conference on Computer Vision, IEEE, 2009.

[43] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov, “Improving neural networks by preventing co-adaptation of feature detectors,” arXiv preprint arXiv:1207.0580, 2012.

[44] Y. Jia, Caffe: An Open Source Convolutional Architecture for Fast Feature Embedding, 2013. [Online]. Available: http://goo.gl/Fo9YO8.

[45] S. Axelsson, “The Base-Rate Fallacy and the Difficulty of Intrusion Detection,” ACM Transactions on Information and System Security (TISSEC), vol. 3, no. 3, 2000.

[46] G. Davanzo, E. Medvet, and A. Bartoli, “Anomaly Detection Techniques for a Web Defacement Monitoring Service,” Expert Systems with Applications, vol. 38, no. 10, 2011.

[47] A. Bartoli and E. Medvet, “Automatic Integrity Checks for Remote Web Resources,” Internet Computing, IEEE, vol. 10, no. 6, 2006.

[48] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. Tygar, “Adversarial Machine Learning,” in Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence (AISEC), ACM, Oct. 2011.

[49] M. Barreno, B. Nelson, A. D. Joseph, and J. Tygar, “The Security of Machine Learning,” Machine Learning, vol. 81, no. 2, 2010.

[50] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar, “Can machine learning be secure?,” in Proceedings of the 13th ACM Symposium on Information, Computer and Communications Security (CCS), ACM, Oct. 2006.

[51] N. Šrndic and P. Laskov, “Practical Evasion of a Learning-Based Classifier: A Case Study,” in Proceedings of the 35th IEEE Symposium on Security and Privacy (Oakland), IEEE, May 2014.

[52] D. Lowd and C. Meek, “Adversarial Learning,” in Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining (KDD), ACM, Aug. 2005.

[53] N. Dalvi, P. Domingos, Mausam, S. Sanghai, and D. Verma, “Adversarial Classification,” in Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), ACM, 2004.

[54] A. Globerson and S. Roweis, “Nightmare at Test Time: Robust Learning by Feature Deletion,” in Proceedings of the 23rd International Conference on Machine Learning (ICML), ACM, 2006.

[55] H. Xiao, H. Xiao, and C. Eckert, “Adversarial label flips attack on support vector machines,” in Proceedings of the 20th European Conference on Artificial Intelligence (ECAI), Aug. 2012.

[56] D. Wagner and P. Soto, “Mimicry Attacks on Host-based Intrusion Detection Systems,” in Proceedings of the 9th ACM Conference on Computer and Communications Security (CCS), ACM, 2002.

[57] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna, “Automating Mimicry Attacks Using Static Binary Analysis,” in Proceedings of the 14th Conference on USENIX Security Symposium, USENIX Association, 2005.

[58] A. Kapravelos, Y. Shoshitaishvili, M. Cova, C. Kruegel, and G. Vigna, “Revolver: An Automated Approach to the Detection of Evasive Web-based Malware,” in Proceedings of the 22nd USENIX Security Symposium, 2013.

[59] C. Kolbitsch, E. Kirda, and C. Kruegel, “The Power of Procrastination: Detection and Mitigation of Execution-stalling Malicious Code,” in Proceedings of the 18th ACM Conference on Computer and Communications Security (CCS), ACM, 2011.

[60] K. Borgolte, C. Kruegel, and G. Vigna, “Relevant Change Detection: Framework for the Precise Extraction of Modified and Novel Web-based Content as a Filtering Technique for Analysis Engines,” in Proceedings of the Companion Publication of the 23rd International World Wide Web Conference (WWW), IW3C2, 2014.

[61] E. Medvet, C. Fillon, and A. Bartoli, “Detection of Web Defacements by Means of Genetic Programming,” in Proceedings of the 3rd International Symposium on Information Assurance and Security, IEEE Computer Society, 2007.

[62] G. H. Kim and E. H. Spafford, “The Design and Implementation of Tripwire: A File System Integrity Checker,” in Proceedings of the 2nd ACM Conference on Computer and Communications Security (CCS), ACM, 1994.

[63] A. G. Pennington, J. D. Strunk, J. L. Griffin, C. A. N. Soules, G. R. Goodson, and G. R. Ganger, “Storage-based Intrusion Detection: Watching Storage Activity for Suspicious Behavior,” in Proceedings of the 12th Conference on USENIX Security Symposium, USENIX Association, 2003.

[64] E. Medvet, E. Kirda, and C. Kruegel, “Visual-similarity-based Phishing Detection,” in Proceedings of the 4th International Conference on Security and Privacy in Communication Networks (SecureComm), ACM, 2008.

[65] W. Liu, X. Deng, G. Huang, and A. Y. Fu, “An Antiphishing Strategy Based on Visual Similarity Assessment,” Internet Computing, IEEE, vol. 10, no. 2, 2006.

[66] A. Nappa, M. Rafique, and J. Caballero, “Driving in the Cloud: An Analysis of Drive-by Download Operations and Abuse Reporting,” English, in Detection of Intrusions and Malware, and Vulnerability Assessment, ser. Lecture Notes in Computer Science, K. Rieck, P. Stewin, and J.-P. Seifert, Eds., vol. 7967, Springer Berlin Heidelberg, 2013. [Online]. Available: http://goo.gl/Z2IJ4D.

[67] C. Grier, L. Ballard, J. Caballero, N. Chachra, C. J. Dietrich, K. Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pitsillidis, N. Provos, M. Z. Rafique, M. A. Rajab, C. Rossow, K. Thomas, V. Paxson, S. Savage, and G. M. Voelker, “Manufacturing Compromise: The Emergence of Exploit-as-a-Service,” in Proceedings of the 2012 ACM Conference on Computer and Communications Security, ser. CCS ’12, ACM, 2012. [Online]. Available: http://goo.gl/M1DOdZ.

## Appendix

### A. Reporter Cross-validation Split

In our reporter split experiment (Section 4.4), we divided the dataset by reporter to simulate the emergence of a new defacer group. Each cross-validation bin contains the same number of reporters, but because they reported different numbers of defacements, the bins do not contain the same number of samples. We account for the size difference in our experiments by weighting each bin. Table 3 lists the number of samples per bin.

| Bin | 1       | 2       | 3       | 4       | 5       | 6       | 7       | 8       | 9       | 10      | Total   |
|-----|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|
| Defacements | 1,116,808 | 992,232 | 712,270 | 907,306 | 696,069 | 734,208 | 1,276,764 | 789,895 | 979,309 | 1,053,147 | 9,258,008 |
| Legitimate Websites | 308,202 | 273,823 | 196,563 | 250,387 | 192,092 | 202,617 | 352,345 | 217,985 | 270,257 | 290,634 | 2,554,905 |

**Table 3:** Number of samples per cross-validation bin used for the reporter split. Note that the total number of defacements in the reporter split contains 168 defacements less than available in the whole dataset because otherwise reporters would be distributed unevenly per bin. However, due to the considerable size of the dataset, omitting these defacements has negligible impact.

### B. Image-based Object Recognition

Much prior work in computer vision has focused on classifying images and recognizing objects within them. Recently, object recognition has experienced a resurgence with the rise of deep learning. Deep learning has gained traction due to its ability to train on large datasets and consistently outperform other algorithms. We discuss our two main inspirations:

- **Le et al. [32]**: Introduce a feature learning approach that leverages unsupervised learning with a deep network comprised of stacked sparse autoencoders utilizing pooling and local contrast normalization. The main idea is to learn high-level features from only unlabeled data (10 million pictures from random YouTube videos). After training, the network improves upon the prior state-of-the-art by 70% on the ImageNet dataset.
  
- **Krizhevsky et al. [33]**: Employ supervised learning to train a deep convolutional neural network to classify 1.2 million images spanning 1,000 classes from a subset of the ImageNet dataset. They achieve a top-1 error rate of 37.5% (the classifier is correct for 62.5%) and a top-5 error rate of 17.0% (for 83% of images, the correct class is among the top 5 classes). To prevent overfitting and reduce training time, they use rectified linear units as the neurons' output functions.