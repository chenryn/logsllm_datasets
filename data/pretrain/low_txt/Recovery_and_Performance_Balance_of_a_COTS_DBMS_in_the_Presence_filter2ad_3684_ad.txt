### Proceedings of the International Conference on Dependable Systems and Networks (DSN’02)
**0-7695-1597-5/02 $17.00 © 2002 IEEE**
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 19, 2021 at 04:16:58 UTC from IEEE Xplore. Restrictions apply.**

#### Fault Recovery Analysis

For faults that require processing of archive log files, the recovery time is not influenced by the frequency of checkpoints. This is because the recovery process begins from a checkpoint that is no longer stored in the online redo log files. In practice, recovery typically starts with the restoration of database files from a backup. In such cases, the recovery time depends on the size of the archive log files. Smaller files can increase recovery time due to the need to process a larger number of files. Conversely, larger files generally result in shorter recovery times.

**Fault Configuration and Recovery Time (in seconds):**
- **Injection 150 Sec:**
  - F40G3T10: 31
  - F40G3T5: 28
  - F40G3T1: 24
  - F10G3T5: 21
  - F10G3T1: 19
  - F1G6T1: 14
  - F1G3T1: 17
  - F1G2T1: 18

- **Injection 300 Sec:**
  - F40G3T10: 33
  - F40G3T5: 39
  - F40G3T1: 32
  - F10G3T5: 36
  - F10G3T1: 35
  - F1G6T1: 59
  - F1G3T1: 55
  - F1G2T1: 48

- **Injection 600 Sec:**
  - F40G3T10: 10
  - F40G3T5: 9
  - F40G3T1: 11
  - F10G3T5: 6
  - F10G3T1: 6
  - F1G6T1: 3
  - F1G3T1: 4
  - F1G2T1: 6

- **Set tablespace offline:**
  - Always close to 1 second

**Table 5. Recovery time for faults with complete recovery.**

For faults that result in incomplete recovery, some committed transactions may be lost. However, the number of lost transactions is consistently small because recovery is initiated immediately after the fault occurs. In real-world scenarios, the detection time may vary based on the actions of the database administrator. In our experiments, we assumed a constant and short detection time to focus on assessing the effectiveness of the recovery mechanisms rather than the reaction time of the database administrator.

An important finding is that none of the operator faults caused data integrity violations.

#### Results with Stand-by Database

The primary goal of a stand-by database is to reduce recovery time and minimize downtime. The stand-by database is maintained in a permanent recovery state, where it processes the redo entries in the archive logs of the primary database. Different configurations of the archive logs and online redo logs affect the behavior of the stand-by database. Additionally, the activation of the archive logs mechanism and the sharing of archive log files between the primary and stand-by databases can cause some performance overhead.

**Figure 6. Performance and recovery time with archive logs and stand-by database.**

- **Recovery Time (seconds) for Archive Logs:**
  - F40G3T10: 34
  - F40G3T5: 31
  - F40G3T1: 24
  - F10G3T5: 21
  - F10G3T1: 22
  - F1G6T1: 13
  - F1G3T1: 13
  - F1G2T1: 17

- **Recovery Time (seconds) for Stand-by DB:**
  - F40G3T10: 42
  - F40G3T5: 40
  - F40G3T1: 43
  - F10G3T5: 51
  - F10G3T1: 55
  - F1G6T1: 109
  - F1G3T1: 98
  - F1G2T1: 70

- **Performance Impact (Transactions per minute):**
  - F40G3T10: 17
  - F40G3T5: 18
  - F40G3T1: 11
  - F10G3T5: 7
  - F10G3T1: 5
  - F1G6T1: 5
  - F1G3T1: 4
  - F1G2T1: 3

- **Stand-by Database Activation Time:**
  - Always close to 1 second

**Figure 7. Lost transactions in the stand-by database.**

- **Lost Transactions:**
  - F40G3T10: 5000
  - F40G3T5: 4000
  - F40G3T1: 3000
  - F10G3T5: 2000
  - F10G3T1: 1000
  - F1G6T1: 0
  - F1G3T1: 0
  - F1G2T1: 0

In a stand-by database, the recovery time is consistent across all faults because the activation time of the stand-by database is independent of the primary database. Figure 6 shows the recovery times for operator faults injected 600 seconds after the workload starts. For comparison, the recovery times obtained with the archive log mechanism for the "Delete Datafile" fault, also injected 600 seconds after the workload start, are presented. A significant reduction in recovery time is achieved with the stand-by database.

However, if the primary database's current redo log group cannot be archived due to a system crash, the transactions associated with those log entries are lost, and the corresponding committed transactions cannot be recovered. To minimize the number of lost redo log entries, the size of the redo log files should be as small as possible. Figure 7 illustrates the number of lost transactions for different redo log file sizes and different numbers of redo log groups.

### Conclusion

This paper presents an experimental approach to characterize both the performance and recoverability of DBMS by extending the standard TPC-C benchmark. The approach includes a faultload based on operator faults and measures related to recoverability. Given the often artificial performance results of typical benchmarks, this method is useful for characterizing DBMS in realistic scenarios. The same environment can also be used to evaluate recovery mechanisms in DBMS, including recovery time, data integrity violations, and lost transactions.

The paper proposes a classification of operator faults for DBMS and defines a comprehensive set of types of operator faults. A set of tools has been designed and built to reproduce operator faults in Oracle DBMS, which, to the best of our knowledge, is the first proposal for an environment to inject operator faults in DBMS.

The experimental results, analyzed and discussed in detail, show that recovery mechanisms do impact peak performance but also demonstrate that it is possible to configure the Oracle DBMS to achieve good recovery features with moderate or minimal performance impact. Without an experimental approach like the one proposed, it would be challenging to identify well-balanced configurations.

### References

[1] Transaction Processing Performance Consortium, “TPC Benchmark C, Standard Specification, Version 5.0,” 2001, available at: http://www.tpc.org/tpcc/.

[2] S. Bagchi, Y. Liu, K. Whisnant, Z. Kalbarczyk, R. Iyer, Y. Levendel, “A Framework for Database Audit and Control Flow Checking for a Wireless Telephone Network Controller”, Proc. of the 2001 Intl. Conference on Dependable Systems and Networks, Gotheburg, Sweden, 1-4 July, 2001, pp.225-234.

[3] W. T. Ng and P. M. Chen, “Integrating Reliable Memory in Databases”, In Proceedings of the 1997 Intl. Conf. on Very Large Databases (VLDB), pages 76-85, August 1997.

[4] S.Chandra and Peter M.Chen, "How Fail-Stop are Faulty Programs?", 28th International Symposium on Fault-Tolerant Computing, Munich, Germany, 1998, pp. 240-249.

[5] M. Sabaratnam, Ø. Torbjørsen, and S.Hvasshovd, “Evaluating the Effectiveness of Fault Tolerance in Replicated Database Management Systems”, 29th International Symposium on Fault-Tolerant Computing, June 15-18, Madison, Wisconsin, 1999, pp. 306-313.

[6] D. Costa, T. Rilho, and H. Madeira, “Joint Evaluation of Performance and Robustness of a COTS DBMS Through Fault-Injection”, IEEE/IFIP Dependable Systems and Networks Conference – DSN (FTCS-30 e DCCA-8), New York, USA, 25-28 June, 2000, pp. 251-260.

[7] Aaron Brown and David Patterson, "Towards availability benchmark: software RAID systems", Proceedings of 2000 USENIX Annual Technical Conference, San Diego, California, USA, June 18-23, 2000, pp 263-276.

[8] H. Madeira, “Dependability Benchmarking: making choices in an n-dimensional problem space”, First Workshop on Evaluating and Architecting System Dependability (EASY), DSN-2001, Göteborg, Sweden, July 1, 2001.

[9] K. Kanoun, J. Arlat, D. Costa, M. Dal Cin, P. Gil, J-C. Laprie, H. Madeira, and N. Suri, “DBench: Dependability Benchmarking”, in Suppl. of the Int. Conference on Dependable Systems and Networks, DSN-2001, Chalmers University of Technology, Göteborg, Sweden, 2001, pp. D.12-D.15.

[10] R. Ramakrishnan, “Database Management Systems” second edition, McGraw Hill, ISBN 0-07-232206-3.

[11] E. F. Codd, "A Relational Model of Data for Large Shared Data Banks ", Communications of the ACM (1970).

[12] E. F. Codd, The Relational Model for Database Management, ISBN 0-201-14192-2.

[13] C. J. Date and Hugh Darwen, “The SQL Standard”, Third Edition (Addison-Wesley Publishing Company, 1993), 414 pages; paperbound; ISBN 0-201-55822-X.

[14] J. Gray and A. Reuter, “Transaction Processing: Concepts and Techniques”, The Morgan Kaufmann Series in Data Management Systems, Jim Gray, Series Editor 1993, ISBN 1-55860-190-2.

[15] Oracle Corp., "Oracle 8i Server Concepts Manual", 1999.

[16] J. Gray, “A Census of Tandem Systems Availability Between 1985 and 1990”, IEEE Transactions on Reliability, Vol. 39, No. 4, pp. 409-418, October 1990.

[17] M. Sullivan and R. Chillarege, “Comparison of Software Defects in Database Management Systems and Operating Systems”, Proceedings of the 22nd IEEE Fault Tolerant Computing Symp., FTCS-22, pp. 475-484, July 1992.

[18] I. Lee and R. K. Iyer, “Software Dependability in the Tandem GUARDIAN System”, IEEE Transactions on Software Engineering, Vol. 21, No. 5, pp. 455-467, May 1995.

[19] M. Kalyanakrishnam, Z. Kalbarczyk, R. Iyer, “Failure Data Analysis of a LAN of Windows NT Based Computers”, Symposium on Reliable Distributed Database Systems, SRDS18, October, Switzerland, pp. 178-187, 1999.

[20] Sunbelt Software, “NT Reliability Survey Results”, http://www.sunbelt-software.com/ntrelres3.htm, March 23, 1999.

[21] J. Christmansson and R. Chillarege, “Generation of an Error Set that Emulates Software Faults”, Proceedings of the 26th IEEE Fault Tolerant Computing Symposium, FTCS-26, Sendai, Japan, pp. 304-313, June 1996.

[22] H. Madeira, M. Vieira, and D. Costa, “On the Emulation of Software Faults by Software Fault Injection”, Int. Conf. on Dependable Systems and Networks, New York, USA, June 2000, pp. 417-426.

**Proceedings of the International Conference on Dependable Systems and Networks (DSN’02)**
**0-7695-1597-5/02 $17.00 © 2002 IEEE**
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 19, 2021 at 04:16:58 UTC from IEEE Xplore. Restrictions apply.**