### 5.2.1 Detection Method Performance

**Figure 10: True Positive Test Fraction**

The true positive rate remains consistently high, regardless of the chosen significance level, for moderate to significant proportions of malicious nodes in the population (up to 20% of malicious nodes). However, beyond this point, the proportion of correct positive tests begins to decrease, with the rate of decrease being inversely proportional to the significance level used. This is because a higher significance level results in more positive tests, capturing most malicious embedding steps, but also leading to a higher number of false positives. Therefore, a significance level of 5% offers a good balance.

**Figure 11: False Positive Rate**

**Figure 12: False Negative Rate**

Figures 11 and 12 illustrate the false positive and false negative rates, respectively. As expected, a higher significance level leads to a more aggressive test, incorrectly classifying a larger portion of normal embedding steps as malicious (Figure 11), while a more lenient test (lower significance level) wrongly reports a higher proportion of malicious embedding steps as normal (Figure 12).

Incorrect test results have a negative impact on the embedding system:
- **False Positives:** These reduce the pool of available normal nodes that can be used for normal embedding.
- **False Negatives:** These allow malicious nodes to corrupt and distort the coordinate space, which can propagate through the system, resulting in more normal nodes being incorrectly identified as malicious due to mis-positioning.

This is exemplified in Figure 11, where the false positive rate increases more rapidly as the population of malicious nodes increases, especially for lower values of the significance level. Additionally, despite the negative slopes in the false negative rate curves (Figure 12), these rates decrease much more slowly than the increase in the malicious population. As the number of malicious nodes increases, the number of false negatives also increases, causing more damage to the coordinate space.

Although the accuracy of coordinate systems improves with the number of participating nodes, false negatives can have a greater impact on the system than false positives and should therefore be prioritized. Since the false negative rates for tests with significance levels of 5% and 10% are roughly similar, while the more aggressive test yields a higher false positive rate, a significance level of 5% is a good compromise.

### 5.3 Securing NPS

To evaluate our proposed detection method in the context of the NPS coordinate system, we studied the effects of a colluding isolation attack as described in [11]. Malicious nodes cooperate and behave honestly until a sufficient number of them become reference points at each layer. Once a minimum number of malicious reference points (set to 5 in our experiments) is reached in a layer, these attackers identify a common set of victims (50% of the normal nodes they know from the layer directly below). During the positioning of their victims, the malicious nodes pretend to be clustered in a remote part of the coordinate space, attempting to push the victims into a remote location to isolate them from other nodes. To evade detection, including the basic detection method in NPS, the malicious nodes use the sophisticated anti-detection method proposed in [11].

**5.3.1 Detection Method Performance**

Figures 11 and 12 show the false positive and false negative rates, respectively. A higher significance level results in a more aggressive test, incorrectly classifying a larger portion of normal embedding steps as malicious (Figure 11), while a more lenient test (lower significance level) wrongly reports a higher proportion of malicious embedding steps as normal (Figure 12).

Incorrect test results have a negative impact on the embedding system:
- **False Positives:** These reduce the pool of available normal nodes that can be used for normal embedding.
- **False Negatives:** These allow malicious nodes to corrupt and distort the coordinate space, which can propagate through the system, resulting in more normal nodes being incorrectly identified as malicious due to mis-positioning.

This is exemplified in Figure 11, where the false positive rate increases more rapidly as the population of malicious nodes increases, especially for lower values of the significance level. Additionally, despite the negative slopes in the false negative rate curves (Figure 12), these rates decrease much more slowly than the increase in the malicious population. As the number of malicious nodes increases, the number of false negatives also increases, causing more damage to the coordinate space.

Although the accuracy of coordinate systems improves with the number of participating nodes, false negatives can have a greater impact on the system than false positives and should therefore be prioritized. Since the false negative rates for tests with significance levels of 5% and 10% are roughly similar, while the more aggressive test yields a higher false positive rate, a significance level of 5% is a good compromise.

### 5.2.2 Embedding System Performance

From section 5.2.1, it is clear that a significance level of 5% provides the best overall test performance. We therefore set the significance level to this value and assess the resistance of a Vivaldi system under various attack intensities.

**Figure 13: Distribution of Measured Relative Errors**

The cumulative distribution function of the measured relative errors across all normal nodes after convergence (as defined in [12]) is shown in Figure 13. The detection mechanism renders the system practically immune to attacks when the proportion of malicious nodes is 30% or less of the overall node population. Although the system shows degraded performance for higher intensities of malicious attacks, the steeper slope of the CDF with detection, compared to the corresponding curve without detection (e.g., curves for 50% of malicious nodes), indicates that the detection mechanism is not completely overwhelmed and still offers good protection by significantly reducing the impact of the attack.

**Figure 14: ROC Curves**

Figure 14 shows the ROC curves for the detection test in NPS. These curves exhibit characteristics similar to those observed in the Vivaldi system (see section 5.2.1), albeit slightly better. In particular, these curves show that the detection method withstands heavier attacks better in NPS than in Vivaldi.

There are several reasons for this:
- The basic detection method in NPS works in concert with our own, providing greater opportunities to identify malicious behavior.
- The embedding method in NPS is less prone to mis-positioning error propagation among normal nodes, as nodes in the lower layer do not participate in the embedding of other nodes.
- By design, the attack considered in this section affects fewer victims (50% of normal nodes) compared to the attack studied in section 5.2 (100% in Vivaldi).

The same observation holds for the false positive and false negative rates (not shown), with a significance level of 5% offering the best compromise between catching malicious embedding steps and not being overly cautious about normal variations in network conditions.

The similarities in test performance under NPS and Vivaldi, despite the different nature of the attacks and differences in coordinate structure (two-dimensional with height for Vivaldi versus eight-dimensional for NPS), illustrate the generality of the proposed detection method. This is because our detection test is based on the modeling of a dimensionless quantity (the relative error), which is fundamental to any embedding method.

### 5.3.2 Embedding System Performance

We study the performance of the NPS embedding system under increasing attack intensity, while being protected by our detection scheme. Note that in this section, "detection off" means that our proposed detection mechanism is not used, but the basic NPS detection mechanism is still active.

**Figure 15: Distribution of Measured Relative Errors**

Figure 15 shows the cumulative distribution function of relative errors in the system. We note similarities with the dynamic behavior of similar Vivaldi systems, except that the tail of the CDF for 50% malicious nodes with detection is heavier than the corresponding curve in the Vivaldi case. Given that in NPS not all nodes are victims and not all normal nodes will propagate mis-positioning errors, this indicates that the attack is still quite effective against its victims, albeit dampened by the detection mechanism. This effect is compounded by the fact that, with our simple detection protocol, malicious nodes that have found their way into the layer hierarchy of NPS and act as Reference Points remain in place throughout the experiment, despite numerous detections of their corrupt embedding steps.

Nevertheless, the detection method proposed affords near immunity to the system up to rather severe attack conditions (e.g., about 30% of malicious nodes in the system).

### 6. Discussions and Conclusions

We have presented a method for detecting malicious behavior to secure the embedding phase of Internet coordinate systems. Our method does not rely on the geometric properties of the coordinate space and is therefore unaffected by potential triangular inequality violations, which often occur in the Internet. Instead, our detection test is based on the modeling of dynamic relative errors observed in a clean system. The relative error is a dimensionless quantity fundamental to any embedding method, leading us to believe that our proposed detection test can effectively identify malicious behavior in many embedding protocols and coordinate space structures under a wide range of attacks.

The experiments presented in this paper show that the performance of the detection test is effectively the same in two different scenarios involving different embedding protocols and different attacks. To our knowledge, this is the first such general detection test capable of surviving sophisticated attacks. We consider exclusively attacks aimed at distorting the coordinate space, carried out by nodes inside the embedding system. Our method thus succeeds where more obvious methods based on authentication would fail.

In practice, we introduced the concept of Surveyor nodes, which, by design, are immune to embedding attacks and observe the properties of the coordinate system in clean conditions. The Surveyors form the basis of a "security infrastructure." It is important to note that the deployment of Surveyors does not equate to imposing an embedding infrastructure; peer-to-peer-based embedding systems, like Vivaldi, retain their infrastructure-less embedding characteristics. Apart from a test to accept or filter out embedding steps, our method does not entail any changes to the operations of the embedding protocols. While this paper does not address external attacks on the infrastructure (e.g., denial-of-service attacks, "link clogging," etc.), solutions to such attacks have been proposed elsewhere (e.g., [24]).

The operations of the proposed detection protocol were deliberately kept simple and tested on systems where Surveyors were chosen randomly, although their representativeness increases with closeness to their "clients." Despite the possibly non-optimal Surveyor distribution, the results obtained show the effectiveness of our proposal in securing Internet coordinate systems. Given the enhanced coordinate service afforded by our detection test and simple detection protocol, ISPs may want to deploy Surveyors within their networks to offer enhanced coordinate services to their customers. Such business-driven strategic deployment can improve the representativeness of Surveyors, enhancing the security of large-scale coordinate services with a smaller proportion of Surveyors than the upper bound reported in this paper.

More sophisticated Surveyor selection mechanisms could result in better security through better representativeness in large-scale coordinate systems. We believe that the increased robustness provided by our proposal could catalyze the acceptance and deployment of large-scale coordinate services in the Internet.

With a trusted Surveyor infrastructure in place, it could be argued that using these Surveyors for positioning other nodes would ensure immunity to any insider attacks. For Vivaldi, using the Surveyors for positioning would mean that normal nodes only choose Surveyors as neighbors. The embedding performance of such a Vivaldi scenario is depicted by the "using dedicated Surveyors for embedding" curve in Figure 13, with 1% Surveyors from the simple k-means deployment method. It is clear that such use of the Surveyor infrastructure trades embedding accuracy for increased security. A similar NPS scenario, where only Surveyors are chosen as Landmarks and reference points, unsurprisingly led to embedding performance equivalent to a clean NPS system, as the hierarchical embedding structure in both systems is very similar. An NPS system where only Surveyors are chosen as Landmarks and reference points looks like a hybrid system between GNP [1] and NPS: it is a fixed infrastructure system (like GNP) but with distributed Landmark coordinate computation and a hierarchical structure (like NPS).

In both cases, a clear scalability issue arises as the load on each Surveyor increases as their number decreases. In light of the discussion on strategic Surveyor deployment and the lower bound on the number of required Surveyors, it is not clear that the solution of embedding against Surveyors only is practically viable. Even if it were, a hybrid solution, where Surveyors are used for malicious activity detection under mild to medium attack intensities and exclusively for embedding under more severe conditions, would be more accurate and offer better scalability.

Furthermore, each node using malicious behavior detection does so in isolation, as there is no cooperation between nodes to improve detection and identification of malicious nodes. Instead, any embedding step identified as malicious by a node is simply ignored and discarded locally. One reason the detection protocol was designed this way was to avoid potential denial-of-service attacks that could result from sharing information about malicious activity, with the view of excluding offending nodes. Such an approach could open the door to an attack that consists of trying to get honest nodes excluded from the system through the collusion of wrong malicious reports. Trust propagation could be used to mitigate or remove this threat, allowing detection cooperation among nodes, which could only improve the security of the overall system and reduce the impact of very large-scale attacks on the embedding system.

A property of coordinate systems observed in large-scale deployment is coordinate drift [7]. While the drift rate is low enough that it does not interfere with our detection method, drift and, in general, coordinate variations can be an issue for applications using the coordinate system for distance estimation (the "usage phase" of the coordinate service). Even though the embedding phase of the system may have been secured, this would not prevent a malicious node from lying about its coordinates when a node requests them for simple distance estimation during normal use of the service. This normal use of the service must also be secured, perhaps through the use of validity periods for "certified" coordinates. This is left as future work. However, because lying about its own coordinate during a simple distance estimation only fools a single other node at a time, this type of application-level attack is less dangerous than an attack on the embedding phase, which can distort the coordinate space and bias distance estimates involving unsuspecting honest nodes. This is why we chose to address the problem of securing the embedding phase first.

### Acknowledgments

We would like to thank Dina Papagiannaki, Guy Leduc, and the anonymous reviewers for their useful comments that helped improve the paper.

### 7. References

[1] T. E. Ng, and H. Zhang, Predicting internet network distance with coordinates-based approaches, in Proceedings of the IEEE INFOCOM, New York, June 2002.
[2] M. Pias, J. Crowcroft, S. Wilbur, S. Bhatti, and T. Harris, Lighthouses for Scalable Distributed Location, in Proceedings of International Workshop on Peer-to-Peer Systems (IPTPS03), Berkeley, February 2003.
[3] M. Costa, M. Castro, A. Rowstron, and P. Key, Practical Internet coordinates for distance estimation, in Proceedings of the IEEE International Conference on Distributed Computing Systems (ICDCS), Tokyo, March 2004.
[4] T. E. Ng and H. Zhang, A Network Positioning System for the Internet, in Proceedings of the USENIX annual technical conference, Boston, June 2004.
[5] F. Dabek, R. Cox, F. Kaashoek, and R. Morris, Vivaldi: A decentralized network coordinate system, in Proceedings of the ACM SIGCOMM, Portland, Oregon, August 2004.
[6] Y. Shavitt and T. Tankel, Big-Bang Simulation for embedding network distances in Euclidean Space, in Proceedings of the IEEE INFOCOM, New York, June 2002.
[7] J. Ledlie, P. Gardner, and M. Seltzer, Network Coordinates in the Wild, in Proceedings of NSDI, Cambridge, MA, April 2007.
[8] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan, Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications, in Proceedings of SIGCOMM, San Diego, CA, August 2001.
[9] Azureus BitTorrent Client. http://azureus.sourceforce.net
[10] www.skype.com
[11] M. A. Kaafar, L. Mathy, T. Turletti, and W. Dabbous, Virtual Networks under Attack: Disrupting Internet Coordinate Systems, in Proceedings of CoNext 2006, Lisboa, December 2006.
[12] M. A. Kaafar, L. Mathy, T. Turletti, and W. Dabbous, Real attacks on virtual networks: Vivaldi out of tune, in Proceedings of the SIGCOMM workshop on Large Scale Attack Defense (LSAD), Pisa, September 2006.
[13] R.E. Kalman, A New Approach to Linear Filtering and Prediction Problems, in Transactions of the ASME - Journal of Basic Engineering Vol. 82: pp. 35-45, 1960.
[14] R.E. Kalman, and R.S. Bucy, New Results in Linear Filtering and Prediction Theory, in Transactions of the ASME - Journal of Basic Engineering Vol. 83: pp. 95-107, 1961.
[15] Y. Zhang, N. Duffield, V. Paxson, and S. Shenker, On the Constancy of Internet Path Properties, in Proceedings of ACM SIGCOMM Internet Measurement Workshop, San Francisco, CA, November 2001.
[16] Z. Ghahramani, G. Hinton, Parameter Estimation for Linear Dynamical Systems, University of Toronto, Technical Report CRG-TR-96-2.
[17] M. A. Kaafar, L. Mathy, C. Barakat, K. Salamatian, T. Turletti, and W. Dabbous, Securing Internet Coordinate System: Embedding Phase, Technical Report INRIA inria-00151257.
[18] K. P. Gummadi, S. Saroiu, and S. D. Gribble, King: Estimating Latency between Arbitrary Internet End Hosts, in Proceedings of SIGCOMM Internet Mesurement Workshop (IMW), Pittsburgh, PA, November 2002.
[19] H. Lilliefors, On the Kolmogorov-Smirnov test for normality with mean and variance unknown, Journal of the American Statistical Association, Vol. 62. pp. 399-402, June 1967.
[20] A. Soule, K. Salamatian, and N. Taft, Combining Filtering and Statistical Methods for Anomaly Detection, in Proceedings of Internet Measurement Conference (IMC), Berkeley, October 2005.
[21] E. K. Lua, T. Griffin, M. Pias, H. Zheng, and J. Crowcroft, On the accuracy of Embeddings for Internet Coordinate Systems, in Proceedings of Internet Measurement Conference (IMC), Berkeley, October 2005.
[22] H. Zheng, E. K. Lua, M. Pias, and T. Griffin, Internet Routing Policies and Round-Trip Times, in Proceedings of the Passive Active Measurement (PAM), Boston, March 2005.
[23] J. Bilmes, A gentle tutorial on the EM algorithm including Gaussian mixtures and Baum-Welch, Technical Report TR-97-021, International Computer Science Institute, Berkeley, CA, 1997.
[24] A. Keromytis, V. Misra, and D. Rubenstein, SOS: Secure Overlay Services, in Proceedings of ACM SIGCOMM, Pittsburgh, PA, August 2002.