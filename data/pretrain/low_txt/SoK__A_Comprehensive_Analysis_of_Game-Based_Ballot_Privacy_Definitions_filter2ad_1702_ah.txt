### Funding and Support

This research has been supported by the following grants:
- ERC Grant Agreement No. 258865 (ProSecure)
- Grant Agreement No. 609611 (PRACTICE)
- Walloon Region Greentic–Truedev Project No. 1317971
- ERC Advanced Grant ERC-2010-AdG-267188-CRIPTO

### References

1. B. Adida, "Helios: Web-based Open-Audit Voting," in *17th USENIX Security Symposium*, 2008, pp. 335–348. [Helios website](http://heliosvoting.org).

2. B. Adida, O. de Marneffe, O. Pereira, and J.-J. Quisquater, "Electing a University President Using Open-Audit Voting: Analysis of Real-World Use of Helios," in *Electronic Voting Technology Workshop/Workshop on Trustworthy Elections*. Usenix, Aug. 2009.

3. M. R. Clarkson, S. Chong, and A. C. Myers, "Civitas: Toward a Secure Voting System," in *29th Security and Privacy Symposium (S&P’08)*. IEEE, 2008.

4. R. L. Rivest and W. D. Smith, "Three Voting Protocols: ThreeBallot, VAV, and Twin," in *Electronic Voting Technology Workshop (EVT 2007)*, 2007.

5. P. Ryan, D. Bismark, J. Heather, S. Schneider, and Z. Xia, "The Prêt à Voter Verifiable Election System," *IEEE Transactions on Information Forensics and Security*, vol. 4, pp. 662–673, 2009.

6. D. Chaum, A. Essex, R. Carback, J. Clark, S. Popoveniuc, A. Sherman, and P. Vora, "Scantegrity: End-to-End Voter-Verifiable Optical-Scan Voting," *IEEE Security and Privacy*, vol. 6, no. 3, pp. 40–46, 2008.

7. J. Cohen (Benaloh) and M. Fischer, "A Robust and Verifiable Cryptographically Secure Election Scheme," in *26th Symposium on Foundations of Computer Science*. Portland, OR: IEEE, 1985, pp. 372–382.

8. J. Benaloh, "Verifiable Secret-Ballot Elections," Yale University Department of Computer Science, Tech. Rep. 561, September 1987.

9. S. Delaune, S. Kremer, and M. D. Ryan, "Verifying Privacy-Type Properties of Electronic Voting Protocols," *Journal of Computer Security*, vol. 17, no. 4, pp. 435–487, 2009.

10. R. Kusters, T. Truderung, and A. Vogt, "A Game-Based Definition of Coercion-Resistance and its Applications," in *23rd IEEE Computer Security Foundations Symposium (CSF’10)*. IEEE, 2010, pp. 122–136.

11. R. Kusters, T. Truderung, and A. Vogt, "Verifiability, Privacy, and Coercion-Resistance: New Insights from a Case Study," in *IEEE Symposium on Security and Privacy (S&P 2011)*. IEEE Computer Society, 2011, pp. 538–553.

12. D. Bernhard, V. Cortier, O. Pereira, B. Smyth, and B. Warinschi, "Adapting Helios for Provable Ballot Secrecy," in *16th European Symposium on Research in Computer Security (ESORICS’11)*, ser. LNCS, Springer, Ed., vol. 6879, 2011.

13. J. Groth, "Evaluating Security of Voting Schemes in the Universal Composability Framework," in *ACNS*, ser. Lecture Notes in Computer Science, M. Jakobsson, M. Yung, and J. Zhou, Eds., vol. 3089. Springer, 2004, pp. 46–60.

14. O. de Marneffe, O. Pereira, and J.-J. Quisquater, "Simulation-Based Analysis of E2E Voting Systems," in *Proceedings of the First Conference on E-Voting and Identity (VOTE-ID 2007)*, ser. LNCS, A. Alkasar and M. Volkamer, Eds., no. 4896. Springer, Oct. 2007, pp. 137–149.

15. T. Moran and M. Naor, "Split-Ballot Voting: Everlasting Privacy with Distributed Trust," in *Proceedings of the 2007 ACM Conference on Computer and Communications Security (CCS 2007)*, Alexandria, Virginia, USA, 2007, pp. 246–255.

16. L. Coney, J. L. Hall, P. L. Vora, and D. Wagner, "Towards a Privacy Measurement Criterion for Voting Systems," in *In National Conference on Digital Government Research*, 2005.

17. D. Bernhard, V. Cortier, O. Pereira, and B. Warinschi, "Measuring Vote Privacy, Revisited," in *19th ACM Conference on Computer and Communications Security (CCS’12)*. Raleigh, USA: ACM, October 2012.

18. D. Bernhard, O. Pereira, and B. Warinschi, "On Necessary and Sufficient Conditions for Private Ballot Submission," *Cryptology ePrint Archive*, Report 2012/236, 2012. [Link](http://eprint.iacr.org/).

19. D. Bernhard, O. Pereira, and B. Warinschi, "How Not to Prove Yourself: Pitfalls of the Fiat-Shamir Heuristic and Applications to Helios," in *ASIACRYPT*, ser. Lecture Notes in Computer Science, X. Wang and K. Sako, Eds., vol. 7658. Springer, 2012, pp. 626–643.

20. V. Cortier, D. Galindo, S. Glondu, and M. Izabachène, "Distributed ElGamal à la Pedersen: Application to Helios," in *WPES*, A.-R. Sadeghi and S. Foresti, Eds. ACM, 2013, pp. 131–142.

21. M. Chase, M. Kohlweiss, A. Lysyanskaya, and S. Meiklejohn, "Verifiable Elections that Scale for Free," in *Public Key Cryptography*, ser. Lecture Notes in Computer Science, K. Kurosawa and G. Hanaoka, Eds., vol. 7778. Springer, 2013, pp. 479–496.

22. D. Bernhard and B. Smyth, "Ballot Privacy and Ballot Independence Coincide," in *Proceedings of the 18th European Symposium on Research in Computer Security (ESORICS’13)*, ser. Lecture Notes in Computer Science, Springer, Ed., 2013.

23. J. C. Benaloh and M. Yung, "Distributing the Power of a Government to Enhance the Privacy of Voters (Extended Abstract)," in *PODC*, J. Y. Halpern, Ed. ACM, 1986, pp. 52–62.

24. J. Benaloh, "Verifiable Secret-Ballot Elections," PhD thesis, Yale University, 1987.

25. J. C. Benaloh and D. Tuinstra, "Receipt-Free Secret-Ballot Elections (Extended Abstract)," in *STOC*, F. T. Leighton and M. T. Goodrich, Eds. ACM, 1994, pp. 544–553.

26. E. Cuvelier, O. Pereira, and T. Peters, "Election Verifiability or Ballot Privacy: Do We Need to Choose?" in *Proceedings of the 18th European Symposium on Research in Computer Security (ESORICS’13)*, ser. Lecture Notes in Computer Science, Springer, Ed., 2013.

27. V. Cortier and B. Smyth, "Attacking and Fixing Helios: An Analysis of Ballot Secrecy," in *24th IEEE Computer Security Foundations Symposium (CSF’11)*. IEEE, 2011, pp. 297–311.

28. V. Cortier and B. Smyth, "Attacking and Fixing Helios: An Analysis of Ballot Secrecy," *Journal of Computer Security*, vol. 21, no. 1, pp. 89–148, 2013.

29. J. Benaloh, "Ballot Casting Assurance via Voter-Initiated Poll Station Auditing," in *Proceedings of the Second Usenix/ACCURATE Electronic Voting Technology Workshop*, 2007.

30. M. R. Clarkson, S. Chong, and A. C. Myers, "Civitas: Toward a Secure Voting System," in *Proc. IEEE Symposium on Security and Privacy*, 2008, pp. 354–368.

31. S. Delaune, S. Kremer, and M. Ryan, "Verifying Privacy-Type Properties of Electronic Voting Protocols," *Journal of Computer Security*, vol. 17, no. 4, pp. 435–487, 2009.

32. A. Juels, D. Catalano, and M. Jakobsson, "Coercion-Resistant Electronic Elections," in *4th Workshop on Privacy in the Electronic Society (WPES 2005)*. ACM, 2005, pp. 61–70.

33. J. Dreier, P. Lafourcade, and Y. Lakhnech, "Defining Privacy for Weighted Votes, Single and Multi-Voter Coercion," in *ESORICS*, ser. Lecture Notes in Computer Science, S. Foresti, M. Yung, and F. Martinelli, Eds., vol. 7459. Springer, 2012, pp. 451–468.

34. "Ballot Paper for European Parliament Election in Luxembourg, 2014." [Link](http://upload.wikimedia.org/wikipedia/commons/b/bf/Ballot_paper_European_Parliament_elections_2014_in_Luxembourg.JPG).

35. D. Bernhard, V. Cortier, D. Galindo, O. Pereira, and B. Warinschi, "A Comprehensive Analysis of Game-Based Ballot Privacy Definitions," *Cryptology ePrint Archive*, Report 2015/255, 2015. [Link](http://eprint.iacr.org/).

36. D. Wikström, "Simplified Submission of Inputs to Protocols," in *Security and Cryptography for Networks, 6th International Conference, SCN 2008*, ser. Lecture Notes in Computer Science, R. Ostrovsky, R. D. Prisco, and I. Visconti, Eds., vol. 5229. Springer, 2008, pp. 293–308.

37. B. Adida, O. de Marneffe, O. Pereira, and J.-J. Quisquater, "Electing a University President Using Open-Audit Voting: Analysis of Real-World Use of Helios," in *Proceedings of the 2009 Conference on Electronic Voting Technology/Workshop on Trustworthy Elections*, 2009.

38. R. Cramer, R. Gennaro, and B. Schoenmakers, "A Secure and Optimally Efficient Multi-Authority Election Scheme," in *Advances in Cryptology (EUROCRYPT’97)*, 1997, p. 103118.

39. International Association for Cryptologic Research. Elections page at [IACR Elections](http://www.iacr.org/elections/).

40. T. E. Gamal, "A Public Key Cryptosystem and a Signature Scheme Based on Discrete Logarithms," *IEEE Transactions on Information Theory*, vol. 31, no. 4, pp. 469–472, 1985.

41. D. Chaum and T. P. Pedersen, "Wallet Databases with Observers," in *CRYPTO*, ser. Lecture Notes in Computer Science, E. F. Brickell, Ed., vol. 740. Springer, 1992, pp. 89–105.

42. R. Cramer, I. Damgård, and B. Schoenmakers, "Proofs of Partial Knowledge and Simplified Design of Witness Hiding Protocols," in *CRYPTO*, ser. Lecture Notes in Computer Science, Y. Desmedt, Ed., vol. 839. Springer, 1994, pp. 174–187.

43. V. Cortier, D. Galindo, S. Glondu, and M. Izabachène, "Election Verifiability for Helios Under Weaker Trust Assumptions," in *Computer Security - ESORICS 2014 Proceedings, Part II*, ser. Lecture Notes in Computer Science, M. Kutylowski and J. Vaidya, Eds., vol. 8713. Springer, 2014, pp. 327–344.

### Appendix

#### VIII. Test Cases for BPRIV Definitions

During our work on this paper, we listed some insecure variations on voting protocols. Future designers of ballot privacy-related notions can use these as "safety checks": if any of these schemes is not insecure under some notion of privacy, then the notion may be too weak. We argue that none of these insecure schemes can satisfy BPRIV.

##### A. Helios v3 — Replay Attacks

Any voting scheme in which an adversary can read an honest voter's ballot from the ballot box and resubmit a ballot for the same vote as her own fails to ensure vote privacy, as argued in Section III-F and illustrated on Helios (version 3) [28]. More precisely, consider an adversary who, for any two distinct honest votes \( v_0 \) and \( v_1 \), can perform the following sequence of queries:

```plaintext
start-voting();
vote(v0, v1);
vote(v1, v0);
bb ← board();
b ← first(bb);
ballot(b);
(r, a) ← tally()
```

Here, `first` returns the first ballot of `bb`. We may also imagine more sophisticated attacks where the adversary has to change, for example, identifying information on the ballot. We deliberately choose two vote queries that would produce the same "left" and "right" tallies if \( b \) was independent of the honest ballots. In the BPRIV game, if the ballot \( b \) is not rejected (by Publish) then the tally for \( \beta = 0 \) is \( \rho(v_0, v_1, v_0) \) and for \( \beta = 1 \) it is \( \rho(v_1, v_0, v_1) \). If these are not the same value, which happens, for example, if \( \rho \) counts the number of \( v_0 \) and \( v_1 \) votes submitted, then our adversary can win the BPRIV game (with probability 1), hence the broken scheme is not BPRIV secure.

##### B. Leaky Auxiliary Data

Consider any voting scheme where the result function \( \rho \) is supposed to output how many times each choice was voted for, i.e., one could write \( \rho(v_0, v_1, v_0, v_0) = \{(v_0, 3), (v_1, 1)\} \). Imagine that, unfortunately, a scheme’s tally also contains all votes in clear, in the order that they were cast. This is clearly not desirable. Intuitively, there are two distinct ways of discarding such a scheme. Either the (leaky) output of the tally is classified as being the result itself. Then the scheme does not implement the desired functionality, and this is captured with our "strong consistency" notion. Or this leaky output is contained in the auxiliary data. In that case, we can construct a BPRIV adversary against such a scheme:

```plaintext
start-voting();
vote(v0, v1);
vote(v1, v0);
(r, a) ← tally()
```

To show that this adversary can win, we recall that the output of `tally` is split into a result \( r \) and auxiliary data \( \Pi \) in such a way that \( r \) is guaranteed not to leak any information. In other words, \( r \) is the correct/intended result, so the list of all votes must be part of \( \Pi \). In the case \( \beta = 0 \), the adversary sees auxiliary data that reveals all the votes on \( BB_0 \), i.e., the sequence \( (v_0, v_1) \). In contrast, if \( \beta = 1 \) then \( \Pi \) is computed as a (probabilistic) function of \( BB_1 \) and \( r \), neither of which can contain any information about the order of the votes in \( BB_0 \). So the probability of \( \Pi \) containing the list \( (v_0, v_1) \) is at most the probability of guessing the adversary’s "left" votes without access to any ballots. Therefore, the adversary can distinguish \( \beta = 0 \) from \( \beta = 1 \) with high probability.

#### IX. BPRIV2 Does Not Guarantee Ballot Privacy

Let us prove formally that \( V \) defined in Section III-D is BPRIV2 secure, while it should intuitively not be declared private.

**SimProof(BB0, BB1, pk, info)** := \( \Pi \)

\[
\begin{aligned}
&\text{where } BB_\gamma := BB_\gamma \setminus (BB_0 \cap BB_1), \\
&v_b := \text{Extract}(sk, b) \text{ and } \Pi := \text{SimProof}^\dagger(BB_0, BB_1, pk, \text{info}).
\end{aligned}
\]

Intuitively, **SimProof** decrypts correctly the adversarial ballots but mimics the case if \( \beta = 0 \) for all honest ballots. Then, let us write \( BB_\beta = H_\beta \cup C \), where \( H_\beta \) is the sublist of honest ballots output by the **OvoteLR** oracle for \( \beta = 0, 1 \), and \( C := BB_\beta \setminus H_\beta \). By construction, \( C \subseteq BB_0 \cap BB_1 \). We want to see that for every BPRIV2 adversary \( B \) against \( V \), there exists a BPRIV2 adversary \( B^\dagger \) against scheme \( V^\dagger \) such that:

\[
\text{Succ}_{\text{bpriv2}}(B) \approx_{\text{negl}} \text{Succ}_{\text{bpriv2}}(B^\dagger),
\]

their advantages only differ in a negligible quantity. We compare the data seen by BPRIV2 adversaries \( B \) against scheme \( V \) and adversaries \( B^\dagger \) against scheme \( V^\dagger \) in Figure 3, wherein \( b_0 \in H_0 \), \( b_1 \in H_1 \), \( b_c \in C \).

We observe that the only extra information that adversary \( B \) against \( V \) sees compared to adversary \( B^\dagger \) against \( V^\dagger \) are the relations \( \{(b_0, v_{b_0})\} \) and \( \{(b_c, v_{b_c})\} \) when \( \beta = 0 \), and the relations \( \{(b_1, v_{b_0})\} \) and \( \{(b_c, v_{b_c})\} \) when \( \beta = 1 \). However, this does not allow \( B \) to have a greater distinguishing advantage than \( B^\dagger \). Indeed, since the new matching between ballots and votes is not verifiable (the original tallying proofs \( \Pi^\dagger \) did not change and \( V^\dagger \) is BPRIV2 private), adversary \( B^\dagger \) can simulate \( B \)'s view using its own view. It suffices for \( B^\dagger \) to tell apart the multisets of votes \( V_0 \) and \( V_C \) (this can be done easily, since \( V_0 \) are the left vote queries of \( B \) and \( V_C := r \setminus V_0 \)), and later link \( H_0 \) or \( H_1 \) to \( V_0 \) at its liking. Finally, \( \text{Succ}_{\text{bpriv2}}(B) \approx_{\text{negl}} \text{Succ}_{\text{bpriv2}}(B^\dagger, \Pi) \).