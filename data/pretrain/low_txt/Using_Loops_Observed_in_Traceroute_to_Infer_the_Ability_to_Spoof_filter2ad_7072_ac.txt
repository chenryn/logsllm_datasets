### Understanding the Impact of Random Address Selection and Loop Persistence

Traceroute data alone does not provide sufficient information about the persistence of loops. To gain a deeper understanding, we collected traceroutes to the same IP addresses that initially revealed these loops. We applied the algorithm detailed in Section 5.3 to the traceroute data from August 2016, identifying 2,500 unique loops between 703 provider and 1,780 customer Autonomous Systems (ASes). In October 2016, we repeated this process using two different vantage points and were able to reproduce 1,240 loops involving 461 provider and 1,026 customer ASes.

We extended this procedure to a year's worth of traceroute data, from August 2015 to August 2016, finding 7,784 unique loops between 1,286 provider and 3,993 customer ASes. In October 2016, we reproduced 1,542 unique loops between 505 provider and 1,176 customer ASes. This additional data identified 342 loops that persisted over time.

### Factors Affecting Loop Reproduction

A significant number of loops could not be reproduced, and the likelihood of failure increased with the time lag. There are four primary reasons for this:

1. **Transient Loops**: The loop may have been temporary, occurring during routing protocol convergence or due to a temporary misconfiguration.
2. **Vantage Point Dependence**: The loop's detection might depend on the probe's vantage point, such as in the case of multi-homed routers.
3. **Routing Issue Resolution**: The provider may have fixed the routing issue causing the loop.
4. **Ingress Filtering Implementation**: The provider may have implemented ingress filtering, which prevents the loop from reoccurring.

Future work is needed to disentangle these causes. Our validation efforts (Section 6) show that even loops that appeared only once can correctly signal the absence of ingress filtering. Some of the loops we could not reproduce had already been validated by providers as true positives. For the remainder of the paper, we will use the full set of loops identified by our algorithm.

### Validation by Network Providers

To validate our results and obtain ground truth, we contacted network providers in two rounds: September 2015 and September 2016. We received feedback from one hosting provider, one data center provider, one Internet Service Provider (ISP), two national research and education networks, and two Tier 1 networks. The providers' participation varied based on whether we inferred the absence of ingress filtering for their links and our ability to reach the right specialist.

Feedback from the first round led to improvements in our methodology. We applied the final methodology to both the August 2015 and August 2016 data and compared the results with the feedback from the providers. We talked to six providers in the first round and four in the second round, with three providers participating in both rounds.

We defined a result as a true positive if we identified a provider-to-customer link where the provider does not perform ingress filtering, and an operator at the provider confirmed this. A false positive occurred when we incorrectly detected the boundary or the provider was actually performing Source Address Validation (SAV) at the boundary. Our methodology correctly identified the absence of ingress filtering on the provider boundary in 94 out of 98 IP links between provider and customer ASes (45 of 49 links in the first round and 49 of 49 links in the second round).

The four false positives had different causes. Three occurred due to route aggregation, where providers consolidate multiple routes into a single, more general route. This practice can lead to issues with our border router detection. For example, if a provider aggregates a /24 subnet Y into a /16 advertisement for X, we might infer that customer routers with addresses in Y belong to the provider AS. This would categorize a loop between provider prefix X and customer prefix Z as signaling the absence of SAV, even though the loop was within the customer network.

For the fourth false positive, the provider informed us that the traceroute data suggested the loop occurred inside their network rather than at the boundary. However, they could no longer reproduce it and attributed it to a transient event. In the second round, we found three loops for the same provider, all of which were true positives.

Some providers, while confirming the validity of our inference that they were not doing ingress filtering on their boundary, objected to the implication that they should be filtering. They saw their services as offering transit and contracted them as such, meaning no filtering on the provider’s side. In their view, the downstream customer AS should perform SAV at their border router. Evaluating this interpretation of BCP 38 falls outside the scope of this paper and is for the community to address. The key point is that our proposed method performed accurately.

### Results

Using one month of CAIDA’s traceroute data from August 2016, our approach identified 2,500 unique loops involving 703 provider ASes lacking SAV on one or more of their customer-facing links and 1,780 customer ASes. These represent approximately 1.3% and 3.2% of all advertised ASes, respectively. When compared to all advertised stub ASes and their providers, we found 9.0% of provider ASes without ingress filtering involving 3.8% of all stub ASes.

Some providers argued that customer ASes should be responsible for SAV within their networks or at their borders. However, we found that about 63% of the involved customer ASes advertise /20 or smaller prefix lengths, making it unlikely that such small entities have the resources and incentives to implement SAV. On the other hand, such small prefixes should allow providers to implement static Access Control Lists (ACLs).

We compared our results to the Spoofer and Open Resolver projects. Our method only detects the lack of ingress filtering for provider networks, meaning their customer ASes might be able to spoof. We compared those customer ASes with the Spoofer data from February to August 2016. Of 54 overlapping ASes, 38 Spoofer tests were conducted behind a Network Address Translation (NAT) device, likely preventing spoofing. Of the systems not behind a NAT, 10 of the 16 stub ASes allowed spoofing, suggesting that more than half of these ASes had not deployed SAV. This supports the case for transit providers to filter their customers. Packets with spoofed source addresses from Spoofer tests in the remaining six customer ASes were not received, indicating filtering took place in the customer AS.

Kührer et al. used the Open Resolver data in 2014 to identify 2,692 unique ASes from which spoofing was possible. We analyzed the August 2016 data from the Open Resolver project, provided by Jared Mauch, and found 3,015 unique ASes that were able to spoof. We found only a modest overlap of 244 ASes with the customer ASes identified by our method.

These findings show that our method can add unique data points to existing methods, improving visibility of networks lacking SAV. In terms of observation volume, our method resides between the Spoofer and Open Resolver projects. The three methods are complementary and provide a comprehensive view of SAV adoption.

### Conclusion

In this paper, we implemented and validated an algorithm that uses traceroute data to infer the lack of SAV between a stub and provider network. We identified 703 providers that do not implement ingress filtering on at least one of their links facing 1,780 customer ASes. We also built a public website showing the provider-customer edges that we inferred as lacking ingress filtering: https://spoofer.caida.org/. Providers can use this data to deploy filtering, which would stop attackers from sending packets with spoofed addresses from the customer’s network and block attempts to attack the provider-customer link by sending packets to addresses that enter the forwarding loop.

Future work is needed to improve the reliability of the method, particularly in border detection and untangling the factors that prevent loops from being reproduced. Another direction for future work is to experimentally test the strength of reputation effects among providers and network operators. Public visibility of spoofing-enabled networks is a critical step in incentivizing providers to deploy ingress filtering in their networks. The dataset is also useful for national Computer Emergency Response Teams (CERTs) who want to push BCP 38 compliance in their countries. The problems caused by IP spoofing have been recognized for years, and the task to reduce its role in attacks is becoming increasingly urgent.

### Acknowledgments

This technique is based on an idea from Jared Mauch. Christian Keil (DFN-CERT) provided informative feedback. This work was partly funded by the EU Advanced Cyber Defence Centre (ACDC) project CIP-ICT-PSP.2012.5.1 #325188. This material is based on research sponsored by the Department of Homeland Security (DHS) Science and Technology Directorate, Homeland Security Advanced Research Projects Agency, Cyber Security Division BAA HSHQDC-14-R-B0005, and the Government of the United Kingdom of Great Britain and Northern Ireland via contract number D15PC00188.

### References

1. CAIDA spoofer project. https://spoofer.caida.org/
2. Mutually Agreed Norms for Routing Security (MANRS). https://www.routingmanifesto.org/manrs/
3. Open Resolver Project. http://openresolverproject.org/
4. Augustin, B., Cuvellier, X., Orgogozo, B., Viger, F., Friedman, T., Latapy, M., Magnien, C., Teixeira, R.: Avoiding traceroute anomalies with Paris traceroute. In: IMC, pp. 153–158, October 2006
5. Baker, F., Savola, P.: Ingress filtering for multihomed networks. RFC 3704, IETF BCP84, March 2004
6. Bellovin, S.: Security problems in the TCP/IP protocol suite. CCR 19(2), 32–48 (1989)
7. Beverly, R., Bauer, S.: The spoofer project: inferring the extent of source address filtering on the Internet. In: Proceedings of USENIX SRUTI, July 2005
8. Beverly, R., Berger, A., Hyun, Y., claﬀy, k.: Understanding the efficacy of deployed Internet source address validation. In: IMC, pp. 356–369, November 2009
9. Beverly, R., Koga, R., claﬀy, kc.: Initial longitudinal analysis of IP source spoofing capability on the Internet, July 2013. http://www.internetsociety.org/
10. Bright, P.: Spamhaus DDoS grows to Internet-threatening size, March 2013
11. Ferguson, P., Senie, D.: Network ingress filtering: defeating denial of service attacks which employ IP source address spoofing. RFC 2827, IETF BCP38, May 2000
12. Francois, P., Bonaventure, O.: Avoiding transient loops during IGP convergence in IP networks. In: INFOCOM, pp. 237–247, March 2005
13. Huﬀaker, B., Keys, K., Koga, R., claﬀy, kc.: CAIDA inferred AS to organization mapping dataset. https://www.caida.org/data/as-organizations/
14. Kührer, M., Hupperich, T., Rossow, C., Holz, T.: Exit from hell? Reducing the impact of amplification DDoS attacks. In: USENIX Security, August 2014
15. Luckie, M.: Scamper: a scalable and extensible packet prober for active measurement of the Internet. In: IMC, pp. 239–245, November 2010
16. Luckie, M., Dhamdhere, A., Huﬀaker, B., Clark, D., claﬀy, k.: bdrmap: inference of borders between IP networks. In: IMC, pp. 381–396, November 2016
17. Luckie, M., Huﬀaker, B., Dhamdhere, A., Giotsas, V., claﬀy, k.: AS relationships, customer cones, and validation. In: IMC, pp. 243–256, October 2013
18. Marder, A., Smith, J.M.: MAP-IT: multipass accurate passive inferences from traceroute. In: IMC, November 2016
19. Prince, M.: Technical details behind a 400 Gbps NTP amplification DDoS attack. http://blog.cloudflare.com/
20. Vixie, P.: Rate-limiting state: the edge of the Internet is an unruly place. ACM Queue 12(2), 1–5 (2014)
21. Xia, J., Gao, L., Fei, T.: A measurement study of persistent forwarding loops on the Internet. Comput. Netw. 51(17), 4780–4796 (2007)