### Figure 13: Execution Overhead of Replacing Return with Pop and Jmp Sequence
Figure 13 illustrates the execution overhead incurred when replacing return instructions with a pop and jmp sequence in programs from the LLVM Shootout suite. Each box in the figure represents eight executions. The higher the average, the greater the overhead.

### Hardware Overhead Estimation
Estimating the hardware-level overhead for false positive detection, when used in conjunction with our system, is not straightforward. Based on the filtering statistics from Layers 1 and 2 (Section IV-B), we expect that Layer 3 will be activated for less than 0.03% of indirect branches in a program. Consequently, verification similar to CFIMon does not introduce a measurable cost. 

Previous work can help us set an upper bound on the expected overhead for a hardware implementation of Layer 3. The authors of CFIMon report an overall overhead of about 6.1%, with 86% of this cost attributed to the code for recording executed branches, implemented through their "pure BTS" approach. Therefore, the remaining components of CFIMon, including tracking and handling false positives, account for no more than 0.9% overhead. In our case, this overhead is applied to a negligible number of indirect branches, as discussed in Section IV-B. We thus anticipate a much lower cost. Importantly, this verification does not impose any overhead on branches that do not reach Layer 3.

### Related Work
#### Techniques Reused in Our Multi-Layer System
The concept of combining different defense mechanisms in layers, where low-overhead protections are used to gradually filter safe control flows, is a novel contribution of this paper. However, except for the verification of executable targets (discussed in Section III-B), our defense layers reuse techniques from previous work. Our selection criteria for each layer were based on two principles: (i) upper layers, which are applied first, should have lower computational overhead; and (ii) work done in upper layers should not be repeated in lower layers.

Our topmost layer, which certifies targets of indirect branches using the branch predictor, was first described by Shi and Lee [57] in 2007, shortly after Hovav Shacham [1] introduced Return-Oriented Programming (ROP). More recent works have revisited this concept to block ROP attacks [64]–[66]. Other proposals use the number of mispredictions of indirect branches as an attack indicator [67], [68]. We take the inverse perspective: correct predictions of indirect branches indicate authentic executions. Flows that cannot be validated by branch prediction are passed to lower layers. This multi-layer approach is not covered in previous literature.

The idea of checking if the address before the target of a return is a call instruction has been independently described in previous works. Carlini et al. [23] provide a comprehensive overview of the related literature. Their ability to circumvent this type of defense led us to develop the Executable Target Constraint, as detailed in Section III-B. This test is designed to be easily implemented once the call-validation mechanism is in place.

The technique we use to filter out false positives, discussed in Section III-C, was first suggested by Zhang and Sekar [43]. We adopted the same strategy because it is simple and computationally inexpensive. However, without our upper layers, it would be too costly to be practical. Finally, sandboxing, one of the alternatives described in Section III-D for protecting an application when all upper layers fail, is well-known in the systems community.

#### Comparison of Overhead with Previous Works
The primary goal of this paper is to provide protection against ROP attacks with minimal computational cost. We compare our overhead with eight recent systems [9], [19], [21], [69]–[73] that enforce some form of Control Flow Integrity (CFI) policy. We report these overheads rather than reproducing them, as these tools exist primarily as research artifacts and are not readily available today. Some of these systems were tested via software-based prototypes, although they are intended for hardware implementation; hence, some numbers are estimates from the authors.

SCRAP's authors report the lowest overhead [71], between 1% and 2%. However, their strategy, based on controlling the frequency of small gadgets, has been overcome in subsequent work [74]–[76]. Kayaalp et al. report a 2% overhead for BR [70], the same value reported by Lucas et al. for HAFIX [69] and Zipper Stack [72]. The same group had previously proposed MoCFI with a 7% overhead [19]. Veen et al. report an 8.4% overhead for PathArmor [9]. PittyPat’s original presentation reports a 12.73% overhead [21]. Finally, Lockdown’s authors measured a 19% runtime slowdown [73]. Most of these techniques require some hardware support. For example, HAFIX requires changes to the target architecture’s instruction set. Software-only approaches, such as PittyPat, tend to have higher overhead and require recompilation of the protected code.

### Conclusion
This paper presents a multilayer approach to mitigate Return-Oriented Programming (ROP) attacks. Each layer of the proposed system validates targets of indirect branches, ensuring they belong to legitimate program flows. Our key insight is to combine layers such that layer \( L_i \) runs at a lower computational cost than \( L_{i+1} \). A branch certified at \( L_i \) does not need to be checked at \( L_{i+1} \). We apply stronger enforcement guarantees only to cases that are difficult to verify, as \( L_i \) receives more branches than \( L_{i+1} \).

Recent developments show that no system can stop all ROP attacks [23]. Our system is no exception, as it still faces false positives and false negatives. False positives occur if we flag a legitimate branch target as unsafe. The way the operating system handles such exceptions, whether through preemptive termination or sandboxing, impacts user experience. The experiments in Section IV-B indicate that exceptions raised by authentic program flows are rare, as our system includes a layer specifically designed to prevent such occurrences.

False negatives occur if an attacker can manipulate the control flow of the protected application. Through a statistical argument, we have shown in Section IV-A that our call-validation constraint leaves very few gadgets available for constructing an attack. Consequently, state-of-the-art exploits, such as those by Carlini et al. [23], are not possible. Constructing attacks that bypass our protection remains an open problem.

### Acknowledgements
We thank the anonymous reviewers and Marcus Botacin for their valuable suggestions, which greatly improved this paper. This work was made possible by the financial support of CNPq, CAPES, FAPEMIG, Intel, and CEFET-MG, which granted Mateus Tymburibá his sabbatical.

### References
[References remain unchanged]

---

This version of the text is more structured, clear, and professional. It maintains the technical details while improving readability and coherence.