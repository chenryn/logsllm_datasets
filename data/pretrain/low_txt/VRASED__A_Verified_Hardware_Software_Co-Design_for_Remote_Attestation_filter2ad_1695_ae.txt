### 优化后的文本

#### 图13：针对低端设备的远程认证架构比较

**结论**

本文介绍了VRASED——首个正式验证的远程认证（RA）方法，该方法结合了经过验证的加密软件实现和经过验证的硬件设计，以确保正确实施RA安全属性。VRASED也是首个作为硬件/软件协同设计实现的验证安全服务。设计时考虑了简单性和最小化，从而实现了高效的计算和低硬件成本，使其在低端嵌入式系统中具有实际可行性。VRASED的实际应用通过使用低端MSP430平台的公开实现得到了证明。本文提出的设计和验证方法可以扩展到其他微控制器架构。我们相信，随着互联物联网设备的兴起，这项工作代表了嵌入式系统安全领域的一个重要且及时的进展。

未来工作的自然方向是将VRASED适应于其他微控制器架构。这种努力可以遵循本文提出的验证方法，包括：（1）将MCU规格映射到一组公理（如我们在第3节中对MSP430所做的），以及（2）相应地修改LTL规范和硬件设计（如第4节所述）。第二个方向是扩展VRASED的功能，以包括并验证其他可信计算服务，例如安全更新、安全删除和远程代码执行。此外，验证和实现具有不同要求和权衡的其他RA设计（如基于软件和基于硬件的技术）也是一个有前途的方向。特别是，验证基于形式验证的seL4微内核构建的HYDRA RA架构[20]是一个有前景的研究方向。最后，优化VRASED的HMAC，在保持其验证属性的同时，改进计算和内存分配，是一个有趣的开放问题。

**致谢**

加州大学欧文分校作者的工作部分由国土安全部通过HRL实验室的分包合同以及ARO合同W911NF-16-1-0536资助，并且还得到了NSF WiFiUS计划奖#1702911的支持。作者感谢论文指导者Stephen McCamant和匿名评审者的宝贵意见。

**参考文献**

[1] VRASED源代码. https://github.com/sprout-uci/vrased, 2019.

[2] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein, J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis, et al. Understanding the Mirai botnet. In USENIX Security, 2017.

[3] Arm Ltd. Arm TrustZone. https://www.arm.com/products/security-on-arm/trustzone, 2018.

[4] L. Beringer, A. Petcher, Q. Y. Katherine, and A. W. Appel. Verified correctness and security of OpenSSL HMAC. In USENIX Security, 2015.

[5] D. J. Bernstein, T. Lange, and P. Schwabe. The security impact of a new cryptographic library. In International Conference on Cryptology and Information Security in Latin America, 2012.

[6] K. Bhargavan, C. Fournet, M. Kohlweiss, A. Pironti, and P.-Y. Strub. Implementing TLS with verified cryptographic security. In IEEE S&P, 2013.

[7] A. Bogdanov, M. Knezevic, G. Leander, D. Toz, K. Varici, and I. Verbauwhede. Spongent: The design space of lightweight cryptographic hashing. IEEE Transactions on Computers, 62, 2013.

[8] B. Bond, C. Hawblitzel, M. Kapritsos, K. R. M. Leino, J. R. Lorch, B. Parno, A. Rane, S. Setty, and L. Thompson. Vale: Verifying high-performance cryptographic assembly code. In USENIX Security, 2017.

[9] F. Brasser, B. El Mahjoub, A.-R. Sadeghi, C. Wachsmann, and P. Koeberl. TyTAN: Tiny trust anchor for tiny devices. In DAC, 2015.

[10] F. Brasser, A.-R. Sadeghi, and G. Tsudik. Remote attestation for low-end embedded devices: the prover’s perspective. In DAC, 2016.

[11] G. Cabodi, P. Camurati, S. F. Finocchiaro, C. Loiacono, F. Savarese, and D. Vendraminetto. Secure embedded architectures: Taint properties verification. In DAS, 2016.

[12] G. Cabodi, P. Camurati, C. Loiacono, G. Pipitone, F. Savarese, and D. Vendraminetto. Formal verification of embedded systems for remote attestation. WSEAS Transactions on Computers, 14, 2015.

[13] X. Carpent, K. Eldefrawy, N. Rattanavipanon, A.-R. Sadeghi, and G. Tsudik. Reconciling remote attestation and safety-critical operation on simple IoT devices. In DAC, 2018.

[14] X. Carpent, K. Eldefrawy, N. Rattanavipanon, and G. Tsudik. Temporal consistency of integrity-ensuring computations and applications to embedded systems security. In ASIACCS, 2018.

[15] X. Carpent, N. Rattanavipanon, and G. Tsudik. ERASMUS: Efficient remote attestation via self-measurement for unattended settings. In DATE, 2018.

[16] X. Carpent, N. Rattanavipanon, and G. Tsudik. Remote attestation of IoT devices via SMARM: Shuffled measurements against roving malware. In IEEE HOST, 2018.

[17] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore, M. Roveri, R. Sebastiani, and A. Tacchella. NuSMV 2: An open-source tool for symbolic model checking. In CAV, 2002.

[18] I. De Oliveira Nunes, K. Eldefrawy, N. Rattanavipanon, M. Steiner, and G. Tsudik. Formally verified hardware/software co-design for remote attestation. arXiv preprint arXiv:1811.00175, 2018.

[19] A. Duret-Lutz, A. Lewkowicz, A. Fauchille, T. Michaud, E. Renault, and L. Xu. Spot 2.0—a framework for LTL and ω-automata manipulation. In ATVA, 2016.

[20] K. Eldefrawy, N. Rattanavipanon, and G. Tsudik. HYDRA: Hybrid design for remote attestation (using a formally verified microkernel). In WiSec, 2017.

[21] K. Eldefrawy, G. Tsudik, A. Francillon, and D. Perito. SMART: Secure and minimal architecture for (establishing dynamic) root of trust. In NDSS, 2012.

[22] O. Girard. openMSP430, 2009.

[23] C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan, B. Parno, D. Zhang, and B. Zill. Ironclad apps: End-to-end security via automated full-system verification. In USENIX OSDI, 2014.

[24] G. Hinterwälder, A. Moradi, M. Hutter, P. Schwabe, and C. Paar. Full-size high-security ECC implementation on MSP430 microcontrollers. In International Conference on Cryptology and Information Security in Latin America, pages 31–47. Springer, 2014.

[25] A. Ibrahim, A.-R. Sadeghi, and S. Zeitouni. SeED: Secure non-interactive attestation for embedded devices. In ACM WiSec, 2017.

[26] Texas Instruments. Msp430 ultra-low-power sensing & measurement mcus. http://www.ti.com/microcontrollers/msp430-ultra-low-power-mcus/overview.html.

[27] Intel. Intel Software Guard Extensions (Intel SGX). https://software.intel.com/en-us/sgx.

[28] A. Irfan, A. Cimatti, A. Griggio, M. Roveri, and R. Sebastiani. Verilog2SMV: A tool for word-level verification. In DATE, 2016.

[29] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and S. Winwood. seL4: Formal verification of an OS kernel. In SOSP, 2009.

[30] P. Koeberl, S. Schulz, A.-R. Sadeghi, and V. Varadharajan. TrustLite: A security architecture for tiny embedded devices. In EuroSys, 2014.

[31] X. Kovah, C. Kallenberg, C. Weathers, A. Herzog, M. Albin, and J. Butterworth. New results for timing-based attestation. In IEEE S&P, 2012.

[32] H. Krawczyk and P. Eronen. HMAC-based extract-and-expand key derivation function (HKDF). Internet Request for Comment RFC 5869, Internet Engineering Task Force, May 2010.

[33] X. Leroy. Formal verification of a realistic compiler. Communications of the ACM, 52(7):107–115, 2009.

[34] Y. Li, Y. Cheng, V. Gligor, and A. Perrig. Establishing software-only root of trust on embedded systems: Facts and fiction. In Security Protocols—22nd International Workshop, 2015.

[35] Y. Li, J. M. McCune, and A. Perrig. VIPER: Verifying the integrity of peripherals’ firmware. In CCS, 2011.

[36] F. Lugou, L. Apvrille, and A. Francillon. Toward a methodology for unified verification of hardware/software co-designs. Journal of Cryptographic Engineering, 2016.

[37] F. Lugou, L. Apvrille, and A. Francillon. Smashup: A toolchain for unified verification of hardware/software co-designs. Journal of Cryptographic Engineering, 7(1):63–74, 2017.

[38] J. Noorman, J. V. Bulck, J. T. Mühlberg, F. Piessens, P. Maene, B. Preneel, I. Verbauwhede, J. Götzfried, T. Müller, and F. Freiling. Sancus 2.0: A low-cost security architecture for IoT devices. ACM Trans. Priv. Secur., 20(3):7:1–7:33, July 2017.

[39] I. D. O. Nunes, G. Dessouky, A. Ibrahim, N. Rattanavipanon, A.-R. Sadeghi, and G. Tsudik. Towards systematic design of collective remote attestation protocols. In ICDCS, 2019.

[40] D. Perito and G. Tsudik. Secure code update for embedded devices via proofs of secure erasure. In ESORICS, 2010.

[41] J. Protzenko, J.-K. Zinzindohoué, A. Rastogi, T. Ramananandro, P. Wang, S. Zanella-Béguelin, A. Delignat-Lavaud, C. Hriţcu, K. Bhargavan, C. Fournet, et al. Verified low-level programming embedded in F*. Proceedings of the ACM on Programming Languages, 1, 2017.

[42] S. Ravi, A. Raghunathan, and S. Chakradhar. Tamper resistance mechanisms for secure embedded systems. In VLSI Design, 2004.

[43] A. Seshadri, M. Luk, A. Perrig, L. van Doorn, and P. Khosla. Scuba: Secure code update by attestation in sensor networks. In ACM workshop on Wireless security, 2006.

[44] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla. Pioneer: Verifying code integrity and enforcing untampered code execution on legacy systems. ACM SIGOPS Operating Systems Review, December 2005.

[45] L. Simon, D. Chisnall, and R. Anderson. What you get is what you C: Controlling side effects in mainstream C compilers. In IEEE EuroS&P, 2018.

[46] Texas Instruments. MSP430 GCC user’s guide, 2016.

[47] Trusted Computing Group. Trusted platform module (TPM), 2017.

[48] G. S. Tuncay, S. Demetriou, K. Ganju, and C. A. Gunter. Resolving the

### 相关工作

据我们所知，目前尚无任何先前工作能够产出一个正式验证的RA设计（RA架构在第2.1节中有概述）。据我们所知，VRASED是首个验证的安全服务，其实现为硬件/软件协同设计。尽管如此，形式验证已被广泛用作确保系统免受实现错误和漏洞的默认手段。近年来，多个研究致力于验证安全关键系统。

在密码学原语方面，Hawblitzel等人[23]验证了SHA、HMAC和RSA的新实现。Beringer等人[4]验证了OpenSSL SHA-256实现。Bond等人[8]验证了一个汇编实现的Poly1305。最近，Zinzindohoué等人[52]开发了HACL*，一个包含NaCl[5]整个密码学API的验证密码库。正如前面讨论的，HACL*的验证HMAC构成了VRASED软件组件的核心。

更大规模的安全关键系统也已成功验证。例如，Bhargavan[6]实现了一个具有验证密码学安全性的TLS协议。CompCert[33]是一个形式验证的C编译器，它保证生成的汇编代码保留C代码的语义。Klein等人[29]设计并证明了seL4——第一个验证的通用微内核的功能正确性。最近，Tuncay等人[48]验证了一个Android操作系统应用程序权限模型的设计。Lugou等人[36]最近承认了验证RA的重要性，讨论了专门用于验证硬件/软件RA协同设计的方法论。随后的结果提出了SMASH-UP工具[37]。通过建模硬件抽象，SMASH-UP允许自动转换汇编指令为硬件表示的效果。类似地，Cabodi等人[11, 12]讨论了迈向形式化混合RA属性的第一步。然而，这些结果都没有产生一个完全验证的（并且公开可用的）RA架构，如VRASED。

**图13：针对低端设备的远程认证架构比较**

与VRASED相比，SANCUS需要多12倍的查找表、多22倍的寄存器，并且其未经验证的TCB在Verilog代码行数上大2.5倍。这一比较展示了即使在设计为最小化的情况下，依赖纯硬件方法的成本。SMART的开销略小于VRASED，因为它不支持DMA。在认证执行时间方面，SMART最慢，需要9.2M时钟周期来认证4KB的内存。SANCUS由于实现了SPONGENT-128/128/8的硬件实现，达到了最快的认证时间（1.3M周期）。VRASED介于两者之间，总认证时间为3.6M周期。

**A.2 机器模型**

为了证明VRASED的设计满足RA的端到端定义的声音性和安全性，我们首先形式化定义（在LTL中）与第3节介绍的架构相对应的内存和执行模型。

**定义4（内存模型）**

1. K存储在ROM中 ↔ G : {KR = K}
2. SW-Att存储在ROM中 ↔ G : {CR = SW-Att}
3. MR、CR、AR、KR和XS是非重叠的内存区域

定义4中的内存模型捕获了KR和CR是ROM区域，因此是不可变的。因此，存储在这些区域中的值始终对应于K和SW-Att代码。最后，内存模型声明MR、CR、AR、KR和XS在内存布局中是不相交的区域，对应于图3中的架构。

**定义5（执行模型）**

...