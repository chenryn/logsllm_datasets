# 4.3 Hypothesis Testing and ROC Analysis

In Table 3, from column U1 to U8, we perform hypothesis testing on the results of 20 runs within each experiment. The last column presents the results of hypothesis testing on the combined results of all experiments. We observe significant improvements in our model compared with baseline models, as indicated by the p-values.

| Experiment | B1 vs. B2 | B1 vs. Our | B2 vs. Our |
|------------|-----------|-------------|-------------|
| U5         | -5.41**   | -5.41**     | -5.41**     |
| U6         | -5.41**   | -5.41**     | -5.41**     |
| U7         | -5.41**   | -5.41**     | -15.47**    |
| U8         | -5.41**   | -5.41**     | -5.41**     |
| All        | -5.41**   | -5.41**     | -5.41**     |

* Indicates significance under 0.01.
** Indicates significance under 0.0001.
p-value is shown in parentheses if it is not significant at these levels.

Furthermore, Figure 8 illustrates the average ROC curves for eight experiments under our probabilistic integrity level, providing a better understanding of the performance.

![Figure 8: Average ROC of eight experiments under our model](fig8.png)

## 4.4 Running Time Analysis

The time complexity of the employed classifier, random forests, has been well studied and is given by \( O(mn \log n) \), where \( m \) is the number of trees in the random forest, and \( n \) is the number of processes (data points). In our experiments, we found that \( m = 10 \) is optimal. Therefore, we do not present the running time of the random forest classifier separately.

We explore the running time of our probabilistic integrity model, as the running time of loopy belief propagation can vary depending on the problem. We vary the problem size, which is the number of subject-object pairs, by randomly selecting different portions of subjects and their associated subject-object pairs. Figure 9 shows a scatter plot of running time in seconds against problem size in thousands, along with a linear regression fit. We observe a strong linear relationship, supported by significant coefficients and an \( R^2 \) value of 0.93, between the running time and the problem size. This result verifies the linear time complexity of our probabilistic integrity model and demonstrates its feasibility for runtime malware detection.

![Figure 9: Scatter plot of running time in seconds against problem size in thousands](fig9.png)

## 5 Conclusion and Future Work

Despite considerable efforts by security researchers and engineers, attackers often move faster than defenders. This paper presents a probabilistic model for access behaviors of programs and the integrity levels of programs, files, and registries. By employing probabilistic inference, we determine the integrity levels of these system subjects and objects. Combined with a statistical classifier, we build an integrity-based access behavior model for malware detection. The encouraging experimental results indicate the feasibility and usefulness of our model. The linear time complexity of our probabilistic integrity model is both theoretically proven and experimentally verified.

Our model can be extended to subjects and objects at other granularities, constrained by similar security policies. Additionally, our model can be adapted to determine levels of other security attributes, such as confidentiality, according to corresponding security policies, such as the Bell-LaPadula model.

We believe that our probabilistic integrity model will be enhanced when acquiring knowledge from both benign and malicious programs. Thus, building a model that combines the access behaviors of both benign and malicious programs will be our future work.

## Acknowledgments

We would like to thank our shepherd, Manos Antonakakis, and the anonymous reviewers for their insightful comments that greatly helped improve the presentation of this paper. This work is supported by NFSC (61175039, 61221063, 61403301), 863 High Tech Development Plan (2012AA011003), Research Fund for Doctoral Program of Higher Education of China (20090201120032), International Research Collaboration Project of Shaanxi Province (2013KW11), and Fundamental Research Funds for Central Universities (2012jdhz08). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsor.

## Appendix: Derivation of Eq. (8)

\[ P(EI|Acc) \propto \sum_{T} P(Acc|T)P(T|EI) \]

where

\[ P(EI|D)P(D) = \sum_{D} D \]

And then,

\[ P(> | Acc) \propto \frac{\alpha_3}{\alpha_1 + \alpha_2 + \alpha_3} \]

Summing up Eqs. (19)–(21), we derive the posterior distribution of \( EI \) given \( Acc \), i.e., \( P(EI|Acc) \), as shown in Eqs. (9)–(11).

## References

1. Anderson, R.: Security Engineering: A Guide to Building Dependable Distributed Systems. John Wiley & Sons (2008)
2. Apap, F., Honig, A., Hershkop, S., Eskin, E., Stolfo, S.J.: Detecting malicious software by monitoring anomalous windows registry accesses. In: Wespi, A., Vigna, G., Deri, L. (eds.) RAID 2002. LNCS, vol. 2516, p. 36. Springer, Heidelberg (2002)
3. Bellovin, S.M.: Security and usability: Windows Vista, July 2007. https://www.cs.columbia.edu/smb/blog/2007-07/2007-07-13.html
4. Biba, K.J.: Integrity considerations for secure computer systems. ESD-TR 76–372, MITRE Corp. (1977)
5. Breiman, L.: Random forests. Mach. Learn. 45, 5–32 (2001)
6. Canali, D., Lanzi, A., Balzarotti, D., Kruegel, C., Christodorescu, M., Kirda, E.: A quantitative study of accuracy in system call-based malware detection. In: Proceedings of the 2012 International Symposium on Software Testing and Analysis, pp. 122–132. ACM (2012)
7. Fraser, T.: Lomac: low water-mark integrity protection for COTS environments. In: IEEE Symposium on Security and Privacy (S&P), pp. 230–245 (2000)
8. Fredrikson, M., Jha, S., Christodorescu, M., Sailer, R., Yan, X.: Synthesizing near-optimal malware specifications from suspicious behaviors. In: IEEE Symposium on Security and Privacy (S&P), pp. 45–60 (2010)
9. Gelman, A., Carlin, J.B., Stern, H.S., Rubin, D.B.: Bayesian data analysis, vol. 2. Taylor & Francis (2014)
10. Gu, Z., Pei, K., Wang, Q., Si, L., Zhang, X., Xu, D.: LEAPS: detecting camouflaged attacks with statistical learning guided by program analysis. In: 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE (2015)
11. How the integrity mechanism is implemented in Windows Vista (2014). http://msdn.microsoft.com/en-us/library/bb625962.aspx
12. Hsu, F., Chen, H., Ristenpart, T., Li, J., Su, Z.: Back to the future: a framework for automatic malware removal and system repair. In: 22nd Annual Computer Security Applications Conference, ACSAC 2006, pp. 257–268. IEEE (2006)
13. King, S.T., Chen, P.M.: Backtracking intrusions. ACM Trans. Comput. Syst. 23, 51–76 (2005)
14. Koller, D., Friedman, N.: Probabilistic graphical models: principles and techniques. MIT press (2009)
15. Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G.: Automating mimicry attacks using static binary analysis. In: Proceedings of the 14th conference on USENIX Security Symposium, vol. 14, pp. 11–11. USENIX Association (2005)
16. Kruegel, C., Mutz, D., Valeur, F., Vigna, G.: On the detection of anomalous system call arguments. In: Snekkenes, E., Gollmann, D. (eds.) ESORICS 2003. LNCS, vol. 2808, pp. 326–343. Springer, Heidelberg (2003)
17. Lanzi, A., Balzarotti, D., Kruegel, C., Christodorescu, M., Kirda, E.: Accessminer: using system-centric models for malware protection. In: Proceedings of the 17th ACM conference on Computer and Communications Security (CCS), pp. 399–412. ACM (2010)
18. Manadhata, P.K., Yadav, S., Rao, P., Horne, W.: Detecting malicious domains via graph inference. In: Kutyłowski, M., Vaidya, J. (eds.) ICAIS 2014, Part I. LNCS, vol. 8712, pp. 1–18. Springer, Heidelberg (2014)
19. Mandatory Integrity Control (2014). http://msdn.microsoft.com/en-us/library/windows/desktop/bb648648
20. Mao, W., Cai, Z., Guan, X., Towsley, D.: Centrality metrics of importance in access behaviors and malware detections. In: Proceedings of the 30th Annual Computer Security Applications Conference (ACSAC 2014). ACM (2014)
21. Mao, Z., Li, N., Chen, H., Jiang, X.: Combining discretionary policy with mandatory information flow in operating systems. ACM Trans. Inf. Syst. Secur. (TISSEC) 14(3), 24 (2011)
22. Mark Russinovich, B.C.: Process monitor (2014). http://technet.microsoft.com/en-us/sysinternals/bb896645
23. Muthukumaran, D., Rueda, S., Talele, N., Vijayakumar, H., Teutsch, J., Jaeger, T., Edwards, N.: Transforming commodity security policies to enforce Clark-Wilson integrity. In: Proceedings of the 28th Annual Computer Security Applications Conference (ACSAC 2012). ACM (2012)
24. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., et al.: Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825–2830 (2011)
25. Sun, W., Sekar, R., Liang, Z., Venkatakrishnan, V.N.: Expanding malware defense by securing software installations. In: Zamboni, D. (ed.) DIMVA 2008. LNCS, vol. 5137, pp. 164–185. Springer, Heidelberg (2008)
26. Sun, W., Sekar, R., Poothia, G., Karandikar, T.: Practical proactive integrity preservation: a basis for malware defense. In: IEEE Symposium on Security and Privacy (S&P), pp. 248–262 (2008)
27. Symantec. Internet Security Threat Report, April 2015. https://www4.symantec.com/mktginfo/whitepaper/ISTR/21347932 GA-internet-security-threat-report-volume-20-2015-social v2.pdf
28. Sze, W.-K., Sekar, R.: A portable user-level approach for system-wide integrity protection. In: Proceedings of the 29th Annual Computer Security Applications Conference (ACSAC 2013), pp. 219–228. ACM (2013)
29. Tamersoy, A., Roundy, K., Chau, D.H.: Guilt by association: large scale malware detection by mining file-relation graphs. In: Proceedings of the 20th ACM SIGKDD international conference on Knowledge Discovery and Data Mining, pp. 1524–1533. ACM (2014)
30. VXHeaven (2010). http://vx.netlux.org/