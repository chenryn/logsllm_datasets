### Optimized Text

**Numerical Values and Exponents:**
- \(1.36 \times 10^4\)
- \(1.84 \times 10^2\)
- \(8.87 \times 10^{-6}\)
- \(74\)

**Text:**

The rapid decrease in the magnitude of pivots is illustrated in Figure 6.

For Case Study 2, the parameter assignments (with rates expressed in hour\(^{-1}\)) are:
- \(n_c = 3\)
- \(\lambda = 10^{-5}\)
- \(n_{e,1} = 5\)
- \(n_{e,2} = 3\)
- \(\theta_1 := L \in [1, 3]\)
- \(\theta_2 := \mu \in [0.5, 2.5]\)

Table II reports the speedup and accuracy for Reliability as the number of points increases (specifically, \(n_0\) is kept at 10, while both \(n_1\) and \(n_2\) span \{10, 20, 100\}), and for Low charge with \(10^6\) points. As expected, the speedup increases with the number of points. The value of \(k\) remains low (approximately 30), but the number of approximation points required for the parameters' fibers increases. It is important to note that the strict definition of accuracy used here and the adaptive choice of pivots result in a smaller accuracy with 32 and 34 approximation points compared to 32.

**Figure 6:**
- **Caption:** Case Study 1c: Absolute value of the pivot when computing Reliability as a function of the steps \(h = 1, \ldots, k\). In this run, ACA stops at \(k = 15\).

**Comparison with GLM:**

To enrich the comparison, the Generalized Linear Model (GLM) has been selected as an alternative to the proposed ACA approximation. The GLM, defined consistently with the rest of the paper, is given by:
\[ \hat{m} = E[m|t, \theta] = g(\beta^{-1} + \beta_0 \cdot t + \beta_1 \cdot h_1(\theta_1) + \cdots + \beta_p \cdot h_p(\theta_p)) \]
GLM is the ancestor of many interpretable metamodels. Choosing GLM allows for both quantitative and qualitative comparisons between ACA and GLM descendants. Key differences include:
- In GLM, a case-by-case choice of the dependent variable distribution (within the exponential family) and link function \(g\) is needed, whereas ACA is more general.
- The independent variable functions \(h_i\) are also chosen case-by-case, considering how each parameter influences the final measure.
- The parameters vector \(\beta\) in GLM has \(p + 2\) entries, while in ACA, the number of approximants \(k\) is chosen dynamically. Thus, GLM does not gain much in accuracy as the number of points increases beyond a threshold of the order of \(p\).

**Numerical Evaluations:**

Numerical evaluations were conducted on Reliability in Case Study 1 for \(n_0 n_1 n_2 = 8 \times 10^3\), using the Gamma family with the default link function and MATLAB's `fitglm` function. Several arrangements of points and functions of the independent variables were considered. The best relative accuracy achieved with the GLM metamodel was \(1.40 \times 10^{-2}\) with 100 randomly distributed points (with 10 points, the accuracy was \(2.21 \times 10^{-2}\)). Using the approach in Section IV, \(k = 9\) was sufficient to achieve a relative accuracy of \(3.19 \times 10^{-7}\). Although the ACA approximation provides higher accuracy, it requires more computation time: GLM is about 37 times faster than ACA. However, both methods take less than one second to perform the approximation, while the full tensor evaluation takes about 9 seconds.

In `fitglm`, mixed terms can be introduced in the approximation, albeit with a slight loss of interpretability. Through trial and error, the best accuracy obtained was \(2.59 \times 10^{-4}\) with the `poly233` option, and the training time was almost the same.

**Sensitivity Analysis:**

To demonstrate the utility of the computed measure bundle, global sensitivity analysis was selected. Specifically, the measures "Under repair" from Case Study 1a and "Reliability" from Case Study 2 were considered. Heatmaps of the approximated measures \(\hat{m}\) for \(t_{\text{max}}\) equal to 2 years and varying parameter values are shown in Figures 7 and 8. Figure 7 confirms that \(c\) is more relevant than \(\lambda\) for "Under repair," and the increase/decrease pattern follows the axes directions. In Figure 8, bend curves of equal Reliability appear, indicating that more complex design choices are possible.

**Related Work:**

Focusing on aspects directly related to the contribution, the literature primarily addresses the time fiber. Integration- and simulation-based approaches differ from expansion- and approximation-based ones in that the former impose a causal order among time points, preventing parallelization in time. Uniformization and semi-symbolic methods, such as those in [11], [30], [31], work with a single time point and allow for high levels of parallelism, even with dedicated hardware. Importing a different method to evaluate the tensor along the time fiber, such as [7], does not impact the presented speedup.

The main issue with previously mentioned strategies is that, even if they are efficient in solving one system of ODEs, dealing with large values of \(n_{\text{sample}}\) can quickly become unfeasible. Among the published strategies to mitigate this, only those explicitly addressing the parameters fiber are discussed here.

In [16], [17], a metamodel (also known as a surrogate model or emulator) is presented. The performability model is solved on a predefined set of time and parameters points, and the dataset \(\{(t(h), \theta(h)), m_{\theta(h)}(t(h))\}_h\) is divided into training, test, and validation sets. The results show that the required training set size is much smaller than the number of points in the full tensor \(M\). However, choosing the samples (e.g., through random sampling, Latin hypercube sampling, or Sobol sequence sampling) can be challenging. The training set is fixed at the beginning, whereas the approach presented in this paper is adaptive. No assumption is made about the smoothness of the measure, and the performability model can be solved through simulation, addressing models more general than Markov. Instead of using a single approximation/machine learning method, the authors present a stack of methods to enhance accuracy. This stack, however, is trained as a black box, losing interpretability. Further work is needed to investigate how explainability techniques can increase trust in this approach.

**Conclusions and Future Work:**

This paper presents a new low-rank approximation \(\hat{M}\) of performability measures based on the ACA technique for Markov models. The main challenge, addressing parameters' fibers to gain efficiency over the full evaluation of the tensor \(M\), is addressed by tailoring well-known results to the measures of interest in Sections IV-D and IV-E. The resulting approximation approach is accurate and trustworthy due to the decomposability property promoted by separable approximants.

Future work includes:
- Comparing the presented approach with existing alternatives in the explainable (black box) category, such as [16], [17].
- Tweaking the approach to address models more general than Markov, maintaining good performance as long as the resulting measures are smooth.
- Addressing semi-Markov models under not-so-restrictive conditions on the involved Cumulative Distribution Functions.
- Considering time- and parameters-dependent rewards \(r(t, \theta)\) for instantaneous measures, provided they are smooth functions.
- Investigating generalizations of ACA to address high-dimensional tensors.
- Exploring natural competitors among approximation/machine learning approaches addressing PDEs, such as the strategy in [8].

**References:**

[1] K. S. Trivedi and A. Bobbio, *Reliability and Availability Engineering: Modeling, Analysis, and Applications*, 2017.

[2] B. R. Haverkort and K. S. Trivedi, “Specification techniques for Markov reward models,” *Discrete Event Dyn. Syst.*, no. 3, pp. 219–247, 1993.

[3] W. H. Sanders and J. F. Meyer, “A unified approach for specifying measures of performance, dependability and performability,” *Dependable Computing for Critical Applications, Vol. 4 of Dependable Computing and Fault-Tolerant Systems*, pp. 215–237, 1991.

[4] A. L. Reibman and K. S. Trivedi, “Transient analysis of cumulative measures of Markov model behavior,” *Communications in Statistics. Stochastic Models*, vol. 5, no. 4, pp. 683–710, 1989.

[5] A. L. Reibman, R. Smith, and K. S. Trivedi, “Markov and Markov reward model transient analysis: An overview of numerical approaches,” *European Journal of Operational Research*, vol. 40, pp. 257–267, 1989.

[6] M. Malhotra, J. K. Muppala, and K. S. Trivedi, “Stiffness-tolerant methods for transient analysis of stiff Markov chains,” *Microelectronics Reliability*, vol. 34, no. 11, pp. 1825–1841, 1994.

[7] A. V. Ramesh and K. Trivedi, “Semi-numerical transient analysis of Markov models,” in *Proceedings of the 33rd Annual on Southeast Regional Conference, ser. ACM-SE 33*, 1995, pp. 13–23.

[8] C. W. Flamant, P. Protopapas, and D. Sondak, “Solving differential equations using neural network solution bundles,” *ArXiv*, vol. abs/2006.14372, 2020.

[9] M. Bebendorf, “Adaptive cross approximation of multivariate functions,” *Const. Approx.*, vol. 34, no. 2, pp. 149–179, 2011.

[10] R. Marcinkeviˇcs and J. E. Vogt, “Interpretability and explainability: A machine learning zoo mini-tour,” *ArXiv*, vol. 2012.01805, 2020.

[11] M. Malhotra, J. K. Muppala, and K. S. Trivedi, “Stiffness-tolerant methods for transient analysis of stiff Markov chains,” *Microelectronics Reliability*, vol. 34, no. 11, pp. 1825–1841, 1994.

[12] A. C. Hindmarsh, P. N. Brown, K. E. Grant, S. L. Lee, R. Serban, D. E. Shumaker, and C. S. Woodward, “SUNDIALS: Suite of nonlinear and differential/algebraic equation solvers,” *ACM Transactions on Mathematical Software (TOMS)*, vol. 31, no. 3, pp. 363–396, 2005.

[13] R. L. Iman and J. C. Helton, “An investigation of uncertainty and sensitivity analysis techniques for computer models,” *Risk Analysis*, vol. 8, no. 1, pp. 71–90, 1988.

[14] É. Walter and L. Pronzato, *Identification of parametric models: from experimental data*, ser. Communications and Control Engineering. Heidelberg: Springer-Verlag, 1997.

[15] H. Pham, *Reliability Modeling, Analysis and Optimization*, ser. on Quality, Reliability and Engineering Statistics, M. Xie, T. Bendell, and A. P. Basu, Eds. Singapore: World Scientific, 2006, vol. 9.

[16] M. Rausch and W. H. Sanders, “Sensitivity analysis and uncertainty quantification of state-based discrete-event simulation models through a stacked ensemble of metamodels,” in *Quantitative Evaluation of Systems*, 2020, pp. 276–293.

[17] ——, “Evaluating the effectiveness of metamodeling in emulating quantitative models,” in *Quantitative Evaluation of Systems*, 2021, pp. 127–145.

[18] A. Townsend and L. N. Trefethen, “An extension of Chebfun to two dimensions,” *SIAM J. Sci. Comput.*, vol. 35, no. 6, pp. C495–C518, 2013. [Online]. Available: https://doi.org/10.1137/130908002

[19] R. A. Maire, A. L. Reibman, and K. S. Trivedi, “Transient analysis of acyclic Markov chains,” *Performance Evaluation*, vol. 7, no. 3, pp. 175–194, 1987.

[20] L. N. Trefethen, *Approximation theory and approximation practice*. Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA, 2013.

[21] A. J. Carpenter, A. Ruttan, and R. S. Varga, “Extended numerical computations on the 1/9 conjecture in rational approximation theory,” in *Rational approximation and interpolation*. Springer, 1984, pp. 383–411.

[22] B. Hashemi and L. N. Trefethen, “Chebfun in three dimensions,” *SIAM J. Sci. Comput.*, vol. 39, no. 5, pp. C341–C363, 2017. [Online]. Available: https://doi.org/10.1137/16M1083803

[23] J. W. Demmel, *Applied numerical linear algebra*. Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA, 1997. [Online]. Available: https://doi.org/10.1137/1.9781611971446

[24] T. F. Chan, “Rank revealing QR factorizations,” *Linear Algebra Appl.*, vol. 88/89, pp. 67–82, 1987. [Online]. Available: https://doi.org/10.1016/0024-3795(87)90103-0