# Performance Analysis with LSM and SELinux

## 2.5.15 vs. 2.5.15-lsm

### Page Fault Overhead
- **Page Faults**: 
  - 2.5.15: 73
  - 2.5.15-lsm: 73
  - % Overhead: 0%
- **Latency (ms)**:
  - 2.5.15: 8.545
  - 2.5.15-lsm: 8.811
  - % Overhead: 3.1%
- **Operations**:
  - 2.5.15: 142
  - 2.5.15-lsm: 143
  - % Overhead: 0.7%
- **Context Switches**:
  - 2.5.15: 25
  - 2.5.15-lsm: 27
  - % Overhead: 8%
- **System Calls**:
  - 2.5.15: 4874
  - 2.5.15-lsm: 4853
  - % Overhead: -0.4%
- **Efficiency**:
  - 2.5.15: 0.974
  - 2.5.15-lsm: 0.990
  - % Overhead: 1.6%

### Local Communication Bandwidth (MB/s)
- **Test Type**:
  - **pipe**:
    - 2.5.15: 537
    - 2.5.15-lsm: 542
    - % Overhead: -0.9%
  - **AF Unix**:
    - 2.5.15: 98
    - 2.5.15-lsm: 116
    - % Overhead: -18.4%
  - **TCP**:
    - 2.5.15: 257
    - 2.5.15-lsm: 235
    - % Overhead: 8.6%
  - **File Reread**:
    - 2.5.15: 306
    - 2.5.15-lsm: 306
    - % Overhead: 0%
  - **mmap Reread**:
    - 2.5.15: 368
    - 2.5.15-lsm: 368
    - % Overhead: 0%
  - **bcopy (libc)**:
    - 2.5.15: 191
    - 2.5.15-lsm: 191
    - % Overhead: 0%
  - **bcopy (hand)**:
    - 2.5.15: 148
    - 2.5.15-lsm: 151
    - % Overhead: -2%
  - **Memory Read**:
    - 2.5.15: 368
    - 2.5.15-lsm: 368
    - % Overhead: 0%
  - **Memory Write**:
    - 2.5.15: 197
    - 2.5.15-lsm: 197
    - % Overhead: 0%

## LMBench Microbenchmarks

### 4-Processor Machine
- **Local Communication Bandwidth (MB/s)**:
  - **pipe**:
    - 2.5.15: 630
    - 2.5.15-lsm: 597
    - % Overhead: 5.2%
  - **AF Unix**:
    - 2.5.15: 125
    - 2.5.15-lsm: 125
    - % Overhead: 0%
  - **TCP**:
    - 2.5.15: 222
    - 2.5.15-lsm: 220
    - % Overhead: 0.9%
  - **File Reread**:
    - 2.5.15: 316
    - 2.5.15-lsm: 313
    - % Overhead: 0.9%
  - **mmap Reread**:
    - 2.5.15: 378
    - 2.5.15-lsm: 368
    - % Overhead: 2.6%
  - **bcopy (libc)**:
    - 2.5.15: 199
    - 2.5.15-lsm: 191
    - % Overhead: 4%
  - **bcopy (hand)**:
    - 2.5.15: 168
    - 2.5.15-lsm: 149
    - % Overhead: 11.3%
  - **Memory Read**:
    - 2.5.15: 378
    - 2.5.15-lsm: 396
    - % Overhead: 2.6%
  - **Memory Write**:
    - 2.5.15: 206
    - 2.5.15-lsm: 197
    - % Overhead: 4.4%

### 1-Processor Machine
- **Linux Kernel Build Time (seconds)**:
  - 2.5.15: 92
  - 2.5.15-lsm: 92
  - % Overhead: 0%
  - 2.5.15: 341
  - 2.5.15-lsm: 342
  - % Overhead: 0.3%

## Macrobenchmark: Webstone

### UP Webstone Results
- **Connection Rate (connections/second)**:
  - **Standard Kernel (2.5.7)**:
    - 8 clients: 916.56
    - 16 clients: 917.64
    - 24 clients: 917.44
    - 32 clients: 918.91
  - **LSM Kernel (2.5.7-lsm)**:
    - 8 clients: 870.98
    - 16 clients: 869.79
    - 24 clients: 872.28
    - 32 clients: 876.17
  - **% Overhead**:
    - 8 clients: 4.97%
    - 16 clients: 5.21%
    - 24 clients: 4.92%
    - 32 clients: 4.65%

- **SELinux Kernel (2.5.7-SEL)**:
  - 8 clients: 766.58
  - 16 clients: 766.48
  - 24 clients: 765.56
  - 32 clients: 764.80
  - **% Overhead**:
    - 8 clients: 16.4%
    - 16 clients: 15.5%
    - 24 clients: 16.6%
    - 32 clients: 16.8%

### SMP Webstone Results
- **Connection Rate (connections/second)**:
  - **Standard Kernel (2.5.7)**:
    - 8 clients: 1206.05
    - 16 clients: 1206.74
    - 24 clients: 1214.54
    - 32 clients: 1207.30
  - **LSM Kernel (2.5.7-lsm)**:
    - 8 clients: 1115.29
    - 16 clients: 1117.61
    - 24 clients: 1130.13
    - 32 clients: 1125.89
  - **% Overhead**:
    - 8 clients: 7.53%
    - 16 clients: 7.39%
    - 24 clients: 6.95%
    - 32 clients: 6.74%

- **SELinux Kernel (2.5.7-SEL)**:
  - 8 clients: 949.56
  - 16 clients: 949.74
  - 24 clients: 952.28
  - 32 clients: 956.76
  - **% Overhead**:
    - 8 clients: 21.3%
    - 16 clients: 21.3%
    - 24 clients: 21.6%
    - 32 clients: 20.1%

## Observations
- The worst-case overhead for the `select()` system call was 5.1%, while `open/close` and `file delete` operations showed overheads of 2.7% and 3.1%, respectively.
- The performance penalty for `select()` is an opportunity for optimization, as confirmed by macrobenchmark experiments.
- For comprehensive application-level impact, see Sections 5.2.2 and 5.2.3.
- The standard kernel was compiled with Netfilter support, while the LSM kernel included Netfilter-based hooks and used the default superuser logic.
- The SELinux kernel was compiled with SELinux and Netfilter support, and the SELinux module was stacked with the capabilities module.
- The 5–7% overhead observed in the LSM benchmarks is greater than desired, and a separate experiment without the Netfilter LSM hooks showed a more desirable 1–2% performance overhead.
- The SELinux module imposes about 16% overhead on connection rate in UP tests and about 21% overhead in SMP tests, likely due to locking issues.

This structured format provides a clear and professional presentation of the performance analysis, making it easier to understand and reference.