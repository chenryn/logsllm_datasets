### Introduction

In the context of multi-threading, only Mtrt (Multi-Threaded Real-Time) actually requires replicated lock acquisition. We implemented this mechanism for both a green threads library, which supports user-level threads on uniprocessors, and a native threads library, which supports multi-threading on Symmetric Multi-Processing (SMP) systems. Thread scheduling was implemented exclusively for the green threads library. The overheads observed in both implementations of replicated lock acquisition were qualitatively similar, leading us to report results from the green threads implementation. All experiments were conducted on lightly loaded machines running in multi-user mode, with repetitions until 95% confidence intervals were within 1% of the mean.

### Experimental Results

**Figure 2** shows the overall execution times of benchmark applications using each of our replication approaches, normalized to the corresponding times without any replication. The primary columns represent the execution times of logging events to the backup, while the backup columns show the times for the backup to replay events from the log.

Although our implementation was not aggressively optimized (we only optimized some aspects of the replicated thread scheduler), we observed under 100% overhead for most applications. Replicating lock acquisitions resulted in an average of 140% overhead (skewed by Db) for green threads, significantly higher than the 60% average for replicated thread scheduling.

**Figure 3** details the normalized overhead for the replicated lock acquisition implementation using the green threads library. The overhead ranges from 5% (Mpegaudio) to 375% (Db). The large overhead in Db is due to processing over 53 million lock acquisitions. In **Figure 3**, Communication Overhead represents the time spent sending messages to the backup, and Lock Acquire Overhead measures the time spent storing information on lock acquire. Pessimistic Overhead represents the time spent waiting for acknowledgments from the backup on output commit events.

In our implementation, lock acquisition messages are very small (36 bytes). The primary buffers such messages and sends them to the backup either periodically or on an output commit. In the latter case, the primary sends the buffered messages and waits for an acknowledgment. Similarly, the backup sends an acknowledgment message after processing a burst of incoming logging messages.

**Figure 4** details the sources of overhead for the replicated thread scheduling implementation. Communication Overhead and Pessimistic Overhead are as in **Figure 3**, while Rescheduling Overhead measures the time spent updating counters and storing scheduling decisions. The overhead varies from 100% (Jack) to 15% (Compress).

Replicating thread scheduling yields lower communication overhead than replicating lock acquisition, as only Mtrt logs any thread schedule records to the backup. Further, to reduce the number of records, a record is sent only when a new thread is scheduled. Single-threaded benchmarks do not involve transmission of any records, unlike the replicated lock acquisition implementation, which sends many unnecessary messages. For single-threaded applications, we expect replicated thread scheduling to incur smaller overhead.

In practice, however, this is not always the case, as seen in **Figure 2**, because storing thread progress incurs significant overhead. As shown in **Figure 4**, the overhead of replicated thread scheduling is dominated by Misc. Overhead, which captures the overhead resulting from extra bookkeeping. In an earlier version, the bookkeeping overhead overwhelmed any communication advantages. To reduce these costs, we added about 12 instructions that update counters and track the virtual machine’s PC to the hand-written optimized assembly loop that executes bytecodes at the heart of the JVM. Significant additional reductions could be achieved by further optimizing the code. Using a deterministic scheduler, as in Jikes RVM [9, 10] or Jalapeño [11], might result in lower overhead, as the progress indicators would be simplified.

### Tradeoffs

The two approaches to handling multi-threading present different tradeoffs. Replicating lock acquisitions may be less effective if a thread acquires or releases objects several times before being rescheduled. Replicating thread scheduling handles the single-threaded case automatically, as no extra messages are sent. Nonetheless, replicating lock acquisitions is still compelling because it works on multiprocessor systems and may provide better performance, as in the case of Mtrt.

Communication overhead is the dominant source of overhead in our experiments. The amount of communication for a given application created by each technique is an effective predictor of their performance.

### Related Work

Replica coordination can be implemented at various levels of a system's architecture, from the application level [12] down to the hardware [13]. Systems implementing replica coordination at intermediate levels include TFT [14] (at the interface above the operating system) and [3], where replica coordination is implemented above a virtual machine that exports the same instruction set architecture as HP’s PA-RISC.

We first reported on our fault-tolerant JVM in [15]. Since then, other concurrent and independent efforts have addressed similar issues. Basile et al. [16] developed a leader-follower replicated lock acquisition algorithm for a webserver application, assuming R4A and a Byzantine failure model. Their algorithm is similar to ours but does not explore scenarios where R4A doesn’t hold.

Friedman and Kama [10] explored modifying the Jikes RVM to achieve transparent fault-tolerance using semi-active replication. Although we share the same goals, our approaches differ: their approach only applies to systems where R4A holds, and they do not address non-deterministic native methods. They report experiments using JIT, while all our experiments are performed in interpreted mode.

Earlier work on debugging multi-threaded applications, such as DejaVu [18, 11], addresses non-determinism by recording logical thread intervals. Our focus on fault-tolerance includes a general approach to handling application-provided native methods and addressing output to the environment. The use of intervals in DejaVu results in much smaller trace sizes, but the overhead is still 40%-80%, comparable to ours without pessimism.

To the best of our knowledge, replicating lock acquisitions for handling multi-threading was first proposed by Goldberg et al. [19] for Mach applications. Correctness depends on the absence of data races, and mechanisms like those in [21, 6] can verify R4A.

Our implementation of replicated thread scheduling is based on Slye and Elnozahy [7], who record thread progress using a count of control flow changes. Our solution differs in that the JVM cannot track all control flow changes (e.g., during native method execution) and does not recover all threads (e.g., the garbage collector).

### Conclusions

We built a fault-tolerant JVM using the state machine approach and implemented and evaluated two techniques for eliminating the non-determinism introduced by multi-threading. The first technique allows the backup to reproduce the exact sequence of monitor acquisitions, while the second replicates thread scheduling decisions. Our results suggest that this is a viable solution for providing transparent fault-tolerance to Java applications.

### References

[1] L. Lamport, “Time, clocks, and the ordering of events in distributed systems,” Communications of the ACM, vol. 21, no. 7, pp. 558–565, July 1978.
[2] F. B. Schneider, “Implementing fault-tolerant services using the state machine approach: A tutorial,” ACM Computing Surveys, vol. 22, no. 4, pp. 299–319, Dec 1990.
[3] T. C. Bressoud and F. B. Schneider, “Hypervisor-based fault tolerance,” in Proceedings of SOSP 15, Dec 1995.
[4] T. Lindholm and F. Yellin, The JavaTM Virtual Machine Specification, 2nd Ed. Addison-Wesley, April 1999.
[5] S. Liang, The JavaTM Native Interface: Programmer’s Guide and Specification. Addison-Wesley, June 1999.
[6] S. Savage et al., “Eraser: A dynamic race detector for multi-threaded programs,” ACM TOCS, vol. 15, no. 4, pp. 391–411, October 1997.
[7] J. H. Slye and E. Elnozahy, “Support for software interrupts in log-based rollback recovery,” IEEE TOCS, vol. 47, no. 10, pp. 1113–1123, October 1998.
[8] P. Chan, R. Lee, and D. Kramer, The Java Class Libraries: 2nd Ed, Vol 1 Supplement for the JavaTM 2 Platform, Std Ed, v1.2. Addison-Wesley, June 1999.
[9] IBM, “Jikes RVM,” 2002. [Online]. Available: http://www.ibm.com/developerworks/oss/jikesrvm/
[10] R. Friedman and A. Kama, “Transparent fault-tolerant JVM,” Department of Computer Science, The Technion, Tech. Rep. CS-2002-19, Dec 2002.
[11] J.-D. Choi, B. Alpern, T. Ngo, M. Sridharan, and J. Vlissides, “A perturbation-free replay platform for cross-optimized multithreaded application,” in Proceedings of IPDPS, 2001.
[12] K. P. Birman, “The process group approach to reliable distributed computing,” Communications of the ACM, vol. 36, no. 12, pp. 37–53, 1993.
[13] J. Bartlett, J. Gray, and B. Horst, “Fault tolerance in tandem computer systems,” in The Evolution of Fault-Tolerant Systems, A. Avizienis, H. Kopetz, and J.-C. Laprie, Eds. Vienna, Austria: Springer-Verlag, 1987, pp. 55–76.
[14] T. C. Bressoud, “TFT: A Software System for Application-Transparent Fault Tolerance,” in Proceedings of FTCS 28, June 1998, pp. 128–137.
[15] J. Napper, L. Alvisi, and H. Vin, “A fault-tolerant java virtual machine,” University of Texas, Dept. of Computer Sciences, Tech. Rep. TR02-56, May 2002.
[16] C. Basile, Z. Kalbarczyk, K. Whisnant, and R. Iyer, “Active replication of multithreaded applications, Tech. Rep. UILU-ENG-02-2201, March 2002.
[17] T. J. LeBlanc and J. M. Mellor-Crummey, “Debugging parallel programs with instant replay,” IEEE Transactions on Computers, vol. C-36, no. 4, pp. 471–482, April 1987.
[18] J. Choi and H. Srinivasa, “Deterministic replay of java multi-threaded applications,” in SIGMETRICS Symposium on Parallel and Distributed Tools, August 1998, pp. 48–59.
[19] A. Goldberg, A. Gopal, K. Li, R. Strom, and D. F. Bacon, “Transparent Recovery of Mach Applications,” in Usenix Mach Workshop, 1990, pp. 169–183.
[20] C. Boyapati and M. Rinard, “A parameterized type system for race-free Java programs,” in Proceedings of OOPSLA, Tampa Bay, FL, October 2001.
[21] G.-I. Cheng et al., “Detecting data races in cilk programs that use locks,” in Proceedings of ACM SPAA, 1998.