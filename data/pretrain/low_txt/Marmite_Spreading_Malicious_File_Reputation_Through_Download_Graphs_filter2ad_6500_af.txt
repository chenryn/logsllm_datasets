### Comparison with Other Systems

The system under discussion performs worse than the full feature set (88% TPR for 2% FPR during the validation phase) but outperforms it when compared to the graph-only features. Several systems aim to detect malicious hosts based on the structural properties of malware delivery networks. Although Marmite's primary goal is to detect malicious files, these approaches share similarities in their operational methods.

- **ARROW by Zhang et al. [41]**: This system detects drive-by download attacks by building a hostname-IP mapping to identify central servers of malware distribution networks (MDNs) and generating corresponding signatures. These signatures are later used to detect malicious webpages.
  
- **Li et al. [20]**: They conducted a large-scale study on the topological relations among hosts in the malicious web infrastructure. The system constructs hostname-IP clusters (HICs) and builds topological relationships between HICs. By observing the higher density of interconnections among malicious infrastructures, a variation of the PageRank algorithm is employed to detect dedicated malicious hosts.

- **WebCop by Stokes et al. [32]**: This bottom-up approach identifies malware distribution sites by using final destination distribution sites as starting points and following web graph hyperlinks in reverse to identify higher-level landing sites. WebCop further utilizes identified landing sites to detect unknown distribution sites that share a landing site with a known malware distribution site.

- **SpiderWeb by Stringhini et al. [35]**: This system builds graphs of HTTP redirections used in malware delivery and performs classifications on these graphs for malware detection.

- **Mekky et al. [22]**: They expanded on the model by considering not only automated redirections but also the links clicked by users.

- **Manadhata et al. [21]**: This approach performs belief propagation over download graphs to detect malicious hosts. It is designed to operate over proxy logs for a single organization, whereas Marmite is designed to operate over the entire Internet.

- **Comparison with Marmite**: Marmite is generic and does not rely on specific network structures or protocols, making it applicable to settings beyond HTTP. It also does not depend on features typical of cybercriminal operations (e.g., Domain Generation Algorithms or Fast Flux), thus being resilient to evasion. In fact, Marmite was shown to efficiently detect malware six months after the system was tuned.

### Conclusion

We presented Marmite, a system capable of detecting malicious files by leveraging a global download graph and label propagation with Bayesian confidence. We demonstrated that the global download graph used by Marmite remains stable over time, allowing the system to detect malware for over six months without re-tuning. Our system can grow the knowledge of malware samples by up to eleven times compared to the initial malicious seeds, and 36% of our detections do not appear on VirusTotal three months after they were detected by Marmite. We provided several case studies to shed light on malware delivery ecosystems, aiming to help the community better understand the idiosyncrasies associated with malware delivery and devise better mitigation systems. Additionally, we showed that building a whitelist of known benign files can be a simple and durable solution to systematic false positives.

### Acknowledgements

We would like to thank the anonymous reviewers for their feedback and Christian Rossow for his assistance in improving the final version of this paper. This work was supported by UCL through a BEAMS Future Leaders in Engineering and Physical Sciences Award and by the EPSRC under grant EP/N008448/1.

### References

[1] National Software Reference Library. http://www.nsrl.nist.gov/.
[2] VirusTotal. https://www.virustotal.com.
[3] Antonakakis, M., Perdisci, R., Nadji, Y., Vasiloglou, N., Abu-Nimeh, S., Lee, W., and Dagon, D. From throw-away traffic to bots: detecting the rise of DGA-based malware. In USENIX Security Symposium (2012).
[4] Bergstra, J., and Bengio, Y. Random Search for Hyper-parameter Optimization. Journal of Machine Learning Research (Feb. 2012).
[5] Caballero, J., Grier, C., Kreibich, C., and Paxson, V. Measuring pay-per-install: the commoditization of malware distribution. In USENIX Security Symposium (2011).
[6] Egele, M., Scholte, T., Kirda, E., and Kruegel, C. A survey on automated dynamic malware-analysis techniques and tools. ACM Computer Surveys 44, 2 (2012).
[7] Fawcett, T. An introduction to ROC analysis. Pattern Recognition Letters 27, 8 (June 2006), 861–874.
[8] Grier, C., Ballard, L., Caballero, J., Chachra, N., Dietrich, C. J., Levchenko, K., Mavrommatis, P., McCoy, D., Nappa, A., Pitsillidis, A., et al. Manufacturing compromise: the emergence of exploit-as-a-service. In ACM conference on Computer and communications security (CCS) (2012).
[9] Holz, T., Gorecki, C., Rieck, K., and Freiling, F. C. Measuring and Detecting Fast-Flux Service Networks. In Network and Distributed Systems Security Symposium (NDSS) (2008).
[10] Invernizzi, L., Comparetti, P. M., Benvenuti, S., Cova, M., Kruegel, C., and Vigna, G. EvilSeed: A Guided Approach to Finding Malicious Web Pages. In IEEE Symposium on Security and Privacy (2012).
[11] Invernizzi, L., Miskovic, S., Torres, R., Kruegel, C., Saha, S., Vigna, G., Lee, S., and Mellia, M. Nazca: Detecting malware distribution in large-scale networks. In Network and Distributed System Security Symposium (NDSS) (2014).
[12] Kapravelos, A., Shoshitaishvili, Y., Cova, M., Kruegel, C., and Vigna, G. Revolver: An automated approach to the detection of evasive web-based malware. In USENIX Security Symposium (2013).
[13] Karampatziakis, N., Stokes, J. W., Thomas, A., and Marinescu, M. Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA). 2013, ch. Using File Relationships in Malware Classification.
[14] Kharraz, A., Robertson, W., Balzarotti, D., Bilge, L., and Kirda, E. Cutting the gordian knot: a look under the hood of ransomware attacks. In Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA) (2015).
[15] Kirat, D., Vigna, G., and Kruegel, C. Barecloud: bare-metal analysis-based evasive malware detection. In USENIX Security Symposium (2014).
[16] Kohavi, R. A study of cross-validation and bootstrap for accuracy estimation and model selection. In IJCAI (1995).
[17] Kotzias, P., Bilge, L., and Caballero, J. Measuring PUP Prevalence and PUP Distribution through Pay-Per-Install Services. In USENIX Security Symposium (2016).
[18] Kruegel, C., Robertson, W., Valeur, F., and Vigna, G. Static disassembly of obfuscated binaries. In USENIX Security Symposium (2004).
[19] Kwon, B. J., Mondal, J., Jang, J., Bilge, L., and Dumitras, T. The dropper effect: Insights into malware distribution with downloader graph analytics. In ACM Conference on Computer and Communications Security (CCS) (2015).
[20] Li, Z., Alrwais, S., Xie, Y., Yu, F., and Wang, X. Finding the linchpins of the dark web: A study on topologically dedicated hosts on malicious web infrastructures. In IEEE Symposium on Security and Privacy (2013).
[21] Manadhata, P. K., Yadav, S., Rao, P., and Horne, W. Detecting malicious domains via graph inference. In European Symposium on Research in Computer Security (ESORICS) (2014).
[22] Mekky, H., Torres, R., Zhang, Z.-L., Saha, S., and Nucci, A. Detecting malicious HTTP redirections using trees of user browsing activity. In INFOCOM (2014).
[23] Nachenberg, C., Wilhelm, J., Wright, A., and Faloutsos, C. Polonium: Tera-scale graph mining and inference for malware detection.
[24] Nelms, T., Perdisci, R., Antonakakis, M., and Ahamad, M. Webwitness: Investigating, categorizing, and mitigating malware download paths. In USENIX Security Symposium (2015).
[25] Nguyen, G. H., Bouzerdoum, A., and Phung, S. L. Learning pattern classification tasks with imbalanced data sets. Tech. rep., 2009.
[26] Pitsillidis, A., Kanich, C., Voelker, G. M., Levchenko, K., and Savage, S. Taster’s choice: A comparative analysis of spam feeds. In ACM Conference on Internet Measurement Conference (IMC) (2012).
[27] Rahbarinia, B., Balduzzi, M., and Perdisci, R. Real-time detection of malware downloads via large-scale URL->file->machine graph mining. In ACM Asia Conference on Computer and Communications Security (ASIACCS) (2016).
[28] Rajab, M. A., Ballard, L., Lutz, N., Mavrommatis, P., and Provos, N. Camp: Content-agnostic malware protection. In Network and Distributed System Security Symposium (NDSS) (2013).
[29] Ramachandran, A., Dagon, D., and Feamster, N. Can DNS-based blacklists keep up with bots? In CEAS (2006).
[30] Rossow, C., Dietrich, C., and Bos, H. Large-scale analysis of malware downloaders. In Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA). 2013.
[31] Song, D., Brumley, D., Yin, H., Caballero, J., Jager, I., Kang, M. G., Liang, Z., Newsome, J., Poosankam, P., and Saxena, P. Bitblaze: A new approach to computer security via binary analysis. In Information systems security. 2008.
[32] Stokes, J. W., Andersen, R., Seifert, C., and Chellapilla, K. Webcop: Locating neighborhoods of malware on the web. In USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET) (2010).
[33] Stone-Gross, B., Cova, M., Cavallaro, L., Gilbert, B., Szydlowski, M., Kemmerer, R., Kruegel, C., and Vigna, G. Your botnet is my botnet: analysis of a botnet takeover. In ACM conference on Computer and communications security (CCS) (2009).
[34] Stone-Gross, B., Holz, T., Stringhini, G., and Vigna, G. The underground economy of spam: A botmaster’s perspective of coordinating large-scale spam campaigns. In Workshop on large-scale exploits and emerging threats (LEET) (2011).
[35] Stringhini, G., Kruegel, C., and Vigna, G. Shady paths: Leveraging surfing crowds to detect malicious web pages. In ACM conference on Computer and communications security (CCS) (2013).
[36] Tamersoy, A., Roundy, K., and Chau, D. H. Guilt by association: Large scale malware detection by mining file-relation graphs. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2014).
[37] Thomas, K., Crespo, J., Picod, J.-M., Phillips, C., Sharp, C., Decoste, M.-A., Tofigh, A., Courteau, M.-A., Ballard, L., Shield, R., Jagpal, N., Abu Rajab, M., Mavrommatis, P., Provos, N., Bursztein, E., and McCoy, D. Investigating Commercial Pay-Per-Install and the Distribution of Unwanted Software. In USENIX Security Symposium (2016).
[38] Vadrevu, P., Rahbarinia, B., Perdisci, R., Li, K., and Antonakakis, M. Measuring and detecting malware downloads in live network traffic. In ESORICS. 2013.
[39] Willems, C., Holz, T., and Freiling, F. Toward automated dynamic malware analysis using cwsandbox. In IEEE Symposium on Security & Privacy (2007).
[40] Yamaguchi, Y., Faloutsos, C., and Kitagawa, H. SocNL: Bayesian Label Propagation with Confidence. PAKDD. 2015.
[41] Zhang, J., Seifert, C., Stokes, J. W., and Lee, W. ARROW: Generating signatures to detect drive-by downloads. In International World Wide Web Conference (WWW) (2011).
[42] Zhu, X., Ghahramani, Z., and Lafferty, J. Semi-supervised learning using Gaussian fields and harmonic functions. In ICML (2003).

### A PUP Operation Case Study

As an additional experiment, we studied PUP binaries as discussed in Section 6.1. We used a download graph from January 3rd for this study. Figure 11 illustrates one such case. The site `balancer1.amber1glue.com` was hosted by three IP addresses during the day. The first two belong to the web hosting company CloudFlare, and the last is from MTS PJSC, registered in Russia. In total, 72 files dropped from this URL were previously identified and confirmed to belong to the Mizenota family (via VirusTotal). Additionally, 811 files are marked as PUP by Symantec. Both the 72 confirmed malicious and 811 newly discovered files share the same naming pattern: ‘string 10924 i il.exe’, e.g., `MS+Office+2010+Crack+Prod 10924 i18078 21319 il2622354.exe`, `Structural+analysis +hibbe 10924 i1807858669 il2 640857.exe`. Another binary (classified as Amonetize) with SHA2 `9A91B...` also dropped five PUP files with the same name but different SHA2s. This case study shows that different PUP-related PPI services, already studied in previous work [17, 37], often share the same delivery infrastructure.

**Figure 11: PUP Case Study Detected by Marmite.**

This case study highlights the blurry line between malware and PUP files. While some files are classified as malware by VirusTotal, others are not and are considered PUP by Symantec. The label propagation performed by Marmite is able to flag all of them as malicious.

```
{…72 confirmed from Mizenota Family
{811 shady binaries
http://balancer1.amber1glue.com/download.php
{5 shady binaries
104.24.98.90
104.24.99.90
192.162.0.103
CloudFlare, Inc. (CLOUD14)
CloudFlare, Inc. (CLOUD14)
MTS PJSC
Amonetize
}
```