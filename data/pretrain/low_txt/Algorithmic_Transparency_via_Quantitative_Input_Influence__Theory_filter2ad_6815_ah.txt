以下是优化后的参考文献列表，使其更加清晰、连贯和专业：

1. [26] D. Pedreschi, S. Ruggieri, and F. Turini, "Discrimination-aware classification: An application to predictive policing," *Fairness, Accountability and Transparency in Machine Learning*, vol. 26, no. 1, pp. 137–141, 2014.
2. [27] C. M. Bishop, *Pattern Recognition and Machine Learning* (Information Science and Statistics). Secaucus, NJ, USA: Springer-Verlag New York, Inc., 2006.
3. [28] S. Barocas and H. Nissenbaum, "Big data's end run around procedural privacy protections," *Communications of the ACM*, vol. 57, no. 11, pp. 31–33, Oct. 2014.
4. [29] T. Calders and S. Verwer, "Three naive Bayes approaches for discrimination-free classification," *Data Mining and Knowledge Discovery*, vol. 21, no. 2, pp. 277–292, 2010. [Online]. Available: http://dx.doi.org/10.1007/s10618-010-0190-x
5. [30] A. Datta, M. Tschantz, and A. Datta, "Automated experiments on ad privacy settings: A tale of opacity, choice, and discrimination," in *Proceedings on Privacy Enhancing Technologies (PoPETs 2015)*, 2015, pp. 92–112.
6. [31] T. Kamishima, S. Akaho, and J. Sakuma, "Fairness-aware learning through regularization approach," in *Proceedings of the 2011 IEEE 11th International Conference on Data Mining Workshops (ICDMW 2011)*, 2011, pp. 643–650.
7. [32] R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork, "Learning fair representations," in *Proceedings of the 30th International Conference on Machine Learning (ICML 2013)*, 2013, pp. 325–333.
8. [33] George Washington University, "Standardized test scores will be optional for GW applicants," 2015. [Online]. Available: https://gwtoday.gwu.edu/standardized-test-scores-will-be-optional-gw-applicants
9. [34] The National Center for Fair and Open Testing, "850+ colleges and universities that do not use SAT/ACT scores to admit substantial numbers of students into bachelor degree programs," 2015. [Online]. Available: http://www.fairtest.org/university/optional
10. [35] D. Janzing, D. Balduzzi, M. Grosse-Wentrup, and B. Schölkopf, "Quantifying causal influences," *Ann. Statist.*, vol. 41, no. 5, pp. 2324–2358, Oct. 2013.
11. [36] I. Guyon and A. Elisseeff, "An introduction to variable and feature selection," *J. Mach. Learn. Res.*, vol. 3, pp. 1157–1182, Mar. 2003. [Online]. Available: http://dl.acm.org/citation.cfm?id=944919.944968
12. [37] L. Breiman, "Random forests," *Mach. Learn.*, vol. 45, no. 1, pp. 5–32, Oct. 2001. [Online]. Available: http://dx.doi.org/10.1023/A:1010933404324
13. [38] J. Pearl, *Causality: Models, Reasoning and Inference*, 2nd ed. New York, NY, USA: Cambridge University Press, 2009.
14. [39] J. Tian and J. Pearl, "Probabilities of causation: Bounds and identification," *Annals of Mathematics and Artificial Intelligence*, vol. 28, no. 1-4, pp. 287–313, 2000.
15. [40] J. Halpern and J. Pearl, "Causes and explanations: A structural-model approach. Part I: Causes," *The British Journal for the Philosophy of Science*, vol. 56, no. 4, pp. 843–887, 2005.
16. [41] H. Chockler and J. Halpern, "Responsibility and blame: A structural-model approach," *Journal of Artificial Intelligence Research*, vol. 22, pp. 93–115, 2004.
17. [42] C. E. Shannon, "A mathematical theory of communication," *Bell System Technical Journal*, vol. 27, no. 3, pp. 379–423, 1948. [Online]. Available: http://dx.doi.org/10.1002/j.1538-7305.1948.tb01338.x
18. [43] A. Rényi, "On measures of entropy and information," in *Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics*. Berkeley, CA, USA: University of California Press, 1961, pp. 547–561. [Online]. Available: http://projecteuclid.org/euclid.bsmsp/1200512181
19. [44] G. Smith, "Quantifying information flow using min-entropy," in *Proceedings of the 8th International Conference on Quantitative Evaluation of Systems (QEST 2011)*, 2011, pp. 159–167.
20. [45] T. M. Cover and J. A. Thomas, *Elements of Information Theory*. John Wiley & Sons, 2012.
21. [46] R. Tibshirani, "Regression shrinkage and selection via the lasso: A retrospective," *Journal of the Royal Statistical Society Series B*, vol. 73, no. 3, pp. 273–282, 2011. [Online]. Available: http://EconPapers.repec.org/RePEc:bla:jorssb:v:73:y:2011:i:3:p:273-282
22. [47] B. Letham, C. Rudin, T. H. McCormick, and D. Madigan, "Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model," *Ann. Appl. Stat.*, vol. 9, no. 3, pp. 1350–1371, Sep. 2015. [Online]. Available: http://dx.doi.org/10.1214/15-AOAS848
23. [48] B. Ustun, S. Trac, and C. Rudin, "Supersparse linear integer models for interpretable classification," *ArXiv e-prints*, 2013. [Online]. Available: http://arxiv.org/pdf/1306.5860v1
24. [49] S. Rüping, "Learning interpretable models." Ph.D. dissertation, Dortmund University of Technology, 2006. [Online]. Available: http://d-nb.info/997491736
25. [50] S. Guha, B. Cheng, and P. Francis, "Challenges in measuring online advertising systems," in *Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement (IMC '10)*. New York, NY, USA: ACM, 2010, pp. 81–87.
26. [51] P. Barford, I. Canadi, D. Krushevskaja, Q. Ma, and S. Muthukrishnan, "Adscape: Harvesting and analyzing online display ads," in *Proceedings of the 23rd International Conference on World Wide Web (WWW '14)*. New York, NY, USA: ACM, 2014, pp. 597–608.
27. [52] M. Lécuyer, G. Ducoffe, F. Lan, A. Papancea, T. Petsios, R. Spahn, A. Chaintreau, and R. Geambasu, "Xray: Enhancing the web's transparency with differential correlation," in *Proceedings of the 23rd USENIX Conference on Security Symposium (SEC'14)*. Berkeley, CA, USA: USENIX Association, 2014, pp. 49–64.
28. [53] A. Datta, M. C. Tschantz, and A. Datta, "Automated experiments on ad privacy settings," *PoPETs*, vol. 2015, no. 1, pp. 92–112, 2015.
29. [54] M. Lécuyer, R. Spahn, Y. Spiliopolous, A. Chaintreau, R. Geambasu, and D. Hsu, "Sunlight: Fine-grained targeting detection at scale with statistical confidence," in *Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (CCS '15)*. New York, NY, USA: ACM, 2015, pp. 554–566.
30. [55] A. Datta, A. Datta, A. Procaccia, and Y. Zick, "Influence in classification via cooperative game theory," in *Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI 2015)*, 2015, pp. 511–517.
31. [56] R. Lindelauf, H. Hamers, and B. Husslage, "Cooperative game theoretic centrality analysis of terrorist networks: The cases of Jemaah Islamiyah and Al Qaeda," *European Journal of Operational Research*, vol. 229, no. 1, pp. 230–238, 2013.
32. [57] T. Michalak, T. Rahwan, P. Szczepanski, O. Skibski, R. Narayanam, M. Wooldridge, and N. Jennings, "Computational analysis of connectivity games with applications to the investigation of terrorist networks," in *Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI 2013)*, 2013, pp. 293–301.
33. [58] M. del Pozo, C. Manuel, E. González-Arangüena, and G. Owen, "Centrality in directed social networks: A game-theoretic approach," *Social Networks*, vol. 33, no. 3, pp. 191–200, 2011.
34. [59] T. Michalak, K. Aaditha, P. Szczepanski, B. Ravindran, and N. Jennings, "Efficient computation of the Shapley value for game-theoretic network centrality," *Journal of Artificial Intelligence Research*, vol. 46, pp. 607–650, 2013.
35. [60] P. Bork, L. Jensen, C. von Mering, A. Ramani, I. Lee, and E. Marcotte, "Protein interaction networks from yeast to human," *Current Opinions in Structural Biology*, vol. 14, no. 3, pp. 292–299, 2004.
36. [61] A. Keinan, B. Sandbank, C. Hilgetag, I. Meilijson, and E. Ruppin, "Fair attribution of functional contribution in artificial and biological networks," *Neural Computation*, vol. 16, no. 9, pp. 1887–1915, Sep. 2004.
37. [62] M. Malawski, "Equal treatment, symmetry and Banzhaf value axiomatizations," *International Journal of Game Theory*, vol. 31, no. 1, pp. 47–67, 2002.

### 附录 A：替代博弈论影响度量

在下文中，我们描述了本文中使用的Shapley值的两种替代方法。Shapley值在我们的设置中具有直观的意义，正如我们在第III-B节中所论证的那样。然而，对于某些输入数据生成过程，其他度量可能更为合适。以下我们将重新讨论在第III-A节中简要提到的Banzhaf指数，并向读者介绍Deegan-Packel指数，这是一种与责任和责备形式理论有深刻联系的博弈论影响度量。

#### A. Banzhaf指数

回顾一下，Banzhaf指数βi(N, v)定义如下：
\[
\beta_i(N, v) = \frac{1}{2^{n-1}} \sum_{S \subseteq N \setminus \{i\}} m_i(S)
\]

Banzhaf指数可以这样理解：每个\( j \in N \setminus \{i\} \)将以概率 \( \frac{1}{2} \) 加入工作努力（或者等价地说，每个 \( S \subseteq N \setminus \{i\} \) 有相等的机会形成）；如果i也加入，则其对形成的集合的期望边际贡献正好是Banzhaf指数。

注意两种概率模型之间的显著差异：在Shapley值下，我们均匀随机地抽取排列，而在Banzhaf指数的体制下，我们均匀随机地抽取集合。不同的抽样协议反映了不同的规范假设。例如，Banzhaf指数不保证效率；即 \( \sum_{i \in N} \beta_i(N, v) \) 不一定等于 \( v(N) \)，而 \( \sum_{i \in N} \phi_i(N, v) = v(N) \) 总是成立的。此外，Banzhaf指数更倾向于测量i对大小为 \( n/2 \pm O(\sqrt{n}) \) 的集合的边际贡献；这是因为随机选择的集合的大小遵循二项分布 \( B(n, \frac{1}{2}) \)。另一方面，Shapley值同样可能测量i对任何大小 \( k \in \{0, \ldots, n-1\} \) 的集合的边际贡献，因为i在随机选择的排列 \( \sigma \) 中的位置是等可能的（特别是i的前驱集合在 \( \sigma \) 中的大小也是等可能的）。

回到QII设置中，采样程序的差异不仅仅是有趣的轶事，而是重要的建模选择。直观上，当假设大型特征集对结果有显著影响时，Banzhaf指数更合适；而当假设即使是小特征集也可能对结果产生显著影响时，Shapley值更合适。确实，如我们在第VIII节中提到的，聚合i在集合上的边际影响是一个重要的建模选择；虽然使用这里提出的度量在许多设置中是合理的，但在其他情况下可能适用其他聚合方法。

与Shapley值不同，Banzhaf指数不保证效率（尽管它满足对称性和虚拟玩家性质）。事实上，[62]表明，用另一种公理替换效率公理唯一地刻画了Banzhaf指数；该公理称为2-效率，规定了两个玩家合并时的影响度量行为。首先，让我们定义一个合并游戏；给定一个游戏 \( (N, v) \) 和两个玩家 \( i, j \in N \)，我们写 \( T = \{i, j\} \)。我们定义游戏 \( \bar{v} \) 在 \( N \setminus T \cup \{\bar{t}\} \) 上如下：对于每个集合 \( S \subseteq N \setminus \{i, j\} \)，\( \bar{v}(S) = v(S) \)，且 \( \bar{v}(S \cup \{\bar{t}\}) = v(S \cup \{i, j\}) \)，注意添加的玩家 \( \bar{t} \) 代表现在作为一个整体行动的两个玩家 \( i \) 和 \( j \)。2-效率公理规定影响应该在合并下不变。

**定义14（2-效率（2-EFF））**：给定两个玩家 \( i, j \in N \)，令 \( \bar{v} \) 是由 \( i \) 和 \( j \) 合并成一个单一玩家 \( \bar{t} \) 的游戏；一个影响度量 \( \varphi \) 满足2-效率，如果 \( \varphi_i(N, v) + \varphi_j(N, v) = \varphi_{\bar{t}}(N \setminus \{i, j\} \cup \{\bar{t}\}, \bar{v}) \)。

**定理15 ([62])**：Banzhaf指数是唯一满足（Sym）、（D）、（Mono）和（2-EFF）的函数。

在我们的上下文中，2-效率可以解释如下：假设我们将两个特征 \( i \) 和 \( j \) 人为地视为一个，保持所有其他参数不变；在这种设置下，2-效率意味着合并特征的影响等于它们作为单独实体时的影响。

#### B. Deegan-Packel指数

最后，我们讨论Deegan-Packel指数[18]。虽然Shapley值和Banzhaf指数适用于任何合作博弈，但Deegan-Packel指数仅适用于简单博弈。一个合作博弈被称为简单的，如果对于所有 \( S \subseteq N \)，\( v(S) \in \{0, 1\} \)。在我们的设置中，一个影响度量对应于一个简单的博弈，如果它是二元的（例如，它测量某种阈值行为或对应于一个二元分类器）。二元要求相当严格；然而，我们希望引起读者对Deegan-Packel指数的关注，因为它与因果责任[41]有有趣的联系，这是经典的Pearl-Halpern因果模型[40]的一个变体，旨在衡量单个变量对结果的因果程度。

给定一个简单的博弈 \( v : 2^N \rightarrow \{0, 1\} \)，令 \( M(v) \) 为最小获胜联盟的集合；即对于每个 \( S \in M(v) \)，\( v(S) = 1 \)，且对于 \( S \) 的每个真子集 \( T \)，\( v(T) = 0 \)。Deegan-Packel指数分配的值为：
\[
\delta_i(N, v) = \frac{1}{|M(v)|} \sum_{S \in M(v): i \in S} \frac{1}{|S|}
\]

Deegan-Packel指数背后的直觉是：玩家不会形成比他们必须获胜所需的更大的联盟，因此测量非最小获胜联盟的效果是没有意义的。此外，当形成一个最小获胜联盟时，从其形成中获得的好处在成员之间平均分配；特别是，小联盟为其成员提供的好处大于大联盟。Deegan-Packel指数测量的是假设每个最小获胜联盟等可能形成时，一个人预期收到的支付。

有趣的是，Deegan-Packel指数很好地对应于[41]中描述的责任和责备概念。

假设我们有一组变量 \( X_1, \ldots, X_n \) 设置为 \( x_1, \ldots, x_n \)，并且某个二元效应 \( f(x_1, \ldots, x_n) \)（记作 \( f(x) \)）发生（比如 \( f(x) = 1 \)）。为了建立 \( X_i \) 设置为 \( x_i \) 与 \( f(x) = 1 \) 之间的因果关系，[40] 要求存在某个集合 \( S \subseteq N \setminus \{i\} \) 和一些值 \( (y_j)_{j \in S \cup \{i\}} \) 使得 \( f(x - S \cup \{i\}, (y_j)_{j \in S \cup \{i\}}) = 0 \)，但 \( f(x - S, (y_j)_{j \in S}) = 1 \)。换句话说，对 \( S \) 和 \( i \) 的值进行干预可能导致 \( f \) 值的变化，但仅对 \( S \) 中的变量进行相同的干预则不会导致这种变化。这个定义是我们第三节A部分描述的干预边际贡献方法的核心。[41] 定义 \( i \) 对结果的责任为 \( \frac{1}{k+1} \)，其中 \( k \) 是满足上述因果定义的最小集合 \( S \) 的大小。Deegan-Packel指数可以被认为是在测量类似的概念：不是取使 \( i \) 成为直接反事实原因所需的整体最小变化数，而是观察所有这样的最小集合。取 \( i \) 根据这个变体的平均责任（[41] 称之为责备），我们得到Deegan-Packel指数。

**示例16**：让我们检查以下基于[41]中的示例3.3的设置。有 \( n = 2k + 1 \) 名选民（\( n \) 是奇数），他们必须在两位候选人Mr. B和Mr. G之间做出选择（[41] 描述了 \( n = 11 \) 的情况）。所有选民都选择了Mr. B，结果是 \( n-0 \) 胜利。很自然地问：选民 \( i \) 对Mr. B的胜利有多大的责任？

根据[41]，每个选民的责任度是 \( \frac{1}{k+1} \)。这需要 \( i \) 和另外 \( k \) 名选民改变他们的投票以改变结果。将此设置建模为一个合作博弈是很自然的：选民是玩家 \( N = \{1, \ldots, n\} \)；对于每个子集 \( S \subseteq N \)，我们有
\[
v(S) = 
\begin{cases}
1 & \text{如果 } |S| \geq k + 1 \\
0 & \text{否则}
\end{cases}
\]
也就是说，\( v(S) = 1 \) 当且仅当集合 \( S \) 可以改变选举的结果。这里的最小获胜联盟是 \( N \) 的大小为 \( k + 1 \) 的子集，因此玩家 \( i \) 的Deegan-Packel指数是
\[
\delta_i(N, v) = \frac{1}{|M(v)|} \sum_{S \in M(v): i \in S} \frac{1}{|S|} = \frac{1}{\binom{n}{k+1}} \cdot \binom{n-1}{k} \cdot \frac{1}{k+1} = \frac{1}{k+1}
\]

我们注意到，如果假设所有选民都喜欢Mr. B而不是Mr. G的可能性相同，那么选民 \( i \) 的责备将与Deegan-Packel指数完全相同地计算。