### Avoiding Code Coverage Issues with Static Analysis

We chose static analysis to avoid the code coverage issues inherent in runtime analysis and to achieve faster processing (end-to-end processing takes several minutes per application). In this section, we discuss some of the limitations of our current static analysis approach.

#### Potential Sources of Errors

Our analysis may introduce two types of errors:

1. **False Positives**: The analysis may classify a resource access as unprotected when it is actually protected by runtime prompts.
2. **False Negatives**: The analysis may classify a resource access as protected when, in fact, there are no preceding prompts that protect the resource access at runtime.

### Manual Inspection

To manually check for these errors, we examined a subset of applications. The verification process included running the applications in an emulator to collect network packets and API calls invoked at runtime. We exercised as much functionality as possible and inspected the text of any runtime prompts, clicking through "allow" and "don't allow" buttons to determine their impact on application behavior. After the runtime inspection, we correlated the collected data with the app's disassembled code to verify the observed behavior.

Although thorough, this verification process is labor-intensive, limiting the number of cases we can examine. Our findings from 10 applications, which contain 27 resource access points (21 classified as unprotected by our analysis), are discussed below.

### False Negatives

Our manual analysis found no false negatives. Upon close examination of the 27 resource accesses, we identified 10 accesses that were not protected. Our analysis correctly classified all of these as unprotected and suggested appropriate prompt placements. These unprotected accesses were found in third-party libraries included in five applications. One application, in an effort to maximize revenue, embedded two advertising-related third-party libraries (SOMAWP7.dll and AdRotatorXNA.dll), both of which contained unprotected location accesses. Two placements were made via dominator-based placement, and the other eight through backward placement, resulting in 40 inserted prompts in the application code. These results are promising, as users increasingly express concerns about data sharing with third parties [21].

### False Positives

Eleven out of the 21 accesses flagged as unprotected were actually properly protected. Although the number of false positives is high, our manual inspection revealed the following reasons:

1. **Sticky Location Prompts**: Seven false positives were due to our analysis's inability to handle sticky location prompts. Three cases were similar to the example in Figure 5, while the rest were caused by an application using the location flag to enable or disable a button that allows the user to navigate to a page invoking location access (Figure 18(b)). We are exploring ways to detect such storage mechanisms statically.

2. **Custom Consent Dialogs**: Two false positives resulted from the limitation of identifying existing prompts. Both were from a single application that implemented a custom consent dialog page instead of using MessageBox() (Figure 19). We are investigating methods to parse blocking pages with buttons to detect such custom-made consent dialog pages, although this is a challenging problem. However, such cases are not common, and five out of six applications that show prompts use MessageBox().

3. **Async Calls and XAML Files**: Two false positives were due to limitations in call graph construction. Applications may use multiple types of EventHandlers called asynchronously. In our current implementation, we parse EventHandlers and add links when handlers are registered. However, the current implementation fails when multiple delegates and EventHandlers are used in complex ways (Figure 20(b)). We are working on extending our call graph construction to support these cases.

### Impact of False Positives

Like most practical static analysis tools, our analysis is potentially vulnerable to false positives, primarily due to challenges in program representation. Unlike most static analysis tools for bug detection, our analysis is two-phase: if it detects that a resource access is not adequately protected, it proposes a prompt placement. Our analysis errs on the safe side, introducing false positives rather than false negatives. False positives may lead to double-prompting, as our analysis will inject a prompt to protect already protected resource accesses. However, because our inserted prompts are sticky, our approach introduces at most one extra runtime prompt per app during its entire lifecycle, which we believe will not lead to prompt fatigue. Nonetheless, double-prompting can confuse end-users and should be minimized. Our experience with the ten test applications shows that resource accesses are typically triggered quickly, with several clicks, so runtime checking of this kind is unlikely to require excessive effort. If desired, runtime testing by developers or App Store maintainers can accompany our analysis to detect and eliminate potential double-prompting.

### Related Work

The requirement to protect privacy-sensitive resource accesses with runtime prompts or consent dialogs has only recently been introduced to mobile applications. To our knowledge, no previous work has investigated static analysis approaches to detect unprotected resource accesses in mobile application binaries. This section discusses previous research in three related areas: automatic hook placement, graph-based analysis for information security, and user studies of consent dialogs.

#### Automatic Hook Placement

Several previous studies have examined the issues of protecting security-sensitive operations with authorization hooks. Ganapathy et al. [14] use static program analysis over the Linux kernel source code to identify previously unspecified sensitive operations and find the right set of hooks to protect them. AutoISES by Tan et al. [34] aims for a similar goal but uses different methods to infer access to sensitive data structures. Muthukumaran et al. [27] focus on server code, such as the X server and PostgreSQL, and use insights into object access patterns to identify sensitive operations requiring authorization.

In comparison, our work starts with a known set of APIs that access sensitive resources, which is easy to mine from developer documentation for most mobile operating systems. Our work focuses on algorithms to find placements that meet four important conditions specific to user prompts on mobile devices, whereas previous work concentrates on ensuring safety [14, 34] or safety and non-repetition [27].

#### Graph-Based Analysis

Program dependence graphs are used in several projects to analyze information security [16, 17, 32]. Program dependence graphs include both data and control dependencies, while the data flow graphs we use typically contain just data dependencies. Hammer et al. [15] consider the enforcement of declassification [30] using program dependence graphs. Recent efforts focus on automating security-critical decisions for application developers [31, 36]. The use of a security type system for enforcing correctness is another way to cooperate with developers to achieve better code quality and correctness guarantees [29]. Livshits and Chong [25] address the problem of sanitizer placement through static analysis, partially inspiring our work on consent dialog placement. In our work, we use a backward traversal to find the closest valid node to insert a missing prompt. Au et al. [5] use a similar backward reachability analysis over a call graph constructed from the Android framework, but their goal is to create a mapping between API calls and permission checks, so they do not consider the four conditions.

#### Mobile User Privacy and Consent Dialogs

Several recent studies have investigated the effectiveness of existing consent dialogs used on mobile devices to inform users about privacy-sensitive data access. Felt et al. [12] show that only 17% of study participants paid attention to permissions when installing Android applications, indicating that placing consent dialogs at install time (far removed from when the data is accessed) renders these dialogs ineffective. On the contrary, a study by Fisher et al. [13] focused on iPhone users' responses to runtime consent dialogs for location access and found that 85% of participants denied location requests for at least one app.

Although orthogonal to our work, previous studies have explored ways to improve the presentation of consent dialogs. Lin et al. [23] measure users' expectations of apps' access to phone resources and show that highlighting unexpected behaviors in the Android permissions interface makes it more easily understood and efficient. Felt et al. [11] propose a framework for requesting permissions on smartphones. These studies can inform better usable privacy design for consent dialogs, which our analysis can automatically insert in mobile apps.

### Conclusions

In this paper, we explored the problem of missing prompts that should guard sensitive resource accesses. Our core contribution is a graph-theoretic algorithm for automatically placing such prompts. The approach balances execution speed and few prompts inserted via dominator-based placement with the comprehensive nature of a more exhaustive backward analysis. Our two-prong strategy of dominator-based and backward placement succeeds in about 95% of all unique cases. Our approach is highly scalable; once the application is represented as a graph, analysis usually takes under a second on average.

### References

[1] Pandora discloses privacy-related US inquiry into phone apps. http://www.nytimes.com/2011/04/05/technology/05pandora.html, April 2011.

[2] Daily report: Social app makes off with address books. http://bits.blogs.nytimes.com/2012/02/08/daily-report-social-app-makes-off-with-address-books/, February 2012.

[3] LinkedIn’s iOS app collects and transmits names, emails, and notes in plain text. http://thenextweb.com/insider/2012/06/06/linkedins-ios-app-collects-and-sends-names-emails-and-meeting-notes-from-your-calendar-back-in-plain-text/, June 2012.

[4] A. V. Aho, M. Lam, R. Sethi, and J. D. Ullman. Compilers: Principles, Techniques, and Tools. Addison-Wesley, 2007.

[5] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie. Pscout: analyzing the Android permission specification. In ACM CCS, 2012.

[6] E. Bodden, A. Sewe, J. Sinschek, H. Oueslati, and M. Mezini. Taming reflection: Aiding static analysis in the presence of reflection and custom class loaders. In Software Engineering (ICSE), 2011 33rd International Conference on, pages 241–250, 2011.

[7] R. Böhm and S. Kopsell. Trained to accept?: a field experiment on consent dialogs. In Proceedings of CHI, 2010.

[8] A. S. Christensen, A. Møller, and M. Schwartzbach. Precise analysis of string expressions. In International Conference on Static analysis, 2003.

[9] M. Egele, C. Kruegel, E. Kirda, and G. Vigna. PiOS: Detecting privacy leaks in iOS applications. In Proceedings of the Annual Network and Distributed System Security Symposium, Feb. 2011.

[10] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N. Sheth. TaintDroid: an information-flow tracking system for real-time privacy monitoring on smartphones. In Proceedings of the Usenix Conference on Operating Systems Design and Implementation, 2010.

[11] A. P. Felt, S. Egelman, M. Finifter, D. Akhawe, and D. Wagner. How to ask for permission. In Proceedings of HotSec, 2012.

[12] A. P. Felt, E. Hay, S. Egelman, A. Haney, E. Chin, and D. Wagner. Android permissions: User attention, comprehension, and behavior. In Proceedings of SOUPS, 2012.

[26] B. Livshits, J. Whaley, and M. S. Lam. Reflection analysis for Java. In Asian Symposium on Programming Languages and Systems, Nov. 2005.

[27] D. Muthukumaran, T. Jaeger, and V. Ganapathy. Leveraging “choice” to automate authorization hook placement. In ACM CCS, 2012.

[28] G. Richards, S. Lebresne, B. Burg, and J. Vitek. An analysis of the dynamic behavior of JavaScript programs. In ACM Sigplan Notices, volume 45, pages 1–12. ACM, 2010.

[29] W. Robertson and G. Vigna. Static enforcement of Web application integrity through strong typing. In Proceedings of the Usenix Security Symposium, Aug. 2009.

[30] A. Sabelfeld and D. Sands. Dimensions and principles of declassification. In Proceedings of the 18th IEEE Computer Security Foundations Workshop, pages 255–269. IEEE Computer Society, June 2005.

[31] M. Samuel, P. Saxena, and D. Song. Context-sensitive autosanitization in web templating languages using type qualifiers. In Proceedings of the Conference on Computer and Communications Security, Oct. 2011.

[13] D. Fisher, L. Dorner, and D. Wagner. Short paper: Location privacy: user behavior in the field. In Proceedings of SPSM, 2012.

[32] B. Scholz, C. Zhang, and C. Cifuentes. User-input dependence analysis via graph reachability. Technical Report 2008-171, Sun Microsystems Labs, 2008.

[14] V. Ganapathy, T. Jaeger, and S. Jha. Automatic placement of authorization hooks in the Linux security modules framework. In ACM CCS, 2005.

[15] C. Hammer, J. Krinke, and F. Nodes. Intransitive noninterference in dependence graphs. In 2nd International Symposium on Leveraging Application of Formal Methods, Verification and Validation, Nov. 2006.

[16] C. Hammer, J. Krinke, and G. Snelting. Information flow control for Java based on path conditions in dependence graphs. In IEEE International Symposium on Secure Software Engineering, Mar. 2006.

[17] C. Hammer and G. Snelting. Flow-sensitive, context-sensitive, and object-sensitive information flow control based on program dependence graphs. International Journal of Information Security, 8(6):399–422, Dec. 2009.

[18] M. Hirzel, D. von Dincklage, A. Diwan, and M. Hind. Fast online pointer analysis. ACM Trans. Program. Lang. Syst., 29(2), 2007.

[19] P. Hooimeijer and M. Veanes. An evaluation of automata algorithms for string analysis. In Verification, Model Checking, and Abstract Interpretation, pages 248–262. Springer, 2011.

[33] D. Shannon, S. Hajra, A. Lee, D. Zhan, and S. Khurshid. Abstracting symbolic execution with string analysis. In Testing: Academic and Industrial Conference Practice and Research Techniques-MUTATION, 2007. TAICPART-MUTATION 2007, pages 13–22, 2007.

[34] L. Tan, X. Zhang, X. Ma, W. Xiong, and Y. Zhou. AutoISES: Automatically inferring security specification and detecting violations. In USENIX Security Symposium, 2008.

[35] O. Tripp, M. Pistoia, S. J. Fink, M. Sridharan, and O. Weisman. TAJ: Effective taint analysis of Web applications. In Proceedings of the Conference on Programming Language Design and Implementation, 2009.

[36] J. Weinberger, P. Saxena, D. Akhawe, M. Finifter, R. Shin, and D. Song. A systematic analysis of XSS sanitization in Web application frameworks. In Proceedings of the European Symposium on Research in Computer Security, Sept. 2011.

[20] Pew Internet. Privacy and data management on mobile devices. http://pewinternet.org/Reports/2012/Mobile-Privacy.aspx, September 2012.

[21] J. Jung, S. Han, and D. Wetherall. Short paper: Enhancing mobile application permissions with runtime feedback and constraints. In Proceedings of SPSM, 2012.

[22] S. Kaplan, B. Livshits, B. Zorn, C. Seifert, and C. Curtsinger. “nofus: Automatically detecting” + string.fromcharcode(32) + “obfuscated ”.tolowercase() + “JavaScript code”. Technical Report MSR-TR-2011-57, Microsoft Research, May 2011.

[23] J. Lin, S. Amini, J. Hong, N. Sadeh, J. Lindqvist, and J. Zhang. Expectation and purpose: Understanding users’ mental models of mobile app privacy through crowdsourcing. In Proceedings of UbiComp 2012, 2012.

[24] B. Livshits. Dynamic taint tracking in managed runtimes. Technical Report MSR-TR-2012-114, Microsoft Research, 2012.

[25] B. Livshits and S. Chong. Towards fully automatic placement of security sanitizers and declassifiers. In Proceedings of the Symposium on Principles of Programming Languages (POPL), Jan. 2013.

USENIX Association  
22nd USENIX Security Symposium  129