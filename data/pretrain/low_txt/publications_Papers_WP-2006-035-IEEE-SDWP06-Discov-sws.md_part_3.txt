# Mapping and Evaluation of Conceptual Properties

The mapping function `ss("WrittenLanguages", "Written_Lang")` is set to 1. The projection Π, defined as:
\[ \Pi(p(\text{SecretaryRecord}), p(\text{EmployeeR})) \]
is not part of the overall Π since `ss("Name", i, 3)` is equivalent to:
\[ \Pi(\{\text{Salary, Degree, Competencies, ComputerSkills}\}) \]
which evaluates to zero. Other mappings are also not part of Π. For instance, computing `ss("SpokenLanguages", "Written_Lang")` results in 0 (with a function g value of 0.13), indicating that the properties are not syntactically equal.

The possible mappings are:
- \[ \Pi_1: (\text{SpokenLanguages, Spoken_Lang}) \]
- \[ \Pi_2: (\text{WrittenLanguages, Written_Lang}) \]
- \[ \Pi_3: (\text{Name, ComputerSkills}) \]

The function Π establishes the best mapping between two sets of properties and is defined as:
\[ \prod(p_{l1}, p_{l2}) = \max\left( \prod(p_{l1} - p, p_{l2} - p) + ss(p, p), ss(p, p) = 1 \right) \]
where \( p_{l1} \neq \emptyset \) and \( p_{l2} \neq \emptyset \).

If \( p_{l1} = \emptyset \) or \( p_{l2} = \emptyset \), then:
\[ \prod(p_{l1} - p, p_{l2} - p) = 0 \]

## Ranking Algorithm

In this section, we present the ranking algorithm for Web service advertisements, based on the previously introduced functions. The algorithm evaluates the structural similarity between two concepts, where a concept in an ontology is typically defined by its properties, superclasses, and subclasses. Since concept labels can be arbitrary, examining the structure of a concept description provides deeper insight into its semantics.

In WSAF, the XML representation of WSDL is matched against the concepts of a given ontology. The best match between WSDL and ontological concepts is returned as a suggestion for potential mappings. Our work matches ontological concepts with other ontological concepts, which differs from previous work [10] due to the lack of empirical testing and validation of weight values, and the undefined weights for ElemMatch and SchemaMatch values.

### Algorithm Steps

1. **Determine Ontology**: Use the function `same_ontology` to check if two concepts are defined in the same ontology.
2. **Calculate Match Degree**: Compute the matching degree for the input and output between a Web service request and a Web service advertisement.
3. **Overall Match Degree**: Define the overall match degree as the arithmetic mean of the input and output match degrees.

```python
for j in range(len(ADV)):
    if same_ontology(c_i, c_ji):
        i = S_i(c_i, c_ji)
    else:
        i = S_neq(c_i, c_ji)
    
    if same_ontology(c_o, c_jo):
        o = S_o(c_o, c_jo)
    else:
        o = S_neq(c_o, c_jo)
    
    match[j] = (i + o) / 2

match.sort()
```

## Related Work

### OWL-S/UDDI Matchmaker

The OWL-S/UDDI Matchmaker [28] introduces semantic search into the UDDI directory by embedding an OWL-S Profile in a UDDI data structure and augmenting the UDDI registry with an OWL-S matchmaking component. The matching algorithm recognizes four degrees of match: exact, plug-in, subsume, and fail. Unlike our approach, it limits the classification of the accuracy of matching using a continuous function with a range of [0, 1]. Our algorithm allows the matching of semantic Web services with and without a common ontology commitment, which is more realistic.

### METEOR-S WSAF

The METEOR-S [10] Web Service Annotation Framework (WSAF) semi-automatically matches WSDL concepts to DAML and RDF ontologies using text-based information retrieval techniques. The strength of matches (SM) is calculated using a scoring formula involving element (ElemMatch) and structure level schema (SchemaMatch) matching. The ElemMatch function performs element-level matching based on linguistic similarity, while the SchemaMatch function handles structure-level matching.

## Conclusions

This paper presents a semantic matching algorithm for use in UDDI registries enhanced with semantics. The algorithm works with Web services described in WSMO and OWL-S or annotated with WSDL-S. Compared to previous work, our approach does not limit the classification of matching accuracy and allows for the matching of services with and without a common ontology commitment. This is important as it is unrealistic to assume that all Web services will be defined by the same ontology.

## References

1. Cardoso, J. and A.P. Sheth, Introduction to Semantic Web Services and Web Process Composition, in Semantic Web Process: powering next generation of processes with Semantics and Web services, J. Cardoso and A.P. Sheth, Editors. 2005, Springer-Verlag: Heidelberg, Germany. p. 1-13.
2. Cardoso, J. and A. Sheth, Semantic e-Workflow Composition. Journal of Intelligent Information Systems (JIIS). 2003. 21(3): p. 191-225.
3. Verma, K., et al., METEOR-S WSDI: A Scalable Infrastructure of Registries for Semantic Publication and Discovery of Web Services. Journal of Information Technology and Management (in print), 2004.
4. UDDI, Universal Description, Discovery, and Integration. 2002.
5. Sheth, A. and R. Meersman, Amicalola Report: Database and Information Systems Research Challenges and Opportunities in Semantic Web and Enterprises. SIGMOD Record, 2002. 31(4): p. pp. 98-106.
6. Rodríguez, A. and M. Egenhofer, Determining Semantic Similarity Among Entity Classes from Different Ontologies. IEEE Transactions on Knowledge and Data Engineering (in press). 2002.
7. Smeaton, A. and I. Quigley. Experiment on Using Semantic Distance Between Words in Image Caption Retrieval. in 19th International Conference on Research and Development in Information Retrieval SIGIR'96. 1996. Zurich, Switzerland.
8. Klein, M. and A. Bernstein. Searching for Services on the Semantic Web Using Process Ontologies. in International Semantic Web Working Symposium (SWWS). 2001. Stanford University, California, USA.
9. Cardoso, J., et al., Academic and Industrial Research: Do their Approaches Differ in Adding Semantics to Web Services, in Semantic Web Process: powering next generation of processes with Semantics and Web services, J. Cardoso and S. A., Editors. 2005, Springer-Verlag: Heidelberg, Germany. p. 14-21.
10. Patil, A., et al. MWSAF - METEOR-S Web Service Annotation Framework. in 13th Conference on World Wide Web. 2004. New York City, USA.
11. Fensel, D. and C. Bussler, The Web Service Modeling Framework WSMF. Electronic Commerce Research and Applications, 2002. 1(2): p. 113-137.
12. Zavaracky, A., Glossary-Based Semantic Similarity in the WordNet Ontology, in Department of Computer Science. 2003, University College Dublin: Dublin.
13. Wu, Z. and M. Palmer. Verb Semantics and Lexical Selection. in 32nd Annual Meeting of the Associations for Computational Linguistics (ACL'94). 1994. Las Cruces, New Mexico.
14. Rada, R., et al., Development and Application of a Metric on Semantic Nets. IEEE Transactions on Systems, Man, and Cybernetics, 1989. 19(1): p. 17-30.
15. Leacock, C. and M. Chodorow, Combining local context and WordNet similarity for word sense identification, in WordNet: An Electronic Lexical Database, C. Fellbaum, Editor. 1998, MIT Press. p. 265-283.
16. Turney, P.D. Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL. in 12th European Conference on Machine Learning. 2001: Springer-Verlag.
17. Keller, F. and M. Lapata, Using the Web to Obtain Frequencies for Unseen Bigrams. Computational Linguistics, 2003.
18. Church, K.W. and P. Hanks. Word association norms, mutual information, and Lexicography. in 27th. Annual Meeting of the Association for Computational Linguistics. 1989. Vancouver, B.C.: Association for Computational Linguistics.
19. Lin, D. An information-theoretic definition of similarity. in 15th International Conf. on Machine Learning. 1989. San Francisco, CA: Morgan Kaufmann.
20. Tversky, A., Features of Similarity. Psychological Review, 1977. 84(4): p. 327-352.
21. Resnik, P. Using Information Content to Evaluate Semantic Similarity in a Taxonomy. in 14th International Joint Conference on Artificial Intelligence. 1995.
22. Jiang, J. and D. Conrath. Semantic Similarity Based on Corpus Statistics and Lexical Taxonomy. in Intemational Conference on Computational Linguistics (ROCLINGX). 1997. Taiwan.
23. Lesk, M. Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone. in 5th annual international conference on Systems documentation. 1986: ACM Press.
24. Banerjee, S. and T. Pedersen. Gloss Overlaps as a Measure of Semantic Relatedness. in Eighteenth International Joint Conference on Artificial Intelligence. 2003. Acapulco, Mexico.
25. Richardson, R. and A. Smeaton, Using WordNet in a Knowledge-Based Approach to Information Retrieval. 1995, Dublin City University, School of Computer Applications: Dublin, Ireland.
26. Belew, R.K., Finding Out About : A Cognitive Perspective on Search Engine Technology and the WWW. 2000, Cambridge, U.K: Cambridge University Press. 356.
27. Salton, G., Automatic Text Processing: The Transformation, Analysis and Retrieval of Information by Computer. 1988, Massachusetts: Addison-Wesley.
28. Srinivasan, N., M. Paolucci, and K. Sycara, An efficient algorithm for OWL-S based semantic search in UDDI, J. Cardoso and A. Sheth, Editors. 2005, Lecture Notes in Computer Science, Springer.