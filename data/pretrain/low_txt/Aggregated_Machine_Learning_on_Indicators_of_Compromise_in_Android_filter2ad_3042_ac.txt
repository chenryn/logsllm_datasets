### MAVeRiC: A Framework for Detecting Malicious Applications on Android Devices

#### Introduction
The proliferation of mobile computing platforms, along with the necessary applications and content to make them useful, continues to accelerate. One of the most significant challenges is the potential security risks and vulnerabilities in mobile applications. This paper introduces MAVeRiC, a new conceptual technology aimed at enhancing security for Android mobile applications. MAVeRiC leverages crowd-sourced behavioral analysis and machine learning to determine if an application is malicious, and it continuously monitors the application post-installation without impacting performance or user experience.

#### Methodology

##### Data Collection and Classification
MAVeRiC collects data from both benign and malicious applications to establish a baseline for known malicious behavior. The collected data is then processed through various classification algorithms, including decision trees, support-vector machines, nearest neighbor, and Naïve Bayes. Initially, all data is evaluated using MATLAB, which provides pre-built functions for these tests. Each method is assessed based on its accuracy, speed, and resource utilization.

##### Unsupervised Learning
For unsupervised learning, MAVeRiC employs clustering and anomaly detection techniques. The methods include k-means clustering, hierarchical clustering, and anomaly detection algorithms. In both clustering and anomaly detection, the center of the clusters serves as the reference point. A threshold is set to represent the distance from this center. Any points outside this threshold are flagged as potentially malicious.

##### Supervised Learning
In the second approach, each Indicator of Compromise (IOC) is analyzed individually. MAVeRiC follows the same steps as in the first approach but performs feature selection reduction on individual IOCs, as they may differ from the superset chosen initially. Once a set of features is selected, the data is input into a series of supervised machine learning algorithms to train the model.

##### Evaluation and Integration
We expect MAVeRiC's dynamic analysis approach to reduce both false positives and false negatives when multiple IOCs are analyzed. After evaluating all approaches, we will determine the best method based on accuracy, speed, data collection requirements, and resource utilization on Android devices. MAVeRiC will integrate the selected approach by deploying data collection applications on Android devices and servers to manage and evaluate the data. Additionally, MAVeRiC will develop a method to introduce additional IOCs in the future.

#### Conclusion and Future Work
The increasing use of mobile computing platforms has led to new trends, such as "Bring Your Own Device" (BYOD), which allows organizations to benefit from the distributed computing and communication capabilities of their employees' devices. However, this trend also introduces new security challenges, including new attack vectors for malware. MAVeRiC aims to address these challenges by providing a robust framework for identifying and monitoring malicious applications.

Future work includes conducting larger-scale experiments and demonstrations to assess scalability and usability. We will also test a more diverse suite of malware, including both legacy and current threats. Collaboration with industry and academia will be essential to fulfill MAVeRiC's goals.

#### References
1. Kernel space. Available at http://www.linfo.org/kernel_space.html (05 April, 2018), 2005.
2. Skygofree — a hollywood-style mobile spy. Available at https://www.kaspersky.com/blog/skygofree-smart-trojan/20717/ (06 April, 2018), 2018.
3. T. Bower. 1.12. system calls — operating systems study guide. Available at http://faculty.salina.k-state.edu/tim/ossg/Introduction/sys_calls.html (05 April, 2018), 2015.
4. I. Burguera, U. Zurutuza, and S. Nadjm-Tehrani. Crowdroid: behavior-based malware detection system for android. In Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices, pages 15–26. ACM, 2011.
5. G. Canfora, E. Medvet, F. Mercaldo, and C. A. Visaggio. Detecting android malware using sequences of system calls. In Proceedings of the 3rd International Workshop on Software Development Lifecycle for Mobile, pages 13–20. ACM, 2015.
6. L. Caviglione, M. Gaggero, J.-F. Lalande, W. Mazurczyk, and M. Urban´ski. Seeing the unseen: revealing mobile malware hidden communications via energy consumption and artificial intelligence. IEEE Transactions on Information Forensics and Security, 11(4):799–810, 2016.
7. D. Dasgupta, A. Roy, and D. Ghosh. Multi-user permission strategy to access sensitive information. Information Sciences, 423:24–49, 2018.
8. T. Fox-Brewster. Google is fighting a massive android malware outbreak — up to 21 million victims, 2017.
9. A. Ghosh, P. K. Gajar, and S. Rai. Bring your own device (BYOD): Security risks and mitigating strategies. International Journal of Global Research in Computer Science (UGC Approved Journal), 4(4):62–70, 2013.
10. K. Giotopoulos, C. Halkiopoulos, D. Papadopoulos, and H. Antonopoulou. Adoption of bring your own device (BYOD) policy in marketing. In 5th International Conference on Contemporary Marketing Issues ICCMI June 21-23, 2017 Thessaloniki, Greece, page 342, 2017.
11. R. A. Hallman and M. Kline. Risk metrics for android (trademark) devices. Technical report, Space and Naval Warfare Systems Center Pacific San Diego United States, 2017.
12. J. Hsu. The strava heat map and the end of secrets. Available at https://www.wired.com/story/strava-heat-map-military-bases-fitness-trackers-privacy/(19 April, 2018), 2018.
13. U. Kanonov and A. Wool. Secure containers in android: the samsung knox case study. In Proceedings of the 6th Workshop on Security and Privacy in Smartphones and Mobile Devices, pages 3–12. ACM, 2016.
14. T. B. Lee. Facebook’s cambridge analytica scandal, explained. Available at https://arstechnica.com/tech-policy/2018/03/facebooks-cambridge-analytica-scandal-explained/ (19 April, 2018), 2018.
15. H.-Y. Lock and A. Kliarsky. Using IOC (Indicators of Compromise) in malware forensics. SANS Institute InfoSec Reading Room, 2013.
16. L. Onwuzurike, M. Almeida, E. Mariconti, J. Blackburn, G. Stringhini, and E. De Cristofaro. A family of droids: Analyzing behavioral model based android malware detection via static and dynamic analysis. arXiv preprint arXiv:1803.03448, 2018.
17. J. Perkins and M. Gordon. Droidsafe. Technical report, Massachusetts Institute of Technology Cambridge United States, 2016.
18. F. Portela, A. M. da Veiga, and M. F. Santos. Benefits of bring your own device in healthcare. In Next-Generation Mobile and Pervasive Healthcare Solutions, pages 32–45. IGI Global, 2018.
19. E. Root, A. Polkovnichenko, and B. Melnykov. Expensivewall: A dangerous ‘packed malware on google play that will hit your wallet. Available at https://blog.checkpoint.com/2017/09/14/expensivewall-dangerous-packed-malware-google-play-will-hit-wallet/ (07 April, 2018), 2017.
20. A. Shabtai, L. Tenenboim-Chekina, D. Mimran, L. Rokach, B. Shapira, and Y. Elovici. Mobile malware detection through analysis of deviations in application network behavior. Computers & Security, 43:1–18, 2014.
21. R. S. Shaji, V. S. Dev, and T. Brindha. A methodological review on attack and defense strategies in cyber warfare. Wireless Networks, pages 1–12, 2018.
22. Y. Song and S. C. Kong. Affordances and constraints of BYOD (bring your own device) for learning and teaching in higher education: Teachers’ perspectives. The Internet and Higher Education, 32:39–46, 2017.
23. M. Souppaya and K. Scarfone. Users guide to telework and bring your own device (BYOD) security. NIST Special Publication, 800:114, 2016.
24. A. Studio. Android debug bridge (adb). Available at https://developer.android.com/studio/command-line/adb.html (23 April, 2018), 2018.
25. A. Studio. UI/application exerciser monkey. Available at https://developer.android.com/studio/test/monkey.html (23 April, 2018), 2018.
26. Unified Compliance Framework, 244 Lafayette Circle, Lafayette, CA 94549. Mobile Application Security Requirements Guide, 2014.
27. R. Vallee-Rai and L. J. Hendren. Jimple: Simplifying java bytecode for analyses and transformations. 1998.
28. M. Viveros. The pros and cons of ’bring your own device’. Available at https://www.forbes.com/sites/ciocentral/2011/11/16/the-pros-and-cons-of-bring-your-own-device/#2a0acb662abe (20 April, 2018), 2011.
29. L.-K. Yan and H. Yin. Droidscope: Seamlessly reconstructing the OS and Dalvik semantic views for dynamic android malware analysis. In USENIX security symposium, pages 569–584, 2012.

#### Report Documentation Page
**Form Approved**  
**OMB No. 0704-01-0188**  
The public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information, including suggestions for reducing the burden to Department of Defense, Washington Headquarters Services Directorate for Information Operations and Reports (0704-0188), 1215 Jefferson Davis Highway, Suite 1204, Arlington VA 22202-4302. Respondents should be aware that notwithstanding any other provision of law, no person shall be subject to any penalty for failing to comply with a collection of information if it does not display a currently valid OMB control number.

**PLEASE DO NOT RETURN YOUR FORM TO THE ABOVE ADDRESS.**

1. **REPORT DATE (DD-MM-YYYY)**: July 2019
2. **REPORT TYPE**: Final
3. **DATES COVERED (From - To)**: [Insert Dates]
4. **TITLE AND SUBTITLE**: Aggregated Machine Learning on Indicators of Compromise
5. **AUTHORS**:
   - John M. San Miguel
   - Megan E.M. Kline
   - Roger A. Hallman
   - Johnny Phan
   - Scott M. Slayback
   - Christopher M. Weeden
   - Jose V. Romero-Mariona
6. **PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES)**:
   - NIWC Pacific
   - 53560 Hull Street
   - San Diego, CA 92152–5001
7. **CONTRACT NUMBER**: [Insert Contract Number]
8. **GRANT NUMBER**: [Insert Grant Number]
9. **PROGRAM ELEMENT NUMBER**: [Insert Program Element Number]
10. **PROJECT NUMBER**: [Insert Project Number]
11. **TASK NUMBER**: [Insert Task Number]
12. **WORK UNIT NUMBER**: [Insert Work Unit Number]
13. **PERFORMING ORGANIZATION REPORT NUMBER**: TD 3390
14. **SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES)**:
   - Naval Innovative Science and Engineering (NISE) Program (Applied Research)
   - NIWC Pacific
   - 53560 Hull Street
   - San Diego, CA 92152–5001
15. **SPONSOR/MONITOR’S ACRONYM(S)**: NISE
16. **DISTRIBUTION/AVAILABILITY STATEMENT**: Distribution Statement A: Approved for public release; distribution is unlimited.
17. **SUPPLEMENTARY NOTES**: This is work of the United States Government and therefore is not copyrighted. This work may be copied and disseminated without restriction.
18. **ABSTRACT**:
   The increasing ubiquity of mobile computing technology has led to new trends in many different sectors. "Bring Your Own Device" (BYOD) is one such growing trend in the workplace, allowing enterprise organizations to benefit from the power of distributed computing and communications equipment that their employees have already purchased. Unfortunately, the integration of a diverse set of mobile devices (e.g., smartphones, tablets, etc.) presents enterprise systems with new challenges, including new attack vectors for malware. Malware mitigation for mobile technology is a long-standing problem for which there is not yet a good solution. In this paper, we focus on identifying malicious applications and verifying the absence of malicious or vulnerable code in applications that enterprises and their users seek to utilize. Our analysis toolbox includes static analysis and permissions risk scoring, pre-installation vetting techniques designed to ensure that malware is never installed on devices on an enterprise network. However, dynamic code-loading techniques and changing security requirements mean that apps which previously passed the verification process, and have been installed on devices, may no longer meet security standards and may be malicious. To identify these apps and prevent future installation of them, we propose a crowd-sourced behavioral analysis technique using machine learning to identify malicious activity through anomalies in system calls, network behavior, and power consumption. These techniques apply effectively to single user devices over time and to individual devices within an enterprise network.
19. **SUBJECT TERMS**:
   - MAVeRiC approach to dynamic analysis for mobile-android
   - Application security
   - MAVeRiC
20. **SECURITY CLASSIFICATION OF**:
   - **a. REPORT**: U
   - **b. ABSTRACT**: U
   - **c. THIS PAGE**: U
21. **LIMITATION OF ABSTRACT**: U
22. **NUMBER OF PAGES**: 32
23. **NAME OF RESPONSIBLE PERSON**: Roger A. Hallman
24. **TELEPHONE NUMBER (Include area code)**: 1 619-553-7905

**Standard Form 298 (Rev. 10/17)**
**Prescribed by ANSI Std. Z39.18**

**Distribution Statement A: Approved for public release; distribution is unlimited.**
**NIWC Pacific**
**San Diego, CA 92152-5001**