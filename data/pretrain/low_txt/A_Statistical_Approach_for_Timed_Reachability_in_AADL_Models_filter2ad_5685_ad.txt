### MaxTime, Local, and Progressive Strategies

The following table presents the time bounds (in seconds) for the system failure probabilities without and with repair:

| Time Bound (s) | 40 | 60 | 80 | 100 | 120 |
|----------------|----|----|----|-----|-----|
| Without Repair |    |    |    |     |     |
| With Repair    |    |    |    |     |     |

**Figure 5. Probabilities of System Failure Containing DPUs Without (Left) and With (Right) Repair.**

To highlight the (lack of) effect of the strategies, different rates have been applied.

### Fault Injection and Component Failures

To link error specifications with the components, fault injections have been defined, which affect the power and control signals. In the event of a fault (whether transient, hot, or permanent), either the power is disabled, or the signal is set to false, indicating a failure.

The case study consists of approximately 800 lines of SLIM code, featuring 20 nominal and error component definitions and 37 component instances. Additionally, 20 fault injections were specified. The case study and tool are accessible from [16].

### Experimental Results

To evaluate the reliability of the system, probabilistic reachability properties were defined, assessing the probability of a system failure. The system is considered failed if control of the thrusters is lost, which occurs when neither triplex can send a command to the thrusters due to failure. This property was specified using the probabilistic existence pattern, which can be translated into the CSL formula \( \text{Pr}(\Diamond_{[0,u]}\text{failure}) \), where `failure` is an atomic proposition indicating that both triplex commands are false and the system is in flight. Here, \( u \) controls the upper time-bound of the property.

**Figure 5** shows the evaluation results for the two versions of the case study with permanent (left graph) and recoverable (right graph) faults for the DPUs (experiments were run with parameters \( \delta = 0.9 \) and \( \epsilon = 0.005 \)). In the left graph, the results are identical for all possible strategies because the model's behavior only contains probabilistic or deterministic transitions, making time scheduling irrelevant. In the right graph, the different strategies result in varying behaviors due to the non-deterministic delay required for recovery. The ASAP strategy always schedules the repair too early, while the MaxTime strategy never does so. The Local and Progressive strategies fall between these extremes, randomly selecting delays before restarting a DPU. The Progressive strategy performs slightly better as it makes it more likely for the DPU error model to preempt a too-early recovery attempt.

### Related Work

Statistical model checking is an active field with extensive past and current research. Various tools have been developed that utilize this technique, such as YMER [21], (P)Vesta [26, 27], MRMC [24], and APMC [7]. These tools allow the analysis of various Markov models by statistical means. More recently, tools like MODES [4] and UPPAAL-SMC [3] have been developed, supporting real-time stochastic models and underspecification of time. These tools differ from ours mainly in the semantics of the input language and the possible scheduling approaches. A major difference between UPPAAL-SMC and our tool is that UPPAAL-SMC supports only broadcast events. For MODES, the main difference is that only the ASAP strategy is supported. PLASMA-lab [5] and Prism [28] support non-deterministic but not real-time models specified in the Prism Reactive Modules language.

An important aspect of statistical model checking is the handling of rare events: occurrences of behavior that happen with very low probability. While full state space model checking guarantees the detection of such events, they are inherently unlikely to be found by regular statistical analysis. Various methods have been introduced to support rare-event simulation for discrete systems [29, 30, 31, 32], which introduce a bias in the model to make such events more likely to occur, adjusting the final probability accordingly.

One drawback of using statistical model checking for non-deterministic models like ours is the current inability to accurately determine the possible lower and upper bounds of the properties' probability. Various approaches, such as reinforcement learning [33] or defining history-dependent schedulers [34], have been suggested to address this issue.

Finally, the efficiency of the simulator is determined by the number of paths required to determine the final outcome. The Chernoff-Hoeffding bound of our implementation is well-known, but other approaches exist for both quantitative and qualitative analysis. The work of [20] introduces various tests and classifies them according to correctness, power, and efficiency.

### Conclusion

This paper introduces our statistical model checker for the COMPASS toolset, supporting an AADL dialect input formalism (SLIM) with linear-hybrid and stochastic aspects. The main aim is to support performability analysis (i.e., probabilistic dependability) for which no tools existed that supported the SLIM semantics.

The Monte Carlo method was chosen as it provides a tractable yet powerful approach to support the combination of real-time and stochastic semantics. By allowing the implementation of various strategies, we address the issue of different possible interpretations of non-determinism, which is inherently required for path generation.

The tool has been integrated into the existing COMPASS toolset, allowing it to be used alongside other analyses and integrating it into both a GUI and CLI-based system. A benchmark and an industrial case study of a launcher show that the use of Monte Carlo simulation is a viable approach. Although it may be outperformed by the existing toolchain for smaller discrete models, for larger or timed models, simulation can be a better alternative.

### Future Work

One area for improvement is more complete support for path generation strategies, giving users more control over the simulation, especially regarding non-deterministic transitions. This includes controlling the scheduling order of transitions and the memory policies [18] being used. Automating or guiding the strategy selection would improve usability, as it requires less intricate knowledge of the methods.

Another area of interest is support for the full spectrum of CSL specifications [35], beyond the predefined patterns of the COMPASS toolset. This would include nested operators. The work of [21] shows that this has a high complexity but is manageable using memoization techniques.

### Acknowledgments

The authors would like to thank Sebastian Junges and Jens Katelaan for their help in designing and building the simulator. This work was partially supported by ESA/ESTEC (contract no. 4000107221 (HASDEL)) and the EU (project reference 318490 (SENSATION)).

### References

[1] P. H. Feiler and D. P. Gluch, Model-Based Engineering with AADL: An Introduction to the SAE Architecture Analysis & Design Language, 1st ed. Addison-Wesley Professional, 2012.

[2] COMPASS Consortium, “COMPASS toolset web-site,” http://compass.informatik.rwth-aachen.de, [Online; accessed 8-December-2014].

[3] P. Bulychev, A. David, K. G. Larsen, M. Mikučionis, D. Bøgsted Poulsen, A. Legay, and Z. Wang, “UPPAAL-SMC: Statistical Model Checking for Priced Timed Automata,” in QAPL, ser. EPTCS, vol. 85. Open Publishing Association, 2012, pp. 1–16.

[4] J. Bogdoll, A. Hartmanns, and H. Hermanns, “Simulation and Statistical Model Checking for Modestly Nondeterministic Models,” in MMB/DFT, ser. LNCS, vol. 7201. Springer, 2012, pp. 249–252.

[5] B. Boyer, K. Corre, A. Legay, and S. Sedwards, “PLASMA-lab: A Flexible, Distributable Statistical Model Checking Library,” in QEST, ser. LNCS, vol. 8054. Springer, 2013, pp. 160–164.

[6] A. Legay, B. Delahaye, and S. Bensalem, “Statistical Model Checking: An Overview,” in RV, ser. LNCS, vol. 6418. Springer, 2010, pp. 122–135.

[7] T. Hérault, R. Lassaigne, F. Magniette, and S. Peyronnet, “Approximate Probabilistic Model Checking,” in VMCAI, ser. LNCS. Springer, 2004, vol. 2937, pp. 73–84.

[8] M. Bozzano, A. Cimatti, J.-P. Katoen, V. Y. Nguyen, T. Noll, and M. Roveri, “Safety, dependability and performance analysis of extended AADL models,” Comput. J., vol. 54, no. 5, pp. 754–775, 2011.

[9] M.-A. Esteve, J.-P. Katoen, V. Y. Nguyen, B. Postma, and Y. Yushtein, “Formal Correctness, Safety, Dependability, and Performance Analysis of a Satellite,” in ICSE, ser. ICSE ’12. IEEE Press, 2012, pp. 1022–1031.

[10] M. Bozzano, A. Cimatti, J.-P. Katoen, P. Katsaros, K. Mokos, V. Y. Nguyen, T. Noll, B. Postma, and M. Roveri, “Spacecraft early design validation using formal methods,” RESS, vol. 132, no. 0, pp. 20–35, 2014.

[11] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore, M. Roveri, R. Sebastiani, and A. Tacchella, “NuSMV 2: An open-source tool for symbolic model checking,” in CAV, ser. LNCS, vol. 2404. Springer, 2002, pp. 359–364.

[12] G. Audemard, A. Cimatti, A. Kornilowicz, and R. Sebastiani, “Bounded model checking for timed systems,” in Formal Techniques for Networked and Distributed Systems–FORTE 2002, ser. LNCS, vol. 2529. Springer, 2002, pp. 243–259.

[13] H. Hermanns and J.-P. Katoen, “The how and why of interactive Markov chains,” in FMCO, ser. LNCS, F. S. de Boer, M. M. Bonsangue, S. Hallerstede, and M. Leuschel, Eds. Springer, 2010, vol. 6286, pp. 311–337.

[14] P. Bertoli, M. Bozzano, and A. Cimatti, “A Symbolic Model Checking Framework for Safety Analysis, Diagnosis, and Synthesis,” in Model Checking and Artificial Intelligence, ser. LNCS, vol. 4428. Springer, 2007, pp. 1–18.

[15] M. Bozzano, A. Cimatti, J.-P. Katoen, V. Y. Nguyen, T. Noll, and M. Roveri, “The COMPASS approach: Correctness, modelling and performability of aerospace systems,” in Computer Safety, Reliability, and Security, ser. LNCS, vol. 5775. Springer, 2009, pp. 173–186.

[16] H. Bruintjes, “Tool and case study download,” http://compass.informatik.rwth-aachen.de/slimsim_dsn, [Online; accessed 8-December-2014].

[17] H. Bohnenkamp, P. R. D’Argenio, H. Hermanns, and J.-P. Katoen, “MODEST: A Compositional Modeling Formalism for Hard and Softly Timed Systems,” IEEE TSE, vol. 32, no. 10, pp. 812–830, 2006.

[18] D. Bohlender, H. Bruintjes, S. Junges, J. Katelaan, V. Y. Nguyen, and T. Noll, “A Review of Statistical Model Checking Pitfalls on Real-Time Stochastic Models,” in ISoLA, ser. LNCS, vol. 8803. Springer, 2014, pp. 177–192.

[19] K. L. McMillan, “The SMV language,” Technical report, Cadence Berkeley Labs, Tech. Rep., 1999.

[20] D. Reijsbergen, P.-T. de Boer, W. Scheinhardt, and B. Haverkort, “On hypothesis testing for statistical model checking,” STTT, pp. 1–19, 2014.

[21] H. L. S. Younes, “Ymer: A Statistical Model Checker,” in CAV, ser. LNCS, vol. 3576. Springer, 2005, pp. 429–433.

[22] P. Bulychev, A. David, K. G. Larsen, A. Legay, and M. Mikučionis and Danny Bøgsted Poulsen, “Checking and distributing statistical model checking,” in NASA Formal Methods, ser. LNCS, vol. 7226. Springer, 2012, pp. 449–463.

[23] R. Wimmer, M. Herbstritt, H. Hermanns, K. Strampp, and B. Becker, “Sigref–a symbolic bisimulation tool box,” in ATVA, ser. LNCS, vol. 4218. Springer, 2006, pp. 477–492.

[24] J.-P. Katoen, I. S. Zapreev, E. M. Hahn, H. Hermanns, and D. N. Jansen, “The Ins and Outs of The Probabilistic Model Checker MRMC,” in QEST. IEEE, 2009, pp. 167–176.

[25] Y. Yushtein, M. Bozzano, A. Cimatti, J.-P. Katoen, V. Y. Nguyen, T. Noll, X. Olive, and M. Roveri, “System-software co-engineering: Dependability and safety perspective,” in SMC-IT. IEEE, 2011, pp. 18–25.

[26] K. Sen, M. Viswanathan, and G. A. Agha, “VESTA: A Statistical Model-Checker and Analyzer for Probabilistic Systems,” in QEST. IEEE Computer Society, 2005, pp. 251–252.

[27] M. AlTurki and J. Meseguer, “PVeStA: A Parallel Statistical Model Checking and Quantitative Analysis Tool,” in CALCO, ser. LNCS, vol. 6859. Springer, 2011, pp. 386–392.

[28] M. Kwiatkowska, G. Norman, and D. Parker, “PRISM 4.0: Verification of Probabilistic Real-time Systems,” in CAV, ser. LNCS, vol. 6806. Springer, 2011, pp. 585–591.

[29] G. Rubino and B. Tuffin, Rare Event Simulation Using Monte Carlo Methods. Wiley Publishing, 2009.

[30] D. Reijsbergen, P.-T. de Boer, W. Scheinhardt, and B. Haverkort, “Rare event simulation for highly dependable systems with fast repairs,” Performance Evaluation, vol. 69, no. 78, pp. 336 – 355, 2012.

[31] D. Reijsbergen, P.-T. de Boer, B. Haverkort, and W. Scheinhardt, “Automated Rare Event Simulation for Stochastic Petri Nets,” in QEST, ser. LNCS, vol. 8054. Springer, 2013, pp. 372–388.

[32] C. Jégourel, Axel Legay, and Sean Sedwards, “An Effective Heuristic for Adaptive Importance Splitting in Statistical Model Checking,” in ISoLA, ser. LNCS, vol. 8803. Springer, 2014, pp. 143–159.

[33] D. Henriques, J. Martins, P. Zuliani, A. Platzer, and E. M. Clarke, “Statistical Model Checking for Markov Decision Processes,” in QEST. IEEE, 2012, pp. 84–93.

[34] P. D’Argenio, A. Legay, S. Sedwards, and L.-M. Traonouez, “Smart Sampling for Lightweight Verification of Markov Decision Processes,” CoRR, vol. abs/1409.2116, 2014. [Online]. Available: http://arxiv.org/abs/1409.2116

[35] C. Baier, B. Haverkort, H. Hermanns, and J.-P. Katoen, “Model Checking Algorithms for Continuous-Time Markov Chains,” IEEE TSE, vol. 29, no. 6, pp. 524–541, 2003.

Authorized licensed use limited to: Tsinghua University. Downloaded on March 19, 2021, at 08:48:59 UTC from IEEE Xplore. Restrictions apply.