### Figures and Analysis

**Figure 9: The 144 AUCs from the poisoned ROC curves for each possible target flow and their mean.**

- **Single Flow AUC**
- **Mean AUC**
- **Iso-performance**
- **PCA AUCs**
- **ANTIDOTE**
- **Random Detector**

**AUC Values:**
- 0.6
- 0.7
- 0.8
- 0.9
- 1.0

**Mean Chaff Volume:**
- 0%
- 10%
- 20%
- 30%
- 40%
- 50%

**Figure 10: The mean AUCs versus mean chaff levels.**

We demonstrated that the PCA-subspace method can be easily compromised (often dramatically) under all of these poisoning scenarios. From the attacker’s perspective, we illustrate that simple strategies can be effective, and conclude that it is not worth the risk or extra effort for the attacker to engage in attempts at optimal strategies. We demonstrated that our ANTIDOTE solution is robust to all of these attacks, as it does not allow poisoning attacks to significantly shift the false positive and false negative rates. Our results show that ANTIDOTE provides robustness for nearly all ingress POP to egress POP flows in a backbone network, rejects much of the contaminated data, and continues to operate as a DoS defense even in the face of poisoning.

### Future Work

In the future, we plan to adapt our scheme to defend against poisoning strategies that enable DDoS evasion. Additionally, we intend to validate our findings on other traffic matrix datasets (e.g., GÉANT or enterprise networks). It is also interesting to consider using robust statistical methods for other detectors, such as general anomography techniques. We plan to go beyond the rejection of poisoning data and study methods for identifying the responsible flow for a poisoning attack by looking at correlations among links that are rejecting chaff.

### Acknowledgements

We would like to thank Peter Bartlett, Fuching Jack Chi, Fernando Silveira, Anthony Tran, and the anonymous reviewers for their helpful feedback on this project. We gratefully acknowledge the support of our sponsors. This work was supported in part by:

- **TRUST (Team for Research in Ubiquitous Secure Technology)**, which receives support from the National Science Foundation (NSF award #CCF-0424422) and AFOSR (#FA9550-06-1-0244).
- **RAD Lab**, which receives support from California state MICRO grants (#06-148 and #07-012).
- **DETERlab (Cyber-DEfense Technology Experimental Research Laboratory)**, which receives support from DHS HSARPA (#022412) and AFOSR (#FA9550-07-1-0501).
- **NSF award #DMS-0707060**.
- **Organizations**: Amazon, BT, Cisco, DoCoMo USA Labs, EADS, ESCHER, Facebook, Google, HP, IBM, iCAST, Intel, Microsoft, NetApp, ORNL, Pirelli, Qualcomm, Sun, Symantec, TCS, Telecom Italia, United Technologies, and VMware.

The opinions expressed in this paper are solely those of the authors and do not necessarily reflect the opinions of any funding agency, the State of California, or the U.S. government.

### References

1. P. Bahl, R. Chandra, A. Greenberg, S. Kandula, D. Maltz, and M. Zhang. Towards highly reliable enterprise network services via inference of multi-level dependencies. In Proc. SIGCOMM, 2007.
2. M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar. Can machine learning be secure? In Proc. ASIACCS, 2006.
3. D. Brauckhoff, K. Salamatian, and M. May. Applying PCA for Traffic Anomaly Detection: Problems and Solutions. In Proc. INFOCOM, 2009.
4. N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press, 2006.
5. Y. Cheng, M. Afanasyev, P. Verkaik, P. Benko, J. Chiang, A. Snoeren, S. Savage, and G. Voelker. Automating cross-layer diagnosis of enterprise wireless networks. In Proc. SIGCOMM, 2007.
6. C. Croux, P. Filzmoser, and M. R. Oliveira. Algorithms for projection-pursuit robust principal component analysis. Chemometrics and Intelligent Laboratory Systems, 87(2), 2007.
7. C. Croux and A. Ruiz-Gazen. High breakdown estimators for principal components: the projection-pursuit approach revisited. J. Multivariate Analysis, 95(1), 2005.
8. N. Dalvi, P. Domingos, Mausam, S. Sanghai, and D. Verma. Adversarial classification. In Proc. ACM KDD, 2004.
9. S. J. Devlin, R. Gnanadesikan, and J. R. Kettenring. Robust estimation of dispersion matrices and principal components. J. American Statistical Association, 76, 1981.
10. P. Fogla and W. Lee. Evading network anomaly detection systems: Formal reasoning and practical techniques. In Proc. ACM CCS, 2006.
11. O. Hossjer and C. Croux. Generalizing univariate signed rank statistics for testing and estimating a multivariate location parameter. J. Nonparametric Statistics, 4, 1995.
12. L. Huang, X. Nguyen, M. Garofalakis, M. Jordan, A. Joseph, and N. Taft. In-network PCA and anomaly detection. In Proc. NIPS '06, 2007.
13. J. E. Jackson and G. S. Mudholkar. Control procedures for residuals associated with principal component analysis. Technometrics, 21(3), 1979.
14. S. Kandula, R. Chandra, and D. Katabi. What's going on? Learning communication rules in edge networks. In Proc. SIGCOMM, 2008.
15. A. Lakhina, M. Crovella, and C. Diot. Characterization of network-wide anomalies in traffic flows. In Proc. IMC, 2004.
16. A. Lakhina, M. Crovella, and C. Diot. Diagnosing network-wide traffic anomalies. In Proc. SIGCOMM, 2004.
17. A. Lakhina, M. Crovella, and C. Diot. Detecting distributed attacks using network-wide flow traffic. In Proc. FloCon 2005 Analysis Workshop, 2005.
18. A. Lakhina, M. Crovella, and C. Diot. Mining anomalies using traffic feature distributions. In Proc. SIGCOMM, 2005.
19. G. Li and Z. Chen. Projection-pursuit approach to robust dispersion matrices and principal components: primary theory and Monte Carlo. J. American Statistical Association, 80, 1985.
20. X. Li, F. Bian, M. Crovella, C. Diot, R. Govindan, G. Iannaccone, and A. Lakhina. Detection and identification of network anomalies using sketch subspaces. In Proc. IMC, 2006.
21. X. Li, F. Bian, H. Zhang, C. Diot, R. Govindan, W. Hong, and C. Iannaccone. MIND: A distributed multidimensional indexing for network diagnosis. In Proc. INFOCOM, 2006.
22. D. Lowd and C. Meek. Adversarial learning. In Proc. ACM KDD, 2005.
23. R. Maronna. Principal components and orthogonal regression based on robust scales. Technometrics, 47(3), 2005.
24. B. Nelson, M. Barreno, F. J. Chi, A. D. Joseph, B. I. P. Rubinstein, U. Saini, C. Sutton, J. D. Tygar, and K. Xia. Exploiting machine learning to subvert your spam filter. In Proc. LEET, 2008.
25. J. Newsome, B. Karp, and D. Song. Polygraph: Automatically generating signatures for polymorphic worms. In Proc. IEEE Symp. Security and Privacy, 2005.
26. J. Newsome, B. Karp, and D. Song. Paragraph: Thwarting signature learning by training maliciously. In Proc. RAID, 2006.
27. A. Ramachandran, N. Feamster, and S. Vempala. Filtering spam with behavioral blacklisting. In Proc. ACM CCS, 2007.
28. H. Ringberg, A. Soule, J. Rexford, and C. Diot. Sensitivity of PCA for traffic anomaly detection. In Proc. SIGMETRICS, 2007.
29. B. I. P. Rubinstein, B. Nelson, L. Huang, A. D. Joseph, S. Lau, S. Rao, N. Taft, and J. D. Tygar. Stealthy poisoning attacks on PCA-based anomaly detectors. In SIGMETRICS Performance Evaluation Review, 2009. To appear.
30. A. Soule, K. Salamatian, and N. Taft. Combining filtering and statistical methods for anomaly detection. In Proc. IMC, 2005.
31. S. Venkataraman, A. Blum, and D. Song. Limits of learning-based signature generation with adversaries. In Proc. NDSS, 2008.
32. G. L. Wittel and S. F. Wu. On attacking statistical spam filters. In Proc. CEAS, 2004.
33. Y. Zhang, Z. Ge, A. Greenberg, and M. Roughan. Network anomography. In Proc. IMC, 2005.