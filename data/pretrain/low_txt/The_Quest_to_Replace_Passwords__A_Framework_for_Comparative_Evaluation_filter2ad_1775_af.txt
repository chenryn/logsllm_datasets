### Missing Information and End-User Burden in Authentication Schemes

The analysis lacks comprehensive information for most authentication schemes, particularly regarding the end-user burden associated with migrating from traditional password systems. This burden, distinct from the costs of modifying browser and server infrastructure, includes both the one-time initial setup and per-account transition costs. While ease of resetting and revoking credentials is a part of the "Easy-Recovery-from-Loss" benefit, it does not encompass user and system aspects related to renewing expiring credentials (excluding loss). Other missing cost-related benefits include:
- Low initial setup costs (including infrastructure changes by all stakeholders).
- Low ongoing administration, support, and maintenance costs.
- Low overall complexity (measured by the number of inter-related components in the system).

Additionally, the analysis does not capture:
- Continued availability under denial-of-service attacks.
- Ease of use on mobile devices.
- Economic and business effects, such as the lack of incentive for relying parties, which has been cited as a key reason for the limited adoption of OpenID [28].

While these and other benefits could be included in the framework and evaluated using this methodology, assigning ratings for them might be even more subjective than for existing benefits.

### Additional Nuanced Ratings

We considered but ultimately decided against using a "fatal" rating to indicate that a scheme's performance on a specific benefit is so poor that the scheme should be eliminated from serious consideration. For example, the 2–3 minutes required for authentication using the Weinshall or Hopper-Blum schemes might make them "fatally-non-Efﬁcient-to-Use," likely preventing widespread adoption even if they provide virtually all other benefits. We did not implement this because, for many properties, it is unclear what level of failure should be declared as fatal.

We also considered a "power" rating to indicate that a scheme optionally enables a benefit for power users. For instance, OpenID could be rated "amenable-to-No-Trusted-Third-Party" because users can run their own identity servers, in contrast to Facebook Connect or Microsoft Passport. The popularity of webmail-based password reset suggests that most users already accept a heavily-trusted third party for their online identities, making "amenable-to" sufficient for adoption. OpenID is arguably amenable to every security benefit for power users but does not provide them for common users who use text passwords to authenticate to their identity provider. However, since an "amenable-to" rating could be argued for many properties of many schemes, we maintained a focus on properties provided by default to all users.

### Weights and Finer-Grained Scoring

We reiterate the caution sounded at the end of Section II: the benefits chosen as metrics are not of equal weight. The importance of any particular benefit depends on the target use and threat environment. While one could assign weights to each column to compute numerical scores for each scheme, providing exact weights is problematic, and no fixed values would suit all scenarios. Nonetheless, our framework allows for such an endeavor. For finer-grained evaluation, table cell scores like "partially" could be allowed beyond our very coarse {no, almost, yes} quantization, to further delineate similar schemes. This has merit but brings the danger of being "precisely wrong," and too fine a granularity adds to the difficulty of scoring schemes consistently. There will be the temptation to be unrealistically precise ("If scheme X gets 0.9 for this benefit, then scheme Y should get at most 0.6"), but this demands the ability to maintain a constant level of precision repeatably across all cells.

We have resisted the temptation to produce an aggregate score for each scheme (e.g., by counting the number of benefits achieved) or to rank the schemes. As discussed above, a fatal failure of a single benefit or combined failure of a pair of benefits (e.g., not being Resilient-to-Internal-Observation and fatally failing Easy-Recovery-from-Loss for biometrics) may eliminate a scheme from consideration. Thus, seeking schemes purely based on high numbers of benefits could well prove a distraction.

Beyond divergences of judgment, there will no doubt be errors in judgment in scoring. The table scoring methodology must include redundancy and cross-checks sufficient to catch most such errors. (Our exercise involved one author initially scoring a scheme row, co-authors verifying the scores, and independently, cross-checks within columns to calibrate individual benefit ratings across schemes; useful clarifications of benefit definitions often resulted.) Another danger in being "too precise" arises from scoring on second-hand data inferred from papers. Coarsely-quantized but self-consistent scores are likely better than inconsistent ones.

On one hand, it could be argued that different application domains (e.g., banking vs. gaming) have different requirements and that therefore they ought to assign different weights to the benefits, resulting in a different choice of optimal scheme for each domain. On the other hand, to users, a proliferation of schemes is in itself a failure: the meta-scheme of "use the best scheme for each application" will score rather poorly on Scalable-for-Users, Easy-to-Learn, and perhaps a few other usability benefits.

### Combining Schemes

It is optimistic to assume that pairs of schemes that complement each other well in a two-factor arrangement might be those where both achieve good scores in usability and deployability and at least one does so in security. A combined scheme might be viewed as having the AND of the usability-deployability scores (i.e., the combination does not have a particular usability or deployability benefit unless both of the schemes do) and the OR of the security scores (i.e., the combination has the security benefit if either of the schemes do). An exception would appear to be the usability benefit Scalable-for-Users, which a combination might inherit from either component. However, this is necessarily just a starting point for the two-component analysis: schemes do not always inherit benefits in this way.

Wimberly and Liebrock [65] observed that the presence of a second factor caused users to pick much weaker passwords than if passwords alone were used to protect an account, as predicted by Adams’s "risk thermostat" model [66]. Thus, especially where user choice is involved, there can be an erosion of the efficacy of one protection when a second factor is known to be in place. Equally, defeating one security mechanism may also make it materially easier to defeat another. For example, Phoolproof was rated Quasi-Resilient-to-Internal-Observation because it requires an attacker to compromise both a PC and a mobile device. However, malware has already been observed in the wild that leverages a compromised PC to download further malware onto mobile devices plugged into the PC for a software update [67].

See O’Gorman [9] for suggested two-factor combinations of biometrics, passwords, and tokens for various applications (e.g., combining a hardware token with a biometric). Another common suggestion is pairing a federated scheme with a higher-security scheme, e.g., a hardware token.

### Concluding Remarks

The concise overview offered by Table I allows us to see high-level patterns that might otherwise be missed. We could draw a variety of conclusions and note, for example, that graphical and cognitive schemes offer only minor improvements over passwords and thus have little hope of displacing them. Or we could note that most of the schemes with substantial improvements in both usability and security can be seen as incarnations of Single-Sign-On (including in this broad definition not only federated schemes but also "local SSO" systems [26] such as password managers or Pico). Having said that, we expect the long-term scientific value of our contribution will lie not as much in the raw data distilled herein, as in the methodology by which it was assembled. A carefully crafted benefits list and coherent methodology for scoring table entries, despite inevitable (albeit instructive) disagreements over fine points of specific scores, allows principled discussions about high-level conclusions.

That a Table I scheme (the CAP reader) scored full marks in security does not at all suggest that its real-world security is perfect—indeed, major issues have been found [55]. This is a loud warning that it would be unwise to read absolute verdicts into these scores. Our ratings are useful and we stand by them, but they are not a substitute for independent critical analysis or for considering aspects we didn’t rate, such as vulnerability to active man-in-the-middle attacks.

We note that the ratings implied by scheme authors in original publications are often not only optimistic but also incomplete. Proponents, perhaps subconsciously, often have a biased and narrow view of what benefits are relevant. Our framework allows a more objective assessment.

In closing, we observe that, looking at the green (vertical) and red (horizontal) patterns in Table I, most schemes do better than passwords on security—as expected, given that inventors of alternatives to passwords tend to come from the security community. Some schemes do better and some worse on usability—suggesting that the community needs to work harder there. But every scheme does worse than passwords on deployability. This was to be expected given that the first four deployability benefits are defined with explicit reference to what passwords achieve, and the remaining two are natural benefits of a long-term incumbent. This uneven playing field reflects the reality of a decentralized system like the Internet. Marginal gains are often not sufficient to reach the activation energy necessary to overcome significant transition costs, which may provide the best explanation of why we are likely to live considerably longer before seeing the funeral procession for passwords arrive at the cemetery.

### Acknowledgments

The authors thank the anonymous reviewers whose comments helped improve the paper greatly. Joseph Bonneau is supported by the Gates Cambridge Trust. Paul C. van Oorschot is Canada Research Chair in Authentication and Computer Security and acknowledges NSERC for funding the chair and a Discovery Grant; partial funding from NSERC ISSNet is also acknowledged. This work grew out of the Related Work section of Pico [8].

### References

[1] J. Bonneau, C. Herley, P. C. van Oorschot, and F. Stajano, “The quest to replace passwords: A framework for comparative evaluation of web authentication schemes,” University of Cambridge Computer Laboratory, Tech Report 817, 2012, www.cl.cam.ac.uk/techreports/UCAM-CL-TR-817.html.
[2] R. Morris and K. Thompson, “Password security: a case history,” Commun. ACM, vol. 22, no. 11, pp. 594–597, 1979.
[3] A. Adams and M. Sasse, “Users Are Not The Enemy,” Commun. ACM, vol. 42, no. 12, pp. 41–46, 1999.
[4] C. Herley and P. C. van Oorschot, “A research agenda acknowledging the persistence of passwords,” IEEE Security & Privacy, vol. 10, no. 1, pp. 28–36, 2012.
[5] D. Florêncio and C. Herley, “One-Time Password Access to Any Server Without Changing the Server,” ISC 2008, Taipei.
[6] M. Mannan and P. C. van Oorschot, “Leveraging personal devices for stronger password authentication from untrusted computers,” Journal of Computer Security, vol. 19, no. 4, pp. 703–750, 2011.
[7] S. Chiasson, E. Stobert, A. Forget, R. Biddle, and P. C. van Oorschot, “Persuasive cued click-points: Design, implementation, and evaluation of a knowledge-based authentication mechanism,” IEEE Trans. on Dependable and Secure Computing, vol. 9, no. 2, pp. 222–235, 2012.
[8] F. Stajano, “Pico: No more passwords!” in Proc. Sec. Protocols Workshop 2011, ser. LNCS, vol. 7114. Springer.
[9] L. O’Gorman, “Comparing passwords, tokens, and biometrics for user authentication,” Proceedings of the IEEE, vol. 91, no. 12, pp. 2019–2040, December 2003.
[10] K. Renaud, “Quantification of authentication mechanisms: a usability perspective,” J. Web Eng., vol. 3, no. 2, pp. 95–123, 2004.
[11] R. Biddle, S. Chiasson, and P. C. van Oorschot, “Graphical Passwords: Learning from the First Twelve Years,” ACM Computing Surveys, vol. 44, no. 4, 2012.
[12] J. Nielsen and R. Mack, Usability Inspection Methods. Wiley & Sons, Inc, 1994.
[13] J. Bonneau and S. Preibusch, “The password thicket: technical and market failures in human authentication on the web,” in Proc. WEIS 2010, 2010.
[14] J. Bonneau, “The science of guessing: analyzing an anonymized corpus of 70 million passwords,” IEEE Symp. Security and Privacy, May 2012.
[15] K. Fu, E. Sit, K. Smith, and N. Feamster, “Dos and don’ts of client authentication on the web,” in Proc. USENIX Security Symposium, 2001.
[16] D. Florêncio and C. Herley, “Where Do Security Policies Come From?” in ACM SOUPS 2010: Proc. 6th Symp. on Usable Privacy and Security.
[17] L. Falk, A. Prakash, and K. Borders, “Analyzing websites for user-visible security design flaws,” in ACM SOUPS 2008, pp. 117–126.
[18] S. Gaw and E. W. Felten, “Password Management Strategies for Online Accounts,” in ACM SOUPS 2006: Proc. 2nd Symp. on Usable Privacy and Security, pp. 44–55.
[19] D. Florêncio and C. Herley, “A large-scale study of web password habits,” in WWW ’07: Proc. 16th International Conf. on the World Wide Web. ACM, 2007, pp. 657–666.
[20] D. Balzarotti, M. Cova, and G. Vigna, “ClearShot: Eavesdropping on Keyboard Input from Video,” in IEEE Symp. Security and Privacy, 2008, pp. 170–183.
[21] B. Kaliski, RFC 2898: PKCS #5: Password-Based Cryptography Specification Version 2.0, IETF, September 2000.
[22] Mozilla Firefox, ver. 10.0.2, www.mozilla.org/.
[23] A. Pashalidis and C. J. Mitchell, “Impostor: A single sign-on system for use from untrusted devices,” Proc. IEEE Globecom, 2004.
[24] R. M. Needham and M. D. Schroeder, “Using encryption for authentication in large networks of computers,” Commun. ACM, vol. 21, pp. 993–999, December 1978.
[25] J. Kohl and C. Neuman, “The Kerberos Network Authentication Service (V5),” United States, 1993.
[26] A. Pashalidis and C. J. Mitchell, “A Taxonomy of Single Sign-On Systems,” in Proc. ACISP 2003, Information Security and Privacy, 8th Australasian Conference. Springer LNCS 2727, 2003, pp. 249–264.
[27] D. Recordon and D. Reed, “OpenID 2.0: a platform for user-centric identity management,” in DIM ’06: Proc. 2nd ACM Workshop on Digital Identity Management, 2006, pp. 11–16.
[28] S.-T. Sun, Y. Boshmaf, K. Hawkey, and K. Beznosov, “A billion keys, but few locks: the crisis of web single sign-on,” Proc. NSPW 2010, pp. 61–72.
[29] B. Laurie, “OpenID: Phishing Heaven,” January 2007, www.links.org/?p=187.
[30] R. Jhawar, P. Inglesant, N. Courtois, and M. A. Sasse, “Make mine a quadruple: Strengthening the security of graphical one-time PIN authentication,” in Proc. NSS 2011, pp. 81–88.
[31] L. Lamport, “Password authentication with insecure communication,” Commun. ACM, vol. 24, no. 11, pp. 770–772, 1981.
[32] N. Haller and C. Metz, “RFC 1938: A One-Time Password System,” 1998.
[33] M. Kuhn, “OTPW — a one-time password login package,” 1998, www.cl.cam.ac.uk/~mgk25/otpw.html.
[34] RSA, “RSA SecurID Two-factor Authentication,” 2011, www.rsa.com/products/securid/sb/10695_SIDTFA_SB_0210.pdf.
[35] P. Bright, “RSA finally comes clean: SecurID is compromised,” Jun. 2011, arstechnica.com/security/news/2011/06/rsa-finally-comes-clean-securid-is-compromised.ars.
[36] B. Parno, C. Kuo, and A. Perrig, “Phoolproof Phishing Prevention,” in Proc. Fin. Crypt. 2006, pp. 1–19.
[37] A. K. Jain, A. Ross, and S. Pankanti, “Biometrics: a tool for information security,” IEEE Transactions on Information Forensics and Security, vol. 1, no. 2, pp. 125–143, 2006.
[38] A. Ross, J. Shah, and A. K. Jain, “From Template to Image: Reconstructing Fingerprints from Minutiae Points,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 4, pp. 544–560, 2007.
[39] J. Daugman, “How iris recognition works,” IEEE Trans. Circuits Syst. Video Techn., vol. 14, no. 1, pp. 21–30, 2004.
[40] P. S. Aleksic and A. K. Katsaggelos, “Audio-Visual Biometrics,” Proc. of the IEEE, vol. 94, no. 11, pp. 2025–2044, 2006.
[41] T. Matsumoto, H. Matsumoto, K. Yamada, and S. Hoshino, “Impact of artificial ‘gummy’ fingers on fingerprint systems,” in SPIE Conf. Series, vol. 4677, Apr. 2002, pp. 275–289.
[42] LastPass, www.lastpass.com/.
[43] D. P. Kormann and A. D. Rubin, “Risks of the Passport single signon protocol,” Computer Networks, vol. 33, no. 1–6, 2000.
[44] “Facebook Connect,” 2011, www.facebook.com/advertising/?connect.
[45] M. Hanson, D. Mills, and B. Adida, “Federated Browser-Based Identity using Email Addresses,” W3C Workshop on Identity in the Browser, May 2011.
[46] T. W. van der Horst and K. E. Seamons, “Simple Authentication for the Web,” in Intl. Conf. on Security and Privacy in Communications Networks, 2007, pp. 473–482.
[47] H. Tao, “Pass-Go, a New Graphical Password Scheme,” Master’s thesis, School of Information Technology and Engineering, University of Ottawa, June 2006.
[48] D. Weinshall, “Cognitive Authentication Schemes Safe Against Spyware (Short Paper),” in IEEE Symposium on Security and Privacy, May 2006.
[49] N. Hopper and M. Blum, “Secure human identification protocols,” ASIACRYPT 2001, pp. 52–66, 2001.
[50] S. Smith, “Authenticating users by word association,” Computers & Security, vol. 6, no. 6, pp. 464–470, 1987.
[51] A. Wiesmaier, M. Fischer, E. G. Karatsiolis, and M. Lippert, “Outflanking and securely using the PIN/TAN-System,” CoRR, vol. cs.CR/0410025, 2004.
[52] “PassWindow,” 2011, www.passwindow.com.
[53] Yubico, “The YubiKey Manual, v. 2.0,” 2009, static.yubico.com/var/uploads/YubiKey_manual-2.0.pdf.
[54] Ironkey, www.ironkey.com/internet-authentication.
[55] S. Drimer, S. J. Murdoch, and R. Anderson, “Optimised to Fail: Card Readers for Online Banking,” in Financial Cryptography and Data Security, 2009, pp. 184–200.
[56] Cronto, www.cronto.com/.
[57] Google Inc., “2-step verification: how it works,” 2012, www.google.com/accounts.
[58] S. Schechter, A. J. B. Brush, and S. Egelman, “It’s no secret: Measuring the security and reliability of authentication via ‘secret’ questions,” in IEEE Symp. Security and Privacy, 2009, pp. 375–390.
[59] M. Jakobsson, L. Yang, and S. Wetzel, “Quantifying the Security of Preference-based Authentication,” in ACM DIM 2008: 4th Workshop on Digital Identity Management.
[60] J. Brainard, A. Juels, R. L. Rivest, M. Szydlo, and M. Yung, “Fourth-factor authentication: somebody you know,” in ACM CCS 2006, pp. 168–178.
[61] D. Weinshall, “Cognitive Authentication Schemes Safe Against Spyware,” IEEE Symp. Security and Privacy, 2006.
[62] P. Golle and D. Wagner, “Cryptanalysis of a Cognitive Authentication Scheme,” IEEE Symp. Security and Privacy, 2007.
[63] B. Coskun and C. Herley, “Can ‘Something You Know’ be Saved?” ISC 2008, Taipei.
[64] Q. Yan, J. Han, Y. Li, and H. Deng, “On limitations of designing usable leakage-resilient password systems: Attacks, principles and usability.” Proc. NDSS, 2012.
[65] H. Wimberly and L. M. Liebrock, “Using Fingerprint Authentication to Reduce System Security: An Empirical Study,” in IEEE Symp. Security and Privacy, 2011, pp. 32–46.
[66] J. Adams, “Risk and morality: three framing devices,” in Risk and Morality, R. Ericson and A. Doyle, Eds. University of Toronto Press, 2003.
[67] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wagner, “A survey of mobile malware in the wild,” in ACM SPSM 2011: 1st Workshop on Security and Privacy in Smartphones and Mobile Devices, pp. 3–14.