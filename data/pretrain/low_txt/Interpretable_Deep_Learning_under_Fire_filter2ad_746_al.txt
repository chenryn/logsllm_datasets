One possible cause of this vulnerability raises critical concerns about the current assessment metrics for interpretation models. Furthermore, we discuss potential countermeasures against ADV2, which provides insights into designing and operating IDLSes in a more robust and informative manner.

### Acknowledgments
This work is supported by the National Science Foundation under Grant Nos. 1846151 and 1910546. The opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. Shouling Ji is partially supported by the National Natural Science Foundation of China (NSFC) under Grant Nos. 61772466 and U1836202, the Zhejiang Provincial Natural Science Foundation for Distinguished Young Scholars (Grant No. LR19F020003), and the Provincial Key Research and Development Program of Zhejiang, China (Grant No. 2017C01055). Xiapu Luo is partially supported by the Hong Kong Research Grants Council (RGC) Projects (PolyU 152279/16E and CityU C1008-16G).

### References
1. J. Adebayo, J. Gilmer, M. Muelly, I. Goodfellow, M. Hardt, and B. Kim. "Sanity Checks for Saliency Maps." In *Proceedings of Advances in Neural Information Processing Systems (NIPS)*, 2018.
2. Rima Alaifari, Giovanni S. Alberti, and Tandri Gauksson. "ADef: An Iterative Algorithm to Construct Adversarial Deformations." In *Proceedings of International Conference on Learning Representations (ICLR)*, 2019.
3. M. Ancona, E. Ceolini, C. Öztireli, and M. Gross. "Towards Better Understanding of Gradient-based Attribution Methods for Deep Neural Networks." In *Proceedings of International Conference on Learning Representations (ICLR)*, 2018.
4. Marcin Andrychowicz, Misha Denil, Sergio Gómez, Matthew W. Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando de Freitas. "Learning to Learn by Gradient Descent by Gradient Descent." In *Proceedings of Advances in Neural Information Processing Systems (NIPS)*, 2016.
5. Anish Athalye, Nicholas Carlini, and David Wagner. "Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples." In *Proceedings of International Conference on Learning Representations (ICLR)*, 2018.
6. Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek. "On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation." *PLoS ONE*, 10(7):e0130140, 2015.
7. Battista Biggio, Blaine Nelson, and Pavel Laskov. "Poisoning Attacks against Support Vector Machines." In *Proceedings of IEEE Conference on Machine Learning (ICML)*, 2012.
8. Chunshui Cao, Xianming Liu, Yi Yang, Yinan Yu, Jiang Wang, Zilei Wang, Yongzhen Huang, Liang Wang, Chang Huang, Wei Xu, Deva Ramanan, and Thomas S. Huang. "Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks." In *Proceedings of IEEE International Conference on Computer Vision (ICCV)*, 2015.
9. Nicholas Carlini and David A. Wagner. "Towards Evaluating the Robustness of Neural Networks." In *Proceedings of IEEE Symposium on Security and Privacy (S&P)*, 2017.
10. P. Dabkowski and Y. Gal. "Real Time Image Saliency for Black Box Classifiers." In *Proceedings of Advances in Neural Information Processing Systems (NIPS)*, 2017.
11. Nilesh Dalvi, Pedro Domingos, Mausam, Sumit Sanghai, and Deepak Verma. "Adversarial Classification." In *Proceedings of ACM International Conference on Knowledge Discovery and Data Mining (KDD)*, 2004.
12. J. Deng, W. Dong, R. Socher, L. Li, Kai Li, and Li Fei-Fei. "ImageNet: A Large-Scale Hierarchical Image Database." In *Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2009.
13. Mengnan Du, Ninghao Liu, Qingquan Song, and Xia Hu. "Towards Explanation of DNN-based Prediction with Guided Feature Inversion." In *Proceedings of ACM International Conference on Knowledge Discovery and Data Mining (KDD)*, 2018.
14. Mengnan Du, Ninghao Liu, Qingquan Song, and Xia Hu. "Towards Explanation of DNN-based Prediction with Guided Feature Inversion." *ArXiv e-prints*, 2018.
15. Chelsea Finn, Pieter Abbeel, and Sergey Levine. "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks." In *Proceedings of IEEE Conference on Machine Learning (ICML)*, 2017.
16. Ruth C. Fong and Andrea Vedaldi. "Interpretable Explanations of Black Boxes by Meaningful Perturbation." In *Proceedings of IEEE International Conference on Computer Vision (ICCV)*, 2017.
17. T. Gehr, M. Mirman, D. Drachsler-Cohen, P. Tsankov, S. Chaudhuri, and M. Vechev. "AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation." In *Proceedings of IEEE Symposium on Security and Privacy (S&P)*, 2018.
18. Nils Gessert, Thilo Sentker, Frederic Madesta, Rüdiger Schmitz, Helge Kniep, Ivo M. Baltruschat, René Werner, and Alexander Schlaefer. "Skin Lesion Diagnosis Using Ensembles, Unscaled Multi-Crop Evaluation, and Loss Weighting." *ArXiv e-prints*, abs/1808.01694, 2018.
19. Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. "Explaining and Harnessing Adversarial Examples." In *Proceedings of International Conference on Learning Representations (ICLR)*, 2015.
20. Wenbo Guo, Dongliang Mu, Jun Xu, Purui Su, Gang Wang, and Xinyu Xing. "LEMNA: Explaining Deep Learning Based Security Applications." In *Proceedings of ACM SAC Conference on Computer and Communications (CCS)*, 2018.
21. K. He, G. Gkioxari, P. Dollár, and R. Girshick. "Mask R-CNN." In *Proceedings of IEEE International Conference on Computer Vision (ICCV)*, 2017.
22. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. "Deep Residual Learning for Image Recognition." In *Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2016.
23. Warren He, James Wei, Xinyun Chen, Nicholas Carlini, and Dawn Song. "Adversarial Example Defenses: En...