### Optimized Text

The presented figures are specific to strictly alternating Interactive Markov Chains (IMCs), which include all the necessary data for the corresponding Continuous-Time Markov Decision Processes (CTMDPs). These figures differentiate between interactive states/transitions and Markov states/transitions. Column 7 displays the time required for the transformation from uIMC to uCTMDP. Notably, our prototypical implementation of the transformation procedure operates efficiently even for large systems (N = 128).

Columns 8 and 9 provide statistics on the implementation of the reachability algorithm. The runtime results for a time bound of 100 hours are shown in column 8, while the results for a time bound of 30,000 hours are in column 9. The last two columns indicate the number of iterations needed by the reachability algorithm to achieve a precision of 0.000001. Readers familiar with the time and space requirements of Continuous-Time Markov Chain (CTMC) analysis will appreciate the efficiency demonstrated in these figures, especially considering that we are reporting on a Java prototype and dealing with non-determinism.

In Figure 4, we compare the worst-case probabilities obtained by the CTMDP algorithm with those from CTMC analysis for N = 4 and N = 128. As evident in the plot, the CTMC analysis consistently overestimates the true probabilities (computed with ETMCC, confirmed with CADP). This is noteworthy because the CTMDP algorithm accounts for the worst-case scenario, and one would expect this probability to be higher than in a corresponding CTMC model. The overestimation in the CTMC approach can be explained as follows: when replacing a non-deterministic selection with high rates, certain paths become possible (albeit with low probability) that would be absent in a non-deterministic interpretation, thus not contributing to the reachability probability. In the CTMC implementation, there are sometimes artificial races between very high rates and ordinary rates, which do not exist in the more accurate interpretation we use.

### Conclusion

This paper introduces a compositional approach to generating and analyzing non-deterministic stochastic systems. Specifically, the paper makes the following contributions:
1. We have developed a sound compositional method to construct uniform IMCs, which are then transformed into uniform CTMDPs. This transformation is shown to preserve path probability measures.
2. We present compelling experimental results for the first implementation of the uniform CTMDP analysis algorithm [2].
3. We discuss how non-determinism affects certain systems, particularly in the fault-tolerant workstation cluster example. Surprisingly, previous studies of this model overestimated the worst-case reachability probabilities, which we were able to compute accurately for the first time.

The experiments demonstrate that both the transformation and the analysis algorithm scale well. Compared to the simpler CTMC case, the time and space requirements are of a similar order for models of similar size. Although our Java prototype performs remarkably well, we are currently porting the algorithm to C++ to integrate it with the MRMC tool [20].

### References

[1] R. B. Ash and C. A. Doléans-Dade. *Probability & Measure Theory*. Academic Press, second edition, 2000.

[2] C. Baier, B. R. Haverkort, H. Hermanns, and J.-P. Katoen. *Efficient Computation of Time-Bounded Reachability Probabilities in Uniform Continuous-Time Markov Decision Processes*. Theor. Comput. Sci., 345(1):2–26, 2005.

[3] A. Bianco and L. de Alfaro. *Model Checking of Probabilistic and Nondeterministic Systems*. FSTTCS, 15, 1995.

[4] E. Böde, M. Herbstritt, H. Hermanns, S. Johr, T. Peikenkamp, R. Pulungan, R. Wimmer, and B. Becker. *Compositional Performability Evaluation for Statemate*. In International Conference on Quantitative Evaluation of Systems (QEST), pages 167–176. IEEE Computer Society, 2006.

[5] CADP. *Project Website*, Aug 2006. http://www.inrialpes.fr/vasy/cadp/demos.html.

[6] M. Calder, V. Vyshemirsky, D. Gilbert, and R. Orton. *Analysis of signalling pathways using continuous time Markov chains*. Transactions on Computational Systems Biology, 2006. To appear.

[7] R. Cleaveland, S. P. Iyer, and M. Narasimha. *Probabilistic temporal logics via the modal mu-calculus*. Theor. Comput. Sci., 342(2-3):316–350, 2005.

[8] L. de Alfaro. *Stochastic Transition Systems*. In International Conference on Concurrency Theory (CONCUR), pages 423–438, 1998.

[9] B. L. Fox and P. W. Glynn. *Computing Poisson probabilities*. Communications of the ACM, 31(4):440–445, 1988.

[10] G. Gallo, G. Longo, S. Pallottino, and S. Nguyen. *Directed hypergraphs and applications*. Discrete Appl. Math., 42(2-3):177–201, 1993.

[11] H. Garavel and H. Hermanns. *On Combining Functional Verification and Performance Evaluation Using CADP*. In Formal Methods Europe (FME), pages 410–429, 2002.

[12] S. Graf, B. Steffen, and G. Lüttgen. *Compositional Minimisation of Finite State Systems Using Interface Specifications*. Formal Asp. Comput., 8(5):607–616, 1996.

[13] B.R. Haverkort, H. Hermanns, and J.-P. Katoen. *On the Use of Model Checking Techniques for Dependability Evaluation*. In Symposium on Reliable Distributed Systems (SRDS’00), pages 228–237. IEEE Computer Society, 2000.

[14] H. Hermanns. *Interactive Markov Chains and the Quest for Quantified Quality*, volume 2428 of LNCS. Springer, 2002.

[15] H. Hermanns and J.-P. Katoen. *Automated compositional Markov chain generation for a plain-old telephone system*. Science of Comp. Programming, 36:97–127, 2000.

[16] H. Hermanns and S. Johr. *Uniformity by Construction in the Analysis of Nondeterministic Stochastic Systems*, 2006. Long version of submission. Available at http://depend.cs.uni-sb.de/~johr/PDS/longV.pdf.

[17] H. Hermanns, J.-P. Katoen, J. Meyer-Kayser, and M. Siegle. *A tool for model-checking Markov chains*. Journal on Software Tools for Technology Transfer (STTT), 4(2):153–172, 2003.

[18] A. Hinton, M. Kwiatkowska, G. Norman, and D. Parker. *PRISM: A Tool for Automatic Verification of Probabilistic Systems*. In TACAS, pages 441–444. Springer, 2006.

[19] A. Jensen. *Markoff Chains as an Aid in the Study of Markoff Processes*. Skandinavisk Aktuarietidsskrift, pages 87–91, March 1953.

[20] J.-P. Katoen, M. Khattri, and I. S. Zapreev. *A Markov Reward Model Checker*. In Quantitative Evaluation of Systems (QEST), pages 243–244. IEEE Computer Society, 2005.

[21] J. G. Kemeny and J. L. Snell. *Finite Markov Chains*. Van Nostrand, 1960.

[22] N.A. Lynch, I. Saias, and R. Segala. *Proving Time Bounds for Randomized Distributed Algorithms*. In Symposium on the Principles of Distributed Computing, pages 314–323, 1994.

[23] M. F. Neuts. *Matrix-Geometric Solutions in Stochastic Models: An Algorithmic Approach*. Dover, 1981.

[24] A. Pogosyants, R. Segala, and N. A. Lynch. *Verification of the Randomized Consensus Algorithm of Aspnes and Herlihy: a Case Study*. In Workshop on Distributed Algorithms (WDAG’97), volume 1320, pages 111–125. Springer-Verlag, 1997.

[25] M. L. Puterman. *Markov Decision Processes: Discrete Stochastic Dynamic Programming*. Wiley, 1994.

[26] M. A. Salsburg, D. Lifka, and R. S. Mitchell. *A Management Framework For Petabyte-Scale Disk Storage*. In Int. CMG Conference, pages 767–782, 2005.

[27] R. Segala. *Modeling and Verification of Randomized Distributed Real-Time Systems*. PhD thesis, Department of Electrical Engineering and Computer Science, MIT, 1995.

[28] R. Segala and N. Lynch. *Probabilistic simulations for probabilistic processes*. Nordic Journal of Computing, 2(2):250–273, 1995.

[29] SVL. *Project Website*, 2006. http://www.inrialpes.fr/vasy/cadp/man/svl.html.

[30] R. J. van Glabbeek and W. P. Weijland. *Branching time and abstraction in bisimulation semantics*. J. ACM, 43(3):555–600, 1996.

[31] N. Wolovick and S. Johr. *A Characterization of Meaningful Schedulers for Continuous-time Markov Decision Processes*. In Formal Modeling and Analysis of Timed Systems (FORMATS), pages 352–367. Springer, 2006.

---

**Note:** The table and figure captions have been left unchanged as they are already clear and concise.