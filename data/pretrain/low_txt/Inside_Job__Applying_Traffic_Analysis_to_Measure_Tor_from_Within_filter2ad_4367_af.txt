### Rendezvous and Circuit Classification

- **Rendezvous / End**: Rendezvous
- **Rendezvous Client / Exit + Rendezvous Client**: Rendezvous Client
- **Rendezvous Service / Exit + Rendezvous Service**: Rendezvous Service
- **Purpose is Rendezvous / Total**: Total
- **SNS Popularity (as % of onion circuits)**: 
  - **Rend. Service to SNS ASN / Rend. Service**: 1.34%
  - **Site is SNS / Total**: 1.45%
- **Direct**:
  - 1.20%
  - 1.20%
  - 1.20%
  - 1.20%
- **Classified**:
  - 4.48%
  - 0.52%
  - 0.02%

The false positive rate was 3.4%, and the true positive and false negative rates for the SNS classifier were 60% and 40%, respectively. These results indicate that our classifiers are functioning as intended. We assert that an adversary who disregards privacy (and does not add noise) could make more precise measurements than those described here.

### Popularity Estimation

We estimate the popularity of the onion service protocol by computing the fraction of middle relay circuits that are rendezvous circuits. Middle relays that do not serve as the rendezvous point on a circuit cannot determine with certainty whether or not the circuit is a rendezvous circuit, but they can predict it using our circuit purpose classifier. Additionally, we measure the popularity of the onion service protocol directly when our relays serve as rendezvous points, allowing us to distinguish client-side and server-side rendezvous circuits from others.

Our popularity estimates are shown in Table IX. The table entries present several ways to estimate popularity, with our classification-based estimates at the bottom of each section. Direct measurement approaches indicate that onion service popularity is between 1% and 1.5% based on circuit counts. For comparison, 0.9% of Tor traffic by volume (i.e., bytes) is onion service traffic (900 Mbit/s out of 100 Gbit/s total) according to Tor metrics. Our classification-based estimate is higher at 4.48%, but this includes noise and an unknown number of false positives. Similarly, our direct measurement of accesses to the SNS onion site front-page is 0.52% of rendezvous service circuits, while our classification-based estimate is 0.02%.

### Discussion

Our laboratory results show that website fingerprinting (WF) at the middle relay position is as effective in terms of recall and precision as has been demonstrated from the guard position in previous works—both for closed- and open-world scenarios. However, our real-world results indicate that the base-rate of the SNS site was too low for our classifier to provide high confidence. Nevertheless, we can confidently state that the popularity of the SNS as an onion service is almost negligible compared to all other onion service circuits. This result was unexpected, as our intuition suggested that the chosen SNS is one of the most popular websites globally. Our findings indicate that a much lower false positive rate—up to two orders of magnitude lower—is necessary for WF to be useful in measuring individual onion sites.

### Conclusion

We have shown that a significant amount of information is leaked to middle relay positions, often overlooked in threat assessments. The design of Tor allows middle relays a wider visibility over all users because clients pick new middle relays for every circuit. Through extensive data collection and experimentation, we have demonstrated that traffic analysis techniques are as effective from internal middle positions as they are from ingress and egress (guard and exit) positions. We have developed a traffic analysis pipeline that can detect a relay’s position in a circuit, the purpose of the circuit, and identify the onion service being accessed. We applied this pipeline to measure the popularity of a well-known social network onion service, making us the first to use these techniques on real Tor user traffic, to the best of our knowledge. Although our measurement results are constrained by resource and ethical concerns, our framework provides a means to study effective mitigation strategies and gather additional measurements.

### Lessons Learned

More progress is needed, and this work provides positive initial steps. We anticipate that classification techniques at middle relay positions will not deteriorate and highlight some challenges for real-world deployment. First, our pipeline reduces the number of circuits processed by the WF classifier, filtering out non-onion service circuits during testing, which significantly reduced overhead and improved results. Careful filtering and data pre-processing are crucial for successful real-world deployments. Second, our measurement was done in real-time, with everything kept in RAM, and we used a low circuit sampling rate of 0.12 due to computational and memory limitations. Real-world scale may overwhelm available resources, necessitating pragmatic compromises. Third, we prioritized user safety in our real-world measurements, resulting in noisy results. Depending on the use-case (e.g., a malicious actor), noise may not be necessary, and removing this requirement could reduce operational overhead and allow higher sampling rates.

### Future Work

Using our current WF classification pipeline, an adversary could target the guards that originate connections to websites of interest (e.g., the SNS). Given the small number of SNS circuits, the set of guards used to access the SNS would also be small. An adversary could reduce the time and cost of a targeting attack by focusing on these specific guards. Some related targeted attacks that depend on our techniques have recently been explored [17].

An alternative approach involves locating the originating client or destination onion service using middle relay network latency measurements. Hopper et al. [16] demonstrate the effectiveness of such attacks from malicious websites. Mapping latency between an adversarial middle and all Tor relays (or at least the most popular ones) [5] would assist in narrowing down the network and geographic location of circuit originators (e.g., to a region or possibly a country).

An adversary could fingerprint protocols instead of websites to target a broader base of users. For example, a censoring regime might fingerprint Tor's pluggable transports (PTs) from the middle relay positions. Fingerprinting PTs from the client-side, which is the current state-of-the-art, has a high false positive rate since PTs are designed to be confused with other protocols that the censor is reluctant to block. In contrast, fingerprinting PTs at a middle does not provide this confusion, as only Tor traffic is present in the Tor network. Assuming the censor already has the ability to identify users on the client-side, the incidence of false positives in detecting PT circuits could be greatly reduced. Furthermore, using timing correlations between client-side observations could also identify PT users, and an adversary could use our fingerprinting techniques to identify which websites PT users visit.

### Acknowledgments

We thank the anonymous reviewers for their helpful feedback. We also thank Roger Dingledine from the Tor Research Safety Board for providing feedback that helped to make our measurement safer and more transparent. We are grateful to Tim Wilson-Brown for suggesting the direct measurement of the SNS, implementing much of the Tor and PrivCount code we used, and for his helpful suggestions and feedback on our approach. We also thank Tim Wilson-Brown and Matt Traudt for operating Tor relays and PrivCount nodes as part of our PrivCount deployment.

This work has been partially supported by the Defense Advanced Research Project Agency (DARPA) and the National Science Foundation (NSF) under grant number CNS-1527401. It is also based upon work supported by the European Commission through KU Leuven BOF OT/13/070, H2020-DS-2014-653497 PANORAMIX, and H2020-ICT-2014-644371 WITDOM. Juarez is supported by a PhD fellowship of the Fund for Scientific Research - Flanders (FWO), and Elahi is supported by NSERC through a Postdoctoral Fellowship Award, the Research Council KU Leuven: C16/15/058. The views expressed in this work are strictly those of the authors and do not necessarily reflect the official policy or position of any employer or funding agency.

### References

[1] “TC: A Tor control protocol (Version 1),” https://gitweb.torproject.org/torspec.git/tree/control-spec.txt.
[2] A. Biryukov, I. Pustogarov, F. Thill, and R.-P. Weinmann, “Content and popularity analysis of Tor hidden services,” in International Conference on Distributed Computing Systems Workshops, 2014.
[3] A. Biryukov, I. Pustogarov, and R.-P. Weinmann, “Trawling for Tor Hidden Services: Detection, Measurement, Deanonymization,” in Symposium on Security and Privacy, 2013.
[4] X. Cai, X. C. Zhang, B. Joshi, and R. Johnson, “Touching from a Distance: Website Fingerprinting Attacks and Defenses,” in Conference on Computer and Communications Security, 2012.
[5] F. Cangialosi, D. Levin, and N. Spring, “Ting: Measuring and exploiting latencies between all tor nodes,” in Internet Measurement Conference, 2015.
[6] G. Cherubin, J. Hayes, and M. Juarez, “Website Fingerprinting Defenses at the Application Layer,” in Proceedings on Privacy Enhancing Technologies, 2017.
[7] R. Dingledine, N. Hopper, G. Kadianakis, and N. Mathewson, “One fast guard for life (or 9 months),” in Workshop on Hot Topics in Privacy Enhancing Technologies, 2014.
[8] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: The Second-Generation Onion Router,” in USENIX Security Symposium, 2004.
[9] C. Dwork, “Differential privacy,” in International Colloquium on Automata, Languages and Programming, 2006.
[10] K. Dyer, S. Coull, T. Ristenpart, and T. Shrimpton, “Peek-a-Boo, I Still See You: Why Efficient Traffic Analysis Countermeasures Fail,” in Symposium on Security and Privacy, 2012.
[11] T. Elahi, G. Danezis, and I. Goldberg, “Privex: Private collection of traffic statistics for anonymous communication networks,” in Conference on Computer and Communications Security, 2014.
[12] N. S. Evans, R. Dingledine, and C. Grothoff, “A practical congestion attack on tor using long paths.” in USENIX Security Symposium, 2009.
[13] D. Goulet, A. Johnson, G. Kadianakis, and K. Loesing, “Hidden-service statistics reported by relays,” Tor Project, Tech. Rep., April 2015.
[14] J. Hayes and G. Danezis, “k-fingerprinting: a Robust Scalable Website Fingerprinting Technique,” in USENIX Security Symposium, 2016.
[15] D. Herrmann, R. Wendolsky, and H. Federrath, “Website Fingerprinting: Attacking Popular Privacy Enhancing Technologies with the Multinomial Naïve-Bayes Classifier,” in Workshop on Cloud Computing Security, 2009.
[16] N. Hopper, E. Y. Vasserman, and E. Chan-Tin, “How much anonymity does network latency leak?” Transactions on Information and System Security, vol. 13, no. 2, 2010.
[17] A. D. Jaggard and P. Syverson, “Onions in the Crosshairs: When The Man really is out to get you,” in Workshop on Privacy in the Electronic Society, 2017.
[18] R. Jansen and N. Hopper, “Shadow: Running Tor in a box for accurate and efficient experimentation,” in Network and Distributed System Security Symposium, 2012.
[19] R. Jansen and A. Johnson, “Safely Measuring Tor,” in Conference on Computer and Communications Security, 2016.
[20] M. Juarez, S. Afroz, G. Acar, C. Diaz, and R. Greenstadt, “A Critical Analysis of Website Fingerprinting Attacks,” in Conference on Computer and Communications Security, 2014.
[21] M. Juarez, M. Imani, M. Perry, C. Diaz, and M. Wright, “Toward an efficient website fingerprinting defense,” in European Symposium on Research in Computer Security, 2016.
[22] A. Kwon, M. AlSabah, D. Lazar, M. Dacier, and S. Devadas, “Circuit fingerprinting attacks: passive deanonymization of tor hidden services,” in USENIX Security Symposium, 2015.
[23] P. Mittal, A. Khurshid, J. Juen, M. Caesar, and N. Borisov, “Stealthy traffic analysis of low-latency anonymous communication using throughput fingerprinting,” in Conference on Computer and Communications Security, 2011.
[24] S. J. Murdoch and G. Danezis, “Low-cost traffic analysis of tor,” in Symposium on Security and Privacy, 2005.
[25] R. Overdorf, M. Juarez, G. Acar, R. Greenstadt, and C. Diaz, “How Unique is Your .onion? An Analysis of the Fingerprintability of Tor Onion Services,” in Conference on Computer and Communications Security, 2017.
[26] A. Panchenko, F. Lanze, A. Zinnen, M. Henze, J. Pennekamp, K. Wehrle, and T. Engel, “Website Fingerprinting at Internet Scale,” in Network and Distributed System Security Symposium, 2016.
[27] A. Panchenko, A. Mitseva, M. Henze, F. Lanze, K. Wehrle, and T. Engel, “Analysis of Fingerprinting Techniques for Tor Hidden Services,” in Workshop on Privacy in the Electronic Society, 2017.
[28] A. Panchenko, L. Niessen, A. Zinnen, and T. Engel, “Website Fingerprinting in Onion Routing Based Anonymization Networks,” in Workshop on Privacy in the Electronic Society, 2011.
[29] T. Wang, X. Cai, R. Nithyanand, R. Johnson, and I. Goldberg, “Effective Attacks and Provable Defenses for Website Fingerprinting,” in USENIX Security Symposium, 2014.
[30] T. Wang and I. Goldberg, “Improved Website Fingerprinting on Tor,” in Workshop on Privacy in the Electronic Society, 2013.
[31] ——, “On Realistically Attacking Tor with Website Fingerprinting,” in Proceedings on Privacy Enhancing Technologies, 2016.