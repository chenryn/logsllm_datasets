### Comparison to Previous Work

Table 4 compares the performance of McBoost with the approach proposed by Kolter et al. [9], referred to as KM. We implemented the classifier described in [9] and set the same parameter values, such as the number of features to be selected, as suggested in the paper. Both McBoost and KM were trained using 80% of the PMDset and NPMDset for malware, and 80% of BDset for benign data. The test set consisted of 20% of PBDset (packed benigns) and NPMDset (non-packed malware).

The results in Table 4 confirm that KM is biased towards detecting packed executables as malware and non-packed executables as benign, regardless of the actual nature of the code. In contrast, McBoost maintains an accuracy of 87% and an AUC of 0.93, even on a challenging dataset.

### 3.4 Discussion of the Results

The most significant result is the AUC of McBoost, which is 0.977 in our experiments. The AUC can be interpreted as the probability of scoring a malware executable higher than a benign one, P(malware|e). Since our system is designed to prioritize the analysis of the most suspicious binaries, a high AUC value (close to 1) is more important than accuracy, which depends on prior class probabilities and detection thresholds.

### Utility of McBoost

McBoost's utility is evident in scenarios where a large set of executables needs to be analyzed, such as those downloaded from P2P networks or web crawlers. After filtering out known malware using signature-based AV software, the remaining dataset is likely to contain mostly benign executables and a small fraction of unknown malware. Given that non-packed executables can be classified in about 1.06 seconds on average, McBoost allows us to quickly filter out most benign executables, which will receive a low P(malware|e) score and thus a low rank. This process is much more efficient compared to existing approaches that require running each unknown executable through an unpacker and/or program analyzer, which can take several minutes per executable.

### Time Savings

The total processing time for validating McBoost using 4,330 executables (3,830 malware and 503 benign) was approximately 195 hours (about 8 days). Processing all 4,330 samples directly with our dynamic unpacker would have taken about 347 hours (nearly 14.5 days). Therefore, McBoost required only 56.2% of the time compared to using dynamic binary analysis tools. If the dataset contained 85% non-packed benigns, 2% packed benigns, and 13% unknown malware, McBoost would require only around 13.4% of the time compared to using dynamic binary analysis tools.

### 4 Related Work

- **Polyunpack** [16]: Royal et al. proposed Polyunpack, a universal unpacker that combines static and dynamic binary analysis to reconstruct hidden code.
- **Renovo** [8]: Kang et al. introduced Renovo, a more effective tool for universal unpacking using dynamic binary analysis, capable of distinguishing between different layers of unpacking.
- **Data Mining Techniques** [17]: Shultz et al. used data mining techniques to detect new malicious executables by extracting features such as DLLs, function calls, and system calls.
- **N-gram Analysis** [9, 15, 25]: Kolter et al. [9] used n-gram analysis to distinguish between malware and benign executables but did not account for packed versus non-packed executables. Our approach, McBoost, first classifies executables as packed or non-packed, then extracts and classifies the hidden or non-packed code.

### 5 Conclusion

We presented McBoost, a fast statistical malware detection tool designed to improve the scalability of malware collection and analysis. McBoost can quickly and accurately filter out benign executables, allowing for the prioritization of detailed analysis of suspicious binaries. Our evaluation showed that McBoost has an overall classification accuracy of 87.3% and an AUC of 0.977, significantly reducing the computational time needed for analyzing large sets of executables.

### References

[1] F. Bellard. Qemu, a fast and portable dynamic translator. In USENIX Annual Technical Conference, 2005.

[2] D. Bilar. Opcode as predictors for malware. International Journal of Electronic Security and Digital Forensics, 1(2), 2007.

[3] L. Breiman. Bagging predictors. Machine Learning, 24(2):123–140, 1996.

[4] T. Brosch and M. Morgenstern. Runtime packers: The hidden problem? Presented at Black Hat USA 2006.

[5] C. Cortes and M. Mohri. Confidence intervals for the area under the ROC curve. In NIPS 2004: Advances in Neural Information Processing Systems, 2004.

[6] R. Duin. The combining classifier: to train or not to train? In International Conference on Pattern Recognition (ICPR), 2002.

[7] A. Kalafut, A. Acharya, and M. Gupta. A study of malware in peer-to-peer networks. In ACM SIGCOMM conference on Internet measurement, 2006.

[8] M. G. Kang, P. Poosankam, and H. Yin. Renovo: A hidden code extractor for packed executables. In WORM ’07: Proceedings of the 5th ACM Workshop on Recurring Malcode, 2007.

[9] J. Z. Kolter and M. A. Maloof. Learning to detect and classify malicious executables in the wild. Journal of Machine Learning Research, 7:2721–2744, 2006.

[10] L. I. Kuncheva. Combining Pattern Classifiers: Methods and Algorithms. Wiley-Interscience, 2004.

[11] A. Niculescu-Mizil and R. Caruana. Predicting good probabilities with supervised learning. In International Conference on Machine Learning (ICML), 2005.

[12] R. Perdisci, G. Gu, and W. Lee. Using an ensemble of one-class SVM classifiers to harden payload-based anomaly detection systems. In International Conference on Data Mining (ICDM), 2006.

[13] R. Perdisci, A. Lanzi, and W. Lee. Classification of packed executables for accurate computer virus detection. Pattern Recognition Letters, 29(14):1941–1946, 2008.

[14] M. B. Prince, L. Holloway, E. Langheinrich, B. M. Dahl, and A. M. Keller. Understanding how spammers steal your email address: An analysis of the first six months of data from project honey pot. In 2nd Conference on Email and Anti-Spam (CEAS), 2005.

[15] D. K. S. Reddy and A. K. Pujari. N-gram analysis for computer virus detection. Journal in Computer Virology, 2(3), 2006.

[16] P. Royal, M. Halpin, D. Dagon, R. Edmonds, and W. Lee. Polyunpack: Automating the hidden-code extraction of unpack-executing malware. In Annual Computer Security Applications Conference (ACSAC), 2006.

[17] M. G. Schultz, E. Eskin, E. Zadok, and S. J. Stolfo. Data mining methods for detection of new malicious executables. In IEEE Symposium on Security and Privacy, 2001.

[18] A. Shevchenko. The evolution of self-defense technologies in malware, 2007. http://www.viruslist.com/analysis?pubid=204791949.

[19] S. Shin, J. Jung, and H. Balakrishnan. Malware prevalence in the Kazaa file-sharing network. In ACM SIGCOMM Conference on Internet measurement, 2006.

[20] A. Stepan. Improving proactive detection of packed malware, March 2006. http://www.virusbtn.com/virusbulletin/archive/2006/03/vb200603-packed.dkb.

[21] Y. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski, S. Chen, and S. T. King. Automated web patrol with Strider HoneyMonkeys: Finding websites that exploit browser vulnerabilities. In NDSS, 2006.

[22] T. Werner. PE Hunter, 2007. http://honeytrap.mwcollect.org/pehunter.

[23] Y. Yang and J. O. Pedersen. A comparative study on feature selection in text categorization. In International Conference on Machine Learning (ICML), 1997.

[24] H. Yin, D. Song, M. Egele, C. Kruegel, and E. Kirda. Panorama: Capturing system-wide information flow for malware detection and analysis. In CCS ’07: 14th ACM conference on Computer and communications security, 2007.

[25] B. Zhang, J. Yin, J. Hao, D. Zhang, and S. Wang. Malicious codes detection based on ensemble learning. In Autonomic and Trusted Computing (ATC), 2007.

[26] J. Zhuge, T. Holz, X. Han, C. Song, and W. Zou. Collecting autonomous spreading malware using high-interaction honeypots. In ICICS 2007, 2007.