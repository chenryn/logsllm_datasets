### Attack Experiments on the Graph

We conducted this attack under various conditions, adding between 10 and 100 edges to the graph. The events to which we connected the incidents were selected based on both black-box policies (random selection of secondary indicators) and white-box policies (where the attacker has knowledge of event confidence and relevance rankings). These experiments were performed on both confidence-weighted and uniformly-weighted graphs.

#### Counter-Intuitive Results

A surprising result from our experiments was that adding noise to security incidents increased their overall ranking, regardless of the graph’s weighting scheme. One such adversarial experiment is shown in Figure 9, where we assumed adversaries would attach their incident to 100 security events, randomly selected from the 10% least relevant events in the confidence-weighted graph. This figure contrasts the results of doing so on Smoke Detector's classification accuracy, finding that adding edges only increases performance relative to the non-adversarial setting. Our experiments have shown that this effect is not due to multiple nodes being attacked simultaneously, as adding edges to a single incident also increases its rank relative to other machine-windows.

#### Reason for Noise-Based Attack Failure

The reason the noise-based attack fails is that adding edges to a machine-window node increases the number of its incoming edges. These additional edges allow event nodes to communicate their relevance to the machine-window, resulting in a net positive effect on the node’s ranking. This is because there is no normalization among a machine-window’s incoming edges, leading to a net positive effect on the machine’s relevance, even if these additional edges come from events with low, but positive, relevance. Since there is a path between each security event and at least one incident in the graph, all events receive a positive relevance.

### Limitations of the Attack

This class of attacks has several limitations:

1. **Event Frequency Handling**: Smoke Detector treats a single instance of an event in a machine-window no differently than millions of instances of the same event in that window. Therefore, successful attacks require controlling many machines across multiple networks over a long period, which is costly and increases the probability of detection.

2. **Model Inversion Attacks**: These attacks depend on feedback from the model. However, this risk can be mitigated by providing limited precision in the confidence scores shared with customers and by sorting events alphabetically by name rather than by rank when they have tied limited-precision scores.

3. **Training-Set Attacks**: Effective training-set attacks on Smoke Detector would need to reduce the score of highly indicative events by triggering them many times without raising a security incident. This is difficult and could result in the blacklisting or loss of control of attacker-controlled machines.

4. **Control of Machines**: Adversaries are more likely to control external machines rather than enterprise-owned machines in sufficient numbers for an attack. However, only internal machines can trigger events produced by endpoint-protection products, making training-set attacks on anti-virus events, for example, difficult to carry out.

### Summary

While these attacks do not cover all possible scenarios, Smoke Detector has important properties that make it a difficult target for adversaries. These include its ability to capture high-order relationships, the relative inaccessibility of its model to concerted model inversion attempts, and its basis in big data, which forces attackers to perform large-scale attacks.

### Figure 9: Detection Rates in an Adversarial Setting

Figure 9 shows Smoke Detector’s detection rates in an adversarial setting where the attacker adds noise to the incidents in the confidence-weighted graph. The attack fails as new edges further increase the relevance of the incidents.

### Altering the Graph and Its Weights

We now consider adversaries who control at least one machine in addition to the machine-window on which they hope to evade detection. They seek to modify Smoke Detector’s training data, a daunting task given that MSSPs use big data systems comprising trillions of event instances across tens of millions of machine windows, each protected by its own sensor net of security devices. Attacks are most likely to try to cause the rank of the primary attack’s machine-window to drop into a range that has many false positives by lowering the relevance of the events connected to the primary attack’s machine-window.

### Related Work

Much of the prior art in intrusion detection analyzes large collections of similar events to alert on a subset of malicious instances. By contrast, Smoke Detector consumes raw event data intermixed with the alerts generated by the prior art, treating events of different types as distinct entities of varying reliability. The prior art discussed includes techniques for event scoring, alert fusion, alert correlation, and root-cause analysis, among others.

#### M-Correlator

M-Correlator [23] assigns priority scores to security events based on context, such as the importance and vulnerability of targeted assets. When such data is available, it should be used and would enable an approach based on M-Correlator to prioritize Smoke Detector incidents, whose event scores represent infection confidence rather than severity.

#### Beehive

Beehive [34] provides important techniques for normalizing and correlating the events provided by diverse collections of security products, allowing anomaly detection algorithms and blacklists to be applied effectively. Smoke Detector makes no attempt to identify anomalies in event types that would otherwise attract attention, as Beehive does, and would instead consume Beehive’s detected anomalies as separate events.

#### Alert Correlation and Clustering

Alert correlation and clustering techniques bear similarity to Smoke Detector in their study of the relationships between different types of alerts. However, many of these methods strive to promote understanding and root-cause analysis for existing incidents [22, 24, 31] rather than detect new incidents. Julisch [14] summarizes large volumes of event data for human consumption, so that anomalous events stand out to an analyst. Viinikka et al. [33] and Valdes and Skinner [29] reduce alerts into aggregate “meta-alerts” for ease of consumption. These techniques are valuable but are not designed for a SIEM or MSSP setting, where events vary widely in nature and quality.

#### Alert Fusion

Alert Fusion refers to the problem of determining whether to output an alert based on the result of multiple IDS models trained over a common dataset of event logs [2, 10, 25, 26], such as the DARPA 2000 dataset [17]. These techniques are not designed for underlying datasets as diverse as those of SIEMs and MSSPs.

#### Expert Systems for Intrusion Detection

Many expert systems for intrusion detection build on P-BEST’s seminal algorithm [18], which provides an inference language to detect misuse and anomalies through production rules. While similar techniques are deployed by SIEMs and MSSPs today, these techniques are costly to maintain due to constant changes in the underlying events being collected and monitored. In Section 7, we evaluate Smoke Detector against an MSSP of this type. Buckzak and Guven [3] describe many applications of Machine Learning and Data Mining to intrusion detection, from which Smoke Detector differs in its use of a graphical model, which models relationships between known incidents, events, and candidate incidents.

### Conclusion

We presented Smoke Detector, an intrusion detection system designed for the challenges faced by MSSPs and SIEMs, including huge data volumes, diverse event types of greatly varying quality, and continual event churn. We showed that Smoke Detector increases the volume of detected critical incidents by 19% at a 1.3% False Positive rate. Its confidence scores provide intuition and a tuning mechanism for Random Walk with Restart (RWR). Our implementation of the RWR algorithm scales linearly with the size of the data and works well in a distributed system on commodity hardware. To the best of our knowledge, our use of RWR represents the first use of this algorithm for computer security applications other than in the context of security for social networks [37].

### Acknowledgments

Thanks to Lenore Zuck and Zhongkai Wen for helpful discussions on improving this paper. Thanks to Daniel Whalen for providing feedback on the Smoke Detector algorithm and its detections.

### References

[1] Amazon. 2017. Amazon S3. https://aws.amazon.com/s3/. (2017). Accessed: 2017-06-08.
[2] Tim Bass. 2000. Intrusion Detection Systems and Multisensor Data Fusion. Commun. ACM 43, 4 (April 2000), 95–105.
[3] A. L. Buczak and E. Guven. 2016. A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection. IEEE Communications Surveys Tutorials 18, 2 (Secondquarter 2016), 1153–1176. DOI: http://dx.doi.org/10.1109/COMST.2015.2494502
[4] George Casella. 1985. An Introduction to Empirical Bayes Data Analysis. The American Statistician 39, 2 (May 1985), 83–87.
[5] Paul Cichonski, Tom Millar, Tim Grance, and Karen Scarfone. 2012. Computer Security Incident Handling Guide. NIST Special Publication 800-61 Rev 2 (August 2012).
[6] Dan Claudiu Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and Jürgen Schmidhuber. 2011. Flexible, high performance convolutional neural networks for image classification. In International Joint Conference on Artificial Intelligence (IJCAI).
[7] Dumitru Erhan, Christian Szegedy, Alexander Toshev, and Dragomir Anguelov. 2014. Scalable object detection using deep neural networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2147–2154.
[8] Matthew Fredrikson, Somesh Jha, and Thomas Ristenpart. 2015. Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures. In ACM Conference on Computer and Communications Security (CCS). Tokyo, Japan.
[9] Leo Grady. 2006. Random walks for image segmentation. IEEE transactions on pattern analysis and machine intelligence 28, 11 (2006), 1768–1783.
[10] Guofei Gu, Alvaro A. Cardenas, and Wenke Lee. 2008. Principled Reasoning and Practical Applications of Alert Fusion in Intrusion Detection Systems. In ACM Symposium on InformAction, Computer and Communications Security (ASIACCS). Tokyo, Japan.
[11] Taher Haveliwala. 1999. Efficient computation of PageRank. Technical Report.
[12] Fred Hohman, Nathan Hodas, and Duen Horng Chau. 2017. ShapeShop: Towards Understanding Deep Learning Representations via Interactive Experimentation. In 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 1694–1699.
[13] Forrest N Iandola, Matthew W Moskewicz, Khalid Ashraf, and Kurt Keutzer. 2016. FireCaffe: near-linear acceleration of deep neural network training on compute clusters. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2592–2600.
[14] Klaus Julisch. 2003. Clustering Intrusion Detection Alarms to Support Root Cause Analysis. ACM Transactions on Information Systems Security 6, 4 (Nov. 2003), 443–471. DOI: http://dx.doi.org/10.1145/950191.950192
[15] Minsuk Kahng, Pierre Andrews, Aditya Kalro, and Duen Horng Chau. 2017. ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models. arXiv preprint arXiv:1704.01942 (2017).
[16] Kaspersky Lab. 2015. Denial of Service: How Businesses Evaluate the Threat of DDoS Attacks. IT Security Risks Special Report Series (September 2015), 7.
[17] MIT Lincoln Laboratory. 2000. DARPA Intrusion Detection Scenario Specific Data Sets. https://www.ll.mit.edu/ideval/data/2000data.html. (2000).
[18] Ulf Lindqvist and Phillip A. Porras. 1999. Detecting Computer and Network Misuse Through the Production-Based Expert System Toolset (P-BEST). In International Symposium on Security and Privacy (SP). Oakland, CA.
[19] David Miller, Shon Harris, Allen Harper, Stephen VanDyke, and Chris Blask. 2010. Security Information and Event Management (SIEM) Implementation (1st ed.). McGraw Hill Education.
[20] P. O’Kane, S. Sezer, and K. McLaughlin. 2011. Obfuscation: The Hidden Malware. (May 2011), 41–47.
[21] Jia-Yu Pan, Hyung-Jeong Yang, Christos Faloutsos, and Pinar Duygulu. 2004. Automatic multimedia cross-modal correlation discovery. In ACM SIGKDD international conference on Knowledge Discovery and Data Mining (KDD). ACM, 653–658.
[22] Roberto Perdisci, Giorgio Giacinto, and Fabio Roli. 2006. Alarm Clustering for Intrusion Detection Systems in Computer Networks. Engineering Applied Artificial Intelligence 19, 4 (June 2006), 429–438. DOI: http://dx.doi.org/10.1016/j.engappai.2006.01.003
[23] Phillip A. Porras, Martin W. Fong, and Alfonso Valdes. 2002. A Mission-Impact-Based Approach to INFOSEC Alarm Correlation. In International Symposium on Recent Advances in Intrusion Detection (RAID). Zurich, Switzerland, 95–114.
[24] Alireza Sadighian, José M. Fernandez, Antoine Lemay, and Saman T. Zargar. 2014. ONTIDS: A Highly Flexible Context-Aware and Ontology-Based Alert Correlation Framework. Springer International Publishing, Cham, 161–177. DOI: http://dx.doi.org/10.1007/978-3-319-05302-8_10
[25] A. Sadighian, S. T. Zargar, J. M. Fernandez, and A. Lemay. 2013. Semantic-based context-aware alert fusion for distributed Intrusion Detection Systems. In 2013 International Conference on Risks and Security of Internet and Systems (CRiSIS). 1–6. DOI: http://dx.doi.org/10.1109/CRiSIS.2013.6766352
[26] Mallikarjun Shankar, Nageswara Rao, and Stephen Batsell. 2003. Fusing Intrusion Data for Detection and Containment. In IEEE Military Communications Conference (MILCOM). Ontario, Canada.
[27] Jimeng Sun, Huiming Qu, Deepayan Chakrabarti, and Christos Faloutsos. 2005. Relevance search and anomaly detection in bipartite graphs. ACM SIGKDD Explorations Newsletter 7, 2 (2005), 48–55.
[28] Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast Random Walk with Restart and Its Applications. In International Conference on Data Mining (ICDM). IEEE Computer Society, Washington, DC, USA, 613–622. DOI: http://dx.doi.org/10.1109/ICDM.2006.70
[29] Alfonso Valdes and Keith Skinner. 2001. Probabilistic Alert Correlation. In International Symposium on Recent Advances in Intrusion Detection (RAID). Davis, CA.
[30] Fredrik Valeur, Giovanni Vigna, Christopher Kruegel, and Richard A. Kemmerer. 2004. A Comprehensive Approach to Intrusion Detection Alert Correlation. IEEE Transactions on Dependable Secure Computing 1, 3 (July 2004), 146–169. DOI: http://dx.doi.org/10.1109/TDSC.2004.21
[31] Fredrik Valeur, Giovanni Vigna, Christopher Kruegel, and Richard A. Kemmerer. 2004. A Comprehensive Approach to Intrusion Detection Alert Correlation. IEEE Transactions on Dependable Secure Computing 1, 3 (July 2004), 146–169. DOI: http://dx.doi.org/10.1109/TDSC.2004.21
[32] Vincent Vanhoucke, Andrew Senior, and Mark Z Mao. 2011. Improving the speed of neural networks on CPUs. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning, Vol. 1. 4.
[33] Jouni Viinikka, Hervé Debar, Ludovic Mé, and Renaud Séguier. 2006. Time Series Modeling for IDS Alert Management. In ACM Symposium on Information, Computer and Communications Security (ASIACCS). ACM, New York, NY, USA, 102–113. DOI: http://dx.doi.org/10.1145/1128817.1128835
[34] Ting-Fang Yen, Alina Oprea, Kaan Onarlioglu, Todd Leetham, William Robertson, Ari Juels, and Engin Kirda. Beehive: Large-Scale Log Analysis for Detecting Suspicious Activity in Enterprise Networks. In Annual Computer Security Applications Conference (ACSAC).
[35] Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma, Murphy McCauley, Michael J Franklin, Scott Shenker, and Ion Stoica. Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing. In USENIX conference on Networked Systems Design and Implementation (NSDI).
[36] Chao Zhang, Shan Jiang, Yucheng Chen, Yidan Sun, and Jiawei Han. 2015. Fast inbound top-k query for random walk with restart. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD). Springer, 608–624.
[37] Ziming Zhao, Gail-Joon Ahn, Hongxin Hu, and Deepinder Mahi. 2012. SocialImpact: Systematic Analysis of Underground Social Dynamics. In European Symposium on Research in Computer Security (ESORICS).

---

This version of the text is more coherent, professional, and structured, with clear headings and improved readability.