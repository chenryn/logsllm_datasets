# Partially Specified Channels: The TLS 1.3 Record Layer without Elision

**Authors: Christopher Patton and Thomas Shrimpton**

The proceedings version of this paper appears at CCS '18. This is the full version.

## Abstract

We advance the study of secure stream-based channels (Fischlin et al., CRYPTO '15) by considering the multiplexing of multiple data streams over a single channel, a key feature of real-world protocols such as TLS. Our approach adopts the definitional perspective of Rogaway and Stegers (CSF '09), which provides an elegant way to reason about what standardizing documents actually provide: a partial specification of a protocol that allows for a collection of compliant, fully realized implementations. We formalize partially specified channels as the component algorithms of two parties communicating over a channel. Each algorithm has an oracle that provides specification details; the algorithms abstract the aspects that must be explicitly specified, while the oracle abstracts the aspects that need not be. Our security notions, which capture various privacy and integrity goals, allow the adversary to respond to these oracle queries. Security relative to these notions implies that the channel withstands attacks in the presence of worst-case (i.e., adversarial) realizations of the specification details. We apply this framework to a formal treatment of the TLS 1.3 record layer and show that its security hinges crucially on details left unspecified by the standard.

## 1. Introduction

As protocols such as TLS [32], SSH [37], IPSec [23], and QUIC [21] have evolved, so have the formal tools used to analyze them. Often, it is the protocol standards themselves, rather than fully realized implementations, that inspire and guide mathematical abstractions of these protocols. However, their complexity makes the task of developing these abstractions challenging and prone to missing subtle attacks. Much of this complexity stems from the fact that protocols are only partially specified. The TLS 1.3 standard [30], whose record layer mechanism is the subject of this paper, contains numerous "SHOULDs," "SHOULD NOTs," and "MAYs." These provide guidelines but not rules (which are "MUSTs" and "MUST NOTs") for compliant realizations of the standard. Additionally, like other protocol standards, TLS 1.3 leaves many implementation details unspecified. Thus, the standard describes a collection of implementations that share a core set of behaviors.

Standards are not more explicit and prescriptive for good reasons. To be broadly adopted, they need to be flexible in the face of various deployment concerns, such as backward compatibility, interoperability with other protocols, and limitations of existing infrastructure. They also need to balance performance with security and account for competing (and often conflicting) interests of stakeholders. However, this need for flexibility presents an important challenge to provable security: deciding which of the standard's guidelines and unspecified implementation details are relevant to security and should be captured in the model.

The implications of these modeling choices are often clear only after an attack is found, leading to what Degabriele et al. [16] call the model-attack-remodel cycle. A prominent example is the case of padding-oracle attacks. The MAC-then-encode-then-encrypt construction, used to provide authenticated encryption in many early secure channel protocols, is provably secure [28], but only in a model where decryption does not surface distinguishable errors. Yet, compliant implementations of these protocols did make visible the cause of decryption failures (whether the encoding was invalid or the MAC was incorrect), leading to plaintext-recovery attacks [36, 17, 27]. The research community reacted by incorporating distinguishable errors into updated models [14, 19], but left more subtle attack vectors unaddressed [3], leading in turn to more sophisticated models [22, 6]. This reactive evolution of the adversarial model is to be expected. However, since standards only partially specify the protocol, it is hard to anticipate where vulnerabilities might arise in implementations.

This work explores a definitional viewpoint that may help us be more proactive by making explicit in the security model which parts of the protocol are fully specified and which are not. Concretely, our goal is to establish the security of the TLS 1.3 record layer [32], which (partially) specifies how plaintext and ciphertext data are formatted, encrypted, and transmitted from sender to receiver. To this end, we formalize a new primitive called a partially specified channel.

### Modeling the TLS 1.3 Record Layer

Our model starts with the stream-based channel abstraction introduced by Fischlin et al. [19] (hereafter FGMP). The FGMP syntax for stream-based channels accurately captures the interfaces exposed by real secure-channel implementations by treating the sender- and receiver-side inputs and outputs as streams of fragments, rather than atomic messages. (It also admits distinguishable error messages.) We augment their syntax to account for the multiplexing of many data streams over the same channel, an essential feature of many secure channel protocols, including TLS 1.3. Although this protocol is our focus, we expect our syntax to be applicable to the authenticated encryption mechanisms in other protocols, such as SSH, IPSec, QUIC, and DTLS [31].

We extend the FGMP notions of privacy and integrity to this setting. There are two main flavors of privacy: the first, PRIV-S, is analogous to indistinguishability under chosen-plaintext attack, as the adversary only controls the sender's inputs; in the second, PRIV-SR, we also allow the adversary to mount chosen-ciphertext fragment attacks. With each of these, we consider different "degrees" of privacy corresponding to various security goals considered in prior works [28, 19, 18]. For integrity, we formalize two notions: integrity of ciphertext streams (INT-CS) and plaintext streams (INT-PS). Following FGMP, we show how to achieve PRIV-SR security from a scheme that is both PRIV-S and INT-CS secure; just as with FGMP, we will need an additional property called status simulatability (SIM-STAT). Our notions are applicable to settings where reliable transport (e.g., via TCP) is expected, and the failure of the underlying transport mechanism to deliver stream fragments in order is deemed an attack (as in TLS and SSH).

A number of implementation details not specified by TLS 1.3 are relevant in the adversarial model of FGMP. For example, there are explicit rules governing how plaintext fragments are buffered and coalesced into atomic plaintext records, but the specification leaves many design choices up to the implementation. To establish the security of the record layer in this setting, we first need to determine how to reason about these missing pieces. To do so, we apply the partially specified protocol approach of Rogaway and Stegers [33] (RS) to the study of secure channels. Loosely speaking, a partially specified channel (PSC) consists of named algorithms for the sender and receiver operations, each taking a specification details (SD) oracle. The algorithms form the cryptographic core of the secure channel and must be realized precisely; everything that is not explicitly part of the cryptographic core is handled by the oracle. Crucially, in our security notions, it is the adversary itself who services calls to the SD-oracle. Thus, a proof of security for a particular PSC implies that all details swept into the SD-oracle are irrelevant with respect to these definitions; they can be implemented to behave in an adversarial manner without concern.

### Our Results

We found this definitional viewpoint to be a useful tool for determining which pieces of the record layer specification are security-critical and which are not. In particular, our formal treatment of the record layer uncovers two subtle and security-critical matters. First, the degree of privacy the record layer can provably provide depends intrinsically on the unspecified details (Theorem 2). The record layer is used to multiplex distinct plaintext streams over the same channel; thus, each record has a content type that associates the content with its stream. The content type is encrypted along with the content, permitting implementations that, at least in principle, hide both the content and its type. This is laudable, but the specification admits implementations that leak the content type entirely. Roughly speaking, this leakage occurs because the boundaries between records depend on the content types of each record. In general, we can conclude only that the record layer ensures privacy of the contents of each of the data streams. (We make this point precise in Section 5.)

Second, following FGMP, our notion of ciphertext-stream integrity implies that the receiver only consumes the stream produced by the sender. Records written to the channel are delimited by strings called record headers, whose values are specified by the standard. These bits are not authenticated, and the standard does not require the receiver to check that their values are correct; thus, the record layer cannot achieve our strong notion of ciphertext-stream integrity. But intuitively, the value of these bits should not impact security. Our framework provides a clean way to reconcile this intuition with our model: we show that the value of these bits is indeed irrelevant if and only if they are authenticated (Theorem 3).

Our analysis applies to draft 23 [32], which was current at the time of writing. We shared our findings with the IETF working group responsible for standardizing TLS 1.3, and the specification was updated so that the record header is authenticated. This change appears in the final version of the standard [30].

### Roadmap of the Paper

The next section motivates our analytical framework, putting it in context with prior work on secure channels and partially specified protocols. Section 3 outlines additional related work on TLS. In Section 4, we formulate our syntax and adversarial model and define our notions of privacy (Section 4.2) and integrity (Section 4.3). Section 5 presents our formal treatment of the record layer and discusses some limitations of our model with respect to TLS. We conclude in Section 6 with directions for future work.

### 1.1 Revision History

Note the following changes from the proceedings version of this paper [29]:

1. **2020/04/03**: Revise the record layer specification (Figure 7; cf. [29, Figure 4]) and the statement of Theorem 4. The original proof of Theorem 4 contained an error in the transition from game 3 to game 4. To patch it, minor changes to the specification are needed to ensure the receiver can correctly compute the record boundaries whenever the channel is in-sync. It is also necessary to restrict the adversary so that the receiver computes these deterministically and independently of the adversary's state. This amounts to assuming that the record boundaries can be computed from the sequence of records written to the channel. This is true of the record layer, of course, so these changes do not alter our claims for the TLS 1.3 standard as it is.

2. **2020/04/03**: Weaken INT security (Figure 6; cf. [29, Figure 4]) by requiring Enc-queries to have distinct nonces and update Theorem 3 (cf. [29, Theorem 5.2]) and Theorem 4 (cf. [29, Theorem 5.3]) accordingly. The previous notion is stronger than usual (cf. nAE [26]) and therefore excludes common instantiations of the AEAD scheme. For example, AES-GCM is known to be vulnerable to ciphertext integrity attacks when nonces are allowed to repeat [15]. Fortunately, it is straightforward to patch the proofs to account for the weaker assumption.

## 2. PSCs in Relation to Prior Work

Our framework combines two existing approaches to analyzing real-world cryptography. First, we extend secure stream-based channels to consider the multiplexing of plaintext streams over the same channel. This addresses a problem left open by FGMP [20] and permits, for the first time, the analysis of TLS in this setting. The second approach is the partially specified protocol framework of RS, which we use to reason about the standard itself.

### Stream-Based Secure Channels

We summarize important landmarks in the development of the theory of secure channels. In 2000, Bellare and Namprempre [8] provided foundations for the study of probabilistic authenticated encryption (AE) schemes used in SSL/TLS, IPSec, and SSH. Shortly thereafter, Rogaway [34] embellished authenticated encryption to take associated data (AEAD), moving the primitive closer to practice. Yet, it was already understood that an AEAD scheme and its attendant notions of privacy and integrity do not suffice for building secure channels. In 2002, Bellare, Kohno, and Namprempre (BKN) [7] formalized stateful AE to account for replay and out-of-order delivery attacks, as well as to model and analyze SSH. Their model regards ciphertexts as atomic, but ciphertexts written to the channel may be (and routinely are) fragmented as they traverse the network, leaving these protocols susceptible to attacks [2]. Likewise, the APIs for real secure channels regard the input plaintext as a stream, meaning that a single logical plaintext may be presented as a sequence of fragments. It took another ten years for the model to be significantly extended, by Boldyreva et al. [13], to address ciphertext fragmentation and attacks that exploit it. Finally, in 2015, FGMP formalized stream-based secure channels that address plaintext fragmentation, with updates provided in 2016 by Albrecht et al. [1]. As FGMP point out [20], these works help shed formal light on truncation [35] and cookie-cutter [12] attacks. (However, as we discuss in Section 5.3, their work is somewhat limited with regard to these.)

Although theory has advanced significantly, it still falls short of capturing an important feature that real protocols provide: a means of multiplexing a number of data streams over the same channel. The TLS 1.3 record layer, for example, handles streams for three distinct sub-protocols: handshake, alert, and application-data. Explicitly modeling the multiplexing of these streams is necessary for a rigorous analysis of TLS, as each of these sub-protocols has side effects on the sender and receiver state and, hence, implications for the security provided by the channel.

Whereas FGMP regard the plaintext stream as a sequence of message fragments \( M_1, M_2, \ldots \), we will consider streams of the form \((M_1, sc_1), (M_2, sc_2), \ldots\) where \( sc_i \) denotes the stream context of its associated message fragment. The stream context is metadata that allows for differentiation of fragments into logical streams, each associated with a higher-level application, protocol, etc. Following prior work, our syntax models a unidirectional channel between a sender and receiver. We decompose the sender into two randomized, stateful algorithms: the stream multiplexer (Mux) and the channel writer (Write). Correspondingly, we decompose the receiver into the channel reader (Read) and the stream demultiplexer (Demux). One might think it cleaner to regard the sender and receiver as atomic processes, as the aforementioned works do. We break with this syntax to precisely capture multiplexing of streams and to separate this functionality from the cryptographic operations that turn plaintext strings into ciphertexts. (More on this in Section 4.2.)

### Partially Specified Protocols

In their treatment of the SSH protocol, BKN introduce a paradigm they call Encode-then-Encrypt-and-MAC, which cleanly abstracts many of the details of the SSH specification. In particular, they treat the details of encoding as a generic transform and give a sufficient condition on this transform for the security of the overall protocol. Of course, this idea—and more generally, the Encode-then-Encipher paradigm [9]—is applicable to the problem of analyzing TLS 1.3. However, our consideration of stream-based channels makes our adversary considerably stronger than that considered by BKN. It stands to reason, then, that there are details of the protocol and implementation that are relevant to the stronger model but not the weaker one. (In particular, we must at least account for processing of plaintext- and ciphertext-stream fragments.) How shall we go about uncovering what these security-critical matters are?

There are many ways to approach this problem. The approach of RS, which we adopt here, is simply to formalize what a standard is: a partial specification (the things that are mandated and explicitly described) plus additional specification details (everything else). RS apply this approach to authentication protocols, in particular the Needham-Schroeder-Lowe protocol. We apply it to secure channels. The component algorithms of a PSC, Mux, Write, Read, and Demux, formalize the core functionalities of the sender and receiver that must be fully specified; the rest of the specification details (SD) are formalized via an oracle given to each of the algorithms. The functionality of this SD oracle is left unspecified, and in our security games, queries made to the oracle are serviced by the adversary. This is clearly a very strong attack model: in addition to influencing the behavior of the algorithms via their inputs, the adversary is allowed to participate in portions of their computation. The actual strength of the model depends on what quantities are exposed to the SD and how the SD return values are used within the algorithms. At one extreme, an empty (or otherwise trivial) SD yields a traditional kind of attack model; at the other, if secret state (e.g., the key) is passed to the SD, then no security is possible. In this way, our model can provide principled guidance to the standard-writing process by surfacing choices that are relevant to security.

This definitional framework admits another interpretation, one that is likely of interest in other settings: it lets us reason about security in the presence of implementation errors. One can view each algorithm as being partitioned into operations whose implementation is assumed to be correct and those that are not. From this perspective, our attack model captures a kind of worst-case (i.e., adversarial) implementation of those operations. This is interesting because if one proves that a particular PSC construction is secure, it makes clear which things must be implemented correctly and deserve the extra scrutiny of formal verification (à la [18]), and which things do not need such hard guarantees.

## 3. Related Work

We have already mentioned the line of papers that our work extends [8, 7, 14, 19, 1]; this section points out important related efforts.

### The miTLS Project

From the standpoint of scope, the work most closely related to ours is the recent paper by Delignat-Lavaud et al. [18] (DLFK+). It provides a formal analysis of the TLS 1.3 record layer (draft 18) "as is," but their approach is fundamentally different from our own. The paper is the latest from miTLS (mitls.org), a project whose goal is to formally verify the security of TLS as is, without omitting any details.