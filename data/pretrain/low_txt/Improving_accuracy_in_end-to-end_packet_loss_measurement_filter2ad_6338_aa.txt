# Title: Improving Accuracy in End-to-End Packet Loss Measurement

## Authors:
- Joel Sommers, University of Wisconsin-Madison
- Paul Barford, University of Wisconsin-Madison
- Nick G. Duffield, AT&T Labs-Research
- Amos Ron, University of Wisconsin-Madison

## Abstract
Measurement and estimation of packet loss characteristics are challenging due to the relatively rare occurrence and typically short duration of packet loss episodes. Active probe tools are commonly used to measure packet loss on end-to-end paths, but there has been little analysis of their accuracy or their impact on the network. Our study aims to understand how to accurately measure packet loss episodes with end-to-end probes.

We begin by testing the capability of standard Poisson-modulated end-to-end measurements in a controlled laboratory environment using IP routers and commodity end hosts. Our tests show that loss characteristics reported by such Poisson-modulated probe tools can be quite inaccurate under various traffic conditions. Motivated by these observations, we introduce a new algorithm for packet loss measurement designed to overcome the deficiencies in standard Poisson-based tools. Specifically, our method creates a probe process that (1) enables an explicit trade-off between accuracy and network impact, and (2) provides more accurate measurements than standard Poisson probing at the same rate.

We evaluate our methodology experimentally by developing and implementing a prototype tool called BADABING. The experiments demonstrate the trade-offs between network impact and measurement accuracy. We show that BADABING reports loss characteristics far more accurately than traditional loss measurement tools.

**Categories and Subject Descriptors:**
- C.2.3 [Network Operations]: Network monitoring
- C.2.5 [Local and Wide-Area Networks]: Internet (e.g., TCP/IP)
- C.4 [Performance of Systems]: Measurement Techniques

**General Terms:**
- Algorithms, Design, Experimentation, Measurement

**Keywords:**
- Active Measurement, BADABING, Network Congestion, Network Probes, Packet Loss

## 1. Introduction
Measuring and analyzing network traffic dynamics between end hosts is crucial for the development of many different network protocols and systems. Understanding packet loss behavior is particularly important, as loss can significantly impact the performance of both TCP- and UDP-based applications. Despite efforts by network engineers and operators to limit loss, it will likely never be eliminated due to the intrinsic dynamics and scaling properties of traffic in packet-switched networks [19]. Network operators can passively monitor nodes within their network for packet loss using SNMP. However, end-to-end active measurements using probes provide an equally valuable perspective, as they indicate the conditions that application traffic is experiencing on those paths.

The most commonly used tools for probing end-to-end paths to measure packet loss resemble the ubiquitous PING utility. PING-like tools send probe packets (e.g., ICMP echo packets) to a target host at fixed intervals. Loss is inferred if the expected response packets from the target host are not received within a specified time period. Generally, an active measurement approach is problematic because of the discrete sampling nature of the probe process. Thus, the accuracy of the resulting measurements depends on the characteristics and interpretation of the sampling process, as well as the characteristics of the underlying loss process.

Despite their widespread use, there is almost no mention in the literature of how to tune and calibrate [28] active measurements of packet loss to improve accuracy or how to best interpret the resulting measurements. One approach is suggested by the well-known PASTA principle [36], which, in a networking context, tells us that Poisson-modulated probes will provide unbiased time average measurements of a router queue's state. This idea has been suggested as a foundation for active measurement of end-to-end delay and loss [3]. However, the asymptotic nature of PASTA means that when it is applied in practice, the higher moments of measurements must be considered to determine the validity of the reported results. A closely related issue is that loss is typically a rare event in the Internet [39]. This reality implies either that measurements must be taken over a long time period or that the average rates of Poisson-modulated probes may have to be quite high to report accurate estimates in a timely fashion. However, increasing the mean probe rate may lead to the situation where the probes themselves skew the results. Thus, there are trade-offs in packet loss measurements between probe rate, measurement accuracy, network impact, and timeliness of results.

The goal of our study is to understand how to accurately measure loss characteristics on end-to-end paths with probes. We are interested in two specific characteristics of packet loss: loss episode frequency and loss episode duration [39]. The commonly referred to notion of loss rate [8, 27] can be estimated directly from these two measurements. Our study consists of three parts: (i) empirical evaluation of the currently prevailing approach, (ii) development of estimation techniques based on novel experimental design, novel probing techniques, and simple validation tests, and (iii) empirical evaluation of this new methodology.

We begin by testing standard Poisson-modulated probing in a controlled and carefully instrumented laboratory environment consisting of commodity workstations separated by a series of IP routers. Background traffic is sent between end hosts at different levels of intensity to generate loss episodes, enabling repeatable tests over a range of conditions. We consider this setting ideal for testing loss measurement tools, as it combines the advantages of traditional simulation environments with those of tests in the wide area. Namely, like simulation, it provides a high level of control and the ability to compare results with "ground truth." Furthermore, like tests in the wide area, it allows us to consider loss processes in actual router buffers and queues and the behavior of implementations of the tools on commodity end hosts. Our tests reveal two important deficiencies with simple Poisson probing. First, individual probes often incorrectly report the absence of a loss episode (i.e., they are successfully transferred when a loss episode is underway). Second, they are not well suited to measure loss episode duration over limited measurement periods.

Our observations about the weaknesses in standard Poisson probing motivate the second part of our study: the development of a different approach for end-to-end loss measurement. There are three key elements in this new approach. First, we design a probe process that assesses the likelihood of loss experienced by other flows that use the same path, rather than merely reporting its own packet losses. Second, we design a new experimental framework with estimation techniques that directly estimate the mean duration of the loss episodes without estimating the duration of any individual loss episode. Our estimators are proven to be consistent under mild assumptions of the probing process. Third, we provide simple validation tests (that require no additional experimentation or data collection) for some of the statistical assumptions that underlie our analysis.

The third part of our study involves the empirical evaluation of our new loss measurement methodology. To this end, we developed a one-way active measurement tool called BADABING. BADABING sends fixed-size probes at specified intervals from one measurement host to a collaborating target host. The target system collects the probe packets and reports the loss characteristics after a specified period. We also compare BADABING with a standard tool for loss measurement that emits probe packets at Poisson intervals. The results show that our tool reports loss episode estimates much more accurately for the same number of probes.

The most important implication of these results is that there is now a methodology and tool available for wide-area studies of packet loss characteristics that enable researchers to understand and specify the trade-offs between accuracy and impact. Furthermore, the tool is self-calibrating [28] in the sense that it can report when estimates are poor. Practical applications could include its use for path selection in peer-to-peer overlay networks and as a tool for network operators to monitor specific segments of their infrastructures.

The remainder of the paper is structured as follows. In Section 2, we consider related work in the areas of loss measurement techniques and loss measurement studies. In Section 3, we provide definitions for loss episode frequency and duration, which provide critical context for our probe process. Our laboratory testbed configuration and results of our tests of basic Poisson-modulated probing are reported in Section 4. Details on our new probe process and an analytic treatment of the validity of the resulting loss estimators are provided in Section 5. A description of the tool that we built to implement our probe process and results of its evaluation experiments are described in Section 6. We provide a discussion of practical considerations for using our tool in Section 7. A concluding summary and future directions for this work are provided in Section 8.

## 2. Related Work
It is well known that packet loss can have a substantial impact on the performance of a wide range of Internet protocols and applications. Understanding the characteristics and impact of packet loss led, for example, to the development of the NewReno [15] and SACK [21] versions of TCP. Loss characteristics are also a fundamental component of TCP throughput modeling [10, 22, 24].

There have been many studies of packet loss behavior in the Internet. Bolot [8] and Paxson [27] evaluated end-to-end probe measurements and reported characteristics of packet loss over a selection of paths in the wide area. Yajnik et al. evaluated packet loss correlations on longer time scales and developed Markov models for temporal dependence structures [37]. Zhang et al. characterized several aspects of packet loss behavior in [39]. In particular, that work reported measures of constancy of loss episode rate, loss episode duration, loss-free period duration, and overall loss rates. The authors in [25] used a sophisticated passive monitoring infrastructure inside Sprint’s IP backbone to gather packet traces and analyze loss episode frequency and duration. Finally, Sommers and Barford pointed out some of the limitations in standard end-to-end Poisson probing tools by comparing the loss rates measured by such tools to loss rates measured by passive means in a fully instrumented wide area infrastructure [6].

The foundation for the notion that Poisson Arrivals See Time Averages (PASTA) was developed by Brumelle in [9] and later formalized by Wolff in [36]. Adaptation of those queuing theory ideas into a network probe context to measure loss and delay characteristics began with Bolot’s study in [8] and was extended by Paxson in [27]. Of particular relevance to our work is Paxson’s recommendation and use of Poisson-modulated active probe streams to reduce bias in delay and loss measurements. Several studies include the use of loss measurements to estimate network properties such as bottleneck buffer size and cross-traffic intensity [4, 29].

The Internet Performance Measurement and Analysis efforts [16, 17] resulted in a series of RFCs that specify how packet loss measurements should be conducted. However, those RFCs are devoid of details on how to tune probe processes and how to interpret the resulting measurements. We are also guided by Paxson’s recent work in [28] where he advocates rigorous calibration of network measurement tools.

ZING is a tool for measuring end-to-end packet loss in one direction between two participating end hosts [2, 20]. ZING sends UDP packets at Poisson-modulated intervals with a fixed mean rate. Savage developed the STING [30] tool to measure loss rates in both forward and reverse directions from a single host. STING uses a clever scheme for manipulating a TCP stream to measure loss. Allman et al. demonstrated how to estimate TCP loss rates from passive packet traces of TCP transfers taken close to the sender. A related study using passive packet traces taken in the middle of the network was presented in [7]. Network tomography based on using both multicast and unicast probes has also been demonstrated to be effective for inferring loss rates on internal links on end-to-end paths [11, 12].

Finally, controlled laboratory environments like the one used in this paper have begun to emerge as effective arenas for network protocol and system evaluation (e.g., [18]). Environments such as WAIL [1], DETER [32], and Emulab [35] are openly available to the research community, often include IP routers as well as general-purpose workstations, and are ideal for measurement tool testing.

## 3. Definitions of Loss Characteristics
There are many factors that can contribute to packet loss in the Internet. We will describe some of these in detail as a foundation for understanding our active measurement objectives. The environment we consider is modeled as a set of N flows that pass through a router R and compete for a single output link with bandwidth Bout, as depicted in Figure 1. The aggregate input bandwidth (Bin) must be greater than the shared output link (Bout) for loss to occur. The typical round trip time for the N flows is M seconds. Router R is configured with Q bytes of packet buffers to accommodate traffic bursts, with Q typically sized on the order of M × B [5, 34]. We assume that the traffic includes a mixture of short- and long-lived TCP flows, as is common in today’s Internet, and that the value of N will fluctuate over time.

Figure 2 illustrates how the occupancy of the buffer in router R might evolve over time. Congestion occurs when the aggregate sending rate of the N flows exceeds the capacity of the shared output link. The onset of congestion results in filling of the output buffer, seen as a positive slope in the queue length graph. The rate of increase of the queue length depends on both the number N and the sending rate of each source. A loss episode begins when the aggregate sending rate has exceeded Bout for a period sufficient to load Q bytes into the output buffer of router R (e.g., at times a and c in Figure 2). A loss episode ends when the aggregate sending rate drops below Bout and the buffer begins a consistent drain down to zero (e.g., at times b and d in Figure 2). This typically happens when TCP sources sense a packet loss and halve their sending rate, or simply when the number of competing flows N drops to a sufficient level. In the former case, the duration of a loss episode is related to M, depending on whether loss is sensed by a timeout or fast retransmit signal. We define loss episode duration as the difference between start and end times (i.e., the time interval during which the buffer is full).

[Figure 1 and Figure 2 would be included here, but are not provided in the text.]

This foundational understanding of loss characteristics provides the context for our probe process and the subsequent sections of the paper.