### 3.2 Stealth Analysis

The "junk bytes" inserted by our obfuscator may serve as starting points for an attacker, but there are numerous such points, each corresponding to thousands of actual opcode pairs in the program, and no discernible pattern is present. 

In summary, the individual opcodes and pairs of adjacent opcodes have approximately similar distributions in both unobfuscated and obfuscated programs. Therefore, our obfuscation method is, on balance, quite stealthy.

### 6. Related Work

The earliest work on binary obfuscation that we are aware of was proposed by Cohen, who suggested overlapping adjacent instructions to deceive disassemblers [7]. We are not aware of any actual implementations of this proposal, and our own experiments with this idea were disappointing. More recently, we described an approach to make binaries more difficult to disassemble using a combination of two techniques: the judicious insertion of "junk bytes" to mislead disassembly, and the use of "branch functions" to obscure branch targets [20]. These techniques proved effective at thwarting most disassemblers, including the commercial IDA Pro system. Conceptually, this paper extends that work by disguising control transfer instructions and inserting misleading control transfers. More recently, we also described a method to use signals to disguise the instruction used for system calls (‘int$0x80’ in Intel x86 processors) to prevent injected malware from finding and executing system calls; this required kernel modifications. In contrast, the work described in this paper applies to arbitrary control transfers in programs without requiring any kernel changes. These two differences lead to significant distinctions in terms of goals, techniques, and effects.

Recent work by Kapoor [14] and Kruegel et al. [15] has focused on disassembly techniques specifically targeting obfuscated binaries. They address the possibility of "junk bytes" in the instruction stream by producing an exhaustive disassembly for each function, i.e., where a recursive disassembly is generated starting at every byte in the code for that function. This results in a set of alternative disassemblies, not all of which are viable. The disassembler then uses various heuristics and statistical reasoning to rule out unlikely or impossible alternatives. To our knowledge, these exhaustive disassemblers are the most sophisticated currently available. One of the "attack disassemblers" used in our experiments is an implementation of Kruegel et al.'s exhaustive disassembler.

There is a considerable body of work on code obfuscation aimed at making it harder for attackers to decompile a program and extract high-level semantic information [9, 10, 31, 32]. Typically, these authors rely on computationally difficult static analysis problems—such as complex Boolean expressions, pointers, or indirect control flow—to make it harder to construct a precise control flow graph for a program. Our work is orthogonal to these proposals and complementary to them. We aim to make a program harder to disassemble correctly, thereby sowing uncertainty in an attacker's mind about which portions of a disassembled program have been correctly disassembled and which parts may contain errors. If the program has already been obfuscated using any of these higher-level obfuscation techniques, our methods add an additional layer of protection, making it even harder to decipher the actual structure of the program.

Even greater security can be achieved by maintaining the software in encrypted form and decrypting it as needed during execution, as suggested by Aucsmith [1], or by using specialized hardware, as discussed by Lie et al. [19]. However, such approaches have the disadvantages of high performance overhead (in the case of runtime decryption without specialized hardware support) or a loss of flexibility because the software can no longer run on standard hardware.

### 7. Conclusions

This paper describes a new approach to obfuscating executable binary programs and evaluates its effectiveness on programs in the SPECint-2000 benchmark suite. Our goals are to make it difficult for disassemblers (and humans) to find the real instructions in a binary and to give them a mistaken notion of the actual control flow in the program. To achieve these goals, we replace many control transfer instructions with traps that cause signals, inject signal handling code to effect the original control transfers, and insert bogus code to further confuse disassemblers. We also use randomization to vary the code we insert so it does not stand out.

These obfuscations confuse even the best disassemblers. On average, the GNU objdump program [24] misunderstands over 43% of the original instructions, over-reports the control flow edges by 71%, and misses 63% of the original control flow edges. The IDA Pro system [11], considered the best commercial disassembler, fails to disassemble 57% of the original instructions, over-reports control flow edges by 41%, and under-reports control flow edges by 85%. A recent disassembler [15] designed to handle obfuscated programs fails to disassemble over 55% of the instructions, over-reports control flow edges by 27%, and under-reports control flow edges by over 60%.

These results indicate that we successfully make it hard to disassemble programs, even when we only obfuscate code in cold code blocks. If we obfuscate more of the code, we can confuse disassemblers even more. However, our obfuscation method slows down program execution, so there is a tradeoff between the degree of obfuscation and execution time. When we obfuscate only cold code blocks, the average slowdown is 21%, and this result is skewed by three benchmarks for which the training input is not a very good predictor for execution on the reference input. On many programs, the slowdown is negligible. An interesting possibility—which we have not explored but could easily add to our obfuscator—would be to selectively obfuscate some of the hot code, e.g., that which the creator of the code especially wants to conceal.

### Acknowledgements

We are grateful to Christopher Kruegel for the use of the code for his exhaustive disassembler in our experiments.

### References

[1] D. Aucsmith. Tamper-resistant software: An implementation. In Information Hiding: First International Workshop: Proceedings, volume 1174 of Lecture Notes in Computer Science, pages 317–333. Springer-Verlag, 1996.

[2] Black Fenix. Black fenix’s anti-debugging tricks. http://in.fortunecity.com/skyscraper/browser/12/sicedete.html.

[3] S. Cesare. Linux anti-debugging techniques (fooling the debugger), January 1999. VX Heavens. http://vx.netlux.org/lib/vsc04.html.

[4] M. Christodorescu, S. Jha, S. A. Seshia, D. Song, and R. E. Bryant. Semantics-aware malware detection. In Proc. 2005 IEEE Symposium on Security and Privacy (Oakland 2005), pages 32–46, May 2005.

[5] C. Cifuentes. Reverse Compilation Techniques. PhD thesis, Queensland University of Technology, Australia, July 1994.

[6] C. Cifuentes and K. J. Gough. Decompilation of binary programs. Software—Practice and Experience, 25(7):811–829, July 1995.

[7] F. B. Cohen. Operating system protection through program evolution, 1992. http://all.net/books/IP/evolve.html.

[8] R. S. Cohn, D. W. Goodwin, and P. G. Lowney. Optimizing Alpha executables on Windows NT with Spike. Digital Technical Journal, 9(4):3–20, 1997.

[9] C. Collberg and C. Thomborson. Watermarking, tamper-proofing, and obfuscation – tools for software protection. IEEE Transactions on Software Engineering, 28(8), August 2002.

[10] C. Collberg, C. Thomborson, and D. Low. Breaking abstractions and unstructuring data structures. In Proc. 1998 IEEE International Conference on Computer Languages, pages 28–38.

[11] DataRescue sa/nv, Liège, Belgium. IDA Pro. http://www.datarescue.com/idabase/.

[12] M. L. Fredman, J. Komlós, and E. Szemerédi. Storing a sparse table with O(1) worst case access time. Journal of the ACM, 31(3):538–544, July 1984.

[13] C. R. Hollander. Decompilation of object programs. PhD thesis, Stanford University, 1973.

[14] A. Kapoor. An approach towards disassembly of malicious binaries. Master’s thesis, University of Louisiana at Lafayette, 2004.

[15] C. Kruegel, W. Robertson, F. Valeur, and G. Vigna. Static disassembly of obfuscated binaries. In Proc. 13th USENIX Security Symposium, August 2004.

[16] C. Krügel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna. Polymorphic worm detection using structural information of executables. In Recent Advances in Intrusion Detection, volume 3858 of Lecture Notes in Computer Science, pages 207–226. Springer, 2005.

[17] E. U. Kumar, A. Kapoor, and A. Lakhotia. DOC – answering the hidden ‘call’ of a virus. Virus Bulletin, April 2005.

[18] A. Lakhotia, E. U. Kumar, and M. Venable. A method for detecting obfuscated calls in malicious binaries. IEEE Transactions on Software Engineering, 31(11):955–968, 2005.

[19] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. Mitchell, and M. Horowitz. Architectural support for copy and tamper resistant software. In Proc. 9th. International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IX), pages 168–177, November 2000.

[20] C. Linn and S.K. Debray. Obfuscation of executable code to improve resistance to static disassembly. In Proc. 10th. ACM Conference on Computer and Communications Security (CCS 2003), pages 290–299, October 2003.

[21] C. M. Linn, M. Rajagopalan, S. Baker, C. Collberg, S. K. Debray, and J. H. Hartman. Protecting against unexpected system calls. In Proc. Usenix Security '05, pages 239–254, August 2005.

[22] R. Muth and S. K. Debray. On the complexity of flow-sensitive dataflow analyses. In Proc. 27th ACM Symposium on Principles of Programming Languages (POPL-00), pages 67–80, January 2000.

[23] R. Muth, S. K. Debray, S. Watterson, and K. De Bosschere. alto: A link-time optimizer for the Compaq Alpha. Software—Practice and Experience, 31:67–101, January 2001.

[24] Objdump. Software—GNU Manuals Online. GNU Project—Free Software Foundation. www.gnu.org/manual/binutils-2.10.1/html_chapter/binutils_4.html.

[25] M. Prasad and T. Chiueh. A binary rewriting defense against stack-based buffer overflow attacks. In Proc. USENIX Technical Conference, June 2003.

[26] B. Schwarz, S. K. Debray, and G. R. Andrews. Disassembly of executable code revisited. In Proc. IEEE 2002 Working Conference on Reverse Engineering (WCRE), pages 45–54, October 2002.

[27] P. K. Singh, M. Mohammed, and A. Lakhotia. Using static analysis and verification for analyzing virus and worm programs. In Proc. 2nd. European Conference on Information Warfare, June 2003.

[28] R. L. Sites, A. Chernoff, M. B. Kirk, M. P. Marks, and S. G. Robinson. Binary translation. Communications of the ACM, 36(2):69–81, February 1993.

[29] A. Srivastava and D. W. Wall. A practical system for intermodule code optimization at link-time. Journal of Programming Languages, 1(1):1–18, March 1993.

[30] H. Theiling. Extracting safe and precise control flow from binaries. In Proc. 7th Conference on Real-Time Computing Systems and Applications, December 2000.

[31] C. Wang, J. Davidson, J. Hill, and J. Knight. Protection of software-based survivability mechanisms. In Proc. International Conference of Dependable Systems and Networks, July 2001.

[32] C. Wang, J. Hill, J. Knight, and J. Davidson. Software tamper resistance: Obstructing static analysis of programs. Technical Report CS-2000-12, Dept. of Computer Science, University of Virginia, 12 2000.

[33] Z. Xu, B. P. Miller, and T. Reps. Safety checking of machine code. In Proc. ACM SIGPLAN '00 Conference on Programming Language Design and Implementation, pages 70–82, June 18–21, 2000.

### Appendix — Randomizing the Computation of Values

The essential idea is to carry out multiple, random, value-preserving rewritings of the syntax tree for an expression. We start with a simple expression, e.g., an integer constant or a variable, and repeatedly rewrite it using value-preserving transformation rules to produce an equivalent expression (i.e., one that will always evaluate to the same value).

Figure 9 provides a non-exhaustive list of example rewrite rules. In the rules, we use 'x' and 'y' to denote variables (i.e., the values of registers or memory locations), 'k,' 'm,' and 'n' to denote integer constants, and 'a' to denote something that is either a variable or a constant. Note that equivalences that hold for integers may not hold at the machine level, e.g., (x + 1) - 1 need not evaluate to x. Thus, in general, we cannot use associative and distributive laws for rewriting.

The expression being rewritten is maintained as a syntax tree. Initially, the tree consists of a single node, namely, the variable or constant being rewritten. Each node of the tree has an associated label indicating what kind of value is being computed (zero, nonzero, arbitrary, etc.). The rewriting proceeds as follows:

1. Choose a positive random value as the number of rewriting steps.
2. For each rewriting step:
   1. Randomly choose a leaf node X of the tree.
   2. Randomly choose a rewrite rule R ≡ Y → E from the set of rules corresponding to the label of the chosen leaf node.
   3. Modify the syntax tree by adding the appropriate instance of E (i.e., with all occurrences of Y replaced by X) as child nodes of X and update the set of leaf nodes appropriately.

The rewritten expression may contain "free variables," i.e., variables that are not initialized to any value. The value of the overall expression does not depend on the actual value taken on by such a free variable, so any value will do. In our implementation, we simply use the contents of any arbitrary register or legal memory location for such variables.

Once the rewritten expression has been generated, we generate code for it via a straightforward post-order traversal of the final syntax tree.