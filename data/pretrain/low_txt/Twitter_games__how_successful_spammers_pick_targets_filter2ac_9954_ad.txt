### Table 7: Tweet Posting Methodology of Successful and Unsuccessful Spam Profiles and Regular Twitter Users

#### 6.1 Unbinned Spam Profiles
In Section 4, we discussed five strategies that successful spammers use to select their targets. These strategies helped us understand the behavior of 62% of the 14,230 profiles of successful spammers.

To better understand the behavior of unbinned spam profiles, we made several observations:
- Of the 5,425 unbinned profiles, 64.7% exclusively used regular tweets and did not directly target any other Twitter users except their followers. 
- According to our definition in Section 4.1, a profile is binned if it appears to be running a campaign, defined by at least 10 tweets with links, where 80% of the links lead to a single domain.
- We experimented with alternative definitions of campaigns. For example, if a profile has at least five tweets with links, and when the number of tweets with links is less than 10, 80% of them must lead to a specific domain, and when the number of tweets with links is 10 or more, 50% of them must lead to a specific domain, we were able to bin 8,034 profiles as opposed to 6,630. This resulted in 72% of spam profiles being binned.
- This exercise suggests that further experimentation with campaign definitions could help in binning more spam profiles.

Of the remaining 1,910 unbinned profiles, 89.7% sent at least one mention tweet, and 328 sent exclusively mention tweets. The strategies involving mention tweets (described in Sections 4.2 and 4.3) often had to ignore mention tweets due to the unavailability of keywords spammers may have targeted from usersâ€™ original tweets, leading to missed opportunities for binning more spam profiles.

Additionally, spam automators like TweetAdder provide other methods for spammers to select their targets, such as based on geographical location and language. However, since the profiles we investigated were already suspended, we did not have access to information about their followers, which might have provided further insights into the strategies used, especially by regular tweeting profiles.

#### 6.2 Garnering Followers
Given that about 90% of successful spam profiles use regular tweets and 2/3 of them use them exclusively, the methods spammers use to garner followers are of particular interest. Figure 3 confirmed that a large number of successful spammers have a respectable number of followers.

Spammers can use various methods to gain followers:
- **Peer-Driven Communities:** A popular method is to join communities that encourage following back. Two notable communities in our data are #InstantFollowBack (#IFB) and #TeamFollowBack (#TFB).
  - **#InstantFollowBack (#IFB):** Controlled by a third-party client under the Twitter profile 'instantfollowBA', this community requires members to have a public account with a minimum of 500 followers and to follow back 99% of them daily. Members earn points and promotions, such as retweets and banner ads, as they increase their status. We found only 217 profiles in our dataset involved in this scheme.
  - **#TeamFollowBack (#TFB):** This hashtag is used by numerous follow-back groups. Profiles using this hashtag sign their tweets with #TFB and add it to their publicly searchable profile information. We found 509 profiles in our dataset using the #TFB hashtag.

- **Buying Followers:** Websites like http://getfollowrsontwitter.org/ and online marketplaces like fiverr.com offer services to buy thousands of Twitter followers for as little as $5. Studies [6, 13] confirm that buying followers is prevalent on Twitter.

It is important to note that these techniques are effective for gaining followers but may not work well for spam profiles that require relevant followers. For such profiles, spammers may use the strategies described in Sections 4.2 and 4.3 to locate and friend targets based on location, interests, etc. This increases the likelihood of genuine followers, making it harder to distinguish between spam and non-spam content.

#### 7. Related Work
Research on social network spam has been extensive, including studies on YouTube, Facebook, and Twitter. Our focus is primarily on Twitter-related research, particularly those that influenced our investigation.

- **Spam Detection and Classification:** Many studies have focused on building classifiers to distinguish spam profiles and tweets from non-spam ones. Lee et al. [10], Stringhini et al. [14], and Yang et al. [22] used machine learning techniques to detect and classify spammers. Hongyu et al. [4] gathered spam messages into campaigns and used supervised machine learning for filtering. Works in [1, 3, 21] manually labeled datasets and built classifiers using account-based, content-based, and behavior-based features.

- **Suspicious URLs Detection:** Lee et al. [11] and Thomas et al. [15] proposed machine learning classifiers to detect suspicious URLs in Twitter streams.

- **Characterization of Twitter Spam:** Grier et al. [7] characterized Twitter spam, finding that 70% of spam tweets had hashtags, 11% were retweets, and 10.6% were mentions. Yang et al. [23] studied how spammers integrate into social networks, while Jonghyuk et al. [12] proposed a spam filtering technique based on sender-receiver relationships.

- **Suspended Accounts Analysis:** Thomson et al. [16] analyzed suspended Twitter accounts, showing that spam accounts have evolved to counter Twitter's anti-spam efforts. Our study finds that while the nature of spam campaigns remains similar, the characteristics of spam accounts, such as social relationships and longevity, have changed significantly.

#### 8. Conclusion
Our analysis of successful Twitter spammers revealed that while spam campaigns have remained largely unchanged, the spammers themselves have evolved in response to Twitter's anti-spam efforts. The complexity of their strategies is likely to increase as more tools simulating normal human behavior are developed. To effectively combat sophisticated spam profiles, spam classifiers need to include social metadata such as follower metadata, keyword clouds, and linked domains, along with traditional signals.

#### Acknowledgements
We thank Fil Menczer and the Center for Complex Networks and System Research (CNetS) at Indiana University for providing access to the Twitter streaming API data through their Truthy project. The Truthy project and its infrastructure are supported by the National Science Foundation (NSF) grants CCF-1101743 and IIS-0811994. This work is supported by the NSF under Grant Number CNS-1018617.

#### References
[1] Benevenuto, F., Magno, G., Rodrigues, T., and Almeida, V. Detecting spammers on Twitter. In Collaboration, Electronic messaging, Anti-Abuse and Spam Conference (CEAS) (2010).

[2] Benevenuto, F., Rodrigues, T., Almeida, V., Almeida, J., and Chao Zhang, K. R. Identifying video spammers in online social networks. In Workshop on Adversarial Information Retrieval on the Web (AirWeb), held in conjunction with the International World Wide Web (WWW) conference (2008).

[3] Chu, Z., Gianvecchio, S., and Wang, H. Who is tweeting on Twitter: Human, bot, or cyborg? In Annual Computer Security Applications Conference (ACSAC) (2010).

[4] Gao, H., Chen, Y., Lee, K., Palsetia, D., and Choudhary, A. Towards online spam filtering in social networks. In ISOC Network and Distributed System Security Symposium (NDSS) (2012).

[5] Gao, H., Hu, J., Wilson, C., Li, Z., Chen, Y., and Zhao, B. Y. Detecting and characterizing social spam campaigns. In ACM/USENIX Internet Measurement Conference (IMC) (2010).

[6] Ghosh, S., Viswanath, B., Kooti, F., Sharma, N. K., Korlam, G., Benevenuto, F., Ganguly, N., and Gummadi, K. P. Understanding and combating link farming in the Twitter social network. In International Conference on World Wide Web (WWW) (2012).

[7] Grier, C., Thomas, K., Paxson, V., and Zhang, M. @spam: the underground on 140 characters or less. In ACM Conference on Computer and Communications Security (CCS) (2010).

[8] Jones, K. S. A statistical interpretation of term specificity and its application in retrieval. In Journal of Documentation, Vol. 28 Issue: 1, pp.11 - 21 (1972).

[9] Lee, K., Caverlee, J., Kamath, K. Y., and Cheng, Z. Detecting collective attention spam. In Workshop on WebQuality, held in conjunction with International World Wide Web (WWW) conference (2012).

[10] Lee, K., Caverlee, J., and Webb, S. Uncovering social spammers: Social honeypots + machine learning. In ACM Special Interest Group on Information Retrieval (SIGIR) Conference (2010).

[11] Lee, S., and Kim, J. Warningbird: Detecting suspicious URLs in twitter stream. In ISOC Network and Distributed System Security Symposium (NDSS) (2012).

[12] Song, J., Lee, S., and Kim, J. Spam filtering in twitter using sender-receiver relationship. In International Symposium on Recent Advances in Intrusion Detection (RAID) (2011).