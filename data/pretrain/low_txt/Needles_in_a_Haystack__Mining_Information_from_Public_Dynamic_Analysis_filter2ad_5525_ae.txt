### Detection of Similarities Among Binaries

Flake [29] proposed a technique to analyze binaries as graphs of graphs, which has inspired our control flow analysis described in Section 4. Similarly, Kruegel et al. [39] introduced a method for analyzing the control flow graphs of multiple worms, employing graph coloring to address the graph-isomorphism problem.

### Clustering Malware Samples

A key step in our technique involves clustering similar malware samples. Several papers in the area of malware clustering [31, 33, 51, 32] have been published. However, their primary goal is to cluster samples from the same malware family as quickly and accurately as possible, which is a critical task for antivirus companies. In contrast, our objective is to cluster samples based solely on binary similarity, without considering their behavioral characteristics or family affiliations.

### Conclusion

Public dynamic analysis sandboxes collect thousands of new malware samples daily. Most of these submissions belong to well-known malware families or are benign files that do not pose significant security threats. However, a small number of these samples exhibit unique characteristics that distinguish them from the rest. This paper emphasizes the importance of examining these samples from an intelligence and threat prevention perspective.

We demonstrate that several binaries used in high-profile targeted attack campaigns were submitted to our sandbox months before the attacks were first reported. Additionally, we present a preliminary approach to mining the database of a popular sandbox to identify signs of malware development. Our experiments yielded promising results, enabling us to automatically identify thousands of developments and observe how authors modify their programs to test functionalities or evade detection by known sandboxes. Approximately 1,500 of these developments were confirmed as real malware, some of which were later observed infecting thousands of machines globally.

### Acknowledgment

We would like to thank Claudio Guarnieri for his valuable discussions and insights.

---

### References

[1] Amnpardaz SandBox Jevereg. http://jevereg.amnpardaz.com/
[2] AV Tracker. http://avtracker.info/
[3] Comodo Instant Malware Analysis. http://camas.comodo.com/
[4] ThreatTrack Security Public Sandbox. http://www.threattracksecurity.com/resources/sandbox-malware-analysis.aspx
[5] ViCheck. https://www.vicheck.ca
[6] Xandora - Suspicious File Analyzer. http://www.xandora.net/xangui/
[7] Xtreme RAT. https://sites.google.com/site/xxtremerat/
[8] Bifrost Builder. http://www.megasecurity.org/trojans/b/bifrost/Bifrost2.0special.html, 2008.
[9] Poison Ivy RAT. http://www.poisonivy-rat.com, 2008.
[10] Anubis. http://anubis.iseclab.org, 2009.
[11] A new approach to China. http://googleblog.blogspot.fr/2010/01/new-approach-to-china.html, 2010.
[12] Darpa Cyber Genome Project. https://www.fbo.gov/index?s=opportunity&mode=form&id=c34caee99a41eb14d4ca81949d4f2fde, 2010.
[13] Malwr. https://malwr.com, 2010.
[14] ThreatExpert. http://www.threatexpert.com/, 2010.
[15] Malbox. http://malbox.xjtu.edu.cn/, 2011.
[16] Virustotal Behavioural Information. http://blog.virustotal.com/2012/07/virustotal-behavioural-information.html, 2012.
[17] The Red October Campaign - An Advanced Cyber Espionage Network Targeting Diplomatic and Government Agencies. https://www.securelist.com/en/blog/785/, 2013.
[18] TotalHash. http://totalhash.com/, 2013.
[19] RDG Tejon Crypter. http://blackshop.freeforums.org/rdg-tejon-crypter-2014-t743.html, 2014.
[20] Tracking Malware with Hash Importing. https://www.mandiant.com/blog/tracking-malware-import-hashing/, 2014.
[21] VirusTotal += imphash. http://blog.virustotal.com/2014/02/virustotal-imphash.html, 2014.
[22] XtremeRAT: Nuisance or Threat? http://www.fireeye.com/blog/technical/2014/02/xtremerat-nuisance-or-threat.html, 2014.
[23] BALZAROTTI, D., COVA, M., KARLBERGER, C., KRUEGEL, C., KIRDA, E., AND VIGNA, G. Efficient Detection of Split Personalities in Malware. In Proceedings of the Network and Distributed System Security Symposium (NDSS) (San Diego, CA, February 2010), NDSS 10.
[24] BAYER, U., HABIBI, I., BALZAROTTI, D., KIRDA, E., AND KRUEGEL, C. A view on current malware behaviors. In USENIX workshop on large-scale exploits and emergent threats (LEET) (April 2009), LEET 09.
[25] BILGE, L., AND DUMITRAS, T. Before we knew it: An empirical study of zero-day attacks in the real world. In Proceedings of the 2012 ACM Conference on Computer and Communications Security (New York, NY, USA, 2012), CCS ’12, ACM, pp. 833–844.
[26] BRUSCHI, D., MARTIGNONI, L., AND MONGA, M. Using Code Normalization for Fighting Self-Mutating Malware. In Proceedings of the International Symposium of Secure Software Engineering (ISSSE) (Mar. 2006), IEEE Computer Society. Arlington, VA, USA.
[27] DIXON, B. Watching attackers through virustotal. http://blog.9bplus.com/watching-attackers-through-virustotal/, 2014.
[28] DUMITRAS, T., AND SHOU, D. Toward a standard benchmark for computer security research: The worldwide intelligence network environment (WINE). In Proceedings of the First Workshop on Building Analysis Datasets and Gathering Experience Returns for Security (2011), BADGERS ’11.
[29] FLAKE, H. Structural comparison of executable objects. In Proceedings of the IEEE Conference on Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA) (2004), pp. 161–173.
[30] HAYES, M., WALENSTEIN, A., AND LAKHOTIA, A. Evaluation of malware phylogeny modeling systems using automated variant generation, 2009.
[31] HU, X., BHATKAR, S., GRIFFIN, K., AND SHIN, K. G. MutantX-S: Scalable malware clustering based on static features. In Proceedings of the 2013 USENIX Conference on Annual Technical Conference (Berkeley, CA, USA, 2013), USENIX ATC’13, USENIX Association, pp. 187–198.
[32] JACOB, G., COMPARETTI, P. M., NEUGSCHWANDTNER, M., KRUEGEL, C., AND VIGNA, G. A static, packer-agnostic filter to detect similar malware samples. In Proceedings of the 9th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (Berlin, Heidelberg, 2013), DIMVA’12, Springer-Verlag, pp. 102–122.
[33] JANG, J., BRUMLEY, D., AND VENKATARAMAN, S. BitShred: Feature hashing malware for scalable triage and semantic analysis. In Proceedings of the 18th ACM Conference on Computer and Communications Security (New York, NY, USA, 2011), CCS ’11, pp. 309–320.
[34] JANG, J., WOO, M., AND BRUMLEY, D. Towards automatic software lineage inference. In Proceedings of the 22nd USENIX Conference on Security (Berkeley, CA, USA, 2013), SEC’13, USENIX Association, pp. 81–96.
[35] KASPERSKY LAB. Equation: The Death Star of the Malware Galaxy. http://securelist.com/blog/research/68750/equation-the-death-star-of-malware-galaxy/, 2015.
[36] KHOO, W. M., AND LIO, P. Unity in diversity: Phylogenetic-inspired techniques for reverse engineering and detection of malware families. SysSec Workshop (2011), 3–10.
[37] KOIVUNEN, T. SigBuster. http://www.teamfurry.com, 2009.
[38] KORNBLUM, J. Identifying almost identical files using context triggered piecewise hashing. Digital Investigation 3, Supplement, 0 (2006), 91–97.
[39] KRUEGEL, C., KIRDA, E., MUTZ, D., ROBERTSON, W., AND VIGNA, G. Polymorphic worm detection using structural information of executables. In Proceedings of the 8th International Conference on Recent Advances in Intrusion Detection (Berlin, Heidelberg, 2006), RAID’05, Springer-Verlag, pp. 207–226.
[40] KURTZ, G. Operation Aurora hit Google, Others. http://web.archive.org/web/20100327181927/http://siblog.mcafee.com/cto/operation-%E2%80%9Caurora%E2%80%9D-hit-google-others, 2010.

---

### Individual Sample Features

#### A: File Features
- **A.1 Filename**: The original name of the file submitted by the user.
- **A.2 File Size**: The size of the file.
- **A.3 MD5**: A simple hash used for lookup in other data sources.
- **A.4 Fuzzy Hashes**: Using the SSDeep algorithm.

#### B: Timestamps
- **B.1 Submission Time**: The time at which the sample was submitted to the Anubis Sandbox.
- **B.2 Compile Time**: The time at which the binary was compiled.
- **B.3 Symantec First**: The time the sample was first observed in the wild by Symantec.
- **B.4 VirusTotal First**: The time at which the binary was first submitted to VirusTotal.

#### C: AV Features
- **C.1 AV-Detection**: The number of antivirus engines that flag the sample as malicious (according to VirusTotal).
- **C.2 AV-Labels**: List of labels associated with the sample by various antivirus engines (according to VirusTotal).

#### D: User-based Features
- **D.1 User Agent**: The user agent of the browser used to submit the sample.
- **D.2 Languages**: Languages accepted by the user's browser (according to the accept-language HTTP header).
- **D.3 IP Address**: The IP address of the user who submitted the file.
- **D.4 IP Geolocation**: The geolocation of the user's IP address.
- **D.5 Email Address**: Optional email address specified when the sample was submitted.
- **D.6 Proxy**: Boolean value indicating whether the submission was made through a popular anonymization proxy.

#### E: Binary Features
- **E.1 Number of Sections**: The number of sections in the PE file.
- **E.2 Number of Functions**: The number of functions identified by the disassembly.
- **E.3 Code Coverage**: The fraction of the .text segment covered by the identified functions.
- **E.4 Programming Language**: The programming language used to develop the binary.
- **E.5 Metadata**: Filenames and usernames extracted from the PE file.

#### F: Behavioral Features
- **F.1 Duration**: The duration in seconds of the analysis.
- **F.2 Errors**: Errors raised during the analysis.
- **F.3 Evasion**: Known anti-sandbox techniques detected by the sandbox.
- **F.4 Behavior Bitstring**: A sequence of 24 boolean flags characterizing the behavior of the sample (e.g., has popups, has UDP traffic, has HTTP, has TCP address scan, modified registry keys, etc.).

---

**Table 5: List of Individual Features Associated with Each Sample**

---

**USENIX Association**
**24th USENIX Security Symposium**
**Page 1072**