Certainly! Here is the optimized version of your text, aiming for clarity, coherence, and professionalism:

---

**Security and Biometric Authentication Challenges**

Liveness detection mechanisms make it more difficult to mimic another person's features. However, these features become ineffective if an attacker can successfully replicate them. Recent studies have demonstrated that attacks on fingerprint sensors, including Apple's TouchID, using mock fingers made from various materials, are feasible under practical conditions [31], [32]. This is particularly concerning because fingerprints can be easily collected in everyday environments, such as by lifting them from a coffee mug.

One of the main drawbacks of hard biometrics, like fingerprints, is their poor collectability and high intrusiveness. Facial recognition, while convenient for continuous authentication, is not suitable for high-security contexts due to imperfect liveness detection. Simple photographs [33] or more complex 3D video models [34] can be used to bypass facial recognition systems.

Behavioral biometrics, such as keystroke dynamics and mouse movements, are generally less susceptible to replication attacks. However, they often suffer from high false accept rates (FAR) and false reject rates (FRR), making them unsuitable for standalone authentication. This is due to the low time-stability of human behavior and the noise effects caused by external distractions.

**Keystroke Dynamics**

Keystroke dynamics, one of the oldest behavioral biometrics, was first proposed in 1980 [35]. Extensive research has been conducted using different classifiers with static and dynamic texts in various environments. The error rates are low for static texts but increase significantly for free-form texts due to unpredictable pauses. Additionally, keystroke templates are usually tied to specific keyboard layouts and physical devices, making them conceptually simple to imitate. Tey et al. [36] designed software that facilitates imitation attacks by providing feedback based on the differences between the attacker's and the user's typing patterns. Comprehensive surveys of keystroke dynamics can be found in [37], [38].

**Mouse Movements**

Mouse movements have been extensively studied as a potential behavioral biometric, often combined with keystroke patterns. A survey of this research is available in [39]. The best reported accuracy is a FAR of 0.36% and a FRR of 0% [40], though it is questionable whether the classifier distinguished between input devices rather than subjects [41].

**Mobile Device Biometrics**

With the increasing use of smartphones and tablets, traditional keyboard and mouse inputs are no longer ubiquitous. A recent study reported an equal error rate of 2-3% when identifying subjects based on their touchscreen stroke patterns [25]. Another approach, which also tests resistance to imitation attacks, is described in [42], although it only accounts for observation, not compromised user templates.

**Electrical Currents and Bioimpedance**

Some research has explored how the human body modifies electrical currents. Kinnunen et al. [43] measured the body's response to an electric square pulse signal, reporting 100% accuracy on a static dataset and 88% on a dataset taken over several weeks. However, the number of samples was very low, and it is unclear if this accuracy holds with continuous monitoring. Similar work using bioimpedance as a biometric reports a recognition rate of 90%, but requires augmentation with hand geometry [44]. The scope of this study was limited to a family-size group of up to five subjects.

**Eye Movements**

Eye movements have been studied as a biometric resistant to shoulder-surfing attacks. These systems still rely on conventional PINs, passwords, or passphrases. Martinez-Conde et al. [45] developed a system using a Tobii 1750 gazetracker, reporting a password entry time of 9 to 12 seconds with error rates between 3 and 15%. Other work has used eye gestures instead of passwords, reducing the success rate of shoulder-surfing attacks to 55% with an average input time of 5.3 seconds [46].

Our work is most closely related to [47], where the authors used a Tobii X120 gazetracker with a sampling rate of 120Hz to capture eye movements while subjects watched a movie. They constructed feature vectors using short-term eye gaze direction and modeled them using Gaussian mixtures. Depending on the amount of training data, an equal error rate of 28.7 to 47.1% was reported. Cantoni et al. [22] attempted to distinguish individuals by their gaze patterns on different images, but their approach is not suitable for task-independent identification and does not address the stability of these patterns over time.

**Conclusion**

In this work, we have contributed a set of 21 discriminative features based on eye movement patterns. These features are not limited to our design and can be applied to a wide range of general tasks, such as web browsing or writing emails. We designed a controlled experiment to account for different ways an insider attacker can obtain information to aid in impersonation attacks. Using gaze tracking data from 30 members of the general public, we quantified the advantage an adversary has in impersonating a user and tested the resistance to task familiarity. Our results show that eye movements provide a rich source of distinguishing information, achieving an equal error rate of 3.98%. The time stability of our features allows for reliable authentication over extended periods, making this biometric an excellent foundation for continuous authentication mechanisms.

**Acknowledgments**

We would like to thank our shepherd Gianluca Stringhini and the anonymous reviewers for their invaluable feedback. This work was supported by the Engineering and Physical Sciences Research Council [grant number EP/M50659X/1].

**References**

[1] I. G. Group, “Eye tracking and gaze interaction,” www.gazegroup.org.
[2] A. Duchowski, Eye tracking methodology: Theory and practice. Springer, 2007, vol. 373.
[3] B. Cassin, M. L. Rubin, and S. Solomon, Dictionary of eye terminology. Wiley Online Library, 1984.
[4] S. Martinez-Conde, S. L. Macknik, X. G. Troncoso, and T. A. Dyar, “Microsaccades counteract visual fading during fixation,” Neuron, vol. 49, no. 2, pp. 297–305, 2006.
[5] R. Abadi and E. Gowen, “Characteristics of saccadic intrusions,” Vision research, vol. 44, no. 23, pp. 2675–2690, 2004.
[6] A. Jones, R. Friedland, B. Koss, L. Stark, and B. Thompkins-Ober, “Saccadic intrusions in alzheimer-type dementia,” Journal of neurology, vol. 229, no. 3, pp. 189–194, 1983.
[7] B. A. Clementz, J. A. Sweeney, M. Hirt, and G. Haas, “Pursuit gain and saccadic intrusions in first-degree relatives of probands with schizophrenia.” Journal of abnormal psychology, vol. 99, no. 4, p. 327, 1990.
[8] K. Rayner, C. M. Rotello, A. J. Stewart, J. Keir, and S. A. Duffy, “Integrating text and pictorial information: eye movements when looking at print advertisements.” Journal of Experimental Psychology: Applied, vol. 7, no. 3, p. 219, 2001.
[9] M. Wedel and R. Pieters, “Eye fixations on advertisements and memory for brands: A model and findings,” Marketing science, vol. 19, no. 4, pp. 297–312, 2000.
[31] C. Barral and A. Tria, “Fake fingers in fingerprint recognition: Glycerin supersedes gelatin,” in Formal to Practical Security. Springer, 2009, pp. 57–69.
[32] F. Rieger. (2013) Chaos computer club breaks apple touchid. [Online]. Available: http://www.ccc.de/en/updates/2013/ccc-breaks-apple-touchid/
[33] N. M. Duc and B. Q. Minh, “Your face is not your password face authentication bypassing lenovo–asus–toshiba,” Black Hat Briefings, 2009.
[34] A. Boehm, D. Chen, M. Frank, L. Huang, C. Kuo, T. Lolic, I. Martinovic, and D. Song, “Safe: Secure authentication with face and eyes,” in IEEE PRISMS 2013, June 2013.
[35] R. S. Gaines, W. Lisowski, S. J. Press, and N. Shapiro, “Authentication by keystroke timing: Some preliminary results,” DTIC Document, Tech. Rep., 1980.
[36] C. M. Tey, P. Gupta, and D. GAO, “I can be you: Questioning the use of keystroke dynamics as biometrics.” The 20th Annual Network & Distributed System Security Symposium (NDSS 2013), 2013.
[37] D. Shanmugapriya and G. Padmavathi, “A survey of biometric keystroke dynamics: Approaches, security and challenges,” arXiv preprint arXiv:0910.0817, 2009.
[38] S. P. Banerjee and D. L. Woodard, “Biometric authentication and identification using keystroke dynamics: A survey,” Journal of Pattern Recognition Research, vol. 7, no. 1, pp. 116–139, 2012.
[39] K. Revett, H. Jahankhani, S. T. de Magalh˜aes, and H. M. Santos, “A survey of user authentication based on mouse dynamics,” in Global E-Security. Springer, 2008, pp. 210–219.
[40] Y. Nakkabi, I. Traoré, and A. A. E. Ahmed, “Improving mouse dynamics biometric performance using variance reduction via extractors with separate features,” Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on, vol. 40, no. 6, pp. 1345–1353, 2010.
[41] Z. Jorgensen and T. Yu, “On mouse dynamics as a behavioral biometric for authentication,” in Proceedings of the 6th ACM Symposium on Information, Computer and Communications Security. ACM, 2011, pp. 476–482.
[42] N. Zheng, K. Bai, H. Huang, and H. Wang, “You are how you touch: User verification on smartphones via tapping behaviors,” Tech. Rep. WM-CS-2012-06, Tech. Rep., 2012.
[43] K. B. Rasmussen, M. Roeschlin, I. Martinovic, and G. Tsudik, “Authentication using pulse-response biometrics,” in Proceedings of the 21st Network and Distributed System Security Symposium (NDSS 2014), 2014.
[44] C. Cornelius, J. Sorber, R. Peterson, J. Skinner, R. Halter, and D. Kotz, “Who wears me? bioimpedance as a passive biometric,” in Proc. 3rd USENIX Workshop on Health Security and Privacy, 2012.
[45] M. Kumar, T. Garfinkel, D. Boneh, and T. Winograd, “Reducing shoulder-surfing by using gaze-based password entry,” in Proceedings of the 3rd symposium on Usable privacy and security. ACM, 2007, pp. 13–19.
[46] A. De Luca, M. Denzel, and H. Hussmann, “Look into my eyes!: Can you guess my password?” in Proceedings of the 5th Symposium on Usable Privacy and Security. ACM, 2009, p. 7.
[47] T. Kinnunen, F. Sedlak, and R. Bednarik, “Towards task-independent person authentication using eye movement signals,” in Proceedings of the 2010 Symposium on Eye-Tracking Research & Applications. ACM, 2010, pp. 187–190.
[10] R. J. Jacob, “Eye tracking in advanced interface design,” Virtual environments and advanced interface design, pp. 258–288, 1995.
[11] W. L. Ottati, J. C. Hickox, and J. Richter, “Eye scan patterns of experienced and novice pilots during visual flight rules (vfr) navigation,” in Proceedings of the Human Factors and Ergonomics Society Annual Meeting, vol. 43, no. 1. SAGE Publications, 1999, pp. 66–70.
[12] D. Tock and I. Craw, “Tracking and measuring drivers’ eyes,” Image and Vision Computing, vol. 14, no. 8, pp. 541–547, 1996.
[13] T. Ito, S. Mita, K. Kozuka, T. Nakano, and S. Yamamoto, “Driver blink measurement by the motion picture processing and its application to drowsiness detection,” in Intelligent Transportation Systems, 2002. Proceedings. The IEEE 5th International Conference on. IEEE, 2002, pp. 168–173.
[14] M. S. Devi and P. R. Bajaj, “Driver fatigue detection based on eye tracking,” in Emerging Trends in Engineering and Technology, 2008. ICETET’08. First International Conference on. IEEE, 2008, pp. 649–652.
[15] C. MacLachlan and H. C. Howland, “Normal values and standard deviations for pupil diameter and interpupillary distance in subjects aged 1 month to 19 years,” Ophthalmic and Physiological Optics, vol. 22, no. 3, pp. 175–182, 2002.
[16] D. Kahneman and J. Beatty, “Pupil diameter and load on memory.” Science, 1966.
[17] S. Taptagaporn and S. Saito, “How display polarity and lighting conditions affect the pupil size of vdt operators,” Ergonomics, vol. 33, no. 2, pp. 201–208, 1990.
[18] D. R. Jasinski, J. S. Pevnick, and J. D. Griffith, “Human pharmacology and abuse potential of the analgesic buprenorphine: a potential agent for treating narcotic addiction,” Archives of General Psychiatry, vol. 35, no. 4, p. 501, 1978.
(2011) Cybersecurity watch survey. [Online]. Available: http://resources.sei.cmu.edu/asset files/Presentation/2011 017 001 54029.pdf
[19]
[20] Michelle and E. Kowalski, “Insider Threat Study: Computer System Sabotage in Critical Infrastructure Sectors,” May 2005. [Online]. Available: http://www.cert.org/archive/pdf/insidercross051105.pdf
[21] M. Kandias, A. Mylonas, N. Virvilis, M. Theoharidou, and D. Gritzalis, “An insider threat prediction model,” in Trust, Privacy and Security in Digital Business. Springer, 2010, pp. 26–37.
[22] V. Cantoni, C. Galdi, M. Nappi, M. Porta, and D. Riccio, “Gant: Gaze analysis technique for human identification,” Pattern Recognition, 2014.
[23] Z. Liang, F. Tan, and Z. Chi, “Video-based biometric identification using eye tracking technique,” in Signal Processing, Communication and Computing (ICSPCC), 2012 IEEE International Conference on. IEEE, 2012, pp. 728–733.
[24] Z. M. Hafed and J. J. Clark, “Microsaccades as an overt measure of covert attention shifts,” Vision research, vol. 42, no. 22, pp. 2533–2545, 2002.
[25] M. Frank, R. Biedert, E. Ma, I. Martinovic, and D. Song, “Touchalytics: On the applicability of touchscreen input as a behavioral biometric for continuous authentication,” IEEE Transactions on Information Forensics and Security, 2012.
J. Dougherty, R. Kohavi, M. Sahami et al., “Supervised and unsupervised discretization of continuous features,” in ICML, 1995, pp. 194–202.
[26]
[27] C. Ding and H. Peng, “Minimum redundancy feature selection from microarray gene expression data,” Journal of bioinformatics and computational biology, vol. 3, no. 02, pp. 185–205, 2005.
[28] K. Holmqvist, M. Nyström, and F. Mulvey, “Eye tracker data quality: what it is and how to measure it,” in Proceedings of the Symposium on Eye Tracking Research and Applications. ACM, 2012, pp. 45–52.
[29] H. Crawford, K. Renaud, and T. Storer, “A framework for continuous, transparent mobile device authentication,” Computers & Security, vol. 39, pp. 127–136, 2013.
[30] A. K. Jain, A. Ross, and S. Pankanti, “Biometrics: a tool for information security,” Information Forensics and Security, IEEE Transactions on, vol. 1, no. 2, pp. 125–143, 2006.

---

This version should be clearer, more coherent, and more professional.