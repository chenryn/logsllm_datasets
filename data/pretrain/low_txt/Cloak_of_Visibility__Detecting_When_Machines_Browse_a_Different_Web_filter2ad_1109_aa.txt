# Cloak of Visibility: Detecting When Machines Browse a Different Web

**Authors:**
- Luca Invernizzi
- Kurt Thomas
- Alexandros Kapravelos
- Oxana Comanescu
- Jean-Michel Picod
- Elie Bursztein

**Publication:**
2016 IEEE Symposium on Security and Privacy

## Abstract
The ongoing conflict between web services and malicious actors, such as those involved in blackhat search engine optimization and the distribution of malicious advertisements, has driven the development of increasingly sophisticated cloaking techniques. These techniques are designed to hide the true nature of malicious sites, thereby reducing the effectiveness of security crawlers and exposing Internet users to harmful content. In this study, we examine a range of blackhat cloaking methods that target browser, network, or contextual cues to detect and differentiate organic visitors from automated ones.

We begin by investigating the capabilities of ten prominent cloaking services available in the underground market. This includes an analysis of multiple IP blacklists containing over 50 million addresses associated with major search engines and numerous antivirus and security crawlers. Based on our findings, we develop an anti-cloaking system capable of detecting split-view content with 95.5% accuracy and a false positive rate of 0.9%, tested on a labeled dataset of 94,946 URLs.

Our system is then applied to an unlabeled set of 135,577 search and advertisement URLs, focusing on high-risk terms (e.g., luxury products, weight loss supplements) to assess the prevalence of threats and variations in cloaking techniques across different traffic sources. This study provides a comprehensive view of cloaking as it affects Google Search and Google Ads, and highlights the essential capabilities required for security crawlers to bypass current cloaking techniques, including mobile, reverse DNS (rDNS), and IP cloaking.

## I. Introduction
The constant evolution of abuse tactics has led to a contentious battle in the realm of web cloaking. Malicious actors use search engines and ad networks to deliver scams, unwanted software, and malware to unsuspecting users. While security crawlers aim to vet and remove harmful content, they face a fundamental challenge: not all clients see the same content. While some content variations are benign (e.g., personalization, geo-optimization, and responsive design), malicious actors exploit similar techniques to serve policy-compliant content to crawlers while delivering harmful content to real users.

Previous research has focused on understanding the prevalence of cloaking and the content behind cloaked doorways, but none have comprehensively measured the spectrum of cloaking techniques affecting search engines and ad networks. Earlier studies often relied on a limited set of known cloaking methods, such as redirect cloaking in search results or visitor profiling based on User-Agent and Referer HTTP headers.

This paper combines both an underground and empirical perspective to study how malicious actors scrutinize incoming client's browser, network, and contextual settings, and the impact on polluting search results and advertisements. We engage directly with specialists selling cloaking software, obtaining ten cloaking packages ranging in price from $167 to $13,188. Our investigation reveals that cloaking software ranges from simple WordPress plugins to fully customized Nginx web servers with built-in blacklisting capabilities. We also analyze multiple IP blacklist databases, one covering 54,166 IP addresses associated with major search engines and another containing over 50 million IP addresses from universities, security products, and cloud providers.

Using our findings, we develop a scalable de-cloaking crawler and classifier that detects when a web server returns divergent content to different browsing clients. We fetch content using 11 increasingly sophisticated user emulators, including Chrome, Android, and a simple robot, accessing the internet via residential, mobile, and data center networks. Our system accurately distinguishes blackhat cloaking from legitimate targeting with 95.5% accuracy and a false positive rate of 0.9%. We apply our system to an unlabeled set of 135,577 Google Search and Google Ads URLs, finding that 11.7% of the top 100 search results and 4.9% of ads cloak against the Googlebot crawler.

Finally, we explore the potential for client-side detection of cloaking and centralized reporting, which can hinder the ability of malicious servers to show benign content exclusively to crawlers, though these approaches must address privacy concerns.

**Contributions:**
- We provide the first broad study of blackhat cloaking techniques and the companies affected.
- We build a distributed crawler and classifier that detects and bypasses mobile, search, and ad cloaking with 95.5% accuracy and a false positive rate of 0.9%.
- We measure the most prominent search and ad cloaking techniques in the wild, finding that 4.9% of ads and 11.7% of search results cloak against Google’s generic crawler.
- We determine the minimum set of capabilities required for security crawlers to contend with cloaking today.

## II. Background & Related Work

### A. Web Cloaking Incentives
Web cloaking involves techniques used by web servers to fingerprint incoming visitors and customize page content. Benign examples include redirecting mobile clients to optimized pages. However, malicious cloaking serves entirely different content to crawlers to inflate search rankings, evade ad quality scanners, or deliver drive-by exploits only to vulnerable clients. This creates a discrepancy between what bots and real users see.

#### 1. Search Results
Cloaking is a tool in blackhat SEO, where servers manipulate pages to appear enticing to crawlers while directing organic visitors to profit-generating content like counterfeit luxury products, pharmaceuticals, and dietary supplements.

#### 2. Advertisements
Miscreants pay ad networks to display their URLs, relying on cloaking to evade policies that prohibit deceptive ads, including malware. Ad scanners see benign pages, while organic visitors land on scam and malware-hosting pages.

#### 3. Drive-by Downloads
Miscreants compromise popular websites and load them with drive-by exploits. To evade security crawlers, these payloads fingerprint clients and attack only vulnerable, organic visitors.

### B. Prevalence of Cloaking
Previous studies have shown that finding instances of cloaking requires knowledge of targeted keywords or vulnerable pages. Wang et al. estimated that only 2.2% of Google searches for trending keywords contained cloaked results, while 61% of searches for specific terms like "viagra 50mg canada" contained cloaked results. Leontiadis et al. found that 32% of searches for pharmaceutical keywords in spam emails led to cloaked content. Our strategy for selecting URLs to crawl builds on these findings to minimize bandwidth waste.

### C. Cloaking Detection Techniques
Researchers have developed various anti-cloaking techniques, such as comparing redirect chains and content fetched by different browser profiles. Early approaches by Wang et al. classified a page as cloaking if the redirect chain deviated across fetches. Subsequent strategies involve examining divergent redirects, content variations, and applying cloaking detection to spammed forum URLs. Our study improves on these techniques by addressing previously unexplored cloaking methods and incorporating additional cross-view comparisons to handle page dynamism, interstitial ads, and network-based cloaking. Our pipeline also distinguishes adversarial cloaking from geo-targeting and content optimization for small screens.

## III. Underground Perspective of Cloaking
Cloaking is a commoditized service in the underground market. We exhaustively crawled and indexed underground forums, ranking discussions based on cloaking-related keywords. The most discussed cloaking package was mentioned 623 times, while the least popular was mentioned only twice. We obtained the top ten most popular cloaking packages, priced from $167 to $13,188. For legal and anonymity reasons, we cannot disclose the names of the forums or software.

We analyzed all ten packages to understand their fingerprinting capabilities, switch logic for displaying targeted content, and other built-in SEO features. Table I summarizes the fingerprinting capabilities of the most sophisticated six samples of cloaking software.

| Capability | C1 | C2 | C3 | C4 | C5 | C6 |
|------------|----|----|----|----|----|----|
| IP Address | ✓  | ✓  | ✓  | ✓  | ✓  | ✓  |
| rDNS       | –  | ✓  | –  | ✓  | ✓  | ✓  |
| Geolocation| –  | ✓  | ✓  | –  | ✓  | ✓  |
| User-Agent | ✓  | ✓  | ✓  | ✓  | ✓  | ✓  |
| JavaScript | –  | ✓  | ✓  | –  | ✓  | ✓  |
| Flash      | –  | ✓  | –  | –  | –  | –  |
| HTTP Referer| ✓  | ✓  | ✓  | ✓  | ✓  | ✓  |
| Keywords   | –  | ✓  | ✓  | –  | ✓  | ✓  |
| Time Window| –  | ✓  | ✓  | –  | ✓  | ✓  |
| Order of Operations | ✓  | ✓  | ✓  | ✓  | ✓  | ✓  |

This table provides a detailed breakdown of the capabilities of each cloaking type, highlighting the sophistication and diversity of cloaking techniques in the underground market.