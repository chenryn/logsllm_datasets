# Summary/Overview for Artificial Intelligence and Security (AISec'13)

## Authors
- **Blaine Nelson**
  - University of Potsdam
  - Building 4, Office 0.20, August-Bebel-Str. 89, 14482 Potsdam, Germany
  - Email: bnelson@cs.uni-potsdam.de

- **Christos Dimitrakakis**
  - Computer Science and Engineering, Chalmers University
  - SE-4172, Sweden
  - Email: chrdimi@chalmers.se

- **Elaine Shi**
  - Department of Computer Science, University of Maryland
  - A.V. Williams Building, College Park, MD 20742, USA
  - Email: elaineshi@umd.edu

## Abstract
The Workshop on Artificial Intelligence and Security (AISec) focuses on the theory and application of AI and machine learning in adversarial settings, such as security and privacy applications. It also addresses the security and privacy implications arising from the use of large-scale AI methods. AISec serves as the premier venue for this interdisciplinary field, attracting submissions from a diverse set of researchers who address newly emerging problems. The workshop provides a forum for researchers in security, privacy, AI, and learning to discuss the role of intelligent technologies in security and privacy applications and to present the unique challenges these problems pose to the AI and learning communities.

## Categories and Subject Descriptors
- **C.2.0 [Computer-Communication Networks]**
  - General—security and protection (e.g., firewalls)
- **D.4.6 [Operating Systems]**
  - Security and Protection
- **I.2.6 [Artificial Intelligence]**
  - Learning
- **I.2.7 [Artificial Intelligence]**
  - Natural Language Processing
- **I.2.8 [Artificial Intelligence]**
  - Problem Solving, Control Methods, and Search
- **K.4.1 [Computers and Society]**
  - Public Policy Issues—privacy
- **K.6.5 [Management of Computing and Information Systems]**
  - Security and Protection

## General Terms
- Algorithms
- Security
- Theory

## Keywords
- Artificial Intelligence
- Computer Security
- Machine Learning
- Computer Privacy
- Secure Learning

## Permission
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee, provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). Copyright is held by the author/owner(s).

**AISec'13, November 4, 2013, Berlin, Germany.**
**ACM 978-1-4503-2488-5/13/11 ...$15.00.**
**http://dx.doi.org/10.1145/2508859.2509031**

## 1. Background and Motivation
The application of artificial intelligence (AI), machine learning (ML), and data mining to security and privacy problems is rapidly expanding. These techniques provide analytical tools and intelligent behavior, making them increasingly important for real-time decision-making in data-rich domains. They offer new solutions to security problems involving big-data analysis, often scaled through cloud computing. However, the use of learning methods in security-sensitive domains also creates new frontiers for security research, where adversaries may attempt to mislead or evade intelligent machines. The AISec workshop provides a platform for presenting and discussing new developments at the intersection of security/privacy with AI and ML.

AISec, now in its sixth consecutive year with CCS, is the leading venue for researchers interested in the convergence of security, privacy, AI, and ML. The past year has seen significant activity within the AISec community, including a Dagstuhl workshop and the fifth AISec workshop. This surge is driven by several factors:
1. AI and ML technologies play a key role in extracting knowledge, situational awareness, and security intelligence from big data.
2. Data-centric companies like Google and Amazon are increasingly exploring and deploying learning technologies to address big-data problems for their customers.
3. These trends are exposing companies and their customers to intelligent technologies, leading to both potential solutions and new vulnerabilities in security and privacy.

## 2. Workshop Objective
The AISec Workshop aims to bring together practical security problems and advances in AI and ML. Researchers at the workshop develop unique theories and analytics, exploring diverse topics such as learning in game-theoretic adversarial environments, privacy-preserving learning, and applications to spam and intrusion detection. While security researchers often use AI/ML techniques to address problems, and AI/ML researchers develop techniques for big-data analytics, each community can only devote limited attention to the other. In security research, AI/ML components are often treated as black-box solvers, while the learning community rarely considers the security/privacy implications of their algorithms. Where these fields intersect, interesting new problems arise, leading to a new branch of research known as secure learning. The AISec Workshop has become the primary venue for this unique fusion of research.

## 3. Topics of Interest
We solicited paper submissions on the following (but not limited to) research topics:

### Learning Theory Topics Related to Security
- Adversarial learning
- Robust statistics
- Online learning
- Learning in stochastic games

### Security Applications
- Computer forensics
- Spam detection
- Phishing detection and prevention
- Botnet detection
- Intrusion detection and response
- Malware identification
- Authorship identification
- Big-data analytics for security

### Security-Related AI Problems
- Distributed inference and decision-making for security
- Secure multiparty computation and cryptographic approaches
- Privacy-preserving data mining
- Adaptive side-channel attacks
- Design and analysis of CAPTCHAs
- AI approaches to trust and reputation
- Vulnerability testing through intelligent probing (e.g., fuzzing)
- Content-driven security policy management and access control
- Techniques and methods for generating training and test sets
- Anomalous behavior detection (e.g., for fraud prevention, authentication)

## 4. Program Committee
We are grateful to the members of our program committee:
- Battista Biggio, University of Cagliari, Italy
- Ulf Brefeld, Technische Universität Darmstadt, Germany
- Michael Brückner, Amazon.com Inc, Germany
- Mike Burmester, Florida State University, USA
- Alvaro A. Cárdenas, University of Texas at Dallas, USA
- Mario Frank, University of California, Berkeley, USA
- Rachel Greenstadt, Drexel University, USA
- Guofei Gu, Texas A&M University, USA
- Ling Huang, Intel Labs, USA
- Anthony Joseph, University of California, Berkeley, USA
- Ari Juels, RSA Labs, USA
- Pavel Laskov, University of Tübingen, Germany
- Daniel Lowd, University of Oregon, USA
- Pratyusa Manadhata, HP Labs, USA
- Aikaterini Mitrokotsa, Chalmers University of Technology, Sweden
- Roberto Perdisci, University of Georgia, USA
- Vasyl Pihur, Google Inc., USA
- Konrad Rieck, University of Göttingen, Germany
- Fabio Roli, University of Cagliari, Italy
- Benjamin I. P. Rubinstein, IBM Research, Australia
- Robin Sommer, ICSI and LBNL, USA
- Nina Taft, Technicolor, USA
- J. D. Tygar, University of California, Berkeley, USA
- Shobha Venkataraman, AT&T Research, USA
- Ting-Fang Yen, RSA Labs

## 5. Workshop Organizers
- **Blaine Nelson**
  - Postdoctoral researcher at the University of Potsdam
  - Previously a postdoctoral research fellow at the University of Tübingen and obtained his Ph.D. from the University of California, Berkeley
  - Co-chair of AISec 2012 and co-organizer of the Dagstuhl Workshop on "Machine Learning Methods for Computer Security" in 2012
  - Research focuses on learning algorithms in security-sensitive application domains, investigating the vulnerability of learning to security threats and resilient learning techniques

- **Christos Dimitrakakis**
  - Researcher at Chalmers University of Technology
  - Main research interest in decision theory, including reinforcement learning and problems in security applications
  - Obtained his Ph.D. in 2006 from EPFL and was a researcher at the universities of Leoben, Amsterdam, and Frankfurt
  - Most recently a Marie Curie Fellow at EPFL
  - Co-organized a workshop on Privacy, Security, Data Mining, and Machine Learning (PSDML) in conjunction with ECML 2010

- **Elaine Shi**
  - Assistant Professor in the Computer Science Department at the University of Maryland, College Park
  - Research combines systems security, cryptography, and data mining to design secure and privacy-preserving computing systems
  - Obtained her Ph.D. from Carnegie Mellon University in 2008
  - Previously a Member of Research Staff at Xerox PARC and a research scientist at UC Berkeley
  - Served on the program committees of more than 25 conferences and workshops, currently co-chairing a cloud security workshop under AsiaCCS
  - Helped organize an NSF/Intel-sponsored security curriculum workshop and the Cross-Disciplinary Conversations session for the SaTC PI meeting in 2012