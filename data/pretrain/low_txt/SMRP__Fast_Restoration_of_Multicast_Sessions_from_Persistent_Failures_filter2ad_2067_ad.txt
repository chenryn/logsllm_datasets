### 4.3.1 Effect of Dthresh on Performance

In this section, we analyze the impact of the parameter \(D_{\text{thresh}}\) on the performance of the proposed protocol (PIM), which we refer to as global detour for simplicity. In the simulation, the values of \(N\), \(N_G\), \(\alpha\), and \(D_{\text{thresh}}\) are set to 100, 30, 0.2, and 0.3, respectively. Five network topologies are randomly generated using GT-ITM, and in each topology, a group of multicast members is also randomly selected.

In Figure 7, the x-axis and y-axis represent the recovery distance via global detour and local detour, respectively. For each multicast member \(R\), we consider the worst-case scenario where the link closest to the source node on \(R\)'s multicast path (i.e., the incident link of \(S\) towards \(R\)) fails. This situation represents the most severe condition for \(R\) because it disables the largest portion of the multicast tree. Each asterisk in the figure represents the simulation result for one member in each randomly-generated topology. As shown in the figure, most points lie below the line \(y = x\), indicating that the recovery path via local detour is shorter than the recovery path via global detour. Overall, we observe that the length of the recovery path via local detour is reduced by an average of 33%.

### 4.3.2 Threshold \(D_{\text{thresh}}\)

Next, we explore how the parameter \(D_{\text{thresh}}\) affects the protocol performance with respect to the evaluation metrics. All parameters except \(D_{\text{thresh}}\) are fixed, with \(N\), \(N_G\), and \(\alpha\) set to 100, 30, and 0.2, respectively. Four values of \(D_{\text{thresh}}\) are tested. For each test, ten network topologies are randomly generated using GT-ITM, and in each topology, ten different sets of multicast members are also randomly selected. Each of these 100 simulation scenarios is tested for SMRP and SPF protocols separately, and the performance comparison is plotted in Figure 8. The error bars in the figure represent the 95% confidence intervals for the associated metrics. Similarly to Section 4.3.1, the worst-case scenario for each member's recovery is examined.

According to the definition of the three evaluation metrics, \(RD_{\text{relative}}\) indicates how much SMRP further accelerates the service recovery, while \(D_{\text{relative}}^R\) and \(Cost_{\text{relative}}^T\) measure the performance penalty in terms of increased end-to-end delay and tree cost, respectively. The following characteristics of SMRP can be observed in Figure 8:

- A significant improvement is achieved by SMRP with a moderate amount of overhead. For example, when \(D_{\text{thresh}}\) is 0.3, the length of the recovery path is reduced by an average of 20% in SMRP with only a 5% performance penalty in terms of increased end-to-end delay or tree cost.
- The performance improvement increases linearly with the parameter \(D_{\text{thresh}}\), while more penalties are induced. This illustrates the fundamental property of the new protocol: SMRP trades communication efficiency (e.g., end-to-end delay) for decreased path sharing in the multicast tree (i.e., the increased possibility of fast service recovery via a local assistant). The introduction of the \(D_{\text{thresh}}\) parameter enables fine control of the protocol, making it applicable to a variety of applications with different fault-tolerance preferences.

### 4.3.3 Average Node Degree \(\alpha\)

In this simulation, we examine the impact of the average node degree \(\alpha\) on the performance achieved by SMRP. The average node degree of the topology can be tuned by \(\alpha\). We fix the values of \(N\), \(N_G\), and \(D_{\text{thresh}}\) to 100, 30, and 0.3, respectively, and compare the results under four different \(\alpha\) values: 0.15, 0.2, 0.25, and 0.3. During each test, one hundred scenarios are generated in which SMRP and SPF-based protocols are evaluated. Figure 9 shows SMRP’s relative performance against the SPF algorithms. The number under each \(\alpha\) value indicates the corresponding average node degree in the network.

- In Figure 9, we observe that the performance improvement slightly diminishes as \(\alpha\) (i.e., the node degree) increases. In a network with low connectivity, the multicast tree established by SPF-based algorithms tends to have serious link/node concentration, and hence, the deployment of SMRP makes more performance improvement by lowering path sharing in the multicast tree.
- An acceptable performance improvement can still be achieved in networks with high connectivity. Further study shows that even when the average node degree goes up to 10, SMRP achieves a 12% reduction in path length at the expense of a 5% performance penalty.

### 4.3.4 Group Size \(N_G\)

The effect of group size \(N_G\) on SMRP’s performance is examined using a similar procedure. All tunable parameters except for \(N_G\) are fixed (\(N = 100\), \(\alpha = 0.2\), \(D_{\text{thresh}} = 0.3\)), and the value of \(N_G\) is varied to 20, 30, 40, and 50. The simulation results are plotted in Figure 10 and summarized as follows:

- The performance remains steady with changes in \(N_G\). SMRP outperforms SPF-based algorithms in terms of recovery distance, with the path shortened by an average of 20%. The overhead incurred by SMRP remains at about 5%.
- With the increase in group size, we observe a slight decrease in the performance improvement in terms of average \(RD_{\text{relative}}^R\). This is possibly because, in the same network topology, a larger group makes each member have more close neighbors, thereby diminishing SMRP’s advantage.

### 5 Conclusion and Future Work

With the objective of increasing the likelihood of successful local multicast service recovery, we have proposed a new multicast routing protocol, called SMRP, to construct a multicast tree with less node/link sharing. During the path selection, the parameter \(D_{\text{thresh}}\) can be used to make a controlled tradeoff between the recovery distance and communication overhead in terms of end-to-end delay and tree cost. Our in-depth simulation demonstrates the merits of the proposed protocol. For example, in one simulation setup, the recovery path for each receiver is reduced, on average, by 20% with about 5% overhead. SMRP provides a good option for multicast applications with different quality-of-service (especially fault-tolerance) preferences.

In our ongoing work, we are conducting a more comprehensive evaluation of the protocol by comparing it against other recently proposed algorithms. Additionally, we are collecting Internet topology data to evaluate SMRP’s applicability to real networks.

### References

[1] A. Reddy, R. Govindan, and D. Estrin. Fault Isolation in Multicast Trees. In Proc. ACM SIGCOMM, pages 29–40, Stockholm, Sweden, Aug. 2000.

[2] B. M. Waxman. Routing of Multipoint Connections. IEEE Journal on Selected Areas in Communications, 6(9):1617–1622, 1988.

[3] C. Labovitz, R. Malan, and F. Jahanian. Internet Routing Instability. IEEE/ACM Transactions on Networking, 6(5):515–558, Oct. 1998.

[4] C. Labovitz, R. Malan, and F. Jahanian. Origins of Internet Routing Instability. In Proc. IEEE INFOCOM ’99, volume 1, pages 21–25, Mar. 1999.

[5] D. Estrin, D. Farinacci, A. Helmy, D. Thaler, S. Deering, M. Handley, V. Jabobson, C. Liu, P. Sharma, and L. Wei. Protocol Independent Mutlicast-Sparse Mode (PIM-SM): Protocol Specification. IETF RFC 2362, Jun. 1998.

[6] D. Li and D. R. Cheriton. OTERS (On-Tree Efficient Recovery using Subcasting): A Reliable Multicast Protocol. In Proc. IEEE International Conference on Network Protocols (ICNP’98), pages 237–245, Oct. 1998.

[7] E. W. Zegura, K. Calvert and M. J. Donahoo. A quantitative comparison of graph-based models for internet topology. IEEE/ACM Transactions on Networking, 5(6), Dec. 1997.

[8] H. W. Holbrook and D. R. Cheriton. IP Multicast Channels: EXPRESS Support for Large-scale Single-source Applications. In Proc. ACM SIGCOMM ’99, pages 65–78, Cambridge, MA, Aug. 1999.

[9] J. Moy. Multicast Extensions to OSPF. IETF RFC 1584, Mar. 1994.

[10] J. Moy. OSPF Version 2. IETF RFC 2328, Apr. 1998.

[11] K. Calvert and E. Zegura. GT-ITM: Georgia Tech internetwork topology models. http://www.cc.gatech.edu/fac/Ellen.Zegura/gt-itm/gt-itm.tar.gz, 1996.

[12] K. P. Birman, M. Hayden, O. Ozkasap, Z. Xiao, M. Budiu, and Y. Minsky. Bimodal Multicast. ACM Transactions on Computer Systems, 17(2):41–88, 1999.

[13] L. Wei and D. Estrin. The Trade-offs of Multicast Trees and Algorithms. In Proc. ICCCN ’94, San Francisco, CA, Sep. 1994.

[14] M. Handley, I. Kouvelas, T. Speakman, and L. Vicisano. Bi-directional Protocol Independent Multicast (BIDIR-PIM). IETF Draft, Jun. 2003.

[15] M. J. Lin and K. Marzullo. Directional Gossip: Gossip in a Wide Area Network. In Proc. of European Dependable Computing Conference (EDCC-3), 2000.

[16] M. Medard, S. G. Finn, R. A. Barry, and R. G. Gallager. Redundant Trees for Preplanned Recovery in Arbitrary Vertex-Redundant or Edge-Redundant Graphs. IEEE/ACM Transactions on Networking, 7(5):641–652, Oct. 1999.

[17] R. Yavatkar, J. Griffoen, and M. Sudan. A Reliable Dissemination Protocol for Interactive Collaborative Applications. In Proc. ACM MULTIMEDIA’95, pages 333–344, Nov. 1995.

[18] S. Banerjee, B. Bhattacharjee, and C. Kommareddy. Scalable Application Layer Multicast. In Proc. ACM SIGCOMM, pages 205–220, Pittsburgh, PA, Sep. 2002.

[19] S. Banerjee, S. Lee, B. Bhattacharjee, and A. Srinivasan. Resilient Multicast using Overlays. Proc. ACM SIGMETRICS ’03, pages 102–113, Jun. 2003.

[20] S. D. Nikolopoulos, A. Pitsillides and D. Tipper. Addressing Network Survivability Issues by Finding the K-best Paths through a Trellis Graph. In Proc. IEEE INFOCOM ’97, volume 1, pages 370–377, Kobe, Japan, Jun. 1997.

[21] S. Floyd, V. Jacobson, C. Liu, S. McCanne and L. Zhang. A Reliable Multicast Framework for Light-Weight Sessions and Application Level Framing. IEEE/ACM Transactions on Networking, 5(6):784–803, Dec. 1997.

[22] S. Han and K. G. Shin. Fast Restoration of Real-Time Communication Service From Component Failures in Multihop Networks. In Proc. ACM SIGCOMM ’97, pages 77–88, Cannes, France, Sep. 1997.

[23] S. Paul, K. Sabnani, J. Lin, and S. Bhattacharyya. Reliable Multicast Transport Protocol (RMTP). IEEE Journal on Selected Areas in Communications, 15(3):407–421, Apr. 1997.

[24] UCB/LBNL/VINT. ns2. Simulator Network. http://www.isi.edu/nsnam/ns/index.html, Mar. 2002.

[25] X. Wang, C. Yu, H. Schulzrinne, P. Stirpe, and W. Wu. IP Multicast Fault Recovery in PIM over OSPF. In 8th International Conference on Network Protocols (ICNP’2000), Osaka, Japan, Nov. 2000.