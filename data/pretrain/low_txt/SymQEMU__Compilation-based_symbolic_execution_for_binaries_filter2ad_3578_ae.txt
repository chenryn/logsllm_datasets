# SymQEMU: A Compilation-Based Symbolic Execution for Binaries

## Figure 14: Time Spent in Execution and SMT Solving

- **Execution and SMT Solving Time**: The figure shows the time spent in execution and SMT solving, respectively, averaged across concolic execution of a fixed set of test cases (1000 cases per target, chosen at random and analyzed in each of the three symbolic executors). Times are normalized to the total execution time of the slowest engine per target to highlight the differences in the overall amount of time required to complete the benchmark.

## Alternative Approaches for Helper Functions
- **Automatic Symbolic Versions of Helpers**: An alternative approach is to automatically build symbolic versions of the helpers. SymCC can be used to compile symbolic tracing into the helpers, whose source code is available as part of QEMU. The resulting binaries would be compatible with SymQEMU because SymCC uses the same backend for symbolic reasoning. S2E follows a similar approach by compiling the helpers to LLVM bitcode for interpretation in KLEE.
- **Future Work**: Such improvements would primarily benefit specific targets that heavily use complex instructions, and we leave this to future work.

## VI. Related Work
### A. Binary-Only Symbolic Execution
- **Angr, S2E, QSYM, and SymCC**: These tools have been described in Section II, and we have compared them to SymQEMU in Section III-D.
- **Mayhem**: A high-performance interpreter-based implementation of symbolic execution that won the DARPA CGC competition but is not publicly available for comparison.
- **Triton**: Has a symbolic execution component that can operate in two modes: one using binary translation (like QSYM) and the other working with CPU emulation (like S2E and angr).
- **Eclipser**: Bridges fuzzing and symbolic execution by assuming linear relations between branch conditions and input data, increasing performance but reducing reasoning power.
- **Redqueen**: Uses heuristics to search for correspondence between branch conditions and input bytes. In contrast, SymQEMU implements "full" symbolic execution.

### B. Run-Time Bug Detection
- **Hybrid Fuzzing and Sanitizers**: Hybrid fuzzing relies on fuzzers and sanitizers to detect bugs. AddressSanitizer is a popular sanitizer that checks for certain memory errors, requiring source code for instrumentation. QASan, a QEMU-based system, implements similar checks for binaries. There are many other sanitizers, often requiring source code, which could complement hybrid fuzzing with SymQEMU via emulation, similar to QASan.

### C. Hybrid Fuzzing
- **Driller**: A hybrid fuzzer based on angr, similar to QSYM but slower due to its Python implementation and interpreter-based approach. It uses a more elaborate strategy to coordinate the fuzzer and symbolic executor.
- **Pangolin**: Enhances the fuzzer's benefit from symbolic execution by providing new test cases and an abstraction of the symbolic constraints, along with a fast sampling method, allowing the fuzzer to generate inputs with a high probability of fulfilling path constraints.
- **Coordination Strategies**: More sophisticated coordination strategies between the fuzzer and symbolic executor can enhance hybrid fuzzing performance. However, such improvements are orthogonal to the speed of the symbolic executor, which is SymQEMU's main focus.

## VII. Conclusion
- **SymQEMU Overview**: We have presented SymQEMU, a novel approach to applying compilation-based symbolic execution to binaries. Our evaluation shows that SymQEMU significantly outperforms state-of-the-art binary symbolic executors and even keeps up with source-based techniques. SymQEMU is easy to extend to many target architectures, requiring just a few lines of code to support any architecture that QEMU can handle. We have also demonstrated SymQEMU's real-world use by discovering a previously unknown memory error in the heavily tested libarchive library.

## Availability
- **Source Code**: The source code for SymQEMU is publicly available at http://www.s3.eurecom.fr/tools/symbolic-execution/symqemu.html. Detailed instructions to reproduce our experiments and the raw results of our evaluation are also provided.

## Acknowledgments
- **Reviewers and Support**: We thank the anonymous reviewers for their thoughtful feedback and suggestions, which helped us improve the quality of the paper. This work has been supported partly by the DAPCODS/IOTics ANR 2016 project (ANR-16-CE25-0015) and partly by the Defense Advanced Research Projects Agency (DARPA) under agreement number FA875019C0003.

## References
- [1] C. Aschermann, S. Schumilo, T. Blazytko, R. Gawlik, and T. Holz, “Redqueen: Fuzzing with input-to-state correspondence,” in Network and Distributed System Security Symposium (NDSS), vol. 19, 2019, pp. 1–15.
- [2] R. Baldoni, E. Coppa, D. C. D’Elia, C. Demetrescu, and I. Finocchi, “A survey of symbolic execution techniques,” ACM Computing Surveys (CSUR), vol. 51, no. 3, p. 50, 2018.
- [3] F. Bellard, “QEMU, a fast and portable dynamic translator,” in USENIX Annual Technical Conference, FREENIX Track, vol. 41, 2005, p. 46.
- [4] C. Cadar, D. Dunbar, and D. R. Engler, “KLEE: Unassisted and automatic generation of high-coverage tests for complex systems programs,” in OSDI, vol. 8, 2008, pp. 209–224.
- [5] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley, “Unleashing Mayhem on binary code,” in 2012 IEEE Symposium on Security and Privacy. IEEE, 2012, pp. 380–394.
- [6] V. Chipounov, V. Kuznetsov, and G. Candea, “S2E: A platform for in-vivo multi-path analysis of software systems,” in ACM SIGARCH Computer Architecture News, vol. 39, no. 1. ACM, 2011, pp. 265–278.
- [7] J. Choi, J. Jang, C. Han, and S. K. Cha, “Grey-box concolic testing on binary code,” in 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 2019, pp. 736–747.
- [8] A. Fioraldi, D. C. D’Elia, and L. Querzoni, “Fuzzing binaries for memory safety errors with QASan.” Available: https://andreaﬁoraldi.github.io/assets/qasan-secdev20.pdf
- [9] E. Gustafson, M. Muench, C. Spensky, N. Redini, A. Machiry, Y. Fratantonio, D. Balzarotti, A. Francillon, Y. R. Choe, C. Kruegel, and G. Vigna, “Toward the embedded firmware through automated re-hosting,” in 22nd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2019). Chaoyang District, Beijing: USENIX Association, Sep. 2019, pp. 135–150. Available: https://www.usenix.org/conference/raid2019/presentation/gustafson
- [10] H. Huang, P. Yao, R. Wu, Q. Shi, and C. Zhang, “Pangolin: Incremental hybrid fuzzing with polyhedral path abstraction,” in 2020 IEEE Symposium on Security and Privacy (SP). Los Alamitos, CA, USA: IEEE Computer Society, May 2020, pp. 1613–1627. Available: https://doi.ieeecomputersociety.org/10.1109/SP40000.2020.00063
- [11] S. Kim, M. Faerevaag, M. Jung, S. Jung, D. Oh, J. Lee, and S. K. Cha, “Testing intermediate representations for binary analysis,” in Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering. IEEE Press, 2017, pp. 353–364.
- [12] J. C. King, “Symbolic execution and program testing,” Communications of the ACM, vol. 19, no. 7, pp. 385–394, 1976.
- [13] G. Klees, A. Ruef, B. Cooper, S. Wei, and M. Hicks, “Evaluating fuzz testing,” in Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, 2018, pp. 2123–2138.
- [14] C. Lattner and V. Adve, “LLVM: A compilation framework for lifelong program analysis & transformation,” in Proceedings of the International Symposium on Code Generation and Optimization: Feedback-Directed and Runtime Optimization. IEEE Computer Society, 2004, p. 75.
- [15] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood, “Pin: Building customized program analysis tools with dynamic instrumentation,” in ACM SIGPLAN Notices, vol. 40, no. 6. ACM, 2005, pp. 190–200.
- [16] M. Muench, J. Stijohann, F. Kargl, A. Francillon, and D. Balzarotti, “What you corrupt is not what you crash: Challenges in fuzzing embedded devices,” in Network and Distributed System Security Symposium (NDSS), 2018.
- [17] N. Nethercote and J. Seward, “Valgrind: A framework for heavyweight dynamic binary instrumentation,” in ACM SIGPLAN 2007 Conference on Programming Language Design and Implementation (PLDI 2007), vol. 42, no. 6. ACM, 2007, pp. 89–100.
- [18] C. Pang, R. Yu, Y. Chen, E. Koskinen, G. Portokalidis, B. Mao, and J. Xu, “SoK: All you ever wanted to know about x86/x64 binary disassembly but were afraid to ask,” arXiv preprint arXiv:2007.14266, 2020.
- [19] S. Poeplau and A. Francillon, “Systematic comparison of symbolic execution systems: Intermediate representation and its generation,” in Proceedings of the 35th Annual Computer Security Applications Conference. ACM, 2019, pp. 163–176.
- [20] ——, “Symbolic execution with SymCC: Don’t interpret, compile!” in 29th USENIX Security Symposium (USENIX Security 20). Boston, MA: USENIX Association, 2020. Available: https://www.usenix.org/conference/usenixsecurity20/presentation/poeplau
- [21] N. A. Quynh and D. H. Vu, “Unicorn – the ultimate CPU emulator,” https://www.unicorn-engine.org/, 2015.
- [22] F. Saudel and J. Salwan, “Triton: A dynamic symbolic execution framework,” in Symposium sur la sécurité des technologies de l’information et des communications, SSTIC, Rennes, France, June 3-5 2015. SSTIC, 2015, pp. 31–54.
- [23] K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov, “AddressSanitizer: A fast address sanity checker,” in USENIX Annual Technical Conference (USENIX ATC 12), 2012, pp. 309–318.
- [24] Y. Shoshitaishvili, R. Wang, C. Hauser, C. Kruegel, and G. Vigna, “Firmalice – automatic detection of authentication bypass vulnerabilities in binary firmware,” in Network and Distributed System Security Symposium (NDSS), 2015.
- [25] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino, A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel et al., “Sok: (state of) the art of war: Offensive techniques in binary analysis,” in 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 2016, pp. 138–157.
- [26] D. Song, J. Lettner, P. Rajasekaran, Y. Na, S. Volckaert, P. Larsen, and M. Franz, “SoK: Sanitizing for security,” in 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019, pp. 1275–1295.
- [27] N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang, J. Corbetta, Y. Shoshitaishvili, C. Kruegel, and G. Vigna, “Driller: Augmenting fuzzing through selective symbolic execution,” in Network and Distributed System Security Symposium (NDSS), vol. 16, 2016, pp. 1–16.
- [28] I. Yun, S. Lee, M. Xu, Y. Jang, and T. Kim, “QSYM: A practical concolic execution engine tailored for hybrid fuzzing,” in 27th USENIX Security Symposium (USENIX Security 18), 2018, pp. 745–761.
- [29] J. Zaddach, L. Bruno, A. Francillon, and D. Balzarotti, “AVATAR: A framework to support dynamic security analysis of embedded systems’ firmwares,” in Network and Distributed System Security Symposium (NDSS), vol. 14, 2014, pp. 1–16.

## Appendix A: S2E Resource Consumption
- **Parallel S2E**: S2E has a parallel mode where it starts multiple processes, each assigned a dedicated portion of the state tree. Initially, we tried to use this mode to compensate for the fact that the other symbolic executors in our comparison each use 3 CPU cores. However, in our setup, parallel mode was prone to deadlocks and crashes that were hard to debug. As a workaround, we started 3 independent S2E instances, relying on randomization of the search strategy to prevent them from exploring the same paths.
- **Memory Limits**: We attempted to execute S2E with 2 GB of RAM per CPU core. Setting a hard limit via cgroups, as we did for the other systems, turned out impossible because S2E runs the entire analysis in a single long-running process. If the operating system terminates that process due to excessive memory consumption, the analysis fails. S2E provides the ResourceMonitor plugin for such cases, but in our experiments, the plugin did not reduce memory consumption aggressively enough. Finally, we resorted to imposing a total limit on the cumulative memory consumption of all S2E processes, allowing some processes to consume more than 2 GB of RAM and analyze the target for 24 hours.

## Appendix B: FuzzBench Report
- **Rankings and Performance**: The figures below show the respective ranking of the fuzzers and our SymQEMU/AFL hybrid fuzzer on the 21 FuzzBench targets. The full report, including coverage over time, statistical significance, and coverage distribution, is available on our website. According to the authors of the FuzzBench suite, the low performance of all but five fuzzers on the libpcap target is due to a deficiency in AFL’s code instrumentation, which all the low-performing fuzzers are based on. Similarly, SymQEMU depends on the fuzzer to identify promising test cases, so when the fuzzer’s instrumentation fails, it cannot make progress either.