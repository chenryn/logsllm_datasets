### Management and Human Factors in Vulnerability Discovery

Research has shown that human factors, such as trust, communication, funding, and staffing issues, can significantly hinder vulnerability discovery efforts [4]. To understand how security managers handle staff requirements and behavior, Reinfelder et al. conducted interviews with security managers [33] and found that organizational structures that exclude staff from security development processes often lead to negative perceptions of staff by security managers. To the best of our knowledge, few studies in usable security research have comparatively analyzed managers and developers through interviews and fieldwork [30, 32, 36], and these studies have identified that major constraints on security in software development are often due to organizational structures. Our study is the first to quantitatively analyze the specific security awareness of managers and how the gaps between managers and developers affect secure software development.

## Methodology

In this section, we describe the design of our survey, the recruitment process, and the measures taken to ensure the quality of the data. The complete set of questions used in the screening and main survey is provided in Appendices A and B.

### 3.1 Survey Design

Our survey questions are categorized into three parts: (1) participant demographics, (2) development characteristics, and (3) security behavior and awareness. The question formats include multiple-choice options, Likert scales, and free-form responses. Detailed descriptions of the specific questions are presented in Section 3.2.

To minimize the cognitive load on participants, we iteratively reviewed and refined the questionnaire. Initially, we designed a prototype based on previous studies [6, 37] for (1) participant demographics and (3) security behavior and awareness. We also incorporated insights from interviews with five experts with extensive software development experience to design questions for (2) development characteristics. The prototype was then thoroughly reviewed by the authors and four development experts, and questions that were semantically similar or difficult to understand were either removed or revised. Finally, we conducted a pilot survey with two development management experts to ensure the questionnaire was comprehensive and of appropriate length.

### 3.2 Questionnaire

#### 3.2.1 Questions on Development Characteristics

We asked questions about four development-related characteristics that may impact software security: the industry in which the software is used, the user scope of the software, the contractual relationship of the project, and the development method used in the project.

- **Characteristic 1: User Scope**  
  We asked whether the software being developed was intended for the general public or limited to specific users.

- **Characteristic 2: Contractual Relationship**  
  We inquired about the contractual relationship of the participants' projects: in-house development (developed for the participant's company) or contracted development (developed for another company). For those involved in contracted development, we further asked if their company was the prime contractor or a subcontractor. A prime contractor receives orders directly from a client, while a subcontractor receives orders from a prime contractor or another subcontractor.

- **Characteristic 3: Development Method**  
  We asked which development method was adopted in the participants' projects: Waterfall, Agile, or a hybrid of the two (e.g., Spiral).

A similar survey by Assal and Chiasson [6] explored the relationship between security and development methods but did not qualitatively study user scope or contractual relationships, which are new perspectives in our study. Although we selected the above development characteristics based on their strong impact on security, as indicated by professional developers, there may be other characteristics that also affect security, such as the type of software and the industry it serves (e.g., financial software). Future work will involve analyzing these additional factors for a broader understanding of security in development projects.

#### 3.2.2 Questions on Security Behavior and Awareness

The questionnaire included 32 questions (R1, E1–E15, A1–A5, and C1–C11) about the participants' security behavior and awareness in their development projects. 

- **Question R1** asked about the percentage of resources directed towards security out of the overall resources in a project.
- **Questions E1–E15, A1–A5, and C1–C11** covered security efforts practiced, security awareness, and factors hindering security, respectively. Participants rated their agreement with statements on a 5-point Likert scale (Strongly agree, Agree, Neither agree nor disagree, Disagree, Strongly disagree). For participants unaware of specific security efforts, "Not sure" was an option. Additionally, a free-form question was included to capture any unlisted cases.

These questions were designed based on existing studies [6, 37], and we reduced the number of questions by merging similar ones to minimize respondent fatigue. This was done based on feedback from a pilot survey with development management experts and discussions among the authors. For example, the questions “Software security does not fit in my schedule” and “I do not have time to address software security” in [6] were combined into “C1. Our project does not have enough time to ensure software security.”

### 3.3 Recruitment

Our survey focused on software development in teams, targeting both managers and developers. We recruited participants through a paid service offered by a survey company [23], which has a diverse pool of participants in both the U.S. and Japan, in August 2020. Participants were initially screened with a set of questions and then filtered and grouped based on the results.

- **Screening Condition 1: Working in a Team**  
  We asked if participants were working on software development in a team of multiple people and excluded those who were not (e.g., non-professional development). This filtering was necessary to focus on the roles and job titles of the participants.

- **Screening Condition 2: Developer or Manager**  
  We asked participants to identify their role: (1) developer (with tasks such as implementation, testing, and reviewing) or (2) manager (with tasks such as scheduling and resource management). For those who selected the manager role, we further asked if they had the authority to decide on security efforts and excluded those who did not. This was necessary to focus on the security behavior and awareness of managers with decision-making authority.

All participants who passed the screening and completed the survey received a monetary reward of US$10, which is well above the federal minimum wage based on the average survey completion time.

### 3.4 Data Quality

To ensure high-quality data, we excluded low-quality responses based on the following criteria:
- Responses that failed a simple attention check
- Responses with contradictions
- Responses from questionnaires completed in less than five minutes
- Responses with meaningless answers in open-ended questions (i.e., mechanically filled without reading the questions)

### 3.5 Ethics

This study adheres to the research ethics principles outlined in the Menlo Report, and the survey questions and procedures were approved by our Institutional Review Board (IRB). Participants were informed about the content of the survey and participated voluntarily. Collected personal data was handled in compliance with the personal information protection laws of the participants' countries.

## 4. Results

In this section, we present the basic survey statistics and the analysis results concerning the three research questions (RQs) described in Section 1. Since all questions were optional, the results included empty answers, which were excluded from the analyses. The actual number of responses used in each analysis is specified in the corresponding subsection.

### 4.1 Participant Demographics

Our analysis covered a total of 307 participants (162 developers and 149 managers) in the U.S. and 357 participants (184 developers and 173 managers) in Japan, after the participant screening and exclusion of invalid responses. The average survey completion time for valid responses was 22.4 minutes (median = 10.9 minutes). Table 1 provides the participant demographics (see Table 4 in Appendix D for more detailed demographics). The participants' ages and years of experience were diverse, and the sizes of their companies and projects varied, although companies and projects tended to be larger in the U.S.

Regarding the user scope of developed software, products for specific users outnumbered those for the general public, a trend observed in both the U.S. and Japan. In terms of contractual relationships, the U.S. had more in-house developments (N = 242, 79%), while Japan had more contracted developments (N = 246, 69%). Agile and Waterfall were the most common development methods in both countries.

### 4.2 Factor Analysis

We performed an exploratory factor analysis (EFA) on the results of the security-related questions from the U.S. participants (Figure 1). This allowed us to reduce the number of variables by grouping the results for each question by common factors. The EFA was conducted using principal axis factoring and promax rotation, an oblique rotation method that allows for correlated factors. Since individual factors related to security behavior and awareness are likely to be correlated, we used an oblique rotation method. Questions with factor loadings of 0.4 or higher for the common factors were grouped together.