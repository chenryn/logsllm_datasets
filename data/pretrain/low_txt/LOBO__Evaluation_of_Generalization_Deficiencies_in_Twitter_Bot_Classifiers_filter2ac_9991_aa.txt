# LOBO: Evaluation of Generalization Deficiencies in Twitter Bot Classifiers

## Authors
Juan Echeverría, Emiliano De Cristofaro, Nicolas Kourtellis, Ilias Leontiadis, Gianluca Stringhini, and Shi Zhou

**Affiliations:**
- Juan Echeverría, Emiliano De Cristofaro, and Shi Zhou: University College London
- Nicolas Kourtellis and Ilias Leontiadis: Telefonica Research
- Gianluca Stringhini: Boston University

## Abstract
Botnets on online social networks, particularly Twitter, are increasingly disrupting normal discussions, attacking users, and spreading irrelevant or offensive content. They also manipulate the popularity of messages and accounts. The ongoing arms race between researchers and cybercriminals means that new and updated botnets are constantly developed to evade current detection systems, rendering these systems obsolete.

In this paper, we highlight the need for a generalized evaluation of Twitter bot classifiers and propose a methodology to test their performance on unseen bot classes. Our empirical results show that this methodology is robust, using bot classes of varying sizes and characteristics, and achieving consistent results. We argue that methods trained and tested on single bot classes or datasets may not generalize well to new bot classes. We train a classifier on over 200,000 data points, achieving over 97% accuracy. However, when tested using our proposed methodology, the classifier does not generalize well to unseen bot classes. We discuss the implications of our findings and reasons why some bot classes are easier and faster to detect than others.

## Keywords
Twitter Bots, Botnets, Generalization, Classification, Social Networks, Big Data

## ACM Reference Format
Echeverría, J., De Cristofaro, E., Kourtellis, N., Leontiadis, I., Stringhini, G., & Zhou, S. (2018). LOBO – Evaluation of Generalization Deficiencies in Twitter Bot Classifiers. In Proceedings of ACSAC '18, December 3–7, 2018, San Juan, PR, USA. https://doi.org/10.1145/3274694.3274738

## 1 Introduction
Automated malicious activity on social networks like Twitter has been a significant problem for many years. Fake accounts controlled by bots are used for various types of abuse, such as sending spam, participating in reputation manipulation schemes, spreading malware, and phishing. These accounts are often created and controlled by single miscreants, forming so-called botnets. To counter this, the research community has developed several systems to detect and block bot accounts. These approaches look at profile characteristics, social graph differences, control mechanisms, and posted content to identify malicious behavior.

Despite extensive research, bot detection remains an open problem. One reason is the adversarial nature of the task; once a defense mechanism is known, adversaries can modify their tactics to avoid detection. Another, more fundamental issue, is that machine learning-based detection systems require example datasets of bots, which often contain biases. For instance, a system trained on a dataset containing only one type of botnet will learn the specific idiosyncrasies of that botnet and perform poorly on other botnets.

In this paper, we systematically address this problem. We collect a dataset with over 20 different bot classes, most of which have been used in previous bot detection efforts. We propose a methodology to evaluate the generalization capabilities of bot classifiers by testing them on unseen bot classes. This "Leave-One-Botnet-Out" (LOBO) method trains the classifier on diverse bot data and tests its accuracy on unseen bot behaviors.

We use this methodology to test a classifier on over 1.5 million bots, showing that while it achieves over 97% accuracy on a single bot dataset, it performs poorly on new bot families. Some target botnets completely mislead the classifier, resulting in less than 1% detection accuracy. Our methodology provides a proxy for real-world generalization performance and aids in identifying the relationships between different bot classes.

Our contributions include:
- Highlighting the need to go beyond common machine learning metrics like accuracy, precision, and recall for Twitter bot detection.
- Providing a framework to evaluate the expected generalization of a bot detection algorithm by selectively leaving bot classes out of the training data.
- Collecting and combining the largest and most diverse botnet library to date.
- Introducing a classification strategy that achieves over 97% accuracy with commonly used features and evaluating its performance using the generalization test.
- Analyzing the trade-offs between adding more data from a single bot class and diversifying the training data with different bot classes.

## 2 Related Work
### Bot Detection
Early approaches to detect bots on Twitter rely on account characteristics typical of fake accounts. However, these methods struggle to keep up with the evolution of bots and require constant retraining. Other approaches focus on the social network structure, but these can be gamed by adversaries. Some leverage operational similarities, such as synchronized posting or common IP addresses. Additional work focuses on the content posted by bots, analyzing linked web pages and identifying signs of spam.

### Fake Accounts
Several studies have analyzed suspended accounts, social relationships between spam accounts, and click-spam in ad networks. There have also been efforts to identify entire botnets based on geographic and temporal anomalies, and to study botnets promoting topics or products.

Our work builds on these efforts but explicitly tests against unseen classes to evaluate classifier performance. We create a test inspired by cross-validation, which serves as a proxy for the generalization of bot classification. For a bot detection strategy to be deemed "generalizable," it should pass the test designed in this paper.

## 3 Datasets
We compiled two datasets for this paper: a botnet dataset and a real-user dataset. Each dataset includes user profile information and all retrievable tweets, limited to 3,200 per account by Twitter's API.

### 3.1 Bot Datasets
We study the extent to which various bot types have different signatures that can lead to detection failure. We build a dataset of 20 different botnet types, each with unique purposes and characteristics. This is the most extensive and diverse collection of Twitter bots used in the literature.

- **Star Wars Bots (Dataset A):** Over 355,000 accounts tweeting Star Wars novel quotes, sharing creation periods and small numbers of friends and followers.
- **Bursty Bots (Dataset B):** Over 500,000 accounts created to entice users into blacklisted sites, with zero friends and followers and a few initial tweets.
- **DeBot (Dataset C):** Over 700,000 accounts detected by a bot detection service, focusing on warped correlation in tweet timing.
- **Fake Followers (Datasets D, Q-T):** Various datasets of purchased fake followers from different services.
- **Traditional Spambots (Datasets H, I, K, J):** Spam campaigns pushing links to scam sites and job offers.
- **Social Spambots (Datasets E, F, G):** Bots mimicking real users, retweeting political candidates, and spamming paid apps and Amazon products.
- **Honeypot Bots (Dataset V):** Bots collected using honeypot accounts, logged during interactions with inactive accounts.
- **Journalist Attack Bots (Datasets W, X):** Bots involved in attacks on journalists Brian Krebs and Ben Nimmo.
- **Human Annotated Bots (Datasets L, M, N, O):** Bots identified by humans, divided by follower count.

This comprehensive dataset allows us to train and test classifiers on a wide range of bot behaviors, providing a robust evaluation of their generalization capabilities.