### 4. Temporal Completeness
Despite the rapid changes in inferred attributes, Facebook does not provide any historical information about the attributes it has inferred about a user. Consequently, Facebook's data explanations lack temporal completeness.

### 5. Correctness
Testing the correctness of data explanations is challenging due to their vagueness and the lack of specific details, such as the exact page liked or the ad clicked. According to the Self-Serve Ads Terms, Facebook states: "In instances where we believe doing so will enhance the effectiveness of your advertising campaign, we may broaden the targeting criteria you specify." Therefore, for a user to be certain that they received an ad because Facebook infers they are interested in a particular attribute, it is not sufficient for the user to receive the ad; the attribute must also appear in the explanation.

To briefly test the correctness of these explanations, we created a fake Facebook account and liked 7 Facebook pages related to U.S. Politics and 15 pages related to TV Shows. We conducted this experiment in a controlled environment, using a browser with no history, and performed no other actions on Facebook besides liking the mentioned pages. From these 22 likes, Facebook inferred 27 interests, all of which had data explanations like "You have this preference because you liked a page related to [interest]." Thus, we found no indication that the explanations were incorrect. However, a more comprehensive set of experiments is required for more complete results, and we leave such an exploration to future work.

### E. Summary
While the Ad Preferences Page provides some transparency into the different attributes users can be targeted with, the provided explanations are often incomplete and vague. Facebook does not include information about data-broker-provided attributes in its data explanations or ad explanations. This means that users currently have no way of knowing what data broker attributes advertisers can use to target them, despite the fact that nearly half of the targeting attributes come from data brokers and have an audience reach similar to Facebook’s own targeting attributes.

### V. Related Work

#### A. Bringing Transparency to Targeted Advertising
Although there have been many studies on online advertising, ad auctions, tracking, and ad blocking, we focus here on the studies most closely related to our proposal. For a more general overview, we refer the reader to [44]. We categorize the related works according to the type of transparency they aim to provide.

- **Ad-level Transparency**: Two studies [17], [34] proposed techniques to detect whether an ad is contextual, re-targeted, or behavioral. Other studies [30], [31], [20], [36] went further by proposing methods to detect the specific user action that triggered the targeting of a particular ad. These approaches monitor user actions (e.g., emails sent and received, videos watched on YouTube) and estimate the likelihood that a given ad was shown due to a specific input through controlled experiments. In contrast, we investigate how Facebook's explanations reveal information about why an ad has been targeted.

- **User-level Transparency**: The closest tools to our work are Floodwatch [6] and EyeWnder [4], which collect ads people receive while browsing the internet and provide aggregate statistics about them. MyAdChoices [36] detects whether an ad is interest-based, generic, or retargeted, and allows users to selectively block certain types of ads. None of these tools focus on social media advertising or analyze ad explanations. Two other studies analyzed Google Ad Settings [7], which is the equivalent of the Facebook Ad Preferences Page. Datta et al. [20] checked whether users receive different ads if they change their categories in the Google Ad Settings to detect discrimination. Willis et al. [43] investigated whether the Google Ad Setting pages reveal all the categories Google inferred about a user and found that some behavioral ads were not explained by the revealed inferred categories. In contrast, we provide definitive proof that Facebook makes available more targeting attributes to advertisers than it reveals to users.

- **Platform-level Transparency**: Several measurement studies offer insights into various aspects of the ad ecosystem. Barford et al. [16] focused on presenting aggregated statistics by crawling ads at large scale and studying the relationship between personas and advertiser categories to test whether an ad is behavioral. However, this study did not focus on social media ad targeting but rather on the traditional ad ecosystem that targets users when they browse the Internet.

#### B. Analyzing Facebook’s Advertiser Interface
Several studies have investigated Facebook’s advertiser interface and its pitfalls. For example, ProPublica, an investigative journalism organization, showed that advertisers can create housing-related ads while excluding users based on race, which is illegal [13]. More recently, ProPublica, as part of their “Breaking the Black Box” series [14], investigated whether Facebook sufficiently informs users about the use of data brokers in advertising [15] and found that while advertisers can target users with attributes provided by data brokers, Facebook does not mention this in the Ad Preferences Page. Our work confirms this finding and extends the investigation to other types of transparency.

Korolova et al. [28] proposed an attack that exploits Facebook’s advertiser interface to infer private attributes of Facebook users. Later work by Venkatadri et al. [41] demonstrated that more advanced attacks are possible through the custom audience advertiser interface. However, the focus of these studies is on pinpointing vulnerabilities in the advertising interface, not on transparency.

#### C. Interpretability of Decision Making Systems
Transparency and interpretability have been the focus of many recent studies in the context of automated decision-making systems. Many previous works acknowledge the importance of having more interpretable models [22], [42], [33]. One line of work focuses on providing explanations for existing algorithms/decision-making systems by studying the inputs that have the biggest impact on the outputs [21] or by uncovering how the model behaves locally around specific predictions [38]. Another line of work aims to build algorithms that are interpretable by design by integrating interpretability constraints into their optimization functions [27], [32]. The main use case for interpretable models is to help domain experts understand whether the algorithm is behaving appropriately. In our work, we study the explanations provided to users to ensure they receive satisfactory and useful explanations. To our knowledge, this is the first empirical study of real-world explanations in social media advertising.

While many studies emphasize that explanations and transparency mechanisms bring trust to a platform [33], [38], Weller [42] warns that platforms can manipulate users to trust their system with explanations that are not useful. The "Copy Machine" study [29] shows that useless explanations that do not provide any actual information were almost equally successful in gaining trust as meaningful explanations. Our study highlights the ways in which Facebook’s explanations fail to provide adequate information to end users or, worse, provide misleading information.

### VI. Conclusion
In this paper, we investigated transparency mechanisms for social media advertising by analyzing Facebook’s ad explanations and data explanations. We defined a set of key properties that such explanations should satisfy, such as correctness, completeness, and specificity, and then performed a series of controlled ad campaigns to analyze whether Facebook’s explanations meet these properties.

Our experiments demonstrated that Facebook’s ad explanations are often incomplete and sometimes misleading, and that Facebook’s data explanations are incomplete and often vague. These findings have important implications for users, as they may lead to incorrect conclusions about how they were targeted with ads. Moreover, these findings suggest that malicious advertisers may be able to obfuscate their true targeting attributes by hiding rare (and potentially sensitive) attributes by also selecting very common ones. Twitter recently introduced explanations similar to Facebook’s, underscoring the urgent need to provide properly designed explanations as social media advertising services mature. We hope that our study will provide a basis to guide such a design.

To complement our work, it would be interesting to perform a study on how users react to different possible explanations. This would explore another dimension that could further inform the design choices of explanations. However, we believe it is important first to understand explanations at a technical level to identify their vulnerabilities. Hence, we leave such a study for future work.

Facebook’s explanations only provide a partial view of its advertising mechanisms. To move towards greater transparency, we built a tool, AdAnalyst, that works on top of Facebook and provides explanations with some of the missing properties. AdAnalyst keeps track of historical data about ads and explanations to provide users with a temporal view and provides a wider perspective by aggregating data across users. The tool can be downloaded and installed from http://adanalyst.mpi-sws.org/. We hope that AdAnalyst will help increase the transparency of Facebook advertising and allow users to detect malicious and deceptive advertising.

### Acknowledgments
We thank the anonymous reviewers for their helpful comments. This research was supported in part by NSF through grants CNS-1563320 and CNS-1616234, by ANR through grants ANR-17-CE23-0014 and ANR-16-TERC-0012-01, by Institut Mines Telecom through the “Future & Ruptures” program, and by a Data Transparency Lab grant. We also acknowledge funding from the Alexander von Humboldt Foundation.

### References
[1] “About reach,” https://www.facebook.com/business/help/1665333080167380, accessed: 2017-11-30.
[2] “About the delivery system: Ad auctions,” https://www.facebook.com/business/help/430291176997542, accessed: 2017-11-30.
[3] “Datalogix segments,” http://bit.ly/2qzt5oI, accessed: 2017-11-30.
[4] “Eyewnder,” http://www.eyewnder.com/, accessed: 2017-11-30.
[5] “Facebook ad preferences,” https://www.facebook.com/ads/preferences/, accessed: 2017-11-30.
[6] “Floodwatch,” https://beta.floodwatch.me/, accessed: 2017-08-11.
[7] “Google ad settings,” https://myaccount.google.com/, accessed: 2017-11-30.
[8] “US voter list information,” http://voterlist.electproject.org/, accessed: 2017-11-30.
[9] “EU General data protection regulation,” Apr. 2016, accessible from https://www.eugdpr.org/.
[10] “LOI no 2016-1321 du 7 octobre 2016 pour une République numérique,” Journal Officiel de la République Française no 0235 du 8 octobre 2016, Oct. 2016, accessible at https://www.legifrance.gouv.fr/eli/loi/2016/10/7/ECFI1524250L/jo/texte.
[11] Acxiom, “Consumer data products catalog,” http://bit.ly/2rjzWFT, accessed: 2017-11-30.
[12] ——, “Privacy faq,” http://bit.ly/2qupYAo, accessed: 2017-11-30.
[13] J. Angwin and T. Parris Jr., “Facebook lets advertisers exclude users by race,” http://bit.ly/2eXf7ap, October 28, 2016, accessed: 2017-11-30.
[14] J. Angwin, T. Parris Jr., and S. Mattu, “Breaking the black box: What Facebook knows about you,” http://bit.ly/2driPIj, September 28, 2016, accessed: 2017-11-30.
[15] ——, “Facebook doesn’t tell users everything it really knows about them,” http://bit.ly/2ieiNsq, December 27, 2016, accessed: 2017-11-30.
[16] P. Barford, I. Canadi, D. Krushevskaja, Q. Ma, and S. Muthukrishnan, “Adscape: Harvesting and analyzing online display ads,” in WWW, 2014.
[17] J. M. Carrascosa, J. Mikians, R. Cuevas, V. Erramilli, and N. Laoutaris, “I always feel like somebody’s watching me: measuring online behavioural advertising,” in ACM CoNEXT, 2015.
[18] J. Constine, “Facebook lets businesses plug in CRM email addresses to target customers with hyper-relevant ads,” http://tcrn.ch/2q0JdxP, September 20, 2012, accessed: 2017-11-30.
[19] B. Darwell, “Facebook platform supports more than 42 million pages and 9 million apps,” http://bit.ly/28YXb1H, April 27, 2012, accessed: 2017-11-30.
[20] A. Datta, M. C. Tschantz, and A. Datta, “Automated experiments on ad privacy settings,” in PETS, 2015.
[21] A. Datta, S. Sen, and Y. Zick, “Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems,” in IEEE S&P, 2016.
[22] F. Doshi-Velez and B. Kim, “Towards a rigorous science of interpretable machine learning,” arXiv preprint 1702.08608, 2017.
[23] Experian, “Product and service privacy policies,” http://www.experian.com/privacy/prod_serv_policy.html, accessed: 2017-11-30.
[24] Facebook, “How does the conversion pixel track conversions?” http://bit.ly/2peqORu, accessed: 2017-11-30.
[25] O. Goga, P. Loiseau, R. Sommer, R. Teixeira, and K. P. Gummadi, “On the reliability of profile matching across large online social networks,” in ACM KDD, 2015.
[26] B. Goodman and S. Flaxman, “European Union regulations on algorithmic decision-making and a ‘right to explanation’,” in WHI, 2016.
[27] B. Kim, J. A. Shah, and F. Doshi-Velez, “Mind the gap: A generative approach to interpretable feature selection and extraction,” in NIPS, 2015.
[28] A. Korolova, “Privacy violations using microtargeted ads: A case study,” in IEEE ICDMW, 2010.
[29] E. J. Langer, A. Blank, and B. Chanowitz, “The mindlessness of ostensibly thoughtful action: The role of ‘placebic’ information in interpersonal interaction.” Journal of Personality and Social Psychology, 1978.
[30] M. Lécuyer, G. Ducoffe, F. Lan, A. Papancea, T. Petsios, R. Spahn, A. Chaintreau, and R. Geambasu, “Xray: Enhancing the web’s transparency with differential correlation.” in USENIX Security, 2014.
[31] M. Lecuyer, R. Spahn, Y. Spiliopolous, A. Chaintreau, R. Geambasu, and D. Hsu, “Sunlight: Fine-grained targeting detection at scale with statistical confidence,” in ACM CCS, 2015.
[32] B. Letham, C. Rudin, T. H. McCormick, D. Madigan et al., “Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model,” The Annals of Applied Statistics, 2015.
[33] Z. C. Lipton, “The mythos of model interpretability,” in WHI, 2016.
[34] B. Liu, A. Sheth, U. Weinsberg, J. Chandrashekar, and R. Govindan, “AdReveal: Improving transparency into online targeted advertising,” in ACM HotNets, 2013.
[35] J. R. Mayer and J. C. Mitchell, “Third-party web tracking: Policy and technology,” in IEEE S&P, 2012.
[36] J. Parra-Arnau, J. P. Achara, and C. Castelluccia, “MyAdChoices: Bringing Transparency and Control to Online Advertising,” ACM Trans. Web, 2017.
[37] A. C. Plane, E. M. Redmiles, M. L. Mazurek, and M. C. Tschantz, “Exploring user perceptions of discrimination in online targeted advertising,” in USENIX Security, 2017.
[38] M. T. Ribeiro, S. Singh, and C. Guestrin, “Why should I trust you?: Explaining the predictions of any classifier,” in ACM KDD, 2016.
[39] N. Stokes, “Should you use Facebook or Google to log in to other sites?” http://bit.ly/1kxEP3X, May 6, 2017, accessed: 2017-11-30.
[40] D. Tynan, “Acxiom exposed: A peek inside one of the world’s largest data brokers,” http://bit.ly/2qvQQjy, May 15, 2013, accessed: 2017-11-30.
[41] G. Venkatadri, Y. Liu, A. Andreou, O. Goga, P. Loiseau, A. Mislove, and K. P. Gummadi, “Auditing Data Brokers’ Advertising Interfaces: Privacy Risks with Facebook’s PII-based Targeting,” in IEEE S&P, 2018.
[42] A. Weller, “Challenges for transparency,” in WHI, 2017.
[43] C. E. Wills and C. Tatar, “Understanding what they do with what they know,” in ACM WPES, 2012.
[44] S. Yuan, A. Z. Abidin, M. Sloan, and J. Wang, “Internet advertising: An interplay among advertisers, online publishers, ad exchanges, and web users,” arXiv preprint arXiv:1206.1754, 2012.