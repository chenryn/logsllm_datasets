# Virus Detection Analysis

## 4.2 Virus Detection
The virus detection results, as shown in Figure 7, indicate the following:

- **Detection Times (in minutes):**
  - 4a: 3.7
  - 4b: 36.4
  - 4b.v2: 3.0
  - Detection: 2.2
  - 3.3
  - 3.1
  - 22.7

- **Traffic Consumed by Virus:**
  - < 5 percent for all cases

### Figure 7. Virus Detection
Virus detection typically occurred around 20 minutes after the virus was introduced, with detection taking only two minutes after the virus became active. For virus 4a, the orchestrator initially contained the virus, and no alarms were reported by the anomaly detector. However, after approximately 30 minutes of containment, the orchestrator lost control, and the virus took over the system. Detection occurred a few minutes after the virus escaped containment.

## 4.3 False Alarm Analysis
False alarm rates were measured using two criteria:

1. **Criteria 1: Count any single alarm as a false alarm.**
   - Total false alarms across 6 runs: 18
   - Rate: Approximately 0.3 false alarms per hour
   - (Compare this to 0.38 false alarms per hour in Experiment I.)

2. **Criteria 2: Set a threshold via experimentation.**
   - Threshold: 50 or more alarms in a period of 256 seconds.
   - Using this criterion, no false alarms were observed.
   - The maximum number of alarms within 256 seconds in any run was 14, well below the 50 threshold.

**Note:** The detection results in Figure 7 were obtained using Criteria 2, resulting in a zero false alarm rate.

## 4.4 Runtime Performance and Memory Usage
The performance and memory usage of the anomaly detector in this experiment were similar to those reported for 400 clients in Experiment I.

## 5. Related Work
Self-propagating malicious programs have been analyzed since their inception, starting with the Morris worm [2]. With the growth of the Internet, the threat of worms spreading through computer networks has increased, making propagation analysis and detection a critical research topic. Studies have been conducted on recent viruses like Code Red [12] and Melissa [1], which use email as a propagation medium.

### Epidemiological Modeling
Incidents of virus propagation have been modeled using epidemiological methods, mapping the Internet to ecological systems [15]. Models such as the Kermack-McKendrick model have been adapted to predict the spread of viruses like Code Red [39]. Researchers at IBM, including Kephart and White, have developed detection systems based on these models [7, 8, 9]. These models have been extended to incorporate network topological effects using power-law relationships [20].

### Anomaly Detection Techniques
Anomaly detection techniques have long been used for intrusion detection [13, 27, 25, 32-34, 16, 36]. The approach in this paper is closely related to [36], where a protocol state machine specification forms the basis for detection. This method transforms events into frequency distributions that characterize normal behavior, requiring no supervision.

### Specific Systems
- **Malicious Email Tracking (MET) System [17]:** Tracks the flow of malicious emails but can be defeated by polymorphic viruses.
- **Graph-based Intrusion Detection System (GrIDS) [31]:** Focuses on large-scale automated attacks and uses activity graphs to detect policy violations.
- **Data Mining Approach [6]:** Uses short sequences of machine instructions to detect malicious executables embedded in emails.
- **Email Mining Toolkit (EMT) [35]:** Synthesizes user behavior profiles to detect malicious emails, but may have higher latency compared to the proposed technique.

## 6. Conclusions and Future Work
This paper presents a new technique for detecting self-propagating email viruses using statistical anomaly detection. Our results suggest that current prevalent viruses can be detected before a significant fraction of the network is infected. The approach degrades gracefully against stealthy viruses with low propagation factors, high incubation periods, and randomization.

### Future Work
- **Realistic Email Traffic:** Evaluate the approach using real email traffic from mail server logs, superimposed with simulated virus traffic.
- **Cross-Organizational Boundaries:** Assess the effectiveness of the anomaly detector in detecting Internet-wide virus propagation when deployed on an intranet.

### References
[References listed here as provided in the original text.]

---

This revised version aims to provide a clearer, more structured, and professional presentation of the content.