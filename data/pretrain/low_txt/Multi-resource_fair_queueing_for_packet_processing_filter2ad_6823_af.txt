### Figure 8: CPU Usage vs. Packet Size for Basic Forwarding and Statistical Monitoring

For the initial packets of a flow (which involve some one-time work), a separate linear model can be used.

### Estimation Accuracy and DRFQ Performance

If the estimation is incorrect, DRFQ will still function, but the shares allocated to flows may be off by the ratio of the misestimated processing times. Although dynamic re-computation of each flow's usage is possible, we chose not to explore this further in this paper, as it is orthogonal to our main focus of defining a suitable allocation policy.

## 8. Evaluation

We evaluated DRFQ using both our Click implementation and packet-level simulations. Click was used to demonstrate the basic functioning of the algorithm, while simulations were employed for a more detailed comparison with other schedulers. Our workload is mostly dominant-resource monotonic, so we used the \(\alpha = 0\) configuration by default, unless otherwise stated.

### 8.1 Implementation Results

We ran a Click-based multi-function middlebox in user mode on an Intel(R) Xeon(R) CPU 2.8GHz X5560 machine with a 1Gbps Ethernet link. This machine was connected to a traffic generator that uses Click to send packets from multiple flows. The middlebox was configured to apply three different processing functions to these flows based on their port number: basic forwarding, per-flow statistical monitoring, and IPSec encryption. Since our machine had only one 1 Gbps link, we throttled its outgoing bandwidth to 200 Mbps to emulate a congested link and limited the CPU time available to the DRFQ module to 20% to ensure the CPU could also be a bottleneck at this rate.

#### 8.1.1 Dynamic Allocation

We generated three flows, each sending 25,000 1300-byte UDP packets per second, to exceed the total outgoing bandwidth capacity. The flows were configured as follows:
- **Flow 1**: Undergoes basic forwarding, which is link bandwidth-bound.
- **Flow 2**: Undergoes IPSec, which is CPU-bound.
- **Flow 3**: Requires statistical monitoring, which is bandwidth-bound but uses slightly more CPU than basic forwarding.

Figure 9 shows the resource shares of the flows over time, measured using timing instrumentation added to Click. Initially, Flow 1 has a complete share of the network but only 20% of the CPU. When Flow 2 arrives, Flow 1’s CPU and network share decrease, but its network share remains more than twice that of Flow 2 due to the different dominant resources. As Flow 3 arrives, the network shares of Flow 1 and Flow 3 are equalized, and Flow 2’s share decreases further to equalize the dominant shares.

#### 8.1.2 Isolation of Small Flows

We extended the setup to analyze the impact of DRFQ on short flows. Flow 1 and Flow 2 required basic and IPSec processing, respectively, and were set to send 40,000 packets/second each to exceed the outgoing bandwidth. We added two new flows, Flow 3 and Flow 4, both using only basic processing but sending packets at much lower rates of 1 packet/second and 0.5 packets/second, respectively. Ideally, these low-rate flows should have no backlog and not be impacted by the larger queues from high-rate flows. Figure 10 confirms this, showing the steady-state latency of the four flows: both low-rate flows see more than an order of magnitude lower per-packet latency than the larger ones. The high-rate IPSec flow has higher latency than the high-rate basic flow because it has a smaller bandwidth share but the same queue size.

#### 8.1.3 Comparison with Bottleneck Fairness

We implemented bottleneck fairness [14] in Click to test whether the oscillations that occur when two resources are in demand affect performance. For these experiments, we used TCP flows and added 20 ms of network latency to simulate realistic wide-area behavior. Bottleneck fairness was configured to check for a new bottleneck every 300 ms. We ran two TCP flows for 30 seconds each: one undergoing basic processing and one undergoing CPU-intensive redundancy elimination.

Table 7 shows the throughputs of both flows running separately, together under bottleneck fairness, and together under DRFQ. With bottleneck fairness, the oscillations in available bandwidth for the CPU-bound flow cause it to lose packets, back off, and get less than half the share it had running alone. In contrast, DRFQ provides high throughput for both flows, allowing each to use about 83% of the bandwidth it would have alone because their demands dovetail.

| Scenario          | Running Alone | Bottleneck Fairness | DRFQ |
|-------------------|---------------|---------------------|------|
| Flow 1 (BW-bound) | 191 Mbps      | 75 Mbps             | 160 Mbps |
| Flow 2 (CPU-bound)| 33 Mbps       | 32 Mbps             | 28 Mbps |

### 8.2 Simulation Results

We compared DRFQ with alternative solutions using per-packet simulations. The results are based on a discrete-event simulator that assumes resources are used serially. It implements different queuing principles, including DRFQ, by selecting which flow’s packet should be processed next from an input queue. Poisson arrivals and normally distributed resource consumption were used, with means according to each flow’s provided resource profile and standard deviation set to a tenth of the mean.

#### 8.2.1 Comparison with Alternative Schedulers

- **Single-resource Fair Queuing**: Applying fair queuing to just one resource (e.g., link bandwidth) results in poor isolation for flows. Figure 11 shows a scenario where one flow uses an equal amount of two resources, i.e., \( \langle 1, 1 \rangle \). Another flow, with profile \( \langle 0.1, 1 \rangle \), starts and ends at times 15,000 and 85,000, respectively. Fair queuing is only applied to the first resource, resulting in the share guarantee being violated; the \( \langle 1, 1 \rangle \) flow gets only 10% of each resource when the other flow is active.
- **Bottleneck Fairness**: Figure 5 from Section 4.1 shows how Bottleneck Fairness behaves when multiple resources are bottlenecked. Two flows with resource profiles \( \langle 6, 1 \rangle \) and \( \langle 1, 7 \rangle \) were used, and one flow used equal amounts of two resources, \( \langle 1, 1 \rangle \). Bottleneck queuing was configured to dynamically switch to the current bottleneck every 30 time units. Oscillations occur when the bottleneck shifts, causing the first flow to get only 10% of either resource, far less than its share guarantee.
- **Per-Resource Fairness**: Figure 12 investigates how a flow can manipulate per-resource fair queuing by changing its demands (e.g., by changing packet sizes) to receive better service. It simulates a scenario with ten flows. The first flow has a resource profile \( \langle 20, 1 \rangle \), while the last nine have \( \langle 10, 11 \rangle \). At time 25,000, the first flow artificially changes its demand to roughly \( \langle 20, 11 \rangle \), leading it to double its share under per-resource fair queuing. Meanwhile, the same change under DRFQ has no effect on the shares.

#### 8.2.2 Isolation Under DRFQ

We investigated packet delays under DRFQ. Figure 13 shows two different flows: one constantly backlogged to the level that it overflows all buffers and suffers from packet drops, and another periodically sending single packets spread far apart in time. For both flows, we measured the queuing delay for every packet and plotted the mean and standard deviation. The x-axis shows the same simulation for various buffer sizes. As the buffer size increases, the delay on the backlogged flow increases, while the periodic flow receives constant delay, irrespective of the buffer length.

### 8.3 Overhead

To evaluate the overhead of our Click implementation of DRFQ, we used a trace generator to create a synthetic 350 MB workload from actual traces [4]. We ran the workload through two applications: flow monitor and intrusion detection system (IDS). For each application, we measured the overhead with and without DRFQ. The flow monitor’s overhead was 4%, and the IDS’ overhead was 2%. While this is already low, we believe the overhead can be further reduced. First, DRFQ requires per-flow queues that are currently implemented in software. Many software routers and middleboxes already support in-hardware queues. Second, the overhead can be reduced using fair queuing on a per-class or per-aggregate basis rather than a per-flow basis.

## 9. Related Work

Our work builds on WFQ [10, 24] as it, similar to many GPS approximations [18, 9, 17], uses the notion of virtual time. Specifically, we approximate virtual time using start times as in SFQ [18], which helps us avoid knowing in advance what middlebox modules a packet will traverse. As our evaluation shows, naively performing fair queuing on a single resource provides poor isolation for flows, violating the share guarantee. Our attempt to extend WFQ by doing per-resource fair queuing (§4.2) turned out to violate strategy-proofness. Thus, DRFQ generalizes WFQ to multiple resources while providing isolation and strategy-proofness.

In the context of middleboxes, Egi et al. [14] proposed bottleneck fairness for software routers. We share their motivation for multi-resource fairness. However, we showed (§4.1) that their mechanism can not only provide poor isolation but can also lead to heavy oscillations that severely degrade system performance. Dreger et al. [12] suggest measuring resource consumption of modules in NIDS and shutting off modules that overconsume resources. This approach is infeasible as some modules must run at all times, e.g., a VPN module. Moreover, shutting down modules does not provide isolation between flows. With our approach, the flows that overconsume resources will fill buffers, eventually leading to modules not processing them, but each flow is sure to at least get its share guarantee of service.

In the context of active networks, Alexander et al. [7] propose a scheduling architecture called RCANE. This approach is akin to Per-Resource Fairness and therefore violates strategy-proofness. Multi-resource fairness has also been investigated in the context of micro-economic theory. Ghodsi et al. [16] provide an overview and compare with the method preferred by economists, Competitive Equilibrium from Equal Incomes (CEEI). They show that CEEI is not strategy-proof and has several other undesirable properties. Dolev et al. [11] proposed an alternative to DRF. It too fails to be strategy-proof and is computationally expensive to compute.

Our focus in this paper has been on achieving DRF allocations in the time domain. Others have analyzed how DRF allocations can be computed [19] and extended [21, 25] in the space domain.

## 10. Conclusion

Middleboxes apply complex processing functions to an increasing volume of traffic. Their performance characteristics differ from traditional routers, as different processing functions have different demands across multiple resources, including CPU, memory bandwidth, and link bandwidth. Traditional single-resource fair queuing schedulers therefore provide poor isolation guarantees between flows. Worse, in systems with multiple resources, flows can shift their demand to manipulate schedulers to get better service, thereby wasting resources. We have analyzed two schemes that are natural in the middlebox setting—bottleneck fairness and per-resource fairness—and shown that they have undesirable properties. In light of this, we have designed a new algorithm, DRFQ, for multi-resource fair queuing. We show through a Click implementation and extensive simulations that, unlike other approaches, our solution does not suffer from oscillations, provides flow isolation, and is strategy-proof. For future research directions, we believe DRFQ is applicable in many other multi-resource fair queuing contexts, such as VM scheduling in hypervisors.

## 11. Acknowledgements

We thank Adam Oliner, Ganesh Ananthanarayanan, and Patrick Wendell for useful feedback on earlier drafts of this paper. This research is supported in part by NSF FIA Award #CNS-1038695, NSF CISE Expeditions award CCF-1139158, a Google PhD Fellowship, gifts from Amazon Web Services, Google, SAP, Blue Goji, Cisco, Cloudera, Ericsson, General Electric, Hewlett Packard, Huawei, Intel, MarkLogic, Microsoft, NetApp, Oracle, Quanta, Splunk, VMware, and by DARPA (contract #FA8650-11-C-7136).

## 12. References

[1] Crossbeam network consolidation. http://www.crossbeam.com/why-crossbeam/consolidation/, June 2012.
[2] F5 Networks products. http://www.f5.com/products/big-ip/, June 2012.
[3] Intel perf. counter mon. http://software.intel.com/en-us/articles/intel-performance-counter-monitor/, June 2012.
[4] M57 network traffic traces. https://domex.nps.edu/corp/scenarios/2009-m57/net/, Feb. 2012.
[5] Palo alto networks. http://www.paloaltonetworks.com/, June 2012.
[6] Vyatta Software Middlebox. http://www.vyatta.com, June 2012.
[7] D. S. Alexander, P. B. Menage, A. D. Keromytis, W. A. Arbaugh, K. G. Anagnostakis, and J. M. Smith. The Price of Safety in An Active Network. JCN, 3(1):4–18, March 2001.
[8] K. Argyraki, K. Fall, G. Iannaccone, A. Knies, M. Manesh, and S. Ratnasamy. Understanding the packet forwarding capability of general-purpose processors. Technical Report IRB-TR-08-44, Intel Research Berkeley, May 2008.
[9] J. Bennett and H. Zhang. WF2Q: Worst-case fair weighted fair queuing. In INFOCOM, 1996.
[10] A. Demers, S. Keshav, and S. Shenker. Analysis and simulation of a fair queuing algorithm. In SIGCOMM, pages 1–12, 1989.
[11] D. Dolev, D. G. Feitelson, J. Y. Halpern, R. Kupferman, and N. Linial. No justified complaints: on fair sharing of multiple resources. In ITCS, pages 68–75, 2012.
[12] H. Dreger, A. Feldmann, V. Paxson, and R. Sommer. Operational experiences with high-volume network intrusion detection. In ACM Conference on Computer and Communications Security, pages 2–11, 2004.
[13] H. Dreger, A. Feldmann, V. Paxson, and R. Sommer. Predicting the resource consumption of network intrusion detection systems. In RAID, 2008.
[14] N. Egi, A. Greenhalgh, M. Handley, G. Iannaccone, M. Manesh, L. Mathy, and S. Ratnasamy. Improved forwarding architecture and resource management for multi-core software routers. In NPC, pages 117–124, 2009.
[15] A. Ghodsi, V. Sekar, M. Zaharia, and I. Stoica. Multi-resource fair queuing for packet processing. Technical Report UCB/EECS-2012-166, EECS Department, University of California, Berkeley, June 2012.
[16] A. Ghodsi, M. Zaharia, B. Hindman, A. Konwinski, I. Stoica, and S. Shenker. Dominant resource fairness: Fair allocation of multiple resource types. In NSDI, 2011.
[17] S. J. Golestani. A self-clocked fair queuing scheme for broadband applications. In INFOCOM, pages 636–646, 1994.
[18] P. Goyal, H. Vin, and H. Cheng. Start-time fair queuing: A scheduling algorithm for integrated services packet switching networks. ACM Transactions on Networking, 5(5):690–704, Oct. 1997.
[19] A. Gutman and N. Nisan. Fair Allocation Without Trade. In AAMAS, June 2012.
[20] M. Honda, Y. Nishida, C. Raiciu, A. Greenhalgh, M. Handley, and H. Tokuda. Is it still possible to extend TCP? In Proc. IMC, 2011.
[21] C. Joe-Wong, S. Sen, T. Lan, and M. Chiang. Multi-resource allocation: Fairness-efficiency tradeoffs in a unifying framework. In INFOCOM, 2012.
[22] E. Kohler, R. Morris, B. Chen, J. Jannotti, and M. F. Kaashoek. The Click modular router. ACM Trans. Comput. Syst., 18, August 2000.
[23] M. Kounavis, X. Kang, K. Grewal, M. Eszenyi, S. Gueron, and D. Durham. Encrypting the Internet. In Proc. SIGCOMM, 2010.
[24] A. Parekh and R. Gallager. A generalized processor sharing approach to flow control - the single node case. ACM Transactions on Networking, 1(3):344–357, June 1993.
[25] D. C. Parkes, A. D. Procaccia, and N. Shah. Beyond Dominant Resource Fairness: Extensions, Limitations, and Indivisibilities. In ACM Conference on Electronic Commerce, 2012.
[26] M. Piatek, T. Isdal, T. Anderson, A. Krishnamurthy, and A. Venkataramani. Do incentives build robustness in BitTorrent. In NSDI’07, 2007.
[27] V. Sekar, N. Egi, S. Ratnasamy, M. Reiter, and G. Shi. Design and implementation of a consolidated middlebox architecture. In NSDI, 2012.
[28] V. Sekar, S. Ratnasamy, M. Reiter, N. Egi, and G. Shi. The Middlebox Manifesto: Enabling Innovation in Middlebox Deployments. In HotNets 2011, Oct. 2011.
[29] M. Shreedhar and G. Varghese. Efficient fair queuing using deficit round robin. ACM Transactions on Networking, 4(3):375–385, 1996.
[30] R. Smith, N. Goyal, J. Ormont, K. Sankaralingam, and C. Estan. Signature matching in network processing using SIMD/GPU architectures. In Int. Symp. on Performance Analysis of Systems and Software, 2009.
[31] C. A. Waldspurger. Lottery and Stride Scheduling: Flexible Proportional Share Resource Management. PhD thesis, MIT, Laboratory of Computer Science, Sept. 1995. MIT/LCS/TR-667.
[32] Z. Wang, Z. Qian, Q. Xu, Z. M. Mao, and M. Zhang. An Untold Story of Middleboxes in Cellular Networks. In SIGCOMM, 2011.
[33] L. Zhang. Virtual clock: a new traffic control algorithm for packet switching networks. SIGCOMM CCR, 20:19–29, August 1990.