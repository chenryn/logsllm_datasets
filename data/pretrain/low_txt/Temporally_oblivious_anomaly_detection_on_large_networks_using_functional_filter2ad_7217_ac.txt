### Volume and Traffic Analysis

The volume of outgoing traffic was consistently lower than the incoming traffic, suggesting a potential DDoS (Distributed Denial of Service) attack, where the server struggles to handle the influx of requests.

### Cluster 4: Detailed Analysis

Hosts in Cluster 4 exhibited behavior similar to those in Cluster 2, characterized by low volumes of incoming traffic and significantly larger volumes of outgoing traffic. A key differentiator for this cluster is that no host sent traffic to more IP addresses than it received traffic from. In fact, 66% of the 154 hosts in this cluster sent traffic to fewer IP addresses than they received from. 

An additional subgroup within this cluster received traffic from a few sources, consisting of large numbers of small byte packets in a minimal number of flows. Despite this, these hosts still sent a large volume of traffic in return, with packet sizes approaching the maximum transmission unit (MTU) size of the network (1,500 bytes/packet). This pattern suggests large file transfers, which explains the large outgoing packet sizes, low flow counts, and small incoming packet sizes (likely ACKs from external hosts).

### Cluster Descriptions and Anomalies

Our cluster descriptions provide a high-level understanding of the different types of detected anomalies. Among the 1,658 anomalies, 172 were attributed to unique IP addresses, and each cluster contained at least 39 unique IP addresses. To achieve finer categorical granularity, the cutoff threshold for the hierarchical cluster tree can be decreased. For example, reducing the threshold to 1.2 splits Cluster 1 into three sub-clusters, as shown in Figure 3.

### Classifying New Anomalies

If new anomalies can be detected without a new clustering analysis, the qualitative categorization presented would be highly valuable to analysts, abstracting them from the technical and statistical details of clustering. By training classifiers on anomalies detected over a period of time, we can provide a label and a confidence level for each newly detected anomaly. In the absence of ground truth, we use the previously clustered anomalies as our training set. For this study, we train on the high-level cluster labels represented in Figure 3 (four classes) and implement a simple linear classifier on the normalized anomaly data, using linear discriminant analysis to choose decision boundaries. This results in a 1.69% classification error on the training set. Note that this error is in classifying hosts already flagged as anomalous, so the cost of misclassification is much lower than with a traditional IDS.

### Testing the Classifier

We test this classifier over seven days of traffic occurring eight weeks after the training data. The newly flagged anomalous data is normalized using the same f50 and f90 values from the training data to preserve appropriate scaling. During the testing period, 2,411 out of 1.4 million hosts were flagged, resulting in an average of 1.24 hosts being flagged as anomalous per observation window. After classifying each anomaly, we observe that the types of activity in each class are consistent with those during the training period.

The confidence \( c(x) \) in these labels is quantified using the posterior probability that a sample \( x_i \) belongs to a specific class \( C_j \), denoted as \( P(C_j | x_i) \). Each sample is labeled according to the class \( C_j \) that maximizes this value, and the confidence of our classification label is set as \( c(x_i) = \max_j P(C_j | x_i) \). For the test data, 95.5% of the detected anomalies had \( c(x) > 90\% \), confirming that the general categories of anomalies on the network did not change. It is worth noting that 66% of the anomalies detected during the testing phase were from IP addresses that were never flagged as anomalous during the training phase. This indicates that different hosts are exhibiting behaviors that fall under persistent categorizations rather than the same hosts consistently showing the same anomalous behavior. There was one sample with a confidence of < 50% (c(x) = 42%). Such a low confidence may represent a new category of anomaly, and developing a method to automatically identify and handle such cases is an area for future work.

### Discussion

While our results are promising, there are some limitations to address. First, while we provide intuition for our chosen parameter values, \( \alpha \) and \( n \), a more rigorous approach would be necessary for full deployment. Given the nature of anomalies and their lack of expert-defined labels, there is no straightforward way to define these parameters automatically. A network administrator deploying our system would need to train the parameters to yield an "acceptable" amount of alerts per observation period, as is done in many IDS and anomaly detection systems, and determine which classes of anomalous traffic are potentially benign. The detected anomalies could then be filtered based on their class and network knowledge (e.g., NATs) to reduce the number of alerts an analyst must investigate.

There is a chance that a previously unseen anomaly could occur, which is not accurately described by the previously trained classifier. Our system accounts for this by having a predictably low classification confidence for such anomalies, which can be saved for retraining the system. Periodic retraining is necessary if the statistics of the feature space change, which is almost always the case for network data. Determining the frequency of retraining is an area for future work.

While our method is not specifically an IDS, we recognize that anomaly detection is often used for that purpose. A sophisticated adversary could manipulate the traffic of multiple servers simultaneously, causing them to form a large enough group in the feature space that would not be deemed anomalous. This would require knowledge of the algorithm parameters, specifically the minimum cluster size \( n \), and would also increase the required resources for the adversary.

### Conclusions

In this paper, we describe a temporally-oblivious approach for detecting anomalous hosts on large-scale networks. By modeling the behavior of functional peers, anomalies stand out and can be described by a small set of qualitative characterizations. The fact that anomalous activity, which by definition is significantly abnormal, is categorically consistent over time is intriguing. We utilized this discovery to develop a labeling system for anomalies discovered during new observation periods. This framework was trained over seven days and tested over an additional seven days nearly two months later, with very similar results.

This work is presented as a proof-of-concept of a novel method of detecting anomalies. We note that hierarchical clustering is an \( O(N^2) \) operation, meaning it will not scale purely to large \( N \). This is why we operate our system on a per-service basis, focusing on port 80 in this study. While port numbers do not restrict activity, many are reserved for specified functions, making this split logical for anomaly detection. Since networks are made of a finite number of services of interest, this split also enables scaling to very large-scale networks. Determining a manner to cluster across services is an area for future work. Additionally, we aim to identify clusters of activity within non-anomalous traffic, seeing whether these clusters remain consistent over time, similar to the clusters of anomalous activity. This naturally lends itself to many research areas in network behavioral analysis. The nature of the clusters themselves provides network situational awareness, and identifying the movement of hosts between clusters could provide additional information.

### Acknowledgements

We would like to thank the reviewers for their thoughtful comments and William W. Streilein of MIT Lincoln Laboratory for his help with our normalization methods.

### References

[1] Cisco NetFlow. http://www.cisco.com.
[2] Barford, P., Kline, J., Plonka, D., and Ron, A. A signal analysis of network traffic anomalies. In Internet Measurement Workshop (2002), pp. 71–82.
[3] Brauckhoff, D., Wagner, A., and Salamatian, K. Anomaly extraction in backbone networks using association rules. In Proceedings of 9th ACM SIGCOMM Internet Measurement Conference (2009), pp. 28–34.
[4] Carl, G., Kesidis, G., Brooks, R. R., and Rai, S. Denial-of-service attack-detection techniques. In IEEE Internet Computing (Jan./Feb. 2006), vol. 10, pp. 82–89.
[5] CERT/NetSA at Carnegie Mellon University. SiLK (System for Internet-Level Knowledge). [Online]. Available: http://tools.netsa.cert.org/silk.
[6] Collins, M. P., and Reiter, M. K. Hit-list worm detection and bot identification in large networks using protocol graphs. In Proceedings of the 10th International Symposium on Recent Advances in Intrusion Detection (RAID) (2007).
[7] Collins, M. P., and Reiter, M. K. On the limits of payload-oblivious network attack detection. In Proceedings of 11th International Symposium on Recent Advances in Intrusion Detection (RAID) (2008), pp. 251–270.
[8] Gu, G., Perdisci, R., Zhang, J., and Lee, W. Botminer: Clustering analysis of network traffic for protocol- and structure-independent botnet detection. In Proceedings of 17th USENIX Security Symposium (2008), pp. 139–154.
[9] Hastie, T., Tibshirani, R., and Friedman, J. The Elements of Statistical Learning. Springer, July 2003.
[10] Lakhina, A., Crovella, M., and Diot, C. Characterization of network-wide anomalies in traffic flows. In Proceedings of ACM/SIGCOMM Internet Measurement Conference (2004), pp. 201–206.
[11] Lakhina, A., Crovella, M., and Diot, C. Diagnosing network-wide traffic anomalies. In Proceedings of ACM SIGCOMM (2004), pp. 219–230.
[12] Li, X., Bian, F., Crovella, M., Diot, C., Govindan, R., Iannaccone, G., and Lakhina, A. Detection and identification of network anomalies using sketch subspaces. In Proceedings of 6th ACM SIGCOMM Conference on Internet Measurement (2006), pp. 147–152.
[13] Moore, A. W., and Zuev, D. Internet traffic classification using Bayesian analysis techniques. In Proceedings of 2005 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems (2005), pp. 50–60.
[14] Moore, D., Voelker, G., and Savage, S. Inferring internet denial-of-service activity. In Proceedings of the 10th Usenix Security Symposium (2001), pp. 9–22.
[15] Nychis, G., Sekar, V., Andersen, D. G., Kim, H., and Zhang, H. An empirical evaluation of entropy-based traffic anomaly detection. In Proceedings of 8th ACM SIGCOMM Conference on Internet Measurement (Oct. 2008), pp. 151–156.
[16] Paxson, V. Bro: A system for detecting network intruders in real-time. Computer Networks 31, 23–24 (1999), 2435–2463.
[17] Roesch, M. Snort - lightweight intrusion detection for networks. In Proceedings of 13th LISA Conference (1999), pp. 229–238.
[18] Schechter, S. E., Jung, J., and Berger, A. W. Fast detection of scanning worm infections. In Proceedings of the 7th International Symposium on Recent Advances in Intrusion Detection (RAID) (2004), pp. 59–81.
[19] Sebaugh, J. L., and McCray, P. D. Defining the linear portion of a sigmoid-shaped curve: Bend points. In Pharmaceutical Statistics, vol. 2. 2003, pp. 167–174.
[20] Sommer, R., and Paxson, V. Outside the closed world: On using machine learning for network intrusion detection. In Proceedings of 31st IEEE Symposium on Security and Privacy (May 2010).
[21] Subhabrata, B. K., Krishnamurthy, E., Sen, S., Zhang, Y., and Chen, Y. Sketch-based change detection: Methods, evaluation, and applications. In Proceedings of ACM SIGCOMM Internet Measurement Conference (2003), pp. 234–247.
[22] Thottan, M., and Ji, C. Anomaly detection in IP networks. IEEE Transactions on Signal Processing 51, 8 (Aug. 2003), 2191–2204.
[23] Wang, H., Zhang, D., and Shin, K. G. Detecting SYN flooding attacks. In Proceedings of the IEEE Infocom (2002), pp. 1530–1539.