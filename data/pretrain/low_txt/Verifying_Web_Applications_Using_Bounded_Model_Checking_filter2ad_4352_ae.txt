# Walker)
F
## Abstract

This paper presents a formal verification approach for the reliability and security of web applications. We introduce WebSSARI, a system designed to verify real-world web applications using a combination of abstract interpretation (AI) and bounded model checking (BMC). The system architecture and verification process are detailed, highlighting the role of a code walker, which includes a lexer, parser, abstract syntax tree (AST) maker, and program abstractor. The BMC engine performs AI verification, inserting sanitization routines to secure variables involved in insecure statements. Experimental results from testing 230 PHP projects on SourceForge.net demonstrate the effectiveness of our approach. By providing counterexample traces, we achieve a 41.0% reduction in the number of reported vulnerabilities compared to a previous typestate-based algorithm (TS).

## 4. System Implementation

To test our approach, we developed WebSSARI, a tool designed to verify real-world web applications. Figure 8 illustrates the system architecture of WebSSARI. The code walker consists of a lexer, parser, AST maker, and program abstractor. The program abstractor requests the AST maker to generate a full representation of the program's AST. The AST maker uses the lexer and parser to perform this task, handling external file inclusions as needed. By traversing the AST, the program abstractor generates an AI. Using the algorithms described in Section 3, the BMC engine verifies the AI. For each variable involved in an insecure statement, it inserts a statement that secures the variable by applying a sanitization routine. Sanitization routines are stored in a prelude, and users can supply their own routines. The entire AI verification process is illustrated in Figure 9.

## 5. Experimental Results

We selected a sample of 230 PHP projects from SourceForge.net, reflecting a broad variation in terms of language, purpose, popularity, and development status. After downloading the sources and testing them with WebSSARI, we manually inspected every report of a security violation. If an actual vulnerability was identified, we sent an email notification to the developer. Out of the 69 developers we contacted, 38 acknowledged our findings and stated that they would provide patches (Figure 10).

The 230 projects consisted of 11,848 files containing 1,140,091 statements. The TS algorithm identified 515 files as vulnerable. Manually validating all reported vulnerabilities proved to be a laborious and time-consuming task, requiring the investigation of multiple function calls across multiple files. To speed up the process, we added features to the WebSSARI GUI, including navigation between different source files, function calls, and vulnerable lines; highlighting of specific variables; and search capabilities for variables or text patterns. Despite these enhancements, it still took two of us four full working days to validate the 515 files identified as vulnerable.

In the revised project, we used BMC to provide counterexample traces. Differences in the TS and BMC reports on the 38 vulnerable projects whose developers acknowledged our findings are shown in Figure 10. For these projects, the total number of vulnerable statements originally reported by TS was 980. Using the same test set, BMC reported a total of 578 error introductions, meaning that the 980 vulnerabilities were caused by the propagation of 578 errors. Compared with TS, this process yielded an additional 41.0% reduction in the number of instrumentations.

## 6. Discussion

In this project, we used BMC-provided counterexamples to identify the cause of errors, which increases the precision of both error reports and code instrumentation. Ball, Naik, and Rajamani [2] made a similar effort, enhancing their model checker SLAM with the ability to localize errors. Current model checkers report error symptoms rather than the actual causes, and even state-of-the-art model checkers today report only a single error trace per run. They reported their experiences in using their algorithm to detect locking bugs in C device drivers.

Our efforts were motivated by our previous work in verifying web applications using the TS algorithm. TS reported individual error symptoms, which not only resulted in inefficient automated patching but also made it difficult to report a meaningful number of discovered vulnerabilities, as many of the reported errors were attributed to the same cause and should not have been double-counted. Ball, Naik, and Rajamani [2] focused on locking bugs, which usually have a one-to-one mapping between a symptom and a cause. However, we focused on information flow bugs, which are much more complex and can have a many-to-many symptom-cause mapping, resulting in a MINIMUM-INTERSECTING-SET problem. Furthermore, their efforts mainly contributed to more informative error reports, while ours also resulted in more efficient automated patching. Like Ball, Naik, and Rajamani’s algorithm, ours also requires that all counterexample traces be identified. However, since SLAM is a BDD-based model checker and xBMC is a SAT-based bounded model checker, our method for extracting all counterexamples is unique.

## 7. Conclusion

In this paper, we proposed a practical approach for formally verifying the reliability and security of web applications. In earlier work, we used a typestate-based algorithm (TS) that performed breadth-first searches on control flow graphs, trading space for time. Although TS is incapable of providing counterexample traces, which reduced WebSSARI’s potential for practical use, we implemented a bounded model checker using zChaff (a mature SAT solver) to produce counterexample traces. Two immediate benefits of counterexample traces are that they allow for more informative error reports and can be used to identify multiple errors (symptoms) with the same root cause. This information not only contributes to greater report accuracy but also sharply reduces the number of inserted runtime guards. We showed that the problem of finding the minimum error causes (groups) is NP-complete and offered a greedy heuristic-based strategy.

## 8. Acknowledgment

We deeply appreciate the anonymous reviewers for offering many valuable comments. We would also like to thank Dr. Bow-Yaw Wang for his useful suggestions.

## 9. References

[1] Augustin, L., Bressler, D., Smith, G. “Accelerating Software Development through Collaboration." In Proc. 24th International Conf. Software Engineering, p.559-563, Orlando, Florida, 2002.

[2] Ball, T., Naik, M., Rajamani, S. “From Symptom to Cause: Localizing Errors in Counterexample Traces.” In Proc. 30th ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, p.97-105, New Orleans, Louisiana, 2003.

[3] Biere, A., Cimatti, A., Clarke, E. M., Fujita, M., Zhu, Y. “Symbolic Model Checking without BDDs.” In Proc. 5th Int’l Conf. Tools and Algorithms for Construction and Analysis of Systems, p.193-207, volume LNCS 1579, Amsterdam, The Netherlands, 1999. Springer-Verlag.

[4] Biere, A., Cimatti, A., Clarke, E. M., Fujita, M., Zhu, Y. “Symbolic Model Checking using SAT Procedures instead of BDDs.” In Proc. 36th Design Automation Conference, p.317-320, New Orleans, Las Angeles, 1999.

[5] Chvatal, V. “A Greedy Heuristic for the Set Covering Problem.” Mathematics of Operations Research, 4:33-235, 1979.

[6] Clarke, E., Kroening, D., Yorav, k. “Behavioral Consistency of C and Verilog Programs using Bounded Model Checking.” Technical Report CMU-CS-03-126, Carnegie Mellon University, School of Computer Science, 2003.

[7] Clarke, E., Kroening, D., Yorav, K. “Behavioral Consistency of C and Verilog Programs using Bounded Model Checking.” In Proc. 40th Design Automation Conference, Session 23.3, Anaheim, CA, 2003.

[8] Clarke, E., Kroening, D. “ANSI-C Bounded Model Checker User Manual.” Carnegie Mellon University, School of Computer Science, 2003.

[9] Cousot, P., Cousot, R. “Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Constructions or Approximation of Fixpoints.” In Conference Record of the 4th ACM Symp. Principles of Programming Languages, p.238-252, 1977.

[10] Curphey, M., Endler, D., Hau, W., Taylor, S., Smith, T., Russell, A., McKenna, G., Parke, R., McLaughlin, K., Tranter, N., Klien, A., Groves, D., By-Gad, I., Huseby, S., Eizner, M., McNamara, R. “A Guide to Building Secure Web Applications.” The Open Web Application Security Project, v.1.1.1, Sep 2002.

[11] Cytron, R., Ferrante, J., Rosen, B. K., Wegman, M. N., Zadeck, F. K. “An Efficient Method of Computing Static Single Assignment Form.” In Proc. 16th ACM SIGPLAN-SIGACT Symp. Principles of Programming Languages, p.25-35, Austin, Texas, 1989. ACM Press.

[12] Denning, D. E. “A Lattice Model of Secure Information Flow.” Communications of the ACM, 19(5):236-243, 1976.

[13] Huang, Y. W., Huang, S. K., Lin, T. P., Tsai, C. H. “Web Application Security Assessment by Fault Injection and Behavior Monitoring.” In Proc. 12th Int’l World Wide Web Conference, p.148-159, Budapest, Hungary, 2003.

[14] Huang, Y. W., Yu, F., Hang, C., Tsai, C. H., Lee, D.T., Kuo, S. Y. “Securing Web Application Code by Static Analysis and Runtime Inspection.” In: Proc. 13th Int’l World Wide Web Conference, New York, 2004.

[15] Hughes, F. “PHP: Most Popular Server-Side Web Scripting Technology.” LWN.net. http://lwn.net/Articles/1433/

[16] Kroening, D., Strichman, O. “Efficient Computation of Recurrence Diameters.” In Proc. 4th Int’l Conf. Verification, Model Checking, and Abstract Interpretation, p.298-309, volume LNCS 2575, New York, 2003. Springer-Verlag.

[17] Meier, J.D., Mackman, A., Vasireddy, S. Dunner, M., Escamilla, R., Murukan, A. “Improving Web Application Security—Threats and Countermeasures.” Microsoft Corporation, 2003.

[18] Merzbacher, M., Patterson, D. “Measuring End-User Availability on the Web: Practical Experience.” In Proc. 2002 Int’l Conf. Dependable Systems and Networks, p.473-488, Washington, D.C., 2002.

[19] Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., Malik, S. “Chaff: Engineering an Efficient SAT Solver.” In Proc. 38th Design Automation Conference, session 33.1, New Orleans, LA, 2001.

[20] OWASP. “The Ten Most Critical Web Application Security Vulnerabilities.” OWASP Whitepaper, version 1.0, 2003.

[21] Pottier, F., Simonet, V. “Information Flow Inference for ML.” ACM Transactions on Programming Languages and Systems, 25(1):117-158, 2003.

[22] Sandhu, R. S. “Lattice-Based Access Control Models.” IEEE Computer, 26(11):9-19, 1993.

[23] Sanjit, A. S., Bryant, R. E., “Unbounded, Fully Symbolic Model Checking of Timed Automata using Boolean Methods.” In Proc. 15th Int’l Conf. Computer-Aided Verification, p.154-166, volume LNCS 2725, Boulder, Colorado, 2003. Springer-Verlag.

[24] Scott, D., Sharp, R. “Abstracting Application-Level Web Security.” In Proc. 11th Int’l World Wide Web Conference, p.396-407, Honolulu, Hawaii, 2002.

[25] Shankar, U., Talwar, K., Foster, J. S., Wagner, D. “Detecting Format String Vulnerabilities with Type Qualifiers.” In Proc. 10th USENIX Security Symposium, p.201-220, Washington DC, 2002.

[26] Strom, R. E., Yemini, S. A. “Typestate: A Programming Language Concept for Enhancing Software Reliability.” IEEE Transactions on Software Engineering, 12(1):157-171, Jan 1986.

[27] Watts, G. “PHPXref: PHP Cross Referencing Documentation Generator.” Sep 2003. http://phpxref.sourceforge.net/

[28] Woodman, S., Morgan, G., Parkin, S. “Portal Replication for Web Application Availability Via SOAP.” In Proc. 8th IEEE Int’l Workshop on Object-Oriented Real-Time Dependable Systems, p.122-130, Guadalajara, Mexico, 2003.

[29] Wright, A. K, Cartwright, R. “A Practical Soft Type for Scheme.” ACM Transactions on System Programming Languages and Systems, 19(1):87-152, Jan 1999.

---

**Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04)**
0-7695-2052-9/04 $ 20.00 © 2004 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20, 2021 at 11:49:16 UTC from IEEE Xplore. Restrictions apply.