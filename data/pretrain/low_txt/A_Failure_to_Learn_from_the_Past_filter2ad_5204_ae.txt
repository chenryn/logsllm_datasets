### The Decline in Internet Security Since 1988

It is disheartening to observe that, by some measures, the overall resistance of hosts on the Internet to malicious software has deteriorated since 1988. For example, the Internet Worm in 1988 affected at most 10% of the machines on the Internet due to the diversity of operating systems. In 2003, the Internet landscape is far more homogeneous, facilitating the wider spread of software that exploits security vulnerabilities. In 1988, most system operators were professionals with computing backgrounds. By 2003, the majority of machines connected to the network are operated by individuals with little, if any, system administration experience. In 1988, creating malicious code required knowledge of machine language programming; by 2003, anyone with a text editor and a web browser can write malicious software using macros and downloaded rootkits.

### 7.2. Software Flaws

The Internet Worm exploited three types of flaws in widely-distributed software: trust relationships, buffer overflows, and poor default configurations. Unfortunately, all three of these issues persist and, in some ways, have become even more problematic than in 1988.

In 1988, the Worm exploited trust relationships in the rsh/rlogin/rexec suite to transfer itself between machines without authorization. In 2003, this software remains available on many systems. Additionally, other questionable trust relationships have led to significant security problems. For instance, the lack of separation of privilege and function in Windows allowed viruses in macros attached to word processing documents and spreadsheets to access address books and mailers, thereby spreading themselves. At a network level, system administrators who have configured firewalls to pass traffic by default (permitted unless denied) have repeatedly been hit by software exploiting these flaws. Users frequently fall for fraudulent emails soliciting credit card information or personal details, often displaying logos and email addresses resembling those of well-known entities. Other examples of exploitation of faulty or misguided trust relationships are abundant.

Buffer overflows have been a known problem for decades. Despite this, unsafe routines remain standardized in the C programming library, and overflows continue to drive security issues. Serious security flaws in widely-used software are currently being reported at an average rate of 20 to 30 per week. Examining these flaws, as categorized in vulnerability databases such as the CERIAS Cassandra service or the NIST ICAT database, reveals that more than 25% of the reported flaws can be traced to buffer overflows, and perhaps as many as 75% of all vulnerabilities are simple argument validation errors.

It is alarming that commercial software is still being produced and shipped with buffer overflows. While it is beyond the scope of this paper to analyze all the reasons for this, it is clear that the problem has not diminished in importance over the past fifteen years. It is sobering to realize that our overall infrastructure security might well be better had UNIX been written in COBOL rather than C.

Poor default configurations also continue to plague us. The standard installation of Windows software, for instance, runs various servers on network ports that are not usually needed. This can be contrasted with an installation of macOS X, which has no servers enabled by default. However, Windows is not the only culprit—software on routers, network appliances, and systems by other vendors share this problem. Some distributions of web servers have contained default example scripts with known vulnerabilities. The usual explanation given for these choices is that users do not understand the complexity of the options and interfaces involved, and it is necessary to enable the services to avoid generating too many complaints and help requests. This rationale is similar to why the DEBUG command was left enabled in the 1988 distributions of sendmail—to support users who did not understand how to configure their mailers. Clearly, there is an unmet need for better user interfaces and documentation to address these issues.

### 7.3. Incident Response

In 1988, the response to the Worm was largely ad hoc and coordinated via mailing lists. The CERT/CC was formed to act as a clearinghouse to help coordinate responses to future incidents. In 2003, the situation has not improved significantly. System administrators often learn about new problems via mailing lists like BUGTRAQ or through newspaper stories. Judging by the number of sites that are regularly exploited via flaws for which patches have been available for months, it seems that notices of flaws and fixes are not being distributed widely enough.

The CERT/CC's impact on incident response is currently questionable. Personnel at the CERT/CC release announcements of flaws and fixes weeks or months after mailing list announcements, if at all. Paying customers may receive more timely announcements from the CERT/CC and other vendors, but this does not serve the general network public. The CERT/CC appeared to play little role in the responses to several recent worms and viruses. Furthermore, no organization, including the CERT/CC, is collecting reports of even a majority of security incidents for use in actuarial studies.

It is interesting to note that the newly-formed Department of Homeland Security has announced a partnership with the CERT/CC to establish a U.S. response capability. One might question whether our experience with the CERT model supports such a move as the best approach or whether a new paradigm should be explored. The dedicated response center model also does not reflect what we learned from the Worm incident and subsequent events: a distributed response, with many people working together, is more effective than a single center of expertise. At the very least, this move fails to recognize a key underlying aspect of the problem: the Internet is not U.S.-only.

Another lesson from 1988 that has not been learned is the critical importance of communication in addressing the problem. The teams working to decompile the Worm communicated results to each other and to the public using the Internet. When their computers went down or offline, they were often left without access to phone lists or email, inhibiting their ability to communicate. In 2003, we have an increasing dependence on cell phones and Voice over IP (VoIP). During the 9/11 incident and the August 2003 blackout on the East Coast, cell phones were not dependable during a crisis due to load and power issues. VoIP has similar vulnerabilities—without power, the routers won't run, and without the network, calls cannot go through. Within a few years, a virulent worm that attacks routers and power system SCADA controllers could disable the very communication we need to combat it.

### 7.4. Laws and Professional Ethics

As predicted, numerous laws against computer misuse were enacted in the years following the Worm. However, despite the passage of these laws and the tens of thousands of viruses and worms written since then, fewer than a dozen people have been convicted of crimes related to malware. Part of this is because it is difficult and expensive to investigate and prosecute such crimes. It may also be due, in part, to a lack of tools and protocols for adequate investigation.

Not every jurisdiction has laws against the authorship of malware. For example, when Onel de Guzman was identified in the Philippines as the author of the 2000 ILOVEYOU Trojan/virus, he was not prosecuted because there was no law prohibiting his actions at the time. Many countries still have no laws against releasing malicious software into the public. Where laws do exist, the necessary investigative technology is likely to be poor, and cooperation across international borders may be ineffective. Investigating a crime scene comprising 2 million computers around the world presents a daunting challenge.

Members of the press and public continue to portray computer criminals sympathetically, or even heroically, although this is a problem that is slowly changing. Increasing levels of fraud, identity theft, spam, viruses, and other online misbehavior have helped change the public willingness to view computer criminals as simply misguided geniuses. The staggering levels of loss from computer crime and malware are also helping to reverse public sympathies.

One current issue is the nature of intellectual property and fair use online. Although not malicious per se, it will define much of our legal and moral landscape in the coming years. Intellectual property owners have equated unauthorized copying of their materials with piracy (a violent crime). Legislation, such as the Digital Millennium Copyright Act in the U.S., has been enacted to stem unauthorized copying, but it also has a chilling effect on research into security tools. Some intellectual property owners have even sought legislation to immunize them from legal sanction for the creation of destructive malware aimed at "pirates." This trend is disturbing—having viruses and worms written for vigilante purposes is unlikely to make any of us safer.

Another disturbing trend involves unwanted email, or "spam." Recent events suggest that some spammers may be writing viruses and Trojan programs to collect addresses and subvert third-party machines to act as distribution engines. Given the number of vulnerable machines on the network, this may become a major problem for security and law enforcement specialists, making the Internet Worm appear benign in hindsight.

Reflecting on the sentence Mr. Morris received, it is clear that he acted foolishly and, according to the court, criminally. However, the few thousand dollars in damages caused by the Internet Worm pale in comparison to the billions of dollars in damages caused by others since 1988. Comparing Mr. Morris to some of the computer criminals active in the last 15 years makes it clear that the lack of jail time was probably a correct decision in his case. It is also likely that the desired deterrent effect of his conviction was minimal, at best.

### 8. Parting Thoughts

Fifteen years have passed since the Internet Worm. That is approximately half a human generation and about six "Internet Generations." Reflecting on what has happened in that interval reveals that the community either failed to learn the lessons inherent in that attack or has failed to value them. Systems are deployed with inexcusable flaws, networks are configured with misplaced trust, and incident response is uncoordinated and minimally effective. What is often missed in this kind of retrospective is that these lessons were not new in 1988, either.

As a professional group, computer scientists and engineers have shown surprisingly poor attention to learning from the past. As a community, we frequently address problems as if they were unique and come up with specialized solutions that are not seen as related to past experience or some underlying truth. Our scientific base seems to have been reduced to only those documents and software that reside on the WWW, and this horizon is remarkably closer than our experience warrants.

In 1988, I was hopeful that we could make changes for the better in how we built, configured, and deployed our computing systems. In 2003, with 15 more years of experience, I have become more cynical about how we will address the challenges we face. As such, I fully expect to be writing a paper in 2013 or 2018 that looks back at this time as one where we did not yet know how bad it was going to get, and that these observations are still current. As I wrote in 1988, "It remains to be seen."

### References

[1] L. Adleman. An abstract theory of computer viruses. In Lecture Notes in Computer Science, vol 403. Springer-Verlag, 1990.
[2] E. Allman. Sendmail–An Internetwork Mail Router. University of California, Berkeley, 1983. Issued with the BSD UNIX documentation set.
[3] M. Bishop. An application of a fast data encryption standard implementation. Computing Systems: The Journal of the Usenix Association, 1(3):221–254, Summer 1988.
[4] J. Brunner. The Shockwave Rider. Harper & Row, 1975.
[5] F. Cohen. Computer Viruses. PhD thesis, University of Southern California, 1985.
[6] P. J. Denning. The Internet Worm. American Scientist, 77(2), March-April 1989.
[7] M. W. Eichin and J. A. Rochlis. With microscope and tweezers: An analysis of the internet virus of November 1988. In Proceedings of the Symposium on Research in Security and Privacy, Oakland, CA, May 1989. IEEE-CS.
[8] T. Eisenberg, D. Gries, J. Hartmanis, D. Holcomb, M. S. Lynn, and T. Santoro. The Computer Worm. Office of the Provost, Cornell University, Ithaca, NY, Feb. 1989.
[9] D. Ferbrache. A Pathology of Computer Viruses. Springer-Verlag, 1992.
[10] S. Garfinkel, A. Schwartz, and G. Spafford. Practical UNIX and Internet Security. O’Reilly & Associates, 2003. 3rd edition.
[11] D. Gerrold. When Harlie Was One. Ballantine Books, 1972. The first edition.
[12] F. T. Grampp and R. H. Morris. UNIX operating system security. AT&T Bell Laboratories Technical Journal, 63(8, part 2):1649–1672, Oct. 1984.
[13] H. J. Highland, editor. Computer Virus Handbook. Elsevier Advanced Technology, 1990.
[14] K. M. King. Overreaction to external attacks on computer systems could be more harmful than the viruses themselves. Chronicle of Higher Education, 23 November 1988.
[15] R. Morris and K. Thompson. UNIX password security. Communications of the ACM, 22(11):594–597, Nov. 1979.
[16] Participants. Proceedings of the Virus Post-Mortem Meeting. National Computer Security Center, Ft. George Meade, MD, 8 November 1988.
[17] B. Reid. Reflections on some recent widespread computer break-ins. Communications of the ACM, 30(2):103–105, Feb. 1987.
[18] D. M. Ritchie. On the security of UNIX. In UNIX Supplementary Documents. AT & T, 1979.
[19] D. Seeley. A tour of the worm. In Proceedings of 1989 Winter Usenix Conference, San Diego, CA, Feb. 1989. Usenix Association.
[20] J. F. Shoch and J. A. Hupp. The worm programs – early experience with a distributed computation. Communications of the ACM, 25(3):172–180, Mar. 1982.
[21] E. H. Spafford. An analysis of the Internet worm. In C. Ghezzi and J. A. McDermid, editors, Proceedings of the 2nd European Software Engineering Conference, pages 446–468, Sept. 1989. Issued as #87 in the Lecture Notes in Computer Science series.
[22] E. H. Spafford. The Internet Worm program: An analysis. Computer Communication Review, 19(1), Jan. 1989. Also issued as Purdue CS technical report TR-CSD-823.
[23] E. H. Spafford. Are computer break-ins ethical? Journal of Systems & Software, 17(1):41–48, Jan. 1992.
[24] E. H. Spafford. Virus. In J. Marciniak, editor, Encyclopedia of Software Engineering. John Wiley & Sons, 1994.
[25] E. H. Spafford, K. A. Heaphy, and D. J. Ferbrache. Computer Viruses: Dealing with Electronic Vandalism and Programmed Threats. ADAPSO, Arlington, VA, 1989.
[26] S. Staniford, V. Paxson, and N. Weaver. How to 0wn the internet in your spare time. In Proceedings of the 11th Usenix Security Symposium. Usenix Association, 2002.
[27] B. Stubbs and L. J. Hoffman. Mapping the virus battlefield. In L. J. Hoffman, editor, Rogue Programs: Viruses, Worms, and Trojan Horses, chapter 12, pages 143–157. Van Nostrand Reinhold, New York, NY, 1990.