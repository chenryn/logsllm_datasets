# A Large-Scale Study of User Behavior, Expectations, and Engagement with Android Permissions

**Authors:**
- Weicheng Cao, University of Toronto
- Chunqiu Xia, University of Toronto
- Sai Teja Peddinti, Google
- David Lie, University of Toronto
- Nina Taft, Google
- Lisa M. Austin, University of Toronto

**Publication:**
- [Proceedings of the 30th USENIX Security Symposium](https://www.usenix.org/conference/usenixsecurity21/presentation/cao-weicheng)
- August 11–13, 2021
- ISBN: 978-1-939133-24-3
- Open access sponsored by USENIX

## Abstract
We conducted a global study on the behaviors, expectations, and engagement of 1,719 participants across 10 countries and regions regarding Android application permissions. Participants were recruited using mobile advertising and used an application we designed for 30 days. Our app samples user behaviors (decisions made), rationales (via in-situ surveys), expectations, and attitudes, as well as some app-provided explanations. We studied the grant and deny decisions made by our users and built mixed-effect logistic regression models to illustrate the many factors that influence this decision-making process.

Among several interesting findings, we observed that users facing an unexpected permission request are more than twice as likely to deny it compared to those who expect it. Additionally, permission requests accompanied by an explanation have a deny rate that is roughly half that of requests without explanations. These findings remain true even when controlling for other factors. To the best of our knowledge, this may be the first study of actual privacy behavior (not stated behavior) for Android apps, with users using their own devices across multiple continents.

## 1. Introduction
Permission requests in the Android system serve two important functions: they allow users to control a mobile application’s ability to access resources and data on the phone, and they inform users about the types of data that a mobile application might access. An important implication of this system is that developers can interpret users’ decisions as hints on how to develop privacy-friendly applications. While many factors influence users’ decisions about which permissions they grant and which they deny, this behavior can be viewed as an opportunity to learn about unpopular permissions, which permissions make sense to users, the reasons they grant permissions, and whether application-provided explanations affect users’ decisions. In this paper, we focus on the permissions Android categorizes as “Dangerous,” which must be explicitly granted by the user to the application. Android categorizes permissions into 11 groups (such as Location, Camera, Microphone, etc.), which, for simplicity, we refer to as “permissions” in this paper.

Many factors affect how users interact with Android permissions, such as behaviors, expectations, explanations offered, and attitudes. Prior work typically focuses on one aspect of users at a time, such as behaviors, expectations, or attitudes, and does not seek to analyze the interplay of these factors over the same set of users. These prior studies used surveys or provided users with special devices, but it is preferable to obtain behavior data “in the wild” (when users employ their own devices) as opposed to experiments in a lab, as this captures more naturally the choices users make in their daily lives. Finally, even the largest published research studies to date that record behavior on smartphones contain at most a few hundred participants from a single geographic region.

To overcome these challenges, we designed an Android app called PrivaDroid and used it as our study instrument. PrivaDroid runs in the background on participants’ phones, observing app installs, permission grant and deny events, and launching in-situ surveys immediately after these events. Together, the observations and surveys collect data on participant decisions, rationales, expectations, and attitudes at the moment they act on their own personal devices. To reach a broad base of participants, we designed PrivaDroid to support all major Android versions from 6.0 to 10, translated it into four major languages, and used mobile advertising to recruit participants.

Our collection of decision rationales is similar to [4]; in fact, we reuse the questions from this prior study so we can directly compare decision rationales. We expand beyond [4] in multiple ways:
1. The prior study was done with US-based participants only, whereas our study includes participants from 10 countries and regions, and our app was deployed in four languages.
2. We collect which permissions a user expects an app to ask for and thus can compare expectations against behaviors.
3. We identify apps that provide explanations for their permission requests and those that do not, allowing us to assess the impact on deny rates of providing explanations.
4. We have users complete a privacy attitudes survey at the end of our study, so that we may compare self-stated privacy sensitivity with actual behavior.

The app was published on the Google Play Store from September 2019 to August 2020 and advertised on several online advertising platforms to recruit participants. To the best of our knowledge, this is the first cross-continent study on Android permission decision-making. Over the course of our experiment, approximately 1,700 participants joined from 10 countries and successfully finished the 30-day study. In total, we observed approximately 72,000 app installs and 36,000 permission decision events. Nearly one-third of these events were followed by an in-situ survey that the participant completed. This is a much larger scale study than [4], which was based on 157 participants.

Prior studies have advocated that explaining the reasons for permission requests to users is critical to improving their understanding, which in turn influences their grant and deny choices. In previous surveys, users state they would be more comfortable granting permissions if explanations were offered. Our study allows us to examine actual user behavior both in applications that offer explanations and applications that do not.

Our contributions can be summarized as follows:
- We design and implement the PrivaDroid app to collect behavioral data and perform experience sampling. We translate PrivaDroid into Spanish, French, and Chinese (Traditional) and show that it is possible to use online advertising to recruit participants from around the world.
- We compare the deny rate trends today to the study done three years ago [4] and report which trends have remained the same and which have evolved.
- We find that some countries form cliques with statistically similar deny rates, but also that deny rates may differ significantly between countries in different cliques.
- Using regression modeling, we show there is a statistically significant association between participants’ permissions decisions (grant/deny) and their run-time and install-time expectations. We also employ these methods to show that deny rates are lower when explanations are present. These findings remain true even when controlling for other factors (such as country, attitudes, etc.).
- We use a logistic regression model to study the influence of 12 factors on users’ permission decision behavior. Our model shows that nearly all of these parameters have a statistically significant influence on users' decisions. This sheds light on the complexity of understanding user decisions, as many factors play a role.
- We compare privacy attitudes to behaviors and find that approximately 29% of our participants who say they are privacy-sensitive also exhibit low deny rates. Analysis shows that these participants’ expectations about permissions tend to be more accurate (matching app behavior), suggesting that privacy-sensitive users who grant many permissions may be doing so with a better understanding of how and why applications use permissions.

The rest of the paper is organized as follows. Section 2 discusses related work. Section 3 explains the participant recruitment method, while Section 4 describes the design, data collection, and implementation of our PrivaDroid app. Our findings are presented in Section 5. Section 6 describes the limitations of our study, and Section 7 concludes the paper. The survey questions are listed in Appendix A.

## 2. Related Work
There is extensive existing research on Android permissions and privacy. Much of this research documents user discomfort with permissions and their frustration with what appears to them as unnecessary permission requests. This can happen because developers are not knowledgeable about permissions, leading to mistakes, or (mis)use of permissions in unexpected ways. Many studies have found cases where app permission requests are not related to the app’s core functionality. We do not focus on developers in this work but instead on users.

Research on user privacy expectations with permissions has shown that users are concerned when they learn of the possible risks associated with permissions or about applications collecting data when running in the background. In [19], the authors studied user expectations around four resources (GPS location, Device ID, network location, contact list) based on an older model of Android. This study captured resource requests users did not expect via an mTurk survey, not based on decisions on personal devices as in our study. Wijesekera et al. [48] captured user expectations by monitoring their apps for one week and showing users afterward what was collected and asking in-lab questions about whether the participants expected that. This study reports that users said they were more likely to deny permissions they didn’t expect. Our results corroborate this finding, however, we use a very different mechanism as we captured actual decisions made on personal devices and at a much larger scale.

To help provide explanations or additional information so users can make better choices, Harbach et al. [12] and Kelley et al. [15] suggested providing more privacy information and personal examples to improve user comprehension. Others categorized permissions to reduce the number of privacy/security decisions users need to make. Some have explored creating personalized privacy assistants or surfacing nudges to assist users with decision-making. This research focuses on supplementary features to help users make decisions, whereas we focus on developer-provided explanations.

There is little work on app-provided permission explanations. Tan et al. [40] conducted an online survey of smartphone users and showed that permission requests that include explanations are significantly more likely to be granted. They also analyzed approximately 4,000 iOS apps and showed that only 19% of the permission requests included text within the dialogs to explain the request. Liu et al. [21] analyzed approximately 83,000 Android apps and the extracted permission explanation messages, and showed that less than 25% of apps provide explanations and that the purposes stated in a significant proportion of these explanations were incorrect. We have made similar observations in our analysis: only 15% of apps in our data presented an explanation to users for their permission requests, and having an explanation reduced the permission deny rate from 15.4% to 7.1%. While the prior work mentioned the influence of permission explanations on denial rates based on surveys, ours is the first to study user behavior on their own devices and quantify the reduction in actual permission denial rates when explanations are present.

Others have conducted cross-country studies related to privacy. For example, Shklovski et al. [35] conducted interviews and a survey across two countries (Iceland and Denmark) to investigate how smartphone users feel about data access on their phones and if they are willing to change their behavior after being informed about tracking and data leakage. A multi-country survey [25] showed that psychographics and various attributes of the mobile app context are predictive of users’ privacy preferences. Schubauer et al. [33] examined app behavior on the Google Play Store across three categories and three countries (US, South Korea, and Germany) and discovered that policy changes aligned with privacy law changes (such as the General Data Protection Regulation) have an impact on application permission usage. Overall, there has been little research comparing users in different countries in terms of their attitudes and behaviors related to Android app permissions. With the exception of [33] that focuses on app design, the other prior studies use interviews and surveys as their methodology. To the best of our knowledge, we are the first to compare actual privacy behavior (not stated behavior), with users employing their own devices, across multiple countries.

## 3. Participant Recruitment
### Participant Composition
We recruited participants from 10 countries and territories: Canada, United States, Argentina, United Kingdom, France, Spain, South Africa, India, Singapore, and Hong Kong. These countries were selected using multiple criteria. First, we aimed to cover a diverse set of regions, selecting countries from five continents, covering four languages, and with different privacy legislation. Second, we selected countries where we had access to native speakers of the dominant language spoken, enabling us to check our translations. Third, we focused on countries with high smartphone penetration and included two developing economies, South Africa and India. Finally, we aimed to include countries covering a range of privacy views: India previously had low privacy awareness and few concerns about privacy, whereas France and Spain are reputed to have strong concerns about privacy and are in a region (Europe) with some of the strictest privacy laws (GDPR). This ensemble of countries is similar to that in [5], which also includes two or three countries each from Europe, North America, Asia, and one from South America.

Our aim was to recruit at least 100 participants from each region with a nearly balanced split between males and females, hoping to obtain sufficient data to compute statistically significant results. Because participants self-enrolled asynchronously, and advertisements are sent out in large batches, we could not control the number and gender of participants who joined our study, and this created variance in participant numbers across countries. We found that females were less likely to join our study despite efforts to target more advertisements at females. We did not control for other variables, such as age, profession, or income during the recruitment process, mainly due to the inaccuracy in the advertisement network inferred attributes for targeting our ads and partly due to ethical concerns over targeting for age or income.

### Advertising and Compensation
We used online advertising to recruit participants as it allows us to find participants across many countries. Most recruitment agencies for user studies only work in a single country, and international ones are prohibitively expensive—particularly for large studies. We selected three popular online advertising providers, namely Google, Facebook, and Reddit, to reach a broad audience. Initial experimentation with our app revealed that male participants were more likely to join our experiment than females. To improve gender balance, we targeted our advertising towards female participants first and only started advertising to males after we had more than 50 female participants.

We offered participants $10 USD if they stayed for 30 days and completed the experiment. We initially selected Bitcoin and PayPal as payment methods. However, Bitcoin was not approved by our IRB, so we used PayPal for all participants.

### Transparency and User Consent
This study was approved by our institutional review board (IRB). Participants needed to give their consent before enrolling in our experiment. This process happens after they install and open the PrivaDroid Android app. The consent form enabled us to both gain consent and be transparent about our practices. It contains the following key clauses:
- Participants must come from one of the specified countries and must be above 18 years of age.
- Participants must keep the accessibility service and app usage access enabled for our app during the length of the experiment.
- We notify participants that PrivaDroid collects no personally identifiable information except for their Google advertising identifier (a device ID that we use to associate all the data coming from a single device), and that we don’t use this advertising identifier to infer any other personal information (such as name, email, etc.). Participants must consent to these clauses.

### Data Protection
To protect user privacy, access to the collected raw data is controlled and limited to only the subset of authors (at the University of Toronto) directly involved in the implementation and maintenance of PrivaDroid.