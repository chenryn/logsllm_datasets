### Heuristics for Identifying Automated Spammers

Several heuristics have been developed to identify automated spammers [51], [52]. However, these methods have limited effectiveness in detecting compromised accounts and often incur a delay between the creation of a fraudulent account and its detection. This delay is necessary to develop a history of (mis)activity. In contrast, Monarch operates independently of account properties, generalizes to all web services that receive URL spam, and does not require a monitoring window.

### Characterizing Spam

Monarch builds on a substantial body of previous research aimed at characterizing spam properties. This includes the lexical characteristics of phishing URLs [16], the locality of email spammer IP addresses [17], shared hosting infrastructure and page layout across email spam campaigns [18], and the content of spam websites [27]. These properties have been used to develop techniques for detecting algorithmically generated spam domains [21] and identifying spam domains based on nameserver and registration times [20]. We expand on these properties by adding our own study of spam behavior, including a comparison between email and tweet spam, as well as the services abused by each.

### Detecting Scams, Phishing, and Malware

Detecting scams, phishing, and malware based on URL and page properties is not new. Significant attention has been given to identifying phishing URLs, with many solutions relying on HTML forms, input fields, page links, URL features, and hosting properties for detection [15], [28], [53]. Malware, particularly drive-by-downloads, has also been a focus of recent studies, with most solutions involving exposing sandboxed browsers to potentially malicious content [54], [55]. An exception is Wepawet, which relies on detecting anomalous arguments passed to plugins to prevent attacks [56].

Our system, Monarch, generalizes to all forms of scams, phishing, and malware and allows for real-time URL submission by web services. Among the closest works to ours, Ma et al. show that one can classify spam URLs based on lexical structure and underlying hosting infrastructure, including DNS and WHOIS information [22], [23]. We employ these same metrics but crawl URLs to resolve redirect URLs that would otherwise obscure the final landing page and its hosting infrastructure. A similar approach is taken by Whittaker et al. [24] for classifying phishing pages. We expand on their research and generalize Monarch to detect all forms of spam, adding features such as JavaScript behavior, redirect chains, and the presence of mashup content, while developing our own classification engine and collection infrastructure to meet real-time requirements.

### Spam Filtering and Usability Challenges

In this paper, we focus on providing accurate decisions for whether a URL directs to spam content. However, a second challenge remains for web services: deciding how to appropriately address spam content. Currently, Twitter and Facebook prevent messages containing known spam content from being posted [57], [58], while bit.ly implements a warning page that users must click past to access potentially harmful content [9]. Warnings provide users with an opportunity to bypass false positives but burden them with making (un)informed security decisions.

The effectiveness of warnings in the context of phishing sites has been examined in several studies [59], [60]. The results showed that unobtrusive warning messages are less effective compared to modal dialogs and active, full-screen warnings. These findings lead to a discussion on the best approach for educating users about security practices and making informed decisions [61]. While advances in usability are orthogonal to Monarch, web services relying on Monarch's decisions can benefit from these studies when determining the best mechanism for conveying the potential harm of a URL to users.

### Conclusion

Monarch is a real-time system for filtering scam, phishing, and malware URLs as they are submitted to web services. We demonstrated that while Monarch’s architecture generalizes to many web services targeted by URL spam, accurate classification depends on a deep understanding of the spam campaigns abusing a service. Specifically, we found that email spam provides little insight into the properties of Twitter spammers, and vice versa. We explored the distinctions between email and Twitter spam, including the overlap of spam features, the persistence of features over time, and the abuse of generic redirectors and public web hosting.

We have shown that a modest deployment of Monarch on cloud infrastructure can achieve a throughput of 638,000 URLs per day with an overall accuracy of 91% and a false positive rate of 0.87%. Each component of Monarch readily scales to the requirements of large web services. We estimated it would cost $22,751 a month to run a deployment of Monarch capable of processing 15 million URLs per day.

### Acknowledgments

This material is based upon work supported by the National Science Foundation under Grant Nos. 0311808, 0832943, 0448452, 0842694, 0627511, 0842695, 0831501, 0433702, 0905631, CCF-0424422, and CNS-0509559. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. This work is partially supported by the Office of Naval Research under MURI Grant No. N000140911081. This material is also based upon work supported by the MURI program under AFOSR Grant No: FA9550-08-1-0352. This research is also supported by gifts from Sun Microsystems, Google, Microsoft, Amazon Web Services, Cisco Systems, Cloudera, eBay, Facebook, Fujitsu, Hewlett-Packard, Intel, Network Appliance, SAP, VMWare, and Yahoo! and by matching funds from the State of California’s MICRO program (grants 06-152 and 07-010), and the University of California Industry/University Cooperative Research Program (UC Discovery) grant COM07-10240.

We thank Matei Zaharia and John Duchi for discussions about the distributed learning implementation. We also thank our shepherd Ben Livshits and our anonymous reviewers for their valuable feedback.

### References

[1] G. Cluley, “This you????: Phishing attack hits twitter users.” http://www.sophos.com/blogs/gc/g/2010/02/24/phishing-attack-hits-twitter-users/, 2010.
[2] E. Mills, “Facebook hit by phishing attacks for a second day,” CNET News, 2009.
[3] John E. Dunn, “Zlob Malware Hijacks YouTube,” 2007. http://www.pcworld.com/article/133232/zlob-malware-hijacks-youtube.html.
[4] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Zhao, “Detecting and characterizing social spam campaigns,” in Proceedings of the Internet Measurement Conference (IMC), 2010.
[5] C. Grier, K. Thomas, V. Paxson, and M. Zhang, “@spam: the underground on 140 characters or less,” in Proceedings of the ACM Conference on Computer and Communications Security (CCS), 2010.
[6] Kim Zetter, “Trick or Tweet? Malware Abundant in Twitter URLs,” Wired, 2009.
[7] B. Stone, “Facebook Joins With McAfee to Clean Spam From Site,” New York Times, 2010.
[8] HootSuite, “Kapow! HootSuite Fights the Evils of Phishing, Malware, and Spam,” 2010. http://blog.hootsuite.com/hootsuite-fights-malware-phishing/.
[9] bit.ly, “Spam and Malware Protection,” 2009. http://blog.bit.ly/post/138381844/spam-and-malware-protection.
[10] A. Ramachandran, N. Feamster, and S. Vempala, “Filtering spam with behavioral blacklisting,” in Proceedings of the 14th ACM Conference on Computer and Communications Security, 2007.
[11] S. Sinha, M. Bailey, and F. Jahanian, “Shades of grey: On the effectiveness of reputation-based blacklists,” in 3rd International Conference on Malicious and Unwanted Software, 2008.
[12] F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida, “Detecting Spammers on Twitter,” in Proceedings of the Conference on Email and Anti-Spam (CEAS), 2010.
[13] K. Lee, J. Caverlee, and S. Webb, “Uncovering social spammers: social honeypots+ machine learning,” in Proceeding of the International ACM SIGIR Conference on Research and Development in Information Retrieval, 2010.
[14] G. Stringhini, C. Kruegel, and G. Vigna, “Detecting Spammers on Social Networks,” in Proceedings of the Annual Computer Security Applications Conference (ACSAC), 2010.
[15] C. Ludl, S. McAllister, E. Kirda, and C. Kruegel, “On the effectiveness of techniques to detect phishing sites,” Detection of Intrusions and Malware, and Vulnerability Assessment, 2007.
[16] D. McGrath and M. Gupta, “Behind phishing: an examination of phisher modi operandi,” in Proceedings of the 1st Usenix Workshop on Large-Scale Exploits and Emergent Threats, 2008.
[17] S. Venkataraman, S. Sen, O. Spatscheck, P. Haffner, and D. Song, “Exploiting network structure for proactive spam mitigation,” in Proceedings of 16th USENIX Security Symposium on USENIX Security Symposium, 2007.
[18] D. Anderson, C. Fleizach, S. Savage, and G. Voelker, “Spamscatter: Characterizing internet scam hosting infrastructure,” in USENIX Security, 2007.
[19] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich, G. Voelker, V. Paxson, N. Weaver, and S. Savage, “Botnet Judo: Fighting spam with itself,” in Proceedings of the Network and Distributed System Security Symposium (NDSS), 2010.
[20] M. Felegyhazi, C. Kreibich, and V. Paxson, “On the potential of proactive domain blacklisting,” in Proceedings of the USENIX Conference on Large-scale Exploits and Emergent Threats, April 2010.
[21] S. Yadav, A. Reddy, A. Reddy, and S. Ranjan, “Detecting Algorithmically Generated Malicious Domain Names,” in Proceedings of the Internet Measurement Conference (IMC), 2010.
[22] J. Ma, L. Saul, S. Savage, and G. Voelker, “Beyond blacklists: learning to detect malicious web sites from suspicious urls,” in Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2009.
[23] J. Ma, L. Saul, S. Savage, and G. Voelker, “Identifying suspicious URLs: an application of large-scale online learning,” in Proceedings of the 26th Annual International Conference on Machine Learning, 2009.
[24] C. Whittaker, B. Ryner, and M. Nazif, “Large-Scale Automatic Classification of Phishing Pages,” in Proceedings of the Network and Distributed System Security Symposium (NDSS), 2010.
[25] K. Chellapilla and A. Maykov, “A taxonomy of JavaScript redirection spam,” in Proceedings of the 3rd International Workshop on Adversarial Information Retrieval on the Web, 2007.
[26] Dan Goodin, “Scammers skirt spam shields with help from Adobe Flash,” The Register, 2010. http://www.theregister.co.uk/2008/09/04/spammers-using-adobe-flash/.
[27] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly, “Detecting spam web pages through content analysis,” in Proceedings of the 15th International Conference on World Wide Web, 2006.
[28] Y. Zhang, J. Hong, and L. Cranor, “Cantina: a content-based approach to detecting phishing web sites,” in Proceedings of the 16th international conference on World Wide Web, 2007.
[29] K. Thomas and D. M. Nicol, “The Koobface botnet and the rise of social malware,” in Proceedings of The 5th International Conference on Malicious and Unwanted Software (Malware 2010), 2010.
[30] K. Q. Weinberger, A. Dasgupta, J. Langford, A. Smola, and J. Attenberg, “Feature Hashing for Large Scale Multitask Learning,” in Proceedings of the International Conference on Machine Learning (ICML), pp. 681–688, June 2009.
[31] R. McDonald, K. Hall, and G. Mann, “Distributed Training Strategies for the Structured Perceptron,” in Proceedings of the North American Association for Computing Linguistics (NAACL), (Los Angeles, CA), June 2010.
[32] J. Duchi and Y. Singer, “Efficient Online and Batch Learning Using Forward Backward Splitting,” Journal of Machine Learning Research, vol. 10, pp. 2899–2934, Dec. 2009.
[33] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction. New York, NY: Springer, 2009.
[34] Hadoop, “Hadoop Distributed File system.” http://hadoop.apache.org/hdfs/, 2010.
[35] Amazon Web Services, “Amazon EC2 Instance Types,” 2009. http://aws.amazon.com/ec2/instance-types/.
[36] Twitter, “Twitter API wiki.” http://apiwiki.twitter.com/Twitter-API-Documentation, 2010.
[37] Twitter, “Building on open source.” http://blog.twitter.com/2009/01/building-on-open-source.html, 2010.
[38] Mozilla, “API & Language References.” https://addons.mozilla.org/en-US/developers/docs/reference, 2010.
[39] Mozilla, “Netscape plugin API.” http://www.mozilla.org/projects/plugins/, 2004.
[40] MaxMind, “Resources for Developers.” http://www.maxmind.com/app/api, 2010.
[41] Advanced Network Technology Center, “University of Oregon route views project.” http://www.routeviews.org/, 2010.
[42] M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica, “Spark: Cluster Computing with Working Sets,” in Proceedings of the 2nd USENIX Conference on Hot topics in Cloud Computing, (Boston, MA), June 2010.
[43] B. Zadrozny, J. Langford, and N. Abe, “Cost-Sensitive Learning by Cost-Proportionate Example Weighting,” in Proceedings of the IEEE International Conference on Data Mining (ICDM), (Melbourne, FL), Nov. 2003.
[44] S. Sinha, M. Bailey, and F. Jahanian, “Improving spam blacklisting through dynamic thresholding and speculative aggregation,” in Proceedings of the 17th Annual Network & Distributed System Security Symposium, 2010.
[45] L. Rao, “Twitter seeing 90 million tweets per day, 25 percent contain links.” http://techcrunch.com/2010/09/14/twitter-seeing-90-million-tweets-per-day/, September 2010.
[46] T. Holz, C. Gorecki, F. Freiling, and K. Rieck, “Detection and mitigation of fast-flux service networks,” in Proceedings of the 15th Annual Network and Distributed System Security Symposium (NDSS08), 2008.
[47] N. Dalvi, P. Domingos, S. Mausam, and D. Verma, “Adversarial classification,” in Proceedings of the International Conference on Knowledge Discovery and Data Mining, 2004.
[48] D. Lowd and C. Meek, “Adversarial learning,” in Proceedings of the International Conference on Knowledge Discovery in Data Mining, 2005.
[49] M. Barreno, B. Nelson, R. Sears, A. Joseph, and J. Tygar, “Can machine learning be secure?,” in Proceedings of the ACM Symposium on Information, Computer and Communications Security, 2006.
[50] P. Eckersley, “How Unique Is Your Web Browser?,” in Privacy Enhancing Technologies (PET), 2010.
[51] Twitter, “The twitter rules.” http://support.twitter.com/entries/18311-the-twitter-rules, 2010.
[52] C. Ghiossi, “Explaining Facebook’s Spam Prevention Systems.” http://blog.facebook.com/blog.php?post=403200567130, 2010.
[53] S. Garera, N. Provos, M. Chew, and A. Rubin, “A framework for detection and measurement of phishing attacks,” in Proceedings of the 2007 ACM Workshop on Recurring Malcode, 2007.
[54] N. Provos, P. Mavrommatis, M. A. Rajab, and F. Monrose, “All your iFRAMEs point to us,” in Proceedings of the 17th Usenix Security Symposium, pp. 1–15, July 2008.
[55] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski, S. Chen, and S. King, “Automated Web patrol with Strider HoneyMonkeys: Finding Web sites that exploit browser vulnerabilities,” in Proceedings of the 2006 Network and Distributed System Security Symposium (NDSS), February 2006.
[56] M. Cova, C. Kruegel, and G. Vigna, “Detection and analysis of drive-by-download attacks and malicious JavaScript code,” in Proceedings of the 19th International Conference on World Wide Web, 2010.
[57] F-Secure, “Twitter now filtering malicious URLs.” http://www.f-secure.com/weblog/archives/00001745.html, 2009.
[58] Facebook, “Explaining Facebook’s spam prevention systems.” http://blog.facebook.com/blog.php?post=403200567130, 2010.
[59] M. Wu, R. Miller, and S. Garfinkel, “Do security toolbars actually prevent phishing attacks?,” in Proceedings of the SIGCHI conference on Human Factors in computing systems, 2006.
[60] S. Egelman, L. Cranor, and J. Hong, “You’ve been warned: an empirical study of the effectiveness of web browser phishing warnings,” in Proceeding of the Conference on Human Factors in Computing Systems, 2008.
[61] C. Herley, “So long, and no thanks for the externalities: The rational rejection of security advice by users,” in Proceedings of the 2009 Workshop on New Security Paradigms Workshop, 2009.