# Program Anomaly Detection: Methodology and Practices

**Authors:**
- Xiaokui Shu, IBM Research, Yorktown Heights, NY, USA
- Danfeng Yao, Department of Computer Science, Virginia Tech, Blacksburg, VA, USA

## Abstract

This tutorial provides an overview of program anomaly detection, which involves analyzing normal program behaviors to identify aberrant executions caused by attacks, misconfigurations, program bugs, and unusual usage patterns. Initially introduced as an analogy to the immune system in biology, advanced models and comprehensive techniques, such as hidden Markov models and machine learning, have been developed over the past decade.

We will introduce the audience to the problem of program attacks and the anomaly detection approach to counter these threats. We will provide a general definition of program anomaly detection and derive model abstractions from this definition. The tutorial will cover the evolution of program anomaly detection methods, from early n-gram approaches to more complex pushdown automata and probabilistic models. Lab tools will be provided to help understand primitive detection models, and this process will help the audience grasp the objectives and challenges in designing such models. We will also discuss attacks that subvert anomaly detection mechanisms and present a field map of program anomaly detection. Additionally, we will briefly explore the applications of program anomaly detection in Internet of Things (IoT) security.

By the end of the tutorial, the audience should have a clear understanding of the unsolved challenges in the field and a sense of future directions for program anomaly detection.

**Keywords:** Anomaly detection, intrusion detection, program trace, program analysis, formal language, detection accuracy

## 1. Introduction

Program attacks are one of the oldest and most fundamental threats to computing systems, evolving to form the latest attack vectors and advanced persistent threats. Anomaly-based intrusion detection identifies aberrant executions caused by attacks, misconfigurations, program bugs, and unusual usage patterns. This approach models normal program behaviors rather than specific threats, thereby avoiding the time lag between emerging attacks and deployed countermeasures, which is a common issue with signature-based defenses. The key advantage of program anomaly detection is its independence from attack signatures, enabling proactive defense against new and unknown threats.

Program anomaly detection systems, also known as host-based intrusion detection systems, follow Denning’s intrusion detection vision [1]. Early systems were designed to detect illegal control flows or anomalous system calls based on two primary paradigms: n-gram short call sequence validation [2] and automaton transition verification [5, 7, 10]. These paradigms have been advanced with the integration of machine learning models [6], hidden Markov models [11, 3, 13, 12], and neural network models.

The accuracy of program anomaly detection methods depends on the precision of normal behavior descriptions and the completeness of training data. Early program attacks, such as return address manipulation and library/system call injection, can be distinguished from imprecise descriptions of normal behaviors. However, modern attacks, like data-oriented programming [4] and denial-of-service (DoS) attacks, use indirect means of control flow manipulation, making them harder to detect with conventional models. This has led to the development of new models, such as long trace event correlation analysis [8], which describe program behaviors through context-sensitive grammars.

This tutorial aims to provide an overview of program anomaly detection and inspire the audience to explore future directions and solve open issues. It will explain the topic from both practical and theoretical perspectives, presenting a field map to help the audience understand the evolution of the field and potential future directions.

### Outline
- Introduction to program attacks and primitive anomaly detection paradigms.
- Formal definition of program anomaly detection and the evolution of detection systems.
- A tale of two paths: program anomaly detection and control-flow enforcement.
- Unsolved issues and possible future directions.

## 2. Prerequisite Knowledge

This tutorial is suitable for system security researchers at all levels. We aim to:
- Introduce the problem of program anomaly detection to junior researchers and students.
- Discuss the formalization of the problem, unsolved issues, and possible future directions with senior researchers and students.

A basic understanding of system security, including call stack operations, buffer overflow, protection rings, and control flows in programs, is required. Advanced knowledge in areas like automata theory, hidden Markov models, machine learning, and correlation analysis is not necessary but will enhance the understanding of some subtopics.

## 3. References

[1] D. E. Denning. An intrusion-detection model. IEEE Transactions on Software Engineering, 13(2):222-232, 1987.

[2] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff. A sense of self for Unix processes. In Proceedings of the IEEE Symposium on Security and Privacy, pages 120-128. IEEE Computer Society, 1996.

[3] D. Gao, M. K. Reiter, and D. Song. Behavioral distance measurement using hidden Markov models. In Proceedings of the International Symposium on Research in Attacks, Intrusions and Defenses, pages 19-40. Springer, 2006.

[4] H. Hu, S. Shinde, S. Adrian, Z. L. Chua, P. Saxena, and Z. Liang. Data-oriented programming: On the expressiveness of non-control data attacks. In Proceedings of the IEEE Symposium on Security and Privacy. IEEE Computer Society, 2016.

[5] A. P. Kosoresow and S. A. Hofmeyr. Intrusion detection via system call traces. IEEE software, 14(5):35-42, 1997.

[6] W. Lee and S. J. Stolfo. Data mining approaches for intrusion detection. In Proceedings of the USENIX Security Symposium, pages 6-6. USENIX Association, 1998.

[7] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast automaton-based method for detecting anomalous program behaviors. In Proceedings of the IEEE Symposium on Security and Privacy, pages 144-155. IEEE Computer Society, 2001.

[8] X. Shu, D. Yao, and N. Ramakrishnan. Unearthing stealthy program attacks buried in extremely long execution paths. In Proceedings of the 2015 ACM Conference on Computer and Communications Security (CCS), pages 401-413. ACM, October 2015.

[9] X. Shu, D. Yao, and B. G. Ryder. A formal framework for program anomaly detection. In Proceedings of the 18th International Symposium on Research in Attacks, Intrusions and Defenses (RAID), pages 270-292. Springer, November 2015.

[10] D. Wagner and R. Dean. Intrusion detection via static analysis. In Proceedings of the IEEE Symposium on Security and Privacy, pages 156-168. IEEE Computer Society, 2001.

[11] C. Warrender, S. Forrest, and B. Pearlmutter. Detecting intrusions using system calls: Alternative data models. In Proceedings of the IEEE Symposium on Security and Privacy, pages 133-145. IEEE Computer Society, 1999.

[12] K. Xu, K. Tian, D. Yao, and B. G. Ryder. A sharper sense of self: Probabilistic reasoning of program behaviors for anomaly detection with context sensitivity. In Proceedings of the 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, May 2016.

[13] K. Xu, D. D. Yao, B. G. Ryder, and K. Tian. Probabilistic program modeling for high-precision anomaly classification. In Proceedings of the IEEE 28th Computer Security Foundations Symposium, pages 497-511. IEEE, July 2015.

## Author Biographies

**Xiaokui Shu** is a Research Staff Member in the Security Services Team (GSAL) at the IBM Thomas J. Watson Research Center. He received his Ph.D. in computer science from Virginia Tech and was awarded the Outstanding Ph.D. Student Award at the Department of Computer Science. He also graduated from the University of Science and Technology of China (USTC) with the Guo Moruo Award. Dr. Shu has succeeded in real-world penetration tests and won the first prize in the Virginia Tech Inaugural Cyber Security Summit Competition. He is an active member of the security research community, serving as a shadow PC member and reviewer for top-tier security conferences and journals.

**Danfeng (Daphne) Yao** is an associate professor in the Department of Computer Science at Virginia Tech, Blacksburg. She is an Elizabeth and James E. Turner Jr. ’56 Faculty Fellow and L-3 Faculty Fellow. She received her Ph.D. in Computer Science from Brown University in 2007 and was awarded the NSF CAREER Award in 2010 for her work on human-behavior driven malware detection. She also received the ARO Young Investigator Award in 2014 for her semantic reasoning for mission-oriented security work. Dr. Yao has several Best Paper Awards (ICICS '06, CollaborateCom '09, and ICNP '12) and the Award for Technological Innovation from Brown University in 2006. She holds a U.S. patent for her anomaly detection technologies and serves as an associate editor of IEEE Transactions on Dependable and Secure Computing (TDSC). She is a PC member in numerous computer security conferences, including ACM CCS.