### Introduction
The number of threads is inversely proportional to the average waiting time. Using `qcomputer` [6], an R package for queue system simulation, we created a simulated microservice with exponentially distributed service times and a Poisson arrival process. To achieve a load of \( L \) requests per second with \( \tau \) threads, we generated the sleep time for each thread from a random uniform distribution between 0 and \( U \) (milliseconds), where \( U = 2000\tau \). This means that, on average, each thread will make a request every \( U \) milliseconds. Using this model, we generated samples of arrival and departure times for different parameterizations, from which we calculated response times. We then attempted to estimate the parameters \(\{\lambda, \mu, c\}\) from the samples using the estimators described in Section II. Using the resulting model, we calculated the predicted response time distribution and compared it to the empirical distribution of the sample to calculate the Mean Squared Error (MSE) between both.

### Results
This section presents the results obtained. To measure the error, we calculated both MSE and Bias.

#### A. Simulation with qcomputer
We experimented with five settings in the simulation. The values \([1, 1, 2, 3, 3]\) for \( c \), 30 for all \( \mu \), and \([1, 25, 50, 75, 80]\) for \( \lambda \) were used. Using the sliding window average method, we obtained the results in Table II. Only the estimation in the first line is acceptable and, in fact, very good. This shows the importance of selecting the correct sample for estimating service rate, as their quality will be inversely correlated with occupation. The best estimator for service rate \( \mu \) was used to model all the other settings, as they refer to the same simulated microservice. We know the load to be constant and the inter-arrival times to be exponentially distributed. For each setting, we got an estimate for the arrival rate by the moments method.

When it came time to get an estimate of the parallelism of the service, \( c \), we employed both Park et al. [5] and our alternative method to calculate it by minimizing the MSE. Table III presents the estimations obtained.

For each setting, we calculated the predicted cumulative distribution function (CDF) \( CDF(\lambda, \mu, c, t) \) and the empirical cumulative distribution function \( eCDF(t) \), and calculated the MSE between samplings from those two functions. Figure 1 shows the \( eCDF \) values, the prediction CDF, and the cumulative distribution function of an exponential distribution of rate \( \mu \) ("Exp" in the plots), which represents the distribution of service time \( S \). The exact values are available in Table III. The MSE and Bias values demonstrate that \( eCDF(t) \) and \( CDF(\lambda, \mu, c, t) \) are quite close to each other in the simulated environment. To conserve space, we omitted the figure for the best setting.

#### B. Experiment with a Microservice
To test the approach in a more realistic setting where some assumptions may not hold, we deployed a microservice-based application on a virtual machine with 16 vCores and 32 GiB of system memory, running Ubuntu Server 16.04.3 LTS. The services, data stores, and load balancers were packaged in Docker containers and orchestrated and scaled using Docker Compose. The target microservice was behind a simple gateway service and an Nginx load balancer. Measurements of arrival and departure times, measured from the load balancer, were extracted using OpenTracing [7] compliant tracing instrumentation.

To load the deployments with approximately exponentially distributed inter-arrival request times, we used Apache JMeter. The naive approach would be to have each client thread sleeping for an exponentially distributed time between requests. However, since a client thread can only start a new request once it gets the previous reply, most of the time they will be left waiting for a reply, thus degenerating the distribution of inter-arrival times away from the desired exponential. To mitigate this effect, we attempted to simulate a large number of clients generating load at random intervals, which is known to dilute the degeneration caused by server response time.

We used five deployment settings to evaluate the parameterization technique and the adequacy of the resulting model with the number of instances taking the values \([1, 1, 2, 3, 3]\) and \([16, 25, 50, 75, 85]\) for arrival rate. Given the arrival and departure times for each request, we estimated the model parameters. The service rate was estimated using the sliding window method to maintain independence from \( c \). Parallelism, \( c \), was obtained using two methods: the one proposed by Park et al. [5] and the optimization that minimizes the MSE between observed and predicted response times. Table IV shows the results of the estimation step.

The second method (Optimization) produced better estimations and was used for the remainder of the experiment. Note, however, that they could in principle be used together to get a higher quality estimation. \( CDF(\lambda, \mu, c, t) \) was calculated for each sample and compared to their \( eCDF(t) \) (Figure 1). Table V shows the prediction error. Besides predicting the cumulative distribution function, we also calculated some other typical queueing system performance metrics, namely, mean queue length and mean request time. Table VI shows the resulting values, enabling a comparison between performance metrics and the occupation rate. Note that \( E[T] \) increases as \( \rho \to 1 \) but is not the only determining factor; \( E[T] \) slowly decreases as \( c \) grows, as the chance of finding an available server increases. While the results still have acceptable error, they are not as good as the ones from the simulated experiment. This observation is explored in detail in Section V.

### Discussion
The experiments with the simulated data exposed two important aspects. First, the quality of the estimation of service rate \( \mu \) is very dependent on occupation. To get a good estimate of service rate, we need to sample it under low occupation. With setting S1, we were able to get an estimate of \( \mu \) and accurately predict the behavior of the other settings. In a real setting, there are measurement imprecisions and external factors. In this particular case, we noticed that due to some implementation details, the service time was not independent from the number of instances and improved with the number of instances (refer to Table IV). This might be an artifact of some caching at the back-end, in this case a shared data store, which is a distortion of the intended setting. So far, we avoided more general queuing systems (G/G/c), as they are not easily composable and lack closed solutions.

There are some limitations inherent to the approach. The estimation method for service rate is very sensitive to occupation, thus requiring a favorable sampling period where the load on the microservice to be modeled is low. The estimation methods for parallelism have distinct limitations. The one proposed by Park et al. [5] requires having complete sampling, starting at an instant when there were no requests in the system. The optimization method requires already having a good estimate of service rate and will be dependent on its quality. As for the model itself, since \( E[T] \) grows asymptotically to infinity as \( \rho \to 1 \), the model is far more sensitive to error in estimation under higher loads, for which we are attempting to predict the distribution of \( T \).

Our goal for the future is composing the individual models in networks. A deeper characterization and further study of this modeling approach is necessary. As such, we will run additional experiments in a more varied set of instrumented microservices. To model services in place in a production setting, methods to quantify the impact of services on other upstream services, which depend on them, will have to be developed. For services that have more general service rates, we will attempt to model them as tandem queues.

### Acknowledgments
This work was carried out under the project PTDC/EEI-ESS/1189/2014 — Data Science for Non-Programmers, supported by COMPETE 2020, Portugal 2020-POCI, UE-FEDER, and FCT. We would also like to express our gratitude to the INCD - Infraestrutura Nacional de Computação Distribuída, for providing access to their computational resources.

### References
[1] R. P. R. Filipe and F. Araujo, “Client-side black-box monitoring for web sites,” in 2017 IEEE 16th International Symposium on Network Computing and Applications (NCA), Oct 2017.

[2] R. R. Sambasivan, I. Shafer, J. Mace, B. H. Sigelman, R. Fonseca, and G. R. Ganger, “Principled workflow-centric tracing of distributed systems,” in Proceedings of the Seventh ACM Symposium on Cloud Computing - SoCC ’16. New York, New York, USA: ACM Press, 2016, pp. 401–414.

[3] A. A. Shahin, “Enhancing Elasticity of SaaS Applications using Queuing Theory,” IJACSA) International Journal of Advanced Computer Science and Applications, vol. 8, no. 1, pp. 279–285, 2017.

[4] I. Adan and J. Resing, “Queueing theory,” 2015.

[5] J. Park, Y. B. Kim, and T. R. Willemain, “Analysis of an unobservable queue using arrival and departure times,” Computers and Industrial Engineering, vol. 61, no. 3, pp. 842–847, 2011.

[6] A. Ebert, P. Wu, K. Mengersen, and F. Ruggeri, “Computationally Efficient Simulation of Queues: The R Package queuecomputer,” mar 2017.

[7] “OpenTracing,” http://opentracing.io/, retrieved Oct, 2017.

[8] P. Bahl, R. Chandra, A. Greenberg, S. Kandula, D. A. Maltz, and M. Zhang, “Towards highly reliable enterprise network services via inference of multi-level dependencies,” SIGCOMM Comput. Commun. Rev., vol. 37, no. 4, pp. 13–24, Aug. 2007.

[9] B. Urgaonkar, G. Pacifici, P. Shenoy, M. Spreitzer, and A. Tantawi, “An analytical model for multi-tier internet services and its applications,” SIGMETRICS Perform. Eval. Rev., vol. 33, no. 1, pp. 291–302, Jun. 2005.

[10] J. Bi, Z. Zhu, R. Tian, and Q. Wang, “Dynamic provisioning modeling for virtualized multi-tier applications in cloud data center,” in Proceedings - 2010 IEEE 3rd International Conference on Cloud Computing, CLOUD2010. IEEE, Jul 2010, pp. 370–377.

[11] H. Li, “A Queue Theory Based Response Time Model for Web Services Chain,” 2010 International Conference on Computational Intelligence and Software Engineering, pp. 1–4, 2010.

[12] W.-p. Yang, L.-c. Wang, and H.-p. Wen, “A queueing analytical model for service mashup in mobile cloud computing,” 2013 IEEE Wireless Communications and Networking Conference (WCNC), pp. 2096–2101, Apr 2013.

[13] J. Dilley, R. Friedrich, T. Jin, and J. Rolia, “Web server performance measurement and modeling techniques,” Performance Evaluation, vol. 33, no. 1, pp. 5–26, Jun 1998.

[14] J. Cao, M. Andersson, C. Nyberg, and M. Kihl, “Web Server Performance Modeling using an M/G/1/K*PS Queue,” in 10th International Conference on Telecommunications, ICT2003, vol. 2, no. 2, 2003, pp. 1501–1506.

[15] R. Heinrich, A. van Hoorn, H. Knoche, F. Li, L. E. Lwakatare, C. Pahl, S. Schulte, and J. Wettinger, “Performance Engineering for Microservices,” in Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion - ICPE’17 Companion. New York, New York, USA: ACM Press, 2017, pp. 223–226.