### Over the Measurements in the Density Function for the Recent Window

For the recent window \( s \in R_i \), the value of \( a_i \) is calculated as:
\[ a_i = \sum_{s \in R_i} R_i(s) \log \left( \frac{R_i(s)}{S_i(s)} \right) \]

This computation can be updated incrementally in constant time as one measurement leaves the recent window and another enters it. To prevent division by zero, the measurements in the recent window are included in the distribution \( S_i \).

By default, each client reports this score whenever there is new information available to the model (e.g., a request or hiatus). However, it is straightforward to add feedback or batching to the client-server protocol to reduce communication traffic (as discussed in Section 5.3).

### 4.2 Results

Figure 3 shows the results of our detection experiments. There were no false positives in these experiments, and the detection latency was never more than a couple of seconds. Although some attacks are difficult to detect when only a few machines are infected (low \( d \)), Syzygy is able to correctly detect each attack once a sufficiently large number of clients are infected. In the case of the third (iii) content spoof attack, the behavior is anomalous enough on even a single client for our simple response time model to detect it; this is not true for most of the other attacks, meaning the community was crucial.

We achieved these high detection rates despite the fact that our behavior model was incomplete and noisy. Figure 4 shows part of the distribution of anomaly scores reported by individual healthy clients. These values ranged as high as 0.8, but we have truncated the graph for readability. In contrast, the healthy community scores stayed within a very small range (the dashed red line is actually a very slim Gaussian). The epidemic threshold \( V \) is the dotted line to the right of the cluster of community scores. Because the community scores are such a stable signal, they enable Syzygy both to reliably provide a low false positive rate and to be sensitive to minor—but not isolated—changes in client behavior.

In the subsequent sections, we discuss the benefits of distributed training, the effects of heterogeneous hardware and user behavior, performance and overhead on a real network deployment, predicting and setting the false positive rate, performance in communities with thousands of clients, and Syzygy’s robustness against tainted training data and advanced exploit behavior (like mimicry).

### 5 Deployment Experiments

For practical use, our method assumes that (i) a real deployment can scale to large numbers of clients across a realistic network topology and (ii) despite minor client variations, such as hardware and configuration differences, healthy anomaly score distributions are similar across clients. We verify that these assumptions hold in practice by deploying Syzygy on several dozen Linux workstations on a university campus. Most of these machines were 3.0 GHz Intel Core2 Duos with 2 GB RAM and the CentOS 5 operating system; exceptions include two laptops and (briefly) the Syzygy server itself. Syzygy monitored the Firefox web browser via `strace` on Linux. Over the course of these two weeks of experiments, Syzygy reported no false positives.

#### 5.1 Model

In the next two sections, we use a model of client behavior (different from Section 4) that uses short sequences of a program’s system calls. This information can be gathered with low overhead and has been shown to be useful [9, 14]. We use sequences of six system calls to be consistent with previous work [7, 14, 22], but instead of using one of the existing stide or t-stide algorithms [33], the model uses an information-theoretic approach with several additional modifications. During training, Syzygy computes a frequency distribution of system call sequences of length six and the maximum observed time between consecutive system call invocations. The computations are extremely similar to Section 4.1, but use system call sequences as measurements, instead of request response times.

Whenever a system call is invoked, the model concatenates the name of the call onto a sequence consisting of the previous five and increments the counter associated with that sequence. For example, on Mac OS X, while executing the command `echo hi`, we generate the following period-delimited sequence:
\[ s = \text{sigaction.writev.read.select.select.exit.} \]

Even when idle, many applications will continue to invoke system calls (e.g., polling for new work or user input). This behavior acts as a kind of heartbeat for the program, and its absence indicates unusual behavior just as much as the presence of, say, unusual system call sequences. For example, during one such execution of `echo hi`, the maximum time between system call invocations, according to `dtrace`, was 375 μs.

Using this kind of information about call sequences and timing, we construct a model analogous to the one for request response times in Section 4.1. The only differences are that the tables used to construct \( S_i \) and \( R_i \) are indexed by sequences and the recent window \( W_i \) has units of sequences. The anomaly signal is computed as described in Section 4.1.

#### 5.2 Distributed Training

Over a period of roughly two weeks, we collected normal usage traces from 35 active clients. During the day, a median of 8 clients were active at a time. The first week of these traces is our training data and contains more than 2.2 billion sequences, of which approximately 180,000 are unique. As shown in Figure 5, most of the sequences were seen quickly (90% within the first 25% of the trace). The fact that training speeds up with community size is consistent with previous work [21]; Syzygy’s distinctive use of the community occurs during the monitoring phase (Section 5.3).

During this training period, while the clients were reporting both the complete sequences and timestamps at an average of 100 KB/s, the average bandwidth usage at the server was 1160 KB/s (the peak was 3240 KB/s). The clients required less than 1% CPU each for the `strace` process and Syzygy script. With all 35 clients active, the server-side script was using 13% of the processor, on average, with peaks as high as 32%.

Even though the training data includes machines that are unlike most of the cluster, such as two laptops, we still find that the distribution of community anomaly scores within the training community converges toward a tight normal distribution. Figure 6 shows the standard deviation of the community score for increasing numbers of clients; in the figure, the clients “join” the community in reverse order of average anomaly score (so \( n = 1 \) represents the client with the highest average anomaly score). To evaluate the impact of heterogeneity, we also plot four hypothetical communities: “Outliers Removed,” where the two laptops and the Syzygy server were replaced with the client with the lowest standard deviation, “High SD Removed,” where the five clients with the highest standard deviations were replaced with five clones of the machine with the lowest standard deviation, and “Homogeneous” and “Homogeneous (High SD),” which are communities of \( n \) clones of the client with the lowest average anomaly score and highest standard deviation, respectively. The results show that variance in the community score comes not from client heterogeneity (the client in “Homogeneous (High SD)” was a normal cluster machine) but from client variance. The results also show that a larger community can compensate for client variance.

Section 3.3 shows how to compute the threshold \( V \), given a desired false positive rate and the training data; these analytical results correspond well with what we observe experimentally. Using the data from our deployment, Figure 7 plots the appropriate choice of \( V \) for a desired false positive rate (note the log scale) and community size (\( n \)). The units of the false positive rate, for this purpose, are in terms of the fraction of the training set.