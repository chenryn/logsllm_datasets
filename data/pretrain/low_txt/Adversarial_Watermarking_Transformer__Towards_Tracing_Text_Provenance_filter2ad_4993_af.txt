以下是优化后的参考文献列表，使其更加清晰、连贯和专业：

1. [43] A. Wilson 和 A. D. Ker, “在 Twitter 上避免检测：嵌入式语言隐写策略,” 《电子成像》, 卷 2016, 编号 8, 第 1-9 页, 2016 年。
2. [44] M. H. Shirali-Shahreza 和 M. Shirali-Shahreza, “一种新的同义词文本隐写术,” 在 IEEE 国际智能信息隐藏与多媒体信号处理会议, 2008 年。
3. [45] T. Fang, M. Jaggi 和 K. Argyraki, “使用 LSTM 生成隐写文本,” 在第 55 届计算语言学协会年会-学生研究研讨会, 2017 年。
4. [46] Z. Li, C. Hu, Y. Zhang 和 S. Guo, “如何证明您的模型属于您: 基于盲水印框架保护深度神经网络的知识产权,” 在第 35 届年度计算机安全应用会议 (ACSAC), 2019 年。
5. [47] N. Lukas, Y. Zhang 和 F. Kerschbaum, “通过可转移对抗样本对深度神经网络进行指纹识别,” arXiv 预印本 arXiv:1912.00888, 2019 年。
6. [48] Y. Adi, C. Baum, M. Cisse, B. Pinkas 和 J. Keshet, “将弱点转化为优势: 通过后门技术为深度神经网络加水印,” 在第 27 届 USENIX 安全研讨会 (USENIX Security 18), 2018 年。
7. [49] E. Le Merrer, P. Perez 和 G. Trédan, “远程神经网络水印的对抗边界缝合,” 《神经计算与应用》, 卷 32, 编号 13, 第 9233-9244 页, 2020 年。
8. [50] Y. Uchida, Y. Nagai, S. Sakazawa 和 S. Satoh, “将水印嵌入到深度神经网络中,” 在国际多媒体检索会议 (ICMR), 2017 年。
9. [51] H. Chen, B. D. Rouhani, C. Fu, J. Zhao 和 F. Koushanfar, “DeepMarks: 用于深度学习模型数字版权管理的安全指纹框架,” 在国际多媒体检索会议 (ICMR), 2019 年。
10. [52] B. Darvish Rouhani, H. Chen 和 F. Koushanfar, “DeepSigns: 用于保护深度神经网络所有权的端到端水印框架,” 在第 24 届编程语言和操作系统架构支持国际会议, 2019 年。
11. [53] T. Gu, B. Dolan-Gavitt 和 S. Garg, “BadNets: 识别机器学习模型供应链中的漏洞,” arXiv 预印本 arXiv:1708.06733, 2017 年。
12. [54] J. Zhang, Z. Gu, J. Jang, H. Wu, M. P. Stoecklin, H. Huang 和 I. Molloy, “通过水印保护深度神经网络的知识产权,” 在 ACM 亚洲计算机与通信安全会议 (AsiaCCS), 2018 年。
13. [55] H. Jia, C. A. Choquette-Choo 和 N. Papernot, “作为抵御模型提取防御措施的纠缠水印,” arXiv 预印本 arXiv:2002.12200, 2020 年。
14. [56] H. Li, E. Wenger, B. Y. Zhao 和 H. Zheng, “抗盗版的深度神经网络水印,” arXiv 预印本 arXiv:1910.01226, 2019 年。
15. [57] N. Yu, L. S. Davis 和 M. Fritz, “将伪造图像归因于 GAN: 学习和分析 GAN 指纹,” 在 IEEE 国际计算机视觉会议 (ICCV), 2019 年。
16. [58] S.-Y. Wang, O. Wang, R. Zhang, A. Owens 和 A. A. Efros, “目前 CNN 生成的图像很容易被发现...,” 在 IEEE 计算机视觉与模式识别会议 (CVPR), 2020 年。
17. [59] N. Carlini 和 H. Farid, “通过白盒和黑盒攻击规避 Deepfake 图像检测器,” 在 IEEE 计算机视觉与模式识别会议 (CVPR) 研讨会, 2020 年。
18. [60] B. Zhang, J. P. Zhou, I. Shumailov 和 N. Papernot, “不是我的 Deepfake: 向机器生成媒体提供合理否认的可能性,” arXiv 预印本 arXiv:2008.09194, 2020 年。
19. [61] M. Stern, W. Chan, J. Kiros 和 J. Uszkoreit, “插入变压器: 通过插入操作实现灵活序列生成,” 在国际机器学习会议 (ICML), 2019 年。
20. [62] M. Caccia, L. Caccia, W. Fedus, H. Larochelle, J. Pineau 和 L. Charlin, “语言 GAN 的不足之处,” 在国际表征学习会议 (ICLR), 2020 年。
21. [63] H. Hosseini, B. Xiao, A. Clark 和 R. Poovendran, “攻击自动视频分析算法: 以 Google Cloud Video Intelligence API 为例的研究,” 在多媒体隐私与安全, 2017 年。
22. [64] E. Mariconti, G. Suarez-Tangil, J. Blackburn, E. De Cristofaro, N. Kourtellis, I. Leontiadis, J. L. Serrano 和 G. Stringhini, ““你知道该怎么做”——YouTube 视频受到协调仇恨攻击的主动检测,” 《人机交互》, 卷 3, 编号 CSCW, 第 1-21 页, 2019 年。
23. [65] D. Bahdanau, K. Cho 和 Y. Bengio, “通过联合学习对齐和翻译进行神经机器翻译,” 在国际表征学习会议 (ICLR), 2015 年。
24. [66] R. Shetty, M. Rohrbach, L. Anne Hendricks, M. Fritz 和 B. Schiele, “说同样的语言: 通过对抗训练匹配机器与人类字幕,” 在 IEEE 国际计算机视觉会议 (ICCV), 2017 年。
25. [67] K. Choi, C. Hawthorne, I. Simon, M. Dinculescu 和 J. Engel, “使用 Transformer 自编码器编码音乐风格,” arXiv 预印本 arXiv:1912.05537, 2019 年。
26. [68] E. Jang, S. Gu 和 B. Poole, “带有 Gumbel-Softmax 的分类重参数化,” 在国际表征学习会议 (ICLR), 2017 年。
27. [69] M. J. Kusner 和 J. M. Hernández-Lobato, “使用 Gumbel-Softmax 分布的离散元素序列 GAN,” arXiv 预印本 arXiv:1611.04051, 2016 年。
28. [70] S. Merity, N. S. Keskar 和 R. Socher, “正则化和优化 LSTM 语言模型,” 在国际表征学习会议 (ICLR), 2018 年。
29. [71] H. Inan, K. Khosravi 和 R. Socher, “绑定词向量和词分类器: 语言建模的损失框架,” 在国际表征学习会议 (ICLR), 2017 年。
30. [72] R. Shetty, B. Schiele 和 M. Fritz, “A4NT: 通过对抗训练实现神经机器翻译的作者属性匿名性,” 在第 27 届 USENIX 安全研讨会 (USENIX Security 18), 2018 年。
31. [73] A. Conneau, D. Kiela, H. Schwenk, L. Barrault 和 A. Bordes, “从自然语言推理数据中监督学习通用句子表示,” 在经验方法自然语言处理会议 (EMNLP), 2017 年。
32. [74] S. Bowman, G. Angeli, C. Potts 和 C. D. Manning, “用于学习自然语言推理的大规模标注语料库,” 在经验方法自然语言处理会议 (EMNLP), 2015 年。
33. [75] Z. Dai, Z. Yang, Y. Yang, J. G. Carbonell, Q. Le 和 R. Salakhutdinov, “Transformer-XL: 超越固定长度上下文的注意力语言模型,” 在第 57 届计算语言学协会年会 (ACL), 2019 年。
34. [76] N. Carlini, C. Liu, Ú. Erlingsson, J. Kos 和 D. Song, “秘密分享者: 评估和测试神经网络中的非预期记忆,” 在第 28 届 USENIX 安全研讨会 (USENIX Security 19), 2019 年。
35. [77] S. Merity, C. Xiong, J. Bradbury 和 R. Socher, “指针哨兵混合模型,” 在国际表征学习会议 (ICLR), 2017 年。
36. [78] S. Merity, N. S. Keskar 和 R. Socher, “多尺度神经语言模型的分析,” arXiv 预印本 arXiv:1803.08240, 2018 年。
37. [83] N. Reimers 和 I. Gurevych, “Sentence-BERT: 使用 Siamese BERT 网络的句子嵌入,” 在经验方法自然语言处理会议及第九届国际联合自然语言处理会议 (EMNLP-IJCNLP), 2019 年。
38. [84] A. Venugopal, J. Uszkoreit, D. Talbot, F. J. Och 和 J. Ganitkevitch, “在结构化预测输出中添加水印及其在统计机器翻译中的应用,” 在经验方法自然语言处理会议 (EMNLP), 2011 年。
39. [85] J. A. Suykens 和 J. Vandewalle, “最小二乘支持向量机分类器,” 《神经处理通讯》, 卷 9, 编号 3, 第 293-300 页, 1999 年。
40. [86] L. Fan, K. W. Ng 和 C. S. Chan, “重新思考深度神经网络所有权验证: 嵌入护照以抵御模糊攻击,” 在神经信息处理系统进展, 2019 年。
41. [87] A. Holtzman, J. Buys, L. Du, M. Forbes 和 Y. Choi, “神经文本退化的奇特案例,” 在国际表征学习会议 (ICLR), 2020 年。
42. [88] C. Castillo, M. Mendoza 和 B. Poblete, “Twitter 上的信息可信度,” 在第 20 届万维网国际会议, 2011 年。
43. [89] R. Tan, B. Plummer 和 K. Saenko, “检测跨模态不一致性以防御神经假新闻,” 在经验方法自然语言处理会议 (EMNLP), 2020 年。
44. [90] J. Thorne, M. Chen, G. Myrianthous, J. Pu, X. Wang 和 A. Vlachos, “使用分类器堆叠集成进行假新闻立场检测,” 在 EMNLP 研讨会: 自然语言处理遇见新闻业, 2017 年。
45. [79] M. Marcus, B. Santorini 和 M. A. Marcinkiewicz, “构建大型英语注释语料库: Penn Treebank,” 《计算语言学》, 卷 19, 编号 2, 第 313-330 页, 1993 年。
46. [80] D. P. Kingma 和 J. Ba, “Adam: 一种随机优化方法,” 在国际表征学习会议 (ICLR), 2015 年。
47. [81] M. Denkowski 和 A. Lavie, “Meteor Universal: 适用于任何目标语言的语言特定翻译评估,” 在第 9 届统计机器翻译研讨会, 2014 年。
48. [82] G. A. Miller, 《WordNet: 电子词汇数据库》. MIT 出版社, 1998 年。
49. [91] N. Hassan, F. Arslan, C. Li 和 M. Tremayne, “迈向自动化事实核查: 通过 ClaimBuster 检测值得检查的事实陈述,” 在 ACM SIGKDD 国际知识发现与数据挖掘会议 (KDD), 2017 年。
50. [92] O. Sharir, B. Peleg 和 Y. Shoham, “训练 NLP 模型的成本: 简明概述,” arXiv 预印本 arXiv:2004.08900, 2020 年。
51. [93] Lambda, “OpenAI 的 GPT-3 语言模型: 技术概览。”[在线] 可用: https://lambdalabs.com/blog/demystifying-gpt-3/

### A. 指标分析

#### VIII. 附录
我们展示了更多的示例来检验和验证我们用来评估或排序模型输出的指标。

1. **采样**:
   在第五章第二节第六小节中，我们讨论了语言模型损失在句法正确性方面略优于 SBERT。因此，我们使用它来排序并选择最佳样本。在表 XI 中，我们展示了此类情况的示例。尽管如此，我们仍然使用 SBERT 作为度量标准来测量语义相似性，因为其具有以下所述的优点。

2. **SBERT 和 Meteor**:
   在我们的分析中，我们除了使用 Meteor 分数外，还使用输入和输出句子嵌入之间的 SBERT 距离作为辅助度量标准。这里我们演示了一些高 SBERT 距离的情况，并展示了其相对于仅使用 Meteor 的优点。

   其中一个产生高 SBERT 距离的情况是输出文本改变了情感（例如，使用否定），如表 XII 中的两个示例所示。这些示例的 Meteor 分数并不特别低，因为改变的单词不多。第一个示例在语法上也是正确的（使用“are 't”）。尽管如此，它们不希望地改变了输入句子的语义，而这是通过 SBERT 检测到的，因为它是在自然语言推理 (NLI) 任务上训练的。此外，我们在表 XIII 中展示了两个具有相同输入句子和相近 Meteor 分数的示例，但 SBERT 距离较低的那个更具连贯性。

   根据这些观察以及我们在第五章第二节第六小节中进行的定性分析（例如，在“无判别器”模型上的分析），我们发现使用 SBERT 是一种有效的度量标准来近似语义相似性，并且比单独使用 Meteor 提供更多信息。

### B. 降噪

对于降噪自编码器 (DAE)，我们在编码器和解码器中分别使用了 6 个编码和解码的 Transformer 层。我们还共享了编码器、解码器和预 softmax 层的嵌入（维度：512）。解码器具有掩码自注意力机制，并关注编码器的输出。

| 输入 | SBERT 示例 | LM 示例 |
| --- | --- | --- |
| 新的 M @-@ 120 设计取代了 M @-@ 20 南部。<br>M @-@ 82 现在从 到 只运行。<br>城市继续增长，得益于委员会政府的努力，在 1920 年代带来了蓬勃发展的汽车行业。 | 新的 M @-@ 120 设计取代了 M @-@ 20 南部。<br>M @-@ 82 现在从 到 只运行。<br>城市继续增长，得益于委员会政府的努力，在 1920 年代带来了蓬勃发展的汽车行业。 | 新的 M @-@ 120 设计取代了 M @-@ 20 南部。<br>M @-@ 82 现在从 到 只运行。<br>城市继续增长，得益于委员会政府的努力，在 1920 年代带来了蓬勃发展的汽车行业。 |

| 输入 | 输出 | SBERT | Meteor |
| --- | --- | --- | --- |
| 也有许多物种。<br>有三条主要路线可以攀登这座山，每条路线都要爬升超过 4,100 英尺（1,200 米）的高度。<br>她的家人最初来自波兰和俄罗斯。<br>的父母都在儿童时期表演过。<br>在 2012 年的一次采访中， 表示：“家里从来没有宗教信仰。” | 物种<br>没有很多<br>在那里<br>有三条主要路线可以攀登这座山，每条路线都要爬升超过 4,100 英尺（1,200 米）的高度。<br>她的家人最初来自波兰和俄罗斯。<br>的父母都在儿童时期表演过。<br>在 2012 年的一次采访中， 表示：“家里从来没有宗教信仰。” | 7.5 | 0.93 |
| 搜索<br>指控<br>变得更加<br>这<br>广泛<br>亚历山大出现在纪录片中<br>对于<br>这已被几位作者引用，包括杰拉尔德<br>一位专家。 | 搜索<br>指控<br>变得更加<br>这<br>广泛<br>亚历山大出现在纪录片中<br>对于<br>这已被几位作者引用，包括杰拉尔德<br>一位专家。 | 7.19 | 0.93 |

| 输入 | 输出 | SBERT | Meteor |
| --- | --- | --- | --- |
| 搜索<br>指控<br>变得更加<br>这<br>广泛<br>亚历山大出现在纪录片中<br>对于<br>这已被几位作者引用，包括杰拉尔德<br>一位专家。<br>这首歌的最后一段有一句歌词“喂食他所创造的尖叫”，<br>这句话出自电影《巴西男孩》，其中博士是反派角色。 | 搜索<br>指控<br>变得更加<br>这<br>广泛<br>亚历山大出现在纪录片中<br>对于<br>这已被几位作者引用，包括杰拉尔德<br>一位专家。<br>这首歌的最后一段有一句歌词“喂食他所创造的尖叫”，<br>这句话出自电影《巴西男孩》，其中博士是反派角色。 | 搜索<br>指控<br>变得更加<br>这<br>广泛<br>亚历山大出现在纪录片中<br>对于<br>这已被几位作者引用，包括杰拉尔德<br>一位专家。<br>这首歌的最后一段有一句歌词“喂食他所创造的尖叫”，<br>这句话出自电影《巴西男孩》，其中博士是反派角色。 | 搜索<br>指控<br>变得更加<br>这<br>广泛<br>亚历山大出现在纪录片中<br>对于<br>这已被几位作者引用，包括杰拉尔德<br>一位专家。<br>这首歌的最后一段有一句歌词“喂食他所创造的尖叫”，<br>这句话出自电影《巴西男孩》，其中博士是反派角色。 |