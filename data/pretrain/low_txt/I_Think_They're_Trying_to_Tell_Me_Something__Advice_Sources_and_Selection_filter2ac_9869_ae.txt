### We also found that participants rely on IT professionals, particularly those from their workplaces, as a source of credible digital-security advice, even for personal technology. Given that many IT professionals are already overloaded with requests, we suggest organizations plan to provide them with extra support and training for this potentially critical but under-acknowledged role. Training IT professionals to distribute a small set of valuable advice as an explicit part of their job duties could have a strong positive impact on users’ security behavior. Investigating the feasibility and efficacy of this approach is a rich topic for future work.

### VI. SUMMARY

Users must sift through a multitude of security advice to determine which security behaviors to implement and which to reject. This process of evaluating security tactics based on the advice of others is multifaceted and complex. To understand users' choices, we conducted a semi-structured interview study with 25 participants from diverse demographics and varying levels of security sensitivity. We inquired about their security behaviors, how they learned these behaviors, and why they accepted or rejected different pieces of advice. Our analysis of these interviews yielded three key findings.

First, our findings indicate that users believe they lack the skills to evaluate the content of digital-security advice and instead rely on their assessment of the trustworthiness of the advice source. Trusted sources include their workplace, providers of digital services, IT professionals, family members, and friends. Participants also considered media as a source of advice, but only if it passed a heuristic credibility test.

Second, we found that users reject security advice for several surprising reasons, including the presence of too much marketing information and threats to their sense of privacy. Additionally, a majority of participants believed that someone or something else was responsible for their security in at least one digital domain (e.g., online banking).

Third, we found evidence that vignettes of negative experiences in TV shows or movies may be able to change behavior in a manner similar to directly experienced negative events. Thus, further research testing the efficacy of fictional negative-event vignettes in security-behavior change could lead to the development of a novel, highly effective intervention.

### ACKNOWLEDGMENTS

We would like to thank Lujo Bauer, Yla Tausczik, Bethany Tiernan, and Bruce Webster, Jr. for their input and assistance. This material is based upon work supported by the Maryland Procurement Office under contract no. H98230-14-C-0137.

### REFERENCES

[1] “US-CERT: Tips.” [Online]. Available: https://www.us-cert.gov/ncas/tips

[2] S. Das, T. H. Kim, L. Dabbish, and J. Hong, “The effect of social influence on security sensitivity,” in Tenth Symposium on Usable Privacy and Security. USENIX Association, 2014. [Online]. Available: https://www.usenix.org/conference/soups2014/proceedings/presentation/das

[3] E. Rader, R. Wash, and B. Brooks, “Stories as informal lessons about security,” in Eighth Symposium on Usable Privacy and Security. ACM, 2012. [Online]. Available: http://doi.acm.org/10.1145/2335356.2335364

[4] L. Rainie, S. Kiesler, R. Kang, and M. Madden, “Anonymity, privacy, and security online,” Pew Research Center, 2013. [Online]. Available: http://www.pewinternet.org/2013/09/05/anonymity-privacy-and-security-online/

[5] A. E. Howe, I. Ray, M. Roberts, M. Urbanska, and Z. Byrne, “The psychology of security for the home computer user.” in IEEE Symposium on Security and Privacy. IEEE Computer Society, 2012. [Online]. Available: http://dblp.uni-trier.de/db/conf/sp/sp2012.html#HoweRRUB12

[6] C. Herley, “So long, and no thanks for the externalities: The rational rejection of security advice by users,” in New Security Paradigms Workshop. ACM, 2009. [Online]. Available: http://doi.acm.org/10.1145/1719030.1719050

[7] A. Beautement, M. A. Sasse, and M. Wonham, “The compliance budget: managing security behavior in organizations,” in 2008 workshop on New security paradigms. ACM, 2009. [Online]. Available: http://portal.acm.org/citation.cfm?id=1595676.1595684&coll=DL&dl=ACM&CFID=595658384&CFTOKEN=19488999

[8] I. Ion, R. Reeder, and S. Consolvo, “‘No non-expert can hack my mind’: Comparing expert and non-expert security practices,” in Eleventh Symposium On Usable Privacy and Security. USENIX Association, 2015. [Online]. Available: https://www.usenix.org/conference/soups2015/proceedings/presentation/ion

[9] S. Das, A. D. Kramer, L. A. Dabbish, and J. Hong, “Increasing security sensitivity with social proof: A large-scale experimental confirmation,” in SIGSAC Conference on Computer and Communications Security. ACM, 2014. [Online]. Available: http://doi.acm.org/10.1145/2660267.2660271

[10] R. Wash, “Folk models of home computer security,” in Sixth Symposium on Usable Privacy and Security. ACM, 2010. [Online]. Available: http://cups.cs.cmu.edu/soups/2010/proceedings/a11 Walsh.pdf

[11] E. Rader and R. Wash, “Identifying patterns in informal sources of security information,” Journal of Cybersecurity, 2015. [Online]. Available: http://cybersecurity.oxfordjournals.org/content/early/2015/12/01/cybsec.tyv008

[12] C. Herley, “More is not the answer,” IEEE Security and Privacy magazine, 2014. [Online]. Available: http://research.microsoft.com/apps/pubs/default.aspx?id=208503

[18] E. M. Rogers, Diffusion of innovations. New York: Free Press, 2003.

[19] R. E. Rice and K. E. Pearce, “Divide and diffuse: Comparing digital divide and diffusion of innovations perspectives on mobile phone adoption,” 2015.

[20] P. J. A. van Dijk, “The evolution of the digital divide: Turns to inequality of skills and usage,” in Digital Enlightenment Yearbook 2012, J. Bus, M. Crompton, M. Hildebrandt, and G. Metakides, Eds. Amsterdam: IOS Press, 2012. [Online]. Available: http://doc.utwente.nl/83918/

[21] S. Sheng, B. Magnien, P. Kumaraguru, A. Acquisti, L. F. Cranor, J. Hong, and E. Nunge, “Anti-phishing Phil: The design and evaluation of a game that teaches people not to fall for phish,” in Third Symposium on Usable Privacy and Security. ACM, 2007. [Online]. Available: http://doi.acm.org/10.1145/1280680.1280692

[22] N. A. G. Arachchilage and S. Love, “A game design framework for avoiding phishing attacks,” Comput. Hum. Behav., 2013. [Online]. Available: http://dx.doi.org/10.1016/j.chb.2012.12.018

[13] R. Wash and E. Rader, “Too much knowledge? Among United States internet users and protective behaviors in beliefs and security,” in Eleventh Symposium On Usable Privacy and Security. USENIX Association, 2015. [Online]. Available: https://www.usenix.org/conference/soups2015/proceedings/presentation/wash

[14] T. Halevi, J. Lewis, and N. Memon, “A pilot study of cyber security and privacy-related behavior and personality traits,” in 22nd International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2013. [Online]. Available: http://dl.acm.org/citation.cfm?id=2487788.2488034

[15] S. Sheng, M. Holbrook, P. Kumaraguru, L. F. Cranor, and J. Downs, “Who falls for phish?: A demographic analysis of phishing susceptibility and effectiveness of interventions,” in SIGCHI Conference on Human Factors in Computing Systems. ACM, 2010. [Online]. Available: http://doi.acm.org/10.1145/1753326.1753383

[16] “Microsoft Safety and Security Center.” [Online]. Available: http://www.microsoft.com/security/default.aspx

[17] “McAfee Security Advice Center.” [Online]. Available: http://home.mcafee.com/advicecenter/

[23] V. Garg, L. J. Camp, K. Connelly, and L. Lorenzen-Huber, “Risk communication design: Video vs. text,” in Privacy Enhancing Technologies: 12th International Symposium, PETS 2012, Vigo, Spain, July 11-13, 2012. Springer Berlin Heidelberg, 2012. [Online]. Available: http://dx.doi.org/10.1007/978-3-642-31680-7_15

[24] S. A. Robila and J. W. Ragucci, “Don’t be a phish: Steps in user education,” in Proceedings of the 11th Annual SIGCSE Conference on Innovation and Technology in Computer Science Education. New York, NY, USA: ACM, 2006. [Online]. Available: http://doi.acm.org/10.1145/1140124.1140187

[25] E. Lin, S. Greenberg, E. Trotter, D. Ma, and J. Aycock, “Does domain highlighting help people identify phishing sites?” in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. New York, NY, USA: ACM, 2011. [Online]. Available: http://doi.acm.org/10.1145/1978942.1979244

[26] S. Egelman, L. F. Cranor, and J. Hong, “You’ve been warned: An empirical study of the effectiveness of web browser phishing warnings,” in SIGCHI Conference on Human Factors in Computing Systems. ACM, 2008. [Online]. Available: http://doi.acm.org/10.1145/1357054.1357219

[27] D. Akhawe and A. P. Felt, “Alice in warningland: A large-scale field study of browser security warning effectiveness,” in 22nd USENIX Conference on Security. Berkeley, CA, USA: USENIX Association, 2013. [Online]. Available: http://dl.acm.org/citation.cfm?id=2534766.2534789

[28] J. Sunshine, L. F. Cranor, S. Egelman, H. Almuhimedi, N. Atri, and L. F. Cranor, “Crying wolf: An empirical study of SSL warning effectiveness,” in 18th Conference on USENIX Security Symposium. USENIX Association, 2009. [Online]. Available: http://dl.acm.org/citation.cfm?id=1855768.1855793

[29] M. Wu, R. C. Miller, and S. L. Garfinkel, “Do security toolbars actually prevent phishing attacks?” in SIGCHI Conference on Human Factors in Computing Systems. ACM, 2006. [Online]. Available: http://doi.acm.org/10.1145/1124772.1124863

[30] S. E. Schechter, R. Dhamija, A. Ozment, and I. Fischer, “The Emperor’s New Security Indicators,” IEEE Symposium on Security and Privacy, 2007. [Online]. Available: http://dl.acm.org/citation.cfm?id=1264196

[31] C. Bravo-Lillo, S. Komanduri, L. F. Cranor, R. W. Reeder, M. Sleeper, J. Downs, and S. Schechter, “Your attention please: Designing security-decision UIs to make genuine risks harder to ignore,” in Ninth Symposium on Usable Privacy and Security. ACM, 2013. [Online]. Available: http://doi.acm.org/10.1145/2501604.2501610

[32] B. Ur, P. G. Kelley, S. Komanduri, J. Lee, M. Maass, M. L. Mazurek, T. Passaro, R. Shay, T. Vidas, L. Bauer, N. Christin, and L. F. Cranor, “How does your password measure up? The effect of strength meters on password creation,” in 21st USENIX conference on Security symposium. USENIX Association, 2012. [Online]. Available: https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final209.pdf

[33] M. Ciampa, “A comparison of password feedback mechanisms and their impact on password entropy,” Information Management & Computer Security, 2013. [Online]. Available: http://dx.doi.org/10.1108/IMCS-12-2012-0072

[34] M. Fujita, M. Yamada, S. Arimura, Y. Ikeya, and M. Nishigaki, “An attempt to memorize strong passwords while playing games,” in Network-Based Information Systems (NBiS), 2015 18th International Conference on, September 2015.

[35] S. Schechter and J. Bonneau, “Learning assigned secrets for unlocking mobile devices,” in Eleventh Symposium On Usable Privacy and Security (SOUPS 2015). USENIX Association, July 2015. [Online]. Available: https://www.usenix.org/conference/soups2015/proceedings/presentation/schechter

[36] A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and D. Wagner, “Android permissions: User attention, comprehension, and behavior,” in Eighth Symposium on Usable Privacy and Security. ACM, 2012. [Online]. Available: http://cups.cs.cmu.edu/soups/2012/proceedings/a3_Felt.pdf

[37] P. G. Kelley, L. F. Cranor, and N. Sadeh, “Privacy as part of the app decision-making process,” in SIGCHI Conference on Human Factors in Computing Systems. ACM, 2013. [Online]. Available: http://patrickgagekelley.com/papers/android-decision.pdf

[38] C. S. Gates, J. Chen, N. Li, and R. W. Proctor, “Effective risk communication for Android apps,” IEEE Transactions on Dependable and Secure Computing, May 2014.

### VII. APPENDIX

#### A. Questions

**Employment**
- Could you tell me a little bit about what you do?
- Do you handle sensitive or private data as part of your job?
  - Could you tell me a little bit more about that data?

**Digital Security**

**Device Protection**
- How many devices do you use to access the internet for personal use?
  - Do you have a smartphone? Tablet? Multiple computers?
  - What type or brand of smartphone or computer (e.g., Windows/Mac/Linux) do you use?
- Can you show me how you access your devices?
  - When was the last time you changed this password?
- Are there any other tactics you use to protect your devices?
- Do you use antivirus software?
  - How often do you run the software?
  - Did you install it or did it come with your computer?
  - Why do you use it?
- Why do you use these strategies for protecting your [phone/computer/devices]? For each strategy, ask:
  - When did you start using this strategy?
  - How do you feel that this strategy works to protect [phone/computer/devices]?