### Section III: Automated Large-Scale ML Analysis of Privacy Policies

In this section, we present our automated large-scale machine learning (ML) analysis of privacy policies. We discuss the legal requirements for privacy notice and choice (§ III-A), evaluate the prevalence of privacy policies among apps (§ III-B), and analyze the content of these policies (§ III-C).

#### A. Privacy Notice and Choice

The privacy requirements analyzed in this study are derived from selected laws and app privacy policies. If a policy or app does not adhere to a specific privacy requirement, we define a potential privacy requirement inconsistency (also referred to as potential non-compliance). It is important to note that a potential inconsistency does not necessarily imply a legal violation. First, not all privacy requirements may be applicable to every app or policy. Second, our system is based on a particular interpretation of the law, which we believe is sound and consistent with the enforcement actions of the Federal Trade Commission (FTC) and other regulatory agencies. However, reasonable interpretations may vary. Third, our system relies on machine learning and static analysis, which can introduce errors.

Figure 1 provides an overview of the legal requirements for privacy notice and choice, and the nine specific privacy requirements our system analyzes:
- **Privacy Policy Requirement (PPR):** The app must have a privacy policy.
- **Notice of Policy Changes (NPC):** The policy must include notices about changes.
- **Notice of Access, Edit, and Deletion Rights (NAED):** The policy must inform users about their rights to access, edit, and delete their data.
- **Collection of Device IDs (CID):** The policy must disclose the collection of device identifiers.
- **Collection of Location Data (CL):** The policy must disclose the collection of location data.
- **Collection of Contact Information (CC):** The policy must disclose the collection of contact information.
- **Sharing of Device IDs (SID):** The policy must disclose the sharing of device identifiers.
- **Sharing of Location Data (SL):** The policy must disclose the sharing of location data.
- **Sharing of Contact Information (SC):** The policy must disclose the sharing of contact information.

##### Legal Basis for Privacy Policies

There is no federal statute mandating privacy policies for apps. However, California and Delaware have enacted comprehensive online privacy legislation that effectively sets a national minimum standard. The California Online Privacy Protection Act (CalOPPA) of 2003 and the Delaware Online Privacy and Protection Act (DOPPA) require online services that collect personally identifiable information (PII) to post a privacy policy. Additionally, the FTC's Fair Information Practice Principles (FTC FIPPs) call for consumers to be notified of an entity’s information practices before PII is collected. The Children’s Online Privacy Protection Act (COPPA) mandates privacy policies for apps directed at or known to be used by children.

##### Requirements for Policy Content

CalOPPA and DOPPA require privacy policies to describe the process for notifying users of policy changes. COPPA also requires the description of access, edit, and deletion rights, which are optional under the FTC FIPPs, CalOPPA, and DOPPA. Our analysis focuses on the disclosure of device IDs, location data, and contact information. App publishers must disclose the collection of device IDs (even when hashed) and location data, as required by CalOPPA and COPPA. Sharing these types of information with third parties also requires consent. We interpret ad identifiers as PII since they can track users over time and across devices. We assume that users have not opted out of ads, and that location data includes GPS, cell tower, and Wi-Fi locations.

Our analysis is based on the guidance provided by the FTC and the California Office of the Attorney General (Cal AG) in enforcement actions and best practice recommendations. We assume that all apps in the US Play store are subject to CalOPPA and DOPPA, as we are not aware of any US app publisher excluding California or Delaware residents or providing state-specific app versions.

#### B. Privacy Policy Requirement

To assess whether apps fulfill the requirement of having a privacy policy, we crawled the Google Play store and downloaded a sample of 17,991 free apps. We started with the most popular apps and followed random links to other apps, including all categories but excluding Google’s Designed for Families program and Android Wear. We confirmed the representativeness of our sample using a two-sample Kolmogorov-Smirnov goodness-of-fit test (p > 0.05).

##### Potential Privacy Policy Requirement Inconsistencies

Out of the 17,991 apps, 9,295 (52%) provided a link to their privacy policy from the Play store. Of the remaining 8,696 apps, 6,198 (71%) appear to lack a policy while engaging in data practices that would require one. We adjusted for apps that do not process PII (12% of the 8,696) and those that may have a policy elsewhere (17%). This leaves us with 71% of the 8,696 apps potentially non-compliant with the policy requirement.

We found that apps with recent updates and high install rates are more likely to have a privacy policy. Apps with low install rates, which are often newer, also tend to have policies. Apps with Editors’ Choice or Top Developer badges, in-app purchases, and content ratings for younger audiences typically have policies.

##### Predicting Potential Inconsistencies

We used Pearson’s Chi-square test to evaluate the hypothesis that apps with frequent updates are more likely to have a privacy policy. The test returned p ≤ 0.05, allowing us to reject the null hypothesis at the 95% confidence level. A linear regression model (Figure 3, top) shows that apps with recent update years have a higher likelihood of having a policy. A polynomial regression model (Figure 3, bottom) indicates that the number of installs is also a significant predictor, with both high and low install rates associated with a higher likelihood of having a policy.

#### C. Analysis of Policy Content

Table I summarizes the absolute numbers of annotations and various agreement measures for the nine privacy requirements. These measures, including absolute agreements, percentage agreements, Fleiss’ κ, and Krippendorff’s α, were computed on the full corpus of 115 policies.

| Practice | No. Ann | Agpol | % Agpol | Fleisspol/Krippol |
|----------|---------|-------|---------|-------------------|
| NPC      | 414     | 80/115 | 70%     | 0.59              |
| NAED     | 449     | 92/115 | 80%     | 0.72              |
| CID      | 326     | 85/115 | 74%     | 0.64              |
| CL       | 830     | 86/115 | 75%     | 0.50              |
| CC       | 90      | 101/115 | 88%    | 0.76              |
| SID      | 51      | 95/115 | 83%     | 0.48              |
| SL       | 276     | 85/115 | 74%     | 0.58              |

This table provides a detailed breakdown of the agreement measures for each privacy requirement, highlighting the consistency and reliability of our analysis.