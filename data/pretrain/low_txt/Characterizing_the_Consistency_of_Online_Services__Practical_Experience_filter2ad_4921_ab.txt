### 3.9 Distribution of Monotonic Reads Anomalies per Test
This section presents the distribution of monotonic reads anomalies observed in each test.

### 3.10 Distribution of Writes Follow Reads Anomalies per Test
This section details the distribution of writes follow reads anomalies observed in each test.

### 3.11 Percentage of Tests with Content Divergence Anomalies
This section provides the percentage of tests where content divergence anomalies were observed.

### 3.12 Percentage of Tests with Order Divergence Anomalies
This section presents the percentage of tests where order divergence anomalies were observed.

### 3.13 Cumulative Distribution of Content Divergence Windows
This section shows the cumulative distribution of content divergence windows across all tests.

### 3.14 Tests with Zero-Window Content Divergence Anomalies
This section lists the tests where a content divergence anomaly was observed, but the window size is zero.

### 3.15 Cumulative Distribution of Order Divergence Windows
This section presents the cumulative distribution of order divergence windows across all tests.

### 3.16 Tests with Zero-Window Order Divergence Anomalies in Google+
This section lists the tests where an order divergence anomaly was observed in Google+, but the window size is zero.

### 3.17 Tests with Unconverged Order Divergence Anomalies in Facebook Feed
This section lists the tests where an order divergence anomaly was observed in Facebook Feed, but convergence was not reached during the test.

### 4.1 Architecture Overview
This figure provides an overview of the system architecture.

### 4.2 Service Get Operation
This figure illustrates the service get operation, which returns N elements from the list.

### 4.3 Middleware Architecture
This figure presents the architecture of the middleware.

### 4.4 Combinations Anomaly
This figure illustrates the combinations anomaly.

### 4.5 Time Gap
This figure illustrates the time gap.

### 4.6 Middleware with Adapters
This figure shows the middleware architecture with adapters.

### 4.7 Latency of Get Operation in Facebook
This figure shows the latency of the get operation in Facebook.

### 4.8 Latency of Insert Operation in Facebook
This figure shows the latency of the insert operation in Facebook.

### 4.9 Communication Overhead in Facebook
This figure presents the communication overhead in Facebook.

### 4.10 Local Storage Overhead for Facebook
This figure shows the local storage overhead for Facebook.

### 4.11 Latency of Get Operation in Redis
This figure shows the latency of the get operation in Redis.

### 4.12 Latency of Insert Operation in Redis
This figure shows the latency of the insert operation in Redis.

### 4.13 Latency of Insert Operation in Redis in Ireland
This figure shows the latency of the insert operation in Redis in Ireland.

### 4.14 Communication Overhead in Redis
This figure presents the communication overhead in Redis.

### 4.15 Local Storage Overhead for Redis
This figure shows the local storage overhead for Redis.

---

### Introduction

Many computer systems and applications rely on stateful services running in the cloud, with various types of interfaces mediating access to these services. For example, an application might store its persistent state in a Cassandra cluster on Azure or use a cloud storage service like Amazon S3. At a higher level of abstraction, services such as Twitter and Facebook have not only attracted billions of users but also enabled numerous third-party applications by providing public APIs.

A significant challenge in building applications on top of cloud APIs (whether storage or application-specific) is that the consistency semantics of these services are often not clearly defined, leading to potential consistency anomalies [50]. This poses several challenges for developers, including understanding the impact of these semantics on their applications and modifying code to handle the lack of desired semantics, increasing development time and complexity.

In this work, we address this problem through a comprehensive approach that begins with a deep understanding of the semantics of online services and then proposes tools to improve those semantics, facilitating application development. Specifically, we first systematically analyze the consistency guarantees provided by the APIs of some popular Internet services. This is important for two reasons: it helps explain counterintuitive behavior and aids developers in anticipating the effects of using these services, allowing them to introduce additional logic if needed.

To understand the consistency levels of online service APIs, we conducted a measurement study of three popular platforms: Facebook, Google+, and Blogger. Our methodology involved identifying a set of anomalies not allowed by several consistency definitions, designing black box tests to probe for these anomalies, and conducting extensive experiments. We found a high prevalence of consistency anomalies in all services except Blogger. Google+ and Facebook Feed exhibited all considered anomalies, while Facebook Groups showed only a subset.

These results can be seen as a natural consequence of prioritizing performance over stronger consistency models. However, our study revealed that some anomalies, such as session guarantees, are not inevitable even under weak consistency. Given that some services do not provide session guarantees, the question arises of what provisions applications must make to handle this. Developers may need to enforce session guarantees at the application level, which can be challenging.

To address this, we propose a middleware layer that mediates access to cloud services, providing fine-grained control over consistency semantics. This middleware intercepts calls to the service, inserts metadata, and transforms results transparently. Prior work by Bailis et al. [16] proposed a similar approach but with limitations. Our middleware allows for fine-grained control over session guarantees and operates with services that offer a messaging interface, such as social networks.

We implemented our middleware and integrated it with the Facebook API and the Redis storage system, demonstrating that it allows for fine-grained consistency upgrades with modest latency overhead.

### 1.1 Contributions

The main contributions of this thesis are:
- A generic methodology to probe services and find consistency anomalies.
- A measurement study characterizing the consistency of online services.
- A set of algorithms to provide session guarantees.
- A transparent middleware to provide fine-grained consistency upgrades for online services.

### 1.2 Publications

The main contributions of this thesis were published in:
- "Characterizing the Consistency of Online Services (Practical Experience Report)." Filipe Freitas, João Leitão, Nuno Preguiça, and Rodrigo Rodrigues. Proceedings of the 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN2016).
- "Fine-Grained Consistency Upgrades for Online Services." Filipe Freitas, João Leitão, Nuno Preguiça, and Rodrigo Rodrigues. Proceedings of the 36th IEEE International Symposium on Reliable Distributed Systems (SRDS2017).

### 1.3 Document Organization

The remainder of the document is organized as follows:
- Chapter 2: Context and related work.
- Chapter 3: Results of the measurement study.
- Chapter 4: Evaluation of the middleware for fine-grained consistency.
- Chapter 5: Conclusions and future work.

---

### 2. Background and Related Work

#### 2.1 Online Services

Online services are distributed systems accessed globally via the Internet. These services are typically divided into three layers:
- **Data Layer:** Responsible for storing and retrieving data, using databases like SQLServer and MySQL or cloud storage services like Amazon S3.
- **Processing Layer:** Implements the service logic, composed of application servers that interact with internal or external services.
- **Interface Layer:** Provides an interface for clients to operate with the service, typically using HTTP to access Web APIs.

Geo-replication is used to ensure dependability and low latency, replicating data across multiple sites. While replication at the interface and processing layers is straightforward, replicating the data layer is complex due to the need for synchronization.

Geo-replication introduces a trade-off between performance and consistency. If strong consistency is chosen, performance may suffer, but if performance is prioritized, weaker consistency models are often used, leading to potential anomalies.