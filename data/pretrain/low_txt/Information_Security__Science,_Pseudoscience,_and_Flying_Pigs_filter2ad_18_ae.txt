### Procurement of a Secure Operating System from a Mortal Enemy

#### The Common Criteria and the Distinctions Between Pseudoscience and Science

The Common Criteria (CC) lacks an inherent mechanism for distinguishing between system and subsystem evaluations. This deficiency leaves procurers of secure systems vulnerable, as they must rely on an increasingly limited pool of computer security experts.

#### Advances in Cryptography

Despite this, significant advancements have been made in cryptographic subsystems, standards, and protocols. For example, the Data Encryption Standard (DES) has evolved into Triple DES, and the Advanced Cryptography Standard (ACS) shows considerable promise. However, while DES was once deemed adequate for protecting sensitive but unclassified information, there is a concerning lack of similar assurances for ACS.

Most troubling is that many cryptographic products are built on platforms with no reliable basis for ensuring their security mechanisms cannot be subverted. Today, there is much greater access to turnkey encryption systems compared to twenty years ago. Export restrictions have been relaxed, and the government is less likely to request manufacturers to withdraw products from the market. 

Almost two decades ago, a major chip vendor was encouraged to stop producing a high-quality key generator, leading one manufacturer to replace it with the manual rolling of eight-sided dice. Since then, the engineering of security products incorporating cryptography has become significantly easier. Conversely, the techniques for probing cryptographic solutions for weaknesses, such as power consumption analysis, have also advanced considerably.

Cryptography has become a popular field of study, with new algorithms subject to systematic review. This is beneficial because cryptography relies on relative strength assertions, such as "it is as difficult to break as factoring large numbers into primes." Standards like IPSEC and SSL have greatly enhanced the application of cryptography, making the engineering of Virtual Private Networks (VPNs) more robust and useful even in environments not requiring high assurance.

#### Major Weaknesses in Cryptographic Deployment

Despite these advances, current products are often built on platforms with weak security. The recent neglect of the science of computer and network security suggests this issue will not be resolved soon. As a result, cryptography has, in many cases, become what some refer to as the "opiate of the naive."

This is not a unique insight; others have noted similar issues. For instance, one long-term expert recently observed that while encryption codes may pose an intellectual challenge to hackers, they often opt for more realistic and achievable methods, such as attacking servers and PCs. Ironically, early PC chips were designed to provide higher security, but this capability was never fully realized.

In the early 1980s, Intel developed the 286 chip, which formed the core of GEMSOS, one of the most highly trusted computer systems used by the US Government.

#### Advances in the State of the Science

The period following the publication of the Common Criteria saw few significant advances in the state of the science of computer and network security. However, there were substantial improvements in available cryptographic tools, including:

- Widely Available Crypto Subsystems
- Digital Certificates and Public Key Infrastructure (PKI)
- IPSEC for VPNs

### Summary

The state of the science of information security is rich with solutions and tools accumulated over more than 30 years of research. However, the assimilation of this knowledge by information security practitioners and the understanding of existing science remain poor. The greatest achievement in the science of computer and network security is the ability to build and deploy truly bulletproof systems with verifiable protection, which remains the most powerful solution for many of today's hard problems.

The following list summarizes the key advances in the state of the science of computer and network security:

- Reference Monitor Concept
- A Simple Security Kernel
- Formal Security Policy Models
- Discretionary vs. Mandatory Access Control Policies
- Hardware Rings and Segmentation
- Application of Formal Methods
- Architectural Requirements for Evaluation (e.g., layering, least privilege, minimization)
- Covert Channel Reduction and Analysis
- Technically Sound Objective Evaluation Criteria
- Eventcounts for Secure Synchronization
- Partitioned Trusted Computing Base (TCB)
- TCB Subsets
- Rules for Layering Security Policies
- Rules for Composing Systems
- Balanced Assurance
- Cryptographic Checksum Guards
- Multilevel DBMS Data Model
- Secure Client via TCB Extension
- Widely Available Crypto Subsystems
- Digital Certificates and PKI
- IPSEC for VPNs

### Acknowledgement

The author is deeply grateful to Michael F. Thompson of Aesec Corporation for his invaluable research and review during the preparation of this essay.

### References

[1] Jelen, George F., *Information Security: An Elusive Goal*, Program on Information Resources Policy, Harvard University, Cambridge, MA, June 1985.
[2] Brinkley, D.L. and Schell, R.R., “Concepts and Terminology for Computer Security”, *Information Security*, M. Abrams, S. Jajodia, and H. Podell, eds., IEEE Computer Society Press, Los Alamitos, Calif., 1995.
[3] Jueneman, R.R., *Novell Certificate Extension Attributes—Novell Security Attributes, Tutorial and Detailed Design*, Document Version 0.998, Novell Inc., August 1998.
[4] *Department of Defense Trusted Computer Security Evaluation Criteria*, DOD 5200.28-STD, National Computer Security Center, December 1985.
[5] *Final Evaluation Report, Novell, Incorporated Netware 4.1.1 Server*, National Computer Security Center, June 1998.
[6] Schell, R.R. and Thompson, M.F., “Platform Security: What is Lacking?” *Information Security Technical Report*, Vol 5, No. 1, 2000, Elsevier Advanced Technology.
[7] Denning, D.E., “Cryptographic Checksums for Multilevel Database Security”. *Proc. 1984 Symp. on Security and Privacy*, IEEE Computer Society, 1984, pp. 52-61.
[8] *Trusted Network Interpretation of Trusted Computer System Evaluation Criteria*, NCSC-TG-005, National Computer Security Center Version 1, 31 July 1987.
[9] *Common Criteria for Information Technology Security Evaluation*, CCIB-98-026, ISO/IEC, May 1998.
[10] Carroll, Lewis, *Through the Looking Glass*, (1872), English writer, mathematician.
[11] Carroll, R.T., *The Skeptics Dictionary*, http://skepdic.com, 1994-2001.
[12] *Trust in Cyberspace*, National Academy Press, Washington, D.C. 1998, Fred B. Schneider, Editor.
[13] Schell, R.R., “Computer Security: the Achilles’ Heel of the Electronic Air Force”, *Air University Review*, Vol. 30:2, Jan.-Feb., 1979.
[14] Ware, W.H., ed., *Security Controls for Computer Systems: Report of Defense Science Board Task Force on Computer Security*, AD # A076617/0, Rand Corporation, Santa Monica, Calif., February 1970, reissued October 1979.
[15] Anderson, J.P., *Computer Security Technology Planning Study*. ESD-TR-73-51. Bedford, MA: USAF Electronics Systems Division. October 1972.
[16] Fraim, L.J., “SCOMP: A Solution to the Multilevel Security Problem,” *IEEE Computer*, July 1983.
[17] Whitmore, J.C. et al., “Design for Multics Security Enhancements,” *ESD-TR-74-176*, Honeywell Information Systems, 1974.
[18] Weissman, C., “Security Controls in the ADEPT-50 Time-Sharing System,” *Fall Joint Computer Conference*, 1969.
[19] Saltzer, J.H. and Schroeder, M.R., “The Protection of Information in Computer Systems,” *Proc. IEEE Vol. 63, No. 9*, September 1975.
[20] Denning, D.E., “A Lattice Model of Secure Information Flow.” *Communications of the ACM*, Vol 19. No 5, May 1976.
[21] Bell, D.E. and LaPadula, L.J., *Computer Security Model: Unified Exposition and Multics Interpretation*, ESD-TR-75-306. MITRE Corporation, Bedford, MA, June 1975.
[22] Biba, K.J., *Integrity Considerations for Secure Computer Systems*, ESD-TR-76-372, MITRE Corporation, Bedford, MA, April 1977.
[23] Shockley, W.R., “Implementing the Clark/Wilson Integrity Policy Using Current Technology,” *Proc. 11th National Computer Security Conference*, 1988.
[24] Ames, S.R. et al., “Security Kernel Design and Implementation: An Introduction,” *Computer, IEEE*, July 1983.
[25] Schroeder, M.D., Clark, D.D., and Saltzer, J.H., “The Multics Kernel Design Project,” *Proc. Sixth ACM Symposium on Operating System Principles*, November 1977.
[26] Parnas, D.L., “A Technique for Software Module Specification with Examples,” *Communications of the ACM*, Vol. 13, No. 5, May 1972.
[27] Reed, D.P., and Kanodia, R.K., “Synchronization with Eventcounts and Sequencers,” *Communications of the ACM*, Vol. 22, No. 2, February 1979.
[28] Millen, J.K., “Security Kernel Validation in Practice.” *Communications of the ACM*, Vol 19. No 5, May 1976.
[29] Feirtag, R.J. et al., “Proving Multilevel Security of a System Design, *Proc. Sixth ACM Symposium on Operating Systems Principles*, November 1977.
[30] Padlipsky, M.A., Snow, D.P., and Karger, P.A., *Limitations of End-to-End Encryption in Secure Computer Networks*, The MITRE Corporation, MTR-3592, Vol. I, May 1978 (ESD TR 78-158, DTIC AD A059221).
[31] *Final Evaluation Report, Gemini Network Processor, Version 1.01*, National Computer Security Center, pp 123-124, June 1995.
[32] Shockley, W.R. et al., “A Network of Trusted Systems.” *Proc. AIAA/ASIS/IEEE Third Aerospace Computer Security Conf.*, 1987.
[33] Fellows, J. et al., “The Architecture of a Distributed Trusted Computing Base.” *Proc. 10th National Computer Security Conference*, September 1987.
[34] Karger, P.A. et al., “A Retrospective of the VAX VMM Security Kernel,” *IEEE Transactions on Software Engineering*, Vol. 17, No. 11, Nov. 1991.
[35] Shockley, W.R. and Schell, R.R., “TCB Subsets for Incremental Evaluation,” *Proc. of the 3rd Aerospace Computer Security Conference*, American Institute of Aeronautics and Astronautics, Washington D.C., 1987.
[36] Weissman, C., “Blacker: Security for the DDN. Examples of A1 Security Engineering Trades.” *Proc. 1992 Symp. Research in Security and Privacy*, IEEE Computer Society, 1992, pp. 286-292.
[37] Lunt, T.F. et al., “The SeaView Security Model,” *IEEE Transaction on Software Engineering*, Vol. 16, No. 6, June 1990.
[38] *Trusted Database Management System Interpretation of the Trusted Computer System Evaluation Criteria*, NCSC-TG-021, National Computer Security Center, April 1991.
[39] Caelli, Bill, “Bring in E-Trading PIN Pads,” *The Australian* newspaper, Sydney, Australia, 24 October 2000.