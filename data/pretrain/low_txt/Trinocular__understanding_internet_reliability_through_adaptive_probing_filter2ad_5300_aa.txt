# Title: Trinocular: Understanding Internet Reliability Through Adaptive Probing

## Authors
- Lin Quan
- John S. Heidemann
- Yuri Pradkin

### Abstract
Natural and human factors cause Internet outages, ranging from large-scale events like Hurricane Sandy in 2012 and the Egyptian Internet shutdown in January 2011 to smaller, unpublicized daily outages. This paper introduces Trinocular, an outage detection system that uses active probing to understand the reliability of edge networks. Trinocular is principled, employing a simple model of the Internet that captures pertinent information for outages, populated through long-term data and current network state learned via ICMP probes. It is parsimonious, using Bayesian inference to determine the number of necessary probes. On average, each Trinocular instance sends fewer than 20 probes per hour to each /24 network block, increasing Internet "background radiation" by less than 0.7%. Trinocular is also predictable and precise, providing known precision in outage timing and duration. Probing in 11-minute rounds, it detects 100% of outages lasting one round or longer and estimates outage duration within one-half round. A single machine can track 3.4 million /24 IPv4 blocks, covering all currently analyzable parts of the Internet. Our approach is significantly more accurate than existing methods, with about one-third fewer false conclusions and 30% greater coverage at constant accuracy. We validate our approach using controlled experiments, analyze two days of Internet outages from three sites, and re-analyze three years of existing data to develop trends for the Internet.

### Categories and Subject Descriptors
- C.2.3 [Computer-Communication Networks]: Network Operations—Network Monitoring
- C.2.5 [Computer-Communication Networks]: Local and Wide-Area Networks—Internet
- C.4 [Performance of Systems]: Reliability, availability, and serviceability

### Keywords
- Internet reliability, network outages, Bayesian inference, adaptive probing

### Acknowledgments
This research is sponsored by the Department of Homeland Security (DHS) Science and Technology Directorate, HSARPA, Cyber Security Division, BAA 11-01-RIKA, and Air Force Research Laboratory, Information Directorate under agreement number FA8750-12-2-0344, and contract number D08PC75599. The U.S. Government is authorized to make reprints for governmental purposes notwithstanding any copyright. The views contained herein are those of the authors and do not necessarily represent those of DHS or the U.S. Government.

### Permissions
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

### Introduction
Although rare, network outages are a serious concern as users depend on connectivity, and operators strive for high levels of reliability. Replicated services and content delivery networks may conceal outages but not eliminate them, and the size of the Internet means outages are always occurring somewhere. Outages can be triggered by natural disasters, political upheavals, and human error. Prior work has generally focused on outages from the perspective of routing, monitoring routing, tracking routable prefixes, and studying traffic to unoccupied addresses. While these approaches are useful for detecting and mitigating large outages related to routing, most of the Internet uses default routing, and we show that most outages are smaller than routable prefixes. Some systems target specific kinds of smaller outages, but no service today actively tracks outages in all Internet edge networks.

The contribution of this paper is to address this gap, providing unbiased, accurate measurements of Internet reliability to all analyzable edge networks. First, we describe Trinocular, an adaptive probing system to detect outages in edge networks. Our system is principled, deriving a simple model of the Internet that captures the information pertinent to outages, parameterizing the model with long-term observations, and learning the current network state with probing driven by Bayesian inference.

Second, using experiments, analysis, and simulation, we validate that these principles result in a system that is predictable and precise: we detect 100% of outages longer than our periodic probing interval, with known precision in timing and duration. It is also parsimonious, requiring minimal probing traffic. On average, each Trinocular instance increases traffic to covered networks by no more than 0.7% of the Internet’s "background radiation." This low rate allows a single computer to monitor the entire analyzable Internet, and multiple concurrent instances to identify outage scope.

Finally, we use Trinocular to observe two days of Internet outages from three sites. We also adapt our model to re-analyze existing data, developing three years of trends from measurements of samples of the Internet. This re-analysis includes observations of outages due to Hurricane Sandy in 2012, the Japanese Earthquake in March 2012, and the Egyptian Revolution in January 2012.

### Problem Statement
Our goal is to provide a principled, predictable, precise, and parsimonious record of network outages at the Internet edge. By principled, we mean we build a simple model of network blocks and track their status through learning and active probes. Our simple model, while incomplete, is well-suited to track outages. We use multi-year network observations to inform our model, establishing the expected behavior of each block (a /24 network prefix). We use Bayesian inference to learn the status of each block and to decide how many probes to send to improve our belief when it is uncertain. We use periodic probes at fixed-interval, multi-minute rounds to detect network outages with a known degree of precision. We use adaptive probing at timescales of seconds to quickly resolve inconsistent information and distinguish transient or non-network behavior from outages at the target network. Our default measurements employ three years of quarterly observations, 11-minute rounds, and 3-second intervals for adaptive probes, although these values can be adapted to trade precision for traffic.

By predictable, we mean our conclusions about analyzable network blocks provide guaranteed precision and positive statements about block status. Our periodic probing bounds the precision of detecting block transitions, and we show that error in estimates of outage duration is uniformly distributed by one half round (±330 s). As with all active probing mechanisms, our approach cannot determine the status of networks that decline to participate, such as those that use firewalls that block probes, nor networks that are too sparse for our techniques. We find 3.4 million /24 blocks to be analyzable by our method, and we identify non-analyzable blocks. This coverage is 30% greater than current approaches, if one holds accuracy constant.

By parsimonious, we mean that we use a minimum number of probes required to establish our belief in edge network state. Long-term history informs our model, and Bayesian reasoning justifies each probe we make, avoiding unnecessary probes. Minimizing probing traffic is critical for a service that operates across the entire Internet. While money can solve the problem of outgoing network capacity at the prober, recipients of probing traffic are very sensitive. Even modest traffic can draw complaints (for which we maintain an opt-out list). We evaluate the impact of our traffic on target networks by comparing it to the amount of background radiation that all public networks observe. We show that at steady state, each Trinocular instance increases background traffic by less than 0.7%, allowing us to run multiple instances to understand outage scope.

Finally, our target is all edge networks. We are interested in edge networks because prior work has shown that many networks employ default routing, and outages occur inside ISPs. We show that probing all /24s detects many more outages than considering only ASes or routed prefixes. We combine data from three sites to study outage scope, separating outages adjacent to the prober from partial and global outages affecting some or all of the Internet. These four characteristics distinguish our work from prior work, which often employs ad hoc mechanisms, does not provide guarantees about outage precision, requires excessive probing, or monitors routable prefixes instead of considering smaller outages in edge networks. They also allow us to provide a unique view of Internet reliability, both as a whole and of specific events.

### Related Work
We next review prior outage studies by data source.

#### Control-plane Studies
Several prior efforts use control-plane data to study Internet outages. Markopoulou et al. use IS-IS update messages to categorize failure types in Sprint’s network. Unlike their work, our system uses only data-plane information. Omni runs servers in each Autonomous System (AS) and uses forwarding tables and traceroutes to diagnose routing changes. Their approach benefits from non-public routing information, but deployment is challenging. Our work uses centrally-collected measurement and analysis and is easier to deploy since it does not require peering.

Huang et al. combine data from multiple BGP feeds to detect "faint" outages. We also use data from multiple vantage points, but to distinguish between global and local outages; our mechanism can detect small and short events. BGP misconfiguration is one cause of outages. Mahajan et al. study routing messages and contact network operators about problems. They also use active probing to determine the effects of misconfiguration on connectivity. They report that 0.2% to 1% of prefixes have problems each day. We confirm their results on Internet reachability, finding about 0.6% of the Internet blocks are out, on average. In general, studies using or triggered by control-plane information are indirect and provide incomplete coverage of all outage types, as discussed by Bush et al. We further verify this result experimentally.

#### Data-plane Studies
Several efforts use data-plane probes to detect outages and are close to our work. First, NetDiagnoser and Cunha et al. explore binary tomography to identify routing problems. Their work identifies efficient ways to localize problems with minimal traffic. We also focus on minimizing traffic, but our goal is continuous monitoring of all edge networks, not diagnosing problems in specific ASes.

Second, Hubble finds potential Internet outages by surveying all .1 addresses in each routed prefix and selecting one for regular probes, which trigger traceroutes to confirm and localize a potential outage. We instead regularly probe many selected addresses in each /24 block. Our examination of multiple addresses and /24 blocks detects outages missed by routing and single-address triggering. IPlane captures information about network performance, aggregating information by routable prefixes. We show that it is possible and beneficial to maintain outage information at the granularity of /24 blocks. Our work could be extended with Hubble-like traceroutes to localize outages.

Building on Hubble and iPlane, LIFEGUARD extends this approach to detect and work around local outages caused by routing. Our work's focus on edge networks complements LIFEGUARD's on partial failures in the routing system and the network core. LIFEGUARD detects outages for routable prefixes because that coarser granularity is relevant to re-routing to recover. We instead focus on finer granularity to understand smaller, edge networks, and do not attempt recovery because edge networks are not usually multi-homed.

Schulman and Spring target ICMP probing to study using weather reports. They probe many individual addresses in areas with severe weather from around ten vantage points and report outages for individual addresses. Like their work, we are interested in edge networks, but we track blocks, not individual addresses, and we track all that are analyzable, not just those in regions under severe weather. We consider blocks out of concern that tracking single addresses risks confounding outages with human activity (such as suspending a laptop); but a more complete comparison is future work.

In prior work, we took censuses of all IPv4 using ICMP, establishing what coverage is possible with active probing. That coverage is an upper bound on our coverage of outage detection. We re-analyze datasets from this work for longitudinal analysis and it inspires our new adaptive probing scheme. In later work, we explored using this data to identify outages and to visualize both outages and BGP changes. This outage work is only preliminary and uses methods that require many more probes than Trinocular, and typically underestimate outage duration by 1.5 rounds. We instead use Bayesian analysis to make informed decisions with far less network traffic and to improve the precision of outage detection to within a half-round.

Finally, Bush et al. study the reachability of Internet address space using traceroute to detect incorrect filtering and to find biases in reachability experiments. We provide additional evidence supporting their observation that default routes are widely used and that control-plane measurements underestimate outages.

#### Client-supported Analysis
Client-side observations provide a wider perspective than centralized methods. Several groups have used meshes of measurement computers. Such experiments can provide strong results for the behavior of the networks between their n vantage points (typically less than 50), and for small n link coverage grows as O(n^2), although edge coverage is only O(n). Without probing outside the mesh, however, these approaches ultimately study only a small fraction of the entire Internet. Other methods of active probing, and our work, aim to provide complete coverage.

In early work, Paxson reports routing failures in about