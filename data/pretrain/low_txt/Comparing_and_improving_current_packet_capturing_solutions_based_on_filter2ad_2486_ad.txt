### Packet Capture Rate Optimization

We implemented this modification into `libpcap` using the PF_PACKET interface. Selecting an appropriate sleep interval proved challenging, as a long sleep duration can lead to buffer overflow, while a short interval results in excessive system calls, failing to address the problem. The optimal sleep interval is highly dependent on the hardware, the type of analysis, and the observed traffic. Consequently, users must experiment to find a suitable value, which can be quite laborious. Deri’s user space code, which uses PF_RING, does not implement his proposed adaptive sleep, likely due to similar challenges. Instead, it avoids `poll()` by using `sched_yield()`, which interrupts the application and allows the scheduler to run another process. A call to `poll()` is only made if multiple `sched_yield()` calls have been made without any packets arriving. Figure 11 illustrates that the algorithm used by PF_RING outperforms the simple `poll()` with PF_PACKET, though frequent `sched_yield()` calls can have negative effects.

### Proposed Solution

We propose a new solution that eliminates the need to estimate a timeout and performs better than `sched_yield()`. Our approach involves modifying the packet arrival signaling within `poll()`. Currently, PF_PACKET signals the arrival of every packet to the user space. We recommend signaling packet arrival only under the following conditions:
- N packets are ready for consumption.
- A timeout of m microseconds has elapsed.

This reduces the number of `poll()` system calls significantly. The timeout is only necessary when fewer than N packets arrive within m microseconds, such as during low incoming packet rates. Unlike the sleep timeout, choosing an appropriate m value is not critical for achieving good capturing performance.

### Performance Evaluation

We implemented all solutions into PF_PACKET and `libpcap` and compared their performance. For the sleep solutions, we determined a good timeout value through manual experiments. The results, summarized in Figure 12, show a significant performance boost from reducing the number of system calls. Both the timeout and our proposed modification to PF_PACKET yield similar performance improvements. Combining both methods does not result in further significant gains. Although we did not have time to include and evaluate these measurements with PF_RING, we are confident that PF_RING would also benefit from our proposed modification.

### Driver Improvements

In previous experiments, we were unable to process small packets at wire-speed, even with our earlier improvements. We now focus on driver-level enhancements to improve capturing performance.

Deri proposed using modified drivers to enhance capturing performance [5]. His modifications include:
- Creating a dedicated thread for packet consumption in the driver (for each RX queue of the card).
- Reusing DMA memory pages instead of allocating new pages for the card.

These modifications help leverage multi-core CPUs by spawning a kernel thread to handle the card, ensuring that no other thread is scheduled for driver tasks and that there is always a free thread to handle packets. Additionally, if interrupts are bound to a specific core, the driver thread will run on the same core. It is unclear which of these modifications provides the greatest performance boost, but they are particularly useful for multi-core or multi-CPU systems.

### Signaling and Integration

Signaling between different subsystems, especially those driven by separate threads, should be done for accumulated packets. This applies to all subsystems, from the driver to the user space applications. We recommend integrating our modifications to PF_PACKET into Linux. Other areas, such as generic system calls that allow waiting for one or more sockets until N elements can be read or a timeout occurs, could also benefit from our modifications.

### Recommendations for Users

Configuring a capture system for optimal performance remains a challenging task. Proper hardware selection is crucial for high-speed network traffic. The software driving the hardware is equally important, as it significantly influences capturing performance. Our findings indicate that all parts of the software stack have a significant impact, and users must check each part to debug performance issues.

Performance problems can start at the network card drivers, particularly if interrupt handling is suboptimal. Checking for a high number of interrupts should be one of the first steps in performance debugging. Enabling polling on the driver may help, but we found that the POLLING option, a static compile-time option for many drivers, did not improve performance in our tests.

We recommend using PF_RING with TNAPI for superior performance over the standard capturing stacks of FreeBSD or Linux. If TNAPI or PF_RING is not an option, our modifications to PF_PACKET in Linux are recommended. Pinning involved threads and processes to different cores is highly recommended in most cases. Using the default scheduler is only advisable for low packet rates and low application layer load.

### Conclusions

This paper compares different capturing solutions on Linux and FreeBSD, including some proposed improvements. Our evaluation shows that FreeBSD still outperforms standard Linux PF_PACKET under low application load, especially with multiple capturing processes. However, the performance gap between PF_PACKET and PF_RING has narrowed since 2004 and 2006. We identified a performance bottleneck in standard Linux PF_PACKET and proposed a fix that significantly improves its performance with small packets. Using our improvements, PF_PACKET nearly matches PF_RING's performance.

Finally, we evaluated Luca Deri’s TNAPI driver extension for Linux and found increased performance with all Linux capturing solutions. The best performance is achieved when TNAPI is combined with PF_RING.

### Acknowledgements

We gratefully acknowledge support from the German Research Foundation (DFG) for the LUPUS project and additional funding from ResumeNet, an EU FP7 project within the FIRE initiative. We thank Luca Deri and Gerhard Münz for their valuable support.

### References

[1] Endace Measurement Systems, <http://www.endace.com/>.

[2] F. Schneider and J. Wallerich, "Performance evaluation of packet capturing systems for high-speed networks," in CoNEXT'05: Proceedings of the 2005 ACM conference on Emerging network experiment and technology. New York, NY, USA: ACM Press, Oct. 2005, pp. 284–285.

[3] L. Deri, "ncap: Wire-speed packet capture and transmission," in In Proceedings of the IEEE/IFIP Workshop on End-to-End Monitoring Techniques and Services (E2EMON), May 2005.

[4] F. Schneider, J. Wallerich, and A. Feldmann, "Packet capture in 10-gigabit ethernet environments using contemporary commodity hardware," in In Proceedings of the 8th International Conference on Passive and Active Network Measurement, Apr. 2007.

[5] L. Deri and F. Fusco, "Exploiting commodity multi-core systems for network traffic analysis," <http://luca.ntop.org/MulticorePacketCapture.pdf>, July 2009.

[6] G. A. Cascallana and E. M. Lizarrondo, "Collecting packet traces at high speed," in Proc. of Workshop on Monitoring, Attack Detection and Mitigation (MonAM) 2006, Tübingen, Germany, Sep. 2006.

[7] J. Mogul and K. K. Ramakrishnan, "Eliminating receive livelock in an interrupt-driven kernel," ACM Transactions on Computer Systems, vol. 15, no. 3, pp. 217–252, 1997.

[8] L. Deri, "Improving passive packet capture: Beyond device polling," in In Proceedings of the Fourth International System Administration and Network Engineering Conference (SANE 2004), Sep. 2004.

[9] Intel Corporation, "An Introduction to the Intel QuickPath Interconnect," <http://www.intel.com/technology/quickpath-introduction.pdf>, 2009.

[10] I. Kim, J. Moon, and H. Y. Yeom, "Timer-based interrupt mitigation for high performance packet processing," in 5th International Conference on High-Performance Computing in the Asia-Pacific Region, 2001.

[11] Luigi Rizzo, "Device Polling Support for FreeBSD," in BSDCon Europe Conference 2001, 2001.

[12] V. Jacobson, C. Leres, and S. McCanne, "libpcap," <http://www.tcpdump.org>.

[13] Phil Woods, "libpcap MMAP mode on linux," <http://public.lanl.gov/cpw/>.

[14] R. Olsson, "pktgen the linux packet generator."

[15] tcpdump, <http://www.tcpdump.org>.

[16] S. Kornexl, V. Paxson, H. Dreger, A. Feldmann, and R. Sommer, "Building a Time Machine for Efficient Recording and Retrieval of High-Volume Network Traffic," in Proc. of ACM SIGCOMM Internet Measurement Conference (IMC) 2005, Berkeley, CA, USA, Oct. 2005.

[17] G. Maier, R. Sommer, H. Dreger, A. Feldmann, V. Paxson, and F. Schneider, "Enriching Network Security Analysis with Time Travel," in Proc. of ACM SIGCOMM 2008 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication, Seattle, WA, USA, Aug. 2008.

[18] R. T. Lampert, C. Sommer, G. Münz, and F. Dressler, "Vermont - A Versatile Monitoring Toolkit for IPFIX and PSAMP," in Proceedings of Workshop on Monitoring, Attack Detection and Mitigation (MonAM) 2006, Tuebingen, Germany, Sep. 2006.

[19] Homepage of the zlib project, <http://www.zlib.net/>.

[20] C. Satten, "Lossless gigabit remote packet capture with linux," <http://staff.washington.edu/corey/gulp/>, University of Washington Network Systems, Mar. 2008.