### 6. Remediation and Limitations

Facebook has implemented several mechanisms to counter casual attackers and the practices discussed in this paper. However, these mechanisms have limitations and are not entirely effective. In this section, we will examine these mechanisms, their drawbacks, and propose modifications to Social Authentication (SA) to enhance its security based on our experimental insights.

#### 6.1 Compromise Prevention and Notification

Facebook has recently introduced several security features aimed at preventing account compromises due to stolen credentials. These features include:

- **Trusted Devices:** Users can add certain devices to a list of recognized, trusted devices. When a login attempt is made from an unrecognized device, a security token is sent to the user's mobile phone. This token must be entered to complete the login process. This feature, known as "login approval," follows a traditional second-factor authentication scheme and is only effective when used in conjunction with the trusted devices feature. While this approach can effectively deter our attack by implementing strong two-factor authentication, it requires physical access to the user's mobile phone.

- **Login Alerts:** If a user fails to complete an SA challenge, they are redirected to an alert page upon the next successful login. This page reports the attempted login and provides time and place information. Unfortunately, if the adversary successfully completes the SA test on a subsequent attempt, the account owner will never see the alert. Additionally, users can enable an optional login-notification feature, which sends an alert message via text or email whenever the account is accessed. However, this feature does not prevent the adversary from logging in and is ineffective against our attack, which takes less than one minute. Moreover, if the adversary has compromised the user's email account (a realistic scenario given the prevalence of credential reuse), they can delete the notification email. If the email is not compromised, the adversary will still have access until the owner changes the password and terminates any active sessions.

These mechanisms also present additional drawbacks:
- **Mobile Phone Requirement:** Users must link their mobile phone number to their Facebook account, which many may be reluctant to do.
- **Multiple Devices:** Users often access their accounts from multiple devices, including public ones (e.g., library computers). Adding all these devices to the trusted list is impractical and insecure, and users may not want to receive alerts for every login.
- **Cost Implications:** Involving the cellular network for sending security tokens may result in monetary charges, which could discourage users from opting into the mechanism.

#### 6.2 Slowing Down the Attacker

When prompted with an SA challenge, the attacker must first solve a CAPTCHA before proceeding to the actual SA test. Although solving a CAPTCHA is generally trivial for humans and can be automated, it serves as a minor technical obstacle to automated attacks. Previous research [4, 5, 7] has shown that breaking CAPTCHAs is feasible and, in many cases, easy. Adversaries can also perform laundry attacks [2, 13] and crowdsource CAPTCHA solutions. Therefore, while CAPTCHAs may slow down automated attacks, they should not be considered a definitive countermeasure.

The presence of suggested names in SA tests is a significant disadvantage, as it limits the search space for adversaries. Removing suggestions would increase the likelihood of face-recognition software returning multiple users with similar confidence scores. This change might also increase the time required for face recognition, although cloud-based systems are unlikely to be severely affected. On the downside, it would make it harder for users to identify their friends, reducing the usability of the system. Automatic "type ahead" features could mitigate this issue but are still vulnerable to exhaustive enumeration.

#### 6.3 Revisiting Social Authentication

Designing effective and usable CAPTCHAs [6] is as challenging as designing effective and usable social-based authentication schemes [17]. The main weakness of social-based authentication schemes is that the knowledge needed to solve them is often too public. Social networks and human nature are inherently about sharing knowledge, which makes these schemes vulnerable.

To enhance the security of SA tests, Facebook could use photos that fail or achieve very low confidence scores in its own face recognition system. These photos might show people wearing glasses, masks, or slightly turned away from the camera. Humans can recognize their friends based on contextual cues, while face-recognition algorithms struggle with such variations. Facebook can leverage user-uploaded photos to create a labeled dataset for generating SA tests. Even if an adversary captures a photo and the associated tag, their face recognition algorithm is likely to fail to find a match with other photos of the same person. Additionally, if the adversary attempts to train their algorithm with this data, it may introduce noise, reducing the overall accuracy of the classifier.

### 7. Related Work

Previous research has shown that information available in users' social network profiles can be used to break authentication mechanisms or deduce private information. For example, Rabkin [21] assessed the security properties of personal knowledge questions used for fallback authentication, arguing that their security is diminishing in the era of online social networks and the widespread availability of personal information. Polakis et al. [20] demonstrated how names extracted from Online Social Networks (OSNs) can be used to harvest email addresses for personalized phishing campaigns. Balduzzi et al. [3] focused on using search utilities in OSNs as an oracle to map email addresses to social profiles.

The work most closely related to this paper is a study by Kim et al. [17], which quantified the advantage an attacker has against SA tests when they are already within the victim's social circle. They showed that SA is ineffective against close friends, family, and highly connected sub-networks like universities. Our paper extends this threat model to include attackers outside the victim's social circle and demonstrates the feasibility of large-scale automated attacks using publicly available information. We also present a theoretical estimation of the attack surface based on empirical data from our experiments and previous studies.

Boshmaf et al. [5] explored the feasibility of socialbots infiltrating social networks and operated a Socialbot Network in Facebook for eight weeks. Their findings complement our attack, as determined attackers can use socialbots to infiltrate victims' social circles and gain access to private photos, increasing the success rate of SA tests. Gao et al. [12] found that 97% of malicious accounts were compromised accounts of legitimate users, highlighting the importance of social authentication in preventing account takeovers using stolen credentials. Our results validate the effectiveness of our attack even when using only publicly available information.

### 8. Conclusions

In this paper, we highlighted the security weaknesses of using social authentication as part of a two-factor authentication scheme, focusing on Facebook's implementation. We found that if an attacker acquires the first factor (password), they can access, on average, 42% of the data used to generate the second factor, enabling them to identify randomly selected photos of the victim's friends. Using this information, we managed to solve 22% of real Facebook SA tests and gained a significant advantage in an additional 56% of the tests. We designed an automated system to demonstrate the feasibility of large-scale attacks against social authentication with minimal effort. Our experimental evaluation showed that widely available face recognition software and services can be effectively utilized to break social authentication tests with high accuracy. We argue that Facebook should reconsider its threat model and re-evaluate the security measures taken against it.

### Acknowledgements

We thank the anonymous reviewers for their valuable comments and Alessandro Frossi for his support. This paper was supported in part by the FP7 project SysSec funded by the EU Commission under grant agreement no 257007, the Marie Curie Reintegration Grant project PASS, the ForToo Project of the Directorate General Home Affairs, and ONR MURI N00014-07-1-0907. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of ONR or the US Government.

### 9. References

[1] A. Acquisti, R. Gross, and F. Stutzman. Faces of Facebook: How the largest real ID database in the world came to be. BlackHat USA, 2011, http://www.heinz.cmu.edu/~acquisti/face-recognition-study-FAQ/acquisti-faces-BLACKHAT-draft.pdf.

[2] E. Athanasopoulos and S. Antonatos. Enhanced CAPTCHAs: Using animation to tell humans and computers apart. In Proceedings of the 10th IFIP Open Conference on Communications and Multimedia Security. Springer, 2006.

[3] M. Balduzzi, C. Platzer, T. Holz, E. Kirda, D. Balzarotti, and C. Kruegel. Abusing social networks for automated user profiling. In Proceedings of the 13th International Conference on Recent Advances in Intrusion Detection. Springer, 2010.

[4] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda. All your contacts are belong to us: Automated identity theft attacks on social networks. In Proceedings of the 18th International Conference on World Wide Web. ACM, 2009.

[5] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu. The socialbot network: When bots socialize for fame and money. In Proceedings of the Annual Computer Security Applications Conference. ACM, 2011.

[6] E. Bursztein, S. Bethard, C. Fabry, J. C. Mitchell, and D. Jurafsky. How good are humans at solving CAPTCHAs? A large scale evaluation. In Proceedings of the 2010 IEEE Symposium on Security and Privacy. IEEE, 2010.

[7] E. Bursztein, M. Martin, and J. C. Mitchell. Text-based CAPTCHA strengths and weaknesses. In Proceedings of the 18th ACM Conference on Computer and Communications Security. ACM, 2011.

[8] M. Dantone, L. Bossard, T. Quack, and L. V. Gool. Augmented faces. In Proceedings of the 13th IEEE International Workshop on Mobile Vision. IEEE, 2011.

[9] R. Dey, Z. Jelveh, and K. Ross. Facebook users have become much more private: A large-scale study. In Proceedings of the 4th IEEE International Workshop on Security and Social Networking. IEEE, 2012.

[10] R. Dhamija, J. D. Tygar, and M. Hearst. Why phishing works. In Proceedings of the SIGCHI conference on Human Factors in computing systems. ACM, 2006.

[11] R. Dunbar. Grooming, Gossip, and the Evolution of Language. Harvard University Press, 1998.

[12] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao. Detecting and characterizing social spam campaigns. In Proceedings of the 10th Annual Conference on Internet Measurement. ACM, 2010.

[13] C. Herley. The plight of the targeted attacker in a world of scale. In Proceedings of the Ninth Workshop on the Economics of Information Security, 2010.

[14] D. Irani, M. Balduzzi, D. Balzarotti, E. Kirda, and C. Pu. Reverse social engineering attacks in online social networks. In Proceedings of the 8th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment. Springer, 2011.

[15] D. Jacoby. Facebook Security Phishing Attack In The Wild. Retrieved on January 2012 from http://www.securelist.com/en/blog/208193325/Facebook_Security_Phishing_Attack_In_The_Wild.

[16] M. Jakobsson and J. Ratkiewicz. Designing ethical phishing experiments: A study of (ROT13) rOnl query features. In Proceedings of the 15th International Conference on World Wide Web. ACM, 2006.

[17] H. Kim, J. Tang, and R. Anderson. Social authentication: Harder than it looks. In Proceedings of the 2012 Cryptography and Data Security conference. Springer, 2012.

[18] M. Madejski, M. Johnson, and S. M. Bellovin. A study of privacy settings errors in an online social network. In Proceedings of the 4th IEEE International Workshop on Security and Social Networking. IEEE, 2012.

[19] F. Nagle and L. Singh. Can friends be trusted? Exploring privacy in online social networks. In Proceedings of the 2009 International Conference on Advances in Social Network Analysis and Mining. IEEE, 2009.

[20] I. Polakis, G. Kontaxis, S. Antonatos, E. Gessiou, T. Petsas, and E. P. Markatos. Using social networks to harvest email addresses. In Proceedings of the 9th Annual ACM Workshop on Privacy in the Electronic Society. ACM, 2010.

[21] A. Rabkin. Personal knowledge questions for fallback authentication: Security questions in the era of Facebook. In Proceedings of the 4th Symposium on Usable Privacy and Security. ACM, 2008.

[22] A. Shulman. The underground credentials market. Computer Fraud & Security, (3), 2010.

[23] J. Staddon and A. Swerdlow. Public vs. publicized: Content use trends and privacy expectations. In Proceedings of the 6th USENIX Conference on Hot Topics in Security. USENIX, 2011.

[24] B. E. Ur and V. Ganapathy. Evaluating attack amplification in online social networks. In Proceedings of the 2009 Web 2.0 Security and Privacy Workshop.