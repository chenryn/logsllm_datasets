### Rendering Engine and Cookie Access

The Alloy analyzer identified a violation of assertion 2 in the model with state isolation without entry-point restriction. This violation is similar to one found in the model that includes both mechanisms. In the following paragraphs, we will discuss both findings together.

### Model Analysis with Both Mechanisms

When analyzing the model with both state isolation and entry-point restriction, the Alloy analyzer did not find any violations of assertion 1 but did identify a violation of assertion 2. This violation occurred because our initial implementation did not consider the app container as part of the "same-origin" policy when applied to entry-point restriction. Figure 3 illustrates this violation, as well as the violation found for state isolation without entry-point restriction. The scenario is as follows:

1. **Alice's Session**: Alice opens a session with `bank.com` using a dedicated app renderer and receives her credentials.
2. **Attacker's Script**: Alice also visits `attack.com` using the browser's ordinary renderer, which allows `attack.com` to inject a script that compromises the ordinary renderer.
3. **Script Context Creation**: The attacker creates a `bank.com` script context within the compromised ordinary renderer.
4. **New Window Request**: The attacker then causes the `bank.com` script context to open a new window with a top-level URL pointing to an exploitable non-entry URL within the `bank.com` app.
5. **App Renderer Opening**: This new window opens in the app renderer because its initial URL is within the app. The request for the non-entry URL passes the entry point checks because the script context that initiated the request is considered "same-origin" (owned by `bank.com`).
6. **Success of Attack**: Similarly, the request would also be sent if entry-point restriction were absent, leading to the success of the attack.

### Implications for App Containers

This vulnerability highlights two key points regarding app containers:
1. **Necessity of Both Mechanisms**: Both entry-point restriction and state isolation are necessary to protect against rendering engine attacks.
2. **Extended Same-Origin Policy**: The same-origin policy must be extended to include app containers. Effectively, app containers divide a previously atomic origin into two new origins: one inside and one outside the container. As shown in Figure 4, the entry-point restriction policy should have rejected the last request in our scenario because its source was outside the app container and its target was inside.

We implemented this updated notion of "same-origin" in our model and verified that both assertions were upheld, up to the finite sizes we tested, including up to 10 NetworkEvents.

### Complexity of Adoption

**Entry-Point Restriction** requires websites to identify all URLs they wish to make public to other websites. Highly socially integrated sites like Facebook or content-oriented sites like the New York Times will face significant challenges due to the complexity of capturing all possible entry points. Conversely, non-social web sites such as online banking applications may find it easier to identify valid entry points, making it practical to deploy entry-point restriction.

To gain additional insight, we used the Mozilla Test Pilot platform, which is a Firefox extension installed on more than 3 million active Firefox browsers. Our evaluation involved 10,551 browsers over a period of 3 days. We simulated entry-point restriction for 9 popular websites, including email and web applications, online banking pages, news and social networks, and Chrome Web Store applications.

For each site, we gathered URL hashes of all incoming links to the site from all pages visited by Test Pilot Browsers. Our results confirmed that websites encouraging content sharing (e.g., New York Times, Facebook, Last.fm) will struggle with entry-point restriction, while others (e.g., Wells Fargo, Capital One, Flixster) can opt in with relatively few entry points. For some sites like Gmail and Bank of America, full compatibility is less clear, as 10 entry points cover up to 95% of incoming links, but fully covering all links remains challenging.

### Challenges for Subdomains

Web applications with multiple subdomains face an interesting challenge. If some subdomains are more amenable to app isolation than others, it can be difficult to isolate them. For example, a bank might have login-guarded functionality on one subdomain and a separate credit cards subdomain with many entry points. If the credit cards subdomain can recognize logged-in users, isolating the two subdomains becomes complex. Such apps may either face difficulties adopting app isolation or be forced to specify less precise entry points.

### Report-Only Mode

To assist website owners in identifying valid entry points and determining the suitability of app isolation, we propose a report-only mode similar to Content Security Policy. Instead of enforcing policy violations, this mode sends violation reports to the app's server, helping to generate a suitable policy file that avoids false positives.

### Performance Evaluation

#### Navigation Latency
In an entry-point restriction-enabled browser, every web resource load for an app is preceded by an entry-point check. This check determines whether the URL matches known entry points. Using a hash table, this lookup can be made efficient, imposing negligible cost on navigation latency. We measured the load times of the Alexa Top 100 Websites with and without entry-point restriction. For a high list of 10,000 entry points, the overhead from hash table lookups was minimal (less than 0.1 ms per page load).

#### Storage and Memory Overhead
Policy files must be fetched only once at app installation time, so we do not include this in the performance overhead.

### State Isolation Impact
To evaluate the impact of state isolation, we measured the disk and memory space required for visiting 12 popular sites in their own tabs, similar to those in Figure 4. Chromium stores user state in a configurable profile directory, so we compared three conditions: all sites in a single profile, all as isolated apps, and each in a separate profile. For sites not requiring HTTPS, we used pre-recorded network data to reduce variability. For Gmail, Bank of America, and Chase Bank, we logged into an account. We report the average of three trials.

- **Single Profile**: 19 MB of disk space.
- **Isolated Apps**: 86 MB.
- **Multiple Browsers**: 117 MB.

Each profile includes a partial download of Chromium’s Safe Browsing database (2.6 MB), contributing to the overhead for each additional browser profile. We found that isolated apps required over four times the space of a single profile due to aggressive disk space allocation for each cache. This behavior could be modified to be less aggressive for isolated apps. Users could also opt for an in-memory cache, reducing the disk space to 9.6 MB.

- **Resident Memory**: 
  - Single profile: 729 MB.
  - Isolated apps: 730 MB.
  - Separate browsers: 1.83 GB.

These results show that using isolated apps rather than multiple browsers can reduce the performance trade-off while maintaining security benefits.

### Conclusion
We have demonstrated that a single browser can achieve the security benefits of using multiple browsers by implementing entry-point restriction and state isolation to isolate sensitive apps. These mechanisms are particularly effective for high-value web sites, such as online banks, helping to protect themselves and their users from a broad spectrum of attacks with minimal effort.

### Acknowledgements
We thank John Mitchell for his helpful suggestions and feedback. We also thank David Chan, Sid Stamm, Jono Xia, Jinghua Zhang, and the entire Mozilla Test Pilot team for allowing us to use the Mozilla Test Pilot platform. This work was supported by a Google Focused Research Award on the security of cloud and web clients.

### References
[1] R. Cook, “The Next Big Browser Exploit,” CSO Magazine, p. 15, Feb 2008.
[2] E. Iverson, “Two Web Browsers can be More Secure than One.”
http://www.blueridgenetworks.com/securitynowblog/dual-web-browsers-can-avoid-information-disclosures
[3] D. Jang, R. Jhala, S. Lerner, and H. Shacham, “An empirical study of privacy-violating information flows in JavaScript web applications,” in Proceedings of the 17th ACM Conference on Computer and Communications Security. ACM, 2010, pp. 270–283.
[4] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell, “Protecting browser state from web privacy attacks,” in Proceedings of the 15th International Conference on World Wide Web, ser. WWW ’06. New York, NY, USA: ACM, 2006, pp. 737–744. [Online]. Available: http://doi.acm.org/10.1145/1135777.1135884
[5] E. Felten and M. Schneider, “Timing attacks on web privacy,” in Proceedings of the 7th ACM Conference on Computer and Communications Security. ACM, 2000, pp. 25–32.
[6] A. Barth, C. Jackson, and C. Reis, “The Security Architecture of the Chromium Browser,” 2008 Technical Report.
[7] Mozilla Foundation Security Advisory 2009-29, “Arbitrary code execution using event listeners.” http://www.mozilla.org/security/announce/2009/mfsa2009-29.html
[8] Mozilla, “Test Pilot,” https://testpilot.mozillalabs.com/.
[9] D. Akhawe, A. Barth, P. E. Lam, J. Mitchell, and D. Song, “Towards a Formal Foundation of Web Security,” Computer Security Foundations Symposium, Proceedings of, IEEE, vol. 0, pp. 290–304, 2010.
[10] Mozilla, “Prism,” http://prism.mozillalabs.com/.
[11] T. Ditchendorf, “Fluid,” http://fluidapp.com/.
[12] M. Silbey and P. Brundrett, “Understanding and working in Protected Mode Internet Explorer,” 2006, http://msdn.microsoft.com/en-us/library/bb250462.aspx.
[13] C. Grier, S. Tang, and S. T. King, “Secure Web Browsing with the OP Web Browser,” in IEEE Symposium on Security and Privacy, 2008, pp. 402–416.
[14] H. J. Wang, C. Grier, A. Moshchuk, S. T. King, P. Choudhury, and H. Venter, “The Multi-Principal OS Construction of the Gazelle Web Browser,” in USENIX Security Symposium, 2009, pp. 417–432.
[15] L.-S. Huang, Z. Weinberg, C. Evans, and C. Jackson, “Protecting Browsers from Cross-Origin CSS Attacks,” in ACM Conference on Computer and Communications Security, 2010.
[16] R. S. Cox, S. D. Gribble, H. M. Levy, and J. G. Hansen, “A Safety-Oriented Platform for Web Applications,” in IEEE Symposium on Security and Privacy, 2006, pp. 350–364.
[17] S. Crites, F. Hsu, and H. Chen, “OMash: enabling secure web mashups via object abstractions,” in ACM Conference on Computer and Communications Security, 2008, pp. 99–108.
[18] S. Stamm, B. Sterne, and G. Markham, “Reining in the Web with Content Security Policy,” in International Conference on World Wide Web (WWW), 2010.
[19] T. Oda, G. Wurster, P. V. Oorschot, and A. Somayaji, “SOMA: Mutual Approval for Included Content in Web Pages,” in ACM Conference on Computer and Communications Security, 2008.
[20] L. D. Baron. (2010) Preventing attacks on a user’s history through CSS :visited selectors. http://dbaron.org/mozilla/visited-privacy
[21] Z. Weinberg, E. Y. Chen, P. Jayaraman, and C. Jackson, “I Still Know What You Visited Last Summer: Leaking browsing history via user interaction and side channel attacks,” in IEEE Symposium on Security and Privacy, 2011.
[22] D. Morin, “Announcing Facebook Connect,” 2008, https://developers.facebook.com/blog/post/108/.
[23] E. Hammer-Lahav, “Web Host Metadata,” 2010, http://tools.ietf.org/html/draft-hammer-hostmeta-13.
[24] C. Jackson and A. Barth, “Beware of Finer-Grained Origins,” in Web 2.0 Security and Privacy, 2008.
[25] Google, “Packaged Apps,” http://code.google.com/chrome/extensions/apps.html.
[26] Mozilla, “Manifest File,” https://developer.mozilla.org/en/OpenWebApps/The Manifest.
[27] Google, “Verified Author,” http://www.google.com/support/chrome webstore/bin/answer.py?hl=en&answer=173657.
[28] G. Aggarwal, E. Bursztein, C. Jackson, and D. Boneh, “An Analysis of Private Browsing Modes in Modern Browsers,” in USENIX Security Symposium, 2010, pp. 79–94.
[29] C. Reis and S. D. Gribble, “Isolating Web Programs in Modern Browser Architectures,” in ACM European Conference on Computer Systems (EuroSys), 2009.
[30] D. Jackson, “Alloy: a lightweight object modelling notation,” ACM Transactions on Software Engineering and Methodology (TOSEM), vol. 11, no. 2, pp. 256–290, 2002.
[31] ——, Software Abstractions: Logic, Language, and Analysis. The MIT Press, 2006.
[32] F. Kerschbaum, “Simple cross-site attack prevention,” in Security and Privacy in Communications Networks and the Workshops, 2007. SecureComm 2007. Third International Conference on, Sept. 2007, pp. 464 –472.
[33] Mozilla, “CSP specification,” 2011, https://wiki.mozilla.org/Security/CSP/Specification#Report-Only mode.