### Investigating Attention Scores in Normal and Anomalous Traces

This study investigates how attention scores differ between normal and anomalous traces and how these differences can be utilized to infer interesting patterns. The data for this study was generated from the infrastructure illustrated in Fig. 3.

**Authorized Use:**
- **Licensee:** Technische Universitaet Berlin
- **Download Date:** September 06, 2021
- **Time:** 12:04:10 UTC
- **Source:** IEEE Xplore
- **Restrictions:** Apply as per license agreement

### Methodology

To test and compare the performance and robustness of the proposed attention method and state-of-the-art anomaly detection techniques, we set the `max_len` value to 90, which covers all trace lengths within the dataset. We considered three learning scenarios to evaluate our hypothesis that the proposed method can preserve both global and local properties within the traces.

#### Learning Scenarios

1. **Real Anomalies (LS1):**
   - **Test Set:** Anomalies generated by the deployed testbed.
   - **Goal:** To inspect the performance of anomaly detection methods under the presence of system-generated anomalies.
   - **Parameter Configurations:** Both methods were tested on 9 different parameter configurations. The best configuration was selected and used to test the generalization of both approaches in subsequent experiments.

2. **Artificial Anomalies (LS2):**
   - **Anomaly Injection:** Observations show that system-generated anomalies often result in shortened traces. To test the generalization and robustness of the methods, a set of artificial anomalies was created by truncating randomly selected normal traces at random positions and labeling them as anomalous.
   - **Method Selection:** The best method from the optimization procedure in LS1 was used to directly test the performance change with novel anomalies.

### Implementation Details

- **Programming Environment:** Python using PyTorch [21]
- **Hardware:** Personal computer with GPU-NVIDIA GTX 1660
- **Training Parameters:**
  - Batch sizes: 16, 64, 256
  - Epochs: 10, 25, 50
  - Attention model layers: 1
  - Recurrent layers: 2
  - Hidden sizes: 256
  - Threshold: Varies from 0 to 1 with a step of 0.05
- **Drain Parameters:**
  - Similarity: 0.4
  - Depth: 4
  - Training parameter P: 70% of the number of normal traces
- **LSTM Parameters:**
  - Window size: 3 (covers all traces in the training set)

### Experimental Results

#### Real Anomalies (LS1)

Fig. 4 shows the results for the best-selected models from the optimization procedure. For long traces, the attention mechanism outperformed the LSTM approach, achieving higher scores. The attention mechanism can focus on specific spans of the trace, leveraging the sparsity property to exploit global properties. In contrast, the LSTM-based approach exploits local properties due to its autoregressive nature. For short and combined (short and long) traces, both methods showed comparable performance, indicating their ability to exploit locality in traces.

#### Artificial Anomalies (LS2)

Fig. 5 depicts the results from the LS2 scenario. Notably, there is a decrease in recall for both short and long traces using the LSTM-based approach. This is because the autoregressive model is more likely to predict anomalies as normal, especially when the anomalous trace differs only in length. The forward blindness of the autoregressive approach limits its ability to infer information from the entire trace, making it less effective for longer traces. Long traces are common in real-world distributed systems, where one operation can involve multiple service invocations. Therefore, the ability to handle long traces is crucial for practical applications. The attention mechanism, however, provides good results on long traces by exploiting the information of the whole trace at once, without suffering from reduced recall like the LSTM method.

### Conclusion

This paper addresses the problem of anomaly detection in large-scale distributed systems, an essential task for security and reliability. We introduced a new learning task—masked span prediction—for execution-path anomaly detection from tracing data. This novel definition allows us to include information from the entire trace, directly exploiting existing service relations. Our approach demonstrates better predictive performance, especially for long traces, compared to existing LSTM-based methods. Empirically, we show that the proposed approach is more robust to small permutations in normal traces, a frequent scenario in practice. The high performance on experimental testbed data suggests that this approach opens new possibilities for anomaly detection not only from tracing data but also from other sources with distributed event representations, such as log data. We believe this method will motivate further research into utilizing full trace information for anomaly detection.

### References

1. J. Kaldor, J. Mace, M. Bejda, E. Gao, W. Kuropatwa, J. O’Neill, K. W. Ong, B. Schaller, P. Shan, B. Viscomi et al., “Canopy: An end-to-end performance tracing and analysis system,” in Proceedings of the 26th Symposium on Operating Systems Principles. ACM, 2017, pp. 34–50.
2. C. Sridharan, Distributed Systems Observability: A Guide to Building Robust Systems. O’Reilly Media, 2018.
3. A. Gulenko, F. Schmidt, A. Acker, M. Wallschläger, O. Kao, and F. Liu, “Detecting anomalous behavior of black-box services modeled with distance-based online clustering,” in 2018 IEEE 11th International Conference on Cloud Computing. San Francisco, CA, USA: IEEE, 2018, pp. 912–915.
4. M. Du, F. Li, G. Zheng, and V. Srikumar, “DeepLog: Anomaly detection and diagnosis from system logs through deep learning,” in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. New York, NY, USA: Association for Computing Machinery, 2017, p. 1285–1298.
5. F. Schmidt, S.-P. F., A. Gulenko, M. Wallschläger, A. Acker, and O. Kao, “Unsupervised anomaly event detection for cloud monitoring using online ARIMA,” in 2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion. Zurich: IEEE, 2018, pp. 71–76.
6. W. Meng, Y. Liu, Y. Zhu, S. Zhang, D. Pei, Y. Liu, Y. Chen, R. Zhang, S. Tao, P. Sun, and R. Zhou, “LogAnomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs,” in Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization, 2019, pp. 4739–4745.
7. S. Nedelkoski, J. Cardoso, and O. Kao, “Anomaly detection and classification using distributed tracing and deep learning,” in 2019 19th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing. Larnaca, Cyprus: IEEE, 2019, pp. 241–250.
8. ——, “Anomaly detection from system tracing data using multimodal deep learning,” in 2019 IEEE 12th International Conference on Cloud Computing. Milan, Italy: IEEE, 2019, pp. 179–186.
9. Y. Yang, L. Wang, J. Gu, and Y. Li, “Transparently capturing request execution path for anomaly detection,” 2020.
10. V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A survey,” ACM Computing Surveys, vol. 41, 2009.
11. S. Zhang, Y. Liu, D. Pei, Y. Chen, X. Qu, S. Tao, and Z. Zang, “Rapid and robust impact assessment of software changes in large internet-based services,” in Proceedings of the 11th ACM Conference on Emerging Networking Experiments and Technologies, 2015, pp. 1–13.
12. M. M. Moya, M. W. Koch, and L. D. Hostetler, “One-class classifier networks for target recognition applications,” NASA STI/Recon Technical Report N, vol. 93, 1993.
13. S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural Computation, vol. 9, pp. 1735–1780, 1997.
14. J. Chung, K. Kastner, L. Dinh, K. Goel, A. C. Courville, and Y. Bengio, “A recurrent latent variable model for sequential data,” in Advances in Neural Information Processing Systems, 2015, pp. 2980–2988.
15. P. He, J. Zhu, Z. Zheng, and M. Lyu, “Drain: An online log parsing approach with fixed depth tree.” IEEE, 062017, pp. 33–40.
16. J. Zhu, S. He, J. Liu, P. He, Q. Xie, Z. Zheng, and M. R. Lyu, “Tools and benchmarks for automated log parsing,” in 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). Quebec, Canada: IEEE Press, 2019, pp. 121–130.
17. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in Advances in Neural Information Processing Systems. Red Hook, NY, US: Curran Associates, 2017, pp. 5998–6008.
18. A. Shrivastwa, S. Sarat, K. Jackson, C. Bunch, E. Sigler, and T. Campbell, OpenStack: Building a Cloud Environment. Packt Publishing, 2016.
19. (2020) Kolla-ansible’s documentation. [Online]. Available: https://docs.openstack.org/kolla-ansible/latest/
20. (2020) Rally documentation. [Online]. Available: https://rally.readthedocs.io/en/latest/
21. A. Paszke, S. Gross, and et. al., “PyTorch: An imperative style, high-performance deep learning library,” in Advances in Neural Information Processing Systems 32. Curran Associates, Inc., 2019, pp. 8024–8035.