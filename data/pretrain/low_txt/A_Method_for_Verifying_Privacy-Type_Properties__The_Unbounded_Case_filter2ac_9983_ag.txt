To formalize such a protocol, we consider the following signature:
\[
\Sigma_c = \{ \text{enc}, \text{dec}, \text{dh}, \text{mac}, \text{gen}, g, \text{ok} \} \quad \text{and} \quad \Sigma_d = \{ \text{neq} \}.
\]
All symbols, except for \(g\) and \(\text{ok}\) which are public constants, are public constructor symbols with arity 2. The destructor \(\text{neq}\) has already been defined in Section II. The symbol \(\text{dh}\) models modular exponentiation, while \(\text{mac}\) models message authentication code. We define the equational theory \(E\) by the following equations:
\[
\begin{aligned}
&\text{dec}(\text{enc}(x, y), y) = x, \\
&\text{dh}(\text{dh}(x, y), z) = \text{dh}(\text{dh}(x, z), y).
\end{aligned}
\]

This protocol falls into our generic class of two-party protocols. We take
\[
\Pi_{\text{PACE}} = (k, \{s_T, n_T, n'_T\}, \{n_R, n'_R\}, I_{\text{PACE}}, R_{\text{PACE}})
\]
as the responder role (we do not detail the continuation \(R'\) and omit trivial conditionals). The process modeling the role where the \(R_{\text{PACE}}\) process (reader) is described in Figure 8. The \(I_{\text{PACE}}\) process can be obtained similarly.

\[
\begin{aligned}
R_{\text{PACE}} &:= \text{in}(c_R, y_1). \, \text{out}(c_R, \text{dh}(g, n_R)). \, \text{in}(c_R, y_2). \, \text{out}(c_R, \text{dh}(G, n'_R)). \, \text{in}(c_R, y_3). \\
&\quad \text{let } y_{\text{test}} = \text{neq}(y_3, \text{dh}(G, n'_R)) \text{ in } \text{out}(c_R, \text{mac}(y_3, k')). \\
&\quad \text{in}(c_R, y_4). \, \text{let } y_5 = \text{eq}(y_4, \text{mac}(\text{dh}(G, n'_R), k')) \text{ in } R'.
\end{aligned}
\]
where \(G = \text{gen}(\text{dec}(y_1, k), \text{dh}(y_2, n_R))\) and \(k' = \text{dh}(y_3, n'_R)\).

**Figure 8. Process \(R_{\text{PACE}}\)**

Unfortunately, ProVerif cannot handle the equation above on the \(\text{dh}\) operator due to termination issues. Instead, we use the following equational theory, which is more suitable for ProVerif:
\[
\begin{aligned}
&\text{dh}(\text{dh}(g, y), z) = \text{dh}(\text{dh}(g, z), y), \\
&\text{dh}(\text{dh}(\text{gen}(x_1, x_2), y), z) = \text{dh}(\text{dh}(\text{gen}(x_1, x_2), z), y).
\end{aligned}
\]

We do not model the \(\text{getChallenge}\) constant message used to initiate the protocol, as it does not play a significant role in the security of the protocol. This is sufficient for the protocol to work properly but lacks equations that an attacker might exploit.

### Attacks and Vulnerabilities

#### Imprecision in Official Specification
First, we highlight an imprecision in the official specification [38] that may lead to practical attacks on unlinkability. The specification does not explicitly forbid the decryption operation from failing if the key \(k\) does not match the key of the ciphertext \(y_1\). In this case, an attacker could eavesdrop on a first message \(c_0 = \text{enc}(s^0_T, k_0)\) of a certain tag \(T^0\), replace the challenge \(\text{enc}(s_T, k)\) with \(c_0\), and wait for the reader's response. If the decryption does not fail, the attacker learns that \(k = k_0\), and thus \(T\) is actually \(T^0\). We discovered this attack using our method, as we initially modeled the decryption as a destructor that could fail.

#### Attack on Modelizations in Literature
Second, we report an attack discovered using our method on some modelizations of PACE found in the literature [29], [39], [40]. In these papers, the first conditional of the reader
\[
\text{let } y_{\text{test}} = \text{neq}(y_3, \text{dh}(G, n'_R)) \text{ in }
\]
is omitted. This makes the resulting protocol not well-authenticating. An attacker can send the message outputted at the previous step, allowing the reader to execute its role until the end, but the resulting trace is not honest. This scenario can also be turned into an attack against unlinkability.

#### Proper Understanding of PACE
Third, we consider PACE as properly understood from the official specification, where the decryption may not fail. In this case, we report a new attack. UKano found that the last test of the reader violates well-authentication. For example, if the message \(\text{enc}(s_T, k)\) from a tag \(T(k, n_T)\) is fed to two readers \(R(k, n^1_R)\) and \(R(k, n^2_R)\) of the same identity name, the attacker can forward messages between them. They can complete the two rounds of Diffie-Hellman, and the MAC-key verification phase goes well. This violates well-authentication and unlinkability because the scenario cannot be observed in \(S_\Pi\).

### Fixing the Attack
Finally, we propose a simple fix by adding tags to avoid confusion between reader’s and tag’s messages. Replace messages 8 and 9 from Figure 7 with \(\text{mac}(\langle c_r, G n'_R \rangle, k')\) and \(\text{mac}(\langle c_t, G n'_T \rangle, k')\) respectively, where \(c_r, c_t\) are public constants, and add the corresponding checks. Frame opacity and well-authentication can be automatically established using UKano in about 20 minutes. Thus, PACE with tags preserves unlinkability in the considered model.

### Conclusion
We have identified two conditions, well-authentication and frame opacity, which imply anonymity and unlinkability for a wide class of protocols. These conditions can be checked automatically using the tool ProVerif, and we have mechanized the verification in a tool called UKano. This yields a new verification technique to check anonymity and unlinkability for an unbounded number of sessions. Our case studies have shown the effectiveness of our methodology in discovering attacks against unlinkability and anonymity, as illustrated by the new attacks found on PACE and LAK.

In the future, we plan to develop a mature implementation of our tool to make it widely accessible for the design and study of privacy-preserving two-party protocols. We will also explore extending our conditions to support more comprehensive guidelines for designing new privacy-enhancing protocols.

### References
[1] “ISO 15408-2: Common criteria for information technology security evaluation - part 2: Security functional components,” July 2009.
[2] T. Van Deursen and S. Radomirovic, “Attacks on RFID protocols.” IACR Cryptology ePrint Archive, vol. 2008, p. 310, 2008.
[3] A. Armando, R. Carbone, L. Compagna, J. Cuéllar, and M. L. Tobarra, “Formal analysis of SAML 2.0 web browser single sign-on: breaking the SAML-based single sign-on for Google apps,” in Proc. 6th ACM Workshop on Formal Methods in Security Engineering (FMSE’08). ACM, 2008, pp. 1–10.
[4] V. Cortier and B. Smyth, “Attacking and fixing Helios: An analysis of ballot secrecy,” Journal of Computer Security, vol. 21, no. 1, pp. 89–148, 2013.
[5] A. Armando et al., “The AVANTSSAR platform for the automated validation of trust and security of service-oriented architectures,” in Proc. 18th International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS’12), vol. 7214. Springer, 2012, pp. 267–282.
[6] S. Meier, B. Schmidt, C. Cremers, and D. Basin, “The Tamarin Prover for the Symbolic Analysis of Security Protocols,” in Proc. 25th International Conference on Computer Aided Verification (CAV’13), ser. LNCS, vol. 8044. Springer, 2013, pp. 696–701.
[7] B. Blanchet, “An Efficient Cryptographic Protocol Verifier Based on Prolog Rules,” in Proceedings of CSFW’01. IEEE Comp. Soc. Press, 2001, pp. 82–96.
[8] M. Arapinis, T. Chothia, E. Ritter, and M. Ryan, “Analysing unlinkability and anonymity using the applied pi calculus,” in Proceedings of CSF’10. IEEE Comp. Soc. Press, 2010.
[9] M. Bruso, K. Chatzikokolakis, and J. den Hartog, “Formal verification of privacy for RFID systems,” in Proceedings of CSF’10, 2010.
[10] S. Delaune, S. Kremer, and M. D. Ryan, “Verifying privacy-type properties of electronic voting protocols,” Journal of Computer Security, no. 4, 2008.
[11] M. Backes, C. Hritcu, and M. Maffei, “Automated verification of remote electronic voting protocols in the applied pi-calculus,” in Proceedings of the 21st IEEE Computer Security Foundations Symposium, CSF 2008, Pittsburgh, Pennsylvania, 23-25 June 2008. IEEE Computer Society, 2008, pp. 195–209.
[12] N. Dong, H. Jonker, and J. Pang, “Formal analysis of privacy in an ehealth protocol,” in Computer Security–ESORICS 2012. Springer, 2012, pp. 325–342.
[13] M. Arapinis, L. Mancini, E. Ritter, M. Ryan, N. Golde, K. Redon, and R. Borgaonkar, “New privacy issues in mobile telephony: fix and verification,” in Proceedings of the 2012 ACM conference on Computer and communications security. ACM, 2012, pp. 205–216.
[14] M. Arapinis, L. I. Mancini, E. Ritter, and M. Ryan, “Privacy through pseudonymity in mobile telephony systems.” in NDSS, 2014.
[15] R. Chrétien, V. Cortier, and S. Delaune, “From security protocols to pushdown automata,” ACM Transactions on Computational Logic, vol. 17, no. 1:3, Sep. 2015.
[16] M. Baudet, “Deciding security of protocols against off-line guessing attacks,” in Proc. 12th Conference on Computer and Communications Security. ACM, 2005.
[17] V. Cheval, H. Comon-Lundh, and S. Delaune, “Trace equivalence decision: Negative tests and non-determinism,” in Proceedings of CCS’11. ACM Press, 2011.
[18] V. Cheval and B. Blanchet, “Proving more observational equivalences with ProVerif,” in Principles of Security and Trust. Springer, 2013, pp. 226–246.
[19] D. Basin, J. Dreier, and R. Sasse, “Automated symbolic proofs of observational equivalence,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, 2015, pp. 1144–1155.
[20] S. Santiago, S. Escobar, C. Meadows, and J. Meseguer, “A formal definition of protocol indistinguishability and its verification using Maude-NPA,” in Security and Trust Management. Springer, 2014, pp. 162–177.
[21] M. Abadi and C. Fournet, “Mobile values, new names, and secure communication,” in Proceedings of POPL’01. ACM Press, 2001.
[22] B. Blanchet, M. Abadi, and C. Fournet, “Automated verification of