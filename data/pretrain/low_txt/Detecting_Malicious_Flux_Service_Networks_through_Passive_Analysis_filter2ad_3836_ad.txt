### Optimized Text

Our focus is on classifying malicious flux services. Given that the number of flux agents in each flux service network is typically very high, we only consider clusters of domains for which we observed at least 10 resolved IP addresses (denoted as \(\phi_1 > 10\)). Using our graphical interface, we labeled 670 clusters as related to various types of malicious flux networks (e.g., malware, adult content, phishing websites) and 8,541 clusters as non-flux/legitimate, including those associated with CDNs, NTP pools, IRC pools, and other legitimate services, during March 2009.

We evaluated the accuracy of our classifier using this labeled dataset and a 5-fold cross-validation approach. The results, presented in Table I, show that our network classifier achieves a very high Area Under the ROC curve (AUC) [1], along with a high detection rate and low false positive rate. We conducted experiments using three different sets of features. Initially, we used all "passive" and "active" features described in Section II-F to characterize domain clusters. Subsequently, we repeated the experiments using only the "passive" features (see the second row in Table I). In these experiments, the C4.5 learning algorithm generated a decision tree with feature \(\phi_6\) at the root, and features \(\phi_3\) and \(\phi_5\) as top child nodes. This indicates that these three features are the most useful for distinguishing between malicious flux networks and legitimate networks. For comparison, we also evaluated the classifier's performance using only these three features. As shown in the third row of Table I, these three features alone yield very good classification results, though using all available features produces slightly better outcomes.

To further validate our classifier, we applied it in an operational setting. We trained the classifier on the entire labeled dataset and then used it to classify new, unseen domain clusters obtained in the first 14 days of April 2009. During this period, we observed an average of 448 clusters per day (again, considering only clusters with \(\phi_1 > 10\)), of which 26 (on average per day) were classified as related to flux service networks. Manual verification confirmed that the classifier correctly identified clusters related to malicious flux networks with very few false positives, consistent with the results in Table I. Over the 45-day evaluation period from March 1 to April 14, 2009, we detected an average of 23 malicious flux service networks per day, involving a total of 61,710 flux domain names and 17,332 distinct IP addresses related to flux agents.

### Contribution to Spam Filtering

In this section, we analyze how the information about malicious flux networks passively gathered at the RDNS level can benefit spam filtering applications. Specifically, we focus on detecting whether domain names found in spam emails are related to malicious flux networks detected by our system. 

Assume a mail server receives an email containing a link to a website, performs a DNS query for the domain name in the link, and forwards the email to the spam filter along with the set \(R_f\) of resolved IP addresses. The spam filter can then inspect the email content and check for any intersection between \(R_f\) and the malicious flux networks identified by our detection system. If a significant overlap (i.e., common IP addresses) is found, the spam filter can increase the spam score of the email, aiding in a more accurate overall decision about whether the email should be classified as spam.

This spam detection process can also be extended to other types of spam, such as blog spam or social network spam, using a browser plugin. The output of our malicious flux detection system can thus contribute to various spam filtering applications.

To measure the extent to which our detection system benefits email spam filtering, we obtained a feed of URLs extracted from spam emails captured by a mid-size email spam trap over 30 days (March 1 to March 30, 2009). This feed provided an average of 250,000 spam-related URLs per day, from which we extracted approximately 86,000 new domain names per day. Let \(D_{k+1}\) be the set of spam-related domain names collected on day \(k+1\), \(S(d)_{k+1}\) be the set of resolved IPs for domain \(d \in D_{k+1}\), and \(\hat{R}_k^{k-l}\) be the overall set of IP addresses of flux agents detected by our system from day \(k-l\) to day \(k\).

To obtain a suspiciousness score \(s(d)\) for domain \(d\), we use the similarity metric defined in Equation 1: \(s(d) = \text{sim}(S(d)_{k+1}, \hat{R}_k^{k-l})\), which measures the degree of overlap between the resolved IPs of domain \(d\) and the malicious flux networks. If \(s(d)\) exceeds a predefined threshold \(\theta\), we classify the domain \(d\) as malicious; otherwise, it is classified as legitimate. We repeat this process for each spam-related domain name \(d \in D_{k+1}\) to estimate the detection rate of our approach, i.e., the percentage of spam-related domain names that can be identified by a spam filter.

To estimate the false positives, we considered the list of domain names related to the top 50,000 most popular websites according to Alexa (www.alexa.com). For each domain \(\alpha \in A\), we perform a DNS query to collect the set of resolved IP addresses \(R(\alpha)\) and compute the similarity score \(s(\alpha) = \text{sim}(R(\alpha), \hat{R}_k^{k-l})\). If \(s(\alpha) > \theta\), we classify \(\alpha\) as malicious. In our experiments, we assume the domain names in set \(A\) are legitimate/non-flux domains. Therefore, any domain \(\alpha\) for which \(s(\alpha) > \theta\) is considered a false positive.

Figure 3 shows the ROC curves (i.e., the trade-off between false positive rate and detection rate) obtained by varying the detection threshold \(\theta\), using a fixed value of \(l = 2\), and for four different values of \(k\) (i.e., four different days). Our approach achieves a detection rate of domain names advertised through spam emails between 90% to 95%. It is worth noting that not all detected malicious domains exhibit fast-flux behavior; some resolve to a fixed set of IP addresses that partially intersect with the IP addresses of flux agents detected from our passive analysis of RDNS traffic. These fixed sets often consist of highly reliable compromised machines, suggesting that such machines may be used both as part of larger flux service networks and as standalone providers of malicious content. The false positive rate of our approach for detecting spam-related malicious domains is less than 0.002%, confirming that our malicious flux network detection system is a promising tool for enhancing spam filtering applications.

### Acknowledgments

We would like to thank Giorgio Giacinto and the anonymous reviewers for their valuable comments on earlier versions of this paper. This work was supported in part by the National Science Foundation under grants no. 0716570 and 0831300, the Department of Homeland Security under contract no. FA8750-08-2-0141, and the Office of Naval Research under grant no. N000140911042. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation, the Department of Homeland Security, or the Office of Naval Research.

### References

[1] A. P. Bradley. The use of the area under the ROC curve in the evaluation of machine learning algorithms. Pattern Recognition, 30(7):1145–1159, 1997.
[2] R. Dugad and N. Ahuja. Unsupervised multidimensional hierarchical clustering. In International Conference on Acoustics, Speech and Signal Processing, 1998.
[3] T. Holz, C. Gorecki, K. Rieck, and F. Freiling. Measuring and detecting fast-flux service networks. In Network & Distributed System Security Symposium, 2008.
[4] X. Hu, M. Knysz, and K. G. Shin. Rb-seeker: Auto-detection of redirection botnets. In Network & Distributed System Security Symposium, 2009.
[5] A. K. Jain and R. C. Dubes. Algorithms for clustering data. Prentice-Hall, Inc., 1988.
[6] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. ACM Comput. Surv., 31(3):264–323, 1999.
[7] M. Konte, N. Feamster, and J. Jung. Dynamics of online scam hosting infrastructure. In Passive and Active Measurement Conference, 2009.
[8] J. Nazario and T. Holz. As the net churns: Fast-flux botnet observations. In International Conference on Malicious and Unwanted Software, 2008.
[9] E. Passerini, R. Paleari, L. Martignoni, and D. Bruschi. Fluxor: Detecting and monitoring fast-flux service networks. In Detection of Intrusions and Malware, and Vulnerability Assessment, 2008.
[10] J. R. Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, 1993.
[11] SSAC. SAC 025 - SSAC advisory on fast flux hosting and DNS, 2008.
[12] The Honeynet Project. Know your enemy: Fast-flux service networks, 2007.

### Appendix

In the additional filtering step F3, we apply the following filtering rules (see Section II-D for the notation), where the subscript \(E\) indicates that the quantities are measured at the end of an epoch \(E = 1\) day:

- **F3-a**: \(T_E > 0.5\) AND \(T_E < 3600\) AND \(|G(d)_E| > 10\)
- **F3-b**: \(|R(d)_E| > 5\) AND \(p_E > 0.8\)
- **F3-c**: \(|R(d)_E| > 10\)
- **F3-d**: \(|R(d)_E| > 5\)

---

This optimized version aims to enhance clarity, coherence, and professionalism while maintaining the original content and intent.