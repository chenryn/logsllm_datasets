### Patient and Provider Preferences for IMD Security Systems

The criticality-aware fail-open system was disliked by 18% of patients, but it was more unpopular among providers, with 42% disliking it compared to 38% who liked it. We hypothesize that this discrepancy is primarily due to providers' heightened concern about the lack of a manual override in case the system fails to recognize a medical emergency. The provider feedback suggests that this approach may not be suitable for securing Implantable Medical Devices (IMDs).

### Recommended Solutions for Patients

The patient study recommended a set of three solutions that, if offered together, could satisfy the majority of patients:
- A proximity-based system (System E)
- A fail-open/safety wristband (System D)
- A UV-visible tattoo of a password (System C)

However, there is strong opposition to UV-visible tattoos among providers, with 50% recommending against their use. This new data cautions against the practical implementation of such tattoos.

### Fail-Open/Safety Wristband (System D)

The fail-open/safety wristband (System D) was the least disliked security concept, with only 17% of participants disliking it and 13% recommending against it. It was also the most favored by medical providers, with 58% liking it and 46% recommending it. Additionally, it was the most popular among patients, with 45% liking it and 27% indicating they would choose to use it if available.

### Security Design Considerations

#### 7.1 Access, Access, Access

Access and compatibility are key issues highlighted in both initial perspectives and security system concept datasets. Participants emphasized several aspects of access:
- **Provider Access:** Providers must always have access to the implanted device. Security systems should either fail to an open state or offer a manual override.
- **Unplanned Access:** Unplanned access is not limited to emergencies; patients may travel or change cardiologists, and records may not always transfer smoothly.
- **Centralized Systems:** Access should not rely on a centralized system, which could be unavailable due to technical, geographic, or other reasons, and merely defers the security problem.
- **Patient Dependency:** Access should not depend on a conscious or compliant patient.
- **Additional Equipment:** Access should avoid relying on additional equipment, which can delay or block patient care or remove providers from the bedside.
- **Timeliness:** Access should be timely and require few steps. As one participant put it, "Please, please, please keep it SIMPLE."

#### 7.2 Mechanics and Logistics

Various aspects of IMD mechanics and logistics were raised in both initial perspectives and system concept datasets. Any security system should avoid disturbing the status quo in terms of:
- **Cost:** Cost can affect insurance approval.
- **Training:** Required training, particularly for non-cardiology staff.
- **Battery Usage:** Implant battery usage.
- **Implant Size:** Implant size.
- **Surgical and Healing Processes:** Any aspect that might impact the surgical or healing processes.

#### 7.3 Safety Features and Incentives

Participants expressed interest in incorporating safety features into a security system for IMDs. The exact nature of these features and how they might be tuned requires further investigation. For example, many participants were concerned that a 911 feature could result in false-positive emergency notifications. However, well-designed safety features could function as incentives for patients to comply with using a security system, such as the external battery in the wristband (System D), which provides security only when worn.

#### 7.4 Empowering Without Burdening

Ideally, patients should have some implicit or explicit role in the access control process, whether through overt action or by allowing extended skin contact. This role can give patients a sense of empowerment and provide human reasoning about whether the device should be accessed in a given situation. Conversely, patients should not be unduly burdened mentally or physically by the security system. For instance, visual indicators of a patient's condition should be opt-in, and patients should weigh the advantages and disadvantages before participating. This consideration raises ethical, legal, and philosophical questions:
- Should a security design hinge on patients choosing whether to comply?
- How many patients would actually comply?
- Should a security design aim to equally protect all patients, or is that paternalistic?
- What are the legal and reputational repercussions if a company’s IMD is attacked and security was optional?

### Conclusion

This work makes two important contributions:
1. **Domain-Specific Findings:** We offer domain-specific findings for security in implantable cardiac devices—cyber-physical systems that perform critical operations within patients’ bodies. These findings aim to facilitate designs with increased adoption, correct usage, and minimal negative side effects for patients and medical providers.
2. **Methodological Contribution:** We adapted established methods from value-sensitive design, specifically the Envisioning Workshop and values dams and flows, to the security domain. This work demonstrates how security researchers can draw upon direct and indirect stakeholders to understand the relevant properties of a new technology domain. The techniques we used were in the context of implantable cardiac devices but could be applied to other emerging technology domains.

Bridging the gap between technological innovation and the lives of stakeholders impacted by that technology is not easy, but it is critical. This work provides a specific study and methods for making progress toward incorporating human values into technical security design.

### Acknowledgments

This work was supported in part by the US National Science Foundation (NSF) under awards CNS-0846065, CNS-0905118, and CNS-0905384, by the US Department of Health & Human Services (HHS) under award HHS-2010-03958-09, and by an Alfred P. Sloan Research Fellowship. Any opinions, findings, and conclusions or recommendations expressed in this publication do not necessarily reflect the views of the funding agencies. We thank the medical providers who participated in this study and M. Enev, D. Halperin, K. Koscher, B. Ransford, and A. Takakuwa for contributing to the data analysis process. This work was done while Tamara Denning was at the University of Washington.

### References

[1] S. Avancha, A. Baxi, and D. Kotz. Privacy in Mobile Technology for Personal Healthcare. ACM Computing Surveys, 45(1), 2013.
[2] D. Balfanz. Usable Access Control for the World Wide Web. ACSAC 2003.
[3] S. Cherukuri, K. Venkatasubramanian, and S. Gupta. BioSec: A Biometric Based Approach for Securing Communication in Wireless Networks of Biosensors Implanted in the Human Body. ICPP Workshops 2003.
[4] S. Clark, T. Goodspeed, P. Metzger, Z. Wasserman, K. Xu, and M. Blaze. Why (Special Agent) Johnny (Still) Can’t Encrypt: A Security Analysis of the APCO Project 25 Two-Way Radio System. USENIX 2011.
[5] L. Cranor and S. Garfinkel. Security and Usability. O’Reilly Media, Inc., 2005.
[6] A. Czeskis, I. Dermendjieva, H. Yapit, A. Borning, B. Friedman, B.T. Gill, T. and T. Kohno. Parenting From the Pocket: Value Tensions and Technical Directions for Secure and Private Parent-Teen Mobile Safety. SOUPS 2010.
[7] T. Denning, A. Borning, B. Friedman, B. T. Gill, T. Kohno, and W. H. Maisel. Patients, Pacemakers, and Implantable Defibrillators: Human Values and Security for Wireless Implantable Medical Devices. CHI 2010.
[8] T. Denning, K. Fu, and T. Kohno. Absence Makes the Heart Grow Fonder: New Directions for Implantable Medical Device Security. HotSec 2008.
[9] T. Denning, T. Kohno, H. M. and Levy. Computer Security and the Modern Home. Communications of the ACM, 56(1), 94-103, 2013.
[10] T. Dimkov, A. van Cleeff, W. Pieters, and P. Hartel. Two Methodologies For Physical Penetration Testing Using Social Engineering. ACSAC 2010.
[11] J. L. Fleiss, B. Levin, and M. C. Paik. Statistical Methods for Rates and Proportions (3rd ed.). New York: John Wiley & Sons. 2003.
[12] B. Friedman, D. Howe, and E. Felten. Informed Consent in the Mozilla Browser: Implementing Value Sensitive Design. HICSS 2002.
[13] B. Friedman, D. Hurley, D. C. Howe, E. Felten, and H. Nissenbaum. Users’ Conceptions of Web Security: A Comparative Study. CHI 2002 (Extended Abstracts).
[14] B. Friedman, P. H. Kahn Jr., and A. Borning. Value Sensitive Design and Information Systems: Three Case Studies. In P. Zhang and D. Galletta, editors, Human-Computer Interaction and Management Information Systems: Foundations. 2006.
[15] S. Gollakota, H. Hassanieh, B. Ransford, D. Katabi and K. Fu. They Can Hear Your Heartbeats: Non-Invasive Security for Implanted Medical Devices. ACM SIGCOMM 2011.
[16] S. K. S. Gupta, T. Mukherjee, and K. Venkatasubramanian. Criticality Aware Access Control Model for Pervasive Applications. IEEE PERCOM 2006.
[17] D. Halperin, T. S. Heydt-Benjamin, K. Fu, T. Kohno, and W. H. Maisel. Security and Privacy for Implantable Medical Devices. IEEE Pervasive Computing, 7, 2008.
[18] D. Halperin, T. S. Heydt-Benjamin, B. Ransford, S. S. Clark, B. Defend, W. Morgan, K. Fu, T. Kohno, and W. H. Maisel. Pacemakers and Implantable Cardiac Defibrillators: Software Radio Attacks and Zero-Power Defenses. IEEE S&P Symposium 2008.
[19] A. Jøsang, B. AlFayyadh, T. Grandison, M. AlZomai, and J. McNamara. Security Usability Principles for Vulnerability Analysis and Risk Assessment. ACSAC 2007.
[20] F. Kensing and K.H. Madsen. Generating Visions: Future Workshops and Metaphorical Design. In J. Greenbaum and M. Kyng, editors, Design at Work: Cooperative Design of Computer Systems. Lawrence Erlbaum, 1991.
[21] J. Landis and G. Koch. The Measurement of Observer Agreement for Categorical Data. Biometrics, 33, 1977.
[22] C. A. Le Dantec and W. K. Edwards. Designs on Dignity: Perceptions of Technology Among the Homeless. CHI 2008.
[23] C. Li, A. Raghunathan, and N. K. Jha. Hijacking an Insulin Pump: Security Attacks and Defenses for a Diabetes Therapy System. Healthcom 2011.
[24] J. K. Miller, B. Friedman, G. Jancke, and B. Gill. Value Tensions in Design: The Value Sensitive Design, Development, and Appropriation of a Corporation's Groupware System. GROUP 2007.
[25] L. I. Millett, B. Friedman, and E. Felten. Cookies and Web Browser Design: Toward Realizing Informed Consent Online. CHI 2001.
[26] L. P. Nathan, B. Friedman, P. V. Klasjna, S. K. Kane, and J. K. Miller. Envisioning Systemic Effects on Persons and Society Throughout Interactive System Design. DIS 2008.
[27] X. Ou. Ethnographic Fieldwork at a University IT Security Office. ACSAC 2013.
[28] N. Paul and T. Kohno. Security Risks, Low-tech User Interfaces, and Implantable Medical Devices: A Case Study with Insulin Pump Infusion Systems. HealthSec 2012.
[29] A. Raij, A. Ghosh, S. Kumar, M. Srivastava. Privacy Risks Emerging from the Adoption of Innocuous Wearable Sensors in the Mobile Environment. CHI 2011.
[30] K. B. Rasmussen, C. Castelluccia, T. S. Heydt-Benjamin, and S. Capkun. Proximity-Based Access Control for Implantable Medical Devices. ACM CCS 2009.
[31] M. Rushanan, C. Swanson, D. F. Kune, and A. D. Rubin. SoK: Security and Privacy in Implantable Medical Devices and Body Area Networks. IEEE S&P Symposium 2014.
[32] S. Schechter. Security That Is Meant To Be Skin Deep: Using Ultraviolet Micropigmentation To Store Emergency-Access Keys for Implantable Medical Devices. HealthSec 2010.
[33] S. Schechter, R. Dhamija, A. Ozment, and I. Fischer. The Emperor’s New Security Indicators. IEEE S&P Symposium 2007.
[34] J. Sorber, M Shin, R. Peterson, C. Cornelius, S. Mare, A. Prasad, Z. Marois, E. Smithayer, and D. Kotz. An Amulet for Trustworthy Wearable mHealth. HotMobile 2012.
[35] Symposium on Usable Privacy and Security. http://cups.cs.cmu.edu/soups/.
[36] E. Troshynski, C. Lee, and P. Dourish. Accountabilities of Presence: Reframing Location-Based Systems. CHI 2008.
[37] K. K. Venkatasubramanian and S. K. S. Gupta. PSKA: Usable and Secure Key Agreement Scheme for Body Area Networks. IEEE Transactions on Information Technology in Biomedicine, 14(1), 2010.
[38] R. Wash. Folk Models of Home Computer Security. SOUPS 2010.
[39] A. Whitten and J. D. Tygar. Why Johnny Can’t Encrypt: A Usability Evaluation of PGP 5.0. USENIX 1999.
[40] F. Xu, Z. Qin, C. C. Tan, B. Wang, and Q. Li. IMDGuard: Securing Implantable Medical Devices with the External Wearable Guardian. IEEE INFOCOM 2011.
[41] D. Yoo, M. Lake, T. Nilsen, M. E. Utter, R. Alsdorf, T. Bizimana, L. P. Nathan, M. Ring, E. J. Utter, R. F. Utter, and B. Friedman. Envisioning Across Generations: A Multi-Lifespan Information System for International Justice In Rwanda. CHI 2013.