### Perfect De-Anonymizability and Landmark Identification

When \(\wp = 0.7\), the first 137 users in Google+ are perfectly de-anonymizable. According to the ODA (Optimization-based De-Anonymization) method, the identified landmarks can serve as references for future de-anonymization (DA).

The relationship between the number of landmarks \(L\) and the number of users \(U\) is given by:
\[ L = U_u \]

From Figure 2(a), as the recall increases, there are more common edges between the anonymized graph \(G_a\) and the original graph \(G_u\). This implies that it becomes easier to identify high-degree users based on the increased structural information, leading to the identification of more landmarks. Similarly, from Figure 2(b), we observe that more landmarks can be identified in Google+ for large \(\wp\) due to greater edge overlap between \(G_a\) and \(G_u\).

### DA Results

Using the landmarks identified in Figure 2, we employ ODA to de-anonymize Gowalla (M1, M2, M3, M4) and Google+ (with different \(\wp\)) as shown in Figure 3. In this figure, the x-axis represents the accumulated percentage of users de-anonymized, and the y-axis represents the accumulated percentage of users successfully de-anonymized.

From Figure 3, we can see that the successful de-anonymization rate is higher for large-degree users than for small-degree users. As the x-axis value increases, the percentage of successfully de-anonymized users generally shows a decreasing trend. This is because large-degree users carry more structural information, making them more accurately de-anonymizable. For Gowalla, we observe from Figure 3(a) that although recall dominates the landmark identification process, the large-scale DA performance is more influenced by precision. Generally, a high precision indicates that the dataset is more de-anonymizable, as seen in M4. A high precision implies a low false positive rate, which reduces noise and improves DA accuracy. For Google+, Figure 3(b) shows that the \(G_a\) projected with a large \(\wp\), such as \(\wp = 0.9\), is more de-anonymizable. This is because a large \(\wp\) implies more similarity between \(G_a\) and \(G_u\), allowing more users to be successfully de-anonymized.

From Figure 3, we also observe that the DA performance of ODA on Gowalla and Google+ is better than the evaluation results shown in Table 3. For example, when \(\wp = 0.9\), Table 3 indicates that 91.2% of the users in Google+ are almost surely de-anonymizable, while ODA successfully de-anonymizes 95.5% of the users. The values in Table 3 represent lower bounds on de-anonymizable users.

In summary, approximately 77.7% to 83.3% of the users in Gowalla and 86.9% to 95.5% of the users in Google+ are de-anonymizable. Thus, structure-based DA is both implementable and powerful in practice.

### Time Consumption

We calculated the time consumption for de-anonymizing Gowalla and Google+. On average, the initialization time, execution time, and total time are 1.79 minutes, 1.6 minutes, and 3.39 minutes for Gowalla, respectively. For Google+, the corresponding times are 0.88 hours, 5.61 hours, and 6.49 hours, respectively.

### Implications and Discussion

Based on our DA quantification, evaluation on real-world datasets, and the implemented DA scheme ODA, we provide several implications:

1. **Structural Information and Privacy Leakage**: Although previous work has shown that structure-based DA is possible, this paper provides a theoretical demonstration of the reasons through rigorous quantification under a general data model. From the quantification, structural information can enable large-scale perfect or \((1 - \epsilon)\)-perfect de-anonymization.

2. **Future Work**:
   - Evaluate our quantification on more structural datasets to further examine its generality.
   - Improve ODA to make it more efficient and robust.
   - Develop application-based effective schemes against structure-based DA attacks.
   - Study the tradeoff between privacy and utility, and propose privacy protection schemes that preserve data utility.
   - Develop a secure data publishing platform that is invulnerable to both semantics-based and structure-based DA attacks.

### Acknowledgments

The authors are grateful to Nana Li and Jing S. He for discussions on graph theory, Huy Pham for processing the Gowalla mobility trace, and Neil Z. Gong for sharing the Google+ dataset. This work was partly supported by NSF-CAREER-CNS-0545667 and sponsored by the US Army Research Laboratory and the UK Ministry of Defence under Agreement Number W911NF-06-3-0001.

### References

[1] L. Backstrom, C. Dwork, and J. Kleinberg, "Wherefore Art Thou R3579X? Anonymized Social Networks, Hidden Patterns, and Structural Steganography," WWW 2007.
[2] A. Narayanan and V. Shmatikov, "De-anonymizing Social Networks," S&P 2009.
[3] M. Srivatsa and M. Hicks, "Deanonymizing Mobility Traces: Using Social Networks as a Side-Channel," CCS 2012.
[4] G. Wondracek, T. Holz, E. Kirda, and C. Kruegel, "A Practical Attack to De-Anonymize Social Network Users," S&P 2010.
[5] P. Pedarsani and M. Grossglauser, "On the Privacy of Anonymized Networks," KDD 2011.
[6] M. Hay, G. Miklau, D. Jensen, D. Towsley, and P. Weis, "Resisting Structural Re-identification in Anonymized Social Networks," VLDB 2008.
[7] K. Liu and E. Terzi, "Towards Identity Anonymization on Graphs," SIGMOD 2008.
[8] N. Li, W. Qardaji, and D. Su, "On Sampling, Anonymization, and Differential Privacy Or, k-Anonymization Meets Differential Privacy," ASIACCS 2012.
[9] C. Dwork, "Differential Privacy," ICALP 2006.
[10] A. Korolova, R. Motwani, S. U. Nabar, and Y. Xu, "Link Privacy in Social Networks," CIKM 2008.
[11] E. Zheleva and L. Getoor, "To Join or Not to Join: The Illusion of Privacy in Social Networks with Mixed Public and Private User Profiles," WWW 2009.
[12] J. Pang, B. Greenstein, R. Gummadi, S. Seshan, and D. Wetherall, "802.11 User Fingerprinting," Mobicom 2007.
[13] L. Backstrom, E. Sun, and C. Marlow, "Find me If You Can: Improving Geographical Prediction with Social and Spatial Proximity," WWW 2010.
[14] S. Han, V. Liu, Q. Pu, S. Peter, T. Anderson, A. Krishnamurthy, and D. Wetherall, "Expressive Privacy Control with Pseudonyms," Sigcomm 2013.
[15] P. Mittal, M. Wright, and N. Borisov, "Pisces: Anonymous Communication Using Social Networks," NDSS 2013.
[16] J. Kannan, G. Altekar, P. Maniatis, and B.-G. Chun, "Making Programs Forget: Enforcing Lifetime for Sensitive Data," USENIX 2013.
[17] M. Egele, G. Stringhini, C. Krugel, and G. Vigna, "COMPA: Detecting Compromised Accounts on Social Networks," NDSS 2013.
[18] K. Singh, S. Bhola, and W. Lee, "xBook: Redesigning Privacy Control in Social Networking Platforms," USENIX 2009.
[19] R. Shokri, G. Theodorakopoulos, J.-Y. L. Boudec, and J.-P. Hubaux, "Quantifying Location Privacy," S&P 2011.
[20] R. Shokri, G. Theodorakopoulos, C. Troncoso, J.-P. Hubaux, and J.-Y. L. Boudec, "Protecting Location Privacy: Optimal Strategy against Localization Attacks," CCS 2012.
[21] M. E. J. Newman, "Networks: An Introduction," Oxford University Press, 2010.
[22] M. E. J. Newman, "The Structure and Function of Complex Networks," SIAM Review, No. 45, pp. 167-256, 2003.
[23] B. Bollob√°s, "Random Graphs (Second Edition)," Cambridge University Press, 2001.
[24] J. Riordan, "An Introduction to Combinatorial Analysis," Wiley, 1958.
[25] N. Z. Gong, W. Xu, L. Huang, P. Mittal, E. Stefanov, V. Sekar, and D. Song, "Evolution of Social-Attribute Networks: Measurements, Modeling, and Implications using Google+," IMC 2012.
[26] http://snap.stanford.edu/data/
[27] H. Pham, C. Shahabi, and Yan Liu, "EBM - An Entropy-Based Model to Infer Social Strength from..."