### Criteria for Tool Comparison

Our tool offers unique features that are currently not provided by any other tools. These features can be evaluated based on the following seven essential criteria:

1. **C1: Payload Localization** - Does the tool support the localization of the payload?
2. **C2: Detection of Divided Malicious Behaviors** - Can the tool capture malicious behaviors even when they are divided into small, seemingly harmless actions?
3. **C3: Behavioral Analysis** - Does the tool perform behavioral analysis?
4. **C4: Resilience to Obfuscation** - Is the tool resilient to code obfuscation?
5. **C5: Automation** - Is the tool completely automated?

As shown in Table 1, only FormalDroid satisfies criteria C1 to C4. To the best of our knowledge, we introduce the first method that supports payload localization. Our method is not fully automated, as it requires analyst involvement during the specification of properties. We manually inspect a few samples to identify malicious behaviors and then specify them through logical formulae. Thus, our tool performs behavioral analysis, capturing malicious behaviors that are split into several small actions. FormalDroid is resilient to common code obfuscations. While DroidLegacy and DroidClone claim to be resilient to code obfuscations, they do not provide any examples. Conversely, Apposcopy is resilient to code obfuscations and provides an analysis tested with obfuscated samples obtained using ProGuard.

### Advantages of Using Formal Methods

The advantages of using formal methods stem from the power of automated model checking to search a state space, and the generation of the formal model is also automated. However, as shown in Table 1, our tool is not completely automated because the definition of the logical formulae expressing the malicious behavior is done manually. Verifying branching temporal logic formulae allows us to recognize malicious behavior, not just by checking the presence of a given sequence, as in pattern-matching approaches. The fundamental drawback of pattern-matching approaches to malware detection is that they ignore the behavior of the program. Commercial malware detectors often use simple pattern-matching approaches, where code is considered malware if it contains a sequence of instructions matched by a regular expression. Recent studies have shown that such malware detectors can be easily defeated using simple program obfuscations already employed by hackers.

Another feature of our approach is the reuse of existing model checkers, avoiding the need to design custom-made model checkers. Model checkers, especially the most widely used ones, are highly sophisticated programs developed over many years by experts. Re-implementing the algorithms in these tools could likely result in worse performance.

### Detection on Java Bytecode

Performing Android malware family detection on the bytecode rather than directly on the Java source code offers several advantages:
- **Language Independence**: The detection process is independent of the source programming language.
- **Detection Without Decompilation**: Malware families can be detected without decompilation, even when the source code is missing.
- **Ease of Parsing**: Lower-level code is easier to parse.
- **Obfuscation Independence**: The detection process is independent of obfuscation techniques.

### Experiment

In this section, we demonstrate the effectiveness of FormalDroid in identifying ADRD malicious payloads by testing real-world malicious and legitimate applications. We gathered 861 malware samples from the Drebin dataset, which includes 91 ADRD samples and the rest from the most widespread families. We measure the effectiveness of FormalDroid in terms of accuracy, defined as:
\[ \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{FP} + \text{FN} + \text{TN}} \]
where:
- **TP (True Positive)**: Number of samples correctly identified as belonging to the ADRD family.
- **TN (True Negative)**: Number of samples correctly identified as not belonging to the ADRD family.
- **FP (False Positive)**: Number of samples incorrectly labeled as belonging to the ADRD family.
- **FN (False Negative)**: Number of samples incorrectly not identified as ADRD malware.

Table 2 shows the results achieved by FormalDroid in recognizing ADRD, with an accuracy of 0.94.

| Samples ∈ ADRD | Samples ∉ ADRD | TP | FP | FN | TN | Acc |
|-----------------|-----------------|----|----|----|----|-----|
| 770             | 722             | 91 | 84 | 48 | 7  | 0.94 |

To demonstrate resilience to obfuscation, we applied a set of well-known code transformation techniques to the ADRD malware samples using the implementation provided in [2, 12]. These techniques include disassembling & reassembling, repacking, changing package names, identifier renaming, data encoding, transforming manifests, call indirections, code reordering, defunct methods, and junk code insertion. The detection performance remained unchanged, with FormalDroid correctly identifying 84 out of 91 ADRD samples.

We measured FormalDroid's performance using the `System.currentTimeMillis()` Java method, which returns the current time in milliseconds. Table 3 shows the performance of our method, considering the overall time to analyze a sample as the sum of two contributions: the average time required to extract the class files of the application using the dex2jar tool (`tdex2jar`) and the time required to obtain the response from FormalDroid (`tresponse`).

| tdex2jar | tresponse | Total Time |
|----------|-----------|------------|
| 9.8471 s | 242.1838 s | 252.0309 s |

The experiments were conducted on an Intel Core i5 desktop with 4 GB RAM, running Microsoft Windows 7 (64-bit).

### Conclusions and Future Work

In this paper, we propose FormalDroid, a tool capable of detecting Android malware behaviors and localizing the malicious payload in the application code. We evaluated our tool by analyzing the ADRD family, achieving an accuracy of 0.94. As future work, we plan to extend the experiments to other widespread malware families to further validate and enhance our rule set.

### Acknowledgements

This work was partially supported by H2020 EU-funded projects NeCS and C3ISP and EIT-Digital Project HII.

### References

[1] F. Mercaldo, V. Nardone, A. Santone, and C. A. Visaggio, “Ransomware steals your phone. formal methods rescue it,” in International Conference on Formal Techniques for Distributed Objects, Components, and Systems, pp. 212–221, Springer, 2016.

[2] V. Rastogi, Y. Chen, and X. Jiang, “Droidchameleon: evaluating android anti-malware against transformation attacks,” in Proceedings of the 8th ACM SIGSAC symposium on Information, computer and communications security, pp. 329–334, ACM, 2013.

[3] R. Milner, Communication and concurrency. PHI Series in computer science, Prentice Hall, 1989.

[4] C. Stirling, “An introduction to modal and temporal logics for ccs,” in Concurrency: Theory, Language, And Architecture (A. Yonezawa and T. Ito, eds.), LNCS, pp. 2–20, Springer, 1989.

[5] R. Cleaveland and S. Sims, “The ncsu concurrency workbench,” in CAV (R. Alur and T. A. Henzinger, eds.), vol. 1102 of Lecture Notes in Computer Science, Springer, 1996.

[6] L. Deshotels, V. Notani, and A. Lakhotia, “Droidlegacy: Automated familial classification of android malware,” in Proceedings of ACM SIGPLAN on Program Protection and Reverse Engineering Workshop 2014, PPREW’14, (New York, NY, USA), pp. 3:1–3:12, ACM, 2014.

[7] G. Suarez-Tangil, J. E. Tapiador, P. Peris-Lopez, and J. Blasco, “Dendroid: A text mining approach to analyzing and classifying code structures in android malware families,” Expert Syst. Appl., vol. 41, pp. 1104–1117, Mar. 2014.

[8] Y. Feng, S. Anand, I. Dillig, and A. Aiken, “Apposcopy: Semantics-based detection of android malware through static analysis.”

[9] G. Canfora, F. Mercaldo, and C. A. Visaggio, “An hmm and structural entropy based detector for android malware,” Comput. Secur., vol. 61, pp. 1–18, Aug. 2016.

[10] S. Alam, R. Riley, I. Sogukpinar, and N. Carkaci, “Droidclone: Detecting android malware variants by exposing code clones,” in 2016 Sixth International Conference on Digital Information and Communication Technology and its Applications (DICTAP), pp. 79–84, July 2016.

[11] D. Arp, M. Spreitzenbarth, M. Huebner, H. Gascon, and K. Rieck, “Drebin: Efficient and explainable detection of android malware in your pocket,” in Proceedings of 21st NDSS, IEEE, 2014.

[12] M. Zheng, P. P. Lee, and J. C. Lui, “Adam: an automatic and extensible platform to stress test android anti-virus systems,” in International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pp. 82–101, Springer, 2012.