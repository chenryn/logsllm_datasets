### Using the Same Technique to Enhance GFS Specification

We applied the same technique to reduce a GFS specification, incorporating specific assumptions, to GFS SS (GFS SimpleStore). GFS SS extends Niobe SS as follows: A `read()` in GFS SS can return one of three values:
1. The value from `SerialDB`.
2. A value from pending `wrreq` or `pending wrresp`.
3. A dropped write.

These semantics, while weaker than linearizability, are stronger than safe semantics [12]. The proof for this is straightforward [8].

Using formal methods, we identified two assumptions that upgrade GFS' consistency guarantees to well-understood regular register semantics. This finding provides clarity on GFS' consistency model, which was difficult to grasp from the original paper.

### Inspecting Alternative Designs

In the previous sections, we demonstrated how formal methods can aid in understanding and comparing the mechanisms and consistency properties of fault-tolerant file systems. Our experience indicates that formal methods can also be valuable during the design phase. They allow designers to evaluate alternative designs comfortably. To inspect the effects of an alternative design on consistency, a system builder only needs to modify the specification and re-check the refinement mapping to verify if the system still implements its SimpleStore.

Using our framework (consisting of TLA+ specifications, SimpleStores, and refinement mappings), we experimented with a simple design alternative for Niobe. One key difference between Niobe and GFS is that Niobe directs all reads and writes to the same primary, while GFS allows any replica to answer a read request. This "read-any" policy in GFS significantly enhances read throughput by distributing bandwidth across distinct replicas.

To explore the impact of adopting GFS' read-any policy in Niobe, we modeled a scenario where Niobe employs this policy. Without additional mechanisms, Niobe would no longer be linearizable, as it would admit behaviors similar to those shown for GFS in Figure 5. However, our model-checking results show that Niobe with the read-any policy must offer regular register semantics.

An interesting follow-up question is whether Niobe, with the read-any policy, can simplify or eliminate some of its mechanisms (e.g., reconciliation at primary take-over) without losing its regular-register status. This question highlights a new area for exploration enabled by our framework and represents an interesting point for future work.

### Related Work

Formal modeling and methods have long been used to reason about software [3, 4] and hardware [11, 17]. We leverage these techniques and apply them to several fault-tolerant file systems. While formal methods are widely used in hardware design [11], they have not yet been adopted as a general practice in fault-tolerant file systems. By sharing our experience, we aim to convince builders of the utility and practicality of formally specifying their systems.

Our work is not the first to pursue this goal. Many previous works have reported on the benefits of applying formal methods to various systems, such as caches [11], space shuttle software [6], online transaction processing systems [10], and local and distributed file systems [18, 20, 21]. Our work demonstrates how and why to apply several formal methods to another important domain: enterprise fault-tolerant, replicated file systems. From this body of previous works, the closest to ours are those presenting formal modeling case studies for local or distributed file systems (e.g., Coda, AFS) [18, 20, 21]. Fault-tolerant file systems differ in that they include complex mechanisms like automatic reconfiguration and recovery. We believe our study will have a significant impact in this specific domain.

Some works [2, 18] introduce new formal frameworks specifically designed for modeling file systems. However, these specialized frameworks do not support model checking, requiring manual proofs. In contrast, we use generic formalisms that enable automatic verifications.

The technique of reducing complex systems to simple models to reason about consistency has been used before [11, 19]. The storage service model introduced in [19] is a valid abstraction, but its use of histories makes it unsuitable for model checking.

### Conclusions and Lessons Learned

We have shared our experience with applying formal methods to analyze and compare three real-world fault-tolerant file systems. Here are four key lessons learned:

1. **Moderate Detail in TLA+ Specifications**: Moderately detailed TLA+ specifications of real systems are not as challenging to produce as initially thought. For example, a student wrote a functional specification for GFS in about two weeks. While more in-depth specifications take more time, writing a high-level specification is a manageable and highly useful task for understanding the system.

2. **Similarities in Seemingly Dissimilar Systems**: Writing TLA+ specifications revealed similarities in seemingly dissimilar systems. For GFS and Niobe, we factored out common mechanisms into one abstraction. This common TLA+ specification can facilitate building specifications for other primary-secondary-master systems (e.g., Boxwood [15]).

3. **Insightful Semantic Comparison**: Formal specifications enable insightful semantic comparisons, even between strongly and weakly consistent systems. By building client-centric models and comparing them, we better understood system behavior and reached several conclusions:
   - Niobe and Chain perform similarly from a client perspective, implementing similar client-centric models.
   - GFS can be upgraded to regular register semantics via a clear set of assumptions.
   - GFS' decision to read from any replica for performance heavily influences its consistency model. If Niobe adopted this decision, its consistency model would degrade from linearizability to regular-register.

4. **Intuition vs. Formal Verification**: Intuition can often be unreliable, and formal verification is essential. For example, after verifying that Chain implemented Chain SimpleStore, we mistakenly believed the same model was correct for Niobe, missing one type of transition. Several iterations were needed to arrive at the correct model (Niobe SS).

Our practical experience shows that formal specifications and methods are valuable tools for designing, analyzing, and comparing fault-tolerant file systems. These tools help increase trust in the behavior of these critical infrastructure components, especially in the presence of failures.

### Acknowledgments

We thank Hank Levy and Chandu Thekkath for their valuable comments on the paper, and Idit Keidar, Dahlia Malkhi, and Yuan Yu for their ideas during our work. We also thank the anonymous reviewers for their valuable comments. This work was primarily conducted during an internship at Microsoft Research. Roxana Geambasu is supported in part by National Science Foundation Grant NSF-614975.

### References

[1] M. Abadi and L. Lamport. The existence of refinement mappings. Theoretical Computer Science, 1991.
[2] K. Bhargavan, M. Shapiro, and F. le Fessant. Modelling replication protocols with actions and constraints, 2003.
[3] M. Bickford and D. Guaspari. Formalizing the chain replication protocol. http://www.cs.cornell.edu/Info/Projects/NuPrl/FDLcontentAUXdocs/ChainRepl, 2006.
[4] D. Chkliaev, P. van der Stok, and J. Hooman. Formal modeling and analysis of atomic commitment protocols. In Proc. of the Conference on Parallel and Distributed Systems, 2000.
[5] E. Clarke and J. Wing. Formal methods: state of the art and future directions. ACM Computing Surveys, 28(4), 1996.
[6] J. Crow and B. D. Vito. Formalizing space shuttle software requirements: four case studies. ACM Transactions on Software Engineering and Methodology, 7(3), 1998.
[7] G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman, A. Pilchin, S. Sivasubramanian, and W. V. P. Vosshall. Dynamo: Amazonâ€™s highly available key-value store. In Proc. of ACM SOSP, 2007.
[8] R. Geambasu, A. Birrell, and J. MacCormick. TLA+ Specifications and Proofs for Niobe, GFS, and Chain. http://cs.washington.edu/homes/roxana/fm/, 2007.
[9] S. Ghemawat, H. Gobioff, and S. Leung. The Google File System. In Proc. of ACM SOSP, 2003.
[10] I. Houston and S. King. CICS project report: Experiences and results from using Z. In Proc. of Formal Development Methods, 1991.
[11] R. Joshi, L. Lamport, J. Matthews, S. Tasiran, M. Tuttle, and Y. Yu. Checking cache-coherence with TLA+. Formal Methods in System Design, 2003.
[12] L. Lamport. On interprocess communication. Distributed Computing, 1986.
[13] L. Lamport. Specifying Systems. Addison Wesley, 2003.
[14] L. Lamport, Y. Yu, and L. Zhang. TLA+ tools. http://research.microsoft.com/research/sv/TLA Tools, 2007.
[15] J. MacCormick, N. Murphy, M. Najork, C. Thekkath, and L. Zhou. Boxwood: Abstractions as the foundation for storage infrastructure. In Proc. of OSDI, 2004.
[16] J. MacCormick, C. Thekkath, M. Jager, K. Roomp, L. Zhou, and R. Peterson. Niobe: A practical replication protocol. ACM Trans. Storage, 2008.
[17] K. Shimizu and D. Dill. Using formal specifications for functional validation of hardware designs. IEEE Des. Test, 2002.
[18] M. Sivathanu, A. Arpaci-Dusseau, R. Arpaci-Dusseau, and S. Jha. A logic of file systems. In Proc. of the USENIX Conference on File and Storage Technologies, 2005.
[19] R. van Renesse and F. Schneider. Chain replication for high throughput and availability. In Proc. of OSDI, 2004.
[20] J. Wing and M. Vaziri. A case study in model checking software systems. Science of Computer Programming, 1997.
[21] J. Yang, P. Twohey, D. Engler, and M. Musuvathi. Using model checking to find serious file system errors. In Proc. of OSDI, 2004.