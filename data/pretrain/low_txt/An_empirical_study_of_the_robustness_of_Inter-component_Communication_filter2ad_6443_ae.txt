### Fields and Footprint Increase

We argue that the calculated footprint increase is, in fact, an upper bound. This assertion is based on our consideration of an average of 4-6 fields per Intent. In reality, most Intents contain only 2-3 fields, with a few, such as informative Intents like Battery Status, having a larger number of fields.

### Java Annotations

One method to express additional constraints about the message format when using the subtyping approach is through Java Annotations. Annotations are fully integrated into the language (since Java 1.5) and can be processed by the Java compiler. Therefore, it is possible to use annotations at compile time for criteria that are amenable to static checking. For dynamic checks, the corresponding code can either be implemented as a generic checker facility within the Intent delivery mechanism of the platform or synthesized and injected into Intent receivers.

### IDL and Domain-Specific Language (DSL)

Extended input validation requires additional knowledge about the message format due to the significant semantic gap between the implicit message format and what can be explicitly expressed by classes and the Java type system. For example, an Intent responsible for a contact lookup might need to perform approximate matching and return contact names along with a matching factor between zero and one. In the Java type system, this would require using a float type, thereby extending the range of permitted values to the entire IEEE 754 floating-point number range. Another issue is that every reference type can be set to null, making it impossible to express mandatory data in messages. A more expressive solution is to use a domain-specific language (DSL) to define the schema of the Intents.

Historically, many RPC systems have used an interface definition language (IDL) to describe the format of remote invocations in detail, allowing the synthesis of stub and skeleton code. Systems like CORBA extensively used IDLs, and web services also employ similar principles, such as WSDL files. A type system like XML Schema, which allows value restrictions, is a viable candidate for a DSL approach to specifying Intents. A well-designed DSL can express any type of constraint, enabling full input validation, including version checks.

There are two ways to interface general-purpose languages with domain-specific languages: external DSLs and internal or embedded DSLs. External DSLs are standalone and independent of the host language, but this means that code written in the host language and metadata written in the DSL must be developed separately and cannot be easily cross-validated by existing tools. Internal or embedded DSLs, on the other hand, are implemented in the host language and integrate better with existing tools, but they are limited by the host language's capabilities.

### Related Work

Robustness evaluation of software systems is broadly categorized into functional and exceptional testing. Functional testing involves generating expected test inputs to check the functionality of a software module, while exceptional testing uses specially crafted inputs to crash the system and test its robustness. Generated input test data can be random (pure fuzzing), semi-valid (intelligent fuzzing), or a combination. Miller et al. [6] first applied fuzzing to UNIX utilities by feeding them random inputs, revealing that 25-33% of utility programs either crashed or hung on different versions of UNIX. This simple technique has uncovered various bugs, including buffer overflows, unhandled exceptions, read access violations, thread hangs, and memory leaks. Later work by the authors [7] showed that the robustness of UNIX utilities improved little over five years. Similar studies on Windows NT and Windows 2000 [8] and MacOS [9] reported varying failure rates. Our research extends these works to a mobile platform, where we fuzz the ICC of Android and identify a variety of exception handling errors.

In terms of knowledge about the target application (whitebox vs. blackbox testing), our tool takes a combined approach, using blackbox testing for explicit Intents and whitebox testing for implicit Intents. Fuzzing tools can be classified based on their input generation techniques (generation-based or mutation-based) and their intrusiveness. Our tool, JJB, is a generation-based fuzzer that generates Intents conforming to Android Intent API specifications. JJB is also intelligent, with knowledge of Android APIs and partial knowledge of the target applications.

Fuzz testing has been employed in various domains, including web applications, web servers, web browsers [24], Java-based applications [25], and SMS systems [26]. Fu et al. [25] presented an approach for compiler-assisted fault generation to test error recovery codes in Java server applications, which is complementary to our work. JarJarBinks can additionally test Android market apps for which source code may not be available. We do not know of any rigorous study of fuzz testing on smartphones, but the closest work is [26], which fuzzes messages in the mobile telephony stack, uncovering vulnerabilities in SMS implementations.

A malformed Intent delivered through ICC exposes attack surfaces, such as triggering components unintentionally exported by a developer or unauthorized receipt of an implicit Intent by a malicious component. ComDroid [13], a static analysis tool, detects these vulnerabilities. Our approach narrows down these attack surfaces to input validation errors through runtime testing, though actual exploitation may require combining these with other vulnerabilities (e.g., improper permission assignment). Our work does not provide exploits but discovers vulnerabilities in application components.

Other work on Android security has focused on permission assignment, misuse of sensitive information [27], and future directions for application certification [28]. Our work does not directly detect privacy leaks but can inform good application design practices, particularly in input validation, which can be incorporated into an application certification process aimed at improving robustness.

### Conclusion and Future Work

In this paper, we conducted extensive robustness testing on Android's Inter-component Communication (ICC) mechanism by sending a large number of semi-valid and random Intents to various components across three versions of Android. Key findings include: 1) Many components in Android have faulty exception handling code, with NullPointerExceptions being the most commonly neglected, 2) It is possible to crash Android runtime by sending Intents from a user-level process in Android 2.2, and 3) Across various versions of Android, 4.0 is the most robust in terms of exception handling but displays many environment-dependent failures.

Based on our observations, we recommend that any component running as a thread in a privileged process should be guarded by explicit permissions. We also propose several enhancements to harden the implementation of Intents, including subtyping in combination with Java annotations. Future work will explore whether detected failures can be exploited by attackers, specifically whether these failures can be triggered by an adversary without physical access to the phone. Robustness evaluation of Binder IPC in Android is another future goal.

### References

[1] D. Gross, “Fallout continues over smartphone tracking app,” December 2011. [Online]. Available: http://www.edition.cnn.com/2011/12/02/tech/mobile/carrier-iq-reactions/

[2] K. LaCapria, “iPhone explodes in midair on Aussie flight,” November 2011. [Online]. Available: http://www.inquisitr.com/163661/iphone-explodes-in-midair-on-aussie-flight/

[3] T. Lee, “AT&T’s Samsung Galaxy S2 security flaw lets you bypass the lock screen,” October 2011. [Online]. Available: http://www.uberphones.com/2011/10/atts-samsung-galaxy-s2-security-flaw-lets-you-bypass-the-lock-screen/

[4] D. Ben, “Google Android passes 50% of smartphone sales, Gartner says,” November 2011. [Online]. Available: http://www.businessweek.com/news/2011-11-17/google-android-passes-50-of-smartphone-sales-gartner-says.html

[5] R. Golijan, “Fridge magnet poses security threat to iPad 2,” April 2012. [Online]. Available: http://www.technolog.msnbc.msn.com/technology/technolog/fridge-magnet-poses-security-threat-ipad-2-119905

[6] B. P. Miller, L. Fredriksen, and B. So, “An empirical study of the reliability of Unix utilities,” Commun. ACM, vol. 33, pp. 32 – 44, December 1990.

[7] B. P. Miller, D. Koski, C. Pheow, L. V. Maganty, R. Murthy, A. Natarajan, and J. Steidl, “Fuzz revisited: A re-examination of the reliability of Unix utilities and services,” University of Wisconsin-Madison, Tech. Rep., 1995.

[8] J. E. Forrester and B. P. Miller, “An empirical study of the robustness of Windows NT applications using random testing,” in Proceedings of the 4th conference on USENIX Windows Systems Symposium - Volume 4. Berkeley, CA, USA: USENIX Association, 2000.

[9] B. P. Miller, G. Cooksey, and F. Moore, “An empirical study of the robustness of macOS applications using random testing,” SIGOPS Oper. Syst. Rev., vol. 41, pp. 78 – 86, January 2007.

[10] P. Koopman and J. DeVale, “The exception handling effectiveness of POSIX operating systems,” Software Engineering, IEEE Transactions on, vol. 26, no. 9, pp. 837 – 848, September 2000.

[11] “Dalvik virtual machine,” 2008. [Online]. Available: http://www.dalvikvm.com/

[12] Y. Shi, K. Casey, M. A. Ertl, and D. Gregg, “Virtual machine showdown: Stack versus registers,” ACM Trans. Archit. Code Optim., vol. 4, pp. 153 – 163, January 2008.

[13] E. Chin, A. P. Felt, K. Greenwood, and D. Wagner, “Analyzing inter-application communication in Android,” in Proceedings of the 9th international conference on Mobile systems, applications, and services, ser. MobiSys ’11. New York, NY, USA: ACM, 2011, pp. 239 – 252.

[14] “What is Android?” [Online]. Available: http://developer.android.com/guide/basics/what-is-android.html

[15] “Intent fuzzer.” [Online]. Available: http://www.isecpartners.com/mobile-security-tools/intent-fuzzer.html

[16] “Intent class overview.” [Online]. Available: http://developer.android.com/reference/android/content/Intent-.html

[17] B. Beizer, Black-Box Testing: Techniques for Functional Testing of Software and Systems. Verlag John Wiley & Sons, Inc, 1995.

[18] P. Godefroid, M. Y. Levin, and D. A. Molnar, “Automated whitebox fuzz testing,” in Network Distributed Security Symposium (NDSS). Internet Society, 2008.

[19] J. DeMott, “The evolving art of fuzzing,” June 2006. [Online]. Available: http://www.vdalabs.com/tools/

[20] P. Godefroid, “Random testing for security: blackbox vs. whitebox fuzzing,” in Proceedings of the 2nd international workshop on Random testing: co-located with the 22nd IEEE/ACM International Conference on Automated Software Engineering (ASE 2007), ser. RT ’07. New York, NY, USA: ACM, 2007.

[21] P. Oehlert, “Violating assumptions with fuzzing,” Security Privacy, IEEE, vol. 3, no. 2, pp. 58 – 62, March-April 2005.

[22] J. Neystadt, “Automated penetration testing with white-box fuzzing,” February 2008. [Online]. Available: http://msdn.microsoft.com/en-us/library/cc162782.aspx

[23] A. Johansson, N. Suri, and B. Murphy, “On the selection of error model(s) for OS robustness evaluation,” in Dependable Systems and Networks, 2007. DSN ’07. 37th Annual IEEE/IFIP International Conference on, June 2007, pp. 502 –511.

[24] M. Sutton, A. Greene, and P. Amini, Fuzzing: Brute Force Vulnerability Discovery. Addison-Wesley Professional, 2007.

[25] C. Fu, A. Milanova, B. Ryder, and D. Wonnacott, “Robustness testing of Java server applications,” Software Engineering, IEEE Transactions on, vol. 31, no. 4, pp. 292 – 311, April 2005.

[26] C. Mulliner and C. Miller, “Injecting SMS messages into smartphones for security analysis,” in Proceedings of the 3rd USENIX conference on Offensive technologies, ser. WOOT’09. Berkeley, CA, USA: USENIX Association, 2009.

[27] W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri, “A study of Android application security,” in Proceedings of the 20th USENIX conference on Security, ser. SEC’11. Berkeley, CA, USA: USENIX Association, 2011.

[28] W. Enck, M. Ongtang, and P. McDaniel, “On lightweight mobile phone application certification,” in Proceedings of the 16th ACM conference on Computer and communications security, ser. CCS ’09. New York, NY, USA: ACM, 2009, pp. 235 – 245.

Authorized licensed use limited to: Tsinghua University. Downloaded on March 19, 2021 at 07:17:27 UTC from IEEE Xplore. Restrictions apply.