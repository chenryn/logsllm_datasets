### Introduction

The interconnection between normal and abnormal log sequences leads to a low repetitiveness in the relative ratio of these sequences. This poses a challenge for state-of-the-art methods like LogRobust, DeepLog, and CNN, which directly model log sequences. These methods struggle with unstable sequences, particularly when the availability of target-system log labels is limited. To address this, methods can be categorized into supervised and unsupervised approaches. Supervised methods, such as Logistic Regression (LR) and Decision Trees (DT), require labeled data from the target system. Unsupervised methods, on the other hand, do not need labeled data, making them more practical for large-scale systems where labeling is expensive.

### Supervised Methods

In one of the earliest applications, Bodik et al. [27] used Logistic Regression (LR) to detect anomalies in data centers by treating the problem as a binary classification task. Similarly, Decision Trees (DT) [9] were employed to detect anomalous web requests from access logs. Both methods start by parsing logs to extract events and then use count vectors in fixed time intervals as input samples.

Recent advances in deep learning have led to the development of several supervised deep-learning-based methods, such as LogRobust [11] and CNN [12]. LogRobust uses an LSTM architecture augmented with attention mechanisms, which are popular for sequence modeling. As input, it receives a sequence of events and predicts whether the observed sequence is anomalous or not. By incrementally sliding over the log sequences, it can predict single log lines [8]. Additionally, LogRobust uses vector embeddings from general-purpose languages to represent logs.

Luet al. [12] use Convolutional Neural Networks (CNNs) to learn normal and abnormal sequences from template indices. Similar to LogRobust, CNNs can detect anomalies from a single log. Despite their strong detection performance, the frequent software updates and the large volume of produced logs make the labeling process expensive, rendering supervised methods impractical in many cases [6].

### Unsupervised Methods

Unsupervised methods, in contrast, do not assume the existence of labeled data, which eliminates the need for expensive labeling. One of the earliest works on unsupervised anomaly detection was by Xu et al. [10], who applied Principal Component Analysis (PCA) to learn the normal state of event counts by projecting them into a vector space. In the test phase, a sample is reported as an anomaly if its projection significantly deviates from the learned normal state.

Lin et al. [4] introduced LogCluster, which uses the TF-IDF algorithm for sequence representation. It constructs a knowledge base of normal and anomalous sequence clusters through agglomerative clustering and human-based cluster labeling. A test sample is detected as an anomaly if it is clustered into an anomalous cluster.

DeepLog [8] and LogAnomaly [29] are two popular unsupervised deep learning-based methods. They introduce an auxiliary task called "next event prediction" (NEP), which forecasts the most probable next event given a sequence of events. The labels for NEP originate from the input data itself, making the methods unsupervised. Sequences with incorrect predictions for the next event are considered anomalous. DeepLog uses an LSTM architecture to learn the normal state, while LogAnomaly includes additional features such as log semantics and event counts in joint training.

### Experimental Results

To evaluate the impact of hyperparameters on detection performance and efficiency, we examined the model and batch sizes using the BGL-sin dataset. The experimental results, shown in Fig. 3, indicate that larger batch sizes and smaller model sizes provide better detection performance while being faster for updating. For instance, the prediction time per batch size of 512 is 17 ms (approximately 30,000 logs per second). These experiments suggest that ADLILog has desirable practical properties, including efficient model updates and small model sizes.

### Conclusion

This paper addresses the problem of automating log-based anomaly detection, a crucial maintenance task for enhancing the reliability of IT systems. It introduces ADLILog, a novel unsupervised method for log anomaly detection. ADLILog leverages the unstructured information from logging instructions in over 1,000 GitHub public code projects to improve the target-system log representations, thereby enhancing anomaly detection. Extensive experimental results on common benchmark datasets show that ADLILog outperforms related methods: 5-24% better than supervised methods and 40-63% better than unsupervised methods in terms of F1 score. Further experiments demonstrate that ADLILog has practical benefits, including time-efficient model updates and small model sizes. This study highlights the value of using large unstructured information to aid the automation of IT operations. Future work will explore how to apply SL data for higher-order IT operational tasks, such as failure identification and root-cause analysis.

### References

[1] P. Notaro, J. Cardoso, and M. Gerndt, “A survey of AIOPS methods for failure management,” ACM Trans. Intell. Syst. Technol., vol. 12, 2021.
[2] W. Meng, Y. Liu, S. Zhang, F. Zaiter, Y. Zhang, Y. Huang, Z. Yu, Y. Zhang, L. Song, M. Zhang, and D. Pei, “LogClass: Anomalous log identification and classification with partial labels,” IEEE Trans. Netw., vol. 18, pp. 1870–1884, 2021.
[3] H. Li, W. Shang, B. Adams, M. Sayagh, and A. E. Hassan, “A qualitative study of the benefits and costs of logging from developers’ perspectives,” IEEE Transactions on Software Engineering, pp. 1–17, 2020.
[4] Q. Lin, H. Zhang, J.-G. Lou, Y. Zhang, and X. Chen, “Log clustering based problem identification for online service systems,” in Proceedings of the 38th ICSE. New York, NY, USA: Association for Computing Machinery, 2016, p. 102–111.
[5] S. He, P. He, Z. Chen, T. Yang, Y. Su, and M. R. Lyu, “A survey on automated log analysis for reliability engineering,” ACM Comput. Surv., vol. 54, 2021.
[6] S. He, J. Zhu, P. He, and M. R. Lyu, “Experience report: System log analysis for anomaly detection,” in 2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE). New York, USA: IEEE, 2016, pp. 207–218.
[7] Z. Chen, J. Liu, W. Gu, Y. Su, and M. R. Lyu, “Experience report: Deep learning-based system log analysis for anomaly detection,” CoRR, vol. 2107.05908, 2021.
[8] M. Du, F. Li, G. Zheng, and V. Srikumar, “DeepLog: Anomaly detection and diagnosis from system logs through deep learning,” in Proceedings of the 2017 ACM SIGSAC. New York, NY, USA: Association for Computing Machinery, 2017, p. 1285–1298.
[9] M. Chen, A. Zheng, J. Lloyd, M. Jordan, and E. Brewer, “Failure diagnosis using decision trees,” in International Conference on Autonomic Computing, 2004. Proceedings., 2004, pp. 36–43.
[10] W. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, “Detecting large-scale system problems by mining console logs,” in Proceedings of the ACM 22nd SOSP. New York, NY, USA: Association for Computing Machinery, 2009, p. 117–132.
[11] X. Zhang and et al., “Robust log-based anomaly detection on unstable log data,” in Proceedings of the 2019 27th ACM Joint Meeting on ESEC/FSE. New York, NY, USA: Association for Computing Machinery, 2019, p. 807–817.
[12] S. Lu, X. Wei, Y. Li, and L. Wang, “Detecting anomaly in big data system logs using convolutional neural network,” in IEEE 16th Conf on Dependable, Autonomic and Secure Computing, 2018, pp. 151–158.
[13] T. Li, Y. Jiang, C. Zeng, B. Xia, Z. Liu, W. Zhou, X. Zhu, W. Wang, L. Zhang, J. Wu, L. Xue, and D. Bao, “FLAP: An end-to-end event log analysis platform for system management,” in Proceedings of the 23rd ACM SIGKDD International Conference on KDD. New York, NY, USA: Association for Computing Machinery, 2017, p. 1547–1556.
[14] X. Li, P. Chen, L. Jing, Z. He, and G. Yu, “SwissLog: Robust and unified deep learning based log anomaly detection for diverse faults,” in 2020 IEEE 31st ISSRE, 2020, pp. 92–103.
[15] T.-H. Chen, S. W. Thomas, and A. E. Hassan, “A survey on the use of topic models when mining software repositories,” Empirical Softw. Engg., vol. 21, p. 1843–1919, 2016.
[16] M. Honnibal, I. Montani, S. Van Landeghem, and A. Boyd, “spaCy: Industrial-strength Natural Language Processing in Python,” Explosion.ai. [Online]. Available: https://doi.org/10.5281/zenodo.1212303
[17] P. He, Z. Chen, S. He, and M. R. Lyu, “Characterizing the natural language descriptions in software logging statements,” in Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. New York, NY, USA: Association for Computing Machinery, 2018, p. 178–189.
[18] T. M. Cover and J. A. Thomas, Elements of Information Theory. USA: Wiley-Interscience, 2006.
[19] J. Zhu, S. He, J. Liu, P. He, Q. Xie, Z. Zheng, and M. R. Lyu, “Tools and benchmarks for automated log parsing,” in Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice. NY, USA: IEEE Press, 2019, p. 121–130.
[20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in Advances in Neural Information Processing Systems. Red Hook, NY, USA: Curran Associates, 2017, p. 6000–6010.
[21] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of deep bidirectional transformers for language understanding,” in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics. Minneapolis, Minnesota: Association for Computational Linguistics, 2019, pp. 4171–4186.
[22] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. MIT Press, 2016. [Online]. Available: http://www.deeplearningbook.org
[23] W. Liu, Y.-M. Zhang, X. Li, Z. Yu, B. Dai, T. Zhao, and L. Song, “Deep hyperspherical learning,” in Proceedings of the 31st International Conference on NeurIPS. Red Hook, NY, USA: Curran Associates Inc., 2017, p. 3953–3963.
[24] L. Ruff, J. R. Kauffmann, R. A. Vandermeulen, G. Montavon, W. Samek, M. Kloft, T. G. Dietterich, and K.-R. Müller, “A unifying review of deep and shallow anomaly detection,” Proceedings of the IEEE, vol. 109, no. 5, pp. 756–795, 2021.
[25] P. He, J. Zhu, Z. Zheng, and M. R. Lyu, “Drain: An online log parsing approach with fixed depth tree,” in 2017 IEEE International Conference on Web Services. NY, USA: Curran Associates, 2017, pp. 33–40.
[26] A. Oliner and J. Stearley, “What supercomputers say: A study of five system logs,” in 37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks. Los Alamitos, CA, USA: IEEE Computer Society, 2007, pp. 575–584.
[27] P. Bodik, M. Goldszmidt, A. Fox, D. B. Woodard, and H. Andersen, “Fingerprinting the data center: Automated classification of performance crises,” in Proceedings of the 5th European Conference on Computer Systems. New York, NY, USA: ACM, 2010, p. 111–124.
[28] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” in 3rd International Conference on Learning Representations, 2015.
[29] W. Meng and et al., “LogAnomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs,” in Proceedings of the 28, IJCAI-19. IJCAI, 2019, pp. 4739–4745.
[30] S. Nedelkoski, J. Bogatinovski, A. Acker, J. Cardoso, and O. Kao, “Self-attentive classification-based anomaly detection in unstructured logs,” CoRR, 2020. [Online]. Available: https://arxiv.org/abs/2008.09340
[31] Y. Zhu, W. Meng, Y. Liu, S. Zhang, T. Han, S. Tao, and D. Pei, “UniLog: Deploy one model and specialize it for all log analysis tasks,” 2021.