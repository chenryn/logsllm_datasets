### Issues with the Use of Middle Guards

The primary concern with employing middle guards is that traffic will not be as effectively load-balanced. This issue arises due to three main reasons:

1. **Capacity Mismatch**: The capacity of an entry guard is typically higher than that of its middle guards.
2. **Traffic Concentration**: Traffic from different services may inadvertently concentrate on specific middle relays, creating "hot spots."
3. **New Relay Integration**: New relays joining the network may not be quickly chosen as middle guards.

#### Mitigation Strategies

**1. Capacity Mismatch (i)**

This can be mitigated by setting a sufficiently large value for \(a_m\). For instance, using the 6/30/2013 consensus data, the observed bandwidth of relays, weighted by their probability of being selected as an entry guard, was 9669.89 KiB/s, while the observed relay bandwidth, weighted by the probability of selection as a middle relay, was 7721.50 KiB/s. By setting \(a_m \geq 2\), we can prevent middle-guard bottlenecks in expectation. Additionally, the load from all traffic other than hidden services would continue to be balanced as usual, making the capacities available to hidden-service traffic more similar between guard and middle relays.

**2. Traffic Concentration (ii) and New Relay Integration (iii)**

Both of these issues can be addressed by ensuring that the average middle-guard expiration period is short enough to prevent the development of hot spots and to facilitate the quick use of new relays. Middle guards need only slow down guard discovery to the speed of other known methods for identifying guards, such as throughput fingerprinting [33] or the long-path congestion attack [23], which are effective within hours. However, the complexity and resource cost of these methods are significantly higher than passive observation at a relay, so the speeds of the attacks do not need to be equalized. Since most Tor traffic continues to be effectively load-balanced, the net imbalance from middle guards is likely to be minimal.

### Defense Offered by Middle Guards

Middle guards provide a defense against adversaries running malicious relays who aim to quickly discover hidden-service entry guards by sending many rendezvous requests. Instead, an adversary trying to directly observe the entry guard must wait to be selected either as the entry guard itself or as a middle guard. With \(a_m\) middle guards and an average expiration of \(e = \frac{e_0 + e_1}{2}\) days, an adversary with a probability \(p\) of being selected as a relay will expect to wait \(\left( \frac{1}{1 - (1 - p)^{a_g}} - 1 \right)e\) days until being selected as the middle guard of some entry guard.

For example, if \(a_g = 1\), \(a_m = 2\), \(e_0 = 30\), \(e_1 = 60\) (i.e., middle-guard expiration is the same as current entry-guard expiration), and \(p = 0.021\) (the largest middle-relay selection probability on 6/30/13), the expected time for the adversary to be selected as a middle guard is approximately 1037.79 days.

### Related Work

#### Internet DoS Attacks

DoS attacks, which make an internet service unavailable for longer than the intended waiting time [45], have been extensively studied. Although unique, the Sniper Attack is most closely related to low-rate and slow-read DoS attacks, which are variants of the well-known SYN flood DoS attack [20, 40]. These attacks aim to exhaust resources to prevent the victim from processing new incoming connection requests.

- **Transport Layer Low-Rate Attacks** [30]: Exploit TCP's retransmission timeout (RTO) dynamics. An attacker sends short, high-rate packet bursts, causing packet losses and increasing the RTO of other TCP connections.
- **Transport Layer Slow-Read Attacks** [26]: Send legitimate data requests, advertise a small TCP receive window, and slowly empty the receive buffer, keeping the victim’s send buffer full and blocking resources.
- **Application Layer Attacks** [2, 14, 38]: Prolong HTTP sessions by sending partial HTTP requests or slowly reading responses, reducing the availability of the web server’s connection pool.

While the Sniper Attack shares the goal of preventing new incoming connections, it achieves this by exhausting system memory resources using valid overlay network protocol messages without reading from the victim. Unlike the attacks described above, it does not require several simultaneous connections to the target and continued effort to maintain the effect. It also destroys existing established connections in addition to preventing new ones.

#### Permanent DoS Attacks

The Sniper Attack can be categorized as a permanent DoS attack, exploiting application layer overlay network protocol semantics to consume system memory and crash the process. It differs from similar attacks, such as the Ping of Death [29], in that it uses valid messages to exploit the protocol design, making it more challenging to fix.

#### Misbehaving Receivers and Optimistic ACKs

Our attack is similar to those that rely on misbehaving receivers and optimistic ACKs to bypass flow control protocol mechanisms [9, 39, 41]. Specifically, the opt-ACK attack [41] adjusts a feedback signal rate to appear legitimate. Our attack targets application layer protocols of overlay networks to exhaust available memory, rather than consuming available bandwidth.

#### DoS Attacks on Tor

DoS attacks against the Tor overlay network have been studied, building on the fundamental observation by Syverson et al. [42] that if the first and last relay along a Tor path are compromised, an adversary can link the source and destination by correlating traffic patterns. Øverlier and Syverson [34] demonstrated how an adversary could inflate the probability of being selected for a hidden service circuit by lying about the available bandwidth of compromised relays. Bauer et al. [11] extended this attack to increase the probability of end-to-end compromise of general-purpose circuits. Borisov et al. [13] described a selective DoS attack where malicious relays terminate circuits they are part of but do not control both ends, forcing clients to rebuild circuits and increasing the probability of end-to-end compromise.

Danner et al. [15] showed how selective DoS attacks can be detected by exhaustively probing potential paths, while Das and Borisov [16] reduced the cost of detection using probabilistic inference.

Resource consumption attacks, such as the Packet Spinning attack [36] and the CellFlood attack [31], also increase an adversary’s probability of end-to-end circuit compromise. In the Packet Spinning attack, the adversary crafts special packets that continuously "spin" through circular circuits composed of the target relays. In the CellFlood attack, the adversary efficiently builds a large number of circuits through the target relays, making them appear busy and causing honest clients’ circuits to time out, leading to the selection of new circuits containing malicious relays.

### Conclusions and Future Work

In this paper, we presented a novel and destructive DoS attack against Tor, which can be used to anonymously disable arbitrary Tor relays by exploiting the protocol’s reliable end-to-end data transport. We outlined several ways to carry out the Sniper Attack and assessed its resource and time profiles in large-scale simulations. We performed an in-depth security analysis, showing how the attack can be used to deanonymize hidden services. We developed a defense that identifies and kills malicious circuits in out-of-memory situations, rendering the attack ineffective. Finally, we suggested alternative guard and path selection policies to enhance Tor users’ security.

Although the Sniper Attack is tailored for Tor, our mechanisms may generalize to systems that use hop-by-hop reliability and end-to-end flow control. Future work should analyze the extent of this generalization and consider defenses against bandwidth consumption attacks.

### Acknowledgments

We thank the anonymous reviewers for their feedback and suggestions, Damon McCoy for discussions about misbehaving receivers and authenticated signals, and Roger Dingledine for discussions about attack and defense variations. Aaron Johnson was supported by the Office of Naval Research (ONR) and DARPA. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or ONR. We are also grateful for the DFG grant supporting this work.

### References

[1] “OOM Killer,” http://linux-mm.org/OOM Killer.
[2] “R-U-Dead-Yet (RUDY),” https://code.google.com/p/r-u-dead-yet/.
[3] “Shadow Source Code,” https://github.com/shadow/shadow.
[4] “TC: A Tor control protocol (Version 1),” https://gitweb.torproject.org/torspec.git?a=blob;hb=HEAD;f=control-spec.txt, Acc. June 2013.
[5] “The Tor Path Simulator,” http://torps.github.io/.
[6] “The Tor Project,” https://www.torproject.org/.
[7] “Tor directory protocol, version 3,” https://gitweb.torproject.org/torspec.git?a=blob;hb=HEAD;f=dir-spec.txt, Acc. July 2013.
[8] “Tor Metrics Portal,” https://metrics.torproject.org.
[9] F. Adamsky, S. A. Khayam, R. Jager, and M. Rajarajan, “Security Analysis of the Micro Transport Protocol with a Misbehaving Receiver,” in CyberC ’12, Oct. 2012.
[10] M. AlSabah, K. Bauer, I. Goldberg, D. Grunwald, D. McCoy, S. Savage, and G. Voelker, “DefenestraTor: Throwing out Windows in Tor,” in PETS ’11, Jul. 2011.
[11] K. Bauer, D. McCoy, D. Grunwald, T. Kohno, and D. Sicker, “Low-Resource Routing Attacks Against Tor,” in WPES ’07, Oct. 2007.
[12] A. Biryukov, I. Pustogarov, and R.-P. Weinmann, “Trawling for Tor Hidden Services: Detection, Measurement, Deanonymization,” in SP ’13, May 2013.
[13] N. Borisov, G. Danezis, P. Mittal, and P. Tabriz, “Denial of Service or Denial of Security?” in CCS ’07, Oct. 2007.
[14] T. Brenann, “OWASP HTTP Post Tool,” https://www.owasp.org/index.php/OWASP_HTTP_Post_Tool.
[15] N. Danner, S. Defabbia-Kane, D. Krizanc, and M. Liberatore, “Effectiveness and Detection of Denial-of-Service Attacks in Tor,” ACM TISSEC, vol. 15, no. 3, Nov. 2012.
[16] A. Das and N. Borisov, “Securing Anonymous Communication Channels under the Selective DoS Attack,” in FC ’13.
[17] R. Dingledine, “#6252 didn’t go far enough,” https://trac.torproject.org/projects/tor/ticket/9063, June 2013.
[18] ——, “#9063 enables Guard discovery in about an hour by websites,” https://trac.torproject.org/projects/tor/ticket/9072, June 2013.
[19] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: The Second-Generation Onion Router,” in USENIX Security ’04, Aug. 2004.
[20] W. Eddy, “TCP SYN Flooding Attacks and Common Mitigations,” RFC 4987, IETF, Aug. 2007.
[21] T. Elahi, K. Bauer, M. AlSabah, R. Dingledine, and I. Goldberg, “Changing of the Guards: A Framework for Understanding and Improving Entry Guard Selection in Tor,” in WPES ’12, Oct. 2012.
[22] T. Elahi and I. Goldberg, “CORDON–A Taxonomy of Internet Censorship Resistance Strategies,” University of Waterloo CACR 2012-33, Tech. Rep., 2012.
[23] N. S. Evans, R. Dingledine, and C. Grothoff, “A Practical Congestion Attack on Tor Using Long Paths,” in USENIX Security ’09, Aug. 2009.
[24] J. Geddes, R. Jansen, and N. Hopper, “How Low Can You Go: Balancing Performance with Anonymity in Tor,” in PETS ’13, Jul. 2013.
[25] D. M. Goldschlag, M. G. Reed, and P. F. Syverson, “Hiding Routing Information,” in IHW ’01, May 1996.
[26] ithilgore, “Exploiting TCP and the Persist Timer Infiniteness,” Phrack Magazine, vol. 0x0d, no. 0x42, Jun. 2009.
[27] R. Jansen, K. Bauer, N. Hopper, and R. Dingledine, “Methodically Modeling the Tor Network,” in CSET ’12, Aug. 2012.
[28] R. Jansen and N. Hopper, “Shadow: Running Tor in a Box for Accurate and Efficient Experimentation,” in NDSS ’12, Feb. 2012.
[29] M. Kenney, “Ping of Death,” http://insecure.org/sploits/ping-o-death.
[30] A. Kuzmanovic and E. W. Knightly, “Low-rate TCP-targeted Denial of Service Attacks and Counter Strategies,” IEEE/ACM TON, vol. 14, no. 4, 2006.
[31] V. P. Marco Valerio Barbera, Vasileios P. Kemerlis and A. Keromytis, “CellFlood: Attacking Tor Onion Routers on the Cheap,” in ES-ORICS ’13, Sep. 2013.
[32] N. Mathewson, “We should have better, fairer OOM handling,” https://trac.torproject.org/projects/tor/ticket/9093, June 2013.
[33] P. Mittal, A. Khurshid, J. Juen, M. Caesar, and N. Borisov, “Stealthy Traffic Analysis of Low-Latency Anonymous Communication Using Throughput Fingerprinting,” in CCS ’11, Oct. 2011.
[34] L. Øverlier and P. Syverson, “Locating Hidden Servers,” in SP ’06, May 2006.
[35] ——, “Valet Services: Improving Hidden Servers with a Personal Touch,” in PETS ’06, Jun. 2006.
[36] V. Pappas, E. Athanasopoulos, S. Ioannidis, and E. P. Markatos, “Compromising Anonymity Using Packet Spinning,” in ISC 08, Sep. 2008.
[37] V. Paxson, M. Allman, J. Chu, and M. Sargent, “Computing TCP’s Retransmission Timer,” RFC 6298, IETF, Jun. 2011.
[38] RSnake, “Slowloris HTTP DoS,” http://ha.ckers.org/slowloris/.
[39] S. Savage, N. Cardwell, D. Wetherall, and T. Anderson, “TCP Congestion Control with a Misbehaving Receiver,” ACM SIGCOMM CCR, vol. 29, no. 5, 1999.
[40] S. Shalunov, “Netkill – generic remote DoS attack,” http://seclists.org/bugtraq/2000/Apr/152, 2000.
[41] R. Sherwood, B. Bhattacharjee, and R. Braud, “Misbehaving TCP Receivers Can Cause Internet-wide Congestion Collapse,” in CCS ’05, Nov. 2005.
[42] P. Syverson, G. Tsudik, M. Reed, and C. Landwehr, “Towards an Analysis of Onion Routing Security,” in DIAU ’00, Jul. 2000.
[43] F. Tschorsch and B. Scheuermann, “Tor is unfair – and what to do about it,” in LCN ’11, Oct. 2011.
[44] P. Winter and S. Lindskog, “How the Great Firewall of China is blocking Tor,” in FOCI ’12, Aug. 2012.
[45] C.-F. Yu and V. D. Gligor, “A Formal Specification and Verification Method for the Prevention of Denial of Service,” in SP ’88, May 1988.