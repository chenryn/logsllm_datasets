### Conveying the Risk of Harm

Future research on the role of friction in disinformation warnings could provide valuable insights into this issue. Friction, which may be the primary cause of warning behavioral effects, was not explicitly tested as a mechanism in our crowdworker study. While our results do not conclusively rule out other mechanisms, they strongly suggest that friction warrants further investigation.

### Future Directions for Research

Future work could also evaluate other types of interstitial warnings and their effectiveness in various contexts, particularly on social media platforms. Many platforms already use warning popups that users must dismiss and warning overlays that obscure content until the user clicks through [111, 112].

Another promising direction is to examine how interstitial warnings interact with factors known to impact warning adherence and receptivity to disinformation. These factors include:

- Repetition of warnings [10, 15, 18, 20, 103]
- User age and digital literacy [113, 114]
- User tendency toward cognitive reflection [110, 115, 116]
- Repeated exposure to inaccurate information [19, 83]
- Whether the information aligns with user political preferences [114, 117, 118]

Finally, future studies should explore potential unintended consequences of interstitial disinformation warnings. These warnings could create an implied truth effect [87], generally undermine trust in online content [83], cause concern about the warning provider, or lead to warning fatigue [20].

### Informing Platform Disinformation Warnings

Interstitial warnings can be effective tools for countering disinformation. Compared to contextual warnings, interstitial designs are more noticeable and better at informing users about disinformation. Platforms using contextual warnings should be aware that these may have minimal effects.

Moving forward, platforms should adopt evidence-based approaches for developing and deploying disinformation warnings. By conducting internal evaluations, collaborating with independent researchers, and releasing data, platforms can significantly enhance their ability to counter disinformation with warnings, similar to how software vendors have advanced security warnings over the past decade [10, 13–15, 17, 19].

### Acknowledgments

We thank Marshini Chetty and Elissa Redmiles for their valuable early feedback on this work. Simone Fischer-Hübner provided thoughtful shepherding for our paper.

### References

[1] Samantha Bradshaw and Philip N. Howard. The Global Disinformation Order: 2019 Global Inventory of Organised Social Media Manipulation. Tech. rep. University of Oxford, Sept. 26, 2018. URL: https://comprop.oii.ox.ac.uk/wp-content/uploads/sites/93/2019/09/CyberTroop-Report19.pdf.

[2] Diego A. Martin, Jacob N. Shapiro, and Michelle Nedashkovskaya. “Recent Trends in Online Foreign Influence Efforts”. In: Journal of Information Warfare (JIW) 18 (3 2019). URL: https://esoc.princeton.edu/publications/trends-online-influence-efforts.

[3] Adam Mosseri. Addressing Hoaxes and Fake News. Facebook Newsroom. Dec. 15, 2016. URL: https://about.fb.com/news/2016/12/news-feed-fyi-addressing-hoaxes-and-fake-news/ (visited on 06/03/2020).

[4] Justin Kosslyn and Cong Yu. Fact Check Now Available in Google Search and News Around the World. Google Official Blog. July 2017. URL: https://www.blog.google/products/search/fact-check-now-available-google-search-and-news-around-world/ (visited on 03/05/2020).

[5] Microsoft Bing. Bing Adds Fact Check Label in SERP to Support the ClaimReview Markup. Bing Blogs. Sept. 14, 2017. URL: https://www.blog.google/products/search/fact-check-now-available-google-search-and-news-around-world/ (visited on 03/05/2020).

[6] Davey Alba and Kate Conger. Twitter Moves to Target Fake Videos and Photos. New York Times. Feb. 2020. URL: https://www.nytimes.com/2020/02/04/technology/twitter-fake-videos-photos-disinformation.html (visited on 04/18/2020).

[7] Taylor Hatmaker. Twitter Adds a Warning Label Fact-Checking Trump’s False Voting Claims. TechCrunch. May 26, 2020. URL: https://techcrunch.com/2020/05/26/twitter-trump-labels-fact-checking-tweet/ (visited on 06/03/2020).

[8] Min Wu, Robert C Miller, and Simson L Garfinkel. “Do Security Toolbars Actually Prevent Phishing Attacks?” In: Proceedings of the 2006 ACM SIGCHI Conference on Human Factors in Computing Systems (CHI). Apr. 2006. DOI: 10.1145/1124772.1124863.

[9] Serge Egelman, Lorrie Faith Cranor, and Jason Hong. “You’ve Been Warned: An Empirical Study of the Effectiveness of Web Browser Phishing Warnings”. In: Proceedings of the 2008 ACM SIGCHI Conference on Human Factors in Computing Systems (CHI). Apr. 2008. DOI: 10.1145/1357054.1357219.

[10] Devdatta Akhawe and Adrienne Porter Felt. “Alice in Warningland: A Large-Scale Field Study of Browser Security Warning Effectiveness”. In: Proceedings of the 22nd USENIX Security Symposium (USENIX Security). Aug. 2013. URL: https://dl.acm.org/doi/10.5555/2534766.2534789.

[11] Joshua Sunshine et al. “Crying Wolf: An Empirical Study of SSL Warning Effectiveness”. In: Proceedings of the 18th USENIX Security Symposium (USENIX Security). Aug. 2009. URL: https://dl.acm.org/doi/abs/10.5555/1855768.1855793.

[12] Marian Harbach et al. “Sorry, I Don’t Get It: An Analysis of Warning Message Texts”. In: Proceedings of the 17th International Conference on Financial Cryptography and Data Security (FC). Vol. 7859. Lecture Notes in Computer Science (LNCS). Apr. 2013. DOI: 10.1007/978-3-642-41320-9_7.

[13] Adrienne Porter Felt et al. “Experimenting at Scale with Google Chrome’s SSL Warning”. In: Proceedings of the 2014 ACM SIGCHI Conference on Human Factors in Computing Systems (CHI). Apr. 2014. DOI: 10.1145/2556288.2557292.

[14] Adrienne Porter Felt et al. “Improving SSL Warnings: Comprehension and Adherence”. In: Proceedings of the 2015 ACM SIGCHI Conference on Human Factors in Computing Systems (CHI). Apr. 2015. DOI: 10.1145/2702123.2702442.

[15] Joel Weinberger and Adrienne Porter Felt. “A Week to Remember: The Impact of Browser Warning Storage Policies”. In: Proceedings of the 12th Symposium On Usable Privacy and Security (SOUPS). June 2016. URL: https://dl.acm.org/doi/abs/10.5555/3235895.3235898.

[16] Malkin, Nathan and Mathur, Arunesh and Harbach, Marian and Egelman, Serge. “Personalized Security Messaging: Nudges for Compliance with Browser Warnings”. In: Proceedings of the EuroUSEC 2017 – The 2nd European Workshop on Usable Security. Apr. 2017. DOI: 10.14722/eurousec.2017.23008.

[17] Robert W. Reeder et al. “An Experience Sampling Study of User Reactions to Browser Warnings in the Field”. In: Proceedings of the 2018 ACM SIGCHI Conference on Human Factors in Computing Systems (CHI). Apr. 2018. DOI: 10.1145/3173574.3174086.

[18] Serge Egelman and Stuart E. Schechter. “The Importance of Being Earnest (in Security Warnings)”. In: Proceedings of the 17th International Conference on Financial Cryptography and Data Security (FC). Vol. 7859. Lecture Notes in Computer Science (LNCS). Apr. 2013. DOI: 10.1007/978-3-642-39884-1_5.

[19] Hazim Almuhimedi et al. “Your Reputation Precedes You: History, Reputation, and the Chrome Malware Warning”. In: Proceedings of the 10th Symposium On Usable Privacy and Security (SOUPS). June 2014. URL: https://dl.acm.org/doi/10.5555/3235838.3235848.

[20] Cristian Bravo-Lillo et al. “Harder to Ignore? Revisiting Pop-Up Fatigue and Approaches to Prevent It”. In: Proceedings of the 10th Symposium On Usable Privacy and Security (SOUPS). June 2014. URL: https://dl.acm.org/doi/abs/10.5555/3235838.3235847.

[21] Mustafa Emre Acer et al. “Where the Wild Warnings Are: Root Causes of Chrome HTTPS Certificate Errors”. In: Proceedings of the 24th ACM SIGSAC Conference on Computer and Communications Security (CCS). Oct. 2017. DOI: 10.1145/3133956.3134007.

[22] Michela Del Vicaro et al. “The Spreading of Misinformation Online”. In: Proceedings of the National Academy of Sciences (PNAS) 113 (3 Jan. 2016). DOI: 10.1073/pnas.1517441113.

[23] Hunt Allcott and Matthew Gentzkow. “Social Media and Fake News in the 2016 Election”. In: Journal of Economic Perspectives (JEP) 31.2 (2017). DOI: 10.1257/jep.31.2.211.

[24] Hunt Allcott, Matthew Gentzkow, and Chuan Yu. “Trends in the Diffusion of Misinformation on Social Media”. In: Research and Politics 6 (2 2019). DOI: 10.1177/2053168019848554.

[25] Peter Burger et al. “The Reach of Commercially Motivated Junk News on Facebook”. In: PLoS One 14 (8 Aug. 2019). DOI: 10.1371/journal.pone.0220446.

[26] Andrew M. Guess, Brendan Nyhan, and Jason Reifler. “Exposure to Untrustworthy Websites in the 2016 US Election”. In: Nature Human Behavior (Mar. 2020). DOI: 10.1038/s41562-020-0833-x.

[27] Arkaitz Zubiaga et al. “Analysing How People Orient to and Spread Rumours in Social Media by Looking at Conversational Threads”. In: PLoS One 11 (3 Mar. 2016). DOI: 10.1371/journal.pone.0150989.

[28] Philip N. Howard et al. Social Media, News and Political Information During the US Election: Was Polarizing Content Concentrated in Swing States? 2018. arXiv: 1802.03573 [cs.SI].

[29] Chengcheng Shao et al. “The Spread of Low-Credibility Content by Social Bots”. In: Nature Communications (Nov. 2018). DOI: 10.1038/s41467-018-06930-7.

[30] Soroush Vosoughi, Deb Roy, and Sinan Aral. “The Spread of True and False News Online”. In: Science 359.6380 (Mar. 9, 2018). DOI: 10.1126/science.aap9559.

[31] Srijan Kumar, Robert West, and Jure Leskovec. “Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes”. In: Proceedings of the 25th World Wide Web Conference (WWW). Apr. 2016. DOI: 10.1145/2872427.2883085.

[32] Daniel Bush and Alex Zaheer. Bing’s Top Search Results Contain an Alarming Amount of Disinformation. Stanford Internet Observatory Blog. Dec. 27, 2019. URL: https://cyber.fsi.stanford.edu/io/news/bing-search-disinformation (visited on 05/15/2020).

[33] Adam Fourney et al. “Geographic and Temporal Trends in Fake News Consumption During the 2016 US Presidential Election”. In: Proceedings of the 26th ACM International Conference on Information and Knowledge Management (CIKM). Nov. 2017. DOI: 10.1145/3132847.3133147.

[34] Chengcheng Shao et al. “Anatomy of an Online Misinformation Network”. In: PLoS One 13 (4 Apr. 2018). DOI: 10.1371/journal.pone.0196087.

[35] Adam Badawy, Kristina Lerman, and Emilio Ferrara. “Who Falls for Online Political Manipulation?” In: Companion Proceedings of the The Web Conference (WWW) 2019. May 2019. DOI: 10.1145/3308560.3316494.

[36] Alexandre Bovet and Hernán A. Makse. “Influence of Fake News in Twitter During the 2016 US Presidential Election”. In: Nature Communications (Jan. 2019). DOI: 10.1038/s41467-018-07761-2.

[37] Nir Grinberg et al. “Fake News on Twitter During the 2016 U.S. Presidential Election”. In: Science 363.6425 (Jan. 25, 2019). DOI: 10.1126/science.aau2706.

[38] Emilio Ferrara. “Disinformation and Social Bot Operations in the Run Up to the 2017 French Presidential Election”. In: First Monday 22 (8 Aug. 2017). DOI: 10.2139/ssrn.2995809.

[39] Michele Cantarella, Nicolò Fraccaroli, and Roberto Volpe. Does Fake News Affect Voting Behaviour? Tech. rep. DEMB Working Paper Series n.146, June 12, 2019. URL: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3402913.

[40] Kate Starbird et al. “Ecosystem or Echo-System? Exploring Content Sharing Across Alternative Media Domains”. In: AAAI-ICWSM2018. URL: https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17836.

[41] Andreas Vlachos and Sebastian Riedel. “Identification and Verification of Simple Claims about Statistical Properties”. In: Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Sept. 2015. URL: https://www.aclweb.org/anthology/D15-1312.pdf.

[42] James Thorne and Andreas Vlachos. “An Extensible Framework for Verification of Numerical Claims”. In: Proceedings of the Software Demonstrations of the 15th Annual Meeting of the Association for Computational Linguistics (ACL). Apr. 2017. URL: https://www.aclweb.org/anthology/E17-3010.pdf.

[43] Naeemul Hassan et al. “Toward Automated Fact-Checking: Detecting Check-worthy Factual Claims by ClaimBuster”. In: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery in Data Mining (KDD). July 2017. DOI: 10.1145/3097983.3098131.

[44] James Thorne and Andreas Vlachos. “Automated Fact Checking: Task Formulations, Methods and Future Directions”. In: Proceedings of the 27th International Conference on Computational Linguistics (COLING). Aug. 2018. URL: https://www.aclweb.org/anthology/C18-1283.

[45] James Thorne et al. “FEVER: A Large-Scale Dataset for Fact Extraction and VERification”. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT). (Long paper). June 2018. DOI: 10.18653/v1/N18-1074.

[46] Hannah Rashkin et al. “Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking”. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP). Sept. 2017. DOI: 10.18653/v1/D17-1317.

[47] Martin Potthast et al. “A Stylometric Inquiry into Hyperpartisan and Fake News”. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL). (Long paper). July 2016. DOI: 10.18653/v1/P18-1022.

[48] Benjamin D. Horne and Siebl Adali. “This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News”. In: Proceedings of the 11th International Conference on Weblogs and Social Media (ICWSM). May 2017. URL: https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15772.

[49] Austin Hounsel et al. “Identifying Disinformation Websites Using Infrastructure Features”. In: 10th USENIX Workshop on Free and Open Communications on the Internet (FOCI). Aug. 11, 2020. URL: https://www.usenix.org/conference/foci20/presentation/hounsel.

[50] Fan Yang et al. “Automatic Detection of Rumor on Sina Weibo”. In: Proceedings of the 2012 ACM Workshop on Automated Decision Making for Active Cyber Defense (SafeConfig). Aug. 2012. DOI: 10.1145/2350190.2350203.

[51] Ke Wu, Song Yang, and Kenny Q Zhu. “False Rumors Detection on Sina Weibo by Propagation Structures”. In: Proceedings of the 31st International Conference on Data Engineering (ICDE). Apr. 2015. DOI: 10.1109/ICDE.2015.7113322.

[52] Zhe Zhao, Paul Resnick, and Qiaozhu Mei. “Enquiring Minds: Early Detection of Rumors in Social Media from Enquiry Posts”. In: Proceedings of the 24th World Wide Web Conference (WWW). May 2015. DOI: 10.1145/2736277.2741637.

[53] Jing Ma, Wei Gao, and Kam-Fai Wong. “Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning”. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL). (Long paper). Aug. 2017. DOI: 10.18653/v1/P17-1066.