### Traditional vs. Interleaved Memory Layout

#### (a) Traditional Memory Layout
In a traditional memory layout, code and data are segregated into separate pages, as illustrated in Figure 9(a). This layout allows an attacker to trap only writes to code by setting code pages as non-writable. 

#### (b) Interleaved Memory Layout
An alternative approach is to interleave code and data within the same pages, as shown in Figure 9(b). In this layout, a write to any address in the code range of page P1 is indistinguishable at the page level from a write to any address in the data ranges of P1. This interleaving can be extended to include statically-sized stack frames for non-recursive functions, as their memory requirements and layout can be computed statically by a compiler. Interleaving of code, global data, and stack frames can be achieved transparently to the programmer using a custom compiler.

Interleaving heap data introduces additional complexity because the heap free list must be initialized to non-contiguous memory when the process is loaded for execution. However, heap regions and stack frames are typically represented as linked data structures, which allow straightforward interleaving. Although we have not developed the custom compiler tools supporting interleaving, other research has successfully integrated security enhancements into compilers [6, 16].

### Efficient Trapping of Writes to Code

Efficient trapping of writes to code when code and data are interleaved on the same page requires memory protection at word-level granularity. While the research community has investigated fine-grained memory protection [26], current commodity hardware does not support word-level memory protection, and no efficient software implementations exist. The attacker is left with two options:

1. **Develop specialized hardware** that will, with a single write instruction, alter the memory at two physical addresses. This is beyond the means of typical attackers.
2. **Write protect all memory pages** in a commodity system. Every memory write in the program will now result in a fault, regardless of whether it is a write to data or a write to code. All writes become interpreted, and performance suffers greatly. If Assumption 2 of Section 2.1 holds, this option becomes unappealing to the attacker.

These arguments and the validity of self-checksumming remain dependent upon Assumptions 1 and 2 holding true. Further research is needed to validate these assumptions. An attacker willing to commit the resources required for code analysis and interpretive emulation can defeat any self-checksumming algorithm, even with our memory architecture detection.

### Effects on Other Security Mechanisms

Our technique for strengthening self-checksumming requires the protected program to overwrite part of its code, making all memory pages containing program code writable. Writable code pages present a new target for an attacker who manages to manipulate the control flow of the program, perhaps by exploiting a buffer overflow vulnerability. If the code is overwritten with malicious code, any protection system that permits execution only from code pages, such as PaX [21], will fail to detect the attack. The complementary issue of executable data pages arises from the proposal to interleave code and data, making identification of checksum code more difficult. The attack-detection functionality of PaX’s non-executable stack can no longer be relied upon. Fortunately, many other dynamic techniques detect or prevent all buffer overflow attacks and do not interfere with our architecture detection mechanism [1, 6, 10, 16].

### Effects on Program Performance

Our architecture detection approach incurs performance costs in both execution time and memory usage overhead. Adding self-modifying code to programs can cause performance deterioration due to cache coherency maintenance and processor pipeline flushes of stale instructions. Code scheduling can minimize this impact. For example, the entire code of the function `checksum` in Figure 8 separates the rewriting instruction of line 2 from the rewritten instruction of line 4. Instruction prefetch will follow the call. If the number of instructions executed in `checksum` is greater than the depth of the processor’s pipeline, then self-modification imposes no pipeline flush as the instruction will be rewritten before it is prefetched.

We measured the impact of self-modifying code on execution performance. We executed a benchmark that exercised our worst-case performance impact: the altered instruction is used immediately following modification. The resulting cache and processor pipeline flushes will adversely affect performance to the greatest degree possible. We looped through self-modifying code 300 million times on five commodity processors and present the average measured delays incurred by code modification in Table 1. An expanded report contains the complete benchmark code [12].

In all cases, the cost of self-modifying code is small and similar to the cost of a lightweight system call. Adding our architecture detection to existing self-checksumming algorithms will not significantly diminish the performance of self-checksumming.

Self-modifying code and the more general technique of interleaving code and data may increase memory use requirements for some execution scenarios. In traditional execution designs where programs have non-writable code segments, multiple instances of the same executing program can share the same code segments. The page table entries of the separate processes resolve to the same physical memory addresses containing the non-writable code. However, our technique requires that every instance of an executing program have separate physical memory pages, even for code. The system’s overall physical memory demands increase. This problem is not unique to our technique; obfuscation algorithms that reorder code have similar memory needs [6].

### Applicability to Commodity Processors

One hallmark of the work by Wurster et al. was the authors’ ability to develop implementations of the attack for a wide variety of processors [23]. Nonetheless, our memory architecture detection is independent of the underlying implementation of the page-replication attack. A single code sequence that changes only to match the assembly language of a particular processor can detect the page-replication attack in any of its implementation forms. As Table 1 shows, we tested our detection on three different classes of processor architectures. Our generic detection mechanism allows self-checksumming to be applied to programs for many different architectures.

### Related Work

Wurster [27] suggested an alternate defense to the page-replication attack. Given that the current implementation of the attack creates the Harvard main memory when the operating system loads a process for execution and the data memory pages remain unchanged, a process can simply copy all unchanged code from the data pages to a new region of memory and then continue execution from that region. Although this copy-and-execute defense will evade the existing attack of Wurster et al., a knowledgeable attacker can easily adapt. Rather than replicating memory when loading the process, the attacker can initially leave the memory untouched and simply insert a breakpoint trap immediately before the control flow transfer from the original code pages to the new code pages created by the copy loop. The process begins execution, copies its code to a new region of memory, and then stops at the breakpoint before jumping to the new code. The malicious operating system can then create the Harvard memory for the copied code pages and resume the process’ execution. This easy attack adaptation occurs because Wurster’s defense only generates code once during process execution, and this generation occurs at a predictable time. In our design, code modification occurs continually throughout execution and evasion of our defense requires emulation of memory writes.

Self-modifying code has been used previously in self-checksumming algorithms. Aucsmith [5] proposed a self-checksumming implementation that used integrity verification kernels (IVKs), or code segments for checksum computation and verification that are armored against modification. The system used self-modifying code to prevent reverse engineering of the IVKs.

Previous techniques such as the IVKs, Horne et al.’s testers and correctors [13], and Chang and Atallah’s networks of guards [7] addressed only the opaque code assumption and the performance assumption. In this work, we presented a solution to ensure the validity of the previously disregarded von Neumann assumption. Our solution is orthogonal to the self-checksumming techniques from previous work and can be successfully used in combination with them to obtain the desired level of integrity assurance.

### Conclusions

Previous self-checksumming approaches implicitly assumed a von Neumann main memory and are subject to evasion by a page-replication attack. We showed here that explicitly recognizing the von Neumann assumption allowed investigation of strategies by which processes can verify whether the assumption holds. Self-checksumming algorithms can use self-modifying code to detect violations of the von Neumann assumption. When memory appears Harvard on a commodity von Neumann machine, processes can reasonably conclude that a page-replication attack is in progress and take corrective action as necessary.

### Acknowledgments

We thank Paul van Oorschot, Vinod Ganapathy, Shai Rubin, Hao Wang, and all anonymous reviewers for helping improve the quality of this paper.

### References

[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-flow integrity: Principles, implementations, and applications. In 12th ACM Conference on Computer and Communications Security (CCS), Alexandria, VA, Nov. 2005.

[2] H. H. Aiken. Proposed automatic calculating machine. Unpublished manuscript, Nov. 1937. Also appeared in IEEE Spectrum, 1(8):62–69, Aug. 1964.

[3] H. H. Aiken and G. M. Hopper. The automatic sequence controlled computer. Electrical Engineering, 65:384–391, Aug./Sep. 1946.

[4] AMD64 Architecture Programmer’s Manual Volume 1: Application Programming, Mar. 2005. Advanced Micro Devices publication number 24592, revision 3.10. Page 123.

[5] D. Aucsmith. Tamper resistant software: An implementation. In 1st International Information Hiding Workshop (IHW), Cambridge, United Kingdom, Apr. 1996.

[6] S. Bhatkar, R. Sekar, and D. C. DuVarney. Efficient techniques for comprehensive protection from memory error exploits. In 14th USENIX Security Symposium, Baltimore, MD, July 2005.

[7] H. Chang and M. J. Atallah. Protecting software code by guards. In 1st Digital Rights Management Workshop, Philadelphia, PA, Nov. 2001.

[8] C. Collberg, C. Thomborson, and D. Low. Manufacturing cheap, resilient, and stealthy opaque constructs. In 25th ACM Symposium on Principles of Programming Languages (POPL), San Diego, CA, Jan. 1998.

[9] C. S. Collberg and C. Thomborson. Watermarking, tamper-proofing, and obfuscation—tools for software protection. Technical Report 2000-03, University of Arizona, Feb. 2000.

[10] C. Cowan, C. Pu, D. Maier, H. Hinton, J. Walpole, P. Bakke, S. Beattie, A. Grier, P. Wagle, and Q. Zhang. StackGuard: Automatic adaptive detection and prevention of buffer-overflow attacks. In 7th USENIX Security Symposium, San Antonio, TX, Jan. 1998.

[11] R. Dhamija and F. Wallenberg. A framework for evaluating digital rights management proposals. In 1st International Mobile IPR Workshop, Helsinki, Finland, Aug. 2003.

[12] J. T. Giffin, M. Christodorescu, and L. Kruger. Strengthening software self-checksumming via self-modifying code. Technical Report 1531, Computer Sciences Department, University of Wisconsin, Madison, WI, Sept. 2005.

[13] B. Horne, L. Matheson, C. Sheehan, and R. Tarjan. Dynamic self-checking techniques for improved tamper resistance. In 1st Digital Rights Management Workshop, Philadelphia, PA, Nov. 2001.

[14] Intel Architecture Software Developer’s Manual Volume 1: Basic Architecture, 1997. Intel publication number 243190. Page 2-8.

[15] C. Linn and S. Debray. Obfuscation of executable code to improve resistance to static disassembly. In 10th ACM Conference on Computer and Communications Security (CCS), Washington, DC, Oct. 2003.

[16] G. C. Necula, J. Condit, M. Harren, S. McPeak, and W. Weimer. CCured: Type-safe retrofitting of legacy software. ACM Transactions on Programming Languages and Systems (TOPLAS), 27(3):477–526, May 2005.

[17] PowerPC Processor Reference Guide, Sept. 2003. Pages 170–171.

[18] T. Sander and C. Tschudin. Protecting mobile agents against malicious hosts. Volume 1419 of Lecture Notes in Computer Science, pages 44–60. Springer-Verlag, 1998.

[19] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla. Pioneer: Verifying integrity and guaranteeing execution of code on legacy platforms. In 20th ACM Symposium on Operating System Principles (SOSP), Brighton, United Kingdom, Oct. 2005.

[20] The Sparc Architecture Manual, Version 9, 2000. Pages 308–309.

[21] The PaX Team. Non-executable sign and implementation. Published online at http://pax.grsecurity.net/docs/noexec.txt. Last accessed on May 20, 2005.

[22] P. C. van Oorschot. Revisiting software protection. In 6th International Information Security Conference (ISC), Bristol, United Kingdom, Oct. 2003.

[23] P. C. van Oorschot, A. Somayaji, and G. Wurster. Hardware-assisted circumvention of self-hashing software tamper resistance. IEEE Transactions on Dependable and Secure Computing, Apr./June 2005.

[24] J. von Neumann. First draft of a report on the EDVAC, 1945.

[25] C. Wang, J. Davidson, J. Hill, and J. Knight. Protection of software-based survivability mechanisms. In International Conference of Dependable Systems and Networks, Göteborg, Sweden, July 2001.

[26] E. Witchel, J. Cates, and K. Asanovic. Mondrian memory protection. In 10th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), San Jose, CA, Oct. 2002.

[27] G. Wurster. A generic attack on hashing-based software tamper resistance. Master’s thesis, Carleton University, June 2005.

[28] G. Wurster, P. C. van Oorschot, and A. Somayaji. A generic attack on checksumming-based software tamper resistance. In IEEE Symposium on Security and Privacy, Oakland, CA, May 2005.