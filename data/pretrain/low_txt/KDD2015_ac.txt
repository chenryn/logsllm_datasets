# Table 4: Open Source Systems Used for Evaluation

| Model | Description |
| --- | --- |
| EGADS - Extreme Low-Density Model Outlier | Density-based anomaly detection using EGADS. |
| EGADS - CP | Kernel-based change-point detection using EGADS. |
| EGADS - K-Sigma Model Outlier | Re-implementation of the classic k-sigma model in EGADS. |
| Twitter Outlier | An open-source anomaly detection library from Twitter, based on the Generalized ESD method. |
| Extreme I & II R Outlier | Open-source univariate outlier detection that uses absolute value and residual thresholds to identify anomalies. |
| BreakOut - Twitter CP | A package from Twitter that employs an ESD statistics test to detect change points. |
| ChangePt1 - R CP | An R library implementing various mainstream and specialized change-point methods for detecting single and multiple change-points. Method I uses a change in variance. |
| ChangePt2 & 3 - R CP | Detects changes in both the mean and variance. |

## Abnormal Spikes and Level Shifts Evaluation
The open-source systems listed in Table 4 were used to evaluate instances that exhibited abnormal spikes and level shifts. In the context of YM (Yahoo Metrics), "abnormal" referred to seasonal behavior followed by non-seasonal behavior, which characterizes most attacks. The YM editors did not consider traffic-shift behavior, where a large drop in traffic was observed due to router table updates.

To address this requirement, the filtering stage scanned all anomalies \(a_i\) from all models and classified them as true positives using a boosted tree model based on AdaBoost [8]. The features used in the model are described in Table 1. AdaBoost works by fitting a sequence of weak learners (e.g., small decision trees) on repeatedly modified versions of the data. The final result is produced via a combined weighted majority vote. On each iteration, examples that are difficult to predict receive higher importance, so each subsequent weak learner focuses on the examples missed by the previous ones.

In addition to the time-series features described in Table 1, we used the model features detailed in Section 6.2. The experiments shown in Figure 6 indicate that the precision and recall are significantly improved even with just the time-series features, compared to using the model alone without the filtering stage. This experiment underscores a critical principle: an anomaly is use-case specific and must be learned automatically for a fully scalable and automated solution.

## Importance of Anomaly Detection
Anomaly detection is a critical component in many real-time monitoring systems, with applications ranging from fault detection to fraud detection and network intrusion detection. Despite its importance, implementing a fully-automatic anomaly detection system in practice is challenging due to the large scale and diverse use-cases in real-world settings. These challenges often result in solutions that are either not scalable or highly specialized, leading to a high rate of false positives when applied to other use-cases.

## Introduction to EGADS
In this paper, we introduce EGADS, a generic anomaly detection system implemented at Yahoo. EGADS automatically monitors and alerts on millions of time-series across different Yahoo properties for various use-cases, including fault detection and intrusion detection. The parallel architecture of EGADS on Hadoop and its stream processing mechanism through Storm enable real-time anomaly detection on a massive scale.

EGADS employs different time-series modeling and anomaly detection algorithms to handle various monitoring use-cases. By incorporating these algorithms with a machine-learned mechanism in the alerting module, EGADS adapts itself to the specific anomaly detection use-case important to the user. These features create a powerful, generic, and scalable anomaly detection framework. Our showcase experiments on real and synthetic datasets demonstrate the superior applicability of our framework compared to rival solutions.

## Extendibility of EGADS
EGADS is designed to be extendable, providing an easy mechanism to plug in new models and algorithms. This feature creates an opportunity for the community to contribute to EGADS. To further engage with the anomaly detection and monitoring community, our framework and all its datasets are contributed to the open-source repository.

## Conclusion
In conclusion, EGADS is a robust and versatile anomaly detection system that addresses the challenges of scalability and adaptability in real-world use-cases. By contributing EGADS to the open-source community, we aim to foster collaboration and continuous improvement in the field of anomaly detection.

## References
[1] C. Aggarwal. *Outlier Analysis*. Springer New York, 2013.
[2] P. Bloomfield. *Fourier analysis of time series: an introduction*. John Wiley & Sons, 2004.
[3] M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander. LOF: Identifying density-based local outliers. *SIGMOD Rec.*, 29(2):93–104, May 2000.
[4] V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection: A survey. *ACM Comput. Surv.*, 41(3):15:1–15:58, July 2009.
[5] R. B. Cleveland, W. S. Cleveland, J. E. McRae, and I. Terpenning. STL: A seasonal-trend decomposition procedure based on loess. *Journal of Official Statistics*, 6(1):3–73, 1990.
[6] J. Durbin and S. J. Koopman. *Time series analysis by state space methods*. Oxford University Press, 2012.
[7] V. A. Epanechnikov. Non-parametric estimation of a multivariate probability density. *Theory of Probability & Its Applications*, 14(1):153–158, 1969.
[8] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting, 1996.
[9] S. S. Haykin, S. S. Haykin, and S. S. Haykin. *Kalman filtering and neural networks*. Wiley Online Library, 2001.
[10] R. J. Hyndman and A. B. Koehler. Another look at measures of forecast accuracy. *International Journal of Forecasting*, pages 679–688, 2006.
[11] R. H. Jones. Exponential smoothing for multivariate time series. *Journal of the Royal Statistical Society. Series B (Methodological)*, pages 241–251, 1966.
[12] Y. Kawahara, T. Yairi, and K. Machida. Change-point detection in time-series data based on subspace identification. *Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on*, pages 559–564. IEEE, 2007.
[13] A. Kejariwal and P. Kumar. Mitigating user experience from 'breaking bad': The Twitter approach. *Velocity 2014, New York, NY, Sept. 2014*.
[14] R. Killick. changepoint, an R package that implements various mainstream and specialized changepoint methods., 2014.
[15] L. Komsta. outliers, an R package of some tests commonly used outlier detection techniques., 2011.
[16] S. Kullback. *Information theory and statistics*. Courier Corporation, 1997.
[17] S. Liu, M. Yamada, N. Collier, and M. Sugiyama. Change-point detection in time-series data by relative density-ratio estimation. *Neural Networks*, 43:72–83, 2013.
[18] V. Moskvina and A. Zhigljavsky. An algorithm based on singular spectrum analysis for change-point detection. *Communications in Statistics-Simulation and Computation*, 32(2):319–352, 2003.
[19] D. B. Percival and A. T. Walden. *Wavelet methods for time series analysis*, volume 4. Cambridge University Press, 2006.
[20] B. K. Ray and R. S. Tsay. Bayesian methods for change-point detection in long-range dependent processes. *Journal of Time Series Analysis*, 23(6):687–705, 2002.
[21] B. Rosner. Percentage points for a generalized ESD many-outlier procedure. *Technometrics*, 25(2):165–172, 1983.
[22] A. Toshniwal, S. Taneja, A. Shukla, K. Ramasamy, J. M. Patel, S. Kulkarni, J. Jackson, K. Gade, M. Fu, J. Donham, N. Bhagat, S. Mittal, and D. Ryaboy. Storm@Twitter. *Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data, SIGMOD ’14*, pages 147–156, New York, NY, USA, 2014. ACM.
[23] O. Vallis, J. Hochenbaum, and A. Kejariwal. A novel technique for long-term anomaly detection in the cloud. *6th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 14)*, Philadelphia, PA, June 2014. USENIX Association.
[24] M. van der Loo. extremevalues, an R package for outlier detection in univariate data, 2010. R package version 2.0.
[25] X. Wang, K. Smith-Miles, and R. Hyndman. Rule induction for forecasting method selection: Meta-learning the characteristics of univariate time series. *Neurocomputing*, 72(10-12):2581–2594, June 2009.
[26] W. W.-S. Wei. *Time series analysis*. Addison-Wesley publ, 1994.
[27] Y. Xie, J. Huang, and R. Willett. Change-point detection for high-dimensional time series with missing data. *IEEE Journal of Selected Topics in Signal Processing*, 7(1):12–27, 2013.