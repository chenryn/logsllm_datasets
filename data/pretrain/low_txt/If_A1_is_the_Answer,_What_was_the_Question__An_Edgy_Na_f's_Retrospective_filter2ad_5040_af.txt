### Panelists and Metrics Overview
The panel, consisting of Peter Neumann, Gerry Popek, Pete Tasker, Steve Walker, and Clark Weissman [15], discussed a comprehensive set of metrics. These metrics were divided into four aspects of assurance and four aspects of protection mechanisms. The metrics were visually represented as sectors of concentric circles, with the innermost circle symbolizing Null Confidence. Each successive outer circle illustrated increasing levels of assured protection.

### Decomposition of Metrics
#### 1. Assurance Features
- **Hardware**
  - Software Checks
  - Hardware Fault Detection
  - Design Correctness Formally Verified
  - Fault Tolerant Hardware
- **Software**
  - Formal Design Specifications
  - Proven Design Specifications
  - Design Correctness Formally Verified
  - Verified Implementation
- **Development and Testing**
  - Penetration Exercise
  - Modern Programming Practices
  - Automated Testing
- **Operation and Maintenance**
  - Configuration Management
  - Reverification Aids
  - Read-Only Memory

#### 2. Protection Mechanisms
- **Prevention**
  - Data Security Enforcement
  - System Integrity
  - Collusion Enforcement
  - Sophisticated Threat (Denial of Service)
- **Detection**
  - Audit Recording
  - Security Officer Aids
  - Detection Analysis
- **Authorization Granularity**
  - Physical Devices
  - Logical Devices
  - Data Values
- **Policy Interface**
  - Passwords
  - Labels and Access Control Lists
  - Security Administration Tools

### Interpretation of Levels
The levels within these eight sectors were not directly comparable as requirements. Instead, they illustrated increasing degrees of confidence in a system's security as additional requirements were met, moving outward from the Null Confidence center. No specific evaluation methodology was proposed.

### Air Force Summer Study
Following the Miami workshop, a month-long Air Force Summer Study on Computer Security was conducted at Draper Labs in Cambridge, Massachusetts. The study covered evaluation criteria and methods, along with topics such as database security, network security, and the utility of formal methods. Participants included security researchers, developers, and practitioners from the United States, Canada, the United Kingdom, and Germany. The study primarily functioned as a workshop where ideas and proposals were extensively discussed.

Several key controversies emerged, including:
- The feasibility of verifying the security of composed subsystems.
- The possibility of building a secure multilevel database management system with full functionality.
- The potential to produce a "proof of correctness" for a system that would be accepted by a mathematically sophisticated community [11].

Discussions on database management security highlighted significant issues with inference and data-dependent access control policies. Dennis Tsichritsis criticized least privilege multilevel database management systems, referring to them as "strait-jacket DBMS."

### Nibaldi Report, 1979
Steve Walker, then in the Office of the Secretary of Defense for C3I, tasked MITRE to elaborate on the Lee Panelâ€™s report. Grace Nibaldi produced a technical report in October 1979, outlining seven levels of protection:

1. **No Protection**: No basis for confidence in the system's ability to protect information.
2. **Limited Controlled Sharing**: Some attempt to control access is recognized, but with limited confidence in the controls.
3. **Extensive Mandatory Security**: Minimal protection policy requirements are met, with assurance derived from design and testing.
4. **Structured Protection Mechanism**: Additional confidence through methodical construction and modern programming techniques.
5. **Design Correspondence**: Formal methods verify the TCB implementation.
6. **Implementation Correspondence**: Formal methods verify the software implementation.
7. **Object Code Analysis**: Object code is analyzed, and hardware support is strengthened.

The report includes a 15-page tutorial on primary and supporting factors, providing an overview of the R&D community's state-of-the-art. The Reference Monitor Concept is not explicitly mentioned, and the term TCB is used instead of security kernel, with no explicit requirements for minimizing the size or complexity of the protection mechanism at higher assurance levels.

Each protection level subsumes the requirements of the prior level and must satisfy general criteria for Protection Policy, Specific Protection Mechanisms, and Assurance. A section addresses the "residual risk" associated with the operational environment, recommending appropriate measures. For example, Level 4 discusses storage channels and their detection and auditing.

### Unachievable Level 6 Criteria
Level 6 criteria, though unachievable at the time, offered a high degree of confidence, addressing highly improbable hardware errors and failures in personnel, administrative, physical, or communications security. Formal analysis of object code and verification of security-relevant hardware mechanisms were required, though these were beyond the anticipated state-of-the-art for the 1980s.

### TCSEC Publication
In February 1981, the Department of Defense Computer Security Evaluation Center (DOD/CSEC) was authorized under Directive 5215.1, and the DoD Computer Security Center (DOD/CSC) was established at the National Security Agency (NSA) in July. Melville H. Klein and Colonel Roger Schell were appointed as Director and Deputy Director. The Center aimed to encourage the widespread availability of trusted products, which would be evaluated gratis and listed for vendor advertising and procurement specifications.

When I joined as Chief Scientist in April 1982, Dan Edwards directed the Standards and Products organization, Mario Tinto handled product evaluations, and Steve Barnett led the Application Certifications organization.

### Evolution of TCSEC Drafts
Before my arrival, work had begun on transforming the Nibaldi proposals into draft evaluation criteria. Selected requirements were written, and there was general agreement on what was salutary and what was lacking among mechanisms and assurance techniques. However, more work was needed to finalize the criteria.