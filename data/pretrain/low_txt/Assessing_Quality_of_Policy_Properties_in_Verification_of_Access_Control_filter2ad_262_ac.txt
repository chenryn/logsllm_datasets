### 优化后的文本

**表3总结了生成的变异体数量、被杀死的变异体数量以及每个策略在现有属性集P和增强属性集Pnew下的变异体杀灭率。表格中的每一行对应一个特定的变异操作符，列组1和2分别对应SIMPLE策略和CONTINUE策略。**

在案例研究中，如果某些变异操作符对于给定策略生成等价变异体，或者属性验证工具无法处理特定的XACML特性时，我们不会使用这些变异操作符。例如，由于当前Margrave的限制，我们省略了RCT（Rule Condition True）和RCF（Rule Condition False）操作，因为策略并未使用规则条件的这一特性。此外，Margrave在验证某些变异体时有时会报告错误。例如，某些属性要求特定元素存在于给定策略中。变异操作如PSTT（Policy Set Target True）可能会移除验证特定属性所必需的元素。这些错误正确地指示了变异体策略中的语义错误，因此我们认为这些变异体已被杀死。

PTT（Policy Target True）和PTF（Policy Target False）操作符在SIMPLE策略中有效地删除或修改顶层策略元素；这些操作符移除两个规则中的一个，导致显著的语义差异，立即被P和Pnew检测到。另一方面，CPC（Change Policy Combining Algorithm）和CRC（Change Rule Combining Algorithm）变异操作符生成等价变异体（即与原始策略语义等价的变异体），这些变异体无法被杀死。对于CONTINUE策略，CRC生成等价变异体。这种语义等价的变异体被检测并排除在我们的案例研究之外。

表3显示，现有的属性集P可以分别在SIMPLE和CONTINUE策略中杀死50%和11%的CRE变异体。通过手动指定一个反映SIMPLE策略中未覆盖规则的属性，我们可以杀死所有CRE变异体。正如预期的那样，增强的属性集Pnew仅提高了CRE变异体的杀灭率，因为其余变异体无法被杀死。对于CONTINUE策略，我们手动指定了六个属性，增强的属性集Pnew杀死了78%的CRE变异体。两个未覆盖的规则（即“存活”的CRE变异体）无法被杀死。Pnew还提高了其他变异操作符的变异体杀灭率。

我们观察到，有些类型的变异体即使使用Pnew也无法被杀死。例如，PSTT、CPC和CRC变异体以及RTT、RTF和CRC变异体无法被杀死。这些变异体可能与原始策略不完全等价，但属性集Pnew不足以杀死这些变异体。

### 讨论

我们认为，我们的方法可以应用于评估用其他语言编写的策略的质量，而不仅仅是XACML。以前的方法将一种语言（如XACML）的策略转换为其他具有验证工具的语言（如Alloy [12]、RW [23]和描述逻辑[14]）。由于我们的方法需要这些验证工具提供的属性验证（针对策略及其变异体），这种转换使得我们的方法也适用于其他策略语言和验证工具。

我们的变异验证方法提供了一种属性集质量评估。如果一个属性集实现了100%的变异体杀灭率，是否可以说该属性集是全面或完整的？这种情况类似于软件测试中的语句覆盖率。如果一个测试套件对给定程序实现了100%的语句覆盖率，是否可以说该测试套件能检测到程序中的所有错误？答案当然是否定的。虽然变异验证作为一种属性集质量评估方法，并且通过CRE变异操作符识别哪些属性与策略中的哪些规则交互，但它可能没有考虑到更抽象、通用的属性。例如，第2节示例中的P r1确保学生不能分配成绩。尽管这个属性是问题领域中的直观属性，但它并没有在策略本身中明确表达。该策略只包含允许访问的规则，而该属性关注的是拒绝访问。这并不意味着该属性不需要。第5节讨论了一个更好的例子，其中属性更像是与访问控制问题领域无关的最佳实践。

未来的工作将研究自动生成各种类型属性的方法，以覆盖更多规则和实体。在我们的案例研究中，我们根据CRE变异操作符的变异验证结果手动生成属性以覆盖未覆盖的规则。由于这些属性是从显式表达的未覆盖规则中提取的，因此每个属性都特别有效于杀死（之前未杀死的）规则。但这些属性可能无法杀死其他变异体。由于现有属性通常描述策略的更一般行为，因此需要进一步探索变异操作符，以便在变异验证过程中反映相关属性（不一定在策略本身中指定）。

### 相关工作

据我们所知，还没有定义度量标准来量化某个属性集对策略或模型的覆盖率。我们之前的关于策略变异测试的相关方法 [17] 定义了一个故障模型和相应的自动化变异器，以快速评估测试套件的质量；评估结果可以进一步用于评估测试生成和测试选择技术在故障检测能力方面的效果。这种策略变异测试与Ammann等人 [3] 提出的方法相关，该方法通过对模型（对应于我们工作中的策略）进行变异，然后使用模型变异体来评估测试套件的质量。我们的新方法利用了自动变异器 [17] 的变体来实现变异验证方法。然而，与这些先前评估测试套件质量的方法不同，我们的新方法侧重于基于变异策略来评估属性集的质量。

为了帮助确保策略规范的正确性，研究人员和从业者开发了正式验证工具。几种策略验证工具是专门为防火墙策略开发的。Al-Shaer和Hamed [2] 开发了防火墙策略顾问，用于分类和检测策略异常。Yuan等人 [22] 开发了FIREMAN工具，用于检测防火墙策略的配置错误。

还有几种可用于XACML策略的验证工具 [1]。Hughes和Bultan [11] 将XACML策略转换为Alloy语言 [12]，并使用Alloy分析器检查其属性。Schaad和Moffett [19] 也利用Alloy来检查基于角色的访问控制策略是否违反职责分离约束。Zhang等人 [24] 开发了一种模型检查算法和支持工具，用于评估用RW语言编写并可转换为XACML [23] 的访问控制策略。Kolaczek [13] 提议将基于角色的访问控制策略转换为Prolog进行验证。Kolovski等人 [14] 使用描述逻辑（DL）形式化XACML策略，这是一种一阶逻辑的可判定片段，并利用现有的DL验证器进行策略验证。Fisler等人 [9] 开发了Margrave，它可以验证XACML策略的属性（如果指定了属性），并在未指定属性时对策略的两个版本进行变更影响分析。当Margrave在策略验证期间检测到属性违规时，它会自动生成具体的反例，以说明指定属性的违规情况。类似地，当Margrave在变更影响分析期间检测到语义差异时，它会自动生成具体请求，揭示策略两个版本之间的语义差异。这些方法大多需要用户指定要验证的属性。我们的新方法补充了这些现有的策略验证方法，因为它有助于在策略验证过程中评估属性的质量。

我们之前的工作 [16] 提出了通过机器学习推断策略属性的方法。这些属性在实践中往往不可用，且其引出是一个具有挑战性和繁琐的任务。此外，一旦定义了属性，很难评估其有效性并确定需要改进的潜在问题区域。我们的变异验证方法旨在帮助缓解这一挑战。我们的实现利用了Margrave的属性验证功能来验证变异策略。

尽管存在各种软件程序的覆盖率标准 [25]，但直到最近才提出了访问控制策略的覆盖率标准 [18]。政策覆盖率标准是衡量政策测试程度和现有测试输入未覆盖的政策部分所必需的。Martin等人 [18] 定义了政策覆盖率并开发了政策覆盖率测量工具。由于开发人员手动生成政策测试输入非常繁琐，并且手动生成的测试输入往往不足以实现高政策覆盖率，他们开发了几种测试生成技术。与这些政策测试方法不同，我们的新方法侧重于评估政策验证中属性的质量。

### 结论

随着数据量和可用性的增长，对敏感信息的访问控制需求日益增加。为了将访问控制的语义与系统本身分离，策略作者越来越多地使用声明性语言（如XACML）来指定访问控制策略。这样做有助于管理和分析策略。为了提高对指定策略正确性的信心，策略作者可以正式验证策略的属性集。策略验证是确保访问控制策略正确指定的重要技术。由于验证过程的有效性直接取决于属性的质量，我们提出了一种称为变异验证的新方法来评估访问控制策略验证中属性集的质量。我们已经实现了一个适用于XACML策略的方法工具。我们将变异验证工具应用于现实世界软件系统的策略和属性。我们的经验表明，属性验证的性能令人鼓舞，变异验证可以扩展到足够大的访问控制策略。此外，变异验证是属性验证的一种互补方法，有助于属性的引出。

### 致谢

本工作得到了NSF资助CNS-0716579及其NIST补充的支持。

### 参考文献

[1] OASIS eXtensible Access Control Markup Language (XACML). http://www.oasis-open.org/committees/xacml/, 2005.
[2] E. Al-Shaer and H. Hamed. Discovery of policy anomalies in distributed firewalls. In Proc. INFOCOM, pages 2605–2616, 2004.
[3] P. Ammann and P. E. Black. A specification-based coverage metric to evaluate test sets. In Proc. HASE, pages 239–248, 1999.
[4] P. E. Ammann, P. E. Black, and W. Majurski. Using model checking to generate tests from specifications. In Proc. ICFEM, pages 46–54, 1998.
[5] T. A. Budd and A. S. Gopal. Program testing by specification mutation. Computer Languages, 10(1):63–73, 1985.
[6] N. Damianou, N. Dulay, E. Lupu, and M. Sloman. The Ponder policy specification language. In Proc. POLICY, pages 18–38, 2001.
[7] R. A. DeMillo, R. J. Lipton, and F. G. Sayward. Hints on test data selection: Help for the practicing programmer. IEEE Computer, 11(4):34–41, April 1978.
[8] D. F. Ferraiolo, D. R. Kuhn, and R. Chandramouli. Role-Based Access Control. Artech House, Inc., 2003.
[9] K. Fisler, S. Krishnamurthi, L. A. Meyerovich, and M. C. Tschantz. Verification and change-impact analysis of access-control policies. In Proc. ICSE, pages 196–205, 2005.
[10] G. Fraser and F. Wotawa. Using model-checkers for mutation-based test-case generation, coverage analysis and specification analysis. In Proc. ICSEA, pages 16–21, 2006.
[11] G. Hughes and T. Bultan. Automated verification of access control policies. Technical Report 2004-22, Department of Computer Science, University of California, Santa Barbara, 2004.
[12] D. Jackson, I. Shlyakhter, and M. Sridharan. A micromodularity mechanism. In Proc. ESEC/FSE, pages 62–73, 2001.
[13] G. Kolaczek. Specification and verification of constraints in role based access control for enterprise security system. In Proc. WETICE, pages 190–195, 2003.
[14] V. Kolovski, J. Hendler, and B. Parsia. Analyzing web access control policies. In Proc. WWW, pages 677–686, 2007.
[15] S. Krishnamurthi. The CONTINUE server (or, how i administered PADL 2002 and 2003). In Proc. PADL, pages 2–16, 2003.
[16] E. Martin and T. Xie. Inferring access-control policy properties via machine learning. In Proc. POLICY, pages 235–238, 2006.
[17] E. Martin and T. Xie. A fault model and mutation testing of access control policies. In Proc. WWW, pages 667–676, 2007.
[18] E. Martin, T. Xie, and T. Yu. Defining and measuring policy coverage in testing access control policies. In Proc. ICICS, pages 139–158, 2006.
[19] A. Schaad and J. D. Moffett. A lightweight approach to specification and analysis of role-based access control extensions. In Proc. SACMAT, pages 13–22, 2002.
[20] F. Somenzi. CUDD: CU Decision Diagram Package. http://vlsi.colorado.edu/~fabio/CUDD/.
[21] Y. L. Traon, T. Mouelhi, and B. Baudry. Testing security policies: Going beyond functional testing. In Proc. ISSRE, pages 93–102, 2007.
[22] L. Yuan, J. Mai, Z. Su, H. Chen, C.-N. Chuah, and P. Mohapatra. FIREMAN: A toolkit for FIREwall Modeling and ANalysis. In Proc. S&P, pages 199–213, May 2006.
[23] N. Zhang, M. Ryan, and D. P. Guelev. Synthesising verified access control systems in XACML. In Proc. FMSE, pages 56–65, 2004.
[24] N. Zhang, M. Ryan, and D. P. Guelev. Evaluating access control policies through model checking. In Proc. InfoSec, pages 446–460, 2005.
[25] H. Zhu, P. A. V. Hall, and J. H. R. May. Software unit test coverage and adequacy. ACM Comput. Surv., 29(4):366–427, 1997.