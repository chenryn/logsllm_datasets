### One-Way Delay and Congestion Magnitude

The one-way delay of the last 1000 probing packets before the kth packet is used to calculate the congestion magnitude (M). A higher value of M indicates more severe congestion in the path. Figure 7b illustrates the distribution of congestion magnitudes in the PlanetLab network. The average delay increase during half of the congestion events is less than 20 ms, and it does not exceed 50 ms in 90% of these events. The distribution of M in the other two networks follows a similar trend, but the maximum value of M is at most 60 ms. Finally, Figure 7c shows the relationship between the magnitude and duration of congestion events.

Interestingly, heavier congestion events tend to last for shorter durations, emphasizing that practical tomography methods should be capable of working with short-term measurements.

### Base Delay Calculation

The base delay of a path at time t is set to the median of the one-way delays among the last 100 packets received in that path before t. It's important to note that we have excluded cases where all packets sent or received over every path to or from a specific host are dropped, as such issues can be easily attributed to the corresponding sensor and its local-area network.

### Detection Process Results

Figure 7a, b, and c present the results of the detection process in the PlanetLab network, showing the cumulative distribution function (CDF) of congestion duration and magnitude, and the relationship between congestion magnitude and duration.

### Network Tomography Methods

Network tomography methods face challenges in localizing very short-duration congestion events because it is difficult to reliably detect such events and estimate their magnitude with active measurements. For example, even if the probing frequency is 10 packets per second, a congestion event lasting three seconds with a loss rate of 1% might not be observed by the probing stream. However, Range Tomography methods do not require a long measurement history or precise estimates of path performance, allowing them to localize congestion events that last for at least a few tens of seconds.

### Localization Results

We applied the Sum-Tomo algorithm to the detected congestion events to localize congested links. Ideally, a congested link should cause the same congestion event (in terms of duration and magnitude) for paths that traverse that link. In practice, however, these congestion periods do not exactly overlap due to imperfect clock synchronization in the measurement hosts. Therefore, we consider the time interval that covers all overlapping congestion periods as the designated congestion period for analysis.

The congestion magnitude M is then computed for each path during this designated period. To distinguish good paths from bad paths, we set the threshold δ as the minimum congestion magnitude over all detected congestion events in the network (δ is around 2 ms in practice). The α parameter is determined based on Method-2, introduced in Section 5.1. This process results in α = 2 in Internet2 and ESNet, and α = 1.2 in PlanetLab. Paths containing links with unknown IP addresses (which only occur in the PlanetLab dataset) are ignored in our experiments.

### Validation

Direct validation of the Sum-Tomo algorithm results is not possible because we do not have access to the routers and switches along each path. Instead, we use an indirect validation method [19]. In this method, the measured paths in each period are divided into two groups: inference paths and validation paths. Each link should be included in both sets. The inference paths are used to identify congested links and estimate their congestion magnitude range using the Sum-Tomo algorithm. The validation paths are then used to check if the ranges computed based on the inference paths are consistent with the measured congestion magnitude of the validation paths. The validation error is measured as the fraction of bad links where the estimated congestion magnitude range is not consistent with the measured congestion magnitude in the corresponding validation path.

### Experimental Analysis

We analyzed 254 congestion events in Internet2, 336 events in ESNet, and 159 events in PlanetLab. In almost all events, only one congested link was identified as the root cause. Specifically, more than 97% of congested paths in all three networks include just one congested link, and only 0.5% of paths contain more than two congested links. The validation error in all three datasets was zero. Additionally, the time-series of one-way delay variations in the inference and validation paths are highly correlated when the corresponding congested paths traverse the same congested link. For instance, the time-series in Figure 8 show an interesting example of a congestion event in Internet2 involving two congested links. The congestion magnitude range assigned to links is mostly below 70 ms in PlanetLab and less than 40 ms in Internet2 and ESNet.

### Related Work

For a comprehensive review of prior work up to 2004, see [10]. Analog tomography models the relation between path and link parameters using a typically under-constrained linear system of equations. Techniques from parametric or non-parametric statistical inference, along with additional constraints, assumptions, and optimization objectives, are used to infer the most likely values of the link parameters from the measured path parameters [10, 11]. For example, Shavitt et al. [12] estimate link delays using a least-squares method, Bu et al. [13] use expectation-maximization to infer link loss rates, and Chen et al. [14] use Fourier domain analysis to infer link delays. NetScope [15] is a recent method that estimates link loss rates, considering the observed loss rate variances. Ghita et al. [16] study the case where different links can be correlated, while other related work assumes independent links. The application of Analog tomography in practice has been limited due to several reasons: the need for accurate end-to-end path measurements, which are hard to obtain in short timescales without intrusive probing; some link-level parameters may not be statistically identifiable; and Analog methods can be computationally intensive [5, 6, 7].

Duffield introduced the Boolean tomography framework in 2003 [5, 7], and Nguyen and Thiran compared Analog with Boolean tomography [17]. NetDiagnoser [8] extends Boolean tomography to multiple sources and destinations. Kompella et al. [18] consider a similar approach to detect "silent failures" in MPLS/IP networks using active measurements between edge routers. Bayesian approaches to infer lossy links have also been proposed [19]. The authors in [20] use prior link state probabilities to diagnose the underlying cause behind faulty states of links. Barford et al. [21] proposed a framework to detect and localize performance anomalies using active probe-based measurements and an algorithm to select the paths that should be probed at any point in time to reduce probing overhead.

### Conclusions

We proposed a new tomography framework, Range Tomography, which combines the best features of Analog and Boolean tomography. This framework estimates a range for each bad link instead of aiming to infer a point estimate or a binary estimate for every link. We applied the Range Tomography framework to two path performance metric functions (Min and Sum) and presented an efficient heuristic for each function. The Min-Tomo algorithm considers only the lowest-performance link over a path, while the Sum-Tomo algorithm considers the sum of the performance metrics for all bad links in that path.

Simulation results show that the proposed tomography method performs better than earlier Boolean and Analog techniques in terms of precision, recall, and accuracy. For instance, Sum-Tomo generates up to 35% fewer false positives than the Analog Norm-minimization method, and its false negative error is up to 15% lower than the Boolean Tomo method. The accuracy of the resulting range estimates is consistently high (more than 93%).

We also applied the Sum-Tomo method in three operational networks to detect and localize congested links and estimate their congestion magnitude. According to an indirect validation method, the resulting link range estimate is consistent with the measured path congestion magnitude in every congestion event we analyzed. The experimental results emphasize that congestion events in Internet paths are often short-lived, and practical tomography methods should be accurate even if the path measurements result from few probes and are error-prone. In the networks we measured, we often saw only one bad link during any congestion event, and rarely more than 2-3 bad links.

### Acknowledgements

We are grateful to Partha Kanuparthy for his help with the detection logic and data management. We also thank Jason Zurawski from Internet2, and Joe Metzger, Brian Tierney, and Andrew Lake from ESnet for providing us with the OWAMP datasets. We are also grateful to the anonymous reviewers and our "shepherd," Matthias Grossglauser, for their constructive comments. This research was supported by the U.S. Department of Energy under grant number DE-FG02-10ER26021.

### References

[1] R. Caceres, N.G. Duffield, J. Horowitz, D. Towsley. Multicast-Based Inference of Network Internal Loss Characteristics. IEEE Trans. on Information Theory, 45(7), 2462-2480, 1999.
[2] M. Coates, R. Nowak. Network loss inference using unicast end-to-end measurement, In Proc. ITC Conf. IP Traffic, Modeling and Management, 2000.
[3] Y. Zhang, N. Duffield, V. Paxson, S. Shenker. On the Constancy of Internet Path Properties. In ACM SIGCOMM Workshop on Internet Measurement, 2001.
[4] M. Roughan. Fundamental Bounds on the Accuracy of Network Performance Measurements. In ACM SIGMETRICS, 2005.
[5] N. Duffield. Simple network performance tomography. In Proc. ACM IMC, 2003.
[6] H. Nguyen, and P. Thiran. The Boolean Solution to the Congested IP Link Location Problem: Theory and Practice. In Proc. IEEE INFOCOM, 2007.
[7] N. Duffield. Network Tomography of Binary Network Performance Characteristics. In IEEE Trans. Information Theory, 52, 2006.
[8] A. Dhamdhere, R. Teixeira, C. Dovrolis, C. Diot. NetDiagnoser: Troubleshooting network unreachabilities using end-to-end probes and routing data. In Proc. ACM CoNEXT, 2007.
[9] M. R. Garey, and D. S. Johnson. Computers and Intractability: A Guide to the Theory of NP-Completeness. W. H. Freeman and Co., 1979.
[10] R. Castro, M. Coates, G. Liang, R. Nowak, B. Yu. Network Tomography: Recent Developments. Statistical Science, 19(3):499-517, 2004.
[11] R. Caceres, N. Duffield, S. Moon, D. Towsley. Inference of Internal Loss Rates in the MBone. In Proc. IEEE Global Internet, 1999.
[12] Y. Shavitt, X. Sun, A. Wool, B. Yener. Computing the unmeasured: An algebraic approach to internet mapping. In Proc. IEEE INFOCOM, 2001.
[13] T. Bu, N. Duffield, F. L. Presti, D. Towsley. Network tomography on general topologies. In Proc. ACM SIGMETRICS, 2002.
[14] A. Chen, J. Cao, T. Bu. Network tomography: Identifiability and fourier domain estimation. In Proc. IEEE INFOCOM, 2007.
[15] D. Ghita, H. Nguyen, M. Kurant, K. Argyraki, P. Thiran. Netscope: Practical Network Loss Tomography. In Proc. IEEE INFOCOM, 2010.
[16] D. Ghita, K. Argyraki, P. Thiran. Network Tomography on Correlated Links. In Proc. ACM IMC, 2010.
[17] H. X. Nguyen, and P. Thiran. Binary versus analogue path monitoring in IP networks. In LNCS, Vol. 3431, Jan. 2005, p. 97.
[18] R. R. Kompella, J. Yates, A. Greenberg, A. C. Snoeren. Detection and Localization of Network Blackholes. In Proc. IEEE INFOCOM, 2007.
[19] V. Padmanabhan, L. Qiu, H. Wang. Server-based Inference of Internet Link Lossiness. In Proc. IEEE INFOCOM, 2003.
[20] S. Kandula, D. Katabi, J.-P. Vasseur. Shrink: A Tool for Failure Diagnosis in IP Networks. In Proc. ACM SIGCOMM MineNet Workshop, 2005.
[21] P. Barford, N. Duffield, A. Ron, and J. Sommers. Network Performance Anomaly Detection and Localization. In Proc. IEEE INFOCOM, 2009.
[22] B. Augustin et al. Avoiding traceroute anomalies with Paris traceroute, In Proc. ACM IMC, 2006.
[23] H. H. Song, L. Qiu, Y. Zhang. NetQuest: A Flexible Framework for Large-Scale Network Measurement. In Proc. ACM SIGMETRICS, 2006.
[24] H. X. Nguyen, and P. Thiran. Network Loss Inference with Second Order Statistics of End-to-End Flows. In Proc. ACM IMC, 2007.
[25] Y. Zhao, Y. Chen, D. Bindel, Towards Unbiased End-to-End Network Diagnosis, In Proc. ACM SIGCOMM, 2006.
[26] M. Luckie, A. Dhamdhere, K. Claffy, D. Murrell. Measured impact of crooked traceroute. In ACM SIGCOMM CCR, Vol. 41, Issue 1, 2011.