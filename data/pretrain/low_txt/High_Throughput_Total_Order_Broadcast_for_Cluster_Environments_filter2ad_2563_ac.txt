### Throughput and Latency Evaluation

To measure throughput, we use the time interval between the start message and the acknowledgment of the last message. We ensure that the acknowledgment latency is negligible compared to the overall experience time. We also conduct the same experiment but with only one sender and one message. Repeating this experiment several times allows us to determine the average latency in a contention-free scenario.

#### Figure 7: Latency as a Function of Throughput
- **Latency (ms)**
  - 600
  - 500
  - 400
  - 300
  - 200
  - 100
  - 0
- **Throughput (Mb/s)**
  - 0
  - 10
  - 20
  - 30
  - 40
  - 50
  - 60
  - 70
  - 80
  - 90

Figure 7 plots the latency as a function of throughput. The experiments involved n-to-n TO-broadcasts of 100KB messages between 5 processes. The results were obtained by throttling the senders to a given sending rate and reporting the corresponding average latency and throughput. This graph shows that the latency remains almost constant up to a certain throughput, after which it increases.

#### Figure 8: Throughput as a Function of the Number of Processes
- **Throughput (Mb/s)**
  - 100
  - 90
  - 80
  - 70
  - 60
  - 50
  - 40
- **Number of Processes**
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10

Figure 8 plots the maximum throughput as a function of the number of processes. The experiments involved n-to-n TO-broadcasts of 100KB messages. The graph shows that FSR achieves a throughput of 79 Mbit/s on a 100 Mbit/s switched Ethernet network. Moreover, it demonstrates that the achieved throughput is independent of the number of processes in the ring, confirming our analysis.

### Latency Evaluation

Figure 6 plots the latency without contention as a function of the number of processes. The experiments consisted of n-to-n TO-broadcasts of 100KB messages. The represented latency is the average of the latencies observed at each sender. The graph shows that the latency is linear with respect to the number of processes, which confirms the theoretical analysis.

### Throughput Evaluation

Figure 7 plots the latency as a function of the throughput. The experiments involved n-to-n TO-broadcasts of 100KB messages between 5 processes. The results were obtained by throttling the senders to a given sending rate and reporting the corresponding average latency and throughput. This graph shows that the latency is almost constant until the maximum throughput is reached. Then, unprocessed messages are stored in local queues at each process, which explains the significant increase in observed latency.

### Summary

This paper introduces FSR, a uniform total order broadcast protocol designed for the main communication block of a replication scheme to achieve software-based fault tolerance. FSR is the first uniform total order broadcast protocol that consistently provides high throughput, whether one or multiple processes continuously TO-broadcast messages. High throughput is defined as the ability to deliver the largest possible number of messages, regardless of message broadcast patterns. This notion is precisely defined in a round-based model of computation, which captures message passing interaction patterns over clusters of homogeneous machines interconnected by fully switched LANs. We believe that the model is valuable in its own right and can be used to evaluate the performance of other protocols.

FSR is based on a ring topology, relies solely on point-to-point inter-process communication, and has linear latency with respect to the number of processes. FSR is also fair in the sense that each process has an equal opportunity for its messages to be delivered by all processes.

### References

[1] Y. Amir, L. E. Moser, P. M. Melliar-Smith, D. A. Agarwal, and P. Ciarfella. The Totem single-ring ordering and membership protocol. ACM Transactions on Computer Systems, 13(4):311–342, 1995.
[2] E. Anceaume. A lightweight solution to uniform atomic broadcast for asynchronous systems. In Proceedings of the 27th International Symposium on Fault-Tolerant Computing (FTCS ’97), Washington, DC, USA, 1997. IEEE Computer Society.
[3] S. Armstrong, A. Freier, and K. Marzullo. Multicast transport protocol. RFC 1301, IETF, 1992.
[4] R. Baldoni, S. Cimmino, and C. Marchetti. A Classification of Total Order Specifications and its Application to Fixed Sequencer-based Implementations. to appear in Journal of Parallel and Distributed Computing, June 2006.
[5] A. Bar-Noy and S. Kipnis. Designing broadcasting algorithms in the postal model for message-passing systems. Mathematical Systems Theory, 27(5):431–452, 1994.
[6] K. Birman and T. Joseph. Exploiting virtual synchrony in distributed systems. In Proceedings of the eleventh ACM Symposium on Operating systems principles (SOSP’87), pages 123–138, New York, NY, USA, 1987. ACM Press.
[7] K. Birman and T. Joseph. Reliable communication in the presence of failures. ACM Trans. Comput. Syst., 5(1):47–76, 1987.
[8] K. Birman and R. van Renesse. Reliable Distributed Computing with the Isis Toolkit. IEEE Computer Society Press, 1993.
[9] R. Carr. The tandem global update protocol. Tandem Syst. Rev. 1, pages 74–85, jun 1985.
[10] T. Chandra and S. Toueg. Unreliable failure detectors for reliable distributed systems. J. ACM, 43(2):225–267, 1996.
[11] T. Chandra and S. Toueg. Unreliable failure detectors for reliable distributed systems. Journal of the ACM, 43(2):225–267, 1996.
[12] J.-M. Chang and N. Maxemchuk. Reliable broadcast protocols. ACM Trans. Comput. Syst., 2(3):251–273, 1984.
[13] F. Cristian. Asynchronous atomic broadcast. IBM Technical Disclosure Bulletin, 33(9):115–116, 1991.
[14] F. Cristian, S. Mishra, and G. Alvarez. High-performance asynchronous atomic broadcast. Distrib. Syst. Eng. J., 4(2):109–128, jun 1997.
[15] D. Culler, R. Karp, D. Patterson, A. Sahay, K. Schauser, E. Santos, R. Subramonian, and T. von Eicken. LogP: Towards a realistic model of parallel computation. In Principles Practice of Parallel Programming, pages 1–12, 1993.
[16] X. Défago, A. Schiper, and P. Urbán. Comparative performance analysis of ordering strategies in atomic broadcast algorithms. IEICE Trans. on Information and Systems, E86-D(12):2698–2709, 2003.
[17] X. Défago, A. Schiper, and P. Urbán. Total order broadcast and multicast algorithms: Taxonomy and survey. ACM Comput. Surv., 36(4):372–421, 2004.
[18] R. Ekwall, A. Schiper, and P. Urban. Token-based atomic broadcast using unreliable failure detectors. In Proceedings of the 23rd IEEE International Symposium on Reliable Distributed Systems (SRDS’04), pages 52–65, Washington, DC, USA, 2004. IEEE Computer Society.
[19] P. Ezhilchelvan, R. Macedo, and S. Shrivastava. Newtop: a fault-tolerant group communication protocol. In Proceedings of the 15th International Conference on Distributed Computing Systems (ICDCS’95), Washington, DC, USA, 1995. IEEE Computer Society.
[20] T. Friedman and R. V. Renesse. Packing messages as a tool for boosting the performance of total ordering protocols. In Proceedings of the 6th International Symposium on High Performance Distributed Computing (HPDC ’97), Washington, DC, USA, 1997. IEEE Computer Society.
[21] U. Fritzke, P. Ingels, A. Mostefaoui, and M. Raynal. Consensus-based fault-tolerant total order multicast. IEEE Trans. Parallel Distrib. Syst., 12(2):147–156, 2001.
[22] H. Garcia-Molina and A. Spauster. Ordered and reliable multicast communication. ACM Trans. Comput. Syst., 9(3):242–271, 1991.
[23] A. Gopal and S. Toueg. Reliable broadcast in synchronous and asynchronous environments (preliminary version). In Proceedings of the 3rd International Workshop on Distributed Algorithms, pages 110–123, London, UK, 1989. Springer-Verlag.
[24] R. Guerraoui and A. Schiper. Software-based replication for fault tolerance. Computer, 30(4):68–74, 1997.
[25] V. Hadzilacos and S. Toueg. Fault-tolerant broadcasts and related problems. Distributed systems (2nd Ed.), pages 97–145, 1993.
[26] F. Kaashoek and A. Tanenbaum. An evaluation of the Amoeba group communication system. In Proceedings of the 16th International Conference on Distributed Computing Systems (ICDCS ’96), Washington, DC, USA, 1996. IEEE Computer Society.
[27] J. Kim and C. Kim. A total ordering protocol using a dynamic token-passing scheme. Distrib. Syst. Eng. J., 4(2):87–95, jun 1997.
[28] M. Leclercq, V. Quéma, and J.-B. Stefani. DREAM: a Component Framework for the Construction of Resource-Aware, Configurable MOMs. IEEE Distributed Systems Online, 6(9), September 2005.
[29] S. Luan and V. Gligor. A fault-tolerant protocol for atomic broadcast. IEEE Trans. Parallel Distrib. Syst., 1(3):271–285, 1990.
[30] N. A. Lynch. Distributed Algorithms. Morgan-Kaufmann, 1996.
[31] L. Malhis, W. Sanders, and R. Schlichting. Numerical performability evaluation of a group multicast protocol. Distrib. Syst. Eng. J., 3(1):39–52, march 1996.
[32] L. Moser, P. Melliar-Smith, and V. Agrawala. Asynchronous fault-tolerant total ordering algorithms. SIAM J. Comput., 22(4):727–750, 1993.
[33] Netperf. http://www.netperf.org/.
[34] T. Ng. Ordered broadcasts for large applications. In Proceedings of the 10th IEEE International Symposium on Reliable Distributed Systems (SRDS’91), pages 188–197, Pisa, Italy, 1991. IEEE Computer Society.
[35] L. Peterson, N. Buchholz, and R. Schlichting. Preserving and using context information in interprocess communication. ACM Trans. Comput. Syst., 7(3):217–246, 1989.
[36] L. Rodrigues, H. Fonseca, and P. Verissimo. Totally ordered multicast in large-scale systems. In Proceedings of the 16th International Conference on Distributed Computing Systems (ICDCS ’96), Washington, DC, USA, 1996. IEEE Computer Society.
[37] Sun. Java 2 Platform, Enterprise Edition (J2EE). http://java.sun.com/j2ee/.
[38] P. Urbán, X. Défago, and A. Schiper. Contention-aware metrics for distributed algorithms: Comparison of atomic broadcast algorithms. In Proceedings of 9th IEEE International Conference on Computer Communications and Networks (IC3N 2000), pages 582–589, 2000.
[39] P. Vicente and L. Rodrigues. An indulgent uniform total order algorithm with optimistic delivery. In Proceedings of the 21st IEEE Symposium on Reliable Distributed Systems (SRDS’02), Washington, DC, USA, 2002. IEEE Computer Society.
[40] B. Whetten, T. Montgomery, and S. Kaplan. A high performance totally ordered multicast protocol. In Selected Papers from the International Workshop on Theory and Practice in Distributed Systems, pages 33–57, London, UK, 1994. Springer-Verlag.
[41] U. Wilhelm and A. Schiper. A hierarchy of totally ordered multicasts. In Proceedings of the 14th Symposium on Reliable Distributed Systems, Washington, DC, USA, 1995. IEEE Computer Society.