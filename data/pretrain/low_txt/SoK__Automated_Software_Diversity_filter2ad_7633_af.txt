### B. Error Reports and Patches

Current best practices in software development dictate that program crashes on end-user systems should be reported back to the developers. These reports are crucial for prioritizing and addressing bugs, as well as for generating software updates that enhance the stability and security of the product.

Error reports typically include machine state information such as the instruction pointer, stack, and register contents at the time of the crash. These reports are sent to a server that performs two primary tasks: it uses debug information to determine the source code location of the crash, and it matches the new error report with previous reports to rank bugs by frequency.

However, software diversity can complicate the processing of error reports. The randomization of program implementations can cause error reports to diverge, even if two users trigger the same error. Since programs are usually distributed without debugging information, they report crashes using the instruction pointer, stack, and register contents. Developers store a single copy of the debugging information for each software release to translate locations in the binary into source code locations, a process known as symbolication. With code layout randomization, the instruction pointer corresponding to a particular source code line will vary between variants, which can interfere with the symbolication of error reports.

A straightforward but impractical solution is to generate or store debug information for each program variant on the error reporting server. This approach is space-consuming and not feasible for client-side diversification. A more practical alternative is to transform error reports into a "canonical" version that matches what an undiversified copy of the program would report for the same error. This requires integrating with existing error reporting mechanisms and using metadata to drive the transformations.

Diversification approaches that randomize the on-disk representation of programs also interfere with software patches. If each user has a unique program copy, patches must be customized for each individual copy. These challenges have not received much attention to date.

### C. Implementation Disclosure

In addition to low entropy, information leakage poses a significant threat to the effectiveness of diversified defenses. Information leaks are accidental disclosures of the layout or contents of process or kernel memory. Address Space Layout Randomization (ASLR) shifts all addresses by the same amount, so relative distances within a library remain unchanged. This means that an attacker can infer the entire code layout if a single code address is disclosed.

Finer-grained code randomization affects the relative distances between code fragments, making it more difficult for attackers to bypass randomization. However, this still requires the disclosure of multiple code addresses. For example, Snow et al. [60] demonstrated a just-in-time code-reuse attack that uses JavaScript to discover the code layout via a bounds checking error in C++ code and to build a customized Return-Oriented Programming (ROP) chain, thus defeating fine-grained code diversification. Bittau et al. [9] performed a "blind return-oriented-programming" attack by exploiting a buffer overflow in the nginx web-server and using the response (crash, no crash) as a side channel to incrementally guess the position of a required gadget set in fully diversified binaries. These attacks highlight the need for new types of diversity that prevent or tolerate (partial) information disclosure.

Crane et al. [20] proposed that diversified binaries be "booby-trapped" with code that detects guessing attacks. A booby-trap is an instruction sequence beginning with an unconditional branch past its last instruction, so the trap is skipped during normal execution. Attempts to execute code at random addresses will eventually trigger the trap. Traps help alert defenders to attacks and may even allow programs to operate through attacks by recovering corrupted state.

### D. Measuring Efficacy

The study of how diversity affects the adversary's effort is still in its early stages. Many works report detailed performance metrics on standardized benchmarks, but security evaluations are often qualitative, based on logical arguments, analytical calculations of resulting entropy, or demonstrations of concrete attacks that fail.

Few studies quantify the impact of diversification, such as by counting surviving gadgets when defending against ROP attacks [31] or the percentage of code that can be matched after diversification [17]. Entropy results determine the space of a diversified population, but there are no studies showing how well program variants are distributed within that space. This is important because some transformations are not always legal; performing equivalent instruction selection on a program with thousands of functions can generate many variants in principle, but if only a handful of functions use instructions that can be substituted, the resulting population is not sufficiently diverse.

We believe the reasons for this are twofold: a lack of consensus on acceptable methodologies and the absence of publicly available tools to evaluate and compare approaches. Numerous papers have been published on how to perform sound performance evaluations, and we think a similar effort should be undertaken with respect to efficacy metrics for diversified software.

### E. Diversity as a Counter to Side-Channel Attacks

Covert channels exist whenever computation has observable side effects. For example, the time to divide two numbers depends on the operands, and the time to access a memory location depends on the state of the memory hierarchy. Attackers can build statistical models that correlate sensitive program data, such as cryptographic keys, with these side effects by observing the target program operating on known inputs. The growing popularity of cloud computing, which co-locates the computation of its customers on shared hardware, increases the need for a solution to this long-standing problem.

One key requirement for building a side-channel attack is the ability to accurately replicate the victim environment. Software diversity breaks this assumption by preventing attackers from easily accessing an exact copy of the target program. Consequently, we expect that existing and side-channel-specific randomizing transformations provide an effective counter to this long-standing threat.

### VII. Conclusions

The overall idea of software diversity is simple, but its interactions with current development, distribution, and security practices are complex. We bring clarity to this field by treating the major axes of software diversity independently while using consistent terminology.

There is a tension between pre-distribution and post-distribution diversification approaches. Pre-distribution approaches are easy to implement portably, support a wide range of transformations, and can defend against client-side attacks. Post-distribution approaches support legacy and proprietary software, amortize diversification costs, and require no changes to current distribution mechanisms. In terms of performance, both types of approaches can deliver acceptable overheads (as low as 1-5%). However, the two fastest binary rewriters may not preserve program semantics [47], [21].

With two exceptions [21], [40], research in software diversity does not consider compatibility with security features such as crash reporting and code signing. Naturally, the research in software diversity can be extended, and we point out several promising directions. There is currently a lack of research on hybrid approaches combining aspects of compilation and binary rewriting to address practical challenges of current techniques. We also highlight the need to address memory disclosure attacks on diversity and argue that diversified software may provide an effective defense against side-channel attacks.

### Acknowledgments

We thank the anonymous reviewers, Prof. Greg Morrisett, Stephen Crane, and Mark Murphy for their insightful reviews, helpful suggestions, and proofreading.

This material is based upon work partially supported by the Defense Advanced Research Projects Agency (DARPA) under contracts D11PC20024 and N660001-1-2-4014, by the National Science Foundation (NSF) under grant No. CCF-1117162, and by a gift from Google.

Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Defense Advanced Research Projects Agency (DARPA), its Contracting Agents, the National Science Foundation, or any other agency of the U.S. Government.

### References

[1] M. Abadi, M. Budiu, Ú. Erlingsson, and J. Ligatti. Control-flow integrity. In Proceedings of the 12th ACM Conference on Computer and Communications Security, CCS '05, pages 340–353, 2005.
[2] Aleph One. Smashing the Stack for Fun and Profit. Phrack Magazine, 7(49), 1996. http://www.phrack.org/issues.html?id=14&issue=49.
[3] K. Anand, M. Smithson, K. Elwazeer, A. Kotha, J. Gruen, N. Giles, and R. Barua. A compiler-level intermediate representation based binary analysis and rewriting system. In Proceedings of the 8th ACM European Conference on Computer Systems, EuroSys '13, pages 295–308, 2013.
[4] A. Avizienis and L. Chen. On the implementation of N-version programming for software fault tolerance during execution. In Proceedings of the International Computer Software and Applications Conference, COMPSAC '77, pages 149–155, 1977.
[5] E. Barrantes, D. Ackley, S. Forrest, and D. Stefanović. Randomized instruction set emulation. ACM Transactions on Information and System Security, 8(1):3–40, 2005.
[6] S. Bhatkar, D. DuVarney, and R. Sekar. Address obfuscation: An efficient approach to combat a broad range of memory error exploits. In Proceedings of the 12th USENIX Security Symposium, SEC '03, pages 105–120, 2003.
[7] S. Bhatkar and R. Sekar. Data space randomization. In Proceedings of the Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA '08, pages 1–22, 2008.
[8] S. Bhatkar, R. Sekar, and D. DuVarney. Efficient techniques for comprehensive protection from memory error exploits. In Proceedings of the 14th USENIX Security Symposium, SEC '05, pages 271–286, 2005.
[9] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazières, and D. Boneh. Hacking blind. In Proceedings of the 35th IEEE Symposium on Security and Privacy, S&P '14, 2014.
[10] D. Blazakis. Interpreter exploitation. In Proceedings of the 4th USENIX Workshop on Offensive Technologies, WOOT'10, 2010.
[11] L. Chen and A. Avizienis. N-version programming: A fault-tolerance approach to reliability of software operation. In Twenty-Fifth International Symposium on Fault-Tolerant Computing, 1995, 'Highlights from Twenty-Five Years', FTCS '95, page 113, 1995.
[12] M. Chew and D. Song. Mitigating buffer overflows by operating system randomization. Technical Report CMU-CS-02-197, Department of Computer Science, Carnegie Mellon University, 2002.
[13] F. Cohen. Operating system protection through program evolution. Computers and Security, 12(6):565–584, Oct. 1993.
[14] C. Collberg, C. Thomborson, and D. Low. A taxonomy of obfuscating transformations. Technical Report 148, Department of Computer Science, University of Auckland, New Zealand, 1997.
[15] C. S. Collberg, S. Martin, J. Myers, and J. Nagra. Distributed application tamper detection via continuous software updates. In Proceedings of the 28th Annual Computer Security Applications Conference, ACSAC '12, pages 319–328, 2012.
[16] C. S. Collberg, C. D. Thomborson, and D. Low. Manufacturing cheap, resilient, and stealthy opaque constructs. In Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL '98, pages 184–196, 1998.
[17] B. Coppens, B. De Sutter, and J. Maebe. Feedback-driven binary code diversification. Transactions on Architecture and Code Optimization, 9(4), Jan. 2013.
[18] B. Coppens, B. D. Sutter, and K. D. Bosschere. Protecting your software updates. IEEE Security & Privacy, 11(2):47–54, 2013.
[19] C. Cowan, C. Pu, D. Maier, J. Walpole, P. Bakke, D. Beattie, A. Grier, P. Wagle, Q. Zhang, and H. Hinton. StackGuard: Automatic Adaptive Detection and Prevention of Buffer-Overflow Attacks. In Proceedings of the 7th USENIX Security Symposium, SEC '98, pages 63–78, 1998.
[20] S. Crane, P. Larsen, S. Brunthaler, and M. Franz. Booby trapping. In Proceedings of the 2013 Workshop on New Security Paradigms, NSPW '13, pages 95–106, 2013.
[21] L. V. Davi, A. Dmitrienko, S. Nürnberger, and A.-R. Sadeghi. Gadge me if you can: Secure and efficient ad-hoc instruction-level randomization for x86 and ARM. In Proceedings of the 8th ACM Symposium on Information, Computer and Communications Security, ASIACCS '13, pages 299–310, 2013.
[22] B. De Sutter, B. Anckaert, J. Geiregat, D. Chanet, and K. Bosschere. Instruction set limitation in support of software diversity. In P. Lee and J. Cheon, editors, Information Security and Cryptology ICISC '08, volume 5461 of Lecture Notes in Computer Science, pages 152–165. Springer Berlin Heidelberg, 2009.
[23] R. El-Khalil and A. D. Keromytis. Hydan: Hiding information in program binaries. In Proceedings of the 6th International Conference on Information and Communications Security, ICICS '04, pages 187–199, 2004.
[24] S. Forrest, A. Somayaji, and D. Ackley. Building diverse computer systems. In Proceedings of the Workshop on Hot Topics in Operating Systems, HotOS '97, pages 67–72, 1997.
[25] M. Franz. E unibus pluram: Massive-scale software diversity as a defense mechanism. In Proceedings of the 2010 Workshop on New Security Paradigms, NSPW '10, pages 7–16, 2010.
[26] D. Geer, C. P. Pflueger, B. Schneier, J. S. Quarterman, P. Metzger, R. Bace, and P. Gutmann. CyberInsecurity: The cost of monopoly – how the dominance of Microsoft’s products poses a risk to security. Computer and Communications Industry Association, 2003.
[27] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum. Enhanced operating system security through efficient and fine-grained address space randomization. In Proceedings of the 21st USENIX Security Symposium, SEC '12, pages 475–490, 2012.
[28] A. Gupta, S. Kerr, M. Kirkpatrick, and E. Bertino. Marlin: A fine-grained randomization approach to defend against ROP attacks. In J. Lopez, X. Huang, and R. Sandhu, editors, Network and System Security, volume 7873 of Lecture Notes in Computer Science, pages 293–306. Springer Berlin Heidelberg, 2013.
[29] J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. Davidson. ILR: Where'd my gadgets go? In Proceedings of the 33rd IEEE Symposium on Security and Privacy, S&P '12, pages 571–585, 2012.
[30] A. Homescu, S. Brunthaler, P. Larsen, and M. Franz. librando: Transparent code randomization for just-in-time compilers. In Proceedings of the 20th ACM Conference on Computer and Communications Security, CCS'13, pages 993–1004, 2013.
[31] A. Homescu, S. Neisius, P. Larsen, S. Brunthaler, and M. Franz. Profile-guided automatic software diversity. In Proceedings of the 11th IEEE/ACM International Symposium on Code Generation and Optimization, CGO '13, pages 1–11, 2013.
[32] A. Homescu, M. Stewart, P. Larsen, S. Brunthaler, and M. Franz. Microgadgets: Size does matter in Turing-complete return-oriented programming. In Proceedings of the 6th USENIX Workshop on Offensive Technologies, WOOT '12, pages 64–76, 2012.
[33] R. N. Horspool and N. Marovac. An approach to the problem of detranslation of computer programs. Comput. J., 23(3):223–229, 1980.
[34] T. Jackson, A. Homescu, S. Crane, P. Larsen, S. Brunthaler, and M. Franz. Diversifying the software stack using randomized NOP insertion. In S. Jajodia, A. K. Ghosh, V. Subrahmanian, V. Swarup, C. Wang, and X. S. Wang, editors, Moving Target Defense II, volume 100 of Advances in Information Security, pages 151–173. Springer New York, 2013.
[35] T. Jackson, B. Salamat, A. Homescu, K. Manivannan, G. Wagner, A. Gal, S. Brunthaler, C. Wimmer, and M. Franz. Compiler-generated software diversity. In S. Jajodia, A. K. Ghosh, V. Swarup, C. Wang, and X. S. Wang, editors, Moving Target Defense, volume 54 of Advances in Information Security, pages 77–98. Springer New York, 2011.
[36] M. Jacob, M. Jakubowski, P. Naldurg, C. Saw, and R. Venkatesan. The superdiversifier: Peephole individualization for software protection. In K. Matsuura and E. Fujisaki, editors, Advances in Information and Computer Security, volume 5312 of Lecture Notes in Computer Science, pages 100–120. Springer Berlin / Heidelberg, 2008.
[37] G. S. Kc, A. D. Keromytis, and V. Prevelakis. Countering code-injection attacks with instruction-set randomization. In Proceedings of the 10th ACM Conference on Computer and Communications Security, CCS '03, pages 272–280, 2003.
[38] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning. Address space layout permutation (ASLP): Towards fine-grained randomization of commodity software. In Proceedings of the 22nd Annual Computer Security Applications Conference, ACSAC '06, pages 339–348, 2006.
[39] S. Krahmer. x86-64 buffer overflow exploits and the borrowed code chunks exploitation techniques, 2005. http://www.suse.de/~krahmer/no-nx.pdf.
[40] P. Larsen, S. Brunthaler, and M. Franz. Security through diversity: Are we there yet? IEEE Security & Privacy, 12(2):28–35, 2014.
[41] C. Linn and S. K. Debray. Obfuscation of executable code to improve resistance to static disassembly. In Proceedings of the 10th ACM Conference on Computer and Communications Security, CCS '03, pages 290–299, 2003.
[42] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood. Pin: Building customized program analysis tools with dynamic instrumentation. In Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI '05, pages 190–200, 2005.
[43] S. McCamant and G. Morrisett. Evaluating SFI for a CISC architecture. In Proceedings of the 15th USENIX Security Symposium, SEC '06, pages 209–224, 2006.
[44] Nergal. The advanced return-into-lib(c) exploits: PaX case study. Phrack Magazine, 11(58), 2001. http://www.phrack.org/issues.html?issue=58&id=4.
[45] N. Nethercote and J. Seward. Valgrind: A framework for heavyweight dynamic binary instrumentation. In Proceedings of the 2007 ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI '07, pages 89–100, 2007.
[46] G. Novark and E. D. Berger. Dieharder: Securing the heap. In Proceedings of the 17th ACM conference on Computer and communications security, CCS '10, pages 573–584, 2010.
[47] V. Pappas, M. Polychronakis, and A. D. Keromytis. Smashing the gadgets: Hindering return-oriented programming using in-place code randomization. In Proceedings of the 33rd IEEE Symposium on Security and Privacy, S&P '12, pages 601–615, 2012.
[48] PaX. Homepage of The PaX Team, 2001. http://pax.grsecurity.net.
[49] M. Payer. Too much PIE is bad for performance. Technical report, ETH Zürich, 2012.
[50] K. Pettis and R. C. Hansen. Profile guided code positioning. In Proceedings of the ACM SIGPLAN 1990 Conference on Programming Language Design and Implementation, PLDI '90, pages 16–27, New York, NY, USA, 1990. ACM.
[51] R. Pucella and F. B. Schneider. Independence from obfuscation: A semantic framework for diversity. Journal of Computer Security, 18(5):701–749, 2010.
[52] B. Randell. System structure for software fault tolerance. SIGPLAN Not., 10(6):437–449, 1975.
[53] J. Salwan. ROPgadget tool, 2012. http://shell-storm.org/project/ROPgadget/.
[54] E. J. Schwartz, T. Avgerinos, and D. Brumley. Q: Exploit hardening made easy. In Proceedings of the 20th USENIX Security Symposium, SEC '11, 2011.
[55] K. Scott, N. Kumar, S. Velusamy, B. Childers, J. Davidson, and M. Soffa. Retargetable and reconfigurable software dynamic translation. In Proceedings of the 1st IEEE/ACM International Symposium on Code Generation and Optimization, CGO '03, pages 36–47, 2003.
[56] F. J. Serna. The info leak era on software exploitation. In Black Hat USA, 2012.
[57] H. Shacham. The geometry of innocent flesh on the bone: Return-into-libc without function calls (on the x86). In Proceedings of the 14th ACM Conference on Computer and Communications Security, CCS '07, pages 552–561, 2007.
[58] H. Shacham, M. Page, B. Pfaff, E. Goh, N. Modadugu, and D. Boneh. On the effectiveness of address-space randomization. In Proceedings of the 11th ACM Conference on Computer and Communications Security, CCS '04, pages 298–307, 2004.
[59] E. Shioji, Y. Kawakoya, M. Iwamura, and T. Hariu. Code shredding: byte-granular randomization of program layout for detecting code-reuse attacks. In Proceedings of the 28th Annual Computer Security Applications Conference, ACSAC '12, pages 309–318, 2012.
[60] K. Z. Snow, F. Monrose, L. V. Davi, A. Dmitrienko, C. Liebchen, and A.-R. Sadeghi. Just-in-time code reuse: On the effectiveness of fine-grained address space layout randomization. In Proceedings of the 34th IEEE Symposium on Security and Privacy, S&P '13, pages 574–588, 2013.
[61] L. Szekeres, M. Payer, T. Wei, and D. Song. SoK: Eternal war in memory. In Proceedings of the 34th IEEE Symposium on Security and Privacy, S&P '13, pages 48–62, 2013.
[62] L. Torczon and K. Cooper. Engineering A Compiler. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2nd edition, 2011.
[63] M. Tran, M. Etheridge, T. Bletsch, X. Jiang, V. W. Freeh, and P. Ning. On the expressiveness of return-into-libc attacks. In Proceedings of the 14th Interntional Symposium on Recent Advances in Intrusion Detection, RAID '11, pages 121–141, 2011.
[64] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Binary stirring: Self-randomizing instruction addresses of legacy x86 binary code. In Proceedings of the 19th ACM Conference on Computer and Communications Security, CCS '12, pages 157–168, 2012.
[65] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin. Securing untrusted code via compiler-agnostic binary rewriting. In Proceedings of the 28nd Annual Computer Security Applications Conference, ACSAC '12, pages 299–308, 2012.
[66] T. Wei, T. Wang, L. Duan, and J. Luo. INSeRT: Protect dynamic code generation against spraying. In Proceedings of the 2011 International Conference on Information Science and Technology, ICIST '11, pages 323–328, 2011.
[67] D. W. Williams, W. Hu, J. W. Davidson, J. Hiser, J. C. Knight, and A. Nguyen-Tuong. Security through diversity: Leveraging virtual machine technology. IEEE Security & Privacy, 7(1):26–33, 2009.
[68] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar. Native Client: A sandbox for portable, untrusted x86 native code. In Proceedings of the 30th IEEE Symposium on Security and Privacy, S&P '09, pages 79–93, 2009.
[69] M. Zhang and R. Sekar. Control flow integrity for COTS binaries. In Proceedings of the 22nd USENIX Security Symposium, SEC '13, pages 337–352, 2013.