### 5.7 Comparing Traceroute and BGP Views

Table 1 summarizes the coverage of interdomain connectivity observed by one vantage point (VP) in each of three different networks. We also applied bdrmap to infer border routers for 25 other networks, yielding similar results. The table categorizes observed links into those detected via BGP (broken down by inferred AS relationships) and those inferred only through bdrmap's traceroutes.

bdrmap identified routers connecting between 92.2% and 96.8% of BGP-observed networks, with links for providers and peers being the most well-represented. For two of the three networks, at least one neighbor router was observed for all peers and providers.

The rows in Table 1 list the results of the heuristics in the order in which bdrmap applies them to an inferred neighbor router. At least half of the inferred customer routers were identified using the firewall heuristic, meaning bdrmap did not observe any interface originated by the customer in a traceroute. The difficulty in inferring customers with traceroute is further illustrated by the relative use of the onenet and silent heuristics: only 3.9% to 8.6% of customers in these three networks had two consecutive interfaces in their network, but these heuristics inferred 36.9% of peer and provider routers. Similarly, bdrmap inferred that 2.7% to 8.6% of customers had disabled time-exceeded messages and firewalled our probes.

### 5.8 Supporting Resource-Limited Devices

Some of the densest measurement infrastructure deployments use extremely resource-limited devices. Mapping IP addresses to originating ASes, maintaining stop lists, and managing state for alias resolution can require substantial CPU time and memory storage, often exceeding the resources available on some devices. For example, the most powerful RIPE Atlas probes and SamKnows Whitebox measurement devices use a MIPS-based processor operating at 400 MHz with 32 MB of RAM and 4 MB of flash storage, while bdrmap requires approximately 150 MB of RAM to operate.

To address this, we extended our data collection tools so that the prober (scamper) can run on low-resource devices and call back to a centrally-operated system with greater compute resources, which runs bdrmap. We used VPs from the BISmark project [41] to demonstrate the feasibility of running the system on other densely deployed measurement systems. Similar to the SamKnows systems, the BISmark systems are OpenWrt-based with a 450 MHz MIPS processor, 64-128 MB of RAM, and 16 MB of flash storage. During our measurements, the maximum CPU consumption by scamper on the BISmark VPs was 3%, and it used 3.5 MB of RAM, or 11% of the total memory on the RIPE Atlas and SamKnows Whitebox devices. We use data collected from BISmark in §6.

### 6. Interconnection Insights

We used 19 VPs deployed in a single large U.S. access network to measure the diversity of its interdomain paths in January 2016. Specifically, we computed the number of border routers and next-hop ASes traversed on paths from these VPs towards all routed prefixes (Figure 14). This measure reflects network resiliency; many border routers and next-hop ASes able to reach a destination imply multiple redundant paths available in case of network disruptions. The diversity in interconnection is remarkable: fewer than 2% of prefixes left this access network via the same border router from each VP. For 73% of prefixes, we observed 5-15 distinct border routers, and 13% of prefixes had more than 15 exit points. These numbers suggest astonishing resiliency and redundancy toward most of the IPv4 Internet. However, the AS-level density is lower: most (67%) prefixes are routed via the same next-hop AS regardless of VP location.

A key motivation for this work is the ability to accurately measure interdomain congestion and network resiliency, which requires comprehensive coverage of interdomain links of the network being studied. Therefore, we need to quantify how many VPs are needed in a hosting network and where they should be placed to discover all router-level interconnections. Using the same large access network, we measured the marginal utility of additional VPs for discovering interdomain links with two large transit providers and five CDNs (Figure 15). Akamai and Level3 represent two extremes in terms of our ability to discover their interconnections from VPs in the access network, revealing interesting differences in routing and interconnection strategies across these networks. Specifically, a single VP in the access network observes all the network’s interconnections with Akamai because Akamai advertises certain prefixes only at specific interconnection points. In contrast, each additional VP reveals progressively more interconnections with Level3, consistent with Level3 advertising most prefixes at each interconnection point so that the access network can hand off traffic toward a prefix at its closest interconnection point—hot potato routing [42]. We observed all 45 router-level interconnections this access network has with Level3 (as of January 2016), but required 17 VPs in diverse geographical regions across the U.S. to do so.

Figure 16 illustrates that it is not just the number of VPs but also their geographical diversity within the VP that affects the number of distinct interdomain links observed for a large access network. For this access network, we used the location information embedded in reverse DNS mappings for IP addresses on their border routers to infer their geographical location. Akamai’s announcement policy allows a single VP anywhere to identify all points of interconnection to this network. Visibility of interconnections to Google requires west and east coast VPs, but visibility to all of Level3’s interconnections requires VPs spread across the U.S. due to hot potato routing.

### 7. Conclusions

It may surprise many that something as fundamental as connections between TCP/IP networks remains so opaque to researchers and regulators, and the range of research that is handicapped by the lack of this measurement capability. Although we have only taken the first step—identifying interdomain links directly connected to and visible from the network hosting a measurement vantage point—it is transformative for Internet mapping research. Our method uses targeted traceroutes, detailed knowledge of traceroute behavior, and codification of topological constraints in a structured set of heuristics to correctly identify network boundaries at the router level. We applied our method to reveal the tremendous density and diversity of router-level interconnection between some pairs of ASes. We explored the parameter space of this method by computing the marginal gains of VP deployment inside one large access ISP and the geographical diversity of VPs required to achieve a full view of this ISP’s interconnectivity. This topology measurement and analysis capability forms an essential cornerstone of the system we are developing to map interdomain performance measurements at Internet scale, and we publicly release our source code.

### Acknowledgments

We thank the operators who discussed aspects of their network’s operations, the Research and Education Advanced Network New Zealand (REANNZ), Guilherme Martins (Princeton) who deployed scamper on BISmark nodes to support this work, and the anonymous reviewers for their feedback. BISmark was supported by NSF CNS-1422680 and CNS-1405781. This work was supported by NSF CNS-1414177 and CNS-1413905, by the Department of Homeland Security (DHS) Science and Technology Directorate, Cyber Security Division (DHS S&T/CSD) via contract number HHSP233201600010C, and by a grant from Comcast, but this paper represents only the position of the authors.

### 8. References

[References listed here as provided, with no changes.]