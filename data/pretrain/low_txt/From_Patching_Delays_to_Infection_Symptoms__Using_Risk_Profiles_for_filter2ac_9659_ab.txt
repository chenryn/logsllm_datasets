### 2.3 Threat Model
We consider two types of adversaries in this work. The first type consists of actors who actively exploit software vulnerabilities. We assume that such exploitation can occur as soon as the vulnerabilities are introduced, for example, with new version releases. However, our detection framework is triggered by the official vulnerability disclosure, as shown in Figure 1. We also assume that these adversaries can potentially develop and pursue exploits for any existing vulnerability.

The second type of adversary not only seeks to exploit vulnerabilities but also has the capability to control a significant number of end-hosts. This allows them to manipulate the patching signals used in our detection framework, effectively launching an attack or evasion attempt against our methodology. Such manipulation aims to interfere with how we measure similarity between networks. In Section 7.2, we examine the robustness of our detection method against this type of attack.

### 3 Datasets
Table 1 summarizes the datasets used in this study. To compare behaviors between patching and malicious activity signals, we use only the overlapping time period from January 2013 to July 2014.

#### 3.1 End-Host Patching
Our study draws from multiple data sources to characterize users' patching behavior, allowing us to assess their susceptibility to known vulnerabilities and exploits at any point in time. These data sources include:
- **Host Patching Data** [14]
- **National Vulnerability Database (NVD)** [33]
- **Release Notes** from software vendors

**Patch Deployment Measurements**
This data source, collected by Nappa et al. [30], records the installation of subsequent versions of different applications along with timestamps. It maps binary executables on user machines to their corresponding application versions. The data is derived from the WINE dataset provided by Symantec [14] and includes observations on hosts worldwide from February 2008 to July 2014. We also extract security flaws affecting each application version from the NVD, where each vulnerability is denoted by its Common Vulnerabilities and Exposures Identifier (CVE-ID).

For each host and CVE-ID, we follow the methodology described in [38] to determine the periods when a host is susceptible to disclosed but unpatched vulnerabilities. This involves finding the state of a host (i.e., the set of applications installed) at any point during the observation period and extracting the set of disclosed vulnerabilities from the NVD. Note that users might install different product lines of the same application simultaneously, e.g., Flash Player 10 and 11. We will elaborate on this in Section 4.1.

In this study, we analyze user patching behavior over seven applications with the best host coverage: Google Chrome, Mozilla Firefox, Mozilla Thunderbird, Safari, Opera, Adobe Acrobat Reader, and Adobe Flash Player. We ignore hosts with fewer than 10 recorded events for these applications. During the study period from January 2013 to July 2014, we observed 370,510 events over 30,310 unique hosts.

**Vulnerability Exploits**
Only a small fraction of disclosed vulnerabilities have known exploits; many remain undiscovered, and a large number are never exploited. We identify the set of exploited vulnerabilities from two sources:
1. **Exploited Vulnerabilities Corpus** [36]: Extracted from public descriptions of Symantec’s anti-virus signatures [42] and intrusion-protection signatures (IPS) [4]. Limiting to the seven products from January 2013 to July 2014, we curated a dataset containing 18 vulnerabilities.
2. **SecurityFocus Vulnerability Database** [40]: We queried all CVE-IDs from the NVD and obtained 44 exploited-in-the-wild (EIW) vulnerabilities. Combining all curated datasets, we have 56 EIW and 300 not-exploited-in-the-wild (NEIW) vulnerabilities.

**Software Release Notes**
To determine if a host is susceptible to a vulnerability and address the issue of parallel product lines, we use the release dates of each application version. For Thunderbird, Firefox, Chrome, Opera, Adobe Acrobat Reader, and Adobe Flash Player, we crawl the release history logs from official vendor websites or third-party sources. For sub-versions not included in these sources, we use release dates from Nappa et al. [30].

#### 3.2 Malicious Activities
Our second main category of data consists of IP-level spam activities, which we refer to as symptomatic data. This data is sourced from well-established monitoring systems such as spam traps in the form of various reputation blacklists (RBLs) [9, 39, 41, 45, 48]. We use five common daily IP address-based RBLs from January 2013 to July 2014, which overlap with the patch deployment measurements.

While spam data is a proxy for host infection caused by vulnerability exploits, it is not perfect. Not all spam is caused by exploits; some spamming botnets are distributed through malicious attachments, and cyber-criminals may rent pay-per-install services to install bots. Despite these limitations, our results show that spam is a good proxy for detecting infections related to vulnerability exploits.

Hosts in our patch deployment dataset are anonymized but can be aggregated at the Internet Service Provider (ISP) level. We use the Maxmind GeoIP2ISP service [29] to aggregate malicious activity indicators at the ISP level, aligning the resulting time series data with aggregated patching signals for evaluation.

### 4 Data Processing and Preliminaries
In this section, we detail how time series data are aggregated at the ISP level and how we define similarity measures between ISPs.

#### 4.1 Aggregating at the ISP Level
The mapping from hosts to ISPs is not unique, as devices may move and be associated with different IP addresses and ISPs. Our aggregation accounts for this by mapping the same host to multiple ISPs as indicated in the data.

**Aggregating RBL Signals**
Each RBL provides a daily list of malicious IP addresses. We count the total number of unique IPs belonging to any ISP, denoted as \( R_n(t) \). This is normalized by the size of ISP \( n \) to avoid skewing pairwise comparisons due to size differences. The normalized time series \( r_n(t) \) is referred to as the symptom signal of ISP \( n \).

**Aggregating Patching Data**
Patching data is more complex, consisting of sequences of application versions installed on a host with their corresponding timestamps. To quantify the risk of a given host, we extract known vulnerabilities affecting each application version from the NVD using the CVE-ID. However, this extraction is complicated by the presence of multiple product lines and downgrades. We use release notes to distinguish between parallel product lines, assuming that application versions within the same line follow a chronological order of release dates.

We quantify the vulnerability of a single host \( h \) to CVE \( j \) on day \( t \) by counting how many versions present on the host are subject to this CVE, denoted as \( W^j_h(t) \). This quantity is summed over all hosts belonging to an ISP \( n \), resulting in a total count of unpatched vulnerabilities. We normalize this by the ISP’s size, denoted as \( w^j_n(t) \).

We now have two types of time series for each ISP \( n \):
- \( r_n(t) \): Normalized malicious activities (symptom signal)
- \( w^j_n(t) \): Normalized risk with respect to CVE \( j \) (risk signal)

#### 4.2 Similarity in Symptoms and Risk
Our methodology relies on identifying the similarity structure using symptom data and quantifying how strongly the risk patterns are associated with the symptom similarity structure. This is done for each CVE separately. The aggregated malicious activity signal \( r_n(t) \) for ISP \( n \) is agnostic to the choice of CVE, but our analysis on a given CVE determines the time window for examining this signal.

We define the correlation between two vectors \( u[0 : d] \) and \( v[0 : d] \) as follows:
\[
S_{u,v}(k) = \frac{\sum_{t=k}^{d} u(t) \cdot v(t - k)}{\sqrt{\sum_{t=0}^{d-k} v(t) \cdot v(t) \cdot \sum_{t=0}^{d-k} u(t + k) \cdot u(t + k)}}
\]
where \( k = 0, \ldots, d \) denotes all possible time shifts. The pairwise similarity measure is defined by the maximum of these correlations subject to a lower bound \( a \) to ensure the correlation is computed over vectors of length at least \( d - a \):
\[
S_{u,v} = \max \left( \max_{0 \leq k \leq d-a} S_{u,v}(k), \max_{0 \leq k \leq d-a} S_{v,u}(k) \right)
\]

With this definition, the pairwise symptom similarity between ISPs \( n \) and \( m \) for CVE \( j \) can be formally stated. Assume \( t^j_o \) is the day of disclosure for CVE \( j \). We focus on the time period from disclosure to \( d \) days after, shifting \( t^j_o \) to the origin. This gives us two symptom signals of length \( d + 1 \): \( r_n[0 : d] \) and \( r_m[0 : d] \), and a pairwise symptom similarity measure \( S^j_{r_n, r_m} \) using Equations (1) and (2). Similarly, we define the pairwise risk similarity \( S^j_{w_n, w_m} \).

In Section 6, we also examine whether signs of infection can be detected before the official disclosure, extending the time window to start \( d_1 \) days before and end \( d_2 \) days after the disclosure.