### Evaluation of False Positives in Shield-LSP Implementation

In this section, we evaluate the false positive nature of our Shield-LSP implementation. We focus on the Shield designed for Slammer [40], which exploits the SSRP protocol of SQL Server 2000.

We obtained a stress test suite for SSRP from the vendor. SSRP is a simple protocol with only 12 message types. The test suite includes 36 exhaustive test cases covering various SSRP request forms. When running this test suite against our Shield, no false positives were observed. However, this result does not definitively prove that Shield is free of false positives.

### Related Work

The emergence of CodeRed [7], Slammer [40], and MSBlast [24] in recent years has sparked significant interest in worm defense research. Many studies [23, 42, 22, 45] have characterized and analyzed the rapid and widespread nature of modern-day worms, as well as their potential impact [47, 6].

Most contemporary worm attacks exploit software defects, such as buffer overruns on stacks or heaps, to execute remote code. Static checkers that perform data flow analysis [3, 44] over source code have been effective in systematically identifying software defects before release. However, these tools are not infallible. Mitigation techniques like Stackguard [9] and non-executable stacks or heaps raise the bar for exploiting software defects, but attackers can still find ways to bypass these defenses with new exploitation techniques [28, 49, 19].

Attack prevention techniques, such as software patching and Shield, address known vulnerabilities by leveraging well-defined invariants. Section 1 provides a detailed comparison between these two approaches.

### Worm Containment Techniques

Worm containment techniques are typically used to manage known worms. For example, firewalls can block a port under attack. Firewalls share some functionality with Shield but operate in a more rudimentary manner, often without customization for specific vulnerabilities. They are usually not deployed on end hosts, making them vulnerable to evasion tactics [32]. Additionally, firewalls are often unaware of application-level protocols, especially if traffic is encrypted.

Exploit signature-based Network Intrusion Prevention Systems (NIPS), such as Snort-based Hogwash [41], filter out malicious traffic based on attack signatures, typically regular expressions. These systems rely on packet-level inspection and pattern matching, which can be easily manipulated by attackers to cause false negatives and false positives, as application messages can be scattered across multiple packets [32]. Fast signature extraction algorithms, such as EarlyBird [39] and Autograph [5], are essential for NIPS to be effective against worms, particularly polymorphic or metamorphic ones.

Rate-limiting [48] is another containment method that throttles the sending rate at an infected host. This method, along with blocking detected scanning activity of compromised nodes [46], has been explored as a defense against scanning worms. Rate-limiting and scanning worm containment are most useful for fast-spreading worms rather than stealthy ones.

Network Intrusion Detection Systems (NIDS), exemplified by Bro [27] and Snort [41], monitor network traffic and detect known exploits. NIDS are more customized by application than firewalls but focus on known exploits rather than known vulnerabilities. Unlike Shield, NIDS are not in the traffic forwarding path and primarily focus on detection rather than prevention. To enhance detection reliability, "traffic normalizers" [37, 14] or "protocol scrubbers" [20] have been proposed to eliminate ambiguities before traffic reaches the monitor, thus reducing evasion opportunities. NIDS also face the challenge of high false positive rates, complicating the reaction process.

Honeypots, such as Backscatter [23], honeyd [31], HoneyComb [18], and HoneyStat [10], cover unused IP address space to detect unsolicited outgoing traffic, indicating the occurrence of an attack.

### Conclusions and Further Work

We have demonstrated that network-based, vulnerability-specific filters are feasible to implement with low false positive rates, manageable scalability, and broad applicability across protocols. Future research directions for Shield include:

- **Enhanced Policy Generation**: Further experience in writing shields for specific vulnerabilities will better indicate Shield's applicability and the adequacy of the Shield policy language. Automated tools could be developed to ease policy generation, especially for protocols described in a standard, formalized format.
  
- **Deployment Flexibility**: Shield need not be implemented solely on end hosts. It may be preferable to deploy Shield in firewalls, routers, or special-purpose boxes, depending on administrative or performance considerations. These deployment options require further exploration.

- **Automated Testing**: Shields can be tested relatively simply by verifying that a collection of traffic (test suites or real-world traces) is not interfered with. Automating this process would streamline the shield release process.

- **Secure Distribution**: Ensuring the secure, reliable, and expeditious distribution of Shields is crucial. While patches can be reverse-engineered to understand and exploit vulnerabilities, Shield policies make reverse-engineering even easier. Therefore, Shield distribution and installation must be tightly controlled.

- **Application to Viruses**: Shield's design might be useful in addressing viruses that exploit application vulnerabilities when infected files are opened. Incorporating shield-like technology into anti-virus systems could protect against generic classes of viruses using specific infection methods.

### Acknowledgements

Jon Pincus has provided insightful and constant advice since the inception of the Shield project. Jay Lorch offered many thoughtful critiques on the first draft of this paper. We also received valuable assistance from Microsoft employees who helped us understand various aspects of vulnerabilities from Microsoft Security Bulletins and provided stress test suites for several application-level protocols. Andrew Begel and Zhe Yang contributed to discussions on our policy language design and interpreter implementation. Our work benefited from discussions with Nikita Borisov, David Brumley, Hao Chen, John Dunagan, Jason Garms, Jon Howell, Yih-Chun Hu, Jitu Padhye, Vern Paxson, Stefan Savage, Dawn Song, Nick Weaver, and Brian Zill. The final version of this paper was significantly influenced by the anonymous SIGCOMM reviewers, Nikita Borisov, and our shepherd, Paul Barford. We are grateful for everyone's help.

### References

[1] W. A. Arbaugh, W. L. Fithen, and J. McHugh. Windows of Vulnerability: a Case Study Analysis. IEEE Computer, 2000.

[2] Steve Beattie, Seth Arnold, Crispin Cowan, Perry Wagle, and Chris Wright. Timing the application of security patches for optimal uptime. In LISA XVI, November 2002.

[3] William Bush, Jonathan D. Pincus, and David J. Sielaﬀ. A Static Analyzer for Finding Dynamic Programming Errors. Software-Practice and Experience (SP&E), 2000.

[4] Byacc. http://dickey.his.com/byacc/byacc.html.

[5] H. Chen and B. Karp. Autograph: Toward automated, distributed worm signature detection. In Proceedings of the 13th Usenix Security Symposium, 2004.

[6] Z. Chen, L. Gao, and K. Kwiat. Modeling the Spread of Active Worms. In Proceedings of IEEE Infocom, 2003.

[7] Microsoft Security Bulletin MS01-033, November 2003. http://www.microsoft.com/technet/treeview/default.asp?url=/technet/security/bulletin/MS01-033.asp.

[8] Microsoft Corp. URLScan Security Tool. http://www.microsoft.com/technet/security/URLScan.asp.

[9] Crispin Cowan, Calton Pu, Dave Maier, Heather Hintony, Jonathan Walpole, Peat Bakke, Steve Beattie, Aaron Grier, Perry Wagle, and Qian Zhang. StackGuard: Automatic Adaptive Detection and Prevention of Buffer-Overflow Attacks. In Proceedings of 7th USENIX Security Conference, 1998.

[10] David Dagon, Xinzhou Qin, Guofei Gu, Wenke Lee, Julian Grizzard, John Levine, and Henry Owen. HoneyStat: Local Worm Detection Using Honeypots. In RAID, 2004.

[11] O. Dubuisson. ASN.1 - Communication Between Heterogeneous Systems. Morgan Kaufmann Publishers, 2000.

[12] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach, and T. Berners-Lee. Hypertext Transfer Protocol – HTTP/1.1 (RFC 2616), June 1999.

[13] Alan O. Freier, Philip Karlton, and Paul C. Kocher. The SSL Protocol Version 3.0. http://wp.netscape.com/eng/ssl3/ssl-toc.html.

[14] Mark Handley, Vern Paxson, and Christian Kreibich. Network Intrusion Detection: Evasion, Traffic Normalization, and End-to-End Protocol Semantics. In Proceedings of USENIX Security Symposium, August 2001.

[15] Hung-Yun Hsieh and Raghupathy Sivakumar. A transport layer approach for achieving aggregate bandwidths on multi-homed mobile hosts. In ACM Mobicom, September 2002.

[16] Anthony Jones and Jim Ohlund. Network Programming for Microsoft Windows. Microsoft Publishing, 2002.

[17] J. Klensin. Simple Mail Transfer Protocol (RFC 2821), April 2001.

[18] C. Kreibich and J. Crowcroft. Honeycomb: Creating Intrusion Detection Signatures Using Honeypots. In HotNets-II, 2003.

[19] David Litchfield. Defeating the stack-based buffer overflow prevention mechanism of Microsoft Windows 2003 Server. http://www.nextgenss.com/papers.htm, September 2003.

[20] G. Robert Malan, David Watson, and Farnam Jahanian. Transport and application protocol scrubbing. In Proceedings of IEEE Infocom, 2000.

[21] P. J. McCann and S. Chandra. PacketTypes: Abstract Specification of Network Protocol Messages. In Proceedings of ACM SIGCOMM, 2000.

[22] David Moore, Vern Paxson, Stefan Savage, Colleen Shannon, Stuart Staniford, and Nicholas Weaver. Inside the Slammer Worm. http://www.computer.org/security/v1n4/j4wea.htm, 2003.

[23] David Moore, Colleen Shannon, and Jeffrey Brown. Code-Red: a case study on the spread and victims of an Internet worm. In ACM Internet Measurement Workshop (IMW), 2002.

[24] Microsoft Security Bulletin MS03-026, September 2003. http://www.microsoft.com/technet/treeview/default.asp?url=/technet/security/bulletin/MS03-026.asp.

[25] S. W. O’Malley, T. A. Proebsting, and A. B. Montz. USC: A Universal Stub Compiler. In Proceedings of ACM SIGCOMM, 1994.

[26] Vern Paxson. Flex - a scanner generator - Table of Contents. http://www.gnu.org/software/flex/manual/.

[27] Vern Paxson. Bro: A System for Detecting Network Intruders in Real-Time. In Computer Networks, Dec 1999.

[28] Jonathan Pincus and Brandon Baker. Mitigations for Low-level Coding Vulnerabilities: Incomparability and Limitations. http://research.microsoft.com/users/jpincus/mitigations.pdf, 2004.

[29] J. Postel and J. Reynolds. Telnet Protocol Specification (RFC 854), May 1983.

[30] J. Postel and J. Reynolds. RFC 765 - File Transfer Protocol (FTP), October 1985.

[31] Niels Provos. A Virtual Honeypot Framework. Technical Report CITI-03-1, Center for Information Technology Integration, University of Michigan, October 2003.

[32] Thomas H. Ptacek and Timothy N. Newsham. Insertion, evasion, and denial of service: Eluding network intrusion detection, January 1998. http://www.insecure.org/stf/secnet_ids/secnet_ids.html.

[33] Eric Rescorla. Security holes... Who cares? In Proceedings of USENIX Security Symposium, August 2003.

[34] DCE 1.1: Remote Procedure Call. http://www.opengroup.org/onlinepubs/9629399/.

[35] W32.Sasser.Worm, April 2004. http://securityresponse.symantec.com/avcenter/venc/data/w32.sasser.worm.html.

[36] H. Schulzrinne, S. Casner, R. Frederick, and V. Jacobson. RTP: A Transport Protocol for Real-Time Applications (RFC 1889), January 1996.

[37] Umesh Shankar and Vern Paxson. Active Mapping: Resisting NIDS Evasion Without Altering Traffic. In Proceedings of IEEE Symposium on Security and Privacy, May 2003.

[38] Richard Sharpe. Server message block. http://samba.anu.edu.au/cifs/docs/what-is-smb.html.

[39] Sumeet Singh, Cristian Estan, George Varghese, and Stefan Savage. The EarlyBird System for Real-time Detection of Unknown Worms. Technical Report CS2003-0761, University of California at San Diego, 2003.

[40] Microsoft security bulletin ms02-039, January 2003. http://www.microsoft.com/technet/treeview/default.asp?url=/technet/security/bulletin/MS02-039.asp.

[41] The Open Source Network Intrusion Detection System. http://www.snort.org/.

[42] Stuart Staniford, Vern Paxson, and Nicholas Weaver. How to 0wn the Internet in Your Spare Time. In Proceedings of the 11th USENIX Security Symposium, August 2002.

[43] Peter Szor and Peter Ferrie. Hunting for Metamorphic. Symantec Security Response.

[44] David Wagner, Jeffrey S. Foster, Eric A. Brewer, and Alexander Aiken. A First Step Towards Automated Detection of Buffer Overrun Vulnerabilities. In NDSS, 2000.

[45] Nicholas Weaver, Vern Paxson, Stuart Staniford, and Robert Cunningham. Large Scale Malicious Code: A Research Agenda. http://www.cs.berkeley.edu/~nweaver/large_scale_malicious_code.pdf, 2003.

[46] Nicholas Weaver, Stuart Staniford, and Vern Paxson. Very Fast Containment of Scanning Worms, 2004. http://www.icsi.berkeley.edu/nweaver/containment/.

[47] Nick Weaver. The potential for very fast internet plagues. http://www.cs.berkeley.edu/~nweaver/warhol.html.

[48] Matthew M. Williamson. Throttling viruses: Restricting propagation to defeat malicious mobile code. Technical Report HPL-2002-172, HP Labs Bristol, 2002.

[49] Rafal Wojtczuk. Defeating Solar Designer’s Non-executable Stack Patch. http://www.insecure.org/sploits/non-executable.stack.problems.html, January 1998.