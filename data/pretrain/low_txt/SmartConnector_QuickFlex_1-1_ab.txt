### Quick Flex Parser Tool Log View

When the Quick Flex Parser Tool does not find the log file at the specified path, it notifies you and asks if you want to browse for the log file before opening the project.

#### View a Workflow Summary
**Navigation:**
- **Landing Page > Quick Flex Overview**

**Procedure:**
1. Click on **Quick Flex Overview** for a graphical representation of the Quick Flex workflow.

---

### Quick Flex Parser Tool Log View

The Quick Flex Parser Tool Log View opens when you create a new project or open an existing project. This view displays the log file messages and the number of token filters applied to the messages. It also provides statistics for the token filters and the number of lines parsed by the filters.

**Menu Bar:**
- **File:** Contains commands to create a new project, open an existing project, open a file in the project, export, save, or save as the project, and edit project properties.
- **Base Regex Editor:** Opens the Base Regex Editor where you can create and edit the base regex. See "Create a Base Regex."
- **Token Filter Editor:** Opens the Token Filter Editor where you can create and edit token filters. See "Create a Token Filter."
- **Token Manager:** Opens the Token Manager where you can create, update, and delete tokens. See "Create a Token."
- **Token Filter Manager:** Opens the Token Filter Manager where you can view the token filter status, enable or disable token filters, and test the selected token filters. See "Managing and Testing Token Filters."
- **Help:** Accesses the online help and two workflow summaries.

**Ribbon above the Log View:**
- **Total Logs:** Displays the total number of lines in the log file. Click to display the contents of the log file in the Log View Panel.
- **Base Parsed:** Number of log lines that are parsed successfully by the base regex. Click to display the parsed lines in the Log View Panel.
- **Base Unparsed:** Number of log lines that are not parsed by the base regex. Click to display the unparsed lines in the Log View Panel.
- **Complete:** Number of log lines that are parsed by the base regex and at least one token filter. Click to display the lines in the Log View.
- **Incomplete:** Number of log lines that are not parsed by the base regex, a token filter, or both.
- **Next Unparsed Line:** Click to go to the next line which is not parsed by either the base regex or a token filter.
- **Go to:** Enter a line number or text string to find the information you want.
- **Search by Log:** The entered text will be searched for in the entire log line.

**Settings Drop-Down:**
- **Show Syslog Header:** Select to display the syslog headers. See "Highlighting Patterns in Log Lines."
- **Visualize Stats:** Select to graphically display the statistics that appear in the top toolbar.

**Log View Panel:**
- **Log Message Column:** Displays the messages in the log file.
- **Matched Token Filter Column:** Displays the number of token filters that match a log line. Initially, it displays 0. As token filters are constructed and applied, this value changes to represent the number of token filters parsing a particular log line.

You can begin defining tokens and token filters for your project by selecting a specific line from the log line. This action opens the Token Filter Editor. See "Create a Token Filter."

**Statistics in the Log View:**
- **Token Filter Coverage:** Indicates the number of log lines parsed by a single token filter, by 2 token filters, and by 3 or more token filters.
- **Token Filter Stats:** Displays the number of matching messages for the top ten filters covering most of the log lines.

Once you have defined your base regex, tokens, and token filters and are satisfied with the test results, click **Generate Parser** to generate the parser (.properties) file for the project. See "Generate a Parser File."

---

### Creating Token Filters for Messages

To create a token filter, complete these tasks:
- Create a Base Regex
- Create a Token
- Create a Token Filter
- Create a Mapping
- Override Token Regex

#### Create a Base Regex
**Navigation:**
- **Log View > Base Regex Editor**

**About:**
The Quick Flex Parser Tool automatically generates a suggested base regex to work for the current log line. If you do not want the suggested base regex, you can override the original line on top of the log line with a valid regex. Modify and test the base regex iteratively to fit other log lines. The log line highlight indicates if a regular expression matches the line. An error displays if the regex does not match the line.

**Note:**
- The auto-generated regex is not meant to replace manually typing the base regex. It is a suggestion to improve the base regex by adding or replacing expressions that fit your criteria.
- For Syslog files, the Syslog header is identified by the connector framework and highlighted in the Log View. You can click the Syslog Header button to toggle the view for the Syslog Header. The Syslog message means the remainder of the line, for example, the syslog header is not covered by the base regex and token filter.

**Specify a base regex (also known as a preparser):**
- Connectors use a base regex to separate the header from the body of a log message. The header is considered to be those parts of a log line that are common to all messages. You must create the base regex that processes all log lines successfully before creating and applying token filters to process the rest of the message.
- Once you have a valid regex expression for the log line, click **Tokenize** to create base regex tokens. When you edit the regex, the Quick Flex Parser Tool will do its best to preserve the token properties that were previously created (such as name, type, and assignment). In instances where base regex tokens are added to the base regex, token properties subsequent to the added tokens will not be preserved.

**Procedure:**
1. Click **Base Regex Editor** on the Log View. The Base Regex Editor opens.
2. Define the base regex for the message in the Base Regex field.
   - **Note:**
     - At a minimum, the base regex must be defined as `(.*).`
     - You must create and save at least two base regex tokens before you can create message tokens.
     - The Quick Flex Parser Tool expects the base regex to contain at least one capture group.
     - The Quick Flex Parser Tool uses parentheses to represent captured elements. To represent a parenthesis as a literal character, you must escape it with the backslash character. For example: `\(`.
     - The following is a list of characters that must be escaped in the Quick Flex Parser Tool: `[`, `]`, `(`, `)`, `|`, `{`, `}`.
3. Click **Tokenize.** The Quick Flex Parser Tool opens a pop-up with a list of suggested tokens for the highlighted regex. You can accept the suggested tokens or dismiss the pop-up. If you accept the suggested tokens, the tokenized regex selection is highlighted.
   - **Note:**
     - The Tokenize button will not become active unless the regex is valid and successfully processes the entire log line in the Base Regex Editor.
     - If the user modifies one of the tokens of the base regex defined, all tokens previously configured return to their default values after it is tokenized.
     - After you click Tokenize, when you place the cursor in the regex, the corresponding piece of the log line is highlighted, and information about the token is displayed in Token Details. See "Highlighting in the Base Regex Editor."
     - After you click Tokenize, you can examine how the tokens relate to the log line. Click **Matching Details** to display a table that lists each token, the regex defined for the token, and the portion of the log line it represents.
4. Edit the information about the token. Select a token from the Base Token List. Provide this information in the Token Details region:
   - **Edit the Token Name.**
   - **Select a Type from the drop-down list.** See "ArcSight Token Types" for a description of token types.
     - **Note:**
       - If you select TimeStamp, a Format field opens with a default time format. You can enter a time format or click the search button to select a predefined format. See "Date and Time Format Symbols."
   - **Examine the Regex expression for the token.** This field is populated by the regex defined for the token in the Base Regex field. You can change the value in the Regex field only by editing the Base Regex field.
   - **(Optional) Enter a text Description for the token.**
   - **(Optional) Select an Assignment from the drop-down list.** See "ArcSight Assignments." When an assignment is selected, the Type automatically fills with the associated default value. For example, when you select User Name as the Assignment, the Type displays String.
   - **Click Save Token.** The name of the token appears in the Base Token List.
     - **Note:**
       - The tool verifies the Type matching for mappings.
5. Select a **Message ID Token** and **Message Token** from the drop-down lists. This will be translated into a sub-message in the parser file.
   - **Note:**
     - If you want to process the log file with the base regex only, then this step is not required.
     - The Message ID Token drop-down list contains the tokens created for the project. You associate one of these tokens with the Message Token to identify a sub-message.
     - A Message ID Token is not required but is desirable because parsing performance is improved if the Message Token can be related to a token filter.
6. **(Optional) The Additional Data switch** generates a setting in the parser properties file: `additionaldata.enabled = true/false`. The `true` setting tells the SmartConnectors to collect all the unused base regex tokens (that is, tokens which are not mapped to anything). For example, if the Additional Data switch is set to `true` for the token `TokenABC`, then the additional mapping `addionaldata.TokenABC = TokenABC` will be created. This value will not appear in the parser properties file, but it will be in the exported data or in the ESM view.
   - **If you do not want SmartConnectors to automatically collect the unused tokens, you always have the option to assign additionaldata when you do mapping.** For example, you can enter something similar to the following in the parser properties file: `additonaldata.ANY_CUSTOM_NAME = TokenABC.`
7. **Inspect the Log View** to ensure that the base regex processes all lines successfully before you create any tokens. If the base regex does not parse all lines, they will not be parsed correctly by the resulting parser properties file. See "Highlighting in the Log View."

#### Create a Token
**Navigation:**
- **Log View > Token Manager** or right-click a selected portion of the raw log message in the Token Filter Editor

**About:**
- A token is a tag that identifies a data field or other useful information in a message. Typically, the name of the tag will be the name of the field it applies to. A token’s properties apply to each filter the token is used in.
- If you change a token's properties, the change will be reflected in each filter that uses the token.

**Procedure:**
- The Token Manager contains a list of tokens that have been defined and a region where you can create or edit message tokens. You can create only message tokens in the Token Manager. To create base regex tokens, use the Base Regex Editor. See "Create a Base Regex."
- Use one of these methods to open the Token Manager:
  - Select **Token Manager** in the Log View.
  - Use the top toolbar to open the Token Filter Editor. Select a message in the Log View Panel. The message displays in the Original Log working area of the Token Filter Editor. Select and right-click a part of the message. The Token Manager opens as a pop-up.
- Provide the following information in the Token Manager:
  1. Enter a **Token Name** in the Token Properties table.
  2. **(Optional) Select a Type from the drop-down list.** See "ArcSight Token Types" for a description of token types.
     - **Note:**
       - If you select TimeStamp, a Format field opens with a default time format. You can enter a time format or click the search button to select a predefined format. See "Date and Time Format Symbols."
  3. **Edit the Regex expression for the token.** When a token is created, its initial value is the default regex: `\\S+`. Verify that the edited token regex processes the selected message segment.
     - **Note:**
       - The Quick Flex Parser Tool does not support the use of capture symbols `((...))` or optional symbols `(?...?)` in the regex expression. Use the Capture and Mandatory toggle buttons instead.
  4. **(Optional) Set the value of the Capture and/or Mandatory toggle buttons:**
     - **Capture—Set to True** to capture the value matching the token regex as a back reference. The default is False.
     - **Mandatory—Set to True** if the token value must be present in the message. The default is False.
  5. **(Optional) Enter a text Description for the token.**
  6. **(Optional) Select an Assignment from the drop-down list.** See "ArcSight Assignments." When an assignment is selected, the Type automatically fills with the associated default value. For example, when you select User Name as the Assignment, the Type displays String.
  7. **Click Save** to save the token. The name of the token appears in the Token List.
  8. **Repeat steps 1-7** until you have defined tokens that satisfy all of the log lines.

#### Create a Token Filter
**Navigation:**
- **Log View > Token Filter Editor**

**About:**
- A token filter is the tokenized form of a message or log record. It is used to create a parser file and to exercise various properties. The token filter contains the log text, and all special characters are ignored.

**Procedure:**
1. Use the top toolbar to select **Token Filter Editor.** The log line appears in the Original Log and Token Filter fields of the Token Filter Editor.
2. You can edit the token filter in the **Filter ID.** This value must be the ID for each log line that is prepared to be parsed by the token filter currently under construction. This field is automatically filled as best suggested by the tool.
3. Select the log line value in the **Token Filter.** Right-click the log line value to open a pop-up containing the list of available tokens. You can create, edit, or delete tokens:
   - **Click + New** to create a new token or select a token in the list to edit. See "Create a Token."
   - **Click X Delete** to remove a selected token from the project.
   - **Enable Token Details** to see more information about a selected token. You can edit the details, if necessary.
   - **Enable Override Regex** in the Token Details if the token definition should override the token regex. See "Override Token Regex."
4. **Assign mappings to the tokens.** See "Create a Mapping."
5. **Click Apply** to add the token to the Token Filter field. The Quick Flex Parser Tool highlights portions of the log line that match the regex defined in the filter (see "Highlighting Patterns in Log Lines").
   - **Note:**
     - The order in which tokens appear, and any spaces or punctuation you add to the token filter, is important.
     - The Quick Flex Parser Tool uses parentheses to represent captured elements. To represent a parenthesis as a literal character, you must escape it with the backslash character. For example: `\(`.
     - The following is a list of characters that must be escaped in the Quick Flex Parser Tool: `[`, `]`, `(`, `)`, `|`, `{`, `}`.
6. **When you are satisfied with the results of your token filter, click Save.**

#### Create a Mapping
**Navigation:**
- **Log View > Base Regex Editor or Token Filter Editor**

**About:**
- A mapping describes the relationship or the process of establishing the relationship between a log message field and an ArcSight schema field. The mappings describe how the token will map to the fields in ArcSight products, such as Logger, Management Center Express, and so on. More than one mapping can be associated with a field.

**Procedure:**
1. **Click + New** to create a new mapping or select an existing mapping from the list to edit.
2. **Choose an Assignment from the drop-down list.** See "ArcSight Assignments."
3. **If the Assignment field is set to Additional Data, the Additional Data Name field displays.**
4. **(Optional) Enter a text Description of the mapping.**
5. **Select an Operation from the drop-down list.** See "ArcSight operations."
6. **Enter any Arguments that are required by the selected operation.** See "ArcSight operations."
7. **Click Save Mapping** to add the mapping to the Mapping List field.

#### Override Token Regex
**Navigation:**
- **Log View > Token Manager**

**About:**
- Occasionally, the grammar of a message does not support the regex used by the token. However, if you do not want to modify the token regex that works for all other messages, you can override the token regex to allow for exceptions in the token's definition. Overrides to a token's regex have the following characteristics:
  - Overrides apply only to the token filter that contains the token with the overrides.
  - Overrides do not modify token properties in the token set.

**Procedure:**
1. **Enable the Override Regex selector** on the Token Manager pop-up.
2. **Edit the regex expression in the New Regex field.** Note that other fields in the pop-up cannot be edited.
3. **Save the token.** The token definition is overwritten with the new regex and is saved in the Token List.

#### Highlighting Patterns in Log Lines
**About:**
- The Quick Flex Parser Tool uses highlighting to indicate when a pattern in a log line matches the regex defined in a token, base token filter, or token filter. The tool applies highlighting differently, depending on whether you are in the Log View, the Token Filter Editor, or the Base Regex Editor.

**Highlighting in the Log View:**
- **Base regex:** When the base regex is created and saved, you can click Refresh on the log view to view the base regex on the log lines. If your base regex pattern provides a partial match with the log line, then the matching portion of the line is highlighted in purple from the 0th character in the line to the Nth character.
- **Token Filter:** If the selected Token Filter pattern matches the entire log line, then the entire line will be highlighted in green. However, if a base regex is also valid for the line, then the log line will be highlighted in purple for the base token filter match and the remaining part of the line will be highlighted green for the token filter match.
- **Syslog header highlighting:**
  | Yes | Syslog File Selected | Yes | Syslog File Used | Yes | Highlighting |
  |---|---|---|---|---|---|
  | Yes | Syslog File Selected | No | Syslog File Used | No | Highlighting |
  | No | Syslog File Selected | Yes | Syslog File Used | No | Highlighting |
  | No | Syslog File Selected | No | Syslog File Used | No | Highlighting |

**Highlighting in the Token Filter Editor:**
- The Quick Flex Parser Tool applies highlighting to a log line for the base regex and Token Filter according to their regex patterns.

**Highlighting in the Base Regex Editor:**
- When you place the cursor in a token in the base regex after clicking Tokenize, the corresponding piece of the log line is highlighted. Information about the token is displayed if the log line has content expected to be covered by that regex.
- If you place the cursor in a token in the base regex and highlighting is not displayed in the log line, then this means that the token is not present in the log line.

#### Managing and Testing Token Filters
**Navigation:**
- **Log View > Token Filter Manager > Token Filter List tab**

**About:**
- Use the Token Filter List tab of the Token Filter Manager to view the content and status of the token filters you have created. For each token filter, the table displays the tokens used in the filter, whether it is currently being used to parse the log file, and the number of log lines it has matched.
- The position of the token filters in the list is important. The Quick Flex Parser Tool applies token filters to the log file from top to bottom. Typically, token filters are ordered from most specific to least specific.

**Procedure:**
For each token filter in the Token Filter list tab, you can perform the following actions:
- **View the list of tokens** that comprise the token filter.
- **View the number of log lines** each token filter has matched and whether it is currently being used to parse the log file.
- **Enable or disable the token filter.**
- **Change the position of the selected token filter** in the list by clicking Move Up or Move Down.
- **Double-click the token filter name or click Edit** to display the definition of the token filter.
- **Select the token filter and click Delete** to remove the token filter from the project.
- **Test the validity of your token filters against the log file.** See "Test Token Filters."

**Test Token Filters**
**Navigation:**
- **Log View > Token Filter Manager > Token Filter Test tab**

**About:**
- Use the Token Filter Test tab of the Token Filter Manager to test the performance of your base regex and token filters against the log file. You can test a single token filter or any combination of filters.
- The Token Filter Test region displays the list of token filters, the tokens contained by the token filter, and its status: enabled, disabled, or invalid. You can select filters and click Display Results to display the performance of the filters against the log file in the Results region. Click Export to save the results in a CSV-format file.
  - **Note:**
    - You can export results only if you select the Base Regex filter, a single filter, or all filters.
- The Results regions display grids that identify the tokens used in the filter, the schema events they are mapped to, and any assignments that are applied. It also displays grids that identify matched and unmatched lines for selected token filters. Each section of the Results region can be exported individually to a CSV-format file.

**Procedure:**
- Follow the steps in the Token Filter Test tab to test and validate your token filters.