### Project Categorization and Version Control

- **Category:**
  - Operating System
  - Secure Messenger
  - Virtualization/Containers
  - JavaScript Libraries
  - Code Editor
  - .NET Libraries
  - Version Control System
  - GUI Tool
  - Orchestration
  - Network Security Monitor
  - Scientific Computing
  - Cryptocurrency Exchange
  - Code Analysis
  - Network Protocol
  - Data Format

- **Version Control:**
  - 100+
  - 100+
  - 1,000+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+
  - 100+

### Methodology

#### GitHub Selection and Recruitment

To ensure a representative sample of open source projects, we leveraged GitHub, a widely used platform in the open-source community. Our initial dataset, compiled in July 2021, included repositories that had at least 40 commits from 20 distinct contributors in the previous six months and gained new contributors in July 2021. This criteria helped us exclude inactive or small projects where trust processes might be irrelevant.

**Selection Process:**
1. **Communication Channel:** If the project provided a public communication channel (e.g., Slack, Discord, Gitter), we sought permission from administrators to post a call for participants.
2. **Contact Email:** Otherwise, we contacted the project's primary email or the top contributor by number of commits in the past year via their public email address.

We also solicited recommendations from our participants for other interesting or unique open source projects, which we then contacted using the same methods.

**Eligibility Criteria:**
- We did not require additional eligibility criteria beyond involvement in open source software (OSS). 
- In total, we recruited 27 participants from 27 distinct projects.

#### Interview Procedure

The interviews were conducted between July and November 2021, with a lead/backup interviewer configuration. To ensure participant comfort, we offered the option to conduct the interview in either English or German, as all researchers were proficient in both languages. Most interviews were conducted via our self-hosted Jitsi instance, with a few exceptions using Zoom or the participant’s preferred service. Interviews were advertised to last 30–45 minutes, with the median duration being 37 minutes and 52 seconds.

**Interview Structure:**

1. **Introduction:**
   - Brief introduction of involved institutions and motivations.
   - Emphasis on non-judgmental approach and interest in personal thoughts and opinions.
   - Explanation of data collection and handling, followed by obtaining verbal consent.

2. **Project Demographics:**
   - Establish context and the participant's role in the project.
   - Easing nervous participants into the interview and establishing initial context.

3. **Security Challenges:**
   - Explore past security challenges and the participant's opinion on a recent research conflict (e.g., the "hypocrite commits" incident).

4. **Guidance and Policies:**
   - Identify available guidance and best practices, content and applicability of security and disclosure policies, and practices around testing and reviews.

5. **Project Structure:**
   - Investigate behind-the-scenes structures and processes, including build and deploy steps, control mechanisms, and supply chain handling.

6. **Releases and Updates:**
   - Explore release and update processes, focusing on security-relevant fixes and deprecation guidelines.

7. **Roles and Responsibilities:**
   - Establish the maintainer and contributor hierarchy, decision-making processes, and security-specific roles.

8. **Trust Processes:**
   - Consider established trust models, onboarding of new contributors, and past trust incidents.

9. **Opinions and Improvements:**
   - Elicit personal opinions on current OSS practices and potential improvements.

**Debriefing:**
- Collect feedback on covered topics and suggestions for other interesting or unique open source projects.

#### Coding and Analysis

We recorded and transcribed the interviews using a GDPR-compliant service, manually reviewing transcripts for accuracy. The analysis followed an iterative open-coding approach, with three researchers coding the interviews in multiple rounds, resolving conflicts by consensus. The final codebook, included in the replication package, resulted in 1,618 codes, with a median of 59 codes per interview.

#### Ethical Considerations and Data Protection

This study was approved by the human subjects review board and adhered to strict German data and privacy protection laws and the EU General Data Protection Regulation (GDPR). All documents with personally identifiable data were stored securely, and the transcription service complied with GDPR. Participants were informed about consent and data handling, and we obtained informed consent for participation and audio recording. Participants were given the opportunity to suggest changes or veto the work.

#### Limitations

- **Self-Report Biases:** Potential over- and under-reporting, sample bias, and social-desirability bias.
- **Convenience Sample:** Our sample may not be representative of all OSS contributors.
- **Language Bias:** Focus on projects with English Readme documents, with some interviews conducted in German, limiting generalizability to non-English and non-German speaking contributors.

### Results

In this section, we report and discuss the results from 27 semi-structured interviews with open source contributors, maintainers, and owners. We adhere to the structure of the interview guide and summarize key findings after each question block. Quotes are reported as transcribed, with minor grammatical corrections and omissions marked by brackets. German quotes were translated by native speakers.

#### A. Project Demographics

- **Total Participants:** 27
- **General Interview and Project Demographics:** Reported in Table I.
- **Largest Project Mentioned:** For quantitative data, we considered the largest project mentioned during the interview, balancing concise reporting and comprehensive data.