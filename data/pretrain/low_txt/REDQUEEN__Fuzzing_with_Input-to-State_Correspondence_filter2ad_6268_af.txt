### Fuzzing Performance Analysis

The overall fuzzing performance is illustrated in Figure 4, where the bars represent the average number of executions performed per second. Typically, KAFL and REDQUEEN exhibit a performance impact of 25-50% compared to LAF-INTEL and AFLFast. This is because KAFL does not use fast compiler-based instrumentation and operates on binary code. However, to the best of our knowledge, REDQUEEN is currently the fastest binary-only fuzzer.

### Table VI: Percentage of Paths Found by Different Encoding Schemes

| Encoding | Zero Ext | Sign Ext | Plain | Mem | C-Str | ASCII |
|----------|----------|----------|-------|-----|-------|-------|
| **Plain** | 38.40%   | 22.65%   | 4.42% | 5.16% | 2.42% | 1.21% |
| **Reverse** | 6.82%   | 6.61%   | 11.64% | -   | -     | -     |
| **Total** | 45.22%  | 29.27%  | 16.06% | 5.16% | 2.42% | 1.21% |

In some cases, REDQUEEN outperforms KAFL, which is counter-intuitive given the additional work it performs. This can be explained by the fact that the number of executions per second is heavily dependent on the inputs in the queue. If the queue contains slow inputs, the performance drops. When KAFL encounters a roadblock, the only new inputs are those that perform more loop iterations. As shown in Figure 4, the impact of the REDQUEEN extension on the number of executions per second is minimal and sometimes even increases the number of executions. Despite the slow breakpoint-based tracing (often 50x or more), it has little effect on fuzzing performance because the REDQUEEN phase is triggered only once per input in the queue.

### Effectiveness of Techniques

Table V shows the effectiveness of different techniques used by REDQUEEN. Each technique's ability to find new inputs is noted, and it is evident that input-to-state correspondence-based mutations often find as many or more new inputs than other phases while using significantly less time. This indicates that our techniques are useful beyond typical roadblocks, helping to find a significant number of paths faster than other mutation strategies.

### Prevalence of Encoding Schemes

We evaluated the prevalence of different encoding schemes by counting the percentage of paths found using each scheme, as shown in Table VI. The results indicate that most improvements are due to what we consider one-to-one correspondences. Based on these experiments, we conclude that input-to-state-based mutations are a highly general, effective, and efficient scheme for improving fuzzer performance.

### High-Level Summary

Our work demonstrates that input-to-state correspondence-based techniques significantly increase coverage on three large test corpora and find novel bugs in both kernel- and user-space software. We also outperform state-of-the-art tools like VUZZER, ANGORA, T-FUZZ, and KLEE in uncovering new behavior and bugs. Even in a binary-only scenario, our techniques compete with other approaches, even when hash checks are removed and they are provided with a proper dictionary.

Our approach is applicable without source code access and outperforms state-of-the-art fuzzers, even when they have source code access. However, this does not mean that more complex approaches are useless. In certain cases, such as PNG file format compression, hash maps, and base64 decoding, our approach may not offer advantages. These cases are rare, and tools that can solve them often struggle with common problems like path explosion or poor performance on complex targets. We recommend using our lightweight approach as a first step and then addressing remaining challenges with more complex methods.

### Conclusion

In this paper, we presented and evaluated methods based on input-to-state correspondence to improve fuzzing. Our approach significantly enhances coverage in binary-only targets by solving magic-bytes comparisons and checksum checks. While not as formal as symbolic execution or taint tracking, our method is fast, lightweight, and robust. It remains effective even if some parts of the program are hard to analyze.

### Acknowledgments

This work was supported by Intel as part of the Intel Collaborative Research Institute “Collaborative Autonomous & Resilient Systems” (ICRI-CARS) and received funding from the European Union’s Horizon 2020 Research and Innovation Programme under Grant Agreement No. 786669. We thank Ali Abbasi, Joel Frank, Emre Güler, and Christine Utz for their valuable feedback.

### References

[1] Announcing OSS-Fuzz: Continuous Fuzzing for Open Source Software. https://testing.googleblog.com/2016/12/announcing-oss-fuzz-continuous-fuzzing.html.
[2] Circumventing fuzzing roadblocks with compiler transformations. https://lafintel.wordpress.com/. Accessed: 2018-08-07.
[3] Darpa challenge binaries on Linux, OS X, and Windows. https://github.com/trailofbits/cb-multios. Accessed: 2018-08-07.
[4] Peach. http://www.peachfuzzer.com/. Accessed: 2018-08-07.
[5] Project Triforce: Run AFL on Everything! https://www.nccgroup.trust/us/about-us/newsroom-and-events/blog/2016/june/project-triforce-run-afl-on-everything/.
[6] Security-oriented fuzzer with powerful analysis options. https://github.com/google/honggfuzz. Accessed: 2018-08-07.
[7] Andrea Arcuri and Lionel Briand. A hitchhiker’s guide to statistical tests for assessing randomized algorithms in software engineering. Software Testing, Verification and Reliability, 24(3):219–250, 2014.
[8] Osbert Bastani, Rahul Sharma, Alex Aiken, and Percy Liang. Synthesizing program input grammars. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2017.
[9] Fabrice Bellard. Qemu, a fast and portable dynamic translator. In USENIX Annual Technical Conference, FREENIX Track, 2005.
[10] Marcel Böhme, Van-Thuan Pham, and Abhik Roychoudhury. Coverage-based greybox fuzzing as Markov chain. In ACM Conference on Computer and Communications Security (CCS), 2016.
[11] Derek Bruening, Evelyn Duesterwald, and Saman Amarasinghe. Design and implementation of a dynamic optimization framework for Windows. In ACM Workshop on Feedback-Directed and Dynamic Optimization, 2001.
[12] Cristian Cadar, Daniel Dunbar, and Dawson R Engler. Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs. In Symposium on Operating Systems Design and Implementation (OSDI), 2008.
[13] Sang Kil Cha, Thanassis Avgerinos, Alexandre Rebert, and David Brumley. Unleashing Mayhem on Binary Code. In IEEE Symposium on Security and Privacy, 2012.
[14] Sang Kil Cha, Maverick Woo, and David Brumley. Program-adaptive mutational fuzzing. In IEEE Symposium on Security and Privacy, 2015.
[15] Buddhika Chamith, Bo Joel Svensson, Luke Dalessandro, and Ryan R. Newton. Instruction punning: Lightweight instrumentation for x86-64. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2017.
[16] Peng Chen and Hao Chen. Angora: Efficient fuzzing by principled search. In IEEE Symposium on Security and Privacy, 2018.
[17] Brendan Dolan, Patrick Hulin, Engin Kirda, Tim Leek, Andrea Mambretti, William Robertson, Frederick Ulrich, and Ryan Whelan. LAVA: Large-scale automated vulnerability addition. In IEEE Symposium on Security and Privacy, 2016.
[18] Will Drewry and Tavis Ormandy. Flayer: Exposing application internals. In USENIX Workshop on Offensive Technologies (WOOT), 2007.
[19] Shuitao Gan, Chao Zhang, Xiaojun Qin, Xuwen Tu, Kang Li, Zhongyu Pei, and Zuoning Chen. CollaF: Path sensitive fuzzing. In IEEE Symposium on Security and Privacy, 2018.
[20] Vijay Ganesh, Tim Leek, and Martin Rinard. Taint-based directed whitebox fuzzing. In International Conference on Software Engineering (ICSE), 2009.
[21] Patrice Godefroid, Adam Kiezun, and Michael Y Levin. Grammar-based whitebox fuzzing. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2008.
[22] Patrice Godefroid, Nils Klarlund, and Koushik Sen. DART: Directed Automated Random Testing. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2005.
[23] Patrice Godefroid, Michael Y Levin, David A Molnar, et al. Automated whitebox fuzz testing. In Symposium on Network and Distributed System Security (NDSS), 2008.
[24] Patrice Godefroid, Hila Peleg, and Rishabh Singh. Learn&Fuzz: Machine learning for input fuzzing. Technical report, January 2017.
[25] Peter Shin Goodman. GRR: Make Fuzzing Fast Again. https://blog.trailofbits.com/2016/11/02/shin-grr-make-fuzzing-fast-again/.
[26] Istvan Haller, Asia Slowinska, Matthias Neugschwandtner, and Herbert Bos. Dowsing for overflows: A guided fuzzer to find buffer boundary violations. In USENIX Security Symposium, 2013.
[27] HyungSeok Han and Sang Kil Cha. IMF: Inferred model-based fuzzer. In ACM Conference on Computer and Communications Security (CCS), 2017.
[28] Wookhyun Han, Byunggill Joe, Byoungyoung Lee, Chengyu Song, and Insik Shin. Enhancing memory error detection for large-scale applications and fuzz testing. In Symposium on Network and Distributed System Security (NDSS), 2018.
[29] Aki Helin. A general-purpose fuzzer. https://gitlab.com/akihe/radamsa. Accessed: 2018-08-07.
[30] Chin-Chia Hsu, Che-Yu Wu, Hsu-Chun Hsiao, and Shih-Kun Huang. Instrim: Lightweight instrumentation for coverage-guided fuzzing. In Symposium on Network and Distributed System Security (NDSS), Workshop on Binary Analysis Research, 2018.
[31] Yuekang Li, Bihuan Chen, Mahinthan Chandramohan, Shang-Wei Lin, Yang Liu, and Alwen Tiu. Steelix: Program-state Based Binary Fuzzing. In Joint Meeting on Foundations of Software Engineering, 2017.
[32] Chi-Keung Luk, Robert Cohn, Robert Muth, Harish Patil, Artur Klauser, Geoff Lowney, Steven Wallace, Vijay Janapa Reddi, and Kim Hazelwood. Pin: Building customized program analysis tools with dynamic instrumentation. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2005.
[33] David Molnar, Xue Cong Li, and David Wagner. Dynamic Test Generation to Find Integer Bugs in x86 Binary Linux Programs. In USENIX Security Symposium, 2009.
[34] Hui Peng, Yan Shoshitaishvili, and Mathias Payer. T-Fuzz: Fuzzing by program transformation. In IEEE Symposium on Security and Privacy, 2018.
[35] Sanjay Rawat, Vivek Jain, Ashish Kumar, Lucian Cojocar, Cristiano Giuffrida, and Herbert Bos. VUzzer: Application-aware Evolutionary Fuzzing. In Symposium on Network and Distributed System Security (NDSS), February 2017.
[36] Alexandre Rebert, Sang Kil Cha, Thanassis Avgerinos, Jonathan M Foote, David Warren, Gustavo Grieco, and David Brumley. Optimizing seed selection for fuzzing. In USENIX Security Symposium, 2014.
[37] Sergej Schumilo, Cornelius Aschermann, Robert Gawlik, Sebastian Schinzel, and Thorsten Holz. KAFL: Hardware-assisted feedback fuzzing for OS kernels. In USENIX Security Symposium, 2017.
[38] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang, Jacopo Corbetta, Yan Shoshitaishvili, Christopher Kruegel, and Giovanni Vigna. Driller: Augmenting fuzzing through selective symbolic execution. In Symposium on Network and Distributed System Security (NDSS), 2016.
[39] Dmitry Vyukov. gofuzz. https://go-talks.appspot.com/github.com/dvyukov/go-fuzz/slides/go-fuzz.slide#17.
[40] Tielei Wang, Tao Wei, Guofei Gu, and Wei Zou. TaintScope: A checksum-aware directed fuzzing tool for automatic software vulnerability detection. In IEEE Symposium on Security and Privacy, 2010.
[41] Maverick Woo, Sang Kil Cha, Samantha Gottlieb, and David Brumley. Scheduling black-box mutational fuzzing. In ACM Conference on Computer and Communications Security (CCS), 2013.
[42] Wen Xu, Sanidhya Kashyap, Changwoo Min, and Taesoo Kim. Designing new operating primitives to improve fuzzing performance. In ACM Conference on Computer and Communications Security (CCS), 2017.
[43] Michał Zalewski. AFL-Fuzz: Making up grammar with a dictionary in hand. https://lcamtuf.blogspot.de/2015/01/afl-fuzz-making-up-grammar-with.html. Accessed: 2018-08-07.
[44] Michał Zalewski. American Fuzzy Lop. http://lcamtuf.coredump.cx/afl/. Accessed: 2018-08-07.