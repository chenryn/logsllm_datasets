### Vulnerability of IVK-Protected Applications

An application protected by Instruction Verification Keys (IVK) is susceptible to our attack. This vulnerability arises from the surrounding program, making the IVK-protected application less secure than intended.

### Alternative Solutions and Their Limitations

If one is willing to modify the requirements and allow applications to depend on a trusted third party, several alternatives exist. For example, an application could use a custom operating system extension, such as a kernel module, to verify the integrity of its code. However, this approach faces significant challenges, including implementation complexity, lack of portability, stability issues, and security concerns associated with modifying the underlying operating system.

Another alternative is to assume that the application has access to a trusted platform. This can be in the form of an external hardware "dongle" [9], a trusted remote server [15], or a trusted operating system [20, 23]. Regardless of the method used, to prevent a processor-based attack like ours, the developer must ensure that the executed code is identical to the code that is checked.

### Summary of Alternatives

We are not aware of any alternatives to checksumming in the self-checking tamper resistance space that combine the ease of implementation, platform independence, and runtime efficiency of checksumming while also being invulnerable to a processor-based instruction/data separation attack. Nonetheless, advances in static and runtime analysis might enable the development of alternative systems that verify the state of a program binary by intermingling and checking runtime intermediate values. These systems could be applied to existing programs with minimal runtime overhead. Our work provides significant motivation for pursuing such methods.

### Related Work

Various tamper resistance proposals attempt to address the malicious host problem through the introduction of secure hardware [29, 28, 32]. Storing programs in execute-only memory [18] has also been proposed, preventing the application from being visible in its binary form to an attacker. However, secure hardware is not widely deployed, making it unsuitable for mass-market solutions. Other research involves the use of external trusted third parties [5, 6, 11]. However, not all computers are continuously connected to the network, which, among other drawbacks, makes this solution unappealing in general.

Ongoing research focuses on techniques for remote authentication (e.g., see [15, 27, 16], also [3]). SWATT [26] has been proposed as a method for external software to verify the integrity of software on an embedded device. Another recent study [24] proposes a method using a Trusted Platform Module [31] to verify client integrity properties before allowing clients (remote) access to enterprise services.

Software tamper resistance often employs software obfuscation to make intelligent software tampering impossible (see [10, 34] and recent surveys [7, 33]). We view obfuscation and tamper resistance as distinct approaches with different end goals. Obfuscation, primarily effective against static analysis, attempts to thwart reverse engineering and extraction of intelligence regarding program design details. As a secondary effect, it often thwarts intelligent software modification. Tamper resistance, on the other hand, aims to make the program unmodifiable. In an obfuscated program, code modifications are generally not directly detected.

Other proposed methods of integrity verification, such as Tripwire [17], aim to protect the integrity of a file system against malicious intruders. Integrity verification at the level of Tripwire assumes that the operator is trusted to read and act on the verification results appropriately. Recent proposals include a co-processor-based kernel runtime integrity monitor [22], but these do not protect against the hostile host problem in the case of a hostile end user.

### Concluding Remarks

We have demonstrated that the use of self-checksumming for tamper resistance is less secure than previously believed on several prominent computer processors, as shown on the UltraSparc and x86. Our attack should be carefully considered before choosing to use checksumming for tamper resistance. While other forms of tamper resistance exist that are not susceptible to our attack, they typically have their own disadvantages (see Section 5.2). We encourage further research into new forms of self-checking tamper resistance, such as those possible through execute-only page table entries [18].

Memory management functionality within a processor plays a crucial role in determining the vulnerability of current implementations to our attack. If a processor does not distinguish between code and data reads, our attack fails. Modern processors, however, increasingly provide functionality that allows such a distinction, due to the performance and general security benefits of code/data separation at the processor level. On such processors, self-integrity checksumming tamper resistance is not secure against attack, and alternative mechanisms that are not compromised by such distinctions should be pursued.

### Acknowledgements

The first author acknowledges Canada’s National Sciences and Engineering Research Council (NSERC) for funding his PGS M scholarship. The second author acknowledges NSERC for funding an NSERC Discovery Grant and his Canada Research Chair in Network and Software Security. The third author acknowledges NSERC for funding an NSERC Discovery Grant. We thank David Lie, Mike Atallah, Clark Thomborson (and his group), and anonymous referees for their comments on a preliminary draft.

### References

[1] Advanced Micro Devices, Inc. AMD64 Architecture Programmer’s Manual, volume 2: System Programming. Advanced Micro Devices, Inc., Sep 2003.
[2] D. Aucsmith. Tamper resistant software: An implementation. In R. Anderson, editor, Proceedings of the First International Workshop on Information Hiding, volume 1174 of Lecture Notes in Computer Science, pages 317–333. Springer-Verlag, May 1996.
[3] E. Brickell, J. Camenisch, and L. Chen. Direct anonymous attestation. In B. Pfitzmann and P. Liu, editors, Proceedings of the 11th ACM Conference on Computer and Communications Security, pages 132–144. The Association for Computing Machinery, Oct 2004.
[4] H. Chang and M. Atallah. Protecting software code by guards. In Proc. 1st ACM Workshop on Digital Rights Management (DRM 2001), volume 2320 of Lecture Notes in Computer Science, pages 160–175. Springer-Verlag, 2002.
[5] Y. Chen, R. Venkatesan, M. Cary, R. Pang, S. Sinba, and M. Jakubowski. Oblivious hashing: A stealthy software integrity verification primitive. In Proc. 5th Information Hiding Workshop (IHW), volume 2578 of Lecture Notes in Computer Science, pages 400–414, Netherlands, Oct 2002. Springer-Verlag.
[6] J. Claessens, B. Preneel, and J. Vandewalle. (How) can mobile agents do secure electronic transactions on untrusted hosts? A survey of the security issues and the current solutions. ACM Trans. Inter. Tech., 3(1):28–48, 2003.
[7] C. S. Collberg and C. Thomborson. Watermarking, tamper-proofing, and obfuscation: Tools for software protection. IEEE Trans. Softw. Eng., 28(8):735–746, 2002.
[8] Compaq Computer Corporation. Alpha Architecture Handbook, chapter 6 - Common PALcode Architecture. Number EC-QD2KC-TE. 4th edition, Oct 1998.
[9] J. Gosler. Software protection: Myth or reality? In Advances in Cryptology – CRYPTO’85, volume 218 of Lecture Notes in Computer Science, pages 140–157. Springer-Verlag, 1985.
[10] H. Goto, M. Mambo, K. Matsumura, and H. Shizuya. An approach to the objective and quantitative evaluation of tamper-resistant software. In J. S. J. Pieprzyk, E. Okamoto, editor, Information Security: Third International Workshop, ISW 2000, volume 1975 of Lecture Notes in Computer Science, pages 82–96, Wollongong, Australia, Dec 2000. Springer-Verlag.
[11] F. Hohl. Time limited blackbox security: Protecting mobile agents from malicious hosts. In Mobile Agents and Security, volume 1419 of Lecture Notes in Computer Science, pages 92–113. Springer-Verlag, 1998.
[12] B. Horne, L. Matheson, C. Sheehan, and R. Tarjan. Dynamic self-checking techniques for improved tamper resistance. In Proc. 1st ACM Workshop on Digital Rights Management (DRM 2001), volume 2320 of Lecture Notes in Computer Science, pages 141–159. Springer-Verlag, 2002.
[13] Intel. IA-32 Intel Architecture Software Developer’s Manual, volume 3: System Programming Guide, chapter 3 - Protected-Mode Memory Management. Intel Corporation, P.O. Box 5937 Denver CO, 2003.
[14] H. Jin and J. Lotspiech. Proactive software tampering detection. In C. Boyd and W. Mao, editors, Information Security: 6th International Conference, ISC 2003, volume 2851 of Lecture Notes in Computer Science, pages 352–365, Bristol, UK, Oct 2003. Springer-Verlag.
[15] R. Kennell and L. H. Jamieson. Establishing the genuineness of remote computer systems. In Proceedings of the 12th USENIX Security Symposium, pages 295–308, Aug 2003.
[16] R. Kennell and L. H. Jamieson. An analysis of proposed attacks against genuineness tests. Technical report, Purdue University, Aug 2004. CERIAS TR 2004-27.
[17] G. H. Kim and E. H. Spafford. The design and implementation of Tripwire: A file system integrity checker. In Proceedings of the 2nd ACM Conference on Computer and Communications Security, pages 18–29. ACM Press, 1994.
[18] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. Mitchell, and M. Horowitz. Architectural support for copy and tamper-resistant software. In Proceedings of the Ninth International Conference on Architectural Support for Programming Languages and Operating Systems, pages 168–177. ACM Press, 2000.
[19] The Linux Kernel Archives, Oct 2004. http://www.kernel.org.
[20] P. A. Loscocco, S. D. Smalley, P. A. Muckelbauer, R. C. Taylor, S. J. Turner, and J. F. Farrell. The inevitability of failure: The flawed assumption of security in modern computing environments. In 21st National Information Systems Security Conference. National Security Agency, 1998. http://csrc.nist.gov/nissc/1998/proceedings/paperF1.pdf.
[21] Motorola. Programming Environments Manual: For 32-Bit Implementations of the PowerPC Architecture. Dec. 2001. http://e-www.motorola.com/brdata/PDFDB/docs/MPCFPE32B.pdf.
[22] J. Nick L. Petroni, T. Fraser, J. Molina, and W. A. Arbaugh. Copilot - a coprocessor-based kernel runtime integrity monitor. In Proceedings of the 13th USENIX Security Symposium, pages 179–194, Aug 2004.
[25] T. Sander and C. Tschudin. Protecting mobile agents against malicious hosts. In G. Vigna, editor, Mobile Agents and Security, volume 1419 of Lecture Notes in Computer Science, pages 44–60. Springer-Verlag, 1998.
[26] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla. SWATT: Software-based attestation for embedded devices. In Proceedings of the IEEE Symposium on Security and Privacy, Oakland, CA, May 2004.
[27] U. Shankar, M. Chew, and J. Tygar. Side effects are not sufficient to authenticate software. In Proceedings of the 13th USENIX Security Symposium, pages 89–102, Aug 2004.
[28] S. W. Smith and S. Weingart. Building a high-performance, programmable secure coprocessor. Computer Networks, 31(9):831–860, 1999.
[29] G. E. Suh, D. Clarke, B. Gassend, M. van Dijk, and S. Devadas. AEGIS: architecture for tamper-evident and tamper-resistant processing. In Proceedings of the 17th Annual International Conference on Supercomputing, pages 160–171. ACM Press, 2003.
[30] Sun Microsystems. UltraSPARC III Cu user’s manual. 4150 Network Circle, Santa Clara, California, Jan 2004. http://www.sun.com/processors/manuals/USIIIv2.pdf.
[31] Trusted Computing Group. Trusted Platform Module (TPM) main specification, version 1.2, revision 62, Oct 2001. http://www.trustedcomputinggroup.org.
[32] Trusted Computing Group, Oct 2004. http://www.trustedcomputingroup.com/home.
[33] P. C. van Oorschot. Revisiting software protection. In C. Boyd and W. Mao, editors, Information Security: 6th International Conference, ISC 2003, volume 2851 of Lecture Notes in Computer Science, pages 1–13, Bristol, UK, Oct 2003. Springer-Verlag.
[34] C. Wang. A Security Architecture for Survivability Mechanisms. PhD thesis, University of Virginia, Charlottesville, Virginia, Oct. 2000. http://www.cs.virginia.edu/~survive/pub/wangthesis.pdf.
[35] G. Wurster, P. C. van Oorschot, and A. Somayaji. Generic attacks on self-checksumming software tamper resistance. In preparation.
[23] M. Peinado, Y. Chen, P. England, and J. Manferdelli. NGSCB: A trusted open system, Jan 2005. http://research.microsoft.com/~yuqunc/papers/ngscb.pdf.
[24] R. Sailer, T. Jaeger, X. Zhang, and L. van Doorn. Attestation-based policy enforcement for remote access. In B. Pfitzmann and P. Liu, editors, Proceedings of the 11th ACM Conference on Computer and Communications Security, pages 308–317. The Association for Computing Machinery, Oct 2004.