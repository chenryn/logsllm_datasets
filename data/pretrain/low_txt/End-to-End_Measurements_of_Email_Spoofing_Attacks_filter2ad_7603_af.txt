### Oral Differences in Role-Playing Experiments with Reality

Our work is the first to examine the impact of security indicators on phishing emails using realistic phishing tests.

### Visual Security Indicators

Security indicators are commonly used in web and mobile browsers to warn users about unencrypted web sessions [25, 39, 61, 49], phishing web pages [21, 24, 69, 70], and malware sites [7]. Existing research shows that users often ignore these indicators due to a lack of understanding of the attack [69] or frequent exposure to false alarms [43]. Researchers have explored various methods to make security UIs more noticeable, such as using attractors [13, 12, 14]. Our work is the first to measure the usage and effectiveness of security indicators on forged emails.

### Conclusion

Through extensive end-to-end measurements and real-world phishing tests, our study reveals a concerning gap between server-side spoofing detection and actual user protection. We demonstrate that most email providers allow forged emails to reach user inboxes without necessary warning mechanisms, particularly in mobile apps. For the few email services that have implemented security indicators, we show that these indicators positively impact reducing risky user actions under phishing attacks but cannot eliminate the risk entirely. We hope our results will draw more community attention to promoting the adoption of SMTP security extensions and developing effective security indicators for web and mobile email interfaces.

### Acknowledgments

We would like to thank the anonymous reviewers for their valuable feedback. This project was supported in part by NSF grants CNS-1750101 and CNS-1717028. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of any funding agencies.

### References

[1] Alexa. http://www.alexa.com.
[2] Phishing activity trends report, 2015. APWG Trends Report Q1-Q3 2015. http://docs.apwg.org/reports/1st-3rd-quarters-2015.pdf.
[3] Postfix. http://www.postfix.org.
[4] Data breach investigations report. Verizon Inc., 2017. http://www.verizonenterprise.com/verizon-insights-lab/dbir/2017/.
[5] Email statistics report. The Radicati Group, 2017. http://www.radicati.com/wp/wp-content/uploads/2017/01/Email-Statistics-Report-2017-2021-Executive-Summary.pdf.
[6] AGTEN, P., JOOSEN, W., PIESSENS, F., AND NIKIFORAKIS, N. Seven months’ worth of mistakes: A longitudinal study of typosquatting abuse. In Proc. of NDSS (2015).
[7] AKHAWE, D., AND FELT, A. P. Alice in warningland: A large-scale field study of browser security warning effectiveness. In Proc. of USENIX Security (2013).
[8] ANDERSON, B. B., VANCE, T., KIRWAN, C. B., EARLE, D., AND HOWARD, S. Users aren’t (necessarily) lazy: Using neuroIS to explain habituation to security warnings. In Proc. of ICIS (2014).
[9] ANTIN, J., AND SHAW, A. Social desirability bias and self-reports of motivation: A study of Amazon Mechanical Turk in the US and India. In Proc. of CHI (2012).
[10] BILOGREVIC, I., HUGUENIN, K., MIHAILA, S., SHOKRI, R., AND HUBAUX, J.-P. Predicting users’ motivations behind location check-ins and utility implications of privacy protection mechanisms. In Proc. of NDSS (2015).
[11] BLANZIERI, E., AND BRYL, A. A survey of learning-based techniques of email spam filtering. Artificial Intelligence Review 29, 1 (2008), 63–92.
[12] BRAVO-LILLO, C., CRANOR, L., AND KOMANDURI, S. Harder to ignore? Revisiting pop-up fatigue and approaches to prevent it. In Proc. of SOUPS (2014).
[13] BRAVO-LILLO, C., CRANOR, L. F., DOWNS, J., AND KOMANDURI, S. Bridging the gap in computer security warnings: A mental model approach. In Proc. of IEEE S&P (2011).
[14] BRAVO-LILLO, C., KOMANDURI, S., CRANOR, L. F., REEDER, R. W., SLEEPER, M., DOWNS, J., AND SCHECHTER, S. Your attention please: Designing security-decision UIs to make genuine risks harder to ignore. In Proc. of SOUPS (2013).
[15] CONSTANTIN, L. Yahoo email anti-spoofing policy breaks mailing lists. PC World, 2014. https://www.pcworld.com/article/2141120/yahoo-email-antispoofing-policy-breaks-mailing-lists.html.
[16] CONWAY, D., TAIB, R., HARRIS, M., YU, K., BERKOVSKY, S., AND CHEN, F. A qualitative investigation of bank employee experiences of information security and phishing. In Proc. of SOUPS (2017).
[17] COVER, T. M., AND THOMAS, J. A. Elements of information theory. John Wiley & Sons, 2012.
[18] CUI, Q., JOURDAN, G.-V., BOCHMANN, G. V., COUTURIER, R., AND ONUT, I.-V. Tracking phishing attacks over time. In Proc. of WWW (2017).
[19] D. CROCKER, T. HANSEN, M. K. DomainKeys Identified Mail (DKIM) signatures, 2011. https://tools.ietf.org/html/rfc6376.
[20] DEWAN, P., KASHYAP, A., AND KUMARAGURU, P. Analyzing social and stylometric features to identify spear phishing emails. In Proc. of eCrime (2014).
[21] DHAMIJA, R., TYGAR, J. D., AND HEARST, M. Why phishing works. In Proc. of CHI (2006).
[22] DUMAN, S., KALKAN-CAKMAKCI, K., EGELE, M., ROBERTSON, W. K., AND KIRDA, E. EmailProfiler: Spearphishing filtering with header and stylometric features of emails. In Proc. of COMPSAC (2016).
[23] DURUMERIC, Z., ADRIAN, D., MIRIAN, A., KASTEN, J., BURSZTEIN, E., LIDZBORSKI, N., THOMAS, K., ERANTI, V., BAILEY, M., AND HALDERMAN, J. A. Neither snow nor rain nor MITM: An empirical analysis of email delivery security. In Proc. of IMC (2015).
[24] EGELMAN, S., CRANOR, L. F., AND HONG, J. You’ve been warned: An empirical study of the effectiveness of web browser phishing warnings. In Proc. of CHI (2008).
[25] FELT, A. P., ET AL. Rethinking connection security indicators. In Proc. of SOUPS (2016).
[26] FETTE, I., SADEH, N., AND TOMASIC, A. Learning to detect phishing emails. In Proc. of WWW (2007).
[27] FOSTER, I. D., LARSON, J., MASICH, M., SNOEREN, A. C., SAVAGE, S., AND LEVCHENKO, K. Security by any other name: On the effectiveness of provider-based email security. In Proc. of CCS (2015).
[28] GADIRAJU, U., KAWASE, R., DIETZE, S., AND DEMARTINI, G. Understanding malicious behavior in crowdsourcing platforms: The case of online surveys. In Proc. of CHI (2015).
[29] GARFINKEL, S. PGP: Pretty Good Privacy, 1st ed. O’Reilly & Associates, Inc., 1996.
[30] GAW, S., FELTEN, E. W., AND FERNANDEZ-KELLY, P. Secrecy, flagging, and paranoia: Adoption criteria in encrypted email. In Proc. of CHI (2006).
[31] GREITZER, F. L., STROZER, J. R., COHEN, S., MOORE, A. P., MUNDIE, D., AND COWLEY, J. Analysis of unintentional insider threats deriving from social engineering exploits. In Proc. of IEEE S&P Workshops (2014).
[32] HAN, X., KHEIR, N., AND BALZAROTTI, D. Phisheye: Live monitoring of sandboxed phishing kits. In Proc. of CCS (2016).
[33] HO, G., SHARMA, A., JAVED, M., PAXSON, V., AND WAGNER, D. Detecting credential spearphishing in enterprise settings. In Proc. of USENIX Security (2017).
[34] HOLZ, R., AMANN, J., MEHANI, O., WACHS, M., AND KAAFAR, M. A. TLS in the wild: An internet-wide analysis of TLS-based protocols for electronic communication. In Proc. of NDSS (2016).
[35] HONG, J. The state of phishing attacks. Communications of the ACM 55, 1 (2012).
[36] HU, H., PENG, P., AND WANG, G. Towards the adoption of anti-spoofing protocols. CoRR abs/1711.06654 (2017).
[37] HU, H., PENG, P., AND WANG, G. Towards understanding the adoption of anti-spoofing protocols in email systems. In Proc. of SecDev (2018).
[38] JAGATIC, T. N., JOHNSON, N. A., JAKOBSSON, M., AND MENCZER, F. Social phishing. Communications of the ACM 50, 10 (2007).
[39] JOEL WEINBERGER, A. P. F. A week to remember: The impact of browser warning storage policies. In Proc. of SOUPS (2016).
[40] KITTERMAN, S. Sender Policy Framework (SPF), 2014. https://tools.ietf.org/html/rfc7208.
[41] KOCIENIEWSKI, D. Adobe announces security breach. The New York Times, 2013. https://www.nytimes.com/2013/10/04/technology/adobe-announces-security-breach.html.
[42] KRAMMER, V. Phishing defense against IDN address spoofing attacks. In Proc. of PST (2006).
[43] KROL, K., MOROZ, M., AND SASSE, M. A. Don't work. Can't work? Why it’s time to rethink security warnings. In Proc. of CRiSIS (2012).
[44] KUMARAGURU, P., RHEE, Y., ACQUISTI, A., CRANOR, L. F., HONG, J., AND NUNGE, E. Protecting people from phishing: The design and evaluation of an embedded training email system. In Proc. of CHI (2007).
[45] LANCASTER, H. O., AND SENETA, E. Chi-square distribution. Wiley Online Library, 1969.
[46] LARDINOIS, F. Gmail now has more than 1B monthly active users. TechCrunch, 2016. https://techcrunch.com/2016/02/01/gmail-now-has-more-than-1b-monthly-active-users/.
[47] LASTDRAGER, E., GALLARDO, I. C., HARTEL, P., AND JUNGER, M. How effective is anti-phishing training for children? In Proc. of SOUPS (2017).
[48] LUBAR, K., AND IMAGES, G. After 3 years, why Gmail's end-to-end encryption is still vapor. Wired, 2017. https://www.wired.com/2017/02/3-years-gmails-end-end-encryption-still-vapor/.
[49] LUO, M., STAROV, O., HONARMAND, N., AND NIKIFORAKIS, N. Hindsight: Understanding the evolution of UI vulnerabilities in mobile browsers. In Proc. of CCS (2017).
[50] M. KUCHERAWY, E. Z. Domain-based message authentication, reporting, and conformance (DMARC), 2015. https://tools.ietf.org/html/rfc7489.
[51] MCGRATH, D. K., AND GUPTA, M. Behind phishing: An examination of phisher modus operandi. In Proc. of LEET (2008).
[52] OLIVEIRA, D., ROCHA, H., YANG, H., ELLIS, D., DOMMARAJU, S., MURADOGLU, M., WEIR, D., SOLIMAN, A., LIN, T., AND EBNER, N. Dissecting spear phishing emails for older vs young adults: On the interplay of weapons of influence and life domains in predicting susceptibility to phishing. In Proc. of CHI (2017).
[53] PATTINSON, M. R., JERRAM, C., PARSONS, K., MCCORMAC, A., AND BUTAVICIUS, M. A. Why do some people manage phishing emails better than others? Inf. Manag. Comput. Security, 1 (2012), 18–28.
[54] PEREZ, S. Recently confirmed MySpace hack could be the largest yet. TechCrunch, 2016. https://techcrunch.com/2016/05/31/recently-confirmed-myspace-hack-could-be-the-largest-yet/.
[55] PERLROTH, V. G. Yahoo says 1 billion user accounts were hacked. The New York Times, 2016. https://www.nytimes.com/2016/12/14/technology/yahoo-hack.html.
[56] POSTEL, J. B. Simple Mail Transfer Protocol, 1982. https://tools.ietf.org/html/rfc821.
[57] PRAKASH, P., KUMAR, M., KOMPELLA, R. R., AND GUPTA, M. PhishNet: Predictive blacklisting to detect phishing attacks. In Proc. of INFOCOM (2010).
[58] RAMACHANDRAN, A., FEAMSTER, N., AND VEMPALA, S. Filtering spam with behavioral blacklisting. In Proc. of CCS (2007).
[59] SCHECHTER, S. E., DHAMIJA, R., OZMENT, A., AND FISCHER, I. The emperor’s new security indicators: An evaluation of website authentication and the effect of role playing on usability studies. In Proc. of IEEE S&P (2007).
[60] SHENG, S., HOLBROOK, M., KUMARAGURU, P., CRANOR, L. F., AND DOWNS, J. Who falls for phish?: A demographic analysis of phishing susceptibility and effectiveness of interventions. In Proc. of CHI (2010).
[61] SUNSHINE, J., EGELMAN, S., ALMUHIMEDI, H., ATRI, N., AND CRANOR, L. F. Crying wolf: An empirical study of SSL warning effectiveness. In Proc. of USENIX Security (2009).
[62] THOMAS, K., LI, F., ZAND, A., BARRETT, J., RANIERI, J., INVERNIZZI, L., MARKOV, Y., COMANESCU, O., ERANTI, V., MOSCICKI, A., MARGOLIS, D., PAXSON, V., AND BURSZTEIN, E. Data breaches, phishing, or malware? Understanding the risks of stolen credentials. In Proc. of CCS (2017).
[63] VARGAS, J., BAHNSEN, A. C., VILLEGAS, S., AND INGEVALDSON, D. Knowing your enemies: Leveraging data analysis to expose phishing patterns against a major US financial institution. In Proc. of eCrime (2016).
[64] VISHWANATH, A., HERATH, T., CHEN, R., WANG, J., AND RAO, H. R. Why do people get phished? Testing individual differences in phishing vulnerability within an integrated, information processing model. Decis. Support Syst. 51, 3 (2011).
[65] WANG, J., HERATH, T., CHEN, R., VISHWANATH, A., AND RAO, H. R. Research article: Phishing susceptibility: An investigation into the processing of a targeted spear phishing email. IEEE Transactions on Professional Communication 55, 4 (2012), 345–362.
[66] WANG, J., LI, Y., AND RAO, H. R. Overconfidence in phishing email detection. Journal of the Association for Information Systems 17, 1 (2016).
[67] WASH, R., AND COOPER, M. M. Who provides phishing training? Facts, stories, and people like me. In Proc. of CHI'18 (2018).
[68] WHITTAKER, C., RYNER, B., AND NAZIF, M. Large-scale automatic classification of phishing pages. In Proc. of NDSS (2010).
[69] WU, M., MILLER, R. C., AND GARFINKEL, S. L. Do security toolbars actually prevent phishing attacks? In Proc. of CHI (2006).
[70] ZHANG, B., WU, M., KANG, H., GO, E., AND SUNDAR, S. S. Effects of security warnings and instant gratification cues on attitudes toward mobile websites. In Proc. of CHI (2014).
[71] ZHANG, Y., EGELMAN, S., CRANOR, L., AND HONG, J. Phinding Phish: Evaluating Anti-Phishing Tools. In Proc. of NDSS (2007).
[72] ZHANG, Y., HONG, J. I., AND CRANOR, L. F. Cantina: A content-based approach to detecting phishing web sites. In Proc. of WWW (2007).

### Appendix A – Spoofing Target Domains

Table 7 lists the 30 domains used in the end-to-end spoofing experiment as the spoofed sender addresses. The domains per category are selected randomly from the Alexa top 5000 domains.

**None: No SPF/DKIM/DMARC (10)**
- thepiratebay.org
- torrent-baza.net
- frdic.com
- chinafloor.cn
- onlinesbi.com
- 4dsply.com
- peliculasflv.tv
- sh.st
- contw.com
- anyanime.com

**Relaxed: SPF/DKIM; DMARC=none (10)**
- tumblr.com
- wikipedia.org
- ebay.com
- microsoftonline.com
- msn.com
- apple.com
- vt.edu
- github.com
- qq.com
- live.com

**Strict: SPF/DKIM; DMARC=reject (10)**
- google.com
- youtube.com
- yahoo.com
- vk.com
- reddit.com
- facebook.com
- twitter.com
- instagram.com
- linkedin.com
- blogspot.com

### Table 7: Spoofed Sender Domain List

### Appendix B – Other Vulnerabilities

We find that two email services, "runbox.com" and "sapo.pt," are not carefully configured, allowing forged emails to bypass the SPF/DKIM checks. However, this gives the attacker a static and reputable IP address. If the attacker aggressively sends malicious emails through the vulnerable mail server, it can damage the reputation of the IP. We have reported the vulnerability to the service administrators.

### Appendix C – Misleading User Interface

Figure 11 shows three examples of misleading UI elements. Figures 11(a) and 11(b) illustrate that when an attacker spoofs a user from the same email provider as the receiver, the email provider automatically loads the profile photo of the spoofed sender from its internal database. In both Google Inbox and Seznam, the forged emails appear to be sent by the user "Forged," and the photo icon gives the forged email a more authentic look. Figure 11(c) demonstrates the misleading UIs when the attacker spoofs an existing contact of the receiver. Despite the sender address (PI:EMAIL) being spoofed, Zoho still loads the contact’s photo from its internal database. Additionally, users can check recent email conversations with this contact by clicking on the highlighted link. These elements make the forged email look authentic.

**(a) Google Inbox profile photo (same-domain spoofing)**
**(b) Seznam profile photo (same-domain spoofing)**
**(c) Zoho profile photo and email history (spoofing a contact)**

### Figure 11: Examples of Misleading UIs (Profile Photo, Email History, Namecard)

An attacker can piggyback on these mail servers to send forged emails. This threat model is different from our experiments above, and we briefly describe it using Figure 1. Here, the attacker is the sender MUA, and the vulnerable server (e.g., runbox.com) is the sender service. Typically, Runbox should only allow its users to send an email with the sender address as "{someone}@runbox.com." However, the Runbox server allows a user (the attacker) to set the "MAIL FROM" freely (without requiring verification) in step ① to send forged emails. This attack does not help the attacker in terms of IP reputation, but it can still be used to bypass certain security measures.