### Atomic Events and Side Effects

To achieve a desired side effect in an exploit, specific conditions must be met by the inputs. These side effects can include writing to memory, writing to a register, writing to a control flag, or branching based on a control flag. For example, an input might need to be a certain value from a specified range, the address used to load an input might need to be within a specific range, or a control flag might need to be set based on a comparison of data from a specific range (e.g., writing to the program counter EIP).

### 5.3.2 Slammer Example

Suppose we aim to exploit the vulnerability used by Slammer to write the value `0` to the virtual address `0x0102aabb` in the SQL server process. This requires that the value `0x0102aabb` be loaded into the EAX register before executing the instruction `MOV [EAX], 0`. To achieve this, we need to send a long UDP packet to port `1434`.

When the Ethernet packet is received, the `IN DX` instructions should read the packet two bytes at a time, ensuring that the packet is stored in a buffer and interpreted correctly by the Windows kernel. Specifically, the 24th byte of the packet must be `0x11` so that when it is loaded into a register and compared to `0x11`, the branch will be taken, and the kernel will interpret it as a UDP packet. Similar requirements for the port number and destination address will ensure that the kernel recognizes the packet for the SQL server process and context-switches into that process, allowing us to read and write the physical memory.

The SQL thread chosen to handle the request will context-switch to the kernel and back twice to obtain the source address and port number information, then read the packet into its own memory space. Each byte must not be `0x00` or `0xFF` to reach the buffer overflow condition. The first data byte of the UDP packet must be `0x04` to reach the vulnerable function through the sequence `MOV EDX, [EBP+fffffbf4]; JMP [42cfa23b+EDX<<2]`. Before the `MOV [EAX], 0` instruction, the EAX register must hold the attacker's desired arbitrary address (`0x0102aabb`), provided by the instruction `MOV EAX, [EBP+10]`, which requires the value `0x0102aabb` to be at `[EBP+10]`. Finally, this will result in the value `0` being written to the virtual address `0x0102aabb` of the SQL server process, which may be necessary for the exploit described in Subsection 4.3.3.

### 5.3.3 Focus on Primitives, Not Vulnerabilities

The goal of a signature generation algorithm based on DACODA should be to identify the most valuable primitive for the attacker in generating new exploits and to generate a signature that prevents that primitive. This can be achieved using heuristics. One such heuristic is that arbitrary write primitives are valuable to attackers, which can be identified by a write requirement where the address used for the write is derived from a specific range. By tracing these requirements, we can work backwards to generate a primitive-specific signature from the partial ordering. Another heuristic is that saved base pointers and return pointers on the stack should not be overwritten by long fields, but this requires knowing the delimiters between fields for the specific protocol, which can be extracted from the partial ordering. Similar heuristics can be developed for other valuable primitives. The key point is that an attacker searching for a zero-day vulnerability is primarily looking for useful primitives to build exploits, rather than just vulnerabilities.

### 6. Future Work

DACODA can be applied to various objectives, including the analysis of known exploits to quantify the polymorphism available to attackers within the exploit vector. It can also be used as a honeypot technology to analyze zero-day worms exploiting unknown vulnerabilities for signature generation, similar to Vigilante [10] and suggested for Polygraph [28] and TaintCheck [29].

Another potential application is to use predicates discovered by DACODA and heuristics about different memory corruption errors to narrow the search space of a random "fuzz tester" [26, 27]. This could help find buffer overflows and other remote vulnerabilities in both user-space and the kernel, similar to recent papers on automatically generating test cases [4, 18], but operating on a full system without source code.

Full system symbolic execution has many security applications, but as noted in Cohen’s seminal paper on computer viruses [9], the general problem of precisely marking information flow within a system is NP-complete [17]. DACODA can analyze the exploit vector part of an attack because the executed code is chosen by the host owner, such as the operating system and installed software. After control flow is hijacked, the computational complexity of information flow tracking becomes more than a theoretical issue, as attackers can use techniques like phi-hiding to obfuscate information flow cryptographically [45].

### 7. Conclusion

This paper presented DACODA and provided a quantitative analysis of the exploit vectors mapped by  for 14 real exploits. Our results and experiences with DACODA offer practical experience and sound theory towards reliable, automatic, host-based worm signature generation. We have shown that single contiguous byte string signatures are not effective for content filtering, and token-based byte string signatures composed of smaller substrings are only semantically rich enough if the vulnerability lies in a less commonly used part of a protocol. Whole-system analysis is critical in understanding exploits. Therefore, the focus of a signature generation algorithm based on DACODA should be on primitives rather than vulnerabilities.

### 8. Acknowledgments

This work was supported by NSF ITR grants CCR-0113418 and ACI-0220147. We are grateful to our shepherd, Dan Boneh, and to Daniela Alvim Seabra de Oliveira, Timothy Sherwood, Helen Wang, and everyone in the U.C. Davis malware reading group and security lab seminar. The anonymous reviewers provided insightful comments. We also thank the Bochs developers.

### 9. References

[1] P. Akritidis, E. P. Markatos, M. Polychronakis, and K. Anagnostakis. Stride: Polymorphic sled detection through instruction sequence analysis. In 20th IFIP International Information Security Conference.
[2] Barnaby Jack. Remote Windows Kernel Exploitation-Step Into the Ring 0.
[3] E. G. Barrantes, D. H. Ackley, T. S. Palmer, D. Stefanovic, and D. D. Zovi. Randomized instruction set emulation to disrupt binary code injection attacks. In Proceedings of the 10th ACM conference on Computer and communication security, pages 281–289. ACM Press, 2003.
[4] C. Cadar and D. Engler. Execution generated test cases: how to make systems code crash itself. In SPIN, 2005.
[5] S. Chen, J. Xu, and E. C. Sezer. Non-control-hijacking attacks are realistic threats. In USENIX Security Symposium 2005, 2005.
[6] R. Chinchani and E. van den Berg. A fast static analysis approach to detect exploit code inside network flows. In RAID, 2005.
[7] K. Fan. Buttercup: On network-based detection of polymorphic buffer overflow vulnerabilities. In 9th IEEE/IFIP Network Operation and Management Symposium (NOMS’2004), 2004.
[8] M. Christodorescu and S. Jha. Static analysis of executables to detect malicious patterns, 2003.
[9] F. Cohen. Computer viruses: theory and experiments. In 7th DoD/NBS Computer Security Conference Proceedings, pages 240–263, September 1984.
[10] M. Costa, J. Crowcroft, M. Castro, and A. Rowstron. Can we contain internet worms? In HotNets III.
[11] M. Costa, J. Crowcroft, M. Castro, A. Rowstron, L. Zhou, L. Zhang, and P. Barham. Vigilante: End-to-end containment of Internet worms. In SOSP ’05: Proceedings of the twentieth ACM Symposium on Operating Systems Principles, New York, NY, USA, 2005. ACM Press.
[12] J. R. Crandall and F. T. Chong. A Security Assessment of the Minos Architecture. In Workshop on Architectural Support for Security and Anti-Virus, Oct. 2004.
[13] J. R. Crandall and F. T. Chong. Minos: Control data attack prevention orthogonal to memory model. In Proceedings of the 37th International Symposium on Microarchitecture (MICRO), December 2004.
[14] J. R. Crandall, S. F. Wu, and F. T. Chong. Experiences using Minos as a tool for capturing and analyzing novel worms for unknown vulnerabilities. In Proceedings of GI SIG SIDAR Conference on Detection of Intrusions and Malware and Vulnerability Assessment (DIMVA), 2005.
[15] H. Dreger, C. Kreibich, V. Paxson, and R. Sommer. Enhancing the accuracy of network-based intrusion detection with host-based context. In Proceedings of GI SIG SIDAR Conference on Detection of Intrusions and Malware and Vulnerability Assessment (DIMVA), 2005.
[16] G. W. Dunlap, S. T. King, S. Cinar, M. A. Basrai, and P. M. Chen. Revirt: enabling intrusion analysis through virtual-machine logging and replay. SIGOPS Oper. Syst. Rev., 36(SI):211–224, 2002.
[17] J. Fenton. Information protection systems. In Ph.D. Thesis, University of Cambridge, 1973.
[18] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed Automated Random Testing. In PLDI, 2005.
[19] S.-S. Hong, F. Wong, S. F. Wu, B. Lilja, T. Y. Jansson, H. Johnson, and A. Nelsson. TCPtransform: Property-oriented TCP traffic transformation. In Proceedings of GI SIG SIDAR Conference on Detection of Intrusions and Malware and Vulnerability Assessment (DIMVA), 2005.
[20] S.-S. Hong and S. F. Wu. On interactive Internet traffic replay. In RAID, 2005.
[21] H.-A. Kim and B. Karp. Autograph: Toward automated, distributed worm signature detection. In USENIX Security Symposium, pages 271–286, 2004.
[22] J. C. King. Symbolic execution and program testing. Commun. ACM, 19(7):385–394, 1976.
[23] O. Kolesnikov and W. Lee. Advanced polymorphic worms: Evading IDS by blending in with normal traffic.
[24] C. Kreibich and J. Crowcroft. Honeycomb: creating intrusion detection signatures using honeypots. SIGCOMM Comput. Commun. Rev., 34(1):51–56, 2004.
[25] C. Krügel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna. Polymorphic worm detection using structural information of executables. In RAID, 2005.
[26] B. Miller, D. Koski, C. P. Lee, V. Maganty, R. Murthy, A. Natarajan, and J. Steidl. Fuzz revisited: A re-examination of the reliability of UNIX utilities and services. Technical report, 1995.
[27] B. P. Miller, L. Fredriksen, and B. So. An empirical study of the reliability of UNIX utilities. Communications of the Association for Computing Machinery, 33(12):32–44, 1990.
[28] J. Newsome, B. Karp, and D. Song. Polygraph: Automatically generating signatures for polymorphic worms. In Proceedings of the IEEE Symposium on Security and Privacy, May, 2005.
[29] J. Newsome and D. Song. Dynamic taint analysis for automatic detection, analysis, and signature generation of exploits on commodity software. In Proceedings of the 12th Annual Network and Distributed System Security Symposium (NDSS 05), Feb. 2005.
[30] A. Pasupulati, J. Coit, K. Levitt, S. Wu, S. Li, R. Kuo, and others.
[31] U. Payer, P. Teufl, and M. Lamberger. Hybrid engine for polymorphic shellcode detection. In Proceedings of GI SIG SIDAR Conference on Detection of Intrusions and Malware and Vulnerability Assessment (DIMVA), 2005.
[32] T. H. Ptacek and T. N. Newsham. Insertion, evasion, and denial of service: Eluding network intrusion detection. Technical report, Secure Networks, Inc., Suite 330, 1201 5th Street S.W, Calgary, Alberta, Canada, T2R-0Y6, 1998.
[33] C. Raiu. Holding the Bady. In Virus Bulletin, 2001.
[34] S. Rubin, S. Jha, and B. P. Miller. Automatic generation and analysis of NIDS attacks. In 20th Annual Computer Security Applications Conference (ACSAC).
[35] S. Rubin, S. Jha, and B. P. Miller. Language-based generation and evaluation of NIDS signatures. In IEEE Symposium on Security and Privacy, Oakland, California, May, 2005.
[36] M. E. Russinovich and D. A. Solomon. Microsoft Windows Internals, Fourth Edition. 2004.
[37] S. Singh, C. Estan, G. Varghese, and S. Savage. Automated worm fingerprinting. In OSDI, 2004.
[38] P. Szor. The Art of Computer Virus Research and Defense. 2005.
[39] S. J. Templeton and K. Levitt. A requires/provides model for computer attacks. In NSPW ’00: Proceedings of the 2000 workshop on New security paradigms, pages 31–38, New York, NY, USA, 2000. ACM Press.
[40] T. Toth and C. Krügel. Accurate buffer overflow detection via abstract payload execution. In RAID, pages 274–291, 2002.
[41] N. Vachharajani, M. J. Bridges, J. Chang, R. Rangan, G. Ottoni, J. A. Blome, G. A. Reis, M. Vachharajani, and D. I. August. Rifle: An architectural framework for user-centric information-flow security. In Proceedings of the 37th International Symposium on Microarchitecture (MICRO), December 2004.
[42] G. Vigna, W. Robertson, and D. Balzarotti. Testing Network-based Intrusion Detection Signatures Using Mutant Exploits. In Proceedings of the ACM Conference on Computer and Communication Security (ACM CCS), pages 21–30, Washington, DC, October 2004.
[43] H. J. Wang, C. Guo, D. R. Simon, and A. Zugenmaier. Shield: vulnerability-driven network filters for preventing known vulnerability exploits. In SIGCOMM ’04: Proceedings of the 2004 conference on Applications, technologies, architectures, and protocols for computer communications, pages 193–204. ACM Press, 2004.
[44] V. Yegneswaran, J. T. Giffin, P. Barford, and S. Jha. An architecture for generating semantics-aware signatures. In USENIX Security Symposium, 2005.
[45] A. Young and M. Yung. Malicious Cryptography: Exposing Cryptovirology. 2004.
[46] bochs: the Open Source IA-32 Emulation Project (Home Page), http://bochs.sourceforge.net.
[47] eEye advisory for the DCOM RPC Race Condition (http://www.eeye.com/html/research/advisories/AD20040413B.html).
[48] eEye advisory for the LSASS buffer overflow (http://www.eeye.com/html/research/advisories/AD20040413C.html).
[49] General William T. Sherman, as quoted in B. H. Liddell Hart, Strategy, second revised edition.
[50] Microsoft advisory MSXX-YYY (http://www.microsoft.com/technet/security/bulletin/MSXX-YYY.mspx).
[51] QEMU (Home Page), http://fabrice.bellard.free.fr/qemu/.
[52] Security Focus Vulnerability Notes, (http://www.securityfocus.com), bid == Bugtraq ID.
[53] SNORT: The open source network intrusion detection system (http://www.snort.org). 2002.