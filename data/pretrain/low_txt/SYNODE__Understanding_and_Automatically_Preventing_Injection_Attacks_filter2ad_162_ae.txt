### Complexity and Limitations of Static Analysis

No static analysis can guarantee the detection of all sink calls due to the inherent complexity. Synode is designed to target code that is inadvertently vulnerable, rather than code that is maliciously crafted. Therefore, we consider the problem of hidden sink calls to be negligible in practice. Additionally, while Synode prevents the addition of new commands to the templates, it does not defend against data-only attacks. For example, simply ensuring that the input is a literal may be insufficient:

```javascript
exec("rm " + userInput);
```

### Computational Cost

Our static analysis identifies a total of 1,560 templates for the injection APIs in the considered modules. For each template, we construct a PAST (Partial Abstract Syntax Tree) with a median computation time of 2 milliseconds per module. However, for some modules, this number is significantly higher due to our simple PAST construction algorithm and the high number of templates per module.

The last column of Figure 14 shows the average runtime overhead per call of an injection API imposed by the runtime mechanism (in milliseconds). We report absolute times because the absolute overhead is more meaningful than normalizing it by an arbitrary workload. Our enforcement mechanism costs 0.74 milliseconds per call, on average over 100 runs of the modules using all inputs. This result demonstrates that the overhead of enforcement is generally negligible in practice.

### Scalability of Runtime Enforcement

To demonstrate the scalability of our runtime enforcement, we consider input data of different sizes and complexities and pass it to the injection APIs. Specifically, we focus on `eval` call sites from Figure 14. As inputs, we use a diverse sample of 200 JavaScript programs taken from a corpus of real-world code. For every call to `eval`, we pass all 200 JavaScript programs 100 times each and measure the variance in enforcement times. Figure 13c shows the enforcement time, in milliseconds, depending on the size of the JavaScript program, measured as the number of AST nodes. For each input size, the figure shows the 25th percentile, the median value, and the 75th percentile. We find that the enforcement time scales linearly. The reason is that all steps of the runtime enforcement—parsing the input, matching the AST with the PASTs, and checking whether nodes are on a whitelist—are of linear complexity.

### Related Work

#### Analysis of Node.js Code

Injections into Node.js code are known to be exploitable [43], and there is a community-driven effort [14] to identify such problems. Ojamaa and Dünna [28] identify denial of service as one of the main threats for the Node.js platform and also mention `eval` as a security risk. We extend these observations by presenting an in-depth study of injection vulnerabilities on Node.js and introducing a technique to prevent injections.

NodeSentry [7] is a security architecture for least-privilege integration of Node.js modules. Using their terminology, Synode’s runtime enforcement is a lower-bound policy check on `exec` and `eval`. Our mechanism is more powerful as it uses static analysis to perform fine-grained policy enforcement. Madsen et al. [22] enhance the call graph construction for Node.js applications with event-based dependencies. Our static analysis is intra-procedural but could benefit from integrating an inter-procedural approach, which may further reduce the false positive rate.

Staicu and Pradel show that many real-world websites suffer from ReDoS vulnerabilities [38], a form of algorithmic complexity attack that may cause websites to be unreachable. Their work underlines the importance of fixing vulnerabilities in popular Node.js modules but addresses a different kind of vulnerability than this paper.

#### Program Analysis for JavaScript

Studies of client-side JavaScript [49, 32] show that `eval` is prevalent but often unnecessary. We extend these findings to server-side JavaScript, add a new category of `eval` uses, and categorize uses of `exec`, an API not studied by existing work. Other studies focus on inclusions of third-party libraries [27], the `postMessage` API [36], injection attacks on JavaScript-based mobile applications [15], and the use of outdated libraries [17]. In contrast, we study Node.js code and address vulnerabilities specific to this platform.

Blueprint [44] prevents XSS attacks by enforcing that the client-side DOM resembles a parse tree learned at the server-side. Their work shares the idea of comparing data prone to injections to a tree-based template. Our work differs by learning templates statically and focusing on command injections in Node.js code. Stock et al. [40] study DOM-based XSS injections and propose dynamic taint tracking to prevent them. Similar to Synode, their prevention policy is grammar-based. However, their strict policy to reject any tainted data that influences JavaScript code except for literals and JSON would break many uses of `eval` found during our study. Another difference is that we avoid taint tracking by statically computing sink-specific templates.

Defenses against XSS attacks [37, 25] use signature-based whitelisting to reject scripts not originating from the website creator. SICILIAN [37] uses an AST-based signature; nsign [25] creates signatures from script-dependent elements and context-based information. Both rely on a training phase to discover valid signatures. Our work also uses templates as a whitelisting mechanism. However, we do not rely on testing to collect these templates but compute them statically. As we show in our evaluation, there may be hundreds or even thousands of paths that reach an injection API call site, making constructing valid signatures for every path infeasible.

CSPAutoGen [29] presents an automatic way to generate CSP policies on the server-side to protect against illegitimate script execution on the client-side. It uses gASTs, partial ASTs similar in structure to ours, but different in many ways. First, gASTs are created during a training session, limiting the approach to behavior observed during the training phase. gASTs also differ from our partial ASTs in how they are enforced: gASTs are synthesized into a JavaScript function that replaces the actual call to the sink. Such a step cannot be easily implemented for sinks other than `eval` since these sinks call outside the JavaScript world. For example, to refactor a call to `exec` that uses the `awk` system utility on Linux, we would need to completely rewrite `awk` in JavaScript.

DLint [10] is a dynamic checker for violations of code quality rules, including uses of `eval` missed by static analysis. Dynamic [12] and hybrid (static and dynamic) [6] information flow analyses for JavaScript track how values at some program location influence values at another program location. The FLAX system [34] and a system proposed by Lekies et al. [18] use dynamic taint analysis to detect vulnerabilities caused by missing input validation and then generate inputs that exploit these vulnerabilities. Jin et al. [15] use a static taint analysis to detect code injection vulnerabilities. In contrast to these approaches, we do not require an information flow (or taint) analysis, performing lightweight runtime checks at possible injection locations without tracking the values that flow to these locations.

Several approaches rewrite JavaScript code to enforce security policies. Yu et al. [48] propose a rewriting technique based on edit automata that replaces or modifies particular calls. Gatekeeper [11] is a static analysis for a JavaScript subset that enforces security and reliability policies. Instead of conservatively preventing all possibly insecure behavior, our approach defers checks to runtime when hitting limitations of purely static analysis. Other techniques [14, 24] replace `eval` calls with simpler, faster, and safer alternatives. Their main goal is to enable more precise static analysis; our focus is on preventing injections at runtime.

#### Program Analysis for Other Languages

CSAS [33] uses a type system to insert runtime checks that prevent injections into template-based code generators. Livshits et al. [20] propose to automatically place sanitizers into .NET server applications. Similar to our work, these approaches first statically address some code locations and use runtime mechanisms only for the remaining ones. CSAS differs from our work by checking code generators instead of final code. The approach in [20] addresses the problem of placing generic sanitizers, whereas we insert runtime checks specific to injection call sites.

There are several purely dynamic approaches to prevent injections. XSS-Guard [4] modifies server applications to compute a shadow response along each actual response and compares both responses to detect unexpected, injected content. Instead of comparing two strings with each other, our runtime mechanism compares runtime strings against statically extracted templates. ScriptGard [35] learns during a training phase which sanitizers to use for particular program paths and detects incorrect sanitization by comparing executions against the behavior seen during training. Their approach is limited by the executions observed during training and needs to check all execution paths, whereas Synode statically identifies some locations as safe.

Su and Wassermann [42] formalize the problem of command injection attacks and propose grammar-based runtime prevention. Their work shares the idea of rejecting runtime values based on a grammar that defines which parts of a string may be influenced by attacker-controlled values. Their analysis tracks input data with special marker characters, which may get lost on string operations, such as `substring`, leading to missed injections. Instead, our analysis does not need to track input values through the program. Buehrer et al. [5] take a similar approach to mitigate SQL injections. They construct two parse trees at runtime, one representing the developers' intentions only and one including the user input. They use these trees to ensure that the user input contains only literals. Their approach is purely dynamic and employs markers for tracking user input, similar to Su and Wassermann [42]. Ray and Ligatti [30] propose a novel formulation of command injections that requires dynamic taint tracking and a set of trusted inputs. For Node.js libraries, example inputs are rarely available.

Constraint-based static string analysis, e.g., Z3-str [50], is a more heavyweight alternative to our static analysis. Even though such techniques have the potential of producing more precise templates, we opted for efficiency, enabling us to apply the analysis easily to thousands of npm modules. Wassermann et al. address the problem of finding inputs that trigger SQL injections [46] and XSS vulnerabilities [45] in PHP code. Ardilla [16] finds and exploits injection vulnerabilities in PHP through a combination of taint analysis and test generation. Instead of triggering attacks, our work addresses the problem of preventing attacks. Similar to our preliminary study of dependencies on injection APIs, a recent work analyzes the usage of the unsafe API in Java [23]. Existing analyses for Java [31] and Android applications [3, 19] focus on security risks due to libraries, which shares with Synode the idea to consider third-party code as a potential security threat.

### Conclusions

This paper studies injection vulnerabilities in Node.js and shows that the problem is widespread and not yet adequately addressed. We present Synode, an automated technique for mitigating injection vulnerabilities in Node.js applications. At the same time, the approach effectively prevents a range of attacks while causing very few false positives and imposing sub-millisecond overheads. To aid with its adoption, our technique requires virtually no involvement on the part of the developer. Instead, Synode can be deployed automatically as part of module installation.

In a broader scope, this work highlights the urgent need for security tools targeted at Node.js. The technique presented in this paper is an important first step toward securing the increasingly important class of Node.js applications, and we hope it will inspire future work in this space.

### Acknowledgements

This work was supported by the German Federal Ministry of Education and Research and by the Hessian Ministry of Science and the Arts within CRISP, by the German Research Foundation within the Emmy Noether project “ConcSys”, and by the Royal Society Wolfson Merit Award.

### References

[1] A. V. Aho, R. Sethi, and J. D. Ullman. Compilers. Principles, Techniques and Tools. Addison Wesley, 1986.
[2] E. Andreasen, L. Gong, A. Møller, M. Pradel, M. Selakovic, K. Sen, and C.-A. Staicu. A survey of dynamic analysis and test generation for JavaScript. ACM Computing Surveys, 2017.
[3] M. Backes, S. Bugiel, and E. Derr. Reliable third-party library detection in Android and its security applications. In CCS, pages 356–367, 2016.
[4] P. Bisht and V. N. Venkatakrishnan. XSS-GUARD: precise dynamic prevention of cross-site scripting attacks. In DIMVA, pages 23–43, 2008.
[5] G. Buehrer, B. W. Weide, and P. A. G. Sivilotti. Using parse tree validation to prevent SQL injection attacks. In Workshop on Software Eng. and Middleware, pages 106–113, 2005.
[6] R. Chugh, J. A. Meister, R. Jhala, and S. Lerner. Staged information flow for JavaScript. In PLDI, pages 50–62. ACM, 2009.
[7] W. De Groef, F. Massacci, and F. Piessens. NodeSentry: least-privilege library integration for server-side JavaScript. In ACSAC, pages 446–455, 2014.
[8] A. Doupé, B. Boe, C. Kruegel, and G. Vigna. Fear the EAR: discovering and mitigating execution after redirect vulnerabilities. In CCS, pages 251–262, 2011.
[29] X. Pan, Y. Cao, S. Liu, Y. Zhou, Y. Chen, and T. Zhou. CSPAutoGen: Black-box enforcement of content security policy upon real-world websites. In CCS, pages 653–665, 2016.
[30] D. Ray and J. Ligatti. Defining code-injection attacks. In POPL, pages 179–190, 2012.
[31] M. Reif, M. Eichberg, B. Hermann, J. Lerch, and M. Mezini. Call graph construction for Java libraries. In FSE, pages 474–486, 2016.
[32] G. Richards, C. Hammer, B. Burg, and J. Vitek. The eval that men do - A large-scale study of the use of eval in JavaScript applications. In ECOOP, pages 52–78, 2011.
[33] M. Samuel, P. Saxena, and D. Song. Context-sensitive auto-sanitization in web templating languages using type qualifiers. In CCS, pages 587–600, 2011.
[34] P. Saxena, S. Hanna, P. Poosankam, and D. Song. FLAX: Systematic discovery of client-side validation vulnerabilities in rich web applications. In NDSS, 2010.
[35] P. Saxena, D. Molnar, and B. Livshits. SCRIPTGARD: automatic context-sensitive sanitization for large-scale legacy web applications. In CCS, pages 601–614, 2011.
[36] S. Son and V. Shmatikov. The postman always rings twice: Attacking and defending postMessage in HTML5 websites. In NDSS, 2013.
[37] P. Soni, E. Budianto, and P. Saxena. The SICILIAN defense: Signature-based whitelisting of web JavaScript. In CCS, pages 1542–1557, 2015.
[38] C.-A. Staicu and M. Pradel. Freezing the web: A study of ReDoS vulnerabilities in JavaScript-based web servers. Technical Report TUD-CS-2017-0305, TU Darmstadt, 2017.
[39] C.-A. Staicu, M. Pradel, and B. Livshits. Understanding and automatically preventing injection attacks on Node.js. Technical Report TUD-CS-2016-14663, TU Darmstadt, Department of Computer Science, 2016.
[40] B. Stock, S. Lekies, T. Mueller, P. Spiegel, and M. Johns. Precise client-side protection against DOM-based cross-site scripting. In USENIX Security, pages 655–670, 2014.
[41] B. Stock, G. Pellegrino, C. Rossow, M. Johns, and M. Backes. Hey, you have a problem: On the feasibility of large-scale web vulnerability notification. In USENIX Security, pages 1015–1032, 2016.
[42] Z. Su and G. Wassermann. The essence of command injection attacks in web applications. In POPL, pages 372–382, 2006.
[43] B. Sullivan. Server-side JavaScript injection. Black Hat USA, 2011.
[44] M. Ter Louw and V. N. Venkatakrishnan. Blueprint: Robust prevention of cross-site scripting attacks for existing browsers. In Sec. and Privacy, pages 331–346, 2009.
[45] G. Wassermann and Z. Su. Static detection of cross-site scripting vulnerabilities. In ICSE, pages 171–180, 2008.
[46] G. Wassermann, D. Yu, A. Chander, D. Dhurjati, H. Inamura, and Z. Su. Dynamic test input generation for web applications. In ISSTA, pages 249–260, 2008.
[47] S. Wei. Practical analysis of the dynamic characteristics of JavaScript, 2015.
[48] D. Yu, A. Chander, N. Islam, and I. Serikov. JavaScript instrumentation for browser security. In POPL, pages 237–249, 2007.
[49] C. Yue and H. Wang. Characterizing insecure JavaScript practices on the web. In WWW, pages 961–970, 2009.
[50] Y. Zheng, X. Zhang, and V. Ganesh. Z3-str: a Z3-based string solver for web application analysis. In ESEC/FSE, pages 114–124, 2013.
[9] Z. Durumeric, J. Kasten, D. Adrian, J. A. Halderman, M. Bailey, F. Li, N. Weaver, J. Amann, J. Beekman, M. Payer, and V. Paxson. The matter of heartbleed. In IMC, pages 475–488, 2014.
[10] L. Gong, M. Pradel, M. Sridharan, and K. Sen. DLint: Dynamically checking bad coding practices in JavaScript. In ISSTA, pages 94–105, 2015.
[11] S. Guarnieri and B. Livshits. GATEKEEPER: mostly static enforcement of security and reliability policies for JavaScript code. In USENIX Security, pages 151–168, 2009.
[12] D. Hedin, A. Birgisson, L. Bello, and A. Sabelfeld. JSFlow: tracking information flow in JavaScript and its APIs. In SAC, pages 1663–1671, 2014.
[13] P. Hooimeijer, B. Livshits, D. Molnar, P. Saxena, and M. Veanes. Fast and precise sanitizer analysis with BEK. In USENIX Security, pages 1–16, Aug. 2011.
[14] S. H. Jensen, P. A. Jonsson, and A. Møller. Remedying the eval that men do. In ISSTA, pages 34–44, 2012.
[15] X. Jin, X. Hu, K. Ying, W. Du, H. Yin, and G. N. Peri. Code injection attacks on HTML5-based mobile apps: Characterization, detection and mitigation. In Conference on Computer and Communications Security, pages 66–77, 2014.
[16] A. Kiezun, P. J. Guo, K. Jayaraman, and M. D. Ernst. Automatic creation of SQL injection and cross-site scripting attacks. In ICSE, pages 199–209, 2009.
[17] T. Lauinger, A. Chaabane, S. Arshad, W. Robertson, C. Wilson, and E. Kirda. Thou shalt not depend on me: Analysing the use of outdated JavaScript libraries on the web. 2017.
[18] S. Lekies, B. Stock, and M. Johns. 25 million flows later: large-scale detection of DOM-based XSS. In CCS, pages 1193–1204, 2013.
[19] M. Li, W. Wang, P. Wang, S. Wang, D. Wu, J. Liu, R. Xue, and W. Huo. Libd: Scalable and precise third-party library detection in Android markets. In ICSE, 2017.
[20] B. Livshits and S. Chong. Towards fully automatic placement of security sanitizers and declassifiers. In POPL, pages 385–398, 2013.
[21] B. Livshits, M. Sridharan, Y. Smaragdakis, O. Lhoták, J. N. Amaral, B. E. Chang, S. Z. Guyer, U. P. Khedker, A. Møller, and D. Vardoulakis. In defense of soundiness: a manifesto. Commun. ACM, 58(2):44–46, 2015.
[22] M. Madsen, F. Tip, and O. Lhoták. Static analysis of event-driven Node.js JavaScript applications. In OOPSLA, pages 505–519, 2015.
[23] L. Mastrangelo, L. Ponzanelli, A. Mocci, M. Lanza, M. Hauswirth, and N. Nystrom. Use at your own risk: the Java unsafe API in the wild. In OOPSLA, pages 695–710, 2015.
[24] F. Meawad, G. Richards, F. Morandat, and J. Vitek. Eval begone!: semi-automated removal of eval from JavaScript programs. In OOPSLA, pages 607–620, 2012.
[25] D. Mitropoulos, K. Stroggylos, D. Spinellis, and A. D. Keromytis. How to train your browser: Preventing XSS attacks using contextual script fingerprints. Trans. Priv. and Sec., 19(1):2, 2016.
[26] F. Nielson, H. R. Nielson, and C. Hankin. Principles of Program Analysis. Springer, second edition, 2005.
[27] N. Nikiforakis, L. Invernizzi, A. Kapravelos, S. Van Acker, W. Joosen, C. Kruegel, F. Piessens, and G. Vigna. You are what you include: large-scale evaluation of remote JavaScript inclusions. In ACM Conference on Computer and Communications Security, pages 736–747, 2012.
[28] A. Ojamaa and K. Dünna. Assessing the security of Node.js platform. In Intl. Conf. f. Internet Techn. and Secured Transactions, pages 348–355, 2012.