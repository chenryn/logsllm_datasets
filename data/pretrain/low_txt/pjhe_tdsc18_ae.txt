# Optimized Text

## Observations and Findings

### POP and Ground Truth Comparison
- **POP**: 
  - Accuracy: 0.99
  - Total Logs: 10,998
  - True Anomalies Detected: 10,720 (63%)
  - False Alarms: 278 (2.5%)
  - Parameters: `splitRel` to 0.1, `splitAbs` to 10, `maxDistance` to 0

- **Ground Truth**:
  - Accuracy: 1.00
  - Total Logs: 11,473
  - True Anomalies Detected: 11,195 (66%)
  - False Alarms: 278 (2.4%)
  - Parameters: `splitRel` to 0.1, `splitAbs` to 10, `maxDistance` to 0

We observe that the accuracy of POP peaks for all datasets when we set the parameters as follows: `splitRel` to 0.1, `splitAbs` to 10, and `maxDistance` to 0. 

### Anomaly Detection
- **Detected Anomalies**: Number of true anomalies detected by PCA.
- **False Alarms**: Number of wrongly detected anomalies.
- **Ground Truth**: An anomaly detection task with exactly correct parsed results.

From Table 6, we observe that LogSig and IPLoM lead to nearly optimal results on the anomaly detection task. However, SLCT does not perform well in anomaly detection despite its acceptable parsing accuracy (0.83). It reports 7,515 false alarms, which introduces extensive human effort for inspection. The parsing accuracy of SLCT (0.83) and LogSig (0.87) is comparable, but the performance of anomaly detection using LogSig as a parser is one order of magnitude better than that using SLCT. Anomaly detection using LogSig only reports 413 false alarms. These findings reveal that anomaly detection results are sensitive to critical events generated by log parsers. 

### Parameter Sensitivity
- **GS (Group Size)**:
  - Smaller GS: Easier for a log group to be sent to step 4 without further partitioning, potentially lowering accuracy.
  - Larger GS: Higher probability of a log group going through the partitioning process in step 3, which may also lower accuracy.
  - For HPC and HDFS, accuracy is lower in the ranges [0, 0.3] and [0, 0.2] respectively for smaller GS, and [0.8, 1.0] for larger GS.
  - For BGL, Zookeeper, and Proxifier, POPâ€™s accuracy is consistently high (larger than 0.9) under all GS values.

- **splitRel and splitAbs**:
  - POP is not sensitive to these parameters in our experiments.

- **maxDistance**:
  - Setting too large a value can cause an accuracy drop.
  - To find a suitable value, set the parameter to a reasonable value based on its physical meaning, then tune it on a small sample dataset by evaluating the resulting accuracy.

## Importance of Log Parsing
- **Log Mining Effectiveness**:
  - Log mining is effective only when the parsing result is accurate enough.
  - Log mining is sensitive to some critical events. Even 4% errors in parsing can cause a one-order-of-magnitude performance degradation in anomaly detection.

- **Parameter Tuning**:
  - The parameters of POP in this experiment are the same as those tuned for 2k HDFS datasets.
  - We observe that the accurate parsed results of POP are effective for the anomaly detection task.
  - Although there are still 37% non-detected anomalies, this is likely due to the limitations of the PCA-based anomaly detection model. The ground truth input provides comparable performance, with 34% non-detected anomalies.

- **Parser Performance**:
  - **LKE**: Quadratic time complexity.
  - **LogSig**: Accurate on most datasets but computationally intensive.
  - **IPLoM**: Accurate and efficient on small datasets.
  - **SLCT**: Requires the least running time but has low parsing accuracy, leading to a 40% false alarm rate in anomaly detection.

## Limitations and Future Work
- **Dataset Diversity**:
  - Not all datasets used in our evaluation are production data, limiting the representativeness of our results.
  - Zookeeper and HDFS are widely adopted systems, and their logs reflect industrial logs to some extent.
  - We mitigate this issue by generating many sample datasets with different properties.

- **Log Mining Tasks**:
  - Results are evaluated on anomaly detection, which may not generalize to other log mining tasks.
  - We will consider extending our methodology to more log parsing data and different log mining tasks in future work.

- **Log Management**:
  - With the prevalence of distributed systems and cloud computing, log management is challenging due to security requirements and the volume of log data.
  - Tools like Splunk, Logstash, and Kibana provide solutions for log analysis but require user-defined matching patterns.
  - Our proposed automated log parsing method can accurately and efficiently parse production-level log data.

- **Log Event Changes**:
  - Logs change over time, and a log message may not match the current list of log events.
  - Developers can use POP to periodically retrain on new training data to update the list.
  - In runtime, if a log message is not matched, it is marked as "other events" and recorded for retraining.

- **Empirical Study**:
  - Empirical studies provide useful insights and suggestions for both academic researchers and industrial practitioners.
  - Our work extends previous research on log parsing and its subsequent use in log mining.

## Conclusion
This paper targets automated log parsing for large-scale log analysis in modern systems. We conduct a comprehensive study of four representative log parsing methods, characterizing their accuracy, efficiency, and effectiveness on subsequent log mining tasks. Based on our findings, we propose a parallel log parsing method, POP, which employs specially designed heuristic rules and hierarchical clustering. Extensive experiments on synthetic and real-world datasets reveal that POP can perform accurately and efficiently on large-scale log data. POP and the four studied log parsers have been publicly released to facilitate future research.

## Acknowledgments
This work was supported by the National Natural Science Foundation of China, the Research Grants Council of the Hong Kong Special Administrative Region, and the 2015 Microsoft Research Asia Collaborative Research Program.