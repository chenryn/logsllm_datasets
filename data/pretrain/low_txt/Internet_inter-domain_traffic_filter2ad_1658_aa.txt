# Internet Inter-Domain Traffic

**Authors:**
- Craig Labovitz, Arbor Networks, Ann Arbor, MI, labovit@arbor.net
- Scott Iekel-Johnson, Arbor Networks, Ann Arbor, MI, scottij@arbor.net
- Danny McPherson, Arbor Networks, Ann Arbor, MI, danny@arbor.net
- Jon Oberheide, University of Michigan, Ann Arbor, MI, jonojono@umich.edu
- Farnam Jahanian, University of Michigan, Ann Arbor, MI, farnam@umich.edu

## Abstract
In this paper, we examine changes in Internet inter-domain traffic demands and interconnection policies. We analyze over 200 exabytes of commercial Internet traffic over a two-year period, using data from 110 large and geographically diverse cable operators, international transit backbones, regional networks, and content providers. Our analysis reveals significant changes in inter-AS traffic patterns and an evolution in provider peering strategies. Specifically, the majority of inter-domain traffic now flows directly between large content providers, data centers/CDNs, and consumer networks. We also observe a global decline in P2P traffic and a significant rise in video traffic. The paper concludes with estimates of the current size of the Internet by inter-domain traffic volume and the annualized rate of inter-domain traffic growth.

## 1. Introduction
The rapid evolution of the Internet is a well-known phenomenon. Fifteen years ago, new applications like the web drove widespread consumer interest and adoption. Ten years ago, advancements in backbone and subscriber access technologies (e.g., DSL/Cable broadband) significantly increased end-user connection speeds. More recently, applications such as social networking and video (e.g., Facebook and YouTube) have reshaped consumer Internet usage.

However, beyond these technological and protocol evolutions, the last five years have seen a significant shift in Internet inter-domain traffic demands and peering policies. For most of the past fifteen years, ten to twelve large transit providers comprised the Internet "core," interconnecting thousands of tier-2, regional providers, consumer networks, and content/hosting companies. Textbook diagrams and research based on active probing and BGP routing table analysis typically depict a strict hierarchy of global transit providers at the core, interconnecting smaller tier-2 and regional/tier-3 providers (Figure 1a).

Recent economic forces, including the decline in IP wholesale transit prices and the growth of ad-supported content, have altered the interconnection strategies of many providers. In the new Internet economy, content providers are building their own global backbones, cable ISPs are offering wholesale national transit, and transit ISPs are providing CDN and cloud/content hosting services. For example, Google has migrated the majority of its video and search traffic (which constitutes more than 5% of all inter-domain traffic) away from transit providers to its own fiber backbone and direct interconnects with consumer networks.

These substantial changes in provider inter-connection strategies have significant implications for backbone engineering, design of Internet-scale applications, and research. However, most providers treat their Internet traffic statistics with great secrecy, making it difficult to document these shifts in the commercial and research literature. Most Internet traffic research has focused on secondary indicators such as BGP route advertisements, DNS probing, industry surveys, private CDN statistics, or traffic measured on individual provider or enterprise networks.

In this paper, we provide one of the first large-scale longitudinal studies of Internet inter-domain traffic using direct instrumentation of peering routers across multiple providers. We address significant experimental data collection and commercial privacy challenges to instrument 3,095 peering routers across 18 global carriers, 38 regional/tier-2, and 42 consumer and content providers in the Americas, Asia, and Europe. At its peak, the study monitored more than 12 terabits per second of offered load and a total of more than 200 exabytes of Internet traffic over the two-year period (July 2007 to July 2009). Based on independent estimates, we believe the probes directly monitor more than 25% of all Internet inter-domain traffic.

Our major findings include:
- **Evolution of the Internet “Core”:** Over the last two years, the majority of Internet inter-domain traffic growth has occurred outside the traditional ten to twelve global transit carriers. Today, most inter-domain traffic flows directly between large content providers, hosting/CDNs, and consumer networks.
- **Consolidation of Content:** Most content by inter-domain traffic volume has migrated to a relatively small number of large hosting, cloud, and content providers. Out of approximately thirty-thousand ASNs, 30 ASNs contribute an average of 30% of all Internet inter-domain traffic in July 2009.
- **Estimation of Google’s Traffic Contribution:** Google represents both the largest and fastest-growing contributor of inter-domain traffic, accounting for more than 5% of all inter-domain traffic in July 2009. Google's share of inter-domain traffic grew by more than 4% between July 2007 and July 2009.
- **Consolidation of Application Transport:** The majority of inter-domain traffic has shifted to a small number of protocols and TCP/UDP ports, including video over HTTP and Adobe Flash. Other mechanisms like P2P have declined significantly in the last two years.
- **Estimation of Internet Size:** Using data from independent known inter-domain provider traffic volumes, we estimate that inter-domain traffic peaks exceed 39 Tbps and grew at an annualized average of 44.5% between July 2007 and July 2009.

The rest of this report is organized as follows: §2 provides an overview of our data collection infrastructure and analysis methodology. §3 discusses significant changes in Internet topology and commercial interconnection relationships between providers. §4 analyzes changes in Internet protocols and applications. Finally, we conclude with validation of our data and estimates of both the volume of all inter-domain traffic and the annualized rate of growth.

## 2. Methodology
Our analysis is based on traffic statistics exported by operational routers from a large and representative sample of Internet providers. We leveraged a widely deployed commercial security and traffic monitoring platform to instrument the BGP peering edge routers of 110 participating Internet providers. Based on private commercial sales data, we believe the majority of the probe deployments cover the provider’s BGP peering edge. However, we lack specific visibility into the network probe coverage of any individual anonymous study participant.

The instrumented routers export traffic flow samples (e.g., NetFlow, cFlowd, IPFIX, or sFlow) and participate in routing protocol exchange (i.e., iBGP) with one or more probe devices. A smaller number of providers have deployed inline or "port span" versions of the appliances to monitor traffic payloads and enact security policies. Per our anonymity agreement with participating providers, we did not collect more specific details on deployment configuration (e.g., flow sample rates, router model number, etc.).

While sampled flow introduces potential data artifacts, particularly around short-lived flows, we believe the accuracy of flow is sufficient for the granularity of our inter-domain traffic analysis. Further, flow provides the only scalable and cost-effective monitoring approach given the scale of our study.

Each probe independently calculates traffic statistics based on user-configured information and BGP-learned topology. Calculated statistics include breakdowns of traffic per BGP autonomous system (AS), ASPath, network and transport layer protocols, ports, nexthops, and countries. A more detailed description of the probe capabilities is available in commercial datasheets and white papers [26].

The probe configuration includes user-supplied classification of the probe’s primary geographic coverage area (e.g., North America, Europe) and market segment (e.g., tier-1, tier-2, content, consumer, or educational). We use the provider-supplied self-categorizations in our aggregate data analysis discussed in later sections.

We worked extensively with the provider community to address commercial privacy concerns. Every participating probe strips all provider-identifying information from the calculated statistics before forwarding an encrypted and authenticated snapshot of the data to central servers. We also agreed not to publish any per-provider traffic rates or customer data derived from ASPath traffic analysis.

To mitigate possible sources of error, we excluded three ISPs (out of 113) from the dataset that exhibited signs of obvious misconfiguration via manual inspection (e.g., wild daily fluctuations, unrealistic traffic statistics, internally inconsistent data, etc.). Unfortunately, our measurement infrastructure suffered from real-world operational exigencies. Throughout the study, providers expanded deployments with new probes, decommissioned older appliances, and modified the configuration of their probes and backbone infrastructure. As a result, the absolute traffic volumes reported by probes exhibited occasional discontinuities.

The probe data exhibited less variance with respect to traffic ratios (e.g., the ratio of ASN, port, protocol, etc., to all inter-domain traffic in each deployment). Ratios such as TCP port 80 or Google ASN origin traffic remained relatively consistent even as the number of monitored routers, probe appliances, and absolute volume of reported traffic fluctuated in a deployment. Given the relative consistency of ratios and our inability to distinguish changes in absolute traffic volumes from artifacts due to provider measurement infrastructure changes, most of the analysis in this paper focuses on traffic percentages rather than absolute traffic values. This focus on ratios also simplifies our aggregate analysis across a large set of heterogeneous providers.

Throughout every 24-hour period, the probes independently calculated the average traffic volume every five minutes for all members of all datasets (e.g., traffic contributed by every nexthop, AS Path, ASN, etc.) and the average volume of total inter-domain network traffic. The probes then calculated a 24-hour average for each of these items using the five-minute averages. Finally, the probes used the daily traffic volume per item and network total to calculate a daily percentage for each item.

Table 1 provides a market segment breakdown of anonymous provider participants by percentage of all deployments in our study. The second table shows a breakdown of percentage of deployments by geographic region. Regional and tier-2 providers comprise the largest component at 34% of anonymous statistics, followed by unclassified and tier-1 at 16% each.

We note that the relative high cost of the commercial probes used in our study may introduce a selection bias towards larger providers. Both analyst data and our study participant set reflect a continued weighting towards North America and Europe in traffic volume and number of providers.

While our study included a large and diverse set of Internet providers, evaluating sample bias is challenging given the anonymity of the study participants and the lack of "ground-truth" quantitative market data. We evaluated several mechanisms for weighting the traffic ratio samples from the 110 deployments to reduce selection bias. Ultimately, we found a weighted average based on the number of routers in each deployment provided the best results during data validation in §5 and represents a compromise between the relative size of an ISP while not obscuring data from smaller networks.

Specifically, for each day \(d\), we calculate the weighted average percent share of Internet traffic \(P_d(A)\) for a specific traffic attribute \(A\), where \(A\) is an ASN, TCP port, country of origin, etc. The weights are calculated based on the total number of routers reporting traffic on that day at each of the \(N\) study participants reporting data for that day. Thus, on day \(d\) for participant \(i\) with router count \(R_{d,i}\), we calculate the weight:

\[ W_{d,i} = \frac{R_{d,i}}{\sum_{x=1}^{N} R_{d,x}} \]

We then calculate day \(d\)'s weighted average percent share \(P_d(A)\) based on each provider’s measured average traffic volume for \(A\) on day \(d\), \(M_{d,i}(A)\), and total average inter-domain traffic for day \(d\), \(T_{d,i}\):

\[ P_d(A) = \sum_{x=1}^{N} W_{d,x} \times \frac{M_{d,x}(A)}{T_{d,x}} \times 100 \]

We excluded any provider more than 1.5 standard deviations from the true mean to focus on values less likely to have measurement errors due to transient provider issues (misconfiguration, network problems, or probe failures). With the exception of Comcast’s peering ratios discussed in §3, we used the sum of traffic both in and out of the provider networks for \(M_{d,i}(A)\) and \(T_{d,i}\).

In some cases, our analysis may underestimate categories of inter-domain traffic. Specifically, the probes lack visibility into traffic exchanged over direct peering adjacencies between enterprise business partners or between smaller tier-2 and tier-3 Internet edge providers. Similarly, the study may underestimate inter-domain traffic associated with large content providers such as Google, who are increasingly pursuing edge peering strategies. We emphasize that our study is limited to inter-domain traffic and excludes all internal provider traffic, such as intra-domain cache traffic, VPNs, IPTV, and VoIP services.

Finally, we validated our findings with private discussions with more than twenty large content providers, transit ISPs, and regional networks. These discussions provided "ground-truth" and additional context to better understand the market forces underlying our observed inter-domain traffic trends. We note that our derived data matched provider expectations both in relative ordering and magnitude of ASN traffic volumes. Additionally, twelve providers supplied independent inter-domain traffic measurements for validation of our analysis. We use these twelve known provider traffic values in §5 to add confidence to our calculated inter-domain ASN traffic distributions and to estimate the overall volume of global inter-domain traffic.

## 3. ASN Traffic Analysis
In this section, we present a coarse-grained analysis of changes in inter-domain traffic patterns. We begin with a look at the ten largest contributors (based on our analysis) of inter-domain traffic in the months of July 2007 and July 2009. With the exception of content providers (e.g., Google, Microsoft) and Comcast, we anonymize provider names to avoid potential commercial impact.

### 3.1 Provider Inter-domain Traffic Share
We calculate the ten largest contributors of inter-domain traffic in the first two charts of Table 2 using the weighted average percentage of inter-domain traffic (i.e., \(P(A)\)) reported by each Internet provider in our study either originating or transiting each ASN \(A\). We then aggregate all ASNs managed by the same Internet commercial entity (e.g., Verizon’s AS701, AS702, etc.). This step is required since many large transit providers manage dozens of ASNs reflecting geographic backbone segmentation and merger or acquisition lineage. Finally, we exclude stub ASNs from the aggregation step, which we only observed downstream from other corporate ASNs (e.g., DoubleClick (AS 6432) traffic transits Google (AS 15169) in all our observed ASPaths).

As a category, the ten largest providers by inter-domain traffic volume in Table 2a account for 28.8% of all inter-domain traffic. ISP A represents the largest provider traffic share in 2007 with an average of 5.77% of all inter-domain traffic, followed by ISP B (4.55%) and ISP C (3.35%).

[Figures and Tables will be included here as per the original document.]

---

This optimized version of the text aims to improve clarity, coherence, and professionalism while maintaining the original content and structure.