### Shared Pitfalls and Oracle Vulnerabilities

A common vulnerability in various onion routing systems lies in the oracles. In HORNET's analysis, this attack was not considered because the oracles were not taken into account. Similarly, TARANET's proof also ignores the oracles, but its transmission phase inadvertently provides some protection against such attacks.

Sphinx, the improved Minx, and an extension in [8] restrict the oracle in Step 7 to allow only non-duplicate onions, i.e., those with a changed header. This restriction weakens the security properties, as the limited oracle loses protection against modification attacks, where the onion is altered before it reaches the honest node.

**Note:**
- Technically, controlling the link from the sender to the first relay is sufficient for an attack.
- However, whether the adversary controls these links is not explicitly stated in [11].
- Although this attack works for TARANET, it falls outside its attacker model, as the receiver needs to be compromised.
- We emphasize that this model was never intended by Sphinx, but other works have used Sphinx in this manner.

### Impact on Security Properties

Our property LU (and even the insecure original Onion-Security) cannot be fulfilled if the previously mentioned attack (Section V-A) is successful. The adversary can alter the payload of the challenge onion and query the oracle with the modified onion. Since processing at the honest node does not abort for modified onions, the adversary learns the next relay after the honest node. This allows the adversary to determine whether the next relay corresponds to their choice (b = 0) or not (b = 1).

It is important to note that this is not the only attack that prevents HORNET from achieving LU. Another attack exploits the use of sessions (discussed further in Section VII-C2).

### Proving the Adapted Sphinx Secure

Sphinx specifies the use of a header and a payload. The original Sphinx [13] suggests per-hop integrity protection only for the header, as an integrity check for the payload conflicts with support for replies. Consequently, Sphinx allows linking the sender and exit node, which is not possible in the ideal functionality. Therefore, even with the flaw from Section IV-A fixed, Sphinx cannot realize the ideal functionality.

Beato et al. proposed an adaptation to Sphinx to simplify the protocol and improve security and performance, at the cost of losing support for replies [5]. This adaptation introduces integrity checks for the payload at each hop, thereby preventing the linking attack. We analyzed this version of Sphinx, adapted with the small fix to the attack from Section IV-A, for compliance with our properties for secure OR protocols. Note that this variation covers only the forward phase and no replies.

The proof for Onion-Correctness follows the ideas in [13]. To analyze LU and T I, we successively define games with marginally weaker adversary models. By arguing how each step follows from reasonable assumptions, we ultimately reduce it to the security of an authenticated encryption scheme and the DDH assumption. The detailed proof is provided in Appendix C, leading to the following theorem:

**Theorem 3:** Beato’s Sphinx variation, adapted with the fix to the attack from Section IV-A, is a secure OR scheme.

This implies that it realizes the ideal functionality, achieving confidentiality (M O) for honest senders with honest receivers, and sender (SM L) and relationship anonymity (SRL) for honest senders with corrupted receivers. This holds under a restricted adversary model that does not allow timing attacks or attacks that lead to the dropping of onions, conforming to the adversary model of the original Sphinx, which is used in the adapted version as well.

### Discussion

#### Onion-Security Properties vs. Existing OR Attacks

Our new properties prevent well-known attacks on OR if they comply with the adversary model of the ideal functionality. For example:
- Passive linking attacks based on the length of the onion layer or the included message are prevented.
- Our properties imply non-deterministic encryption in FormOnion, as the adversary could otherwise use FormOnion on chosen parameters and compare the results.

In tagging attacks, the attacker modifies an onion and recognizes it later based on the modification. To be useful, the tagging must preserve some information of the original communication, such as part of the path or the message. This translates to an attack on LU using an oracle to learn the output of a tagged challenge onion after processing at an honest relay, and deciding if it relates to the chosen input (b = 0) or not.

Duplicate attacks assume an adversary can create an onion that matches an intercepted onion in parts of the input, such as the message, but is not bit-identical. Such onions appear different at the relays and may not be detected by duplicate protection, jeopardizing anonymity. Our properties protect against duplicate attacks, as an adversary able to create a duplicate onion breaks LU by learning the message or path contained in the challenge onion using the oracle.

Replay attacks (duplicate attacks with bit-identical onions) are possible in the ideal functionality and thus not necessarily prevented. The n-1 Attack, where all but one onion is known to the adversary, is also possible in the ideal functionality and not mitigated by the properties.

#### Adapting Our Properties

There are cases where our properties need adaptation:
- **Correctness:** Due to practical reasons, space-efficient data structures like Bloom filters are frequently used for duplicate detection. Bloom filters exhibit false-positive detections but no false-negatives. This can be covered by extending our Onion-Correctness to δ-Onion-Correctness, accepting a correctness failure at a probability of at most δ.
- **Security properties and Cascades:** When analyzing OR with fixed cascades, some adaptations are necessary. Senders can only choose a cascade instead of a path, resulting in a different path choice in the adversary class and a slightly different anonymity set. In the game, the path of the replacement onion must match the cascade of the challenge onion (assured in Step 5 of both LU and T I).

#### Limitations

**Adversary Model and Anonymity Set:**
- We fully assumed the adversary model of Camenisch and Lysyanskaya, which does not allow traffic analysis, delaying, or dropping by the adversary. Although this model is not very realistic, the analysis is useful for splitting the proof. Upon showing the protocol’s privacy for the restricted adversary model of the ideal functionality, only the privacy for the remaining attacks needs to be shown.
- We restrict the paths in the adversary class to include at least one honest relay, meaning the anonymity set consists only of users whose onions share an honest relay and are processed together.

**Reply Channels and Sessions:**
- All systems that proved privacy with the properties consider a reply channel, but none analyzes the backward phase separately. They only show indistinguishability to the forward onions, implying the same security properties for the reply channel. However, our analysis shows that privacy goals, except confidentiality (M O), are only guaranteed for an honest sender. In the reply phase, the sender is the original receiver, which cannot be considered honest. Thus, proving the properties does not guarantee the anonymity of the initial sender for a corrupted receiver in the reply phase.
- HORNET and TARANET introduce sessions, reusing the same path and header to efficiently send multiple onions. The ideal functionality does not cover sessions. For a corrupted relay, it is always possible to link onions of the same session, making it impossible to show the properties or the ideal functionality in this case.

**Mix Networks:**
- Mix networks include reordering of onions to conceal timing information and prevent linking outgoing to incoming onions based on their order and timing. The ideal functionality and our properties do not consider timing attacks. While none of the widely deployed anonymization systems considers this, a real anonymous communication network should prevent linking based on timings. From our perspective, this is an extension, as all presented properties need to be met by mix networks to prevent linking based on the onions and their processing at honest nodes.

**Extended Version:**
- Our extended version of this paper [24] contains technical details excluded due to space limitations, including the technical proofs of the notions the ideal functionality does and does not achieve, a scheme and corresponding proofs illustrating the second insecurity (Section IV-D1) of the properties from [8], and the proof that Wrap-Resistance and Onion-Integrity of [8] do not need to be proven for privacy reasons.

### Conclusion and Future Work

Camenisch and Lysyanskaya made a seminal attempt to formally analyze the predominant anonymization approach of OR in [8]. They designed an ideal functionality for OR in the UC model and suggested properties to analyze protocols and real-world systems. A whole family of subsequent OR schemes based their security analyses on this work.

Analyzing approaches from this family, we discovered a new, severe vulnerability and explained one that was known. We presented a new attack to completely break sender and relationship anonymity in HORNET. Additionally, as known and corrected in the implementation, in Sphinx, the anonymity set can be reduced by discovering the used path length.

As these attacks contradict the proofs in the respective papers, we formally analyzed the used proof strategy proposed in [8]. First, we confirmed that the foundation of the proof, the ideal functionality, indeed guarantees privacy. Second, we explained the reason for the attack on Sphinx: the properties as originally suggested by Camenisch and Lysyanskaya are insufficient. To resolve this, we fixed one property, developed two new properties, and proved that achieving these three properties implies the privacy of the ideal functionality: sender anonymity and relationship anonymity against corrupted receivers in an adversary model that limits onion dropping and timing-based attacks.

Third, we explained the reason for the attack on HORNET: the original Onion-Security property would have prevented it, but was proven incorrectly. By proving a variation of Sphinx secure, we demonstrated how systems can be analyzed using our new properties.

We wish to point out that several published systems consider reply channels and sessions, which are not covered by the ideal functionality of [8]. Therefore, much remains to be done: while we repaired the anonymization for the simple delivery of a message from a sender to a receiver, modeling reply channels and sessions is left for future work. Further, analyses and proofs for the security and privacy of other onion routing protocols beyond the variation of Sphinx need to be conducted, using our or adapted properties.

### Acknowledgment

We thank our shepherd Ian Goldberg and the anonymous reviewers for their valuable feedback. This work was partially funded by DFG EXC 2050/1 – ID 390696704.

### References

[1] E. D. Ayele. Analysis and deployment of the BitTorrent protocol for Community Ad-hoc Networks. Technical report, TU Delft, 2011.
[2] M. Backes, A. Kate, P. Manoharan, S. Meiser, and E. Mohammadi. Anoa: A framework for analyzing anonymous communication protocols. Journal of Privacy and Confidentiality, 2017.
[3] M. Backes, P. Manoharan, and E. Mohammadi. Tuc: Time-sensitive and modular analysis of anonymous communication. In IEEE CSF, 2014.
[4] E. Balkovich, D. Prosnitz, A. Boustead, and S. C. Isley. Electronic Surveillance of Mobile Devices. Rand Corporation, 2015.
[5] F. Beato, K. Halunen, and B. Mennink. Improving the sphinx mix network. In Cryptology and Network Security, 2016.
[6] R. Berman, A. Fiat, M. Gomulkiewicz, M. Klonowski, M. Kutylowski, T. Levinboim, and A. Ta-Shma. Provable unlinkability against traffic analysis with low message overhead. Journal of Cryptology, 2015.
[7] J.-M. Bohli and A. Pashalidis. Relations among privacy notions. ACM TISSEC, 2011.
[8] J. Camenisch and A. Lysyanskaya. A formal treatment of onion routing. In Annual International Cryptology Conference, 2005.
[9] R. Canetti. Universally composable security: A new paradigm for cryptographic protocols. In IEEE FOCS, 2001.
[10] D. L. Chaum. Untraceable electronic mail, return addresses, and digital pseudonyms. Communications of the ACM, 1981.
[11] C. Chen, D. E. Asoni, D. Barrera, G. Danezis, and A. Perrig. HORNET: High-speed onion routing at the network layer. In ACM CCS, 2015.
[12] C. Chen, D. E. Asoni, A. Perrig, D. Barrera, G. Danezis, and C. Troncoso. TARANET: Traffic-Analysis Resistant Anonymity at the NETwork layer. IEEE EuroS&P, 2018.
[13] G. Danezis and I. Goldberg. Sphinx: A compact and provably secure packet format. In WPES, 2004.
[14] G. Danezis and B. Laurie. Minx: A simple and efficient anonymous mix format. In IEEE S&P, 2009.
[15] J. P. Degabriele and M. Stam. Untagging Tor: a formal treatment of onion encryption. In Theory and Applications of Cryptographic Techniques, 2018.
[16] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-generation onion router. Technical report, Naval Research Lab Washington DC, 2004.
[17] J. Feigenbaum, A. Johnson, and P. Syverson. A model of onion routing with provable anonymity. In Financial Cryptography and Data Security, 2007.
[18] J. Feigenbaum, A. Johnson, and P. Syverson. Anonymity analysis of onion routing in the universally composable framework. In 2012 Workshop on Provable Privacy, 2012.
[19] A. Fujioka, Y. Okamoto, and T. Saito. Security of sequential multiple encryption. In International Conference on Cryptology and Information Security in Latin America, 2010.
[20] N. Gelernter and A. Herzberg. On the limits of provable anonymity. In ACM WPES, 2013.
[21] D. M. Goldschlag, M. G. Reed, and P. F. Syverson. Hiding routing information. In International workshop on information hiding, 1996.
[22] A. Hevia and D. Micciancio. An indistinguishability-based characterization of anonymous channels. Lecture Notes in Computer Science, 2008.
[23] C. Kuhn, M. Beck, S. Schiffner, E. Jorswieck, and T. Strufe. On privacy notions in anonymous communication. PoPETs, 2019.
[24] C. Kuhn, M. Beck, and T. Strufe. Breaking and (Partially) Fixing Provably Secure Onion Routing. arXiv e-prints, page arXiv:1910.13772, 2019.
[25] S. Mauw, J. H. Verschuren, and E. P. de Vink. A formalization of anonymity and onion routing. In European Symposium on Research in Computer Security, 2004.
[26] K. Peng. A general and efficient countermeasure to relation attacks in mix-based e-voting. Int. J. Inf. Secur., 10(1), Feb. 2011.
[27] D. J. Pohly and P. McDaniel. Modeling Privacy and Tradeoffs in Multichannel Secret Sharing Protocols. In IEEE/IFIP DSN, 2016.