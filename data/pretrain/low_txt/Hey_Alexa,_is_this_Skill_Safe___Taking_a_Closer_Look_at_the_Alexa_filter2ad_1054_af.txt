### Server Errors and Unregistered Domains

Some skills (30 such skills) point to homepages of websites that are sometimes entirely unrelated to the skill. We also analyzed whether the privacy policies address the permissions requested. To do this, we contacted the authors of PoliCheck [18] and obtained the source code of their tool to measure flow-to-policy consistency.

### Flow-to-Policy Consistency Analysis

PoliCheck was designed to analyze data flows. Therefore, we converted the eight permissions that grant access to privacy-sensitive data into a set of first-party data flows based on a manually constructed mapping, as shown in Table V. For example, the Postal Code permission gives the skill access to the country, zip code, and state. Using PoliCheck's notation, we converted the Postal Code permission request into the following three data flows: (we, country), (we, zip code), and (we, state).

Since we are applying PoliCheck to a new domain, we manually adapted their data type ontology (shown in Figure 9 in Appendix D) to include the data types covered by the Alexa permissions. Additionally, we made trivial modifications to their code to identify references to first-party entities within privacy policies by adding terms that refer to Alexa skills (e.g., "skills") and extending the synonym list for a set of entities.

### Classification of Consistency

PoliCheck classifies flow-to-policy consistency into two types of consistencies (clear, vague) and three types of inconsistencies (ambiguous, incorrect, omitted). In our case, we aim to measure whether the privacy policies disclose the permissions requested (permission-to-policy consistency). After analysis with PoliCheck, we re-mapped the data flows and flow-to-policy consistency results back to the skill’s permission requests. This process may result in multiple consistency types being mapped back to the permission, so we abstracted PoliCheck’s classification at a higher level to either consistent or inconsistent for each data flow.

We introduced the concept of partial consistency, which represents cases where the privacy policy only discloses a subset of the data types granted by a permission request. For example, if a skill requests the Postal Code permission but only discloses the collection of the user’s country within the privacy policy, the Postal Code permission would be partially consistent with the policy, as it did not also disclose the collection of zip code and state. Pseudo code for the permission-to-policy consistency algorithm is provided in Appendix C.

### Initial Dataset and Exclusions

Our initial dataset consists of 1,146 skills that request one or more of the eight permissions that grant access to privacy-sensitive data. We excluded 22 skills from the dataset whose privacy policy link does not directly display a privacy policy. We deploy the modified version of PoliCheck on these 1,124 skills with 1,447 permission requests, which produce 4,384 first-party data flows for analysis.

### Manual Validation

We manually validated the consistency results from PoliCheck for the 4,384 data flows using the validation methodology documented in PoliCheck [18]. After manual validation, we found that PoliCheck correctly classified the data flows as either consistent or inconsistent with the privacy policy with an 83.3% precision. Most errors arose from the NER (Named-entity recognition) model not tagging entities (e.g., skill names) or missing sentence patterns for sentence classification, which can be addressed in future work with further domain adaptation. Note that we corrected the misclassified flows during validation, so all reported results are validated and correctly classified.

### Results of Permission-to-Policy Consistency Analysis

Figure 8 shows the validated results of our permission-to-policy consistency analysis. Only 76.7% (862/1,124) of the privacy policies completely addressed all of their requested permissions. Note that 100 skills produced 404 errors when fetching the policy. We still included these in our analysis, as the lack of an available policy is equivalent to no disclosures at all.

Surprisingly, 33.1% (41/124) of skills requesting the Full Name permission did not disclose the collection of such data in their privacy policy, which requires disclosure according to various regulations (e.g., CCPA [48], GDPR [2]). Several of these skills (B07MKPRVPB, B07RWWHK7W, B07MQKDKMZ, B07MFQH176) requesting the Full Name permission have privacy policies that explicitly state that they do not collect information from the user. For a set of 16 skills requesting the Postal Code and Device Address permissions (e.g., B072KL1S3G, B074PZQTXG, B07GKZ43J5), we found similarly potentially deceptive statements within the privacy policy ("We never collect or share personal data with our skills"). These cases may denote a misunderstanding by the developer on the purpose of providing a privacy policy and what they are required to disclose when accessing PII.

### Partially Consistent Skills

Two skills that requested the Device Address permission were marked as partially consistent (B076ZWH8ZL, B07VWR9YX8). However, their privacy policies only discuss requiring the state and country of the device, which may denote either that their privacy policies are incomplete or these skills are over-privileged and should request the more coarse-grained Postal Code permission.

### Finding 9: Privacy Policy Disclosure

Around 23.3% of the privacy policies are not fully disclosing the data types associated with permissions requested by the skill. Many skills (33.1%) accessing the Full Name permission did not disclose the collection of such data in their privacy policy.

### Privacy Policy Templates

We found that two widely-used privacy policy templates were resulting in 74 permission-to-policy inconsistencies across 46 skills. The BBB-Template, previously provided by the Better Business Bureau as a sample privacy policy template for websites, was used by 35 skills with 62 permission requests, such as Device Address (17 skills), Email Address (17 skills), and Full Name (15 skills). All 62 permission requests were marked as inconsistent. While the BBB-Template discusses the collection and sharing of data, it does not disclose the types or categories of data collected. For example, the BBB-Template includes overly broad statements, such as, "We are the sole owners of the information collected on this site. We only have access to/collect information that you voluntarily give us via email or other direct contact from you. We will not sell or rent this information to anyone." Privacy policies that solely discuss broad collection of "information" likely do not comply with the specificity requirement of disclosures defined by new regulations (e.g., CCPA [48], GDPR [2]).

The FPP-Template, a checkbox-based privacy policy generator provided by freeprivacypolicy.com, allows for a configurable specification of the data collection practices. However, it was also a source of inconsistencies due to skills omitting data collection practices. This omittance of information can likely be attributed to developers not selecting all of the required checkboxes to cover their skill’s behaviors or potential lack of expressibility by the generator. In total, we found 22 skills that used the FPP-Template requesting 31 permissions. In total, 12 permissions were marked as inconsistent across 11 skills that used the FPP-Template, such as Device Address (5 skills), Postal Code (5 skills), and Phone Number (1 skill).

### Finding 10: Regulatory Non-Compliance

Privacy policy templates result in potential regulatory non-compliance in 46 skills. The fact that developers are relying on these templates and they are resulting in permission-to-policy inconsistencies highlights an inherent flaw with the current publishing model of app markets. While developers are provided rich APIs to develop their skills and obtain easy access to PII of end users, there does not appear to be any guidance to developers to create proper privacy policies. In turn, this negatively impacts the transparency of privacy risks placed on end users of these skills. Prior work [17] demonstrates that privacy policy templates are negatively impacting the transparency of privacy practices in the Android ecosystem, and we demonstrate that this problem is also reflected in the Amazon Alexa skill ecosystem and is likely to be a problem in all application markets that similarly have a low barrier to entry.

### Discussion

#### Summary

We perform a comprehensive broad analysis of the Alexa skill ecosystem. This work advances the state-of-the-art by providing the following insights: (1) we highlight several gaps in the skill vetting process that can be exploited by an adversary; (2) we showcase that while common skill squatting techniques exist (we also found one new technique which we termed word-spacing) and are effective, there is no systematic abuse in the wild; (3) we show that 23.3% of the skills requesting permission to access sensitive user data do not fully disclose the data types associated with the permissions in their privacy policies. We open-source our data to the research community to encourage further analysis in this domain [4].

#### Recommendations

Our analysis shows that while Amazon restricts access to user data for skills and has put forth a number of rules, there is still room for malicious actors to exploit or circumvent some of these rules. Auto-enabling skills reduces the distinction between native and third-party skills; however, users are still in the dark regarding which skill is responding to their queries. This can enable an attacker to exploit the trust they have built with the system. Based on our analyses, we propose the following suggestions:

- **Skill-Type Indicator**: Skill names and invocation phrases are not required to be unique. Since Amazon introduced the auto-enable feature, users are less likely to know about the skills they are interacting with and how their data is being used. Alexa could provide some form of visual or verbal indicator (e.g., light or a different voice template) when interacting with a third-party application. Further HCI research is required to evaluate how voice assistants can ensure users are aware of what skills are being enabled.
- **Validating Developers**: It is possible to register accounts with any developer name, even those of well-known companies. This can mislead users and even be misused to launch phishing attacks. Amazon could utilize developer information to validate or flag trademark infringements. Also, like the Google Play store, Amazon can display developer details like contact email address or website for higher transparency.
- **(Recurring) Backend Validation**: Currently, there is no provision to verify if the backend code has changed. A developer can push any code update once a skill has been approved without any further verification. While we do not expect Amazon to fully solve this problem as backend code may go through multiple rounds of updates, the threat needs to be acknowledged and understood. Potentially random recurring backend checks can be performed by Amazon.
- **Privacy Policy Template**: Developers only need to provide a (working) policy link to get certified and start collecting user data. There is no check as to whether the policy link conveys all (or any) of the necessary information that a user might be interested in learning [22]. This issue can be addressed by asking developers to fill out a simple policy template that will include what data is collected, for what purpose, for how long the data is retained, and whether users can delete or modify their data. Also, a valid contact address should be provided. Most of these requirements align with the minimum requirements imposed on companies/developers by GDPR and CCPA.

#### Limitations and Future Work

Our analysis has a few limitations. First, while our collection of skill data is the largest to the best of our knowledge, it is possible that we might have missed many skills. However, given that we have collected over 90,194 unique skills, which exceeds the 80,000 reported by Amazon in 2019 [24], we do not foresee any significant difference in our reported numbers. Second, we provide a conservative lower-bound approximation to demonstrate the existence of skills bypassing the permission APIs, a more comprehensive estimate could be possible by utilizing more sophisticated NLP techniques. We plan to explore this in the near future. Lastly, in determining the effectiveness of different skill-squatting techniques, we tested a relatively small number of random skills. A fully automated approach would enable us to scale our test significantly. However, developing such a fully automated approach is a challenging problem.

### Conclusion

In this paper, we analyze skills, which are third-party applications built on top of Alexa. While skills expand Alexa’s capabilities and functionalities, they also create new security and privacy risks. Our study covers skill stores from seven different countries with the goal to thoroughly analyze the overall vetting process enforced by Amazon. We identify several gaps in the current ecosystem that can be exploited by an adversary to launch further attacks, including registration of arbitrary developer names, bypassing of permission APIs, and making backend code changes after approval to trigger dormant intents. We also identify common skill squatting techniques, including one new technique. Moreover, we find that while certain skill-squatting techniques are more favorable, there is no systematic abuse of skill squatting in the wild. Lastly, we show that many skills requesting permissions do not properly address the use of such permission-protected data in their privacy policies. Based on our findings, we make several recommendations to strengthen the overall skill ecosystem.

### Acknowledgement

We thank our anonymous reviewers for their feedback. This material is based upon work supported in parts by the National Science Foundation under grant number CNS-1849997 and by the state of North Rhine-Westphalia. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or the state of North Rhine-Westphalia.

### References

[1] “COPPA: Children’s Online Privacy Protection Rule,” 2019. [Online]. Available: http://uscode.house.gov/view.xhtml?req=granuleid%3AUSC-prelim-title15-section6501&edition=prelim

[2] “EU’s General Data Protection Regulation,” 2019. [Online]. Available: https://eugdpr.org/

[3] “Invoked apps,” 2019. [Online]. Available: https://invokedapps.com/

[4] “A privacy & security analysis of the Alexa skill ecosystem,” 2020. [Online]. Available: https://www.alexa-skill-analysis.org/

[5] H. Abdullah, W. Garcia, C. Peeters, P. Traynor, K. R. B. Butler, and J. Wilson, “Practical hidden voice attacks against speech and speaker recognition systems,” in Proceedings of the 26th Annual Network and Distributed System Security Symposium (NDSS), 2019.

[6] P. Agten, W. Joosen, F. Piessensand, and N. Nikiforakis, “Adversarial attacks against automatic speech recognition systems via psychoacoustic hiding,” in Proceedings of the 22nd Annual Network and Distributed System Security Symposium (NDSS), 2015.

[7] A. Alexa, “Choose the invocation name for a custom skill,” 2019. [Online]. Available: https://developer.amazon.com/docs/custom-skills/choose-the-invocation-name-for-a-custom-skill.html

[8] A. Alhadlaq, J. Tang, M. Almaymoni, and A. Korolova, “Privacy in the Amazon Alexa Skills Ecosystem,” in 10th Workshop on Hot Topics in Privacy Enhancing Technologies (HotPETs), 2017. [Online]. Available: https://petsymposium.org/2017/papers/hotpets/amazon-alexa-skills-ecosystem-privacy.pdf

[9] “Alexa developer console,” Amazon, 2019. [Online]. Available: https://developer.amazon.com/alexa/console/ask

[10] “Alexa voice service,” Amazon, 2019. [Online]. Available: https://developer.amazon.com/alexa-voice-service

[11] “All Alexa,” Amazon, 2019. [Online]. Available: https://www.amazon.com/Amazon-Echo-And-Alexa-Devices/b?ie=UTF8&node=9818047011

[12] “Understand...” [Online]. Available: [URL]