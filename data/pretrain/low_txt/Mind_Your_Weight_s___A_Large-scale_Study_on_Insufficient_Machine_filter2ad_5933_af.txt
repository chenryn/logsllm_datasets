### Program Slicing on Smali Code and Related Techniques

Program slicing on Smali code [43] has been a focus of several research efforts. DroidTrace [63] introduces a dynamic analysis method based on `ptrace` with forward execution capabilities. This tool monitors selected system calls of the target process and classifies behaviors through sequences of system calls. Rasthofer et al. [51] combine program slicing and dynamic execution to extract values from obfuscated samples, including reflected function calls, sensitive values in native code, dynamically loaded code, and other anti-analysis techniques. Similar works include DeGuard [39] and TIRO [60].

To extract cryptographic keys from TLS connections, DroidKex [54] applies fast extraction of ephemeral data from the memory of a running process, followed by partial reconstruction of the semantics of data structures. ARTIST [42] provides an Android Runtime Instrumentation Toolkit, which monitors the execution of Java and native code. It parses OAT executable files in memory to identify classes and methods of interest, and locates internal structures of the Android Runtime. AndroidSlicer [37] uses asynchronous slicing for data modeling and control dependencies in callbacks, enabling it to locate instructions responsible for model loading/unloading and track relevant parts based on app inputs. CredMiner [64] investigates unsafe uses of developer credentials, leveraging data flow analysis to identify embedded credentials.

Our work also combines static and dynamic analysis on Android apps, but with a different goal: machine learning model extraction.

### Machine Learning Model Extraction

Prior work on machine learning (ML) model extraction primarily focuses on learning-based techniques targeting ML-as-a-service. Tramer et al. [57] propose stealing ML models via prediction APIs, as ML-as-a-service may accept partial feature vectors as inputs and include confidence values with predictions. Wang et al. [59] extend these attacks by stealing hyperparameters. Other related work includes stealing model functionality [45, 50], querying gradients to reconstruct models [49], exploratory attacks to reverse-engineer classifiers [52], and side-channel attacks to recover models [38]. Our work is orthogonal to these studies, focusing on on-device model inference, assuming attackers have physical access to mobile devices running model inference.

Model extraction facilitates adversarial machine learning. Prior work [44, 47] on fooling models or bypassing checks is often under the black-box threat model. When ML models become white-box, attackers can easily craft adversarial examples to deceive the learning systems. Our study highlights that white-box adversarial machine learning is a real threat to on-device ML models.

### Protecting Machine Learning Models

To protect ML models as intellectual property, watermarking techniques have been used to detect illegitimate model uses [36, 62]. Additionally, fingerprinting has been employed to ensure model integrity. Chen et al. [40] encode fingerprints in DNN weights to attest that the models have not been tampered with or modified. Our research supports this finding, indicating that model plagiarism is a significant problem, especially on mobile platforms.

### Conclusion

We conducted a large-scale security analysis of ML model protection in 46,753 Android apps from both Chinese and US app markets. Our analysis shows that on-device ML is gaining popularity across all categories of mobile apps, but 41% of them do not protect their models. Among those that do, many suffer from weak protection mechanisms, such as using the same encrypted model for multiple apps, and even encrypted models can be easily recovered with unsophisticated analysis. Our impact analysis reveals that model leakage can financially benefit attackers, potentially resulting in millions of dollars in gains, and allow them to evade model-based authentication and access user private information. Attackers are both technically capable and financially motivated to steal models. We call for further research into robust model protection.

### Acknowledgment

The authors would like to thank Prof. Konrad Rieck and the anonymous reviewers for their insightful comments. This project was supported by the National Science Foundation (Grant#: CNS-1748334) and the Army Research Office (Grant#: W911NF-18-1-0093). The opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding agencies.

### References

[1] A brief guide to mobile AI chips. https://www.theverge.com/2017/10/19/16502538/mobile-ai-chips-apple-google-huawei-qualcomm.
[2] Amazon SageMaker Ground Truth pricing. https://aws.amazon.com/sagemaker/groundtruth/pricing/.
[3] Amazon SageMaker Pricing. https://aws.amazon.com/sagemaker/pricing/.
[4] Android ml. https://developer.android.com/ml.
[5] Apache MXNet | A flexible and efficient library for deep learning. https://mxnet.apache.org/.
[6] Apple core ml. https://developer.apple.com/documentation/coreml/core_ml_api/personalizing_a_model_with_on-device_updates.
[7] Artificial Intelligence + GANs can create fake celebrity faces. https://medium.com/datadriveninvestor/artificial-intelligence-gans-can-create-fake-celebrity-faces-44fe80d419f7.
[8] Caffe2 - a lightweight, modular, and scalable deep learning framework. https://github.com/facebookarchive/caffe2.
[9] Converting model to C++ code. https://mace.readthedocs.io/en/latest/user_guide/advanced_usage.html.
[10] Core ML | Apple Developer Documentation. https://developer.apple.com/documentation/coreml.
[11] Dynamic instrumentation toolkit for developers, reverse-engineers, and security researchers. https://frida.re/.
[12] Entropy (information theory). https://en.wikipedia.org/wiki/Entropy_(information_theory)#Entropy_as_information_content.
[13] Face++ - Cognitive Services. https://www.faceplusplus.com/.
[14] Face++ pricing details - mobile SDK. https://www.faceplusplus.com/pricing-details/#offline.
[15] Intel R Software Guard Extensions. https://software.intel.com/en-us/sgx.
[16] MegaFace and MF2: Million-Scale Face Recognition. http://megaface.cs.washington.edu/.
[17] Megvii’s Competitors, Revenue, Number of Employees, Funding, and Acquisitions. https://www.owler.com/company/megvii.
[18] Netron. https://lutzroeder.github.io/netron/.
[19] Online Protobuf Decoder. https://protogen.marcgravell.com/decode.
[20] Over 1.5 TB’s of Labeled Audio Datasets. https://towardsdatascience.com/a-data-lakes-worth-of-audio-datasets-b45b88cd4ad.
[21] Paddle-lite GitHub. https://github.com/PaddlePaddle/Paddle-Lite.
[22] Protocol Buffers Encoding Rule. https://developers.google.com/protocol-buffers/docs/encoding#simple.
[23] Salary for the Machine Learning Engineer. https://www.linkedin.com/salary/machine-learning-engineer-salaries-in-san-francisco-bay-area-at-xnor-ai.
[24] SenseTime customers and partners. https://www.forbes.com/sites/bernardmarr/2019/06/17/meet-the-worlds-most-valuable-ai-startup-chinas-sensetime/.
[25] Strip visible string in ncnn. https://github.com/Tencent/ncnn/wiki.
[26] Tencent ncnn GitHub. https://github.com/Tencent/ncnn.
[27] TensorFlow. https://www.tensorflow.org/.
[28] TF Trusted. https://github.com/dropoutlabs/tf-trusted.
[29] The CMU Multi-PIE Face Database. http://www.cs.cmu.edu/afs/cs/project/PIE/MultiPie/Multi-Pie/Home.html.
[30] Unity Asset Store - The Best Assets for Game Making. https://assetstore.unity.com/?category=tools%2Fai&orderBy=1.
[31] Video Dataset Overview - Sortable and searchable compilation of video datasets. https://www.di.ens.fr/~miech/datasetviz/.
[32] Xiaomi mace GitHub. https://github.com/XiaoMi/mace.
[33] ARM TrustZone in Android. https://medium.com/@nimronagy/arm-trustzone-on-android-975bfe7497d2, 2019.
[34] SenseTime. https://www.sensetime.com/, 2019.
[35] The AppInChina App Store Index. https://www.appinchina.co/market/app-stores/, 2019.
[36] Yossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, and Joseph Keshet. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. In 27th USENIX Security Symposium (USENIX Security 18), pages 1615–1631, 2018.
[37] Tanzirul Azim, Arash Alavi, Iulian Neamtiu, and Rajiv Gupta. Dynamic slicing for Android. In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pages 1154–1164. IEEE, 2019.
[38] Lejla Batina, Shivam Bhasin, Dirmanto Jap, and Stjepan Picek. CSI Neural Network: Using side-channels to recover your artificial neural network information. arXiv preprint arXiv:1810.09076, 2018.
[39] Benjamin Bichsel, Veselin Raychev, Petar Tsankov, and Martin Vechev. Statistical deobfuscation of Android applications. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pages 343–355, 2016.
[40] Huili Chen, Cheng Fu, Bita Darvish Rouhani, Jishen Zhao, and Farinaz Koushanfar. DeepAttest: An End-to-End Attestation Framework for Deep Neural Networks. 2019.
[41] Yi Chen, Wei You, Yeonjoon Lee, Kai Chen, XiaoFeng Wang, and Wei Zou. Mass discovery of Android traffic imprints through instantiated partial execution. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pages 815–828, 2017.
[42] Lukas Dresel, Mykolai Protsenko, and Tilo Müller. ARTIST: The Android Runtime Instrumentation Toolkit. In 2016 11th International Conference on Availability, Reliability and Security (ARES), pages 107–116. IEEE, 2016.
[43] Johannes Hoffmann, Martin Ussath, Thorsten Holz, and Michael Spreitzenbarth. Slicing droids: Program slicing for Smali code. In Proceedings of the 28th Annual ACM Symposium on Applied Computing, pages 1844–1851, 2013.
[44] Ling Huang, Anthony D Joseph, Blaine Nelson, Benjamin IP Rubinstein, and J Doug Tygar. Adversarial machine learning. In Proceedings of the 4th ACM workshop on Security and artificial intelligence, pages 43–58. ACM, 2011.
[45] Matthew Jagielski, Nicholas Carlini, David Berthelot, Alex Kurakin, and Nicolas Papernot. High-fidelity extraction of neural network models. arXiv preprint arXiv:1909.01838, 2019.
[46] Roland Kunkel, Do Le Quoc, Franz Gregor, Sergei Arnautov, Pramod Bhatotia, and Christof Fetzer. TensorSCONE: A Secure TensorFlow Framework using Intel SGX. arXiv preprint arXiv:1902.04413, 2019.
[47] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial machine learning at scale. arXiv preprint arXiv:1611.01236, 2016.
[48] Juhyun Lee, Nikolay Chirkov, Ekaterina Ignasheva, Yury Pisarchyk, Mogan Shieh, Fabio Riccardi, Raman Sarokin, Andrei Kulik, and Matthias Grundmann. On-Device Neural Net Inference with Mobile GPUs. https://arxiv.org/abs/1907.01989, 2019.
[49] Smitha Milli, Ludwig Schmidt, Anca D Dragan, and Moritz Hardt. Model reconstruction from model explanations. arXiv preprint arXiv:1807.05185, 2018.
[50] Tribhuvanesh Orekondy, Bernt Schiele, and Mario Fritz. Knockoff nets: Stealing functionality of black-box models. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4954–4963, 2019.
[51] Siegfried Rasthofer, Steven Arzt, Marc Miltenberger, and Eric Bodden. Harvesting runtime values in Android applications that feature anti-analysis techniques. In NDSS, 2016.
[52] Tegjyot Singh Sethi and Mehmed Kantardzic. Data-driven exploratory attacks on black-box classifiers in adversarial domains. Neurocomputing, 289:129–143, 2018.
[53] Mark Slee, Aditya Agarwal, and Marc Kwiatkowski. Thrift: Scalable Cross-Language Services Implementation. Technical report.
[54] Benjamin Taubmann, Omar Alabduljaleel, and Hans P Reiser. DroidKex: Fast extraction of ephemeral TLS keys from the memory of Android apps. Digital Investigation, 26:S67–S76, 2018.
[55] Shruti Tople, Karan Grover, Shweta Shinde, Ranjita Bhagwan, and Ramachandran Ramjee. Privado: Practical and secure DNN inference. arXiv preprint arXiv:1810.00602, 2018.
[56] Florian Tramer and Dan Boneh. Slalom: Fast, verifiable, and private execution of neural networks in trusted hardware. arXiv preprint arXiv:1806.03287, 2018.
[57] Florian Tramèr, Fan Zhang, Ari Juels, Michael K Reiter, and Thomas Ristenpart. Stealing machine learning models via prediction APIs. In 25th USENIX Security Symposium (USENIX Security 16), pages 601–618, 2016.
[58] Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. Graviton: Trusted execution environments on GPUs. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18), pages 681–696, 2018.
[59] Binghui Wang and Neil Zhenqiang Gong. Stealing hyperparameters in machine learning. In 2018 IEEE Symposium on Security and Privacy (SP), pages 36–52. IEEE, 2018.
[60] Michelle Y Wong and David Lie. Tackling runtime-based obfuscation in Android with TIRO. In 27th USENIX Security Symposium (USENIX Security 18), pages 1247–1262, 2018.
[61] Mengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu Lin, Yunxin Liu, and Xuanzhe Liu. A First Look at Deep Learning Apps on Smartphones. The World Wide Web Conference on - WWW '19, (May):2125–2136, 2019.
[62] Jialong Zhang, Zhongshu Gu, Jiyong Jang, Hui Wu, Marc Ph Stoecklin, Heqing Huang, and Ian Molloy. Protecting intellectual property of deep neural networks with watermarking. In Proceedings of the 2018 on Asia Conference on Computer and Communications Security, pages 159–172. ACM, 2018.
[63] Min Zheng, Mingshen Sun, and John CS Lui. DroidTrace: A ptrace-based Android dynamic analysis system with forward execution capability. In 2014 international wireless communications and mobile computing conference (IWCMC), pages 128–133. IEEE, 2014.
[64] Yajin Zhou, Lei Wu, Zhi Wang, and Xuxian Jiang. Harvesting developer credentials in Android apps. In Proceedings of the 8th ACM Conference on Security & Privacy in Wireless and Mobile Networks, pages 1–12, 2015.

### Appendix A: Keywords for Different ML Frameworks

**Table A1: ML Framework Keywords**

| Framework   | Magic Words                |
|-------------|----------------------------|
| TensorFlow  | tensorﬂow                  |
| MXnet       | mxnet                      |
| Mace        | libmace, mace_input         |
| ULS         | ulstracker, ulsface         |
| Caffe       | caffe                      |
| NCNN        | ncnn                       |
| SenseTime   | sensetime, st_mobile        |
| Other       | cnn, neuralnetwork, lstm, rnn |

Note: "TensorFlow Lite" and "TensorFlow" are merged into one framework.