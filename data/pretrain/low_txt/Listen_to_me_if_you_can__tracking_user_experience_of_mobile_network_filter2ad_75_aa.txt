# Listen to Me if You Can: Tracking User Experience of Mobile Networks on Social Media

**Authors:**
- Tongqing Qiu, Georgia Tech, Atlanta, GA
- Junlan Feng, AT&T Labs – Research, Florham Park, NJ
- Zihui Ge, AT&T Labs – Research, Florham Park, NJ
- Jia Wang, AT&T Labs – Research, Florham Park, NJ
- Jun (Jim) Xu, Georgia Tech, Atlanta, GA
- Jennifer Yates, AT&T Labs – Research, Florham Park, NJ

**Abstract:**
Social media platforms such as Twitter continue to grow rapidly, and people of all ages use them to exchange messages and share experiences in real-time. Many of these platforms make their data available, raising the question of whether this real-time, massive data flow can be leveraged to improve business operations measurably.

In this paper, we focus on tweets related to mobile network performance. We compare these tweets with a more traditional source of user feedback, customer care tickets, and correlate both with a list of major network incidents. Our study reveals the following key observations:
1. Twitter users and those who call customer service tend to report different types of performance issues.
2. Tweets generally appear more quickly in response to network problems compared to customer tickets and cover a broader range of issues.
3. Significant spikes in the number of tweets often indicate short-term performance impairments that are not captured in our current list of major network incidents.

These findings suggest that Twitter is a valuable, complementary source for monitoring service performance and its impact on user experience.

**Categories and Subject Descriptors:**
- C.2.3 [Network Operations]
- General Terms: Management, Measurement, Performance

**Keywords:**
- Social Media, Twitter, User Experience

## 1. Introduction
Monitoring network performance is a critical task in network operations. Traditionally, service performance issues are detected from both a systems perspective (e.g., network delay, packet loss) and a customer perspective (e.g., user feedback via calls or emails). In this paper, we propose to leverage online social media, specifically Twitter, as an additional channel for tracking user feedback on service performance.

Online social networks (OSNs) have gained significant popularity in recent years. Microblogging services like Twitter allow users to share information and experiences quickly and easily. Unlike other social networking sites, Twitter messages (tweets) are short (less than 140 characters), making it easy for users to post and distribute them within seconds. According to comScore, Twitter's website had nearly 20 million visitors by the end of 2009, up from just 2 million in 2008.

In this study, we analyze tweets related to one of the largest mobile service providers in the United States. We first identify tweets related to service performance issues and compare them with customer care trouble tickets. We then correlate these two sources of feedback with a report of major network incidents. Our findings show that:
1. Issues reported on Twitter complement those reported through customer care calls.
2. Twitter users are faster to report service performance issues than customers who call the customer care center.
3. Tweets often report short-term and/or less severe problems that are not recorded in the major network incidents report.

The remainder of the paper is structured as follows: Section 2 discusses the datasets used in our analysis, Section 3 presents the results, Section 4 reviews related work, and Section 5 concludes the paper.

## 2. Datasets
This section outlines the methodology used to collect and describe the data. We discuss Twitter data in Section 2.1, customer care call data in Section 2.2, and major network incidents report data in Section 2.3.

### 2.1 Twitter Data
We used Twitter APIs to retrieve publicly available data relevant to our study. Only information shared publicly by Twitter users was obtained and analyzed. We manually selected keywords to query tweets related to the mobile service provider. Using the Twitter search API, we retrieved and archived tweets along with associated metadata, including submission time and author. We also fetched user profiles, such as location, to help localize reported issues.

To identify tweets related to mobile network performance, we applied heuristic rules:
1. Tweets must contain mobile-related words (e.g., phone, mobile, 3G, edge).
2. Tweets must contain performance-related words (e.g., slow, drop, intermittent, doesn't work).
3. Tweets should not contain advertising-related words (e.g., "Ads," price symbols $).

We randomly sampled 100 tweets and manually annotated them to verify the effectiveness of these rules, achieving an 87% agreement between rule-based prediction and human annotation. This level of accuracy is acceptable for our study, though natural language processing and machine learning could potentially improve this step further.

### 2.2 Customer Care Calls
We obtained anonymized customer care tickets created in response to customer calls. These tickets are tagged with issue types, such as billing, calling plans, mobile devices, service coverage, performance impairments, and service outages. We focused on tickets related to service impairments and outages. Each ticket includes the type of service, call time, location, and a description of the performance issue.

Performance-related tickets include issues such as no coverage, inability to make or receive calls, call disconnections, and poor voice quality. Not all customers report performance issues, and some may not call the customer care team immediately after experiencing a problem.

### 2.3 Major Network Incidents Report
The service provider maintains a Major Network Incidents Review in a collaborative editing system. This report tracks major network or service incidents, serving as a communication channel for summary-level information among team members and senior management.

We filtered out non-customer-impacting events and long-duration incidents to avoid false associations. Each entry in the report contains temporal and spatial information, facilitator contact details, and estimated customer impact. Most entries include detailed incident summaries and root cause descriptions. For our analysis, we utilized the temporal and spatial information.

## 3. Results
We first present the results from the major network incidents report, tweets, and tickets. Then, we correlate tweets and tickets with the incidents report. The data analyzed are from a large U.S. cellular network provider over a 16-day period.

### 3.1 Major Network Incidents Report
We analyzed the temporal distribution of major network incidents. The report includes only significant incidents, with durations ranging from seconds to over a day. In our later analysis, we focused on incidents lasting less than three hours.

### 3.2 Tweets vs. Customer Care Tickets
We compared two sources of user experience: tweets and customer care tickets. First, we analyzed raw data, which included all archived tweets and tickets. We then classified the data into different categories and focused on performance-related logs.

#### 3.2.1 Time Series
We compared the volume of tweets and customer call tickets over a common period. Figure 1 shows the number of tweets and tickets per hour. Both datasets exhibit a daily pattern, which is expected due to common user behavior and the daily access pattern of social media. A spike in Twitter data on Day 7 was caused by discussions about new technology.

#### 3.2.2 Classification
We manually inspected the message content of the collected tweets and observed three major types:
1. Comments and news regarding the product and customer service.
2. Advertisements (e.g., promotions of mobile phones).
3. Comments or complaints regarding performance issues (our primary interest).

Classifying tweets automatically is challenging due to their loose structure, but most tweets fall into the first two categories. Customer care tickets, with their fixed structure and categorization, are easier to classify. Over 97% of tickets relate to plan, bill, or device issues. We focused on performance-related tweets and tickets, which comprised about 1% of the data.

Figure 2 breaks down performance-related issues into several categories. Twitter users primarily complain about call drops, followed by slow connections, no service, and other minor issues. In contrast, customer care tickets often report more severe issues like lack of service or coverage and voice quality problems. This indicates that Twitter users tend to report short-term and minor performance issues, while customer calls report more severe issues.

We also compared the geographic locations of tweets and tickets, revealing differences in the types of issues reported in different regions.

## 4. Related Work
[This section would review existing literature on using social media for network performance monitoring, comparing and contrasting our approach with previous studies.]

## 5. Conclusion
Our study demonstrates that Twitter is a valuable, complementary source for monitoring mobile network performance and its impact on user experience. Tweets provide real-time, broad-ranging feedback and can help identify short-term and minor performance issues that may not be captured through traditional customer care channels. Future work could explore advanced natural language processing and machine learning techniques to improve the classification and analysis of social media data.

**Acknowledgments:**
This work was supported in part by NSF grants CNS-0905169 and CNS-0716423, funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).

**References:**
[1] comScore. (2010). Twitter Finishes 2009 with Nearly 20 Million Visitors. Retrieved from [URL].

[2] Smith, A. (2010). The rise of social networking. Pew Internet & American Life Project. Retrieved from [URL].

[3] Additional references and citations as needed.