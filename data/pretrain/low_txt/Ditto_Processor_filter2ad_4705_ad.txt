# Ditto Processor: A Fault-Tolerant Superscalar Design

## 5.3 The Characteristics of the Ditto Processor

### 5.3.1 Functional Unit Utilization
Figure 4 shows the average utilization of various functional units for different benchmarks. The figure is divided into four groups, each representing the utilization ratio for integer and floating-point benchmarks:
- **Integer ALU Unit Utilization**: The leftmost group.
- **Memory Port Utilization**: The second group.
- **Multiplier/Divider Unit Utilization**: The third group, which includes both integer and floating-point operations.
- **Overall Functional Unit Utilization**: The rightmost group.

The O3rs model does not affect cache ports since it does not verify memory reference micro-ops. Integer benchmarks rarely use multipliers and dividers, resulting in low utilization rates for these modules across all models. However, the O3rs model has a slightly better utilization rate for the MULT/DIV unit in floating-point benchmarks due to its larger Reorder Buffer (ROB) entry, which allows for more Instruction-Level Parallelism (ILP) exploration compared to the Ditto3 model.

In summary, the Dual model has about 5% higher functional unit utilization for integer benchmarks and 3% higher for floating-point benchmarks compared to the Base model. The O3rs model shows 3.6% and 4.7% improvements, respectively. The Ditto model, with 5.7% and 7.4% better utilization, demonstrates the highest improvement, indicating full transient fault coverage with minimal performance degradation.

### 5.3.2 Performance Degradation with L1 Cache Hit Latency
Figure 5 illustrates the percentage of Instructions Per Cycle (IPC) degradation when comparing the Ditto model to the Base model under varying L1 cache hit latencies. As the L1 cache hit latency increases, the Ditto model gradually reduces performance loss for both integer and floating-point benchmarks. This reduction is attributed to the increased availability of idle processor cycles, which can be used for time-redundant fault checking through re-execution. As memory latency increases, more stalled cycles become available, providing more opportunities to execute cloned instructions and thus reduce the effect of performance degradation.

## 6. Conclusion
This paper presents the detailed design of a fault-tolerant superscalar processor called the Ditto Processor. The Ditto Processor refetches and redecodes all instructions to protect all pipeline stages from soft errors, ensuring high computational confidence. It requires minimal additional hardware on top of a baseline superscalar design. We have explained the additional microarchitectural resources needed and the units that can be protected, as well as how to handle register renaming in the Ditto Processor.

We identified that long-latency operations significantly impact the fault tolerance of a superscalar processor. Our study compares the performance degradation of the Ditto Processor with a baseline superscalar and other published schemes. Generally, the Ditto Processor suffers only 1.8% to 13.3% performance degradation across all benchmarks. While the Ditto Processor incurs only 1% to 6% more performance loss compared to the O3RS scheme, it provides much better fault coverage. The degree of performance reduction varies with the amount of resource contention caused by duplication.

As technology advances, the performance gap between processors will continue to grow, leading to more available stalled cycles for time redundancy. Our study reveals that different applications have varying characteristics and requirements for hardware resources. Adopting a time-redundant fault-tolerant technique based on this knowledge can provide a balanced, fault-tolerant computing environment with minimal performance loss.

## Acknowledgments
The authors would like to thank the anonymous reviewers for their valuable comments.

## References
[1] T. Juhnke and H. Klar, “Calculation of the Soft Error Rate of Submicron CMOS Logic Circuits,” IEEE JSSC, Vol. 30, No. 7, July 1995, pp. 830-834.
[2] J. Robertson, “Alpha Particles Worry IC Makers as Device Features Keep Shrinking,” Semicond. Business News, October 21, 1998.
[3] N. Cohen et al., “Soft Error Considerations for Deep-Submicron CMOS Circuit Applications,” Proc. of IEDM, 1999, pp. 315-318.
[4] P. Hazucha and C. Svensson, “Impact of CMOS Technology Scaling on the Atmospheric Neutron Soft Error Rate,” IEEE Trans. On Nuclear Science, Vol. 47, No. 6, Dec. 2000, pp. 2586-2594.
[5] T. Karnik et al., “Scaling Trends of Cosmic Rays Induced Soft Errors in Static Latches Beyond 0.18um,” Symposium on VLSI Circuits Design of Tech. Papers, 2001, pp. 61-62.
[6] U. Gunneflo, “Evaluation of Error Detection Schemes Using Fault Injection by Heavy-ion Radiation,” Digest of Papers in the 19th International Symposium on Fault-Tolerant Computing, 1989, pp. 340-347.
[7] G. Miremadi and J. Torin, “Evaluating processor-behavior and three error-detection mechanisms using physical fault-injection,” IEEE Transactions on Reliability, Volume: 44, Issue: 3, Sept. 1995, pp. 441 –454.
[8] R. Horst et al., “The Risk of Data Corruption in Microprocessor-based Systems,” Digest of Papers in the 23rd International Symposium on Fault-Tolerant Computing, Aug. 1993, pp. 576 –585.
[9] Barry W. Johnson, Design and Analysis of Fault Tolerant Digital Systems, Addison-Wesley, 1989.
[10] A. Avizienis, “Toward Systematic Design of Fault-Tolerant Systems,” IEEE Computer, April 1997, pp. 51-58.
[11] D. K. Pradhan, Fault-tolerant computer system design, Prentice-Hall, 1996.
[12] W. Torres-Pomales, “Software Tolerance: A Tutorial,” NASA Tech. Memorandum, TM-2000-210616, Langley Res. Center, Hampton Virginia, Oct. 2000.
[13] R.E. Blahut, Theory and Practice of Data Transmission Codes, Addison-Wesley, 1983.
[14] Parag K. Lala, Self-Checking and Fault-Tolerant Digital Design, Academic Press, 2001.
[15] G. Sohi, “A Study of Time-Redundant Fault Tolerance Techniques for High-performance Pipelined Computers,” Digest of Papers in the 19th International Symposium on Fault-Tolerant Computing, 1989.
[16] J. H. Patel and L. Y. Fung, “Concurrent Error Detection in ALUs by Recomputing with Shifted Operands,” IEEE Trans. On Computers, Vol. C-13, No. 7, July 1982, pp. 581-595.
[17] M. Nicolaidis, “Time redundancy based soft-error tolerance to rescue nanometer technologies,” Proceedings of 17th IEEE VLSI Test Symposium, 1999, pp. 86 –94.
[18] M. Franklin, “Incorporating Fault Tolerance in Superscalar Processors,” Proceedings of 3rd International Conference on High Performance Computing, 1996, pp. 301 –306.
[19] A. Avizienis and Y. He, Microprocessor entomology: a taxonomy of design faults in COTS microprocessors, Dependable Computing for Critical Applications 7, 1999, pp. 3 –23.
[20] L. Spainhower and T. A. Gregg, “IBM S/390 Parallel Enterprise Server G5 fault tolerance: A historical perspective,” IBM J. of Research and Development, Vol. 43, No. 5/6, 1999.
[21] Y. He et al., “Assessment of the applicability of COTS microprocessors in high-confidence computing systems: a case study,” Proceedings International Conference on Dependable Systems and Networks, 2000.
[22] E. Rotenberg, “AR-SMT: a microarchitectural approach to fault tolerance in microprocessors,” Digest of Papers in 29th International Symposium on Fault-Tolerant Computing, 1999, pp. 84 –91.
[23] K. Sundaramoorthy et al., "Slipstream Processors: Improving both Performance and Fault Tolerance,” 9th Int'l Conference on Architectural Support for Programming Languages and Operating Systems, November 2000.
[24] F. Rashid et al., “Fault Tolerance Through Re-execution in Multiscalar Architecture,” Proc. Conference on Dependable Systems and Networks, 2000, pp. 482 –491.
[25] M. Franklin, “A Study of Time Redundant Fault Tolerance Techniques for Superscalar Processors,” Digest of Papers in the 25th International Symposium on Fault-Tolerant Computing, Aug. 1995, pp. 207–215.
[26] Joel Nickel, "REESE: A Method of Soft Error Detection in Microprocessors,” M. S. Thesis, Dept. of ECE, Iowa State University, Ames Iowa, 2000.
[27] A. Mendelson and N. Suri, “Designing High-Performance and Reliable Superscalar Architectures The Out of Order Reliable Superscalar(O3RS) Approach,” Proc. Conference on Dependable Systems and Networks, 2000.
[28] Doug Burger and Todd M. Austin, “Simplescalar Tool Set Version 2.0,” June 1997, University of Wisconsin-Madison Computer Science Department Technical Report #1342.
[29] http://www.spec.org/osg/cpu2000/docs/readme1st.txt
[30] S. Sair and M. Charney, “Memory Behavior of the SPEC2000 Benchmark Suite,” IBM Research Report, RC 21852 (98345), Oct. 6, 2000.
[31] A. Avizienis, “A Fault Tolerance Infrastructure for dependable Computing with High-Performance COTS Components,” In proceeding of Dependable Systems and Networks, 2000.
[32] Joydeep Ray et al., “Dual Use of Superscalar Datapath for Transient-Fault Detection and Recovery,” In proceeding of 34th Microarchitecture, December 2001.
[33] Steven K. Reinhardt et al., “Transient Fault Detection via Simultaneous Multithreading,” In proceedings of the 27th International Symposium on Computer Architecture, June 2000.
[34] T. Austin, “DIVA: A Reliable Substrate for Deep Submicron Microarchitecture Design,” In proceeding of 32nd Microarchitecture, November 1999.
[35] T. Austin, “DIVA: A Dynamic Approach to Microprocessor Verification,” The Journal of Instruction-Level Parallelism Volume 2, 2000.
[36] Saugata et al., “Effective Checker Processor Design,” in proceeding of 33rd Microarchitecture, December 2000.
[37] A. Yoaz et al., “Speculation Techniques for improving load related Instruction scheduling,” Proc. Of 26th Int’l Symp. On Computer Architecture, May 1999.

## Appendix: Examples of Pipeline Flow and Fault Detection

### A. Sample Program Instructions
| Instruction | Label |
|-------------|-------|
| Multiu r1, r2, 4 | A |
| Sub r1, r1, r4 | B |
| Lw r3, 16[r1] | C |
| Addu r4, r3, r2 | D |
| Bne r4, r5, [next_loc] | E |

### B. Pipeline Diagram
```
ROB
SCH REG EXE/MEM WB
CMT
FET Dec
A14 A2
B2
B1
C2
C1
D2
D1
E2
E3
A'4
A'3
B'4
B'3
C'4
C'3
D'3
D'4
~
A4
B9
A5-7
B10
A3
B8
C11 C12 C13-16
D17 D18 D19
E20 E21 E22
A'5 A'6 A'7-9
B'20 B'21 B'22
C'23 C'24 C'25-28
D'29 D'30 D'31
~
~
~
A9
A8(CHK)
B11
B12
C17(CHK) C18
D20
D21
E23
E24
A'10(CHK) A'11
B'23
B'24
C'29(CHK) C'30
D'32
D'33
~
~
$A10 $A11 $A12 $A13 $A14(CHK)
$A'12 $A'13 $A'14 $A'15 $A'16(CHK)
$B13 $B14 $B15 $B16 $B17(CHK) $B18(CHK)
$C19 $C20 $C21 $C22 $C23(CHK) $C24(CHK)
$D22 $D23 $D24 $D25 $D26(CLK) $D27(CLK)
$E25 $E26 $E27 $E28 $E29(CHK) $E30(CHK)
$B'25 $B'26 $B'27 $B'28 $B'29(CHK) $B'30(CHK)
$C'31 $C'32 $C'33 $C'34 $C'35(CHK) $C'36(CHK)
$D'34 $D'35 $D'36 $D'37 $D'38(CHK) $D'39(CHK)
1
2
3
4
5
6
7
8
9
LP-ROB ~
1
2
3
4
5
6
7
8
9
```

### C. Examples of Fault Detection
1. **Case 1**: A fault at the FET stage of instruction B is detected at $B17. Instructions C, D, E, B', C', D' are squashed from the ROB, and instruction $B is squashed from the LP-ROB.
2. **Case 2**: A fault at the DEC stage of instruction E is detected at $E29. Instructions E, C', D' are squashed from the ROB, and instructions $E, $B' are squashed from the LP-ROB.
3. **Case 3**: A fault at the EXE stage of instruction A' is detected at A'10. Instructions B, C, D, E, A', B', C', D' are squashed from the ROB.
4. **Case 4**: A fault at the WB stage of instruction B is detected at $C23. An error occurs in propagating the result to B's dependent instructions. Instructions E, C', D' are squashed from the ROB, and instructions $C, $D are squashed from the LP-ROB.
5. **Case 5**: A fault at the REG stage of instruction A' is detected at $A'16. Instructions B', C', D' are squashed from the ROB, and instruction $A' is squashed from the LP-ROB.

**Note**: The number following the instruction label indicates the cycle time. An “$” means it is a cloned instruction. For example, $A10 means instruction A cloned at cycle time 10.

---

Proceedings of the International Conference on Dependable Systems and Networks (DSN’02)  
0-7695-1597-5/02 $17.00 © 2002 IEEE  
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19, 2021, at 04:09:01 UTC from IEEE Xplore. Restrictions apply.