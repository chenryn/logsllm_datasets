# A Case for a Coordinated Internet Video Control Plane

**Authors:**
- Xi Liu, Conviva
- Florin Dobrian, Conviva
- Henry Milner, Conviva
- Junchen Jiang, Carnegie Mellon University (CMU)
- Vyas Sekar, Intel Labs
- Ion Stoica, Conviva and UC Berkeley
- Hui Zhang, Conviva and CMU

## Abstract
Video traffic already represents a significant fraction of today's internet traffic and is projected to exceed 90% in the next five years. Concurrently, user expectations for a high-quality viewing experience (e.g., low startup delays, minimal buffering, and high bitrates) are continuously increasing. Unlike traditional workloads that either require low latency (e.g., short web transfers) or high average throughput (e.g., large file transfers), a high-quality video viewing experience requires sustained performance over extended periods (e.g., tens of minutes). This imposes fundamentally different demands on content delivery infrastructures compared to those designed for traditional traffic patterns.

Our large-scale measurements over 200 million video sessions reveal that today’s delivery infrastructure often fails to meet these requirements: more than 20% of sessions have a rebuffering ratio ≥ 10%, and more than 14% of sessions have a video startup delay ≥ 10 seconds. Using measurement-driven insights, we argue for a video control plane that can use a global view of client and network conditions to dynamically optimize video delivery, providing a high-quality viewing experience despite an unreliable delivery infrastructure. Our analysis shows that such a control plane can potentially improve the rebuffering ratio by up to 2× in the average case and by more than an order of magnitude under stress.

**Categories and Subject Descriptors:**
- C.2.4 [Computer-Communication Networks]: Distributed systems—Distributed applications
- C.4 [Performance of Systems]: Measurement techniques

**General Terms:**
- Design, Performance, Measurement

**Keywords:**
- Video, CDNs, Control plane

## 1. Introduction
Over the last few years, video traffic has quickly become the dominant fraction of internet data traffic. Studies show that Netflix alone accounts for more than 20% of US internet traffic, and projections indicate that by 2014, video traffic will constitute more than 90% of total internet traffic. These estimates pertain to streaming traffic (including both live and video-on-demand services) and do not include offline video downloads (e.g., via shared upload or P2P services).

User expectations for streaming video impose fundamentally different service requirements on the network infrastructure compared to traditional data traffic. Traditional workloads focus either on latency (e.g., interactive sessions or short web transfers) or on transfer completion time (e.g., long file transfers). In contrast, latency is less critical in streaming video because application data units are large enough to amortize latency effects. Similarly, overall completion time does not reflect the actual user experience as it does not capture rebuffering-induced interruptions. We know that users are sensitive to buffering, with a 1% increase in buffering leading to more than a 3-minute reduction in expected viewing time. Streaming video not only introduces new quality metrics at the network- and user-level but also requires sustained quality (e.g., high bitrates with low rebuffering) over extended periods, as typical videos span multiple minutes.

In addition to improvements in last-mile connectivity, a key driver for the rapid growth of streaming video traffic has been the shift from specialized streaming protocols and infrastructure (e.g., Windows Media Services, RealNetworks, RTMP) to HTTP chunk-based streaming protocols (e.g., HLS, DASH). The use of a commodity service dramatically decreases the cost of dissemination and the barrier to entry, allowing content providers to leverage existing HTTP CDN infrastructures to deliver content to a wide audience. Furthermore, the reliance on HTTP implies the ability to support multiple viewing platforms, as HTTP support is ubiquitous.

Unfortunately, there is a mismatch between the requirements of video streaming and the architecture of today’s HTTP-based video delivery infrastructures, both at the ISP and CDN level. Using fine-grained client-side measurements from over 200 million client viewing sessions, we find that 20% of these sessions experience a rebuffering ratio of ≥ 10%, 14% of users have to wait more than 10 seconds for video to start, more than 28% of sessions have an average bitrate less than 500 Kbps, and 10% of users fail to see any video at all.

Analyzing the causes of these performance problems reveals:
- Significant spatial diversity in CDN performance and availability.
- Substantial temporal variability in CDN performance.
- Poor system response to overload scenarios when there are "hotspots" of client arrivals in particular regions or ISPs.

Our overarching goal is to meet the demands for a high-quality viewing experience despite an unreliable video delivery infrastructure. In this context, the design space for optimizing video delivery quality consists of three high-level dimensions:
1. What parameters can we adapt? (e.g., bitrate, CDN)
2. When are these parameters optimized? (e.g., at video startup or midstream)
3. Who chooses these parameters? (e.g., client or server)

The above observations regarding CDN variability across space and time suggest that purely server- or client-driven selection and adaptation are unlikely to be sufficient. To this end, we envision a video control plane that can use a global view of network and CDN performance to dynamically assign clients a suitable choice of CDN and bitrate that optimizes the video delivery. Beyond the performance benefits, such a control plane also offers content providers more flexibility in instrumenting fine-grained policies; e.g., providing higher quality service to premium customers under load, ensuring that certain types of content are only accessible within specific geographical regions, or taking into account the cost-performance tradeoffs that different CDNs offer.

Realizing such a control plane is challenging, and thus a natural first question is whether this exercise is worthwhile. To this end, we use a measurement-driven framework to extrapolate the potential for improvement in video quality. We observe that there is significant potential, and even just choosing a CDN more optimally can reduce the average rebuffering ratio by 2× in the common case and more than 10× under extreme scenarios.

We would also like to confirm that these gains are not merely hypothetical. To do so, however, we need to concretely specify aspects of the control plane such as allocation algorithms, performance estimators, and policy functions. To this end, we present one specific realization of such a control plane to illustrate the benefits. Our choices in this respect are far from ideal and necessarily embed several simplifying assumptions. We believe this exercise is still valuable because our goal is to make a case for a control plane rather than present a reference design and implementation. Our simulations confirm that such an approach can outperform other options in the design space for optimizing video delivery in both common and extreme load scenarios.

**Contributions and Roadmap:**
To summarize, our key contributions are:
- Measurements to expose the shortcomings of today’s video delivery infrastructure (Section 2) that motivate the need for a video control plane (Section 3).
- Using an extrapolation approach to establish the potential room for improvement (Section 4).
- Corroborating these potential gains under a concrete (but simplified) operational model (Sections 5 and 6).

We discuss outstanding issues in Section 7 and place our work in the context of related work in Section 8 before concluding in Section 9.

## 2. Motivation
Previous research has confirmed the impact of quality on user experience, showing that users are quite sensitive to buffering and high startup latency and prefer higher bitrate content. Given this need for high-quality video delivery, we analyze how today’s infrastructure performs.

In this section, we examine the performance of today’s delivery infrastructure and highlight potential sources of inefficiencies. We begin by focusing on the end-user streaming video performance. Then, we identify three potential sources of performance problems: variability in client-side, variability within a single ISP or Autonomous System (AS), and variability in CDN performance.

### 2.1 Dataset
The dataset used in this paper is based on one week of client-side measurements from over 200 million viewing sessions (both successful and failed) from over 50 million viewers across 91 popular video content providers around the world. The chosen week includes a single large live event lasting two hours, but otherwise has normal traffic. Table 1 summarizes the dataset. The content served by these providers includes both live (e.g., sports broadcasts) and video-on-demand (e.g., TV episodes and movies). Since we observe similar results from both live and video-on-demand traffic, we show results only on aggregate data from both types of traffic. The data was generated via client-side player instrumentation that collects statistics regarding the current network conditions (e.g., estimated bandwidth to the chosen CDN server) and the observed video quality (e.g., rebuffering ratio, chosen bitrate). Many of the content providers have the option to deliver content to their customers from multiple CDNs; the specifics of how they choose CDNs are proprietary. Due to business and anonymity considerations, we anonymize the providers, CDNs, ISPs, and cities in the following results. Our goal here is to highlight the overall problems in video delivery in general rather than pinpoint inefficiencies of specific ISPs or CDNs.

| **Time**          | **Views** | **Viewers** | **View Hours** | **Content Providers** | **Videos** | **Countries/Regions** |
|-------------------|-----------|-------------|----------------|-----------------------|------------|-----------------------|
| 2011.12.10 - 2011.12.17 | 281M      | 54M         | 30M            | 91                    | 2M         | 231                   |

### 2.2 Metrics
We focus on the following industry-standard video quality metrics:
- **Average Bitrate:** The average bitrate experienced by a view over its lifetime.
- **Rebuffering Ratio:** Computed as the buffering time divided by buffering plus playing time, excluding paused or stopped time and buffering time before video start. (We use the terms rebuffering ratio and buffering ratio interchangeably.)
- **Startup Time:** The wait or buffering time before a video starts to play.
- **Failure Rate:** The percentage of views that failed to start playing and experienced a fatal error during the process. In our experience, these fatal errors usually indicate CDN issues. For example, missing content that the CDN failed to populate to edge servers, or the CDN server rejecting new connections (e.g., due to overload).
- **Exits Before Video Start:** The percentage of views that failed to play the video without experiencing a fatal error. There are generally two causes: (1) users are not interested in the content, and (2) users waited too long for the video to load and lost patience.

We choose these metrics because earlier work showed that they have a significant impact on user engagement. Our goal is not to design an aggregate quality metric that can combine these factors (e.g., [8]). Rather, we want to show the inefficiencies of today’s infrastructure and provide directions to improve video quality. Thus, we consider each metric in isolation in this study.

### 2.3 Video Quality Today
We begin by analyzing the video quality that today’s delivery infrastructure provides before looking at more in-depth analysis to understand the reasons for this inefficiency.

Figure 1 shows the distribution of rebuffering ratio, video startup time, and average bitrate from views that have started the video playing. Note that these are the observed performances in the wild with the default video players that the providers use. For rebuffering ratio and average bitrate, we remove sessions less than one minute, as they usually come from users who are not interested in the video.

- **Rebuffering Ratio:** 40% of the views experience at least 1% rebuffering ratio, and 20% experience at least 10% rebuffering ratio.
- **Video Startup Time:** 14% of users have to wait more than 10 seconds for the video to start.
- **Average Bitrate:** More than 28% of sessions have an average bitrate less than 500 Kbps.
- **Failure Rate:** 10% of users fail to see any video at all.

These results indicate that today’s end-user experience is far from perfect and highlight the need for performance optimization.

### 2.4 Sources of Quality Issues
(a) Intra-session
(b) Inter-session

Figure 2 shows significant variability in client-side bandwidth both within and across sessions, confirming the need for bitrate adaptation.