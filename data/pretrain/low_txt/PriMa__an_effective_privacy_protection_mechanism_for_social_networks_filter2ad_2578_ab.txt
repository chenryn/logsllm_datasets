### Sensitivity and Clustering of Traits

Given a sensitivity value \(\theta\) for each trait \(T_l(i)\) in a profile \(profi = [T_1(i), \ldots, T_m(i)]\), we can cluster the traits into \(\gamma_1(i), \ldots, \gamma_k(i)\) (where \(k \geq 2\)) based on their sensitivity levels. The clustering is performed using the k-means algorithm for discrete objects, as described in [16]. This allows the system administrator to control the granularity of the partitions and, consequently, the privacy policies by adjusting the value of \(k\). After clustering, the overall sensitivity of each partition, denoted by \(\theta(\gamma(i))\), is calculated as the mean of the sensitivity scores of all the traits within that cluster.

### P RiM a Privacy Policy Generation

One of the key features of P RiM a is its ability to automatically suggest privacy policies based on users' privacy preferences and the actual risk of exposing traits to a specific set of users. These policies are defined by a set of access rules that specify who is granted or denied access to the classes of traits generated for a user's profile. An access rule in P RiM a is represented as a tuple \(AccRule\) of the form \(\langle P red, Users, \gamma \rangle\), where:
- \(P red\) is a predicate that can take the values "Share" (positive rule) or "NotShare" (negative rule).
- \(Users\) is the set of users to which the policy applies, which can be a set of user identifiers or relationships.
- \(\gamma\) is the partition of traits protected by the rule.

At the implementation level, only positive access rules are necessary, as negative rules are complementary. For simplicity, we will demonstrate the rule generation for users with a first-degree relationship to the profile owner, assuming that other users are denied access. The same mechanism can be extended to higher-degree connections.

Access rules are generated for each class of traits \(\gamma_n(i)\) in the profile, based on the user access score.

### User Access Score

The user access score, denoted as \(\delta(\gamma_n(i), j)\), represents the adequacy of a given user \(j\) to access a given partition \(\gamma_n(i)\) (where \(n \leq k\)). The score is computed using two metrics: the relationship score and the risk.

#### Relationship Score
The relationship score, \(rel(i, j)\), quantifies the strength of the relationship between users \(i\) and \(j\). It is calculated as:
\[ rel(i, j) = type \times \frac{\#(deg(j) \cap deg(i))}{\#deg(i)} \times rep_j \]
where:
- \(type\) is a normalized numerical value assigned to each relationship type, with closer relationships having higher scores. For example, "Best Friends" has \(type = 1\), "Friends" has \(type = 0.8\), and "Friends of Friends" has \(type = 0.6\).
- \(\#(deg(j) \cap deg(i)) / \#deg(i)\) measures the similarity in terms of common first-degree connections.
- \(rep_j\) is the normalized rating given by user \(i\) to user \(j\), which can be directly input by the user or calculated using methods such as [6].

#### Risk Score
The risk score, \(risk(\gamma_n(i), j)\), estimates the risk of disclosing a class of traits \(\gamma_n(i)\) to user \(j\):
\[ risk(\gamma_n(i), j) = L(j) \times \theta(\gamma_n(i)) \]
where:
- \(L(j)\) is the looseness of user \(j\), representing the information leakage associated with \(j\).
- \(\theta(\gamma_n(i))\) is the sensitivity of the partition under consideration.

#### User Access Score
The user access score is calculated as the ratio of the relationship score to the risk score:
\[ \delta(\gamma_n(i), j) = \frac{rel(i, j)}{risk(\gamma_n(i), j)} \]

Once the user access scores are computed, generating access rules in P RiM a is straightforward. For each class \(\gamma_n(i)\), the set of users in \(deg(i)\) is partitioned into two sets: \(Users\) (allowed access) and \(Users''\) (denied access). A user \(j\) is added to \(Users\) if \(\delta(\gamma_n(i), j) > \xi\); otherwise, they are added to \(Users''\). This process is repeated for all partitions, ensuring fine-grained access control at a per-user, per-partition level.

### Related Work

Social networks (SNs) require new approaches to access control that are flexible and based on interpersonal relationships. Previous work includes:
- [9] presents a social-networking-based access control scheme suitable for online sharing.
- [8] proposes a content-based access control model using relationship information in SNs.
- [4, 3] introduce more sophisticated mechanisms, including decentralized and collaborative access control.
- [11] explores the effect of sanitizing traits and link details on private information leakage.

Our work builds on these ideas, focusing on fine-grained data protection and leveraging local trust metrics and social graph network metrics to predict appropriate data protection.

### Conclusion

This paper introduces P RiM a, an adaptive policy generation framework for providing flexible, adaptive, and powerful access control to SN users. P RiM a generates access rules based on users' privacy preferences, data sensitivity, and the risk of disclosing data to other users. While there are still challenges to overcome, such as tuning thresholds, P RiM a represents a significant step towards robust privacy protection in social networks.

### References

[1] A. Acquisti. Privacy in electronic commerce and the economics of immediate gratification. In A. Press, editor, Proceedings of the 5th ACM Electronic Commerce Conference, pages 21–29, 2004.

[2] A. Acquisti and J. Grossklags. Privacy and rationality in decision making. IEEE Security and Privacy (January/February), pages 26–33, 2005.

[3] B. Carminati and E. Ferrari. Privacy-aware collaborative access control in web-based social networks. In DBSec, pages 81–96, 2008.

[4] B. Carminati, E. Ferrari, and A. Perego. Private relationships in social networks. In ICDE Workshops, pages 163–171, 2007.

[5] Facebook. http://www.facebook.com.

[6] J. A. Golbeck. Computing and applying trust in web-based social networks. PhD thesis, College Park, MD, USA, 2005. Chair-Hendler, James.

[7] R. Gross, A. Acquisti, and H. J. Heinz, III. Information revelation and privacy in online social networks. In WPES '05: Proceedings of the 2005 ACM workshop on Privacy in the electronic society, pages 71–80, New York, NY, USA, 2005. ACM.

[8] M. Hart, R. Johnson. A. Stent. More content - Less control: Access control in the Web 2.0. In IEEE Web 2.0 Privacy and Security Workshop, 2007.

[9] K. Kollu, S. Saroiu, and A. Wolman. A social networking-based access control scheme for personal content. In 21st ACM Symposium on Operating Systems Principles. Work in Progress, October 2007.

[10] S. R. Kruk, A. Gzella, and S. Grzonkowski. D-FOAF distributed identity management based on social networks. In First Asian Semantic Web Conference, pages 140–154, 2006.

[11] J. Lindamood, R. Heatherly, M. Kantarcioglu, and B. Thuraisingham. Inferring private information using social network data. In 18th International World Wide Web Conference (WWW2009), 2009, ACM.

[12] P. Massa and P. Avesani. Controversial users demand local trust metrics: an experimental study on epinions.com community. In 25th American Association for Artificial Intelligence Conference (AAAI), 2005.

[13] G. McLachlan and T. Krishnan. The EM algorithm and extensions. Wiley series in probability and statistics.

[14] B. Monahan. Gnosis: HP labs modeling and simulation framework. Systems Security Lab, 2009.

[15] M. E. J. Newman. The mathematics of networks. In Blume, L.E., Durlauf, S.N. (eds.), The New Palgrave Encyclopedia of Economics, 2nd edn. Palgrave Macmillan, Basingstoke, 2008.

[16] D. Pelleg and A. W. Moore. X-means: Extending k-means with efficient estimation of the number of clusters. In ICML '00: Proceedings of the Seventeenth International Conference on Machine Learning, San Francisco, CA, USA, 2000.

[17] P. Resnick and R. Zeckhauser. The value of reputation on eBay: A controlled experiment. 9(2):79–101, 2006.

[18] S. E. Robertson, C. J. van Rijsbergen, and M. F. Porter. Probabilistic models of indexing and searching. In SIGIR '80: Proceedings of the 3rd annual ACM conference on Research and development in information retrieval, pages 35–56, Kent, UK, 1981. Butterworth & Co.

[19] E. Zheleva and L. Getoor. To join or not to join: the illusion of privacy in social networks with mixed public and private user profiles. In WWW '09: Proceedings of the 18th international conference on World wide web, pages 531–540, 2009. ACM.

[20] C.-N. Ziegler and J. Golbeck. Investigating interactions of trust and interest similarity. Decis. Support Syst., 43(2):460–475, 2007.