### Packet Rate and Stream Behavior

The packet rate exhibits a diurnal pattern, rising from approximately 0600 to 0900 and falling from around 1700 to 2000, before rising again in the evening. In contrast, the number of streams increased while the traffic rate decreased around midnight on Friday, October 1, 2004. This increase was not repeated over the weekend, suggesting it was a one-off event, possibly due to a database replication job involving many small files, rather than part of the regular daily pattern.

### Observations of Internet Stream Lifetimes

At regular three-hour intervals, we observed short, high spikes in the number of streams. Our network security team is investigating these spikes, which are believed to be caused by some form of network attack. Additionally, every day at 1630, a larger spike occurs. We have also noted other, less regular spikes, with the number of active streams reaching as high as 140,000. Figure 6 provides more detailed views of two such spikes.

### Packet and Active Stream Data

**Figure 6: Details of Figure 5 showing spike in streams at 1633 and step at 2120**

- **Local Time (Fri 1 Oct 04, NZST)**
  - 16:26 to 16:44
  - 21:16 to 21:34

- **Packet/s and Active Streams Count**
  - 100,000
  - 10,000
  - 1,000

### Usage Metering at Auckland

For usage accounting at Auckland, we aim to ignore streams with K or fewer packets. To determine an appropriate value for K, we plotted distributions of byte density versus stream size (in packets). Figure 7 shows these distributions for inbound and outbound byte-percentage distributions for ten-minute sample intervals from 2100 on Friday, October 1, 2004. For most intervals, ignoring streams with six or fewer packets in either direction seems feasible. However, one outbound trace, ending at 2120, had 29% of its bytes in streams with only one or two packets. Figure 6 indicates that at 2120, the number of active streams rose sharply.

**Table 1: Inbound and Outbound Traffic Rates (Mb/s) for Various Kinds of Traffic on Friday, October 1, 2004**

| Time | Inbound UDP | Non-Web | Web | SSL | Other | Outbound UDP | Non-Web | Web | SSL | Other |
|------|-------------|---------|-----|-----|-------|--------------|---------|-----|-----|-------|
| 2110 | 0.15        | 2.91    | 8.85| 0.51| 0.03  | 1.47         | 3.31    | 0.73| 0.03|       |
| 2120 | 1.66        | 10.15   | 0.52| 0.04|       | 0.92         | 3.34    | 0.85| 0.03|       |
| 2130 | 0.21        | 9.86    | 0.50| 1.09|       | 3.71         | 3.54    | 0.85| 0.07|       |

**Figure 7: Byte Density vs Packets in Stream for Three Hours at Auckland, from 2100 on Friday, October 1, 2004**

- **Cumulative % Bytes vs Stream Size (Packets)**
  - 0 to 100%
  - 0 to 40 packets

### Total Byte-Percentage Distributions

Given that the University of Auckland has about five times more inbound traffic bytes than outbound, we plotted the total (inbound + outbound) byte-percentage distributions for every ten-minute interval over October 1-2, 2004, resulting in Figure 8. This figure shows that short streams often contribute significantly to the total link bytes, indicating that we should not solely focus on large flows for our usage measurements.

**Figure 8: Total (Inbound+Outbound) Byte Density vs Packets in Stream at Auckland, October 1-2, 2004**

- **Cumulative % Bytes vs Stream Size (Packets)**
  - 0 to 100%
  - 0 to 40 packets

### Ignoring Short Streams at Auckland

Our observations suggest that on our link, intervals dominated by short streams are often due to network attacks. While important for security monitoring, these intervals are less critical for usage accounting. We decided to meter while ignoring streams with six or fewer packets (total in both directions).

We ran the meter with K = 6 for five days using our standard 'usage accounting' ruleset. All five days showed similar patterns, including regular three-hourly spikes and a daily spike at 1640. Figure 9 illustrates the packet rate, active streams, and flows for every second of Thursday, October 7, 2004. The packet rate and streams traces are similar to those in Figure 5, with the number of flows remaining stable and tracking the packet rate.

**Figure 9: Packet Rate, Active Streams, and Active Flows at One-Second Intervals at Auckland for Thursday, October 7, 2004**

- **NeTraMet Meter with K = 6**

**Figure 10: Detailed View of Figure 9 Showing Spike and Steps in Streams, and Sawtooth Variation in Flows**

- **Number of Active Flows**
  - Steady rise as new flows appear
  - Rapid fall when flows are read every ten minutes
  - Sawtooth behavior due to RTFM architecture

### Verification of Ignored Streams

To verify our estimate that ignoring streams with six or fewer packets would exclude between 5% and 10% of the total bytes, we modified NeTraMet to collect distributions of ignored packets and bytes as a function of stream size. Figure 11 shows one day of typical 'ignored' data, collected at five-minute intervals.

**Figure 11: Percent of Bytes and Packets Ignored at Five-Minute Intervals at Auckland, Measured Using K = 6**

- **Ignored Packet Percentage**
  - Generally varies between 2.5% and 8%
  - Average varies inversely with the average packet rate

- **Ignored Byte Percentage**
  - Between 0.5% and 2% for 95% of intervals
  - 10% to 30% during spikes in packet rate and active streams

### Conclusion

At Auckland, we frequently observe bursts of incoming 'attack' streams, which can dominate the traffic mix on our Internet gateway. Ignoring streams with six or fewer packets (K = 6) means that, in the long term, only about 2% of our total bytes are not measured as 'user' traffic. This approach significantly reduces the number of flows we need to create, read, store, and process.

However, for some traffic mixes, this sampling bias against small flows can distort inferences about aggregate traffic. We are continuing our investigation into stream behavior, particularly related to 'attack streams' (plague of dragonflies) events. These events have not been observed on the California backbone link, where traffic levels are higher and there is more statistical mixing.

An alternative approach, proposed in [7], adapts sampling parameters to the traffic in real time, avoiding bias against small flows and providing a true picture of the actual traffic load within its sampling limitations. Our approach may be more useful for accounting applications, as it preserves detail for all larger streams (which can be billed to users) while ignoring small 'attack' streams (which are overhead, not billable to users).

### Future Work

We are continuing to investigate the 'plague of dragonflies' events at Auckland. Improving our network attack detection ability by recognizing and reporting frequently occurring attack patterns will help. Summarizing large groups of small streams would also reduce the number of packets we ignore in our traffic monitoring.

At this stage, it is clear that NeTraMet can handle our network's data rate at 100 Mb/s. We are confident that this can be done without sampling techniques at 1 Gb/s.

### The Need for Ongoing Measurements

At the University of Auckland, we use NeTraMet for usage accounting and traffic analysis, Snort for security monitoring, and MRTG for traffic engineering. Each tool is specialized for its intended function, but there is little overlap. When an unusual event occurs, data from multiple tools provides different perspectives, enhancing our understanding and response.

We believe that every large network should continuously collect traffic data using several different tools. The effort required to support such monitoring is justified by the ability to investigate incidents promptly and gain insights into the network's performance and user service improvements.

### Acknowledgment

This work is supported by DARPA NMS Contract N66001-01-1-8909, NSF Award NCR-9711092 'CAIDA: Cooperative Association for Internet Data Analysis,' and The University of Auckland.

### References

1. C. Estan and G. Varghese, New Directions in Traffic Measurement and Accounting: Focusing on the Elephants, Ignoring the Mice, ACM Transactions on Computer Systems, August 2003.
2. N. Brownlee and M. Murray, Streams, Flows and Torrents, PAM2001, April 2001.
3. N. Brownlee, Using NeTraMet for Production Traffic Measurement, Intelligent Management Conference, IM2001, May 2001.
4. N. Brownlee and K. Claffy, Understanding Internet Stream Lifetimes: Dragonflies and Tortoises, IEEE Communications Magazine, October 2002.
5. K. Claffy, G. Polyzos, and H-W. Braun, A Parameterizable Methodology for Internet Traffic Flow Profiling, IEEE Journal on Selected Areas in Communications, 1995.
6. N. Brownlee, C. Mills, and G. Ruth, Traffic Flow Measurement: Architecture, RFC 2722, October 1999.
7. C. Estan, K. Keys, D. Moore, and G. Varghese, Building a Better NetFlow, SIGCOMM, September 2004.