### Entry Points in Bash Scripts

The following table (Table 3) lists the entry points identified in various Bash scripts. Each row corresponds to a specific script and line number, along with the source and target types.

| ID | Source Script:Line Number | Source Type | Target Type |
|----|---------------------------|-------------|-------------|
| 1  | /lib/udev/console-setup-tty:76 | udev t | initrc t    |
| 2  | /etc/rcS.d/S70x11-common:33,47 | initrc t | tty device t |
| 3  | /usr/lib/pm-utils/functions:30 | initrc t | tmp t       |
| 4  | /etc/NetM/dispatcher.d/01ifupdown:27,29 | NetworkManager t | initrc var run t |
| 5  | /etc/init/mounted-tmp.conf:44,45 | init t | tmp t       |

**Table 3: Entry points in Bash scripts.**

### Apache Entry Points Receiving Low-Integrity Data

The following table (Table 4) details the entry points in the Apache web server that receive low-integrity data. The table includes the source file and line number, object type accessed, description, and configuration option.

| ID | Source File:Line Number | Object Type Accessed | Description | Configuration Option |
|----|-------------------------|----------------------|-------------|---------------------|
| 1  | server/util.c:879        | httpd user htaccess t | Read user .htaccess file | AccessFileName      |
| 2  | server/core filters.c:155 | httpd t              | Read TCP socket | -                   |
| 3  | server/core filters.c:383 | httpd user content t | Read user HTML file | UserDir             |
| 4  | server/connection.c:153  | httpd t              | Read remaining TCP data | -                   |
| 5  | os/unix/unixd.c:410      | httpd user script exec t | Execute CGI user script | Script              |

**Table 4: Apache entry points receiving low-integrity data.**

We identified 30 entry points for the Apache web server, of which 5 received untrusted data. These entry points are listed in Table 4. Specifically, the entry points accessing local untrusted data (IDs 1, 3, and 5) have implications for security. For example, `httpd_user_htaccess_t` denotes the user-defined configuration file `.htaccess`, which has been associated with vulnerabilities such as Bugtraq IDs 8911, 11182, and 15177. Similarly, `httpd_user_content_t` refers to user-defined web pages served by Apache, and a vulnerability due to incorrect parsing of HTML files is BID 11471. Entry point 5, where Apache forks a child to execute a user-defined CGI script, involves an untrusted executable (BID 8275), which can be easily missed in manual analysis.

### Secure Shell Daemon (sshd)

Our tool was able to associate some entry points with the configuration options that control them. Different application configurations may expose different attack surfaces, and this knowledge is valuable for administrators to understand the impact of their configuration on the attack surface.

We conducted a study on the SSH daemon (sshd, v. 5.1p1) and found 78 entry points, of which 27 required filtering. Table 5 lists 14 of these entry points, including those opened by non-default configuration options.

| ID | Source File:Line Number | Object Type Accessed | Description | Configuration Option |
|----|-------------------------|----------------------|-------------|---------------------|
| 1* | msg.c:72                | initrc var run t     | Master-slave Unix socket read | UsePrivilegeSeparation |
| 2  | msg.c:84                | user home ssh t      | Unix socket read | -                   |
| 3  | sshd.c:442              | user home ssh t      | Unix socket read | -                   |
| 4  | dispatch.c:92           | user home ssh t      | TCP socket read | -                   |
| 5  | packet.c:1005           | sshd t               | TCP socket read | -                   |
| 6  | misc.c:627              | sshd t               | TCP socket read | -                   |
| 7* | monitor wrap.c:123      | sshd t               | ~/.ssh/authorized_keys file read | AuthorizedKeysFile |
| 8* | channels.c:1496         | sshd t               | Pseudo-terminal read | -                   |
| 10 | serverloop.c:380        | sshd t               | FIFO file read | -                   |
| 11 | loginrec.c:1423         | sshd t               | Read utmp | -                   |
| 12 | session.c:1001          | user home ssh t      | ~/.ssh/environment file read | PermitUserEnvironment |
| 13* | hostfile.c:222          | sshd t               | ~/.ssh/known_hosts file read | IgnoreUserKnownHosts |
| 14* | auth-rhosts.c:82        | sshd t               | ~/.ssh/rhosts file read | IgnoreRhosts |

**Table 5: sshd entry points that may receive low-integrity data. Entry points marked with * are in the master part of the privilege-separated daemon.**

OpenSSH has been re-engineered to separate privileged operations from unprivileged ones to prevent vulnerabilities. Our tool identified an additional entry point (ID 7) that reads the `authorized_keys` file in the `.ssh/` directory of users. Since this file is modifiable by users, it could be of low integrity, and our tool correctly flagged it. This entry point was missed in a manual analysis for configuring SELinux policies to enforce privilege separation, highlighting the importance of automated techniques.

### Icecat

We also performed a study on the GNU version of Firefox, Icecat, to see if we could find any issues using our tool. We found 18 entry points for Icecat, of which 4 accessed untrusted data. One entry point searched the `user_home_dir_t` directory, whose code was in the dynamic loader/linker library `ld.so`. We suspected an untrusted library search path and confirmed that this was the case. This could be exploited by an adversary-controlled library downloaded to the user's home directory. The developers accepted our patch [5].

### Performance

Micro- and macro-benchmarks showed acceptable performance overheads for online logging and enforcement. For example, the `stat` system call took an unmodified kernel 8.5 µs on average. Overhead for checking if the subject was trusted and the object was untrusted added an additional 0.2 µs. If the access was untrusted, the logging mode added an overhead of 1 µs, while the enforcement mode added an overhead of 0.1 µs. The sshd test suite ran in 318.29 s on the unmodified kernel, whereas configured with an integrity wall for sshd with both enforcement and logging enabled, it took 318.81 s.

### Related Work

Taint tracking has been used to track the flow of untrusted input to a program and find places where it may affect the integrity of the program. Tracking can be done for whole systems or specific processes. However, these systems often require manual specifications of taint entry points. Our tool provides the origin input to taint tracking systems, making it more comprehensive.

Manadhata et al. [17] calculate an attack surface metric for programs based on methods, channels, and data. They prepare a list of input and output library calls from `libc` to determine the methods. While this is useful for a first approximation, it does not distinguish between entry points receiving high-integrity input and those receiving low-integrity input. In our analysis, only a small percentage (13.8%) of the entry points were found to receive data of low integrity. Hence, a simple listing of all such library methods may not give a true picture of the work required to secure an application.

Several practical integrity models, such as UMIP [16] and PPI [31], identify trusted subjects that need to maintain their integrity on receiving low-integrity input. Although their goals differ from ours, they also build integrity walls. UMIP builds integrity walls system-wide based on the DAC policy, while PPI uses package dependencies. However, they identify trusted processes as a whole and do not identify entry points within a process, which we have seen to be necessary. Further, they only consider system-wide integrity walls, not per-application.

Flume [15] allows entry point-level control but leaves the specification of the policy up to the user, who must decide which entry points to allow to receive untrusted input. Such a policy could benefit from knowledge of the attack surface. Shankar et al. [29] identify the need to verify input filtering for entry points that receive low-integrity input. However, they identify entry points manually and missed an entry point in sshd that we identified using our automated approach.

Bouncer [10] uses knowledge of vulnerabilities to generate filters automatically. It symbolically executes the vulnerable program to build a filter that covers the particular attack and generalizes the filter to cover other unauthorized inputs without preventing legitimate function. EXE [6] automatically generates inputs that will crash a program. Both systems would benefit from knowledge of the attack surface of a program.

System call interposition [24, 12, 1, 3, 11] could also be leveraged to monitor objects accessed by a program instead of doing it in the kernel. However, as noted in Section 3.2, maintaining a list of system calls, knowing the sets of objects accessed by each call, and fetching the security contexts of these objects from the kernel would duplicate information readily available in the kernel. Additionally, system call interposition has high overhead and is challenging to implement system-wide.

### Conclusion

In this paper, we introduced an approach to identify attack surfaces in programs with respect to an integrity wall constructed from the system’s security policy. We implemented a system in the Linux kernel that enabled precise identification of attack surface entry points, even in interpreter scripts. Our results indicate that accurate location of attack surfaces requires considering a program in relation to the system’s access control policy. For the system TCB in an Ubuntu 10.04.2 Desktop system, we obtained an attack surface of 81 entry points, some subtle; 35 of these have had past vulnerabilities, many recently. Our attack surface indicated an entry point in sshd that was missed by earlier manual analysis and an entry point in the GNU Icecat browser that was due to an untrusted search path bug. Further, our attack surface helped us find a bug in an entry point of the system TCB of Ubuntu that has been around for several years. We envision that our tool will be used on new programs to identify attack surfaces before an adversary does and prepare defenses, moving us away from the current penetrate-and-patch paradigm.

### References

[1] A. Acharya et al. MAPbox: Using parameterized behavior classes to confine untrusted applications. In USENIX Security, 2000.
[2] J. P. Anderson. Computer Security Technology Planning Study, Volume II. Technical Report ESD-TR-73-51, Deputy for Command and Management Systems, HQ Electronics Systems Division (AFSC), L. G. Hanscom Field, Bedford, MA, October 1972.
[3] A. Berman et al. TRON: Process-specific file protection for the UNIX operating system. In USENIX TC ’95, 1995.
[4] E. Bertino et al. A system to specify and manage multipolicy access control models. In POLICY, 2002.
[5] run-icecat.sh possible vulnerability. http://lists.gnu.org/archive/html/bug-gnuzilla/2011-06/msg00006.html.
[6] C. Cadar el. al. EXE: Automatically Generating Inputs of Death. ACM Trans. Inf. Syst. Secur., 2008.
[7] H. Chen et al. Analyzing and Comparing the Protection Quality of Security Enhanced Operating Systems. In NDSS, 2009.
[8] J. Chow et al. Understanding data lifetime via whole system simulation. In USENIX Security ’04, 2004.
[9] D. D. Clark et al. A Comparison of Military and Commercial Security Policies. In IEEE SSP ’87, 1987.
[10] M. Costa et al. Bouncer: securing software by blocking bad input. In SOSP ’07, 2007.
[11] T. Garfinkel et al. Ostia: A delegating architecture for secure system call interposition. In NDSS ’04, 2004.
[12] I. Goldberg et al. A secure environment for untrusted helper applications. In USENIX Security ’96, 1996.
[13] M. Howard et al. Measuring Relative Attack Surfaces. In WADIS ’03, 2003.
[14] T. Jaeger, R. Sailer, and X. Zhang. Analyzing integrity protection in the SELinux example policy. In Proceedings of the 12th USENIX Security Symposium, pages 59–74, Aug. 2003.
[15] M. N. Krohn et al. Information flow control for standard OS abstractions. In SOSP ’07, 2007.
[16] N. Li et al. Usable Mandatory Integrity Protection For Operating Systems. In IEEE SSP ’07, 2007.
[17] P. Manadhata et al. An Approach to Measuring A System’s Attack Surface. Technical Report CMU-CS-07-146, CMU, 2007.
[18] P. K. Manadhata et al. An attack surface metric. IEEE Trans. Software Eng., 2011.
[19] J. Newsome et al. Dynamic taint analysis for automatic detection, analysis, and signature generation of exploits on commodity software. In NDSS, 2005.
[20] S. Noel et al. Efficient minimum-cost network hardening via exploit dependency graphs. In ACSAC, 2003.
[21] Novell. AppArmor Linux Application Security. http://www.novell.com/linux/security/apparmor/.
[22] SELinux. http://www.nsa.gov/selinux.
[23] X. Ou et al. A scalable approach to attack graph generation. In CCS ’06, New York, NY, USA, 2006.
[24] N. Provos. Improving host security with system call policies. In USENIX Security ’02, 2002.
[25] N. Provos et al. Preventing privilege escalation. In USENIX Security ’03, 2003.
[26] F. Qin et al. LIFT: A Low-Overhead Practical Information Flow Tracking System for Detecting Security Attacks. In MICRO 39, 2006.
[27] S. Rueda, D. King, and T. Jaeger. Verifying Compliance of Trusted Programs. In Proceedings of the 17th USENIX Security Symposium, 2008.
[28] SecurityFocus. BugTraq Mailing List. http://www.securityfocus.com/bid/1334.
[29] U. Shankar, T. Jaeger, and R. Sailer. Toward Automated Information-Flow Integrity Verification for Security-Critical Applications. In Proceedings of the 2006 ISOC Networked and Distributed Systems Security Symposium, February 2006.
[30] O. Sheyner et al. Automated generation and analysis of attack graphs. In IEEE SSP ’02, 2002.
[31] W. Sun et al. Practical Proactive Integrity Preservation: A Basis for Malware Defense. In IEEE SSP ’08, 2008.
[32] Sun Microsystems. Trusted Solaris Operating Environment. http://www.sun.com.
[33] Tresys. SETools - Policy Analysis Tools for SELinux. http://oss.tresys.com/projects/setools.
[34] Tresys. SETools - Policy Analysis Tools for SELinux. Available at http://oss.tresys.com/projects/setools.
[35] R. N. M. Watson. TrustedBSD: Adding trusted operating system features to FreeBSD. In USENIX ATC ’01 FREENIX Track, 2001.
[36] C. Wright et al. Linux Security Modules: General Security Support for the Linux Kernel. In USENIX Security ’02, 2002.
[37] N. Zeldovich et al. Making Information Flow Explicit in HiStar. In OSDI ’06, 2006.