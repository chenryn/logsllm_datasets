### Memory and System Configuration
- **Linux Kernel 2.6.8**: Pentium IV 2.0 GHz, 512 MB RAM (Replica)
- **Windows XP Pro SP2**: Pentium IV 2.0 GHz, 512 MB RAM (Replica)
- **Proxy**: Windows XP Pro SP2, Pentium IV 2.2 GHz, 512 MB RAM (Client)
- **Linux Kernel 2.6.11**: Pentium IV 3.0 GHz, 1 GB RAM

### Performance Metrics
We are primarily interested in the request throughput and latency observed by the client (C) in five tests.

### Test Descriptions
1. **Baseline Test**:
   - Both L (Linux) and W (Windows) send their responses to the proxy P.
   - P performs output voting on these responses before responding to the client.
   - No system call traces are collected, and no behavioral distance is calculated.

2. **System Call Collection Test**:
   - L and W capture the system calls made by the web server processes/threads.
   - The system call information is sent to another machine (not P) for logging and potential offline behavioral-distance calculations.
   - This test includes the costs of collecting and sending system call information but not the cost of calculating behavioral distances.

3. **Online Behavioral Distance Calculation Test**:
   - The system call information is sent to the proxy P for online behavioral distance calculation.
   - P computes the behavioral distance and performs output voting before responding to the client.

4. **Behavioral Distance Caching Test**:
   - The results of each behavioral distance calculation are cached at P.
   - If the same system call sequences are received from L and W in the future, the behavioral distance does not need to be recalculated.
   - This test evaluates the performance improvement due to caching.

5. **Single Server Performance Test**:
   - Only W and C are used to evaluate the performance of an individual server.
   - Neither output voting nor behavioral distance is used.

### Results
- **Test 1 (Baseline)**: Serves as a reference point with only output voting performed by P.
- **Test 2 (System Call Collection)**: Shows a minimal overhead of capturing and transporting system call information, with roughly 1% reduction in throughput and 0.03 milliseconds of additional latency.
- **Test 3 (Online Behavioral Distance Calculation)**: Demonstrates substantial overhead due to the HMM-based behavioral distance calculation, significantly increasing request processing time.
- **Test 4 (Behavioral Distance Caching)**: Reduces the overhead of behavioral distance calculation through caching. By the end of the test, there is less than a 20% throughput loss and 0.59 milliseconds of additional latency.
- **Test 5 (Single Server Performance)**: Evaluates the performance of an individual server without output voting or behavioral distance, showing that L and W are underutilized by approximately 25% compared to the fourth test.

### Conclusion
In this paper, we present a new algorithm for computing behavioral distance between processes. Our approach addresses shortcomings in prior techniques by better accounting for system-call orderings while maintaining comparable performance. Empirical tests suggest that our algorithm provides strong defense against mimicry attacks and significantly reduces false-alarm rates. We believe this algorithm is a significant step toward practical use of behavioral distance in anomaly detection, particularly in fault- and intrusion-tolerant architectures that redundantly execute requests on multiple diverse platforms.

### References
1. M. Abd-El-Malek, G. R. Ganger, G. R. Goodson, M. K. Reiter, and J. J. Wylie. Fault-scalable Byzantine fault-tolerant services. In Proceedings of the 20th ACM Symposium on Operating Systems Principles, pages 59–74, October 2005.
2. L. Alvisi, D. Malkhi, E. Pierce, and M. K. Reiter. Fault detection for Byzantine quorum systems. IEEE Transactions on Parallel Distributed Systems, 12(9), September 2001.
3. L. E. Baum and T. Petrie. Statistical inference for probabilistic functions of finite state Markov chains. Ann. Math. Statist., 37:1554–1563, 1966.
4. S. Bhatkar, A. Chaturvedi, and R. Sekar. Dataflow anomaly detection. In Proceedings of the 2006 IEEE Symposium on Security and Privacy, 2006.
5. R. W. Buskens and R. P. Bianchini, Jr. Distributed on-line diagnosis in the presence of arbitrary faults. In Proceedings of the 23rd International Symposium on Fault-Tolerant Computing, pages 470–479, June 1993.
6. C. Cachin and J. A. Poritz. Secure intrusion-tolerant replication on the Internet. In Proceedings of the 2002 International Conference on Dependable Systems and Networks, 2002.
7. M. Castro and B. Liskov. Practical Byzantine fault tolerance and proactive recovery. ACM Transactions on Computer Systems, 20(4), November 2002.
8. M. Castro, R. Rodrigues, and B. Liskov. BASE: Using abstraction to improve fault tolerance. ACM Transactions on Computer Systems, 21(3), August 2003.
9. L. Chen and A. Avizienis. N-version programming: A fault-tolerance approach to reliability of software operation. In Proceedings of the 8th International Symposium on Fault-Tolerant Computing, pages 3–9, 1978.
10. S. Cho and S. Han. Two sophisticated techniques to improve HMM-based intrusion detection systems. In Proceedings of the 6th International Symposium on Recent Advances in Intrusion Detection (RAID 2003), 2003.
11. B. Cox, D. Evans, A. Filipi, J. Rowanhill, W. Hu, J. Davidson, J. Knight, A. Nguyen-Tuong, and J. Hiser. N-variant systems – A secretless framework for security through diversity. In Proceedings of the 15th USENIX Security Symposium, August 2006.
12. R. I. A. Davis, B. C. Lovell, and T. Caelli. Improved estimation of Hidden Markov Model parameters from multiple observation sequences. In Proceedings of the 16th International Conference on Pattern Recognition (ICPR 2002), 2002.
13. H. H. Feng, J. T. Griffin, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing sensitivity in static analysis for intrusion detection. In Proceedings of the 2004 IEEE Symposium on Security and Privacy, 2004.
14. H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong. Anomaly detection using call stack information. In Proceedings of the 2003 IEEE Symposium on Security and Privacy, 2003.
15. S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff. A sense of self for Unix processes. In Proceedings of the 1996 IEEE Symposium on Security and Privacy, 1996.
16. D. Gao, M. K. Reiter, and D. Song. Gray-box extraction of execution graph for anomaly detection. In Proceedings of the 11th ACM Conference on Computer & Communication Security, 2004.
17. D. Gao, M. K. Reiter, and D. Song. On gray-box program tracking for anomaly detection. In Proceedings of the 13th USENIX Security Symposium, 2004.
18. D. Gao, M. K. Reiter, and D. Song. Behavioral distance for intrusion detection. In Proceedings of the 8th International Symposium on Recent Advances in Intrusion Detection (RAID 2005), 2005.
19. J. T. Griffin, S. Jha, and B. P. Miller. Detecting manipulated remote call streams. In Proceedings of the 11th USENIX Security Symposium, 2002.
20. J. T. Griffin, S. Jha, and B. P. Miller. Efficient context-sensitive intrusion detection. In Proceedings of Symposium on Network and Distributed System Security, 2004.
21. C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detection of anomalous system call arguments. In Proceedings of the 8th European Symposium on Research in Computer Security (ESORICS 2003), 2003.
22. L. Lamport. The implementation of reliable distributed multiprocess systems. Computer Networks, 2:95–114, 1978.
23. I. M. Meyer and R. Durbin. Comparative ab initio prediction of gene structures using pair HMMs. Oxford University Press, 2002.
24. L. Pachter, M. Alexandersson, and S. Cawley. Applications of generalized pair Hidden Markov Models to alignment and gene finding problems. Computational Biology, 9(2), 2002.
25. L. R. Rabiner. A tutorial on Hidden Markov Models and selected applications in speech recognition. In Proceedings of IEEE, February 1989.
26. M. K. Reiter. Secure agreement protocols: Reliable and atomic group multicast in Rampart. In Proceedings of the 2nd ACM Conference on Computer and Communication Security, pages 68–80, November 1994.
27. F. B. Schneider. Implementing fault-tolerant services using the state machine approach: A tutorial. ACM Computing Surveys, 22(4):299–319, December 1990.
28. R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast automaton-based method for detecting anomalous program behaviors. In Proceedings of the 2001 IEEE Symposium on Security and Privacy, 2001.
29. P. H. Sellers. On the theory and computation of evolutionary distances. SIAM J. Appl. Math., 26:787–793, 1974.
30. K. Shin and P. Ramanathan. Diagnosis of processors with Byzantine faults in a distributed computing system. In Proceedings of the 17th International Symposium on Fault-Tolerant Computing, pages 55–60, 1987.
31. K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions: From the abnormal to the normal and beyond. In Proceedings of the 5th International Workshop on Information Hiding, October 2002.
32. D. Wagner and D. Dean. Intrusion detection via static analysis. In Proceedings of the 2001 IEEE Symposium on Security and Privacy, 2001.
33. D. Wagner and P. Soto. Mimicry attacks on host-based intrusion detection systems. In Proceedings of the 9th ACM Conference on Computer and Communications Security, 2002.
34. C. Warrender, S. Forrest, and B. Pearlmutter. Detecting intrusions using system calls: alternative data models. In Proceedings of the 1999 IEEE Symposium on Security and Privacy, 1999.
35. A. Wespi, M. Dacier, and H. Debar. Intrusion detection using variable-length audit trail patterns. In Proceedings of the 2000 Recent Advances in Intrusion Detection, 2000.
36. J. Yin, J. Martin, A. Venkataramani, L. Alvisi, and M. Dahlin. Separating agreement from execution for Byzantine fault tolerant services. In Proceedings of the 19th ACM Symposium on Operating System Principles, October 2003.

### Appendix: Updating the bi Parameters of λ
The idea of updating the \( b_i \) parameters of \( \lambda \) is similar to updating the \( a_i \) parameters (see Section 4.3). Here, we need to calculate the expected number of times \( \lambda \) emits observable symbol \([x, y]\) at state \( q_i \) when generating \([S_1, S_2]\).

To compute this expectation, we define a conditional probability, \( \zeta([x, y], u, v, i) \), as follows:

\[
\zeta([x, y], u, v, i) = \Pr_{\lambda} \left( \text{State}_t = q_i \land \text{Out}_t^1 = \text{Seq}(x) \land \text{Out}_t^2 = \text{Seq}(y) \mid \text{Out}_{\leq t}^1 = \text{Pre}(S_1, u) \land \text{Out}_{\leq t}^2 = \text{Pre}(S_2, v) \right)
\]

where

\[
\text{Seq}(x) = 
\begin{cases} 
\text{sequence of system calls from } C_1 \text{ if } x \neq \sigma \\
\emptyset \text{ if } x = \sigma 
\end{cases}
\]

\[
\gamma(u, v, i) = \sum_{[x, y]} \zeta([x, y], u, v, i)
\]

We can calculate \( \zeta([x, y], u, v, i) \) as follows:

\[
\zeta([x, y], u, v, i) = \frac{\alpha(u-1, v, j) a_{j, i} b_i([x, \sigma]) \beta(u, v, i) + \alpha(u, v-1, j) a_{j, i} b_i([\sigma, y]) \beta(u, v, i) + \alpha(u-1, v-1, j) a_{j, i} b_i([x, y]) \beta(u, v, i)}{\Pr_{\lambda}([S_1, S_2])}
\]

This formulation allows us to update the \( b_i \) parameters based on the observed system call sequences.