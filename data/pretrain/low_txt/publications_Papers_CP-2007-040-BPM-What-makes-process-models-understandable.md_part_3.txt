# Section 4.4: Metrics and Score

In this section, we describe the search for secondary factors that influence the understandability of process models. As detailed in Section 3.2, a wide range of potential factors was considered. To evaluate their impact on model understandability, we calculated the average score for each model based on responses from 73 participants and then determined Pearson correlation coefficients with all potential factors.

The signs of the correlation coefficients for #or joins, density, average connector degree, mismatch, and connector heterogeneity align with the hypothesized influences as listed in Table 1. However, only the correlation coefficients for density and average connector degree are significant at a 95% confidence level (see Table 2).

**Table 2: Factors with Expected Impact on Understandability**

| Factor                | Correlation Coefficient | P-value   |
|-----------------------|-------------------------|-----------|
| #or joins             | -0.330                  | 0.295     |
| Density               | -0.618*                 | 0.032*    |
| Average connector degree | -0.674*              | 0.016*    |
| Mismatch              | -0.438                  | 0.154     |
| Connector heterogeneity | -0.312                | 0.323     |

*Significant at 95% confidence level

To further examine the value of these factors in explaining differences in scores, we developed various linear regression models. It should be noted, however, that the number of 12 different model observations is quite low for this purpose. We compared all 31 (2^5 - 1) possible linear regression models that consider non-empty subsets of the factors shown in Table 2. The adjusted R² statistic was used to differentiate between the regression models, measuring how well each model explains the variability in the scores. Within this setting, no multivariate regression model had acceptable t-values.

The best adjusted R² statistic is 45%, corresponding to the regression model that uses average connector degree—one of the factors significantly correlated with the average score. For this regression model, the Durbin-Watson statistic indicates no serial autocorrelation in the residuals at the 95% confidence level. Figure 6 shows a plot of the fitted model values using this regression model, where the outlying model L can be clearly identified at the bottom right corner.

Despite the small number of models, the two factors most convincingly related to model understandability both concern the number of arcs in a process model. The average connector degree measures the model’s average number of incoming/outgoing arcs per routing element, while density gives the ratio of existing arcs to the maximum possible number of arcs between the nodes in the model (i.e., when it would be completely connected). Both factors suggest that a relatively high number of arcs negatively affects a model’s understandability.

## Section 4.5: Expert Interviews

To validate our results, we interviewed 12 professional process modelers regarding the insights gained from our questionnaire. On average, this group possessed over 10 years of expertise in developing process models, primarily for documentation purposes, though most had experience with enactment models as well. The professionals were employed in 7 different companies, including four consultancy firms, two financial institutions, and one utilities company.

Regarding personal factors, the experts emphasized the importance of subjects' analytical skills and visual perceptiveness in understanding process models. In addition to these mental faculties, both modeling experience and familiarity with the modeling technique were frequently mentioned as positive influences. While the former aspect is supported by our questionnaire findings, we have no direct support for the latter.

When asked whether users can accurately assess their own ability to understand process models, half of the experts thought so, while the other half disagreed. Among those who agreed, almost all cited modeling experience and familiarity with the modeling technique as important conditional factors. One expert from the opposing group stated that “people tend to overestimate themselves, particularly men.” Interestingly, one respondent indicated that people generally can understand what a model intends to communicate but find it difficult to determine if the model is completely correct. This suggests that self-assessment regarding model understandability is problematic, consistent with our findings.

Finally, experts indicated a decreasing relevance of (a) model-related factors, (b) person-related factors, and (c) domain knowledge for understanding process models. The most frequently mentioned model-related factors positively influencing understandability were unambiguity (7 times), simplicity (4 times), structuredness (4 times), and modularity (4 times). Less-mentioned factors, such as the positive effects of textual support (well-chosen textual descriptions of model elements and textual context information, 3 times each), were also interesting. Some of these factors overlap with those considered in our study (e.g., simplicity and structuredness), while others provide avenues for further research (e.g., modularity and textual support).

## Section 5: Conclusions

This research aimed to develop a better understanding of the factors that make process models understandable for humans. Focusing on the relationships between personal and model characteristics (questions 1 and 2), our findings suggest that personal factors do influence the ability to understand process models. Specifically, the amount of theoretical modeling knowledge of the subjects appears to play a role. However, respondents were not capable of accurate self-assessment regarding their modeling proficiency.

Regarding model characteristics, our questionnaire findings underscore the importance of model size in model understandability. Small variations between models can lead to significant differences in comprehensibility, indicating that secondary explanatory factors are still needed. From our analysis of a wide set of candidate factors, the average connector degree is the most convincing factor related to model understandability, followed by model density. Both factors highlight the negative effect of a relatively high number of arcs on a model’s understandability.

To counter the potentially limited validity of an experiment involving students, we interviewed several experienced process modelers. Their opinions generally supported our findings and generated additional factors for future investigation. Our research has limitations, particularly the small set of models and participants. Future replications with larger sets will allow us to investigate the impact of secondary factors in greater detail. Other directions for future research follow logically from the research questions we did not address yet. While we tried to neutralize the influences of modeling purpose, domain knowledge, modeling language, and layout strategy, these issues require further exploration.

## References

1. Hoppenbrouwers, S., Proper, H., van der Weide, T.: A Fundamental View on the Process of Conceptual Modeling. In: Conceptual Modeling – ER 2005, 24th International Conference on Conceptual Modeling. Volume 3716 of Lecture Notes in Computer Science. (2005) 128–143
2. Becker, J., Rosemann, M., Uthmann, C.: Guidelines of Business Process Modeling. In: van der Aalst, W., Desel, J., Oberweis, A., eds.: Business Process Management. Models, Techniques, and Empirical Studies. Springer, Berlin et al. (2000) 30–49
3. Moody, D.: Theoretical and practical issues in evaluating the quality of conceptual models: current state and future directions. Data & Knowledge Engineering 55 (2005) 243–276
4. Davies, I., Green, P., Rosemann, M., Indulska, M., Gallo, S.: How do practitioners use conceptual modeling in practice? Data & Knowledge Engineering 58 (2006) 358–380
5. Mendling, J., Moser, M., Neumann, G., Verbeek, H., Dongen, B., Aalst, W.: Faulty EPCs in the SAP Reference Model. In: Dustdar, S., J.F., Sheth, A., eds.: Proceedings of BPM 2006. Volume 4102 of Lecture Notes in Computer Science., Vienna, Austria, Springer-Verlag (2006) 451–457
6. Mendling, J., Moser, M., Neumann, G., Verbeek, H., Dongen, B., Aalst, W.: A Quantitative Analysis of Faulty EPCs in the SAP Reference Model. BPM Center Report BPM-06-08, BPMCenter.org (2006)
7. Simon, H.: Sciences of the Artificial. 3rd edn. The MIT Press (1996)
8. Mendling, J.: Detection and Prediction of Errors in EPC Business Process Models. PhD thesis, Vienna University of Economics and Business Administration (2007)
9. Lindland, O.I., Sindre, G., Sølvberg, A.: Understanding quality in conceptual modeling. IEEE Software 11 (1994) 42–49
10. Krogstie, J., Sindre, G., Jørgensen, H.: Process models representing knowledge for action: a revised quality framework. European Journal of Information Systems 15 (2006) 91–102
11. Moody, D., Sindre, G., Brasethvik, T., Sølvberg, A.: Evaluating the quality of process models: Empirical testing of a quality framework. In: Spaccapietra, S., March, S., Kambayashi, Y., eds.: Conceptual Modeling - ER 2002, 21st International Conference on Conceptual Modeling. Volume 2503 of Lecture Notes in Computer Science., Springer (2002) 380–396
12. Int. Standards Org. (ISO): Information technology - software product evaluation - quality characteristics and guidelines for their use. ISO/IEC IS 9126 (1991)
13. Güceglioğlu, A.S., Demirörs, O.: Using software quality characteristics to measure business process quality. In: van der Aalst, W., Benatallah, B., Casati, F., Curbera, F., eds.: Business Process Management, 3rd International Conference, BPM 2005, Nancy, France, September 5-8, 2005, Proceedings. Volume 3649 of Lecture Notes in Computer Science (LNCS)., Springer Verlag (2005) 374–379
14. Gemino, A., Wand, Y.: Evaluating modeling techniques based on models of learning. Commun. ACM 46 (2003) 79–84
15. Lee, G., Yoon, J.M.: An empirical study on the complexity metrics of Petri nets. Microelectronics and Reliability 32 (1992) 323–329
16. Nissen, M.: Redesigning reengineering through measurement-driven inference. MIS Quarterly 22 (1998) 509–534
17. Morasca, S.: Measuring attributes of concurrent software specifications in Petri nets. In: METRICS’99: Proceedings of the 6th International Symposium on Software Metrics, Washington, DC, USA, IEEE Computer Society (1999) 100–110
18. Reijers, H., van der Feesten, I.: Cohesion and coupling metrics for workflow process design. In: Desel, J., Pernici, B., Weske, M., eds.: Business Process Management: Second International Conference, BPM 2004. Proceedings. Volume 3080 of Lecture Notes in Computer Science., Springer (2004) 290–305
19. Cardoso, J.: Evaluating Workflows and Web Process Complexity. In: Workflow Handbook 2005. Future Strategies, Inc., Lighthouse Point, USA (2005) 284–290
20. Balasubramanian, S., Gupta, M.: Structural metrics for goal-based business process design and evaluation. Business Process Management Journal 11 (2005) 680–694
21. Canfora, G., García, F., Piattini, M., Ruiz, F., Visaggio, C.: A family of experiments to validate metrics for software process models. Journal of Systems and Software 77 (2005) 113–129
22. Aguilar, E.R., Ruiz, F., García, F., Piattini, M.: Towards a Suite of Metrics for Business Process Models in BPMN. In: Manolopoulos, Y., Filipe, J., Constantopoulos, P., Cordeiro, J., eds.: ICEIS 2006 - Proceedings of the Eighth International Conference on Enterprise Information Systems (III). (2006) 440–443
23. Laue, R., Gruhn, V.: Complexity metrics for business process models. In: Abramowicz, W., Mayr, H.C., eds.: 9th International Conference on Business Information Systems (BIS 2006). Volume 85 of Lecture Notes in Informatics. (2006) 1–12
24. Cardoso, J.: Process control-flow complexity metric: An empirical validation. In: Proceedings of IEEE International Conference on Services Computing (IEEE SCC 06), Chicago, USA, September 18-22, IEEE Computer Society (2006) 167–173
25. Rosemann, M., Recker, J., Indulska, M., Green, P.: A study of the evolution of the representational capabilities of process modeling grammars. In: Dubois, E., Pohl, K., eds.: Advanced Information Systems Engineering, 18th International Conference, CAiSE 2006, Luxembourg, Luxembourg, June 5-9, 2006, Proceedings. Volume 4001 of Lecture Notes in Computer Science., Springer (2006) 447–461
26. Agarwal, R., Sinha, A.P.: Object-oriented modeling with UML: a study of developers’ perceptions. Commun. ACM 46 (2003) 248–256
27. Sarshar, K., Loos, P.: Comparing the control-flow of EPC and Petri net from the end-user perspective. In: Aalst, W., Benatallah, B., Casati, F., Curbera, F., eds.: Business Process Management, 3rd International Conference, BPM 2005, Nancy, France, September 5-8, 2005, Proceedings. LNCS 3649 (2005) 434–439
28. Lange, C., Chaudron, M.: Effects of defects in UML models: an experimental investigation. In: Osterweil, L., Rombach, H., Soffa, M., eds.: 28th International Conference on Software Engineering (ICSE 2006), Shanghai, China, May 20-28, 2006, ACM (2006) 401–411
29. Mendling, J., Aalst, W.: Towards EPC Semantics based on State and Context. In: Nuettgens, M., Rump, F.J., Mendling, J., eds.: Proceedings of the 5th GI Workshop on Business Process Management with Event-Driven Process Chains (EPK 2006), Vienna, Austria, German Informatics Society (2006) 25–48
30. Mendling, J., Aalst, W.: Formalization and Verification of EPCs with OR-Joins Based on State and Context. In: Proceedings of the 19th Conference on Advanced Information Systems Engineering (CAiSE 2007). Lecture Notes in Computer Science, Trondheim, Norway, Springer-Verlag (2007)
31. Siegel, S., Castellan, N.J.: Nonparametric Statistics for the Behavioral Sciences. 2nd edn. McGraw Hill (1988)
32. Kendall, M.: Rank Correlation Methods. 4th edn. Griffin (1970)
33. Aalst, W.: Workflow Verification: Finding Control-Flow Errors Using Petri-Net-Based Techniques. In: Business Process Management. Volume LNCS 1806. Springer Verlag (2000) 161–183