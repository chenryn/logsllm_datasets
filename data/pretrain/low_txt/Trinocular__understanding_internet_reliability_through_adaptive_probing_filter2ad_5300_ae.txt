### 7.3 Case Studies of Internet Outages

In this section, we will examine several notable instances where internet outages made global news. Systematic measurement of these outages can provide valuable insights into the scope of the problems and the speed of recovery. Where possible, we visualize outages by clustering blocks based on their similarity in outage timing [26] and color-coding them according to their geolocation.

#### 7.3.1 Political Outages: Egypt and Libya

Two significant outages in 2011 were caused by political events. In Egypt, most routes were withdrawn on January 27, 2011, during the 2011 Egyptian Revolution. In Libya, all routable prefixes were withdrawn on February 18, 2011, during the Libyan Revolution. We re-examined surveys covering these events (S 38c began on January 27, 2011, just after the Egyptian outage, and ran for three weeks to cover Libya).

We have strong evidence of the Egyptian outage, with 19 /24 blocks out of Egypt's 22k in the survey (visualization omitted due to space constraints). The end of the observed outage is confirmed by news reports and BGP data analysis. 

Libya’s internet footprint was much smaller, with only 1168 /24 blocks as of March 2011. Only one block was in the dataset, and it was too sparse (only 4 active addresses) to apply Trinocular. However, Trinocular’s lightweight probing could have covered the entire analyzable internet. Had it been active at the time, we would have tracked 36% of Libya’s 1168 blocks and likely detected the outage.

#### 7.3.2 March 2011 Japanese Earthquake

In survey S 39c, we observed a Japanese internet outage mid-day (UTC) on March 11, 2011. This event was confirmed as an undersea cable outage caused by the Tōhoku earthquake [22]. We marked a vertical line 30 minutes before the earthquake to avoid obscuring transition times. Individual blocks did not cluster well due to varying recovery times, but the outage is visible as a large uptick in the marginal distribution.

Unlike most human-caused outages, both the start and recovery from this outage varied in time. For most blocks, the outage began at the exact time of the earthquake, as shown by the sudden large jump in the marginal distribution less than six hours into March 11, 2011. For some, it occurred two hours later. Recovery for most blocks occurred within ten hours, but a few remained down for several days.

This dataset also shows strong evidence of diurnal outages in Asia, as seen in the green and white banding in the low 300 blocks. These diurnal outages make Trinocular’s outage rate slightly higher than our previous approach [26]. We show that these blocks come and go, meeting our definition of an outage. Future work may distinguish between cases where networks intentionally go down (such as turning off a laboratory at night) and unexpected outages.

#### 7.3.3 October 2012: Hurricane Sandy

We observed a noticeable increase in network outages following Hurricane Sandy, which made landfall in the U.S. at about 00:00 UTC on October 30, 2012. Focusing on known U.S. networks, we saw about triple the number of outages after the hurricane landfall compared to the prior baseline. These issues were generally resolved over the following four days.

Because of our more sensitive methodology, we detected more outages than in our prior analysis [14], but the qualitative results are similar. While re-analysis of S 50j provides insight into Sandy-related problems and recovery, survey collection places significant traffic on the targets. Trinocular can cover 3.4M blocks, about 80× more than the 40k in a survey, at about 1% of the traffic to each target block.

### 7.4 Longitudinal Re-analysis of Existing Data

Finally, we re-analyzed three years of surveys to compare the stability of our results over time and across different locations. Probing location can affect evaluation results. If the probing site’s first hop ISP is unreliable, we might underestimate overall network reliability. We re-analyzed surveys collected from three sites (see §7.2), each with several upstream networks.

Figure 10 suggests that the results are similar regardless of the probing site and for many different random samples of targets. Numerically, the variation is low: the mean outage rate (area) is 0.64% with a standard deviation of only 0.1%. To strengthen this comparison, we conducted a Student’s t-test to evaluate the hypothesis that our estimates of events, outages, and outage rates for our sites are equal. The test was unable to reject the hypothesis at 95% confidence, suggesting the sites are statistically similar.

Besides location, Figure 10 suggests fairly stable results over time. We see more variation after 2011 when the size of the target list doubled to about 40k blocks. These observations are from a single vantage point, thus they include both global and local outages. Surveys are taken for non-overlapping, two-week periods because each places a significant burden on the subject networks. Trinocular’s much lower traffic rate to targeted blocks (1% that of a survey) allows for continuous monitoring and detection, overcoming these limitations. As demonstrated in §7.1, it can operate concurrently from three sites. We plan to carry out continuous monitoring as Trinocular matures.

### 8. Conclusions

Trinocular represents a significant advance in the ability to observe outages at the network edge. Our approach is principled, using a simple, outage-centric model of the Internet, populated from long-term observations, and learns the current status of the Internet with probes driven by Bayesian inference. We have shown that it is parsimonious, increasing the burden on target networks by less than 0.7%. It is also predictable and precise, detecting all outages lasting at least 11 minutes with durations within 330 seconds. It has been used to study 3.4M blocks for two days and to re-analyze three years of existing data, providing a new approach and understanding of Internet reliability.

### Data Availability and Acknowledgments

The raw and analyzed data from this paper are available at no cost to researchers through the U.S. DHS PREDICT program (www.predict.org) and by request from the authors [27]. This work was classified by USC’s IRB as non-human subjects research (IIR00000975).

We thank our shepherd, Olaf Maennel, and the anonymous reviewers for comments that made this paper stronger and more readable. We thank John Wroclawski for comments that helped clarify the role of the model, Ethan Katz-Bassett and Harsha Madhyastha for discussion about §6.2, and Ítalo Cunha for a careful reading. We thank Jim Koda (ISI), Brian Yamaguchi (USC), and CSU network operations for providing BGP feeds to assist our evaluation, and Dan Massey, Christos Papadopoulos, Mikhail Strizhov for assisting with BGPmon and at CSU. We also thank Katsuhiro Horiba (WIDE) for providing probing infrastructure and BGP feeds.

### 9. References

[References remain unchanged and are listed as provided.]

This version of the text is more coherent and professional, with improved clarity and structure.