### Clang-Format and Its Impact on Code Attribution

Clang-format is a tool that standardizes the layout of code. Our study reveals that while the attribution method can correctly identify 27.5% of programmers based on layout features when the code is unformatted, this performance drops to 4.5% when the code is formatted using clang-format. This significant reduction in accuracy suggests that it is relatively easy to mislead an attribution system that relies on layout features.

### Limitations

Our experiments have demonstrated the impact of our attack on program authorship attribution. However, our approach has certain limitations, which we discuss below:

#### Adversarial Examples ≠ Anonymization
Our attack allows a programmer to obscure their identity by misleading the attribution system. While this protects the programmer's privacy, it does not achieve full anonymity. For true anonymity, k-anonymity would require a set of k developers who are equally likely to be attributed to the source code. In our scenario, the code is transformed to match a different author, but there is no guarantee of a sufficiently large anonymity set. Nonetheless, we consider anonymization a promising direction for future research, building on the code transformation concepts developed in this paper.

#### Verification of Semantics
We consider two programs to be semantically equivalent if they produce the same output for a given input. We verify the semantic equivalence of the transformed source code by applying the test cases provided by the Google Code Jam (GCJ) competition. Although this approach is reasonable in our context, it cannot ensure strict semantic equivalence in all cases. For instance, some API functions may provide the same functionality but differ in edge cases, such as when memory is exhausted. We acknowledge this limitation, but it does not affect the general validity of our results.

### Related Work

The automatic attack on source-code authorship attribution intersects with various areas of security research. In this section, we review related methods and concepts.

#### Authorship Attribution of Source Code
Identifying the author of a program is a challenging task in computer security that has seen significant research in recent years. Early approaches focused on hand-crafted features [14, 16], and more advanced techniques have incorporated expressive features like n-grams [1, 8, 13] and abstract syntax trees [4, 9, 21]. Similarly, techniques for analyzing native code and identifying authors of compiled programs have also advanced [3, 10, 17, 22].

Two notable studies in this area are by Caliskan et al. [9] and Abuhamad et al. [1]. The former examines features derived from code layout, lexical analysis, and syntactic analysis, and is considered the current state of the art. The latter focuses on lexical features as input for recurrent neural networks, covering the largest set of authors and leveraging recent advances in deep learning. Table 6 compares these approaches.

| Method | Layout Features | Lexical Features | Syntactic Features | Authors | Results |
|--------|-----------------|------------------|--------------------|---------|---------|
| *Abuhamad et al. [1] | - | ✓ | - | 8903 | 92% |
| *Caliskan et al. [9] | ✓ | ✓ | ✓ | 250 | 95% |
| Alsulami et al. [4] | - | ✓ | ✓ | 70 | 89% |
| Frantzeskou et al. [13] | ✓ | ✓ | - | 30 | 97% |
| Krsul and Spafford [14] | ✓ | ✓ | - | 29 | 73% |
| Burrows et al. [8] | - | ✓ | - | 10 | 77% |

*Attacked in this paper.

Previous work has largely ignored the problem of untargeted and targeted attacks. The empirical study by Simko et al. [25] examines how programmers can mislead the attribution by mimicking the style of other developers. While this study provides valuable insights into the risk of forgeries, it does not consider automatic attacks and is limited to human manipulations. In this paper, we demonstrate that such attacks can be fully automated, achieving even higher success rates than handcrafted samples. We also evaluate the impact of different feature sets and learning algorithms.

#### Adversarial Machine Learning
The security of machine learning techniques has attracted significant research recently. Much of the work on attacks has focused on scenarios where the problem and feature space are identical [6, 11, 18]. In these scenarios, changes in the problem space, such as modifying an image pixel, have a one-to-one effect on the feature space, allowing for sophisticated attack strategies. However, a one-to-one mapping between source code and extracted features cannot be constructed, necessitating a mixed attack strategy (see Section 3).

Creating evasive PDF malware samples [27, 31] and adversarial examples for text classifiers [5, 15] are similar scenarios where practical feasibility is essential. These works typically operate in the problem space, using search algorithms like hill climbing or genetic programming guided by information from the feature space. Monte Carlo Tree Search (MCTS) is a novel concept in creating adversarial examples under feasibility constraints, previously examined by Wicker et al. [30] in the image context only.

### Conclusion

Authorship attribution of source code can be a powerful tool if accurate and robust identification of programmers is possible. However, our findings show that the current state of the art is insufficient for achieving robust attribution. We present a black-box attack that seeks adversarial examples in the domain of source code by combining Monte Carlo Tree Search with concepts from source-to-source compilation. Our empirical evaluation demonstrates that automatic untargeted and targeted attacks are technically feasible and can successfully mislead recent attribution methods.

Our findings suggest a need for alternative techniques for constructing attribution methods. These techniques should be designed with robustness in mind, making it harder to transfer stylistic patterns from one source code to another. Promising directions include generative approaches in machine learning, such as Generative Adversarial Networks (GANs), which learn a decision function while actively searching for its weak spots. Additionally, it would be beneficial to systematically seek out stylistic patterns that are inherently difficult to manipulate, either due to their complexity or tight coupling with program semantics.

### Public Dataset and Implementation

To encourage further research on program authorship attribution and the development of robust methods, we make our dataset and implementation publicly available.1 The attribution methods, code transformers, and our attack algorithm are implemented as individual modules, allowing for easy combination and extension.

1. [www.tu-braunschweig.de/sec/research/code/imitator](http://www.tu-braunschweig.de/sec/research/code/imitator)

### Acknowledgment

The authors would like to thank Johannes Heidtmann for his assistance during the project and the anonymous reviewers for their suggestions and comments. Furthermore, the authors acknowledge funding by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany’s Excellence Strategy - EXC 2092 CASA - 390781972 and the research grant RI 2469/3-1.

### References

[1] M. Abuhamad, T. AbuHmed, A. Mohaisen, and D. Nyang. Large-scale and language-oblivious code authorship identification. In Proc. of ACM Conference on Computer and Communications Security (CCS), 2018.

[2] A. V. Aho, R. Sethi, and J. D. Ullman. Compilers: Principles, Techniques, and Tools (2nd Edition). Addison-Wesley, 2006.

[3] S. Alrabaee, P. Shirani, L. Wang, M. Debbabi, and A. Hanna. On leveraging coding habits for effective binary authorship attribution. In Proc. of European Symposium on Research in Computer Security (ESORICS), 2018.

[4] B. Alsulami, E. Dauber, R. E. Harang, S. Mancoridis, and R. Greenstadt. Source code authorship attribution using long short-term memory based networks. In Proc. of European Symposium on Research in Computer Security (ESORICS), 2017.

[5] M. Alzantot, Y. Sharma, A. Elgohary, B.-J. Ho, M. Srivastava, and K.-W. Chang. Generating natural language adversarial examples. In Conference on Empirical Methods in Natural Language Processing (EMNLP), 2018.

[6] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Šrndić, P. Laskov, G. Giacinto, and F. Roli. Evasion attacks against machine learning at test time. In Machine Learning and Knowledge Discovery in Databases. Springer, 2013.

[7] C. B. Browne, E. Powley, D. Whitehouse, S. M. Lucas, P. I. Cowling, P. Rohlfshagen, S. Tavener, D. Perez, S. Samothrakis, and S. Colton. A survey of Monte Carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in Games, 4(1), 2012.

[9] A. Caliskan, R. Harang, A. Liu, A. Narayanan, C. R. Voss, F. Yamaguchi, and R. Greenstadt. Deanonymizing programmers via code stylometry. In Proc. of USENIX Security Symposium, 2015.

[10] A. Caliskan, F. Yamaguchi, E. Tauber, R. Harang, K. Rieck, R. Greenstadt, and A. Narayanan. When coding style survives compilation: De-anonymizing programmers from executable binaries. In Proc. of Network and Distributed System Security Symposium (NDSS), 2018.

[11] N. Carlini and D. A. Wagner. Towards evaluating the robustness of neural networks. In Proc. of IEEE Symposium on Security and Privacy (S&P), 2017.

[12] E. Dauber, A. Caliskan, R. E. Harang, and R. Greenstadt. Git blame who?: Stylistic authorship attribution of small, incomplete source code fragments. Technical Report abs/1701.05681, arXiv, Computing Research Repository, 2017.

[13] G. Frantzeskou, E. Stamatatos, S. Gritzalis, and S. Katsikas. Effective identification of source code authors using byte-level information. In Proc. of International Conference on Software Engineering (ICSE), 2006.

[14] I. Krsul and E. H. Spafford. Authorship analysis: identifying the author of a program. Computers & Security, 16(3), 1997.

[15] J. Li, S. Ji, T. Du, B. Li, and T. Wang. TextBugger: Generating adversarial text against real-world applications. In Proc. of Network and Distributed System Security Symposium (NDSS), 2019.

[16] S. MacDonell, A. Gray, G. MacLennan, and P. Sallis. Software forensics for discriminating between program authors using case-based reasoning, feed-forward neural networks, and multiple discriminant analysis. In Proc. of International Conference on Neural Information Processing (ICONIP), 1999.

[17] X. Meng, B. P. Miller, and K.-S. Jun. Identifying multiple authors in a binary program. In Proc. of European Symposium on Research in Computer Security (ESORICS), 2017.

[18] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and A. Swami. The limitations of deep learning in adversarial settings. In Proc. of IEEE European Symposium on Security and Privacy (EuroS&P), 2016.

[8] S. Burrows, A. L. Uitdenbogerd, and A. Turpin. Application of information retrieval techniques for source code authorship attribution. In Proc. of Conference on Database Systems for Advanced Applications (DASFAA), 2009.

[19] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. Berkay Celik, and A. Swami. Practical black-box attacks against machine learning. In Proc. of ACM Asia Conference on Computer and Communications Security (ASIA CCS), 2017.

[20] N. Papernot, P. D. McDaniel, A. Sinha, and M. P. Wellman. SoK: Security and privacy in machine learning. In Proc. of IEEE European Symposium on Security and Privacy (EuroS&P), 2018.

[21] B. N. Pellin. Using classification techniques to determine source code authorship. Technical report, Department of Computer Science, University of Wisconsin, 2000.

[22] N. E. Rosenblum, X. Zhu, and B. P. Miller. Who wrote this code? Identifying the authors of program binaries. In Proc. of European Symposium on Research in Computer Security (ESORICS), 2011.

[23] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter. Accessorize to a Crime: Real and stealthy attacks on state-of-the-art face recognition. In Proc. of ACM Conference on Computer and Communications Security (CCS), 2016.

[24] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, and D. Hassabis. Mastering the game of Go with deep neural networks and tree search. Nature, 529, 2016.

[25] L. Simko, L. Zettlemoyer, and T. Kohno. Recognizing and imitating programmer style: Adversaries in program authorship attribution. Proceedings on Privacy Enhancing Technologies, 1, 2018.

[26] F. Tramèr, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart. Stealing machine learning models via prediction APIs. In Proc. of USENIX Security Symposium, 2016.

[27] N. Šrndić and P. Laskov. Practical evasion of a learning-based classifier: A case study. In Proc. of IEEE Symposium on Security and Privacy (S&P), 2014.

[28] Website. Clang: C language family frontend for LLVM. LLVM Project, https://clang.llvm.org, 2019. Last visited May 2019.

[29] Website. Google Code Jam. https://code.google.com/codejam/, 2019. Last visited May 2019.

[30] M. Wicker, X. Huang, and M. Kwiatkowska. Feature-guided black-box safety testing of deep neural networks. In Tools and Algorithms for the Construction and Analysis of Systems (TACAS), 2018.

[31] W. Xu, Y. Qi, and D. Evans. Automatically evading classifiers: A case study on PDF malware classifiers. In Proc. of Network and Distributed System Security Symposium (NDSS), 2016.

### Monte-Carlo Tree Search

In this section, we provide further details about our variant of Monte-Carlo Tree Search. Algorithm 1 gives an overview of the attack. The procedure `ATTACK` starts with the root node \( r_0 \) that represents the original source code \( x \). The algorithm then works in two nested loops:

- The outer loop in lines 3–5 repeatedly builds a search tree for the current state of the source code \( r \) and takes a step.
- The inner loop in lines 6–10 performs the actual search and updates the tree.

This approach allows us to efficiently explore the space of possible code transformations and find those that effectively mislead the attribution system.