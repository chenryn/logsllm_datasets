以下是优化后的文本，使其更加清晰、连贯和专业：

---

### 参考文献

[51] D. Smilkov, N. Thorat, B. Kim, F. Viégas, and M. Wattenberg. SmoothGrad: Removing Noise by Adding Noise. In *International Conference on Machine Learning Workshop*, 2017.

[52] J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller. Striving for Simplicity: The All Convolutional Net. In *Proceedings of International Conference on Learning Representations (ICLR)*, 2015.

[53] M. Sundararajan, A. Taly, and Q. Yan. Axiomatic Attribution for Deep Networks. In *Proceedings of the IEEE Conference on Machine Learning (ICML)*, 2017.

[54] I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to Sequence Learning with Neural Networks. In *Proceedings of Advances in Neural Information Processing Systems (NIPS)*, 2014.

[55] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the Inception Architecture for Computer Vision. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2016.

[56] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing Properties of Neural Networks. In *Proceedings of International Conference on Learning Representations (ICLR)*, 2014.

[57] G. Tao, S. Ma, Y. Liu, and X. Zhang. Attacks Meet Interpretability: Attribute-Steered Detection of Adversarial Samples. In *Proceedings of Advances in Neural Information Processing Systems (NIPS)*, 2018.

[58] F. Tramèr, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel. Ensemble Adversarial Training: Attacks and Defenses. In *Proceedings of International Conference on Learning Representations (ICLR)*, 2018.

[59] D. Tsipras, S. Santurkar, L. Engstrom, A. Turner, and A. Madry. Robustness May Be at Odds with Accuracy. In *Proceedings of International Conference on Learning Representations (ICLR)*, 2019.

[60] C. Xiao, J.-Y. Zhu, B. Li, W. He, M. Liu, and D. Song. Spatially Transformed Adversarial Examples. In *Proceedings of International Conference on Learning Representations (ICLR)*, 2018.

[61] W. Xu, D. Evans, and Y. Qi. Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks. In *Proceedings of Network and Distributed System Security Symposium (NDSS)*, 2018.

[62] Q. Zhang, Y. Nian Wu, and S.-C. Zhu. Interpretable Convolutional Neural Networks. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2018.

[63] Q. Zhang, Y. Nian Wu, and S.-C. Zhu. Interpretable Convolutional Neural Networks. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2018.

[64] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba. Learning Deep Features for Discriminative Localization. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2016.

---

### 附录

#### A. 实现细节

**A1: StAdv-based ADV2 的细节**

我们首先简要介绍空间变换的概念。设 \(\tilde{x}_i\) 为对抗输入 \(\tilde{x}\) 的第 \(i\) 个像素，\((\tilde{u}_i, \tilde{v}_i)\) 为其空间坐标。通过基于流的变换，\(\tilde{x}\) 由另一个输入 \(x\) 通过每个像素的流矢量 \(r\) 生成，其中 \(r_i = (\Delta u_i, \Delta v_i)\)。在 \(x\) 中，\(\tilde{x}_i\) 对应的坐标为 \((u_i, v_i) = (\tilde{u}_i + \Delta u_i, \tilde{v}_i + \Delta v_i)\)。由于 \((u_i, v_i)\) 不一定位于整数网格上，因此使用双线性插值 [25] 来计算 \(\tilde{x}_i\)：

\[
\tilde{x}_i = \sum_j x_j \max(0, 1 - |\tilde{u}_i + \Delta u_i - u_j|) \max(0, 1 - |\tilde{v}_i + \Delta v_i - v_j|)
\]

其中 \(j\) 遍历 \(x\) 中 \((u_i, v_i)\) 附近的像素。以 STADV 作为基础攻击框架，ADV2 可以通过优化以下目标函数来构造：

\[
\min_r \mathcal{L}_{\text{prd}}(f(x + r), c_t) + \lambda \mathcal{L}_{\text{int}}(g(x + r; f), m_t) + \tau \mathcal{L}_{\text{flow}}(r)
\]

其中 \(\mathcal{L}_{\text{flow}}(r) = \sum_i \sum_{j \in \mathcal{N}(i)} \|\Delta u_i - \Delta u_j\|_2^2 + \|\Delta v_i - \Delta v_j\|_2^2\) 衡量空间变换的幅度，\(\tau\) 是控制其重要性的超参数。在实现中，我们使用 Adam 优化器求解方程 (14)。

**A2: AID 的细节**

我们以 RTS 为例具体说明 AID 的实现。在 RTS 中，训练一个 DNN \(g\)（参数化为 \(\theta\)）直接预测给定输入 \(x\) 的归因图 \(g(x; \theta)\)。为了训练 \(g\)，最小化解释损失：

\[
\mathcal{L}_{\text{int}}(\theta) \triangleq \lambda_1 \text{rtv}(g(x; \theta)) + \lambda_2 \text{rav}(g(x; \theta)) - \log(f_c(\varphi(x; g(x; \theta)))) + \lambda_3 f_c(\varphi(x; 1 - g(x; \theta)))
\]

所有项的定义与方程 (8) 类似。

在 AID 中，设 \(A\) 表示 ADV2 攻击。进一步考虑对抗蒸馏损失：

\[
\mathcal{L}_{\text{aid}}(\theta) \triangleq -\|g(x; \theta) - g(A(x); \theta)\|_1
\]

该损失衡量了当前解释器 \(g(·; \theta)\) 下良性输入和对抗输入的归因图之间的差异。AID 通过交替最小化 \(\mathcal{L}_{\text{int}}(\theta)\) 和 \(\mathcal{L}_{\text{aid}}(\theta)\) 直至收敛来训练 \(g\)。

#### B. 参数设置

以下是本文实现的攻击所使用的默认参数设置。

**B1: PGD-based ADV2 的参数设置**

对于常规 PGD，我们设置学习率 \(\alpha = 1/255\) 和扰动阈值 \(\epsilon = 0.031\)。表 10 列出了 PGD-based ADV2 的参数设置。

---

希望这些改进能够使您的文档更加清晰和专业。