# Performance of the kNN Classifier in Intrusion Detection

## Figure 2: ROC Curves for kNN Classifier
Figure 2 illustrates the performance of the kNN classifier method, expressed in Receiver Operating Characteristic (ROC) curves. The false positive rate is plotted against the attack detection rate for different values of \( k \) (5, 10, and 25). The corresponding threshold values are shown in parentheses for \( k = 10 \).

Unlike the groups that participated in the 1998 DARPA Intrusion Detection Evaluation program [20], we define our false positive probability as the rate of misclassified processes, rather than misclassified sessions.

### Impact of \( k \) on Performance
The performance of the kNN classifier algorithm depends on the value of \( k \), which represents the number of nearest neighbors of the test process. The optimal value of \( k \) is typically determined empirically. In our study, we varied \( k \) from 5 to 25. As shown in Figure 2, for this particular dataset, \( k = 10 \) is a better choice because it achieves a 100% attack detection rate more quickly. Specifically, for \( k = 10 \), the kNN classifier can detect 10 out of 35 attacks with a zero false positive rate. When the threshold is raised to 0.72, the detection rate reaches 100%, and the false positive rate remains as low as 0.44% (23 false alarms out of 5285 normal processes) for the entire simulation day.

### Comparison with RSTCORP Group
The RSTCORP group performed well during the 1998 DARPA BSM data evaluation [20]. By learning normal sequences of system calls for over 150 programs, their Elman neural networks [8] detected 77.3% of all intrusions with no false positives and 100% of all attacks with about 10% misclassified normal sessions, resulting in 40 to 50 false positive alarms for a typical simulation day with 500 sessions. Their test data consisted of 139 normal sessions and 22 intrusive sessions. Due to the use of different test datasets, direct comparison with our kNN classifier is challenging. Although the kNN classifier has a lower attack detection rate at zero false positive rate, it quickly reaches a 100% detection rate, leading to a low false alarm frequency.

## Anomaly Detection Combined with Signature Verification

We have demonstrated that the kNN classifier algorithm can be effectively implemented for anomaly detection. The overall running time of the kNN method is \( O(N) \), where \( N \) is the number of processes in the training dataset (typically, \( k \) is a small constant). For large \( N \), this method may still be computationally expensive for real-time intrusion detection systems. To enhance attack detection, the kNN anomaly detection can be integrated with signature verification.

### Training Data Set
After carefully analyzing the 35 attack instances within the seven-week DARPA training data, we generated a dataset of 19 intrusive processes. This dataset covers most attack types in the DARPA training data, including clearly malicious processes such as ejectexploit, formatexploit, ffbexploit, and others.

For the improved kNN algorithm, the training dataset includes 606 normal processes and the 19 aforementioned intrusive processes. Each new test process is first compared to the intrusive processes. If there is a perfect match (i.e., cosine similarity equals 1.0), the new process is labeled as intrusive. Otherwise, the abnormal detection procedure in Figure 1 is performed. This modification only causes minor additional calculations for normal testing processes due to the small number of intrusive processes in the training dataset.

### Evaluation of the Modified kNN Algorithm
The performance of the modified kNN classifier was evaluated using 24 attacks within the two-week DARPA testing audit data. The testing data included both known and novel attacks, with some duplicate instances of the eject attack excluded. The false positive rate was evaluated using the same 5285 testing normal processes as described in Section 4.2. Table 3 shows the attack detection accuracy for \( k = 10 \) and a threshold of 0.8. The false positive rate is 0.59% (31 false alarms) when the threshold is adjusted to 0.8.

### Missed Attack Instances
The two missed attack instances were a new denial of service attack called "process table." These attacks matched exactly with one of the training normal processes, making it impossible for the kNN algorithm to detect them. The process table attack was executed by establishing connections to the telnet port of the victim machine every 4 seconds, exhausting its process table, and preventing new processes from being launched [21]. Since this attack involves the abuse of a legal action, it did not show any abnormality when analyzed individually. However, it could be easily identified by other intrusion detection methods due to the unusually large number of active connections on a particular port.

Among the 22 detected attacks, eight were captured with signature verification. These attacks could also be identified without signature verification, but the integration reduced the need to compare them with each normal process in the training dataset.

## Summary

In this paper, we propose a new algorithm based on the k-Nearest Neighbor (kNN) classifier for modeling program behavior in intrusion detection. Our preliminary experiments with the 1998 DARPA BSM audit data show that this approach effectively detects intrusive program behavior. Compared to other methods using short system call sequences, the kNN classifier does not require separate learning of individual program profiles, thus reducing the computational cost. Our results also indicate that a low false positive rate can be achieved. While this result may not hold for more sophisticated datasets, the k-Nearest Neighbor classifier appears well-suited for intrusion detection.

### Vector Transformation
The tf-idf text categorization weighting technique was used to transform each process into a vector. With the frequency-weighting method, where each entry is the number of occurrences of a system call during the process execution, each process vector does not carry information about other processes. A new training process can be easily added to the training dataset without changing the weights of existing samples, making the kNN classifier more suitable for dynamic environments requiring frequent updates.

### Future Work
In our current implementation, we used all system calls to represent program behavior. The dimension of process vectors, and hence the classification cost, can be further reduced by using only the most relevant system calls.

## Discussion

Despite the encouraging initial results, several issues require deeper analysis. Our approach relies on the consistency of system call frequencies across normal executions and the appearance of unseen or unusual system call frequencies during exploitation. However, if an intrusion does not reveal anomalies in system call frequencies, our method would miss it. For example, attacks involving the abuse of normal processes, such as the process table attack, would not be identified by the kNN classifier.

With the kNN classifier, each process is classified upon termination. We argue that this is still suitable for real-time intrusion detection, as each attack is usually conducted within one or more sessions, and each session contains several processes. Since the kNN classifier monitors each process's execution, it is highly likely that an attack can be detected while in operation. However, an attacker might avoid detection by not letting the process exit. Therefore, effective classification during a process's execution is a significant issue for future work.

## Acknowledgment
The authors wish to thank Dr. Marc Zissman of Lincoln Laboratory at MIT for providing the DARPA training and testing data. We also thank the reviewers for their valuable comments. Special thanks to Dr. Vern Paxton for his insightful comments, which helped improve the quality and readability of the final version. This work is supported in part by the AFOSR grant F49620-01-1-0327 to the Center for Digital Security of the University of California, Davis.

## References
[1] H.S. Javitz and A. Valdes, The NIDES Statistical Component: Description and Justification, Technical Report, Computer Science Laboratory, SRI International, Menlo Park, CA, March 1994.
[2] H.S. Vaccaro and G.E. Liepins, “Detection of Anomalous Computer Session Activity”, Proceedings of 1989 IEEE Symposium on Security and Privacy, 280-289, 1989.
[3] E. Lundin and E. Johnsson, “Anomaly-based intrusion detection: privacy concern and other problems”, Computer Networks, vol. 34, 623-640, 2000.
[4] V. Dao and V. R. Vemuri, “Computer Network Intrusion Detection: A Comparison of Neural Networks Methods”, Differential Equations and Dynamical Systems, (Special Issue on Neural Networks, Part-2), vol.10, No. 1&2, 2002.
[5] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Logstaff, “A Sense of Self for Unix process”, Proceedings of 1996 IEEE Symposium on Computer Security and Privacy, 120-128, 1996.
[6] C. Warrender, S. Forrest and B. Pearlmutter, “Detecting Intrusions Using System Calls: Alternative Data Models”, Proceedings of 1999 IEEE Symposium on Security and Privacy, 133-145, 1999.
[7] W. Lee, S. J. Stolfo and P. K. Chan, “Learning Patterns from Unix Process Execution Traces for Intrusion Detection”, Proceedings of AAAI97 Workshop on AI Methods in Fraud and Risk Management, 50-56, 1997.
[8] A. K. Ghosh, A. Schwartzbard and A. M. Shatz, “Learning Program Behavior Profiles for Intrusion Detection”, Proceedings of 1st USENIX Workshop on Intrusion Detection and Network Monitoring, Santa Clara, CA, April 1999.
[9] K. Aas and L. Eikvil, Text Categorisation: A Survey, http://citeseer.nj.nec.com/aas99text.html, 1999.
[10] Y. Yang, An Evaluation of Statistical Approaches to Text Categorization, Technical Report CMU-CS-97-127, Computer Science Department, Carnegie Mellon University, 1997.
[11] Y. Yang, “Expert Network: Effective and Efficient Learning from Human Decisions in Text Categorization and Retrieval”, Proceedings of 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’94), 13-22, 1994.
[12] C. Ko, G. Fink and K. Levitt, “Automated Detection of Vulnerabilities in Privileged Programs by Execution Monitoring”, Proceedings of 10th Annual Computer Security Applications Conference, Orlando, FL, Dec, 134-144, 1994.
[13] P. Uppuluri and R. Sekar, “Experiences with Specification-Based Intrusion Detection”, Recent Advances in Intrusion Detection (RAID 2001), LNCS 2212, Springer, 172-189, 2001.
[14] D. Wagner and D. Dean, “Intrusion Detection via Static Analysis”, Proceedings of IEEE Symposium on Research in Security and Privacy, Oakland, CA, 2001.
[15] M. Asaka, T. Onabuta, T. Inoue, S. Okazawa and S. Goto, “A New Intrusion Detection Method Based on Discriminant Analysis”, IEEE TRANS. INF. & SYST., Vol. E84-D, No. 5, 570-577, 2001.
[16] N. Ye, X. Li, Q. Chen S. M. Emran and M. Xu, “Probabilistic Techniques for Intrusion Detection Based on Computer Audit Data”, IEEE Trans. SMC-A, Vol. 31, No. 4, 266-274, 2001.
[17] J. T.-Y. Kwok, “Automatic Text Categorization Using Support Vector Machine”, Proceedings of International Conference on Neural Information Processing, 347-351, 1998.
[18] MIT Lincoln Laboratory, http://www.ll.mit.edu/IST/ideval/.
[19] Sun Microsystems, SunShield Basic Security Module Guide, 1995.
[20] R. Lippmann, D. Fried, I. Graf, J. Haines, K. Kendall, D. McClung, D. Webber, S. Webster, D. Wyschograd, R. Cunninghan and M. Zissan, “Evaluating Intrusion Detection Systems: the 1998 DARPA off-line Intrusion Detection Evaluation”, Proceedings of the DARPA Information Survivability Conference and Exposition, IEEE Computer Society Press, Los Alamitos, CA, 12-26, 2000.
[21] K. Kendall, “A Database of Computer Attacks for the Evaluation of Intrusion Detection Systems”, Master’s Thesis, Massachusetts Institute of Technology, 1998.