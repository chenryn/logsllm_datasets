{"input": "最近一天登录数据库时长排名Top10。索引可用字段有：oracle.ACCOUNT_STATUS, oracle.ACTION, oracle.ACTION_NAME, oracle.BLOCK_CHANGES, oracle.CREATED, oracle.EVENT, oracle.EXECUTIONS, oracle.EXPIRY_DATE, oracle.FILE_COUNTS, oracle.FILE_SIZE, oracle.FREE_BYTES, oracle.GRANTED_ROLE, oracle.GRANTEE, oracle.HOST_NAME, oracle.INSTANCE_NAME, oracle.JOB, oracle.LAST_DATE, oracle.LIMIT, oracle.LOCK_DATE, oracle.LOGON_TIME, oracle.LOG_USER, oracle.MACHINE, oracle.NEXT_DATE, oracle.Name, oracle.ORACODE, oracle.OSUSER, oracle.PHYSICAL_READS, oracle.PROFILE, oracle.PROG, oracle.PROGRAM, oracle.RESOURCE_NAME, oracle.RESOURCE_TYPE, oracle.SID, oracle.SPID, oracle.SQL_ID, oracle.SQL_TEXT, oracle.STATUS, oracle.TABLESPACE_NAME, oracle.TERMINAL, oracle.TOTAL_BLOCKS, oracle.TOTAL_BYTES, oracle.TS_COUNTS, oracle.USED_BYTES, oracle.USED_SIZE, oracle.USERNAME, oracle.VALUE, oracle.WAIT_TIME, oracle.WHAT, oracle.action, oracle.conn_str.HOST, oracle.conn_str.SID, oracle.description, oracle.event, oracle.host, oracle.host_addr, oracle.logical_reads_M, oracle.login_user, oracle.msg, oracle.ora_code, oracle.osprivilege, oracle.physical_reads_M, oracle.policy, oracle.src_ip, oracle.status, oracle.tns_error, oracle.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Oracle数据，编写查询语句实现如下分析场景", "output": "starttime=\"-1d\" appname:oracle |table oracle.ACTION_NAME, oracle.USERNAME, oracle.SESSIONID, timestamp | sort by oracle.USERNAME, oracle.SESSIONID, +timestamp | autoregress oracle.ACTION_NAME p=1|autoregress oracle.USERNAME p=1 | autoregress oracle.SESSIONID p=1 | autoregress timestamp p=1 | where oracle.ACTION_NAME == \"LOGOFF\" && oracle.ACTION_NAME_p1 == \"LOGON\" && oracle.USERNAME == oracle.USERNAME_p1 && oracle.SESSIONID == oracle.SESSIONID_p1 | eval duration=timestamp-timestamp_p1 | table oracle.USERNAME, duration | eval duration_sec = duration/1000 | sort by duration_sec | limit 10 | table oracle.USERNAME, duration_sec"}
{"input": "银证转账资金净流入。", "instruction": "通达信数据，编写查询语句实现如下分析场景", "output": "appname:tdx TDX.TDX_ID_ZZFX:*  AND [[appname:tdx \"银证\" 成功  |stats count() by TDX.TRANSACTION_ID | fields TDX.TRANSACTION_ID]] | stats sum(TDX.TDX_ID_ZZJE) as RMB  by TDX.TDX_ID_ZZFX | autoregress RMB  as _RMB p=1 | where  TDX.TDX_ID_ZZFX==\"0\" | eval tot=RMB-_RMB"}
{"input": "", "instruction": "绘制当期日志量趋势(每 30 分钟)和近5日、近15日、近60日的移动平均线趋势", "output": "*|bucket timestamp span=30m as ts|stats count() as cnt by ts|movingavg cnt,5 as MA5|movingavg cnt,15 as MA15|movingavg cnt,60 as MA60"}
{"input": "", "instruction": "我想问的是最近三十分钟内的请求数量有没有异常增长？", "output": "*|bucket timestamp span=30m as ts|stats count() as cnt by ts|movingavg cnt,5 as MA5|movingavg cnt,15 as MA15|movingavg cnt,60 as MA60"}
{"input": "按每小时分桶统计3sigma异常请求量分析。", "instruction": "安全态势数据，编写查询语句实现如下分析场景", "output": "appname:middleware| bucket timestamp span=1h as ts | stats count() as count_ by ts | movingavg count_,5 as ma | rollingstd count_,5 as rs | eval lower=ma-3*rs | eval upper=ma+3*rs | eval outlier=if(count_>upper||count_<lower, count_, NULL)"}
{"input": "按每小时分桶统计端口耗尽异常检测。索引可用字段有：loadbalancing.dst_ip, loadbalancing.level, loadbalancing.listenervs_ip, loadbalancing.msg, loadbalancing.querytype, loadbalancing.responsecode, loadbalancing.severity, loadbalancing.src.geo.province, loadbalancing.src_ip, loadbalancing.status, loadbalancing.type, loadbalancing.user, loadbalancing.username, loadblancing.status, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "F5数据，编写查询语句实现如下分析场景", "output": "appname:loadbalancing tag:f5 AND loadbalancing.level:crit (Inet port exhaustion)|bucket timestamp span=1h as  ts|stats count() as ct by ts|movingavg ct,5  as ma|rollingstd ct,5 as rs|eval lower=ma-3*rs|eval upper=ma+3*rs|eval outlier=if(count>upper||count<lower,ct,NULL)"}
{"input": "按每小时分桶统计3sigma异常请求量分析。索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Apache日志数据，编写查询语句实现如下分析场景", "output": "appname:apache tag:access*| bucket timestamp span=1h as ts | stats count() as count_ by ts | movingavg count_,5 as ma | rollingstd count_,5 as rs | eval lower=ma-3*rs | eval upper=ma+3*rs | eval outlier=if(count_>upper||count_<lower, count_, NULL)"}
{"input": "按每小时分桶统计3sigma异常请求量分析。索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "瑞数waf数据，编写查询语句实现如下分析场景", "output": "appname:apache tag:access*| bucket timestamp span=1h as ts | stats count() as count_ by ts | movingavg count_,5 as ma | rollingstd count_,5 as rs | eval lower=ma-3*rs | eval upper=ma+3*rs | eval outlier=if(count_>upper||count_<lower, count_, NULL)"}
{"input": "索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我需要从我们的 Apache 应用中检索所有包含“访问”标记且时间戳在一小时内的所有数据点的数量统计信息和移动平均数以及滚动标准 deviation。然后计算出三倍标准偏差下的下限和上限，并将任何离群值的数据点设置为 null。", "output": "appname:apache tag:access*| bucket timestamp span=1h as ts | stats count() as count_ by ts | movingavg count_,5 as ma | rollingstd count_,5 as rs | eval lower=ma-3*rs | eval upper=ma+3*rs | eval outlier=if(count_>upper||count_<lower, count_, NULL)"}
{"input": "每10分钟统计esma告警预测", "instruction": "日志易告警监控-有数据数据，编写查询语句实现如下分析场景", "output": " _index:monitor * NOT issue_alert:false\n| bucket timestamp span=10m as ts\n| stats count() as cnt by ts|where cnt>0| esma cnt timefield=ts period=144 futurecount=6|eval upper95_=upper95*1.2|eval lower95_=lower95*0.8"}
{"input": "", "instruction": "名为 \"monitor\" 的索引中，未标记为 \"issue_alert\" 的文档数目超过 0 个的情况，并按时间戳进行分组，计算每个时间段内事件数量的统计值（即 `cnt`），同时过滤出每条数据的上限和下限 95 分位数 (`upper95_` 和 `lower95_`) 。", "output": " _index:monitor * NOT issue_alert:false| bucket timestamp span=10m as ts| stats count() as cnt by ts|where cnt>0| esma cnt timefield=ts period=144 futurecount=6|eval upper95_=upper95*1.2|eval lower95_=lower95*0.8"}
{"input": "每10分钟统计192.168.1.253主机内存使用情况预测分析", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats AND 192.168.1.253 | bucket timestamp span=10m as ts | stats avg(json.Mem.used_percent) as count_ by ts|esma count_  timefield=ts"}
{"input": "每10分钟统计192.168.1.253主机CPU使用情况预测分析", "instruction": "Linux主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats AND 192.168.1.253| bucket timestamp span=10m as ts | stats avg(json.cpu.system_percent) as count_ by ts |esma count_  timefield=ts|eval count_=format(\"%.2f\",count_)"}
{"input": "每10分钟统计主机CPU使用情况预测分析", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_win_system_stats\n| bucket timestamp span=10m as ts \n| stats avg(json.cpu.system_percent) as count_ by ts \n|esma count_  timefield=ts\n"}
{"input": "每10分钟统计主机内存使用情况预测分析", "instruction": "Windows主机运维监控指标数据，编写查询语句实现如下分析场景", "output": "appname:top_info_system_stats\n| bucket timestamp span=10m as ts \n| stats avg(json.Mem.used_percent) as count_ by ts\n|esma count_  timefield=ts\n"}
{"input": "", "instruction": "我想问有关内存使用率的统计信息和某个IP地址（192.168.1.253）的访问情况，按十分钟做出预测", "output": "appname:top_info_system_stats AND 192.168.1.253 | bucket timestamp span=10m as ts | stats avg(json.Mem.used_percent) as count_ by ts|esma count_  timefield=ts"}
{"input": "每10分钟统计表空间预测。索引可用字段有：oracle.ACCOUNT_STATUS, oracle.ACTION, oracle.ACTION_NAME, oracle.BLOCK_CHANGES, oracle.CREATED, oracle.EVENT, oracle.EXECUTIONS, oracle.EXPIRY_DATE, oracle.FILE_COUNTS, oracle.FILE_SIZE, oracle.FREE_BYTES, oracle.GRANTED_ROLE, oracle.GRANTEE, oracle.HOST_NAME, oracle.INSTANCE_NAME, oracle.JOB, oracle.LAST_DATE, oracle.LIMIT, oracle.LOCK_DATE, oracle.LOGON_TIME, oracle.LOG_USER, oracle.MACHINE, oracle.NEXT_DATE, oracle.Name, oracle.ORACODE, oracle.OSUSER, oracle.PHYSICAL_READS, oracle.PROFILE, oracle.PROG, oracle.PROGRAM, oracle.RESOURCE_NAME, oracle.RESOURCE_TYPE, oracle.SID, oracle.SPID, oracle.SQL_ID, oracle.SQL_TEXT, oracle.STATUS, oracle.TABLESPACE_NAME, oracle.TERMINAL, oracle.TOTAL_BLOCKS, oracle.TOTAL_BYTES, oracle.TS_COUNTS, oracle.USED_BYTES, oracle.USED_SIZE, oracle.USERNAME, oracle.VALUE, oracle.WAIT_TIME, oracle.WHAT, oracle.action, oracle.conn_str.HOST, oracle.conn_str.SID, oracle.description, oracle.event, oracle.host, oracle.host_addr, oracle.logical_reads_M, oracle.login_user, oracle.msg, oracle.ora_code, oracle.osprivilege, oracle.physical_reads_M, oracle.policy, oracle.src_ip, oracle.status, oracle.tns_error, oracle.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Database_Oracle数据，编写查询语句实现如下分析场景", "output": "appname:oracle AND tag:tablespace\n| bucket timestamp span=10m as ts \n| stats avg('oracle.Size_(M)') as count_ by ts \n|esma count_  timefield=ts"}
{"input": "索引可用字段有：oracle.ACCOUNT_STATUS, oracle.ACTION, oracle.ACTION_NAME, oracle.BLOCK_CHANGES, oracle.CREATED, oracle.EVENT, oracle.EXECUTIONS, oracle.EXPIRY_DATE, oracle.FILE_COUNTS, oracle.FILE_SIZE, oracle.FREE_BYTES, oracle.GRANTED_ROLE, oracle.GRANTEE, oracle.HOST_NAME, oracle.INSTANCE_NAME, oracle.JOB, oracle.LAST_DATE, oracle.LIMIT, oracle.LOCK_DATE, oracle.LOGON_TIME, oracle.LOG_USER, oracle.MACHINE, oracle.NEXT_DATE, oracle.Name, oracle.ORACODE, oracle.OSUSER, oracle.PHYSICAL_READS, oracle.PROFILE, oracle.PROG, oracle.PROGRAM, oracle.RESOURCE_NAME, oracle.RESOURCE_TYPE, oracle.SID, oracle.SPID, oracle.SQL_ID, oracle.SQL_TEXT, oracle.STATUS, oracle.TABLESPACE_NAME, oracle.TERMINAL, oracle.TOTAL_BLOCKS, oracle.TOTAL_BYTES, oracle.TS_COUNTS, oracle.USED_BYTES, oracle.USED_SIZE, oracle.USERNAME, oracle.VALUE, oracle.WAIT_TIME, oracle.WHAT, oracle.action, oracle.conn_str.HOST, oracle.conn_str.SID, oracle.description, oracle.event, oracle.host, oracle.host_addr, oracle.logical_reads_M, oracle.login_user, oracle.msg, oracle.ora_code, oracle.osprivilege, oracle.physical_reads_M, oracle.policy, oracle.src_ip, oracle.status, oracle.tns_error, oracle.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想要知道在最近十分钟内，Oracle数据库中有多少表空间的大小平均值是多少。请告诉我这个结果的趋势。", "output": "appname:oracle AND tag:tablespace| bucket timestamp span=10m as ts | stats avg('oracle.Size_(M)') as count_ by ts |esma count_  timefield=ts"}
{"input": "按每30分钟分桶统计前 7 天的请求时长趋势，使用指数平滑预测后续 24 个点，然后对比今天的实际走势。。索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Apache日志数据，编写查询语句实现如下分析场景", "output": "starttime=\"-7d/d\" endtime=\"now/d\" appname:apache tag:access | bucket timestamp span=30m as ts | stats avg(middleware.req_time) as avg_ by ts | esma avg_ timefield=ts futurecount=24 | where typeof(_predict_avg_) == \"double\" | eval time = formatdate(ts, \"HH:mm\") | table time, _predict_avg_|rename _predict_avg_ as \"avg_\"|eval line=\"预测值\"|append [[starttime=\"now/d\" appname:apache tag:access | bucket timestamp span=30m as ts | stats avg(middleware.req_time) as avg_ by ts|eval time = formatdate(ts, \"HH:mm\")  | table time, avg_|eval line=\"实际值\"]]|rename avg_ as \"请求时长\""}
{"input": "索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "首先从最近一周的数据中筛选出包含`Apache`应用名称、访问标签（tag）为`access`的所有记录；然后将这些记录按时间划分成小时的bucket，并计算每个小时内的平均响应时间；接着使用Exponential Smoothing移动平均算法对上一步得到的结果进行预测，并生成未来的24个小时内的预测值", "output": "starttime=\"-7d/d\" endtime=\"now/d\" appname:apache tag:access | bucket timestamp span=30m as ts | stats avg(middleware.req_time) as avg_ by ts | esma avg_ timefield=ts futurecount=24 | where typeof(_predict_avg_) == \"double\" | eval time = formatdate(ts, \"HH:mm\") | table time, _predict_avg_|rename _predict_avg_ as \"avg_\"|eval line=\"预测值\"|append [[starttime=\"now/d\" appname:apache tag:access | bucket timestamp span=30m as ts | stats avg(middleware.req_time) as avg_ by ts|eval time = formatdate(ts, \"HH:mm\")  | table time, avg_|eval line=\"实际值\"]]|rename avg_ as \"请求时长\""}
{"input": "按每30分钟分桶统计前 7 天的请求时长趋势，使用指数平滑预测未来 24 个点，然后环比今天的实际值趋势。索引可用字段有：waf.action, waf.attack_name, waf.attack_type, waf.bytes_in, waf.cost, waf.cve_id, waf.dst_city, waf.dst_domain, waf.dst_ip, waf.dst_latitude, waf.dst_longitude, waf.dst_port, waf.error_msg, waf.event_level, waf.event_log_level, waf.event_name, waf.event_type, waf.http_method, waf.http_refer, waf.is_truncated, waf.kv.Evt_level, waf.kv.Evt_type, waf.kv.event_name, waf.kv.http_method, waf.kv.http_refer, waf.kv.http_url, waf.kv.msg, waf.kv.owasp_top, waf.kv.pri, waf.kv.severity_level, waf.kv.status, waf.kv.type, waf.level, waf.log_category, waf.message, waf.message.action, waf.message.event, waf.message.method, waf.message.policy, waf.message.src_ip.geo.ip, waf.message.src_ip.geo.province, waf.message.src_port, waf.message.status, waf.message.threaten, waf.method, waf.module, waf.msg.act, waf.msg.cs, waf.msg.policy_id, waf.msg.src.geo.country, waf.policy_name, waf.proto, waf.referer, waf.risk_level, waf.severity, waf.src.geo.city, waf.src.geo.country, waf.src.geo.ip, waf.src.geo.isp, waf.src.geo.latitude, waf.src.geo.longitude, waf.src.geo.province, waf.src_ip, waf.src_port, waf.status, waf.status_code, waf.threat_level, waf.time, waf.ua_browser, waf.ua_device, waf.ua_os, waf.uri, waf.url, waf.user_agent.browser, waf.user_agent.os, waf.website_name, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "瑞数waf数据，编写查询语句实现如下分析场景", "output": "starttime=\"-7d/d\" endtime=\"now/d\" appname:waf tag:river | bucket timestamp span=30m as ts | stats avg(waf.cost) as avg_ by ts | esma avg_ timefield=ts futurecount=24 | where typeof(_predict_avg_) == \"double\" | eval time = formatdate(ts, \"HH:mm\") | table time, _predict_avg_|rename _predict_avg_ as \"avg_\"|eval line=\"预测值\"|append [[starttime=\"now/d\" appname:waf tag:river | bucket timestamp span=30m as ts | stats avg(waf.cost) as avg_ by ts|eval time = formatdate(ts, \"HH:mm\")  | table time, avg_|eval line=\"实际值\"]]|rename avg_ as \"请求时长\""}
{"input": "", "instruction": "查找最近一月内访问量最高的国家和城市，并显示月份和访问量，以及占比和排名", "output": " starttime=\"now-1M\" _index:web| iplocation apache.clientip | stats count() as cnt by Country, City | sort by -cnt | head 10 | eval month=parsedate(now(), \"MMM\") | eventstats sum(cnt) as total | eval percentage=round(cnt*100/total,2) | streamstats count() as rank by month | table month, rank, Country, City, cnt, percentage"}
{"input": "", "instruction": "通过 EventID 4688 来关联父子进程", "output": "EventCode:4688 | table timestamp ComputerName New_Process_Name New_Process_ID Creator_Process_ID| eval proc_name_id_all=New_Process_Name+\"#mysep#\"+New_Process_ID| sort by + timestamp| streamstats time_window=60s values(proc_name_id_all) as proc_name_id_all by ComputerName| eval parent=mvfind(proc_name_id_all, \"#mysep#\"+Creator_Process_ID+\"$\")| eval parent=replace(mvindex(proc_name_id_all,parent), \"^(.+)#mysep#.+$\", \"\\1\")"}
{"input": "", "instruction": "查找最近一月内访问量最高的国家和城市，并显示月份和访问量，以及占比和排名", "output": " starttime=\"now-1M\" _index:web| iplocation apache.clientip | stats count() as cnt by Country, City | sort by -cnt | head 10 | eval month=parsedate(now(), \"MMM\") | eventstats sum(cnt) as total | eval percentage=round(cnt*100/total,2) | streamstats count() as rank by month | table month, rank, Country, City, cnt, percentage"}
{"input": "从定时任务索引中搜索 linux 操作系统审计_各事件占比任务的数据，按类型计算 cnt 字段的总和，按总和排序，并使用 streamstats 指令给列表添加序号。将 type 字段重命名为事件类型， 总和 value 重命名为事件数", "instruction": "Linux操作系统审计，前七天到今天零点的各事件列表", "output": "starttime=\"-7d/d\" endtime=\"now/d\" _index:schedule schedule_name:Linux操作系统审计_各事件占比  |stats sum(cnt) as value by type |sort by value |streamstats count() as seq |fields seq,type,value |rename seq as \"序号\",type as \"事件类型\",value as \"事件数\""}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Linux操作系统审计_审计功能启动事件明细，将时间转换为年月日时分秒，然后按时间、ip 统计次数。再以 IP 地址正序排序后，使用 streamstats 计算得到表格序号", "output": "appname:linux tag:messages \"Starting Security Auditing Service\" |eval time=formatdate(timestamp,\"yyyy-MM-dd HH:mm:ss\") |stats count() as cnt by time,ip |eval type=\"审计功能启动事件\" |sort by +ip |streamstats count() as seq  |rename seq as \"序号\",time as \"时间\",ip as \"主机IP\",type as \"事件类型\",cnt as \"变更次数\""}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Linux操作系统审计_审计功能关闭事件明细，将时间转换为年月日时分秒，然后按时间、ip 统计次数。再以 IP 地址正序排序后，使用 streamstats 计算得到表格序号", "output": "appname:linux tag:messages \"The audit daemon is exiting.\" |eval time=formatdate(timestamp,\"yyyy-MM-dd HH:mm:ss\") |stats count() as cnt by time,ip |eval type=\"审计功能关闭事件\" |sort by +ip |streamstats count() as seq | rename seq as \"序号\",time as \"时间\",ip as \"主机IP\",type as \"事件类型\",cnt as \"变更次数\""}
{"input": "按 ip、hostname 统计表格，然后使用 streamstats 给列表附加序号，并重命名为中文字段名。索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "Linux操作系统审计_昨天零点至今的设备列表", "output": "starttime=\"-1d/d\" endtime=\"now\" appname:linux |stats count() as cnt by ip,hostname |sort by +ip |streamstats count() as seq |fields seq,ip,hostname |rename seq as \"序号\",ip as \"主机IP\"hostname as \"主机名称\""}
{"input": "", "instruction": "浪潮云宿主机存储使用详情", "output": "appname:incloud_sphere tag:host |dedup 1 host |table host,storagePerf,storageScore |sort by +host |streamstats count() as seq |fields seq,host,storagePerf,storageScore |rename seq as \"序号\",host as \"主机IP\",storagePerf as \"存储使用率(%)\",storageScore as \"存储健康度\""}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想要知道系统中哪些服务正在运行，以及它们的使用情况和错误信息。我还想知道内发生了多少次这种类型的事件，并按日期列出详细信息。", "output": "appname:linux tag:messages \"The audit daemon is exiting.\" |eval time=formatdate(timestamp,\"yyyy-MM-dd HH:mm:ss\") |stats count() as cnt by time,ip |eval type=\"审计功能关闭事件\" |sort by +ip |streamstats count() as seq | rename seq as \"序号\",time as \"时间\",ip as \"主机IP\",type as \"事件类型\",cnt as \"变更次数\""}
{"input": "", "instruction": "我想问的是，在哪些业务场景下，我们需要对云硬盘进行性能和健康状况的评估呢？", "output": "appname:incloud_sphere tag:host |dedup 1 host |table host,storagePerf,storageScore |sort by +host |streamstats count() as seq |fields seq,host,storagePerf,storageScore |rename seq as \"序号\",host as \"主机IP\",storagePerf as \"存储使用率(%)\",storageScore as \"存储健康度\""}
{"input": "索引可用字段有：linux.cmd, linux.command, linux.event_detail.comm, linux.event_detail.exe, linux.event_detail.key, linux.event_detail.pid, linux.event_detail.ppid, linux.event_id, linux.event_msg.terminal, linux.event_name, linux.event_type, linux.log_type, linux.login_time, linux.msg, linux.pid, linux.result, linux.service_name, linux.src_ip, linux.status, linux.terminal, linux.type, linux.use_time, linux.user, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想要知道昨天到现在的每台 Linux 服务器的访问量排名，并且显示 IP、主机名和访问次数。请帮我把这个需求转化为查询语言。", "output": "starttime=\"-1d/d\" endtime=\"now\" appname:linux |stats count() as cnt by ip,hostname |sort by +ip |streamstats count() as seq |fields seq,ip,hostname |rename seq as \"序号\",ip as \"主机IP\"hostname as \"主机名称\""}
{"input": "索引可用字段有：apache.clientip, apache.domain, apache.geo.country, apache.geo.isp, apache.method, apache.referer, apache.request_path, apache.request_query, apache.resp_time, apache.status, apache.ua, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "每小时的平均响应时间与历史总平均值偏差比较，过滤偏差大于一半的时段", "output": "appname:apache | bucket timestamp span=1h as ts | stats avg(apache.resp_time) as hour_avg, sum(apache.resp_time) as hour_sum, count() as hour_cnt by ts | eventstats sum(hour_sum) as total_sum, sum(hour_cnt) as total_cnt | eval total_avg=total_sum/total_cnt | eval duration_diff=(hour_avg-total_avg)/total_avg | where abs(duration_diff)>0.5"}
{"input": "按每5分钟分桶统计包类型占比。索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "网络设备接口数据数据，编写查询语句实现如下分析场景", "output": "appname:switchperf AND (switchperf.type:ifOutUcastPkts OR switchperf.type:ifOutNUcastPkts OR switchperf.type:ifInNUcastPkts OR switchperf.type:ifInUcastPkts) | bucket timestamp span=5m as ts | stats sum(switchperf.value) as _totalPkts by ts,switchperf.devip,switchperf.ifindex,switchperf.type  | sort by switchperf.ifindex,switchperf.type,+ts | autoregress _totalPkts as last_totalPkts p=1 | autoregress switchperf.ifindex as lastifindex p=1 | autoregress switchperf.type as lasttype p=1 | where\tswitchperf.ifindex==lastifindex| where\tswitchperf.type==lasttype | eval Pkts=case(_totalPkts-last_totalPkts<0,_totalPkts-last_totalPkts+4294967296,default,_totalPkts-last_totalPkts) | stats sum(Pkts) as Pkts by switchperf.devip,switchperf.type \n|eval type=case(switchperf.type==\"ifOutNUcastPkts\",\"端口出方向非单播报文数\",switchperf.type==\"ifOutUcastPkts\",\"端口出方向单播报文数\",switchperf.type==\"ifInNUcastPkts\",\"端口进方向非单播报文数\",switchperf.type==\"ifInUcastPkts\",\"端口进方向单播报文数\")"}
{"input": "按每5分钟分桶统计进出包类型实时趋势。索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "网络设备接口数据数据，编写查询语句实现如下分析场景", "output": "appname:switchperf AND (switchperf.type:ifOutUcastPkts OR switchperf.type:ifOutNUcastPkts OR switchperf.type:ifInNUcastPkts OR switchperf.type:ifInUcastPkts) | bucket timestamp span=5m as ts | stats sum(switchperf.value) as _totalPkts by ts,switchperf.devip,switchperf.ifindex,switchperf.type  | sort by switchperf.ifindex,switchperf.type,+ts | autoregress _totalPkts as last_totalPkts p=1 | autoregress switchperf.ifindex as lastifindex p=1 | autoregress switchperf.type as lasttype p=1 | where\tswitchperf.ifindex==lastifindex| where\tswitchperf.type==lasttype | eval Pkts=case(_totalPkts-last_totalPkts<0,_totalPkts-last_totalPkts+4294967296,default,_totalPkts-last_totalPkts) | stats sum(Pkts) as Pkts by ts,switchperf.devip,switchperf.type \n|eval type=case(switchperf.type==\"ifOutNUcastPkts\",\"端口出方向非单播报文数\",switchperf.type==\"ifOutUcastPkts\",\"端口出方向单播报文数\",switchperf.type==\"ifInNUcastPkts\",\"端口进方向非单播报文数\",switchperf.type==\"ifInUcastPkts\",\"端口进方向单播报文数\") "}
{"input": "按每5分钟分桶统计正常包和丢包、错包的占比。索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "网络设备接口数据数据，编写查询语句实现如下分析场景", "output": "appname:switchperf AND (switchperf.type:ifInErrors OR switchperf.type:ifOutErrors OR switchperf.type:ifInDiscards OR switchperf.type:ifOutDiscards OR switchperf.type:ifInUcastPkts OR switchperf.type:ifInNUcastPkts OR switchperf.type:ifOutNUcastPkts OR switchperf.type:ifOutUcastPkts)\n| bucket timestamp span=5m as ts | stats sum(switchperf.value) as _totalPkts by ts,switchperf.devip,switchperf.ifindex,switchperf.type  | sort by switchperf.ifindex,switchperf.type,+ts | autoregress _totalPkts as last_totalPkts p=1 | autoregress switchperf.ifindex as lastifindex p=1 | autoregress switchperf.type as lasttype p=1 | where\tswitchperf.ifindex==lastifindex| where\tswitchperf.type==lasttype | eval Pkts=case(_totalPkts-last_totalPkts<0,_totalPkts-last_totalPkts+4294967296,default,_totalPkts-last_totalPkts) | stats sum(Pkts) as Pkts by switchperf.devip,switchperf.type | parse field=switchperf.type \"[a-zA-Z]+(?<type>[A-Z]\\S+)\" | stats sum(Pkts) as Pkts by type | eval type=case(type==\"Pkts\",\"正常包数\",type==\"Discards\",\"丢弃包数\",type==\"Errors\",\"错误包数\")\n"}
{"input": "按每5分钟分桶统计正常包和丢包、错包实时趋势。索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "网络设备接口数据数据，编写查询语句实现如下分析场景", "output": "appname:switchperf AND (switchperf.type:ifInErrors OR switchperf.type:ifOutErrors OR switchperf.type:ifInDiscards OR switchperf.type:ifOutDiscards OR switchperf.type:ifInUcastPkts OR switchperf.type:ifInNUcastPkts OR switchperf.type:ifOutNUcastPkts OR switchperf.type:ifOutUcastPkts)\n| bucket timestamp span=5m as ts | stats sum(switchperf.value) as _totalPkts by ts,switchperf.devip,switchperf.ifindex,switchperf.type  | sort by switchperf.ifindex,switchperf.type,+ts | autoregress _totalPkts as last_totalPkts p=1 | autoregress switchperf.ifindex as lastifindex p=1 | autoregress switchperf.type as lasttype p=1 | where\tswitchperf.ifindex==lastifindex| where\tswitchperf.type==lasttype | eval Pkts=case(_totalPkts-last_totalPkts<0,_totalPkts-last_totalPkts+4294967296,default,_totalPkts-last_totalPkts) | stats sum(Pkts) as Pkts by ts,switchperf.devip,switchperf.type | parse field=switchperf.type \"[a-zA-Z]+(?<type>[A-Z]\\S+)\" | eval type=case(type==\"Pkts\",\"正常包数\",type==\"Discards\",\"丢弃包数\",type==\"Errors\",\"错误包数\")\n"}
{"input": "索引可用字段有：switchperf.devip, switchperf.ifindex, switchperf.type, switchperf.value, appname, tag, logtype, ip, hostname, timestamp, source。请仅使用所需要的字段。", "instruction": "我想问的是，在五分钟内，这个交换机的哪个端口出错了或者丢失了数据包呢？", "output": "appname:switchperf AND (switchperf.type:ifInErrors OR switchperf.type:ifOutErrors OR switchperf.type:ifInDiscards OR switchperf.type:ifOutDiscards OR switchperf.type:ifInUcastPkts OR switchperf.type:ifInNUcastPkts OR switchperf.type:ifOutNUcastPkts OR switchperf.type:ifOutUcastPkts)| bucket timestamp span=5m as ts | stats sum(switchperf.value) as _totalPkts by ts,switchperf.devip,switchperf.ifindex,switchperf.type  | sort by switchperf.ifindex,switchperf.type,+ts | autoregress _totalPkts as last_totalPkts p=1 | autoregress switchperf.ifindex as lastifindex p=1 | autoregress switchperf.type as lasttype p=1 | where switchperf.ifindex==lastifindex| where switchperf.type==lasttype | eval Pkts=case(_totalPkts-last_totalPkts<0,_totalPkts-last_totalPkts+4294967296,default,_totalPkts-last_totalPkts) | stats sum(Pkts) as Pkts by ts,switchperf.devip,switchperf.type | parse field=switchperf.type \"[a-zA-Z]+(?<type>[A-Z]\\S+)\" | eval type=case(type==\"Pkts\",\"正常包数\",type==\"Discards\",\"丢弃包数\",type==\"Errors\",\"错误包数\")"}
{"input": "", "instruction": "业务交易日志里如果任意某个业务类型下连续出现 10 次以上失败，中间不含成功，就要过滤出来监控告警。请生成对应的查询语句", "output": "trans_status:failed OR trans_status:success | streamstats window=10 count() as cnt by trans_type, trans_status | where cnt >= 10"}
{"input": "", "instruction": "审计日志里如果任意某台服务器下连续出现 3 次以上SSH失败，然后才登录成功的，过滤出来发告警。请生成对应的查询语句", "output": "appname:audit AND audit.msg.ser:sshd AND (\"Accepted password for\" OR \"Failed password for\") | parse \"(?<status>Accepted|Failed) password for\" | streamstats window=3 count() as cnt by hostname, status | where cnt >= 3"}
